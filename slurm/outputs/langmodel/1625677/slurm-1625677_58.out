FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'rnn_dropout', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5733966827392578 and batch: 50, loss is 7.529269466400146 and perplexity is 1861.7449394155121
At time: 2.290335178375244 and batch: 100, loss is 6.661665878295898 and perplexity is 781.8523236666405
At time: 3.0045719146728516 and batch: 150, loss is 6.322501630783081 and perplexity is 556.9645708335003
At time: 3.7215664386749268 and batch: 200, loss is 6.121335554122925 and perplexity is 455.47259677046895
At time: 4.435655355453491 and batch: 250, loss is 5.9791983699798585 and perplexity is 395.1234983081944
At time: 5.152608633041382 and batch: 300, loss is 5.863260517120361 and perplexity is 351.8695523930861
At time: 5.8701348304748535 and batch: 350, loss is 5.771248979568481 and perplexity is 320.93832784189124
At time: 6.587938070297241 and batch: 400, loss is 5.685671348571777 and perplexity is 294.6155684137898
At time: 7.307750701904297 and batch: 450, loss is 5.583511943817139 and perplexity is 266.00415895193953
At time: 8.024023056030273 and batch: 500, loss is 5.5559280967712406 and perplexity is 258.76701393893825
At time: 8.738792419433594 and batch: 550, loss is 5.499081373214722 and perplexity is 244.46725491421682
At time: 9.453074216842651 and batch: 600, loss is 5.486215696334839 and perplexity is 241.34216451320245
At time: 10.170368432998657 and batch: 650, loss is 5.527605218887329 and perplexity is 251.54080399061797
At time: 10.885520458221436 and batch: 700, loss is 5.472345523834228 and perplexity is 238.01781500545505
At time: 11.601327180862427 and batch: 750, loss is 5.393798112869263 and perplexity is 220.03752783412324
At time: 12.316478729248047 and batch: 800, loss is 5.382771310806274 and perplexity is 217.6245457557116
At time: 13.034759283065796 and batch: 850, loss is 5.388177900314331 and perplexity is 218.80433879592985
At time: 13.751051902770996 and batch: 900, loss is 5.382208957672119 and perplexity is 217.50219831479447
At time: 14.473661422729492 and batch: 950, loss is 5.39705075263977 and perplexity is 220.75439587288867
At time: 15.192054271697998 and batch: 1000, loss is 5.357533445358277 and perplexity is 212.20089531154392
At time: 15.907220125198364 and batch: 1050, loss is 5.257499742507934 and perplexity is 192.00083913402307
At time: 16.625672340393066 and batch: 1100, loss is 5.331812877655029 and perplexity is 206.8125603837158
At time: 17.34388566017151 and batch: 1150, loss is 5.2297523307800295 and perplexity is 186.7465464206905
At time: 18.061491012573242 and batch: 1200, loss is 5.302763643264771 and perplexity is 200.8912352142748
At time: 18.776833295822144 and batch: 1250, loss is 5.2617794704437255 and perplexity is 192.82431135058746
At time: 19.49686288833618 and batch: 1300, loss is 5.269172582626343 and perplexity is 194.25516583247853
At time: 20.215712785720825 and batch: 1350, loss is 5.202108488082886 and perplexity is 181.65485546324894
At time: 20.933332920074463 and batch: 1400, loss is 5.2027435207366945 and perplexity is 181.77024886360175
At time: 21.65160298347473 and batch: 1450, loss is 5.159768362045288 and perplexity is 174.12411717896646
At time: 22.370210647583008 and batch: 1500, loss is 5.125296926498413 and perplexity is 168.22408442514916
At time: 23.08781409263611 and batch: 1550, loss is 5.11156153678894 and perplexity is 165.9292573179386
At time: 23.807552099227905 and batch: 1600, loss is 5.143262052536011 and perplexity is 171.27356140686484
At time: 24.524145364761353 and batch: 1650, loss is 5.126027927398682 and perplexity is 168.34710133957054
At time: 25.244693994522095 and batch: 1700, loss is 5.143217811584472 and perplexity is 171.26598426914592
At time: 25.962477922439575 and batch: 1750, loss is 5.131298847198487 and perplexity is 169.23678808318098
At time: 26.68193817138672 and batch: 1800, loss is 5.090077772140503 and perplexity is 162.40249195177773
At time: 27.40202832221985 and batch: 1850, loss is 5.082959995269776 and perplexity is 161.25065138583105
At time: 28.12143898010254 and batch: 1900, loss is 5.166048803329468 and perplexity is 175.2211347443832
At time: 28.843771934509277 and batch: 1950, loss is 5.083446264266968 and perplexity is 161.3290816459335
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.805855400617733 and perplexity of 122.22399680002039
finished 1 epochs...
Completing Train Step...
At time: 31.49312162399292 and batch: 50, loss is 5.045869750976562 and perplexity is 155.37938181479697
At time: 32.23961091041565 and batch: 100, loss is 4.993941335678101 and perplexity is 147.51669202940474
At time: 32.951924085617065 and batch: 150, loss is 4.922907943725586 and perplexity is 137.40158889417702
At time: 33.6668815612793 and batch: 200, loss is 4.891971530914307 and perplexity is 133.21595469347818
At time: 34.38557481765747 and batch: 250, loss is 4.910928564071655 and perplexity is 135.76542278975904
At time: 35.10240173339844 and batch: 300, loss is 4.917330846786499 and perplexity is 136.6374198165674
At time: 35.81699776649475 and batch: 350, loss is 4.920938663482666 and perplexity is 137.13127291114282
At time: 36.560791969299316 and batch: 400, loss is 4.8600774765014645 and perplexity is 129.0341988384126
At time: 37.27091360092163 and batch: 450, loss is 4.841590967178345 and perplexity is 126.67072046082959
At time: 37.98651742935181 and batch: 500, loss is 4.840329790115357 and perplexity is 126.51106695046654
At time: 38.71142649650574 and batch: 550, loss is 4.815534954071045 and perplexity is 123.41281484216181
At time: 39.431766510009766 and batch: 600, loss is 4.773352298736572 and perplexity is 118.31520581025234
At time: 40.14575552940369 and batch: 650, loss is 4.843682355880738 and perplexity is 126.935915390704
At time: 40.86029624938965 and batch: 700, loss is 4.856086521148682 and perplexity is 128.5202553567733
At time: 41.57281231880188 and batch: 750, loss is 4.804593849182129 and perplexity is 122.06990216098554
At time: 42.29075479507446 and batch: 800, loss is 4.793906593322754 and perplexity is 120.77225637127162
At time: 43.00409197807312 and batch: 850, loss is 4.791906080245972 and perplexity is 120.5308914004748
At time: 43.71793532371521 and batch: 900, loss is 4.769330282211303 and perplexity is 117.84029578547967
At time: 44.428646087646484 and batch: 950, loss is 4.818553457260132 and perplexity is 123.7858996128463
At time: 45.141900300979614 and batch: 1000, loss is 4.798905839920044 and perplexity is 121.37753837936874
At time: 45.85972738265991 and batch: 1050, loss is 4.727622661590576 and perplexity is 113.0265403615261
At time: 46.57322573661804 and batch: 1100, loss is 4.780494146347046 and perplexity is 119.1632195681878
At time: 47.28643321990967 and batch: 1150, loss is 4.726430616378784 and perplexity is 112.89188788714617
At time: 47.999584913253784 and batch: 1200, loss is 4.792451238632202 and perplexity is 120.59661774072654
At time: 48.71378803253174 and batch: 1250, loss is 4.783320474624634 and perplexity is 119.50049033974766
At time: 49.429429054260254 and batch: 1300, loss is 4.771256942749023 and perplexity is 118.06755288646838
At time: 50.14477610588074 and batch: 1350, loss is 4.669726638793946 and perplexity is 106.66857939509934
At time: 50.86925768852234 and batch: 1400, loss is 4.665421352386475 and perplexity is 106.21032777019772
At time: 51.58914637565613 and batch: 1450, loss is 4.6249298667907714 and perplexity is 101.99561955172615
At time: 52.30674386024475 and batch: 1500, loss is 4.6113695049285885 and perplexity is 100.62185744880225
At time: 53.028432846069336 and batch: 1550, loss is 4.618786563873291 and perplexity is 101.37095029538875
At time: 53.74632740020752 and batch: 1600, loss is 4.677364196777344 and perplexity is 107.48638590217114
At time: 54.466591358184814 and batch: 1650, loss is 4.651863489151001 and perplexity is 104.78006026642711
At time: 55.18629264831543 and batch: 1700, loss is 4.66168999671936 and perplexity is 105.81475772698806
At time: 55.90306735038757 and batch: 1750, loss is 4.645995063781738 and perplexity is 104.16696700807795
At time: 56.620845317840576 and batch: 1800, loss is 4.611813974380493 and perplexity is 100.66659073118447
At time: 57.33832597732544 and batch: 1850, loss is 4.646114931106568 and perplexity is 104.17945397212335
At time: 58.05516076087952 and batch: 1900, loss is 4.733007593154907 and perplexity is 113.63682223466752
At time: 58.769888401031494 and batch: 1950, loss is 4.659258937835693 and perplexity is 105.55782825207277
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.59195670194404 and perplexity of 98.68734307991197
finished 2 epochs...
Completing Train Step...
At time: 61.4261200428009 and batch: 50, loss is 4.666306047439575 and perplexity is 106.30433309865734
At time: 62.17060685157776 and batch: 100, loss is 4.615785961151123 and perplexity is 101.06723224247185
At time: 62.88823103904724 and batch: 150, loss is 4.557908353805542 and perplexity is 95.38376195061143
At time: 63.602601051330566 and batch: 200, loss is 4.547738943099976 and perplexity is 94.41868077126102
At time: 64.3166491985321 and batch: 250, loss is 4.55813304901123 and perplexity is 95.40519663266726
At time: 65.0326919555664 and batch: 300, loss is 4.571637659072876 and perplexity is 96.70234564298634
At time: 65.75057744979858 and batch: 350, loss is 4.58737847328186 and perplexity is 98.2365625328094
At time: 66.46549773216248 and batch: 400, loss is 4.529232835769653 and perplexity is 92.68742732111835
At time: 67.18088722229004 and batch: 450, loss is 4.539995126724243 and perplexity is 93.6903435394816
At time: 67.89982533454895 and batch: 500, loss is 4.547021551132202 and perplexity is 94.35096985860434
At time: 68.61519694328308 and batch: 550, loss is 4.517020931243897 and perplexity is 91.56242052676122
At time: 69.329336643219 and batch: 600, loss is 4.481313943862915 and perplexity is 88.35068428198838
At time: 70.04716038703918 and batch: 650, loss is 4.546742353439331 and perplexity is 94.32463096255029
At time: 70.76961588859558 and batch: 700, loss is 4.577396955490112 and perplexity is 97.26088998310948
At time: 71.48655414581299 and batch: 750, loss is 4.529923791885376 and perplexity is 92.75149239640547
At time: 72.20258975028992 and batch: 800, loss is 4.518302373886108 and perplexity is 91.679827726078
At time: 72.97606348991394 and batch: 850, loss is 4.51910472869873 and perplexity is 91.75341699547872
At time: 73.69411754608154 and batch: 900, loss is 4.496174411773682 and perplexity is 89.67342068967187
At time: 74.41110324859619 and batch: 950, loss is 4.553417863845826 and perplexity is 94.9564023703286
At time: 75.1320276260376 and batch: 1000, loss is 4.542364978790284 and perplexity is 93.91263909343762
At time: 75.84654426574707 and batch: 1050, loss is 4.477697858810425 and perplexity is 88.03177763745795
At time: 76.56248307228088 and batch: 1100, loss is 4.520726728439331 and perplexity is 91.90236177558727
At time: 77.27852249145508 and batch: 1150, loss is 4.47987398147583 and perplexity is 88.22355417300362
At time: 77.99337244033813 and batch: 1200, loss is 4.53678521156311 and perplexity is 93.39008764109128
At time: 78.71014666557312 and batch: 1250, loss is 4.542619676589966 and perplexity is 93.93656148233764
At time: 79.43014574050903 and batch: 1300, loss is 4.5280551338195805 and perplexity is 92.57833340988034
At time: 80.1469337940216 and batch: 1350, loss is 4.423207597732544 and perplexity is 83.36325274794359
At time: 80.86115527153015 and batch: 1400, loss is 4.426867580413818 and perplexity is 83.66891983616743
At time: 81.58314156532288 and batch: 1450, loss is 4.379074783325195 and perplexity is 79.7642000864702
At time: 82.30251550674438 and batch: 1500, loss is 4.367977089881897 and perplexity is 78.88389515803323
At time: 83.02177691459656 and batch: 1550, loss is 4.384013395309449 and perplexity is 80.1590988441726
At time: 83.73725366592407 and batch: 1600, loss is 4.454359703063965 and perplexity is 86.00106699231826
At time: 84.45435929298401 and batch: 1650, loss is 4.422236480712891 and perplexity is 83.28233657028417
At time: 85.17951726913452 and batch: 1700, loss is 4.43337155342102 and perplexity is 84.2148737424967
At time: 85.89516401290894 and batch: 1750, loss is 4.421689682006836 and perplexity is 83.23681034438532
At time: 86.61674880981445 and batch: 1800, loss is 4.384230289459229 and perplexity is 80.176486769365
At time: 87.33415341377258 and batch: 1850, loss is 4.427744808197022 and perplexity is 83.7423487394666
At time: 88.05311155319214 and batch: 1900, loss is 4.519712581634521 and perplexity is 91.80920653356775
At time: 88.7733964920044 and batch: 1950, loss is 4.445420598983764 and perplexity is 85.23572035649298
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.518160655886628 and perplexity of 91.66683596490489
finished 3 epochs...
Completing Train Step...
At time: 91.44727659225464 and batch: 50, loss is 4.457510070800781 and perplexity is 86.2724292000398
At time: 92.16340923309326 and batch: 100, loss is 4.407418832778931 and perplexity is 82.05738608309933
At time: 92.87852883338928 and batch: 150, loss is 4.357291431427002 and perplexity is 78.04545640979205
At time: 93.59706950187683 and batch: 200, loss is 4.352285490036011 and perplexity is 77.65574168753695
At time: 94.31455779075623 and batch: 250, loss is 4.354099683761596 and perplexity is 77.7967521183059
At time: 95.0353946685791 and batch: 300, loss is 4.372923278808594 and perplexity is 79.27503633841444
At time: 95.75577473640442 and batch: 350, loss is 4.387464876174927 and perplexity is 80.43624444626876
At time: 96.47896528244019 and batch: 400, loss is 4.329877424240112 and perplexity is 75.93497821105315
At time: 97.19567060470581 and batch: 450, loss is 4.354434976577759 and perplexity is 77.82284118390565
At time: 97.91642332077026 and batch: 500, loss is 4.366782026290894 and perplexity is 78.78968019466251
At time: 98.63317894935608 and batch: 550, loss is 4.334000806808472 and perplexity is 76.24873359873918
At time: 99.34971284866333 and batch: 600, loss is 4.308761968612671 and perplexity is 74.3483863032909
At time: 100.06582140922546 and batch: 650, loss is 4.36570671081543 and perplexity is 78.70500196830544
At time: 100.78968667984009 and batch: 700, loss is 4.400503997802734 and perplexity is 81.49193007036592
At time: 101.50901484489441 and batch: 750, loss is 4.357159156799316 and perplexity is 78.03513365883695
At time: 102.22745776176453 and batch: 800, loss is 4.34685869216919 and perplexity is 77.23546109455616
At time: 102.94826745986938 and batch: 850, loss is 4.346016817092895 and perplexity is 77.17046584763258
At time: 103.66354298591614 and batch: 900, loss is 4.327438449859619 and perplexity is 75.75000041436313
At time: 104.38493132591248 and batch: 950, loss is 4.392902088165283 and perplexity is 80.87478449625081
At time: 105.10390043258667 and batch: 1000, loss is 4.376966485977173 and perplexity is 79.59621058309796
At time: 105.8225200176239 and batch: 1050, loss is 4.315986423492432 and perplexity is 74.88745776963178
At time: 106.55323147773743 and batch: 1100, loss is 4.352933378219604 and perplexity is 77.70607022683693
At time: 107.27355623245239 and batch: 1150, loss is 4.3139158678054805 and perplexity is 74.73255953611468
At time: 107.99881768226624 and batch: 1200, loss is 4.375941700935364 and perplexity is 79.51468335818292
At time: 108.716970205307 and batch: 1250, loss is 4.38508599281311 and perplexity is 80.24512342011396
At time: 109.43502402305603 and batch: 1300, loss is 4.365795602798462 and perplexity is 78.71199852296915
At time: 110.15416026115417 and batch: 1350, loss is 4.258759188652038 and perplexity is 70.72217611069748
At time: 110.87206721305847 and batch: 1400, loss is 4.269396467208862 and perplexity is 71.47848299017042
At time: 111.59197998046875 and batch: 1450, loss is 4.219002203941345 and perplexity is 67.9656346026434
At time: 112.31027674674988 and batch: 1500, loss is 4.2087577438354495 and perplexity is 67.27291768411924
At time: 113.02667951583862 and batch: 1550, loss is 4.231298446655273 and perplexity is 68.80651578658232
At time: 113.74771475791931 and batch: 1600, loss is 4.307972555160522 and perplexity is 74.28971784687864
At time: 114.46579241752625 and batch: 1650, loss is 4.267957754135132 and perplexity is 71.37571990322614
At time: 115.1847779750824 and batch: 1700, loss is 4.282472453117371 and perplexity is 72.41927209429676
At time: 115.90597796440125 and batch: 1750, loss is 4.2715472221374515 and perplexity is 71.63238112901544
At time: 116.62589144706726 and batch: 1800, loss is 4.234397010803223 and perplexity is 69.02004784008146
At time: 117.3468451499939 and batch: 1850, loss is 4.28480941772461 and perplexity is 72.58871127963812
At time: 118.0645592212677 and batch: 1900, loss is 4.370690536499024 and perplexity is 79.0982330622156
At time: 118.78286170959473 and batch: 1950, loss is 4.300368070602417 and perplexity is 73.72692541994884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.490145803052326 and perplexity of 89.13444100483699
finished 4 epochs...
Completing Train Step...
At time: 121.43642139434814 and batch: 50, loss is 4.309944920539856 and perplexity is 74.43638891131647
At time: 122.1841766834259 and batch: 100, loss is 4.266692590713501 and perplexity is 71.28547505249152
At time: 122.8994870185852 and batch: 150, loss is 4.217713112831116 and perplexity is 67.8780771541652
At time: 123.6188759803772 and batch: 200, loss is 4.21366515159607 and perplexity is 67.60386470425614
At time: 124.33409476280212 and batch: 250, loss is 4.214578485488891 and perplexity is 67.66563781061797
At time: 125.05016756057739 and batch: 300, loss is 4.233298549652099 and perplexity is 68.94427362401596
At time: 125.76674318313599 and batch: 350, loss is 4.243834152221679 and perplexity is 69.67448293354789
At time: 126.48618221282959 and batch: 400, loss is 4.190029039382934 and perplexity is 66.02470824935732
At time: 127.20459222793579 and batch: 450, loss is 4.221836967468262 and perplexity is 68.15857444490908
At time: 127.9548978805542 and batch: 500, loss is 4.237828574180603 and perplexity is 69.25730135096671
At time: 128.67322158813477 and batch: 550, loss is 4.2057036018371585 and perplexity is 67.06777007530091
At time: 129.39061665534973 and batch: 600, loss is 4.186781492233276 and perplexity is 65.81063768654052
At time: 130.1114523410797 and batch: 650, loss is 4.2365113496780396 and perplexity is 69.16613399376605
At time: 130.83101534843445 and batch: 700, loss is 4.27466986656189 and perplexity is 71.85641318874535
At time: 131.55253624916077 and batch: 750, loss is 4.23429913520813 and perplexity is 69.01329279240834
At time: 132.269837141037 and batch: 800, loss is 4.224485177993774 and perplexity is 68.33931190895906
At time: 132.9901351928711 and batch: 850, loss is 4.220867805480957 and perplexity is 68.09254974493085
At time: 133.71064114570618 and batch: 900, loss is 4.206485342979431 and perplexity is 67.12022020903188
At time: 134.42997980117798 and batch: 950, loss is 4.272473602294922 and perplexity is 71.69877069176468
At time: 135.14823961257935 and batch: 1000, loss is 4.257599296569825 and perplexity is 70.64019357322906
At time: 135.86496496200562 and batch: 1050, loss is 4.1988785314559935 and perplexity is 66.61158633809788
At time: 136.58367609977722 and batch: 1100, loss is 4.231152338981628 and perplexity is 68.79646336101527
At time: 137.3054633140564 and batch: 1150, loss is 4.195808806419373 and perplexity is 66.40742061043441
At time: 138.02095913887024 and batch: 1200, loss is 4.260620760917663 and perplexity is 70.85395317051412
At time: 138.7393617630005 and batch: 1250, loss is 4.267989444732666 and perplexity is 71.37798187828075
At time: 139.45636796951294 and batch: 1300, loss is 4.24751498222351 and perplexity is 69.9314154330304
At time: 140.17718720436096 and batch: 1350, loss is 4.140426054000854 and perplexity is 62.82958454340187
At time: 140.8979697227478 and batch: 1400, loss is 4.155296277999878 and perplexity is 63.77085565072835
At time: 141.61811017990112 and batch: 1450, loss is 4.102397313117981 and perplexity is 60.48511569014331
At time: 142.3376703262329 and batch: 1500, loss is 4.093831067085266 and perplexity is 59.96919820075379
At time: 143.05625104904175 and batch: 1550, loss is 4.1132468986511235 and perplexity is 61.144926993512215
At time: 143.7747323513031 and batch: 1600, loss is 4.200907788276672 and perplexity is 66.74689559619584
At time: 144.4961588382721 and batch: 1650, loss is 4.155782051086426 and perplexity is 63.80184134150761
At time: 145.2141137123108 and batch: 1700, loss is 4.170091638565063 and perplexity is 64.72138281030799
At time: 145.93185353279114 and batch: 1750, loss is 4.158174777030945 and perplexity is 63.95468444550307
At time: 146.6497459411621 and batch: 1800, loss is 4.123468933105468 and perplexity is 61.77315797299596
At time: 147.36665391921997 and batch: 1850, loss is 4.175992412567139 and perplexity is 65.10441805416552
At time: 148.08744072914124 and batch: 1900, loss is 4.259856691360474 and perplexity is 70.79983649897342
At time: 148.80548238754272 and batch: 1950, loss is 4.187458467483521 and perplexity is 65.8552049432199
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482166662881541 and perplexity of 88.42605472112069
finished 5 epochs...
Completing Train Step...
At time: 151.54194474220276 and batch: 50, loss is 4.198267827033996 and perplexity is 66.57091876696167
At time: 152.30057573318481 and batch: 100, loss is 4.155186061859131 and perplexity is 63.76382746044349
At time: 153.0200879573822 and batch: 150, loss is 4.1097521257400516 and perplexity is 60.93161231928707
At time: 153.7426679134369 and batch: 200, loss is 4.110680017471314 and perplexity is 60.98817649718868
At time: 154.46002507209778 and batch: 250, loss is 4.11225013256073 and perplexity is 61.08401016864179
At time: 155.18390822410583 and batch: 300, loss is 4.127048749923706 and perplexity is 61.994690849802176
At time: 155.9018039703369 and batch: 350, loss is 4.138742260932922 and perplexity is 62.72388154045219
At time: 156.62010216712952 and batch: 400, loss is 4.084331097602845 and perplexity is 59.40219019169146
At time: 157.34253668785095 and batch: 450, loss is 4.122340965270996 and perplexity is 61.70351912034507
At time: 158.06063985824585 and batch: 500, loss is 4.136767172813416 and perplexity is 62.60011860879329
At time: 158.78447008132935 and batch: 550, loss is 4.109198780059814 and perplexity is 60.897905401469046
At time: 159.50454878807068 and batch: 600, loss is 4.093484930992126 and perplexity is 59.94844428882606
At time: 160.23135137557983 and batch: 650, loss is 4.13726053237915 and perplexity is 62.63101059592711
At time: 160.95849418640137 and batch: 700, loss is 4.1769456911087035 and perplexity is 65.16651028975339
At time: 161.68635773658752 and batch: 750, loss is 4.139674506187439 and perplexity is 62.78238284590849
At time: 162.42572712898254 and batch: 800, loss is 4.128583917617798 and perplexity is 62.089936186476244
At time: 163.14662957191467 and batch: 850, loss is 4.124324231147766 and perplexity is 61.82601503512548
At time: 163.86633610725403 and batch: 900, loss is 4.1104084014892575 and perplexity is 60.971613383240644
At time: 164.6383831501007 and batch: 950, loss is 4.176393280029297 and perplexity is 65.13052152867341
At time: 165.35549187660217 and batch: 1000, loss is 4.164389758110047 and perplexity is 64.35339931855219
At time: 166.0754792690277 and batch: 1050, loss is 4.107322993278504 and perplexity is 60.78378098550587
At time: 166.79267930984497 and batch: 1100, loss is 4.139654021263123 and perplexity is 62.781096766720175
At time: 167.5103578567505 and batch: 1150, loss is 4.108851919174194 and perplexity is 60.876785963034386
At time: 168.22756719589233 and batch: 1200, loss is 4.173433485031128 and perplexity is 64.93803353984043
At time: 168.9477572441101 and batch: 1250, loss is 4.177525191307068 and perplexity is 65.20428523963136
At time: 169.66349697113037 and batch: 1300, loss is 4.153405075073242 and perplexity is 63.650365992996704
At time: 170.38229179382324 and batch: 1350, loss is 4.047616319656372 and perplexity is 57.260802790048984
At time: 171.10131788253784 and batch: 1400, loss is 4.067582378387451 and perplexity is 58.41556500536671
At time: 171.82251143455505 and batch: 1450, loss is 4.012696075439453 and perplexity is 55.29575129341008
At time: 172.54357290267944 and batch: 1500, loss is 4.005905795097351 and perplexity is 54.921549545590615
At time: 173.26505303382874 and batch: 1550, loss is 4.0224313020706175 and perplexity is 55.83669680524888
At time: 173.9841012954712 and batch: 1600, loss is 4.1169657802581785 and perplexity is 61.372741082127895
At time: 174.7049810886383 and batch: 1650, loss is 4.07067214012146 and perplexity is 58.596334306013325
At time: 175.42744517326355 and batch: 1700, loss is 4.082995619773865 and perplexity is 59.32291283205827
At time: 176.1461946964264 and batch: 1750, loss is 4.071366477012634 and perplexity is 58.63703403063455
At time: 176.86759757995605 and batch: 1800, loss is 4.037525148391723 and perplexity is 56.685879923672196
At time: 177.58685517311096 and batch: 1850, loss is 4.0911874055862425 and perplexity is 59.81086931654349
At time: 178.30812525749207 and batch: 1900, loss is 4.172047548294067 and perplexity is 64.84809587188028
At time: 179.0283544063568 and batch: 1950, loss is 4.104023551940918 and perplexity is 60.583558957924694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479285235737645 and perplexity of 88.17162821856886
finished 6 epochs...
Completing Train Step...
At time: 181.77914953231812 and batch: 50, loss is 4.110886445045471 and perplexity is 61.00076743802928
At time: 182.4999737739563 and batch: 100, loss is 4.071725487709045 and perplexity is 58.6580891323346
At time: 183.24795246124268 and batch: 150, loss is 4.027621521949768 and perplexity is 56.127254916973826
At time: 183.96399545669556 and batch: 200, loss is 4.027794280052185 and perplexity is 56.13695219264453
At time: 184.68386483192444 and batch: 250, loss is 4.0291211128234865 and perplexity is 56.21148597649357
At time: 185.40304517745972 and batch: 300, loss is 4.046074123382568 and perplexity is 57.1725634520291
At time: 186.1214303970337 and batch: 350, loss is 4.049017186164856 and perplexity is 57.34107374224358
At time: 186.84272074699402 and batch: 400, loss is 4.003077797889709 and perplexity is 54.76645096937416
At time: 187.5669903755188 and batch: 450, loss is 4.041401238441467 and perplexity is 56.906025875948835
At time: 188.283198595047 and batch: 500, loss is 4.056851835250854 and perplexity is 57.79208538521953
At time: 189.00371289253235 and batch: 550, loss is 4.0289343738555905 and perplexity is 56.2009900816452
At time: 189.7209780216217 and batch: 600, loss is 4.015469188690186 and perplexity is 55.44930548721118
At time: 190.44270753860474 and batch: 650, loss is 4.058196401596069 and perplexity is 57.86984294163044
At time: 191.15903854370117 and batch: 700, loss is 4.09927041053772 and perplexity is 60.296280015066245
At time: 191.87637376785278 and batch: 750, loss is 4.060219240188599 and perplexity is 57.98702277126012
At time: 192.59870982170105 and batch: 800, loss is 4.052669053077698 and perplexity is 57.55085853211307
At time: 193.31744623184204 and batch: 850, loss is 4.04893536567688 and perplexity is 57.33638225954124
At time: 194.034991979599 and batch: 900, loss is 4.039131484031677 and perplexity is 56.77700964574067
At time: 194.7515320777893 and batch: 950, loss is 4.102974195480346 and perplexity is 60.52001855302561
At time: 195.4702751636505 and batch: 1000, loss is 4.088968858718872 and perplexity is 59.67832318405555
At time: 196.19337797164917 and batch: 1050, loss is 4.035526733398438 and perplexity is 56.57271112809723
At time: 196.91301655769348 and batch: 1100, loss is 4.065110754966736 and perplexity is 58.27136200792845
At time: 197.63114857673645 and batch: 1150, loss is 4.037508349418641 and perplexity is 56.68492766709967
At time: 198.34915900230408 and batch: 1200, loss is 4.101420459747314 and perplexity is 60.42605945034582
At time: 199.06727075576782 and batch: 1250, loss is 4.104618225097656 and perplexity is 60.6195970885691
At time: 199.7926423549652 and batch: 1300, loss is 4.0807679176330565 and perplexity is 59.190906142527744
At time: 200.51258730888367 and batch: 1350, loss is 3.975313596725464 and perplexity is 53.26681858668719
At time: 201.23374438285828 and batch: 1400, loss is 3.9929834747314454 and perplexity is 54.21640157384931
At time: 201.9587116241455 and batch: 1450, loss is 3.940400466918945 and perplexity is 51.43919687301369
At time: 202.67693781852722 and batch: 1500, loss is 3.9372369909286498 and perplexity is 51.276727328491354
At time: 203.40184807777405 and batch: 1550, loss is 3.956423840522766 and perplexity is 52.27006522243879
At time: 204.1244020462036 and batch: 1600, loss is 4.044904584884644 and perplexity is 57.10573702370444
At time: 204.84057092666626 and batch: 1650, loss is 4.00123966217041 and perplexity is 54.66587526384481
At time: 205.55935740470886 and batch: 1700, loss is 4.011896848678589 and perplexity is 55.25157510496181
At time: 206.2782232761383 and batch: 1750, loss is 4.001526789665222 and perplexity is 54.68157359326418
At time: 206.99903678894043 and batch: 1800, loss is 3.9669631481170655 and perplexity is 52.82386874439766
At time: 207.717924118042 and batch: 1850, loss is 4.0164251708984375 and perplexity is 55.50233938240801
At time: 208.43548226356506 and batch: 1900, loss is 4.098227624893188 and perplexity is 60.233436691600325
At time: 209.1547589302063 and batch: 1950, loss is 4.035163545608521 and perplexity is 56.552168340843565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.484002259720204 and perplexity of 88.58851837088586
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 211.81216430664062 and batch: 50, loss is 4.075713882446289 and perplexity is 58.89250791289485
At time: 212.56269812583923 and batch: 100, loss is 4.061887497901917 and perplexity is 58.08384080553245
At time: 213.2804491519928 and batch: 150, loss is 4.018644976615906 and perplexity is 55.62568063886769
At time: 214.0060031414032 and batch: 200, loss is 4.018458647727966 and perplexity is 55.61531693321224
At time: 214.7300727367401 and batch: 250, loss is 4.012215843200684 and perplexity is 55.26920286618756
At time: 215.44776368141174 and batch: 300, loss is 4.032638015747071 and perplexity is 56.40952435261377
At time: 216.16905570030212 and batch: 350, loss is 4.037315888404846 and perplexity is 56.674019078226706
At time: 216.89409065246582 and batch: 400, loss is 3.9843120431900023 and perplexity is 53.748300246671356
At time: 217.6130256652832 and batch: 450, loss is 4.007752165794373 and perplexity is 55.02304875905845
At time: 218.33407974243164 and batch: 500, loss is 4.01151828289032 and perplexity is 55.23066270748796
At time: 219.05567574501038 and batch: 550, loss is 3.98485737323761 and perplexity is 53.777618803222055
At time: 219.80789875984192 and batch: 600, loss is 3.9581798934936523 and perplexity is 52.36193486613307
At time: 220.52373909950256 and batch: 650, loss is 3.9928642082214356 and perplexity is 54.20993575843359
At time: 221.24445176124573 and batch: 700, loss is 4.031431136131286 and perplexity is 56.341485912897994
At time: 221.96808528900146 and batch: 750, loss is 3.974961071014404 and perplexity is 53.24804397305046
At time: 222.68566298484802 and batch: 800, loss is 3.9718579292297362 and perplexity is 53.08306385358652
At time: 223.40691304206848 and batch: 850, loss is 3.9773871231079103 and perplexity is 53.37738333017743
At time: 224.12509059906006 and batch: 900, loss is 3.948648691177368 and perplexity is 51.865233511982034
At time: 224.84392166137695 and batch: 950, loss is 4.016927886009216 and perplexity is 55.53024826161899
At time: 225.568457365036 and batch: 1000, loss is 3.9830019283294678 and perplexity is 53.677929906469245
At time: 226.29098415374756 and batch: 1050, loss is 3.9319239234924317 and perplexity is 51.00501307553889
At time: 227.0081286430359 and batch: 1100, loss is 3.9489699363708497 and perplexity is 51.881897645449634
At time: 227.7267289161682 and batch: 1150, loss is 3.9146619558334352 and perplexity is 50.13212177499498
At time: 228.44599390029907 and batch: 1200, loss is 3.967392864227295 and perplexity is 52.84657288962088
At time: 229.1639814376831 and batch: 1250, loss is 3.9678492736816406 and perplexity is 52.87069807017893
At time: 229.88546872138977 and batch: 1300, loss is 3.9494744682312013 and perplexity is 51.90808032022866
At time: 230.60844016075134 and batch: 1350, loss is 3.8322355365753173 and perplexity is 46.165627910626476
At time: 231.32665157318115 and batch: 1400, loss is 3.8351324605941772 and perplexity is 46.29956012903158
At time: 232.04475212097168 and batch: 1450, loss is 3.7852041339874267 and perplexity is 44.044660653330794
At time: 232.76047921180725 and batch: 1500, loss is 3.788217010498047 and perplexity is 44.1775618837958
At time: 233.4784836769104 and batch: 1550, loss is 3.7950177240371703 and perplexity is 44.47902474643033
At time: 234.1973831653595 and batch: 1600, loss is 3.8807230377197266 and perplexity is 48.45924026613252
At time: 234.91804552078247 and batch: 1650, loss is 3.8258866930007933 and perplexity is 45.8734580123863
At time: 235.6366903781891 and batch: 1700, loss is 3.8200474119186403 and perplexity is 45.60637055512073
At time: 236.35646033287048 and batch: 1750, loss is 3.8013449192047117 and perplexity is 44.76134442085204
At time: 237.07362747192383 and batch: 1800, loss is 3.7562589025497437 and perplexity is 42.788051906404995
At time: 237.80664134025574 and batch: 1850, loss is 3.7960451221466065 and perplexity is 44.524745895253574
At time: 238.53544688224792 and batch: 1900, loss is 3.879361100196838 and perplexity is 48.39328673097518
At time: 239.2686800956726 and batch: 1950, loss is 3.8124042654037478 and perplexity is 45.259123104972474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39335085846657 and perplexity of 80.91108684275389
finished 8 epochs...
Completing Train Step...
At time: 242.0068633556366 and batch: 50, loss is 3.989382243156433 and perplexity is 54.02150689767908
At time: 242.8076765537262 and batch: 100, loss is 3.956495146751404 and perplexity is 52.27379253654922
At time: 243.5316939353943 and batch: 150, loss is 3.9115688896179197 and perplexity is 49.977299364237595
At time: 244.25684142112732 and batch: 200, loss is 3.9124646902084352 and perplexity is 50.02208911686872
At time: 244.97376251220703 and batch: 250, loss is 3.9070100736618043 and perplexity is 49.74998060034961
At time: 245.6952497959137 and batch: 300, loss is 3.9280484342575073 and perplexity is 50.80772623487876
At time: 246.4178969860077 and batch: 350, loss is 3.941373558044434 and perplexity is 51.48927626094536
At time: 247.13956260681152 and batch: 400, loss is 3.889676322937012 and perplexity is 48.89505775347687
At time: 247.8592836856842 and batch: 450, loss is 3.917818531990051 and perplexity is 50.290617655825635
At time: 248.5801763534546 and batch: 500, loss is 3.92874240398407 and perplexity is 50.84299749593941
At time: 249.30013298988342 and batch: 550, loss is 3.9018633365631104 and perplexity is 49.49458831177253
At time: 250.01834297180176 and batch: 600, loss is 3.8802450466156007 and perplexity is 48.436082715365146
At time: 250.7430398464203 and batch: 650, loss is 3.9136126756668093 and perplexity is 50.07954672170965
At time: 251.48777651786804 and batch: 700, loss is 3.9543098163604737 and perplexity is 52.15968175935753
At time: 252.23061871528625 and batch: 750, loss is 3.9047755908966066 and perplexity is 49.63893923234238
At time: 252.9552023410797 and batch: 800, loss is 3.902861065864563 and perplexity is 49.54399515602405
At time: 253.67731404304504 and batch: 850, loss is 3.9083921194076536 and perplexity is 49.818784883776374
At time: 254.40019249916077 and batch: 900, loss is 3.8790321207046508 and perplexity is 48.377368950536365
At time: 255.11996793746948 and batch: 950, loss is 3.9524346446990966 and perplexity is 52.06196504869246
At time: 255.84425973892212 and batch: 1000, loss is 3.9214935064315797 and perplexity is 50.475774405134985
At time: 256.6301181316376 and batch: 1050, loss is 3.874622073173523 and perplexity is 48.16449219734486
At time: 257.3621914386749 and batch: 1100, loss is 3.892247223854065 and perplexity is 49.02092382757099
At time: 258.084623336792 and batch: 1150, loss is 3.8629755401611328 and perplexity is 47.60679676197653
At time: 258.80198884010315 and batch: 1200, loss is 3.9161869144439696 and perplexity is 50.20862950649553
At time: 259.52269196510315 and batch: 1250, loss is 3.9197717618942263 and perplexity is 50.388942788665254
At time: 260.2473464012146 and batch: 1300, loss is 3.903366084098816 and perplexity is 49.5690220959742
At time: 260.964866399765 and batch: 1350, loss is 3.7868181705474853 and perplexity is 44.11580774746066
At time: 261.68715143203735 and batch: 1400, loss is 3.7949786901474 and perplexity is 44.47728859096596
At time: 262.40583324432373 and batch: 1450, loss is 3.7457536697387694 and perplexity is 42.34090625641575
At time: 263.12581491470337 and batch: 1500, loss is 3.7510267448425294 and perplexity is 42.56476272234591
At time: 263.84274315834045 and batch: 1550, loss is 3.7623377084732055 and perplexity is 43.04894432360091
At time: 264.566575050354 and batch: 1600, loss is 3.85290789604187 and perplexity is 47.12991305023686
At time: 265.2866806983948 and batch: 1650, loss is 3.7986682939529417 and perplexity is 44.641695275467704
At time: 266.00414276123047 and batch: 1700, loss is 3.7978916120529176 and perplexity is 44.607036339987076
At time: 266.7246661186218 and batch: 1750, loss is 3.781721954345703 and perplexity is 43.89155595641331
At time: 267.4495630264282 and batch: 1800, loss is 3.7391501235961915 and perplexity is 42.06222727567839
At time: 268.168253660202 and batch: 1850, loss is 3.783914661407471 and perplexity is 43.987902872790166
At time: 268.8864517211914 and batch: 1900, loss is 3.8708102607727053 and perplexity is 47.981247657489874
At time: 269.6066930294037 and batch: 1950, loss is 3.8065435314178466 and perplexity is 44.9946471925256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.392065997456395 and perplexity of 80.80719410013869
finished 9 epochs...
Completing Train Step...
At time: 272.28185391426086 and batch: 50, loss is 3.945201206207275 and perplexity is 51.686736758205434
At time: 272.9999532699585 and batch: 100, loss is 3.9091115522384645 and perplexity is 49.854639048998195
At time: 273.71776127815247 and batch: 150, loss is 3.8642087411880492 and perplexity is 47.66554172736256
At time: 274.438134431839 and batch: 200, loss is 3.8661691427230833 and perplexity is 47.75907698190538
At time: 275.21227383613586 and batch: 250, loss is 3.859024887084961 and perplexity is 47.41908985048453
At time: 275.9332067966461 and batch: 300, loss is 3.881521711349487 and perplexity is 48.49795884314638
At time: 276.65352845191956 and batch: 350, loss is 3.897674298286438 and perplexity is 49.287687247643895
At time: 277.37190437316895 and batch: 400, loss is 3.8465298080444335 and perplexity is 46.83027090526145
At time: 278.0928292274475 and batch: 450, loss is 3.8758485317230225 and perplexity is 48.223600189924845
At time: 278.81245398521423 and batch: 500, loss is 3.88934485912323 and perplexity is 48.87885349686951
At time: 279.5340747833252 and batch: 550, loss is 3.8607946395874024 and perplexity is 47.503084206098755
At time: 280.2528495788574 and batch: 600, loss is 3.8421124744415285 and perplexity is 46.62386219964894
At time: 280.97361421585083 and batch: 650, loss is 3.874789595603943 and perplexity is 48.17256150601394
At time: 281.6920495033264 and batch: 700, loss is 3.916723442077637 and perplexity is 50.2355750515427
At time: 282.4157428741455 and batch: 750, loss is 3.868186311721802 and perplexity is 47.8555123419106
At time: 283.13570833206177 and batch: 800, loss is 3.866776270866394 and perplexity is 47.78808166552856
At time: 283.86152172088623 and batch: 850, loss is 3.8726300048828124 and perplexity is 48.068640742719616
At time: 284.58225417137146 and batch: 900, loss is 3.844232816696167 and perplexity is 46.722825625835334
At time: 285.3065359592438 and batch: 950, loss is 3.9186371421813964 and perplexity is 50.33180292300753
At time: 286.03195095062256 and batch: 1000, loss is 3.888437547683716 and perplexity is 48.83452526673759
At time: 286.75458908081055 and batch: 1050, loss is 3.8428076553344725 and perplexity is 46.65628548652437
At time: 287.4735655784607 and batch: 1100, loss is 3.8607137250900267 and perplexity is 47.499240673417276
At time: 288.1964304447174 and batch: 1150, loss is 3.832458348274231 and perplexity is 46.17591529864531
At time: 288.9220767021179 and batch: 1200, loss is 3.8854069614410403 and perplexity is 48.68675205912296
At time: 289.6445984840393 and batch: 1250, loss is 3.890638313293457 and perplexity is 48.942116959135404
At time: 290.3893895149231 and batch: 1300, loss is 3.8760618066787718 and perplexity is 48.23388617295372
At time: 291.10903429985046 and batch: 1350, loss is 3.759404225349426 and perplexity is 42.92284601598615
At time: 291.8275372982025 and batch: 1400, loss is 3.769850902557373 and perplexity is 43.373597461270094
At time: 292.5481376647949 and batch: 1450, loss is 3.720024433135986 and perplexity is 41.26540233948051
At time: 293.26923418045044 and batch: 1500, loss is 3.7266235065460207 and perplexity is 41.53861624664104
At time: 293.9891951084137 and batch: 1550, loss is 3.7389382791519163 and perplexity is 42.05331757028531
At time: 294.7073941230774 and batch: 1600, loss is 3.8315633964538574 and perplexity is 46.134608565716285
At time: 295.4326367378235 and batch: 1650, loss is 3.778264183998108 and perplexity is 43.740051121132396
At time: 296.15265917778015 and batch: 1700, loss is 3.778704023361206 and perplexity is 43.75929394892574
At time: 296.8723027706146 and batch: 1750, loss is 3.7633477210998536 and perplexity is 43.09244626598905
At time: 297.59544467926025 and batch: 1800, loss is 3.721688289642334 and perplexity is 41.33411919929418
At time: 298.3175377845764 and batch: 1850, loss is 3.7691784858703614 and perplexity is 43.34444213392425
At time: 299.0360815525055 and batch: 1900, loss is 3.8572897911071777 and perplexity is 47.33688451611099
At time: 299.75960874557495 and batch: 1950, loss is 3.7935476541519164 and perplexity is 44.41368551001411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39480832122093 and perplexity of 81.02909771557803
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 302.4129660129547 and batch: 50, loss is 3.940022087097168 and perplexity is 51.4197370007122
At time: 303.164345741272 and batch: 100, loss is 3.9329642963409426 and perplexity is 51.05810491914813
At time: 303.8847346305847 and batch: 150, loss is 3.8960211801528932 and perplexity is 49.206276187684075
At time: 304.60357189178467 and batch: 200, loss is 3.901566686630249 and perplexity is 49.479907923048664
At time: 305.32442831993103 and batch: 250, loss is 3.895827260017395 and perplexity is 49.196735025080066
At time: 306.050626039505 and batch: 300, loss is 3.9183799600601197 and perplexity is 50.31886014756068
At time: 306.76808309555054 and batch: 350, loss is 3.9354288721084596 and perplexity is 51.184096681615316
At time: 307.4878342151642 and batch: 400, loss is 3.894877381324768 and perplexity is 49.15002628206479
At time: 308.2122611999512 and batch: 450, loss is 3.9313778018951417 and perplexity is 50.9771657410358
At time: 308.9348428249359 and batch: 500, loss is 3.9368571424484253 and perplexity is 51.25725364030432
At time: 309.658203125 and batch: 550, loss is 3.9037596559524537 and perplexity is 49.58853490747833
At time: 310.37889981269836 and batch: 600, loss is 3.8675300741195677 and perplexity is 47.824118057419305
At time: 311.09873604774475 and batch: 650, loss is 3.906810779571533 and perplexity is 49.740066711147435
At time: 311.8496108055115 and batch: 700, loss is 3.9556305694580076 and perplexity is 52.228617334023596
At time: 312.5668773651123 and batch: 750, loss is 3.8839885663986204 and perplexity is 48.61774396331074
At time: 313.288761138916 and batch: 800, loss is 3.878101654052734 and perplexity is 48.33237635732031
At time: 314.0077540874481 and batch: 850, loss is 3.8903346729278563 and perplexity is 48.92725841279004
At time: 314.726913690567 and batch: 900, loss is 3.859383659362793 and perplexity is 47.43610555756239
At time: 315.45010900497437 and batch: 950, loss is 3.933973860740662 and perplexity is 51.10967739267796
At time: 316.1669406890869 and batch: 1000, loss is 3.895784215927124 and perplexity is 49.194617441951664
At time: 316.89270067214966 and batch: 1050, loss is 3.849670443534851 and perplexity is 46.97757891539256
At time: 317.617595911026 and batch: 1100, loss is 3.862149229049683 and perplexity is 47.567474985079535
At time: 318.34344506263733 and batch: 1150, loss is 3.838080577850342 and perplexity is 46.4362580629618
At time: 319.06145453453064 and batch: 1200, loss is 3.8720475816726685 and perplexity is 48.04065260193356
At time: 319.7796382904053 and batch: 1250, loss is 3.8752706146240232 and perplexity is 48.19573899830474
At time: 320.4945158958435 and batch: 1300, loss is 3.873352818489075 and perplexity is 48.103397970268226
At time: 321.21367025375366 and batch: 1350, loss is 3.75796187877655 and perplexity is 42.8609810222429
At time: 321.9300420284271 and batch: 1400, loss is 3.764865026473999 and perplexity is 43.15788029544217
At time: 322.64859652519226 and batch: 1450, loss is 3.6981141710281373 and perplexity is 40.371099538885474
At time: 323.3688418865204 and batch: 1500, loss is 3.711060438156128 and perplexity is 40.89715244102316
At time: 324.09203815460205 and batch: 1550, loss is 3.7210616159439085 and perplexity is 41.3082243086153
At time: 324.814640045166 and batch: 1600, loss is 3.8124745178222654 and perplexity is 45.262302779519196
At time: 325.5398590564728 and batch: 1650, loss is 3.7636380100250246 and perplexity is 43.104957341724095
At time: 326.26043367385864 and batch: 1700, loss is 3.7502729272842408 and perplexity is 42.53268874732299
At time: 326.9807891845703 and batch: 1750, loss is 3.7228269529342652 and perplexity is 41.38121164966485
At time: 327.70644450187683 and batch: 1800, loss is 3.67914155960083 and perplexity is 39.612374610148876
At time: 328.4252049922943 and batch: 1850, loss is 3.7196489000320434 and perplexity is 41.24990872421932
At time: 329.1444163322449 and batch: 1900, loss is 3.8169377613067628 and perplexity is 45.46477095376678
At time: 329.86266708374023 and batch: 1950, loss is 3.755010290145874 and perplexity is 42.73465955417057
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366021302688954 and perplexity of 78.72976581737896
finished 11 epochs...
Completing Train Step...
At time: 332.51639342308044 and batch: 50, loss is 3.946548023223877 and perplexity is 51.75639623355769
At time: 333.2671220302582 and batch: 100, loss is 3.911999659538269 and perplexity is 49.99883271913181
At time: 333.9891686439514 and batch: 150, loss is 3.8607179927825928 and perplexity is 47.49944338600615
At time: 334.70925855636597 and batch: 200, loss is 3.8610842037200928 and perplexity is 47.51684138717399
At time: 335.4274456501007 and batch: 250, loss is 3.8538205194473267 and perplexity is 47.172944544771504
At time: 336.1495473384857 and batch: 300, loss is 3.8711067485809325 and perplexity is 47.995475621548565
At time: 336.8742775917053 and batch: 350, loss is 3.892297444343567 and perplexity is 49.02338574418027
At time: 337.59138011932373 and batch: 400, loss is 3.8509513998031615 and perplexity is 47.037793697592015
At time: 338.3118793964386 and batch: 450, loss is 3.8905555772781373 and perplexity is 48.93806785090274
At time: 339.0313060283661 and batch: 500, loss is 3.8982367372512816 and perplexity is 49.315416360674824
At time: 339.7525041103363 and batch: 550, loss is 3.8669573974609377 and perplexity is 47.79673814195579
At time: 340.4708044528961 and batch: 600, loss is 3.8347625732421875 and perplexity is 46.28243767422212
At time: 341.19255900382996 and batch: 650, loss is 3.8724891328811646 and perplexity is 48.06186969401849
At time: 341.9153287410736 and batch: 700, loss is 3.9223171949386595 and perplexity is 50.517367848067266
At time: 342.6366753578186 and batch: 750, loss is 3.8543873023986817 and perplexity is 47.199688943923476
At time: 343.35648584365845 and batch: 800, loss is 3.850618348121643 and perplexity is 47.02213028981305
At time: 344.0799973011017 and batch: 850, loss is 3.863734579086304 and perplexity is 47.642945891384166
At time: 344.7981581687927 and batch: 900, loss is 3.8326438951492308 and perplexity is 46.18448389034234
At time: 345.5212936401367 and batch: 950, loss is 3.908294644355774 and perplexity is 49.813929031801294
At time: 346.250248670578 and batch: 1000, loss is 3.87213481426239 and perplexity is 48.044843495260515
At time: 346.979101896286 and batch: 1050, loss is 3.8280307626724244 and perplexity is 45.97191941878194
At time: 347.6985342502594 and batch: 1100, loss is 3.8417589044570923 and perplexity is 46.60738031533815
At time: 348.4491002559662 and batch: 1150, loss is 3.8191073083877565 and perplexity is 45.56351599215027
At time: 349.1669270992279 and batch: 1200, loss is 3.854990367889404 and perplexity is 47.22816203220393
At time: 349.89019989967346 and batch: 1250, loss is 3.860658645629883 and perplexity is 47.496624512932755
At time: 350.6290636062622 and batch: 1300, loss is 3.858902721405029 and perplexity is 47.41329721896879
At time: 351.3496890068054 and batch: 1350, loss is 3.744752082824707 and perplexity is 42.298519389388915
At time: 352.0701780319214 and batch: 1400, loss is 3.7543590831756593 and perplexity is 42.70683950528715
At time: 352.79112434387207 and batch: 1450, loss is 3.688384952545166 and perplexity is 39.98022482707918
At time: 353.5141713619232 and batch: 1500, loss is 3.702071075439453 and perplexity is 40.53116058502951
At time: 354.23882818222046 and batch: 1550, loss is 3.714281163215637 and perplexity is 41.029083267167515
At time: 354.9564311504364 and batch: 1600, loss is 3.8077112150192263 and perplexity is 45.04721739090824
At time: 355.6795082092285 and batch: 1650, loss is 3.759388689994812 and perplexity is 42.92217919953187
At time: 356.39955258369446 and batch: 1700, loss is 3.748796944618225 and perplexity is 42.46995754246685
At time: 357.1258111000061 and batch: 1750, loss is 3.7226700448989867 and perplexity is 41.37471911442625
At time: 357.84591364860535 and batch: 1800, loss is 3.6807480907440184 and perplexity is 39.67606426962817
At time: 358.568724155426 and batch: 1850, loss is 3.7240855932235717 and perplexity is 41.43332850117178
At time: 359.2926104068756 and batch: 1900, loss is 3.822425980567932 and perplexity is 45.71497755172527
At time: 360.0117931365967 and batch: 1950, loss is 3.7602141284942627 and perplexity is 42.957623445233494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365170784883721 and perplexity of 78.66283321746823
finished 12 epochs...
Completing Train Step...
At time: 362.7291259765625 and batch: 50, loss is 3.934551672935486 and perplexity is 51.1392177211081
At time: 363.44730854034424 and batch: 100, loss is 3.8971269750595092 and perplexity is 49.26071833264169
At time: 364.17020893096924 and batch: 150, loss is 3.844824366569519 and perplexity is 46.75047268391759
At time: 364.8893053531647 and batch: 200, loss is 3.844261116981506 and perplexity is 46.72414791384288
At time: 365.609082698822 and batch: 250, loss is 3.8363850116729736 and perplexity is 46.35758902751198
At time: 366.3253581523895 and batch: 300, loss is 3.8520500469207763 and perplexity is 47.08950003236376
At time: 367.074298620224 and batch: 350, loss is 3.8739049530029295 and perplexity is 48.129964850092016
At time: 367.793577671051 and batch: 400, loss is 3.8324490070343016 and perplexity is 46.17548396035615
At time: 368.5101923942566 and batch: 450, loss is 3.8728618144989015 and perplexity is 48.0797848074769
At time: 369.230265378952 and batch: 500, loss is 3.881023979187012 and perplexity is 48.473825855596
At time: 369.94966650009155 and batch: 550, loss is 3.8497785043716433 and perplexity is 46.982655626172495
At time: 370.6692793369293 and batch: 600, loss is 3.8193323755264283 and perplexity is 45.57377199642393
At time: 371.392694234848 and batch: 650, loss is 3.8571939420700074 and perplexity is 47.332347538743406
At time: 372.1115896701813 and batch: 700, loss is 3.9073079347610475 and perplexity is 49.76480139141754
At time: 372.83410120010376 and batch: 750, loss is 3.8407641506195067 and perplexity is 46.561040497086914
At time: 373.55345034599304 and batch: 800, loss is 3.8375083684921263 and perplexity is 46.409694402250075
At time: 374.2712869644165 and batch: 850, loss is 3.8505990266799928 and perplexity is 47.02122176324343
At time: 374.99027609825134 and batch: 900, loss is 3.8189997339248656 and perplexity is 45.558614785017085
At time: 375.70769810676575 and batch: 950, loss is 3.895340294837952 and perplexity is 49.17278376036983
At time: 376.4246063232422 and batch: 1000, loss is 3.8600559759140016 and perplexity is 47.46800835964286
At time: 377.14217710494995 and batch: 1050, loss is 3.8170697927474975 and perplexity is 45.470774129273714
At time: 377.8631591796875 and batch: 1100, loss is 3.8310494804382325 and perplexity is 46.11090534275442
At time: 378.58232522010803 and batch: 1150, loss is 3.80904577255249 and perplexity is 45.10737562761514
At time: 379.30081820487976 and batch: 1200, loss is 3.8456790256500244 and perplexity is 46.79044547903783
At time: 380.0228822231293 and batch: 1250, loss is 3.8526979875564575 and perplexity is 47.12002111980724
At time: 380.7402775287628 and batch: 1300, loss is 3.850440683364868 and perplexity is 47.01377685654939
At time: 381.4621572494507 and batch: 1350, loss is 3.736446876525879 and perplexity is 41.948676230438046
At time: 382.18486881256104 and batch: 1400, loss is 3.747455930709839 and perplexity is 42.41304290890066
At time: 382.90313935279846 and batch: 1450, loss is 3.681134777069092 and perplexity is 39.691409427804174
At time: 383.6241068840027 and batch: 1500, loss is 3.6947581481933596 and perplexity is 40.23584030046506
At time: 384.34343957901 and batch: 1550, loss is 3.7078185749053953 and perplexity is 40.764784141357104
At time: 385.0645327568054 and batch: 1600, loss is 3.8022359943389894 and perplexity is 44.80124791770888
At time: 385.78637981414795 and batch: 1650, loss is 3.754086022377014 and perplexity is 42.69517953359727
At time: 386.50613355636597 and batch: 1700, loss is 3.744822955131531 and perplexity is 42.30151728926605
At time: 387.2295308113098 and batch: 1750, loss is 3.719317941665649 and perplexity is 41.23625898068704
At time: 387.94860792160034 and batch: 1800, loss is 3.678298091888428 and perplexity is 39.578976938062695
At time: 388.66729497909546 and batch: 1850, loss is 3.723079309463501 and perplexity is 41.39165578637994
At time: 389.3896653652191 and batch: 1900, loss is 3.8214375257492064 and perplexity is 45.66981268726761
At time: 390.10819387435913 and batch: 1950, loss is 3.7595592594146727 and perplexity is 42.92950103515997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365811512082122 and perplexity of 78.7132507844424
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 392.7624797821045 and batch: 50, loss is 3.9392965173721315 and perplexity is 51.38244192799914
At time: 393.5193667411804 and batch: 100, loss is 3.925685658454895 and perplexity is 50.68782067950082
At time: 394.23863077163696 and batch: 150, loss is 3.8833317947387695 and perplexity is 48.58582369022251
At time: 394.96153688430786 and batch: 200, loss is 3.882804045677185 and perplexity is 48.56018933221284
At time: 395.6786231994629 and batch: 250, loss is 3.884571943283081 and perplexity is 48.646114705926664
At time: 396.39840483665466 and batch: 300, loss is 3.8877984952926634 and perplexity is 48.8033274161922
At time: 397.1182687282562 and batch: 350, loss is 3.909573884010315 and perplexity is 49.877693761657106
At time: 397.83847999572754 and batch: 400, loss is 3.865880432128906 and perplexity is 47.745290420671495
At time: 398.561576128006 and batch: 450, loss is 3.9118458938598635 and perplexity is 49.99114520575227
At time: 399.2872416973114 and batch: 500, loss is 3.9215338039398193 and perplexity is 50.47780849405406
At time: 400.00667238235474 and batch: 550, loss is 3.896980962753296 and perplexity is 49.253526186635895
At time: 400.73025369644165 and batch: 600, loss is 3.8617317342758177 and perplexity is 47.54761995784076
At time: 401.4497847557068 and batch: 650, loss is 3.88990779876709 and perplexity is 48.90637708758265
At time: 402.16830611228943 and batch: 700, loss is 3.941370949745178 and perplexity is 51.48914196167956
At time: 402.88660526275635 and batch: 750, loss is 3.876422257423401 and perplexity is 48.25127524690518
At time: 403.63869976997375 and batch: 800, loss is 3.8651044034957884 and perplexity is 47.70825308108525
At time: 404.3569269180298 and batch: 850, loss is 3.8732946157455443 and perplexity is 48.10059830200819
At time: 405.07826709747314 and batch: 900, loss is 3.8384785985946657 and perplexity is 46.45474433567559
At time: 405.79979062080383 and batch: 950, loss is 3.9217126512527467 and perplexity is 50.486837121814524
At time: 406.51946234703064 and batch: 1000, loss is 3.888199963569641 and perplexity is 48.822924337468656
At time: 407.2397918701172 and batch: 1050, loss is 3.847121825218201 and perplexity is 46.858003438147435
At time: 407.9602372646332 and batch: 1100, loss is 3.8534631729125977 and perplexity is 47.15609046805777
At time: 408.68142652511597 and batch: 1150, loss is 3.836411881446838 and perplexity is 46.35883466218094
At time: 409.4015440940857 and batch: 1200, loss is 3.874968032836914 and perplexity is 48.1811580515433
At time: 410.1237814426422 and batch: 1250, loss is 3.8767918825149534 and perplexity is 48.269113425451934
At time: 410.8464767932892 and batch: 1300, loss is 3.8703738498687743 and perplexity is 47.96031268628505
At time: 411.5638084411621 and batch: 1350, loss is 3.753784866333008 and perplexity is 42.68232355815532
At time: 412.2839241027832 and batch: 1400, loss is 3.768119425773621 and perplexity is 43.29856206400866
At time: 413.0080270767212 and batch: 1450, loss is 3.6992841005325316 and perplexity is 40.41835851880792
At time: 413.7332994937897 and batch: 1500, loss is 3.7061566591262816 and perplexity is 40.69709276762157
At time: 414.4571752548218 and batch: 1550, loss is 3.7169283533096316 and perplexity is 41.13783893491137
At time: 415.17923307418823 and batch: 1600, loss is 3.805826630592346 and perplexity is 44.96240205247496
At time: 415.89892387390137 and batch: 1650, loss is 3.7562672472000123 and perplexity is 42.78840895922356
At time: 416.6187152862549 and batch: 1700, loss is 3.7499122714996336 and perplexity is 42.51735185292746
At time: 417.3390600681305 and batch: 1750, loss is 3.721130828857422 and perplexity is 41.311083470116074
At time: 418.0678606033325 and batch: 1800, loss is 3.670617227554321 and perplexity is 39.27614069659607
At time: 418.789363861084 and batch: 1850, loss is 3.712064514160156 and perplexity is 40.93823691293679
At time: 419.5100817680359 and batch: 1900, loss is 3.8091724252700807 and perplexity is 45.11308896111873
At time: 420.23091983795166 and batch: 1950, loss is 3.748340435028076 and perplexity is 42.450574024273095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352475756268168 and perplexity of 77.67051835861939
finished 14 epochs...
Completing Train Step...
At time: 422.8682019710541 and batch: 50, loss is 3.9474377536773684 and perplexity is 51.80246596723302
At time: 423.61644101142883 and batch: 100, loss is 3.9199423122406007 and perplexity is 50.397537373195156
At time: 424.3344256877899 and batch: 150, loss is 3.8713124656677245 and perplexity is 48.005350126615006
At time: 425.06215047836304 and batch: 200, loss is 3.867325129508972 and perplexity is 47.81431776645966
At time: 425.78721857070923 and batch: 250, loss is 3.8689442920684813 and perplexity is 47.89179963053449
At time: 426.51040625572205 and batch: 300, loss is 3.8734305906295776 and perplexity is 48.10713921997444
At time: 427.2279200553894 and batch: 350, loss is 3.892358841896057 and perplexity is 49.02639575248236
At time: 427.94843888282776 and batch: 400, loss is 3.847353014945984 and perplexity is 46.86883777955272
At time: 428.66714668273926 and batch: 450, loss is 3.892018241882324 and perplexity is 49.00970020482907
At time: 429.38711524009705 and batch: 500, loss is 3.9015998077392577 and perplexity is 49.48154677961295
At time: 430.1083114147186 and batch: 550, loss is 3.878542766571045 and perplexity is 48.35370107652574
At time: 430.82626819610596 and batch: 600, loss is 3.845980749130249 and perplexity is 46.8045653851355
At time: 431.5429973602295 and batch: 650, loss is 3.8737164545059204 and perplexity is 48.120893279072284
At time: 432.271879196167 and batch: 700, loss is 3.9236348724365233 and perplexity is 50.58397732219689
At time: 432.99906849861145 and batch: 750, loss is 3.8610265970230104 and perplexity is 47.51410417772744
At time: 433.7197058200836 and batch: 800, loss is 3.851423768997192 and perplexity is 47.06001815095024
At time: 434.4377603530884 and batch: 850, loss is 3.861127562522888 and perplexity is 47.51890170519528
At time: 435.16541814804077 and batch: 900, loss is 3.8267550086975097 and perplexity is 45.91330795470252
At time: 435.88841557502747 and batch: 950, loss is 3.911147365570068 and perplexity is 49.956237170131416
At time: 436.60662865638733 and batch: 1000, loss is 3.876882619857788 and perplexity is 48.27349343525736
At time: 437.3264112472534 and batch: 1050, loss is 3.8353037071228027 and perplexity is 46.30748944689527
At time: 438.0541067123413 and batch: 1100, loss is 3.8431744146347047 and perplexity is 46.6734002514486
At time: 438.7729835510254 and batch: 1150, loss is 3.8266768407821656 and perplexity is 45.90971914739977
At time: 439.4905297756195 and batch: 1200, loss is 3.8659349346160887 and perplexity is 47.74789272866616
At time: 440.242960691452 and batch: 1250, loss is 3.869732255935669 and perplexity is 47.929551509783025
At time: 440.96391916275024 and batch: 1300, loss is 3.864060869216919 and perplexity is 47.658493850856885
At time: 441.6869125366211 and batch: 1350, loss is 3.7487147521972655 and perplexity is 42.46646697728936
At time: 442.40948843955994 and batch: 1400, loss is 3.764370946884155 and perplexity is 43.136562134515046
At time: 443.13534903526306 and batch: 1450, loss is 3.6973119258880613 and perplexity is 40.33872500837211
At time: 443.8538043498993 and batch: 1500, loss is 3.706116647720337 and perplexity is 40.6954644522979
At time: 444.5707564353943 and batch: 1550, loss is 3.717483263015747 and perplexity is 41.160673055876714
At time: 445.288747549057 and batch: 1600, loss is 3.807302293777466 and perplexity is 45.02880039264243
At time: 446.0054726600647 and batch: 1650, loss is 3.757749662399292 and perplexity is 42.85188618519545
At time: 446.72776341438293 and batch: 1700, loss is 3.7521770715713503 and perplexity is 42.61375427935776
At time: 447.44534397125244 and batch: 1750, loss is 3.723563117980957 and perplexity is 41.41168626706887
At time: 448.16488552093506 and batch: 1800, loss is 3.6744761419296266 and perplexity is 39.42799677188917
At time: 448.89083647727966 and batch: 1850, loss is 3.716606864929199 and perplexity is 41.12461572336601
At time: 449.6116280555725 and batch: 1900, loss is 3.813965330123901 and perplexity is 45.32983070052408
At time: 450.3334605693817 and batch: 1950, loss is 3.7525876569747925 and perplexity is 42.63125445726369
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351042991460756 and perplexity of 77.55931445688353
finished 15 epochs...
Completing Train Step...
At time: 452.97817850112915 and batch: 50, loss is 3.9437741899490355 and perplexity is 51.6130315462916
At time: 453.6949071884155 and batch: 100, loss is 3.914640793800354 and perplexity is 50.13106088860083
At time: 454.41501903533936 and batch: 150, loss is 3.8649530601501465 and perplexity is 47.701033300795864
At time: 455.1311779022217 and batch: 200, loss is 3.8604406356811523 and perplexity is 47.4862709048936
At time: 455.84959602355957 and batch: 250, loss is 3.861613841056824 and perplexity is 47.542014746283144
At time: 456.57187032699585 and batch: 300, loss is 3.8656202125549317 and perplexity is 47.73286777791644
At time: 457.2968399524689 and batch: 350, loss is 3.8844483518600463 and perplexity is 48.64010283490054
At time: 458.0154891014099 and batch: 400, loss is 3.839020028114319 and perplexity is 46.4799031158254
At time: 458.7913861274719 and batch: 450, loss is 3.883679275512695 and perplexity is 48.60270926337632
At time: 459.5100350379944 and batch: 500, loss is 3.8931809186935427 and perplexity is 49.066715785705995
At time: 460.23491621017456 and batch: 550, loss is 3.8710650396347046 and perplexity is 47.99347382258344
At time: 460.9530973434448 and batch: 600, loss is 3.8391646337509155 and perplexity is 46.486624857793586
At time: 461.67143058776855 and batch: 650, loss is 3.866551995277405 and perplexity is 47.77736516713577
At time: 462.39863896369934 and batch: 700, loss is 3.915994176864624 and perplexity is 50.198953349291685
At time: 463.1175220012665 and batch: 750, loss is 3.8543058109283446 and perplexity is 47.19584272859098
At time: 463.83848214149475 and batch: 800, loss is 3.8454150104522706 and perplexity is 46.77809372091937
At time: 464.5571129322052 and batch: 850, loss is 3.8553266859054567 and perplexity is 47.244048385244035
At time: 465.2755591869354 and batch: 900, loss is 3.8212465620040894 and perplexity is 45.661092241469056
At time: 465.9945430755615 and batch: 950, loss is 3.90610710144043 and perplexity is 49.7050780257933
At time: 466.71448373794556 and batch: 1000, loss is 3.871615853309631 and perplexity is 48.01991656611597
At time: 467.4336836338043 and batch: 1050, loss is 3.829768853187561 and perplexity is 46.05189225576818
At time: 468.15661811828613 and batch: 1100, loss is 3.838245029449463 and perplexity is 46.443895207810584
At time: 468.87438583374023 and batch: 1150, loss is 3.822018556594849 and perplexity is 45.6963559676392
At time: 469.59194922447205 and batch: 1200, loss is 3.861582841873169 and perplexity is 47.54054100547919
At time: 470.3126132488251 and batch: 1250, loss is 3.866248159408569 and perplexity is 47.76285089496944
At time: 471.0361692905426 and batch: 1300, loss is 3.8609658098220825 and perplexity is 47.5112160161124
At time: 471.75999426841736 and batch: 1350, loss is 3.746133017539978 and perplexity is 42.356971233019415
At time: 472.4799084663391 and batch: 1400, loss is 3.7623588132858274 and perplexity is 43.04985287309178
At time: 473.19881939888 and batch: 1450, loss is 3.69598792552948 and perplexity is 40.28535186282505
At time: 473.9183328151703 and batch: 1500, loss is 3.7056010723114015 and perplexity is 40.67448827943518
At time: 474.6429126262665 and batch: 1550, loss is 3.71707745552063 and perplexity is 41.14397313495229
At time: 475.3609218597412 and batch: 1600, loss is 3.807303423881531 and perplexity is 45.02885127990155
At time: 476.0783598423004 and batch: 1650, loss is 3.757560338973999 and perplexity is 42.843774087251916
At time: 476.79585123062134 and batch: 1700, loss is 3.7522663688659668 and perplexity is 42.61755974223459
At time: 477.51580905914307 and batch: 1750, loss is 3.7237234926223755 and perplexity is 41.418328183987775
At time: 478.23626589775085 and batch: 1800, loss is 3.6754010486602784 and perplexity is 39.464480861068566
At time: 478.95545864105225 and batch: 1850, loss is 3.7175919437408447 and perplexity is 41.165146670763384
At time: 479.67958521842957 and batch: 1900, loss is 3.814931216239929 and perplexity is 45.373635306364335
At time: 480.397438287735 and batch: 1950, loss is 3.753262310028076 and perplexity is 42.66002546738222
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350591899073401 and perplexity of 77.52433593043021
finished 16 epochs...
Completing Train Step...
At time: 483.02478528022766 and batch: 50, loss is 3.939552597999573 and perplexity is 51.39560166087195
At time: 483.7737352848053 and batch: 100, loss is 3.909712634086609 and perplexity is 49.884614775606394
At time: 484.4939844608307 and batch: 150, loss is 3.8596055459976197 and perplexity is 47.446632163207205
At time: 485.21354961395264 and batch: 200, loss is 3.8549393463134765 and perplexity is 47.22575243842004
At time: 485.93354320526123 and batch: 250, loss is 3.855956358909607 and perplexity is 47.27380605493641
At time: 486.6578025817871 and batch: 300, loss is 3.859639286994934 and perplexity is 47.448233086903834
At time: 487.3811252117157 and batch: 350, loss is 3.878745036125183 and perplexity is 48.36348254729694
At time: 488.1019675731659 and batch: 400, loss is 3.8331868982315065 and perplexity is 46.20956901748242
At time: 488.8199291229248 and batch: 450, loss is 3.8779823637008666 and perplexity is 48.326611115013776
At time: 489.53812742233276 and batch: 500, loss is 3.8873459339141845 and perplexity is 48.78124591205722
At time: 490.25790071487427 and batch: 550, loss is 3.8658079528808593 and perplexity is 47.74183000332976
At time: 490.9753158092499 and batch: 600, loss is 3.834391951560974 and perplexity is 46.26528757765577
At time: 491.7030487060547 and batch: 650, loss is 3.8614917325973512 and perplexity is 47.53620981852485
At time: 492.4289643764496 and batch: 700, loss is 3.9107092666625975 and perplexity is 49.93435619057243
At time: 493.149062871933 and batch: 750, loss is 3.849554252624512 and perplexity is 46.97212086482692
At time: 493.86967968940735 and batch: 800, loss is 3.8411866521835325 and perplexity is 46.58071676585407
At time: 494.5970540046692 and batch: 850, loss is 3.8511644840240478 and perplexity is 47.04781777716294
At time: 495.35110569000244 and batch: 900, loss is 3.817276577949524 and perplexity is 45.480177784723224
At time: 496.07345175743103 and batch: 950, loss is 3.9023794507980347 and perplexity is 49.52013976651953
At time: 496.79496145248413 and batch: 1000, loss is 3.867714877128601 and perplexity is 47.832956915039276
At time: 497.51467275619507 and batch: 1050, loss is 3.825684118270874 and perplexity is 45.86416615019898
At time: 498.2361695766449 and batch: 1100, loss is 3.8344928789138795 and perplexity is 46.26995724630707
At time: 498.9569568634033 and batch: 1150, loss is 3.818350439071655 and perplexity is 45.529043412226756
At time: 499.68304347991943 and batch: 1200, loss is 3.858109164237976 and perplexity is 47.37568698205728
At time: 500.4032099246979 and batch: 1250, loss is 3.863365902900696 and perplexity is 47.625384309289274
At time: 501.1254303455353 and batch: 1300, loss is 3.858368601799011 and perplexity is 47.387979609255936
At time: 501.8472008705139 and batch: 1350, loss is 3.7439019298553466 and perplexity is 42.26257445904007
At time: 502.5658016204834 and batch: 1400, loss is 3.7605232572555543 and perplexity is 42.9709049348966
At time: 503.2852897644043 and batch: 1450, loss is 3.694533123970032 and perplexity is 40.22678728036412
At time: 504.00328159332275 and batch: 1500, loss is 3.7046873140335084 and perplexity is 40.637338604567105
At time: 504.72197008132935 and batch: 1550, loss is 3.71610276222229 and perplexity is 41.103889917665555
At time: 505.44343614578247 and batch: 1600, loss is 3.806565489768982 and perplexity is 44.99563521163545
At time: 506.16541934013367 and batch: 1650, loss is 3.756609959602356 and perplexity is 42.80307559072514
At time: 506.885879278183 and batch: 1700, loss is 3.7515477466583254 and perplexity is 42.58694481896772
At time: 507.6063208580017 and batch: 1750, loss is 3.723053631782532 and perplexity is 41.39059295829342
At time: 508.32737255096436 and batch: 1800, loss is 3.6752747678756714 and perplexity is 39.45949757011489
At time: 509.0479874610901 and batch: 1850, loss is 3.7174211597442626 and perplexity is 41.15811692279638
At time: 509.76607728004456 and batch: 1900, loss is 3.8147961711883545 and perplexity is 45.36750823516889
At time: 510.4847602844238 and batch: 1950, loss is 3.7528626346588134 and perplexity is 42.64297871276169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35045648619186 and perplexity of 77.51383884744851
finished 17 epochs...
Completing Train Step...
At time: 513.1163325309753 and batch: 50, loss is 3.9354418516159058 and perplexity is 51.18476103029077
At time: 513.8679239749908 and batch: 100, loss is 3.9052108669281007 and perplexity is 49.66055057592773
At time: 514.5930573940277 and batch: 150, loss is 3.8549006748199464 and perplexity is 47.22392618335239
At time: 515.3122115135193 and batch: 200, loss is 3.8501878356933594 and perplexity is 47.001891035256826
At time: 516.0346601009369 and batch: 250, loss is 3.851132297515869 and perplexity is 47.0463034965611
At time: 516.7539780139923 and batch: 300, loss is 3.8546235179901123 and perplexity is 47.21083956328593
At time: 517.4736008644104 and batch: 350, loss is 3.8740413904190065 and perplexity is 48.13653202612612
At time: 518.193719625473 and batch: 400, loss is 3.828437476158142 and perplexity is 45.99062062113168
At time: 518.919376373291 and batch: 450, loss is 3.8733577585220336 and perplexity is 48.10363560322658
At time: 519.6392011642456 and batch: 500, loss is 3.882581105232239 and perplexity is 48.549364508686786
At time: 520.3623716831207 and batch: 550, loss is 3.8614822483062743 and perplexity is 47.535758973412214
At time: 521.0852546691895 and batch: 600, loss is 3.8304743194580078 and perplexity is 46.08439177475422
At time: 521.8137171268463 and batch: 650, loss is 3.857334566116333 and perplexity is 47.33900407299983
At time: 522.5346598625183 and batch: 700, loss is 3.906424865722656 and perplexity is 49.720875033964724
At time: 523.252986907959 and batch: 750, loss is 3.8456669282913207 and perplexity is 46.78987944165875
At time: 523.973230600357 and batch: 800, loss is 3.8376782941818237 and perplexity is 46.41758127165191
At time: 524.6986792087555 and batch: 850, loss is 3.847726893424988 and perplexity is 46.886364305525696
At time: 525.4223582744598 and batch: 900, loss is 3.8139629316329957 and perplexity is 45.329721977467784
At time: 526.1435496807098 and batch: 950, loss is 3.899228882789612 and perplexity is 49.36436871090037
At time: 526.8741562366486 and batch: 1000, loss is 3.8643775367736817 and perplexity is 47.67358813947323
At time: 527.5969591140747 and batch: 1050, loss is 3.822219395637512 and perplexity is 45.70553450169809
At time: 528.321976184845 and batch: 1100, loss is 3.8312201929092407 and perplexity is 46.11877772128338
At time: 529.0446164608002 and batch: 1150, loss is 3.8150868129730227 and perplexity is 45.38069584507072
At time: 529.7666068077087 and batch: 1200, loss is 3.8549904346466066 and perplexity is 47.22816518502401
At time: 530.4939959049225 and batch: 1250, loss is 3.8606988048553466 and perplexity is 47.498531978886255
At time: 531.2178635597229 and batch: 1300, loss is 3.8559450006484983 and perplexity is 47.27326910975303
At time: 531.9405436515808 and batch: 1350, loss is 3.741766571998596 and perplexity is 42.17242502353008
At time: 532.6600334644318 and batch: 1400, loss is 3.758716287612915 and perplexity is 42.89332792492181
At time: 533.3805661201477 and batch: 1450, loss is 3.6930153656005857 and perplexity is 40.1657790468834
At time: 534.1040558815002 and batch: 1500, loss is 3.7035860061645507 and perplexity is 40.59260901883174
At time: 534.8340079784393 and batch: 1550, loss is 3.7148687124252318 and perplexity is 41.05319695590721
At time: 535.5577166080475 and batch: 1600, loss is 3.8054982948303224 and perplexity is 44.94764171124119
At time: 536.2801716327667 and batch: 1650, loss is 3.7553530597686766 and perplexity is 42.74931020806267
At time: 537.0050628185272 and batch: 1700, loss is 3.7504931688308716 and perplexity is 42.54205724410331
At time: 537.7251272201538 and batch: 1750, loss is 3.7220404529571534 and perplexity is 41.348678123135514
At time: 538.4525985717773 and batch: 1800, loss is 3.6746861362457275 and perplexity is 39.43627729650764
At time: 539.1724362373352 and batch: 1850, loss is 3.7167460203170775 and perplexity is 41.130338833409915
At time: 539.8964030742645 and batch: 1900, loss is 3.8141979217529296 and perplexity is 45.34037526593158
At time: 540.6164267063141 and batch: 1950, loss is 3.752009725570679 and perplexity is 42.60662363466459
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35048459075218 and perplexity of 77.5160173704211
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 543.3089091777802 and batch: 50, loss is 3.93685622215271 and perplexity is 51.25720646849513
At time: 544.0334265232086 and batch: 100, loss is 3.916785869598389 and perplexity is 50.23871123183768
At time: 544.7524936199188 and batch: 150, loss is 3.8722713565826417 and perplexity is 48.05140409755723
At time: 545.4725005626678 and batch: 200, loss is 3.8697766494750976 and perplexity is 47.93167931944792
At time: 546.1926245689392 and batch: 250, loss is 3.877188220024109 and perplexity is 48.28824807727577
At time: 546.9102840423584 and batch: 300, loss is 3.8780016613006594 and perplexity is 48.327543711612826
At time: 547.6306409835815 and batch: 350, loss is 3.8983202457427977 and perplexity is 49.31953478866305
At time: 548.35316157341 and batch: 400, loss is 3.8534909534454345 and perplexity is 47.15740050757418
At time: 549.073005437851 and batch: 450, loss is 3.8999712228775025 and perplexity is 49.40102746565604
At time: 549.7935647964478 and batch: 500, loss is 3.909078459739685 and perplexity is 49.85298926171426
At time: 550.565619468689 and batch: 550, loss is 3.8909538650512694 and perplexity is 48.957563167083784
At time: 551.2844386100769 and batch: 600, loss is 3.860419359207153 and perplexity is 47.485260575233546
At time: 552.0046260356903 and batch: 650, loss is 3.88300190448761 and perplexity is 48.56979834409061
At time: 552.7270765304565 and batch: 700, loss is 3.9292022609710693 and perplexity is 50.86638338024694
At time: 553.4478340148926 and batch: 750, loss is 3.8664793729782105 and perplexity is 47.77389559101371
At time: 554.1665406227112 and batch: 800, loss is 3.853232698440552 and perplexity is 47.14522344533716
At time: 554.8859977722168 and batch: 850, loss is 3.867523679733276 and perplexity is 47.82381225251211
At time: 555.6080422401428 and batch: 900, loss is 3.8302384185791016 and perplexity is 46.07352170841022
At time: 556.3270130157471 and batch: 950, loss is 3.9251744318008424 and perplexity is 50.66191433710421
At time: 557.046498298645 and batch: 1000, loss is 3.8908631134033205 and perplexity is 48.953120389144566
At time: 557.764356136322 and batch: 1050, loss is 3.847138662338257 and perplexity is 46.858792398618796
At time: 558.4842393398285 and batch: 1100, loss is 3.850130710601807 and perplexity is 46.999206124616904
At time: 559.2025225162506 and batch: 1150, loss is 3.8384599018096925 and perplexity is 46.453875789429304
At time: 559.924950838089 and batch: 1200, loss is 3.8829458475112917 and perplexity is 48.56707574436612
At time: 560.6458446979523 and batch: 1250, loss is 3.882735686302185 and perplexity is 48.55686990147862
At time: 561.3680620193481 and batch: 1300, loss is 3.8671249103546144 and perplexity is 47.80474538250955
At time: 562.0889844894409 and batch: 1350, loss is 3.74295401096344 and perplexity is 42.222531947814524
At time: 562.8136937618256 and batch: 1400, loss is 3.758069248199463 and perplexity is 42.86558322810441
At time: 563.5347714424133 and batch: 1450, loss is 3.6887064027786254 and perplexity is 39.99307854548831
At time: 564.2561542987823 and batch: 1500, loss is 3.7003838872909545 and perplexity is 40.46283454689454
At time: 564.9787924289703 and batch: 1550, loss is 3.713689479827881 and perplexity is 41.004814220687315
At time: 565.7028346061707 and batch: 1600, loss is 3.803850321769714 and perplexity is 44.8736302097936
At time: 566.4216930866241 and batch: 1650, loss is 3.752631516456604 and perplexity is 42.633124282997656
At time: 567.1421101093292 and batch: 1700, loss is 3.7495297145843507 and perplexity is 42.50108965676274
At time: 567.8644840717316 and batch: 1750, loss is 3.7221295976638795 and perplexity is 41.352364303219595
At time: 568.5844564437866 and batch: 1800, loss is 3.6734256076812746 and perplexity is 39.38659806012604
At time: 569.3038837909698 and batch: 1850, loss is 3.715408663749695 and perplexity is 41.07536966953134
At time: 570.026937007904 and batch: 1900, loss is 3.812622470855713 and perplexity is 45.26899996993884
At time: 570.7486734390259 and batch: 1950, loss is 3.751175909042358 and perplexity is 42.57111233467394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341916390352471 and perplexity of 76.85468187287975
finished 19 epochs...
Completing Train Step...
At time: 573.4003067016602 and batch: 50, loss is 3.936119737625122 and perplexity is 51.219470226788474
At time: 574.1602182388306 and batch: 100, loss is 3.909437098503113 and perplexity is 49.87087168260925
At time: 574.8827238082886 and batch: 150, loss is 3.8623538970947267 and perplexity is 47.577211523537564
At time: 575.6001596450806 and batch: 200, loss is 3.8586851596832275 and perplexity is 47.4029830224174
At time: 576.3184649944305 and batch: 250, loss is 3.8640452146530153 and perplexity is 47.657747783759035
At time: 577.0421278476715 and batch: 300, loss is 3.8666524648666383 and perplexity is 47.782165580532514
At time: 577.7789142131805 and batch: 350, loss is 3.886223497390747 and perplexity is 48.72652277735459
At time: 578.4996373653412 and batch: 400, loss is 3.841763486862183 and perplexity is 46.607593889724306
At time: 579.218385219574 and batch: 450, loss is 3.887978000640869 and perplexity is 48.81208866079525
At time: 579.9363212585449 and batch: 500, loss is 3.8961919593811034 and perplexity is 49.214680315159285
At time: 580.655158996582 and batch: 550, loss is 3.8787083721160887 and perplexity is 48.361709380638885
At time: 581.3750326633453 and batch: 600, loss is 3.848544750213623 and perplexity is 46.92472632204689
At time: 582.0929110050201 and batch: 650, loss is 3.8707167530059814 and perplexity is 47.976761247937134
At time: 582.8104112148285 and batch: 700, loss is 3.9174850273132322 and perplexity is 50.27384829612268
At time: 583.5302379131317 and batch: 750, loss is 3.856597480773926 and perplexity is 47.30412404333194
At time: 584.2511303424835 and batch: 800, loss is 3.845062885284424 and perplexity is 46.76162487653381
At time: 584.9719398021698 and batch: 850, loss is 3.858800983428955 and perplexity is 47.40847373144083
At time: 585.6914455890656 and batch: 900, loss is 3.821664056777954 and perplexity is 45.68015948880993
At time: 586.4090371131897 and batch: 950, loss is 3.9150513792037964 and perplexity is 50.151648196595644
At time: 587.1715795993805 and batch: 1000, loss is 3.881699447631836 and perplexity is 48.50657945612782
At time: 587.8920180797577 and batch: 1050, loss is 3.8388674688339233 and perplexity is 46.472812716120075
At time: 588.6142058372498 and batch: 1100, loss is 3.8432029151916502 and perplexity is 46.67473048830646
At time: 589.3347232341766 and batch: 1150, loss is 3.8309288454055785 and perplexity is 46.10534308769085
At time: 590.0525453090668 and batch: 1200, loss is 3.8762149524688723 and perplexity is 48.241273555220104
At time: 590.7791061401367 and batch: 1250, loss is 3.877885413169861 and perplexity is 48.32192605151784
At time: 591.4978313446045 and batch: 1300, loss is 3.8639815711975096 and perplexity is 47.65471477652501
At time: 592.2194418907166 and batch: 1350, loss is 3.741469941139221 and perplexity is 42.159917236043015
At time: 592.9417457580566 and batch: 1400, loss is 3.757584800720215 and perplexity is 42.844822133599045
At time: 593.663284778595 and batch: 1450, loss is 3.6901928567886353 and perplexity is 40.052570622629005
At time: 594.3851311206818 and batch: 1500, loss is 3.7035332822799685 and perplexity is 40.59046887521777
At time: 595.1063468456268 and batch: 1550, loss is 3.7171486377716065 and perplexity is 41.1469019598131
At time: 595.82763504982 and batch: 1600, loss is 3.8077657413482666 and perplexity is 45.04967371727267
At time: 596.5493531227112 and batch: 1650, loss is 3.7567423009872436 and perplexity is 42.808740583874524
At time: 597.2712280750275 and batch: 1700, loss is 3.754261031150818 and perplexity is 42.70265221848842
At time: 597.9893198013306 and batch: 1750, loss is 3.7272101259231567 and perplexity is 41.56299075241044
At time: 598.7149114608765 and batch: 1800, loss is 3.678224411010742 and perplexity is 39.57606083173595
At time: 599.4374659061432 and batch: 1850, loss is 3.720448179244995 and perplexity is 41.282892098505506
At time: 600.1562986373901 and batch: 1900, loss is 3.817681894302368 and perplexity is 45.498615380786816
At time: 600.8722665309906 and batch: 1950, loss is 3.754320945739746 and perplexity is 42.70521080698985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340282635356105 and perplexity of 76.72922266508544
Finished Training.
Improved accuracyfrom -10000000 to -76.72922266508544
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7420a98b38>
ELAPSED
637.8414123058319


RESULTS SO FAR:
[{'best_accuracy': -76.72922266508544, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.7798990364997814, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3775751613796833, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.2929496765136719 and batch: 50, loss is 7.590076990127564 and perplexity is 1978.4658302192436
At time: 1.994877576828003 and batch: 100, loss is 6.736637849807739 and perplexity is 842.7226074409455
At time: 2.6949539184570312 and batch: 150, loss is 6.526423940658569 and perplexity is 682.951564100484
At time: 3.396090030670166 and batch: 200, loss is 6.451507406234741 and perplexity is 633.6567513908473
At time: 4.123136281967163 and batch: 250, loss is 6.405974225997925 and perplexity is 605.4513579032991
At time: 4.822338104248047 and batch: 300, loss is 6.33229619026184 and perplexity is 562.4465966382863
At time: 5.523382186889648 and batch: 350, loss is 6.302744474411011 and perplexity is 546.0685265716004
At time: 6.227417707443237 and batch: 400, loss is 6.259805927276611 and perplexity is 523.117407436045
At time: 6.9295172691345215 and batch: 450, loss is 6.176327657699585 and perplexity is 481.2214974160482
At time: 7.631590127944946 and batch: 500, loss is 6.165749464035034 and perplexity is 476.1578724410983
At time: 8.33765721321106 and batch: 550, loss is 6.1236923313140865 and perplexity is 456.54731013025474
At time: 9.040249109268188 and batch: 600, loss is 6.166770896911621 and perplexity is 476.6444842247844
At time: 9.742505550384521 and batch: 650, loss is 6.242475643157959 and perplexity is 514.1297385101009
At time: 10.445199489593506 and batch: 700, loss is 6.147543897628784 and perplexity is 467.56758149506766
At time: 11.147488117218018 and batch: 750, loss is 6.078181505203247 and perplexity is 436.2351815749636
At time: 11.848468780517578 and batch: 800, loss is 6.09260124206543 and perplexity is 442.5711498152154
At time: 12.554801225662231 and batch: 850, loss is 6.137544870376587 and perplexity is 462.9156566256611
At time: 13.260185956954956 and batch: 900, loss is 6.114907360076904 and perplexity is 452.55412085023715
At time: 13.964630126953125 and batch: 950, loss is 6.134621086120606 and perplexity is 461.56416781059994
At time: 14.670865774154663 and batch: 1000, loss is 6.117641859054565 and perplexity is 453.79332315758353
At time: 15.372302293777466 and batch: 1050, loss is 6.018616180419922 and perplexity is 411.0094391030241
At time: 16.076056241989136 and batch: 1100, loss is 6.094291687011719 and perplexity is 443.3199246818298
At time: 16.77923560142517 and batch: 1150, loss is 6.003550367355347 and perplexity is 404.8636595549521
At time: 17.485961198806763 and batch: 1200, loss is 6.08802827835083 and perplexity is 440.55190848351486
At time: 18.188846349716187 and batch: 1250, loss is 6.014598875045777 and perplexity is 409.3616008254442
At time: 18.89188265800476 and batch: 1300, loss is 6.040966167449951 and perplexity is 420.29891791335416
At time: 19.595596075057983 and batch: 1350, loss is 6.019627513885498 and perplexity is 411.42531696360913
At time: 20.298851251602173 and batch: 1400, loss is 6.044557905197143 and perplexity is 421.8112357005543
At time: 21.0045747756958 and batch: 1450, loss is 6.021650505065918 and perplexity is 412.2584691968987
At time: 21.707569360733032 and batch: 1500, loss is 6.001823377609253 and perplexity is 404.16506757056044
At time: 22.416256189346313 and batch: 1550, loss is 5.972451171875 and perplexity is 392.46649553120136
At time: 23.128350734710693 and batch: 1600, loss is 5.972327480316162 and perplexity is 392.41795374074417
At time: 23.84108591079712 and batch: 1650, loss is 5.976154441833496 and perplexity is 393.92259942260813
At time: 24.559974670410156 and batch: 1700, loss is 5.992095203399658 and perplexity is 400.2523420788666
At time: 25.264503002166748 and batch: 1750, loss is 5.996417474746704 and perplexity is 401.986085464148
At time: 25.968732833862305 and batch: 1800, loss is 6.002461853027344 and perplexity is 404.4231994277091
At time: 26.675623178482056 and batch: 1850, loss is 5.962795248031616 and perplexity is 388.6951063652208
At time: 27.380605697631836 and batch: 1900, loss is 5.945505104064941 and perplexity is 382.03227862877543
At time: 28.084935426712036 and batch: 1950, loss is 5.88337776184082 and perplexity is 359.0198795839568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.287300145348837 and perplexity of 197.80864922358987
finished 1 epochs...
Completing Train Step...
At time: 30.83965039253235 and batch: 50, loss is 5.5458997535705565 and perplexity is 256.18497792487045
At time: 31.60354208946228 and batch: 100, loss is 5.427007341384888 and perplexity is 227.46749325372204
At time: 32.310951471328735 and batch: 150, loss is 5.312465867996216 and perplexity is 202.84981304211777
At time: 33.011561155319214 and batch: 200, loss is 5.253717956542968 and perplexity is 191.2761043150648
At time: 33.70847725868225 and batch: 250, loss is 5.269049081802368 and perplexity is 194.23117664080985
At time: 34.412376403808594 and batch: 300, loss is 5.259974374771118 and perplexity is 192.47655897817177
At time: 35.11106061935425 and batch: 350, loss is 5.235343599319458 and perplexity is 187.79362102034602
At time: 35.810739040374756 and batch: 400, loss is 5.18096881866455 and perplexity is 177.8550368313567
At time: 36.50999927520752 and batch: 450, loss is 5.133857383728027 and perplexity is 169.6703409815909
At time: 37.2133150100708 and batch: 500, loss is 5.117706270217895 and perplexity is 166.95198735595184
At time: 37.919360637664795 and batch: 550, loss is 5.073667526245117 and perplexity is 159.75917518322538
At time: 38.62280225753784 and batch: 600, loss is 5.049069595336914 and perplexity is 155.8773679675965
At time: 39.33243536949158 and batch: 650, loss is 5.124715328216553 and perplexity is 168.12627403261524
At time: 40.04167866706848 and batch: 700, loss is 5.116181116104126 and perplexity is 166.69755392005445
At time: 40.74898815155029 and batch: 750, loss is 5.049095554351807 and perplexity is 155.88141444303398
At time: 41.44990301132202 and batch: 800, loss is 5.043958826065063 and perplexity is 155.08274699705197
At time: 42.22759032249451 and batch: 850, loss is 5.048883504867554 and perplexity is 155.8483633738517
At time: 42.932361125946045 and batch: 900, loss is 5.043675765991211 and perplexity is 155.03885547549552
At time: 43.64554691314697 and batch: 950, loss is 5.084113178253173 and perplexity is 161.43671015235384
At time: 44.345805644989014 and batch: 1000, loss is 5.04767858505249 and perplexity is 155.66069168005424
At time: 45.04599213600159 and batch: 1050, loss is 4.962719297409057 and perplexity is 142.98207852542666
At time: 45.756690979003906 and batch: 1100, loss is 5.027467451095581 and perplexity is 152.54619238928356
At time: 46.46355438232422 and batch: 1150, loss is 4.94684308052063 and perplexity is 140.72998867294578
At time: 47.16677498817444 and batch: 1200, loss is 5.022416028976441 and perplexity is 151.77756015621256
At time: 47.875921964645386 and batch: 1250, loss is 4.983717460632324 and perplexity is 146.01618337975978
At time: 48.58256554603577 and batch: 1300, loss is 4.991766834259034 and perplexity is 147.19626528371762
At time: 49.29091191291809 and batch: 1350, loss is 4.9089040184021 and perplexity is 135.4908375399527
At time: 49.99421048164368 and batch: 1400, loss is 4.901258716583252 and perplexity is 134.4589188844122
At time: 50.69619107246399 and batch: 1450, loss is 4.858097820281983 and perplexity is 128.7790081624026
At time: 51.39861607551575 and batch: 1500, loss is 4.836916952133179 and perplexity is 126.08004110506344
At time: 52.10292339324951 and batch: 1550, loss is 4.83212984085083 and perplexity is 125.4779242678266
At time: 52.80259299278259 and batch: 1600, loss is 4.892015352249145 and perplexity is 133.22179252234437
At time: 53.50713276863098 and batch: 1650, loss is 4.866941633224488 and perplexity is 129.92295659854193
At time: 54.20966625213623 and batch: 1700, loss is 4.872553224563599 and perplexity is 130.65408060251866
At time: 54.91556978225708 and batch: 1750, loss is 4.871319694519043 and perplexity is 130.49301422918012
At time: 55.61559867858887 and batch: 1800, loss is 4.820846729278564 and perplexity is 124.07010010266727
At time: 56.318156719207764 and batch: 1850, loss is 4.840681095123291 and perplexity is 126.5555187294544
At time: 57.023412227630615 and batch: 1900, loss is 4.931661691665649 and perplexity is 138.60964757626016
At time: 57.72537350654602 and batch: 1950, loss is 4.84315242767334 and perplexity is 126.86866628877844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.647311898164971 and perplexity of 104.30422800699787
finished 2 epochs...
Completing Train Step...
At time: 60.37784767150879 and batch: 50, loss is 4.804437236785889 and perplexity is 122.05078599805243
At time: 61.084019899368286 and batch: 100, loss is 4.749265995025635 and perplexity is 115.49947621605499
At time: 61.79166626930237 and batch: 150, loss is 4.687390279769898 and perplexity is 108.56947381960774
At time: 62.49755573272705 and batch: 200, loss is 4.664160137176514 and perplexity is 106.07645812631961
At time: 63.203362226486206 and batch: 250, loss is 4.679925031661988 and perplexity is 107.76199353101224
At time: 63.908305644989014 and batch: 300, loss is 4.707230863571167 and perplexity is 110.74506671191416
At time: 64.61010527610779 and batch: 350, loss is 4.705836782455444 and perplexity is 110.59078667018446
At time: 65.31409621238708 and batch: 400, loss is 4.652455453872681 and perplexity is 104.84210472789465
At time: 66.01673913002014 and batch: 450, loss is 4.647342138290405 and perplexity is 104.30738222762787
At time: 66.71890020370483 and batch: 500, loss is 4.654562397003174 and perplexity is 105.06323395178391
At time: 67.4220700263977 and batch: 550, loss is 4.615464162826538 and perplexity is 101.0347142088708
At time: 68.12214040756226 and batch: 600, loss is 4.5879214572906495 and perplexity is 98.28991789958773
At time: 68.82318067550659 and batch: 650, loss is 4.657312240600586 and perplexity is 105.35253900250865
At time: 69.5302243232727 and batch: 700, loss is 4.6777316665649415 and perplexity is 107.52589115961801
At time: 70.23523688316345 and batch: 750, loss is 4.626375198364258 and perplexity is 102.14314362594145
At time: 70.93762350082397 and batch: 800, loss is 4.626150703430175 and perplexity is 102.1202155813574
At time: 71.64141154289246 and batch: 850, loss is 4.635187463760376 and perplexity is 103.04723380661115
At time: 72.34171485900879 and batch: 900, loss is 4.6092204570770265 and perplexity is 100.40584845220152
At time: 73.04496502876282 and batch: 950, loss is 4.667784652709961 and perplexity is 106.4616315083125
At time: 73.74716567993164 and batch: 1000, loss is 4.639539318084717 and perplexity is 103.49665756072854
At time: 74.44838809967041 and batch: 1050, loss is 4.577033233642578 and perplexity is 97.22552050522789
At time: 75.15760159492493 and batch: 1100, loss is 4.626328439712524 and perplexity is 102.13836766192135
At time: 75.86600089073181 and batch: 1150, loss is 4.5805979347229 and perplexity is 97.57271888477025
At time: 76.56827473640442 and batch: 1200, loss is 4.645755262374878 and perplexity is 104.1419906176475
At time: 77.2695140838623 and batch: 1250, loss is 4.629398794174194 and perplexity is 102.45245058098548
At time: 77.97062826156616 and batch: 1300, loss is 4.627430429458618 and perplexity is 102.25098513602173
At time: 78.678142786026 and batch: 1350, loss is 4.523857927322387 and perplexity is 92.19057734277843
At time: 79.37872648239136 and batch: 1400, loss is 4.5238479804992675 and perplexity is 92.1896603439729
At time: 80.08401942253113 and batch: 1450, loss is 4.486754217147827 and perplexity is 88.83264596231771
At time: 80.78555607795715 and batch: 1500, loss is 4.477978858947754 and perplexity is 88.05651805493099
At time: 81.48810601234436 and batch: 1550, loss is 4.480844869613647 and perplexity is 88.30925096949619
At time: 82.19044041633606 and batch: 1600, loss is 4.558404407501221 and perplexity is 95.43108915568182
At time: 82.89122152328491 and batch: 1650, loss is 4.526339721679688 and perplexity is 92.41965954730306
At time: 83.59819889068604 and batch: 1700, loss is 4.529479370117188 and perplexity is 92.71028077250226
At time: 84.3017795085907 and batch: 1750, loss is 4.528362503051758 and perplexity is 92.60679351479304
At time: 85.00430107116699 and batch: 1800, loss is 4.485684204101562 and perplexity is 88.73764470755894
At time: 85.70525050163269 and batch: 1850, loss is 4.5249834156036375 and perplexity is 92.29439516913384
At time: 86.40862679481506 and batch: 1900, loss is 4.629005222320557 and perplexity is 102.4121361139408
At time: 87.11078214645386 and batch: 1950, loss is 4.543429698944092 and perplexity is 94.01268302292064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.517083314407704 and perplexity of 91.56813265840808
finished 3 epochs...
Completing Train Step...
At time: 89.72542715072632 and batch: 50, loss is 4.519160671234131 and perplexity is 91.75855005783403
At time: 90.45606637001038 and batch: 100, loss is 4.47672607421875 and perplexity is 87.94627126598836
At time: 91.16818475723267 and batch: 150, loss is 4.421119327545166 and perplexity is 83.18934939429919
At time: 91.87582325935364 and batch: 200, loss is 4.4121231269836425 and perplexity is 82.4443175751133
At time: 92.579665184021 and batch: 250, loss is 4.420331516265869 and perplexity is 83.12383769534496
At time: 93.285817861557 and batch: 300, loss is 4.440602531433106 and perplexity is 84.82603663253973
At time: 93.98800444602966 and batch: 350, loss is 4.444141616821289 and perplexity is 85.12677507493822
At time: 94.69292950630188 and batch: 400, loss is 4.390949668884278 and perplexity is 80.717037052339
At time: 95.40701746940613 and batch: 450, loss is 4.40867509841919 and perplexity is 82.16053673650975
At time: 96.1614670753479 and batch: 500, loss is 4.4203289604187015 and perplexity is 83.12362524379132
At time: 96.86776924133301 and batch: 550, loss is 4.380267105102539 and perplexity is 79.85936139946496
At time: 97.57045841217041 and batch: 600, loss is 4.363244276046753 and perplexity is 78.51143445648493
At time: 98.27281665802002 and batch: 650, loss is 4.432282724380493 and perplexity is 84.1232280446244
At time: 98.9796142578125 and batch: 700, loss is 4.450125751495361 and perplexity is 85.63771239550863
At time: 99.68168473243713 and batch: 750, loss is 4.404458017349243 and perplexity is 81.81478862863388
At time: 100.3839910030365 and batch: 800, loss is 4.403844423294068 and perplexity is 81.76460295909474
At time: 101.0939109325409 and batch: 850, loss is 4.411806077957153 and perplexity is 82.41818282770356
At time: 101.79557514190674 and batch: 900, loss is 4.381580104827881 and perplexity is 79.96428558668912
At time: 102.49970579147339 and batch: 950, loss is 4.4490632152557374 and perplexity is 85.54676754726475
At time: 103.20680022239685 and batch: 1000, loss is 4.42575758934021 and perplexity is 83.57609960635433
At time: 103.91184329986572 and batch: 1050, loss is 4.376568832397461 and perplexity is 79.5645651574035
At time: 104.61752247810364 and batch: 1100, loss is 4.414297399520874 and perplexity is 82.62376900813312
At time: 105.32147216796875 and batch: 1150, loss is 4.377348318099975 and perplexity is 79.62660877628593
At time: 106.02417039871216 and batch: 1200, loss is 4.438693332672119 and perplexity is 84.66424136730727
At time: 106.7264461517334 and batch: 1250, loss is 4.429836282730102 and perplexity is 83.9176770125936
At time: 107.43261361122131 and batch: 1300, loss is 4.418743562698364 and perplexity is 82.99194564767065
At time: 108.13681745529175 and batch: 1350, loss is 4.320047373771668 and perplexity is 75.19219034530508
At time: 108.84225845336914 and batch: 1400, loss is 4.324943714141845 and perplexity is 75.56125970968563
At time: 109.54873204231262 and batch: 1450, loss is 4.284068460464478 and perplexity is 72.53494606833351
At time: 110.25065064430237 and batch: 1500, loss is 4.2773799705505375 and perplexity is 72.05141565987319
At time: 110.95833587646484 and batch: 1550, loss is 4.2871472263336186 and perplexity is 72.75860830977548
At time: 111.66073036193848 and batch: 1600, loss is 4.371793327331543 and perplexity is 79.18550998375441
At time: 112.36910915374756 and batch: 1650, loss is 4.333076400756836 and perplexity is 76.17828137621827
At time: 113.07611608505249 and batch: 1700, loss is 4.338749465942382 and perplexity is 76.61167390186677
At time: 113.77957510948181 and batch: 1750, loss is 4.3363370609283445 and perplexity is 76.42707826485643
At time: 114.48074626922607 and batch: 1800, loss is 4.29085563659668 and perplexity is 73.02892799791722
At time: 115.18748044967651 and batch: 1850, loss is 4.3387236976623536 and perplexity is 76.6096997762352
At time: 115.89670443534851 and batch: 1900, loss is 4.44007381439209 and perplexity is 84.78119951556864
At time: 116.6040506362915 and batch: 1950, loss is 4.3607563781738286 and perplexity is 78.3163488029174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470574241460755 and perplexity of 87.40690127151029
finished 4 epochs...
Completing Train Step...
At time: 119.21987438201904 and batch: 50, loss is 4.340600438117981 and perplexity is 76.75361129914741
At time: 119.95523595809937 and batch: 100, loss is 4.300981187820435 and perplexity is 73.7721425276325
At time: 120.66271495819092 and batch: 150, loss is 4.25243504524231 and perplexity is 70.27633020939302
At time: 121.36984634399414 and batch: 200, loss is 4.246201677322388 and perplexity is 69.83963444380299
At time: 122.07319068908691 and batch: 250, loss is 4.253475470542908 and perplexity is 70.34948553110071
At time: 122.78249835968018 and batch: 300, loss is 4.269514932632446 and perplexity is 71.4869512205213
At time: 123.48474216461182 and batch: 350, loss is 4.272816200256347 and perplexity is 71.72333875268386
At time: 124.18808937072754 and batch: 400, loss is 4.221979322433472 and perplexity is 68.16827784705032
At time: 124.89567422866821 and batch: 450, loss is 4.251558504104614 and perplexity is 70.21475710458023
At time: 125.60038900375366 and batch: 500, loss is 4.2676145362854 and perplexity is 71.35122668561306
At time: 126.30314421653748 and batch: 550, loss is 4.226233634948731 and perplexity is 68.4589047751853
At time: 127.00509023666382 and batch: 600, loss is 4.216242384910584 and perplexity is 67.77832034644523
At time: 127.71201348304749 and batch: 650, loss is 4.281724262237549 and perplexity is 72.3651089201156
At time: 128.41951322555542 and batch: 700, loss is 4.301519346237183 and perplexity is 73.81185431171225
At time: 129.1219244003296 and batch: 750, loss is 4.256549782752991 and perplexity is 70.56609460479729
At time: 129.82394886016846 and batch: 800, loss is 4.2559513664245605 and perplexity is 70.52387933396568
At time: 130.5268726348877 and batch: 850, loss is 4.263037834167481 and perplexity is 71.02541950523282
At time: 131.2317430973053 and batch: 900, loss is 4.23518783569336 and perplexity is 69.07465220022958
At time: 131.96478724479675 and batch: 950, loss is 4.302559442520142 and perplexity is 73.88866568570793
At time: 132.66983127593994 and batch: 1000, loss is 4.281525745391845 and perplexity is 72.3507446527755
At time: 133.38292598724365 and batch: 1050, loss is 4.239927787780761 and perplexity is 69.40283992470421
At time: 134.08740282058716 and batch: 1100, loss is 4.270162882804871 and perplexity is 71.53328621265275
At time: 134.79646468162537 and batch: 1150, loss is 4.236820454597473 and perplexity is 69.1875168906508
At time: 135.50530076026917 and batch: 1200, loss is 4.297397360801697 and perplexity is 73.508229122479
At time: 136.21065044403076 and batch: 1250, loss is 4.292394046783447 and perplexity is 73.1413629080084
At time: 136.9131531715393 and batch: 1300, loss is 4.276295499801636 and perplexity is 71.97332036086064
At time: 137.62310934066772 and batch: 1350, loss is 4.183445153236389 and perplexity is 65.59143695691786
At time: 138.3311631679535 and batch: 1400, loss is 4.190774474143982 and perplexity is 66.07394371060667
At time: 139.03383779525757 and batch: 1450, loss is 4.1451618146896365 and perplexity is 63.12783608652394
At time: 139.7439670562744 and batch: 1500, loss is 4.140637516975403 and perplexity is 62.842872079100474
At time: 140.44932413101196 and batch: 1550, loss is 4.153503394126892 and perplexity is 63.65662434439814
At time: 141.15287232398987 and batch: 1600, loss is 4.239760122299194 and perplexity is 69.391204439588
At time: 141.85678601264954 and batch: 1650, loss is 4.197941417694092 and perplexity is 66.5491929432589
At time: 142.56053376197815 and batch: 1700, loss is 4.204564452171326 and perplexity is 66.9914133465596
At time: 143.26869535446167 and batch: 1750, loss is 4.205482869148255 and perplexity is 67.05296765982199
At time: 143.97063612937927 and batch: 1800, loss is 4.15457453250885 and perplexity is 63.72484592885533
At time: 144.67585945129395 and batch: 1850, loss is 4.207687072753906 and perplexity is 67.20092906152892
At time: 145.37914991378784 and batch: 1900, loss is 4.306637716293335 and perplexity is 74.19061919914205
At time: 146.08321022987366 and batch: 1950, loss is 4.228442134857178 and perplexity is 68.61026333627728
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.458379701126454 and perplexity of 86.34748695226007
finished 5 epochs...
Completing Train Step...
At time: 148.71895384788513 and batch: 50, loss is 4.21588629245758 and perplexity is 67.75418929479028
At time: 149.43004775047302 and batch: 100, loss is 4.175532131195069 and perplexity is 65.0744585987143
At time: 150.17346596717834 and batch: 150, loss is 4.136210994720459 and perplexity is 62.56531147458659
At time: 150.88637971878052 and batch: 200, loss is 4.127544021606445 and perplexity is 62.02540266937976
At time: 151.5980622768402 and batch: 250, loss is 4.133588461875916 and perplexity is 62.40144685440699
At time: 152.30246996879578 and batch: 300, loss is 4.150886292457581 and perplexity is 63.49024629566158
At time: 153.01376128196716 and batch: 350, loss is 4.15330183506012 and perplexity is 63.643795067573386
At time: 153.72634959220886 and batch: 400, loss is 4.102594108581543 and perplexity is 60.49702005784849
At time: 154.4317865371704 and batch: 450, loss is 4.1331289100646975 and perplexity is 62.37277674468739
At time: 155.13539004325867 and batch: 500, loss is 4.152949161529541 and perplexity is 63.621353543165924
At time: 155.84253215789795 and batch: 550, loss is 4.117386021614075 and perplexity is 61.39853786611341
At time: 156.55398297309875 and batch: 600, loss is 4.10887378692627 and perplexity is 60.8781172160527
At time: 157.27612829208374 and batch: 650, loss is 4.167532315254212 and perplexity is 64.55595165277961
At time: 157.97915816307068 and batch: 700, loss is 4.190468506813049 and perplexity is 66.05373033487935
At time: 158.68507266044617 and batch: 750, loss is 4.145237898826599 and perplexity is 63.1326392961726
At time: 159.3886682987213 and batch: 800, loss is 4.145175247192383 and perplexity is 63.128684057050734
At time: 160.0929400920868 and batch: 850, loss is 4.153305168151856 and perplexity is 63.6440071985343
At time: 160.7986147403717 and batch: 900, loss is 4.128430624008178 and perplexity is 62.08041892552347
At time: 161.5020079612732 and batch: 950, loss is 4.194489250183105 and perplexity is 66.31985007426374
At time: 162.2062406539917 and batch: 1000, loss is 4.1759970760345455 and perplexity is 65.10472166720511
At time: 162.90807151794434 and batch: 1050, loss is 4.1335117149353025 and perplexity is 62.39665791804153
At time: 163.61143946647644 and batch: 1100, loss is 4.164259090423584 and perplexity is 64.34499095810968
At time: 164.31431078910828 and batch: 1150, loss is 4.132419276237488 and perplexity is 62.328530613544835
At time: 165.0184440612793 and batch: 1200, loss is 4.191346292495727 and perplexity is 66.11173680855629
At time: 165.72593593597412 and batch: 1250, loss is 4.188661751747131 and perplexity is 65.93449516977886
At time: 166.42789554595947 and batch: 1300, loss is 4.169597544670105 and perplexity is 64.6894122690632
At time: 167.13633823394775 and batch: 1350, loss is 4.078499612808227 and perplexity is 59.05679528419448
At time: 167.84040784835815 and batch: 1400, loss is 4.090745606422424 and perplexity is 59.78445076076984
At time: 168.5453565120697 and batch: 1450, loss is 4.04252863407135 and perplexity is 56.97021765880403
At time: 169.25046300888062 and batch: 1500, loss is 4.041204652786255 and perplexity is 56.8948400670873
At time: 169.95912861824036 and batch: 1550, loss is 4.055478029251098 and perplexity is 57.71274478335492
At time: 170.668612241745 and batch: 1600, loss is 4.14118266582489 and perplexity is 62.877140138260714
At time: 171.3738236427307 and batch: 1650, loss is 4.095954284667969 and perplexity is 60.0966611246707
At time: 172.0777096748352 and batch: 1700, loss is 4.103623843193054 and perplexity is 60.559348018417
At time: 172.77868485450745 and batch: 1750, loss is 4.105095410346985 and perplexity is 60.64853076893373
At time: 173.48558282852173 and batch: 1800, loss is 4.053613367080689 and perplexity is 57.60523028167094
At time: 174.18776679039001 and batch: 1850, loss is 4.108557806015015 and perplexity is 60.858883931934635
At time: 174.89066433906555 and batch: 1900, loss is 4.203507256507874 and perplexity is 66.92062773859286
At time: 175.59505581855774 and batch: 1950, loss is 4.124917645454406 and perplexity is 61.86271436484657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.461841955850291 and perplexity of 86.64696207727934
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 178.20571517944336 and batch: 50, loss is 4.152401738166809 and perplexity is 63.58653525890837
At time: 178.9374599456787 and batch: 100, loss is 4.137667293548584 and perplexity is 62.65649164103847
At time: 179.639151096344 and batch: 150, loss is 4.0944227647781375 and perplexity is 60.004692336836186
At time: 180.3479518890381 and batch: 200, loss is 4.0922837066650395 and perplexity is 59.87647599286309
At time: 181.05415725708008 and batch: 250, loss is 4.094001526832581 and perplexity is 59.979421406423526
At time: 181.7607617378235 and batch: 300, loss is 4.104387993812561 and perplexity is 60.60564216732081
At time: 182.4656913280487 and batch: 350, loss is 4.110795655250549 and perplexity is 60.99522944226405
At time: 183.1682312488556 and batch: 400, loss is 4.049187259674072 and perplexity is 57.3508267692194
At time: 183.86971235275269 and batch: 450, loss is 4.071741857528687 and perplexity is 58.65904936253357
At time: 184.5718138217926 and batch: 500, loss is 4.087406902313233 and perplexity is 59.58518100582798
At time: 185.27525353431702 and batch: 550, loss is 4.05552442073822 and perplexity is 57.7154222255161
At time: 186.00816774368286 and batch: 600, loss is 4.02594970703125 and perplexity is 56.033498928035755
At time: 186.71309351921082 and batch: 650, loss is 4.091182188987732 and perplexity is 59.81055730806552
At time: 187.4185950756073 and batch: 700, loss is 4.1106967353820805 and perplexity is 60.98919610060399
At time: 188.12097835540771 and batch: 750, loss is 4.046731514930725 and perplexity is 57.21016056868829
At time: 188.83866906166077 and batch: 800, loss is 4.0419056224823 and perplexity is 56.934735606984326
At time: 189.5450735092163 and batch: 850, loss is 4.048051085472107 and perplexity is 57.285703242224095
At time: 190.2559471130371 and batch: 900, loss is 4.015002751350403 and perplexity is 55.4234478916098
At time: 190.95820569992065 and batch: 950, loss is 4.085186042785645 and perplexity is 59.45299752369076
At time: 191.6626753807068 and batch: 1000, loss is 4.05218201637268 and perplexity is 57.52283597616325
At time: 192.37509751319885 and batch: 1050, loss is 4.008384308815002 and perplexity is 55.057842191359306
At time: 193.08014941215515 and batch: 1100, loss is 4.024276337623596 and perplexity is 55.939812592910755
At time: 193.78663301467896 and batch: 1150, loss is 3.9995132446289063 and perplexity is 54.57158055730596
At time: 194.4887797832489 and batch: 1200, loss is 4.0351266241073604 and perplexity is 56.55008038843995
At time: 195.19122743606567 and batch: 1250, loss is 4.031532807350159 and perplexity is 56.347214511655714
At time: 195.90003561973572 and batch: 1300, loss is 4.019824233055115 and perplexity is 55.6913162739628
At time: 196.60646605491638 and batch: 1350, loss is 3.921456899642944 and perplexity is 50.473926682949916
At time: 197.30910801887512 and batch: 1400, loss is 3.9240583992004394 and perplexity is 50.60540552780714
At time: 198.01155829429626 and batch: 1450, loss is 3.8665242767333985 and perplexity is 47.77604086649081
At time: 198.71394681930542 and batch: 1500, loss is 3.862073040008545 and perplexity is 47.563851002826695
At time: 199.41857385635376 and batch: 1550, loss is 3.8782786893844605 and perplexity is 48.340933653051344
At time: 200.12980437278748 and batch: 1600, loss is 3.9492381238937377 and perplexity is 51.8958135890197
At time: 200.83601903915405 and batch: 1650, loss is 3.89373987197876 and perplexity is 49.0941494540445
At time: 201.54189133644104 and batch: 1700, loss is 3.8883968210220337 and perplexity is 48.83253644004805
At time: 202.24696111679077 and batch: 1750, loss is 3.8846373701095582 and perplexity is 48.64929757095356
At time: 202.95535135269165 and batch: 1800, loss is 3.829474201202393 and perplexity is 46.03832497320579
At time: 203.65896654129028 and batch: 1850, loss is 3.8707406520843506 and perplexity is 47.977907862015556
At time: 204.36334371566772 and batch: 1900, loss is 3.961046347618103 and perplexity is 52.51224327345321
At time: 205.06668138504028 and batch: 1950, loss is 3.879608497619629 and perplexity is 48.405260586482214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388075717659884 and perplexity of 80.48539325080684
finished 7 epochs...
Completing Train Step...
At time: 207.70888209342957 and batch: 50, loss is 4.0598542642593385 and perplexity is 57.965862765420425
At time: 208.44582295417786 and batch: 100, loss is 4.03730676651001 and perplexity is 56.67350210614263
At time: 209.15153670310974 and batch: 150, loss is 3.988408808708191 and perplexity is 53.968946088320585
At time: 209.8551847934723 and batch: 200, loss is 3.985819835662842 and perplexity is 53.829402656647744
At time: 210.55969166755676 and batch: 250, loss is 3.9875223207473756 and perplexity is 53.921124467132884
At time: 211.26253628730774 and batch: 300, loss is 4.001085076332092 and perplexity is 54.65742534682536
At time: 211.9641511440277 and batch: 350, loss is 4.007440042495728 and perplexity is 55.005877463498365
At time: 212.66818237304688 and batch: 400, loss is 3.9495738887786866 and perplexity is 51.91324130654281
At time: 213.37107372283936 and batch: 450, loss is 3.98148108959198 and perplexity is 53.59635647705798
At time: 214.07535481452942 and batch: 500, loss is 3.996844711303711 and perplexity is 54.42614860728537
At time: 214.78154110908508 and batch: 550, loss is 3.9669287157058717 and perplexity is 52.82204992254159
At time: 215.4921898841858 and batch: 600, loss is 3.9423113679885864 and perplexity is 51.53758606540695
At time: 216.20312547683716 and batch: 650, loss is 4.010107393264771 and perplexity is 55.15279328395996
At time: 216.90935707092285 and batch: 700, loss is 4.028621301651001 and perplexity is 56.18339786774053
At time: 217.61582398414612 and batch: 750, loss is 3.9699709939956667 and perplexity is 52.98299399243403
At time: 218.32073330879211 and batch: 800, loss is 3.9692629766464234 and perplexity is 52.94549439022352
At time: 219.0278160572052 and batch: 850, loss is 3.976651420593262 and perplexity is 53.33812789696714
At time: 219.72999715805054 and batch: 900, loss is 3.9448498249053956 and perplexity is 51.6685781958299
At time: 220.4407434463501 and batch: 950, loss is 4.018831038475037 and perplexity is 55.63603141933568
At time: 221.14296555519104 and batch: 1000, loss is 3.987224645614624 and perplexity is 53.90507587800047
At time: 221.8980906009674 and batch: 1050, loss is 3.948369388580322 and perplexity is 51.8507494403793
At time: 222.60051822662354 and batch: 1100, loss is 3.9636915016174314 and perplexity is 52.65133011572289
At time: 223.3035969734192 and batch: 1150, loss is 3.943075976371765 and perplexity is 51.57700720470759
At time: 224.00673699378967 and batch: 1200, loss is 3.9812100458145143 and perplexity is 53.58183148668309
At time: 224.71460127830505 and batch: 1250, loss is 3.981386342048645 and perplexity is 53.59127859451232
At time: 225.42026114463806 and batch: 1300, loss is 3.972253079414368 and perplexity is 53.10404378090716
At time: 226.1231963634491 and batch: 1350, loss is 3.8738789844512937 and perplexity is 48.12871500084304
At time: 226.8304467201233 and batch: 1400, loss is 3.881970844268799 and perplexity is 48.519745765227974
At time: 227.53351140022278 and batch: 1450, loss is 3.826278386116028 and perplexity is 45.89142984955443
At time: 228.2379550933838 and batch: 1500, loss is 3.8248881340026855 and perplexity is 45.82767352117593
At time: 228.9421467781067 and batch: 1550, loss is 3.8434596395492555 and perplexity is 46.68671456674407
At time: 229.64551544189453 and batch: 1600, loss is 3.9181243133544923 and perplexity is 50.305997940893455
At time: 230.35199213027954 and batch: 1650, loss is 3.864832158088684 and perplexity is 47.69526649615222
At time: 231.05532217025757 and batch: 1700, loss is 3.8645057773590086 and perplexity is 47.67970222034915
At time: 231.76062679290771 and batch: 1750, loss is 3.864144310951233 and perplexity is 47.66247072415487
At time: 232.4642095565796 and batch: 1800, loss is 3.8116598176956176 and perplexity is 45.22544259275055
At time: 233.16593647003174 and batch: 1850, loss is 3.8579981184005736 and perplexity is 47.37042640131205
At time: 233.87301635742188 and batch: 1900, loss is 3.950272870063782 and perplexity is 51.949540375371704
At time: 234.57770133018494 and batch: 1950, loss is 3.8708959674835204 and perplexity is 47.98536014863893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.387557060773982 and perplexity of 80.44365977099669
finished 8 epochs...
Completing Train Step...
At time: 237.21887469291687 and batch: 50, loss is 4.012151288986206 and perplexity is 55.265635121369435
At time: 237.9247407913208 and batch: 100, loss is 3.9889409732818604 and perplexity is 53.99767409284223
At time: 238.63310360908508 and batch: 150, loss is 3.939527082443237 and perplexity is 51.394290290232604
At time: 239.3383343219757 and batch: 200, loss is 3.935600633621216 and perplexity is 51.1928888945507
At time: 240.10498690605164 and batch: 250, loss is 3.936504611968994 and perplexity is 51.23918708079771
At time: 240.8099377155304 and batch: 300, loss is 3.951013922691345 and perplexity is 51.9880519865705
At time: 241.51370787620544 and batch: 350, loss is 3.959363956451416 and perplexity is 52.42397141394608
At time: 242.2168562412262 and batch: 400, loss is 3.901798310279846 and perplexity is 49.49136996729255
At time: 242.9193925857544 and batch: 450, loss is 3.9365612983703615 and perplexity is 51.24209172824855
At time: 243.6210618019104 and batch: 500, loss is 3.953084077835083 and perplexity is 52.09578679521236
At time: 244.32469582557678 and batch: 550, loss is 3.921825060844421 and perplexity is 50.492512645546
At time: 245.0299801826477 and batch: 600, loss is 3.899421339035034 and perplexity is 49.37387010623221
At time: 245.73224520683289 and batch: 650, loss is 3.9678459119796754 and perplexity is 52.87052033494807
At time: 246.43360352516174 and batch: 700, loss is 3.986356554031372 and perplexity is 53.85830164043456
At time: 247.14127373695374 and batch: 750, loss is 3.929161148071289 and perplexity is 50.86429215871323
At time: 247.84313249588013 and batch: 800, loss is 3.9294298601150515 and perplexity is 50.87796184313589
At time: 248.54964089393616 and batch: 850, loss is 3.9371258354187013 and perplexity is 51.27102795448095
At time: 249.25450563430786 and batch: 900, loss is 3.906632966995239 and perplexity is 49.731223088017494
At time: 249.95820450782776 and batch: 950, loss is 3.982311487197876 and perplexity is 53.64088124723401
At time: 250.6652147769928 and batch: 1000, loss is 3.94968243598938 and perplexity is 51.918876649929544
At time: 251.37011075019836 and batch: 1050, loss is 3.913677020072937 and perplexity is 50.082769164074556
At time: 252.07566022872925 and batch: 1100, loss is 3.9276448106765747 and perplexity is 50.78722317651406
At time: 252.77821731567383 and batch: 1150, loss is 3.9086953735351564 and perplexity is 49.833894926895226
At time: 253.48417115211487 and batch: 1200, loss is 3.9481049966812134 and perplexity is 51.83704233436829
At time: 254.18942618370056 and batch: 1250, loss is 3.949937081336975 and perplexity is 51.93209923378411
At time: 254.89342594146729 and batch: 1300, loss is 3.940662531852722 and perplexity is 51.4526790492614
At time: 255.59562993049622 and batch: 1350, loss is 3.8432052993774413 and perplexity is 46.67484176966835
At time: 256.29792618751526 and batch: 1400, loss is 3.853959937095642 and perplexity is 47.17952174424223
At time: 257.0011055469513 and batch: 1450, loss is 3.798590803146362 and perplexity is 44.63823608852306
At time: 257.7068974971771 and batch: 1500, loss is 3.7982157278060913 and perplexity is 44.621496526427784
At time: 258.4148006439209 and batch: 1550, loss is 3.818179383277893 and perplexity is 45.521256071620506
At time: 259.1186957359314 and batch: 1600, loss is 3.893730125427246 and perplexity is 49.09367095771967
At time: 259.82518243789673 and batch: 1650, loss is 3.8410666370391846 and perplexity is 46.57512670985999
At time: 260.5334839820862 and batch: 1700, loss is 3.8425042247772216 and perplexity is 46.64213069142722
At time: 261.2357716560364 and batch: 1750, loss is 3.8433204746246337 and perplexity is 46.680217865697486
At time: 261.9433913230896 and batch: 1800, loss is 3.7924896049499512 and perplexity is 44.36671849659095
At time: 262.64863181114197 and batch: 1850, loss is 3.841078505516052 and perplexity is 46.57567948895426
At time: 263.35346388816833 and batch: 1900, loss is 3.9335260915756227 and perplexity is 51.08679717801602
At time: 264.056476354599 and batch: 1950, loss is 3.85470242023468 and perplexity is 47.21456475145632
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.390658498364826 and perplexity of 80.69353805200595
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 266.6862769126892 and batch: 50, loss is 4.001883368492127 and perplexity is 54.701075361381534
At time: 267.4185907840729 and batch: 100, loss is 4.0142372035980225 and perplexity is 55.38103483232968
At time: 268.1217534542084 and batch: 150, loss is 3.9716277647018434 and perplexity is 53.070847421204185
At time: 268.82705068588257 and batch: 200, loss is 3.965220947265625 and perplexity is 52.731919075947744
At time: 269.5296025276184 and batch: 250, loss is 3.964234356880188 and perplexity is 52.67991992672992
At time: 270.23713755607605 and batch: 300, loss is 3.9784073877334594 and perplexity is 53.43187017696829
At time: 270.94103479385376 and batch: 350, loss is 3.9859724378585817 and perplexity is 53.837617768494624
At time: 271.64296221733093 and batch: 400, loss is 3.9337696504592894 and perplexity is 51.09924133668798
At time: 272.34869408607483 and batch: 450, loss is 3.9611841297149657 and perplexity is 52.519479018909045
At time: 273.05699706077576 and batch: 500, loss is 3.9793079805374147 and perplexity is 53.48001220968179
At time: 273.76283288002014 and batch: 550, loss is 3.953178200721741 and perplexity is 52.100690431816844
At time: 274.46767830848694 and batch: 600, loss is 3.9157728815078734 and perplexity is 50.1878457830735
At time: 275.17544627189636 and batch: 650, loss is 3.976467080116272 and perplexity is 53.3282964272256
At time: 275.9367163181305 and batch: 700, loss is 4.005532898902893 and perplexity is 54.90107332676065
At time: 276.6427719593048 and batch: 750, loss is 3.9446469831466673 and perplexity is 51.658098713431926
At time: 277.3451769351959 and batch: 800, loss is 3.939564280509949 and perplexity is 51.3962020940289
At time: 278.04758501052856 and batch: 850, loss is 3.949000611305237 and perplexity is 51.883489143665216
At time: 278.75511717796326 and batch: 900, loss is 3.910670323371887 and perplexity is 49.93241162028709
At time: 279.46004986763 and batch: 950, loss is 3.9918855571746827 and perplexity is 54.15690909958901
At time: 280.16764187812805 and batch: 1000, loss is 3.9449838542938234 and perplexity is 51.67550376787115
At time: 280.869624376297 and batch: 1050, loss is 3.9033891677856447 and perplexity is 49.570166344963354
At time: 281.5763816833496 and batch: 1100, loss is 3.9087960290908814 and perplexity is 49.83891123773858
At time: 282.28045773506165 and batch: 1150, loss is 3.8989071655273437 and perplexity is 49.34848989572653
At time: 282.9889762401581 and batch: 1200, loss is 3.929714226722717 and perplexity is 50.892431893852276
At time: 283.69583559036255 and batch: 1250, loss is 3.9269570112228394 and perplexity is 50.752303762310135
At time: 284.3978281021118 and batch: 1300, loss is 3.924862432479858 and perplexity is 50.64611031978081
At time: 285.09982538223267 and batch: 1350, loss is 3.8288323497772216 and perplexity is 46.008784689959846
At time: 285.80319571495056 and batch: 1400, loss is 3.830728740692139 and perplexity is 46.09611811423537
At time: 286.51751351356506 and batch: 1450, loss is 3.7663376998901366 and perplexity is 43.22148458112522
At time: 287.2272598743439 and batch: 1500, loss is 3.7661643552780153 and perplexity is 43.213993018974925
At time: 287.9375853538513 and batch: 1550, loss is 3.7884714078903197 and perplexity is 44.1888019699997
At time: 288.6513364315033 and batch: 1600, loss is 3.8603895473480225 and perplexity is 47.48384497243548
At time: 289.3859701156616 and batch: 1650, loss is 3.801133089065552 and perplexity is 44.751863623229184
At time: 290.09584307670593 and batch: 1700, loss is 3.7917904090881347 and perplexity is 44.33570831297513
At time: 290.80121183395386 and batch: 1750, loss is 3.792638726234436 and perplexity is 44.373335011960904
At time: 291.5043227672577 and batch: 1800, loss is 3.745289168357849 and perplexity is 42.32124341405248
At time: 292.2196054458618 and batch: 1850, loss is 3.7937186050415037 and perplexity is 44.421278718076245
At time: 292.9237415790558 and batch: 1900, loss is 3.88778687953949 and perplexity is 48.80276053207928
At time: 293.63429522514343 and batch: 1950, loss is 3.8116426515579223 and perplexity is 45.224666253239064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361819528978924 and perplexity of 78.39965516796723
finished 10 epochs...
Completing Train Step...
At time: 296.29193329811096 and batch: 50, loss is 3.9953317928314207 and perplexity is 54.34386853889387
At time: 297.03186202049255 and batch: 100, loss is 3.9830524110794068 and perplexity is 53.68063978438243
At time: 297.7371942996979 and batch: 150, loss is 3.9336016082763674 and perplexity is 51.09065523006236
At time: 298.44072461128235 and batch: 200, loss is 3.9242915105819702 and perplexity is 50.61720359888156
At time: 299.1454026699066 and batch: 250, loss is 3.9229124546051026 and perplexity is 50.54744775139051
At time: 299.8493618965149 and batch: 300, loss is 3.937220973968506 and perplexity is 51.275906037770724
At time: 300.556702375412 and batch: 350, loss is 3.9468811559677124 and perplexity is 51.77364085606072
At time: 301.2696328163147 and batch: 400, loss is 3.8953436756134034 and perplexity is 49.17295000279107
At time: 301.975962638855 and batch: 450, loss is 3.9238072776794435 and perplexity is 50.59269901690634
At time: 302.68046474456787 and batch: 500, loss is 3.9442304277420046 and perplexity is 51.63658473441145
At time: 303.38500118255615 and batch: 550, loss is 3.9187184381484985 and perplexity is 50.33589486192896
At time: 304.0898771286011 and batch: 600, loss is 3.883202438354492 and perplexity is 48.57953921022037
At time: 304.79386734962463 and batch: 650, loss is 3.9452047157287597 and perplexity is 51.68691815423686
At time: 305.4977345466614 and batch: 700, loss is 3.9747936868667604 and perplexity is 53.239131840492
At time: 306.2029592990875 and batch: 750, loss is 3.9153447198867797 and perplexity is 50.16636187328485
At time: 306.9057402610779 and batch: 800, loss is 3.911612467765808 and perplexity is 49.979477329835866
At time: 307.60850954055786 and batch: 850, loss is 3.9234668397903443 and perplexity is 50.57547827671173
At time: 308.31720757484436 and batch: 900, loss is 3.8849024772644043 and perplexity is 48.66219655754912
At time: 309.02100014686584 and batch: 950, loss is 3.9676694869995117 and perplexity is 52.86119347721627
At time: 309.7311246395111 and batch: 1000, loss is 3.9231380081176757 and perplexity is 50.55885019166433
At time: 310.4425768852234 and batch: 1050, loss is 3.8829384088516234 and perplexity is 48.56671447176227
At time: 311.15079736709595 and batch: 1100, loss is 3.8897145795822143 and perplexity is 48.896928350134644
At time: 311.90611839294434 and batch: 1150, loss is 3.8806420755386353 and perplexity is 48.45531705916438
At time: 312.6093485355377 and batch: 1200, loss is 3.9124424409866334 and perplexity is 50.02097617669404
At time: 313.31549406051636 and batch: 1250, loss is 3.912050848007202 and perplexity is 50.00139214833321
At time: 314.01924991607666 and batch: 1300, loss is 3.911250901222229 and perplexity is 49.9614096894918
At time: 314.7224454879761 and batch: 1350, loss is 3.815794529914856 and perplexity is 45.4128238997958
At time: 315.4253423213959 and batch: 1400, loss is 3.8194499158859254 and perplexity is 45.57912906879796
At time: 316.1319832801819 and batch: 1450, loss is 3.758670172691345 and perplexity is 42.89134994807616
At time: 316.83949279785156 and batch: 1500, loss is 3.7589357709884643 and perplexity is 42.90274333054803
At time: 317.550252199173 and batch: 1550, loss is 3.782869143486023 and perplexity is 43.941936765391446
At time: 318.2660801410675 and batch: 1600, loss is 3.856386032104492 and perplexity is 47.29412270666617
At time: 318.9720456600189 and batch: 1650, loss is 3.798714294433594 and perplexity is 44.64374886214013
At time: 319.6755921840668 and batch: 1700, loss is 3.7916887998580933 and perplexity is 44.331203624652936
At time: 320.3799138069153 and batch: 1750, loss is 3.7942168283462525 and perplexity is 44.44341594854447
At time: 321.084184885025 and batch: 1800, loss is 3.748075680732727 and perplexity is 42.43933654011189
At time: 321.78617238998413 and batch: 1850, loss is 3.7977667236328125 and perplexity is 44.60146578554912
At time: 322.48894000053406 and batch: 1900, loss is 3.8923114109039307 and perplexity is 49.024070437037885
At time: 323.19298577308655 and batch: 1950, loss is 3.816567258834839 and perplexity is 45.44792926387949
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360438431140988 and perplexity of 78.29145231028532
finished 11 epochs...
Completing Train Step...
At time: 325.841637134552 and batch: 50, loss is 3.9818592405319215 and perplexity is 53.616627822209765
At time: 326.5447268486023 and batch: 100, loss is 3.967025165557861 and perplexity is 52.827144847136815
At time: 327.2496147155762 and batch: 150, loss is 3.916654224395752 and perplexity is 50.232097981828225
At time: 327.9512686729431 and batch: 200, loss is 3.906346096992493 and perplexity is 49.71695873801854
At time: 328.6550409793854 and batch: 250, loss is 3.904597544670105 and perplexity is 49.63010199326639
At time: 329.35893177986145 and batch: 300, loss is 3.9186150598526 and perplexity is 50.33069149185802
At time: 330.09192085266113 and batch: 350, loss is 3.928636226654053 and perplexity is 50.83759940879754
At time: 330.7977023124695 and batch: 400, loss is 3.8777169227600097 and perplexity is 48.313784956260115
At time: 331.5030047893524 and batch: 450, loss is 3.9071165418624876 and perplexity is 49.75527767324806
At time: 332.2074453830719 and batch: 500, loss is 3.9281260204315185 and perplexity is 50.811668364892945
At time: 332.913099527359 and batch: 550, loss is 3.9027217054367065 and perplexity is 49.53709116474416
At time: 333.6203017234802 and batch: 600, loss is 3.8678099870681764 and perplexity is 47.83750652103411
At time: 334.3252170085907 and batch: 650, loss is 3.9300869274139405 and perplexity is 50.911403073463426
At time: 335.02570390701294 and batch: 700, loss is 3.9596002292633057 and perplexity is 52.43635923647768
At time: 335.7267107963562 and batch: 750, loss is 3.9006701564788817 and perplexity is 49.43556757290913
At time: 336.4326150417328 and batch: 800, loss is 3.897633476257324 and perplexity is 49.28567526530699
At time: 337.137736082077 and batch: 850, loss is 3.910503177642822 and perplexity is 49.92406632840222
At time: 337.84306621551514 and batch: 900, loss is 3.8717542123794555 and perplexity is 48.0265610167545
At time: 338.5451593399048 and batch: 950, loss is 3.955300097465515 and perplexity is 52.21136009046298
At time: 339.25601840019226 and batch: 1000, loss is 3.911116933822632 and perplexity is 49.954716937670774
At time: 339.96401047706604 and batch: 1050, loss is 3.8718170356750488 and perplexity is 48.02957829837038
At time: 340.6692969799042 and batch: 1100, loss is 3.878972396850586 and perplexity is 48.37447975389095
At time: 341.3733654022217 and batch: 1150, loss is 3.8701913785934448 and perplexity is 47.9515621052531
At time: 342.078843832016 and batch: 1200, loss is 3.902379093170166 and perplexity is 49.520122056740654
At time: 342.7834405899048 and batch: 1250, loss is 3.902994327545166 and perplexity is 49.55059791201976
At time: 343.490355014801 and batch: 1300, loss is 3.9024388790130615 and perplexity is 49.52308274748092
At time: 344.19848132133484 and batch: 1350, loss is 3.8074385118484497 and perplexity is 45.034934546752474
At time: 344.9043881893158 and batch: 1400, loss is 3.8118728399276733 and perplexity is 45.23507764368095
At time: 345.6082625389099 and batch: 1450, loss is 3.7524587869644166 and perplexity is 42.62576092104308
At time: 346.31531262397766 and batch: 1500, loss is 3.7529040145874024 and perplexity is 42.6447433126849
At time: 347.0253653526306 and batch: 1550, loss is 3.7772124719619753 and perplexity is 43.69407336482509
At time: 347.7372028827667 and batch: 1600, loss is 3.8512586641311644 and perplexity is 47.05224895434189
At time: 348.44365882873535 and batch: 1650, loss is 3.7943380546569823 and perplexity is 44.448803986475525
At time: 349.150780916214 and batch: 1700, loss is 3.7882521629333494 and perplexity is 44.17911485997704
At time: 349.8544383049011 and batch: 1750, loss is 3.791333637237549 and perplexity is 44.31546163385054
At time: 350.5586874485016 and batch: 1800, loss is 3.7457868480682373 and perplexity is 42.34231108025821
At time: 351.2634451389313 and batch: 1850, loss is 3.796210751533508 and perplexity is 44.532121112377645
At time: 351.9689679145813 and batch: 1900, loss is 3.8911723995208742 and perplexity is 48.96826325130968
At time: 352.6776852607727 and batch: 1950, loss is 3.81534348487854 and perplexity is 45.3923452897256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36055170103561 and perplexity of 78.30032087709965
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 355.34000515937805 and batch: 50, loss is 3.9837196111679076 and perplexity is 53.71646746278338
At time: 356.0814654827118 and batch: 100, loss is 3.991817317008972 and perplexity is 54.153213549231594
At time: 356.7860834598541 and batch: 150, loss is 3.9585633134841918 and perplexity is 52.382015328083334
At time: 357.49311327934265 and batch: 200, loss is 3.9501988077163697 and perplexity is 51.94569301293862
At time: 358.2027142047882 and batch: 250, loss is 3.9484834766387937 and perplexity is 51.85666532917297
At time: 358.90898036956787 and batch: 300, loss is 3.95430552482605 and perplexity is 52.15945791476804
At time: 359.61291766166687 and batch: 350, loss is 3.9587475872039795 and perplexity is 52.391668846315355
At time: 360.3193140029907 and batch: 400, loss is 3.91503342628479 and perplexity is 50.1507478361996
At time: 361.0243353843689 and batch: 450, loss is 3.9438281440734864 and perplexity is 51.61581635734428
At time: 361.7311542034149 and batch: 500, loss is 3.9610464143753052 and perplexity is 52.51224677902378
At time: 362.43795347213745 and batch: 550, loss is 3.9354345846176146 and perplexity is 51.18438907207135
At time: 363.1454339027405 and batch: 600, loss is 3.8944513273239134 and perplexity is 49.12909017699757
At time: 363.8481197357178 and batch: 650, loss is 3.9444377422332764 and perplexity is 51.647290856435454
At time: 364.5547528266907 and batch: 700, loss is 3.973639769554138 and perplexity is 53.177733715544704
At time: 365.257648229599 and batch: 750, loss is 3.920836992263794 and perplexity is 50.44264721953124
At time: 365.99598956108093 and batch: 800, loss is 3.920075922012329 and perplexity is 50.4042714265169
At time: 366.6963074207306 and batch: 850, loss is 3.931530714035034 and perplexity is 50.98496136454246
At time: 367.40159487724304 and batch: 900, loss is 3.8903905296325685 and perplexity is 48.929991404542825
At time: 368.1075441837311 and batch: 950, loss is 3.9811841583251955 and perplexity is 53.5804444055469
At time: 368.81299114227295 and batch: 1000, loss is 3.936368217468262 and perplexity is 51.232198814049326
At time: 369.5191698074341 and batch: 1050, loss is 3.890736002922058 and perplexity is 48.94689832990546
At time: 370.2276668548584 and batch: 1100, loss is 3.8970933771133422 and perplexity is 49.25906330148198
At time: 370.93058586120605 and batch: 1150, loss is 3.8933935260772703 and perplexity is 49.077148840810274
At time: 371.63307309150696 and batch: 1200, loss is 3.9154483795166017 and perplexity is 50.171562369322245
At time: 372.3370623588562 and batch: 1250, loss is 3.9097233772277833 and perplexity is 49.88515069594409
At time: 373.04036116600037 and batch: 1300, loss is 3.9055940389633177 and perplexity is 49.679582756228676
At time: 373.7498025894165 and batch: 1350, loss is 3.8103353786468506 and perplexity is 45.16558389892873
At time: 374.45456624031067 and batch: 1400, loss is 3.8115232133865358 and perplexity is 45.21926502436308
At time: 375.15852189064026 and batch: 1450, loss is 3.746402049064636 and perplexity is 42.368368126563226
At time: 375.8633990287781 and batch: 1500, loss is 3.7445173549652098 and perplexity is 42.28859191364588
At time: 376.5696048736572 and batch: 1550, loss is 3.77266640663147 and perplexity is 43.49588807570834
At time: 377.2777485847473 and batch: 1600, loss is 3.847957968711853 and perplexity is 46.89719983747127
At time: 377.9838352203369 and batch: 1650, loss is 3.7911089658737183 and perplexity is 44.30550633702342
At time: 378.685097694397 and batch: 1700, loss is 3.779441685676575 and perplexity is 43.79158543966264
At time: 379.3915503025055 and batch: 1750, loss is 3.7751691913604737 and perplexity is 43.60488526150884
At time: 380.0984616279602 and batch: 1800, loss is 3.7300403356552123 and perplexity is 41.680789352071436
At time: 380.80289459228516 and batch: 1850, loss is 3.77841034412384 and perplexity is 43.74644463973115
At time: 381.5092215538025 and batch: 1900, loss is 3.8775400924682617 and perplexity is 48.305242370887036
At time: 382.21545481681824 and batch: 1950, loss is 3.813339238166809 and perplexity is 45.30145894069823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344635435592297 and perplexity of 77.06393758874106
finished 13 epochs...
Completing Train Step...
At time: 384.84487652778625 and batch: 50, loss is 3.9923820018768312 and perplexity is 54.18380168498469
At time: 385.5770981311798 and batch: 100, loss is 3.986012477874756 and perplexity is 53.83977347073774
At time: 386.2806248664856 and batch: 150, loss is 3.942842903137207 and perplexity is 51.56498738561304
At time: 386.9832241535187 and batch: 200, loss is 3.928965425491333 and perplexity is 50.8543378423983
At time: 387.6847538948059 and batch: 250, loss is 3.9293338298797607 and perplexity is 50.87307625507482
At time: 388.3890697956085 and batch: 300, loss is 3.9341632080078126 and perplexity is 51.11935578667703
At time: 389.093843460083 and batch: 350, loss is 3.9398866415023805 and perplexity is 51.41277289548966
At time: 389.79813051223755 and batch: 400, loss is 3.8974675035476682 and perplexity is 49.27749586703321
At time: 390.50539541244507 and batch: 450, loss is 3.9269024991989134 and perplexity is 50.74953722691855
At time: 391.21159052848816 and batch: 500, loss is 3.944777460098267 and perplexity is 51.66483934441641
At time: 391.9155213832855 and batch: 550, loss is 3.9194647455215454 and perplexity is 50.37347493279106
At time: 392.6203634738922 and batch: 600, loss is 3.8807249021530152 and perplexity is 48.459330615237434
At time: 393.3225243091583 and batch: 650, loss is 3.930448303222656 and perplexity is 50.929804547645496
At time: 394.0284276008606 and batch: 700, loss is 3.9603589391708374 and perplexity is 52.47615831781478
At time: 394.7326891422272 and batch: 750, loss is 3.908679513931274 and perplexity is 49.83310458732903
At time: 395.436429977417 and batch: 800, loss is 3.9070965671539306 and perplexity is 49.754283836003204
At time: 396.14047837257385 and batch: 850, loss is 3.9184414911270142 and perplexity is 50.32195641596785
At time: 396.8449754714966 and batch: 900, loss is 3.878124952316284 and perplexity is 48.33350243088041
At time: 397.54989075660706 and batch: 950, loss is 3.970086431503296 and perplexity is 52.989110570241714
At time: 398.25556468963623 and batch: 1000, loss is 3.9250546360015868 and perplexity is 50.65584561609527
At time: 398.9596185684204 and batch: 1050, loss is 3.880181531906128 and perplexity is 48.43300640933985
At time: 399.6652190685272 and batch: 1100, loss is 3.8872467851638794 and perplexity is 48.7764095522502
At time: 400.37044286727905 and batch: 1150, loss is 3.8840394258499145 and perplexity is 48.62021669797229
At time: 401.07732343673706 and batch: 1200, loss is 3.9069847297668456 and perplexity is 49.74871975804447
At time: 401.8152630329132 and batch: 1250, loss is 3.9026126575469973 and perplexity is 49.53168954401334
At time: 402.5173532962799 and batch: 1300, loss is 3.899982671737671 and perplexity is 49.401593054349334
At time: 403.22438383102417 and batch: 1350, loss is 3.805915184020996 and perplexity is 44.96638380363329
At time: 403.9309928417206 and batch: 1400, loss is 3.808516125679016 and perplexity is 45.08349097291805
At time: 404.6390118598938 and batch: 1450, loss is 3.744950270652771 and perplexity is 42.3069032718413
At time: 405.3422648906708 and batch: 1500, loss is 3.7440452098846437 and perplexity is 42.26863027577517
At time: 406.04684138298035 and batch: 1550, loss is 3.7727866172790527 and perplexity is 43.501117058864544
At time: 406.74908471107483 and batch: 1600, loss is 3.8486717462539675 and perplexity is 46.9306859549009
At time: 407.45473051071167 and batch: 1650, loss is 3.792446994781494 and perplexity is 44.36482806351804
At time: 408.161274433136 and batch: 1700, loss is 3.7819261837005613 and perplexity is 43.9005208159826
At time: 408.86718583106995 and batch: 1750, loss is 3.778614015579224 and perplexity is 43.75535544918675
At time: 409.5751178264618 and batch: 1800, loss is 3.734601836204529 and perplexity is 41.871350587765754
At time: 410.27793526649475 and batch: 1850, loss is 3.7838773345947265 and perplexity is 43.98626097522021
At time: 410.98534059524536 and batch: 1900, loss is 3.883275032043457 and perplexity is 48.58306590618624
At time: 411.6915798187256 and batch: 1950, loss is 3.81907356262207 and perplexity is 45.5619784423588
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343400538244913 and perplexity of 76.96883027260627
finished 14 epochs...
Completing Train Step...
At time: 414.31707549095154 and batch: 50, loss is 3.9893865728378297 and perplexity is 54.021740794098854
At time: 415.0232620239258 and batch: 100, loss is 3.981378378868103 and perplexity is 53.59085183918456
At time: 415.7279007434845 and batch: 150, loss is 3.937017283439636 and perplexity is 51.26546268499376
At time: 416.43127846717834 and batch: 200, loss is 3.9223646926879883 and perplexity is 50.51976736632747
At time: 417.14015889167786 and batch: 250, loss is 3.9223860549926757 and perplexity is 50.52084659651807
At time: 417.8439450263977 and batch: 300, loss is 3.926770944595337 and perplexity is 50.74286133079904
At time: 418.55277037620544 and batch: 350, loss is 3.9324347400665283 and perplexity is 51.03107393717323
At time: 419.2591254711151 and batch: 400, loss is 3.8898030376434325 and perplexity is 48.9012538689267
At time: 419.9943060874939 and batch: 450, loss is 3.919405221939087 and perplexity is 50.37047661233844
At time: 420.6971483230591 and batch: 500, loss is 3.9375452518463137 and perplexity is 51.292536376043
At time: 421.4050405025482 and batch: 550, loss is 3.9122719287872316 and perplexity is 50.01244771715379
At time: 422.1075882911682 and batch: 600, loss is 3.8743104314804078 and perplexity is 48.14948447208638
At time: 422.81003856658936 and batch: 650, loss is 3.924057364463806 and perplexity is 50.6053531645673
At time: 423.5164611339569 and batch: 700, loss is 3.9541214084625245 and perplexity is 52.1498553890715
At time: 424.2200322151184 and batch: 750, loss is 3.9027720308303833 and perplexity is 49.53958420108962
At time: 424.9281966686249 and batch: 800, loss is 3.9013285732269285 and perplexity is 49.46812749637153
At time: 425.6327893733978 and batch: 850, loss is 3.9124983024597166 and perplexity is 50.023770500155116
At time: 426.3418507575989 and batch: 900, loss is 3.872306909561157 and perplexity is 48.05311249846394
At time: 427.05059123039246 and batch: 950, loss is 3.9648777055740356 and perplexity is 52.71382238878979
At time: 427.75449895858765 and batch: 1000, loss is 3.9199763774871825 and perplexity is 50.39925420697491
At time: 428.4568552970886 and batch: 1050, loss is 3.875489478111267 and perplexity is 48.20628844021391
At time: 429.1611280441284 and batch: 1100, loss is 3.883057885169983 and perplexity is 48.57251739065097
At time: 429.8651716709137 and batch: 1150, loss is 3.8801334714889526 and perplexity is 48.43067875478124
At time: 430.5670793056488 and batch: 1200, loss is 3.9032460975646974 and perplexity is 49.563074837615844
At time: 431.2697014808655 and batch: 1250, loss is 3.89949182510376 and perplexity is 49.37735039888841
At time: 431.9710168838501 and batch: 1300, loss is 3.897398533821106 and perplexity is 49.27409732881706
At time: 432.6747946739197 and batch: 1350, loss is 3.8035431432724 and perplexity is 44.859848112387084
At time: 433.3798677921295 and batch: 1400, loss is 3.806511001586914 and perplexity is 44.993183548065744
At time: 434.0848639011383 and batch: 1450, loss is 3.7437324476242066 and perplexity is 42.25541231057262
At time: 434.790408372879 and batch: 1500, loss is 3.743106498718262 and perplexity is 42.228970857829125
At time: 435.4968988895416 and batch: 1550, loss is 3.772178301811218 and perplexity is 43.47466270360208
At time: 436.2028889656067 and batch: 1600, loss is 3.8484068536758422 and perplexity is 46.91825601087776
At time: 436.9072766304016 and batch: 1650, loss is 3.7923535442352296 and perplexity is 44.36068233981367
At time: 437.60974192619324 and batch: 1700, loss is 3.782410216331482 and perplexity is 43.921775244075356
At time: 438.3190977573395 and batch: 1750, loss is 3.779387993812561 and perplexity is 43.78923425093268
At time: 439.0218222141266 and batch: 1800, loss is 3.7357417869567873 and perplexity is 41.919109081359906
At time: 439.7252461910248 and batch: 1850, loss is 3.785419068336487 and perplexity is 44.05412838123141
At time: 440.43651366233826 and batch: 1900, loss is 3.88470938205719 and perplexity is 48.65280102776641
At time: 441.14010548591614 and batch: 1950, loss is 3.820347480773926 and perplexity is 45.620057659961184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343084858739099 and perplexity of 76.94453662500783
finished 15 epochs...
Completing Train Step...
At time: 443.75811314582825 and batch: 50, loss is 3.9856854915618896 and perplexity is 53.822171479686894
At time: 444.4927887916565 and batch: 100, loss is 3.976985378265381 and perplexity is 53.355943548666
At time: 445.2036294937134 and batch: 150, loss is 3.932188549041748 and perplexity is 51.01851209115533
At time: 445.9056808948517 and batch: 200, loss is 3.917329502105713 and perplexity is 50.26603005341631
At time: 446.60929441452026 and batch: 250, loss is 3.917220687866211 and perplexity is 50.260560691160904
At time: 447.31735706329346 and batch: 300, loss is 3.921291918754578 and perplexity is 50.46560013656582
At time: 448.0243866443634 and batch: 350, loss is 3.9269546127319335 and perplexity is 50.75218203351709
At time: 448.73053908348083 and batch: 400, loss is 3.8842327785491944 and perplexity is 48.629618457008874
At time: 449.43894839286804 and batch: 450, loss is 3.9139102268218995 and perplexity is 50.094450165841636
At time: 450.1493558883667 and batch: 500, loss is 3.9322215509414673 and perplexity is 51.02019582675827
At time: 450.8547875881195 and batch: 550, loss is 3.9069076585769653 and perplexity is 49.74488571276681
At time: 451.5599088668823 and batch: 600, loss is 3.869483623504639 and perplexity is 47.917636150206754
At time: 452.2620048522949 and batch: 650, loss is 3.9193379974365232 and perplexity is 50.3670905959172
At time: 452.96795296669006 and batch: 700, loss is 3.949502778053284 and perplexity is 51.909549849548135
At time: 453.67236375808716 and batch: 750, loss is 3.898362946510315 and perplexity is 49.32164081561629
At time: 454.3766121864319 and batch: 800, loss is 3.8971517753601073 and perplexity is 49.26194002841316
At time: 455.0791902542114 and batch: 850, loss is 3.9082270669937134 and perplexity is 49.81056285162353
At time: 455.81385707855225 and batch: 900, loss is 3.8680698919296264 and perplexity is 47.84994133740319
At time: 456.5168604850769 and batch: 950, loss is 3.961062874794006 and perplexity is 52.5131111597067
At time: 457.21995425224304 and batch: 1000, loss is 3.9163246059417727 and perplexity is 50.21554328386817
At time: 457.92801332473755 and batch: 1050, loss is 3.872050290107727 and perplexity is 48.04078271709751
At time: 458.63075256347656 and batch: 1100, loss is 3.8799518966674804 and perplexity is 48.42188576124984
At time: 459.34079670906067 and batch: 1150, loss is 3.87723117351532 and perplexity is 48.290322270661754
At time: 460.0439443588257 and batch: 1200, loss is 3.90040771484375 and perplexity is 49.42259532402518
At time: 460.7494716644287 and batch: 1250, loss is 3.8970514726638794 and perplexity is 49.256999170801706
At time: 461.457307100296 and batch: 1300, loss is 3.8951991844177245 and perplexity is 49.16584545773457
At time: 462.1682462692261 and batch: 1350, loss is 3.8013748931884765 and perplexity is 44.76268611677089
At time: 462.87248635292053 and batch: 1400, loss is 3.8045395278930663 and perplexity is 44.904568050561245
At time: 463.5769588947296 and batch: 1450, loss is 3.7422735691070557 and perplexity is 42.193811742117866
At time: 464.2821385860443 and batch: 1500, loss is 3.741776394844055 and perplexity is 42.17283927877829
At time: 464.9856743812561 and batch: 1550, loss is 3.7709823846817017 and perplexity is 43.42270168650307
At time: 465.68914890289307 and batch: 1600, loss is 3.847491731643677 and perplexity is 46.8753397209077
At time: 466.3959450721741 and batch: 1650, loss is 3.7915385389328002 and perplexity is 44.324542877414494
At time: 467.0988664627075 and batch: 1700, loss is 3.781981658935547 and perplexity is 43.90295627524407
At time: 467.8011689186096 and batch: 1750, loss is 3.77913537979126 and perplexity is 43.77817387344089
At time: 468.5057933330536 and batch: 1800, loss is 3.7356830549240114 and perplexity is 41.91664715916896
At time: 469.20912194252014 and batch: 1850, loss is 3.7856501150131225 and perplexity is 44.06430811713777
At time: 469.9139666557312 and batch: 1900, loss is 3.8848655557632448 and perplexity is 48.66039990937018
At time: 470.6207160949707 and batch: 1950, loss is 3.8203635787963868 and perplexity is 45.620792058585224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343057605832122 and perplexity of 76.94243969128273
finished 16 epochs...
Completing Train Step...
At time: 473.2270932197571 and batch: 50, loss is 3.982042589187622 and perplexity is 53.62645926010708
At time: 473.9623849391937 and batch: 100, loss is 3.972958941459656 and perplexity is 53.141541142288624
At time: 474.67320370674133 and batch: 150, loss is 3.927930269241333 and perplexity is 50.80172289378587
At time: 475.37850618362427 and batch: 200, loss is 3.9130116367340086 and perplexity is 50.04945600814393
At time: 476.08525681495667 and batch: 250, loss is 3.9128706455230713 and perplexity is 50.0423999721658
At time: 476.7877895832062 and batch: 300, loss is 3.916685075759888 and perplexity is 50.233647734480236
At time: 477.4938519001007 and batch: 350, loss is 3.922347846031189 and perplexity is 50.51891628431403
At time: 478.2049582004547 and batch: 400, loss is 3.879604182243347 and perplexity is 48.405051700019484
At time: 478.90871000289917 and batch: 450, loss is 3.9093177127838135 and perplexity is 49.864918168110705
At time: 479.6125679016113 and batch: 500, loss is 3.9277393293380736 and perplexity is 50.79202374373797
At time: 480.3162930011749 and batch: 550, loss is 3.9023614883422852 and perplexity is 49.51925027118905
At time: 481.01959705352783 and batch: 600, loss is 3.865375418663025 and perplexity is 47.72118449349789
At time: 481.72664856910706 and batch: 650, loss is 3.9153565645217894 and perplexity is 50.16695607905007
At time: 482.43075680732727 and batch: 700, loss is 3.945602331161499 and perplexity is 51.70747375690733
At time: 483.1330990791321 and batch: 750, loss is 3.89463397026062 and perplexity is 49.13806407779008
At time: 483.8428180217743 and batch: 800, loss is 3.8936424112319945 and perplexity is 49.089364934732096
At time: 484.5619022846222 and batch: 850, loss is 3.9046582841873168 and perplexity is 49.63311659325239
At time: 485.2669937610626 and batch: 900, loss is 3.864514260292053 and perplexity is 47.680106685786185
At time: 485.9713566303253 and batch: 950, loss is 3.957847137451172 and perplexity is 52.34451401451796
At time: 486.67554473876953 and batch: 1000, loss is 3.913242621421814 and perplexity is 50.06101800138509
At time: 487.37920331954956 and batch: 1050, loss is 3.869112448692322 and perplexity is 47.8998536310178
At time: 488.0836386680603 and batch: 1100, loss is 3.877240195274353 and perplexity is 48.29075793627815
At time: 488.79127836227417 and batch: 1150, loss is 3.874686861038208 and perplexity is 48.1676127730346
At time: 489.4977161884308 and batch: 1200, loss is 3.897903389930725 and perplexity is 49.298979938439714
At time: 490.20477271080017 and batch: 1250, loss is 3.894828028678894 and perplexity is 49.147600658078964
At time: 490.90814685821533 and batch: 1300, loss is 3.8931069564819336 and perplexity is 49.063086837094275
At time: 491.6135501861572 and batch: 1350, loss is 3.799257559776306 and perplexity is 44.6680088528751
At time: 492.321072101593 and batch: 1400, loss is 3.802567195892334 and perplexity is 44.81608861810686
At time: 493.0269799232483 and batch: 1450, loss is 3.7406770181655884 and perplexity is 42.1265009191336
At time: 493.7309989929199 and batch: 1500, loss is 3.740211763381958 and perplexity is 42.10690592174996
At time: 494.43354058265686 and batch: 1550, loss is 3.7695748567581178 and perplexity is 43.36162601430215
At time: 495.13498163223267 and batch: 1600, loss is 3.8462906551361082 and perplexity is 46.81907264887796
At time: 495.8400547504425 and batch: 1650, loss is 3.7903842449188234 and perplexity is 44.27340884043279
At time: 496.5424542427063 and batch: 1700, loss is 3.7811236333847047 and perplexity is 43.86530257323169
At time: 497.2472448348999 and batch: 1750, loss is 3.778385405540466 and perplexity is 43.74535367897776
At time: 497.953471660614 and batch: 1800, loss is 3.73507598400116 and perplexity is 41.89120850381045
At time: 498.65756916999817 and batch: 1850, loss is 3.7852962160110475 and perplexity is 44.0487165615487
At time: 499.363153219223 and batch: 1900, loss is 3.8844626998901366 and perplexity is 48.64080072956631
At time: 500.0662751197815 and batch: 1950, loss is 3.8198488998413085 and perplexity is 45.597318038308956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3431646302688955 and perplexity of 76.95067485322859
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 502.6073899269104 and batch: 50, loss is 3.9837751007080078 and perplexity is 53.719448247559114
At time: 503.31158995628357 and batch: 100, loss is 3.9845243883132935 and perplexity is 53.759714647967265
At time: 504.0161192417145 and batch: 150, loss is 3.9466606092453005 and perplexity is 51.762223608327155
At time: 504.721483707428 and batch: 200, loss is 3.934761266708374 and perplexity is 51.1499373060327
At time: 505.42894220352173 and batch: 250, loss is 3.938598861694336 and perplexity is 51.346607177261205
At time: 506.1352233886719 and batch: 300, loss is 3.9415516662597656 and perplexity is 51.49844774078263
At time: 506.8447296619415 and batch: 350, loss is 3.9469942378997804 and perplexity is 51.77949585043972
At time: 507.5515470504761 and batch: 400, loss is 3.9113613748550415 and perplexity is 49.966929412806955
At time: 508.2570803165436 and batch: 450, loss is 3.9443754720687867 and perplexity is 51.64407487126938
At time: 508.9612910747528 and batch: 500, loss is 3.9583954572677613 and perplexity is 52.37322341909029
At time: 509.6987397670746 and batch: 550, loss is 3.9353850746154784 and perplexity is 51.181854995590626
At time: 510.40062975883484 and batch: 600, loss is 3.8905613803863526 and perplexity is 48.93835184463035
At time: 511.11436009407043 and batch: 650, loss is 3.9299399518966673 and perplexity is 50.903920893523704
At time: 511.8177390098572 and batch: 700, loss is 3.952300763130188 and perplexity is 52.05499537769693
At time: 512.5209648609161 and batch: 750, loss is 3.8980700731277467 and perplexity is 49.3071979349077
At time: 513.2275466918945 and batch: 800, loss is 3.897454342842102 and perplexity is 49.27684734468658
At time: 513.936136007309 and batch: 850, loss is 3.9071799421310427 and perplexity is 49.7584322712147
At time: 514.6413366794586 and batch: 900, loss is 3.865612382888794 and perplexity is 47.732494046961044
At time: 515.3613770008087 and batch: 950, loss is 3.962503080368042 and perplexity is 52.588795322403406
At time: 516.0706992149353 and batch: 1000, loss is 3.919753842353821 and perplexity is 50.38803985005912
At time: 516.7855434417725 and batch: 1050, loss is 3.876773266792297 and perplexity is 48.2682148693872
At time: 517.4960296154022 and batch: 1100, loss is 3.8858458280563353 and perplexity is 48.70812373852414
At time: 518.2034838199615 and batch: 1150, loss is 3.887259702682495 and perplexity is 48.77703962649808
At time: 518.912805557251 and batch: 1200, loss is 3.9129859590530396 and perplexity is 50.04817087067962
At time: 519.6228175163269 and batch: 1250, loss is 3.9065608596801757 and perplexity is 49.727637232330565
At time: 520.3335862159729 and batch: 1300, loss is 3.89965950012207 and perplexity is 49.38563044117938
At time: 521.0509366989136 and batch: 1350, loss is 3.7978379249572756 and perplexity is 44.60464158204516
At time: 521.7623631954193 and batch: 1400, loss is 3.8002061796188356 and perplexity is 44.71040191667092
At time: 522.4742217063904 and batch: 1450, loss is 3.73414448261261 and perplexity is 41.85220495367194
At time: 523.186624288559 and batch: 1500, loss is 3.734465537071228 and perplexity is 41.86564394788438
At time: 523.8992128372192 and batch: 1550, loss is 3.7646178722381594 and perplexity is 43.14721496056293
At time: 524.6149981021881 and batch: 1600, loss is 3.8400386238098143 and perplexity is 46.52727146556926
At time: 525.3289129734039 and batch: 1650, loss is 3.7855754041671754 and perplexity is 44.061016158376304
At time: 526.0413722991943 and batch: 1700, loss is 3.7748749351501463 and perplexity is 43.59205614083682
At time: 526.7558529376984 and batch: 1750, loss is 3.770852370262146 and perplexity is 43.41705647613508
At time: 527.4665009975433 and batch: 1800, loss is 3.727478013038635 and perplexity is 41.57412643359993
At time: 528.1733102798462 and batch: 1850, loss is 3.776655983924866 and perplexity is 43.669764900017235
At time: 528.8898258209229 and batch: 1900, loss is 3.8759403657913207 and perplexity is 48.22802896267127
At time: 529.604630947113 and batch: 1950, loss is 3.8136993789672853 and perplexity is 45.317776782567826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338009572583576 and perplexity of 76.55501039819973
finished 18 epochs...
Completing Train Step...
At time: 532.2755300998688 and batch: 50, loss is 3.9845540809631346 and perplexity is 53.761310940048816
At time: 533.0334625244141 and batch: 100, loss is 3.9788992500305174 and perplexity is 53.45815776377608
At time: 533.7406690120697 and batch: 150, loss is 3.9378326320648194 and perplexity is 51.307278954615725
At time: 534.4495809078217 and batch: 200, loss is 3.924321150779724 and perplexity is 50.618703925040855
At time: 535.1561763286591 and batch: 250, loss is 3.92749577999115 and perplexity is 50.77965488580102
At time: 535.8635582923889 and batch: 300, loss is 3.928714394569397 and perplexity is 50.841573433283
At time: 536.5796954631805 and batch: 350, loss is 3.9344406604766844 and perplexity is 51.133540945909914
At time: 537.2911314964294 and batch: 400, loss is 3.896850862503052 and perplexity is 49.24711870736998
At time: 537.9992351531982 and batch: 450, loss is 3.929519114494324 and perplexity is 50.88250312670055
At time: 538.7108957767487 and batch: 500, loss is 3.945225729942322 and perplexity is 51.6880043255858
At time: 539.4200291633606 and batch: 550, loss is 3.922491092681885 and perplexity is 50.52615346820735
At time: 540.1318888664246 and batch: 600, loss is 3.880294637680054 and perplexity is 48.43848477182471
At time: 540.8385694026947 and batch: 650, loss is 3.921915922164917 and perplexity is 50.49710067035397
At time: 541.5476551055908 and batch: 700, loss is 3.9464155054092407 and perplexity is 51.749538043461584
At time: 542.252899646759 and batch: 750, loss is 3.894677538871765 and perplexity is 49.140205001634506
At time: 542.9612355232239 and batch: 800, loss is 3.8942231559753417 and perplexity is 49.11788160502391
At time: 543.6665968894958 and batch: 850, loss is 3.9035462808609007 and perplexity is 49.57795507807865
At time: 544.3836586475372 and batch: 900, loss is 3.8618630313873292 and perplexity is 47.55386323285349
At time: 545.1099724769592 and batch: 950, loss is 3.9587029457092284 and perplexity is 52.389330056109486
At time: 545.8685369491577 and batch: 1000, loss is 3.9161740922927857 and perplexity is 50.20798572798458
At time: 546.5752279758453 and batch: 1050, loss is 3.873184175491333 and perplexity is 48.0952863530359
At time: 547.2870554924011 and batch: 1100, loss is 3.882229042053223 and perplexity is 48.532275073535594
At time: 547.9954192638397 and batch: 1150, loss is 3.8835703992843627 and perplexity is 48.59741787176359
At time: 548.7046558856964 and batch: 1200, loss is 3.9089208459854126 and perplexity is 49.84513236410884
At time: 549.4069559574127 and batch: 1250, loss is 3.9037154960632323 and perplexity is 49.586345131620654
At time: 550.1177728176117 and batch: 1300, loss is 3.8970209407806395 and perplexity is 49.25549528481263
At time: 550.8345725536346 and batch: 1350, loss is 3.796092472076416 and perplexity is 44.526854188759884
At time: 551.5421736240387 and batch: 1400, loss is 3.799275965690613 and perplexity is 44.668831015984615
At time: 552.2565536499023 and batch: 1450, loss is 3.7338664531707764 and perplexity is 41.840570425934736
At time: 552.9627742767334 and batch: 1500, loss is 3.735084195137024 and perplexity is 41.8915524796272
At time: 553.671808719635 and batch: 1550, loss is 3.7664499473571778 and perplexity is 43.22633635558581
At time: 554.3748314380646 and batch: 1600, loss is 3.842150082588196 and perplexity is 46.625615669668925
At time: 555.0814530849457 and batch: 1650, loss is 3.787768592834473 and perplexity is 44.157756325626416
At time: 555.7841093540192 and batch: 1700, loss is 3.77777560710907 and perplexity is 43.71868596271558
At time: 556.4924011230469 and batch: 1750, loss is 3.773917307853699 and perplexity is 43.55033117963764
At time: 557.2032473087311 and batch: 1800, loss is 3.731070709228516 and perplexity is 41.72375826915099
At time: 557.9075949192047 and batch: 1850, loss is 3.780523591041565 and perplexity is 43.83898942958281
At time: 558.6130640506744 and batch: 1900, loss is 3.8797357940673827 and perplexity is 48.411422796412864
At time: 559.3159985542297 and batch: 1950, loss is 3.8168789672851564 and perplexity is 45.462097975619336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336994401798692 and perplexity of 76.47733342257614
finished 19 epochs...
Completing Train Step...
At time: 561.9295403957367 and batch: 50, loss is 3.984092059135437 and perplexity is 53.73647777808206
At time: 562.6910786628723 and batch: 100, loss is 3.9767698574066164 and perplexity is 53.34444546897471
At time: 563.3965225219727 and batch: 150, loss is 3.9348426342010496 and perplexity is 51.1540994175098
At time: 564.1327834129333 and batch: 200, loss is 3.9207886028289796 and perplexity is 50.440206387397474
At time: 564.8362300395966 and batch: 250, loss is 3.9236071062088014 and perplexity is 50.5825728154625
At time: 565.5641877651215 and batch: 300, loss is 3.9247276163101197 and perplexity is 50.6392828654113
At time: 566.2668986320496 and batch: 350, loss is 3.930413122177124 and perplexity is 50.92801281539047
At time: 566.9752910137177 and batch: 400, loss is 3.892442560195923 and perplexity is 49.03050033079507
At time: 567.6784744262695 and batch: 450, loss is 3.925102882385254 and perplexity is 50.658289636414956
At time: 568.3808109760284 and batch: 500, loss is 3.9411020421981813 and perplexity is 51.475298004273405
At time: 569.0919408798218 and batch: 550, loss is 3.9185059213638307 and perplexity is 50.32519877598868
At time: 569.8107271194458 and batch: 600, loss is 3.877157211303711 and perplexity is 48.28675074370795
At time: 570.5192856788635 and batch: 650, loss is 3.919122576713562 and perplexity is 50.35624164943347
At time: 571.233252286911 and batch: 700, loss is 3.944253406524658 and perplexity is 51.63777129390183
At time: 571.939882516861 and batch: 750, loss is 3.8931165599822997 and perplexity is 49.06355801672916
At time: 572.6418769359589 and batch: 800, loss is 3.8926736021041872 and perplexity is 49.0418297398884
At time: 573.3451721668243 and batch: 850, loss is 3.9017381954193113 and perplexity is 49.488394889913366
At time: 574.049464225769 and batch: 900, loss is 3.86000940322876 and perplexity is 47.465797698509085
At time: 574.7515745162964 and batch: 950, loss is 3.956927170753479 and perplexity is 52.296380948621284
At time: 575.4556007385254 and batch: 1000, loss is 3.9143052434921266 and perplexity is 50.11424221758084
At time: 576.1608123779297 and batch: 1050, loss is 3.871416907310486 and perplexity is 48.010364146075226
At time: 576.8643064498901 and batch: 1100, loss is 3.88058434009552 and perplexity is 48.45251955072115
At time: 577.5711426734924 and batch: 1150, loss is 3.881927185058594 and perplexity is 48.51762747769024
At time: 578.2800748348236 and batch: 1200, loss is 3.9071744871139527 and perplexity is 49.758160838856625
At time: 578.9828546047211 and batch: 1250, loss is 3.9024050998687745 and perplexity is 49.52140992837661
At time: 579.6891174316406 and batch: 1300, loss is 3.89599524974823 and perplexity is 49.20500026557323
At time: 580.3939731121063 and batch: 1350, loss is 3.7954359912872313 and perplexity is 44.49763275708585
At time: 581.0975091457367 and batch: 1400, loss is 3.7989128684997557 and perplexity is 44.65261483312722
At time: 581.7994875907898 and batch: 1450, loss is 3.73391815662384 and perplexity is 41.84273378382997
At time: 582.5039870738983 and batch: 1500, loss is 3.7354548597335815 and perplexity is 41.907083073169005
At time: 583.2058804035187 and batch: 1550, loss is 3.767205739021301 and perplexity is 43.25901880928125
At time: 583.908834695816 and batch: 1600, loss is 3.8430445861816405 and perplexity is 46.66734110942773
At time: 584.6167237758636 and batch: 1650, loss is 3.78860586643219 and perplexity is 44.19474393134436
At time: 585.3223347663879 and batch: 1700, loss is 3.7788241958618163 and perplexity is 43.764552928690556
At time: 586.0245804786682 and batch: 1750, loss is 3.7750347471237182 and perplexity is 43.59902323005805
At time: 586.7284646034241 and batch: 1800, loss is 3.7322652626037596 and perplexity is 41.77362930629681
At time: 587.4306905269623 and batch: 1850, loss is 3.781907682418823 and perplexity is 43.899708607592004
At time: 588.1363365650177 and batch: 1900, loss is 3.8809424829483032 and perplexity is 48.46987558208136
At time: 588.8430371284485 and batch: 1950, loss is 3.817864708900452 and perplexity is 45.506933952226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33657595612282 and perplexity of 76.44533850763699
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7420a98b38>
ELAPSED
1258.6876990795135


RESULTS SO FAR:
[{'best_accuracy': -76.72922266508544, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.44533850763699, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.7798990364997814, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3775751613796833, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.278968697079667, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.1071481079890072, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3144867420196533 and batch: 50, loss is 7.460478944778442 and perplexity is 1737.9802546126607
At time: 2.014296293258667 and batch: 100, loss is 6.6502892208099365 and perplexity is 773.0078631679966
At time: 2.715538740158081 and batch: 150, loss is 6.348478441238403 and perplexity is 571.6222900810262
At time: 3.419072151184082 and batch: 200, loss is 6.15546064376831 and perplexity is 471.283886452408
At time: 4.122958660125732 and batch: 250, loss is 6.026524391174316 and perplexity is 414.2726745394598
At time: 4.824458599090576 and batch: 300, loss is 5.930367202758789 and perplexity is 376.2926641629869
At time: 5.527363061904907 and batch: 350, loss is 5.844374189376831 and perplexity is 345.2863902621151
At time: 6.227964162826538 and batch: 400, loss is 5.769297103881836 and perplexity is 320.3125070837138
At time: 6.930083751678467 and batch: 450, loss is 5.674458703994751 and perplexity is 291.33059976762524
At time: 7.66306471824646 and batch: 500, loss is 5.647297143936157 and perplexity is 283.52410441250066
At time: 8.368525743484497 and batch: 550, loss is 5.594625978469849 and perplexity is 268.97702807642276
At time: 9.07539677619934 and batch: 600, loss is 5.595239181518554 and perplexity is 269.1420161905083
At time: 9.78421425819397 and batch: 650, loss is 5.642992143630981 and perplexity is 282.3061565704172
At time: 10.48576283454895 and batch: 700, loss is 5.574010887145996 and perplexity is 263.4888065376221
At time: 11.192875623703003 and batch: 750, loss is 5.500261077880859 and perplexity is 244.75582425538917
At time: 11.899851322174072 and batch: 800, loss is 5.506552667617798 and perplexity is 246.30058188229586
At time: 12.605885028839111 and batch: 850, loss is 5.512233781814575 and perplexity is 247.70382583512654
At time: 13.309463024139404 and batch: 900, loss is 5.501502189636231 and perplexity is 245.0597821699216
At time: 14.016624689102173 and batch: 950, loss is 5.516117038726807 and perplexity is 248.66759349659466
At time: 14.720214366912842 and batch: 1000, loss is 5.477471189498901 and perplexity is 239.240946751719
At time: 15.421907663345337 and batch: 1050, loss is 5.376289882659912 and perplexity is 216.21858912484004
At time: 16.125816345214844 and batch: 1100, loss is 5.453743419647217 and perplexity is 233.6311102781302
At time: 16.830526113510132 and batch: 1150, loss is 5.35936206817627 and perplexity is 212.58928571225675
At time: 17.535507202148438 and batch: 1200, loss is 5.427109956741333 and perplexity is 227.49083610926917
At time: 18.24422574043274 and batch: 1250, loss is 5.382350387573243 and perplexity is 217.53296180458372
At time: 18.948585033416748 and batch: 1300, loss is 5.388900079727173 and perplexity is 218.96241185653358
At time: 19.65634036064148 and batch: 1350, loss is 5.326359014511109 and perplexity is 205.6877031797658
At time: 20.358687162399292 and batch: 1400, loss is 5.327224903106689 and perplexity is 205.86588294698177
At time: 21.06230115890503 and batch: 1450, loss is 5.300189113616943 and perplexity is 200.3746999761775
At time: 21.765597820281982 and batch: 1500, loss is 5.254683294296265 and perplexity is 191.46083951144743
At time: 22.475796699523926 and batch: 1550, loss is 5.24219144821167 and perplexity is 189.0840165342168
At time: 23.178587198257446 and batch: 1600, loss is 5.276128091812134 and perplexity is 195.6110192821315
At time: 23.88192582130432 and batch: 1650, loss is 5.266538553237915 and perplexity is 193.74416530747013
At time: 24.586323976516724 and batch: 1700, loss is 5.274856414794922 and perplexity is 195.3624233449686
At time: 25.298205375671387 and batch: 1750, loss is 5.263919763565063 and perplexity is 193.23745386312453
At time: 26.005403757095337 and batch: 1800, loss is 5.23136565208435 and perplexity is 187.04807176576983
At time: 26.717180252075195 and batch: 1850, loss is 5.223187713623047 and perplexity is 185.52464189384042
At time: 27.42026948928833 and batch: 1900, loss is 5.290451393127442 and perplexity is 198.43297647833222
At time: 28.13446593284607 and batch: 1950, loss is 5.213767385482788 and perplexity is 183.7851450684776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.846306663335755 and perplexity of 127.26947174555445
finished 1 epochs...
Completing Train Step...
At time: 30.760377407073975 and batch: 50, loss is 5.102926197052002 and perplexity is 164.50257063634714
At time: 31.48970341682434 and batch: 100, loss is 5.042927808761597 and perplexity is 154.92293639933118
At time: 32.1956045627594 and batch: 150, loss is 4.966788558959961 and perplexity is 143.56509541964493
At time: 32.89886260032654 and batch: 200, loss is 4.936522970199585 and perplexity is 139.2851081514081
At time: 33.59996032714844 and batch: 250, loss is 4.950840463638306 and perplexity is 141.29366622078777
At time: 34.30760335922241 and batch: 300, loss is 4.963566398620605 and perplexity is 143.10325013243687
At time: 35.01779508590698 and batch: 350, loss is 4.959587774276733 and perplexity is 142.53502718016273
At time: 35.73553705215454 and batch: 400, loss is 4.90902626991272 and perplexity is 135.5074025120429
At time: 36.465779066085815 and batch: 450, loss is 4.883422756195069 and perplexity is 132.08197548028173
At time: 37.18014311790466 and batch: 500, loss is 4.879819345474243 and perplexity is 131.60688635849453
At time: 37.882089614868164 and batch: 550, loss is 4.845182571411133 and perplexity is 127.12648953774271
At time: 38.58633327484131 and batch: 600, loss is 4.8104440784454345 and perplexity is 122.78613208665465
At time: 39.287588119506836 and batch: 650, loss is 4.885210409164428 and perplexity is 132.31830338915583
At time: 39.9914813041687 and batch: 700, loss is 4.900167837142944 and perplexity is 134.3123203894152
At time: 40.696706771850586 and batch: 750, loss is 4.834276247024536 and perplexity is 125.74754010817966
At time: 41.397881746292114 and batch: 800, loss is 4.838918704986572 and perplexity is 126.33267495801044
At time: 42.10176682472229 and batch: 850, loss is 4.840212125778198 and perplexity is 126.49618198536248
At time: 42.80136179924011 and batch: 900, loss is 4.808067235946655 and perplexity is 122.49463534780028
At time: 43.50109601020813 and batch: 950, loss is 4.868631620407104 and perplexity is 130.14271036814566
At time: 44.20123767852783 and batch: 1000, loss is 4.8371759796142575 and perplexity is 126.11270353057544
At time: 44.9073486328125 and batch: 1050, loss is 4.762082738876343 and perplexity is 116.98933056370656
At time: 45.60903739929199 and batch: 1100, loss is 4.814389371871949 and perplexity is 123.27151626835659
At time: 46.31176567077637 and batch: 1150, loss is 4.756749496459961 and perplexity is 116.36705894134879
At time: 47.0157253742218 and batch: 1200, loss is 4.826947956085205 and perplexity is 124.82939387970046
At time: 47.71639132499695 and batch: 1250, loss is 4.810832958221436 and perplexity is 122.83389041571888
At time: 48.418850898742676 and batch: 1300, loss is 4.807414512634278 and perplexity is 122.41470633227125
At time: 49.11964797973633 and batch: 1350, loss is 4.701106061935425 and perplexity is 110.06884811248403
At time: 49.81925296783447 and batch: 1400, loss is 4.711305437088012 and perplexity is 111.1972261807904
At time: 50.519091844558716 and batch: 1450, loss is 4.6639742660522465 and perplexity is 106.05674340804458
At time: 51.224586725234985 and batch: 1500, loss is 4.644566030502319 and perplexity is 104.0182152565232
At time: 51.930384397506714 and batch: 1550, loss is 4.65360203742981 and perplexity is 104.96238390315565
At time: 52.631561279296875 and batch: 1600, loss is 4.713377466201782 and perplexity is 111.42786893754261
At time: 53.340731620788574 and batch: 1650, loss is 4.687909784317017 and perplexity is 108.62589080810757
At time: 54.04576587677002 and batch: 1700, loss is 4.688986959457398 and perplexity is 108.74296295957342
At time: 54.75567030906677 and batch: 1750, loss is 4.684869041442871 and perplexity is 108.29608907992792
At time: 55.46506595611572 and batch: 1800, loss is 4.640810194015503 and perplexity is 103.62827258720938
At time: 56.17132878303528 and batch: 1850, loss is 4.676254167556762 and perplexity is 107.36713906898402
At time: 56.87154197692871 and batch: 1900, loss is 4.777520122528077 and perplexity is 118.80935178128512
At time: 57.57475137710571 and batch: 1950, loss is 4.68808871269226 and perplexity is 108.64532880121163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.593491665152616 and perplexity of 98.83894083941827
finished 2 epochs...
Completing Train Step...
At time: 60.307886362075806 and batch: 50, loss is 4.6653334903717045 and perplexity is 106.20099632675613
At time: 61.013315200805664 and batch: 100, loss is 4.627585353851319 and perplexity is 102.26682753495227
At time: 61.718090772628784 and batch: 150, loss is 4.567278728485108 and perplexity is 96.28174418290077
At time: 62.41815662384033 and batch: 200, loss is 4.560281305313111 and perplexity is 95.61037175303115
At time: 63.12461733818054 and batch: 250, loss is 4.568914194107055 and perplexity is 96.43933850045023
At time: 63.826637744903564 and batch: 300, loss is 4.584459552764892 and perplexity is 97.95023590055092
At time: 64.53213119506836 and batch: 350, loss is 4.591294527053833 and perplexity is 98.62201643056362
At time: 65.23339033126831 and batch: 400, loss is 4.5373493003845216 and perplexity is 93.44278280653985
At time: 65.9351658821106 and batch: 450, loss is 4.542797775268554 and perplexity is 93.9532929496907
At time: 66.63572263717651 and batch: 500, loss is 4.552342023849487 and perplexity is 94.8542994078237
At time: 67.3952841758728 and batch: 550, loss is 4.5162588977813725 and perplexity is 91.49267347657832
At time: 68.0955879688263 and batch: 600, loss is 4.492139682769776 and perplexity is 89.31234165619514
At time: 68.80017304420471 and batch: 650, loss is 4.558804502487183 and perplexity is 95.46927829509008
At time: 69.50410079956055 and batch: 700, loss is 4.593597173690796 and perplexity is 98.84936974174094
At time: 70.20568180084229 and batch: 750, loss is 4.535405426025391 and perplexity is 93.26131820632902
At time: 70.91016268730164 and batch: 800, loss is 4.536441154479981 and perplexity is 93.35796164684913
At time: 71.61562180519104 and batch: 850, loss is 4.543182401657105 and perplexity is 93.98943681594714
At time: 72.32307314872742 and batch: 900, loss is 4.5038356590271 and perplexity is 90.36306934885926
At time: 73.03069233894348 and batch: 950, loss is 4.576238346099854 and perplexity is 97.14826785779456
At time: 73.73593831062317 and batch: 1000, loss is 4.548961992263794 and perplexity is 94.53423010668249
At time: 74.44139981269836 and batch: 1050, loss is 4.489183578491211 and perplexity is 89.04871490695365
At time: 75.14540362358093 and batch: 1100, loss is 4.526743955612183 and perplexity is 92.45702626165985
At time: 75.84808111190796 and batch: 1150, loss is 4.4900650215148925 and perplexity is 89.12724087847688
At time: 76.55373883247375 and batch: 1200, loss is 4.5529302310943605 and perplexity is 94.91010980637401
At time: 77.25698781013489 and batch: 1250, loss is 4.552023944854736 and perplexity is 94.82413304551767
At time: 77.96023225784302 and batch: 1300, loss is 4.535861883163452 and perplexity is 93.303897717851
At time: 78.6620569229126 and batch: 1350, loss is 4.429376010894775 and perplexity is 83.87906095700176
At time: 79.37322545051575 and batch: 1400, loss is 4.448379983901978 and perplexity is 85.48833927575006
At time: 80.07327008247375 and batch: 1450, loss is 4.394170188903809 and perplexity is 80.97740692423488
At time: 80.77390217781067 and batch: 1500, loss is 4.380088233947754 and perplexity is 79.84507814074063
At time: 81.4733510017395 and batch: 1550, loss is 4.39216386795044 and perplexity is 80.81510312717147
At time: 82.17553687095642 and batch: 1600, loss is 4.464249153137207 and perplexity is 86.85578965305885
At time: 82.87895369529724 and batch: 1650, loss is 4.431879777908325 and perplexity is 84.08933771510931
At time: 83.577880859375 and batch: 1700, loss is 4.433079452514648 and perplexity is 84.190278093927
At time: 84.28165674209595 and batch: 1750, loss is 4.438939332962036 and perplexity is 84.68507135721597
At time: 84.98606371879578 and batch: 1800, loss is 4.392124881744385 and perplexity is 80.81195251432425
At time: 85.68697214126587 and batch: 1850, loss is 4.437742023468018 and perplexity is 84.58373779320306
At time: 86.3928587436676 and batch: 1900, loss is 4.537805595397949 and perplexity is 93.48543001148882
At time: 87.09531736373901 and batch: 1950, loss is 4.453101415634155 and perplexity is 85.89292098442161
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509937658975291 and perplexity of 90.91615052787097
finished 3 epochs...
Completing Train Step...
At time: 89.66150403022766 and batch: 50, loss is 4.436788682937622 and perplexity is 84.50313911285114
At time: 90.4010362625122 and batch: 100, loss is 4.405904769897461 and perplexity is 81.93324004684904
At time: 91.11413860321045 and batch: 150, loss is 4.3542179679870605 and perplexity is 77.80595479112863
At time: 91.81804847717285 and batch: 200, loss is 4.347638320922852 and perplexity is 77.29569955959636
At time: 92.52217721939087 and batch: 250, loss is 4.358283977508545 and perplexity is 78.12295857760778
At time: 93.22804355621338 and batch: 300, loss is 4.368544445037842 and perplexity is 78.92866304111593
At time: 93.93061566352844 and batch: 350, loss is 4.3762595844268795 and perplexity is 79.53996378125726
At time: 94.636239528656 and batch: 400, loss is 4.320273580551148 and perplexity is 75.20920125244388
At time: 95.34534335136414 and batch: 450, loss is 4.3419295501708985 and perplexity is 76.85569327319344
At time: 96.05233955383301 and batch: 500, loss is 4.361060161590576 and perplexity is 78.3401436249971
At time: 96.76583051681519 and batch: 550, loss is 4.323781299591064 and perplexity is 75.473477231623
At time: 97.47473740577698 and batch: 600, loss is 4.303713188171387 and perplexity is 73.97396360901128
At time: 98.17543172836304 and batch: 650, loss is 4.366320514678955 and perplexity is 78.75332623188501
At time: 98.87613534927368 and batch: 700, loss is 4.405830011367798 and perplexity is 81.92711506724271
At time: 99.58114266395569 and batch: 750, loss is 4.351701488494873 and perplexity is 77.61040385468392
At time: 100.28664207458496 and batch: 800, loss is 4.3516639137268065 and perplexity is 77.60748771654647
At time: 100.99337697029114 and batch: 850, loss is 4.35907940864563 and perplexity is 78.18512473255146
At time: 101.7072594165802 and batch: 900, loss is 4.3213747692108155 and perplexity is 75.29206638866624
At time: 102.41402673721313 and batch: 950, loss is 4.399173402786255 and perplexity is 81.3835694223877
At time: 103.16822719573975 and batch: 1000, loss is 4.371316366195678 and perplexity is 79.1477505785688
At time: 103.8811423778534 and batch: 1050, loss is 4.320378646850586 and perplexity is 75.21710362003218
At time: 104.5836021900177 and batch: 1100, loss is 4.352744789123535 and perplexity is 77.691417091048
At time: 105.29182624816895 and batch: 1150, loss is 4.320217280387879 and perplexity is 75.2049670813274
At time: 105.99380159378052 and batch: 1200, loss is 4.38116024017334 and perplexity is 79.93071845686447
At time: 106.69895315170288 and batch: 1250, loss is 4.385112571716308 and perplexity is 80.24725627582583
At time: 107.40445876121521 and batch: 1300, loss is 4.363001079559326 and perplexity is 78.49234307297503
At time: 108.10877466201782 and batch: 1350, loss is 4.258059592247009 and perplexity is 70.67271643345805
At time: 108.81449818611145 and batch: 1400, loss is 4.2841676998138425 and perplexity is 72.5421447463777
At time: 109.52051138877869 and batch: 1450, loss is 4.21966061592102 and perplexity is 68.0103987256723
At time: 110.22495698928833 and batch: 1500, loss is 4.21718120098114 and perplexity is 67.84198160125055
At time: 110.93133616447449 and batch: 1550, loss is 4.227379865646363 and perplexity is 68.53741946274108
At time: 111.63393998146057 and batch: 1600, loss is 4.305467138290405 and perplexity is 74.1038241024102
At time: 112.33762526512146 and batch: 1650, loss is 4.26791175365448 and perplexity is 71.37243666131963
At time: 113.03996181488037 and batch: 1700, loss is 4.272455883026123 and perplexity is 71.69750025322989
At time: 113.74384188652039 and batch: 1750, loss is 4.280835719108581 and perplexity is 72.30083795779717
At time: 114.44608283042908 and batch: 1800, loss is 4.2328365039825435 and perplexity is 68.91242557913951
At time: 115.15205764770508 and batch: 1850, loss is 4.280626173019409 and perplexity is 72.2856891871975
At time: 115.85689949989319 and batch: 1900, loss is 4.379482545852661 and perplexity is 79.79673157040808
At time: 116.56941199302673 and batch: 1950, loss is 4.296675615310669 and perplexity is 73.45519403077775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.491444858284884 and perplexity of 89.25030680857066
finished 4 epochs...
Completing Train Step...
At time: 119.1820330619812 and batch: 50, loss is 4.286525692939758 and perplexity is 72.71340045557102
At time: 119.91553807258606 and batch: 100, loss is 4.2540118741989135 and perplexity is 70.38723137493699
At time: 120.62164855003357 and batch: 150, loss is 4.20944278717041 and perplexity is 67.3190183366716
At time: 121.35438466072083 and batch: 200, loss is 4.2040090656280515 and perplexity is 66.95421754705136
At time: 122.05561828613281 and batch: 250, loss is 4.2125184535980225 and perplexity is 67.52638791766718
At time: 122.76511406898499 and batch: 300, loss is 4.222818803787232 and perplexity is 68.22552787202291
At time: 123.46922588348389 and batch: 350, loss is 4.234826188087464 and perplexity is 69.04967603419082
At time: 124.17025089263916 and batch: 400, loss is 4.177698287963867 and perplexity is 65.21557286031185
At time: 124.8747091293335 and batch: 450, loss is 4.205588140487671 and perplexity is 67.06002678709476
At time: 125.57555222511292 and batch: 500, loss is 4.232486529350281 and perplexity is 68.88831219812106
At time: 126.28397750854492 and batch: 550, loss is 4.191178479194641 and perplexity is 66.10064331060619
At time: 126.99459457397461 and batch: 600, loss is 4.174518995285034 and perplexity is 65.00856271426184
At time: 127.69905495643616 and batch: 650, loss is 4.23104926109314 and perplexity is 68.78937233230693
At time: 128.4032862186432 and batch: 700, loss is 4.272698698043823 and perplexity is 71.71491159680521
At time: 129.10502314567566 and batch: 750, loss is 4.219525566101074 and perplexity is 68.0012145537443
At time: 129.80916142463684 and batch: 800, loss is 4.21902871131897 and perplexity is 67.96743621726324
At time: 130.51095032691956 and batch: 850, loss is 4.227363119125366 and perplexity is 68.53627170901747
At time: 131.21442818641663 and batch: 900, loss is 4.193426361083985 and perplexity is 66.24939687716487
At time: 131.9173641204834 and batch: 950, loss is 4.271065125465393 and perplexity is 71.59785571942272
At time: 132.6196210384369 and batch: 1000, loss is 4.245840902328491 and perplexity is 69.81444259468066
At time: 133.3278660774231 and batch: 1050, loss is 4.198530673980713 and perplexity is 66.58841902954421
At time: 134.02950382232666 and batch: 1100, loss is 4.2272794055938725 and perplexity is 68.53053453582017
At time: 134.73834443092346 and batch: 1150, loss is 4.197927045822143 and perplexity is 66.5482365136525
At time: 135.4467635154724 and batch: 1200, loss is 4.2559409427642825 and perplexity is 70.5231442208373
At time: 136.15472745895386 and batch: 1250, loss is 4.261566848754883 and perplexity is 70.92101895388616
At time: 136.8634011745453 and batch: 1300, loss is 4.239115648269653 and perplexity is 69.3464980180593
At time: 137.56609797477722 and batch: 1350, loss is 4.138070673942566 and perplexity is 62.6817711396064
At time: 138.27083778381348 and batch: 1400, loss is 4.164407844543457 and perplexity is 64.35456325254938
At time: 138.98021054267883 and batch: 1450, loss is 4.096050190925598 and perplexity is 60.10242504692886
At time: 139.68315291404724 and batch: 1500, loss is 4.098944034576416 and perplexity is 60.27660396978202
At time: 140.38801836967468 and batch: 1550, loss is 4.107994084358215 and perplexity is 60.82458612916891
At time: 141.09109807014465 and batch: 1600, loss is 4.191936345100403 and perplexity is 66.15075772212349
At time: 141.794264793396 and batch: 1650, loss is 4.153380608558654 and perplexity is 63.64880870943935
At time: 142.49900937080383 and batch: 1700, loss is 4.158786916732788 and perplexity is 63.99384563180662
At time: 143.2026882171631 and batch: 1750, loss is 4.1695948457717895 and perplexity is 64.689237679153
At time: 143.9078905582428 and batch: 1800, loss is 4.121070032119751 and perplexity is 61.625147885196206
At time: 144.60885334014893 and batch: 1850, loss is 4.166858549118042 and perplexity is 64.51247068831337
At time: 145.31955552101135 and batch: 1900, loss is 4.269816236495972 and perplexity is 71.508493760378
At time: 146.02465152740479 and batch: 1950, loss is 4.18225594997406 and perplexity is 65.51348176757764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477465536428053 and perplexity of 88.01132826066872
finished 5 epochs...
Completing Train Step...
At time: 148.66675209999084 and batch: 50, loss is 4.177985033988953 and perplexity is 65.23427584797874
At time: 149.37536525726318 and batch: 100, loss is 4.143472056388855 and perplexity is 63.02125537466751
At time: 150.07951426506042 and batch: 150, loss is 4.099926843643188 and perplexity is 60.33587348321459
At time: 150.78207969665527 and batch: 200, loss is 4.094378547668457 and perplexity is 60.002039161432094
At time: 151.48790383338928 and batch: 250, loss is 4.0994796419143675 and perplexity is 60.30889720865089
At time: 152.19016647338867 and batch: 300, loss is 4.114069271087646 and perplexity is 61.195231577821595
At time: 152.8930583000183 and batch: 350, loss is 4.129545464515686 and perplexity is 62.1496672845303
At time: 153.5963270664215 and batch: 400, loss is 4.0738082599639895 and perplexity is 58.7803878889256
At time: 154.2984209060669 and batch: 450, loss is 4.105478420257568 and perplexity is 60.67176420631488
At time: 154.99926614761353 and batch: 500, loss is 4.133648581504822 and perplexity is 62.4051985190083
At time: 155.70584321022034 and batch: 550, loss is 4.094954128265381 and perplexity is 60.03658511198496
At time: 156.40958213806152 and batch: 600, loss is 4.080157914161682 and perplexity is 59.15481049466154
At time: 157.17083024978638 and batch: 650, loss is 4.130234937667847 and perplexity is 62.1925325870783
At time: 157.87844467163086 and batch: 700, loss is 4.1720712804794315 and perplexity is 64.84963487717394
At time: 158.58871173858643 and batch: 750, loss is 4.120789866447449 and perplexity is 61.60788505254773
At time: 159.29131984710693 and batch: 800, loss is 4.121785864830017 and perplexity is 61.66927697446585
At time: 159.9990963935852 and batch: 850, loss is 4.130493750572205 and perplexity is 62.208630900202245
At time: 160.70945382118225 and batch: 900, loss is 4.096034202575684 and perplexity is 60.10146411600838
At time: 161.41512989997864 and batch: 950, loss is 4.174555687904358 and perplexity is 65.01094809246895
At time: 162.1253364086151 and batch: 1000, loss is 4.152738280296326 and perplexity is 63.607938408221735
At time: 162.83182215690613 and batch: 1050, loss is 4.106714220046997 and perplexity is 60.746788707828784
At time: 163.53589630126953 and batch: 1100, loss is 4.130322542190552 and perplexity is 62.19798117286826
At time: 164.2425389289856 and batch: 1150, loss is 4.100163345336914 and perplexity is 60.35014470700358
At time: 164.95226979255676 and batch: 1200, loss is 4.160584921836853 and perplexity is 64.109010395272
At time: 165.65698504447937 and batch: 1250, loss is 4.170865483283997 and perplexity is 64.77148649433315
At time: 166.36470293998718 and batch: 1300, loss is 4.146457719802856 and perplexity is 63.20969680249897
At time: 167.06924867630005 and batch: 1350, loss is 4.0431391143798825 and perplexity is 57.00500747302532
At time: 167.78011178970337 and batch: 1400, loss is 4.0724454116821285 and perplexity is 58.70033370153068
At time: 168.48912453651428 and batch: 1450, loss is 4.006402292251587 and perplexity is 54.94882470910647
At time: 169.19491171836853 and batch: 1500, loss is 4.007807321548462 and perplexity is 55.02608368050097
At time: 169.90625476837158 and batch: 1550, loss is 4.019042091369629 and perplexity is 55.64777480400441
At time: 170.62799382209778 and batch: 1600, loss is 4.101020002365113 and perplexity is 60.401866233261096
At time: 171.33671832084656 and batch: 1650, loss is 4.067350096702576 and perplexity is 58.401997715281844
At time: 172.04174280166626 and batch: 1700, loss is 4.071027874946594 and perplexity is 58.6171827707938
At time: 172.74618411064148 and batch: 1750, loss is 4.079901785850525 and perplexity is 59.13966121311547
At time: 173.44893622398376 and batch: 1800, loss is 4.031229891777039 and perplexity is 56.33014864776666
At time: 174.15535736083984 and batch: 1850, loss is 4.078698072433472 and perplexity is 59.06851683674372
At time: 174.8650450706482 and batch: 1900, loss is 4.17910412311554 and perplexity is 65.30731968041721
At time: 175.57167530059814 and batch: 1950, loss is 4.095440855026245 and perplexity is 60.06581363716555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.481486475744913 and perplexity of 88.36592890687747
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 178.18728375434875 and batch: 50, loss is 4.127383942604065 and perplexity is 62.0154744994652
At time: 178.921550989151 and batch: 100, loss is 4.1162335729599 and perplexity is 61.32781996098554
At time: 179.6235966682434 and batch: 150, loss is 4.072060899734497 and perplexity is 58.677767060742035
At time: 180.3254852294922 and batch: 200, loss is 4.065275750160217 and perplexity is 58.2809772957937
At time: 181.03487014770508 and batch: 250, loss is 4.065748691558838 and perplexity is 58.30854730169363
At time: 181.74156069755554 and batch: 300, loss is 4.080248174667358 and perplexity is 59.1601500787431
At time: 182.44915390014648 and batch: 350, loss is 4.091771736145019 and perplexity is 59.845828848198764
At time: 183.15147018432617 and batch: 400, loss is 4.032088980674744 and perplexity is 56.37856204580487
At time: 183.85866117477417 and batch: 450, loss is 4.049390511512756 and perplexity is 57.36248461490945
At time: 184.5678312778473 and batch: 500, loss is 4.07691722869873 and perplexity is 58.96341864811563
At time: 185.27250003814697 and batch: 550, loss is 4.039770021438598 and perplexity is 56.813275467562285
At time: 185.97612142562866 and batch: 600, loss is 4.006462235450744 and perplexity is 54.95211861617214
At time: 186.681715965271 and batch: 650, loss is 4.049274263381958 and perplexity is 57.35581672086761
At time: 187.39054656028748 and batch: 700, loss is 4.093046622276306 and perplexity is 59.92217412083679
At time: 188.095059633255 and batch: 750, loss is 4.027381749153137 and perplexity is 56.11379874137207
At time: 188.80033373832703 and batch: 800, loss is 4.024086546897888 and perplexity is 55.92919674270961
At time: 189.50758290290833 and batch: 850, loss is 4.034310789108276 and perplexity is 56.503963668033194
At time: 190.21355986595154 and batch: 900, loss is 3.996376872062683 and perplexity is 54.40069187452246
At time: 190.91576504707336 and batch: 950, loss is 4.069321374893189 and perplexity is 58.517237847527895
At time: 191.62143993377686 and batch: 1000, loss is 4.029691619873047 and perplexity is 56.243564175058566
At time: 192.32288265228271 and batch: 1050, loss is 3.9783237981796264 and perplexity is 53.42740401744448
At time: 193.08121061325073 and batch: 1100, loss is 3.997280216217041 and perplexity is 54.449856624521765
At time: 193.78961968421936 and batch: 1150, loss is 3.970446949005127 and perplexity is 53.008217515995966
At time: 194.4958291053772 and batch: 1200, loss is 4.013040313720703 and perplexity is 55.31478948444482
At time: 195.20037579536438 and batch: 1250, loss is 4.008667573928833 and perplexity is 55.073440366400035
At time: 195.91201329231262 and batch: 1300, loss is 3.9958270931243898 and perplexity is 54.37079173988652
At time: 196.6177384853363 and batch: 1350, loss is 3.893114585876465 and perplexity is 49.06346116016861
At time: 197.32063698768616 and batch: 1400, loss is 3.9054994773864746 and perplexity is 49.67488519865407
At time: 198.02589631080627 and batch: 1450, loss is 3.8404189491271974 and perplexity is 46.54497033030621
At time: 198.7289423942566 and batch: 1500, loss is 3.831779227256775 and perplexity is 46.14456690994537
At time: 199.43460869789124 and batch: 1550, loss is 3.8462421035766603 and perplexity is 46.81679956507028
At time: 200.14091610908508 and batch: 1600, loss is 3.912388730049133 and perplexity is 50.01828957531949
At time: 200.84461379051208 and batch: 1650, loss is 3.8692712211608886 and perplexity is 47.907459412801174
At time: 201.55413556098938 and batch: 1700, loss is 3.8676262950897216 and perplexity is 47.828719961851846
At time: 202.26030468940735 and batch: 1750, loss is 3.8620150089263916 and perplexity is 47.561090901168235
At time: 202.96592473983765 and batch: 1800, loss is 3.8168628883361815 and perplexity is 45.46136699874238
At time: 203.67847895622253 and batch: 1850, loss is 3.8517233180999755 and perplexity is 47.07411704871499
At time: 204.38410830497742 and batch: 1900, loss is 3.9437674283981323 and perplexity is 51.61268256333137
At time: 205.08716130256653 and batch: 1950, loss is 3.8558505630493163 and perplexity is 47.26880494650857
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3947047033975295 and perplexity of 81.02070209181628
finished 7 epochs...
Completing Train Step...
At time: 207.73615980148315 and batch: 50, loss is 4.037719044685364 and perplexity is 56.696872171334746
At time: 208.48736834526062 and batch: 100, loss is 4.0138851213455204 and perplexity is 55.3615395850067
At time: 209.1940734386444 and batch: 150, loss is 3.9648005867004397 and perplexity is 52.7097573149332
At time: 209.9016900062561 and batch: 200, loss is 3.9596506452560423 and perplexity is 52.43900293422584
At time: 210.60501551628113 and batch: 250, loss is 3.959319863319397 and perplexity is 52.421659927814275
At time: 211.34362840652466 and batch: 300, loss is 3.975843224525452 and perplexity is 53.29503764676732
At time: 212.05164074897766 and batch: 350, loss is 3.9900159883499144 and perplexity is 54.055753618721305
At time: 212.75799560546875 and batch: 400, loss is 3.9308767032623293 and perplexity is 50.95162755208848
At time: 213.46143460273743 and batch: 450, loss is 3.9600340509414673 and perplexity is 52.45911220084608
At time: 214.1677451133728 and batch: 500, loss is 3.988451714515686 and perplexity is 53.971261719208826
At time: 214.87119603157043 and batch: 550, loss is 3.953344693183899 and perplexity is 52.10936552619585
At time: 215.57615733146667 and batch: 600, loss is 3.92608323097229 and perplexity is 50.70797677045804
At time: 216.28242111206055 and batch: 650, loss is 3.970658802986145 and perplexity is 53.01944870754772
At time: 216.98477220535278 and batch: 700, loss is 4.012889490127564 and perplexity is 55.306447338253086
At time: 217.6889727115631 and batch: 750, loss is 3.9538409519195556 and perplexity is 52.13523167166723
At time: 218.39494562149048 and batch: 800, loss is 3.9529214239120485 and perplexity is 52.08731390021004
At time: 219.10018682479858 and batch: 850, loss is 3.9653358602523805 and perplexity is 52.7379790064418
At time: 219.80238914489746 and batch: 900, loss is 3.9293010807037354 and perplexity is 50.8714102310262
At time: 220.5078408718109 and batch: 950, loss is 4.001873331069946 and perplexity is 54.70052630634996
At time: 221.21013712882996 and batch: 1000, loss is 3.9680672550201415 and perplexity is 52.88222415190146
At time: 221.9123294353485 and batch: 1050, loss is 3.919961347579956 and perplexity is 50.398496716552415
At time: 222.61848163604736 and batch: 1100, loss is 3.93951762676239 and perplexity is 51.39380432452382
At time: 223.32811307907104 and batch: 1150, loss is 3.915056028366089 and perplexity is 50.15188136028935
At time: 224.03013014793396 and batch: 1200, loss is 3.960847053527832 and perplexity is 52.50177893647685
At time: 224.7359619140625 and batch: 1250, loss is 3.960653190612793 and perplexity is 52.49160177508644
At time: 225.44328618049622 and batch: 1300, loss is 3.948819570541382 and perplexity is 51.87409696736823
At time: 226.14994478225708 and batch: 1350, loss is 3.84643404006958 and perplexity is 46.82578627980019
At time: 226.85397124290466 and batch: 1400, loss is 3.863976550102234 and perplexity is 47.65447549826251
At time: 227.55605292320251 and batch: 1450, loss is 3.798867974281311 and perplexity is 44.65061023388057
At time: 228.26067852973938 and batch: 1500, loss is 3.793800392150879 and perplexity is 44.42491195463128
At time: 228.9718656539917 and batch: 1550, loss is 3.8107361459732054 and perplexity is 45.18368841683846
At time: 229.67367458343506 and batch: 1600, loss is 3.881748971939087 and perplexity is 48.50898177035849
At time: 230.37641310691833 and batch: 1650, loss is 3.840516586303711 and perplexity is 46.54951507165441
At time: 231.0815942287445 and batch: 1700, loss is 3.84305317401886 and perplexity is 46.66774188267754
At time: 231.79148244857788 and batch: 1750, loss is 3.8409367752075196 and perplexity is 46.5690787713021
At time: 232.49353766441345 and batch: 1800, loss is 3.798427019119263 and perplexity is 44.63092565713615
At time: 233.19919443130493 and batch: 1850, loss is 3.8386045360565184 and perplexity is 46.460595096675505
At time: 233.90079188346863 and batch: 1900, loss is 3.9326307201385498 and perplexity is 51.04107599078836
At time: 234.60294318199158 and batch: 1950, loss is 3.849191608428955 and perplexity is 46.95508978613986
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.393196141442587 and perplexity of 80.89856948853925
finished 8 epochs...
Completing Train Step...
At time: 237.31091213226318 and batch: 50, loss is 3.9911234951019288 and perplexity is 54.11565389469664
At time: 238.0156946182251 and batch: 100, loss is 3.965581021308899 and perplexity is 52.75090989010344
At time: 238.72124004364014 and batch: 150, loss is 3.9172659158706664 and perplexity is 50.26283392743036
At time: 239.4277045726776 and batch: 200, loss is 3.912093801498413 and perplexity is 50.00353992881839
At time: 240.13339972496033 and batch: 250, loss is 3.910256109237671 and perplexity is 49.91173319258263
At time: 240.8386332988739 and batch: 300, loss is 3.9268430566787718 and perplexity is 50.746520636187526
At time: 241.54059886932373 and batch: 350, loss is 3.941432166099548 and perplexity is 51.49229403571835
At time: 242.2490894794464 and batch: 400, loss is 3.8834372043609617 and perplexity is 48.5909453734742
At time: 242.95405268669128 and batch: 450, loss is 3.9164029026031493 and perplexity is 50.21947514718039
At time: 243.66193842887878 and batch: 500, loss is 3.9458124303817748 and perplexity is 51.71833859813345
At time: 244.36304926872253 and batch: 550, loss is 3.91083251953125 and perplexity is 49.94051112251595
At time: 245.0706021785736 and batch: 600, loss is 3.8853963470458983 and perplexity is 48.68623528144107
At time: 245.77923202514648 and batch: 650, loss is 3.930025372505188 and perplexity is 50.90826932314263
At time: 246.48608255386353 and batch: 700, loss is 3.9707089376449587 and perplexity is 53.022106886152045
At time: 247.24547696113586 and batch: 750, loss is 3.914365315437317 and perplexity is 50.117252768016485
At time: 247.95045495033264 and batch: 800, loss is 3.914220595359802 and perplexity is 50.11000032011114
At time: 248.65377759933472 and batch: 850, loss is 3.9281957387924193 and perplexity is 50.815210994617715
At time: 249.3557095527649 and batch: 900, loss is 3.8918572902679442 and perplexity is 49.00181264923526
At time: 250.062739610672 and batch: 950, loss is 3.9653699827194213 and perplexity is 52.73977858709513
At time: 250.77215790748596 and batch: 1000, loss is 3.933624348640442 and perplexity is 51.091817063373306
At time: 251.47682857513428 and batch: 1050, loss is 3.886518568992615 and perplexity is 48.74090271193479
At time: 252.18577766418457 and batch: 1100, loss is 3.9057094764709475 and perplexity is 49.68531797446542
At time: 252.88885402679443 and batch: 1150, loss is 3.8819589853286742 and perplexity is 48.519170375879845
At time: 253.594553232193 and batch: 1200, loss is 3.928781785964966 and perplexity is 50.84499983332323
At time: 254.2986340522766 and batch: 1250, loss is 3.9305269145965576 and perplexity is 50.933808366924325
At time: 255.00491571426392 and batch: 1300, loss is 3.9190862798690795 and perplexity is 50.35441390993239
At time: 255.716459274292 and batch: 1350, loss is 3.8162543296813967 and perplexity is 45.43370950685354
At time: 256.4251172542572 and batch: 1400, loss is 3.8367063426971435 and perplexity is 46.372487552623205
At time: 257.1331434249878 and batch: 1450, loss is 3.770767750740051 and perplexity is 43.413382701004046
At time: 257.8393180370331 and batch: 1500, loss is 3.766688199043274 and perplexity is 43.236636330050715
At time: 258.541464805603 and batch: 1550, loss is 3.7832158279418944 and perplexity is 43.95717339282724
At time: 259.24369645118713 and batch: 1600, loss is 3.858200969696045 and perplexity is 47.38003652835499
At time: 259.94829869270325 and batch: 1650, loss is 3.816991062164307 and perplexity is 45.4671943296301
At time: 260.65465807914734 and batch: 1700, loss is 3.8214793682098387 and perplexity is 45.67172366458678
At time: 261.36043429374695 and batch: 1750, loss is 3.8214617013931274 and perplexity is 45.67091679774332
At time: 262.0703332424164 and batch: 1800, loss is 3.7794460391998292 and perplexity is 43.791776087763196
At time: 262.7736692428589 and batch: 1850, loss is 3.822020311355591 and perplexity is 45.69643615388106
At time: 263.4853038787842 and batch: 1900, loss is 3.9161716365814208 and perplexity is 50.2078624318148
At time: 264.1973309516907 and batch: 1950, loss is 3.8342764282226565 and perplexity is 46.25994316589466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.395958904887355 and perplexity of 81.12238212738382
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 266.86803674697876 and batch: 50, loss is 3.9816896533966064 and perplexity is 53.60753590285021
At time: 267.6251742839813 and batch: 100, loss is 3.986794323921204 and perplexity is 53.881884344732526
At time: 268.3287115097046 and batch: 150, loss is 3.9490624380111696 and perplexity is 51.88669702805671
At time: 269.0309143066406 and batch: 200, loss is 3.95361825466156 and perplexity is 52.12362259123214
At time: 269.74089431762695 and batch: 250, loss is 3.9581325578689577 and perplexity is 52.35945633989772
At time: 270.448956489563 and batch: 300, loss is 3.961188793182373 and perplexity is 52.519723942358794
At time: 271.1590678691864 and batch: 350, loss is 3.9791892528533936 and perplexity is 53.473663028609955
At time: 271.86103320121765 and batch: 400, loss is 3.9181671714782715 and perplexity is 50.30815400778221
At time: 272.564954996109 and batch: 450, loss is 3.9500010299682615 and perplexity is 51.93542032663847
At time: 273.2678213119507 and batch: 500, loss is 3.9715942907333375 and perplexity is 53.06907095906181
At time: 273.9723722934723 and batch: 550, loss is 3.9401300048828123 and perplexity is 51.425286404302014
At time: 274.6764922142029 and batch: 600, loss is 3.9067251300811767 and perplexity is 49.735806682220584
At time: 275.3828594684601 and batch: 650, loss is 3.947565140724182 and perplexity is 51.809065350719315
At time: 276.08850359916687 and batch: 700, loss is 3.988148112297058 and perplexity is 53.95487841153884
At time: 276.7989032268524 and batch: 750, loss is 3.924758138656616 and perplexity is 50.64082851873762
At time: 277.50550651550293 and batch: 800, loss is 3.9201146173477173 and perplexity is 50.40622187444113
At time: 278.2165973186493 and batch: 850, loss is 3.9347834253311156 and perplexity is 51.151070730754235
At time: 278.92016196250916 and batch: 900, loss is 3.8950971508026124 and perplexity is 49.16082914470311
At time: 279.6216821670532 and batch: 950, loss is 3.978467106819153 and perplexity is 53.435061174682936
At time: 280.33115434646606 and batch: 1000, loss is 3.9263314390182495 and perplexity is 50.720564460405136
At time: 281.0370862483978 and batch: 1050, loss is 3.8790185689926147 and perplexity is 48.37671335880549
At time: 281.7424705028534 and batch: 1100, loss is 3.890156373977661 and perplexity is 48.91853551164427
At time: 282.4504425525665 and batch: 1150, loss is 3.87351327419281 and perplexity is 48.11111705411056
At time: 283.15528869628906 and batch: 1200, loss is 3.9089923763275145 and perplexity is 49.84869793100056
At time: 283.91400122642517 and batch: 1250, loss is 3.9084269762039185 and perplexity is 49.820521437276405
At time: 284.6203498840332 and batch: 1300, loss is 3.9007512855529787 and perplexity is 49.43957839742881
At time: 285.32302141189575 and batch: 1350, loss is 3.8018724870681764 and perplexity is 44.784965297953924
At time: 286.0292224884033 and batch: 1400, loss is 3.8190381050109865 and perplexity is 45.56036295208787
At time: 286.7342731952667 and batch: 1450, loss is 3.749682331085205 and perplexity is 42.50757651933719
At time: 287.43549394607544 and batch: 1500, loss is 3.7444050693511963 and perplexity is 42.283843779715646
At time: 288.1434895992279 and batch: 1550, loss is 3.761061282157898 and perplexity is 42.9940305723544
At time: 288.8489918708801 and batch: 1600, loss is 3.830796494483948 and perplexity is 46.099241406831545
At time: 289.5582916736603 and batch: 1650, loss is 3.7854490232467652 and perplexity is 44.055448038459474
At time: 290.26504921913147 and batch: 1700, loss is 3.7779581212997435 and perplexity is 43.72666597151166
At time: 290.97099471092224 and batch: 1750, loss is 3.778113965988159 and perplexity is 43.73348107118019
At time: 291.67719626426697 and batch: 1800, loss is 3.7358139896392824 and perplexity is 41.92213586275294
At time: 292.38026452064514 and batch: 1850, loss is 3.772029023170471 and perplexity is 43.46817334941979
At time: 293.0844168663025 and batch: 1900, loss is 3.8704729461669922 and perplexity is 47.96506561122838
At time: 293.79051899909973 and batch: 1950, loss is 3.786914792060852 and perplexity is 44.120070489501586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369163619640261 and perplexity of 78.97754879752146
finished 10 epochs...
Completing Train Step...
At time: 296.4417507648468 and batch: 50, loss is 3.9700082397460936 and perplexity is 52.984967420555826
At time: 297.17495226860046 and batch: 100, loss is 3.958332381248474 and perplexity is 52.36992002882322
At time: 297.8763611316681 and batch: 150, loss is 3.9131139278411866 and perplexity is 50.05457588426709
At time: 298.58707761764526 and batch: 200, loss is 3.91171932220459 and perplexity is 49.98481814417632
At time: 299.2880675792694 and batch: 250, loss is 3.9149256229400633 and perplexity is 50.145341709246836
At time: 299.99159145355225 and batch: 300, loss is 3.918649034500122 and perplexity is 50.3324014884091
At time: 300.69801688194275 and batch: 350, loss is 3.9379820680618285 and perplexity is 51.314946681903095
At time: 301.4022240638733 and batch: 400, loss is 3.877098412513733 and perplexity is 48.28391162466146
At time: 302.16184091567993 and batch: 450, loss is 3.9130238628387453 and perplexity is 50.05006792177575
At time: 302.86525106430054 and batch: 500, loss is 3.935285573005676 and perplexity is 51.17676257198228
At time: 303.56962490081787 and batch: 550, loss is 3.9052546644210815 and perplexity is 49.662725631173636
At time: 304.2770583629608 and batch: 600, loss is 3.874707427024841 and perplexity is 48.168603397701595
At time: 305.003457069397 and batch: 650, loss is 3.917008776664734 and perplexity is 50.24991104378756
At time: 305.7086730003357 and batch: 700, loss is 3.9574952507019043 and perplexity is 52.3260979140203
At time: 306.41594886779785 and batch: 750, loss is 3.897312169075012 and perplexity is 49.26984196767149
At time: 307.119704246521 and batch: 800, loss is 3.893510437011719 and perplexity is 49.08288683155172
At time: 307.82535576820374 and batch: 850, loss is 3.91028000831604 and perplexity is 49.9129260512598
At time: 308.5285391807556 and batch: 900, loss is 3.8706943941116334 and perplexity is 47.97568855259342
At time: 309.23546957969666 and batch: 950, loss is 3.9543993997573854 and perplexity is 52.16435461013317
At time: 309.9504566192627 and batch: 1000, loss is 3.9042072916030883 and perplexity is 49.61073747252475
At time: 310.6563971042633 and batch: 1050, loss is 3.8596718883514405 and perplexity is 47.44977998888171
At time: 311.36213850975037 and batch: 1100, loss is 3.87183714389801 and perplexity is 48.030544097549765
At time: 312.06775641441345 and batch: 1150, loss is 3.8561838626861573 and perplexity is 47.28456224783668
At time: 312.7716875076294 and batch: 1200, loss is 3.893540382385254 and perplexity is 49.08435665893922
At time: 313.4813058376312 and batch: 1250, loss is 3.8944211483001707 and perplexity is 49.12760753139118
At time: 314.1846709251404 and batch: 1300, loss is 3.8882934713363646 and perplexity is 48.82748987354157
At time: 314.88950872421265 and batch: 1350, loss is 3.788944945335388 and perplexity is 44.209731977565255
At time: 315.5978217124939 and batch: 1400, loss is 3.8083613204956053 and perplexity is 45.07651235500624
At time: 316.3013298511505 and batch: 1450, loss is 3.740086326599121 and perplexity is 42.101624498185224
At time: 317.00875329971313 and batch: 1500, loss is 3.736025667190552 and perplexity is 41.931010777093285
At time: 317.71477150917053 and batch: 1550, loss is 3.7535387516021728 and perplexity is 42.67182010216202
At time: 318.41901659965515 and batch: 1600, loss is 3.825182557106018 and perplexity is 45.84116823351261
At time: 319.1260733604431 and batch: 1650, loss is 3.781027984619141 and perplexity is 43.86110711183802
At time: 319.83304953575134 and batch: 1700, loss is 3.775912494659424 and perplexity is 43.637308965404266
At time: 320.53864002227783 and batch: 1750, loss is 3.7779859352111815 and perplexity is 43.7278821980404
At time: 321.24514174461365 and batch: 1800, loss is 3.7367715883255004 and perplexity is 41.962299672315034
At time: 321.9484314918518 and batch: 1850, loss is 3.774762902259827 and perplexity is 43.58717267035215
At time: 322.65374755859375 and batch: 1900, loss is 3.873372960090637 and perplexity is 48.10436685950138
At time: 323.35868787765503 and batch: 1950, loss is 3.7909214687347412 and perplexity is 44.29719996007959
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368016726471657 and perplexity of 78.8870219085907
finished 11 epochs...
Completing Train Step...
At time: 326.03488516807556 and batch: 50, loss is 3.955855140686035 and perplexity is 52.240347695858055
At time: 326.7448556423187 and batch: 100, loss is 3.942349238395691 and perplexity is 51.53953785172966
At time: 327.45489478111267 and batch: 150, loss is 3.8959252882003783 and perplexity is 49.201557928009635
At time: 328.15810894966125 and batch: 200, loss is 3.8934536170959473 and perplexity is 49.080098025286745
At time: 328.8617489337921 and batch: 250, loss is 3.8963177537918092 and perplexity is 49.220871636276236
At time: 329.5653455257416 and batch: 300, loss is 3.900536508560181 and perplexity is 49.428961053676815
At time: 330.26879143714905 and batch: 350, loss is 3.919998745918274 and perplexity is 50.40038157182834
At time: 330.97780442237854 and batch: 400, loss is 3.8588665437698366 and perplexity is 47.41158194902612
At time: 331.6873574256897 and batch: 450, loss is 3.895896716117859 and perplexity is 49.200152157119426
At time: 332.39702582359314 and batch: 500, loss is 3.9183939599990847 and perplexity is 50.31956461346276
At time: 333.100608587265 and batch: 550, loss is 3.8889115905761718 and perplexity is 48.85768041417967
At time: 333.80492520332336 and batch: 600, loss is 3.858933491706848 and perplexity is 47.41475616288041
At time: 334.5108940601349 and batch: 650, loss is 3.9021034812927247 and perplexity is 49.506475603578146
At time: 335.2176275253296 and batch: 700, loss is 3.9421506786346434 and perplexity is 51.52930518934045
At time: 335.9226961135864 and batch: 750, loss is 3.883281178474426 and perplexity is 48.5833645195648
At time: 336.62735891342163 and batch: 800, loss is 3.8793535327911375 and perplexity is 48.392920520726925
At time: 337.3870027065277 and batch: 850, loss is 3.8968312740325928 and perplexity is 49.24615404108819
At time: 338.0969684123993 and batch: 900, loss is 3.857250337600708 and perplexity is 47.33501694687279
At time: 338.80372881889343 and batch: 950, loss is 3.9417216920852662 and perplexity is 51.50720455129263
At time: 339.5118820667267 and batch: 1000, loss is 3.892426109313965 and perplexity is 49.02969374245635
At time: 340.2186255455017 and batch: 1050, loss is 3.8490316486358642 and perplexity is 46.9475794603842
At time: 340.9296760559082 and batch: 1100, loss is 3.8615010595321655 and perplexity is 47.536653187722784
At time: 341.63266038894653 and batch: 1150, loss is 3.8460806798934937 and perplexity is 46.80924283478444
At time: 342.3358271121979 and batch: 1200, loss is 3.8838996505737304 and perplexity is 48.61342126868277
At time: 343.04134035110474 and batch: 1250, loss is 3.8854699420928953 and perplexity is 48.6898184790659
At time: 343.74727416038513 and batch: 1300, loss is 3.880193552970886 and perplexity is 48.43358862914578
At time: 344.45974016189575 and batch: 1350, loss is 3.7803783130645754 and perplexity is 43.832621052488875
At time: 345.1689636707306 and batch: 1400, loss is 3.800862135887146 and perplexity is 44.73973960613554
At time: 345.8751299381256 and batch: 1450, loss is 3.7331505489349364 and perplexity is 41.81062730381969
At time: 346.5853796005249 and batch: 1500, loss is 3.7293935346603395 and perplexity is 41.653838892782936
At time: 347.2922406196594 and batch: 1550, loss is 3.7470164489746094 and perplexity is 42.39440724652326
At time: 348.00580739974976 and batch: 1600, loss is 3.8195356225967405 and perplexity is 45.58303567344099
At time: 348.70993065834045 and batch: 1650, loss is 3.775636315345764 and perplexity is 43.625258907429206
At time: 349.41170477867126 and batch: 1700, loss is 3.7715950441360473 and perplexity is 43.44931316627948
At time: 350.1260025501251 and batch: 1750, loss is 3.774462175369263 and perplexity is 43.574066806188185
At time: 350.8307111263275 and batch: 1800, loss is 3.7337338447570803 and perplexity is 41.83502238212918
At time: 351.53941440582275 and batch: 1850, loss is 3.772266707420349 and perplexity is 43.4785062775344
At time: 352.2479569911957 and batch: 1900, loss is 3.870971817970276 and perplexity is 47.988999999603834
At time: 352.95704650878906 and batch: 1950, loss is 3.789381675720215 and perplexity is 44.229043927575646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368167752997819 and perplexity of 78.89893684118164
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 355.6210095882416 and batch: 50, loss is 3.9560878229141236 and perplexity is 52.25250451063858
At time: 356.38192224502563 and batch: 100, loss is 3.963443570137024 and perplexity is 52.63827781160729
At time: 357.0865993499756 and batch: 150, loss is 3.9288138151168823 and perplexity is 50.846628381627454
At time: 357.79301261901855 and batch: 200, loss is 3.9326867389678957 and perplexity is 51.04393533220165
At time: 358.51037859916687 and batch: 250, loss is 3.9423750591278077 and perplexity is 51.540868657511076
At time: 359.22467398643494 and batch: 300, loss is 3.943587551116943 and perplexity is 51.603399449252684
At time: 359.92804884910583 and batch: 350, loss is 3.9625854110717773 and perplexity is 52.59312517316828
At time: 360.6344029903412 and batch: 400, loss is 3.90302574634552 and perplexity is 49.55215475681994
At time: 361.3416655063629 and batch: 450, loss is 3.944245195388794 and perplexity is 51.637347290886794
At time: 362.0509705543518 and batch: 500, loss is 3.964747357368469 and perplexity is 52.70695168443457
At time: 362.7565977573395 and batch: 550, loss is 3.931467709541321 and perplexity is 50.98174918405666
At time: 363.4626727104187 and batch: 600, loss is 3.8940161180496218 and perplexity is 49.107713393339694
At time: 364.1716299057007 and batch: 650, loss is 3.9295641136169435 and perplexity is 50.88479284621524
At time: 364.87541580200195 and batch: 700, loss is 3.9631096744537353 and perplexity is 52.62070505176782
At time: 365.5830616950989 and batch: 750, loss is 3.907015337944031 and perplexity is 49.750242498977606
At time: 366.29652881622314 and batch: 800, loss is 3.9063582038879394 and perplexity is 49.7175606596836
At time: 367.00318574905396 and batch: 850, loss is 3.91940456867218 and perplexity is 50.37044370698374
At time: 367.7107319831848 and batch: 900, loss is 3.8713287258148195 and perplexity is 48.00613070701557
At time: 368.4222056865692 and batch: 950, loss is 3.964592900276184 and perplexity is 52.69881135061651
At time: 369.13011932373047 and batch: 1000, loss is 3.9096255826950075 and perplexity is 49.88027243947663
At time: 369.83433961868286 and batch: 1050, loss is 3.865568470954895 and perplexity is 47.73039806685723
At time: 370.54045581817627 and batch: 1100, loss is 3.8714372158050536 and perplexity is 48.01133917419533
At time: 371.24715399742126 and batch: 1150, loss is 3.8571761226654053 and perplexity is 47.331504112006556
At time: 371.95143818855286 and batch: 1200, loss is 3.893763990402222 and perplexity is 49.095333541809644
At time: 372.65342831611633 and batch: 1250, loss is 3.8897592926025393 and perplexity is 48.89911472836521
At time: 373.36229372024536 and batch: 1300, loss is 3.8774539756774904 and perplexity is 48.301082657549784
At time: 374.06823110580444 and batch: 1350, loss is 3.7778158140182496 and perplexity is 43.72044379128974
At time: 374.7773869037628 and batch: 1400, loss is 3.80171350479126 and perplexity is 44.77784584814739
At time: 375.48708319664 and batch: 1450, loss is 3.7336914777755736 and perplexity is 41.83324999605518
At time: 376.194123506546 and batch: 1500, loss is 3.7310408973693847 and perplexity is 41.7225144248878
At time: 376.89821100234985 and batch: 1550, loss is 3.7544843339920044 and perplexity is 42.71218890680017
At time: 377.6021773815155 and batch: 1600, loss is 3.829520373344421 and perplexity is 46.04045071035975
At time: 378.3076169490814 and batch: 1650, loss is 3.7792991161346436 and perplexity is 43.78534253842042
At time: 379.0159447193146 and batch: 1700, loss is 3.763849334716797 and perplexity is 43.114067446109296
At time: 379.7200963497162 and batch: 1750, loss is 3.7706623792648317 and perplexity is 43.408808409828715
At time: 380.42426013946533 and batch: 1800, loss is 3.729113121032715 and perplexity is 41.64216022621967
At time: 381.13380885124207 and batch: 1850, loss is 3.759730887413025 and perplexity is 42.93686957179841
At time: 381.84604811668396 and batch: 1900, loss is 3.8594337368011473 and perplexity is 47.43848109569416
At time: 382.5534975528717 and batch: 1950, loss is 3.7841780233383178 and perplexity is 43.9994891374482
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349248557867006 and perplexity of 77.42026421304001
finished 13 epochs...
Completing Train Step...
At time: 385.20367312431335 and batch: 50, loss is 3.956930327415466 and perplexity is 52.29654603087963
At time: 385.940922498703 and batch: 100, loss is 3.950495104789734 and perplexity is 51.96108665018444
At time: 386.6457781791687 and batch: 150, loss is 3.9092877769470213 and perplexity is 49.86342544240188
At time: 387.35068702697754 and batch: 200, loss is 3.9065227127075195 and perplexity is 49.72574030969396
At time: 388.0525276660919 and batch: 250, loss is 3.916138596534729 and perplexity is 50.20620358910003
At time: 388.760000705719 and batch: 300, loss is 3.9160349988937377 and perplexity is 50.201002614254094
At time: 389.4777548313141 and batch: 350, loss is 3.9361373949050904 and perplexity is 51.22037463129874
At time: 390.18528175354004 and batch: 400, loss is 3.876161847114563 and perplexity is 48.23871175331893
At time: 390.894779920578 and batch: 450, loss is 3.919705657958984 and perplexity is 50.38561199134485
At time: 391.60023283958435 and batch: 500, loss is 3.9408501529693605 and perplexity is 51.46233356402576
At time: 392.3566665649414 and batch: 550, loss is 3.909835448265076 and perplexity is 49.89074168981647
At time: 393.0621712207794 and batch: 600, loss is 3.8762327814102173 and perplexity is 48.242133653724025
At time: 393.77213430404663 and batch: 650, loss is 3.9133448600769043 and perplexity is 50.066136434184386
At time: 394.4776248931885 and batch: 700, loss is 3.949735474586487 and perplexity is 51.92163042733804
At time: 395.18904161453247 and batch: 750, loss is 3.8942728281021117 and perplexity is 49.12032145526144
At time: 395.89342522621155 and batch: 800, loss is 3.893145818710327 and perplexity is 49.064993575030435
At time: 396.6067204475403 and batch: 850, loss is 3.9066973114013672 and perplexity is 49.73442311698399
At time: 397.32183837890625 and batch: 900, loss is 3.8591190814971923 and perplexity is 47.42355667415316
At time: 398.0263090133667 and batch: 950, loss is 3.9528181982040405 and perplexity is 52.081937427854314
At time: 398.7282874584198 and batch: 1000, loss is 3.898557481765747 and perplexity is 49.33123654693444
At time: 399.43373584747314 and batch: 1050, loss is 3.8557007455825807 and perplexity is 47.261723784349996
At time: 400.1422984600067 and batch: 1100, loss is 3.8625137996673584 and perplexity is 47.58481985033813
At time: 400.8538165092468 and batch: 1150, loss is 3.8495852279663088 and perplexity is 46.97357586486008
At time: 401.55871844291687 and batch: 1200, loss is 3.8877556848526003 and perplexity is 48.80123816899008
At time: 402.2603795528412 and batch: 1250, loss is 3.8852276182174683 and perplexity is 48.678021202996774
At time: 402.9680178165436 and batch: 1300, loss is 3.8740491580963137 and perplexity is 48.13690593662579
At time: 403.6732351779938 and batch: 1350, loss is 3.7751165771484376 and perplexity is 43.602591085183555
At time: 404.38591408729553 and batch: 1400, loss is 3.8000290536880494 and perplexity is 44.702483246437225
At time: 405.0925123691559 and batch: 1450, loss is 3.732398719787598 and perplexity is 41.77920466925058
At time: 405.7975115776062 and batch: 1500, loss is 3.7312228965759275 and perplexity is 41.73010858045228
At time: 406.5019006729126 and batch: 1550, loss is 3.7551189136505125 and perplexity is 42.73930179478454
At time: 407.20530700683594 and batch: 1600, loss is 3.831145749092102 and perplexity is 46.11534459121728
At time: 407.91144132614136 and batch: 1650, loss is 3.7815010786056518 and perplexity is 43.88186244707937
At time: 408.62023758888245 and batch: 1700, loss is 3.7673426389694216 and perplexity is 43.264941372102
At time: 409.3250889778137 and batch: 1750, loss is 3.775102291107178 and perplexity is 43.60196818121771
At time: 410.0286922454834 and batch: 1800, loss is 3.733777813911438 and perplexity is 41.836861873126004
At time: 410.73324751853943 and batch: 1850, loss is 3.764726161956787 and perplexity is 43.15188761332614
At time: 411.4402582645416 and batch: 1900, loss is 3.8647256755828856 and perplexity is 47.690188055048345
At time: 412.1435492038727 and batch: 1950, loss is 3.7886532974243163 and perplexity is 44.19684018160902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347671295875727 and perplexity of 77.29824842367087
finished 14 epochs...
Completing Train Step...
At time: 414.7976758480072 and batch: 50, loss is 3.9529768323898313 and perplexity is 52.09020005894314
At time: 415.49925422668457 and batch: 100, loss is 3.944499282836914 and perplexity is 51.6504693596935
At time: 416.20894861221313 and batch: 150, loss is 3.902012519836426 and perplexity is 49.501972627262774
At time: 416.9155864715576 and batch: 200, loss is 3.898100037574768 and perplexity is 49.30867541996389
At time: 417.624076128006 and batch: 250, loss is 3.9075572729110717 and perplexity is 49.77721120198811
At time: 418.32874512672424 and batch: 300, loss is 3.90697407245636 and perplexity is 49.74818957331692
At time: 419.03796768188477 and batch: 350, loss is 3.9274584579467775 and perplexity is 50.7777597206341
At time: 419.7406589984894 and batch: 400, loss is 3.867288179397583 and perplexity is 47.81255105473248
At time: 420.4407398700714 and batch: 450, loss is 3.9110325622558593 and perplexity is 49.950502357732915
At time: 421.1458349227905 and batch: 500, loss is 3.9322829627990723 and perplexity is 51.02332916797053
At time: 421.85175037384033 and batch: 550, loss is 3.901562385559082 and perplexity is 49.47969510690103
At time: 422.5565273761749 and batch: 600, loss is 3.8690225172042845 and perplexity is 47.89554611959735
At time: 423.2637429237366 and batch: 650, loss is 3.906225380897522 and perplexity is 49.710957463138385
At time: 423.969446182251 and batch: 700, loss is 3.943415699005127 and perplexity is 51.59453205804222
At time: 424.6774251461029 and batch: 750, loss is 3.888414945602417 and perplexity is 48.83342151730088
At time: 425.3826525211334 and batch: 800, loss is 3.8869831371307373 and perplexity is 48.76355144289011
At time: 426.08919858932495 and batch: 850, loss is 3.9007892322540285 and perplexity is 49.44145450192605
At time: 426.79485273361206 and batch: 900, loss is 3.8534826946258547 and perplexity is 47.157011044719795
At time: 427.5013384819031 and batch: 950, loss is 3.9474128341674803 and perplexity is 51.80117509125419
At time: 428.2582414150238 and batch: 1000, loss is 3.8934876489639283 and perplexity is 49.081768341125056
At time: 428.9627332687378 and batch: 1050, loss is 3.8512784099578856 and perplexity is 47.05317804906943
At time: 429.66660594940186 and batch: 1100, loss is 3.858596796989441 and perplexity is 47.39879455219901
At time: 430.36792945861816 and batch: 1150, loss is 3.8461023569107056 and perplexity is 46.810257530544796
At time: 431.07282853126526 and batch: 1200, loss is 3.884747290611267 and perplexity is 48.65464542006408
At time: 431.78157353401184 and batch: 1250, loss is 3.8827650022506712 and perplexity is 48.55829341304099
At time: 432.48865604400635 and batch: 1300, loss is 3.872088918685913 and perplexity is 48.0426385000717
At time: 433.19117522239685 and batch: 1350, loss is 3.7731772327423094 and perplexity is 43.518112586998626
At time: 433.89667797088623 and batch: 1400, loss is 3.7984033584594727 and perplexity is 44.62986967248076
At time: 434.6005735397339 and batch: 1450, loss is 3.7310999059677123 and perplexity is 41.72497648462335
At time: 435.30495858192444 and batch: 1500, loss is 3.7303838205337523 and perplexity is 41.69510853200959
At time: 436.0125231742859 and batch: 1550, loss is 3.7544344234466553 and perplexity is 42.71005717135726
At time: 436.71382331848145 and batch: 1600, loss is 3.8309849643707277 and perplexity is 46.107930544434794
At time: 437.4152946472168 and batch: 1650, loss is 3.781423683166504 and perplexity is 43.87846632248863
At time: 438.11717462539673 and batch: 1700, loss is 3.767822599411011 and perplexity is 43.28571181656541
At time: 438.8269999027252 and batch: 1750, loss is 3.7758347320556642 and perplexity is 43.63391574657252
At time: 439.5336129665375 and batch: 1800, loss is 3.734663653373718 and perplexity is 41.87393903613367
At time: 440.2457871437073 and batch: 1850, loss is 3.765677070617676 and perplexity is 43.192940632733766
At time: 440.95049500465393 and batch: 1900, loss is 3.865612816810608 and perplexity is 47.73251475913594
At time: 441.66240096092224 and batch: 1950, loss is 3.7892977952957154 and perplexity is 44.22533413218757
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347298271711483 and perplexity of 77.26941968639723
finished 15 epochs...
Completing Train Step...
At time: 444.27320981025696 and batch: 50, loss is 3.948817400932312 and perplexity is 51.873984420979035
At time: 445.0072829723358 and batch: 100, loss is 3.939519371986389 and perplexity is 51.3938940183028
At time: 445.7138316631317 and batch: 150, loss is 3.8965641021728517 and perplexity is 49.23299861198642
At time: 446.4493188858032 and batch: 200, loss is 3.8922436904907225 and perplexity is 49.02075061914173
At time: 447.1567430496216 and batch: 250, loss is 3.901621770858765 and perplexity is 49.482633560672774
At time: 447.8619177341461 and batch: 300, loss is 3.9009692430496217 and perplexity is 49.45035529858194
At time: 448.5707404613495 and batch: 350, loss is 3.9215242767333987 and perplexity is 50.47732758384374
At time: 449.27657413482666 and batch: 400, loss is 3.861300573348999 and perplexity is 47.52712370086181
At time: 449.98090529441833 and batch: 450, loss is 3.9051194620132446 and perplexity is 49.656011564977746
At time: 450.68548226356506 and batch: 500, loss is 3.9264216470718383 and perplexity is 50.72514007017735
At time: 451.3936049938202 and batch: 550, loss is 3.8959414196014404 and perplexity is 49.20235162447515
At time: 452.0992352962494 and batch: 600, loss is 3.8639331007003785 and perplexity is 47.65240498478798
At time: 452.80713629722595 and batch: 650, loss is 3.901195278167725 and perplexity is 49.461534078832955
At time: 453.51379656791687 and batch: 700, loss is 3.9387897062301636 and perplexity is 51.35640733179749
At time: 454.2208046913147 and batch: 750, loss is 3.884149742126465 and perplexity is 48.62558059510064
At time: 454.9274854660034 and batch: 800, loss is 3.882573866844177 and perplexity is 48.549013090818164
At time: 455.62877559661865 and batch: 850, loss is 3.8965184116363525 and perplexity is 49.23074918125561
At time: 456.33860087394714 and batch: 900, loss is 3.849339680671692 and perplexity is 46.96204304637212
At time: 457.04269766807556 and batch: 950, loss is 3.943471417427063 and perplexity is 51.597406904039204
At time: 457.74879121780396 and batch: 1000, loss is 3.889779167175293 and perplexity is 48.90008658703608
At time: 458.4622769355774 and batch: 1050, loss is 3.8479808616638183 and perplexity is 46.89827346510366
At time: 459.16909074783325 and batch: 1100, loss is 3.8556371450424196 and perplexity is 47.258718008773855
At time: 459.88160705566406 and batch: 1150, loss is 3.843274168968201 and perplexity is 46.6780563576122
At time: 460.5858209133148 and batch: 1200, loss is 3.882193446159363 and perplexity is 48.530547554569765
At time: 461.2913453578949 and batch: 1250, loss is 3.8806439065933227 and perplexity is 48.45540578358104
At time: 461.99738812446594 and batch: 1300, loss is 3.8701571893692015 and perplexity is 47.949922706568515
At time: 462.7024734020233 and batch: 1350, loss is 3.7712052488327026 and perplexity is 43.432380128497414
At time: 463.4075267314911 and batch: 1400, loss is 3.7966408586502074 and perplexity is 44.55127881422641
At time: 464.11673951148987 and batch: 1450, loss is 3.7295699739456176 and perplexity is 41.66118891474351
At time: 464.83320903778076 and batch: 1500, loss is 3.7290263605117797 and perplexity is 41.6385474874294
At time: 465.5371341705322 and batch: 1550, loss is 3.7530713844299317 and perplexity is 42.65188135398761
At time: 466.2412827014923 and batch: 1600, loss is 3.8300397205352783 and perplexity is 46.06436789922681
At time: 466.94884181022644 and batch: 1650, loss is 3.780456442832947 and perplexity is 43.836045818805175
At time: 467.6523222923279 and batch: 1700, loss is 3.7672240257263185 and perplexity is 43.259809881430584
At time: 468.36215472221375 and batch: 1750, loss is 3.7753755140304563 and perplexity is 43.613882866033265
At time: 469.0735926628113 and batch: 1800, loss is 3.734390525817871 and perplexity is 41.86250367123876
At time: 469.77562141418457 and batch: 1850, loss is 3.7654589223861694 and perplexity is 43.18351919679333
At time: 470.4756622314453 and batch: 1900, loss is 3.8653194189071653 and perplexity is 47.718512193641686
At time: 471.1800158023834 and batch: 1950, loss is 3.7889530849456787 and perplexity is 44.210091829019134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3472375204396805 and perplexity of 77.26472561346674
finished 16 epochs...
Completing Train Step...
At time: 473.8279299736023 and batch: 50, loss is 3.94492196559906 and perplexity is 51.67230573735371
At time: 474.56314516067505 and batch: 100, loss is 3.9352134895324706 and perplexity is 51.1730737061434
At time: 475.2718858718872 and batch: 150, loss is 3.8919954776763914 and perplexity is 49.008584550619446
At time: 475.98285365104675 and batch: 200, loss is 3.8874814224243166 and perplexity is 48.78785565815045
At time: 476.6866247653961 and batch: 250, loss is 3.8967108058929445 and perplexity is 49.240221805855874
At time: 477.3913059234619 and batch: 300, loss is 3.8960780096054077 and perplexity is 49.209072632879575
At time: 478.09365224838257 and batch: 350, loss is 3.9166902351379393 and perplexity is 50.23390690952839
At time: 478.7999618053436 and batch: 400, loss is 3.8563984537124636 and perplexity is 47.29471017936647
At time: 479.50422406196594 and batch: 450, loss is 3.9002825927734377 and perplexity is 49.416411853430425
At time: 480.21057176589966 and batch: 500, loss is 3.921643772125244 and perplexity is 50.483359752283675
At time: 480.91744804382324 and batch: 550, loss is 3.891388726234436 and perplexity is 48.978857540640256
At time: 481.6208851337433 and batch: 600, loss is 3.859719262123108 and perplexity is 47.45202791717057
At time: 482.378701210022 and batch: 650, loss is 3.897020516395569 and perplexity is 49.255474381520216
At time: 483.0818557739258 and batch: 700, loss is 3.9348634767532347 and perplexity is 51.15516561060744
At time: 483.7871072292328 and batch: 750, loss is 3.8805483627319335 and perplexity is 48.45077638816598
At time: 484.49078392982483 and batch: 800, loss is 3.8788928842544554 and perplexity is 48.370633526333066
At time: 485.1954016685486 and batch: 850, loss is 3.892985773086548 and perplexity is 49.05714156588461
At time: 485.898234128952 and batch: 900, loss is 3.8458381366729735 and perplexity is 46.79789094699454
At time: 486.60763239860535 and batch: 950, loss is 3.940136351585388 and perplexity is 51.42561278633543
At time: 487.31204867362976 and batch: 1000, loss is 3.8866207790374756 and perplexity is 48.7458847763917
At time: 488.0156421661377 and batch: 1050, loss is 3.845126986503601 and perplexity is 46.76462244977212
At time: 488.7195816040039 and batch: 1100, loss is 3.853034563064575 and perplexity is 47.135883234108
At time: 489.42599296569824 and batch: 1150, loss is 3.8406891059875488 and perplexity is 46.557546472044784
At time: 490.1379120349884 and batch: 1200, loss is 3.8797831106185914 and perplexity is 48.413713512172656
At time: 490.8402376174927 and batch: 1250, loss is 3.8785617971420288 and perplexity is 48.35462128382242
At time: 491.5525312423706 and batch: 1300, loss is 3.8682463645935057 and perplexity is 47.85838628914712
At time: 492.2672498226166 and batch: 1350, loss is 3.769201455116272 and perplexity is 43.345437734508536
At time: 492.97428917884827 and batch: 1400, loss is 3.7948246574401856 and perplexity is 44.470438161403386
At time: 493.68292117118835 and batch: 1450, loss is 3.7278944635391236 and perplexity is 41.591443604982636
At time: 494.3971357345581 and batch: 1500, loss is 3.727452621459961 and perplexity is 41.57307081429975
At time: 495.1156826019287 and batch: 1550, loss is 3.7514238357543945 and perplexity is 42.58166815906415
At time: 495.820440530777 and batch: 1600, loss is 3.828774871826172 and perplexity is 46.006140275284075
At time: 496.5242385864258 and batch: 1650, loss is 3.7791361141204836 and perplexity is 43.77820602104513
At time: 497.2294442653656 and batch: 1700, loss is 3.7661543226242067 and perplexity is 43.2135594701181
At time: 497.93704867362976 and batch: 1750, loss is 3.7744356060028075 and perplexity is 43.57290908621927
At time: 498.64419531822205 and batch: 1800, loss is 3.7336258697509765 and perplexity is 41.830505489192284
At time: 499.35017585754395 and batch: 1850, loss is 3.7647346687316894 and perplexity is 43.15225469828203
At time: 500.05781650543213 and batch: 1900, loss is 3.8645514678955077 and perplexity is 47.681880781293145
At time: 500.7607960700989 and batch: 1950, loss is 3.7882154893875124 and perplexity is 44.177494684892146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347328079578489 and perplexity of 77.27172295731049
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 503.46602034568787 and batch: 50, loss is 3.9455335521698 and perplexity is 51.7039174912986
At time: 504.1734974384308 and batch: 100, loss is 3.9431898975372315 and perplexity is 51.58288325217635
At time: 504.87786507606506 and batch: 150, loss is 3.9056398725509642 and perplexity is 49.68185980192136
At time: 505.5799036026001 and batch: 200, loss is 3.90352276802063 and perplexity is 49.576789373244516
At time: 506.2907712459564 and batch: 250, loss is 3.9153668212890627 and perplexity is 50.16747063248221
At time: 506.99549436569214 and batch: 300, loss is 3.913337049484253 and perplexity is 50.06574538951422
At time: 507.70649552345276 and batch: 350, loss is 3.9360168409347533 and perplexity is 51.214200183959335
At time: 508.4117910861969 and batch: 400, loss is 3.8781895589828492 and perplexity is 48.336625198230585
At time: 509.1176040172577 and batch: 450, loss is 3.925399885177612 and perplexity is 50.67333752441482
At time: 509.824271440506 and batch: 500, loss is 3.948052430152893 and perplexity is 51.83431751263221
At time: 510.530814409256 and batch: 550, loss is 3.918385467529297 and perplexity is 50.31913727789511
At time: 511.2332684993744 and batch: 600, loss is 3.883140273094177 and perplexity is 48.57651934438573
At time: 511.9398739337921 and batch: 650, loss is 3.91542272567749 and perplexity is 50.170275292642536
At time: 512.6442058086395 and batch: 700, loss is 3.947296380996704 and perplexity is 51.79514303139794
At time: 513.3467419147491 and batch: 750, loss is 3.8924395132064817 and perplexity is 49.03035093560587
At time: 514.0500309467316 and batch: 800, loss is 3.8912108278274538 and perplexity is 48.9701450548996
At time: 514.7533395290375 and batch: 850, loss is 3.907169828414917 and perplexity is 49.75792903110066
At time: 515.4576940536499 and batch: 900, loss is 3.854576573371887 and perplexity is 47.20862332046729
At time: 516.1648786067963 and batch: 950, loss is 3.9509299898147585 and perplexity is 51.98368866293484
At time: 516.8694570064545 and batch: 1000, loss is 3.8977070951461794 and perplexity is 49.28930375551757
At time: 517.5742990970612 and batch: 1050, loss is 3.858173441886902 and perplexity is 47.378732277703925
At time: 518.3297009468079 and batch: 1100, loss is 3.8618660020828246 and perplexity is 47.55400450111061
At time: 519.0366151332855 and batch: 1150, loss is 3.8511789989471437 and perplexity is 47.048500677575916
At time: 519.7440640926361 and batch: 1200, loss is 3.8913482999801636 and perplexity is 48.97687754891343
At time: 520.4517288208008 and batch: 1250, loss is 3.888362855911255 and perplexity is 48.830877865705254
At time: 521.159360408783 and batch: 1300, loss is 3.869788579940796 and perplexity is 47.93225117011513
At time: 521.864926815033 and batch: 1350, loss is 3.7665549516677856 and perplexity is 43.23087554554802
At time: 522.5693566799164 and batch: 1400, loss is 3.7915348482131956 and perplexity is 44.32437928825701
At time: 523.2775001525879 and batch: 1450, loss is 3.7192017889022826 and perplexity is 41.23146955341352
At time: 523.9933233261108 and batch: 1500, loss is 3.7170401763916017 and perplexity is 41.14243935205828
At time: 524.7026357650757 and batch: 1550, loss is 3.7446101617813112 and perplexity is 42.29251676534248
At time: 525.4135315418243 and batch: 1600, loss is 3.8231784772872923 and perplexity is 45.74939086868874
At time: 526.1235861778259 and batch: 1650, loss is 3.773585247993469 and perplexity is 43.53587226349885
At time: 526.8319427967072 and batch: 1700, loss is 3.7596128940582276 and perplexity is 42.931803605394194
At time: 527.5477404594421 and batch: 1750, loss is 3.768383469581604 and perplexity is 43.309996290718175
At time: 528.2531502246857 and batch: 1800, loss is 3.7276491260528566 and perplexity is 41.58124091636054
At time: 528.9630551338196 and batch: 1850, loss is 3.7584666204452515 and perplexity is 42.88262020596569
At time: 529.6730298995972 and batch: 1900, loss is 3.8579266023635865 and perplexity is 47.36703877728161
At time: 530.3783483505249 and batch: 1950, loss is 3.7861845779418943 and perplexity is 44.08786515092824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340739689316861 and perplexity of 76.76430007573434
finished 18 epochs...
Completing Train Step...
At time: 533.0254769325256 and batch: 50, loss is 3.946723213195801 and perplexity is 51.76546422944851
At time: 533.758305311203 and batch: 100, loss is 3.9377170419692993 and perplexity is 51.30134868408735
At time: 534.4611279964447 and batch: 150, loss is 3.8984561443328856 and perplexity is 49.32623769935236
At time: 535.1673197746277 and batch: 200, loss is 3.893187851905823 and perplexity is 49.067055976841736
At time: 535.8715200424194 and batch: 250, loss is 3.903412046432495 and perplexity is 49.57130045626689
At time: 536.6054780483246 and batch: 300, loss is 3.9010905408859253 and perplexity is 49.45635388348443
At time: 537.3151693344116 and batch: 350, loss is 3.9230263900756834 and perplexity is 50.55320722673476
At time: 538.0241107940674 and batch: 400, loss is 3.863698525428772 and perplexity is 47.64122821989354
At time: 538.7310130596161 and batch: 450, loss is 3.9119006204605102 and perplexity is 49.993881126054944
At time: 539.4378731250763 and batch: 500, loss is 3.936283130645752 and perplexity is 51.22783981449138
At time: 540.141375541687 and batch: 550, loss is 3.907068452835083 and perplexity is 49.752885047866485
At time: 540.8458268642426 and batch: 600, loss is 3.8735411405563354 and perplexity is 48.11245775466813
At time: 541.5502753257751 and batch: 650, loss is 3.9063374996185303 and perplexity is 49.71653130456939
At time: 542.2593748569489 and batch: 700, loss is 3.9396693181991576 and perplexity is 51.401600915865885
At time: 542.9654068946838 and batch: 750, loss is 3.8857918405532836 and perplexity is 48.70549417952746
At time: 543.6703205108643 and batch: 800, loss is 3.8854162073135377 and perplexity is 48.68720221270584
At time: 544.3762369155884 and batch: 850, loss is 3.9014609622955323 and perplexity is 49.47467696922609
At time: 545.0828678607941 and batch: 900, loss is 3.8499032640457154 and perplexity is 46.98851753263262
At time: 545.789799451828 and batch: 950, loss is 3.9452673959732056 and perplexity is 51.69015800443766
At time: 546.4933097362518 and batch: 1000, loss is 3.8919925022125246 and perplexity is 49.0084387275639
At time: 547.1969068050385 and batch: 1050, loss is 3.852250757217407 and perplexity is 47.0989523284383
At time: 547.9003398418427 and batch: 1100, loss is 3.8566089200973512 and perplexity is 47.3046651736013
At time: 548.6045689582825 and batch: 1150, loss is 3.846033091545105 and perplexity is 46.80701531323107
At time: 549.3142144680023 and batch: 1200, loss is 3.886223545074463 and perplexity is 48.72652510081632
At time: 550.0193247795105 and batch: 1250, loss is 3.8842071199417116 and perplexity is 48.62837070472471
At time: 550.7267277240753 and batch: 1300, loss is 3.8673843431472776 and perplexity is 47.81714911000395
At time: 551.4365930557251 and batch: 1350, loss is 3.7651357889175414 and perplexity is 43.16956741071362
At time: 552.1413021087646 and batch: 1400, loss is 3.790950713157654 and perplexity is 44.298495425071536
At time: 552.8508467674255 and batch: 1450, loss is 3.7203653287887573 and perplexity is 41.279471933743395
At time: 553.5555281639099 and batch: 1500, loss is 3.7194685316085816 and perplexity is 41.242469214161304
At time: 554.2595906257629 and batch: 1550, loss is 3.747287836074829 and perplexity is 42.405914103107015
At time: 554.9687850475311 and batch: 1600, loss is 3.8266009950637816 and perplexity is 45.90623722381639
At time: 555.677768945694 and batch: 1650, loss is 3.776783266067505 and perplexity is 43.6753236350186
At time: 556.3819794654846 and batch: 1700, loss is 3.7635442447662353 and perplexity is 43.100915783725675
At time: 557.0940382480621 and batch: 1750, loss is 3.773363070487976 and perplexity is 43.52620064644755
At time: 557.8007352352142 and batch: 1800, loss is 3.732528715133667 and perplexity is 41.78463612444435
At time: 558.5083405971527 and batch: 1850, loss is 3.7632035541534425 and perplexity is 43.086234207395016
At time: 559.2163820266724 and batch: 1900, loss is 3.862819986343384 and perplexity is 47.599391918930145
At time: 559.9214999675751 and batch: 1950, loss is 3.790329942703247 and perplexity is 44.27100476151563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.339519837845203 and perplexity of 76.67071612218264
finished 19 epochs...
Completing Train Step...
At time: 562.5415983200073 and batch: 50, loss is 3.9465484857559203 and perplexity is 51.756420172554925
At time: 563.2928040027618 and batch: 100, loss is 3.9356958055496216 and perplexity is 51.19776125235962
At time: 563.9988009929657 and batch: 150, loss is 3.8957992601394653 and perplexity is 49.195357541789605
At time: 564.7046809196472 and batch: 200, loss is 3.889634957313538 and perplexity is 48.89303522076004
At time: 565.4148073196411 and batch: 250, loss is 3.89909113407135 and perplexity is 49.3575693006984
At time: 566.1278350353241 and batch: 300, loss is 3.896557502746582 and perplexity is 49.23267370351416
At time: 566.8327054977417 and batch: 350, loss is 3.9187019443511963 and perplexity is 50.33506463872887
At time: 567.5392971038818 and batch: 400, loss is 3.8589684629440306 and perplexity is 47.4164143445583
At time: 568.246339559555 and batch: 450, loss is 3.9071003293991087 and perplexity is 49.75447102416978
At time: 568.9541506767273 and batch: 500, loss is 3.931781363487244 and perplexity is 50.9977423188821
At time: 569.6596031188965 and batch: 550, loss is 3.902645425796509 and perplexity is 49.533312637367864
At time: 570.3670601844788 and batch: 600, loss is 3.869666266441345 and perplexity is 47.92638876727076
At time: 571.074018239975 and batch: 650, loss is 3.902603464126587 and perplexity is 49.531234180460906
At time: 571.7890613079071 and batch: 700, loss is 3.936482534408569 and perplexity is 51.2380558570362
At time: 572.5661008358002 and batch: 750, loss is 3.882899422645569 and perplexity is 48.56482107673286
At time: 573.2719349861145 and batch: 800, loss is 3.882716112136841 and perplexity is 48.555919450580745
At time: 573.9808988571167 and batch: 850, loss is 3.898623046875 and perplexity is 49.3344710608827
At time: 574.6870350837708 and batch: 900, loss is 3.847551884651184 and perplexity is 46.878159498378025
At time: 575.393105506897 and batch: 950, loss is 3.9428305578231813 and perplexity is 51.56435080358044
At time: 576.0962209701538 and batch: 1000, loss is 3.889570608139038 and perplexity is 48.889889095531174
At time: 576.8003132343292 and batch: 1050, loss is 3.849865264892578 and perplexity is 46.986732042682966
At time: 577.5026659965515 and batch: 1100, loss is 3.854539575576782 and perplexity is 47.20687673780454
At time: 578.2084045410156 and batch: 1150, loss is 3.8441114139556887 and perplexity is 46.71715369106265
At time: 578.912323474884 and batch: 1200, loss is 3.8845461893081663 and perplexity is 48.64486189124137
At time: 579.6208026409149 and batch: 1250, loss is 3.882960753440857 and perplexity is 48.56779968717187
At time: 580.3292405605316 and batch: 1300, loss is 3.8666978788375856 and perplexity is 47.784335607686394
At time: 581.0359597206116 and batch: 1350, loss is 3.764849934577942 and perplexity is 43.15722896611362
At time: 581.7431261539459 and batch: 1400, loss is 3.7909722566604613 and perplexity is 44.299449780112134
At time: 582.4454734325409 and batch: 1450, loss is 3.720958685874939 and perplexity is 41.30397266905275
At time: 583.1564230918884 and batch: 1500, loss is 3.7205598163604736 and perplexity is 41.28750105875873
At time: 583.8614304065704 and batch: 1550, loss is 3.748493094444275 and perplexity is 42.45705499879926
At time: 584.5657048225403 and batch: 1600, loss is 3.828138871192932 and perplexity is 45.976889643632184
At time: 585.2706353664398 and batch: 1650, loss is 3.7781287002563477 and perplexity is 43.73412545676638
At time: 585.9755964279175 and batch: 1700, loss is 3.7650648832321165 and perplexity is 43.16650655146431
At time: 586.6813013553619 and batch: 1750, loss is 3.7752788972854616 and perplexity is 43.609669238190946
At time: 587.3869225978851 and batch: 1800, loss is 3.7344326877593996 and perplexity is 41.86426871287932
At time: 588.0950582027435 and batch: 1850, loss is 3.7650107765197753 and perplexity is 43.16417101689618
At time: 588.8009080886841 and batch: 1900, loss is 3.864632511138916 and perplexity is 47.68574523215516
At time: 589.5069527626038 and batch: 1950, loss is 3.791727647781372 and perplexity is 44.3329258333021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.339003452034884 and perplexity of 76.6311346728391
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7420a98b38>
ELAPSED
1880.9812276363373


RESULTS SO FAR:
[{'best_accuracy': -76.72922266508544, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.44533850763699, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.7798990364997814, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3775751613796833, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.6311346728391, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.278968697079667, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.1071481079890072, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.20408011909539603, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.046635900383796614, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3029968738555908 and batch: 50, loss is 7.544452762603759 and perplexity is 1890.228050857045
At time: 2.007209300994873 and batch: 100, loss is 6.665846090316773 and perplexity is 785.1274727882359
At time: 2.757563591003418 and batch: 150, loss is 6.364414978027344 and perplexity is 580.8049452523858
At time: 3.4611964225769043 and batch: 200, loss is 6.142359857559204 and perplexity is 465.14996434375894
At time: 4.167112112045288 and batch: 250, loss is 6.014620971679688 and perplexity is 409.37064643881337
At time: 4.872839450836182 and batch: 300, loss is 5.898034772872925 and perplexity is 364.3207907783649
At time: 5.576657295227051 and batch: 350, loss is 5.813679456710815 and perplexity is 334.8489239126192
At time: 6.281052350997925 and batch: 400, loss is 5.727663450241089 and perplexity is 307.2505228769416
At time: 6.987198114395142 and batch: 450, loss is 5.635105361938477 and perplexity is 280.08842641535693
At time: 7.692884206771851 and batch: 500, loss is 5.600223646163941 and perplexity is 270.4868940183468
At time: 8.402013778686523 and batch: 550, loss is 5.543701868057251 and perplexity is 255.6225309965586
At time: 9.111846208572388 and batch: 600, loss is 5.540687580108642 and perplexity is 254.8531712004925
At time: 9.82058072090149 and batch: 650, loss is 5.587669849395752 and perplexity is 267.1124816822721
At time: 10.527607679367065 and batch: 700, loss is 5.522735233306885 and perplexity is 250.31878193239095
At time: 11.23961329460144 and batch: 750, loss is 5.443621311187744 and perplexity is 231.2781991405855
At time: 11.946760416030884 and batch: 800, loss is 5.443189363479615 and perplexity is 231.17832062522723
At time: 12.652493953704834 and batch: 850, loss is 5.450807313919068 and perplexity is 232.94615068593004
At time: 13.359216690063477 and batch: 900, loss is 5.450548505783081 and perplexity is 232.88587012777154
At time: 14.075008630752563 and batch: 950, loss is 5.45977445602417 and perplexity is 235.04440553670327
At time: 14.784109354019165 and batch: 1000, loss is 5.420517778396606 and perplexity is 225.99610811560729
At time: 15.490780115127563 and batch: 1050, loss is 5.318261585235596 and perplexity is 204.02888668884634
At time: 16.19594383239746 and batch: 1100, loss is 5.396523637771606 and perplexity is 220.6380636115374
At time: 16.894778966903687 and batch: 1150, loss is 5.292264757156372 and perplexity is 198.79313414982278
At time: 17.60051441192627 and batch: 1200, loss is 5.366746864318848 and perplexity is 214.1650253462216
At time: 18.307562589645386 and batch: 1250, loss is 5.331448383331299 and perplexity is 206.73719211586726
At time: 19.01180601119995 and batch: 1300, loss is 5.33131887435913 and perplexity is 206.7104195282899
At time: 19.720030546188354 and batch: 1350, loss is 5.270595836639404 and perplexity is 194.53183711686205
At time: 20.428784132003784 and batch: 1400, loss is 5.268259029388428 and perplexity is 194.0777844327632
At time: 21.135316610336304 and batch: 1450, loss is 5.2296632957458495 and perplexity is 186.72992017571704
At time: 21.853198528289795 and batch: 1500, loss is 5.19564037322998 and perplexity is 180.4836827175859
At time: 22.564728021621704 and batch: 1550, loss is 5.182397108078003 and perplexity is 178.1092467970777
At time: 23.270577907562256 and batch: 1600, loss is 5.2122499370574955 and perplexity is 183.50647207891978
At time: 23.98002052307129 and batch: 1650, loss is 5.1928643798828125 and perplexity is 179.9833559882245
At time: 24.687448978424072 and batch: 1700, loss is 5.211595821380615 and perplexity is 183.3864768683766
At time: 25.39039182662964 and batch: 1750, loss is 5.202243480682373 and perplexity is 181.67937917962024
At time: 26.10494112968445 and batch: 1800, loss is 5.174587240219116 and perplexity is 176.7236548030666
At time: 26.81429362297058 and batch: 1850, loss is 5.158904037475586 and perplexity is 173.97368244789342
At time: 27.520668506622314 and batch: 1900, loss is 5.230139560699463 and perplexity is 186.81887427366604
At time: 28.225958108901978 and batch: 1950, loss is 5.155252437591553 and perplexity is 173.33955865704917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.822946947674419 and perplexity of 124.33094823241711
finished 1 epochs...
Completing Train Step...
At time: 30.925836086273193 and batch: 50, loss is 5.079061994552612 and perplexity is 160.62331969510385
At time: 31.62542963027954 and batch: 100, loss is 5.024854946136474 and perplexity is 152.14818482990788
At time: 32.32953596115112 and batch: 150, loss is 4.956235380172729 and perplexity is 142.05799364439977
At time: 33.032265186309814 and batch: 200, loss is 4.928843297958374 and perplexity is 138.21954101293437
At time: 33.732492446899414 and batch: 250, loss is 4.9420844841003415 and perplexity is 140.06190229004645
At time: 34.439098834991455 and batch: 300, loss is 4.9553907775878905 and perplexity is 141.93806175029408
At time: 35.14324903488159 and batch: 350, loss is 4.944625005722046 and perplexity is 140.4181849614784
At time: 35.84554123878479 and batch: 400, loss is 4.888275241851806 and perplexity is 132.72445893198824
At time: 36.55067443847656 and batch: 450, loss is 4.862428045272827 and perplexity is 129.3378593442763
At time: 37.253418922424316 and batch: 500, loss is 4.857997093200684 and perplexity is 128.76603728204825
At time: 37.95608115196228 and batch: 550, loss is 4.830946226119995 and perplexity is 125.32949460736334
At time: 38.656001567840576 and batch: 600, loss is 4.799966669082641 and perplexity is 121.50636753254558
At time: 39.359959840774536 and batch: 650, loss is 4.8722543621063235 and perplexity is 130.61503883728628
At time: 40.133880376815796 and batch: 700, loss is 4.882431001663208 and perplexity is 131.95104751745373
At time: 40.83427119255066 and batch: 750, loss is 4.823488063812256 and perplexity is 124.3982439206877
At time: 41.53338885307312 and batch: 800, loss is 4.825426158905029 and perplexity is 124.6395733309124
At time: 42.232227087020874 and batch: 850, loss is 4.8262966537475585 and perplexity is 124.74811867389839
At time: 42.936763763427734 and batch: 900, loss is 4.796662425994873 and perplexity is 121.10554353215637
At time: 43.63953971862793 and batch: 950, loss is 4.851632814407349 and perplexity is 127.94913657092178
At time: 44.347338914871216 and batch: 1000, loss is 4.831237144470215 and perplexity is 125.36596056121886
At time: 45.04931664466858 and batch: 1050, loss is 4.751787652969361 and perplexity is 115.79109391326554
At time: 45.76017475128174 and batch: 1100, loss is 4.802010469436645 and perplexity is 121.75495623583016
At time: 46.46897101402283 and batch: 1150, loss is 4.744668464660645 and perplexity is 114.96968267116563
At time: 47.17119240760803 and batch: 1200, loss is 4.809260158538819 and perplexity is 122.64084915926566
At time: 47.902979612350464 and batch: 1250, loss is 4.798652038574219 and perplexity is 121.34673650571897
At time: 48.619850873947144 and batch: 1300, loss is 4.791992702484131 and perplexity is 120.54133250826477
At time: 49.32137942314148 and batch: 1350, loss is 4.686476430892944 and perplexity is 108.47030304833687
At time: 50.02351140975952 and batch: 1400, loss is 4.691471652984619 and perplexity is 109.01349184727768
At time: 50.72249984741211 and batch: 1450, loss is 4.649465160369873 and perplexity is 104.5290643378918
At time: 51.4230899810791 and batch: 1500, loss is 4.630487728118896 and perplexity is 102.5640752970821
At time: 52.12546730041504 and batch: 1550, loss is 4.635550527572632 and perplexity is 103.08465332058408
At time: 52.82853102684021 and batch: 1600, loss is 4.696158838272095 and perplexity is 109.5256576527373
At time: 53.53134107589722 and batch: 1650, loss is 4.668047370910645 and perplexity is 106.4896045909423
At time: 54.236024618148804 and batch: 1700, loss is 4.678624401092529 and perplexity is 107.62192609573937
At time: 54.94739007949829 and batch: 1750, loss is 4.668204116821289 and perplexity is 106.50629770924287
At time: 55.65550923347473 and batch: 1800, loss is 4.633337411880493 and perplexity is 102.85676731875813
At time: 56.360395193099976 and batch: 1850, loss is 4.662699127197266 and perplexity is 105.92159252007926
At time: 57.06360650062561 and batch: 1900, loss is 4.759621019363403 and perplexity is 116.70168983650767
At time: 57.765750885009766 and batch: 1950, loss is 4.6789837837219235 and perplexity is 107.66061049735477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.603363179051599 and perplexity of 99.81946247175907
finished 2 epochs...
Completing Train Step...
At time: 60.38145732879639 and batch: 50, loss is 4.67746280670166 and perplexity is 107.49698564916156
At time: 61.142577171325684 and batch: 100, loss is 4.6240147113800045 and perplexity is 101.90232040673912
At time: 61.84975004196167 and batch: 150, loss is 4.5711431980133055 and perplexity is 96.65454191821091
At time: 62.55686569213867 and batch: 200, loss is 4.563212003707886 and perplexity is 95.89098791586976
At time: 63.26438903808594 and batch: 250, loss is 4.571491985321045 and perplexity is 96.68825967548845
At time: 63.96623206138611 and batch: 300, loss is 4.5909319019317625 and perplexity is 98.58626009328155
At time: 64.66824555397034 and batch: 350, loss is 4.595853605270386 and perplexity is 99.07266841559499
At time: 65.37308955192566 and batch: 400, loss is 4.535080051422119 and perplexity is 93.23097827810572
At time: 66.07764530181885 and batch: 450, loss is 4.537817316055298 and perplexity is 93.48652572860233
At time: 66.77989792823792 and batch: 500, loss is 4.540257263183594 and perplexity is 93.71490641368418
At time: 67.48855257034302 and batch: 550, loss is 4.517338781356812 and perplexity is 91.5915282781704
At time: 68.18958497047424 and batch: 600, loss is 4.489551153182983 and perplexity is 89.08145297736274
At time: 68.89177584648132 and batch: 650, loss is 4.563150882720947 and perplexity is 95.88512714315978
At time: 69.59199357032776 and batch: 700, loss is 4.5815618705749515 and perplexity is 97.66681807218941
At time: 70.29776430130005 and batch: 750, loss is 4.5417154598236085 and perplexity is 93.85166085853974
At time: 71.00123047828674 and batch: 800, loss is 4.538560199737549 and perplexity is 93.5560011459582
At time: 71.70354223251343 and batch: 850, loss is 4.538873815536499 and perplexity is 93.58534638732937
At time: 72.40437531471252 and batch: 900, loss is 4.504427433013916 and perplexity is 90.41655968820344
At time: 73.10784983634949 and batch: 950, loss is 4.574676218032837 and perplexity is 96.99662829295849
At time: 73.80719017982483 and batch: 1000, loss is 4.562931880950928 and perplexity is 95.86413042983952
At time: 74.5089499950409 and batch: 1050, loss is 4.490803747177124 and perplexity is 89.19310578357026
At time: 75.211905002594 and batch: 1100, loss is 4.526931085586548 and perplexity is 92.47432936152788
At time: 75.96871519088745 and batch: 1150, loss is 4.486060590744018 and perplexity is 88.77105065809228
At time: 76.67008924484253 and batch: 1200, loss is 4.546683969497681 and perplexity is 94.31912407955834
At time: 77.37643551826477 and batch: 1250, loss is 4.549173631668091 and perplexity is 94.55423939212986
At time: 78.07848334312439 and batch: 1300, loss is 4.5349320125579835 and perplexity is 93.2171774915308
At time: 78.7805962562561 and batch: 1350, loss is 4.420599660873413 and perplexity is 83.14612989281403
At time: 79.48763632774353 and batch: 1400, loss is 4.437859754562378 and perplexity is 84.59369651543268
At time: 80.18895101547241 and batch: 1450, loss is 4.387799806594849 and perplexity is 80.46318950350587
At time: 80.90433502197266 and batch: 1500, loss is 4.37772689819336 and perplexity is 79.65675953215022
At time: 81.6172547340393 and batch: 1550, loss is 4.387580118179321 and perplexity is 80.44551461445081
At time: 82.32629537582397 and batch: 1600, loss is 4.459240865707398 and perplexity is 86.4218783767094
At time: 83.0280249118805 and batch: 1650, loss is 4.428233327865601 and perplexity is 83.78326851816341
At time: 83.72948813438416 and batch: 1700, loss is 4.4324258518218995 and perplexity is 84.13526924871007
At time: 84.43790435791016 and batch: 1750, loss is 4.425659837722779 and perplexity is 83.56793030672681
At time: 85.1427309513092 and batch: 1800, loss is 4.389315395355225 and perplexity is 80.58523106819237
At time: 85.8480122089386 and batch: 1850, loss is 4.431364135742188 and perplexity is 84.0459888840639
At time: 86.5529351234436 and batch: 1900, loss is 4.528403978347779 and perplexity is 92.61063448861981
At time: 87.25669360160828 and batch: 1950, loss is 4.451730880737305 and perplexity is 85.77528237114646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507826694222384 and perplexity of 90.72443216518387
finished 3 epochs...
Completing Train Step...
At time: 89.90262389183044 and batch: 50, loss is 4.450378494262695 and perplexity is 85.65935944337981
At time: 90.60448479652405 and batch: 100, loss is 4.408849992752075 and perplexity is 82.17490740540944
At time: 91.3097562789917 and batch: 150, loss is 4.3617864608764645 and perplexity is 78.39706268300183
At time: 92.01307463645935 and batch: 200, loss is 4.35448187828064 and perplexity is 77.82649129327775
At time: 92.71930503845215 and batch: 250, loss is 4.357382307052612 and perplexity is 78.0525491617436
At time: 93.421795129776 and batch: 300, loss is 4.381297559738159 and perplexity is 79.94169526198641
At time: 94.1272144317627 and batch: 350, loss is 4.387765836715698 and perplexity is 80.46045622510721
At time: 94.88823914527893 and batch: 400, loss is 4.329699583053589 and perplexity is 75.92147504517462
At time: 95.59427809715271 and batch: 450, loss is 4.34743408203125 and perplexity is 77.27991438362102
At time: 96.29675102233887 and batch: 500, loss is 4.349951257705689 and perplexity is 77.47468653925378
At time: 97.00493454933167 and batch: 550, loss is 4.324088907241821 and perplexity is 75.49669702175811
At time: 97.72369289398193 and batch: 600, loss is 4.306163101196289 and perplexity is 74.15541556595967
At time: 98.42815256118774 and batch: 650, loss is 4.373971309661865 and perplexity is 79.35816257421259
At time: 99.13385558128357 and batch: 700, loss is 4.4005180358886715 and perplexity is 81.4930740691132
At time: 99.83598709106445 and batch: 750, loss is 4.3640570545196535 and perplexity is 78.57527279998901
At time: 100.54523968696594 and batch: 800, loss is 4.355862874984741 and perplexity is 77.93404366889038
At time: 101.25276923179626 and batch: 850, loss is 4.355172815322876 and perplexity is 77.88028308020864
At time: 101.95800018310547 and batch: 900, loss is 4.32351770401001 and perplexity is 75.45358537835544
At time: 102.66111159324646 and batch: 950, loss is 4.399986343383789 and perplexity is 81.4497563293101
At time: 103.36685132980347 and batch: 1000, loss is 4.386241769790649 and perplexity is 80.33792250351452
At time: 104.07103681564331 and batch: 1050, loss is 4.323348817825317 and perplexity is 75.44084338620299
At time: 104.77432203292847 and batch: 1100, loss is 4.354041500091553 and perplexity is 77.79222574943184
At time: 105.48938846588135 and batch: 1150, loss is 4.323681468963623 and perplexity is 75.46594304311344
At time: 106.19424867630005 and batch: 1200, loss is 4.380745716094971 and perplexity is 79.89759211577008
At time: 106.90136313438416 and batch: 1250, loss is 4.385497169494629 and perplexity is 80.27812512797132
At time: 107.60518336296082 and batch: 1300, loss is 4.36678991317749 and perplexity is 78.79030160238564
At time: 108.31262588500977 and batch: 1350, loss is 4.251797695159912 and perplexity is 70.2315538551657
At time: 109.01631617546082 and batch: 1400, loss is 4.274622755050659 and perplexity is 71.8530280042696
At time: 109.72111415863037 and batch: 1450, loss is 4.219450316429138 and perplexity is 67.99609767718192
At time: 110.422523021698 and batch: 1500, loss is 4.21508451461792 and perplexity is 67.69988725926292
At time: 111.12469744682312 and batch: 1550, loss is 4.229395694732666 and perplexity is 68.6757185332064
At time: 111.82855439186096 and batch: 1600, loss is 4.306987438201904 and perplexity is 74.21656982157242
At time: 112.53184294700623 and batch: 1650, loss is 4.272877235412597 and perplexity is 71.72771653146924
At time: 113.2375545501709 and batch: 1700, loss is 4.276550765037537 and perplexity is 71.9916949925637
At time: 113.94331932067871 and batch: 1750, loss is 4.269060873985291 and perplexity is 71.4544993202514
At time: 114.6517276763916 and batch: 1800, loss is 4.2329878234863285 and perplexity is 68.92285416218688
At time: 115.35396313667297 and batch: 1850, loss is 4.278069653511047 and perplexity is 72.10112543355594
At time: 116.06270480155945 and batch: 1900, loss is 4.374316911697388 and perplexity is 79.38559365657953
At time: 116.7711820602417 and batch: 1950, loss is 4.300739221572876 and perplexity is 73.75429431854984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.480249875090843 and perplexity of 88.25672307731014
finished 4 epochs...
Completing Train Step...
At time: 119.38469767570496 and batch: 50, loss is 4.297757997512817 and perplexity is 73.53474366924208
At time: 120.13675284385681 and batch: 100, loss is 4.261497898101807 and perplexity is 70.91612907189469
At time: 120.83951473236084 and batch: 150, loss is 4.21899567604065 and perplexity is 67.96519093117814
At time: 121.5465841293335 and batch: 200, loss is 4.208195333480835 and perplexity is 67.23509333602807
At time: 122.2554063796997 and batch: 250, loss is 4.21078806400299 and perplexity is 67.40964199571917
At time: 122.95789051055908 and batch: 300, loss is 4.234122343063355 and perplexity is 69.0010928628152
At time: 123.66443228721619 and batch: 350, loss is 4.241493802070618 and perplexity is 69.51161091001244
At time: 124.36723351478577 and batch: 400, loss is 4.1884168434143065 and perplexity is 65.91834923970832
At time: 125.07128262519836 and batch: 450, loss is 4.211420826911926 and perplexity is 67.45230981476169
At time: 125.7775514125824 and batch: 500, loss is 4.22107750415802 and perplexity is 68.10683015976997
At time: 126.48493003845215 and batch: 550, loss is 4.189053754806519 and perplexity is 65.96034676022485
At time: 127.19000792503357 and batch: 600, loss is 4.179477343559265 and perplexity is 65.33169825625531
At time: 127.89685344696045 and batch: 650, loss is 4.236528768539428 and perplexity is 69.16733879956004
At time: 128.60217308998108 and batch: 700, loss is 4.26980751991272 and perplexity is 71.5078704533555
At time: 129.30800557136536 and batch: 750, loss is 4.233075280189514 and perplexity is 68.92888219137795
At time: 130.0168604850769 and batch: 800, loss is 4.226968660354614 and perplexity is 68.50924230687005
At time: 130.77351140975952 and batch: 850, loss is 4.228029079437256 and perplexity is 68.58192934730067
At time: 131.48194360733032 and batch: 900, loss is 4.19354745388031 and perplexity is 66.25741968763006
At time: 132.19056701660156 and batch: 950, loss is 4.27525384426117 and perplexity is 71.89838798657783
At time: 132.90163397789001 and batch: 1000, loss is 4.260705318450928 and perplexity is 70.85994465932542
At time: 133.60543704032898 and batch: 1050, loss is 4.2048879241943355 and perplexity is 67.01308669973182
At time: 134.31431198120117 and batch: 1100, loss is 4.229860553741455 and perplexity is 68.70765048100337
At time: 135.01788449287415 and batch: 1150, loss is 4.204265804290771 and perplexity is 66.97140949015164
At time: 135.71926736831665 and batch: 1200, loss is 4.257467427253723 and perplexity is 70.6308789133857
At time: 136.42504715919495 and batch: 1250, loss is 4.266389780044555 and perplexity is 71.2638923180108
At time: 137.13420820236206 and batch: 1300, loss is 4.242298994064331 and perplexity is 69.56760364201186
At time: 137.83925485610962 and batch: 1350, loss is 4.131695232391357 and perplexity is 62.28341835811203
At time: 138.5432095527649 and batch: 1400, loss is 4.157804713249207 and perplexity is 63.93102151178471
At time: 139.24631214141846 and batch: 1450, loss is 4.101836175918579 and perplexity is 60.45118476256259
At time: 139.95323705673218 and batch: 1500, loss is 4.097840666770935 and perplexity is 60.21013338303432
At time: 140.65698099136353 and batch: 1550, loss is 4.116094932556153 and perplexity is 61.31931803663392
At time: 141.35922932624817 and batch: 1600, loss is 4.190800585746765 and perplexity is 66.07566902970449
At time: 142.06253480911255 and batch: 1650, loss is 4.156798806190491 and perplexity is 63.86674517940311
At time: 142.76699256896973 and batch: 1700, loss is 4.163140358924866 and perplexity is 64.27304644074259
At time: 143.48150372505188 and batch: 1750, loss is 4.154500288963318 and perplexity is 63.720114945979745
At time: 144.18770718574524 and batch: 1800, loss is 4.121088848114014 and perplexity is 61.626307434534276
At time: 144.8912193775177 and batch: 1850, loss is 4.162956829071045 and perplexity is 64.26125150031964
At time: 145.5944480895996 and batch: 1900, loss is 4.2611377239227295 and perplexity is 70.8905915125837
At time: 146.29829025268555 and batch: 1950, loss is 4.189564852714539 and perplexity is 65.9940675720504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.463729503542878 and perplexity of 86.81066680225153
finished 5 epochs...
Completing Train Step...
At time: 148.98930764198303 and batch: 50, loss is 4.187294826507569 and perplexity is 65.84442921491086
At time: 149.69744539260864 and batch: 100, loss is 4.152513575553894 and perplexity is 63.59364700853787
At time: 150.40774393081665 and batch: 150, loss is 4.112158145904541 and perplexity is 61.07839151322439
At time: 151.11558985710144 and batch: 200, loss is 4.100465850830078 and perplexity is 60.36840371887716
At time: 151.82253170013428 and batch: 250, loss is 4.10236536026001 and perplexity is 60.48318304870917
At time: 152.52965664863586 and batch: 300, loss is 4.125115671157837 and perplexity is 61.874965985402646
At time: 153.23324704170227 and batch: 350, loss is 4.130887804031372 and perplexity is 62.23314925685286
At time: 153.9428994655609 and batch: 400, loss is 4.077439079284668 and perplexity is 58.99419677277875
At time: 154.64906978607178 and batch: 450, loss is 4.1088560104370115 and perplexity is 60.87703502647473
At time: 155.3542764186859 and batch: 500, loss is 4.117676944732666 and perplexity is 61.416402718749666
At time: 156.05754375457764 and batch: 550, loss is 4.085676774978638 and perplexity is 59.48218018339526
At time: 156.76105284690857 and batch: 600, loss is 4.081058688163758 and perplexity is 59.208119616183644
At time: 157.46592569351196 and batch: 650, loss is 4.133374290466309 and perplexity is 62.38808367962873
At time: 158.1714735031128 and batch: 700, loss is 4.168174881935119 and perplexity is 64.59744648653704
At time: 158.87432265281677 and batch: 750, loss is 4.134652571678162 and perplexity is 62.467884187718816
At time: 159.58049654960632 and batch: 800, loss is 4.12943829536438 and perplexity is 62.143007114322224
At time: 160.28432297706604 and batch: 850, loss is 4.1303471326828 and perplexity is 62.199510670647655
At time: 160.99023747444153 and batch: 900, loss is 4.103723554611206 and perplexity is 60.565386777951936
At time: 161.6927878856659 and batch: 950, loss is 4.178963794708252 and perplexity is 65.29815585125002
At time: 162.40089631080627 and batch: 1000, loss is 4.162911758422852 and perplexity is 64.25835526932882
At time: 163.10477328300476 and batch: 1050, loss is 4.11730432510376 and perplexity is 61.393522024722465
At time: 163.81088423728943 and batch: 1100, loss is 4.136327567100525 and perplexity is 62.57260528697505
At time: 164.51659655570984 and batch: 1150, loss is 4.10980899810791 and perplexity is 60.9350777428996
At time: 165.22086572647095 and batch: 1200, loss is 4.161959562301636 and perplexity is 64.19719783424271
At time: 165.92876172065735 and batch: 1250, loss is 4.173290600776673 and perplexity is 64.92875558018522
At time: 166.6360640525818 and batch: 1300, loss is 4.148437333106995 and perplexity is 63.334951496264125
At time: 167.3405065536499 and batch: 1350, loss is 4.036289587020874 and perplexity is 56.61588429102048
At time: 168.04433178901672 and batch: 1400, loss is 4.0678163385391235 and perplexity is 58.42923351869678
At time: 168.7553780078888 and batch: 1450, loss is 4.005131831169129 and perplexity is 54.879058692675045
At time: 169.46337747573853 and batch: 1500, loss is 4.0101062679290775 and perplexity is 55.15273121858803
At time: 170.17251205444336 and batch: 1550, loss is 4.0303347873687745 and perplexity is 56.27974984285511
At time: 170.88019180297852 and batch: 1600, loss is 4.103053865432739 and perplexity is 60.524840372097024
At time: 171.58862972259521 and batch: 1650, loss is 4.067213463783264 and perplexity is 58.39401862495597
At time: 172.29619479179382 and batch: 1700, loss is 4.07693733215332 and perplexity is 58.964604028439965
At time: 173.00956225395203 and batch: 1750, loss is 4.066922025680542 and perplexity is 58.377002862598786
At time: 173.72648000717163 and batch: 1800, loss is 4.033102173805236 and perplexity is 56.4357133653498
At time: 174.43378400802612 and batch: 1850, loss is 4.078181948661804 and perplexity is 59.03803803714021
At time: 175.1383330821991 and batch: 1900, loss is 4.170758380889892 and perplexity is 64.76454968454098
At time: 175.85148525238037 and batch: 1950, loss is 4.099601731300354 and perplexity is 60.31626073437565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470057003997093 and perplexity of 87.36170283775932
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 178.48957705497742 and batch: 50, loss is 4.139941139221191 and perplexity is 62.79912493501071
At time: 179.2234592437744 and batch: 100, loss is 4.127248396873474 and perplexity is 62.00706913633466
At time: 179.92871642112732 and batch: 150, loss is 4.084944324493408 and perplexity is 59.438628383373
At time: 180.63572931289673 and batch: 200, loss is 4.071146759986878 and perplexity is 58.62415189118267
At time: 181.34169626235962 and batch: 250, loss is 4.0726887893676755 and perplexity is 58.71462179151841
At time: 182.051331281662 and batch: 300, loss is 4.0885478162765505 and perplexity is 59.653201366155365
At time: 182.75328397750854 and batch: 350, loss is 4.090433158874512 and perplexity is 59.76577417360521
At time: 183.4562110900879 and batch: 400, loss is 4.036502504348755 and perplexity is 56.62794007721672
At time: 184.16294193267822 and batch: 450, loss is 4.057785987854004 and perplexity is 57.84609723595132
At time: 184.86812663078308 and batch: 500, loss is 4.064918732643127 and perplexity is 58.260173679834594
At time: 185.63051414489746 and batch: 550, loss is 4.02160906791687 and perplexity is 55.79080483566106
At time: 186.3419189453125 and batch: 600, loss is 3.9973127317428587 and perplexity is 54.45162711902473
At time: 187.04991960525513 and batch: 650, loss is 4.047847995758056 and perplexity is 57.27407028644027
At time: 187.77009177207947 and batch: 700, loss is 4.0910540962219235 and perplexity is 59.80289649901296
At time: 188.49156999588013 and batch: 750, loss is 4.0306617498397825 and perplexity is 56.298154217537395
At time: 189.1982445716858 and batch: 800, loss is 4.0276448440551755 and perplexity is 56.12856393799375
At time: 189.90543127059937 and batch: 850, loss is 4.043775591850281 and perplexity is 57.0413014248979
At time: 190.61159443855286 and batch: 900, loss is 4.000903739929199 and perplexity is 54.647514864514314
At time: 191.31654524803162 and batch: 950, loss is 4.06925754070282 and perplexity is 58.51350256624786
At time: 192.02805519104004 and batch: 1000, loss is 4.037877688407898 and perplexity is 56.705867487698406
At time: 192.7325828075409 and batch: 1050, loss is 3.987975306510925 and perplexity is 53.94555550190879
At time: 193.43765664100647 and batch: 1100, loss is 4.003384861946106 and perplexity is 54.783270360146304
At time: 194.1417214870453 and batch: 1150, loss is 3.9741097927093505 and perplexity is 53.20273435671259
At time: 194.85277795791626 and batch: 1200, loss is 4.018246083259583 and perplexity is 55.60349634929693
At time: 195.57289266586304 and batch: 1250, loss is 4.014552206993103 and perplexity is 55.39848279426427
At time: 196.2886188030243 and batch: 1300, loss is 4.000129375457764 and perplexity is 54.6052141507497
At time: 196.99970149993896 and batch: 1350, loss is 3.881236276626587 and perplexity is 48.484117817151436
At time: 197.7104790210724 and batch: 1400, loss is 3.904047842025757 and perplexity is 49.60282769202599
At time: 198.42273616790771 and batch: 1450, loss is 3.829229025840759 and perplexity is 46.02703889382231
At time: 199.1331799030304 and batch: 1500, loss is 3.8353275537490843 and perplexity is 46.308593737456896
At time: 199.84089827537537 and batch: 1550, loss is 3.8535248327255247 and perplexity is 47.15899819341838
At time: 200.55059027671814 and batch: 1600, loss is 3.915717849731445 and perplexity is 50.18508393276041
At time: 201.25753021240234 and batch: 1650, loss is 3.8694836044311525 and perplexity is 47.91763523625038
At time: 201.96532273292542 and batch: 1700, loss is 3.8708571910858156 and perplexity is 47.98349948530495
At time: 202.66890120506287 and batch: 1750, loss is 3.8537528276443482 and perplexity is 47.16975143117849
At time: 203.372976064682 and batch: 1800, loss is 3.81414014339447 and perplexity is 45.33775564915609
At time: 204.0754954814911 and batch: 1850, loss is 3.844238076210022 and perplexity is 46.7230713658303
At time: 204.78708863258362 and batch: 1900, loss is 3.936902184486389 and perplexity is 51.259562423464466
At time: 205.50085949897766 and batch: 1950, loss is 3.8637131309509276 and perplexity is 47.641924049989306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386701149164244 and perplexity of 80.37483656616043
finished 7 epochs...
Completing Train Step...
At time: 208.17216444015503 and batch: 50, loss is 4.046903777122497 and perplexity is 57.220016565222906
At time: 208.87607431411743 and batch: 100, loss is 4.022749676704406 and perplexity is 55.85447662331758
At time: 209.57890248298645 and batch: 150, loss is 3.9774760580062867 and perplexity is 53.38213065343772
At time: 210.28591775894165 and batch: 200, loss is 3.964120321273804 and perplexity is 52.67391288263178
At time: 210.99375772476196 and batch: 250, loss is 3.963300943374634 and perplexity is 52.63077071983404
At time: 211.70204901695251 and batch: 300, loss is 3.9791449880599976 and perplexity is 53.471296080350484
At time: 212.4189910888672 and batch: 350, loss is 3.9865463972091675 and perplexity is 53.86852724216829
At time: 213.12334728240967 and batch: 400, loss is 3.9374654388427732 and perplexity is 51.28844272802097
At time: 213.828626871109 and batch: 450, loss is 3.9662399768829344 and perplexity is 52.785681851541646
At time: 214.53807878494263 and batch: 500, loss is 3.9760960865020754 and perplexity is 53.30851563929501
At time: 215.2534236907959 and batch: 550, loss is 3.935485496520996 and perplexity is 51.18699503307908
At time: 215.9538426399231 and batch: 600, loss is 3.9194332790374755 and perplexity is 50.37188988158266
At time: 216.66338109970093 and batch: 650, loss is 3.9669489574432375 and perplexity is 52.823119143424655
At time: 217.3695297241211 and batch: 700, loss is 4.009957709312439 and perplexity is 55.144538413705305
At time: 218.0752148628235 and batch: 750, loss is 3.9567769670486452 and perplexity is 52.28852642835718
At time: 218.78925704956055 and batch: 800, loss is 3.9545281887054444 and perplexity is 52.17107323512261
At time: 219.49631905555725 and batch: 850, loss is 3.974265766143799 and perplexity is 53.21103321709631
At time: 220.21302914619446 and batch: 900, loss is 3.92926766872406 and perplexity is 50.8697105448966
At time: 220.9214539527893 and batch: 950, loss is 4.001379866600036 and perplexity is 54.67354019902257
At time: 221.67730903625488 and batch: 1000, loss is 3.9740859699249267 and perplexity is 53.201466934538075
At time: 222.3837730884552 and batch: 1050, loss is 3.9302295446395874 and perplexity is 50.918664434308816
At time: 223.08892583847046 and batch: 1100, loss is 3.944442629814148 and perplexity is 51.6475432873632
At time: 223.795649766922 and batch: 1150, loss is 3.9191906023025513 and perplexity is 50.359667278944876
At time: 224.4973499774933 and batch: 1200, loss is 3.9663391971588133 and perplexity is 52.79091952129463
At time: 225.20113706588745 and batch: 1250, loss is 3.9660210943222047 and perplexity is 52.77412925070567
At time: 225.904296875 and batch: 1300, loss is 3.9541524839401245 and perplexity is 52.15147599591492
At time: 226.60989141464233 and batch: 1350, loss is 3.8329310417175293 and perplexity is 46.197747510610476
At time: 227.32386898994446 and batch: 1400, loss is 3.861251616477966 and perplexity is 47.524796978551215
At time: 228.04366970062256 and batch: 1450, loss is 3.7877962827682494 and perplexity is 44.15897906790354
At time: 228.76218271255493 and batch: 1500, loss is 3.7963387298583986 and perplexity is 44.53782062334058
At time: 229.46636939048767 and batch: 1550, loss is 3.81933678150177 and perplexity is 45.57397279378191
At time: 230.16909003257751 and batch: 1600, loss is 3.8853326272964477 and perplexity is 48.68313310556323
At time: 230.87249374389648 and batch: 1650, loss is 3.8402115440368654 and perplexity is 46.535317667570645
At time: 231.57430601119995 and batch: 1700, loss is 3.84589364528656 and perplexity is 46.80048870513809
At time: 232.2756643295288 and batch: 1750, loss is 3.8319183921813966 and perplexity is 46.150989061979885
At time: 232.9833357334137 and batch: 1800, loss is 3.7962693071365354 and perplexity is 44.5347287939299
At time: 233.69152331352234 and batch: 1850, loss is 3.8322495079040526 and perplexity is 46.16627291029603
At time: 234.4014117717743 and batch: 1900, loss is 3.9262745904922487 and perplexity is 50.71768115303429
At time: 235.10850286483765 and batch: 1950, loss is 3.855333695411682 and perplexity is 47.24437954385592
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385551984920058 and perplexity of 80.28252572816213
finished 8 epochs...
Completing Train Step...
At time: 237.74339199066162 and batch: 50, loss is 3.998851556777954 and perplexity is 54.535483149369114
At time: 238.47846722602844 and batch: 100, loss is 3.9739356088638305 and perplexity is 53.19346810688909
At time: 239.18642258644104 and batch: 150, loss is 3.9299247074127197 and perplexity is 50.903144895433634
At time: 239.91943979263306 and batch: 200, loss is 3.915142159461975 and perplexity is 50.156201182824525
At time: 240.6242458820343 and batch: 250, loss is 3.9127707052230836 and perplexity is 50.03739896960549
At time: 241.33340692520142 and batch: 300, loss is 3.930549349784851 and perplexity is 50.93495108932408
At time: 242.041588306427 and batch: 350, loss is 3.9380722570419313 and perplexity is 51.319574933313866
At time: 242.7474763393402 and batch: 400, loss is 3.8901271200180054 and perplexity is 48.9171044717119
At time: 243.45149993896484 and batch: 450, loss is 3.923060793876648 and perplexity is 50.55494647913258
At time: 244.1558063030243 and batch: 500, loss is 3.932464919090271 and perplexity is 51.03261402840431
At time: 244.86080145835876 and batch: 550, loss is 3.8930360221862794 and perplexity is 49.05960670501868
At time: 245.5632185935974 and batch: 600, loss is 3.8793582248687746 and perplexity is 48.393147584599795
At time: 246.27178120613098 and batch: 650, loss is 3.924914336204529 and perplexity is 50.648739109767895
At time: 246.97408962249756 and batch: 700, loss is 3.967154583930969 and perplexity is 52.83398209270193
At time: 247.67675399780273 and batch: 750, loss is 3.9162800979614256 and perplexity is 50.213308341191336
At time: 248.3817994594574 and batch: 800, loss is 3.915060324668884 and perplexity is 50.15209682842029
At time: 249.08675837516785 and batch: 850, loss is 3.9357701110839844 and perplexity is 51.20156567071057
At time: 249.79516768455505 and batch: 900, loss is 3.891293697357178 and perplexity is 48.974203355943246
At time: 250.5029754638672 and batch: 950, loss is 3.9647576284408568 and perplexity is 52.70749304413083
At time: 251.20522260665894 and batch: 1000, loss is 3.937486653327942 and perplexity is 51.289530797469915
At time: 251.90910410881042 and batch: 1050, loss is 3.896017241477966 and perplexity is 49.20608238053947
At time: 252.61765313148499 and batch: 1100, loss is 3.9107264137268065 and perplexity is 49.9352124255252
At time: 253.3231177330017 and batch: 1150, loss is 3.8864332962036134 and perplexity is 48.736746616425535
At time: 254.0309543609619 and batch: 1200, loss is 3.9342401027679443 and perplexity is 51.12328674841159
At time: 254.7434117794037 and batch: 1250, loss is 3.9361125469207763 and perplexity is 51.2191019240455
At time: 255.4508194923401 and batch: 1300, loss is 3.92500066280365 and perplexity is 50.65311163189478
At time: 256.1619019508362 and batch: 1350, loss is 3.802383460998535 and perplexity is 44.807855095240015
At time: 256.86854791641235 and batch: 1400, loss is 3.8331672954559326 and perplexity is 46.20866319055
At time: 257.5774784088135 and batch: 1450, loss is 3.759769849777222 and perplexity is 42.938542526339056
At time: 258.2843096256256 and batch: 1500, loss is 3.7696564388275147 and perplexity is 43.3651636897883
At time: 258.99700713157654 and batch: 1550, loss is 3.794101204872131 and perplexity is 44.43827754345653
At time: 259.70130944252014 and batch: 1600, loss is 3.8622924518585204 and perplexity is 47.574288220349914
At time: 260.4032962322235 and batch: 1650, loss is 3.816735668182373 and perplexity is 45.45558376452023
At time: 261.11062145233154 and batch: 1700, loss is 3.824308843612671 and perplexity is 45.80113367818858
At time: 261.8218650817871 and batch: 1750, loss is 3.811548891067505 and perplexity is 45.22042616513167
At time: 262.5316460132599 and batch: 1800, loss is 3.7773901891708372 and perplexity is 43.70183924363201
At time: 263.2446999549866 and batch: 1850, loss is 3.8162908029556273 and perplexity is 45.43536665322029
At time: 263.95338702201843 and batch: 1900, loss is 3.9106175613403322 and perplexity is 49.92977715431007
At time: 264.6635584831238 and batch: 1950, loss is 3.839912977218628 and perplexity is 46.52142583976157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388617369186046 and perplexity of 80.52900009568579
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 267.35560297966003 and batch: 50, loss is 3.991441025733948 and perplexity is 54.13284000089314
At time: 268.06115078926086 and batch: 100, loss is 3.998980746269226 and perplexity is 54.5425290158096
At time: 268.77453780174255 and batch: 150, loss is 3.9615186834335328 and perplexity is 52.53705254539243
At time: 269.4769480228424 and batch: 200, loss is 3.9496287965774535 and perplexity is 51.91609182660697
At time: 270.1829147338867 and batch: 250, loss is 3.9444800329208376 and perplexity is 51.649475102062745
At time: 270.8936131000519 and batch: 300, loss is 3.9594924640655518 and perplexity is 52.4307087263247
At time: 271.603942155838 and batch: 350, loss is 3.965546875 and perplexity is 52.749108671992275
At time: 272.31022000312805 and batch: 400, loss is 3.9145872020721435 and perplexity is 50.128374350399554
At time: 273.02221870422363 and batch: 450, loss is 3.9524961519241333 and perplexity is 52.065167334173395
At time: 273.7305476665497 and batch: 500, loss is 3.966978278160095 and perplexity is 52.82466797785095
At time: 274.43946051597595 and batch: 550, loss is 3.9272565507888793 and perplexity is 50.7675083624306
At time: 275.14836502075195 and batch: 600, loss is 3.8975186014175414 and perplexity is 49.280013906437375
At time: 275.86206555366516 and batch: 650, loss is 3.93622416973114 and perplexity is 51.224819463244536
At time: 276.62171053886414 and batch: 700, loss is 3.9828245353698732 and perplexity is 53.668408664143875
At time: 277.3367774486542 and batch: 750, loss is 3.916984190940857 and perplexity is 50.24867562853666
At time: 278.0436313152313 and batch: 800, loss is 3.9170218324661255 and perplexity is 50.25056710092876
At time: 278.7497854232788 and batch: 850, loss is 3.9398856925964356 and perplexity is 51.41272410962696
At time: 279.45811223983765 and batch: 900, loss is 3.9065756511688234 and perplexity is 49.728372783552096
At time: 280.16661953926086 and batch: 950, loss is 3.989812994003296 and perplexity is 54.044781719988876
At time: 280.8788917064667 and batch: 1000, loss is 3.944581665992737 and perplexity is 51.65472466363937
At time: 281.5856964588165 and batch: 1050, loss is 3.8869168281555178 and perplexity is 48.760318088967246
At time: 282.2924475669861 and batch: 1100, loss is 3.9046442031860353 and perplexity is 49.63241771419451
At time: 282.99924421310425 and batch: 1150, loss is 3.877127799987793 and perplexity is 48.285330587711606
At time: 283.70716547966003 and batch: 1200, loss is 3.913545880317688 and perplexity is 50.076201752617976
At time: 284.4134888648987 and batch: 1250, loss is 3.9168413162231444 and perplexity is 50.24149687603412
At time: 285.1197280883789 and batch: 1300, loss is 3.908586859703064 and perplexity is 49.828487553381336
At time: 285.8275098800659 and batch: 1350, loss is 3.7832802438735964 and perplexity is 43.9600050263065
At time: 286.54167103767395 and batch: 1400, loss is 3.81102201461792 and perplexity is 45.196606863010764
At time: 287.2579209804535 and batch: 1450, loss is 3.7268550252914427 and perplexity is 41.54823432830116
At time: 287.96223402023315 and batch: 1500, loss is 3.7424663352966308 and perplexity is 42.20194606641721
At time: 288.6681418418884 and batch: 1550, loss is 3.7655430841445923 and perplexity is 43.18715375064689
At time: 289.3743143081665 and batch: 1600, loss is 3.8358217096328735 and perplexity is 46.33148305650233
At time: 290.0817620754242 and batch: 1650, loss is 3.7866458559036253 and perplexity is 44.10820660267314
At time: 290.7901394367218 and batch: 1700, loss is 3.783178472518921 and perplexity is 43.95553138469157
At time: 291.49733209609985 and batch: 1750, loss is 3.771713604927063 and perplexity is 43.45446485660578
At time: 292.20160007476807 and batch: 1800, loss is 3.7323641967773438 and perplexity is 41.77776235023612
At time: 292.90953159332275 and batch: 1850, loss is 3.7655061054229737 and perplexity is 43.185556774438105
At time: 293.6164481639862 and batch: 1900, loss is 3.8655909061431886 and perplexity is 47.73146891933752
At time: 294.3315052986145 and batch: 1950, loss is 3.7929629278182984 and perplexity is 44.387723249671744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3594627202943315 and perplexity of 78.21509974613556
finished 10 epochs...
Completing Train Step...
At time: 296.9663462638855 and batch: 50, loss is 3.9778826999664307 and perplexity is 53.40384248185435
At time: 297.7075593471527 and batch: 100, loss is 3.9686608123779297 and perplexity is 52.9136221024635
At time: 298.42038464546204 and batch: 150, loss is 3.926018490791321 and perplexity is 50.704694033128995
At time: 299.13074827194214 and batch: 200, loss is 3.909101867675781 and perplexity is 49.85415623095922
At time: 299.8409960269928 and batch: 250, loss is 3.9045426845550537 and perplexity is 49.62737935484385
At time: 300.5467779636383 and batch: 300, loss is 3.9176385974884034 and perplexity is 50.28156945266655
At time: 301.2551245689392 and batch: 350, loss is 3.9262677907943724 and perplexity is 50.717336289297954
At time: 301.9587473869324 and batch: 400, loss is 3.8749199867248536 and perplexity is 48.17884318983485
At time: 302.66409134864807 and batch: 450, loss is 3.915308966636658 and perplexity is 50.16456829486441
At time: 303.37392139434814 and batch: 500, loss is 3.9313640928268434 and perplexity is 50.976466896379264
At time: 304.0881690979004 and batch: 550, loss is 3.8922645473480224 and perplexity is 49.02177304860442
At time: 304.7923665046692 and batch: 600, loss is 3.864808802604675 and perplexity is 47.69415256312654
At time: 305.5014503002167 and batch: 650, loss is 3.904816975593567 and perplexity is 49.640993567308676
At time: 306.21074771881104 and batch: 700, loss is 3.951782259941101 and perplexity is 52.02801169275358
At time: 306.918687582016 and batch: 750, loss is 3.8912048387527465 and perplexity is 48.96985176992069
At time: 307.62376046180725 and batch: 800, loss is 3.8901853132247926 and perplexity is 48.919951197717104
At time: 308.3464777469635 and batch: 850, loss is 3.9146386337280275 and perplexity is 50.13095260200047
At time: 309.06901955604553 and batch: 900, loss is 3.8791293239593507 and perplexity is 48.38207161680571
At time: 309.77241587638855 and batch: 950, loss is 3.96264741897583 and perplexity is 52.596386463739705
At time: 310.47971630096436 and batch: 1000, loss is 3.9203844976425173 and perplexity is 50.41982735630351
At time: 311.183874130249 and batch: 1050, loss is 3.866199798583984 and perplexity is 47.76054109996788
At time: 311.8874728679657 and batch: 1100, loss is 3.884834899902344 and perplexity is 48.658908205784016
At time: 312.64249992370605 and batch: 1150, loss is 3.8579890298843384 and perplexity is 47.36999587637906
At time: 313.3535387516022 and batch: 1200, loss is 3.8977906560897826 and perplexity is 49.29342258833331
At time: 314.0691759586334 and batch: 1250, loss is 3.9035616588592528 and perplexity is 49.578717493652334
At time: 314.78332924842834 and batch: 1300, loss is 3.8953134870529174 and perplexity is 49.17146556462227
At time: 315.49014830589294 and batch: 1350, loss is 3.769706745147705 and perplexity is 43.367345286471576
At time: 316.1973261833191 and batch: 1400, loss is 3.7997538948059084 and perplexity is 44.69018465322938
At time: 316.9001898765564 and batch: 1450, loss is 3.716977386474609 and perplexity is 41.13985610280835
At time: 317.60817980766296 and batch: 1500, loss is 3.733686800003052 and perplexity is 41.833054310085544
At time: 318.3231279850006 and batch: 1550, loss is 3.759100513458252 and perplexity is 42.90981181666891
At time: 319.0310380458832 and batch: 1600, loss is 3.831191382408142 and perplexity is 46.117449035327326
At time: 319.7410624027252 and batch: 1650, loss is 3.7830922746658326 and perplexity is 43.9517426755465
At time: 320.44539403915405 and batch: 1700, loss is 3.781107783317566 and perplexity is 43.86460731075083
At time: 321.15862250328064 and batch: 1750, loss is 3.771776251792908 and perplexity is 43.45718722790913
At time: 321.86353302001953 and batch: 1800, loss is 3.7342649602890017 and perplexity is 41.85724751382849
At time: 322.5716679096222 and batch: 1850, loss is 3.769151334762573 and perplexity is 43.34326530028009
At time: 323.28247141838074 and batch: 1900, loss is 3.869364995956421 and perplexity is 47.911952135660876
At time: 323.9921340942383 and batch: 1950, loss is 3.797244915962219 and perplexity is 44.5781984696424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3586181640625 and perplexity of 78.1490705828171
finished 11 epochs...
Completing Train Step...
At time: 326.6340651512146 and batch: 50, loss is 3.9637467527389525 and perplexity is 52.65423924112684
At time: 327.339971780777 and batch: 100, loss is 3.9528189420700075 and perplexity is 52.081976169849476
At time: 328.0432918071747 and batch: 150, loss is 3.909834818840027 and perplexity is 49.89071028734382
At time: 328.7485692501068 and batch: 200, loss is 3.8917627429962156 and perplexity is 48.99717988055079
At time: 329.461128950119 and batch: 250, loss is 3.886420569419861 and perplexity is 48.73612635833749
At time: 330.18136739730835 and batch: 300, loss is 3.8996580934524534 and perplexity is 49.3855609719624
At time: 330.89110136032104 and batch: 350, loss is 3.9088646507263185 and perplexity is 49.842331382682744
At time: 331.6423716545105 and batch: 400, loss is 3.857557773590088 and perplexity is 47.34957167184867
At time: 332.35455107688904 and batch: 450, loss is 3.8986293506622314 and perplexity is 49.334782055871656
At time: 333.06986832618713 and batch: 500, loss is 3.9149043416976927 and perplexity is 50.14427456543128
At time: 333.77791595458984 and batch: 550, loss is 3.8762895154953 and perplexity is 48.24487070468062
At time: 334.48715329170227 and batch: 600, loss is 3.849223175048828 and perplexity is 46.956572023004725
At time: 335.19088196754456 and batch: 650, loss is 3.8894884252548216 and perplexity is 48.885871348533556
At time: 335.8941185474396 and batch: 700, loss is 3.9364962434768676 and perplexity is 51.238758287858246
At time: 336.6072082519531 and batch: 750, loss is 3.877434210777283 and perplexity is 48.30012800090552
At time: 337.31829380989075 and batch: 800, loss is 3.8762402534484863 and perplexity is 48.24249412213958
At time: 338.03270292282104 and batch: 850, loss is 3.9013986730575563 and perplexity is 49.47159532527618
At time: 338.7472450733185 and batch: 900, loss is 3.865507287979126 and perplexity is 47.72747786840297
At time: 339.4578788280487 and batch: 950, loss is 3.9487716007232665 and perplexity is 51.871608636054674
At time: 340.1767511367798 and batch: 1000, loss is 3.9073710203170777 and perplexity is 49.767940930612795
At time: 340.885498046875 and batch: 1050, loss is 3.854645175933838 and perplexity is 47.21186206406502
At time: 341.59892320632935 and batch: 1100, loss is 3.873829641342163 and perplexity is 48.12634023899598
At time: 342.30423188209534 and batch: 1150, loss is 3.847352590560913 and perplexity is 46.868817889121885
At time: 343.0127465724945 and batch: 1200, loss is 3.8879496479034423 and perplexity is 48.81070472408148
At time: 343.72149419784546 and batch: 1250, loss is 3.8950605392456055 and perplexity is 49.1590293231517
At time: 344.4334886074066 and batch: 1300, loss is 3.8867859268188476 and perplexity is 48.75393571589264
At time: 345.14521074295044 and batch: 1350, loss is 3.761075563430786 and perplexity is 42.99464458622199
At time: 345.85425066947937 and batch: 1400, loss is 3.7919096899032594 and perplexity is 44.34099702781667
At time: 346.5658178329468 and batch: 1450, loss is 3.709692053794861 and perplexity is 40.84122768920688
At time: 347.2756142616272 and batch: 1500, loss is 3.7266952991485596 and perplexity is 41.54159851905852
At time: 347.98623514175415 and batch: 1550, loss is 3.7530176067352294 and perplexity is 42.64958769580805
At time: 348.69496035575867 and batch: 1600, loss is 3.825832095146179 and perplexity is 45.87095348836653
At time: 349.39857053756714 and batch: 1650, loss is 3.7780452728271485 and perplexity is 43.73047698330474
At time: 350.1027669906616 and batch: 1700, loss is 3.77677649974823 and perplexity is 43.675028114834234
At time: 350.8227581977844 and batch: 1750, loss is 3.768325057029724 and perplexity is 43.30746651719891
At time: 351.53662395477295 and batch: 1800, loss is 3.7315494871139525 and perplexity is 41.743739464803184
At time: 352.24889159202576 and batch: 1850, loss is 3.7675324630737306 and perplexity is 43.2731548803822
At time: 352.96129751205444 and batch: 1900, loss is 3.8676216316223146 and perplexity is 47.82849691469527
At time: 353.67154145240784 and batch: 1950, loss is 3.795727515220642 and perplexity is 44.51060677304086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358982387808866 and perplexity of 78.17753951429549
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 356.2788043022156 and batch: 50, loss is 3.9643635892868043 and perplexity is 52.68672831948543
At time: 357.01979303359985 and batch: 100, loss is 3.973341341018677 and perplexity is 53.16186633011089
At time: 357.73345160484314 and batch: 150, loss is 3.9389357280731203 and perplexity is 51.363907036590746
At time: 358.4460391998291 and batch: 200, loss is 3.9239744901657105 and perplexity is 50.60115945522166
At time: 359.15928983688354 and batch: 250, loss is 3.9259432458877566 and perplexity is 50.70087890685242
At time: 359.87203073501587 and batch: 300, loss is 3.9378307104110717 and perplexity is 51.30718035988557
At time: 360.58001041412354 and batch: 350, loss is 3.947141251564026 and perplexity is 51.787108703440474
At time: 361.2908570766449 and batch: 400, loss is 3.897314443588257 and perplexity is 49.26995403270706
At time: 361.9975428581238 and batch: 450, loss is 3.9364061641693113 and perplexity is 51.23414294386825
At time: 362.7011981010437 and batch: 500, loss is 3.952458968162537 and perplexity is 52.063231391396805
At time: 363.41856932640076 and batch: 550, loss is 3.918938856124878 and perplexity is 50.346991020865204
At time: 364.1312839984894 and batch: 600, loss is 3.8871162366867065 and perplexity is 48.770042281888955
At time: 364.84786009788513 and batch: 650, loss is 3.9148218870162963 and perplexity is 50.14014010570326
At time: 365.5643005371094 and batch: 700, loss is 3.9600452041625975 and perplexity is 52.45969729218757
At time: 366.2786407470703 and batch: 750, loss is 3.896878471374512 and perplexity is 49.24847838350963
At time: 366.9948470592499 and batch: 800, loss is 3.8983940839767457 and perplexity is 49.323176590461436
At time: 367.75183629989624 and batch: 850, loss is 3.918281970024109 and perplexity is 50.31392964221694
At time: 368.45780205726624 and batch: 900, loss is 3.880799264907837 and perplexity is 48.4629343185478
At time: 369.162793636322 and batch: 950, loss is 3.9765649318695067 and perplexity is 53.33351494984466
At time: 369.8728561401367 and batch: 1000, loss is 3.933267297744751 and perplexity is 51.073577940669665
At time: 370.58013248443604 and batch: 1050, loss is 3.8724937057495117 and perplexity is 48.062089475123635
At time: 371.28723669052124 and batch: 1100, loss is 3.888395419120789 and perplexity is 48.832467981702415
At time: 371.9988114833832 and batch: 1150, loss is 3.8641055250167846 and perplexity is 47.66062212653976
At time: 372.71602630615234 and batch: 1200, loss is 3.8967543983459474 and perplexity is 49.24236835469712
At time: 373.43177127838135 and batch: 1250, loss is 3.8996015405654907 and perplexity is 49.38276815488684
At time: 374.1440465450287 and batch: 1300, loss is 3.8884360122680666 and perplexity is 48.834450285500836
At time: 374.85555768013 and batch: 1350, loss is 3.76426766872406 and perplexity is 43.13210729979249
At time: 375.5640504360199 and batch: 1400, loss is 3.7917524766921997 and perplexity is 44.33402658522952
At time: 376.26898193359375 and batch: 1450, loss is 3.705384864807129 and perplexity is 40.66569510044663
At time: 376.9822018146515 and batch: 1500, loss is 3.7230342483520507 and perplexity is 41.38979067438777
At time: 377.6962060928345 and batch: 1550, loss is 3.751745133399963 and perplexity is 42.59535174692261
At time: 378.40671277046204 and batch: 1600, loss is 3.8268579959869387 and perplexity is 45.918036685332886
At time: 379.1152153015137 and batch: 1650, loss is 3.777263379096985 and perplexity is 43.69629776153535
At time: 379.8448028564453 and batch: 1700, loss is 3.77501416683197 and perplexity is 43.59812595867313
At time: 380.5623595714569 and batch: 1750, loss is 3.7660542488098145 and perplexity is 43.20923514076814
At time: 381.2869882583618 and batch: 1800, loss is 3.7239388942718508 and perplexity is 41.42725072112722
At time: 382.0392425060272 and batch: 1850, loss is 3.753770122528076 and perplexity is 42.681694262941846
At time: 382.7523846626282 and batch: 1900, loss is 3.85723361492157 and perplexity is 47.33422538519094
At time: 383.48555397987366 and batch: 1950, loss is 3.7884858512878417 and perplexity is 44.18944021104175
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3440636923146805 and perplexity of 77.01988939380763
finished 13 epochs...
Completing Train Step...
At time: 386.3826835155487 and batch: 50, loss is 3.9698520278930665 and perplexity is 52.97669118705219
At time: 387.09455251693726 and batch: 100, loss is 3.961966381072998 and perplexity is 52.56057852567143
At time: 387.8105630874634 and batch: 150, loss is 3.920984301567078 and perplexity is 50.45007843807932
At time: 388.519807100296 and batch: 200, loss is 3.9015969896316527 and perplexity is 49.481407335486146
At time: 389.2306115627289 and batch: 250, loss is 3.90438937664032 and perplexity is 49.61977166797546
At time: 389.9394211769104 and batch: 300, loss is 3.915512661933899 and perplexity is 50.17478762229334
At time: 390.64583015441895 and batch: 350, loss is 3.9250720834732054 and perplexity is 50.6567294402342
At time: 391.35894083976746 and batch: 400, loss is 3.873832836151123 and perplexity is 48.1264939937046
At time: 392.0790033340454 and batch: 450, loss is 3.9154448175430296 and perplexity is 50.17138365986129
At time: 392.7921767234802 and batch: 500, loss is 3.933779788017273 and perplexity is 51.099759360835705
At time: 393.50010895729065 and batch: 550, loss is 3.900320553779602 and perplexity is 49.418287785751325
At time: 394.21047830581665 and batch: 600, loss is 3.870855565071106 and perplexity is 47.9834214634924
At time: 394.9322843551636 and batch: 650, loss is 3.9001073122024534 and perplexity is 49.40775087561751
At time: 395.6704070568085 and batch: 700, loss is 3.945175008773804 and perplexity is 51.685382716094146
At time: 396.4236044883728 and batch: 750, loss is 3.885476517677307 and perplexity is 48.69013864412993
At time: 397.13171315193176 and batch: 800, loss is 3.885082440376282 and perplexity is 48.67095474592419
At time: 397.8408842086792 and batch: 850, loss is 3.9056832551956178 and perplexity is 49.68401517914352
At time: 398.55423188209534 and batch: 900, loss is 3.868801226615906 and perplexity is 47.884948458640395
At time: 399.2603542804718 and batch: 950, loss is 3.9648842144012453 and perplexity is 52.71416549506788
At time: 399.9711592197418 and batch: 1000, loss is 3.9221388339996337 and perplexity is 50.50835832639803
At time: 400.68389201164246 and batch: 1050, loss is 3.8625311040878296 and perplexity is 47.58564328519337
At time: 401.39962220191956 and batch: 1100, loss is 3.879154558181763 and perplexity is 48.3832925161658
At time: 402.1122884750366 and batch: 1150, loss is 3.8554842138290404 and perplexity is 47.25149122830027
At time: 402.82087755203247 and batch: 1200, loss is 3.8893071365356446 and perplexity is 48.87700969481413
At time: 403.5371689796448 and batch: 1250, loss is 3.8941999673843384 and perplexity is 49.116742643761924
At time: 404.24752140045166 and batch: 1300, loss is 3.8833783292770385 and perplexity is 48.58808466170058
At time: 404.95717000961304 and batch: 1350, loss is 3.7590395545959474 and perplexity is 42.907196163083306
At time: 405.66292214393616 and batch: 1400, loss is 3.7888725233078 and perplexity is 44.20653033507245
At time: 406.3756959438324 and batch: 1450, loss is 3.7038332748413088 and perplexity is 40.60264754060483
At time: 407.08926343917847 and batch: 1500, loss is 3.7226799869537355 and perplexity is 41.37513046619374
At time: 407.80958890914917 and batch: 1550, loss is 3.75218204498291 and perplexity is 42.61396621562292
At time: 408.5201885700226 and batch: 1600, loss is 3.828967571258545 and perplexity is 46.01500648663031
At time: 409.22747254371643 and batch: 1650, loss is 3.7795401287078856 and perplexity is 43.79589662827898
At time: 409.93501234054565 and batch: 1700, loss is 3.7782700777053835 and perplexity is 43.7403089129496
At time: 410.6491508483887 and batch: 1750, loss is 3.770478196144104 and perplexity is 43.40081397627117
At time: 411.36186027526855 and batch: 1800, loss is 3.7289160680770874 and perplexity is 41.633955323895066
At time: 412.072970867157 and batch: 1850, loss is 3.7591103410720823 and perplexity is 42.91023351980114
At time: 412.77737498283386 and batch: 1900, loss is 3.8624737882614135 and perplexity is 47.58291595288334
At time: 413.4884672164917 and batch: 1950, loss is 3.7930088567733766 and perplexity is 44.38976197823688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342616733284884 and perplexity of 76.90852535840379
finished 14 epochs...
Completing Train Step...
At time: 416.15363121032715 and batch: 50, loss is 3.9655762338638305 and perplexity is 52.75065734862455
At time: 416.90139603614807 and batch: 100, loss is 3.955925211906433 and perplexity is 52.24400836902754
At time: 417.61070108413696 and batch: 150, loss is 3.914460473060608 and perplexity is 50.122022033588166
At time: 418.31521582603455 and batch: 200, loss is 3.894247841835022 and perplexity is 49.11909413712315
At time: 419.02550888061523 and batch: 250, loss is 3.896643667221069 and perplexity is 49.23691599373614
At time: 419.7325918674469 and batch: 300, loss is 3.90757577419281 and perplexity is 49.778132152716054
At time: 420.4456193447113 and batch: 350, loss is 3.9171226024627686 and perplexity is 50.25563110555242
At time: 421.1593680381775 and batch: 400, loss is 3.865599122047424 and perplexity is 47.73186107812615
At time: 421.87380146980286 and batch: 450, loss is 3.9076417875289917 and perplexity is 49.781418281751336
At time: 422.58628034591675 and batch: 500, loss is 3.9260810661315917 and perplexity is 50.70786699588502
At time: 423.3539912700653 and batch: 550, loss is 3.892541456222534 and perplexity is 49.035349492237984
At time: 424.0586938858032 and batch: 600, loss is 3.8636979961395266 and perplexity is 47.64120300391049
At time: 424.76810002326965 and batch: 650, loss is 3.8933472490310668 and perplexity is 49.07487774787597
At time: 425.47314405441284 and batch: 700, loss is 3.9386225652694704 and perplexity is 51.347824289847225
At time: 426.18388986587524 and batch: 750, loss is 3.8800091981887816 and perplexity is 48.42466048846552
At time: 426.89649081230164 and batch: 800, loss is 3.8792128562927246 and perplexity is 48.38611325294262
At time: 427.6082990169525 and batch: 850, loss is 3.8999208641052245 and perplexity is 49.398539753203195
At time: 428.32357716560364 and batch: 900, loss is 3.863105058670044 and perplexity is 47.612963122627484
At time: 429.05972504615784 and batch: 950, loss is 3.959368839263916 and perplexity is 52.42422739099395
At time: 429.77792263031006 and batch: 1000, loss is 3.916961727142334 and perplexity is 50.2475468650895
At time: 430.48599457740784 and batch: 1050, loss is 3.8579842853546142 and perplexity is 47.369771128558746
At time: 431.1900849342346 and batch: 1100, loss is 3.8749436426162718 and perplexity is 48.17998291679858
At time: 431.89449191093445 and batch: 1150, loss is 3.851559109687805 and perplexity is 47.06638771732808
At time: 432.59910130500793 and batch: 1200, loss is 3.885954427719116 and perplexity is 48.713413711576266
At time: 433.3073251247406 and batch: 1250, loss is 3.8915634250640867 and perplexity is 48.9874148371833
At time: 434.01517057418823 and batch: 1300, loss is 3.880892109870911 and perplexity is 48.467434066781294
At time: 434.7309296131134 and batch: 1350, loss is 3.7564998388290407 and perplexity is 42.79836234245886
At time: 435.4468410015106 and batch: 1400, loss is 3.787087249755859 and perplexity is 44.12767999130147
At time: 436.1559932231903 and batch: 1450, loss is 3.702528405189514 and perplexity is 40.54970092977201
At time: 436.8683919906616 and batch: 1500, loss is 3.7217383861541746 and perplexity is 41.33618994635424
At time: 437.5750939846039 and batch: 1550, loss is 3.7515839195251464 and perplexity is 42.58848533871331
At time: 438.28270411491394 and batch: 1600, loss is 3.82912832736969 and perplexity is 46.0224042747313
At time: 438.9907820224762 and batch: 1650, loss is 3.7795487737655638 and perplexity is 43.79627524796799
At time: 439.6996560096741 and batch: 1700, loss is 3.778457217216492 and perplexity is 43.748495218942054
At time: 440.40830540657043 and batch: 1750, loss is 3.7711701154708863 and perplexity is 43.43085422977695
At time: 441.1104004383087 and batch: 1800, loss is 3.7298628664016724 and perplexity is 41.67339294983458
At time: 441.80971336364746 and batch: 1850, loss is 3.7602992820739747 and perplexity is 42.96128159639589
At time: 442.5167257785797 and batch: 1900, loss is 3.8635780000686646 and perplexity is 47.63548658971936
At time: 443.23030948638916 and batch: 1950, loss is 3.79384259223938 and perplexity is 44.42678672940497
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342248251271802 and perplexity of 76.88019117079642
finished 15 epochs...
Completing Train Step...
At time: 445.89551186561584 and batch: 50, loss is 3.9613704967498777 and perplexity is 52.5292678306165
At time: 446.6130802631378 and batch: 100, loss is 3.951077046394348 and perplexity is 51.99133376850182
At time: 447.32081508636475 and batch: 150, loss is 3.9093972969055177 and perplexity is 49.868886781744195
At time: 448.03546667099 and batch: 200, loss is 3.8889399099349977 and perplexity is 48.8590640519545
At time: 448.7436292171478 and batch: 250, loss is 3.89112238407135 and perplexity is 48.96581414285789
At time: 449.4507987499237 and batch: 300, loss is 3.901950087547302 and perplexity is 49.498882202267666
At time: 450.157940864563 and batch: 350, loss is 3.9114108085632324 and perplexity is 49.969399524467626
At time: 450.8709683418274 and batch: 400, loss is 3.8599200201034547 and perplexity is 47.46155524677031
At time: 451.5816068649292 and batch: 450, loss is 3.9021351194381713 and perplexity is 49.508041921431406
At time: 452.3001654148102 and batch: 500, loss is 3.9206061601638793 and perplexity is 50.43100478112426
At time: 453.0119721889496 and batch: 550, loss is 3.887255964279175 and perplexity is 48.77685727859204
At time: 453.72299885749817 and batch: 600, loss is 3.858643608093262 and perplexity is 47.40101339402458
At time: 454.4316487312317 and batch: 650, loss is 3.8884239912033083 and perplexity is 48.833863246939934
At time: 455.1432180404663 and batch: 700, loss is 3.9339535665512084 and perplexity is 51.10864017372685
At time: 455.846462726593 and batch: 750, loss is 3.875882930755615 and perplexity is 48.22525906365117
At time: 456.55486130714417 and batch: 800, loss is 3.8749974012374877 and perplexity is 48.18257307587146
At time: 457.2637882232666 and batch: 850, loss is 3.895759506225586 and perplexity is 49.19340187265563
At time: 457.97586584091187 and batch: 900, loss is 3.8589037895202636 and perplexity is 47.41334786186091
At time: 458.69288086891174 and batch: 950, loss is 3.955248866081238 and perplexity is 52.20868529872779
At time: 459.43683099746704 and batch: 1000, loss is 3.913048520088196 and perplexity is 50.05130203400036
At time: 460.14885544776917 and batch: 1050, loss is 3.854549150466919 and perplexity is 47.20732874062694
At time: 460.8542420864105 and batch: 1100, loss is 3.8717576932907103 and perplexity is 48.026728193242235
At time: 461.5646631717682 and batch: 1150, loss is 3.8485534143447877 and perplexity is 46.925132885791854
At time: 462.2768623828888 and batch: 1200, loss is 3.883245630264282 and perplexity is 48.581637498609794
At time: 462.9815077781677 and batch: 1250, loss is 3.889267587661743 and perplexity is 48.87507670234511
At time: 463.6876606941223 and batch: 1300, loss is 3.87870192527771 and perplexity is 48.36139760151978
At time: 464.39609956741333 and batch: 1350, loss is 3.7542568397521974 and perplexity is 42.702473235025906
At time: 465.1140763759613 and batch: 1400, loss is 3.7852732610702513 and perplexity is 44.04770543747307
At time: 465.829852104187 and batch: 1450, loss is 3.7010189199447634 and perplexity is 40.488537928477015
At time: 466.544447183609 and batch: 1500, loss is 3.7203853368759154 and perplexity is 41.280297865278314
At time: 467.2529921531677 and batch: 1550, loss is 3.750403742790222 and perplexity is 42.53825304646259
At time: 467.9591951370239 and batch: 1600, loss is 3.82842191696167 and perplexity is 45.98990504959644
At time: 468.6655101776123 and batch: 1650, loss is 3.778667550086975 and perplexity is 43.75769793330351
At time: 469.37321400642395 and batch: 1700, loss is 3.7776812362670897 and perplexity is 43.714560388181056
At time: 470.07922530174255 and batch: 1750, loss is 3.7707105827331544 and perplexity is 43.41090091538243
At time: 470.78667306900024 and batch: 1800, loss is 3.729603338241577 and perplexity is 41.66257893416886
At time: 471.494660615921 and batch: 1850, loss is 3.7602596950531004 and perplexity is 42.959580920907115
At time: 472.20668959617615 and batch: 1900, loss is 3.8634798192977904 and perplexity is 47.63080993050777
At time: 472.9108145236969 and batch: 1950, loss is 3.7936500692367554 and perplexity is 44.418234374315816
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342195448764535 and perplexity of 76.87613181111657
finished 16 epochs...
Completing Train Step...
At time: 475.49398851394653 and batch: 50, loss is 3.9574423456192016 and perplexity is 52.323329670710365
At time: 476.2252883911133 and batch: 100, loss is 3.946808729171753 and perplexity is 51.76989119292806
At time: 476.95750975608826 and batch: 150, loss is 3.904975118637085 and perplexity is 49.6488445658887
At time: 477.7081000804901 and batch: 200, loss is 3.8844854068756103 and perplexity is 48.641905228061766
At time: 478.42052483558655 and batch: 250, loss is 3.886528043746948 and perplexity is 48.74136452220172
At time: 479.1306006908417 and batch: 300, loss is 3.8972681903839113 and perplexity is 49.267675192157334
At time: 479.8471064567566 and batch: 350, loss is 3.9066802310943602 and perplexity is 49.73357364502298
At time: 480.5608537197113 and batch: 400, loss is 3.8552920055389404 and perplexity is 47.24240997274086
At time: 481.2798764705658 and batch: 450, loss is 3.8975997447967528 and perplexity is 49.28401281553363
At time: 481.9883029460907 and batch: 500, loss is 3.916095747947693 and perplexity is 50.204052370304474
At time: 482.6999526023865 and batch: 550, loss is 3.8830155515670777 and perplexity is 48.57046118451125
At time: 483.40621066093445 and batch: 600, loss is 3.8544830560684202 and perplexity is 47.20420870373872
At time: 484.1125590801239 and batch: 650, loss is 3.884304599761963 and perplexity is 48.63311122060868
At time: 484.81880378723145 and batch: 700, loss is 3.9300132513046266 and perplexity is 50.90765225753972
At time: 485.52852988243103 and batch: 750, loss is 3.8723209524154663 and perplexity is 48.05378730605995
At time: 486.24580335617065 and batch: 800, loss is 3.8714431381225585 and perplexity is 48.01162351343172
At time: 486.96010875701904 and batch: 850, loss is 3.892252492904663 and perplexity is 49.02118212197948
At time: 487.6765716075897 and batch: 900, loss is 3.855342888832092 and perplexity is 47.24481388329562
At time: 488.3892271518707 and batch: 950, loss is 3.95172327041626 and perplexity is 52.02494267558621
At time: 489.1036114692688 and batch: 1000, loss is 3.909665198326111 and perplexity is 49.88224851709045
At time: 489.8113648891449 and batch: 1050, loss is 3.8515492343902586 and perplexity is 47.06592292503992
At time: 490.519020318985 and batch: 1100, loss is 3.868956642150879 and perplexity is 47.89239110185845
At time: 491.223347902298 and batch: 1150, loss is 3.8458985328674316 and perplexity is 46.800717446870465
At time: 491.927622795105 and batch: 1200, loss is 3.8807461500167846 and perplexity is 48.46036028343179
At time: 492.63410687446594 and batch: 1250, loss is 3.8870635271072387 and perplexity is 48.76747170121736
At time: 493.34986209869385 and batch: 1300, loss is 3.87658748626709 and perplexity is 48.259248408000694
At time: 494.06456565856934 and batch: 1350, loss is 3.7521026611328123 and perplexity is 42.61058348918549
At time: 494.7806692123413 and batch: 1400, loss is 3.7834207010269165 and perplexity is 43.966179957118875
At time: 495.49524450302124 and batch: 1450, loss is 3.699390912055969 and perplexity is 40.42267589582486
At time: 496.2106845378876 and batch: 1500, loss is 3.7188414669036867 and perplexity is 41.216615624158436
At time: 496.91331720352173 and batch: 1550, loss is 3.7489785051345823 and perplexity is 42.47766910992484
At time: 497.6257154941559 and batch: 1600, loss is 3.827329797744751 and perplexity is 45.93970600716642
At time: 498.3326690196991 and batch: 1650, loss is 3.777421193122864 and perplexity is 43.7031941943637
At time: 499.03737688064575 and batch: 1700, loss is 3.77651939868927 and perplexity is 43.66380066221264
At time: 499.74778962135315 and batch: 1750, loss is 3.7697752618789675 and perplexity is 43.37031677701138
At time: 500.4557909965515 and batch: 1800, loss is 3.728839774131775 and perplexity is 41.630779026352116
At time: 501.1699712276459 and batch: 1850, loss is 3.75969633102417 and perplexity is 42.93538585427336
At time: 501.886723279953 and batch: 1900, loss is 3.862868194580078 and perplexity is 47.60168665699447
At time: 502.60037660598755 and batch: 1950, loss is 3.7929851627349853 and perplexity is 44.388710217972665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342299350472384 and perplexity of 76.88411978747958
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 505.22016286849976 and batch: 50, loss is 3.959062418937683 and perplexity is 52.40816600302782
At time: 505.92519521713257 and batch: 100, loss is 3.9556902265548706 and perplexity is 52.23173323464878
At time: 506.6323800086975 and batch: 150, loss is 3.91659375667572 and perplexity is 50.229060653221936
At time: 507.33978056907654 and batch: 200, loss is 3.8975232553482058 and perplexity is 49.28024325273891
At time: 508.0507698059082 and batch: 250, loss is 3.9043378019332886 and perplexity is 49.61721260878066
At time: 508.7598373889923 and batch: 300, loss is 3.915286173820496 and perplexity is 50.16342491611188
At time: 509.46938252449036 and batch: 350, loss is 3.9241483354568483 and perplexity is 50.60995699320218
At time: 510.1826946735382 and batch: 400, loss is 3.8754948425292968 and perplexity is 48.20654703959038
At time: 510.8895239830017 and batch: 450, loss is 3.9186960554122923 and perplexity is 50.33476821948128
At time: 511.5952651500702 and batch: 500, loss is 3.9369493341445922 and perplexity is 51.261979351290584
At time: 512.2986693382263 and batch: 550, loss is 3.9068749141693115 and perplexity is 49.74325687261819
At time: 513.0078885555267 and batch: 600, loss is 3.8791574573516847 and perplexity is 48.383432787755524
At time: 513.7189953327179 and batch: 650, loss is 3.906143627166748 and perplexity is 49.706893573026775
At time: 514.4567918777466 and batch: 700, loss is 3.9482481861114502 and perplexity is 51.84446538236364
At time: 515.1648361682892 and batch: 750, loss is 3.8883947801589964 and perplexity is 48.83243677963112
At time: 515.8774566650391 and batch: 800, loss is 3.887430353164673 and perplexity is 48.78536416210235
At time: 516.590206861496 and batch: 850, loss is 3.9071571254730224 and perplexity is 49.757296963033966
At time: 517.3005084991455 and batch: 900, loss is 3.8583979272842406 and perplexity is 47.389369305128675
At time: 518.004879951477 and batch: 950, loss is 3.9566289806365966 and perplexity is 52.28078900947029
At time: 518.7106702327728 and batch: 1000, loss is 3.916960892677307 and perplexity is 50.24750493528644
At time: 519.4190192222595 and batch: 1050, loss is 3.8618635606765745 and perplexity is 47.553888402608536
At time: 520.1288673877716 and batch: 1100, loss is 3.8742457818984986 and perplexity is 48.146371728665976
At time: 520.8366162776947 and batch: 1150, loss is 3.855059142112732 and perplexity is 47.231410224061555
At time: 521.5438189506531 and batch: 1200, loss is 3.88977011680603 and perplexity is 48.89964402519816
At time: 522.2557377815247 and batch: 1250, loss is 3.8921891403198243 and perplexity is 49.01807660175262
At time: 522.972177028656 and batch: 1300, loss is 3.8811748361587526 and perplexity is 48.48113902178045
At time: 523.6827285289764 and batch: 1350, loss is 3.75459331035614 and perplexity is 42.71684377948246
At time: 524.3953232765198 and batch: 1400, loss is 3.784436664581299 and perplexity is 44.01087069181548
At time: 525.1075558662415 and batch: 1450, loss is 3.6987928533554078 and perplexity is 40.39850799043879
At time: 525.8210926055908 and batch: 1500, loss is 3.7163146495819093 and perplexity is 41.11260023514079
At time: 526.5277180671692 and batch: 1550, loss is 3.746707215309143 and perplexity is 42.38129949535857
At time: 527.2376594543457 and batch: 1600, loss is 3.825490803718567 and perplexity is 45.8553007963813
At time: 527.9420046806335 and batch: 1650, loss is 3.773056597709656 and perplexity is 43.51286309470838
At time: 528.6455926895142 and batch: 1700, loss is 3.770198440551758 and perplexity is 43.388674054033686
At time: 529.3544752597809 and batch: 1750, loss is 3.763365683555603 and perplexity is 43.09322031910016
At time: 530.0657162666321 and batch: 1800, loss is 3.720891528129578 and perplexity is 41.301198880515564
At time: 530.7783019542694 and batch: 1850, loss is 3.751345701217651 and perplexity is 42.57834119012607
At time: 531.4951100349426 and batch: 1900, loss is 3.856213274002075 and perplexity is 47.28595296948637
At time: 532.201384305954 and batch: 1950, loss is 3.789951481819153 and perplexity is 44.254253088040386
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336693768168605 and perplexity of 76.45434521989647
finished 18 epochs...
Completing Train Step...
At time: 534.8853688240051 and batch: 50, loss is 3.96225323677063 and perplexity is 52.57565798980404
At time: 535.6199958324432 and batch: 100, loss is 3.9506122255325318 and perplexity is 51.9671727276455
At time: 536.3262648582458 and batch: 150, loss is 3.9082840347290038 and perplexity is 49.81340052740994
At time: 537.0436406135559 and batch: 200, loss is 3.889499235153198 and perplexity is 48.88639980269114
At time: 537.7567398548126 and batch: 250, loss is 3.8960260581970214 and perplexity is 49.20651621865615
At time: 538.4703650474548 and batch: 300, loss is 3.9061545515060425 and perplexity is 49.707436590963496
At time: 539.1838958263397 and batch: 350, loss is 3.9144356060028076 and perplexity is 50.12077566186604
At time: 539.8894810676575 and batch: 400, loss is 3.8645042848587035 and perplexity is 47.67963105843214
At time: 540.5967619419098 and batch: 450, loss is 3.907700567245483 and perplexity is 49.78434450540494
At time: 541.3029475212097 and batch: 500, loss is 3.9264819622039795 and perplexity is 50.728199655972304
At time: 542.0087568759918 and batch: 550, loss is 3.8967758798599244 and perplexity is 49.24342616668285
At time: 542.7169938087463 and batch: 600, loss is 3.869743266105652 and perplexity is 47.93007922519747
At time: 543.4216620922089 and batch: 650, loss is 3.8968378925323486 and perplexity is 49.24647997782529
At time: 544.1360790729523 and batch: 700, loss is 3.9401321601867676 and perplexity is 51.42539724154465
At time: 544.8525578975677 and batch: 750, loss is 3.88203227519989 and perplexity is 48.52272646993944
At time: 545.5633406639099 and batch: 800, loss is 3.8805251359939574 and perplexity is 48.44965104774712
At time: 546.2772459983826 and batch: 850, loss is 3.900068850517273 and perplexity is 49.40585060680187
At time: 546.9800260066986 and batch: 900, loss is 3.8533613300323486 and perplexity is 47.15128820052574
At time: 547.6872510910034 and batch: 950, loss is 3.951881103515625 and perplexity is 52.03315458157124
At time: 548.3935585021973 and batch: 1000, loss is 3.912410397529602 and perplexity is 50.019373357373325
At time: 549.103759765625 and batch: 1050, loss is 3.8574172830581666 and perplexity is 47.34291997259957
At time: 549.8158895969391 and batch: 1100, loss is 3.87035306930542 and perplexity is 47.95931605432409
At time: 550.5507464408875 and batch: 1150, loss is 3.8508192920684814 and perplexity is 47.03158005166666
At time: 551.265142917633 and batch: 1200, loss is 3.8853048610687257 and perplexity is 48.68178137736949
At time: 551.9727475643158 and batch: 1250, loss is 3.888782205581665 and perplexity is 48.85135937240046
At time: 552.6835017204285 and batch: 1300, loss is 3.878301124572754 and perplexity is 48.34201820316613
At time: 553.3980188369751 and batch: 1350, loss is 3.7525789594650267 and perplexity is 42.63088367312417
At time: 554.1080718040466 and batch: 1400, loss is 3.7835446405410766 and perplexity is 43.971629441798505
At time: 554.8142764568329 and batch: 1450, loss is 3.6991853094100953 and perplexity is 40.41436574103155
At time: 555.523051738739 and batch: 1500, loss is 3.7178806018829347 and perplexity is 41.177031040697784
At time: 556.2275402545929 and batch: 1550, loss is 3.748636608123779 and perplexity is 42.46314860423046
At time: 556.9407474994659 and batch: 1600, loss is 3.827829704284668 and perplexity is 45.96267730791461
At time: 557.6526942253113 and batch: 1650, loss is 3.775502142906189 and perplexity is 43.6194059926732
At time: 558.3645040988922 and batch: 1700, loss is 3.7738699913024902 and perplexity is 43.54827057691291
At time: 559.0746870040894 and batch: 1750, loss is 3.7679557323455812 and perplexity is 43.291474954027706
At time: 559.7869911193848 and batch: 1800, loss is 3.725115027427673 and perplexity is 41.4760033484257
At time: 560.5038168430328 and batch: 1850, loss is 3.7557557678222655 and perplexity is 42.76652916644272
At time: 561.212938785553 and batch: 1900, loss is 3.860750923156738 and perplexity is 47.50100758620325
At time: 561.9195213317871 and batch: 1950, loss is 3.793795337677002 and perplexity is 44.4246874106418
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335544887808866 and perplexity of 76.3665587619813
finished 19 epochs...
Completing Train Step...
At time: 564.5929226875305 and batch: 50, loss is 3.9616190147399903 and perplexity is 52.542323920949315
At time: 565.3032109737396 and batch: 100, loss is 3.948006682395935 and perplexity is 51.831946263112656
At time: 566.020122051239 and batch: 150, loss is 3.905274667739868 and perplexity is 49.66371906044216
At time: 566.7312190532684 and batch: 200, loss is 3.8860869646072387 and perplexity is 48.719870463708894
At time: 567.4483366012573 and batch: 250, loss is 3.89229208946228 and perplexity is 49.02312323047219
At time: 568.1581814289093 and batch: 300, loss is 3.9021655797958372 and perplexity is 49.509549977063514
At time: 568.8665547370911 and batch: 350, loss is 3.910434145927429 and perplexity is 49.92062010341496
At time: 569.6079308986664 and batch: 400, loss is 3.8602058696746826 and perplexity is 47.475124051213484
At time: 570.3171489238739 and batch: 450, loss is 3.9033432245254516 and perplexity is 49.56788898222829
At time: 571.0263693332672 and batch: 500, loss is 3.9222959423065187 and perplexity is 50.516294232440295
At time: 571.7329800128937 and batch: 550, loss is 3.8926225566864012 and perplexity is 49.0393264430918
At time: 572.4413104057312 and batch: 600, loss is 3.8660965251922605 and perplexity is 47.75560896158164
At time: 573.1541690826416 and batch: 650, loss is 3.893347911834717 and perplexity is 49.074910274894854
At time: 573.8646357059479 and batch: 700, loss is 3.936936364173889 and perplexity is 51.26131448923184
At time: 574.5789341926575 and batch: 750, loss is 3.879457516670227 and perplexity is 48.397952865959994
At time: 575.289078950882 and batch: 800, loss is 3.8778055095672608 and perplexity is 48.31806510979537
At time: 575.9969158172607 and batch: 850, loss is 3.8972622632980345 and perplexity is 49.26738317928091
At time: 576.7118530273438 and batch: 900, loss is 3.8512431621551513 and perplexity is 47.0515195571608
At time: 577.4175066947937 and batch: 950, loss is 3.94988703250885 and perplexity is 51.92950015811627
At time: 578.1283259391785 and batch: 1000, loss is 3.910445604324341 and perplexity is 49.92119211697136
At time: 578.8320608139038 and batch: 1050, loss is 3.8555888605117796 and perplexity is 47.25643619884465
At time: 579.5473608970642 and batch: 1100, loss is 3.8688134765625 and perplexity is 47.885535050294514
At time: 580.2591664791107 and batch: 1150, loss is 3.849308114051819 and perplexity is 46.96056063680826
At time: 580.9713020324707 and batch: 1200, loss is 3.883683023452759 and perplexity is 48.60289142375893
At time: 581.6873917579651 and batch: 1250, loss is 3.8875651931762696 and perplexity is 48.79194282469523
At time: 582.4074945449829 and batch: 1300, loss is 3.8772529268264773 and perplexity is 48.29137275649372
At time: 583.118289232254 and batch: 1350, loss is 3.751735110282898 and perplexity is 42.59492481086524
At time: 583.8320868015289 and batch: 1400, loss is 3.7831942224502564 and perplexity is 43.956223686744536
At time: 584.5386922359467 and batch: 1450, loss is 3.6992943572998045 and perplexity is 40.418773082630835
At time: 585.2555627822876 and batch: 1500, loss is 3.7185166454315186 and perplexity is 41.203229756519924
At time: 585.9632666110992 and batch: 1550, loss is 3.7494517850875853 and perplexity is 42.497777697285144
At time: 586.6784379482269 and batch: 1600, loss is 3.828977084159851 and perplexity is 46.0154442249277
At time: 587.3911385536194 and batch: 1650, loss is 3.7766235780715944 and perplexity is 43.66834976695291
At time: 588.1103439331055 and batch: 1700, loss is 3.775374698638916 and perplexity is 43.61384730365662
At time: 588.8258502483368 and batch: 1750, loss is 3.7697333240509034 and perplexity is 43.368497958262225
At time: 589.5404434204102 and batch: 1800, loss is 3.7268199348449706 and perplexity is 41.54677640778815
At time: 590.2473940849304 and batch: 1850, loss is 3.7575112867355345 and perplexity is 42.8416725557715
At time: 590.9567224979401 and batch: 1900, loss is 3.8623781299591062 and perplexity is 47.578364469621505
At time: 591.6620690822601 and batch: 1950, loss is 3.794993119239807 and perplexity is 44.47793036250314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33509521484375 and perplexity of 76.33222650478953
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7420a98b38>
ELAPSED
2504.767486810684


RESULTS SO FAR:
[{'best_accuracy': -76.72922266508544, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.44533850763699, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.7798990364997814, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3775751613796833, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.6311346728391, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.278968697079667, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.1071481079890072, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.33222650478953, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.20408011909539603, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.046635900383796614, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.13889208123057972, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8005403062602345, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3237407207489014 and batch: 50, loss is 7.515394220352173 and perplexity is 1836.0911581422533
At time: 2.030165433883667 and batch: 100, loss is 6.642093353271484 and perplexity is 766.6982846690962
At time: 2.7419114112854004 and batch: 150, loss is 6.317544622421265 and perplexity is 554.210524353709
At time: 3.4484786987304688 and batch: 200, loss is 6.1289943504333495 and perplexity is 458.9743611472122
At time: 4.1539177894592285 and batch: 250, loss is 5.984811191558838 and perplexity is 397.34749160596976
At time: 4.86149263381958 and batch: 300, loss is 5.878303089141846 and perplexity is 357.2025861871922
At time: 5.568428039550781 and batch: 350, loss is 5.781035013198853 and perplexity is 324.0944589263108
At time: 6.2792980670928955 and batch: 400, loss is 5.6950137424469 and perplexity is 297.3808802989838
At time: 6.989978790283203 and batch: 450, loss is 5.592715969085694 and perplexity is 268.463769748822
At time: 7.707441806793213 and batch: 500, loss is 5.565173921585083 and perplexity is 261.17062296868284
At time: 8.446019887924194 and batch: 550, loss is 5.504958086013794 and perplexity is 245.9081484720723
At time: 9.159916877746582 and batch: 600, loss is 5.505171670913696 and perplexity is 245.96067634872983
At time: 9.873942375183105 and batch: 650, loss is 5.550578336715699 and perplexity is 257.38636885686054
At time: 10.583276510238647 and batch: 700, loss is 5.482663965225219 and perplexity is 240.48650247966967
At time: 11.294669389724731 and batch: 750, loss is 5.406794834136963 and perplexity is 222.91595881706053
At time: 12.001137018203735 and batch: 800, loss is 5.3976766300201415 and perplexity is 220.89260430213625
At time: 12.706894397735596 and batch: 850, loss is 5.399264535903931 and perplexity is 221.24363959994082
At time: 13.421074867248535 and batch: 900, loss is 5.401032314300537 and perplexity is 221.63509522787052
At time: 14.13370394706726 and batch: 950, loss is 5.415739393234253 and perplexity is 224.9187876417892
At time: 14.845521211624146 and batch: 1000, loss is 5.375884284973145 and perplexity is 216.13090914785482
At time: 15.561510801315308 and batch: 1050, loss is 5.274364576339722 and perplexity is 195.266360218173
At time: 16.273263216018677 and batch: 1100, loss is 5.354034433364868 and perplexity is 211.45969931688447
At time: 16.98400568962097 and batch: 1150, loss is 5.248477725982666 and perplexity is 190.2763950689173
At time: 17.689591884613037 and batch: 1200, loss is 5.322567873001098 and perplexity is 204.9093882733276
At time: 18.397151231765747 and batch: 1250, loss is 5.28056957244873 and perplexity is 196.4817540810556
At time: 19.10797905921936 and batch: 1300, loss is 5.289398040771484 and perplexity is 198.22406668218844
At time: 19.818713188171387 and batch: 1350, loss is 5.220173358917236 and perplexity is 184.96624683969708
At time: 20.532554626464844 and batch: 1400, loss is 5.229328336715699 and perplexity is 186.66738377690527
At time: 21.24892830848694 and batch: 1450, loss is 5.1876820373535155 and perplexity is 179.053033295463
At time: 21.96373462677002 and batch: 1500, loss is 5.138774452209472 and perplexity is 170.506676141049
At time: 22.683059453964233 and batch: 1550, loss is 5.134746990203857 and perplexity is 169.8213479741248
At time: 23.39587426185608 and batch: 1600, loss is 5.1644974708557125 and perplexity is 174.94951924541115
At time: 24.10559868812561 and batch: 1650, loss is 5.149544439315796 and perplexity is 172.3529551992614
At time: 24.805696487426758 and batch: 1700, loss is 5.166307144165039 and perplexity is 175.26640736637444
At time: 25.515735864639282 and batch: 1750, loss is 5.155354166030884 and perplexity is 173.3571931167735
At time: 26.228657484054565 and batch: 1800, loss is 5.1172237205505375 and perplexity is 166.8714441645965
At time: 26.937633275985718 and batch: 1850, loss is 5.104700431823731 and perplexity is 164.7946958899682
At time: 27.643906354904175 and batch: 1900, loss is 5.183603954315186 and perplexity is 178.32432702966187
At time: 28.357678174972534 and batch: 1950, loss is 5.114278268814087 and perplexity is 166.3806555315609
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.818055618640988 and perplexity of 123.72428954872073
finished 1 epochs...
Completing Train Step...
At time: 30.983582735061646 and batch: 50, loss is 5.060166568756103 and perplexity is 157.6167681659523
At time: 31.715402126312256 and batch: 100, loss is 4.997579517364502 and perplexity is 148.05436203430094
At time: 32.418156147003174 and batch: 150, loss is 4.9363831043243405 and perplexity is 139.26562828016438
At time: 33.154345750808716 and batch: 200, loss is 4.90299168586731 and perplexity is 134.69213407982602
At time: 33.85922837257385 and batch: 250, loss is 4.917650356292724 and perplexity is 136.68108374625368
At time: 34.56773662567139 and batch: 300, loss is 4.934960737228393 and perplexity is 139.06768224224032
At time: 35.26967406272888 and batch: 350, loss is 4.928001337051391 and perplexity is 138.10321454086332
At time: 35.976794719696045 and batch: 400, loss is 4.869612827301025 and perplexity is 130.27046996179925
At time: 36.68619894981384 and batch: 450, loss is 4.848722524642945 and perplexity is 127.57730883406515
At time: 37.39936137199402 and batch: 500, loss is 4.850826482772828 and perplexity is 127.84600871770772
At time: 38.10931086540222 and batch: 550, loss is 4.8143356418609615 and perplexity is 123.26489306636705
At time: 38.814045429229736 and batch: 600, loss is 4.784117298126221 and perplexity is 119.59574908606525
At time: 39.51639747619629 and batch: 650, loss is 4.851486253738403 and perplexity is 127.93038563398339
At time: 40.22364020347595 and batch: 700, loss is 4.8609484100341795 and perplexity is 129.14662800110523
At time: 40.925572872161865 and batch: 750, loss is 4.8065682220458985 and perplexity is 122.31115174324063
At time: 41.63292908668518 and batch: 800, loss is 4.803793115615845 and perplexity is 121.97219581648763
At time: 42.3379852771759 and batch: 850, loss is 4.807652597427368 and perplexity is 122.44385488207512
At time: 43.043118715286255 and batch: 900, loss is 4.778904552459717 and perplexity is 118.97394891435921
At time: 43.75091195106506 and batch: 950, loss is 4.83455675125122 and perplexity is 125.7828177722108
At time: 44.47282886505127 and batch: 1000, loss is 4.806946783065796 and perplexity is 122.35746274280596
At time: 45.194509506225586 and batch: 1050, loss is 4.736319093704224 and perplexity is 114.01375439499398
At time: 45.9140305519104 and batch: 1100, loss is 4.788577299118042 and perplexity is 120.13033749186513
At time: 46.62081789970398 and batch: 1150, loss is 4.734105129241943 and perplexity is 113.76161121556446
At time: 47.318618297576904 and batch: 1200, loss is 4.798231630325318 and perplexity is 121.29573205881101
At time: 48.04069662094116 and batch: 1250, loss is 4.781905689239502 and perplexity is 119.33154233326489
At time: 48.748939752578735 and batch: 1300, loss is 4.779659585952759 and perplexity is 119.06381215119676
At time: 49.459171533584595 and batch: 1350, loss is 4.676732969284058 and perplexity is 107.4185589496065
At time: 50.17047691345215 and batch: 1400, loss is 4.680568075180053 and perplexity is 107.83131146728239
At time: 50.886109828948975 and batch: 1450, loss is 4.635795087814331 and perplexity is 103.10986681129862
At time: 51.58773875236511 and batch: 1500, loss is 4.61933445930481 and perplexity is 101.426506193966
At time: 52.2899854183197 and batch: 1550, loss is 4.622523021697998 and perplexity is 101.75042708383246
At time: 52.99441933631897 and batch: 1600, loss is 4.684204740524292 and perplexity is 108.22417177848301
At time: 53.70314025878906 and batch: 1650, loss is 4.655855131149292 and perplexity is 105.19914060847607
At time: 54.405117988586426 and batch: 1700, loss is 4.6675875377655025 and perplexity is 106.44064839784104
At time: 55.110924243927 and batch: 1750, loss is 4.656183443069458 and perplexity is 105.23368441058975
At time: 55.81906461715698 and batch: 1800, loss is 4.616154346466065 and perplexity is 101.10447078529681
At time: 56.53074884414673 and batch: 1850, loss is 4.650803813934326 and perplexity is 104.66908624195726
At time: 57.235177516937256 and batch: 1900, loss is 4.753065032958984 and perplexity is 115.93909764798676
At time: 57.9421648979187 and batch: 1950, loss is 4.678861150741577 and perplexity is 107.64740856533622
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.591834347747093 and perplexity of 98.6752690079723
finished 2 epochs...
Completing Train Step...
At time: 60.73960876464844 and batch: 50, loss is 4.668090991973877 and perplexity is 106.49424988203323
At time: 61.45095157623291 and batch: 100, loss is 4.6156880569458005 and perplexity is 101.05733781977571
At time: 62.16347813606262 and batch: 150, loss is 4.565279588699341 and perplexity is 96.08945578719383
At time: 62.864492654800415 and batch: 200, loss is 4.55586802482605 and perplexity is 95.18934610052233
At time: 63.56795120239258 and batch: 250, loss is 4.558121643066406 and perplexity is 95.4041084524644
At time: 64.27804350852966 and batch: 300, loss is 4.577615690231323 and perplexity is 97.28216664559771
At time: 64.9807391166687 and batch: 350, loss is 4.591398677825928 and perplexity is 98.63228852463438
At time: 65.68616819381714 and batch: 400, loss is 4.531019287109375 and perplexity is 92.85315688966054
At time: 66.39110612869263 and batch: 450, loss is 4.535694990158081 and perplexity is 93.28832724928532
At time: 67.09516072273254 and batch: 500, loss is 4.548591270446777 and perplexity is 94.4991907004645
At time: 67.80070090293884 and batch: 550, loss is 4.512913751602173 and perplexity is 91.18712844079865
At time: 68.50775361061096 and batch: 600, loss is 4.485160818099976 and perplexity is 88.69121281846557
At time: 69.27310395240784 and batch: 650, loss is 4.557114572525024 and perplexity is 95.3080781480765
At time: 69.98277831077576 and batch: 700, loss is 4.583983612060547 and perplexity is 97.90362848834772
At time: 70.69256734848022 and batch: 750, loss is 4.530246315002441 and perplexity is 92.78141172142321
At time: 71.3992669582367 and batch: 800, loss is 4.527650003433227 and perplexity is 92.54083471034228
At time: 72.11182975769043 and batch: 850, loss is 4.533437118530274 and perplexity is 93.07793179433044
At time: 72.81734919548035 and batch: 900, loss is 4.496290111541748 and perplexity is 89.68379648387433
At time: 73.52282357215881 and batch: 950, loss is 4.5705575752258305 and perplexity is 96.597955386749
At time: 74.2278459072113 and batch: 1000, loss is 4.5405974864959715 and perplexity is 93.74679583401793
At time: 74.93178582191467 and batch: 1050, loss is 4.481451749801636 and perplexity is 88.36286036992182
At time: 75.6349503993988 and batch: 1100, loss is 4.528720436096191 and perplexity is 92.63994647924777
At time: 76.34423542022705 and batch: 1150, loss is 4.48611572265625 and perplexity is 88.7759449107794
At time: 77.04985165596008 and batch: 1200, loss is 4.5437693023681645 and perplexity is 94.04461547385944
At time: 77.75391960144043 and batch: 1250, loss is 4.543140888214111 and perplexity is 93.98553507180787
At time: 78.45646667480469 and batch: 1300, loss is 4.529975366592407 and perplexity is 92.75627615081184
At time: 79.16557478904724 and batch: 1350, loss is 4.425606269836425 and perplexity is 83.56345386923107
At time: 79.875803232193 and batch: 1400, loss is 4.436396694183349 and perplexity is 84.47002132394263
At time: 80.57804012298584 and batch: 1450, loss is 4.3860500526428225 and perplexity is 80.32252182248433
At time: 81.28502535820007 and batch: 1500, loss is 4.375742950439453 and perplexity is 79.49888134581421
At time: 81.98900270462036 and batch: 1550, loss is 4.389328060150146 and perplexity is 80.58625167008037
At time: 82.69424390792847 and batch: 1600, loss is 4.455222101211548 and perplexity is 86.07526614318905
At time: 83.4050612449646 and batch: 1650, loss is 4.427139749526978 and perplexity is 83.69169503108999
At time: 84.11549854278564 and batch: 1700, loss is 4.433455257415772 and perplexity is 84.22192315887447
At time: 84.82273626327515 and batch: 1750, loss is 4.42623140335083 and perplexity is 83.61570851618794
At time: 85.52827620506287 and batch: 1800, loss is 4.38698444366455 and perplexity is 80.3976095408996
At time: 86.23276424407959 and batch: 1850, loss is 4.433099393844604 and perplexity is 84.1919569767811
At time: 86.93715691566467 and batch: 1900, loss is 4.530768880844116 and perplexity is 92.82990878828288
At time: 87.64190936088562 and batch: 1950, loss is 4.459979028701782 and perplexity is 86.48569536000227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.522978458848111 and perplexity of 92.10953427901357
finished 3 epochs...
Completing Train Step...
At time: 90.28169226646423 and batch: 50, loss is 4.45140682220459 and perplexity is 85.74749066231149
At time: 91.0139729976654 and batch: 100, loss is 4.408063259124756 and perplexity is 82.11028306683515
At time: 91.7187111377716 and batch: 150, loss is 4.362928056716919 and perplexity is 78.48661154824535
At time: 92.42141509056091 and batch: 200, loss is 4.356833143234253 and perplexity is 78.00969729323808
At time: 93.12662506103516 and batch: 250, loss is 4.356196002960205 and perplexity is 77.96001000389373
At time: 93.82893204689026 and batch: 300, loss is 4.368680353164673 and perplexity is 78.93939081684253
At time: 94.53399968147278 and batch: 350, loss is 4.387918481826782 and perplexity is 80.47273905781886
At time: 95.24089074134827 and batch: 400, loss is 4.331341581344605 and perplexity is 76.04624038165254
At time: 95.94847011566162 and batch: 450, loss is 4.347291116714477 and perplexity is 77.26886682590862
At time: 96.65432095527649 and batch: 500, loss is 4.36412938117981 and perplexity is 78.58095609256578
At time: 97.366042137146 and batch: 550, loss is 4.330900011062622 and perplexity is 76.01266803466434
At time: 98.07569217681885 and batch: 600, loss is 4.312331466674805 and perplexity is 74.61424693634608
At time: 98.78279209136963 and batch: 650, loss is 4.379114274978638 and perplexity is 79.76735016881771
At time: 99.48770070075989 and batch: 700, loss is 4.409158697128296 and perplexity is 82.20027907491225
At time: 100.19248604774475 and batch: 750, loss is 4.354928302764892 and perplexity is 77.86124270087699
At time: 100.9034411907196 and batch: 800, loss is 4.352114944458008 and perplexity is 77.64249897346086
At time: 101.61520791053772 and batch: 850, loss is 4.360324211120606 and perplexity is 78.28251036969073
At time: 102.32024025917053 and batch: 900, loss is 4.321642160415649 and perplexity is 75.31220151687047
At time: 103.02689146995544 and batch: 950, loss is 4.402711849212647 and perplexity is 81.67205090992488
At time: 103.73651838302612 and batch: 1000, loss is 4.370755386352539 and perplexity is 79.10336273737057
At time: 104.44378924369812 and batch: 1050, loss is 4.322583217620849 and perplexity is 75.38310796502651
At time: 105.20535230636597 and batch: 1100, loss is 4.361565036773682 and perplexity is 78.37970560544501
At time: 105.91076755523682 and batch: 1150, loss is 4.324976415634155 and perplexity is 75.5637307160415
At time: 106.6181252002716 and batch: 1200, loss is 4.379593119621277 and perplexity is 79.80555548357873
At time: 107.33070516586304 and batch: 1250, loss is 4.384196472167969 and perplexity is 80.1737754636045
At time: 108.03418517112732 and batch: 1300, loss is 4.369987659454345 and perplexity is 79.04265626403748
At time: 108.73549056053162 and batch: 1350, loss is 4.262975430488586 and perplexity is 71.02098739605206
At time: 109.4410490989685 and batch: 1400, loss is 4.27946195602417 and perplexity is 72.20158192838315
At time: 110.1525194644928 and batch: 1450, loss is 4.229307808876038 and perplexity is 68.66968317406877
At time: 110.86426377296448 and batch: 1500, loss is 4.216693878173828 and perplexity is 67.80892871069084
At time: 111.58172106742859 and batch: 1550, loss is 4.239039478302002 and perplexity is 69.34121609871288
At time: 112.29174423217773 and batch: 1600, loss is 4.304047231674194 and perplexity is 73.99867825858601
At time: 113.00023174285889 and batch: 1650, loss is 4.277260084152221 and perplexity is 72.04277819292388
At time: 113.70935463905334 and batch: 1700, loss is 4.282884140014648 and perplexity is 72.44909229760066
At time: 114.41859841346741 and batch: 1750, loss is 4.277593846321106 and perplexity is 72.06682735995386
At time: 115.12617087364197 and batch: 1800, loss is 4.235768537521363 and perplexity is 69.11477562577669
At time: 115.8332154750824 and batch: 1850, loss is 4.28430811882019 and perplexity is 72.55233175746957
At time: 116.54187250137329 and batch: 1900, loss is 4.381076097488403 and perplexity is 79.92399315455103
At time: 117.2497878074646 and batch: 1950, loss is 4.310830612182617 and perplexity is 74.5023458033149
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493365904342297 and perplexity of 89.42192554956233
finished 4 epochs...
Completing Train Step...
At time: 119.92580723762512 and batch: 50, loss is 4.305278596878051 and perplexity is 74.0898537797867
At time: 120.66111040115356 and batch: 100, loss is 4.263242039680481 and perplexity is 71.03992476843592
At time: 121.37263774871826 and batch: 150, loss is 4.224578104019165 and perplexity is 68.34566270466526
At time: 122.08110737800598 and batch: 200, loss is 4.2213489437103275 and perplexity is 68.12531955652086
At time: 122.7914662361145 and batch: 250, loss is 4.216874136924743 and perplexity is 67.82115296521245
At time: 123.55450987815857 and batch: 300, loss is 4.227274670600891 and perplexity is 68.53021004498835
At time: 124.2602264881134 and batch: 350, loss is 4.2421306848526 and perplexity is 69.55589575878078
At time: 124.97076511383057 and batch: 400, loss is 4.189186410903931 and perplexity is 65.96909738280887
At time: 125.67750144004822 and batch: 450, loss is 4.210932469367981 and perplexity is 67.41937701255283
At time: 126.37968325614929 and batch: 500, loss is 4.232407069206237 and perplexity is 68.8828385403826
At time: 127.08608341217041 and batch: 550, loss is 4.201539816856385 and perplexity is 66.78909487599041
At time: 127.78988742828369 and batch: 600, loss is 4.189301276206971 and perplexity is 65.97667537838706
At time: 128.4981381893158 and batch: 650, loss is 4.247795276641845 and perplexity is 69.9510195657787
At time: 129.2078197002411 and batch: 700, loss is 4.280487380027771 and perplexity is 72.27565713634786
At time: 129.9212954044342 and batch: 750, loss is 4.226532559394837 and perplexity is 68.479371874282
At time: 130.62774896621704 and batch: 800, loss is 4.229672255516053 and perplexity is 68.69471417032665
At time: 131.33286571502686 and batch: 850, loss is 4.2327430725097654 and perplexity is 68.90598729049903
At time: 132.0429892539978 and batch: 900, loss is 4.19438175201416 and perplexity is 66.31272119499364
At time: 132.74949169158936 and batch: 950, loss is 4.284468812942505 and perplexity is 72.56399142753834
At time: 133.46271562576294 and batch: 1000, loss is 4.247549304962158 and perplexity is 69.9338157119174
At time: 134.16979384422302 and batch: 1050, loss is 4.20354739189148 and perplexity is 66.92331367755853
At time: 134.8740429878235 and batch: 1100, loss is 4.236711463928223 and perplexity is 69.17997650780424
At time: 135.58219742774963 and batch: 1150, loss is 4.20604868888855 and perplexity is 67.09091828816413
At time: 136.2918736934662 and batch: 1200, loss is 4.260932078361511 and perplexity is 70.87601467598925
At time: 137.00232863426208 and batch: 1250, loss is 4.266517009735107 and perplexity is 71.27295977779077
At time: 137.71480417251587 and batch: 1300, loss is 4.248485236167908 and perplexity is 69.99929959180254
At time: 138.42192792892456 and batch: 1350, loss is 4.141182751655578 and perplexity is 62.87714553504916
At time: 139.1315987110138 and batch: 1400, loss is 4.166881580352783 and perplexity is 64.51395650727956
At time: 139.84440684318542 and batch: 1450, loss is 4.115208392143249 and perplexity is 61.26498007306204
At time: 140.55114364624023 and batch: 1500, loss is 4.105715751647949 and perplexity is 60.68616522931066
At time: 141.25668334960938 and batch: 1550, loss is 4.123160061836242 and perplexity is 61.75408096561014
At time: 141.9673764705658 and batch: 1600, loss is 4.19587043762207 and perplexity is 66.41151350575844
At time: 142.67831945419312 and batch: 1650, loss is 4.16927656173706 and perplexity is 64.66865140389608
At time: 143.38389658927917 and batch: 1700, loss is 4.17287513256073 and perplexity is 64.90178534896583
At time: 144.0944812297821 and batch: 1750, loss is 4.164345774650574 and perplexity is 64.35056889566769
At time: 144.8018183708191 and batch: 1800, loss is 4.125963196754456 and perplexity is 61.927428831527344
At time: 145.50990772247314 and batch: 1850, loss is 4.175474925041199 and perplexity is 65.07073604570019
At time: 146.21310544013977 and batch: 1900, loss is 4.266516494750976 and perplexity is 71.27292307335698
At time: 146.92386603355408 and batch: 1950, loss is 4.201110162734985 and perplexity is 66.76040482995202
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487992823401163 and perplexity of 88.94274280234886
finished 5 epochs...
Completing Train Step...
At time: 149.5764696598053 and batch: 50, loss is 4.196940126419068 and perplexity is 66.4825911664584
At time: 150.2837929725647 and batch: 100, loss is 4.157028665542603 and perplexity is 63.88142723541086
At time: 150.98891592025757 and batch: 150, loss is 4.122957344055176 and perplexity is 61.74156358413577
At time: 151.6992893218994 and batch: 200, loss is 4.117112236022949 and perplexity is 61.38173013209218
At time: 152.40636825561523 and batch: 250, loss is 4.109938654899597 and perplexity is 60.94297890178934
At time: 153.11583590507507 and batch: 300, loss is 4.118694505691528 and perplexity is 61.47892945937995
At time: 153.82223629951477 and batch: 350, loss is 4.135389857292175 and perplexity is 62.51395784270267
At time: 154.5303132534027 and batch: 400, loss is 4.083156599998474 and perplexity is 59.33246341659745
At time: 155.24529647827148 and batch: 450, loss is 4.108220715522766 and perplexity is 60.83837243810128
At time: 155.95413541793823 and batch: 500, loss is 4.133309478759766 and perplexity is 62.38404033248704
At time: 156.66114854812622 and batch: 550, loss is 4.101005954742432 and perplexity is 60.40101773659471
At time: 157.36735105514526 and batch: 600, loss is 4.094364585876465 and perplexity is 60.001201431290355
At time: 158.08204102516174 and batch: 650, loss is 4.148651781082154 and perplexity is 63.34853500479518
At time: 158.79328441619873 and batch: 700, loss is 4.180338468551636 and perplexity is 65.38798124428362
At time: 159.57197332382202 and batch: 750, loss is 4.129881548881531 and perplexity is 62.17055832642673
At time: 160.27919173240662 and batch: 800, loss is 4.131681318283081 and perplexity is 62.28255174591426
At time: 160.99118208885193 and batch: 850, loss is 4.138268046379089 and perplexity is 62.694144014493894
At time: 161.69816660881042 and batch: 900, loss is 4.09892560005188 and perplexity is 60.27549280948907
At time: 162.4027509689331 and batch: 950, loss is 4.193393502235413 and perplexity is 66.24722003402938
At time: 163.10868072509766 and batch: 1000, loss is 4.151249189376831 and perplexity is 63.513290891598224
At time: 163.8142523765564 and batch: 1050, loss is 4.115266942977906 and perplexity is 61.26856729379688
At time: 164.5239360332489 and batch: 1100, loss is 4.142753872871399 and perplexity is 62.97601079670781
At time: 165.23118948936462 and batch: 1150, loss is 4.114228091239929 and perplexity is 61.20495138565001
At time: 165.9369089603424 and batch: 1200, loss is 4.169746613502502 and perplexity is 64.69905616300274
At time: 166.6454954147339 and batch: 1250, loss is 4.175114870071411 and perplexity is 65.0473112211645
At time: 167.3553466796875 and batch: 1300, loss is 4.153373069763184 and perplexity is 63.648328875897235
At time: 168.06389617919922 and batch: 1350, loss is 4.04930212020874 and perplexity is 57.3574144941733
At time: 168.76762866973877 and batch: 1400, loss is 4.078236246109009 and perplexity is 59.04124373892355
At time: 169.471914768219 and batch: 1450, loss is 4.026388974189758 and perplexity is 56.058118010672494
At time: 170.1810872554779 and batch: 1500, loss is 4.01893223285675 and perplexity is 55.641661758010656
At time: 170.88865995407104 and batch: 1550, loss is 4.035639095306396 and perplexity is 56.579068102992196
At time: 171.60002875328064 and batch: 1600, loss is 4.11055585861206 and perplexity is 60.98060474482664
At time: 172.30576348304749 and batch: 1650, loss is 4.086521925926209 and perplexity is 59.532472853796264
At time: 173.01415991783142 and batch: 1700, loss is 4.08438099861145 and perplexity is 59.40515449485563
At time: 173.7248649597168 and batch: 1750, loss is 4.077924489974976 and perplexity is 59.02284013789378
At time: 174.43018460273743 and batch: 1800, loss is 4.038634567260742 and perplexity is 56.748803206151024
At time: 175.13956093788147 and batch: 1850, loss is 4.091035823822022 and perplexity is 59.80180376655631
At time: 175.84472608566284 and batch: 1900, loss is 4.178198680877686 and perplexity is 65.24821443696749
At time: 176.55224204063416 and batch: 1950, loss is 4.115544843673706 and perplexity is 61.28559623734654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487124420875727 and perplexity of 88.865538227056
finished 6 epochs...
Completing Train Step...
At time: 179.18645000457764 and batch: 50, loss is 4.110625448226929 and perplexity is 60.98484850928456
At time: 179.91691303253174 and batch: 100, loss is 4.073518419265747 and perplexity is 58.76335340901896
At time: 180.622314453125 and batch: 150, loss is 4.039600186347961 and perplexity is 56.80362739908734
At time: 181.32834577560425 and batch: 200, loss is 4.03621922492981 and perplexity is 56.611900819158684
At time: 182.03551983833313 and batch: 250, loss is 4.0280003213882445 and perplexity is 56.14851991695037
At time: 182.74336051940918 and batch: 300, loss is 4.032376379966736 and perplexity is 56.3947675332316
At time: 183.45225930213928 and batch: 350, loss is 4.05370936870575 and perplexity is 57.610760742852385
At time: 184.1668357849121 and batch: 400, loss is 3.9987745332717894 and perplexity is 54.53128279701158
At time: 184.87031602859497 and batch: 450, loss is 4.027038044929505 and perplexity is 56.094515505795194
At time: 185.58012700080872 and batch: 500, loss is 4.0563186836242675 and perplexity is 57.76128165315215
At time: 186.28647685050964 and batch: 550, loss is 4.0239682865142825 and perplexity is 55.92258292553203
At time: 186.99403429031372 and batch: 600, loss is 4.016343894004822 and perplexity is 55.49782850799204
At time: 187.6985821723938 and batch: 650, loss is 4.068792719841003 and perplexity is 58.48631058974566
At time: 188.41224884986877 and batch: 700, loss is 4.099887690544128 and perplexity is 60.33351119302904
At time: 189.12090468406677 and batch: 750, loss is 4.052135601043701 and perplexity is 57.520166096769735
At time: 189.8283338546753 and batch: 800, loss is 4.0572221040725704 and perplexity is 57.813487954687204
At time: 190.53583073616028 and batch: 850, loss is 4.059341607093811 and perplexity is 57.936153766434
At time: 191.247722864151 and batch: 900, loss is 4.023446097373962 and perplexity is 55.89338838322953
At time: 191.95879340171814 and batch: 950, loss is 4.115433773994446 and perplexity is 61.278789643839275
At time: 192.66613054275513 and batch: 1000, loss is 4.0788476848602295 and perplexity is 59.077354882016856
At time: 193.37726020812988 and batch: 1050, loss is 4.039688982963562 and perplexity is 56.80867159290459
At time: 194.08598709106445 and batch: 1100, loss is 4.065531520843506 and perplexity is 58.29588576767313
At time: 194.80005598068237 and batch: 1150, loss is 4.037224178314209 and perplexity is 56.66882173712822
At time: 195.50655841827393 and batch: 1200, loss is 4.096162104606629 and perplexity is 60.10915170695036
At time: 196.27956771850586 and batch: 1250, loss is 4.1024705600738525 and perplexity is 60.48954620300194
At time: 196.98930978775024 and batch: 1300, loss is 4.078762440681458 and perplexity is 59.0723190960547
At time: 197.6995403766632 and batch: 1350, loss is 3.9722791481018067 and perplexity is 53.105428151670516
At time: 198.41205143928528 and batch: 1400, loss is 4.006588888168335 and perplexity is 54.95907889209189
At time: 199.12279343605042 and batch: 1450, loss is 3.9522349548339846 and perplexity is 52.05156983985788
At time: 199.8330361843109 and batch: 1500, loss is 3.9486907386779784 and perplexity is 51.867414361269084
At time: 200.5442373752594 and batch: 1550, loss is 3.9691307401657103 and perplexity is 52.93849352727069
At time: 201.24699068069458 and batch: 1600, loss is 4.0415511274337765 and perplexity is 56.91455610210125
At time: 201.95304083824158 and batch: 1650, loss is 4.013114795684815 and perplexity is 55.318909592045
At time: 202.6567907333374 and batch: 1700, loss is 4.014585995674134 and perplexity is 55.40035466755289
At time: 203.3604497909546 and batch: 1750, loss is 4.005891156196594 and perplexity is 54.92074556036217
At time: 204.0752351284027 and batch: 1800, loss is 3.9672026205062867 and perplexity is 52.83652011722056
At time: 204.79130864143372 and batch: 1850, loss is 4.022067742347717 and perplexity is 55.816400520910015
At time: 205.50133538246155 and batch: 1900, loss is 4.107717099189759 and perplexity is 60.807740953973166
At time: 206.21392679214478 and batch: 1950, loss is 4.0436883592605595 and perplexity is 57.03632578147582
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.498854810138082 and perplexity of 89.91410359875698
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 208.8646261692047 and batch: 50, loss is 4.08181137084961 and perplexity is 59.25270131851359
At time: 209.60683155059814 and batch: 100, loss is 4.066290516853332 and perplexity is 58.34014890800861
At time: 210.31808161735535 and batch: 150, loss is 4.041166372299195 and perplexity is 56.89266214658451
At time: 211.0277454853058 and batch: 200, loss is 4.03821496963501 and perplexity is 56.72499653802254
At time: 211.73717331886292 and batch: 250, loss is 4.02075605392456 and perplexity is 55.74323479033562
At time: 212.445228099823 and batch: 300, loss is 4.028681221008301 and perplexity is 56.186764441692155
At time: 213.1551902294159 and batch: 350, loss is 4.0278526782989506 and perplexity is 56.14023058795667
At time: 213.86299228668213 and batch: 400, loss is 3.9744060325622557 and perplexity is 53.21849746162724
At time: 214.59369111061096 and batch: 450, loss is 3.9983127737045288 and perplexity is 54.506108268202134
At time: 215.30439567565918 and batch: 500, loss is 4.017640905380249 and perplexity is 55.56985652335868
At time: 216.01421761512756 and batch: 550, loss is 3.985891318321228 and perplexity is 53.833250662980205
At time: 216.7351758480072 and batch: 600, loss is 3.954850926399231 and perplexity is 52.18791352433277
At time: 217.44962644577026 and batch: 650, loss is 3.9951339864730837 and perplexity is 54.33312003925608
At time: 218.1644425392151 and batch: 700, loss is 4.042774653434753 and perplexity is 56.984235159703005
At time: 218.87206554412842 and batch: 750, loss is 3.9821021699905397 and perplexity is 53.62965446279286
At time: 219.57513403892517 and batch: 800, loss is 3.978932991027832 and perplexity is 53.45996152576383
At time: 220.28258180618286 and batch: 850, loss is 3.9784131908416747 and perplexity is 53.43218024879276
At time: 220.9886326789856 and batch: 900, loss is 3.9398977041244505 and perplexity is 51.41334165871177
At time: 221.69184231758118 and batch: 950, loss is 4.027947063446045 and perplexity is 56.145529641950695
At time: 222.3981065750122 and batch: 1000, loss is 3.9844904708862305 and perplexity is 53.757891287688786
At time: 223.11299467086792 and batch: 1050, loss is 3.9362270069122314 and perplexity is 51.2249647975399
At time: 223.82206869125366 and batch: 1100, loss is 3.957259750366211 and perplexity is 52.313776551295504
At time: 224.53203201293945 and batch: 1150, loss is 3.9232101964950563 and perplexity is 50.56250008476024
At time: 225.2377209663391 and batch: 1200, loss is 3.9613385343551637 and perplexity is 52.52758889625558
At time: 225.94641160964966 and batch: 1250, loss is 3.962997784614563 and perplexity is 52.61481765891832
At time: 226.6508994102478 and batch: 1300, loss is 3.9499466228485107 and perplexity is 51.93259474687198
At time: 227.3529336452484 and batch: 1350, loss is 3.834605031013489 and perplexity is 46.275146810165886
At time: 228.0619056224823 and batch: 1400, loss is 3.856601190567017 and perplexity is 47.30429953217
At time: 228.7706961631775 and batch: 1450, loss is 3.7951587295532225 and perplexity is 44.485296976467325
At time: 229.4970099925995 and batch: 1500, loss is 3.802118282318115 and perplexity is 44.79597458265235
At time: 230.2052617073059 and batch: 1550, loss is 3.8051501274108888 and perplexity is 44.93199513078979
At time: 230.90871238708496 and batch: 1600, loss is 3.8708830738067626 and perplexity is 47.984741444904756
At time: 231.62032651901245 and batch: 1650, loss is 3.8407659339904785 and perplexity is 46.561123532768995
At time: 232.32893013954163 and batch: 1700, loss is 3.826068682670593 and perplexity is 45.88180726757861
At time: 233.03552532196045 and batch: 1750, loss is 3.8060158014297487 and perplexity is 44.970908432276985
At time: 233.75012707710266 and batch: 1800, loss is 3.7620339298248293 and perplexity is 43.03586895958902
At time: 234.45678567886353 and batch: 1850, loss is 3.80480694770813 and perplexity is 44.91657802762619
At time: 235.16337060928345 and batch: 1900, loss is 3.8884048509597777 and perplexity is 48.83292856384991
At time: 235.87613487243652 and batch: 1950, loss is 3.8172836542129516 and perplexity is 45.48049961558065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.430897699400436 and perplexity of 84.0067959216915
finished 8 epochs...
Completing Train Step...
At time: 238.59299683570862 and batch: 50, loss is 3.9978861904144285 and perplexity is 54.4828618318297
At time: 239.30178689956665 and batch: 100, loss is 3.9707203006744383 and perplexity is 53.022709381338736
At time: 240.00909948349 and batch: 150, loss is 3.9427748250961305 and perplexity is 51.56147706177303
At time: 240.71486139297485 and batch: 200, loss is 3.9322191095352172 and perplexity is 51.02007126588535
At time: 241.42013835906982 and batch: 250, loss is 3.918036403656006 and perplexity is 50.30157575016199
At time: 242.12685012817383 and batch: 300, loss is 3.924333257675171 and perplexity is 50.6193167641067
At time: 242.83150696754456 and batch: 350, loss is 3.9324438190460205 and perplexity is 51.03153724935017
At time: 243.5372290611267 and batch: 400, loss is 3.8789032649993898 and perplexity is 48.371135652148226
At time: 244.24343276023865 and batch: 450, loss is 3.907391753196716 and perplexity is 49.76897277403847
At time: 244.95063757896423 and batch: 500, loss is 3.9332586240768435 and perplexity is 51.07313494733695
At time: 245.65301823616028 and batch: 550, loss is 3.903249659538269 and perplexity is 49.56325138029297
At time: 246.35625982284546 and batch: 600, loss is 3.876691150665283 and perplexity is 48.26425143325748
At time: 247.06062746047974 and batch: 650, loss is 3.9192657804489137 and perplexity is 50.36345336769612
At time: 247.76224994659424 and batch: 700, loss is 3.9644270038604734 and perplexity is 52.69006953183949
At time: 248.46908283233643 and batch: 750, loss is 3.909513301849365 and perplexity is 49.87467215471448
At time: 249.1755039691925 and batch: 800, loss is 3.9078847646713255 and perplexity is 49.793515498120776
At time: 249.92983222007751 and batch: 850, loss is 3.9096221685409547 and perplexity is 49.88010214083303
At time: 250.63642001152039 and batch: 900, loss is 3.872452907562256 and perplexity is 48.06012866899627
At time: 251.34185528755188 and batch: 950, loss is 3.9645097255706787 and perplexity is 52.69442832478292
At time: 252.04520750045776 and batch: 1000, loss is 3.922953577041626 and perplexity is 50.549526428341935
At time: 252.7476348876953 and batch: 1050, loss is 3.8776755905151368 and perplexity is 48.31178808033753
At time: 253.45062470436096 and batch: 1100, loss is 3.8978527307510378 and perplexity is 49.296482555814826
At time: 254.154141664505 and batch: 1150, loss is 3.8698999977111814 and perplexity is 47.93759197219466
At time: 254.86472153663635 and batch: 1200, loss is 3.9106190824508666 and perplexity is 49.92985310307784
At time: 255.56746864318848 and batch: 1250, loss is 3.91470694065094 and perplexity is 50.13437701006945
At time: 256.2699465751648 and batch: 1300, loss is 3.903198971748352 and perplexity is 49.56073919228857
At time: 256.9811384677887 and batch: 1350, loss is 3.7862807655334474 and perplexity is 44.09210606045199
At time: 257.6892373561859 and batch: 1400, loss is 3.8152982807159423 and perplexity is 45.390293413145464
At time: 258.39297914505005 and batch: 1450, loss is 3.7556474876403807 and perplexity is 42.761898649587124
At time: 259.1017007827759 and batch: 1500, loss is 3.765527381896973 and perplexity is 43.18647562058882
At time: 259.8124876022339 and batch: 1550, loss is 3.773007607460022 and perplexity is 43.51073144089863
At time: 260.51978158950806 and batch: 1600, loss is 3.8425313997268677 and perplexity is 46.6433982062024
At time: 261.2312843799591 and batch: 1650, loss is 3.8108659315109255 and perplexity is 45.18955298669575
At time: 261.9384162425995 and batch: 1700, loss is 3.8046664953231812 and perplexity is 44.910269830129536
At time: 262.6410701274872 and batch: 1750, loss is 3.787909164428711 and perplexity is 44.1639640881384
At time: 263.345130443573 and batch: 1800, loss is 3.745037803649902 and perplexity is 42.31060668396704
At time: 264.05116629600525 and batch: 1850, loss is 3.7915327835083006 and perplexity is 44.32428777158861
At time: 264.7645881175995 and batch: 1900, loss is 3.8781082105636595 and perplexity is 48.3326932501128
At time: 265.47537446022034 and batch: 1950, loss is 3.808124861717224 and perplexity is 45.06585487803774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.430746105105378 and perplexity of 83.99406193590784
finished 9 epochs...
Completing Train Step...
At time: 268.07866525650024 and batch: 50, loss is 3.9530148029327394 and perplexity is 52.09217798967089
At time: 268.8144562244415 and batch: 100, loss is 3.9262257385253907 and perplexity is 50.71520355507375
At time: 269.5188374519348 and batch: 150, loss is 3.8971340608596803 and perplexity is 49.26106738548473
At time: 270.22773933410645 and batch: 200, loss is 3.8852889490127565 and perplexity is 48.681006756302445
At time: 270.9369840621948 and batch: 250, loss is 3.8720825338363647 and perplexity is 48.04233175603224
At time: 271.6425166130066 and batch: 300, loss is 3.8782005596160887 and perplexity is 48.337156934641136
At time: 272.35065960884094 and batch: 350, loss is 3.888783473968506 and perplexity is 48.85142133486114
At time: 273.05315041542053 and batch: 400, loss is 3.8350757217407225 and perplexity is 46.296933219599026
At time: 273.76189970970154 and batch: 450, loss is 3.8658278799057006 and perplexity is 47.74278136544108
At time: 274.4657166004181 and batch: 500, loss is 3.8935939025878907 and perplexity is 49.08698373395407
At time: 275.16756653785706 and batch: 550, loss is 3.8636011505126953 and perplexity is 47.63658938515058
At time: 275.8758466243744 and batch: 600, loss is 3.837915453910828 and perplexity is 46.42859095812285
At time: 276.5781500339508 and batch: 650, loss is 3.880626091957092 and perplexity is 48.45454257584249
At time: 277.2864725589752 and batch: 700, loss is 3.924636011123657 and perplexity is 50.63464425692563
At time: 277.99401593208313 and batch: 750, loss is 3.871776571273804 and perplexity is 48.02763484956301
At time: 278.69923305511475 and batch: 800, loss is 3.8705470085144045 and perplexity is 47.96861814813432
At time: 279.40250158309937 and batch: 850, loss is 3.874215006828308 and perplexity is 48.14489004349621
At time: 280.10611605644226 and batch: 900, loss is 3.8370323514938356 and perplexity is 46.3876078560319
At time: 280.8118944168091 and batch: 950, loss is 3.9311074113845823 and perplexity is 50.96338386249276
At time: 281.5167169570923 and batch: 1000, loss is 3.8887392902374267 and perplexity is 48.84926294448127
At time: 282.229615688324 and batch: 1050, loss is 3.8454846000671385 and perplexity is 46.78134910371477
At time: 282.9342415332794 and batch: 1100, loss is 3.864256443977356 and perplexity is 47.66781556089044
At time: 283.63896775245667 and batch: 1150, loss is 3.839319987297058 and perplexity is 46.493847280813426
At time: 284.34426641464233 and batch: 1200, loss is 3.8803675985336303 and perplexity is 48.442019013948716
At time: 285.05294156074524 and batch: 1250, loss is 3.8858467388153075 and perplexity is 48.70816809990505
At time: 285.758873462677 and batch: 1300, loss is 3.8750824975967406 and perplexity is 48.18667341187901
At time: 286.4659399986267 and batch: 1350, loss is 3.756649079322815 and perplexity is 42.80475006782937
At time: 287.17178750038147 and batch: 1400, loss is 3.7894779872894286 and perplexity is 44.233303901340214
At time: 287.8778307437897 and batch: 1450, loss is 3.729746489524841 and perplexity is 41.66854341270857
At time: 288.5851128101349 and batch: 1500, loss is 3.7407146883010864 and perplexity is 42.12808786002123
At time: 289.2911477088928 and batch: 1550, loss is 3.7507334423065184 and perplexity is 42.55228020016193
At time: 289.9948945045471 and batch: 1600, loss is 3.8210028266906737 and perplexity is 45.649964377022535
At time: 290.69861102104187 and batch: 1650, loss is 3.7884780168533325 and perplexity is 44.189094013122556
At time: 291.40179538726807 and batch: 1700, loss is 3.7855418920516968 and perplexity is 44.05953960525605
At time: 292.10840940475464 and batch: 1750, loss is 3.7708385944366456 and perplexity is 43.41645837446101
At time: 292.8164439201355 and batch: 1800, loss is 3.727398715019226 and perplexity is 41.570829818424336
At time: 293.5206108093262 and batch: 1850, loss is 3.775525116920471 and perplexity is 43.62040811704082
At time: 294.2271406650543 and batch: 1900, loss is 3.863128981590271 and perplexity is 47.61410217737074
At time: 294.93096685409546 and batch: 1950, loss is 3.793010392189026 and perplexity is 44.38983013502442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.433972451853197 and perplexity of 84.26549353524847
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 297.6246688365936 and batch: 50, loss is 3.9527381801605226 and perplexity is 52.077770099851655
At time: 298.37456917762756 and batch: 100, loss is 3.9598668098449705 and perplexity is 52.45033961498925
At time: 299.08258962631226 and batch: 150, loss is 3.945030436515808 and perplexity is 51.67791098372513
At time: 299.7855854034424 and batch: 200, loss is 3.938018012046814 and perplexity is 51.31679117872524
At time: 300.4927251338959 and batch: 250, loss is 3.927287974357605 and perplexity is 50.76910368378387
At time: 301.19957423210144 and batch: 300, loss is 3.9388467407226564 and perplexity is 51.35933650195699
At time: 301.9021987915039 and batch: 350, loss is 3.9450161457061768 and perplexity is 51.67717246981411
At time: 302.607369184494 and batch: 400, loss is 3.883145322799683 and perplexity is 48.57676464212226
At time: 303.31854152679443 and batch: 450, loss is 3.905013585090637 and perplexity is 49.65075441759449
At time: 304.022588968277 and batch: 500, loss is 3.9356093788146973 and perplexity is 51.193336588226536
At time: 304.76333689689636 and batch: 550, loss is 3.915729637145996 and perplexity is 50.18567548863546
At time: 305.46750235557556 and batch: 600, loss is 3.873675742149353 and perplexity is 48.11893420398632
At time: 306.1716275215149 and batch: 650, loss is 3.898713641166687 and perplexity is 49.33894068480237
At time: 306.87338304519653 and batch: 700, loss is 3.9440610361099244 and perplexity is 51.627838669824236
At time: 307.5795488357544 and batch: 750, loss is 3.893575043678284 and perplexity is 49.08605801569401
At time: 308.2844693660736 and batch: 800, loss is 3.8951739501953124 and perplexity is 49.16460481150865
At time: 308.98490381240845 and batch: 850, loss is 3.901186618804932 and perplexity is 49.46110577531949
At time: 309.6916296482086 and batch: 900, loss is 3.8548155879974364 and perplexity is 47.219908220467275
At time: 310.39401602745056 and batch: 950, loss is 3.95084584236145 and perplexity is 51.979314551958005
At time: 311.09898114204407 and batch: 1000, loss is 3.8974469232559206 and perplexity is 49.2764817322273
At time: 311.8013393878937 and batch: 1050, loss is 3.8489125776290893 and perplexity is 46.94198969762815
At time: 312.5043020248413 and batch: 1100, loss is 3.8707733488082887 and perplexity is 47.979476608070335
At time: 313.2102265357971 and batch: 1150, loss is 3.8448635005950926 and perplexity is 46.752302253910166
At time: 313.91864490509033 and batch: 1200, loss is 3.8779637908935545 and perplexity is 48.32571356251255
At time: 314.62669110298157 and batch: 1250, loss is 3.878781409263611 and perplexity is 48.36524171093544
At time: 315.3357493877411 and batch: 1300, loss is 3.8791841506958007 and perplexity is 48.384724320614026
At time: 316.0401027202606 and batch: 1350, loss is 3.756903486251831 and perplexity is 42.815641278182376
At time: 316.7453291416168 and batch: 1400, loss is 3.7751875925064087 and perplexity is 43.60568764874842
At time: 317.45194840431213 and batch: 1450, loss is 3.7083843469619753 and perplexity is 40.78785424271075
At time: 318.1611385345459 and batch: 1500, loss is 3.7310289192199706 and perplexity is 41.722014669369166
At time: 318.86504793167114 and batch: 1550, loss is 3.734178605079651 and perplexity is 41.85363307852149
At time: 319.56675839424133 and batch: 1600, loss is 3.8071995401382446 and perplexity is 45.0241737572382
At time: 320.2689824104309 and batch: 1650, loss is 3.77076446056366 and perplexity is 43.4132398635522
At time: 320.977303981781 and batch: 1700, loss is 3.7558014965057374 and perplexity is 42.76848486823366
At time: 321.6814646720886 and batch: 1750, loss is 3.734472336769104 and perplexity is 41.86592862258246
At time: 322.38642144203186 and batch: 1800, loss is 3.684944958686829 and perplexity is 39.8429293823535
At time: 323.09295105934143 and batch: 1850, loss is 3.730408101081848 and perplexity is 41.696120924388325
At time: 323.80338644981384 and batch: 1900, loss is 3.8227638578414918 and perplexity is 45.730426213430164
At time: 324.50549244880676 and batch: 1950, loss is 3.756528058052063 and perplexity is 42.799570096031644
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.390245162609012 and perplexity of 80.66019141961841
finished 11 epochs...
Completing Train Step...
At time: 327.20471692085266 and batch: 50, loss is 3.9458160400390625 and perplexity is 51.71852528394821
At time: 327.90500926971436 and batch: 100, loss is 3.9323841381072997 and perplexity is 51.0284917301834
At time: 328.61368775367737 and batch: 150, loss is 3.904496021270752 and perplexity is 49.625063632361886
At time: 329.3207015991211 and batch: 200, loss is 3.893168921470642 and perplexity is 49.06612712491087
At time: 330.04635739326477 and batch: 250, loss is 3.8823683929443358 and perplexity is 48.539038560552854
At time: 330.76980686187744 and batch: 300, loss is 3.8940144872665403 and perplexity is 49.10763330937682
At time: 331.4805407524109 and batch: 350, loss is 3.903291254043579 and perplexity is 49.56531298209104
At time: 332.18659472465515 and batch: 400, loss is 3.840530524253845 and perplexity is 46.55016388099577
At time: 332.89129543304443 and batch: 450, loss is 3.866185927391052 and perplexity is 47.759878608882524
At time: 333.59555220603943 and batch: 500, loss is 3.897736096382141 and perplexity is 49.29073322697429
At time: 334.3033766746521 and batch: 550, loss is 3.8783742332458497 and perplexity is 48.34555255316598
At time: 335.008483171463 and batch: 600, loss is 3.840192437171936 and perplexity is 46.53442853203585
At time: 335.7237660884857 and batch: 650, loss is 3.8665495920181274 and perplexity is 47.77725034587766
At time: 336.4369626045227 and batch: 700, loss is 3.9129286003112793 and perplexity is 50.045300252899374
At time: 337.1479253768921 and batch: 750, loss is 3.867339057922363 and perplexity is 47.81498374868155
At time: 337.86288237571716 and batch: 800, loss is 3.8686003494262695 and perplexity is 47.87533043082168
At time: 338.57057762145996 and batch: 850, loss is 3.8746360445022585 and perplexity is 48.16516512399957
At time: 339.2766652107239 and batch: 900, loss is 3.827160906791687 and perplexity is 45.931947861594146
At time: 339.9819846153259 and batch: 950, loss is 3.925737557411194 and perplexity is 50.69045139275619
At time: 340.7383668422699 and batch: 1000, loss is 3.874246678352356 and perplexity is 48.14641488968598
At time: 341.44217109680176 and batch: 1050, loss is 3.8288792610168456 and perplexity is 46.010943069708986
At time: 342.148889541626 and batch: 1100, loss is 3.8506200170516967 and perplexity is 47.02220876652496
At time: 342.86266016960144 and batch: 1150, loss is 3.8278736543655394 and perplexity is 45.96469741569099
At time: 343.57017612457275 and batch: 1200, loss is 3.861782865524292 and perplexity is 47.5500511891666
At time: 344.2770311832428 and batch: 1250, loss is 3.864799966812134 and perplexity is 47.69373114935083
At time: 344.98596239089966 and batch: 1300, loss is 3.865716423988342 and perplexity is 47.73746044647621
At time: 345.69418573379517 and batch: 1350, loss is 3.742863664627075 and perplexity is 42.21871746905566
At time: 346.39643955230713 and batch: 1400, loss is 3.7625894021987913 and perplexity is 43.05978083646419
At time: 347.097608089447 and batch: 1450, loss is 3.6978148126602175 and perplexity is 40.35901592117266
At time: 347.799081325531 and batch: 1500, loss is 3.7209411239624024 and perplexity is 41.303247298666776
At time: 348.500853061676 and batch: 1550, loss is 3.727493643760681 and perplexity is 41.57477627229323
At time: 349.20412611961365 and batch: 1600, loss is 3.802733917236328 and perplexity is 44.82356103952259
At time: 349.9053452014923 and batch: 1650, loss is 3.766568102836609 and perplexity is 43.231444085829175
At time: 350.6175262928009 and batch: 1700, loss is 3.754932556152344 and perplexity is 42.7313377475316
At time: 351.3298144340515 and batch: 1750, loss is 3.7339991664886476 and perplexity is 41.8461235953392
At time: 352.0423526763916 and batch: 1800, loss is 3.6864540672302244 and perplexity is 39.90310207962427
At time: 352.75352215766907 and batch: 1850, loss is 3.733473711013794 and perplexity is 41.824141096512605
At time: 353.46170806884766 and batch: 1900, loss is 3.826442723274231 and perplexity is 45.898972136443795
At time: 354.170480966568 and batch: 1950, loss is 3.7592719650268553 and perplexity is 42.917169401930096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389383289425872 and perplexity of 80.59070251330088
finished 12 epochs...
Completing Train Step...
At time: 356.7701225280762 and batch: 50, loss is 3.9316640377044676 and perplexity is 50.9917593198316
At time: 357.50634574890137 and batch: 100, loss is 3.917322430610657 and perplexity is 50.26567459869009
At time: 358.2148668766022 and batch: 150, loss is 3.8879665327072144 and perplexity is 48.811528890210646
At time: 358.9649338722229 and batch: 200, loss is 3.875698561668396 and perplexity is 48.21636863624188
At time: 359.67736887931824 and batch: 250, loss is 3.864579701423645 and perplexity is 47.683227028020376
At time: 360.38507986068726 and batch: 300, loss is 3.875764923095703 and perplexity is 48.21956844945506
At time: 361.08844661712646 and batch: 350, loss is 3.8863666963577272 and perplexity is 48.73350086469637
At time: 361.7930381298065 and batch: 400, loss is 3.822400155067444 and perplexity is 45.713796954795
At time: 362.4993643760681 and batch: 450, loss is 3.849004945755005 and perplexity is 46.94632584150092
At time: 363.2096014022827 and batch: 500, loss is 3.8809354305267334 and perplexity is 48.469533753290676
At time: 363.9198274612427 and batch: 550, loss is 3.8614683628082274 and perplexity is 47.535098920306424
At time: 364.6301021575928 and batch: 600, loss is 3.824692406654358 and perplexity is 45.818704669910986
At time: 365.3392632007599 and batch: 650, loss is 3.851307611465454 and perplexity is 47.05455209286633
At time: 366.04658031463623 and batch: 700, loss is 3.8971345615386963 and perplexity is 49.26109204947365
At time: 366.76134419441223 and batch: 750, loss is 3.853672833442688 and perplexity is 47.16597827548755
At time: 367.467901468277 and batch: 800, loss is 3.8554499769210815 and perplexity is 47.24987351103714
At time: 368.1710603237152 and batch: 850, loss is 3.8619674587249757 and perplexity is 47.5588294154838
At time: 368.8786025047302 and batch: 900, loss is 3.813704228401184 and perplexity is 45.31799654866365
At time: 369.5847706794739 and batch: 950, loss is 3.9125802755355834 and perplexity is 50.02787127056355
At time: 370.28878808021545 and batch: 1000, loss is 3.861975893974304 and perplexity is 47.55923058775968
At time: 370.9953269958496 and batch: 1050, loss is 3.8180989408493042 and perplexity is 45.5175943785094
At time: 371.7026219367981 and batch: 1100, loss is 3.839560146331787 and perplexity is 46.505014539202556
At time: 372.4084289073944 and batch: 1150, loss is 3.818216619491577 and perplexity is 45.52295114239757
At time: 373.1198842525482 and batch: 1200, loss is 3.852251772880554 and perplexity is 47.09900016513273
At time: 373.8318085670471 and batch: 1250, loss is 3.856393337249756 and perplexity is 47.294468198364605
At time: 374.54239892959595 and batch: 1300, loss is 3.8573801517486572 and perplexity is 47.34116210062124
At time: 375.24951696395874 and batch: 1350, loss is 3.7339155149459837 and perplexity is 41.84262324895268
At time: 375.95704793930054 and batch: 1400, loss is 3.7545046043395995 and perplexity is 42.71305470649086
At time: 376.66196966171265 and batch: 1450, loss is 3.6905272006988525 and perplexity is 40.06596419461007
At time: 377.36426877975464 and batch: 1500, loss is 3.7132066440582276 and perplexity is 40.98502040861836
At time: 378.0673146247864 and batch: 1550, loss is 3.721670002937317 and perplexity is 41.33336334136034
At time: 378.76986956596375 and batch: 1600, loss is 3.7975384187698364 and perplexity is 44.591284216309525
At time: 379.4842858314514 and batch: 1650, loss is 3.7614622592926024 and perplexity is 43.01127365235206
At time: 380.1978621482849 and batch: 1700, loss is 3.7517419052124024 and perplexity is 42.5952142413599
At time: 380.90830516815186 and batch: 1750, loss is 3.7306177902221678 and perplexity is 41.70486506488324
At time: 381.62037777900696 and batch: 1800, loss is 3.6838251066207888 and perplexity is 39.79833616912882
At time: 382.3245368003845 and batch: 1850, loss is 3.731578245162964 and perplexity is 41.74493995057036
At time: 383.0364999771118 and batch: 1900, loss is 3.8247697830200194 and perplexity is 45.82225009192182
At time: 383.7426142692566 and batch: 1950, loss is 3.7567116117477415 and perplexity is 42.80742683634102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389800031795058 and perplexity of 80.62429507283589
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 386.3677568435669 and batch: 50, loss is 3.9354982280731203 and perplexity is 51.18764672712295
At time: 387.12022256851196 and batch: 100, loss is 3.9456235551834107 and perplexity is 51.70857120910947
At time: 387.83141326904297 and batch: 150, loss is 3.9297790145874023 and perplexity is 50.89572921265528
At time: 388.5444133281708 and batch: 200, loss is 3.9206742572784425 and perplexity is 50.43443910396679
At time: 389.25681614875793 and batch: 250, loss is 3.9144003105163576 and perplexity is 50.11900665592695
At time: 389.9649636745453 and batch: 300, loss is 3.926886339187622 and perplexity is 50.748717120450415
At time: 390.67643094062805 and batch: 350, loss is 3.9432437229156494 and perplexity is 51.58565979511086
At time: 391.38304829597473 and batch: 400, loss is 3.8813172960281372 and perplexity is 48.48804613049433
At time: 392.090678691864 and batch: 450, loss is 3.908744397163391 and perplexity is 49.83633802511789
At time: 392.7978551387787 and batch: 500, loss is 3.9431615686416626 and perplexity is 51.581421986761676
At time: 393.50812101364136 and batch: 550, loss is 3.9297938537597656 and perplexity is 50.8964844687573
At time: 394.21798634529114 and batch: 600, loss is 3.8865953731536864 and perplexity is 48.74464635983947
At time: 394.9876630306244 and batch: 650, loss is 3.893744111061096 and perplexity is 49.09435756862737
At time: 395.69504737854004 and batch: 700, loss is 3.929533896446228 and perplexity is 50.883255274973635
At time: 396.3995404243469 and batch: 750, loss is 3.8754426574707033 and perplexity is 48.20403144374736
At time: 397.10300874710083 and batch: 800, loss is 3.8759219455718994 and perplexity is 48.22714059997746
At time: 397.8079960346222 and batch: 850, loss is 3.895360507965088 and perplexity is 49.17377770614496
At time: 398.51432824134827 and batch: 900, loss is 3.845703225135803 and perplexity is 46.79157779745849
At time: 399.2194414138794 and batch: 950, loss is 3.9441051054000855 and perplexity is 51.63011392216097
At time: 399.92643904685974 and batch: 1000, loss is 3.893324303627014 and perplexity is 49.07375171789586
At time: 400.6297836303711 and batch: 1050, loss is 3.843370909690857 and perplexity is 46.682572244948005
At time: 401.33798694610596 and batch: 1100, loss is 3.8647740077972412 and perplexity is 47.69249308314319
At time: 402.0473527908325 and batch: 1150, loss is 3.8462023067474367 and perplexity is 46.81493644196664
At time: 402.75924277305603 and batch: 1200, loss is 3.872663040161133 and perplexity is 48.07022872987469
At time: 403.47133898735046 and batch: 1250, loss is 3.872684564590454 and perplexity is 48.07126342525101
At time: 404.17542695999146 and batch: 1300, loss is 3.8754963302612304 and perplexity is 48.20661875806318
At time: 404.8798506259918 and batch: 1350, loss is 3.7533481121063232 and perplexity is 42.66368594326138
At time: 405.5856990814209 and batch: 1400, loss is 3.770814929008484 and perplexity is 43.41543091754197
At time: 406.2884075641632 and batch: 1450, loss is 3.6974055004119872 and perplexity is 40.342499861972854
At time: 406.9992473125458 and batch: 1500, loss is 3.7151196718215944 and perplexity is 41.06350093432005
At time: 407.706250667572 and batch: 1550, loss is 3.7233181476593016 and perplexity is 41.40154287542942
At time: 408.4217646121979 and batch: 1600, loss is 3.8013184213638307 and perplexity is 44.76015835758408
At time: 409.1299555301666 and batch: 1650, loss is 3.767176418304443 and perplexity is 43.25775044243399
At time: 409.8412938117981 and batch: 1700, loss is 3.751938247680664 and perplexity is 42.60357831194444
At time: 410.54907727241516 and batch: 1750, loss is 3.735191135406494 and perplexity is 41.89603261308696
At time: 411.25249123573303 and batch: 1800, loss is 3.682686848640442 and perplexity is 39.75306116758399
At time: 411.9667866230011 and batch: 1850, loss is 3.7240124559402465 and perplexity is 41.43029829089811
At time: 412.67393231391907 and batch: 1900, loss is 3.8234739017486574 and perplexity is 45.76290835444357
At time: 413.3740680217743 and batch: 1950, loss is 3.7693412733078 and perplexity is 43.351498638926046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361227062136628 and perplexity of 78.35321972892
finished 14 epochs...
Completing Train Step...
At time: 416.07682394981384 and batch: 50, loss is 3.9372040176391603 and perplexity is 51.27503659399177
At time: 416.78777027130127 and batch: 100, loss is 3.9311279535293577 and perplexity is 50.964430770455145
At time: 417.4997065067291 and batch: 150, loss is 3.902486972808838 and perplexity is 49.525464557783486
At time: 418.2114534378052 and batch: 200, loss is 3.890001811981201 and perplexity is 48.910975149419095
At time: 418.92325091362 and batch: 250, loss is 3.8836587047576905 and perplexity is 48.601709479234685
At time: 419.6389229297638 and batch: 300, loss is 3.8939802980422975 and perplexity is 49.10595438619028
At time: 420.3467893600464 and batch: 350, loss is 3.9122255182266237 and perplexity is 50.01012666527893
At time: 421.05145263671875 and batch: 400, loss is 3.852148241996765 and perplexity is 47.094124216430046
At time: 421.75930666923523 and batch: 450, loss is 3.8814289665222166 and perplexity is 48.49346111690414
At time: 422.4703016281128 and batch: 500, loss is 3.915822081565857 and perplexity is 50.1903150887406
At time: 423.175101518631 and batch: 550, loss is 3.9021817350387575 and perplexity is 49.510349822331094
At time: 423.88615345954895 and batch: 600, loss is 3.863301844596863 and perplexity is 47.62233360566353
At time: 424.5960307121277 and batch: 650, loss is 3.872680230140686 and perplexity is 48.071055063225984
At time: 425.3102798461914 and batch: 700, loss is 3.9108301305770876 and perplexity is 49.94039181706654
At time: 426.0238449573517 and batch: 750, loss is 3.861126480102539 and perplexity is 47.51885026979696
At time: 426.73693895339966 and batch: 800, loss is 3.8625340366363528 and perplexity is 47.58578283260593
At time: 427.44394063949585 and batch: 850, loss is 3.881613335609436 and perplexity is 48.50240263631093
At time: 428.1471953392029 and batch: 900, loss is 3.8296297883987425 and perplexity is 46.04548850437542
At time: 428.84956216812134 and batch: 950, loss is 3.929108729362488 and perplexity is 50.86162598807341
At time: 429.5557231903076 and batch: 1000, loss is 3.8790209770202635 and perplexity is 48.37682985140908
At time: 430.2616720199585 and batch: 1050, loss is 3.8307728958129883 and perplexity is 46.09815353883827
At time: 431.0228443145752 and batch: 1100, loss is 3.8530916357040406 and perplexity is 47.1385734801467
At time: 431.73150992393494 and batch: 1150, loss is 3.836874933242798 and perplexity is 46.38030617465742
At time: 432.4405572414398 and batch: 1200, loss is 3.8651399993896485 and perplexity is 47.70995132922333
At time: 433.1561553478241 and batch: 1250, loss is 3.8670090341567995 and perplexity is 47.79920627130889
At time: 433.86369943618774 and batch: 1300, loss is 3.8702985715866087 and perplexity is 47.95670245222172
At time: 434.5658977031708 and batch: 1350, loss is 3.7484257984161378 and perplexity is 42.45419790376809
At time: 435.26889204978943 and batch: 1400, loss is 3.7672067499160766 and perplexity is 43.25906253961946
At time: 435.97205877304077 and batch: 1450, loss is 3.695186128616333 and perplexity is 40.25306413788526
At time: 436.6756887435913 and batch: 1500, loss is 3.7139880514144896 and perplexity is 41.01705892099661
At time: 437.38120222091675 and batch: 1550, loss is 3.723211579322815 and perplexity is 41.3971310169636
At time: 438.0857331752777 and batch: 1600, loss is 3.802933759689331 and perplexity is 44.83251958503208
At time: 438.80341029167175 and batch: 1650, loss is 3.7695387697219847 and perplexity is 43.36006124997141
At time: 439.51131296157837 and batch: 1700, loss is 3.7558634948730467 and perplexity is 42.77113652666618
At time: 440.2237079143524 and batch: 1750, loss is 3.739550037384033 and perplexity is 42.07905190428951
At time: 440.9350140094757 and batch: 1800, loss is 3.687744212150574 and perplexity is 39.954616087200776
At time: 441.6404347419739 and batch: 1850, loss is 3.7299898052215577 and perplexity is 41.67868325692181
At time: 442.34965777397156 and batch: 1900, loss is 3.829520654678345 and perplexity is 46.040463663102216
At time: 443.05483531951904 and batch: 1950, loss is 3.7746795797348023 and perplexity is 43.58354102836747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358854072038517 and perplexity of 78.16750874665536
finished 15 epochs...
Completing Train Step...
At time: 445.7563245296478 and batch: 50, loss is 3.932604069709778 and perplexity is 51.03971574235391
At time: 446.551784992218 and batch: 100, loss is 3.9247126960754395 and perplexity is 50.63852732106338
At time: 447.2593584060669 and batch: 150, loss is 3.894381184577942 and perplexity is 49.125644248560334
At time: 447.9677846431732 and batch: 200, loss is 3.881105356216431 and perplexity is 48.47777067205525
At time: 448.6700687408447 and batch: 250, loss is 3.8740829372406007 and perplexity is 48.1385319875801
At time: 449.4320104122162 and batch: 300, loss is 3.8846541166305544 and perplexity is 48.65011228425856
At time: 450.13532996177673 and batch: 350, loss is 3.9028568506240844 and perplexity is 49.543786316610365
At time: 450.8383285999298 and batch: 400, loss is 3.8427149200439454 and perplexity is 46.65195900294682
At time: 451.54133582115173 and batch: 450, loss is 3.8722862815856933 and perplexity is 48.052121270261914
At time: 452.24517941474915 and batch: 500, loss is 3.906524806022644 and perplexity is 49.72584440144717
At time: 452.94979214668274 and batch: 550, loss is 3.8922614669799804 and perplexity is 49.02162204373394
At time: 453.66149163246155 and batch: 600, loss is 3.8546708488464354 and perplexity is 47.21307414563213
At time: 454.37095737457275 and batch: 650, loss is 3.864426808357239 and perplexity is 47.67593715052399
At time: 455.08082246780396 and batch: 700, loss is 3.90333345413208 and perplexity is 49.56740468682021
At time: 455.78543305397034 and batch: 750, loss is 3.854891777038574 and perplexity is 47.22350599705104
At time: 456.4961585998535 and batch: 800, loss is 3.8563753080368044 and perplexity is 47.29361552401257
At time: 457.19908690452576 and batch: 850, loss is 3.8751092195510863 and perplexity is 48.18796107117031
At time: 457.9053740501404 and batch: 900, loss is 3.8226500606536864 and perplexity is 45.72522251561863
At time: 458.61059951782227 and batch: 950, loss is 3.9227772188186645 and perplexity is 50.54061238974458
At time: 459.31518030166626 and batch: 1000, loss is 3.8731738710403443 and perplexity is 48.09479076006829
At time: 460.0209197998047 and batch: 1050, loss is 3.825708656311035 and perplexity is 45.865291580757805
At time: 460.72973442077637 and batch: 1100, loss is 3.84859227180481 and perplexity is 46.92695631269363
At time: 461.4364297389984 and batch: 1150, loss is 3.833160424232483 and perplexity is 46.208345681590735
At time: 462.1453778743744 and batch: 1200, loss is 3.8618688344955445 and perplexity is 47.5541391938686
At time: 462.84933948516846 and batch: 1250, loss is 3.8642580556869506 and perplexity is 47.667892387628044
At time: 463.55756664276123 and batch: 1300, loss is 3.8677743816375734 and perplexity is 47.83580327633802
At time: 464.2685823440552 and batch: 1350, loss is 3.7456817388534547 and perplexity is 42.337860747078096
At time: 464.9785621166229 and batch: 1400, loss is 3.76498260974884 and perplexity is 43.16295523870089
At time: 465.68674063682556 and batch: 1450, loss is 3.6937287187576295 and perplexity is 40.194441654236876
At time: 466.3972821235657 and batch: 1500, loss is 3.7127958869934083 and perplexity is 40.96818897898473
At time: 467.11387038230896 and batch: 1550, loss is 3.7223560762405397 and perplexity is 41.36173078844261
At time: 467.82171154022217 and batch: 1600, loss is 3.8028332471847532 and perplexity is 44.828013582660645
At time: 468.5336310863495 and batch: 1650, loss is 3.7696503829956054 and perplexity is 43.36490107844144
At time: 469.2398204803467 and batch: 1700, loss is 3.7564959383010863 and perplexity is 42.79819540657571
At time: 469.95140528678894 and batch: 1750, loss is 3.740152587890625 and perplexity is 42.10441429862578
At time: 470.6558828353882 and batch: 1800, loss is 3.6887903356552125 and perplexity is 39.996435420488325
At time: 471.3633804321289 and batch: 1850, loss is 3.7313544178009033 and perplexity is 41.735597336387194
At time: 472.0703616142273 and batch: 1900, loss is 3.830803089141846 and perplexity is 46.099545416560396
At time: 472.773229598999 and batch: 1950, loss is 3.7755513525009157 and perplexity is 43.62155253877922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358137831577035 and perplexity of 78.11154205931328
finished 16 epochs...
Completing Train Step...
At time: 475.4412376880646 and batch: 50, loss is 3.928031907081604 and perplexity is 50.80688653358899
At time: 476.1810142993927 and batch: 100, loss is 3.9195307683944702 and perplexity is 50.37680084411723
At time: 476.8864040374756 and batch: 150, loss is 3.8886203718185426 and perplexity is 48.8434542127577
At time: 477.5904448032379 and batch: 200, loss is 3.875095748901367 and perplexity is 48.18731195239807
At time: 478.30436968803406 and batch: 250, loss is 3.8677593994140627 and perplexity is 47.83508659501027
At time: 479.0110499858856 and batch: 300, loss is 3.8783457565307615 and perplexity is 48.34417585024222
At time: 479.71198654174805 and batch: 350, loss is 3.8965269327163696 and perplexity is 49.231168682195985
At time: 480.4199683666229 and batch: 400, loss is 3.8364143657684324 and perplexity is 46.358949832578034
At time: 481.1257493495941 and batch: 450, loss is 3.8661788511276245 and perplexity is 47.759540648595966
At time: 481.8321237564087 and batch: 500, loss is 3.9003254652023314 and perplexity is 49.41853050044924
At time: 482.54171419143677 and batch: 550, loss is 3.8857777976989745 and perplexity is 48.70481022017103
At time: 483.252690076828 and batch: 600, loss is 3.8489170360565184 and perplexity is 46.94219898554914
At time: 483.9653551578522 and batch: 650, loss is 3.858929433822632 and perplexity is 47.414563759680135
At time: 484.67423701286316 and batch: 700, loss is 3.8981145334243776 and perplexity is 49.30939019628786
At time: 485.4119839668274 and batch: 750, loss is 3.8504225730896 and perplexity is 47.01292543181891
At time: 486.1154544353485 and batch: 800, loss is 3.8519119453430175 and perplexity is 47.0829973471393
At time: 486.82275319099426 and batch: 850, loss is 3.8705125856399536 and perplexity is 47.96696695883373
At time: 487.5287790298462 and batch: 900, loss is 3.8179065942764283 and perplexity is 45.508840067183016
At time: 488.2316474914551 and batch: 950, loss is 3.9184698390960695 and perplexity is 50.32338296145086
At time: 488.94143629074097 and batch: 1000, loss is 3.869145379066467 and perplexity is 47.901431017091184
At time: 489.6690921783447 and batch: 1050, loss is 3.822134747505188 and perplexity is 45.70166577730811
At time: 490.38652777671814 and batch: 1100, loss is 3.84534282207489 and perplexity is 46.77471700811787
At time: 491.0958194732666 and batch: 1150, loss is 3.8303705406188966 and perplexity is 46.07960943823166
At time: 491.7995674610138 and batch: 1200, loss is 3.8591556453704836 and perplexity is 47.425290694771476
At time: 492.5041151046753 and batch: 1250, loss is 3.861832342147827 and perplexity is 47.55240386334907
At time: 493.2074725627899 and batch: 1300, loss is 3.865505585670471 and perplexity is 47.727396621573476
At time: 493.91471314430237 and batch: 1350, loss is 3.743208746910095 and perplexity is 42.233288914495304
At time: 494.6214725971222 and batch: 1400, loss is 3.762882866859436 and perplexity is 43.07241921480281
At time: 495.3282446861267 and batch: 1450, loss is 3.6921477937698364 and perplexity is 40.130947460058756
At time: 496.03289461135864 and batch: 1500, loss is 3.7112894868850708 and perplexity is 40.90652095468926
At time: 496.73859167099 and batch: 1550, loss is 3.721021637916565 and perplexity is 41.30657292030422
At time: 497.4488308429718 and batch: 1600, loss is 3.801940016746521 and perplexity is 44.78798971437296
At time: 498.1555733680725 and batch: 1650, loss is 3.768799557685852 and perplexity is 43.32802081460473
At time: 498.85993123054504 and batch: 1700, loss is 3.755997533798218 and perplexity is 42.77686990807412
At time: 499.5623335838318 and batch: 1750, loss is 3.7395898056030275 and perplexity is 42.0807253465154
At time: 500.27091670036316 and batch: 1800, loss is 3.6885812091827392 and perplexity is 39.98807198157605
At time: 500.97542428970337 and batch: 1850, loss is 3.7313295936584474 and perplexity is 41.73456129883286
At time: 501.68370604515076 and batch: 1900, loss is 3.8307721710205076 and perplexity is 46.09812012725532
At time: 502.38913655281067 and batch: 1950, loss is 3.7752504539489746 and perplexity is 43.60842885133517
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357920092205669 and perplexity of 78.09453595276551
finished 17 epochs...
Completing Train Step...
At time: 505.0498242378235 and batch: 50, loss is 3.9238104152679445 and perplexity is 50.59285775622603
At time: 505.75574827194214 and batch: 100, loss is 3.9149979639053343 and perplexity is 50.14896940288378
At time: 506.4572756290436 and batch: 150, loss is 3.8838064432144166 and perplexity is 48.60889035121981
At time: 507.16094398498535 and batch: 200, loss is 3.8701725721359255 and perplexity is 47.950660314717155
At time: 507.8656849861145 and batch: 250, loss is 3.8626413917541504 and perplexity is 47.59089168415319
At time: 508.57045817375183 and batch: 300, loss is 3.8732085752487184 and perplexity is 48.09645988067113
At time: 509.2797474861145 and batch: 350, loss is 3.891418390274048 and perplexity is 48.98031047296029
At time: 509.9830152988434 and batch: 400, loss is 3.831355805397034 and perplexity is 46.1250324275627
At time: 510.6935784816742 and batch: 450, loss is 3.86129629611969 and perplexity is 47.526920416890086
At time: 511.4013249874115 and batch: 500, loss is 3.895367455482483 and perplexity is 49.17411934300772
At time: 512.110164642334 and batch: 550, loss is 3.8807140350341798 and perplexity is 48.458804004794324
At time: 512.8206293582916 and batch: 600, loss is 3.8443386936187744 and perplexity is 46.727772756717
At time: 513.5296709537506 and batch: 650, loss is 3.854531044960022 and perplexity is 47.20647403574831
At time: 514.2399208545685 and batch: 700, loss is 3.8938457345962525 and perplexity is 49.099346964315444
At time: 514.9518764019012 and batch: 750, loss is 3.846605587005615 and perplexity is 46.833819789006164
At time: 515.6585347652435 and batch: 800, loss is 3.8481386518478393 and perplexity is 46.90567413616525
At time: 516.3622190952301 and batch: 850, loss is 3.8666666984558105 and perplexity is 47.78284569708738
At time: 517.0770738124847 and batch: 900, loss is 3.8139907550811767 and perplexity is 45.330983224184315
At time: 517.7857940196991 and batch: 950, loss is 3.9148688411712644 and perplexity is 50.14249444888457
At time: 518.500180721283 and batch: 1000, loss is 3.8657552099227903 and perplexity is 47.73931202439517
At time: 519.222669839859 and batch: 1050, loss is 3.819089369773865 and perplexity is 45.562698653160325
At time: 519.9358365535736 and batch: 1100, loss is 3.842527689933777 and perplexity is 46.64322516916696
At time: 520.6413285732269 and batch: 1150, loss is 3.8278641891479492 and perplexity is 45.96426235188748
At time: 521.3921813964844 and batch: 1200, loss is 3.8566116952896117 and perplexity is 47.30479645332414
At time: 522.0962076187134 and batch: 1250, loss is 3.8595216369628904 and perplexity is 47.442651129125935
At time: 522.8021574020386 and batch: 1300, loss is 3.863311800956726 and perplexity is 47.62280775311482
At time: 523.5075492858887 and batch: 1350, loss is 3.7408611249923704 and perplexity is 42.13425740953076
At time: 524.2154145240784 and batch: 1400, loss is 3.7608100032806395 and perplexity is 42.98322843785431
At time: 524.9257197380066 and batch: 1450, loss is 3.6904780197143556 and perplexity is 40.063993759500526
At time: 525.6336162090302 and batch: 1500, loss is 3.7096014785766602 and perplexity is 40.83752865362035
At time: 526.3398921489716 and batch: 1550, loss is 3.7194527435302733 and perplexity is 41.241818079967814
At time: 527.0501277446747 and batch: 1600, loss is 3.8006629133224488 and perplexity is 44.73082732826022
At time: 527.7574336528778 and batch: 1650, loss is 3.7675116872787475 and perplexity is 43.27225585552715
At time: 528.4607753753662 and batch: 1700, loss is 3.7550398111343384 and perplexity is 42.73592114218387
At time: 529.1654672622681 and batch: 1750, loss is 3.7385520219802855 and perplexity is 42.037077311443056
At time: 529.8709981441498 and batch: 1800, loss is 3.68784631729126 and perplexity is 39.95869586717712
At time: 530.5777251720428 and batch: 1850, loss is 3.7307163190841677 and perplexity is 41.70897440021869
At time: 531.2797284126282 and batch: 1900, loss is 3.830206623077393 and perplexity is 46.072056800960866
At time: 531.9899077415466 and batch: 1950, loss is 3.774468865394592 and perplexity is 43.57435831877393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357913846747819 and perplexity of 78.094048218156
finished 18 epochs...
Completing Train Step...
At time: 534.6548495292664 and batch: 50, loss is 3.9198933172225954 and perplexity is 50.395068205433084
At time: 535.385594367981 and batch: 100, loss is 3.910893702507019 and perplexity is 49.94356672507232
At time: 536.0878949165344 and batch: 150, loss is 3.8795326566696167 and perplexity is 48.40158962474012
At time: 536.7970328330994 and batch: 200, loss is 3.8658280324935914 and perplexity is 47.742788650411946
At time: 537.4981083869934 and batch: 250, loss is 3.8581655502319334 and perplexity is 47.378358382571264
At time: 538.2039079666138 and batch: 300, loss is 3.86871374130249 and perplexity is 47.88075941215928
At time: 538.9080171585083 and batch: 350, loss is 3.886984610557556 and perplexity is 48.76362329246752
At time: 539.6699101924896 and batch: 400, loss is 3.826978759765625 and perplexity is 45.92358225579815
At time: 540.3771185874939 and batch: 450, loss is 3.8570769786834718 and perplexity is 47.326811710833496
At time: 541.0867145061493 and batch: 500, loss is 3.8910957908630373 and perplexity is 48.964512002076304
At time: 541.7975072860718 and batch: 550, loss is 3.876410765647888 and perplexity is 48.25072075726787
At time: 542.5052626132965 and batch: 600, loss is 3.840390515327454 and perplexity is 46.543646898755945
At time: 543.2113966941833 and batch: 650, loss is 3.850724153518677 and perplexity is 47.027105748188276
At time: 543.9170336723328 and batch: 700, loss is 3.8900942993164063 and perplexity is 48.915499004369366
At time: 544.6254115104675 and batch: 750, loss is 3.8432055950164794 and perplexity is 46.674855568575715
At time: 545.33265209198 and batch: 800, loss is 3.844789423942566 and perplexity is 46.748839128131245
At time: 546.0373284816742 and batch: 850, loss is 3.863246259689331 and perplexity is 47.61968659622117
At time: 546.7486717700958 and batch: 900, loss is 3.8105467319488526 and perplexity is 45.17513080307194
At time: 547.4580581188202 and batch: 950, loss is 3.911684432029724 and perplexity is 49.98307419555416
At time: 548.1685264110565 and batch: 1000, loss is 3.8627246236801147 and perplexity is 47.594852930575215
At time: 548.8842811584473 and batch: 1050, loss is 3.8163182020187376 and perplexity is 45.43661155675318
At time: 549.5937585830688 and batch: 1100, loss is 3.839943628311157 and perplexity is 46.522851794143
At time: 550.3026616573334 and batch: 1150, loss is 3.825509672164917 and perplexity is 45.85616602282694
At time: 551.0173096656799 and batch: 1200, loss is 3.8541926527023316 and perplexity is 47.19050243290752
At time: 551.7225441932678 and batch: 1250, loss is 3.8572936487197875 and perplexity is 47.337067123825825
At time: 552.4322538375854 and batch: 1300, loss is 3.8611607646942137 and perplexity is 47.52047946210324
At time: 553.1417512893677 and batch: 1350, loss is 3.738579607009888 and perplexity is 42.038236921458946
At time: 553.8506107330322 and batch: 1400, loss is 3.758776755332947 and perplexity is 42.895921665084
At time: 554.5629522800446 and batch: 1450, loss is 3.68875940322876 and perplexity is 39.99519825282571
At time: 555.2740879058838 and batch: 1500, loss is 3.7078353500366212 and perplexity is 40.76546798169621
At time: 555.9835073947906 and batch: 1550, loss is 3.717789134979248 and perplexity is 41.17326487740775
At time: 556.686182975769 and batch: 1600, loss is 3.7992186164855957 and perplexity is 44.66626936749175
At time: 557.4030725955963 and batch: 1650, loss is 3.7660271310806275 and perplexity is 43.20806342031848
At time: 558.1079013347626 and batch: 1700, loss is 3.7538707876205444 and perplexity is 42.68599103590543
At time: 558.8093791007996 and batch: 1750, loss is 3.7372901535034178 and perplexity is 41.98406550272353
At time: 559.5138170719147 and batch: 1800, loss is 3.6868549966812134 and perplexity is 39.91910361596305
At time: 560.221512556076 and batch: 1850, loss is 3.7298097658157348 and perplexity is 41.67118012700254
At time: 560.9249620437622 and batch: 1900, loss is 3.829374923706055 and perplexity is 46.033754630436704
At time: 561.6353332996368 and batch: 1950, loss is 3.773457546234131 and perplexity is 43.5303130109872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358027684411337 and perplexity of 78.10293876816993
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 564.2963435649872 and batch: 50, loss is 3.9217291975021364 and perplexity is 50.48767249652358
At time: 565.0513336658478 and batch: 100, loss is 3.921161580085754 and perplexity is 50.45902294606307
At time: 565.7543921470642 and batch: 150, loss is 3.893748707771301 and perplexity is 49.09458324168049
At time: 566.4567701816559 and batch: 200, loss is 3.881811819076538 and perplexity is 48.51203051680491
At time: 567.1600713729858 and batch: 250, loss is 3.8783765125274656 and perplexity is 48.3456627464207
At time: 567.865978717804 and batch: 300, loss is 3.885394368171692 and perplexity is 48.6861389376012
At time: 568.5774486064911 and batch: 350, loss is 3.904549140930176 and perplexity is 49.62769976885565
At time: 569.2895426750183 and batch: 400, loss is 3.8495350790023806 and perplexity is 46.971220247764826
At time: 569.9970767498016 and batch: 450, loss is 3.880007586479187 and perplexity is 48.424582442038485
At time: 570.7029223442078 and batch: 500, loss is 3.9186010265350344 and perplexity is 50.3299851902369
At time: 571.4110400676727 and batch: 550, loss is 3.9110613250732422 and perplexity is 49.951939095572634
At time: 572.1117448806763 and batch: 600, loss is 3.876738705635071 and perplexity is 48.266546692851286
At time: 572.8129382133484 and batch: 650, loss is 3.8839204359054564 and perplexity is 48.61443172527148
At time: 573.5161581039429 and batch: 700, loss is 3.920391907691956 and perplexity is 50.420200971101146
At time: 574.2237279415131 and batch: 750, loss is 3.86382315158844 and perplexity is 47.64716593319798
At time: 574.9288311004639 and batch: 800, loss is 3.855679063796997 and perplexity is 47.26069907689737
At time: 575.6882274150848 and batch: 850, loss is 3.873235330581665 and perplexity is 48.09774673468381
At time: 576.3961369991302 and batch: 900, loss is 3.819544024467468 and perplexity is 45.58341865782298
At time: 577.1099314689636 and batch: 950, loss is 3.923225655555725 and perplexity is 50.56328173955843
At time: 577.8166580200195 and batch: 1000, loss is 3.8744763422012327 and perplexity is 48.15747365048934
At time: 578.5199227333069 and batch: 1050, loss is 3.8281150436401368 and perplexity is 45.97579413991848
At time: 579.2220487594604 and batch: 1100, loss is 3.850591917037964 and perplexity is 47.020887460377324
At time: 579.9271080493927 and batch: 1150, loss is 3.8398136568069456 and perplexity is 46.516805542043855
At time: 580.6317150592804 and batch: 1200, loss is 3.8676158380508423 and perplexity is 47.82821981768268
At time: 581.3367369174957 and batch: 1250, loss is 3.863584532737732 and perplexity is 47.63579777760556
At time: 582.042900800705 and batch: 1300, loss is 3.864669451713562 and perplexity is 47.687506803522986
At time: 582.7489809989929 and batch: 1350, loss is 3.742657446861267 and perplexity is 42.21001211709388
At time: 583.4547939300537 and batch: 1400, loss is 3.7654322290420534 and perplexity is 43.18236649964001
At time: 584.1621074676514 and batch: 1450, loss is 3.6932638263702393 and perplexity is 40.17575990713389
At time: 584.869059085846 and batch: 1500, loss is 3.709330315589905 and perplexity is 40.82645652862202
At time: 585.5733728408813 and batch: 1550, loss is 3.7203157901763917 and perplexity is 41.27742705663522
At time: 586.2797114849091 and batch: 1600, loss is 3.7995917129516603 and perplexity is 44.68293730392579
At time: 586.9900710582733 and batch: 1650, loss is 3.7634153509140016 and perplexity is 43.09536069867136
At time: 587.6925640106201 and batch: 1700, loss is 3.7461642169952394 and perplexity is 42.35829276806389
At time: 588.3963170051575 and batch: 1750, loss is 3.7318661880493162 and perplexity is 41.75696183979601
At time: 589.1000466346741 and batch: 1800, loss is 3.68069287776947 and perplexity is 39.67387369657606
At time: 589.807624578476 and batch: 1850, loss is 3.723612303733826 and perplexity is 41.41372318212868
At time: 590.5157632827759 and batch: 1900, loss is 3.819313898086548 and perplexity is 45.57292991757149
At time: 591.2248363494873 and batch: 1950, loss is 3.7715052366256714 and perplexity is 43.445411266849035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351879598928052 and perplexity of 77.62422830843686
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7420a98b38>
ELAPSED
3127.8746407032013


RESULTS SO FAR:
[{'best_accuracy': -76.72922266508544, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.44533850763699, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.7798990364997814, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3775751613796833, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.6311346728391, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.278968697079667, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.1071481079890072, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.33222650478953, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.20408011909539603, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.046635900383796614, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -77.62422830843686, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.13889208123057972, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8005403062602345, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.07746058627322845, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.0, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.2976412773132324 and batch: 50, loss is 7.64784610748291 and perplexity is 2096.1258938206665
At time: 2.032635450363159 and batch: 100, loss is 6.67992600440979 and perplexity is 796.2601900932244
At time: 2.7436792850494385 and batch: 150, loss is 6.350788345336914 and perplexity is 572.9442089167775
At time: 3.4505863189697266 and batch: 200, loss is 6.108982429504395 and perplexity is 449.8806968505217
At time: 4.161226034164429 and batch: 250, loss is 5.9770338916778565 and perplexity is 394.26918697220515
At time: 4.862921953201294 and batch: 300, loss is 5.847910327911377 and perplexity is 346.5095320971216
At time: 5.5659568309783936 and batch: 350, loss is 5.760312299728394 and perplexity is 317.447452192058
At time: 6.2760515213012695 and batch: 400, loss is 5.672171468734741 and perplexity is 290.66501960688515
At time: 6.983048439025879 and batch: 450, loss is 5.568378934860229 and perplexity is 262.0090211032751
At time: 7.689777374267578 and batch: 500, loss is 5.537274599075317 and perplexity is 253.98484479456678
At time: 8.394813776016235 and batch: 550, loss is 5.4890423679351805 and perplexity is 242.02532463537992
At time: 9.107598543167114 and batch: 600, loss is 5.479816226959229 and perplexity is 239.80263406538916
At time: 9.814733505249023 and batch: 650, loss is 5.519935607910156 and perplexity is 249.61896318547585
At time: 10.522073030471802 and batch: 700, loss is 5.453335237503052 and perplexity is 233.53576569089608
At time: 11.232283592224121 and batch: 750, loss is 5.372401752471924 and perplexity is 215.37953533348391
At time: 11.939003229141235 and batch: 800, loss is 5.366095609664917 and perplexity is 214.02559478408511
At time: 12.643634796142578 and batch: 850, loss is 5.362238264083862 and perplexity is 213.2016143122028
At time: 13.350582599639893 and batch: 900, loss is 5.359246635437012 and perplexity is 212.5647473649617
At time: 14.057374000549316 and batch: 950, loss is 5.37205620765686 and perplexity is 215.3051249085873
At time: 14.76124882698059 and batch: 1000, loss is 5.331333532333374 and perplexity is 206.71344950650175
At time: 15.46634316444397 and batch: 1050, loss is 5.234731397628784 and perplexity is 187.67868863255023
At time: 16.17465591430664 and batch: 1100, loss is 5.313833837509155 and perplexity is 203.12749528918582
At time: 16.883288145065308 and batch: 1150, loss is 5.210941877365112 and perplexity is 183.26659158270928
At time: 17.596505403518677 and batch: 1200, loss is 5.284372463226318 and perplexity is 197.23037529175204
At time: 18.315285205841064 and batch: 1250, loss is 5.239587125778198 and perplexity is 188.5922214625811
At time: 19.032193422317505 and batch: 1300, loss is 5.250663814544677 and perplexity is 190.69281111513894
At time: 19.738038301467896 and batch: 1350, loss is 5.179550056457519 and perplexity is 177.60288174312166
At time: 20.442037105560303 and batch: 1400, loss is 5.181490154266357 and perplexity is 177.9477831679005
At time: 21.1506450176239 and batch: 1450, loss is 5.131025009155273 and perplexity is 169.19045095701608
At time: 21.85631251335144 and batch: 1500, loss is 5.094534568786621 and perplexity is 163.1279021353292
At time: 22.56426978111267 and batch: 1550, loss is 5.0802175807952885 and perplexity is 160.80904108146868
At time: 23.27518630027771 and batch: 1600, loss is 5.124731111526489 and perplexity is 168.12892764264805
At time: 23.99741554260254 and batch: 1650, loss is 5.1021255683898925 and perplexity is 164.3709178728254
At time: 24.706748485565186 and batch: 1700, loss is 5.111302728652954 and perplexity is 165.88631903277502
At time: 25.41785764694214 and batch: 1750, loss is 5.10805760383606 and perplexity is 165.34886973876849
At time: 26.132624864578247 and batch: 1800, loss is 5.065898666381836 and perplexity is 158.52283722579836
At time: 26.839686393737793 and batch: 1850, loss is 5.0621759223937985 and perplexity is 157.9337943946651
At time: 27.546061515808105 and batch: 1900, loss is 5.139710235595703 and perplexity is 170.66630813465795
At time: 28.252406120300293 and batch: 1950, loss is 5.0603667259216305 and perplexity is 157.6483194490103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.797611396257268 and perplexity of 121.22052363930207
finished 1 epochs...
Completing Train Step...
At time: 30.832905054092407 and batch: 50, loss is 5.0359727573394775 and perplexity is 153.8491777618612
At time: 31.561851024627686 and batch: 100, loss is 4.987245025634766 and perplexity is 146.53217451911235
At time: 32.27916669845581 and batch: 150, loss is 4.922116861343384 and perplexity is 137.29293590031727
At time: 32.986000299453735 and batch: 200, loss is 4.888405637741089 and perplexity is 132.74176678425212
At time: 33.70039963722229 and batch: 250, loss is 4.910832214355469 and perplexity is 135.7523424599584
At time: 34.40944862365723 and batch: 300, loss is 4.91814489364624 and perplexity is 136.74869436429537
At time: 35.108102798461914 and batch: 350, loss is 4.915550584793091 and perplexity is 136.39438580748327
At time: 35.80674624443054 and batch: 400, loss is 4.853083772659302 and perplexity is 128.13492017599313
At time: 36.504971981048584 and batch: 450, loss is 4.8352640438079835 and perplexity is 125.87181449263859
At time: 37.25016164779663 and batch: 500, loss is 4.835180892944336 and perplexity is 125.86134857768558
At time: 37.95460772514343 and batch: 550, loss is 4.806071472167969 and perplexity is 122.25040878182116
At time: 38.66253614425659 and batch: 600, loss is 4.76800609588623 and perplexity is 117.6843565463482
At time: 39.370797634124756 and batch: 650, loss is 4.842670679092407 and perplexity is 126.80756220841272
At time: 40.07810950279236 and batch: 700, loss is 4.854225473403931 and perplexity is 128.2812954522522
At time: 40.78882551193237 and batch: 750, loss is 4.7960649108886715 and perplexity is 121.03320275495707
At time: 41.49751353263855 and batch: 800, loss is 4.79385705947876 and perplexity is 120.76627420532672
At time: 42.19909906387329 and batch: 850, loss is 4.793063678741455 and perplexity is 120.67049856795292
At time: 42.90322184562683 and batch: 900, loss is 4.765527400970459 and perplexity is 117.39301415373019
At time: 43.606804847717285 and batch: 950, loss is 4.814338254928589 and perplexity is 123.26521516628952
At time: 44.3181574344635 and batch: 1000, loss is 4.7980803203582765 and perplexity is 121.27738019403601
At time: 45.039271116256714 and batch: 1050, loss is 4.723978757858276 and perplexity is 112.61543200378584
At time: 45.75134515762329 and batch: 1100, loss is 4.781066064834595 and perplexity is 119.23139070880434
At time: 46.45760536193848 and batch: 1150, loss is 4.721242523193359 and perplexity is 112.30771094543769
At time: 47.16589593887329 and batch: 1200, loss is 4.789679670333863 and perplexity is 120.26283873742432
At time: 47.88093614578247 and batch: 1250, loss is 4.775917892456055 and perplexity is 118.61914428380068
At time: 48.60121536254883 and batch: 1300, loss is 4.767948150634766 and perplexity is 117.67753749428242
At time: 49.31199240684509 and batch: 1350, loss is 4.660443086624145 and perplexity is 105.68289846276377
At time: 50.01754665374756 and batch: 1400, loss is 4.663013000488281 and perplexity is 105.95484369696824
At time: 50.72370648384094 and batch: 1450, loss is 4.622909021377564 and perplexity is 101.78971029724862
At time: 51.43164896965027 and batch: 1500, loss is 4.60574273109436 and perplexity is 100.05727090415037
At time: 52.146610498428345 and batch: 1550, loss is 4.605604524612427 and perplexity is 100.04344329630136
At time: 52.849828243255615 and batch: 1600, loss is 4.671214561462403 and perplexity is 106.8274121285022
At time: 53.56766486167908 and batch: 1650, loss is 4.646854152679444 and perplexity is 104.25649414332003
At time: 54.27760291099548 and batch: 1700, loss is 4.64305193901062 and perplexity is 103.86084133114693
At time: 54.9972505569458 and batch: 1750, loss is 4.640089483261108 and perplexity is 103.55361348373742
At time: 55.72540736198425 and batch: 1800, loss is 4.600227613449096 and perplexity is 99.50696218737944
At time: 56.42526197433472 and batch: 1850, loss is 4.633308343887329 and perplexity is 102.8537775224027
At time: 57.12771821022034 and batch: 1900, loss is 4.731118965148926 and perplexity is 113.42240708864261
At time: 57.82985734939575 and batch: 1950, loss is 4.647013120651245 and perplexity is 104.27306890413425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.585390738553779 and perplexity of 98.04148824809046
finished 2 epochs...
Completing Train Step...
At time: 60.49044752120972 and batch: 50, loss is 4.656830558776855 and perplexity is 105.30180481923517
At time: 61.20238494873047 and batch: 100, loss is 4.609923410415649 and perplexity is 100.47645389184557
At time: 61.91077208518982 and batch: 150, loss is 4.56313154220581 and perplexity is 95.88327269333992
At time: 62.62625288963318 and batch: 200, loss is 4.542215929031372 and perplexity is 93.89864248034385
At time: 63.33049392700195 and batch: 250, loss is 4.559354419708252 and perplexity is 95.52179293333616
At time: 64.03337597846985 and batch: 300, loss is 4.569147319793701 and perplexity is 96.46182360828408
At time: 64.7363703250885 and batch: 350, loss is 4.574130868911743 and perplexity is 96.94374568802148
At time: 65.43918538093567 and batch: 400, loss is 4.515797729492188 and perplexity is 91.4504896845394
At time: 66.14753699302673 and batch: 450, loss is 4.528324499130249 and perplexity is 92.60327416035614
At time: 66.85041379928589 and batch: 500, loss is 4.537323083877563 and perplexity is 93.4403330952858
At time: 67.56289958953857 and batch: 550, loss is 4.500955801010132 and perplexity is 90.10321089647724
At time: 68.27920484542847 and batch: 600, loss is 4.476511650085449 and perplexity is 87.92741548463465
At time: 68.98887777328491 and batch: 650, loss is 4.5480869770050045 and perplexity is 94.45154739245503
At time: 69.69573903083801 and batch: 700, loss is 4.571915483474731 and perplexity is 96.7292156467211
At time: 70.40173983573914 and batch: 750, loss is 4.524170303344727 and perplexity is 92.21937996701634
At time: 71.10362243652344 and batch: 800, loss is 4.520360975265503 and perplexity is 91.86875434147308
At time: 71.80609321594238 and batch: 850, loss is 4.523108682632446 and perplexity is 92.1215299121822
At time: 72.50900340080261 and batch: 900, loss is 4.487399482727051 and perplexity is 88.88998510856779
At time: 73.26924705505371 and batch: 950, loss is 4.549338159561157 and perplexity is 94.56979748175226
At time: 73.97590112686157 and batch: 1000, loss is 4.532978487014771 and perplexity is 93.03525310905486
At time: 74.68590044975281 and batch: 1050, loss is 4.476188659667969 and perplexity is 87.89902035792309
At time: 75.38908863067627 and batch: 1100, loss is 4.522786073684692 and perplexity is 92.09181547568099
At time: 76.0902898311615 and batch: 1150, loss is 4.477930393218994 and perplexity is 88.05225043502888
At time: 76.79470634460449 and batch: 1200, loss is 4.5405090713500975 and perplexity is 93.73850756379876
At time: 77.5080943107605 and batch: 1250, loss is 4.543204135894776 and perplexity is 93.99147962690485
At time: 78.22069787979126 and batch: 1300, loss is 4.521935443878174 and perplexity is 92.01351274054271
At time: 78.9401364326477 and batch: 1350, loss is 4.408982572555542 and perplexity is 82.18580286072581
At time: 79.675363779068 and batch: 1400, loss is 4.418003053665161 and perplexity is 82.93051211108708
At time: 80.42145991325378 and batch: 1450, loss is 4.376420850753784 and perplexity is 79.5527919334051
At time: 81.13104104995728 and batch: 1500, loss is 4.362824258804321 and perplexity is 78.47846522459272
At time: 81.8345365524292 and batch: 1550, loss is 4.374514131546021 and perplexity is 79.40125161532346
At time: 82.54178667068481 and batch: 1600, loss is 4.44827507019043 and perplexity is 85.4793708472464
At time: 83.24660134315491 and batch: 1650, loss is 4.4161710357666015 and perplexity is 82.7787210130217
At time: 83.94946694374084 and batch: 1700, loss is 4.413839035034179 and perplexity is 82.58590588488141
At time: 84.65056729316711 and batch: 1750, loss is 4.413144292831421 and perplexity is 82.5285498968299
At time: 85.36211562156677 and batch: 1800, loss is 4.3720657253265385 and perplexity is 79.20708289598234
At time: 86.07271528244019 and batch: 1850, loss is 4.409904499053955 and perplexity is 82.2616070677609
At time: 86.77946043014526 and batch: 1900, loss is 4.509587965011597 and perplexity is 90.88436325706132
At time: 87.48882985115051 and batch: 1950, loss is 4.4306014919281 and perplexity is 83.9819161659792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5161217977834305 and perplexity of 91.48013069106057
finished 3 epochs...
Completing Train Step...
At time: 90.16604542732239 and batch: 50, loss is 4.4473170471191406 and perplexity is 85.39751885216565
At time: 90.86859560012817 and batch: 100, loss is 4.399402256011963 and perplexity is 81.40219644611555
At time: 91.60361504554749 and batch: 150, loss is 4.355534582138062 and perplexity is 77.90846267909885
At time: 92.30615043640137 and batch: 200, loss is 4.337712326049805 and perplexity is 76.53225806840918
At time: 93.0172507762909 and batch: 250, loss is 4.351404809951783 and perplexity is 77.58738192836428
At time: 93.73314023017883 and batch: 300, loss is 4.361562957763672 and perplexity is 78.37954265342191
At time: 94.44387483596802 and batch: 350, loss is 4.368685111999512 and perplexity is 78.93976647725958
At time: 95.15001368522644 and batch: 400, loss is 4.314440422058105 and perplexity is 74.77177110142642
At time: 95.85445070266724 and batch: 450, loss is 4.339097843170166 and perplexity is 76.63836831402925
At time: 96.56271433830261 and batch: 500, loss is 4.355421552658081 and perplexity is 77.89965722372351
At time: 97.2712550163269 and batch: 550, loss is 4.31804349899292 and perplexity is 75.04166547837511
At time: 97.97503852844238 and batch: 600, loss is 4.298708543777466 and perplexity is 73.60467507641226
At time: 98.68333458900452 and batch: 650, loss is 4.367451782226563 and perplexity is 78.84246772605032
At time: 99.39200234413147 and batch: 700, loss is 4.398010177612305 and perplexity is 81.28895704410797
At time: 100.09499096870422 and batch: 750, loss is 4.34642201423645 and perplexity is 77.20174143592241
At time: 100.79921174049377 and batch: 800, loss is 4.344864597320557 and perplexity is 77.08159971753011
At time: 101.50192523002625 and batch: 850, loss is 4.350090484619141 and perplexity is 77.48547385165601
At time: 102.20735359191895 and batch: 900, loss is 4.312812352180481 and perplexity is 74.65013647490255
At time: 102.91106152534485 and batch: 950, loss is 4.382570943832397 and perplexity is 80.04355658573014
At time: 103.61589241027832 and batch: 1000, loss is 4.362691049575806 and perplexity is 78.46801186504253
At time: 104.32180261611938 and batch: 1050, loss is 4.316440391540527 and perplexity is 74.92146200049545
At time: 105.03293585777283 and batch: 1100, loss is 4.35775782585144 and perplexity is 78.08186486520465
At time: 105.740647315979 and batch: 1150, loss is 4.313568468093872 and perplexity is 74.70660197556967
At time: 106.45186448097229 and batch: 1200, loss is 4.3779067707061765 and perplexity is 79.67108888233959
At time: 107.15324068069458 and batch: 1250, loss is 4.385145797729492 and perplexity is 80.24992261651649
At time: 107.85975122451782 and batch: 1300, loss is 4.355726118087769 and perplexity is 77.92338637965526
At time: 108.56793022155762 and batch: 1350, loss is 4.2484363842010495 and perplexity is 69.99588007186458
At time: 109.2680733203888 and batch: 1400, loss is 4.261278896331787 and perplexity is 70.90060001461262
At time: 109.97482085227966 and batch: 1450, loss is 4.211047835350037 and perplexity is 67.42715536386144
At time: 110.68671011924744 and batch: 1500, loss is 4.2031079864501955 and perplexity is 66.89391366911472
At time: 111.3942437171936 and batch: 1550, loss is 4.2241825771331785 and perplexity is 68.31863550286982
At time: 112.10105276107788 and batch: 1600, loss is 4.29887167930603 and perplexity is 73.61668359346689
At time: 112.80805087089539 and batch: 1650, loss is 4.261344513893127 and perplexity is 70.90525249172356
At time: 113.51125884056091 and batch: 1700, loss is 4.262598123550415 and perplexity is 70.99419573940858
At time: 114.21540522575378 and batch: 1750, loss is 4.264452314376831 and perplexity is 71.12595464120167
At time: 114.9168312549591 and batch: 1800, loss is 4.224126706123352 and perplexity is 68.31481857834301
At time: 115.61780214309692 and batch: 1850, loss is 4.26420952796936 and perplexity is 71.108688322295
At time: 116.32274127006531 and batch: 1900, loss is 4.360426025390625 and perplexity is 78.29048105209701
At time: 117.0264720916748 and batch: 1950, loss is 4.28583794593811 and perplexity is 72.66340922505796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493910962481832 and perplexity of 89.47067898345698
finished 4 epochs...
Completing Train Step...
At time: 119.65694451332092 and batch: 50, loss is 4.300074219703674 and perplexity is 73.7052638794401
At time: 120.39108872413635 and batch: 100, loss is 4.258129525184631 and perplexity is 70.67765895694856
At time: 121.09748554229736 and batch: 150, loss is 4.210787553787231 and perplexity is 67.40960760226626
At time: 121.80601048469543 and batch: 200, loss is 4.197590508460999 and perplexity is 66.52584431386461
At time: 122.50901389122009 and batch: 250, loss is 4.209338212013245 and perplexity is 67.31197880783519
At time: 123.22245573997498 and batch: 300, loss is 4.219272217750549 and perplexity is 67.98398874036124
At time: 123.93009400367737 and batch: 350, loss is 4.230098686218262 and perplexity is 68.72401395224763
At time: 124.64138460159302 and batch: 400, loss is 4.173105621337891 and perplexity is 64.9167462061951
At time: 125.34513807296753 and batch: 450, loss is 4.209319758415222 and perplexity is 67.31073667109712
At time: 126.0492479801178 and batch: 500, loss is 4.228001046180725 and perplexity is 68.58000679942963
At time: 126.75278949737549 and batch: 550, loss is 4.191864852905273 and perplexity is 66.14602862829314
At time: 127.45823383331299 and batch: 600, loss is 4.174321217536926 and perplexity is 64.99570673847538
At time: 128.23128175735474 and batch: 650, loss is 4.238336544036866 and perplexity is 69.29249090923986
At time: 128.935133934021 and batch: 700, loss is 4.270128493309021 and perplexity is 71.53082626130188
At time: 129.6433708667755 and batch: 750, loss is 4.221553311347962 and perplexity is 68.13924358990414
At time: 130.34752202033997 and batch: 800, loss is 4.2168493700027465 and perplexity is 67.81947326480783
At time: 131.0558099746704 and batch: 850, loss is 4.222747716903687 and perplexity is 68.22067810424775
At time: 131.76017498970032 and batch: 900, loss is 4.18774384021759 and perplexity is 65.87400090490716
At time: 132.465069770813 and batch: 950, loss is 4.263449063301087 and perplexity is 71.05463323331632
At time: 133.16885805130005 and batch: 1000, loss is 4.24233416557312 and perplexity is 69.57005048262407
At time: 133.87517857551575 and batch: 1050, loss is 4.200767908096314 and perplexity is 66.73755968137141
At time: 134.58813738822937 and batch: 1100, loss is 4.236902470588684 and perplexity is 69.19319160613352
At time: 135.29946947097778 and batch: 1150, loss is 4.196441674232483 and perplexity is 66.44946103110183
At time: 136.00722670555115 and batch: 1200, loss is 4.258488111495971 and perplexity is 70.70300754252438
At time: 136.71044945716858 and batch: 1250, loss is 4.267378702163696 and perplexity is 71.3344016157759
At time: 137.41633915901184 and batch: 1300, loss is 4.239157056808471 and perplexity is 69.34936961466828
At time: 138.12227249145508 and batch: 1350, loss is 4.132579588890076 and perplexity is 62.33852346658842
At time: 138.82635378837585 and batch: 1400, loss is 4.144373097419739 and perplexity is 63.07806570195223
At time: 139.53394293785095 and batch: 1450, loss is 4.091093130111695 and perplexity is 59.80523088424267
At time: 140.24112510681152 and batch: 1500, loss is 4.085875096321106 and perplexity is 59.49397793905687
At time: 140.94665336608887 and batch: 1550, loss is 4.1080920696258545 and perplexity is 60.83054633452121
At time: 141.65355706214905 and batch: 1600, loss is 4.188890538215637 and perplexity is 65.94958181582592
At time: 142.35705828666687 and batch: 1650, loss is 4.148565735816955 and perplexity is 63.343084397803594
At time: 143.05825662612915 and batch: 1700, loss is 4.152349443435669 and perplexity is 63.583210105087645
At time: 143.7718470096588 and batch: 1750, loss is 4.153081741333008 and perplexity is 63.629789008888785
At time: 144.47582697868347 and batch: 1800, loss is 4.114439024925232 and perplexity is 61.21786293329684
At time: 145.18320560455322 and batch: 1850, loss is 4.156040844917297 and perplexity is 63.81835500116945
At time: 145.88960313796997 and batch: 1900, loss is 4.248487157821655 and perplexity is 69.99943410634815
At time: 146.5983910560608 and batch: 1950, loss is 4.177851462364197 and perplexity is 65.22556298167278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482454521711483 and perplexity of 88.45151260573171
finished 5 epochs...
Completing Train Step...
At time: 149.32235407829285 and batch: 50, loss is 4.186537280082702 and perplexity is 65.79456789147991
At time: 150.02769136428833 and batch: 100, loss is 4.1506215810775755 and perplexity is 63.47344192919943
At time: 150.73638939857483 and batch: 150, loss is 4.1036397027969365 and perplexity is 60.560308473304154
At time: 151.44690370559692 and batch: 200, loss is 4.092199740409851 and perplexity is 59.87144860046868
At time: 152.15708470344543 and batch: 250, loss is 4.104254031181336 and perplexity is 60.59752381981871
At time: 152.860506772995 and batch: 300, loss is 4.111122169494629 and perplexity is 61.015148505249776
At time: 153.56971883773804 and batch: 350, loss is 4.126577458381653 and perplexity is 61.965480160268626
At time: 154.27831196784973 and batch: 400, loss is 4.0710551404953 and perplexity is 58.61878102223414
At time: 154.98470950126648 and batch: 450, loss is 4.108830370903015 and perplexity is 60.875474187675245
At time: 155.69458675384521 and batch: 500, loss is 4.129096159934997 and perplexity is 62.12174942661148
At time: 156.39600205421448 and batch: 550, loss is 4.094800767898559 and perplexity is 60.027378585245664
At time: 157.1068398952484 and batch: 600, loss is 4.078414840698242 and perplexity is 59.051789127243524
At time: 157.8164837360382 and batch: 650, loss is 4.135667061805725 and perplexity is 62.53128939605796
At time: 158.52607893943787 and batch: 700, loss is 4.1736459541320805 and perplexity is 64.95183233130075
At time: 159.231600522995 and batch: 750, loss is 4.126150813102722 and perplexity is 61.939048519569866
At time: 159.93907713890076 and batch: 800, loss is 4.1194909572601315 and perplexity is 61.527913953483115
At time: 160.64659690856934 and batch: 850, loss is 4.127833523750305 and perplexity is 62.043361755897934
At time: 161.35556769371033 and batch: 900, loss is 4.095109305381775 and perplexity is 60.045902139016775
At time: 162.05803155899048 and batch: 950, loss is 4.173095021247864 and perplexity is 64.91605808648812
At time: 162.76230883598328 and batch: 1000, loss is 4.146240572929383 and perplexity is 63.195972504613216
At time: 163.46504473686218 and batch: 1050, loss is 4.112746062278748 and perplexity is 61.11431105751474
At time: 164.22117805480957 and batch: 1100, loss is 4.140794553756714 and perplexity is 62.8527414963706
At time: 164.9272804260254 and batch: 1150, loss is 4.105502524375916 and perplexity is 60.67322666332522
At time: 165.63390111923218 and batch: 1200, loss is 4.167132201194764 and perplexity is 64.53012707563501
At time: 166.3431236743927 and batch: 1250, loss is 4.174795169830322 and perplexity is 65.02651890391641
At time: 167.0494933128357 and batch: 1300, loss is 4.15103850364685 and perplexity is 63.4999109570734
At time: 167.7580053806305 and batch: 1350, loss is 4.041729397773743 and perplexity is 56.92470318380159
At time: 168.46751475334167 and batch: 1400, loss is 4.055807495117188 and perplexity is 57.73176229543789
At time: 169.1722297668457 and batch: 1450, loss is 3.9997567892074586 and perplexity is 54.58487278845343
At time: 169.87658405303955 and batch: 1500, loss is 3.997259340286255 and perplexity is 54.448719944948216
At time: 170.5784468650818 and batch: 1550, loss is 4.023082332611084 and perplexity is 55.87306003565028
At time: 171.2834620475769 and batch: 1600, loss is 4.098987302780151 and perplexity is 60.27921208658693
At time: 171.98495078086853 and batch: 1650, loss is 4.060729384422302 and perplexity is 58.016612063318156
At time: 172.69114470481873 and batch: 1700, loss is 4.0659520721435545 and perplexity is 58.32040733414711
At time: 173.39859986305237 and batch: 1750, loss is 4.062086606025696 and perplexity is 58.09540692151276
At time: 174.10657835006714 and batch: 1800, loss is 4.0300876235961915 and perplexity is 56.26584124648531
At time: 174.81347227096558 and batch: 1850, loss is 4.072439565658569 and perplexity is 58.699990538999984
At time: 175.51604390144348 and batch: 1900, loss is 4.162938737869263 and perplexity is 64.26008894756801
At time: 176.22075843811035 and batch: 1950, loss is 4.089582643508911 and perplexity is 59.71496407478133
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4801808911700585 and perplexity of 88.25063499250906
finished 6 epochs...
Completing Train Step...
At time: 178.87406826019287 and batch: 50, loss is 4.100698418617249 and perplexity is 60.38244509766799
At time: 179.61536645889282 and batch: 100, loss is 4.06459005355835 and perplexity is 58.24102792584734
At time: 180.32905340194702 and batch: 150, loss is 4.020165424346924 and perplexity is 55.71032090802836
At time: 181.0413212776184 and batch: 200, loss is 4.010974164009094 and perplexity is 55.20061883554646
At time: 181.74779105186462 and batch: 250, loss is 4.018948740959168 and perplexity is 55.64258030384334
At time: 182.48056530952454 and batch: 300, loss is 4.025435147285461 and perplexity is 56.00467376184277
At time: 183.18665194511414 and batch: 350, loss is 4.045472168922425 and perplexity is 57.13815852859876
At time: 183.8965790271759 and batch: 400, loss is 3.990456500053406 and perplexity is 54.07957105637627
At time: 184.60606932640076 and batch: 450, loss is 4.031214256286621 and perplexity is 56.32926790515268
At time: 185.3111412525177 and batch: 500, loss is 4.049021944999695 and perplexity is 57.3413466195923
At time: 186.01536870002747 and batch: 550, loss is 4.016513891220093 and perplexity is 55.50726378625477
At time: 186.72425842285156 and batch: 600, loss is 4.000280694961548 and perplexity is 54.61347760985452
At time: 187.43768501281738 and batch: 650, loss is 4.054439291954041 and perplexity is 57.65282752736459
At time: 188.14549899101257 and batch: 700, loss is 4.093214602470398 and perplexity is 59.93224070474568
At time: 188.8534140586853 and batch: 750, loss is 4.051031889915467 and perplexity is 57.4567154713727
At time: 189.55976676940918 and batch: 800, loss is 4.040294542312622 and perplexity is 56.843083033128444
At time: 190.26741647720337 and batch: 850, loss is 4.048667321205139 and perplexity is 57.321015618810485
At time: 190.97447085380554 and batch: 900, loss is 4.017706890106201 and perplexity is 55.57352340609034
At time: 191.68309783935547 and batch: 950, loss is 4.099918832778931 and perplexity is 60.33539014265826
At time: 192.39214968681335 and batch: 1000, loss is 4.073263192176819 and perplexity is 58.748357323177785
At time: 193.09967851638794 and batch: 1050, loss is 4.040975384712219 and perplexity is 56.88179739187418
At time: 193.80845642089844 and batch: 1100, loss is 4.067941880226135 and perplexity is 58.43656928370602
At time: 194.5164303779602 and batch: 1150, loss is 4.031777238845825 and perplexity is 56.36098922899422
At time: 195.2217833995819 and batch: 1200, loss is 4.093320722579956 and perplexity is 59.938601058170086
At time: 195.92578959465027 and batch: 1250, loss is 4.099431862831116 and perplexity is 60.30601577366705
At time: 196.634441614151 and batch: 1300, loss is 4.072979245185852 and perplexity is 58.73167827198688
At time: 197.34266424179077 and batch: 1350, loss is 3.9675764513015745 and perplexity is 52.85627572795399
At time: 198.04591250419617 and batch: 1400, loss is 3.9843596458435058 and perplexity is 53.75085886928253
At time: 198.7515423297882 and batch: 1450, loss is 3.927117338180542 and perplexity is 50.760441377090835
At time: 199.45852398872375 and batch: 1500, loss is 3.9275604248046876 and perplexity is 50.78293763322778
At time: 200.16192483901978 and batch: 1550, loss is 3.9488512563705442 and perplexity is 51.87574066718354
At time: 200.86830401420593 and batch: 1600, loss is 4.027958340644837 and perplexity is 56.146162809819906
At time: 201.57232546806335 and batch: 1650, loss is 3.9913549423217773 and perplexity is 54.128180261881376
At time: 202.2768256664276 and batch: 1700, loss is 3.9996621894836424 and perplexity is 54.57970931879836
At time: 202.98759365081787 and batch: 1750, loss is 3.9933129072189333 and perplexity is 54.2342651601437
At time: 203.6985330581665 and batch: 1800, loss is 3.959097828865051 and perplexity is 52.4100218052362
At time: 204.40879154205322 and batch: 1850, loss is 4.005682520866394 and perplexity is 54.909288347708554
At time: 205.12079429626465 and batch: 1900, loss is 4.0927855587005615 and perplexity is 59.90653266559036
At time: 205.83354902267456 and batch: 1950, loss is 4.018976392745972 and perplexity is 55.64411894188409
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486974813771802 and perplexity of 88.85224430570047
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 208.47147870063782 and batch: 50, loss is 4.0652065849304195 and perplexity is 58.2769464180061
At time: 209.23612189292908 and batch: 100, loss is 4.051363315582275 and perplexity is 57.47576125756729
At time: 209.94161891937256 and batch: 150, loss is 4.014185628890991 and perplexity is 55.37817864533725
At time: 210.64804673194885 and batch: 200, loss is 3.997385835647583 and perplexity is 54.455607891088945
At time: 211.35345721244812 and batch: 250, loss is 4.007035465240478 and perplexity is 54.98362783772135
At time: 212.05732798576355 and batch: 300, loss is 4.015261092185974 and perplexity is 55.437767881087716
At time: 212.76770544052124 and batch: 350, loss is 4.026180696487427 and perplexity is 56.04644357046122
At time: 213.4769778251648 and batch: 400, loss is 3.959800148010254 and perplexity is 52.446843295655825
At time: 214.18331480026245 and batch: 450, loss is 3.9895979595184325 and perplexity is 54.03316147761337
At time: 214.895610332489 and batch: 500, loss is 4.012882719039917 and perplexity is 55.30607285471855
At time: 215.59742164611816 and batch: 550, loss is 3.9822811555862425 and perplexity is 53.63925425753108
At time: 216.3022747039795 and batch: 600, loss is 3.949337430000305 and perplexity is 51.90096741611339
At time: 217.0087604522705 and batch: 650, loss is 3.992703008651733 and perplexity is 54.20119784440865
At time: 217.7135899066925 and batch: 700, loss is 4.021487274169922 and perplexity is 55.78401027827057
At time: 218.47495079040527 and batch: 750, loss is 3.963452353477478 and perplexity is 52.63874015355267
At time: 219.17756152153015 and batch: 800, loss is 3.9644229412078857 and perplexity is 52.68985547082699
At time: 219.88217568397522 and batch: 850, loss is 3.978454351425171 and perplexity is 53.43437959377213
At time: 220.5841977596283 and batch: 900, loss is 3.9372421884536744 and perplexity is 51.27699384125742
At time: 221.289799451828 and batch: 950, loss is 4.018620409965515 and perplexity is 55.62431411900419
At time: 221.993803024292 and batch: 1000, loss is 3.9760579538345335 and perplexity is 53.30648288214846
At time: 222.69875836372375 and batch: 1050, loss is 3.939112424850464 and perplexity is 51.37298367531868
At time: 223.40174317359924 and batch: 1100, loss is 3.958366885185242 and perplexity is 52.371727028406546
At time: 224.11482524871826 and batch: 1150, loss is 3.9133905601501464 and perplexity is 50.068424512568654
At time: 224.82101321220398 and batch: 1200, loss is 3.9534983587265016 and perplexity is 52.117373555387424
At time: 225.52548384666443 and batch: 1250, loss is 3.9560289573669434 and perplexity is 52.2494287288987
At time: 226.2303855419159 and batch: 1300, loss is 3.9277484798431397 and perplexity is 50.792488518535016
At time: 226.93530654907227 and batch: 1350, loss is 3.8294744348526 and perplexity is 46.03833573007122
At time: 227.6417272090912 and batch: 1400, loss is 3.8422246742248536 and perplexity is 46.629093680365536
At time: 228.34469628334045 and batch: 1450, loss is 3.785259099006653 and perplexity is 44.04708163548448
At time: 229.04840517044067 and batch: 1500, loss is 3.771688175201416 and perplexity is 43.45335983553659
At time: 229.75523710250854 and batch: 1550, loss is 3.784406056404114 and perplexity is 44.0095236199031
At time: 230.4636640548706 and batch: 1600, loss is 3.8532560873031616 and perplexity is 47.14632613138627
At time: 231.16617727279663 and batch: 1650, loss is 3.8155787229537963 and perplexity is 45.40302455369843
At time: 231.869473695755 and batch: 1700, loss is 3.8041250324249267 and perplexity is 44.885959167520795
At time: 232.57338666915894 and batch: 1750, loss is 3.7910038661956786 and perplexity is 44.30085008726147
At time: 233.27803111076355 and batch: 1800, loss is 3.7518588733673095 and perplexity is 42.600196816373206
At time: 233.9923231601715 and batch: 1850, loss is 3.787652807235718 and perplexity is 44.15264378935532
At time: 234.70489931106567 and batch: 1900, loss is 3.8714036083221437 and perplexity is 48.00972566104776
At time: 235.4076566696167 and batch: 1950, loss is 3.79221399307251 and perplexity is 44.35449218694566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399636344022529 and perplexity of 81.42125395481743
finished 8 epochs...
Completing Train Step...
At time: 238.05315017700195 and batch: 50, loss is 3.98007851600647 and perplexity is 53.521236336261055
At time: 238.76502919197083 and batch: 100, loss is 3.952865891456604 and perplexity is 52.084421444085
At time: 239.47283744812012 and batch: 150, loss is 3.9135630416870115 and perplexity is 50.077061136184646
At time: 240.17572355270386 and batch: 200, loss is 3.8952940320968628 and perplexity is 49.170508945226096
At time: 240.88389110565186 and batch: 250, loss is 3.902030339241028 and perplexity is 49.50285473080088
At time: 241.58719944953918 and batch: 300, loss is 3.911736545562744 and perplexity is 49.98567905801539
At time: 242.29525208473206 and batch: 350, loss is 3.9246922588348387 and perplexity is 50.63749241987215
At time: 243.00062084197998 and batch: 400, loss is 3.8631696987152098 and perplexity is 47.616040926187814
At time: 243.7029573917389 and batch: 450, loss is 3.898649101257324 and perplexity is 49.3357564567985
At time: 244.4106843471527 and batch: 500, loss is 3.924995584487915 and perplexity is 50.6528544000541
At time: 245.1231505870819 and batch: 550, loss is 3.897835817337036 and perplexity is 49.295648791047455
At time: 245.8297562599182 and batch: 600, loss is 3.8703370332717895 and perplexity is 47.9585469832854
At time: 246.53592038154602 and batch: 650, loss is 3.914044156074524 and perplexity is 50.10115972740624
At time: 247.2434961795807 and batch: 700, loss is 3.9442035961151123 and perplexity is 51.635199259423224
At time: 247.94771671295166 and batch: 750, loss is 3.8899209833145143 and perplexity is 48.90702190028149
At time: 248.65140748023987 and batch: 800, loss is 3.8924062967300417 and perplexity is 49.028722347157306
At time: 249.35519123077393 and batch: 850, loss is 3.9098804569244385 and perplexity is 49.89298725574911
At time: 250.05646443367004 and batch: 900, loss is 3.8675178480148316 and perplexity is 47.82353335831732
At time: 250.76026248931885 and batch: 950, loss is 3.952018632888794 and perplexity is 52.04031116081349
At time: 251.46369051933289 and batch: 1000, loss is 3.9124672698974607 and perplexity is 50.02221815846949
At time: 252.16902589797974 and batch: 1050, loss is 3.8808214807510377 and perplexity is 48.464010975457036
At time: 252.87949538230896 and batch: 1100, loss is 3.9011680364608763 and perplexity is 49.4601866805741
At time: 253.5904312133789 and batch: 1150, loss is 3.860657935142517 and perplexity is 47.496590767193105
At time: 254.34543418884277 and batch: 1200, loss is 3.9028016471862794 and perplexity is 49.54105140477277
At time: 255.0525221824646 and batch: 1250, loss is 3.909441599845886 and perplexity is 49.871096169002335
At time: 255.7594017982483 and batch: 1300, loss is 3.881843957901001 and perplexity is 48.51358966149244
At time: 256.4619734287262 and batch: 1350, loss is 3.7843617248535155 and perplexity is 44.007572652724946
At time: 257.1672840118408 and batch: 1400, loss is 3.8020549488067625 and perplexity is 44.79313758612699
At time: 257.86960673332214 and batch: 1450, loss is 3.746058712005615 and perplexity is 42.353823992568095
At time: 258.5737931728363 and batch: 1500, loss is 3.73662437915802 and perplexity is 41.956122891765226
At time: 259.2765374183655 and batch: 1550, loss is 3.7520916986465456 and perplexity is 42.61011637380955
At time: 259.98178339004517 and batch: 1600, loss is 3.8261030960083007 and perplexity is 45.88338624087545
At time: 260.6868541240692 and batch: 1650, loss is 3.786273031234741 and perplexity is 44.0917650402519
At time: 261.39511489868164 and batch: 1700, loss is 3.7824466943740847 and perplexity is 43.92337745368645
At time: 262.1023440361023 and batch: 1750, loss is 3.7705044889450074 and perplexity is 43.40195512023397
At time: 262.80909609794617 and batch: 1800, loss is 3.734934754371643 and perplexity is 41.88529264171078
At time: 263.51942801475525 and batch: 1850, loss is 3.776105275154114 and perplexity is 43.645722198341105
At time: 264.2270290851593 and batch: 1900, loss is 3.861919889450073 and perplexity is 47.55656713026135
At time: 264.9343168735504 and batch: 1950, loss is 3.7857647514343262 and perplexity is 44.06935978126995
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399619027071221 and perplexity of 81.4198439991354
finished 9 epochs...
Completing Train Step...
At time: 267.5498502254486 and batch: 50, loss is 3.9349271202087404 and perplexity is 51.15842140571779
At time: 268.28607058525085 and batch: 100, loss is 3.9073044204711915 and perplexity is 49.76462650378813
At time: 268.9940640926361 and batch: 150, loss is 3.8688000726699827 and perplexity is 47.884893202031215
At time: 269.7019295692444 and batch: 200, loss is 3.8500996017456055 and perplexity is 46.99774405581376
At time: 270.4073133468628 and batch: 250, loss is 3.855875701904297 and perplexity is 47.2699932450774
At time: 271.110586643219 and batch: 300, loss is 3.865411915779114 and perplexity is 47.72292621089188
At time: 271.81320309638977 and batch: 350, loss is 3.8800684881210326 and perplexity is 48.42753166842034
At time: 272.54768443107605 and batch: 400, loss is 3.8186166381835935 and perplexity is 45.54116481643243
At time: 273.2529423236847 and batch: 450, loss is 3.854617257118225 and perplexity is 47.210543983193034
At time: 273.9659204483032 and batch: 500, loss is 3.8837252950668333 and perplexity is 48.6049459898527
At time: 274.6729073524475 and batch: 550, loss is 3.8585360860824585 and perplexity is 47.395917015741674
At time: 275.37997174263 and batch: 600, loss is 3.833086051940918 and perplexity is 46.20490918882448
At time: 276.0927381515503 and batch: 650, loss is 3.874875020980835 and perplexity is 48.17667684101098
At time: 276.79826641082764 and batch: 700, loss is 3.9051121616363527 and perplexity is 49.65564905870159
At time: 277.50254464149475 and batch: 750, loss is 3.852823004722595 and perplexity is 47.12591229955761
At time: 278.2105007171631 and batch: 800, loss is 3.854955306053162 and perplexity is 47.22650615514994
At time: 278.9199776649475 and batch: 850, loss is 3.875070753097534 and perplexity is 48.186107486854624
At time: 279.6244008541107 and batch: 900, loss is 3.831867523193359 and perplexity is 46.14864146757976
At time: 280.3332815170288 and batch: 950, loss is 3.9181338787078857 and perplexity is 50.30647913784298
At time: 281.0396010875702 and batch: 1000, loss is 3.878256001472473 and perplexity is 48.33983691064468
At time: 281.7520043849945 and batch: 1050, loss is 3.8487829828262328 and perplexity is 46.93590665390153
At time: 282.456378698349 and batch: 1100, loss is 3.8702584743499755 and perplexity is 47.95477955952694
At time: 283.16506695747375 and batch: 1150, loss is 3.830833115577698 and perplexity is 46.10092964238523
At time: 283.87792801856995 and batch: 1200, loss is 3.8725455808639526 and perplexity is 48.06458276618474
At time: 284.58068799972534 and batch: 1250, loss is 3.8814027214050295 and perplexity is 48.49218841703547
At time: 285.2839047908783 and batch: 1300, loss is 3.853825707435608 and perplexity is 47.17318927808983
At time: 285.99267077445984 and batch: 1350, loss is 3.755330147743225 and perplexity is 42.748330745999915
At time: 286.70040917396545 and batch: 1400, loss is 3.776284065246582 and perplexity is 43.653526318677685
At time: 287.4041123390198 and batch: 1450, loss is 3.7219401454925536 and perplexity is 41.34453075007814
At time: 288.11371994018555 and batch: 1500, loss is 3.7135683155059813 and perplexity is 40.99984620115708
At time: 288.82139706611633 and batch: 1550, loss is 3.7294600296020506 and perplexity is 41.65660875446203
At time: 289.5272808074951 and batch: 1600, loss is 3.804705443382263 and perplexity is 44.91201903203605
At time: 290.2293322086334 and batch: 1650, loss is 3.765285625457764 and perplexity is 43.17603627396128
At time: 290.93387269973755 and batch: 1700, loss is 3.7640832805633546 and perplexity is 43.1241549830392
At time: 291.65099573135376 and batch: 1750, loss is 3.7513906860351565 and perplexity is 42.58025661211631
At time: 292.360915184021 and batch: 1800, loss is 3.7179937744140625 and perplexity is 41.1816914132331
At time: 293.0710916519165 and batch: 1850, loss is 3.7611384487152097 and perplexity is 42.997348401689706
At time: 293.78120398521423 and batch: 1900, loss is 3.8474264097213746 and perplexity is 46.87227783361382
At time: 294.4944911003113 and batch: 1950, loss is 3.7728923892974855 and perplexity is 43.50571850316767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4034514671148255 and perplexity of 81.73247936511441
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 297.1377606391907 and batch: 50, loss is 3.9291384267807006 and perplexity is 50.86313646947994
At time: 297.8765516281128 and batch: 100, loss is 3.9359869527816773 and perplexity is 51.212669508979204
At time: 298.5831115245819 and batch: 150, loss is 3.913897213935852 and perplexity is 50.093798296711384
At time: 299.29513573646545 and batch: 200, loss is 3.903621206283569 and perplexity is 49.581669866482216
At time: 300.0001847743988 and batch: 250, loss is 3.907136654853821 and perplexity is 49.75627841078057
At time: 300.7088215351105 and batch: 300, loss is 3.9108663511276247 and perplexity is 49.94220071831169
At time: 301.41925382614136 and batch: 350, loss is 3.9227421188354494 and perplexity is 50.5388384462309
At time: 302.1245789527893 and batch: 400, loss is 3.862009644508362 and perplexity is 47.56083576427902
At time: 302.83001923561096 and batch: 450, loss is 3.8918621349334717 and perplexity is 49.002050047202836
At time: 303.5380754470825 and batch: 500, loss is 3.912415976524353 and perplexity is 50.01965241597318
At time: 304.2416114807129 and batch: 550, loss is 3.896343913078308 and perplexity is 49.22215923600036
At time: 304.9507164955139 and batch: 600, loss is 3.8693816375732424 and perplexity is 47.912749474643974
At time: 305.65809893608093 and batch: 650, loss is 3.9001256895065306 and perplexity is 49.40865886522229
At time: 306.36166167259216 and batch: 700, loss is 3.926082344055176 and perplexity is 50.70793179670557
At time: 307.0721516609192 and batch: 750, loss is 3.8668480682373048 and perplexity is 47.79151284732645
At time: 307.7820954322815 and batch: 800, loss is 3.858619785308838 and perplexity is 47.39988418335155
At time: 308.5406413078308 and batch: 850, loss is 3.885372815132141 and perplexity is 48.68508961463119
At time: 309.2455794811249 and batch: 900, loss is 3.8446881341934205 and perplexity is 46.744104189747524
At time: 309.95470333099365 and batch: 950, loss is 3.9443149852752684 and perplexity is 51.64095118124814
At time: 310.6588659286499 and batch: 1000, loss is 3.9015344619750976 and perplexity is 49.47831347576931
At time: 311.361918926239 and batch: 1050, loss is 3.8653446531295774 and perplexity is 47.719716348384445
At time: 312.0663266181946 and batch: 1100, loss is 3.8795870113372803 and perplexity is 48.404220548559415
At time: 312.77353978157043 and batch: 1150, loss is 3.852956142425537 and perplexity is 47.13218695295741
At time: 313.478476524353 and batch: 1200, loss is 3.875150508880615 and perplexity is 48.189950760850486
At time: 314.18323826789856 and batch: 1250, loss is 3.8776203346252442 and perplexity is 48.30911864324659
At time: 314.8861918449402 and batch: 1300, loss is 3.843171353340149 and perplexity is 46.67325737064122
At time: 315.5913887023926 and batch: 1350, loss is 3.734565200805664 and perplexity is 41.86981664223449
At time: 316.29613065719604 and batch: 1400, loss is 3.7472380208969116 and perplexity is 42.403801697566585
At time: 317.00756788253784 and batch: 1450, loss is 3.6998117685317995 and perplexity is 40.43969162108394
At time: 317.7143952846527 and batch: 1500, loss is 3.7014141130447387 and perplexity is 40.50454188141204
At time: 318.4204568862915 and batch: 1550, loss is 3.717782206535339 and perplexity is 41.172979611739734
At time: 319.12345719337463 and batch: 1600, loss is 3.7836882877349853 and perplexity is 43.97794629666779
At time: 319.83404517173767 and batch: 1650, loss is 3.7433801031112672 and perplexity is 42.24052647052903
At time: 320.54165148735046 and batch: 1700, loss is 3.725121035575867 and perplexity is 41.476252543148895
At time: 321.2473101615906 and batch: 1750, loss is 3.71386531829834 and perplexity is 41.01202507845585
At time: 321.9564332962036 and batch: 1800, loss is 3.6819426155090333 and perplexity is 39.723486628928995
At time: 322.65903902053833 and batch: 1850, loss is 3.715757746696472 and perplexity is 41.08971088360655
At time: 323.3629159927368 and batch: 1900, loss is 3.806094460487366 and perplexity is 44.97444594068117
At time: 324.0727787017822 and batch: 1950, loss is 3.7306461572647094 and perplexity is 41.706048125344616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376713242641715 and perplexity of 79.5760559253642
finished 11 epochs...
Completing Train Step...
At time: 326.7448019981384 and batch: 50, loss is 3.926799454689026 and perplexity is 50.744308035152365
At time: 327.45161175727844 and batch: 100, loss is 3.9132007122039796 and perplexity is 50.05892002723919
At time: 328.1608507633209 and batch: 150, loss is 3.8802655220031737 and perplexity is 48.437074473084536
At time: 328.8660469055176 and batch: 200, loss is 3.862170333862305 and perplexity is 47.56847889831966
At time: 329.5729355812073 and batch: 250, loss is 3.8662963104248047 and perplexity is 47.7651507801488
At time: 330.28380489349365 and batch: 300, loss is 3.8679220199584963 and perplexity is 47.842866195379656
At time: 330.99299454689026 and batch: 350, loss is 3.8845836782455443 and perplexity is 48.64668556960624
At time: 331.70584774017334 and batch: 400, loss is 3.8226088285446167 and perplexity is 45.72333720712452
At time: 332.41373467445374 and batch: 450, loss is 3.8539186239242555 and perplexity is 47.17757264883641
At time: 333.1257972717285 and batch: 500, loss is 3.874846963882446 and perplexity is 48.175325162210974
At time: 333.8300256729126 and batch: 550, loss is 3.860617232322693 and perplexity is 47.49465756136059
At time: 334.53793811798096 and batch: 600, loss is 3.8353412199020385 and perplexity is 46.309226602106406
At time: 335.240877866745 and batch: 650, loss is 3.868118848800659 and perplexity is 47.85228397815388
At time: 335.949777841568 and batch: 700, loss is 3.8960264253616335 and perplexity is 49.2065342855509
At time: 336.65544843673706 and batch: 750, loss is 3.8393036413192747 and perplexity is 46.49308729963005
At time: 337.3603820800781 and batch: 800, loss is 3.8326894092559813 and perplexity is 46.186585983709435
At time: 338.07173681259155 and batch: 850, loss is 3.8591812896728515 and perplexity is 47.426506898860225
At time: 338.7779052257538 and batch: 900, loss is 3.8187660789489746 and perplexity is 45.54797103150927
At time: 339.48923563957214 and batch: 950, loss is 3.9177964735031128 and perplexity is 50.28950833312799
At time: 340.1961364746094 and batch: 1000, loss is 3.877330994606018 and perplexity is 48.29514290389741
At time: 340.9012279510498 and batch: 1050, loss is 3.8429486465454104 and perplexity is 46.662864076463755
At time: 341.6084523200989 and batch: 1100, loss is 3.8580644226074217 and perplexity is 47.373567363991015
At time: 342.3126690387726 and batch: 1150, loss is 3.8335229349136353 and perplexity is 46.22509973703725
At time: 343.01450061798096 and batch: 1200, loss is 3.857583312988281 and perplexity is 47.35078096685614
At time: 343.71893334388733 and batch: 1250, loss is 3.861804165840149 and perplexity is 47.55106403106283
At time: 344.4213356971741 and batch: 1300, loss is 3.827921528816223 and perplexity is 45.96689800300615
At time: 345.1252224445343 and batch: 1350, loss is 3.72044153213501 and perplexity is 41.28261768749325
At time: 345.83251452445984 and batch: 1400, loss is 3.7348841524124143 and perplexity is 41.883173217464204
At time: 346.53838324546814 and batch: 1450, loss is 3.688993368148804 and perplexity is 40.004556820932706
At time: 347.2489597797394 and batch: 1500, loss is 3.6929917669296266 and perplexity is 40.164831199063876
At time: 347.95845079421997 and batch: 1550, loss is 3.712286882400513 and perplexity is 40.94734128886694
At time: 348.6716058254242 and batch: 1600, loss is 3.780912399291992 and perplexity is 43.8560377044036
At time: 349.3871054649353 and batch: 1650, loss is 3.740230526924133 and perplexity is 42.10769600386743
At time: 350.11492562294006 and batch: 1700, loss is 3.7244428777694703 and perplexity is 41.4481346339741
At time: 350.8342881202698 and batch: 1750, loss is 3.715036277770996 and perplexity is 41.06007662543086
At time: 351.5393490791321 and batch: 1800, loss is 3.6838331508636473 and perplexity is 39.798656317898
At time: 352.2427842617035 and batch: 1850, loss is 3.7189259147644043 and perplexity is 41.22009642614499
At time: 352.949120759964 and batch: 1900, loss is 3.8104703426361084 and perplexity is 45.17168003767924
At time: 353.654757976532 and batch: 1950, loss is 3.7353135776519775 and perplexity is 41.9011627714646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.374994890079942 and perplexity of 79.43943362206896
finished 12 epochs...
Completing Train Step...
At time: 356.3138816356659 and batch: 50, loss is 3.913148522377014 and perplexity is 50.0563075290384
At time: 357.0666675567627 and batch: 100, loss is 3.8971573543548583 and perplexity is 49.26221486128465
At time: 357.7759668827057 and batch: 150, loss is 3.864341626167297 and perplexity is 47.67187618275351
At time: 358.4862711429596 and batch: 200, loss is 3.8446667623519897 and perplexity is 46.7431051928402
At time: 359.1906599998474 and batch: 250, loss is 3.8488721227645875 and perplexity is 46.940090704207506
At time: 359.8958990573883 and batch: 300, loss is 3.849689860343933 and perplexity is 46.97849107892912
At time: 360.5977203845978 and batch: 350, loss is 3.8668544721603393 and perplexity is 47.791818901476404
At time: 361.30541157722473 and batch: 400, loss is 3.8041510725021364 and perplexity is 44.887128016581535
At time: 362.0122332572937 and batch: 450, loss is 3.83640718460083 and perplexity is 46.35861692238476
At time: 362.77274203300476 and batch: 500, loss is 3.8576248550415038 and perplexity is 47.352748056377386
At time: 363.4829077720642 and batch: 550, loss is 3.8439623403549192 and perplexity is 46.710189915814645
At time: 364.1933915615082 and batch: 600, loss is 3.8196828174591064 and perplexity is 45.58974575593589
At time: 364.90120363235474 and batch: 650, loss is 3.8532611560821532 and perplexity is 47.14656510629935
At time: 365.6148638725281 and batch: 700, loss is 3.88153000831604 and perplexity is 48.49836123075808
At time: 366.3218786716461 and batch: 750, loss is 3.8255428647994996 and perplexity is 45.85768813505042
At time: 367.0308668613434 and batch: 800, loss is 3.8197918796539305 and perplexity is 45.594718144814394
At time: 367.735963344574 and batch: 850, loss is 3.845781397819519 and perplexity is 46.795235763644875
At time: 368.436514377594 and batch: 900, loss is 3.805240092277527 and perplexity is 44.9360376135775
At time: 369.14378213882446 and batch: 950, loss is 3.9042625522613523 and perplexity is 49.613479070284995
At time: 369.8500556945801 and batch: 1000, loss is 3.864561719894409 and perplexity is 47.68236961838831
At time: 370.5604588985443 and batch: 1050, loss is 3.8312062644958496 and perplexity is 46.1181353643557
At time: 371.2708489894867 and batch: 1100, loss is 3.84667537689209 and perplexity is 46.837088430030136
At time: 371.98150277137756 and batch: 1150, loss is 3.8235171604156495 and perplexity is 45.764888039675625
At time: 372.6882483959198 and batch: 1200, loss is 3.84863564491272 and perplexity is 46.928991724774434
At time: 373.3891558647156 and batch: 1250, loss is 3.853565425872803 and perplexity is 47.160912564432444
At time: 374.09391951560974 and batch: 1300, loss is 3.819350838661194 and perplexity is 45.574613438885876
At time: 374.7984764575958 and batch: 1350, loss is 3.711739673614502 and perplexity is 40.92494067341565
At time: 375.5020971298218 and batch: 1400, loss is 3.726297698020935 and perplexity is 41.52508481579508
At time: 376.2103750705719 and batch: 1450, loss is 3.68105357170105 and perplexity is 39.68818640315871
At time: 376.91529750823975 and batch: 1500, loss is 3.6862966346740724 and perplexity is 39.89682052673892
At time: 377.6287977695465 and batch: 1550, loss is 3.7070672416687014 and perplexity is 40.7341677071576
At time: 378.34067392349243 and batch: 1600, loss is 3.776931438446045 and perplexity is 43.68179559107583
At time: 379.0545496940613 and batch: 1650, loss is 3.7361931705474856 and perplexity is 41.938034950427955
At time: 379.76438999176025 and batch: 1700, loss is 3.72154465675354 and perplexity is 41.32818268669727
At time: 380.4700548648834 and batch: 1750, loss is 3.7126226568222047 and perplexity is 40.96109266725939
At time: 381.1764361858368 and batch: 1800, loss is 3.681660590171814 and perplexity is 39.712285178837554
At time: 381.8901877403259 and batch: 1850, loss is 3.717141337394714 and perplexity is 41.14660157301731
At time: 382.5969853401184 and batch: 1900, loss is 3.8093935823440552 and perplexity is 45.12306714320343
At time: 383.3047561645508 and batch: 1950, loss is 3.734245228767395 and perplexity is 41.85642161479292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.374980128088663 and perplexity of 79.43826094649815
finished 13 epochs...
Completing Train Step...
At time: 385.9425001144409 and batch: 50, loss is 3.9009575033187867 and perplexity is 49.44977476812868
At time: 386.689644575119 and batch: 100, loss is 3.8839248037338256 and perplexity is 48.61464406522925
At time: 387.39353919029236 and batch: 150, loss is 3.8515595197677612 and perplexity is 47.066407018314244
At time: 388.09566354751587 and batch: 200, loss is 3.83116593837738 and perplexity is 46.11627563646347
At time: 388.8012731075287 and batch: 250, loss is 3.8353731536865237 and perplexity is 46.31070545458095
At time: 389.5096435546875 and batch: 300, loss is 3.8358372974395754 and perplexity is 46.332205268333254
At time: 390.2173001766205 and batch: 350, loss is 3.8534191465377807 and perplexity is 47.154014402045085
At time: 390.9257688522339 and batch: 400, loss is 3.79041139125824 and perplexity is 44.27461071772951
At time: 391.6396744251251 and batch: 450, loss is 3.8233410120010376 and perplexity is 45.75682733716337
At time: 392.3440420627594 and batch: 500, loss is 3.8446580934524537 and perplexity is 46.74269998331364
At time: 393.0557019710541 and batch: 550, loss is 3.831640291213989 and perplexity is 46.138156211771665
At time: 393.7699091434479 and batch: 600, loss is 3.8081391048431397 and perplexity is 45.06649676125446
At time: 394.4731295108795 and batch: 650, loss is 3.842132363319397 and perplexity is 46.6247895051715
At time: 395.17398405075073 and batch: 700, loss is 3.870400810241699 and perplexity is 47.96160573163108
At time: 395.8887679576874 and batch: 750, loss is 3.815019292831421 and perplexity is 45.37763183750354
At time: 396.59485816955566 and batch: 800, loss is 3.8097385931015015 and perplexity is 45.138637772639676
At time: 397.29988527297974 and batch: 850, loss is 3.83535825252533 and perplexity is 46.310015376435466
At time: 398.01079654693604 and batch: 900, loss is 3.7946022844314573 and perplexity is 44.46055023571461
At time: 398.7756333351135 and batch: 950, loss is 3.893934235572815 and perplexity is 49.10369249675946
At time: 399.4823372364044 and batch: 1000, loss is 3.8546275424957277 and perplexity is 47.21102956395719
At time: 400.1965193748474 and batch: 1050, loss is 3.8217844676971438 and perplexity is 45.685660209969505
At time: 400.909779548645 and batch: 1100, loss is 3.8375587463378906 and perplexity is 46.41203248156985
At time: 401.62615942955017 and batch: 1150, loss is 3.815618233680725 and perplexity is 45.404818495643056
At time: 402.3347566127777 and batch: 1200, loss is 3.841584801673889 and perplexity is 46.59926654704276
At time: 403.03801703453064 and batch: 1250, loss is 3.8470327186584474 and perplexity is 46.853828268684396
At time: 403.7431786060333 and batch: 1300, loss is 3.8123902463912964 and perplexity is 45.25848862120956
At time: 404.4458041191101 and batch: 1350, loss is 3.704233784675598 and perplexity is 40.61891255717516
At time: 405.1504554748535 and batch: 1400, loss is 3.7187703227996827 and perplexity is 41.213683409275916
At time: 405.86154413223267 and batch: 1450, loss is 3.67355592250824 and perplexity is 39.39173105228223
At time: 406.5719316005707 and batch: 1500, loss is 3.6795687580108645 and perplexity is 39.629300568713894
At time: 407.2786524295807 and batch: 1550, loss is 3.7016277217864992 and perplexity is 40.5131949297894
At time: 407.98699402809143 and batch: 1600, loss is 3.7723507118225097 and perplexity is 43.48215881687362
At time: 408.69811177253723 and batch: 1650, loss is 3.7316110563278198 and perplexity is 41.74630967314795
At time: 409.4105689525604 and batch: 1700, loss is 3.7177630281448364 and perplexity is 41.17218998783046
At time: 410.1129822731018 and batch: 1750, loss is 3.7091915512084963 and perplexity is 40.82079166368655
At time: 410.8148744106293 and batch: 1800, loss is 3.678356943130493 and perplexity is 39.5813062785568
At time: 411.52027440071106 and batch: 1850, loss is 3.713988604545593 and perplexity is 41.01708160881395
At time: 412.2306249141693 and batch: 1900, loss is 3.8067610359191892 and perplexity is 45.00443479521153
At time: 412.9400427341461 and batch: 1950, loss is 3.731619424819946 and perplexity is 41.74665902827354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375624261900436 and perplexity of 79.48944629966076
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 415.65732741355896 and batch: 50, loss is 3.903423562049866 and perplexity is 49.57187130368234
At time: 416.3683009147644 and batch: 100, loss is 3.9063173151016235 and perplexity is 49.71552781053029
At time: 417.15018796920776 and batch: 150, loss is 3.887935171127319 and perplexity is 48.80999810755156
At time: 417.86927938461304 and batch: 200, loss is 3.8777103519439695 and perplexity is 48.31346749630995
At time: 418.57757210731506 and batch: 250, loss is 3.8857731008529663 and perplexity is 48.70458146171479
At time: 419.289342880249 and batch: 300, loss is 3.8847695446014403 and perplexity is 48.655728192113095
At time: 419.9989252090454 and batch: 350, loss is 3.898729906082153 and perplexity is 49.33974318502807
At time: 420.70813941955566 and batch: 400, loss is 3.841184124946594 and perplexity is 46.58059904549479
At time: 421.43500328063965 and batch: 450, loss is 3.875351166725159 and perplexity is 48.199621422713456
At time: 422.1468765735626 and batch: 500, loss is 3.8962168645858766 and perplexity is 49.21590603211368
At time: 422.85610580444336 and batch: 550, loss is 3.8839221811294555 and perplexity is 48.614516568418466
At time: 423.56772470474243 and batch: 600, loss is 3.847688398361206 and perplexity is 46.884559446680555
At time: 424.2799298763275 and batch: 650, loss is 3.874793248176575 and perplexity is 48.17273746011505
At time: 424.9881212711334 and batch: 700, loss is 3.9047740793228147 and perplexity is 49.63886419947949
At time: 425.6943531036377 and batch: 750, loss is 3.846802806854248 and perplexity is 46.84305725873211
At time: 426.40284395217896 and batch: 800, loss is 3.834927406311035 and perplexity is 46.290067179237795
At time: 427.112343788147 and batch: 850, loss is 3.85361777305603 and perplexity is 47.16338136998056
At time: 427.81772089004517 and batch: 900, loss is 3.805448155403137 and perplexity is 44.94538811872985
At time: 428.5250551700592 and batch: 950, loss is 3.9078778982162476 and perplexity is 49.79317359435727
At time: 429.2421259880066 and batch: 1000, loss is 3.8698720693588258 and perplexity is 47.93625317293029
At time: 429.95635986328125 and batch: 1050, loss is 3.842811255455017 and perplexity is 46.656453455078626
At time: 430.6700747013092 and batch: 1100, loss is 3.8526092195510864 and perplexity is 47.1158385551611
At time: 431.3832120895386 and batch: 1150, loss is 3.8369373083114624 and perplexity is 46.38319923966637
At time: 432.0923492908478 and batch: 1200, loss is 3.8702721786499024 and perplexity is 47.95543675071212
At time: 432.80466413497925 and batch: 1250, loss is 3.8802123212814332 and perplexity is 48.43449765430849
At time: 433.5132610797882 and batch: 1300, loss is 3.861038155555725 and perplexity is 47.51465337422893
At time: 434.22228598594666 and batch: 1350, loss is 3.7450703811645507 and perplexity is 42.31198508082832
At time: 434.9311969280243 and batch: 1400, loss is 3.741846551895142 and perplexity is 42.175798104608084
At time: 435.65075635910034 and batch: 1450, loss is 3.670978751182556 and perplexity is 39.29034251647581
At time: 436.36453104019165 and batch: 1500, loss is 3.666533627510071 and perplexity is 39.116079681721764
At time: 437.0804748535156 and batch: 1550, loss is 3.6913098001480105 and perplexity is 40.0973320687583
At time: 437.79628467559814 and batch: 1600, loss is 3.766473340988159 and perplexity is 43.22734758837534
At time: 438.50923776626587 and batch: 1650, loss is 3.7231447744369506 and perplexity is 41.39436557872431
At time: 439.2184269428253 and batch: 1700, loss is 3.71146276473999 and perplexity is 40.91360976304152
At time: 439.92921471595764 and batch: 1750, loss is 3.708658766746521 and perplexity is 40.799048772814146
At time: 440.63956236839294 and batch: 1800, loss is 3.673809304237366 and perplexity is 39.40171346183621
At time: 441.3432824611664 and batch: 1850, loss is 3.7078299951553344 and perplexity is 40.765249688039034
At time: 442.0481963157654 and batch: 1900, loss is 3.8058091497421263 and perplexity is 44.96161607832892
At time: 442.75511932373047 and batch: 1950, loss is 3.734663472175598 and perplexity is 41.87393144865533
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358911416696948 and perplexity of 78.17199136427067
finished 15 epochs...
Completing Train Step...
At time: 445.46656823158264 and batch: 50, loss is 3.914262490272522 and perplexity is 50.11209971817769
At time: 446.211327791214 and batch: 100, loss is 3.8996072578430176 and perplexity is 49.383050490684525
At time: 446.9176480770111 and batch: 150, loss is 3.8697026634216307 and perplexity is 47.928133174843275
At time: 447.6219983100891 and batch: 200, loss is 3.8548868227005006 and perplexity is 47.22327203641688
At time: 448.32967257499695 and batch: 250, loss is 3.860993227958679 and perplexity is 47.512518702981545
At time: 449.03244185447693 and batch: 300, loss is 3.858740863800049 and perplexity is 47.40562363726724
At time: 449.740047454834 and batch: 350, loss is 3.875635108947754 and perplexity is 48.21330927353589
At time: 450.4518256187439 and batch: 400, loss is 3.8157405185699464 and perplexity is 45.41037115833936
At time: 451.1650176048279 and batch: 450, loss is 3.8522495317459104 and perplexity is 47.09889461005006
At time: 451.8844201564789 and batch: 500, loss is 3.872177767753601 and perplexity is 48.04690723334539
At time: 452.5975501537323 and batch: 550, loss is 3.8599010133743286 and perplexity is 47.46065316641865
At time: 453.35033559799194 and batch: 600, loss is 3.8277794313430786 and perplexity is 45.96036668700437
At time: 454.0598816871643 and batch: 650, loss is 3.8577865839004515 and perplexity is 47.36040698160651
At time: 454.7672221660614 and batch: 700, loss is 3.8894147205352785 and perplexity is 48.88226836187638
At time: 455.4729995727539 and batch: 750, loss is 3.833989667892456 and perplexity is 46.24667955114751
At time: 456.180623292923 and batch: 800, loss is 3.824516897201538 and perplexity is 45.81066375977396
At time: 456.8871593475342 and batch: 850, loss is 3.842486901283264 and perplexity is 46.64132269375671
At time: 457.59469389915466 and batch: 900, loss is 3.795636682510376 and perplexity is 44.5065639376057
At time: 458.30619955062866 and batch: 950, loss is 3.8982404565811155 and perplexity is 49.315599781315264
At time: 459.0218315124512 and batch: 1000, loss is 3.8598929119110106 and perplexity is 47.46026866723548
At time: 459.73514008522034 and batch: 1050, loss is 3.832919006347656 and perplexity is 46.197191506977745
At time: 460.4449346065521 and batch: 1100, loss is 3.8423961496353147 and perplexity is 46.637090108919644
At time: 461.1572091579437 and batch: 1150, loss is 3.8273939323425292 and perplexity is 45.942652426215936
At time: 461.8630599975586 and batch: 1200, loss is 3.861467819213867 and perplexity is 47.53507308050177
At time: 462.5736756324768 and batch: 1250, loss is 3.872861928939819 and perplexity is 48.07979030977191
At time: 463.28513860702515 and batch: 1300, loss is 3.8539811897277834 and perplexity is 47.18052444391743
At time: 463.99369502067566 and batch: 1350, loss is 3.738796992301941 and perplexity is 42.04737640922863
At time: 464.7041759490967 and batch: 1400, loss is 3.737566547393799 and perplexity is 41.99567124572619
At time: 465.4210135936737 and batch: 1450, loss is 3.668380784988403 and perplexity is 39.18840001378698
At time: 466.1306917667389 and batch: 1500, loss is 3.6651121473312376 and perplexity is 39.06051645015266
At time: 466.84664940834045 and batch: 1550, loss is 3.69151469707489 and perplexity is 40.10554873063089
At time: 467.5627567768097 and batch: 1600, loss is 3.768259201049805 and perplexity is 43.304614555464006
At time: 468.2700250148773 and batch: 1650, loss is 3.725933337211609 and perplexity is 41.509957458359715
At time: 468.98088240623474 and batch: 1700, loss is 3.7146637058258056 and perplexity is 41.0447816422306
At time: 469.68894481658936 and batch: 1750, loss is 3.712946124076843 and perplexity is 40.9743443825839
At time: 470.39520621299744 and batch: 1800, loss is 3.678434104919434 and perplexity is 39.584360560793286
At time: 471.10033893585205 and batch: 1850, loss is 3.712607398033142 and perplexity is 40.96046765535508
At time: 471.8090977668762 and batch: 1900, loss is 3.811373038291931 and perplexity is 45.212474726839645
At time: 472.5231170654297 and batch: 1950, loss is 3.7393289470672606 and perplexity is 42.06974966173027
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357624000726744 and perplexity of 78.07141624906187
finished 16 epochs...
Completing Train Step...
At time: 475.16481280326843 and batch: 50, loss is 3.910875053405762 and perplexity is 49.94263533112419
At time: 475.9004473686218 and batch: 100, loss is 3.894058680534363 and perplexity is 49.10980358412321
At time: 476.61158418655396 and batch: 150, loss is 3.863625192642212 and perplexity is 47.63773468396996
At time: 477.3180413246155 and batch: 200, loss is 3.84768394947052 and perplexity is 46.88435086286469
At time: 478.02355313301086 and batch: 250, loss is 3.853783869743347 and perplexity is 47.17121570199907
At time: 478.7261097431183 and batch: 300, loss is 3.851061658859253 and perplexity is 47.042980326256874
At time: 479.43727469444275 and batch: 350, loss is 3.86800030708313 and perplexity is 47.8466118224236
At time: 480.146963596344 and batch: 400, loss is 3.8075653982162474 and perplexity is 45.040649228571056
At time: 480.8598349094391 and batch: 450, loss is 3.8443531370162964 and perplexity is 46.728447669388245
At time: 481.57055592536926 and batch: 500, loss is 3.8640265560150144 and perplexity is 47.65685856339105
At time: 482.2812283039093 and batch: 550, loss is 3.851745409965515 and perplexity is 47.075157015266576
At time: 482.99031472206116 and batch: 600, loss is 3.820582776069641 and perplexity is 45.63079310786948
At time: 483.6998887062073 and batch: 650, loss is 3.8509994077682497 and perplexity is 47.04005194055607
At time: 484.4113938808441 and batch: 700, loss is 3.883341908454895 and perplexity is 48.5863150759359
At time: 485.11691331863403 and batch: 750, loss is 3.8284818983078 and perplexity is 45.992663668741734
At time: 485.82715225219727 and batch: 800, loss is 3.8194011926651 and perplexity is 45.57690836092777
At time: 486.5457055568695 and batch: 850, loss is 3.837335076332092 and perplexity is 46.40165266286591
At time: 487.25529432296753 and batch: 900, loss is 3.7908139991760255 and perplexity is 44.29243961534819
At time: 487.9679203033447 and batch: 950, loss is 3.8932272386550903 and perplexity is 49.06898860673254
At time: 488.6769058704376 and batch: 1000, loss is 3.855085892677307 and perplexity is 47.2326737078501
At time: 489.43379497528076 and batch: 1050, loss is 3.8283867406845093 and perplexity is 45.98828732440277
At time: 490.1400010585785 and batch: 1100, loss is 3.8379034852981566 and perplexity is 46.42803527562618
At time: 490.84385347366333 and batch: 1150, loss is 3.823366837501526 and perplexity is 45.75800904538915
At time: 491.5465168952942 and batch: 1200, loss is 3.85767053604126 and perplexity is 47.35491122665732
At time: 492.2528281211853 and batch: 1250, loss is 3.8696333980560302 and perplexity is 47.9248135301459
At time: 492.9605007171631 and batch: 1300, loss is 3.850977339744568 and perplexity is 47.039013871029965
At time: 493.6687307357788 and batch: 1350, loss is 3.735805721282959 and perplexity is 41.92178923702881
At time: 494.3771345615387 and batch: 1400, loss is 3.735271635055542 and perplexity is 41.89940536475965
At time: 495.0879888534546 and batch: 1450, loss is 3.6666009759902956 and perplexity is 39.11871417895438
At time: 495.7974693775177 and batch: 1500, loss is 3.663779492378235 and perplexity is 39.008496929173425
At time: 496.50155210494995 and batch: 1550, loss is 3.690804886817932 and perplexity is 40.07709150159229
At time: 497.2063875198364 and batch: 1600, loss is 3.7681145763397215 and perplexity is 43.29835209100312
At time: 497.9098393917084 and batch: 1650, loss is 3.726066327095032 and perplexity is 41.51547822985824
At time: 498.61690735816956 and batch: 1700, loss is 3.715015592575073 and perplexity is 41.05922729848553
At time: 499.32798767089844 and batch: 1750, loss is 3.713641242980957 and perplexity is 41.002836325444704
At time: 500.0362422466278 and batch: 1800, loss is 3.6791834688186644 and perplexity is 39.61403476857308
At time: 500.74303007125854 and batch: 1850, loss is 3.713348536491394 and perplexity is 40.990836285492215
At time: 501.4465913772583 and batch: 1900, loss is 3.8123306941986086 and perplexity is 45.255793459226624
At time: 502.1527726650238 and batch: 1950, loss is 3.7399351596832275 and perplexity is 42.09526060647279
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357390647710756 and perplexity of 78.05320017408833
finished 17 epochs...
Completing Train Step...
At time: 504.8694996833801 and batch: 50, loss is 3.90705988407135 and perplexity is 49.752458728976
At time: 505.5801856517792 and batch: 100, loss is 3.8893936920166015 and perplexity is 48.881240450990916
At time: 506.2849795818329 and batch: 150, loss is 3.85886146068573 and perplexity is 47.411340952579955
At time: 506.9905159473419 and batch: 200, loss is 3.8424456024169924 and perplexity is 46.63939649978314
At time: 507.75882267951965 and batch: 250, loss is 3.8487092876434326 and perplexity is 46.93244783113163
At time: 508.4783537387848 and batch: 300, loss is 3.8456705951690675 and perplexity is 46.79005101474102
At time: 509.1962285041809 and batch: 350, loss is 3.8625616359710695 and perplexity is 47.58709618667785
At time: 509.9018325805664 and batch: 400, loss is 3.801970281600952 and perplexity is 44.78934523687417
At time: 510.610808134079 and batch: 450, loss is 3.838980679512024 and perplexity is 46.478074232585215
At time: 511.3154158592224 and batch: 500, loss is 3.8585463190078735 and perplexity is 47.39640201710696
At time: 512.0215034484863 and batch: 550, loss is 3.8462484788894655 and perplexity is 46.81709803776348
At time: 512.7240862846375 and batch: 600, loss is 3.8156367778778075 and perplexity is 45.40566049935284
At time: 513.4195992946625 and batch: 650, loss is 3.8462644910812376 and perplexity is 46.817847688117226
At time: 514.1310646533966 and batch: 700, loss is 3.879011745452881 and perplexity is 48.37638325950592
At time: 514.8392601013184 and batch: 750, loss is 3.8244327449798585 and perplexity is 45.80680885284373
At time: 515.5491163730621 and batch: 800, loss is 3.8155380153656004 and perplexity is 45.40117634369039
At time: 516.2613084316254 and batch: 850, loss is 3.833452944755554 and perplexity is 46.221864548216345
At time: 516.9787421226501 and batch: 900, loss is 3.7870768117904663 and perplexity is 44.12721939050873
At time: 517.6857857704163 and batch: 950, loss is 3.889382424354553 and perplexity is 48.88068967679599
At time: 518.3942511081696 and batch: 1000, loss is 3.8514353322982786 and perplexity is 47.06056232325546
At time: 519.0984060764313 and batch: 1050, loss is 3.824894733428955 and perplexity is 45.827975958526395
At time: 519.8047688007355 and batch: 1100, loss is 3.8344921970367434 and perplexity is 46.26992569589189
At time: 520.5151844024658 and batch: 1150, loss is 3.82037983417511 and perplexity is 45.62153364786517
At time: 521.2226705551147 and batch: 1200, loss is 3.854759521484375 and perplexity is 47.21726083908168
At time: 521.9263412952423 and batch: 1250, loss is 3.8670357990264894 and perplexity is 47.80048562795685
At time: 522.6380016803741 and batch: 1300, loss is 3.84859130859375 and perplexity is 46.926911112152084
At time: 523.351146697998 and batch: 1350, loss is 3.7333410215377807 and perplexity is 41.81859184131782
At time: 524.072671175003 and batch: 1400, loss is 3.7332226610183716 and perplexity is 41.81364246397774
At time: 524.7980508804321 and batch: 1450, loss is 3.664850378036499 and perplexity is 39.05029294446769
At time: 525.5017621517181 and batch: 1500, loss is 3.662275958061218 and perplexity is 38.94989038490099
At time: 526.2047579288483 and batch: 1550, loss is 3.6895560598373414 and perplexity is 40.02707338690763
At time: 526.9186015129089 and batch: 1600, loss is 3.7671474170684816 and perplexity is 43.2564959323975
At time: 527.6260659694672 and batch: 1650, loss is 3.7252176141738893 and perplexity is 41.48025845491029
At time: 528.3361139297485 and batch: 1700, loss is 3.7143689680099485 and perplexity is 41.03268597554979
At time: 529.0452427864075 and batch: 1750, loss is 3.713222861289978 and perplexity is 40.985685077582154
At time: 529.7503991127014 and batch: 1800, loss is 3.678761057853699 and perplexity is 39.597304899609114
At time: 530.463344335556 and batch: 1850, loss is 3.712971177101135 and perplexity is 40.97537092668803
At time: 531.1662549972534 and batch: 1900, loss is 3.812126889228821 and perplexity is 45.24657104342696
At time: 531.8743422031403 and batch: 1950, loss is 3.7395459032058715 and perplexity is 42.07887794235166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357457644440407 and perplexity of 78.05842965841602
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 534.5158824920654 and batch: 50, loss is 3.909017324447632 and perplexity is 49.84994157781749
At time: 535.2502918243408 and batch: 100, loss is 3.8991408729553223 and perplexity is 49.36002435216626
At time: 535.9530873298645 and batch: 150, loss is 3.872690362930298 and perplexity is 48.07154215958117
At time: 536.6621561050415 and batch: 200, loss is 3.8629362535476686 and perplexity is 47.60492648889247
At time: 537.3748655319214 and batch: 250, loss is 3.8728769969940187 and perplexity is 48.08051478411639
At time: 538.0789902210236 and batch: 300, loss is 3.8696836042404175 and perplexity is 47.92721971257283
At time: 538.7830111980438 and batch: 350, loss is 3.8856012773513795 and perplexity is 48.6962135889039
At time: 539.4854624271393 and batch: 400, loss is 3.828784623146057 and perplexity is 46.00658889806192
At time: 540.198903799057 and batch: 450, loss is 3.868997559547424 and perplexity is 47.894350773908734
At time: 540.9122092723846 and batch: 500, loss is 3.890091576576233 and perplexity is 48.91536582035644
At time: 541.63441157341 and batch: 550, loss is 3.8797805213928225 and perplexity is 48.41358815830035
At time: 542.3622379302979 and batch: 600, loss is 3.844604015350342 and perplexity is 46.74017229515786
At time: 543.0710558891296 and batch: 650, loss is 3.8695687770843508 and perplexity is 47.92171668218976
At time: 543.8321390151978 and batch: 700, loss is 3.9021837949752807 and perplexity is 49.510451810614015
At time: 544.5453352928162 and batch: 750, loss is 3.843206763267517 and perplexity is 46.67491009655602
At time: 545.263133764267 and batch: 800, loss is 3.834843626022339 and perplexity is 46.28618914649938
At time: 545.9764244556427 and batch: 850, loss is 3.8546757316589355 and perplexity is 47.21330467878356
At time: 546.6853346824646 and batch: 900, loss is 3.798945631980896 and perplexity is 44.654077832197494
At time: 547.3886489868164 and batch: 950, loss is 3.897943687438965 and perplexity is 49.300966604518585
At time: 548.0935957431793 and batch: 1000, loss is 3.8578959798812864 and perplexity is 47.36558830318371
At time: 548.7991881370544 and batch: 1050, loss is 3.83238329410553 and perplexity is 46.17244973376272
At time: 549.5050852298737 and batch: 1100, loss is 3.8322329092025758 and perplexity is 46.16550661647345
At time: 550.2070338726044 and batch: 1150, loss is 3.817595372200012 and perplexity is 45.49467891522787
At time: 550.9178700447083 and batch: 1200, loss is 3.8558858489990233 and perplexity is 47.270472900610116
At time: 551.6376626491547 and batch: 1250, loss is 3.8696769142150877 and perplexity is 47.9268990793315
At time: 552.3515167236328 and batch: 1300, loss is 3.8568065977096557 and perplexity is 47.314017171173504
At time: 553.0607702732086 and batch: 1350, loss is 3.7485214185714724 and perplexity is 42.458257574856354
At time: 553.7707521915436 and batch: 1400, loss is 3.752964062690735 and perplexity is 42.647304125523135
At time: 554.4811682701111 and batch: 1450, loss is 3.6790450191497803 and perplexity is 39.60855059822575
At time: 555.1891946792603 and batch: 1500, loss is 3.6747802305221557 and perplexity is 39.43998819906948
At time: 555.8934352397919 and batch: 1550, loss is 3.698451976776123 and perplexity is 40.38473943204966
At time: 556.6024160385132 and batch: 1600, loss is 3.769831213951111 and perplexity is 43.372743503994144
At time: 557.3176212310791 and batch: 1650, loss is 3.7243692827224733 and perplexity is 41.44508436880135
At time: 558.0237650871277 and batch: 1700, loss is 3.710028676986694 and perplexity is 40.85497810785507
At time: 558.7307252883911 and batch: 1750, loss is 3.7086860609054564 and perplexity is 40.80016236373295
At time: 559.4427425861359 and batch: 1800, loss is 3.6713857412338258 and perplexity is 39.306336549476384
At time: 560.1541872024536 and batch: 1850, loss is 3.7047559690475462 and perplexity is 40.64012865739392
At time: 560.8606848716736 and batch: 1900, loss is 3.802962608337402 and perplexity is 44.833812961267725
At time: 561.5656759738922 and batch: 1950, loss is 3.7339952039718627 and perplexity is 41.8459577797006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351027093931686 and perplexity of 77.55808146522808
finished 19 epochs...
Completing Train Step...
At time: 564.218822479248 and batch: 50, loss is 3.909901809692383 and perplexity is 49.894052620502244
At time: 564.9648718833923 and batch: 100, loss is 3.893974094390869 and perplexity is 49.10564975091113
At time: 565.6727209091187 and batch: 150, loss is 3.8647263288497924 and perplexity is 47.69021920948016
At time: 566.3877663612366 and batch: 200, loss is 3.852302508354187 and perplexity is 47.101389815833265
At time: 567.0976903438568 and batch: 250, loss is 3.8612237215042113 and perplexity is 47.52347129407684
At time: 567.8100910186768 and batch: 300, loss is 3.8572949600219726 and perplexity is 47.337129197066076
At time: 568.5219826698303 and batch: 350, loss is 3.872973837852478 and perplexity is 48.08517116790372
At time: 569.2342298030853 and batch: 400, loss is 3.814896197319031 and perplexity is 45.372046398439764
At time: 569.9521481990814 and batch: 450, loss is 3.855218276977539 and perplexity is 47.2389269862158
At time: 570.65962433815 and batch: 500, loss is 3.8773127126693727 and perplexity is 48.29425998322533
At time: 571.3656048774719 and batch: 550, loss is 3.866499242782593 and perplexity is 47.774844858404535
At time: 572.0711205005646 and batch: 600, loss is 3.833689785003662 and perplexity is 46.232813042554845
At time: 572.7823495864868 and batch: 650, loss is 3.8599753952026368 and perplexity is 47.464183507868874
At time: 573.4983174800873 and batch: 700, loss is 3.8933128690719605 and perplexity is 49.073190584588325
At time: 574.2125992774963 and batch: 750, loss is 3.8360480308532714 and perplexity is 46.34197004095932
At time: 574.9269840717316 and batch: 800, loss is 3.828110165596008 and perplexity is 45.975569868512814
At time: 575.6321234703064 and batch: 850, loss is 3.8481527757644653 and perplexity is 46.90633663267455
At time: 576.3363788127899 and batch: 900, loss is 3.7942086267471313 and perplexity is 44.44305144295805
At time: 577.0514969825745 and batch: 950, loss is 3.8943819284439085 and perplexity is 49.12568079146877
At time: 577.7583305835724 and batch: 1000, loss is 3.8539298152923585 and perplexity is 47.17810063337255
At time: 578.4631743431091 and batch: 1050, loss is 3.8284622192382813 and perplexity is 45.991758584821675
At time: 579.1689395904541 and batch: 1100, loss is 3.8290941524505615 and perplexity is 46.02083148966217
At time: 579.9380152225494 and batch: 1150, loss is 3.814854006767273 and perplexity is 45.37013216714934
At time: 580.6488127708435 and batch: 1200, loss is 3.8525669717788698 and perplexity is 47.11384805799336
At time: 581.363972902298 and batch: 1250, loss is 3.8665057945251466 and perplexity is 47.775157867913975
At time: 582.0753040313721 and batch: 1300, loss is 3.854066405296326 and perplexity is 47.18454513044216
At time: 582.7816305160522 and batch: 1350, loss is 3.7458737087249756 and perplexity is 42.34598912094267
At time: 583.48401927948 and batch: 1400, loss is 3.7513809108734133 and perplexity is 42.57984038525521
At time: 584.1893877983093 and batch: 1450, loss is 3.6793926334381104 and perplexity is 39.622321489694386
At time: 584.9010381698608 and batch: 1500, loss is 3.676119842529297 and perplexity is 39.49285788534925
At time: 585.6119902133942 and batch: 1550, loss is 3.7003257274627686 and perplexity is 40.46048130382215
At time: 586.3149616718292 and batch: 1600, loss is 3.771759662628174 and perplexity is 43.45646631545102
At time: 587.0254182815552 and batch: 1650, loss is 3.726579818725586 and perplexity is 41.53680155467361
At time: 587.7414033412933 and batch: 1700, loss is 3.713376774787903 and perplexity is 40.991993813224624
At time: 588.4637763500214 and batch: 1750, loss is 3.712948451042175 and perplexity is 40.974439728573714
At time: 589.1751937866211 and batch: 1800, loss is 3.675898356437683 and perplexity is 39.48411173522062
At time: 589.8801395893097 and batch: 1850, loss is 3.7096324300765993 and perplexity is 40.838792655947266
At time: 590.5855224132538 and batch: 1900, loss is 3.8078898429870605 and perplexity is 45.055264802532356
At time: 591.2895104885101 and batch: 1950, loss is 3.7382698011398316 and perplexity is 42.02521524609376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349560262990552 and perplexity of 77.44440026753202
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f7420a98b38>
ELAPSED
3750.8127961158752


RESULTS SO FAR:
[{'best_accuracy': -76.72922266508544, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.44533850763699, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.7798990364997814, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3775751613796833, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.6311346728391, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.278968697079667, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.1071481079890072, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.33222650478953, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.20408011909539603, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.046635900383796614, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -77.62422830843686, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.13889208123057972, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8005403062602345, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -77.44440026753202, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.07746058627322845, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.0, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -76.72922266508544, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.11249569129953374, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.2438496344567861, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.44533850763699, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.7798990364997814, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.3775751613796833, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.6311346728391, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.278968697079667, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.1071481079890072, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -76.33222650478953, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.20408011909539603, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.046635900383796614, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -77.62422830843686, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.13889208123057972, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.8005403062602345, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}, {'best_accuracy': -77.44440026753202, 'params': {'tie_weights': 'TRUE', 'wordvec_dim': 300, 'dropout': 0.07746058627322845, 'seq_len': 35, 'batch_size': 32, 'tune_wordvecs': 'FALSE', 'rnn_dropout': 0.0, 'num_layers': 1, 'wordvec_source': 'gigavec', 'data': 'wikitext'}}]
Exception ignored in: <bound method DropoutDescriptor.__del__ of <torch.backends.cudnn.DropoutDescriptor object at 0x7f7412ef64e0>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 215, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroyDropoutDescriptor'
Exception ignored in: <bound method CuDNNHandle.__del__ of <torch.backends.cudnn.CuDNNHandle object at 0x7f7415c6f748>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 91, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroy'
