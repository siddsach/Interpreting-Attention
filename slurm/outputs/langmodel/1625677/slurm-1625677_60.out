FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'type': 'continuous', 'name': 'dropout'}, {'domain': [0, 1], 'type': 'continuous', 'name': 'rnn_dropout'}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.1462619304656982 and batch: 50, loss is 7.69024845123291 and perplexity is 2186.917837169699
At time: 3.624692678451538 and batch: 100, loss is 7.003143711090088 and perplexity is 1100.0860809019591
At time: 5.105934143066406 and batch: 150, loss is 6.67693021774292 and perplexity is 793.8783339801546
At time: 6.588536739349365 and batch: 200, loss is 6.485122032165528 and perplexity is 655.3189293478824
At time: 8.068288087844849 and batch: 250, loss is 6.367519826889038 and perplexity is 582.6110592300586
At time: 9.54907751083374 and batch: 300, loss is 6.280476112365722 and perplexity is 534.0428677190976
At time: 11.030879735946655 and batch: 350, loss is 6.2248029708862305 and perplexity is 505.12350861437193
At time: 12.510118961334229 and batch: 400, loss is 6.169865379333496 and perplexity is 478.121736689769
At time: 13.99250054359436 and batch: 450, loss is 6.076566104888916 and perplexity is 435.53105600098087
At time: 15.4722900390625 and batch: 500, loss is 6.056159257888794 and perplexity is 426.73331278569736
At time: 16.953162670135498 and batch: 550, loss is 5.999128189086914 and perplexity is 403.0772331372593
At time: 18.435906171798706 and batch: 600, loss is 6.031147680282593 and perplexity is 416.19241121284296
At time: 19.918396472930908 and batch: 650, loss is 6.094647207260132 and perplexity is 443.47756191153235
At time: 21.402360439300537 and batch: 700, loss is 5.9993259048461915 and perplexity is 403.15693573742703
At time: 22.885462999343872 and batch: 750, loss is 5.919229097366333 and perplexity is 372.1247313371569
At time: 24.36811065673828 and batch: 800, loss is 5.924643182754517 and perplexity is 374.14491018338254
At time: 25.855379581451416 and batch: 850, loss is 5.955378408432007 and perplexity is 385.8228816896404
At time: 27.338027477264404 and batch: 900, loss is 5.933158626556397 and perplexity is 377.34452387069507
At time: 28.821173906326294 and batch: 950, loss is 5.940712242126465 and perplexity is 380.2056315915339
At time: 30.304224967956543 and batch: 1000, loss is 5.923398246765137 and perplexity is 373.67941353633773
At time: 31.787419080734253 and batch: 1050, loss is 5.822410593032837 and perplexity is 337.78533596735144
At time: 33.27078294754028 and batch: 1100, loss is 5.89747836112976 and perplexity is 364.1181347974091
At time: 34.75382614135742 and batch: 1150, loss is 5.799084358215332 and perplexity is 329.9972622504425
At time: 36.23814129829407 and batch: 1200, loss is 5.872282705307007 and perplexity is 355.0585499479888
At time: 37.720749855041504 and batch: 1250, loss is 5.815111713409424 and perplexity is 335.3288571386609
At time: 39.20492172241211 and batch: 1300, loss is 5.832130794525146 and perplexity is 341.0846866935436
At time: 40.689979791641235 and batch: 1350, loss is 5.798327550888062 and perplexity is 329.74761238473184
At time: 42.17702078819275 and batch: 1400, loss is 5.8076902198791505 and perplexity is 332.84942810841824
At time: 43.65848135948181 and batch: 1450, loss is 5.784670763015747 and perplexity is 325.27492994429707
At time: 45.142595052719116 and batch: 1500, loss is 5.751758689880371 and perplexity is 314.74371039971703
At time: 46.62605667114258 and batch: 1550, loss is 5.732436943054199 and perplexity is 308.720687157408
At time: 48.10984754562378 and batch: 1600, loss is 5.739491605758667 and perplexity is 310.90630781894043
At time: 49.60115385055542 and batch: 1650, loss is 5.73820930480957 and perplexity is 310.50788786707835
At time: 51.096216678619385 and batch: 1700, loss is 5.745762538909912 and perplexity is 312.8621064234805
At time: 52.583794832229614 and batch: 1750, loss is 5.7548674297332765 and perplexity is 315.72368917599533
At time: 54.0684232711792 and batch: 1800, loss is 5.7580628490448 and perplexity is 316.73417234840326
At time: 55.551265716552734 and batch: 1850, loss is 5.723387269973755 and perplexity is 305.93946940218194
At time: 57.03560543060303 and batch: 1900, loss is 5.717935333251953 and perplexity is 304.27604533592074
At time: 58.521060943603516 and batch: 1950, loss is 5.655694618225097 and perplexity is 285.9150155469006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.1787546557049415 and perplexity of 177.46167244375948
finished 1 epochs...
Completing Train Step...
At time: 62.49928092956543 and batch: 50, loss is 5.4680298233032225 and perplexity is 236.9928147827583
At time: 63.758009910583496 and batch: 100, loss is 5.4095198345184325 and perplexity is 223.52423328755322
At time: 65.01675772666931 and batch: 150, loss is 5.324055204391479 and perplexity is 205.21438319672737
At time: 66.27285408973694 and batch: 200, loss is 5.27901535987854 and perplexity is 196.17661685452984
At time: 67.53773832321167 and batch: 250, loss is 5.273687505722046 and perplexity is 195.1341958504028
At time: 68.80548596382141 and batch: 300, loss is 5.273674573898315 and perplexity is 195.13167242569443
At time: 70.07456064224243 and batch: 350, loss is 5.2284896945953365 and perplexity is 186.5109022715343
At time: 71.33455729484558 and batch: 400, loss is 5.189962110519409 and perplexity is 179.46175309040146
At time: 72.59690427780151 and batch: 450, loss is 5.127342185974121 and perplexity is 168.56849841579157
At time: 73.86210227012634 and batch: 500, loss is 5.119148044586182 and perplexity is 167.19286805814045
At time: 75.1310362815857 and batch: 550, loss is 5.074135313034057 and perplexity is 159.83392589712318
At time: 76.40445852279663 and batch: 600, loss is 5.059568204879761 and perplexity is 157.52248419644977
At time: 77.67114067077637 and batch: 650, loss is 5.122659950256348 and perplexity is 167.7810658825788
At time: 78.93845915794373 and batch: 700, loss is 5.1074814605712895 and perplexity is 165.25363253890114
At time: 80.20650720596313 and batch: 750, loss is 5.036942462921143 and perplexity is 153.99843852607341
At time: 81.47385239601135 and batch: 800, loss is 5.038911390304565 and perplexity is 154.30194896564856
At time: 82.74031448364258 and batch: 850, loss is 5.02962965965271 and perplexity is 152.8763859168186
At time: 84.01130771636963 and batch: 900, loss is 5.034018306732178 and perplexity is 153.54878079409332
At time: 85.29295825958252 and batch: 950, loss is 5.075710735321045 and perplexity is 160.08593028073744
At time: 86.56545972824097 and batch: 1000, loss is 5.024280109405518 and perplexity is 152.06074959761844
At time: 87.83772206306458 and batch: 1050, loss is 4.945382833480835 and perplexity is 140.5246380913547
At time: 89.10895085334778 and batch: 1100, loss is 5.013597593307495 and perplexity is 150.44500367328422
At time: 90.37637662887573 and batch: 1150, loss is 4.920420808792114 and perplexity is 137.06027722255624
At time: 91.64307308197021 and batch: 1200, loss is 5.005266599655151 and perplexity is 149.19685368649021
At time: 92.9192841053009 and batch: 1250, loss is 4.961035470962525 and perplexity is 142.74152410301093
At time: 94.1876130104065 and batch: 1300, loss is 4.978215751647949 and perplexity is 145.21505065213412
At time: 95.4537444114685 and batch: 1350, loss is 4.881110429763794 and perplexity is 131.77691167675934
At time: 96.72452187538147 and batch: 1400, loss is 4.885221796035767 and perplexity is 132.3198100892305
At time: 97.9922456741333 and batch: 1450, loss is 4.84086051940918 and perplexity is 126.57822790025523
At time: 99.26010727882385 and batch: 1500, loss is 4.799559707641602 and perplexity is 121.45692918655165
At time: 100.52695035934448 and batch: 1550, loss is 4.806921215057373 and perplexity is 122.3543343461615
At time: 101.79445290565491 and batch: 1600, loss is 4.854852867126465 and perplexity is 128.36180358424502
At time: 103.06147599220276 and batch: 1650, loss is 4.832230777740478 and perplexity is 125.49059025844382
At time: 104.32921957969666 and batch: 1700, loss is 4.843150787353515 and perplexity is 126.86845818376065
At time: 105.60513734817505 and batch: 1750, loss is 4.843388395309448 and perplexity is 126.8986067204063
At time: 106.8736481666565 and batch: 1800, loss is 4.809290409088135 and perplexity is 122.64455916843595
At time: 108.14026260375977 and batch: 1850, loss is 4.813676042556763 and perplexity is 123.18361443727875
At time: 109.40807461738586 and batch: 1900, loss is 4.903024835586548 and perplexity is 134.696599160262
At time: 110.67705178260803 and batch: 1950, loss is 4.816540145874024 and perplexity is 123.53693076172553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.652384629360465 and perplexity of 104.83467959991125
finished 2 epochs...
Completing Train Step...
At time: 114.59797191619873 and batch: 50, loss is 4.79155818939209 and perplexity is 120.48896709870975
At time: 115.86404991149902 and batch: 100, loss is 4.735775136947632 and perplexity is 113.95175270759363
At time: 117.12720155715942 and batch: 150, loss is 4.679502983093261 and perplexity is 107.71652233208155
At time: 118.39323163032532 and batch: 200, loss is 4.659793529510498 and perplexity is 105.61427367454903
At time: 119.6618402004242 and batch: 250, loss is 4.673054065704346 and perplexity is 107.02410245715231
At time: 120.92988848686218 and batch: 300, loss is 4.694697494506836 and perplexity is 109.3657199062675
At time: 122.19774293899536 and batch: 350, loss is 4.693740329742432 and perplexity is 109.26108897524799
At time: 123.46582412719727 and batch: 400, loss is 4.641657247543335 and perplexity is 103.71608846821269
At time: 124.73386788368225 and batch: 450, loss is 4.632052783966064 and perplexity is 102.72471947860282
At time: 126.00181126594543 and batch: 500, loss is 4.633532371520996 and perplexity is 102.87682219201979
At time: 127.26949524879456 and batch: 550, loss is 4.6016862678527835 and perplexity is 99.65221436658292
At time: 128.53819370269775 and batch: 600, loss is 4.579017696380615 and perplexity is 97.41865249609546
At time: 129.8052794933319 and batch: 650, loss is 4.640276374816895 and perplexity is 103.5729685882652
At time: 131.07525420188904 and batch: 700, loss is 4.670928983688355 and perplexity is 106.7969089496615
At time: 132.34643816947937 and batch: 750, loss is 4.607776288986206 and perplexity is 100.26095018364659
At time: 133.65887570381165 and batch: 800, loss is 4.614122772216797 and perplexity is 100.89927804867774
At time: 134.92630696296692 and batch: 850, loss is 4.607403774261474 and perplexity is 100.22360845899054
At time: 136.19282507896423 and batch: 900, loss is 4.589695348739624 and perplexity is 98.46442827994507
At time: 137.45921325683594 and batch: 950, loss is 4.650351409912109 and perplexity is 104.62174423600406
At time: 138.72698187828064 and batch: 1000, loss is 4.621005735397339 and perplexity is 101.59615961828365
At time: 139.99461030960083 and batch: 1050, loss is 4.552082042694092 and perplexity is 94.8296422828023
At time: 141.26223802566528 and batch: 1100, loss is 4.606942167282105 and perplexity is 100.177355218059
At time: 142.5297839641571 and batch: 1150, loss is 4.5410277366638185 and perplexity is 93.78713908688395
At time: 143.79734754562378 and batch: 1200, loss is 4.618220176696777 and perplexity is 101.31355134561939
At time: 145.06761765480042 and batch: 1250, loss is 4.598072052001953 and perplexity is 99.29269982677123
At time: 146.3416314125061 and batch: 1300, loss is 4.605862493515015 and perplexity is 100.06925472270915
At time: 147.60901737213135 and batch: 1350, loss is 4.488188991546631 and perplexity is 88.96019224671385
At time: 148.87557578086853 and batch: 1400, loss is 4.4996559619903564 and perplexity is 89.98616731253517
At time: 150.1431713104248 and batch: 1450, loss is 4.455732316970825 and perplexity is 86.1191943059268
At time: 151.41028308868408 and batch: 1500, loss is 4.437368383407593 and perplexity is 84.55213982380424
At time: 152.67779088020325 and batch: 1550, loss is 4.446108808517456 and perplexity is 85.29440058168255
At time: 153.94568061828613 and batch: 1600, loss is 4.51371000289917 and perplexity is 91.25976522481812
At time: 155.21328711509705 and batch: 1650, loss is 4.487267112731933 and perplexity is 88.87821952039553
At time: 156.48127102851868 and batch: 1700, loss is 4.4988759422302245 and perplexity is 89.91600369195558
At time: 157.749125957489 and batch: 1750, loss is 4.491517848968506 and perplexity is 89.25682148723067
At time: 159.0182957649231 and batch: 1800, loss is 4.459087533950806 and perplexity is 86.40862817415429
At time: 160.286705493927 and batch: 1850, loss is 4.483774852752686 and perplexity is 88.56837501502277
At time: 161.5544788837433 and batch: 1900, loss is 4.588965673446655 and perplexity is 98.392607425531
At time: 162.823814868927 and batch: 1950, loss is 4.505659914016723 and perplexity is 90.5280650803823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.503639682503634 and perplexity of 90.34536204384324
finished 3 epochs...
Completing Train Step...
At time: 166.72842359542847 and batch: 50, loss is 4.496585712432862 and perplexity is 89.71031101269949
At time: 168.0050573348999 and batch: 100, loss is 4.43524941444397 and perplexity is 84.37316615050558
At time: 169.27089190483093 and batch: 150, loss is 4.388543529510498 and perplexity is 80.52305407997514
At time: 170.5345859527588 and batch: 200, loss is 4.384912586212158 and perplexity is 80.23120959242833
At time: 171.80196714401245 and batch: 250, loss is 4.390760040283203 and perplexity is 80.70173224468034
At time: 173.07016563415527 and batch: 300, loss is 4.419016304016114 and perplexity is 83.01458406736504
At time: 174.3372950553894 and batch: 350, loss is 4.4203015804290775 and perplexity is 83.12134935095175
At time: 175.6042516231537 and batch: 400, loss is 4.366916980743408 and perplexity is 78.8003139303358
At time: 176.87079119682312 and batch: 450, loss is 4.37663516998291 and perplexity is 79.56984345361612
At time: 178.1380636692047 and batch: 500, loss is 4.384353399276733 and perplexity is 80.18635788962278
At time: 179.42370676994324 and batch: 550, loss is 4.351270971298217 and perplexity is 77.57699843250539
At time: 180.7009665966034 and batch: 600, loss is 4.331704769134522 and perplexity is 76.07386446368926
At time: 181.97827672958374 and batch: 650, loss is 4.388381986618042 and perplexity is 80.5100472035222
At time: 183.24578428268433 and batch: 700, loss is 4.429804763793945 and perplexity is 83.91503205837267
At time: 184.51451134681702 and batch: 750, loss is 4.365470724105835 and perplexity is 78.68643082521994
At time: 185.78286910057068 and batch: 800, loss is 4.375838823318482 and perplexity is 79.50650349782137
At time: 187.05129551887512 and batch: 850, loss is 4.371877489089965 and perplexity is 79.19217465596759
At time: 188.31996083259583 and batch: 900, loss is 4.341420850753784 and perplexity is 76.8166067693072
At time: 189.58736634254456 and batch: 950, loss is 4.41614068031311 and perplexity is 82.7762082655439
At time: 190.85568118095398 and batch: 1000, loss is 4.385673856735229 and perplexity is 80.29231050153109
At time: 192.12368321418762 and batch: 1050, loss is 4.3289430046081545 and perplexity is 75.86405621727253
At time: 193.39161729812622 and batch: 1100, loss is 4.374527797698975 and perplexity is 79.40233673238747
At time: 194.65889596939087 and batch: 1150, loss is 4.316767978668213 and perplexity is 74.94600932750885
At time: 195.94495964050293 and batch: 1200, loss is 4.3910447692871095 and perplexity is 80.72471364009557
At time: 197.2116973400116 and batch: 1250, loss is 4.3811672592163085 and perplexity is 79.93127949598076
At time: 198.480322599411 and batch: 1300, loss is 4.379759578704834 and perplexity is 79.81884094891981
At time: 199.74750781059265 and batch: 1350, loss is 4.262043714523315 and perplexity is 70.95484682512351
At time: 201.015145778656 and batch: 1400, loss is 4.280031909942627 and perplexity is 72.24274523240096
At time: 202.28259229660034 and batch: 1450, loss is 4.231785688400269 and perplexity is 68.84004936221676
At time: 203.5509331226349 and batch: 1500, loss is 4.2215823602676394 and perplexity is 68.14122299006766
At time: 204.81841254234314 and batch: 1550, loss is 4.238265476226807 and perplexity is 69.28756661863875
At time: 206.08717966079712 and batch: 1600, loss is 4.316280813217163 and perplexity is 74.90950711310121
At time: 207.3548846244812 and batch: 1650, loss is 4.278932023048401 and perplexity is 72.16333006557355
At time: 208.62319827079773 and batch: 1700, loss is 4.287883200645447 and perplexity is 72.81217648643887
At time: 209.8915355205536 and batch: 1750, loss is 4.280202083587646 and perplexity is 72.25504008978402
At time: 211.1602566242218 and batch: 1800, loss is 4.246328859329224 and perplexity is 69.84851735352943
At time: 212.4292070865631 and batch: 1850, loss is 4.279874496459961 and perplexity is 72.23137414528124
At time: 213.6976261138916 and batch: 1900, loss is 4.387502489089965 and perplexity is 80.43926994479568
At time: 214.96622228622437 and batch: 1950, loss is 4.305041818618775 and perplexity is 74.07231298989944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4478663244912795 and perplexity of 85.44443866172313
finished 4 epochs...
Completing Train Step...
At time: 218.86782479286194 and batch: 50, loss is 4.297603855133056 and perplexity is 73.52340972240101
At time: 220.16975569725037 and batch: 100, loss is 4.244289727210998 and perplexity is 69.70623211688395
At time: 221.4385724067688 and batch: 150, loss is 4.195831618309021 and perplexity is 66.40893550646398
At time: 222.70643043518066 and batch: 200, loss is 4.197760457992554 and perplexity is 66.53715131072425
At time: 223.97327303886414 and batch: 250, loss is 4.200547518730164 and perplexity is 66.72285305354657
At time: 225.23996829986572 and batch: 300, loss is 4.228277807235718 and perplexity is 68.59898970120564
At time: 226.50895237922668 and batch: 350, loss is 4.231248998641968 and perplexity is 68.80311352519244
At time: 227.79273056983948 and batch: 400, loss is 4.1795585203170775 and perplexity is 65.337001886965
At time: 229.06153178215027 and batch: 450, loss is 4.1989011335372926 and perplexity is 66.61309191560228
At time: 230.32910227775574 and batch: 500, loss is 4.212657866477966 and perplexity is 67.53580262212924
At time: 231.59747123718262 and batch: 550, loss is 4.178852400779724 and perplexity is 65.29088243825869
At time: 232.86520528793335 and batch: 600, loss is 4.156525831222535 and perplexity is 63.84931353599371
At time: 234.13258934020996 and batch: 650, loss is 4.21151376247406 and perplexity is 67.45857882439401
At time: 235.40082621574402 and batch: 700, loss is 4.263534159660339 and perplexity is 71.06067998118696
At time: 236.6699697971344 and batch: 750, loss is 4.202754330635071 and perplexity is 66.87026043034845
At time: 237.93760991096497 and batch: 800, loss is 4.209970002174377 and perplexity is 67.35451929068655
At time: 239.20720887184143 and batch: 850, loss is 4.204635562896729 and perplexity is 66.9961773239414
At time: 240.4768934249878 and batch: 900, loss is 4.164985203742981 and perplexity is 64.39172967983153
At time: 241.74556064605713 and batch: 950, loss is 4.24940140247345 and perplexity is 70.06345997780417
At time: 243.01662015914917 and batch: 1000, loss is 4.2219605016708375 and perplexity is 68.166994880147
At time: 244.28825902938843 and batch: 1050, loss is 4.170906338691712 and perplexity is 64.77413281388002
At time: 245.55956387519836 and batch: 1100, loss is 4.212758402824402 and perplexity is 67.54259276630094
At time: 246.82914566993713 and batch: 1150, loss is 4.1600768184661865 and perplexity is 64.07644466507932
At time: 248.1003053188324 and batch: 1200, loss is 4.229956073760986 and perplexity is 68.7142137505761
At time: 249.3717668056488 and batch: 1250, loss is 4.227188386917114 and perplexity is 68.52429726110775
At time: 250.6418755054474 and batch: 1300, loss is 4.217817602157592 and perplexity is 67.88517005928955
At time: 251.9127972126007 and batch: 1350, loss is 4.102902359962464 and perplexity is 60.515671222298835
At time: 253.18268537521362 and batch: 1400, loss is 4.12717556476593 and perplexity is 62.00255319526158
At time: 254.45352411270142 and batch: 1450, loss is 4.079324173927307 and perplexity is 59.10551130331073
At time: 255.7247190475464 and batch: 1500, loss is 4.0712412118911745 and perplexity is 58.629689315472596
At time: 256.9949026107788 and batch: 1550, loss is 4.090721898078918 and perplexity is 59.78303338727673
At time: 258.2658312320709 and batch: 1600, loss is 4.170445036888123 and perplexity is 64.74425928047425
At time: 259.53724122047424 and batch: 1650, loss is 4.130354542732238 and perplexity is 62.1999715738044
At time: 260.806405544281 and batch: 1700, loss is 4.134523186683655 and perplexity is 62.45980230371487
At time: 262.07552218437195 and batch: 1750, loss is 4.127722115516662 and perplexity is 62.03644999957587
At time: 263.3458514213562 and batch: 1800, loss is 4.091533370018006 and perplexity is 59.83156532979565
At time: 264.6161971092224 and batch: 1850, loss is 4.128415975570679 and perplexity is 62.07950955104737
At time: 265.8870334625244 and batch: 1900, loss is 4.23917356967926 and perplexity is 69.35051478130299
At time: 267.1612756252289 and batch: 1950, loss is 4.1563336324691775 and perplexity is 63.837042956762176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4351375136264535 and perplexity of 84.36372525246888
finished 5 epochs...
Completing Train Step...
At time: 271.08133697509766 and batch: 50, loss is 4.150462832450867 and perplexity is 63.463366407219475
At time: 272.37947607040405 and batch: 100, loss is 4.098932847976685 and perplexity is 60.275929683311766
At time: 273.6507170200348 and batch: 150, loss is 4.054782485961914 and perplexity is 57.67261702793368
At time: 274.92300367355347 and batch: 200, loss is 4.0590720462799075 and perplexity is 57.920538554389495
At time: 276.19421792030334 and batch: 250, loss is 4.060325546264648 and perplexity is 57.993187471779486
At time: 277.46466732025146 and batch: 300, loss is 4.085448064804077 and perplexity is 59.468577559170825
At time: 278.73152923583984 and batch: 350, loss is 4.088882193565369 and perplexity is 59.673151377126935
At time: 280.00220346450806 and batch: 400, loss is 4.03652702331543 and perplexity is 56.62932855281426
At time: 281.27174615859985 and batch: 450, loss is 4.06958607673645 and perplexity is 58.532729518495174
At time: 282.5413010120392 and batch: 500, loss is 4.08282699584961 and perplexity is 59.31291041304558
At time: 283.8128023147583 and batch: 550, loss is 4.0466323089599605 and perplexity is 57.20448526068835
At time: 285.082772731781 and batch: 600, loss is 4.025337033271789 and perplexity is 55.999179188067366
At time: 286.3537087440491 and batch: 650, loss is 4.077404861450195 and perplexity is 58.992178153655324
At time: 287.6302354335785 and batch: 700, loss is 4.135058517456055 and perplexity is 62.49324790935828
At time: 288.9014186859131 and batch: 750, loss is 4.075326747894287 and perplexity is 58.86971300086147
At time: 290.1698613166809 and batch: 800, loss is 4.082085752487183 and perplexity is 59.268961402364205
At time: 291.462660074234 and batch: 850, loss is 4.074509301185608 and perplexity is 58.82160981130363
At time: 292.7343876361847 and batch: 900, loss is 4.03582332611084 and perplexity is 56.58949267045724
At time: 294.0008978843689 and batch: 950, loss is 4.121258754730224 and perplexity is 61.636779041472465
At time: 295.2687556743622 and batch: 1000, loss is 4.094691114425659 and perplexity is 60.02079673558265
At time: 296.5376253128052 and batch: 1050, loss is 4.048393793106079 and perplexity is 57.30533885448762
At time: 297.807498216629 and batch: 1100, loss is 4.0880982875823975 and perplexity is 59.62639156678171
At time: 299.074848651886 and batch: 1150, loss is 4.037807564735413 and perplexity is 56.70189120343619
At time: 300.34172558784485 and batch: 1200, loss is 4.106597414016724 and perplexity is 60.73969353097578
At time: 301.6086084842682 and batch: 1250, loss is 4.109149112701416 and perplexity is 60.894880838487396
At time: 302.875333070755 and batch: 1300, loss is 4.0936783504486085 and perplexity is 59.96004060577788
At time: 304.1430916786194 and batch: 1350, loss is 3.9835939264297484 and perplexity is 53.70971654688791
At time: 305.40688967704773 and batch: 1400, loss is 4.011699299812317 and perplexity is 55.2406612969808
At time: 306.67194080352783 and batch: 1450, loss is 3.9572163009643555 and perplexity is 52.311503598375126
At time: 307.93558859825134 and batch: 1500, loss is 3.9507475233078004 and perplexity is 51.97420424616623
At time: 309.2022840976715 and batch: 1550, loss is 3.973887152671814 and perplexity is 53.19089061643267
At time: 310.46766114234924 and batch: 1600, loss is 4.055076837539673 and perplexity is 57.689595552454506
At time: 311.7336263656616 and batch: 1650, loss is 4.011865658760071 and perplexity is 55.24985183971068
At time: 312.99651193618774 and batch: 1700, loss is 4.01765745639801 and perplexity is 55.570776268652295
At time: 314.2637619972229 and batch: 1750, loss is 4.013175950050354 and perplexity is 55.32229268830795
At time: 315.5303671360016 and batch: 1800, loss is 3.9713958358764647 and perplexity is 53.05854018915604
At time: 316.79583978652954 and batch: 1850, loss is 4.013577451705933 and perplexity is 55.344509140085336
At time: 318.06202840805054 and batch: 1900, loss is 4.123093557357788 and perplexity is 61.74997417922448
At time: 319.328556060791 and batch: 1950, loss is 4.039847750663757 and perplexity is 56.81769169107569
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.431775470112646 and perplexity of 84.08056699908711
finished 6 epochs...
Completing Train Step...
At time: 323.2304000854492 and batch: 50, loss is 4.034478597640991 and perplexity is 56.51344631088084
At time: 324.5039095878601 and batch: 100, loss is 3.9849043226242067 and perplexity is 53.78014368870794
At time: 325.77121472358704 and batch: 150, loss is 3.9464878177642824 and perplexity is 51.75328030973424
At time: 327.03980350494385 and batch: 200, loss is 3.9482615041732787 and perplexity is 51.845155854756925
At time: 328.30568385124207 and batch: 250, loss is 3.9472186374664306 and perplexity is 51.791116450649994
At time: 329.5720603466034 and batch: 300, loss is 3.9705749940872193 and perplexity is 53.01500539212717
At time: 330.8378975391388 and batch: 350, loss is 3.976321382522583 and perplexity is 53.32052718875405
At time: 332.102091550827 and batch: 400, loss is 3.924497351646423 and perplexity is 50.62762377036279
At time: 333.3664138317108 and batch: 450, loss is 3.9631034183502196 and perplexity is 52.6203758522197
At time: 334.631311416626 and batch: 500, loss is 3.9831528854370117 and perplexity is 53.68603358314528
At time: 335.8977119922638 and batch: 550, loss is 3.940084538459778 and perplexity is 51.42294833362794
At time: 337.1646800041199 and batch: 600, loss is 3.922466530799866 and perplexity is 50.52491246602773
At time: 338.43124413490295 and batch: 650, loss is 3.9737550401687622 and perplexity is 53.18386389890263
At time: 339.69837975502014 and batch: 700, loss is 4.028360137939453 and perplexity is 56.16872671889522
At time: 340.9638395309448 and batch: 750, loss is 3.9744537830352784 and perplexity is 53.22103873072751
At time: 342.22941994667053 and batch: 800, loss is 3.9781853342056275 and perplexity is 53.4200067589025
At time: 343.49598383903503 and batch: 850, loss is 3.971719169616699 and perplexity is 53.075698579200505
At time: 344.76125264167786 and batch: 900, loss is 3.931305136680603 and perplexity is 50.97346160893305
At time: 346.0282447338104 and batch: 950, loss is 4.0225264263153075 and perplexity is 55.84200848148905
At time: 347.2955882549286 and batch: 1000, loss is 3.9956572914123534 and perplexity is 54.36156027014618
At time: 348.5617115497589 and batch: 1050, loss is 3.951930212974548 and perplexity is 52.03570996438501
At time: 349.82614159584045 and batch: 1100, loss is 3.984743051528931 and perplexity is 53.77147120536041
At time: 351.09321808815 and batch: 1150, loss is 3.9373794317245485 and perplexity is 51.28403174655432
At time: 352.3592839241028 and batch: 1200, loss is 4.004533352851868 and perplexity is 54.84622459220444
At time: 353.62629771232605 and batch: 1250, loss is 4.010245184898377 and perplexity is 55.16039340104876
At time: 354.89080905914307 and batch: 1300, loss is 3.990608639717102 and perplexity is 54.087799330037136
At time: 356.15697169303894 and batch: 1350, loss is 3.882042875289917 and perplexity is 48.52324081793445
At time: 357.4230909347534 and batch: 1400, loss is 3.9147911262512207 and perplexity is 50.13859778035428
At time: 358.69018816947937 and batch: 1450, loss is 3.8561654090881348 and perplexity is 47.28368968558327
At time: 359.9562289714813 and batch: 1500, loss is 3.8524351501464844 and perplexity is 47.10763784296373
At time: 361.22101521492004 and batch: 1550, loss is 3.877468328475952 and perplexity is 48.30177591822975
At time: 362.4866406917572 and batch: 1600, loss is 3.959656834602356 and perplexity is 52.43932749837976
At time: 363.7514967918396 and batch: 1650, loss is 3.91676242351532 and perplexity is 50.23753334464934
At time: 365.01781582832336 and batch: 1700, loss is 3.9202099227905274 and perplexity is 50.4110260906676
At time: 366.28469800949097 and batch: 1750, loss is 3.917817916870117 and perplexity is 50.29058672107373
At time: 367.5496075153351 and batch: 1800, loss is 3.8700296306610107 and perplexity is 47.94380666645559
At time: 368.8155391216278 and batch: 1850, loss is 3.91943678855896 and perplexity is 50.37206666312263
At time: 370.0808184146881 and batch: 1900, loss is 4.026288714408874 and perplexity is 56.05249791778334
At time: 371.3514759540558 and batch: 1950, loss is 3.942519497871399 and perplexity is 51.548313693486456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.439630268895349 and perplexity of 84.7436035346956
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 375.2660150527954 and batch: 50, loss is 3.9834689617156984 and perplexity is 53.70300514687075
At time: 376.5318522453308 and batch: 100, loss is 3.9635172748565672 and perplexity is 52.64215764408985
At time: 377.79713320732117 and batch: 150, loss is 3.9374344110488892 and perplexity is 51.28685138547942
At time: 379.06340622901917 and batch: 200, loss is 3.939226498603821 and perplexity is 51.37884431865412
At time: 380.3288645744324 and batch: 250, loss is 3.934303846359253 and perplexity is 51.12654563417386
At time: 381.59576201438904 and batch: 300, loss is 3.9521684074401855 and perplexity is 52.04810605879597
At time: 382.8623251914978 and batch: 350, loss is 3.965176658630371 and perplexity is 52.729583702933176
At time: 384.1287078857422 and batch: 400, loss is 3.9043260383605958 and perplexity is 49.61662893652636
At time: 385.4194359779358 and batch: 450, loss is 3.939210658073425 and perplexity is 51.378030456955
At time: 386.6931884288788 and batch: 500, loss is 3.9501103591918945 and perplexity is 51.94109869622205
At time: 387.96749448776245 and batch: 550, loss is 3.908440446853638 and perplexity is 49.82119255658971
At time: 389.23321318626404 and batch: 600, loss is 3.871274304389954 and perplexity is 48.00351821606859
At time: 390.50030636787415 and batch: 650, loss is 3.9150337314605714 and perplexity is 50.1507631409956
At time: 391.7646245956421 and batch: 700, loss is 3.9693988752365112 and perplexity is 52.952690097194804
At time: 393.02903389930725 and batch: 750, loss is 3.9046913766860962 and perplexity is 49.63475910427992
At time: 394.2959408760071 and batch: 800, loss is 3.9035211277008055 and perplexity is 49.576708051520775
At time: 395.56272172927856 and batch: 850, loss is 3.891925129890442 and perplexity is 49.00513702646806
At time: 396.8285810947418 and batch: 900, loss is 3.846368947029114 and perplexity is 46.82273834619973
At time: 398.0942053794861 and batch: 950, loss is 3.9399595499038695 and perplexity is 51.41652145522667
At time: 399.361056804657 and batch: 1000, loss is 3.902656307220459 and perplexity is 49.53385163327485
At time: 400.62548661231995 and batch: 1050, loss is 3.8585768795013426 and perplexity is 47.39785049667428
At time: 401.89168310165405 and batch: 1100, loss is 3.8802217864990234 and perplexity is 48.434956099537295
At time: 403.1595034599304 and batch: 1150, loss is 3.8338987112045286 and perplexity is 46.24247329764425
At time: 404.4247999191284 and batch: 1200, loss is 3.876120300292969 and perplexity is 48.23670762980055
At time: 405.6911585330963 and batch: 1250, loss is 3.870047564506531 and perplexity is 47.944666490987956
At time: 406.95756435394287 and batch: 1300, loss is 3.8561743831634523 and perplexity is 47.284114014879776
At time: 408.2252790927887 and batch: 1350, loss is 3.739420280456543 and perplexity is 42.07359221002694
At time: 409.490763425827 and batch: 1400, loss is 3.757340817451477 and perplexity is 42.83436998897244
At time: 410.7563693523407 and batch: 1450, loss is 3.695068416595459 and perplexity is 40.24832614722391
At time: 412.02217531204224 and batch: 1500, loss is 3.6806498336791993 and perplexity is 39.672166007528496
At time: 413.28763341903687 and batch: 1550, loss is 3.709947257041931 and perplexity is 40.851651833208614
At time: 414.5527672767639 and batch: 1600, loss is 3.78278368473053 and perplexity is 43.9381817026153
At time: 415.81820940971375 and batch: 1650, loss is 3.7286376905441285 and perplexity is 41.62236697916692
At time: 417.08336663246155 and batch: 1700, loss is 3.717243986129761 and perplexity is 41.15082543640365
At time: 418.3493640422821 and batch: 1750, loss is 3.7030850791931154 and perplexity is 40.57228017819065
At time: 419.6146683692932 and batch: 1800, loss is 3.6541554594039916 and perplexity is 38.6348786097333
At time: 420.8804740905762 and batch: 1850, loss is 3.687428855895996 and perplexity is 39.94201813564423
At time: 422.14666295051575 and batch: 1900, loss is 3.784199385643005 and perplexity is 44.00042907798086
At time: 423.4126009941101 and batch: 1950, loss is 3.7020252752304077 and perplexity is 40.529304291911494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376633471111918 and perplexity of 79.5697082748321
finished 8 epochs...
Completing Train Step...
At time: 427.31082105636597 and batch: 50, loss is 3.9083107566833495 and perplexity is 49.814731656609744
At time: 428.5836229324341 and batch: 100, loss is 3.874912667274475 and perplexity is 48.17849054847339
At time: 429.8583014011383 and batch: 150, loss is 3.832872977256775 and perplexity is 46.19506514118914
At time: 431.1258900165558 and batch: 200, loss is 3.8292454528808593 and perplexity is 46.02779498804609
At time: 432.3977782726288 and batch: 250, loss is 3.820520029067993 and perplexity is 45.62793000224573
At time: 433.66794419288635 and batch: 300, loss is 3.8383787536621092 and perplexity is 46.45010629640668
At time: 434.9299998283386 and batch: 350, loss is 3.8532551956176757 and perplexity is 47.146284091710285
At time: 436.19616985321045 and batch: 400, loss is 3.7966634750366213 and perplexity is 44.5522864145574
At time: 437.46409940719604 and batch: 450, loss is 3.8375203800201416 and perplexity is 46.41025185694251
At time: 438.7323088645935 and batch: 500, loss is 3.850439453125 and perplexity is 47.01371901836232
At time: 440.0008819103241 and batch: 550, loss is 3.809750757217407 and perplexity is 45.13918684760087
At time: 441.26892852783203 and batch: 600, loss is 3.780396270751953 and perplexity is 43.83340819206226
At time: 442.53456139564514 and batch: 650, loss is 3.8226356077194215 and perplexity is 45.72456165675906
At time: 443.8022871017456 and batch: 700, loss is 3.8796840047836305 and perplexity is 48.40891566842256
At time: 445.070513010025 and batch: 750, loss is 3.818853416442871 and perplexity is 45.55194925087256
At time: 446.3401782512665 and batch: 800, loss is 3.818496036529541 and perplexity is 45.5356728078074
At time: 447.6068127155304 and batch: 850, loss is 3.8099003410339356 and perplexity is 45.14593944447154
At time: 448.89782667160034 and batch: 900, loss is 3.7649225568771363 and perplexity is 43.16036325711633
At time: 450.1634769439697 and batch: 950, loss is 3.859937171936035 and perplexity is 47.46236930640119
At time: 451.4301595687866 and batch: 1000, loss is 3.824732193946838 and perplexity is 45.82052770838139
At time: 452.6955029964447 and batch: 1050, loss is 3.785831985473633 and perplexity is 44.072322841945855
At time: 453.9615659713745 and batch: 1100, loss is 3.807695393562317 and perplexity is 45.04650468393744
At time: 455.22824001312256 and batch: 1150, loss is 3.7660944414138795 and perplexity is 43.21097186734965
At time: 456.4942297935486 and batch: 1200, loss is 3.8100826215744017 and perplexity is 45.1541694207728
At time: 457.76017212867737 and batch: 1250, loss is 3.806977348327637 and perplexity is 45.014170865871385
At time: 459.02936458587646 and batch: 1300, loss is 3.795889668464661 and perplexity is 44.51782489752769
At time: 460.29598593711853 and batch: 1350, loss is 3.679591941833496 and perplexity is 39.630219338039545
At time: 461.56388306617737 and batch: 1400, loss is 3.7023432302474975 and perplexity is 40.54219283643038
At time: 462.83069825172424 and batch: 1450, loss is 3.6415228843688965 and perplexity is 38.14989038141361
At time: 464.09641551971436 and batch: 1500, loss is 3.631361336708069 and perplexity is 37.764191420075775
At time: 465.36068296432495 and batch: 1550, loss is 3.6640233516693117 and perplexity is 39.01801067354087
At time: 466.6254518032074 and batch: 1600, loss is 3.740940279960632 and perplexity is 42.13759267733851
At time: 467.89167380332947 and batch: 1650, loss is 3.6879402780532837 and perplexity is 39.962450593085975
At time: 469.15733194351196 and batch: 1700, loss is 3.6819870328903197 and perplexity is 39.7252510813665
At time: 470.42288088798523 and batch: 1750, loss is 3.67112340927124 and perplexity is 39.29602659344194
At time: 471.6868417263031 and batch: 1800, loss is 3.625068407058716 and perplexity is 37.527290203342424
At time: 472.9512929916382 and batch: 1850, loss is 3.660393443107605 and perplexity is 38.87663560705092
At time: 474.2176342010498 and batch: 1900, loss is 3.7602747774124143 and perplexity is 42.960228857628735
At time: 475.48338174819946 and batch: 1950, loss is 3.6823499822616577 and perplexity is 39.73967195313759
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382716263172238 and perplexity of 80.05518930774095
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 479.34801602363586 and batch: 50, loss is 3.8821304035186768 and perplexity is 48.527488157135245
At time: 480.62325143814087 and batch: 100, loss is 3.882894344329834 and perplexity is 48.56457444986405
At time: 481.8889718055725 and batch: 150, loss is 3.854760961532593 and perplexity is 47.21732883426297
At time: 483.1553053855896 and batch: 200, loss is 3.861646366119385 and perplexity is 47.54356107843418
At time: 484.4209978580475 and batch: 250, loss is 3.8579724264144897 and perplexity is 47.369209376610115
At time: 485.6881408691406 and batch: 300, loss is 3.8654526233673097 and perplexity is 47.72486893566113
At time: 486.96370697021484 and batch: 350, loss is 3.886855001449585 and perplexity is 48.75730349231183
At time: 488.23171043395996 and batch: 400, loss is 3.840211238861084 and perplexity is 46.53530346612087
At time: 489.49921202659607 and batch: 450, loss is 3.8790313005447388 and perplexity is 48.377329273373974
At time: 490.7672975063324 and batch: 500, loss is 3.891861915588379 and perplexity is 49.00203929884481
At time: 492.03609585762024 and batch: 550, loss is 3.861190733909607 and perplexity is 47.5219036349284
At time: 493.30498027801514 and batch: 600, loss is 3.818734998703003 and perplexity is 45.546555411365134
At time: 494.5718677043915 and batch: 650, loss is 3.8442253637313843 and perplexity is 46.72247740355905
At time: 495.8406140804291 and batch: 700, loss is 3.903823709487915 and perplexity is 49.59171133018698
At time: 497.10458064079285 and batch: 750, loss is 3.832341442108154 and perplexity is 46.170517364954655
At time: 498.3716142177582 and batch: 800, loss is 3.830082321166992 and perplexity is 46.06633031219853
At time: 499.63734889030457 and batch: 850, loss is 3.815138077735901 and perplexity is 45.383022335315445
At time: 500.90287733078003 and batch: 900, loss is 3.7630535316467286 and perplexity is 43.079770787375715
At time: 502.1696979999542 and batch: 950, loss is 3.8624081659317016 and perplexity is 47.57979355353471
At time: 503.43629479408264 and batch: 1000, loss is 3.829066834449768 and perplexity is 46.01957430972292
At time: 504.7006676197052 and batch: 1050, loss is 3.786441226005554 and perplexity is 44.09918166826913
At time: 505.97324681282043 and batch: 1100, loss is 3.809907469749451 and perplexity is 45.14626127817763
At time: 507.237548828125 and batch: 1150, loss is 3.7810664129257203 and perplexity is 43.862792652295056
At time: 508.5038540363312 and batch: 1200, loss is 3.8156215953826904 and perplexity is 45.404971133367184
At time: 509.7705852985382 and batch: 1250, loss is 3.8081126737594606 and perplexity is 45.06530562064908
At time: 511.03652358055115 and batch: 1300, loss is 3.8009861183166502 and perplexity is 44.74528689162315
At time: 512.3032505512238 and batch: 1350, loss is 3.6601550006866455 and perplexity is 38.867366873011626
At time: 513.5695292949677 and batch: 1400, loss is 3.6763733053207397 and perplexity is 39.502869124035584
At time: 514.8355629444122 and batch: 1450, loss is 3.608055105209351 and perplexity is 36.89422760015562
At time: 516.1025245189667 and batch: 1500, loss is 3.600520510673523 and perplexity is 36.61728917400306
At time: 517.3680276870728 and batch: 1550, loss is 3.6282922649383544 and perplexity is 37.64846807873743
At time: 518.6342582702637 and batch: 1600, loss is 3.706713695526123 and perplexity is 40.719768844774705
At time: 519.9014089107513 and batch: 1650, loss is 3.651469597816467 and perplexity is 38.53124990181657
At time: 521.1649475097656 and batch: 1700, loss is 3.6364436769485473 and perplexity is 37.95661044507134
At time: 522.4291038513184 and batch: 1750, loss is 3.6249369955062867 and perplexity is 37.52235900789347
At time: 523.6964802742004 and batch: 1800, loss is 3.5781892108917237 and perplexity is 35.80864020844023
At time: 524.9644558429718 and batch: 1850, loss is 3.6081885862350465 and perplexity is 36.89915260818818
At time: 526.2366180419922 and batch: 1900, loss is 3.7100758838653562 and perplexity is 40.85690678937251
At time: 527.5051279067993 and batch: 1950, loss is 3.633629069328308 and perplexity is 37.84992768555666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354629019803779 and perplexity of 77.83794364428474
finished 10 epochs...
Completing Train Step...
At time: 531.4137635231018 and batch: 50, loss is 3.882098217010498 and perplexity is 48.52592625187705
At time: 532.6933093070984 and batch: 100, loss is 3.856743793487549 and perplexity is 47.311045744440364
At time: 533.9614505767822 and batch: 150, loss is 3.8178931999206545 and perplexity is 45.508230509670625
At time: 535.2292408943176 and batch: 200, loss is 3.8163501453399657 and perplexity is 45.43806297621311
At time: 536.4973361492157 and batch: 250, loss is 3.809603934288025 and perplexity is 45.13255986646626
At time: 537.7654161453247 and batch: 300, loss is 3.8135141038894655 and perplexity is 45.30938130570815
At time: 539.0332028865814 and batch: 350, loss is 3.8352713584899902 and perplexity is 46.30599148715129
At time: 540.3020598888397 and batch: 400, loss is 3.7877869272232054 and perplexity is 44.1585659385183
At time: 541.5700912475586 and batch: 450, loss is 3.829131464958191 and perplexity is 46.02254867432428
At time: 542.849867105484 and batch: 500, loss is 3.840475182533264 and perplexity is 46.547587786116694
At time: 544.1186695098877 and batch: 550, loss is 3.810279855728149 and perplexity is 45.16307624350262
At time: 545.3861837387085 and batch: 600, loss is 3.772792115211487 and perplexity is 43.50135622572441
At time: 546.6524901390076 and batch: 650, loss is 3.7993970012664793 and perplexity is 44.674237860873596
At time: 547.9183025360107 and batch: 700, loss is 3.8610799407958982 and perplexity is 47.51663882691294
At time: 549.1846656799316 and batch: 750, loss is 3.7926671504974365 and perplexity is 44.37459630923114
At time: 550.449170589447 and batch: 800, loss is 3.7901994132995607 and perplexity is 44.26522647079015
At time: 551.7151141166687 and batch: 850, loss is 3.7768310928344726 and perplexity is 43.67741253449658
At time: 552.9812910556793 and batch: 900, loss is 3.7260256671905516 and perplexity is 41.51379024879577
At time: 554.2477083206177 and batch: 950, loss is 3.8269860410690306 and perplexity is 45.923916640551404
At time: 555.5126028060913 and batch: 1000, loss is 3.7943113088607787 and perplexity is 44.44761518372042
At time: 556.7782337665558 and batch: 1050, loss is 3.753953428268433 and perplexity is 42.6895187796259
At time: 558.0452733039856 and batch: 1100, loss is 3.7788036680221557 and perplexity is 43.76365454618618
At time: 559.3118674755096 and batch: 1150, loss is 3.7515729904174804 and perplexity is 42.5880198871152
At time: 560.5777351856232 and batch: 1200, loss is 3.7872426891326905 and perplexity is 44.13453970350121
At time: 561.8435878753662 and batch: 1250, loss is 3.7834191131591797 and perplexity is 43.96611014469564
At time: 563.1098008155823 and batch: 1300, loss is 3.777556548118591 and perplexity is 43.70911004038777
At time: 564.3734056949615 and batch: 1350, loss is 3.639156017303467 and perplexity is 38.059701437044794
At time: 565.6370389461517 and batch: 1400, loss is 3.6578347301483154 and perplexity is 38.77728861013598
At time: 566.9072911739349 and batch: 1450, loss is 3.5923682928085325 and perplexity is 36.319990523221215
At time: 568.1767077445984 and batch: 1500, loss is 3.5872742891311646 and perplexity is 36.13544679021956
At time: 569.4537718296051 and batch: 1550, loss is 3.618144364356995 and perplexity is 37.26834714442103
At time: 570.7193994522095 and batch: 1600, loss is 3.698879346847534 and perplexity is 40.402002349589054
At time: 571.9866967201233 and batch: 1650, loss is 3.6440605688095093 and perplexity is 38.246825708260275
At time: 573.2536842823029 and batch: 1700, loss is 3.6322839403152467 and perplexity is 37.799048876637116
At time: 574.5205380916595 and batch: 1750, loss is 3.6235556268692015 and perplexity is 37.470562581186606
At time: 575.7875056266785 and batch: 1800, loss is 3.579305076599121 and perplexity is 35.84862014404848
At time: 577.052928686142 and batch: 1850, loss is 3.610433826446533 and perplexity is 36.982093145265715
At time: 578.3181095123291 and batch: 1900, loss is 3.713407440185547 and perplexity is 40.993250868289074
At time: 579.5886085033417 and batch: 1950, loss is 3.636680579185486 and perplexity is 37.96560351618966
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354902968295785 and perplexity of 77.85927015261595
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 583.5292301177979 and batch: 50, loss is 3.875798645019531 and perplexity is 48.22119453348652
At time: 584.8068125247955 and batch: 100, loss is 3.868549666404724 and perplexity is 47.87290402590724
At time: 586.0744347572327 and batch: 150, loss is 3.843017745018005 and perplexity is 46.66608852049914
At time: 587.3509714603424 and batch: 200, loss is 3.8468302869796753 and perplexity is 46.84434452950808
At time: 588.6200385093689 and batch: 250, loss is 3.848697509765625 and perplexity is 46.93189506975104
At time: 589.9065296649933 and batch: 300, loss is 3.845232353210449 and perplexity is 46.76955014363952
At time: 591.1820430755615 and batch: 350, loss is 3.8711340618133545 and perplexity is 47.9967865510322
At time: 592.4514410495758 and batch: 400, loss is 3.827731704711914 and perplexity is 45.95817320587946
At time: 593.7202656269073 and batch: 450, loss is 3.875382704734802 and perplexity is 48.20114156680973
At time: 594.9890406131744 and batch: 500, loss is 3.8876641273498533 and perplexity is 48.79677025403106
At time: 596.2575244903564 and batch: 550, loss is 3.867255301475525 and perplexity is 47.810979103246915
At time: 597.5234098434448 and batch: 600, loss is 3.8210023260116577 and perplexity is 45.64994152104901
At time: 598.7908487319946 and batch: 650, loss is 3.8348852825164794 and perplexity is 46.28811730702627
At time: 600.057391166687 and batch: 700, loss is 3.891741199493408 and perplexity is 48.996124321038735
At time: 601.3236167430878 and batch: 750, loss is 3.8178719663619995 and perplexity is 45.507264218247755
At time: 602.5902662277222 and batch: 800, loss is 3.8139494132995604 and perplexity is 45.329109199313436
At time: 603.8563075065613 and batch: 850, loss is 3.799139041900635 and perplexity is 44.662715209057296
At time: 605.1209673881531 and batch: 900, loss is 3.7378203964233396 and perplexity is 42.00633315931779
At time: 606.395170211792 and batch: 950, loss is 3.8371290826797484 and perplexity is 46.39209520138109
At time: 607.6573169231415 and batch: 1000, loss is 3.8063139724731445 and perplexity is 44.98431945425654
At time: 608.9219071865082 and batch: 1050, loss is 3.765038347244263 and perplexity is 43.16536110076867
At time: 610.1878814697266 and batch: 1100, loss is 3.7822598743438722 and perplexity is 43.91517245343658
At time: 611.4553005695343 and batch: 1150, loss is 3.763496785163879 and perplexity is 43.09887027994118
At time: 612.7213308811188 and batch: 1200, loss is 3.8041249990463255 and perplexity is 44.885957669290285
At time: 613.9887397289276 and batch: 1250, loss is 3.7992708492279053 and perplexity is 44.6686024701612
At time: 615.2549407482147 and batch: 1300, loss is 3.7983249855041503 and perplexity is 44.62637203476076
At time: 616.5210132598877 and batch: 1350, loss is 3.6523722648620605 and perplexity is 38.56604649383421
At time: 617.7878429889679 and batch: 1400, loss is 3.671735963821411 and perplexity is 39.320104927228954
At time: 619.0550811290741 and batch: 1450, loss is 3.6020485591888427 and perplexity is 36.67328493958814
At time: 620.3213608264923 and batch: 1500, loss is 3.5919232034683226 and perplexity is 36.30382847964628
At time: 621.5878260135651 and batch: 1550, loss is 3.613606963157654 and perplexity is 37.0996287623496
At time: 622.8544936180115 and batch: 1600, loss is 3.690821590423584 and perplexity is 40.07776093911541
At time: 624.1221160888672 and batch: 1650, loss is 3.636817684173584 and perplexity is 37.97080914665869
At time: 625.3897829055786 and batch: 1700, loss is 3.6168104076385497 and perplexity is 37.21866592602697
At time: 626.6615362167358 and batch: 1750, loss is 3.602926979064941 and perplexity is 36.70551363509189
At time: 627.9283576011658 and batch: 1800, loss is 3.5606710863113404 and perplexity is 35.186802605138304
At time: 629.1945557594299 and batch: 1850, loss is 3.5904857540130615 and perplexity is 36.25168104980081
At time: 630.4588572978973 and batch: 1900, loss is 3.7026833152770995 and perplexity is 40.55598297405806
At time: 631.7238099575043 and batch: 1950, loss is 3.6255773973464964 and perplexity is 37.546396091525935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338797351925872 and perplexity of 76.61534261505761
finished 12 epochs...
Completing Train Step...
At time: 635.607549905777 and batch: 50, loss is 3.8759505701065065 and perplexity is 48.228521099190544
At time: 636.8731789588928 and batch: 100, loss is 3.853509645462036 and perplexity is 47.15828198272561
At time: 638.1485633850098 and batch: 150, loss is 3.8186034393310546 and perplexity is 45.54056372928041
At time: 639.4168002605438 and batch: 200, loss is 3.8179830169677733 and perplexity is 45.51231810811987
At time: 640.6836488246918 and batch: 250, loss is 3.817006092071533 and perplexity is 45.46787770247821
At time: 641.9590623378754 and batch: 300, loss is 3.815020885467529 and perplexity is 45.37770410761607
At time: 643.2252509593964 and batch: 350, loss is 3.840131649971008 and perplexity is 46.53159992035117
At time: 644.4908020496368 and batch: 400, loss is 3.798876233100891 and perplexity is 44.65097899673739
At time: 645.7566485404968 and batch: 450, loss is 3.8465248441696165 and perplexity is 46.83003844623598
At time: 647.0222308635712 and batch: 500, loss is 3.86059476852417 and perplexity is 47.49359066292555
At time: 648.2882652282715 and batch: 550, loss is 3.8404953956604 and perplexity is 46.54852866793554
At time: 649.55437541008 and batch: 600, loss is 3.797956695556641 and perplexity is 44.609939616679476
At time: 650.8163177967072 and batch: 650, loss is 3.8130107355117797 and perplexity is 45.286579735222574
At time: 652.0795426368713 and batch: 700, loss is 3.8712370920181276 and perplexity is 48.00173192453605
At time: 653.347225189209 and batch: 750, loss is 3.800495910644531 and perplexity is 44.723357784045234
At time: 654.6137323379517 and batch: 800, loss is 3.7956676483154297 and perplexity is 44.50794214052668
At time: 655.8793494701385 and batch: 850, loss is 3.7816391658782957 and perplexity is 43.88792239217424
At time: 657.1460831165314 and batch: 900, loss is 3.7226050758361815 and perplexity is 41.37203112502058
At time: 658.4130918979645 and batch: 950, loss is 3.8219419622421267 and perplexity is 45.69285601887197
At time: 659.6770470142365 and batch: 1000, loss is 3.7910492610931397 and perplexity is 44.30286116545462
At time: 660.94211602211 and batch: 1050, loss is 3.750209903717041 and perplexity is 42.53000827002305
At time: 662.2135381698608 and batch: 1100, loss is 3.76864399433136 and perplexity is 43.321281086584236
At time: 663.4920046329498 and batch: 1150, loss is 3.750387473106384 and perplexity is 42.53756096816447
At time: 664.7576620578766 and batch: 1200, loss is 3.7912348318099975 and perplexity is 44.31108324202468
At time: 666.023218870163 and batch: 1250, loss is 3.78856737613678 and perplexity is 44.19304289533178
At time: 667.2890617847443 and batch: 1300, loss is 3.7882646131515503 and perplexity is 44.179664903021035
At time: 668.5544221401215 and batch: 1350, loss is 3.644537706375122 and perplexity is 38.265079059904714
At time: 669.8206717967987 and batch: 1400, loss is 3.665107498168945 and perplexity is 39.060334851894595
At time: 671.0946509838104 and batch: 1450, loss is 3.5973480272293092 and perplexity is 36.50130550573815
At time: 672.3652913570404 and batch: 1500, loss is 3.5896310949325563 and perplexity is 36.220711457514774
At time: 673.633697271347 and batch: 1550, loss is 3.6141056871414183 and perplexity is 37.118135851583176
At time: 674.9017748832703 and batch: 1600, loss is 3.692848916053772 and perplexity is 40.15909402753829
At time: 676.179370880127 and batch: 1650, loss is 3.6393386125564575 and perplexity is 38.06665159237081
At time: 677.4513866901398 and batch: 1700, loss is 3.621404685974121 and perplexity is 37.390052233309326
At time: 678.7207274436951 and batch: 1750, loss is 3.608932919502258 and perplexity is 36.926628099198844
At time: 679.9902873039246 and batch: 1800, loss is 3.5675711107254027 and perplexity is 35.43043195980861
At time: 681.2604720592499 and batch: 1850, loss is 3.5981789016723633 and perplexity is 36.53164611049204
At time: 682.5278785228729 and batch: 1900, loss is 3.709951171875 and perplexity is 40.85181176091917
At time: 683.7951760292053 and batch: 1950, loss is 3.63173378944397 and perplexity is 37.778259416158456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337396949945494 and perplexity of 76.50812542863443
finished 13 epochs...
Completing Train Step...
At time: 687.7512195110321 and batch: 50, loss is 3.870733046531677 and perplexity is 47.97754296489777
At time: 689.0180082321167 and batch: 100, loss is 3.8456802988052368 and perplexity is 46.7905050505753
At time: 690.2864973545074 and batch: 150, loss is 3.8091119146347046 and perplexity is 45.11035922203186
At time: 691.5630114078522 and batch: 200, loss is 3.8073492813110352 and perplexity is 45.03091623462118
At time: 692.8292512893677 and batch: 250, loss is 3.8054812860488894 and perplexity is 44.946877213129
At time: 694.0933556556702 and batch: 300, loss is 3.8034042358398437 and perplexity is 44.85361717883244
At time: 695.3699610233307 and batch: 350, loss is 3.828116054534912 and perplexity is 45.97584061663206
At time: 696.6378717422485 and batch: 400, loss is 3.786837158203125 and perplexity is 44.11664541117904
At time: 697.9070873260498 and batch: 450, loss is 3.835089797973633 and perplexity is 46.297584910600726
At time: 699.1847057342529 and batch: 500, loss is 3.8490062713623048 and perplexity is 46.946388073934415
At time: 700.4617025852203 and batch: 550, loss is 3.8287631130218505 and perplexity is 46.00559930126361
At time: 701.7307131290436 and batch: 600, loss is 3.78713641166687 and perplexity is 44.129849445705155
At time: 703.0008010864258 and batch: 650, loss is 3.802596106529236 and perplexity is 44.817384298501636
At time: 704.2702157497406 and batch: 700, loss is 3.8611837816238403 and perplexity is 47.52157325022262
At time: 705.5389003753662 and batch: 750, loss is 3.7913177585601807 and perplexity is 44.314757968519494
At time: 706.8068218231201 and batch: 800, loss is 3.786552996635437 and perplexity is 44.10411093705013
At time: 708.096559047699 and batch: 850, loss is 3.7725655221939087 and perplexity is 43.49150023883955
At time: 709.377434015274 and batch: 900, loss is 3.714190754890442 and perplexity is 41.02537406413898
At time: 710.6458623409271 and batch: 950, loss is 3.8141421127319335 and perplexity is 45.33784493458471
At time: 711.9150218963623 and batch: 1000, loss is 3.7832906579971315 and perplexity is 43.96046283361327
At time: 713.1834983825684 and batch: 1050, loss is 3.742864146232605 and perplexity is 42.21873780182837
At time: 714.4485268592834 and batch: 1100, loss is 3.7617027044296263 and perplexity is 43.021616747362586
At time: 715.7164347171783 and batch: 1150, loss is 3.7438384532928466 and perplexity is 42.25989186123295
At time: 716.9852831363678 and batch: 1200, loss is 3.784642105102539 and perplexity is 44.019913236851416
At time: 718.2531332969666 and batch: 1250, loss is 3.783100137710571 and perplexity is 43.95208827142421
At time: 719.5211701393127 and batch: 1300, loss is 3.7830564641952513 and perplexity is 43.950168771139715
At time: 720.7955591678619 and batch: 1350, loss is 3.640072455406189 and perplexity is 38.094596784890854
At time: 722.0670900344849 and batch: 1400, loss is 3.6610002660751344 and perplexity is 38.90023400173736
At time: 723.3360171318054 and batch: 1450, loss is 3.5941216373443603 and perplexity is 36.38372784055643
At time: 724.60515832901 and batch: 1500, loss is 3.587314734458923 and perplexity is 36.136908329764715
At time: 725.8733365535736 and batch: 1550, loss is 3.6131206512451173 and perplexity is 37.08159115723839
At time: 727.1413300037384 and batch: 1600, loss is 3.6925586557388304 and perplexity is 40.147439127817336
At time: 728.4120061397552 and batch: 1650, loss is 3.6392017221450805 and perplexity is 38.06144098942351
At time: 729.6809365749359 and batch: 1700, loss is 3.6220825147628783 and perplexity is 37.41540487853191
At time: 730.9495203495026 and batch: 1750, loss is 3.6100024366378785 and perplexity is 36.96614288781675
At time: 732.2183976173401 and batch: 1800, loss is 3.568983163833618 and perplexity is 35.48049695027688
At time: 733.4861660003662 and batch: 1850, loss is 3.599882273674011 and perplexity is 36.59392612160569
At time: 734.7529466152191 and batch: 1900, loss is 3.7114023685455324 and perplexity is 40.9111388113291
At time: 736.0209448337555 and batch: 1950, loss is 3.632593812942505 and perplexity is 37.81076358215993
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337250749454942 and perplexity of 76.49694072079035
finished 14 epochs...
Completing Train Step...
At time: 739.9768643379211 and batch: 50, loss is 3.8650178623199465 and perplexity is 47.7041245314136
At time: 741.2473049163818 and batch: 100, loss is 3.8389004850387574 and perplexity is 46.474347097353515
At time: 742.516170501709 and batch: 150, loss is 3.801692204475403 and perplexity is 44.77689207604529
At time: 743.7845571041107 and batch: 200, loss is 3.7995019245147703 and perplexity is 44.67892547294033
At time: 745.0550756454468 and batch: 250, loss is 3.7971226358413697 and perplexity is 44.57274777540886
At time: 746.3250024318695 and batch: 300, loss is 3.794915266036987 and perplexity is 44.474467747959174
At time: 747.5958330631256 and batch: 350, loss is 3.8195542764663695 and perplexity is 45.583885981376476
At time: 748.8660552501678 and batch: 400, loss is 3.7781950569152833 and perplexity is 43.73702760350048
At time: 750.1358892917633 and batch: 450, loss is 3.8269224882125856 and perplexity is 45.92099813721035
At time: 751.4066030979156 and batch: 500, loss is 3.840632586479187 and perplexity is 46.55491513676923
At time: 752.6762957572937 and batch: 550, loss is 3.820286111831665 and perplexity is 45.61725809118088
At time: 753.945303440094 and batch: 600, loss is 3.779258437156677 and perplexity is 43.783561431663095
At time: 755.2160711288452 and batch: 650, loss is 3.7949731874465944 and perplexity is 44.47704384642758
At time: 756.4923136234283 and batch: 700, loss is 3.8537865257263184 and perplexity is 47.17134098811109
At time: 757.7614243030548 and batch: 750, loss is 3.784461236000061 and perplexity is 44.011952114635335
At time: 759.0305025577545 and batch: 800, loss is 3.779847025871277 and perplexity is 43.80933952741067
At time: 760.3011789321899 and batch: 850, loss is 3.7658225440979005 and perplexity is 43.199224517186934
At time: 761.5705943107605 and batch: 900, loss is 3.70781334400177 and perplexity is 40.76457090525766
At time: 762.8382685184479 and batch: 950, loss is 3.8081188917160036 and perplexity is 45.065585835632206
At time: 764.1358780860901 and batch: 1000, loss is 3.7772818660736083 and perplexity is 43.69710558143764
At time: 765.4048027992249 and batch: 1050, loss is 3.737242021560669 and perplexity is 41.98204477671752
At time: 766.6739692687988 and batch: 1100, loss is 3.756284236907959 and perplexity is 42.78913592797076
At time: 767.9438269138336 and batch: 1150, loss is 3.7386899900436403 and perplexity is 42.042877485699016
At time: 769.2110567092896 and batch: 1200, loss is 3.7794036293029785 and perplexity is 43.78991892243777
At time: 770.4762585163116 and batch: 1250, loss is 3.7785979890823365 and perplexity is 43.754654209738064
At time: 771.7431943416595 and batch: 1300, loss is 3.7787229108810423 and perplexity is 43.76012046126357
At time: 773.0085971355438 and batch: 1350, loss is 3.6361232137680055 and perplexity is 37.944448697765715
At time: 774.2727797031403 and batch: 1400, loss is 3.6573255443573 and perplexity is 38.75754879180559
At time: 775.5390024185181 and batch: 1450, loss is 3.5909853076934812 and perplexity is 36.26979523461778
At time: 776.8046817779541 and batch: 1500, loss is 3.584705319404602 and perplexity is 36.042735059163256
At time: 778.0771877765656 and batch: 1550, loss is 3.6112445545196534 and perplexity is 37.012087723461725
At time: 779.3414573669434 and batch: 1600, loss is 3.691121664047241 and perplexity is 40.08978902263352
At time: 780.6039788722992 and batch: 1650, loss is 3.6378104162216185 and perplexity is 38.008522702418816
At time: 781.8714466094971 and batch: 1700, loss is 3.62121636390686 and perplexity is 37.383011524359
At time: 783.1669306755066 and batch: 1750, loss is 3.609310245513916 and perplexity is 36.940564105547
At time: 784.4457955360413 and batch: 1800, loss is 3.568523964881897 and perplexity is 35.46420808347228
At time: 785.717119216919 and batch: 1850, loss is 3.5996428442001345 and perplexity is 36.58516550594397
At time: 786.9785356521606 and batch: 1900, loss is 3.711078224182129 and perplexity is 40.89787984530864
At time: 788.2405614852905 and batch: 1950, loss is 3.6318894529342653 and perplexity is 37.78414056960502
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337534633902616 and perplexity of 76.51866009530613
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 792.1942369937897 and batch: 50, loss is 3.8635003852844236 and perplexity is 47.63178951518116
At time: 793.4680933952332 and batch: 100, loss is 3.843311324119568 and perplexity is 46.67979072008175
At time: 794.7346878051758 and batch: 150, loss is 3.811053605079651 and perplexity is 45.19803466724262
At time: 796.0132446289062 and batch: 200, loss is 3.8102598905563356 and perplexity is 45.16217456392692
At time: 797.2796940803528 and batch: 250, loss is 3.8105828523635865 and perplexity is 45.1767625770022
At time: 798.5445408821106 and batch: 300, loss is 3.806111135482788 and perplexity is 44.97519589561408
At time: 799.8072283267975 and batch: 350, loss is 3.8316303491592407 and perplexity is 46.13769750597687
At time: 801.0713393688202 and batch: 400, loss is 3.7928810214996336 and perplexity is 44.38408776355313
At time: 802.3353197574615 and batch: 450, loss is 3.846437349319458 and perplexity is 46.82594123828413
At time: 803.5975687503815 and batch: 500, loss is 3.862032399177551 and perplexity is 47.561918007676205
At time: 804.8622071743011 and batch: 550, loss is 3.847509713172913 and perplexity is 46.8761826187776
At time: 806.1367251873016 and batch: 600, loss is 3.8029473304748533 and perplexity is 44.833128001668136
At time: 807.4150590896606 and batch: 650, loss is 3.8164664268493653 and perplexity is 45.44334688996496
At time: 808.6787497997284 and batch: 700, loss is 3.87222674369812 and perplexity is 48.04926043363299
At time: 809.9419140815735 and batch: 750, loss is 3.7997375249862673 and perplexity is 44.689453088954686
At time: 811.2112250328064 and batch: 800, loss is 3.7984780788421633 and perplexity is 44.63320455801253
At time: 812.4897215366364 and batch: 850, loss is 3.790986919403076 and perplexity is 44.300099336304356
At time: 813.7721176147461 and batch: 900, loss is 3.72801287651062 and perplexity is 41.5963688630102
At time: 815.037791967392 and batch: 950, loss is 3.8330001497268675 and perplexity is 46.200940255297695
At time: 816.3057973384857 and batch: 1000, loss is 3.803021078109741 and perplexity is 44.83643446074315
At time: 817.5732283592224 and batch: 1050, loss is 3.755832085609436 and perplexity is 42.76979313786161
At time: 818.8383574485779 and batch: 1100, loss is 3.7617286109924315 and perplexity is 43.02273130401594
At time: 820.1145172119141 and batch: 1150, loss is 3.7411633920669556 and perplexity is 42.14699513325802
At time: 821.3814239501953 and batch: 1200, loss is 3.779121618270874 and perplexity is 43.777571423354
At time: 822.6482698917389 and batch: 1250, loss is 3.774378190040588 and perplexity is 43.57040737753708
At time: 823.9139878749847 and batch: 1300, loss is 3.7725726795196532 and perplexity is 43.491811522787856
At time: 825.1794645786285 and batch: 1350, loss is 3.6301791715621947 and perplexity is 37.71957428682285
At time: 826.4459927082062 and batch: 1400, loss is 3.6535819292068483 and perplexity is 38.6127266931914
At time: 827.7137920856476 and batch: 1450, loss is 3.583210687637329 and perplexity is 35.988904680682374
At time: 828.9792165756226 and batch: 1500, loss is 3.573115553855896 and perplexity is 35.62741956355149
At time: 830.2454986572266 and batch: 1550, loss is 3.602532734870911 and perplexity is 36.69104555161871
At time: 831.5094997882843 and batch: 1600, loss is 3.6846122455596926 and perplexity is 39.82967532174668
At time: 832.7746975421906 and batch: 1650, loss is 3.6323263359069826 and perplexity is 37.80065142365152
At time: 834.0398750305176 and batch: 1700, loss is 3.614293308258057 and perplexity is 37.125100651030486
At time: 835.30601811409 and batch: 1750, loss is 3.600546565055847 and perplexity is 36.61824322728346
At time: 836.5756242275238 and batch: 1800, loss is 3.557157049179077 and perplexity is 35.06337187132406
At time: 837.8418533802032 and batch: 1850, loss is 3.586960430145264 and perplexity is 36.12410713515431
At time: 839.1085195541382 and batch: 1900, loss is 3.699347825050354 and perplexity is 40.42093424128317
At time: 840.3747589588165 and batch: 1950, loss is 3.6252510166168213 and perplexity is 37.534143670958656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334429789698401 and perplexity of 76.28145001772204
finished 16 epochs...
Completing Train Step...
At time: 844.2703292369843 and batch: 50, loss is 3.8629533863067627 and perplexity is 47.605742099616506
At time: 845.5506658554077 and batch: 100, loss is 3.8394486951828 and perplexity is 46.499831790715504
At time: 846.832234621048 and batch: 150, loss is 3.8058667898178102 and perplexity is 44.96420774397374
At time: 848.1029753684998 and batch: 200, loss is 3.803537302017212 and perplexity is 44.85958607533188
At time: 849.3695492744446 and batch: 250, loss is 3.8024316358566286 and perplexity is 44.81001375929694
At time: 850.6349380016327 and batch: 300, loss is 3.797750310897827 and perplexity is 44.60073375951852
At time: 851.9024951457977 and batch: 350, loss is 3.8214796781539917 and perplexity is 45.67173782027268
At time: 853.168238401413 and batch: 400, loss is 3.7816432428359987 and perplexity is 43.888101321742255
At time: 854.4333553314209 and batch: 450, loss is 3.833475961685181 and perplexity is 46.222928445863644
At time: 855.7072942256927 and batch: 500, loss is 3.8490227556228636 and perplexity is 46.94716195680614
At time: 856.9737470149994 and batch: 550, loss is 3.833434910774231 and perplexity is 46.221030991490565
At time: 858.271598815918 and batch: 600, loss is 3.7916858053207396 and perplexity is 44.33107087340652
At time: 859.5444271564484 and batch: 650, loss is 3.8059928035736084 and perplexity is 44.96987420968686
At time: 860.8137362003326 and batch: 700, loss is 3.863344235420227 and perplexity is 47.624352398384424
At time: 862.0808882713318 and batch: 750, loss is 3.791712121963501 and perplexity is 44.33223753371315
At time: 863.3490676879883 and batch: 800, loss is 3.7898939037323 and perplexity is 44.2517050861677
At time: 864.6165690422058 and batch: 850, loss is 3.781177101135254 and perplexity is 43.867648014989626
At time: 865.8900101184845 and batch: 900, loss is 3.7198419761657715 and perplexity is 41.25787386602707
At time: 867.1587545871735 and batch: 950, loss is 3.8239755773544313 and perplexity is 45.78587224894547
At time: 868.4281849861145 and batch: 1000, loss is 3.794198899269104 and perplexity is 44.44261912625434
At time: 869.6939768791199 and batch: 1050, loss is 3.748540410995483 and perplexity is 42.459063967744626
At time: 870.9608640670776 and batch: 1100, loss is 3.7565675020217895 and perplexity is 42.80125831427362
At time: 872.2275578975677 and batch: 1150, loss is 3.7359927177429197 and perplexity is 41.92962919621081
At time: 873.4932336807251 and batch: 1200, loss is 3.775057315826416 and perplexity is 43.60000721455483
At time: 874.7793066501617 and batch: 1250, loss is 3.7714583683013916 and perplexity is 43.44337510094152
At time: 876.0534105300903 and batch: 1300, loss is 3.7706927394866945 and perplexity is 43.41012633088892
At time: 877.3196322917938 and batch: 1350, loss is 3.6285489988327027 and perplexity is 37.658134957418135
At time: 878.5883166790009 and batch: 1400, loss is 3.653041000366211 and perplexity is 38.5918456038083
At time: 879.8552725315094 and batch: 1450, loss is 3.584050555229187 and perplexity is 36.01914329182743
At time: 881.1184620857239 and batch: 1500, loss is 3.575756392478943 and perplexity is 35.72163017192879
At time: 882.383172750473 and batch: 1550, loss is 3.6053787231445313 and perplexity is 36.79561657036968
At time: 883.6488537788391 and batch: 1600, loss is 3.6878128719329832 and perplexity is 39.957359456626065
At time: 884.9242162704468 and batch: 1650, loss is 3.6359894275665283 and perplexity is 37.93937259367121
At time: 886.1928417682648 and batch: 1700, loss is 3.618117527961731 and perplexity is 37.267347009746295
At time: 887.4685473442078 and batch: 1750, loss is 3.604969596862793 and perplexity is 36.78056559566257
At time: 888.7357318401337 and batch: 1800, loss is 3.561915807723999 and perplexity is 35.23062764110596
At time: 890.0018992424011 and batch: 1850, loss is 3.5920965576171877 and perplexity is 36.3101224444596
At time: 891.2711389064789 and batch: 1900, loss is 3.7043887996673583 and perplexity is 40.62520958562481
At time: 892.5367877483368 and batch: 1950, loss is 3.6292274713516237 and perplexity is 37.68369363655083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33343023255814 and perplexity of 76.20524044394433
finished 17 epochs...
Completing Train Step...
At time: 896.4353079795837 and batch: 50, loss is 3.862364296913147 and perplexity is 47.57770632047124
At time: 897.7128343582153 and batch: 100, loss is 3.837253060340881 and perplexity is 46.39784714138788
At time: 898.9865138530731 and batch: 150, loss is 3.8030615282058715 and perplexity is 44.83824813550864
At time: 900.2581253051758 and batch: 200, loss is 3.7998081159591677 and perplexity is 44.69260787227492
At time: 901.5260348320007 and batch: 250, loss is 3.7980943155288696 and perplexity is 44.61607925778958
At time: 902.7917904853821 and batch: 300, loss is 3.7933903789520262 and perplexity is 44.406700888015976
At time: 904.0575575828552 and batch: 350, loss is 3.816331777572632 and perplexity is 45.43722838810905
At time: 905.3241693973541 and batch: 400, loss is 3.776107530593872 and perplexity is 43.645820638749235
At time: 906.6040978431702 and batch: 450, loss is 3.827535157203674 and perplexity is 45.949141129097754
At time: 907.8692569732666 and batch: 500, loss is 3.8431008100509643 and perplexity is 46.66996500167795
At time: 909.133403301239 and batch: 550, loss is 3.8271511077880858 and perplexity is 45.931497776476824
At time: 910.3946783542633 and batch: 600, loss is 3.7863794660568235 and perplexity is 44.09645818917207
At time: 911.6584985256195 and batch: 650, loss is 3.80098388671875 and perplexity is 44.74518703824629
At time: 912.923909664154 and batch: 700, loss is 3.858864779472351 and perplexity is 47.4114983009651
At time: 914.1919357776642 and batch: 750, loss is 3.7877621030807496 and perplexity is 44.15746975359278
At time: 915.4610438346863 and batch: 800, loss is 3.7857707166671752 and perplexity is 44.069622666046634
At time: 916.7298927307129 and batch: 850, loss is 3.776629590988159 and perplexity is 43.66861234188599
At time: 917.998729467392 and batch: 900, loss is 3.715994606018066 and perplexity is 41.099444517356375
At time: 919.2678673267365 and batch: 950, loss is 3.8200421285629274 and perplexity is 45.606129601078834
At time: 920.5385608673096 and batch: 1000, loss is 3.7904542446136475 and perplexity is 44.276508074011886
At time: 921.8246204853058 and batch: 1050, loss is 3.745294804573059 and perplexity is 42.32148194636053
At time: 923.0952763557434 and batch: 1100, loss is 3.754139628410339 and perplexity is 42.69746831415984
At time: 924.3639969825745 and batch: 1150, loss is 3.733729395866394 and perplexity is 41.83483626310177
At time: 925.6318070888519 and batch: 1200, loss is 3.7730125904083254 and perplexity is 43.51094825316422
At time: 926.9034912586212 and batch: 1250, loss is 3.769969005584717 and perplexity is 43.37872031694348
At time: 928.1721823215485 and batch: 1300, loss is 3.769628782272339 and perplexity is 43.36396437533053
At time: 929.4410126209259 and batch: 1350, loss is 3.6277644300460814 and perplexity is 37.62860114733591
At time: 930.7100760936737 and batch: 1400, loss is 3.6526451778411864 and perplexity is 38.576573104835
At time: 931.9770205020905 and batch: 1450, loss is 3.584186234474182 and perplexity is 36.024030673545276
At time: 933.243759393692 and batch: 1500, loss is 3.5766570377349853 and perplexity is 35.753817181044035
At time: 934.5098395347595 and batch: 1550, loss is 3.606603488922119 and perplexity is 36.840710191235225
At time: 935.7752225399017 and batch: 1600, loss is 3.6891898775100707 and perplexity is 40.01241886329851
At time: 937.0414700508118 and batch: 1650, loss is 3.637431468963623 and perplexity is 37.99412220564698
At time: 938.3068351745605 and batch: 1700, loss is 3.6198870515823365 and perplexity is 37.3333508410039
At time: 939.5874307155609 and batch: 1750, loss is 3.6069738721847533 and perplexity is 36.85435790095922
At time: 940.8698756694794 and batch: 1800, loss is 3.5640842866897584 and perplexity is 35.30710740851042
At time: 942.1492788791656 and batch: 1850, loss is 3.594292039871216 and perplexity is 36.389928247984436
At time: 943.4296901226044 and batch: 1900, loss is 3.706399712562561 and perplexity is 40.70698553805256
At time: 944.7165610790253 and batch: 1950, loss is 3.6307375383377076 and perplexity is 37.74064152496666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333044717478198 and perplexity of 76.17586783673788
finished 18 epochs...
Completing Train Step...
At time: 948.6852478981018 and batch: 50, loss is 3.8611748695373533 and perplexity is 47.521149735739016
At time: 949.9531157016754 and batch: 100, loss is 3.8351783895492555 and perplexity is 46.30168666828338
At time: 951.2224361896515 and batch: 150, loss is 3.8006175422668456 and perplexity is 44.72879788944557
At time: 952.4901413917542 and batch: 200, loss is 3.7968811845779418 and perplexity is 44.561986928306375
At time: 953.7736184597015 and batch: 250, loss is 3.7948300647735596 and perplexity is 44.470678628537954
At time: 955.0424747467041 and batch: 300, loss is 3.7901252031326296 and perplexity is 44.26194166282909
At time: 956.3101897239685 and batch: 350, loss is 3.8127062034606936 and perplexity is 45.27279061992948
At time: 957.5778667926788 and batch: 400, loss is 3.772328004837036 and perplexity is 43.481171479334776
At time: 958.8457248210907 and batch: 450, loss is 3.8237336826324464 and perplexity is 45.77479822753464
At time: 960.1148953437805 and batch: 500, loss is 3.8393452644348143 and perplexity is 46.49502252704933
At time: 961.383111000061 and batch: 550, loss is 3.823264708518982 and perplexity is 45.753336065109536
At time: 962.651890039444 and batch: 600, loss is 3.7829644680023193 and perplexity is 43.946125708910074
At time: 963.9181883335114 and batch: 650, loss is 3.797685704231262 and perplexity is 44.59785234786416
At time: 965.181713104248 and batch: 700, loss is 3.8558298778533935 and perplexity is 47.267827192129765
At time: 966.4508285522461 and batch: 750, loss is 3.785072031021118 and perplexity is 44.038842607307465
At time: 967.7202680110931 and batch: 800, loss is 3.7830224657058715 and perplexity is 43.94867455719416
At time: 968.9900255203247 and batch: 850, loss is 3.7737134170532225 and perplexity is 43.54145257291628
At time: 970.2641894817352 and batch: 900, loss is 3.7134667825698853 and perplexity is 40.995683577718054
At time: 971.5378878116608 and batch: 950, loss is 3.8175978565216067 and perplexity is 45.49479193878154
At time: 972.8053789138794 and batch: 1000, loss is 3.788170223236084 and perplexity is 44.17549498498771
At time: 974.0731143951416 and batch: 1050, loss is 3.743229751586914 and perplexity is 42.234176020396596
At time: 975.3483638763428 and batch: 1100, loss is 3.7524782037734985 and perplexity is 42.62658858534013
At time: 976.6308524608612 and batch: 1150, loss is 3.7321941900253295 and perplexity is 41.77066045225494
At time: 977.909196138382 and batch: 1200, loss is 3.7714977169036867 and perplexity is 43.445084570663134
At time: 979.1912288665771 and batch: 1250, loss is 3.7687995529174803 and perplexity is 43.32802060800061
At time: 980.4609253406525 and batch: 1300, loss is 3.7686558389663696 and perplexity is 43.321794214385754
At time: 981.7357306480408 and batch: 1350, loss is 3.6270061779022216 and perplexity is 37.60007999432471
At time: 983.0070118904114 and batch: 1400, loss is 3.652075185775757 and perplexity is 38.554591029653146
At time: 984.2797093391418 and batch: 1450, loss is 3.583867349624634 and perplexity is 36.01254498734681
At time: 985.5474669933319 and batch: 1500, loss is 3.576769776344299 and perplexity is 35.75784824389462
At time: 986.8231024742126 and batch: 1550, loss is 3.607009210586548 and perplexity is 36.85566029807879
At time: 988.0984964370728 and batch: 1600, loss is 3.689704279899597 and perplexity is 40.033006641919805
At time: 989.3731169700623 and batch: 1650, loss is 3.6379241037368772 and perplexity is 38.01284404256006
At time: 990.6432559490204 and batch: 1700, loss is 3.620668301582336 and perplexity is 37.3625289175505
At time: 991.9116854667664 and batch: 1750, loss is 3.607876806259155 and perplexity is 36.88764998451463
At time: 993.1798028945923 and batch: 1800, loss is 3.565096616744995 and perplexity is 35.34286795218611
At time: 994.4483876228333 and batch: 1850, loss is 3.5952726221084594 and perplexity is 36.425629066172405
At time: 995.7181761264801 and batch: 1900, loss is 3.7072200536727906 and perplexity is 40.740392852586204
At time: 996.9864635467529 and batch: 1950, loss is 3.631278748512268 and perplexity is 37.761072672428156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3328860260719475 and perplexity of 76.16378034026481
finished 19 epochs...
Completing Train Step...
At time: 1000.9354629516602 and batch: 50, loss is 3.8597717809677126 and perplexity is 47.454520108293856
At time: 1002.2022578716278 and batch: 100, loss is 3.8332356786727906 and perplexity is 46.211823195630096
At time: 1003.469290971756 and batch: 150, loss is 3.798422451019287 and perplexity is 44.630721779071415
At time: 1004.7373774051666 and batch: 200, loss is 3.794419846534729 and perplexity is 44.4524396863005
At time: 1006.0068943500519 and batch: 250, loss is 3.7921401023864747 and perplexity is 44.35121492417032
At time: 1007.2926735877991 and batch: 300, loss is 3.787434639930725 and perplexity is 44.14301217674117
At time: 1008.5610241889954 and batch: 350, loss is 3.8098172330856324 and perplexity is 45.14218761397571
At time: 1009.829418182373 and batch: 400, loss is 3.7693477869033813 and perplexity is 43.35178101397565
At time: 1011.0986840724945 and batch: 450, loss is 3.820844407081604 and perplexity is 45.64273310031502
At time: 1012.3754570484161 and batch: 500, loss is 3.8364850950241087 and perplexity is 46.362228882554646
At time: 1013.6450719833374 and batch: 550, loss is 3.820338473320007 and perplexity is 45.61964674124471
At time: 1014.9133138656616 and batch: 600, loss is 3.7803355646133423 and perplexity is 43.83074731587535
At time: 1016.1985428333282 and batch: 650, loss is 3.795125665664673 and perplexity is 44.48382614388185
At time: 1017.466873884201 and batch: 700, loss is 3.853435835838318 and perplexity is 47.154801376129974
At time: 1018.7345335483551 and batch: 750, loss is 3.7829213094711305 and perplexity is 43.94422909960076
At time: 1020.0008869171143 and batch: 800, loss is 3.780857629776001 and perplexity is 43.8536357962215
At time: 1021.2701549530029 and batch: 850, loss is 3.771469330787659 and perplexity is 43.44385135095491
At time: 1022.5392000675201 and batch: 900, loss is 3.711479277610779 and perplexity is 40.914285369771136
At time: 1023.8071296215057 and batch: 950, loss is 3.815732135772705 and perplexity is 45.40999049400081
At time: 1025.075520992279 and batch: 1000, loss is 3.7864131498336793 and perplexity is 44.09794354944597
At time: 1026.3437724113464 and batch: 1050, loss is 3.741602826118469 and perplexity is 42.16552002802522
At time: 1027.6123270988464 and batch: 1100, loss is 3.7510893297195436 and perplexity is 42.56742671614801
At time: 1028.881070613861 and batch: 1150, loss is 3.7309028196334837 and perplexity is 41.7167538722711
At time: 1030.1502304077148 and batch: 1200, loss is 3.7701701307296753 and perplexity is 43.3874457457775
At time: 1031.4320275783539 and batch: 1250, loss is 3.767724857330322 and perplexity is 43.281481187786966
At time: 1032.703991651535 and batch: 1300, loss is 3.767685933113098 and perplexity is 43.279796522798776
At time: 1033.9798822402954 and batch: 1350, loss is 3.6261952781677245 and perplexity is 37.56960245822327
At time: 1035.249544620514 and batch: 1400, loss is 3.6513789749145507 and perplexity is 38.527758246350366
At time: 1036.5184230804443 and batch: 1450, loss is 3.583318943977356 and perplexity is 35.99280091867711
At time: 1037.7872195243835 and batch: 1500, loss is 3.5765114927291872 and perplexity is 35.74861377018953
At time: 1039.055867433548 and batch: 1550, loss is 3.6069946479797363 and perplexity is 36.855123587497054
At time: 1040.3251826763153 and batch: 1600, loss is 3.6897853231430053 and perplexity is 40.03625117809354
At time: 1041.5936822891235 and batch: 1650, loss is 3.6379620885849 and perplexity is 38.014287982087666
At time: 1042.8615157604218 and batch: 1700, loss is 3.620947813987732 and perplexity is 37.37297366753051
At time: 1044.1312205791473 and batch: 1750, loss is 3.6082316398620606 and perplexity is 36.90074128474061
At time: 1045.4066951274872 and batch: 1800, loss is 3.56553430557251 and perplexity is 35.35834051645837
At time: 1046.6860144138336 and batch: 1850, loss is 3.5956835412979125 and perplexity is 36.44060013188203
At time: 1047.9550921916962 and batch: 1900, loss is 3.707501244544983 and perplexity is 40.751850289973795
At time: 1049.2338876724243 and batch: 1950, loss is 3.631383261680603 and perplexity is 37.7650194080122
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332837197946947 and perplexity of 76.16006149647069
Finished Training.
Improved accuracyfrom -10000000 to -76.16006149647069
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f98e3f9bb38>
ELAPSED
1081.3424441814423


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -76.16006149647069}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.909600321875081, 'seq_len': 35, 'dropout': 0.7290759996057752, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9215087890625 and batch: 50, loss is 7.67403392791748 and perplexity is 2151.7439415151853
At time: 3.4037024974823 and batch: 100, loss is 7.016540298461914 and perplexity is 1114.9226379269112
At time: 4.883204698562622 and batch: 150, loss is 6.779510555267334 and perplexity is 879.638084502144
At time: 6.362019300460815 and batch: 200, loss is 6.621589412689209 and perplexity is 751.1380171354208
At time: 7.843144416809082 and batch: 250, loss is 6.548184871673584 and perplexity is 697.9761071089678
At time: 9.324657678604126 and batch: 300, loss is 6.496537189483643 and perplexity is 662.8423568789938
At time: 10.804789543151855 and batch: 350, loss is 6.465761070251465 and perplexity is 642.753357802559
At time: 12.284159183502197 and batch: 400, loss is 6.4493638610839845 and perplexity is 632.2999342530808
At time: 13.765417098999023 and batch: 450, loss is 6.353035717010498 and perplexity is 574.2332754657097
At time: 15.245691537857056 and batch: 500, loss is 6.345037221908569 and perplexity is 569.6585931008782
At time: 16.726308345794678 and batch: 550, loss is 6.3015055847167964 and perplexity is 545.3924267946949
At time: 18.206913471221924 and batch: 600, loss is 6.352371273040771 and perplexity is 573.8518563584553
At time: 19.687103033065796 and batch: 650, loss is 6.439589681625367 and perplexity is 626.14982631561
At time: 21.167417526245117 and batch: 700, loss is 6.326449184417725 and perplexity is 559.1675637049183
At time: 22.64855647087097 and batch: 750, loss is 6.27230899810791 and perplexity is 529.6990410094381
At time: 24.130872011184692 and batch: 800, loss is 6.274086980819702 and perplexity is 530.6416744915006
At time: 25.61603331565857 and batch: 850, loss is 6.323078203201294 and perplexity is 557.2857938382281
At time: 27.100317239761353 and batch: 900, loss is 6.30677020072937 and perplexity is 548.2712798767199
At time: 28.583644151687622 and batch: 950, loss is 6.313902473449707 and perplexity is 552.1956784741172
At time: 30.06921696662903 and batch: 1000, loss is 6.303100328445435 and perplexity is 546.262881838855
At time: 31.554323434829712 and batch: 1050, loss is 6.196160516738892 and perplexity is 490.86076671666865
At time: 33.03706765174866 and batch: 1100, loss is 6.277643928527832 and perplexity is 532.5324999695558
At time: 34.521119356155396 and batch: 1150, loss is 6.1837608432769775 and perplexity is 484.8118333958212
At time: 36.00424337387085 and batch: 1200, loss is 6.275712757110596 and perplexity is 531.5050808074319
At time: 37.49031448364258 and batch: 1250, loss is 6.200443382263184 and perplexity is 492.96756571966955
At time: 38.97423768043518 and batch: 1300, loss is 6.21675968170166 and perplexity is 501.0769497978619
At time: 40.45951724052429 and batch: 1350, loss is 6.202201633453369 and perplexity is 493.8350889672185
At time: 41.94228196144104 and batch: 1400, loss is 6.222901992797851 and perplexity is 504.16419200139296
At time: 43.42585062980652 and batch: 1450, loss is 6.217549819946289 and perplexity is 501.4730263163951
At time: 44.91031098365784 and batch: 1500, loss is 6.201265707015991 and perplexity is 493.3731118737593
At time: 46.39493751525879 and batch: 1550, loss is 6.165013513565063 and perplexity is 475.8075727485175
At time: 47.87712335586548 and batch: 1600, loss is 6.154929418563842 and perplexity is 471.03359505989897
At time: 49.36311078071594 and batch: 1650, loss is 6.150174541473389 and perplexity is 468.79920454579747
At time: 50.84486699104309 and batch: 1700, loss is 6.175588808059692 and perplexity is 480.86607840274723
At time: 52.33513426780701 and batch: 1750, loss is 6.1829229354858395 and perplexity is 484.4057759264989
At time: 53.82176971435547 and batch: 1800, loss is 6.200792427062988 and perplexity is 493.1396635181299
At time: 55.303593158721924 and batch: 1850, loss is 6.150909767150879 and perplexity is 469.1440044959232
At time: 56.78728151321411 and batch: 1900, loss is 6.110799808502197 and perplexity is 450.6990439786953
At time: 58.27135515213013 and batch: 1950, loss is 6.053114929199219 and perplexity is 425.4361717823901
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.54203249909157 and perplexity of 255.1961586617733
finished 1 epochs...
Completing Train Step...
At time: 62.23816657066345 and batch: 50, loss is 5.836327447891235 and perplexity is 342.5191086727504
At time: 63.49569249153137 and batch: 100, loss is 5.761763114929199 and perplexity is 317.90834403475776
At time: 64.75429201126099 and batch: 150, loss is 5.6213072681427 and perplexity is 276.2502804797336
At time: 66.01356029510498 and batch: 200, loss is 5.559334564208984 and perplexity is 259.6499984209791
At time: 67.27506375312805 and batch: 250, loss is 5.5513316822052 and perplexity is 257.58034277241137
At time: 68.54160380363464 and batch: 300, loss is 5.526713953018189 and perplexity is 251.3167141339794
At time: 69.82529854774475 and batch: 350, loss is 5.471385269165039 and perplexity is 237.7893669889373
At time: 71.09255909919739 and batch: 400, loss is 5.41759030342102 and perplexity is 225.33547762593867
At time: 72.3593897819519 and batch: 450, loss is 5.3435555267333985 and perplexity is 209.255402353115
At time: 73.6342670917511 and batch: 500, loss is 5.323445777893067 and perplexity is 205.08935821439005
At time: 74.90017461776733 and batch: 550, loss is 5.277405071258545 and perplexity is 195.86097009030286
At time: 76.16431879997253 and batch: 600, loss is 5.263585557937622 and perplexity is 193.17288360908324
At time: 77.42918491363525 and batch: 650, loss is 5.333261375427246 and perplexity is 207.11234498294422
At time: 78.69465327262878 and batch: 700, loss is 5.292855358123779 and perplexity is 198.91057624445918
At time: 79.96008610725403 and batch: 750, loss is 5.222319221496582 and perplexity is 185.36358515147012
At time: 81.23355317115784 and batch: 800, loss is 5.219679794311523 and perplexity is 184.87497657274494
At time: 82.50848603248596 and batch: 850, loss is 5.217363510131836 and perplexity is 184.447249149657
At time: 83.77539563179016 and batch: 900, loss is 5.21675256729126 and perplexity is 184.33459683889038
At time: 85.04343795776367 and batch: 950, loss is 5.243484516143798 and perplexity is 189.32867315720276
At time: 86.3110773563385 and batch: 1000, loss is 5.205003366470337 and perplexity is 182.1814860763173
At time: 87.57871103286743 and batch: 1050, loss is 5.115608253479004 and perplexity is 166.60208646919236
At time: 88.84732818603516 and batch: 1100, loss is 5.183166513442993 and perplexity is 178.246337739608
At time: 90.11548852920532 and batch: 1150, loss is 5.0845998191833495 and perplexity is 161.51529098192015
At time: 91.38165378570557 and batch: 1200, loss is 5.158517103195191 and perplexity is 173.90637908809603
At time: 92.64634490013123 and batch: 1250, loss is 5.112454996109009 and perplexity is 166.07757460722718
At time: 93.91021823883057 and batch: 1300, loss is 5.124995431900024 and perplexity is 168.17337341730777
At time: 95.17780184745789 and batch: 1350, loss is 5.045288677215576 and perplexity is 155.289121159615
At time: 96.44444155693054 and batch: 1400, loss is 5.046471338272095 and perplexity is 155.47288419898777
At time: 97.71170711517334 and batch: 1450, loss is 5.004343032836914 and perplexity is 149.05912403409843
At time: 98.97819471359253 and batch: 1500, loss is 4.9606871509552 and perplexity is 142.6918130324727
At time: 100.24440741539001 and batch: 1550, loss is 4.956821002960205 and perplexity is 142.141210407059
At time: 101.51044535636902 and batch: 1600, loss is 5.003473768234253 and perplexity is 148.92960851365598
At time: 102.7766056060791 and batch: 1650, loss is 4.981635971069336 and perplexity is 145.7125683134435
At time: 104.04307532310486 and batch: 1700, loss is 4.9917855548858645 and perplexity is 147.1990209158644
At time: 105.30764150619507 and batch: 1750, loss is 4.9862817192077635 and perplexity is 146.39108709975463
At time: 106.57240438461304 and batch: 1800, loss is 4.9525570297241215 and perplexity is 141.53641442342214
At time: 107.83799910545349 and batch: 1850, loss is 4.947548542022705 and perplexity is 140.82930328934245
At time: 109.10406041145325 and batch: 1900, loss is 5.023555450439453 and perplexity is 151.95059732827116
At time: 110.37159848213196 and batch: 1950, loss is 4.937495985031128 and perplexity is 139.4207005834785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.730752066678779 and perplexity of 113.38080021421746
finished 2 epochs...
Completing Train Step...
At time: 114.269690990448 and batch: 50, loss is 4.927479114532471 and perplexity is 138.03111276052002
At time: 115.54968619346619 and batch: 100, loss is 4.865762481689453 and perplexity is 129.7698480316735
At time: 116.81686329841614 and batch: 150, loss is 4.803178129196167 and perplexity is 121.89720763320278
At time: 118.0853009223938 and batch: 200, loss is 4.786404790878296 and perplexity is 119.86963663373957
At time: 119.35206151008606 and batch: 250, loss is 4.807019567489624 and perplexity is 122.36636878433931
At time: 120.61921620368958 and batch: 300, loss is 4.831219959259033 and perplexity is 125.36380613922371
At time: 121.88611793518066 and batch: 350, loss is 4.826554965972901 and perplexity is 124.7803468003206
At time: 123.1544098854065 and batch: 400, loss is 4.7849737167358395 and perplexity is 119.69821698265766
At time: 124.42201137542725 and batch: 450, loss is 4.765389938354492 and perplexity is 117.37687811198498
At time: 125.68907523155212 and batch: 500, loss is 4.761769905090332 and perplexity is 116.95273807248563
At time: 126.95644903182983 and batch: 550, loss is 4.727444391250611 and perplexity is 113.00639287765348
At time: 128.22372031211853 and batch: 600, loss is 4.70047399520874 and perplexity is 109.99929923802775
At time: 129.49165797233582 and batch: 650, loss is 4.7621417999267575 and perplexity is 116.99624028050253
At time: 130.75887179374695 and batch: 700, loss is 4.789498949050904 and perplexity is 120.2411066467002
At time: 132.02701139450073 and batch: 750, loss is 4.73236629486084 and perplexity is 113.56397049676956
At time: 133.32517409324646 and batch: 800, loss is 4.737379589080811 and perplexity is 114.13472958987668
At time: 134.59147357940674 and batch: 850, loss is 4.728164882659912 and perplexity is 113.08784235121752
At time: 135.85814213752747 and batch: 900, loss is 4.710834369659424 and perplexity is 111.14485712503391
At time: 137.13228797912598 and batch: 950, loss is 4.766915674209595 and perplexity is 117.55610091203927
At time: 138.4020493030548 and batch: 1000, loss is 4.735915660858154 and perplexity is 113.96776677864854
At time: 139.66872239112854 and batch: 1050, loss is 4.675619955062866 and perplexity is 107.29906707628841
At time: 140.935382604599 and batch: 1100, loss is 4.7213770866394045 and perplexity is 112.32282447488149
At time: 142.20264291763306 and batch: 1150, loss is 4.658367166519165 and perplexity is 105.46373676888105
At time: 143.46976518630981 and batch: 1200, loss is 4.729448385238648 and perplexity is 113.23308407762516
At time: 144.73589897155762 and batch: 1250, loss is 4.709702882766724 and perplexity is 111.01916929648061
At time: 146.0026466846466 and batch: 1300, loss is 4.710970125198364 and perplexity is 111.15994667923543
At time: 147.26952624320984 and batch: 1350, loss is 4.600094814300537 and perplexity is 99.49374862491955
At time: 148.53644609451294 and batch: 1400, loss is 4.607597122192383 and perplexity is 100.24298835978576
At time: 149.81170630455017 and batch: 1450, loss is 4.567668952941895 and perplexity is 96.31932300583405
At time: 151.08029556274414 and batch: 1500, loss is 4.546233644485474 and perplexity is 94.2766593810314
At time: 152.34743762016296 and batch: 1550, loss is 4.5505961990356445 and perplexity is 94.68884488754553
At time: 153.61299419403076 and batch: 1600, loss is 4.621985301971436 and perplexity is 101.6957285795537
At time: 154.88063859939575 and batch: 1650, loss is 4.593665590286255 and perplexity is 98.85613291043582
At time: 156.1467046737671 and batch: 1700, loss is 4.6059633731842045 and perplexity is 100.07935018522653
At time: 157.41441369056702 and batch: 1750, loss is 4.593486671447754 and perplexity is 98.83844726815121
At time: 158.68041515350342 and batch: 1800, loss is 4.560571250915527 and perplexity is 95.63809757916277
At time: 159.94504117965698 and batch: 1850, loss is 4.584237775802612 and perplexity is 97.92851520344243
At time: 161.21268343925476 and batch: 1900, loss is 4.681887321472168 and perplexity is 107.97366140177544
At time: 162.4791920185089 and batch: 1950, loss is 4.604922943115234 and perplexity is 99.97527876891431
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.557722508630087 and perplexity of 95.36603698573686
finished 3 epochs...
Completing Train Step...
At time: 166.37739038467407 and batch: 50, loss is 4.591590690612793 and perplexity is 98.65122900357775
At time: 167.65426087379456 and batch: 100, loss is 4.530191879272461 and perplexity is 92.77636123501232
At time: 168.92132329940796 and batch: 150, loss is 4.478600482940674 and perplexity is 88.11127311605362
At time: 170.188472032547 and batch: 200, loss is 4.47326325416565 and perplexity is 87.64225583341178
At time: 171.4560992717743 and batch: 250, loss is 4.4893333435058596 and perplexity is 89.0620522877577
At time: 172.7250680923462 and batch: 300, loss is 4.513519229888916 and perplexity is 91.24235698525506
At time: 173.99283003807068 and batch: 350, loss is 4.518251123428345 and perplexity is 91.6751292133409
At time: 175.27018070220947 and batch: 400, loss is 4.470384683609009 and perplexity is 87.39033417733842
At time: 176.53787207603455 and batch: 450, loss is 4.476669206619262 and perplexity is 87.94127011486069
At time: 177.80501914024353 and batch: 500, loss is 4.4741435241699214 and perplexity is 87.71943864820308
At time: 179.0732319355011 and batch: 550, loss is 4.448298625946045 and perplexity is 85.48138440213147
At time: 180.34141182899475 and batch: 600, loss is 4.424012193679809 and perplexity is 83.43035347412167
At time: 181.60860109329224 and batch: 650, loss is 4.483709478378296 and perplexity is 88.56258510217349
At time: 182.8763530254364 and batch: 700, loss is 4.522688884735107 and perplexity is 92.08286560379088
At time: 184.14357709884644 and batch: 750, loss is 4.4691204071044925 and perplexity is 87.27991844383233
At time: 185.41132950782776 and batch: 800, loss is 4.475531215667725 and perplexity is 87.84125066661075
At time: 186.67875576019287 and batch: 850, loss is 4.463199157714843 and perplexity is 86.76463933360084
At time: 187.96456837654114 and batch: 900, loss is 4.440668439865112 and perplexity is 84.83162756785035
At time: 189.24255776405334 and batch: 950, loss is 4.510471448898316 and perplexity is 90.96469360761371
At time: 190.5221939086914 and batch: 1000, loss is 4.484116640090942 and perplexity is 88.59865173797839
At time: 191.79710865020752 and batch: 1050, loss is 4.432461500167847 and perplexity is 84.13826858535498
At time: 193.0741970539093 and batch: 1100, loss is 4.465436506271362 and perplexity is 86.95897939633237
At time: 194.33962750434875 and batch: 1150, loss is 4.417580156326294 and perplexity is 82.89544843289512
At time: 195.6057288646698 and batch: 1200, loss is 4.483844041824341 and perplexity is 88.574503190667
At time: 196.89204025268555 and batch: 1250, loss is 4.476789312362671 and perplexity is 87.95183300080306
At time: 198.15921807289124 and batch: 1300, loss is 4.467915563583374 and perplexity is 87.1748231239926
At time: 199.42645049095154 and batch: 1350, loss is 4.351480860710144 and perplexity is 77.59328273197663
At time: 200.69421768188477 and batch: 1400, loss is 4.364607820510864 and perplexity is 78.61856130782202
At time: 201.9631667137146 and batch: 1450, loss is 4.330900077819824 and perplexity is 76.01267310905759
At time: 203.23939633369446 and batch: 1500, loss is 4.311668081283569 and perplexity is 74.56476534944605
At time: 204.5136251449585 and batch: 1550, loss is 4.323128700256348 and perplexity is 75.42423935864194
At time: 205.78067183494568 and batch: 1600, loss is 4.404434013366699 and perplexity is 81.8128247714461
At time: 207.0473325252533 and batch: 1650, loss is 4.369326801300049 and perplexity is 78.9904375365945
At time: 208.31542325019836 and batch: 1700, loss is 4.379984560012818 and perplexity is 79.83680071638847
At time: 209.595712184906 and batch: 1750, loss is 4.373761749267578 and perplexity is 79.34153398878094
At time: 210.8704960346222 and batch: 1800, loss is 4.334176502227783 and perplexity is 76.26213132888618
At time: 212.13880491256714 and batch: 1850, loss is 4.367449531555176 and perplexity is 78.84229027776382
At time: 213.40362000465393 and batch: 1900, loss is 4.468650026321411 and perplexity is 87.2388733016273
At time: 214.67244815826416 and batch: 1950, loss is 4.384754428863525 and perplexity is 80.21852144043028
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487299009811046 and perplexity of 88.8810545212089
finished 4 epochs...
Completing Train Step...
At time: 218.55049800872803 and batch: 50, loss is 4.37808602809906 and perplexity is 79.68537179414132
At time: 219.8350648880005 and batch: 100, loss is 4.324378595352173 and perplexity is 75.51857068537335
At time: 221.1045536994934 and batch: 150, loss is 4.274949140548706 and perplexity is 71.87648361817887
At time: 222.3725209236145 and batch: 200, loss is 4.282953538894653 and perplexity is 72.45412035793238
At time: 223.6392366886139 and batch: 250, loss is 4.288576335906982 and perplexity is 72.86266266828589
At time: 224.90533351898193 and batch: 300, loss is 4.310232110023499 and perplexity is 74.45776932938082
At time: 226.171382188797 and batch: 350, loss is 4.31664659500122 and perplexity is 74.93691265817493
At time: 227.46524047851562 and batch: 400, loss is 4.266290235519409 and perplexity is 71.25679874075918
At time: 228.7318732738495 and batch: 450, loss is 4.281659774780273 and perplexity is 72.36044242871257
At time: 229.99888825416565 and batch: 500, loss is 4.285478773117066 and perplexity is 72.63731518979456
At time: 231.26558017730713 and batch: 550, loss is 4.25912353515625 and perplexity is 70.74794818303076
At time: 232.5331482887268 and batch: 600, loss is 4.242916560173034 and perplexity is 69.61057950513727
At time: 233.80143404006958 and batch: 650, loss is 4.300475902557373 and perplexity is 73.7348759671036
At time: 235.06789660453796 and batch: 700, loss is 4.3400747680664065 and perplexity is 76.71327482710375
At time: 236.336190700531 and batch: 750, loss is 4.292494611740112 and perplexity is 73.14871873586274
At time: 237.6038031578064 and batch: 800, loss is 4.293946723937989 and perplexity is 73.25501604172686
At time: 238.8703932762146 and batch: 850, loss is 4.279935216903686 and perplexity is 72.23576019953047
At time: 240.13837051391602 and batch: 900, loss is 4.254776759147644 and perplexity is 70.44109010403828
At time: 241.40601515769958 and batch: 950, loss is 4.334245128631592 and perplexity is 76.2673651042916
At time: 242.6732132434845 and batch: 1000, loss is 4.3073696041107175 and perplexity is 74.24493828481177
At time: 243.94060277938843 and batch: 1050, loss is 4.264121971130371 and perplexity is 71.1024625428796
At time: 245.21126699447632 and batch: 1100, loss is 4.29519606590271 and perplexity is 73.34659380145159
At time: 246.47883796691895 and batch: 1150, loss is 4.249910521507263 and perplexity is 70.09913970069601
At time: 247.74670433998108 and batch: 1200, loss is 4.316731181144714 and perplexity is 74.94325155070949
At time: 249.01609539985657 and batch: 1250, loss is 4.310812339782715 and perplexity is 74.50098447909613
At time: 250.2841432094574 and batch: 1300, loss is 4.2990876483917235 and perplexity is 73.63258423827641
At time: 251.55358791351318 and batch: 1350, loss is 4.176081280708313 and perplexity is 65.11020401987047
At time: 252.82255005836487 and batch: 1400, loss is 4.2010876131057735 and perplexity is 66.75889942455031
At time: 254.0906057357788 and batch: 1450, loss is 4.158378801345825 and perplexity is 63.967734087357286
At time: 255.36182594299316 and batch: 1500, loss is 4.1461781930923465 and perplexity is 63.19203047309995
At time: 256.63032269477844 and batch: 1550, loss is 4.1617434692382815 and perplexity is 64.18332676387897
At time: 257.89849281311035 and batch: 1600, loss is 4.248905692100525 and perplexity is 70.02873740081199
At time: 259.1672258377075 and batch: 1650, loss is 4.210179600715637 and perplexity is 67.3686381792747
At time: 260.4357850551605 and batch: 1700, loss is 4.221600089073181 and perplexity is 68.14243106326825
At time: 261.70411586761475 and batch: 1750, loss is 4.211978974342347 and perplexity is 67.48996865677603
At time: 262.97203040122986 and batch: 1800, loss is 4.177773504257202 and perplexity is 65.220478318453
At time: 264.2390887737274 and batch: 1850, loss is 4.213823199272156 and perplexity is 67.61455018235233
At time: 265.5063519477844 and batch: 1900, loss is 4.311437377929687 and perplexity is 74.54756499216485
At time: 266.7710950374603 and batch: 1950, loss is 4.231251893043518 and perplexity is 68.80331266931906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465720952943314 and perplexity of 86.9837181068731
finished 5 epochs...
Completing Train Step...
At time: 270.7022967338562 and batch: 50, loss is 4.225841650962829 and perplexity is 68.43207523953879
At time: 271.9708547592163 and batch: 100, loss is 4.174110684394837 and perplexity is 64.98202442845378
At time: 273.24126172065735 and batch: 150, loss is 4.1299776935577395 and perplexity is 62.17653598198203
At time: 274.5093832015991 and batch: 200, loss is 4.14195209980011 and perplexity is 62.92553856345635
At time: 275.77844762802124 and batch: 250, loss is 4.140588541030883 and perplexity is 62.83979436545167
At time: 277.0484983921051 and batch: 300, loss is 4.158989763259887 and perplexity is 64.00682787780597
At time: 278.31749653816223 and batch: 350, loss is 4.170529379844665 and perplexity is 64.74972023301432
At time: 279.58747124671936 and batch: 400, loss is 4.126652522087097 and perplexity is 61.97013169339756
At time: 280.8560779094696 and batch: 450, loss is 4.144218249320984 and perplexity is 63.06829893960695
At time: 282.1252164840698 and batch: 500, loss is 4.148228240013123 and perplexity is 63.32170997970861
At time: 283.39408707618713 and batch: 550, loss is 4.121470460891723 and perplexity is 61.64982930873276
At time: 284.662220954895 and batch: 600, loss is 4.109831409454346 and perplexity is 60.93644339533997
At time: 285.9286422729492 and batch: 650, loss is 4.166807327270508 and perplexity is 64.50916632500424
At time: 287.1971170902252 and batch: 700, loss is 4.204006824493408 and perplexity is 66.95406749380305
At time: 288.46736216545105 and batch: 750, loss is 4.159996757507324 and perplexity is 64.07131484883068
At time: 289.7366428375244 and batch: 800, loss is 4.159888682365417 and perplexity is 64.0643907065568
At time: 291.03588700294495 and batch: 850, loss is 4.145980715751648 and perplexity is 63.179552711046966
At time: 292.3063385486603 and batch: 900, loss is 4.1154245042800905 and perplexity is 61.278221609596
At time: 293.575266122818 and batch: 950, loss is 4.202462930679321 and perplexity is 66.85077727825075
At time: 294.8445553779602 and batch: 1000, loss is 4.180077342987061 and perplexity is 65.37090899986154
At time: 296.1141541004181 and batch: 1050, loss is 4.134424409866333 and perplexity is 62.45363302792848
At time: 297.3816499710083 and batch: 1100, loss is 4.1656764698028566 and perplexity is 64.43625688539572
At time: 298.6487317085266 and batch: 1150, loss is 4.126363549232483 and perplexity is 61.95222659470965
At time: 299.91742300987244 and batch: 1200, loss is 4.189628376960754 and perplexity is 65.99825992860433
At time: 301.1863522529602 and batch: 1250, loss is 4.181007719039917 and perplexity is 65.43175682944103
At time: 302.4547264575958 and batch: 1300, loss is 4.1680569124221805 and perplexity is 64.58982640671532
At time: 303.7248673439026 and batch: 1350, loss is 4.045455121994019 and perplexity is 57.137184506803145
At time: 304.9930181503296 and batch: 1400, loss is 4.075218420028687 and perplexity is 58.86333611590698
At time: 306.2621202468872 and batch: 1450, loss is 4.030753445625305 and perplexity is 56.30331675769983
At time: 307.53610825538635 and batch: 1500, loss is 4.0208902215957645 and perplexity is 55.750714232071246
At time: 308.80844616889954 and batch: 1550, loss is 4.035033178329468 and perplexity is 56.54479626908134
At time: 310.0787160396576 and batch: 1600, loss is 4.12414764881134 and perplexity is 61.815098616790365
At time: 311.3472328186035 and batch: 1650, loss is 4.092389736175537 and perplexity is 59.88282500288821
At time: 312.6237041950226 and batch: 1700, loss is 4.103341603279114 and perplexity is 60.542258165076845
At time: 313.8929023742676 and batch: 1750, loss is 4.090992164611817 and perplexity is 59.799192924029086
At time: 315.1698069572449 and batch: 1800, loss is 4.054511394500732 and perplexity is 57.65698459291898
At time: 316.4384443759918 and batch: 1850, loss is 4.095196495056152 and perplexity is 60.051137749914254
At time: 317.7071042060852 and batch: 1900, loss is 4.191666135787964 and perplexity is 66.13288558607961
At time: 318.97592639923096 and batch: 1950, loss is 4.113705630302429 and perplexity is 61.17298254133282
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.458307594476744 and perplexity of 86.34126094873591
finished 6 epochs...
Completing Train Step...
At time: 322.8578336238861 and batch: 50, loss is 4.103972239494324 and perplexity is 60.5804503470471
At time: 324.1254243850708 and batch: 100, loss is 4.061812982559204 and perplexity is 58.0795128294811
At time: 325.3937542438507 and batch: 150, loss is 4.018864693641663 and perplexity is 55.6379038907525
At time: 326.6626560688019 and batch: 200, loss is 4.025003404617309 and perplexity is 55.98049937349684
At time: 327.9324915409088 and batch: 250, loss is 4.023389163017273 and perplexity is 55.890206219706855
At time: 329.20864057540894 and batch: 300, loss is 4.039238214492798 and perplexity is 56.78306980555728
At time: 330.4824104309082 and batch: 350, loss is 4.049021043777466 and perplexity is 57.34129494231936
At time: 331.751305103302 and batch: 400, loss is 4.011356854438782 and perplexity is 55.22174762672289
At time: 333.0200021266937 and batch: 450, loss is 4.036662559509278 and perplexity is 56.63700439663204
At time: 334.28827023506165 and batch: 500, loss is 4.037006812095642 and perplexity is 56.656505188285905
At time: 335.5577952861786 and batch: 550, loss is 4.011930499076843 and perplexity is 55.25343437375067
At time: 336.8275535106659 and batch: 600, loss is 4.003656039237976 and perplexity is 54.79812835352649
At time: 338.09693574905396 and batch: 650, loss is 4.059883418083191 and perplexity is 57.967552716607116
At time: 339.36679697036743 and batch: 700, loss is 4.091890439987183 and perplexity is 59.85293319966908
At time: 340.6356749534607 and batch: 750, loss is 4.056150231361389 and perplexity is 57.75155245402675
At time: 341.90483951568604 and batch: 800, loss is 4.055977535247803 and perplexity is 57.74157984650442
At time: 343.1870050430298 and batch: 850, loss is 4.036431736946106 and perplexity is 56.62393280677382
At time: 344.46047258377075 and batch: 900, loss is 4.0021640586853025 and perplexity is 54.71643157185965
At time: 345.74349761009216 and batch: 950, loss is 4.100025310516357 and perplexity is 60.34181486052602
At time: 347.02286028862 and batch: 1000, loss is 4.0762908124923705 and perplexity is 58.92649457321895
At time: 348.29117488861084 and batch: 1050, loss is 4.032680444717407 and perplexity is 56.411917801424636
At time: 349.55959939956665 and batch: 1100, loss is 4.0586761951446535 and perplexity is 57.89761518086927
At time: 350.83496952056885 and batch: 1150, loss is 4.023504920005799 and perplexity is 55.8966762761368
At time: 352.1039824485779 and batch: 1200, loss is 4.088381996154785 and perplexity is 59.64331048511736
At time: 353.37305641174316 and batch: 1250, loss is 4.079077596664429 and perplexity is 59.09093902478265
At time: 354.6418797969818 and batch: 1300, loss is 4.068405513763428 and perplexity is 58.463668718648286
At time: 355.91180658340454 and batch: 1350, loss is 3.9424174070358275 and perplexity is 51.543051351692185
At time: 357.1819317340851 and batch: 1400, loss is 3.9743935108184814 and perplexity is 53.217831077410125
At time: 358.45141673088074 and batch: 1450, loss is 3.9291989946365358 and perplexity is 50.86621723389365
At time: 359.7211585044861 and batch: 1500, loss is 3.921622185707092 and perplexity is 50.48227000913221
At time: 360.9904456138611 and batch: 1550, loss is 3.9357751703262327 and perplexity is 51.20182471249007
At time: 362.25969195365906 and batch: 1600, loss is 4.028109316825867 and perplexity is 56.15464018298503
At time: 363.52771401405334 and batch: 1650, loss is 3.9934471654891968 and perplexity is 54.24154704758898
At time: 364.80724024772644 and batch: 1700, loss is 4.0049335527420045 and perplexity is 54.86817843793096
At time: 366.08802485466003 and batch: 1750, loss is 3.996367573738098 and perplexity is 54.40018604158347
At time: 367.36375403404236 and batch: 1800, loss is 3.9550518083572386 and perplexity is 52.19839818764046
At time: 368.63221526145935 and batch: 1850, loss is 3.995010929107666 and perplexity is 54.3264343600186
At time: 369.9087760448456 and batch: 1900, loss is 4.093664536476135 and perplexity is 59.95921232514837
At time: 371.17648696899414 and batch: 1950, loss is 4.017996897697449 and perplexity is 55.58964248696545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.45809695221657 and perplexity of 86.32307574573677
finished 7 epochs...
Completing Train Step...
At time: 375.09223198890686 and batch: 50, loss is 4.007423729896545 and perplexity is 55.00498018198513
At time: 376.36131596565247 and batch: 100, loss is 3.9675259685516355 and perplexity is 52.853607465154894
At time: 377.63143253326416 and batch: 150, loss is 3.9248158979415892 and perplexity is 50.64375358125726
At time: 378.9009368419647 and batch: 200, loss is 3.9274470376968384 and perplexity is 50.77717982923801
At time: 380.17479515075684 and batch: 250, loss is 3.928650426864624 and perplexity is 50.838321318539684
At time: 381.44912600517273 and batch: 300, loss is 3.9404474878311158 and perplexity is 51.441615647838034
At time: 382.71803092956543 and batch: 350, loss is 3.951000757217407 and perplexity is 51.98736754373249
At time: 383.9876205921173 and batch: 400, loss is 3.9170743227005005 and perplexity is 50.25320483420038
At time: 385.26963543891907 and batch: 450, loss is 3.9461597442626952 and perplexity is 51.736304214700134
At time: 386.54050850868225 and batch: 500, loss is 3.950628399848938 and perplexity is 51.96801326793749
At time: 387.8106117248535 and batch: 550, loss is 3.9205620193481447 and perplexity is 50.42877876456436
At time: 389.0804624557495 and batch: 600, loss is 3.91175847530365 and perplexity is 49.986775243025626
At time: 390.35190510749817 and batch: 650, loss is 3.9728548908233643 and perplexity is 53.13601201877866
At time: 391.6203463077545 and batch: 700, loss is 3.9991065406799318 and perplexity is 54.549390592670505
At time: 392.88827109336853 and batch: 750, loss is 3.973871054649353 and perplexity is 53.190034355172884
At time: 394.15817952156067 and batch: 800, loss is 3.9713287925720215 and perplexity is 53.05498308853405
At time: 395.42884063720703 and batch: 850, loss is 3.948508858680725 and perplexity is 51.85798157393119
At time: 396.69794273376465 and batch: 900, loss is 3.9168204355239866 and perplexity is 50.24044780940528
At time: 397.96749901771545 and batch: 950, loss is 4.015062937736511 and perplexity is 55.42678372902902
At time: 399.23785042762756 and batch: 1000, loss is 3.9916712713241576 and perplexity is 54.145305283571986
At time: 400.505907535553 and batch: 1050, loss is 3.946808624267578 and perplexity is 51.769885762050606
At time: 401.775146484375 and batch: 1100, loss is 3.9762476444244386 and perplexity is 53.31659557944357
At time: 403.04988646507263 and batch: 1150, loss is 3.9403122568130495 and perplexity is 51.43465961612923
At time: 404.3175160884857 and batch: 1200, loss is 4.0028366851806645 and perplexity is 54.75324767382131
At time: 405.58558440208435 and batch: 1250, loss is 3.993659644126892 and perplexity is 54.25307344212507
At time: 406.85382652282715 and batch: 1300, loss is 3.9807841539382935 and perplexity is 53.55901627869061
At time: 408.123423576355 and batch: 1350, loss is 3.8575783252716063 and perplexity is 47.35054479516533
At time: 409.39252829551697 and batch: 1400, loss is 3.8921158504486084 and perplexity is 49.014484204875984
At time: 410.66133642196655 and batch: 1450, loss is 3.845034861564636 and perplexity is 46.7603144602229
At time: 411.9310688972473 and batch: 1500, loss is 3.8364767980575563 and perplexity is 46.361844218288084
At time: 413.2010426521301 and batch: 1550, loss is 3.8551463413238527 and perplexity is 47.23552894534522
At time: 414.4698905944824 and batch: 1600, loss is 3.946468515396118 and perplexity is 51.75228135850508
At time: 415.73929238319397 and batch: 1650, loss is 3.915933704376221 and perplexity is 50.1959177854524
At time: 417.00849962234497 and batch: 1700, loss is 3.9253756332397463 and perplexity is 50.67210861268352
At time: 418.2790298461914 and batch: 1750, loss is 3.9141909074783325 and perplexity is 50.10851268244371
At time: 419.5476071834564 and batch: 1800, loss is 3.8735640001297 and perplexity is 48.113557597496836
At time: 420.81656098365784 and batch: 1850, loss is 3.9106193733215333 and perplexity is 49.929867626209614
At time: 422.0983827114105 and batch: 1900, loss is 4.01217442035675 and perplexity is 55.26691350603913
At time: 423.3743906021118 and batch: 1950, loss is 3.937016429901123 and perplexity is 51.265418927965634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.460776537518169 and perplexity of 86.55469597518552
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 427.2783672809601 and batch: 50, loss is 3.962070860862732 and perplexity is 52.566070330750414
At time: 428.5592999458313 and batch: 100, loss is 3.9516577339172363 and perplexity is 52.02153325470332
At time: 429.8261470794678 and batch: 150, loss is 3.919961895942688 and perplexity is 50.398524353217326
At time: 431.0961468219757 and batch: 200, loss is 3.916701440811157 and perplexity is 50.234469817427545
At time: 432.366103887558 and batch: 250, loss is 3.914385004043579 and perplexity is 50.118239516586996
At time: 433.634165763855 and batch: 300, loss is 3.9246775341033935 and perplexity is 50.63674680188473
At time: 434.9029176235199 and batch: 350, loss is 3.9399254751205444 and perplexity is 51.41476947824804
At time: 436.1757926940918 and batch: 400, loss is 3.89468918800354 and perplexity is 49.14077744569224
At time: 437.44407629966736 and batch: 450, loss is 3.9108319759368895 and perplexity is 49.94048397514312
At time: 438.7131996154785 and batch: 500, loss is 3.911418070793152 and perplexity is 49.969762415053616
At time: 439.9819257259369 and batch: 550, loss is 3.8790990686416627 and perplexity is 48.380607824002404
At time: 441.2501480579376 and batch: 600, loss is 3.861258096694946 and perplexity is 47.525104950545426
At time: 442.5187232494354 and batch: 650, loss is 3.9136767578125 and perplexity is 50.08275602934736
At time: 443.78768825531006 and batch: 700, loss is 3.943689775466919 and perplexity is 51.608674842850185
At time: 445.05589747428894 and batch: 750, loss is 3.90843722820282 and perplexity is 49.82103219982561
At time: 446.32505774497986 and batch: 800, loss is 3.8974296712875365 and perplexity is 49.27563162325543
At time: 447.59364557266235 and batch: 850, loss is 3.8642895936965944 and perplexity is 47.66939576178446
At time: 448.8796122074127 and batch: 900, loss is 3.831370372772217 and perplexity is 46.125704353109484
At time: 450.1484580039978 and batch: 950, loss is 3.925060887336731 and perplexity is 50.65616228375303
At time: 451.41630125045776 and batch: 1000, loss is 3.8982896995544434 and perplexity is 49.31802828787289
At time: 452.684268951416 and batch: 1050, loss is 3.8468106985092163 and perplexity is 46.843426929436305
At time: 453.95241141319275 and batch: 1100, loss is 3.870574231147766 and perplexity is 47.96992399801329
At time: 455.22240686416626 and batch: 1150, loss is 3.8383954191207885 and perplexity is 46.450880415184315
At time: 456.492041349411 and batch: 1200, loss is 3.8724885988235473 and perplexity is 48.061844026217734
At time: 457.7608335018158 and batch: 1250, loss is 3.8676307153701783 and perplexity is 47.82893137867522
At time: 459.0299208164215 and batch: 1300, loss is 3.849092526435852 and perplexity is 46.950437612734625
At time: 460.2995467185974 and batch: 1350, loss is 3.717767176628113 and perplexity is 41.172360790326366
At time: 461.56806564331055 and batch: 1400, loss is 3.7443273782730104 and perplexity is 42.28055882990986
At time: 462.83789253234863 and batch: 1450, loss is 3.6915100955963136 and perplexity is 40.1053641862322
At time: 464.10456705093384 and batch: 1500, loss is 3.6781562852859495 and perplexity is 39.573364775743784
At time: 465.3706817626953 and batch: 1550, loss is 3.6994357776641844 and perplexity is 40.424489524449086
At time: 466.6399781703949 and batch: 1600, loss is 3.7788365507125854 and perplexity is 43.76509363655114
At time: 467.90968561172485 and batch: 1650, loss is 3.7358764028549194 and perplexity is 41.92475243971215
At time: 469.17849802970886 and batch: 1700, loss is 3.736083641052246 and perplexity is 41.933441750178545
At time: 470.44823455810547 and batch: 1750, loss is 3.715094962120056 and perplexity is 41.062486280003796
At time: 471.7169361114502 and batch: 1800, loss is 3.675306615829468 and perplexity is 39.460754294382276
At time: 472.9867310523987 and batch: 1850, loss is 3.6908705902099608 and perplexity is 40.079724788953605
At time: 474.25488543510437 and batch: 1900, loss is 3.7918846797943115 and perplexity is 44.3398880685178
At time: 475.52328968048096 and batch: 1950, loss is 3.715055532455444 and perplexity is 41.06086723186112
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.403213004178779 and perplexity of 81.71299152177119
finished 9 epochs...
Completing Train Step...
At time: 479.421777009964 and batch: 50, loss is 3.8954059219360353 and perplexity is 49.17601093336655
At time: 480.7159938812256 and batch: 100, loss is 3.8587234020233154 and perplexity is 47.40479585807865
At time: 481.9955883026123 and batch: 150, loss is 3.818650450706482 and perplexity is 45.54270470414374
At time: 483.27838611602783 and batch: 200, loss is 3.814641861915588 and perplexity is 45.36050814806897
At time: 484.5574462413788 and batch: 250, loss is 3.8092915773391725 and perplexity is 45.118464599264406
At time: 485.82805132865906 and batch: 300, loss is 3.820147271156311 and perplexity is 45.61092499991521
At time: 487.0967307090759 and batch: 350, loss is 3.8409349012374876 and perplexity is 46.56899150232584
At time: 488.36566972732544 and batch: 400, loss is 3.794963617324829 and perplexity is 44.476618197738965
At time: 489.6346950531006 and batch: 450, loss is 3.817751159667969 and perplexity is 45.501766968162165
At time: 490.90254616737366 and batch: 500, loss is 3.81914430141449 and perplexity is 45.56520155569229
At time: 492.17144680023193 and batch: 550, loss is 3.7918136072158815 and perplexity is 44.3367368303301
At time: 493.43901324272156 and batch: 600, loss is 3.771859369277954 and perplexity is 43.4607994301352
At time: 494.70950150489807 and batch: 650, loss is 3.8285090255737306 and perplexity is 45.99391134088282
At time: 495.98069953918457 and batch: 700, loss is 3.859529037475586 and perplexity is 47.44300223036709
At time: 497.24791526794434 and batch: 750, loss is 3.827111701965332 and perplexity is 45.92968784367781
At time: 498.5199887752533 and batch: 800, loss is 3.8178073930740357 and perplexity is 45.50432575944494
At time: 499.79389786720276 and batch: 850, loss is 3.7850099420547485 and perplexity is 44.03610836597385
At time: 501.06225848197937 and batch: 900, loss is 3.753200316429138 and perplexity is 42.65738090084666
At time: 502.3299825191498 and batch: 950, loss is 3.852918953895569 and perplexity is 47.13043420880165
At time: 503.6039288043976 and batch: 1000, loss is 3.8275004959106447 and perplexity is 45.947548500054076
At time: 504.8757264614105 and batch: 1050, loss is 3.778628640174866 and perplexity is 43.755995358246565
At time: 506.1435499191284 and batch: 1100, loss is 3.8041012620925905 and perplexity is 44.88489222603498
At time: 507.4137282371521 and batch: 1150, loss is 3.7756847143173218 and perplexity is 43.627370376190306
At time: 508.6831886768341 and batch: 1200, loss is 3.8110476970672607 and perplexity is 45.197767637482585
At time: 509.95809841156006 and batch: 1250, loss is 3.8105363273620605 and perplexity is 45.17466077694787
At time: 511.22727847099304 and batch: 1300, loss is 3.7932254886627197 and perplexity is 44.39937925790884
At time: 512.4959173202515 and batch: 1350, loss is 3.6624212789535524 and perplexity is 38.95555102902301
At time: 513.7823512554169 and batch: 1400, loss is 3.6925348615646363 and perplexity is 40.14648386402219
At time: 515.0629913806915 and batch: 1450, loss is 3.642211422920227 and perplexity is 38.176167096897935
At time: 516.3350994586945 and batch: 1500, loss is 3.6303686904907226 and perplexity is 37.726723537563984
At time: 517.6073958873749 and batch: 1550, loss is 3.6551397371292116 and perplexity is 38.672924781093336
At time: 518.8764274120331 and batch: 1600, loss is 3.7390569400787355 and perplexity is 42.05830795199982
At time: 520.1450653076172 and batch: 1650, loss is 3.696912841796875 and perplexity is 40.32262967687152
At time: 521.4137830734253 and batch: 1700, loss is 3.7023418045043943 and perplexity is 40.54213503371977
At time: 522.6831772327423 and batch: 1750, loss is 3.683922824859619 and perplexity is 39.80222538246809
At time: 523.9501156806946 and batch: 1800, loss is 3.645600509643555 and perplexity is 38.30576892982969
At time: 525.2179095745087 and batch: 1850, loss is 3.6679704904556276 and perplexity is 39.17232452558108
At time: 526.4931399822235 and batch: 1900, loss is 3.767521343231201 and perplexity is 43.27267369238955
At time: 527.7653558254242 and batch: 1950, loss is 3.694653697013855 and perplexity is 40.23163783896716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4055519281431685 and perplexity of 81.90433567832997
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 531.6961419582367 and batch: 50, loss is 3.8716428232192994 and perplexity is 48.021211676392454
At time: 532.9816431999207 and batch: 100, loss is 3.8714602899551394 and perplexity is 48.01244700782236
At time: 534.2515468597412 and batch: 150, loss is 3.8459133100509644 and perplexity is 46.80140903477149
At time: 535.5219893455505 and batch: 200, loss is 3.851049737930298 and perplexity is 47.04241953357316
At time: 536.7982332706451 and batch: 250, loss is 3.8509805631637573 and perplexity is 47.0391654977343
At time: 538.0735719203949 and batch: 300, loss is 3.845773148536682 and perplexity is 46.794849738101846
At time: 539.3413691520691 and batch: 350, loss is 3.8833773136138916 and perplexity is 48.58803531259867
At time: 540.6144599914551 and batch: 400, loss is 3.841695704460144 and perplexity is 46.60443482212302
At time: 541.8803586959839 and batch: 450, loss is 3.859865140914917 and perplexity is 47.45895066660091
At time: 543.1457149982452 and batch: 500, loss is 3.8535759019851685 and perplexity is 47.16140663003967
At time: 544.4390404224396 and batch: 550, loss is 3.838460545539856 and perplexity is 46.45390569319998
At time: 545.7049884796143 and batch: 600, loss is 3.815712294578552 and perplexity is 45.40908951450121
At time: 546.9707775115967 and batch: 650, loss is 3.866559634208679 and perplexity is 47.77773013653873
At time: 548.2358877658844 and batch: 700, loss is 3.89983090877533 and perplexity is 49.39409629112292
At time: 549.5031032562256 and batch: 750, loss is 3.8532830572128294 and perplexity is 47.147597680689906
At time: 550.7674226760864 and batch: 800, loss is 3.8396170330047608 and perplexity is 46.50766013000499
At time: 552.033536195755 and batch: 850, loss is 3.80356680393219 and perplexity is 44.86090953854848
At time: 553.299544095993 and batch: 900, loss is 3.7574162435531617 and perplexity is 42.837600940366336
At time: 554.5664432048798 and batch: 950, loss is 3.857196717262268 and perplexity is 47.33247889529024
At time: 555.8300294876099 and batch: 1000, loss is 3.832828583717346 and perplexity is 46.193014424263
At time: 557.097069978714 and batch: 1050, loss is 3.7843114948272705 and perplexity is 44.00536220671147
At time: 558.3637647628784 and batch: 1100, loss is 3.8175900173187256 and perplexity is 45.494435297275395
At time: 559.6289820671082 and batch: 1150, loss is 3.8057464790344238 and perplexity is 44.95879839032402
At time: 560.8938431739807 and batch: 1200, loss is 3.823736491203308 and perplexity is 45.77492678947968
At time: 562.1598689556122 and batch: 1250, loss is 3.8216404867172242 and perplexity is 45.679082817365284
At time: 563.4255681037903 and batch: 1300, loss is 3.803368706703186 and perplexity is 44.852023596847566
At time: 564.692031621933 and batch: 1350, loss is 3.645524115562439 and perplexity is 38.30284270758531
At time: 565.9583969116211 and batch: 1400, loss is 3.672549605369568 and perplexity is 39.352110417008085
At time: 567.226068019867 and batch: 1450, loss is 3.6169686698913575 and perplexity is 37.22455670207438
At time: 568.4929263591766 and batch: 1500, loss is 3.604722442626953 and perplexity is 36.771476246360876
At time: 569.7626075744629 and batch: 1550, loss is 3.630973234176636 and perplexity is 37.74953788550898
At time: 571.0379090309143 and batch: 1600, loss is 3.7130751514434817 and perplexity is 40.979631535425696
At time: 572.3180696964264 and batch: 1650, loss is 3.6653750276565553 and perplexity is 39.070786041201735
At time: 573.5852646827698 and batch: 1700, loss is 3.661510639190674 and perplexity is 38.92009270260249
At time: 574.8524162769318 and batch: 1750, loss is 3.644971194267273 and perplexity is 38.281670104117964
At time: 576.1194479465485 and batch: 1800, loss is 3.6077844429016115 and perplexity is 36.884243074649405
At time: 577.3878967761993 and batch: 1850, loss is 3.625837607383728 and perplexity is 37.55616731188049
At time: 578.6556477546692 and batch: 1900, loss is 3.7272739362716676 and perplexity is 41.56564298595458
At time: 579.9307961463928 and batch: 1950, loss is 3.6701858901977538 and perplexity is 39.25920308306716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377852470930232 and perplexity of 79.66676287751567
finished 11 epochs...
Completing Train Step...
At time: 583.8468890190125 and batch: 50, loss is 3.8772061824798585 and perplexity is 48.28911546058522
At time: 585.122701883316 and batch: 100, loss is 3.842909507751465 and perplexity is 46.66103778398145
At time: 586.3864710330963 and batch: 150, loss is 3.800861916542053 and perplexity is 44.73972979269428
At time: 587.6525149345398 and batch: 200, loss is 3.8014956188201903 and perplexity is 44.76809044654354
At time: 588.9173076152802 and batch: 250, loss is 3.799907307624817 and perplexity is 44.697041226364234
At time: 590.1848304271698 and batch: 300, loss is 3.7978922080993653 and perplexity is 44.607062927860554
At time: 591.4498875141144 and batch: 350, loss is 3.835712990760803 and perplexity is 46.32644622372743
At time: 592.7148816585541 and batch: 400, loss is 3.79627206325531 and perplexity is 44.5348515371012
At time: 593.988849401474 and batch: 450, loss is 3.8151121520996094 and perplexity is 45.38184576683628
At time: 595.2550027370453 and batch: 500, loss is 3.810578203201294 and perplexity is 45.17655254338937
At time: 596.5223784446716 and batch: 550, loss is 3.7932362365722656 and perplexity is 44.39985646098546
At time: 597.7887854576111 and batch: 600, loss is 3.774158072471619 and perplexity is 43.56081782083981
At time: 599.0543158054352 and batch: 650, loss is 3.8268265104293824 and perplexity is 45.916590953105924
At time: 600.3206827640533 and batch: 700, loss is 3.861488389968872 and perplexity is 47.53605092290168
At time: 601.5864923000336 and batch: 750, loss is 3.814432907104492 and perplexity is 45.35103084185651
At time: 602.8535921573639 and batch: 800, loss is 3.8022165536880492 and perplexity is 44.80037696075244
At time: 604.1189482212067 and batch: 850, loss is 3.7676158618927 and perplexity is 43.27676396088674
At time: 605.3831164836884 and batch: 900, loss is 3.7243347215652465 and perplexity is 41.44365200347645
At time: 606.6759376525879 and batch: 950, loss is 3.82406614780426 and perplexity is 45.79001928378744
At time: 607.9447865486145 and batch: 1000, loss is 3.7999520683288575 and perplexity is 44.699041942174446
At time: 609.2109172344208 and batch: 1050, loss is 3.7536197233200075 and perplexity is 42.67527545262977
At time: 610.4777674674988 and batch: 1100, loss is 3.7892555570602418 and perplexity is 44.22346617156055
At time: 611.743077993393 and batch: 1150, loss is 3.778169994354248 and perplexity is 43.73593145531285
At time: 613.0102496147156 and batch: 1200, loss is 3.79714120388031 and perplexity is 44.57357541160899
At time: 614.2767677307129 and batch: 1250, loss is 3.796650457382202 and perplexity is 44.551706452064145
At time: 615.5442478656769 and batch: 1300, loss is 3.7796996641159057 and perplexity is 43.80288418188347
At time: 616.811357498169 and batch: 1350, loss is 3.6240781211853026 and perplexity is 37.49014585278491
At time: 618.0774669647217 and batch: 1400, loss is 3.6539764547348024 and perplexity is 38.627963405014036
At time: 619.3424499034882 and batch: 1450, loss is 3.6011767292022707 and perplexity is 36.64132600347543
At time: 620.6099154949188 and batch: 1500, loss is 3.590930128097534 and perplexity is 36.26779393718755
At time: 621.8764953613281 and batch: 1550, loss is 3.6203931760787964 and perplexity is 37.3522509468993
At time: 623.1420676708221 and batch: 1600, loss is 3.7045635747909547 and perplexity is 40.63231048216322
At time: 624.4076154232025 and batch: 1650, loss is 3.658320817947388 and perplexity is 38.796142358927874
At time: 625.6726222038269 and batch: 1700, loss is 3.656907711029053 and perplexity is 38.74135797896538
At time: 626.9384486675262 and batch: 1750, loss is 3.6428987264633177 and perplexity is 38.2024147308179
At time: 628.2044665813446 and batch: 1800, loss is 3.607013053894043 and perplexity is 36.85580194598644
At time: 629.4779536724091 and batch: 1850, loss is 3.6281371402740477 and perplexity is 37.642628325721624
At time: 630.7644274234772 and batch: 1900, loss is 3.7293666791915894 and perplexity is 41.652720274434806
At time: 632.0306971073151 and batch: 1950, loss is 3.671233820915222 and perplexity is 39.30036557187253
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377808752725291 and perplexity of 79.66328006578085
finished 12 epochs...
Completing Train Step...
At time: 635.9363663196564 and batch: 50, loss is 3.857850375175476 and perplexity is 47.36342825871808
At time: 637.2036197185516 and batch: 100, loss is 3.822939600944519 and perplexity is 45.73846372668373
At time: 638.4827561378479 and batch: 150, loss is 3.779037275314331 and perplexity is 43.77387924925651
At time: 639.7491393089294 and batch: 200, loss is 3.779015507698059 and perplexity is 43.77292640662087
At time: 641.0157845020294 and batch: 250, loss is 3.7771983766555786 and perplexity is 43.69345748781379
At time: 642.2801928520203 and batch: 300, loss is 3.774530601501465 and perplexity is 43.57704851305622
At time: 643.545428276062 and batch: 350, loss is 3.810579104423523 and perplexity is 45.17659325752109
At time: 644.8106617927551 and batch: 400, loss is 3.7703672361373903 and perplexity is 43.39599848882919
At time: 646.0758333206177 and batch: 450, loss is 3.7895995950698853 and perplexity is 44.23868334233423
At time: 647.3458428382874 and batch: 500, loss is 3.7868876838684082 and perplexity is 44.11887449035089
At time: 648.624251127243 and batch: 550, loss is 3.7715714836120604 and perplexity is 43.44828948975364
At time: 649.8944668769836 and batch: 600, loss is 3.754219880104065 and perplexity is 42.70089499580653
At time: 651.1630787849426 and batch: 650, loss is 3.8079376459121703 and perplexity is 45.05741862746067
At time: 652.4324984550476 and batch: 700, loss is 3.8419553995132447 and perplexity is 46.6165393349719
At time: 653.7020452022552 and batch: 750, loss is 3.7936950397491453 and perplexity is 44.4202319299903
At time: 654.9714238643646 and batch: 800, loss is 3.781395354270935 and perplexity is 43.8772233116051
At time: 656.2405593395233 and batch: 850, loss is 3.74837833404541 and perplexity is 42.45218288980091
At time: 657.5072078704834 and batch: 900, loss is 3.706203589439392 and perplexity is 40.69900273974528
At time: 658.7738893032074 and batch: 950, loss is 3.806213493347168 and perplexity is 44.979799696229605
At time: 660.0459258556366 and batch: 1000, loss is 3.7816689157485963 and perplexity is 43.88922807159497
At time: 661.317645072937 and batch: 1050, loss is 3.73605055809021 and perplexity is 41.93205449066454
At time: 662.5864644050598 and batch: 1100, loss is 3.771843767166138 and perplexity is 43.460121355172575
At time: 663.8552222251892 and batch: 1150, loss is 3.7605426836013796 and perplexity is 42.971739710664586
At time: 665.1222467422485 and batch: 1200, loss is 3.7787848138809204 and perplexity is 43.76282942784086
At time: 666.3875148296356 and batch: 1250, loss is 3.7805495500564574 and perplexity is 43.8401274613333
At time: 667.654212474823 and batch: 1300, loss is 3.764063572883606 and perplexity is 43.12330511437786
At time: 668.923068523407 and batch: 1350, loss is 3.609592113494873 and perplexity is 36.950977935360484
At time: 670.1979513168335 and batch: 1400, loss is 3.6404631900787354 and perplexity is 38.10948457308949
At time: 671.4654970169067 and batch: 1450, loss is 3.5886125707626344 and perplexity is 36.183838568595455
At time: 672.731467962265 and batch: 1500, loss is 3.57920964717865 and perplexity is 35.8451992942309
At time: 673.9980807304382 and batch: 1550, loss is 3.610595774650574 and perplexity is 36.98808281382721
At time: 675.2647683620453 and batch: 1600, loss is 3.6959251260757444 and perplexity is 40.28282204417097
At time: 676.5330579280853 and batch: 1650, loss is 3.649689598083496 and perplexity is 38.46272529226642
At time: 677.7998929023743 and batch: 1700, loss is 3.649348669052124 and perplexity is 38.449614467645965
At time: 679.0667600631714 and batch: 1750, loss is 3.6359642267227175 and perplexity is 37.93841650151541
At time: 680.3323740959167 and batch: 1800, loss is 3.600981125831604 and perplexity is 36.63415953751874
At time: 681.599781036377 and batch: 1850, loss is 3.624086561203003 and perplexity is 37.49046227161479
At time: 682.8675653934479 and batch: 1900, loss is 3.725433793067932 and perplexity is 41.489226580632504
At time: 684.1341073513031 and batch: 1950, loss is 3.6652155256271364 and perplexity is 39.06455466850867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380008573310319 and perplexity of 79.83871788425431
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 688.0180685520172 and batch: 50, loss is 3.8570404863357544 and perplexity is 47.32508467587616
At time: 689.2841744422913 and batch: 100, loss is 3.850309662818909 and perplexity is 47.007617489348675
At time: 690.5746417045593 and batch: 150, loss is 3.8197653818130495 and perplexity is 45.59350999923467
At time: 691.841965675354 and batch: 200, loss is 3.822567081451416 and perplexity is 45.72142843054791
At time: 693.1077237129211 and batch: 250, loss is 3.830003037452698 and perplexity is 46.062678147208
At time: 694.3740775585175 and batch: 300, loss is 3.833455190658569 and perplexity is 46.22196835815787
At time: 695.641205072403 and batch: 350, loss is 3.8742960500717163 and perplexity is 48.14879201965113
At time: 696.9073073863983 and batch: 400, loss is 3.8262822151184084 and perplexity is 45.89160556828498
At time: 698.1734836101532 and batch: 450, loss is 3.8413733768463136 and perplexity is 46.589415346578775
At time: 699.4401533603668 and batch: 500, loss is 3.8373440408706667 and perplexity is 46.40206863413562
At time: 700.7135560512543 and batch: 550, loss is 3.820384187698364 and perplexity is 45.621732262705144
At time: 701.9760344028473 and batch: 600, loss is 3.7913112020492554 and perplexity is 44.314467419277214
At time: 703.2421221733093 and batch: 650, loss is 3.845547013282776 and perplexity is 46.78426896926234
At time: 704.5084590911865 and batch: 700, loss is 3.889707489013672 and perplexity is 48.89658164434183
At time: 705.7762229442596 and batch: 750, loss is 3.851449065208435 and perplexity is 47.061208606167426
At time: 707.0422728061676 and batch: 800, loss is 3.8467508697509767 and perplexity is 46.840624429207324
At time: 708.3066689968109 and batch: 850, loss is 3.814844961166382 and perplexity is 45.36972176889754
At time: 709.57142329216 and batch: 900, loss is 3.7623099756240843 and perplexity is 43.04775047027771
At time: 710.8357865810394 and batch: 950, loss is 3.8639832305908204 and perplexity is 47.65479385450555
At time: 712.1030595302582 and batch: 1000, loss is 3.820081572532654 and perplexity is 45.60792852335225
At time: 713.3701939582825 and batch: 1050, loss is 3.7611204862594603 and perplexity is 42.99657607065819
At time: 714.6369106769562 and batch: 1100, loss is 3.789520974159241 and perplexity is 44.235205393485685
At time: 715.901360988617 and batch: 1150, loss is 3.7896140241622924 and perplexity is 44.23932167098938
At time: 717.168030500412 and batch: 1200, loss is 3.814232029914856 and perplexity is 45.341921769166994
At time: 718.4337344169617 and batch: 1250, loss is 3.822729263305664 and perplexity is 45.72884421792647
At time: 719.7001478672028 and batch: 1300, loss is 3.8192143392562867 and perplexity is 45.56839295582837
At time: 720.9661860466003 and batch: 1350, loss is 3.65586865901947 and perplexity is 38.70112459901027
At time: 722.232173204422 and batch: 1400, loss is 3.6664786338806152 and perplexity is 39.113928605678275
At time: 723.4992733001709 and batch: 1450, loss is 3.5978687143325807 and perplexity is 36.520316213653274
At time: 724.7654502391815 and batch: 1500, loss is 3.574011812210083 and perplexity is 35.65936524962902
At time: 726.0318329334259 and batch: 1550, loss is 3.5979049682617186 and perplexity is 36.521640242609855
At time: 727.2997808456421 and batch: 1600, loss is 3.683923211097717 and perplexity is 39.80224075560688
At time: 728.5668275356293 and batch: 1650, loss is 3.6387890005111694 and perplexity is 38.045735450540114
At time: 729.8347148895264 and batch: 1700, loss is 3.6377502346038817 and perplexity is 38.00623535686356
At time: 731.1025004386902 and batch: 1750, loss is 3.6287231969833376 and perplexity is 37.66469550628523
At time: 732.3701777458191 and batch: 1800, loss is 3.6007271909713747 and perplexity is 36.62485802837567
At time: 733.6374995708466 and batch: 1850, loss is 3.626589479446411 and perplexity is 37.584415362993234
At time: 734.9038324356079 and batch: 1900, loss is 3.7483950662612915 and perplexity is 42.452893214832294
At time: 736.1698622703552 and batch: 1950, loss is 3.6955299520492555 and perplexity is 40.26690646410449
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358336550690407 and perplexity of 78.12706585808208
finished 14 epochs...
Completing Train Step...
At time: 740.0457532405853 and batch: 50, loss is 3.899586582183838 and perplexity is 49.38202947411845
At time: 741.3227891921997 and batch: 100, loss is 3.865316615104675 and perplexity is 47.71837840054594
At time: 742.5888900756836 and batch: 150, loss is 3.8144785737991334 and perplexity is 45.353101920822944
At time: 743.8548946380615 and batch: 200, loss is 3.801934242248535 and perplexity is 44.787731086963284
At time: 745.12078332901 and batch: 250, loss is 3.7963389110565187 and perplexity is 44.537828693510676
At time: 746.3879082202911 and batch: 300, loss is 3.7929246950149538 and perplexity is 44.38602621501923
At time: 747.6537816524506 and batch: 350, loss is 3.8319488096237184 and perplexity is 46.15239287837791
At time: 748.9201383590698 and batch: 400, loss is 3.7905461025238036 and perplexity is 44.28057540831813
At time: 750.1887793540955 and batch: 450, loss is 3.8128935146331786 and perplexity is 45.28127151368045
At time: 751.4544408321381 and batch: 500, loss is 3.8111683034896853 and perplexity is 45.20321910727345
At time: 752.7211830615997 and batch: 550, loss is 3.798400149345398 and perplexity is 44.62972645036764
At time: 753.9881603717804 and batch: 600, loss is 3.771939821243286 and perplexity is 43.46429607751843
At time: 755.2517175674438 and batch: 650, loss is 3.82422990322113 and perplexity is 45.79751826146609
At time: 756.5168626308441 and batch: 700, loss is 3.8665630626678467 and perplexity is 47.777893940816426
At time: 757.7823488712311 and batch: 750, loss is 3.8268394327163695 and perplexity is 45.91718430430541
At time: 759.0481877326965 and batch: 800, loss is 3.821366686820984 and perplexity is 45.666577601271094
At time: 760.3108689785004 and batch: 850, loss is 3.7899349546432495 and perplexity is 44.253521696259064
At time: 761.5734610557556 and batch: 900, loss is 3.7408424186706544 and perplexity is 42.13346923992829
At time: 762.8380813598633 and batch: 950, loss is 3.8420414543151855 and perplexity is 46.62055108464422
At time: 764.1140687465668 and batch: 1000, loss is 3.7994416999816893 and perplexity is 44.67623478653864
At time: 765.3794546127319 and batch: 1050, loss is 3.7433249044418333 and perplexity is 42.238194914021676
At time: 766.6461744308472 and batch: 1100, loss is 3.7745957136154176 and perplexity is 43.57988599918107
At time: 767.9129953384399 and batch: 1150, loss is 3.7760908460617064 and perplexity is 43.64509243472578
At time: 769.1783466339111 and batch: 1200, loss is 3.8019332122802734 and perplexity is 44.7876849570455
At time: 770.4448621273041 and batch: 1250, loss is 3.8098576641082764 and perplexity is 45.144012795682066
At time: 771.7123470306396 and batch: 1300, loss is 3.80577853679657 and perplexity is 44.96023969189152
At time: 772.9760572910309 and batch: 1350, loss is 3.641955943107605 and perplexity is 38.166415102653275
At time: 774.2422156333923 and batch: 1400, loss is 3.6544697761535643 and perplexity is 38.6470241078648
At time: 775.5091106891632 and batch: 1450, loss is 3.5887440776824953 and perplexity is 36.18859730665099
At time: 776.7751176357269 and batch: 1500, loss is 3.569451766014099 and perplexity is 35.49712708466664
At time: 778.041139125824 and batch: 1550, loss is 3.5964680337905883 and perplexity is 36.46919872533833
At time: 779.3066160678864 and batch: 1600, loss is 3.684725437164307 and perplexity is 39.834183961772894
At time: 780.5706505775452 and batch: 1650, loss is 3.6410291147232057 and perplexity is 38.13105777342455
At time: 781.8369855880737 and batch: 1700, loss is 3.6414912700653077 and perplexity is 38.148684318261736
At time: 783.1036615371704 and batch: 1750, loss is 3.633541226387024 and perplexity is 37.846602982609355
At time: 784.3720107078552 and batch: 1800, loss is 3.605725493431091 and perplexity is 36.80837840945735
At time: 785.641491651535 and batch: 1850, loss is 3.6319465017318726 and perplexity is 37.78629617087979
At time: 786.9108371734619 and batch: 1900, loss is 3.7539237117767335 and perplexity is 42.68825021574416
At time: 788.1806395053864 and batch: 1950, loss is 3.6999271965026854 and perplexity is 40.44435976204285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357328193132267 and perplexity of 78.04832554659478
finished 15 epochs...
Completing Train Step...
At time: 792.0748293399811 and batch: 50, loss is 3.8960720443725587 and perplexity is 49.20877909017856
At time: 793.3514885902405 and batch: 100, loss is 3.8591524362564087 and perplexity is 47.425138501847805
At time: 794.6375350952148 and batch: 150, loss is 3.8087207555770872 and perplexity is 45.092717347044335
At time: 795.9258978366852 and batch: 200, loss is 3.79513530254364 and perplexity is 44.484254831196
At time: 797.1951611042023 and batch: 250, loss is 3.789407148361206 and perplexity is 44.230170572482244
At time: 798.4645404815674 and batch: 300, loss is 3.785370707511902 and perplexity is 44.05199793877192
At time: 799.7315888404846 and batch: 350, loss is 3.8231749963760375 and perplexity is 45.74923161939633
At time: 800.9995694160461 and batch: 400, loss is 3.779926371574402 and perplexity is 43.81281574816869
At time: 802.2678089141846 and batch: 450, loss is 3.802198042869568 and perplexity is 44.79954767678202
At time: 803.5374228954315 and batch: 500, loss is 3.7995500707626344 and perplexity is 44.68107664734553
At time: 804.80783867836 and batch: 550, loss is 3.7857745695114136 and perplexity is 44.0697924597655
At time: 806.0787603855133 and batch: 600, loss is 3.7609369802474975 and perplexity is 42.9886866643543
At time: 807.3484570980072 and batch: 650, loss is 3.813828558921814 and perplexity is 45.32363130904754
At time: 808.6173470020294 and batch: 700, loss is 3.8566707611083983 and perplexity is 47.30759063237861
At time: 809.8862149715424 and batch: 750, loss is 3.816780333518982 and perplexity is 45.457614098812265
At time: 811.1537845134735 and batch: 800, loss is 3.8108913040161134 and perplexity is 45.19069957340918
At time: 812.4305572509766 and batch: 850, loss is 3.780126008987427 and perplexity is 43.82156329850209
At time: 813.7037603855133 and batch: 900, loss is 3.731547112464905 and perplexity is 41.743640338189714
At time: 814.9736549854279 and batch: 950, loss is 3.832781114578247 and perplexity is 46.19082173367887
At time: 816.2515180110931 and batch: 1000, loss is 3.7912588024139406 and perplexity is 44.312145418181814
At time: 817.5170199871063 and batch: 1050, loss is 3.735891790390015 and perplexity is 41.9253975632751
At time: 818.7846324443817 and batch: 1100, loss is 3.768202991485596 and perplexity is 43.30218049036112
At time: 820.0543563365936 and batch: 1150, loss is 3.769895815849304 and perplexity is 43.37554555606231
At time: 821.3177196979523 and batch: 1200, loss is 3.7961983394622805 and perplexity is 44.53156837994876
At time: 822.5816209316254 and batch: 1250, loss is 3.804246153831482 and perplexity is 44.89139614729041
At time: 823.8456184864044 and batch: 1300, loss is 3.8000502395629883 and perplexity is 44.70343031768897
At time: 825.1116847991943 and batch: 1350, loss is 3.636201376914978 and perplexity is 37.947414671199475
At time: 826.3754813671112 and batch: 1400, loss is 3.649162406921387 and perplexity is 38.442453427465196
At time: 827.6413993835449 and batch: 1450, loss is 3.5842970991134644 and perplexity is 36.02802468610468
At time: 828.9068913459778 and batch: 1500, loss is 3.566222095489502 and perplexity is 35.382667991684215
At time: 830.1730256080627 and batch: 1550, loss is 3.5941682386398317 and perplexity is 36.385423408915415
At time: 831.4385876655579 and batch: 1600, loss is 3.683011145591736 and perplexity is 39.765955054736395
At time: 832.7038688659668 and batch: 1650, loss is 3.639933714866638 and perplexity is 38.08931188660223
At time: 833.9697372913361 and batch: 1700, loss is 3.641199049949646 and perplexity is 38.13753813396686
At time: 835.235833644867 and batch: 1750, loss is 3.6337863063812255 and perplexity is 37.85587956455477
At time: 836.5044348239899 and batch: 1800, loss is 3.6063495206832887 and perplexity is 36.831355008960564
At time: 837.7705583572388 and batch: 1850, loss is 3.6329593372344973 and perplexity is 37.824586860966185
At time: 839.0366287231445 and batch: 1900, loss is 3.7551326990127563 and perplexity is 42.73989097560285
At time: 840.3044083118439 and batch: 1950, loss is 3.7007002449035644 and perplexity is 40.475637297648284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3573511877725295 and perplexity of 78.0501202603981
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 844.2361829280853 and batch: 50, loss is 3.9008944845199585 and perplexity is 49.446658600910055
At time: 845.520147562027 and batch: 100, loss is 3.8821918106079103 and perplexity is 48.53046818042713
At time: 846.7856225967407 and batch: 150, loss is 3.8436479663848875 and perplexity is 46.69550775593524
At time: 848.0523233413696 and batch: 200, loss is 3.8341133975982666 and perplexity is 46.25240199321384
At time: 849.3197538852692 and batch: 250, loss is 3.838345160484314 and perplexity is 46.448545915936485
At time: 850.5863616466522 and batch: 300, loss is 3.836767954826355 and perplexity is 46.375344748336204
At time: 851.8530278205872 and batch: 350, loss is 3.8795256090164183 and perplexity is 48.40124850832423
At time: 853.1183929443359 and batch: 400, loss is 3.831397895812988 and perplexity is 46.126973890221684
At time: 854.3856914043427 and batch: 450, loss is 3.8552485370635985 and perplexity is 47.24035646183968
At time: 855.6568927764893 and batch: 500, loss is 3.8465598678588866 and perplexity is 46.831678635673605
At time: 856.925214767456 and batch: 550, loss is 3.8348390817642213 and perplexity is 46.28597881058652
At time: 858.1930921077728 and batch: 600, loss is 3.7945031547546386 and perplexity is 44.45614309418143
At time: 859.4891285896301 and batch: 650, loss is 3.8290547227859495 and perplexity is 46.019016939485155
At time: 860.7550427913666 and batch: 700, loss is 3.8670538663864136 and perplexity is 47.801349264337034
At time: 862.0217726230621 and batch: 750, loss is 3.8232986164093017 and perplexity is 45.75488749051322
At time: 863.2890059947968 and batch: 800, loss is 3.823041167259216 and perplexity is 45.74310944980486
At time: 864.5618221759796 and batch: 850, loss is 3.8026733350753785 and perplexity is 44.820845613587366
At time: 865.8258559703827 and batch: 900, loss is 3.758719687461853 and perplexity is 42.89347375600511
At time: 867.0908725261688 and batch: 950, loss is 3.870837802886963 and perplexity is 47.98256918069377
At time: 868.3552296161652 and batch: 1000, loss is 3.832324585914612 and perplexity is 46.16973911233721
At time: 869.6230883598328 and batch: 1050, loss is 3.7749562883377075 and perplexity is 43.59560263781368
At time: 870.8863217830658 and batch: 1100, loss is 3.797271647453308 and perplexity is 44.57939012728489
At time: 872.1500282287598 and batch: 1150, loss is 3.796188611984253 and perplexity is 44.531135202202684
At time: 873.4140913486481 and batch: 1200, loss is 3.820160536766052 and perplexity is 45.61153006065942
At time: 874.6788852214813 and batch: 1250, loss is 3.8275388574600218 and perplexity is 45.94931115301345
At time: 875.953066110611 and batch: 1300, loss is 3.83105447769165 and perplexity is 46.11113577120949
At time: 877.2183613777161 and batch: 1350, loss is 3.676802248954773 and perplexity is 39.51981726291067
At time: 878.4822206497192 and batch: 1400, loss is 3.691163811683655 and perplexity is 40.09147874809387
At time: 879.7453076839447 and batch: 1450, loss is 3.6310393905639646 and perplexity is 37.752035341169226
At time: 881.006973028183 and batch: 1500, loss is 3.6087490844726564 and perplexity is 36.919840315364475
At time: 882.2706317901611 and batch: 1550, loss is 3.6309594202041624 and perplexity is 37.74901641803352
At time: 883.5362107753754 and batch: 1600, loss is 3.7094218921661377 and perplexity is 40.83019544692668
At time: 884.80011510849 and batch: 1650, loss is 3.6592363119125366 and perplexity is 38.83167625618094
At time: 886.0638909339905 and batch: 1700, loss is 3.6476646947860716 and perplexity is 38.384920792872585
At time: 887.3263750076294 and batch: 1750, loss is 3.635592260360718 and perplexity is 37.924307310984126
At time: 888.5891432762146 and batch: 1800, loss is 3.598584976196289 and perplexity is 36.546483693672954
At time: 889.8540558815002 and batch: 1850, loss is 3.6196033716201783 and perplexity is 37.32276161949608
At time: 891.1196942329407 and batch: 1900, loss is 3.746866235733032 and perplexity is 42.38803952345614
At time: 892.3858497142792 and batch: 1950, loss is 3.705560541152954 and perplexity is 40.672839728715026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35228271484375 and perplexity of 77.65552617822264
finished 17 epochs...
Completing Train Step...
At time: 896.2699222564697 and batch: 50, loss is 3.921614618301392 and perplexity is 50.48188799075982
At time: 897.5355110168457 and batch: 100, loss is 3.897544951438904 and perplexity is 49.28131245296485
At time: 898.8025588989258 and batch: 150, loss is 3.849240503311157 and perplexity is 46.95738570585265
At time: 900.0684297084808 and batch: 200, loss is 3.834433522224426 and perplexity is 46.26721089633171
At time: 901.3387184143066 and batch: 250, loss is 3.835365037918091 and perplexity is 46.31032960914465
At time: 902.6053948402405 and batch: 300, loss is 3.8288040113449098 and perplexity is 46.00748089160305
At time: 903.8721804618835 and batch: 350, loss is 3.8643661546707153 and perplexity is 47.67304551687235
At time: 905.1384944915771 and batch: 400, loss is 3.815165629386902 and perplexity is 45.38427272973334
At time: 906.4061124324799 and batch: 450, loss is 3.8413240194320677 and perplexity is 46.587115870254614
At time: 907.673077583313 and batch: 500, loss is 3.833571572303772 and perplexity is 46.2273480599231
At time: 908.9390313625336 and batch: 550, loss is 3.8258572721481325 and perplexity is 45.87210839599061
At time: 910.2050642967224 and batch: 600, loss is 3.788802900314331 and perplexity is 44.20345265123966
At time: 911.4726610183716 and batch: 650, loss is 3.8253098821640013 and perplexity is 45.84700533451269
At time: 912.7408125400543 and batch: 700, loss is 3.862300796508789 and perplexity is 47.57468521280327
At time: 914.0072298049927 and batch: 750, loss is 3.818475213050842 and perplexity is 45.53472460656712
At time: 915.274614572525 and batch: 800, loss is 3.81627863407135 and perplexity is 45.43481375886546
At time: 916.5524241924286 and batch: 850, loss is 3.7946507787704467 and perplexity is 44.462706372989196
At time: 917.8273394107819 and batch: 900, loss is 3.7498363780975343 and perplexity is 42.51412518888989
At time: 919.1039855480194 and batch: 950, loss is 3.863115644454956 and perplexity is 47.61346714588187
At time: 920.3698358535767 and batch: 1000, loss is 3.8241490173339843 and perplexity is 45.793814038384134
At time: 921.663827419281 and batch: 1050, loss is 3.7663383531570434 and perplexity is 43.22151281629998
At time: 922.9320437908173 and batch: 1100, loss is 3.7872032356262206 and perplexity is 44.132798475502476
At time: 924.1993246078491 and batch: 1150, loss is 3.7849874544143676 and perplexity is 44.03511810893946
At time: 925.4658823013306 and batch: 1200, loss is 3.8098289728164674 and perplexity is 45.142717574218395
At time: 926.7329378128052 and batch: 1250, loss is 3.8177709579467773 and perplexity is 45.50266783374864
At time: 928.0000576972961 and batch: 1300, loss is 3.822885231971741 and perplexity is 45.73597704099436
At time: 929.2739069461823 and batch: 1350, loss is 3.6697253942489625 and perplexity is 39.24112854104073
At time: 930.5410706996918 and batch: 1400, loss is 3.685846543312073 and perplexity is 39.87886735303587
At time: 931.8075942993164 and batch: 1450, loss is 3.6256541633605956 and perplexity is 37.54927848933135
At time: 933.0740587711334 and batch: 1500, loss is 3.6033829736709593 and perplexity is 36.72225496800928
At time: 934.3417947292328 and batch: 1550, loss is 3.6255977392196654 and perplexity is 37.547159863321426
At time: 935.6088910102844 and batch: 1600, loss is 3.704937677383423 and perplexity is 40.647513978508954
At time: 936.8756449222565 and batch: 1650, loss is 3.6554617643356324 and perplexity is 38.685380520460555
At time: 938.1402986049652 and batch: 1700, loss is 3.646381335258484 and perplexity is 38.33569073574566
At time: 939.4046609401703 and batch: 1750, loss is 3.636117057800293 and perplexity is 37.94421511368363
At time: 940.6677186489105 and batch: 1800, loss is 3.6032245540618897 and perplexity is 36.71643790351381
At time: 941.9300327301025 and batch: 1850, loss is 3.6276389169692993 and perplexity is 37.62387856221019
At time: 943.1959187984467 and batch: 1900, loss is 3.757005476951599 and perplexity is 42.820008298091274
At time: 944.4595959186554 and batch: 1950, loss is 3.7139227390289307 and perplexity is 41.01438008651136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349776866824128 and perplexity of 77.46117683838814
finished 18 epochs...
Completing Train Step...
At time: 948.3344881534576 and batch: 50, loss is 3.923073854446411 and perplexity is 50.55560675984975
At time: 949.5987451076508 and batch: 100, loss is 3.8946936988830565 and perplexity is 49.14099911431861
At time: 950.8634419441223 and batch: 150, loss is 3.8441329908370974 and perplexity is 46.71816171242253
At time: 952.1290416717529 and batch: 200, loss is 3.827196636199951 and perplexity is 45.93358901223015
At time: 953.4031376838684 and batch: 250, loss is 3.8269335556030275 and perplexity is 45.92150636563859
At time: 954.6682667732239 and batch: 300, loss is 3.818824963569641 and perplexity is 45.55065318547363
At time: 955.9335496425629 and batch: 350, loss is 3.854077739715576 and perplexity is 47.18507994288969
At time: 957.1987528800964 and batch: 400, loss is 3.807088041305542 and perplexity is 45.0191538942805
At time: 958.4626433849335 and batch: 450, loss is 3.8349003314971926 and perplexity is 46.288813901252375
At time: 959.7285044193268 and batch: 500, loss is 3.828581566810608 and perplexity is 45.997247917118536
At time: 960.9951708316803 and batch: 550, loss is 3.822798743247986 and perplexity is 45.73202156576487
At time: 962.2599606513977 and batch: 600, loss is 3.787229018211365 and perplexity is 44.13393634780541
At time: 963.5248951911926 and batch: 650, loss is 3.8225481843948366 and perplexity is 45.72056443829144
At time: 964.7907526493073 and batch: 700, loss is 3.8584261465072633 and perplexity is 47.39070661517884
At time: 966.0570595264435 and batch: 750, loss is 3.8137401342391968 and perplexity is 45.319623758519775
At time: 967.3247275352478 and batch: 800, loss is 3.8107150030136108 and perplexity is 45.18273311003896
At time: 968.5918650627136 and batch: 850, loss is 3.7880869197845457 and perplexity is 44.171815167054945
At time: 969.8603522777557 and batch: 900, loss is 3.743340563774109 and perplexity is 42.2388563411293
At time: 971.1271369457245 and batch: 950, loss is 3.8567742490768433 and perplexity is 47.31248665216039
At time: 972.3947858810425 and batch: 1000, loss is 3.817928433418274 and perplexity is 45.509833952049235
At time: 973.6637036800385 and batch: 1050, loss is 3.7608841705322265 and perplexity is 42.986416503995464
At time: 974.9328875541687 and batch: 1100, loss is 3.7821011972427367 and perplexity is 43.90820467400394
At time: 976.2011053562164 and batch: 1150, loss is 3.780300612449646 and perplexity is 43.82921536319292
At time: 977.4698407649994 and batch: 1200, loss is 3.806348567008972 and perplexity is 44.9858756928261
At time: 978.7384693622589 and batch: 1250, loss is 3.8144407892227172 and perplexity is 45.351388305452026
At time: 980.0059900283813 and batch: 1300, loss is 3.8206294345855714 and perplexity is 45.6329222226269
At time: 981.27321600914 and batch: 1350, loss is 3.6677380275726317 and perplexity is 39.16321947242267
At time: 982.5416769981384 and batch: 1400, loss is 3.6841758728027343 and perplexity is 39.81229852817317
At time: 983.8090689182281 and batch: 1450, loss is 3.624032835960388 and perplexity is 37.488448141538804
At time: 985.0759875774384 and batch: 1500, loss is 3.602284646034241 and perplexity is 36.68194404184976
At time: 986.3439788818359 and batch: 1550, loss is 3.6252116775512695 and perplexity is 37.532667141863186
At time: 987.6128957271576 and batch: 1600, loss is 3.7048159790039064 and perplexity is 40.6425675429191
At time: 988.880469083786 and batch: 1650, loss is 3.6557360601425173 and perplexity is 38.69599321356713
At time: 990.1530573368073 and batch: 1700, loss is 3.6477942752838133 and perplexity is 38.389895052291244
At time: 991.4186036586761 and batch: 1750, loss is 3.63851411819458 and perplexity is 38.0352787878848
At time: 992.6832959651947 and batch: 1800, loss is 3.6065221405029297 and perplexity is 36.83771337959395
At time: 993.9506189823151 and batch: 1850, loss is 3.631006736755371 and perplexity is 37.75080261355991
At time: 995.218936920166 and batch: 1900, loss is 3.759952411651611 and perplexity is 42.94638218273562
At time: 996.4872853755951 and batch: 1950, loss is 3.7150862979888917 and perplexity is 41.06213051077794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348524936409884 and perplexity of 77.36426151346065
finished 19 epochs...
Completing Train Step...
At time: 1000.3767690658569 and batch: 50, loss is 3.9200261497497557 and perplexity is 50.40176275431631
At time: 1001.6430773735046 and batch: 100, loss is 3.8899547147750853 and perplexity is 48.90867163338616
At time: 1002.9101357460022 and batch: 150, loss is 3.8389567613601683 and perplexity is 46.4769625762422
At time: 1004.1767840385437 and batch: 200, loss is 3.821792197227478 and perplexity is 45.68601334003071
At time: 1005.4425404071808 and batch: 250, loss is 3.821463289260864 and perplexity is 45.670989317176186
At time: 1006.7112209796906 and batch: 300, loss is 3.8133770179748536 and perplexity is 45.303170453451266
At time: 1007.9781413078308 and batch: 350, loss is 3.849143972396851 and perplexity is 46.95285308524955
At time: 1009.2439374923706 and batch: 400, loss is 3.803110432624817 and perplexity is 44.84044097759964
At time: 1010.511180639267 and batch: 450, loss is 3.8315529298782347 and perplexity is 46.13412569687391
At time: 1011.7766926288605 and batch: 500, loss is 3.8257794523239137 and perplexity is 45.86853877547411
At time: 1013.0438396930695 and batch: 550, loss is 3.8204671144485474 and perplexity is 45.62551568157056
At time: 1014.3122143745422 and batch: 600, loss is 3.7851517820358276 and perplexity is 44.04235488974421
At time: 1015.5791616439819 and batch: 650, loss is 3.8194168329238893 and perplexity is 45.57762120114384
At time: 1016.8550808429718 and batch: 700, loss is 3.854917221069336 and perplexity is 47.22470756867666
At time: 1018.1226758956909 and batch: 750, loss is 3.810141334533691 and perplexity is 45.15682063351326
At time: 1019.3904404640198 and batch: 800, loss is 3.8068649530410767 and perplexity is 45.00911176955227
At time: 1020.6560425758362 and batch: 850, loss is 3.784160556793213 and perplexity is 43.99872062509824
At time: 1021.9242582321167 and batch: 900, loss is 3.739726366996765 and perplexity is 42.086472341418094
At time: 1023.1897854804993 and batch: 950, loss is 3.853409080505371 and perplexity is 47.15353975059679
At time: 1024.457043170929 and batch: 1000, loss is 3.8147763872146605 and perplexity is 45.3666106944579
At time: 1025.7236907482147 and batch: 1050, loss is 3.7582567501068116 and perplexity is 42.8736213602783
At time: 1026.9917874336243 and batch: 1100, loss is 3.7797073698043824 and perplexity is 43.80322171456381
At time: 1028.2594077587128 and batch: 1150, loss is 3.777936863899231 and perplexity is 43.72573646613949
At time: 1029.5261778831482 and batch: 1200, loss is 3.804430351257324 and perplexity is 44.899665788503135
At time: 1030.7925713062286 and batch: 1250, loss is 3.812383813858032 and perplexity is 45.25819749541235
At time: 1032.0590288639069 and batch: 1300, loss is 3.8188535261154173 and perplexity is 45.551954246671094
At time: 1033.3250875473022 and batch: 1350, loss is 3.6659038209915162 and perplexity is 39.09145187594829
At time: 1034.5947008132935 and batch: 1400, loss is 3.682468891143799 and perplexity is 39.74439763406335
At time: 1035.8670966625214 and batch: 1450, loss is 3.6225018215179445 and perplexity is 37.431096700154505
At time: 1037.1345031261444 and batch: 1500, loss is 3.6013929224014283 and perplexity is 36.649248465325826
At time: 1038.4024155139923 and batch: 1550, loss is 3.6250351905822753 and perplexity is 37.52604369969386
At time: 1039.6700057983398 and batch: 1600, loss is 3.7050275468826293 and perplexity is 40.65116711438448
At time: 1040.9361760616302 and batch: 1650, loss is 3.6561608934402465 and perplexity is 38.712436052458386
At time: 1042.2023639678955 and batch: 1700, loss is 3.648723669052124 and perplexity is 38.42559096672973
At time: 1043.4671339988708 and batch: 1750, loss is 3.6397812795639037 and perplexity is 38.08350617332293
At time: 1044.7308323383331 and batch: 1800, loss is 3.6078104734420777 and perplexity is 36.88520320392762
At time: 1045.9965970516205 and batch: 1850, loss is 3.6318516683578492 and perplexity is 37.78271293882973
At time: 1047.2636966705322 and batch: 1900, loss is 3.7601362609863282 and perplexity is 42.954278572379174
At time: 1048.5308561325073 and batch: 1950, loss is 3.7141906356811525 and perplexity is 41.025369173533576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347902093931686 and perplexity of 77.31609076804611
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f98e3f9bb38>
ELAPSED
2157.3489344120026


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -76.16006149647069}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.909600321875081, 'seq_len': 35, 'dropout': 0.7290759996057752, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -77.31609076804611}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.43001077421999756, 'seq_len': 35, 'dropout': 0.7678082231043937, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9150021076202393 and batch: 50, loss is 7.68902928352356 and perplexity is 2184.25324218375
At time: 3.3978137969970703 and batch: 100, loss is 7.013529386520386 and perplexity is 1111.570752690374
At time: 4.880025625228882 and batch: 150, loss is 6.700782299041748 and perplexity is 813.0416181237674
At time: 6.3741843700408936 and batch: 200, loss is 6.531350259780884 and perplexity is 686.3243022215047
At time: 7.865921974182129 and batch: 250, loss is 6.458692636489868 and perplexity is 638.2261173668938
At time: 9.34868597984314 and batch: 300, loss is 6.391057977676391 and perplexity is 596.4873162414212
At time: 10.831861019134521 and batch: 350, loss is 6.341194820404053 and perplexity is 567.4739359185736
At time: 12.316593170166016 and batch: 400, loss is 6.293728380203247 and perplexity is 541.1672496812304
At time: 13.802343368530273 and batch: 450, loss is 6.197491903305053 and perplexity is 491.514727387957
At time: 15.28529691696167 and batch: 500, loss is 6.175874662399292 and perplexity is 481.0035557063308
At time: 16.767832040786743 and batch: 550, loss is 6.119726037979126 and perplexity is 454.7400959170145
At time: 18.2512469291687 and batch: 600, loss is 6.163575267791748 and perplexity is 475.12373639834965
At time: 19.73367428779602 and batch: 650, loss is 6.222193365097046 and perplexity is 503.8070538431274
At time: 21.215344190597534 and batch: 700, loss is 6.120371322631836 and perplexity is 455.0336274173828
At time: 22.704190492630005 and batch: 750, loss is 6.03871753692627 and perplexity is 419.35488272841036
At time: 24.198591947555542 and batch: 800, loss is 6.056630926132202 and perplexity is 426.93463681308555
At time: 25.69065284729004 and batch: 850, loss is 6.079642124176026 and perplexity is 436.8728205181726
At time: 27.184077262878418 and batch: 900, loss is 6.061663818359375 and perplexity is 429.08876903886784
At time: 28.675954818725586 and batch: 950, loss is 6.0674888610839846 and perplexity is 431.59552333853884
At time: 30.168619394302368 and batch: 1000, loss is 6.046694698333741 and perplexity is 422.71352271097294
At time: 31.661245107650757 and batch: 1050, loss is 5.940453939437866 and perplexity is 380.10743613729414
At time: 33.155407190322876 and batch: 1100, loss is 6.0132678127288814 and perplexity is 408.81707750223524
At time: 34.649824142456055 and batch: 1150, loss is 5.919733333587646 and perplexity is 372.3124174206276
At time: 36.14159083366394 and batch: 1200, loss is 5.990810174942016 and perplexity is 399.73833675552277
At time: 37.634995222091675 and batch: 1250, loss is 5.929968938827515 and perplexity is 376.1428302059587
At time: 39.12473487854004 and batch: 1300, loss is 5.943062391281128 and perplexity is 381.10022233430533
At time: 40.61793327331543 and batch: 1350, loss is 5.91634160041809 and perplexity is 371.05177213975463
At time: 42.11213397979736 and batch: 1400, loss is 5.939865303039551 and perplexity is 379.88375690444116
At time: 43.60770893096924 and batch: 1450, loss is 5.915805082321167 and perplexity is 370.8527495434927
At time: 45.09941554069519 and batch: 1500, loss is 5.885642518997193 and perplexity is 359.83389384991
At time: 46.59338974952698 and batch: 1550, loss is 5.858544816970825 and perplexity is 350.21414735685397
At time: 48.086475133895874 and batch: 1600, loss is 5.856425771713257 and perplexity is 349.4728134662008
At time: 49.583986043930054 and batch: 1650, loss is 5.855607986450195 and perplexity is 349.1871365766038
At time: 51.07701849937439 and batch: 1700, loss is 5.861192111968994 and perplexity is 351.1424957813414
At time: 52.57169055938721 and batch: 1750, loss is 5.86496678352356 and perplexity is 352.47044808692556
At time: 54.063987255096436 and batch: 1800, loss is 5.873322191238404 and perplexity is 355.42782020785125
At time: 55.55590057373047 and batch: 1850, loss is 5.831784992218018 and perplexity is 340.9667592129313
At time: 57.053285121917725 and batch: 1900, loss is 5.814786205291748 and perplexity is 335.219722636618
At time: 58.546807289123535 and batch: 1950, loss is 5.754469118118286 and perplexity is 315.5979578052639
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.215841319949128 and perplexity of 184.16669893733436
finished 1 epochs...
Completing Train Step...
At time: 62.528706312179565 and batch: 50, loss is 5.516730318069458 and perplexity is 248.82014296781122
At time: 63.79773926734924 and batch: 100, loss is 5.430169696807861 and perplexity is 228.18796490786193
At time: 65.06430292129517 and batch: 150, loss is 5.315068397521973 and perplexity is 203.37842323330585
At time: 66.33070611953735 and batch: 200, loss is 5.263242712020874 and perplexity is 193.10666642650537
At time: 67.59803247451782 and batch: 250, loss is 5.267098636627197 and perplexity is 193.85270859003654
At time: 68.86534237861633 and batch: 300, loss is 5.249381036758423 and perplexity is 190.44835144028414
At time: 70.14360427856445 and batch: 350, loss is 5.219392280578614 and perplexity is 184.8218301186427
At time: 71.40538239479065 and batch: 400, loss is 5.169835729598999 and perplexity is 175.88594225655007
At time: 72.67028737068176 and batch: 450, loss is 5.1105928802490235 and perplexity is 165.76860667788208
At time: 73.9397439956665 and batch: 500, loss is 5.097077798843384 and perplexity is 163.54330192384924
At time: 75.20873355865479 and batch: 550, loss is 5.0457189083099365 and perplexity is 155.35594574212962
At time: 76.47617673873901 and batch: 600, loss is 5.031686248779297 and perplexity is 153.19111335138712
At time: 77.74320793151855 and batch: 650, loss is 5.098468675613403 and perplexity is 163.77092876713556
At time: 79.00909996032715 and batch: 700, loss is 5.08846736907959 and perplexity is 162.14116895579122
At time: 80.2766683101654 and batch: 750, loss is 5.018284826278687 and perplexity is 151.15182968986838
At time: 81.54651546478271 and batch: 800, loss is 5.018511142730713 and perplexity is 151.18604170690617
At time: 82.8141417503357 and batch: 850, loss is 5.008184938430786 and perplexity is 149.6328966008081
At time: 84.08130979537964 and batch: 900, loss is 5.0067306327819825 and perplexity is 149.4154427945104
At time: 85.34875631332397 and batch: 950, loss is 5.044974756240845 and perplexity is 155.24038029812505
At time: 86.61457347869873 and batch: 1000, loss is 5.006308717727661 and perplexity is 149.35241546687143
At time: 87.88096165657043 and batch: 1050, loss is 4.925315341949463 and perplexity is 137.7327677149438
At time: 89.14838361740112 and batch: 1100, loss is 4.9844393539428715 and perplexity is 146.12162954163352
At time: 90.41421031951904 and batch: 1150, loss is 4.9075164699554445 and perplexity is 135.30296780810738
At time: 91.67984747886658 and batch: 1200, loss is 4.978452243804932 and perplexity is 145.24939693384226
At time: 92.94523906707764 and batch: 1250, loss is 4.937947072982788 and perplexity is 139.4836057685426
At time: 94.21468472480774 and batch: 1300, loss is 4.949489727020263 and perplexity is 141.10294452831027
At time: 95.48208928108215 and batch: 1350, loss is 4.856985492706299 and perplexity is 128.63584335829523
At time: 96.74998497962952 and batch: 1400, loss is 4.862063665390014 and perplexity is 129.29073981547074
At time: 98.01913189888 and batch: 1450, loss is 4.812251806259155 and perplexity is 123.0082967388768
At time: 99.28709316253662 and batch: 1500, loss is 4.780166940689087 and perplexity is 119.12423506684705
At time: 100.55517983436584 and batch: 1550, loss is 4.780895223617554 and perplexity is 119.21102281279381
At time: 101.82081651687622 and batch: 1600, loss is 4.8362748908996585 and perplexity is 125.9991159805719
At time: 103.08661723136902 and batch: 1650, loss is 4.811578960418701 and perplexity is 122.9255589560826
At time: 104.35258626937866 and batch: 1700, loss is 4.819434404373169 and perplexity is 123.89499649097934
At time: 105.62030863761902 and batch: 1750, loss is 4.813219251632691 and perplexity is 123.12735812987296
At time: 106.8861494064331 and batch: 1800, loss is 4.778436250686646 and perplexity is 118.91824624698029
At time: 108.15653991699219 and batch: 1850, loss is 4.788898601531982 and perplexity is 120.16894186079502
At time: 109.42887306213379 and batch: 1900, loss is 4.881239356994629 and perplexity is 131.79390240433005
At time: 110.69816136360168 and batch: 1950, loss is 4.795378875732422 and perplexity is 120.95019819807125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614818200399709 and perplexity of 100.96947065439748
finished 2 epochs...
Completing Train Step...
At time: 114.57710838317871 and batch: 50, loss is 4.76265022277832 and perplexity is 117.05573896657219
At time: 115.85961318016052 and batch: 100, loss is 4.690701713562012 and perplexity is 108.9295903659822
At time: 117.1306734085083 and batch: 150, loss is 4.630306024551391 and perplexity is 102.54544073173751
At time: 118.39913749694824 and batch: 200, loss is 4.622689504623413 and perplexity is 101.76736820275994
At time: 119.66805267333984 and batch: 250, loss is 4.630090456008912 and perplexity is 102.52333754300274
At time: 120.93546390533447 and batch: 300, loss is 4.651788644790649 and perplexity is 104.7722183633036
At time: 122.1997435092926 and batch: 350, loss is 4.650261821746827 and perplexity is 104.61237178572587
At time: 123.467111825943 and batch: 400, loss is 4.60229866027832 and perplexity is 99.71325931767404
At time: 124.73568987846375 and batch: 450, loss is 4.595274124145508 and perplexity is 99.01527430526475
At time: 126.00319027900696 and batch: 500, loss is 4.597844409942627 and perplexity is 99.27009920463027
At time: 127.27045178413391 and batch: 550, loss is 4.570581178665162 and perplexity is 96.60023545763714
At time: 128.5373454093933 and batch: 600, loss is 4.535617256164551 and perplexity is 93.28107585690199
At time: 129.80443477630615 and batch: 650, loss is 4.604992895126343 and perplexity is 99.98227248533478
At time: 131.06952714920044 and batch: 700, loss is 4.635447082519531 and perplexity is 103.07399027467659
At time: 132.33613681793213 and batch: 750, loss is 4.580707292556763 and perplexity is 97.58338980941559
At time: 133.61298656463623 and batch: 800, loss is 4.577153167724609 and perplexity is 97.23718185806251
At time: 134.88212609291077 and batch: 850, loss is 4.5685021018981935 and perplexity is 96.39960478796539
At time: 136.1671323776245 and batch: 900, loss is 4.542717552185058 and perplexity is 93.9457560291472
At time: 137.4444441795349 and batch: 950, loss is 4.613526954650879 and perplexity is 100.83917839242122
At time: 138.7221324443817 and batch: 1000, loss is 4.583363494873047 and perplexity is 97.84293558590437
At time: 139.99447178840637 and batch: 1050, loss is 4.521389751434326 and perplexity is 91.96331535931976
At time: 141.25830507278442 and batch: 1100, loss is 4.564907007217407 and perplexity is 96.05366130395326
At time: 142.5235242843628 and batch: 1150, loss is 4.518755226135254 and perplexity is 91.72135454431192
At time: 143.79075002670288 and batch: 1200, loss is 4.585280036926269 and perplexity is 98.0306354964976
At time: 145.06799221038818 and batch: 1250, loss is 4.568703098297119 and perplexity is 96.41898270876653
At time: 146.33661818504333 and batch: 1300, loss is 4.566244707107544 and perplexity is 96.18223825564051
At time: 147.60491180419922 and batch: 1350, loss is 4.4530981826782225 and perplexity is 85.89264329684205
At time: 148.89435267448425 and batch: 1400, loss is 4.464722785949707 and perplexity is 86.89693714862699
At time: 150.16537404060364 and batch: 1450, loss is 4.413852233886718 and perplexity is 82.58699593126865
At time: 151.43219089508057 and batch: 1500, loss is 4.399652509689331 and perplexity is 81.42257019431842
At time: 152.70024633407593 and batch: 1550, loss is 4.405728158950805 and perplexity is 81.91877101749388
At time: 153.9712462425232 and batch: 1600, loss is 4.480981435775757 and perplexity is 88.32131184851511
At time: 155.2402548789978 and batch: 1650, loss is 4.455867977142334 and perplexity is 86.13087804308752
At time: 156.5106761455536 and batch: 1700, loss is 4.4607656288146975 and perplexity is 86.55375178082308
At time: 157.78061771392822 and batch: 1750, loss is 4.457842140197754 and perplexity is 86.3010823907402
At time: 159.049875497818 and batch: 1800, loss is 4.4180666446685795 and perplexity is 82.93578591324764
At time: 160.32086420059204 and batch: 1850, loss is 4.4511639022827145 and perplexity is 85.72666341835742
At time: 161.59041380882263 and batch: 1900, loss is 4.561160392761231 and perplexity is 95.69445858517352
At time: 162.8579592704773 and batch: 1950, loss is 4.471733360290528 and perplexity is 87.50827499737326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.478286530250727 and perplexity of 88.08361468679044
finished 3 epochs...
Completing Train Step...
At time: 166.7249116897583 and batch: 50, loss is 4.454338893890381 and perplexity is 85.9992773998069
At time: 168.01232075691223 and batch: 100, loss is 4.387085208892822 and perplexity is 80.40571123255502
At time: 169.2911765575409 and batch: 150, loss is 4.338007946014404 and perplexity is 76.55488587628115
At time: 170.5626184940338 and batch: 200, loss is 4.344176235198975 and perplexity is 77.0285579220895
At time: 171.828763961792 and batch: 250, loss is 4.340674705505371 and perplexity is 76.75931180100943
At time: 173.09667825698853 and batch: 300, loss is 4.361695051193237 and perplexity is 78.3898967598584
At time: 174.36125445365906 and batch: 350, loss is 4.367980489730835 and perplexity is 78.88416335181627
At time: 175.62776589393616 and batch: 400, loss is 4.3150325202941895 and perplexity is 74.81605644454746
At time: 176.8972511291504 and batch: 450, loss is 4.3311143970489505 and perplexity is 76.02896583242175
At time: 178.1692452430725 and batch: 500, loss is 4.3363141918182375 and perplexity is 76.42533046557384
At time: 179.43945455551147 and batch: 550, loss is 4.310903129577636 and perplexity is 74.50774871525557
At time: 180.70931005477905 and batch: 600, loss is 4.281614365577698 and perplexity is 72.35715667332624
At time: 181.97854900360107 and batch: 650, loss is 4.349817867279053 and perplexity is 77.46435284698596
At time: 183.2476921081543 and batch: 700, loss is 4.386502485275269 and perplexity is 80.35887057453797
At time: 184.51546239852905 and batch: 750, loss is 4.3325925636291505 and perplexity is 76.1414324105329
At time: 185.78108835220337 and batch: 800, loss is 4.330316648483277 and perplexity is 75.96833802006975
At time: 187.057284116745 and batch: 850, loss is 4.319778852462768 and perplexity is 75.17200235050925
At time: 188.32325172424316 and batch: 900, loss is 4.286446413993835 and perplexity is 72.70763604232975
At time: 189.58948612213135 and batch: 950, loss is 4.375091466903687 and perplexity is 79.44710600072925
At time: 190.85571789741516 and batch: 1000, loss is 4.340208797454834 and perplexity is 76.72355734947782
At time: 192.1206078529358 and batch: 1050, loss is 4.289383726119995 and perplexity is 72.9215150242294
At time: 193.387770652771 and batch: 1100, loss is 4.324214906692505 and perplexity is 75.50621016342402
At time: 194.65395140647888 and batch: 1150, loss is 4.289832515716553 and perplexity is 72.954248786274
At time: 195.92149138450623 and batch: 1200, loss is 4.3550820684432985 and perplexity is 77.87321600820069
At time: 197.20020079612732 and batch: 1250, loss is 4.346546592712403 and perplexity is 77.21135971031397
At time: 198.46620559692383 and batch: 1300, loss is 4.336385946273804 and perplexity is 76.43081452030322
At time: 199.73918223381042 and batch: 1350, loss is 4.2182671117782595 and perplexity is 67.91569195576093
At time: 201.00891828536987 and batch: 1400, loss is 4.241950793266296 and perplexity is 69.54338436373706
At time: 202.27838826179504 and batch: 1450, loss is 4.184926633834839 and perplexity is 65.68868141329582
At time: 203.54945540428162 and batch: 1500, loss is 4.181623468399048 and perplexity is 65.47205879845801
At time: 204.81731867790222 and batch: 1550, loss is 4.194734501838684 and perplexity is 66.33611712197084
At time: 206.08428764343262 and batch: 1600, loss is 4.269157319068909 and perplexity is 71.46139108774643
At time: 207.35172033309937 and batch: 1650, loss is 4.245584282875061 and perplexity is 69.79652914914809
At time: 208.61802649497986 and batch: 1700, loss is 4.244689497947693 and perplexity is 69.73410419949982
At time: 209.89525485038757 and batch: 1750, loss is 4.244066543579102 and perplexity is 69.69067656277139
At time: 211.16383457183838 and batch: 1800, loss is 4.197380986213684 and perplexity is 66.51190712958554
At time: 212.4320569038391 and batch: 1850, loss is 4.243407468795777 and perplexity is 69.64476032799433
At time: 213.6989459991455 and batch: 1900, loss is 4.347383861541748 and perplexity is 77.27603344594411
At time: 214.96636962890625 and batch: 1950, loss is 4.262914314270019 and perplexity is 71.01664699449935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.427040561409884 and perplexity of 83.6833942211211
finished 4 epochs...
Completing Train Step...
At time: 218.84084606170654 and batch: 50, loss is 4.2556574392318725 and perplexity is 70.50315349418874
At time: 220.12676358222961 and batch: 100, loss is 4.187668886184692 and perplexity is 65.8690635679152
At time: 221.39308547973633 and batch: 150, loss is 4.1500368642807 and perplexity is 63.436338790019406
At time: 222.65983843803406 and batch: 200, loss is 4.156752943992615 and perplexity is 63.863816177263764
At time: 223.92720317840576 and batch: 250, loss is 4.149198651313782 and perplexity is 63.38318790726332
At time: 225.19657588005066 and batch: 300, loss is 4.1694548797607425 and perplexity is 64.68018401821455
At time: 226.4824833869934 and batch: 350, loss is 4.174866518974304 and perplexity is 65.03115865589555
At time: 227.7737011909485 and batch: 400, loss is 4.125464072227478 and perplexity is 61.89652704546608
At time: 229.04244923591614 and batch: 450, loss is 4.150227437019348 and perplexity is 63.44842917884506
At time: 230.31208658218384 and batch: 500, loss is 4.160292930603028 and perplexity is 64.09029385889261
At time: 231.58203196525574 and batch: 550, loss is 4.135223031044006 and perplexity is 62.50352974352212
At time: 232.85013151168823 and batch: 600, loss is 4.1062778997421265 and perplexity is 60.72028943196636
At time: 234.11728048324585 and batch: 650, loss is 4.172184839248657 and perplexity is 64.85699954004842
At time: 235.38398504257202 and batch: 700, loss is 4.212320308685303 and perplexity is 67.5130092329299
At time: 236.65471529960632 and batch: 750, loss is 4.156735587120056 and perplexity is 63.86270771076504
At time: 237.92339968681335 and batch: 800, loss is 4.157857894897461 and perplexity is 63.93442155929253
At time: 239.18927884101868 and batch: 850, loss is 4.145119981765747 and perplexity is 63.12519531979752
At time: 240.45501255989075 and batch: 900, loss is 4.113105325698853 and perplexity is 61.1362711384133
At time: 241.72133326530457 and batch: 950, loss is 4.207358593940735 and perplexity is 67.17885860514392
At time: 242.99140739440918 and batch: 1000, loss is 4.174653463363647 and perplexity is 65.01730487854128
At time: 244.26120948791504 and batch: 1050, loss is 4.125704808235168 and perplexity is 61.911429561991085
At time: 245.52793169021606 and batch: 1100, loss is 4.15696310043335 and perplexity is 63.87723897995815
At time: 246.7929573059082 and batch: 1150, loss is 4.123229579925537 and perplexity is 61.75837414054997
At time: 248.06302571296692 and batch: 1200, loss is 4.191312918663025 and perplexity is 66.10953044332999
At time: 249.331369638443 and batch: 1250, loss is 4.188545160293579 and perplexity is 65.92680821927286
At time: 250.6013457775116 and batch: 1300, loss is 4.172057256698609 and perplexity is 64.84872544648482
At time: 251.87663221359253 and batch: 1350, loss is 4.0523530292510985 and perplexity is 57.53267396310557
At time: 253.14268469810486 and batch: 1400, loss is 4.082719383239746 and perplexity is 59.30652793938088
At time: 254.4087393283844 and batch: 1450, loss is 4.026573247909546 and perplexity is 56.06844900043837
At time: 255.67497777938843 and batch: 1500, loss is 4.027484889030457 and perplexity is 56.1195866101651
At time: 256.940123796463 and batch: 1550, loss is 4.040668416023254 and perplexity is 56.86433914080815
At time: 258.21061396598816 and batch: 1600, loss is 4.115519547462464 and perplexity is 61.28404596356613
At time: 259.4821226596832 and batch: 1650, loss is 4.0892834997177125 and perplexity is 59.69710338562704
At time: 260.7505931854248 and batch: 1700, loss is 4.086926145553589 and perplexity is 59.55654191205539
At time: 262.0185112953186 and batch: 1750, loss is 4.088335285186767 and perplexity is 59.64052455341609
At time: 263.28577613830566 and batch: 1800, loss is 4.043763761520386 and perplexity is 57.040626611476036
At time: 264.55461621284485 and batch: 1850, loss is 4.089627461433411 and perplexity is 59.71764043550675
At time: 265.8226294517517 and batch: 1900, loss is 4.192917833328247 and perplexity is 66.21571578466296
At time: 267.0904598236084 and batch: 1950, loss is 4.110465612411499 and perplexity is 60.975101725257524
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.415590082212936 and perplexity of 82.73064438737673
finished 5 epochs...
Completing Train Step...
At time: 271.00214886665344 and batch: 50, loss is 4.107916145324707 and perplexity is 60.81984570444694
At time: 272.2721014022827 and batch: 100, loss is 4.045791025161743 and perplexity is 57.15638029185585
At time: 273.54258036613464 and batch: 150, loss is 4.008204259872437 and perplexity is 55.047929977461386
At time: 274.81254506111145 and batch: 200, loss is 4.015549516677856 and perplexity is 55.45375979723917
At time: 276.08191680908203 and batch: 250, loss is 4.00529188156128 and perplexity is 54.88784281047169
At time: 277.35018157958984 and batch: 300, loss is 4.0231148147583005 and perplexity is 55.874874942087665
At time: 278.6250102519989 and batch: 350, loss is 4.0337229347229 and perplexity is 56.47075732640285
At time: 279.8932099342346 and batch: 400, loss is 3.986360855102539 and perplexity is 53.858533289321
At time: 281.1622095108032 and batch: 450, loss is 4.017073726654052 and perplexity is 55.53834741941223
At time: 282.43103289604187 and batch: 500, loss is 4.027403426170349 and perplexity is 56.11501513433707
At time: 283.70031332969666 and batch: 550, loss is 4.000707235336304 and perplexity is 54.636777431865085
At time: 284.96961069107056 and batch: 600, loss is 3.9728366231918333 and perplexity is 53.13504135855593
At time: 286.23801445961 and batch: 650, loss is 4.039493985176087 and perplexity is 56.79759510761472
At time: 287.50791597366333 and batch: 700, loss is 4.080424313545227 and perplexity is 59.170571398965414
At time: 288.7767457962036 and batch: 750, loss is 4.023966813087464 and perplexity is 55.92250052775928
At time: 290.04524326324463 and batch: 800, loss is 4.025516877174377 and perplexity is 56.00925120466251
At time: 291.32447028160095 and batch: 850, loss is 4.017269968986511 and perplexity is 55.549247463740805
At time: 292.5930812358856 and batch: 900, loss is 3.9795089244842528 and perplexity is 53.490759774205
At time: 293.8633396625519 and batch: 950, loss is 4.0828004074096675 and perplexity is 59.31133339625456
At time: 295.1332368850708 and batch: 1000, loss is 4.045989379882813 and perplexity is 57.16771865419766
At time: 296.4003372192383 and batch: 1050, loss is 4.00220377445221 and perplexity is 54.71860472005579
At time: 297.66555166244507 and batch: 1100, loss is 4.028543839454651 and perplexity is 56.179045946900104
At time: 298.93335700035095 and batch: 1150, loss is 3.999573202133179 and perplexity is 54.57485263117209
At time: 300.2025499343872 and batch: 1200, loss is 4.066090731620789 and perplexity is 58.32849457201329
At time: 301.4712677001953 and batch: 1250, loss is 4.065015172958374 and perplexity is 58.26579258029051
At time: 302.7415463924408 and batch: 1300, loss is 4.04459310054779 and perplexity is 57.087952251059946
At time: 304.0101068019867 and batch: 1350, loss is 3.9250919818878174 and perplexity is 50.657737438868246
At time: 305.2783143520355 and batch: 1400, loss is 3.961360659599304 and perplexity is 52.52875109484093
At time: 306.5465602874756 and batch: 1450, loss is 3.902631311416626 and perplexity is 49.53261351031032
At time: 307.8151614665985 and batch: 1500, loss is 3.90339551448822 and perplexity is 49.57048095306413
At time: 309.0834300518036 and batch: 1550, loss is 3.920927057266235 and perplexity is 50.44719054127029
At time: 310.3498613834381 and batch: 1600, loss is 3.997258701324463 and perplexity is 54.44868515430767
At time: 311.6174416542053 and batch: 1650, loss is 3.969190535545349 and perplexity is 52.941659099231
At time: 312.882132768631 and batch: 1700, loss is 3.9711133575439455 and perplexity is 53.043554417874994
At time: 314.14849877357483 and batch: 1750, loss is 3.9668819808959963 and perplexity is 52.81958135176578
At time: 315.41787576675415 and batch: 1800, loss is 3.924217643737793 and perplexity is 50.61346480387882
At time: 316.68731331825256 and batch: 1850, loss is 3.9697462511062622 and perplexity is 52.97108777924337
At time: 317.9540591239929 and batch: 1900, loss is 4.072168607711792 and perplexity is 58.68408746471716
At time: 319.22601413726807 and batch: 1950, loss is 3.989845142364502 and perplexity is 54.04651919908132
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.423011957212936 and perplexity of 83.34694511312888
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 323.1219766139984 and batch: 50, loss is 4.03359766960144 and perplexity is 56.46368395316017
At time: 324.39198994636536 and batch: 100, loss is 4.015315732955933 and perplexity is 55.4407971261689
At time: 325.661661863327 and batch: 150, loss is 3.982681293487549 and perplexity is 53.66072165082974
At time: 326.92818427085876 and batch: 200, loss is 3.9901620292663575 and perplexity is 54.063648546996056
At time: 328.19575357437134 and batch: 250, loss is 3.969235744476318 and perplexity is 52.94405258914576
At time: 329.4652273654938 and batch: 300, loss is 3.986116623878479 and perplexity is 53.84538095997981
At time: 330.7335114479065 and batch: 350, loss is 3.9985678005218506 and perplexity is 54.52001056017166
At time: 332.0004508495331 and batch: 400, loss is 3.9485181999206542 and perplexity is 51.85846599404185
At time: 333.2665436267853 and batch: 450, loss is 3.971917862892151 and perplexity is 53.08624541135572
At time: 334.53501415252686 and batch: 500, loss is 3.9771989679336546 and perplexity is 53.36734104409929
At time: 335.8030414581299 and batch: 550, loss is 3.9478635025024413 and perplexity is 51.82452550183171
At time: 337.0713720321655 and batch: 600, loss is 3.9099247360229494 and perplexity is 49.895196521158596
At time: 338.3365545272827 and batch: 650, loss is 3.9667048549652097 and perplexity is 52.81022646277626
At time: 339.6062686443329 and batch: 700, loss is 4.007402477264404 and perplexity is 55.00381119379747
At time: 340.87819623947144 and batch: 750, loss is 3.9331798219680785 and perplexity is 51.06911043517397
At time: 342.1491689682007 and batch: 800, loss is 3.9350627040863038 and perplexity is 51.16535813310557
At time: 343.4183316230774 and batch: 850, loss is 3.920171813964844 and perplexity is 50.40910502226684
At time: 344.686625957489 and batch: 900, loss is 3.8789316844940185 and perplexity is 48.372510354912166
At time: 345.95327162742615 and batch: 950, loss is 3.9788348388671877 and perplexity is 53.45471457253622
At time: 347.2205276489258 and batch: 1000, loss is 3.930197596549988 and perplexity is 50.91703770624074
At time: 348.4878330230713 and batch: 1050, loss is 3.875458025932312 and perplexity is 48.20477227124667
At time: 349.75366377830505 and batch: 1100, loss is 3.8967128944396974 and perplexity is 49.24032464646863
At time: 351.0215404033661 and batch: 1150, loss is 3.8738452339172365 and perplexity is 48.12709065841963
At time: 352.29032945632935 and batch: 1200, loss is 3.915953164100647 and perplexity is 50.196894593684
At time: 353.5589134693146 and batch: 1250, loss is 3.9153819942474364 and perplexity is 50.1682318272006
At time: 354.8285663127899 and batch: 1300, loss is 3.8984326314926148 and perplexity is 49.325077913039166
At time: 356.09656739234924 and batch: 1350, loss is 3.771232442855835 and perplexity is 43.43356124570692
At time: 357.3645284175873 and batch: 1400, loss is 3.7954101276397707 and perplexity is 44.496481900882124
At time: 358.6329576969147 and batch: 1450, loss is 3.727074594497681 and perplexity is 41.55735804273994
At time: 359.91709780693054 and batch: 1500, loss is 3.718315715789795 and perplexity is 41.194951638014636
At time: 361.1996920108795 and batch: 1550, loss is 3.728291220664978 and perplexity is 41.60794858062432
At time: 362.47082901000977 and batch: 1600, loss is 3.7980386877059935 and perplexity is 44.613597431465145
At time: 363.7424428462982 and batch: 1650, loss is 3.7731461238861086 and perplexity is 43.51675880934937
At time: 365.01252841949463 and batch: 1700, loss is 3.756336317062378 and perplexity is 42.79136445080774
At time: 366.2803256511688 and batch: 1750, loss is 3.742813663482666 and perplexity is 42.21660653764167
At time: 367.54829502105713 and batch: 1800, loss is 3.69168092250824 and perplexity is 40.11221584695517
At time: 368.81834602355957 and batch: 1850, loss is 3.7289401721954345 and perplexity is 41.634958885776385
At time: 370.08963680267334 and batch: 1900, loss is 3.8198727798461913 and perplexity is 45.5984069154875
At time: 371.36018919944763 and batch: 1950, loss is 3.7309073638916015 and perplexity is 41.71694344439926
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.353828465661337 and perplexity of 77.77565509206704
finished 7 epochs...
Completing Train Step...
At time: 375.2485361099243 and batch: 50, loss is 3.949778823852539 and perplexity is 51.92388124069448
At time: 376.5181667804718 and batch: 100, loss is 3.9082059907913207 and perplexity is 49.80951304518258
At time: 377.78857707977295 and batch: 150, loss is 3.8680808782577514 and perplexity is 47.850467035447224
At time: 379.0572075843811 and batch: 200, loss is 3.8765510940551757 and perplexity is 48.257492179162526
At time: 380.3265268802643 and batch: 250, loss is 3.8564311170578005 and perplexity is 47.29625500804716
At time: 381.5949921607971 and batch: 300, loss is 3.869912781715393 and perplexity is 47.93820481048958
At time: 382.8613440990448 and batch: 350, loss is 3.8850810813903807 and perplexity is 48.670888602827844
At time: 384.1272406578064 and batch: 400, loss is 3.838314905166626 and perplexity is 46.447140621682564
At time: 385.4062166213989 and batch: 450, loss is 3.8672659397125244 and perplexity is 47.81148773047923
At time: 386.67845344543457 and batch: 500, loss is 3.871751503944397 and perplexity is 48.02643094010906
At time: 387.94893860816956 and batch: 550, loss is 3.84622407913208 and perplexity is 46.815955725865976
At time: 389.2146317958832 and batch: 600, loss is 3.8102308034896852 and perplexity is 45.16086094785001
At time: 390.48157024383545 and batch: 650, loss is 3.8670623302459717 and perplexity is 47.80175384995607
At time: 391.74882888793945 and batch: 700, loss is 3.9089067792892456 and perplexity is 49.84443121270793
At time: 393.0158472061157 and batch: 750, loss is 3.838929142951965 and perplexity is 46.47567897424334
At time: 394.2832863330841 and batch: 800, loss is 3.843090744018555 and perplexity is 46.669495222662114
At time: 395.55696725845337 and batch: 850, loss is 3.83143319606781 and perplexity is 46.1286022128941
At time: 396.82776927948 and batch: 900, loss is 3.7931774425506593 and perplexity is 44.397246091603186
At time: 398.1038656234741 and batch: 950, loss is 3.896197509765625 and perplexity is 49.21495347631722
At time: 399.37322640419006 and batch: 1000, loss is 3.8515553998947145 and perplexity is 47.066213111092004
At time: 400.6445109844208 and batch: 1050, loss is 3.79940288066864 and perplexity is 44.674500519456345
At time: 401.9093441963196 and batch: 1100, loss is 3.820249094963074 and perplexity is 45.615569514385726
At time: 403.1769244670868 and batch: 1150, loss is 3.800258240699768 and perplexity is 44.71272964911523
At time: 404.4481415748596 and batch: 1200, loss is 3.846269783973694 and perplexity is 46.81809549060587
At time: 405.7196509838104 and batch: 1250, loss is 3.8485330724716187 and perplexity is 46.924178350398805
At time: 406.99527192115784 and batch: 1300, loss is 3.8339033126831055 and perplexity is 46.24268608188403
At time: 408.2685434818268 and batch: 1350, loss is 3.707590537071228 and perplexity is 40.7554892881006
At time: 409.53665041923523 and batch: 1400, loss is 3.7359704065322874 and perplexity is 41.92869370585808
At time: 410.8037133216858 and batch: 1450, loss is 3.6712145614624023 and perplexity is 39.29960867562473
At time: 412.0865669250488 and batch: 1500, loss is 3.66392409324646 and perplexity is 39.01413799953954
At time: 413.3708610534668 and batch: 1550, loss is 3.6770596075057984 and perplexity is 39.52998933469692
At time: 414.64064383506775 and batch: 1600, loss is 3.7523006200790405 and perplexity is 42.6190194703526
At time: 415.90745782852173 and batch: 1650, loss is 3.730512056350708 and perplexity is 41.70045568115595
At time: 417.17520093917847 and batch: 1700, loss is 3.7185361433029174 and perplexity is 41.204033139627036
At time: 418.4435143470764 and batch: 1750, loss is 3.7081492710113526 and perplexity is 40.77826712599523
At time: 419.7093198299408 and batch: 1800, loss is 3.66078595161438 and perplexity is 38.891898012357494
At time: 420.98148679733276 and batch: 1850, loss is 3.7027584218978884 and perplexity is 40.55902911128312
At time: 422.2526276111603 and batch: 1900, loss is 3.797598557472229 and perplexity is 44.59396595891777
At time: 423.52237486839294 and batch: 1950, loss is 3.7098519086837767 and perplexity is 40.84775688097003
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360558514262355 and perplexity of 78.30085435675731
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 427.3984520435333 and batch: 50, loss is 3.9170887994766237 and perplexity is 50.253932343862225
At time: 428.6807076931 and batch: 100, loss is 3.9091886138916014 and perplexity is 49.858481077934506
At time: 429.9498345851898 and batch: 150, loss is 3.8932914400100707 and perplexity is 49.07213900341739
At time: 431.21749472618103 and batch: 200, loss is 3.912715907096863 and perplexity is 50.034657089026645
At time: 432.48508882522583 and batch: 250, loss is 3.899821915626526 and perplexity is 49.39365208466236
At time: 433.753919839859 and batch: 300, loss is 3.9063454151153563 and perplexity is 49.716924837172634
At time: 435.04168224334717 and batch: 350, loss is 3.9205558490753174 and perplexity is 50.428467606201
At time: 436.30598759651184 and batch: 400, loss is 3.866099338531494 and perplexity is 47.75574331449895
At time: 437.57269501686096 and batch: 450, loss is 3.9015378761291504 and perplexity is 49.478482402642165
At time: 438.8435559272766 and batch: 500, loss is 3.899127511978149 and perplexity is 49.35936485841338
At time: 440.1167063713074 and batch: 550, loss is 3.876273126602173 and perplexity is 48.24408003112986
At time: 441.3952782154083 and batch: 600, loss is 3.836536922454834 and perplexity is 46.364631780027786
At time: 442.6755886077881 and batch: 650, loss is 3.886361017227173 and perplexity is 48.73322410156848
At time: 443.95338916778564 and batch: 700, loss is 3.9278882551193237 and perplexity is 50.79958854883856
At time: 445.23040890693665 and batch: 750, loss is 3.855247163772583 and perplexity is 47.240291587127125
At time: 446.5010361671448 and batch: 800, loss is 3.8563396453857424 and perplexity is 47.291928938378916
At time: 447.7727472782135 and batch: 850, loss is 3.839226064682007 and perplexity is 46.48948066215836
At time: 449.05657148361206 and batch: 900, loss is 3.797795867919922 and perplexity is 44.602765682415665
At time: 450.32756876945496 and batch: 950, loss is 3.9075197410583495 and perplexity is 49.775343006087
At time: 451.59854555130005 and batch: 1000, loss is 3.8563278007507322 and perplexity is 47.291368786059124
At time: 452.8677625656128 and batch: 1050, loss is 3.797887053489685 and perplexity is 44.60683299645478
At time: 454.13685750961304 and batch: 1100, loss is 3.812348475456238 and perplexity is 45.25659817130372
At time: 455.40491914749146 and batch: 1150, loss is 3.79108980178833 and perplexity is 44.30465727065262
At time: 456.6763198375702 and batch: 1200, loss is 3.8257068014144897 and perplexity is 45.865206505465814
At time: 457.9467089176178 and batch: 1250, loss is 3.823850884437561 and perplexity is 45.78016343091529
At time: 459.2157988548279 and batch: 1300, loss is 3.8132897663116454 and perplexity is 45.299217848918765
At time: 460.48251152038574 and batch: 1350, loss is 3.68352059841156 and perplexity is 39.78621909401972
At time: 461.7496178150177 and batch: 1400, loss is 3.708854732513428 and perplexity is 40.80704477314155
At time: 463.01672625541687 and batch: 1450, loss is 3.6362250375747682 and perplexity is 37.94831254269
At time: 464.28373885154724 and batch: 1500, loss is 3.6285138845443727 and perplexity is 37.65681264202549
At time: 465.5492548942566 and batch: 1550, loss is 3.6400213766098024 and perplexity is 38.092651008432625
At time: 466.8143901824951 and batch: 1600, loss is 3.709519872665405 and perplexity is 40.834196205856735
At time: 468.0812063217163 and batch: 1650, loss is 3.6868736267089846 and perplexity is 39.919847316899585
At time: 469.35369300842285 and batch: 1700, loss is 3.668921322822571 and perplexity is 39.20958855274251
At time: 470.6249530315399 and batch: 1750, loss is 3.6579180097579957 and perplexity is 38.78051810206944
At time: 471.89495372772217 and batch: 1800, loss is 3.606318640708923 and perplexity is 36.83021767522255
At time: 473.1620807647705 and batch: 1850, loss is 3.642027735710144 and perplexity is 38.16915526728367
At time: 474.4293591976166 and batch: 1900, loss is 3.7430135297775267 and perplexity is 42.225045057631704
At time: 475.697993516922 and batch: 1950, loss is 3.660618281364441 and perplexity is 38.88537754475665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330176632903343 and perplexity of 75.95770201378593
finished 9 epochs...
Completing Train Step...
At time: 479.5756697654724 and batch: 50, loss is 3.915378384590149 and perplexity is 50.16805073740383
At time: 480.85623812675476 and batch: 100, loss is 3.8787674474716187 and perplexity is 48.364566450204954
At time: 482.12688398361206 and batch: 150, loss is 3.851564860343933 and perplexity is 47.06665838071728
At time: 483.39701437950134 and batch: 200, loss is 3.8599210929870607 and perplexity is 47.46160616752216
At time: 484.666836977005 and batch: 250, loss is 3.8432730865478515 and perplexity is 46.67800583236148
At time: 485.93676018714905 and batch: 300, loss is 3.849379620552063 and perplexity is 46.96391874221065
At time: 487.20797538757324 and batch: 350, loss is 3.8654830121994017 and perplexity is 47.726319260726555
At time: 488.4800503253937 and batch: 400, loss is 3.8125167655944825 and perplexity is 45.26421505137137
At time: 489.7520022392273 and batch: 450, loss is 3.8495373058319093 and perplexity is 46.971324844781535
At time: 491.0222930908203 and batch: 500, loss is 3.8490092420578 and perplexity is 46.94652753756514
At time: 492.2922947406769 and batch: 550, loss is 3.8272078132629392 and perplexity is 45.93410241771698
At time: 493.5610542297363 and batch: 600, loss is 3.79073805809021 and perplexity is 44.28907612710548
At time: 494.82906222343445 and batch: 650, loss is 3.8409377193450926 and perplexity is 46.56912273893987
At time: 496.1006214618683 and batch: 700, loss is 3.884060091972351 and perplexity is 48.6212214997061
At time: 497.36938071250916 and batch: 750, loss is 3.812881212234497 and perplexity is 45.2807144488521
At time: 498.63844418525696 and batch: 800, loss is 3.8157737398147584 and perplexity is 45.41187977245549
At time: 499.90839171409607 and batch: 850, loss is 3.7999776363372804 and perplexity is 44.70018482226584
At time: 501.18429374694824 and batch: 900, loss is 3.758712582588196 and perplexity is 42.89316900437597
At time: 502.455561876297 and batch: 950, loss is 3.869221067428589 and perplexity is 47.90505673515876
At time: 503.7262635231018 and batch: 1000, loss is 3.8201855325698855 and perplexity is 45.6126701717663
At time: 504.99676275253296 and batch: 1050, loss is 3.765176463127136 and perplexity is 43.17132333445676
At time: 506.2641136646271 and batch: 1100, loss is 3.780999264717102 and perplexity is 43.85984744322732
At time: 507.53249168395996 and batch: 1150, loss is 3.761880249977112 and perplexity is 43.02925572197462
At time: 508.8041195869446 and batch: 1200, loss is 3.7988379287719725 and perplexity is 44.64926870370739
At time: 510.0842227935791 and batch: 1250, loss is 3.800182342529297 and perplexity is 44.709336163519396
At time: 511.35328340530396 and batch: 1300, loss is 3.7901857709884643 and perplexity is 44.264622594919025
At time: 512.6374845504761 and batch: 1350, loss is 3.6629564428329466 and perplexity is 38.976404212273174
At time: 513.9294629096985 and batch: 1400, loss is 3.689256019592285 and perplexity is 40.01506545552115
At time: 515.2093436717987 and batch: 1450, loss is 3.6209067630767824 and perplexity is 37.371439504406176
At time: 516.4808623790741 and batch: 1500, loss is 3.6151301717758177 and perplexity is 37.156182297092386
At time: 517.7518656253815 and batch: 1550, loss is 3.629739327430725 and perplexity is 37.702987201564724
At time: 519.0234048366547 and batch: 1600, loss is 3.7025753593444826 and perplexity is 40.551604951413914
At time: 520.2940504550934 and batch: 1650, loss is 3.681166353225708 and perplexity is 39.69266274975202
At time: 521.5629031658173 and batch: 1700, loss is 3.666158061027527 and perplexity is 39.101391751584565
At time: 522.8319656848907 and batch: 1750, loss is 3.6566526889801025 and perplexity is 38.731479338163616
At time: 524.1039807796478 and batch: 1800, loss is 3.6075176906585695 and perplexity is 36.87440543224126
At time: 525.374359369278 and batch: 1850, loss is 3.6448223304748537 and perplexity is 38.275971773674186
At time: 526.644332408905 and batch: 1900, loss is 3.7462238121032714 and perplexity is 42.360817190318315
At time: 527.9142444133759 and batch: 1950, loss is 3.663420786857605 and perplexity is 38.99450687527825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330692734829215 and perplexity of 75.99691404791287
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 531.8055467605591 and batch: 50, loss is 3.9099401807785035 and perplexity is 49.89596714622323
At time: 533.0841507911682 and batch: 100, loss is 3.890893087387085 and perplexity is 48.95458773117126
At time: 534.3538501262665 and batch: 150, loss is 3.8780165910720825 and perplexity is 48.328265236179966
At time: 535.6267580986023 and batch: 200, loss is 3.89233190536499 and perplexity is 49.02507516923612
At time: 536.8975582122803 and batch: 250, loss is 3.8817959880828856 and perplexity is 48.51126252923675
At time: 538.1660287380219 and batch: 300, loss is 3.884530825614929 and perplexity is 48.64411453224682
At time: 539.434814453125 and batch: 350, loss is 3.9072701072692873 and perplexity is 49.76291894940721
At time: 540.7037341594696 and batch: 400, loss is 3.8552525091171264 and perplexity is 47.24054410343688
At time: 541.9726114273071 and batch: 450, loss is 3.895264048576355 and perplexity is 49.169034662364965
At time: 543.2440893650055 and batch: 500, loss is 3.88541232585907 and perplexity is 48.687013235914044
At time: 544.5276212692261 and batch: 550, loss is 3.8669497776031494 and perplexity is 47.796373938996
At time: 545.798876285553 and batch: 600, loss is 3.824147925376892 and perplexity is 45.79376403353141
At time: 547.0688982009888 and batch: 650, loss is 3.8614399337768557 and perplexity is 47.53374756269695
At time: 548.3385791778564 and batch: 700, loss is 3.901852221488953 and perplexity is 49.49403817881044
At time: 549.6059863567352 and batch: 750, loss is 3.8361751556396486 and perplexity is 46.347861628476544
At time: 550.8725080490112 and batch: 800, loss is 3.8363987493515013 and perplexity is 46.35822587754176
At time: 552.1409585475922 and batch: 850, loss is 3.8233925199508665 and perplexity is 45.75918423822923
At time: 553.4083671569824 and batch: 900, loss is 3.77557222366333 and perplexity is 43.62246298078798
At time: 554.674902677536 and batch: 950, loss is 3.890309829711914 and perplexity is 48.9260429174423
At time: 555.9413855075836 and batch: 1000, loss is 3.84238064289093 and perplexity is 46.636366925091615
At time: 557.2128257751465 and batch: 1050, loss is 3.788959460258484 and perplexity is 44.210373683082146
At time: 558.4813632965088 and batch: 1100, loss is 3.8037860059738158 and perplexity is 44.87074421936019
At time: 559.7505631446838 and batch: 1150, loss is 3.787141857147217 and perplexity is 44.13008975458731
At time: 561.0279448032379 and batch: 1200, loss is 3.8200604343414306 and perplexity is 45.606964464427094
At time: 562.2982702255249 and batch: 1250, loss is 3.809421491622925 and perplexity is 45.12432651304175
At time: 563.5691449642181 and batch: 1300, loss is 3.7915188217163087 and perplexity is 44.32366892942263
At time: 564.8413627147675 and batch: 1350, loss is 3.6585185670852662 and perplexity is 38.803815021238535
At time: 566.1118407249451 and batch: 1400, loss is 3.683372597694397 and perplexity is 39.780331140781996
At time: 567.3825581073761 and batch: 1450, loss is 3.6092609405517577 and perplexity is 36.9387427973318
At time: 568.6506435871124 and batch: 1500, loss is 3.602741503715515 and perplexity is 36.69870629844064
At time: 569.9191815853119 and batch: 1550, loss is 3.6197918319702147 and perplexity is 37.32979614305878
At time: 571.1853942871094 and batch: 1600, loss is 3.689514718055725 and perplexity is 40.02541863058645
At time: 572.4555141925812 and batch: 1650, loss is 3.666494574546814 and perplexity is 39.11455211272744
At time: 573.7273366451263 and batch: 1700, loss is 3.6450189542770386 and perplexity is 38.28349848071728
At time: 575.0017292499542 and batch: 1750, loss is 3.637792067527771 and perplexity is 38.007825302070366
At time: 576.2730166912079 and batch: 1800, loss is 3.5895680665969847 and perplexity is 36.21842859830156
At time: 577.5454556941986 and batch: 1850, loss is 3.6242245769500734 and perplexity is 37.4956369028553
At time: 578.8145716190338 and batch: 1900, loss is 3.7303365325927733 and perplexity is 41.69313690279573
At time: 580.0859272480011 and batch: 1950, loss is 3.659763536453247 and perplexity is 38.85215466674606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315240336573401 and perplexity of 74.83160605469817
finished 11 epochs...
Completing Train Step...
At time: 583.9785335063934 and batch: 50, loss is 3.9208270692825318 and perplexity is 50.4421466805715
At time: 585.246256351471 and batch: 100, loss is 3.886343016624451 and perplexity is 48.73234688205732
At time: 586.5148777961731 and batch: 150, loss is 3.8630724716186524 and perplexity is 47.61141158183151
At time: 587.7844276428223 and batch: 200, loss is 3.8678953552246096 and perplexity is 47.84159049509236
At time: 589.0508465766907 and batch: 250, loss is 3.8558973979949953 and perplexity is 47.271018830263706
At time: 590.3181731700897 and batch: 300, loss is 3.85424919128418 and perplexity is 47.19317059241805
At time: 591.5855123996735 and batch: 350, loss is 3.874155516624451 and perplexity is 48.14202597936556
At time: 592.8556966781616 and batch: 400, loss is 3.8242097902297973 and perplexity is 45.79659714564146
At time: 594.1275670528412 and batch: 450, loss is 3.863471260070801 and perplexity is 47.63040224933861
At time: 595.3971507549286 and batch: 500, loss is 3.8547642707824705 and perplexity is 47.21748508846118
At time: 596.666424036026 and batch: 550, loss is 3.837760362625122 and perplexity is 46.42139084660936
At time: 597.9382917881012 and batch: 600, loss is 3.797853798866272 and perplexity is 44.60534963768625
At time: 599.2086009979248 and batch: 650, loss is 3.83770525932312 and perplexity is 46.418832945165235
At time: 600.4769339561462 and batch: 700, loss is 3.8808977508544924 and perplexity is 48.467707471552245
At time: 601.7446086406708 and batch: 750, loss is 3.8154221963882446 and perplexity is 45.39591833037025
At time: 603.0109436511993 and batch: 800, loss is 3.8165942811965943 and perplexity is 45.44915739085846
At time: 604.2778627872467 and batch: 850, loss is 3.8038293504714966 and perplexity is 44.87268916137991
At time: 605.5441670417786 and batch: 900, loss is 3.757120804786682 and perplexity is 42.82494692172145
At time: 606.8242871761322 and batch: 950, loss is 3.8715502214431763 and perplexity is 48.01676503278636
At time: 608.0939629077911 and batch: 1000, loss is 3.8248150634765623 and perplexity is 45.82432499130165
At time: 609.3634626865387 and batch: 1050, loss is 3.772133984565735 and perplexity is 43.47273606899463
At time: 610.6471104621887 and batch: 1100, loss is 3.7881176900863647 and perplexity is 44.17317436805094
At time: 611.9217612743378 and batch: 1150, loss is 3.7724413681030273 and perplexity is 43.48610092634663
At time: 613.1907818317413 and batch: 1200, loss is 3.806554436683655 and perplexity is 44.99513787378868
At time: 614.4674656391144 and batch: 1250, loss is 3.79805609703064 and perplexity is 44.61437413082736
At time: 615.7331783771515 and batch: 1300, loss is 3.7822451543807984 and perplexity is 43.914526028477376
At time: 617.0005495548248 and batch: 1350, loss is 3.6507302379608153 and perplexity is 38.50277197146761
At time: 618.2680509090424 and batch: 1400, loss is 3.677460970878601 and perplexity is 39.5458584089627
At time: 619.5383596420288 and batch: 1450, loss is 3.60576877117157 and perplexity is 36.80997142737646
At time: 620.8097717761993 and batch: 1500, loss is 3.6015795850753785 and perplexity is 36.65609015056639
At time: 622.0803627967834 and batch: 1550, loss is 3.620697865486145 and perplexity is 37.36363351608951
At time: 623.3503677845001 and batch: 1600, loss is 3.6916257762908935 and perplexity is 40.11000387097345
At time: 624.6190495491028 and batch: 1650, loss is 3.669989275932312 and perplexity is 39.251484922466254
At time: 625.886203289032 and batch: 1700, loss is 3.6508130121231077 and perplexity is 38.50595913806919
At time: 627.1570417881012 and batch: 1750, loss is 3.644512724876404 and perplexity is 38.26412315282128
At time: 628.4273235797882 and batch: 1800, loss is 3.5968265533447266 and perplexity is 36.48227599029264
At time: 629.6966366767883 and batch: 1850, loss is 3.6318358421325683 and perplexity is 37.78211498583472
At time: 630.9652497768402 and batch: 1900, loss is 3.7381359004974364 and perplexity is 42.01958841950176
At time: 632.2332675457001 and batch: 1950, loss is 3.6667493057250975 and perplexity is 39.12451707781492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313774641170058 and perplexity of 74.72200605340885
finished 12 epochs...
Completing Train Step...
At time: 636.1322522163391 and batch: 50, loss is 3.916250157356262 and perplexity is 50.21180494685872
At time: 637.4022209644318 and batch: 100, loss is 3.879030156135559 and perplexity is 48.377273909945934
At time: 638.6927027702332 and batch: 150, loss is 3.8538335275650026 and perplexity is 47.17355817997637
At time: 639.9635424613953 and batch: 200, loss is 3.857730107307434 and perplexity is 47.357732302705365
At time: 641.2313084602356 and batch: 250, loss is 3.844950008392334 and perplexity is 46.75634686753689
At time: 642.5067534446716 and batch: 300, loss is 3.8425745439529417 and perplexity is 46.645410642931665
At time: 643.7780342102051 and batch: 350, loss is 3.862153506278992 and perplexity is 47.567678442512815
At time: 645.0481135845184 and batch: 400, loss is 3.8121782445907595 and perplexity is 45.24889475712644
At time: 646.319452047348 and batch: 450, loss is 3.8513012456893922 and perplexity is 47.05425255507841
At time: 647.589700460434 and batch: 500, loss is 3.8424048709869383 and perplexity is 46.63749684915484
At time: 648.8577523231506 and batch: 550, loss is 3.825441150665283 and perplexity is 45.85302399721298
At time: 650.1247942447662 and batch: 600, loss is 3.786594066619873 and perplexity is 44.10592232939655
At time: 651.3922152519226 and batch: 650, loss is 3.82689612865448 and perplexity is 45.919787695945104
At time: 652.6584529876709 and batch: 700, loss is 3.8707103824615476 and perplexity is 47.976455610821354
At time: 653.9260470867157 and batch: 750, loss is 3.8056916999816894 and perplexity is 44.95633565738983
At time: 655.2006177902222 and batch: 800, loss is 3.806907711029053 and perplexity is 45.01103630975657
At time: 656.4734756946564 and batch: 850, loss is 3.7941964149475096 and perplexity is 44.44250871663309
At time: 657.743688583374 and batch: 900, loss is 3.7477029609680175 and perplexity is 42.42352150805282
At time: 659.0157468318939 and batch: 950, loss is 3.8622662448883056 and perplexity is 47.573041458732526
At time: 660.287398815155 and batch: 1000, loss is 3.816053714752197 and perplexity is 45.42459574064689
At time: 661.5574371814728 and batch: 1050, loss is 3.7639751958847047 and perplexity is 43.11949417449134
At time: 662.822511434555 and batch: 1100, loss is 3.7804569101333616 and perplexity is 43.83606630341236
At time: 664.0915365219116 and batch: 1150, loss is 3.765286016464233 and perplexity is 43.17605315607409
At time: 665.3591327667236 and batch: 1200, loss is 3.800048565864563 and perplexity is 44.70335549769066
At time: 666.6378531455994 and batch: 1250, loss is 3.7924256420135496 and perplexity is 44.3638807617533
At time: 667.9062314033508 and batch: 1300, loss is 3.777311372756958 and perplexity is 43.698394957117834
At time: 669.1783354282379 and batch: 1350, loss is 3.6467967796325684 and perplexity is 38.35162039150228
At time: 670.4490976333618 and batch: 1400, loss is 3.673982343673706 and perplexity is 39.408532102054295
At time: 671.719006061554 and batch: 1450, loss is 3.6033518362045287 and perplexity is 36.72111154782966
At time: 672.9863817691803 and batch: 1500, loss is 3.599922595024109 and perplexity is 36.59540166786011
At time: 674.2525005340576 and batch: 1550, loss is 3.61988347530365 and perplexity is 37.33321732677573
At time: 675.520870923996 and batch: 1600, loss is 3.6914710187911988 and perplexity is 40.10379702735182
At time: 676.7928965091705 and batch: 1650, loss is 3.670262188911438 and perplexity is 39.262198624039186
At time: 678.0639641284943 and batch: 1700, loss is 3.651767678260803 and perplexity is 38.54273702586659
At time: 679.3348653316498 and batch: 1750, loss is 3.645758318901062 and perplexity is 38.3118144117867
At time: 680.6064627170563 and batch: 1800, loss is 3.598425784111023 and perplexity is 36.54066624578274
At time: 681.8757054805756 and batch: 1850, loss is 3.6335016250610352 and perplexity is 37.845104236623435
At time: 683.1429705619812 and batch: 1900, loss is 3.7396728944778443 and perplexity is 42.08422193189758
At time: 684.4214236736298 and batch: 1950, loss is 3.6677110958099366 and perplexity is 39.162164752092266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313698276253634 and perplexity of 74.71630013153043
finished 13 epochs...
Completing Train Step...
At time: 688.312757730484 and batch: 50, loss is 3.9105346107482912 and perplexity is 49.92563562150832
At time: 689.5834674835205 and batch: 100, loss is 3.872294430732727 and perplexity is 48.05251285565896
At time: 690.8544840812683 and batch: 150, loss is 3.8463118982315065 and perplexity is 46.82006724146878
At time: 692.1239132881165 and batch: 200, loss is 3.8498461771011354 and perplexity is 46.98583517830078
At time: 693.3925766944885 and batch: 250, loss is 3.8366435623168944 and perplexity is 46.369576361605354
At time: 694.6646707057953 and batch: 300, loss is 3.833946852684021 and perplexity is 46.24469953231086
At time: 695.939975976944 and batch: 350, loss is 3.853434042930603 and perplexity is 47.15471683199859
At time: 697.2107832431793 and batch: 400, loss is 3.8033710384368895 and perplexity is 44.85212817994458
At time: 698.4775238037109 and batch: 450, loss is 3.842578568458557 and perplexity is 46.64559836802648
At time: 699.7488543987274 and batch: 500, loss is 3.833572659492493 and perplexity is 46.22739831780183
At time: 701.0314328670502 and batch: 550, loss is 3.8167423725128176 and perplexity is 45.45588851479591
At time: 702.2997004985809 and batch: 600, loss is 3.7785726308822634 and perplexity is 43.753544684530326
At time: 703.5705564022064 and batch: 650, loss is 3.8191092443466186 and perplexity is 45.563604201328225
At time: 704.841224193573 and batch: 700, loss is 3.8631553506851195 and perplexity is 47.615357734701064
At time: 706.1105921268463 and batch: 750, loss is 3.798460855484009 and perplexity is 44.632435830964894
At time: 707.3798744678497 and batch: 800, loss is 3.7997144508361815 and perplexity is 44.688421929703466
At time: 708.6496515274048 and batch: 850, loss is 3.7871073865890503 and perplexity is 44.12856859197934
At time: 709.9198579788208 and batch: 900, loss is 3.740700435638428 and perplexity is 42.12748742687541
At time: 711.1884677410126 and batch: 950, loss is 3.8554836177825926 and perplexity is 47.251463064225156
At time: 712.4766628742218 and batch: 1000, loss is 3.8096063566207885 and perplexity is 45.13266919267715
At time: 713.7582290172577 and batch: 1050, loss is 3.7579239654541015 and perplexity is 42.859356050853165
At time: 715.0275175571442 and batch: 1100, loss is 3.7746624422073363 and perplexity is 43.58279412063612
At time: 716.2976999282837 and batch: 1150, loss is 3.7598483610153197 and perplexity is 42.94191381681528
At time: 717.5659952163696 and batch: 1200, loss is 3.795036640167236 and perplexity is 44.47986612540543
At time: 718.8328680992126 and batch: 1250, loss is 3.7879417085647584 and perplexity is 44.16540138958182
At time: 720.103280544281 and batch: 1300, loss is 3.773091745376587 and perplexity is 43.51439249720496
At time: 721.3723335266113 and batch: 1350, loss is 3.6432385444641113 and perplexity is 38.21539880500333
At time: 722.6432809829712 and batch: 1400, loss is 3.6706082248687744 and perplexity is 39.27578710744352
At time: 723.9147458076477 and batch: 1450, loss is 3.6006260967254637 and perplexity is 36.62115565311926
At time: 725.1830215454102 and batch: 1500, loss is 3.5975349283218385 and perplexity is 36.50812827718778
At time: 726.451678276062 and batch: 1550, loss is 3.6179657220840453 and perplexity is 37.2616900368162
At time: 727.7206394672394 and batch: 1600, loss is 3.690058832168579 and perplexity is 40.04720295177709
At time: 728.9895498752594 and batch: 1650, loss is 3.669085717201233 and perplexity is 39.216034918548864
At time: 730.260103225708 and batch: 1700, loss is 3.650953531265259 and perplexity is 38.51137034259498
At time: 731.5285336971283 and batch: 1750, loss is 3.645133442878723 and perplexity is 38.287881755838654
At time: 732.7968587875366 and batch: 1800, loss is 3.5981171894073487 and perplexity is 36.52939172942805
At time: 734.06174659729 and batch: 1850, loss is 3.6332108688354494 and perplexity is 37.83410213650075
At time: 735.3301389217377 and batch: 1900, loss is 3.7393267488479616 and perplexity is 42.0696571832963
At time: 736.5980336666107 and batch: 1950, loss is 3.6669681787490847 and perplexity is 39.13308131638598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314088333484738 and perplexity of 74.74544944925962
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 740.4916396141052 and batch: 50, loss is 3.909908423423767 and perplexity is 49.89438260745516
At time: 741.7750434875488 and batch: 100, loss is 3.8790723752975462 and perplexity is 48.37931640102547
At time: 743.0457410812378 and batch: 150, loss is 3.859150938987732 and perplexity is 47.4250674937266
At time: 744.3154294490814 and batch: 200, loss is 3.8639805555343627 and perplexity is 47.65466637541201
At time: 745.5837395191193 and batch: 250, loss is 3.854006371498108 and perplexity is 47.181712548006985
At time: 746.8508667945862 and batch: 300, loss is 3.850316185951233 and perplexity is 47.007924127257915
At time: 748.1172683238983 and batch: 350, loss is 3.871070399284363 and perplexity is 47.99373105147834
At time: 749.3847441673279 and batch: 400, loss is 3.825073184967041 and perplexity is 45.836154761061806
At time: 750.6522233486176 and batch: 450, loss is 3.8664659547805784 and perplexity is 47.773254555741794
At time: 751.9280416965485 and batch: 500, loss is 3.854280614852905 and perplexity is 47.194653593558
At time: 753.1978757381439 and batch: 550, loss is 3.837821707725525 and perplexity is 46.424238658840444
At time: 754.4691462516785 and batch: 600, loss is 3.797347707748413 and perplexity is 44.58278097780647
At time: 755.7403335571289 and batch: 650, loss is 3.8296150875091555 and perplexity is 46.0448115997085
At time: 757.0122992992401 and batch: 700, loss is 3.8714599323272707 and perplexity is 48.01242983723634
At time: 758.2832705974579 and batch: 750, loss is 3.805508465766907 and perplexity is 44.94809887317954
At time: 759.5514328479767 and batch: 800, loss is 3.8040292835235596 and perplexity is 44.88166159199105
At time: 760.8213787078857 and batch: 850, loss is 3.7942221117019654 and perplexity is 44.44365075954032
At time: 762.0881335735321 and batch: 900, loss is 3.740990285873413 and perplexity is 42.13969985880805
At time: 763.3570866584778 and batch: 950, loss is 3.8572714710235596 and perplexity is 47.33601730837212
At time: 764.6353073120117 and batch: 1000, loss is 3.8137606287002566 and perplexity is 45.320552569301846
At time: 765.9038047790527 and batch: 1050, loss is 3.7631939172744753 and perplexity is 43.0858189925715
At time: 767.1720206737518 and batch: 1100, loss is 3.7762898111343386 and perplexity is 43.65377714766071
At time: 768.4579238891602 and batch: 1150, loss is 3.7636910104751586 and perplexity is 43.10724198440923
At time: 769.7400267124176 and batch: 1200, loss is 3.801789150238037 and perplexity is 44.78123321642017
At time: 771.0100831985474 and batch: 1250, loss is 3.7917184591293336 and perplexity is 44.33251847534431
At time: 772.2820346355438 and batch: 1300, loss is 3.7744529962539675 and perplexity is 43.57366683664077
At time: 773.5507373809814 and batch: 1350, loss is 3.6434073495864867 and perplexity is 38.22185030458301
At time: 774.8192698955536 and batch: 1400, loss is 3.6689640855789185 and perplexity is 39.21126529867516
At time: 776.0913426876068 and batch: 1450, loss is 3.5953075647354127 and perplexity is 36.426901895578276
At time: 777.357513666153 and batch: 1500, loss is 3.5914044046401976 and perplexity is 36.2849989807579
At time: 778.6289372444153 and batch: 1550, loss is 3.611933560371399 and perplexity is 37.03759805586346
At time: 779.8999764919281 and batch: 1600, loss is 3.682360553741455 and perplexity is 39.74009206249738
At time: 781.1713447570801 and batch: 1650, loss is 3.659195499420166 and perplexity is 38.83009147102973
At time: 782.4396421909332 and batch: 1700, loss is 3.6358551216125488 and perplexity is 37.93427745220321
At time: 783.7077739238739 and batch: 1750, loss is 3.6295078372955323 and perplexity is 37.694260342090175
At time: 784.9791667461395 and batch: 1800, loss is 3.582772722244263 and perplexity is 35.97314623697626
At time: 786.2507612705231 and batch: 1850, loss is 3.6200202226638796 and perplexity is 37.33832289477257
At time: 787.5195288658142 and batch: 1900, loss is 3.727745141983032 and perplexity is 41.58523356956106
At time: 788.7857985496521 and batch: 1950, loss is 3.6599315452575683 and perplexity is 38.85868271916671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.30936392850654 and perplexity of 74.39315452300397
finished 15 epochs...
Completing Train Step...
At time: 792.6602697372437 and batch: 50, loss is 3.9106461906433108 and perplexity is 49.93120662949021
At time: 793.9392476081848 and batch: 100, loss is 3.8744355821609497 and perplexity is 48.15551078992683
At time: 795.208758354187 and batch: 150, loss is 3.8507990217208863 and perplexity is 47.030626714853334
At time: 796.4894218444824 and batch: 200, loss is 3.8554037284851073 and perplexity is 47.24768832881829
At time: 797.7566833496094 and batch: 250, loss is 3.844371886253357 and perplexity is 46.729323800344446
At time: 799.0241944789886 and batch: 300, loss is 3.8396347522735597 and perplexity is 46.50848421903715
At time: 800.2916107177734 and batch: 350, loss is 3.8598362159729005 and perplexity is 47.45757793905784
At time: 801.560539484024 and batch: 400, loss is 3.814245147705078 and perplexity is 45.34251655888618
At time: 802.8332178592682 and batch: 450, loss is 3.8559394454956055 and perplexity is 47.273006500244804
At time: 804.1027472019196 and batch: 500, loss is 3.844566402435303 and perplexity is 46.7384142940904
At time: 805.3747563362122 and batch: 550, loss is 3.8277154541015626 and perplexity is 45.95742636358256
At time: 806.6409883499146 and batch: 600, loss is 3.787662386894226 and perplexity is 44.153066758631006
At time: 807.9090301990509 and batch: 650, loss is 3.8219096946716307 and perplexity is 45.69138164520657
At time: 809.1810367107391 and batch: 700, loss is 3.8646075201034544 and perplexity is 47.684553530896046
At time: 810.450701713562 and batch: 750, loss is 3.799413809776306 and perplexity is 44.674988774550535
At time: 811.7194623947144 and batch: 800, loss is 3.798724160194397 and perplexity is 44.64418930886042
At time: 812.9880483150482 and batch: 850, loss is 3.7885657215118407 and perplexity is 44.192969772481355
At time: 814.258615732193 and batch: 900, loss is 3.7368212080001832 and perplexity is 41.96438187963251
At time: 815.5273878574371 and batch: 950, loss is 3.8531855869293214 and perplexity is 47.143002414931814
At time: 816.7967073917389 and batch: 1000, loss is 3.809232096672058 and perplexity is 45.11578100270271
At time: 818.064553976059 and batch: 1050, loss is 3.758618116378784 and perplexity is 42.88911724067086
At time: 819.3314349651337 and batch: 1100, loss is 3.772846188545227 and perplexity is 43.503708552676244
At time: 820.5982954502106 and batch: 1150, loss is 3.760769920349121 and perplexity is 42.98150557858125
At time: 821.8638048171997 and batch: 1200, loss is 3.7989679622650145 and perplexity is 44.65507498157582
At time: 823.1276025772095 and batch: 1250, loss is 3.7892961072921754 and perplexity is 44.22525947973
At time: 824.3923618793488 and batch: 1300, loss is 3.772134404182434 and perplexity is 43.47275431088447
At time: 825.6573193073273 and batch: 1350, loss is 3.640840926170349 and perplexity is 38.123882620005325
At time: 826.921552658081 and batch: 1400, loss is 3.6673953676223756 and perplexity is 39.149802104514976
At time: 828.1859591007233 and batch: 1450, loss is 3.5945795297622682 and perplexity is 36.400391488457714
At time: 829.4513239860535 and batch: 1500, loss is 3.591707663536072 and perplexity is 36.29600439814662
At time: 830.7153680324554 and batch: 1550, loss is 3.613192067146301 and perplexity is 37.08423946705281
At time: 831.9813981056213 and batch: 1600, loss is 3.6838450717926023 and perplexity is 39.799130757680345
At time: 833.248309135437 and batch: 1650, loss is 3.6615337228775022 and perplexity is 38.920991132203255
At time: 834.5124413967133 and batch: 1700, loss is 3.638995552062988 and perplexity is 38.05359466787634
At time: 835.7775270938873 and batch: 1750, loss is 3.6334782648086548 and perplexity is 37.844220175763084
At time: 837.0442991256714 and batch: 1800, loss is 3.586716957092285 and perplexity is 36.11531295911987
At time: 838.3093135356903 and batch: 1850, loss is 3.624088416099548 and perplexity is 37.490531812608225
At time: 839.5772387981415 and batch: 1900, loss is 3.7319948291778564 and perplexity is 41.762333848014684
At time: 840.8409509658813 and batch: 1950, loss is 3.663910493850708 and perplexity is 39.01360743444465
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.30826785065407 and perplexity of 74.31165850510504
finished 16 epochs...
Completing Train Step...
At time: 844.6933934688568 and batch: 50, loss is 3.910118956565857 and perplexity is 49.90488813444014
At time: 845.9946517944336 and batch: 100, loss is 3.872201085090637 and perplexity is 48.04802757233651
At time: 847.2621819972992 and batch: 150, loss is 3.8475097608566284 and perplexity is 46.876184854008216
At time: 848.5286641120911 and batch: 200, loss is 3.8512691116333007 and perplexity is 47.052740535381254
At time: 849.7952959537506 and batch: 250, loss is 3.839716019630432 and perplexity is 46.51226399420587
At time: 851.0627694129944 and batch: 300, loss is 3.8344869089126585 and perplexity is 46.26968101543037
At time: 852.3380801677704 and batch: 350, loss is 3.8545374727249144 and perplexity is 47.20677746884
At time: 853.6043407917023 and batch: 400, loss is 3.8090081357955934 and perplexity is 45.105677964231866
At time: 854.8714363574982 and batch: 450, loss is 3.850516095161438 and perplexity is 47.01732238361129
At time: 856.1381602287292 and batch: 500, loss is 3.8394379234313964 and perplexity is 46.499330908784835
At time: 857.4056668281555 and batch: 550, loss is 3.8226471900939942 and perplexity is 45.72509125882636
At time: 858.6725583076477 and batch: 600, loss is 3.782904314994812 and perplexity is 43.94348229678577
At time: 859.9572200775146 and batch: 650, loss is 3.8177961206436155 and perplexity is 45.50381281799005
At time: 861.243485212326 and batch: 700, loss is 3.860840611457825 and perplexity is 47.50526806192813
At time: 862.5203523635864 and batch: 750, loss is 3.7959007930755617 and perplexity is 44.51832014376254
At time: 863.7974636554718 and batch: 800, loss is 3.795591993331909 and perplexity is 44.504575020268824
At time: 865.0673987865448 and batch: 850, loss is 3.785340361595154 and perplexity is 44.05066116079287
At time: 866.3439366817474 and batch: 900, loss is 3.7339704132080076 and perplexity is 41.84492039930177
At time: 867.6121842861176 and batch: 950, loss is 3.8503967332839966 and perplexity is 47.011710642659935
At time: 868.8810384273529 and batch: 1000, loss is 3.806465344429016 and perplexity is 44.9911293340753
At time: 870.1488935947418 and batch: 1050, loss is 3.7559659767150877 and perplexity is 42.77552001613382
At time: 871.4178688526154 and batch: 1100, loss is 3.7706493282318116 and perplexity is 43.40824188373368
At time: 872.685872554779 and batch: 1150, loss is 3.758856039047241 and perplexity is 42.899322747905146
At time: 873.9583814144135 and batch: 1200, loss is 3.7971760654449462 and perplexity is 44.575129343275364
At time: 875.2262525558472 and batch: 1250, loss is 3.787894358634949 and perplexity is 44.16331021043499
At time: 876.4962565898895 and batch: 1300, loss is 3.7709966707229614 and perplexity is 43.423322029442076
At time: 877.7721512317657 and batch: 1350, loss is 3.639687919616699 and perplexity is 38.07995086516149
At time: 879.0408613681793 and batch: 1400, loss is 3.6665882301330566 and perplexity is 39.11821558058562
At time: 880.3111484050751 and batch: 1450, loss is 3.5942818927764892 and perplexity is 36.38955899780882
At time: 881.5974080562592 and batch: 1500, loss is 3.5920097160339357 and perplexity is 36.30696935285017
At time: 882.8797359466553 and batch: 1550, loss is 3.614002742767334 and perplexity is 37.114314944994554
At time: 884.1556370258331 and batch: 1600, loss is 3.6847948598861695 and perplexity is 39.83694945523963
At time: 885.4252023696899 and batch: 1650, loss is 3.662799286842346 and perplexity is 38.97027931815365
At time: 886.6941773891449 and batch: 1700, loss is 3.6406318807601927 and perplexity is 38.11591383027475
At time: 887.9640200138092 and batch: 1750, loss is 3.635388889312744 and perplexity is 37.91659538908002
At time: 889.2327599525452 and batch: 1800, loss is 3.5885620403289793 and perplexity is 36.18201022973505
At time: 890.5021777153015 and batch: 1850, loss is 3.6259481048583986 and perplexity is 37.56031740280982
At time: 891.7731523513794 and batch: 1900, loss is 3.73387216091156 and perplexity is 41.84080924174651
At time: 893.047351360321 and batch: 1950, loss is 3.6654987430572508 and perplexity is 39.0756199981636
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307882335574128 and perplexity of 74.28301576159535
finished 17 epochs...
Completing Train Step...
At time: 896.9556667804718 and batch: 50, loss is 3.9089112997055055 and perplexity is 49.844656530794516
At time: 898.2245836257935 and batch: 100, loss is 3.870147671699524 and perplexity is 47.94946633721491
At time: 899.4936356544495 and batch: 150, loss is 3.8449084091186525 and perplexity is 46.75440187792257
At time: 900.7635259628296 and batch: 200, loss is 3.8482782506942748 and perplexity is 46.9122225712323
At time: 902.0323483943939 and batch: 250, loss is 3.836392674446106 and perplexity is 46.357944256560685
At time: 903.3004171848297 and batch: 300, loss is 3.8309011936187742 and perplexity is 46.10406821019965
At time: 904.5673227310181 and batch: 350, loss is 3.8508932542800904 and perplexity is 47.0350587399869
At time: 905.8364136219025 and batch: 400, loss is 3.80539071559906 and perplexity is 44.94280653858558
At time: 907.1152646541595 and batch: 450, loss is 3.846803379058838 and perplexity is 46.84308406255215
At time: 908.3834955692291 and batch: 500, loss is 3.8358689880371095 and perplexity is 46.33367358686911
At time: 909.6527111530304 and batch: 550, loss is 3.819107661247253 and perplexity is 45.563532069672426
At time: 910.9319474697113 and batch: 600, loss is 3.779620580673218 and perplexity is 43.7994202359749
At time: 912.1989789009094 and batch: 650, loss is 3.8148409795761107 and perplexity is 45.36954112561436
At time: 913.4817039966583 and batch: 700, loss is 3.858090667724609 and perplexity is 47.37481070513382
At time: 914.7625441551208 and batch: 750, loss is 3.7933139514923098 and perplexity is 44.403307126362655
At time: 916.0419113636017 and batch: 800, loss is 3.793189425468445 and perplexity is 44.39777810334053
At time: 917.3082456588745 and batch: 850, loss is 3.7828998136520386 and perplexity is 43.9432844925545
At time: 918.5734529495239 and batch: 900, loss is 3.731711893081665 and perplexity is 41.75051944774684
At time: 919.8464832305908 and batch: 950, loss is 3.848204674720764 and perplexity is 46.90877108576183
At time: 921.1206963062286 and batch: 1000, loss is 3.8043470287323 and perplexity is 44.89592479083375
At time: 922.4229502677917 and batch: 1050, loss is 3.7539830732345583 and perplexity is 42.690784327722504
At time: 923.6962950229645 and batch: 1100, loss is 3.7688916730880737 and perplexity is 43.33201217649965
At time: 924.9674119949341 and batch: 1150, loss is 3.7572787380218506 and perplexity is 42.83171093825216
At time: 926.2341539859772 and batch: 1200, loss is 3.795710039138794 and perplexity is 44.509828908830826
At time: 927.5019354820251 and batch: 1250, loss is 3.7867250633239746 and perplexity is 44.111700438301405
At time: 928.7716999053955 and batch: 1300, loss is 3.770049033164978 and perplexity is 43.38219194987661
At time: 930.0420949459076 and batch: 1350, loss is 3.638822903633118 and perplexity is 38.04702534161426
At time: 931.3123323917389 and batch: 1400, loss is 3.665890860557556 and perplexity is 39.090945237050974
At time: 932.5791966915131 and batch: 1450, loss is 3.5939183712005613 and perplexity is 36.37633301208585
At time: 933.8503341674805 and batch: 1500, loss is 3.592004113197327 and perplexity is 36.30676593140299
At time: 935.1188366413116 and batch: 1550, loss is 3.6143272161483764 and perplexity is 37.1263595062139
At time: 936.3882968425751 and batch: 1600, loss is 3.6852347087860107 and perplexity is 39.854475547764245
At time: 937.6581513881683 and batch: 1650, loss is 3.6633874464035032 and perplexity is 38.99320680238417
At time: 938.9268832206726 and batch: 1700, loss is 3.641429486274719 and perplexity is 38.14632742074837
At time: 940.2079513072968 and batch: 1750, loss is 3.6362862968444825 and perplexity is 37.95063729980899
At time: 941.4909763336182 and batch: 1800, loss is 3.589439926147461 and perplexity is 36.21378784992007
At time: 942.7593116760254 and batch: 1850, loss is 3.626827940940857 and perplexity is 37.59337886753143
At time: 944.0314562320709 and batch: 1900, loss is 3.7347391128540037 and perplexity is 41.87709894103175
At time: 945.3016312122345 and batch: 1950, loss is 3.666115155220032 and perplexity is 39.099714110787815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307747490461483 and perplexity of 74.27299973528865
finished 18 epochs...
Completing Train Step...
At time: 949.1959540843964 and batch: 50, loss is 3.9074656343460084 and perplexity is 49.772649898779534
At time: 950.460604429245 and batch: 100, loss is 3.8681904172897337 and perplexity is 47.85570881637075
At time: 951.7279441356659 and batch: 150, loss is 3.842628893852234 and perplexity is 46.647945885197004
At time: 952.9964323043823 and batch: 200, loss is 3.8457967042922974 and perplexity is 46.79595203912905
At time: 954.2766523361206 and batch: 250, loss is 3.833684606552124 and perplexity is 46.23257362879292
At time: 955.5445420742035 and batch: 300, loss is 3.8280479431152346 and perplexity is 45.97270924349913
At time: 956.8115952014923 and batch: 350, loss is 3.848016662597656 and perplexity is 46.89995249714437
At time: 958.0798547267914 and batch: 400, loss is 3.8025306940078734 and perplexity is 44.814452776273974
At time: 959.350367307663 and batch: 450, loss is 3.843910994529724 and perplexity is 46.70779160414057
At time: 960.6212773323059 and batch: 500, loss is 3.8330563068389893 and perplexity is 46.20353483953124
At time: 961.8904135227203 and batch: 550, loss is 3.8163110256195067 and perplexity is 45.43628548665896
At time: 963.1562960147858 and batch: 600, loss is 3.7770270824432375 and perplexity is 43.685973692412674
At time: 964.4232590198517 and batch: 650, loss is 3.8124402570724487 and perplexity is 45.26075208565165
At time: 965.6911160945892 and batch: 700, loss is 3.855822057723999 and perplexity is 47.26745755305025
At time: 966.9592263698578 and batch: 750, loss is 3.7911776304244995 and perplexity is 44.30854865916183
At time: 968.2253837585449 and batch: 800, loss is 3.791149926185608 and perplexity is 44.30732114154865
At time: 969.4904170036316 and batch: 850, loss is 3.7808427476882933 and perplexity is 43.852983167423545
At time: 970.760999917984 and batch: 900, loss is 3.7297629261016847 and perplexity is 41.66922830655298
At time: 972.0321359634399 and batch: 950, loss is 3.8463251304626467 and perplexity is 46.82068677951944
At time: 973.300968170166 and batch: 1000, loss is 3.802548675537109 and perplexity is 44.815258615911844
At time: 974.569216966629 and batch: 1050, loss is 3.752306537628174 and perplexity is 42.61927167124053
At time: 975.838042974472 and batch: 1100, loss is 3.767346167564392 and perplexity is 43.265094036825865
At time: 977.1069669723511 and batch: 1150, loss is 3.7558629655838014 and perplexity is 42.7711138883696
At time: 978.3765938282013 and batch: 1200, loss is 3.7943869113922117 and perplexity is 44.450975662973235
At time: 979.6475522518158 and batch: 1250, loss is 3.7856318855285647 and perplexity is 44.063504854834946
At time: 980.9165534973145 and batch: 1300, loss is 3.769124598503113 and perplexity is 43.34210647898451
At time: 982.1875610351562 and batch: 1350, loss is 3.6380159997940065 and perplexity is 38.01633743355981
At time: 983.4601602554321 and batch: 1400, loss is 3.6651833152770994 and perplexity is 39.06329640579341
At time: 984.7298474311829 and batch: 1450, loss is 3.593449568748474 and perplexity is 36.359283694665
At time: 985.9969260692596 and batch: 1500, loss is 3.591765365600586 and perplexity is 36.29809881295945
At time: 987.2655165195465 and batch: 1550, loss is 3.614318947792053 and perplexity is 37.12605253351361
At time: 988.5453338623047 and batch: 1600, loss is 3.685330867767334 and perplexity is 39.858308097798194
At time: 989.8129687309265 and batch: 1650, loss is 3.6635665035247804 and perplexity is 39.000189438870315
At time: 991.08052277565 and batch: 1700, loss is 3.641751070022583 and perplexity is 38.15859663237137
At time: 992.3476824760437 and batch: 1750, loss is 3.636648244857788 and perplexity is 37.96437594377078
At time: 993.6141021251678 and batch: 1800, loss is 3.58981511592865 and perplexity is 36.22737744223817
At time: 994.8835573196411 and batch: 1850, loss is 3.6272070026397705 and perplexity is 37.60763177878857
At time: 996.1519300937653 and batch: 1900, loss is 3.7350975465774536 and perplexity is 41.892111795928464
At time: 997.423445224762 and batch: 1950, loss is 3.666263303756714 and perplexity is 39.10550710531924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307726766896803 and perplexity of 74.2714605499234
finished 19 epochs...
Completing Train Step...
At time: 1001.3179957866669 and batch: 50, loss is 3.90594886302948 and perplexity is 49.69721339549006
At time: 1002.5884544849396 and batch: 100, loss is 3.866325478553772 and perplexity is 47.76654402054591
At time: 1003.8574092388153 and batch: 150, loss is 3.840552735328674 and perplexity is 46.55119782165146
At time: 1005.1251232624054 and batch: 200, loss is 3.8436004972457884 and perplexity is 46.69329121299138
At time: 1006.4005184173584 and batch: 250, loss is 3.831322441101074 and perplexity is 46.12349352400199
At time: 1007.6686835289001 and batch: 300, loss is 3.825599708557129 and perplexity is 45.860294932449584
At time: 1008.9351055622101 and batch: 350, loss is 3.845560245513916 and perplexity is 46.784888033618856
At time: 1010.2066142559052 and batch: 400, loss is 3.8000857496261595 and perplexity is 44.70501776750858
At time: 1011.4782044887543 and batch: 450, loss is 3.841467123031616 and perplexity is 46.59378313127137
At time: 1012.7487123012543 and batch: 500, loss is 3.8306601238250733 and perplexity is 46.09295525154059
At time: 1014.0179443359375 and batch: 550, loss is 3.8139308977127073 and perplexity is 45.32826991202506
At time: 1015.2880358695984 and batch: 600, loss is 3.774812397956848 and perplexity is 43.589330101235994
At time: 1016.557544708252 and batch: 650, loss is 3.8103544187545775 and perplexity is 45.16644386469861
At time: 1017.8406453132629 and batch: 700, loss is 3.853825845718384 and perplexity is 47.17319580132984
At time: 1019.1097431182861 and batch: 750, loss is 3.789295001029968 and perplexity is 44.2252105550239
At time: 1020.3766095638275 and batch: 800, loss is 3.789323453903198 and perplexity is 44.22646890723517
At time: 1021.6429650783539 and batch: 850, loss is 3.779008083343506 and perplexity is 43.77260142210181
At time: 1022.9128863811493 and batch: 900, loss is 3.727997817993164 and perplexity is 41.595742488079715
At time: 1024.1817519664764 and batch: 950, loss is 3.8446308851242064 and perplexity is 46.74142820989082
At time: 1025.4498255252838 and batch: 1000, loss is 3.8009337520599367 and perplexity is 44.74294380979281
At time: 1026.715579509735 and batch: 1050, loss is 3.7507945728302 and perplexity is 42.554881522843715
At time: 1027.9828462600708 and batch: 1100, loss is 3.7659205198287964 and perplexity is 43.20345720012986
At time: 1029.250881433487 and batch: 1150, loss is 3.7545397901535034 and perplexity is 42.714557626525604
At time: 1030.5195739269257 and batch: 1200, loss is 3.793140892982483 and perplexity is 44.39562342108445
At time: 1031.7867007255554 and batch: 1250, loss is 3.7845726871490477 and perplexity is 44.01685757062193
At time: 1033.0537729263306 and batch: 1300, loss is 3.7681921339035034 and perplexity is 43.30171033593403
At time: 1034.323256969452 and batch: 1350, loss is 3.637209539413452 and perplexity is 37.98569112278456
At time: 1035.5946798324585 and batch: 1400, loss is 3.66444522857666 and perplexity is 39.03447494391825
At time: 1036.8653135299683 and batch: 1450, loss is 3.592894582748413 and perplexity is 36.33911039970814
At time: 1038.1338357925415 and batch: 1500, loss is 3.5913700103759765 and perplexity is 36.28375100637739
At time: 1039.4020771980286 and batch: 1550, loss is 3.614093294143677 and perplexity is 37.117675849459815
At time: 1040.6707689762115 and batch: 1600, loss is 3.6852024221420288 and perplexity is 39.853188801273625
At time: 1041.9421772956848 and batch: 1650, loss is 3.663491477966309 and perplexity is 38.997263537637224
At time: 1043.2121658325195 and batch: 1700, loss is 3.641786494255066 and perplexity is 38.159948395312135
At time: 1044.4809226989746 and batch: 1750, loss is 3.636703906059265 and perplexity is 37.96648914536027
At time: 1045.7495107650757 and batch: 1800, loss is 3.589902458190918 and perplexity is 36.23054176152741
At time: 1047.0165672302246 and batch: 1850, loss is 3.62730094909668 and perplexity is 37.61116504851343
At time: 1048.2830510139465 and batch: 1900, loss is 3.7351724672317506 and perplexity is 41.89525049792943
At time: 1049.549343585968 and batch: 1950, loss is 3.666160125732422 and perplexity is 39.101472484502864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.30777701444404 and perplexity of 74.27519260240825
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f98e3f9bb38>
ELAPSED
3233.6014721393585


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -76.16006149647069}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.909600321875081, 'seq_len': 35, 'dropout': 0.7290759996057752, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -77.31609076804611}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.43001077421999756, 'seq_len': 35, 'dropout': 0.7678082231043937, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.2714605499234}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.8411519755907202, 'seq_len': 35, 'dropout': 0.7399604006877908, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9180686473846436 and batch: 50, loss is 7.653138790130615 and perplexity is 2107.2494336830105
At time: 3.4017162322998047 and batch: 100, loss is 6.972481002807617 and perplexity is 1066.8663682255208
At time: 4.884231328964233 and batch: 150, loss is 6.7160911369323735 and perplexity is 825.5841009176012
At time: 6.366713047027588 and batch: 200, loss is 6.555543546676636 and perplexity is 703.1312306178131
At time: 7.849195241928101 and batch: 250, loss is 6.5080290699005126 and perplexity is 670.503598703029
At time: 9.33261775970459 and batch: 300, loss is 6.44997465133667 and perplexity is 632.6862548581161
At time: 10.815162420272827 and batch: 350, loss is 6.402486829757691 and perplexity is 603.3435865672328
At time: 12.29543137550354 and batch: 400, loss is 6.370297889709473 and perplexity is 584.2318396249754
At time: 13.776013374328613 and batch: 450, loss is 6.287446966171265 and perplexity is 537.7786079980348
At time: 15.254051685333252 and batch: 500, loss is 6.274903383255005 and perplexity is 531.0750685347326
At time: 16.74638843536377 and batch: 550, loss is 6.23357479095459 and perplexity is 509.5738514114968
At time: 18.233667612075806 and batch: 600, loss is 6.283449878692627 and perplexity is 535.6333501056358
At time: 19.71325397491455 and batch: 650, loss is 6.361242179870605 and perplexity is 578.965088682863
At time: 21.193870782852173 and batch: 700, loss is 6.249097814559937 and perplexity is 517.5456917920848
At time: 22.674951553344727 and batch: 750, loss is 6.18745849609375 and perplexity is 486.60781765398815
At time: 24.166863441467285 and batch: 800, loss is 6.193725509643555 and perplexity is 489.6669713068978
At time: 25.648118019104004 and batch: 850, loss is 6.236540565490722 and perplexity is 511.0873758410081
At time: 27.128328800201416 and batch: 900, loss is 6.215904684066772 and perplexity is 500.6487132875771
At time: 28.608830213546753 and batch: 950, loss is 6.223434524536133 and perplexity is 504.4327469356051
At time: 30.08846163749695 and batch: 1000, loss is 6.20686445236206 and perplexity is 496.14312936327025
At time: 31.56995153427124 and batch: 1050, loss is 6.0996360588073735 and perplexity is 445.69553359799187
At time: 33.0508017539978 and batch: 1100, loss is 6.171726198196411 and perplexity is 479.01226293322213
At time: 34.530245304107666 and batch: 1150, loss is 6.082424030303955 and perplexity is 438.08985174312556
At time: 36.00514554977417 and batch: 1200, loss is 6.16930323600769 and perplexity is 477.8530392768707
At time: 37.4850709438324 and batch: 1250, loss is 6.102330121994019 and perplexity is 446.8978844048141
At time: 38.97074842453003 and batch: 1300, loss is 6.107222976684571 and perplexity is 449.08984892368835
At time: 40.45130896568298 and batch: 1350, loss is 6.09605260848999 and perplexity is 444.1012639956365
At time: 41.937883615493774 and batch: 1400, loss is 6.117203903198242 and perplexity is 453.5946252277834
At time: 43.42232131958008 and batch: 1450, loss is 6.096043558120727 and perplexity is 444.09724473339514
At time: 44.90572381019592 and batch: 1500, loss is 6.083586664199829 and perplexity is 438.5994860558567
At time: 46.387757301330566 and batch: 1550, loss is 6.038813638687134 and perplexity is 419.3951854076156
At time: 47.87119102478027 and batch: 1600, loss is 6.039928731918335 and perplexity is 419.863110981896
At time: 49.357322692871094 and batch: 1650, loss is 6.037519826889038 and perplexity is 418.8529178404027
At time: 50.842761754989624 and batch: 1700, loss is 6.045042057037353 and perplexity is 422.01550583142966
At time: 52.32839298248291 and batch: 1750, loss is 6.058877954483032 and perplexity is 427.89504967932066
At time: 53.81306862831116 and batch: 1800, loss is 6.073820152282715 and perplexity is 434.3367488685133
At time: 55.29672646522522 and batch: 1850, loss is 6.024907007217407 and perplexity is 413.6031781242007
At time: 56.78005051612854 and batch: 1900, loss is 5.999909172058105 and perplexity is 403.392152549757
At time: 58.26527285575867 and batch: 1950, loss is 5.936511631011963 and perplexity is 378.6118852873819
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.395937613553779 and perplexity of 220.50880224173244
finished 1 epochs...
Completing Train Step...
At time: 62.23267149925232 and batch: 50, loss is 5.699914913177491 and perplexity is 298.8419723713949
At time: 63.48942685127258 and batch: 100, loss is 5.635825624465943 and perplexity is 280.29023628259876
At time: 64.74919414520264 and batch: 150, loss is 5.520457124710083 and perplexity is 249.74917761991355
At time: 66.00751733779907 and batch: 200, loss is 5.471100740432739 and perplexity is 237.72171870618988
At time: 67.27055621147156 and batch: 250, loss is 5.468586816787719 and perplexity is 237.12485500582315
At time: 68.53744888305664 and batch: 300, loss is 5.455242691040039 and perplexity is 233.98164942924183
At time: 69.81592035293579 and batch: 350, loss is 5.39573748588562 and perplexity is 220.46467674484492
At time: 71.07857465744019 and batch: 400, loss is 5.341433067321777 and perplexity is 208.81173725209572
At time: 72.34620571136475 and batch: 450, loss is 5.273509387969971 and perplexity is 195.0994420813083
At time: 73.61311078071594 and batch: 500, loss is 5.25052843093872 and perplexity is 190.66699618223888
At time: 74.88119959831238 and batch: 550, loss is 5.200391445159912 and perplexity is 181.34321390678252
At time: 76.14977264404297 and batch: 600, loss is 5.190887451171875 and perplexity is 179.62789320234373
At time: 77.41943049430847 and batch: 650, loss is 5.251285161972046 and perplexity is 190.81133442100534
At time: 78.68798732757568 and batch: 700, loss is 5.230010471343994 and perplexity is 186.79475950211022
At time: 79.9565818309784 and batch: 750, loss is 5.150974006652832 and perplexity is 172.59952155406796
At time: 81.22581076622009 and batch: 800, loss is 5.152177133560181 and perplexity is 172.8073056529011
At time: 82.49465608596802 and batch: 850, loss is 5.147736215591431 and perplexity is 172.04158409585395
At time: 83.7664008140564 and batch: 900, loss is 5.149490442276001 and perplexity is 172.34364890113923
At time: 85.03568387031555 and batch: 950, loss is 5.1811073112487795 and perplexity is 177.8796701407516
At time: 86.30459189414978 and batch: 1000, loss is 5.129481821060181 and perplexity is 168.92955962127218
At time: 87.56881046295166 and batch: 1050, loss is 5.049090805053711 and perplexity is 155.8806741174873
At time: 88.83421564102173 and batch: 1100, loss is 5.1214524269104 and perplexity is 167.57858860114263
At time: 90.10031151771545 and batch: 1150, loss is 5.025352077484131 and perplexity is 152.22384126611075
At time: 91.36547350883484 and batch: 1200, loss is 5.090282421112061 and perplexity is 162.43573085577194
At time: 92.6323447227478 and batch: 1250, loss is 5.046578741073608 and perplexity is 155.4895833190601
At time: 93.89971399307251 and batch: 1300, loss is 5.068876457214356 and perplexity is 158.9955886052631
At time: 95.16846752166748 and batch: 1350, loss is 4.98576361656189 and perplexity is 146.31526113470866
At time: 96.43724155426025 and batch: 1400, loss is 4.985275411605835 and perplexity is 146.24384673292715
At time: 97.71580839157104 and batch: 1450, loss is 4.937653503417969 and perplexity is 139.44266363707357
At time: 98.98204016685486 and batch: 1500, loss is 4.896215839385986 and perplexity is 133.78256588430037
At time: 100.25139880180359 and batch: 1550, loss is 4.893271102905273 and perplexity is 133.38919095906553
At time: 101.5193817615509 and batch: 1600, loss is 4.941258964538574 and perplexity is 139.94632616158867
At time: 102.7897698879242 and batch: 1650, loss is 4.9203495693206785 and perplexity is 137.05051346863854
At time: 104.05495834350586 and batch: 1700, loss is 4.93393837928772 and perplexity is 138.92557794611417
At time: 105.32231187820435 and batch: 1750, loss is 4.931278858184815 and perplexity is 138.55659331852232
At time: 106.59007692337036 and batch: 1800, loss is 4.890830583572388 and perplexity is 133.0640489787589
At time: 107.8584554195404 and batch: 1850, loss is 4.889701423645019 and perplexity is 132.91388318343306
At time: 109.12729859352112 and batch: 1900, loss is 4.977821159362793 and perplexity is 145.15776121718613
At time: 110.39751410484314 and batch: 1950, loss is 4.888340091705322 and perplexity is 132.73306637280055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.693576546602471 and perplexity of 109.24319531639992
finished 2 epochs...
Completing Train Step...
At time: 114.30248045921326 and batch: 50, loss is 4.874524354934692 and perplexity is 130.9118708144925
At time: 115.57960081100464 and batch: 100, loss is 4.807568349838257 and perplexity is 122.43353971701983
At time: 116.84369158744812 and batch: 150, loss is 4.742606840133667 and perplexity is 114.73290251326786
At time: 118.10837030410767 and batch: 200, loss is 4.733272943496704 and perplexity is 113.6669798052721
At time: 119.37431454658508 and batch: 250, loss is 4.749814453125 and perplexity is 115.56284021391875
At time: 120.64137864112854 and batch: 300, loss is 4.767415418624878 and perplexity is 117.6148635988918
At time: 121.90765619277954 and batch: 350, loss is 4.76200379371643 and perplexity is 116.98009518684611
At time: 123.17622876167297 and batch: 400, loss is 4.715551176071167 and perplexity is 111.67034423597636
At time: 124.44349002838135 and batch: 450, loss is 4.700890588760376 and perplexity is 110.04513378329989
At time: 125.71078968048096 and batch: 500, loss is 4.702660446166992 and perplexity is 110.2400704325397
At time: 126.98053503036499 and batch: 550, loss is 4.6763263511657716 and perplexity is 107.37488949629454
At time: 128.25002431869507 and batch: 600, loss is 4.643080558776855 and perplexity is 103.86381384668296
At time: 129.51862382888794 and batch: 650, loss is 4.708440313339233 and perplexity is 110.87908833703823
At time: 130.78789472579956 and batch: 700, loss is 4.741510858535767 and perplexity is 114.607226245458
At time: 132.05499291419983 and batch: 750, loss is 4.682367286682129 and perplexity is 108.02549744159319
At time: 133.3400411605835 and batch: 800, loss is 4.678342819213867 and perplexity is 107.59162597778638
At time: 134.60270524024963 and batch: 850, loss is 4.674140462875366 and perplexity is 107.14043632024062
At time: 135.86750197410583 and batch: 900, loss is 4.657589845657348 and perplexity is 105.38178945992811
At time: 137.13275694847107 and batch: 950, loss is 4.71551028251648 and perplexity is 111.6657777320183
At time: 138.39904761314392 and batch: 1000, loss is 4.681114196777344 and perplexity is 107.89021655854606
At time: 139.66504502296448 and batch: 1050, loss is 4.621799936294556 and perplexity is 101.67687942903649
At time: 140.9314525127411 and batch: 1100, loss is 4.673887758255005 and perplexity is 107.11336485764093
At time: 142.19795179367065 and batch: 1150, loss is 4.608377361297608 and perplexity is 100.3212323798814
At time: 143.46624732017517 and batch: 1200, loss is 4.6838382053375245 and perplexity is 108.18451108043215
At time: 144.7328417301178 and batch: 1250, loss is 4.656541194915771 and perplexity is 105.27133869052447
At time: 146.00784945487976 and batch: 1300, loss is 4.668619394302368 and perplexity is 106.5505365613384
At time: 147.27082681655884 and batch: 1350, loss is 4.5569260597229 and perplexity is 95.29011304857859
At time: 148.5338900089264 and batch: 1400, loss is 4.563380508422852 and perplexity is 95.90714736088945
At time: 149.79737854003906 and batch: 1450, loss is 4.511809320449829 and perplexity is 91.08647412856612
At time: 151.0631811618805 and batch: 1500, loss is 4.498810567855835 and perplexity is 89.91012568160433
At time: 152.33158159255981 and batch: 1550, loss is 4.507142858505249 and perplexity is 90.66241276600952
At time: 153.60100412368774 and batch: 1600, loss is 4.570699720382691 and perplexity is 96.61168729420878
At time: 154.87043738365173 and batch: 1650, loss is 4.546835393905639 and perplexity is 94.33340737847398
At time: 156.1389284133911 and batch: 1700, loss is 4.564047632217407 and perplexity is 95.97115064764581
At time: 157.4099259376526 and batch: 1750, loss is 4.550971765518188 and perplexity is 94.72441352273158
At time: 158.67982292175293 and batch: 1800, loss is 4.514402942657471 and perplexity is 91.32302465943299
At time: 159.94732403755188 and batch: 1850, loss is 4.537398710250854 and perplexity is 93.44739991601251
At time: 161.21497201919556 and batch: 1900, loss is 4.648352069854736 and perplexity is 104.41277875801536
At time: 162.48421907424927 and batch: 1950, loss is 4.561188659667969 and perplexity is 95.69716360974085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.53713265352471 and perplexity of 93.42254091382316
finished 3 epochs...
Completing Train Step...
At time: 166.38123059272766 and batch: 50, loss is 4.554344358444214 and perplexity is 95.04441973171596
At time: 167.65856957435608 and batch: 100, loss is 4.488401079177857 and perplexity is 88.9790616040688
At time: 168.92302131652832 and batch: 150, loss is 4.433713827133179 and perplexity is 84.24370321345508
At time: 170.18860507011414 and batch: 200, loss is 4.433267564773559 and perplexity is 84.20611680699895
At time: 171.4580225944519 and batch: 250, loss is 4.440066967010498 and perplexity is 84.78061898833133
At time: 172.72697162628174 and batch: 300, loss is 4.465422143936157 and perplexity is 86.95773047128998
At time: 173.99490880966187 and batch: 350, loss is 4.468296918869019 and perplexity is 87.20807404337
At time: 175.26375341415405 and batch: 400, loss is 4.414871234893798 and perplexity is 82.67119505550475
At time: 176.5330195426941 and batch: 450, loss is 4.427550249099731 and perplexity is 83.72605748854778
At time: 177.80306839942932 and batch: 500, loss is 4.4331312084198 and perplexity is 84.19463555073582
At time: 179.07212448120117 and batch: 550, loss is 4.408157558441162 and perplexity is 82.11802637548689
At time: 180.3405740261078 and batch: 600, loss is 4.381473655700684 and perplexity is 79.9557739113197
At time: 181.60924983024597 and batch: 650, loss is 4.44141773223877 and perplexity is 84.89521507927554
At time: 182.8784637451172 and batch: 700, loss is 4.484432935714722 and perplexity is 88.62667953609714
At time: 184.14818263053894 and batch: 750, loss is 4.433406019210816 and perplexity is 84.21777632465238
At time: 185.4175832271576 and batch: 800, loss is 4.43387059211731 and perplexity is 84.25691071146201
At time: 186.68629384040833 and batch: 850, loss is 4.420613842010498 and perplexity is 83.1473090078407
At time: 187.9547233581543 and batch: 900, loss is 4.3961911964416505 and perplexity is 81.141228360442
At time: 189.2369029521942 and batch: 950, loss is 4.468375225067138 and perplexity is 87.21490324347452
At time: 190.51490759849548 and batch: 1000, loss is 4.436883220672607 and perplexity is 84.51112822585239
At time: 191.7814028263092 and batch: 1050, loss is 4.387404117584229 and perplexity is 80.43135740188161
At time: 193.04860854148865 and batch: 1100, loss is 4.428468103408814 and perplexity is 83.80294108977087
At time: 194.31454062461853 and batch: 1150, loss is 4.377091016769409 and perplexity is 79.60612337947227
At time: 195.5849268436432 and batch: 1200, loss is 4.452542171478272 and perplexity is 85.84489929950425
At time: 196.88335132598877 and batch: 1250, loss is 4.434351367950439 and perplexity is 84.29742913726575
At time: 198.15251874923706 and batch: 1300, loss is 4.435592288970947 and perplexity is 84.40210052008473
At time: 199.4217336177826 and batch: 1350, loss is 4.316160469055176 and perplexity is 74.9004927336677
At time: 200.6892158985138 and batch: 1400, loss is 4.3320830535888675 and perplexity is 76.10264746773613
At time: 201.95893216133118 and batch: 1450, loss is 4.280418481826782 and perplexity is 72.27067764513684
At time: 203.23021841049194 and batch: 1500, loss is 4.272216644287109 and perplexity is 71.6803494853247
At time: 204.5036952495575 and batch: 1550, loss is 4.282958784103394 and perplexity is 72.45450039591444
At time: 205.77249336242676 and batch: 1600, loss is 4.360614509582519 and perplexity is 78.30523896092369
At time: 207.04095816612244 and batch: 1650, loss is 4.325251989364624 and perplexity is 75.58455696465477
At time: 208.30897212028503 and batch: 1700, loss is 4.341685705184936 and perplexity is 76.83695468249465
At time: 209.57675647735596 and batch: 1750, loss is 4.333928060531616 and perplexity is 76.24318698900495
At time: 210.84490704536438 and batch: 1800, loss is 4.295115776062012 and perplexity is 73.34070505152611
At time: 212.11465644836426 and batch: 1850, loss is 4.32509488105774 and perplexity is 75.57268293566219
At time: 213.38367319107056 and batch: 1900, loss is 4.434711360931397 and perplexity is 84.32778108298385
At time: 214.65286993980408 and batch: 1950, loss is 4.349540529251098 and perplexity is 77.44287201499408
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4708161110101745 and perplexity of 87.42804489623336
finished 4 epochs...
Completing Train Step...
At time: 218.56690907478333 and batch: 50, loss is 4.349493651390076 and perplexity is 77.43924174389292
At time: 219.84444499015808 and batch: 100, loss is 4.290423402786255 and perplexity is 72.99736924696833
At time: 221.11338019371033 and batch: 150, loss is 4.239387698173523 and perplexity is 69.3653662926186
At time: 222.38224029541016 and batch: 200, loss is 4.237772731781006 and perplexity is 69.25343396505272
At time: 223.65265130996704 and batch: 250, loss is 4.243067717552185 and perplexity is 69.62110245318699
At time: 224.92206168174744 and batch: 300, loss is 4.2686807775497435 and perplexity is 71.4273448807357
At time: 226.19132328033447 and batch: 350, loss is 4.275914068222046 and perplexity is 71.94587269862244
At time: 227.47375392913818 and batch: 400, loss is 4.224195470809937 and perplexity is 68.31951638695146
At time: 228.73758268356323 and batch: 450, loss is 4.2463999938964845 and perplexity is 69.85348617431053
At time: 230.00640273094177 and batch: 500, loss is 4.256928081512451 and perplexity is 70.5927947208382
At time: 231.28023958206177 and batch: 550, loss is 4.228352136611939 and perplexity is 68.604088810824
At time: 232.54959273338318 and batch: 600, loss is 4.201219491958618 and perplexity is 66.76770409218554
At time: 233.81996726989746 and batch: 650, loss is 4.258854494094849 and perplexity is 70.72891664020771
At time: 235.0889127254486 and batch: 700, loss is 4.307326474189758 and perplexity is 74.24173617554578
At time: 236.35865831375122 and batch: 750, loss is 4.255625295639038 and perplexity is 70.50088730595118
At time: 237.62700200080872 and batch: 800, loss is 4.258408370018006 and perplexity is 70.69736980499006
At time: 238.8940465450287 and batch: 850, loss is 4.245274286270142 and perplexity is 69.77489581537996
At time: 240.16309666633606 and batch: 900, loss is 4.215811409950256 and perplexity is 67.74911588117153
At time: 241.4313714504242 and batch: 950, loss is 4.297430143356324 and perplexity is 73.51063894951562
At time: 242.70039176940918 and batch: 1000, loss is 4.2657043075561525 and perplexity is 71.21505961905824
At time: 243.96604251861572 and batch: 1050, loss is 4.219375419616699 and perplexity is 67.991005176916
At time: 245.23768067359924 and batch: 1100, loss is 4.259387063980102 and perplexity is 70.76659476345321
At time: 246.51078462600708 and batch: 1150, loss is 4.21275119304657 and perplexity is 67.54210580096832
At time: 247.7952573299408 and batch: 1200, loss is 4.287424974441528 and perplexity is 72.77881968227295
At time: 249.07134079933167 and batch: 1250, loss is 4.273881196975708 and perplexity is 71.79976456255183
At time: 250.3372404575348 and batch: 1300, loss is 4.269542903900146 and perplexity is 71.48895082913664
At time: 251.60431957244873 and batch: 1350, loss is 4.150048351287841 and perplexity is 63.437067487881365
At time: 252.8744833469391 and batch: 1400, loss is 4.171435813903809 and perplexity is 64.8084381927125
At time: 254.1420819759369 and batch: 1450, loss is 4.121390895843506 and perplexity is 61.64492433222615
At time: 255.40795493125916 and batch: 1500, loss is 4.112031626701355 and perplexity is 61.07066441262186
At time: 256.67671966552734 and batch: 1550, loss is 4.12269091129303 and perplexity is 61.72511580002241
At time: 257.94938468933105 and batch: 1600, loss is 4.204311408996582 and perplexity is 66.97446377122344
At time: 259.23846530914307 and batch: 1650, loss is 4.16748125076294 and perplexity is 64.55265522011594
At time: 260.53403401374817 and batch: 1700, loss is 4.180087466239929 and perplexity is 65.37157076945317
At time: 261.8244605064392 and batch: 1750, loss is 4.1774071598052975 and perplexity is 65.19658953409943
At time: 263.09991478919983 and batch: 1800, loss is 4.139510588645935 and perplexity is 62.77209255546523
At time: 264.3730626106262 and batch: 1850, loss is 4.171923174858093 and perplexity is 64.84003099291905
At time: 265.6461777687073 and batch: 1900, loss is 4.276622104644775 and perplexity is 71.99683103500834
At time: 266.9181852340698 and batch: 1950, loss is 4.19896017074585 and perplexity is 66.61702468269101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.445985022256541 and perplexity of 85.28384296021525
finished 5 epochs...
Completing Train Step...
At time: 271.05233001708984 and batch: 50, loss is 4.199593801498413 and perplexity is 66.65924865396484
At time: 272.3262221813202 and batch: 100, loss is 4.144047436714172 and perplexity is 63.05752699907569
At time: 273.6001853942871 and batch: 150, loss is 4.097609128952026 and perplexity is 60.196194073875496
At time: 274.8715012073517 and batch: 200, loss is 4.095239610671997 and perplexity is 60.05372694751754
At time: 276.1445345878601 and batch: 250, loss is 4.095694427490234 and perplexity is 60.081046604779964
At time: 277.4191184043884 and batch: 300, loss is 4.118452043533325 and perplexity is 61.464024952421674
At time: 278.69616770744324 and batch: 350, loss is 4.129446167945861 and perplexity is 62.143496342135
At time: 279.9704051017761 and batch: 400, loss is 4.084143695831298 and perplexity is 59.39105915903601
At time: 281.243816614151 and batch: 450, loss is 4.110978918075562 and perplexity is 61.00640862465689
At time: 282.51758885383606 and batch: 500, loss is 4.119542102813721 and perplexity is 61.531060913179296
At time: 283.7916839122772 and batch: 550, loss is 4.093601965904236 and perplexity is 59.95546076031259
At time: 285.0705006122589 and batch: 600, loss is 4.068567299842835 and perplexity is 58.473128091574836
At time: 286.3420398235321 and batch: 650, loss is 4.121243863105774 and perplexity is 61.63586117654094
At time: 287.6166627407074 and batch: 700, loss is 4.173208994865417 and perplexity is 64.9234572261109
At time: 288.90046882629395 and batch: 750, loss is 4.120639452934265 and perplexity is 61.59861909099751
At time: 290.1671099662781 and batch: 800, loss is 4.121263070106506 and perplexity is 61.637045027940765
At time: 291.5087263584137 and batch: 850, loss is 4.1092189693450925 and perplexity is 60.89913489906534
At time: 292.78435802459717 and batch: 900, loss is 4.085836725234985 and perplexity is 59.49169513430282
At time: 294.0561525821686 and batch: 950, loss is 4.170770301818847 and perplexity is 64.7653217427384
At time: 295.3255476951599 and batch: 1000, loss is 4.1391935586929325 and perplexity is 62.75219507612761
At time: 296.5938081741333 and batch: 1050, loss is 4.09334400177002 and perplexity is 59.93999639649738
At time: 297.8627088069916 and batch: 1100, loss is 4.131134104728699 and perplexity is 62.24847921272361
At time: 299.13023233413696 and batch: 1150, loss is 4.092689828872681 and perplexity is 59.90079809801831
At time: 300.4018976688385 and batch: 1200, loss is 4.165032877922058 and perplexity is 64.39479957586013
At time: 301.6815564632416 and batch: 1250, loss is 4.147572798728943 and perplexity is 63.2802199154389
At time: 302.9572274684906 and batch: 1300, loss is 4.14212399482727 and perplexity is 62.93635608032881
At time: 304.23133730888367 and batch: 1350, loss is 4.023228025436401 and perplexity is 55.88120093264673
At time: 305.5070068836212 and batch: 1400, loss is 4.048788528442383 and perplexity is 57.32796376182378
At time: 306.7854051589966 and batch: 1450, loss is 3.993872056007385 and perplexity is 54.26459866348108
At time: 308.0573754310608 and batch: 1500, loss is 3.989455213546753 and perplexity is 54.02544901195014
At time: 309.3359763622284 and batch: 1550, loss is 4.000787672996521 and perplexity is 54.64117246316415
At time: 310.60767245292664 and batch: 1600, loss is 4.085620546340943 and perplexity is 59.47883567546584
At time: 311.8856785297394 and batch: 1650, loss is 4.045503368377686 and perplexity is 57.13994123582908
At time: 313.15316557884216 and batch: 1700, loss is 4.061520938873291 and perplexity is 58.062553551023946
At time: 314.420551776886 and batch: 1750, loss is 4.056235642433166 and perplexity is 57.756485286674895
At time: 315.6876518726349 and batch: 1800, loss is 4.015637311935425 and perplexity is 55.45862858808898
At time: 316.9547200202942 and batch: 1850, loss is 4.05726318359375 and perplexity is 57.81586295387167
At time: 318.2382507324219 and batch: 1900, loss is 4.158110218048096 and perplexity is 63.9505557294011
At time: 319.5113060474396 and batch: 1950, loss is 4.080179028511047 and perplexity is 59.1560595231831
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.450869821947674 and perplexity of 85.70145659905407
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 323.59923481941223 and batch: 50, loss is 4.116745853424073 and perplexity is 61.359245053605115
At time: 324.8704152107239 and batch: 100, loss is 4.094706673622131 and perplexity is 60.02173061821666
At time: 326.14050221443176 and batch: 150, loss is 4.057046751976014 and perplexity is 57.80335112714804
At time: 327.4103684425354 and batch: 200, loss is 4.054724760055542 and perplexity is 57.66928791993175
At time: 328.67936849594116 and batch: 250, loss is 4.041594047546386 and perplexity is 56.916998933681214
At time: 329.94585824012756 and batch: 300, loss is 4.057271018028259 and perplexity is 57.816315910237904
At time: 331.2145402431488 and batch: 350, loss is 4.058780097961426 and perplexity is 57.903631218707204
At time: 332.4842505455017 and batch: 400, loss is 4.0242077302932735 and perplexity is 55.935974843360384
At time: 333.75261783599854 and batch: 450, loss is 4.045423851013184 and perplexity is 57.13539779893767
At time: 335.01980447769165 and batch: 500, loss is 4.055869264602661 and perplexity is 57.73532846682949
At time: 336.2880210876465 and batch: 550, loss is 4.022703900337219 and perplexity is 55.85191986680657
At time: 337.5572991371155 and batch: 600, loss is 3.981367573738098 and perplexity is 53.59027278619173
At time: 338.8307237625122 and batch: 650, loss is 4.0256045007705685 and perplexity is 56.014159151695885
At time: 340.1004023551941 and batch: 700, loss is 4.071920952796936 and perplexity is 58.669555861518454
At time: 341.3709964752197 and batch: 750, loss is 4.014778771400452 and perplexity is 55.41103554063566
At time: 342.639790058136 and batch: 800, loss is 4.010496520996094 and perplexity is 55.17425894145714
At time: 343.9058475494385 and batch: 850, loss is 4.004813241958618 and perplexity is 54.861577601483965
At time: 345.1748216152191 and batch: 900, loss is 3.9741844654083254 and perplexity is 53.20670729681308
At time: 346.4442210197449 and batch: 950, loss is 4.058765697479248 and perplexity is 57.90279738450161
At time: 347.71165657043457 and batch: 1000, loss is 4.010953912734985 and perplexity is 55.199500964002624
At time: 348.97956562042236 and batch: 1050, loss is 3.9591097974777223 and perplexity is 52.4106490842411
At time: 350.2484345436096 and batch: 1100, loss is 3.988968501091003 and perplexity is 53.99916055096819
At time: 351.51611280441284 and batch: 1150, loss is 3.955854878425598 and perplexity is 52.240333995283436
At time: 352.7847783565521 and batch: 1200, loss is 4.005752959251404 and perplexity is 54.913156205523045
At time: 354.0518021583557 and batch: 1250, loss is 3.9865024375915525 and perplexity is 53.86615925435755
At time: 355.320485830307 and batch: 1300, loss is 3.9759569358825684 and perplexity is 53.30109824239846
At time: 356.5910692214966 and batch: 1350, loss is 3.8577165937423707 and perplexity is 47.357092335232764
At time: 357.8603024482727 and batch: 1400, loss is 3.8777204751968384 and perplexity is 48.31395658823398
At time: 359.13015151023865 and batch: 1450, loss is 3.8105540227890016 and perplexity is 45.17546016893
At time: 360.40072417259216 and batch: 1500, loss is 3.8052396154403687 and perplexity is 44.93601618641013
At time: 361.6692867279053 and batch: 1550, loss is 3.8186118745803834 and perplexity is 45.540947876910224
At time: 362.9382047653198 and batch: 1600, loss is 3.8917178201675413 and perplexity is 48.994978838072385
At time: 364.20951414108276 and batch: 1650, loss is 3.840669903755188 and perplexity is 46.556652471802714
At time: 365.47715997695923 and batch: 1700, loss is 3.840905547142029 and perplexity is 46.567624531767045
At time: 366.7439112663269 and batch: 1750, loss is 3.8301457357406616 and perplexity is 46.06925168152352
At time: 368.0120470523834 and batch: 1800, loss is 3.780487265586853 and perplexity is 43.837396987280925
At time: 369.2796370983124 and batch: 1850, loss is 3.805767087936401 and perplexity is 44.95972495134074
At time: 370.54558658599854 and batch: 1900, loss is 3.9031939935684203 and perplexity is 49.560492470625434
At time: 371.81305289268494 and batch: 1950, loss is 3.8316814279556275 and perplexity is 46.14005422422218
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378136355377907 and perplexity of 79.68938224298431
finished 7 epochs...
Completing Train Step...
At time: 375.7962508201599 and batch: 50, loss is 4.032792725563049 and perplexity is 56.41825213486519
At time: 377.06520438194275 and batch: 100, loss is 3.99308039188385 and perplexity is 54.22165632773726
At time: 378.33380818367004 and batch: 150, loss is 3.951690330505371 and perplexity is 52.02322900683469
At time: 379.60236644744873 and batch: 200, loss is 3.9501844310760497 and perplexity is 51.94494621376224
At time: 380.87309551239014 and batch: 250, loss is 3.93454035282135 and perplexity is 51.13863882260328
At time: 382.14274191856384 and batch: 300, loss is 3.9459746217727663 and perplexity is 51.72672754769976
At time: 383.4115378856659 and batch: 350, loss is 3.9514261150360106 and perplexity is 52.00948548067105
At time: 384.67965149879456 and batch: 400, loss is 3.9184581327438353 and perplexity is 50.32279386165241
At time: 385.96920895576477 and batch: 450, loss is 3.947917551994324 and perplexity is 51.82732666680223
At time: 387.2464473247528 and batch: 500, loss is 3.961700429916382 and perplexity is 52.54660183766068
At time: 388.51368618011475 and batch: 550, loss is 3.929497284889221 and perplexity is 50.88139239387413
At time: 389.7814884185791 and batch: 600, loss is 3.8929269790649412 and perplexity is 49.05425738403057
At time: 391.049654006958 and batch: 650, loss is 3.9368490409851074 and perplexity is 51.256838383226274
At time: 392.3181538581848 and batch: 700, loss is 3.98746262550354 and perplexity is 53.91790572853258
At time: 393.5875654220581 and batch: 750, loss is 3.9336528825759887 and perplexity is 51.093274934787665
At time: 394.85652136802673 and batch: 800, loss is 3.926282911300659 and perplexity is 50.71810316689793
At time: 396.1265823841095 and batch: 850, loss is 3.9205603265762328 and perplexity is 50.42869340021637
At time: 397.3936812877655 and batch: 900, loss is 3.8913825511932374 and perplexity is 48.97855509511088
At time: 398.6636219024658 and batch: 950, loss is 3.981273641586304 and perplexity is 53.58523917296646
At time: 399.93035674095154 and batch: 1000, loss is 3.9354177141189575 and perplexity is 51.183525573188085
At time: 401.19702672958374 and batch: 1050, loss is 3.887925457954407 and perplexity is 48.80952400990259
At time: 402.4750974178314 and batch: 1100, loss is 3.9151276397705077 and perplexity is 50.15547293554515
At time: 403.76000928878784 and batch: 1150, loss is 3.886581611633301 and perplexity is 48.743975564010505
At time: 405.0308554172516 and batch: 1200, loss is 3.9390730094909667 and perplexity is 51.37095883060393
At time: 406.29362773895264 and batch: 1250, loss is 3.925991625785828 and perplexity is 50.70333186954262
At time: 407.5574164390564 and batch: 1300, loss is 3.914884662628174 and perplexity is 50.14328778247565
At time: 408.82678604125977 and batch: 1350, loss is 3.79825119972229 and perplexity is 44.6230793644862
At time: 410.0976779460907 and batch: 1400, loss is 3.8211076784133913 and perplexity is 45.65475110537343
At time: 411.37033772468567 and batch: 1450, loss is 3.756025218963623 and perplexity is 42.77805420918675
At time: 412.63927841186523 and batch: 1500, loss is 3.7538956212997436 and perplexity is 42.6870510992757
At time: 413.90814661979675 and batch: 1550, loss is 3.7707003211975096 and perplexity is 43.41045545516087
At time: 415.17648458480835 and batch: 1600, loss is 3.847514672279358 and perplexity is 46.876415083333356
At time: 416.447505235672 and batch: 1650, loss is 3.7980536079406737 and perplexity is 44.61426308177457
At time: 417.71630024909973 and batch: 1700, loss is 3.8019312810897827 and perplexity is 44.78759846357773
At time: 418.98471331596375 and batch: 1750, loss is 3.7940841007232664 and perplexity is 44.43751747104235
At time: 420.2512333393097 and batch: 1800, loss is 3.7480484676361083 and perplexity is 42.43818165006032
At time: 421.51892161369324 and batch: 1850, loss is 3.7780873441696166 and perplexity is 43.73231682188017
At time: 422.7875940799713 and batch: 1900, loss is 3.8782491493225097 and perplexity is 48.339505679967786
At time: 424.05503129959106 and batch: 1950, loss is 3.8111538553237914 and perplexity is 45.2025660083829
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382294978651889 and perplexity of 80.02147039883789
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 428.0456004142761 and batch: 50, loss is 4.0011777544021605 and perplexity is 54.6624911262611
At time: 429.3259518146515 and batch: 100, loss is 3.9931271266937256 and perplexity is 54.2241904257517
At time: 430.59556102752686 and batch: 150, loss is 3.9676916790008545 and perplexity is 52.86236658590967
At time: 431.867928981781 and batch: 200, loss is 3.9790553045272827 and perplexity is 53.46650080065118
At time: 433.1393675804138 and batch: 250, loss is 3.9715126657485964 and perplexity is 53.064739373739755
At time: 434.40846991539 and batch: 300, loss is 3.970740933418274 and perplexity is 53.0238033966051
At time: 435.6783969402313 and batch: 350, loss is 3.970444679260254 and perplexity is 53.00809720100258
At time: 436.9486129283905 and batch: 400, loss is 3.9266360664367674 and perplexity is 50.73601768864149
At time: 438.21897625923157 and batch: 450, loss is 3.9516213226318357 and perplexity is 52.01963911829319
At time: 439.4878189563751 and batch: 500, loss is 3.9686331796646117 and perplexity is 52.91215997571468
At time: 440.75761675834656 and batch: 550, loss is 3.9433532190322875 and perplexity is 51.59130853378446
At time: 442.0256690979004 and batch: 600, loss is 3.9121015644073487 and perplexity is 50.003928103252
At time: 443.29640340805054 and batch: 650, loss is 3.9487644052505493 and perplexity is 51.87123539665276
At time: 444.5660676956177 and batch: 700, loss is 3.993539152145386 and perplexity is 54.24653677561909
At time: 445.8333146572113 and batch: 750, loss is 3.9323612737655638 and perplexity is 51.0273250106484
At time: 447.10171341896057 and batch: 800, loss is 3.9186905574798585 and perplexity is 50.334491483087284
At time: 448.383460521698 and batch: 850, loss is 3.9099788284301757 and perplexity is 49.89789554544516
At time: 449.66399097442627 and batch: 900, loss is 3.8806559085845946 and perplexity is 48.455987348428295
At time: 450.93564081192017 and batch: 950, loss is 3.9776294326782224 and perplexity is 53.39031874812104
At time: 452.20216274261475 and batch: 1000, loss is 3.933922362327576 and perplexity is 51.10704539317138
At time: 453.47152614593506 and batch: 1050, loss is 3.883408966064453 and perplexity is 48.58957326732417
At time: 454.7435450553894 and batch: 1100, loss is 3.9021175146102904 and perplexity is 49.50717034854663
At time: 456.01397347450256 and batch: 1150, loss is 3.872726755142212 and perplexity is 48.07329162116368
At time: 457.291668176651 and batch: 1200, loss is 3.911016936302185 and perplexity is 49.94972183959526
At time: 458.5586154460907 and batch: 1250, loss is 3.8933792734146118 and perplexity is 49.0764493657483
At time: 459.8266806602478 and batch: 1300, loss is 3.8866891765594485 and perplexity is 48.74921898814139
At time: 461.0931029319763 and batch: 1350, loss is 3.7692801713943482 and perplexity is 43.34884986033174
At time: 462.35993456840515 and batch: 1400, loss is 3.784396195411682 and perplexity is 44.009089644463465
At time: 463.6262457370758 and batch: 1450, loss is 3.71407208442688 and perplexity is 41.020505852843144
At time: 464.8958249092102 and batch: 1500, loss is 3.711815414428711 and perplexity is 40.928040479133124
At time: 466.1658022403717 and batch: 1550, loss is 3.7354441595077517 and perplexity is 41.90663466031532
At time: 467.4373004436493 and batch: 1600, loss is 3.815307674407959 and perplexity is 45.39071979758499
At time: 468.7087564468384 and batch: 1650, loss is 3.76136775970459 and perplexity is 43.00720929675501
At time: 469.97910261154175 and batch: 1700, loss is 3.751953749656677 and perplexity is 42.60423875671259
At time: 471.24988985061646 and batch: 1750, loss is 3.737223882675171 and perplexity is 41.98128327612075
At time: 472.51823711395264 and batch: 1800, loss is 3.6896353816986083 and perplexity is 40.0302485347974
At time: 473.78744864463806 and batch: 1850, loss is 3.711706032752991 and perplexity is 40.923563946311376
At time: 475.05561423301697 and batch: 1900, loss is 3.812016038894653 and perplexity is 45.24155572388691
At time: 476.32315468788147 and batch: 1950, loss is 3.7536991024017334 and perplexity is 42.67866311126044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355703522438227 and perplexity of 77.92162567001778
finished 9 epochs...
Completing Train Step...
At time: 480.2394986152649 and batch: 50, loss is 3.9896863460540772 and perplexity is 54.0379374926309
At time: 481.51948285102844 and batch: 100, loss is 3.9613778257369994 and perplexity is 52.52965281835472
At time: 482.79239225387573 and batch: 150, loss is 3.9265460777282715 and perplexity is 50.731452225358616
At time: 484.0636429786682 and batch: 200, loss is 3.9347893810272216 and perplexity is 51.15137537189418
At time: 485.3328092098236 and batch: 250, loss is 3.924812078475952 and perplexity is 50.64356014955012
At time: 486.60250878334045 and batch: 300, loss is 3.9224191427230837 and perplexity is 50.5225182443256
At time: 487.8723063468933 and batch: 350, loss is 3.9243616104125976 and perplexity is 50.62075198064969
At time: 489.1405303478241 and batch: 400, loss is 3.882199378013611 and perplexity is 48.530835431558266
At time: 490.4085659980774 and batch: 450, loss is 3.910930480957031 and perplexity is 49.94540360582315
At time: 491.67578864097595 and batch: 500, loss is 3.9265320444107057 and perplexity is 50.73074029977431
At time: 492.9438407421112 and batch: 550, loss is 3.9020419311523438 and perplexity is 49.50342856682871
At time: 494.2119822502136 and batch: 600, loss is 3.8731102037429808 and perplexity is 48.091728792197976
At time: 495.4793322086334 and batch: 650, loss is 3.910907406806946 and perplexity is 49.94425117138006
At time: 496.7533779144287 and batch: 700, loss is 3.955356183052063 and perplexity is 52.2142884773375
At time: 498.03827261924744 and batch: 750, loss is 3.8984180736541747 and perplexity is 49.324359851750586
At time: 499.31355333328247 and batch: 800, loss is 3.884815144538879 and perplexity is 48.65794694086172
At time: 500.58448219299316 and batch: 850, loss is 3.8767374992370605 and perplexity is 48.266488464220515
At time: 501.85411047935486 and batch: 900, loss is 3.849678635597229 and perplexity is 46.977963760225734
At time: 503.12393856048584 and batch: 950, loss is 3.947900929450989 and perplexity is 51.8264651719789
At time: 504.39172196388245 and batch: 1000, loss is 3.9056791353225706 and perplexity is 49.68381048773016
At time: 505.66016149520874 and batch: 1050, loss is 3.8569572877883913 and perplexity is 47.32114746136483
At time: 506.9297888278961 and batch: 1100, loss is 3.874636998176575 and perplexity is 48.1652110579024
At time: 508.1959409713745 and batch: 1150, loss is 3.8458327865600586 and perplexity is 46.79764057366356
At time: 509.4623701572418 and batch: 1200, loss is 3.8863181352615355 and perplexity is 48.73113436993337
At time: 510.72924423217773 and batch: 1250, loss is 3.8720384407043458 and perplexity is 48.04021346585699
At time: 511.9961895942688 and batch: 1300, loss is 3.8663529205322265 and perplexity is 47.76785484700352
At time: 513.263480424881 and batch: 1350, loss is 3.7497359561920165 and perplexity is 42.50985605378793
At time: 514.531543970108 and batch: 1400, loss is 3.7670160722732544 and perplexity is 43.25081478989943
At time: 515.7987656593323 and batch: 1450, loss is 3.6977866220474245 and perplexity is 40.35787819181884
At time: 517.0687382221222 and batch: 1500, loss is 3.697895088195801 and perplexity is 40.36225589283484
At time: 518.3439729213715 and batch: 1550, loss is 3.723391585350037 and perplexity is 41.40458342077501
At time: 519.6146569252014 and batch: 1600, loss is 3.805767149925232 and perplexity is 44.95972773834161
At time: 520.8846879005432 and batch: 1650, loss is 3.7528178596496584 and perplexity is 42.64106941574414
At time: 522.1544179916382 and batch: 1700, loss is 3.746307706832886 and perplexity is 42.364371188701526
At time: 523.4225161075592 and batch: 1750, loss is 3.7340251779556275 and perplexity is 41.84721208855793
At time: 524.6919882297516 and batch: 1800, loss is 3.687236337661743 and perplexity is 39.93432930898367
At time: 525.9603755474091 and batch: 1850, loss is 3.7113816261291506 and perplexity is 40.910290224254126
At time: 527.2314269542694 and batch: 1900, loss is 3.8131122827529906 and perplexity is 45.291178695960504
At time: 528.503180027008 and batch: 1950, loss is 3.755495715141296 and perplexity is 42.755409061846414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354867198855378 and perplexity of 77.85648521990014
finished 10 epochs...
Completing Train Step...
At time: 532.4165263175964 and batch: 50, loss is 3.969628720283508 and perplexity is 52.964862409558066
At time: 533.7015883922577 and batch: 100, loss is 3.938841881752014 and perplexity is 51.359086949055005
At time: 534.9745764732361 and batch: 150, loss is 3.903282346725464 and perplexity is 49.56487149004709
At time: 536.2510621547699 and batch: 200, loss is 3.9119783782958986 and perplexity is 49.99776869317641
At time: 537.5285782814026 and batch: 250, loss is 3.90170166015625 and perplexity is 49.48658685141637
At time: 538.7972042560577 and batch: 300, loss is 3.898619546890259 and perplexity is 49.33429839128895
At time: 540.0688760280609 and batch: 350, loss is 3.9015307664871215 and perplexity is 49.478130629594645
At time: 541.3413896560669 and batch: 400, loss is 3.8589361715316772 and perplexity is 47.414883226291494
At time: 542.61274766922 and batch: 450, loss is 3.888511047363281 and perplexity is 48.838114720606654
At time: 543.8840019702911 and batch: 500, loss is 3.9034354972839354 and perplexity is 49.572462959100385
At time: 545.1668970584869 and batch: 550, loss is 3.879324460029602 and perplexity is 48.39151362533988
At time: 546.4363992214203 and batch: 600, loss is 3.851541476249695 and perplexity is 47.06555778241052
At time: 547.7066237926483 and batch: 650, loss is 3.8900341844558715 and perplexity is 48.91255854435229
At time: 548.97705245018 and batch: 700, loss is 3.934647970199585 and perplexity is 51.14414252498158
At time: 550.247475862503 and batch: 750, loss is 3.879494047164917 and perplexity is 48.39972089941355
At time: 551.5169222354889 and batch: 800, loss is 3.865736379623413 and perplexity is 47.73841308732135
At time: 552.784725189209 and batch: 850, loss is 3.857300386428833 and perplexity is 47.33738606828564
At time: 554.0530252456665 and batch: 900, loss is 3.8307425737380982 and perplexity is 46.09675576836613
At time: 555.3213510513306 and batch: 950, loss is 3.928980760574341 and perplexity is 50.855117703870036
At time: 556.5879120826721 and batch: 1000, loss is 3.8882533740997314 and perplexity is 48.825532065377516
At time: 557.8571734428406 and batch: 1050, loss is 3.8410277509689332 and perplexity is 46.573315621424065
At time: 559.1281604766846 and batch: 1100, loss is 3.857818908691406 and perplexity is 47.36193792160524
At time: 560.3943002223969 and batch: 1150, loss is 3.8291686582565307 and perplexity is 46.024260436540324
At time: 561.6610131263733 and batch: 1200, loss is 3.8700219774246216 and perplexity is 47.943439742573865
At time: 562.9337224960327 and batch: 1250, loss is 3.857656865119934 and perplexity is 47.354263845816696
At time: 564.2041816711426 and batch: 1300, loss is 3.852046890258789 and perplexity is 47.08935138696362
At time: 565.4783861637115 and batch: 1350, loss is 3.7356869077682493 and perplexity is 41.91680865779256
At time: 566.7463307380676 and batch: 1400, loss is 3.753571286201477 and perplexity is 42.67320843531494
At time: 568.0194268226624 and batch: 1450, loss is 3.6843734264373778 and perplexity is 39.8201643693881
At time: 569.2920672893524 and batch: 1500, loss is 3.6852325105667116 and perplexity is 39.85438793898324
At time: 570.5619959831238 and batch: 1550, loss is 3.710959906578064 and perplexity is 40.89304119240856
At time: 571.8339352607727 and batch: 1600, loss is 3.7956258964538576 and perplexity is 44.50608388988056
At time: 573.1057889461517 and batch: 1650, loss is 3.7432703733444215 and perplexity is 42.23589168169978
At time: 574.3756673336029 and batch: 1700, loss is 3.7378116273880004 and perplexity is 42.005964805912896
At time: 575.6447768211365 and batch: 1750, loss is 3.726696643829346 and perplexity is 41.54165437928543
At time: 576.9149212837219 and batch: 1800, loss is 3.679921226501465 and perplexity is 39.643271110412144
At time: 578.1870651245117 and batch: 1850, loss is 3.7051929378509523 and perplexity is 40.657891006297156
At time: 579.4563694000244 and batch: 1900, loss is 3.807559666633606 and perplexity is 45.0403910751076
At time: 580.724011182785 and batch: 1950, loss is 3.7503498125076296 and perplexity is 42.53595900831442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355771654705668 and perplexity of 77.9269348279178
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 584.6568405628204 and batch: 50, loss is 3.9628082847595216 and perplexity is 52.60484810324343
At time: 585.9267239570618 and batch: 100, loss is 3.947407155036926 and perplexity is 51.800880906453344
At time: 587.2149322032928 and batch: 150, loss is 3.9243304681777955 and perplexity is 50.61917556185239
At time: 588.4882988929749 and batch: 200, loss is 3.943670935630798 and perplexity is 51.607702553032645
At time: 589.7573411464691 and batch: 250, loss is 3.9472932529449465 and perplexity is 51.79498101376315
At time: 591.0302836894989 and batch: 300, loss is 3.956002960205078 and perplexity is 52.248070409698954
At time: 592.3024685382843 and batch: 350, loss is 3.9682917404174805 and perplexity is 52.89409677156738
At time: 593.5740122795105 and batch: 400, loss is 3.926551718711853 and perplexity is 50.73173840145484
At time: 594.8458569049835 and batch: 450, loss is 3.9546223163604735 and perplexity is 52.175984207032094
At time: 596.1178212165833 and batch: 500, loss is 3.9568171977996824 and perplexity is 52.29063007736143
At time: 597.3907811641693 and batch: 550, loss is 3.9298458242416383 and perplexity is 50.89912965231591
At time: 598.6624009609222 and batch: 600, loss is 3.880070457458496 and perplexity is 48.42762703866662
At time: 599.9344177246094 and batch: 650, loss is 3.908380331993103 and perplexity is 49.81819765256751
At time: 601.2065582275391 and batch: 700, loss is 3.9566321849822996 and perplexity is 52.280956535460305
At time: 602.4802751541138 and batch: 750, loss is 3.902592616081238 and perplexity is 49.53069686630072
At time: 603.7521121501923 and batch: 800, loss is 3.8880635356903075 and perplexity is 48.81626398377772
At time: 605.0236420631409 and batch: 850, loss is 3.878093094825745 and perplexity is 48.33196267131055
At time: 606.2955145835876 and batch: 900, loss is 3.8460822057724 and perplexity is 46.8093142600752
At time: 607.5793325901031 and batch: 950, loss is 3.9432771730422975 and perplexity is 51.58738537082443
At time: 608.8519127368927 and batch: 1000, loss is 3.905010848045349 and perplexity is 49.65061852141703
At time: 610.123277425766 and batch: 1050, loss is 3.864556131362915 and perplexity is 47.682103144708584
At time: 611.3944861888885 and batch: 1100, loss is 3.8881568574905394 and perplexity is 48.8208198179893
At time: 612.6675605773926 and batch: 1150, loss is 3.8635236167907716 and perplexity is 47.63289608625526
At time: 613.9386839866638 and batch: 1200, loss is 3.8976827001571657 and perplexity is 49.288101358160255
At time: 615.2110483646393 and batch: 1250, loss is 3.8742384576797484 and perplexity is 48.14601909539879
At time: 616.4839234352112 and batch: 1300, loss is 3.8579448795318605 and perplexity is 47.367904520531624
At time: 617.7579493522644 and batch: 1350, loss is 3.7288236141204836 and perplexity is 41.6301062779288
At time: 619.0294966697693 and batch: 1400, loss is 3.7446739625930787 and perplexity is 42.29521514832239
At time: 620.3006854057312 and batch: 1450, loss is 3.673896842002869 and perplexity is 39.40516275075897
At time: 621.5743172168732 and batch: 1500, loss is 3.6720296001434325 and perplexity is 39.331652433521946
At time: 622.8470125198364 and batch: 1550, loss is 3.699367423057556 and perplexity is 40.42172641880607
At time: 624.1210134029388 and batch: 1600, loss is 3.7881756019592285 and perplexity is 44.175732593384026
At time: 625.3951349258423 and batch: 1650, loss is 3.7403335857391355 and perplexity is 42.112035796743186
At time: 626.6669459342957 and batch: 1700, loss is 3.7317470693588257 and perplexity is 41.751988101421276
At time: 627.9387788772583 and batch: 1750, loss is 3.725726256370544 and perplexity is 41.5013624314201
At time: 629.2089178562164 and batch: 1800, loss is 3.679794206619263 and perplexity is 39.63823594657532
At time: 630.4766502380371 and batch: 1850, loss is 3.6998329257965086 and perplexity is 40.44054722339539
At time: 631.7439587116241 and batch: 1900, loss is 3.801491756439209 and perplexity is 44.767917535456355
At time: 633.0120098590851 and batch: 1950, loss is 3.74613320350647 and perplexity is 42.356979109997496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3356573060501455 and perplexity of 76.37514423878294
finished 12 epochs...
Completing Train Step...
At time: 636.9380528926849 and batch: 50, loss is 3.9649525022506715 and perplexity is 52.71776535497579
At time: 638.2117364406586 and batch: 100, loss is 3.9344456148147584 and perplexity is 51.13379427938623
At time: 639.4936428070068 and batch: 150, loss is 3.9013277006149294 and perplexity is 49.468084329908734
At time: 640.7660915851593 and batch: 200, loss is 3.912930827140808 and perplexity is 50.04541169537583
At time: 642.0416111946106 and batch: 250, loss is 3.9145671844482424 and perplexity is 50.12737090949832
At time: 643.322051525116 and batch: 300, loss is 3.923501877784729 and perplexity is 50.577250371080716
At time: 644.5911536216736 and batch: 350, loss is 3.9350887393951415 and perplexity is 51.1666902563474
At time: 645.864509344101 and batch: 400, loss is 3.894485602378845 and perplexity is 49.13077410812038
At time: 647.1365065574646 and batch: 450, loss is 3.9258071279525755 and perplexity is 50.693978077577725
At time: 648.4041314125061 and batch: 500, loss is 3.9305188035964966 and perplexity is 50.933395244476976
At time: 649.6709451675415 and batch: 550, loss is 3.905531268119812 and perplexity is 49.67646442478523
At time: 650.9518485069275 and batch: 600, loss is 3.859239311218262 and perplexity is 47.42925873791612
At time: 652.2342643737793 and batch: 650, loss is 3.8898479557037353 and perplexity is 48.903450467729975
At time: 653.5140650272369 and batch: 700, loss is 3.9389465284347533 and perplexity is 51.36446178835738
At time: 654.7862260341644 and batch: 750, loss is 3.8884919834136964 and perplexity is 48.837183682124476
At time: 656.0580928325653 and batch: 800, loss is 3.8743962049484253 and perplexity is 48.15361459747786
At time: 657.3275496959686 and batch: 850, loss is 3.864608826637268 and perplexity is 47.684615832418324
At time: 658.5959658622742 and batch: 900, loss is 3.834041647911072 and perplexity is 46.24908351689006
At time: 659.8645918369293 and batch: 950, loss is 3.932584886550903 and perplexity is 51.03873664876899
At time: 661.1302545070648 and batch: 1000, loss is 3.8935552644729614 and perplexity is 49.08508714207563
At time: 662.4000146389008 and batch: 1050, loss is 3.8525348043441774 and perplexity is 47.11233255073797
At time: 663.6707100868225 and batch: 1100, loss is 3.8760413408279417 and perplexity is 48.23289903553569
At time: 664.9484016895294 and batch: 1150, loss is 3.851301054954529 and perplexity is 47.05424358019283
At time: 666.2151303291321 and batch: 1200, loss is 3.8875030374526975 and perplexity is 48.7889102204323
At time: 667.483195066452 and batch: 1250, loss is 3.8655145597457885 and perplexity is 47.72782493274731
At time: 668.7495408058167 and batch: 1300, loss is 3.8503099060058594 and perplexity is 47.00762892098922
At time: 670.0156021118164 and batch: 1350, loss is 3.723102025985718 and perplexity is 41.392596071528175
At time: 671.2813742160797 and batch: 1400, loss is 3.7396892738342284 and perplexity is 42.08491125001203
At time: 672.5479574203491 and batch: 1450, loss is 3.6698957204818727 and perplexity is 39.24781290388528
At time: 673.8129172325134 and batch: 1500, loss is 3.669782614707947 and perplexity is 39.24337400066941
At time: 675.0812919139862 and batch: 1550, loss is 3.6975307416915895 and perplexity is 40.34755272468481
At time: 676.3535590171814 and batch: 1600, loss is 3.7872236871719362 and perplexity is 44.13370106867774
At time: 677.6268014907837 and batch: 1650, loss is 3.73958553314209 and perplexity is 42.080545558644204
At time: 678.8939538002014 and batch: 1700, loss is 3.731701736450195 and perplexity is 41.750095405260566
At time: 680.1637511253357 and batch: 1750, loss is 3.7276655292510985 and perplexity is 41.581922987292494
At time: 681.4339418411255 and batch: 1800, loss is 3.682161960601807 and perplexity is 39.73220073645233
At time: 682.705283164978 and batch: 1850, loss is 3.703801279067993 and perplexity is 40.601348448280945
At time: 683.9830553531647 and batch: 1900, loss is 3.8062031745910643 and perplexity is 44.97933556304159
At time: 685.2630913257599 and batch: 1950, loss is 3.751509132385254 and perplexity is 42.58530038680068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333830793513808 and perplexity of 76.2357714022302
finished 13 epochs...
Completing Train Step...
At time: 689.1750979423523 and batch: 50, loss is 3.9601294565200806 and perplexity is 52.46411733155404
At time: 690.4445552825928 and batch: 100, loss is 3.927332110404968 and perplexity is 50.77134448079824
At time: 691.7159955501556 and batch: 150, loss is 3.8922368335723876 and perplexity is 49.02041448901043
At time: 692.9854662418365 and batch: 200, loss is 3.9028123092651366 and perplexity is 49.54157961818544
At time: 694.2588160037994 and batch: 250, loss is 3.903496150970459 and perplexity is 49.57546980291606
At time: 695.5293884277344 and batch: 300, loss is 3.9118268871307373 and perplexity is 49.99019504662637
At time: 696.7957038879395 and batch: 350, loss is 3.9241788721084596 and perplexity is 50.611502475423755
At time: 698.0682253837585 and batch: 400, loss is 3.8841950368881224 and perplexity is 48.62778312906539
At time: 699.339438199997 and batch: 450, loss is 3.916415319442749 and perplexity is 50.220098718219454
At time: 700.6081311702728 and batch: 500, loss is 3.9215711116790772 and perplexity is 50.47969174210131
At time: 701.9055964946747 and batch: 550, loss is 3.89671404838562 and perplexity is 49.24038146717328
At time: 703.172153711319 and batch: 600, loss is 3.851149072647095 and perplexity is 47.047092711095516
At time: 704.4395725727081 and batch: 650, loss is 3.8815534591674803 and perplexity is 48.499498571958156
At time: 705.7104394435883 and batch: 700, loss is 3.9310211515426636 and perplexity is 50.95898795865485
At time: 706.9807844161987 and batch: 750, loss is 3.8813204765319824 and perplexity is 48.488200347156734
At time: 708.2495391368866 and batch: 800, loss is 3.8676962280273437 and perplexity is 47.832064881700155
At time: 709.518367767334 and batch: 850, loss is 3.858133487701416 and perplexity is 47.37683933686212
At time: 710.7892558574677 and batch: 900, loss is 3.8281556701660158 and perplexity is 45.97766201465128
At time: 712.0570929050446 and batch: 950, loss is 3.9267097330093383 and perplexity is 50.73975537484009
At time: 713.3214938640594 and batch: 1000, loss is 3.8872323846817016 and perplexity is 48.7757071534912
At time: 714.5900912284851 and batch: 1050, loss is 3.8459863805770875 and perplexity is 46.804828963299435
At time: 715.877685546875 and batch: 1100, loss is 3.8695542097091673 and perplexity is 47.92101859364809
At time: 717.1581871509552 and batch: 1150, loss is 3.8450690698623657 and perplexity is 46.76191407834183
At time: 718.4403111934662 and batch: 1200, loss is 3.8824373960494993 and perplexity is 48.54238802049542
At time: 719.714937210083 and batch: 1250, loss is 3.8610759496688845 and perplexity is 47.51644918235056
At time: 720.9869484901428 and batch: 1300, loss is 3.846232089996338 and perplexity is 46.816330763634596
At time: 722.2580606937408 and batch: 1350, loss is 3.7197396659851076 and perplexity is 41.253652981421446
At time: 723.5263571739197 and batch: 1400, loss is 3.736467442512512 and perplexity is 41.94953895522405
At time: 724.7952411174774 and batch: 1450, loss is 3.666994047164917 and perplexity is 39.13409364029984
At time: 726.0638098716736 and batch: 1500, loss is 3.667647204399109 and perplexity is 39.15966270606566
At time: 727.3308382034302 and batch: 1550, loss is 3.695507216453552 and perplexity is 40.26599098240594
At time: 728.5977416038513 and batch: 1600, loss is 3.785250334739685 and perplexity is 44.04669559679353
At time: 729.8648884296417 and batch: 1650, loss is 3.7377453947067263 and perplexity is 42.00318273036748
At time: 731.132609128952 and batch: 1700, loss is 3.7302572774887084 and perplexity is 41.689832639833284
At time: 732.3995885848999 and batch: 1750, loss is 3.7267758512496947 and perplexity is 41.54494491688162
At time: 733.6671040058136 and batch: 1800, loss is 3.681383638381958 and perplexity is 39.701288313249094
At time: 734.93572473526 and batch: 1850, loss is 3.7036754989624026 and perplexity is 40.596241927542096
At time: 736.2021160125732 and batch: 1900, loss is 3.8065032005310058 and perplexity is 44.99283255509445
At time: 737.4683511257172 and batch: 1950, loss is 3.7520424842834474 and perplexity is 42.60801939567182
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3334606081940406 and perplexity of 76.20755526173865
finished 14 epochs...
Completing Train Step...
At time: 741.3554029464722 and batch: 50, loss is 3.9551982164382933 and perplexity is 52.20604101442539
At time: 742.6363048553467 and batch: 100, loss is 3.921553349494934 and perplexity is 50.47879512048411
At time: 743.9044559001923 and batch: 150, loss is 3.885083212852478 and perplexity is 48.670992343092706
At time: 745.1719555854797 and batch: 200, loss is 3.8951405477523804 and perplexity is 49.162962621028896
At time: 746.4498860836029 and batch: 250, loss is 3.895190782546997 and perplexity is 49.16543237439216
At time: 747.7210993766785 and batch: 300, loss is 3.903133716583252 and perplexity is 49.55750520358846
At time: 748.9897272586823 and batch: 350, loss is 3.916192708015442 and perplexity is 50.20892039462174
At time: 750.2580280303955 and batch: 400, loss is 3.8767522954940796 and perplexity is 48.26720263287274
At time: 751.5275459289551 and batch: 450, loss is 3.9095988512039184 and perplexity is 49.878939083239764
At time: 752.7960920333862 and batch: 500, loss is 3.9149207353591917 and perplexity is 50.145096620432845
At time: 754.0643918514252 and batch: 550, loss is 3.890459713935852 and perplexity is 48.93337670901144
At time: 755.3323769569397 and batch: 600, loss is 3.845197458267212 and perplexity is 46.76791815131634
At time: 756.6011004447937 and batch: 650, loss is 3.875351896286011 and perplexity is 48.199656587283165
At time: 757.8728656768799 and batch: 700, loss is 3.924966049194336 and perplexity is 50.65135837522167
At time: 759.1401543617249 and batch: 750, loss is 3.875799617767334 and perplexity is 48.22124144057036
At time: 760.4088160991669 and batch: 800, loss is 3.862624502182007 and perplexity is 47.59008790114251
At time: 761.675329208374 and batch: 850, loss is 3.8532989692687987 and perplexity is 47.14834790187178
At time: 762.9426312446594 and batch: 900, loss is 3.8235946559906004 and perplexity is 45.76843475341236
At time: 764.2093236446381 and batch: 950, loss is 3.9217838191986085 and perplexity is 50.490430294163374
At time: 765.5039827823639 and batch: 1000, loss is 3.8819558429718017 and perplexity is 48.51901791157092
At time: 766.7745184898376 and batch: 1050, loss is 3.840802206993103 and perplexity is 46.56281247515643
At time: 768.0416076183319 and batch: 1100, loss is 3.864139633178711 and perplexity is 47.66224777048046
At time: 769.3115084171295 and batch: 1150, loss is 3.8401748514175416 and perplexity is 46.53361019620034
At time: 770.5827105045319 and batch: 1200, loss is 3.8783345460891723 and perplexity is 48.343633893720465
At time: 771.8524417877197 and batch: 1250, loss is 3.857578115463257 and perplexity is 47.35053486062672
At time: 773.1213495731354 and batch: 1300, loss is 3.842895164489746 and perplexity is 46.660368517304185
At time: 774.3897244930267 and batch: 1350, loss is 3.7167364311218263 and perplexity is 41.12994442845111
At time: 775.6586935520172 and batch: 1400, loss is 3.733540959358215 and perplexity is 41.82695379533178
At time: 776.925838470459 and batch: 1450, loss is 3.6643490171432496 and perplexity is 39.03071956178972
At time: 778.1947150230408 and batch: 1500, loss is 3.6653313541412356 and perplexity is 39.0690797198898
At time: 779.4652273654938 and batch: 1550, loss is 3.693082232475281 and perplexity is 40.168464896794156
At time: 780.7353706359863 and batch: 1600, loss is 3.7828868770599366 and perplexity is 43.94271601988445
At time: 782.004821062088 and batch: 1650, loss is 3.735291919708252 and perplexity is 41.90025528826641
At time: 783.275511264801 and batch: 1700, loss is 3.7281820440292357 and perplexity is 41.60340621274288
At time: 784.5445590019226 and batch: 1750, loss is 3.7246821975708007 and perplexity is 41.45805518036446
At time: 785.8121340274811 and batch: 1800, loss is 3.6794916105270388 and perplexity is 39.62624338581775
At time: 787.0801887512207 and batch: 1850, loss is 3.7021631383895874 and perplexity is 40.5348921750133
At time: 788.3463113307953 and batch: 1900, loss is 3.8053395318984986 and perplexity is 44.94050625830225
At time: 789.6143026351929 and batch: 1950, loss is 3.751242961883545 and perplexity is 42.57396694441223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333608228106831 and perplexity of 76.21880584478498
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 793.5041000843048 and batch: 50, loss is 3.9554345655441283 and perplexity is 52.218381323791434
At time: 794.7837855815887 and batch: 100, loss is 3.9292175483703615 and perplexity is 50.867161000904105
At time: 796.0553522109985 and batch: 150, loss is 3.897063341140747 and perplexity is 49.25758377982613
At time: 797.3392703533173 and batch: 200, loss is 3.907130198478699 and perplexity is 49.75595716661951
At time: 798.6079831123352 and batch: 250, loss is 3.9103552150726317 and perplexity is 49.91667998169881
At time: 799.8785357475281 and batch: 300, loss is 3.9203293991088866 and perplexity is 50.41704937428233
At time: 801.1493213176727 and batch: 350, loss is 3.938914542198181 and perplexity is 51.36281885880692
At time: 802.4213552474976 and batch: 400, loss is 3.906220307350159 and perplexity is 49.710705252881034
At time: 803.6919214725494 and batch: 450, loss is 3.946311593055725 and perplexity is 51.744160906550455
At time: 804.9616436958313 and batch: 500, loss is 3.953796148300171 and perplexity is 52.132895876917296
At time: 806.2294907569885 and batch: 550, loss is 3.9404487133026125 and perplexity is 51.441678688110386
At time: 807.4969799518585 and batch: 600, loss is 3.88611563205719 and perplexity is 48.721267158176786
At time: 808.7641003131866 and batch: 650, loss is 3.9047046518325805 and perplexity is 49.63541801735131
At time: 810.0323746204376 and batch: 700, loss is 3.951150975227356 and perplexity is 51.99517756921595
At time: 811.2999804019928 and batch: 750, loss is 3.8980740404129026 and perplexity is 49.30739355101018
At time: 812.5713441371918 and batch: 800, loss is 3.879550271034241 and perplexity is 48.40244219549689
At time: 813.8460338115692 and batch: 850, loss is 3.8689006853103636 and perplexity is 47.88971126994583
At time: 815.1152441501617 and batch: 900, loss is 3.831097002029419 and perplexity is 46.11309665841435
At time: 816.3820514678955 and batch: 950, loss is 3.9339318609237672 and perplexity is 51.10753084066364
At time: 817.6457347869873 and batch: 1000, loss is 3.8926204442977905 and perplexity is 49.03922285308656
At time: 818.9137864112854 and batch: 1050, loss is 3.8527812910079957 and perplexity is 47.123946543701486
At time: 820.1772544384003 and batch: 1100, loss is 3.8757909870147706 and perplexity is 48.220825256763185
At time: 821.4390132427216 and batch: 1150, loss is 3.857801389694214 and perplexity is 47.36110819521579
At time: 822.7002594470978 and batch: 1200, loss is 3.9026230573654175 and perplexity is 49.53220466726923
At time: 823.9631793498993 and batch: 1250, loss is 3.883641982078552 and perplexity is 48.60089673523714
At time: 825.2248373031616 and batch: 1300, loss is 3.8729808568954467 and perplexity is 48.085508680970804
At time: 826.4879994392395 and batch: 1350, loss is 3.7396592473983765 and perplexity is 42.08364760909546
At time: 827.7506971359253 and batch: 1400, loss is 3.756226592063904 and perplexity is 42.786669425994184
At time: 829.0132322311401 and batch: 1450, loss is 3.6806156253814697 and perplexity is 39.670808913474204
At time: 830.2768325805664 and batch: 1500, loss is 3.6750571870803834 and perplexity is 39.45091287521816
At time: 831.5405995845795 and batch: 1550, loss is 3.697779812812805 and perplexity is 40.3576033864931
At time: 832.8028907775879 and batch: 1600, loss is 3.7776716566085815 and perplexity is 43.71414161962653
At time: 834.0653977394104 and batch: 1650, loss is 3.724876070022583 and perplexity is 41.466093534350925
At time: 835.329169511795 and batch: 1700, loss is 3.7162825775146486 and perplexity is 41.11128169020513
At time: 836.592086315155 and batch: 1750, loss is 3.7145189952850344 and perplexity is 41.038842459424856
At time: 837.8570885658264 and batch: 1800, loss is 3.6738814878463746 and perplexity is 39.404557722368274
At time: 839.1213328838348 and batch: 1850, loss is 3.6991344404220583 and perplexity is 40.41230995543246
At time: 840.3852295875549 and batch: 1900, loss is 3.8080618524551393 and perplexity is 45.06301540123426
At time: 841.6532974243164 and batch: 1950, loss is 3.7651686811447145 and perplexity is 43.17098737728466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.329523414789244 and perplexity of 75.90810126874145
finished 16 epochs...
Completing Train Step...
At time: 845.5643699169159 and batch: 50, loss is 3.9760711097717287 and perplexity is 53.307184183502486
At time: 846.8453311920166 and batch: 100, loss is 3.943809943199158 and perplexity is 51.61487691290677
At time: 848.1151916980743 and batch: 150, loss is 3.9047457456588743 and perplexity is 49.637457768507645
At time: 849.3869304656982 and batch: 200, loss is 3.9084392261505125 and perplexity is 49.821131739741375
At time: 850.6579229831696 and batch: 250, loss is 3.907547688484192 and perplexity is 49.77673411823336
At time: 851.9280114173889 and batch: 300, loss is 3.9127159976959227 and perplexity is 50.034661622119735
At time: 853.1983921527863 and batch: 350, loss is 3.9270549964904786 and perplexity is 50.75727698402484
At time: 854.4683792591095 and batch: 400, loss is 3.8911866903305055 and perplexity is 48.96896305243813
At time: 855.7381038665771 and batch: 450, loss is 3.929098296165466 and perplexity is 50.8610953414768
At time: 857.008296251297 and batch: 500, loss is 3.934778552055359 and perplexity is 51.1508214580887
At time: 858.278861284256 and batch: 550, loss is 3.919318995475769 and perplexity is 50.36613353153147
At time: 859.5490267276764 and batch: 600, loss is 3.8689231634140016 and perplexity is 47.89078775193754
At time: 860.8321964740753 and batch: 650, loss is 3.8907467412948606 and perplexity is 48.94742394276936
At time: 862.1030368804932 and batch: 700, loss is 3.938333396911621 and perplexity is 51.332978270421165
At time: 863.3810393810272 and batch: 750, loss is 3.886283392906189 and perplexity is 48.729441364956315
At time: 864.6508963108063 and batch: 800, loss is 3.8702399349212646 and perplexity is 47.95389051355118
At time: 865.9206554889679 and batch: 850, loss is 3.8610713720321654 and perplexity is 47.516231669805876
At time: 867.1907842159271 and batch: 900, loss is 3.8247825145721435 and perplexity is 45.822833484001045
At time: 868.4609079360962 and batch: 950, loss is 3.926754903793335 and perplexity is 50.74204738113564
At time: 869.7300291061401 and batch: 1000, loss is 3.8847014808654787 and perplexity is 48.65241661417687
At time: 870.9989171028137 and batch: 1050, loss is 3.844472360610962 and perplexity is 46.73401913501102
At time: 872.2690954208374 and batch: 1100, loss is 3.8678831005096437 and perplexity is 47.841004213629695
At time: 873.5389516353607 and batch: 1150, loss is 3.8485135078430175 and perplexity is 46.9232603052576
At time: 874.8087849617004 and batch: 1200, loss is 3.893865818977356 and perplexity is 49.10033310421478
At time: 876.0789291858673 and batch: 1250, loss is 3.874711661338806 and perplexity is 48.16880735912345
At time: 877.3595430850983 and batch: 1300, loss is 3.864328589439392 and perplexity is 47.67125470152603
At time: 878.6391694545746 and batch: 1350, loss is 3.733320608139038 and perplexity is 41.8177381904407
At time: 879.9084417819977 and batch: 1400, loss is 3.751295876502991 and perplexity is 42.57621978927509
At time: 881.176619052887 and batch: 1450, loss is 3.677581338882446 and perplexity is 39.55061875149045
At time: 882.4486908912659 and batch: 1500, loss is 3.674557480812073 and perplexity is 39.43120393151532
At time: 883.7243492603302 and batch: 1550, loss is 3.700245246887207 and perplexity is 40.45722515202956
At time: 884.9946558475494 and batch: 1600, loss is 3.781303954124451 and perplexity is 43.873213110236385
At time: 886.2656650543213 and batch: 1650, loss is 3.7295515537261963 and perplexity is 41.66042151357022
At time: 887.5340428352356 and batch: 1700, loss is 3.721409225463867 and perplexity is 41.322585936612256
At time: 888.8060557842255 and batch: 1750, loss is 3.7204256010055543 and perplexity is 41.28196001400536
At time: 890.0739443302155 and batch: 1800, loss is 3.6804485940933227 and perplexity is 39.66418320052564
At time: 891.3480105400085 and batch: 1850, loss is 3.705535078048706 and perplexity is 40.67180408514235
At time: 892.6207795143127 and batch: 1900, loss is 3.814468755722046 and perplexity is 45.35265664275803
At time: 893.8966648578644 and batch: 1950, loss is 3.770639805793762 and perplexity is 43.40782853340755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3276270666787795 and perplexity of 75.76428948602997
finished 17 epochs...
Completing Train Step...
At time: 898.1182587146759 and batch: 50, loss is 3.9759595727920534 and perplexity is 53.301238792755285
At time: 899.4077451229095 and batch: 100, loss is 3.9413630628585814 and perplexity is 51.48873587425733
At time: 900.7220697402954 and batch: 150, loss is 3.9008278226852418 and perplexity is 49.443362505790205
At time: 901.9917802810669 and batch: 200, loss is 3.9033111429214475 and perplexity is 49.566298790350736
At time: 903.2616913318634 and batch: 250, loss is 3.9012316560745237 and perplexity is 49.46333341863772
At time: 904.5333821773529 and batch: 300, loss is 3.9062117385864257 and perplexity is 49.71027929541767
At time: 905.807195186615 and batch: 350, loss is 3.9202667760848997 and perplexity is 50.41389220504679
At time: 907.0773856639862 and batch: 400, loss is 3.883873453140259 and perplexity is 48.612147738494954
At time: 908.3469171524048 and batch: 450, loss is 3.9219077253341674 and perplexity is 50.496686755862825
At time: 909.6147985458374 and batch: 500, loss is 3.927641806602478 and perplexity is 50.78707060816164
At time: 910.8894448280334 and batch: 550, loss is 3.9116004610061648 and perplexity is 49.978877241867025
At time: 912.1583049297333 and batch: 600, loss is 3.8624276304244995 and perplexity is 47.58071967909691
At time: 913.4294016361237 and batch: 650, loss is 3.8850253438949585 and perplexity is 48.6681758849979
At time: 914.6974921226501 and batch: 700, loss is 3.9329043006896973 and perplexity is 51.05504174678158
At time: 915.9672508239746 and batch: 750, loss is 3.8811608171463012 and perplexity is 48.48045936885289
At time: 917.2359027862549 and batch: 800, loss is 3.8659024047851562 and perplexity is 47.746339523051205
At time: 918.524796962738 and batch: 850, loss is 3.856888704299927 and perplexity is 47.31790212328337
At time: 919.798181772232 and batch: 900, loss is 3.821439199447632 and perplexity is 45.66988912482517
At time: 921.0683043003082 and batch: 950, loss is 3.9235986042022706 and perplexity is 50.58214276392623
At time: 922.3370759487152 and batch: 1000, loss is 3.8820006799697877 and perplexity is 48.52119340745029
At time: 923.7005612850189 and batch: 1050, loss is 3.841992287635803 and perplexity is 46.61825896330487
At time: 924.9695773124695 and batch: 1100, loss is 3.8658020734786986 and perplexity is 47.74154931073644
At time: 926.2470209598541 and batch: 1150, loss is 3.846162338256836 and perplexity is 46.81306535701195
At time: 927.5145599842072 and batch: 1200, loss is 3.891704239845276 and perplexity is 48.99431347498831
At time: 928.7845501899719 and batch: 1250, loss is 3.872408456802368 and perplexity is 48.0579924072362
At time: 930.0567388534546 and batch: 1300, loss is 3.8622024345397947 and perplexity is 47.57000590322828
At time: 931.3428184986115 and batch: 1350, loss is 3.731697268486023 and perplexity is 41.74990886774682
At time: 932.613555431366 and batch: 1400, loss is 3.7501942205429075 and perplexity is 42.52934126972781
At time: 933.8867683410645 and batch: 1450, loss is 3.6770485973358156 and perplexity is 39.52955410519091
At time: 935.1559979915619 and batch: 1500, loss is 3.6748779010772705 and perplexity is 39.44384051273635
At time: 936.4239835739136 and batch: 1550, loss is 3.7014312028884886 and perplexity is 40.50523410361892
At time: 937.6938128471375 and batch: 1600, loss is 3.7826174449920655 and perplexity is 43.930878037876944
At time: 938.959793806076 and batch: 1650, loss is 3.7309589481353758 and perplexity is 41.719095436883386
At time: 940.2246994972229 and batch: 1700, loss is 3.722746562957764 and perplexity is 41.37788514874319
At time: 941.4942598342896 and batch: 1750, loss is 3.721925368309021 and perplexity is 41.34391979887327
At time: 942.7681913375854 and batch: 1800, loss is 3.682108373641968 and perplexity is 39.73007166565288
At time: 944.0369625091553 and batch: 1850, loss is 3.706962742805481 and perplexity is 40.72991125533904
At time: 945.3032839298248 and batch: 1900, loss is 3.815757212638855 and perplexity is 45.411129248532426
At time: 946.5762326717377 and batch: 1950, loss is 3.7714012479782104 and perplexity is 43.44089367218636
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.326787904251454 and perplexity of 75.70073760986298
finished 18 epochs...
Completing Train Step...
At time: 950.6270468235016 and batch: 50, loss is 3.9740201234817505 and perplexity is 53.197963922500385
At time: 951.8993592262268 and batch: 100, loss is 3.9386606454849242 and perplexity is 51.34977966328955
At time: 953.1753239631653 and batch: 150, loss is 3.8976863479614257 and perplexity is 49.28828115183428
At time: 954.4448072910309 and batch: 200, loss is 3.8998916292190553 and perplexity is 49.39709561362631
At time: 955.7514100074768 and batch: 250, loss is 3.897474822998047 and perplexity is 49.277856552539006
At time: 957.0232558250427 and batch: 300, loss is 3.902335982322693 and perplexity is 49.51798724832884
At time: 958.2939701080322 and batch: 350, loss is 3.9163946104049683 and perplexity is 50.219058719066474
At time: 959.5625586509705 and batch: 400, loss is 3.879993438720703 and perplexity is 48.4238973475877
At time: 960.8302726745605 and batch: 450, loss is 3.9182115316390993 and perplexity is 50.310385735084466
At time: 962.098358631134 and batch: 500, loss is 3.924141774177551 and perplexity is 50.60962492822851
At time: 963.3657031059265 and batch: 550, loss is 3.908004741668701 and perplexity is 49.799489932989225
At time: 964.6370091438293 and batch: 600, loss is 3.8593815660476682 and perplexity is 47.4360062589491
At time: 965.9068877696991 and batch: 650, loss is 3.882250175476074 and perplexity is 48.533300737464515
At time: 967.1734516620636 and batch: 700, loss is 3.9302365159988404 and perplexity is 50.919019407848594
At time: 968.4396257400513 and batch: 750, loss is 3.8788177013397216 and perplexity is 48.366997017820395
At time: 969.7087635993958 and batch: 800, loss is 3.8638170194625854 and perplexity is 47.6468737556757
At time: 970.9807870388031 and batch: 850, loss is 3.854818096160889 and perplexity is 47.22002665586383
At time: 972.2524540424347 and batch: 900, loss is 3.8196964836120606 and perplexity is 45.5903687966318
At time: 973.5200138092041 and batch: 950, loss is 3.921959285736084 and perplexity is 50.49929045245065
At time: 974.7870697975159 and batch: 1000, loss is 3.880512166023254 and perplexity is 48.449022661267534
At time: 976.05788230896 and batch: 1050, loss is 3.8405488681793214 and perplexity is 46.55101780156502
At time: 977.3277962207794 and batch: 1100, loss is 3.864286618232727 and perplexity is 47.66925392343081
At time: 978.598048210144 and batch: 1150, loss is 3.8444748878479005 and perplexity is 46.734137243099696
At time: 979.8690230846405 and batch: 1200, loss is 3.8899900674819947 and perplexity is 48.910400717883476
At time: 981.1366503238678 and batch: 1250, loss is 3.8707083225250245 and perplexity is 47.976356782469985
At time: 982.4038691520691 and batch: 1300, loss is 3.8605106353759764 and perplexity is 47.48959504570834
At time: 983.6719331741333 and batch: 1350, loss is 3.7301698684692384 and perplexity is 41.686188731697904
At time: 984.949275970459 and batch: 1400, loss is 3.748859601020813 and perplexity is 42.47261864059108
At time: 986.217208147049 and batch: 1450, loss is 3.6760070610046385 and perplexity is 39.48840407178249
At time: 987.4859752655029 and batch: 1500, loss is 3.674302716255188 and perplexity is 39.42115953785034
At time: 988.7568693161011 and batch: 1550, loss is 3.70125696182251 and perplexity is 40.498177043283704
At time: 990.0252959728241 and batch: 1600, loss is 3.78268262386322 and perplexity is 43.93374149623376
At time: 991.2942614555359 and batch: 1650, loss is 3.7311722660064697 and perplexity is 41.72799581477703
At time: 992.563805103302 and batch: 1700, loss is 3.7230105590820313 and perplexity is 41.38881019207394
At time: 993.8348064422607 and batch: 1750, loss is 3.722375540733337 and perplexity is 41.36253588138897
At time: 995.114150762558 and batch: 1800, loss is 3.6826389598846436 and perplexity is 39.75115748852828
At time: 996.3819315433502 and batch: 1850, loss is 3.7073586082458494 and perplexity is 40.746038011396394
At time: 997.6544070243835 and batch: 1900, loss is 3.8160510158538816 and perplexity is 45.424473144447404
At time: 998.9296493530273 and batch: 1950, loss is 3.7714353799819946 and perplexity is 43.44237642223804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.326419422238372 and perplexity of 75.67284838833054
finished 19 epochs...
Completing Train Step...
At time: 1002.8732349872589 and batch: 50, loss is 3.9722644662857056 and perplexity is 53.104648473263985
At time: 1004.1596646308899 and batch: 100, loss is 3.936517610549927 and perplexity is 51.23985312184671
At time: 1005.4298915863037 and batch: 150, loss is 3.895337839126587 and perplexity is 49.17266300635418
At time: 1006.6959073543549 and batch: 200, loss is 3.8974460124969483 and perplexity is 49.27643685324988
At time: 1007.9658191204071 and batch: 250, loss is 3.8948886585235596 and perplexity is 49.15058055980713
At time: 1009.2374839782715 and batch: 300, loss is 3.8995719003677367 and perplexity is 49.38130446156527
At time: 1010.5092194080353 and batch: 350, loss is 3.9136474084854127 and perplexity is 50.081286155729224
At time: 1011.7799215316772 and batch: 400, loss is 3.8772619199752807 and perplexity is 48.29180704994767
At time: 1013.0513098239899 and batch: 450, loss is 3.9156090927124025 and perplexity is 50.17962624941755
At time: 1014.3213500976562 and batch: 500, loss is 3.9216336107254026 and perplexity is 50.482846773286184
At time: 1015.5888664722443 and batch: 550, loss is 3.9054857110977172 and perplexity is 49.67420136454737
At time: 1016.8553576469421 and batch: 600, loss is 3.8571939611434938 and perplexity is 47.332348441536304
At time: 1018.1253066062927 and batch: 650, loss is 3.8802214527130126 and perplexity is 48.43493993262921
At time: 1019.428900718689 and batch: 700, loss is 3.9282972383499146 and perplexity is 50.82036897780978
At time: 1020.6973459720612 and batch: 750, loss is 3.8771304082870484 and perplexity is 48.28545653046767
At time: 1021.965104341507 and batch: 800, loss is 3.8622422218322754 and perplexity is 47.571898622619294
At time: 1023.2363605499268 and batch: 850, loss is 3.8532684898376464 and perplexity is 47.14691086894805
At time: 1024.5071756839752 and batch: 900, loss is 3.818309097290039 and perplexity is 45.52716119936409
At time: 1025.7773025035858 and batch: 950, loss is 3.920613980293274 and perplexity is 50.431399159649196
At time: 1027.045462846756 and batch: 1000, loss is 3.879207158088684 and perplexity is 48.38583753978211
At time: 1028.3127400875092 and batch: 1050, loss is 3.839251971244812 and perplexity is 46.49068506040975
At time: 1029.5803482532501 and batch: 1100, loss is 3.8628619623184206 and perplexity is 47.601389991752335
At time: 1030.8537302017212 and batch: 1150, loss is 3.842930383682251 and perplexity is 46.66201188674423
At time: 1032.12375831604 and batch: 1200, loss is 3.888414144515991 and perplexity is 48.833382397525455
At time: 1033.3932576179504 and batch: 1250, loss is 3.8691931343078614 and perplexity is 47.903718616114524
At time: 1034.659963607788 and batch: 1300, loss is 3.8589899921417237 and perplexity is 47.4174351929056
At time: 1035.9287631511688 and batch: 1350, loss is 3.728760452270508 and perplexity is 41.62747692643984
At time: 1037.2014291286469 and batch: 1400, loss is 3.747580819129944 and perplexity is 42.41834013759578
At time: 1038.4723443984985 and batch: 1450, loss is 3.674977388381958 and perplexity is 39.447764869324075
At time: 1039.743087053299 and batch: 1500, loss is 3.673621110916138 and perplexity is 39.39429902021383
At time: 1041.0139713287354 and batch: 1550, loss is 3.7008346843719484 and perplexity is 40.48107918660321
At time: 1042.2817163467407 and batch: 1600, loss is 3.7825003051757813 and perplexity is 43.925732284286575
At time: 1043.5512714385986 and batch: 1650, loss is 3.73112539768219 and perplexity is 41.72604013936761
At time: 1044.8245804309845 and batch: 1700, loss is 3.7230029296875 and perplexity is 41.38849442171637
At time: 1046.094349861145 and batch: 1750, loss is 3.722522678375244 and perplexity is 41.368622315142616
At time: 1047.3626737594604 and batch: 1800, loss is 3.6828022384643555 and perplexity is 39.757648530974585
At time: 1048.6387798786163 and batch: 1850, loss is 3.7074095726013185 and perplexity is 40.74811465987864
At time: 1049.9177105426788 and batch: 1900, loss is 3.8160150766372682 and perplexity is 45.422840653802915
At time: 1051.1926007270813 and batch: 1950, loss is 3.7712227058410646 and perplexity is 43.433138334538484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.326228935773982 and perplexity of 75.65843510780176
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f98e3f9bb38>
ELAPSED
4311.843786478043


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -76.16006149647069}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.909600321875081, 'seq_len': 35, 'dropout': 0.7290759996057752, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -77.31609076804611}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.43001077421999756, 'seq_len': 35, 'dropout': 0.7678082231043937, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.2714605499234}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.8411519755907202, 'seq_len': 35, 'dropout': 0.7399604006877908, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -75.65843510780176}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.3249180821502161, 'seq_len': 35, 'dropout': 0.0492471584881673, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.98093843460083 and batch: 50, loss is 7.714856376647949 and perplexity is 2241.4009571452953
At time: 3.4822494983673096 and batch: 100, loss is 7.041864385604859 and perplexity is 1143.5175781795099
At time: 4.9628376960754395 and batch: 150, loss is 6.642067718505859 and perplexity is 766.678630790176
At time: 6.443210601806641 and batch: 200, loss is 6.342555646896362 and perplexity is 568.2466951606382
At time: 7.926662921905518 and batch: 250, loss is 6.176550941467285 and perplexity is 481.3289583617855
At time: 9.411054849624634 and batch: 300, loss is 6.064641828536987 and perplexity is 430.36850434676813
At time: 10.89332628250122 and batch: 350, loss is 5.957861728668213 and perplexity is 386.7821941063033
At time: 12.37644624710083 and batch: 400, loss is 5.855877056121826 and perplexity is 349.2811048862242
At time: 13.86497712135315 and batch: 450, loss is 5.740665426254273 and perplexity is 311.2714702909398
At time: 15.350429773330688 and batch: 500, loss is 5.6928842258453365 and perplexity is 296.7482765865166
At time: 16.833083629608154 and batch: 550, loss is 5.619984712600708 and perplexity is 275.8851656358585
At time: 18.31620478630066 and batch: 600, loss is 5.618773450851441 and perplexity is 275.5511987889989
At time: 19.798299551010132 and batch: 650, loss is 5.676011171340942 and perplexity is 291.78323226838995
At time: 21.28315281867981 and batch: 700, loss is 5.579098844528199 and perplexity is 264.8328426557621
At time: 22.76936101913452 and batch: 750, loss is 5.489021596908569 and perplexity is 242.02029757313005
At time: 24.25569987297058 and batch: 800, loss is 5.482460680007935 and perplexity is 240.4376200974603
At time: 25.74150252342224 and batch: 850, loss is 5.48374979019165 and perplexity is 240.74777054817767
At time: 27.227972984313965 and batch: 900, loss is 5.469854717254639 and perplexity is 237.4256963983722
At time: 28.71216654777527 and batch: 950, loss is 5.474546422958374 and perplexity is 238.54224510321006
At time: 30.1937735080719 and batch: 1000, loss is 5.428508396148682 and perplexity is 227.8091908072906
At time: 31.67551040649414 and batch: 1050, loss is 5.329046182632446 and perplexity is 206.24116390667336
At time: 33.16044807434082 and batch: 1100, loss is 5.394065113067627 and perplexity is 220.09628574153987
At time: 34.64610004425049 and batch: 1150, loss is 5.2927030754089355 and perplexity is 198.88028790815116
At time: 36.13201332092285 and batch: 1200, loss is 5.356065311431885 and perplexity is 211.88958455678372
At time: 37.61665153503418 and batch: 1250, loss is 5.313569297790528 and perplexity is 203.07376710566908
At time: 39.10014629364014 and batch: 1300, loss is 5.321946525573731 and perplexity is 204.7821078988421
At time: 40.583107471466064 and batch: 1350, loss is 5.248350896835327 and perplexity is 190.25226400626536
At time: 42.07047653198242 and batch: 1400, loss is 5.249977283477783 and perplexity is 190.5619395049283
At time: 43.557806968688965 and batch: 1450, loss is 5.210531311035156 and perplexity is 183.19136393482603
At time: 45.041970014572144 and batch: 1500, loss is 5.1636010265350345 and perplexity is 174.79275701728082
At time: 46.53094720840454 and batch: 1550, loss is 5.154763879776001 and perplexity is 173.25489294465478
At time: 48.0163369178772 and batch: 1600, loss is 5.181466913223266 and perplexity is 177.9436475238625
At time: 49.502846002578735 and batch: 1650, loss is 5.160002269744873 and perplexity is 174.1648509144396
At time: 50.98887348175049 and batch: 1700, loss is 5.17437370300293 and perplexity is 176.68592175463405
At time: 52.47581934928894 and batch: 1750, loss is 5.166489448547363 and perplexity is 175.29836211316828
At time: 53.96199297904968 and batch: 1800, loss is 5.128996839523316 and perplexity is 168.84765176732895
At time: 55.44835376739502 and batch: 1850, loss is 5.118324842453003 and perplexity is 167.05529116706697
At time: 56.93563747406006 and batch: 1900, loss is 5.185499639511108 and perplexity is 178.66269443419424
At time: 58.42581343650818 and batch: 1950, loss is 5.104418516159058 and perplexity is 164.7482442317745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.840071425327035 and perplexity of 126.47838516752627
finished 1 epochs...
Completing Train Step...
At time: 62.54797124862671 and batch: 50, loss is 5.0819863510131835 and perplexity is 161.09372702188713
At time: 63.81761312484741 and batch: 100, loss is 5.037794723510742 and perplexity is 154.1297412702184
At time: 65.08438158035278 and batch: 150, loss is 4.962501668930054 and perplexity is 142.95096493887652
At time: 66.35133719444275 and batch: 200, loss is 4.935323438644409 and perplexity is 139.11813143595558
At time: 67.61852073669434 and batch: 250, loss is 4.957552900314331 and perplexity is 142.24528126281453
At time: 68.88865494728088 and batch: 300, loss is 4.954344406127929 and perplexity is 141.78961948981282
At time: 70.15891361236572 and batch: 350, loss is 4.96018235206604 and perplexity is 142.61980054120363
At time: 71.42790150642395 and batch: 400, loss is 4.90101734161377 and perplexity is 134.4264677835692
At time: 72.70049095153809 and batch: 450, loss is 4.865198850631714 and perplexity is 129.69672632373334
At time: 74.0170648097992 and batch: 500, loss is 4.865323429107666 and perplexity is 129.71288475070992
At time: 75.28557324409485 and batch: 550, loss is 4.826966228485108 and perplexity is 124.8316748331442
At time: 76.55469608306885 and batch: 600, loss is 4.801362867355347 and perplexity is 121.6761329985645
At time: 77.8246238231659 and batch: 650, loss is 4.866298971176147 and perplexity is 129.83948686941426
At time: 79.09276723861694 and batch: 700, loss is 4.870345029830933 and perplexity is 130.36588925833968
At time: 80.3624062538147 and batch: 750, loss is 4.812238693237305 and perplexity is 123.00668373896953
At time: 81.6326813697815 and batch: 800, loss is 4.8144254398345945 and perplexity is 123.27596250098345
At time: 82.90622067451477 and batch: 850, loss is 4.808430252075195 and perplexity is 122.53911094828283
At time: 84.17429900169373 and batch: 900, loss is 4.789103317260742 and perplexity is 120.19354485152601
At time: 85.44010043144226 and batch: 950, loss is 4.845080356597901 and perplexity is 127.11349599143551
At time: 86.70543551445007 and batch: 1000, loss is 4.810419988632202 and perplexity is 122.78317422729246
At time: 87.97168731689453 and batch: 1050, loss is 4.740209941864014 and perplexity is 114.45822873182007
At time: 89.23948192596436 and batch: 1100, loss is 4.788992834091187 and perplexity is 120.18026622127681
At time: 90.5061902999878 and batch: 1150, loss is 4.720139808654785 and perplexity is 112.18393585662155
At time: 91.77415704727173 and batch: 1200, loss is 4.7971302318573 and perplexity is 121.1622106689691
At time: 93.0409619808197 and batch: 1250, loss is 4.774749116897583 and perplexity is 118.48058611466868
At time: 94.30774331092834 and batch: 1300, loss is 4.770839834213257 and perplexity is 118.01831617160332
At time: 95.57423281669617 and batch: 1350, loss is 4.6627254295349125 and perplexity is 105.92437854220907
At time: 96.83964848518372 and batch: 1400, loss is 4.667373352050781 and perplexity is 106.41785277282429
At time: 98.10656547546387 and batch: 1450, loss is 4.623468856811524 and perplexity is 101.84671173810999
At time: 99.37771320343018 and batch: 1500, loss is 4.603768091201783 and perplexity is 99.85988876893579
At time: 100.64926290512085 and batch: 1550, loss is 4.60622091293335 and perplexity is 100.10512791522045
At time: 101.919602394104 and batch: 1600, loss is 4.674245557785034 and perplexity is 107.15169682641809
At time: 103.19929432868958 and batch: 1650, loss is 4.641700868606567 and perplexity is 103.72061277294279
At time: 104.47627425193787 and batch: 1700, loss is 4.6560885524749756 and perplexity is 105.22369919747536
At time: 105.75318050384521 and batch: 1750, loss is 4.641743450164795 and perplexity is 103.72502945228888
At time: 107.02217960357666 and batch: 1800, loss is 4.604342250823975 and perplexity is 99.91724074796326
At time: 108.29067134857178 and batch: 1850, loss is 4.631108961105347 and perplexity is 102.62781127927889
At time: 109.5732216835022 and batch: 1900, loss is 4.735364847183227 and perplexity is 113.90500905969756
At time: 110.84393668174744 and batch: 1950, loss is 4.6474676609039305 and perplexity is 104.3204759846192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.581590377452762 and perplexity of 97.66960228792279
finished 2 epochs...
Completing Train Step...
At time: 114.76526474952698 and batch: 50, loss is 4.6539599895477295 and perplexity is 104.99996213597846
At time: 116.04756498336792 and batch: 100, loss is 4.590357055664063 and perplexity is 98.52960443532736
At time: 117.31719660758972 and batch: 150, loss is 4.534129943847656 and perplexity is 93.14244088615276
At time: 118.5872871875763 and batch: 200, loss is 4.524696969985962 and perplexity is 92.2679616301681
At time: 119.85411095619202 and batch: 250, loss is 4.543324747085571 and perplexity is 94.0028167348646
At time: 121.12058925628662 and batch: 300, loss is 4.555467624664306 and perplexity is 95.15123990032086
At time: 122.38822841644287 and batch: 350, loss is 4.569864015579224 and perplexity is 96.5309821705928
At time: 123.65814232826233 and batch: 400, loss is 4.5073717594146725 and perplexity is 90.68316785008038
At time: 124.92797422409058 and batch: 450, loss is 4.50661787033081 and perplexity is 90.6148285631061
At time: 126.19515991210938 and batch: 500, loss is 4.5125612545013425 and perplexity is 91.15499090691677
At time: 127.46386694908142 and batch: 550, loss is 4.483749055862427 and perplexity is 88.56609025584208
At time: 128.73233556747437 and batch: 600, loss is 4.462178802490234 and perplexity is 86.67615373159565
At time: 130.00134944915771 and batch: 650, loss is 4.522274618148804 and perplexity is 92.04472664979275
At time: 131.27037024497986 and batch: 700, loss is 4.547877759933471 and perplexity is 94.43178858331997
At time: 132.53800916671753 and batch: 750, loss is 4.49725338935852 and perplexity is 89.77022851789826
At time: 133.80635738372803 and batch: 800, loss is 4.496277656555176 and perplexity is 89.68267948034948
At time: 135.07064723968506 and batch: 850, loss is 4.486451272964477 and perplexity is 88.80573870483622
At time: 136.35160517692566 and batch: 900, loss is 4.461341276168823 and perplexity is 86.60359056243045
At time: 137.62047410011292 and batch: 950, loss is 4.529072036743164 and perplexity is 92.67252447125135
At time: 138.889093875885 and batch: 1000, loss is 4.507509307861328 and perplexity is 90.6956420368388
At time: 140.15630674362183 and batch: 1050, loss is 4.444846048355102 and perplexity is 85.18676218559841
At time: 141.42637872695923 and batch: 1100, loss is 4.479961023330689 and perplexity is 88.23123364901416
At time: 142.6952199935913 and batch: 1150, loss is 4.434759349822998 and perplexity is 84.33182797683138
At time: 143.9656901359558 and batch: 1200, loss is 4.50598726272583 and perplexity is 90.55770417651952
At time: 145.23516416549683 and batch: 1250, loss is 4.495061893463134 and perplexity is 89.57371284087296
At time: 146.5029275417328 and batch: 1300, loss is 4.482975730895996 and perplexity is 88.49762636289886
At time: 147.7715470790863 and batch: 1350, loss is 4.370511293411255 and perplexity is 79.08405652124593
At time: 149.0423240661621 and batch: 1400, loss is 4.381506938934326 and perplexity is 79.95843514231076
At time: 150.31237721443176 and batch: 1450, loss is 4.335119571685791 and perplexity is 76.3340857394156
At time: 151.58304452896118 and batch: 1500, loss is 4.326480650901795 and perplexity is 75.6774818775445
At time: 152.85214710235596 and batch: 1550, loss is 4.3362767791748045 and perplexity is 76.42247124542169
At time: 154.11890864372253 and batch: 1600, loss is 4.412313461303711 and perplexity is 82.4600110516987
At time: 155.3846514225006 and batch: 1650, loss is 4.37452615737915 and perplexity is 79.40220648726721
At time: 156.6493330001831 and batch: 1700, loss is 4.390749921798706 and perplexity is 80.70091566958504
At time: 157.91698145866394 and batch: 1750, loss is 4.380767345428467 and perplexity is 79.89932026612478
At time: 159.18485236167908 and batch: 1800, loss is 4.336520833969116 and perplexity is 76.44112479207344
At time: 160.45188903808594 and batch: 1850, loss is 4.374523191452027 and perplexity is 79.40197098645855
At time: 161.72044682502747 and batch: 1900, loss is 4.485178480148315 and perplexity is 88.69277930078725
At time: 162.9871289730072 and batch: 1950, loss is 4.400897369384766 and perplexity is 81.52399298572693
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479111214571221 and perplexity of 88.15628582397012
finished 3 epochs...
Completing Train Step...
At time: 166.90088939666748 and batch: 50, loss is 4.403615684509277 and perplexity is 81.74590236203245
At time: 168.1793019771576 and batch: 100, loss is 4.3415821933746335 and perplexity is 76.82900156184537
At time: 169.44777750968933 and batch: 150, loss is 4.296206426620484 and perplexity is 73.42073776837955
At time: 170.71615409851074 and batch: 200, loss is 4.29309832572937 and perplexity is 73.19289297362083
At time: 171.98205041885376 and batch: 250, loss is 4.304771642684937 and perplexity is 74.05230313677798
At time: 173.24765872955322 and batch: 300, loss is 4.318999700546264 and perplexity is 75.11345475250891
At time: 174.5151562690735 and batch: 350, loss is 4.330361280441284 and perplexity is 75.9717287114082
At time: 175.7808084487915 and batch: 400, loss is 4.2742708301544186 and perplexity is 71.82774558386215
At time: 177.04518175125122 and batch: 450, loss is 4.292551431655884 and perplexity is 73.15287515798276
At time: 178.30999112129211 and batch: 500, loss is 4.300935525894165 and perplexity is 73.7687740264063
At time: 179.5750608444214 and batch: 550, loss is 4.270408477783203 and perplexity is 71.55085658603959
At time: 180.84223556518555 and batch: 600, loss is 4.2503643274307255 and perplexity is 70.13095832471578
At time: 182.10869455337524 and batch: 650, loss is 4.307546243667603 and perplexity is 74.25805403615753
At time: 183.37505531311035 and batch: 700, loss is 4.341843948364258 and perplexity is 76.84911456857716
At time: 184.64283180236816 and batch: 750, loss is 4.29539797782898 and perplexity is 73.36140484870462
At time: 185.91317629814148 and batch: 800, loss is 4.290493936538696 and perplexity is 73.00251820692527
At time: 187.17860984802246 and batch: 850, loss is 4.276588525772095 and perplexity is 71.99441350317484
At time: 188.44739270210266 and batch: 900, loss is 4.253392910957336 and perplexity is 70.34367774647754
At time: 189.7182879447937 and batch: 950, loss is 4.330029745101928 and perplexity is 75.94654557332919
At time: 190.98799514770508 and batch: 1000, loss is 4.306776971817016 and perplexity is 74.20095137206023
At time: 192.25766348838806 and batch: 1050, loss is 4.255437707901001 and perplexity is 70.48766344432775
At time: 193.52812790870667 and batch: 1100, loss is 4.283272681236267 and perplexity is 72.47724722574802
At time: 194.7976212501526 and batch: 1150, loss is 4.248266835212707 and perplexity is 69.98401334723427
At time: 196.06602334976196 and batch: 1200, loss is 4.31385929107666 and perplexity is 74.72833153196422
At time: 197.33223223686218 and batch: 1250, loss is 4.303924608230591 and perplexity is 73.98960484215398
At time: 198.5992774963379 and batch: 1300, loss is 4.293367538452149 and perplexity is 73.21260008420971
At time: 199.86644434928894 and batch: 1350, loss is 4.172177534103394 and perplexity is 64.85652575197601
At time: 201.13948035240173 and batch: 1400, loss is 4.195899782180786 and perplexity is 66.41346235090974
At time: 202.41131973266602 and batch: 1450, loss is 4.146170444488526 and perplexity is 63.19154082498822
At time: 203.68883061408997 and batch: 1500, loss is 4.143014621734619 and perplexity is 62.992433860987816
At time: 204.95722484588623 and batch: 1550, loss is 4.155620307922363 and perplexity is 63.79152266432623
At time: 206.22363257408142 and batch: 1600, loss is 4.232164711952209 and perplexity is 68.86614630760783
At time: 207.49088954925537 and batch: 1650, loss is 4.194799427986145 and perplexity is 66.3404242103129
At time: 208.75771641731262 and batch: 1700, loss is 4.2119962596893314 and perplexity is 67.49113525438476
At time: 210.023992061615 and batch: 1750, loss is 4.201994433403015 and perplexity is 66.81946520655981
At time: 211.29333925247192 and batch: 1800, loss is 4.161052422523499 and perplexity is 64.13898840847683
At time: 212.56326508522034 and batch: 1850, loss is 4.202170963287354 and perplexity is 66.83126188022639
At time: 213.8321008682251 and batch: 1900, loss is 4.310460395812989 and perplexity is 74.47476892034453
At time: 215.1016240119934 and batch: 1950, loss is 4.2309191608428955 and perplexity is 68.78042339989416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.439441769622093 and perplexity of 84.72763093247545
finished 4 epochs...
Completing Train Step...
At time: 219.02364110946655 and batch: 50, loss is 4.2284872388839725 and perplexity is 68.61335800522366
At time: 220.3183183670044 and batch: 100, loss is 4.1701712322235105 and perplexity is 64.72653442696091
At time: 221.58868789672852 and batch: 150, loss is 4.1309179592132566 and perplexity is 62.23502593708365
At time: 222.85887360572815 and batch: 200, loss is 4.129788041114807 and perplexity is 62.16474516815364
At time: 224.1242265701294 and batch: 250, loss is 4.1379440402984615 and perplexity is 62.67383402107182
At time: 225.39155960083008 and batch: 300, loss is 4.150191593170166 and perplexity is 63.44615498367693
At time: 226.6596384048462 and batch: 350, loss is 4.159956316947937 and perplexity is 64.06872382140921
At time: 227.92814564704895 and batch: 400, loss is 4.107189583778381 and perplexity is 60.775672392562726
At time: 229.19649147987366 and batch: 450, loss is 4.137149896621704 and perplexity is 62.62408174992635
At time: 230.46399402618408 and batch: 500, loss is 4.148226523399353 and perplexity is 63.32160128088266
At time: 231.75736284255981 and batch: 550, loss is 4.1149182748794555 and perplexity is 61.24720862270378
At time: 233.02536177635193 and batch: 600, loss is 4.0960114431381225 and perplexity is 60.100096256054414
At time: 234.30061531066895 and batch: 650, loss is 4.153056449890137 and perplexity is 63.62817974006564
At time: 235.57652759552002 and batch: 700, loss is 4.1920523881912235 and perplexity is 66.15843450591996
At time: 236.84432744979858 and batch: 750, loss is 4.148592667579651 and perplexity is 63.34479036169321
At time: 238.11074662208557 and batch: 800, loss is 4.137746739387512 and perplexity is 62.66146963631906
At time: 239.37501764297485 and batch: 850, loss is 4.120424647331237 and perplexity is 61.58538878350097
At time: 240.64185166358948 and batch: 900, loss is 4.09784508228302 and perplexity is 60.21039924219286
At time: 241.91114830970764 and batch: 950, loss is 4.182840261459351 and perplexity is 65.55177323339801
At time: 243.1808259487152 and batch: 1000, loss is 4.1604034090042115 and perplexity is 64.09737484323024
At time: 244.4506540298462 and batch: 1050, loss is 4.118336658477784 and perplexity is 61.45693333163014
At time: 245.7185890674591 and batch: 1100, loss is 4.139737191200257 and perplexity is 62.786318483733375
At time: 246.986811876297 and batch: 1150, loss is 4.108070554733277 and perplexity is 60.82923758593022
At time: 248.25526022911072 and batch: 1200, loss is 4.172777447700501 and perplexity is 64.89544573678249
At time: 249.52337217330933 and batch: 1250, loss is 4.161425499916077 and perplexity is 64.16292167923841
At time: 250.79251432418823 and batch: 1300, loss is 4.143800854682922 and perplexity is 63.04198006285902
At time: 252.06202268600464 and batch: 1350, loss is 4.027841343879699 and perplexity is 56.13959427465246
At time: 253.32881426811218 and batch: 1400, loss is 4.054214935302735 and perplexity is 57.639894182937404
At time: 254.59406328201294 and batch: 1450, loss is 4.004607443809509 and perplexity is 54.85028835204955
At time: 255.8617115020752 and batch: 1500, loss is 4.001586089134216 and perplexity is 54.68481627768579
At time: 257.1289949417114 and batch: 1550, loss is 4.018530368804932 and perplexity is 55.619305866682055
At time: 258.3949294090271 and batch: 1600, loss is 4.097241377830505 and perplexity is 60.17406092598794
At time: 259.6617648601532 and batch: 1650, loss is 4.061709060668945 and perplexity is 58.07347741033403
At time: 260.9302637577057 and batch: 1700, loss is 4.076308598518372 and perplexity is 58.92754265070414
At time: 262.1968312263489 and batch: 1750, loss is 4.067835454940796 and perplexity is 58.430350486070296
At time: 263.4829640388489 and batch: 1800, loss is 4.025479259490967 and perplexity is 56.007144306011234
At time: 264.74946880340576 and batch: 1850, loss is 4.067423248291016 and perplexity is 58.406270070445665
At time: 266.0170934200287 and batch: 1900, loss is 4.1768384408950805 and perplexity is 65.15952154238276
At time: 267.2883405685425 and batch: 1950, loss is 4.09840353012085 and perplexity is 60.244032999940075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.43114013671875 and perplexity of 84.027164773
finished 5 epochs...
Completing Train Step...
At time: 271.23384189605713 and batch: 50, loss is 4.095392227172852 and perplexity is 60.06289283660273
At time: 272.5092737674713 and batch: 100, loss is 4.041306962966919 and perplexity is 56.900661286233344
At time: 273.77925848960876 and batch: 150, loss is 3.999329752922058 and perplexity is 54.5615680434788
At time: 275.04623198509216 and batch: 200, loss is 3.9989438247680664 and perplexity is 54.54051526093695
At time: 276.3151352405548 and batch: 250, loss is 4.006240434646607 and perplexity is 54.93993154367522
At time: 277.58427715301514 and batch: 300, loss is 4.017659921646118 and perplexity is 55.57091326457221
At time: 278.8566224575043 and batch: 350, loss is 4.028723216056823 and perplexity is 56.18912405713693
At time: 280.12374687194824 and batch: 400, loss is 3.9811335706710818 and perplexity is 53.57773396511604
At time: 281.39157915115356 and batch: 450, loss is 4.016793751716614 and perplexity is 55.52280025057842
At time: 282.65691208839417 and batch: 500, loss is 4.029321608543396 and perplexity is 56.22275726872675
At time: 283.92434430122375 and batch: 550, loss is 3.996676092147827 and perplexity is 54.41697208973927
At time: 285.19379353523254 and batch: 600, loss is 3.978815860748291 and perplexity is 53.45370011223377
At time: 286.4623565673828 and batch: 650, loss is 4.026759934425354 and perplexity is 56.078917200934555
At time: 287.7298722267151 and batch: 700, loss is 4.071424932479858 and perplexity is 58.64046178603999
At time: 288.996928691864 and batch: 750, loss is 4.034725623130798 and perplexity is 56.52740829704873
At time: 290.2654638290405 and batch: 800, loss is 4.020538759231568 and perplexity is 55.73112339716381
At time: 291.530775308609 and batch: 850, loss is 4.000555973052979 and perplexity is 54.62851357317807
At time: 292.79861545562744 and batch: 900, loss is 3.9778735065460205 and perplexity is 53.4033515201357
At time: 294.07954359054565 and batch: 950, loss is 4.071225852966308 and perplexity is 58.628788833394715
At time: 295.3466486930847 and batch: 1000, loss is 4.044581489562988 and perplexity is 57.08728940756212
At time: 296.61348485946655 and batch: 1050, loss is 4.002811455726624 and perplexity is 54.75186629670132
At time: 297.88255310058594 and batch: 1100, loss is 4.025167636871338 and perplexity is 55.989693932091456
At time: 299.1512985229492 and batch: 1150, loss is 3.999077625274658 and perplexity is 54.54781329773826
At time: 300.4217207431793 and batch: 1200, loss is 4.0632560920715335 and perplexity is 58.163388433201185
At time: 301.6913321018219 and batch: 1250, loss is 4.047901463508606 and perplexity is 57.277132684012344
At time: 302.98405146598816 and batch: 1300, loss is 4.032028479576111 and perplexity is 56.375151184043226
At time: 304.2539644241333 and batch: 1350, loss is 3.9131009864807127 and perplexity is 50.053928114148725
At time: 305.52246284484863 and batch: 1400, loss is 3.9458188915252688 and perplexity is 51.71867275881993
At time: 306.7889060974121 and batch: 1450, loss is 3.8951872062683104 and perplexity is 49.16525654541865
At time: 308.0535304546356 and batch: 1500, loss is 3.889627847671509 and perplexity is 48.89268761001762
At time: 309.31906151771545 and batch: 1550, loss is 3.907804594039917 and perplexity is 49.78952368055864
At time: 310.58579659461975 and batch: 1600, loss is 3.9876540994644163 and perplexity is 53.92823059194428
At time: 311.85209107398987 and batch: 1650, loss is 3.9567943811416626 and perplexity is 52.28943699354845
At time: 313.1180989742279 and batch: 1700, loss is 3.9659868812561037 and perplexity is 52.77232371681979
At time: 314.3837869167328 and batch: 1750, loss is 3.961412205696106 and perplexity is 52.5314588167154
At time: 315.65020394325256 and batch: 1800, loss is 3.917454175949097 and perplexity is 50.272297303247655
At time: 316.91931796073914 and batch: 1850, loss is 3.9607012462615967 and perplexity is 52.49412435367808
At time: 318.1919376850128 and batch: 1900, loss is 4.067002491950989 and perplexity is 58.381700431294384
At time: 319.46531891822815 and batch: 1950, loss is 3.9919600963592528 and perplexity is 54.16094606188619
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.437911916333576 and perplexity of 84.59810918756047
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 323.4552733898163 and batch: 50, loss is 4.033269281387329 and perplexity is 56.445144988979926
At time: 324.7264013290405 and batch: 100, loss is 4.012326974868774 and perplexity is 55.27534536620291
At time: 326.004022359848 and batch: 150, loss is 3.975689630508423 and perplexity is 53.286852476460126
At time: 327.26721930503845 and batch: 200, loss is 3.9700540685653687 and perplexity is 52.987395714694536
At time: 328.53650999069214 and batch: 250, loss is 3.971481122970581 and perplexity is 53.063065590843266
At time: 329.80749797821045 and batch: 300, loss is 3.977556290626526 and perplexity is 53.386413813476274
At time: 331.0761561393738 and batch: 350, loss is 3.9906440925598146 and perplexity is 54.08971693027144
At time: 332.34548830986023 and batch: 400, loss is 3.9439205360412597 and perplexity is 51.62058546449597
At time: 333.6131749153137 and batch: 450, loss is 3.96524215221405 and perplexity is 52.73303726542764
At time: 334.881689786911 and batch: 500, loss is 3.9804996395111085 and perplexity is 53.543780133407836
At time: 336.150048494339 and batch: 550, loss is 3.9478292655944824 and perplexity is 51.82275122069521
At time: 337.41505336761475 and batch: 600, loss is 3.9116243934631347 and perplexity is 49.98007337350915
At time: 338.68804144859314 and batch: 650, loss is 3.953813271522522 and perplexity is 52.133788567728054
At time: 339.96790957450867 and batch: 700, loss is 3.999269824028015 and perplexity is 54.558298327024936
At time: 341.2384023666382 and batch: 750, loss is 3.9457906818389894 and perplexity is 51.71721381186493
At time: 342.50708961486816 and batch: 800, loss is 3.93759024143219 and perplexity is 51.29484405792354
At time: 343.78150606155396 and batch: 850, loss is 3.9089416313171386 and perplexity is 49.84616842248733
At time: 345.0495367050171 and batch: 900, loss is 3.86620943069458 and perplexity is 47.76100113699743
At time: 346.3161702156067 and batch: 950, loss is 3.965870475769043 and perplexity is 52.7661810862991
At time: 347.5841727256775 and batch: 1000, loss is 3.935705876350403 and perplexity is 51.198276857409915
At time: 348.85714530944824 and batch: 1050, loss is 3.883176326751709 and perplexity is 48.578270737150135
At time: 350.1289474964142 and batch: 1100, loss is 3.8995705604553224 and perplexity is 49.381238294986716
At time: 351.3980588912964 and batch: 1150, loss is 3.8800490283966065 and perplexity is 48.426589291168675
At time: 352.6671779155731 and batch: 1200, loss is 3.917253198623657 and perplexity is 50.262194726620365
At time: 353.9348466396332 and batch: 1250, loss is 3.899599719047546 and perplexity is 49.38267820337042
At time: 355.2031219005585 and batch: 1300, loss is 3.877466654777527 and perplexity is 48.301695075691114
At time: 356.4705173969269 and batch: 1350, loss is 3.7621625518798827 and perplexity is 43.041404677495684
At time: 357.73739552497864 and batch: 1400, loss is 3.779524564743042 and perplexity is 43.79521499578803
At time: 359.0043706893921 and batch: 1450, loss is 3.718585271835327 and perplexity is 41.20605748303065
At time: 360.2706458568573 and batch: 1500, loss is 3.7091545629501343 and perplexity is 40.819281801621706
At time: 361.53776121139526 and batch: 1550, loss is 3.726956081390381 and perplexity is 41.55243324293955
At time: 362.8044230937958 and batch: 1600, loss is 3.8032392406463624 and perplexity is 44.84621715808839
At time: 364.07093715667725 and batch: 1650, loss is 3.768017530441284 and perplexity is 43.294150367406914
At time: 365.33651185035706 and batch: 1700, loss is 3.7598277950286865 and perplexity is 42.941030683071006
At time: 366.6046509742737 and batch: 1750, loss is 3.73955952167511 and perplexity is 42.079450996158556
At time: 367.87501549720764 and batch: 1800, loss is 3.6830260515213014 and perplexity is 39.766547807679295
At time: 369.14139103889465 and batch: 1850, loss is 3.719991011619568 and perplexity is 41.26402321020513
At time: 370.41186022758484 and batch: 1900, loss is 3.8181934452056883 and perplexity is 45.52189619273718
At time: 371.6825706958771 and batch: 1950, loss is 3.751318359375 and perplexity is 42.57717703573603
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365981842750727 and perplexity of 78.72665920697689
finished 7 epochs...
Completing Train Step...
At time: 375.61201429367065 and batch: 50, loss is 3.9482430744171144 and perplexity is 51.844200369980925
At time: 376.8771834373474 and batch: 100, loss is 3.9070731592178345 and perplexity is 49.753119204537526
At time: 378.1440689563751 and batch: 150, loss is 3.8635228872299194 and perplexity is 47.632861335171675
At time: 379.41287302970886 and batch: 200, loss is 3.861145749092102 and perplexity is 47.51976591884865
At time: 380.681898355484 and batch: 250, loss is 3.8587207889556883 and perplexity is 47.404671986303065
At time: 381.95097827911377 and batch: 300, loss is 3.863691644668579 and perplexity is 47.64090041315466
At time: 383.21996903419495 and batch: 350, loss is 3.8779832887649537 and perplexity is 48.32665582024685
At time: 384.48855471611023 and batch: 400, loss is 3.8346807765960693 and perplexity is 46.278652080872725
At time: 385.7556862831116 and batch: 450, loss is 3.8622504568099973 and perplexity is 47.57229037775769
At time: 387.02207493782043 and batch: 500, loss is 3.8812148857116697 and perplexity is 48.48308070860477
At time: 388.3021311759949 and batch: 550, loss is 3.8478795433044435 and perplexity is 46.89352204968554
At time: 389.5725739002228 and batch: 600, loss is 3.8178964376449587 and perplexity is 45.50837785301312
At time: 390.84234833717346 and batch: 650, loss is 3.8608719062805177 and perplexity is 47.50675475413186
At time: 392.1112382411957 and batch: 700, loss is 3.90827269077301 and perplexity is 49.812835449591574
At time: 393.3817481994629 and batch: 750, loss is 3.8566832971572875 and perplexity is 47.30818368636488
At time: 394.65055751800537 and batch: 800, loss is 3.8496195697784423 and perplexity is 46.975189050277365
At time: 395.9152216911316 and batch: 850, loss is 3.8245959997177126 and perplexity is 45.81428764187219
At time: 397.18505358695984 and batch: 900, loss is 3.7821013069152833 and perplexity is 43.90820948952883
At time: 398.45613408088684 and batch: 950, loss is 3.884635272026062 and perplexity is 48.649195500772294
At time: 399.725399017334 and batch: 1000, loss is 3.8575316572189333 and perplexity is 47.34833508900848
At time: 400.9912474155426 and batch: 1050, loss is 3.8110420417785646 and perplexity is 45.197512031780946
At time: 402.25793385505676 and batch: 1100, loss is 3.8261754274368287 and perplexity is 45.88670517177802
At time: 403.52549839019775 and batch: 1150, loss is 3.8104731035232544 and perplexity is 45.171804751762174
At time: 404.7909691333771 and batch: 1200, loss is 3.851100945472717 and perplexity is 47.0448285219456
At time: 406.0569257736206 and batch: 1250, loss is 3.836725196838379 and perplexity is 46.37336187429523
At time: 407.3225214481354 and batch: 1300, loss is 3.816595425605774 and perplexity is 45.449209403321156
At time: 408.5879395008087 and batch: 1350, loss is 3.699358696937561 and perplexity is 40.421373695509885
At time: 409.85399532318115 and batch: 1400, loss is 3.723025155067444 and perplexity is 41.38941430695257
At time: 411.12009167671204 and batch: 1450, loss is 3.6635161590576173 and perplexity is 38.99822604453719
At time: 412.3889830112457 and batch: 1500, loss is 3.6577382373809812 and perplexity is 38.77354706276731
At time: 413.65568566322327 and batch: 1550, loss is 3.679639253616333 and perplexity is 39.63209435872559
At time: 414.9241712093353 and batch: 1600, loss is 3.75937153339386 and perplexity is 42.92144280714837
At time: 416.19423627853394 and batch: 1650, loss is 3.725393886566162 and perplexity is 41.48757092377449
At time: 417.464341878891 and batch: 1700, loss is 3.7210100173950194 and perplexity is 41.30609291917256
At time: 418.73318004608154 and batch: 1750, loss is 3.704918231964111 and perplexity is 40.646723578240525
At time: 420.0000853538513 and batch: 1800, loss is 3.6520561170578003 and perplexity is 38.55385585004036
At time: 421.2661440372467 and batch: 1850, loss is 3.6937009620666506 and perplexity is 40.19332600502424
At time: 422.5324022769928 and batch: 1900, loss is 3.7948159742355347 and perplexity is 44.470052017164406
At time: 423.80047154426575 and batch: 1950, loss is 3.731951971054077 and perplexity is 41.760544031095684
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369496899981831 and perplexity of 79.00387484869503
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 427.7122836112976 and batch: 50, loss is 3.915477786064148 and perplexity is 50.17303776344955
At time: 428.99207401275635 and batch: 100, loss is 3.9115443563461305 and perplexity is 49.976073272609085
At time: 430.27135729789734 and batch: 150, loss is 3.878042907714844 and perplexity is 48.32953709060686
At time: 431.55179595947266 and batch: 200, loss is 3.8880603313446045 and perplexity is 48.81610755984261
At time: 432.81898522377014 and batch: 250, loss is 3.8868086385726928 and perplexity is 48.755043015853914
At time: 434.0928707122803 and batch: 300, loss is 3.883620901107788 and perplexity is 48.599872191953175
At time: 435.3632581233978 and batch: 350, loss is 3.9002232503890992 and perplexity is 49.41347945273428
At time: 436.63360261917114 and batch: 400, loss is 3.865359001159668 and perplexity is 47.72040103722249
At time: 437.905695438385 and batch: 450, loss is 3.898910059928894 and perplexity is 49.34863273027891
At time: 439.1742784976959 and batch: 500, loss is 3.9209766721725465 and perplexity is 50.449693535995074
At time: 440.4408357143402 and batch: 550, loss is 3.887096791267395 and perplexity is 48.76909393718745
At time: 441.70829129219055 and batch: 600, loss is 3.8457411479949952 and perplexity is 46.793352301521594
At time: 442.9742748737335 and batch: 650, loss is 3.8719412183761595 and perplexity is 48.035543111492316
At time: 444.2449109554291 and batch: 700, loss is 3.9224307250976564 and perplexity is 50.52310341844512
At time: 445.51498794555664 and batch: 750, loss is 3.8741968154907225 and perplexity is 48.144014231514525
At time: 446.7927870750427 and batch: 800, loss is 3.8692570447921755 and perplexity is 47.906780263806375
At time: 448.0600402355194 and batch: 850, loss is 3.8453219032287596 and perplexity is 46.77373854524418
At time: 449.3288071155548 and batch: 900, loss is 3.797832956314087 and perplexity is 44.604419958047174
At time: 450.59876251220703 and batch: 950, loss is 3.8887068891525267 and perplexity is 48.847680201006746
At time: 451.9008605480194 and batch: 1000, loss is 3.8555204248428345 and perplexity is 47.25320228368027
At time: 453.16690325737 and batch: 1050, loss is 3.8063844442367554 and perplexity is 44.98748969028807
At time: 454.4336361885071 and batch: 1100, loss is 3.8156905221939086 and perplexity is 45.4081008611007
At time: 455.7065200805664 and batch: 1150, loss is 3.805754008293152 and perplexity is 44.95913689802356
At time: 456.99022483825684 and batch: 1200, loss is 3.840623073577881 and perplexity is 46.55447226656273
At time: 458.26689982414246 and batch: 1250, loss is 3.8211676502227783 and perplexity is 45.65748918550732
At time: 459.53825545310974 and batch: 1300, loss is 3.7947421884536743 and perplexity is 44.46677088065904
At time: 460.8071258068085 and batch: 1350, loss is 3.670738458633423 and perplexity is 39.28090247414755
At time: 462.07450461387634 and batch: 1400, loss is 3.6883545303344727 and perplexity is 39.9790085587568
At time: 463.34464955329895 and batch: 1450, loss is 3.6266583967208863 and perplexity is 37.58700566772014
At time: 464.6151328086853 and batch: 1500, loss is 3.632513747215271 and perplexity is 37.80773635706656
At time: 465.8838288784027 and batch: 1550, loss is 3.6533611679077147 and perplexity is 38.604203438320546
At time: 467.15184688568115 and batch: 1600, loss is 3.7334716939926147 and perplexity is 41.82405673641928
At time: 468.4194495677948 and batch: 1650, loss is 3.6894676637649537 and perplexity is 40.023535307209535
At time: 469.687593460083 and batch: 1700, loss is 3.6724847459793093 and perplexity is 39.349558145891315
At time: 470.95407009124756 and batch: 1750, loss is 3.655725235939026 and perplexity is 38.69557436252916
At time: 472.2214081287384 and batch: 1800, loss is 3.603057107925415 and perplexity is 36.71029039254459
At time: 473.4887466430664 and batch: 1850, loss is 3.6372486400604247 and perplexity is 37.98717641692095
At time: 474.756222486496 and batch: 1900, loss is 3.7399445581436157 and perplexity is 42.0956562389713
At time: 476.0251033306122 and batch: 1950, loss is 3.690145969390869 and perplexity is 40.05069270584432
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343030920694041 and perplexity of 76.94038649905023
finished 9 epochs...
Completing Train Step...
At time: 479.92517375946045 and batch: 50, loss is 3.923419885635376 and perplexity is 50.57310360361796
At time: 481.2022223472595 and batch: 100, loss is 3.8913548231124877 and perplexity is 48.977197032608515
At time: 482.46746015548706 and batch: 150, loss is 3.845155191421509 and perplexity is 46.765941460710515
At time: 483.74735283851624 and batch: 200, loss is 3.842870192527771 and perplexity is 46.65920333090438
At time: 485.01788997650146 and batch: 250, loss is 3.837635111808777 and perplexity is 46.41557689361873
At time: 486.288658618927 and batch: 300, loss is 3.829977264404297 and perplexity is 46.061490986873075
At time: 487.55895829200745 and batch: 350, loss is 3.847412848472595 and perplexity is 46.87164219130332
At time: 488.8283689022064 and batch: 400, loss is 3.813261408805847 and perplexity is 45.297933294299426
At time: 490.09621930122375 and batch: 450, loss is 3.8498203468322756 and perplexity is 46.98462153721992
At time: 491.3635959625244 and batch: 500, loss is 3.8710116481781007 and perplexity is 47.9909114495136
At time: 492.63043665885925 and batch: 550, loss is 3.8370404624938965 and perplexity is 46.387984107447934
At time: 493.89945101737976 and batch: 600, loss is 3.799452152252197 and perplexity is 44.67670175707035
At time: 495.1680898666382 and batch: 650, loss is 3.8277069091796876 and perplexity is 45.95703366264251
At time: 496.4393470287323 and batch: 700, loss is 3.881080975532532 and perplexity is 48.476588765260274
At time: 497.70692682266235 and batch: 750, loss is 3.8353384733200073 and perplexity is 46.309099410191415
At time: 498.9749267101288 and batch: 800, loss is 3.830096249580383 and perplexity is 46.066971947559004
At time: 500.24098539352417 and batch: 850, loss is 3.8058924436569215 and perplexity is 44.965361263321
At time: 501.5112063884735 and batch: 900, loss is 3.7587553310394286 and perplexity is 42.89500266011206
At time: 502.7816960811615 and batch: 950, loss is 3.851466345787048 and perplexity is 47.06202185810908
At time: 504.0519025325775 and batch: 1000, loss is 3.8196057796478273 and perplexity is 45.58623375698617
At time: 505.3220925331116 and batch: 1050, loss is 3.773897819519043 and perplexity is 43.54948246447928
At time: 506.5916428565979 and batch: 1100, loss is 3.7845661449432373 and perplexity is 44.01656960422254
At time: 507.8611090183258 and batch: 1150, loss is 3.7762990522384645 and perplexity is 43.6541805586248
At time: 509.12994384765625 and batch: 1200, loss is 3.8133297634124754 and perplexity is 45.301029722537194
At time: 510.39854764938354 and batch: 1250, loss is 3.7978805541992187 and perplexity is 44.60654308463246
At time: 511.66555666923523 and batch: 1300, loss is 3.7732560873031615 and perplexity is 43.52154432395806
At time: 512.9335789680481 and batch: 1350, loss is 3.650505404472351 and perplexity is 38.49411623201623
At time: 514.2039849758148 and batch: 1400, loss is 3.6705249738693237 and perplexity is 39.27251749501375
At time: 515.4732360839844 and batch: 1450, loss is 3.610143127441406 and perplexity is 36.97134405003222
At time: 516.7420585155487 and batch: 1500, loss is 3.6167229223251343 and perplexity is 37.21540998179926
At time: 518.0125870704651 and batch: 1550, loss is 3.6406210470199585 and perplexity is 38.11550089460235
At time: 519.278776884079 and batch: 1600, loss is 3.723560581207275 and perplexity is 41.411581215126276
At time: 520.5458588600159 and batch: 1650, loss is 3.680773825645447 and perplexity is 39.67708534236977
At time: 521.8157994747162 and batch: 1700, loss is 3.6668376874923707 and perplexity is 39.12797512458986
At time: 523.0917637348175 and batch: 1750, loss is 3.652490520477295 and perplexity is 38.57060741506145
At time: 524.357871055603 and batch: 1800, loss is 3.6022619438171386 and perplexity is 36.68111128984509
At time: 525.6249675750732 and batch: 1850, loss is 3.638390259742737 and perplexity is 38.03056808887467
At time: 526.8955426216125 and batch: 1900, loss is 3.742692594528198 and perplexity is 42.211495726613485
At time: 528.1642789840698 and batch: 1950, loss is 3.69189838886261 and perplexity is 40.120939852855614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343580520984738 and perplexity of 76.98268458029064
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 532.0977520942688 and batch: 50, loss is 3.9161356544494628 and perplexity is 50.20605587838547
At time: 533.390144109726 and batch: 100, loss is 3.9070693016052247 and perplexity is 49.752927276647696
At time: 534.6564607620239 and batch: 150, loss is 3.8726157426834105 and perplexity is 48.067955183069174
At time: 535.922933101654 and batch: 200, loss is 3.8788978052139282 and perplexity is 48.37087155684599
At time: 537.1896870136261 and batch: 250, loss is 3.8801324462890623 and perplexity is 48.43062910368015
At time: 538.456524848938 and batch: 300, loss is 3.867093815803528 and perplexity is 47.803258938522355
At time: 539.7217376232147 and batch: 350, loss is 3.881724615097046 and perplexity is 48.507800259140936
At time: 540.9876012802124 and batch: 400, loss is 3.847462239265442 and perplexity is 46.87395727604464
At time: 542.2520976066589 and batch: 450, loss is 3.887974781990051 and perplexity is 48.811931551978994
At time: 543.5182754993439 and batch: 500, loss is 3.9103592824935913 and perplexity is 49.91688301426211
At time: 544.7838087081909 and batch: 550, loss is 3.8830474615097046 and perplexity is 48.57201108986958
At time: 546.0495483875275 and batch: 600, loss is 3.8409719133377074 and perplexity is 46.570715150404176
At time: 547.3511319160461 and batch: 650, loss is 3.854251799583435 and perplexity is 47.19329368649029
At time: 548.6202094554901 and batch: 700, loss is 3.8980160570144653 and perplexity is 49.304534623649964
At time: 549.8961911201477 and batch: 750, loss is 3.8506340646743773 and perplexity is 47.02286932141093
At time: 551.1629695892334 and batch: 800, loss is 3.8449301147460937 and perplexity is 46.755416722564846
At time: 552.42848944664 and batch: 850, loss is 3.829788637161255 and perplexity is 46.05280335420567
At time: 553.6921143531799 and batch: 900, loss is 3.792954421043396 and perplexity is 44.3873456549077
At time: 554.960887670517 and batch: 950, loss is 3.8923701190948488 and perplexity is 49.026948636010786
At time: 556.2300848960876 and batch: 1000, loss is 3.850741810798645 and perplexity is 47.02793612629164
At time: 557.4965307712555 and batch: 1050, loss is 3.7986210918426515 and perplexity is 44.63958814297471
At time: 558.764276266098 and batch: 1100, loss is 3.800699858665466 and perplexity is 44.73247995454755
At time: 560.0332281589508 and batch: 1150, loss is 3.787922248840332 and perplexity is 44.164541951403834
At time: 561.3018622398376 and batch: 1200, loss is 3.8277211475372312 and perplexity is 45.95768801997792
At time: 562.5706701278687 and batch: 1250, loss is 3.8088047885894776 and perplexity is 45.096506783136505
At time: 563.8393988609314 and batch: 1300, loss is 3.7862868165969847 and perplexity is 44.09237286539448
At time: 565.1074271202087 and batch: 1350, loss is 3.664519877433777 and perplexity is 39.03738893162255
At time: 566.3752632141113 and batch: 1400, loss is 3.684090504646301 and perplexity is 39.80889997071081
At time: 567.6418197154999 and batch: 1450, loss is 3.6197602558135986 and perplexity is 37.32861743017903
At time: 568.9090306758881 and batch: 1500, loss is 3.6172338199615477 and perplexity is 37.23442810454043
At time: 570.176796913147 and batch: 1550, loss is 3.64635302066803 and perplexity is 38.33460529172972
At time: 571.4434163570404 and batch: 1600, loss is 3.7269231939315794 and perplexity is 41.551066711474164
At time: 572.7181525230408 and batch: 1650, loss is 3.68175172328949 and perplexity is 39.715904448111075
At time: 573.9855628013611 and batch: 1700, loss is 3.6649371433258056 and perplexity is 39.05368130142629
At time: 575.2527759075165 and batch: 1750, loss is 3.652034616470337 and perplexity is 38.55302692840179
At time: 576.5209498405457 and batch: 1800, loss is 3.597197551727295 and perplexity is 36.495813366694556
At time: 577.7902553081512 and batch: 1850, loss is 3.6268342876434327 and perplexity is 37.59361746228307
At time: 579.0621185302734 and batch: 1900, loss is 3.7287855529785157 and perplexity is 41.62852181869698
At time: 580.3300309181213 and batch: 1950, loss is 3.6824231576919555 and perplexity is 39.74258002713114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324105480105378 and perplexity of 75.49794822858487
finished 11 epochs...
Completing Train Step...
At time: 584.2617681026459 and batch: 50, loss is 3.919376726150513 and perplexity is 50.369041286336994
At time: 585.5438089370728 and batch: 100, loss is 3.894904475212097 and perplexity is 49.15135796537926
At time: 586.8109083175659 and batch: 150, loss is 3.8534293746948243 and perplexity is 47.15449670317614
At time: 588.0801069736481 and batch: 200, loss is 3.8573264408111574 and perplexity is 47.33861943070769
At time: 589.3559229373932 and batch: 250, loss is 3.86013623714447 and perplexity is 47.47181835329703
At time: 590.6217141151428 and batch: 300, loss is 3.8451185131073 and perplexity is 46.76422619627204
At time: 591.8969361782074 and batch: 350, loss is 3.861116156578064 and perplexity is 47.518359710315316
At time: 593.1642737388611 and batch: 400, loss is 3.824167990684509 and perplexity is 45.794682908712424
At time: 594.4318053722382 and batch: 450, loss is 3.8654699325561523 and perplexity is 47.72569502157944
At time: 595.7009863853455 and batch: 500, loss is 3.888699769973755 and perplexity is 48.84733244687667
At time: 596.9708125591278 and batch: 550, loss is 3.8576024341583253 and perplexity is 47.35168637784697
At time: 598.2398734092712 and batch: 600, loss is 3.8173471593856814 and perplexity is 45.48338795427582
At time: 599.5083539485931 and batch: 650, loss is 3.8319112634658814 and perplexity is 46.15066006588077
At time: 600.7758588790894 and batch: 700, loss is 3.878804159164429 and perplexity is 48.36634202790341
At time: 602.0430400371552 and batch: 750, loss is 3.833519949913025 and perplexity is 46.22496175529226
At time: 603.3090374469757 and batch: 800, loss is 3.8281452465057373 and perplexity is 45.97718276161984
At time: 604.5765187740326 and batch: 850, loss is 3.8123492908477785 and perplexity is 45.256635073166066
At time: 605.8453121185303 and batch: 900, loss is 3.7758552503585814 and perplexity is 43.63481104965829
At time: 607.1126320362091 and batch: 950, loss is 3.874510488510132 and perplexity is 48.15911807853582
At time: 608.3794782161713 and batch: 1000, loss is 3.8330176639556885 and perplexity is 46.20174943622314
At time: 609.6623878479004 and batch: 1050, loss is 3.781982035636902 and perplexity is 43.902972813550306
At time: 610.9309377670288 and batch: 1100, loss is 3.7843443393707275 and perplexity is 44.00680756647876
At time: 612.2017517089844 and batch: 1150, loss is 3.774215507507324 and perplexity is 43.563319809816925
At time: 613.4722392559052 and batch: 1200, loss is 3.8143758726119996 and perplexity is 45.34844434258898
At time: 614.7406070232391 and batch: 1250, loss is 3.7972387313842773 and perplexity is 44.577922773152
At time: 616.0076060295105 and batch: 1300, loss is 3.7763152170181273 and perplexity is 43.654886224538345
At time: 617.2729659080505 and batch: 1350, loss is 3.655793824195862 and perplexity is 38.698228515542766
At time: 618.5387544631958 and batch: 1400, loss is 3.6772894954681394 and perplexity is 39.53907784802632
At time: 619.8056635856628 and batch: 1450, loss is 3.6134227609634397 and perplexity is 37.09279555869192
At time: 621.0736532211304 and batch: 1500, loss is 3.612574939727783 and perplexity is 37.06136082632715
At time: 622.3426961898804 and batch: 1550, loss is 3.6429727458953858 and perplexity is 38.20524255651564
At time: 623.6137552261353 and batch: 1600, loss is 3.7260242033004762 and perplexity is 41.51372947721472
At time: 624.8815288543701 and batch: 1650, loss is 3.6817615127563474 and perplexity is 39.716293247544456
At time: 626.1576030254364 and batch: 1700, loss is 3.6655933332443236 and perplexity is 39.07931634318544
At time: 627.426187992096 and batch: 1750, loss is 3.6546498918533326 and perplexity is 38.653985670580504
At time: 628.6935837268829 and batch: 1800, loss is 3.6012390518188475 and perplexity is 36.64360965794773
At time: 629.9608950614929 and batch: 1850, loss is 3.6316554594039916 and perplexity is 37.7753003594811
At time: 631.2278957366943 and batch: 1900, loss is 3.7342045593261717 and perplexity is 41.854719372129104
At time: 632.4944596290588 and batch: 1950, loss is 3.686935625076294 and perplexity is 39.92232235897996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322558025981104 and perplexity of 75.38120896484737
finished 12 epochs...
Completing Train Step...
At time: 636.4272944927216 and batch: 50, loss is 3.9131116104125976 and perplexity is 50.05445988649633
At time: 637.6999235153198 and batch: 100, loss is 3.8869444799423216 and perplexity is 48.76166641752929
At time: 638.9805681705475 and batch: 150, loss is 3.844579839706421 and perplexity is 46.739042335054464
At time: 640.2474789619446 and batch: 200, loss is 3.8477160358428955 and perplexity is 46.88585523573987
At time: 641.5291390419006 and batch: 250, loss is 3.8501548957824707 and perplexity is 47.00034282265366
At time: 642.7956931591034 and batch: 300, loss is 3.834558229446411 and perplexity is 46.27298111145786
At time: 644.0623347759247 and batch: 350, loss is 3.8510128593444826 and perplexity is 47.04068470765659
At time: 645.3277444839478 and batch: 400, loss is 3.8131158113479615 and perplexity is 45.29133851046783
At time: 646.5955216884613 and batch: 450, loss is 3.8548089933395384 and perplexity is 47.219596822353374
At time: 647.8656904697418 and batch: 500, loss is 3.87822594165802 and perplexity is 48.33838384595599
At time: 649.1352121829987 and batch: 550, loss is 3.8464332246780395 and perplexity is 46.825748098465745
At time: 650.403938293457 and batch: 600, loss is 3.8069693088531493 and perplexity is 45.01380897704784
At time: 651.6715519428253 and batch: 650, loss is 3.821404242515564 and perplexity is 45.66829267351716
At time: 652.9374852180481 and batch: 700, loss is 3.8692706346511843 and perplexity is 47.90743131461956
At time: 654.204107761383 and batch: 750, loss is 3.824611687660217 and perplexity is 45.81500637942035
At time: 655.4707562923431 and batch: 800, loss is 3.8191591453552247 and perplexity is 45.56587792786376
At time: 656.7393777370453 and batch: 850, loss is 3.803312940597534 and perplexity is 44.849522443901385
At time: 658.0094830989838 and batch: 900, loss is 3.7671114778518677 and perplexity is 43.25494135575553
At time: 659.2795214653015 and batch: 950, loss is 3.8655286121368406 and perplexity is 47.728495627519756
At time: 660.5475604534149 and batch: 1000, loss is 3.824465265274048 and perplexity is 45.80829852796572
At time: 661.8155844211578 and batch: 1050, loss is 3.774173827171326 and perplexity is 43.56150411384973
At time: 663.0881636142731 and batch: 1100, loss is 3.7769149017333983 and perplexity is 43.68107324374689
At time: 664.3538444042206 and batch: 1150, loss is 3.767517423629761 and perplexity is 43.272504081087824
At time: 665.6224126815796 and batch: 1200, loss is 3.807903275489807 and perplexity is 45.05587001156529
At time: 666.9116683006287 and batch: 1250, loss is 3.791482744216919 and perplexity is 44.32206987112907
At time: 668.2031755447388 and batch: 1300, loss is 3.771370553970337 and perplexity is 43.439560317517056
At time: 669.481951713562 and batch: 1350, loss is 3.6514049768447876 and perplexity is 38.5287600554569
At time: 670.7571709156036 and batch: 1400, loss is 3.6734658336639403 and perplexity is 39.38818245660361
At time: 672.0349752902985 and batch: 1450, loss is 3.609878935813904 and perplexity is 36.961577820611524
At time: 673.3057637214661 and batch: 1500, loss is 3.6094885635375977 and perplexity is 36.94715186127232
At time: 674.5751414299011 and batch: 1550, loss is 3.640502653121948 and perplexity is 38.11098851900096
At time: 675.8467676639557 and batch: 1600, loss is 3.7246612167358397 and perplexity is 41.457185364875684
At time: 677.1166543960571 and batch: 1650, loss is 3.6806011724472047 and perplexity is 39.67023555802408
At time: 678.3929076194763 and batch: 1700, loss is 3.6647764825820923 and perplexity is 39.04740741194103
At time: 679.6596381664276 and batch: 1750, loss is 3.654378962516785 and perplexity is 38.6435145904133
At time: 680.9313962459564 and batch: 1800, loss is 3.6015371751785277 and perplexity is 36.6545356025285
At time: 682.2003495693207 and batch: 1850, loss is 3.6319012117385863 and perplexity is 37.78458486853262
At time: 683.4695887565613 and batch: 1900, loss is 3.7347059202194215 and perplexity is 41.87570895285804
At time: 684.7341446876526 and batch: 1950, loss is 3.6868708658218385 and perplexity is 39.9197371028584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322401889534884 and perplexity of 75.36944012956378
finished 13 epochs...
Completing Train Step...
At time: 688.667662858963 and batch: 50, loss is 3.906538004875183 and perplexity is 49.7265007298662
At time: 689.9359364509583 and batch: 100, loss is 3.879784369468689 and perplexity is 48.413774457818995
At time: 691.2053182125092 and batch: 150, loss is 3.837083492279053 and perplexity is 46.38998021538365
At time: 692.473935842514 and batch: 200, loss is 3.839936137199402 and perplexity is 46.52250328756639
At time: 693.7416381835938 and batch: 250, loss is 3.84219304561615 and perplexity is 46.62761889033021
At time: 695.0096909999847 and batch: 300, loss is 3.826394739151001 and perplexity is 45.896769767348474
At time: 696.2765684127808 and batch: 350, loss is 3.8432093763351443 and perplexity is 46.67503206141194
At time: 697.5448822975159 and batch: 400, loss is 3.804766674041748 and perplexity is 44.91476910877383
At time: 698.8162660598755 and batch: 450, loss is 3.846803975105286 and perplexity is 46.84311198321433
At time: 700.0829110145569 and batch: 500, loss is 3.870363545417786 and perplexity is 47.95981848413983
At time: 701.3511395454407 and batch: 550, loss is 3.838297038078308 and perplexity is 46.446310753932636
At time: 702.620927810669 and batch: 600, loss is 3.7994289684295652 and perplexity is 44.675665992347575
At time: 703.8920912742615 and batch: 650, loss is 3.81372031211853 and perplexity is 45.31872543637242
At time: 705.169273853302 and batch: 700, loss is 3.8621108293533326 and perplexity is 47.565648443553506
At time: 706.4351170063019 and batch: 750, loss is 3.8178324937820434 and perplexity is 45.50546796457393
At time: 707.6998465061188 and batch: 800, loss is 3.8122956228256224 and perplexity is 45.254206304246445
At time: 708.9680509567261 and batch: 850, loss is 3.7964342498779295 and perplexity is 44.542075080026045
At time: 710.2329659461975 and batch: 900, loss is 3.760488634109497 and perplexity is 42.96941717273448
At time: 711.5041708946228 and batch: 950, loss is 3.8586918544769286 and perplexity is 47.403300376671865
At time: 712.773800611496 and batch: 1000, loss is 3.8179484510421755 and perplexity is 45.510744959907186
At time: 714.0426876544952 and batch: 1050, loss is 3.7682546520233156 and perplexity is 43.30441756207335
At time: 715.3097231388092 and batch: 1100, loss is 3.7712364625930785 and perplexity is 43.43373583756158
At time: 716.5778269767761 and batch: 1150, loss is 3.7621283531188965 and perplexity is 43.039932739953976
At time: 717.8485867977142 and batch: 1200, loss is 3.802605128288269 and perplexity is 44.817788631967176
At time: 719.1174027919769 and batch: 1250, loss is 3.7866567373275757 and perplexity is 44.10868656538021
At time: 720.3848967552185 and batch: 1300, loss is 3.7671101331710815 and perplexity is 43.254883191706085
At time: 721.6534929275513 and batch: 1350, loss is 3.647549958229065 and perplexity is 38.38051689186889
At time: 722.9209306240082 and batch: 1400, loss is 3.669862494468689 and perplexity is 39.24650887720022
At time: 724.187873840332 and batch: 1450, loss is 3.6065493869781493 and perplexity is 36.838717091112436
At time: 725.4560935497284 and batch: 1500, loss is 3.6063904571533203 and perplexity is 36.832862785482426
At time: 726.7233083248138 and batch: 1550, loss is 3.637869997024536 and perplexity is 38.01078734818317
At time: 727.9913988113403 and batch: 1600, loss is 3.722743854522705 and perplexity is 41.37777307958015
At time: 729.2585291862488 and batch: 1650, loss is 3.678776979446411 and perplexity is 39.59793535678915
At time: 730.5259120464325 and batch: 1700, loss is 3.6634439849853515 and perplexity is 38.995411485322734
At time: 731.7932453155518 and batch: 1750, loss is 3.653171181678772 and perplexity is 38.59686986794871
At time: 733.0622153282166 and batch: 1800, loss is 3.6006725025177 and perplexity is 36.62285512629236
At time: 734.329567193985 and batch: 1850, loss is 3.630873165130615 and perplexity is 37.745760514267175
At time: 735.5965616703033 and batch: 1900, loss is 3.7337165546417235 and perplexity is 41.83429905601946
At time: 736.861022233963 and batch: 1950, loss is 3.6854872512817383 and perplexity is 39.86454176750562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322653978924419 and perplexity of 75.38844236074542
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 740.7798445224762 and batch: 50, loss is 3.9043147706985475 and perplexity is 49.61606987626919
At time: 742.0598523616791 and batch: 100, loss is 3.884221568107605 and perplexity is 48.62907330056738
At time: 743.3271794319153 and batch: 150, loss is 3.8458840608596803 and perplexity is 46.80004015142573
At time: 744.5964660644531 and batch: 200, loss is 3.853642864227295 and perplexity is 47.16456476930632
At time: 745.8628106117249 and batch: 250, loss is 3.862783136367798 and perplexity is 47.597637914817724
At time: 747.1299479007721 and batch: 300, loss is 3.847792692184448 and perplexity is 46.889449471631536
At time: 748.3967978954315 and batch: 350, loss is 3.8655473375320435 and perplexity is 47.72938937083064
At time: 749.6628346443176 and batch: 400, loss is 3.8293283700942995 and perplexity is 46.031611642778294
At time: 750.9298944473267 and batch: 450, loss is 3.875102882385254 and perplexity is 48.18765569703747
At time: 752.1964392662048 and batch: 500, loss is 3.9030829524993895 and perplexity is 49.55498952609187
At time: 753.4631037712097 and batch: 550, loss is 3.870441427230835 and perplexity is 47.96355382721265
At time: 754.7291488647461 and batch: 600, loss is 3.8299483489990234 and perplexity is 46.06015911944951
At time: 755.99596118927 and batch: 650, loss is 3.841119341850281 and perplexity is 46.577581507804275
At time: 757.2742173671722 and batch: 700, loss is 3.885277099609375 and perplexity is 48.680429918833966
At time: 758.5479760169983 and batch: 750, loss is 3.8390476751327514 and perplexity is 46.48118816432738
At time: 759.8133556842804 and batch: 800, loss is 3.8244475746154785 and perplexity is 45.80748815616483
At time: 761.081032037735 and batch: 850, loss is 3.806036238670349 and perplexity is 44.97182752294444
At time: 762.3494327068329 and batch: 900, loss is 3.7674009227752685 and perplexity is 43.267463091031885
At time: 763.6212704181671 and batch: 950, loss is 3.8681035232543945 and perplexity is 47.85155062138147
At time: 764.8911623954773 and batch: 1000, loss is 3.83087082862854 and perplexity is 46.1026682818732
At time: 766.1612741947174 and batch: 1050, loss is 3.7882849550247193 and perplexity is 44.1805636093018
At time: 767.4401757717133 and batch: 1100, loss is 3.7894359636306763 and perplexity is 44.23144509512876
At time: 768.7083003520966 and batch: 1150, loss is 3.7789580821990967 and perplexity is 43.77041279665427
At time: 769.9797720909119 and batch: 1200, loss is 3.8169671726226806 and perplexity is 45.46610815217272
At time: 771.2489895820618 and batch: 1250, loss is 3.802748775482178 and perplexity is 44.824227043960185
At time: 772.5166907310486 and batch: 1300, loss is 3.7782958269119264 and perplexity is 43.74143520569856
At time: 773.7852771282196 and batch: 1350, loss is 3.653999614715576 and perplexity is 38.62885803826362
At time: 775.0531268119812 and batch: 1400, loss is 3.676656360626221 and perplexity is 39.51405220336317
At time: 776.3221824169159 and batch: 1450, loss is 3.6076599407196044 and perplexity is 36.87965119176059
At time: 777.5932931900024 and batch: 1500, loss is 3.6050819110870362 and perplexity is 36.78469680834731
At time: 778.8637809753418 and batch: 1550, loss is 3.635974812507629 and perplexity is 37.938818111558064
At time: 780.1353390216827 and batch: 1600, loss is 3.7168887662887573 and perplexity is 41.13621044265653
At time: 781.4074249267578 and batch: 1650, loss is 3.6721656799316404 and perplexity is 39.33700504063753
At time: 782.6780695915222 and batch: 1700, loss is 3.6549162578582766 and perplexity is 38.66428314970704
At time: 783.9491527080536 and batch: 1750, loss is 3.645999240875244 and perplexity is 38.321045681712526
At time: 785.21861743927 and batch: 1800, loss is 3.5929125118255616 and perplexity is 36.33976193226268
At time: 786.4869177341461 and batch: 1850, loss is 3.6240143299102785 and perplexity is 37.48775438485833
At time: 787.7539088726044 and batch: 1900, loss is 3.729094457626343 and perplexity is 41.641383048913575
At time: 789.0225691795349 and batch: 1950, loss is 3.683876118659973 and perplexity is 39.800366415196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315336005632267 and perplexity of 74.83876546648449
finished 15 epochs...
Completing Train Step...
At time: 792.9383499622345 and batch: 50, loss is 3.9064771270751955 and perplexity is 49.72347358204466
At time: 794.2153401374817 and batch: 100, loss is 3.8784643459320067 and perplexity is 48.34990929706629
At time: 795.4783179759979 and batch: 150, loss is 3.8370762157440184 and perplexity is 46.389642658295486
At time: 796.7507002353668 and batch: 200, loss is 3.840479679107666 and perplexity is 46.547797091278966
At time: 798.0205998420715 and batch: 250, loss is 3.8476943492889406 and perplexity is 46.88483845413587
At time: 799.2991390228271 and batch: 300, loss is 3.832468490600586 and perplexity is 46.176383632222986
At time: 800.567218542099 and batch: 350, loss is 3.8512944984436035 and perplexity is 47.05393506954209
At time: 801.8359594345093 and batch: 400, loss is 3.813943123817444 and perplexity is 45.32882410358833
At time: 803.1036832332611 and batch: 450, loss is 3.859378571510315 and perplexity is 47.43586421026916
At time: 804.3705101013184 and batch: 500, loss is 3.8857916498184206 and perplexity is 48.705484889692585
At time: 805.637889623642 and batch: 550, loss is 3.8527019214630127 and perplexity is 47.12020648593181
At time: 806.9055950641632 and batch: 600, loss is 3.814097352027893 and perplexity is 45.335815626142725
At time: 808.1726746559143 and batch: 650, loss is 3.8266320180892945 and perplexity is 45.90766139627595
At time: 809.4407742023468 and batch: 700, loss is 3.872838397026062 and perplexity is 48.07865891360488
At time: 810.7074525356293 and batch: 750, loss is 3.827650308609009 and perplexity is 45.95443254192365
At time: 811.9713439941406 and batch: 800, loss is 3.8158291673660276 and perplexity is 45.4143969115086
At time: 813.2343854904175 and batch: 850, loss is 3.798867630958557 and perplexity is 44.65059490431272
At time: 814.5014050006866 and batch: 900, loss is 3.7609202241897584 and perplexity is 42.987966349473254
At time: 815.7654473781586 and batch: 950, loss is 3.8616182899475096 and perplexity is 47.54222625598022
At time: 817.0292119979858 and batch: 1000, loss is 3.8236733579635622 and perplexity is 45.7720369612754
At time: 818.3058722019196 and batch: 1050, loss is 3.779432802200317 and perplexity is 43.791196419881025
At time: 819.5831592082977 and batch: 1100, loss is 3.780394196510315 and perplexity is 43.83331727107615
At time: 820.8473052978516 and batch: 1150, loss is 3.7703177165985107 and perplexity is 43.39384959220143
At time: 822.1121158599854 and batch: 1200, loss is 3.8079392290115357 and perplexity is 45.05748995788797
At time: 823.3774402141571 and batch: 1250, loss is 3.7937407541275023 and perplexity is 44.42226261969496
At time: 824.6424639225006 and batch: 1300, loss is 3.770965132713318 and perplexity is 43.421952565888354
At time: 825.9076480865479 and batch: 1350, loss is 3.6492111444473267 and perplexity is 38.44432706319413
At time: 827.1746227741241 and batch: 1400, loss is 3.6730791568756103 and perplexity is 39.37295490497325
At time: 828.4390139579773 and batch: 1450, loss is 3.6076075220108033 and perplexity is 36.877718058730686
At time: 829.7037627696991 and batch: 1500, loss is 3.60662956237793 and perplexity is 36.84167076838716
At time: 830.9676563739777 and batch: 1550, loss is 3.6393994235992433 and perplexity is 38.06896653553584
At time: 832.2349965572357 and batch: 1600, loss is 3.721428256034851 and perplexity is 41.323372336499965
At time: 833.501672744751 and batch: 1650, loss is 3.6777035856246947 and perplexity is 39.55545398132626
At time: 834.7652266025543 and batch: 1700, loss is 3.6610230922698976 and perplexity is 38.901121956189286
At time: 836.034811258316 and batch: 1750, loss is 3.652727971076965 and perplexity is 38.57976711636705
At time: 837.2991359233856 and batch: 1800, loss is 3.5998411893844606 and perplexity is 36.59242271703249
At time: 838.5650458335876 and batch: 1850, loss is 3.630591402053833 and perplexity is 37.73512665083457
At time: 839.8319251537323 and batch: 1900, loss is 3.7348270130157473 and perplexity is 41.88078010658717
At time: 841.0992050170898 and batch: 1950, loss is 3.6885025978088377 and perplexity is 39.98492858785278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3137204192405525 and perplexity of 74.71795459190413
finished 16 epochs...
Completing Train Step...
At time: 845.0159294605255 and batch: 50, loss is 3.905543999671936 and perplexity is 49.6770968873075
At time: 846.2978720664978 and batch: 100, loss is 3.8752791118621825 and perplexity is 48.19614853071722
At time: 847.5649774074554 and batch: 150, loss is 3.8329634428024293 and perplexity is 46.19924439199992
At time: 848.837530374527 and batch: 200, loss is 3.835488953590393 and perplexity is 46.31606854033713
At time: 850.1084949970245 and batch: 250, loss is 3.841862554550171 and perplexity is 46.612211425014145
At time: 851.3765208721161 and batch: 300, loss is 3.8266301584243774 and perplexity is 45.907576023488
At time: 852.6443374156952 and batch: 350, loss is 3.845448498725891 and perplexity is 46.77966026475161
At time: 853.9176614284515 and batch: 400, loss is 3.807657814025879 and perplexity is 45.0448118889807
At time: 855.1849544048309 and batch: 450, loss is 3.853104062080383 and perplexity is 47.139159245440474
At time: 856.4515287876129 and batch: 500, loss is 3.8792282056808474 and perplexity is 48.386855955874694
At time: 857.7188034057617 and batch: 550, loss is 3.845897011756897 and perplexity is 46.80064625786028
At time: 858.987161397934 and batch: 600, loss is 3.807775912284851 and perplexity is 45.05013191697736
At time: 860.2537817955017 and batch: 650, loss is 3.820981683731079 and perplexity is 45.64899921187347
At time: 861.5191600322723 and batch: 700, loss is 3.867946925163269 and perplexity is 47.84405774659702
At time: 862.8199272155762 and batch: 750, loss is 3.823218641281128 and perplexity is 45.7512283838423
At time: 864.0875551700592 and batch: 800, loss is 3.812223334312439 and perplexity is 45.25093506319541
At time: 865.3563604354858 and batch: 850, loss is 3.795465741157532 and perplexity is 44.49895657558068
At time: 866.6239860057831 and batch: 900, loss is 3.7576563787460326 and perplexity is 42.84788899114237
At time: 867.892147064209 and batch: 950, loss is 3.858517723083496 and perplexity is 47.39504669255759
At time: 869.159167766571 and batch: 1000, loss is 3.8204890632629396 and perplexity is 45.62651711853594
At time: 870.4274754524231 and batch: 1050, loss is 3.7756500148773195 and perplexity is 43.62585655713397
At time: 871.6943712234497 and batch: 1100, loss is 3.776827359199524 and perplexity is 43.677249459287104
At time: 872.9620697498322 and batch: 1150, loss is 3.767113790512085 and perplexity is 43.25504138985327
At time: 874.2305295467377 and batch: 1200, loss is 3.804604959487915 and perplexity is 44.907506324191715
At time: 875.49818110466 and batch: 1250, loss is 3.790668969154358 and perplexity is 44.286016347665644
At time: 876.765691280365 and batch: 1300, loss is 3.768592982292175 and perplexity is 43.31907123606088
At time: 878.039172410965 and batch: 1350, loss is 3.647669486999512 and perplexity is 38.38510474204667
At time: 879.3159754276276 and batch: 1400, loss is 3.672034978866577 and perplexity is 39.33186398816015
At time: 880.5836291313171 and batch: 1450, loss is 3.607568020820618 and perplexity is 36.87626137374663
At time: 881.8515672683716 and batch: 1500, loss is 3.6071221828460693 and perplexity is 36.85982420049712
At time: 883.119943857193 and batch: 1550, loss is 3.640631456375122 and perplexity is 38.1158976544534
At time: 884.4071054458618 and batch: 1600, loss is 3.723083662986755 and perplexity is 41.391835986308195
At time: 885.6840679645538 and batch: 1650, loss is 3.6796420335769655 and perplexity is 39.632204534540826
At time: 886.965226650238 and batch: 1700, loss is 3.6630994367599485 and perplexity is 38.98197799987129
At time: 888.2361042499542 and batch: 1750, loss is 3.6550293159484863 and perplexity is 38.66865470683457
At time: 889.5039541721344 and batch: 1800, loss is 3.602226204872131 and perplexity is 36.67980036905149
At time: 890.7715601921082 and batch: 1850, loss is 3.6327190685272215 and perplexity is 37.81549988807919
At time: 892.0404012203217 and batch: 1900, loss is 3.736583905220032 and perplexity is 41.95442479661361
At time: 893.3088643550873 and batch: 1950, loss is 3.6896130800247193 and perplexity is 40.02935580320363
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313062942859738 and perplexity of 74.66884544735757
finished 17 epochs...
Completing Train Step...
At time: 897.2083055973053 and batch: 50, loss is 3.903757390975952 and perplexity is 49.58842259073923
At time: 898.477963924408 and batch: 100, loss is 3.8725989389419557 and perplexity is 48.067147468364354
At time: 899.7466564178467 and batch: 150, loss is 3.8298344659805297 and perplexity is 46.054913948170324
At time: 901.016548871994 and batch: 200, loss is 3.8320344400405886 and perplexity is 46.15634509623226
At time: 902.284677028656 and batch: 250, loss is 3.8380169916152953 and perplexity is 46.43330545001569
At time: 903.5508828163147 and batch: 300, loss is 3.8228210687637327 and perplexity is 45.733042568129626
At time: 904.8156023025513 and batch: 350, loss is 3.8416631698608397 and perplexity is 46.6029185901754
At time: 906.0814757347107 and batch: 400, loss is 3.803673405647278 and perplexity is 44.86569204335276
At time: 907.356696844101 and batch: 450, loss is 3.849238953590393 and perplexity is 46.957312935073375
At time: 908.6299774646759 and batch: 500, loss is 3.875437092781067 and perplexity is 48.2037632040195
At time: 909.9004170894623 and batch: 550, loss is 3.8420333671569824 and perplexity is 46.62017405839662
At time: 911.1686742305756 and batch: 600, loss is 3.8041380929946897 and perplexity is 44.88654540755019
At time: 912.4333333969116 and batch: 650, loss is 3.817665295600891 and perplexity is 45.49786016912028
At time: 913.6984422206879 and batch: 700, loss is 3.8649570035934446 and perplexity is 47.70122140748684
At time: 914.9638047218323 and batch: 750, loss is 3.8204762744903564 and perplexity is 45.62593361511591
At time: 916.2287847995758 and batch: 800, loss is 3.809823398590088 and perplexity is 45.142465939192576
At time: 917.4973406791687 and batch: 850, loss is 3.793086075782776 and perplexity is 44.39318984403081
At time: 918.7668237686157 and batch: 900, loss is 3.7553491592407227 and perplexity is 42.74914346350838
At time: 920.0358819961548 and batch: 950, loss is 3.856327052116394 and perplexity is 47.29133338212981
At time: 921.3041708469391 and batch: 1000, loss is 3.818357992172241 and perplexity is 45.52938729896993
At time: 922.5743653774261 and batch: 1050, loss is 3.7732937145233154 and perplexity is 43.52318194949723
At time: 923.844514131546 and batch: 1100, loss is 3.774694604873657 and perplexity is 43.58419588204283
At time: 925.1459469795227 and batch: 1150, loss is 3.765239706039429 and perplexity is 43.17405370100922
At time: 926.4152600765228 and batch: 1200, loss is 3.8026897525787353 and perplexity is 44.8215814660111
At time: 927.6843676567078 and batch: 1250, loss is 3.788992156982422 and perplexity is 44.21181924109804
At time: 928.9520380496979 and batch: 1300, loss is 3.7673159790039064 and perplexity is 43.263787945632224
At time: 930.22017121315 and batch: 1350, loss is 3.6467154026031494 and perplexity is 38.34849957754442
At time: 931.4863383769989 and batch: 1400, loss is 3.6712838315963747 and perplexity is 39.3023310590716
At time: 932.750688791275 and batch: 1450, loss is 3.607130780220032 and perplexity is 36.860141099552216
At time: 934.015923500061 and batch: 1500, loss is 3.6069184875488283 and perplexity is 36.85231679228818
At time: 935.2807643413544 and batch: 1550, loss is 3.6407990026474 and perplexity is 38.12228436603985
At time: 936.5462334156036 and batch: 1600, loss is 3.723477630615234 and perplexity is 41.40814624241561
At time: 937.8118588924408 and batch: 1650, loss is 3.68012815952301 and perplexity is 39.651475461133224
At time: 939.098212480545 and batch: 1700, loss is 3.6636314153671266 and perplexity is 39.00272109518499
At time: 940.3689815998077 and batch: 1750, loss is 3.6556819248199464 and perplexity is 38.69389845019317
At time: 941.6389932632446 and batch: 1800, loss is 3.6029683637619017 and perplexity is 36.707032713083535
At time: 942.9094839096069 and batch: 1850, loss is 3.633330154418945 and perplexity is 37.83861546863252
At time: 944.1769013404846 and batch: 1900, loss is 3.7370244741439818 and perplexity is 41.97291268469663
At time: 945.4437396526337 and batch: 1950, loss is 3.6896615839004516 and perplexity is 40.031297429190964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312759470385174 and perplexity of 74.64618894604295
finished 18 epochs...
Completing Train Step...
At time: 949.3565289974213 and batch: 50, loss is 3.901846995353699 and perplexity is 49.49377951694856
At time: 950.6238446235657 and batch: 100, loss is 3.870251331329346 and perplexity is 47.95443701877065
At time: 951.8925974369049 and batch: 150, loss is 3.82724130153656 and perplexity is 45.93564069726429
At time: 953.1625843048096 and batch: 200, loss is 3.829276328086853 and perplexity is 46.02921612763665
At time: 954.4301450252533 and batch: 250, loss is 3.835038757324219 and perplexity is 46.29522191210559
At time: 955.6965048313141 and batch: 300, loss is 3.8198625230789185 and perplexity is 45.59793922563826
At time: 956.9761350154877 and batch: 350, loss is 3.8387370443344118 and perplexity is 46.466751918027555
At time: 958.2457988262177 and batch: 400, loss is 3.8006338596343996 and perplexity is 44.729527751635686
At time: 959.514312505722 and batch: 450, loss is 3.846329379081726 and perplexity is 46.82088570320517
At time: 960.7825741767883 and batch: 500, loss is 3.872639594078064 and perplexity is 48.06910168451121
At time: 962.0488858222961 and batch: 550, loss is 3.839220814704895 and perplexity is 46.48923659408962
At time: 963.3127143383026 and batch: 600, loss is 3.8014899682998657 and perplexity is 44.76783748425326
At time: 964.5769259929657 and batch: 650, loss is 3.8151982498168944 and perplexity is 45.38575320837146
At time: 965.8441834449768 and batch: 700, loss is 3.8626783418655397 and perplexity is 47.59265020539061
At time: 967.1121492385864 and batch: 750, loss is 3.8183548927307127 and perplexity is 45.529246183514864
At time: 968.3782222270966 and batch: 800, loss is 3.807887396812439 and perplexity is 45.05515458962183
At time: 969.6457762718201 and batch: 850, loss is 3.7911347103118898 and perplexity is 44.30664697207441
At time: 970.9216160774231 and batch: 900, loss is 3.7534496355056763 and perplexity is 42.66801752556203
At time: 972.1867632865906 and batch: 950, loss is 3.85449800491333 and perplexity is 47.204914357408065
At time: 973.4519600868225 and batch: 1000, loss is 3.816598892211914 and perplexity is 45.449366958102615
At time: 974.7163169384003 and batch: 1050, loss is 3.771465983390808 and perplexity is 43.4437059273871
At time: 975.9803681373596 and batch: 1100, loss is 3.7730471515655517 and perplexity is 43.512452067874506
At time: 977.2475166320801 and batch: 1150, loss is 3.763768558502197 and perplexity is 43.110584995596476
At time: 978.5177979469299 and batch: 1200, loss is 3.801198501586914 and perplexity is 44.75479105120861
At time: 979.7869591712952 and batch: 1250, loss is 3.7876857137680053 and perplexity is 44.15409672365914
At time: 981.0549783706665 and batch: 1300, loss is 3.766301326751709 and perplexity is 43.219912508674284
At time: 982.319310426712 and batch: 1350, loss is 3.64585542678833 and perplexity is 38.315534971786576
At time: 983.5837163925171 and batch: 1400, loss is 3.6705054426193238 and perplexity is 39.271750461147015
At time: 984.8476798534393 and batch: 1450, loss is 3.6064646100997924 and perplexity is 36.835594152053154
At time: 986.114405632019 and batch: 1500, loss is 3.6063865184783936 and perplexity is 36.83271771309499
At time: 987.3792326450348 and batch: 1550, loss is 3.6404921770095826 and perplexity is 38.11058926609418
At time: 988.6437003612518 and batch: 1600, loss is 3.72332839012146 and perplexity is 41.401966931337306
At time: 989.9200699329376 and batch: 1650, loss is 3.680017976760864 and perplexity is 39.64710679272414
At time: 991.1902067661285 and batch: 1700, loss is 3.663560404777527 and perplexity is 38.99995158729739
At time: 992.4606881141663 and batch: 1750, loss is 3.655691123008728 and perplexity is 38.6942543656127
At time: 993.7280135154724 and batch: 1800, loss is 3.6030683755874633 and perplexity is 36.710704034020814
At time: 994.9925622940063 and batch: 1850, loss is 3.6333708810806273 and perplexity is 37.840156540504374
At time: 996.2565977573395 and batch: 1900, loss is 3.7369871282577516 and perplexity is 41.97134519834452
At time: 997.5219976902008 and batch: 1950, loss is 3.689362978935242 and perplexity is 40.019345669531006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312624909156977 and perplexity of 74.63614513894679
finished 19 epochs...
Completing Train Step...
At time: 1001.4459819793701 and batch: 50, loss is 3.8999975299835206 and perplexity is 49.40232708081746
At time: 1002.7116494178772 and batch: 100, loss is 3.8681428050994873 and perplexity is 47.853430355499896
At time: 1003.9806468486786 and batch: 150, loss is 3.824984941482544 and perplexity is 45.832110197505564
At time: 1005.2486608028412 and batch: 200, loss is 3.826914916038513 and perplexity is 45.92065041673536
At time: 1006.5177729129791 and batch: 250, loss is 3.8325290489196777 and perplexity is 46.17918008107076
At time: 1007.7861475944519 and batch: 300, loss is 3.8173605680465696 and perplexity is 45.48399782968975
At time: 1009.0538907051086 and batch: 350, loss is 3.8362601709365847 and perplexity is 46.351802073191905
At time: 1010.3189694881439 and batch: 400, loss is 3.7980778884887694 and perplexity is 44.61534635368624
At time: 1011.5853686332703 and batch: 450, loss is 3.8438867807388304 and perplexity is 46.706660645134015
At time: 1012.850652217865 and batch: 500, loss is 3.8702911806106566 and perplexity is 47.956348006697
At time: 1014.1148986816406 and batch: 550, loss is 3.8368752002716064 and perplexity is 46.38031855953697
At time: 1015.3792066574097 and batch: 600, loss is 3.799290809631348 and perplexity is 44.66949408238616
At time: 1016.6431720256805 and batch: 650, loss is 3.813115649223328 and perplexity is 45.291331167626765
At time: 1017.9081592559814 and batch: 700, loss is 3.8607329607009886 and perplexity is 47.50015435911948
At time: 1019.1751582622528 and batch: 750, loss is 3.8165231275558473 and perplexity is 45.445923632889404
At time: 1020.4526302814484 and batch: 800, loss is 3.806175079345703 and perplexity is 44.978071875324645
At time: 1021.7184357643127 and batch: 850, loss is 3.7894007682800295 and perplexity is 44.22988838130373
At time: 1022.9848306179047 and batch: 900, loss is 3.7517565584182737 and perplexity is 42.59583840237628
At time: 1024.2511463165283 and batch: 950, loss is 3.852844681739807 and perplexity is 47.126933859841806
At time: 1025.518614768982 and batch: 1000, loss is 3.8150054168701173 and perplexity is 45.37700218360866
At time: 1026.785976409912 and batch: 1050, loss is 3.769874024391174 and perplexity is 43.37460034997621
At time: 1028.0530517101288 and batch: 1100, loss is 3.7716008949279787 and perplexity is 43.44956737991405
At time: 1029.3206095695496 and batch: 1150, loss is 3.762443332672119 and perplexity is 43.053491574004774
At time: 1030.587253332138 and batch: 1200, loss is 3.799858179092407 and perplexity is 44.69484538026551
At time: 1031.8524329662323 and batch: 1250, loss is 3.786489372253418 and perplexity is 44.10130492951344
At time: 1033.1206459999084 and batch: 1300, loss is 3.7653437662124634 and perplexity is 43.1785466342716
At time: 1034.3895621299744 and batch: 1350, loss is 3.644990391731262 and perplexity is 38.28240502215549
At time: 1035.6582236289978 and batch: 1400, loss is 3.6696699619293214 and perplexity is 39.23895337454818
At time: 1036.9279572963715 and batch: 1450, loss is 3.6056785774230957 and perplexity is 36.806651547790636
At time: 1038.1983692646027 and batch: 1500, loss is 3.6056977796554563 and perplexity is 36.80735832445189
At time: 1039.4671318531036 and batch: 1550, loss is 3.6399619960784912 and perplexity is 38.090389113733615
At time: 1040.737857580185 and batch: 1600, loss is 3.7229261064529418 and perplexity is 41.38531494583177
At time: 1042.0075800418854 and batch: 1650, loss is 3.6796416807174683 and perplexity is 39.63219054994353
At time: 1043.2766206264496 and batch: 1700, loss is 3.6632305145263673 and perplexity is 38.98708800537484
At time: 1044.5427024364471 and batch: 1750, loss is 3.655420446395874 and perplexity is 38.68378215325952
At time: 1045.8106849193573 and batch: 1800, loss is 3.602885513305664 and perplexity is 36.70399164465481
At time: 1047.0775830745697 and batch: 1850, loss is 3.6331642150878904 and perplexity is 37.83233707502424
At time: 1048.345798254013 and batch: 1900, loss is 3.7367479181289673 and perplexity is 41.96130642819
At time: 1049.612578868866 and batch: 1950, loss is 3.688936710357666 and perplexity is 40.00229031531599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312590559138808 and perplexity of 74.63358143003721
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f98e3f9bb38>
ELAPSED
5389.649310588837


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -76.16006149647069}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.909600321875081, 'seq_len': 35, 'dropout': 0.7290759996057752, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -77.31609076804611}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.43001077421999756, 'seq_len': 35, 'dropout': 0.7678082231043937, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.2714605499234}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.8411519755907202, 'seq_len': 35, 'dropout': 0.7399604006877908, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -75.65843510780176}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.3249180821502161, 'seq_len': 35, 'dropout': 0.0492471584881673, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.63358143003721}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.4296857462830832, 'seq_len': 35, 'dropout': 0.7850632272183664, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8985936641693115 and batch: 50, loss is 7.65885290145874 and perplexity is 2119.324959135043
At time: 3.3758249282836914 and batch: 100, loss is 6.996254739761352 and perplexity is 1092.533663493461
At time: 4.85228967666626 and batch: 150, loss is 6.726416540145874 and perplexity is 834.1527509012684
At time: 6.331972599029541 and batch: 200, loss is 6.558991203308105 and perplexity is 705.559569301492
At time: 7.81149959564209 and batch: 250, loss is 6.485714721679687 and perplexity is 655.707445128979
At time: 9.290001392364502 and batch: 300, loss is 6.406371860504151 and perplexity is 605.6921541263137
At time: 10.769783735275269 and batch: 350, loss is 6.364059038162232 and perplexity is 580.5982504061665
At time: 12.248631715774536 and batch: 400, loss is 6.3208866310119625 and perplexity is 556.0657991324787
At time: 13.728455305099487 and batch: 450, loss is 6.220080013275147 and perplexity is 502.7434565614869
At time: 15.208455562591553 and batch: 500, loss is 6.198319044113159 and perplexity is 491.92144746096096
At time: 16.689194679260254 and batch: 550, loss is 6.14635591506958 and perplexity is 467.01244917204934
At time: 18.168898344039917 and batch: 600, loss is 6.181538505554199 and perplexity is 483.735614074349
At time: 19.648923635482788 and batch: 650, loss is 6.253034133911132 and perplexity is 519.5869317643313
At time: 21.129130363464355 and batch: 700, loss is 6.14215781211853 and perplexity is 465.05599240785386
At time: 22.607922792434692 and batch: 750, loss is 6.075684108734131 and perplexity is 435.1470886380586
At time: 24.087117671966553 and batch: 800, loss is 6.081274328231811 and perplexity is 437.58646835869945
At time: 25.567712783813477 and batch: 850, loss is 6.114224243164062 and perplexity is 452.2450790441683
At time: 27.05471920967102 and batch: 900, loss is 6.085697402954102 and perplexity is 439.52623270464096
At time: 28.547369956970215 and batch: 950, loss is 6.09970290184021 and perplexity is 445.72532623488337
At time: 30.041770935058594 and batch: 1000, loss is 6.076710796356201 and perplexity is 435.5940781877982
At time: 31.53588366508484 and batch: 1050, loss is 5.96987024307251 and perplexity is 391.4548734726774
At time: 33.02745985984802 and batch: 1100, loss is 6.040314359664917 and perplexity is 420.0250530699314
At time: 34.510849714279175 and batch: 1150, loss is 5.944388580322266 and perplexity is 381.60596855616427
At time: 35.994741916656494 and batch: 1200, loss is 6.025430603027344 and perplexity is 413.8197957203271
At time: 37.47940421104431 and batch: 1250, loss is 5.963239126205444 and perplexity is 388.86767793675347
At time: 38.964197874069214 and batch: 1300, loss is 5.975469493865967 and perplexity is 393.652875322802
At time: 40.446483850479126 and batch: 1350, loss is 5.943284788131714 and perplexity is 381.1849872488858
At time: 41.92840361595154 and batch: 1400, loss is 5.961763753890991 and perplexity is 388.2943763513766
At time: 43.41328835487366 and batch: 1450, loss is 5.947769813537597 and perplexity is 382.8984511934425
At time: 44.89772629737854 and batch: 1500, loss is 5.915529642105103 and perplexity is 370.75061584853944
At time: 46.3829550743103 and batch: 1550, loss is 5.888099212646484 and perplexity is 360.7189822420959
At time: 47.86784839630127 and batch: 1600, loss is 5.884404745101929 and perplexity is 359.38877638369115
At time: 49.35203790664673 and batch: 1650, loss is 5.88275671005249 and perplexity is 358.7969788693035
At time: 50.834977865219116 and batch: 1700, loss is 5.894153499603272 and perplexity is 362.90950280036
At time: 52.320329427719116 and batch: 1750, loss is 5.896875858306885 and perplexity is 363.8988186692611
At time: 53.80510234832764 and batch: 1800, loss is 5.905482025146484 and perplexity is 367.04410764304345
At time: 55.29395127296448 and batch: 1850, loss is 5.853375520706177 and perplexity is 348.4084577662344
At time: 56.78103423118591 and batch: 1900, loss is 5.842553911209106 and perplexity is 344.65844467551625
At time: 58.26524567604065 and batch: 1950, loss is 5.7862412643432615 and perplexity is 325.7861760048089
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.24124386809593 and perplexity of 188.9049291431705
finished 1 epochs...
Completing Train Step...
At time: 62.23190379142761 and batch: 50, loss is 5.542957429885864 and perplexity is 255.43230664093886
At time: 63.490933418273926 and batch: 100, loss is 5.4591826152801515 and perplexity is 234.90533783787757
At time: 64.7503912448883 and batch: 150, loss is 5.346812086105347 and perplexity is 209.93796579574135
At time: 66.00819730758667 and batch: 200, loss is 5.291116418838501 and perplexity is 198.56498339874534
At time: 67.26910614967346 and batch: 250, loss is 5.2811735820770265 and perplexity is 196.60046680050877
At time: 68.53038167953491 and batch: 300, loss is 5.269736995697022 and perplexity is 194.36483693411142
At time: 69.80745506286621 and batch: 350, loss is 5.233212280273437 and perplexity is 187.39379912450485
At time: 71.09443664550781 and batch: 400, loss is 5.1824421691894536 and perplexity is 178.11727277852643
At time: 72.36902332305908 and batch: 450, loss is 5.122800426483154 and perplexity is 167.8046367891808
At time: 73.64032483100891 and batch: 500, loss is 5.105992097854614 and perplexity is 165.0076931317562
At time: 74.90877079963684 and batch: 550, loss is 5.0595043277740475 and perplexity is 157.512422437436
At time: 76.17765283584595 and batch: 600, loss is 5.042638034820556 and perplexity is 154.8780502732221
At time: 77.44742369651794 and batch: 650, loss is 5.108474140167236 and perplexity is 165.41775789654784
At time: 78.71643471717834 and batch: 700, loss is 5.094302320480347 and perplexity is 163.09002035551217
At time: 79.98194003105164 and batch: 750, loss is 5.026770496368409 and perplexity is 152.43991164012309
At time: 81.24667596817017 and batch: 800, loss is 5.029083051681519 and perplexity is 152.79284529973316
At time: 82.51431798934937 and batch: 850, loss is 5.022535514831543 and perplexity is 151.7956965112706
At time: 83.77875828742981 and batch: 900, loss is 5.010862007141113 and perplexity is 150.03401081193027
At time: 85.04386925697327 and batch: 950, loss is 5.056464080810547 and perplexity is 157.03427298791155
At time: 86.3087797164917 and batch: 1000, loss is 5.0125936794281 and perplexity is 150.2940456331253
At time: 87.57361388206482 and batch: 1050, loss is 4.929962005615234 and perplexity is 138.3742547954043
At time: 88.8429012298584 and batch: 1100, loss is 4.993802490234375 and perplexity is 147.4962114306948
At time: 90.11284947395325 and batch: 1150, loss is 4.909466819763184 and perplexity is 135.56711342980856
At time: 91.38053750991821 and batch: 1200, loss is 4.985266895294189 and perplexity is 146.2426012800554
At time: 92.64645433425903 and batch: 1250, loss is 4.94517038345337 and perplexity is 140.4947867991988
At time: 93.91490530967712 and batch: 1300, loss is 4.954315013885498 and perplexity is 141.78545203618827
At time: 95.18389177322388 and batch: 1350, loss is 4.862441997528077 and perplexity is 129.33966391169218
At time: 96.44967722892761 and batch: 1400, loss is 4.864314470291138 and perplexity is 129.58207579354564
At time: 97.71840190887451 and batch: 1450, loss is 4.816757287979126 and perplexity is 123.56375874356578
At time: 98.98700976371765 and batch: 1500, loss is 4.782535362243652 and perplexity is 119.40670584574966
At time: 100.25393724441528 and batch: 1550, loss is 4.785610761642456 and perplexity is 119.77449441561299
At time: 101.52598071098328 and batch: 1600, loss is 4.840670871734619 and perplexity is 126.55422490981151
At time: 102.80684614181519 and batch: 1650, loss is 4.816987886428833 and perplexity is 123.59225564031583
At time: 104.07663536071777 and batch: 1700, loss is 4.824783992767334 and perplexity is 124.55955971127077
At time: 105.34759140014648 and batch: 1750, loss is 4.820663967132568 and perplexity is 124.04742685688723
At time: 106.61446642875671 and batch: 1800, loss is 4.777617425918579 and perplexity is 118.82091289649554
At time: 107.87961149215698 and batch: 1850, loss is 4.788581275939942 and perplexity is 120.13081522977198
At time: 109.14476799964905 and batch: 1900, loss is 4.883666038513184 and perplexity is 132.11411259849555
At time: 110.40929007530212 and batch: 1950, loss is 4.797781085968017 and perplexity is 121.24109526024218
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.615530182594477 and perplexity of 101.0413847174469
finished 2 epochs...
Completing Train Step...
At time: 114.29687476158142 and batch: 50, loss is 4.764594650268554 and perplexity is 117.28356678886793
At time: 115.5867829322815 and batch: 100, loss is 4.697653913497925 and perplexity is 109.68952921972219
At time: 116.85127401351929 and batch: 150, loss is 4.642332973480225 and perplexity is 103.7861958032682
At time: 118.11562728881836 and batch: 200, loss is 4.626873903274536 and perplexity is 102.19409561716704
At time: 119.38078737258911 and batch: 250, loss is 4.629746217727661 and perplexity is 102.48805115930932
At time: 120.64512634277344 and batch: 300, loss is 4.6461998558044435 and perplexity is 104.18830175646919
At time: 121.90891861915588 and batch: 350, loss is 4.649758682250977 and perplexity is 104.55975040878258
At time: 123.17059302330017 and batch: 400, loss is 4.5991205215454105 and perplexity is 99.39685979316164
At time: 124.43493866920471 and batch: 450, loss is 4.59009783744812 and perplexity is 98.50406707706529
At time: 125.70171737670898 and batch: 500, loss is 4.588613882064819 and perplexity is 98.35799984188408
At time: 126.96972584724426 and batch: 550, loss is 4.562587823867798 and perplexity is 95.83115337006781
At time: 128.23913264274597 and batch: 600, loss is 4.5309192943573 and perplexity is 92.84387271114733
At time: 129.50606751441956 and batch: 650, loss is 4.598041172027588 and perplexity is 99.28963371808686
At time: 130.77165126800537 and batch: 700, loss is 4.6283767032623295 and perplexity is 102.34778835861302
At time: 132.03666162490845 and batch: 750, loss is 4.578233585357666 and perplexity is 97.34229539696625
At time: 133.31390571594238 and batch: 800, loss is 4.575567378997802 and perplexity is 97.08310642907284
At time: 134.58231449127197 and batch: 850, loss is 4.565166254043579 and perplexity is 96.07856613889871
At time: 135.84994101524353 and batch: 900, loss is 4.541264734268188 and perplexity is 93.809369048288
At time: 137.13127517700195 and batch: 950, loss is 4.607253303527832 and perplexity is 100.20852887364406
At time: 138.40817546844482 and batch: 1000, loss is 4.580692071914672 and perplexity is 97.58190453886871
At time: 139.6846113204956 and batch: 1050, loss is 4.513918743133545 and perplexity is 91.2788167979459
At time: 140.9522135257721 and batch: 1100, loss is 4.566596870422363 and perplexity is 96.21611607640402
At time: 142.22134685516357 and batch: 1150, loss is 4.520507402420044 and perplexity is 91.88220740668552
At time: 143.48795461654663 and batch: 1200, loss is 4.5818197059631345 and perplexity is 97.69200328081916
At time: 144.75372862815857 and batch: 1250, loss is 4.56540849685669 and perplexity is 96.10184330028856
At time: 146.0230257511139 and batch: 1300, loss is 4.557508163452148 and perplexity is 95.34559792615497
At time: 147.2926812171936 and batch: 1350, loss is 4.445269575119019 and perplexity is 85.22284870057844
At time: 148.56032538414001 and batch: 1400, loss is 4.461201763153076 and perplexity is 86.59150907711839
At time: 149.82771635055542 and batch: 1450, loss is 4.411668548583984 and perplexity is 82.40684868608811
At time: 151.1047065258026 and batch: 1500, loss is 4.399426794052124 and perplexity is 81.40419392098806
At time: 152.38329577445984 and batch: 1550, loss is 4.40574577331543 and perplexity is 81.92021397730457
At time: 153.66370701789856 and batch: 1600, loss is 4.47726243019104 and perplexity is 87.99345442617627
At time: 154.93270564079285 and batch: 1650, loss is 4.449376459121704 and perplexity is 85.57356874488845
At time: 156.2002556324005 and batch: 1700, loss is 4.457886390686035 and perplexity is 86.30490134026972
At time: 157.466148853302 and batch: 1750, loss is 4.451136493682862 and perplexity is 85.72431380274305
At time: 158.73132276535034 and batch: 1800, loss is 4.411920223236084 and perplexity is 82.42759101111108
At time: 159.99900460243225 and batch: 1850, loss is 4.443696546554565 and perplexity is 85.08889610847639
At time: 161.27001118659973 and batch: 1900, loss is 4.550146169662476 and perplexity is 94.64624171309369
At time: 162.54124188423157 and batch: 1950, loss is 4.475170278549195 and perplexity is 87.8095512198047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.464595918877181 and perplexity of 86.885913487884
finished 3 epochs...
Completing Train Step...
At time: 166.4383943080902 and batch: 50, loss is 4.448761253356934 and perplexity is 85.52093958262654
At time: 167.71649408340454 and batch: 100, loss is 4.387420654296875 and perplexity is 80.43268748312427
At time: 168.9837930202484 and batch: 150, loss is 4.346303777694702 and perplexity is 77.19261390861242
At time: 170.25327897071838 and batch: 200, loss is 4.340802345275879 and perplexity is 76.76910996725658
At time: 171.52135133743286 and batch: 250, loss is 4.337524461746216 and perplexity is 76.51788173948684
At time: 172.7891297340393 and batch: 300, loss is 4.350652666091919 and perplexity is 77.52904699632452
At time: 174.05602097511292 and batch: 350, loss is 4.360963201522827 and perplexity is 78.33254812759968
At time: 175.32395124435425 and batch: 400, loss is 4.314372987747192 and perplexity is 74.7667290885707
At time: 176.59004521369934 and batch: 450, loss is 4.32391209602356 and perplexity is 75.48334953881013
At time: 177.8572895526886 and batch: 500, loss is 4.327772731781006 and perplexity is 75.77532650283764
At time: 179.12273502349854 and batch: 550, loss is 4.3015095901489255 and perplexity is 73.8111342002599
At time: 180.3855848312378 and batch: 600, loss is 4.2724898099899296 and perplexity is 71.69993277298975
At time: 181.649151802063 and batch: 650, loss is 4.337628650665283 and perplexity is 76.52585447020249
At time: 182.91521501541138 and batch: 700, loss is 4.371136732101441 and perplexity is 79.13353422099216
At time: 184.18027687072754 and batch: 750, loss is 4.3302163314819335 and perplexity is 75.96071748644349
At time: 185.44687128067017 and batch: 800, loss is 4.322983312606811 and perplexity is 75.41327440286742
At time: 186.71599173545837 and batch: 850, loss is 4.312697067260742 and perplexity is 74.64153093596447
At time: 187.98937129974365 and batch: 900, loss is 4.282635173797607 and perplexity is 72.43105716632566
At time: 189.25969886779785 and batch: 950, loss is 4.3623811054229735 and perplexity is 78.44369493222085
At time: 190.52734446525574 and batch: 1000, loss is 4.3417141723632815 and perplexity is 76.83914204492098
At time: 191.79804277420044 and batch: 1050, loss is 4.279898633956909 and perplexity is 72.23311765089612
At time: 193.06420636177063 and batch: 1100, loss is 4.324517631530762 and perplexity is 75.52907122881474
At time: 194.32806730270386 and batch: 1150, loss is 4.288310222625732 and perplexity is 72.8432755257451
At time: 195.60140466690063 and batch: 1200, loss is 4.3497493982315065 and perplexity is 77.45904911810044
At time: 196.88138389587402 and batch: 1250, loss is 4.342852792739868 and perplexity is 76.92668248598004
At time: 198.14903783798218 and batch: 1300, loss is 4.325630178451538 and perplexity is 75.61314762523521
At time: 199.4159562587738 and batch: 1350, loss is 4.208708448410034 and perplexity is 67.26960151875963
At time: 200.68231010437012 and batch: 1400, loss is 4.235566229820251 and perplexity is 69.10079458869042
At time: 201.94834566116333 and batch: 1450, loss is 4.183901863098145 and perplexity is 65.62140005472313
At time: 203.21593141555786 and batch: 1500, loss is 4.173936171531677 and perplexity is 64.97068521876464
At time: 204.48675560951233 and batch: 1550, loss is 4.18663444519043 and perplexity is 65.80096113835222
At time: 205.7557897567749 and batch: 1600, loss is 4.262365102767944 and perplexity is 70.97765454366255
At time: 207.02765154838562 and batch: 1650, loss is 4.231869220733643 and perplexity is 68.84579997234715
At time: 208.29850244522095 and batch: 1700, loss is 4.234801259040832 and perplexity is 69.04795471305262
At time: 209.56849265098572 and batch: 1750, loss is 4.236210122108459 and perplexity is 69.1453023850108
At time: 210.83717036247253 and batch: 1800, loss is 4.196819720268249 and perplexity is 66.47458673546063
At time: 212.105051279068 and batch: 1850, loss is 4.229986743927002 and perplexity is 68.71632125923813
At time: 213.37192368507385 and batch: 1900, loss is 4.338130006790161 and perplexity is 76.56423079535163
At time: 214.6381995677948 and batch: 1950, loss is 4.26413028717041 and perplexity is 71.10305383626358
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.417294240552326 and perplexity of 82.87175070453657
finished 4 epochs...
Completing Train Step...
At time: 218.5317256450653 and batch: 50, loss is 4.24353111743927 and perplexity is 69.65337234055616
At time: 219.81030440330505 and batch: 100, loss is 4.189376640319824 and perplexity is 65.98164783936618
At time: 221.07602834701538 and batch: 150, loss is 4.153404154777527 and perplexity is 63.65030741586456
At time: 222.34965014457703 and batch: 200, loss is 4.151535596847534 and perplexity is 63.531484177820715
At time: 223.619074344635 and batch: 250, loss is 4.144659714698792 and perplexity is 63.09614755667385
At time: 224.88816380500793 and batch: 300, loss is 4.154036417007446 and perplexity is 63.69056382612915
At time: 226.15661144256592 and batch: 350, loss is 4.167611393928528 and perplexity is 64.56105685370915
At time: 227.4350550174713 and batch: 400, loss is 4.124063768386841 and perplexity is 61.80991375753504
At time: 228.70468544960022 and batch: 450, loss is 4.145016465187073 and perplexity is 63.11866115375296
At time: 229.97239184379578 and batch: 500, loss is 4.1499221134185795 and perplexity is 63.42905983309474
At time: 231.2394835948944 and batch: 550, loss is 4.125059170722961 and perplexity is 61.871470121676396
At time: 232.50607299804688 and batch: 600, loss is 4.102025856971741 and perplexity is 60.46265229450563
At time: 233.77247619628906 and batch: 650, loss is 4.161693444252014 and perplexity is 64.18011607414705
At time: 235.04036045074463 and batch: 700, loss is 4.1977810955047605 and perplexity is 66.53852448616604
At time: 236.3068869113922 and batch: 750, loss is 4.157781062126159 and perplexity is 63.92950948920896
At time: 237.57319474220276 and batch: 800, loss is 4.151962623596192 and perplexity is 63.55861961431283
At time: 238.8419907093048 and batch: 850, loss is 4.139929203987122 and perplexity is 62.798375417228094
At time: 240.11014676094055 and batch: 900, loss is 4.1118330383300785 and perplexity is 61.058537692996
At time: 241.379065990448 and batch: 950, loss is 4.192957496643066 and perplexity is 66.21834217152937
At time: 242.6519694328308 and batch: 1000, loss is 4.172190380096436 and perplexity is 64.85735890380585
At time: 243.92411875724792 and batch: 1050, loss is 4.118642058372497 and perplexity is 61.47570513890713
At time: 245.192373752594 and batch: 1100, loss is 4.156888856887817 and perplexity is 63.872496683302074
At time: 246.45941758155823 and batch: 1150, loss is 4.124986443519592 and perplexity is 61.86697054630888
At time: 247.7276291847229 and batch: 1200, loss is 4.18876503944397 and perplexity is 65.94130574364537
At time: 248.99382996559143 and batch: 1250, loss is 4.181118974685669 and perplexity is 65.439036886766
At time: 250.25942015647888 and batch: 1300, loss is 4.162500987052917 and perplexity is 64.2319651972192
At time: 251.5233976840973 and batch: 1350, loss is 4.04387282371521 and perplexity is 57.04684792665743
At time: 252.78844928741455 and batch: 1400, loss is 4.078940858840943 and perplexity is 59.082859610785974
At time: 254.05312871932983 and batch: 1450, loss is 4.024988436698914 and perplexity is 55.979661468221344
At time: 255.3188853263855 and batch: 1500, loss is 4.010931687355042 and perplexity is 55.19827414775428
At time: 256.58576798439026 and batch: 1550, loss is 4.035026535987854 and perplexity is 56.54442068047544
At time: 257.8562035560608 and batch: 1600, loss is 4.111198191642761 and perplexity is 61.019787184226686
At time: 259.12565875053406 and batch: 1650, loss is 4.07968638420105 and perplexity is 59.12692380441948
At time: 260.395033121109 and batch: 1700, loss is 4.078443078994751 and perplexity is 59.053456672718504
At time: 261.6627869606018 and batch: 1750, loss is 4.082985820770264 and perplexity is 59.322331529469935
At time: 262.9287643432617 and batch: 1800, loss is 4.042694449424744 and perplexity is 56.97966497881175
At time: 264.19389724731445 and batch: 1850, loss is 4.080445289611816 and perplexity is 59.17181257782869
At time: 265.4595663547516 and batch: 1900, loss is 4.182312679290772 and perplexity is 65.51719840805397
At time: 266.72431087493896 and batch: 1950, loss is 4.10872510433197 and perplexity is 60.86906637251707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.407633652797965 and perplexity of 82.07501554585252
finished 5 epochs...
Completing Train Step...
At time: 270.6386389732361 and batch: 50, loss is 4.094391865730286 and perplexity is 60.00283827762081
At time: 271.90577244758606 and batch: 100, loss is 4.044717121124267 and perplexity is 57.09503277086401
At time: 273.174373626709 and batch: 150, loss is 4.010904870033264 and perplexity is 55.19679389772316
At time: 274.44313621520996 and batch: 200, loss is 4.008842649459839 and perplexity is 55.08308322230594
At time: 275.7114281654358 and batch: 250, loss is 4.004940314292908 and perplexity is 54.86854943316668
At time: 276.97737407684326 and batch: 300, loss is 4.009805111885071 and perplexity is 55.13612414102449
At time: 278.2440826892853 and batch: 350, loss is 4.024584522247315 and perplexity is 55.957055039797616
At time: 279.50975465774536 and batch: 400, loss is 3.985486135482788 and perplexity is 53.81144277206405
At time: 280.77490973472595 and batch: 450, loss is 4.011117334365845 and perplexity is 55.208522493609266
At time: 282.0524287223816 and batch: 500, loss is 4.016814618110657 and perplexity is 55.52395882329439
At time: 283.33065390586853 and batch: 550, loss is 3.991860480308533 and perplexity is 54.155551031056554
At time: 284.5954647064209 and batch: 600, loss is 3.9726941204071045 and perplexity is 53.12747000667783
At time: 285.8637261390686 and batch: 650, loss is 4.027807388305664 and perplexity is 56.13768805486634
At time: 287.1357452869415 and batch: 700, loss is 4.06908447265625 and perplexity is 58.5033766249245
At time: 288.39793610572815 and batch: 750, loss is 4.026443476676941 and perplexity is 56.0611734007933
At time: 289.66562843322754 and batch: 800, loss is 4.01907678604126 and perplexity is 55.64970551877079
At time: 290.94861102104187 and batch: 850, loss is 4.009620747566223 and perplexity is 55.12595994403973
At time: 292.21547985076904 and batch: 900, loss is 3.981774163246155 and perplexity is 53.61206645907964
At time: 293.4804799556732 and batch: 950, loss is 4.066168942451477 and perplexity is 58.33305667042699
At time: 294.7488422393799 and batch: 1000, loss is 4.043182830810547 and perplexity is 57.00749958295474
At time: 296.0173101425171 and batch: 1050, loss is 3.9935246992111204 and perplexity is 54.24575275965463
At time: 297.2822790145874 and batch: 1100, loss is 4.032250514030457 and perplexity is 56.38766979970561
At time: 298.54571080207825 and batch: 1150, loss is 4.000084595680237 and perplexity is 54.602768996155376
At time: 299.8100185394287 and batch: 1200, loss is 4.066072049140931 and perplexity is 58.32740486126757
At time: 301.07293248176575 and batch: 1250, loss is 4.058539347648621 and perplexity is 57.889692579311955
At time: 302.3362731933594 and batch: 1300, loss is 4.035128760337829 and perplexity is 56.55020119257373
At time: 303.6042866706848 and batch: 1350, loss is 3.918465566635132 and perplexity is 50.32316795722222
At time: 304.86834597587585 and batch: 1400, loss is 3.9593411827087404 and perplexity is 52.42277753750563
At time: 306.13375449180603 and batch: 1450, loss is 3.90041277885437 and perplexity is 49.42284560120648
At time: 307.3988678455353 and batch: 1500, loss is 3.8868727254867554 and perplexity is 48.75816767622964
At time: 308.665176153183 and batch: 1550, loss is 3.915111560821533 and perplexity is 50.15466649473841
At time: 309.93031907081604 and batch: 1600, loss is 3.9947381114959715 and perplexity is 54.31161517350407
At time: 311.1942503452301 and batch: 1650, loss is 3.9604447650909425 and perplexity is 52.48066232566353
At time: 312.45770716667175 and batch: 1700, loss is 3.9600339698791505 and perplexity is 52.459107948389075
At time: 313.72538471221924 and batch: 1750, loss is 3.964723992347717 and perplexity is 52.70572019980158
At time: 314.9928870201111 and batch: 1800, loss is 3.9204864645004274 and perplexity is 50.42496876979783
At time: 316.2593927383423 and batch: 1850, loss is 3.9619014739990233 and perplexity is 52.55716708302749
At time: 317.5238320827484 and batch: 1900, loss is 4.060213007926941 and perplexity is 57.98666138208758
At time: 318.78863549232483 and batch: 1950, loss is 3.9883557176589965 and perplexity is 53.96608089640754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411607751180959 and perplexity of 82.40183871599466
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 322.7109658718109 and batch: 50, loss is 4.017210559844971 and perplexity is 55.54594742866286
At time: 323.9834852218628 and batch: 100, loss is 4.005365862846374 and perplexity is 54.891903633829486
At time: 325.2537622451782 and batch: 150, loss is 3.976392092704773 and perplexity is 53.32429762624862
At time: 326.519572019577 and batch: 200, loss is 3.97907039642334 and perplexity is 53.467307717612755
At time: 327.7900366783142 and batch: 250, loss is 3.9689169549942016 and perplexity is 52.927177272019435
At time: 329.06077313423157 and batch: 300, loss is 3.9747800827026367 and perplexity is 53.238407571531184
At time: 330.32997250556946 and batch: 350, loss is 3.998331446647644 and perplexity is 54.50712606716389
At time: 331.5971829891205 and batch: 400, loss is 3.9492079067230224 and perplexity is 51.894245468053285
At time: 332.86303520202637 and batch: 450, loss is 3.9564692068099974 and perplexity is 52.27243657502059
At time: 334.1270616054535 and batch: 500, loss is 3.959390416145325 and perplexity is 52.42535855453475
At time: 335.39193964004517 and batch: 550, loss is 3.932793664932251 and perplexity is 51.04939354601871
At time: 336.65803360939026 and batch: 600, loss is 3.898110270500183 and perplexity is 49.30917999454341
At time: 337.9239225387573 and batch: 650, loss is 3.944901008605957 and perplexity is 51.671222852545796
At time: 339.19063353538513 and batch: 700, loss is 3.991388831138611 and perplexity is 54.130014632949965
At time: 340.4560661315918 and batch: 750, loss is 3.9353226709365843 and perplexity is 51.178661159200885
At time: 341.724023103714 and batch: 800, loss is 3.9240827131271363 and perplexity is 50.60663595888586
At time: 342.9921889305115 and batch: 850, loss is 3.9145522356033324 and perplexity is 50.126621568805746
At time: 344.2556426525116 and batch: 900, loss is 3.8748748826980592 and perplexity is 48.176670179006834
At time: 345.52123498916626 and batch: 950, loss is 3.9706911420822144 and perplexity is 53.02116333631764
At time: 346.78583574295044 and batch: 1000, loss is 3.9234428453445434 and perplexity is 50.57426476069824
At time: 348.0507609844208 and batch: 1050, loss is 3.8711132192611695 and perplexity is 47.995786185928914
At time: 349.3327479362488 and batch: 1100, loss is 3.894097242355347 and perplexity is 49.11169738409153
At time: 350.6070623397827 and batch: 1150, loss is 3.873153553009033 and perplexity is 48.09381357853096
At time: 351.87179136276245 and batch: 1200, loss is 3.919810080528259 and perplexity is 50.39087366111724
At time: 353.13812232017517 and batch: 1250, loss is 3.9083422565460206 and perplexity is 49.81630083853031
At time: 354.40233635902405 and batch: 1300, loss is 3.881219382286072 and perplexity is 48.483298716874565
At time: 355.6678159236908 and batch: 1350, loss is 3.761355299949646 and perplexity is 43.006673440804676
At time: 356.9330141544342 and batch: 1400, loss is 3.7826389598846437 and perplexity is 43.93182321616646
At time: 358.19895696640015 and batch: 1450, loss is 3.7189201498031617 and perplexity is 41.21985879457164
At time: 359.46306347846985 and batch: 1500, loss is 3.706597867012024 and perplexity is 40.7150526075976
At time: 360.7357678413391 and batch: 1550, loss is 3.72516583442688 and perplexity is 41.478110673227896
At time: 362.0062448978424 and batch: 1600, loss is 3.8041778230667114 and perplexity is 44.888328788658725
At time: 363.2751352787018 and batch: 1650, loss is 3.762091121673584 and perplexity is 43.0383303308821
At time: 364.543470621109 and batch: 1700, loss is 3.7430304384231565 and perplexity is 42.225759031991444
At time: 365.81187868118286 and batch: 1750, loss is 3.739048647880554 and perplexity is 42.05795919762108
At time: 367.08185601234436 and batch: 1800, loss is 3.687214913368225 and perplexity is 39.93347375335598
At time: 368.34840416908264 and batch: 1850, loss is 3.7139869499206544 and perplexity is 41.017013740983955
At time: 369.61348152160645 and batch: 1900, loss is 3.805649218559265 and perplexity is 44.954425888869245
At time: 370.881888628006 and batch: 1950, loss is 3.7320131397247316 and perplexity is 41.76309854618722
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352205498273983 and perplexity of 77.64953011636831
finished 7 epochs...
Completing Train Step...
At time: 374.7726900577545 and batch: 50, loss is 3.9370907878875734 and perplexity is 51.26923106302124
At time: 376.03791642189026 and batch: 100, loss is 3.907253828048706 and perplexity is 49.76210885446674
At time: 377.3029417991638 and batch: 150, loss is 3.8709963750839234 and perplexity is 47.9901784854007
At time: 378.56737899780273 and batch: 200, loss is 3.864824151992798 and perplexity is 47.694884644803906
At time: 379.83273816108704 and batch: 250, loss is 3.854683828353882 and perplexity is 47.213686952056534
At time: 381.09939312934875 and batch: 300, loss is 3.860043849945068 and perplexity is 47.46743276753797
At time: 382.3655586242676 and batch: 350, loss is 3.8806379652023315 and perplexity is 48.455117891924885
At time: 383.6309766769409 and batch: 400, loss is 3.8371900796890257 and perplexity is 46.39492506674827
At time: 384.9291515350342 and batch: 450, loss is 3.8529744577407836 and perplexity is 47.133050201725034
At time: 386.19632148742676 and batch: 500, loss is 3.858107771873474 and perplexity is 47.375621017878395
At time: 387.4731721878052 and batch: 550, loss is 3.834102373123169 and perplexity is 46.25189208757058
At time: 388.7372817993164 and batch: 600, loss is 3.803446431159973 and perplexity is 44.85550983149852
At time: 389.99999022483826 and batch: 650, loss is 3.848385934829712 and perplexity is 46.91727454536516
At time: 391.26274156570435 and batch: 700, loss is 3.8952849817276003 and perplexity is 49.17006393597707
At time: 392.53365111351013 and batch: 750, loss is 3.844660439491272 and perplexity is 46.742809643630906
At time: 393.7997682094574 and batch: 800, loss is 3.832192964553833 and perplexity is 46.16366258835739
At time: 395.0688009262085 and batch: 850, loss is 3.8283385705947874 and perplexity is 45.98607211782998
At time: 396.33452463150024 and batch: 900, loss is 3.789788212776184 and perplexity is 44.24702832829725
At time: 397.6043038368225 and batch: 950, loss is 3.889890093803406 and perplexity is 48.905511209617586
At time: 398.87215542793274 and batch: 1000, loss is 3.8443059062957765 and perplexity is 46.72624070325475
At time: 400.13904213905334 and batch: 1050, loss is 3.7953201866149904 and perplexity is 44.4924800216701
At time: 401.4067316055298 and batch: 1100, loss is 3.817842192649841 and perplexity is 45.505909318232106
At time: 402.67648220062256 and batch: 1150, loss is 3.8002595138549804 and perplexity is 44.71278657539628
At time: 403.94377756118774 and batch: 1200, loss is 3.849575834274292 and perplexity is 46.973134611627984
At time: 405.2114884853363 and batch: 1250, loss is 3.842397379875183 and perplexity is 46.637147483762526
At time: 406.47936630249023 and batch: 1300, loss is 3.8169984722137453 and perplexity is 45.467531245036184
At time: 407.74628710746765 and batch: 1350, loss is 3.6973713397979737 and perplexity is 40.34112176094525
At time: 409.0119414329529 and batch: 1400, loss is 3.7257560157775877 and perplexity is 41.502597505735004
At time: 410.276978969574 and batch: 1450, loss is 3.661244831085205 and perplexity is 38.90974880130384
At time: 411.54229378700256 and batch: 1500, loss is 3.6522864151000975 and perplexity is 38.56273575003818
At time: 412.807076215744 and batch: 1550, loss is 3.6757630777359007 and perplexity is 39.47877073711385
At time: 414.07279109954834 and batch: 1600, loss is 3.7596742296218872 and perplexity is 42.93443693252473
At time: 415.33999371528625 and batch: 1650, loss is 3.718071279525757 and perplexity is 41.18488332851911
At time: 416.61634731292725 and batch: 1700, loss is 3.704715857505798 and perplexity is 40.63849855186988
At time: 417.88577485084534 and batch: 1750, loss is 3.7048994970321654 and perplexity is 40.64596207177387
At time: 419.1539080142975 and batch: 1800, loss is 3.656819920539856 and perplexity is 38.737957005485
At time: 420.42110657691956 and batch: 1850, loss is 3.6870616245269776 and perplexity is 39.92735286658115
At time: 421.688353061676 and batch: 1900, loss is 3.782130241394043 and perplexity is 43.90947996906392
At time: 422.95700120925903 and batch: 1950, loss is 3.710010652542114 and perplexity is 40.8542417262028
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35898806549782 and perplexity of 78.17798338330809
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 426.8320026397705 and batch: 50, loss is 3.9060757207870482 and perplexity is 49.70351827244163
At time: 428.11090564727783 and batch: 100, loss is 3.910535740852356 and perplexity is 49.925692042703936
At time: 429.378050327301 and batch: 150, loss is 3.8923171091079714 and perplexity is 49.02434978699004
At time: 430.6438715457916 and batch: 200, loss is 3.897429485321045 and perplexity is 49.27562245963995
At time: 431.9081952571869 and batch: 250, loss is 3.8925857496261598 and perplexity is 49.03752148286705
At time: 433.1746850013733 and batch: 300, loss is 3.892761116027832 and perplexity is 49.04612177063514
At time: 434.439649105072 and batch: 350, loss is 3.913232264518738 and perplexity is 50.06049952695866
At time: 435.7043104171753 and batch: 400, loss is 3.8742713499069215 and perplexity is 48.1476027512412
At time: 436.97020292282104 and batch: 450, loss is 3.889428825378418 and perplexity is 48.88295784346644
At time: 438.23477268218994 and batch: 500, loss is 3.887193078994751 and perplexity is 48.773790028492236
At time: 439.50009632110596 and batch: 550, loss is 3.8677982330322265 and perplexity is 47.83694424056725
At time: 440.7691185474396 and batch: 600, loss is 3.8275299644470215 and perplexity is 45.948902527008975
At time: 442.03882122039795 and batch: 650, loss is 3.859887523651123 and perplexity is 47.46001293966253
At time: 443.3088278770447 and batch: 700, loss is 3.910179405212402 and perplexity is 49.9079049085629
At time: 444.572612285614 and batch: 750, loss is 3.8520105838775636 and perplexity is 47.08764177405562
At time: 445.8390326499939 and batch: 800, loss is 3.8383337306976317 and perplexity is 46.44801502199896
At time: 447.110595703125 and batch: 850, loss is 3.8395408248901366 and perplexity is 46.5041160039582
At time: 448.41909623146057 and batch: 900, loss is 3.787783670425415 and perplexity is 44.158422123232505
At time: 449.68595147132874 and batch: 950, loss is 3.8987869119644163 and perplexity is 49.342555920789444
At time: 450.95135378837585 and batch: 1000, loss is 3.846602449417114 and perplexity is 46.833672843982264
At time: 452.21720933914185 and batch: 1050, loss is 3.7860932683944704 and perplexity is 44.08383969169864
At time: 453.48431611061096 and batch: 1100, loss is 3.8021630668640136 and perplexity is 44.79798079495543
At time: 454.7517580986023 and batch: 1150, loss is 3.7932359647750853 and perplexity is 44.39984439323131
At time: 456.0184519290924 and batch: 1200, loss is 3.8340862226486205 and perplexity is 46.25114510359669
At time: 457.2848918437958 and batch: 1250, loss is 3.8218235778808594 and perplexity is 45.68744701947448
At time: 458.5512580871582 and batch: 1300, loss is 3.800967745780945 and perplexity is 44.744464814793936
At time: 459.81879234313965 and batch: 1350, loss is 3.680742449760437 and perplexity is 39.6758404582323
At time: 461.0919530391693 and batch: 1400, loss is 3.696869397163391 and perplexity is 40.32087791305675
At time: 462.3811786174774 and batch: 1450, loss is 3.623460168838501 and perplexity is 37.46698588578823
At time: 463.6557078361511 and batch: 1500, loss is 3.61491192817688 and perplexity is 37.14807408296018
At time: 464.9226529598236 and batch: 1550, loss is 3.6362153339385985 and perplexity is 37.94794430785844
At time: 466.1911768913269 and batch: 1600, loss is 3.7174934482574464 and perplexity is 41.16109228941529
At time: 467.4596793651581 and batch: 1650, loss is 3.6735624361038206 and perplexity is 39.39198763492316
At time: 468.7261519432068 and batch: 1700, loss is 3.647917881011963 and perplexity is 38.39464055650249
At time: 469.9933021068573 and batch: 1750, loss is 3.653684525489807 and perplexity is 38.616688418650696
At time: 471.2599971294403 and batch: 1800, loss is 3.608070673942566 and perplexity is 36.89480200101363
At time: 472.5251233577728 and batch: 1850, loss is 3.6282435035705567 and perplexity is 37.64663233269553
At time: 473.7900414466858 and batch: 1900, loss is 3.726209840774536 and perplexity is 41.52143669644589
At time: 475.0635886192322 and batch: 1950, loss is 3.660511326789856 and perplexity is 38.881218798146236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328109386355378 and perplexity of 75.80084090765895
finished 9 epochs...
Completing Train Step...
At time: 478.9438314437866 and batch: 50, loss is 3.9020494413375855 and perplexity is 49.50380034814342
At time: 480.2253761291504 and batch: 100, loss is 3.8791421937942503 and perplexity is 48.382694290086356
At time: 481.48893642425537 and batch: 150, loss is 3.847491283416748 and perplexity is 46.87531871012284
At time: 482.7535471916199 and batch: 200, loss is 3.8469756031036377 and perplexity is 46.851152262709384
At time: 484.0182361602783 and batch: 250, loss is 3.8410252285003663 and perplexity is 46.57319814184752
At time: 485.28321838378906 and batch: 300, loss is 3.8384060764312746 and perplexity is 46.451375459277166
At time: 486.5486056804657 and batch: 350, loss is 3.8581804752349855 and perplexity is 47.379065509991655
At time: 487.8140983581543 and batch: 400, loss is 3.82049108505249 and perplexity is 45.62660936584473
At time: 489.079785823822 and batch: 450, loss is 3.8375605964660644 and perplexity is 46.412118349858176
At time: 490.3463897705078 and batch: 500, loss is 3.835946650505066 and perplexity is 46.337272114042804
At time: 491.61303091049194 and batch: 550, loss is 3.8175699424743654 and perplexity is 45.4935220127346
At time: 492.8802309036255 and batch: 600, loss is 3.780078024864197 and perplexity is 43.81946060965689
At time: 494.146005153656 and batch: 650, loss is 3.813547477722168 and perplexity is 45.31089347865306
At time: 495.4120934009552 and batch: 700, loss is 3.866079788208008 and perplexity is 47.754809683395244
At time: 496.67575454711914 and batch: 750, loss is 3.8112178373336794 and perplexity is 45.205458251933
At time: 497.9426620006561 and batch: 800, loss is 3.798384637832642 and perplexity is 44.62903418116559
At time: 499.2097818851471 and batch: 850, loss is 3.800358171463013 and perplexity is 44.71719804957744
At time: 500.47789549827576 and batch: 900, loss is 3.7510077953338623 and perplexity is 42.563956148647904
At time: 501.7464349269867 and batch: 950, loss is 3.8624815940856934 and perplexity is 47.583287378213626
At time: 503.01621317863464 and batch: 1000, loss is 3.8116253995895386 and perplexity is 45.22388604545678
At time: 504.2904574871063 and batch: 1050, loss is 3.7538192081451416 and perplexity is 42.68378937166158
At time: 505.5698866844177 and batch: 1100, loss is 3.7717011833190917 and perplexity is 43.453925085631134
At time: 506.83977484703064 and batch: 1150, loss is 3.7648579931259154 and perplexity is 43.15757675211497
At time: 508.10726952552795 and batch: 1200, loss is 3.8070250034332274 and perplexity is 45.01631607205168
At time: 509.3723175525665 and batch: 1250, loss is 3.797163233757019 and perplexity is 44.574557372795994
At time: 510.6373736858368 and batch: 1300, loss is 3.778687663078308 and perplexity is 43.758578040353555
At time: 511.9021029472351 and batch: 1350, loss is 3.6594426155090334 and perplexity is 38.83968819706828
At time: 513.1668539047241 and batch: 1400, loss is 3.6784229278564453 and perplexity is 39.5839181263745
At time: 514.4321236610413 and batch: 1450, loss is 3.607453670501709 and perplexity is 36.872044802586096
At time: 515.6966321468353 and batch: 1500, loss is 3.601314001083374 and perplexity is 36.646356172464536
At time: 516.9651048183441 and batch: 1550, loss is 3.625560507774353 and perplexity is 37.54576195431559
At time: 518.2343952655792 and batch: 1600, loss is 3.7100486087799074 and perplexity is 40.85579242894586
At time: 519.5040831565857 and batch: 1650, loss is 3.666848225593567 and perplexity is 39.12838746132394
At time: 520.7720003128052 and batch: 1700, loss is 3.645000500679016 and perplexity is 38.282792018943816
At time: 522.0500135421753 and batch: 1750, loss is 3.652214879989624 and perplexity is 38.559977259141796
At time: 523.3150005340576 and batch: 1800, loss is 3.609126925468445 and perplexity is 36.93379278033422
At time: 524.5838947296143 and batch: 1850, loss is 3.6305216932296753 and perplexity is 37.732496271207715
At time: 525.8544280529022 and batch: 1900, loss is 3.7295303916931153 and perplexity is 41.65953990368034
At time: 527.1229441165924 and batch: 1950, loss is 3.6629794359207155 and perplexity is 38.977300410459286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328339900526889 and perplexity of 75.8183160897618
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 531.0201814174652 and batch: 50, loss is 3.8955334663391112 and perplexity is 49.18228345833093
At time: 532.3004422187805 and batch: 100, loss is 3.88699640750885 and perplexity is 48.764198557949605
At time: 533.5658254623413 and batch: 150, loss is 3.8635071468353273 and perplexity is 47.63211158103943
At time: 534.8354587554932 and batch: 200, loss is 3.8698201513290407 and perplexity is 47.9337644817148
At time: 536.1029455661774 and batch: 250, loss is 3.873945713043213 and perplexity is 48.13192666937979
At time: 537.3696222305298 and batch: 300, loss is 3.8697253274917602 and perplexity is 47.92921943372421
At time: 538.6349046230316 and batch: 350, loss is 3.88892165184021 and perplexity is 48.85817198667553
At time: 539.9030628204346 and batch: 400, loss is 3.8573783588409425 and perplexity is 47.34107722236257
At time: 541.1726865768433 and batch: 450, loss is 3.882500505447388 and perplexity is 48.545451598044714
At time: 542.4425132274628 and batch: 500, loss is 3.8782061195373534 and perplexity is 48.337425686174974
At time: 543.7268540859222 and batch: 550, loss is 3.863256268501282 and perplexity is 47.62016321509466
At time: 544.9958300590515 and batch: 600, loss is 3.820553684234619 and perplexity is 45.62946564367375
At time: 546.2642078399658 and batch: 650, loss is 3.8409658527374266 and perplexity is 46.57043290477015
At time: 547.532262802124 and batch: 700, loss is 3.893301124572754 and perplexity is 49.07261424792484
At time: 548.7980120182037 and batch: 750, loss is 3.8343079042434693 and perplexity is 46.26139926774458
At time: 550.0657620429993 and batch: 800, loss is 3.8202528953552246 and perplexity is 45.61574287176747
At time: 551.3347406387329 and batch: 850, loss is 3.823306460380554 and perplexity is 45.75524639194296
At time: 552.6019525527954 and batch: 900, loss is 3.7708453559875488 and perplexity is 43.416751938046815
At time: 553.8694176673889 and batch: 950, loss is 3.8878479051589965 and perplexity is 48.805738841650054
At time: 555.1401579380035 and batch: 1000, loss is 3.839920468330383 and perplexity is 46.52177433826687
At time: 556.4092445373535 and batch: 1050, loss is 3.7751942110061645 and perplexity is 43.60597625393654
At time: 557.6770617961884 and batch: 1100, loss is 3.7898903274536133 and perplexity is 44.25154683002095
At time: 558.9432623386383 and batch: 1150, loss is 3.7828529262542725 and perplexity is 43.94122415459766
At time: 560.2080526351929 and batch: 1200, loss is 3.8176168155670167 and perplexity is 45.495654484784325
At time: 561.4733331203461 and batch: 1250, loss is 3.8023420763015747 and perplexity is 44.80600077410597
At time: 562.7394616603851 and batch: 1300, loss is 3.780543336868286 and perplexity is 43.83985507521812
At time: 564.005612373352 and batch: 1350, loss is 3.656557855606079 and perplexity is 38.72780647545479
At time: 565.2709255218506 and batch: 1400, loss is 3.676138024330139 and perplexity is 39.493575943153786
At time: 566.5407772064209 and batch: 1450, loss is 3.601509327888489 and perplexity is 36.65351488725648
At time: 567.8103673458099 and batch: 1500, loss is 3.5911409425735474 and perplexity is 36.275440519139345
At time: 569.0791671276093 and batch: 1550, loss is 3.613703932762146 and perplexity is 37.10322647310896
At time: 570.3461701869965 and batch: 1600, loss is 3.6973663473129275 and perplexity is 40.34092035900086
At time: 571.6108856201172 and batch: 1650, loss is 3.6548540353775025 and perplexity is 38.6618774369376
At time: 572.8742787837982 and batch: 1700, loss is 3.6288478803634643 and perplexity is 37.669391960611215
At time: 574.1405503749847 and batch: 1750, loss is 3.6315174770355223 and perplexity is 37.770088393655826
At time: 575.4052176475525 and batch: 1800, loss is 3.5930334997177122 and perplexity is 36.34415886944284
At time: 576.6722486019135 and batch: 1850, loss is 3.6122083568573 and perplexity is 37.04777725619561
At time: 577.9408054351807 and batch: 1900, loss is 3.7110280799865722 and perplexity is 40.8958291054406
At time: 579.2083485126495 and batch: 1950, loss is 3.6606008052825927 and perplexity is 38.884697986654004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3131804710210755 and perplexity of 74.67762165518785
finished 11 epochs...
Completing Train Step...
At time: 583.1601886749268 and batch: 50, loss is 3.9044448804855345 and perplexity is 49.622525832534365
At time: 584.4286334514618 and batch: 100, loss is 3.8805335569381714 and perplexity is 48.45005904127362
At time: 585.6979856491089 and batch: 150, loss is 3.8471373653411867 and perplexity is 46.858731622941754
At time: 586.9657926559448 and batch: 200, loss is 3.847267746925354 and perplexity is 46.8648415369043
At time: 588.2338745594025 and batch: 250, loss is 3.847776327133179 and perplexity is 46.88868212966576
At time: 589.499071598053 and batch: 300, loss is 3.8411000251770018 and perplexity is 46.576681792569936
At time: 590.76553606987 and batch: 350, loss is 3.8606963682174684 and perplexity is 47.49841624230508
At time: 592.0306117534637 and batch: 400, loss is 3.827991065979004 and perplexity is 45.97009452181225
At time: 593.2948672771454 and batch: 450, loss is 3.8519827270507814 and perplexity is 47.086330080045045
At time: 594.5597865581512 and batch: 500, loss is 3.848971791267395 and perplexity is 46.94476938592436
At time: 595.824004650116 and batch: 550, loss is 3.8337366437911986 and perplexity is 46.23497950687696
At time: 597.0904932022095 and batch: 600, loss is 3.792604126930237 and perplexity is 44.371799752004115
At time: 598.3568935394287 and batch: 650, loss is 3.8149692583084107 and perplexity is 45.375361446138676
At time: 599.6223385334015 and batch: 700, loss is 3.8692052507400514 and perplexity is 47.90429904178912
At time: 600.8864915370941 and batch: 750, loss is 3.813737359046936 and perplexity is 45.31949798802518
At time: 602.1535692214966 and batch: 800, loss is 3.800545678138733 and perplexity is 44.72558360888083
At time: 603.4175646305084 and batch: 850, loss is 3.8029679584503175 and perplexity is 44.834052827871155
At time: 604.6860537528992 and batch: 900, loss is 3.750194330215454 and perplexity is 42.52934593402922
At time: 605.9661762714386 and batch: 950, loss is 3.8666137647628784 and perplexity is 47.780316441547846
At time: 607.244024515152 and batch: 1000, loss is 3.819917597770691 and perplexity is 45.600450587242165
At time: 608.5194466114044 and batch: 1050, loss is 3.757855987548828 and perplexity is 42.85644266063167
At time: 609.7891848087311 and batch: 1100, loss is 3.774700388908386 and perplexity is 43.5844479752745
At time: 611.0587494373322 and batch: 1150, loss is 3.7685824823379517 and perplexity is 43.318616390183834
At time: 612.3273804187775 and batch: 1200, loss is 3.8051079177856444 and perplexity is 44.93009860813987
At time: 613.5934021472931 and batch: 1250, loss is 3.791961965560913 and perplexity is 44.34331504318468
At time: 614.859078168869 and batch: 1300, loss is 3.7720760107040405 and perplexity is 43.47021585966013
At time: 616.1248199939728 and batch: 1350, loss is 3.6492172193527224 and perplexity is 38.44456060955342
At time: 617.3991844654083 and batch: 1400, loss is 3.6706340456008912 and perplexity is 39.276801250114
At time: 618.6686146259308 and batch: 1450, loss is 3.597920823097229 and perplexity is 36.52221929179882
At time: 619.9433946609497 and batch: 1500, loss is 3.590182228088379 and perplexity is 36.24067939451713
At time: 621.210690498352 and batch: 1550, loss is 3.614751091003418 and perplexity is 37.142099772183634
At time: 622.4868443012238 and batch: 1600, loss is 3.6997492361068725 and perplexity is 40.43716290816767
At time: 623.7531549930573 and batch: 1650, loss is 3.6580663537979126 and perplexity is 38.786271387517026
At time: 625.0193152427673 and batch: 1700, loss is 3.6342098760604857 and perplexity is 37.87191756368534
At time: 626.285224199295 and batch: 1750, loss is 3.638390097618103 and perplexity is 38.03056192318325
At time: 627.5606000423431 and batch: 1800, loss is 3.6008881521224976 and perplexity is 36.63075368215651
At time: 628.8379604816437 and batch: 1850, loss is 3.6202993297576906 and perplexity is 37.34874574004087
At time: 630.1143946647644 and batch: 1900, loss is 3.7196292877197266 and perplexity is 41.24909972605956
At time: 631.3834095001221 and batch: 1950, loss is 3.667419919967651 and perplexity is 39.1507633357739
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311628758630087 and perplexity of 74.56183332266417
finished 12 epochs...
Completing Train Step...
At time: 635.3100781440735 and batch: 50, loss is 3.899592089653015 and perplexity is 49.38230144487262
At time: 636.5769412517548 and batch: 100, loss is 3.872770290374756 and perplexity is 48.07538454865127
At time: 637.8586525917053 and batch: 150, loss is 3.837847476005554 and perplexity is 46.425434947035434
At time: 639.1339030265808 and batch: 200, loss is 3.8366573905944823 and perplexity is 46.37021757741236
At time: 640.4030110836029 and batch: 250, loss is 3.8359106588363647 and perplexity is 46.335604388308646
At time: 641.67041182518 and batch: 300, loss is 3.8289031457901 and perplexity is 46.01204204377574
At time: 642.93638920784 and batch: 350, loss is 3.8488176488876342 and perplexity is 46.93753376512613
At time: 644.2001149654388 and batch: 400, loss is 3.8155856990814208 and perplexity is 45.40334129209705
At time: 645.4660158157349 and batch: 450, loss is 3.839829068183899 and perplexity is 46.51752243559287
At time: 646.7337737083435 and batch: 500, loss is 3.8368057870864867 and perplexity is 46.377099265630896
At time: 648.0039048194885 and batch: 550, loss is 3.8218916702270507 and perplexity is 45.6905580908524
At time: 649.2707207202911 and batch: 600, loss is 3.781155490875244 and perplexity is 43.866700033953094
At time: 650.5370516777039 and batch: 650, loss is 3.8036756134033203 and perplexity is 44.86579109596481
At time: 651.8039238452911 and batch: 700, loss is 3.8585751247406006 and perplexity is 47.39776732485994
At time: 653.0685081481934 and batch: 750, loss is 3.804171853065491 and perplexity is 44.888060806081
At time: 654.3370661735535 and batch: 800, loss is 3.7914338159561156 and perplexity is 44.31990132238716
At time: 655.6090075969696 and batch: 850, loss is 3.7936812257766723 and perplexity is 44.41961831436742
At time: 656.8786249160767 and batch: 900, loss is 3.7413527297973634 and perplexity is 42.154975905166836
At time: 658.1510982513428 and batch: 950, loss is 3.8577242565155028 and perplexity is 47.35745522327788
At time: 659.417073726654 and batch: 1000, loss is 3.8114234972000123 and perplexity is 45.21475615650475
At time: 660.6832494735718 and batch: 1050, loss is 3.7501796436309816 and perplexity is 42.52872132778428
At time: 661.949027299881 and batch: 1100, loss is 3.767607750892639 and perplexity is 43.27641294447517
At time: 663.2153427600861 and batch: 1150, loss is 3.7618166160583497 and perplexity is 43.026517688928415
At time: 664.4816699028015 and batch: 1200, loss is 3.79889657497406 and perplexity is 44.65188729052718
At time: 665.7519841194153 and batch: 1250, loss is 3.786712713241577 and perplexity is 44.111155658530336
At time: 667.0219857692719 and batch: 1300, loss is 3.7675143671035767 and perplexity is 43.27237181774818
At time: 668.2907197475433 and batch: 1350, loss is 3.6450185585021972 and perplexity is 38.28348332907474
At time: 669.5577981472015 and batch: 1400, loss is 3.6671028757095336 and perplexity is 39.1383527785093
At time: 670.8241872787476 and batch: 1450, loss is 3.59512752532959 and perplexity is 36.42034420814382
At time: 672.089038848877 and batch: 1500, loss is 3.5884170961380004 and perplexity is 36.17676623758659
At time: 673.3548765182495 and batch: 1550, loss is 3.6138367319107054 and perplexity is 37.10815407717697
At time: 674.6218092441559 and batch: 1600, loss is 3.6996407604217527 and perplexity is 40.432776697119834
At time: 675.8876514434814 and batch: 1650, loss is 3.6581408405303955 and perplexity is 38.78916055773896
At time: 677.1523044109344 and batch: 1700, loss is 3.63501904964447 and perplexity is 37.902574920841715
At time: 678.4193263053894 and batch: 1750, loss is 3.639572253227234 and perplexity is 38.07554654945447
At time: 679.6896059513092 and batch: 1800, loss is 3.602406969070435 and perplexity is 36.686431363064244
At time: 680.9604525566101 and batch: 1850, loss is 3.6218714475631715 and perplexity is 37.40750854715589
At time: 682.2297854423523 and batch: 1900, loss is 3.7212008237838745 and perplexity is 41.31397513756509
At time: 683.4969556331635 and batch: 1950, loss is 3.668125696182251 and perplexity is 39.17840476650449
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311574252816134 and perplexity of 74.55776938000429
finished 13 epochs...
Completing Train Step...
At time: 687.413081407547 and batch: 50, loss is 3.8937394714355467 and perplexity is 49.094129789720064
At time: 688.6796839237213 and batch: 100, loss is 3.8657813024520875 and perplexity is 47.74055768004388
At time: 689.944356918335 and batch: 150, loss is 3.8303272008895872 and perplexity is 46.077612403707704
At time: 691.2079844474792 and batch: 200, loss is 3.828689680099487 and perplexity is 46.002221099698964
At time: 692.4734451770782 and batch: 250, loss is 3.8273506355285645 and perplexity is 45.94066329880254
At time: 693.742219209671 and batch: 300, loss is 3.8201853466033935 and perplexity is 45.61266168933882
At time: 695.0119028091431 and batch: 350, loss is 3.840101556777954 and perplexity is 46.530199657000956
At time: 696.2813067436218 and batch: 400, loss is 3.806665472984314 and perplexity is 45.00013424482999
At time: 697.5499663352966 and batch: 450, loss is 3.8311998796463014 and perplexity is 46.11784090793999
At time: 698.8167679309845 and batch: 500, loss is 3.828132872581482 and perplexity is 45.97661384696272
At time: 700.096960067749 and batch: 550, loss is 3.8135510158538817 and perplexity is 45.31105379484586
At time: 701.3655092716217 and batch: 600, loss is 3.7731144762039186 and perplexity is 43.51538162658907
At time: 702.6344463825226 and batch: 650, loss is 3.795672836303711 and perplexity is 44.5081730478079
At time: 703.8997893333435 and batch: 700, loss is 3.850997896194458 and perplexity is 47.03998083610014
At time: 705.1636464595795 and batch: 750, loss is 3.7971099281311034 and perplexity is 44.57218136144328
At time: 706.4294748306274 and batch: 800, loss is 3.7845979499816895 and perplexity is 44.017969575174284
At time: 707.6948614120483 and batch: 850, loss is 3.7867722845077516 and perplexity is 44.11378349419631
At time: 708.9619061946869 and batch: 900, loss is 3.734890103340149 and perplexity is 41.883422461942935
At time: 710.2299346923828 and batch: 950, loss is 3.8513132619857786 and perplexity is 47.05481797632048
At time: 711.4989767074585 and batch: 1000, loss is 3.805282564163208 and perplexity is 44.93794617235975
At time: 712.7682039737701 and batch: 1050, loss is 3.7444462680816653 and perplexity is 42.28558585628414
At time: 714.0360701084137 and batch: 1100, loss is 3.7621347904205322 and perplexity is 43.040209801875164
At time: 715.3046238422394 and batch: 1150, loss is 3.756592621803284 and perplexity is 42.80233348603414
At time: 716.5719163417816 and batch: 1200, loss is 3.7939489030838014 and perplexity is 44.431510029681675
At time: 717.8397762775421 and batch: 1250, loss is 3.7823098611831667 and perplexity is 43.917367688970586
At time: 719.1053516864777 and batch: 1300, loss is 3.7635145235061644 and perplexity is 43.099634789234855
At time: 720.3709125518799 and batch: 1350, loss is 3.641204161643982 and perplexity is 38.13773308190278
At time: 721.6390295028687 and batch: 1400, loss is 3.66370521068573 and perplexity is 39.005599419616736
At time: 722.9048628807068 and batch: 1450, loss is 3.5921697425842285 and perplexity is 36.31277989681554
At time: 724.1691098213196 and batch: 1500, loss is 3.586031551361084 and perplexity is 36.09056779783999
At time: 725.4349517822266 and batch: 1550, loss is 3.611894073486328 and perplexity is 37.036135585360114
At time: 726.7008264064789 and batch: 1600, loss is 3.698290252685547 and perplexity is 40.378208774888385
At time: 727.9669504165649 and batch: 1650, loss is 3.656875004768372 and perplexity is 38.74009091473276
At time: 729.2404391765594 and batch: 1700, loss is 3.6341817140579225 and perplexity is 37.87085102966377
At time: 730.5238716602325 and batch: 1750, loss is 3.6388686227798464 and perplexity is 38.048764858912755
At time: 731.7954456806183 and batch: 1800, loss is 3.6019414854049683 and perplexity is 36.669358402420904
At time: 733.0617575645447 and batch: 1850, loss is 3.6214515590667724 and perplexity is 37.391804861767135
At time: 734.3286564350128 and batch: 1900, loss is 3.720779275894165 and perplexity is 41.296562988815474
At time: 735.593320608139 and batch: 1950, loss is 3.667251901626587 and perplexity is 39.144185842052096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311997524527616 and perplexity of 74.58933425444202
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 739.4834280014038 and batch: 50, loss is 3.892871785163879 and perplexity is 49.051549962919104
At time: 740.7639656066895 and batch: 100, loss is 3.87112060546875 and perplexity is 47.996140694077916
At time: 742.0334920883179 and batch: 150, loss is 3.838244023323059 and perplexity is 46.44384847940482
At time: 743.3017704486847 and batch: 200, loss is 3.838364825248718 and perplexity is 46.44945932462978
At time: 744.5730931758881 and batch: 250, loss is 3.8398931646347045 and perplexity is 46.520504139238554
At time: 745.8382079601288 and batch: 300, loss is 3.8325527572631835 and perplexity is 46.180274925913366
At time: 747.1056981086731 and batch: 350, loss is 3.8521954154968263 and perplexity is 47.09634586350268
At time: 748.3756005764008 and batch: 400, loss is 3.823014702796936 and perplexity is 45.741898899028605
At time: 749.6420428752899 and batch: 450, loss is 3.851128077507019 and perplexity is 47.0461049611629
At time: 750.907568693161 and batch: 500, loss is 3.849224829673767 and perplexity is 46.95664971858412
At time: 752.174839258194 and batch: 550, loss is 3.837298493385315 and perplexity is 46.399955184725734
At time: 753.4424715042114 and batch: 600, loss is 3.792857165336609 and perplexity is 44.3830289421495
At time: 754.7080678939819 and batch: 650, loss is 3.810178098678589 and perplexity is 45.15848081592756
At time: 755.9730093479156 and batch: 700, loss is 3.8655052280426023 and perplexity is 47.7273795529294
At time: 757.2359774112701 and batch: 750, loss is 3.8088805150985716 and perplexity is 45.09992191347385
At time: 758.5021185874939 and batch: 800, loss is 3.795038104057312 and perplexity is 44.47993123908768
At time: 759.770024061203 and batch: 850, loss is 3.7954981327056885 and perplexity is 44.50039798902019
At time: 761.0543134212494 and batch: 900, loss is 3.742900557518005 and perplexity is 42.22027506832646
At time: 762.3236627578735 and batch: 950, loss is 3.8611688375473023 and perplexity is 47.52086308950112
At time: 763.603178024292 and batch: 1000, loss is 3.815482087135315 and perplexity is 45.39863720724996
At time: 764.8701894283295 and batch: 1050, loss is 3.7562059926986695 and perplexity is 42.78578805684137
At time: 766.1380324363708 and batch: 1100, loss is 3.773250799179077 and perplexity is 43.52131417723985
At time: 767.4049308300018 and batch: 1150, loss is 3.764823627471924 and perplexity is 43.15609363924941
At time: 768.6702950000763 and batch: 1200, loss is 3.800602173805237 and perplexity is 44.72811048191462
At time: 769.934003829956 and batch: 1250, loss is 3.7856324815750124 and perplexity is 44.06353111873832
At time: 771.198605298996 and batch: 1300, loss is 3.7631360054016114 and perplexity is 43.08332388434865
At time: 772.4642663002014 and batch: 1350, loss is 3.636573691368103 and perplexity is 37.96154567256507
At time: 773.7294564247131 and batch: 1400, loss is 3.6589862298965454 and perplexity is 38.82196636648347
At time: 774.99316573143 and batch: 1450, loss is 3.5833970880508423 and perplexity is 35.99561365265489
At time: 776.2589886188507 and batch: 1500, loss is 3.5750569820404055 and perplexity is 35.69665482593192
At time: 777.5272924900055 and batch: 1550, loss is 3.602494502067566 and perplexity is 36.689642776905785
At time: 778.792010307312 and batch: 1600, loss is 3.6896160316467284 and perplexity is 40.02947395490559
At time: 780.0590784549713 and batch: 1650, loss is 3.6465275144577025 and perplexity is 38.341295025924246
At time: 781.3243222236633 and batch: 1700, loss is 3.6214611673355104 and perplexity is 37.39216413400283
At time: 782.5917882919312 and batch: 1750, loss is 3.6241401481628417 and perplexity is 37.492471325339935
At time: 783.8566336631775 and batch: 1800, loss is 3.5863944339752196 and perplexity is 36.10366681398697
At time: 785.1218485832214 and batch: 1850, loss is 3.6077787828445436 and perplexity is 36.884034308319514
At time: 786.3880999088287 and batch: 1900, loss is 3.7081236457824707 and perplexity is 40.77722218695517
At time: 787.6559972763062 and batch: 1950, loss is 3.659368782043457 and perplexity is 38.836820634149134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.308864291878634 and perplexity of 74.35599426222552
finished 15 epochs...
Completing Train Step...
At time: 791.5227463245392 and batch: 50, loss is 3.8953199052810668 and perplexity is 49.17178115931948
At time: 792.7991127967834 and batch: 100, loss is 3.869988465309143 and perplexity is 47.941833083406195
At time: 794.0646641254425 and batch: 150, loss is 3.835487332344055 and perplexity is 46.315993450641486
At time: 795.361414194107 and batch: 200, loss is 3.833638548851013 and perplexity is 46.230444311771244
At time: 796.6241796016693 and batch: 250, loss is 3.833443284034729 and perplexity is 46.22141801384385
At time: 797.8914978504181 and batch: 300, loss is 3.824975600242615 and perplexity is 45.83168207076737
At time: 799.1573603153229 and batch: 350, loss is 3.8444867849349977 and perplexity is 46.7346932465083
At time: 800.4244914054871 and batch: 400, loss is 3.814508681297302 and perplexity is 45.3544674098116
At time: 801.6910755634308 and batch: 450, loss is 3.8411563348770144 and perplexity is 46.579304585392904
At time: 802.9566197395325 and batch: 500, loss is 3.8393040704727173 and perplexity is 46.4931072523028
At time: 804.2210805416107 and batch: 550, loss is 3.826811261177063 and perplexity is 45.91589076476351
At time: 805.4854891300201 and batch: 600, loss is 3.783766121864319 and perplexity is 43.981369415043666
At time: 806.7507934570312 and batch: 650, loss is 3.801802005767822 and perplexity is 44.781808906597995
At time: 808.0151064395905 and batch: 700, loss is 3.8572462511062624 and perplexity is 47.334823512984194
At time: 809.2756371498108 and batch: 750, loss is 3.8015543603897095 and perplexity is 44.77072027168002
At time: 810.5346705913544 and batch: 800, loss is 3.787806510925293 and perplexity is 44.159430735186184
At time: 811.7955358028412 and batch: 850, loss is 3.788441605567932 and perplexity is 44.18748506070104
At time: 813.0544981956482 and batch: 900, loss is 3.735810327529907 and perplexity is 41.921982339587274
At time: 814.3128867149353 and batch: 950, loss is 3.8538112115859984 and perplexity is 47.172505467588664
At time: 815.5721952915192 and batch: 1000, loss is 3.808517127037048 and perplexity is 45.08353611765645
At time: 816.8310122489929 and batch: 1050, loss is 3.74984263420105 and perplexity is 42.514391162489936
At time: 818.089982509613 and batch: 1100, loss is 3.7676662254333495 and perplexity is 43.278943586834046
At time: 819.3494505882263 and batch: 1150, loss is 3.7604809474945067 and perplexity is 42.96908688463772
At time: 820.6096155643463 and batch: 1200, loss is 3.7969474172592164 and perplexity is 44.56493848592727
At time: 821.8719673156738 and batch: 1250, loss is 3.782439727783203 and perplexity is 43.92307145855147
At time: 823.1307682991028 and batch: 1300, loss is 3.7608647203445433 and perplexity is 42.985580418257676
At time: 824.3918988704681 and batch: 1350, loss is 3.6352163314819337 and perplexity is 37.91005314810165
At time: 825.6511471271515 and batch: 1400, loss is 3.658294758796692 and perplexity is 38.79513137758043
At time: 826.912770986557 and batch: 1450, loss is 3.5836612033843993 and perplexity is 36.005121901743266
At time: 828.1719419956207 and batch: 1500, loss is 3.5765526342391967 and perplexity is 35.75008455239567
At time: 829.4324104785919 and batch: 1550, loss is 3.6045245790481566 and perplexity is 36.76420123022724
At time: 830.6903398036957 and batch: 1600, loss is 3.691830024719238 and perplexity is 40.1181971129249
At time: 831.9492406845093 and batch: 1650, loss is 3.64937126159668 and perplexity is 38.45048315208683
At time: 833.2120976448059 and batch: 1700, loss is 3.625233211517334 and perplexity is 37.53347537774596
At time: 834.4767487049103 and batch: 1750, loss is 3.6282737684249877 and perplexity is 37.6477717197845
At time: 835.7396879196167 and batch: 1800, loss is 3.5910270977020264 and perplexity is 36.271310981341884
At time: 837.0040872097015 and batch: 1850, loss is 3.6121985721588135 and perplexity is 37.047414756639036
At time: 838.2672231197357 and batch: 1900, loss is 3.712662363052368 and perplexity is 40.96271911012232
At time: 839.5286812782288 and batch: 1950, loss is 3.6634989881515505 and perplexity is 38.997556415410095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307966649255087 and perplexity of 74.28927910012585
finished 16 epochs...
Completing Train Step...
At time: 843.4258553981781 and batch: 50, loss is 3.895159330368042 and perplexity is 49.163886038732656
At time: 844.7246809005737 and batch: 100, loss is 3.8682112503051758 and perplexity is 47.85670580547662
At time: 846.0014343261719 and batch: 150, loss is 3.8331734991073607 and perplexity is 46.20894985387857
At time: 847.2843270301819 and batch: 200, loss is 3.830290904045105 and perplexity is 46.07593996212854
At time: 848.569185256958 and batch: 250, loss is 3.829314351081848 and perplexity is 46.030966329564855
At time: 849.8337552547455 and batch: 300, loss is 3.820321502685547 and perplexity is 45.6188725534649
At time: 851.0983176231384 and batch: 350, loss is 3.8399734449386598 and perplexity is 46.52423896936565
At time: 852.3629393577576 and batch: 400, loss is 3.8095689821243286 and perplexity is 45.13098241341364
At time: 853.6331374645233 and batch: 450, loss is 3.8357239818572997 and perplexity is 46.32695540496644
At time: 854.9005749225616 and batch: 500, loss is 3.83383629322052 and perplexity is 46.23958702576402
At time: 856.1649360656738 and batch: 550, loss is 3.8211532640457153 and perplexity is 45.656832353508314
At time: 857.4282796382904 and batch: 600, loss is 3.778775544166565 and perplexity is 43.762423760792906
At time: 858.7235894203186 and batch: 650, loss is 3.7971861600875854 and perplexity is 44.57557931554783
At time: 859.9865062236786 and batch: 700, loss is 3.852870054244995 and perplexity is 47.1281296033851
At time: 861.249945640564 and batch: 750, loss is 3.7976995038986208 and perplexity is 44.598467787637894
At time: 862.5132541656494 and batch: 800, loss is 3.7840745496749877 and perplexity is 43.99493658466122
At time: 863.7843022346497 and batch: 850, loss is 3.7846134901046753 and perplexity is 44.018653625150165
At time: 865.0473940372467 and batch: 900, loss is 3.731886553764343 and perplexity is 41.75781225884089
At time: 866.3097400665283 and batch: 950, loss is 3.8498116731643677 and perplexity is 46.98421400998331
At time: 867.5734417438507 and batch: 1000, loss is 3.804762406349182 and perplexity is 44.91457742675662
At time: 868.8458316326141 and batch: 1050, loss is 3.7464758586883544 and perplexity is 42.37149543528352
At time: 870.1092491149902 and batch: 1100, loss is 3.764721450805664 and perplexity is 43.151684318741225
At time: 871.37979388237 and batch: 1150, loss is 3.758082389831543 and perplexity is 42.8661465555296
At time: 872.6445598602295 and batch: 1200, loss is 3.7949287271499634 and perplexity is 44.47506642782353
At time: 873.9099836349487 and batch: 1250, loss is 3.7808549356460572 and perplexity is 43.85351764898732
At time: 875.1812489032745 and batch: 1300, loss is 3.7597529745101927 and perplexity is 42.93781793308195
At time: 876.4486351013184 and batch: 1350, loss is 3.6344575309753417 and perplexity is 37.88129789169923
At time: 877.7145476341248 and batch: 1400, loss is 3.65787672996521 and perplexity is 38.77891728335902
At time: 879.0025794506073 and batch: 1450, loss is 3.5837879514694215 and perplexity is 36.009685771220056
At time: 880.2659788131714 and batch: 1500, loss is 3.5773065185546873 and perplexity is 35.77704614210004
At time: 881.5327913761139 and batch: 1550, loss is 3.6056585454940797 and perplexity is 36.80591424694431
At time: 882.795577287674 and batch: 1600, loss is 3.693057126998901 and perplexity is 40.16745646100617
At time: 884.0598244667053 and batch: 1650, loss is 3.650842618942261 and perplexity is 38.50709919391434
At time: 885.3226642608643 and batch: 1700, loss is 3.6271785640716554 and perplexity is 37.60656228679807
At time: 886.5931301116943 and batch: 1750, loss is 3.63037034034729 and perplexity is 37.72678578129793
At time: 887.856442451477 and batch: 1800, loss is 3.5932990598678587 and perplexity is 36.3538117113775
At time: 889.119279384613 and batch: 1850, loss is 3.6143176651000974 and perplexity is 37.12600491225521
At time: 890.3825914859772 and batch: 1900, loss is 3.714807376861572 and perplexity is 41.05067901215243
At time: 891.6455249786377 and batch: 1950, loss is 3.6652551174163817 and perplexity is 39.06610133474151
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307604696584303 and perplexity of 74.26239476286723
finished 17 epochs...
Completing Train Step...
At time: 895.5997035503387 and batch: 50, loss is 3.8940914249420167 and perplexity is 49.111411681879524
At time: 896.8656594753265 and batch: 100, loss is 3.866237134933472 and perplexity is 47.76232433751169
At time: 898.1299498081207 and batch: 150, loss is 3.830905532836914 and perplexity is 46.1042682662428
At time: 899.3951206207275 and batch: 200, loss is 3.827472290992737 and perplexity is 45.94625257149643
At time: 900.6606256961823 and batch: 250, loss is 3.826046085357666 and perplexity is 45.88077047373655
At time: 901.9255647659302 and batch: 300, loss is 3.8168417167663575 and perplexity is 45.4604045204253
At time: 903.1909549236298 and batch: 350, loss is 3.8366161346435548 and perplexity is 46.36830456945324
At time: 904.455504655838 and batch: 400, loss is 3.805965371131897 and perplexity is 44.968640593154454
At time: 905.7195014953613 and batch: 450, loss is 3.832010440826416 and perplexity is 46.155237393512934
At time: 906.9837114810944 and batch: 500, loss is 3.8300983762741088 and perplexity is 46.06706991800338
At time: 908.248387336731 and batch: 550, loss is 3.817359757423401 and perplexity is 45.48396095932225
At time: 909.51304936409 and batch: 600, loss is 3.7753391742706297 and perplexity is 43.612297976802225
At time: 910.7816476821899 and batch: 650, loss is 3.7939582538604735 and perplexity is 44.43192550075165
At time: 912.051287651062 and batch: 700, loss is 3.8498530530929567 and perplexity is 46.98615825362991
At time: 913.3158655166626 and batch: 750, loss is 3.7949888134002685 and perplexity is 44.4777388480843
At time: 914.5809471607208 and batch: 800, loss is 3.7814967155456545 and perplexity is 43.881670988298396
At time: 915.8458740711212 and batch: 850, loss is 3.7819399547576906 and perplexity is 43.901125376725474
At time: 917.1092109680176 and batch: 900, loss is 3.7291971158981325 and perplexity is 41.64565810076327
At time: 918.3722488880157 and batch: 950, loss is 3.8471255540847777 and perplexity is 46.858178165716076
At time: 919.6374583244324 and batch: 1000, loss is 3.8022228145599364 and perplexity is 44.800657451051144
At time: 920.93532538414 and batch: 1050, loss is 3.744218258857727 and perplexity is 42.275945451761615
At time: 922.1960301399231 and batch: 1100, loss is 3.76272735118866 and perplexity is 43.06572129946556
At time: 923.4596321582794 and batch: 1150, loss is 3.7563647079467772 and perplexity is 42.792579352735146
At time: 924.7271480560303 and batch: 1200, loss is 3.7934270906448364 and perplexity is 44.40833116310258
At time: 925.9938957691193 and batch: 1250, loss is 3.779672079086304 and perplexity is 43.80167589469206
At time: 927.259726524353 and batch: 1300, loss is 3.758867092132568 and perplexity is 42.899796920400476
At time: 928.5251686573029 and batch: 1350, loss is 3.6337472009658813 and perplexity is 37.854399223606045
At time: 929.7899043560028 and batch: 1400, loss is 3.6573638486862183 and perplexity is 38.759033402135906
At time: 931.0550916194916 and batch: 1450, loss is 3.5835974645614623 and perplexity is 36.002827050789875
At time: 932.3182570934296 and batch: 1500, loss is 3.5775132846832274 and perplexity is 35.78444438824844
At time: 933.5824375152588 and batch: 1550, loss is 3.6061445903778075 and perplexity is 36.82380792146718
At time: 934.8491053581238 and batch: 1600, loss is 3.693615198135376 and perplexity is 40.18987901519086
At time: 936.1150505542755 and batch: 1650, loss is 3.6514803266525266 and perplexity is 38.53166329949757
At time: 937.3794093132019 and batch: 1700, loss is 3.628117575645447 and perplexity is 37.64189186888315
At time: 938.6453256607056 and batch: 1750, loss is 3.6313920545578005 and perplexity is 37.76535147265012
At time: 939.906895160675 and batch: 1800, loss is 3.5943993759155273 and perplexity is 36.39383440856751
At time: 941.1697142124176 and batch: 1850, loss is 3.6153214597702026 and perplexity is 37.163290508519076
At time: 942.4354951381683 and batch: 1900, loss is 3.7157997989654543 and perplexity is 41.09143883551292
At time: 943.6978731155396 and batch: 1950, loss is 3.6659467935562136 and perplexity is 39.0931317719876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307469283702762 and perplexity of 74.25233935883325
finished 18 epochs...
Completing Train Step...
At time: 947.6197040081024 and batch: 50, loss is 3.8926911544799805 and perplexity is 49.04269054806818
At time: 948.8844330310822 and batch: 100, loss is 3.8642748975753785 and perplexity is 47.66869521171375
At time: 950.1500923633575 and batch: 150, loss is 3.8287586164474487 and perplexity is 46.00539243412855
At time: 951.4166696071625 and batch: 200, loss is 3.8250057220458986 and perplexity is 45.83306262447115
At time: 952.6981017589569 and batch: 250, loss is 3.8232848119735716 and perplexity is 45.75425587446908
At time: 953.9646542072296 and batch: 300, loss is 3.8139925384521485 and perplexity is 45.33106406621601
At time: 955.2302975654602 and batch: 350, loss is 3.8338576698303224 and perplexity is 46.240575481938166
At time: 956.4966382980347 and batch: 400, loss is 3.803059096336365 and perplexity is 44.83813909487286
At time: 957.7620096206665 and batch: 450, loss is 3.829134616851807 and perplexity is 46.02269373273023
At time: 959.0257461071014 and batch: 500, loss is 3.8271967554092408 and perplexity is 45.93359448794099
At time: 960.2968645095825 and batch: 550, loss is 3.814469633102417 and perplexity is 45.352696434306196
At time: 961.5744450092316 and batch: 600, loss is 3.7726574420928953 and perplexity is 43.495498156889575
At time: 962.8417255878448 and batch: 650, loss is 3.7913941383361816 and perplexity is 44.318142849073226
At time: 964.1086139678955 and batch: 700, loss is 3.847466983795166 and perplexity is 46.874179671455806
At time: 965.3779542446136 and batch: 750, loss is 3.7928026151657104 and perplexity is 44.380607906370265
At time: 966.6453583240509 and batch: 800, loss is 3.7794296073913576 and perplexity is 43.79105651559784
At time: 967.9103710651398 and batch: 850, loss is 3.779792141914368 and perplexity is 43.806935163488944
At time: 969.2138333320618 and batch: 900, loss is 3.7270849418640135 and perplexity is 41.557788054172164
At time: 970.4847376346588 and batch: 950, loss is 3.845039825439453 and perplexity is 46.76054657314637
At time: 971.7619607448578 and batch: 1000, loss is 3.8002348947525024 and perplexity is 44.71168580027161
At time: 973.0307066440582 and batch: 1050, loss is 3.7424419736862182 and perplexity is 42.200917971571556
At time: 974.2969725131989 and batch: 1100, loss is 3.7611238765716553 and perplexity is 42.9967218427215
At time: 975.5705561637878 and batch: 1150, loss is 3.754915256500244 and perplexity is 42.730598516649046
At time: 976.8444120883942 and batch: 1200, loss is 3.792117033004761 and perplexity is 44.35019178086545
At time: 978.1207296848297 and batch: 1250, loss is 3.7786025619506836 and perplexity is 43.754854294468814
At time: 979.4000351428986 and batch: 1300, loss is 3.758011317253113 and perplexity is 42.8631000562291
At time: 980.6814384460449 and batch: 1350, loss is 3.633000636100769 and perplexity is 37.82614900577792
At time: 981.957882642746 and batch: 1400, loss is 3.6567454147338867 and perplexity is 38.735070910293466
At time: 983.2264564037323 and batch: 1450, loss is 3.5831897258758545 and perplexity is 35.98815029775335
At time: 984.4950737953186 and batch: 1500, loss is 3.5773866748809815 and perplexity is 35.779914013621934
At time: 985.7643206119537 and batch: 1550, loss is 3.6062284231185915 and perplexity is 36.82689509161249
At time: 987.0347459316254 and batch: 1600, loss is 3.6937650632858277 and perplexity is 40.19590252880222
At time: 988.3073167800903 and batch: 1650, loss is 3.651648178100586 and perplexity is 38.538131437806534
At time: 989.5805568695068 and batch: 1700, loss is 3.6285044527053834 and perplexity is 37.65645747070676
At time: 990.8599925041199 and batch: 1750, loss is 3.6318315982818605 and perplexity is 37.78195464451953
At time: 992.1303639411926 and batch: 1800, loss is 3.594884629249573 and perplexity is 36.41149892358875
At time: 993.3990180492401 and batch: 1850, loss is 3.6157461500167845 and perplexity is 37.179076747422506
At time: 994.6666514873505 and batch: 1900, loss is 3.7161981439590455 and perplexity is 41.10781066505418
At time: 995.9343762397766 and batch: 1950, loss is 3.666117939949036 and perplexity is 39.09982299304734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307457928324855 and perplexity of 74.25149620024654
finished 19 epochs...
Completing Train Step...
At time: 999.8573527336121 and batch: 50, loss is 3.8911818265914917 and perplexity is 48.968724880761265
At time: 1001.1300132274628 and batch: 100, loss is 3.8623854875564576 and perplexity is 47.578714533357726
At time: 1002.4067432880402 and batch: 150, loss is 3.826744623184204 and perplexity is 45.912831123907914
At time: 1003.674423456192 and batch: 200, loss is 3.822788677215576 and perplexity is 45.73156122807051
At time: 1004.9431357383728 and batch: 250, loss is 3.820856838226318 and perplexity is 45.64330049526201
At time: 1006.2115874290466 and batch: 300, loss is 3.8115271139144897 and perplexity is 45.219441403714356
At time: 1007.4786069393158 and batch: 350, loss is 3.8314539766311646 and perplexity is 46.12956080119481
At time: 1008.7441136837006 and batch: 400, loss is 3.800560932159424 and perplexity is 44.72626585906214
At time: 1010.0146989822388 and batch: 450, loss is 3.8267150688171387 and perplexity is 45.9114742192952
At time: 1011.2877538204193 and batch: 500, loss is 3.824750747680664 and perplexity is 45.82137785814295
At time: 1012.5571150779724 and batch: 550, loss is 3.8120654010772705 and perplexity is 45.24378900094171
At time: 1013.8269741535187 and batch: 600, loss is 3.7703909635543824 and perplexity is 43.39702817599699
At time: 1015.1043238639832 and batch: 650, loss is 3.7891963481903077 and perplexity is 44.22084782761932
At time: 1016.4089286327362 and batch: 700, loss is 3.845422291755676 and perplexity is 46.77843432765251
At time: 1017.6771564483643 and batch: 750, loss is 3.7908990716934206 and perplexity is 44.29620784497195
At time: 1018.9452993869781 and batch: 800, loss is 3.7776273250579835 and perplexity is 43.712203746900244
At time: 1020.2126944065094 and batch: 850, loss is 3.7779215669631956 and perplexity is 43.725067601461475
At time: 1021.4849219322205 and batch: 900, loss is 3.7252754163742066 and perplexity is 41.48265617441478
At time: 1022.7538945674896 and batch: 950, loss is 3.843263258934021 and perplexity is 46.677547101199906
At time: 1024.0231161117554 and batch: 1000, loss is 3.79853147983551 and perplexity is 44.63558807911281
At time: 1025.2905530929565 and batch: 1050, loss is 3.740903820991516 and perplexity is 42.13605641215395
At time: 1026.5570669174194 and batch: 1100, loss is 3.759703583717346 and perplexity is 42.93569725258261
At time: 1027.825077533722 and batch: 1150, loss is 3.7535902786254884 and perplexity is 42.67401891067989
At time: 1029.0950906276703 and batch: 1200, loss is 3.790892872810364 and perplexity is 44.295933258810734
At time: 1030.366646528244 and batch: 1250, loss is 3.7775672340393065 and perplexity is 43.70957711496776
At time: 1031.6347448825836 and batch: 1300, loss is 3.7571444272994996 and perplexity is 42.82595856652776
At time: 1032.900444984436 and batch: 1350, loss is 3.6322126674652098 and perplexity is 37.79635492669888
At time: 1034.1684119701385 and batch: 1400, loss is 3.656050581932068 and perplexity is 38.708165860782145
At time: 1035.4342892169952 and batch: 1450, loss is 3.5826469039916993 and perplexity is 35.96862044329721
At time: 1036.7040095329285 and batch: 1500, loss is 3.577056565284729 and perplexity is 35.768104669949025
At time: 1037.9698405265808 and batch: 1550, loss is 3.6060614585876465 and perplexity is 36.82074681963332
At time: 1039.2395668029785 and batch: 1600, loss is 3.6936623859405517 and perplexity is 40.19177553211775
At time: 1040.5121717453003 and batch: 1650, loss is 3.6515425872802734 and perplexity is 38.534062379726066
At time: 1041.781949043274 and batch: 1700, loss is 3.628573136329651 and perplexity is 37.659043941506006
At time: 1043.0504655838013 and batch: 1750, loss is 3.6319372701644896 and perplexity is 37.785947345750635
At time: 1044.3198111057281 and batch: 1800, loss is 3.595024085044861 and perplexity is 36.416577072209165
At time: 1045.5855979919434 and batch: 1850, loss is 3.6158461999893188 and perplexity is 37.18279669911737
At time: 1046.856726884842 and batch: 1900, loss is 3.716269164085388 and perplexity is 41.110730250634724
At time: 1048.140733718872 and batch: 1950, loss is 3.666015148162842 and perplexity is 39.095804058962266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.307516408521075 and perplexity of 74.25583856928407
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f98e3f9bb38>
ELAPSED
6464.594836473465


RESULTS SO FAR:
[{'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -76.16006149647069}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.909600321875081, 'seq_len': 35, 'dropout': 0.7290759996057752, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -77.31609076804611}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.43001077421999756, 'seq_len': 35, 'dropout': 0.7678082231043937, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.2714605499234}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.8411519755907202, 'seq_len': 35, 'dropout': 0.7399604006877908, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -75.65843510780176}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.3249180821502161, 'seq_len': 35, 'dropout': 0.0492471584881673, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.63358143003721}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.4296857462830832, 'seq_len': 35, 'dropout': 0.7850632272183664, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.25149620024654}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.7628103641564832, 'seq_len': 35, 'dropout': 0.5417815712203037, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -76.16006149647069}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.909600321875081, 'seq_len': 35, 'dropout': 0.7290759996057752, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -77.31609076804611}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.43001077421999756, 'seq_len': 35, 'dropout': 0.7678082231043937, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.2714605499234}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.8411519755907202, 'seq_len': 35, 'dropout': 0.7399604006877908, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -75.65843510780176}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.3249180821502161, 'seq_len': 35, 'dropout': 0.0492471584881673, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.63358143003721}, {'params': {'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.4296857462830832, 'seq_len': 35, 'dropout': 0.7850632272183664, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'data': 'wikitext'}, 'best_accuracy': -74.25149620024654}]
