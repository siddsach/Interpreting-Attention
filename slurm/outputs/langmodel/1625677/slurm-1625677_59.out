FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'type': 'continuous', 'name': 'dropout'}, {'domain': [0, 1], 'type': 'continuous', 'name': 'rnn_dropout'}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9332482814788818 and batch: 50, loss is 7.73616244316101 and perplexity is 2289.668767700655
At time: 3.1047167778015137 and batch: 100, loss is 6.977318286895752 and perplexity is 1072.0396060557086
At time: 4.2775559425354 and batch: 150, loss is 6.713887767791748 and perplexity is 823.7670369531102
At time: 5.452007055282593 and batch: 200, loss is 6.631562042236328 and perplexity is 758.6663143861151
At time: 6.6255576610565186 and batch: 250, loss is 6.577038507461548 and perplexity is 718.4086140078473
At time: 7.79795503616333 and batch: 300, loss is 6.509877233505249 and perplexity is 671.7439448792719
At time: 8.97373628616333 and batch: 350, loss is 6.472265710830689 and perplexity is 646.9478644660375
At time: 10.149669885635376 and batch: 400, loss is 6.438162784576416 and perplexity is 625.2570121047044
At time: 11.327064037322998 and batch: 450, loss is 6.356730861663818 and perplexity is 576.3590756340459
At time: 12.504870891571045 and batch: 500, loss is 6.3395071220397945 and perplexity is 566.5170188060216
At time: 13.681866884231567 and batch: 550, loss is 6.300793170928955 and perplexity is 545.0040200796391
At time: 14.859348058700562 and batch: 600, loss is 6.342648687362671 and perplexity is 568.2995675577326
At time: 16.039889574050903 and batch: 650, loss is 6.418059883117675 and perplexity is 612.813031141376
At time: 17.216960191726685 and batch: 700, loss is 6.3085026359558105 and perplexity is 549.2219476029802
At time: 18.402934312820435 and batch: 750, loss is 6.2375924682617185 and perplexity is 511.6252729259949
At time: 19.590054988861084 and batch: 800, loss is 6.240720281600952 and perplexity is 513.2280465610296
At time: 20.77895474433899 and batch: 850, loss is 6.290126695632934 and perplexity is 539.2216417842889
At time: 21.97080397605896 and batch: 900, loss is 6.273073825836182 and perplexity is 530.1043244899068
At time: 23.20443105697632 and batch: 950, loss is 6.279807109832763 and perplexity is 533.6857111705234
At time: 24.49846887588501 and batch: 1000, loss is 6.263800373077393 and perplexity is 525.2111504550896
At time: 25.82286524772644 and batch: 1050, loss is 6.161274461746216 and perplexity is 474.03182545260944
At time: 27.142430543899536 and batch: 1100, loss is 6.231523809432983 and perplexity is 508.52979589363224
At time: 28.460917472839355 and batch: 1150, loss is 6.138611669540405 and perplexity is 463.409758167764
At time: 29.779972076416016 and batch: 1200, loss is 6.225775737762451 and perplexity is 505.6151151024398
At time: 31.09755229949951 and batch: 1250, loss is 6.157170133590698 and perplexity is 472.09023048184105
At time: 32.417041301727295 and batch: 1300, loss is 6.173738889694214 and perplexity is 479.97733771528806
At time: 33.73911142349243 and batch: 1350, loss is 6.163395862579346 and perplexity is 475.0385043692678
At time: 35.057621240615845 and batch: 1400, loss is 6.181963233947754 and perplexity is 483.94111396234956
At time: 36.37801766395569 and batch: 1450, loss is 6.176050434112549 and perplexity is 481.0881099563047
At time: 37.69857835769653 and batch: 1500, loss is 6.1511867809295655 and perplexity is 469.2739818512846
At time: 39.0178120136261 and batch: 1550, loss is 6.119920778274536 and perplexity is 454.82866076092034
At time: 40.337554931640625 and batch: 1600, loss is 6.110525197982788 and perplexity is 450.5752942723946
At time: 41.65873169898987 and batch: 1650, loss is 6.110223417282104 and perplexity is 450.439339859619
At time: 42.98298931121826 and batch: 1700, loss is 6.12653190612793 and perplexity is 457.84555272959153
At time: 44.30558943748474 and batch: 1750, loss is 6.137456970214844 and perplexity is 462.8749680528625
At time: 45.630855560302734 and batch: 1800, loss is 6.150529842376709 and perplexity is 468.965798920462
At time: 46.95866250991821 and batch: 1850, loss is 6.094095001220703 and perplexity is 443.23273852619076
At time: 48.28627395629883 and batch: 1900, loss is 6.065352373123169 and perplexity is 430.6744090241806
At time: 49.61413598060608 and batch: 1950, loss is 6.000725212097168 and perplexity is 403.7214710479465
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.50013910337936 and perplexity of 244.72597210637414
finished 1 epochs...
Completing Train Step...
At time: 53.6722297668457 and batch: 50, loss is 5.730586061477661 and perplexity is 308.14981020104676
At time: 54.92182421684265 and batch: 100, loss is 5.609545688629151 and perplexity is 273.02017365560545
At time: 56.17237305641174 and batch: 150, loss is 5.479937534332276 and perplexity is 239.83172565745403
At time: 57.42144513130188 and batch: 200, loss is 5.404526586532593 and perplexity is 222.4109032395901
At time: 58.671042919158936 and batch: 250, loss is 5.3890536022186275 and perplexity is 218.9960300920483
At time: 59.91989827156067 and batch: 300, loss is 5.369298467636108 and perplexity is 214.71218730860906
At time: 61.190834760665894 and batch: 350, loss is 5.3227934074401855 and perplexity is 204.9556076091056
At time: 62.438963413238525 and batch: 400, loss is 5.265983085632325 and perplexity is 193.63657658366145
At time: 63.68875551223755 and batch: 450, loss is 5.196114902496338 and perplexity is 180.56934783082957
At time: 64.93890810012817 and batch: 500, loss is 5.175942983627319 and perplexity is 176.96340921915078
At time: 66.19577693939209 and batch: 550, loss is 5.129310417175293 and perplexity is 168.90060691985428
At time: 67.44690537452698 and batch: 600, loss is 5.1128302001953125 and perplexity is 166.1398992833686
At time: 68.69632291793823 and batch: 650, loss is 5.181065654754638 and perplexity is 177.87226045164647
At time: 69.9455246925354 and batch: 700, loss is 5.154273653030396 and perplexity is 173.16997957742868
At time: 71.19507932662964 and batch: 750, loss is 5.081030693054199 and perplexity is 160.93985005809986
At time: 72.443119764328 and batch: 800, loss is 5.078528251647949 and perplexity is 160.53761101312833
At time: 73.69096207618713 and batch: 850, loss is 5.077421970367432 and perplexity is 160.360109460671
At time: 74.93869495391846 and batch: 900, loss is 5.075173387527466 and perplexity is 159.99993156699682
At time: 76.18663501739502 and batch: 950, loss is 5.107520170211792 and perplexity is 165.26002957142111
At time: 77.43509793281555 and batch: 1000, loss is 5.064781188964844 and perplexity is 158.34579047641714
At time: 78.68269228935242 and batch: 1050, loss is 4.981234483718872 and perplexity is 145.65407830274742
At time: 79.92842292785645 and batch: 1100, loss is 5.04647837638855 and perplexity is 155.47397843910304
At time: 81.17683720588684 and batch: 1150, loss is 4.959092788696289 and perplexity is 142.46449185542477
At time: 82.42964100837708 and batch: 1200, loss is 5.030919151306152 and perplexity is 153.07364589568144
At time: 83.67656779289246 and batch: 1250, loss is 4.991986236572266 and perplexity is 147.2285640279
At time: 84.9244773387909 and batch: 1300, loss is 5.004607152938843 and perplexity is 149.09849874472914
At time: 86.17335867881775 and batch: 1350, loss is 4.914651384353638 and perplexity is 136.27179504092203
At time: 87.4208447933197 and batch: 1400, loss is 4.910923795700073 and perplexity is 135.76477541131865
At time: 88.66932988166809 and batch: 1450, loss is 4.865117826461792 and perplexity is 129.68621817985394
At time: 89.91801309585571 and batch: 1500, loss is 4.829007997512817 and perplexity is 125.08681265811468
At time: 91.16790962219238 and batch: 1550, loss is 4.826509580612183 and perplexity is 124.77468372778186
At time: 92.4156768321991 and batch: 1600, loss is 4.882977695465088 and perplexity is 132.02320405925303
At time: 93.66195130348206 and batch: 1650, loss is 4.858996448516845 and perplexity is 128.89478462740402
At time: 94.9153163433075 and batch: 1700, loss is 4.873315849304199 and perplexity is 130.75375864048445
At time: 96.16881561279297 and batch: 1750, loss is 4.863315763473511 and perplexity is 129.45272589307345
At time: 97.42749619483948 and batch: 1800, loss is 4.815563631057739 and perplexity is 123.41635400055694
At time: 98.67662835121155 and batch: 1850, loss is 4.826808481216431 and perplexity is 124.81198453048148
At time: 99.92594957351685 and batch: 1900, loss is 4.921597414016723 and perplexity is 137.22163797115695
At time: 101.17559003829956 and batch: 1950, loss is 4.838834133148193 and perplexity is 126.32199122321987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.631962549963663 and perplexity of 102.71545063420744
finished 2 epochs...
Completing Train Step...
At time: 105.13568782806396 and batch: 50, loss is 4.8008208847045895 and perplexity is 121.61020451312953
At time: 106.41170954704285 and batch: 100, loss is 4.73694543838501 and perplexity is 114.08518867250021
At time: 107.6696035861969 and batch: 150, loss is 4.674217462539673 and perplexity is 107.14868641549418
At time: 108.91727495193481 and batch: 200, loss is 4.655361270904541 and perplexity is 105.1471997619628
At time: 110.1658124923706 and batch: 250, loss is 4.664533815383911 and perplexity is 106.11610399397638
At time: 111.414071559906 and batch: 300, loss is 4.686536540985108 and perplexity is 108.47682340421773
At time: 112.66166019439697 and batch: 350, loss is 4.691643095016479 and perplexity is 109.03218294399413
At time: 113.9106650352478 and batch: 400, loss is 4.639738569259643 and perplexity is 103.51728144594692
At time: 115.15921401977539 and batch: 450, loss is 4.627794981002808 and perplexity is 102.28826768584058
At time: 116.40712594985962 and batch: 500, loss is 4.629808197021484 and perplexity is 102.49440349320007
At time: 117.65577435493469 and batch: 550, loss is 4.601741933822632 and perplexity is 99.65776175814224
At time: 118.90686202049255 and batch: 600, loss is 4.570155239105224 and perplexity is 96.55909835743759
At time: 120.15482258796692 and batch: 650, loss is 4.63017424583435 and perplexity is 102.5319283154635
At time: 121.40462756156921 and batch: 700, loss is 4.660037984848023 and perplexity is 105.64009480339533
At time: 122.65444540977478 and batch: 750, loss is 4.603214597702026 and perplexity is 99.80463226308484
At time: 123.92948889732361 and batch: 800, loss is 4.597816572189331 and perplexity is 99.26733578656285
At time: 125.17670130729675 and batch: 850, loss is 4.597394037246704 and perplexity is 99.22540072866906
At time: 126.42463207244873 and batch: 900, loss is 4.5776241016387935 and perplexity is 97.2829849289824
At time: 127.67380547523499 and batch: 950, loss is 4.642156209945679 and perplexity is 103.76785180978321
At time: 128.9216821193695 and batch: 1000, loss is 4.607391748428345 and perplexity is 100.22240319384677
At time: 130.16888189315796 and batch: 1050, loss is 4.548086490631103 and perplexity is 94.45150145369863
At time: 131.41610741615295 and batch: 1100, loss is 4.603163013458252 and perplexity is 99.79948404938888
At time: 132.663560628891 and batch: 1150, loss is 4.548906002044678 and perplexity is 94.52893726259997
At time: 133.91119027137756 and batch: 1200, loss is 4.616278352737427 and perplexity is 101.1170091511389
At time: 135.1587131023407 and batch: 1250, loss is 4.602317390441894 and perplexity is 99.7151269808223
At time: 136.41900753974915 and batch: 1300, loss is 4.595454988479614 and perplexity is 99.03318425650518
At time: 137.66342401504517 and batch: 1350, loss is 4.477028875350952 and perplexity is 87.97290552873966
At time: 138.91152429580688 and batch: 1400, loss is 4.484748115539551 and perplexity is 88.65461727990386
At time: 140.16156244277954 and batch: 1450, loss is 4.442117357254029 and perplexity is 84.95463067731662
At time: 141.4109230041504 and batch: 1500, loss is 4.428645553588868 and perplexity is 83.8178132562516
At time: 142.66441822052002 and batch: 1550, loss is 4.436962308883667 and perplexity is 84.51781232411166
At time: 143.9166841506958 and batch: 1600, loss is 4.506412620544434 and perplexity is 90.59623179745734
At time: 145.16694903373718 and batch: 1650, loss is 4.478442983627319 and perplexity is 88.09739674382726
At time: 146.41690754890442 and batch: 1700, loss is 4.492466087341309 and perplexity is 89.34149837098967
At time: 147.66699051856995 and batch: 1750, loss is 4.481460514068604 and perplexity is 88.36363480901386
At time: 148.9159083366394 and batch: 1800, loss is 4.439126062393188 and perplexity is 84.70088602890397
At time: 150.1652204990387 and batch: 1850, loss is 4.478853597640991 and perplexity is 88.1335781972958
At time: 151.41665172576904 and batch: 1900, loss is 4.580528688430786 and perplexity is 97.56596256970361
At time: 152.66577816009521 and batch: 1950, loss is 4.501947765350342 and perplexity is 90.19263441376239
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479915743095931 and perplexity of 88.2272386084904
finished 3 epochs...
Completing Train Step...
At time: 156.59748339653015 and batch: 50, loss is 4.476886167526245 and perplexity is 87.96035200252297
At time: 157.82647371292114 and batch: 100, loss is 4.417847557067871 and perplexity is 82.91761770118671
At time: 159.03292417526245 and batch: 150, loss is 4.365460224151612 and perplexity is 78.6856046256358
At time: 160.24128651618958 and batch: 200, loss is 4.362954006195069 and perplexity is 78.48864826128245
At time: 161.4599540233612 and batch: 250, loss is 4.3653055191040036 and perplexity is 78.6734325069945
At time: 162.6874930858612 and batch: 300, loss is 4.392813835144043 and perplexity is 80.8676473671181
At time: 163.9064211845398 and batch: 350, loss is 4.399025621414185 and perplexity is 81.37154333547217
At time: 165.12719249725342 and batch: 400, loss is 4.347604703903198 and perplexity is 77.29310115222074
At time: 166.3526382446289 and batch: 450, loss is 4.35978271484375 and perplexity is 78.24013215664037
At time: 167.58072328567505 and batch: 500, loss is 4.364704914093018 and perplexity is 78.6261950361502
At time: 168.806631565094 and batch: 550, loss is 4.3352767276763915 and perplexity is 76.34608304097578
At time: 170.0444769859314 and batch: 600, loss is 4.310253610610962 and perplexity is 74.45937023237273
At time: 171.29020953178406 and batch: 650, loss is 4.368291912078857 and perplexity is 78.90873346883225
At time: 172.53662395477295 and batch: 700, loss is 4.404388952255249 and perplexity is 81.8091382776904
At time: 173.78291273117065 and batch: 750, loss is 4.356454229354858 and perplexity is 77.98014393564856
At time: 175.0297827720642 and batch: 800, loss is 4.349397811889649 and perplexity is 77.4318203612872
At time: 176.2766149044037 and batch: 850, loss is 4.345968952178955 and perplexity is 77.16677217832536
At time: 177.52228355407715 and batch: 900, loss is 4.324331388473511 and perplexity is 75.51500577351511
At time: 178.76908087730408 and batch: 950, loss is 4.401910133361817 and perplexity is 81.60659937241385
At time: 180.01509809494019 and batch: 1000, loss is 4.365035772323608 and perplexity is 78.65221346388606
At time: 181.26127696037292 and batch: 1050, loss is 4.316965255737305 and perplexity is 74.9607959150485
At time: 182.50695133209229 and batch: 1100, loss is 4.364895639419555 and perplexity is 78.64119247302291
At time: 183.75446796417236 and batch: 1150, loss is 4.3202149868011475 and perplexity is 75.2047945924106
At time: 185.00135707855225 and batch: 1200, loss is 4.381845951080322 and perplexity is 79.98554661829904
At time: 186.28775334358215 and batch: 1250, loss is 4.3816063117980955 and perplexity is 79.96638123579989
At time: 187.53474235534668 and batch: 1300, loss is 4.368732423782348 and perplexity is 78.94350134669928
At time: 188.78091669082642 and batch: 1350, loss is 4.245397019386291 and perplexity is 69.78346003131809
At time: 190.02828073501587 and batch: 1400, loss is 4.261061334609986 and perplexity is 70.88517643584768
At time: 191.27592873573303 and batch: 1450, loss is 4.215191597938538 and perplexity is 67.70713717616177
At time: 192.5219805240631 and batch: 1500, loss is 4.210632796287537 and perplexity is 67.39917626712285
At time: 193.76772737503052 and batch: 1550, loss is 4.222277240753174 and perplexity is 68.18858945129276
At time: 195.01460528373718 and batch: 1600, loss is 4.297640480995178 and perplexity is 73.52610262998297
At time: 196.26861548423767 and batch: 1650, loss is 4.262125563621521 and perplexity is 70.96065465302897
At time: 197.51571416854858 and batch: 1700, loss is 4.274304056167603 and perplexity is 71.83013217313213
At time: 198.7623324394226 and batch: 1750, loss is 4.262401366233826 and perplexity is 70.9802284860862
At time: 200.00714135169983 and batch: 1800, loss is 4.222276000976563 and perplexity is 68.18850491272681
At time: 201.25199055671692 and batch: 1850, loss is 4.271195878982544 and perplexity is 71.60721800294094
At time: 202.49872589111328 and batch: 1900, loss is 4.370375251770019 and perplexity is 79.0732985281853
At time: 203.74543070793152 and batch: 1950, loss is 4.295410928726196 and perplexity is 73.36235495087077
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.42820675872093 and perplexity of 83.781042497953
finished 4 epochs...
Completing Train Step...
At time: 207.61630868911743 and batch: 50, loss is 4.274948143959046 and perplexity is 71.87641198685414
At time: 208.83149099349976 and batch: 100, loss is 4.2232667922973635 and perplexity is 68.2560989718467
At time: 210.02893805503845 and batch: 150, loss is 4.173396883010864 and perplexity is 64.93565672011934
At time: 211.2296051979065 and batch: 200, loss is 4.174994874000549 and perplexity is 65.03950626768908
At time: 212.45429968833923 and batch: 250, loss is 4.173544907569886 and perplexity is 64.94526950351658
At time: 213.6833028793335 and batch: 300, loss is 4.199952492713928 and perplexity is 66.6831630295717
At time: 214.90154385566711 and batch: 350, loss is 4.2102879667282105 and perplexity is 67.3759390455424
At time: 216.1419334411621 and batch: 400, loss is 4.159939098358154 and perplexity is 64.06762065783327
At time: 217.36492800712585 and batch: 450, loss is 4.183067755699158 and perplexity is 65.56668758061747
At time: 218.5915834903717 and batch: 500, loss is 4.1885830545425415 and perplexity is 65.92930651349204
At time: 219.81843161582947 and batch: 550, loss is 4.157249751091004 and perplexity is 63.89555205712329
At time: 221.0453336238861 and batch: 600, loss is 4.13883695602417 and perplexity is 62.729821465374485
At time: 222.28621792793274 and batch: 650, loss is 4.1923759126663205 and perplexity is 66.17984184142848
At time: 223.53121376037598 and batch: 700, loss is 4.23350724697113 and perplexity is 68.9586636106074
At time: 224.77934002876282 and batch: 750, loss is 4.185802435874939 and perplexity is 65.74623689441405
At time: 226.02956342697144 and batch: 800, loss is 4.182871217727661 and perplexity is 65.5538025030876
At time: 227.2774214744568 and batch: 850, loss is 4.178838887214661 and perplexity is 65.29000013163238
At time: 228.52480244636536 and batch: 900, loss is 4.151734199523926 and perplexity is 63.54410295363341
At time: 229.77248525619507 and batch: 950, loss is 4.239121279716492 and perplexity is 69.34688854027593
At time: 231.02798175811768 and batch: 1000, loss is 4.200140476226807 and perplexity is 66.69569954309986
At time: 232.2759599685669 and batch: 1050, loss is 4.160328130722046 and perplexity is 64.09254988457033
At time: 233.52319979667664 and batch: 1100, loss is 4.2015171813964844 and perplexity is 66.7875830912216
At time: 234.77117657661438 and batch: 1150, loss is 4.160835366249085 and perplexity is 64.12506814940267
At time: 236.0194115638733 and batch: 1200, loss is 4.223260526657104 and perplexity is 68.25567130502486
At time: 237.26781606674194 and batch: 1250, loss is 4.224178438186645 and perplexity is 68.31835273627544
At time: 238.5169219970703 and batch: 1300, loss is 4.208594455718994 and perplexity is 67.2619337129025
At time: 239.77198147773743 and batch: 1350, loss is 4.08603123664856 and perplexity is 59.50326807351722
At time: 241.01968908309937 and batch: 1400, loss is 4.109705014228821 and perplexity is 60.928741806566606
At time: 242.26601910591125 and batch: 1450, loss is 4.059068026542664 and perplexity is 57.92030572951145
At time: 243.51398968696594 and batch: 1500, loss is 4.05743754863739 and perplexity is 57.825944898282515
At time: 244.76071763038635 and batch: 1550, loss is 4.069879655838013 and perplexity is 58.549916027315675
At time: 246.0079381465912 and batch: 1600, loss is 4.14973940372467 and perplexity is 63.41747178764402
At time: 247.25554871559143 and batch: 1650, loss is 4.108642482757569 and perplexity is 60.86403748217129
At time: 248.50558471679688 and batch: 1700, loss is 4.125743474960327 and perplexity is 61.913823520505105
At time: 249.75291228294373 and batch: 1750, loss is 4.1114136552810665 and perplexity is 61.03293614609273
At time: 251.00367140769958 and batch: 1800, loss is 4.068374147415161 and perplexity is 58.46183495561371
At time: 252.2543432712555 and batch: 1850, loss is 4.119330892562866 and perplexity is 61.518066294715055
At time: 253.50227284431458 and batch: 1900, loss is 4.218752355575561 and perplexity is 67.94865562108218
At time: 254.7497365474701 and batch: 1950, loss is 4.14740864276886 and perplexity is 63.26983294274949
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.417014614371366 and perplexity of 82.84858083297995
finished 5 epochs...
Completing Train Step...
At time: 258.6650855541229 and batch: 50, loss is 4.130218291282654 and perplexity is 62.19149731484152
At time: 259.8655126094818 and batch: 100, loss is 4.0842108106613155 and perplexity is 59.39504531363956
At time: 261.0744700431824 and batch: 150, loss is 4.030960078239441 and perplexity is 56.314952061301184
At time: 262.2925262451172 and batch: 200, loss is 4.03791449546814 and perplexity is 56.707954702391
At time: 263.51147079467773 and batch: 250, loss is 4.03700207233429 and perplexity is 56.65623665060866
At time: 264.74790024757385 and batch: 300, loss is 4.05891740322113 and perplexity is 57.91158223767538
At time: 265.9950556755066 and batch: 350, loss is 4.071827101707458 and perplexity is 58.664049918155115
At time: 267.2411153316498 and batch: 400, loss is 4.023880877494812 and perplexity is 55.917695001019716
At time: 268.4879469871521 and batch: 450, loss is 4.052854442596436 and perplexity is 57.56152884713104
At time: 269.73394656181335 and batch: 500, loss is 4.059527187347412 and perplexity is 57.94690657026586
At time: 270.98492884635925 and batch: 550, loss is 4.026372289657592 and perplexity is 56.05718271500191
At time: 272.23161482810974 and batch: 600, loss is 4.012535891532898 and perplexity is 55.28689451332776
At time: 273.47915387153625 and batch: 650, loss is 4.061013712882995 and perplexity is 58.03311018265204
At time: 274.72657585144043 and batch: 700, loss is 4.099754395484925 and perplexity is 60.32546957004881
At time: 275.9734835624695 and batch: 750, loss is 4.05966721534729 and perplexity is 57.955021327825385
At time: 277.2277777194977 and batch: 800, loss is 4.054716358184814 and perplexity is 57.668803392065136
At time: 278.49697065353394 and batch: 850, loss is 4.054597754478454 and perplexity is 57.66196406383435
At time: 279.75050616264343 and batch: 900, loss is 4.023774685859681 and perplexity is 55.91175732482613
At time: 280.9979465007782 and batch: 950, loss is 4.115449213981629 and perplexity is 61.27973579487023
At time: 282.24573588371277 and batch: 1000, loss is 4.078639698028565 and perplexity is 59.065068847862754
At time: 283.4925231933594 and batch: 1050, loss is 4.04284321308136 and perplexity is 56.98814211265585
At time: 284.7400224208832 and batch: 1100, loss is 4.076753950119018 and perplexity is 58.953791970800296
At time: 285.9903326034546 and batch: 1150, loss is 4.043929591178894 and perplexity is 57.050086423445116
At time: 287.2372536659241 and batch: 1200, loss is 4.103623876571655 and perplexity is 60.559350039803356
At time: 288.48534202575684 and batch: 1250, loss is 4.107764129638672 and perplexity is 60.810600836577876
At time: 289.73076701164246 and batch: 1300, loss is 4.090648341178894 and perplexity is 59.778636094394315
At time: 290.9779803752899 and batch: 1350, loss is 3.9646008253097533 and perplexity is 52.69922899212044
At time: 292.22556018829346 and batch: 1400, loss is 3.996152172088623 and perplexity is 54.388469413714134
At time: 293.4708163738251 and batch: 1450, loss is 3.941963267326355 and perplexity is 51.51964891971505
At time: 294.7179865837097 and batch: 1500, loss is 3.9440194892883302 and perplexity is 51.62569374177951
At time: 295.9654452800751 and batch: 1550, loss is 3.9528229904174803 and perplexity is 52.08218701621287
At time: 297.2123610973358 and batch: 1600, loss is 4.036461138725281 and perplexity is 56.62559767561716
At time: 298.4586498737335 and batch: 1650, loss is 3.996459708213806 and perplexity is 54.40519840510501
At time: 299.7059977054596 and batch: 1700, loss is 4.013404045104981 and perplexity is 55.334912868926416
At time: 300.9525785446167 and batch: 1750, loss is 3.996226725578308 and perplexity is 54.39252441506294
At time: 302.19981360435486 and batch: 1800, loss is 3.951661219596863 and perplexity is 52.02171458541797
At time: 303.44763684272766 and batch: 1850, loss is 4.003542256355286 and perplexity is 54.79189361922615
At time: 304.69339084625244 and batch: 1900, loss is 4.102672157287597 and perplexity is 60.50174195625079
At time: 305.9395799636841 and batch: 1950, loss is 4.032443609237671 and perplexity is 56.3985590397861
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419966728742732 and perplexity of 83.09352068644795
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 309.8679840564728 and batch: 50, loss is 4.059349327087403 and perplexity is 57.93660103489628
At time: 311.091570854187 and batch: 100, loss is 4.045275721549988 and perplexity is 57.12693498994337
At time: 312.30863523483276 and batch: 150, loss is 3.996230788230896 and perplexity is 54.392745393441885
At time: 313.5269865989685 and batch: 200, loss is 4.0028210496902465 and perplexity is 54.75239158663465
At time: 314.7597303390503 and batch: 250, loss is 3.9981198501586914 and perplexity is 54.495593770804916
At time: 316.00686287879944 and batch: 300, loss is 4.0107007455825805 and perplexity is 55.1855280323477
At time: 317.2524015903473 and batch: 350, loss is 4.033145327568054 and perplexity is 56.438148831288174
At time: 318.49862003326416 and batch: 400, loss is 3.9806837272644042 and perplexity is 53.5536377949051
At time: 319.7495856285095 and batch: 450, loss is 4.006486883163452 and perplexity is 54.95347307689661
At time: 320.99453926086426 and batch: 500, loss is 4.00973237991333 and perplexity is 55.13211412783139
At time: 322.2396969795227 and batch: 550, loss is 3.9618276357650757 and perplexity is 52.55328649789833
At time: 323.4852135181427 and batch: 600, loss is 3.9363511419296264 and perplexity is 51.23132400412804
At time: 324.7314021587372 and batch: 650, loss is 3.9740425062179567 and perplexity is 53.19915465181941
At time: 325.9764914512634 and batch: 700, loss is 4.013369932174682 and perplexity is 55.33302526509669
At time: 327.2213113307953 and batch: 750, loss is 3.96401424407959 and perplexity is 52.66832567808766
At time: 328.46624660491943 and batch: 800, loss is 3.961854739189148 and perplexity is 52.55471089121155
At time: 329.71160554885864 and batch: 850, loss is 3.9528374576568606 and perplexity is 52.08294050713033
At time: 330.96163296699524 and batch: 900, loss is 3.9127766132354735 and perplexity is 50.037694592051835
At time: 332.20960807800293 and batch: 950, loss is 4.004959836006164 and perplexity is 54.86962057171071
At time: 333.4592447280884 and batch: 1000, loss is 3.960125002861023 and perplexity is 52.463883674783006
At time: 334.7045147418976 and batch: 1050, loss is 3.916185555458069 and perplexity is 50.208561273722296
At time: 335.953590631485 and batch: 1100, loss is 3.9332812595367432 and perplexity is 51.07429102431913
At time: 337.2031807899475 and batch: 1150, loss is 3.9081433629989624 and perplexity is 49.80639368302252
At time: 338.44760823249817 and batch: 1200, loss is 3.9518693399429323 and perplexity is 52.03254248937508
At time: 339.69278025627136 and batch: 1250, loss is 3.94955828666687 and perplexity is 51.91243135666566
At time: 340.937885761261 and batch: 1300, loss is 3.9307691049575806 and perplexity is 50.946145538272674
At time: 342.18225383758545 and batch: 1350, loss is 3.8016148233413696 and perplexity is 44.77342732341293
At time: 343.42761754989624 and batch: 1400, loss is 3.8297617721557615 and perplexity is 46.05156616200923
At time: 344.6731879711151 and batch: 1450, loss is 3.761657786369324 and perplexity is 43.01968434318747
At time: 345.9239692687988 and batch: 1500, loss is 3.7620556259155276 and perplexity is 43.036802679834246
At time: 347.1699204444885 and batch: 1550, loss is 3.765266819000244 and perplexity is 43.17522429330449
At time: 348.41647124290466 and batch: 1600, loss is 3.837595167160034 and perplexity is 46.413722876732784
At time: 349.666757106781 and batch: 1650, loss is 3.797461485862732 and perplexity is 44.58785381114046
At time: 350.91149163246155 and batch: 1700, loss is 3.791888313293457 and perplexity is 44.34004917775591
At time: 352.1568169593811 and batch: 1750, loss is 3.7636376142501833 and perplexity is 43.10494028186982
At time: 353.40228509902954 and batch: 1800, loss is 3.714668536186218 and perplexity is 41.044979903797824
At time: 354.6478052139282 and batch: 1850, loss is 3.7482148694992063 and perplexity is 42.445244030133686
At time: 355.89278173446655 and batch: 1900, loss is 3.8424592638015747 and perplexity is 46.64003366286766
At time: 357.13673853874207 and batch: 1950, loss is 3.770314922332764 and perplexity is 43.3937283384233
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365039630268895 and perplexity of 78.6525169004076
finished 7 epochs...
Completing Train Step...
At time: 361.06299662590027 and batch: 50, loss is 3.977082509994507 and perplexity is 53.36112635542545
At time: 362.27087020874023 and batch: 100, loss is 3.9433367824554444 and perplexity is 51.590460556246256
At time: 363.49905276298523 and batch: 150, loss is 3.887033181190491 and perplexity is 48.76599183003525
At time: 364.7434284687042 and batch: 200, loss is 3.892365002632141 and perplexity is 49.02669779209813
At time: 365.98433542251587 and batch: 250, loss is 3.886208662986755 and perplexity is 48.72579995379193
At time: 367.23211765289307 and batch: 300, loss is 3.901696982383728 and perplexity is 49.4863553649616
At time: 368.4814577102661 and batch: 350, loss is 3.922718982696533 and perplexity is 50.53766918617008
At time: 369.7300136089325 and batch: 400, loss is 3.8716863775253296 and perplexity is 48.023303252489995
At time: 371.00656819343567 and batch: 450, loss is 3.90437949180603 and perplexity is 49.6192811871792
At time: 372.25617837905884 and batch: 500, loss is 3.911475377082825 and perplexity is 49.97262607878564
At time: 373.50599193573 and batch: 550, loss is 3.8660285902023315 and perplexity is 47.75236479496524
At time: 374.7561876773834 and batch: 600, loss is 3.845663318634033 and perplexity is 46.78971054653425
At time: 376.0060770511627 and batch: 650, loss is 3.882394790649414 and perplexity is 48.54031989668965
At time: 377.2549698352814 and batch: 700, loss is 3.9250828075408934 and perplexity is 50.65727268934249
At time: 378.5052351951599 and batch: 750, loss is 3.8800949382781984 and perplexity is 48.42881260118449
At time: 379.7544252872467 and batch: 800, loss is 3.880512499809265 and perplexity is 48.449038832876234
At time: 381.0043511390686 and batch: 850, loss is 3.873099932670593 and perplexity is 48.09123484110701
At time: 382.25370144844055 and batch: 900, loss is 3.8320104360580443 and perplexity is 46.155237173427594
At time: 383.5026979446411 and batch: 950, loss is 3.9272668075561525 and perplexity is 50.768029075619324
At time: 384.7516176700592 and batch: 1000, loss is 3.885765790939331 and perplexity is 48.70422543673192
At time: 386.00176525115967 and batch: 1050, loss is 3.845957055091858 and perplexity is 46.803456409104506
At time: 387.2518193721771 and batch: 1100, loss is 3.8644533729553223 and perplexity is 47.67720365945472
At time: 388.5011377334595 and batch: 1150, loss is 3.844333462715149 and perplexity is 46.72752832888037
At time: 389.7509846687317 and batch: 1200, loss is 3.8897866201400757 and perplexity is 48.900451039017405
At time: 391.0061557292938 and batch: 1250, loss is 3.889807538986206 and perplexity is 48.901473990727844
At time: 392.26065015792847 and batch: 1300, loss is 3.8732574462890623 and perplexity is 48.09881046213957
At time: 393.51307678222656 and batch: 1350, loss is 3.745761947631836 and perplexity is 42.34125675136076
At time: 394.76219487190247 and batch: 1400, loss is 3.779601426124573 and perplexity is 43.79858128588425
At time: 396.01149892807007 and batch: 1450, loss is 3.7119386529922487 and perplexity is 40.933084702865244
At time: 397.2603781223297 and batch: 1500, loss is 3.713628158569336 and perplexity is 41.00229983096645
At time: 398.5101430416107 and batch: 1550, loss is 3.7216655302047728 and perplexity is 41.3331784686944
At time: 399.7661383152008 and batch: 1600, loss is 3.7987095642089845 and perplexity is 44.64353768768006
At time: 401.0136766433716 and batch: 1650, loss is 3.7609407091140747 and perplexity is 42.98884696373007
At time: 402.2637002468109 and batch: 1700, loss is 3.75990816116333 and perplexity is 42.944481826400285
At time: 403.51328897476196 and batch: 1750, loss is 3.733995294570923 and perplexity is 41.84596157090522
At time: 404.7625708580017 and batch: 1800, loss is 3.689803972244263 and perplexity is 40.036997825157854
At time: 406.01719546318054 and batch: 1850, loss is 3.727558674812317 and perplexity is 41.57748001162829
At time: 407.2655267715454 and batch: 1900, loss is 3.8251171779632567 and perplexity is 45.83817127520067
At time: 408.5137209892273 and batch: 1950, loss is 3.755729942321777 and perplexity is 42.76542471368443
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368634175145349 and perplexity of 78.93574563629224
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 412.4217178821564 and batch: 50, loss is 3.9503212118148805 and perplexity is 51.95205176782428
At time: 413.66745114326477 and batch: 100, loss is 3.949654803276062 and perplexity is 51.91744201031687
At time: 414.90874457359314 and batch: 150, loss is 3.9087504148483276 and perplexity is 49.836637925400865
At time: 416.1576454639435 and batch: 200, loss is 3.922316298484802 and perplexity is 50.5173225615983
At time: 417.40692353248596 and batch: 250, loss is 3.91996768951416 and perplexity is 50.398816341516095
At time: 418.66301107406616 and batch: 300, loss is 3.9274646186828615 and perplexity is 50.778072549974304
At time: 419.9137923717499 and batch: 350, loss is 3.952059168815613 and perplexity is 52.04242070581422
At time: 421.1671278476715 and batch: 400, loss is 3.905165977478027 and perplexity is 49.658321391155845
At time: 422.41530680656433 and batch: 450, loss is 3.932419567108154 and perplexity is 51.03029965068672
At time: 423.6641218662262 and batch: 500, loss is 3.9395352935791017 and perplexity is 51.39471229746542
At time: 424.9129877090454 and batch: 550, loss is 3.9022475147247313 and perplexity is 49.51360670471204
At time: 426.164785861969 and batch: 600, loss is 3.870025329589844 and perplexity is 47.943600457174576
At time: 427.41776061058044 and batch: 650, loss is 3.899112696647644 and perplexity is 49.3586335885265
At time: 428.6671459674835 and batch: 700, loss is 3.934154582023621 and perplexity is 51.11891483382395
At time: 429.91680812835693 and batch: 750, loss is 3.8833992958068846 and perplexity is 48.58910339590742
At time: 431.165584564209 and batch: 800, loss is 3.8797456789016724 and perplexity is 48.41190133767009
At time: 432.42405366897583 and batch: 850, loss is 3.8712536478042603 and perplexity is 48.00252663752232
At time: 433.7182078361511 and batch: 900, loss is 3.8265342903137207 and perplexity is 45.90317516186432
At time: 434.9677846431732 and batch: 950, loss is 3.9236907529830933 and perplexity is 50.58680406147647
At time: 436.21888422966003 and batch: 1000, loss is 3.8813435935974123 and perplexity is 48.489321265012855
At time: 437.4689736366272 and batch: 1050, loss is 3.834842104911804 and perplexity is 46.286118740143
At time: 438.71884775161743 and batch: 1100, loss is 3.8528890228271484 and perplexity is 47.12902356566179
At time: 439.96885347366333 and batch: 1150, loss is 3.833537902832031 and perplexity is 46.22579163573608
At time: 441.2188467979431 and batch: 1200, loss is 3.8726404809951784 and perplexity is 48.069144317839076
At time: 442.47342133522034 and batch: 1250, loss is 3.860971837043762 and perplexity is 47.511502377606575
At time: 443.722941160202 and batch: 1300, loss is 3.850483250617981 and perplexity is 47.01577814648304
At time: 444.97111201286316 and batch: 1350, loss is 3.7165355396270754 and perplexity is 41.121682602328946
At time: 446.22088408470154 and batch: 1400, loss is 3.7459211349487305 and perplexity is 42.347997478921876
At time: 447.4770610332489 and batch: 1450, loss is 3.6732640647888184 and perplexity is 39.38023594904215
At time: 448.73074555397034 and batch: 1500, loss is 3.6735403680801393 and perplexity is 39.39111834119902
At time: 449.98169469833374 and batch: 1550, loss is 3.6850581312179567 and perplexity is 39.84743876268343
At time: 451.23993134498596 and batch: 1600, loss is 3.756862454414368 and perplexity is 42.813884509790526
At time: 452.49489307403564 and batch: 1650, loss is 3.719594020843506 and perplexity is 41.24764502481684
At time: 453.74398612976074 and batch: 1700, loss is 3.702942976951599 and perplexity is 40.566515175853475
At time: 454.9936661720276 and batch: 1750, loss is 3.6767189788818357 and perplexity is 39.516526581854244
At time: 456.24359154701233 and batch: 1800, loss is 3.6328658866882324 and perplexity is 37.821052297817786
At time: 457.49261569976807 and batch: 1850, loss is 3.6694359159469605 and perplexity is 39.2297707297813
At time: 458.74899983406067 and batch: 1900, loss is 3.764592156410217 and perplexity is 43.1461054084734
At time: 459.9985921382904 and batch: 1950, loss is 3.700021514892578 and perplexity is 40.44817458883717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344471350381541 and perplexity of 77.05129357367645
finished 9 epochs...
Completing Train Step...
At time: 463.966570854187 and batch: 50, loss is 3.936922702789307 and perplexity is 51.26061419348393
At time: 465.21522855758667 and batch: 100, loss is 3.917004580497742 and perplexity is 50.24970018721188
At time: 466.4459969997406 and batch: 150, loss is 3.868629021644592 and perplexity is 47.87670314242731
At time: 467.6820709705353 and batch: 200, loss is 3.8772290086746217 and perplexity is 48.290217729919924
At time: 468.9372718334198 and batch: 250, loss is 3.8710909366607664 and perplexity is 47.99471672691951
At time: 470.19139790534973 and batch: 300, loss is 3.8776085329055787 and perplexity is 48.30854851593532
At time: 471.4455690383911 and batch: 350, loss is 3.9020779752731323 and perplexity is 49.505212906544706
At time: 472.6972212791443 and batch: 400, loss is 3.8547083520889283 and perplexity is 47.214844822203496
At time: 473.94880747795105 and batch: 450, loss is 3.8855133199691774 and perplexity is 48.6919305857971
At time: 475.19900822639465 and batch: 500, loss is 3.8928999948501586 and perplexity is 49.05293371127254
At time: 476.44874477386475 and batch: 550, loss is 3.8572802686691285 and perplexity is 47.33643375570691
At time: 477.69947147369385 and batch: 600, loss is 3.8291705369949343 and perplexity is 46.024346904167125
At time: 478.95062589645386 and batch: 650, loss is 3.8588130474090576 and perplexity is 47.409045669774535
At time: 480.2014091014862 and batch: 700, loss is 3.895644087791443 and perplexity is 49.18772437489157
At time: 481.4517984390259 and batch: 750, loss is 3.847216968536377 and perplexity is 46.86246187616957
At time: 482.7030084133148 and batch: 800, loss is 3.8442836666107176 and perplexity is 46.725201537932925
At time: 483.95417833328247 and batch: 850, loss is 3.837020978927612 and perplexity is 46.387080312889374
At time: 485.2059600353241 and batch: 900, loss is 3.7932420444488524 and perplexity is 44.40011433062109
At time: 486.45496129989624 and batch: 950, loss is 3.8921403646469117 and perplexity is 49.01568577038916
At time: 487.70425510406494 and batch: 1000, loss is 3.8508112716674803 and perplexity is 47.031202841047616
At time: 488.95509672164917 and batch: 1050, loss is 3.8072022724151613 and perplexity is 45.024296775916916
At time: 490.20506954193115 and batch: 1100, loss is 3.826093873977661 and perplexity is 45.88296310483278
At time: 491.4575412273407 and batch: 1150, loss is 3.8083976984024046 and perplexity is 45.078152173997935
At time: 492.70838689804077 and batch: 1200, loss is 3.8487725591659547 and perplexity is 46.93541741250558
At time: 493.9590849876404 and batch: 1250, loss is 3.8409838008880617 and perplexity is 46.571268765416114
At time: 495.2096469402313 and batch: 1300, loss is 3.8315487003326414 and perplexity is 46.133930570898514
At time: 496.46019554138184 and batch: 1350, loss is 3.6997617435455323 and perplexity is 40.43766867666525
At time: 497.7118875980377 and batch: 1400, loss is 3.731280493736267 and perplexity is 41.73251218542691
At time: 498.9635787010193 and batch: 1450, loss is 3.660677933692932 and perplexity is 38.887697217257696
At time: 500.2141282558441 and batch: 1500, loss is 3.6626061534881593 and perplexity is 38.96275358415386
At time: 501.4652373790741 and batch: 1550, loss is 3.6761739540100096 and perplexity is 39.494994960186624
At time: 502.7172453403473 and batch: 1600, loss is 3.7514052963256836 and perplexity is 42.580878726580764
At time: 503.9688901901245 and batch: 1650, loss is 3.715200204849243 and perplexity is 41.06680803553979
At time: 505.21934700012207 and batch: 1700, loss is 3.701443920135498 and perplexity is 40.50574922196162
At time: 506.47122716903687 and batch: 1750, loss is 3.6766665601730346 and perplexity is 39.514455230843765
At time: 507.72080540657043 and batch: 1800, loss is 3.6343695402145384 and perplexity is 37.877964834118806
At time: 508.97089552879333 and batch: 1850, loss is 3.6727346181869507 and perplexity is 39.35939173537414
At time: 510.2231743335724 and batch: 1900, loss is 3.7688965940475465 and perplexity is 43.332225412100115
At time: 511.4739956855774 and batch: 1950, loss is 3.7033954000473024 and perplexity is 40.584872556569614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344225506449854 and perplexity of 77.03235330899271
finished 10 epochs...
Completing Train Step...
At time: 515.4142277240753 and batch: 50, loss is 3.9182775974273683 and perplexity is 50.313709640173165
At time: 516.661819934845 and batch: 100, loss is 3.895882110595703 and perplexity is 49.19943356845472
At time: 517.8840115070343 and batch: 150, loss is 3.846969256401062 and perplexity is 46.85085491332423
At time: 519.1187553405762 and batch: 200, loss is 3.8549300813674927 and perplexity is 47.22531489640156
At time: 520.3618972301483 and batch: 250, loss is 3.848020620346069 and perplexity is 46.90013811572425
At time: 521.6094975471497 and batch: 300, loss is 3.8544539070129393 and perplexity is 47.202832765694026
At time: 522.8587009906769 and batch: 350, loss is 3.878359832763672 and perplexity is 48.34485635891084
At time: 524.1084024906158 and batch: 400, loss is 3.83054591178894 and perplexity is 46.087691181885695
At time: 525.3589613437653 and batch: 450, loss is 3.8624728870391847 and perplexity is 47.582873070121096
At time: 526.6090097427368 and batch: 500, loss is 3.8700896072387696 and perplexity is 47.9466822581374
At time: 527.881551027298 and batch: 550, loss is 3.8356187629699705 and perplexity is 46.32208119069958
At time: 529.1297047138214 and batch: 600, loss is 3.8088075923919678 and perplexity is 45.096633225011786
At time: 530.3834731578827 and batch: 650, loss is 3.838082971572876 and perplexity is 46.43636921861216
At time: 531.6291434764862 and batch: 700, loss is 3.8758211660385133 and perplexity is 48.222280536152844
At time: 532.8776717185974 and batch: 750, loss is 3.8281974029541015 and perplexity is 45.979580830715314
At time: 534.1256217956543 and batch: 800, loss is 3.825252847671509 and perplexity is 45.844390548398344
At time: 535.3738701343536 and batch: 850, loss is 3.8186151933670045 and perplexity is 45.541099017849554
At time: 536.62202501297 and batch: 900, loss is 3.7754207372665407 and perplexity is 43.61585527155361
At time: 537.87158203125 and batch: 950, loss is 3.8749040508270265 and perplexity is 48.17807542282989
At time: 539.1196012496948 and batch: 1000, loss is 3.833544135093689 and perplexity is 46.226079727862626
At time: 540.3677487373352 and batch: 1050, loss is 3.791485319137573 and perplexity is 44.32218399708914
At time: 541.6167705059052 and batch: 1100, loss is 3.8105793094635008 and perplexity is 45.17660252052972
At time: 542.8666920661926 and batch: 1150, loss is 3.7938278818130495 and perplexity is 44.42613319723857
At time: 544.1176018714905 and batch: 1200, loss is 3.8346226692199705 and perplexity is 46.27596302795858
At time: 545.3661000728607 and batch: 1250, loss is 3.8281718635559083 and perplexity is 45.97840655488693
At time: 546.613320350647 and batch: 1300, loss is 3.8190863275527955 and perplexity is 45.562560041569355
At time: 547.8602685928345 and batch: 1350, loss is 3.688129606246948 and perplexity is 39.970017327946685
At time: 549.1079664230347 and batch: 1400, loss is 3.7202121877670287 and perplexity is 41.273150837256985
At time: 550.3566358089447 and batch: 1450, loss is 3.650239086151123 and perplexity is 38.483865908589216
At time: 551.6103744506836 and batch: 1500, loss is 3.6525449180603027 and perplexity is 38.572705619948096
At time: 552.8589165210724 and batch: 1550, loss is 3.666988215446472 and perplexity is 39.13386542194958
At time: 554.1067745685577 and batch: 1600, loss is 3.7440213060379026 and perplexity is 42.26761990499102
At time: 555.3538510799408 and batch: 1650, loss is 3.7081887245178224 and perplexity is 40.77987600335883
At time: 556.6016523838043 and batch: 1700, loss is 3.6954872894287107 and perplexity is 40.26518860899786
At time: 557.8515846729279 and batch: 1750, loss is 3.671389832496643 and perplexity is 39.30649736235856
At time: 559.1061084270477 and batch: 1800, loss is 3.6297937488555907 and perplexity is 37.70503910768325
At time: 560.3546171188354 and batch: 1850, loss is 3.669352855682373 and perplexity is 39.22651242996427
At time: 561.6029314994812 and batch: 1900, loss is 3.7657928466796875 and perplexity is 43.19794163079927
At time: 562.8520901203156 and batch: 1950, loss is 3.6997733068466188 and perplexity is 40.43813627230686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34575677916061 and perplexity of 77.15040120815685
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 566.8062262535095 and batch: 50, loss is 3.9145423364639282 and perplexity is 50.126125360847
At time: 568.0255105495453 and batch: 100, loss is 3.910550594329834 and perplexity is 49.926433618353755
At time: 569.2515399456024 and batch: 150, loss is 3.8738386392593385 and perplexity is 48.126773277767626
At time: 570.5012044906616 and batch: 200, loss is 3.8911642599105836 and perplexity is 48.96786467035235
At time: 571.751620054245 and batch: 250, loss is 3.8937938737869264 and perplexity is 49.096800698470766
At time: 573.0030262470245 and batch: 300, loss is 3.8976660680770876 and perplexity is 49.28728160132872
At time: 574.2558298110962 and batch: 350, loss is 3.918797435760498 and perplexity is 50.339871434488714
At time: 575.5056781768799 and batch: 400, loss is 3.872129864692688 and perplexity is 48.044605694547315
At time: 576.7541348934174 and batch: 450, loss is 3.903350305557251 and perplexity is 49.5682399752691
At time: 578.0021238327026 and batch: 500, loss is 3.906263451576233 and perplexity is 49.71285002905378
At time: 579.2510588169098 and batch: 550, loss is 3.878865041732788 and perplexity is 48.36928678466947
At time: 580.5033848285675 and batch: 600, loss is 3.8492177867889406 and perplexity is 46.956319009472885
At time: 581.7540235519409 and batch: 650, loss is 3.8701198291778565 and perplexity is 47.94813132174467
At time: 583.0050001144409 and batch: 700, loss is 3.9069052028656004 and perplexity is 49.74476355383561
At time: 584.2559678554535 and batch: 750, loss is 3.8530568933486937 and perplexity is 47.13693580352484
At time: 585.5072565078735 and batch: 800, loss is 3.8469226360321045 and perplexity is 46.848670760095615
At time: 586.7570486068726 and batch: 850, loss is 3.8379483938217165 and perplexity is 46.43012033696036
At time: 588.0062777996063 and batch: 900, loss is 3.7905507469177246 and perplexity is 44.28078106523095
At time: 589.2784326076508 and batch: 950, loss is 3.894168176651001 and perplexity is 49.11518121131381
At time: 590.5341613292694 and batch: 1000, loss is 3.8475154733657835 and perplexity is 46.8764526354082
At time: 591.7861304283142 and batch: 1050, loss is 3.804251232147217 and perplexity is 44.89162412055269
At time: 593.0376455783844 and batch: 1100, loss is 3.822375235557556 and perplexity is 45.712657803573386
At time: 594.2877430915833 and batch: 1150, loss is 3.8085251474380493 and perplexity is 45.08389770714471
At time: 595.5365946292877 and batch: 1200, loss is 3.844300055503845 and perplexity is 46.72596731854242
At time: 596.7860906124115 and batch: 1250, loss is 3.8315207529067994 and perplexity is 46.132641264311566
At time: 598.0354270935059 and batch: 1300, loss is 3.823038687705994 and perplexity is 45.74299602747105
At time: 599.2891623973846 and batch: 1350, loss is 3.6876794290542603 and perplexity is 39.95202778729857
At time: 600.5406064987183 and batch: 1400, loss is 3.7151738691329954 and perplexity is 41.0657265259774
At time: 601.7921905517578 and batch: 1450, loss is 3.6432063293457033 and perplexity is 38.214167711235845
At time: 603.042183637619 and batch: 1500, loss is 3.644370446205139 and perplexity is 38.25867937149814
At time: 604.2978489398956 and batch: 1550, loss is 3.660060167312622 and perplexity is 38.86368112424041
At time: 605.5491542816162 and batch: 1600, loss is 3.7309516716003417 and perplexity is 41.71879186752832
At time: 606.7997808456421 and batch: 1650, loss is 3.6948408126831054 and perplexity is 40.239166513150934
At time: 608.0506157875061 and batch: 1700, loss is 3.6774079513549807 and perplexity is 39.543761761970806
At time: 609.3012387752533 and batch: 1750, loss is 3.652473258972168 and perplexity is 38.56994163407001
At time: 610.5510675907135 and batch: 1800, loss is 3.6095511054992677 and perplexity is 36.94946268088868
At time: 611.8019104003906 and batch: 1850, loss is 3.6496660900115967 and perplexity is 38.46182111838254
At time: 613.0530004501343 and batch: 1900, loss is 3.7538853120803832 and perplexity is 42.68661103137045
At time: 614.3042788505554 and batch: 1950, loss is 3.696768879890442 and perplexity is 40.316825172054656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330522120276163 and perplexity of 75.98394897443576
finished 12 epochs...
Completing Train Step...
At time: 618.2479207515717 and batch: 50, loss is 3.9222024869918823 and perplexity is 50.51157343686369
At time: 619.4717078208923 and batch: 100, loss is 3.905091109275818 and perplexity is 49.65460370107868
At time: 620.7257633209229 and batch: 150, loss is 3.8586914682388307 and perplexity is 47.40328206771483
At time: 621.9656677246094 and batch: 200, loss is 3.8701441287994385 and perplexity is 47.949296457347465
At time: 623.2167019844055 and batch: 250, loss is 3.8699338245391846 and perplexity is 47.93921357629989
At time: 624.4686298370361 and batch: 300, loss is 3.8713722705841063 and perplexity is 48.00822116841556
At time: 625.7229187488556 and batch: 350, loss is 3.8928139114379885 and perplexity is 49.0487112491063
At time: 626.9718270301819 and batch: 400, loss is 3.8448827934265135 and perplexity is 46.753204246897056
At time: 628.2225117683411 and batch: 450, loss is 3.8769854640960695 and perplexity is 48.27845834122051
At time: 629.4714386463165 and batch: 500, loss is 3.8801233053207396 and perplexity is 48.43018640285702
At time: 630.7199339866638 and batch: 550, loss is 3.8533879280090333 and perplexity is 47.15254234606875
At time: 631.9694187641144 and batch: 600, loss is 3.8269927978515623 and perplexity is 45.92422693951746
At time: 633.2171113491058 and batch: 650, loss is 3.8496482706069948 and perplexity is 46.976537296472316
At time: 634.4656348228455 and batch: 700, loss is 3.888122658729553 and perplexity is 48.8191502349902
At time: 635.7198634147644 and batch: 750, loss is 3.8368366622924803 and perplexity is 46.37853119022948
At time: 636.9721434116364 and batch: 800, loss is 3.831466498374939 and perplexity is 46.13013842735202
At time: 638.2221705913544 and batch: 850, loss is 3.8230629920959474 and perplexity is 45.74410779659452
At time: 639.4717247486115 and batch: 900, loss is 3.776764540672302 and perplexity is 43.674505804980036
At time: 640.7213389873505 and batch: 950, loss is 3.8804426908493044 and perplexity is 48.4456567739146
At time: 641.972235918045 and batch: 1000, loss is 3.834770188331604 and perplexity is 46.28279012046537
At time: 643.2226765155792 and batch: 1050, loss is 3.7924754333496096 and perplexity is 44.3660897536431
At time: 644.4732344150543 and batch: 1100, loss is 3.811801567077637 and perplexity is 45.23185372566594
At time: 645.7290890216827 and batch: 1150, loss is 3.7984305095672606 and perplexity is 44.63108143933313
At time: 646.9798469543457 and batch: 1200, loss is 3.834849820137024 and perplexity is 46.28647584935121
At time: 648.2296748161316 and batch: 1250, loss is 3.823977241516113 and perplexity is 45.785948444103035
At time: 649.479998588562 and batch: 1300, loss is 3.8165479469299317 and perplexity is 45.447051586266156
At time: 650.7300779819489 and batch: 1350, loss is 3.6829898977279663 and perplexity is 39.76511012211726
At time: 651.9784212112427 and batch: 1400, loss is 3.7120201587677 and perplexity is 40.936421121642425
At time: 653.228866815567 and batch: 1450, loss is 3.6412812089920044 and perplexity is 38.14067160629763
At time: 654.4801239967346 and batch: 1500, loss is 3.644352593421936 and perplexity is 38.25799635368659
At time: 655.7306866645813 and batch: 1550, loss is 3.6614463472366334 and perplexity is 38.91759053422671
At time: 656.9800627231598 and batch: 1600, loss is 3.733545141220093 and perplexity is 41.827128710241055
At time: 658.2302832603455 and batch: 1650, loss is 3.6983792209625244 and perplexity is 40.38180131435918
At time: 659.4812061786652 and batch: 1700, loss is 3.6814600372314454 and perplexity is 39.70432156186628
At time: 660.7280926704407 and batch: 1750, loss is 3.657568678855896 and perplexity is 38.76697323465506
At time: 661.9778454303741 and batch: 1800, loss is 3.615119500160217 and perplexity is 37.15578578271346
At time: 663.2348282337189 and batch: 1850, loss is 3.6554198408126832 and perplexity is 38.68375872701839
At time: 664.4829540252686 and batch: 1900, loss is 3.7596713495254517 and perplexity is 42.93431327738403
At time: 665.7321064472198 and batch: 1950, loss is 3.701896347999573 and perplexity is 40.524079297770726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.329038256268168 and perplexity of 75.87128273872622
finished 13 epochs...
Completing Train Step...
At time: 669.6724247932434 and batch: 50, loss is 3.9176878452301027 and perplexity is 50.28404576738715
At time: 670.893120765686 and batch: 100, loss is 3.8984413242340086 and perplexity is 49.32550668504929
At time: 672.1175816059113 and batch: 150, loss is 3.851021685600281 and perplexity is 47.04109990260505
At time: 673.3557925224304 and batch: 200, loss is 3.861638402938843 and perplexity is 47.54318248198112
At time: 674.5997500419617 and batch: 250, loss is 3.86092041015625 and perplexity is 47.509059071744616
At time: 675.8448374271393 and batch: 300, loss is 3.861757001876831 and perplexity is 47.548821387309545
At time: 677.0903534889221 and batch: 350, loss is 3.883364496231079 and perplexity is 48.5874125451411
At time: 678.3349843025208 and batch: 400, loss is 3.8347416353225707 and perplexity is 46.28146862640739
At time: 679.5808980464935 and batch: 450, loss is 3.867080626487732 and perplexity is 47.802628450402004
At time: 680.8257615566254 and batch: 500, loss is 3.869987139701843 and perplexity is 47.94176953140441
At time: 682.069566488266 and batch: 550, loss is 3.843337435722351 and perplexity is 46.68100962014867
At time: 683.3532741069794 and batch: 600, loss is 3.8178026056289673 and perplexity is 45.50410791050646
At time: 684.5967581272125 and batch: 650, loss is 3.840709171295166 and perplexity is 46.55848067290913
At time: 685.8439037799835 and batch: 700, loss is 3.8797089576721193 and perplexity is 48.41012362576805
At time: 687.0950651168823 and batch: 750, loss is 3.8291725587844847 and perplexity is 46.02443995580483
At time: 688.3442902565002 and batch: 800, loss is 3.82399733543396 and perplexity is 45.78686847243307
At time: 689.5945515632629 and batch: 850, loss is 3.8158512783050536 and perplexity is 45.41540107757109
At time: 690.8471660614014 and batch: 900, loss is 3.7699241542816164 and perplexity is 43.37677476844096
At time: 692.0956032276154 and batch: 950, loss is 3.8738148498535154 and perplexity is 48.12562838404539
At time: 693.3471958637238 and batch: 1000, loss is 3.8284870195388794 and perplexity is 45.99289920840346
At time: 694.6002821922302 and batch: 1050, loss is 3.7868054056167604 and perplexity is 44.11524461582506
At time: 695.8469116687775 and batch: 1100, loss is 3.806553955078125 and perplexity is 44.99511620388669
At time: 697.1006486415863 and batch: 1150, loss is 3.793467707633972 and perplexity is 44.41013493243856
At time: 698.3474442958832 and batch: 1200, loss is 3.8301271343231202 and perplexity is 46.06839473610739
At time: 699.5945219993591 and batch: 1250, loss is 3.8201426553726194 and perplexity is 45.61071447023731
At time: 700.840612411499 and batch: 1300, loss is 3.813025050163269 and perplexity is 45.28722800146848
At time: 702.0900349617004 and batch: 1350, loss is 3.680137071609497 and perplexity is 39.65182884008654
At time: 703.3391065597534 and batch: 1400, loss is 3.709557919502258 and perplexity is 40.83574984741319
At time: 704.5848701000214 and batch: 1450, loss is 3.6394376802444457 and perplexity is 38.070422954340486
At time: 705.8347494602203 and batch: 1500, loss is 3.6433452558517456 and perplexity is 38.21947704083205
At time: 707.0886085033417 and batch: 1550, loss is 3.660939655303955 and perplexity is 38.89787630000723
At time: 708.335910320282 and batch: 1600, loss is 3.7336300468444823 and perplexity is 41.83068021949004
At time: 709.5833172798157 and batch: 1650, loss is 3.6987509822845457 and perplexity is 40.39681649706056
At time: 710.83087849617 and batch: 1700, loss is 3.6820799493789673 and perplexity is 39.7289423836964
At time: 712.0780277252197 and batch: 1750, loss is 3.6585609340667724 and perplexity is 38.805459056578066
At time: 713.3255980014801 and batch: 1800, loss is 3.616266255378723 and perplexity is 37.19841881411105
At time: 714.5719439983368 and batch: 1850, loss is 3.656598267555237 and perplexity is 38.72937157322518
At time: 715.8196113109589 and batch: 1900, loss is 3.7608530521392822 and perplexity is 42.985078856608254
At time: 717.0677480697632 and batch: 1950, loss is 3.7026482582092286 and perplexity is 40.55456122513169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328779637536337 and perplexity of 75.85166354085734
finished 14 epochs...
Completing Train Step...
At time: 720.9967648983002 and batch: 50, loss is 3.9128024530410768 and perplexity is 50.038987573058044
At time: 722.2422440052032 and batch: 100, loss is 3.892577247619629 and perplexity is 49.03710456731146
At time: 723.484132528305 and batch: 150, loss is 3.8448037052154542 and perplexity is 46.74950676582739
At time: 724.7237043380737 and batch: 200, loss is 3.855067420005798 and perplexity is 47.231801202242984
At time: 725.9641723632812 and batch: 250, loss is 3.8541505432128904 and perplexity is 47.18851530678233
At time: 727.2132687568665 and batch: 300, loss is 3.854710111618042 and perplexity is 47.214927898170636
At time: 728.4615476131439 and batch: 350, loss is 3.8764188432693483 and perplexity is 48.25111050989946
At time: 729.710170507431 and batch: 400, loss is 3.8274295854568483 and perplexity is 45.94429045405523
At time: 730.9590203762054 and batch: 450, loss is 3.8600169944763185 and perplexity is 47.46615802449764
At time: 732.2152900695801 and batch: 500, loss is 3.8627944374084473 and perplexity is 47.59817582069807
At time: 733.4642832279205 and batch: 550, loss is 3.836285319328308 and perplexity is 46.35296776112504
At time: 734.7134344577789 and batch: 600, loss is 3.8113390016555786 and perplexity is 45.21093587246763
At time: 735.9619355201721 and batch: 650, loss is 3.8342805814743044 and perplexity is 46.260135295478825
At time: 737.2131288051605 and batch: 700, loss is 3.8736677742004395 and perplexity is 48.1185507963043
At time: 738.4646928310394 and batch: 750, loss is 3.823561120033264 and perplexity is 45.766899890873795
At time: 739.7161464691162 and batch: 800, loss is 3.818458957672119 and perplexity is 45.53398442838954
At time: 740.9672727584839 and batch: 850, loss is 3.810476245880127 and perplexity is 45.171946697916304
At time: 742.2235424518585 and batch: 900, loss is 3.7647678518295287 and perplexity is 43.15368664752979
At time: 743.4759957790375 and batch: 950, loss is 3.868870186805725 and perplexity is 47.88825072763681
At time: 744.7494201660156 and batch: 1000, loss is 3.823631329536438 and perplexity is 45.77011327498068
At time: 746.0016264915466 and batch: 1050, loss is 3.782431011199951 and perplexity is 43.92268860111102
At time: 747.25763630867 and batch: 1100, loss is 3.802370548248291 and perplexity is 44.807276506333785
At time: 748.5085616111755 and batch: 1150, loss is 3.7895023822784424 and perplexity is 44.234382985465
At time: 749.7593114376068 and batch: 1200, loss is 3.8262878704071044 and perplexity is 45.89186509929705
At time: 751.0110013484955 and batch: 1250, loss is 3.8168820762634277 and perplexity is 45.46223931651382
At time: 752.2693405151367 and batch: 1300, loss is 3.809932050704956 and perplexity is 45.14737103005667
At time: 753.5197906494141 and batch: 1350, loss is 3.6774324798583984 and perplexity is 39.54473172316213
At time: 754.7702207565308 and batch: 1400, loss is 3.707000756263733 and perplexity is 40.73145956954835
At time: 756.0212132930756 and batch: 1450, loss is 3.6372798347473143 and perplexity is 37.98836143347812
At time: 757.2719969749451 and batch: 1500, loss is 3.6416810750961304 and perplexity is 38.15592581767938
At time: 758.5240411758423 and batch: 1550, loss is 3.659476237297058 and perplexity is 38.8409940787847
At time: 759.7747783660889 and batch: 1600, loss is 3.732577223777771 and perplexity is 41.7866630896494
At time: 761.0269496440887 and batch: 1650, loss is 3.69786406993866 and perplexity is 40.361003945419476
At time: 762.2765839099884 and batch: 1700, loss is 3.681383948326111 and perplexity is 39.70130061843318
At time: 763.5271162986755 and batch: 1750, loss is 3.658074598312378 and perplexity is 38.78659116281073
At time: 764.7804918289185 and batch: 1800, loss is 3.6158770895004273 and perplexity is 37.183945275268435
At time: 766.0411584377289 and batch: 1850, loss is 3.6562723207473753 and perplexity is 38.7167499152967
At time: 767.2939949035645 and batch: 1900, loss is 3.7605886173248293 and perplexity is 42.97371360800649
At time: 768.5513730049133 and batch: 1950, loss is 3.7021234941482546 and perplexity is 40.53328523181874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328938612827035 and perplexity of 75.86372303967444
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 772.5119774341583 and batch: 50, loss is 3.9132105684280396 and perplexity is 50.059413421602684
At time: 773.761331319809 and batch: 100, loss is 3.9010531234741213 and perplexity is 49.45450338934541
At time: 774.990312576294 and batch: 150, loss is 3.8577445125579835 and perplexity is 47.358414507618285
At time: 776.2416191101074 and batch: 200, loss is 3.8719966316223147 and perplexity is 48.03820499061795
At time: 777.487818479538 and batch: 250, loss is 3.876118850708008 and perplexity is 48.23663770664528
At time: 778.7364454269409 and batch: 300, loss is 3.8751926231384277 and perplexity is 48.191980287596515
At time: 779.9867913722992 and batch: 350, loss is 3.895686535835266 and perplexity is 49.18981234188613
At time: 781.2365894317627 and batch: 400, loss is 3.8475276041030884 and perplexity is 46.87702128478997
At time: 782.486848115921 and batch: 450, loss is 3.8833515787124635 and perplexity is 48.586784920388745
At time: 783.7356526851654 and batch: 500, loss is 3.8850954151153565 and perplexity is 48.671586242959286
At time: 784.9850270748138 and batch: 550, loss is 3.8597740745544433 and perplexity is 47.45462894947631
At time: 786.2350718975067 and batch: 600, loss is 3.8324985122680664 and perplexity is 46.17776994506745
At time: 787.484808921814 and batch: 650, loss is 3.852256531715393 and perplexity is 47.099224302028915
At time: 788.7414207458496 and batch: 700, loss is 3.8917528438568114 and perplexity is 48.99669485303742
At time: 789.9885897636414 and batch: 750, loss is 3.8393629884719847 and perplexity is 46.49584661385989
At time: 791.2461106777191 and batch: 800, loss is 3.8321506214141845 and perplexity is 46.16170791532952
At time: 792.4958448410034 and batch: 850, loss is 3.8239885997772216 and perplexity is 45.786468495814
At time: 793.7457408905029 and batch: 900, loss is 3.7716589641571043 and perplexity is 43.452090536055806
At time: 794.9958746433258 and batch: 950, loss is 3.8756911945343018 and perplexity is 48.21601342109706
At time: 796.244651556015 and batch: 1000, loss is 3.8298006200790407 and perplexity is 46.053355204468446
At time: 797.49454164505 and batch: 1050, loss is 3.7890877103805543 and perplexity is 44.216044032507504
At time: 798.744669675827 and batch: 1100, loss is 3.8038887214660644 and perplexity is 44.87535337665212
At time: 799.9943518638611 and batch: 1150, loss is 3.793217840194702 and perplexity is 44.399039671975245
At time: 801.244814157486 and batch: 1200, loss is 3.8306637048721313 and perplexity is 46.09312031287793
At time: 802.4937546253204 and batch: 1250, loss is 3.818765287399292 and perplexity is 45.547934978041525
At time: 803.743310213089 and batch: 1300, loss is 3.810320887565613 and perplexity is 45.16492940552547
At time: 804.9920132160187 and batch: 1350, loss is 3.675728988647461 and perplexity is 39.47742496474491
At time: 806.2488286495209 and batch: 1400, loss is 3.7028692674636843 and perplexity is 40.56352514899141
At time: 807.4984440803528 and batch: 1450, loss is 3.6304329109191893 and perplexity is 37.729146441713354
At time: 808.7488541603088 and batch: 1500, loss is 3.631640410423279 and perplexity is 37.774731883992075
At time: 810.0019028186798 and batch: 1550, loss is 3.652341613769531 and perplexity is 38.56486442049064
At time: 811.2503457069397 and batch: 1600, loss is 3.7248992252349855 and perplexity is 41.467053701670615
At time: 812.4985542297363 and batch: 1650, loss is 3.690487322807312 and perplexity is 40.064366480292406
At time: 813.7459321022034 and batch: 1700, loss is 3.673610906600952 and perplexity is 39.39389703042113
At time: 814.9945902824402 and batch: 1750, loss is 3.651176052093506 and perplexity is 38.519940878146514
At time: 816.242931842804 and batch: 1800, loss is 3.6071518754959104 and perplexity is 36.86091868259927
At time: 817.4916112422943 and batch: 1850, loss is 3.646152181625366 and perplexity is 38.32690697938876
At time: 818.7400987148285 and batch: 1900, loss is 3.7532074069976806 and perplexity is 42.65768336700211
At time: 819.9870219230652 and batch: 1950, loss is 3.701391034126282 and perplexity is 40.503607091179845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322565406976744 and perplexity of 75.3817653552754
finished 16 epochs...
Completing Train Step...
At time: 823.8922288417816 and batch: 50, loss is 3.917557830810547 and perplexity is 50.27750854133982
At time: 825.1387584209442 and batch: 100, loss is 3.898377604484558 and perplexity is 49.322363776255536
At time: 826.3693573474884 and batch: 150, loss is 3.8508058691024782 and perplexity is 47.030948752603514
At time: 827.6128718852997 and batch: 200, loss is 3.863004221916199 and perplexity is 47.60816222804263
At time: 828.8617417812347 and batch: 250, loss is 3.8645296144485473 and perplexity is 47.68083877922623
At time: 830.1103529930115 and batch: 300, loss is 3.862992625236511 and perplexity is 47.60761013463599
At time: 831.3601293563843 and batch: 350, loss is 3.883910713195801 and perplexity is 48.61395906356452
At time: 832.6086566448212 and batch: 400, loss is 3.835184836387634 and perplexity is 46.30198516873619
At time: 833.857747554779 and batch: 450, loss is 3.8706942701339724 and perplexity is 47.97568260468014
At time: 835.1063969135284 and batch: 500, loss is 3.873247981071472 and perplexity is 48.098355198587306
At time: 836.357932806015 and batch: 550, loss is 3.8481229066848757 and perplexity is 46.904935604496224
At time: 837.6070160865784 and batch: 600, loss is 3.822282223701477 and perplexity is 45.708406182153425
At time: 838.8870027065277 and batch: 650, loss is 3.8421031999588013 and perplexity is 46.62342978944949
At time: 840.1355471611023 and batch: 700, loss is 3.8828245306015017 and perplexity is 48.5611840942049
At time: 841.3841786384583 and batch: 750, loss is 3.831892547607422 and perplexity is 46.14979632474203
At time: 842.6315133571625 and batch: 800, loss is 3.825263833999634 and perplexity is 45.844894212682306
At time: 843.8808944225311 and batch: 850, loss is 3.81746693611145 and perplexity is 45.48883613183778
At time: 845.1302058696747 and batch: 900, loss is 3.7661590814590453 and perplexity is 43.21376511679973
At time: 846.3790793418884 and batch: 950, loss is 3.8709581470489502 and perplexity is 47.988343950244754
At time: 847.6266345977783 and batch: 1000, loss is 3.824938626289368 and perplexity is 45.8299875236245
At time: 848.875718832016 and batch: 1050, loss is 3.7845703744888306 and perplexity is 44.01675577470425
At time: 850.1239964962006 and batch: 1100, loss is 3.8006552267074585 and perplexity is 44.730483500933786
At time: 851.3717806339264 and batch: 1150, loss is 3.7906790733337403 and perplexity is 44.28646382377965
At time: 852.6210150718689 and batch: 1200, loss is 3.8276057481765746 and perplexity is 45.95238483816094
At time: 853.87051820755 and batch: 1250, loss is 3.815767974853516 and perplexity is 45.411617975483274
At time: 855.1194908618927 and batch: 1300, loss is 3.8079403114318846 and perplexity is 45.057538729058365
At time: 856.3685913085938 and batch: 1350, loss is 3.6741365146636964 and perplexity is 39.41460822283128
At time: 857.6180994510651 and batch: 1400, loss is 3.7024023485183717 and perplexity is 40.54458969161659
At time: 858.8670740127563 and batch: 1450, loss is 3.6306410026550293 and perplexity is 37.7369983822218
At time: 860.116461277008 and batch: 1500, loss is 3.6332678604125976 and perplexity is 37.836258423096005
At time: 861.3647689819336 and batch: 1550, loss is 3.65461549282074 and perplexity is 38.652656033736825
At time: 862.613498210907 and batch: 1600, loss is 3.7274607372283937 and perplexity is 41.57340821308465
At time: 863.8618688583374 and batch: 1650, loss is 3.6933073663711546 and perplexity is 40.1775091978388
At time: 865.1100022792816 and batch: 1700, loss is 3.676879587173462 and perplexity is 39.52287377337171
At time: 866.3590734004974 and batch: 1750, loss is 3.6551433610916138 and perplexity is 38.67306493057267
At time: 867.6077659130096 and batch: 1800, loss is 3.610916504859924 and perplexity is 36.999947912017554
At time: 868.8580408096313 and batch: 1850, loss is 3.6503310775756836 and perplexity is 38.4874062570751
At time: 870.1075999736786 and batch: 1900, loss is 3.757357134819031 and perplexity is 42.83506893883399
At time: 871.3621890544891 and batch: 1950, loss is 3.7055302906036376 and perplexity is 40.67160937158055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.321533770893895 and perplexity of 75.30403890574453
finished 17 epochs...
Completing Train Step...
At time: 875.2914042472839 and batch: 50, loss is 3.917463808059692 and perplexity is 50.27278153390724
At time: 876.5061421394348 and batch: 100, loss is 3.896554412841797 and perplexity is 49.23252157947511
At time: 877.7275609970093 and batch: 150, loss is 3.847848696708679 and perplexity is 46.89207556647656
At time: 878.9772849082947 and batch: 200, loss is 3.859089493751526 and perplexity is 47.4221535387776
At time: 880.224018573761 and batch: 250, loss is 3.8602116298675537 and perplexity is 47.47539751787221
At time: 881.4721524715424 and batch: 300, loss is 3.858596472740173 and perplexity is 47.39877918317707
At time: 882.7368261814117 and batch: 350, loss is 3.8796738386154175 and perplexity is 48.40842353774441
At time: 884.0130264759064 and batch: 400, loss is 3.8305634307861327 and perplexity is 46.08849859909067
At time: 885.2679319381714 and batch: 450, loss is 3.8660823202133177 and perplexity is 47.75493059898001
At time: 886.5230259895325 and batch: 500, loss is 3.868513765335083 and perplexity is 47.87118536829689
At time: 887.7778308391571 and batch: 550, loss is 3.8433239221572877 and perplexity is 46.68037879755028
At time: 889.0329875946045 and batch: 600, loss is 3.8178936862945556 and perplexity is 45.50825264369162
At time: 890.2854619026184 and batch: 650, loss is 3.8377801370620728 and perplexity is 46.42230881255191
At time: 891.5370163917542 and batch: 700, loss is 3.8789289093017576 and perplexity is 48.372376112082065
At time: 892.7914476394653 and batch: 750, loss is 3.828492603302002 and perplexity is 45.99315602257495
At time: 894.0449798107147 and batch: 800, loss is 3.8220877647399902 and perplexity is 45.699518637115425
At time: 895.2964980602264 and batch: 850, loss is 3.8143805646896363 and perplexity is 45.348657121509724
At time: 896.5485634803772 and batch: 900, loss is 3.763369235992432 and perplexity is 43.093373405315006
At time: 897.8024616241455 and batch: 950, loss is 3.868317012786865 and perplexity is 47.86176751711296
At time: 899.0579450130463 and batch: 1000, loss is 3.822455325126648 and perplexity is 45.71631905725107
At time: 900.3802492618561 and batch: 1050, loss is 3.782328734397888 and perplexity is 43.91819655870266
At time: 901.640750169754 and batch: 1100, loss is 3.798946862220764 and perplexity is 44.654132767458115
At time: 902.9118149280548 and batch: 1150, loss is 3.7891599559783935 and perplexity is 44.21923856243669
At time: 904.1829662322998 and batch: 1200, loss is 3.826134467124939 and perplexity is 45.884825676515206
At time: 905.4317398071289 and batch: 1250, loss is 3.8145831823349 and perplexity is 45.35784649056427
At time: 906.6791610717773 and batch: 1300, loss is 3.8070539665222167 and perplexity is 45.01761990250144
At time: 907.926337480545 and batch: 1350, loss is 3.6736145782470704 and perplexity is 39.394041671135774
At time: 909.1731224060059 and batch: 1400, loss is 3.7022801208496094 and perplexity is 40.539634323785364
At time: 910.4264006614685 and batch: 1450, loss is 3.630803289413452 and perplexity is 37.743123094328254
At time: 911.6725254058838 and batch: 1500, loss is 3.63399525642395 and perplexity is 37.86379037866086
At time: 912.9191935062408 and batch: 1550, loss is 3.6556247997283937 and perplexity is 38.691688120834904
At time: 914.165999174118 and batch: 1600, loss is 3.7286277484893797 and perplexity is 41.6219531693727
At time: 915.4117515087128 and batch: 1650, loss is 3.694640188217163 and perplexity is 40.231094361621885
At time: 916.6585896015167 and batch: 1700, loss is 3.678304743766785 and perplexity is 39.57924021347842
At time: 917.905460357666 and batch: 1750, loss is 3.6567644262313843 and perplexity is 38.73580732899733
At time: 919.1497490406036 and batch: 1800, loss is 3.612476177215576 and perplexity is 37.057700733969064
At time: 920.39381980896 and batch: 1850, loss is 3.6520487594604494 and perplexity is 38.55357218733623
At time: 921.6556749343872 and batch: 1900, loss is 3.7589162826538085 and perplexity is 42.901907235675424
At time: 922.9015762805939 and batch: 1950, loss is 3.7069196367263793 and perplexity is 40.728155586402934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3211309388626455 and perplexity of 75.27371013590096
finished 18 epochs...
Completing Train Step...
At time: 926.8283426761627 and batch: 50, loss is 3.9163194465637208 and perplexity is 50.215284203564636
At time: 928.0448589324951 and batch: 100, loss is 3.894648971557617 and perplexity is 49.13880121801218
At time: 929.2651233673096 and batch: 150, loss is 3.845525441169739 and perplexity is 46.78325974460937
At time: 930.4887156486511 and batch: 200, loss is 3.856368103027344 and perplexity is 47.293274774292854
At time: 931.7710590362549 and batch: 250, loss is 3.857333559989929 and perplexity is 47.33895644400185
At time: 933.0154614448547 and batch: 300, loss is 3.855643572807312 and perplexity is 47.259021777678605
At time: 934.2623164653778 and batch: 350, loss is 3.8768333530426027 and perplexity is 48.271115212562144
At time: 935.5082631111145 and batch: 400, loss is 3.8275230503082276 and perplexity is 45.948584831017776
At time: 936.7555577754974 and batch: 450, loss is 3.8631156301498413 and perplexity is 47.61346646476576
At time: 938.0030076503754 and batch: 500, loss is 3.8654325437545776 and perplexity is 47.723910648396256
At time: 939.2517440319061 and batch: 550, loss is 3.8401987886428834 and perplexity is 46.53472409504535
At time: 940.4987070560455 and batch: 600, loss is 3.8150317573547365 and perplexity is 45.37819745157864
At time: 941.7455363273621 and batch: 650, loss is 3.8349845695495604 and perplexity is 46.292713345020296
At time: 942.9909393787384 and batch: 700, loss is 3.8763480377197266 and perplexity is 48.247694184448775
At time: 944.2385952472687 and batch: 750, loss is 3.8261837482452394 and perplexity is 45.88708698784886
At time: 945.4877471923828 and batch: 800, loss is 3.8198759269714357 and perplexity is 45.598550419610824
At time: 946.7366132736206 and batch: 850, loss is 3.8122442722320558 and perplexity is 45.251882533555346
At time: 947.9845702648163 and batch: 900, loss is 3.7613690233230592 and perplexity is 43.007263641493324
At time: 949.2329196929932 and batch: 950, loss is 3.8663894367218017 and perplexity is 47.769599178894694
At time: 950.4875514507294 and batch: 1000, loss is 3.8207069349288942 and perplexity is 45.63645892681211
At time: 951.7409474849701 and batch: 1050, loss is 3.7807244539260862 and perplexity is 43.84779593987505
At time: 952.9983925819397 and batch: 1100, loss is 3.797640013694763 and perplexity is 44.595814694614766
At time: 954.2484040260315 and batch: 1150, loss is 3.787963795661926 and perplexity is 44.16637688586666
At time: 955.5020291805267 and batch: 1200, loss is 3.8250199842453 and perplexity is 45.83371630941096
At time: 956.7575151920319 and batch: 1250, loss is 3.8136989736557005 and perplexity is 45.31775841475163
At time: 958.0080564022064 and batch: 1300, loss is 3.8063297700881957 and perplexity is 44.9850301048319
At time: 959.2573511600494 and batch: 1350, loss is 3.673110284805298 and perplexity is 39.37418052262049
At time: 960.505702495575 and batch: 1400, loss is 3.701982464790344 and perplexity is 40.52756925169847
At time: 961.7556571960449 and batch: 1450, loss is 3.630681900978088 and perplexity is 37.738541793734164
At time: 963.005806684494 and batch: 1500, loss is 3.6341892433166505 and perplexity is 37.87113617017287
At time: 964.2541632652283 and batch: 1550, loss is 3.6560021257400512 and perplexity is 38.706290255907284
At time: 965.5037903785706 and batch: 1600, loss is 3.729130711555481 and perplexity is 41.64289274002979
At time: 966.7539880275726 and batch: 1650, loss is 3.6952445793151854 and perplexity is 40.25541702637838
At time: 968.0025472640991 and batch: 1700, loss is 3.678939619064331 and perplexity is 39.604376073609664
At time: 969.2503085136414 and batch: 1750, loss is 3.657494535446167 and perplexity is 38.76409902562773
At time: 970.4984259605408 and batch: 1800, loss is 3.6132007789611817 and perplexity is 37.084562539489305
At time: 971.745974779129 and batch: 1850, loss is 3.6528349351882934 and perplexity is 38.583893987581526
At time: 972.9967896938324 and batch: 1900, loss is 3.759589977264404 and perplexity is 42.930819757375865
At time: 974.2499701976776 and batch: 1950, loss is 3.707430715560913 and perplexity is 40.74897620472822
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320941871820494 and perplexity of 75.25947970346908
finished 19 epochs...
Completing Train Step...
At time: 978.1785006523132 and batch: 50, loss is 3.9149654722213745 and perplexity is 50.14734000489011
At time: 979.388111114502 and batch: 100, loss is 3.8928585481643676 and perplexity is 49.05090067187354
At time: 980.6082556247711 and batch: 150, loss is 3.84354775428772 and perplexity is 46.690828535635866
At time: 981.8317968845367 and batch: 200, loss is 3.8541857862472533 and perplexity is 47.19017840255491
At time: 983.0750946998596 and batch: 250, loss is 3.855051417350769 and perplexity is 47.23104537406959
At time: 984.3264555931091 and batch: 300, loss is 3.8532792425155638 and perplexity is 47.147417827221
At time: 985.5758347511292 and batch: 350, loss is 3.8745415592193604 and perplexity is 48.160614439736726
At time: 986.8239834308624 and batch: 400, loss is 3.825108208656311 and perplexity is 45.837760140416485
At time: 988.0717287063599 and batch: 450, loss is 3.8607792758941653 and perplexity is 47.50235438889155
At time: 989.3196461200714 and batch: 500, loss is 3.8630222415924074 and perplexity is 47.6090201194403
At time: 990.5676867961884 and batch: 550, loss is 3.8377755308151245 and perplexity is 46.422094980426095
At time: 991.8159875869751 and batch: 600, loss is 3.812811088562012 and perplexity is 45.27753931018969
At time: 993.0641202926636 and batch: 650, loss is 3.83281879901886 and perplexity is 46.19256244175595
At time: 994.3564119338989 and batch: 700, loss is 3.8743204498291015 and perplexity is 48.14996685282757
At time: 995.6009793281555 and batch: 750, loss is 3.8243434715270994 and perplexity is 45.80271970338652
At time: 996.8458626270294 and batch: 800, loss is 3.818091297149658 and perplexity is 45.51724645701906
At time: 998.090086221695 and batch: 850, loss is 3.810520577430725 and perplexity is 45.17394928474551
At time: 999.3346107006073 and batch: 900, loss is 3.7597273778915405 and perplexity is 42.936718884196594
At time: 1000.5806930065155 and batch: 950, loss is 3.8648058128356935 and perplexity is 47.69400996884176
At time: 1001.8256764411926 and batch: 1000, loss is 3.819272060394287 and perplexity is 45.57102329123888
At time: 1003.0725584030151 and batch: 1050, loss is 3.7793941068649293 and perplexity is 43.78950193763301
At time: 1004.3180375099182 and batch: 1100, loss is 3.7964956188201904 and perplexity is 44.54480866393752
At time: 1005.5706210136414 and batch: 1150, loss is 3.786901888847351 and perplexity is 44.11950120248521
At time: 1006.8161108493805 and batch: 1200, loss is 3.824029049873352 and perplexity is 45.78832060032478
At time: 1008.0608696937561 and batch: 1250, loss is 3.812888016700745 and perplexity is 45.28102256099351
At time: 1009.3069951534271 and batch: 1300, loss is 3.8056131172180176 and perplexity is 44.952803003094
At time: 1010.5528209209442 and batch: 1350, loss is 3.6725482320785523 and perplexity is 39.352056375145516
At time: 1011.8001148700714 and batch: 1400, loss is 3.7015496349334716 and perplexity is 40.510031505403774
At time: 1013.053952217102 and batch: 1450, loss is 3.6303770542144775 and perplexity is 37.727039074777366
At time: 1014.3009157180786 and batch: 1500, loss is 3.634095478057861 and perplexity is 37.86758533976409
At time: 1015.5486538410187 and batch: 1550, loss is 3.656041784286499 and perplexity is 38.70782532155625
At time: 1016.7968249320984 and batch: 1600, loss is 3.729280319213867 and perplexity is 41.64912330175931
At time: 1018.0423941612244 and batch: 1650, loss is 3.6954608249664305 and perplexity is 40.2641230265328
At time: 1019.2908544540405 and batch: 1700, loss is 3.679173526763916 and perplexity is 39.61364092562841
At time: 1020.5390779972076 and batch: 1750, loss is 3.6577968311309816 and perplexity is 38.77581901685104
At time: 1021.790100812912 and batch: 1800, loss is 3.6135161828994753 and perplexity is 37.096261001337645
At time: 1023.0399992465973 and batch: 1850, loss is 3.653178124427795 and perplexity is 38.59713783725951
At time: 1024.289964914322 and batch: 1900, loss is 3.759859104156494 and perplexity is 42.9423751503358
At time: 1025.537169456482 and batch: 1950, loss is 3.7075619316101074 and perplexity is 40.7543234752107
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320857842023982 and perplexity of 75.2531559304004
Finished Training.
Improved accuracyfrom -10000000 to -75.2531559304004
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc433bcbb38>
ELAPSED
1057.3388566970825


RESULTS SO FAR:
[{'best_accuracy': -75.2531559304004, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7460609200881098, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.7558732386815785, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6043167114257812 and batch: 50, loss is 7.667528028488159 and perplexity is 2137.7903513785395
At time: 2.7717409133911133 and batch: 100, loss is 6.870137701034546 and perplexity is 963.0811739556699
At time: 3.9446938037872314 and batch: 150, loss is 6.590573635101318 and perplexity is 728.1984703155479
At time: 5.117936134338379 and batch: 200, loss is 6.4815718364715575 and perplexity is 652.9965438075641
At time: 6.291786193847656 and batch: 250, loss is 6.423889989852905 and perplexity is 616.3962315927599
At time: 7.465285062789917 and batch: 300, loss is 6.358567628860474 and perplexity is 577.41868590846
At time: 8.640424966812134 and batch: 350, loss is 6.322144966125489 and perplexity is 556.7659566769835
At time: 9.815277338027954 and batch: 400, loss is 6.277931909561158 and perplexity is 532.6858813135756
At time: 10.990251779556274 and batch: 450, loss is 6.18886999130249 and perplexity is 487.29514722422476
At time: 12.168688535690308 and batch: 500, loss is 6.179835367202759 and perplexity is 482.91244658110384
At time: 13.353972673416138 and batch: 550, loss is 6.133045310974121 and perplexity is 460.8374192130255
At time: 14.530241012573242 and batch: 600, loss is 6.173207702636719 and perplexity is 479.72244766874326
At time: 15.706818342208862 and batch: 650, loss is 6.242757186889649 and perplexity is 514.2745088938946
At time: 16.883747816085815 and batch: 700, loss is 6.145802173614502 and perplexity is 466.75391660561127
At time: 18.080811738967896 and batch: 750, loss is 6.071976203918457 and perplexity is 433.53659228133574
At time: 19.345391511917114 and batch: 800, loss is 6.084644031524658 and perplexity is 439.063492090278
At time: 20.66373610496521 and batch: 850, loss is 6.122941274642944 and perplexity is 456.2045459610595
At time: 21.98729658126831 and batch: 900, loss is 6.107364320755005 and perplexity is 449.1533295971288
At time: 23.311187744140625 and batch: 950, loss is 6.1185032081604005 and perplexity is 454.1843660187518
At time: 24.636245489120483 and batch: 1000, loss is 6.101856832504272 and perplexity is 446.68642237846
At time: 25.959837675094604 and batch: 1050, loss is 6.000006008148193 and perplexity is 403.4312173599933
At time: 27.283441066741943 and batch: 1100, loss is 6.065134134292602 and perplexity is 430.580429400175
At time: 28.607260704040527 and batch: 1150, loss is 5.978576278686523 and perplexity is 394.87777186017126
At time: 29.929216623306274 and batch: 1200, loss is 6.0569280242919925 and perplexity is 427.061497152087
At time: 31.254597425460815 and batch: 1250, loss is 5.990829858779907 and perplexity is 399.7462052175829
At time: 32.576197385787964 and batch: 1300, loss is 6.005120477676392 and perplexity is 405.4998394710664
At time: 33.89478063583374 and batch: 1350, loss is 5.9857337760925295 and perplexity is 397.71424741182966
At time: 35.21307682991028 and batch: 1400, loss is 6.003011837005615 and perplexity is 404.64568688449543
At time: 36.53390908241272 and batch: 1450, loss is 5.979347982406616 and perplexity is 395.182618116064
At time: 37.85585165023804 and batch: 1500, loss is 5.959795083999634 and perplexity is 387.5307048588517
At time: 39.180774211883545 and batch: 1550, loss is 5.934389591217041 and perplexity is 377.8093076519828
At time: 40.50116539001465 and batch: 1600, loss is 5.92840723991394 and perplexity is 375.5558668060247
At time: 41.82135725021362 and batch: 1650, loss is 5.928746204376221 and perplexity is 375.68318847601466
At time: 43.14175605773926 and batch: 1700, loss is 5.940618734359742 and perplexity is 380.1700810741787
At time: 44.46168875694275 and batch: 1750, loss is 5.9395693492889405 and perplexity is 379.7713455168957
At time: 45.781636476516724 and batch: 1800, loss is 5.953197660446167 and perplexity is 384.9824159725456
At time: 47.10211396217346 and batch: 1850, loss is 5.908541450500488 and perplexity is 368.1687712269006
At time: 48.42195677757263 and batch: 1900, loss is 5.897090492248535 and perplexity is 363.9769320896697
At time: 49.74804639816284 and batch: 1950, loss is 5.841117315292358 and perplexity is 344.16366524537136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.267762082122093 and perplexity of 193.9813619687573
finished 1 epochs...
Completing Train Step...
At time: 53.68500566482544 and batch: 50, loss is 5.556619062423706 and perplexity is 258.9458748438158
At time: 54.96130990982056 and batch: 100, loss is 5.458364953994751 and perplexity is 234.71334334132388
At time: 56.21154594421387 and batch: 150, loss is 5.3386961936950685 and perplexity is 208.2410272522776
At time: 57.46163630485535 and batch: 200, loss is 5.276686544418335 and perplexity is 195.7202892738673
At time: 58.712565183639526 and batch: 250, loss is 5.286778440475464 and perplexity is 197.70547840199484
At time: 59.96354603767395 and batch: 300, loss is 5.2720534324646 and perplexity is 194.8155926607207
At time: 61.21365475654602 and batch: 350, loss is 5.243641386032104 and perplexity is 189.35837545465117
At time: 62.483969926834106 and batch: 400, loss is 5.1841941165924075 and perplexity is 178.42959838112057
At time: 63.733481645584106 and batch: 450, loss is 5.131466875076294 and perplexity is 169.26522697072554
At time: 64.98278141021729 and batch: 500, loss is 5.115249252319336 and perplexity is 166.54228686165325
At time: 66.2326328754425 and batch: 550, loss is 5.0660757732391355 and perplexity is 158.5509151936366
At time: 67.48283886909485 and batch: 600, loss is 5.040681819915772 and perplexity is 154.57537167157324
At time: 68.73245525360107 and batch: 650, loss is 5.108917579650879 and perplexity is 165.4911269278553
At time: 69.98282814025879 and batch: 700, loss is 5.09754319190979 and perplexity is 163.61943155634927
At time: 71.23343324661255 and batch: 750, loss is 5.036187419891357 and perplexity is 153.8822069639037
At time: 72.48377227783203 and batch: 800, loss is 5.037616872787476 and perplexity is 154.10233162174185
At time: 73.73762607574463 and batch: 850, loss is 5.030833930969238 and perplexity is 153.06060146383885
At time: 74.98976445198059 and batch: 900, loss is 5.032490520477295 and perplexity is 153.31437018758882
At time: 76.2401475906372 and batch: 950, loss is 5.057886543273926 and perplexity is 157.25780729358888
At time: 77.49002146720886 and batch: 1000, loss is 5.024538307189942 and perplexity is 152.10001641534691
At time: 78.74076271057129 and batch: 1050, loss is 4.944502601623535 and perplexity is 140.4009982520169
At time: 79.99109435081482 and batch: 1100, loss is 5.004417791366577 and perplexity is 149.07026789158806
At time: 81.24081587791443 and batch: 1150, loss is 4.925469007492065 and perplexity is 137.75393412166088
At time: 82.49048185348511 and batch: 1200, loss is 4.999488754272461 and perplexity is 148.33730290130646
At time: 83.74053239822388 and batch: 1250, loss is 4.958891191482544 and perplexity is 142.4357743055954
At time: 84.99018597602844 and batch: 1300, loss is 4.969717321395874 and perplexity is 143.9861798052909
At time: 86.23873162269592 and batch: 1350, loss is 4.871682472229004 and perplexity is 130.5403627740272
At time: 87.4889349937439 and batch: 1400, loss is 4.869723529815674 and perplexity is 130.28489202867326
At time: 88.73955082893372 and batch: 1450, loss is 4.8242893886566165 and perplexity is 124.4979672742003
At time: 89.98833703994751 and batch: 1500, loss is 4.797553157806396 and perplexity is 121.21346414936036
At time: 91.2388436794281 and batch: 1550, loss is 4.797181663513183 and perplexity is 121.16844240234713
At time: 92.48912787437439 and batch: 1600, loss is 4.854737405776977 and perplexity is 128.34698361276395
At time: 93.73811101913452 and batch: 1650, loss is 4.8327971458435055 and perplexity is 125.56168425678233
At time: 94.98828363418579 and batch: 1700, loss is 4.836763191223144 and perplexity is 126.06065641354803
At time: 96.23872756958008 and batch: 1750, loss is 4.827814130783081 and perplexity is 124.93756478291695
At time: 97.48807454109192 and batch: 1800, loss is 4.784324369430542 and perplexity is 119.62051649804143
At time: 98.73780417442322 and batch: 1850, loss is 4.796689929962159 and perplexity is 121.1088744608705
At time: 99.98811841011047 and batch: 1900, loss is 4.895750484466553 and perplexity is 133.72032399254016
At time: 101.23866486549377 and batch: 1950, loss is 4.81031904220581 and perplexity is 122.77078033020346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.640826841842297 and perplexity of 103.62999778710271
finished 2 epochs...
Completing Train Step...
At time: 105.15011215209961 and batch: 50, loss is 4.772316665649414 and perplexity is 118.19273809515612
At time: 106.41779613494873 and batch: 100, loss is 4.702269639968872 and perplexity is 110.19699634709147
At time: 107.66490268707275 and batch: 150, loss is 4.641606884002686 and perplexity is 103.71086509031018
At time: 108.91275382041931 and batch: 200, loss is 4.630405340194702 and perplexity is 102.55562560390261
At time: 110.16022205352783 and batch: 250, loss is 4.645505170822144 and perplexity is 104.11594884205893
At time: 111.40862846374512 and batch: 300, loss is 4.665107154846192 and perplexity is 106.17696198845742
At time: 112.6565465927124 and batch: 350, loss is 4.667899103164673 and perplexity is 106.47381678774005
At time: 113.90512132644653 and batch: 400, loss is 4.610773820877075 and perplexity is 100.5619364618463
At time: 115.15354251861572 and batch: 450, loss is 4.608310794830322 and perplexity is 100.3145545721096
At time: 116.40164518356323 and batch: 500, loss is 4.6071749019622805 and perplexity is 100.20067267607185
At time: 117.64986491203308 and batch: 550, loss is 4.57188868522644 and perplexity is 96.72662350791579
At time: 118.89757037162781 and batch: 600, loss is 4.542407217025757 and perplexity is 93.91660588137607
At time: 120.14695644378662 and batch: 650, loss is 4.60870023727417 and perplexity is 100.35362892550768
At time: 121.39439630508423 and batch: 700, loss is 4.636207685470581 and perplexity is 103.15241847843667
At time: 122.6426272392273 and batch: 750, loss is 4.582186918258667 and perplexity is 97.72788357303817
At time: 123.91057109832764 and batch: 800, loss is 4.588141670227051 and perplexity is 98.31156499442474
At time: 125.15950179100037 and batch: 850, loss is 4.580987472534179 and perplexity is 97.61073455191436
At time: 126.40704822540283 and batch: 900, loss is 4.562582483291626 and perplexity is 95.83064157786026
At time: 127.65558743476868 and batch: 950, loss is 4.610496397018433 and perplexity is 100.534042050867
At time: 128.90471982955933 and batch: 1000, loss is 4.595198860168457 and perplexity is 99.00782230236898
At time: 130.15321683883667 and batch: 1050, loss is 4.531935577392578 and perplexity is 92.93827632618411
At time: 131.40175676345825 and batch: 1100, loss is 4.584173545837403 and perplexity is 97.92222546031503
At time: 132.65100169181824 and batch: 1150, loss is 4.5346160316467286 and perplexity is 93.18772729593726
At time: 133.9057059288025 and batch: 1200, loss is 4.599925441741943 and perplexity is 99.47689854116207
At time: 135.15470385551453 and batch: 1250, loss is 4.580150003433228 and perplexity is 97.52902279811619
At time: 136.4027135372162 and batch: 1300, loss is 4.578721132278442 and perplexity is 97.38976590445786
At time: 137.64917397499084 and batch: 1350, loss is 4.460447425842285 and perplexity is 86.52621450118745
At time: 138.89612770080566 and batch: 1400, loss is 4.470452709197998 and perplexity is 87.39627915849593
At time: 140.14274764060974 and batch: 1450, loss is 4.426022882461548 and perplexity is 83.59827471200956
At time: 141.38836026191711 and batch: 1500, loss is 4.4187400436401365 and perplexity is 82.99165359469534
At time: 142.63545060157776 and batch: 1550, loss is 4.421069993972778 and perplexity is 83.18524546774043
At time: 143.88136672973633 and batch: 1600, loss is 4.503065299987793 and perplexity is 90.29348414780246
At time: 145.127281665802 and batch: 1650, loss is 4.46864200592041 and perplexity is 87.23817361368641
At time: 146.3752360343933 and batch: 1700, loss is 4.46980562210083 and perplexity is 87.33974444732578
At time: 147.62118339538574 and batch: 1750, loss is 4.463283987045288 and perplexity is 86.77199983205043
At time: 148.8671271800995 and batch: 1800, loss is 4.418442668914795 and perplexity is 82.96697764368592
At time: 150.1140947341919 and batch: 1850, loss is 4.454108724594116 and perplexity is 85.97948528450448
At time: 151.36081266403198 and batch: 1900, loss is 4.561812038421631 and perplexity is 95.75683778619532
At time: 152.60737824440002 and batch: 1950, loss is 4.4855559539794925 and perplexity is 88.72626482354435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479446198219477 and perplexity of 88.18582168495115
finished 3 epochs...
Completing Train Step...
At time: 156.46997165679932 and batch: 50, loss is 4.459540739059448 and perplexity is 86.44779788115882
At time: 157.71387147903442 and batch: 100, loss is 4.3999074268341065 and perplexity is 81.44332884918872
At time: 158.9388518333435 and batch: 150, loss is 4.348753385543823 and perplexity is 77.38193733093694
At time: 160.18720936775208 and batch: 200, loss is 4.3513883686065675 and perplexity is 77.58610629792024
At time: 161.43472981452942 and batch: 250, loss is 4.36145058631897 and perplexity is 78.37073552582294
At time: 162.68290090560913 and batch: 300, loss is 4.379018878936767 and perplexity is 79.75974104228716
At time: 163.93259644508362 and batch: 350, loss is 4.384950389862061 and perplexity is 80.23424268231763
At time: 165.18218612670898 and batch: 400, loss is 4.32892936706543 and perplexity is 75.86302162501929
At time: 166.438458442688 and batch: 450, loss is 4.345882062911987 and perplexity is 77.16006750534278
At time: 167.6910719871521 and batch: 500, loss is 4.3518111038208005 and perplexity is 77.6189116106795
At time: 168.9443440437317 and batch: 550, loss is 4.317075996398926 and perplexity is 74.96909758284139
At time: 170.19765639305115 and batch: 600, loss is 4.297750020027161 and perplexity is 73.5341570492191
At time: 171.44957566261292 and batch: 650, loss is 4.359392042160034 and perplexity is 78.20957184416484
At time: 172.70159530639648 and batch: 700, loss is 4.387037076950073 and perplexity is 80.40184124260112
At time: 173.95565724372864 and batch: 750, loss is 4.339261026382446 and perplexity is 76.65087542960251
At time: 175.20971775054932 and batch: 800, loss is 4.344139947891235 and perplexity is 77.0257628138172
At time: 176.46070790290833 and batch: 850, loss is 4.339258899688721 and perplexity is 76.65071241684004
At time: 177.7124207019806 and batch: 900, loss is 4.313552503585815 and perplexity is 74.70540933094054
At time: 178.963721036911 and batch: 950, loss is 4.378241443634034 and perplexity is 79.69775710123794
At time: 180.21563363075256 and batch: 1000, loss is 4.36046272277832 and perplexity is 78.29335416095047
At time: 181.46700596809387 and batch: 1050, loss is 4.304316596984863 and perplexity is 74.01861362037116
At time: 182.72473907470703 and batch: 1100, loss is 4.3471817111969 and perplexity is 77.26041364796146
At time: 183.97616600990295 and batch: 1150, loss is 4.3120826148986815 and perplexity is 74.59568135860616
At time: 185.22639536857605 and batch: 1200, loss is 4.374261302947998 and perplexity is 79.38117924573775
At time: 186.50583696365356 and batch: 1250, loss is 4.364412631988525 and perplexity is 78.60321736454146
At time: 187.75665426254272 and batch: 1300, loss is 4.354718370437622 and perplexity is 77.84489882460663
At time: 189.00676918029785 and batch: 1350, loss is 4.2343483161926265 and perplexity is 69.0166870175562
At time: 190.25712132453918 and batch: 1400, loss is 4.2531952381134035 and perplexity is 70.32977408587806
At time: 191.508052110672 and batch: 1450, loss is 4.20155424118042 and perplexity is 66.79005827048509
At time: 192.75850200653076 and batch: 1500, loss is 4.196775560379028 and perplexity is 66.47165128988935
At time: 194.01206994056702 and batch: 1550, loss is 4.208574357032776 and perplexity is 67.26058184998782
At time: 195.26166558265686 and batch: 1600, loss is 4.295803260803223 and perplexity is 73.39114300283308
At time: 196.50531315803528 and batch: 1650, loss is 4.255751876831055 and perplexity is 70.5098119571392
At time: 197.74859189987183 and batch: 1700, loss is 4.256507425308228 and perplexity is 70.5631056686452
At time: 198.99570274353027 and batch: 1750, loss is 4.252649393081665 and perplexity is 70.29139540346944
At time: 200.24273657798767 and batch: 1800, loss is 4.205460295677185 and perplexity is 67.0514540586801
At time: 201.48482131958008 and batch: 1850, loss is 4.249233951568604 and perplexity is 70.0517287702623
At time: 202.72654366493225 and batch: 1900, loss is 4.35539514541626 and perplexity is 77.89760013579858
At time: 203.97575402259827 and batch: 1950, loss is 4.286450634002685 and perplexity is 72.70794286984471
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4295228470203485 and perplexity of 83.8913783376255
finished 4 epochs...
Completing Train Step...
At time: 207.96691012382507 and batch: 50, loss is 4.2632021760940555 and perplexity is 71.03709291869946
At time: 209.14367747306824 and batch: 100, loss is 4.208815755844117 and perplexity is 67.27682043440508
At time: 210.33586621284485 and batch: 150, loss is 4.1601834392547605 and perplexity is 64.08327691036175
At time: 211.53217887878418 and batch: 200, loss is 4.1678515863418575 and perplexity is 64.57656579225207
At time: 212.74167776107788 and batch: 250, loss is 4.172271203994751 and perplexity is 64.86260114023304
At time: 213.96136498451233 and batch: 300, loss is 4.188669815063476 and perplexity is 65.93502682261492
At time: 215.180926322937 and batch: 350, loss is 4.199399180412293 and perplexity is 66.64627662094838
At time: 216.40567803382874 and batch: 400, loss is 4.141206793785095 and perplexity is 62.878657253698144
At time: 217.66399121284485 and batch: 450, loss is 4.170176048278808 and perplexity is 64.72684615428058
At time: 218.90290307998657 and batch: 500, loss is 4.180616574287415 and perplexity is 65.40616854579788
At time: 220.1424868106842 and batch: 550, loss is 4.147999048233032 and perplexity is 63.307198827261935
At time: 221.38187742233276 and batch: 600, loss is 4.130709753036499 and perplexity is 62.22206956911763
At time: 222.62067365646362 and batch: 650, loss is 4.189529709815979 and perplexity is 65.99174838997978
At time: 223.85860323905945 and batch: 700, loss is 4.2207366609573365 and perplexity is 68.08362036546487
At time: 225.1022093296051 and batch: 750, loss is 4.174412264823913 and perplexity is 65.00162469064237
At time: 226.3483808040619 and batch: 800, loss is 4.1759249877929685 and perplexity is 65.10002855146303
At time: 227.59570455551147 and batch: 850, loss is 4.173368606567383 and perplexity is 64.93382059665184
At time: 228.85215091705322 and batch: 900, loss is 4.145319452285767 and perplexity is 63.13778819124585
At time: 230.09972620010376 and batch: 950, loss is 4.222281289100647 and perplexity is 68.18886550295534
At time: 231.34754371643066 and batch: 1000, loss is 4.200776581764221 and perplexity is 66.73813854331146
At time: 232.59444999694824 and batch: 1050, loss is 4.146583051681518 and perplexity is 63.217619489021104
At time: 233.84164810180664 and batch: 1100, loss is 4.185043020248413 and perplexity is 65.69632712825798
At time: 235.08858466148376 and batch: 1150, loss is 4.155170292854309 and perplexity is 63.76282197626856
At time: 236.33736205101013 and batch: 1200, loss is 4.216287589073181 and perplexity is 67.78138427790942
At time: 237.59154200553894 and batch: 1250, loss is 4.214587988853455 and perplexity is 67.6662808648981
At time: 238.843811750412 and batch: 1300, loss is 4.202157640457154 and perplexity is 66.83037150460349
At time: 240.09346961975098 and batch: 1350, loss is 4.080807189941407 and perplexity is 59.19323075169139
At time: 241.34235835075378 and batch: 1400, loss is 4.103109722137451 and perplexity is 60.52822118465309
At time: 242.5913007259369 and batch: 1450, loss is 4.046343684196472 and perplexity is 57.18797701211878
At time: 243.8403663635254 and batch: 1500, loss is 4.049315414428711 and perplexity is 57.35817702132715
At time: 245.08794260025024 and batch: 1550, loss is 4.0615404605865475 and perplexity is 58.06368704260913
At time: 246.33590626716614 and batch: 1600, loss is 4.146635074615478 and perplexity is 63.22090834061199
At time: 247.58330392837524 and batch: 1650, loss is 4.109946517944336 and perplexity is 60.94345810104294
At time: 248.83018732070923 and batch: 1700, loss is 4.109321460723877 and perplexity is 60.90537685523583
At time: 250.07732510566711 and batch: 1750, loss is 4.1087131643295285 and perplexity is 60.86833960005478
At time: 251.3239243030548 and batch: 1800, loss is 4.057728328704834 and perplexity is 57.842761975356964
At time: 252.5714316368103 and batch: 1850, loss is 4.103980107307434 and perplexity is 60.58092698458361
At time: 253.82337641716003 and batch: 1900, loss is 4.209410700798035 and perplexity is 67.31685834823462
At time: 255.06931114196777 and batch: 1950, loss is 4.1437615966796875 and perplexity is 63.039505209180994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416332723928052 and perplexity of 82.79210643433245
finished 5 epochs...
Completing Train Step...
At time: 258.9494149684906 and batch: 50, loss is 4.123187294006348 and perplexity is 61.75576268614606
At time: 260.1677210330963 and batch: 100, loss is 4.070438580513001 and perplexity is 58.5826501672089
At time: 261.3859794139862 and batch: 150, loss is 4.025140962600708 and perplexity is 55.988200467761665
At time: 262.6069679260254 and batch: 200, loss is 4.0339511251449585 and perplexity is 56.48364488270366
At time: 263.8321228027344 and batch: 250, loss is 4.034424047470093 and perplexity is 56.510363576809155
At time: 265.0613474845886 and batch: 300, loss is 4.049662313461304 and perplexity is 57.378077969057315
At time: 266.30043387413025 and batch: 350, loss is 4.061950402259827 and perplexity is 58.08749464716335
At time: 267.5454931259155 and batch: 400, loss is 4.003609123229981 and perplexity is 54.795557504406005
At time: 268.7875032424927 and batch: 450, loss is 4.042611622810364 and perplexity is 56.97494574151499
At time: 270.0363726615906 and batch: 500, loss is 4.05298388004303 and perplexity is 57.568979946662296
At time: 271.276841878891 and batch: 550, loss is 4.019737238883972 and perplexity is 55.68647166479316
At time: 272.5273857116699 and batch: 600, loss is 4.008151698112488 and perplexity is 55.04503663742041
At time: 273.7761461734772 and batch: 650, loss is 4.066535620689392 and perplexity is 58.35445005486366
At time: 275.0258002281189 and batch: 700, loss is 4.090299386978149 and perplexity is 59.75777972738445
At time: 276.27470993995667 and batch: 750, loss is 4.051910066604615 and perplexity is 57.50719478116713
At time: 277.52329421043396 and batch: 800, loss is 4.048868112564087 and perplexity is 57.33252633902075
At time: 278.7922160625458 and batch: 850, loss is 4.050539603233338 and perplexity is 57.42843725661262
At time: 280.0428898334503 and batch: 900, loss is 4.020158977508545 and perplexity is 55.709961753751095
At time: 281.29243063926697 and batch: 950, loss is 4.104262433052063 and perplexity is 60.59803295451907
At time: 282.5417642593384 and batch: 1000, loss is 4.076796436309815 and perplexity is 58.956296746062954
At time: 283.79134702682495 and batch: 1050, loss is 4.030025329589844 and perplexity is 56.26233633098227
At time: 285.04060435295105 and batch: 1100, loss is 4.063199472427368 and perplexity is 58.16009533607253
At time: 286.29067039489746 and batch: 1150, loss is 4.036260104179382 and perplexity is 56.614215118484104
At time: 287.54093980789185 and batch: 1200, loss is 4.0964443349838255 and perplexity is 60.126118729701574
At time: 288.7922718524933 and batch: 1250, loss is 4.096431498527527 and perplexity is 60.1253469283597
At time: 290.04245924949646 and batch: 1300, loss is 4.082497172355652 and perplexity is 59.29335084747576
At time: 291.29275703430176 and batch: 1350, loss is 3.9632468461990356 and perplexity is 52.62792362079924
At time: 292.5426483154297 and batch: 1400, loss is 3.991758952140808 and perplexity is 54.15005299629565
At time: 293.7916555404663 and batch: 1450, loss is 3.9313344860076906 and perplexity is 50.974957667684656
At time: 295.04140758514404 and batch: 1500, loss is 3.933171510696411 and perplexity is 51.06868598768718
At time: 296.2917449474335 and batch: 1550, loss is 3.950124168395996 and perplexity is 51.94181596640765
At time: 297.53990483283997 and batch: 1600, loss is 4.034824447631836 and perplexity is 56.532994866009034
At time: 298.79259395599365 and batch: 1650, loss is 3.998508529663086 and perplexity is 54.51677920808936
At time: 300.0503656864166 and batch: 1700, loss is 3.998575782775879 and perplexity is 54.5204457544825
At time: 301.300434589386 and batch: 1750, loss is 3.993697638511658 and perplexity is 54.2551347934318
At time: 302.5496609210968 and batch: 1800, loss is 3.9459127378463745 and perplexity is 51.72352659374453
At time: 303.79833483695984 and batch: 1850, loss is 3.989827013015747 and perplexity is 54.045539379767554
At time: 305.0473253726959 and batch: 1900, loss is 4.096002550125122 and perplexity is 60.09956178749359
At time: 306.30347537994385 and batch: 1950, loss is 4.034483933448792 and perplexity is 56.51374785657301
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.415404421784157 and perplexity of 82.7152860062325
finished 6 epochs...
Completing Train Step...
At time: 310.1794214248657 and batch: 50, loss is 4.0153227090835575 and perplexity is 55.441183889594335
At time: 311.38781809806824 and batch: 100, loss is 3.9630927228927613 and perplexity is 52.61981305623802
At time: 312.60531520843506 and batch: 150, loss is 3.9190080261230467 and perplexity is 50.350473642587
At time: 313.8369379043579 and batch: 200, loss is 3.9289314270019533 and perplexity is 50.852608901124114
At time: 315.08457612991333 and batch: 250, loss is 3.926388311386108 and perplexity is 50.72344914103366
At time: 316.3344421386719 and batch: 300, loss is 3.9398311519622804 and perplexity is 51.4099201035172
At time: 317.5833058357239 and batch: 350, loss is 3.9540636491775514 and perplexity is 52.14684333770058
At time: 318.83228302001953 and batch: 400, loss is 3.8959294414520262 and perplexity is 49.20176227488553
At time: 320.0806932449341 and batch: 450, loss is 3.9368942832946776 and perplexity is 51.25915741343474
At time: 321.3293333053589 and batch: 500, loss is 3.9503202199935914 and perplexity is 51.95200024069888
At time: 322.57590675354004 and batch: 550, loss is 3.92208710193634 and perplexity is 50.50574549239247
At time: 323.82465863227844 and batch: 600, loss is 3.9109200382232667 and perplexity is 49.94488204199382
At time: 325.07386898994446 and batch: 650, loss is 3.961156139373779 and perplexity is 52.518009001345604
At time: 326.32288217544556 and batch: 700, loss is 3.992885499000549 and perplexity is 54.21108994248827
At time: 327.5721242427826 and batch: 750, loss is 3.9558322715759275 and perplexity is 52.23915301925519
At time: 328.8198754787445 and batch: 800, loss is 3.9490765285491944 and perplexity is 51.88742814468507
At time: 330.0675120353699 and batch: 850, loss is 3.9525200653076173 and perplexity is 52.06641240337287
At time: 331.31442308425903 and batch: 900, loss is 3.9240516233444214 and perplexity is 50.605062634027256
At time: 332.5642981529236 and batch: 950, loss is 4.010185894966125 and perplexity is 55.15712304201167
At time: 333.8136909008026 and batch: 1000, loss is 3.977254581451416 and perplexity is 53.370309072198815
At time: 335.06269097328186 and batch: 1050, loss is 3.935887451171875 and perplexity is 51.20757401942971
At time: 336.31194281578064 and batch: 1100, loss is 3.9677052211761477 and perplexity is 52.863082462191635
At time: 337.56125378608704 and batch: 1150, loss is 3.9428904628753663 and perplexity is 51.56743986123037
At time: 338.80890917778015 and batch: 1200, loss is 4.003043513298035 and perplexity is 54.76457335615202
At time: 340.057834148407 and batch: 1250, loss is 4.003754930496216 and perplexity is 54.803547677346025
At time: 341.3086814880371 and batch: 1300, loss is 3.989877142906189 and perplexity is 54.04824874464504
At time: 342.5583338737488 and batch: 1350, loss is 3.8694837522506713 and perplexity is 47.91764231941269
At time: 343.80678033828735 and batch: 1400, loss is 3.897004508972168 and perplexity is 49.2546859345975
At time: 345.0549850463867 and batch: 1450, loss is 3.8400255107879637 and perplexity is 46.52666135644208
At time: 346.30462646484375 and batch: 1500, loss is 3.841634120941162 and perplexity is 46.60156484539904
At time: 347.55355954170227 and batch: 1550, loss is 3.862459592819214 and perplexity is 47.582240497144454
At time: 348.8024561405182 and batch: 1600, loss is 3.947775192260742 and perplexity is 51.81994906753467
At time: 350.0514647960663 and batch: 1650, loss is 3.9101428270339964 and perplexity is 49.90607940170036
At time: 351.30036759376526 and batch: 1700, loss is 3.907893805503845 and perplexity is 49.793965674989934
At time: 352.5492899417877 and batch: 1750, loss is 3.9024446964263917 and perplexity is 49.52337084456063
At time: 353.79668283462524 and batch: 1800, loss is 3.8524881172180176 and perplexity is 47.11013306266878
At time: 355.0446653366089 and batch: 1850, loss is 3.901582841873169 and perplexity is 49.480707289437774
At time: 356.29335618019104 and batch: 1900, loss is 4.0041638851165775 and perplexity is 54.82596442478468
At time: 357.5409333705902 and batch: 1950, loss is 3.9448798847198487 and perplexity is 51.67013136704743
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.426648516987646 and perplexity of 83.65059304336229
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 361.4036293029785 and batch: 50, loss is 3.969138650894165 and perplexity is 52.93891231097422
At time: 362.64205598831177 and batch: 100, loss is 3.9528750133514405 and perplexity is 52.08489655486698
At time: 363.86175417900085 and batch: 150, loss is 3.9143476247787476 and perplexity is 50.11636616865162
At time: 365.1014132499695 and batch: 200, loss is 3.921269998550415 and perplexity is 50.46449393243178
At time: 366.34830021858215 and batch: 250, loss is 3.914963150024414 and perplexity is 50.14722355302479
At time: 367.5935904979706 and batch: 300, loss is 3.9295142984390257 and perplexity is 50.88225807434188
At time: 368.8382918834686 and batch: 350, loss is 3.9403087186813353 and perplexity is 51.43447763385077
At time: 370.0831263065338 and batch: 400, loss is 3.8820862007141113 and perplexity is 48.525343153468114
At time: 371.3283338546753 and batch: 450, loss is 3.9103253698349 and perplexity is 49.9151902287491
At time: 372.59302043914795 and batch: 500, loss is 3.9144837760925295 and perplexity is 50.1231900422766
At time: 373.844331741333 and batch: 550, loss is 3.884947967529297 and perplexity is 48.66441026411145
At time: 375.0913178920746 and batch: 600, loss is 3.86367871761322 and perplexity is 47.64028456057825
At time: 376.3376820087433 and batch: 650, loss is 3.909769401550293 and perplexity is 49.887446679043286
At time: 377.5841624736786 and batch: 700, loss is 3.9422908210754395 and perplexity is 51.536527137981146
At time: 378.8369359970093 and batch: 750, loss is 3.8920080614089967 and perplexity is 49.00920126542307
At time: 380.0841979980469 and batch: 800, loss is 3.8771592950820923 and perplexity is 48.286851362700084
At time: 381.32998514175415 and batch: 850, loss is 3.878459997177124 and perplexity is 48.34969903561933
At time: 382.5760250091553 and batch: 900, loss is 3.8360544633865357 and perplexity is 46.34226813818189
At time: 383.82321882247925 and batch: 950, loss is 3.92592661857605 and perplexity is 50.70003589454357
At time: 385.068660736084 and batch: 1000, loss is 3.8862589597702026 and perplexity is 48.728250766433995
At time: 386.3150486946106 and batch: 1050, loss is 3.831482391357422 and perplexity is 46.13087157865995
At time: 387.56642961502075 and batch: 1100, loss is 3.8501360416412354 and perplexity is 46.99945667990572
At time: 388.81289649009705 and batch: 1150, loss is 3.831499581336975 and perplexity is 46.13166457421492
At time: 390.0563156604767 and batch: 1200, loss is 3.8724627161026 and perplexity is 48.06060007101913
At time: 391.3007164001465 and batch: 1250, loss is 3.861691927909851 and perplexity is 47.545727297550094
At time: 392.547287940979 and batch: 1300, loss is 3.8436179113388063 and perplexity is 46.6941043413878
At time: 393.7925593852997 and batch: 1350, loss is 3.7247494888305663 and perplexity is 41.460845038990485
At time: 395.0386805534363 and batch: 1400, loss is 3.7435048627853393 and perplexity is 42.2457967135942
At time: 396.28616642951965 and batch: 1450, loss is 3.687727327346802 and perplexity is 39.953941467043784
At time: 397.53330850601196 and batch: 1500, loss is 3.674376244544983 and perplexity is 39.424058214858974
At time: 398.77922224998474 and batch: 1550, loss is 3.693770728111267 and perplexity is 40.19613023221837
At time: 400.0243947505951 and batch: 1600, loss is 3.7660953521728517 and perplexity is 43.2110112221479
At time: 401.27105498313904 and batch: 1650, loss is 3.7259641695022583 and perplexity is 41.51123732516343
At time: 402.51723051071167 and batch: 1700, loss is 3.7075833559036253 and perplexity is 40.755196617152144
At time: 403.76464915275574 and batch: 1750, loss is 3.6835754537582397 and perplexity is 39.788401640722824
At time: 405.0111186504364 and batch: 1800, loss is 3.6266471004486083 and perplexity is 37.58658107706815
At time: 406.2582776546478 and batch: 1850, loss is 3.6645374393463133 and perplexity is 39.03807450885262
At time: 407.50957107543945 and batch: 1900, loss is 3.7603015184402464 and perplexity is 42.96137767366448
At time: 408.75792050361633 and batch: 1950, loss is 3.7013321590423582 and perplexity is 40.50122250811009
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3700746048328485 and perplexity of 79.04952895647433
finished 8 epochs...
Completing Train Step...
At time: 412.6333022117615 and batch: 50, loss is 3.8886383724212648 and perplexity is 48.84433343228578
At time: 413.89547514915466 and batch: 100, loss is 3.854878706932068 and perplexity is 47.22288878483158
At time: 415.14099764823914 and batch: 150, loss is 3.8100816917419436 and perplexity is 45.15412743497997
At time: 416.3840172290802 and batch: 200, loss is 3.8140355253219607 and perplexity is 45.33301274864905
At time: 417.6278417110443 and batch: 250, loss is 3.8047068119049072 and perplexity is 44.912080495193145
At time: 418.8846414089203 and batch: 300, loss is 3.816954174041748 and perplexity is 45.46551716112725
At time: 420.1357877254486 and batch: 350, loss is 3.831031231880188 and perplexity is 46.110063892899426
At time: 421.3846445083618 and batch: 400, loss is 3.772514204978943 and perplexity is 43.48926843343811
At time: 422.63374948501587 and batch: 450, loss is 3.8114967584609984 and perplexity is 45.21806876789752
At time: 423.88390350341797 and batch: 500, loss is 3.8184136724472046 and perplexity is 45.53192245835219
At time: 425.13718843460083 and batch: 550, loss is 3.792082486152649 and perplexity is 44.3486596478142
At time: 426.3902826309204 and batch: 600, loss is 3.7740016317367555 and perplexity is 43.55400366750815
At time: 427.64072370529175 and batch: 650, loss is 3.820165205001831 and perplexity is 45.611742986532974
At time: 428.89037346839905 and batch: 700, loss is 3.854661478996277 and perplexity is 47.21263176827437
At time: 430.1407606601715 and batch: 750, loss is 3.8081051015853884 and perplexity is 45.06496437960227
At time: 431.39044666290283 and batch: 800, loss is 3.7950057983398438 and perplexity is 44.47849430620676
At time: 432.6400570869446 and batch: 850, loss is 3.7999895429611206 and perplexity is 44.70071705372064
At time: 433.891863822937 and batch: 900, loss is 3.7580057334899903 and perplexity is 42.86286071949989
At time: 435.1617476940155 and batch: 950, loss is 3.850293016433716 and perplexity is 47.00683498895386
At time: 436.41205382347107 and batch: 1000, loss is 3.8137810468673705 and perplexity is 45.32147794136507
At time: 437.6615695953369 and batch: 1050, loss is 3.7649676179885865 and perplexity is 43.16230815487459
At time: 438.9115526676178 and batch: 1100, loss is 3.783025984764099 and perplexity is 43.948829215411074
At time: 440.1616680622101 and batch: 1150, loss is 3.766422514915466 and perplexity is 43.225150567897934
At time: 441.4115355014801 and batch: 1200, loss is 3.8119401645660402 and perplexity is 45.23812318144353
At time: 442.6609628200531 and batch: 1250, loss is 3.8031718349456787 and perplexity is 44.84319436927558
At time: 443.910968542099 and batch: 1300, loss is 3.787565965652466 and perplexity is 44.14880967034678
At time: 445.1601994037628 and batch: 1350, loss is 3.6688604736328125 and perplexity is 39.20720275363602
At time: 446.4123373031616 and batch: 1400, loss is 3.6934696292877196 and perplexity is 40.184029046612096
At time: 447.6680099964142 and batch: 1450, loss is 3.6384980392456057 and perplexity is 38.034667225494594
At time: 448.9184696674347 and batch: 1500, loss is 3.629058737754822 and perplexity is 37.677335667799305
At time: 450.1670792102814 and batch: 1550, loss is 3.652449579238892 and perplexity is 38.569028318953215
At time: 451.4163467884064 and batch: 1600, loss is 3.731220006942749 and perplexity is 41.729987995920204
At time: 452.6665370464325 and batch: 1650, loss is 3.691654324531555 and perplexity is 40.11114895736192
At time: 453.916867017746 and batch: 1700, loss is 3.6770220518112184 and perplexity is 39.52850478636751
At time: 455.167608499527 and batch: 1750, loss is 3.6587230730056763 and perplexity is 38.811751442639796
At time: 456.4187285900116 and batch: 1800, loss is 3.603334412574768 and perplexity is 36.72047173835156
At time: 457.66817116737366 and batch: 1850, loss is 3.6465949630737304 and perplexity is 38.34388118042575
At time: 458.9187469482422 and batch: 1900, loss is 3.7446806955337526 and perplexity is 42.295499920455455
At time: 460.16960406303406 and batch: 1950, loss is 3.6873687267303468 and perplexity is 39.93961652762346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.374425417877907 and perplexity of 79.39420795147909
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 464.0634913444519 and batch: 50, loss is 3.865693440437317 and perplexity is 47.73636328272664
At time: 465.3190906047821 and batch: 100, loss is 3.8653269147872926 and perplexity is 47.71886988722955
At time: 466.55285692214966 and batch: 150, loss is 3.8350004959106445 and perplexity is 46.293450625359675
At time: 467.79473900794983 and batch: 200, loss is 3.844670600891113 and perplexity is 46.74328461842259
At time: 469.0435938835144 and batch: 250, loss is 3.8383465576171876 and perplexity is 46.44861081077224
At time: 470.29335618019104 and batch: 300, loss is 3.849588656425476 and perplexity is 46.97373691212294
At time: 471.54200196266174 and batch: 350, loss is 3.873728885650635 and perplexity is 48.121491480578584
At time: 472.7905979156494 and batch: 400, loss is 3.817380437850952 and perplexity is 45.48490159680796
At time: 474.0373914241791 and batch: 450, loss is 3.847360816001892 and perplexity is 46.869203407402715
At time: 475.28814697265625 and batch: 500, loss is 3.8483004188537597 and perplexity is 46.91326254039111
At time: 476.54082012176514 and batch: 550, loss is 3.820323724746704 and perplexity is 45.61897392150226
At time: 477.78928995132446 and batch: 600, loss is 3.7933245706558227 and perplexity is 44.40377865484516
At time: 479.03831481933594 and batch: 650, loss is 3.837365107536316 and perplexity is 46.40304618129776
At time: 480.2890181541443 and batch: 700, loss is 3.8766070985794068 and perplexity is 48.26019489273399
At time: 481.5409457683563 and batch: 750, loss is 3.831303496360779 and perplexity is 46.122619734672554
At time: 482.7887237071991 and batch: 800, loss is 3.813730697631836 and perplexity is 45.319196097042465
At time: 484.0372042655945 and batch: 850, loss is 3.8203082513809203 and perplexity is 45.618268047893224
At time: 485.2855463027954 and batch: 900, loss is 3.7726695203781127 and perplexity is 43.49602351109467
At time: 486.54727029800415 and batch: 950, loss is 3.864920835494995 and perplexity is 47.69949617621417
At time: 487.79634284973145 and batch: 1000, loss is 3.8173845386505127 and perplexity is 45.4850881216549
At time: 489.04484391212463 and batch: 1050, loss is 3.761634793281555 and perplexity is 43.018695199181366
At time: 490.29464292526245 and batch: 1100, loss is 3.7818662548065185 and perplexity is 43.89788998515437
At time: 491.5429964065552 and batch: 1150, loss is 3.7642588901519773 and perplexity is 43.13172866314143
At time: 492.79087686538696 and batch: 1200, loss is 3.8005120038986204 and perplexity is 44.72407753419733
At time: 494.04458928108215 and batch: 1250, loss is 3.7919133567810057 and perplexity is 44.341159621130025
At time: 495.2933247089386 and batch: 1300, loss is 3.77200484752655 and perplexity is 43.46712249104164
At time: 496.54230189323425 and batch: 1350, loss is 3.6459281492233275 and perplexity is 38.31832147210727
At time: 497.7898783683777 and batch: 1400, loss is 3.6709980010986327 and perplexity is 39.291098859551624
At time: 499.038405418396 and batch: 1450, loss is 3.603319902420044 and perplexity is 36.71993892249073
At time: 500.2856924533844 and batch: 1500, loss is 3.5947915506362915 and perplexity is 36.4081099494844
At time: 501.53425669670105 and batch: 1550, loss is 3.619186758995056 and perplexity is 37.30721572433392
At time: 502.7825174331665 and batch: 1600, loss is 3.694371738433838 and perplexity is 40.220295782560534
At time: 504.03069949150085 and batch: 1650, loss is 3.650432367324829 and perplexity is 38.491304834239756
At time: 505.27833819389343 and batch: 1700, loss is 3.628851466178894 and perplexity is 37.66952703634032
At time: 506.5337634086609 and batch: 1750, loss is 3.6094836378097535 and perplexity is 36.946969870105846
At time: 507.7854492664337 and batch: 1800, loss is 3.5549155712127685 and perplexity is 34.98486611318276
At time: 509.0368437767029 and batch: 1850, loss is 3.5902621030807493 and perplexity is 36.24357423411838
At time: 510.2838182449341 and batch: 1900, loss is 3.6918338680267335 and perplexity is 40.11835129978886
At time: 511.5323805809021 and batch: 1950, loss is 3.6423032760620115 and perplexity is 38.179673858838164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3487733353015985 and perplexity of 77.38348109724173
finished 10 epochs...
Completing Train Step...
At time: 515.4218499660492 and batch: 50, loss is 3.862766828536987 and perplexity is 47.59686170692078
At time: 516.6518795490265 and batch: 100, loss is 3.8352960538864136 and perplexity is 46.307135046088106
At time: 517.8923254013062 and batch: 150, loss is 3.7945419359207153 and perplexity is 44.45786718868087
At time: 519.1338622570038 and batch: 200, loss is 3.797840428352356 and perplexity is 44.60475324522523
At time: 520.3807187080383 and batch: 250, loss is 3.789840884208679 and perplexity is 44.24935894404085
At time: 521.6288785934448 and batch: 300, loss is 3.797990403175354 and perplexity is 44.611443336858166
At time: 522.8775236606598 and batch: 350, loss is 3.8211683559417726 and perplexity is 45.65752140687604
At time: 524.1261837482452 and batch: 400, loss is 3.76498028755188 and perplexity is 43.16285500593383
At time: 525.3748240470886 and batch: 450, loss is 3.797850637435913 and perplexity is 44.60520862120263
At time: 526.6251912117004 and batch: 500, loss is 3.800910248756409 and perplexity is 44.74189221516174
At time: 527.8953845500946 and batch: 550, loss is 3.7748631477355956 and perplexity is 43.59154230622836
At time: 529.144612789154 and batch: 600, loss is 3.751876459121704 and perplexity is 42.60094597955886
At time: 530.3953304290771 and batch: 650, loss is 3.7951980304718016 and perplexity is 44.487045323857366
At time: 531.6444141864777 and batch: 700, loss is 3.8373412799835207 and perplexity is 46.40194052343763
At time: 532.8947424888611 and batch: 750, loss is 3.79231746673584 and perplexity is 44.3590819461929
At time: 534.1462996006012 and batch: 800, loss is 3.7756654691696165 and perplexity is 43.62653076908263
At time: 535.401597738266 and batch: 850, loss is 3.7828936052322386 and perplexity is 43.943011675043856
At time: 536.6504561901093 and batch: 900, loss is 3.7351200008392333 and perplexity is 41.89305246293419
At time: 537.8983294963837 and batch: 950, loss is 3.828257694244385 and perplexity is 45.98235308254076
At time: 539.1472072601318 and batch: 1000, loss is 3.784081907272339 and perplexity is 43.99526028288093
At time: 540.3969089984894 and batch: 1050, loss is 3.7318868112564085 and perplexity is 41.75782301114761
At time: 541.6454191207886 and batch: 1100, loss is 3.7526916790008547 and perplexity is 42.63568927738139
At time: 542.8950352668762 and batch: 1150, loss is 3.7369284868240356 and perplexity is 41.96888401065159
At time: 544.1432175636292 and batch: 1200, loss is 3.7750639724731445 and perplexity is 43.6002974453662
At time: 545.3923916816711 and batch: 1250, loss is 3.7695089960098267 and perplexity is 43.35877027920719
At time: 546.6424467563629 and batch: 1300, loss is 3.751986255645752 and perplexity is 42.60562367214107
At time: 547.8923330307007 and batch: 1350, loss is 3.6275574922561646 and perplexity is 37.62081517341072
At time: 549.1424221992493 and batch: 1400, loss is 3.655564522743225 and perplexity is 38.68935597281203
At time: 550.392655134201 and batch: 1450, loss is 3.5904704189300536 and perplexity is 36.25112513152527
At time: 551.6428561210632 and batch: 1500, loss is 3.5837546586990356 and perplexity is 36.0084869289765
At time: 552.8920922279358 and batch: 1550, loss is 3.611121263504028 and perplexity is 37.00752474686868
At time: 554.1437866687775 and batch: 1600, loss is 3.6896381425857543 and perplexity is 40.0303590539486
At time: 555.3923766613007 and batch: 1650, loss is 3.6464933824539183 and perplexity is 38.339986383030755
At time: 556.6478624343872 and batch: 1700, loss is 3.6271981048583983 and perplexity is 37.607297155791784
At time: 557.897943019867 and batch: 1750, loss is 3.609506573677063 and perplexity is 36.947817290622396
At time: 559.1469194889069 and batch: 1800, loss is 3.557024564743042 and perplexity is 35.05872682798097
At time: 560.3957579135895 and batch: 1850, loss is 3.593923192024231 and perplexity is 36.37650837639575
At time: 561.6445782184601 and batch: 1900, loss is 3.6959629964828493 and perplexity is 40.28434759992764
At time: 562.8947887420654 and batch: 1950, loss is 3.6462093353271485 and perplexity is 38.329097566599984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348622592659884 and perplexity of 77.37181698603759
finished 11 epochs...
Completing Train Step...
At time: 566.7894370555878 and batch: 50, loss is 3.844791603088379 and perplexity is 46.7489410007793
At time: 568.0134885311127 and batch: 100, loss is 3.814500494003296 and perplexity is 45.354096080972504
At time: 569.2507195472717 and batch: 150, loss is 3.7731059408187866 and perplexity is 43.51501020763282
At time: 570.4903585910797 and batch: 200, loss is 3.7753751850128174 and perplexity is 43.61386851629886
At time: 571.7327029705048 and batch: 250, loss is 3.7669437885284425 and perplexity is 43.24768857202898
At time: 572.9791700839996 and batch: 300, loss is 3.7744189167022704 and perplexity is 43.57218189091246
At time: 574.2251472473145 and batch: 350, loss is 3.797360563278198 and perplexity is 44.58335411675923
At time: 575.4725451469421 and batch: 400, loss is 3.740198860168457 and perplexity is 42.10636261085821
At time: 576.7193400859833 and batch: 450, loss is 3.774251046180725 and perplexity is 43.564868019922415
At time: 577.9674787521362 and batch: 500, loss is 3.7782044649124145 and perplexity is 43.73743908326629
At time: 579.2147536277771 and batch: 550, loss is 3.7526441383361817 and perplexity is 42.633662396554364
At time: 580.4617595672607 and batch: 600, loss is 3.7311421060562133 and perplexity is 41.72673731947713
At time: 581.7092080116272 and batch: 650, loss is 3.774182777404785 and perplexity is 43.56189400122617
At time: 582.9566373825073 and batch: 700, loss is 3.817260184288025 and perplexity is 45.47943220419512
At time: 584.2042074203491 and batch: 750, loss is 3.7726669025421145 and perplexity is 43.495909645787584
At time: 585.4521245956421 and batch: 800, loss is 3.75597216129303 and perplexity is 42.77578456548944
At time: 586.6991374492645 and batch: 850, loss is 3.763774118423462 and perplexity is 43.11082468772106
At time: 587.9454395771027 and batch: 900, loss is 3.7160697555541993 and perplexity is 41.10253323760367
At time: 589.2188200950623 and batch: 950, loss is 3.8095442628860474 and perplexity is 45.12986682369382
At time: 590.4647748470306 and batch: 1000, loss is 3.7662496614456176 and perplexity is 43.21767959634782
At time: 591.7163088321686 and batch: 1050, loss is 3.7157326555252075 and perplexity is 41.08867990756781
At time: 592.9656159877777 and batch: 1100, loss is 3.7366550254821775 and perplexity is 41.9574087124105
At time: 594.2126016616821 and batch: 1150, loss is 3.7214503145217894 and perplexity is 41.32428387762247
At time: 595.4596521854401 and batch: 1200, loss is 3.760238127708435 and perplexity is 42.95865440680998
At time: 596.706689119339 and batch: 1250, loss is 3.7561115026474 and perplexity is 42.78174541653192
At time: 597.9546012878418 and batch: 1300, loss is 3.7391841268539427 and perplexity is 42.06365755275093
At time: 599.2010343074799 and batch: 1350, loss is 3.6156140899658205 and perplexity is 37.17416720083707
At time: 600.4480617046356 and batch: 1400, loss is 3.644595355987549 and perplexity is 38.2672850904698
At time: 601.6946866512299 and batch: 1450, loss is 3.5802815628051756 and perplexity is 35.883642923973056
At time: 602.9414649009705 and batch: 1500, loss is 3.574133024215698 and perplexity is 35.66368785478043
At time: 604.1894545555115 and batch: 1550, loss is 3.6025592470169068 and perplexity is 36.69201832287018
At time: 605.4423851966858 and batch: 1600, loss is 3.68279483795166 and perplexity is 39.7573543050806
At time: 606.6893272399902 and batch: 1650, loss is 3.6397628355026246 and perplexity is 38.082803765278996
At time: 607.935394525528 and batch: 1700, loss is 3.621377730369568 and perplexity is 37.38904437543087
At time: 609.181399345398 and batch: 1750, loss is 3.6044046878814697 and perplexity is 36.759793791461206
At time: 610.4291553497314 and batch: 1800, loss is 3.552917366027832 and perplexity is 34.91502897002915
At time: 611.6776542663574 and batch: 1850, loss is 3.590365195274353 and perplexity is 36.24731085629519
At time: 612.9284255504608 and batch: 1900, loss is 3.692451615333557 and perplexity is 40.14314195965183
At time: 614.1773896217346 and batch: 1950, loss is 3.642785544395447 and perplexity is 38.19809114720169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350346339026163 and perplexity of 77.50530138799424
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 618.0808534622192 and batch: 50, loss is 3.841885142326355 and perplexity is 46.6132643031043
At time: 619.3122079372406 and batch: 100, loss is 3.831593198776245 and perplexity is 46.13598350468208
At time: 620.5643594264984 and batch: 150, loss is 3.8007166719436647 and perplexity is 44.7332320605002
At time: 621.8084659576416 and batch: 200, loss is 3.810112266540527 and perplexity is 45.15550803443718
At time: 623.0565838813782 and batch: 250, loss is 3.806761898994446 and perplexity is 45.0044736374424
At time: 624.3058643341064 and batch: 300, loss is 3.811019334793091 and perplexity is 45.19648574418378
At time: 625.5551369190216 and batch: 350, loss is 3.838494725227356 and perplexity is 46.455493500314944
At time: 626.805374622345 and batch: 400, loss is 3.790267572402954 and perplexity is 44.268243651760905
At time: 628.0523409843445 and batch: 450, loss is 3.8241405868530274 and perplexity is 45.79342797613429
At time: 629.3024272918701 and batch: 500, loss is 3.8272027015686034 and perplexity is 45.93386761722595
At time: 630.5516533851624 and batch: 550, loss is 3.799940614700317 and perplexity is 44.69852997888386
At time: 631.8017916679382 and batch: 600, loss is 3.764921536445618 and perplexity is 43.16031921494378
At time: 633.0513203144073 and batch: 650, loss is 3.7973207426071167 and perplexity is 44.58157881302637
At time: 634.3013093471527 and batch: 700, loss is 3.8374740982055666 and perplexity is 46.40810395597644
At time: 635.5502052307129 and batch: 750, loss is 3.797534604072571 and perplexity is 44.591114114384
At time: 636.8009343147278 and batch: 800, loss is 3.7845544528961184 and perplexity is 44.016054963425326
At time: 638.0498204231262 and batch: 850, loss is 3.795913887023926 and perplexity is 44.51890306816414
At time: 639.2998433113098 and batch: 900, loss is 3.7450848388671876 and perplexity is 42.312596819348755
At time: 640.5484251976013 and batch: 950, loss is 3.8455604410171507 and perplexity is 46.78489718021669
At time: 641.7964024543762 and batch: 1000, loss is 3.7981046342849734 and perplexity is 44.61653964260505
At time: 643.0448892116547 and batch: 1050, loss is 3.7425233364105224 and perplexity is 42.204351692912425
At time: 644.295459985733 and batch: 1100, loss is 3.757460289001465 and perplexity is 42.83948778325711
At time: 645.5456733703613 and batch: 1150, loss is 3.7454002571105955 and perplexity is 42.32594508934481
At time: 646.7964515686035 and batch: 1200, loss is 3.7740494537353517 and perplexity is 43.55608655681396
At time: 648.0455811023712 and batch: 1250, loss is 3.7667490243911743 and perplexity is 43.23926629348094
At time: 649.2942497730255 and batch: 1300, loss is 3.748587007522583 and perplexity is 42.46104245876449
At time: 650.5519843101501 and batch: 1350, loss is 3.618859553337097 and perplexity is 37.295010589169756
At time: 651.8014566898346 and batch: 1400, loss is 3.64638277053833 and perplexity is 38.33574575822944
At time: 653.0518107414246 and batch: 1450, loss is 3.5770131158828735 and perplexity is 35.76655060095754
At time: 654.3015160560608 and batch: 1500, loss is 3.56887216091156 and perplexity is 35.47655873002035
At time: 655.5512347221375 and batch: 1550, loss is 3.5980863046646117 and perplexity is 36.52826354598406
At time: 656.8006126880646 and batch: 1600, loss is 3.6784913301467896 and perplexity is 39.58662584964133
At time: 658.0505537986755 and batch: 1650, loss is 3.6304986381530764 and perplexity is 37.73162635564393
At time: 659.2988233566284 and batch: 1700, loss is 3.615750956535339 and perplexity is 37.17925544977421
At time: 660.5473718643188 and batch: 1750, loss is 3.5926064109802245 and perplexity is 36.32864000271873
At time: 661.7956545352936 and batch: 1800, loss is 3.5393290376663207 and perplexity is 34.443800942926444
At time: 663.0455124378204 and batch: 1850, loss is 3.5762906503677367 and perplexity is 35.740719833595826
At time: 664.29532122612 and batch: 1900, loss is 3.681792697906494 and perplexity is 39.71753182542517
At time: 665.5444481372833 and batch: 1950, loss is 3.6404627323150636 and perplexity is 38.10946712795589
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337959608920785 and perplexity of 76.55118552502836
finished 13 epochs...
Completing Train Step...
At time: 669.4188630580902 and batch: 50, loss is 3.8559606409072877 and perplexity is 47.2740084816977
At time: 670.6647212505341 and batch: 100, loss is 3.8282278776168823 and perplexity is 45.980982064286884
At time: 671.9147772789001 and batch: 150, loss is 3.7880002069473266 and perplexity is 44.1679850696984
At time: 673.1666746139526 and batch: 200, loss is 3.7898683595657348 and perplexity is 44.250574727679286
At time: 674.4170355796814 and batch: 250, loss is 3.784077706336975 and perplexity is 43.99507546202437
At time: 675.6658596992493 and batch: 300, loss is 3.786373372077942 and perplexity is 44.09618946710591
At time: 676.9152836799622 and batch: 350, loss is 3.810629014968872 and perplexity is 45.178848102197385
At time: 678.163969039917 and batch: 400, loss is 3.762328953742981 and perplexity is 43.04856744335666
At time: 679.4125511646271 and batch: 450, loss is 3.798945894241333 and perplexity is 44.65408954319702
At time: 680.6618800163269 and batch: 500, loss is 3.80311990737915 and perplexity is 44.840865831774785
At time: 681.909740447998 and batch: 550, loss is 3.7757562446594237 and perplexity is 43.630491168532664
At time: 683.1786639690399 and batch: 600, loss is 3.74371826171875 and perplexity is 42.254812883540275
At time: 684.4264974594116 and batch: 650, loss is 3.7779260635375977 and perplexity is 43.72526421492323
At time: 685.6768267154694 and batch: 700, loss is 3.82098961353302 and perplexity is 45.649361200831265
At time: 686.9255440235138 and batch: 750, loss is 3.781379361152649 and perplexity is 43.876521583594034
At time: 688.172075510025 and batch: 800, loss is 3.76884259223938 and perplexity is 43.32988545675746
At time: 689.4229025840759 and batch: 850, loss is 3.779856686592102 and perplexity is 43.809762759253736
At time: 690.6725623607635 and batch: 900, loss is 3.728776717185974 and perplexity is 41.62815399933936
At time: 691.9231324195862 and batch: 950, loss is 3.829941625595093 and perplexity is 46.0598494394357
At time: 693.1724433898926 and batch: 1000, loss is 3.784061379432678 and perplexity is 43.99435716450156
At time: 694.4226162433624 and batch: 1050, loss is 3.727630352973938 and perplexity is 41.58046031577045
At time: 695.674084186554 and batch: 1100, loss is 3.7437057638168336 and perplexity is 42.254284790333394
At time: 696.9249427318573 and batch: 1150, loss is 3.7326611185073855 and perplexity is 41.79016891750898
At time: 698.1739082336426 and batch: 1200, loss is 3.762942314147949 and perplexity is 43.07497982944487
At time: 699.4246435165405 and batch: 1250, loss is 3.7573464822769167 and perplexity is 42.83461263888854
At time: 700.6763141155243 and batch: 1300, loss is 3.7409702014923094 and perplexity is 42.13885351751565
At time: 701.927540063858 and batch: 1350, loss is 3.61321186542511 and perplexity is 37.08497367843323
At time: 703.1809928417206 and batch: 1400, loss is 3.6426383543014524 and perplexity is 38.19246918033439
At time: 704.432454586029 and batch: 1450, loss is 3.574796075820923 and perplexity is 35.68734256153979
At time: 705.6896643638611 and batch: 1500, loss is 3.5683924627304076 and perplexity is 35.459544770433006
At time: 706.9408152103424 and batch: 1550, loss is 3.598834991455078 and perplexity is 36.555622014563696
At time: 708.1918709278107 and batch: 1600, loss is 3.6802461099624635 and perplexity is 39.65615264592141
At time: 709.442461013794 and batch: 1650, loss is 3.6333323383331297 and perplexity is 37.8386981050118
At time: 710.6915633678436 and batch: 1700, loss is 3.619439401626587 and perplexity is 37.31664230821794
At time: 711.9414303302765 and batch: 1750, loss is 3.597540159225464 and perplexity is 36.50831924818782
At time: 713.191771030426 and batch: 1800, loss is 3.5451443195343018 and perplexity is 34.64468488627506
At time: 714.4425234794617 and batch: 1850, loss is 3.582587571144104 and perplexity is 35.96648638593272
At time: 715.693820476532 and batch: 1900, loss is 3.6882531023025513 and perplexity is 39.9749537722385
At time: 716.9442894458771 and batch: 1950, loss is 3.6455474853515626 and perplexity is 38.30373784740179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336532805686773 and perplexity of 76.44203992911473
finished 14 epochs...
Completing Train Step...
At time: 720.8584887981415 and batch: 50, loss is 3.8517126703262328 and perplexity is 47.07361581683602
At time: 722.1067113876343 and batch: 100, loss is 3.821382794380188 and perplexity is 45.66731318429766
At time: 723.34596824646 and batch: 150, loss is 3.7803300762176515 and perplexity is 43.8305067560508
At time: 724.5925602912903 and batch: 200, loss is 3.7812963485717774 and perplexity is 43.872879431472036
At time: 725.8413851261139 and batch: 250, loss is 3.7748842525482176 and perplexity is 43.59246230726883
At time: 727.0884890556335 and batch: 300, loss is 3.7768456077575685 and perplexity is 43.67804651338162
At time: 728.3371384143829 and batch: 350, loss is 3.800734910964966 and perplexity is 44.7340479583132
At time: 729.5848863124847 and batch: 400, loss is 3.751833038330078 and perplexity is 42.599096252919004
At time: 730.8336300849915 and batch: 450, loss is 3.789078426361084 and perplexity is 44.21563353179937
At time: 732.0824272632599 and batch: 500, loss is 3.7931633949279786 and perplexity is 44.39662242022259
At time: 733.3324921131134 and batch: 550, loss is 3.7656493330001832 and perplexity is 43.191742580083755
At time: 734.5812191963196 and batch: 600, loss is 3.734502511024475 and perplexity is 41.867191914863426
At time: 735.8366942405701 and batch: 650, loss is 3.76904616355896 and perplexity is 43.338707076601075
At time: 737.0914912223816 and batch: 700, loss is 3.8128310775756837 and perplexity is 45.278444372587614
At time: 738.3398282527924 and batch: 750, loss is 3.7736383199691774 and perplexity is 43.53818285956747
At time: 739.5956566333771 and batch: 800, loss is 3.7614106702804566 and perplexity is 43.00905480046789
At time: 740.8533654212952 and batch: 850, loss is 3.7724595928192137 and perplexity is 43.48689345541585
At time: 742.1015977859497 and batch: 900, loss is 3.7211893653869628 and perplexity is 41.31350174835211
At time: 743.3484554290771 and batch: 950, loss is 3.822582468986511 and perplexity is 45.72213197604538
At time: 744.5993523597717 and batch: 1000, loss is 3.777261161804199 and perplexity is 43.696200874156965
At time: 745.8705613613129 and batch: 1050, loss is 3.720913791656494 and perplexity is 41.30211840110436
At time: 747.1162943840027 and batch: 1100, loss is 3.737517213821411 and perplexity is 41.99359950034255
At time: 748.363578081131 and batch: 1150, loss is 3.7268597793579104 and perplexity is 41.548431851838295
At time: 749.6124911308289 and batch: 1200, loss is 3.757665777206421 and perplexity is 42.84829169722218
At time: 750.8656125068665 and batch: 1250, loss is 3.7527668571472166 and perplexity is 42.63889466995635
At time: 752.1134867668152 and batch: 1300, loss is 3.7370947313308718 and perplexity is 41.97586168706053
At time: 753.3629305362701 and batch: 1350, loss is 3.6098929595947267 and perplexity is 36.96209616531231
At time: 754.6110072135925 and batch: 1400, loss is 3.6401441144943236 and perplexity is 38.09732670677
At time: 755.8606088161469 and batch: 1450, loss is 3.5728805351257322 and perplexity is 35.61904743648853
At time: 757.111403465271 and batch: 1500, loss is 3.5671929597854612 and perplexity is 35.41703644158401
At time: 758.3599483966827 and batch: 1550, loss is 3.5981239557266234 and perplexity is 36.529638899791614
At time: 759.6080090999603 and batch: 1600, loss is 3.680049934387207 and perplexity is 39.64837384039441
At time: 760.8572192192078 and batch: 1650, loss is 3.633524627685547 and perplexity is 37.845974783358194
At time: 762.1056418418884 and batch: 1700, loss is 3.6198525762557985 and perplexity is 37.332063783728884
At time: 763.3545479774475 and batch: 1750, loss is 3.5985277986526487 and perplexity is 36.544394115245716
At time: 764.6029276847839 and batch: 1800, loss is 3.546303725242615 and perplexity is 34.68487542576328
At time: 765.8503272533417 and batch: 1850, loss is 3.5838389205932617 and perplexity is 36.01152120012828
At time: 767.1049427986145 and batch: 1900, loss is 3.6894241189956665 and perplexity is 40.02179252954322
At time: 768.3534600734711 and batch: 1950, loss is 3.646115803718567 and perplexity is 38.32551275209844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336445085392442 and perplexity of 76.43533470496926
finished 15 epochs...
Completing Train Step...
At time: 772.2957689762115 and batch: 50, loss is 3.846794996261597 and perplexity is 46.842691388122155
At time: 773.5557200908661 and batch: 100, loss is 3.815383915901184 and perplexity is 45.39418058576707
At time: 774.7893426418304 and batch: 150, loss is 3.7740928888320924 and perplexity is 43.55797846073442
At time: 776.0618851184845 and batch: 200, loss is 3.7746740627288817 and perplexity is 43.583300578376864
At time: 777.3145580291748 and batch: 250, loss is 3.7679535245895384 and perplexity is 43.29137937711778
At time: 778.5671606063843 and batch: 300, loss is 3.7698458766937257 and perplexity is 43.37337947203115
At time: 779.8187475204468 and batch: 350, loss is 3.7935927009582517 and perplexity is 44.41568624976705
At time: 781.0718123912811 and batch: 400, loss is 3.7442755031585695 and perplexity is 42.27836557797002
At time: 782.3243834972382 and batch: 450, loss is 3.781951141357422 and perplexity is 43.901616483789724
At time: 783.5768930912018 and batch: 500, loss is 3.7859514141082764 and perplexity is 44.0775866536071
At time: 784.8331830501556 and batch: 550, loss is 3.758292346000671 and perplexity is 42.87514751231583
At time: 786.0875499248505 and batch: 600, loss is 3.7277802181243898 and perplexity is 41.58669224467434
At time: 787.3396377563477 and batch: 650, loss is 3.7625165462493895 and perplexity is 43.056643789527975
At time: 788.5920579433441 and batch: 700, loss is 3.806780385971069 and perplexity is 45.005305641785085
At time: 789.844645023346 and batch: 750, loss is 3.76788019657135 and perplexity is 43.28820502244941
At time: 791.0962469577789 and batch: 800, loss is 3.75590829372406 and perplexity is 42.77305266735924
At time: 792.351644039154 and batch: 850, loss is 3.767050485610962 and perplexity is 43.2523032204057
At time: 793.6055934429169 and batch: 900, loss is 3.715648202896118 and perplexity is 41.08521000704697
At time: 794.85693526268 and batch: 950, loss is 3.817156295776367 and perplexity is 45.47470765908962
At time: 796.1087415218353 and batch: 1000, loss is 3.772168517112732 and perplexity is 43.47423731921687
At time: 797.3616290092468 and batch: 1050, loss is 3.716011919975281 and perplexity is 41.10015611754058
At time: 798.6131861209869 and batch: 1100, loss is 3.7328609895706175 and perplexity is 41.79852239778485
At time: 799.8648271560669 and batch: 1150, loss is 3.7224322605133056 and perplexity is 41.36488202185875
At time: 801.1177122592926 and batch: 1200, loss is 3.753516187667847 and perplexity is 42.670857268878365
At time: 802.3745489120483 and batch: 1250, loss is 3.7490206718444825 and perplexity is 42.47946029123928
At time: 803.6257543563843 and batch: 1300, loss is 3.7337325859069823 and perplexity is 41.83496971814031
At time: 804.8774540424347 and batch: 1350, loss is 3.606806936264038 and perplexity is 36.84820609828336
At time: 806.1284477710724 and batch: 1400, loss is 3.637584776878357 and perplexity is 37.999947451811245
At time: 807.3793296813965 and batch: 1450, loss is 3.5706153821945192 and perplexity is 35.53845615702614
At time: 808.6321499347687 and batch: 1500, loss is 3.5653800439834593 and perplexity is 35.352886503347285
At time: 809.8850789070129 and batch: 1550, loss is 3.5966089153289795 and perplexity is 36.474336924088824
At time: 811.1368601322174 and batch: 1600, loss is 3.6789158964157105 and perplexity is 39.6034365640561
At time: 812.3893756866455 and batch: 1650, loss is 3.632608861923218 and perplexity is 37.81133259989338
At time: 813.6419003009796 and batch: 1700, loss is 3.6190387344360353 and perplexity is 37.3016937488821
At time: 814.8960525989532 and batch: 1750, loss is 3.5981115674972535 and perplexity is 36.529186365049185
At time: 816.1460163593292 and batch: 1800, loss is 3.545944919586182 and perplexity is 34.67243252869226
At time: 817.3956937789917 and batch: 1850, loss is 3.583540916442871 and perplexity is 36.00079121621804
At time: 818.6459665298462 and batch: 1900, loss is 3.689069528579712 and perplexity is 40.00760370124286
At time: 819.8957107067108 and batch: 1950, loss is 3.6454418516159057 and perplexity is 38.29969189418169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33678716615189 and perplexity of 76.4614862350264
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 823.7946536540985 and batch: 50, loss is 3.8478763580322264 and perplexity is 46.89337268129048
At time: 825.0237283706665 and batch: 100, loss is 3.825603013038635 and perplexity is 45.86044647719645
At time: 826.2475292682648 and batch: 150, loss is 3.791175785064697 and perplexity is 44.30846689402268
At time: 827.4835915565491 and batch: 200, loss is 3.7953661489486694 and perplexity is 44.494525046879765
At time: 828.7324149608612 and batch: 250, loss is 3.7909572076797486 and perplexity is 44.29878312356307
At time: 829.9817199707031 and batch: 300, loss is 3.7910954999923705 and perplexity is 44.304909728348974
At time: 831.2318387031555 and batch: 350, loss is 3.8142892360687255 and perplexity is 45.34451568031359
At time: 832.4821856021881 and batch: 400, loss is 3.7690837144851685 and perplexity is 43.34033451574821
At time: 833.7333972454071 and batch: 450, loss is 3.8137234354019167 and perplexity is 45.318866979815716
At time: 834.982328414917 and batch: 500, loss is 3.8239386224746705 and perplexity is 45.78418026880542
At time: 836.2328107357025 and batch: 550, loss is 3.803945846557617 and perplexity is 44.87791695854395
At time: 837.4842603206635 and batch: 600, loss is 3.763643946647644 and perplexity is 43.10521324034844
At time: 838.7603776454926 and batch: 650, loss is 3.785879487991333 and perplexity is 44.074416437966896
At time: 840.0187540054321 and batch: 700, loss is 3.8253020238876343 and perplexity is 45.84664505748975
At time: 841.2709572315216 and batch: 750, loss is 3.777261734008789 and perplexity is 43.696225877330825
At time: 842.527295589447 and batch: 800, loss is 3.7671537685394285 and perplexity is 43.25677067564719
At time: 843.7786662578583 and batch: 850, loss is 3.7790169954299926 and perplexity is 43.772991529049754
At time: 845.0296227931976 and batch: 900, loss is 3.7256852197647095 and perplexity is 41.49965939131213
At time: 846.2842869758606 and batch: 950, loss is 3.8281990814208986 and perplexity is 45.97965800597985
At time: 847.5439114570618 and batch: 1000, loss is 3.7858748912811278 and perplexity is 44.074213841112694
At time: 848.8026447296143 and batch: 1050, loss is 3.7335301733016966 and perplexity is 41.82650264987719
At time: 850.0548803806305 and batch: 1100, loss is 3.745049295425415 and perplexity is 42.31109291075467
At time: 851.3068952560425 and batch: 1150, loss is 3.7414934539794924 and perplexity is 42.16090854709706
At time: 852.5635306835175 and batch: 1200, loss is 3.7714005756378173 and perplexity is 43.44086446512865
At time: 853.8212370872498 and batch: 1250, loss is 3.7607823514938357 and perplexity is 42.98203989121819
At time: 855.0788900852203 and batch: 1300, loss is 3.7432720994949342 and perplexity is 42.23596458726879
At time: 856.3299813270569 and batch: 1350, loss is 3.6104229497909546 and perplexity is 36.98169090596352
At time: 857.5806455612183 and batch: 1400, loss is 3.638660817146301 and perplexity is 38.040858932702086
At time: 858.8309316635132 and batch: 1450, loss is 3.5683286571502686 and perplexity is 35.45728232578653
At time: 860.0808863639832 and batch: 1500, loss is 3.560220232009888 and perplexity is 35.170942059495694
At time: 861.3314650058746 and batch: 1550, loss is 3.5881413793563843 and perplexity is 36.166793070978166
At time: 862.5819637775421 and batch: 1600, loss is 3.6715900754928588 and perplexity is 39.314369001255116
At time: 863.8335356712341 and batch: 1650, loss is 3.6235215950012205 and perplexity is 37.46928740964602
At time: 865.0835947990417 and batch: 1700, loss is 3.6097602605819703 and perplexity is 36.95719165706067
At time: 866.3325281143188 and batch: 1750, loss is 3.591280221939087 and perplexity is 36.2804932913448
At time: 867.5826399326324 and batch: 1800, loss is 3.5387805700302124 and perplexity is 34.42491481253378
At time: 868.8331506252289 and batch: 1850, loss is 3.5774169397354125 and perplexity is 35.78099690389779
At time: 870.0840060710907 and batch: 1900, loss is 3.6845106983184817 and perplexity is 39.82563093345114
At time: 871.3339078426361 and batch: 1950, loss is 3.643237199783325 and perplexity is 38.21534741752537
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331905773074128 and perplexity of 76.08915714704086
finished 17 epochs...
Completing Train Step...
At time: 875.2665314674377 and batch: 50, loss is 3.8498634243011476 and perplexity is 46.98664555938622
At time: 876.4933185577393 and batch: 100, loss is 3.8226730537414553 and perplexity is 45.726273891760336
At time: 877.7292025089264 and batch: 150, loss is 3.784953055381775 and perplexity is 44.03360336952934
At time: 878.9786236286163 and batch: 200, loss is 3.787488942146301 and perplexity is 44.14540930518868
At time: 880.2298307418823 and batch: 250, loss is 3.781652398109436 and perplexity is 43.888503131149825
At time: 881.4814255237579 and batch: 300, loss is 3.7795823335647585 and perplexity is 43.79774506683406
At time: 882.7330164909363 and batch: 350, loss is 3.8008412599563597 and perplexity is 44.73880563217694
At time: 883.9844145774841 and batch: 400, loss is 3.754742341041565 and perplexity is 42.72321037438732
At time: 885.2363367080688 and batch: 450, loss is 3.7993495225906373 and perplexity is 44.672116837567806
At time: 886.4883406162262 and batch: 500, loss is 3.809946370124817 and perplexity is 45.14801751884673
At time: 887.7397215366364 and batch: 550, loss is 3.7896201276779173 and perplexity is 44.23959168720447
At time: 888.9902408123016 and batch: 600, loss is 3.7515877723693847 and perplexity is 42.588649425829765
At time: 890.240993976593 and batch: 650, loss is 3.7762890672683715 and perplexity is 43.653744675113636
At time: 891.4929013252258 and batch: 700, loss is 3.8172453165054323 and perplexity is 45.478756030911285
At time: 892.7444987297058 and batch: 750, loss is 3.7708878660202028 and perplexity is 43.418597624819256
At time: 893.9965012073517 and batch: 800, loss is 3.7614280557632447 and perplexity is 43.009802540149735
At time: 895.2480232715607 and batch: 850, loss is 3.7728456354141233 and perplexity is 43.50368448942858
At time: 896.4987914562225 and batch: 900, loss is 3.720235662460327 and perplexity is 41.27411972318646
At time: 897.7495636940002 and batch: 950, loss is 3.8234184074401854 and perplexity is 45.760368843955604
At time: 899.0020816326141 and batch: 1000, loss is 3.780847625732422 and perplexity is 43.85319708473236
At time: 900.2747266292572 and batch: 1050, loss is 3.726623911857605 and perplexity is 41.53863308272681
At time: 901.526674747467 and batch: 1100, loss is 3.739113712310791 and perplexity is 42.0606957637988
At time: 902.7783622741699 and batch: 1150, loss is 3.7355420207977295 and perplexity is 41.910735898314755
At time: 904.0300807952881 and batch: 1200, loss is 3.7655559825897216 and perplexity is 43.187710801372376
At time: 905.2826611995697 and batch: 1250, loss is 3.7562538766860962 and perplexity is 42.787836860030765
At time: 906.5355746746063 and batch: 1300, loss is 3.7392017126083372 and perplexity is 42.064397280405906
At time: 907.7935059070587 and batch: 1350, loss is 3.6071878480911255 and perplexity is 36.8622446893561
At time: 909.0451426506042 and batch: 1400, loss is 3.636824674606323 and perplexity is 37.97107457997381
At time: 910.2962424755096 and batch: 1450, loss is 3.567379941940308 and perplexity is 35.42365941454572
At time: 911.5486516952515 and batch: 1500, loss is 3.5610843753814696 and perplexity is 35.201347931572975
At time: 912.8004038333893 and batch: 1550, loss is 3.5900186824798586 and perplexity is 36.23475287519368
At time: 914.0526053905487 and batch: 1600, loss is 3.6742217779159545 and perplexity is 39.41796898378751
At time: 915.3032736778259 and batch: 1650, loss is 3.6268085479736327 and perplexity is 37.592649827436354
At time: 916.5546841621399 and batch: 1700, loss is 3.6145725011825562 and perplexity is 37.13546716351471
At time: 917.8055553436279 and batch: 1750, loss is 3.596370973587036 and perplexity is 36.465659189263484
At time: 919.0578339099884 and batch: 1800, loss is 3.5439954471588133 and perplexity is 34.604905419992114
At time: 920.3104045391083 and batch: 1850, loss is 3.5829495334625245 and perplexity is 35.97950725512024
At time: 921.5622947216034 and batch: 1900, loss is 3.6903116512298584 and perplexity is 40.05732892800018
At time: 922.814361333847 and batch: 1950, loss is 3.6479363870620727 and perplexity is 38.39535109621919
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3308454646620635 and perplexity of 76.0085219303048
finished 18 epochs...
Completing Train Step...
At time: 926.7296447753906 and batch: 50, loss is 3.8493381690979005 and perplexity is 46.961972059832306
At time: 927.9507229328156 and batch: 100, loss is 3.8204808139801028 and perplexity is 45.62614073404383
At time: 929.1776461601257 and batch: 150, loss is 3.7819712114334108 and perplexity is 43.9024976014106
At time: 930.4256114959717 and batch: 200, loss is 3.7837175035476687 and perplexity is 43.979231166878165
At time: 931.7037093639374 and batch: 250, loss is 3.777353539466858 and perplexity is 43.7002376135102
At time: 932.9528520107269 and batch: 300, loss is 3.775171546936035 and perplexity is 43.6049879762319
At time: 934.2019610404968 and batch: 350, loss is 3.7959927845001222 and perplexity is 44.52241563582378
At time: 935.4504363536835 and batch: 400, loss is 3.74987961769104 and perplexity is 42.51596352212542
At time: 936.7087247371674 and batch: 450, loss is 3.7946854257583618 and perplexity is 44.4642468985267
At time: 937.9575395584106 and batch: 500, loss is 3.805160484313965 and perplexity is 44.9324604895182
At time: 939.2060167789459 and batch: 550, loss is 3.7845153999328613 and perplexity is 44.01433603961287
At time: 940.4544186592102 and batch: 600, loss is 3.7472211265563966 and perplexity is 42.40308531935296
At time: 941.7026512622833 and batch: 650, loss is 3.7722579860687255 and perplexity is 43.47812708784661
At time: 942.9504528045654 and batch: 700, loss is 3.813582592010498 and perplexity is 45.31248456636597
At time: 944.1998221874237 and batch: 750, loss is 3.767647829055786 and perplexity is 43.2781474183706
At time: 945.4508337974548 and batch: 800, loss is 3.7584961795806886 and perplexity is 42.88388779787862
At time: 946.7034227848053 and batch: 850, loss is 3.76959415435791 and perplexity is 43.36246279768125
At time: 947.9501452445984 and batch: 900, loss is 3.7172360229492187 and perplexity is 41.15049774625598
At time: 949.1955142021179 and batch: 950, loss is 3.820581216812134 and perplexity is 45.630721957768245
At time: 950.4416761398315 and batch: 1000, loss is 3.778025760650635 and perplexity is 43.729623714843406
At time: 951.6942348480225 and batch: 1050, loss is 3.7233860301971435 and perplexity is 41.4043534126225
At time: 952.9402062892914 and batch: 1100, loss is 3.736402735710144 and perplexity is 41.946824622516274
At time: 954.1863701343536 and batch: 1150, loss is 3.7329284143447876 and perplexity is 41.80134074873044
At time: 955.4346964359283 and batch: 1200, loss is 3.7632036447525024 and perplexity is 43.0862381109675
At time: 956.6837587356567 and batch: 1250, loss is 3.7545520305633544 and perplexity is 42.71508047341749
At time: 957.9323363304138 and batch: 1300, loss is 3.737703537940979 and perplexity is 42.001424649781335
At time: 959.1906630992889 and batch: 1350, loss is 3.6062577962875366 and perplexity is 36.827976830110714
At time: 960.439395904541 and batch: 1400, loss is 3.6364291429519655 and perplexity is 37.956058787833776
At time: 961.6865582466125 and batch: 1450, loss is 3.567264213562012 and perplexity is 35.41956012909477
At time: 962.9332225322723 and batch: 1500, loss is 3.561526961326599 and perplexity is 35.216931001586616
At time: 964.178902387619 and batch: 1550, loss is 3.590917534828186 and perplexity is 36.26733720996568
At time: 965.4253339767456 and batch: 1600, loss is 3.675330944061279 and perplexity is 39.46171431643797
At time: 966.6726036071777 and batch: 1650, loss is 3.628123745918274 and perplexity is 37.64212413034226
At time: 967.9196701049805 and batch: 1700, loss is 3.616302418708801 and perplexity is 37.19976405713309
At time: 969.167397737503 and batch: 1750, loss is 3.5982506847381592 and perplexity is 36.534268558170965
At time: 970.4145212173462 and batch: 1800, loss is 3.545954122543335 and perplexity is 34.67275161907151
At time: 971.6607706546783 and batch: 1850, loss is 3.5849684286117554 and perplexity is 36.052219482273124
At time: 972.9105789661407 and batch: 1900, loss is 3.692271838188171 and perplexity is 40.13592578885423
At time: 974.1607074737549 and batch: 1950, loss is 3.649333519935608 and perplexity is 38.449031994368376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330425599563953 and perplexity of 75.97661530349552
finished 19 epochs...
Completing Train Step...
At time: 978.0717303752899 and batch: 50, loss is 3.8479809761047363 and perplexity is 46.89827883218543
At time: 979.3175921440125 and batch: 100, loss is 3.818357858657837 and perplexity is 45.529381220141325
At time: 980.5626344680786 and batch: 150, loss is 3.779599871635437 and perplexity is 43.79851320151838
At time: 981.8113813400269 and batch: 200, loss is 3.7810491800308226 and perplexity is 43.862036775912344
At time: 983.0603709220886 and batch: 250, loss is 3.774424138069153 and perplexity is 43.57240939785393
At time: 984.3073501586914 and batch: 300, loss is 3.772250337600708 and perplexity is 43.47779454805383
At time: 985.5540719032288 and batch: 350, loss is 3.792884931564331 and perplexity is 44.3842613085471
At time: 986.8055734634399 and batch: 400, loss is 3.7467760610580445 and perplexity is 42.384217368102156
At time: 988.0530705451965 and batch: 450, loss is 3.791769995689392 and perplexity is 44.33480327972024
At time: 989.3018472194672 and batch: 500, loss is 3.802188811302185 and perplexity is 44.799134108647856
At time: 990.5502676963806 and batch: 550, loss is 3.7814287614822386 and perplexity is 43.87868915176036
At time: 991.7982575893402 and batch: 600, loss is 3.7445128536224366 and perplexity is 42.28840155862671
At time: 993.0475330352783 and batch: 650, loss is 3.769629054069519 and perplexity is 43.36397616153538
At time: 994.3172605037689 and batch: 700, loss is 3.811090502738953 and perplexity is 45.199702399694395
At time: 995.5658502578735 and batch: 750, loss is 3.7653339672088624 and perplexity is 43.17812352961065
At time: 996.814183473587 and batch: 800, loss is 3.7563624668121336 and perplexity is 42.79248344891053
At time: 998.0627388954163 and batch: 850, loss is 3.7672679901123045 and perplexity is 43.26171181421824
At time: 999.3103818893433 and batch: 900, loss is 3.715036311149597 and perplexity is 41.06007799595881
At time: 1000.5577368736267 and batch: 950, loss is 3.818451337814331 and perplexity is 45.53363746722558
At time: 1001.806069612503 and batch: 1000, loss is 3.775947723388672 and perplexity is 43.63884627942557
At time: 1003.054545879364 and batch: 1050, loss is 3.721205677986145 and perplexity is 41.31417568444375
At time: 1004.3036229610443 and batch: 1100, loss is 3.7345479917526245 and perplexity is 41.86909610853901
At time: 1005.560563325882 and batch: 1150, loss is 3.7311971950531007 and perplexity is 41.729036066896704
At time: 1006.8086714744568 and batch: 1200, loss is 3.7617061376571654 and perplexity is 43.021764450615535
At time: 1008.0564415454865 and batch: 1250, loss is 3.753432106971741 and perplexity is 42.667269624323694
At time: 1009.3063838481903 and batch: 1300, loss is 3.736748332977295 and perplexity is 41.96132383577141
At time: 1010.5615191459656 and batch: 1350, loss is 3.605642409324646 and perplexity is 36.80532034526753
At time: 1011.812091588974 and batch: 1400, loss is 3.636123871803284 and perplexity is 37.944473666559794
At time: 1013.060718536377 and batch: 1450, loss is 3.5670554065704345 and perplexity is 35.41216504940026
At time: 1014.3105659484863 and batch: 1500, loss is 3.5615858316421507 and perplexity is 35.21900429445454
At time: 1015.5604627132416 and batch: 1550, loss is 3.5912243938446045 and perplexity is 36.27846787707549
At time: 1016.8092133998871 and batch: 1600, loss is 3.6757398080825805 and perplexity is 39.47785209049362
At time: 1018.0585675239563 and batch: 1650, loss is 3.628631634712219 and perplexity is 37.66124699910267
At time: 1019.3088240623474 and batch: 1700, loss is 3.616952738761902 and perplexity is 37.22396367756642
At time: 1020.5586349964142 and batch: 1750, loss is 3.599007019996643 and perplexity is 36.5619111658461
At time: 1021.8086998462677 and batch: 1800, loss is 3.546760368347168 and perplexity is 34.700717651805085
At time: 1023.0576004981995 and batch: 1850, loss is 3.585797152519226 and perplexity is 36.082109201927445
At time: 1024.3078224658966 and batch: 1900, loss is 3.6930176830291748 and perplexity is 40.16587212831592
At time: 1025.5576794147491 and batch: 1950, loss is 3.649720187187195 and perplexity is 38.46390185055377
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330236532521802 and perplexity of 75.96225198742506
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc433bcbb38>
ELAPSED
2109.325295448303


RESULTS SO FAR:
[{'best_accuracy': -75.2531559304004, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.96225198742506, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7460609200881098, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.7558732386815785, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.06428528362550812, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.41802598995097096, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6438300609588623 and batch: 50, loss is 7.678961057662963 and perplexity is 2162.372024565013
At time: 2.8170857429504395 and batch: 100, loss is 6.836537199020386 and perplexity is 931.2587811018116
At time: 3.996070384979248 and batch: 150, loss is 6.488211412429809 and perplexity is 657.346589208487
At time: 5.176257371902466 and batch: 200, loss is 6.295806293487549 and perplexity is 542.2929174133121
At time: 6.3609938621521 and batch: 250, loss is 6.161458702087402 and perplexity is 474.11916928374546
At time: 7.541391849517822 and batch: 300, loss is 6.0504939746856685 and perplexity is 424.3225828981099
At time: 8.723228454589844 and batch: 350, loss is 5.962427415847778 and perplexity is 388.5521580874996
At time: 9.9038827419281 and batch: 400, loss is 5.886747179031372 and perplexity is 360.23160760018817
At time: 11.085977792739868 and batch: 450, loss is 5.784231023788452 and perplexity is 325.131925242638
At time: 12.271731853485107 and batch: 500, loss is 5.753449096679687 and perplexity is 315.27620524747505
At time: 13.463369369506836 and batch: 550, loss is 5.693795413970947 and perplexity is 297.0187933195384
At time: 14.656706094741821 and batch: 600, loss is 5.7081810474395756 and perplexity is 301.3224782111318
At time: 15.852538108825684 and batch: 650, loss is 5.767904167175293 and perplexity is 319.8666426376
At time: 17.047141551971436 and batch: 700, loss is 5.68037202835083 and perplexity is 293.0584356912022
At time: 18.242775917053223 and batch: 750, loss is 5.595557489395142 and perplexity is 269.2276998503508
At time: 19.479974031448364 and batch: 800, loss is 5.602279014587403 and perplexity is 271.0434159721771
At time: 20.783504962921143 and batch: 850, loss is 5.603718461990357 and perplexity is 271.43384965034295
At time: 22.11289381980896 and batch: 900, loss is 5.5930264282226565 and perplexity is 268.5471297183466
At time: 23.44263243675232 and batch: 950, loss is 5.600034523010254 and perplexity is 270.4357435209432
At time: 24.779115200042725 and batch: 1000, loss is 5.564892845153809 and perplexity is 261.09722437781545
At time: 26.108521699905396 and batch: 1050, loss is 5.467173204421997 and perplexity is 236.78988919025653
At time: 27.438043355941772 and batch: 1100, loss is 5.53282865524292 and perplexity is 252.85814890953486
At time: 28.766308546066284 and batch: 1150, loss is 5.43324387550354 and perplexity is 228.8905348476551
At time: 30.095266103744507 and batch: 1200, loss is 5.5066800212860105 and perplexity is 246.3319511623356
At time: 31.42382526397705 and batch: 1250, loss is 5.462784671783448 and perplexity is 235.75300589528734
At time: 32.751489877700806 and batch: 1300, loss is 5.468751783370972 and perplexity is 237.16397590968987
At time: 34.08073925971985 and batch: 1350, loss is 5.409900922775268 and perplexity is 223.60943198105699
At time: 35.4095184803009 and batch: 1400, loss is 5.41280909538269 and perplexity is 224.26067330801183
At time: 36.73750853538513 and batch: 1450, loss is 5.385343036651611 and perplexity is 218.18493670169278
At time: 38.06706881523132 and batch: 1500, loss is 5.336802949905396 and perplexity is 207.84714919192342
At time: 39.39493179321289 and batch: 1550, loss is 5.324498462677002 and perplexity is 205.30536633541305
At time: 40.72867131233215 and batch: 1600, loss is 5.348752708435058 and perplexity is 210.3457716706287
At time: 42.06614398956299 and batch: 1650, loss is 5.338991470336914 and perplexity is 208.30252504248284
At time: 43.39545774459839 and batch: 1700, loss is 5.346766967773437 and perplexity is 209.92849395859847
At time: 44.7236111164093 and batch: 1750, loss is 5.333438138961792 and perplexity is 207.14895812893081
At time: 46.0561261177063 and batch: 1800, loss is 5.310203304290772 and perplexity is 202.39137123993495
At time: 47.389047622680664 and batch: 1850, loss is 5.2871855354309085 and perplexity is 197.7859796896383
At time: 48.72118639945984 and batch: 1900, loss is 5.344953908920288 and perplexity is 209.54822607229494
At time: 50.051332235336304 and batch: 1950, loss is 5.273627185821534 and perplexity is 195.12242573011227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.865265602289244 and perplexity of 129.70538408414842
finished 1 epochs...
Completing Train Step...
At time: 53.99284076690674 and batch: 50, loss is 5.1335630702972415 and perplexity is 169.6204120691692
At time: 55.2647430896759 and batch: 100, loss is 5.062692375183105 and perplexity is 158.0153808092583
At time: 56.510777711868286 and batch: 150, loss is 4.986365251541137 and perplexity is 146.40331599959237
At time: 57.76322960853577 and batch: 200, loss is 4.9414850521087645 and perplexity is 139.97796986341672
At time: 59.00921821594238 and batch: 250, loss is 4.959548273086548 and perplexity is 142.52939698814637
At time: 60.256455183029175 and batch: 300, loss is 4.976990175247193 and perplexity is 145.0371875277073
At time: 61.5029296875 and batch: 350, loss is 4.969128837585449 and perplexity is 143.90147119681762
At time: 62.787158727645874 and batch: 400, loss is 4.914320621490479 and perplexity is 136.22672884534924
At time: 64.0347032546997 and batch: 450, loss is 4.884622621536255 and perplexity is 132.24055118057444
At time: 65.28044486045837 and batch: 500, loss is 4.8800687503814695 and perplexity is 131.6397138552763
At time: 66.52794528007507 and batch: 550, loss is 4.845258169174194 and perplexity is 127.13610037925206
At time: 67.77218413352966 and batch: 600, loss is 4.813048181533813 and perplexity is 123.10629652210015
At time: 69.0180504322052 and batch: 650, loss is 4.88121750831604 and perplexity is 131.7910229131731
At time: 70.26437878608704 and batch: 700, loss is 4.890490474700928 and perplexity is 133.01880041038478
At time: 71.51338386535645 and batch: 750, loss is 4.835779504776001 and perplexity is 125.93671322492781
At time: 72.76110553741455 and batch: 800, loss is 4.834180002212524 and perplexity is 125.73543814220608
At time: 74.00849437713623 and batch: 850, loss is 4.829372148513794 and perplexity is 125.1323714407879
At time: 75.25680184364319 and batch: 900, loss is 4.8193020915985105 and perplexity is 123.87860468467392
At time: 76.50696158409119 and batch: 950, loss is 4.8527583885192875 and perplexity is 128.09323388758222
At time: 77.75581669807434 and batch: 1000, loss is 4.828675479888916 and perplexity is 125.04522600291929
At time: 79.00472497940063 and batch: 1050, loss is 4.751764631271362 and perplexity is 115.78842823635486
At time: 80.25425982475281 and batch: 1100, loss is 4.803187503814697 and perplexity is 121.89835037838064
At time: 81.50316762924194 and batch: 1150, loss is 4.742719469070434 and perplexity is 114.74582548582681
At time: 82.7535195350647 and batch: 1200, loss is 4.816518564224243 and perplexity is 123.53426465972034
At time: 84.00324749946594 and batch: 1250, loss is 4.799717035293579 and perplexity is 121.47603922326613
At time: 85.25377941131592 and batch: 1300, loss is 4.790339193344116 and perplexity is 120.34218100800065
At time: 86.50860333442688 and batch: 1350, loss is 4.6808633041381835 and perplexity is 107.86315109277915
At time: 87.75820899009705 and batch: 1400, loss is 4.680924072265625 and perplexity is 107.86970593365164
At time: 89.00780773162842 and batch: 1450, loss is 4.638239946365356 and perplexity is 103.3622642631796
At time: 90.25678730010986 and batch: 1500, loss is 4.632917823791504 and perplexity is 102.81361889723418
At time: 91.50628280639648 and batch: 1550, loss is 4.629384365081787 and perplexity is 102.4509722957739
At time: 92.75590062141418 and batch: 1600, loss is 4.691966829299926 and perplexity is 109.06748611372704
At time: 94.00507974624634 and batch: 1650, loss is 4.660218801498413 and perplexity is 105.65919801852223
At time: 95.25295901298523 and batch: 1700, loss is 4.669285774230957 and perplexity is 106.62156336307243
At time: 96.50293564796448 and batch: 1750, loss is 4.655476398468018 and perplexity is 105.15930579973379
At time: 97.7542314529419 and batch: 1800, loss is 4.619014902114868 and perplexity is 101.39409980278451
At time: 99.0020763874054 and batch: 1850, loss is 4.642464227676392 and perplexity is 103.79981907100755
At time: 100.25051927566528 and batch: 1900, loss is 4.751615762710571 and perplexity is 115.77119226266623
At time: 101.50297021865845 and batch: 1950, loss is 4.666944093704224 and perplexity is 106.37218182431809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.548296977198401 and perplexity of 94.47138431848029
finished 2 epochs...
Completing Train Step...
At time: 105.43018221855164 and batch: 50, loss is 4.641675176620484 and perplexity is 103.7179480186344
At time: 106.70523047447205 and batch: 100, loss is 4.579718980789185 and perplexity is 97.48699463903361
At time: 107.95776987075806 and batch: 150, loss is 4.523522434234619 and perplexity is 92.15965322902579
At time: 109.21032977104187 and batch: 200, loss is 4.513029870986938 and perplexity is 91.19771764884598
At time: 110.46328353881836 and batch: 250, loss is 4.518231296539307 and perplexity is 91.67331159874531
At time: 111.71470284461975 and batch: 300, loss is 4.547806444168091 and perplexity is 94.42505434817235
At time: 112.96692705154419 and batch: 350, loss is 4.543763561248779 and perplexity is 94.04407555404434
At time: 114.21928381919861 and batch: 400, loss is 4.493326997756958 and perplexity is 89.41844651546384
At time: 115.47065234184265 and batch: 450, loss is 4.496051416397095 and perplexity is 89.66239195178012
At time: 116.7243721485138 and batch: 500, loss is 4.498275442123413 and perplexity is 89.86202533076238
At time: 117.97542476654053 and batch: 550, loss is 4.472060041427612 and perplexity is 87.53686697012854
At time: 119.22705006599426 and batch: 600, loss is 4.443325624465943 and perplexity is 85.05734061009073
At time: 120.47923040390015 and batch: 650, loss is 4.509094276428223 and perplexity is 90.83950575824271
At time: 121.72948956489563 and batch: 700, loss is 4.533894071578979 and perplexity is 93.12047375813084
At time: 122.98370051383972 and batch: 750, loss is 4.490226974487305 and perplexity is 89.14167646897191
At time: 124.27601981163025 and batch: 800, loss is 4.487265729904175 and perplexity is 88.87809661721147
At time: 125.52810549736023 and batch: 850, loss is 4.482031126022338 and perplexity is 88.41407054355936
At time: 126.77961587905884 and batch: 900, loss is 4.460508260726929 and perplexity is 86.53147847358024
At time: 128.03106689453125 and batch: 950, loss is 4.521886730194092 and perplexity is 92.0090305325251
At time: 129.2830114364624 and batch: 1000, loss is 4.498563299179077 and perplexity is 89.88789647220675
At time: 130.53568029403687 and batch: 1050, loss is 4.436009788513184 and perplexity is 84.43734571533017
At time: 131.78713512420654 and batch: 1100, loss is 4.476674489974975 and perplexity is 87.94173474109994
At time: 133.04151916503906 and batch: 1150, loss is 4.431020183563232 and perplexity is 84.01708605393543
At time: 134.29335474967957 and batch: 1200, loss is 4.499535694122314 and perplexity is 89.97534551880926
At time: 135.54554080963135 and batch: 1250, loss is 4.499911336898804 and perplexity is 90.00915045630836
At time: 136.79843401908875 and batch: 1300, loss is 4.481184644699097 and perplexity is 88.33926135089158
At time: 138.04950666427612 and batch: 1350, loss is 4.366318063735962 and perplexity is 78.75313321220841
At time: 139.30227828025818 and batch: 1400, loss is 4.37604793548584 and perplexity is 79.52313101353418
At time: 140.55333542823792 and batch: 1450, loss is 4.330837588310242 and perplexity is 76.00792326280231
At time: 141.80387425422668 and batch: 1500, loss is 4.330925512313843 and perplexity is 76.01460647752413
At time: 143.05537486076355 and batch: 1550, loss is 4.33468861579895 and perplexity is 76.30119620327825
At time: 144.30683040618896 and batch: 1600, loss is 4.405257539749146 and perplexity is 81.8802275412381
At time: 145.55897045135498 and batch: 1650, loss is 4.37401104927063 and perplexity is 79.36131629920905
At time: 146.81069803237915 and batch: 1700, loss is 4.375175247192383 and perplexity is 79.45376238103889
At time: 148.06222891807556 and batch: 1750, loss is 4.3692372608184815 and perplexity is 78.98336501142165
At time: 149.31492519378662 and batch: 1800, loss is 4.334858684539795 and perplexity is 76.31417375514816
At time: 150.56741571426392 and batch: 1850, loss is 4.3651119899749755 and perplexity is 78.65820837932738
At time: 151.82015991210938 and batch: 1900, loss is 4.47897162437439 and perplexity is 88.14398092952138
At time: 153.07292890548706 and batch: 1950, loss is 4.397459983825684 and perplexity is 81.24424466638553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4600568904433135 and perplexity of 86.492429549025
finished 3 epochs...
Completing Train Step...
At time: 156.99419355392456 and batch: 50, loss is 4.377375268936158 and perplexity is 79.62875480889338
At time: 158.2615180015564 and batch: 100, loss is 4.324251613616943 and perplexity is 75.50898181504422
At time: 159.51317405700684 and batch: 150, loss is 4.276472320556641 and perplexity is 71.98604786291716
At time: 160.76390433311462 and batch: 200, loss is 4.2786079788208005 and perplexity is 72.1399497433552
At time: 162.01727747917175 and batch: 250, loss is 4.273886232376099 and perplexity is 71.80012610402463
At time: 163.26606130599976 and batch: 300, loss is 4.3012658309936525 and perplexity is 73.79314425323372
At time: 164.51474404335022 and batch: 350, loss is 4.302305908203125 and perplexity is 73.86993474788609
At time: 165.7650396823883 and batch: 400, loss is 4.254816336631775 and perplexity is 70.44387804033343
At time: 167.01360058784485 and batch: 450, loss is 4.270139856338501 and perplexity is 71.53163907280741
At time: 168.26137518882751 and batch: 500, loss is 4.278587827682495 and perplexity is 72.13849605589735
At time: 169.51054906845093 and batch: 550, loss is 4.251988925933838 and perplexity is 70.2449855738015
At time: 170.75986337661743 and batch: 600, loss is 4.229338216781616 and perplexity is 68.67177130705853
At time: 172.00911450386047 and batch: 650, loss is 4.293023605346679 and perplexity is 73.18742417696542
At time: 173.2579209804535 and batch: 700, loss is 4.321403150558472 and perplexity is 75.29420330930236
At time: 174.50832557678223 and batch: 750, loss is 4.277974872589112 and perplexity is 72.09429194626196
At time: 175.7582221031189 and batch: 800, loss is 4.275947704315185 and perplexity is 71.94829271739727
At time: 177.0079381465912 and batch: 850, loss is 4.265703077316284 and perplexity is 71.21497200750656
At time: 178.25679898262024 and batch: 900, loss is 4.244689860343933 and perplexity is 69.73412947088158
At time: 179.50542640686035 and batch: 950, loss is 4.316076602935791 and perplexity is 74.89421138340201
At time: 180.75097012519836 and batch: 1000, loss is 4.293369779586792 and perplexity is 73.21276416368794
At time: 181.999267578125 and batch: 1050, loss is 4.240211353302002 and perplexity is 69.42252296776736
At time: 183.24705743789673 and batch: 1100, loss is 4.276633582115173 and perplexity is 71.99765738124748
At time: 184.49403762817383 and batch: 1150, loss is 4.2348514699935915 and perplexity is 69.05142176368605
At time: 185.7424304485321 and batch: 1200, loss is 4.299570255279541 and perplexity is 73.66812840683798
At time: 187.02889561653137 and batch: 1250, loss is 4.308321285247803 and perplexity is 74.31562942447816
At time: 188.27695846557617 and batch: 1300, loss is 4.283981876373291 and perplexity is 72.52866596783123
At time: 189.5252821445465 and batch: 1350, loss is 4.16923481464386 and perplexity is 64.66595173203092
At time: 190.7745382785797 and batch: 1400, loss is 4.186653370857239 and perplexity is 65.80220647720282
At time: 192.02336239814758 and batch: 1450, loss is 4.137956647872925 and perplexity is 62.6746241910822
At time: 193.27309608459473 and batch: 1500, loss is 4.140742101669312 and perplexity is 62.849444825339546
At time: 194.52198696136475 and batch: 1550, loss is 4.1482233047485355 and perplexity is 63.321397471086904
At time: 195.77201652526855 and batch: 1600, loss is 4.2195877265930175 and perplexity is 68.00544167407227
At time: 197.02195358276367 and batch: 1650, loss is 4.189464535713196 and perplexity is 65.9874475771397
At time: 198.27193117141724 and batch: 1700, loss is 4.18819504737854 and perplexity is 65.90373043241934
At time: 199.52188801765442 and batch: 1750, loss is 4.181871404647827 and perplexity is 65.48829370764444
At time: 200.7720603942871 and batch: 1800, loss is 4.148078517913818 and perplexity is 63.3122300300556
At time: 202.02072381973267 and batch: 1850, loss is 4.182375383377075 and perplexity is 65.52130673292035
At time: 203.26861262321472 and batch: 1900, loss is 4.293325319290161 and perplexity is 73.20950917483547
At time: 204.51846933364868 and batch: 1950, loss is 4.217994132041931 and perplexity is 67.89715487831667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4282323083212205 and perplexity of 83.78318309744637
finished 4 epochs...
Completing Train Step...
At time: 208.42250609397888 and batch: 50, loss is 4.203723926544189 and perplexity is 66.93512900437338
At time: 209.63242030143738 and batch: 100, loss is 4.15482355594635 and perplexity is 63.74071688508072
At time: 210.84335088729858 and batch: 150, loss is 4.111582937240601 and perplexity is 61.043268795660595
At time: 212.05463314056396 and batch: 200, loss is 4.116559405326843 and perplexity is 61.34780580556357
At time: 213.26922512054443 and batch: 250, loss is 4.106936769485474 and perplexity is 60.760309375997736
At time: 214.49243187904358 and batch: 300, loss is 4.130417733192444 and perplexity is 62.20390214281886
At time: 215.71532654762268 and batch: 350, loss is 4.132747168540955 and perplexity is 62.34897100996063
At time: 216.9374439716339 and batch: 400, loss is 4.088747930526734 and perplexity is 59.66514001632495
At time: 218.1904878616333 and batch: 450, loss is 4.1119549036026 and perplexity is 61.06597906174471
At time: 219.43238806724548 and batch: 500, loss is 4.125866985321045 and perplexity is 61.92147099144275
At time: 220.6734664440155 and batch: 550, loss is 4.0971075677871704 and perplexity is 60.16600957097591
At time: 221.92456078529358 and batch: 600, loss is 4.082735333442688 and perplexity is 59.30747389808142
At time: 223.16593480110168 and batch: 650, loss is 4.1378308153152465 and perplexity is 62.66673817898764
At time: 224.40793704986572 and batch: 700, loss is 4.170676302909851 and perplexity is 64.75923415927139
At time: 225.6512532234192 and batch: 750, loss is 4.127344560623169 and perplexity is 62.013032255323736
At time: 226.89390897750854 and batch: 800, loss is 4.123775954246521 and perplexity is 61.79212655017137
At time: 228.13568329811096 and batch: 850, loss is 4.118503375053406 and perplexity is 61.467180075230694
At time: 229.37774658203125 and batch: 900, loss is 4.088701148033142 and perplexity is 59.66234879758507
At time: 230.6260643005371 and batch: 950, loss is 4.1702413702011105 and perplexity is 64.73107437439218
At time: 231.86767673492432 and batch: 1000, loss is 4.145532941818237 and perplexity is 63.15126888707053
At time: 233.10944437980652 and batch: 1050, loss is 4.101719698905945 and perplexity is 60.44414399920276
At time: 234.35590386390686 and batch: 1100, loss is 4.13293309211731 and perplexity is 62.36056423132605
At time: 235.60064005851746 and batch: 1150, loss is 4.09270320892334 and perplexity is 59.90159957909332
At time: 236.84338092803955 and batch: 1200, loss is 4.156965208053589 and perplexity is 63.87737360906173
At time: 238.09336590766907 and batch: 1250, loss is 4.167838129997254 and perplexity is 64.57569683357595
At time: 239.34328079223633 and batch: 1300, loss is 4.140274758338928 and perplexity is 62.82007941888004
At time: 240.59329795837402 and batch: 1350, loss is 4.028911051750183 and perplexity is 56.19967937151482
At time: 241.8431100845337 and batch: 1400, loss is 4.047568101882934 and perplexity is 57.258041868196464
At time: 243.0930154323578 and batch: 1450, loss is 3.9980968618392945 and perplexity is 54.49434102308892
At time: 244.343327999115 and batch: 1500, loss is 4.002218952178955 and perplexity is 54.71943523038875
At time: 245.60054779052734 and batch: 1550, loss is 4.011443004608155 and perplexity is 55.22650519456367
At time: 246.85127186775208 and batch: 1600, loss is 4.084541268348694 and perplexity is 59.414676106350186
At time: 248.10103702545166 and batch: 1650, loss is 4.0569056701660156 and perplexity is 57.7951967009812
At time: 249.35118699073792 and batch: 1700, loss is 4.051497745513916 and perplexity is 57.483488239581334
At time: 250.60082983970642 and batch: 1750, loss is 4.050097908973694 and perplexity is 57.403077046677936
At time: 251.8508005142212 and batch: 1800, loss is 4.011479625701904 and perplexity is 55.228527686620566
At time: 253.10238409042358 and batch: 1850, loss is 4.047323775291443 and perplexity is 57.244053914875416
At time: 254.3523416519165 and batch: 1900, loss is 4.156542162895203 and perplexity is 63.85035631059759
At time: 255.60202050209045 and batch: 1950, loss is 4.085586929321289 and perplexity is 59.476836207886244
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.417465990643168 and perplexity of 82.88598515759767
finished 5 epochs...
Completing Train Step...
At time: 259.50822138786316 and batch: 50, loss is 4.072444829940796 and perplexity is 58.70029955313027
At time: 260.71043157577515 and batch: 100, loss is 4.028858418464661 and perplexity is 56.196721475586784
At time: 261.93013644218445 and batch: 150, loss is 3.989027943611145 and perplexity is 54.002370492559436
At time: 263.1574056148529 and batch: 200, loss is 3.994242186546326 and perplexity is 54.284687366121624
At time: 264.38941955566406 and batch: 250, loss is 3.9805511617660523 and perplexity is 53.54653890076687
At time: 265.628098487854 and batch: 300, loss is 4.00234317779541 and perplexity is 54.726233208195055
At time: 266.86601638793945 and batch: 350, loss is 4.006262531280518 and perplexity is 54.94114554464226
At time: 268.1039354801178 and batch: 400, loss is 3.9664679670333864 and perplexity is 52.79771783907986
At time: 269.34292364120483 and batch: 450, loss is 3.994180860519409 and perplexity is 54.2813584040001
At time: 270.58201718330383 and batch: 500, loss is 4.011546950340271 and perplexity is 55.23224605244204
At time: 271.823290348053 and batch: 550, loss is 3.981246953010559 and perplexity is 53.58380907833566
At time: 273.0708062648773 and batch: 600, loss is 3.968759546279907 and perplexity is 52.918846728761054
At time: 274.3189010620117 and batch: 650, loss is 4.01785674571991 and perplexity is 55.58185203457662
At time: 275.5657424926758 and batch: 700, loss is 4.05304226398468 and perplexity is 57.57234114874752
At time: 276.8130283355713 and batch: 750, loss is 4.0119851779937745 and perplexity is 55.25645565429838
At time: 278.0613043308258 and batch: 800, loss is 4.00563000202179 and perplexity is 54.906404651051375
At time: 279.34801506996155 and batch: 850, loss is 4.000433616638183 and perplexity is 54.62182983301922
At time: 280.60129380226135 and batch: 900, loss is 3.972231597900391 and perplexity is 53.10290303790094
At time: 281.8488280773163 and batch: 950, loss is 4.057815947532654 and perplexity is 57.84783031239674
At time: 283.09446382522583 and batch: 1000, loss is 4.031689825057984 and perplexity is 56.35606271676493
At time: 284.34130477905273 and batch: 1050, loss is 3.9934581756591796 and perplexity is 54.2421442595298
At time: 285.5873885154724 and batch: 1100, loss is 4.022653331756592 and perplexity is 55.84909558590415
At time: 286.833993434906 and batch: 1150, loss is 3.982375226020813 and perplexity is 53.64430036283005
At time: 288.08128786087036 and batch: 1200, loss is 4.047101259231567 and perplexity is 57.23131761061564
At time: 289.3278818130493 and batch: 1250, loss is 4.057836284637451 and perplexity is 57.84900678174706
At time: 290.5746397972107 and batch: 1300, loss is 4.031365180015564 and perplexity is 56.33776996987911
At time: 291.82089471817017 and batch: 1350, loss is 3.9229002094268797 and perplexity is 50.546828792673715
At time: 293.06849217414856 and batch: 1400, loss is 3.9408507347106934 and perplexity is 51.46236350180099
At time: 294.32177329063416 and batch: 1450, loss is 3.888254427909851 and perplexity is 48.825583518244414
At time: 295.5693733692169 and batch: 1500, loss is 3.8963043880462647 and perplexity is 49.22021376702693
At time: 296.8168001174927 and batch: 1550, loss is 3.9056051921844483 and perplexity is 49.68013684669077
At time: 298.0642247200012 and batch: 1600, loss is 3.979518485069275 and perplexity is 53.49127117960639
At time: 299.3099727630615 and batch: 1650, loss is 3.951784372329712 and perplexity is 52.028121596248994
At time: 300.5562582015991 and batch: 1700, loss is 3.9455228281021117 and perplexity is 51.70336301796079
At time: 301.80310463905334 and batch: 1750, loss is 3.946588706970215 and perplexity is 51.758501920486744
At time: 303.04997873306274 and batch: 1800, loss is 3.904054036140442 and perplexity is 49.603134938580986
At time: 304.2977349758148 and batch: 1850, loss is 3.942131562232971 and perplexity is 51.528320143859844
At time: 305.5450870990753 and batch: 1900, loss is 4.049938230514527 and perplexity is 57.393911743553886
At time: 306.7928032875061 and batch: 1950, loss is 3.9790320587158203 and perplexity is 53.46525794289969
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.430092035337936 and perplexity of 83.93914192206923
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 310.68777537345886 and batch: 50, loss is 4.008029751777649 and perplexity is 55.03832450621962
At time: 311.8962378501892 and batch: 100, loss is 4.0023678159713745 and perplexity is 54.727581579369335
At time: 313.11424589157104 and batch: 150, loss is 3.9642877864837645 and perplexity is 52.68273466916267
At time: 314.33672046661377 and batch: 200, loss is 3.968063945770264 and perplexity is 52.88204915169722
At time: 315.57426929473877 and batch: 250, loss is 3.9588202667236327 and perplexity is 52.395476786018875
At time: 316.8166837692261 and batch: 300, loss is 3.9712686586380004 and perplexity is 53.051792779605385
At time: 318.06393599510193 and batch: 350, loss is 3.9746962499618532 and perplexity is 53.233944636982145
At time: 319.30626916885376 and batch: 400, loss is 3.9282978439331053 and perplexity is 50.82039975378029
At time: 320.5467085838318 and batch: 450, loss is 3.9473703289031983 and perplexity is 51.79897331541068
At time: 321.79384541511536 and batch: 500, loss is 3.9609871912002563 and perplexity is 52.50913692912908
At time: 323.04325771331787 and batch: 550, loss is 3.9285714530944826 and perplexity is 50.83430658316899
At time: 324.2920138835907 and batch: 600, loss is 3.8998668241500853 and perplexity is 49.39587033045938
At time: 325.542587518692 and batch: 650, loss is 3.9431219339370727 and perplexity is 51.57937761285325
At time: 326.7932987213135 and batch: 700, loss is 3.975079746246338 and perplexity is 53.25436357200151
At time: 328.0420341491699 and batch: 750, loss is 3.917530560493469 and perplexity is 50.27613747643479
At time: 329.2928328514099 and batch: 800, loss is 3.9069034385681154 and perplexity is 49.7446757893518
At time: 330.5433278083801 and batch: 850, loss is 3.9007434606552125 and perplexity is 49.43919153929581
At time: 331.7927055358887 and batch: 900, loss is 3.8641608285903932 and perplexity is 47.66325800214976
At time: 333.0421690940857 and batch: 950, loss is 3.9561877250671387 and perplexity is 52.2577249090998
At time: 334.291880607605 and batch: 1000, loss is 3.919835801124573 and perplexity is 50.39216976110473
At time: 335.5404522418976 and batch: 1050, loss is 3.8769268655776976 and perplexity is 48.27562937797977
At time: 336.7900071144104 and batch: 1100, loss is 3.8985340547561647 and perplexity is 49.33008087712014
At time: 338.0443985462189 and batch: 1150, loss is 3.85921612739563 and perplexity is 47.42815915914025
At time: 339.29456186294556 and batch: 1200, loss is 3.896035656929016 and perplexity is 49.20698854108456
At time: 340.5454065799713 and batch: 1250, loss is 3.8990434551239015 and perplexity is 49.355216039846475
At time: 341.801082611084 and batch: 1300, loss is 3.8730502033233645 and perplexity is 48.088843354854966
At time: 343.04966616630554 and batch: 1350, loss is 3.7639017057418824 and perplexity is 43.11632543314308
At time: 344.30005836486816 and batch: 1400, loss is 3.7743031215667724 and perplexity is 43.567136736314275
At time: 345.54934096336365 and batch: 1450, loss is 3.707860860824585 and perplexity is 40.766507954171345
At time: 346.79906725883484 and batch: 1500, loss is 3.713597502708435 and perplexity is 41.001042889432625
At time: 348.0479054450989 and batch: 1550, loss is 3.7243249225616455 and perplexity is 41.44324589897094
At time: 349.2974531650543 and batch: 1600, loss is 3.7921802282333372 and perplexity is 44.352994589933594
At time: 350.54828238487244 and batch: 1650, loss is 3.749792194366455 and perplexity is 42.512246797712955
At time: 351.7996985912323 and batch: 1700, loss is 3.7339147329330444 and perplexity is 41.842590527492675
At time: 353.05171036720276 and batch: 1750, loss is 3.716522636413574 and perplexity is 41.12115200390202
At time: 354.3044877052307 and batch: 1800, loss is 3.6778177404403687 and perplexity is 39.55996968462413
At time: 355.55640983581543 and batch: 1850, loss is 3.6949880361557006 and perplexity is 40.245091099087695
At time: 356.8086402416229 and batch: 1900, loss is 3.7941051387786864 and perplexity is 44.438452359831714
At time: 358.05914545059204 and batch: 1950, loss is 3.720194525718689 and perplexity is 41.272421875309256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355645326126454 and perplexity of 77.91709105074675
finished 7 epochs...
Completing Train Step...
At time: 362.0149097442627 and batch: 50, loss is 3.9191606187820436 and perplexity is 50.35815734146499
At time: 363.2776849269867 and batch: 100, loss is 3.897517776489258 and perplexity is 49.27997325397686
At time: 364.50101804733276 and batch: 150, loss is 3.851803770065308 and perplexity is 47.07790440629598
At time: 365.72935938835144 and batch: 200, loss is 3.8568670415878294 and perplexity is 47.316877100295045
At time: 366.9854335784912 and batch: 250, loss is 3.845148286819458 and perplexity is 46.76561856160994
At time: 368.2350504398346 and batch: 300, loss is 3.8573283433914183 and perplexity is 47.33870949631627
At time: 369.48395252227783 and batch: 350, loss is 3.8633965492248534 and perplexity is 47.626843874619986
At time: 370.7334108352661 and batch: 400, loss is 3.8207433652877807 and perplexity is 45.638121509673184
At time: 371.984206199646 and batch: 450, loss is 3.846449432373047 and perplexity is 46.82650704205977
At time: 373.28831481933594 and batch: 500, loss is 3.8638080835342405 and perplexity is 47.64644798852827
At time: 374.5377142429352 and batch: 550, loss is 3.832342677116394 and perplexity is 46.17057438595926
At time: 375.7864565849304 and batch: 600, loss is 3.8066723680496217 and perplexity is 45.000444524764156
At time: 377.0355067253113 and batch: 650, loss is 3.8518762016296386 and perplexity is 47.08131445605367
At time: 378.28605031967163 and batch: 700, loss is 3.887068524360657 and perplexity is 48.767715405240935
At time: 379.535587310791 and batch: 750, loss is 3.8318441915512085 and perplexity is 46.14756475655206
At time: 380.7848696708679 and batch: 800, loss is 3.8236275148391723 and perplexity is 45.76993867618774
At time: 382.03492522239685 and batch: 850, loss is 3.8221947526931763 and perplexity is 45.704408196633324
At time: 383.2821698188782 and batch: 900, loss is 3.785460195541382 and perplexity is 44.055940241653936
At time: 384.53082299232483 and batch: 950, loss is 3.878005304336548 and perplexity is 48.32771977090966
At time: 385.78076672554016 and batch: 1000, loss is 3.844476580619812 and perplexity is 46.734216353401486
At time: 387.0299880504608 and batch: 1050, loss is 3.8074026775360106 and perplexity is 45.033320779751534
At time: 388.27942538261414 and batch: 1100, loss is 3.8277806138992307 and perplexity is 45.96042103775088
At time: 389.5291509628296 and batch: 1150, loss is 3.7932807493209837 and perplexity is 44.401832864626485
At time: 390.7797610759735 and batch: 1200, loss is 3.8335420227050783 and perplexity is 46.225982080521426
At time: 392.02837014198303 and batch: 1250, loss is 3.838879246711731 and perplexity is 46.473360070452955
At time: 393.2777626514435 and batch: 1300, loss is 3.816614465713501 and perplexity is 45.450074769402605
At time: 394.5282118320465 and batch: 1350, loss is 3.708454613685608 and perplexity is 40.79072037228798
At time: 395.77718448638916 and batch: 1400, loss is 3.7233873844146728 and perplexity is 41.404409483161636
At time: 397.02606201171875 and batch: 1450, loss is 3.6588082838058473 and perplexity is 38.81505876394401
At time: 398.2753083705902 and batch: 1500, loss is 3.6683102560043337 and perplexity is 39.185636193212574
At time: 399.52454113960266 and batch: 1550, loss is 3.6806841135025024 and perplexity is 39.673525985679056
At time: 400.7782623767853 and batch: 1600, loss is 3.752590160369873 and perplexity is 42.631361180269955
At time: 402.0271439552307 and batch: 1650, loss is 3.712775173187256 and perplexity is 40.96734038064868
At time: 403.27478289604187 and batch: 1700, loss is 3.7014040040969847 and perplexity is 40.50413242518395
At time: 404.5225315093994 and batch: 1750, loss is 3.688467493057251 and perplexity is 39.98352495150479
At time: 405.7715857028961 and batch: 1800, loss is 3.6536670780181884 and perplexity is 38.61601466095321
At time: 407.02327132225037 and batch: 1850, loss is 3.673170118331909 and perplexity is 39.37653648918077
At time: 408.2770748138428 and batch: 1900, loss is 3.7756308555603026 and perplexity is 43.62502072352508
At time: 409.52737069129944 and batch: 1950, loss is 3.7046771001815797 and perplexity is 40.63692354292752
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3586598950763085 and perplexity of 78.15233189080905
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 413.4337303638458 and batch: 50, loss is 3.893131442070007 and perplexity is 49.06428819033604
At time: 414.68869519233704 and batch: 100, loss is 3.9022433948516846 and perplexity is 49.51340271535853
At time: 415.9123203754425 and batch: 150, loss is 3.870936779975891 and perplexity is 47.987318590748075
At time: 417.1542479991913 and batch: 200, loss is 3.8815955400466917 and perplexity is 48.50153951644145
At time: 418.4015712738037 and batch: 250, loss is 3.872951283454895 and perplexity is 48.08408664806574
At time: 419.64911556243896 and batch: 300, loss is 3.879463095664978 and perplexity is 48.398222878638194
At time: 420.89651823043823 and batch: 350, loss is 3.8956973695755006 and perplexity is 49.190345254421956
At time: 422.14403200149536 and batch: 400, loss is 3.8538520193099974 and perplexity is 47.174430509450154
At time: 423.39039182662964 and batch: 450, loss is 3.8748368644714355 and perplexity is 48.17483862225848
At time: 424.6375916004181 and batch: 500, loss is 3.8909620380401613 and perplexity is 48.95796329833885
At time: 425.8847715854645 and batch: 550, loss is 3.866981039047241 and perplexity is 47.797868146023085
At time: 427.1323709487915 and batch: 600, loss is 3.825569944381714 and perplexity is 45.85892995890039
At time: 428.37971210479736 and batch: 650, loss is 3.861120972633362 and perplexity is 47.51858856191444
At time: 429.6271502971649 and batch: 700, loss is 3.90214551448822 and perplexity is 49.50855656267985
At time: 430.87543654441833 and batch: 750, loss is 3.8311463165283204 and perplexity is 46.11537075874145
At time: 432.1227836608887 and batch: 800, loss is 3.823598389625549 and perplexity is 45.76860563635891
At time: 433.3702006340027 and batch: 850, loss is 3.8255843544006347 and perplexity is 45.85959079171008
At time: 434.6188883781433 and batch: 900, loss is 3.7780271911621095 and perplexity is 43.729686270616654
At time: 435.8870973587036 and batch: 950, loss is 3.8713844060897826 and perplexity is 48.008803775991176
At time: 437.1348514556885 and batch: 1000, loss is 3.835896553993225 and perplexity is 46.3349508364861
At time: 438.3819417953491 and batch: 1050, loss is 3.80219545841217 and perplexity is 44.79943189440922
At time: 439.62872648239136 and batch: 1100, loss is 3.8267698001861574 and perplexity is 45.913987085898576
At time: 440.8773477077484 and batch: 1150, loss is 3.792381167411804 and perplexity is 44.36190773969955
At time: 442.1245105266571 and batch: 1200, loss is 3.8233285760879516 and perplexity is 45.75625831277369
At time: 443.3769817352295 and batch: 1250, loss is 3.812032856941223 and perplexity is 45.24231660487622
At time: 444.6245663166046 and batch: 1300, loss is 3.7948567867279053 and perplexity is 44.471866987859556
At time: 445.8723449707031 and batch: 1350, loss is 3.6868197870254518 and perplexity is 39.917698102810384
At time: 447.1209180355072 and batch: 1400, loss is 3.6951152229309083 and perplexity is 40.2502100679682
At time: 448.368022441864 and batch: 1450, loss is 3.623431935310364 and perplexity is 37.465928075520935
At time: 449.61515974998474 and batch: 1500, loss is 3.633814468383789 and perplexity is 37.85694567694398
At time: 450.86232900619507 and batch: 1550, loss is 3.6422008275985718 and perplexity is 38.175762610270816
At time: 452.110360622406 and batch: 1600, loss is 3.713344087600708 and perplexity is 40.99065392214812
At time: 453.3578281402588 and batch: 1650, loss is 3.6693456077575686 and perplexity is 39.22622812018217
At time: 454.6047418117523 and batch: 1700, loss is 3.647742486000061 and perplexity is 38.38790691860562
At time: 455.8518114089966 and batch: 1750, loss is 3.635164318084717 and perplexity is 37.908081368728666
At time: 457.098828792572 and batch: 1800, loss is 3.6073443365097044 and perplexity is 36.8680136551092
At time: 458.34585070610046 and batch: 1850, loss is 3.6207819843292235 and perplexity is 37.36677663390996
At time: 459.59297370910645 and batch: 1900, loss is 3.721294631958008 and perplexity is 41.31785090792557
At time: 460.8423044681549 and batch: 1950, loss is 3.6555165243148804 and perplexity is 38.687498989098174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322385992005814 and perplexity of 75.3682419512224
finished 9 epochs...
Completing Train Step...
At time: 464.7444472312927 and batch: 50, loss is 3.88280508518219 and perplexity is 48.56023981079894
At time: 465.99320101737976 and batch: 100, loss is 3.8676629161834715 and perplexity is 47.83047153396155
At time: 467.22540521621704 and batch: 150, loss is 3.8291918516159056 and perplexity is 46.02532790613164
At time: 468.47601866722107 and batch: 200, loss is 3.832763838768005 and perplexity is 46.19002375670055
At time: 469.7256827354431 and batch: 250, loss is 3.821751537322998 and perplexity is 45.6841557888564
At time: 470.97508692741394 and batch: 300, loss is 3.8295328330993654 and perplexity is 46.04102436666692
At time: 472.2270393371582 and batch: 350, loss is 3.843568048477173 and perplexity is 46.69177609777085
At time: 473.47783064842224 and batch: 400, loss is 3.8039633512496946 and perplexity is 44.878702539537045
At time: 474.72898626327515 and batch: 450, loss is 3.828518452644348 and perplexity is 45.99434493077674
At time: 475.9793074131012 and batch: 500, loss is 3.843543362617493 and perplexity is 46.69062348536457
At time: 477.22932863235474 and batch: 550, loss is 3.819269185066223 and perplexity is 45.57089225978508
At time: 478.4791326522827 and batch: 600, loss is 3.780784635543823 and perplexity is 43.85043485057506
At time: 479.72820115089417 and batch: 650, loss is 3.8187777185440064 and perplexity is 45.54850119453203
At time: 480.97783875465393 and batch: 700, loss is 3.860954794883728 and perplexity is 47.51069268587907
At time: 482.2280213832855 and batch: 750, loss is 3.79302143573761 and perplexity is 44.39032035897706
At time: 483.47808051109314 and batch: 800, loss is 3.7862514734268187 and perplexity is 44.09081452869572
At time: 484.7288010120392 and batch: 850, loss is 3.789715299606323 and perplexity is 44.24380225481796
At time: 485.9796094894409 and batch: 900, loss is 3.7447661638259886 and perplexity is 42.29911499908802
At time: 487.22898411750793 and batch: 950, loss is 3.8385032701492308 and perplexity is 46.455890460573556
At time: 488.4796693325043 and batch: 1000, loss is 3.8042773008346558 and perplexity is 44.89279440152429
At time: 489.7296144962311 and batch: 1050, loss is 3.7730556201934813 and perplexity is 43.51282056020168
At time: 490.98008966445923 and batch: 1100, loss is 3.798170318603516 and perplexity is 44.61947034585676
At time: 492.23104071617126 and batch: 1150, loss is 3.7660893869400023 and perplexity is 43.210753459173105
At time: 493.4822676181793 and batch: 1200, loss is 3.797912244796753 and perplexity is 44.60795671503603
At time: 494.7330572605133 and batch: 1250, loss is 3.78975088596344 and perplexity is 44.24537675858048
At time: 495.9839642047882 and batch: 1300, loss is 3.774607930183411 and perplexity is 43.580418399073565
At time: 497.234495639801 and batch: 1350, loss is 3.6675743770599367 and perplexity is 39.15681091587331
At time: 498.4869463443756 and batch: 1400, loss is 3.678558783531189 and perplexity is 39.589296191592624
At time: 499.73784589767456 and batch: 1450, loss is 3.6097568225860597 and perplexity is 36.9570645986053
At time: 500.9893159866333 and batch: 1500, loss is 3.6229740524291993 and perplexity is 37.44877699532088
At time: 502.2397139072418 and batch: 1550, loss is 3.633370180130005 and perplexity is 37.84013001643239
At time: 503.4884035587311 and batch: 1600, loss is 3.7067685985565184 and perplexity is 40.72200454485408
At time: 504.739488363266 and batch: 1650, loss is 3.6640674829483033 and perplexity is 39.01973262625131
At time: 505.99038338661194 and batch: 1700, loss is 3.6459599924087525 and perplexity is 38.31954166895046
At time: 507.2401075363159 and batch: 1750, loss is 3.6350849628448487 and perplexity is 37.905073283193964
At time: 508.48975944519043 and batch: 1800, loss is 3.6090670299530028 and perplexity is 36.93158067802658
At time: 509.7403841018677 and batch: 1850, loss is 3.623745894432068 and perplexity is 37.477692692101066
At time: 510.9899249076843 and batch: 1900, loss is 3.724608974456787 and perplexity is 41.45501960360176
At time: 512.2402918338776 and batch: 1950, loss is 3.659104323387146 and perplexity is 38.82655125872131
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322014387263808 and perplexity of 75.34023995827557
finished 10 epochs...
Completing Train Step...
At time: 516.1617178916931 and batch: 50, loss is 3.8634798383712767 and perplexity is 47.63081083899338
At time: 517.3843922615051 and batch: 100, loss is 3.846616678237915 and perplexity is 46.8343392366616
At time: 518.6234123706818 and batch: 150, loss is 3.8069400215148925 and perplexity is 45.01249066170317
At time: 519.8691842556 and batch: 200, loss is 3.8096639490127564 and perplexity is 45.13526856590319
At time: 521.1228749752045 and batch: 250, loss is 3.7975925827026367 and perplexity is 44.593699521041906
At time: 522.3728728294373 and batch: 300, loss is 3.8059425497055055 and perplexity is 44.96761435634338
At time: 523.622142791748 and batch: 350, loss is 3.8195304918289184 and perplexity is 45.5828017980683
At time: 524.870546579361 and batch: 400, loss is 3.78042640209198 and perplexity is 43.83472897128736
At time: 526.1196837425232 and batch: 450, loss is 3.8060049867630004 and perplexity is 44.97042208951874
At time: 527.3690745830536 and batch: 500, loss is 3.820389919281006 and perplexity is 45.621993748183236
At time: 528.6388854980469 and batch: 550, loss is 3.7962479734420778 and perplexity is 44.533778713767454
At time: 529.8881525993347 and batch: 600, loss is 3.7587981843948364 and perplexity is 42.89684089429324
At time: 531.1375319957733 and batch: 650, loss is 3.797077679634094 and perplexity is 44.57074399876247
At time: 532.3870418071747 and batch: 700, loss is 3.8397263574600218 and perplexity is 46.512744832550275
At time: 533.636744260788 and batch: 750, loss is 3.772562699317932 and perplexity is 43.49137746790163
At time: 534.885792016983 and batch: 800, loss is 3.7663217782974243 and perplexity is 43.220796431729525
At time: 536.1359119415283 and batch: 850, loss is 3.7708156061172486 and perplexity is 43.415460314520715
At time: 537.3839716911316 and batch: 900, loss is 3.726794066429138 and perplexity is 41.54570167240044
At time: 538.6330864429474 and batch: 950, loss is 3.8206418418884276 and perplexity is 45.63348840762554
At time: 539.8821656703949 and batch: 1000, loss is 3.786763114929199 and perplexity is 44.11337899124788
At time: 541.1311569213867 and batch: 1050, loss is 3.75683708190918 and perplexity is 42.81279822806459
At time: 542.3806836605072 and batch: 1100, loss is 3.7818701171875 and perplexity is 43.89805953585722
At time: 543.6296701431274 and batch: 1150, loss is 3.750884699821472 and perplexity is 42.55871703911848
At time: 544.8790607452393 and batch: 1200, loss is 3.7830971097946167 and perplexity is 43.95195518839638
At time: 546.1288015842438 and batch: 1250, loss is 3.7764083528518677 and perplexity is 43.65895224810702
At time: 547.3777101039886 and batch: 1300, loss is 3.761530485153198 and perplexity is 43.014208233618334
At time: 548.6257843971252 and batch: 1350, loss is 3.65463933467865 and perplexity is 38.653577595855666
At time: 549.8753118515015 and batch: 1400, loss is 3.6669435691833496 and perplexity is 39.132118280098915
At time: 551.1237154006958 and batch: 1450, loss is 3.5991436433792114 and perplexity is 36.56690671906967
At time: 552.374342918396 and batch: 1500, loss is 3.6134646272659303 and perplexity is 37.09434852939935
At time: 553.6238257884979 and batch: 1550, loss is 3.6244007396697997 and perplexity is 37.5022428180709
At time: 554.8741145133972 and batch: 1600, loss is 3.698578372001648 and perplexity is 40.38984419289985
At time: 556.1228005886078 and batch: 1650, loss is 3.656264109611511 and perplexity is 38.71643200810812
At time: 557.371734380722 and batch: 1700, loss is 3.6396205759048463 and perplexity is 38.077386506270756
At time: 558.620599269867 and batch: 1750, loss is 3.629489107131958 and perplexity is 37.69355432904004
At time: 559.8689172267914 and batch: 1800, loss is 3.6041852807998658 and perplexity is 36.7517293171188
At time: 561.1175084114075 and batch: 1850, loss is 3.6195719146728518 and perplexity is 37.32158757781571
At time: 562.3655297756195 and batch: 1900, loss is 3.7206921052932738 and perplexity is 41.29296329950081
At time: 563.6132335662842 and batch: 1950, loss is 3.6555493545532225 and perplexity is 38.68876912976024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323376180959302 and perplexity of 75.44290771235161
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 567.5348994731903 and batch: 50, loss is 3.8596803283691408 and perplexity is 47.45018046755471
At time: 568.7590050697327 and batch: 100, loss is 3.860442910194397 and perplexity is 47.48637891316856
At time: 569.9917995929718 and batch: 150, loss is 3.8299519395828248 and perplexity is 46.06032450260764
At time: 571.2416772842407 and batch: 200, loss is 3.8391626596450807 and perplexity is 46.48653308836679
At time: 572.4923832416534 and batch: 250, loss is 3.8293146276474 and perplexity is 46.03097906014622
At time: 573.7422297000885 and batch: 300, loss is 3.83471568107605 and perplexity is 46.2802674413493
At time: 574.9995210170746 and batch: 350, loss is 3.8508148431777953 and perplexity is 47.031370813773655
At time: 576.2493803501129 and batch: 400, loss is 3.8121702241897584 and perplexity is 45.24853184430099
At time: 577.4992821216583 and batch: 450, loss is 3.8440107107162476 and perplexity is 46.71244935922319
At time: 578.7493722438812 and batch: 500, loss is 3.8582976245880127 and perplexity is 47.38461626199034
At time: 579.9992156028748 and batch: 550, loss is 3.838712954521179 and perplexity is 46.465632556134985
At time: 581.2524602413177 and batch: 600, loss is 3.797945599555969 and perplexity is 44.60944462750574
At time: 582.5129859447479 and batch: 650, loss is 3.8230082178115845 and perplexity is 45.741602264446136
At time: 583.7621653079987 and batch: 700, loss is 3.870238265991211 and perplexity is 47.95381048192889
At time: 585.0122110843658 and batch: 750, loss is 3.798592457771301 and perplexity is 44.63830994812282
At time: 586.2684364318848 and batch: 800, loss is 3.7877282667160035 and perplexity is 44.15597565061758
At time: 587.5218963623047 and batch: 850, loss is 3.7942718935012816 and perplexity is 44.44586329951496
At time: 588.7730612754822 and batch: 900, loss is 3.746791467666626 and perplexity is 42.384870370179435
At time: 590.0447955131531 and batch: 950, loss is 3.8354648780822753 and perplexity is 46.31495347087599
At time: 591.2942390441895 and batch: 1000, loss is 3.7979152631759643 and perplexity is 44.608091358968444
At time: 592.5440583229065 and batch: 1050, loss is 3.7659389305114748 and perplexity is 43.204252612593
At time: 593.793054819107 and batch: 1100, loss is 3.7876813220977783 and perplexity is 44.153902813852945
At time: 595.0431485176086 and batch: 1150, loss is 3.766612629890442 and perplexity is 43.23336909752449
At time: 596.2932109832764 and batch: 1200, loss is 3.8021710109710694 and perplexity is 44.798336676324325
At time: 597.5431056022644 and batch: 1250, loss is 3.7924162435531614 and perplexity is 44.36346381153664
At time: 598.7931244373322 and batch: 1300, loss is 3.7713162803649904 and perplexity is 43.437202759941115
At time: 600.0427327156067 and batch: 1350, loss is 3.663016562461853 and perplexity is 38.9787475296695
At time: 601.2932116985321 and batch: 1400, loss is 3.675090579986572 and perplexity is 39.45223027784669
At time: 602.5431621074677 and batch: 1450, loss is 3.5928886556625366 and perplexity is 36.338895015318435
At time: 603.7935636043549 and batch: 1500, loss is 3.6037253189086913 and perplexity is 36.7348288092909
At time: 605.0442440509796 and batch: 1550, loss is 3.6178419017791748 and perplexity is 37.25707656862226
At time: 606.294406414032 and batch: 1600, loss is 3.6944906234741213 and perplexity is 40.22507765828596
At time: 607.5441808700562 and batch: 1650, loss is 3.648528003692627 and perplexity is 38.41807314517195
At time: 608.7940242290497 and batch: 1700, loss is 3.626938509941101 and perplexity is 37.597535759656076
At time: 610.0437519550323 and batch: 1750, loss is 3.6133737754821778 and perplexity is 37.09097859475291
At time: 611.2918248176575 and batch: 1800, loss is 3.588432579040527 and perplexity is 36.17732636326815
At time: 612.5417332649231 and batch: 1850, loss is 3.6022500371932984 and perplexity is 36.680674544251005
At time: 613.7927329540253 and batch: 1900, loss is 3.7088232040405273 and perplexity is 40.80575820961807
At time: 615.0432412624359 and batch: 1950, loss is 3.659623203277588 and perplexity is 38.8467028030481
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310270371547965 and perplexity of 74.46061825164541
finished 12 epochs...
Completing Train Step...
At time: 618.961389541626 and batch: 50, loss is 3.875321321487427 and perplexity is 48.19818291501992
At time: 620.1797771453857 and batch: 100, loss is 3.8583811378479003 and perplexity is 47.38857367100866
At time: 621.423938035965 and batch: 150, loss is 3.818042125701904 and perplexity is 45.515008363138605
At time: 622.6621508598328 and batch: 200, loss is 3.821465082168579 and perplexity is 45.67107120111868
At time: 623.9099237918854 and batch: 250, loss is 3.808696765899658 and perplexity is 45.09163560027621
At time: 625.1588792800903 and batch: 300, loss is 3.8128022861480715 and perplexity is 45.27714076030058
At time: 626.4072601795197 and batch: 350, loss is 3.8265043258666993 and perplexity is 45.901799719211354
At time: 627.6601254940033 and batch: 400, loss is 3.788425645828247 and perplexity is 44.18677984556968
At time: 628.9056708812714 and batch: 450, loss is 3.821445164680481 and perplexity is 45.67016155716055
At time: 630.1521339416504 and batch: 500, loss is 3.8367866706848144 and perplexity is 46.37621271084683
At time: 631.3986189365387 and batch: 550, loss is 3.8167623901367187 and perplexity is 45.45679844278356
At time: 632.6456506252289 and batch: 600, loss is 3.7777877759933474 and perplexity is 43.719217973582815
At time: 633.8918404579163 and batch: 650, loss is 3.804177551269531 and perplexity is 44.88831658813919
At time: 635.1371648311615 and batch: 700, loss is 3.851474208831787 and perplexity is 47.062391910347316
At time: 636.3833076953888 and batch: 750, loss is 3.783674006462097 and perplexity is 43.977318240100395
At time: 637.6294386386871 and batch: 800, loss is 3.7725078296661376 and perplexity is 43.48899117663198
At time: 638.8748359680176 and batch: 850, loss is 3.779418263435364 and perplexity is 43.79055975459743
At time: 640.1208114624023 and batch: 900, loss is 3.7320725774765013 and perplexity is 41.76558092464451
At time: 641.3718459606171 and batch: 950, loss is 3.822240800857544 and perplexity is 45.70651284919161
At time: 642.6182634830475 and batch: 1000, loss is 3.784670453071594 and perplexity is 44.0211611296772
At time: 643.864743232727 and batch: 1050, loss is 3.7535762643814086 and perplexity is 42.67342087075355
At time: 645.1111161708832 and batch: 1100, loss is 3.776516547203064 and perplexity is 43.66367615566487
At time: 646.3696269989014 and batch: 1150, loss is 3.7566484594345093 and perplexity is 42.804723533673595
At time: 647.6186964511871 and batch: 1200, loss is 3.792217650413513 and perplexity is 44.35465440674527
At time: 648.8654909133911 and batch: 1250, loss is 3.783566474914551 and perplexity is 43.972589545259595
At time: 650.111748456955 and batch: 1300, loss is 3.7640589332580565 and perplexity is 43.12310503885381
At time: 651.3589668273926 and batch: 1350, loss is 3.6567556142807005 and perplexity is 38.73546599247737
At time: 652.6051738262177 and batch: 1400, loss is 3.6699202919006346 and perplexity is 39.24877729017975
At time: 653.8528542518616 and batch: 1450, loss is 3.5897729873657225 and perplexity is 36.225851267035914
At time: 655.1063911914825 and batch: 1500, loss is 3.6024096155166627 and perplexity is 36.68652845186061
At time: 656.3533644676208 and batch: 1550, loss is 3.617886724472046 and perplexity is 37.25874656854924
At time: 657.6001989841461 and batch: 1600, loss is 3.695321002006531 and perplexity is 40.25849357124619
At time: 658.847770690918 and batch: 1650, loss is 3.6506547832489016 and perplexity is 38.49986686550397
At time: 660.0950245857239 and batch: 1700, loss is 3.630307369232178 and perplexity is 37.72441015832628
At time: 661.3418803215027 and batch: 1750, loss is 3.6179160404205324 and perplexity is 37.25983886005502
At time: 662.5896608829498 and batch: 1800, loss is 3.5938670110702513 and perplexity is 36.37446476685921
At time: 663.8359410762787 and batch: 1850, loss is 3.608342890739441 and perplexity is 36.90484675294876
At time: 665.0897822380066 and batch: 1900, loss is 3.714777083396912 and perplexity is 41.04943546369429
At time: 666.3369076251984 and batch: 1950, loss is 3.6647219133377074 and perplexity is 39.04527668256004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3089943109556685 and perplexity of 74.36566258849129
finished 13 epochs...
Completing Train Step...
At time: 670.2540562152863 and batch: 50, loss is 3.8709900474548338 and perplexity is 47.98987482231203
At time: 671.5122401714325 and batch: 100, loss is 3.8520342969894408 and perplexity is 47.08875838181211
At time: 672.7384712696075 and batch: 150, loss is 3.810850143432617 and perplexity is 45.18883953612651
At time: 673.9765555858612 and batch: 200, loss is 3.8135909366607668 and perplexity is 45.3128626847801
At time: 675.2234065532684 and batch: 250, loss is 3.8000084257125852 and perplexity is 44.70156113422031
At time: 676.4712698459625 and batch: 300, loss is 3.8039536905288696 and perplexity is 44.87826898101507
At time: 677.7187743186951 and batch: 350, loss is 3.817188301086426 and perplexity is 45.4761631144991
At time: 678.9657666683197 and batch: 400, loss is 3.778601040840149 and perplexity is 43.75478773854964
At time: 680.2118566036224 and batch: 450, loss is 3.8119569063186645 and perplexity is 45.238880553250866
At time: 681.4593539237976 and batch: 500, loss is 3.827212247848511 and perplexity is 45.93430611687647
At time: 682.7059261798859 and batch: 550, loss is 3.8068607521057127 and perplexity is 45.008922689580096
At time: 683.9985475540161 and batch: 600, loss is 3.7685567474365236 and perplexity is 43.317501604205546
At time: 685.2457144260406 and batch: 650, loss is 3.795471920967102 and perplexity is 44.4992315715081
At time: 686.4940259456635 and batch: 700, loss is 3.8428892278671265 and perplexity is 46.660091513127234
At time: 687.7420845031738 and batch: 750, loss is 3.776177444458008 and perplexity is 43.64887219339521
At time: 688.9914257526398 and batch: 800, loss is 3.765089406967163 and perplexity is 43.16756516841444
At time: 690.2408351898193 and batch: 850, loss is 3.7721272039413454 and perplexity is 43.472441297699525
At time: 691.4889605045319 and batch: 900, loss is 3.724812026023865 and perplexity is 41.46343796494732
At time: 692.7350525856018 and batch: 950, loss is 3.8155176067352294 and perplexity is 45.40024977731899
At time: 693.9822974205017 and batch: 1000, loss is 3.7783145093917847 and perplexity is 43.742252411814455
At time: 695.2295067310333 and batch: 1050, loss is 3.7475548458099364 and perplexity is 42.41723840678105
At time: 696.4776210784912 and batch: 1100, loss is 3.77088484287262 and perplexity is 43.4184663641892
At time: 697.7272439002991 and batch: 1150, loss is 3.751637487411499 and perplexity is 42.59076677496117
At time: 698.9745697975159 and batch: 1200, loss is 3.7872523784637453 and perplexity is 44.134967339739106
At time: 700.2216925621033 and batch: 1250, loss is 3.779115891456604 and perplexity is 43.77732071805114
At time: 701.4712235927582 and batch: 1300, loss is 3.7604732275009156 and perplexity is 42.96875516484279
At time: 702.7196238040924 and batch: 1350, loss is 3.6533937788009645 and perplexity is 38.6054623764053
At time: 703.9665458202362 and batch: 1400, loss is 3.667072982788086 and perplexity is 39.137182836290684
At time: 705.216105222702 and batch: 1450, loss is 3.5875455856323244 and perplexity is 36.145251540438665
At time: 706.4667563438416 and batch: 1500, loss is 3.6010226821899414 and perplexity is 36.63568195141265
At time: 707.7160832881927 and batch: 1550, loss is 3.6170587682724 and perplexity is 37.22791072546203
At time: 708.9649620056152 and batch: 1600, loss is 3.694723768234253 and perplexity is 40.23445701769965
At time: 710.2136826515198 and batch: 1650, loss is 3.65053475856781 and perplexity is 38.49524620856335
At time: 711.4623754024506 and batch: 1700, loss is 3.6307262277603147 and perplexity is 37.740214658933894
At time: 712.7101490497589 and batch: 1750, loss is 3.6185670995712282 and perplexity is 37.28410511762567
At time: 713.9587082862854 and batch: 1800, loss is 3.594760317802429 and perplexity is 36.4069728387928
At time: 715.2071464061737 and batch: 1850, loss is 3.6094236850738524 and perplexity is 36.94475486457736
At time: 716.4603145122528 and batch: 1900, loss is 3.7158268785476682 and perplexity is 41.09255158957554
At time: 717.709303855896 and batch: 1950, loss is 3.6653393030166628 and perplexity is 39.06939027637184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.308897222474564 and perplexity of 74.35844288974471
finished 14 epochs...
Completing Train Step...
At time: 721.6228106021881 and batch: 50, loss is 3.865905785560608 and perplexity is 47.74650094297663
At time: 722.8677790164948 and batch: 100, loss is 3.8462749338150024 and perplexity is 46.81833659698884
At time: 724.1034197807312 and batch: 150, loss is 3.804810600280762 and perplexity is 44.91674208898943
At time: 725.3470048904419 and batch: 200, loss is 3.807303113937378 and perplexity is 45.02883732347455
At time: 726.5960893630981 and batch: 250, loss is 3.7933470487594603 and perplexity is 44.40477677880159
At time: 727.8449671268463 and batch: 300, loss is 3.797294673919678 and perplexity is 44.58041664493092
At time: 729.093236207962 and batch: 350, loss is 3.8102579927444458 and perplexity is 45.16208885469639
At time: 730.3410046100616 and batch: 400, loss is 3.7713420677185057 and perplexity is 43.43832290488712
At time: 731.5900909900665 and batch: 450, loss is 3.804964375495911 and perplexity is 44.92364970176417
At time: 732.8390746116638 and batch: 500, loss is 3.8201668548583982 and perplexity is 45.611818239428764
At time: 734.0882997512817 and batch: 550, loss is 3.7996623420715334 and perplexity is 44.68609333191334
At time: 735.3381998538971 and batch: 600, loss is 3.7618373966217042 and perplexity is 43.02741181349535
At time: 736.5884327888489 and batch: 650, loss is 3.7890577030181887 and perplexity is 44.21471724555864
At time: 737.8371715545654 and batch: 700, loss is 3.8365894174575805 and perplexity is 46.36706575538563
At time: 739.0858147144318 and batch: 750, loss is 3.770417137145996 and perplexity is 43.398164046954555
At time: 740.3357100486755 and batch: 800, loss is 3.7594027137756347 and perplexity is 42.922781134986096
At time: 741.5823922157288 and batch: 850, loss is 3.7665648221969605 and perplexity is 43.23130225927229
At time: 742.8327460289001 and batch: 900, loss is 3.719312710762024 and perplexity is 41.2360432783546
At time: 744.0822088718414 and batch: 950, loss is 3.810334868431091 and perplexity is 45.16556085474192
At time: 745.3317081928253 and batch: 1000, loss is 3.773447561264038 and perplexity is 43.52987836428362
At time: 746.6141920089722 and batch: 1050, loss is 3.742909827232361 and perplexity is 42.22066644003031
At time: 747.8580167293549 and batch: 1100, loss is 3.766378788948059 and perplexity is 43.22326054769481
At time: 749.1078877449036 and batch: 1150, loss is 3.747616477012634 and perplexity is 42.41985271275976
At time: 750.3563985824585 and batch: 1200, loss is 3.7833088064193725 and perplexity is 43.96126065389425
At time: 751.6047031879425 and batch: 1250, loss is 3.775484952926636 and perplexity is 43.6186561824207
At time: 752.852744102478 and batch: 1300, loss is 3.7573849678039553 and perplexity is 42.83626118325378
At time: 754.1008038520813 and batch: 1350, loss is 3.6503635025024415 and perplexity is 38.48865422863667
At time: 755.3497779369354 and batch: 1400, loss is 3.6643986749649047 and perplexity is 39.032657790424494
At time: 756.5982766151428 and batch: 1450, loss is 3.5851529741287234 and perplexity is 36.05887337170917
At time: 757.8477530479431 and batch: 1500, loss is 3.5991631937026978 and perplexity is 36.56762162091318
At time: 759.0971984863281 and batch: 1550, loss is 3.615473942756653 and perplexity is 37.168957710107065
At time: 760.3464925289154 and batch: 1600, loss is 3.6933114099502564 and perplexity is 40.17767165910382
At time: 761.6019673347473 and batch: 1650, loss is 3.6493670558929443 and perplexity is 38.45032144108627
At time: 762.8509140014648 and batch: 1700, loss is 3.6298697423934936 and perplexity is 37.7079045558782
At time: 764.0993387699127 and batch: 1750, loss is 3.6178273820877074 and perplexity is 37.25653561129278
At time: 765.3480756282806 and batch: 1800, loss is 3.5941261148452757 and perplexity is 36.383890749095855
At time: 766.5972483158112 and batch: 1850, loss is 3.608944840431213 and perplexity is 36.92706830153277
At time: 767.844812631607 and batch: 1900, loss is 3.71543496131897 and perplexity is 41.07644986611393
At time: 769.0923037528992 and batch: 1950, loss is 3.6646799516677855 and perplexity is 39.04363831192251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.30918706849564 and perplexity of 74.37999851230451
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 772.9851195812225 and batch: 50, loss is 3.867415976524353 and perplexity is 47.81866175183729
At time: 774.2408905029297 and batch: 100, loss is 3.85714626789093 and perplexity is 47.33009106171897
At time: 775.4777910709381 and batch: 150, loss is 3.8196399116516115 and perplexity is 45.58778973304341
At time: 776.7418019771576 and batch: 200, loss is 3.825295720100403 and perplexity is 45.84635605090496
At time: 777.987206697464 and batch: 250, loss is 3.8149806118011473 and perplexity is 45.37587661789977
At time: 779.2337918281555 and batch: 300, loss is 3.8170968770980833 and perplexity is 45.472005692339614
At time: 780.4797606468201 and batch: 350, loss is 3.8290979290008544 and perplexity is 46.021005289975
At time: 781.7258803844452 and batch: 400, loss is 3.7876141548156737 and perplexity is 44.150937215803324
At time: 782.9720783233643 and batch: 450, loss is 3.8265878343582154 and perplexity is 45.905633069320196
At time: 784.2175765037537 and batch: 500, loss is 3.844561667442322 and perplexity is 46.73819298855072
At time: 785.4626362323761 and batch: 550, loss is 3.8296109104156493 and perplexity is 46.044619266626675
At time: 786.7082448005676 and batch: 600, loss is 3.7878138399124146 and perplexity is 44.15975438027134
At time: 787.9540898799896 and batch: 650, loss is 3.8120127058029176 and perplexity is 45.24140492988273
At time: 789.2010531425476 and batch: 700, loss is 3.8581286334991454 and perplexity is 47.3766093606592
At time: 790.4491376876831 and batch: 750, loss is 3.793266091346741 and perplexity is 44.401182028474004
At time: 791.6994824409485 and batch: 800, loss is 3.7809639596939086 and perplexity is 43.85829899763019
At time: 792.9456915855408 and batch: 850, loss is 3.7888436555862426 and perplexity is 44.20525421168318
At time: 794.1971433162689 and batch: 900, loss is 3.739641990661621 and perplexity is 42.082921388933066
At time: 795.4426047801971 and batch: 950, loss is 3.827618427276611 and perplexity is 45.95296747673888
At time: 796.6884248256683 and batch: 1000, loss is 3.7906644916534424 and perplexity is 44.28581805743084
At time: 797.9347770214081 and batch: 1050, loss is 3.7563787269592286 and perplexity is 42.79317926664301
At time: 799.1822776794434 and batch: 1100, loss is 3.7712874698638914 and perplexity is 43.4359513303905
At time: 800.4304857254028 and batch: 1150, loss is 3.750901393890381 and perplexity is 42.55942752320382
At time: 801.6760730743408 and batch: 1200, loss is 3.7882352018356324 and perplexity is 44.178365540047515
At time: 802.9235711097717 and batch: 1250, loss is 3.782636637687683 and perplexity is 43.93172119793857
At time: 804.1696660518646 and batch: 1300, loss is 3.761577830314636 and perplexity is 43.016244796461606
At time: 805.4181892871857 and batch: 1350, loss is 3.6516762447357176 and perplexity is 38.53921308865933
At time: 806.664276599884 and batch: 1400, loss is 3.6679200744628906 and perplexity is 39.17034966373504
At time: 807.9105515480042 and batch: 1450, loss is 3.584567675590515 and perplexity is 36.0377743410535
At time: 809.1567528247833 and batch: 1500, loss is 3.593503394126892 and perplexity is 36.36124079953935
At time: 810.4030990600586 and batch: 1550, loss is 3.61304048538208 and perplexity is 37.07861859863094
At time: 811.649820804596 and batch: 1600, loss is 3.6914107608795166 and perplexity is 40.10138052909973
At time: 812.8965094089508 and batch: 1650, loss is 3.650222635269165 and perplexity is 38.483232820261314
At time: 814.1414585113525 and batch: 1700, loss is 3.63227885723114 and perplexity is 37.79885674138085
At time: 815.388543844223 and batch: 1750, loss is 3.618194718360901 and perplexity is 37.27022380216693
At time: 816.6355087757111 and batch: 1800, loss is 3.590333595275879 and perplexity is 36.24616545942481
At time: 817.8822312355042 and batch: 1850, loss is 3.6022576236724855 and perplexity is 36.68095282248058
At time: 819.1282818317413 and batch: 1900, loss is 3.711226181983948 and perplexity is 40.90393145338987
At time: 820.3742961883545 and batch: 1950, loss is 3.662719602584839 and perplexity is 38.967174124100524
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.304695164880087 and perplexity of 74.04663999574505
finished 16 epochs...
Completing Train Step...
At time: 824.3219866752625 and batch: 50, loss is 3.8752393388748168 and perplexity is 48.19423166403064
At time: 825.5566508769989 and batch: 100, loss is 3.8553664875030518 and perplexity is 47.24592881126836
At time: 826.8001043796539 and batch: 150, loss is 3.8132687473297118 and perplexity is 45.298265715483666
At time: 828.0420205593109 and batch: 200, loss is 3.8167091035842895 and perplexity is 45.45437627124523
At time: 829.2853462696075 and batch: 250, loss is 3.8054341650009156 and perplexity is 44.944759319070656
At time: 830.5361328125 and batch: 300, loss is 3.8076219034194945 and perplexity is 45.0431943315152
At time: 831.7861361503601 and batch: 350, loss is 3.8183802318573 and perplexity is 45.53039986946396
At time: 833.0366480350494 and batch: 400, loss is 3.778166027069092 and perplexity is 43.735757942745394
At time: 834.2863342761993 and batch: 450, loss is 3.814897685050964 and perplexity is 45.37211389993228
At time: 835.53795170784 and batch: 500, loss is 3.8328776502609254 and perplexity is 46.19528101142465
At time: 836.7891321182251 and batch: 550, loss is 3.8169048261642455 and perplexity is 45.46327358971399
At time: 838.0402679443359 and batch: 600, loss is 3.776917004585266 and perplexity is 43.68116509866992
At time: 839.32754945755 and batch: 650, loss is 3.8009044981002806 and perplexity is 44.74163492066489
At time: 840.5773804187775 and batch: 700, loss is 3.847712450027466 and perplexity is 46.88568711201817
At time: 841.8311877250671 and batch: 750, loss is 3.7840059757232667 and perplexity is 43.991919781442135
At time: 843.0850615501404 and batch: 800, loss is 3.771832275390625 and perplexity is 43.459621924083876
At time: 844.3352961540222 and batch: 850, loss is 3.7797670793533324 and perplexity is 43.805837263260784
At time: 845.5854828357697 and batch: 900, loss is 3.730834197998047 and perplexity is 41.71389129861364
At time: 846.8350465297699 and batch: 950, loss is 3.820235056877136 and perplexity is 45.61492916359545
At time: 848.0863509178162 and batch: 1000, loss is 3.783455853462219 and perplexity is 43.96772550258001
At time: 849.33820271492 and batch: 1050, loss is 3.749339990615845 and perplexity is 42.49302694623614
At time: 850.5892226696014 and batch: 1100, loss is 3.7653343725204467 and perplexity is 43.17814103020785
At time: 851.839581489563 and batch: 1150, loss is 3.7457796001434325 and perplexity is 42.34200418748361
At time: 853.0902135372162 and batch: 1200, loss is 3.7836029148101806 and perplexity is 43.97419193102841
At time: 854.3402092456818 and batch: 1250, loss is 3.7785577964782715 and perplexity is 43.75289563158657
At time: 855.5900928974152 and batch: 1300, loss is 3.758551993370056 and perplexity is 42.88628137695618
At time: 856.8403780460358 and batch: 1350, loss is 3.6499520778656005 and perplexity is 38.472822305093175
At time: 858.0902850627899 and batch: 1400, loss is 3.6671244859695435 and perplexity is 39.139198577628136
At time: 859.3406472206116 and batch: 1450, loss is 3.5847034549713133 and perplexity is 36.04266785995084
At time: 860.5898163318634 and batch: 1500, loss is 3.5948200368881227 and perplexity is 36.40914709484524
At time: 861.8392882347107 and batch: 1550, loss is 3.6151570224761964 and perplexity is 37.15717998000464
At time: 863.0906503200531 and batch: 1600, loss is 3.6941487407684326 and perplexity is 40.211327750461386
At time: 864.3408288955688 and batch: 1650, loss is 3.6532210874557496 and perplexity is 38.598796122793594
At time: 865.5913128852844 and batch: 1700, loss is 3.635765242576599 and perplexity is 37.93086810913288
At time: 866.8491578102112 and batch: 1750, loss is 3.6226168346405028 and perplexity is 37.43540201504588
At time: 868.1003751754761 and batch: 1800, loss is 3.5947302770614624 and perplexity is 36.40587916277986
At time: 869.350536108017 and batch: 1850, loss is 3.6068946266174318 and perplexity is 36.85143747217614
At time: 870.60107421875 and batch: 1900, loss is 3.716268653869629 and perplexity is 41.11070927529764
At time: 871.8512260913849 and batch: 1950, loss is 3.6669130516052246 and perplexity is 39.13092408084423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.303736203215843 and perplexity of 73.9756661426642
finished 17 epochs...
Completing Train Step...
At time: 875.7614753246307 and batch: 50, loss is 3.8753259992599487 and perplexity is 48.19840837568289
At time: 876.9811766147614 and batch: 100, loss is 3.8534543704986572 and perplexity is 47.155675382456536
At time: 878.2215504646301 and batch: 150, loss is 3.8106807708740233 and perplexity is 45.18118643488535
At time: 879.4690699577332 and batch: 200, loss is 3.813767881393433 and perplexity is 45.32088126655618
At time: 880.7167377471924 and batch: 250, loss is 3.802139678001404 and perplexity is 44.796933033390445
At time: 881.970516204834 and batch: 300, loss is 3.80421115398407 and perplexity is 44.88982498277057
At time: 883.2196834087372 and batch: 350, loss is 3.8144616889953613 and perplexity is 45.35233614906153
At time: 884.4688727855682 and batch: 400, loss is 3.774148154258728 and perplexity is 43.56038577751751
At time: 885.7171769142151 and batch: 450, loss is 3.810501413345337 and perplexity is 45.1730835756194
At time: 886.9657511711121 and batch: 500, loss is 3.8285714292526247 and perplexity is 45.99678161971427
At time: 888.2187266349792 and batch: 550, loss is 3.8122331047058107 and perplexity is 45.25137718479127
At time: 889.4677815437317 and batch: 600, loss is 3.7727630376815795 and perplexity is 43.500091332127816
At time: 890.7157821655273 and batch: 650, loss is 3.796672167778015 and perplexity is 44.55267369774498
At time: 891.9639713764191 and batch: 700, loss is 3.8437350368499756 and perplexity is 46.69957373252374
At time: 893.2127513885498 and batch: 750, loss is 3.780537476539612 and perplexity is 43.839598160011164
At time: 894.4607145786285 and batch: 800, loss is 3.7684202098846438 and perplexity is 43.31158754233791
At time: 895.7083849906921 and batch: 850, loss is 3.7762986516952513 and perplexity is 43.65416307324255
At time: 896.9559669494629 and batch: 900, loss is 3.7276165771484373 and perplexity is 41.579887514550315
At time: 898.2046942710876 and batch: 950, loss is 3.8175050973892213 and perplexity is 45.490572077071626
At time: 899.4529156684875 and batch: 1000, loss is 3.780786437988281 and perplexity is 43.850513888619574
At time: 900.7396409511566 and batch: 1050, loss is 3.746753702163696 and perplexity is 42.383269714458265
At time: 901.9938411712646 and batch: 1100, loss is 3.763131513595581 and perplexity is 43.08313036284926
At time: 903.243714094162 and batch: 1150, loss is 3.743808159828186 and perplexity is 42.258611682082915
At time: 904.4922506809235 and batch: 1200, loss is 3.78172260761261 and perplexity is 43.891584629323674
At time: 905.7411358356476 and batch: 1250, loss is 3.77688277721405 and perplexity is 43.67967003280318
At time: 906.9891278743744 and batch: 1300, loss is 3.7573469924926757 and perplexity is 42.83463449378851
At time: 908.2378435134888 and batch: 1350, loss is 3.649126214981079 and perplexity is 38.441062145662215
At time: 909.4859006404877 and batch: 1400, loss is 3.6665795612335206 and perplexity is 39.11787647017458
At time: 910.7341754436493 and batch: 1450, loss is 3.5845916938781737 and perplexity is 36.03863991707899
At time: 911.9830222129822 and batch: 1500, loss is 3.5952092742919923 and perplexity is 36.42332165519312
At time: 913.230783700943 and batch: 1550, loss is 3.6158225917816162 and perplexity is 37.18191889029172
At time: 914.4870710372925 and batch: 1600, loss is 3.6950008773803713 and perplexity is 40.245607898662556
At time: 915.7370648384094 and batch: 1650, loss is 3.654211230278015 and perplexity is 38.63703337076705
At time: 916.9869666099548 and batch: 1700, loss is 3.63686909198761 and perplexity is 37.97276119312849
At time: 918.2354202270508 and batch: 1750, loss is 3.6240393924713135 and perplexity is 37.48869393576439
At time: 919.4825296401978 and batch: 1800, loss is 3.5960744714736936 and perplexity is 36.454848647002954
At time: 920.7349634170532 and batch: 1850, loss is 3.608437213897705 and perplexity is 36.90832789882351
At time: 921.9886586666107 and batch: 1900, loss is 3.717848706245422 and perplexity is 41.175717693986996
At time: 923.2372670173645 and batch: 1950, loss is 3.6680771589279173 and perplexity is 39.17650320045673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.303315770348838 and perplexity of 73.94457087845278
finished 18 epochs...
Completing Train Step...
At time: 927.1550204753876 and batch: 50, loss is 3.874137268066406 and perplexity is 48.14114746482593
At time: 928.3761162757874 and batch: 100, loss is 3.8515074682235717 and perplexity is 47.063957202908384
At time: 929.6005544662476 and batch: 150, loss is 3.8084993600845336 and perplexity is 45.08273512772666
At time: 930.8340291976929 and batch: 200, loss is 3.8114656829833984 and perplexity is 45.21666361664739
At time: 932.1022238731384 and batch: 250, loss is 3.7996613931655885 and perplexity is 44.68605092903384
At time: 933.3521113395691 and batch: 300, loss is 3.801685290336609 and perplexity is 44.77658248346901
At time: 934.6024639606476 and batch: 350, loss is 3.811684556007385 and perplexity is 45.22656140768797
At time: 935.8517935276031 and batch: 400, loss is 3.771277003288269 and perplexity is 43.435496707100356
At time: 937.1015706062317 and batch: 450, loss is 3.8075613975524902 and perplexity is 45.04046903643853
At time: 938.3511507511139 and batch: 500, loss is 3.8257354307174682 and perplexity is 45.86651961315562
At time: 939.6012332439423 and batch: 550, loss is 3.8092629146575927 and perplexity is 45.117171401613575
At time: 940.8499429225922 and batch: 600, loss is 3.770075116157532 and perplexity is 43.38332350202328
At time: 942.1012697219849 and batch: 650, loss is 3.793969964981079 and perplexity is 44.432445851436874
At time: 943.3510203361511 and batch: 700, loss is 3.841157875061035 and perplexity is 46.579376326148775
At time: 944.5997269153595 and batch: 750, loss is 3.778271727561951 and perplexity is 43.74038107824505
At time: 945.8493006229401 and batch: 800, loss is 3.766217212677002 and perplexity is 43.21627725861468
At time: 947.0997748374939 and batch: 850, loss is 3.7740775966644287 and perplexity is 43.5573123699177
At time: 948.3490805625916 and batch: 900, loss is 3.72554310798645 and perplexity is 41.493762219957546
At time: 949.5992224216461 and batch: 950, loss is 3.8156639528274536 and perplexity is 45.40689441265625
At time: 950.8478031158447 and batch: 1000, loss is 3.7790356874465942 and perplexity is 43.77380974218112
At time: 952.0971281528473 and batch: 1050, loss is 3.745037622451782 and perplexity is 42.31059901736534
At time: 953.3456659317017 and batch: 1100, loss is 3.761619305610657 and perplexity is 43.01802894494703
At time: 954.5961394309998 and batch: 1150, loss is 3.742414803504944 and perplexity is 42.199771380556946
At time: 955.8453059196472 and batch: 1200, loss is 3.780364646911621 and perplexity is 43.83202203327834
At time: 957.0951614379883 and batch: 1250, loss is 3.775640916824341 and perplexity is 43.62545964858533
At time: 958.3443503379822 and batch: 1300, loss is 3.7564298725128173 and perplexity is 42.79536800345802
At time: 959.593282699585 and batch: 1350, loss is 3.6483658742904663 and perplexity is 38.41184495084112
At time: 960.8420164585114 and batch: 1400, loss is 3.665955147743225 and perplexity is 39.093458364685496
At time: 962.0908932685852 and batch: 1450, loss is 3.5842267751693724 and perplexity is 36.02549114239635
At time: 963.346321105957 and batch: 1500, loss is 3.595155930519104 and perplexity is 36.42137874961633
At time: 964.5979099273682 and batch: 1550, loss is 3.615946102142334 and perplexity is 37.18651152611925
At time: 965.8478486537933 and batch: 1600, loss is 3.6951643896102904 and perplexity is 40.25218908579214
At time: 967.097371339798 and batch: 1650, loss is 3.654454355239868 and perplexity is 38.64642814003662
At time: 968.34716629982 and batch: 1700, loss is 3.637192177772522 and perplexity is 37.98503163457971
At time: 969.5970327854156 and batch: 1750, loss is 3.6245299577713013 and perplexity is 37.507089099796815
At time: 970.846529006958 and batch: 1800, loss is 3.596520447731018 and perplexity is 36.47111026984319
At time: 972.0961384773254 and batch: 1850, loss is 3.609035611152649 and perplexity is 36.930420350294646
At time: 973.3456366062164 and batch: 1900, loss is 3.718423590660095 and perplexity is 41.19939577778079
At time: 974.5962452888489 and batch: 1950, loss is 3.668378400802612 and perplexity is 39.18830658147188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.303098030977471 and perplexity of 73.9284719868186
finished 19 epochs...
Completing Train Step...
At time: 978.5006582736969 and batch: 50, loss is 3.8727395820617674 and perplexity is 48.07390825736283
At time: 979.7396483421326 and batch: 100, loss is 3.8496886539459227 and perplexity is 46.97843440420514
At time: 980.9665575027466 and batch: 150, loss is 3.806541109085083 and perplexity is 44.99453820064952
At time: 982.1960639953613 and batch: 200, loss is 3.80944878578186 and perplexity is 45.12555816038976
At time: 983.4387927055359 and batch: 250, loss is 3.797545394897461 and perplexity is 44.59159529188421
At time: 984.686115026474 and batch: 300, loss is 3.7995387220382693 and perplexity is 44.68056957699962
At time: 985.9338600635529 and batch: 350, loss is 3.8093893241882326 and perplexity is 45.122875002561415
At time: 987.1867065429688 and batch: 400, loss is 3.7689119958877564 and perplexity is 43.33289281325143
At time: 988.4403545856476 and batch: 450, loss is 3.805207414627075 and perplexity is 44.93456923343941
At time: 989.6868321895599 and batch: 500, loss is 3.8234612798690795 and perplexity is 45.76233074417045
At time: 990.9333126544952 and batch: 550, loss is 3.8069174814224245 and perplexity is 45.01147608743578
At time: 992.1802744865417 and batch: 600, loss is 3.767934799194336 and perplexity is 43.29056873651989
At time: 993.426177740097 and batch: 650, loss is 3.7918357181549074 and perplexity is 44.337717168052826
At time: 994.6945204734802 and batch: 700, loss is 3.839101128578186 and perplexity is 46.48367281038852
At time: 995.941611289978 and batch: 750, loss is 3.7764348649978636 and perplexity is 43.660109755966985
At time: 997.1872510910034 and batch: 800, loss is 3.7644447660446168 and perplexity is 43.139746556851264
At time: 998.4329843521118 and batch: 850, loss is 3.7722987031936643 and perplexity is 43.479897428220696
At time: 999.6791944503784 and batch: 900, loss is 3.7238681316375732 and perplexity is 41.424319323453254
At time: 1000.9297392368317 and batch: 950, loss is 3.814118332862854 and perplexity is 45.33676681938658
At time: 1002.1762089729309 and batch: 1000, loss is 3.7775777482986452 and perplexity is 43.710036691213176
At time: 1003.4237442016602 and batch: 1050, loss is 3.7436062335968017 and perplexity is 42.250079421355046
At time: 1004.6709585189819 and batch: 1100, loss is 3.7603147792816163 and perplexity is 42.961947381456234
At time: 1005.9185526371002 and batch: 1150, loss is 3.7412038803100587 and perplexity is 42.14870162558924
At time: 1007.1659462451935 and batch: 1200, loss is 3.7791803312301635 and perplexity is 43.780141809579526
At time: 1008.4110844135284 and batch: 1250, loss is 3.7745421600341795 and perplexity is 43.57755220270801
At time: 1009.6584112644196 and batch: 1300, loss is 3.7555845975875854 and perplexity is 42.75920943608671
At time: 1010.9092860221863 and batch: 1350, loss is 3.647600574493408 and perplexity is 38.382459619423905
At time: 1012.1586678028107 and batch: 1400, loss is 3.665274701118469 and perplexity is 39.066866401123164
At time: 1013.4047114849091 and batch: 1450, loss is 3.5837359380722047 and perplexity is 36.00781283383972
At time: 1014.6517949104309 and batch: 1500, loss is 3.5948913860321046 and perplexity is 36.411744948999804
At time: 1015.9052186012268 and batch: 1550, loss is 3.6158089733123777 and perplexity is 37.181412532921
At time: 1017.1518714427948 and batch: 1600, loss is 3.6950317096710203 and perplexity is 40.24684878207217
At time: 1018.3992042541504 and batch: 1650, loss is 3.654382572174072 and perplexity is 38.6436540805091
At time: 1019.6461579799652 and batch: 1700, loss is 3.637193036079407 and perplexity is 37.98506423740789
At time: 1020.8921258449554 and batch: 1750, loss is 3.624643774032593 and perplexity is 37.51135825939537
At time: 1022.1387524604797 and batch: 1800, loss is 3.5966051769256593 and perplexity is 36.474200568561436
At time: 1023.3855702877045 and batch: 1850, loss is 3.609243278503418 and perplexity is 36.93809038923235
At time: 1024.6312687397003 and batch: 1900, loss is 3.7185994291305544 and perplexity is 41.206640853481055
At time: 1025.878512620926 and batch: 1950, loss is 3.6683498859405517 and perplexity is 39.18718914824713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.302986748273983 and perplexity of 73.92024548433339
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc433bcbb38>
ELAPSED
3162.124824285507


RESULTS SO FAR:
[{'best_accuracy': -75.2531559304004, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.96225198742506, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7460609200881098, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.7558732386815785, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -73.92024548433339, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.06428528362550812, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.41802598995097096, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.47589954029325743, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.2146320946900251, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6347050666809082 and batch: 50, loss is 7.663614416122437 and perplexity is 2129.4402188727786
At time: 2.8346831798553467 and batch: 100, loss is 6.775740938186646 and perplexity is 876.3284277424951
At time: 4.01400089263916 and batch: 150, loss is 6.405453281402588 and perplexity is 605.1360334310809
At time: 5.193017244338989 and batch: 200, loss is 6.238608875274658 and perplexity is 512.1455568066953
At time: 6.3725502490997314 and batch: 250, loss is 6.111769189834595 and perplexity is 451.1361550478838
At time: 7.551631689071655 and batch: 300, loss is 5.98863715171814 and perplexity is 398.8706391712215
At time: 8.735763311386108 and batch: 350, loss is 5.8943048858642575 and perplexity is 362.9644464718187
At time: 9.916934728622437 and batch: 400, loss is 5.800276565551758 and perplexity is 330.39092202290465
At time: 11.097965478897095 and batch: 450, loss is 5.698506536483765 and perplexity is 298.42138654355904
At time: 12.278702735900879 and batch: 500, loss is 5.661009321212768 and perplexity is 287.43861408479444
At time: 13.459303855895996 and batch: 550, loss is 5.60365083694458 and perplexity is 271.4154945444745
At time: 14.639588832855225 and batch: 600, loss is 5.602156944274903 and perplexity is 271.010331637037
At time: 15.820684671401978 and batch: 650, loss is 5.6558161544799805 and perplexity is 285.94976669882465
At time: 17.003355503082275 and batch: 700, loss is 5.579299249649048 and perplexity is 264.8859218320911
At time: 18.227020025253296 and batch: 750, loss is 5.501401958465576 and perplexity is 245.03522077200367
At time: 19.513908863067627 and batch: 800, loss is 5.50397557258606 and perplexity is 245.66665906692742
At time: 20.840392589569092 and batch: 850, loss is 5.50390474319458 and perplexity is 245.64925926317486
At time: 22.166183948516846 and batch: 900, loss is 5.491684894561768 and perplexity is 242.665728769867
At time: 23.492162466049194 and batch: 950, loss is 5.5132330131530765 and perplexity is 247.95146296335253
At time: 24.81928825378418 and batch: 1000, loss is 5.475169162750245 and perplexity is 238.6908411148004
At time: 26.145665884017944 and batch: 1050, loss is 5.368325595855713 and perplexity is 214.50340145806823
At time: 27.471112728118896 and batch: 1100, loss is 5.442317237854004 and perplexity is 230.97679197964604
At time: 28.795600414276123 and batch: 1150, loss is 5.33982479095459 and perplexity is 208.4761801764672
At time: 30.121073961257935 and batch: 1200, loss is 5.410802860260009 and perplexity is 223.81120468920847
At time: 31.447322130203247 and batch: 1250, loss is 5.3726544761657715 and perplexity is 215.4339737238784
At time: 32.7731773853302 and batch: 1300, loss is 5.37882321357727 and perplexity is 216.76703676794563
At time: 34.09915113449097 and batch: 1350, loss is 5.316975116729736 and perplexity is 203.76657871348684
At time: 35.42476511001587 and batch: 1400, loss is 5.319342584609985 and perplexity is 204.24956104064321
At time: 36.75010395050049 and batch: 1450, loss is 5.287285842895508 and perplexity is 197.805820094848
At time: 38.07645535469055 and batch: 1500, loss is 5.238418798446656 and perplexity is 188.37201267874906
At time: 39.40340256690979 and batch: 1550, loss is 5.225519380569458 and perplexity is 185.95772827948187
At time: 40.729185581207275 and batch: 1600, loss is 5.259743089675903 and perplexity is 192.43204716655967
At time: 42.055341720581055 and batch: 1650, loss is 5.2377270984649655 and perplexity is 188.24176081382777
At time: 43.38204574584961 and batch: 1700, loss is 5.254709806442261 and perplexity is 191.465915616466
At time: 44.70633864402771 and batch: 1750, loss is 5.240232467651367 and perplexity is 188.71396719963067
At time: 46.02985954284668 and batch: 1800, loss is 5.21751838684082 and perplexity is 184.4758179448498
At time: 47.35678195953369 and batch: 1850, loss is 5.191243715286255 and perplexity is 179.69189957554337
At time: 48.6827232837677 and batch: 1900, loss is 5.260824689865112 and perplexity is 192.64029430495532
At time: 50.008575677871704 and batch: 1950, loss is 5.183632640838623 and perplexity is 178.32944260802245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.847653411155523 and perplexity of 127.44098709719016
finished 1 epochs...
Completing Train Step...
At time: 53.97036337852478 and batch: 50, loss is 5.090913171768189 and perplexity is 162.5382196186171
At time: 55.25007653236389 and batch: 100, loss is 5.028013496398926 and perplexity is 152.62951226732469
At time: 56.49920463562012 and batch: 150, loss is 4.9572739410400395 and perplexity is 142.20560615650874
At time: 57.74775195121765 and batch: 200, loss is 4.921561365127563 and perplexity is 137.21669137269961
At time: 58.99621272087097 and batch: 250, loss is 4.933079614639282 and perplexity is 138.80632478353922
At time: 60.244312047958374 and batch: 300, loss is 4.94087924003601 and perplexity is 139.89319520070364
At time: 61.493693351745605 and batch: 350, loss is 4.934694728851318 and perplexity is 139.03069399359362
At time: 62.74249744415283 and batch: 400, loss is 4.882414846420288 and perplexity is 131.9489158334466
At time: 63.992005348205566 and batch: 450, loss is 4.855323104858399 and perplexity is 128.4221783417614
At time: 65.26308512687683 and batch: 500, loss is 4.855102338790894 and perplexity is 128.39383021173617
At time: 66.5125024318695 and batch: 550, loss is 4.818820333480835 and perplexity is 123.8189395344999
At time: 67.76222729682922 and batch: 600, loss is 4.78996129989624 and perplexity is 120.29671307785215
At time: 69.01562833786011 and batch: 650, loss is 4.855093584060669 and perplexity is 128.39270616331058
At time: 70.26442646980286 and batch: 700, loss is 4.873627214431763 and perplexity is 130.7944771400544
At time: 71.51291036605835 and batch: 750, loss is 4.811894407272339 and perplexity is 122.96434155348958
At time: 72.76071095466614 and batch: 800, loss is 4.809487142562866 and perplexity is 122.6686898322949
At time: 74.01038670539856 and batch: 850, loss is 4.808482885360718 and perplexity is 122.54556075403283
At time: 75.25900387763977 and batch: 900, loss is 4.78972825050354 and perplexity is 120.26868126845046
At time: 76.50927400588989 and batch: 950, loss is 4.842040023803711 and perplexity is 126.72761556069713
At time: 77.75874304771423 and batch: 1000, loss is 4.812468299865722 and perplexity is 123.03493013155108
At time: 79.00747346878052 and batch: 1050, loss is 4.734707536697388 and perplexity is 113.830162704195
At time: 80.25725507736206 and batch: 1100, loss is 4.792965602874756 and perplexity is 120.65866428455915
At time: 81.50545382499695 and batch: 1150, loss is 4.733885316848755 and perplexity is 113.73660775168655
At time: 82.76022863388062 and batch: 1200, loss is 4.8040534782409665 and perplexity is 122.00395695210919
At time: 84.02014088630676 and batch: 1250, loss is 4.778196649551392 and perplexity is 118.88975671337568
At time: 85.2723126411438 and batch: 1300, loss is 4.77575945854187 and perplexity is 118.60035247714364
At time: 86.52052402496338 and batch: 1350, loss is 4.672115354537964 and perplexity is 106.92368487603
At time: 87.77006530761719 and batch: 1400, loss is 4.679018211364746 and perplexity is 107.66431706220283
At time: 89.02027201652527 and batch: 1450, loss is 4.63393720626831 and perplexity is 102.91847873577566
At time: 90.26934027671814 and batch: 1500, loss is 4.613643732070923 and perplexity is 100.85095481911024
At time: 91.51826882362366 and batch: 1550, loss is 4.614171438217163 and perplexity is 100.90418853246598
At time: 92.76663875579834 and batch: 1600, loss is 4.67956621170044 and perplexity is 107.72333331308087
At time: 94.01545786857605 and batch: 1650, loss is 4.654112758636475 and perplexity is 105.01600410983995
At time: 95.2645902633667 and batch: 1700, loss is 4.666053667068481 and perplexity is 106.27750735690869
At time: 96.51542949676514 and batch: 1750, loss is 4.6449567985534665 and perplexity is 104.05887019459095
At time: 97.76401925086975 and batch: 1800, loss is 4.616346244812012 and perplexity is 101.12387442771225
At time: 99.014399766922 and batch: 1850, loss is 4.638244762420654 and perplexity is 103.36276206275869
At time: 100.2628059387207 and batch: 1900, loss is 4.735794906616211 and perplexity is 113.9540055182472
At time: 101.51274085044861 and batch: 1950, loss is 4.655697460174561 and perplexity is 105.18255506499918
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.567817723473837 and perplexity of 96.33365354870878
finished 2 epochs...
Completing Train Step...
At time: 105.43988943099976 and batch: 50, loss is 4.638161315917968 and perplexity is 103.35413716162056
At time: 106.71517872810364 and batch: 100, loss is 4.570913419723511 and perplexity is 96.63233535425893
At time: 107.96331334114075 and batch: 150, loss is 4.527805166244507 and perplexity is 92.55519472045505
At time: 109.21123456954956 and batch: 200, loss is 4.517160053253174 and perplexity is 91.57515976081255
At time: 110.45992660522461 and batch: 250, loss is 4.522339725494385 and perplexity is 92.05071963271118
At time: 111.70835304260254 and batch: 300, loss is 4.534947900772095 and perplexity is 93.21865855777138
At time: 112.96169996261597 and batch: 350, loss is 4.546752271652221 and perplexity is 94.32556649896037
At time: 114.21162939071655 and batch: 400, loss is 4.4906998634338375 and perplexity is 89.18384055112793
At time: 115.46115946769714 and batch: 450, loss is 4.4937414455413816 and perplexity is 89.45551347313747
At time: 116.70986580848694 and batch: 500, loss is 4.499981126785278 and perplexity is 90.01543240390602
At time: 117.95948648452759 and batch: 550, loss is 4.471069936752319 and perplexity is 87.45023920123722
At time: 119.20763683319092 and batch: 600, loss is 4.449524354934693 and perplexity is 85.5862256533371
At time: 120.45607495307922 and batch: 650, loss is 4.505484361648559 and perplexity is 90.51217405906615
At time: 121.70564150810242 and batch: 700, loss is 4.540214891433716 and perplexity is 93.71093563323487
At time: 122.96039628982544 and batch: 750, loss is 4.489838523864746 and perplexity is 89.10705605384784
At time: 124.20737075805664 and batch: 800, loss is 4.484010162353516 and perplexity is 88.58921845622848
At time: 125.45427942276001 and batch: 850, loss is 4.483466911315918 and perplexity is 88.54110534131517
At time: 126.72341680526733 and batch: 900, loss is 4.457956981658936 and perplexity is 86.31099390225886
At time: 127.97067666053772 and batch: 950, loss is 4.529162797927857 and perplexity is 92.6809359210716
At time: 129.21920037269592 and batch: 1000, loss is 4.505758256912231 and perplexity is 90.53696831020456
At time: 130.47355723381042 and batch: 1050, loss is 4.440588340759278 and perplexity is 84.82483290246263
At time: 131.72120308876038 and batch: 1100, loss is 4.48420931816101 and perplexity is 88.60686327054071
At time: 132.96732378005981 and batch: 1150, loss is 4.447416791915893 and perplexity is 85.40603723515187
At time: 134.21307063102722 and batch: 1200, loss is 4.5082956981658935 and perplexity is 90.7669922612883
At time: 135.45878410339355 and batch: 1250, loss is 4.500429172515869 and perplexity is 90.05577247050431
At time: 136.70577764511108 and batch: 1300, loss is 4.490573186874389 and perplexity is 89.17254376458266
At time: 137.95353436470032 and batch: 1350, loss is 4.374555015563965 and perplexity is 79.40449792387993
At time: 139.1996636390686 and batch: 1400, loss is 4.387297763824463 and perplexity is 80.42280367948716
At time: 140.44657254219055 and batch: 1450, loss is 4.34332160949707 and perplexity is 76.96275545895183
At time: 141.69521236419678 and batch: 1500, loss is 4.330517501831054 and perplexity is 75.9835980475487
At time: 142.94887804985046 and batch: 1550, loss is 4.342920217514038 and perplexity is 76.93186942503645
At time: 144.19609022140503 and batch: 1600, loss is 4.414998378753662 and perplexity is 82.68170685858509
At time: 145.44307374954224 and batch: 1650, loss is 4.380860948562622 and perplexity is 79.90679944295032
At time: 146.69753885269165 and batch: 1700, loss is 4.3899134826660156 and perplexity is 80.63344248821353
At time: 147.94955134391785 and batch: 1750, loss is 4.374396600723267 and perplexity is 79.3919200692763
At time: 149.1977608203888 and batch: 1800, loss is 4.342049140930175 and perplexity is 76.86488505352176
At time: 150.44653058052063 and batch: 1850, loss is 4.377695722579956 and perplexity is 79.6542762225196
At time: 151.692223072052 and batch: 1900, loss is 4.478990440368652 and perplexity is 88.14563946176422
At time: 152.9391794204712 and batch: 1950, loss is 4.403620128631592 and perplexity is 81.74626565162852
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47712771393532 and perplexity of 87.98160107590554
finished 3 epochs...
Completing Train Step...
At time: 156.84581565856934 and batch: 50, loss is 4.385448546409607 and perplexity is 80.2742218527632
At time: 158.12357330322266 and batch: 100, loss is 4.330357933044434 and perplexity is 75.97147440430842
At time: 159.37259721755981 and batch: 150, loss is 4.292154188156128 and perplexity is 73.12382142492316
At time: 160.6223623752594 and batch: 200, loss is 4.291935520172119 and perplexity is 73.10783333441462
At time: 161.8745677471161 and batch: 250, loss is 4.286094903945923 and perplexity is 72.68208306902746
At time: 163.12437272071838 and batch: 300, loss is 4.2984834575653075 and perplexity is 73.58810954330863
At time: 164.37322235107422 and batch: 350, loss is 4.314537439346314 and perplexity is 74.77902560779381
At time: 165.62537360191345 and batch: 400, loss is 4.259337916374206 and perplexity is 70.76311684020966
At time: 166.87627291679382 and batch: 450, loss is 4.278720607757569 and perplexity is 72.14807524676812
At time: 168.12800240516663 and batch: 500, loss is 4.28883915901184 and perplexity is 72.88181517626718
At time: 169.3794972896576 and batch: 550, loss is 4.258285284042358 and perplexity is 70.68866848576809
At time: 170.62974286079407 and batch: 600, loss is 4.244224724769592 and perplexity is 69.70170118887741
At time: 171.8806233406067 and batch: 650, loss is 4.294370346069336 and perplexity is 73.28605506169804
At time: 173.13217997550964 and batch: 700, loss is 4.3330624294281 and perplexity is 76.17721707184153
At time: 174.38456988334656 and batch: 750, loss is 4.28616473197937 and perplexity is 72.68715849315637
At time: 175.6360592842102 and batch: 800, loss is 4.278863444328308 and perplexity is 72.15838136644967
At time: 176.88633751869202 and batch: 850, loss is 4.281154022216797 and perplexity is 72.32385520228165
At time: 178.13657999038696 and batch: 900, loss is 4.249740810394287 and perplexity is 70.0872441071145
At time: 179.38756728172302 and batch: 950, loss is 4.332400436401367 and perplexity is 76.1268049734139
At time: 180.63764309883118 and batch: 1000, loss is 4.311774682998657 and perplexity is 74.57271450500673
At time: 181.888601064682 and batch: 1050, loss is 4.25083254814148 and perplexity is 70.16380278049563
At time: 183.13873767852783 and batch: 1100, loss is 4.287857837677002 and perplexity is 72.81032977692338
At time: 184.38886952400208 and batch: 1150, loss is 4.258033003807068 and perplexity is 70.67083738116231
At time: 185.63702869415283 and batch: 1200, loss is 4.311498174667358 and perplexity is 74.55209737869345
At time: 186.8872241973877 and batch: 1250, loss is 4.319092330932617 and perplexity is 75.12041286310416
At time: 188.13630843162537 and batch: 1300, loss is 4.304121370315552 and perplexity is 74.00416462342767
At time: 189.38757395744324 and batch: 1350, loss is 4.182280125617981 and perplexity is 65.51506561733012
At time: 190.6375343799591 and batch: 1400, loss is 4.206370491981506 and perplexity is 67.11251182742605
At time: 191.88769793510437 and batch: 1450, loss is 4.155838880538941 and perplexity is 63.8054672682492
At time: 193.13827896118164 and batch: 1500, loss is 4.146574139595032 and perplexity is 63.217056090639275
At time: 194.3882007598877 and batch: 1550, loss is 4.164375457763672 and perplexity is 64.35247904923166
At time: 195.63701462745667 and batch: 1600, loss is 4.2371205234527585 and perplexity is 69.20828102482338
At time: 196.88713693618774 and batch: 1650, loss is 4.204145665168762 and perplexity is 66.9633640871093
At time: 198.1374008655548 and batch: 1700, loss is 4.21298152923584 and perplexity is 67.55766498408649
At time: 199.3872354030609 and batch: 1750, loss is 4.198462872505188 and perplexity is 66.58390438953252
At time: 200.63691425323486 and batch: 1800, loss is 4.165029249191284 and perplexity is 64.39456590489321
At time: 201.88600206375122 and batch: 1850, loss is 4.204126386642456 and perplexity is 66.96207314457698
At time: 203.13561606407166 and batch: 1900, loss is 4.303332653045654 and perplexity is 73.94581927276225
At time: 204.3853931427002 and batch: 1950, loss is 4.230457077026367 and perplexity is 68.74864842126418
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4430973496547965 and perplexity of 85.03792637770078
finished 4 epochs...
Completing Train Step...
At time: 208.2768054008484 and batch: 50, loss is 4.21124388217926 and perplexity is 67.4403755397185
At time: 209.48957419395447 and batch: 100, loss is 4.16886860370636 and perplexity is 64.64227468888349
At time: 210.7083728313446 and batch: 150, loss is 4.12959924697876 and perplexity is 62.153009936603326
At time: 211.9306619167328 and batch: 200, loss is 4.131348619461059 and perplexity is 62.261833860914955
At time: 213.15029644966125 and batch: 250, loss is 4.12233136177063 and perplexity is 61.702926553422
At time: 214.37118816375732 and batch: 300, loss is 4.133668360710144 and perplexity is 62.40643285645001
At time: 215.59296917915344 and batch: 350, loss is 4.15369056224823 and perplexity is 63.66853995026343
At time: 216.8185214996338 and batch: 400, loss is 4.100549349784851 and perplexity is 60.37344462794137
At time: 218.06185913085938 and batch: 450, loss is 4.125619668960571 and perplexity is 61.90615869217108
At time: 219.3160436153412 and batch: 500, loss is 4.137989673614502 and perplexity is 62.67669410120415
At time: 220.60356259346008 and batch: 550, loss is 4.105339140892029 and perplexity is 60.66331446994069
At time: 221.85224151611328 and batch: 600, loss is 4.094879956245422 and perplexity is 60.032132242336985
At time: 223.10050749778748 and batch: 650, loss is 4.1439592647552494 and perplexity is 63.05196733850206
At time: 224.3482048511505 and batch: 700, loss is 4.18656539440155 and perplexity is 65.79641768694283
At time: 225.59644651412964 and batch: 750, loss is 4.140442533493042 and perplexity is 62.83061995158099
At time: 226.8417522907257 and batch: 800, loss is 4.13087414264679 and perplexity is 62.2322990716745
At time: 228.08807229995728 and batch: 850, loss is 4.1315565061569215 and perplexity is 62.2747786133089
At time: 229.33573698997498 and batch: 900, loss is 4.098249797821045 and perplexity is 60.23477225805328
At time: 230.581702709198 and batch: 950, loss is 4.189434289932251 and perplexity is 65.98545176543779
At time: 231.8285472393036 and batch: 1000, loss is 4.164938020706177 and perplexity is 64.38869155415469
At time: 233.07556009292603 and batch: 1050, loss is 4.108885350227356 and perplexity is 60.87882117212166
At time: 234.3221242427826 and batch: 1100, loss is 4.147716450691223 and perplexity is 63.28931089615625
At time: 235.56900358200073 and batch: 1150, loss is 4.118193092346192 and perplexity is 61.44811083077354
At time: 236.81537628173828 and batch: 1200, loss is 4.169467983245849 and perplexity is 64.6810315595954
At time: 238.06423664093018 and batch: 1250, loss is 4.179421396255493 and perplexity is 65.32804322613252
At time: 239.31096076965332 and batch: 1300, loss is 4.165957312583924 and perplexity is 64.45435588434862
At time: 240.55787920951843 and batch: 1350, loss is 4.043103070259094 and perplexity is 57.002952814679816
At time: 241.80495929718018 and batch: 1400, loss is 4.076688642501831 and perplexity is 58.949941964841265
At time: 243.05429339408875 and batch: 1450, loss is 4.015080986022949 and perplexity is 55.42778409652552
At time: 244.30139565467834 and batch: 1500, loss is 4.011978764533996 and perplexity is 55.256101270378956
At time: 245.54892206192017 and batch: 1550, loss is 4.031813530921936 and perplexity is 56.36303472342243
At time: 246.79673099517822 and batch: 1600, loss is 4.106548013687134 and perplexity is 60.736693044209304
At time: 248.04629588127136 and batch: 1650, loss is 4.072604818344116 and perplexity is 58.70969167162518
At time: 249.30032467842102 and batch: 1700, loss is 4.080222911834717 and perplexity is 59.15865554465081
At time: 250.54879450798035 and batch: 1750, loss is 4.065530543327331 and perplexity is 58.295828782529725
At time: 251.79718136787415 and batch: 1800, loss is 4.03098156452179 and perplexity is 56.31616207326092
At time: 253.04735136032104 and batch: 1850, loss is 4.076690831184387 and perplexity is 58.95007098769212
At time: 254.2963261604309 and batch: 1900, loss is 4.169638857841492 and perplexity is 64.69208484904519
At time: 255.54625606536865 and batch: 1950, loss is 4.098133859634399 and perplexity is 60.22778915259678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.436824922783431 and perplexity of 84.50620154907372
finished 5 epochs...
Completing Train Step...
At time: 259.46792554855347 and batch: 50, loss is 4.0849859285354615 and perplexity is 59.441101322009615
At time: 260.6712119579315 and batch: 100, loss is 4.045721635818482 and perplexity is 57.15241438576159
At time: 261.8743402957916 and batch: 150, loss is 4.007607235908508 and perplexity is 55.01507485272448
At time: 263.0777096748352 and batch: 200, loss is 4.011091876029968 and perplexity is 55.20711699439128
At time: 264.287780046463 and batch: 250, loss is 4.001998567581177 and perplexity is 54.70737723841151
At time: 265.50847482681274 and batch: 300, loss is 4.010900583267212 and perplexity is 55.19655728248804
At time: 266.729820728302 and batch: 350, loss is 4.0303357982635495 and perplexity is 56.279806735788924
At time: 267.9598126411438 and batch: 400, loss is 3.9777967405319212 and perplexity is 53.39925211504947
At time: 269.19101333618164 and batch: 450, loss is 4.004968681335449 and perplexity is 54.870105913718916
At time: 270.42123913764954 and batch: 500, loss is 4.02318308353424 and perplexity is 55.87868958161466
At time: 271.65008068084717 and batch: 550, loss is 3.9896177196502687 and perplexity is 54.03422919055673
At time: 272.8800628185272 and batch: 600, loss is 3.9803514003753664 and perplexity is 53.53584343799546
At time: 274.11007738113403 and batch: 650, loss is 4.027847404479981 and perplexity is 56.13993451532434
At time: 275.3514926433563 and batch: 700, loss is 4.069154572486878 and perplexity is 58.50747784546279
At time: 276.60149240493774 and batch: 750, loss is 4.024787068367004 and perplexity is 55.96839007205984
At time: 277.8510446548462 and batch: 800, loss is 4.018026237487793 and perplexity is 55.59127349934798
At time: 279.1009576320648 and batch: 850, loss is 4.014447889328003 and perplexity is 55.392704055306616
At time: 280.34953713417053 and batch: 900, loss is 3.9831119203567504 and perplexity is 53.683834375516305
At time: 281.6367988586426 and batch: 950, loss is 4.076712770462036 and perplexity is 58.95136432385432
At time: 282.885817527771 and batch: 1000, loss is 4.050465922355652 and perplexity is 57.42420603483344
At time: 284.13456320762634 and batch: 1050, loss is 4.002304749488831 and perplexity is 54.72413021213493
At time: 285.3845555782318 and batch: 1100, loss is 4.036213030815125 and perplexity is 56.611550159638476
At time: 286.6343319416046 and batch: 1150, loss is 4.010177459716797 and perplexity is 55.156657779888874
At time: 287.8828921318054 and batch: 1200, loss is 4.060196828842163 and perplexity is 57.98572321856644
At time: 289.13142800331116 and batch: 1250, loss is 4.0696447515487675 and perplexity is 58.53616401617236
At time: 290.3795268535614 and batch: 1300, loss is 4.0558267593383786 and perplexity is 57.73287446358897
At time: 291.62846875190735 and batch: 1350, loss is 3.939750380516052 and perplexity is 51.405767817615285
At time: 292.87835574150085 and batch: 1400, loss is 3.970597925186157 and perplexity is 53.016221098399704
At time: 294.12783551216125 and batch: 1450, loss is 3.9045397567749025 and perplexity is 49.62723405700032
At time: 295.3762876987457 and batch: 1500, loss is 3.9053437376022337 and perplexity is 49.667149445148965
At time: 296.62427020072937 and batch: 1550, loss is 3.928242483139038 and perplexity is 50.8175863739713
At time: 297.87289786338806 and batch: 1600, loss is 4.005407452583313 and perplexity is 54.89418662113578
At time: 299.12149572372437 and batch: 1650, loss is 3.9709649515151977 and perplexity is 53.03568301870916
At time: 300.3709363937378 and batch: 1700, loss is 3.978283338546753 and perplexity is 53.425242408021816
At time: 301.62119722366333 and batch: 1750, loss is 3.9627295923233032 and perplexity is 52.60070866246276
At time: 302.8706543445587 and batch: 1800, loss is 3.9279505014419556 and perplexity is 50.80275073483313
At time: 304.1196413040161 and batch: 1850, loss is 3.9776193141937255 and perplexity is 53.38977852174164
At time: 305.3692662715912 and batch: 1900, loss is 4.067964549064636 and perplexity is 58.43789398787239
At time: 306.61663603782654 and batch: 1950, loss is 3.9949005126953123 and perplexity is 54.32043616119649
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.449912279705669 and perplexity of 85.61943311090363
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 310.48670411109924 and batch: 50, loss is 4.0265146923065185 and perplexity is 56.06516597471703
At time: 311.6896026134491 and batch: 100, loss is 4.017927708625794 and perplexity is 55.585796424262426
At time: 312.91663360595703 and batch: 150, loss is 3.974062180519104 and perplexity is 53.200201318305
At time: 314.13878536224365 and batch: 200, loss is 3.983779983520508 and perplexity is 53.7197105501929
At time: 315.36552715301514 and batch: 250, loss is 3.9741557836532593 and perplexity is 53.20518125695138
At time: 316.5976233482361 and batch: 300, loss is 3.9788333654403685 and perplexity is 53.45463581098418
At time: 317.84345173835754 and batch: 350, loss is 4.003383746147156 and perplexity is 54.78320923306485
At time: 319.08918619155884 and batch: 400, loss is 3.9446812105178832 and perplexity is 51.65986686461231
At time: 320.3351776599884 and batch: 450, loss is 3.9615094900131225 and perplexity is 52.536569552401446
At time: 321.5825545787811 and batch: 500, loss is 3.97557870388031 and perplexity is 53.28094187341987
At time: 322.8321809768677 and batch: 550, loss is 3.929637565612793 and perplexity is 50.88853057307826
At time: 324.07803535461426 and batch: 600, loss is 3.9093755435943605 and perplexity is 49.86780198013202
At time: 325.32506823539734 and batch: 650, loss is 3.9493971395492555 and perplexity is 51.90406649198919
At time: 326.57284235954285 and batch: 700, loss is 3.9873359870910643 and perplexity is 53.91107808287733
At time: 327.8193974494934 and batch: 750, loss is 3.9360997819900514 and perplexity is 51.21844811993055
At time: 329.0671741962433 and batch: 800, loss is 3.92430540561676 and perplexity is 50.61790693157293
At time: 330.3139600753784 and batch: 850, loss is 3.9172009229660034 and perplexity is 50.259567306011576
At time: 331.56083703041077 and batch: 900, loss is 3.8795574712753296 and perplexity is 48.40279070600465
At time: 332.80836939811707 and batch: 950, loss is 3.9682917690277097 and perplexity is 52.89409828487964
At time: 334.0593478679657 and batch: 1000, loss is 3.9312206888198853 and perplexity is 50.96915719089881
At time: 335.30731201171875 and batch: 1050, loss is 3.8827262210845945 and perplexity is 48.55641030231459
At time: 336.55412888526917 and batch: 1100, loss is 3.9064470195770262 and perplexity is 49.7219765551908
At time: 337.80049324035645 and batch: 1150, loss is 3.8774993801116944 and perplexity is 48.3032757906679
At time: 339.0463376045227 and batch: 1200, loss is 3.9107059383392335 and perplexity is 49.93418999316463
At time: 340.29330468177795 and batch: 1250, loss is 3.91137122631073 and perplexity is 49.96742166222264
At time: 341.5408384799957 and batch: 1300, loss is 3.8942108869552614 and perplexity is 49.11727898044501
At time: 342.7880434989929 and batch: 1350, loss is 3.778461260795593 and perplexity is 43.748672119800695
At time: 344.0353844165802 and batch: 1400, loss is 3.800105609893799 and perplexity is 44.705905629942826
At time: 345.2833971977234 and batch: 1450, loss is 3.7275058221817017 and perplexity is 41.57528259050558
At time: 346.5299348831177 and batch: 1500, loss is 3.7244823789596557 and perplexity is 41.44977191696021
At time: 347.7767469882965 and batch: 1550, loss is 3.7369114685058595 and perplexity is 41.96816977690755
At time: 349.0244438648224 and batch: 1600, loss is 3.811001863479614 and perplexity is 45.195696109111296
At time: 350.271365404129 and batch: 1650, loss is 3.769361963272095 and perplexity is 43.35239558916391
At time: 351.51891565322876 and batch: 1700, loss is 3.758259320259094 and perplexity is 42.873731552155704
At time: 352.7654802799225 and batch: 1750, loss is 3.736485719680786 and perplexity is 41.95030568101331
At time: 354.0117611885071 and batch: 1800, loss is 3.6997536325454714 and perplexity is 40.43734068806231
At time: 355.25829696655273 and batch: 1850, loss is 3.7355824661254884 and perplexity is 41.912431026044544
At time: 356.5057485103607 and batch: 1900, loss is 3.822596983909607 and perplexity is 45.722795634091256
At time: 357.7529399394989 and batch: 1950, loss is 3.735336046218872 and perplexity is 41.902104241119986
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365526492096657 and perplexity of 78.69081913173439
finished 7 epochs...
Completing Train Step...
At time: 361.66023778915405 and batch: 50, loss is 3.9370907497406007 and perplexity is 51.26922910725532
At time: 362.903311252594 and batch: 100, loss is 3.9128560066223144 and perplexity is 50.04166741180092
At time: 364.1242609024048 and batch: 150, loss is 3.864127812385559 and perplexity is 47.661684368238355
At time: 365.34537386894226 and batch: 200, loss is 3.869709234237671 and perplexity is 47.928448102824184
At time: 366.5777151584625 and batch: 250, loss is 3.858397812843323 and perplexity is 47.38936388184607
At time: 367.8220627307892 and batch: 300, loss is 3.863441586494446 and perplexity is 47.628988905930214
At time: 369.0792953968048 and batch: 350, loss is 3.894129266738892 and perplexity is 49.113270181108895
At time: 370.32771611213684 and batch: 400, loss is 3.8377482509613037 and perplexity is 46.42082860973426
At time: 371.576477766037 and batch: 450, loss is 3.8610374975204467 and perplexity is 47.514622107921056
At time: 372.8251509666443 and batch: 500, loss is 3.87647132396698 and perplexity is 48.25364282828886
At time: 374.0758697986603 and batch: 550, loss is 3.831585626602173 and perplexity is 46.13563415630665
At time: 375.35913920402527 and batch: 600, loss is 3.816817212104797 and perplexity is 45.45929054224701
At time: 376.6065740585327 and batch: 650, loss is 3.858966736793518 and perplexity is 47.416332496761
At time: 377.85564374923706 and batch: 700, loss is 3.900748610496521 and perplexity is 49.43944614394225
At time: 379.1043813228607 and batch: 750, loss is 3.851381149291992 and perplexity is 47.05801250959016
At time: 380.3552474975586 and batch: 800, loss is 3.8427033615112305 and perplexity is 46.651419777868796
At time: 381.60395860671997 and batch: 850, loss is 3.835236530303955 and perplexity is 46.30437876154955
At time: 382.8523864746094 and batch: 900, loss is 3.8003129673004152 and perplexity is 44.71517669177314
At time: 384.1009910106659 and batch: 950, loss is 3.888683123588562 and perplexity is 48.84651932213293
At time: 385.3503770828247 and batch: 1000, loss is 3.856562809944153 and perplexity is 47.3024839985307
At time: 386.5984454154968 and batch: 1050, loss is 3.8120903158187867 and perplexity is 45.244916252292406
At time: 387.8487768173218 and batch: 1100, loss is 3.837052927017212 and perplexity is 46.38856231516092
At time: 389.0977556705475 and batch: 1150, loss is 3.8118579292297365 and perplexity is 45.23440316213057
At time: 390.3476049900055 and batch: 1200, loss is 3.8473457002639773 and perplexity is 46.86849495016218
At time: 391.5973381996155 and batch: 1250, loss is 3.8525274753570558 and perplexity is 47.111987266324725
At time: 392.8464448451996 and batch: 1300, loss is 3.838069882392883 and perplexity is 46.43576140859512
At time: 394.0949568748474 and batch: 1350, loss is 3.724340877532959 and perplexity is 41.443907130045346
At time: 395.3434269428253 and batch: 1400, loss is 3.7495521688461304 and perplexity is 42.502043998070285
At time: 396.5924298763275 and batch: 1450, loss is 3.6777543735504152 and perplexity is 39.5574629718007
At time: 397.84075903892517 and batch: 1500, loss is 3.6764861488342286 and perplexity is 39.50732701809792
At time: 399.08949160575867 and batch: 1550, loss is 3.6932911348342894 and perplexity is 40.176857060409716
At time: 400.3402588367462 and batch: 1600, loss is 3.7715422105789185 and perplexity is 43.44701764515091
At time: 401.59188318252563 and batch: 1650, loss is 3.732551960945129 and perplexity is 41.78560745350734
At time: 402.84472846984863 and batch: 1700, loss is 3.7269311332702637 and perplexity is 41.55139660077503
At time: 404.0922701358795 and batch: 1750, loss is 3.7091431617736816 and perplexity is 40.818816416440185
At time: 405.3413531780243 and batch: 1800, loss is 3.6741093254089354 and perplexity is 39.41353658357561
At time: 406.5895733833313 and batch: 1850, loss is 3.715651421546936 and perplexity is 41.085342246204576
At time: 407.8383560180664 and batch: 1900, loss is 3.8045005083084105 and perplexity is 44.90281592715055
At time: 409.08784079551697 and batch: 1950, loss is 3.719547681808472 and perplexity is 41.24573369303394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368449934138808 and perplexity of 78.92120377470889
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 412.9792342185974 and batch: 50, loss is 3.909720845222473 and perplexity is 49.88502438663753
At time: 414.23303866386414 and batch: 100, loss is 3.9180628299713134 and perplexity is 50.30290505302744
At time: 415.47519421577454 and batch: 150, loss is 3.875908303260803 and perplexity is 48.22648267480993
At time: 416.7175889015198 and batch: 200, loss is 3.8838058805465696 and perplexity is 48.60886300056783
At time: 417.9668347835541 and batch: 250, loss is 3.8826703643798828 and perplexity is 48.55369817698837
At time: 419.21562576293945 and batch: 300, loss is 3.8848797035217286 and perplexity is 48.661088349825754
At time: 420.46461153030396 and batch: 350, loss is 3.9206199502944945 and perplexity is 50.43170023606244
At time: 421.7129456996918 and batch: 400, loss is 3.8759248781204225 and perplexity is 48.22728202861477
At time: 422.9622325897217 and batch: 450, loss is 3.8946641731262206 and perplexity is 49.13954821054771
At time: 424.212260723114 and batch: 500, loss is 3.909012188911438 and perplexity is 49.849685572295634
At time: 425.46098470687866 and batch: 550, loss is 3.8597744131088256 and perplexity is 47.454645015451625
At time: 426.71022748947144 and batch: 600, loss is 3.8269075965881347 and perplexity is 45.92031430404339
At time: 427.9584798812866 and batch: 650, loss is 3.8668560218811034 and perplexity is 47.791892965507905
At time: 429.21415400505066 and batch: 700, loss is 3.9109475564956666 and perplexity is 49.94625645777352
At time: 430.46439838409424 and batch: 750, loss is 3.8540997648239137 and perplexity is 47.1861192108323
At time: 431.7141571044922 and batch: 800, loss is 3.848335247039795 and perplexity is 46.914896472679665
At time: 432.96307587623596 and batch: 850, loss is 3.839499816894531 and perplexity is 46.5022090024749
At time: 434.2114555835724 and batch: 900, loss is 3.7960610580444336 and perplexity is 44.52545544270856
At time: 435.4600160121918 and batch: 950, loss is 3.884321913719177 and perplexity is 48.63395325950504
At time: 436.7073543071747 and batch: 1000, loss is 3.845447916984558 and perplexity is 46.77963305109761
At time: 437.9958908557892 and batch: 1050, loss is 3.8028853702545167 and perplexity is 44.830350217235726
At time: 439.2463140487671 and batch: 1100, loss is 3.821543126106262 and perplexity is 45.674635690445
At time: 440.49953866004944 and batch: 1150, loss is 3.805598201751709 and perplexity is 44.95213251607565
At time: 441.74845600128174 and batch: 1200, loss is 3.8307959175109865 and perplexity is 46.09921480882338
At time: 442.9982204437256 and batch: 1250, loss is 3.831028017997742 and perplexity is 46.109915700812635
At time: 444.24852180480957 and batch: 1300, loss is 3.8135977745056153 and perplexity is 45.31317252816412
At time: 445.497385263443 and batch: 1350, loss is 3.6930300188064575 and perplexity is 40.166367608624924
At time: 446.7463400363922 and batch: 1400, loss is 3.7119628620147704 and perplexity is 40.93407566482976
At time: 447.9966757297516 and batch: 1450, loss is 3.6380621337890626 and perplexity is 38.0180913195396
At time: 449.24566864967346 and batch: 1500, loss is 3.643423137664795 and perplexity is 38.22245375891238
At time: 450.49440336227417 and batch: 1550, loss is 3.6574603128433227 and perplexity is 38.76277243996189
At time: 451.74326610565186 and batch: 1600, loss is 3.73093770980835 and perplexity is 41.71820940250025
At time: 452.9926931858063 and batch: 1650, loss is 3.6842605018615724 and perplexity is 39.8156679481012
At time: 454.2424170970917 and batch: 1700, loss is 3.669193887710571 and perplexity is 39.22027716645915
At time: 455.4916744232178 and batch: 1750, loss is 3.6523197412490847 and perplexity is 38.56402091892988
At time: 456.74012184143066 and batch: 1800, loss is 3.617202525138855 and perplexity is 37.2332628779477
At time: 457.98932456970215 and batch: 1850, loss is 3.654573163986206 and perplexity is 38.65101994648236
At time: 459.23710680007935 and batch: 1900, loss is 3.7532289361953737 and perplexity is 42.65860176258657
At time: 460.4870870113373 and batch: 1950, loss is 3.6655769681930543 and perplexity is 39.0786768134029
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336354242369186 and perplexity of 76.42839140346112
finished 9 epochs...
Completing Train Step...
At time: 464.3957176208496 and batch: 50, loss is 3.896164288520813 and perplexity is 49.21331852145715
At time: 465.6434545516968 and batch: 100, loss is 3.8863534212112425 and perplexity is 48.7328539246278
At time: 466.87033438682556 and batch: 150, loss is 3.8343450689315794 and perplexity is 46.263118590168745
At time: 468.1283676624298 and batch: 200, loss is 3.8373101329803467 and perplexity is 46.400495264556724
At time: 469.36933159828186 and batch: 250, loss is 3.831716856956482 and perplexity is 46.141688949200876
At time: 470.6181297302246 and batch: 300, loss is 3.831304974555969 and perplexity is 46.122687912957595
At time: 471.86673974990845 and batch: 350, loss is 3.869021148681641 and perplexity is 47.8954805735028
At time: 473.11642360687256 and batch: 400, loss is 3.822428421974182 and perplexity is 45.715089160693424
At time: 474.36473631858826 and batch: 450, loss is 3.8466394329071045 and perplexity is 46.83540494868255
At time: 475.61268067359924 and batch: 500, loss is 3.860396771430969 and perplexity is 47.48418800090921
At time: 476.86653685569763 and batch: 550, loss is 3.81310830116272 and perplexity is 45.290998365403055
At time: 478.1150231361389 and batch: 600, loss is 3.782181673049927 and perplexity is 43.91173836440374
At time: 479.36414313316345 and batch: 650, loss is 3.8244304132461546 and perplexity is 45.80670204368818
At time: 480.61403346061707 and batch: 700, loss is 3.872097430229187 and perplexity is 48.04304741880856
At time: 481.8640766143799 and batch: 750, loss is 3.8167642545700073 and perplexity is 45.45688319403077
At time: 483.1132261753082 and batch: 800, loss is 3.8130298805236817 and perplexity is 45.28744675563014
At time: 484.3620526790619 and batch: 850, loss is 3.8040663242340087 and perplexity is 44.88332407141207
At time: 485.60918521881104 and batch: 900, loss is 3.7615536785125734 and perplexity is 43.01520588917759
At time: 486.863646030426 and batch: 950, loss is 3.851512761116028 and perplexity is 47.06420630803167
At time: 488.1122934818268 and batch: 1000, loss is 3.815357246398926 and perplexity is 45.39296996170887
At time: 489.3625054359436 and batch: 1050, loss is 3.7747521781921387 and perplexity is 43.58670524106848
At time: 490.609986782074 and batch: 1100, loss is 3.7929480600357057 and perplexity is 44.38706330755864
At time: 491.85851860046387 and batch: 1150, loss is 3.778509292602539 and perplexity is 43.75077349804019
At time: 493.10583305358887 and batch: 1200, loss is 3.806001830101013 and perplexity is 44.970280133320834
At time: 494.3549573421478 and batch: 1250, loss is 3.8088706588745116 and perplexity is 45.09947740072899
At time: 495.6037902832031 and batch: 1300, loss is 3.7935126972198487 and perplexity is 44.41213297096302
At time: 496.8504936695099 and batch: 1350, loss is 3.6756701040267945 and perplexity is 39.475100419991605
At time: 498.09944128990173 and batch: 1400, loss is 3.6972680377960203 and perplexity is 40.33695465754507
At time: 499.34734416007996 and batch: 1450, loss is 3.625157527923584 and perplexity is 37.530634816936725
At time: 500.59391379356384 and batch: 1500, loss is 3.6323079013824464 and perplexity is 37.79995459303826
At time: 501.84225630760193 and batch: 1550, loss is 3.6483121299743653 and perplexity is 38.40978058797844
At time: 503.09044098854065 and batch: 1600, loss is 3.725016565322876 and perplexity is 41.47191973488133
At time: 504.33693265914917 and batch: 1650, loss is 3.6798393535614013 and perplexity is 39.64002553211692
At time: 505.5833537578583 and batch: 1700, loss is 3.6670685720443728 and perplexity is 39.13701021258823
At time: 506.8292832374573 and batch: 1750, loss is 3.652361431121826 and perplexity is 38.56562868156787
At time: 508.07647824287415 and batch: 1800, loss is 3.6196807050704956 and perplexity is 37.32564802903405
At time: 509.33108258247375 and batch: 1850, loss is 3.6571974849700926 and perplexity is 38.75258584164062
At time: 510.578262090683 and batch: 1900, loss is 3.7562195444107056 and perplexity is 42.78636788144915
At time: 511.82489228248596 and batch: 1950, loss is 3.668031768798828 and perplexity is 39.17472501427556
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335826785065407 and perplexity of 76.38808931994782
finished 10 epochs...
Completing Train Step...
At time: 515.7696666717529 and batch: 50, loss is 3.876834273338318 and perplexity is 48.27115963628308
At time: 516.9919335842133 and batch: 100, loss is 3.865201640129089 and perplexity is 47.71289229654271
At time: 518.2383413314819 and batch: 150, loss is 3.8119127130508423 and perplexity is 45.236881343462734
At time: 519.4872949123383 and batch: 200, loss is 3.814997048377991 and perplexity is 45.37662244811207
At time: 520.7372374534607 and batch: 250, loss is 3.8084031915664673 and perplexity is 45.07839979636359
At time: 521.9864044189453 and batch: 300, loss is 3.8071030473709104 and perplexity is 45.01982945971545
At time: 523.236813545227 and batch: 350, loss is 3.8453951978683474 and perplexity is 46.777166935192795
At time: 524.4870669841766 and batch: 400, loss is 3.7984748697280883 and perplexity is 44.633061325197396
At time: 525.7375054359436 and batch: 450, loss is 3.824219470024109 and perplexity is 45.797040449427534
At time: 526.9877111911774 and batch: 500, loss is 3.8375110101699828 and perplexity is 46.40981700187404
At time: 528.2374742031097 and batch: 550, loss is 3.790912141799927 and perplexity is 44.29678680490984
At time: 529.488997220993 and batch: 600, loss is 3.7607457494735717 and perplexity is 42.98046669051445
At time: 530.781200170517 and batch: 650, loss is 3.8031153202056887 and perplexity is 44.840660139416826
At time: 532.0346777439117 and batch: 700, loss is 3.852013874053955 and perplexity is 47.08779670095778
At time: 533.2859416007996 and batch: 750, loss is 3.7973076343536376 and perplexity is 44.58099443022092
At time: 534.5401513576508 and batch: 800, loss is 3.7942208194732667 and perplexity is 44.443593328216444
At time: 535.7894892692566 and batch: 850, loss is 3.7849848318099975 and perplexity is 44.035002622397705
At time: 537.0395588874817 and batch: 900, loss is 3.7436103343963625 and perplexity is 42.25025268081743
At time: 538.2893550395966 and batch: 950, loss is 3.83355673789978 and perplexity is 46.22666230985287
At time: 539.5390741825104 and batch: 1000, loss is 3.7985609722137452 and perplexity is 44.6369045081714
At time: 540.7965979576111 and batch: 1050, loss is 3.758652381896973 and perplexity is 42.89058688367666
At time: 542.0480451583862 and batch: 1100, loss is 3.7767037391662597 and perplexity is 43.67185040997827
At time: 543.2995917797089 and batch: 1150, loss is 3.7625451374053953 and perplexity is 43.05787484634623
At time: 544.5496578216553 and batch: 1200, loss is 3.790856332778931 and perplexity is 44.29431471358813
At time: 545.7994341850281 and batch: 1250, loss is 3.7949198484420776 and perplexity is 44.47467154845353
At time: 547.0493586063385 and batch: 1300, loss is 3.7803486585617065 and perplexity is 43.83132123717491
At time: 548.2998900413513 and batch: 1350, loss is 3.6636571884155273 and perplexity is 39.00372632715743
At time: 549.5533487796783 and batch: 1400, loss is 3.6863134908676147 and perplexity is 39.89749304093544
At time: 550.8024730682373 and batch: 1450, loss is 3.614722018241882 and perplexity is 37.14101996447059
At time: 552.0524144172668 and batch: 1500, loss is 3.6224281120300295 and perplexity is 37.428337774865376
At time: 553.3026626110077 and batch: 1550, loss is 3.6391814947128296 and perplexity is 38.06067111199087
At time: 554.5508522987366 and batch: 1600, loss is 3.717552213668823 and perplexity is 41.163511209010096
At time: 555.8000452518463 and batch: 1650, loss is 3.6725396299362183 and perplexity is 39.351717864611395
At time: 557.0484249591827 and batch: 1700, loss is 3.660593547821045 and perplexity is 38.88441578347761
At time: 558.2987172603607 and batch: 1750, loss is 3.6468413877487182 and perplexity is 38.35333122319744
At time: 559.5477287769318 and batch: 1800, loss is 3.6154572916030885 and perplexity is 37.16833880923713
At time: 560.7983937263489 and batch: 1850, loss is 3.6529068613052367 and perplexity is 38.58666927705931
At time: 562.0532810688019 and batch: 1900, loss is 3.751970443725586 and perplexity is 42.604950000746975
At time: 563.3046300411224 and batch: 1950, loss is 3.663574342727661 and perplexity is 39.00049517046605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3373750908430235 and perplexity of 76.50645304795931
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 567.229966878891 and batch: 50, loss is 3.8712111568450926 and perplexity is 48.00048700745625
At time: 568.4505271911621 and batch: 100, loss is 3.8768032932281495 and perplexity is 48.269664213603896
At time: 569.6721079349518 and batch: 150, loss is 3.8343063306808474 and perplexity is 46.261326472593126
At time: 570.8959925174713 and batch: 200, loss is 3.8405284452438355 and perplexity is 46.55006710283972
At time: 572.138819694519 and batch: 250, loss is 3.838858027458191 and perplexity is 46.472373950905165
At time: 573.3869042396545 and batch: 300, loss is 3.8401576709747314 and perplexity is 46.532810735039185
At time: 574.6362950801849 and batch: 350, loss is 3.883107385635376 and perplexity is 48.574921812376616
At time: 575.8836805820465 and batch: 400, loss is 3.8325291013717653 and perplexity is 46.179182503265224
At time: 577.1324391365051 and batch: 450, loss is 3.863108835220337 and perplexity is 47.613142935716844
At time: 578.3809404373169 and batch: 500, loss is 3.8795515394210813 and perplexity is 48.40250358855655
At time: 579.6298067569733 and batch: 550, loss is 3.842512679100037 and perplexity is 46.64252502072377
At time: 580.8788123130798 and batch: 600, loss is 3.7996203756332396 and perplexity is 44.68421805508456
At time: 582.1274363994598 and batch: 650, loss is 3.830102186203003 and perplexity is 46.06724543059847
At time: 583.375735282898 and batch: 700, loss is 3.8812053632736205 and perplexity is 48.482619033670424
At time: 584.6227967739105 and batch: 750, loss is 3.822277479171753 and perplexity is 45.708189317776124
At time: 585.8706777095795 and batch: 800, loss is 3.8182452297210694 and perplexity is 45.52425358310838
At time: 587.1191806793213 and batch: 850, loss is 3.804758381843567 and perplexity is 44.914396668151305
At time: 588.3697538375854 and batch: 900, loss is 3.760967812538147 and perplexity is 42.99001212446955
At time: 589.6213383674622 and batch: 950, loss is 3.8550457525253297 and perplexity is 47.23077781920005
At time: 590.870016336441 and batch: 1000, loss is 3.8116945934295656 and perplexity is 45.22701536805688
At time: 592.1576595306396 and batch: 1050, loss is 3.771056900024414 and perplexity is 43.42593746455678
At time: 593.4072470664978 and batch: 1100, loss is 3.790947313308716 and perplexity is 44.29834481713494
At time: 594.6604845523834 and batch: 1150, loss is 3.775291333198547 and perplexity is 43.61021156761945
At time: 595.9105985164642 and batch: 1200, loss is 3.800119242668152 and perplexity is 44.706515099620894
At time: 597.1585602760315 and batch: 1250, loss is 3.8009939432144164 and perplexity is 44.745637020288456
At time: 598.407387971878 and batch: 1300, loss is 3.783313355445862 and perplexity is 43.961460635288326
At time: 599.6551642417908 and batch: 1350, loss is 3.660371174812317 and perplexity is 38.87576990028837
At time: 600.9024407863617 and batch: 1400, loss is 3.6813276863098143 and perplexity is 39.69906700604515
At time: 602.1576883792877 and batch: 1450, loss is 3.603950138092041 and perplexity is 36.74308843193032
At time: 603.4069683551788 and batch: 1500, loss is 3.611221957206726 and perplexity is 37.01125135918317
At time: 604.6562347412109 and batch: 1550, loss is 3.631649522781372 and perplexity is 37.77507610244419
At time: 605.9042317867279 and batch: 1600, loss is 3.7113433265686036 and perplexity is 40.90872340812106
At time: 607.1515147686005 and batch: 1650, loss is 3.66214732170105 and perplexity is 38.944880335017125
At time: 608.4003348350525 and batch: 1700, loss is 3.6449503612518313 and perplexity is 38.28087258980089
At time: 609.6544833183289 and batch: 1750, loss is 3.625823221206665 and perplexity is 37.55562702609407
At time: 610.9031310081482 and batch: 1800, loss is 3.5984193420410158 and perplexity is 36.540430849010896
At time: 612.1530578136444 and batch: 1850, loss is 3.6365940141677857 and perplexity is 37.962317165292845
At time: 613.4016311168671 and batch: 1900, loss is 3.746909289360046 and perplexity is 42.38986452158576
At time: 614.6518700122833 and batch: 1950, loss is 3.6686519718170167 and perplexity is 39.19902883283789
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3200868118640985 and perplexity of 75.19515584033435
finished 12 epochs...
Completing Train Step...
At time: 618.5332872867584 and batch: 50, loss is 3.881109480857849 and perplexity is 48.47797062588839
At time: 619.7514231204987 and batch: 100, loss is 3.8671100521087647 and perplexity is 47.80403509312672
At time: 620.9820308685303 and batch: 150, loss is 3.817801947593689 and perplexity is 45.504077967208005
At time: 622.2305519580841 and batch: 200, loss is 3.8202961778640745 and perplexity is 45.61771727829034
At time: 623.5083734989166 and batch: 250, loss is 3.8157925987243653 and perplexity is 45.412736199066806
At time: 624.7585718631744 and batch: 300, loss is 3.81427206993103 and perplexity is 45.343737296794636
At time: 626.0086033344269 and batch: 350, loss is 3.855168604850769 and perplexity is 47.236580586521875
At time: 627.2575960159302 and batch: 400, loss is 3.8087847805023194 and perplexity is 45.0956044973248
At time: 628.5073823928833 and batch: 450, loss is 3.8416275119781496 and perplexity is 46.60125685839839
At time: 629.7573585510254 and batch: 500, loss is 3.858623628616333 and perplexity is 47.400066356031765
At time: 631.0062487125397 and batch: 550, loss is 3.820714569091797 and perplexity is 45.63680732430372
At time: 632.2558705806732 and batch: 600, loss is 3.7794088745117187 and perplexity is 43.790148610305614
At time: 633.5056324005127 and batch: 650, loss is 3.809525694847107 and perplexity is 45.12902885834896
At time: 634.7550795078278 and batch: 700, loss is 3.860905179977417 and perplexity is 47.50833550578879
At time: 636.010217666626 and batch: 750, loss is 3.804968614578247 and perplexity is 44.92384013721774
At time: 637.2589702606201 and batch: 800, loss is 3.8013657426834104 and perplexity is 44.76227651745882
At time: 638.5077550411224 and batch: 850, loss is 3.7898662185668943 and perplexity is 44.250479987351525
At time: 639.7593162059784 and batch: 900, loss is 3.7468552207946777 and perplexity is 42.387572624385264
At time: 641.00883436203 and batch: 950, loss is 3.8407199573516846 and perplexity is 46.55898285802138
At time: 642.2596962451935 and batch: 1000, loss is 3.799512267112732 and perplexity is 44.6793875714935
At time: 643.5098094940186 and batch: 1050, loss is 3.759484877586365 and perplexity is 42.926307979138784
At time: 644.7590203285217 and batch: 1100, loss is 3.779127388000488 and perplexity is 43.777824008832944
At time: 646.0084066390991 and batch: 1150, loss is 3.7648733139038084 and perplexity is 43.15823796482792
At time: 647.2570521831512 and batch: 1200, loss is 3.7906566572189333 and perplexity is 44.285471104448675
At time: 648.5067751407623 and batch: 1250, loss is 3.7930272960662843 and perplexity is 44.39058050160658
At time: 649.7554116249084 and batch: 1300, loss is 3.7763617420196534 and perplexity is 43.65691731543445
At time: 651.004816532135 and batch: 1350, loss is 3.6553563690185547 and perplexity is 38.68130347736872
At time: 652.2544114589691 and batch: 1400, loss is 3.677927656173706 and perplexity is 39.56431818668283
At time: 653.5042262077332 and batch: 1450, loss is 3.6012825965881348 and perplexity is 36.64520533021748
At time: 654.7547061443329 and batch: 1500, loss is 3.6102964639663697 and perplexity is 36.97701354211109
At time: 656.0044121742249 and batch: 1550, loss is 3.6324930334091188 and perplexity is 37.80695322305548
At time: 657.2548105716705 and batch: 1600, loss is 3.7135741567611693 and perplexity is 41.000085692420875
At time: 658.5046532154083 and batch: 1650, loss is 3.6645686340332033 and perplexity is 39.03929230835805
At time: 659.7549316883087 and batch: 1700, loss is 3.6483727264404298 and perplexity is 38.41210815546485
At time: 661.0052733421326 and batch: 1750, loss is 3.6306337833404543 and perplexity is 37.73672594794276
At time: 662.2565286159515 and batch: 1800, loss is 3.603762354850769 and perplexity is 36.736189343477086
At time: 663.506854057312 and batch: 1850, loss is 3.6421600484848025 and perplexity is 38.1742058682456
At time: 664.7574317455292 and batch: 1900, loss is 3.752484130859375 and perplexity is 42.626841237540035
At time: 666.0070898532867 and batch: 1950, loss is 3.6729524898529053 and perplexity is 39.36796796584737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318846804596657 and perplexity of 75.10197108744151
finished 13 epochs...
Completing Train Step...
At time: 669.9130029678345 and batch: 50, loss is 3.8759643840789795 and perplexity is 48.22918733125507
At time: 671.1516952514648 and batch: 100, loss is 3.8598201084136963 and perplexity is 47.45681351946798
At time: 672.3700242042542 and batch: 150, loss is 3.8096548748016357 and perplexity is 45.13485900080548
At time: 673.6032950878143 and batch: 200, loss is 3.8120680618286134 and perplexity is 45.2439093835742
At time: 674.8411095142365 and batch: 250, loss is 3.8066738176345827 and perplexity is 45.00050975677905
At time: 676.0769376754761 and batch: 300, loss is 3.8046649646759034 and perplexity is 44.91020108839989
At time: 677.3229293823242 and batch: 350, loss is 3.8454590892791747 and perplexity is 46.78015568985965
At time: 678.5689747333527 and batch: 400, loss is 3.798842968940735 and perplexity is 44.649493744123895
At time: 679.8157510757446 and batch: 450, loss is 3.8322713470458982 and perplexity is 46.16728115308814
At time: 681.0611827373505 and batch: 500, loss is 3.8492993927001953 and perplexity is 46.960151079032464
At time: 682.3071353435516 and batch: 550, loss is 3.8113954877853393 and perplexity is 45.21348973538616
At time: 683.5531105995178 and batch: 600, loss is 3.7703244066238404 and perplexity is 43.394139899125435
At time: 684.7998247146606 and batch: 650, loss is 3.8004492044448854 and perplexity is 44.7212689747483
At time: 686.0671036243439 and batch: 700, loss is 3.8522931051254274 and perplexity is 47.100946912772294
At time: 687.3135991096497 and batch: 750, loss is 3.7971266412734987 and perplexity is 44.57292630888243
At time: 688.558807849884 and batch: 800, loss is 3.793786849975586 and perplexity is 44.42431034875974
At time: 689.8038671016693 and batch: 850, loss is 3.782632031440735 and perplexity is 43.93151883804793
At time: 691.0506610870361 and batch: 900, loss is 3.740041561126709 and perplexity is 42.09973984125934
At time: 692.2971606254578 and batch: 950, loss is 3.833920202255249 and perplexity is 46.2434671076623
At time: 693.5447800159454 and batch: 1000, loss is 3.7934165573120118 and perplexity is 44.40786339783382
At time: 694.7906882762909 and batch: 1050, loss is 3.75372296333313 and perplexity is 42.67968147606255
At time: 696.0363743305206 and batch: 1100, loss is 3.7733772134780885 and perplexity is 43.52681624142609
At time: 697.2830319404602 and batch: 1150, loss is 3.7594586849212646 and perplexity is 42.92518363945468
At time: 698.5300951004028 and batch: 1200, loss is 3.785606551170349 and perplexity is 44.06238854835922
At time: 699.7773611545563 and batch: 1250, loss is 3.7887955379486082 and perplexity is 44.20312721045304
At time: 701.0234446525574 and batch: 1300, loss is 3.772558822631836 and perplexity is 43.4912088658101
At time: 702.2695889472961 and batch: 1350, loss is 3.6522789573669434 and perplexity is 38.56244816051765
At time: 703.5160162448883 and batch: 1400, loss is 3.6755048656463623 and perplexity is 39.46857815720971
At time: 704.762332201004 and batch: 1450, loss is 3.599154076576233 and perplexity is 36.56728823080213
At time: 706.0082955360413 and batch: 1500, loss is 3.6087846612930297 and perplexity is 36.92115382925677
At time: 707.2541062831879 and batch: 1550, loss is 3.6316070222854613 and perplexity is 37.7734706770927
At time: 708.499986410141 and batch: 1600, loss is 3.7132397413253786 and perplexity is 40.98637692323636
At time: 709.7453379631042 and batch: 1650, loss is 3.664354796409607 and perplexity is 39.030945131366
At time: 710.9914951324463 and batch: 1700, loss is 3.648634920120239 and perplexity is 38.422180887897056
At time: 712.2399225234985 and batch: 1750, loss is 3.631481204032898 and perplexity is 37.76871838398774
At time: 713.4930987358093 and batch: 1800, loss is 3.6048131513595583 and perplexity is 36.774811891651
At time: 714.7405438423157 and batch: 1850, loss is 3.6432816410064697 and perplexity is 38.21704579204614
At time: 715.9867997169495 and batch: 1900, loss is 3.753485984802246 and perplexity is 42.669568506173455
At time: 717.2341809272766 and batch: 1950, loss is 3.6732434701919554 and perplexity is 39.379424937309665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3187687363735465 and perplexity of 75.09610823886072
finished 14 epochs...
Completing Train Step...
At time: 721.1529965400696 and batch: 50, loss is 3.8705161952972413 and perplexity is 47.96714010345808
At time: 722.3917276859283 and batch: 100, loss is 3.8536209583282472 and perplexity is 47.163531598428165
At time: 723.6260857582092 and batch: 150, loss is 3.8031494760513307 and perplexity is 44.84219173623938
At time: 724.8685855865479 and batch: 200, loss is 3.805613303184509 and perplexity is 44.95281136280984
At time: 726.1174550056458 and batch: 250, loss is 3.799915242195129 and perplexity is 44.6973958795876
At time: 727.3684051036835 and batch: 300, loss is 3.797597398757935 and perplexity is 44.59391428728191
At time: 728.624382019043 and batch: 350, loss is 3.838418107032776 and perplexity is 46.45193430062609
At time: 729.8730719089508 and batch: 400, loss is 3.791691360473633 and perplexity is 44.33131713996716
At time: 731.1213719844818 and batch: 450, loss is 3.8254829168319704 and perplexity is 45.854939142250224
At time: 732.370353937149 and batch: 500, loss is 3.842517628669739 and perplexity is 46.642755881723765
At time: 733.6194288730621 and batch: 550, loss is 3.8046293020248414 and perplexity is 44.908599500127956
At time: 734.8751926422119 and batch: 600, loss is 3.76385066986084 and perplexity is 43.11412500963804
At time: 736.1226074695587 and batch: 650, loss is 3.7939496278762816 and perplexity is 44.4315422333177
At time: 737.3721539974213 and batch: 700, loss is 3.8461018323898317 and perplexity is 46.81023297759405
At time: 738.6219599246979 and batch: 750, loss is 3.791350255012512 and perplexity is 44.316198064338266
At time: 739.8700566291809 and batch: 800, loss is 3.7881976413726806 and perplexity is 44.17670621134814
At time: 741.1181998252869 and batch: 850, loss is 3.7771860218048094 and perplexity is 43.692917665001666
At time: 742.3673784732819 and batch: 900, loss is 3.734890174865723 and perplexity is 41.883425457678875
At time: 743.6218087673187 and batch: 950, loss is 3.8287821674346922 and perplexity is 46.00647591929742
At time: 744.8747065067291 and batch: 1000, loss is 3.788683142662048 and perplexity is 44.19815926649534
At time: 746.1240916252136 and batch: 1050, loss is 3.749209752082825 and perplexity is 42.487493077112404
At time: 747.3745439052582 and batch: 1100, loss is 3.768852405548096 and perplexity is 43.33031066838643
At time: 748.6632194519043 and batch: 1150, loss is 3.7550603485107423 and perplexity is 42.73679883489506
At time: 749.9124660491943 and batch: 1200, loss is 3.781460237503052 and perplexity is 43.88007030002978
At time: 751.1611571311951 and batch: 1250, loss is 3.7851595878601074 and perplexity is 44.04269867796913
At time: 752.4158895015717 and batch: 1300, loss is 3.7691839027404783 and perplexity is 43.3446769257735
At time: 753.665417432785 and batch: 1350, loss is 3.649326901435852 and perplexity is 38.44877752030163
At time: 754.914427280426 and batch: 1400, loss is 3.6729700469970705 and perplexity is 39.368659161004125
At time: 756.1641056537628 and batch: 1450, loss is 3.596802206039429 and perplexity is 36.48138775599425
At time: 757.4124448299408 and batch: 1500, loss is 3.606771512031555 and perplexity is 36.84690080198366
At time: 758.6612811088562 and batch: 1550, loss is 3.6299276876449587 and perplexity is 37.710089613196146
At time: 759.9117043018341 and batch: 1600, loss is 3.711916208267212 and perplexity is 40.93216598134445
At time: 761.1619017124176 and batch: 1650, loss is 3.6631167268753053 and perplexity is 38.98265200859457
At time: 762.4109921455383 and batch: 1700, loss is 3.6477190113067626 and perplexity is 38.38700578484129
At time: 763.6601004600525 and batch: 1750, loss is 3.6309332036972046 and perplexity is 37.74802678365438
At time: 764.9084451198578 and batch: 1800, loss is 3.604386568069458 and perplexity is 36.75912771694271
At time: 766.1576807498932 and batch: 1850, loss is 3.642943663597107 and perplexity is 38.20413147641225
At time: 767.4049475193024 and batch: 1900, loss is 3.7530009078979494 and perplexity is 42.64887550322947
At time: 768.6541123390198 and batch: 1950, loss is 3.672307600975037 and perplexity is 39.342588185610495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319080157612645 and perplexity of 75.119498403848
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 772.5212860107422 and batch: 50, loss is 3.8706124782562257 and perplexity is 47.97175874398587
At time: 773.7669157981873 and batch: 100, loss is 3.860417366027832 and perplexity is 47.48516592868843
At time: 775.0047268867493 and batch: 150, loss is 3.8149078989028933 and perplexity is 45.372577326352044
At time: 776.2513177394867 and batch: 200, loss is 3.8182224464416503 and perplexity is 45.52321640313388
At time: 777.4974544048309 and batch: 250, loss is 3.8149524402618407 and perplexity is 45.37459832761384
At time: 778.7662081718445 and batch: 300, loss is 3.812701873779297 and perplexity is 45.272594603594506
At time: 780.0143015384674 and batch: 350, loss is 3.8556547737121583 and perplexity is 47.25955112444924
At time: 781.2626457214355 and batch: 400, loss is 3.8055828332901003 and perplexity is 44.95144167626144
At time: 782.5112719535828 and batch: 450, loss is 3.8436089181900024 and perplexity is 46.69368441624742
At time: 783.7594349384308 and batch: 500, loss is 3.8612837743759156 and perplexity is 47.5263253006962
At time: 785.0073602199554 and batch: 550, loss is 3.8295238542556764 and perplexity is 46.04061097336175
At time: 786.2547385692596 and batch: 600, loss is 3.7869554376602172 and perplexity is 44.12186381265577
At time: 787.5021731853485 and batch: 650, loss is 3.811970624923706 and perplexity is 45.239501171842704
At time: 788.7528424263 and batch: 700, loss is 3.8632969284057617 and perplexity is 47.62209948574632
At time: 790.0013947486877 and batch: 750, loss is 3.8058222246170046 and perplexity is 44.962203949676635
At time: 791.2500739097595 and batch: 800, loss is 3.802325110435486 and perplexity is 44.805240607945315
At time: 792.4988551139832 and batch: 850, loss is 3.791686553955078 and perplexity is 44.33110406118085
At time: 793.7480223178864 and batch: 900, loss is 3.7455447149276733 and perplexity is 42.33205984462964
At time: 794.9977219104767 and batch: 950, loss is 3.8442088747024536 and perplexity is 46.721707001629035
At time: 796.24889087677 and batch: 1000, loss is 3.800452036857605 and perplexity is 44.72139564401876
At time: 797.496910572052 and batch: 1050, loss is 3.7591346645355226 and perplexity is 42.91127725799099
At time: 798.7462701797485 and batch: 1100, loss is 3.7777838277816773 and perplexity is 43.71904536119696
At time: 799.9944176673889 and batch: 1150, loss is 3.7648473739624024 and perplexity is 43.15711845718397
At time: 801.2433397769928 and batch: 1200, loss is 3.791325626373291 and perplexity is 44.315106630124816
At time: 802.493132352829 and batch: 1250, loss is 3.7945790100097656 and perplexity is 44.459515454161796
At time: 803.7427105903625 and batch: 1300, loss is 3.7776472425460814 and perplexity is 43.71307439286861
At time: 804.9926106929779 and batch: 1350, loss is 3.6531383895874026 and perplexity is 38.59560421661722
At time: 806.2425906658173 and batch: 1400, loss is 3.6751964855194093 and perplexity is 39.45640870857144
At time: 807.4907579421997 and batch: 1450, loss is 3.594711036682129 and perplexity is 36.40517870659335
At time: 808.7394664287567 and batch: 1500, loss is 3.597967948913574 and perplexity is 36.52394047175337
At time: 809.9897744655609 and batch: 1550, loss is 3.6238135147094725 and perplexity is 37.48022702976273
At time: 811.2397804260254 and batch: 1600, loss is 3.7099842405319214 and perplexity is 40.85316269780363
At time: 812.4892783164978 and batch: 1650, loss is 3.660237364768982 and perplexity is 38.87056827985562
At time: 813.7396142482758 and batch: 1700, loss is 3.6432064628601073 and perplexity is 38.21417281337801
At time: 814.9892597198486 and batch: 1750, loss is 3.6221045780181886 and perplexity is 37.41623039326902
At time: 816.2457432746887 and batch: 1800, loss is 3.5924398422241213 and perplexity is 36.322589290286366
At time: 817.4955606460571 and batch: 1850, loss is 3.632061767578125 and perplexity is 37.79065189131274
At time: 818.7453536987305 and batch: 1900, loss is 3.744896550178528 and perplexity is 42.304630585979204
At time: 819.9959588050842 and batch: 1950, loss is 3.676776065826416 and perplexity is 39.51878252400904
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314952193859011 and perplexity of 74.81004697880189
finished 16 epochs...
Completing Train Step...
At time: 823.9637076854706 and batch: 50, loss is 3.8835000562667847 and perplexity is 48.59399950297459
At time: 825.1843764781952 and batch: 100, loss is 3.86710976600647 and perplexity is 47.804021416284534
At time: 826.4065701961517 and batch: 150, loss is 3.8169339752197264 and perplexity is 45.46459882051272
At time: 827.634015083313 and batch: 200, loss is 3.8161431741714478 and perplexity is 45.428659580373214
At time: 828.8731172084808 and batch: 250, loss is 3.809589171409607 and perplexity is 45.13189358489039
At time: 830.116311788559 and batch: 300, loss is 3.802842149734497 and perplexity is 44.828412668057915
At time: 831.3703215122223 and batch: 350, loss is 3.8430622148513796 and perplexity is 46.6681637998232
At time: 832.6184086799622 and batch: 400, loss is 3.7951015758514406 and perplexity is 44.48275454972549
At time: 833.8657097816467 and batch: 450, loss is 3.8331370830535887 and perplexity is 46.207267136915085
At time: 835.116504907608 and batch: 500, loss is 3.851668744087219 and perplexity is 47.07154809535036
At time: 836.365562915802 and batch: 550, loss is 3.8192258644104005 and perplexity is 45.568918141606325
At time: 837.6124784946442 and batch: 600, loss is 3.778949189186096 and perplexity is 43.770023547535025
At time: 838.8592357635498 and batch: 650, loss is 3.803644051551819 and perplexity is 44.864375070875056
At time: 840.1043961048126 and batch: 700, loss is 3.855213370323181 and perplexity is 47.23869520169748
At time: 841.3711779117584 and batch: 750, loss is 3.7981362342834473 and perplexity is 44.61794954746604
At time: 842.6171844005585 and batch: 800, loss is 3.7944380855560302 and perplexity is 44.4532504626887
At time: 843.8634486198425 and batch: 850, loss is 3.7835071229934694 and perplexity is 43.96997976504366
At time: 845.109055519104 and batch: 900, loss is 3.7385321712493895 and perplexity is 42.03624285301603
At time: 846.3548777103424 and batch: 950, loss is 3.836500210762024 and perplexity is 46.36292968715217
At time: 847.6003432273865 and batch: 1000, loss is 3.793523917198181 and perplexity is 44.41263127692813
At time: 848.8504068851471 and batch: 1050, loss is 3.752859787940979 and perplexity is 42.64285732040646
At time: 850.0979490280151 and batch: 1100, loss is 3.7711146163940428 and perplexity is 43.428443924346155
At time: 851.3442814350128 and batch: 1150, loss is 3.7588112020492552 and perplexity is 42.897399314178315
At time: 852.5972263813019 and batch: 1200, loss is 3.785670781135559 and perplexity is 44.065218764934144
At time: 853.8434970378876 and batch: 1250, loss is 3.7895752811431884 and perplexity is 44.2376077393064
At time: 855.087208032608 and batch: 1300, loss is 3.773635425567627 and perplexity is 43.53805684276587
At time: 856.333544254303 and batch: 1350, loss is 3.6495929956436157 and perplexity is 38.45900987862064
At time: 857.5799932479858 and batch: 1400, loss is 3.6723032855987547 and perplexity is 39.34241840790489
At time: 858.8264117240906 and batch: 1450, loss is 3.5932563400268553 and perplexity is 36.352258715493434
At time: 860.0727851390839 and batch: 1500, loss is 3.5981798553466797 and perplexity is 36.531680949801284
At time: 861.3199644088745 and batch: 1550, loss is 3.624696846008301 and perplexity is 37.51334911411851
At time: 862.566398859024 and batch: 1600, loss is 3.7111813402175904 and perplexity is 40.90209728997641
At time: 863.8201336860657 and batch: 1650, loss is 3.661815629005432 and perplexity is 38.93196474480017
At time: 865.0661690235138 and batch: 1700, loss is 3.645228319168091 and perplexity is 38.29151454031724
At time: 866.3180797100067 and batch: 1750, loss is 3.6254379892349244 and perplexity is 37.54116218418353
At time: 867.5643484592438 and batch: 1800, loss is 3.5962504625320433 and perplexity is 36.461264938986766
At time: 868.8114790916443 and batch: 1850, loss is 3.6369683504104615 and perplexity is 37.97653049658031
At time: 870.0577509403229 and batch: 1900, loss is 3.7500878858566282 and perplexity is 42.52481916599873
At time: 871.3030853271484 and batch: 1950, loss is 3.681720094680786 and perplexity is 39.71464830917505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31432622865189 and perplexity of 74.763233145694
finished 17 epochs...
Completing Train Step...
At time: 875.2139475345612 and batch: 50, loss is 3.884170928001404 and perplexity is 48.62661078148261
At time: 876.443253993988 and batch: 100, loss is 3.86617648601532 and perplexity is 47.75942769205229
At time: 877.6881213188171 and batch: 150, loss is 3.815303626060486 and perplexity is 45.39053604055115
At time: 878.9296290874481 and batch: 200, loss is 3.8140233850479124 and perplexity is 45.33246239679156
At time: 880.1728887557983 and batch: 250, loss is 3.806841411590576 and perplexity is 45.0080522022474
At time: 881.4153068065643 and batch: 300, loss is 3.7994770431518554 and perplexity is 44.67781381421084
At time: 882.6642868518829 and batch: 350, loss is 3.83890362739563 and perplexity is 46.47449313656696
At time: 883.9158306121826 and batch: 400, loss is 3.7909373092651366 and perplexity is 44.297901656779594
At time: 885.1725330352783 and batch: 450, loss is 3.8290748167037965 and perplexity is 46.01994165112145
At time: 886.4220626354218 and batch: 500, loss is 3.8475054025650026 and perplexity is 46.87598055436952
At time: 887.6716876029968 and batch: 550, loss is 3.8148334217071533 and perplexity is 45.369198229863656
At time: 888.9215903282166 and batch: 600, loss is 3.775122632980347 and perplexity is 43.6028551359455
At time: 890.1714985370636 and batch: 650, loss is 3.799709539413452 and perplexity is 44.68820244651125
At time: 891.4210767745972 and batch: 700, loss is 3.851321940422058 and perplexity is 47.055226340331906
At time: 892.6705856323242 and batch: 750, loss is 3.7946037530899046 and perplexity is 44.460615533125235
At time: 893.9216585159302 and batch: 800, loss is 3.790909237861633 and perplexity is 44.29665816996112
At time: 895.1719882488251 and batch: 850, loss is 3.780064558982849 and perplexity is 43.81887054597247
At time: 896.4214327335358 and batch: 900, loss is 3.735563049316406 and perplexity is 41.91161722827384
At time: 897.6706385612488 and batch: 950, loss is 3.833419442176819 and perplexity is 46.22031602249997
At time: 898.9203357696533 and batch: 1000, loss is 3.790843644142151 and perplexity is 44.29375268268302
At time: 900.1703841686249 and batch: 1050, loss is 3.750351028442383 and perplexity is 42.53601072929669
At time: 901.4191293716431 and batch: 1100, loss is 3.768550057411194 and perplexity is 43.31721180999196
At time: 902.7099199295044 and batch: 1150, loss is 3.7565766954421997 and perplexity is 42.80165180604415
At time: 903.9666314125061 and batch: 1200, loss is 3.7836691522598267 and perplexity is 43.97710476582047
At time: 905.2163481712341 and batch: 1250, loss is 3.787793984413147 and perplexity is 44.15887757500532
At time: 906.4671051502228 and batch: 1300, loss is 3.772247176170349 and perplexity is 43.477657096251484
At time: 907.7175886631012 and batch: 1350, loss is 3.648499674797058 and perplexity is 38.41698481900548
At time: 908.9721167087555 and batch: 1400, loss is 3.6715024185180662 and perplexity is 39.310922973638974
At time: 910.2227244377136 and batch: 1450, loss is 3.5929349422454835 and perplexity is 36.340577057524456
At time: 911.4728391170502 and batch: 1500, loss is 3.5985197019577027 and perplexity is 36.54409822763243
At time: 912.7237446308136 and batch: 1550, loss is 3.6255239057540893 and perplexity is 37.54438772872559
At time: 913.9748673439026 and batch: 1600, loss is 3.712256383895874 and perplexity is 40.94609247523227
At time: 915.2316429615021 and batch: 1650, loss is 3.6628684186935425 and perplexity is 38.972973498830335
At time: 916.4822015762329 and batch: 1700, loss is 3.6464048480987548 and perplexity is 38.33659212731569
At time: 917.7324261665344 and batch: 1750, loss is 3.627083086967468 and perplexity is 37.602971892535436
At time: 918.9833452701569 and batch: 1800, loss is 3.597919588088989 and perplexity is 36.52217418658492
At time: 920.2336242198944 and batch: 1850, loss is 3.6388130521774293 and perplexity is 38.04665052487628
At time: 921.4832928180695 and batch: 1900, loss is 3.7517765808105468 and perplexity is 42.596691281500284
At time: 922.7331142425537 and batch: 1950, loss is 3.682993144989014 and perplexity is 39.765239250020066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314072435955668 and perplexity of 74.74426119074936
finished 18 epochs...
Completing Train Step...
At time: 926.6498382091522 and batch: 50, loss is 3.883070149421692 and perplexity is 48.57311309988334
At time: 927.8796529769897 and batch: 100, loss is 3.8643984365463258 and perplexity is 47.67458451703847
At time: 929.1087777614594 and batch: 150, loss is 3.8132559967041018 and perplexity is 45.297688137938984
At time: 930.347062587738 and batch: 200, loss is 3.811947784423828 and perplexity is 45.23846789082208
At time: 931.5874209403992 and batch: 250, loss is 3.804476284980774 and perplexity is 44.901728244702234
At time: 932.8276135921478 and batch: 300, loss is 3.7968950366973875 and perplexity is 44.56260421054737
At time: 934.089391708374 and batch: 350, loss is 3.83603057384491 and perplexity is 46.341161055862074
At time: 935.3375728130341 and batch: 400, loss is 3.787958345413208 and perplexity is 44.16613616878364
At time: 936.5855333805084 and batch: 450, loss is 3.8262087011337282 and perplexity is 45.888232017499384
At time: 937.8336050510406 and batch: 500, loss is 3.8446097660064695 and perplexity is 46.74044108258894
At time: 939.0820083618164 and batch: 550, loss is 3.811929545402527 and perplexity is 45.237642792967094
At time: 940.329344034195 and batch: 600, loss is 3.7724616432189944 and perplexity is 43.48698262102407
At time: 941.5778968334198 and batch: 650, loss is 3.7970188426971436 and perplexity is 44.568121669853625
At time: 942.8253712654114 and batch: 700, loss is 3.848651099205017 and perplexity is 46.92971698473393
At time: 944.0758857727051 and batch: 750, loss is 3.7921882343292235 and perplexity is 44.35334968568259
At time: 945.3273751735687 and batch: 800, loss is 3.7884943151473998 and perplexity is 44.18981422584045
At time: 946.5754029750824 and batch: 850, loss is 3.7777327919006347 and perplexity is 43.71681417813429
At time: 947.8276836872101 and batch: 900, loss is 3.733486351966858 and perplexity is 41.82466979685877
At time: 949.0783565044403 and batch: 950, loss is 3.8313459253311155 and perplexity is 46.12457671145309
At time: 950.3252794742584 and batch: 1000, loss is 3.7890545988082884 and perplexity is 44.21457999400865
At time: 951.5721182823181 and batch: 1050, loss is 3.7486742877960206 and perplexity is 42.46474863189628
At time: 952.8202583789825 and batch: 1100, loss is 3.766917495727539 and perplexity is 43.24655148411249
At time: 954.0689644813538 and batch: 1150, loss is 3.7551159763336184 and perplexity is 42.7391762560957
At time: 955.318338394165 and batch: 1200, loss is 3.782374505996704 and perplexity is 43.92020681078215
At time: 956.5664420127869 and batch: 1250, loss is 3.7866482400894164 and perplexity is 44.10831176495796
At time: 957.8143570423126 and batch: 1300, loss is 3.7713338994979857 and perplexity is 43.43796809253571
At time: 959.0617604255676 and batch: 1350, loss is 3.6477727270126343 and perplexity is 38.38906782533481
At time: 960.310968875885 and batch: 1400, loss is 3.670956754684448 and perplexity is 39.28947827603616
At time: 961.560733795166 and batch: 1450, loss is 3.5926031970977785 and perplexity is 36.32852324692796
At time: 962.813453912735 and batch: 1500, loss is 3.5985354137420655 and perplexity is 36.544672405134186
At time: 964.0617864131927 and batch: 1550, loss is 3.625868263244629 and perplexity is 37.55731864616906
At time: 965.315395116806 and batch: 1600, loss is 3.712756938934326 and perplexity is 40.96659337861285
At time: 966.564257144928 and batch: 1650, loss is 3.6633170366287233 and perplexity is 38.990461396128126
At time: 967.8124439716339 and batch: 1700, loss is 3.64691237449646 and perplexity is 38.35605389808182
At time: 969.0636034011841 and batch: 1750, loss is 3.627845058441162 and perplexity is 37.63163520336943
At time: 970.3121981620789 and batch: 1800, loss is 3.59867835521698 and perplexity is 36.54989652787104
At time: 971.5608603954315 and batch: 1850, loss is 3.639616889953613 and perplexity is 38.077246155139676
At time: 972.8060476779938 and batch: 1900, loss is 3.7524380588531496 and perplexity is 42.62487737868498
At time: 974.05282330513 and batch: 1950, loss is 3.683348708152771 and perplexity is 39.779380818256755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313964275981105 and perplexity of 74.73617729054531
finished 19 epochs...
Completing Train Step...
At time: 977.9433047771454 and batch: 50, loss is 3.8816865921020507 and perplexity is 48.50595588235904
At time: 979.18425989151 and batch: 100, loss is 3.8626303005218507 and perplexity is 47.59036384544537
At time: 980.4168782234192 and batch: 150, loss is 3.81132643699646 and perplexity is 45.21036781603869
At time: 981.6600337028503 and batch: 200, loss is 3.8100604391098023 and perplexity is 45.15316780111735
At time: 982.9019644260406 and batch: 250, loss is 3.80239990234375 and perplexity is 44.808591802710176
At time: 984.153068780899 and batch: 300, loss is 3.794674401283264 and perplexity is 44.463756706246095
At time: 985.4034292697906 and batch: 350, loss is 3.8336654901504517 and perplexity is 46.231689836792576
At time: 986.6524722576141 and batch: 400, loss is 3.7855151987075804 and perplexity is 44.058363524500585
At time: 987.9017317295074 and batch: 450, loss is 3.8238671255111694 and perplexity is 45.78090695595717
At time: 989.1515944004059 and batch: 500, loss is 3.8422750759124757 and perplexity is 46.631443924606955
At time: 990.4012463092804 and batch: 550, loss is 3.809632725715637 and perplexity is 45.133859316003026
At time: 991.651535987854 and batch: 600, loss is 3.7703256750106813 and perplexity is 43.39419493971636
At time: 992.9012424945831 and batch: 650, loss is 3.7948755979537965 and perplexity is 44.47270356606378
At time: 994.1518037319183 and batch: 700, loss is 3.8465384435653687 and perplexity is 46.83067531079238
At time: 995.4026200771332 and batch: 750, loss is 3.7902616167068484 and perplexity is 44.26798000433969
At time: 996.6934545040131 and batch: 800, loss is 3.7865660619735717 and perplexity is 44.104687175937016
At time: 997.9436378479004 and batch: 850, loss is 3.7758641910552977 and perplexity is 43.63520117701416
At time: 999.1936554908752 and batch: 900, loss is 3.731792187690735 and perplexity is 41.75387192397545
At time: 1000.4431774616241 and batch: 950, loss is 3.8296759366989135 and perplexity is 46.04761347443195
At time: 1001.6910789012909 and batch: 1000, loss is 3.7875899362564085 and perplexity is 44.14986795666176
At time: 1002.9404327869415 and batch: 1050, loss is 3.7473041105270384 and perplexity is 42.406604241745285
At time: 1004.1900908946991 and batch: 1100, loss is 3.765594801902771 and perplexity is 43.18938735117891
At time: 1005.4405329227448 and batch: 1150, loss is 3.7538857746124266 and perplexity is 42.686630775300436
At time: 1006.6895599365234 and batch: 1200, loss is 3.781266474723816 and perplexity is 43.87156879931917
At time: 1007.9392538070679 and batch: 1250, loss is 3.785669207572937 and perplexity is 44.06514942560752
At time: 1009.1949331760406 and batch: 1300, loss is 3.7705266523361205 and perplexity is 43.40291706540032
At time: 1010.44455742836 and batch: 1350, loss is 3.64709135055542 and perplexity is 38.3629193278012
At time: 1011.6943557262421 and batch: 1400, loss is 3.6704079627990724 and perplexity is 39.267922444551324
At time: 1012.9441664218903 and batch: 1450, loss is 3.592180323600769 and perplexity is 36.31316412497303
At time: 1014.1936485767365 and batch: 1500, loss is 3.5983315229415895 and perplexity is 36.53722204218041
At time: 1015.4436752796173 and batch: 1550, loss is 3.625893783569336 and perplexity is 37.558277133366445
At time: 1016.692892074585 and batch: 1600, loss is 3.7128926372528075 and perplexity is 40.97215285364542
At time: 1017.9414913654327 and batch: 1650, loss is 3.663404746055603 and perplexity is 38.993881377131046
At time: 1019.192108631134 and batch: 1700, loss is 3.647050518989563 and perplexity is 38.36135294171342
At time: 1020.4423720836639 and batch: 1750, loss is 3.628153433799744 and perplexity is 37.64324166185021
At time: 1021.6923954486847 and batch: 1800, loss is 3.598989472389221 and perplexity is 36.56126959741138
At time: 1022.9424107074738 and batch: 1850, loss is 3.6399632596969607 and perplexity is 38.090437245483216
At time: 1024.1924691200256 and batch: 1900, loss is 3.752685580253601 and perplexity is 42.63542925388142
At time: 1025.4431428909302 and batch: 1950, loss is 3.6833770418167116 and perplexity is 39.78050792983214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313941849109739 and perplexity of 74.73450121070549
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc433bcbb38>
ELAPSED
4213.933474302292


RESULTS SO FAR:
[{'best_accuracy': -75.2531559304004, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.96225198742506, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7460609200881098, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.7558732386815785, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -73.92024548433339, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.06428528362550812, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.41802598995097096, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -74.73450121070549, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.47589954029325743, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.2146320946900251, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.9183464086206847, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.17881090566881874, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6132895946502686 and batch: 50, loss is 7.675892057418824 and perplexity is 2155.745877318302
At time: 2.7832181453704834 and batch: 100, loss is 6.774455003738403 and perplexity is 875.2022510791596
At time: 3.985630750656128 and batch: 150, loss is 6.467090492248535 and perplexity is 643.6084164960972
At time: 5.164644479751587 and batch: 200, loss is 6.335486927032471 and perplexity is 564.2440818017125
At time: 6.351495981216431 and batch: 250, loss is 6.246612119674682 and perplexity is 516.2608286635283
At time: 7.529928684234619 and batch: 300, loss is 6.138179721832276 and perplexity is 463.2096326097982
At time: 8.710036754608154 and batch: 350, loss is 6.064244432449341 and perplexity is 430.19751156507596
At time: 9.89037013053894 and batch: 400, loss is 6.000731239318847 and perplexity is 403.7239043740822
At time: 11.071384191513062 and batch: 450, loss is 5.900336151123047 and perplexity is 365.1601962465918
At time: 12.251856088638306 and batch: 500, loss is 5.873780069351196 and perplexity is 355.59060009123084
At time: 13.441184997558594 and batch: 550, loss is 5.8222493648529055 and perplexity is 337.73087984247485
At time: 14.631279706954956 and batch: 600, loss is 5.842447586059571 and perplexity is 344.62180076296676
At time: 15.822885513305664 and batch: 650, loss is 5.902406024932861 and perplexity is 365.91681455526333
At time: 17.015259742736816 and batch: 700, loss is 5.814369993209839 and perplexity is 335.0802291694094
At time: 18.206716775894165 and batch: 750, loss is 5.743288040161133 and perplexity is 312.0888865928914
At time: 19.43245816230774 and batch: 800, loss is 5.762061967849731 and perplexity is 318.0033660699333
At time: 20.728048086166382 and batch: 850, loss is 5.773858299255371 and perplexity is 321.77685205211037
At time: 22.063463926315308 and batch: 900, loss is 5.748024215698242 and perplexity is 313.5705001644034
At time: 23.390652418136597 and batch: 950, loss is 5.765465288162232 and perplexity is 319.08747712731304
At time: 24.717474460601807 and batch: 1000, loss is 5.743956146240234 and perplexity is 312.2974647436508
At time: 26.04444169998169 and batch: 1050, loss is 5.645267305374145 and perplexity is 282.9491799514273
At time: 27.370660543441772 and batch: 1100, loss is 5.7183584690094 and perplexity is 304.4048226540595
At time: 28.69683861732483 and batch: 1150, loss is 5.62534426689148 and perplexity is 277.3677566236189
At time: 30.02266812324524 and batch: 1200, loss is 5.680130500793457 and perplexity is 292.9876625502379
At time: 31.348974466323853 and batch: 1250, loss is 5.629256935119629 and perplexity is 278.45513051189107
At time: 32.675090312957764 and batch: 1300, loss is 5.652199821472168 and perplexity is 284.91754467316485
At time: 34.0020170211792 and batch: 1350, loss is 5.6113259220123295 and perplexity is 273.50664617185646
At time: 35.329389333724976 and batch: 1400, loss is 5.613079099655152 and perplexity is 273.9865724842023
At time: 36.65890955924988 and batch: 1450, loss is 5.575735311508179 and perplexity is 263.94356504040803
At time: 37.98573088645935 and batch: 1500, loss is 5.544445314407349 and perplexity is 255.8126432946212
At time: 39.31070923805237 and batch: 1550, loss is 5.532600193023682 and perplexity is 252.8003869741438
At time: 40.63742113113403 and batch: 1600, loss is 5.5401576805114745 and perplexity is 254.71816038198483
At time: 41.96768140792847 and batch: 1650, loss is 5.533323640823364 and perplexity is 252.98334102873375
At time: 43.29370832443237 and batch: 1700, loss is 5.553926334381104 and perplexity is 258.2495419633914
At time: 44.62275791168213 and batch: 1750, loss is 5.559491739273072 and perplexity is 259.69081213348613
At time: 45.9513373374939 and batch: 1800, loss is 5.549101362228393 and perplexity is 257.00649635673057
At time: 47.28021454811096 and batch: 1850, loss is 5.5215123176574705 and perplexity is 250.01285027905405
At time: 48.60939884185791 and batch: 1900, loss is 5.536284627914429 and perplexity is 253.73353153987955
At time: 49.93812561035156 and batch: 1950, loss is 5.466872959136963 and perplexity is 236.71880481439175
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.088306231831395 and perplexity of 162.11504407890857
finished 1 epochs...
Completing Train Step...
At time: 53.925191164016724 and batch: 50, loss is 5.3468890953063966 and perplexity is 209.95413357328312
At time: 55.20319747924805 and batch: 100, loss is 5.274436779022217 and perplexity is 195.280459482178
At time: 56.4583899974823 and batch: 150, loss is 5.178134460449218 and perplexity is 177.35164567900264
At time: 57.70917010307312 and batch: 200, loss is 5.140229558944702 and perplexity is 170.7549621514177
At time: 58.965391874313354 and batch: 250, loss is 5.1600740528106686 and perplexity is 174.17735345012184
At time: 60.21519136428833 and batch: 300, loss is 5.156962413787841 and perplexity is 173.6362187447854
At time: 61.46533417701721 and batch: 350, loss is 5.146566848754883 and perplexity is 171.84052195351714
At time: 62.71488976478577 and batch: 400, loss is 5.095707817077637 and perplexity is 163.31940398536858
At time: 63.96310758590698 and batch: 450, loss is 5.048479709625244 and perplexity is 155.78544525007402
At time: 65.21249103546143 and batch: 500, loss is 5.0354172897338865 and perplexity is 153.76374325771408
At time: 66.46180701255798 and batch: 550, loss is 4.9999213218688965 and perplexity is 148.40148269193236
At time: 67.73337817192078 and batch: 600, loss is 4.977672719955445 and perplexity is 145.1362156842817
At time: 68.98265957832336 and batch: 650, loss is 5.042955722808838 and perplexity is 154.9272609858546
At time: 70.23988318443298 and batch: 700, loss is 5.035168933868408 and perplexity is 153.72555987190827
At time: 71.48990225791931 and batch: 750, loss is 4.974348945617676 and perplexity is 144.65461646204858
At time: 72.73962664604187 and batch: 800, loss is 4.973316097259522 and perplexity is 144.50528730939652
At time: 73.98900866508484 and batch: 850, loss is 4.969354047775268 and perplexity is 143.9338829240497
At time: 75.23926281929016 and batch: 900, loss is 4.965799465179443 and perplexity is 143.42316627885194
At time: 76.48916363716125 and batch: 950, loss is 5.010164985656738 and perplexity is 149.92947032072408
At time: 77.73854398727417 and batch: 1000, loss is 4.975083436965942 and perplexity is 144.76090305483993
At time: 78.98724246025085 and batch: 1050, loss is 4.891515617370605 and perplexity is 133.15523357833743
At time: 80.23708605766296 and batch: 1100, loss is 4.957382259368896 and perplexity is 142.22101046439104
At time: 81.48729014396667 and batch: 1150, loss is 4.877281265258789 and perplexity is 131.2732810615987
At time: 82.73650527000427 and batch: 1200, loss is 4.958922567367554 and perplexity is 142.44024342418226
At time: 83.9862105846405 and batch: 1250, loss is 4.922166767120362 and perplexity is 137.29978778192972
At time: 85.2360737323761 and batch: 1300, loss is 4.929623737335205 and perplexity is 138.3274550901085
At time: 86.48569250106812 and batch: 1350, loss is 4.826564302444458 and perplexity is 124.78151181391802
At time: 87.73508548736572 and batch: 1400, loss is 4.839549779891968 and perplexity is 126.41242550054427
At time: 88.98625707626343 and batch: 1450, loss is 4.79438159942627 and perplexity is 120.82963755731123
At time: 90.23639869689941 and batch: 1500, loss is 4.7583473110198975 and perplexity is 116.55314054478086
At time: 91.48600006103516 and batch: 1550, loss is 4.7606410312652585 and perplexity is 116.82078767939011
At time: 92.73567223548889 and batch: 1600, loss is 4.815913991928101 and perplexity is 123.45960183749388
At time: 93.98610496520996 and batch: 1650, loss is 4.78641975402832 and perplexity is 119.87143027451506
At time: 95.23579287528992 and batch: 1700, loss is 4.795061626434326 and perplexity is 120.91183291858914
At time: 96.48702383041382 and batch: 1750, loss is 4.791279830932617 and perplexity is 120.45543264296097
At time: 97.73392128944397 and batch: 1800, loss is 4.74784218788147 and perplexity is 115.33514425294435
At time: 98.98287034034729 and batch: 1850, loss is 4.764533100128173 and perplexity is 117.27634819102283
At time: 100.23340892791748 and batch: 1900, loss is 4.857763090133667 and perplexity is 128.73590915957067
At time: 101.48480176925659 and batch: 1950, loss is 4.77065824508667 and perplexity is 117.9968872743347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.631640625 and perplexity of 102.68238928841623
finished 2 epochs...
Completing Train Step...
At time: 105.4445378780365 and batch: 50, loss is 4.752973680496216 and perplexity is 115.92850680964239
At time: 106.71504616737366 and batch: 100, loss is 4.698518972396851 and perplexity is 109.78445817674239
At time: 107.96401000022888 and batch: 150, loss is 4.647912130355835 and perplexity is 104.36685355534574
At time: 109.2133059501648 and batch: 200, loss is 4.624873695373535 and perplexity is 101.98989047413072
At time: 110.46969676017761 and batch: 250, loss is 4.637225131988526 and perplexity is 103.25742395710597
At time: 111.71901679039001 and batch: 300, loss is 4.657241125106811 and perplexity is 105.34504707107644
At time: 112.96802973747253 and batch: 350, loss is 4.665050468444824 and perplexity is 106.1709433691627
At time: 114.21720147132874 and batch: 400, loss is 4.6115130519866945 and perplexity is 100.63630245716459
At time: 115.46701645851135 and batch: 450, loss is 4.603821611404419 and perplexity is 99.8652334334404
At time: 116.71679186820984 and batch: 500, loss is 4.607799015045166 and perplexity is 100.26322874580312
At time: 117.96579098701477 and batch: 550, loss is 4.567313375473023 and perplexity is 96.28508011311754
At time: 119.21587538719177 and batch: 600, loss is 4.551187763214111 and perplexity is 94.74487598764323
At time: 120.46423172950745 and batch: 650, loss is 4.611795177459717 and perplexity is 100.66469852703753
At time: 121.71201825141907 and batch: 700, loss is 4.6324889183044435 and perplexity is 102.76953102738509
At time: 122.96067428588867 and batch: 750, loss is 4.5797514057159425 and perplexity is 97.49015569894291
At time: 124.20894956588745 and batch: 800, loss is 4.573258790969849 and perplexity is 96.85924003891434
At time: 125.45752573013306 and batch: 850, loss is 4.578212900161743 and perplexity is 97.34028187333949
At time: 126.70678544044495 and batch: 900, loss is 4.555607957839966 and perplexity is 95.16459371295356
At time: 127.95602250099182 and batch: 950, loss is 4.620476655960083 and perplexity is 101.54242139647306
At time: 129.20574617385864 and batch: 1000, loss is 4.599598617553711 and perplexity is 99.44439239673494
At time: 130.47777891159058 and batch: 1050, loss is 4.536333875656128 and perplexity is 93.34794685172369
At time: 131.72584295272827 and batch: 1100, loss is 4.5825381565094 and perplexity is 97.76221537287984
At time: 132.97532296180725 and batch: 1150, loss is 4.5279586887359615 and perplexity is 92.5694051153253
At time: 134.2252767086029 and batch: 1200, loss is 4.5957872104644775 and perplexity is 99.06609072336944
At time: 135.47480058670044 and batch: 1250, loss is 4.587851305007934 and perplexity is 98.2830228793327
At time: 136.72397661209106 and batch: 1300, loss is 4.576101779937744 and perplexity is 97.13500159757938
At time: 137.97279143333435 and batch: 1350, loss is 4.465839128494263 and perplexity is 86.99399806309178
At time: 139.2211515903473 and batch: 1400, loss is 4.476265163421631 and perplexity is 87.90574522015899
At time: 140.47003960609436 and batch: 1450, loss is 4.431202411651611 and perplexity is 84.03239772198383
At time: 141.71927523612976 and batch: 1500, loss is 4.408852806091309 and perplexity is 82.17513859162565
At time: 142.9687783718109 and batch: 1550, loss is 4.425087766647339 and perplexity is 83.52013718279929
At time: 144.2175052165985 and batch: 1600, loss is 4.497132940292358 and perplexity is 89.75941642887022
At time: 145.46694087982178 and batch: 1650, loss is 4.463089389801025 and perplexity is 86.75511588284223
At time: 146.71439290046692 and batch: 1700, loss is 4.465515661239624 and perplexity is 86.96586290401487
At time: 147.96396708488464 and batch: 1750, loss is 4.462775659561157 and perplexity is 86.72790244858838
At time: 149.21282720565796 and batch: 1800, loss is 4.423277730941773 and perplexity is 83.36909948541337
At time: 150.4623441696167 and batch: 1850, loss is 4.458347911834717 and perplexity is 86.34474207043577
At time: 151.71176409721375 and batch: 1900, loss is 4.553944301605225 and perplexity is 95.00640416629498
At time: 152.9610435962677 and batch: 1950, loss is 4.469121217727661 and perplexity is 87.27998919498505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.503191996729651 and perplexity of 90.304924762784
finished 3 epochs...
Completing Train Step...
At time: 156.8395254611969 and batch: 50, loss is 4.4608457660675045 and perplexity is 86.56068823864155
At time: 158.11157321929932 and batch: 100, loss is 4.417297592163086 and perplexity is 82.87202845885344
At time: 159.33846974372864 and batch: 150, loss is 4.369431781768799 and perplexity is 78.9987304250419
At time: 160.6040198802948 and batch: 200, loss is 4.360271215438843 and perplexity is 78.2783618446115
At time: 161.85061049461365 and batch: 250, loss is 4.36499493598938 and perplexity is 78.64900166138877
At time: 163.09866046905518 and batch: 300, loss is 4.380015563964844 and perplexity is 79.83927601109956
At time: 164.34577989578247 and batch: 350, loss is 4.39388689994812 and perplexity is 80.95447016821112
At time: 165.5994691848755 and batch: 400, loss is 4.3442892074584964 and perplexity is 77.03726050389155
At time: 166.84515237808228 and batch: 450, loss is 4.354232244491577 and perplexity is 77.80706559612278
At time: 168.09074568748474 and batch: 500, loss is 4.359178123474121 and perplexity is 78.19284314468457
At time: 169.33683443069458 and batch: 550, loss is 4.325543212890625 and perplexity is 75.60657217136271
At time: 170.59422898292542 and batch: 600, loss is 4.314337944984436 and perplexity is 74.76410910172723
At time: 171.84357833862305 and batch: 650, loss is 4.365409812927246 and perplexity is 78.68163808794654
At time: 173.08968019485474 and batch: 700, loss is 4.396402130126953 and perplexity is 81.1583455840061
At time: 174.3368718624115 and batch: 750, loss is 4.351132745742798 and perplexity is 77.56627604988
At time: 175.58437323570251 and batch: 800, loss is 4.344565839767456 and perplexity is 77.05857444706737
At time: 176.83156538009644 and batch: 850, loss is 4.344563217163086 and perplexity is 77.05837235317829
At time: 178.07794857025146 and batch: 900, loss is 4.3163323497772215 and perplexity is 74.91336779089569
At time: 179.32497668266296 and batch: 950, loss is 4.392749261856079 and perplexity is 80.86242564583138
At time: 180.5719804763794 and batch: 1000, loss is 4.37006236076355 and perplexity is 79.04856107448916
At time: 181.819904088974 and batch: 1050, loss is 4.317682876586914 and perplexity is 75.01460865136183
At time: 183.0660605430603 and batch: 1100, loss is 4.35929533958435 and perplexity is 78.20200914279661
At time: 184.31310176849365 and batch: 1150, loss is 4.315119962692261 and perplexity is 74.82259882597383
At time: 185.56077432632446 and batch: 1200, loss is 4.376748304367066 and perplexity is 79.57884604809452
At time: 186.8079855442047 and batch: 1250, loss is 4.376134386062622 and perplexity is 79.53000613125253
At time: 188.05423784255981 and batch: 1300, loss is 4.359706182479858 and perplexity is 78.23414448350356
At time: 189.30069780349731 and batch: 1350, loss is 4.251679096221924 and perplexity is 70.22322496137399
At time: 190.54743766784668 and batch: 1400, loss is 4.265747938156128 and perplexity is 71.21816684262123
At time: 191.79395198822021 and batch: 1450, loss is 4.2107537317276 and perplexity is 67.40732770905377
At time: 193.0410749912262 and batch: 1500, loss is 4.195447368621826 and perplexity is 66.38342279570814
At time: 194.2873992919922 and batch: 1550, loss is 4.220471935272217 and perplexity is 68.06559926784715
At time: 195.53418397903442 and batch: 1600, loss is 4.302272348403931 and perplexity is 73.86745572930741
At time: 196.7877917289734 and batch: 1650, loss is 4.266900453567505 and perplexity is 71.30029419490621
At time: 198.03448724746704 and batch: 1700, loss is 4.266176743507385 and perplexity is 71.24871212219169
At time: 199.2837221622467 and batch: 1750, loss is 4.259243822097778 and perplexity is 70.75645874918182
At time: 200.5348024368286 and batch: 1800, loss is 4.217629337310791 and perplexity is 67.87239087112197
At time: 201.78560876846313 and batch: 1850, loss is 4.262861766815186 and perplexity is 71.01291534849408
At time: 203.03764176368713 and batch: 1900, loss is 4.357180223464966 and perplexity is 78.036777616223
At time: 204.28373003005981 and batch: 1950, loss is 4.275616121292114 and perplexity is 71.92443983981643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.450966910428779 and perplexity of 85.70977762723517
finished 4 epochs...
Completing Train Step...
At time: 208.1762146949768 and batch: 50, loss is 4.269996690750122 and perplexity is 71.52139893664689
At time: 209.38482451438904 and batch: 100, loss is 4.234864706993103 and perplexity is 69.05233580337178
At time: 210.5981683731079 and batch: 150, loss is 4.1904674243927005 and perplexity is 66.0536588370162
At time: 211.82689452171326 and batch: 200, loss is 4.184792346954346 and perplexity is 65.67986087743952
At time: 213.06942868232727 and batch: 250, loss is 4.182254853248597 and perplexity is 65.5134099173134
At time: 214.31571507453918 and batch: 300, loss is 4.195774869918823 and perplexity is 66.40516701320821
At time: 215.5628170967102 and batch: 350, loss is 4.208970994949341 and perplexity is 67.28726523851168
At time: 216.81484651565552 and batch: 400, loss is 4.16482717037201 and perplexity is 64.38155444176229
At time: 218.06611895561218 and batch: 450, loss is 4.185410318374633 and perplexity is 65.72046169813156
At time: 219.3162009716034 and batch: 500, loss is 4.195844631195069 and perplexity is 66.40979968399698
At time: 220.56539463996887 and batch: 550, loss is 4.1601274299621585 and perplexity is 64.07968775186842
At time: 221.8142442703247 and batch: 600, loss is 4.155959134101868 and perplexity is 63.81314056438379
At time: 223.10294580459595 and batch: 650, loss is 4.200438470840454 and perplexity is 66.7155774639267
At time: 224.35281491279602 and batch: 700, loss is 4.23725914478302 and perplexity is 69.21787543378366
At time: 225.60330891609192 and batch: 750, loss is 4.193117709159851 and perplexity is 66.22895202867925
At time: 226.85427284240723 and batch: 800, loss is 4.186753888130188 and perplexity is 65.80882106798666
At time: 228.10671472549438 and batch: 850, loss is 4.179253106117248 and perplexity is 65.31705008575125
At time: 229.3558704853058 and batch: 900, loss is 4.149384813308716 and perplexity is 63.3949885463506
At time: 230.60782837867737 and batch: 950, loss is 4.236832027435303 and perplexity is 69.18831759119676
At time: 231.85764527320862 and batch: 1000, loss is 4.210314340591431 and perplexity is 67.37771603277605
At time: 233.11737298965454 and batch: 1050, loss is 4.16447871685028 and perplexity is 64.35912437052826
At time: 234.36827874183655 and batch: 1100, loss is 4.20321638584137 and perplexity is 66.90116532165999
At time: 235.61896300315857 and batch: 1150, loss is 4.16122887134552 and perplexity is 64.15030665594348
At time: 236.87101554870605 and batch: 1200, loss is 4.222738966941834 and perplexity is 68.22008117852832
At time: 238.12355709075928 and batch: 1250, loss is 4.226295289993286 and perplexity is 68.46312574213002
At time: 239.37692832946777 and batch: 1300, loss is 4.203680353164673 and perplexity is 66.93221247813622
At time: 240.63347172737122 and batch: 1350, loss is 4.101265239715576 and perplexity is 60.416680843372795
At time: 241.88700222969055 and batch: 1400, loss is 4.116018810272217 and perplexity is 61.31465044775161
At time: 243.14079642295837 and batch: 1450, loss is 4.057618465423584 and perplexity is 57.83640752879634
At time: 244.3943464756012 and batch: 1500, loss is 4.044380235671997 and perplexity is 57.07580152447205
At time: 245.64607000350952 and batch: 1550, loss is 4.075259189605713 and perplexity is 58.86573599814355
At time: 246.89790773391724 and batch: 1600, loss is 4.160844168663025 and perplexity is 64.12563260728074
At time: 248.1503927707672 and batch: 1650, loss is 4.125631875991822 and perplexity is 61.90691438719723
At time: 249.40301203727722 and batch: 1700, loss is 4.124845705032349 and perplexity is 61.858264095144584
At time: 250.65717196464539 and batch: 1750, loss is 4.117382493019104 and perplexity is 61.39832121592371
At time: 251.91421723365784 and batch: 1800, loss is 4.072232012748718 and perplexity is 58.6878084494132
At time: 253.1642792224884 and batch: 1850, loss is 4.1182482719421385 and perplexity is 61.451501606250815
At time: 254.41528820991516 and batch: 1900, loss is 4.212283906936645 and perplexity is 67.51055168606644
At time: 255.66716408729553 and batch: 1950, loss is 4.1342701864242555 and perplexity is 62.44400195636027
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.43206049009811 and perplexity of 84.1045350565965
finished 5 epochs...
Completing Train Step...
At time: 259.5660357475281 and batch: 50, loss is 4.129463295936585 and perplexity is 62.144560744479385
At time: 260.7560398578644 and batch: 100, loss is 4.0967604923248295 and perplexity is 60.14513104880781
At time: 261.9480233192444 and batch: 150, loss is 4.055274248123169 and perplexity is 57.70098521335698
At time: 263.1440517902374 and batch: 200, loss is 4.053930940628052 and perplexity is 57.62352708413463
At time: 264.3538064956665 and batch: 250, loss is 4.04821473121643 and perplexity is 57.295078570865655
At time: 265.5819401741028 and batch: 300, loss is 4.058662228584289 and perplexity is 57.89680655597877
At time: 266.8145287036896 and batch: 350, loss is 4.0679799699783326 and perplexity is 58.4387951605406
At time: 268.0439393520355 and batch: 400, loss is 4.031555991172791 and perplexity is 56.34852087062592
At time: 269.27229595184326 and batch: 450, loss is 4.060915532112122 and perplexity is 58.02741272685301
At time: 270.50013184547424 and batch: 500, loss is 4.071840977668762 and perplexity is 58.664863943889365
At time: 271.7283294200897 and batch: 550, loss is 4.0349398040771485 and perplexity is 56.53951668749948
At time: 272.97030997276306 and batch: 600, loss is 4.031471610069275 and perplexity is 56.343766320853256
At time: 274.2118811607361 and batch: 650, loss is 4.072724223136902 and perplexity is 58.71670230873725
At time: 275.45087361335754 and batch: 700, loss is 4.110774817466736 and perplexity is 60.99395845010167
At time: 276.69279742240906 and batch: 750, loss is 4.072796587944031 and perplexity is 58.72095148531862
At time: 277.93904876708984 and batch: 800, loss is 4.063205580711365 and perplexity is 58.160450595537135
At time: 279.1825225353241 and batch: 850, loss is 4.054431195259094 and perplexity is 57.652360731897055
At time: 280.4262316226959 and batch: 900, loss is 4.030336847305298 and perplexity is 56.27986577568676
At time: 281.66894125938416 and batch: 950, loss is 4.118205423355103 and perplexity is 61.448868552647475
At time: 282.9150903224945 and batch: 1000, loss is 4.0892271089553835 and perplexity is 59.69373711537246
At time: 284.19204568862915 and batch: 1050, loss is 4.045729498863221 and perplexity is 57.15286377951964
At time: 285.44154834747314 and batch: 1100, loss is 4.0790509557723995 and perplexity is 59.089364810425515
At time: 286.69202494621277 and batch: 1150, loss is 4.045804147720337 and perplexity is 57.15713033472645
At time: 287.94116950035095 and batch: 1200, loss is 4.106235766410828 and perplexity is 60.71773113779028
At time: 289.1909680366516 and batch: 1250, loss is 4.1095188617706295 and perplexity is 60.91740082711316
At time: 290.4421422481537 and batch: 1300, loss is 4.084220509529114 and perplexity is 59.395621381125544
At time: 291.692280292511 and batch: 1350, loss is 3.9861822748184204 and perplexity is 53.8489160758919
At time: 292.941725730896 and batch: 1400, loss is 4.001544637680054 and perplexity is 54.682549559510186
At time: 294.1920611858368 and batch: 1450, loss is 3.944928503036499 and perplexity is 51.672643542923986
At time: 295.4415304660797 and batch: 1500, loss is 3.9298359155654907 and perplexity is 50.89862531182266
At time: 296.6915397644043 and batch: 1550, loss is 3.9670682096481324 and perplexity is 52.82941879246799
At time: 297.9408292770386 and batch: 1600, loss is 4.050705728530883 and perplexity is 57.43797836532728
At time: 299.1884059906006 and batch: 1650, loss is 4.015184979438782 and perplexity is 55.43354852085168
At time: 300.4372344017029 and batch: 1700, loss is 4.0097888517379765 and perplexity is 55.13522762682448
At time: 301.6928560733795 and batch: 1750, loss is 4.004984936714172 and perplexity is 54.870997855320525
At time: 302.9431722164154 and batch: 1800, loss is 3.95930561542511 and perplexity is 52.42091303486611
At time: 304.1930556297302 and batch: 1850, loss is 4.005329885482788 and perplexity is 54.88992880337933
At time: 305.44129061698914 and batch: 1900, loss is 4.10041567325592 and perplexity is 60.365374654818936
At time: 306.6896367073059 and batch: 1950, loss is 4.025237865447998 and perplexity is 55.993626146679276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.428289369095204 and perplexity of 83.78796396711944
finished 6 epochs...
Completing Train Step...
At time: 310.61174607276917 and batch: 50, loss is 4.02307695388794 and perplexity is 55.87275951073735
At time: 311.81913137435913 and batch: 100, loss is 3.9947393941879272 and perplexity is 54.311684838620636
At time: 313.02674293518066 and batch: 150, loss is 3.95062020778656 and perplexity is 51.96758754447493
At time: 314.23602533340454 and batch: 200, loss is 3.9527886724472046 and perplexity is 52.080399691935796
At time: 315.4961347579956 and batch: 250, loss is 3.94070659160614 and perplexity is 51.45494609155531
At time: 316.7371332645416 and batch: 300, loss is 3.9533023929595945 and perplexity is 52.10716133496494
At time: 317.9792637825012 and batch: 350, loss is 3.959794297218323 and perplexity is 52.44653644098594
At time: 319.2222890853882 and batch: 400, loss is 3.9261519861221315 and perplexity is 50.711463324856965
At time: 320.46572828292847 and batch: 450, loss is 3.961830291748047 and perplexity is 52.55342607871772
At time: 321.7096862792969 and batch: 500, loss is 3.9762679052352907 and perplexity is 53.31767582784521
At time: 322.95266604423523 and batch: 550, loss is 3.93950870513916 and perplexity is 51.39334581041063
At time: 324.19572472572327 and batch: 600, loss is 3.9359056425094603 and perplexity is 51.20850556216859
At time: 325.43816232681274 and batch: 650, loss is 3.9695947551727295 and perplexity is 52.963063482689506
At time: 326.68120312690735 and batch: 700, loss is 4.012700543403626 and perplexity is 55.29599835339769
At time: 327.92344069480896 and batch: 750, loss is 3.977976469993591 and perplexity is 53.40885039640681
At time: 329.1658980846405 and batch: 800, loss is 3.9659113836288453 and perplexity is 52.76833968198874
At time: 330.4083528518677 and batch: 850, loss is 3.9588445234298706 and perplexity is 52.39674774312202
At time: 331.6521167755127 and batch: 900, loss is 3.932372560501099 and perplexity is 51.02790094582106
At time: 332.893652677536 and batch: 950, loss is 4.024339127540588 and perplexity is 55.94332515937574
At time: 334.1346044540405 and batch: 1000, loss is 3.994479188919067 and perplexity is 54.2975544905402
At time: 335.3778989315033 and batch: 1050, loss is 3.9519788026809692 and perplexity is 52.038238425683694
At time: 336.6414749622345 and batch: 1100, loss is 3.9831833267211914 and perplexity is 53.687667879824986
At time: 337.8932240009308 and batch: 1150, loss is 3.9536211681365967 and perplexity is 52.12377445232661
At time: 339.1457085609436 and batch: 1200, loss is 4.014096908569336 and perplexity is 55.3732656934577
At time: 340.3970968723297 and batch: 1250, loss is 4.01903989315033 and perplexity is 55.64765247812634
At time: 341.64802503585815 and batch: 1300, loss is 3.9912174272537233 and perplexity is 54.12073733325816
At time: 342.89824533462524 and batch: 1350, loss is 3.8918355083465577 and perplexity is 49.000745307228755
At time: 344.14827489852905 and batch: 1400, loss is 3.9123912620544434 and perplexity is 50.01841622205465
At time: 345.39879274368286 and batch: 1450, loss is 3.853459119796753 and perplexity is 47.15589933934765
At time: 346.649293422699 and batch: 1500, loss is 3.8369002628326414 and perplexity is 46.38148098366829
At time: 347.8990168571472 and batch: 1550, loss is 3.877380256652832 and perplexity is 48.29752208008908
At time: 349.1489522457123 and batch: 1600, loss is 3.9649744749069216 and perplexity is 52.7189237170383
At time: 350.3982708454132 and batch: 1650, loss is 3.924334945678711 and perplexity is 50.61940220976471
At time: 351.646999835968 and batch: 1700, loss is 3.9236874961853028 and perplexity is 50.58663931075305
At time: 352.9029347896576 and batch: 1750, loss is 3.913825478553772 and perplexity is 50.0902049278381
At time: 354.15357279777527 and batch: 1800, loss is 3.870018801689148 and perplexity is 47.943287487133304
At time: 355.40450954437256 and batch: 1850, loss is 3.9151033115386964 and perplexity is 50.15425275641543
At time: 356.6543514728546 and batch: 1900, loss is 4.007969250679016 and perplexity is 55.03499472784875
At time: 357.9061326980591 and batch: 1950, loss is 3.9365149116516114 and perplexity is 51.23971483088005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.437767703034157 and perplexity of 84.58590989478121
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 361.80521059036255 and batch: 50, loss is 3.975495343208313 and perplexity is 53.27650052342019
At time: 363.02872824668884 and batch: 100, loss is 3.979331331253052 and perplexity is 53.481261020819424
At time: 364.2371106147766 and batch: 150, loss is 3.9392853021621703 and perplexity is 51.381865666356056
At time: 365.4606056213379 and batch: 200, loss is 3.9422146558761595 and perplexity is 51.532601997602924
At time: 366.688472032547 and batch: 250, loss is 3.9364409399032594 and perplexity is 51.23592467977273
At time: 367.9248368740082 and batch: 300, loss is 3.9363034915924073 and perplexity is 51.2288828724239
At time: 369.16333389282227 and batch: 350, loss is 3.938657703399658 and perplexity is 51.34962858808163
At time: 370.4028341770172 and batch: 400, loss is 3.8950472259521485 and perplexity is 49.15837485892481
At time: 371.64284086227417 and batch: 450, loss is 3.9266115713119505 and perplexity is 50.73477491877646
At time: 372.88314604759216 and batch: 500, loss is 3.9356721782684327 and perplexity is 51.19655160274869
At time: 374.122572183609 and batch: 550, loss is 3.9023549699783326 and perplexity is 49.51892748774513
At time: 375.365136384964 and batch: 600, loss is 3.8715214633941653 and perplexity is 48.01538418415955
At time: 376.6117808818817 and batch: 650, loss is 3.9016695976257325 and perplexity is 49.48500021165121
At time: 377.8855154514313 and batch: 700, loss is 3.944545431137085 and perplexity is 51.65285299605745
At time: 379.140709400177 and batch: 750, loss is 3.9026158237457276 and perplexity is 49.531846371434156
At time: 380.3896939754486 and batch: 800, loss is 3.88490818977356 and perplexity is 48.66247454158648
At time: 381.6446895599365 and batch: 850, loss is 3.8725776720046996 and perplexity is 48.06612523822495
At time: 382.8942930698395 and batch: 900, loss is 3.8506914281845095 and perplexity is 47.02556679561925
At time: 384.14011120796204 and batch: 950, loss is 3.9394891166687014 and perplexity is 51.39233910323441
At time: 385.387122631073 and batch: 1000, loss is 3.9014836359024048 and perplexity is 49.4757987513192
At time: 386.63479113578796 and batch: 1050, loss is 3.8511139392852782 and perplexity is 47.045439817600894
At time: 387.88150429725647 and batch: 1100, loss is 3.8665474033355713 and perplexity is 47.777145776757685
At time: 389.12701058387756 and batch: 1150, loss is 3.834001226425171 and perplexity is 46.24721409799535
At time: 390.3727159500122 and batch: 1200, loss is 3.8791023302078247 and perplexity is 48.380765620813115
At time: 391.6183087825775 and batch: 1250, loss is 3.874084639549255 and perplexity is 48.13861393428947
At time: 392.86582684516907 and batch: 1300, loss is 3.8545760440826418 and perplexity is 47.20859833345729
At time: 394.11067032814026 and batch: 1350, loss is 3.761317129135132 and perplexity is 43.0050318723801
At time: 395.35659623146057 and batch: 1400, loss is 3.7693054485321045 and perplexity is 43.349945609029874
At time: 396.6090030670166 and batch: 1450, loss is 3.691875615119934 and perplexity is 40.12002615929965
At time: 397.85188460350037 and batch: 1500, loss is 3.664094047546387 and perplexity is 39.02076918353366
At time: 399.0962996482849 and batch: 1550, loss is 3.6955952548980715 and perplexity is 40.269536093669814
At time: 400.3407242298126 and batch: 1600, loss is 3.77511372089386 and perplexity is 43.602466545261024
At time: 401.58503580093384 and batch: 1650, loss is 3.737811326980591 and perplexity is 42.005952187011715
At time: 402.8277132511139 and batch: 1700, loss is 3.7225898790359495 and perplexity is 41.37140240730564
At time: 404.07091069221497 and batch: 1750, loss is 3.703027982711792 and perplexity is 40.56996370988494
At time: 405.3150773048401 and batch: 1800, loss is 3.654287939071655 and perplexity is 38.63999728466443
At time: 406.5590043067932 and batch: 1850, loss is 3.6802712154388426 and perplexity is 39.65714824502239
At time: 407.8036768436432 and batch: 1900, loss is 3.766915216445923 and perplexity is 43.246452913155075
At time: 409.05025458335876 and batch: 1950, loss is 3.691081519126892 and perplexity is 40.08817965355062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370655432412791 and perplexity of 79.09545643975703
finished 8 epochs...
Completing Train Step...
At time: 412.9166693687439 and batch: 50, loss is 3.8935238552093505 and perplexity is 49.08354543984621
At time: 414.14962553977966 and batch: 100, loss is 3.8759141826629637 and perplexity is 48.2267662185299
At time: 415.3732831478119 and batch: 150, loss is 3.8309988880157473 and perplexity is 46.10857253936173
At time: 416.6120271682739 and batch: 200, loss is 3.834573359489441 and perplexity is 46.27368122894959
At time: 417.8544454574585 and batch: 250, loss is 3.8246879625320434 and perplexity is 45.8185010464356
At time: 419.0972752571106 and batch: 300, loss is 3.8282713985443113 and perplexity is 45.98298324281667
At time: 420.3393051624298 and batch: 350, loss is 3.836373691558838 and perplexity is 46.35706425728336
At time: 421.5822329521179 and batch: 400, loss is 3.7924609661102293 and perplexity is 44.36544790344519
At time: 422.8245179653168 and batch: 450, loss is 3.8287602996826173 and perplexity is 46.00546987208821
At time: 424.0662441253662 and batch: 500, loss is 3.841576862335205 and perplexity is 46.59889658115185
At time: 425.3083655834198 and batch: 550, loss is 3.811045055389404 and perplexity is 45.19764823969836
At time: 426.55055022239685 and batch: 600, loss is 3.78608259677887 and perplexity is 44.083369248417455
At time: 427.79244685173035 and batch: 650, loss is 3.817736186981201 and perplexity is 45.50108568955827
At time: 429.03510999679565 and batch: 700, loss is 3.8601397895812988 and perplexity is 47.47198699423242
At time: 430.28512144088745 and batch: 750, loss is 3.8204131174087523 and perplexity is 45.62305210529815
At time: 431.5349540710449 and batch: 800, loss is 3.805113000869751 and perplexity is 44.93032699219046
At time: 432.78575229644775 and batch: 850, loss is 3.7940993452072145 and perplexity is 44.43819490322767
At time: 434.0361135005951 and batch: 900, loss is 3.77294846534729 and perplexity is 43.50815820040889
At time: 435.2864236831665 and batch: 950, loss is 3.866593952178955 and perplexity is 47.779369799396214
At time: 436.5363187789917 and batch: 1000, loss is 3.8304207706451416 and perplexity is 46.08192407635478
At time: 437.7853307723999 and batch: 1050, loss is 3.7836552333831786 and perplexity is 43.97649265818383
At time: 439.0349190235138 and batch: 1100, loss is 3.799058961868286 and perplexity is 44.659138760581534
At time: 440.30667090415955 and batch: 1150, loss is 3.770312466621399 and perplexity is 43.3936217760823
At time: 441.5558364391327 and batch: 1200, loss is 3.817153882980347 and perplexity is 45.47459793802832
At time: 442.80606508255005 and batch: 1250, loss is 3.814868173599243 and perplexity is 45.37077492274111
At time: 444.05505752563477 and batch: 1300, loss is 3.8008917999267577 and perplexity is 44.741066787228114
At time: 445.30518317222595 and batch: 1350, loss is 3.7087158393859863 and perplexity is 40.80137734866363
At time: 446.556184053421 and batch: 1400, loss is 3.7181344985961915 and perplexity is 41.18748708086164
At time: 447.80690145492554 and batch: 1450, loss is 3.642456765174866 and perplexity is 38.18553447286654
At time: 449.0570960044861 and batch: 1500, loss is 3.6191082334518434 and perplexity is 37.30428626997342
At time: 450.3066236972809 and batch: 1550, loss is 3.6546362829208374 and perplexity is 38.65345963467824
At time: 451.5558705329895 and batch: 1600, loss is 3.7364609622955323 and perplexity is 41.9492671139902
At time: 452.8062963485718 and batch: 1650, loss is 3.7016899824142455 and perplexity is 40.51571738526175
At time: 454.054967880249 and batch: 1700, loss is 3.692225637435913 and perplexity is 40.134071521724806
At time: 455.302942276001 and batch: 1750, loss is 3.6749730491638184 and perplexity is 39.44759369723857
At time: 456.55323338508606 and batch: 1800, loss is 3.631056146621704 and perplexity is 37.75266792175295
At time: 457.80180764198303 and batch: 1850, loss is 3.6607800483703614 and perplexity is 38.89166842467084
At time: 459.05075883865356 and batch: 1900, loss is 3.75087881565094 and perplexity is 42.55846661710655
At time: 460.29960083961487 and batch: 1950, loss is 3.677475342750549 and perplexity is 39.54642676105996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373232535428779 and perplexity of 79.29955645952698
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 464.1910488605499 and batch: 50, loss is 3.8671769666671754 and perplexity is 47.807233986050285
At time: 465.42457485198975 and batch: 100, loss is 3.878423810005188 and perplexity is 48.34794942840414
At time: 466.6363399028778 and batch: 150, loss is 3.848272581100464 and perplexity is 46.91195659873953
At time: 467.8654592037201 and batch: 200, loss is 3.866466884613037 and perplexity is 47.77329897688519
At time: 469.0941653251648 and batch: 250, loss is 3.872646698951721 and perplexity is 48.06944321061873
At time: 470.3445785045624 and batch: 300, loss is 3.8684421014785766 and perplexity is 47.86775485746115
At time: 471.58266401290894 and batch: 350, loss is 3.874307222366333 and perplexity is 48.14932995514599
At time: 472.82829213142395 and batch: 400, loss is 3.8196761417388916 and perplexity is 45.58944141256441
At time: 474.0769748687744 and batch: 450, loss is 3.8662556552886964 and perplexity is 47.76320892091615
At time: 475.3252866268158 and batch: 500, loss is 3.8795940828323365 and perplexity is 48.40456283997597
At time: 476.57483196258545 and batch: 550, loss is 3.8578110122680664 and perplexity is 47.36156393316981
At time: 477.82472229003906 and batch: 600, loss is 3.8200504398345947 and perplexity is 45.60650864758683
At time: 479.07471680641174 and batch: 650, loss is 3.842196216583252 and perplexity is 46.62776674521019
At time: 480.32582211494446 and batch: 700, loss is 3.875717487335205 and perplexity is 48.21728117180457
At time: 481.5789155960083 and batch: 750, loss is 3.8289939069747927 and perplexity is 46.01621834074174
At time: 482.8289535045624 and batch: 800, loss is 3.815822801589966 and perplexity is 45.41410781454804
At time: 484.0782377719879 and batch: 850, loss is 3.8092900133132934 and perplexity is 45.11839403287333
At time: 485.32521080970764 and batch: 900, loss is 3.7831015825271606 and perplexity is 43.95215177417636
At time: 486.5741090774536 and batch: 950, loss is 3.877211275100708 and perplexity is 48.2893613793676
At time: 487.82739448547363 and batch: 1000, loss is 3.841662859916687 and perplexity is 46.602904145875534
At time: 489.0784866809845 and batch: 1050, loss is 3.798054966926575 and perplexity is 44.61432371197028
At time: 490.3281729221344 and batch: 1100, loss is 3.811913070678711 and perplexity is 45.23689752143509
At time: 491.5775189399719 and batch: 1150, loss is 3.7778496980667113 and perplexity is 43.72192524202456
At time: 492.8261663913727 and batch: 1200, loss is 3.8059835720062254 and perplexity is 44.96945906917909
At time: 494.07500410079956 and batch: 1250, loss is 3.795742559432983 and perplexity is 44.51127640509762
At time: 495.32336163520813 and batch: 1300, loss is 3.7852030181884766 and perplexity is 44.0446115083721
At time: 496.57162618637085 and batch: 1350, loss is 3.692749300003052 and perplexity is 40.15509373644066
At time: 497.8239324092865 and batch: 1400, loss is 3.704397883415222 and perplexity is 40.62557861646168
At time: 499.0710611343384 and batch: 1450, loss is 3.626666407585144 and perplexity is 37.58730677332645
At time: 500.319128036499 and batch: 1500, loss is 3.603253173828125 and perplexity is 36.71748873442078
At time: 501.574679851532 and batch: 1550, loss is 3.629144892692566 and perplexity is 37.68058189614542
At time: 502.82475185394287 and batch: 1600, loss is 3.699875774383545 and perplexity is 40.442280080827864
At time: 504.07475423812866 and batch: 1650, loss is 3.6546747398376467 and perplexity is 38.65494615614314
At time: 505.3217453956604 and batch: 1700, loss is 3.6399209976196287 and perplexity is 38.0888274984946
At time: 506.5786144733429 and batch: 1750, loss is 3.6267275333404543 and perplexity is 37.589604396064296
At time: 507.82783031463623 and batch: 1800, loss is 3.5843267011642457 and perplexity is 36.029091205306486
At time: 509.07487177848816 and batch: 1850, loss is 3.6111862564086916 and perplexity is 37.00993005155941
At time: 510.324018239975 and batch: 1900, loss is 3.706916012763977 and perplexity is 40.72800798936582
At time: 511.5738368034363 and batch: 1950, loss is 3.645433449745178 and perplexity is 38.2993701064733
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342300202125727 and perplexity of 76.88418526612506
finished 10 epochs...
Completing Train Step...
At time: 515.4819135665894 and batch: 50, loss is 3.861701822280884 and perplexity is 47.54619773494433
At time: 516.697592496872 and batch: 100, loss is 3.8500487565994264 and perplexity is 46.99535450939609
At time: 517.9164001941681 and batch: 150, loss is 3.8082230424880983 and perplexity is 45.07027969562221
At time: 519.1365134716034 and batch: 200, loss is 3.8193075370788576 and perplexity is 45.57264002873581
At time: 520.3682935237885 and batch: 250, loss is 3.822961935997009 and perplexity is 45.73948530908039
At time: 521.6151616573334 and batch: 300, loss is 3.8143401288986207 and perplexity is 45.346823449760755
At time: 522.861733675003 and batch: 350, loss is 3.823686776161194 and perplexity is 45.77265114363395
At time: 524.1086807250977 and batch: 400, loss is 3.7698843669891358 and perplexity is 43.37504895834926
At time: 525.3565247058868 and batch: 450, loss is 3.819532151222229 and perplexity is 45.58287743792745
At time: 526.6048271656036 and batch: 500, loss is 3.832539954185486 and perplexity is 46.17968368005028
At time: 527.8529434204102 and batch: 550, loss is 3.810639109611511 and perplexity is 45.17930416882573
At time: 529.1066179275513 and batch: 600, loss is 3.7778804683685303 and perplexity is 43.72327059955879
At time: 530.3527662754059 and batch: 650, loss is 3.8015978574752807 and perplexity is 44.772667709884395
At time: 531.5996482372284 and batch: 700, loss is 3.8371980237960814 and perplexity is 46.39529363446381
At time: 532.8818483352661 and batch: 750, loss is 3.793454670906067 and perplexity is 44.409555973367084
At time: 534.13472032547 and batch: 800, loss is 3.7804812669754027 and perplexity is 43.83713402455812
At time: 535.3834435939789 and batch: 850, loss is 3.7729516506195067 and perplexity is 43.50829678595712
At time: 536.6307947635651 and batch: 900, loss is 3.748272294998169 and perplexity is 42.44768153943764
At time: 537.8781883716583 and batch: 950, loss is 3.843678503036499 and perplexity is 46.69693370215909
At time: 539.1251831054688 and batch: 1000, loss is 3.808544592857361 and perplexity is 45.084774390963545
At time: 540.37287068367 and batch: 1050, loss is 3.7666423320770264 and perplexity is 43.23465324219096
At time: 541.6205885410309 and batch: 1100, loss is 3.782362895011902 and perplexity is 43.919696856888905
At time: 542.8685801029205 and batch: 1150, loss is 3.7502700519561767 and perplexity is 42.53256645206522
At time: 544.1165628433228 and batch: 1200, loss is 3.781484489440918 and perplexity is 43.881134489672526
At time: 545.3627469539642 and batch: 1250, loss is 3.7731902408599853 and perplexity is 43.51867867941008
At time: 546.6082272529602 and batch: 1300, loss is 3.7647110271453856 and perplexity is 43.15123452258771
At time: 547.8560655117035 and batch: 1350, loss is 3.673150854110718 and perplexity is 39.37577793817858
At time: 549.1030282974243 and batch: 1400, loss is 3.6861961889266968 and perplexity is 39.892813262042914
At time: 550.3507287502289 and batch: 1450, loss is 3.610537886619568 and perplexity is 36.98594170851521
At time: 551.5967030525208 and batch: 1500, loss is 3.589020357131958 and perplexity is 36.198596853662764
At time: 552.8446927070618 and batch: 1550, loss is 3.6172795581817625 and perplexity is 37.23613117996017
At time: 554.0927753448486 and batch: 1600, loss is 3.692292194366455 and perplexity is 40.136742811230874
At time: 555.3409657478333 and batch: 1650, loss is 3.649283971786499 and perplexity is 38.4471269631938
At time: 556.5916304588318 and batch: 1700, loss is 3.638176212310791 and perplexity is 38.02242861458766
At time: 557.8415102958679 and batch: 1750, loss is 3.6265872716903687 and perplexity is 37.584332385864705
At time: 559.0921499729156 and batch: 1800, loss is 3.5863311862945557 and perplexity is 36.10138341300819
At time: 560.3373746871948 and batch: 1850, loss is 3.614556546211243 and perplexity is 37.13487467292801
At time: 561.584566116333 and batch: 1900, loss is 3.711111149787903 and perplexity is 40.89922645494625
At time: 562.8336596488953 and batch: 1950, loss is 3.6485629653930665 and perplexity is 38.41941632981659
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342285724018895 and perplexity of 76.88307213673514
finished 11 epochs...
Completing Train Step...
At time: 566.7632465362549 and batch: 50, loss is 3.843027033805847 and perplexity is 46.66652199390804
At time: 567.9866836071014 and batch: 100, loss is 3.8295227479934693 and perplexity is 46.040560040402006
At time: 569.2087092399597 and batch: 150, loss is 3.786500644683838 and perplexity is 44.101802061206634
At time: 570.4313366413116 and batch: 200, loss is 3.796166977882385 and perplexity is 44.530171821508404
At time: 571.6628863811493 and batch: 250, loss is 3.7996408557891845 and perplexity is 44.68513320420977
At time: 572.8949871063232 and batch: 300, loss is 3.7903765630722046 and perplexity is 44.273068740203094
At time: 574.1293721199036 and batch: 350, loss is 3.800621566772461 and perplexity is 44.72897790110608
At time: 575.3720188140869 and batch: 400, loss is 3.746646294593811 and perplexity is 42.37871767492057
At time: 576.6210691928864 and batch: 450, loss is 3.7971342515945437 and perplexity is 44.57326552445232
At time: 577.8783187866211 and batch: 500, loss is 3.8101224517822265 and perplexity is 45.155967956542774
At time: 579.1282894611359 and batch: 550, loss is 3.7885182428359987 and perplexity is 44.19087159860469
At time: 580.378170967102 and batch: 600, loss is 3.7570662260055543 and perplexity is 42.822609652099835
At time: 581.6290295124054 and batch: 650, loss is 3.7818605136871337 and perplexity is 43.89763796285067
At time: 582.8789482116699 and batch: 700, loss is 3.8174999856948855 and perplexity is 45.490339543766325
At time: 584.1307253837585 and batch: 750, loss is 3.774946427345276 and perplexity is 43.59517274402562
At time: 585.3812210559845 and batch: 800, loss is 3.762017297744751 and perplexity is 43.035153189522624
At time: 586.6333491802216 and batch: 850, loss is 3.75445104598999 and perplexity is 42.71076712703404
At time: 587.8845534324646 and batch: 900, loss is 3.72995219707489 and perplexity is 41.6771158283632
At time: 589.1348073482513 and batch: 950, loss is 3.8257010221481322 and perplexity is 45.86494143898682
At time: 590.3851156234741 and batch: 1000, loss is 3.791044011116028 and perplexity is 44.302628577058066
At time: 591.636666059494 and batch: 1050, loss is 3.7495718479156492 and perplexity is 42.50288040697867
At time: 592.888286113739 and batch: 1100, loss is 3.766162657737732 and perplexity is 43.21391966154323
At time: 594.1785485744476 and batch: 1150, loss is 3.73497588634491 and perplexity is 41.88701550188007
At time: 595.4286525249481 and batch: 1200, loss is 3.767526779174805 and perplexity is 43.27290892084267
At time: 596.6776494979858 and batch: 1250, loss is 3.759844331741333 and perplexity is 42.941740792427574
At time: 597.928501367569 and batch: 1300, loss is 3.7513534307479857 and perplexity is 42.57867030197782
At time: 599.1785531044006 and batch: 1350, loss is 3.6597767066955567 and perplexity is 38.85266636240684
At time: 600.4312701225281 and batch: 1400, loss is 3.6735240030288696 and perplexity is 39.390473708802524
At time: 601.6816985607147 and batch: 1450, loss is 3.598442220687866 and perplexity is 36.54126685418734
At time: 602.9325895309448 and batch: 1500, loss is 3.5777320671081543 and perplexity is 35.79227425225345
At time: 604.1842873096466 and batch: 1550, loss is 3.606738634109497 and perplexity is 36.845689372365754
At time: 605.4357256889343 and batch: 1600, loss is 3.684122486114502 and perplexity is 39.810173138138104
At time: 606.6842660903931 and batch: 1650, loss is 3.641566762924194 and perplexity is 38.15156438021437
At time: 607.93732213974 and batch: 1700, loss is 3.632107558250427 and perplexity is 37.79238239028964
At time: 609.1884467601776 and batch: 1750, loss is 3.6212335443496704 and perplexity is 37.38365378656772
At time: 610.4401607513428 and batch: 1800, loss is 3.5820033502578736 and perplexity is 35.945480150120055
At time: 611.689740896225 and batch: 1850, loss is 3.6110141849517823 and perplexity is 37.003562246849754
At time: 612.9395687580109 and batch: 1900, loss is 3.707822151184082 and perplexity is 40.76492992784648
At time: 614.1962337493896 and batch: 1950, loss is 3.644530291557312 and perplexity is 38.264795332366894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343934241006541 and perplexity of 77.00991971368083
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 618.1138083934784 and batch: 50, loss is 3.8394498109817503 and perplexity is 46.49988367520795
At time: 619.3217098712921 and batch: 100, loss is 3.847918210029602 and perplexity is 46.89533530367042
At time: 620.5389053821564 and batch: 150, loss is 3.8123805475234986 and perplexity is 45.25804966724037
At time: 621.7830078601837 and batch: 200, loss is 3.8264173221588136 and perplexity is 45.89780626616229
At time: 623.031711101532 and batch: 250, loss is 3.8414302110671996 and perplexity is 46.59206329494786
At time: 624.2811284065247 and batch: 300, loss is 3.838198447227478 and perplexity is 46.44173179836276
At time: 625.5532104969025 and batch: 350, loss is 3.852242512702942 and perplexity is 47.098564022045224
At time: 626.7951483726501 and batch: 400, loss is 3.794678454399109 and perplexity is 44.46393692336814
At time: 628.0369427204132 and batch: 450, loss is 3.843085675239563 and perplexity is 46.669258665904685
At time: 629.2772560119629 and batch: 500, loss is 3.855576376914978 and perplexity is 47.25584627223108
At time: 630.523191690445 and batch: 550, loss is 3.8394917345046995 and perplexity is 46.501833155012584
At time: 631.7715187072754 and batch: 600, loss is 3.8064191341400146 and perplexity is 44.98905032902235
At time: 633.0191442966461 and batch: 650, loss is 3.8214740562438965 and perplexity is 45.67148105859051
At time: 634.2698678970337 and batch: 700, loss is 3.8520120573043823 and perplexity is 47.087711154300955
At time: 635.5186800956726 and batch: 750, loss is 3.8080061149597166 and perplexity is 45.060503771616226
At time: 636.7681257724762 and batch: 800, loss is 3.791183886528015 and perplexity is 44.308825858895965
At time: 638.025963306427 and batch: 850, loss is 3.784781742095947 and perplexity is 44.026060474366794
At time: 639.2742249965668 and batch: 900, loss is 3.7581106328964236 and perplexity is 42.86735724398465
At time: 640.5229761600494 and batch: 950, loss is 3.864633779525757 and perplexity is 47.68580571616528
At time: 641.7704231739044 and batch: 1000, loss is 3.8273726177215575 and perplexity is 45.94167318642913
At time: 643.0192503929138 and batch: 1050, loss is 3.7807397556304934 and perplexity is 43.848466891020756
At time: 644.2674040794373 and batch: 1100, loss is 3.7995963764190672 and perplexity is 44.68314568183344
At time: 645.5179402828217 and batch: 1150, loss is 3.780088658332825 and perplexity is 43.819926564993935
At time: 646.7678709030151 and batch: 1200, loss is 3.809513282775879 and perplexity is 45.128468717104596
At time: 648.0179762840271 and batch: 1250, loss is 3.7886226081848147 and perplexity is 44.1954838350082
At time: 649.265289068222 and batch: 1300, loss is 3.768438811302185 and perplexity is 43.312393206755395
At time: 650.514096736908 and batch: 1350, loss is 3.660608215332031 and perplexity is 38.88498612525604
At time: 651.7630248069763 and batch: 1400, loss is 3.672303557395935 and perplexity is 39.34242910106473
At time: 653.0120191574097 and batch: 1450, loss is 3.596057481765747 and perplexity is 36.45422929503252
At time: 654.2599809169769 and batch: 1500, loss is 3.578076190948486 and perplexity is 35.80459334664881
At time: 655.507860660553 and batch: 1550, loss is 3.6087652158737185 and perplexity is 36.92043588891946
At time: 656.7562816143036 and batch: 1600, loss is 3.684720973968506 and perplexity is 39.83400617440705
At time: 658.00510597229 and batch: 1650, loss is 3.6339385890960694 and perplexity is 37.861644799629346
At time: 659.2539358139038 and batch: 1700, loss is 3.6159096336364747 and perplexity is 37.185155414333614
At time: 660.5110769271851 and batch: 1750, loss is 3.6057097053527833 and perplexity is 36.8077972804841
At time: 661.7614178657532 and batch: 1800, loss is 3.5680937576293945 and perplexity is 35.44895440530726
At time: 663.010142326355 and batch: 1850, loss is 3.6000421142578123 and perplexity is 36.59977578361479
At time: 664.2657725811005 and batch: 1900, loss is 3.7057876873016355 and perplexity is 40.682079456959954
At time: 665.5136868953705 and batch: 1950, loss is 3.655007314682007 and perplexity is 38.66780395681679
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331571641079215 and perplexity of 76.06373757215519
finished 13 epochs...
Completing Train Step...
At time: 669.4172465801239 and batch: 50, loss is 3.863280167579651 and perplexity is 47.621301306706904
At time: 670.6683986186981 and batch: 100, loss is 3.849771647453308 and perplexity is 46.982333471044186
At time: 671.8880615234375 and batch: 150, loss is 3.802085280418396 and perplexity is 44.7944962547853
At time: 673.1085095405579 and batch: 200, loss is 3.804993019104004 and perplexity is 44.92493649560945
At time: 674.3406147956848 and batch: 250, loss is 3.814834041595459 and perplexity is 45.369226353707795
At time: 675.5811679363251 and batch: 300, loss is 3.808767776489258 and perplexity is 45.09483769759626
At time: 676.8264875411987 and batch: 350, loss is 3.82308171749115 and perplexity is 45.74496438111111
At time: 678.078164100647 and batch: 400, loss is 3.766268334388733 and perplexity is 43.21848660515509
At time: 679.3279809951782 and batch: 450, loss is 3.8175305271148683 and perplexity is 45.49172890454791
At time: 680.5766925811768 and batch: 500, loss is 3.831069197654724 and perplexity is 46.11181453042098
At time: 681.8253157138824 and batch: 550, loss is 3.8145181560516357 and perplexity is 45.354897134284
At time: 683.0749666690826 and batch: 600, loss is 3.7862552547454835 and perplexity is 44.09098125043086
At time: 684.3233215808868 and batch: 650, loss is 3.802053623199463 and perplexity is 44.793078208056194
At time: 685.5720982551575 and batch: 700, loss is 3.8358458137512206 and perplexity is 46.33259984951272
At time: 686.8219854831696 and batch: 750, loss is 3.7935831785202025 and perplexity is 44.41526330616006
At time: 688.1119868755341 and batch: 800, loss is 3.776771321296692 and perplexity is 43.67480194640333
At time: 689.3628458976746 and batch: 850, loss is 3.769736313819885 and perplexity is 43.36862762024604
At time: 690.6111836433411 and batch: 900, loss is 3.7428306436538694 and perplexity is 42.21732338893441
At time: 691.8608109951019 and batch: 950, loss is 3.848891429901123 and perplexity is 46.94099699169661
At time: 693.1111567020416 and batch: 1000, loss is 3.8104502058029173 and perplexity is 45.17077043225167
At time: 694.360996723175 and batch: 1050, loss is 3.765089635848999 and perplexity is 43.16757504868713
At time: 695.6110684871674 and batch: 1100, loss is 3.7843601942062377 and perplexity is 44.00750529270522
At time: 696.8632218837738 and batch: 1150, loss is 3.765652394294739 and perplexity is 43.191874802932546
At time: 698.1129064559937 and batch: 1200, loss is 3.796352424621582 and perplexity is 44.5384305624232
At time: 699.3630940914154 and batch: 1250, loss is 3.777534370422363 and perplexity is 43.70814068377199
At time: 700.6130442619324 and batch: 1300, loss is 3.758583650588989 and perplexity is 42.887639058845046
At time: 701.8626754283905 and batch: 1350, loss is 3.6530724382400512 and perplexity is 38.593058868452786
At time: 703.1111252307892 and batch: 1400, loss is 3.665964698791504 and perplexity is 39.093831749976836
At time: 704.36034989357 and batch: 1450, loss is 3.591364207267761 and perplexity is 36.283540448454794
At time: 705.6094388961792 and batch: 1500, loss is 3.5762011337280275 and perplexity is 35.737520587650536
At time: 706.8591151237488 and batch: 1550, loss is 3.607856764793396 and perplexity is 36.88691070934864
At time: 708.1107103824615 and batch: 1600, loss is 3.684961643218994 and perplexity is 39.84359414853598
At time: 709.3660478591919 and batch: 1650, loss is 3.6351191091537474 and perplexity is 37.906367623633464
At time: 710.6160206794739 and batch: 1700, loss is 3.618637595176697 and perplexity is 37.286733575836585
At time: 711.8664343357086 and batch: 1750, loss is 3.6103726625442505 and perplexity is 36.9798312453084
At time: 713.120808839798 and batch: 1800, loss is 3.5737252044677734 and perplexity is 35.64914646392414
At time: 714.3744285106659 and batch: 1850, loss is 3.6061551141738892 and perplexity is 36.82419544975183
At time: 715.6246716976166 and batch: 1900, loss is 3.7125520658493043 and perplexity is 40.958201285930855
At time: 716.8736798763275 and batch: 1950, loss is 3.661034336090088 and perplexity is 38.90155935586879
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330299554869186 and perplexity of 75.96703945771513
finished 14 epochs...
Completing Train Step...
At time: 720.7565822601318 and batch: 50, loss is 3.8596486949920656 and perplexity is 47.44867948184445
At time: 721.9852492809296 and batch: 100, loss is 3.8439758586883546 and perplexity is 46.71082136400481
At time: 723.2070474624634 and batch: 150, loss is 3.7952323961257934 and perplexity is 44.488574176533945
At time: 724.4358673095703 and batch: 200, loss is 3.796389145851135 and perplexity is 44.540066098385076
At time: 725.6736998558044 and batch: 250, loss is 3.805419545173645 and perplexity is 44.9441022392559
At time: 726.9104888439178 and batch: 300, loss is 3.7985758495330813 and perplexity is 44.63756859059381
At time: 728.1522591114044 and batch: 350, loss is 3.813048048019409 and perplexity is 45.288269522599364
At time: 729.3988931179047 and batch: 400, loss is 3.756064476966858 and perplexity is 42.77973362314228
At time: 730.6475129127502 and batch: 450, loss is 3.8077546644210813 and perplexity is 45.04917470808093
At time: 731.9006502628326 and batch: 500, loss is 3.8211728525161743 and perplexity is 45.657726709779624
At time: 733.1490652561188 and batch: 550, loss is 3.804233388900757 and perplexity is 44.89082311538581
At time: 734.3961274623871 and batch: 600, loss is 3.777176456451416 and perplexity is 43.69249972880227
At time: 735.6435751914978 and batch: 650, loss is 3.793207759857178 and perplexity is 44.39859211692536
At time: 736.8908953666687 and batch: 700, loss is 3.8280261993408202 and perplexity is 45.97170963414781
At time: 738.1408224105835 and batch: 750, loss is 3.7863216400146484 and perplexity is 44.09390833924562
At time: 739.3909709453583 and batch: 800, loss is 3.7696008396148684 and perplexity is 43.36275268785639
At time: 740.6374316215515 and batch: 850, loss is 3.762304120063782 and perplexity is 43.04749840231695
At time: 741.8850297927856 and batch: 900, loss is 3.7352522087097166 and perplexity is 41.89859142032717
At time: 743.1314535140991 and batch: 950, loss is 3.84095760345459 and perplexity is 46.57004873368185
At time: 744.3780164718628 and batch: 1000, loss is 3.802501721382141 and perplexity is 44.81315440271502
At time: 745.6243793964386 and batch: 1050, loss is 3.7579459857940676 and perplexity is 42.86029983883536
At time: 746.8782503604889 and batch: 1100, loss is 3.777644352912903 and perplexity is 43.71294807830102
At time: 748.1255316734314 and batch: 1150, loss is 3.7593335103988648 and perplexity is 42.91981083636973
At time: 749.373060464859 and batch: 1200, loss is 3.790729479789734 and perplexity is 44.2886962037322
At time: 750.6410193443298 and batch: 1250, loss is 3.7724534559249876 and perplexity is 43.486626581769386
At time: 751.8879745006561 and batch: 1300, loss is 3.75396222114563 and perplexity is 42.6898941449724
At time: 753.134982585907 and batch: 1350, loss is 3.648989562988281 and perplexity is 38.43580945681811
At time: 754.3825538158417 and batch: 1400, loss is 3.662274980545044 and perplexity is 38.94985231077177
At time: 755.6308815479279 and batch: 1450, loss is 3.588196210861206 and perplexity is 36.16877620503544
At time: 756.8856344223022 and batch: 1500, loss is 3.573651924133301 and perplexity is 35.64653417826336
At time: 758.1329891681671 and batch: 1550, loss is 3.605651168823242 and perplexity is 36.80564274283143
At time: 759.3797237873077 and batch: 1600, loss is 3.6835354471206667 and perplexity is 39.786809872399644
At time: 760.62619805336 and batch: 1650, loss is 3.6339705324172975 and perplexity is 37.862854245628164
At time: 761.8727655410767 and batch: 1700, loss is 3.618357067108154 and perplexity is 37.276275067505445
At time: 763.1211202144623 and batch: 1750, loss is 3.6112089729309083 and perplexity is 37.01077079800704
At time: 764.3687498569489 and batch: 1800, loss is 3.574931116104126 and perplexity is 35.69216211579574
At time: 765.6227121353149 and batch: 1850, loss is 3.6075555658340455 and perplexity is 36.87580208326661
At time: 766.8699481487274 and batch: 1900, loss is 3.7140508031845094 and perplexity is 41.01963289480477
At time: 768.117015838623 and batch: 1950, loss is 3.662108120918274 and perplexity is 38.94335369514582
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330172374636628 and perplexity of 75.95737856632034
finished 15 epochs...
Completing Train Step...
At time: 772.0161666870117 and batch: 50, loss is 3.854959545135498 and perplexity is 47.226706352622315
At time: 773.2641332149506 and batch: 100, loss is 3.838426294326782 and perplexity is 46.45231461782626
At time: 774.4863052368164 and batch: 150, loss is 3.7893637895584105 and perplexity is 44.228252846814215
At time: 775.7097098827362 and batch: 200, loss is 3.7896546077728273 and perplexity is 44.241117098822635
At time: 776.945188999176 and batch: 250, loss is 3.7982604265213014 and perplexity is 44.62349109457025
At time: 778.1872205734253 and batch: 300, loss is 3.791095504760742 and perplexity is 44.30490993961124
At time: 779.4366292953491 and batch: 350, loss is 3.8056607341766355 and perplexity is 44.954943569817594
At time: 780.7080550193787 and batch: 400, loss is 3.748661141395569 and perplexity is 42.46419037697521
At time: 781.9579477310181 and batch: 450, loss is 3.8007486248016358 and perplexity is 44.73466143794705
At time: 783.2083632946014 and batch: 500, loss is 3.814198598861694 and perplexity is 45.34040596630746
At time: 784.4578948020935 and batch: 550, loss is 3.7969965028762815 and perplexity is 44.56712603712053
At time: 785.7059371471405 and batch: 600, loss is 3.7706142473220825 and perplexity is 43.406719109828956
At time: 786.9541053771973 and batch: 650, loss is 3.7867534351348877 and perplexity is 44.11295198487953
At time: 788.2041628360748 and batch: 700, loss is 3.8221720314025878 and perplexity is 45.70336974529103
At time: 789.4538578987122 and batch: 750, loss is 3.780771269798279 and perplexity is 43.84984876073762
At time: 790.7042505741119 and batch: 800, loss is 3.7640573453903197 and perplexity is 43.12303656512097
At time: 791.9541020393372 and batch: 850, loss is 3.7566041851043703 and perplexity is 42.802828425164996
At time: 793.2041344642639 and batch: 900, loss is 3.7293792724609376 and perplexity is 41.653244821663186
At time: 794.4530675411224 and batch: 950, loss is 3.8348216009140015 and perplexity is 46.28516969939565
At time: 795.7020833492279 and batch: 1000, loss is 3.7965085887908936 and perplexity is 44.54538641254756
At time: 796.9512603282928 and batch: 1050, loss is 3.752515683174133 and perplexity is 42.62818623427068
At time: 798.2000615596771 and batch: 1100, loss is 3.77253812789917 and perplexity is 43.490308836182265
At time: 799.450032711029 and batch: 1150, loss is 3.75460551738739 and perplexity is 42.71736522851204
At time: 800.6991286277771 and batch: 1200, loss is 3.786480927467346 and perplexity is 44.10093250500035
At time: 801.952309846878 and batch: 1250, loss is 3.768542137145996 and perplexity is 43.31686872754545
At time: 803.2033185958862 and batch: 1300, loss is 3.750282073020935 and perplexity is 42.533077741873996
At time: 804.4523174762726 and batch: 1350, loss is 3.645402641296387 and perplexity is 38.29819018046658
At time: 805.708137512207 and batch: 1400, loss is 3.6589476585388185 and perplexity is 38.820468979409405
At time: 806.9565181732178 and batch: 1450, loss is 3.585060229301453 and perplexity is 36.05552925280401
At time: 808.2053582668304 and batch: 1500, loss is 3.5707059955596923 and perplexity is 35.54167656203524
At time: 809.4551196098328 and batch: 1550, loss is 3.602852201461792 and perplexity is 36.70276898738027
At time: 810.7028951644897 and batch: 1600, loss is 3.681566209793091 and perplexity is 39.70853729518854
At time: 811.9526567459106 and batch: 1650, loss is 3.631645903587341 and perplexity is 37.77493938736165
At time: 813.202784538269 and batch: 1700, loss is 3.6168476295471192 and perplexity is 37.22005130159015
At time: 814.4521405696869 and batch: 1750, loss is 3.610584325790405 and perplexity is 36.98765934486328
At time: 815.7011415958405 and batch: 1800, loss is 3.574522829055786 and perplexity is 35.6775924427834
At time: 816.9537272453308 and batch: 1850, loss is 3.607435493469238 and perplexity is 36.871374584321764
At time: 818.2019984722137 and batch: 1900, loss is 3.7139539527893066 and perplexity is 41.01566031952369
At time: 819.4503347873688 and batch: 1950, loss is 3.661727313995361 and perplexity is 38.92852661976292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330423044603925 and perplexity of 75.97642118652831
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 823.3749701976776 and batch: 50, loss is 3.857236466407776 and perplexity is 47.334360358274125
At time: 824.5959119796753 and batch: 100, loss is 3.851739277839661 and perplexity is 47.07486834536424
At time: 825.8250141143799 and batch: 150, loss is 3.8081797695159914 and perplexity is 45.06832941286366
At time: 827.0460484027863 and batch: 200, loss is 3.808043293952942 and perplexity is 45.062179106924134
At time: 828.2812366485596 and batch: 250, loss is 3.8168259286880493 and perplexity is 45.45968679366458
At time: 829.5212831497192 and batch: 300, loss is 3.811004681587219 and perplexity is 45.19582347562569
At time: 830.7633812427521 and batch: 350, loss is 3.8316445636749266 and perplexity is 46.13835333566291
At time: 832.0039527416229 and batch: 400, loss is 3.7831044960021973 and perplexity is 43.952279827859904
At time: 833.2449736595154 and batch: 450, loss is 3.8384649181365966 and perplexity is 46.4541088178407
At time: 834.4848942756653 and batch: 500, loss is 3.853405404090881 and perplexity is 47.153366394958674
At time: 835.725811958313 and batch: 550, loss is 3.8354045152664185 and perplexity is 46.3121578542447
At time: 836.9741914272308 and batch: 600, loss is 3.8021220922470094 and perplexity is 44.796145252455375
At time: 838.2220249176025 and batch: 650, loss is 3.8079066371917722 and perplexity is 45.05602147622664
At time: 839.4748303890228 and batch: 700, loss is 3.8409311723709108 and perplexity is 46.56881785309366
At time: 840.7235898971558 and batch: 750, loss is 3.799336462020874 and perplexity is 44.6715333980794
At time: 841.9715566635132 and batch: 800, loss is 3.7831165742874147 and perplexity is 43.95281069923762
At time: 843.2410645484924 and batch: 850, loss is 3.7776741695404055 and perplexity is 43.71425147042219
At time: 844.4903695583344 and batch: 900, loss is 3.74377281665802 and perplexity is 42.257118155172414
At time: 845.736828327179 and batch: 950, loss is 3.8560517692565917 and perplexity is 47.27831668035215
At time: 846.985570192337 and batch: 1000, loss is 3.8179535245895386 and perplexity is 45.510975861413016
At time: 848.2352056503296 and batch: 1050, loss is 3.7721930074691774 and perplexity is 43.47530203182256
At time: 849.484979391098 and batch: 1100, loss is 3.786104860305786 and perplexity is 44.08435071062064
At time: 850.7321798801422 and batch: 1150, loss is 3.768936233520508 and perplexity is 43.33394311272184
At time: 851.9801633358002 and batch: 1200, loss is 3.8032009172439576 and perplexity is 44.84449853139393
At time: 853.2330961227417 and batch: 1250, loss is 3.790726022720337 and perplexity is 44.288543094900575
At time: 854.4850993156433 and batch: 1300, loss is 3.7742597532272337 and perplexity is 43.56524734290579
At time: 855.7337725162506 and batch: 1350, loss is 3.6628605365753173 and perplexity is 38.972666310456276
At time: 856.9816882610321 and batch: 1400, loss is 3.675442018508911 and perplexity is 39.466097747997395
At time: 858.2293858528137 and batch: 1450, loss is 3.600820746421814 and perplexity is 36.62828464375255
At time: 859.4779300689697 and batch: 1500, loss is 3.583008370399475 and perplexity is 35.981624241398
At time: 860.732625246048 and batch: 1550, loss is 3.6174526596069336 and perplexity is 37.24257736524111
At time: 861.9827153682709 and batch: 1600, loss is 3.6913699293136597 and perplexity is 40.09974316036809
At time: 863.2377440929413 and batch: 1650, loss is 3.632861657142639 and perplexity is 37.820892332290995
At time: 864.4868650436401 and batch: 1700, loss is 3.6069909858703615 and perplexity is 36.85498862025058
At time: 865.7350957393646 and batch: 1750, loss is 3.599459342956543 and perplexity is 36.578452698499724
At time: 866.9833924770355 and batch: 1800, loss is 3.563089337348938 and perplexity is 35.27199609515354
At time: 868.2306563854218 and batch: 1850, loss is 3.595869541168213 and perplexity is 36.447378709167936
At time: 869.4796528816223 and batch: 1900, loss is 3.703003568649292 and perplexity is 40.56897324434599
At time: 870.7355737686157 and batch: 1950, loss is 3.659221453666687 and perplexity is 38.831099289874736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3280125817587205 and perplexity of 75.79350339298686
finished 17 epochs...
Completing Train Step...
At time: 874.6353237628937 and batch: 50, loss is 3.8687350130081177 and perplexity is 47.88177792841147
At time: 875.8547444343567 and batch: 100, loss is 3.85596209526062 and perplexity is 47.27407723485947
At time: 877.0790479183197 and batch: 150, loss is 3.806990451812744 and perplexity is 45.014760712253455
At time: 878.3010516166687 and batch: 200, loss is 3.8031491470336913 and perplexity is 44.842176982369736
At time: 879.5321772098541 and batch: 250, loss is 3.8086786556243895 and perplexity is 45.09081898573775
At time: 880.772501707077 and batch: 300, loss is 3.7999119091033937 and perplexity is 44.69724689931508
At time: 882.020051240921 and batch: 350, loss is 3.8192011642456056 and perplexity is 45.56779259571935
At time: 883.2660644054413 and batch: 400, loss is 3.7700288486480713 and perplexity is 43.38131631012696
At time: 884.5130069255829 and batch: 450, loss is 3.8255764627456665 and perplexity is 45.85922888507059
At time: 885.7588088512421 and batch: 500, loss is 3.8417305374145507 and perplexity is 46.60605822055004
At time: 887.0048451423645 and batch: 550, loss is 3.823257336616516 and perplexity is 45.752998777221784
At time: 888.2517304420471 and batch: 600, loss is 3.7930139398574827 and perplexity is 44.38998761570394
At time: 889.4988784790039 and batch: 650, loss is 3.7997719860076904 and perplexity is 44.690993159691025
At time: 890.7464554309845 and batch: 700, loss is 3.8346970891952514 and perplexity is 46.27940701213224
At time: 891.9924573898315 and batch: 750, loss is 3.79471125125885 and perplexity is 44.465395224784686
At time: 893.2383596897125 and batch: 800, loss is 3.7799035835266115 and perplexity is 43.81181735100539
At time: 894.4842216968536 and batch: 850, loss is 3.774697113037109 and perplexity is 43.58430519846712
At time: 895.7307028770447 and batch: 900, loss is 3.7415656995773316 and perplexity is 42.16395459717102
At time: 896.9774653911591 and batch: 950, loss is 3.8537732219696044 and perplexity is 47.170713436241115
At time: 898.2228767871857 and batch: 1000, loss is 3.814522180557251 and perplexity is 45.3550796656895
At time: 899.4687311649323 and batch: 1050, loss is 3.7682800769805906 and perplexity is 43.30551858903641
At time: 900.7144720554352 and batch: 1100, loss is 3.7813798427581786 and perplexity is 43.876542714774544
At time: 901.9596908092499 and batch: 1150, loss is 3.764574055671692 and perplexity is 43.1453244391691
At time: 903.2062861919403 and batch: 1200, loss is 3.7981280374526976 and perplexity is 44.61758382318409
At time: 904.4525620937347 and batch: 1250, loss is 3.7851405477523805 and perplexity is 44.04186010822497
At time: 905.6961057186127 and batch: 1300, loss is 3.7689633655548094 and perplexity is 43.33511886670302
At time: 906.942138671875 and batch: 1350, loss is 3.6583181190490723 and perplexity is 38.796037652225905
At time: 908.196888923645 and batch: 1400, loss is 3.671534299850464 and perplexity is 39.31217627821955
At time: 909.4432709217072 and batch: 1450, loss is 3.5969862079620363 and perplexity is 36.488101019088454
At time: 910.692554473877 and batch: 1500, loss is 3.5813519620895384 and perplexity is 35.92207331394085
At time: 911.9420940876007 and batch: 1550, loss is 3.6164207887649535 and perplexity is 37.20416765591537
At time: 913.1894969940186 and batch: 1600, loss is 3.6906200504302977 and perplexity is 40.06968448133677
At time: 914.4359338283539 and batch: 1650, loss is 3.6330777168273927 and perplexity is 37.82906478520242
At time: 915.6830427646637 and batch: 1700, loss is 3.6088119316101075 and perplexity is 36.92216069455728
At time: 916.9287462234497 and batch: 1750, loss is 3.602314772605896 and perplexity is 36.68304915971201
At time: 918.1749730110168 and batch: 1800, loss is 3.5668498039245606 and perplexity is 35.40488496299814
At time: 919.4200239181519 and batch: 1850, loss is 3.6008191537857055 and perplexity is 36.6282263082703
At time: 920.6652500629425 and batch: 1900, loss is 3.7080740928649902 and perplexity is 40.7752016066923
At time: 921.9142067432404 and batch: 1950, loss is 3.6634027671813967 and perplexity is 38.99380421322134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327231615643169 and perplexity of 75.73433434257701
finished 18 epochs...
Completing Train Step...
At time: 925.8465089797974 and batch: 50, loss is 3.869194130897522 and perplexity is 47.90376635648899
At time: 927.0574126243591 and batch: 100, loss is 3.854802827835083 and perplexity is 47.21930569061627
At time: 928.2794740200043 and batch: 150, loss is 3.805027599334717 and perplexity is 44.926490037139
At time: 929.5084862709045 and batch: 200, loss is 3.800143527984619 and perplexity is 44.707600824671765
At time: 930.7377264499664 and batch: 250, loss is 3.804867424964905 and perplexity is 44.91929454119183
At time: 931.9803650379181 and batch: 300, loss is 3.7954904985427858 and perplexity is 44.50005826702946
At time: 933.2300448417664 and batch: 350, loss is 3.8143404960632323 and perplexity is 45.34684009951263
At time: 934.4801187515259 and batch: 400, loss is 3.7649957942962646 and perplexity is 43.163524326482786
At time: 935.7535374164581 and batch: 450, loss is 3.8206369256973267 and perplexity is 45.63326406522739
At time: 937.0022375583649 and batch: 500, loss is 3.8367450284957885 and perplexity is 46.37428154404011
At time: 938.2462174892426 and batch: 550, loss is 3.8181747722625734 and perplexity is 45.5210461728953
At time: 939.4892427921295 and batch: 600, loss is 3.7887927532196044 and perplexity is 44.20300411689402
At time: 940.7310678958893 and batch: 650, loss is 3.7958284330368044 and perplexity is 44.51509891293712
At time: 941.9727559089661 and batch: 700, loss is 3.8313080739974974 and perplexity is 46.12283086775345
At time: 943.2147443294525 and batch: 750, loss is 3.7918515586853028 and perplexity is 44.33841950657198
At time: 944.4633369445801 and batch: 800, loss is 3.7770923233032225 and perplexity is 43.6888238958795
At time: 945.7132842540741 and batch: 850, loss is 3.7718641328811646 and perplexity is 43.461006460632
At time: 946.9639885425568 and batch: 900, loss is 3.7389734888076784 and perplexity is 42.054798279188084
At time: 948.2150135040283 and batch: 950, loss is 3.851074652671814 and perplexity is 47.04359159789691
At time: 949.4685626029968 and batch: 1000, loss is 3.8117417383193968 and perplexity is 45.229147640976294
At time: 950.7222497463226 and batch: 1050, loss is 3.7654286861419677 and perplexity is 43.182213509101054
At time: 951.9721369743347 and batch: 1100, loss is 3.7784241008758546 and perplexity is 43.74704645286106
At time: 953.222259759903 and batch: 1150, loss is 3.761917200088501 and perplexity is 43.03084568714104
At time: 954.4711377620697 and batch: 1200, loss is 3.7955154848098753 and perplexity is 44.501170171261926
At time: 955.7211625576019 and batch: 1250, loss is 3.7828202390670778 and perplexity is 43.93978786305245
At time: 956.971896648407 and batch: 1300, loss is 3.766950635910034 and perplexity is 43.24798470646945
At time: 958.2220973968506 and batch: 1350, loss is 3.656667013168335 and perplexity is 38.7320341391377
At time: 959.4720447063446 and batch: 1400, loss is 3.6701781940460205 and perplexity is 39.25890093944598
At time: 960.7219257354736 and batch: 1450, loss is 3.595872130393982 and perplexity is 36.44747307978227
At time: 961.9723889827728 and batch: 1500, loss is 3.5812298583984377 and perplexity is 35.917687363973016
At time: 963.2307362556458 and batch: 1550, loss is 3.616488842964172 and perplexity is 37.206699641907946
At time: 964.4798908233643 and batch: 1600, loss is 3.690798993110657 and perplexity is 40.076855299642595
At time: 965.7290489673615 and batch: 1650, loss is 3.633557858467102 and perplexity is 37.84723245557555
At time: 966.9791052341461 and batch: 1700, loss is 3.6097849798202515 and perplexity is 36.95810522197871
At time: 968.2301690578461 and batch: 1750, loss is 3.6037005758285523 and perplexity is 36.733919887722585
At time: 969.4802443981171 and batch: 1800, loss is 3.568469605445862 and perplexity is 35.46228032151793
At time: 970.7309737205505 and batch: 1850, loss is 3.6026697969436645 and perplexity is 36.69607484702846
At time: 971.9821636676788 and batch: 1900, loss is 3.7097014713287355 and perplexity is 40.84161231466323
At time: 973.2325518131256 and batch: 1950, loss is 3.6645511388778687 and perplexity is 39.038609315849506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.326812602198401 and perplexity of 75.70260728575282
finished 19 epochs...
Completing Train Step...
At time: 977.13600730896 and batch: 50, loss is 3.8680542945861816 and perplexity is 47.8491950112547
At time: 978.3778817653656 and batch: 100, loss is 3.8530157136917116 and perplexity is 47.13499476064328
At time: 979.5983564853668 and batch: 150, loss is 3.802961664199829 and perplexity is 44.83377063200035
At time: 980.8258323669434 and batch: 200, loss is 3.7976275491714477 and perplexity is 44.59525883250703
At time: 982.0608332157135 and batch: 250, loss is 3.8020227575302123 and perplexity is 44.79169566105624
At time: 983.3028478622437 and batch: 300, loss is 3.7923879337310793 and perplexity is 44.362207907546484
At time: 984.5498402118683 and batch: 350, loss is 3.811112790107727 and perplexity is 45.200709793356296
At time: 985.7971343994141 and batch: 400, loss is 3.7617557144165037 and perplexity is 43.02389738314952
At time: 987.0456507205963 and batch: 450, loss is 3.8174668455123903 and perplexity is 45.48883201059218
At time: 988.2933447360992 and batch: 500, loss is 3.8335009670257567 and perplexity is 46.22408428038281
At time: 989.5413191318512 and batch: 550, loss is 3.8149935388565064 and perplexity is 45.376463198160145
At time: 990.7902457714081 and batch: 600, loss is 3.7860174798965454 and perplexity is 44.08049877030895
At time: 992.0369758605957 and batch: 650, loss is 3.7931915378570555 and perplexity is 44.39787188880039
At time: 993.2850391864777 and batch: 700, loss is 3.828942370414734 and perplexity is 46.01384688425043
At time: 994.5348093509674 and batch: 750, loss is 3.7897603940963744 and perplexity is 44.24579745150442
At time: 995.781772851944 and batch: 800, loss is 3.774980163574219 and perplexity is 43.596643505562945
At time: 997.0346822738647 and batch: 850, loss is 3.7696559906005858 and perplexity is 43.36514425235851
At time: 998.3111193180084 and batch: 900, loss is 3.736802544593811 and perplexity is 41.963598688628856
At time: 999.5581755638123 and batch: 950, loss is 3.8488413667678834 and perplexity is 46.938647037133336
At time: 1000.8069911003113 and batch: 1000, loss is 3.8095747947692873 and perplexity is 45.13124474455346
At time: 1002.0558400154114 and batch: 1050, loss is 3.7632592058181764 and perplexity is 43.08863209477836
At time: 1003.3039422035217 and batch: 1100, loss is 3.776291637420654 and perplexity is 43.65385687202934
At time: 1004.5519332885742 and batch: 1150, loss is 3.7599572801589964 and perplexity is 42.94659126802341
At time: 1005.7985186576843 and batch: 1200, loss is 3.7936052465438843 and perplexity is 44.41624347405767
At time: 1007.0477542877197 and batch: 1250, loss is 3.7812733316421507 and perplexity is 43.871869624115014
At time: 1008.2960822582245 and batch: 1300, loss is 3.7656041193008423 and perplexity is 43.18978976576804
At time: 1009.5434694290161 and batch: 1350, loss is 3.6555061674118043 and perplexity is 38.6870983084958
At time: 1010.7912709712982 and batch: 1400, loss is 3.6691836452484132 and perplexity is 39.2198754563117
At time: 1012.0389144420624 and batch: 1450, loss is 3.595071873664856 and perplexity is 36.41831741175627
At time: 1013.2857346534729 and batch: 1500, loss is 3.5809671831130983 and perplexity is 35.90825391421725
At time: 1014.5340692996979 and batch: 1550, loss is 3.6163041973114014 and perplexity is 37.19983022078901
At time: 1015.7877459526062 and batch: 1600, loss is 3.6907181453704836 and perplexity is 40.07361530743316
At time: 1017.0328140258789 and batch: 1650, loss is 3.6336004734039307 and perplexity is 37.84884534736218
At time: 1018.2787170410156 and batch: 1700, loss is 3.610082664489746 and perplexity is 36.969108721022096
At time: 1019.5265324115753 and batch: 1750, loss is 3.6042627239227296 and perplexity is 36.754575596018704
At time: 1020.7770705223083 and batch: 1800, loss is 3.5691382360458372 and perplexity is 35.48599941605834
At time: 1022.0278875827789 and batch: 1850, loss is 3.603420128822327 and perplexity is 36.72361941429913
At time: 1023.2809262275696 and batch: 1900, loss is 3.710264115333557 and perplexity is 40.86459806877131
At time: 1024.5262269973755 and batch: 1950, loss is 3.664843420982361 and perplexity is 39.050021270410596
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.326588049600291 and perplexity of 75.68560997706946
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc433bcbb38>
ELAPSED
5264.997786283493


RESULTS SO FAR:
[{'best_accuracy': -75.2531559304004, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.96225198742506, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7460609200881098, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.7558732386815785, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -73.92024548433339, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.06428528362550812, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.41802598995097096, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -74.73450121070549, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.47589954029325743, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.2146320946900251, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.68560997706946, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.9183464086206847, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.17881090566881874, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.0, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.0, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5499231815338135 and batch: 50, loss is 7.677213354110718 and perplexity is 2158.5961398211034
At time: 2.677471876144409 and batch: 100, loss is 6.826530447006226 and perplexity is 921.9863761212179
At time: 3.782916307449341 and batch: 150, loss is 6.442301387786865 and perplexity is 627.8500648894891
At time: 4.906777381896973 and batch: 200, loss is 6.226354026794434 and perplexity is 505.90759133765715
At time: 6.019363164901733 and batch: 250, loss is 6.052717514038086 and perplexity is 425.2671305896209
At time: 7.138178825378418 and batch: 300, loss is 5.923346328735351 and perplexity is 373.6600133410298
At time: 8.252307176589966 and batch: 350, loss is 5.7933316326141355 and perplexity is 328.1043285360592
At time: 9.366790056228638 and batch: 400, loss is 5.67540225982666 and perplexity is 291.6056161803157
At time: 10.484047651290894 and batch: 450, loss is 5.560018148422241 and perplexity is 259.82755174028085
At time: 11.606881856918335 and batch: 500, loss is 5.509443655014038 and perplexity is 247.01366401928922
At time: 12.72837781906128 and batch: 550, loss is 5.435967416763305 and perplexity is 229.51477735252246
At time: 13.851344347000122 and batch: 600, loss is 5.4210254669189455 and perplexity is 226.11087287570166
At time: 14.974205255508423 and batch: 650, loss is 5.466649160385132 and perplexity is 236.66583336903213
At time: 16.096667766571045 and batch: 700, loss is 5.403304500579834 and perplexity is 222.13926401604786
At time: 17.218987226486206 and batch: 750, loss is 5.330170030593872 and perplexity is 206.47307791192344
At time: 18.34934377670288 and batch: 800, loss is 5.320833215713501 and perplexity is 204.55424882133366
At time: 19.50886607170105 and batch: 850, loss is 5.306341924667358 and perplexity is 201.61136823609692
At time: 20.727623224258423 and batch: 900, loss is 5.300186882019043 and perplexity is 200.37425282091672
At time: 21.97669529914856 and batch: 950, loss is 5.31323395729065 and perplexity is 203.00567966397222
At time: 23.225669860839844 and batch: 1000, loss is 5.272365350723266 and perplexity is 194.87636867922666
At time: 24.475144147872925 and batch: 1050, loss is 5.168893213272095 and perplexity is 175.72024498275954
At time: 25.725167274475098 and batch: 1100, loss is 5.238858795166015 and perplexity is 188.4549139831604
At time: 26.97514510154724 and batch: 1150, loss is 5.132020320892334 and perplexity is 169.3589320303383
At time: 28.22500205039978 and batch: 1200, loss is 5.206283454895019 and perplexity is 182.4148438152397
At time: 29.474524974822998 and batch: 1250, loss is 5.167596311569214 and perplexity is 175.49250081063428
At time: 30.725468397140503 and batch: 1300, loss is 5.174015731811523 and perplexity is 176.62268460393315
At time: 31.976194620132446 and batch: 1350, loss is 5.093324050903321 and perplexity is 162.93055236434162
At time: 33.228957176208496 and batch: 1400, loss is 5.09011399269104 and perplexity is 162.4083743659764
At time: 34.478416204452515 and batch: 1450, loss is 5.045953483581543 and perplexity is 155.39239267990575
At time: 35.728495359420776 and batch: 1500, loss is 4.991707172393799 and perplexity is 147.18748354194534
At time: 36.978458881378174 and batch: 1550, loss is 4.985541801452637 and perplexity is 146.28280979830615
At time: 38.22866988182068 and batch: 1600, loss is 5.026108989715576 and perplexity is 152.33910497023334
At time: 39.479177951812744 and batch: 1650, loss is 5.007771673202515 and perplexity is 149.57107130364014
At time: 40.72949576377869 and batch: 1700, loss is 5.020494918823243 and perplexity is 151.4862586451055
At time: 41.980414390563965 and batch: 1750, loss is 5.004662895202637 and perplexity is 149.1068100642212
At time: 43.23067569732666 and batch: 1800, loss is 4.96033938407898 and perplexity is 142.64219817409432
At time: 44.4811065196991 and batch: 1850, loss is 4.955692701339721 and perplexity is 141.98092269246797
At time: 45.73153257369995 and batch: 1900, loss is 5.05081919670105 and perplexity is 156.15032994092047
At time: 46.98284649848938 and batch: 1950, loss is 4.967134466171265 and perplexity is 143.61476421134347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.756602016715116 and perplexity of 116.34989842263334
finished 1 epochs...
Completing Train Step...
At time: 50.92395210266113 and batch: 50, loss is 4.988357391357422 and perplexity is 146.69526257727995
At time: 52.19713544845581 and batch: 100, loss is 4.937691850662231 and perplexity is 139.448010981484
At time: 53.44453573226929 and batch: 150, loss is 4.8756163120269775 and perplexity is 131.0548990364215
At time: 54.69042706489563 and batch: 200, loss is 4.836206293106079 and perplexity is 125.99047301567019
At time: 55.945544719696045 and batch: 250, loss is 4.866160144805908 and perplexity is 129.82146297586334
At time: 57.19232726097107 and batch: 300, loss is 4.874403915405273 and perplexity is 130.896104799821
At time: 58.4380943775177 and batch: 350, loss is 4.870766353607178 and perplexity is 130.42082707958804
At time: 59.68454194068909 and batch: 400, loss is 4.807290506362915 and perplexity is 122.39952708215961
At time: 60.931055545806885 and batch: 450, loss is 4.784698419570923 and perplexity is 119.66526893833641
At time: 62.19920635223389 and batch: 500, loss is 4.791583433151245 and perplexity is 120.49200873156698
At time: 63.4457905292511 and batch: 550, loss is 4.751781425476074 and perplexity is 115.79037282725086
At time: 64.69229316711426 and batch: 600, loss is 4.715478448867798 and perplexity is 111.66222305945963
At time: 65.94138717651367 and batch: 650, loss is 4.777694311141968 and perplexity is 118.83004882013111
At time: 67.18793749809265 and batch: 700, loss is 4.799332809448242 and perplexity is 121.4293739549826
At time: 68.43435072898865 and batch: 750, loss is 4.739671573638916 and perplexity is 114.39662464269995
At time: 69.68021869659424 and batch: 800, loss is 4.738823757171631 and perplexity is 114.29967840264244
At time: 70.92729020118713 and batch: 850, loss is 4.737941617965698 and perplexity is 114.19889463429021
At time: 72.17407941818237 and batch: 900, loss is 4.7193233680725095 and perplexity is 112.0923817180515
At time: 73.42214488983154 and batch: 950, loss is 4.764634027481079 and perplexity is 117.28818517973208
At time: 74.66810607910156 and batch: 1000, loss is 4.7406722354888915 and perplexity is 114.51115427390538
At time: 75.91289782524109 and batch: 1050, loss is 4.666702070236206 and perplexity is 106.34644037511539
At time: 77.15929579734802 and batch: 1100, loss is 4.715317039489746 and perplexity is 111.64420118397271
At time: 78.40530967712402 and batch: 1150, loss is 4.659165410995484 and perplexity is 105.547956223594
At time: 79.65194368362427 and batch: 1200, loss is 4.725978937149048 and perplexity is 112.84090848021815
At time: 80.89754796028137 and batch: 1250, loss is 4.7128817653656006 and perplexity is 111.37264773746458
At time: 82.14296174049377 and batch: 1300, loss is 4.710660257339478 and perplexity is 111.12550712069569
At time: 83.38769841194153 and batch: 1350, loss is 4.594462041854858 and perplexity is 98.93489839484154
At time: 84.63364458084106 and batch: 1400, loss is 4.598867063522339 and perplexity is 99.37167005398452
At time: 85.87938570976257 and batch: 1450, loss is 4.556060590744019 and perplexity is 95.20767808933648
At time: 87.12478160858154 and batch: 1500, loss is 4.542028369903565 and perplexity is 93.88103258435791
At time: 88.37114715576172 and batch: 1550, loss is 4.545757141113281 and perplexity is 94.23174693623277
At time: 89.61719679832458 and batch: 1600, loss is 4.616223783493042 and perplexity is 101.11149142290552
At time: 90.86724328994751 and batch: 1650, loss is 4.5852756690979 and perplexity is 98.03020731644193
At time: 92.11512660980225 and batch: 1700, loss is 4.592959442138672 and perplexity is 98.7863504765718
At time: 93.36068964004517 and batch: 1750, loss is 4.580939598083496 and perplexity is 97.60606160347525
At time: 94.60853552818298 and batch: 1800, loss is 4.536136903762817 and perplexity is 93.32956174063017
At time: 95.85711073875427 and batch: 1850, loss is 4.566194257736206 and perplexity is 96.17738604458314
At time: 97.1048231124878 and batch: 1900, loss is 4.675281562805176 and perplexity is 107.26276404541109
At time: 98.35183358192444 and batch: 1950, loss is 4.598432703018188 and perplexity is 99.32851629810368
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.569278876726018 and perplexity of 96.47451466466359
finished 2 epochs...
Completing Train Step...
At time: 102.25777316093445 and batch: 50, loss is 4.601860675811768 and perplexity is 99.66959602160429
At time: 103.50664377212524 and batch: 100, loss is 4.548299493789673 and perplexity is 94.4716220646407
At time: 104.75356149673462 and batch: 150, loss is 4.504104299545288 and perplexity is 90.3873477915749
At time: 106.00224447250366 and batch: 200, loss is 4.488647584915161 and perplexity is 89.00099815688613
At time: 107.25075793266296 and batch: 250, loss is 4.505224533081055 and perplexity is 90.48865946555256
At time: 108.50001907348633 and batch: 300, loss is 4.522045850753784 and perplexity is 92.02367222582649
At time: 109.7477650642395 and batch: 350, loss is 4.526293048858642 and perplexity is 92.41534616173165
At time: 110.99610686302185 and batch: 400, loss is 4.467380104064941 and perplexity is 87.12815703020017
At time: 112.24441170692444 and batch: 450, loss is 4.462437648773193 and perplexity is 86.69859243577255
At time: 113.49368476867676 and batch: 500, loss is 4.476068153381347 and perplexity is 87.88842861158092
At time: 114.74260425567627 and batch: 550, loss is 4.439995193481446 and perplexity is 84.77453420247717
At time: 115.99066209793091 and batch: 600, loss is 4.415365953445434 and perplexity is 82.7121041477937
At time: 117.2392270565033 and batch: 650, loss is 4.473658618927002 and perplexity is 87.67691334370139
At time: 118.48904228210449 and batch: 700, loss is 4.507743711471558 and perplexity is 90.71690391459744
At time: 119.73830366134644 and batch: 750, loss is 4.4629519748687745 and perplexity is 86.74319525352577
At time: 120.98631072044373 and batch: 800, loss is 4.459513320922851 and perplexity is 86.44542767612148
At time: 122.23440170288086 and batch: 850, loss is 4.451752490997315 and perplexity is 85.77713601732974
At time: 123.48589897155762 and batch: 900, loss is 4.427927932739258 and perplexity is 83.75768542296399
At time: 124.79020237922668 and batch: 950, loss is 4.490348529815674 and perplexity is 89.15251277331839
At time: 126.0342755317688 and batch: 1000, loss is 4.470124397277832 and perplexity is 87.36759062792103
At time: 127.2756040096283 and batch: 1050, loss is 4.410601053237915 and perplexity is 82.31892669513884
At time: 128.51647663116455 and batch: 1100, loss is 4.447036476135254 and perplexity is 85.37356214721508
At time: 129.75630855560303 and batch: 1150, loss is 4.408101596832275 and perplexity is 82.11343104719452
At time: 130.9971764087677 and batch: 1200, loss is 4.470666580200195 and perplexity is 87.41497268723846
At time: 132.2386999130249 and batch: 1250, loss is 4.462942380905151 and perplexity is 86.74236304645801
At time: 133.4789900779724 and batch: 1300, loss is 4.453493509292603 and perplexity is 85.92660565738694
At time: 134.7180941104889 and batch: 1350, loss is 4.332466368675232 and perplexity is 76.13182435223554
At time: 135.96286273002625 and batch: 1400, loss is 4.3512398052215575 and perplexity is 77.57458069950103
At time: 137.20568251609802 and batch: 1450, loss is 4.301401987075805 and perplexity is 73.80319232268235
At time: 138.45059990882874 and batch: 1500, loss is 4.294072318077087 and perplexity is 73.26421702018365
At time: 139.69760084152222 and batch: 1550, loss is 4.307777404785156 and perplexity is 74.27522159507548
At time: 140.94507575035095 and batch: 1600, loss is 4.384816598892212 and perplexity is 80.22350878323948
At time: 142.193510055542 and batch: 1650, loss is 4.35233850479126 and perplexity is 77.65985869680634
At time: 143.44170784950256 and batch: 1700, loss is 4.353410215377807 and perplexity is 77.74313220410075
At time: 144.69022059440613 and batch: 1750, loss is 4.340096311569214 and perplexity is 76.71492751755767
At time: 145.93887329101562 and batch: 1800, loss is 4.299310865402222 and perplexity is 73.6490221181443
At time: 147.18666172027588 and batch: 1850, loss is 4.335617637634277 and perplexity is 76.37211461788979
At time: 148.4425733089447 and batch: 1900, loss is 4.446669282913208 and perplexity is 85.34221930864388
At time: 149.6878957748413 and batch: 1950, loss is 4.374614877700806 and perplexity is 79.40925138907527
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479408725472384 and perplexity of 88.18251718187277
finished 3 epochs...
Completing Train Step...
At time: 153.5668842792511 and batch: 50, loss is 4.374664030075073 and perplexity is 79.41315463824606
At time: 154.76791286468506 and batch: 100, loss is 4.319973268508911 and perplexity is 75.18661841473954
At time: 156.00772500038147 and batch: 150, loss is 4.287560701370239 and perplexity is 72.78869839833239
At time: 157.2406780719757 and batch: 200, loss is 4.279936513900757 and perplexity is 72.23585388916061
At time: 158.48043155670166 and batch: 250, loss is 4.286749215126037 and perplexity is 72.72965533040754
At time: 159.72112226486206 and batch: 300, loss is 4.303753633499145 and perplexity is 73.97695557072004
At time: 160.96152782440186 and batch: 350, loss is 4.309465770721435 and perplexity is 74.40073127244355
At time: 162.20172548294067 and batch: 400, loss is 4.251446533203125 and perplexity is 70.2068955350711
At time: 163.44214797019958 and batch: 450, loss is 4.262966856956482 and perplexity is 71.0203784979468
At time: 164.68175506591797 and batch: 500, loss is 4.271897268295288 and perplexity is 71.65746015795912
At time: 165.92516660690308 and batch: 550, loss is 4.2459315586090085 and perplexity is 69.82077199926847
At time: 167.17341589927673 and batch: 600, loss is 4.224389200210571 and perplexity is 68.33275316804819
At time: 168.4214265346527 and batch: 650, loss is 4.27831262588501 and perplexity is 72.11864614360597
At time: 169.66866993904114 and batch: 700, loss is 4.314318571090698 and perplexity is 74.76266064385331
At time: 170.92255902290344 and batch: 750, loss is 4.273484582901001 and perplexity is 71.77129341176845
At time: 172.1770429611206 and batch: 800, loss is 4.27148998260498 and perplexity is 71.62828104235446
At time: 173.4255015850067 and batch: 850, loss is 4.263177585601807 and perplexity is 71.0353461030943
At time: 174.67578792572021 and batch: 900, loss is 4.2343320512771605 and perplexity is 69.01556447610515
At time: 175.92719793319702 and batch: 950, loss is 4.307928857803344 and perplexity is 74.28647165346878
At time: 177.1757574081421 and batch: 1000, loss is 4.2880008506774905 and perplexity is 72.8207433452714
At time: 178.42309093475342 and batch: 1050, loss is 4.233102531433105 and perplexity is 68.93076061473161
At time: 179.67067170143127 and batch: 1100, loss is 4.269324345588684 and perplexity is 71.47332803206348
At time: 180.9170527458191 and batch: 1150, loss is 4.231833658218384 and perplexity is 68.843351686069
At time: 182.16382026672363 and batch: 1200, loss is 4.2961270618438725 and perplexity is 73.41491097915193
At time: 183.41121125221252 and batch: 1250, loss is 4.295828399658203 and perplexity is 73.39298799532423
At time: 184.6601324081421 and batch: 1300, loss is 4.281229934692383 and perplexity is 72.3293456935697
At time: 185.9112033843994 and batch: 1350, loss is 4.158923716545105 and perplexity is 64.0026005767022
At time: 187.15706515312195 and batch: 1400, loss is 4.18220549583435 and perplexity is 65.51017642460049
At time: 188.40385031700134 and batch: 1450, loss is 4.130930109024048 and perplexity is 62.235782085466894
At time: 189.65075778961182 and batch: 1500, loss is 4.126723437309265 and perplexity is 61.974526474881
At time: 190.90532183647156 and batch: 1550, loss is 4.1456950616836545 and perplexity is 63.16150779222598
At time: 192.15343809127808 and batch: 1600, loss is 4.222777643203735 and perplexity is 68.2227197272792
At time: 193.4010055065155 and batch: 1650, loss is 4.190282964706421 and perplexity is 66.04147572351073
At time: 194.64895248413086 and batch: 1700, loss is 4.1888947057724 and perplexity is 65.94985666502434
At time: 195.8957667350769 and batch: 1750, loss is 4.17659167766571 and perplexity is 65.14344455210936
At time: 197.14346075057983 and batch: 1800, loss is 4.137720160484314 and perplexity is 62.65980418531636
At time: 198.3911566734314 and batch: 1850, loss is 4.17794132232666 and perplexity is 65.23142441166394
At time: 199.6391088962555 and batch: 1900, loss is 4.290216417312622 and perplexity is 72.98226141552557
At time: 200.89169073104858 and batch: 1950, loss is 4.21463613986969 and perplexity is 67.66953914353064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.452595839389535 and perplexity of 85.84950653957165
finished 4 epochs...
Completing Train Step...
At time: 204.80907917022705 and batch: 50, loss is 4.21365957736969 and perplexity is 67.6034878660604
At time: 206.00736904144287 and batch: 100, loss is 4.159334392547607 and perplexity is 64.02889030676793
At time: 207.21281099319458 and batch: 150, loss is 4.1315053367614745 and perplexity is 62.271592132061514
At time: 208.4205093383789 and batch: 200, loss is 4.127990684509277 and perplexity is 62.05311330398095
At time: 209.64199876785278 and batch: 250, loss is 4.128402347564697 and perplexity is 62.07866353688464
At time: 210.87603497505188 and batch: 300, loss is 4.145675625801086 and perplexity is 63.160280204507366
At time: 212.1130301952362 and batch: 350, loss is 4.153323721885681 and perplexity is 63.64518804345797
At time: 213.3505311012268 and batch: 400, loss is 4.096682467460632 and perplexity is 60.140438416199
At time: 214.58764553070068 and batch: 450, loss is 4.117817993164063 and perplexity is 61.42506601697313
At time: 215.82473969459534 and batch: 500, loss is 4.127099504470825 and perplexity is 61.99783744211135
At time: 217.0831482410431 and batch: 550, loss is 4.1050533151626585 and perplexity is 60.64597781158585
At time: 218.3221640586853 and batch: 600, loss is 4.085728158950806 and perplexity is 59.4852366926134
At time: 219.56116914749146 and batch: 650, loss is 4.138438158035278 and perplexity is 62.70480992633779
At time: 220.7999713420868 and batch: 700, loss is 4.173304209709167 and perplexity is 64.92963919724941
At time: 222.0411901473999 and batch: 750, loss is 4.132591857910156 and perplexity is 62.33928830387647
At time: 223.28667783737183 and batch: 800, loss is 4.1310103178024296 and perplexity is 62.240774141720294
At time: 224.5309329032898 and batch: 850, loss is 4.123964700698853 and perplexity is 61.80379069558814
At time: 225.7764778137207 and batch: 900, loss is 4.097359309196472 and perplexity is 60.181157753649785
At time: 227.02153182029724 and batch: 950, loss is 4.172198495864868 and perplexity is 64.85788527324779
At time: 228.26764917373657 and batch: 1000, loss is 4.149090604782105 and perplexity is 63.376339943599326
At time: 229.5175256729126 and batch: 1050, loss is 4.102481155395508 and perplexity is 60.49018711259608
At time: 230.76338601112366 and batch: 1100, loss is 4.131421265602111 and perplexity is 62.26635710717598
At time: 232.0082061290741 and batch: 1150, loss is 4.103368515968323 and perplexity is 60.5438875419802
At time: 233.25314140319824 and batch: 1200, loss is 4.163309717178345 and perplexity is 64.28393253343238
At time: 234.4984884262085 and batch: 1250, loss is 4.16956244468689 and perplexity is 64.68714171162685
At time: 235.74284434318542 and batch: 1300, loss is 4.149080476760864 and perplexity is 63.3756980699327
At time: 236.98894119262695 and batch: 1350, loss is 4.029096450805664 and perplexity is 56.210099704918775
At time: 238.23446226119995 and batch: 1400, loss is 4.0548670291900635 and perplexity is 57.677493063268045
At time: 239.48266100883484 and batch: 1450, loss is 4.000795478820801 and perplexity is 54.64159898421954
At time: 240.73336172103882 and batch: 1500, loss is 4.002920231819153 and perplexity is 54.757822314706054
At time: 241.98305201530457 and batch: 1550, loss is 4.019634718894959 and perplexity is 55.68076298096197
At time: 243.22875833511353 and batch: 1600, loss is 4.102086167335511 and perplexity is 60.46629892902382
At time: 244.47514390945435 and batch: 1650, loss is 4.065974683761596 and perplexity is 58.321726067831094
At time: 245.72185349464417 and batch: 1700, loss is 4.067358655929565 and perplexity is 58.402497593376204
At time: 246.96758151054382 and batch: 1750, loss is 4.055208082199097 and perplexity is 57.6971675006531
At time: 248.21281957626343 and batch: 1800, loss is 4.015851168632508 and perplexity is 55.47049005550547
At time: 249.45918726921082 and batch: 1850, loss is 4.054584312438965 and perplexity is 57.66118897464575
At time: 250.7072615623474 and batch: 1900, loss is 4.166960277557373 and perplexity is 64.51903377509451
At time: 251.95764327049255 and batch: 1950, loss is 4.093661737442017 and perplexity is 59.95904449750225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4500641578851745 and perplexity of 85.63243782207576
finished 5 epochs...
Completing Train Step...
At time: 255.90442848205566 and batch: 50, loss is 4.0926311540603635 and perplexity is 59.89728353304149
At time: 257.1066162586212 and batch: 100, loss is 4.038534483909607 and perplexity is 56.743123879960955
At time: 258.31719636917114 and batch: 150, loss is 4.01282341003418 and perplexity is 55.30279280379557
At time: 259.52866554260254 and batch: 200, loss is 4.010391254425048 and perplexity is 55.16845124209205
At time: 260.7503252029419 and batch: 250, loss is 4.008285479545593 and perplexity is 55.05240113391258
At time: 261.9720754623413 and batch: 300, loss is 4.023976979255676 and perplexity is 55.923069048196325
At time: 263.20719027519226 and batch: 350, loss is 4.031033091545105 and perplexity is 56.31906395221902
At time: 264.4502990245819 and batch: 400, loss is 3.9770542573928833 and perplexity is 53.35961878607682
At time: 265.6934812068939 and batch: 450, loss is 4.008129196166992 and perplexity is 55.04379803094179
At time: 266.93542885780334 and batch: 500, loss is 4.018477468490601 and perplexity is 55.61636366574121
At time: 268.1769289970398 and batch: 550, loss is 3.9972230195999146 and perplexity is 54.44674236598319
At time: 269.4210133552551 and batch: 600, loss is 3.9803660202026365 and perplexity is 53.53662612850067
At time: 270.6645014286041 and batch: 650, loss is 4.023402404785156 and perplexity is 55.89094630974459
At time: 271.9074158668518 and batch: 700, loss is 4.060428366661072 and perplexity is 57.999150660868686
At time: 273.151104927063 and batch: 750, loss is 4.025698418617249 and perplexity is 56.01942012795293
At time: 274.39486932754517 and batch: 800, loss is 4.021734194755554 and perplexity is 55.79778619946668
At time: 275.6381220817566 and batch: 850, loss is 4.015410552024841 and perplexity is 55.44605422016439
At time: 276.88226675987244 and batch: 900, loss is 3.987152132987976 and perplexity is 53.90116722107412
At time: 278.12648940086365 and batch: 950, loss is 4.068226099014282 and perplexity is 58.45318041509732
At time: 279.39192628860474 and batch: 1000, loss is 4.039505019187927 and perplexity is 56.79822181640918
At time: 280.6354978084564 and batch: 1050, loss is 3.9999441623687746 and perplexity is 54.59510148688969
At time: 281.87801003456116 and batch: 1100, loss is 4.0267923021316525 and perplexity is 56.08073237623241
At time: 283.12021565437317 and batch: 1150, loss is 4.001202158927917 and perplexity is 54.663825154711816
At time: 284.3623905181885 and batch: 1200, loss is 4.056099028587341 and perplexity is 57.74859549003853
At time: 285.6056852340698 and batch: 1250, loss is 4.064656629562378 and perplexity is 58.24490550983271
At time: 286.8488037586212 and batch: 1300, loss is 4.0419394969940186 and perplexity is 56.936664276019
At time: 288.092814207077 and batch: 1350, loss is 3.9262086248397825 and perplexity is 50.7143356384512
At time: 289.3364403247833 and batch: 1400, loss is 3.955152039527893 and perplexity is 52.20363035640591
At time: 290.58025097846985 and batch: 1450, loss is 3.8974337911605836 and perplexity is 49.27583463302022
At time: 291.82150053977966 and batch: 1500, loss is 3.900886068344116 and perplexity is 49.446242450887645
At time: 293.06204414367676 and batch: 1550, loss is 3.92215211391449 and perplexity is 50.50902907754988
At time: 294.3018248081207 and batch: 1600, loss is 4.0063366079330445 and perplexity is 54.94521555153457
At time: 295.54272532463074 and batch: 1650, loss is 3.9681813955307006 and perplexity is 52.88826050045506
At time: 296.78398871421814 and batch: 1700, loss is 3.9679823303222657 and perplexity is 52.87773333568567
At time: 298.0256106853485 and batch: 1750, loss is 3.9590504121780397 and perplexity is 52.4075367545529
At time: 299.26738953590393 and batch: 1800, loss is 3.919497127532959 and perplexity is 50.37510615364224
At time: 300.51011848449707 and batch: 1850, loss is 3.9599908351898194 and perplexity is 52.45684518986718
At time: 301.75316071510315 and batch: 1900, loss is 4.06598171710968 and perplexity is 58.322136266273894
At time: 302.9954071044922 and batch: 1950, loss is 3.9958505201339722 and perplexity is 54.372065499865755
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.455757460483285 and perplexity of 86.12135967218418
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 306.904673576355 and batch: 50, loss is 4.038918852806091 and perplexity is 56.764938364005786
At time: 308.12701749801636 and batch: 100, loss is 4.017527804374695 and perplexity is 55.56357187211428
At time: 309.3284752368927 and batch: 150, loss is 3.9938981676101686 and perplexity is 54.26601561762598
At time: 310.5578124523163 and batch: 200, loss is 3.9841666507720945 and perplexity is 53.740486219403984
At time: 311.7648766040802 and batch: 250, loss is 3.971934714317322 and perplexity is 53.08713999778538
At time: 312.98323154449463 and batch: 300, loss is 3.9851609373092653 and perplexity is 53.79394623423522
At time: 314.2173535823822 and batch: 350, loss is 3.990565843582153 and perplexity is 54.08548463080837
At time: 315.45732378959656 and batch: 400, loss is 3.937139048576355 and perplexity is 51.27170541113204
At time: 316.6981632709503 and batch: 450, loss is 3.9554352807998656 and perplexity is 52.21841867330162
At time: 317.9386661052704 and batch: 500, loss is 3.9700050258636477 and perplexity is 52.98479713337277
At time: 319.17935585975647 and batch: 550, loss is 3.9428273248672485 and perplexity is 51.564184098576064
At time: 320.4188117980957 and batch: 600, loss is 3.9099546241760255 and perplexity is 49.89668781871593
At time: 321.6581108570099 and batch: 650, loss is 3.955864624977112 and perplexity is 52.24084316087112
At time: 322.8991265296936 and batch: 700, loss is 3.9772268962860107 and perplexity is 53.368831526817544
At time: 324.1388816833496 and batch: 750, loss is 3.931381344795227 and perplexity is 50.97734634836059
At time: 325.3784210681915 and batch: 800, loss is 3.9202374696731566 and perplexity is 50.41241477641343
At time: 326.61718559265137 and batch: 850, loss is 3.918334879875183 and perplexity is 50.31659181516823
At time: 327.8577311038971 and batch: 900, loss is 3.8899913835525513 and perplexity is 48.910465087464125
At time: 329.10576701164246 and batch: 950, loss is 3.9794782781600953 and perplexity is 53.48912050416046
At time: 330.34629821777344 and batch: 1000, loss is 3.9254132318496704 and perplexity is 50.67401384934619
At time: 331.58616375923157 and batch: 1050, loss is 3.882757515907288 and perplexity is 48.55792989034312
At time: 332.8268737792969 and batch: 1100, loss is 3.8999060726165773 and perplexity is 49.39780908066712
At time: 334.06753039360046 and batch: 1150, loss is 3.8737879896163943 and perplexity is 48.12433573561589
At time: 335.3085310459137 and batch: 1200, loss is 3.9070493745803834 and perplexity is 49.75193585870797
At time: 336.54951000213623 and batch: 1250, loss is 3.910113525390625 and perplexity is 49.9046170929838
At time: 337.7901704311371 and batch: 1300, loss is 3.8944080686569214 and perplexity is 49.126964964013254
At time: 339.0315341949463 and batch: 1350, loss is 3.7754099416732787 and perplexity is 43.61538441506192
At time: 340.27309679985046 and batch: 1400, loss is 3.787146587371826 and perplexity is 44.130298500317586
At time: 341.5130000114441 and batch: 1450, loss is 3.7219690227508546 and perplexity is 41.345724684010634
At time: 342.75336050987244 and batch: 1500, loss is 3.7142811012268067 and perplexity is 41.0290807238227
At time: 343.99420070648193 and batch: 1550, loss is 3.73923620223999 and perplexity is 42.065848090992624
At time: 345.2345836162567 and batch: 1600, loss is 3.816692523956299 and perplexity is 45.45362266084342
At time: 346.47501516342163 and batch: 1650, loss is 3.7701100492477417 and perplexity is 43.38483904204787
At time: 347.7166483402252 and batch: 1700, loss is 3.7551962661743166 and perplexity is 42.74260791551073
At time: 348.9577968120575 and batch: 1750, loss is 3.73795955657959 and perplexity is 42.01217917396047
At time: 350.19854712486267 and batch: 1800, loss is 3.6919985961914064 and perplexity is 40.12496046651118
At time: 351.44065403938293 and batch: 1850, loss is 3.7197392988204956 and perplexity is 41.25363783454274
At time: 352.681378364563 and batch: 1900, loss is 3.818148946762085 and perplexity is 45.51987058427528
At time: 353.9254162311554 and batch: 1950, loss is 3.739054174423218 and perplexity is 42.058191633369226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37586669921875 and perplexity of 79.50871984407472
finished 7 epochs...
Completing Train Step...
At time: 357.80344223976135 and batch: 50, loss is 3.950251359939575 and perplexity is 51.94842294632381
At time: 359.0629940032959 and batch: 100, loss is 3.911420993804932 and perplexity is 49.96990847747126
At time: 360.2769739627838 and batch: 150, loss is 3.8817176008224488 and perplexity is 48.5074600133031
At time: 361.49794006347656 and batch: 200, loss is 3.8716388368606567 and perplexity is 48.02102024700181
At time: 362.72550106048584 and batch: 250, loss is 3.8623052787780763 and perplexity is 47.57489845583155
At time: 363.9544038772583 and batch: 300, loss is 3.875828490257263 and perplexity is 48.22263372797753
At time: 365.1892457008362 and batch: 350, loss is 3.8840184736251833 and perplexity is 48.619198006937516
At time: 366.4171543121338 and batch: 400, loss is 3.8305147552490233 and perplexity is 46.08625527126483
At time: 367.6462824344635 and batch: 450, loss is 3.855678505897522 and perplexity is 47.26067271018551
At time: 368.8756914138794 and batch: 500, loss is 3.8744858169555663 and perplexity is 48.15792993288308
At time: 370.10401821136475 and batch: 550, loss is 3.848120150566101 and perplexity is 46.90480632910074
At time: 371.373074054718 and batch: 600, loss is 3.81973286151886 and perplexity is 45.59202730898525
At time: 372.6133337020874 and batch: 650, loss is 3.8635273361206055 and perplexity is 47.63307324903621
At time: 373.8546853065491 and batch: 700, loss is 3.8878914308547974 and perplexity is 48.80786319162379
At time: 375.0958876609802 and batch: 750, loss is 3.847795262336731 and perplexity is 46.88956998481201
At time: 376.3386118412018 and batch: 800, loss is 3.839025378227234 and perplexity is 46.48015178922056
At time: 377.58841037750244 and batch: 850, loss is 3.839566707611084 and perplexity is 46.50531967259268
At time: 378.8392517566681 and batch: 900, loss is 3.8104976558685304 and perplexity is 45.17291383912447
At time: 380.0884304046631 and batch: 950, loss is 3.9040356922149657 and perplexity is 49.60222503071594
At time: 381.338830947876 and batch: 1000, loss is 3.853350567817688 and perplexity is 47.15078075097124
At time: 382.58758187294006 and batch: 1050, loss is 3.8126755857467653 and perplexity is 45.27140449179769
At time: 383.8375880718231 and batch: 1100, loss is 3.8277949237823488 and perplexity is 45.96107873070973
At time: 385.08760356903076 and batch: 1150, loss is 3.808997087478638 and perplexity is 45.10517962515813
At time: 386.33567214012146 and batch: 1200, loss is 3.843548083305359 and perplexity is 46.69084389774456
At time: 387.58566522598267 and batch: 1250, loss is 3.851102271080017 and perplexity is 47.04489088495504
At time: 388.83510398864746 and batch: 1300, loss is 3.835620985031128 and perplexity is 46.322184121311274
At time: 390.08577394485474 and batch: 1350, loss is 3.717514982223511 and perplexity is 41.16197866052334
At time: 391.33523178100586 and batch: 1400, loss is 3.7363505363464355 and perplexity is 41.9446350821082
At time: 392.5855987071991 and batch: 1450, loss is 3.6726927042007445 and perplexity is 39.35774206094431
At time: 393.8352720737457 and batch: 1500, loss is 3.6681838703155516 and perplexity is 39.18068400254154
At time: 395.0865468978882 and batch: 1550, loss is 3.6972618865966798 and perplexity is 40.336706537659296
At time: 396.33512687683105 and batch: 1600, loss is 3.775919861793518 and perplexity is 43.637630448495116
At time: 397.58430576324463 and batch: 1650, loss is 3.732161297798157 and perplexity is 41.76928654479775
At time: 398.8334379196167 and batch: 1700, loss is 3.724464077949524 and perplexity is 41.44901335120568
At time: 400.08363127708435 and batch: 1750, loss is 3.708500165939331 and perplexity is 40.7925785238531
At time: 401.3347096443176 and batch: 1800, loss is 3.6663538646697997 and perplexity is 39.10904869611181
At time: 402.58471965789795 and batch: 1850, loss is 3.698479914665222 and perplexity is 40.38586771218202
At time: 403.8345468044281 and batch: 1900, loss is 3.799607586860657 and perplexity is 44.683646602435914
At time: 405.0838029384613 and batch: 1950, loss is 3.725699028968811 and perplexity is 41.5002324725357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37952398255814 and perplexity of 79.80003815257876
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 408.9423668384552 and batch: 50, loss is 3.9227646493911745 and perplexity is 50.5399771271743
At time: 410.1700978279114 and batch: 100, loss is 3.915675802230835 and perplexity is 50.182973819775924
At time: 411.3697373867035 and batch: 150, loss is 3.906325216293335 and perplexity is 49.71592062399841
At time: 412.5745368003845 and batch: 200, loss is 3.9014348459243773 and perplexity is 49.47338488707191
At time: 413.7913022041321 and batch: 250, loss is 3.9037172746658326 and perplexity is 49.58643332610148
At time: 415.0103106498718 and batch: 300, loss is 3.909139885902405 and perplexity is 49.85605163359864
At time: 416.23450684547424 and batch: 350, loss is 3.9127651500701903 and perplexity is 50.0371210049759
At time: 417.47296833992004 and batch: 400, loss is 3.8578224086761477 and perplexity is 47.36210368795539
At time: 418.7123351097107 and batch: 450, loss is 3.8772805881500245 and perplexity is 48.292708578255294
At time: 419.95272731781006 and batch: 500, loss is 3.8995864582061768 and perplexity is 49.382023351850314
At time: 421.19237995147705 and batch: 550, loss is 3.8753979349136354 and perplexity is 48.20187568440611
At time: 422.4319477081299 and batch: 600, loss is 3.8423318433761597 and perplexity is 46.63409114854386
At time: 423.6740691661835 and batch: 650, loss is 3.8886147212982176 and perplexity is 48.843178222606674
At time: 424.9224908351898 and batch: 700, loss is 3.9170467901229857 and perplexity is 50.251821252989785
At time: 426.1718873977661 and batch: 750, loss is 3.862316188812256 and perplexity is 47.5754175024312
At time: 427.4210283756256 and batch: 800, loss is 3.842887964248657 and perplexity is 46.66003255261107
At time: 428.6718225479126 and batch: 850, loss is 3.838835368156433 and perplexity is 46.471320931290784
At time: 429.9185371398926 and batch: 900, loss is 3.8121228408813477 and perplexity is 45.24638786995618
At time: 431.17166924476624 and batch: 950, loss is 3.912528281211853 and perplexity is 50.02527017285091
At time: 432.41866302490234 and batch: 1000, loss is 3.856255693435669 and perplexity is 47.28795885537224
At time: 433.6857476234436 and batch: 1050, loss is 3.815104594230652 and perplexity is 45.381502778089065
At time: 434.9322395324707 and batch: 1100, loss is 3.8269827795028686 and perplexity is 45.92376685690312
At time: 436.17854595184326 and batch: 1150, loss is 3.8070876455307006 and perplexity is 45.01913607683554
At time: 437.42420053482056 and batch: 1200, loss is 3.834168677330017 and perplexity is 46.254958884260304
At time: 438.67081117630005 and batch: 1250, loss is 3.8298794412612915 and perplexity is 46.05698532743569
At time: 439.9171600341797 and batch: 1300, loss is 3.815333127975464 and perplexity is 45.39187516803954
At time: 441.16307282447815 and batch: 1350, loss is 3.6936433124542236 and perplexity is 40.191008942147434
At time: 442.4091765880585 and batch: 1400, loss is 3.709141716957092 and perplexity is 40.81875744077967
At time: 443.65614342689514 and batch: 1450, loss is 3.6431632328033445 and perplexity is 38.21252084822568
At time: 444.9000904560089 and batch: 1500, loss is 3.6336510229110717 and perplexity is 37.850758636197845
At time: 446.14775490760803 and batch: 1550, loss is 3.6594933748245237 and perplexity is 38.841659723091254
At time: 447.39425349235535 and batch: 1600, loss is 3.7391652965545656 and perplexity is 42.06286548894374
At time: 448.6423132419586 and batch: 1650, loss is 3.6983100509643556 and perplexity is 40.379008201837124
At time: 449.88888669013977 and batch: 1700, loss is 3.684027142524719 and perplexity is 39.806377674260695
At time: 451.13600635528564 and batch: 1750, loss is 3.6634871768951416 and perplexity is 38.99709580799213
At time: 452.38502860069275 and batch: 1800, loss is 3.613970618247986 and perplexity is 37.113122684616506
At time: 453.63675570487976 and batch: 1850, loss is 3.6377710628509523 and perplexity is 38.00702696836771
At time: 454.8844585418701 and batch: 1900, loss is 3.749737057685852 and perplexity is 42.509902878158115
At time: 456.1311209201813 and batch: 1950, loss is 3.680698857307434 and perplexity is 39.674110928719266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345726687409157 and perplexity of 77.14807965238919
finished 9 epochs...
Completing Train Step...
At time: 460.04874873161316 and batch: 50, loss is 3.9141531229019164 and perplexity is 50.10661938928603
At time: 461.2573239803314 and batch: 100, loss is 3.8842264556884767 and perplexity is 48.62931097967668
At time: 462.46541237831116 and batch: 150, loss is 3.861688756942749 and perplexity is 47.545576531852014
At time: 463.67366194725037 and batch: 200, loss is 3.85261257648468 and perplexity is 47.115996720167814
At time: 464.9036502838135 and batch: 250, loss is 3.852033076286316 and perplexity is 47.0887009004527
At time: 466.1205024719238 and batch: 300, loss is 3.8576423263549806 and perplexity is 47.35357537830985
At time: 467.34170937538147 and batch: 350, loss is 3.866402711868286 and perplexity is 47.77023333153052
At time: 468.57911014556885 and batch: 400, loss is 3.8102533769607545 and perplexity is 45.16188039674429
At time: 469.81980562210083 and batch: 450, loss is 3.8318868923187255 and perplexity is 46.14953533505851
At time: 471.06196308135986 and batch: 500, loss is 3.852810959815979 and perplexity is 47.12534467576326
At time: 472.303457736969 and batch: 550, loss is 3.831747736930847 and perplexity is 46.14311382537275
At time: 473.5450015068054 and batch: 600, loss is 3.802089686393738 and perplexity is 44.79469361866604
At time: 474.78618931770325 and batch: 650, loss is 3.846357207298279 and perplexity is 46.82218866308116
At time: 476.0286121368408 and batch: 700, loss is 3.8781774854660034 and perplexity is 48.336041608694984
At time: 477.27086329460144 and batch: 750, loss is 3.824845509529114 and perplexity is 45.825720182347396
At time: 478.5125458240509 and batch: 800, loss is 3.806916604042053 and perplexity is 45.01143659526749
At time: 479.7522249221802 and batch: 850, loss is 3.805318250656128 and perplexity is 44.93954987867282
At time: 480.9910967350006 and batch: 900, loss is 3.777383599281311 and perplexity is 43.70155125428822
At time: 482.2326774597168 and batch: 950, loss is 3.881669158935547 and perplexity is 48.505110277324526
At time: 483.47847056388855 and batch: 1000, loss is 3.826176528930664 and perplexity is 45.886755715728725
At time: 484.7284209728241 and batch: 1050, loss is 3.787378959655762 and perplexity is 44.14055435011234
At time: 485.9830913543701 and batch: 1100, loss is 3.7980629301071165 and perplexity is 44.61467898529929
At time: 487.2385923862457 and batch: 1150, loss is 3.7808650827407835 and perplexity is 43.85396263704265
At time: 488.4872326850891 and batch: 1200, loss is 3.80911009311676 and perplexity is 45.110277052777896
At time: 489.7358024120331 and batch: 1250, loss is 3.8076411390304568 and perplexity is 45.0440607732111
At time: 490.9837324619293 and batch: 1300, loss is 3.794818434715271 and perplexity is 44.47016143496088
At time: 492.2319588661194 and batch: 1350, loss is 3.674176278114319 and perplexity is 39.416175514819415
At time: 493.4813675880432 and batch: 1400, loss is 3.6928964710235594 and perplexity is 40.16100383745157
At time: 494.7301218509674 and batch: 1450, loss is 3.6284699296951293 and perplexity is 37.65515747887932
At time: 495.9792516231537 and batch: 1500, loss is 3.621332120895386 and perplexity is 37.38733911966495
At time: 497.2346816062927 and batch: 1550, loss is 3.6506273889541627 and perplexity is 38.49881220324958
At time: 498.48464012145996 and batch: 1600, loss is 3.731389684677124 and perplexity is 41.73706924648713
At time: 499.7341785430908 and batch: 1650, loss is 3.693067498207092 and perplexity is 40.167873048219874
At time: 500.983824968338 and batch: 1700, loss is 3.6812857246398925 and perplexity is 39.697401201849445
At time: 502.2334990501404 and batch: 1750, loss is 3.661972427368164 and perplexity is 38.93806969174043
At time: 503.4798345565796 and batch: 1800, loss is 3.6142347049713135 and perplexity is 37.12292506186062
At time: 504.7292082309723 and batch: 1850, loss is 3.6401329135894773 and perplexity is 38.0968999846285
At time: 505.9786374568939 and batch: 1900, loss is 3.7537211275100706 and perplexity is 42.679603123791054
At time: 507.22757053375244 and batch: 1950, loss is 3.684243712425232 and perplexity is 39.81499947109053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345344862827035 and perplexity of 77.11862824210839
finished 10 epochs...
Completing Train Step...
At time: 511.1270170211792 and batch: 50, loss is 3.894680676460266 and perplexity is 49.140359183618536
At time: 512.3339509963989 and batch: 100, loss is 3.8628177738189695 and perplexity is 47.599286604229924
At time: 513.5516765117645 and batch: 150, loss is 3.83985490322113 and perplexity is 46.51872423304108
At time: 514.7715287208557 and batch: 200, loss is 3.8293919372558594 and perplexity is 46.03453783467632
At time: 516.0002677440643 and batch: 250, loss is 3.8278514337539673 and perplexity is 45.963676063351265
At time: 517.2406668663025 and batch: 300, loss is 3.8333379316329954 and perplexity is 46.21654873294428
At time: 518.4815354347229 and batch: 350, loss is 3.8431010961532595 and perplexity is 46.66997835406397
At time: 519.7224340438843 and batch: 400, loss is 3.7860359287261964 and perplexity is 44.08131201142335
At time: 520.9704852104187 and batch: 450, loss is 3.809159598350525 and perplexity is 45.112510302866916
At time: 522.2253642082214 and batch: 500, loss is 3.8292645406723023 and perplexity is 46.02867356538243
At time: 523.4734883308411 and batch: 550, loss is 3.8096415758132935 and perplexity is 45.13425875683313
At time: 524.7217590808868 and batch: 600, loss is 3.781348624229431 and perplexity is 43.8751729750452
At time: 525.9913194179535 and batch: 650, loss is 3.82469642162323 and perplexity is 45.81888863095329
At time: 527.2410588264465 and batch: 700, loss is 3.85756383895874 and perplexity is 47.34985886532735
At time: 528.4893012046814 and batch: 750, loss is 3.8056363391876222 and perplexity is 44.9538469078397
At time: 529.7380094528198 and batch: 800, loss is 3.7877694511413575 and perplexity is 44.157794226548944
At time: 530.9871120452881 and batch: 850, loss is 3.78719087600708 and perplexity is 44.132253014292566
At time: 532.2346143722534 and batch: 900, loss is 3.758521122932434 and perplexity is 42.88495747911684
At time: 533.4838292598724 and batch: 950, loss is 3.8641687297821044 and perplexity is 47.66363460017659
At time: 534.7315702438354 and batch: 1000, loss is 3.8088874769210816 and perplexity is 45.10023589221836
At time: 535.97989153862 and batch: 1050, loss is 3.771648473739624 and perplexity is 43.4516347078766
At time: 537.2283730506897 and batch: 1100, loss is 3.7814541625976563 and perplexity is 43.879803733563634
At time: 538.4769132137299 and batch: 1150, loss is 3.7648741674423216 and perplexity is 43.158274802061904
At time: 539.7251114845276 and batch: 1200, loss is 3.793961138725281 and perplexity is 44.432053681034745
At time: 540.973799943924 and batch: 1250, loss is 3.793670401573181 and perplexity is 44.41913750998195
At time: 542.222142457962 and batch: 1300, loss is 3.7811602926254273 and perplexity is 43.86691067139374
At time: 543.4714210033417 and batch: 1350, loss is 3.66092134475708 and perplexity is 38.89716406514062
At time: 544.7198874950409 and batch: 1400, loss is 3.6810221338272093 and perplexity is 39.686938710574104
At time: 545.9700317382812 and batch: 1450, loss is 3.6168800973892212 and perplexity is 37.221259775957016
At time: 547.2190690040588 and batch: 1500, loss is 3.6107912921905516 and perplexity is 36.99531533980726
At time: 548.4659984111786 and batch: 1550, loss is 3.641447877883911 and perplexity is 38.14702899954597
At time: 549.7142300605774 and batch: 1600, loss is 3.72251127243042 and perplexity is 41.368150469609965
At time: 550.9676184654236 and batch: 1650, loss is 3.684943289756775 and perplexity is 39.84286288734672
At time: 552.2168521881104 and batch: 1700, loss is 3.6747692441940307 and perplexity is 39.439554900798065
At time: 553.4656417369843 and batch: 1750, loss is 3.65584566116333 and perplexity is 38.700234566348755
At time: 554.7204117774963 and batch: 1800, loss is 3.608963785171509 and perplexity is 36.92776788187829
At time: 555.9696686267853 and batch: 1850, loss is 3.6359741783142088 and perplexity is 37.93879405101687
At time: 557.2184548377991 and batch: 1900, loss is 3.7502937746047973 and perplexity is 42.533575449162086
At time: 558.466206073761 and batch: 1950, loss is 3.680431728363037 and perplexity is 39.66351424075104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346813113190407 and perplexity of 77.23194086133861
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 562.3777058124542 and batch: 50, loss is 3.890316915512085 and perplexity is 48.92638959883383
At time: 563.5827765464783 and batch: 100, loss is 3.877342200279236 and perplexity is 48.295684086518946
At time: 564.7866237163544 and batch: 150, loss is 3.866355605125427 and perplexity is 47.76798308443398
At time: 566.0063834190369 and batch: 200, loss is 3.8612657022476196 and perplexity is 47.52546640660897
At time: 567.2315621376038 and batch: 250, loss is 3.8731436109542847 and perplexity is 48.0933354295802
At time: 568.455591917038 and batch: 300, loss is 3.883113307952881 and perplexity is 48.57520948933822
At time: 569.6892535686493 and batch: 350, loss is 3.898948302268982 and perplexity is 49.35051997356072
At time: 570.9256753921509 and batch: 400, loss is 3.8312390661239624 and perplexity is 46.11964813909179
At time: 572.1624882221222 and batch: 450, loss is 3.8538617944717406 and perplexity is 47.17489164939238
At time: 573.3985142707825 and batch: 500, loss is 3.870786900520325 and perplexity is 47.980126816526685
At time: 574.634527683258 and batch: 550, loss is 3.8467181730270386 and perplexity is 46.83909291927908
At time: 575.8711667060852 and batch: 600, loss is 3.8110185050964356 and perplexity is 45.196448244826286
At time: 577.111207485199 and batch: 650, loss is 3.8515021419525146 and perplexity is 47.063706528182884
At time: 578.3545932769775 and batch: 700, loss is 3.8969384813308716 and perplexity is 49.25143387122666
At time: 579.6002895832062 and batch: 750, loss is 3.848478569984436 and perplexity is 46.92162093566308
At time: 580.8449628353119 and batch: 800, loss is 3.827246279716492 and perplexity is 45.93586937371816
At time: 582.0917522907257 and batch: 850, loss is 3.817078666687012 and perplexity is 45.47117763596335
At time: 583.3345074653625 and batch: 900, loss is 3.7808210611343385 and perplexity is 43.8520321576501
At time: 584.577210187912 and batch: 950, loss is 3.887541484832764 and perplexity is 48.79078606226694
At time: 585.8209583759308 and batch: 1000, loss is 3.828956713676453 and perplexity is 46.01450687763219
At time: 587.0755360126495 and batch: 1050, loss is 3.7934550189971925 and perplexity is 44.409571431942105
At time: 588.3448250293732 and batch: 1100, loss is 3.8096831607818604 and perplexity is 45.13613570259091
At time: 589.5916476249695 and batch: 1150, loss is 3.794622554779053 and perplexity is 44.46145147565637
At time: 590.8394560813904 and batch: 1200, loss is 3.822657809257507 and perplexity is 45.725576823625225
At time: 592.0843088626862 and batch: 1250, loss is 3.819431734085083 and perplexity is 45.57830036568435
At time: 593.3288326263428 and batch: 1300, loss is 3.7998059129714967 and perplexity is 44.69250941511925
At time: 594.5810265541077 and batch: 1350, loss is 3.667810125350952 and perplexity is 39.16604315532791
At time: 595.826268196106 and batch: 1400, loss is 3.685615749359131 and perplexity is 39.86966461360978
At time: 597.0729146003723 and batch: 1450, loss is 3.6197270011901854 and perplexity is 37.32737610170392
At time: 598.325220823288 and batch: 1500, loss is 3.6166662693023683 and perplexity is 37.21330167605183
At time: 599.5714707374573 and batch: 1550, loss is 3.6429136037826537 and perplexity is 38.202983084569034
At time: 600.8188078403473 and batch: 1600, loss is 3.7221890449523927 and perplexity is 41.35482266222169
At time: 602.0652675628662 and batch: 1650, loss is 3.679082531929016 and perplexity is 39.610036452909284
At time: 603.3116009235382 and batch: 1700, loss is 3.6702349948883057 and perplexity is 39.26113094141893
At time: 604.5560545921326 and batch: 1750, loss is 3.648594970703125 and perplexity is 38.42064597482598
At time: 605.8081493377686 and batch: 1800, loss is 3.6056832218170167 and perplexity is 36.8068224927763
At time: 607.056262254715 and batch: 1850, loss is 3.621461901664734 and perplexity is 37.39219159217177
At time: 608.3033640384674 and batch: 1900, loss is 3.7411498546600344 and perplexity is 42.14642457609633
At time: 609.5507938861847 and batch: 1950, loss is 3.6878496074676512 and perplexity is 39.958827338551174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328867641715116 and perplexity of 75.85833909795043
finished 12 epochs...
Completing Train Step...
At time: 613.4708721637726 and batch: 50, loss is 3.911444454193115 and perplexity is 49.97108080467319
At time: 614.7018990516663 and batch: 100, loss is 3.878928861618042 and perplexity is 48.37237380550749
At time: 615.9125788211823 and batch: 150, loss is 3.854740686416626 and perplexity is 47.2163715071502
At time: 617.1297755241394 and batch: 200, loss is 3.8409332513809202 and perplexity is 46.56891467023275
At time: 618.3528389930725 and batch: 250, loss is 3.847301549911499 and perplexity is 46.86642573526862
At time: 619.5969913005829 and batch: 300, loss is 3.854593348503113 and perplexity is 47.20941525796089
At time: 620.8255598545074 and batch: 350, loss is 3.8721832418441773 and perplexity is 48.047170247187374
At time: 622.0666785240173 and batch: 400, loss is 3.8080045318603517 and perplexity is 45.060432436417784
At time: 623.3087968826294 and batch: 450, loss is 3.832903208732605 and perplexity is 46.19646170729443
At time: 624.5593338012695 and batch: 500, loss is 3.850150351524353 and perplexity is 47.00012924144953
At time: 625.8077023029327 and batch: 550, loss is 3.8272527408599855 and perplexity is 45.936166172920515
At time: 627.0566928386688 and batch: 600, loss is 3.79324357509613 and perplexity is 44.40018229158724
At time: 628.3067364692688 and batch: 650, loss is 3.8338783264160154 and perplexity is 46.24153066421348
At time: 629.5627608299255 and batch: 700, loss is 3.8791945028305053 and perplexity is 48.385225208390466
At time: 630.8114304542542 and batch: 750, loss is 3.832344641685486 and perplexity is 46.170665091331756
At time: 632.0604996681213 and batch: 800, loss is 3.810978899002075 and perplexity is 45.19465822548041
At time: 633.3093686103821 and batch: 850, loss is 3.8022972631454466 and perplexity is 44.80399292078726
At time: 634.5582919120789 and batch: 900, loss is 3.7672326374053955 and perplexity is 43.260182422634315
At time: 635.8056004047394 and batch: 950, loss is 3.874444432258606 and perplexity is 48.155936972785874
At time: 637.0533518791199 and batch: 1000, loss is 3.815513973236084 and perplexity is 45.40008481584991
At time: 638.3019404411316 and batch: 1050, loss is 3.7807700967788698 and perplexity is 43.849797324044104
At time: 639.557042837143 and batch: 1100, loss is 3.7973077487945557 and perplexity is 44.58099953211114
At time: 640.8064420223236 and batch: 1150, loss is 3.783665018081665 and perplexity is 43.97692295701015
At time: 642.0557057857513 and batch: 1200, loss is 3.812058048248291 and perplexity is 45.243456332321834
At time: 643.3041517734528 and batch: 1250, loss is 3.809374508857727 and perplexity is 45.122206497206975
At time: 644.5535180568695 and batch: 1300, loss is 3.7908527994155885 and perplexity is 44.29415820595675
At time: 645.8038420677185 and batch: 1350, loss is 3.6606551218032837 and perplexity is 38.88681012551825
At time: 647.0523374080658 and batch: 1400, loss is 3.6799004554748533 and perplexity is 39.64244768752464
At time: 648.3017346858978 and batch: 1450, loss is 3.61582555770874 and perplexity is 37.18202916931702
At time: 649.5574612617493 and batch: 1500, loss is 3.61450382232666 and perplexity is 37.13291682969476
At time: 650.807639837265 and batch: 1550, loss is 3.642259273529053 and perplexity is 38.177993893442476
At time: 652.0571110248566 and batch: 1600, loss is 3.7226174592971804 and perplexity is 41.372543457126675
At time: 653.3068840503693 and batch: 1650, loss is 3.6809560441970826 and perplexity is 39.68431590214504
At time: 654.5611886978149 and batch: 1700, loss is 3.673282742500305 and perplexity is 39.380971488596565
At time: 655.8165593147278 and batch: 1750, loss is 3.6526634883880615 and perplexity is 38.57727946945206
At time: 657.0662667751312 and batch: 1800, loss is 3.6104261350631712 and perplexity is 36.98180870290369
At time: 658.314722776413 and batch: 1850, loss is 3.62679545879364 and perplexity is 37.592157773696655
At time: 659.5694949626923 and batch: 1900, loss is 3.7471718788146973 and perplexity is 42.40099711458001
At time: 660.8190517425537 and batch: 1950, loss is 3.6931087827682494 and perplexity is 40.169531395463125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327537075308866 and perplexity of 75.75747166060594
finished 13 epochs...
Completing Train Step...
At time: 664.6948683261871 and batch: 50, loss is 3.9069056415557863 and perplexity is 49.74478537637997
At time: 665.9259445667267 and batch: 100, loss is 3.872554316520691 and perplexity is 48.06500264371502
At time: 667.1347191333771 and batch: 150, loss is 3.84703736782074 and perplexity is 46.85404610024241
At time: 668.354430437088 and batch: 200, loss is 3.8319960832595825 and perplexity is 46.15457472136452
At time: 669.5812253952026 and batch: 250, loss is 3.837440004348755 and perplexity is 46.406521751697156
At time: 670.8064303398132 and batch: 300, loss is 3.8443026733398438 and perplexity is 46.72608963962185
At time: 672.0371341705322 and batch: 350, loss is 3.861994218826294 and perplexity is 47.560102111606206
At time: 673.2814898490906 and batch: 400, loss is 3.797668123245239 and perplexity is 44.597068280537734
At time: 674.5308036804199 and batch: 450, loss is 3.8232730054855346 and perplexity is 45.753715680583355
At time: 675.7802321910858 and batch: 500, loss is 3.8401105260849 and perplexity is 46.53061700251557
At time: 677.0290398597717 and batch: 550, loss is 3.8177763986587525 and perplexity is 45.5029154013319
At time: 678.2772884368896 and batch: 600, loss is 3.7844953680038453 and perplexity is 44.01345435638858
At time: 679.5264146327972 and batch: 650, loss is 3.825056824684143 and perplexity is 45.835404874737165
At time: 680.8164746761322 and batch: 700, loss is 3.870294508934021 and perplexity is 47.95650762119617
At time: 682.0645794868469 and batch: 750, loss is 3.8243746995925902 and perplexity is 45.80415005605053
At time: 683.312769651413 and batch: 800, loss is 3.8030804777145386 and perplexity is 44.8390978063307
At time: 684.5612781047821 and batch: 850, loss is 3.7949037981033324 and perplexity is 44.4739577206382
At time: 685.8095700740814 and batch: 900, loss is 3.760302686691284 and perplexity is 42.961427863367845
At time: 687.0592889785767 and batch: 950, loss is 3.867942066192627 and perplexity is 47.843825274289834
At time: 688.3128015995026 and batch: 1000, loss is 3.8087724924087523 and perplexity is 45.09505036172191
At time: 689.5625367164612 and batch: 1050, loss is 3.7745269250869753 and perplexity is 43.576888306058144
At time: 690.8112685680389 and batch: 1100, loss is 3.7912107944488525 and perplexity is 44.31001813331531
At time: 692.0595233440399 and batch: 1150, loss is 3.778173089027405 and perplexity is 43.73606680393535
At time: 693.30810379982 and batch: 1200, loss is 3.806821246147156 and perplexity is 45.007144604068344
At time: 694.5565025806427 and batch: 1250, loss is 3.8045003700256346 and perplexity is 44.90280971786495
At time: 695.8044111728668 and batch: 1300, loss is 3.786490321159363 and perplexity is 44.10134677752372
At time: 697.0534384250641 and batch: 1350, loss is 3.6567458295822144 and perplexity is 38.735086979476186
At time: 698.3012819290161 and batch: 1400, loss is 3.676470079421997 and perplexity is 39.50669216367478
At time: 699.549831867218 and batch: 1450, loss is 3.6129031419754027 and perplexity is 37.07352644453261
At time: 700.7988369464874 and batch: 1500, loss is 3.612357287406921 and perplexity is 37.053295212910584
At time: 702.0475265979767 and batch: 1550, loss is 3.641118016242981 and perplexity is 38.13444783309974
At time: 703.2956821918488 and batch: 1600, loss is 3.7216509866714476 and perplexity is 41.332577342607166
At time: 704.5436842441559 and batch: 1650, loss is 3.6804443359375 and perplexity is 39.664014304612586
At time: 705.7913181781769 and batch: 1700, loss is 3.67311619758606 and perplexity is 39.37441333420588
At time: 707.0392339229584 and batch: 1750, loss is 3.6528183317184446 and perplexity is 38.58325336637934
At time: 708.2886483669281 and batch: 1800, loss is 3.6108901405334475 and perplexity is 36.99897244616999
At time: 709.5385019779205 and batch: 1850, loss is 3.6275234603881836 and perplexity is 37.619534888580766
At time: 710.793240070343 and batch: 1900, loss is 3.7483259534835813 and perplexity is 42.449959278847786
At time: 712.0432851314545 and batch: 1950, loss is 3.6937632846832273 and perplexity is 40.19583103632904
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327482285610465 and perplexity of 75.75332104528853
finished 14 epochs...
Completing Train Step...
At time: 715.9148573875427 and batch: 50, loss is 3.901783709526062 and perplexity is 49.49064736126052
At time: 717.1523208618164 and batch: 100, loss is 3.866735591888428 and perplexity is 47.78613773474627
At time: 718.3612954616547 and batch: 150, loss is 3.84079496383667 and perplexity is 46.56247521464311
At time: 719.5811741352081 and batch: 200, loss is 3.825194754600525 and perplexity is 45.84172738432044
At time: 720.8022527694702 and batch: 250, loss is 3.8301628828048706 and perplexity is 46.07004164071288
At time: 722.0232903957367 and batch: 300, loss is 3.8368229150772093 and perplexity is 46.377893618959675
At time: 723.2458226680756 and batch: 350, loss is 3.854472584724426 and perplexity is 47.20371441481935
At time: 724.4895265102386 and batch: 400, loss is 3.7899386405944826 and perplexity is 44.25368481288255
At time: 725.7404589653015 and batch: 450, loss is 3.8161078023910524 and perplexity is 45.427052716221866
At time: 726.9899122714996 and batch: 500, loss is 3.8326617288589477 and perplexity is 46.1853075383658
At time: 728.2391676902771 and batch: 550, loss is 3.8107655382156373 and perplexity is 45.18501648627974
At time: 729.4884223937988 and batch: 600, loss is 3.7779390716552737 and perplexity is 43.72583300200496
At time: 730.7396614551544 and batch: 650, loss is 3.8184277629852295 and perplexity is 45.532564032156984
At time: 731.9896581172943 and batch: 700, loss is 3.8637346982955934 and perplexity is 47.64295157086624
At time: 733.2386932373047 and batch: 750, loss is 3.818335967063904 and perplexity is 45.52838452032534
At time: 734.4874124526978 and batch: 800, loss is 3.797205982208252 and perplexity is 44.576462906817106
At time: 735.7381675243378 and batch: 850, loss is 3.7892835521698 and perplexity is 44.22470422967076
At time: 736.9884080886841 and batch: 900, loss is 3.754960789680481 and perplexity is 42.73254422098965
At time: 738.2447032928467 and batch: 950, loss is 3.8628856897354127 and perplexity is 47.602519463181736
At time: 739.4947514533997 and batch: 1000, loss is 3.8034613132476807 and perplexity is 44.85617738009724
At time: 740.7431094646454 and batch: 1050, loss is 3.7696470165252687 and perplexity is 43.36475509203404
At time: 741.9912428855896 and batch: 1100, loss is 3.7864463710784912 and perplexity is 44.099408562358974
At time: 743.2793407440186 and batch: 1150, loss is 3.7737944602966307 and perplexity is 43.54498145644964
At time: 744.5274412631989 and batch: 1200, loss is 3.8026674699783327 and perplexity is 44.82058273574907
At time: 745.7772483825684 and batch: 1250, loss is 3.8006810426712034 and perplexity is 44.7316382763799
At time: 747.0254826545715 and batch: 1300, loss is 3.782962369918823 and perplexity is 43.94603350636572
At time: 748.2752568721771 and batch: 1350, loss is 3.6533553314208986 and perplexity is 38.60397812605365
At time: 749.5262396335602 and batch: 1400, loss is 3.673389058113098 and perplexity is 39.38515852328239
At time: 750.776426076889 and batch: 1450, loss is 3.610022120475769 and perplexity is 36.966870530542174
At time: 752.025456905365 and batch: 1500, loss is 3.6099528455734253 and perplexity is 36.9643097428964
At time: 753.2735085487366 and batch: 1550, loss is 3.6393614482879637 and perplexity is 38.067520882131305
At time: 754.5234122276306 and batch: 1600, loss is 3.7199356174468994 and perplexity is 41.26173748708689
At time: 755.780837059021 and batch: 1650, loss is 3.678840689659119 and perplexity is 39.60045823003906
At time: 757.0292899608612 and batch: 1700, loss is 3.6717317867279053 and perplexity is 39.319940683817045
At time: 758.2782859802246 and batch: 1750, loss is 3.651581811904907 and perplexity is 38.53557389350261
At time: 759.526417016983 and batch: 1800, loss is 3.609923415184021 and perplexity is 36.96322188487473
At time: 760.7746884822845 and batch: 1850, loss is 3.626789584159851 and perplexity is 37.591936934185085
At time: 762.0242512226105 and batch: 1900, loss is 3.7479811573028563 and perplexity is 42.43532521804562
At time: 763.2719125747681 and batch: 1950, loss is 3.6930751991271973 and perplexity is 40.16818237899208
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327842251090116 and perplexity of 75.78059453429655
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 767.1716639995575 and batch: 50, loss is 3.9033697652816772 and perplexity is 49.56920456894464
At time: 768.37810587883 and batch: 100, loss is 3.8790231370925903 and perplexity is 48.37693434897336
At time: 769.585419178009 and batch: 150, loss is 3.860041255950928 and perplexity is 47.46730963745521
At time: 770.8054473400116 and batch: 200, loss is 3.8493668603897095 and perplexity is 46.963319478806106
At time: 772.0319924354553 and batch: 250, loss is 3.8572517108917235 and perplexity is 47.33508195167092
At time: 773.270304441452 and batch: 300, loss is 3.8634221935272217 and perplexity is 47.62806524746571
At time: 774.5301067829132 and batch: 350, loss is 3.8872455501556398 and perplexity is 48.77634931301969
At time: 775.7668809890747 and batch: 400, loss is 3.8241854763031005 and perplexity is 45.7954836640721
At time: 777.0080676078796 and batch: 450, loss is 3.8562155961990356 and perplexity is 47.28606277691012
At time: 778.2463212013245 and batch: 500, loss is 3.8809299659729004 and perplexity is 48.4692688896379
At time: 779.4858093261719 and batch: 550, loss is 3.85879891872406 and perplexity is 47.4083758470341
At time: 780.7250933647156 and batch: 600, loss is 3.8156305837631224 and perplexity is 45.405379252355395
At time: 781.9634535312653 and batch: 650, loss is 3.8431892824172973 and perplexity is 46.67409418657502
At time: 783.2069547176361 and batch: 700, loss is 3.878677978515625 and perplexity is 48.36023951650358
At time: 784.4534678459167 and batch: 750, loss is 3.8338576698303224 and perplexity is 46.240575481938166
At time: 785.7072224617004 and batch: 800, loss is 3.814965019226074 and perplexity is 45.37516909665314
At time: 786.9535055160522 and batch: 850, loss is 3.81015531539917 and perplexity is 45.15745196936128
At time: 788.2005760669708 and batch: 900, loss is 3.7704667139053343 and perplexity is 43.40031564062331
At time: 789.4484519958496 and batch: 950, loss is 3.878918080329895 and perplexity is 48.371852291818435
At time: 790.6963109970093 and batch: 1000, loss is 3.819412317276001 and perplexity is 45.577415389119594
At time: 791.9466564655304 and batch: 1050, loss is 3.7809462976455688 and perplexity is 43.85752437707391
At time: 793.1922218799591 and batch: 1100, loss is 3.795118489265442 and perplexity is 44.483506911331595
At time: 794.4433484077454 and batch: 1150, loss is 3.7872303915023804 and perplexity is 44.13399695658529
At time: 795.692699432373 and batch: 1200, loss is 3.81841001033783 and perplexity is 45.531755715777415
At time: 796.9398136138916 and batch: 1250, loss is 3.8204040241241457 and perplexity is 45.62263724378696
At time: 798.1857016086578 and batch: 1300, loss is 3.8062342977523804 and perplexity is 44.98073548394308
At time: 799.4381453990936 and batch: 1350, loss is 3.671085014343262 and perplexity is 39.294517854295194
At time: 800.6847035884857 and batch: 1400, loss is 3.6914364290237427 and perplexity is 40.102409870329396
At time: 801.9311351776123 and batch: 1450, loss is 3.6271793460845947 and perplexity is 37.60659169562788
At time: 803.184068441391 and batch: 1500, loss is 3.6209471082687377 and perplexity is 37.37294729272242
At time: 804.4302453994751 and batch: 1550, loss is 3.652143144607544 and perplexity is 38.55721124365188
At time: 805.67622423172 and batch: 1600, loss is 3.7313535404205322 and perplexity is 41.73556071840938
At time: 806.9222950935364 and batch: 1650, loss is 3.683764033317566 and perplexity is 39.79590562749756
At time: 808.1677076816559 and batch: 1700, loss is 3.6703572273254395 and perplexity is 39.265930218446215
At time: 809.4141147136688 and batch: 1750, loss is 3.6432873964309693 and perplexity is 38.21726574800077
At time: 810.6611771583557 and batch: 1800, loss is 3.6051422786712646 and perplexity is 36.78691747865778
At time: 811.9076728820801 and batch: 1850, loss is 3.6211489486694335 and perplexity is 37.38049142470887
At time: 813.1531536579132 and batch: 1900, loss is 3.73772910118103 and perplexity is 42.00249835600579
At time: 814.3988118171692 and batch: 1950, loss is 3.690061492919922 and perplexity is 40.047309507567874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320541026980378 and perplexity of 75.22931837477047
finished 16 epochs...
Completing Train Step...
At time: 818.2985315322876 and batch: 50, loss is 3.9097714614868164 and perplexity is 49.88754944412261
At time: 819.51345038414 and batch: 100, loss is 3.8782509851455687 and perplexity is 48.339594422828426
At time: 820.7383663654327 and batch: 150, loss is 3.855998687744141 and perplexity is 47.27580714240225
At time: 821.959358215332 and batch: 200, loss is 3.8435365343093872 and perplexity is 46.690304668490256
At time: 823.1891531944275 and batch: 250, loss is 3.848341326713562 and perplexity is 46.915181700812084
At time: 824.4302098751068 and batch: 300, loss is 3.852238335609436 and perplexity is 47.09836728735021
At time: 825.6696469783783 and batch: 350, loss is 3.8746517848968507 and perplexity is 48.16592326867095
At time: 826.9116065502167 and batch: 400, loss is 3.81178279876709 and perplexity is 45.23100480815501
At time: 828.1612277030945 and batch: 450, loss is 3.8440616369247436 and perplexity is 46.71482830773352
At time: 829.4096496105194 and batch: 500, loss is 3.8678442907333372 and perplexity is 47.83914755098645
At time: 830.6571929454803 and batch: 550, loss is 3.8468809795379637 and perplexity is 46.846719249363424
At time: 831.9116864204407 and batch: 600, loss is 3.805225257873535 and perplexity is 44.93537101918602
At time: 833.1587131023407 and batch: 650, loss is 3.8341619873046877 and perplexity is 46.254649438448865
At time: 834.4075829982758 and batch: 700, loss is 3.871440029144287 and perplexity is 48.011474246569485
At time: 835.6743648052216 and batch: 750, loss is 3.8267510986328124 and perplexity is 45.913128431048925
At time: 836.9229426383972 and batch: 800, loss is 3.8082492113113404 and perplexity is 45.071459147237405
At time: 838.1710336208344 and batch: 850, loss is 3.802917728424072 and perplexity is 44.831800868779375
At time: 839.420670747757 and batch: 900, loss is 3.7631315755844117 and perplexity is 43.08313303352221
At time: 840.6693317890167 and batch: 950, loss is 3.8707901430130005 and perplexity is 47.98028239198869
At time: 841.916698217392 and batch: 1000, loss is 3.8109812688827516 and perplexity is 45.194765331554535
At time: 843.1651735305786 and batch: 1050, loss is 3.7736264133453368 and perplexity is 43.5376644698876
At time: 844.4168365001678 and batch: 1100, loss is 3.789516234397888 and perplexity is 44.23499572966561
At time: 845.6703357696533 and batch: 1150, loss is 3.782634344100952 and perplexity is 43.93162043684131
At time: 846.9198644161224 and batch: 1200, loss is 3.813898196220398 and perplexity is 45.326787634191625
At time: 848.16819024086 and batch: 1250, loss is 3.816658034324646 and perplexity is 45.45205500917458
At time: 849.4162352085114 and batch: 1300, loss is 3.802781524658203 and perplexity is 44.82569502449929
At time: 850.6654620170593 and batch: 1350, loss is 3.6684474039077757 and perplexity is 39.19101078961041
At time: 851.9182155132294 and batch: 1400, loss is 3.6894666576385498 and perplexity is 40.02349503849414
At time: 853.1700313091278 and batch: 1450, loss is 3.625559244155884 and perplexity is 37.545714510827324
At time: 854.4193651676178 and batch: 1500, loss is 3.620559964179993 and perplexity is 37.358481377476544
At time: 855.6676969528198 and batch: 1550, loss is 3.6522430849075316 and perplexity is 38.561064855472615
At time: 856.9165923595428 and batch: 1600, loss is 3.7319478178024292 and perplexity is 41.76037058940754
At time: 858.1654274463654 and batch: 1650, loss is 3.6854957580566405 and perplexity is 39.86488088763142
At time: 859.4175035953522 and batch: 1700, loss is 3.672892689704895 and perplexity is 39.365613825925806
At time: 860.6657366752625 and batch: 1750, loss is 3.646945581436157 and perplexity is 38.35732760639849
At time: 861.9147822856903 and batch: 1800, loss is 3.6089916753768922 and perplexity is 36.92879781927138
At time: 863.1639564037323 and batch: 1850, loss is 3.62488667011261 and perplexity is 37.52047072791933
At time: 864.4146854877472 and batch: 1900, loss is 3.741531324386597 and perplexity is 42.16250522810092
At time: 865.6633856296539 and batch: 1950, loss is 3.6936531496047973 and perplexity is 40.19140430909874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.319347008993459 and perplexity of 75.13954682057798
finished 17 epochs...
Completing Train Step...
At time: 869.5489010810852 and batch: 50, loss is 3.909604911804199 and perplexity is 49.879241380468024
At time: 870.7484667301178 and batch: 100, loss is 3.8762417459487915 and perplexity is 48.24256612413051
At time: 871.9663259983063 and batch: 150, loss is 3.8532420015335083 and perplexity is 47.145662043773484
At time: 873.1868278980255 and batch: 200, loss is 3.8401673460006713 and perplexity is 46.53326094336799
At time: 874.4062385559082 and batch: 250, loss is 3.84418821811676 and perplexity is 46.720741900652484
At time: 875.6339628696442 and batch: 300, loss is 3.847641501426697 and perplexity is 46.88236075612302
At time: 876.8654644489288 and batch: 350, loss is 3.8698640394210817 and perplexity is 47.93586824934709
At time: 878.1135411262512 and batch: 400, loss is 3.8072862339019777 and perplexity is 45.02807724152162
At time: 879.3615493774414 and batch: 450, loss is 3.8399609613418577 and perplexity is 46.52365818314999
At time: 880.6170568466187 and batch: 500, loss is 3.8637807512283326 and perplexity is 47.64514571903352
At time: 881.8651239871979 and batch: 550, loss is 3.8431945562362673 and perplexity is 46.67434033794743
At time: 883.1134932041168 and batch: 600, loss is 3.801981191635132 and perplexity is 44.789833892827204
At time: 884.3609764575958 and batch: 650, loss is 3.8307148742675783 and perplexity is 46.09547893032261
At time: 885.6088280677795 and batch: 700, loss is 3.868152322769165 and perplexity is 47.8538858108104
At time: 886.8626651763916 and batch: 750, loss is 3.8235892391204835 and perplexity is 45.76818683241732
At time: 888.1109511852264 and batch: 800, loss is 3.8051068925857545 and perplexity is 44.93005254583134
At time: 889.3607149124146 and batch: 850, loss is 3.7995712757110596 and perplexity is 44.6820241173169
At time: 890.614440202713 and batch: 900, loss is 3.759908471107483 and perplexity is 42.94449513679339
At time: 891.8685803413391 and batch: 950, loss is 3.86747670173645 and perplexity is 47.821565638383035
At time: 893.1166377067566 and batch: 1000, loss is 3.8078158378601072 and perplexity is 45.0519306053161
At time: 894.3639945983887 and batch: 1050, loss is 3.770920786857605 and perplexity is 43.420027024940296
At time: 895.6123080253601 and batch: 1100, loss is 3.787280740737915 and perplexity is 44.13621912553493
At time: 896.8601939678192 and batch: 1150, loss is 3.780762677192688 and perplexity is 43.84947197790077
At time: 898.127614736557 and batch: 1200, loss is 3.8119735765457152 and perplexity is 45.23963470194711
At time: 899.3752267360687 and batch: 1250, loss is 3.814911026954651 and perplexity is 45.372719254344275
At time: 900.6241676807404 and batch: 1300, loss is 3.8012065076828003 and perplexity is 44.755149363791475
At time: 901.8724608421326 and batch: 1350, loss is 3.6672960758209228 and perplexity is 39.145915043117355
At time: 903.1194615364075 and batch: 1400, loss is 3.688558006286621 and perplexity is 39.98714415326009
At time: 904.3677263259888 and batch: 1450, loss is 3.6247103929519655 and perplexity is 37.51385730878787
At time: 905.6220455169678 and batch: 1500, loss is 3.6201745796203615 and perplexity is 37.344086769490374
At time: 906.872447013855 and batch: 1550, loss is 3.652196516990662 and perplexity is 38.559269188820565
At time: 908.1214776039124 and batch: 1600, loss is 3.732023210525513 and perplexity is 41.76351913615053
At time: 909.3691115379333 and batch: 1650, loss is 3.6860069036483765 and perplexity is 39.88526285439468
At time: 910.6238338947296 and batch: 1700, loss is 3.673556299209595 and perplexity is 39.391745891203485
At time: 911.8706564903259 and batch: 1750, loss is 3.648037986755371 and perplexity is 38.39925225028932
At time: 913.1187217235565 and batch: 1800, loss is 3.610098705291748 and perplexity is 36.96970173993151
At time: 914.3671472072601 and batch: 1850, loss is 3.625905771255493 and perplexity is 37.558727372903974
At time: 915.6151165962219 and batch: 1900, loss is 3.742514715194702 and perplexity is 42.20398784165635
At time: 916.8633875846863 and batch: 1950, loss is 3.694365873336792 and perplexity is 40.220059887314335
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318855605014535 and perplexity of 75.10263201907878
finished 18 epochs...
Completing Train Step...
At time: 920.7148241996765 and batch: 50, loss is 3.908123245239258 and perplexity is 49.805391700041525
At time: 921.9468059539795 and batch: 100, loss is 3.874042925834656 and perplexity is 48.136605935767435
At time: 923.156131029129 and batch: 150, loss is 3.8507351016998292 and perplexity is 47.027620612279485
At time: 924.3728792667389 and batch: 200, loss is 3.8375041818618776 and perplexity is 46.40950010242639
At time: 925.59832239151 and batch: 250, loss is 3.8412426233291628 and perplexity is 46.58332401490041
At time: 926.824380159378 and batch: 300, loss is 3.8445334959030153 and perplexity is 46.736876320256194
At time: 928.0491781234741 and batch: 350, loss is 3.8667366313934326 and perplexity is 47.78618740870142
At time: 929.3041973114014 and batch: 400, loss is 3.804216547012329 and perplexity is 44.890067075518054
At time: 930.5424604415894 and batch: 450, loss is 3.837176647186279 and perplexity is 46.39430187097543
At time: 931.7794313430786 and batch: 500, loss is 3.8610682392120363 and perplexity is 47.516082810232014
At time: 933.0172786712646 and batch: 550, loss is 3.840697555541992 and perplexity is 46.557939864230434
At time: 934.2619986534119 and batch: 600, loss is 3.7997154140472413 and perplexity is 44.688464974106445
At time: 935.5072841644287 and batch: 650, loss is 3.8283384084701537 and perplexity is 45.98606466235548
At time: 936.7537822723389 and batch: 700, loss is 3.8657268476486206 and perplexity is 47.73795804813987
At time: 937.9994685649872 and batch: 750, loss is 3.821277046203613 and perplexity is 45.66248420453175
At time: 939.2447905540466 and batch: 800, loss is 3.8027820014953613 and perplexity is 44.82571639906141
At time: 940.4895703792572 and batch: 850, loss is 3.797177414894104 and perplexity is 44.5751894951867
At time: 941.7406005859375 and batch: 900, loss is 3.7576639556884768 and perplexity is 42.84821364836106
At time: 942.9897601604462 and batch: 950, loss is 3.865264058113098 and perplexity is 47.71587053203786
At time: 944.2346465587616 and batch: 1000, loss is 3.8057435607910155 and perplexity is 44.95866718979841
At time: 945.4807453155518 and batch: 1050, loss is 3.7691155815124513 and perplexity is 43.341715665377116
At time: 946.7251799106598 and batch: 1100, loss is 3.785667200088501 and perplexity is 44.06506096559467
At time: 947.9694261550903 and batch: 1150, loss is 3.779314818382263 and perplexity is 43.786030072108964
At time: 949.2137823104858 and batch: 1200, loss is 3.8104873275756836 and perplexity is 45.172447282450975
At time: 950.4569907188416 and batch: 1250, loss is 3.8135202360153198 and perplexity is 45.30965914938858
At time: 951.7089433670044 and batch: 1300, loss is 3.7999722814559935 and perplexity is 44.6999454587235
At time: 952.9547905921936 and batch: 1350, loss is 3.6663423681259157 and perplexity is 39.10859907980174
At time: 954.1986355781555 and batch: 1400, loss is 3.687759418487549 and perplexity is 39.955223655176134
At time: 955.4443020820618 and batch: 1450, loss is 3.623928737640381 and perplexity is 37.48454586018158
At time: 956.6901235580444 and batch: 1500, loss is 3.619669337272644 and perplexity is 37.32522372102431
At time: 957.9347267150879 and batch: 1550, loss is 3.6519347763061525 and perplexity is 38.54917798000647
At time: 959.1804993152618 and batch: 1600, loss is 3.7318373823165896 and perplexity is 41.75575901723795
At time: 960.4263710975647 and batch: 1650, loss is 3.686020188331604 and perplexity is 39.885792720996704
At time: 961.679169178009 and batch: 1700, loss is 3.6736280727386474 and perplexity is 39.39457327728616
At time: 962.9255530834198 and batch: 1750, loss is 3.648297739028931 and perplexity is 38.40922783889915
At time: 964.1703226566315 and batch: 1800, loss is 3.6103782510757445 and perplexity is 36.980037908837424
At time: 965.4166784286499 and batch: 1850, loss is 3.6261277294158933 and perplexity is 37.56706476418042
At time: 966.6644804477692 and batch: 1900, loss is 3.7427525424957278 and perplexity is 42.21402629583917
At time: 967.9094543457031 and batch: 1950, loss is 3.694345307350159 and perplexity is 40.21923273060598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318585347020349 and perplexity of 75.08233767486915
finished 19 epochs...
Completing Train Step...
At time: 971.7877032756805 and batch: 50, loss is 3.906453776359558 and perplexity is 49.72231251690844
At time: 973.0165402889252 and batch: 100, loss is 3.87200074672699 and perplexity is 48.03840267326664
At time: 974.2277550697327 and batch: 150, loss is 3.848522605895996 and perplexity is 46.92368721750781
At time: 975.448100566864 and batch: 200, loss is 3.8352509260177614 and perplexity is 46.30504535093218
At time: 976.6684815883636 and batch: 250, loss is 3.838842897415161 and perplexity is 46.47167082720674
At time: 977.8982179164886 and batch: 300, loss is 3.842038083076477 and perplexity is 46.62039391590271
At time: 979.126772403717 and batch: 350, loss is 3.864248104095459 and perplexity is 47.667418018596095
At time: 980.3561818599701 and batch: 400, loss is 3.8016863536834715 and perplexity is 44.77663009653282
At time: 981.5962703227997 and batch: 450, loss is 3.8348741817474363 and perplexity is 46.28760347617857
At time: 982.8417181968689 and batch: 500, loss is 3.858806109428406 and perplexity is 47.40871674787399
At time: 984.0907244682312 and batch: 550, loss is 3.8385847091674803 and perplexity is 46.459673936743776
At time: 985.3391389846802 and batch: 600, loss is 3.7977726554870603 and perplexity is 44.601730355728094
At time: 986.588446855545 and batch: 650, loss is 3.826362814903259 and perplexity is 45.89530457088764
At time: 987.8377792835236 and batch: 700, loss is 3.8636865758895875 and perplexity is 47.640658932571505
At time: 989.0869309902191 and batch: 750, loss is 3.8193274402618407 and perplexity is 45.57354707835588
At time: 990.3354971408844 and batch: 800, loss is 3.800825972557068 and perplexity is 44.73812169741921
At time: 991.6041033267975 and batch: 850, loss is 3.7952102327346804 and perplexity is 44.487588169791074
At time: 992.8518788814545 and batch: 900, loss is 3.7558242321014403 and perplexity is 42.7694572462682
At time: 994.10027551651 and batch: 950, loss is 3.8634696769714356 and perplexity is 47.63032684573872
At time: 995.3484053611755 and batch: 1000, loss is 3.804051260948181 and perplexity is 44.882647986164734
At time: 996.5961902141571 and batch: 1050, loss is 3.7676095247268675 and perplexity is 43.276489709725816
At time: 997.8443765640259 and batch: 1100, loss is 3.784252700805664 and perplexity is 44.00277503055108
At time: 999.0938408374786 and batch: 1150, loss is 3.7779981088638306 and perplexity is 43.72841452932956
At time: 1000.3434772491455 and batch: 1200, loss is 3.80914267539978 and perplexity is 45.111746872536855
At time: 1001.5962646007538 and batch: 1250, loss is 3.812252345085144 and perplexity is 45.25224784682957
At time: 1002.8465187549591 and batch: 1300, loss is 3.7988498401641846 and perplexity is 44.649800541826366
At time: 1004.095232963562 and batch: 1350, loss is 3.6654276609420777 and perplexity is 39.072842519158144
At time: 1005.3437669277191 and batch: 1400, loss is 3.6869721031188964 and perplexity is 39.92377867371736
At time: 1006.5921745300293 and batch: 1450, loss is 3.6231530475616456 and perplexity is 37.4554807440704
At time: 1007.8405015468597 and batch: 1500, loss is 3.6190897035598755 and perplexity is 37.30359503198319
At time: 1009.0895247459412 and batch: 1550, loss is 3.6515397310256956 and perplexity is 38.53395231679118
At time: 1010.3470771312714 and batch: 1600, loss is 3.7314951276779174 and perplexity is 41.741470360342056
At time: 1011.5945851802826 and batch: 1650, loss is 3.6857897281646728 and perplexity is 39.87660169367155
At time: 1012.8447079658508 and batch: 1700, loss is 3.6734357976913454 and perplexity is 39.38699941200182
At time: 1014.0914058685303 and batch: 1750, loss is 3.648205771446228 and perplexity is 38.40569559748967
At time: 1015.3403432369232 and batch: 1800, loss is 3.6103116703033447 and perplexity is 36.9775758313145
At time: 1016.5894486904144 and batch: 1850, loss is 3.6260260152816772 and perplexity is 37.56324385703632
At time: 1017.8376071453094 and batch: 1900, loss is 3.7427006435394286 and perplexity is 42.21183548878402
At time: 1019.0872378349304 and batch: 1950, loss is 3.694065155982971 and perplexity is 40.20796683572087
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318421261809593 and perplexity of 75.07001878436925
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc433bcbb38>
ELAPSED
6310.786228179932


RESULTS SO FAR:
[{'best_accuracy': -75.2531559304004, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.96225198742506, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7460609200881098, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.7558732386815785, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -73.92024548433339, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.06428528362550812, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.41802598995097096, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -74.73450121070549, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.47589954029325743, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.2146320946900251, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.68560997706946, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.9183464086206847, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.17881090566881874, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.07001878436925, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.0, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.0, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -75.2531559304004, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.49490296198819195, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.872928551783885, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.96225198742506, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7460609200881098, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.7558732386815785, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -73.92024548433339, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.06428528362550812, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.41802598995097096, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -74.73450121070549, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.47589954029325743, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.2146320946900251, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.68560997706946, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.9183464086206847, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.17881090566881874, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}, {'best_accuracy': -75.07001878436925, 'params': {'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.0, 'wordvec_dim': 300, 'wordvec_source': 'gigavec', 'tie_weights': 'TRUE', 'dropout': 0.0, 'tune_wordvecs': 'FALSE', 'num_layers': 2, 'seq_len': 35}}]
Exception ignored in: <bound method DropoutDescriptor.__del__ of <torch.backends.cudnn.DropoutDescriptor object at 0x7fc426706358>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 215, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroyDropoutDescriptor'
Exception ignored in: <bound method CuDNNHandle.__del__ of <torch.backends.cudnn.CuDNNHandle object at 0x7fc4267062e8>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 91, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroy'
