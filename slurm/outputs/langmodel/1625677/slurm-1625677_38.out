TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8972136974334717 and batch: 50, loss is 7.819522428512573 and perplexity is 2488.716584111994
At time: 3.121567726135254 and batch: 100, loss is 6.960750036239624 and perplexity is 1054.4241170307193
At time: 4.359941005706787 and batch: 150, loss is 6.724497900009156 and perplexity is 832.5538463049895
At time: 5.5881712436676025 and batch: 200, loss is 6.6302667999267575 and perplexity is 757.6842937914786
At time: 6.812429904937744 and batch: 250, loss is 6.6122309112548825 and perplexity is 744.1412814703978
At time: 8.03883147239685 and batch: 300, loss is 6.558292093276978 and perplexity is 705.0664779116873
At time: 9.264122724533081 and batch: 350, loss is 6.519360704421997 and perplexity is 678.1447118159198
At time: 10.489291667938232 and batch: 400, loss is 6.488951148986817 and perplexity is 657.8330324088757
At time: 11.713411331176758 and batch: 450, loss is 6.419676551818847 and perplexity is 613.804548049715
At time: 12.940548419952393 and batch: 500, loss is 6.430075845718384 and perplexity is 620.220987335166
At time: 14.168067693710327 and batch: 550, loss is 6.3738940334320064 and perplexity is 586.3366035360327
At time: 15.3944993019104 and batch: 600, loss is 6.428741407394409 and perplexity is 619.3938926564869
At time: 16.619874238967896 and batch: 650, loss is 6.518325338363647 and perplexity is 677.4429471530027
At time: 17.84447193145752 and batch: 700, loss is 6.408612794876099 and perplexity is 607.0509924584271
At time: 19.070216417312622 and batch: 750, loss is 6.343800439834594 and perplexity is 568.9544850684936
At time: 20.294906616210938 and batch: 800, loss is 6.3538675880432125 and perplexity is 574.7111622361123
At time: 21.520976781845093 and batch: 850, loss is 6.409127988815308 and perplexity is 607.363822027562
At time: 22.747629165649414 and batch: 900, loss is 6.3997181797027585 and perplexity is 601.6754496224435
At time: 23.974201440811157 and batch: 950, loss is 6.4174830436706545 and perplexity is 612.4596383466164
At time: 25.19893455505371 and batch: 1000, loss is 6.407922458648682 and perplexity is 606.6320677825208
At time: 26.423480987548828 and batch: 1050, loss is 6.313015003204345 and perplexity is 551.7058386311471
At time: 27.644354343414307 and batch: 1100, loss is 6.386777639389038 and perplexity is 593.9396051662021
At time: 28.864272117614746 and batch: 1150, loss is 6.289598388671875 and perplexity is 538.9368424747335
At time: 30.085312128067017 and batch: 1200, loss is 6.377330303192139 and perplexity is 588.3548799611707
At time: 31.309707403182983 and batch: 1250, loss is 6.312206468582153 and perplexity is 551.2599456435985
At time: 32.535929679870605 and batch: 1300, loss is 6.335908346176147 and perplexity is 564.4819151697371
At time: 33.76235747337341 and batch: 1350, loss is 6.346334104537964 and perplexity is 570.3978526978073
At time: 34.987393617630005 and batch: 1400, loss is 6.3578503227233885 and perplexity is 577.0046484549462
At time: 36.21365666389465 and batch: 1450, loss is 6.364952974319458 and perplexity is 581.1175002285435
At time: 37.4402391910553 and batch: 1500, loss is 6.334833383560181 and perplexity is 563.8754442387301
At time: 38.6675386428833 and batch: 1550, loss is 6.317524709701538 and perplexity is 554.1994886247442
At time: 39.89561605453491 and batch: 1600, loss is 6.307789239883423 and perplexity is 548.830274548312
At time: 41.122376680374146 and batch: 1650, loss is 6.297185287475586 and perplexity is 543.0412519420008
At time: 42.34752297401428 and batch: 1700, loss is 6.328277177810669 and perplexity is 560.1906531323837
At time: 43.57498908042908 and batch: 1750, loss is 6.347733774185181 and perplexity is 571.1967802459559
At time: 44.801236629486084 and batch: 1800, loss is 6.357205018997193 and perplexity is 576.6324253166716
At time: 46.02761101722717 and batch: 1850, loss is 6.3025087547302245 and perplexity is 545.93982264245
At time: 47.253217697143555 and batch: 1900, loss is 6.259445266723633 and perplexity is 522.9287736410358
At time: 48.48125219345093 and batch: 1950, loss is 6.205997200012207 and perplexity is 495.7130345957724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.702330123546512 and perplexity of 299.5646109125367
finished 1 epochs...
Completing Train Step...
At time: 52.172990560531616 and batch: 50, loss is 6.005878763198853 and perplexity is 405.80744073875246
At time: 53.35938835144043 and batch: 100, loss is 5.887439632415772 and perplexity is 360.4811375800077
At time: 54.51925754547119 and batch: 150, loss is 5.732519798278808 and perplexity is 308.7462673389952
At time: 55.678990840911865 and batch: 200, loss is 5.661657218933105 and perplexity is 287.62490524989073
At time: 56.837483406066895 and batch: 250, loss is 5.611334266662598 and perplexity is 273.5089284986875
At time: 58.019577980041504 and batch: 300, loss is 5.583965120315551 and perplexity is 266.12473310387907
At time: 59.17735981941223 and batch: 350, loss is 5.515323295593261 and perplexity is 248.47029361479335
At time: 60.331926107406616 and batch: 400, loss is 5.463114013671875 and perplexity is 235.83066202245723
At time: 61.488075733184814 and batch: 450, loss is 5.390192747116089 and perplexity is 219.24564044648048
At time: 62.64499068260193 and batch: 500, loss is 5.359745454788208 and perplexity is 212.67080522398655
At time: 63.80104660987854 and batch: 550, loss is 5.305237741470337 and perplexity is 201.3888752100981
At time: 64.95938491821289 and batch: 600, loss is 5.32252537727356 and perplexity is 204.90068068481241
At time: 66.11590671539307 and batch: 650, loss is 5.391118021011352 and perplexity is 219.4485965947691
At time: 67.27141213417053 and batch: 700, loss is 5.316908445358276 and perplexity is 203.75299376909476
At time: 68.42633271217346 and batch: 750, loss is 5.251526145935059 and perplexity is 190.85732243352612
At time: 69.58204770088196 and batch: 800, loss is 5.229524297714233 and perplexity is 186.7039668881385
At time: 70.74651145935059 and batch: 850, loss is 5.227126121520996 and perplexity is 186.25675434114206
At time: 71.90485739707947 and batch: 900, loss is 5.242977266311645 and perplexity is 189.23266057276436
At time: 73.0671374797821 and batch: 950, loss is 5.275730047225952 and perplexity is 195.53317286910826
At time: 74.22606134414673 and batch: 1000, loss is 5.238365535736084 and perplexity is 188.361979741951
At time: 75.38470077514648 and batch: 1050, loss is 5.1369227695465085 and perplexity is 170.19124401514608
At time: 76.54555177688599 and batch: 1100, loss is 5.219955024719238 and perplexity is 184.92586679086975
At time: 77.70084190368652 and batch: 1150, loss is 5.111589984893799 and perplexity is 165.93397775799335
At time: 78.85681772232056 and batch: 1200, loss is 5.193021078109741 and perplexity is 180.01156127078565
At time: 80.01232838630676 and batch: 1250, loss is 5.12450945854187 and perplexity is 168.09166549382107
At time: 81.1705117225647 and batch: 1300, loss is 5.155300445556641 and perplexity is 173.34788053628614
At time: 82.33014464378357 and batch: 1350, loss is 5.081711139678955 and perplexity is 161.04939830250038
At time: 83.489506483078 and batch: 1400, loss is 5.092547225952148 and perplexity is 162.80403299402096
At time: 84.65080952644348 and batch: 1450, loss is 5.033683261871338 and perplexity is 153.49734368155129
At time: 85.81109070777893 and batch: 1500, loss is 5.004590806961059 and perplexity is 149.09606160389987
At time: 86.9714708328247 and batch: 1550, loss is 4.987068243026734 and perplexity is 146.50627246872367
At time: 88.13222098350525 and batch: 1600, loss is 5.0422946548461915 and perplexity is 154.82487738206507
At time: 89.29322338104248 and batch: 1650, loss is 5.001816177368164 and perplexity is 148.68294864194587
At time: 90.45334315299988 and batch: 1700, loss is 5.023734292984009 and perplexity is 151.97777498993278
At time: 91.61337566375732 and batch: 1750, loss is 5.038095960617065 and perplexity is 154.17617786133803
At time: 92.7726480960846 and batch: 1800, loss is 4.98610556602478 and perplexity is 146.36530211492186
At time: 93.93309044837952 and batch: 1850, loss is 4.980255670547486 and perplexity is 145.51157992346089
At time: 95.09172201156616 and batch: 1900, loss is 5.0329567813873295 and perplexity is 153.3858713531577
At time: 96.25187063217163 and batch: 1950, loss is 4.950712900161744 and perplexity is 141.2756434590559
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.764892578125 and perplexity of 117.31851403613837
finished 2 epochs...
Completing Train Step...
At time: 99.90310525894165 and batch: 50, loss is 4.949566373825073 and perplexity is 141.11376003263925
At time: 101.08569717407227 and batch: 100, loss is 4.888383283615112 and perplexity is 132.73879949124077
At time: 102.24649453163147 and batch: 150, loss is 4.828660163879395 and perplexity is 125.04331082371375
At time: 103.40728545188904 and batch: 200, loss is 4.813710355758667 and perplexity is 123.18784133403106
At time: 104.56763768196106 and batch: 250, loss is 4.822216186523438 and perplexity is 124.24012519459974
At time: 105.72918796539307 and batch: 300, loss is 4.848292207717895 and perplexity is 127.52242196904204
At time: 106.88974714279175 and batch: 350, loss is 4.836648578643799 and perplexity is 126.04620910449998
At time: 108.05173468589783 and batch: 400, loss is 4.807213382720947 and perplexity is 122.39008754886616
At time: 109.21217179298401 and batch: 450, loss is 4.787270727157593 and perplexity is 119.97348105572412
At time: 110.37452054023743 and batch: 500, loss is 4.791680755615235 and perplexity is 120.50373588139615
At time: 111.53481006622314 and batch: 550, loss is 4.749063291549683 and perplexity is 115.47606644345666
At time: 112.69477534294128 and batch: 600, loss is 4.729343767166138 and perplexity is 113.2212384702677
At time: 113.8557801246643 and batch: 650, loss is 4.787449159622192 and perplexity is 119.99489012961556
At time: 115.05706405639648 and batch: 700, loss is 4.786520795822144 and perplexity is 119.88354291078912
At time: 116.21610569953918 and batch: 750, loss is 4.749320678710937 and perplexity is 115.50579232575751
At time: 117.37505006790161 and batch: 800, loss is 4.726440916061401 and perplexity is 112.89305064374943
At time: 118.53464603424072 and batch: 850, loss is 4.725145845413208 and perplexity is 112.74694079918271
At time: 119.69651484489441 and batch: 900, loss is 4.73731333732605 and perplexity is 114.12716821424222
At time: 120.85822033882141 and batch: 950, loss is 4.795290136337281 and perplexity is 120.9394656268489
At time: 122.01960492134094 and batch: 1000, loss is 4.764288663864136 and perplexity is 117.24768510190296
At time: 123.1817364692688 and batch: 1050, loss is 4.6796222591400145 and perplexity is 107.72937109929518
At time: 124.34226250648499 and batch: 1100, loss is 4.755253343582154 and perplexity is 116.19308620858685
At time: 125.50372004508972 and batch: 1150, loss is 4.673296775817871 and perplexity is 107.05008144176325
At time: 126.66559863090515 and batch: 1200, loss is 4.753209009170532 and perplexity is 115.95579132175347
At time: 127.82713508605957 and batch: 1250, loss is 4.715299863815307 and perplexity is 111.6422836359878
At time: 128.98753142356873 and batch: 1300, loss is 4.730097665786743 and perplexity is 113.30662798924958
At time: 130.1474733352661 and batch: 1350, loss is 4.628747940063477 and perplexity is 102.38579067766098
At time: 131.31603932380676 and batch: 1400, loss is 4.651945276260376 and perplexity is 104.78863027512976
At time: 132.48700141906738 and batch: 1450, loss is 4.587900562286377 and perplexity is 98.28786415278987
At time: 133.65692329406738 and batch: 1500, loss is 4.577522640228271 and perplexity is 97.27311496083061
At time: 134.82612466812134 and batch: 1550, loss is 4.577107267379761 and perplexity is 97.23271874031325
At time: 135.99605441093445 and batch: 1600, loss is 4.656177234649658 and perplexity is 105.23303107772796
At time: 137.1664080619812 and batch: 1650, loss is 4.604699010848999 and perplexity is 99.95289358464817
At time: 138.33657789230347 and batch: 1700, loss is 4.634594240188599 and perplexity is 102.98612188681847
At time: 139.5061867237091 and batch: 1750, loss is 4.634591836929321 and perplexity is 102.98587438476295
At time: 140.67620062828064 and batch: 1800, loss is 4.5911961364746094 and perplexity is 98.61231343059254
At time: 141.84686493873596 and batch: 1850, loss is 4.609794282913208 and perplexity is 100.46348045593211
At time: 143.01685881614685 and batch: 1900, loss is 4.68754225730896 and perplexity is 108.58597519494354
At time: 144.18763828277588 and batch: 1950, loss is 4.617036447525025 and perplexity is 101.19369449241997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.580327375545058 and perplexity of 97.54632326111908
finished 3 epochs...
Completing Train Step...
At time: 147.83119440078735 and batch: 50, loss is 4.604105033874512 and perplexity is 99.89354149595754
At time: 149.0271327495575 and batch: 100, loss is 4.545593547821045 and perplexity is 94.2163325154006
At time: 150.1863145828247 and batch: 150, loss is 4.498578910827637 and perplexity is 89.8892997814102
At time: 151.34609961509705 and batch: 200, loss is 4.498541269302368 and perplexity is 89.8859162747417
At time: 152.503276348114 and batch: 250, loss is 4.49928469657898 and perplexity is 89.95276476209915
At time: 153.66184496879578 and batch: 300, loss is 4.525165233612061 and perplexity is 92.31117747786885
At time: 154.82025742530823 and batch: 350, loss is 4.528418493270874 and perplexity is 92.61197873461302
At time: 155.97879099845886 and batch: 400, loss is 4.498182544708252 and perplexity is 89.85367776862748
At time: 157.13785076141357 and batch: 450, loss is 4.499271116256714 and perplexity is 89.95154318285972
At time: 158.2990837097168 and batch: 500, loss is 4.514491338729858 and perplexity is 91.33109761293483
At time: 159.45796251296997 and batch: 550, loss is 4.473947114944458 and perplexity is 87.7022114330475
At time: 160.6167905330658 and batch: 600, loss is 4.452164916992188 and perplexity is 85.81252003413167
At time: 161.7767288684845 and batch: 650, loss is 4.500703773498535 and perplexity is 90.08050526978957
At time: 162.93577408790588 and batch: 700, loss is 4.522058811187744 and perplexity is 92.02486490028188
At time: 164.09617948532104 and batch: 750, loss is 4.494791860580444 and perplexity is 89.54952825844451
At time: 165.2520763874054 and batch: 800, loss is 4.458771514892578 and perplexity is 86.38132571513187
At time: 166.41206169128418 and batch: 850, loss is 4.465072584152222 and perplexity is 86.92733885796726
At time: 167.57199573516846 and batch: 900, loss is 4.465709209442139 and perplexity is 86.98269661947523
At time: 168.73220467567444 and batch: 950, loss is 4.535024995803833 and perplexity is 93.22584553024785
At time: 169.90118956565857 and batch: 1000, loss is 4.509179229736328 and perplexity is 90.84722320257012
At time: 171.06109595298767 and batch: 1050, loss is 4.437286510467529 and perplexity is 84.54521757490447
At time: 172.22197437286377 and batch: 1100, loss is 4.5024550342559815 and perplexity is 90.23839793894358
At time: 173.42411756515503 and batch: 1150, loss is 4.436396074295044 and perplexity is 84.46996896198051
At time: 174.58366060256958 and batch: 1200, loss is 4.514102735519409 and perplexity is 91.29561295036208
At time: 175.74227166175842 and batch: 1250, loss is 4.486095266342163 and perplexity is 88.77412890074143
At time: 176.8997254371643 and batch: 1300, loss is 4.489551029205322 and perplexity is 89.08144193325325
At time: 178.05799794197083 and batch: 1350, loss is 4.377988986968994 and perplexity is 79.67763941079838
At time: 179.21825790405273 and batch: 1400, loss is 4.413584413528443 and perplexity is 82.5648804140545
At time: 180.3781361579895 and batch: 1450, loss is 4.344731192588807 and perplexity is 77.07131735327017
At time: 181.54318070411682 and batch: 1500, loss is 4.338191637992859 and perplexity is 76.56894968639314
At time: 182.69910192489624 and batch: 1550, loss is 4.344338169097901 and perplexity is 77.04103246680101
At time: 183.85676074028015 and batch: 1600, loss is 4.429602899551392 and perplexity is 83.89809432360637
At time: 185.0129668712616 and batch: 1650, loss is 4.376022119522094 and perplexity is 79.52107807376645
At time: 186.1701819896698 and batch: 1700, loss is 4.404265699386596 and perplexity is 81.79905568808249
At time: 187.32736897468567 and batch: 1750, loss is 4.408470096588135 and perplexity is 82.14369540234948
At time: 188.48327493667603 and batch: 1800, loss is 4.358363018035889 and perplexity is 78.1291337014907
At time: 189.64200067520142 and batch: 1850, loss is 4.3889727210998535 and perplexity is 80.55762131498814
At time: 190.8012080192566 and batch: 1900, loss is 4.471247787475586 and perplexity is 87.46579367267502
At time: 191.9607036113739 and batch: 1950, loss is 4.407661590576172 and perplexity is 82.07730857146409
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5185972701671515 and perplexity of 91.70686775312687
finished 4 epochs...
Completing Train Step...
At time: 195.61422491073608 and batch: 50, loss is 4.390938954353333 and perplexity is 80.71617221178089
At time: 196.77481150627136 and batch: 100, loss is 4.333249168395996 and perplexity is 76.1914436550221
At time: 197.9356153011322 and batch: 150, loss is 4.293387241363526 and perplexity is 73.21404259979168
At time: 199.0961136817932 and batch: 200, loss is 4.303016185760498 and perplexity is 73.9224215425917
At time: 200.25571250915527 and batch: 250, loss is 4.295242843627929 and perplexity is 73.35002486851036
At time: 201.41929030418396 and batch: 300, loss is 4.3167776679992675 and perplexity is 74.94673550772255
At time: 202.60063982009888 and batch: 350, loss is 4.319077758789063 and perplexity is 75.11931820563986
At time: 203.75898504257202 and batch: 400, loss is 4.291779775619506 and perplexity is 73.09644807423861
At time: 204.91705131530762 and batch: 450, loss is 4.306687641143799 and perplexity is 74.19432324717262
At time: 206.07493996620178 and batch: 500, loss is 4.3241040134429936 and perplexity is 75.4978374986653
At time: 207.23454999923706 and batch: 550, loss is 4.282803058624268 and perplexity is 72.44321826260605
At time: 208.39586281776428 and batch: 600, loss is 4.264928259849548 and perplexity is 71.15981477445527
At time: 209.55523252487183 and batch: 650, loss is 4.3107795143127445 and perplexity is 74.49853898940472
At time: 210.715229511261 and batch: 700, loss is 4.338775987625122 and perplexity is 76.6137057993207
At time: 211.874831199646 and batch: 750, loss is 4.313154773712158 and perplexity is 74.67570266593151
At time: 213.0349576473236 and batch: 800, loss is 4.2751786279678345 and perplexity is 71.89298025971385
At time: 214.1962447166443 and batch: 850, loss is 4.275697822570801 and perplexity is 71.93031639857806
At time: 215.3569211959839 and batch: 900, loss is 4.271682314872741 and perplexity is 71.64205879699409
At time: 216.5189723968506 and batch: 950, loss is 4.355641679763794 and perplexity is 77.91680693729337
At time: 217.68006253242493 and batch: 1000, loss is 4.327708978652954 and perplexity is 75.77049574273357
At time: 218.84377598762512 and batch: 1050, loss is 4.264018087387085 and perplexity is 71.09507653656344
At time: 220.00506973266602 and batch: 1100, loss is 4.323465299606323 and perplexity is 75.44963138181198
At time: 221.16557931900024 and batch: 1150, loss is 4.262759265899658 and perplexity is 71.0056368326902
At time: 222.3269166946411 and batch: 1200, loss is 4.340943312644958 and perplexity is 76.77993266952122
At time: 223.493501663208 and batch: 1250, loss is 4.319949645996093 and perplexity is 75.18484233886008
At time: 224.66265177726746 and batch: 1300, loss is 4.316065587997437 and perplexity is 74.89338643282392
At time: 225.83229398727417 and batch: 1350, loss is 4.201467514038086 and perplexity is 66.78426601077165
At time: 226.99908447265625 and batch: 1400, loss is 4.244056901931763 and perplexity is 69.6900046330844
At time: 228.16473054885864 and batch: 1450, loss is 4.169718151092529 and perplexity is 64.69721469814776
At time: 229.3327295780182 and batch: 1500, loss is 4.1690964508056645 and perplexity is 64.65700492172047
At time: 230.50082206726074 and batch: 1550, loss is 4.171397085189819 and perplexity is 64.80592829384851
At time: 231.669086933136 and batch: 1600, loss is 4.26413580417633 and perplexity is 71.10344611331466
At time: 232.83820915222168 and batch: 1650, loss is 4.211205263137817 and perplexity is 67.43777110735127
At time: 234.00637125968933 and batch: 1700, loss is 4.240390520095826 and perplexity is 69.43496229295035
At time: 235.1739478111267 and batch: 1750, loss is 4.241626353263855 and perplexity is 69.52082536766254
At time: 236.34007573127747 and batch: 1800, loss is 4.187280831336975 and perplexity is 65.8435077173396
At time: 237.5080006122589 and batch: 1850, loss is 4.229090299606323 and perplexity is 68.65474850570334
At time: 238.6770875453949 and batch: 1900, loss is 4.30971396446228 and perplexity is 74.41919935999671
At time: 239.8465394973755 and batch: 1950, loss is 4.245764808654785 and perplexity is 69.80913035938221
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477760208484739 and perplexity of 88.03726656123747
finished 5 epochs...
Completing Train Step...
At time: 243.5848412513733 and batch: 50, loss is 4.223414058685303 and perplexity is 68.26615154118174
At time: 244.744704246521 and batch: 100, loss is 4.176595644950867 and perplexity is 65.14370299524262
At time: 245.9033501148224 and batch: 150, loss is 4.136640725135803 and perplexity is 62.59220346961294
At time: 247.06433939933777 and batch: 200, loss is 4.149270038604737 and perplexity is 63.387712822848925
At time: 248.22394037246704 and batch: 250, loss is 4.135636744499206 and perplexity is 62.52939364452752
At time: 249.3844714164734 and batch: 300, loss is 4.152648649215698 and perplexity is 63.60223741546258
At time: 250.5562801361084 and batch: 350, loss is 4.161230010986328 and perplexity is 64.15037976429248
At time: 251.7160987854004 and batch: 400, loss is 4.134467353820801 and perplexity is 62.456315091490396
At time: 252.87615609169006 and batch: 450, loss is 4.159338207244873 and perplexity is 64.02913455806659
At time: 254.03707599639893 and batch: 500, loss is 4.174594435691834 and perplexity is 65.01346717167328
At time: 255.19774508476257 and batch: 550, loss is 4.137342076301575 and perplexity is 62.636117982431884
At time: 256.36058139801025 and batch: 600, loss is 4.11938244342804 and perplexity is 61.52123768599966
At time: 257.5234673023224 and batch: 650, loss is 4.16246045589447 and perplexity is 64.22936185401902
At time: 258.68429470062256 and batch: 700, loss is 4.195992202758789 and perplexity is 66.41960060513352
At time: 259.88597083091736 and batch: 750, loss is 4.167372889518738 and perplexity is 64.54566059305985
At time: 261.04434466362 and batch: 800, loss is 4.130044317245483 and perplexity is 62.180678550095315
At time: 262.20505833625793 and batch: 850, loss is 4.1285396194458 and perplexity is 62.087185776723274
At time: 263.36324405670166 and batch: 900, loss is 4.120675048828125 and perplexity is 61.60081178792987
At time: 264.52325773239136 and batch: 950, loss is 4.214123649597168 and perplexity is 67.634868048032
At time: 265.6822762489319 and batch: 1000, loss is 4.1851046276092525 and perplexity is 65.70037463026587
At time: 266.84295105934143 and batch: 1050, loss is 4.129405646324158 and perplexity is 62.14097823790407
At time: 268.0028643608093 and batch: 1100, loss is 4.178908195495605 and perplexity is 65.29452542612276
At time: 269.17100071907043 and batch: 1150, loss is 4.128291883468628 and perplexity is 62.071806452169646
At time: 270.3325045108795 and batch: 1200, loss is 4.20005687713623 and perplexity is 66.69012407632793
At time: 271.4943027496338 and batch: 1250, loss is 4.1850728511810305 and perplexity is 65.69828694019711
At time: 272.6532530784607 and batch: 1300, loss is 4.180595350265503 and perplexity is 65.40478037857481
At time: 273.80993008613586 and batch: 1350, loss is 4.0645389652252195 and perplexity is 58.23805256481459
At time: 274.9702043533325 and batch: 1400, loss is 4.110260972976684 and perplexity is 60.962625091551885
At time: 276.13312244415283 and batch: 1450, loss is 4.032319087982177 and perplexity is 56.39153665763344
At time: 277.2918789386749 and batch: 1500, loss is 4.030900015830993 and perplexity is 56.311569751224624
At time: 278.45479798316956 and batch: 1550, loss is 4.03570867061615 and perplexity is 56.583004746126015
At time: 279.61899971961975 and batch: 1600, loss is 4.134597883224488 and perplexity is 62.46446800914191
At time: 280.78121304512024 and batch: 1650, loss is 4.074590449333191 and perplexity is 58.82638326965369
At time: 281.94145250320435 and batch: 1700, loss is 4.1092742156982425 and perplexity is 60.90249944711715
At time: 283.1025712490082 and batch: 1750, loss is 4.1082923698425295 and perplexity is 60.84273192648009
At time: 284.2639412879944 and batch: 1800, loss is 4.058051066398621 and perplexity is 57.861433027723265
At time: 285.42428946495056 and batch: 1850, loss is 4.096904149055481 and perplexity is 60.15377192234386
At time: 286.5857059955597 and batch: 1900, loss is 4.178492832183838 and perplexity is 65.26741010754557
At time: 287.74550342559814 and batch: 1950, loss is 4.115776638984681 and perplexity is 61.299803597720796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.464359443132268 and perplexity of 86.86536950594196
finished 6 epochs...
Completing Train Step...
At time: 291.408789396286 and batch: 50, loss is 4.092635526657104 and perplexity is 59.89754544028085
At time: 292.5685467720032 and batch: 100, loss is 4.050126314163208 and perplexity is 57.40470761511834
At time: 293.72814679145813 and batch: 150, loss is 4.010800738334655 and perplexity is 55.191046461067195
At time: 294.8859441280365 and batch: 200, loss is 4.027542181015015 and perplexity is 56.122801904759015
At time: 296.04467511177063 and batch: 250, loss is 4.012543940544129 and perplexity is 55.28733951995354
At time: 297.20721650123596 and batch: 300, loss is 4.027130541801452 and perplexity is 56.09970431298341
At time: 298.3682379722595 and batch: 350, loss is 4.033736987113953 and perplexity is 56.47155088114349
At time: 299.5278615951538 and batch: 400, loss is 4.008349156379699 and perplexity is 55.05590680814066
At time: 300.686808347702 and batch: 450, loss is 4.037194466590881 and perplexity is 56.66713803378843
At time: 301.84669828414917 and batch: 500, loss is 4.055771336555481 and perplexity is 57.7296748356885
At time: 303.0065712928772 and batch: 550, loss is 4.017413802146912 and perplexity is 55.55723786218975
At time: 304.1661653518677 and batch: 600, loss is 4.000793743133545 and perplexity is 54.641504143574835
At time: 305.32500410079956 and batch: 650, loss is 4.036948795318604 and perplexity is 56.65321825580615
At time: 306.4848732948303 and batch: 700, loss is 4.07720440864563 and perplexity is 58.98035419120984
At time: 307.6442081928253 and batch: 750, loss is 4.049671301841736 and perplexity is 57.37859370736838
At time: 308.8022518157959 and batch: 800, loss is 4.0085981702804565 and perplexity is 55.06961820134758
At time: 309.9607548713684 and batch: 850, loss is 4.011717023849488 and perplexity is 55.24164039319168
At time: 311.1261899471283 and batch: 900, loss is 3.9983289766311647 and perplexity is 54.506991433830535
At time: 312.2831652164459 and batch: 950, loss is 4.0997721958160405 and perplexity is 60.326543392939044
At time: 313.4422085285187 and batch: 1000, loss is 4.063420791625976 and perplexity is 58.172968706272705
At time: 314.59926199913025 and batch: 1050, loss is 4.014226369857788 and perplexity is 55.3804348518344
At time: 315.7587614059448 and batch: 1100, loss is 4.064563493728638 and perplexity is 58.23948107460555
At time: 316.9175796508789 and batch: 1150, loss is 4.014014759063721 and perplexity is 55.368716993895966
At time: 318.11987137794495 and batch: 1200, loss is 4.084215860366822 and perplexity is 59.395345241884186
At time: 319.27869749069214 and batch: 1250, loss is 4.0723053026199345 and perplexity is 58.69210982895828
At time: 320.4380805492401 and batch: 1300, loss is 4.062690362930298 and perplexity is 58.13049301523716
At time: 321.5977818965912 and batch: 1350, loss is 3.951710052490234 and perplexity is 52.02425501828714
At time: 322.7572388648987 and batch: 1400, loss is 3.9953710985183717 and perplexity is 54.346004603957844
At time: 323.9180181026459 and batch: 1450, loss is 3.9203835678100587 and perplexity is 50.419780474333265
At time: 325.07721304893494 and batch: 1500, loss is 3.9160261487960817 and perplexity is 50.200558332444494
At time: 326.23664116859436 and batch: 1550, loss is 3.9217536306381224 and perplexity is 50.48890608376145
At time: 327.39669847488403 and batch: 1600, loss is 4.027268924713135 and perplexity is 56.10746809058546
At time: 328.5555109977722 and batch: 1650, loss is 3.9675109243392943 and perplexity is 52.852812330242294
At time: 329.7133934497833 and batch: 1700, loss is 4.001631932258606 and perplexity is 54.68732325798412
At time: 330.87179255485535 and batch: 1750, loss is 4.0008447647094725 and perplexity is 54.64429211034992
At time: 332.03166699409485 and batch: 1800, loss is 3.9466601705551145 and perplexity is 51.76220090075263
At time: 333.18994402885437 and batch: 1850, loss is 3.988845553398132 and perplexity is 53.99252188687406
At time: 334.3475093841553 and batch: 1900, loss is 4.067974290847778 and perplexity is 58.438463279935846
At time: 335.50596737861633 and batch: 1950, loss is 4.006989250183105 and perplexity is 54.98108682492323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.460460574127907 and perplexity of 86.52735218004875
finished 7 epochs...
Completing Train Step...
At time: 339.16252875328064 and batch: 50, loss is 3.9840693855285645 and perplexity is 53.73525939212286
At time: 340.34608030319214 and batch: 100, loss is 3.94564425945282 and perplexity is 51.7096418083815
At time: 341.5080156326294 and batch: 150, loss is 3.9058827924728394 and perplexity is 49.69392998140724
At time: 342.6696832180023 and batch: 200, loss is 3.922201795578003 and perplexity is 50.51153851247282
At time: 343.83009481430054 and batch: 250, loss is 3.9051077508926393 and perplexity is 49.65543004084269
At time: 344.9922001361847 and batch: 300, loss is 3.922283115386963 and perplexity is 50.51564626815362
At time: 346.15365171432495 and batch: 350, loss is 3.9263982582092285 and perplexity is 50.723953680719596
At time: 347.33828806877136 and batch: 400, loss is 3.9028444862365723 and perplexity is 49.543173741824596
At time: 348.50002551078796 and batch: 450, loss is 3.9385092306137084 and perplexity is 51.34200513161958
At time: 349.6621296405792 and batch: 500, loss is 3.959046654701233 and perplexity is 52.40733983481901
At time: 350.82132363319397 and batch: 550, loss is 3.9200190830230714 and perplexity is 50.40140658009302
At time: 351.98292350769043 and batch: 600, loss is 3.9061310863494874 and perplexity is 49.706270211866624
At time: 353.14409852027893 and batch: 650, loss is 3.9389034605026243 and perplexity is 51.362249674839155
At time: 354.30468225479126 and batch: 700, loss is 3.975524425506592 and perplexity is 53.278049949029985
At time: 355.46527457237244 and batch: 750, loss is 3.9477690696716308 and perplexity is 51.81963179625003
At time: 356.62598872184753 and batch: 800, loss is 3.9046961879730224 and perplexity is 49.63499791192197
At time: 357.7866458892822 and batch: 850, loss is 3.913459510803223 and perplexity is 50.071876882157504
At time: 358.94787192344666 and batch: 900, loss is 3.8998599672317504 and perplexity is 49.395531628171675
At time: 360.10838532447815 and batch: 950, loss is 4.00063422203064 and perplexity is 54.6327883657632
At time: 361.27072525024414 and batch: 1000, loss is 3.9620510053634646 and perplexity is 52.56502661554125
At time: 362.43173336982727 and batch: 1050, loss is 3.9185940265655517 and perplexity is 50.329632883109575
At time: 363.59324407577515 and batch: 1100, loss is 3.965325961112976 and perplexity is 52.737456948419656
At time: 364.754501581192 and batch: 1150, loss is 3.916636028289795 and perplexity is 50.23118396156673
At time: 365.9168846607208 and batch: 1200, loss is 3.9934430837631227 and perplexity is 54.241325648903945
At time: 367.0778794288635 and batch: 1250, loss is 3.97516074180603 and perplexity is 53.258677113671574
At time: 368.2391839027405 and batch: 1300, loss is 3.966507172584534 and perplexity is 52.799787843284626
At time: 369.40092372894287 and batch: 1350, loss is 3.8594140672683714 and perplexity is 47.437548012112096
At time: 370.562979221344 and batch: 1400, loss is 3.9016755294799803 and perplexity is 49.48529375033053
At time: 371.7305693626404 and batch: 1450, loss is 3.8239314794540404 and perplexity is 45.78385323262925
At time: 372.901216506958 and batch: 1500, loss is 3.818831195831299 and perplexity is 45.55093706994759
At time: 374.0720272064209 and batch: 1550, loss is 3.8279997634887697 and perplexity is 45.97049434889703
At time: 375.2418842315674 and batch: 1600, loss is 3.933658881187439 and perplexity is 51.09358142441097
At time: 376.4127039909363 and batch: 1650, loss is 3.873967809677124 and perplexity is 48.1329902346934
At time: 377.58250427246094 and batch: 1700, loss is 3.9094323348999023 and perplexity is 49.87063411813062
At time: 378.75312209129333 and batch: 1750, loss is 3.9075665950775145 and perplexity is 49.777675235598885
At time: 379.9237504005432 and batch: 1800, loss is 3.853533625602722 and perplexity is 47.15941285852129
At time: 381.09209418296814 and batch: 1850, loss is 3.8995868158340454 and perplexity is 49.38204101224124
At time: 382.2603621482849 and batch: 1900, loss is 3.9729155683517456 and perplexity is 53.13923627847506
At time: 383.4281463623047 and batch: 1950, loss is 3.9126253366470336 and perplexity is 50.03012563283814
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473625999273255 and perplexity of 87.67405339979203
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 387.09222316741943 and batch: 50, loss is 3.9196144199371337 and perplexity is 50.38101511748506
At time: 388.30905747413635 and batch: 100, loss is 3.9106278085708617 and perplexity is 49.93028879886832
At time: 389.48249411582947 and batch: 150, loss is 3.870256004333496 and perplexity is 47.95466111057745
At time: 390.65925121307373 and batch: 200, loss is 3.8759928607940672 and perplexity is 48.23056075963689
At time: 391.8409061431885 and batch: 250, loss is 3.863081703186035 and perplexity is 47.611851111814474
At time: 393.01847672462463 and batch: 300, loss is 3.889257616996765 and perplexity is 48.87458938775896
At time: 394.1958727836609 and batch: 350, loss is 3.9006718015670776 and perplexity is 49.43564889884469
At time: 395.3690433502197 and batch: 400, loss is 3.86222722530365 and perplexity is 47.57118521462917
At time: 396.54018115997314 and batch: 450, loss is 3.8876308155059816 and perplexity is 48.79514477071299
At time: 397.70885133743286 and batch: 500, loss is 3.894173474311829 and perplexity is 49.11544140757458
At time: 398.8833510875702 and batch: 550, loss is 3.857634654045105 and perplexity is 47.35321206839956
At time: 400.0538363456726 and batch: 600, loss is 3.8272580766677855 and perplexity is 45.93641128012821
At time: 401.22355222702026 and batch: 650, loss is 3.8450294446945192 and perplexity is 46.760061166358874
At time: 402.39353704452515 and batch: 700, loss is 3.883681836128235 and perplexity is 48.60283371638826
At time: 403.5627682209015 and batch: 750, loss is 3.8355647563934325 and perplexity is 46.31957956122918
At time: 404.7332110404968 and batch: 800, loss is 3.792724585533142 and perplexity is 44.37714503894708
At time: 405.9471027851105 and batch: 850, loss is 3.8100860118865967 and perplexity is 45.154322507763546
At time: 407.1195249557495 and batch: 900, loss is 3.7904774379730224 and perplexity is 44.27753500688448
At time: 408.29021883010864 and batch: 950, loss is 3.8820965909957885 and perplexity is 48.52584734807132
At time: 409.4618515968323 and batch: 1000, loss is 3.825110116004944 and perplexity is 45.83784756908899
At time: 410.6316604614258 and batch: 1050, loss is 3.77922598361969 and perplexity is 43.78214052328962
At time: 411.8021237850189 and batch: 1100, loss is 3.808144564628601 and perplexity is 45.06674281532998
At time: 412.9731562137604 and batch: 1150, loss is 3.7669070625305174 and perplexity is 43.24610028667408
At time: 414.1432285308838 and batch: 1200, loss is 3.8275792503356936 and perplexity is 45.951167215311656
At time: 415.3113033771515 and batch: 1250, loss is 3.7984513998031617 and perplexity is 44.63201380289153
At time: 416.48159623146057 and batch: 1300, loss is 3.7931051301956176 and perplexity is 44.39403573825644
At time: 417.65180373191833 and batch: 1350, loss is 3.6857674360275268 and perplexity is 39.875712768905736
At time: 418.821989774704 and batch: 1400, loss is 3.7160250520706177 and perplexity is 41.100695852253
At time: 419.9927086830139 and batch: 1450, loss is 3.634327049255371 and perplexity is 37.8763553972552
At time: 421.16218280792236 and batch: 1500, loss is 3.6139412784576415 and perplexity is 37.11203380935168
At time: 422.33149003982544 and batch: 1550, loss is 3.6117225599288942 and perplexity is 37.02978393070528
At time: 423.5121579170227 and batch: 1600, loss is 3.7042629384994505 and perplexity is 40.62009677105902
At time: 424.68491768836975 and batch: 1650, loss is 3.6359184217453 and perplexity is 37.936678773002924
At time: 425.8661334514618 and batch: 1700, loss is 3.6682655477523802 and perplexity is 39.18388431107878
At time: 427.04095244407654 and batch: 1750, loss is 3.656642026901245 and perplexity is 38.73106638227813
At time: 428.21766567230225 and batch: 1800, loss is 3.5921852874755857 and perplexity is 36.313344379421316
At time: 429.3959906101227 and batch: 1850, loss is 3.633945665359497 and perplexity is 37.86191271954969
At time: 430.56783628463745 and batch: 1900, loss is 3.6960387563705446 and perplexity is 40.28739965318784
At time: 431.73813486099243 and batch: 1950, loss is 3.6283348846435546 and perplexity is 37.65007267954175
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4266013921693315 and perplexity of 83.64665111724524
finished 9 epochs...
Completing Train Step...
At time: 435.4212489128113 and batch: 50, loss is 3.821595368385315 and perplexity is 45.67702189983835
At time: 436.60858607292175 and batch: 100, loss is 3.800088334083557 and perplexity is 44.705133305871755
At time: 437.7677505016327 and batch: 150, loss is 3.7582387590408324 and perplexity is 42.87285002506623
At time: 438.926397562027 and batch: 200, loss is 3.7662341451644896 and perplexity is 43.21700902388391
At time: 440.08596897125244 and batch: 250, loss is 3.751530632972717 and perplexity is 42.586216005619434
At time: 441.24557995796204 and batch: 300, loss is 3.779997124671936 and perplexity is 43.81591575026064
At time: 442.40520691871643 and batch: 350, loss is 3.7867750787734984 and perplexity is 44.113906760002706
At time: 443.5651435852051 and batch: 400, loss is 3.752578463554382 and perplexity is 42.63086253202041
At time: 444.7252712249756 and batch: 450, loss is 3.7825355243682863 and perplexity is 43.927279340350694
At time: 445.8846719264984 and batch: 500, loss is 3.7944415330886843 and perplexity is 44.45340371698542
At time: 447.04252648353577 and batch: 550, loss is 3.76031268119812 and perplexity is 42.96185724379802
At time: 448.20140743255615 and batch: 600, loss is 3.73628378868103 and perplexity is 41.94183546907504
At time: 449.3595962524414 and batch: 650, loss is 3.7522130537033083 and perplexity is 42.6152876406741
At time: 450.5177285671234 and batch: 700, loss is 3.791489849090576 and perplexity is 44.32238477495439
At time: 451.68287897109985 and batch: 750, loss is 3.7498137378692626 and perplexity is 42.51316267028671
At time: 452.84551978111267 and batch: 800, loss is 3.7053685760498047 and perplexity is 40.66503271220247
At time: 454.0063695907593 and batch: 850, loss is 3.7259986114501955 and perplexity is 41.512667077659785
At time: 455.1655344963074 and batch: 900, loss is 3.707693724632263 and perplexity is 40.75969496462204
At time: 456.3238277435303 and batch: 950, loss is 3.801632604598999 and perplexity is 44.77422345833725
At time: 457.48401284217834 and batch: 1000, loss is 3.7481151628494263 and perplexity is 42.441012168028244
At time: 458.64615654945374 and batch: 1050, loss is 3.706204180717468 and perplexity is 40.69902680418044
At time: 459.80651569366455 and batch: 1100, loss is 3.735281114578247 and perplexity is 41.89980255300671
At time: 460.96569752693176 and batch: 1150, loss is 3.6993729162216185 and perplexity is 40.42194846259083
At time: 462.1267521381378 and batch: 1200, loss is 3.7604180192947387 and perplexity is 42.966383002430504
At time: 463.32795786857605 and batch: 1250, loss is 3.737761001586914 and perplexity is 42.00383827412333
At time: 464.4869921207428 and batch: 1300, loss is 3.7352782773971556 and perplexity is 41.89968367584781
At time: 465.6450958251953 and batch: 1350, loss is 3.6279591655731203 and perplexity is 37.635929486332884
At time: 466.8041799068451 and batch: 1400, loss is 3.662658920288086 and perplexity is 38.96480957822047
At time: 467.96400356292725 and batch: 1450, loss is 3.5828646516799925 and perplexity is 35.976453380020814
At time: 469.1238989830017 and batch: 1500, loss is 3.5666702365875245 and perplexity is 35.39852797285824
At time: 470.2837162017822 and batch: 1550, loss is 3.5672685861587525 and perplexity is 35.41971500488655
At time: 471.44396567344666 and batch: 1600, loss is 3.6652608346939086 and perplexity is 39.06632468712322
At time: 472.6038041114807 and batch: 1650, loss is 3.598840980529785 and perplexity is 36.5558409495705
At time: 473.7637720108032 and batch: 1700, loss is 3.6348093700408937 and perplexity is 37.894628357103066
At time: 474.921560049057 and batch: 1750, loss is 3.627584466934204 and perplexity is 37.621829996474794
At time: 476.08009219169617 and batch: 1800, loss is 3.5670129346847532 and perplexity is 35.410661059913416
At time: 477.2394988536835 and batch: 1850, loss is 3.6126471376419067 and perplexity is 37.06403667586761
At time: 478.3987452983856 and batch: 1900, loss is 3.678063998222351 and perplexity is 39.569712834627964
At time: 479.5748727321625 and batch: 1950, loss is 3.616702227592468 and perplexity is 37.214639826807726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4307957848837205 and perplexity of 83.99823484594069
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 483.2475235462189 and batch: 50, loss is 3.790459880828857 and perplexity is 44.27675762664339
At time: 484.4060387611389 and batch: 100, loss is 3.79316330909729 and perplexity is 44.396618609630075
At time: 485.5651433467865 and batch: 150, loss is 3.7668524503707888 and perplexity is 43.2437385882269
At time: 486.7256124019623 and batch: 200, loss is 3.7777374839782714 and perplexity is 43.71701930130167
At time: 487.885901927948 and batch: 250, loss is 3.771478238105774 and perplexity is 43.44423832088246
At time: 489.04614543914795 and batch: 300, loss is 3.7967706680297852 and perplexity is 44.55706236346003
At time: 490.2060580253601 and batch: 350, loss is 3.8057646560668945 and perplexity is 44.95961561528954
At time: 491.36699891090393 and batch: 400, loss is 3.7686027812957765 and perplexity is 43.3194957218757
At time: 492.55634784698486 and batch: 450, loss is 3.8046187925338746 and perplexity is 44.90812753608723
At time: 493.7170853614807 and batch: 500, loss is 3.8124869155883787 and perplexity is 45.26286393444133
At time: 494.8754029273987 and batch: 550, loss is 3.788583164215088 and perplexity is 44.193740624061554
At time: 496.0355179309845 and batch: 600, loss is 3.758730993270874 and perplexity is 42.893958704168995
At time: 497.1958792209625 and batch: 650, loss is 3.778439555168152 and perplexity is 43.747722537728286
At time: 498.3561854362488 and batch: 700, loss is 3.8076785135269167 and perplexity is 45.04574430376137
At time: 499.5158531665802 and batch: 750, loss is 3.749724473953247 and perplexity is 42.50936794827294
At time: 500.6727056503296 and batch: 800, loss is 3.6926650619506836 and perplexity is 40.15171129201891
At time: 501.8319504261017 and batch: 850, loss is 3.712743740081787 and perplexity is 40.966052670156195
At time: 502.9915795326233 and batch: 900, loss is 3.695752363204956 and perplexity is 40.27586326931743
At time: 504.15221786499023 and batch: 950, loss is 3.8087740468978883 and perplexity is 45.09512046154227
At time: 505.3126232624054 and batch: 1000, loss is 3.743308596611023 and perplexity is 42.23750610630178
At time: 506.4719400405884 and batch: 1050, loss is 3.699473476409912 and perplexity is 40.42601350572675
At time: 507.6329674720764 and batch: 1100, loss is 3.713836359977722 and perplexity is 41.01083745628029
At time: 508.7959690093994 and batch: 1150, loss is 3.6793484115600585 and perplexity is 39.62056935496697
At time: 509.9580030441284 and batch: 1200, loss is 3.7323011302948 and perplexity is 41.77512765679743
At time: 511.11843180656433 and batch: 1250, loss is 3.70718599319458 and perplexity is 40.739005238954675
At time: 512.2783346176147 and batch: 1300, loss is 3.7108661794662474 and perplexity is 40.88920858537659
At time: 513.4382429122925 and batch: 1350, loss is 3.6015013360977175 and perplexity is 36.65322196120497
At time: 514.5991206169128 and batch: 1400, loss is 3.625977940559387 and perplexity is 37.561438057926566
At time: 515.757887840271 and batch: 1450, loss is 3.538481388092041 and perplexity is 34.41461704032932
At time: 516.9174356460571 and batch: 1500, loss is 3.5250968456268312 and perplexity is 33.95706204996934
At time: 518.0757305622101 and batch: 1550, loss is 3.5278024244308472 and perplexity is 34.049059954969366
At time: 519.2330791950226 and batch: 1600, loss is 3.6217959451675417 and perplexity is 37.40468429726619
At time: 520.3873734474182 and batch: 1650, loss is 3.551691770553589 and perplexity is 34.87226348048875
At time: 521.5420308113098 and batch: 1700, loss is 3.5777867889404296 and perplexity is 35.794232924672414
At time: 522.6960787773132 and batch: 1750, loss is 3.567111306190491 and perplexity is 35.41414463130032
At time: 523.854897737503 and batch: 1800, loss is 3.5054969787597656 and perplexity is 33.297988133830444
At time: 525.0132277011871 and batch: 1850, loss is 3.547789463996887 and perplexity is 34.73644639037424
At time: 526.173238992691 and batch: 1900, loss is 3.613733382225037 and perplexity is 37.104319159289545
At time: 527.3321950435638 and batch: 1950, loss is 3.5487848711013794 and perplexity is 34.771040510656164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416975722202035 and perplexity of 82.84535873460294
finished 11 epochs...
Completing Train Step...
At time: 530.9965887069702 and batch: 50, loss is 3.7981573057174685 and perplexity is 44.61888972155146
At time: 532.1570107936859 and batch: 100, loss is 3.785287628173828 and perplexity is 44.04833827996545
At time: 533.3158204555511 and batch: 150, loss is 3.7408151912689207 and perplexity is 42.13232207065215
At time: 534.4733753204346 and batch: 200, loss is 3.7417068529129027 and perplexity is 42.16990660006592
At time: 535.6304895877838 and batch: 250, loss is 3.7289438343048094 and perplexity is 41.635111357828826
At time: 536.7868752479553 and batch: 300, loss is 3.7500652837753297 and perplexity is 42.52385802744064
At time: 537.9441659450531 and batch: 350, loss is 3.760204668045044 and perplexity is 42.95721704874068
At time: 539.1010167598724 and batch: 400, loss is 3.7237842655181885 and perplexity is 41.420845372218885
At time: 540.2587888240814 and batch: 450, loss is 3.762277436256409 and perplexity is 43.04634974648702
At time: 541.4186408519745 and batch: 500, loss is 3.7719813203811645 and perplexity is 43.466099845761306
At time: 542.5788896083832 and batch: 550, loss is 3.7493394422531128 and perplexity is 42.49300364465017
At time: 543.7392838001251 and batch: 600, loss is 3.722555594444275 and perplexity is 41.36998402998148
At time: 544.900536775589 and batch: 650, loss is 3.7420590114593506 and perplexity is 42.18475970824904
At time: 546.0605664253235 and batch: 700, loss is 3.774383945465088 and perplexity is 43.5706581444488
At time: 547.2207581996918 and batch: 750, loss is 3.7175464057922363 and perplexity is 41.16327213711137
At time: 548.3798861503601 and batch: 800, loss is 3.6598732137680052 and perplexity is 38.85641610042951
At time: 549.5696048736572 and batch: 850, loss is 3.67994375705719 and perplexity is 39.64416430540307
At time: 550.7297563552856 and batch: 900, loss is 3.6626549530029298 and perplexity is 38.96465499401645
At time: 551.8896939754486 and batch: 950, loss is 3.7766228103637696 and perplexity is 43.66831624243196
At time: 553.0493824481964 and batch: 1000, loss is 3.7135944080352785 and perplexity is 41.00091600480214
At time: 554.2085728645325 and batch: 1050, loss is 3.6718574142456055 and perplexity is 39.324880660653285
At time: 555.3683314323425 and batch: 1100, loss is 3.687338600158691 and perplexity is 39.93841330202886
At time: 556.5278360843658 and batch: 1150, loss is 3.654079489707947 and perplexity is 38.63194364123434
At time: 557.6889679431915 and batch: 1200, loss is 3.708739161491394 and perplexity is 40.80232893378338
At time: 558.8487842082977 and batch: 1250, loss is 3.686641812324524 and perplexity is 39.91059439458773
At time: 560.0082769393921 and batch: 1300, loss is 3.6921178579330443 and perplexity is 40.129746124546855
At time: 561.1678190231323 and batch: 1350, loss is 3.5836644554138184 and perplexity is 36.00523899164932
At time: 562.3269543647766 and batch: 1400, loss is 3.6107200384140015 and perplexity is 36.99267937778688
At time: 563.4860117435455 and batch: 1450, loss is 3.5251067066192627 and perplexity is 33.957396901952194
At time: 564.6447072029114 and batch: 1500, loss is 3.512494921684265 and perplexity is 33.531822780785305
At time: 565.8039605617523 and batch: 1550, loss is 3.517918462753296 and perplexity is 33.71417805742729
At time: 566.9649460315704 and batch: 1600, loss is 3.614190363883972 and perplexity is 37.12127902749183
At time: 568.1316950321198 and batch: 1650, loss is 3.545927810668945 and perplexity is 34.67183932598828
At time: 569.293826341629 and batch: 1700, loss is 3.573805823326111 and perplexity is 35.65202057326492
At time: 570.4641716480255 and batch: 1750, loss is 3.564852375984192 and perplexity is 35.33423683730644
At time: 571.6297287940979 and batch: 1800, loss is 3.5053257083892824 and perplexity is 33.292285663412464
At time: 572.7899448871613 and batch: 1850, loss is 3.5492987871170043 and perplexity is 34.78891449772525
At time: 573.9503672122955 and batch: 1900, loss is 3.614483423233032 and perplexity is 37.13215935957355
At time: 575.1121129989624 and batch: 1950, loss is 3.551269907951355 and perplexity is 34.857555279309224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418565475109012 and perplexity of 82.97716712810909
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 578.7919971942902 and batch: 50, loss is 3.7925954103469848 and perplexity is 44.371412983203186
At time: 579.9527542591095 and batch: 100, loss is 3.8093438959121704 and perplexity is 45.12082519469905
At time: 581.112752199173 and batch: 150, loss is 3.7917195749282837 and perplexity is 44.33256794154948
At time: 582.2728312015533 and batch: 200, loss is 3.7972922420501707 and perplexity is 44.580308231306894
At time: 583.43310546875 and batch: 250, loss is 3.7821206283569335 and perplexity is 43.90905786763236
At time: 584.592714548111 and batch: 300, loss is 3.784345045089722 and perplexity is 44.006838622929706
At time: 585.7538368701935 and batch: 350, loss is 3.788531475067139 and perplexity is 44.19145634630071
At time: 586.9140088558197 and batch: 400, loss is 3.7491651916503907 and perplexity is 42.485599858229484
At time: 588.0741024017334 and batch: 450, loss is 3.793751902580261 and perplexity is 44.4227578619518
At time: 589.2354500293732 and batch: 500, loss is 3.8043901443481447 and perplexity is 44.89786054801041
At time: 590.3958859443665 and batch: 550, loss is 3.7956026363372803 and perplexity is 44.505048685220416
At time: 591.5565500259399 and batch: 600, loss is 3.7634487533569336 and perplexity is 43.096800213039245
At time: 592.7171070575714 and batch: 650, loss is 3.778045082092285 and perplexity is 43.73046864237898
At time: 593.877699136734 and batch: 700, loss is 3.8124419927597044 and perplexity is 45.26083064423041
At time: 595.0385038852692 and batch: 750, loss is 3.768491768836975 and perplexity is 43.31468698506136
At time: 596.1969368457794 and batch: 800, loss is 3.714904851913452 and perplexity is 41.05468062424435
At time: 597.3565607070923 and batch: 850, loss is 3.7166749620437622 and perplexity is 41.127416286388346
At time: 598.5159854888916 and batch: 900, loss is 3.685072135925293 and perplexity is 39.847996818309106
At time: 599.674964427948 and batch: 950, loss is 3.7949765491485596 and perplexity is 44.4771933652446
At time: 600.834469795227 and batch: 1000, loss is 3.7309974336624148 and perplexity is 41.72070104915509
At time: 601.9933760166168 and batch: 1050, loss is 3.6949228382110597 and perplexity is 40.24246728740064
At time: 603.1530628204346 and batch: 1100, loss is 3.7118208026885986 and perplexity is 40.928261010646054
At time: 604.3112163543701 and batch: 1150, loss is 3.6844166707992554 and perplexity is 39.82188640422
At time: 605.4710140228271 and batch: 1200, loss is 3.7335398149490358 and perplexity is 41.82690592820931
At time: 606.6310024261475 and batch: 1250, loss is 3.7039777040481567 and perplexity is 40.60851217228691
At time: 607.7902727127075 and batch: 1300, loss is 3.702568979263306 and perplexity is 40.55134622970781
At time: 608.9500601291656 and batch: 1350, loss is 3.588183012008667 and perplexity is 36.16829882184224
At time: 610.1096248626709 and batch: 1400, loss is 3.6193270587921145 and perplexity is 37.312450286324264
At time: 611.2715599536896 and batch: 1450, loss is 3.5284548568725587 and perplexity is 34.071281914669214
At time: 612.4317314624786 and batch: 1500, loss is 3.517194333076477 and perplexity is 33.68977345768022
At time: 613.5910048484802 and batch: 1550, loss is 3.5340264987945558 and perplexity is 34.26164472156327
At time: 614.751903295517 and batch: 1600, loss is 3.6288979959487917 and perplexity is 37.67127983154373
At time: 615.9120199680328 and batch: 1650, loss is 3.5597270584106444 and perplexity is 35.15360095585015
At time: 617.0731925964355 and batch: 1700, loss is 3.5784478330612184 and perplexity is 35.81790231429892
At time: 618.2350981235504 and batch: 1750, loss is 3.561420788764954 and perplexity is 35.21319212829528
At time: 619.3961272239685 and batch: 1800, loss is 3.504608073234558 and perplexity is 33.26840251955608
At time: 620.5565371513367 and batch: 1850, loss is 3.5489849185943605 and perplexity is 34.777997065936184
At time: 621.7174963951111 and batch: 1900, loss is 3.6222023439407347 and perplexity is 37.41988860437289
At time: 622.8780601024628 and batch: 1950, loss is 3.557314085960388 and perplexity is 35.06887854274831
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.392004678415698 and perplexity of 80.80223923243042
finished 13 epochs...
Completing Train Step...
At time: 626.5233829021454 and batch: 50, loss is 3.7932149982452392 and perplexity is 44.398913492327594
At time: 627.706725358963 and batch: 100, loss is 3.794753794670105 and perplexity is 44.4672869746208
At time: 628.8660368919373 and batch: 150, loss is 3.771653537750244 and perplexity is 43.45185474797337
At time: 630.0248413085938 and batch: 200, loss is 3.7779744625091554 and perplexity is 43.72738052395549
At time: 631.1838712692261 and batch: 250, loss is 3.7650966882705688 and perplexity is 43.16787948569802
At time: 632.3418192863464 and batch: 300, loss is 3.7662083101272583 and perplexity is 43.21589252526921
At time: 633.5014021396637 and batch: 350, loss is 3.772381443977356 and perplexity is 43.48349513784534
At time: 634.6612982749939 and batch: 400, loss is 3.7300343561172484 and perplexity is 41.680540120954284
At time: 635.8199300765991 and batch: 450, loss is 3.771382632255554 and perplexity is 43.440084996084884
At time: 637.0027203559875 and batch: 500, loss is 3.7810500383377077 and perplexity is 43.862074423016665
At time: 638.1654336452484 and batch: 550, loss is 3.7686159563064576 and perplexity is 43.32006646045427
At time: 639.324807882309 and batch: 600, loss is 3.73943528175354 and perplexity is 42.074223373213535
At time: 640.4829709529877 and batch: 650, loss is 3.758291916847229 and perplexity is 42.87512911230264
At time: 641.6420540809631 and batch: 700, loss is 3.7967044258117677 and perplexity is 44.55411090257746
At time: 642.8005344867706 and batch: 750, loss is 3.7535606956481935 and perplexity is 42.67275650482033
At time: 643.9600582122803 and batch: 800, loss is 3.6992501544952394 and perplexity is 40.4169864989898
At time: 645.1170787811279 and batch: 850, loss is 3.700360746383667 and perplexity is 40.461898211025584
At time: 646.2743916511536 and batch: 900, loss is 3.668460569381714 and perplexity is 39.191526761238066
At time: 647.4285714626312 and batch: 950, loss is 3.778544511795044 and perplexity is 43.75231439208861
At time: 648.5860748291016 and batch: 1000, loss is 3.7157771301269533 and perplexity is 41.09050735088006
At time: 649.7422151565552 and batch: 1050, loss is 3.6808340120315552 and perplexity is 39.67947343461243
At time: 650.8990135192871 and batch: 1100, loss is 3.6993786001205446 and perplexity is 40.42217821751324
At time: 652.0566704273224 and batch: 1150, loss is 3.6732767486572264 and perplexity is 39.38073544594057
At time: 653.215692281723 and batch: 1200, loss is 3.7230582284927367 and perplexity is 41.39078321929174
At time: 654.3745512962341 and batch: 1250, loss is 3.6940908241271972 and perplexity is 40.20899891285834
At time: 655.5318942070007 and batch: 1300, loss is 3.6933826780319214 and perplexity is 40.180535146725155
At time: 656.6874063014984 and batch: 1350, loss is 3.580800895690918 and perplexity is 35.90228331967
At time: 657.8462707996368 and batch: 1400, loss is 3.6135652017593385 and perplexity is 37.0980794623262
At time: 659.0027775764465 and batch: 1450, loss is 3.5240506410598753 and perplexity is 33.92155459384234
At time: 660.1591577529907 and batch: 1500, loss is 3.5143022918701172 and perplexity is 33.592481997874415
At time: 661.316606760025 and batch: 1550, loss is 3.531420559883118 and perplexity is 34.17247720142943
At time: 662.47571849823 and batch: 1600, loss is 3.627424807548523 and perplexity is 37.615823797695136
At time: 663.636554479599 and batch: 1650, loss is 3.5587606954574587 and perplexity is 35.119646227153694
At time: 664.8017301559448 and batch: 1700, loss is 3.5790599536895753 and perplexity is 35.83983390287407
At time: 665.9652135372162 and batch: 1750, loss is 3.563514919281006 and perplexity is 35.287010414084435
At time: 667.1209454536438 and batch: 1800, loss is 3.5071907377243043 and perplexity is 33.35443468966862
At time: 668.2850947380066 and batch: 1850, loss is 3.5525079441070555 and perplexity is 34.900736917743664
At time: 669.443276643753 and batch: 1900, loss is 3.626350107192993 and perplexity is 37.57541977348461
At time: 670.5996487140656 and batch: 1950, loss is 3.5611834144592285 and perplexity is 35.204834413254105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3903013717296515 and perplexity of 80.66472538547266
finished 14 epochs...
Completing Train Step...
At time: 674.2351751327515 and batch: 50, loss is 3.786075835227966 and perplexity is 44.083071177479994
At time: 675.4172396659851 and batch: 100, loss is 3.784680542945862 and perplexity is 44.02160529989892
At time: 676.5770633220673 and batch: 150, loss is 3.7609117603302002 and perplexity is 42.987602506903144
At time: 677.7377550601959 and batch: 200, loss is 3.7683806657791137 and perplexity is 43.309874858212964
At time: 678.8983957767487 and batch: 250, loss is 3.755526595115662 and perplexity is 42.75672936816764
At time: 680.0604431629181 and batch: 300, loss is 3.75722222328186 and perplexity is 42.829290383644285
At time: 681.2160754203796 and batch: 350, loss is 3.7632277536392214 and perplexity is 43.08727688472305
At time: 682.3749680519104 and batch: 400, loss is 3.7200470304489137 and perplexity is 41.26633483722619
At time: 683.5360743999481 and batch: 450, loss is 3.7608328104019164 and perplexity is 42.984208772737425
At time: 684.6978590488434 and batch: 500, loss is 3.769498610496521 and perplexity is 43.358319978459846
At time: 685.8590042591095 and batch: 550, loss is 3.7555191230773928 and perplexity is 42.75640988944313
At time: 687.0198063850403 and batch: 600, loss is 3.72838273525238 and perplexity is 41.61175648910826
At time: 688.1807916164398 and batch: 650, loss is 3.748354911804199 and perplexity is 42.451188576177906
At time: 689.3422892093658 and batch: 700, loss is 3.7885921573638917 and perplexity is 44.19413806673431
At time: 690.5029318332672 and batch: 750, loss is 3.7459148931503297 and perplexity is 42.347733152083876
At time: 691.6630358695984 and batch: 800, loss is 3.6912576150894165 and perplexity is 40.09523964173202
At time: 692.8246455192566 and batch: 850, loss is 3.692564916610718 and perplexity is 40.14769048657719
At time: 693.9848504066467 and batch: 900, loss is 3.6605694103240967 and perplexity is 38.8834772223376
At time: 695.1878290176392 and batch: 950, loss is 3.770338954925537 and perplexity is 43.39477121475683
At time: 696.3480803966522 and batch: 1000, loss is 3.7084422159194945 and perplexity is 40.790214661612055
At time: 697.5097529888153 and batch: 1050, loss is 3.674060277938843 and perplexity is 39.41160349672568
At time: 698.6703355312347 and batch: 1100, loss is 3.693308210372925 and perplexity is 40.177543107742004
At time: 699.8299865722656 and batch: 1150, loss is 3.667887725830078 and perplexity is 39.169082576971
At time: 700.9909000396729 and batch: 1200, loss is 3.718058066368103 and perplexity is 41.18433914975791
At time: 702.1517589092255 and batch: 1250, loss is 3.6894151163101196 and perplexity is 40.021432227551905
At time: 703.3129680156708 and batch: 1300, loss is 3.688599634170532 and perplexity is 39.98880876810179
At time: 704.4716863632202 and batch: 1350, loss is 3.5762612056732177 and perplexity is 35.739667474511705
At time: 705.6330842971802 and batch: 1400, loss is 3.609985842704773 and perplexity is 36.96552947920395
At time: 706.7949426174164 and batch: 1450, loss is 3.5214989376068115 and perplexity is 33.83510718683172
At time: 707.9562842845917 and batch: 1500, loss is 3.5122191381454466 and perplexity is 33.52257653107612
At time: 709.1165046691895 and batch: 1550, loss is 3.529537787437439 and perplexity is 34.10819873280681
At time: 710.277179479599 and batch: 1600, loss is 3.6261168098449708 and perplexity is 37.56665455019206
At time: 711.4381258487701 and batch: 1650, loss is 3.557638349533081 and perplexity is 35.080251946485525
At time: 712.5994884967804 and batch: 1700, loss is 3.5783013200759886 and perplexity is 35.812654910921935
At time: 713.7612538337708 and batch: 1750, loss is 3.563215870857239 and perplexity is 35.276459466941326
At time: 714.9210963249207 and batch: 1800, loss is 3.5069331169128417 and perplexity is 33.34584299988456
At time: 716.0820848941803 and batch: 1850, loss is 3.5528379917144775 and perplexity is 34.91225772356325
At time: 717.2422106266022 and batch: 1900, loss is 3.627206344604492 and perplexity is 37.60760703164827
At time: 718.4035749435425 and batch: 1950, loss is 3.5626719284057615 and perplexity is 35.25727632083618
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389771927234738 and perplexity of 80.62202919431269
finished 15 epochs...
Completing Train Step...
At time: 722.0534496307373 and batch: 50, loss is 3.779648175239563 and perplexity is 43.800628878658394
At time: 723.2429852485657 and batch: 100, loss is 3.7763969373703 and perplexity is 43.65845386298703
At time: 724.4032175540924 and batch: 150, loss is 3.752529067993164 and perplexity is 42.62875680864755
At time: 725.5629761219025 and batch: 200, loss is 3.760657901763916 and perplexity is 42.97669112079576
At time: 726.7240169048309 and batch: 250, loss is 3.747992787361145 and perplexity is 42.43581874622129
At time: 727.8828918933868 and batch: 300, loss is 3.750740089416504 and perplexity is 42.55256305078863
At time: 729.0449261665344 and batch: 350, loss is 3.7565746021270754 and perplexity is 42.80156220879286
At time: 730.2063491344452 and batch: 400, loss is 3.712620873451233 and perplexity is 40.96101961850089
At time: 731.3669672012329 and batch: 450, loss is 3.7528836297988892 and perplexity is 42.643874017471504
At time: 732.5272941589355 and batch: 500, loss is 3.7607141494750977 and perplexity is 42.97910852929168
At time: 733.6880977153778 and batch: 550, loss is 3.745530157089233 and perplexity is 42.331443585827294
At time: 734.8478274345398 and batch: 600, loss is 3.71955427646637 and perplexity is 41.24600569543428
At time: 736.0090415477753 and batch: 650, loss is 3.740433053970337 and perplexity is 42.11622481478983
At time: 737.1690864562988 and batch: 700, loss is 3.7817424821853636 and perplexity is 43.89245696448428
At time: 738.3289675712585 and batch: 750, loss is 3.73959894657135 and perplexity is 42.08111000685087
At time: 739.4905180931091 and batch: 800, loss is 3.684861936569214 and perplexity is 39.83962167529252
At time: 740.6473937034607 and batch: 850, loss is 3.686630277633667 and perplexity is 39.91013404087449
At time: 741.8067252635956 and batch: 900, loss is 3.6545179986953737 and perplexity is 38.648887810536536
At time: 742.965882062912 and batch: 950, loss is 3.7642291450500487 and perplexity is 43.13044572455665
At time: 744.1258807182312 and batch: 1000, loss is 3.7029461336135863 and perplexity is 40.566643230832
At time: 745.2839598655701 and batch: 1050, loss is 3.6687572622299194 and perplexity is 39.20315633205831
At time: 746.4445369243622 and batch: 1100, loss is 3.688385877609253 and perplexity is 39.98026181136646
At time: 747.604856967926 and batch: 1150, loss is 3.6635432481765746 and perplexity is 38.99928248643061
At time: 748.7660298347473 and batch: 1200, loss is 3.7142014646530153 and perplexity is 41.02581343850748
At time: 749.9268341064453 and batch: 1250, loss is 3.6857075357437132 and perplexity is 39.87332427393009
At time: 751.0880031585693 and batch: 1300, loss is 3.6847837352752686 and perplexity is 39.836506287142505
At time: 752.2492561340332 and batch: 1350, loss is 3.57233446598053 and perplexity is 35.59960228338423
At time: 753.4099924564362 and batch: 1400, loss is 3.606797218322754 and perplexity is 36.84784801132001
At time: 754.5718162059784 and batch: 1450, loss is 3.518982629776001 and perplexity is 33.75007467052195
At time: 755.7330396175385 and batch: 1500, loss is 3.5098055505752566 and perplexity is 33.441764419823855
At time: 756.8951597213745 and batch: 1550, loss is 3.527342987060547 and perplexity is 34.03342013743589
At time: 758.0568718910217 and batch: 1600, loss is 3.624212594032288 and perplexity is 37.495187598412976
At time: 759.2197806835175 and batch: 1650, loss is 3.5559131622314455 and perplexity is 35.01978411545379
At time: 760.3812937736511 and batch: 1700, loss is 3.5768098878860473 and perplexity is 35.75928257508371
At time: 761.5421686172485 and batch: 1750, loss is 3.5619761610031127 and perplexity is 35.23275398917472
At time: 762.7028968334198 and batch: 1800, loss is 3.505738935470581 and perplexity is 33.30604578027758
At time: 763.8643724918365 and batch: 1850, loss is 3.552136149406433 and perplexity is 34.88776342059802
At time: 765.0219421386719 and batch: 1900, loss is 3.627030124664307 and perplexity is 37.60098040527564
At time: 766.1780593395233 and batch: 1950, loss is 3.563297791481018 and perplexity is 35.279349454878776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389653831304506 and perplexity of 80.6125086229592
finished 16 epochs...
Completing Train Step...
At time: 769.8250524997711 and batch: 50, loss is 3.773856072425842 and perplexity is 43.547664438124905
At time: 770.9865794181824 and batch: 100, loss is 3.769162631034851 and perplexity is 43.34375492037177
At time: 772.1479158401489 and batch: 150, loss is 3.7454313898086546 and perplexity is 42.32726283072566
At time: 773.3088109493256 and batch: 200, loss is 3.7536829614639284 and perplexity is 42.67797424317306
At time: 774.4686961174011 and batch: 250, loss is 3.741261429786682 and perplexity is 42.151127331106515
At time: 775.6294591426849 and batch: 300, loss is 3.745132155418396 and perplexity is 42.31459895286957
At time: 776.7910072803497 and batch: 350, loss is 3.750700511932373 and perplexity is 42.550878960725996
At time: 777.9533779621124 and batch: 400, loss is 3.7061874723434447 and perplexity is 40.698346795299145
At time: 779.1141970157623 and batch: 450, loss is 3.7460688495635988 and perplexity is 42.35425335909101
At time: 780.2755205631256 and batch: 500, loss is 3.75332772731781 and perplexity is 42.66281626191039
At time: 781.4788658618927 and batch: 550, loss is 3.737124638557434 and perplexity is 41.977117087438835
At time: 782.6392061710358 and batch: 600, loss is 3.7119651794433595 and perplexity is 40.93417052673689
At time: 783.8002007007599 and batch: 650, loss is 3.733513283729553 and perplexity is 41.82579622410881
At time: 784.9616539478302 and batch: 700, loss is 3.7757769441604614 and perplexity is 43.631394307277105
At time: 786.1232352256775 and batch: 750, loss is 3.7341250514984132 and perplexity is 41.851391726599076
At time: 787.2839303016663 and batch: 800, loss is 3.679394631385803 and perplexity is 39.62240065309926
At time: 788.44500041008 and batch: 850, loss is 3.6815359163284302 and perplexity is 39.70733440423722
At time: 789.6059408187866 and batch: 900, loss is 3.6493264389038087 and perplexity is 38.44875973651411
At time: 790.7681078910828 and batch: 950, loss is 3.7591178131103518 and perplexity is 42.910554147906026
At time: 791.9287147521973 and batch: 1000, loss is 3.698249454498291 and perplexity is 40.376561450769884
At time: 793.0905203819275 and batch: 1050, loss is 3.6642043828964233 and perplexity is 39.025074791286215
At time: 794.2513754367828 and batch: 1100, loss is 3.684125943183899 and perplexity is 39.81031076490724
At time: 795.4120209217072 and batch: 1150, loss is 3.659725193977356 and perplexity is 38.85066500750123
At time: 796.5732831954956 and batch: 1200, loss is 3.710868716239929 and perplexity is 40.889312312176365
At time: 797.7341821193695 and batch: 1250, loss is 3.6823363637924196 and perplexity is 39.73913076332266
At time: 798.8944318294525 and batch: 1300, loss is 3.6813305902481077 and perplexity is 39.69918228985343
At time: 800.0564706325531 and batch: 1350, loss is 3.5685930824279786 and perplexity is 35.46665936722112
At time: 801.2169306278229 and batch: 1400, loss is 3.603708724975586 and perplexity is 36.7342192390566
At time: 802.3781077861786 and batch: 1450, loss is 3.516325478553772 and perplexity is 33.66051465830333
At time: 803.5387010574341 and batch: 1500, loss is 3.507180690765381 and perplexity is 33.3540995807168
At time: 804.6999688148499 and batch: 1550, loss is 3.5248620176315306 and perplexity is 33.94908891735586
At time: 805.8615102767944 and batch: 1600, loss is 3.6219120121002195 and perplexity is 37.409025996199325
At time: 807.0219628810883 and batch: 1650, loss is 3.553814001083374 and perplexity is 34.946349048210635
At time: 808.1834781169891 and batch: 1700, loss is 3.574938373565674 and perplexity is 35.692421151229816
At time: 809.343587398529 and batch: 1750, loss is 3.5602629566192627 and perplexity is 35.172444756357365
At time: 810.5031356811523 and batch: 1800, loss is 3.5041065216064453 and perplexity is 33.251720881808666
At time: 811.6650245189667 and batch: 1850, loss is 3.550885787010193 and perplexity is 34.844168333636425
At time: 812.8270485401154 and batch: 1900, loss is 3.6262250471115114 and perplexity is 37.570720882254015
At time: 813.9879336357117 and batch: 1950, loss is 3.563353319168091 and perplexity is 35.281308489945275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389898539698401 and perplexity of 80.63223759429616
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 817.6390724182129 and batch: 50, loss is 3.7729694557189943 and perplexity is 43.50907146240651
At time: 818.8050546646118 and batch: 100, loss is 3.775983910560608 and perplexity is 43.6404254744321
At time: 819.9669451713562 and batch: 150, loss is 3.763186559677124 and perplexity is 43.085501985629996
At time: 821.1259756088257 and batch: 200, loss is 3.780435380935669 and perplexity is 43.83512255823392
At time: 822.2858512401581 and batch: 250, loss is 3.7797690725326536 and perplexity is 43.805924576236784
At time: 823.4460561275482 and batch: 300, loss is 3.791211609840393 and perplexity is 44.310054263343986
At time: 824.6058688163757 and batch: 350, loss is 3.8052356576919557 and perplexity is 44.93583834131532
At time: 825.765388250351 and batch: 400, loss is 3.7663540697097777 and perplexity is 43.222192114823514
At time: 826.9244947433472 and batch: 450, loss is 3.8126593351364138 and perplexity is 45.27066880982088
At time: 828.0840373039246 and batch: 500, loss is 3.8138670444488527 and perplexity is 45.32537564645143
At time: 829.2434685230255 and batch: 550, loss is 3.7930457305908205 and perplexity is 44.39139882839472
At time: 830.4018504619598 and batch: 600, loss is 3.7521880531311034 and perplexity is 42.61422224741618
At time: 831.5614016056061 and batch: 650, loss is 3.7598493576049803 and perplexity is 42.94195661230392
At time: 832.7206420898438 and batch: 700, loss is 3.7970326375961303 and perplexity is 44.56873648683075
At time: 833.8809292316437 and batch: 750, loss is 3.749489188194275 and perplexity is 42.499367275925835
At time: 835.0389535427094 and batch: 800, loss is 3.6959852886199953 and perplexity is 40.28524563413869
At time: 836.1990571022034 and batch: 850, loss is 3.7035918712615965 and perplexity is 40.59284709912116
At time: 837.3579502105713 and batch: 900, loss is 3.671742877960205 and perplexity is 39.32037679283167
At time: 838.5449125766754 and batch: 950, loss is 3.7847885417938234 and perplexity is 44.02635983929449
At time: 839.7041938304901 and batch: 1000, loss is 3.7248452281951905 and perplexity is 41.46481466397295
At time: 840.8635210990906 and batch: 1050, loss is 3.6883230876922606 and perplexity is 39.97775153285691
At time: 842.0220155715942 and batch: 1100, loss is 3.705729727745056 and perplexity is 40.67972161000444
At time: 843.1864678859711 and batch: 1150, loss is 3.6853752613067625 and perplexity is 39.86007758844697
At time: 844.352623462677 and batch: 1200, loss is 3.737816309928894 and perplexity is 42.006161501021396
At time: 845.5131132602692 and batch: 1250, loss is 3.709808964729309 and perplexity is 40.84600275442327
At time: 846.6719908714294 and batch: 1300, loss is 3.7113040494918823 and perplexity is 40.90711666460749
At time: 847.831027507782 and batch: 1350, loss is 3.586168475151062 and perplexity is 36.095509793495985
At time: 848.9902753829956 and batch: 1400, loss is 3.6115229654312135 and perplexity is 37.02239372712893
At time: 850.1491963863373 and batch: 1450, loss is 3.5165906143188477 and perplexity is 33.66944044783083
At time: 851.3068599700928 and batch: 1500, loss is 3.4987635040283203 and perplexity is 33.07453014079039
At time: 852.4651126861572 and batch: 1550, loss is 3.518775486946106 and perplexity is 33.7430843085722
At time: 853.6387574672699 and batch: 1600, loss is 3.6170122241973877 and perplexity is 37.226178027116404
At time: 854.8090116977692 and batch: 1650, loss is 3.5501659393310545 and perplexity is 34.81909486555156
At time: 855.969384431839 and batch: 1700, loss is 3.573239369392395 and perplexity is 35.631831064719385
At time: 857.1282222270966 and batch: 1750, loss is 3.5638690853118895 and perplexity is 35.2995100878538
At time: 858.2881116867065 and batch: 1800, loss is 3.507367238998413 and perplexity is 33.360322309459434
At time: 859.4471304416656 and batch: 1850, loss is 3.556090955734253 and perplexity is 35.026010959069
At time: 860.6069173812866 and batch: 1900, loss is 3.63995304107666 and perplexity is 38.090048015756615
At time: 861.7670431137085 and batch: 1950, loss is 3.59063907623291 and perplexity is 36.25723966413126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3744844658430235 and perplexity of 79.39889615631378
finished 18 epochs...
Completing Train Step...
At time: 865.4329390525818 and batch: 50, loss is 3.799065570831299 and perplexity is 44.65943391215311
At time: 866.5918605327606 and batch: 100, loss is 3.7863696432113647 and perplexity is 44.09602503860538
At time: 867.7752876281738 and batch: 150, loss is 3.756519913673401 and perplexity is 42.79922152154567
At time: 868.9342973232269 and batch: 200, loss is 3.7648784065246583 and perplexity is 43.15845775393008
At time: 870.0935642719269 and batch: 250, loss is 3.758807535171509 and perplexity is 42.89724201494779
At time: 871.2533295154572 and batch: 300, loss is 3.7663194704055787 and perplexity is 43.22069668292099
At time: 872.4133007526398 and batch: 350, loss is 3.7816248655319216 and perplexity is 43.88729478416991
At time: 873.573668718338 and batch: 400, loss is 3.743719263076782 and perplexity is 42.254855195757735
At time: 874.7433948516846 and batch: 450, loss is 3.7858800315856933 and perplexity is 44.07444039657761
At time: 875.9099225997925 and batch: 500, loss is 3.789441499710083 and perplexity is 44.2316899645989
At time: 877.0718991756439 and batch: 550, loss is 3.767025938034058 and perplexity is 43.25124149419758
At time: 878.2382731437683 and batch: 600, loss is 3.728884449005127 and perplexity is 41.63263891767757
At time: 879.3988025188446 and batch: 650, loss is 3.739093475341797 and perplexity is 42.05984459141536
At time: 880.5584819316864 and batch: 700, loss is 3.7795605659484863 and perplexity is 43.79679170470211
At time: 881.7321412563324 and batch: 750, loss is 3.7363824224472046 and perplexity is 41.945972554292425
At time: 882.9013299942017 and batch: 800, loss is 3.6857105827331544 and perplexity is 39.873445767713235
At time: 884.0621960163116 and batch: 850, loss is 3.694656476974487 and perplexity is 40.23174968149199
At time: 885.2226758003235 and batch: 900, loss is 3.6646922540664675 and perplexity is 39.044118645281635
At time: 886.3870384693146 and batch: 950, loss is 3.7788953590393066 and perplexity is 43.76766746415721
At time: 887.5420613288879 and batch: 1000, loss is 3.715278353691101 and perplexity is 41.07001748443229
At time: 888.704451084137 and batch: 1050, loss is 3.6777706050872805 and perplexity is 39.55810505543021
At time: 889.8675479888916 and batch: 1100, loss is 3.694820623397827 and perplexity is 40.238354121339675
At time: 891.0252375602722 and batch: 1150, loss is 3.6737383937835695 and perplexity is 39.3989195675136
At time: 892.1794588565826 and batch: 1200, loss is 3.725819149017334 and perplexity is 41.50521778188582
At time: 893.3383901119232 and batch: 1250, loss is 3.698599500656128 and perplexity is 40.39069758497777
At time: 894.5056140422821 and batch: 1300, loss is 3.699767804145813 and perplexity is 40.43791375395404
At time: 895.6626908779144 and batch: 1350, loss is 3.5772523641586305 and perplexity is 35.775108710234214
At time: 896.8210399150848 and batch: 1400, loss is 3.605940160751343 and perplexity is 36.816280813576924
At time: 897.982880115509 and batch: 1450, loss is 3.5137768888473513 and perplexity is 33.57483704205299
At time: 899.140988111496 and batch: 1500, loss is 3.4989689588546753 and perplexity is 33.08132616075088
At time: 900.2978324890137 and batch: 1550, loss is 3.5211922979354857 and perplexity is 33.82473359124393
At time: 901.4555249214172 and batch: 1600, loss is 3.6213634395599366 and perplexity is 37.38851005953332
At time: 902.6116993427277 and batch: 1650, loss is 3.5561554765701295 and perplexity is 35.028270939480635
At time: 903.7762393951416 and batch: 1700, loss is 3.5802671766281127 and perplexity is 35.88312669924555
At time: 904.9380068778992 and batch: 1750, loss is 3.5726915884017942 and perplexity is 35.61231796994096
At time: 906.103343963623 and batch: 1800, loss is 3.5163063907623293 and perplexity is 33.65987215955164
At time: 907.2613320350647 and batch: 1850, loss is 3.56537962436676 and perplexity is 35.352871668688856
At time: 908.4308214187622 and batch: 1900, loss is 3.6488482666015627 and perplexity is 38.4303789994823
At time: 909.6050364971161 and batch: 1950, loss is 3.5984260511398314 and perplexity is 36.540676003194605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372085074491279 and perplexity of 79.2086155017052
finished 19 epochs...
Completing Train Step...
At time: 913.4542894363403 and batch: 50, loss is 3.799700212478638 and perplexity is 44.68778564450381
At time: 914.6590156555176 and batch: 100, loss is 3.7824406957626344 and perplexity is 43.92311397520177
At time: 915.8200356960297 and batch: 150, loss is 3.7503995752334593 and perplexity is 42.53807576624784
At time: 916.9782617092133 and batch: 200, loss is 3.7572589778900145 and perplexity is 42.83086458635929
At time: 918.1398844718933 and batch: 250, loss is 3.750285711288452 and perplexity is 42.533232488870645
At time: 919.3020951747894 and batch: 300, loss is 3.7580048847198486 and perplexity is 42.86282433879896
At time: 920.4587721824646 and batch: 350, loss is 3.773146266937256 and perplexity is 43.516765034472094
At time: 921.6161799430847 and batch: 400, loss is 3.735484952926636 and perplexity is 41.908344210086
At time: 922.7732946872711 and batch: 450, loss is 3.7770923805236816 and perplexity is 43.688826395774136
At time: 923.9292335510254 and batch: 500, loss is 3.7813897562026977 and perplexity is 43.87697768460245
At time: 925.0863711833954 and batch: 550, loss is 3.7588030195236204 and perplexity is 42.897048306544825
At time: 926.299905538559 and batch: 600, loss is 3.7219728803634644 and perplexity is 41.34588418010718
At time: 927.4570195674896 and batch: 650, loss is 3.7335740423202513 and perplexity is 41.82833757774596
At time: 928.6142818927765 and batch: 700, loss is 3.774934616088867 and perplexity is 43.59465783330302
At time: 929.7740252017975 and batch: 750, loss is 3.7327877473831177 and perplexity is 41.795461094679816
At time: 930.9317653179169 and batch: 800, loss is 3.682665662765503 and perplexity is 39.75221897312301
At time: 932.0908391475677 and batch: 850, loss is 3.6912238597869873 and perplexity is 40.09388623763435
At time: 933.2469956874847 and batch: 900, loss is 3.66203341960907 and perplexity is 38.940444684294796
At time: 934.4046680927277 and batch: 950, loss is 3.7763930892944337 and perplexity is 43.65828586226759
At time: 935.5617315769196 and batch: 1000, loss is 3.712379035949707 and perplexity is 40.951114905570186
At time: 936.7181694507599 and batch: 1050, loss is 3.674977250099182 and perplexity is 39.44775941437803
At time: 937.8860700130463 and batch: 1100, loss is 3.6921781587600706 and perplexity is 40.132166054387675
At time: 939.0473508834839 and batch: 1150, loss is 3.671391921043396 and perplexity is 39.30657945590172
At time: 940.2035374641418 and batch: 1200, loss is 3.724022307395935 and perplexity is 41.43070644165632
At time: 941.3604838848114 and batch: 1250, loss is 3.6972306156158448 and perplexity is 40.33544518900412
At time: 942.5176427364349 and batch: 1300, loss is 3.6990393733978273 and perplexity is 40.40846825999487
At time: 943.6740555763245 and batch: 1350, loss is 3.5768003940582274 and perplexity is 35.75894308422351
At time: 944.8322811126709 and batch: 1400, loss is 3.6061144733428954 and perplexity is 36.822698914258496
At time: 945.9887187480927 and batch: 1450, loss is 3.514220414161682 and perplexity is 33.58973163502603
At time: 947.1463792324066 and batch: 1500, loss is 3.499732503890991 and perplexity is 33.106594888813966
At time: 948.3073182106018 and batch: 1550, loss is 3.522265920639038 and perplexity is 33.86106809445275
At time: 949.4639883041382 and batch: 1600, loss is 3.6228322887420656 and perplexity is 37.44346849490056
At time: 950.6204080581665 and batch: 1650, loss is 3.5578025579452515 and perplexity is 35.0860128919411
At time: 951.7776641845703 and batch: 1700, loss is 3.581894054412842 and perplexity is 35.94155167317899
At time: 952.9353768825531 and batch: 1750, loss is 3.574719157218933 and perplexity is 35.68459764661009
At time: 954.0928928852081 and batch: 1800, loss is 3.5183295822143554 and perplexity is 33.7280414617027
At time: 955.2501242160797 and batch: 1850, loss is 3.5671467685699465 and perplexity is 35.415400523403655
At time: 956.4071218967438 and batch: 1900, loss is 3.6503199434280393 and perplexity is 38.486977734997005
At time: 957.563836812973 and batch: 1950, loss is 3.5991636991500853 and perplexity is 36.56764010392667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3713722406431685 and perplexity of 79.15217303895258
Finished Training.
Improved accuracyfrom -10000000 to -79.15217303895258
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fad68d45b38>
ELAPSED
989.0815625190735


RESULTS SO FAR:
[{'best_accuracy': -79.15217303895258, 'params': {'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'dropout': 0.532313874403636, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.08424698132469677, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.7320663928985596 and batch: 50, loss is 7.465544233322143 and perplexity is 1746.8059595864825
At time: 2.9586968421936035 and batch: 100, loss is 6.585660877227784 and perplexity is 724.6297807784006
At time: 4.187249422073364 and batch: 150, loss is 6.270690116882324 and perplexity is 528.8422149137065
At time: 5.414583683013916 and batch: 200, loss is 6.1390622615814205 and perplexity is 463.6186139673699
At time: 6.639621734619141 and batch: 250, loss is 6.060008707046509 and perplexity is 428.37916676037725
At time: 7.868216514587402 and batch: 300, loss is 5.9975222301483155 and perplexity is 402.43042716269025
At time: 9.095765113830566 and batch: 350, loss is 5.937831068038941 and perplexity is 379.1117695380574
At time: 10.32308030128479 and batch: 400, loss is 5.885751495361328 and perplexity is 359.8731093760983
At time: 11.550373792648315 and batch: 450, loss is 5.810864572525024 and perplexity is 333.90768832814496
At time: 12.780327320098877 and batch: 500, loss is 5.788571805953979 and perplexity is 326.5463196733544
At time: 14.04169249534607 and batch: 550, loss is 5.736825685501099 and perplexity is 310.0785602394827
At time: 15.268485307693481 and batch: 600, loss is 5.771836595535278 and perplexity is 321.1269717473456
At time: 16.497478723526 and batch: 650, loss is 5.849567079544068 and perplexity is 347.08408814708207
At time: 17.727176904678345 and batch: 700, loss is 5.753924579620361 and perplexity is 315.42614934977695
At time: 18.955364227294922 and batch: 750, loss is 5.699091358184814 and perplexity is 298.59596088892414
At time: 20.18437170982361 and batch: 800, loss is 5.697526569366455 and perplexity is 298.12908664318184
At time: 21.41249656677246 and batch: 850, loss is 5.7196735000610355 and perplexity is 304.80538776817394
At time: 22.64120125770569 and batch: 900, loss is 5.712939214706421 and perplexity is 302.75963737410615
At time: 23.868840217590332 and batch: 950, loss is 5.743893299102783 and perplexity is 312.27783835869604
At time: 25.09717059135437 and batch: 1000, loss is 5.7097390937805175 and perplexity is 301.792318517192
At time: 26.322139739990234 and batch: 1050, loss is 5.6132801818847655 and perplexity is 274.0416718546482
At time: 27.54651689529419 and batch: 1100, loss is 5.695952939987182 and perplexity is 297.66031089000927
At time: 28.77144145965576 and batch: 1150, loss is 5.608994731903076 and perplexity is 272.86979278505584
At time: 29.998964548110962 and batch: 1200, loss is 5.686040534973144 and perplexity is 294.7243565555949
At time: 31.225385427474976 and batch: 1250, loss is 5.616949214935302 and perplexity is 275.0489866114523
At time: 32.454477310180664 and batch: 1300, loss is 5.636071224212646 and perplexity is 280.35908394777175
At time: 33.685051918029785 and batch: 1350, loss is 5.5933066177368165 and perplexity is 268.6223843504385
At time: 34.913782358169556 and batch: 1400, loss is 5.610367984771728 and perplexity is 273.24476942070845
At time: 36.14253854751587 and batch: 1450, loss is 5.576864185333252 and perplexity is 264.24169226462857
At time: 37.370397090911865 and batch: 1500, loss is 5.558122062683106 and perplexity is 259.3353631880963
At time: 38.598758935928345 and batch: 1550, loss is 5.540507125854492 and perplexity is 254.80718601080207
At time: 39.826669454574585 and batch: 1600, loss is 5.57348783493042 and perplexity is 263.35102417041054
At time: 41.0560941696167 and batch: 1650, loss is 5.550007772445679 and perplexity is 257.2395552784746
At time: 42.28134369850159 and batch: 1700, loss is 5.551879167556763 and perplexity is 257.7214028475687
At time: 43.508397340774536 and batch: 1750, loss is 5.573495454788208 and perplexity is 263.35303087540854
At time: 44.73628807067871 and batch: 1800, loss is 5.578626947402954 and perplexity is 264.7078982814067
At time: 45.96562361717224 and batch: 1850, loss is 5.543200988769531 and perplexity is 255.49452702525284
At time: 47.19287610054016 and batch: 1900, loss is 5.5331652736663814 and perplexity is 252.9432799485144
At time: 48.41614103317261 and batch: 1950, loss is 5.477516946792602 and perplexity is 239.25189402044154
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.02443109556686 and perplexity of 152.0837103998291
finished 1 epochs...
Completing Train Step...
At time: 52.19113516807556 and batch: 50, loss is 5.270993127822876 and perplexity is 194.6091382551667
At time: 53.39332580566406 and batch: 100, loss is 5.194552421569824 and perplexity is 180.28743197036286
At time: 54.5536527633667 and batch: 150, loss is 5.115081033706665 and perplexity is 166.5142737054396
At time: 55.71085739135742 and batch: 200, loss is 5.09038387298584 and perplexity is 162.4522111009977
At time: 56.86819124221802 and batch: 250, loss is 5.085998058319092 and perplexity is 161.741285943472
At time: 58.06235957145691 and batch: 300, loss is 5.098917503356933 and perplexity is 163.84445020154547
At time: 59.221415281295776 and batch: 350, loss is 5.072911367416382 and perplexity is 159.63841753417427
At time: 60.38422870635986 and batch: 400, loss is 5.042306680679321 and perplexity is 154.8267392914002
At time: 61.54085612297058 and batch: 450, loss is 4.996792230606079 and perplexity is 147.93784666706566
At time: 62.697359561920166 and batch: 500, loss is 4.991524248123169 and perplexity is 147.16056184126393
At time: 63.85538363456726 and batch: 550, loss is 4.945016326904297 and perplexity is 140.47314432430716
At time: 65.01521492004395 and batch: 600, loss is 4.94147894859314 and perplexity is 139.97711550829786
At time: 66.1727089881897 and batch: 650, loss is 5.0088200187683105 and perplexity is 149.72795569317128
At time: 67.32921934127808 and batch: 700, loss is 4.988474826812745 and perplexity is 146.7124908138175
At time: 68.48667407035828 and batch: 750, loss is 4.947118530273437 and perplexity is 140.7687580528013
At time: 69.64686346054077 and batch: 800, loss is 4.928254728317261 and perplexity is 138.13821312319672
At time: 70.81211614608765 and batch: 850, loss is 4.916102933883667 and perplexity is 136.4697439325237
At time: 71.96922206878662 and batch: 900, loss is 4.926107444763184 and perplexity is 137.84190944782267
At time: 73.12811803817749 and batch: 950, loss is 4.981982421875 and perplexity is 145.76305929594687
At time: 74.29585576057434 and batch: 1000, loss is 4.945588188171387 and perplexity is 140.55349844812824
At time: 75.46490550041199 and batch: 1050, loss is 4.864016437530518 and perplexity is 129.5434618441668
At time: 76.62818503379822 and batch: 1100, loss is 4.943868618011475 and perplexity is 140.31201453009947
At time: 77.78956961631775 and batch: 1150, loss is 4.855616340637207 and perplexity is 128.45984184111657
At time: 78.94989538192749 and batch: 1200, loss is 4.931875371932984 and perplexity is 138.63926888744152
At time: 80.10645127296448 and batch: 1250, loss is 4.875057792663574 and perplexity is 130.9817227747225
At time: 81.26293420791626 and batch: 1300, loss is 4.913309535980225 and perplexity is 136.08906158211997
At time: 82.42279314994812 and batch: 1350, loss is 4.8188258647918705 and perplexity is 123.81962441746076
At time: 83.5802264213562 and batch: 1400, loss is 4.829998388290405 and perplexity is 125.21075885122113
At time: 84.73645186424255 and batch: 1450, loss is 4.773473272323608 and perplexity is 118.32951969088337
At time: 85.89375519752502 and batch: 1500, loss is 4.749846811294556 and perplexity is 115.56657967639745
At time: 87.05187582969666 and batch: 1550, loss is 4.742737636566162 and perplexity is 114.74791014905766
At time: 88.20895719528198 and batch: 1600, loss is 4.818290729522705 and perplexity is 123.75338189535587
At time: 89.37546753883362 and batch: 1650, loss is 4.77229344367981 and perplexity is 118.18999345885268
At time: 90.5378930568695 and batch: 1700, loss is 4.8035366821289065 and perplexity is 121.94092207099408
At time: 91.70176291465759 and batch: 1750, loss is 4.80789210319519 and perplexity is 122.47318440370833
At time: 92.86019039154053 and batch: 1800, loss is 4.760484848022461 and perplexity is 116.80254365468674
At time: 94.01719450950623 and batch: 1850, loss is 4.777650365829468 and perplexity is 118.82482691124136
At time: 95.17476224899292 and batch: 1900, loss is 4.844073286056519 and perplexity is 126.98554817126436
At time: 96.33287954330444 and batch: 1950, loss is 4.761527194976806 and perplexity is 116.92435590460988
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.635740200308867 and perplexity of 103.10420752323411
finished 2 epochs...
Completing Train Step...
At time: 100.11537289619446 and batch: 50, loss is 4.6998996925354 and perplexity is 109.93614448311793
At time: 101.29921650886536 and batch: 100, loss is 4.645332632064819 and perplexity is 104.09798635528513
At time: 102.45641756057739 and batch: 150, loss is 4.592881965637207 and perplexity is 98.7786971522246
At time: 103.61974382400513 and batch: 200, loss is 4.593043041229248 and perplexity is 98.79460927084203
At time: 104.7801775932312 and batch: 250, loss is 4.593763637542724 and perplexity is 98.86582595823346
At time: 105.94079923629761 and batch: 300, loss is 4.6161863899230955 and perplexity is 101.10771057396879
At time: 107.10109376907349 and batch: 350, loss is 4.61935417175293 and perplexity is 101.42850557841368
At time: 108.26348876953125 and batch: 400, loss is 4.592603540420532 and perplexity is 98.7511985004038
At time: 109.42338061332703 and batch: 450, loss is 4.586735019683838 and perplexity is 98.17337219539554
At time: 110.5812041759491 and batch: 500, loss is 4.596958494186401 and perplexity is 99.18219320402768
At time: 111.73803901672363 and batch: 550, loss is 4.5525288772583 and perplexity is 94.8720249129926
At time: 112.8956687450409 and batch: 600, loss is 4.531304769515991 and perplexity is 92.87966861648701
At time: 114.05493426322937 and batch: 650, loss is 4.585977401733398 and perplexity is 98.09902245427068
At time: 115.21311259269714 and batch: 700, loss is 4.605476875305175 and perplexity is 100.03067363510607
At time: 116.41456866264343 and batch: 750, loss is 4.57347149848938 and perplexity is 96.87984491893548
At time: 117.57158517837524 and batch: 800, loss is 4.547130403518676 and perplexity is 94.36124074583476
At time: 118.72810792922974 and batch: 850, loss is 4.533680982589722 and perplexity is 93.10063292450523
At time: 119.90477895736694 and batch: 900, loss is 4.5287140846252445 and perplexity is 92.63935808118782
At time: 121.07333564758301 and batch: 950, loss is 4.597479467391968 and perplexity is 99.23387793116632
At time: 122.23014187812805 and batch: 1000, loss is 4.581949739456177 and perplexity is 97.70470733920673
At time: 123.38969802856445 and batch: 1050, loss is 4.511117668151855 and perplexity is 91.0234957415045
At time: 124.55196046829224 and batch: 1100, loss is 4.580485391616821 and perplexity is 97.56173836582084
At time: 125.71174454689026 and batch: 1150, loss is 4.518179397583008 and perplexity is 91.66855397301185
At time: 126.86933612823486 and batch: 1200, loss is 4.585160522460938 and perplexity is 98.0189201176027
At time: 128.0265007019043 and batch: 1250, loss is 4.550065975189209 and perplexity is 94.63865191192698
At time: 129.1839520931244 and batch: 1300, loss is 4.575546464920044 and perplexity is 97.0810760466678
At time: 130.34038138389587 and batch: 1350, loss is 4.456232404708862 and perplexity is 86.16227222948173
At time: 131.49699878692627 and batch: 1400, loss is 4.480398063659668 and perplexity is 88.2698026838923
At time: 132.65365600585938 and batch: 1450, loss is 4.41789511680603 and perplexity is 82.92156133515172
At time: 133.81814455986023 and batch: 1500, loss is 4.411800346374512 and perplexity is 82.4177104424313
At time: 134.97518968582153 and batch: 1550, loss is 4.420465393066406 and perplexity is 83.1349667937314
At time: 136.13232231140137 and batch: 1600, loss is 4.502715063095093 and perplexity is 90.26186557580186
At time: 137.28989839553833 and batch: 1650, loss is 4.447072019577027 and perplexity is 85.3765966713786
At time: 138.4482536315918 and batch: 1700, loss is 4.484223384857177 and perplexity is 88.6081096851311
At time: 139.60584235191345 and batch: 1750, loss is 4.490084590911866 and perplexity is 89.128985061901
At time: 140.7629702091217 and batch: 1800, loss is 4.437020654678345 and perplexity is 84.52274372689801
At time: 141.92021298408508 and batch: 1850, loss is 4.476271247863769 and perplexity is 87.90628007920658
At time: 143.078040599823 and batch: 1900, loss is 4.551937980651855 and perplexity is 94.81598191486432
At time: 144.23445677757263 and batch: 1950, loss is 4.476137132644653 and perplexity is 87.89449129973713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5244501158248545 and perplexity of 92.24518771093676
finished 3 epochs...
Completing Train Step...
At time: 147.94811177253723 and batch: 50, loss is 4.426895217895508 and perplexity is 83.67123226636214
At time: 149.10440826416016 and batch: 100, loss is 4.380543270111084 and perplexity is 79.88141880629001
At time: 150.26280736923218 and batch: 150, loss is 4.3331469058990475 and perplexity is 76.18365252612476
At time: 151.42102670669556 and batch: 200, loss is 4.3406439208984375 and perplexity is 76.75694883213885
At time: 152.57635116577148 and batch: 250, loss is 4.33290807723999 and perplexity is 76.16545985910146
At time: 153.73165011405945 and batch: 300, loss is 4.356721134185791 and perplexity is 78.00095999061105
At time: 154.88833475112915 and batch: 350, loss is 4.368917913436889 and perplexity is 78.95814590765762
At time: 156.05290913581848 and batch: 400, loss is 4.338909902572632 and perplexity is 76.62396620670697
At time: 157.2124879360199 and batch: 450, loss is 4.349036817550659 and perplexity is 77.40387295720996
At time: 158.37330222129822 and batch: 500, loss is 4.361856327056885 and perplexity is 78.40254017767127
At time: 159.53590488433838 and batch: 550, loss is 4.319048137664795 and perplexity is 75.11709311993529
At time: 160.69437956809998 and batch: 600, loss is 4.304525079727173 and perplexity is 74.03404683264402
At time: 161.85048151016235 and batch: 650, loss is 4.3504825210571285 and perplexity is 77.51585693606954
At time: 163.00684928894043 and batch: 700, loss is 4.378080711364746 and perplexity is 79.68494812931709
At time: 164.17075037956238 and batch: 750, loss is 4.349869365692139 and perplexity is 77.46834224095116
At time: 165.33929347991943 and batch: 800, loss is 4.3218759059906 and perplexity is 75.32980746829129
At time: 166.50997376441956 and batch: 850, loss is 4.3104587650299075 and perplexity is 74.47464746825044
At time: 167.67819571495056 and batch: 900, loss is 4.300053195953369 and perplexity is 73.7037143346648
At time: 168.84758472442627 and batch: 950, loss is 4.37371190071106 and perplexity is 79.33757902641506
At time: 170.01587748527527 and batch: 1000, loss is 4.360338888168335 and perplexity is 78.28365933426346
At time: 171.18507552146912 and batch: 1050, loss is 4.301606130599976 and perplexity is 73.81826030442124
At time: 172.35106229782104 and batch: 1100, loss is 4.361094913482666 and perplexity is 78.3428661405207
At time: 173.56333875656128 and batch: 1150, loss is 4.307745299339294 and perplexity is 74.27283699424922
At time: 174.73067450523376 and batch: 1200, loss is 4.3724369764328 and perplexity is 79.23649407225928
At time: 175.9005262851715 and batch: 1250, loss is 4.342457895278931 and perplexity is 76.89631033172597
At time: 177.06924533843994 and batch: 1300, loss is 4.36410590171814 and perplexity is 78.57911107567931
At time: 178.2381284236908 and batch: 1350, loss is 4.242905397415161 and perplexity is 69.60980246342979
At time: 179.4046332836151 and batch: 1400, loss is 4.271252946853638 and perplexity is 71.61130459103263
At time: 180.58178663253784 and batch: 1450, loss is 4.2055192470550535 and perplexity is 67.05540695079799
At time: 181.7492551803589 and batch: 1500, loss is 4.205358500480652 and perplexity is 67.04462889012692
At time: 182.9191882610321 and batch: 1550, loss is 4.2127007961273195 and perplexity is 67.53870197268823
At time: 184.0845582485199 and batch: 1600, loss is 4.3036489582061765 and perplexity is 73.96921241648829
At time: 185.25026202201843 and batch: 1650, loss is 4.24170804977417 and perplexity is 69.52650520849772
At time: 186.41631650924683 and batch: 1700, loss is 4.281582584381104 and perplexity is 72.35485711284657
At time: 187.582692861557 and batch: 1750, loss is 4.288652844429016 and perplexity is 72.86823749617633
At time: 188.74964833259583 and batch: 1800, loss is 4.2360614395141605 and perplexity is 69.13502244631154
At time: 189.9152705669403 and batch: 1850, loss is 4.278453397750854 and perplexity is 72.12879913459673
At time: 191.08042073249817 and batch: 1900, loss is 4.358181524276733 and perplexity is 78.11495503802402
At time: 192.2461793422699 and batch: 1950, loss is 4.283226413726807 and perplexity is 72.47389396160055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482847133902617 and perplexity of 88.4862465659469
finished 4 epochs...
Completing Train Step...
At time: 195.92647695541382 and batch: 50, loss is 4.240093150138855 and perplexity is 69.41431749092511
At time: 197.08498573303223 and batch: 100, loss is 4.199692354202271 and perplexity is 66.66581842688596
At time: 198.2380883693695 and batch: 150, loss is 4.156585707664489 and perplexity is 63.85313672016769
At time: 199.3969762325287 and batch: 200, loss is 4.164153652191162 and perplexity is 64.33820689365405
At time: 200.55156230926514 and batch: 250, loss is 4.154779472351074 and perplexity is 63.737907027049765
At time: 201.70547342300415 and batch: 300, loss is 4.1760381412506105 and perplexity is 65.10739526156271
At time: 202.89891862869263 and batch: 350, loss is 4.186206550598144 and perplexity is 65.77281128592823
At time: 204.05493831634521 and batch: 400, loss is 4.155551629066467 and perplexity is 63.78714168597581
At time: 205.20821619033813 and batch: 450, loss is 4.177601809501648 and perplexity is 65.20928126563611
At time: 206.36185312271118 and batch: 500, loss is 4.1950143480300905 and perplexity is 66.35468362946216
At time: 207.51499319076538 and batch: 550, loss is 4.146769342422485 and perplexity is 63.22939744322571
At time: 208.6707785129547 and batch: 600, loss is 4.1404425191879275 and perplexity is 62.83061905278179
At time: 209.82320857048035 and batch: 650, loss is 4.182929277420044 and perplexity is 65.55760864718616
At time: 210.97518491744995 and batch: 700, loss is 4.219555583000183 and perplexity is 68.00325576997615
At time: 212.12862825393677 and batch: 750, loss is 4.190698833465576 and perplexity is 66.0689460216961
At time: 213.28011631965637 and batch: 800, loss is 4.1605358934402465 and perplexity is 64.10586731033511
At time: 214.4323925971985 and batch: 850, loss is 4.149365382194519 and perplexity is 63.39375672305654
At time: 215.58568668365479 and batch: 900, loss is 4.13682032585144 and perplexity is 62.60344608370995
At time: 216.7391586303711 and batch: 950, loss is 4.220308046340943 and perplexity is 68.05444498358344
At time: 217.8926556110382 and batch: 1000, loss is 4.202836799621582 and perplexity is 66.8757753803569
At time: 219.05265545845032 and batch: 1050, loss is 4.147931060791016 and perplexity is 63.302894879061306
At time: 220.20650386810303 and batch: 1100, loss is 4.20144633769989 and perplexity is 66.78285177954261
At time: 221.36113619804382 and batch: 1150, loss is 4.150694336891174 and perplexity is 63.478060159108395
At time: 222.5143735408783 and batch: 1200, loss is 4.2142931079864505 and perplexity is 67.64633031499199
At time: 223.66714525222778 and batch: 1250, loss is 4.189948835372925 and perplexity is 66.01941301534836
At time: 224.8211154937744 and batch: 1300, loss is 4.204174246788025 and perplexity is 66.96527803583791
At time: 225.9746515750885 and batch: 1350, loss is 4.084613447189331 and perplexity is 59.41896474356092
At time: 227.12957239151 and batch: 1400, loss is 4.119076519012451 and perplexity is 61.5024197158993
At time: 228.28294849395752 and batch: 1450, loss is 4.049200186729431 and perplexity is 57.35156815132384
At time: 229.43647122383118 and batch: 1500, loss is 4.049157729148865 and perplexity is 57.34913319419003
At time: 230.5901234149933 and batch: 1550, loss is 4.063130578994751 and perplexity is 58.15608862548308
At time: 231.74441528320312 and batch: 1600, loss is 4.1529488945007325 and perplexity is 63.62133655443394
At time: 232.90115785598755 and batch: 1650, loss is 4.093425650596618 and perplexity is 59.94489062667082
At time: 234.05712699890137 and batch: 1700, loss is 4.133556561470032 and perplexity is 62.39945625467522
At time: 235.20976185798645 and batch: 1750, loss is 4.14173761844635 and perplexity is 62.912043656013914
At time: 236.3627507686615 and batch: 1800, loss is 4.0829763603210445 and perplexity is 59.321770316219585
At time: 237.51552510261536 and batch: 1850, loss is 4.13068932056427 and perplexity is 62.22079823139741
At time: 238.66886186599731 and batch: 1900, loss is 4.211586165428161 and perplexity is 67.46346320159992
At time: 239.82304739952087 and batch: 1950, loss is 4.137557272911072 and perplexity is 62.64959851308395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47373415924782 and perplexity of 87.68353673602716
finished 5 epochs...
Completing Train Step...
At time: 243.48876810073853 and batch: 50, loss is 4.096925292015076 and perplexity is 60.155043764558286
At time: 244.64443802833557 and batch: 100, loss is 4.057989354133606 and perplexity is 57.85786237781171
At time: 245.79976201057434 and batch: 150, loss is 4.02161021232605 and perplexity is 55.7908686832068
At time: 246.95423817634583 and batch: 200, loss is 4.030760779380798 and perplexity is 56.30372967397247
At time: 248.1101176738739 and batch: 250, loss is 4.019614639282227 and perplexity is 55.679644944029626
At time: 249.2638177871704 and batch: 300, loss is 4.035489754676819 and perplexity is 56.570619180240215
At time: 250.42323470115662 and batch: 350, loss is 4.044177598953247 and perplexity is 57.064237043064985
At time: 251.5808985233307 and batch: 400, loss is 4.018887095451355 and perplexity is 55.6391502944479
At time: 252.7371587753296 and batch: 450, loss is 4.044314332008362 and perplexity is 57.07204014399243
At time: 253.89795589447021 and batch: 500, loss is 4.067356905937195 and perplexity is 58.402395389540416
At time: 255.05463099479675 and batch: 550, loss is 4.01461932182312 and perplexity is 55.40220097879148
At time: 256.2131061553955 and batch: 600, loss is 4.0112546443939205 and perplexity is 55.21610369785866
At time: 257.3655323982239 and batch: 650, loss is 4.048698120117187 and perplexity is 57.32278107091591
At time: 258.5183618068695 and batch: 700, loss is 4.090831141471863 and perplexity is 59.78956464542641
At time: 259.6741056442261 and batch: 750, loss is 4.0624544095993045 and perplexity is 58.11677854982843
At time: 260.86883187294006 and batch: 800, loss is 4.028150992393494 and perplexity is 56.1569805082564
At time: 262.02414321899414 and batch: 850, loss is 4.024278144836426 and perplexity is 55.93991368814913
At time: 263.1799671649933 and batch: 900, loss is 4.012555346488953 and perplexity is 55.287970127893914
At time: 264.33430767059326 and batch: 950, loss is 4.094958629608154 and perplexity is 60.036855357841716
At time: 265.48910689353943 and batch: 1000, loss is 4.078883261680603 and perplexity is 59.07945670384747
At time: 266.6440691947937 and batch: 1050, loss is 4.029181537628173 and perplexity is 56.21488264717541
At time: 267.8069677352905 and batch: 1100, loss is 4.068597292900085 and perplexity is 58.47488190575428
At time: 268.96198081970215 and batch: 1150, loss is 4.02986512184143 and perplexity is 56.253323390748925
At time: 270.11758637428284 and batch: 1200, loss is 4.08754638671875 and perplexity is 59.59349278904681
At time: 271.27287793159485 and batch: 1250, loss is 4.069132924079895 and perplexity is 58.50621126548063
At time: 272.43964529037476 and batch: 1300, loss is 4.083657760620117 and perplexity is 59.36220596312096
At time: 273.5992925167084 and batch: 1350, loss is 3.962042727470398 and perplexity is 52.56459148967285
At time: 274.7616994380951 and batch: 1400, loss is 4.002127356529236 and perplexity is 54.71442339770109
At time: 275.91710352897644 and batch: 1450, loss is 3.923210816383362 and perplexity is 50.56253142787246
At time: 277.0793409347534 and batch: 1500, loss is 3.929403862953186 and perplexity is 50.87663917771932
At time: 278.2364647388458 and batch: 1550, loss is 3.9455333709716798 and perplexity is 51.703908122646794
At time: 279.39131903648376 and batch: 1600, loss is 4.0364752817153935 and perplexity is 56.62639853654846
At time: 280.5528862476349 and batch: 1650, loss is 3.9758207273483275 and perplexity is 53.29383867235235
At time: 281.70817589759827 and batch: 1700, loss is 4.015794534683227 and perplexity is 55.46734863154157
At time: 282.86231231689453 and batch: 1750, loss is 4.026815619468689 and perplexity is 56.08204004481609
At time: 284.02115511894226 and batch: 1800, loss is 3.964576144218445 and perplexity is 52.6979283336887
At time: 285.17483377456665 and batch: 1850, loss is 4.013768129348755 and perplexity is 55.35506310680207
At time: 286.3289523124695 and batch: 1900, loss is 4.095219283103943 and perplexity is 60.05250621370345
At time: 287.49012899398804 and batch: 1950, loss is 4.021242122650147 and perplexity is 55.77033641952382
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.469233739098837 and perplexity of 87.28981061159477
finished 6 epochs...
Completing Train Step...
At time: 291.112099647522 and batch: 50, loss is 3.983880429267883 and perplexity is 53.725106737675404
At time: 292.28906059265137 and batch: 100, loss is 3.947082033157349 and perplexity is 51.78404204417888
At time: 293.442507982254 and batch: 150, loss is 3.9154317808151244 and perplexity is 50.17072959344734
At time: 294.5951044559479 and batch: 200, loss is 3.9192688131332396 and perplexity is 50.363606104383344
At time: 295.7483584880829 and batch: 250, loss is 3.9087509870529176 and perplexity is 49.83666644216199
At time: 296.901841878891 and batch: 300, loss is 3.919758186340332 and perplexity is 50.38825873549996
At time: 298.05523324012756 and batch: 350, loss is 3.934973888397217 and perplexity is 51.1608140483616
At time: 299.2081003189087 and batch: 400, loss is 3.906895332336426 and perplexity is 49.74427254911892
At time: 300.360857963562 and batch: 450, loss is 3.933873133659363 and perplexity is 51.104529523317346
At time: 301.53244519233704 and batch: 500, loss is 3.959211549758911 and perplexity is 52.41598225867074
At time: 302.70008730888367 and batch: 550, loss is 3.9120549392700195 and perplexity is 50.0015967175882
At time: 303.86834955215454 and batch: 600, loss is 3.906704001426697 and perplexity is 49.734755842647374
At time: 305.0324866771698 and batch: 650, loss is 3.9450460147857664 and perplexity is 51.678716042444016
At time: 306.1899621486664 and batch: 700, loss is 3.9843951845169068 and perplexity is 53.7527691374449
At time: 307.3444790840149 and batch: 750, loss is 3.960351576805115 and perplexity is 52.475771970567756
At time: 308.5022392272949 and batch: 800, loss is 3.927099380493164 and perplexity is 50.75952984513794
At time: 309.6604917049408 and batch: 850, loss is 3.920941171646118 and perplexity is 50.44790257710658
At time: 310.82500767707825 and batch: 900, loss is 3.907262053489685 and perplexity is 49.76251817143951
At time: 311.9849019050598 and batch: 950, loss is 3.993077931404114 and perplexity is 54.22152291661472
At time: 313.14152908325195 and batch: 1000, loss is 3.9742484283447266 and perplexity is 53.21011066289151
At time: 314.30137300491333 and batch: 1050, loss is 3.9307058525085448 and perplexity is 50.94292317171081
At time: 315.4549822807312 and batch: 1100, loss is 3.9662261247634887 and perplexity is 52.78495066303588
At time: 316.61024165153503 and batch: 1150, loss is 3.9333995676040647 and perplexity is 51.08033388243241
At time: 317.8114912509918 and batch: 1200, loss is 3.989095687866211 and perplexity is 54.00602896683917
At time: 318.9641897678375 and batch: 1250, loss is 3.9714127159118653 and perplexity is 53.05943582675191
At time: 320.1178617477417 and batch: 1300, loss is 3.9858599948883056 and perplexity is 53.831564447173236
At time: 321.2696454524994 and batch: 1350, loss is 3.858678812980652 and perplexity is 47.40268217073768
At time: 322.4225833415985 and batch: 1400, loss is 3.903048963546753 and perplexity is 49.553305232523826
At time: 323.577189207077 and batch: 1450, loss is 3.8259280347824096 and perplexity is 45.875354542072124
At time: 324.7351281642914 and batch: 1500, loss is 3.8340516662597657 and perplexity is 46.24954685865646
At time: 325.88628339767456 and batch: 1550, loss is 3.8491443395614624 and perplexity is 46.952870324678784
At time: 327.03995847702026 and batch: 1600, loss is 3.9414576292037964 and perplexity is 51.493605206062526
At time: 328.1914253234863 and batch: 1650, loss is 3.878277201652527 and perplexity is 48.34086173475414
At time: 329.3446156978607 and batch: 1700, loss is 3.9192452144622805 and perplexity is 50.36241760423814
At time: 330.497882604599 and batch: 1750, loss is 3.9248663568496704 and perplexity is 50.64630907423725
At time: 331.6497075557709 and batch: 1800, loss is 3.86416335105896 and perplexity is 47.6633782313715
At time: 332.80191707611084 and batch: 1850, loss is 3.918053960800171 and perplexity is 50.30245890993203
At time: 333.96018624305725 and batch: 1900, loss is 3.998122520446777 and perplexity is 54.49573928993397
At time: 335.11316180229187 and batch: 1950, loss is 3.927101979255676 and perplexity is 50.759661757272625
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.480089480377907 and perplexity of 88.24256830075346
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 338.72419476509094 and batch: 50, loss is 3.9257350301742555 and perplexity is 50.69032328613688
At time: 339.8989112377167 and batch: 100, loss is 3.9213093090057374 and perplexity is 50.46647775365808
At time: 341.0523591041565 and batch: 150, loss is 3.8901854372024536 and perplexity is 48.9199572626986
At time: 342.2091131210327 and batch: 200, loss is 3.9003416013717653 and perplexity is 49.41932793266431
At time: 343.3612594604492 and batch: 250, loss is 3.8936645126342775 and perplexity is 49.090449890523814
At time: 344.51518988609314 and batch: 300, loss is 3.8905225801467895 and perplexity is 48.936453061691815
At time: 345.66962909698486 and batch: 350, loss is 3.9019996166229247 and perplexity is 49.50133389686208
At time: 346.8471658229828 and batch: 400, loss is 3.8717171573638915 and perplexity is 48.02478142476015
At time: 348.00112652778625 and batch: 450, loss is 3.8836272239685057 and perplexity is 48.60017948314742
At time: 349.1551549434662 and batch: 500, loss is 3.8977591037750243 and perplexity is 49.29186729128503
At time: 350.30783677101135 and batch: 550, loss is 3.84641655921936 and perplexity is 46.824967732398285
At time: 351.4679319858551 and batch: 600, loss is 3.8295676136016845 and perplexity is 46.04262572446953
At time: 352.621515750885 and batch: 650, loss is 3.8603381061553956 and perplexity is 47.48140240964429
At time: 353.77492213249207 and batch: 700, loss is 3.8950725030899047 and perplexity is 49.15961745764259
At time: 354.93123030662537 and batch: 750, loss is 3.857549204826355 and perplexity is 47.34916594629445
At time: 356.0948956012726 and batch: 800, loss is 3.814864559173584 and perplexity is 45.370610933744416
At time: 357.2540793418884 and batch: 850, loss is 3.8075608444213866 and perplexity is 45.04044412316108
At time: 358.4111659526825 and batch: 900, loss is 3.793731050491333 and perplexity is 44.42183156431209
At time: 359.5696976184845 and batch: 950, loss is 3.879825792312622 and perplexity is 48.415779935578584
At time: 360.73011231422424 and batch: 1000, loss is 3.851029939651489 and perplexity is 47.04148818385499
At time: 361.8843696117401 and batch: 1050, loss is 3.792931160926819 and perplexity is 44.38631321208062
At time: 363.03780817985535 and batch: 1100, loss is 3.819614119529724 and perplexity is 45.58661394237716
At time: 364.19502568244934 and batch: 1150, loss is 3.780690426826477 and perplexity is 43.84630395193912
At time: 365.3523197174072 and batch: 1200, loss is 3.821920051574707 and perplexity is 45.69185486886826
At time: 366.5053782463074 and batch: 1250, loss is 3.7938559532165526 and perplexity is 44.42738031865377
At time: 367.65812158584595 and batch: 1300, loss is 3.802959370613098 and perplexity is 44.833667801976844
At time: 368.81714487075806 and batch: 1350, loss is 3.672687268257141 and perplexity is 39.357528115059615
At time: 369.9751296043396 and batch: 1400, loss is 3.702880311012268 and perplexity is 40.563973116725684
At time: 371.1312346458435 and batch: 1450, loss is 3.621213660240173 and perplexity is 37.38291045329271
At time: 372.28776955604553 and batch: 1500, loss is 3.6122613906860352 and perplexity is 37.049742093770604
At time: 373.44944858551025 and batch: 1550, loss is 3.6235784530639648 and perplexity is 37.47141790130778
At time: 374.6109354496002 and batch: 1600, loss is 3.709343295097351 and perplexity is 40.82698643935751
At time: 375.77176332473755 and batch: 1650, loss is 3.642522220611572 and perplexity is 38.188034005504434
At time: 376.9298369884491 and batch: 1700, loss is 3.6622086429595946 and perplexity is 38.94726855731679
At time: 378.08934569358826 and batch: 1750, loss is 3.6583655786514284 and perplexity is 38.797878940438935
At time: 379.2507519721985 and batch: 1800, loss is 3.5829099559783937 and perplexity is 35.978083304921185
At time: 380.40613293647766 and batch: 1850, loss is 3.6233184814453123 and perplexity is 37.46167766229049
At time: 381.5617685317993 and batch: 1900, loss is 3.6947356176376345 and perplexity is 40.234933774835326
At time: 382.72130584716797 and batch: 1950, loss is 3.6133846139907835 and perplexity is 37.09138060782222
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.422212822492733 and perplexity of 83.28036628173716
finished 8 epochs...
Completing Train Step...
At time: 386.420991897583 and batch: 50, loss is 3.8237776136398316 and perplexity is 45.77680920470543
At time: 387.6435556411743 and batch: 100, loss is 3.8031408739089967 and perplexity is 44.84180599898258
At time: 388.8220384120941 and batch: 150, loss is 3.767905650138855 and perplexity is 43.2893068757211
At time: 389.9898796081543 and batch: 200, loss is 3.7722726964950564 and perplexity is 43.47876667433643
At time: 391.1627130508423 and batch: 250, loss is 3.764656810760498 and perplexity is 43.14889508206703
At time: 392.3408155441284 and batch: 300, loss is 3.7634018898010253 and perplexity is 43.0947805910567
At time: 393.5001540184021 and batch: 350, loss is 3.7724966907501223 and perplexity is 43.48850675910962
At time: 394.6553587913513 and batch: 400, loss is 3.7505759954452516 and perplexity is 42.54558100460216
At time: 395.8109188079834 and batch: 450, loss is 3.7694371795654296 and perplexity is 43.35565651830326
At time: 396.9667179584503 and batch: 500, loss is 3.7880261611938475 and perplexity is 44.169131431347644
At time: 398.12352108955383 and batch: 550, loss is 3.7347015857696535 and perplexity is 41.875527445094455
At time: 399.2822484970093 and batch: 600, loss is 3.725971984863281 and perplexity is 41.51156175173738
At time: 400.44067096710205 and batch: 650, loss is 3.754341135025024 and perplexity is 42.706073003377234
At time: 401.59537148475647 and batch: 700, loss is 3.7915514373779295 and perplexity is 44.32511459878583
At time: 402.75281047821045 and batch: 750, loss is 3.7578213357925416 and perplexity is 42.8549576353548
At time: 403.9091145992279 and batch: 800, loss is 3.7189733743667603 and perplexity is 41.22205276195354
At time: 405.09114599227905 and batch: 850, loss is 3.7130502700805663 and perplexity is 40.9786119190261
At time: 406.2481679916382 and batch: 900, loss is 3.700708622932434 and perplexity is 40.47597640512661
At time: 407.40516114234924 and batch: 950, loss is 3.7882829236984255 and perplexity is 44.18047386425241
At time: 408.56301188468933 and batch: 1000, loss is 3.7634176921844484 and perplexity is 43.09546159668387
At time: 409.7201852798462 and batch: 1050, loss is 3.712308340072632 and perplexity is 40.94821993291726
At time: 410.87806391716003 and batch: 1100, loss is 3.738281874656677 and perplexity is 42.02572264130098
At time: 412.036292552948 and batch: 1150, loss is 3.7036019229888915 and perplexity is 40.59325512940102
At time: 413.1927447319031 and batch: 1200, loss is 3.7474514293670653 and perplexity is 42.41285199368614
At time: 414.3490660190582 and batch: 1250, loss is 3.725168390274048 and perplexity is 41.478216685075054
At time: 415.50552582740784 and batch: 1300, loss is 3.7352770376205444 and perplexity is 41.899631729632176
At time: 416.6626555919647 and batch: 1350, loss is 3.6084899950027465 and perplexity is 36.910276012566584
At time: 417.81910824775696 and batch: 1400, loss is 3.641935119628906 and perplexity is 38.165620353396115
At time: 418.97468519210815 and batch: 1450, loss is 3.5622526931762697 and perplexity is 35.24249832645094
At time: 420.1359405517578 and batch: 1500, loss is 3.557119174003601 and perplexity is 35.06204386511105
At time: 421.29267406463623 and batch: 1550, loss is 3.5721716356277464 and perplexity is 35.593806059498874
At time: 422.4498963356018 and batch: 1600, loss is 3.660389666557312 and perplexity is 38.87648878775856
At time: 423.6135559082031 and batch: 1650, loss is 3.598142533302307 and perplexity is 36.530317538226676
At time: 424.77410793304443 and batch: 1700, loss is 3.6223315238952636 and perplexity is 37.42472281611619
At time: 425.9296576976776 and batch: 1750, loss is 3.623350210189819 and perplexity is 37.46286629314662
At time: 427.0878038406372 and batch: 1800, loss is 3.55225727558136 and perplexity is 34.89198949787203
At time: 428.2474009990692 and batch: 1850, loss is 3.5959961652755736 and perplexity is 36.45199411816748
At time: 429.4174506664276 and batch: 1900, loss is 3.6733768701553347 and perplexity is 39.38467850155905
At time: 430.5825798511505 and batch: 1950, loss is 3.5961993932724 and perplexity is 36.45940293672661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.429412132085756 and perplexity of 83.8820908233027
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 434.3017108440399 and batch: 50, loss is 3.784269609451294 and perplexity is 44.00351906417109
At time: 435.4561376571655 and batch: 100, loss is 3.792794427871704 and perplexity is 44.38024455077261
At time: 436.61585116386414 and batch: 150, loss is 3.773739957809448 and perplexity is 43.54260821133042
At time: 437.7712335586548 and batch: 200, loss is 3.790096001625061 and perplexity is 44.26064916627614
At time: 438.92696928977966 and batch: 250, loss is 3.7889989757537843 and perplexity is 44.21212071241278
At time: 440.0821316242218 and batch: 300, loss is 3.795318727493286 and perplexity is 44.49241510177418
At time: 441.2375946044922 and batch: 350, loss is 3.817668857574463 and perplexity is 45.4980222315844
At time: 442.3929476737976 and batch: 400, loss is 3.798121242523193 and perplexity is 44.617280650877376
At time: 443.5476849079132 and batch: 450, loss is 3.8219466066360472 and perplexity is 45.693068234987486
At time: 444.7022616863251 and batch: 500, loss is 3.8300048398971556 and perplexity is 46.06276117270175
At time: 445.8585317134857 and batch: 550, loss is 3.7698917818069457 and perplexity is 43.37537057762716
At time: 447.0132098197937 and batch: 600, loss is 3.7405789613723757 and perplexity is 42.12237033206357
At time: 448.16937255859375 and batch: 650, loss is 3.763383331298828 and perplexity is 43.09398082389767
At time: 449.3245768547058 and batch: 700, loss is 3.795175561904907 and perplexity is 44.486045774932826
At time: 450.4795072078705 and batch: 750, loss is 3.7538727807998655 and perplexity is 42.68607611682486
At time: 451.63408303260803 and batch: 800, loss is 3.7084542512893677 and perplexity is 40.79070558988696
At time: 452.78888607025146 and batch: 850, loss is 3.696664628982544 and perplexity is 40.312622325506
At time: 453.94414591789246 and batch: 900, loss is 3.681402425765991 and perplexity is 39.7020342036059
At time: 455.099782705307 and batch: 950, loss is 3.7801200437545774 and perplexity is 43.82130189345286
At time: 456.2559335231781 and batch: 1000, loss is 3.7525959968566895 and perplexity is 42.63160999837356
At time: 457.4114742279053 and batch: 1050, loss is 3.700814242362976 and perplexity is 40.480251680477245
At time: 458.57127952575684 and batch: 1100, loss is 3.7313963556289673 and perplexity is 41.737347673394844
At time: 459.72710514068604 and batch: 1150, loss is 3.698434715270996 and perplexity is 40.38404233667938
At time: 460.88727855682373 and batch: 1200, loss is 3.7262456369400025 and perplexity is 41.522923031266664
At time: 462.04725193977356 and batch: 1250, loss is 3.69763943195343 and perplexity is 40.3519383490881
At time: 463.21011567115784 and batch: 1300, loss is 3.7058807897567747 and perplexity is 40.685867234760536
At time: 464.3722381591797 and batch: 1350, loss is 3.5730608558654784 and perplexity is 35.62547086859294
At time: 465.53624057769775 and batch: 1400, loss is 3.5980333375930784 and perplexity is 36.52632880207515
At time: 466.69885444641113 and batch: 1450, loss is 3.5091151762008668 and perplexity is 33.41868505025336
At time: 467.86164689064026 and batch: 1500, loss is 3.508249135017395 and perplexity is 33.38975562154887
At time: 469.01976442337036 and batch: 1550, loss is 3.5159325551986695 and perplexity is 33.647291254011634
At time: 470.17617082595825 and batch: 1600, loss is 3.5974604892730713 and perplexity is 36.505410747992954
At time: 471.3320882320404 and batch: 1650, loss is 3.539824357032776 and perplexity is 34.46086585052853
At time: 472.48670649528503 and batch: 1700, loss is 3.5567791652679444 and perplexity is 35.05012449036753
At time: 473.6430141925812 and batch: 1750, loss is 3.551043314933777 and perplexity is 34.84965769547556
At time: 474.8010046482086 and batch: 1800, loss is 3.4740950632095338 and perplexity is 32.2686142638445
At time: 475.95625400543213 and batch: 1850, loss is 3.506844882965088 and perplexity is 33.3429008943142
At time: 477.1110463142395 and batch: 1900, loss is 3.5896772289276124 and perplexity is 36.22238250218378
At time: 478.2663173675537 and batch: 1950, loss is 3.523898024559021 and perplexity is 33.91637799990357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.397702239280523 and perplexity of 81.26392891204196
finished 10 epochs...
Completing Train Step...
At time: 481.93042039871216 and batch: 50, loss is 3.7697747802734374 and perplexity is 43.37029588963201
At time: 483.0869572162628 and batch: 100, loss is 3.7589048957824707 and perplexity is 42.90141871995892
At time: 484.24414014816284 and batch: 150, loss is 3.7258072233200075 and perplexity is 41.50472280617255
At time: 485.40029406547546 and batch: 200, loss is 3.7358265209197996 and perplexity is 41.92266120408891
At time: 486.55498242378235 and batch: 250, loss is 3.732747001647949 and perplexity is 41.793758142585055
At time: 487.71100187301636 and batch: 300, loss is 3.7353061866760253 and perplexity is 41.900853082122644
At time: 488.8690764904022 and batch: 350, loss is 3.760701813697815 and perplexity is 42.978578351851134
At time: 490.0250196456909 and batch: 400, loss is 3.7419817781448366 and perplexity is 42.18150176524728
At time: 491.20465064048767 and batch: 450, loss is 3.7677570676803587 and perplexity is 43.28287532189878
At time: 492.36076498031616 and batch: 500, loss is 3.7784583520889283 and perplexity is 43.74854486793159
At time: 493.5193474292755 and batch: 550, loss is 3.719034185409546 and perplexity is 41.224559594188534
At time: 494.67375206947327 and batch: 600, loss is 3.69355872631073 and perplexity is 40.18760948347348
At time: 495.83073592185974 and batch: 650, loss is 3.719207515716553 and perplexity is 41.23170567905787
At time: 496.9926381111145 and batch: 700, loss is 3.7539214277267456 and perplexity is 42.68815271375813
At time: 498.14815640449524 and batch: 750, loss is 3.7159545183181764 and perplexity is 41.09779696818237
At time: 499.30360102653503 and batch: 800, loss is 3.6714346170425416 and perplexity is 39.30825772541203
At time: 500.4614861011505 and batch: 850, loss is 3.6601189374923706 and perplexity is 38.86596521688338
At time: 501.6192293167114 and batch: 900, loss is 3.6449566793441774 and perplexity is 38.281114452653064
At time: 502.777911901474 and batch: 950, loss is 3.743384447097778 and perplexity is 42.240709963204786
At time: 503.94029712677 and batch: 1000, loss is 3.7163659143447876 and perplexity is 41.114707916867594
At time: 505.1041386127472 and batch: 1050, loss is 3.6681305074691775 and perplexity is 39.17859326550462
At time: 506.26285338401794 and batch: 1100, loss is 3.6996876621246337 and perplexity is 40.43467310767123
At time: 507.4193377494812 and batch: 1150, loss is 3.6688163471221924 and perplexity is 39.205472714757896
At time: 508.5752258300781 and batch: 1200, loss is 3.698434271812439 and perplexity is 40.38402442803421
At time: 509.7326624393463 and batch: 1250, loss is 3.672581281661987 and perplexity is 39.35335696570789
At time: 510.8893585205078 and batch: 1300, loss is 3.684115033149719 and perplexity is 39.80987643542537
At time: 512.0462601184845 and batch: 1350, loss is 3.5528965854644774 and perplexity is 34.91430342359627
At time: 513.2021331787109 and batch: 1400, loss is 3.580974817276001 and perplexity is 35.90852804472356
At time: 514.3642058372498 and batch: 1450, loss is 3.4943987941741943 and perplexity is 32.93048400164726
At time: 515.5198004245758 and batch: 1500, loss is 3.495535373687744 and perplexity is 32.967933393208966
At time: 516.6751682758331 and batch: 1550, loss is 3.5056106758117678 and perplexity is 33.301774232148894
At time: 517.8321659564972 and batch: 1600, loss is 3.5895778560638427 and perplexity is 36.21878315914345
At time: 518.9908831119537 and batch: 1650, loss is 3.5339848470687865 and perplexity is 34.26021769465219
At time: 520.1487727165222 and batch: 1700, loss is 3.5533537817001344 and perplexity is 34.93026976128875
At time: 521.3078303337097 and batch: 1750, loss is 3.5489336156845095 and perplexity is 34.77621289925478
At time: 522.4652049541473 and batch: 1800, loss is 3.4750197172164916 and perplexity is 32.298465366166376
At time: 523.6213185787201 and batch: 1850, loss is 3.5091309213638304 and perplexity is 33.41921123703795
At time: 524.7778589725494 and batch: 1900, loss is 3.5930146551132203 and perplexity is 36.343473984596564
At time: 525.9330554008484 and batch: 1950, loss is 3.5278324270248413 and perplexity is 34.05008153041595
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399060626362646 and perplexity of 81.37439179200754
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 529.6223258972168 and batch: 50, loss is 3.7581660604476927 and perplexity is 42.86973334247612
At time: 530.7756328582764 and batch: 100, loss is 3.7614690923690794 and perplexity is 43.01156755267842
At time: 531.9301588535309 and batch: 150, loss is 3.735741848945618 and perplexity is 41.919111679876536
At time: 533.086079120636 and batch: 200, loss is 3.7527077102661135 and perplexity is 42.63637278690444
At time: 534.2393853664398 and batch: 250, loss is 3.7527371788024904 and perplexity is 42.637629236919665
At time: 535.3968570232391 and batch: 300, loss is 3.7558047103881838 and perplexity is 42.76862232133731
At time: 536.5530540943146 and batch: 350, loss is 3.792664661407471 and perplexity is 44.3744858570062
At time: 537.7066099643707 and batch: 400, loss is 3.785966057777405 and perplexity is 44.078232115927996
At time: 538.8624277114868 and batch: 450, loss is 3.8221004724502565 and perplexity is 45.70009937704751
At time: 540.0191493034363 and batch: 500, loss is 3.843438048362732 and perplexity is 46.6857065560638
At time: 541.1720020771027 and batch: 550, loss is 3.7915593576431275 and perplexity is 44.32546566683865
At time: 542.323371887207 and batch: 600, loss is 3.760425019264221 and perplexity is 42.96668376685296
At time: 543.4761295318604 and batch: 650, loss is 3.7637421703338623 and perplexity is 43.10944740123218
At time: 544.6291272640228 and batch: 700, loss is 3.7855066013336183 and perplexity is 44.05798473990149
At time: 545.7873060703278 and batch: 750, loss is 3.740060639381409 and perplexity is 42.100543038480616
At time: 546.9401142597198 and batch: 800, loss is 3.691291832923889 and perplexity is 40.096611637478446
At time: 548.0974435806274 and batch: 850, loss is 3.6794618368148804 and perplexity is 39.6250635830169
At time: 549.2871367931366 and batch: 900, loss is 3.65237952709198 and perplexity is 38.566326570347925
At time: 550.4383623600006 and batch: 950, loss is 3.755962495803833 and perplexity is 42.775371118603914
At time: 551.5911111831665 and batch: 1000, loss is 3.725895481109619 and perplexity is 41.50838608291985
At time: 552.7441425323486 and batch: 1050, loss is 3.6794089460372925 and perplexity is 39.622967838015306
At time: 553.9010682106018 and batch: 1100, loss is 3.7077311182022097 and perplexity is 40.76121914362378
At time: 555.0600323677063 and batch: 1150, loss is 3.6824106884002688 and perplexity is 39.74208446839804
At time: 556.2154011726379 and batch: 1200, loss is 3.7164843845367432 and perplexity is 41.11957907274439
At time: 557.3723876476288 and batch: 1250, loss is 3.6881261968612673 and perplexity is 39.969881054974245
At time: 558.5280194282532 and batch: 1300, loss is 3.694938292503357 and perplexity is 40.24308921105855
At time: 559.6848380565643 and batch: 1350, loss is 3.5615654230117797 and perplexity is 35.218285530148385
At time: 560.8408195972443 and batch: 1400, loss is 3.5867097759246827 and perplexity is 36.115053609935714
At time: 561.9968776702881 and batch: 1450, loss is 3.4919680070877077 and perplexity is 32.85053421620409
At time: 563.1537306308746 and batch: 1500, loss is 3.4857576274871827 and perplexity is 32.64715212232832
At time: 564.3096315860748 and batch: 1550, loss is 3.492029724121094 and perplexity is 32.85256171628606
At time: 565.4656522274017 and batch: 1600, loss is 3.5714500999450682 and perplexity is 35.56813312142887
At time: 566.6222167015076 and batch: 1650, loss is 3.5142253637313843 and perplexity is 33.58989789015548
At time: 567.7817282676697 and batch: 1700, loss is 3.532268919944763 and perplexity is 34.201480066991536
At time: 568.938108921051 and batch: 1750, loss is 3.5309842729568484 and perplexity is 34.15757144821727
At time: 570.09796833992 and batch: 1800, loss is 3.4584620666503905 and perplexity is 31.768081733496654
At time: 571.2645862102509 and batch: 1850, loss is 3.491869387626648 and perplexity is 32.847294673967745
At time: 572.4183034896851 and batch: 1900, loss is 3.5776809215545655 and perplexity is 35.790443683385746
At time: 573.5792021751404 and batch: 1950, loss is 3.523630304336548 and perplexity is 33.907299114994714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381819188317587 and perplexity of 79.98340601273708
finished 12 epochs...
Completing Train Step...
At time: 577.2188320159912 and batch: 50, loss is 3.7676825666427614 and perplexity is 43.27965082289285
At time: 578.4003660678864 and batch: 100, loss is 3.7582530689239504 and perplexity is 42.87346353492864
At time: 579.5565741062164 and batch: 150, loss is 3.7187130355834963 and perplexity is 41.21132245971137
At time: 580.7169597148895 and batch: 200, loss is 3.7275606298446657 and perplexity is 41.57756129702615
At time: 581.8733267784119 and batch: 250, loss is 3.7256625366210936 and perplexity is 41.49871805925437
At time: 583.0341353416443 and batch: 300, loss is 3.7228859663009644 and perplexity is 41.38365376634044
At time: 584.1949167251587 and batch: 350, loss is 3.754490714073181 and perplexity is 42.712461414901945
At time: 585.3516752719879 and batch: 400, loss is 3.7461593532562256 and perplexity is 42.358086748883814
At time: 586.5082297325134 and batch: 450, loss is 3.7813467454910277 and perplexity is 43.87509054515021
At time: 587.664125919342 and batch: 500, loss is 3.8036536598205566 and perplexity is 44.8648061419184
At time: 588.8188123703003 and batch: 550, loss is 3.7533365440368653 and perplexity is 42.66319240963367
At time: 589.9758849143982 and batch: 600, loss is 3.726849927902222 and perplexity is 41.548022541319135
At time: 591.1353945732117 and batch: 650, loss is 3.7358705043792724 and perplexity is 41.924505148310196
At time: 592.2911536693573 and batch: 700, loss is 3.762631950378418 and perplexity is 43.06161299073105
At time: 593.4475798606873 and batch: 750, loss is 3.7221937704086305 and perplexity is 41.35501808308813
At time: 594.6034336090088 and batch: 800, loss is 3.6750422668457032 and perplexity is 39.450324262730845
At time: 595.7591648101807 and batch: 850, loss is 3.6626491212844847 and perplexity is 38.964427763781785
At time: 596.9142093658447 and batch: 900, loss is 3.638652286529541 and perplexity is 38.04053442209745
At time: 598.0696437358856 and batch: 950, loss is 3.743744077682495 and perplexity is 42.255903746338504
At time: 599.2243888378143 and batch: 1000, loss is 3.7113543701171876 and perplexity is 40.90917518809015
At time: 600.3853180408478 and batch: 1050, loss is 3.665309314727783 and perplexity is 39.0682186697772
At time: 601.5452694892883 and batch: 1100, loss is 3.6920116329193116 and perplexity is 40.125483568112756
At time: 602.7020907402039 and batch: 1150, loss is 3.6670328617095946 and perplexity is 39.13561264180534
At time: 603.864166021347 and batch: 1200, loss is 3.7010627794265747 and perplexity is 40.490313773713396
At time: 605.0262999534607 and batch: 1250, loss is 3.67466055393219 and perplexity is 39.43526843820161
At time: 606.1826758384705 and batch: 1300, loss is 3.6826514387130738 and perplexity is 39.75165353949754
At time: 607.336163520813 and batch: 1350, loss is 3.5506194829940796 and perplexity is 34.83489042709776
At time: 608.4893639087677 and batch: 1400, loss is 3.578562479019165 and perplexity is 35.822008927420185
At time: 609.6440467834473 and batch: 1450, loss is 3.4857896614074706 and perplexity is 32.64819795534802
At time: 610.7987537384033 and batch: 1500, loss is 3.4831373167037962 and perplexity is 32.561718417886354
At time: 611.9561984539032 and batch: 1550, loss is 3.491147031784058 and perplexity is 32.82357580650934
At time: 613.113347530365 and batch: 1600, loss is 3.5733387804031373 and perplexity is 35.63537343713263
At time: 614.2759211063385 and batch: 1650, loss is 3.517977032661438 and perplexity is 33.71615275156746
At time: 615.4376795291901 and batch: 1700, loss is 3.537852349281311 and perplexity is 34.392975717884006
At time: 616.5946629047394 and batch: 1750, loss is 3.537410078048706 and perplexity is 34.37776805732359
At time: 617.7516822814941 and batch: 1800, loss is 3.4657234001159667 and perplexity is 31.99959991662075
At time: 618.9127326011658 and batch: 1850, loss is 3.499876608848572 and perplexity is 33.11136605703231
At time: 620.0695080757141 and batch: 1900, loss is 3.58546266078949 and perplexity is 36.07004205310122
At time: 621.227198600769 and batch: 1950, loss is 3.5308995962142946 and perplexity is 34.1546792187875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380614382721657 and perplexity of 79.88709958450266
finished 13 epochs...
Completing Train Step...
At time: 624.8801476955414 and batch: 50, loss is 3.7625417280197144 and perplexity is 43.05772804569453
At time: 626.0737082958221 and batch: 100, loss is 3.7504392528533934 and perplexity is 42.5397636093354
At time: 627.2281000614166 and batch: 150, loss is 3.7092115449905396 and perplexity is 40.821607833857044
At time: 628.3823473453522 and batch: 200, loss is 3.71636616230011 and perplexity is 41.11471811147952
At time: 629.5351014137268 and batch: 250, loss is 3.7137656307220457 and perplexity is 41.00793689285091
At time: 630.6899349689484 and batch: 300, loss is 3.709991593360901 and perplexity is 40.853463085226565
At time: 631.8499712944031 and batch: 350, loss is 3.741047992706299 and perplexity is 42.14213167759127
At time: 633.0050296783447 and batch: 400, loss is 3.7324965715408327 and perplexity is 41.78329303769997
At time: 634.160439491272 and batch: 450, loss is 3.7672407102584837 and perplexity is 43.260531657141236
At time: 635.3384530544281 and batch: 500, loss is 3.7897267723083496 and perplexity is 44.24430985368951
At time: 636.4916334152222 and batch: 550, loss is 3.7393252849578857 and perplexity is 42.069595597987735
At time: 637.6449916362762 and batch: 600, loss is 3.7140301275253296 and perplexity is 41.01878479562289
At time: 638.8001763820648 and batch: 650, loss is 3.7236798906326296 and perplexity is 41.41652230183732
At time: 639.9579429626465 and batch: 700, loss is 3.75198938369751 and perplexity is 42.605756944945526
At time: 641.1164016723633 and batch: 750, loss is 3.7125764322280883 and perplexity is 40.95919930113666
At time: 642.2770581245422 and batch: 800, loss is 3.6662075614929197 and perplexity is 39.10332733657956
At time: 643.4320771694183 and batch: 850, loss is 3.6538908004760744 and perplexity is 38.62465489713832
At time: 644.5884413719177 and batch: 900, loss is 3.630648679733276 and perplexity is 37.73728809322325
At time: 645.7448163032532 and batch: 950, loss is 3.7360674142837524 and perplexity is 41.9327613114478
At time: 646.8984968662262 and batch: 1000, loss is 3.7036217641830445 and perplexity is 40.59406055604764
At time: 648.0529344081879 and batch: 1050, loss is 3.6580677938461306 and perplexity is 38.786327241658235
At time: 649.207197189331 and batch: 1100, loss is 3.684486722946167 and perplexity is 39.82467611056801
At time: 650.3609802722931 and batch: 1150, loss is 3.659913892745972 and perplexity is 38.85799677187375
At time: 651.5135281085968 and batch: 1200, loss is 3.6940899085998535 and perplexity is 40.208962100437226
At time: 652.6682612895966 and batch: 1250, loss is 3.6683639430999757 and perplexity is 39.187740012684145
At time: 653.8221182823181 and batch: 1300, loss is 3.6770488691329954 and perplexity is 39.5295648492137
At time: 654.9751219749451 and batch: 1350, loss is 3.5455092906951906 and perplexity is 34.65733150482178
At time: 656.1289019584656 and batch: 1400, loss is 3.574573111534119 and perplexity is 35.67938644565544
At time: 657.2831275463104 and batch: 1450, loss is 3.4824936199188232 and perplexity is 32.540765288881936
At time: 658.4369893074036 and batch: 1500, loss is 3.4810334920883177 and perplexity is 32.49328628300195
At time: 659.5911953449249 and batch: 1550, loss is 3.4897615194320677 and perplexity is 32.778129827045895
At time: 660.7508325576782 and batch: 1600, loss is 3.5729195737838744 and perplexity is 35.62043798344712
At time: 661.9048688411713 and batch: 1650, loss is 3.5180893182754516 and perplexity is 33.719938803036925
At time: 663.0598473548889 and batch: 1700, loss is 3.538712797164917 and perplexity is 34.42258181647719
At time: 664.2150337696075 and batch: 1750, loss is 3.5386289310455323 and perplexity is 34.41969504917372
At time: 665.3731462955475 and batch: 1800, loss is 3.467385754585266 and perplexity is 32.05283883327332
At time: 666.5271706581116 and batch: 1850, loss is 3.5018316745758056 and perplexity is 33.17616427574084
At time: 667.681079864502 and batch: 1900, loss is 3.5872052526474 and perplexity is 36.13295221214333
At time: 668.8344242572784 and batch: 1950, loss is 3.532333459854126 and perplexity is 34.20368749864808
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3807804551235465 and perplexity of 79.90036772871647
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 672.4521019458771 and batch: 50, loss is 3.760433707237244 and perplexity is 42.96705706186399
At time: 673.6342866420746 and batch: 100, loss is 3.7536541843414306 and perplexity is 42.67674611155144
At time: 674.7888767719269 and batch: 150, loss is 3.714637722969055 and perplexity is 41.04371519540356
At time: 675.9423589706421 and batch: 200, loss is 3.7223948192596437 and perplexity is 41.36333329781154
At time: 677.0965864658356 and batch: 250, loss is 3.7205881023406984 and perplexity is 41.28866893271436
At time: 678.2495248317719 and batch: 300, loss is 3.7151720905303955 and perplexity is 41.065653486434385
At time: 679.4071271419525 and batch: 350, loss is 3.7487814140319826 and perplexity is 42.46929796425036
At time: 680.5612225532532 and batch: 400, loss is 3.7419824171066285 and perplexity is 42.18152871762385
At time: 681.7148425579071 and batch: 450, loss is 3.780152106285095 and perplexity is 43.822706937806664
At time: 682.8694088459015 and batch: 500, loss is 3.8067745208740233 and perplexity is 45.005041682073994
At time: 684.023444890976 and batch: 550, loss is 3.762386693954468 and perplexity is 43.051053148506924
At time: 685.1761176586151 and batch: 600, loss is 3.738169617652893 and perplexity is 42.0210052243819
At time: 686.3358917236328 and batch: 650, loss is 3.742163314819336 and perplexity is 42.189159949902795
At time: 687.4917528629303 and batch: 700, loss is 3.769415230751038 and perplexity is 43.35470492348874
At time: 688.6461279392242 and batch: 750, loss is 3.7262731838226317 and perplexity is 41.52406687410841
At time: 689.7998914718628 and batch: 800, loss is 3.6760830688476562 and perplexity is 39.49140561426914
At time: 690.9525148868561 and batch: 850, loss is 3.665417070388794 and perplexity is 39.072428718328695
At time: 692.1060245037079 and batch: 900, loss is 3.6389395904541018 and perplexity is 38.051465187079955
At time: 693.299968957901 and batch: 950, loss is 3.7459655094146727 and perplexity is 42.34987669038792
At time: 694.4531035423279 and batch: 1000, loss is 3.7137313175201414 and perplexity is 41.00652980337364
At time: 695.6120593547821 and batch: 1050, loss is 3.6685534048080446 and perplexity is 39.19516529222317
At time: 696.769121170044 and batch: 1100, loss is 3.687944097518921 and perplexity is 39.96260322858428
At time: 697.9226517677307 and batch: 1150, loss is 3.661467981338501 and perplexity is 38.918432490452226
At time: 699.0825090408325 and batch: 1200, loss is 3.697939729690552 and perplexity is 40.364057764488244
At time: 700.2364456653595 and batch: 1250, loss is 3.670802059173584 and perplexity is 39.283400840210795
At time: 701.3907098770142 and batch: 1300, loss is 3.678641314506531 and perplexity is 39.592563669652634
At time: 702.5463266372681 and batch: 1350, loss is 3.5456391620635985 and perplexity is 34.66183279217752
At time: 703.7031979560852 and batch: 1400, loss is 3.5754130506515502 and perplexity is 35.70936754740453
At time: 704.8594195842743 and batch: 1450, loss is 3.4805175924301146 and perplexity is 32.476527331055145
At time: 706.0165133476257 and batch: 1500, loss is 3.4748857593536377 and perplexity is 32.294139022552805
At time: 707.1704456806183 and batch: 1550, loss is 3.485709090232849 and perplexity is 32.64556755765802
At time: 708.3245432376862 and batch: 1600, loss is 3.565500545501709 and perplexity is 35.35714683652859
At time: 709.4801969528198 and batch: 1650, loss is 3.505752110481262 and perplexity is 33.30648459067714
At time: 710.6374833583832 and batch: 1700, loss is 3.523439745903015 and perplexity is 33.900838408780615
At time: 711.7911803722382 and batch: 1750, loss is 3.5244672679901123 and perplexity is 33.93569017142832
At time: 712.9459710121155 and batch: 1800, loss is 3.4547565746307374 and perplexity is 31.650583189556396
At time: 714.1001482009888 and batch: 1850, loss is 3.491425356864929 and perplexity is 32.832712702354826
At time: 715.2532260417938 and batch: 1900, loss is 3.5755581951141355 and perplexity is 35.714550940527765
At time: 716.406952381134 and batch: 1950, loss is 3.5252321767807007 and perplexity is 33.96165780932627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377805913880814 and perplexity of 79.66305391443923
finished 15 epochs...
Completing Train Step...
At time: 720.0557117462158 and batch: 50, loss is 3.762914009094238 and perplexity is 43.073760607082356
At time: 721.2161059379578 and batch: 100, loss is 3.752173647880554 and perplexity is 42.61360838328919
At time: 722.3951182365417 and batch: 150, loss is 3.7108740282058714 and perplexity is 40.88952951538766
At time: 723.5503253936768 and batch: 200, loss is 3.716510548591614 and perplexity is 41.120654941741996
At time: 724.7041721343994 and batch: 250, loss is 3.7146639156341554 and perplexity is 41.04479025376941
At time: 725.8595356941223 and batch: 300, loss is 3.7077291584014893 and perplexity is 40.76113925983541
At time: 727.0159800052643 and batch: 350, loss is 3.73921293258667 and perplexity is 42.06486924467968
At time: 728.1718792915344 and batch: 400, loss is 3.7321181774139403 and perplexity is 41.76748547594516
At time: 729.3324184417725 and batch: 450, loss is 3.769017195701599 and perplexity is 43.33745166529965
At time: 730.4863407611847 and batch: 500, loss is 3.7957153129577637 and perplexity is 44.51006364622984
At time: 731.6413872241974 and batch: 550, loss is 3.7510507774353026 and perplexity is 42.56578567624697
At time: 732.7971036434174 and batch: 600, loss is 3.726859827041626 and perplexity is 41.54843383302195
At time: 733.9598233699799 and batch: 650, loss is 3.7325701761245726 and perplexity is 41.786368592777386
At time: 735.1153342723846 and batch: 700, loss is 3.760468692779541 and perplexity is 42.96856031395211
At time: 736.270920753479 and batch: 750, loss is 3.718608865737915 and perplexity is 41.20702970620615
At time: 737.426442861557 and batch: 800, loss is 3.668405337333679 and perplexity is 39.18936219272676
At time: 738.5824658870697 and batch: 850, loss is 3.6577095651626585 and perplexity is 38.772435355098416
At time: 739.7391102313995 and batch: 900, loss is 3.6322876834869384 and perplexity is 37.79919036523165
At time: 740.8951840400696 and batch: 950, loss is 3.73969717502594 and perplexity is 42.085243772277636
At time: 742.0500657558441 and batch: 1000, loss is 3.707181439399719 and perplexity is 40.73881972230439
At time: 743.206125497818 and batch: 1050, loss is 3.6621628427505493 and perplexity is 38.94548480512355
At time: 744.3603365421295 and batch: 1100, loss is 3.6824287700653078 and perplexity is 39.74280307795416
At time: 745.5162935256958 and batch: 1150, loss is 3.6563525772094727 and perplexity is 38.71985730936137
At time: 746.6748535633087 and batch: 1200, loss is 3.6929630041122437 and perplexity is 40.1636759619729
At time: 747.8331506252289 and batch: 1250, loss is 3.666859574317932 and perplexity is 39.12883152112784
At time: 748.9890322685242 and batch: 1300, loss is 3.6745853519439695 and perplexity is 39.432302939116155
At time: 750.1443707942963 and batch: 1350, loss is 3.542101411819458 and perplexity is 34.53942453733983
At time: 751.2999646663666 and batch: 1400, loss is 3.5725129795074464 and perplexity is 35.60595786120609
At time: 752.4549884796143 and batch: 1450, loss is 3.478905611038208 and perplexity is 32.42421794552888
At time: 753.6093947887421 and batch: 1500, loss is 3.475216979980469 and perplexity is 32.30483727916665
At time: 754.7721374034882 and batch: 1550, loss is 3.4862050008773804 and perplexity is 32.66176085698951
At time: 755.928905248642 and batch: 1600, loss is 3.5669696712493897 and perplexity is 35.4091291062065
At time: 757.084231376648 and batch: 1650, loss is 3.50852822303772 and perplexity is 33.39907560283148
At time: 758.2476696968079 and batch: 1700, loss is 3.5272606897354124 and perplexity is 34.03061939324185
At time: 759.4144496917725 and batch: 1750, loss is 3.5289632749557494 and perplexity is 34.08860877478339
At time: 760.5820360183716 and batch: 1800, loss is 3.4597745513916016 and perplexity is 31.80980423011018
At time: 761.7541127204895 and batch: 1850, loss is 3.4975851249694823 and perplexity is 33.03557876134375
At time: 762.9236302375793 and batch: 1900, loss is 3.5811248064041137 and perplexity is 35.91391433746938
At time: 764.0909841060638 and batch: 1950, loss is 3.5303529691696167 and perplexity is 34.13601444922288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376966183684593 and perplexity of 79.59618652175777
finished 16 epochs...
Completing Train Step...
At time: 767.778370141983 and batch: 50, loss is 3.76314492225647 and perplexity is 43.08370805380734
At time: 768.942809343338 and batch: 100, loss is 3.7506274223327636 and perplexity is 42.54776904767226
At time: 770.1077451705933 and batch: 150, loss is 3.7083892250061035 and perplexity is 40.78805320814892
At time: 771.2709131240845 and batch: 200, loss is 3.713067021369934 and perplexity is 40.979298369361686
At time: 772.4449689388275 and batch: 250, loss is 3.7108858394622803 and perplexity is 40.89001247495738
At time: 773.612663269043 and batch: 300, loss is 3.7033172941207884 and perplexity is 40.581702761287644
At time: 774.7766919136047 and batch: 350, loss is 3.733948516845703 and perplexity is 41.84400415779531
At time: 775.9403808116913 and batch: 400, loss is 3.7267181634902955 and perplexity is 41.54254835122192
At time: 777.1098837852478 and batch: 450, loss is 3.763025231361389 and perplexity is 43.07855163482133
At time: 778.2775318622589 and batch: 500, loss is 3.7895983505249022 and perplexity is 44.23862828533708
At time: 779.466162443161 and batch: 550, loss is 3.7447941875457764 and perplexity is 42.30030039424354
At time: 780.6301057338715 and batch: 600, loss is 3.7208927631378175 and perplexity is 41.30124988786798
At time: 781.794979095459 and batch: 650, loss is 3.727067060470581 and perplexity is 41.55704494965767
At time: 782.9593114852905 and batch: 700, loss is 3.755518765449524 and perplexity is 42.75639459856212
At time: 784.1242921352386 and batch: 750, loss is 3.714290590286255 and perplexity is 41.02947005305599
At time: 785.3029005527496 and batch: 800, loss is 3.664214129447937 and perplexity is 39.025455153041605
At time: 786.4688324928284 and batch: 850, loss is 3.6535211849212645 and perplexity is 38.61038126193048
At time: 787.6330740451813 and batch: 900, loss is 3.628756070137024 and perplexity is 37.665933683960446
At time: 788.8007485866547 and batch: 950, loss is 3.736352815628052 and perplexity is 41.9447306858528
At time: 789.9680242538452 and batch: 1000, loss is 3.703777050971985 and perplexity is 40.600364766829095
At time: 791.1323750019073 and batch: 1050, loss is 3.6590133619308474 and perplexity is 38.82301969969607
At time: 792.3021368980408 and batch: 1100, loss is 3.6794692373275755 and perplexity is 39.62535682988808
At time: 793.4663166999817 and batch: 1150, loss is 3.653636264801025 and perplexity is 38.61482479563937
At time: 794.6336262226105 and batch: 1200, loss is 3.690267071723938 and perplexity is 40.0555432318711
At time: 795.8006508350372 and batch: 1250, loss is 3.6647386074066164 and perplexity is 39.045928512540385
At time: 796.9646008014679 and batch: 1300, loss is 3.6725684785842896 and perplexity is 39.352853124846355
At time: 798.1283910274506 and batch: 1350, loss is 3.5403872394561766 and perplexity is 34.48026872646757
At time: 799.2938361167908 and batch: 1400, loss is 3.5712119722366333 and perplexity is 35.55966437175736
At time: 800.4588842391968 and batch: 1450, loss is 3.478253321647644 and perplexity is 32.403074868617715
At time: 801.6308090686798 and batch: 1500, loss is 3.4754692459106447 and perplexity is 32.31298771698772
At time: 802.7960813045502 and batch: 1550, loss is 3.486652855873108 and perplexity is 32.67639186579921
At time: 803.9672169685364 and batch: 1600, loss is 3.567954173088074 and perplexity is 35.44400662459119
At time: 805.1311120986938 and batch: 1650, loss is 3.510045094490051 and perplexity is 33.44977615053298
At time: 806.295661687851 and batch: 1700, loss is 3.5292153930664063 and perplexity is 34.09720421391002
At time: 807.4616661071777 and batch: 1750, loss is 3.5311280727386474 and perplexity is 34.16248365271681
At time: 808.6257450580597 and batch: 1800, loss is 3.4621735858917235 and perplexity is 31.886208659686975
At time: 809.7908718585968 and batch: 1850, loss is 3.5004144716262817 and perplexity is 33.12918021871129
At time: 810.9576508998871 and batch: 1900, loss is 3.583634786605835 and perplexity is 36.00417077497372
At time: 812.121012210846 and batch: 1950, loss is 3.5325705671310423 and perplexity is 34.21179840339065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376641703760901 and perplexity of 79.57036334700649
finished 17 epochs...
Completing Train Step...
At time: 815.8029851913452 and batch: 50, loss is 3.762217683792114 and perplexity is 43.04377769785466
At time: 816.9600269794464 and batch: 100, loss is 3.748727922439575 and perplexity is 42.46702627463251
At time: 818.1178436279297 and batch: 150, loss is 3.706025757789612 and perplexity is 40.6917658124401
At time: 819.2735414505005 and batch: 200, loss is 3.7101951742172243 and perplexity is 40.86178091487195
At time: 820.4368858337402 and batch: 250, loss is 3.707763228416443 and perplexity is 40.76252801611687
At time: 821.5937080383301 and batch: 300, loss is 3.699874324798584 and perplexity is 40.442221456349365
At time: 822.7497146129608 and batch: 350, loss is 3.730105366706848 and perplexity is 41.683499985772734
At time: 823.9061405658722 and batch: 400, loss is 3.7228205156326295 and perplexity is 41.3809452671808
At time: 825.0626192092896 and batch: 450, loss is 3.7588272380828855 and perplexity is 42.89808722383203
At time: 826.2189662456512 and batch: 500, loss is 3.785328826904297 and perplexity is 44.05015305296477
At time: 827.3735349178314 and batch: 550, loss is 3.7404209566116333 and perplexity is 42.11571532279277
At time: 828.5285062789917 and batch: 600, loss is 3.716830496788025 and perplexity is 41.133813526046254
At time: 829.6843159198761 and batch: 650, loss is 3.7231972789764405 and perplexity is 41.396539027883975
At time: 830.8407790660858 and batch: 700, loss is 3.75206627368927 and perplexity is 42.60903302719331
At time: 831.9952392578125 and batch: 750, loss is 3.7111976623535154 and perplexity is 40.90276490501643
At time: 833.1576991081238 and batch: 800, loss is 3.6612617492675783 and perplexity is 38.91040708909866
At time: 834.3191492557526 and batch: 850, loss is 3.6506155824661253 and perplexity is 38.498357670167074
At time: 835.4745817184448 and batch: 900, loss is 3.6262681436538697 and perplexity is 37.572340085308724
At time: 836.6334271430969 and batch: 950, loss is 3.7339882898330687 and perplexity is 41.84566845194077
At time: 837.8113493919373 and batch: 1000, loss is 3.7014041328430176 and perplexity is 40.504137639930654
At time: 838.9646782875061 and batch: 1050, loss is 3.6568525075912475 and perplexity is 38.73921938184919
At time: 840.1249639987946 and batch: 1100, loss is 3.6773587369918825 and perplexity is 39.54181568880895
At time: 841.2832064628601 and batch: 1150, loss is 3.6517014360427855 and perplexity is 38.54018395403904
At time: 842.4393932819366 and batch: 1200, loss is 3.688327794075012 and perplexity is 39.97793968389992
At time: 843.6029629707336 and batch: 1250, loss is 3.6631484603881836 and perplexity is 38.9838890847124
At time: 844.7595529556274 and batch: 1300, loss is 3.6711067295074464 and perplexity is 39.29537115046666
At time: 845.9153578281403 and batch: 1350, loss is 3.5391189670562744 and perplexity is 34.43656607259347
At time: 847.0709505081177 and batch: 1400, loss is 3.5702352285385133 and perplexity is 35.52494865061588
At time: 848.2263331413269 and batch: 1450, loss is 3.4776423263549803 and perplexity is 32.38328278945448
At time: 849.3833892345428 and batch: 1500, loss is 3.4753927516937257 and perplexity is 32.31051605483114
At time: 850.5408382415771 and batch: 1550, loss is 3.486752061843872 and perplexity is 32.6796337197783
At time: 851.6979508399963 and batch: 1600, loss is 3.568382253646851 and perplexity is 35.45918276282544
At time: 852.8540859222412 and batch: 1650, loss is 3.5107554960250855 and perplexity is 33.47354736541092
At time: 854.012393951416 and batch: 1700, loss is 3.530179510116577 and perplexity is 34.13009376199521
At time: 855.1678814888 and batch: 1750, loss is 3.532194538116455 and perplexity is 34.19893619298348
At time: 856.3300023078918 and batch: 1800, loss is 3.463391032218933 and perplexity is 31.92505204738046
At time: 857.4861073493958 and batch: 1850, loss is 3.5018258142471312 and perplexity is 33.17596985308372
At time: 858.6433892250061 and batch: 1900, loss is 3.5848569965362547 and perplexity is 36.048202332453634
At time: 859.8037791252136 and batch: 1950, loss is 3.5335871171951294 and perplexity is 34.246594092033504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376537518168605 and perplexity of 79.56207369341067
finished 18 epochs...
Completing Train Step...
At time: 863.4285545349121 and batch: 50, loss is 3.7608573722839354 and perplexity is 42.98526455876797
At time: 864.6051771640778 and batch: 100, loss is 3.74674955368042 and perplexity is 42.383093888537374
At time: 865.7592585086823 and batch: 150, loss is 3.703787798881531 and perplexity is 40.600801138222174
At time: 866.937980890274 and batch: 200, loss is 3.707640595436096 and perplexity is 40.75752949231797
At time: 868.0921156406403 and batch: 250, loss is 3.705032367706299 and perplexity is 40.651363086965475
At time: 869.2443268299103 and batch: 300, loss is 3.6969392776489256 and perplexity is 40.3236956540339
At time: 870.3979575634003 and batch: 350, loss is 3.726939992904663 and perplexity is 41.55176473258845
At time: 871.551157951355 and batch: 400, loss is 3.7196579647064207 and perplexity is 41.250282642904715
At time: 872.7030575275421 and batch: 450, loss is 3.7555064821243285 and perplexity is 42.755869411088604
At time: 873.8568880558014 and batch: 500, loss is 3.7819728231430054 and perplexity is 43.90256835954424
At time: 875.0106334686279 and batch: 550, loss is 3.736990351676941 and perplexity is 41.97148048980209
At time: 876.1631436347961 and batch: 600, loss is 3.713667268753052 and perplexity is 41.00390346980472
At time: 877.3164939880371 and batch: 650, loss is 3.720139493942261 and perplexity is 41.27015064311153
At time: 878.4767253398895 and batch: 700, loss is 3.7493367099761965 and perplexity is 42.49288754215583
At time: 879.6368668079376 and batch: 750, loss is 3.7086990165710447 and perplexity is 40.80069096041664
At time: 880.7891376018524 and batch: 800, loss is 3.658883447647095 and perplexity is 38.817976362506535
At time: 881.9423577785492 and batch: 850, loss is 3.64829035282135 and perplexity is 38.408944141417045
At time: 883.096727848053 and batch: 900, loss is 3.624236283302307 and perplexity is 37.49607584255731
At time: 884.251378774643 and batch: 950, loss is 3.7320347166061403 and perplexity is 41.76399967333354
At time: 885.4055240154266 and batch: 1000, loss is 3.699463725090027 and perplexity is 40.425619300659385
At time: 886.5601859092712 and batch: 1050, loss is 3.655083889961243 and perplexity is 38.670765068074736
At time: 887.7154772281647 and batch: 1100, loss is 3.6756064653396607 and perplexity is 39.472588356359466
At time: 888.8701314926147 and batch: 1150, loss is 3.6500861120223997 and perplexity is 38.477979322991075
At time: 890.0248413085938 and batch: 1200, loss is 3.686704020500183 and perplexity is 39.913077237080245
At time: 891.17809009552 and batch: 1250, loss is 3.6617622804641723 and perplexity is 38.92988783667316
At time: 892.3311831951141 and batch: 1300, loss is 3.6698429107666017 and perplexity is 39.2457402927883
At time: 893.4860951900482 and batch: 1350, loss is 3.5379929399490355 and perplexity is 34.39781138922238
At time: 894.6403498649597 and batch: 1400, loss is 3.5693250703811645 and perplexity is 35.492630038567356
At time: 895.7942352294922 and batch: 1450, loss is 3.476967315673828 and perplexity is 32.36143110357122
At time: 896.9477341175079 and batch: 1500, loss is 3.4750897550582884 and perplexity is 32.30072756019264
At time: 898.0998685359955 and batch: 1550, loss is 3.486591348648071 and perplexity is 32.67438209341973
At time: 899.2559978961945 and batch: 1600, loss is 3.568455305099487 and perplexity is 35.4617732022521
At time: 900.4110956192017 and batch: 1650, loss is 3.511010823249817 and perplexity is 33.48209516455813
At time: 901.567587852478 and batch: 1700, loss is 3.5306169509887697 and perplexity is 34.14502692592848
At time: 902.7213568687439 and batch: 1750, loss is 3.532704567909241 and perplexity is 34.216383118171095
At time: 903.8782017230988 and batch: 1800, loss is 3.46401789188385 and perplexity is 31.94507084864333
At time: 905.0321352481842 and batch: 1850, loss is 3.502564716339111 and perplexity is 33.20049270548935
At time: 906.1860964298248 and batch: 1900, loss is 3.585470995903015 and perplexity is 36.07034270224956
At time: 907.3392040729523 and batch: 1950, loss is 3.534047050476074 and perplexity is 34.2623488632095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376541208666424 and perplexity of 79.56236731761194
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 910.9807329177856 and batch: 50, loss is 3.7604556846618653 and perplexity is 42.968001377498545
At time: 912.1599726676941 and batch: 100, loss is 3.747671227455139 and perplexity is 42.42217528204706
At time: 913.318838596344 and batch: 150, loss is 3.7054281711578367 and perplexity is 40.667456221434
At time: 914.4742348194122 and batch: 200, loss is 3.709445843696594 and perplexity is 40.8311734043082
At time: 915.6302206516266 and batch: 250, loss is 3.7070097494125367 and perplexity is 40.73182587527237
At time: 916.7864744663239 and batch: 300, loss is 3.698077750205994 and perplexity is 40.36962921702476
At time: 917.941085100174 and batch: 350, loss is 3.728194165229797 and perplexity is 41.6039104990299
At time: 919.0971026420593 and batch: 400, loss is 3.721077394485474 and perplexity is 41.30887609729167
At time: 920.2521755695343 and batch: 450, loss is 3.7576777124404908 and perplexity is 42.84880310466496
At time: 921.4068760871887 and batch: 500, loss is 3.785163722038269 and perplexity is 44.042880758708556
At time: 922.5633449554443 and batch: 550, loss is 3.7419114542007446 and perplexity is 42.178535499976384
At time: 923.7424113750458 and batch: 600, loss is 3.7191207456588744 and perplexity is 41.228128156791065
At time: 924.8952169418335 and batch: 650, loss is 3.7249181509017943 and perplexity is 41.467838500738914
At time: 926.050231218338 and batch: 700, loss is 3.7540865325927735 and perplexity is 42.69520131735627
At time: 927.2048962116241 and batch: 750, loss is 3.7127332639694215 and perplexity is 40.96562350743323
At time: 928.3592307567596 and batch: 800, loss is 3.66169650554657 and perplexity is 38.92732731071855
At time: 929.5151710510254 and batch: 850, loss is 3.6510729360580445 and perplexity is 38.515969059339575
At time: 930.6701436042786 and batch: 900, loss is 3.6270525550842283 and perplexity is 37.60182382051463
At time: 931.8251953125 and batch: 950, loss is 3.7350336503982544 and perplexity is 41.889435135561214
At time: 932.9802017211914 and batch: 1000, loss is 3.7027405500411987 and perplexity is 40.55830425260468
At time: 934.1421175003052 and batch: 1050, loss is 3.6578005599975585 and perplexity is 38.775963606976134
At time: 935.2998006343842 and batch: 1100, loss is 3.6762747955322266 and perplexity is 39.498977896417664
At time: 936.4553339481354 and batch: 1150, loss is 3.650253190994263 and perplexity is 38.4844087213094
At time: 937.6119573116302 and batch: 1200, loss is 3.686856174468994 and perplexity is 39.91915063222319
At time: 938.7730002403259 and batch: 1250, loss is 3.6605246114730834 and perplexity is 38.881735326252404
At time: 939.9290835857391 and batch: 1300, loss is 3.66830689907074 and perplexity is 39.185504649854835
At time: 941.0837376117706 and batch: 1350, loss is 3.535545573234558 and perplexity is 34.31373026122223
At time: 942.2382302284241 and batch: 1400, loss is 3.5664945077896117 and perplexity is 35.39230797862175
At time: 943.3961560726166 and batch: 1450, loss is 3.473367338180542 and perplexity is 32.245140127987874
At time: 944.5573678016663 and batch: 1500, loss is 3.4701962804794313 and perplexity is 32.14305087905857
At time: 945.7128295898438 and batch: 1550, loss is 3.4822278738021852 and perplexity is 32.53211885580288
At time: 946.8685212135315 and batch: 1600, loss is 3.564144115447998 and perplexity is 35.30921985209551
At time: 948.0280175209045 and batch: 1650, loss is 3.5054515409469604 and perplexity is 33.296475180451736
At time: 949.1852359771729 and batch: 1700, loss is 3.5241211652755737 and perplexity is 33.92394696923455
At time: 950.3412537574768 and batch: 1750, loss is 3.5264045333862306 and perplexity is 34.00149633110796
At time: 951.5047197341919 and batch: 1800, loss is 3.4581518840789793 and perplexity is 31.758229356312597
At time: 952.6676247119904 and batch: 1850, loss is 3.4971494770050047 and perplexity is 33.021190013143034
At time: 953.8231198787689 and batch: 1900, loss is 3.580037989616394 and perplexity is 35.87490369500511
At time: 955.2140936851501 and batch: 1950, loss is 3.5298538970947266 and perplexity is 34.11898236813477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376260446947675 and perplexity of 79.54003238615967
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fad68d45b38>
ELAPSED
1971.5655295848846


RESULTS SO FAR:
[{'best_accuracy': -79.15217303895258, 'params': {'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.54003238615967, 'params': {'num_layers': 2, 'dropout': 0.532313874403636, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.08424698132469677, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'dropout': 0.5310812723449767, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.5433392138601495, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6796066761016846 and batch: 50, loss is 7.479542369842529 and perplexity is 1771.4299306545872
At time: 2.903229236602783 and batch: 100, loss is 6.64444299697876 and perplexity is 768.5018705313604
At time: 4.121168851852417 and batch: 150, loss is 6.307712097167968 and perplexity is 548.7879379236117
At time: 5.338529825210571 and batch: 200, loss is 6.19313684463501 and perplexity is 489.37880631969307
At time: 6.56170392036438 and batch: 250, loss is 6.117975101470948 and perplexity is 453.94457154091947
At time: 7.794738054275513 and batch: 300, loss is 6.0493057823181156 and perplexity is 423.81870545467746
At time: 9.018052101135254 and batch: 350, loss is 6.000253963470459 and perplexity is 403.53126268037806
At time: 10.236511945724487 and batch: 400, loss is 5.949700298309327 and perplexity is 383.6383447694462
At time: 11.454521656036377 and batch: 450, loss is 5.876865491867066 and perplexity is 356.6894416587087
At time: 12.70255708694458 and batch: 500, loss is 5.8510000514984135 and perplexity is 347.58180643420155
At time: 13.922881841659546 and batch: 550, loss is 5.804393005371094 and perplexity is 331.75375946497564
At time: 15.142127275466919 and batch: 600, loss is 5.850735158920288 and perplexity is 347.48974678688256
At time: 16.361597299575806 and batch: 650, loss is 5.918570899963379 and perplexity is 371.8798803943828
At time: 17.582048177719116 and batch: 700, loss is 5.823171577453613 and perplexity is 338.04248317568965
At time: 18.80314612388611 and batch: 750, loss is 5.768627109527588 and perplexity is 320.09797138925
At time: 20.023824214935303 and batch: 800, loss is 5.773596391677857 and perplexity is 321.69258729156047
At time: 21.24292516708374 and batch: 850, loss is 5.801009960174561 and perplexity is 330.6333178235629
At time: 22.46098780632019 and batch: 900, loss is 5.793855447769165 and perplexity is 328.2762395766504
At time: 23.680362939834595 and batch: 950, loss is 5.824510087966919 and perplexity is 338.4952595487322
At time: 24.905213832855225 and batch: 1000, loss is 5.798380613327026 and perplexity is 329.7651100615183
At time: 26.126534938812256 and batch: 1050, loss is 5.700882873535156 and perplexity is 299.13137959862195
At time: 27.346880435943604 and batch: 1100, loss is 5.788360366821289 and perplexity is 326.47728230159765
At time: 28.56752109527588 and batch: 1150, loss is 5.698854532241821 and perplexity is 298.5252539918569
At time: 29.787819385528564 and batch: 1200, loss is 5.773724193572998 and perplexity is 321.7337028411359
At time: 31.007663249969482 and batch: 1250, loss is 5.707200717926026 and perplexity is 301.0272276377167
At time: 32.22824478149414 and batch: 1300, loss is 5.7191234302520755 and perplexity is 304.63776963181886
At time: 33.453317165374756 and batch: 1350, loss is 5.6966706562042235 and perplexity is 297.874023205528
At time: 34.67246460914612 and batch: 1400, loss is 5.7203688621521 and perplexity is 305.0174115881001
At time: 35.892656564712524 and batch: 1450, loss is 5.686795282363891 and perplexity is 294.946882959743
At time: 37.113351583480835 and batch: 1500, loss is 5.66412537574768 and perplexity is 288.33568541745444
At time: 38.33382701873779 and batch: 1550, loss is 5.646937417984009 and perplexity is 283.42213177628526
At time: 39.55434966087341 and batch: 1600, loss is 5.6672216892242435 and perplexity is 289.2298466733882
At time: 40.77467131614685 and batch: 1650, loss is 5.646421623229981 and perplexity is 283.2759818224696
At time: 41.995665550231934 and batch: 1700, loss is 5.6593555736541745 and perplexity is 286.96365601712466
At time: 43.21673274040222 and batch: 1750, loss is 5.673372983932495 and perplexity is 291.0144679370983
At time: 44.438079595565796 and batch: 1800, loss is 5.677057523727417 and perplexity is 292.08870013545277
At time: 45.659363985061646 and batch: 1850, loss is 5.636456747055053 and perplexity is 280.46718961597327
At time: 46.879575967788696 and batch: 1900, loss is 5.62494683265686 and perplexity is 277.25754308432465
At time: 48.10050082206726 and batch: 1950, loss is 5.561751728057861 and perplexity is 260.278374148119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.09911371275436 and perplexity of 163.8766011764499
finished 1 epochs...
Completing Train Step...
At time: 51.75450801849365 and batch: 50, loss is 5.365218305587769 and perplexity is 213.83791159681735
At time: 52.937150955200195 and batch: 100, loss is 5.281726207733154 and perplexity is 196.70914328841135
At time: 54.0886492729187 and batch: 150, loss is 5.190291862487793 and perplexity is 179.52094071481423
At time: 55.23849177360535 and batch: 200, loss is 5.156437101364136 and perplexity is 173.54502943540913
At time: 56.38820815086365 and batch: 250, loss is 5.156294612884522 and perplexity is 173.52030302967606
At time: 57.53966188430786 and batch: 300, loss is 5.160690670013428 and perplexity is 174.284787321973
At time: 58.69055104255676 and batch: 350, loss is 5.121536483764649 and perplexity is 167.59267532217427
At time: 59.84100890159607 and batch: 400, loss is 5.095712261199951 and perplexity is 163.32012979838905
At time: 60.991105794906616 and batch: 450, loss is 5.045330381393432 and perplexity is 155.29559749978722
At time: 62.1415810585022 and batch: 500, loss is 5.0364602851867675 and perplexity is 153.92420180697238
At time: 63.290539026260376 and batch: 550, loss is 4.982785005569458 and perplexity is 145.88009330910518
At time: 64.44195580482483 and batch: 600, loss is 4.977433376312256 and perplexity is 145.1014824104211
At time: 65.59257006645203 and batch: 650, loss is 5.049013061523437 and perplexity is 155.86855587464353
At time: 66.74538230895996 and batch: 700, loss is 5.020472526550293 and perplexity is 151.48286656143216
At time: 67.89661288261414 and batch: 750, loss is 4.974000253677368 and perplexity is 144.60418535613107
At time: 69.04859757423401 and batch: 800, loss is 4.951164884567261 and perplexity is 141.33951227954694
At time: 70.19956302642822 and batch: 850, loss is 4.945205717086792 and perplexity is 140.49975107819586
At time: 71.35073184967041 and batch: 900, loss is 4.957185802459716 and perplexity is 142.19307290860758
At time: 72.5009868144989 and batch: 950, loss is 5.020552892684936 and perplexity is 151.49504114308786
At time: 73.65274262428284 and batch: 1000, loss is 4.978535861968994 and perplexity is 145.26154292955087
At time: 74.80439710617065 and batch: 1050, loss is 4.892331848144531 and perplexity is 133.26396334594793
At time: 75.95458245277405 and batch: 1100, loss is 4.974525375366211 and perplexity is 144.68014009115296
At time: 77.10527563095093 and batch: 1150, loss is 4.883475275039673 and perplexity is 132.08891245518632
At time: 78.25671458244324 and batch: 1200, loss is 4.961321496963501 and perplexity is 142.7823577297845
At time: 79.40772080421448 and batch: 1250, loss is 4.9012633228302 and perplexity is 134.45953823682345
At time: 80.55873465538025 and batch: 1300, loss is 4.937500133514404 and perplexity is 139.42127896912288
At time: 81.71061754226685 and batch: 1350, loss is 4.844231424331665 and perplexity is 127.00563103471345
At time: 82.86132264137268 and batch: 1400, loss is 4.8624207878112795 and perplexity is 129.33692068314164
At time: 84.01351189613342 and batch: 1450, loss is 4.795678281784058 and perplexity is 120.9864168411282
At time: 85.16459584236145 and batch: 1500, loss is 4.7717996597290036 and perplexity is 118.13164754326068
At time: 86.31572008132935 and batch: 1550, loss is 4.772996339797974 and perplexity is 118.27309794995128
At time: 87.46659111976624 and batch: 1600, loss is 4.835893821716309 and perplexity is 125.95111074758078
At time: 88.61801767349243 and batch: 1650, loss is 4.791392488479614 and perplexity is 120.46900362094718
At time: 89.76725912094116 and batch: 1700, loss is 4.817904529571533 and perplexity is 123.70559757305593
At time: 90.91749858856201 and batch: 1750, loss is 4.833540773391723 and perplexity is 125.65509010947459
At time: 92.06775951385498 and batch: 1800, loss is 4.786085119247437 and perplexity is 119.83132383558993
At time: 93.21875548362732 and batch: 1850, loss is 4.791569490432739 and perplexity is 120.49032875711876
At time: 94.36942768096924 and batch: 1900, loss is 4.857359561920166 and perplexity is 128.68397106808152
At time: 95.51969981193542 and batch: 1950, loss is 4.7801410102844235 and perplexity is 119.12114616727492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.638981592932413 and perplexity of 103.43895096533319
finished 2 epochs...
Completing Train Step...
At time: 99.13998532295227 and batch: 50, loss is 4.717408266067505 and perplexity is 111.87791879780907
At time: 100.31960391998291 and batch: 100, loss is 4.660550298690796 and perplexity is 105.69422955212156
At time: 101.47267246246338 and batch: 150, loss is 4.612942686080933 and perplexity is 100.78027843823894
At time: 102.6267364025116 and batch: 200, loss is 4.612140665054321 and perplexity is 100.69948294003878
At time: 103.7847490310669 and batch: 250, loss is 4.610615711212159 and perplexity is 100.5460379046599
At time: 104.94306015968323 and batch: 300, loss is 4.637300701141357 and perplexity is 103.2652273280013
At time: 106.1013593673706 and batch: 350, loss is 4.6379643821716305 and perplexity is 103.33378524824485
At time: 107.25526785850525 and batch: 400, loss is 4.607294244766235 and perplexity is 100.21263161889986
At time: 108.4153254032135 and batch: 450, loss is 4.603967094421387 and perplexity is 99.87976318578103
At time: 109.57088232040405 and batch: 500, loss is 4.610993900299072 and perplexity is 100.58407051023272
At time: 110.749915599823 and batch: 550, loss is 4.569643030166626 and perplexity is 96.50965258851934
At time: 111.90436053276062 and batch: 600, loss is 4.546357498168946 and perplexity is 94.28833661568049
At time: 113.06094741821289 and batch: 650, loss is 4.60418327331543 and perplexity is 99.90135741654814
At time: 114.21490168571472 and batch: 700, loss is 4.622771253585816 and perplexity is 101.77568791957647
At time: 115.36600732803345 and batch: 750, loss is 4.578792629241943 and perplexity is 97.39672922592128
At time: 116.51992344856262 and batch: 800, loss is 4.559083251953125 and perplexity is 95.49589401481524
At time: 117.67583990097046 and batch: 850, loss is 4.558624267578125 and perplexity is 95.45207294894732
At time: 118.83105540275574 and batch: 900, loss is 4.551645154953003 and perplexity is 94.78822142338875
At time: 119.98596835136414 and batch: 950, loss is 4.629219923019409 and perplexity is 102.43412643171926
At time: 121.14094734191895 and batch: 1000, loss is 4.603009099960327 and perplexity is 99.78412474374032
At time: 122.2971715927124 and batch: 1050, loss is 4.530522298812866 and perplexity is 92.80702142273566
At time: 123.45189046859741 and batch: 1100, loss is 4.599138393402099 and perplexity is 99.39863621546911
At time: 124.60766434669495 and batch: 1150, loss is 4.5315399074554445 and perplexity is 92.90151071823539
At time: 125.76387810707092 and batch: 1200, loss is 4.606451101303101 and perplexity is 100.12817360374196
At time: 126.91982460021973 and batch: 1250, loss is 4.56837498664856 and perplexity is 96.3873517069314
At time: 128.07649755477905 and batch: 1300, loss is 4.593440971374512 and perplexity is 98.83393044708224
At time: 129.23282766342163 and batch: 1350, loss is 4.474895582199097 and perplexity is 87.78543356924784
At time: 130.3888063430786 and batch: 1400, loss is 4.490508327484131 and perplexity is 89.1667602753251
At time: 131.5445511341095 and batch: 1450, loss is 4.429706897735596 and perplexity is 83.90682002679497
At time: 132.70017886161804 and batch: 1500, loss is 4.422752785682678 and perplexity is 83.325346756782
At time: 133.85403537750244 and batch: 1550, loss is 4.427828063964844 and perplexity is 83.7493210632492
At time: 135.00770258903503 and batch: 1600, loss is 4.50846830368042 and perplexity is 90.78266049686262
At time: 136.16096568107605 and batch: 1650, loss is 4.462416696548462 and perplexity is 86.69677592640998
At time: 137.3172824382782 and batch: 1700, loss is 4.496881685256958 and perplexity is 89.73686675649586
At time: 138.47174715995789 and batch: 1750, loss is 4.500867681503296 and perplexity is 90.09527139578626
At time: 139.62661170959473 and batch: 1800, loss is 4.450298328399658 and perplexity is 85.65249276214318
At time: 140.78245973587036 and batch: 1850, loss is 4.479190683364868 and perplexity is 88.16329177603055
At time: 141.93814730644226 and batch: 1900, loss is 4.555550918579102 and perplexity is 95.15916574967275
At time: 143.09354901313782 and batch: 1950, loss is 4.484466571807861 and perplexity is 88.62966064148073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.527469794694768 and perplexity of 92.52415954581343
finished 3 epochs...
Completing Train Step...
At time: 146.78199410438538 and batch: 50, loss is 4.438486819267273 and perplexity is 84.64675887180076
At time: 147.9376609325409 and batch: 100, loss is 4.3860594844818115 and perplexity is 80.32327941515008
At time: 149.09139037132263 and batch: 150, loss is 4.346455917358399 and perplexity is 77.20435886034618
At time: 150.24553203582764 and batch: 200, loss is 4.357441291809082 and perplexity is 78.05715320813073
At time: 151.3988311290741 and batch: 250, loss is 4.347360954284668 and perplexity is 77.27426328425472
At time: 152.5524458885193 and batch: 300, loss is 4.380576276779175 and perplexity is 79.8840554692807
At time: 153.70747089385986 and batch: 350, loss is 4.378781213760376 and perplexity is 79.74078718178892
At time: 154.86225128173828 and batch: 400, loss is 4.3496806430816655 and perplexity is 77.45372359265252
At time: 156.0167212486267 and batch: 450, loss is 4.36491455078125 and perplexity is 78.64267969912055
At time: 157.17017698287964 and batch: 500, loss is 4.370361967086792 and perplexity is 79.07224807144013
At time: 158.32344889640808 and batch: 550, loss is 4.332141132354736 and perplexity is 76.10706754393544
At time: 159.47757124900818 and batch: 600, loss is 4.3150525426864625 and perplexity is 74.81755445597474
At time: 160.63086581230164 and batch: 650, loss is 4.366115036010743 and perplexity is 78.7371457657208
At time: 161.78751468658447 and batch: 700, loss is 4.392152633666992 and perplexity is 80.81419523249588
At time: 162.95237469673157 and batch: 750, loss is 4.3496454811096195 and perplexity is 77.45100021486866
At time: 164.11547541618347 and batch: 800, loss is 4.333998012542724 and perplexity is 76.24852053981225
At time: 165.27788758277893 and batch: 850, loss is 4.32758544921875 and perplexity is 75.7611364343521
At time: 166.44774913787842 and batch: 900, loss is 4.313098697662354 and perplexity is 74.67151526491719
At time: 167.65417885780334 and batch: 950, loss is 4.398169946670532 and perplexity is 81.30194554177163
At time: 168.81853675842285 and batch: 1000, loss is 4.379982070922852 and perplexity is 79.83660199565618
At time: 169.98254013061523 and batch: 1050, loss is 4.311274490356445 and perplexity is 74.53542310911996
At time: 171.14584302902222 and batch: 1100, loss is 4.368725824356079 and perplexity is 78.94298036660177
At time: 172.31526589393616 and batch: 1150, loss is 4.313640351295471 and perplexity is 74.71197231831665
At time: 173.47793769836426 and batch: 1200, loss is 4.38894063949585 and perplexity is 80.55503693873733
At time: 174.64196300506592 and batch: 1250, loss is 4.361322984695435 and perplexity is 78.36073593072805
At time: 175.810555934906 and batch: 1300, loss is 4.37196828842163 and perplexity is 79.19936557896001
At time: 176.97516179084778 and batch: 1350, loss is 4.248705897331238 and perplexity is 70.01474742298826
At time: 178.13816499710083 and batch: 1400, loss is 4.281231079101563 and perplexity is 72.32942846798426
At time: 179.31168246269226 and batch: 1450, loss is 4.211882824897766 and perplexity is 67.48347984572773
At time: 180.47345876693726 and batch: 1500, loss is 4.2112803602218625 and perplexity is 67.4428356774808
At time: 181.63756394386292 and batch: 1550, loss is 4.215631880760193 and perplexity is 67.73695402900627
At time: 182.7999927997589 and batch: 1600, loss is 4.308065128326416 and perplexity is 74.29659539958658
At time: 183.96497893333435 and batch: 1650, loss is 4.252164959907532 and perplexity is 70.25735216618239
At time: 185.12733101844788 and batch: 1700, loss is 4.292974348068237 and perplexity is 73.18381925241941
At time: 186.29180645942688 and batch: 1750, loss is 4.298894090652466 and perplexity is 73.61833346095415
At time: 187.45254778862 and batch: 1800, loss is 4.245694260597229 and perplexity is 69.80420563455262
At time: 188.61349654197693 and batch: 1850, loss is 4.288607168197632 and perplexity is 72.86490922571186
At time: 189.77385759353638 and batch: 1900, loss is 4.36028359413147 and perplexity is 78.27933083438954
At time: 190.93444514274597 and batch: 1950, loss is 4.292388458251953 and perplexity is 73.1409541563404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489656102380088 and perplexity of 89.0908024949332
finished 4 epochs...
Completing Train Step...
At time: 194.57235074043274 and batch: 50, loss is 4.250677156448364 and perplexity is 70.15290075545013
At time: 195.72295427322388 and batch: 100, loss is 4.204026203155518 and perplexity is 66.95536498662568
At time: 196.89732432365417 and batch: 150, loss is 4.1669108152389525 and perplexity is 64.51584259302402
At time: 198.04828786849976 and batch: 200, loss is 4.182212619781494 and perplexity is 65.51064311729709
At time: 199.19960117340088 and batch: 250, loss is 4.174748687744141 and perplexity is 65.02349640590721
At time: 200.3515338897705 and batch: 300, loss is 4.196320815086365 and perplexity is 66.44143049127344
At time: 201.5021014213562 and batch: 350, loss is 4.197783870697021 and perplexity is 66.53870914362048
At time: 202.65330123901367 and batch: 400, loss is 4.166900205612182 and perplexity is 64.51515810764442
At time: 203.80445861816406 and batch: 450, loss is 4.193471794128418 and perplexity is 66.25240685733263
At time: 204.955739736557 and batch: 500, loss is 4.203130745887757 and perplexity is 66.89543615429149
At time: 206.10768604278564 and batch: 550, loss is 4.16522340297699 and perplexity is 64.40706956741994
At time: 207.25949716567993 and batch: 600, loss is 4.15021954536438 and perplexity is 63.44792846770946
At time: 208.41144275665283 and batch: 650, loss is 4.200849061012268 and perplexity is 66.74297584870915
At time: 209.56280708312988 and batch: 700, loss is 4.230287671089172 and perplexity is 68.73700297847893
At time: 210.7138020992279 and batch: 750, loss is 4.1922708511352536 and perplexity is 66.17288925115015
At time: 211.86544275283813 and batch: 800, loss is 4.1695597457885745 and perplexity is 64.68696712784464
At time: 213.0165674686432 and batch: 850, loss is 4.163681616783142 and perplexity is 64.30784414862089
At time: 214.17226672172546 and batch: 900, loss is 4.14317223072052 and perplexity is 63.00236281703385
At time: 215.32865405082703 and batch: 950, loss is 4.2320781373977665 and perplexity is 68.86018450974879
At time: 216.4830048084259 and batch: 1000, loss is 4.217501516342163 and perplexity is 67.86371591081044
At time: 217.63805985450745 and batch: 1050, loss is 4.159606914520264 and perplexity is 64.0463419641334
At time: 218.7916419506073 and batch: 1100, loss is 4.206727476119995 and perplexity is 67.13647420648273
At time: 219.94883275032043 and batch: 1150, loss is 4.16047884941101 and perplexity is 64.102210557665
At time: 221.10434412956238 and batch: 1200, loss is 4.235878362655639 and perplexity is 69.12236658212156
At time: 222.25859427452087 and batch: 1250, loss is 4.209172224998474 and perplexity is 67.30080682064259
At time: 223.41775250434875 and batch: 1300, loss is 4.218828721046448 and perplexity is 67.95384475029742
At time: 224.56944251060486 and batch: 1350, loss is 4.084579882621765 and perplexity is 59.416970405173814
At time: 225.72234654426575 and batch: 1400, loss is 4.127713494300842 and perplexity is 62.035915172257134
At time: 226.87373971939087 and batch: 1450, loss is 4.058999376296997 and perplexity is 57.91632962277593
At time: 228.02561831474304 and batch: 1500, loss is 4.057240419387817 and perplexity is 57.814546836641455
At time: 229.17914390563965 and batch: 1550, loss is 4.062342777252197 and perplexity is 58.110291199538395
At time: 230.33189272880554 and batch: 1600, loss is 4.159019832611084 and perplexity is 64.0087525505291
At time: 231.48452258110046 and batch: 1650, loss is 4.104452800750733 and perplexity is 60.609569960698344
At time: 232.63917231559753 and batch: 1700, loss is 4.14662693977356 and perplexity is 63.22039405060855
At time: 233.7952003479004 and batch: 1750, loss is 4.151922059059143 and perplexity is 63.5560414406243
At time: 234.94946122169495 and batch: 1800, loss is 4.094797968864441 and perplexity is 60.02721056680012
At time: 236.10229396820068 and batch: 1850, loss is 4.1448727893829345 and perplexity is 63.10959318079531
At time: 237.2566237449646 and batch: 1900, loss is 4.214236202239991 and perplexity is 67.6424809595964
At time: 238.41712641716003 and batch: 1950, loss is 4.1467734146118165 and perplexity is 63.229654925827674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475991608375727 and perplexity of 87.88170144878754
finished 5 epochs...
Completing Train Step...
At time: 242.1050021648407 and batch: 50, loss is 4.109414925575257 and perplexity is 60.91106963326499
At time: 243.26189708709717 and batch: 100, loss is 4.065054473876953 and perplexity is 58.26808252445881
At time: 244.41379022598267 and batch: 150, loss is 4.02803524017334 and perplexity is 56.15048058928272
At time: 245.56732320785522 and batch: 200, loss is 4.043562741279602 and perplexity is 57.02916144338417
At time: 246.71933889389038 and batch: 250, loss is 4.0389421272277835 and perplexity is 56.766259550493466
At time: 247.8747637271881 and batch: 300, loss is 4.055345506668091 and perplexity is 57.705097048103774
At time: 249.02772760391235 and batch: 350, loss is 4.060320363044739 and perplexity is 57.99288688111459
At time: 250.17871928215027 and batch: 400, loss is 4.031002612113952 and perplexity is 56.31734740534654
At time: 251.3374547958374 and batch: 450, loss is 4.062466578483582 and perplexity is 58.1174857704842
At time: 252.4950408935547 and batch: 500, loss is 4.071808204650879 and perplexity is 58.66294135075901
At time: 253.6456904411316 and batch: 550, loss is 4.034914951324463 and perplexity is 56.538111542335244
At time: 254.82756853103638 and batch: 600, loss is 4.020134844779968 and perplexity is 55.70861733658738
At time: 255.97966408729553 and batch: 650, loss is 4.070583834648132 and perplexity is 58.591160157433315
At time: 257.1358139514923 and batch: 700, loss is 4.104051904678345 and perplexity is 60.585276692015356
At time: 258.29310297966003 and batch: 750, loss is 4.064585270881653 and perplexity is 58.2407493785064
At time: 259.4456150531769 and batch: 800, loss is 4.041486535072327 and perplexity is 56.91087997524789
At time: 260.59783840179443 and batch: 850, loss is 4.039176502227783 and perplexity is 56.7795657018293
At time: 261.75638484954834 and batch: 900, loss is 4.017329773902893 and perplexity is 55.55256968118192
At time: 262.90904712677 and batch: 950, loss is 4.102804183959961 and perplexity is 60.509730327240895
At time: 264.0609247684479 and batch: 1000, loss is 4.093292474746704 and perplexity is 59.936907946475515
At time: 265.21278285980225 and batch: 1050, loss is 4.035762796401977 and perplexity is 56.58606742860668
At time: 266.3679084777832 and batch: 1100, loss is 4.081079378128051 and perplexity is 59.20934464273724
At time: 267.5196576118469 and batch: 1150, loss is 4.033501353263855 and perplexity is 56.458245839808995
At time: 268.67166328430176 and batch: 1200, loss is 4.11661849975586 and perplexity is 61.35143122623911
At time: 269.8291726112366 and batch: 1250, loss is 4.091533732414246 and perplexity is 59.8315870125339
At time: 270.98558020591736 and batch: 1300, loss is 4.095034732818603 and perplexity is 60.041424529141814
At time: 272.15655636787415 and batch: 1350, loss is 3.9602116107940675 and perplexity is 52.4684276600773
At time: 273.3200159072876 and batch: 1400, loss is 4.009303369522095 and perplexity is 55.10846695078482
At time: 274.48567962646484 and batch: 1450, loss is 3.937910113334656 and perplexity is 51.31125446175267
At time: 275.64811968803406 and batch: 1500, loss is 3.933350262641907 and perplexity is 51.07781543058992
At time: 276.8092474937439 and batch: 1550, loss is 3.9429751586914064 and perplexity is 51.57180759259219
At time: 277.97070145606995 and batch: 1600, loss is 4.041653718948364 and perplexity is 56.920395352137476
At time: 279.131151676178 and batch: 1650, loss is 3.9867183446884153 and perplexity is 53.87779059602072
At time: 280.2936632633209 and batch: 1700, loss is 4.036308507919312 and perplexity is 56.61695552455146
At time: 281.4554531574249 and batch: 1750, loss is 4.034564561843872 and perplexity is 56.5183046530638
At time: 282.62637209892273 and batch: 1800, loss is 3.9769971227645873 and perplexity is 53.356570191182456
At time: 283.7903528213501 and batch: 1850, loss is 4.024280977249146 and perplexity is 55.94007213329658
At time: 284.95437479019165 and batch: 1900, loss is 4.101508712768554 and perplexity is 60.43139246797796
At time: 286.11890625953674 and batch: 1950, loss is 4.0306026029586794 and perplexity is 56.294824455777054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.471614110192587 and perplexity of 87.49784024919398
finished 6 epochs...
Completing Train Step...
At time: 289.81684613227844 and batch: 50, loss is 3.9918523406982422 and perplexity is 54.155110227770066
At time: 291.01146245002747 and batch: 100, loss is 3.9463901948928832 and perplexity is 51.748228252508255
At time: 292.17850947380066 and batch: 150, loss is 3.9153573608398435 and perplexity is 50.16699602791883
At time: 293.3448476791382 and batch: 200, loss is 3.9316950130462645 and perplexity is 50.993338831468186
At time: 294.51057982444763 and batch: 250, loss is 3.9274924993515015 and perplexity is 50.779488296325134
At time: 295.6756343841553 and batch: 300, loss is 3.9430463027954104 and perplexity is 51.575476753153254
At time: 296.84168910980225 and batch: 350, loss is 3.945486183166504 and perplexity is 51.70146838626683
At time: 298.00718450546265 and batch: 400, loss is 3.918541202545166 and perplexity is 50.32697433977423
At time: 299.17387676239014 and batch: 450, loss is 3.9555856370925904 and perplexity is 52.226270631426154
At time: 300.33887910842896 and batch: 500, loss is 3.965656876564026 and perplexity is 52.75491147560006
At time: 301.5051038265228 and batch: 550, loss is 3.9270203065872193 and perplexity is 50.75551624953659
At time: 302.676789522171 and batch: 600, loss is 3.916525778770447 and perplexity is 50.22564630294639
At time: 303.84380078315735 and batch: 650, loss is 3.9665140199661253 and perplexity is 52.80014938481774
At time: 305.02204489707947 and batch: 700, loss is 3.995732431411743 and perplexity is 54.36564515121876
At time: 306.1947422027588 and batch: 750, loss is 3.962159233093262 and perplexity is 52.57071591690311
At time: 307.3604714870453 and batch: 800, loss is 3.9353565788269043 and perplexity is 51.18039654905173
At time: 308.52358412742615 and batch: 850, loss is 3.9342259693145754 and perplexity is 51.12256420492829
At time: 309.6884734630585 and batch: 900, loss is 3.9096396493911745 and perplexity is 49.880974095048735
At time: 310.85366892814636 and batch: 950, loss is 3.9959883546829222 and perplexity is 54.37956036550326
At time: 312.0399646759033 and batch: 1000, loss is 3.987603349685669 and perplexity is 53.92549381561948
At time: 313.20436334609985 and batch: 1050, loss is 3.9371568775177 and perplexity is 51.27261953950943
At time: 314.3676269054413 and batch: 1100, loss is 3.98021098613739 and perplexity is 53.528326771070574
At time: 315.5305016040802 and batch: 1150, loss is 3.928645496368408 and perplexity is 50.838070661006746
At time: 316.6946053504944 and batch: 1200, loss is 4.0134362649917605 and perplexity is 55.33669578227651
At time: 317.858375787735 and batch: 1250, loss is 3.989194884300232 and perplexity is 54.011386438044944
At time: 319.02165508270264 and batch: 1300, loss is 3.9977297306060793 and perplexity is 54.474338120535684
At time: 320.1852366924286 and batch: 1350, loss is 3.8584495210647582 and perplexity is 47.39181436492187
At time: 321.34921288490295 and batch: 1400, loss is 3.9134854078292847 and perplexity is 50.073173611648734
At time: 322.51264667510986 and batch: 1450, loss is 3.8358028602600096 and perplexity is 46.33060974533357
At time: 323.67571234703064 and batch: 1500, loss is 3.8300180768966676 and perplexity is 46.063370909484455
At time: 324.8394591808319 and batch: 1550, loss is 3.848418979644775 and perplexity is 46.918824943641965
At time: 326.00842237472534 and batch: 1600, loss is 3.945541167259216 and perplexity is 51.704311222752615
At time: 327.1700279712677 and batch: 1650, loss is 3.8902278041839597 and perplexity is 48.92202989752857
At time: 328.33249068260193 and batch: 1700, loss is 3.938109850883484 and perplexity is 51.321504269547816
At time: 329.49526047706604 and batch: 1750, loss is 3.936928539276123 and perplexity is 51.26091337625594
At time: 330.65850472450256 and batch: 1800, loss is 3.8816459798812866 and perplexity is 48.503985987771536
At time: 331.8256776332855 and batch: 1850, loss is 3.9276078605651854 and perplexity is 50.78534661763028
At time: 332.99751377105713 and batch: 1900, loss is 3.999544606208801 and perplexity is 54.57329203512678
At time: 334.1610150337219 and batch: 1950, loss is 3.9287091445922853 and perplexity is 50.8413065168868
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477627918332122 and perplexity of 88.0256208681304
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 337.79861879348755 and batch: 50, loss is 3.9231483936309814 and perplexity is 50.559375274002335
At time: 338.97451663017273 and batch: 100, loss is 3.907792077064514 and perplexity is 49.78890047021577
At time: 340.1265244483948 and batch: 150, loss is 3.879924831390381 and perplexity is 48.420575227229094
At time: 341.30247688293457 and batch: 200, loss is 3.9013551330566405 and perplexity is 49.46944137886217
At time: 342.45422863960266 and batch: 250, loss is 3.898208703994751 and perplexity is 49.31403390833447
At time: 343.60616064071655 and batch: 300, loss is 3.917835388183594 and perplexity is 50.29146537135483
At time: 344.7573380470276 and batch: 350, loss is 3.9105040931701662 and perplexity is 49.924112035270994
At time: 345.9087498188019 and batch: 400, loss is 3.872360334396362 and perplexity is 48.05567979665839
At time: 347.0597290992737 and batch: 450, loss is 3.89511305809021 and perplexity is 49.16161116637074
At time: 348.2120394706726 and batch: 500, loss is 3.9058947658538816 and perplexity is 49.69452498932851
At time: 349.3646664619446 and batch: 550, loss is 3.862382912635803 and perplexity is 47.578592022100686
At time: 350.5176730155945 and batch: 600, loss is 3.8417862367630007 and perplexity is 46.608654219923814
At time: 351.6697313785553 and batch: 650, loss is 3.8822349596023558 and perplexity is 48.53256226650761
At time: 352.82663774490356 and batch: 700, loss is 3.907034492492676 and perplexity is 49.75119545154431
At time: 353.9787709712982 and batch: 750, loss is 3.8608067560195924 and perplexity is 47.50365977748428
At time: 355.1313307285309 and batch: 800, loss is 3.8322804498672487 and perplexity is 46.16770140751346
At time: 356.2856514453888 and batch: 850, loss is 3.826017484664917 and perplexity is 45.87945827068218
At time: 357.439172744751 and batch: 900, loss is 3.7886945104598997 and perplexity is 44.1986617050911
At time: 358.59062814712524 and batch: 950, loss is 3.87716824054718 and perplexity is 48.28728331297515
At time: 359.7455940246582 and batch: 1000, loss is 3.858843026161194 and perplexity is 47.41046695510776
At time: 360.8985970020294 and batch: 1050, loss is 3.8014320755004882 and perplexity is 44.76524582383919
At time: 362.05765438079834 and batch: 1100, loss is 3.839683132171631 and perplexity is 46.510734349193214
At time: 363.21106910705566 and batch: 1150, loss is 3.7830274295806885 and perplexity is 43.948892713454484
At time: 364.36370849609375 and batch: 1200, loss is 3.8409029817581177 and perplexity is 46.56750506808553
At time: 365.51587295532227 and batch: 1250, loss is 3.8075692749023435 and perplexity is 45.04082383736814
At time: 366.66887736320496 and batch: 1300, loss is 3.818056221008301 and perplexity is 45.51564991564857
At time: 367.82072734832764 and batch: 1350, loss is 3.6818691730499267 and perplexity is 39.72056934551422
At time: 368.9763123989105 and batch: 1400, loss is 3.7090579891204833 and perplexity is 40.815339917599005
At time: 370.1285011768341 and batch: 1450, loss is 3.625769166946411 and perplexity is 37.55359703932201
At time: 371.2838644981384 and batch: 1500, loss is 3.613105659484863 and perplexity is 37.081035243081
At time: 372.43777894973755 and batch: 1550, loss is 3.625098690986633 and perplexity is 37.528426694302496
At time: 373.5905385017395 and batch: 1600, loss is 3.7185464477539063 and perplexity is 41.20445772675463
At time: 374.7446687221527 and batch: 1650, loss is 3.6559692859649657 and perplexity is 38.705019170912074
At time: 375.8977482318878 and batch: 1700, loss is 3.6869898414611817 and perplexity is 39.92448686164981
At time: 377.04996252059937 and batch: 1750, loss is 3.672961173057556 and perplexity is 39.36830980745405
At time: 378.2048783302307 and batch: 1800, loss is 3.6031702089309694 and perplexity is 36.71444259810707
At time: 379.3586263656616 and batch: 1850, loss is 3.6317662715911867 and perplexity is 37.77948655507235
At time: 380.5124921798706 and batch: 1900, loss is 3.703506178855896 and perplexity is 40.589368749435195
At time: 381.6655421257019 and batch: 1950, loss is 3.6333361053466797 and perplexity is 37.83884064416875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4177853606468025 and perplexity of 82.91246068249788
finished 8 epochs...
Completing Train Step...
At time: 385.2947006225586 and batch: 50, loss is 3.821702365875244 and perplexity is 45.68190948800424
At time: 386.472620010376 and batch: 100, loss is 3.7927045440673828 and perplexity is 44.37625566482649
At time: 387.6237061023712 and batch: 150, loss is 3.757137584686279 and perplexity is 42.82566552606007
At time: 388.77573323249817 and batch: 200, loss is 3.774705901145935 and perplexity is 43.58468822376734
At time: 389.92742586135864 and batch: 250, loss is 3.770411992073059 and perplexity is 43.39794076080961
At time: 391.08633184432983 and batch: 300, loss is 3.78725875377655 and perplexity is 44.13524871485845
At time: 392.2383761405945 and batch: 350, loss is 3.7869309473037718 and perplexity is 44.1207832657155
At time: 393.38986706733704 and batch: 400, loss is 3.752136254310608 and perplexity is 42.612014938135935
At time: 394.54274559020996 and batch: 450, loss is 3.781594228744507 and perplexity is 43.88595023904578
At time: 395.6965899467468 and batch: 500, loss is 3.793308725357056 and perplexity is 44.40307506928028
At time: 396.84965538978577 and batch: 550, loss is 3.7527560567855835 and perplexity is 42.63843415696114
At time: 398.00195503234863 and batch: 600, loss is 3.738223519325256 and perplexity is 42.02327028788269
At time: 399.19386887550354 and batch: 650, loss is 3.7781067657470704 and perplexity is 43.733166180706476
At time: 400.3474838733673 and batch: 700, loss is 3.8063177919387816 and perplexity is 44.984491270647034
At time: 401.49967336654663 and batch: 750, loss is 3.7624180126190185 and perplexity is 43.05240147111275
At time: 402.6564636230469 and batch: 800, loss is 3.7323600673675537 and perplexity is 41.777589833091454
At time: 403.8157503604889 and batch: 850, loss is 3.7318041944503784 and perplexity is 41.7543732556895
At time: 404.96852231025696 and batch: 900, loss is 3.6939686346054077 and perplexity is 40.20408609466311
At time: 406.12868070602417 and batch: 950, loss is 3.787655482292175 and perplexity is 44.152761900328166
At time: 407.2790353298187 and batch: 1000, loss is 3.7715946006774903 and perplexity is 43.44929389831403
At time: 408.432986497879 and batch: 1050, loss is 3.7177924346923827 and perplexity is 41.17340073759482
At time: 409.5857033729553 and batch: 1100, loss is 3.7562305879592897 and perplexity is 42.786840397390705
At time: 410.7384395599365 and batch: 1150, loss is 3.708395504951477 and perplexity is 40.788309355699255
At time: 411.890611410141 and batch: 1200, loss is 3.767528285980225 and perplexity is 43.272974124745495
At time: 413.04851722717285 and batch: 1250, loss is 3.738917031288147 and perplexity is 42.052424036615406
At time: 414.2022647857666 and batch: 1300, loss is 3.7484789991378786 and perplexity is 42.45645655781798
At time: 415.3568046092987 and batch: 1350, loss is 3.617190957069397 and perplexity is 37.23283216346786
At time: 416.5115554332733 and batch: 1400, loss is 3.6504854106903077 and perplexity is 38.493346596740324
At time: 417.6631009578705 and batch: 1450, loss is 3.5694538497924806 and perplexity is 35.49720105288973
At time: 418.81336307525635 and batch: 1500, loss is 3.5576091766357423 and perplexity is 35.07922856882439
At time: 419.9644513130188 and batch: 1550, loss is 3.5757883644104003 and perplexity is 35.72277227969779
At time: 421.1246738433838 and batch: 1600, loss is 3.6710914182662964 and perplexity is 39.29476949416895
At time: 422.27937173843384 and batch: 1650, loss is 3.6124019193649293 and perplexity is 37.05494901093243
At time: 423.4317059516907 and batch: 1700, loss is 3.648433814048767 and perplexity is 38.41445473095587
At time: 424.5841062068939 and batch: 1750, loss is 3.6374480009078978 and perplexity is 37.99475032755008
At time: 425.7504823207855 and batch: 1800, loss is 3.573201880455017 and perplexity is 35.63049529027448
At time: 426.9155831336975 and batch: 1850, loss is 3.605979471206665 and perplexity is 36.81772810678566
At time: 428.0823743343353 and batch: 1900, loss is 3.683468999862671 and perplexity is 39.78416623581139
At time: 429.24488162994385 and batch: 1950, loss is 3.616421604156494 and perplexity is 37.20419799189131
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425787779342296 and perplexity of 83.5786228070633
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 432.91182017326355 and batch: 50, loss is 3.783999733924866 and perplexity is 43.991645193604555
At time: 434.07487893104553 and batch: 100, loss is 3.78711368560791 and perplexity is 44.12884655954062
At time: 435.23850297927856 and batch: 150, loss is 3.765716805458069 and perplexity is 43.19465693143412
At time: 436.4066970348358 and batch: 200, loss is 3.7845287990570067 and perplexity is 44.014925797116746
At time: 437.5787000656128 and batch: 250, loss is 3.7847345876693725 and perplexity is 44.02398449967687
At time: 438.7425727844238 and batch: 300, loss is 3.802210111618042 and perplexity is 44.80008835451732
At time: 439.90594840049744 and batch: 350, loss is 3.8149546003341674 and perplexity is 45.37469634013389
At time: 441.0703830718994 and batch: 400, loss is 3.786487174034119 and perplexity is 44.10120798528038
At time: 442.23572850227356 and batch: 450, loss is 3.809838833808899 and perplexity is 45.14316272840956
At time: 443.39987564086914 and batch: 500, loss is 3.814214725494385 and perplexity is 45.34113716027635
At time: 444.5637266635895 and batch: 550, loss is 3.775582275390625 and perplexity is 43.62290146409355
At time: 445.7273609638214 and batch: 600, loss is 3.749679698944092 and perplexity is 42.507464633544664
At time: 446.89186811447144 and batch: 650, loss is 3.788256788253784 and perplexity is 44.17931920301236
At time: 448.0562663078308 and batch: 700, loss is 3.8161135005950926 and perplexity is 45.42731156957469
At time: 449.2217152118683 and batch: 750, loss is 3.764219408035278 and perplexity is 43.13002576481415
At time: 450.3853886127472 and batch: 800, loss is 3.731554160118103 and perplexity is 41.743934533926726
At time: 451.5523588657379 and batch: 850, loss is 3.726577262878418 and perplexity is 41.53669539309265
At time: 452.71723341941833 and batch: 900, loss is 3.6898776388168333 and perplexity is 40.03994732220198
At time: 453.8872718811035 and batch: 950, loss is 3.7897631120681763 and perplexity is 44.24591771049768
At time: 455.0572907924652 and batch: 1000, loss is 3.759101057052612 and perplexity is 42.90983514220695
At time: 456.26284098625183 and batch: 1050, loss is 3.6992643213272096 and perplexity is 40.417559083702116
At time: 457.4272267818451 and batch: 1100, loss is 3.738517875671387 and perplexity is 42.03564192492269
At time: 458.5916085243225 and batch: 1150, loss is 3.69687593460083 and perplexity is 40.3211415091352
At time: 459.755065202713 and batch: 1200, loss is 3.7429661560058594 and perplexity is 42.223044745370046
At time: 460.9232258796692 and batch: 1250, loss is 3.712362060546875 and perplexity is 40.95041974979853
At time: 462.0870566368103 and batch: 1300, loss is 3.7217569541931153 and perplexity is 41.336957485464644
At time: 463.2600452899933 and batch: 1350, loss is 3.5898095750808716 and perplexity is 36.22717671241047
At time: 464.42390298843384 and batch: 1400, loss is 3.6221875286102296 and perplexity is 37.41933422046245
At time: 465.5894410610199 and batch: 1450, loss is 3.5283312940597535 and perplexity is 34.067072231325476
At time: 466.753874540329 and batch: 1500, loss is 3.5036272382736207 and perplexity is 33.235787704760384
At time: 467.9173393249512 and batch: 1550, loss is 3.5211317920684815 and perplexity is 33.82268705832605
At time: 469.08087706565857 and batch: 1600, loss is 3.615059103965759 and perplexity is 37.1535417824153
At time: 470.24389481544495 and batch: 1650, loss is 3.5615811491012574 and perplexity is 35.218839380412824
At time: 471.40804290771484 and batch: 1700, loss is 3.5926057291030884 and perplexity is 36.32861523105817
At time: 472.57610750198364 and batch: 1750, loss is 3.5767810440063474 and perplexity is 35.75825115351413
At time: 473.7438232898712 and batch: 1800, loss is 3.5079816961288453 and perplexity is 33.38082709638713
At time: 474.90657234191895 and batch: 1850, loss is 3.5297461271286013 and perplexity is 34.115305564688775
At time: 476.06951117515564 and batch: 1900, loss is 3.6026255798339846 and perplexity is 36.69445228853482
At time: 477.2341613769531 and batch: 1950, loss is 3.546854882240295 and perplexity is 34.70399750671816
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.404100426962209 and perplexity of 81.78553767694436
finished 10 epochs...
Completing Train Step...
At time: 480.9263668060303 and batch: 50, loss is 3.7917479562759397 and perplexity is 44.333826177427845
At time: 482.09050393104553 and batch: 100, loss is 3.771205072402954 and perplexity is 43.43237246573418
At time: 483.25491857528687 and batch: 150, loss is 3.7318740701675415 and perplexity is 41.7572909744031
At time: 484.41849279403687 and batch: 200, loss is 3.7397744178771974 and perplexity is 42.088494682055625
At time: 485.60466480255127 and batch: 250, loss is 3.733405089378357 and perplexity is 41.821271154021005
At time: 486.76878571510315 and batch: 300, loss is 3.747775664329529 and perplexity is 42.426605952797004
At time: 487.93330097198486 and batch: 350, loss is 3.7613783359527586 and perplexity is 43.00766415407891
At time: 489.0977907180786 and batch: 400, loss is 3.731345338821411 and perplexity is 41.73521842147496
At time: 490.2668616771698 and batch: 450, loss is 3.75693199634552 and perplexity is 42.81686197352756
At time: 491.4289004802704 and batch: 500, loss is 3.764071235656738 and perplexity is 43.12363555974771
At time: 492.59162282943726 and batch: 550, loss is 3.7270371389389036 and perplexity is 41.55580151782358
At time: 493.75590109825134 and batch: 600, loss is 3.7040760707855225 and perplexity is 40.6125068956093
At time: 494.9188697338104 and batch: 650, loss is 3.7432316064834597 and perplexity is 42.234254360496465
At time: 496.08147716522217 and batch: 700, loss is 3.7744234895706175 and perplexity is 43.57238114121942
At time: 497.2471067905426 and batch: 750, loss is 3.723757333755493 and perplexity is 41.41972985086222
At time: 498.4108364582062 and batch: 800, loss is 3.690670328140259 and perplexity is 40.07169914395725
At time: 499.5793225765228 and batch: 850, loss is 3.6880439138412475 and perplexity is 39.96659234775545
At time: 500.74551224708557 and batch: 900, loss is 3.65071138381958 and perplexity is 38.50204604161032
At time: 501.914626121521 and batch: 950, loss is 3.751605758666992 and perplexity is 42.58941544484193
At time: 503.0818841457367 and batch: 1000, loss is 3.722488293647766 and perplexity is 41.367199890793145
At time: 504.2458906173706 and batch: 1050, loss is 3.665859274864197 and perplexity is 39.08971054194106
At time: 505.41082096099854 and batch: 1100, loss is 3.7066235733032227 and perplexity is 40.71609925404875
At time: 506.57419323921204 and batch: 1150, loss is 3.667450776100159 and perplexity is 39.151971395553105
At time: 507.73780035972595 and batch: 1200, loss is 3.714988145828247 and perplexity is 41.05810037173431
At time: 508.9007520675659 and batch: 1250, loss is 3.687615141868591 and perplexity is 39.9494594664263
At time: 510.0643820762634 and batch: 1300, loss is 3.699228448867798 and perplexity is 40.416109232459384
At time: 511.2277069091797 and batch: 1350, loss is 3.569009990692139 and perplexity is 35.48144879331624
At time: 512.3918240070343 and batch: 1400, loss is 3.6043820905685426 and perplexity is 36.75896312828318
At time: 513.5567390918732 and batch: 1450, loss is 3.513653450012207 and perplexity is 33.570692859060195
At time: 514.7271559238434 and batch: 1500, loss is 3.4903022956848146 and perplexity is 32.7958602549309
At time: 515.8957424163818 and batch: 1550, loss is 3.5103123998641967 and perplexity is 33.4587186505979
At time: 517.0601623058319 and batch: 1600, loss is 3.606027593612671 and perplexity is 36.81949990707715
At time: 518.2236363887787 and batch: 1650, loss is 3.5548681163787843 and perplexity is 34.98320595156106
At time: 519.3877441883087 and batch: 1700, loss is 3.5890833377838134 and perplexity is 36.20087673668237
At time: 520.5511484146118 and batch: 1750, loss is 3.5745968198776246 and perplexity is 35.68023235483288
At time: 521.7151055335999 and batch: 1800, loss is 3.5090513134002688 and perplexity is 33.41655090758064
At time: 522.8787727355957 and batch: 1850, loss is 3.53181236743927 and perplexity is 34.185868859514486
At time: 524.0429632663727 and batch: 1900, loss is 3.6053449440002443 and perplexity is 36.79437366692064
At time: 525.2063524723053 and batch: 1950, loss is 3.550727653503418 and perplexity is 34.83865873874442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.406340843023256 and perplexity of 81.96897672227833
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 528.8854384422302 and batch: 50, loss is 3.7852879619598387 and perplexity is 44.04835298268702
At time: 530.0398511886597 and batch: 100, loss is 3.787427821159363 and perplexity is 44.14271117666013
At time: 531.1988184452057 and batch: 150, loss is 3.7618907833099366 and perplexity is 43.029708965833414
At time: 532.3600931167603 and batch: 200, loss is 3.7727235984802245 and perplexity is 43.498375757097484
At time: 533.5145499706268 and batch: 250, loss is 3.770349006652832 and perplexity is 43.39520740935536
At time: 534.6749324798584 and batch: 300, loss is 3.772015428543091 and perplexity is 43.46758241981695
At time: 535.8295321464539 and batch: 350, loss is 3.7894578886032106 and perplexity is 44.23241487897884
At time: 536.985044002533 and batch: 400, loss is 3.773698577880859 and perplexity is 43.54080645859051
At time: 538.1387875080109 and batch: 450, loss is 3.800242009162903 and perplexity is 44.71200389868562
At time: 539.2936108112335 and batch: 500, loss is 3.803599252700806 and perplexity is 44.86236524343977
At time: 540.448647737503 and batch: 550, loss is 3.7699738550186157 and perplexity is 43.37893067969034
At time: 541.6027584075928 and batch: 600, loss is 3.7364089107513427 and perplexity is 41.94708364668622
At time: 542.7563071250916 and batch: 650, loss is 3.760612440109253 and perplexity is 42.974737373716096
At time: 543.9351532459259 and batch: 700, loss is 3.7960796117782594 and perplexity is 44.52628156382111
At time: 545.0959634780884 and batch: 750, loss is 3.7517705869674685 and perplexity is 42.59643596438225
At time: 546.2497625350952 and batch: 800, loss is 3.7165323066711426 and perplexity is 41.121549657956116
At time: 547.4037992954254 and batch: 850, loss is 3.706219186782837 and perplexity is 40.699637541019484
At time: 548.5600483417511 and batch: 900, loss is 3.669051294326782 and perplexity is 39.21468501313635
At time: 549.7142219543457 and batch: 950, loss is 3.7829736280441284 and perplexity is 43.9465282591026
At time: 550.8678317070007 and batch: 1000, loss is 3.74980384349823 and perplexity is 42.51274203136246
At time: 552.0216088294983 and batch: 1050, loss is 3.6865255784988404 and perplexity is 39.9059557031076
At time: 553.1754343509674 and batch: 1100, loss is 3.7191461229324343 and perplexity is 41.22917442755335
At time: 554.3317108154297 and batch: 1150, loss is 3.681496849060059 and perplexity is 39.70578317744903
At time: 555.4853804111481 and batch: 1200, loss is 3.724577612876892 and perplexity is 41.453719529078704
At time: 556.6443991661072 and batch: 1250, loss is 3.6930692863464354 and perplexity is 40.16794487403823
At time: 557.7986271381378 and batch: 1300, loss is 3.700158452987671 and perplexity is 40.4537138640756
At time: 558.952718257904 and batch: 1350, loss is 3.5683485317230224 and perplexity is 35.4579870311266
At time: 560.1117422580719 and batch: 1400, loss is 3.612087302207947 and perplexity is 37.04329272195289
At time: 561.2679395675659 and batch: 1450, loss is 3.524068932533264 and perplexity is 33.92217507473024
At time: 562.4236083030701 and batch: 1500, loss is 3.5031810331344606 and perplexity is 33.220961033596915
At time: 563.5787942409515 and batch: 1550, loss is 3.5143053913116455 and perplexity is 33.59258611596952
At time: 564.73468542099 and batch: 1600, loss is 3.6036507654190064 and perplexity is 36.73209020169784
At time: 565.8877193927765 and batch: 1650, loss is 3.547751197814941 and perplexity is 34.735117184628486
At time: 567.0428657531738 and batch: 1700, loss is 3.5808497190475466 and perplexity is 35.904036232443495
At time: 568.1985409259796 and batch: 1750, loss is 3.567942318916321 and perplexity is 35.44358646773935
At time: 569.3532340526581 and batch: 1800, loss is 3.5015328693389893 and perplexity is 33.16625254503004
At time: 570.5074815750122 and batch: 1850, loss is 3.5213527393341066 and perplexity is 33.830160914181285
At time: 571.6603651046753 and batch: 1900, loss is 3.595856704711914 and perplexity is 36.44691085698672
At time: 572.8141741752625 and batch: 1950, loss is 3.5397621297836306 and perplexity is 34.4587215123623
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.387894599382268 and perplexity of 80.47081719504287
finished 12 epochs...
Completing Train Step...
At time: 576.451422214508 and batch: 50, loss is 3.7919290399551393 and perplexity is 44.3418550367108
At time: 577.6264300346375 and batch: 100, loss is 3.781850185394287 and perplexity is 43.89718457753187
At time: 578.7794189453125 and batch: 150, loss is 3.746544876098633 and perplexity is 42.37441990708666
At time: 579.931403875351 and batch: 200, loss is 3.750723123550415 and perplexity is 42.551841115826306
At time: 581.0838196277618 and batch: 250, loss is 3.7465127992630003 and perplexity is 42.373060691584065
At time: 582.2357475757599 and batch: 300, loss is 3.7480310201644897 and perplexity is 42.4374412175498
At time: 583.3926618099213 and batch: 350, loss is 3.763367953300476 and perplexity is 43.09331812982704
At time: 584.5436298847198 and batch: 400, loss is 3.742760214805603 and perplexity is 42.21435017617245
At time: 585.704252243042 and batch: 450, loss is 3.7737586307525635 and perplexity is 43.54342128756788
At time: 586.8596820831299 and batch: 500, loss is 3.7789856815338134 and perplexity is 43.77162084759836
At time: 588.0148160457611 and batch: 550, loss is 3.7415304040908812 and perplexity is 42.162466426145855
At time: 589.168568611145 and batch: 600, loss is 3.713897032737732 and perplexity is 41.013325772464825
At time: 590.322437286377 and batch: 650, loss is 3.7384792804718017 and perplexity is 42.03401958224043
At time: 591.4747498035431 and batch: 700, loss is 3.774829626083374 and perplexity is 43.590081070199034
At time: 592.6318230628967 and batch: 750, loss is 3.7328495359420777 and perplexity is 41.79804365577746
At time: 593.7844631671906 and batch: 800, loss is 3.698672308921814 and perplexity is 40.393638468677814
At time: 594.9357075691223 and batch: 850, loss is 3.6897891998291015 and perplexity is 40.03640638637267
At time: 596.0906913280487 and batch: 900, loss is 3.65255811214447 and perplexity is 38.573214554830066
At time: 597.2427246570587 and batch: 950, loss is 3.7670077514648437 and perplexity is 43.25045490965321
At time: 598.4030177593231 and batch: 1000, loss is 3.734486503601074 and perplexity is 41.86652173435978
At time: 599.5556221008301 and batch: 1050, loss is 3.672421793937683 and perplexity is 39.34708108883766
At time: 600.73126745224 and batch: 1100, loss is 3.7060852575302126 and perplexity is 40.69418703398084
At time: 601.8849415779114 and batch: 1150, loss is 3.6691858100891115 and perplexity is 39.21996036118617
At time: 603.0378792285919 and batch: 1200, loss is 3.712642192840576 and perplexity is 40.96189289173483
At time: 604.1897785663605 and batch: 1250, loss is 3.6827170515060423 and perplexity is 39.75426184207946
At time: 605.3457877635956 and batch: 1300, loss is 3.6912290620803834 and perplexity is 40.094094818336494
At time: 606.4975426197052 and batch: 1350, loss is 3.5601147174835206 and perplexity is 35.167231209980095
At time: 607.6526036262512 and batch: 1400, loss is 3.6048739051818846 and perplexity is 36.77704616990853
At time: 608.8057534694672 and batch: 1450, loss is 3.517554426193237 and perplexity is 33.701907097696555
At time: 609.9586367607117 and batch: 1500, loss is 3.498203649520874 and perplexity is 33.05601839843413
At time: 611.1132245063782 and batch: 1550, loss is 3.5105884218215944 and perplexity is 33.467955266307584
At time: 612.2686343193054 and batch: 1600, loss is 3.6024475955963133 and perplexity is 36.68792183559356
At time: 613.4201130867004 and batch: 1650, loss is 3.5478729009628296 and perplexity is 34.739344814984875
At time: 614.5752308368683 and batch: 1700, loss is 3.582595720291138 and perplexity is 35.966779483312806
At time: 615.7281427383423 and batch: 1750, loss is 3.5721963453292847 and perplexity is 35.59468558268954
At time: 616.8840565681458 and batch: 1800, loss is 3.5068513774871826 and perplexity is 33.343117441223946
At time: 618.0385830402374 and batch: 1850, loss is 3.526838903427124 and perplexity is 34.016268770580034
At time: 619.1908617019653 and batch: 1900, loss is 3.6006451988220216 and perplexity is 36.621855200652
At time: 620.3421874046326 and batch: 1950, loss is 3.5441578149795534 and perplexity is 34.61052459924667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386721021075582 and perplexity of 80.3764337836563
finished 13 epochs...
Completing Train Step...
At time: 623.9614706039429 and batch: 50, loss is 3.7857397413253784 and perplexity is 44.06825761556326
At time: 625.1377596855164 and batch: 100, loss is 3.7736594533920287 and perplexity is 43.539102980118635
At time: 626.2916495800018 and batch: 150, loss is 3.737218976020813 and perplexity is 41.98107728897956
At time: 627.4438672065735 and batch: 200, loss is 3.7405194902420043 and perplexity is 42.11986534157404
At time: 628.5980861186981 and batch: 250, loss is 3.735746645927429 and perplexity is 41.919312765575114
At time: 629.7769477367401 and batch: 300, loss is 3.737155957221985 and perplexity is 41.97843177527472
At time: 630.9319136142731 and batch: 350, loss is 3.751932673454285 and perplexity is 42.603340830616254
At time: 632.0869381427765 and batch: 400, loss is 3.730645694732666 and perplexity is 41.70602883496542
At time: 633.2434301376343 and batch: 450, loss is 3.7616917514801025 and perplexity is 43.0211455363465
At time: 634.4005975723267 and batch: 500, loss is 3.767460894584656 and perplexity is 43.27005799689088
At time: 635.5566737651825 and batch: 550, loss is 3.729966988563538 and perplexity is 41.677732299508094
At time: 636.7129671573639 and batch: 600, loss is 3.703074369430542 and perplexity is 40.57184566102968
At time: 637.8688135147095 and batch: 650, loss is 3.727991108894348 and perplexity is 41.59546341906919
At time: 639.0246176719666 and batch: 700, loss is 3.764913353919983 and perplexity is 43.159966055970266
At time: 640.1817412376404 and batch: 750, loss is 3.7234453058242796 and perplexity is 41.406807754377795
At time: 641.3369913101196 and batch: 800, loss is 3.689516530036926 and perplexity is 40.025491155958285
At time: 642.4900074005127 and batch: 850, loss is 3.6811075448989867 and perplexity is 39.690328559308185
At time: 643.642786026001 and batch: 900, loss is 3.6439097929000854 and perplexity is 38.241059443049394
At time: 644.7966794967651 and batch: 950, loss is 3.7584684181213377 and perplexity is 42.88269729509584
At time: 645.9487488269806 and batch: 1000, loss is 3.7264839696884153 and perplexity is 41.53282048303143
At time: 647.1033022403717 and batch: 1050, loss is 3.6648683071136476 and perplexity is 39.050993086459
At time: 648.2562038898468 and batch: 1100, loss is 3.6990526294708252 and perplexity is 40.40900392115023
At time: 649.4098966121674 and batch: 1150, loss is 3.662572293281555 and perplexity is 38.961434319603036
At time: 650.5637085437775 and batch: 1200, loss is 3.7064369344711303 and perplexity is 40.70850075794589
At time: 651.7177562713623 and batch: 1250, loss is 3.6770210695266723 and perplexity is 39.5284659581472
At time: 652.8729958534241 and batch: 1300, loss is 3.686027479171753 and perplexity is 39.88608352299574
At time: 654.0263142585754 and batch: 1350, loss is 3.5553340673446656 and perplexity is 34.99951020836093
At time: 655.1804888248444 and batch: 1400, loss is 3.6005195140838624 and perplexity is 36.61725268160946
At time: 656.3348426818848 and batch: 1450, loss is 3.513704175949097 and perplexity is 33.57239580709895
At time: 657.4893691539764 and batch: 1500, loss is 3.4949193811416626 and perplexity is 32.947631645483625
At time: 658.6434674263 and batch: 1550, loss is 3.507799334526062 and perplexity is 33.374740270274145
At time: 659.7963325977325 and batch: 1600, loss is 3.600737419128418 and perplexity is 36.62523263509103
At time: 660.9503901004791 and batch: 1650, loss is 3.5469092416763304 and perplexity is 34.70588404772598
At time: 662.1045563220978 and batch: 1700, loss is 3.582136044502258 and perplexity is 35.95025022492135
At time: 663.2596633434296 and batch: 1750, loss is 3.5726032638549805 and perplexity is 35.609172667001054
At time: 664.4145784378052 and batch: 1800, loss is 3.507762660980225 and perplexity is 33.37351632265043
At time: 665.5707213878632 and batch: 1850, loss is 3.527770285606384 and perplexity is 34.04796567579286
At time: 666.7234547138214 and batch: 1900, loss is 3.6012362098693846 and perplexity is 36.64350551880892
At time: 667.8782787322998 and batch: 1950, loss is 3.544573760032654 and perplexity is 34.6249236701425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386855014534884 and perplexity of 80.38720442164676
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 671.5309672355652 and batch: 50, loss is 3.7836612606048585 and perplexity is 43.976757715052564
At time: 672.7287976741791 and batch: 100, loss is 3.7794041776657106 and perplexity is 43.78994293520393
At time: 673.8827800750732 and batch: 150, loss is 3.7491103172302247 and perplexity is 42.483268549537044
At time: 675.0366423130035 and batch: 200, loss is 3.7556950187683107 and perplexity is 42.76393121916715
At time: 676.1884500980377 and batch: 250, loss is 3.7562311840057374 and perplexity is 42.786865900342534
At time: 677.344703912735 and batch: 300, loss is 3.7550551986694334 and perplexity is 42.736578747729716
At time: 678.497011423111 and batch: 350, loss is 3.7739576864242554 and perplexity is 43.55208971526127
At time: 679.6515057086945 and batch: 400, loss is 3.7612579011917116 and perplexity is 43.00248484821382
At time: 680.8136990070343 and batch: 450, loss is 3.795662407875061 and perplexity is 44.5077088999211
At time: 681.96857380867 and batch: 500, loss is 3.8020006465911864 and perplexity is 44.79070528555371
At time: 683.1222741603851 and batch: 550, loss is 3.768066825866699 and perplexity is 43.29628462357135
At time: 684.2792670726776 and batch: 600, loss is 3.7391248464584352 and perplexity is 42.06116407640258
At time: 685.4331655502319 and batch: 650, loss is 3.747940516471863 and perplexity is 42.433600646209534
At time: 686.5865797996521 and batch: 700, loss is 3.7765214252471924 and perplexity is 43.66388914952345
At time: 687.763683795929 and batch: 750, loss is 3.7363984394073486 and perplexity is 41.94664440664353
At time: 688.9180285930634 and batch: 800, loss is 3.6977305030822754 and perplexity is 40.355613413008214
At time: 690.0714781284332 and batch: 850, loss is 3.688990650177002 and perplexity is 40.004448089823086
At time: 691.2252333164215 and batch: 900, loss is 3.646105546951294 and perplexity is 38.32511965824947
At time: 692.3793811798096 and batch: 950, loss is 3.763846211433411 and perplexity is 43.113932788869015
At time: 693.5341730117798 and batch: 1000, loss is 3.73549955368042 and perplexity is 41.908956107968386
At time: 694.6888864040375 and batch: 1050, loss is 3.678548502922058 and perplexity is 39.588889191604814
At time: 695.8474700450897 and batch: 1100, loss is 3.7121392393112185 and perplexity is 40.94129614317363
At time: 697.001513004303 and batch: 1150, loss is 3.676550726890564 and perplexity is 39.50987840686873
At time: 698.1557319164276 and batch: 1200, loss is 3.722416558265686 and perplexity is 41.36423250533794
At time: 699.3101634979248 and batch: 1250, loss is 3.689374871253967 and perplexity is 40.01982159517481
At time: 700.4646887779236 and batch: 1300, loss is 3.6940481948852537 and perplexity is 40.20728487024981
At time: 701.6186692714691 and batch: 1350, loss is 3.559057903289795 and perplexity is 35.130085612337965
At time: 702.7735998630524 and batch: 1400, loss is 3.6035183668136597 and perplexity is 36.72722724611503
At time: 703.9289970397949 and batch: 1450, loss is 3.5133246898651125 and perplexity is 33.55965796715351
At time: 705.0871863365173 and batch: 1500, loss is 3.494162640571594 and perplexity is 32.92270826738487
At time: 706.2412369251251 and batch: 1550, loss is 3.5090860080718995 and perplexity is 33.41771030395373
At time: 707.3960378170013 and batch: 1600, loss is 3.59910044670105 and perplexity is 36.565327184284335
At time: 708.552788734436 and batch: 1650, loss is 3.540927686691284 and perplexity is 34.498908528827684
At time: 709.7135453224182 and batch: 1700, loss is 3.5712390613555907 and perplexity is 35.56062766478292
At time: 710.8675630092621 and batch: 1750, loss is 3.56248215675354 and perplexity is 35.250586124080876
At time: 712.0206708908081 and batch: 1800, loss is 3.498826365470886 and perplexity is 33.07660931881661
At time: 713.1841094493866 and batch: 1850, loss is 3.5238700199127195 and perplexity is 33.91542819703336
At time: 714.3378009796143 and batch: 1900, loss is 3.5998020124435426 and perplexity is 36.590989165930914
At time: 715.498297214508 and batch: 1950, loss is 3.547841396331787 and perplexity is 34.73825038198376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380232558139535 and perplexity of 79.8566025487164
finished 15 epochs...
Completing Train Step...
At time: 719.1709222793579 and batch: 50, loss is 3.7877363204956054 and perplexity is 44.156331274545636
At time: 720.3361892700195 and batch: 100, loss is 3.773944687843323 and perplexity is 43.55152360357766
At time: 721.501394033432 and batch: 150, loss is 3.738836841583252 and perplexity is 42.04905200034489
At time: 722.662755727768 and batch: 200, loss is 3.7429493618011476 and perplexity is 42.22233564886741
At time: 723.8237602710724 and batch: 250, loss is 3.7408009815216063 and perplexity is 42.13172338525535
At time: 724.9848952293396 and batch: 300, loss is 3.7397192478179933 and perplexity is 42.08617272136414
At time: 726.147604227066 and batch: 350, loss is 3.7579856443405153 and perplexity is 42.86199964973308
At time: 727.3087847232819 and batch: 400, loss is 3.7421214389801025 and perplexity is 42.18739328041398
At time: 728.4697079658508 and batch: 450, loss is 3.7780271196365356 and perplexity is 43.72968314282586
At time: 729.6313087940216 and batch: 500, loss is 3.7848710346221925 and perplexity is 44.02999184804571
At time: 730.7919411659241 and batch: 550, loss is 3.7499124956130983 and perplexity is 42.51736138163956
At time: 731.9535751342773 and batch: 600, loss is 3.7223502159118653 and perplexity is 41.3614883958159
At time: 733.1258428096771 and batch: 650, loss is 3.734359173774719 and perplexity is 41.86119121679139
At time: 734.2870261669159 and batch: 700, loss is 3.7651046752929687 and perplexity is 43.16822426989533
At time: 735.4491279125214 and batch: 750, loss is 3.725532627105713 and perplexity is 41.493327331063405
At time: 736.6095592975616 and batch: 800, loss is 3.6892998027801513 and perplexity is 40.01681748100383
At time: 737.7713923454285 and batch: 850, loss is 3.681273317337036 and perplexity is 39.69690866722565
At time: 738.9323585033417 and batch: 900, loss is 3.6404575872421265 and perplexity is 38.10927105247234
At time: 740.0935981273651 and batch: 950, loss is 3.7579600858688353 and perplexity is 42.86090417652825
At time: 741.2556247711182 and batch: 1000, loss is 3.728829951286316 and perplexity is 41.63037009565184
At time: 742.4283404350281 and batch: 1050, loss is 3.671346163749695 and perplexity is 39.304780934349225
At time: 743.5897779464722 and batch: 1100, loss is 3.704512152671814 and perplexity is 40.630221136372406
At time: 744.7758939266205 and batch: 1150, loss is 3.6688405227661134 and perplexity is 39.206420543763144
At time: 745.936853647232 and batch: 1200, loss is 3.713772554397583 and perplexity is 41.00822081948331
At time: 747.0972926616669 and batch: 1250, loss is 3.6819189167022706 and perplexity is 39.72254524085036
At time: 748.2635064125061 and batch: 1300, loss is 3.687428674697876 and perplexity is 39.942010898226286
At time: 749.4225249290466 and batch: 1350, loss is 3.5532414150238036 and perplexity is 34.92634498348359
At time: 750.5898480415344 and batch: 1400, loss is 3.5993436431884764 and perplexity is 36.574220824824394
At time: 751.7491633892059 and batch: 1450, loss is 3.511191110610962 and perplexity is 33.48813210731684
At time: 752.9090039730072 and batch: 1500, loss is 3.49445586681366 and perplexity is 32.93236348492113
At time: 754.0686571598053 and batch: 1550, loss is 3.510234889984131 and perplexity is 33.456125369831874
At time: 755.2279133796692 and batch: 1600, loss is 3.6020101070404054 and perplexity is 36.67187480010358
At time: 756.3863627910614 and batch: 1650, loss is 3.5450941514968872 and perplexity is 34.64294687402417
At time: 757.546275138855 and batch: 1700, loss is 3.5769839668273926 and perplexity is 35.7655080549844
At time: 758.7049298286438 and batch: 1750, loss is 3.5685480356216432 and perplexity is 35.46506174346944
At time: 759.8638961315155 and batch: 1800, loss is 3.505394196510315 and perplexity is 33.29456586758499
At time: 761.0234224796295 and batch: 1850, loss is 3.530940613746643 and perplexity is 34.15608018817916
At time: 762.1831896305084 and batch: 1900, loss is 3.6059639692306518 and perplexity is 36.81715736367153
At time: 763.3447735309601 and batch: 1950, loss is 3.5528264570236208 and perplexity is 34.91185502378581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378878713208576 and perplexity of 79.74856224356417
finished 16 epochs...
Completing Train Step...
At time: 766.982488155365 and batch: 50, loss is 3.7870666360855103 and perplexity is 44.12677036722825
At time: 768.1436493396759 and batch: 100, loss is 3.7710222482681273 and perplexity is 43.424432705626664
At time: 769.3072736263275 and batch: 150, loss is 3.7346174240112306 and perplexity is 41.87200327537203
At time: 770.4677803516388 and batch: 200, loss is 3.737903046607971 and perplexity is 42.00980513398679
At time: 771.6280953884125 and batch: 250, loss is 3.735260443687439 and perplexity is 41.8989364557148
At time: 772.7967712879181 and batch: 300, loss is 3.7342230319976806 and perplexity is 41.855492547752455
At time: 773.9871942996979 and batch: 350, loss is 3.7522106409072875 and perplexity is 42.6151848188017
At time: 775.1519854068756 and batch: 400, loss is 3.7359351682662965 and perplexity is 41.92721623742848
At time: 776.3142824172974 and batch: 450, loss is 3.7714949560165407 and perplexity is 43.44496462385317
At time: 777.4775025844574 and batch: 500, loss is 3.7785112619400025 and perplexity is 43.75085965816233
At time: 778.6404898166656 and batch: 550, loss is 3.743224263191223 and perplexity is 42.23394422316302
At time: 779.8048746585846 and batch: 600, loss is 3.7165104150772095 and perplexity is 41.12064945154261
At time: 780.9677431583405 and batch: 650, loss is 3.7290078353881837 and perplexity is 41.63777613533556
At time: 782.1374864578247 and batch: 700, loss is 3.7603102207183836 and perplexity is 42.961751537148885
At time: 783.3034234046936 and batch: 750, loss is 3.7210620927810667 and perplexity is 41.30824400591629
At time: 784.466361284256 and batch: 800, loss is 3.6854095602035524 and perplexity is 39.86144476858046
At time: 785.6297662258148 and batch: 850, loss is 3.6774892234802246 and perplexity is 39.54697569812928
At time: 786.7944388389587 and batch: 900, loss is 3.636812672615051 and perplexity is 37.97061885420293
At time: 787.9587647914886 and batch: 950, loss is 3.7541339206695556 and perplexity is 42.6972246087741
At time: 789.1224210262299 and batch: 1000, loss is 3.725197811126709 and perplexity is 41.47943702752847
At time: 790.2874722480774 and batch: 1050, loss is 3.6677545881271363 and perplexity is 39.163868042423644
At time: 791.451824426651 and batch: 1100, loss is 3.700979166030884 and perplexity is 40.48692838262019
At time: 792.6198689937592 and batch: 1150, loss is 3.665549621582031 and perplexity is 39.07760815864089
At time: 793.7876064777374 and batch: 1200, loss is 3.710670037269592 and perplexity is 40.88118927267368
At time: 794.9521157741547 and batch: 1250, loss is 3.6796758794784545 and perplexity is 39.63354594493179
At time: 796.1232991218567 and batch: 1300, loss is 3.6857019233703614 and perplexity is 39.87310049057546
At time: 797.2879765033722 and batch: 1350, loss is 3.5517535543441774 and perplexity is 34.87441808767219
At time: 798.4531402587891 and batch: 1400, loss is 3.5982230854034425 and perplexity is 36.53326025057877
At time: 799.6196489334106 and batch: 1450, loss is 3.5105689191818237 and perplexity is 33.46730255919694
At time: 800.7822813987732 and batch: 1500, loss is 3.494501838684082 and perplexity is 32.933877482068326
At time: 801.949773311615 and batch: 1550, loss is 3.5107393312454223 and perplexity is 33.473006277266514
At time: 803.1138615608215 and batch: 1600, loss is 3.6030737590789794 and perplexity is 36.71090166631651
At time: 804.2776329517365 and batch: 1650, loss is 3.546343379020691 and perplexity is 34.68625083938601
At time: 805.4417021274567 and batch: 1700, loss is 3.5785985946655274 and perplexity is 35.82330268578892
At time: 806.6056065559387 and batch: 1750, loss is 3.5706097888946533 and perplexity is 35.53825738033999
At time: 807.7704482078552 and batch: 1800, loss is 3.5075242280960084 and perplexity is 33.365559927468
At time: 808.9346575737 and batch: 1850, loss is 3.5330900621414183 and perplexity is 34.22957587921239
At time: 810.0996301174164 and batch: 1900, loss is 3.6075497817993165 and perplexity is 36.87558879296355
At time: 811.2634603977203 and batch: 1950, loss is 3.5537501907348634 and perplexity is 34.94411918064377
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37831662200218 and perplexity of 79.70374887378478
finished 17 epochs...
Completing Train Step...
At time: 814.9225492477417 and batch: 50, loss is 3.7851191568374634 and perplexity is 44.04091802261867
At time: 816.0741901397705 and batch: 100, loss is 3.768240170478821 and perplexity is 43.30379045176438
At time: 817.2271325588226 and batch: 150, loss is 3.731414771080017 and perplexity is 41.73811629255509
At time: 818.3798048496246 and batch: 200, loss is 3.7342861223220827 and perplexity is 41.858133307657624
At time: 819.5323598384857 and batch: 250, loss is 3.731506972312927 and perplexity is 41.74196477575132
At time: 820.6864476203918 and batch: 300, loss is 3.7305874633789062 and perplexity is 41.703600307155334
At time: 821.8407521247864 and batch: 350, loss is 3.74842257976532 and perplexity is 42.45406125874919
At time: 822.9949207305908 and batch: 400, loss is 3.7320146417617797 and perplexity is 41.763161275955596
At time: 824.1487538814545 and batch: 450, loss is 3.7673563051223753 and perplexity is 43.2655326414485
At time: 825.3078517913818 and batch: 500, loss is 3.7745168256759642 and perplexity is 43.57644820737493
At time: 826.4616858959198 and batch: 550, loss is 3.7393097829818727 and perplexity is 42.068943441180764
At time: 827.6157565116882 and batch: 600, loss is 3.712990155220032 and perplexity is 40.97614856952839
At time: 828.7697806358337 and batch: 650, loss is 3.7255628967285155 and perplexity is 41.494583337439856
At time: 829.9233131408691 and batch: 700, loss is 3.757086572647095 and perplexity is 42.82348095725229
At time: 831.0757296085358 and batch: 750, loss is 3.7180112981796265 and perplexity is 41.182413077862066
At time: 832.2529509067535 and batch: 800, loss is 3.682599139213562 and perplexity is 39.74957460227683
At time: 833.4079594612122 and batch: 850, loss is 3.6748003816604613 and perplexity is 39.44078296773417
At time: 834.5636489391327 and batch: 900, loss is 3.634019999504089 and perplexity is 37.86472725705114
At time: 835.7206127643585 and batch: 950, loss is 3.7513410234451294 and perplexity is 42.578142018797465
At time: 836.8756783008575 and batch: 1000, loss is 3.722594118118286 and perplexity is 41.371577784458545
At time: 838.0319139957428 and batch: 1050, loss is 3.6652623891830443 and perplexity is 39.06638541534772
At time: 839.1880133152008 and batch: 1100, loss is 3.698588032722473 and perplexity is 40.390234389793555
At time: 840.3437328338623 and batch: 1150, loss is 3.663419485092163 and perplexity is 38.99445611360981
At time: 841.4996011257172 and batch: 1200, loss is 3.708773980140686 and perplexity is 40.80374964049821
At time: 842.655425786972 and batch: 1250, loss is 3.678315353393555 and perplexity is 39.57966013667254
At time: 843.8100297451019 and batch: 1300, loss is 3.6846723222732543 and perplexity is 39.83206822962054
At time: 844.9640634059906 and batch: 1350, loss is 3.5508468770980834 and perplexity is 34.84281257648539
At time: 846.1207699775696 and batch: 1400, loss is 3.5974175262451173 and perplexity is 36.50384239870127
At time: 847.27468085289 and batch: 1450, loss is 3.5099205684661867 and perplexity is 33.445611042247364
At time: 848.4339029788971 and batch: 1500, loss is 3.494120306968689 and perplexity is 32.92131456002704
At time: 849.5916209220886 and batch: 1550, loss is 3.5106286287307737 and perplexity is 33.46930093639783
At time: 850.7448933124542 and batch: 1600, loss is 3.6032321071624756 and perplexity is 36.71671522750977
At time: 851.8993992805481 and batch: 1650, loss is 3.5465237283706665 and perplexity is 34.69250704631245
At time: 853.0534040927887 and batch: 1700, loss is 3.5789188814163206 and perplexity is 35.83477825264674
At time: 854.2076423168182 and batch: 1750, loss is 3.571257004737854 and perplexity is 35.561265748443304
At time: 855.3615152835846 and batch: 1800, loss is 3.5082636976242068 and perplexity is 33.39024186697201
At time: 856.5158975124359 and batch: 1850, loss is 3.533838891983032 and perplexity is 34.25521760654363
At time: 857.676017999649 and batch: 1900, loss is 3.6079984664916993 and perplexity is 36.8921380175918
At time: 858.8297619819641 and batch: 1950, loss is 3.553772473335266 and perplexity is 34.94489783516308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378035008630087 and perplexity of 79.68130639249573
finished 18 epochs...
Completing Train Step...
At time: 862.4510974884033 and batch: 50, loss is 3.7830512428283694 and perplexity is 43.94993929178314
At time: 863.6298537254333 and batch: 100, loss is 3.7656844234466553 and perplexity is 43.19325822420696
At time: 864.7937388420105 and batch: 150, loss is 3.7287022781372072 and perplexity is 41.625055354485255
At time: 865.9506542682648 and batch: 200, loss is 3.7313963556289673 and perplexity is 41.737347673394844
At time: 867.1059989929199 and batch: 250, loss is 3.7284913301467895 and perplexity is 41.61627555877988
At time: 868.2609038352966 and batch: 300, loss is 3.7276393699645998 and perplexity is 41.580835248083204
At time: 869.4147391319275 and batch: 350, loss is 3.745391116142273 and perplexity is 42.32555819098984
At time: 870.5711035728455 and batch: 400, loss is 3.7289017915725706 and perplexity is 41.633360940786694
At time: 871.7244458198547 and batch: 450, loss is 3.764142689704895 and perplexity is 43.12671702817009
At time: 872.8815567493439 and batch: 500, loss is 3.771407208442688 and perplexity is 43.441152600861635
At time: 874.035740852356 and batch: 550, loss is 3.7363258504867556 and perplexity is 41.943599655512486
At time: 875.196786403656 and batch: 600, loss is 3.7102771329879762 and perplexity is 40.86513003344941
At time: 876.3512749671936 and batch: 650, loss is 3.7228538370132447 and perplexity is 41.38232416038145
At time: 877.5066046714783 and batch: 700, loss is 3.7545244455337525 and perplexity is 42.71390219290971
At time: 878.6609313488007 and batch: 750, loss is 3.7155631732940675 and perplexity is 41.08171669650942
At time: 879.815687417984 and batch: 800, loss is 3.680291314125061 and perplexity is 39.657945309611236
At time: 880.9781804084778 and batch: 850, loss is 3.6726261663436888 and perplexity is 39.35512336825109
At time: 882.1325986385345 and batch: 900, loss is 3.631741704940796 and perplexity is 37.778558451034456
At time: 883.287168264389 and batch: 950, loss is 3.749101791381836 and perplexity is 42.48290634517439
At time: 884.4405205249786 and batch: 1000, loss is 3.7204894542694094 and perplexity is 41.28459608605059
At time: 885.5957698822021 and batch: 1050, loss is 3.6632557487487794 and perplexity is 38.98807182663769
At time: 886.7504391670227 and batch: 1100, loss is 3.6966714334487913 and perplexity is 40.31289663231721
At time: 887.9042520523071 and batch: 1150, loss is 3.6616946935653685 and perplexity is 38.927256775197144
At time: 889.0997531414032 and batch: 1200, loss is 3.7072303533554076 and perplexity is 40.74081246786322
At time: 890.2543725967407 and batch: 1250, loss is 3.6771347761154174 and perplexity is 39.53296086071481
At time: 891.4084956645966 and batch: 1300, loss is 3.6837157440185546 and perplexity is 39.7939839575097
At time: 892.5668404102325 and batch: 1350, loss is 3.5499705266952515 and perplexity is 34.812291439206994
At time: 893.7218749523163 and batch: 1400, loss is 3.5965833139419554 and perplexity is 36.47340314242589
At time: 894.8811900615692 and batch: 1450, loss is 3.5091616106033325 and perplexity is 33.42023686295333
At time: 896.0398743152618 and batch: 1500, loss is 3.493514347076416 and perplexity is 32.90137160672791
At time: 897.2026047706604 and batch: 1550, loss is 3.5102006292343138 and perplexity is 33.454979157525884
At time: 898.3610565662384 and batch: 1600, loss is 3.602975959777832 and perplexity is 36.70731154134777
At time: 899.5180823802948 and batch: 1650, loss is 3.5462813234329222 and perplexity is 34.684098430487865
At time: 900.6746244430542 and batch: 1700, loss is 3.578764352798462 and perplexity is 35.829241181721066
At time: 901.8302228450775 and batch: 1750, loss is 3.5713314247131347 and perplexity is 35.56391231543876
At time: 902.9867923259735 and batch: 1800, loss is 3.508469796180725 and perplexity is 33.39712425682354
At time: 904.1436567306519 and batch: 1850, loss is 3.5340655183792116 and perplexity is 34.262981622792424
At time: 905.3003666400909 and batch: 1900, loss is 3.6080654954910276 and perplexity is 36.894610943564146
At time: 906.4577510356903 and batch: 1950, loss is 3.5535444974899293 and perplexity is 34.93693215056525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377905557321948 and perplexity of 79.67099221075551
finished 19 epochs...
Completing Train Step...
At time: 910.0970048904419 and batch: 50, loss is 3.78106258392334 and perplexity is 43.86262470187911
At time: 911.2737431526184 and batch: 100, loss is 3.7633346128463745 and perplexity is 43.09188140298255
At time: 912.4322907924652 and batch: 150, loss is 3.7262850427627563 and perplexity is 41.52455930845107
At time: 913.5904514789581 and batch: 200, loss is 3.728869595527649 and perplexity is 41.63202053280564
At time: 914.7472836971283 and batch: 250, loss is 3.7258758449554445 and perplexity is 41.5075710258535
At time: 915.9012725353241 and batch: 300, loss is 3.7250503587722776 and perplexity is 41.47332123778315
At time: 917.0613811016083 and batch: 350, loss is 3.742748475074768 and perplexity is 42.21385459397302
At time: 918.2484982013702 and batch: 400, loss is 3.726191759109497 and perplexity is 41.520685926523214
At time: 919.4065358638763 and batch: 450, loss is 3.76139102935791 and perplexity is 43.0082100712494
At time: 920.5599975585938 and batch: 500, loss is 3.7687697505950926 and perplexity is 43.32672935160334
At time: 921.7126421928406 and batch: 550, loss is 3.733784809112549 and perplexity is 41.83715453141225
At time: 922.8635265827179 and batch: 600, loss is 3.7079492378234864 and perplexity is 40.77011093500799
At time: 924.014228105545 and batch: 650, loss is 3.720519642829895 and perplexity is 41.28584242738919
At time: 925.1666662693024 and batch: 700, loss is 3.75231276512146 and perplexity is 42.61953708329514
At time: 926.3176536560059 and batch: 750, loss is 3.7134375858306883 and perplexity is 40.99448665490964
At time: 927.4695093631744 and batch: 800, loss is 3.6782634544372557 and perplexity is 39.57760604692378
At time: 928.621675491333 and batch: 850, loss is 3.6707335567474364 and perplexity is 39.28070992411411
At time: 929.7761924266815 and batch: 900, loss is 3.6297707605361937 and perplexity is 37.70417234216414
At time: 930.9324905872345 and batch: 950, loss is 3.747165117263794 and perplexity is 42.40071041904893
At time: 932.0856983661652 and batch: 1000, loss is 3.7186506462097166 and perplexity is 41.20875139131498
At time: 933.2427544593811 and batch: 1050, loss is 3.6614985704421996 and perplexity is 38.9196229886275
At time: 934.3989038467407 and batch: 1100, loss is 3.6949875116348267 and perplexity is 40.24506998970288
At time: 935.5518381595612 and batch: 1150, loss is 3.6601477432250977 and perplexity is 38.867084795614666
At time: 936.7039251327515 and batch: 1200, loss is 3.705825457572937 and perplexity is 40.683616059156904
At time: 937.8596804141998 and batch: 1250, loss is 3.6759970426559447 and perplexity is 39.48800846516281
At time: 939.012371301651 and batch: 1300, loss is 3.6827456665039064 and perplexity is 39.75539942647307
At time: 940.1656510829926 and batch: 1350, loss is 3.549057421684265 and perplexity is 34.78051866959509
At time: 941.318701505661 and batch: 1400, loss is 3.5957046699523927 and perplexity is 36.441370080865234
At time: 942.472692489624 and batch: 1450, loss is 3.5083416271209718 and perplexity is 33.392844053109776
At time: 943.624941110611 and batch: 1500, loss is 3.4927975654602053 and perplexity is 32.87779695835872
At time: 944.7805845737457 and batch: 1550, loss is 3.5095767307281496 and perplexity is 33.43411315581624
At time: 945.9360427856445 and batch: 1600, loss is 3.6024923849105837 and perplexity is 36.68956509925463
At time: 947.0890491008759 and batch: 1650, loss is 3.545830864906311 and perplexity is 34.66847820100894
At time: 948.2419519424438 and batch: 1700, loss is 3.578395714759827 and perplexity is 35.81603559471644
At time: 949.397686958313 and batch: 1750, loss is 3.571133923530579 and perplexity is 35.55688909427022
At time: 950.5504624843597 and batch: 1800, loss is 3.5084292888641357 and perplexity is 33.395771456337435
At time: 951.7056932449341 and batch: 1850, loss is 3.5340469312667846 and perplexity is 34.26234477881948
At time: 952.8620510101318 and batch: 1900, loss is 3.6079637718200686 and perplexity is 36.89085807918117
At time: 954.0189089775085 and batch: 1950, loss is 3.5532368421554565 and perplexity is 34.926185270271304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37789193086846 and perplexity of 79.66990658508242
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fad68d45b38>
ELAPSED
2951.573326587677


RESULTS SO FAR:
[{'best_accuracy': -79.15217303895258, 'params': {'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.54003238615967, 'params': {'num_layers': 2, 'dropout': 0.532313874403636, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.08424698132469677, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.66990658508242, 'params': {'num_layers': 2, 'dropout': 0.5310812723449767, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.5433392138601495, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'dropout': 0.10281409912265316, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.34256577207194716, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.683588981628418 and batch: 50, loss is 7.414550142288208 and perplexity is 1659.9622535856086
At time: 2.9056410789489746 and batch: 100, loss is 6.518637771606445 and perplexity is 677.654635917374
At time: 4.126864433288574 and batch: 150, loss is 6.155906038284302 and perplexity is 471.49384046362087
At time: 5.348757743835449 and batch: 200, loss is 5.973302659988403 and perplexity is 392.80081840283117
At time: 6.569764137268066 and batch: 250, loss is 5.861949310302735 and perplexity is 351.40848098311983
At time: 7.792182445526123 and batch: 300, loss is 5.7761022567749025 and perplexity is 322.4997163739765
At time: 9.014072179794312 and batch: 350, loss is 5.705567779541016 and perplexity is 300.5360698471176
At time: 10.236848592758179 and batch: 400, loss is 5.635603904724121 and perplexity is 280.2280972927501
At time: 11.458876848220825 and batch: 450, loss is 5.558871421813965 and perplexity is 259.52977134212136
At time: 12.72003698348999 and batch: 500, loss is 5.525624542236328 and perplexity is 251.04307607512908
At time: 13.941080093383789 and batch: 550, loss is 5.471458740234375 and perplexity is 237.8068382698157
At time: 15.16324782371521 and batch: 600, loss is 5.477460269927978 and perplexity is 239.2383343574964
At time: 16.384655714035034 and batch: 650, loss is 5.544498176574707 and perplexity is 255.8261664628122
At time: 17.60410189628601 and batch: 700, loss is 5.460958833694458 and perplexity is 235.32295180157433
At time: 18.825901746749878 and batch: 750, loss is 5.403816404342652 and perplexity is 222.25300705142732
At time: 20.047902822494507 and batch: 800, loss is 5.386940813064575 and perplexity is 218.53382609661867
At time: 21.270562648773193 and batch: 850, loss is 5.389272003173828 and perplexity is 219.04386425752918
At time: 22.4939022064209 and batch: 900, loss is 5.393493566513062 and perplexity is 219.97052640983156
At time: 23.716687440872192 and batch: 950, loss is 5.432485704421997 and perplexity is 228.71706243248866
At time: 24.94035267829895 and batch: 1000, loss is 5.387957944869995 and perplexity is 218.75621688289962
At time: 26.163912773132324 and batch: 1050, loss is 5.282350358963012 and perplexity is 196.83195786556684
At time: 27.38655185699463 and batch: 1100, loss is 5.366734714508056 and perplexity is 214.16242329749278
At time: 28.608713388442993 and batch: 1150, loss is 5.278686685562134 and perplexity is 196.11214923409625
At time: 29.831413984298706 and batch: 1200, loss is 5.346338758468628 and perplexity is 209.838619867975
At time: 31.05416250228882 and batch: 1250, loss is 5.284121160507202 and perplexity is 197.18081698947782
At time: 32.27846646308899 and batch: 1300, loss is 5.308256092071534 and perplexity is 201.9976557370094
At time: 33.503674268722534 and batch: 1350, loss is 5.244375944137573 and perplexity is 189.49752128327128
At time: 34.73094034194946 and batch: 1400, loss is 5.255108232498169 and perplexity is 191.54221582505218
At time: 35.953742027282715 and batch: 1450, loss is 5.201333980560303 and perplexity is 181.5142168810292
At time: 37.17931628227234 and batch: 1500, loss is 5.175101795196533 and perplexity is 176.81461223856653
At time: 38.40057301521301 and batch: 1550, loss is 5.164378147125245 and perplexity is 174.92864486156066
At time: 39.62400794029236 and batch: 1600, loss is 5.202941408157349 and perplexity is 181.8062224685456
At time: 40.84976315498352 and batch: 1650, loss is 5.175536394119263 and perplexity is 176.8914723790256
At time: 42.07682728767395 and batch: 1700, loss is 5.194701299667359 and perplexity is 180.31427481835047
At time: 43.30468130111694 and batch: 1750, loss is 5.199716091156006 and perplexity is 181.22078438747573
At time: 44.528000354766846 and batch: 1800, loss is 5.172215347290039 and perplexity is 176.30498193572876
At time: 45.755592823028564 and batch: 1850, loss is 5.153323402404785 and perplexity is 173.0055028554288
At time: 46.9790678024292 and batch: 1900, loss is 5.19689395904541 and perplexity is 180.71007637444802
At time: 48.20287370681763 and batch: 1950, loss is 5.116002893447876 and perplexity is 166.6678472864805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.827762763444768 and perplexity of 124.9311472375862
finished 1 epochs...
Completing Train Step...
At time: 51.82505249977112 and batch: 50, loss is 5.042368221282959 and perplexity is 154.836267715585
At time: 53.00480675697327 and batch: 100, loss is 4.980081558227539 and perplexity is 145.48624677017236
At time: 54.15562057495117 and batch: 150, loss is 4.912072420120239 and perplexity is 135.9208077418721
At time: 55.30686569213867 and batch: 200, loss is 4.882035093307495 and perplexity is 131.89881733506158
At time: 56.462642431259155 and batch: 250, loss is 4.885900020599365 and perplexity is 132.40958307436432
At time: 57.6176016330719 and batch: 300, loss is 4.904426221847534 and perplexity is 134.88549344974393
At time: 58.77259969711304 and batch: 350, loss is 4.901434335708618 and perplexity is 134.48253451576198
At time: 59.92384076118469 and batch: 400, loss is 4.868397922515869 and perplexity is 130.11229984474897
At time: 61.07379198074341 and batch: 450, loss is 4.848580226898194 and perplexity is 127.55915616230942
At time: 62.22440695762634 and batch: 500, loss is 4.844496908187867 and perplexity is 127.03935345558101
At time: 63.37583589553833 and batch: 550, loss is 4.800638246536255 and perplexity is 121.58799587626055
At time: 64.52688789367676 and batch: 600, loss is 4.773606615066528 and perplexity is 118.34529912562056
At time: 65.6778838634491 and batch: 650, loss is 4.830848808288574 and perplexity is 125.31728587446948
At time: 66.82789635658264 and batch: 700, loss is 4.842081928253174 and perplexity is 126.73292612292632
At time: 67.97768640518188 and batch: 750, loss is 4.802672414779663 and perplexity is 121.83557804277082
At time: 69.12788414955139 and batch: 800, loss is 4.776804704666137 and perplexity is 118.7243838462686
At time: 70.27841401100159 and batch: 850, loss is 4.775670261383056 and perplexity is 118.58977413445444
At time: 71.42955183982849 and batch: 900, loss is 4.7674901485443115 and perplexity is 117.62365327659464
At time: 72.58286094665527 and batch: 950, loss is 4.8454646873474125 and perplexity is 127.16235900580097
At time: 73.74438166618347 and batch: 1000, loss is 4.817290477752685 and perplexity is 123.62965924328543
At time: 74.9119782447815 and batch: 1050, loss is 4.733389301300049 and perplexity is 113.68020661486138
At time: 76.07255387306213 and batch: 1100, loss is 4.8002039813995365 and perplexity is 121.53520591185823
At time: 77.23367524147034 and batch: 1150, loss is 4.724549522399903 and perplexity is 112.67972724619032
At time: 78.39516544342041 and batch: 1200, loss is 4.804153289794922 and perplexity is 122.01613496438432
At time: 79.55969071388245 and batch: 1250, loss is 4.758429765701294 and perplexity is 116.56275129307038
At time: 80.72241115570068 and batch: 1300, loss is 4.781065902709961 and perplexity is 119.23137137846037
At time: 81.88394498825073 and batch: 1350, loss is 4.67178786277771 and perplexity is 106.8886739834594
At time: 83.04655265808105 and batch: 1400, loss is 4.694819746017456 and perplexity is 109.37909084802831
At time: 84.2088234424591 and batch: 1450, loss is 4.631558055877686 and perplexity is 102.6739112436727
At time: 85.37115049362183 and batch: 1500, loss is 4.620518846511841 and perplexity is 101.54670561763481
At time: 86.53305196762085 and batch: 1550, loss is 4.615343189239502 and perplexity is 101.02249241634966
At time: 87.69584012031555 and batch: 1600, loss is 4.694153604507446 and perplexity is 109.30625315808514
At time: 88.85827350616455 and batch: 1650, loss is 4.648215293884277 and perplexity is 104.3984985754876
At time: 90.02003407478333 and batch: 1700, loss is 4.676282587051392 and perplexity is 107.37019043217508
At time: 91.17897152900696 and batch: 1750, loss is 4.679649801254272 and perplexity is 107.73233823480331
At time: 92.34425520896912 and batch: 1800, loss is 4.635375738143921 and perplexity is 103.06663678751691
At time: 93.5074028968811 and batch: 1850, loss is 4.654253015518188 and perplexity is 105.03073436009173
At time: 94.66958999633789 and batch: 1900, loss is 4.738559970855713 and perplexity is 114.26953168788616
At time: 95.83214712142944 and batch: 1950, loss is 4.656919898986817 and perplexity is 105.31121292484187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.592087004905523 and perplexity of 98.70020317081195
finished 2 epochs...
Completing Train Step...
At time: 99.45666122436523 and batch: 50, loss is 4.614951419830322 and perplexity is 100.9829226458008
At time: 100.63505792617798 and batch: 100, loss is 4.566816701889038 and perplexity is 96.23726973135314
At time: 101.78682827949524 and batch: 150, loss is 4.515178995132446 and perplexity is 91.39392362584309
At time: 102.93681263923645 and batch: 200, loss is 4.506811618804932 and perplexity is 90.63238674875387
At time: 104.09347152709961 and batch: 250, loss is 4.500177564620972 and perplexity is 90.03311657749
At time: 105.24590563774109 and batch: 300, loss is 4.5267724609375 and perplexity is 92.45966181683478
At time: 106.39683628082275 and batch: 350, loss is 4.540405702590943 and perplexity is 93.72881843137228
At time: 107.5478618144989 and batch: 400, loss is 4.507365808486939 and perplexity is 90.68262820270753
At time: 108.70046424865723 and batch: 450, loss is 4.512113513946534 and perplexity is 91.11418625634462
At time: 109.8536787033081 and batch: 500, loss is 4.515433216094971 and perplexity is 91.4171608306433
At time: 111.0278377532959 and batch: 550, loss is 4.474813175201416 and perplexity is 87.77819973329075
At time: 112.18004775047302 and batch: 600, loss is 4.450369853973388 and perplexity is 85.65861932492979
At time: 113.33179950714111 and batch: 650, loss is 4.503577032089233 and perplexity is 90.33970204677446
At time: 114.48388004302979 and batch: 700, loss is 4.536553039550781 and perplexity is 93.36840759335959
At time: 115.63456320762634 and batch: 750, loss is 4.499904909133911 and perplexity is 90.00857190051045
At time: 116.79202079772949 and batch: 800, loss is 4.468819999694825 and perplexity is 87.25370284749343
At time: 117.94576096534729 and batch: 850, loss is 4.462414798736572 and perplexity is 86.69661139239395
At time: 119.10688328742981 and batch: 900, loss is 4.451024961471558 and perplexity is 85.71475331362328
At time: 120.26656651496887 and batch: 950, loss is 4.540626850128174 and perplexity is 93.74954862086665
At time: 121.42690348625183 and batch: 1000, loss is 4.518588056564331 and perplexity is 91.706022806364
At time: 122.5788516998291 and batch: 1050, loss is 4.446790657043457 and perplexity is 85.35257827492849
At time: 123.73690795898438 and batch: 1100, loss is 4.510001735687256 and perplexity is 90.92197632250819
At time: 124.89590954780579 and batch: 1150, loss is 4.447156810760498 and perplexity is 85.38383616096928
At time: 126.05295467376709 and batch: 1200, loss is 4.524029006958008 and perplexity is 92.20635062236288
At time: 127.2038049697876 and batch: 1250, loss is 4.484905395507813 and perplexity is 88.66856197187751
At time: 128.35345911979675 and batch: 1300, loss is 4.495890846252442 and perplexity is 89.64799600434506
At time: 129.50558042526245 and batch: 1350, loss is 4.378576860427857 and perplexity is 79.72449355107621
At time: 130.66465497016907 and batch: 1400, loss is 4.410645160675049 and perplexity is 82.32255765209848
At time: 131.81596875190735 and batch: 1450, loss is 4.343230981826782 and perplexity is 76.95578081977804
At time: 132.97285342216492 and batch: 1500, loss is 4.340750074386596 and perplexity is 76.76509728248335
At time: 134.12585139274597 and batch: 1550, loss is 4.337286062240601 and perplexity is 76.49964208855774
At time: 135.27667260169983 and batch: 1600, loss is 4.428015050888061 and perplexity is 83.76498255531781
At time: 136.42781972885132 and batch: 1650, loss is 4.380586767196656 and perplexity is 79.88489349076819
At time: 137.57918167114258 and batch: 1700, loss is 4.410590686798096 and perplexity is 82.31807334536236
At time: 138.7308328151703 and batch: 1750, loss is 4.417986459732056 and perplexity is 82.9291359791345
At time: 139.88182401657104 and batch: 1800, loss is 4.367402296066285 and perplexity is 78.838566211592
At time: 141.0337109565735 and batch: 1850, loss is 4.405165767669677 and perplexity is 81.87271356728108
At time: 142.19376754760742 and batch: 1900, loss is 4.490755844116211 and perplexity is 89.18883326312506
At time: 143.34745931625366 and batch: 1950, loss is 4.412689123153687 and perplexity is 82.4909939511817
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5179099859193315 and perplexity of 91.64386072185344
finished 3 epochs...
Completing Train Step...
At time: 146.96564888954163 and batch: 50, loss is 4.376563310623169 and perplexity is 79.56412582104602
At time: 148.11888527870178 and batch: 100, loss is 4.333330116271973 and perplexity is 76.19761144018474
At time: 149.27207398414612 and batch: 150, loss is 4.287223253250122 and perplexity is 72.76414013269543
At time: 150.4260549545288 and batch: 200, loss is 4.2887060165405275 and perplexity is 72.87211215723714
At time: 151.58120012283325 and batch: 250, loss is 4.280995817184448 and perplexity is 72.31241410947285
At time: 152.73585772514343 and batch: 300, loss is 4.302347173690796 and perplexity is 73.87298308966294
At time: 153.8962197303772 and batch: 350, loss is 4.315655107498169 and perplexity is 74.86265046685804
At time: 155.05573964118958 and batch: 400, loss is 4.2861402893066405 and perplexity is 72.68538184644278
At time: 156.21978282928467 and batch: 450, loss is 4.303058109283447 and perplexity is 73.92552069589097
At time: 157.3836052417755 and batch: 500, loss is 4.309767894744873 and perplexity is 74.42321291667366
At time: 158.54863333702087 and batch: 550, loss is 4.278093633651733 and perplexity is 72.10285444941836
At time: 159.71287846565247 and batch: 600, loss is 4.250734353065491 and perplexity is 70.15691337880814
At time: 160.87680459022522 and batch: 650, loss is 4.305322847366333 and perplexity is 74.09313236453211
At time: 162.04091572761536 and batch: 700, loss is 4.338042182922363 and perplexity is 76.55750692373076
At time: 163.2141137123108 and batch: 750, loss is 4.304256582260132 and perplexity is 74.01417154694599
At time: 164.37810802459717 and batch: 800, loss is 4.273182654380799 and perplexity is 71.7496268823918
At time: 165.54044699668884 and batch: 850, loss is 4.262966156005859 and perplexity is 71.02032871618569
At time: 166.70316100120544 and batch: 900, loss is 4.254017934799195 and perplexity is 70.38765796510395
At time: 167.8979368209839 and batch: 950, loss is 4.346536722183227 and perplexity is 77.21059759709651
At time: 169.06858897209167 and batch: 1000, loss is 4.3270383548736575 and perplexity is 75.71969928108074
At time: 170.23657536506653 and batch: 1050, loss is 4.264874286651612 and perplexity is 71.15597415533348
At time: 171.40031957626343 and batch: 1100, loss is 4.3165310192108155 and perplexity is 74.92825226573946
At time: 172.56492710113525 and batch: 1150, loss is 4.265558867454529 and perplexity is 71.20470284671339
At time: 173.72878170013428 and batch: 1200, loss is 4.33317494392395 and perplexity is 76.1857885952169
At time: 174.89301204681396 and batch: 1250, loss is 4.304094586372376 and perplexity is 74.00218252663188
At time: 176.0571517944336 and batch: 1300, loss is 4.304099283218384 and perplexity is 74.00253010430374
At time: 177.2213351726532 and batch: 1350, loss is 4.1912291145324705 and perplexity is 66.10399042375134
At time: 178.38500094413757 and batch: 1400, loss is 4.223340702056885 and perplexity is 68.26114395014186
At time: 179.54888701438904 and batch: 1450, loss is 4.152933812141418 and perplexity is 63.620377001812145
At time: 180.71539664268494 and batch: 1500, loss is 4.155210523605347 and perplexity is 63.76538725408616
At time: 181.88159799575806 and batch: 1550, loss is 4.154797530174255 and perplexity is 63.73905800529682
At time: 183.04616737365723 and batch: 1600, loss is 4.246098413467407 and perplexity is 69.83242290627187
At time: 184.21035885810852 and batch: 1650, loss is 4.201610398292542 and perplexity is 66.79380911259322
At time: 185.37384295463562 and batch: 1700, loss is 4.231885070800781 and perplexity is 68.84689119154687
At time: 186.53757405281067 and batch: 1750, loss is 4.242315654754639 and perplexity is 69.56876269596687
At time: 187.7021279335022 and batch: 1800, loss is 4.191243510246277 and perplexity is 66.10494204472859
At time: 188.8663718700409 and batch: 1850, loss is 4.231819105148316 and perplexity is 68.84234981123838
At time: 190.03076124191284 and batch: 1900, loss is 4.318854007720947 and perplexity is 75.10251205822209
At time: 191.19555282592773 and batch: 1950, loss is 4.242855701446533 and perplexity is 69.60634322282627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485930970657703 and perplexity of 88.75954489254897
finished 4 epochs...
Completing Train Step...
At time: 194.86010885238647 and batch: 50, loss is 4.204831686019897 and perplexity is 67.00931811204259
At time: 196.01455760002136 and batch: 100, loss is 4.170291132926941 and perplexity is 64.73429564924804
At time: 197.19089460372925 and batch: 150, loss is 4.1256671905517575 and perplexity is 61.90910064123888
At time: 198.34389114379883 and batch: 200, loss is 4.128819932937622 and perplexity is 62.10459209206428
At time: 199.49693083763123 and batch: 250, loss is 4.118634767532349 and perplexity is 61.47525693100186
At time: 200.6496946811676 and batch: 300, loss is 4.139376225471497 and perplexity is 62.763658864444785
At time: 201.80111742019653 and batch: 350, loss is 4.152209625244141 and perplexity is 63.57432063710837
At time: 202.95617747306824 and batch: 400, loss is 4.124677724838257 and perplexity is 61.84787400462486
At time: 204.10822796821594 and batch: 450, loss is 4.14889844417572 and perplexity is 63.364162677718205
At time: 205.26091361045837 and batch: 500, loss is 4.165220489501953 and perplexity is 64.40688191930394
At time: 206.41388368606567 and batch: 550, loss is 4.125897979736328 and perplexity is 61.92339024097246
At time: 207.56591773033142 and batch: 600, loss is 4.105629534721374 and perplexity is 60.6809332802035
At time: 208.71818685531616 and batch: 650, loss is 4.1529002857208255 and perplexity is 63.618244074049436
At time: 209.87156510353088 and batch: 700, loss is 4.189383025169373 and perplexity is 65.98206912360551
At time: 211.02484679222107 and batch: 750, loss is 4.155984234809876 and perplexity is 63.814742339494934
At time: 212.17927885055542 and batch: 800, loss is 4.1299396324157716 and perplexity is 62.17416951705441
At time: 213.33189916610718 and batch: 850, loss is 4.118666977882385 and perplexity is 61.477237102437
At time: 214.48486375808716 and batch: 900, loss is 4.101524481773376 and perplexity is 60.4323454184107
At time: 215.63811492919922 and batch: 950, loss is 4.202725639343262 and perplexity is 66.86834186371631
At time: 216.79132676124573 and batch: 1000, loss is 4.179411845207214 and perplexity is 65.32741927781741
At time: 217.94517278671265 and batch: 1050, loss is 4.121882224082947 and perplexity is 61.6752196662359
At time: 219.0997977256775 and batch: 1100, loss is 4.171583724021912 and perplexity is 64.81802472541476
At time: 220.25820326805115 and batch: 1150, loss is 4.123066048622132 and perplexity is 61.748275538871816
At time: 221.4126033782959 and batch: 1200, loss is 4.193324627876282 and perplexity is 66.24265745632945
At time: 222.56689310073853 and batch: 1250, loss is 4.164701628684997 and perplexity is 64.37347238013363
At time: 223.7209107875824 and batch: 1300, loss is 4.161413269042969 and perplexity is 64.16213691548428
At time: 224.87838506698608 and batch: 1350, loss is 4.045792436599731 and perplexity is 57.15646096459917
At time: 226.03541803359985 and batch: 1400, loss is 4.085162110328675 and perplexity is 59.45157468441188
At time: 227.18990850448608 and batch: 1450, loss is 4.013516449928284 and perplexity is 55.34113312961706
At time: 228.34461379051208 and batch: 1500, loss is 4.017435545921326 and perplexity is 55.55844589937048
At time: 229.49899578094482 and batch: 1550, loss is 4.01443657875061 and perplexity is 55.39207753538356
At time: 230.65580248832703 and batch: 1600, loss is 4.110482831001281 and perplexity is 60.97615163956007
At time: 231.81154203414917 and batch: 1650, loss is 4.067703328132629 and perplexity is 58.42263078036179
At time: 232.96542596817017 and batch: 1700, loss is 4.099559006690979 and perplexity is 60.313683800746404
At time: 234.11831283569336 and batch: 1750, loss is 4.106104798316956 and perplexity is 60.70977957299093
At time: 235.272953748703 and batch: 1800, loss is 4.058025670051575 and perplexity is 57.85996357734894
At time: 236.4271047115326 and batch: 1850, loss is 4.099362707138061 and perplexity is 60.30184541355459
At time: 237.58624148368835 and batch: 1900, loss is 4.181907534599304 and perplexity is 65.49065983926226
At time: 238.73999857902527 and batch: 1950, loss is 4.1106241512298585 and perplexity is 60.98476941216598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4830506790515985 and perplexity of 88.50425934533176
finished 5 epochs...
Completing Train Step...
At time: 242.3832085132599 and batch: 50, loss is 4.0740776014328 and perplexity is 58.79622201723484
At time: 243.54285717010498 and batch: 100, loss is 4.0392287063598635 and perplexity is 56.78252990714787
At time: 244.7036783695221 and batch: 150, loss is 4.002938137054444 and perplexity is 54.75880277517628
At time: 245.85896062850952 and batch: 200, loss is 4.004847240447998 and perplexity is 54.863442843954964
At time: 247.01492071151733 and batch: 250, loss is 3.9925622940063477 and perplexity is 54.19357147865776
At time: 248.1686131954193 and batch: 300, loss is 4.011275610923767 and perplexity is 55.2172614000813
At time: 249.32402992248535 and batch: 350, loss is 4.021280436515808 and perplexity is 55.772473237635914
At time: 250.47886776924133 and batch: 400, loss is 3.998103551864624 and perplexity is 54.49470559283018
At time: 251.63686347007751 and batch: 450, loss is 4.02555016040802 and perplexity is 56.01111540467965
At time: 252.7929437160492 and batch: 500, loss is 4.046003384590149 and perplexity is 57.16851927697271
At time: 253.95051312446594 and batch: 550, loss is 4.007215318679809 and perplexity is 54.99351772163301
At time: 255.1400215625763 and batch: 600, loss is 3.9895552968978882 and perplexity is 54.03085633052059
At time: 256.29338908195496 and batch: 650, loss is 4.03410276889801 and perplexity is 56.492210924076616
At time: 257.4476900100708 and batch: 700, loss is 4.067165036201477 and perplexity is 58.39119081231573
At time: 258.601469039917 and batch: 750, loss is 4.040594515800476 and perplexity is 56.86013700874865
At time: 259.7559461593628 and batch: 800, loss is 4.010523376464843 and perplexity is 55.17574069194037
At time: 260.90963435173035 and batch: 850, loss is 3.9994932794570923 and perplexity is 54.570491037200235
At time: 262.06488156318665 and batch: 900, loss is 3.985605640411377 and perplexity is 53.817873888957216
At time: 263.2187159061432 and batch: 950, loss is 4.086349649429321 and perplexity is 59.52221769130905
At time: 264.3737325668335 and batch: 1000, loss is 4.064746284484864 and perplexity is 58.25012768641482
At time: 265.52885913848877 and batch: 1050, loss is 4.011148328781128 and perplexity is 55.21023367600102
At time: 266.688027381897 and batch: 1100, loss is 4.0544376564025875 and perplexity is 57.65273323327585
At time: 267.8435597419739 and batch: 1150, loss is 4.01048743724823 and perplexity is 55.17375775467666
At time: 268.9998769760132 and batch: 1200, loss is 4.083117742538452 and perplexity is 59.330157952564754
At time: 270.1546654701233 and batch: 1250, loss is 4.056137413978576 and perplexity is 57.75081223501475
At time: 271.31000781059265 and batch: 1300, loss is 4.048542051315308 and perplexity is 57.31383547123645
At time: 272.46558904647827 and batch: 1350, loss is 3.9350152683258055 and perplexity is 51.16293112299535
At time: 273.61982107162476 and batch: 1400, loss is 3.9761916160583497 and perplexity is 53.31360842139141
At time: 274.7738502025604 and batch: 1450, loss is 3.8984287357330323 and perplexity is 49.32488575476853
At time: 275.92617750167847 and batch: 1500, loss is 3.906681036949158 and perplexity is 49.73361372307805
At time: 277.08510279655457 and batch: 1550, loss is 3.9062231588363647 and perplexity is 49.71084700247344
At time: 278.248539686203 and batch: 1600, loss is 4.000025091171264 and perplexity is 54.59951998186417
At time: 279.41569781303406 and batch: 1650, loss is 3.9607256698608397 and perplexity is 52.495406464790726
At time: 280.58043789863586 and batch: 1700, loss is 3.990841464996338 and perplexity is 54.10039380311838
At time: 281.7436451911926 and batch: 1750, loss is 3.99611177444458 and perplexity is 54.38627229206629
At time: 282.907066822052 and batch: 1800, loss is 3.9473510551452637 and perplexity is 51.79797496415876
At time: 284.07136607170105 and batch: 1850, loss is 3.9908551740646363 and perplexity is 54.10113547419579
At time: 285.23435139656067 and batch: 1900, loss is 4.073807444572449 and perplexity is 58.78033995991408
At time: 286.399382352829 and batch: 1950, loss is 4.002984843254089 and perplexity is 54.7613604104793
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.467443563771802 and perplexity of 87.13368633294675
finished 6 epochs...
Completing Train Step...
At time: 290.00917291641235 and batch: 50, loss is 3.966119256019592 and perplexity is 52.77930990307772
At time: 291.19339632987976 and batch: 100, loss is 3.932221188545227 and perplexity is 51.02017733723448
At time: 292.35523772239685 and batch: 150, loss is 3.901387014389038 and perplexity is 49.47101855570742
At time: 293.5208559036255 and batch: 200, loss is 3.8985902070999146 and perplexity is 49.332850954551205
At time: 294.6818392276764 and batch: 250, loss is 3.8906515407562257 and perplexity is 48.94276434344692
At time: 295.84276127815247 and batch: 300, loss is 3.9025643920898436 and perplexity is 49.529298932066354
At time: 297.009774684906 and batch: 350, loss is 3.9152735662460327 and perplexity is 50.16279248098367
At time: 298.17489075660706 and batch: 400, loss is 3.8896123695373537 and perplexity is 48.89193084829622
At time: 299.3406059741974 and batch: 450, loss is 3.9227496337890626 and perplexity is 50.53921824468457
At time: 300.5034713745117 and batch: 500, loss is 3.9481559562683106 and perplexity is 51.83968399595041
At time: 301.672199010849 and batch: 550, loss is 3.906849308013916 and perplexity is 49.741983155360394
At time: 302.83860063552856 and batch: 600, loss is 3.890274233818054 and perplexity is 48.92430138220755
At time: 304.00405383110046 and batch: 650, loss is 3.934924907684326 and perplexity is 51.15830821658665
At time: 305.1659336090088 and batch: 700, loss is 3.966635708808899 and perplexity is 52.80657496484742
At time: 306.3276309967041 and batch: 750, loss is 3.9420497226715088 and perplexity is 51.524103261292645
At time: 307.4896545410156 and batch: 800, loss is 3.911526823043823 and perplexity is 49.975197034689955
At time: 308.6568880081177 and batch: 850, loss is 3.902103958129883 and perplexity is 49.50649921011091
At time: 309.823184967041 and batch: 900, loss is 3.887811541557312 and perplexity is 48.803964121470706
At time: 310.9901249408722 and batch: 950, loss is 3.989587163925171 and perplexity is 54.03257816072805
At time: 312.180641412735 and batch: 1000, loss is 3.970673704147339 and perplexity is 53.02023876478569
At time: 313.3554513454437 and batch: 1050, loss is 3.9187215900421144 and perplexity is 50.336053515564664
At time: 314.52657532691956 and batch: 1100, loss is 3.958221826553345 and perplexity is 52.3641306083102
At time: 315.6883418560028 and batch: 1150, loss is 3.913803768157959 and perplexity is 50.08911746146749
At time: 316.8499174118042 and batch: 1200, loss is 3.9870438623428344 and perplexity is 53.89533162284289
At time: 318.0112335681915 and batch: 1250, loss is 3.9627052450180056 and perplexity is 52.599427992540576
At time: 319.17843651771545 and batch: 1300, loss is 3.9538177013397218 and perplexity is 52.13401951139286
At time: 320.3411343097687 and batch: 1350, loss is 3.8407257413864135 and perplexity is 46.559252157573994
At time: 321.50325441360474 and batch: 1400, loss is 3.8880187320709227 and perplexity is 48.81407688746169
At time: 322.6690607070923 and batch: 1450, loss is 3.808486385345459 and perplexity is 45.082150194796284
At time: 323.8381314277649 and batch: 1500, loss is 3.814774098396301 and perplexity is 45.36650685864527
At time: 325.00090432167053 and batch: 1550, loss is 3.8143532180786135 and perplexity is 45.347417006379565
At time: 326.16440773010254 and batch: 1600, loss is 3.9080029010772703 and perplexity is 49.79939827255915
At time: 327.3277819156647 and batch: 1650, loss is 3.868861994743347 and perplexity is 47.88785842570657
At time: 328.48921513557434 and batch: 1700, loss is 3.8965896463394163 and perplexity is 49.23425624396595
At time: 329.65656661987305 and batch: 1750, loss is 3.9014858198165894 and perplexity is 49.47590680233588
At time: 330.81902599334717 and batch: 1800, loss is 3.8557170677185058 and perplexity is 47.26249520292524
At time: 331.98237228393555 and batch: 1850, loss is 3.898167634010315 and perplexity is 49.31200862331888
At time: 333.1435794830322 and batch: 1900, loss is 3.9843557834625245 and perplexity is 53.750651263388434
At time: 334.30571603775024 and batch: 1950, loss is 3.910775203704834 and perplexity is 49.93764882287764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473342682594477 and perplexity of 87.64921739656083
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 337.9257559776306 and batch: 50, loss is 3.913959846496582 and perplexity is 50.09693589783236
At time: 339.11141657829285 and batch: 100, loss is 3.907946915626526 and perplexity is 49.7966103088435
At time: 340.2750713825226 and batch: 150, loss is 3.8721332263946535 and perplexity is 48.0447672064642
At time: 341.46244621276855 and batch: 200, loss is 3.8784697341918943 and perplexity is 48.350169819645004
At time: 342.62703585624695 and batch: 250, loss is 3.875999264717102 and perplexity is 48.2308696254249
At time: 343.8008544445038 and batch: 300, loss is 3.880676212310791 and perplexity is 48.45697119551584
At time: 344.96505975723267 and batch: 350, loss is 3.8913668537139894 and perplexity is 48.97778626129307
At time: 346.12889862060547 and batch: 400, loss is 3.859376335144043 and perplexity is 47.435758126420964
At time: 347.29267263412476 and batch: 450, loss is 3.875937900543213 and perplexity is 48.22791006876067
At time: 348.45632433891296 and batch: 500, loss is 3.8949925088882447 and perplexity is 49.155685130573936
At time: 349.61764764785767 and batch: 550, loss is 3.8545124435424807 and perplexity is 47.205595936581076
At time: 350.78115725517273 and batch: 600, loss is 3.8192670822143553 and perplexity is 45.570796431049935
At time: 351.94379210472107 and batch: 650, loss is 3.853215389251709 and perplexity is 47.144407406824016
At time: 353.1060297489166 and batch: 700, loss is 3.880903191566467 and perplexity is 48.46797117110603
At time: 354.2683594226837 and batch: 750, loss is 3.840669188499451 and perplexity is 46.55661917190183
At time: 355.42998027801514 and batch: 800, loss is 3.8084957075119017 and perplexity is 45.08257046006289
At time: 356.59281158447266 and batch: 850, loss is 3.7922220993041993 and perplexity is 44.35485173619309
At time: 357.75637459754944 and batch: 900, loss is 3.7655498790740967 and perplexity is 43.18744720530913
At time: 358.9199056625366 and batch: 950, loss is 3.8671838903427123 and perplexity is 47.807564988972594
At time: 360.09270691871643 and batch: 1000, loss is 3.8357315111160277 and perplexity is 46.3273042139129
At time: 361.26022267341614 and batch: 1050, loss is 3.779382929801941 and perplexity is 43.78901250234685
At time: 362.4249360561371 and batch: 1100, loss is 3.801468434333801 and perplexity is 44.7668734655397
At time: 363.58923077583313 and batch: 1150, loss is 3.765775971412659 and perplexity is 43.19721266014997
At time: 364.7524471282959 and batch: 1200, loss is 3.8202817630767822 and perplexity is 45.61705971333836
At time: 365.9204959869385 and batch: 1250, loss is 3.7891553974151613 and perplexity is 44.21903698670107
At time: 367.08390760421753 and batch: 1300, loss is 3.7773322820663453 and perplexity is 43.69930866993025
At time: 368.2529180049896 and batch: 1350, loss is 3.6523590421676637 and perplexity is 38.565536550158754
At time: 369.41827630996704 and batch: 1400, loss is 3.680118637084961 and perplexity is 39.65109788421231
At time: 370.5871202945709 and batch: 1450, loss is 3.5989205598831178 and perplexity is 36.55875015550863
At time: 371.7515425682068 and batch: 1500, loss is 3.604194550514221 and perplexity is 36.752069996730626
At time: 372.92108845710754 and batch: 1550, loss is 3.5967342233657837 and perplexity is 36.478907738016396
At time: 374.0932734012604 and batch: 1600, loss is 3.6736221265792848 and perplexity is 39.39433903157187
At time: 375.2622275352478 and batch: 1650, loss is 3.6247996997833254 and perplexity is 37.51720770212049
At time: 376.4267716407776 and batch: 1700, loss is 3.636823182106018 and perplexity is 37.97101790817571
At time: 377.5946373939514 and batch: 1750, loss is 3.629915466308594 and perplexity is 37.70962874832284
At time: 378.76111793518066 and batch: 1800, loss is 3.5732024478912354 and perplexity is 35.63051550831372
At time: 379.9276077747345 and batch: 1850, loss is 3.6058258485794066 and perplexity is 36.81207250508953
At time: 381.09288024902344 and batch: 1900, loss is 3.6888418340682985 and perplexity is 39.99849522647949
At time: 382.26407265663147 and batch: 1950, loss is 3.602899308204651 and perplexity is 36.70449797600436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.421080123546512 and perplexity of 83.18608810308571
finished 8 epochs...
Completing Train Step...
At time: 385.89068388938904 and batch: 50, loss is 3.80622193813324 and perplexity is 44.980179542619446
At time: 387.07745480537415 and batch: 100, loss is 3.7877050685882567 and perplexity is 44.1549513265349
At time: 388.24275064468384 and batch: 150, loss is 3.7498891067504885 and perplexity is 42.51636696054491
At time: 389.40310430526733 and batch: 200, loss is 3.753449411392212 and perplexity is 42.66800796308588
At time: 390.56326127052307 and batch: 250, loss is 3.74130970954895 and perplexity is 42.153162426639966
At time: 391.72380924224854 and batch: 300, loss is 3.748772745132446 and perplexity is 42.4689298037687
At time: 392.89487290382385 and batch: 350, loss is 3.7629916572570803 and perplexity is 43.07710533531452
At time: 394.05785965919495 and batch: 400, loss is 3.73438006401062 and perplexity is 41.862065716085226
At time: 395.22400069236755 and batch: 450, loss is 3.7599391889572145 and perplexity is 42.945814319602924
At time: 396.3876042366028 and batch: 500, loss is 3.7794170427322387 and perplexity is 43.790506299356906
At time: 397.5511202812195 and batch: 550, loss is 3.7444582891464235 and perplexity is 42.28609417710534
At time: 398.71705627441406 and batch: 600, loss is 3.7122227859497072 and perplexity is 40.94471679373171
At time: 399.91035652160645 and batch: 650, loss is 3.745507249832153 and perplexity is 42.33047389967297
At time: 401.0782127380371 and batch: 700, loss is 3.777512540817261 and perplexity is 43.70718656273519
At time: 402.24048614501953 and batch: 750, loss is 3.7404277086257935 and perplexity is 42.11599968965902
At time: 403.405654668808 and batch: 800, loss is 3.7106067991256713 and perplexity is 40.87860410388429
At time: 404.57045888900757 and batch: 850, loss is 3.6973944187164305 and perplexity is 40.34205280114849
At time: 405.74024081230164 and batch: 900, loss is 3.6735077857971192 and perplexity is 39.38983490954143
At time: 406.90196442604065 and batch: 950, loss is 3.7795592164993286 and perplexity is 43.79673260319831
At time: 408.06360054016113 and batch: 1000, loss is 3.7496304368972777 and perplexity is 42.50537068040857
At time: 409.2292363643646 and batch: 1050, loss is 3.698909330368042 and perplexity is 40.40321376201617
At time: 410.395090341568 and batch: 1100, loss is 3.718977298736572 and perplexity is 41.22221453285041
At time: 411.55807185173035 and batch: 1150, loss is 3.6900788164138794 and perplexity is 40.04800327290135
At time: 412.72809648513794 and batch: 1200, loss is 3.744420886039734 and perplexity is 42.284512575391936
At time: 413.89578914642334 and batch: 1250, loss is 3.718169264793396 and perplexity is 41.188919038051566
At time: 415.0646255016327 and batch: 1300, loss is 3.7090238332748413 and perplexity is 40.813945858956714
At time: 416.2283992767334 and batch: 1350, loss is 3.5862919425964357 and perplexity is 36.09996668901474
At time: 417.3927481174469 and batch: 1400, loss is 3.620423755645752 and perplexity is 37.35339318002247
At time: 418.5562598705292 and batch: 1450, loss is 3.5412929582595827 and perplexity is 34.51151230101028
At time: 419.7188792228699 and batch: 1500, loss is 3.550087127685547 and perplexity is 34.81635082352278
At time: 420.88181018829346 and batch: 1550, loss is 3.5456057453155516 and perplexity is 34.66067452579711
At time: 422.04742097854614 and batch: 1600, loss is 3.62721125125885 and perplexity is 37.607791559629916
At time: 423.2175703048706 and batch: 1650, loss is 3.5824350690841675 and perplexity is 35.961001840883014
At time: 424.3822615146637 and batch: 1700, loss is 3.5984303903579713 and perplexity is 36.54083456150277
At time: 425.54853343963623 and batch: 1750, loss is 3.5973475217819213 and perplexity is 36.50128705625329
At time: 426.7102241516113 and batch: 1800, loss is 3.5432063817977903 and perplexity is 34.577610657895576
At time: 427.8728668689728 and batch: 1850, loss is 3.5798497867584227 and perplexity is 35.86815257091061
At time: 429.03532338142395 and batch: 1900, loss is 3.665890960693359 and perplexity is 39.090949151454375
At time: 430.19947481155396 and batch: 1950, loss is 3.5843232011795045 and perplexity is 36.02896510425771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4302183639171515 and perplexity of 83.94974650442559
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 433.880384683609 and batch: 50, loss is 3.7647066593170164 and perplexity is 43.15104604581301
At time: 435.0439326763153 and batch: 100, loss is 3.7773127698898317 and perplexity is 43.69845600962461
At time: 436.206001996994 and batch: 150, loss is 3.753961400985718 and perplexity is 42.689859132446934
At time: 437.3691427707672 and batch: 200, loss is 3.76779465675354 and perplexity is 43.28450231564514
At time: 438.5351130962372 and batch: 250, loss is 3.7579904413223266 and perplexity is 42.86220525845894
At time: 439.6978142261505 and batch: 300, loss is 3.7680968952178957 and perplexity is 43.297586534332915
At time: 440.8592176437378 and batch: 350, loss is 3.7869349241256716 and perplexity is 44.12095872656152
At time: 442.0230782032013 and batch: 400, loss is 3.765588493347168 and perplexity is 43.18911488938677
At time: 443.190158367157 and batch: 450, loss is 3.794624786376953 and perplexity is 44.461550695848835
At time: 444.35183119773865 and batch: 500, loss is 3.8025806760787964 and perplexity is 44.81669275140984
At time: 445.5186879634857 and batch: 550, loss is 3.7644375371932983 and perplexity is 43.13943470716465
At time: 446.6826949119568 and batch: 600, loss is 3.7260570192337035 and perplexity is 41.515091811342266
At time: 447.84547781944275 and batch: 650, loss is 3.757577199935913 and perplexity is 42.844496480585164
At time: 449.0087630748749 and batch: 700, loss is 3.7862300157546995 and perplexity is 44.08986845260442
At time: 450.1716401576996 and batch: 750, loss is 3.7460595560073853 and perplexity is 42.3538597392856
At time: 451.3384282588959 and batch: 800, loss is 3.7157016515731813 and perplexity is 41.08740601585507
At time: 452.50283765792847 and batch: 850, loss is 3.6950012159347536 and perplexity is 40.24562152399179
At time: 453.67059350013733 and batch: 900, loss is 3.667964448928833 and perplexity is 39.172087865647754
At time: 454.83498215675354 and batch: 950, loss is 3.772583522796631 and perplexity is 43.49228311910328
At time: 455.99978494644165 and batch: 1000, loss is 3.7397639656066897 and perplexity is 42.08805476402302
At time: 457.1927402019501 and batch: 1050, loss is 3.682676591873169 and perplexity is 39.75265343177824
At time: 458.35535740852356 and batch: 1100, loss is 3.699874472618103 and perplexity is 40.44222743449954
At time: 459.5152530670166 and batch: 1150, loss is 3.6686750984191896 and perplexity is 39.199935383665945
At time: 460.67581844329834 and batch: 1200, loss is 3.713087587356567 and perplexity is 40.98014115773055
At time: 461.8366210460663 and batch: 1250, loss is 3.687647776603699 and perplexity is 39.95076322772751
At time: 462.9978446960449 and batch: 1300, loss is 3.6802207899093626 and perplexity is 39.65514856274242
At time: 464.159068107605 and batch: 1350, loss is 3.5561656951904297 and perplexity is 35.02862888190997
At time: 465.32130217552185 and batch: 1400, loss is 3.583512897491455 and perplexity is 35.999782525929305
At time: 466.4820408821106 and batch: 1450, loss is 3.497394585609436 and perplexity is 33.02928478295215
At time: 467.64306807518005 and batch: 1500, loss is 3.5006043338775634 and perplexity is 33.13547079660347
At time: 468.8041226863861 and batch: 1550, loss is 3.4939582204818724 and perplexity is 32.91597889224014
At time: 469.96574783325195 and batch: 1600, loss is 3.5697255992889403 and perplexity is 35.506848710215216
At time: 471.12656116485596 and batch: 1650, loss is 3.5152462768554686 and perplexity is 33.624207768470725
At time: 472.28745579719543 and batch: 1700, loss is 3.532293438911438 and perplexity is 34.202318662222225
At time: 473.45596408843994 and batch: 1750, loss is 3.531447801589966 and perplexity is 34.17340813071562
At time: 474.6178958415985 and batch: 1800, loss is 3.4695119524002074 and perplexity is 32.121062011448004
At time: 475.7792899608612 and batch: 1850, loss is 3.5000769662857056 and perplexity is 33.118000830116365
At time: 476.94625186920166 and batch: 1900, loss is 3.5886744928359984 and perplexity is 36.18607921627395
At time: 478.1079089641571 and batch: 1950, loss is 3.510358190536499 and perplexity is 33.4602507828977
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.402636434865553 and perplexity of 81.66589189777152
finished 10 epochs...
Completing Train Step...
At time: 481.80015897750854 and batch: 50, loss is 3.7549219512939453 and perplexity is 42.73088459014844
At time: 482.95950198173523 and batch: 100, loss is 3.7455520677566527 and perplexity is 42.33237110617035
At time: 484.1148669719696 and batch: 150, loss is 3.711903300285339 and perplexity is 40.931637633097914
At time: 485.27280282974243 and batch: 200, loss is 3.719553241729736 and perplexity is 41.24596301670327
At time: 486.4598240852356 and batch: 250, loss is 3.7049557876586916 and perplexity is 40.648250122841965
At time: 487.61508798599243 and batch: 300, loss is 3.71385543346405 and perplexity is 41.0116196833877
At time: 488.7692828178406 and batch: 350, loss is 3.7330741596221926 and perplexity is 41.8074335407208
At time: 489.9294185638428 and batch: 400, loss is 3.710672559738159 and perplexity is 40.881292394318656
At time: 491.0828619003296 and batch: 450, loss is 3.7419196510314943 and perplexity is 42.1788812317101
At time: 492.2418472766876 and batch: 500, loss is 3.7489461660385133 and perplexity is 42.4762954427144
At time: 493.39838695526123 and batch: 550, loss is 3.713401427268982 and perplexity is 40.99300438003294
At time: 494.5585777759552 and batch: 600, loss is 3.6802639389038085 and perplexity is 39.65685967944372
At time: 495.7195372581482 and batch: 650, loss is 3.7102358102798463 and perplexity is 40.86344141049782
At time: 496.8726575374603 and batch: 700, loss is 3.742946858406067 and perplexity is 42.22222994981236
At time: 498.02826046943665 and batch: 750, loss is 3.703730592727661 and perplexity is 40.598478588977706
At time: 499.1873996257782 and batch: 800, loss is 3.6747034120559694 and perplexity is 39.43695859603584
At time: 500.342303276062 and batch: 850, loss is 3.6564352083206177 and perplexity is 38.72305690638554
At time: 501.4979898929596 and batch: 900, loss is 3.630749306678772 and perplexity is 37.74108567232155
At time: 502.659645318985 and batch: 950, loss is 3.7376672983169557 and perplexity is 41.9999025615237
At time: 503.81496000289917 and batch: 1000, loss is 3.7061530685424806 and perplexity is 40.69694664156187
At time: 504.97070837020874 and batch: 1050, loss is 3.6516693210601807 and perplexity is 38.53894625657619
At time: 506.1248605251312 and batch: 1100, loss is 3.6683474159240723 and perplexity is 39.18709235536369
At time: 507.2795729637146 and batch: 1150, loss is 3.6413615798950194 and perplexity is 38.14373712970402
At time: 508.4388790130615 and batch: 1200, loss is 3.6871920013427735 and perplexity is 39.93255880707065
At time: 509.5954165458679 and batch: 1250, loss is 3.664362711906433 and perplexity is 39.03125408191105
At time: 510.7513244152069 and batch: 1300, loss is 3.6592638731002807 and perplexity is 38.832746518049426
At time: 511.91122174263 and batch: 1350, loss is 3.5355433082580565 and perplexity is 34.313652541517534
At time: 513.0727863311768 and batch: 1400, loss is 3.5655580949783325 and perplexity is 35.359181680375485
At time: 514.2273788452148 and batch: 1450, loss is 3.482640118598938 and perplexity is 32.54553281725647
At time: 515.3827199935913 and batch: 1500, loss is 3.4871803760528564 and perplexity is 32.69363386926234
At time: 516.5369486808777 and batch: 1550, loss is 3.482398872375488 and perplexity is 32.53768227736876
At time: 517.6928508281708 and batch: 1600, loss is 3.561227388381958 and perplexity is 35.20638254196069
At time: 518.8539447784424 and batch: 1650, loss is 3.5093812465667726 and perplexity is 33.42757795502953
At time: 520.0078375339508 and batch: 1700, loss is 3.528146085739136 and perplexity is 34.06076331033951
At time: 521.1652371883392 and batch: 1750, loss is 3.53036744594574 and perplexity is 34.13650863223888
At time: 522.3235094547272 and batch: 1800, loss is 3.4699834966659546 and perplexity is 32.13621208573382
At time: 523.4807195663452 and batch: 1850, loss is 3.502094259262085 and perplexity is 33.18487697228942
At time: 524.6378636360168 and batch: 1900, loss is 3.591903624534607 and perplexity is 36.30311769635306
At time: 525.7926032543182 and batch: 1950, loss is 3.514137277603149 and perplexity is 33.58693921641349
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.403917605377907 and perplexity of 81.77058688207887
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 529.4440534114838 and batch: 50, loss is 3.7443700313568113 and perplexity is 42.28236226458953
At time: 530.5985882282257 and batch: 100, loss is 3.7487888860702516 and perplexity is 42.46961529765557
At time: 531.7606704235077 and batch: 150, loss is 3.7255068111419676 and perplexity is 41.49225615465613
At time: 532.9187626838684 and batch: 200, loss is 3.7411091709136963 and perplexity is 42.14470993652904
At time: 534.0708074569702 and batch: 250, loss is 3.727831883430481 and perplexity is 41.58884088936319
At time: 535.222749710083 and batch: 300, loss is 3.7373763370513915 and perplexity is 41.987683994371906
At time: 536.3768396377563 and batch: 350, loss is 3.761459832191467 and perplexity is 43.011169259767634
At time: 537.5331017971039 and batch: 400, loss is 3.749135608673096 and perplexity is 42.48434302628402
At time: 538.690402507782 and batch: 450, loss is 3.788866095542908 and perplexity is 44.20624618680197
At time: 539.8444573879242 and batch: 500, loss is 3.7960638666152953 and perplexity is 44.52558049578093
At time: 540.9976582527161 and batch: 550, loss is 3.763862371444702 and perplexity is 43.114629516139246
At time: 542.1482555866241 and batch: 600, loss is 3.717717752456665 and perplexity is 41.17032593079378
At time: 543.2975471019745 and batch: 650, loss is 3.7389224195480346 and perplexity is 42.05265062661548
At time: 544.4747931957245 and batch: 700, loss is 3.766056842803955 and perplexity is 43.20934722541628
At time: 545.6278345584869 and batch: 750, loss is 3.730158905982971 and perplexity is 41.685731749931236
At time: 546.7825665473938 and batch: 800, loss is 3.698168625831604 and perplexity is 40.37329799903442
At time: 547.9369029998779 and batch: 850, loss is 3.6903445959091186 and perplexity is 40.05864862559213
At time: 549.0923826694489 and batch: 900, loss is 3.660429906845093 and perplexity is 38.8780532203317
At time: 550.2435598373413 and batch: 950, loss is 3.769737606048584 and perplexity is 43.368683662467475
At time: 551.3968534469604 and batch: 1000, loss is 3.735796914100647 and perplexity is 41.921420025814
At time: 552.5504133701324 and batch: 1050, loss is 3.675410656929016 and perplexity is 39.464860048227926
At time: 553.7051875591278 and batch: 1100, loss is 3.684567341804504 and perplexity is 39.82788685991142
At time: 554.8597674369812 and batch: 1150, loss is 3.6516016864776613 and perplexity is 38.53633977918038
At time: 556.0118126869202 and batch: 1200, loss is 3.6924450302124026 and perplexity is 40.142877613068876
At time: 557.1671326160431 and batch: 1250, loss is 3.6679049587249755 and perplexity is 39.16975757947038
At time: 558.32097697258 and batch: 1300, loss is 3.666324634552002 and perplexity is 39.10790555071869
At time: 559.4758455753326 and batch: 1350, loss is 3.540674338340759 and perplexity is 34.49016939432639
At time: 560.6298320293427 and batch: 1400, loss is 3.570712785720825 and perplexity is 35.54191789656539
At time: 561.7890899181366 and batch: 1450, loss is 3.4897834205627443 and perplexity is 32.7788477130118
At time: 562.9424202442169 and batch: 1500, loss is 3.4905045938491823 and perplexity is 32.80249546838245
At time: 564.0963702201843 and batch: 1550, loss is 3.4831892824172974 and perplexity is 32.563410554782934
At time: 565.2500689029694 and batch: 1600, loss is 3.5584184741973877 and perplexity is 35.10762959385956
At time: 566.4128551483154 and batch: 1650, loss is 3.498912925720215 and perplexity is 33.07947256228594
At time: 567.569920539856 and batch: 1700, loss is 3.5121026372909547 and perplexity is 33.518671349748374
At time: 568.7232513427734 and batch: 1750, loss is 3.521317491531372 and perplexity is 33.82896849635808
At time: 569.8768904209137 and batch: 1800, loss is 3.462794008255005 and perplexity is 31.905997714771086
At time: 571.0316925048828 and batch: 1850, loss is 3.4894756364822386 and perplexity is 32.76876045793631
At time: 572.1918702125549 and batch: 1900, loss is 3.5780903911590576 and perplexity is 35.8051017830237
At time: 573.3455715179443 and batch: 1950, loss is 3.5147385454177855 and perplexity is 33.60714003439872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386697742550872 and perplexity of 80.37456276063381
finished 12 epochs...
Completing Train Step...
At time: 576.9708127975464 and batch: 50, loss is 3.75841338634491 and perplexity is 42.88033744901953
At time: 578.1488857269287 and batch: 100, loss is 3.746654806137085 and perplexity is 42.379078384745064
At time: 579.3097558021545 and batch: 150, loss is 3.713696460723877 and perplexity is 41.005100472029866
At time: 580.4655110836029 and batch: 200, loss is 3.717488160133362 and perplexity is 41.16087462502733
At time: 581.6249032020569 and batch: 250, loss is 3.704495153427124 and perplexity is 40.62953045917201
At time: 582.7803041934967 and batch: 300, loss is 3.708660101890564 and perplexity is 40.79910324545743
At time: 583.9379296302795 and batch: 350, loss is 3.7302355575561523 and perplexity is 41.688927149313706
At time: 585.0935080051422 and batch: 400, loss is 3.716715941429138 and perplexity is 41.129101697163165
At time: 586.2486479282379 and batch: 450, loss is 3.756201696395874 and perplexity is 42.78560423653541
At time: 587.403843164444 and batch: 500, loss is 3.7637968969345095 and perplexity is 43.11180669930182
At time: 588.55916929245 and batch: 550, loss is 3.732780809402466 and perplexity is 41.795171119585326
At time: 589.7205348014832 and batch: 600, loss is 3.690621185302734 and perplexity is 40.06972995534303
At time: 590.8822281360626 and batch: 650, loss is 3.7138271284103395 and perplexity is 41.010458863718405
At time: 592.0372638702393 and batch: 700, loss is 3.7432904863357543 and perplexity is 42.23674118036606
At time: 593.1918749809265 and batch: 750, loss is 3.7087395668029783 and perplexity is 40.80234547144331
At time: 594.348128080368 and batch: 800, loss is 3.6795419692993163 and perplexity is 39.62823896503167
At time: 595.5104012489319 and batch: 850, loss is 3.6706384658813476 and perplexity is 39.27697486497466
At time: 596.6734709739685 and batch: 900, loss is 3.641897578239441 and perplexity is 38.164187589872384
At time: 597.8288540840149 and batch: 950, loss is 3.7509781551361083 and perplexity is 42.56269456326738
At time: 598.9819977283478 and batch: 1000, loss is 3.717410478591919 and perplexity is 41.15767730902715
At time: 600.1349024772644 and batch: 1050, loss is 3.6587902784347532 and perplexity is 38.81435989069868
At time: 601.31316614151 and batch: 1100, loss is 3.6695245552062987 and perplexity is 39.2332481817199
At time: 602.4690165519714 and batch: 1150, loss is 3.6394387531280517 and perplexity is 38.07046379949506
At time: 603.6265745162964 and batch: 1200, loss is 3.6810104417800904 and perplexity is 39.686474691729366
At time: 604.7821712493896 and batch: 1250, loss is 3.6581207132339477 and perplexity is 38.78837984466231
At time: 605.9380660057068 and batch: 1300, loss is 3.6569908380508425 and perplexity is 38.744578566531324
At time: 607.092310667038 and batch: 1350, loss is 3.5328923749923704 and perplexity is 34.222809800749125
At time: 608.2467226982117 and batch: 1400, loss is 3.564902272224426 and perplexity is 35.335999926861575
At time: 609.4007325172424 and batch: 1450, loss is 3.485377159118652 and perplexity is 32.63473327626203
At time: 610.5539708137512 and batch: 1500, loss is 3.4878086757659914 and perplexity is 32.71418172447355
At time: 611.7092027664185 and batch: 1550, loss is 3.481386775970459 and perplexity is 32.50476766529778
At time: 612.8669729232788 and batch: 1600, loss is 3.5577528429031373 and perplexity is 35.084268632690886
At time: 614.0227475166321 and batch: 1650, loss is 3.5001099491119385 and perplexity is 33.11909317339711
At time: 615.1782355308533 and batch: 1700, loss is 3.5151742553710936 and perplexity is 33.62178619032018
At time: 616.3338799476624 and batch: 1750, loss is 3.526385812759399 and perplexity is 34.00085980774151
At time: 617.4943177700043 and batch: 1800, loss is 3.468470993041992 and perplexity is 32.08764268844764
At time: 618.6542975902557 and batch: 1850, loss is 3.4960138034820556 and perplexity is 32.983710008501625
At time: 619.810384273529 and batch: 1900, loss is 3.5851027536392213 and perplexity is 36.05706252290879
At time: 620.9718286991119 and batch: 1950, loss is 3.5213025760650636 and perplexity is 33.82846392528119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385264693859011 and perplexity of 80.25946458895038
finished 13 epochs...
Completing Train Step...
At time: 624.5989985466003 and batch: 50, loss is 3.753078651428223 and perplexity is 42.65219130626273
At time: 625.7738764286041 and batch: 100, loss is 3.7390173959732054 and perplexity is 42.05664482671537
At time: 626.9308459758759 and batch: 150, loss is 3.704666266441345 and perplexity is 40.63648329543868
At time: 628.0828969478607 and batch: 200, loss is 3.7067214107513426 and perplexity is 40.72008300817416
At time: 629.2348167896271 and batch: 250, loss is 3.693221616744995 and perplexity is 40.17406413915342
At time: 630.4107513427734 and batch: 300, loss is 3.6965642881393435 and perplexity is 40.30857752592293
At time: 631.5641193389893 and batch: 350, loss is 3.717996664047241 and perplexity is 41.181810413386884
At time: 632.7206780910492 and batch: 400, loss is 3.70389630317688 and perplexity is 40.60520673854924
At time: 633.8714265823364 and batch: 450, loss is 3.7434759855270388 and perplexity is 42.24457678842452
At time: 635.0212273597717 and batch: 500, loss is 3.7509810018539427 and perplexity is 42.56281572742153
At time: 636.1701169013977 and batch: 550, loss is 3.7202724552154542 and perplexity is 41.27563833970339
At time: 637.3323872089386 and batch: 600, loss is 3.6792013168334963 and perplexity is 39.614741806762765
At time: 638.4858357906342 and batch: 650, loss is 3.7026113271713257 and perplexity is 40.553063530749824
At time: 639.6378848552704 and batch: 700, loss is 3.7325470447540283 and perplexity is 41.78540202798079
At time: 640.7897336483002 and batch: 750, loss is 3.6982554483413694 and perplexity is 40.376803462268555
At time: 641.9409210681915 and batch: 800, loss is 3.6697338390350343 and perplexity is 39.24145992537571
At time: 643.0920505523682 and batch: 850, loss is 3.6606956005096434 and perplexity is 38.88838424514554
At time: 644.2441182136536 and batch: 900, loss is 3.632576026916504 and perplexity is 37.81009108491629
At time: 645.3959534168243 and batch: 950, loss is 3.741634392738342 and perplexity is 42.16685107197587
At time: 646.5474939346313 and batch: 1000, loss is 3.7083306550979613 and perplexity is 40.785664325578225
At time: 647.6992959976196 and batch: 1050, loss is 3.6504256105422974 and perplexity is 38.49104475774227
At time: 648.8518269062042 and batch: 1100, loss is 3.66178786277771 and perplexity is 38.930883766008826
At time: 650.002923488617 and batch: 1150, loss is 3.6329267501831053 and perplexity is 37.82335428929331
At time: 651.1544098854065 and batch: 1200, loss is 3.674882273674011 and perplexity is 39.444012985121894
At time: 652.3049919605255 and batch: 1250, loss is 3.652954249382019 and perplexity is 38.58849786843215
At time: 653.4568593502045 and batch: 1300, loss is 3.6523264026641846 and perplexity is 38.564277810736776
At time: 654.6075682640076 and batch: 1350, loss is 3.5285972213745116 and perplexity is 34.07613280103871
At time: 655.7588925361633 and batch: 1400, loss is 3.561284613609314 and perplexity is 35.20839729285279
At time: 656.9156715869904 and batch: 1450, loss is 3.48242241859436 and perplexity is 32.53844842577717
At time: 658.0722935199738 and batch: 1500, loss is 3.4854013538360595 and perplexity is 32.635522873963325
At time: 659.2268314361572 and batch: 1550, loss is 3.4793475103378295 and perplexity is 32.43854935101559
At time: 660.3806428909302 and batch: 1600, loss is 3.5563303947448732 and perplexity is 35.03439855659797
At time: 661.5353169441223 and batch: 1650, loss is 3.4993852233886718 and perplexity is 33.09509961006952
At time: 662.6891007423401 and batch: 1700, loss is 3.5150163269042967 and perplexity is 33.61647677244131
At time: 663.8434212207794 and batch: 1750, loss is 3.527040858268738 and perplexity is 34.023139214488246
At time: 664.9971237182617 and batch: 1800, loss is 3.4694455337524412 and perplexity is 32.11892864479284
At time: 666.1547980308533 and batch: 1850, loss is 3.4972726917266845 and perplexity is 33.025258960552
At time: 667.3081269264221 and batch: 1900, loss is 3.58678587436676 and perplexity is 36.11780201382428
At time: 668.4610266685486 and batch: 1950, loss is 3.522792491912842 and perplexity is 33.878903055488585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385126158248546 and perplexity of 80.24834656516684
finished 14 epochs...
Completing Train Step...
At time: 672.0869536399841 and batch: 50, loss is 3.747073631286621 and perplexity is 42.39683152605827
At time: 673.2743775844574 and batch: 100, loss is 3.7320339632034303 and perplexity is 41.76396820823486
At time: 674.4289298057556 and batch: 150, loss is 3.6970682668685915 and perplexity is 40.328897311542015
At time: 675.5829939842224 and batch: 200, loss is 3.698385615348816 and perplexity is 40.38205953202151
At time: 676.7426383495331 and batch: 250, loss is 3.6846543836593626 and perplexity is 39.83135370393688
At time: 677.8961737155914 and batch: 300, loss is 3.687532467842102 and perplexity is 39.94615682027955
At time: 679.0498735904694 and batch: 350, loss is 3.7089849948883056 and perplexity is 40.81236074193328
At time: 680.2049324512482 and batch: 400, loss is 3.69461398601532 and perplexity is 40.23004023217737
At time: 681.3594481945038 and batch: 450, loss is 3.7342888069152833 and perplexity is 41.85824567986853
At time: 682.5143532752991 and batch: 500, loss is 3.741707501411438 and perplexity is 42.16993394719746
At time: 683.6741874217987 and batch: 550, loss is 3.7112835693359374 and perplexity is 40.90627888905786
At time: 684.8294341564178 and batch: 600, loss is 3.670859670639038 and perplexity is 39.285664079694875
At time: 685.988352060318 and batch: 650, loss is 3.6943553352355956 and perplexity is 40.21963604648635
At time: 687.1417708396912 and batch: 700, loss is 3.7247185373306273 and perplexity is 41.459561783507226
At time: 688.3251187801361 and batch: 750, loss is 3.690550651550293 and perplexity is 40.06690378660128
At time: 689.4778621196747 and batch: 800, loss is 3.662322325706482 and perplexity is 38.95169644147239
At time: 690.6378946304321 and batch: 850, loss is 3.6533647441864012 and perplexity is 38.604341497957385
At time: 691.7940971851349 and batch: 900, loss is 3.6256204509735106 and perplexity is 37.54801263485776
At time: 692.9527041912079 and batch: 950, loss is 3.734774990081787 and perplexity is 41.87860140220126
At time: 694.1070466041565 and batch: 1000, loss is 3.701582016944885 and perplexity is 40.511343322945876
At time: 695.2599596977234 and batch: 1050, loss is 3.644213194847107 and perplexity is 38.25266361521578
At time: 696.413964509964 and batch: 1100, loss is 3.6559195470809938 and perplexity is 38.70309407433087
At time: 697.5668876171112 and batch: 1150, loss is 3.627776699066162 and perplexity is 37.6290628162311
At time: 698.7198023796082 and batch: 1200, loss is 3.66993088722229 and perplexity is 39.249193145802785
At time: 699.8725030422211 and batch: 1250, loss is 3.648650779724121 and perplexity is 38.42279025329836
At time: 701.0259184837341 and batch: 1300, loss is 3.64836715221405 and perplexity is 38.411894038275044
At time: 702.1783719062805 and batch: 1350, loss is 3.524774661064148 and perplexity is 33.94612337101414
At time: 703.334689617157 and batch: 1400, loss is 3.557847080230713 and perplexity is 35.08757503619764
At time: 704.4904837608337 and batch: 1450, loss is 3.4793827438354494 and perplexity is 32.43969229470177
At time: 705.6488306522369 and batch: 1500, loss is 3.48268208026886 and perplexity is 32.54689851081517
At time: 706.801707983017 and batch: 1550, loss is 3.476845417022705 and perplexity is 32.35748652919532
At time: 707.9551944732666 and batch: 1600, loss is 3.5542886638641358 and perplexity is 34.962940716839604
At time: 709.1106731891632 and batch: 1650, loss is 3.49782621383667 and perplexity is 33.04354423175875
At time: 710.2632832527161 and batch: 1700, loss is 3.513808403015137 and perplexity is 33.57589514177339
At time: 711.4219381809235 and batch: 1750, loss is 3.5263573217391966 and perplexity is 33.99989110235759
At time: 712.5835680961609 and batch: 1800, loss is 3.4690953874588013 and perplexity is 32.107684289671695
At time: 713.7394533157349 and batch: 1850, loss is 3.4970648193359377 and perplexity is 33.0183946344935
At time: 714.8933954238892 and batch: 1900, loss is 3.5869329881668093 and perplexity is 36.12311583178634
At time: 716.0480227470398 and batch: 1950, loss is 3.5228056144714355 and perplexity is 33.879347636296025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385473348928052 and perplexity of 80.27621288032253
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 719.6990940570831 and batch: 50, loss is 3.7456739854812624 and perplexity is 42.33753248715846
At time: 720.8542721271515 and batch: 100, loss is 3.737329330444336 and perplexity is 41.98571034219691
At time: 722.014888048172 and batch: 150, loss is 3.705972514152527 and perplexity is 40.689599292506045
At time: 723.1679244041443 and batch: 200, loss is 3.7077350425720215 and perplexity is 40.76137910603555
At time: 724.3208827972412 and batch: 250, loss is 3.697023673057556 and perplexity is 40.32709893241462
At time: 725.4788863658905 and batch: 300, loss is 3.698189587593079 and perplexity is 40.374144303347
At time: 726.6320307254791 and batch: 350, loss is 3.718557939529419 and perplexity is 41.2049312418537
At time: 727.7851734161377 and batch: 400, loss is 3.7069808721542357 and perplexity is 40.73064966879839
At time: 728.9416224956512 and batch: 450, loss is 3.7470719623565674 and perplexity is 42.396760768771
At time: 730.1053783893585 and batch: 500, loss is 3.7569622659683226 and perplexity is 42.81815804340476
At time: 731.2572963237762 and batch: 550, loss is 3.7311049365997313 and perplexity is 41.725186388154015
At time: 732.4096744060516 and batch: 600, loss is 3.687478084564209 and perplexity is 39.94398447640256
At time: 733.5629012584686 and batch: 650, loss is 3.7076148223876952 and perplexity is 40.75647906007415
At time: 734.7149183750153 and batch: 700, loss is 3.734814429283142 and perplexity is 41.88025309336491
At time: 735.8702230453491 and batch: 750, loss is 3.6998690462112425 and perplexity is 40.44200797911456
At time: 737.0235905647278 and batch: 800, loss is 3.6685308456420898 and perplexity is 39.19428109195817
At time: 738.1773066520691 and batch: 850, loss is 3.6648647356033326 and perplexity is 39.050853615683444
At time: 739.3289175033569 and batch: 900, loss is 3.637371401786804 and perplexity is 37.99184007453165
At time: 740.481550693512 and batch: 950, loss is 3.7511371088027956 and perplexity is 42.569460597361015
At time: 741.6330535411835 and batch: 1000, loss is 3.720489225387573 and perplexity is 41.28458663675752
At time: 742.7856767177582 and batch: 1050, loss is 3.662802481651306 and perplexity is 38.970403820950075
At time: 743.9389753341675 and batch: 1100, loss is 3.674512038230896 and perplexity is 39.42941211654241
At time: 745.1249709129333 and batch: 1150, loss is 3.646668219566345 and perplexity is 38.34669022156326
At time: 746.2760689258575 and batch: 1200, loss is 3.68517737865448 and perplexity is 39.85219075093349
At time: 747.4299681186676 and batch: 1250, loss is 3.662421045303345 and perplexity is 38.95554192705149
At time: 748.5842037200928 and batch: 1300, loss is 3.6587717628479 and perplexity is 38.81364122670024
At time: 749.7367606163025 and batch: 1350, loss is 3.53041220664978 and perplexity is 34.13803664059584
At time: 750.888516664505 and batch: 1400, loss is 3.561271867752075 and perplexity is 35.20794853450719
At time: 752.0473160743713 and batch: 1450, loss is 3.478901562690735 and perplexity is 32.42408668129379
At time: 753.2055366039276 and batch: 1500, loss is 3.4778095293045044 and perplexity is 32.38869782254429
At time: 754.361409664154 and batch: 1550, loss is 3.4745893573760984 and perplexity is 32.28456839433022
At time: 755.5154941082001 and batch: 1600, loss is 3.5502132415771483 and perplexity is 34.82074192590018
At time: 756.6787700653076 and batch: 1650, loss is 3.4924284553527833 and perplexity is 32.86566367058896
At time: 757.8391108512878 and batch: 1700, loss is 3.5026010417938234 and perplexity is 33.20169875038849
At time: 758.9942383766174 and batch: 1750, loss is 3.512398152351379 and perplexity is 33.52857808566038
At time: 760.1466045379639 and batch: 1800, loss is 3.457030053138733 and perplexity is 31.72262196848227
At time: 761.3003904819489 and batch: 1850, loss is 3.4851369762420656 and perplexity is 32.62689591338496
At time: 762.4543929100037 and batch: 1900, loss is 3.575620312690735 and perplexity is 35.71676951078692
At time: 763.605880022049 and batch: 1950, loss is 3.5200951051712037 and perplexity is 33.787641690497445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381873410247093 and perplexity of 79.98774298491793
finished 16 epochs...
Completing Train Step...
At time: 767.232147693634 and batch: 50, loss is 3.7521260833740233 and perplexity is 42.61158153623831
At time: 768.3834187984467 and batch: 100, loss is 3.73882559299469 and perplexity is 42.04857901051976
At time: 769.536120891571 and batch: 150, loss is 3.704562587738037 and perplexity is 40.632270375942404
At time: 770.6885638237 and batch: 200, loss is 3.7022871923446656 and perplexity is 40.53992100062268
At time: 771.8435626029968 and batch: 250, loss is 3.6911675930023193 and perplexity is 40.091630347037366
At time: 773.0028409957886 and batch: 300, loss is 3.6901576471328736 and perplexity is 40.0511604102317
At time: 774.1982514858246 and batch: 350, loss is 3.709972133636475 and perplexity is 40.85266809582824
At time: 775.3518114089966 and batch: 400, loss is 3.6975079011917114 and perplexity is 40.346631176936064
At time: 776.5069832801819 and batch: 450, loss is 3.737672052383423 and perplexity is 42.00010223232671
At time: 777.6610858440399 and batch: 500, loss is 3.7471946907043456 and perplexity is 42.40196437247961
At time: 778.8155934810638 and batch: 550, loss is 3.721057167053223 and perplexity is 41.30804053324974
At time: 779.9693596363068 and batch: 600, loss is 3.6780545043945314 and perplexity is 39.56933716837071
At time: 781.1236398220062 and batch: 650, loss is 3.6989462566375733 and perplexity is 40.40470572952371
At time: 782.2772974967957 and batch: 700, loss is 3.727827396392822 and perplexity is 41.588654279086605
At time: 783.4288470745087 and batch: 750, loss is 3.6930311822891237 and perplexity is 40.166414341524586
At time: 784.5832347869873 and batch: 800, loss is 3.661881351470947 and perplexity is 38.93452353359458
At time: 785.7370986938477 and batch: 850, loss is 3.6571162033081053 and perplexity is 38.74943609506715
At time: 786.8963584899902 and batch: 900, loss is 3.630002250671387 and perplexity is 37.71290149643455
At time: 788.0577697753906 and batch: 950, loss is 3.742623643875122 and perplexity is 42.20858531675431
At time: 789.2091205120087 and batch: 1000, loss is 3.711603446006775 and perplexity is 40.91936594637581
At time: 790.3617377281189 and batch: 1050, loss is 3.6545250272750853 and perplexity is 38.649159458279925
At time: 791.514814376831 and batch: 1100, loss is 3.6665034675598145 and perplexity is 39.1148999604946
At time: 792.665953874588 and batch: 1150, loss is 3.638968253135681 and perplexity is 38.05255585974097
At time: 793.8207983970642 and batch: 1200, loss is 3.6781320190429687 and perplexity is 39.572404490509875
At time: 794.9728491306305 and batch: 1250, loss is 3.6555754375457763 and perplexity is 38.689778261797905
At time: 796.1271014213562 and batch: 1300, loss is 3.6528408908843994 and perplexity is 38.584123782213
At time: 797.2829623222351 and batch: 1350, loss is 3.52576012134552 and perplexity is 33.979592415801385
At time: 798.4346113204956 and batch: 1400, loss is 3.557777066230774 and perplexity is 35.08511850071814
At time: 799.5877623558044 and batch: 1450, loss is 3.476824641227722 and perplexity is 32.356814283672264
At time: 800.7425999641418 and batch: 1500, loss is 3.4776636600494384 and perplexity is 32.38397365188436
At time: 801.8975446224213 and batch: 1550, loss is 3.4754627418518065 and perplexity is 32.31277755209784
At time: 803.0544965267181 and batch: 1600, loss is 3.551695103645325 and perplexity is 34.87237971313567
At time: 804.206335067749 and batch: 1650, loss is 3.4947237157821656 and perplexity is 32.94118556595094
At time: 805.3590276241302 and batch: 1700, loss is 3.5058662843704225 and perplexity is 33.310287538651664
At time: 806.5119459629059 and batch: 1750, loss is 3.517069487571716 and perplexity is 33.68556770344783
At time: 807.6650428771973 and batch: 1800, loss is 3.462231707572937 and perplexity is 31.888061993600726
At time: 808.8219256401062 and batch: 1850, loss is 3.491048846244812 and perplexity is 32.82035316422983
At time: 809.975255727768 and batch: 1900, loss is 3.5814766216278078 and perplexity is 35.92655162213996
At time: 811.1290998458862 and batch: 1950, loss is 3.525609612464905 and perplexity is 33.97447857023237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381047022619913 and perplexity of 79.92166940874228
finished 17 epochs...
Completing Train Step...
At time: 814.7725715637207 and batch: 50, loss is 3.7524341917037964 and perplexity is 42.62471254223672
At time: 815.9274303913116 and batch: 100, loss is 3.737229199409485 and perplexity is 41.98150648004345
At time: 817.0834202766418 and batch: 150, loss is 3.7020650339126586 and perplexity is 40.53091571567652
At time: 818.2405850887299 and batch: 200, loss is 3.6986222314834594 and perplexity is 40.3916157093852
At time: 819.396378993988 and batch: 250, loss is 3.6872344636917114 and perplexity is 39.93425447331743
At time: 820.5527639389038 and batch: 300, loss is 3.6858259630203247 and perplexity is 39.878046642756416
At time: 821.7084400653839 and batch: 350, loss is 3.7055475997924803 and perplexity is 40.67231337024051
At time: 822.8666698932648 and batch: 400, loss is 3.692724175453186 and perplexity is 40.15408487045942
At time: 824.0208473205566 and batch: 450, loss is 3.7328434562683106 and perplexity is 41.797789538080416
At time: 825.1774432659149 and batch: 500, loss is 3.7421763706207276 and perplexity is 42.18971076679165
At time: 826.3358528614044 and batch: 550, loss is 3.7157780933380127 and perplexity is 41.09054692973024
At time: 827.495142698288 and batch: 600, loss is 3.673326053619385 and perplexity is 39.382677159479165
At time: 828.6604268550873 and batch: 650, loss is 3.6943915939331053 and perplexity is 40.221094384542276
At time: 829.8195624351501 and batch: 700, loss is 3.7236809968948363 and perplexity is 41.41656811939602
At time: 830.9807140827179 and batch: 750, loss is 3.6889645767211916 and perplexity is 40.00340504921149
At time: 832.1689014434814 and batch: 800, loss is 3.6581497764587403 and perplexity is 38.78950717644694
At time: 833.3235659599304 and batch: 850, loss is 3.6528827476501466 and perplexity is 38.58573882264366
At time: 834.4849739074707 and batch: 900, loss is 3.6258668088912964 and perplexity is 37.557264024597245
At time: 835.6412117481232 and batch: 950, loss is 3.738235297203064 and perplexity is 42.02376523573993
At time: 836.7971189022064 and batch: 1000, loss is 3.707079081535339 and perplexity is 40.73464999712598
At time: 837.9524395465851 and batch: 1050, loss is 3.6506031274795534 and perplexity is 38.4978781766253
At time: 839.108137845993 and batch: 1100, loss is 3.6627874898910524 and perplexity is 38.969819590378336
At time: 840.2642908096313 and batch: 1150, loss is 3.635595541000366 and perplexity is 37.924431727174415
At time: 841.4221603870392 and batch: 1200, loss is 3.6751053857803346 and perplexity is 39.452814403755866
At time: 842.5764300823212 and batch: 1250, loss is 3.6530094528198243 and perplexity is 38.59062814497298
At time: 843.7309818267822 and batch: 1300, loss is 3.6507396793365476 and perplexity is 38.503135492320595
At time: 844.8882358074188 and batch: 1350, loss is 3.5240468978881836 and perplexity is 33.921427619877086
At time: 846.0452122688293 and batch: 1400, loss is 3.5566490745544432 and perplexity is 35.04556509123845
At time: 847.2028563022614 and batch: 1450, loss is 3.4763401174545288 and perplexity is 32.34114043540971
At time: 848.3599700927734 and batch: 1500, loss is 3.4779495286941526 and perplexity is 32.39323253789223
At time: 849.5173869132996 and batch: 1550, loss is 3.4761123037338257 and perplexity is 32.333773519049515
At time: 850.6749181747437 and batch: 1600, loss is 3.552458543777466 and perplexity is 34.899012852422054
At time: 851.8316149711609 and batch: 1650, loss is 3.4959153175354003 and perplexity is 32.98046173655443
At time: 852.9919037818909 and batch: 1700, loss is 3.507391986846924 and perplexity is 33.36114791587818
At time: 854.1487879753113 and batch: 1750, loss is 3.519185724258423 and perplexity is 33.75692982056687
At time: 855.3054187297821 and batch: 1800, loss is 3.46448796749115 and perplexity is 31.9600909772442
At time: 856.4636061191559 and batch: 1850, loss is 3.4933721828460693 and perplexity is 32.8966945410197
At time: 857.6176617145538 and batch: 1900, loss is 3.5836826038360594 and perplexity is 36.005892435858904
At time: 858.7740747928619 and batch: 1950, loss is 3.527455267906189 and perplexity is 34.037241653166504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380716865007267 and perplexity of 79.8952870165851
finished 18 epochs...
Completing Train Step...
At time: 862.3872492313385 and batch: 50, loss is 3.7512127685546877 and perplexity is 42.572681514033334
At time: 863.5648953914642 and batch: 100, loss is 3.7351079988479614 and perplexity is 41.89254966590146
At time: 864.720885515213 and batch: 150, loss is 3.69954665184021 and perplexity is 40.42897180489635
At time: 865.8765678405762 and batch: 200, loss is 3.695638699531555 and perplexity is 40.2712856269096
At time: 867.0299141407013 and batch: 250, loss is 3.6840595054626464 and perplexity is 39.8076659464365
At time: 868.1851742267609 and batch: 300, loss is 3.68249397277832 and perplexity is 39.74539450102055
At time: 869.341897726059 and batch: 350, loss is 3.702179846763611 and perplexity is 40.53556945281085
At time: 870.4982209205627 and batch: 400, loss is 3.6891230726242066 and perplexity is 40.00974592750678
At time: 871.6561117172241 and batch: 450, loss is 3.729269070625305 and perplexity is 41.648654810542254
At time: 872.8179726600647 and batch: 500, loss is 3.738493409156799 and perplexity is 42.034613471857725
At time: 873.9727985858917 and batch: 550, loss is 3.71198682308197 and perplexity is 40.93505650071842
At time: 875.1292054653168 and batch: 600, loss is 3.6699680852890015 and perplexity is 39.25065316706261
At time: 876.2840983867645 and batch: 650, loss is 3.6911560535430907 and perplexity is 40.091167713972844
At time: 877.4369955062866 and batch: 700, loss is 3.720611639022827 and perplexity is 41.28964074242708
At time: 878.5917751789093 and batch: 750, loss is 3.685969352722168 and perplexity is 39.88376515395262
At time: 879.7464537620544 and batch: 800, loss is 3.65539044380188 and perplexity is 38.68262155685996
At time: 880.9008722305298 and batch: 850, loss is 3.6498765039443968 and perplexity is 38.46991487291621
At time: 882.0555853843689 and batch: 900, loss is 3.6229690313339233 and perplexity is 37.44858896191568
At time: 883.2098841667175 and batch: 950, loss is 3.7352839946746825 and perplexity is 41.899923228652476
At time: 884.3636360168457 and batch: 1000, loss is 3.7041215753555297 and perplexity is 40.6143549923206
At time: 885.52015376091 and batch: 1050, loss is 3.6480659294128417 and perplexity is 38.400325242433134
At time: 886.6746203899384 and batch: 1100, loss is 3.660406174659729 and perplexity is 38.877130570114375
At time: 887.8294098377228 and batch: 1150, loss is 3.633527202606201 and perplexity is 37.8460722338658
At time: 889.0187854766846 and batch: 1200, loss is 3.6732017755508424 and perplexity is 39.37778306054864
At time: 890.178829908371 and batch: 1250, loss is 3.6514691925048828 and perplexity is 38.53123428465779
At time: 891.3349432945251 and batch: 1300, loss is 3.649477691650391 and perplexity is 38.45457565685281
At time: 892.4918093681335 and batch: 1350, loss is 3.522938160896301 and perplexity is 33.88383852032073
At time: 893.6458964347839 and batch: 1400, loss is 3.555874714851379 and perplexity is 35.01843772238687
At time: 894.8019688129425 and batch: 1450, loss is 3.4758963346481324 and perplexity is 32.32679117755769
At time: 895.9571225643158 and batch: 1500, loss is 3.477906222343445 and perplexity is 32.39182973557873
At time: 897.11274933815 and batch: 1550, loss is 3.476251039505005 and perplexity is 32.33825968124221
At time: 898.2668716907501 and batch: 1600, loss is 3.5526208591461184 and perplexity is 34.90467795831324
At time: 899.4205324649811 and batch: 1650, loss is 3.4963536787033083 and perplexity is 32.994922259513714
At time: 900.5749650001526 and batch: 1700, loss is 3.5079813814163208 and perplexity is 33.38081659102441
At time: 901.7287135124207 and batch: 1750, loss is 3.52011923789978 and perplexity is 33.78845708832244
At time: 902.8873143196106 and batch: 1800, loss is 3.46548020362854 and perplexity is 31.991818672545936
At time: 904.0473256111145 and batch: 1850, loss is 3.4943442487716676 and perplexity is 32.928687844128504
At time: 905.2039971351624 and batch: 1900, loss is 3.5845663261413576 and perplexity is 36.037725709942094
At time: 906.3680357933044 and batch: 1950, loss is 3.5280715894699095 and perplexity is 34.05822600505695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3805720839389535 and perplexity of 79.88372052890203
finished 19 epochs...
Completing Train Step...
At time: 909.9531166553497 and batch: 50, loss is 3.7495939540863037 and perplexity is 42.503819993291536
At time: 911.1273112297058 and batch: 100, loss is 3.7329849195480347 and perplexity is 41.80370280871915
At time: 912.27987241745 and batch: 150, loss is 3.697233567237854 and perplexity is 40.335564244167585
At time: 913.4353172779083 and batch: 200, loss is 3.6930703687667847 and perplexity is 40.16798835266268
At time: 914.5885090827942 and batch: 250, loss is 3.681361355781555 and perplexity is 39.70040367516219
At time: 915.7421982288361 and batch: 300, loss is 3.6796835708618163 and perplexity is 39.63385078289995
At time: 916.8956537246704 and batch: 350, loss is 3.699344253540039 and perplexity is 40.420789877757386
At time: 918.0718278884888 and batch: 400, loss is 3.6861347818374632 and perplexity is 39.890363635712134
At time: 919.2253720760345 and batch: 450, loss is 3.7263433218002318 and perplexity is 41.526979390318495
At time: 920.3799443244934 and batch: 500, loss is 3.7355112648010254 and perplexity is 41.909446911681734
At time: 921.5341601371765 and batch: 550, loss is 3.7089635276794435 and perplexity is 40.81148462386502
At time: 922.6887037754059 and batch: 600, loss is 3.6672825717926028 and perplexity is 39.14538641914128
At time: 923.8448328971863 and batch: 650, loss is 3.6885415077209474 and perplexity is 39.98648442817845
At time: 924.9977362155914 and batch: 700, loss is 3.7181013727188112 and perplexity is 41.18612273181275
At time: 926.1528408527374 and batch: 750, loss is 3.683520083427429 and perplexity is 39.78619860475354
At time: 927.3063173294067 and batch: 800, loss is 3.6531074905395506 and perplexity is 38.594411667620065
At time: 928.459657907486 and batch: 850, loss is 3.6474549055099486 and perplexity is 38.376868892756086
At time: 929.6118311882019 and batch: 900, loss is 3.620650062561035 and perplexity is 37.36184746780421
At time: 930.7636878490448 and batch: 950, loss is 3.7329543733596804 and perplexity is 41.80242588444194
At time: 931.9224851131439 and batch: 1000, loss is 3.7018215751647947 and perplexity is 40.52104931076663
At time: 933.079820394516 and batch: 1050, loss is 3.6460723781585695 and perplexity is 38.323848481381205
At time: 934.2342193126678 and batch: 1100, loss is 3.658531765937805 and perplexity is 38.80432719045096
At time: 935.3885731697083 and batch: 1150, loss is 3.6319105005264283 and perplexity is 37.784935843155225
At time: 936.5432550907135 and batch: 1200, loss is 3.671694655418396 and perplexity is 39.31848071003516
At time: 937.6989269256592 and batch: 1250, loss is 3.650221209526062 and perplexity is 38.48317795309664
At time: 938.8529560565948 and batch: 1300, loss is 3.64857319355011 and perplexity is 38.41980929164997
At time: 940.0105786323547 and batch: 1350, loss is 3.5220131778717043 and perplexity is 33.85251103581058
At time: 941.1664645671844 and batch: 1400, loss is 3.5551670503616335 and perplexity is 34.9936651838811
At time: 942.3277788162231 and batch: 1450, loss is 3.475368785858154 and perplexity is 32.30974171559502
At time: 943.4829940795898 and batch: 1500, loss is 3.477617497444153 and perplexity is 32.38247875779546
At time: 944.638370513916 and batch: 1550, loss is 3.476077117919922 and perplexity is 32.33263584892671
At time: 945.7939956188202 and batch: 1600, loss is 3.552460584640503 and perplexity is 34.899084076600104
At time: 946.9497742652893 and batch: 1650, loss is 3.496395025253296 and perplexity is 32.99628651391967
At time: 948.1058752536774 and batch: 1700, loss is 3.508110942840576 and perplexity is 33.38514173734476
At time: 949.2612302303314 and batch: 1750, loss is 3.520481643676758 and perplexity is 33.80070443948778
At time: 950.4188027381897 and batch: 1800, loss is 3.46587429523468 and perplexity is 32.00442886437211
At time: 951.5750331878662 and batch: 1850, loss is 3.494694347381592 and perplexity is 32.94021815022366
At time: 952.7316236495972 and batch: 1900, loss is 3.5848507690429687 and perplexity is 36.04797784321464
At time: 953.8890392780304 and batch: 1950, loss is 3.5281568813323974 and perplexity is 34.061131018471194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380532907885175 and perplexity of 79.88059106127103
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fad68d45b38>
ELAPSED
3931.8940675258636


RESULTS SO FAR:
[{'best_accuracy': -79.15217303895258, 'params': {'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.54003238615967, 'params': {'num_layers': 2, 'dropout': 0.532313874403636, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.08424698132469677, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.66990658508242, 'params': {'num_layers': 2, 'dropout': 0.5310812723449767, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.5433392138601495, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.88059106127103, 'params': {'num_layers': 2, 'dropout': 0.10281409912265316, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.34256577207194716, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'dropout': 0.22078712054788474, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.31840880658536375, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.690197467803955 and batch: 50, loss is 7.449011430740357 and perplexity is 1718.1637816473767
At time: 2.9115939140319824 and batch: 100, loss is 6.520932302474976 and perplexity is 679.2113206452908
At time: 4.134342193603516 and batch: 150, loss is 6.155650062561035 and perplexity is 471.3731649324545
At time: 5.358231782913208 and batch: 200, loss is 5.993615417480469 and perplexity is 400.86127406138684
At time: 6.581006050109863 and batch: 250, loss is 5.904846620559693 and perplexity is 366.81096021280973
At time: 7.803005933761597 and batch: 300, loss is 5.8228896045684815 and perplexity is 337.947177798809
At time: 9.026270627975464 and batch: 350, loss is 5.764521102905274 and perplexity is 318.78634162195334
At time: 10.252301454544067 and batch: 400, loss is 5.694592113494873 and perplexity is 297.2555223392003
At time: 11.480157375335693 and batch: 450, loss is 5.618747510910034 and perplexity is 275.5440510997535
At time: 12.703685760498047 and batch: 500, loss is 5.580553379058838 and perplexity is 265.2183314556736
At time: 13.95486831665039 and batch: 550, loss is 5.528571739196777 and perplexity is 251.78404081405952
At time: 15.178707122802734 and batch: 600, loss is 5.554055452346802 and perplexity is 258.28288877168177
At time: 16.402680158615112 and batch: 650, loss is 5.62385890007019 and perplexity is 276.9560695894579
At time: 17.626384973526 and batch: 700, loss is 5.535625057220459 and perplexity is 253.56623151755932
At time: 18.849632263183594 and batch: 750, loss is 5.475949382781982 and perplexity is 238.87714516005354
At time: 20.072280645370483 and batch: 800, loss is 5.470110902786255 and perplexity is 237.48652921853483
At time: 21.295243501663208 and batch: 850, loss is 5.470049695968628 and perplexity is 237.47199386868795
At time: 22.52209162712097 and batch: 900, loss is 5.471503496170044 and perplexity is 237.8174817755491
At time: 23.742757558822632 and batch: 950, loss is 5.507810773849488 and perplexity is 246.61064918713643
At time: 24.965911865234375 and batch: 1000, loss is 5.469698572158814 and perplexity is 237.38862643447868
At time: 26.188551902770996 and batch: 1050, loss is 5.368991403579712 and perplexity is 214.64626703480772
At time: 27.41303825378418 and batch: 1100, loss is 5.452464532852173 and perplexity is 233.33251351271178
At time: 28.636547327041626 and batch: 1150, loss is 5.356574077606201 and perplexity is 211.9974142378173
At time: 29.860809326171875 and batch: 1200, loss is 5.432466630935669 and perplexity is 228.7127000423285
At time: 31.085451126098633 and batch: 1250, loss is 5.366414642333984 and perplexity is 214.0938868339559
At time: 32.31159472465515 and batch: 1300, loss is 5.396943492889404 and perplexity is 220.73071908130123
At time: 33.534894943237305 and batch: 1350, loss is 5.338327207565308 and perplexity is 208.1642033759184
At time: 34.75826621055603 and batch: 1400, loss is 5.354818658828735 and perplexity is 211.62559643954214
At time: 35.98300218582153 and batch: 1450, loss is 5.301663036346436 and perplexity is 200.67025455969048
At time: 37.20708084106445 and batch: 1500, loss is 5.275864496231079 and perplexity is 195.55946387703005
At time: 38.434505224227905 and batch: 1550, loss is 5.261055669784546 and perplexity is 192.68479548385508
At time: 39.65853428840637 and batch: 1600, loss is 5.302733297348023 and perplexity is 200.8851390780724
At time: 40.88206672668457 and batch: 1650, loss is 5.278355875015259 and perplexity is 196.04728399640322
At time: 42.104862213134766 and batch: 1700, loss is 5.2932704639434816 and perplexity is 198.99316232205348
At time: 43.32840871810913 and batch: 1750, loss is 5.31093578338623 and perplexity is 202.53967299580677
At time: 44.55148673057556 and batch: 1800, loss is 5.28220703125 and perplexity is 196.8037484128446
At time: 45.77492356300354 and batch: 1850, loss is 5.258323907852173 and perplexity is 192.1591447977622
At time: 46.999836921691895 and batch: 1900, loss is 5.294967231750488 and perplexity is 199.33109412852497
At time: 48.22750473022461 and batch: 1950, loss is 5.2207575607299805 and perplexity is 185.07433602627253
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.878794399527616 and perplexity of 131.47206551761298
finished 1 epochs...
Completing Train Step...
At time: 52.00287890434265 and batch: 50, loss is 5.102061815261841 and perplexity is 164.36043904668284
At time: 53.18929862976074 and batch: 100, loss is 5.03478006362915 and perplexity is 153.6657921983488
At time: 54.34313464164734 and batch: 150, loss is 4.957996482849121 and perplexity is 142.30839278178792
At time: 55.521613121032715 and batch: 200, loss is 4.940807838439941 and perplexity is 139.8832069598795
At time: 56.68108248710632 and batch: 250, loss is 4.943394937515259 and perplexity is 140.24556720407537
At time: 57.83553910255432 and batch: 300, loss is 4.955527458190918 and perplexity is 141.95746325604122
At time: 58.989296436309814 and batch: 350, loss is 4.949327707290649 and perplexity is 141.0800849192939
At time: 60.14188504219055 and batch: 400, loss is 4.909162120819092 and perplexity is 135.52581256597725
At time: 61.29581570625305 and batch: 450, loss is 4.885996923446656 and perplexity is 132.42241456166656
At time: 62.45397901535034 and batch: 500, loss is 4.882354803085327 and perplexity is 131.94099341834198
At time: 63.6074435710907 and batch: 550, loss is 4.8348526096344 and perplexity is 125.82003717887385
At time: 64.76118493080139 and batch: 600, loss is 4.821911792755127 and perplexity is 124.20231302990203
At time: 65.93124556541443 and batch: 650, loss is 4.884854583740235 and perplexity is 132.27122954825515
At time: 67.10864496231079 and batch: 700, loss is 4.8843582725524906 and perplexity is 132.20559814536065
At time: 68.27086901664734 and batch: 750, loss is 4.838232746124268 and perplexity is 126.24604565549019
At time: 69.43362593650818 and batch: 800, loss is 4.8157093334198 and perplexity is 123.43433736492926
At time: 70.59612822532654 and batch: 850, loss is 4.8127106666564945 and perplexity is 123.06475332664998
At time: 71.76089859008789 and batch: 900, loss is 4.820399284362793 and perplexity is 124.01459798517324
At time: 72.92304849624634 and batch: 950, loss is 4.890099239349365 and perplexity is 132.9667689321823
At time: 74.08523106575012 and batch: 1000, loss is 4.849097089767456 and perplexity is 127.62510379523741
At time: 75.24789953231812 and batch: 1050, loss is 4.773208847045899 and perplexity is 118.29823451125631
At time: 76.41037845611572 and batch: 1100, loss is 4.841627492904663 and perplexity is 126.67534728539621
At time: 77.57280445098877 and batch: 1150, loss is 4.7662975788116455 and perplexity is 117.48346247811811
At time: 78.73603200912476 and batch: 1200, loss is 4.843244972229004 and perplexity is 126.88040783642761
At time: 79.89938592910767 and batch: 1250, loss is 4.793442840576172 and perplexity is 120.71626089070102
At time: 81.06212854385376 and batch: 1300, loss is 4.821441793441773 and perplexity is 124.1439517440174
At time: 82.22596526145935 and batch: 1350, loss is 4.71316424369812 and perplexity is 111.40411254113917
At time: 83.39010167121887 and batch: 1400, loss is 4.734817810058594 and perplexity is 113.84271583096803
At time: 84.55210494995117 and batch: 1450, loss is 4.670507488250732 and perplexity is 106.75190402513847
At time: 85.71536755561829 and batch: 1500, loss is 4.655933542251587 and perplexity is 105.20738971245808
At time: 86.87733387947083 and batch: 1550, loss is 4.656516647338867 and perplexity is 105.26875456595926
At time: 88.0378565788269 and batch: 1600, loss is 4.730751447677612 and perplexity is 113.38073003139155
At time: 89.20239639282227 and batch: 1650, loss is 4.686196928024292 and perplexity is 108.43998952402711
At time: 90.36480736732483 and batch: 1700, loss is 4.713059148788452 and perplexity is 111.39240515119933
At time: 91.52754092216492 and batch: 1750, loss is 4.722693729400635 and perplexity is 112.47081090990301
At time: 92.6903645992279 and batch: 1800, loss is 4.677892894744873 and perplexity is 107.54322876096255
At time: 93.85437250137329 and batch: 1850, loss is 4.688354578018188 and perplexity is 108.67421766706762
At time: 95.0173830986023 and batch: 1900, loss is 4.7657929706573485 and perplexity is 117.42419431981222
At time: 96.18354153633118 and batch: 1950, loss is 4.692512302398682 and perplexity is 109.12699572232073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614241063317587 and perplexity of 100.91121424130581
finished 2 epochs...
Completing Train Step...
At time: 99.8118028640747 and batch: 50, loss is 4.640173273086548 and perplexity is 103.56229058645627
At time: 100.99207639694214 and batch: 100, loss is 4.5951058959960935 and perplexity is 98.99861854992736
At time: 102.14892101287842 and batch: 150, loss is 4.534955682754517 and perplexity is 93.21938398655631
At time: 103.3017930984497 and batch: 200, loss is 4.534437351226806 and perplexity is 93.1710779611918
At time: 104.45388746261597 and batch: 250, loss is 4.53549430847168 and perplexity is 93.26960786883264
At time: 105.60586595535278 and batch: 300, loss is 4.556582002639771 and perplexity is 95.25733344958199
At time: 106.75886058807373 and batch: 350, loss is 4.564211235046387 and perplexity is 95.98685308383872
At time: 107.91128301620483 and batch: 400, loss is 4.530047359466553 and perplexity is 92.76295418210944
At time: 109.0627748966217 and batch: 450, loss is 4.5329037952423095 and perplexity is 93.02830440060768
At time: 110.21491861343384 and batch: 500, loss is 4.541149787902832 and perplexity is 93.79858662199172
At time: 111.36919164657593 and batch: 550, loss is 4.497522048950195 and perplexity is 89.79434939084328
At time: 112.52884340286255 and batch: 600, loss is 4.475353441238403 and perplexity is 87.82563612637672
At time: 113.7248125076294 and batch: 650, loss is 4.533653774261475 and perplexity is 93.09809984638515
At time: 114.87534284591675 and batch: 700, loss is 4.5539136981964115 and perplexity is 95.00349669095796
At time: 116.02777671813965 and batch: 750, loss is 4.5198362445831295 and perplexity is 91.8205606327833
At time: 117.1790862083435 and batch: 800, loss is 4.495617685317993 and perplexity is 89.62351101830814
At time: 118.33184576034546 and batch: 850, loss is 4.491600027084351 and perplexity is 89.26415674604152
At time: 119.4839117527008 and batch: 900, loss is 4.484709157943725 and perplexity is 88.65116357643022
At time: 120.63774132728577 and batch: 950, loss is 4.565581760406494 and perplexity is 96.11849568938588
At time: 121.79102563858032 and batch: 1000, loss is 4.541323347091675 and perplexity is 93.81486764141985
At time: 122.94403791427612 and batch: 1050, loss is 4.469007558822632 and perplexity is 87.27006961071743
At time: 124.0971987247467 and batch: 1100, loss is 4.525931186676026 and perplexity is 92.38191059276112
At time: 125.25088953971863 and batch: 1150, loss is 4.471146965026856 and perplexity is 87.45697560171402
At time: 126.40410423278809 and batch: 1200, loss is 4.545094795227051 and perplexity is 94.16935359156588
At time: 127.55682110786438 and batch: 1250, loss is 4.515247859954834 and perplexity is 91.40021766887749
At time: 128.70893788337708 and batch: 1300, loss is 4.526480464935303 and perplexity is 92.43266790646852
At time: 129.86212420463562 and batch: 1350, loss is 4.407947263717651 and perplexity is 82.10075920349624
At time: 131.0170772075653 and batch: 1400, loss is 4.432233877182007 and perplexity is 84.11911896096623
At time: 132.1693377494812 and batch: 1450, loss is 4.366467728614807 and perplexity is 78.76492067241166
At time: 133.32171297073364 and batch: 1500, loss is 4.365903434753418 and perplexity is 78.72048664928575
At time: 134.47966504096985 and batch: 1550, loss is 4.368295640945434 and perplexity is 78.90902770951973
At time: 135.6412055492401 and batch: 1600, loss is 4.453153486251831 and perplexity is 85.89739359831617
At time: 136.8074426651001 and batch: 1650, loss is 4.403092365264893 and perplexity is 81.70313434981483
At time: 137.97255063056946 and batch: 1700, loss is 4.438427610397339 and perplexity is 84.64174718123411
At time: 139.1360502243042 and batch: 1750, loss is 4.441573610305786 and perplexity is 84.90844941274544
At time: 140.29854345321655 and batch: 1800, loss is 4.397612342834472 and perplexity is 81.25662390199278
At time: 141.46092009544373 and batch: 1850, loss is 4.42673475265503 and perplexity is 83.65780701912698
At time: 142.62283945083618 and batch: 1900, loss is 4.510175533294678 and perplexity is 90.93777971771148
At time: 143.78613448143005 and batch: 1950, loss is 4.439822626113892 and perplexity is 84.7599061464731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.522743686409884 and perplexity of 92.08791203731946
finished 3 epochs...
Completing Train Step...
At time: 147.45314168930054 and batch: 50, loss is 4.392913088798523 and perplexity is 80.87567417498691
At time: 148.6048126220703 and batch: 100, loss is 4.353660717010498 and perplexity is 77.7626094250843
At time: 149.75895595550537 and batch: 150, loss is 4.2998803615570065 and perplexity is 73.69097689845333
At time: 150.91223740577698 and batch: 200, loss is 4.309122428894043 and perplexity is 74.37519077422073
At time: 152.06510424613953 and batch: 250, loss is 4.3049471950531 and perplexity is 74.06530433512377
At time: 153.21750259399414 and batch: 300, loss is 4.324388189315796 and perplexity is 75.51929521126887
At time: 154.36884474754333 and batch: 350, loss is 4.333413677215576 and perplexity is 76.20397885052674
At time: 155.51963710784912 and batch: 400, loss is 4.303110489845276 and perplexity is 73.92939305761584
At time: 156.67257070541382 and batch: 450, loss is 4.3146164894104 and perplexity is 74.78493712821039
At time: 157.8247833251953 and batch: 500, loss is 4.33428243637085 and perplexity is 76.2702105203405
At time: 158.9773108959198 and batch: 550, loss is 4.288880796432495 and perplexity is 72.8848498502413
At time: 160.1300127506256 and batch: 600, loss is 4.264661469459534 and perplexity is 71.14083255196807
At time: 161.28322958946228 and batch: 650, loss is 4.322183227539062 and perplexity is 75.35296149905184
At time: 162.4360613822937 and batch: 700, loss is 4.351110534667969 and perplexity is 77.56455323865126
At time: 163.58784794807434 and batch: 750, loss is 4.324660615921021 and perplexity is 75.53987147912639
At time: 164.7408893108368 and batch: 800, loss is 4.293303122520447 and perplexity is 73.20788417825436
At time: 165.8996226787567 and batch: 850, loss is 4.287651996612549 and perplexity is 72.79534396353972
At time: 167.05673575401306 and batch: 900, loss is 4.276929230690002 and perplexity is 72.01894653294187
At time: 168.2121193408966 and batch: 950, loss is 4.3663490295410154 and perplexity is 78.75557190413664
At time: 169.3666865825653 and batch: 1000, loss is 4.341454439163208 and perplexity is 76.8191869602779
At time: 170.56176900863647 and batch: 1050, loss is 4.2766294765472415 and perplexity is 71.99736179058095
At time: 171.7139208316803 and batch: 1100, loss is 4.3274045753479005 and perplexity is 75.74743446354684
At time: 172.87326574325562 and batch: 1150, loss is 4.275123448371887 and perplexity is 71.88901334355907
At time: 174.02573370933533 and batch: 1200, loss is 4.349853010177612 and perplexity is 77.46707521671571
At time: 175.17650508880615 and batch: 1250, loss is 4.326896772384644 and perplexity is 75.70897945647678
At time: 176.3288493156433 and batch: 1300, loss is 4.334555368423462 and perplexity is 76.29102994646613
At time: 177.48573851585388 and batch: 1350, loss is 4.212395606040954 and perplexity is 67.51809297539097
At time: 178.6419861316681 and batch: 1400, loss is 4.241275310516357 and perplexity is 69.49642486917679
At time: 179.79709386825562 and batch: 1450, loss is 4.172970104217529 and perplexity is 64.9079494717535
At time: 180.94903683662415 and batch: 1500, loss is 4.174448318481446 and perplexity is 65.00396827920524
At time: 182.1075315475464 and batch: 1550, loss is 4.180514149665832 and perplexity is 65.39946968680532
At time: 183.2600541114807 and batch: 1600, loss is 4.272342572212219 and perplexity is 71.68937661137824
At time: 184.41785144805908 and batch: 1650, loss is 4.221058492660522 and perplexity is 68.10553535924687
At time: 185.56938529014587 and batch: 1700, loss is 4.253008580207824 and perplexity is 70.31664770265704
At time: 186.72090601921082 and batch: 1750, loss is 4.25851613521576 and perplexity is 70.70498893155874
At time: 187.87407636642456 and batch: 1800, loss is 4.208265647888184 and perplexity is 67.23982109798199
At time: 189.02718257904053 and batch: 1850, loss is 4.24733570098877 and perplexity is 69.91887916631667
At time: 190.17985272407532 and batch: 1900, loss is 4.339313888549805 and perplexity is 76.65492746810651
At time: 191.33585476875305 and batch: 1950, loss is 4.270703125 and perplexity is 71.57194195301189
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.484040868005088 and perplexity of 88.59193868766641
finished 4 epochs...
Completing Train Step...
At time: 194.98093724250793 and batch: 50, loss is 4.217047843933106 and perplexity is 67.83293499807894
At time: 196.1353566646576 and batch: 100, loss is 4.183776450157166 and perplexity is 65.61317079798954
At time: 197.28938746452332 and batch: 150, loss is 4.136403894424438 and perplexity is 62.577381468761125
At time: 198.45379996299744 and batch: 200, loss is 4.14681568145752 and perplexity is 63.232327500376556
At time: 199.63854503631592 and batch: 250, loss is 4.140532159805298 and perplexity is 62.836251480706856
At time: 200.79282236099243 and batch: 300, loss is 4.155571565628052 and perplexity is 63.78841339493106
At time: 201.949077129364 and batch: 350, loss is 4.161158590316773 and perplexity is 64.14579826482631
At time: 203.10636591911316 and batch: 400, loss is 4.136898984909058 and perplexity is 62.608370605459086
At time: 204.26195812225342 and batch: 450, loss is 4.158695087432862 and perplexity is 63.98796939157227
At time: 205.41784501075745 and batch: 500, loss is 4.177569813728333 and perplexity is 65.20719487763266
At time: 206.57254481315613 and batch: 550, loss is 4.135002212524414 and perplexity is 62.48972933036435
At time: 207.73044228553772 and batch: 600, loss is 4.113658747673035 and perplexity is 61.17011465829084
At time: 208.8919243812561 and batch: 650, loss is 4.170465612411499 and perplexity is 64.74559144119948
At time: 210.04954075813293 and batch: 700, loss is 4.203764843940735 and perplexity is 66.93786787162296
At time: 211.20638608932495 and batch: 750, loss is 4.174133315086364 and perplexity is 64.98349503324383
At time: 212.36733293533325 and batch: 800, loss is 4.136944046020508 and perplexity is 62.611191871788876
At time: 213.52973246574402 and batch: 850, loss is 4.137797517776489 and perplexity is 62.66465156558407
At time: 214.68527793884277 and batch: 900, loss is 4.124902696609497 and perplexity is 61.861789595635976
At time: 215.84473371505737 and batch: 950, loss is 4.218595995903015 and perplexity is 67.93803202211218
At time: 217.00263237953186 and batch: 1000, loss is 4.192912268638611 and perplexity is 66.21534731578079
At time: 218.1576509475708 and batch: 1050, loss is 4.131988978385925 and perplexity is 62.30171655016144
At time: 219.31732606887817 and batch: 1100, loss is 4.177896385192871 and perplexity is 65.22849316427931
At time: 220.4797785282135 and batch: 1150, loss is 4.127943663597107 and perplexity is 62.05019557858799
At time: 221.6356921195984 and batch: 1200, loss is 4.208447484970093 and perplexity is 67.25204890253899
At time: 222.7913374900818 and batch: 1250, loss is 4.183469271659851 and perplexity is 65.59301893804724
At time: 223.94655418395996 and batch: 1300, loss is 4.188097648620605 and perplexity is 65.89731180352028
At time: 225.10277104377747 and batch: 1350, loss is 4.064105520248413 and perplexity is 58.21281504340493
At time: 226.25845980644226 and batch: 1400, loss is 4.098977108001709 and perplexity is 60.278597556507506
At time: 227.41319155693054 and batch: 1450, loss is 4.027926898002624 and perplexity is 56.14439745386495
At time: 228.56783819198608 and batch: 1500, loss is 4.032902979850769 and perplexity is 56.4244728319917
At time: 229.7230715751648 and batch: 1550, loss is 4.037062883377075 and perplexity is 56.6596820801987
At time: 230.87877130508423 and batch: 1600, loss is 4.136277360916138 and perplexity is 62.56946383407723
At time: 232.03513097763062 and batch: 1650, loss is 4.0793467092514035 and perplexity is 59.10684328017205
At time: 233.18993520736694 and batch: 1700, loss is 4.115500345230102 and perplexity is 61.282869184373915
At time: 234.3454442024231 and batch: 1750, loss is 4.119046077728272 and perplexity is 61.50054753175899
At time: 235.50114226341248 and batch: 1800, loss is 4.07185848236084 and perplexity is 58.665890863256436
At time: 236.6568946838379 and batch: 1850, loss is 4.111434774398804 and perplexity is 61.03422512146802
At time: 237.8109986782074 and batch: 1900, loss is 4.203938975334167 and perplexity is 66.94952487072415
At time: 238.9657244682312 and batch: 1950, loss is 4.137220025062561 and perplexity is 62.628473633135734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474576160519622 and perplexity of 87.75739747653004
finished 5 epochs...
Completing Train Step...
At time: 242.6296763420105 and batch: 50, loss is 4.08340060710907 and perplexity is 59.34694272601566
At time: 243.78922200202942 and batch: 100, loss is 4.055363121032715 and perplexity is 57.70611349567589
At time: 244.94368839263916 and batch: 150, loss is 4.0129334926605225 and perplexity is 55.30888101556851
At time: 246.097913980484 and batch: 200, loss is 4.018382487297058 and perplexity is 55.611081408001255
At time: 247.25104641914368 and batch: 250, loss is 4.012844605445862 and perplexity is 55.30396498167855
At time: 248.40571928024292 and batch: 300, loss is 4.024446153640747 and perplexity is 55.949312875712735
At time: 249.55866146087646 and batch: 350, loss is 4.031015000343323 and perplexity is 56.31804508188521
At time: 250.71429228782654 and batch: 400, loss is 4.0062210702896115 and perplexity is 54.938867677528094
At time: 251.873517036438 and batch: 450, loss is 4.03541510105133 and perplexity is 56.56639613605702
At time: 253.03379654884338 and batch: 500, loss is 4.057099933624268 and perplexity is 57.806425286379294
At time: 254.18721771240234 and batch: 550, loss is 4.01418701171875 and perplexity is 55.37825522387287
At time: 255.3407847881317 and batch: 600, loss is 3.997328729629517 and perplexity is 54.45249823695173
At time: 256.49574089050293 and batch: 650, loss is 4.048865041732788 and perplexity is 57.33235028077477
At time: 257.6869351863861 and batch: 700, loss is 4.082742357254029 and perplexity is 59.30789046405211
At time: 258.84009528160095 and batch: 750, loss is 4.057879004478455 and perplexity is 57.85147813490651
At time: 259.99754762649536 and batch: 800, loss is 4.021277675628662 and perplexity is 55.772319256343984
At time: 261.1525733470917 and batch: 850, loss is 4.0183519983291625 and perplexity is 55.60938590937272
At time: 262.30717420578003 and batch: 900, loss is 4.005568490028382 and perplexity is 54.903027352523665
At time: 263.4621443748474 and batch: 950, loss is 4.0988235712051395 and perplexity is 60.269343284190846
At time: 264.62314796447754 and batch: 1000, loss is 4.076249079704285 and perplexity is 58.92403545762152
At time: 265.7778766155243 and batch: 1050, loss is 4.018111543655396 and perplexity is 55.59601598012091
At time: 266.9323778152466 and batch: 1100, loss is 4.0643285322189335 and perplexity is 58.22579864569287
At time: 268.087055683136 and batch: 1150, loss is 4.015403795242309 and perplexity is 55.44567958449945
At time: 269.2500169277191 and batch: 1200, loss is 4.08976683139801 and perplexity is 59.72596386094448
At time: 270.40469098091125 and batch: 1250, loss is 4.068535614013672 and perplexity is 58.471275351380456
At time: 271.5586884021759 and batch: 1300, loss is 4.0698575687408445 and perplexity is 58.54862284391258
At time: 272.71435379981995 and batch: 1350, loss is 3.9455268383026123 and perplexity is 51.703570359228785
At time: 273.8689875602722 and batch: 1400, loss is 3.9847215604782105 and perplexity is 53.77031561236293
At time: 275.027889251709 and batch: 1450, loss is 3.9115770864486694 and perplexity is 49.977709021380754
At time: 276.18871450424194 and batch: 1500, loss is 3.9156813478469847 and perplexity is 50.18325211605765
At time: 277.34894013404846 and batch: 1550, loss is 3.926026015281677 and perplexity is 50.70507556154566
At time: 278.5020446777344 and batch: 1600, loss is 4.027693662643433 and perplexity is 56.131304122131525
At time: 279.65522503852844 and batch: 1650, loss is 3.9711010313034056 and perplexity is 53.04290059429375
At time: 280.8148992061615 and batch: 1700, loss is 4.008253693580627 and perplexity is 55.05065126802959
At time: 281.96726632118225 and batch: 1750, loss is 4.007748255729675 and perplexity is 55.02283361579854
At time: 283.1278247833252 and batch: 1800, loss is 3.959025902748108 and perplexity is 52.40625229144371
At time: 284.29157614707947 and batch: 1850, loss is 4.001579837799072 and perplexity is 54.68447442564048
At time: 285.45471358299255 and batch: 1900, loss is 4.095474939346314 and perplexity is 60.06786097447358
At time: 286.62171745300293 and batch: 1950, loss is 4.022716636657715 and perplexity is 55.852631219288305
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.476435319767442 and perplexity of 87.92070421318921
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 290.29918241500854 and batch: 50, loss is 4.0022331237792965 and perplexity is 54.720210697850526
At time: 291.4970004558563 and batch: 100, loss is 4.003657193183899 and perplexity is 54.798191587639764
At time: 292.6616976261139 and batch: 150, loss is 3.9690807628631593 and perplexity is 52.935847870275026
At time: 293.8257567882538 and batch: 200, loss is 3.977406048774719 and perplexity is 53.3783935423089
At time: 294.9898452758789 and batch: 250, loss is 3.967792510986328 and perplexity is 52.86769707202659
At time: 296.1538498401642 and batch: 300, loss is 3.9807588243484497 and perplexity is 53.557659667957104
At time: 297.31813406944275 and batch: 350, loss is 3.990708212852478 and perplexity is 54.09318528994603
At time: 298.4828586578369 and batch: 400, loss is 3.9487838697433473 and perplexity is 51.872245053766754
At time: 299.6473505496979 and batch: 450, loss is 3.9677118110656737 and perplexity is 52.8634308252129
At time: 300.8115520477295 and batch: 500, loss is 3.9853229236602785 and perplexity is 53.802660825095636
At time: 301.9760265350342 and batch: 550, loss is 3.931307010650635 and perplexity is 50.97355713176204
At time: 303.14055585861206 and batch: 600, loss is 3.9104104042053223 and perplexity is 49.91943491599431
At time: 304.3042252063751 and batch: 650, loss is 3.95762818813324 and perplexity is 52.33305447345213
At time: 305.4693691730499 and batch: 700, loss is 3.98593080997467 and perplexity is 53.835376669038524
At time: 306.6325409412384 and batch: 750, loss is 3.9421282386779786 and perplexity is 51.528148886938766
At time: 307.7965409755707 and batch: 800, loss is 3.9063874006271364 and perplexity is 49.71901227152675
At time: 308.96022057533264 and batch: 850, loss is 3.8968330097198485 and perplexity is 49.24623951708433
At time: 310.12756991386414 and batch: 900, loss is 3.8702912092208863 and perplexity is 47.956349378739155
At time: 311.29523253440857 and batch: 950, loss is 3.9633544969558714 and perplexity is 52.63358936156288
At time: 312.4597795009613 and batch: 1000, loss is 3.9274859380722047 and perplexity is 50.77915511901291
At time: 313.6310935020447 and batch: 1050, loss is 3.871787443161011 and perplexity is 48.0281570034303
At time: 314.82369232177734 and batch: 1100, loss is 3.900620770454407 and perplexity is 49.43312620704422
At time: 315.9872443675995 and batch: 1150, loss is 3.853507628440857 and perplexity is 47.15818686356802
At time: 317.1565613746643 and batch: 1200, loss is 3.9113423871994017 and perplexity is 49.965980666965145
At time: 318.32020330429077 and batch: 1250, loss is 3.8823348569869993 and perplexity is 48.537410784721196
At time: 319.48226141929626 and batch: 1300, loss is 3.88223021030426 and perplexity is 48.53233177144941
At time: 320.64568567276 and batch: 1350, loss is 3.7552169370651245 and perplexity is 42.74349145242351
At time: 321.81138277053833 and batch: 1400, loss is 3.7795992612838747 and perplexity is 43.79848646903559
At time: 322.973313331604 and batch: 1450, loss is 3.691425304412842 and perplexity is 40.10196374910487
At time: 324.1346204280853 and batch: 1500, loss is 3.6931802892684935 and perplexity is 40.172403880769124
At time: 325.29573702812195 and batch: 1550, loss is 3.696689567565918 and perplexity is 40.313627677734864
At time: 326.45749020576477 and batch: 1600, loss is 3.7863220834732054 and perplexity is 44.093927893070926
At time: 327.6189820766449 and batch: 1650, loss is 3.7261091375350954 and perplexity is 41.51725556379466
At time: 328.7811768054962 and batch: 1700, loss is 3.7383666944503786 and perplexity is 42.02928740560472
At time: 329.94205808639526 and batch: 1750, loss is 3.727080307006836 and perplexity is 41.557595440206285
At time: 331.1028950214386 and batch: 1800, loss is 3.674231586456299 and perplexity is 39.41835561842274
At time: 332.26423168182373 and batch: 1850, loss is 3.707658190727234 and perplexity is 40.75824663922463
At time: 333.42691922187805 and batch: 1900, loss is 3.787801909446716 and perplexity is 44.1592275369792
At time: 334.5879316329956 and batch: 1950, loss is 3.712679204940796 and perplexity is 40.963409005476834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.412295603197674 and perplexity of 82.45853848522621
finished 7 epochs...
Completing Train Step...
At time: 338.1984820365906 and batch: 50, loss is 3.895181393623352 and perplexity is 49.16497076606864
At time: 339.3835346698761 and batch: 100, loss is 3.876821117401123 and perplexity is 48.270524588115926
At time: 340.5429353713989 and batch: 150, loss is 3.838155026435852 and perplexity is 46.439715305382784
At time: 341.7015392780304 and batch: 200, loss is 3.8444542407989504 and perplexity is 46.73317233104172
At time: 342.8667275905609 and batch: 250, loss is 3.837211694717407 and perplexity is 46.39592790520849
At time: 344.05117297172546 and batch: 300, loss is 3.8486235666275026 and perplexity is 46.92842490645052
At time: 345.21285486221313 and batch: 350, loss is 3.8588894748687745 and perplexity is 47.41266916116803
At time: 346.37542366981506 and batch: 400, loss is 3.8245310735702516 and perplexity is 45.81131319323772
At time: 347.536883354187 and batch: 450, loss is 3.8505158615112305 and perplexity is 47.01731139800543
At time: 348.69853925704956 and batch: 500, loss is 3.8702727222442626 and perplexity is 47.955462819024156
At time: 349.8661684989929 and batch: 550, loss is 3.8203366804122925 and perplexity is 45.619564949501445
At time: 351.02930998802185 and batch: 600, loss is 3.804009222984314 and perplexity is 44.88076125068796
At time: 352.1917984485626 and batch: 650, loss is 3.846478614807129 and perplexity is 46.82787357345408
At time: 353.35345220565796 and batch: 700, loss is 3.8821233034133913 and perplexity is 48.52714360808326
At time: 354.5160527229309 and batch: 750, loss is 3.8439179706573485 and perplexity is 46.70811744479241
At time: 355.6870539188385 and batch: 800, loss is 3.808190608024597 and perplexity is 45.06881788898702
At time: 356.8561987876892 and batch: 850, loss is 3.801795506477356 and perplexity is 44.78151785756011
At time: 358.01706647872925 and batch: 900, loss is 3.776223449707031 and perplexity is 43.650880316821805
At time: 359.17780089378357 and batch: 950, loss is 3.8713486337661744 and perplexity is 48.007086420243546
At time: 360.3392345905304 and batch: 1000, loss is 3.839357361793518 and perplexity is 46.49558499741697
At time: 361.50075936317444 and batch: 1050, loss is 3.789156789779663 and perplexity is 44.21909855576134
At time: 362.6621358394623 and batch: 1100, loss is 3.8190569734573363 and perplexity is 45.56122261346212
At time: 363.8240895271301 and batch: 1150, loss is 3.7767563104629516 and perplexity is 43.67414635613316
At time: 364.98586893081665 and batch: 1200, loss is 3.8360489273071288 and perplexity is 46.34201158441574
At time: 366.146311044693 and batch: 1250, loss is 3.811813793182373 and perplexity is 45.2324067384276
At time: 367.30897188186646 and batch: 1300, loss is 3.812243399620056 and perplexity is 45.25184304623688
At time: 368.4717028141022 and batch: 1350, loss is 3.6857895994186403 and perplexity is 39.876596559717626
At time: 369.6331858634949 and batch: 1400, loss is 3.7171548223495483 and perplexity is 41.14715643682224
At time: 370.7941813468933 and batch: 1450, loss is 3.6310194635391237 and perplexity is 37.751283062918546
At time: 371.957243680954 and batch: 1500, loss is 3.6362556076049803 and perplexity is 37.94947264148296
At time: 373.1229295730591 and batch: 1550, loss is 3.644172101020813 and perplexity is 38.25109169920013
At time: 374.28626322746277 and batch: 1600, loss is 3.738384313583374 and perplexity is 42.03002793173291
At time: 375.4494454860687 and batch: 1650, loss is 3.680384840965271 and perplexity is 39.66165456538004
At time: 376.6125991344452 and batch: 1700, loss is 3.697450819015503 and perplexity is 40.34432816915678
At time: 377.78201174736023 and batch: 1750, loss is 3.6894844245910643 and perplexity is 40.02420614034699
At time: 378.94837760925293 and batch: 1800, loss is 3.6442026138305663 and perplexity is 38.25225886529068
At time: 380.11646366119385 and batch: 1850, loss is 3.6823278427124024 and perplexity is 39.73879214445232
At time: 381.28572177886963 and batch: 1900, loss is 3.764498953819275 and perplexity is 43.142084267053576
At time: 382.4576561450958 and batch: 1950, loss is 3.6932444763183594 and perplexity is 40.17498251161672
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.417687136627907 and perplexity of 82.90431708734802
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 386.14060282707214 and batch: 50, loss is 3.8567844009399415 and perplexity is 47.31296696448574
At time: 387.33607816696167 and batch: 100, loss is 3.86049186706543 and perplexity is 47.488703754604835
At time: 388.49756717681885 and batch: 150, loss is 3.8363618230819703 and perplexity is 46.356514072803506
At time: 389.66105127334595 and batch: 200, loss is 3.850348072052002 and perplexity is 47.00942305056087
At time: 390.81994676589966 and batch: 250, loss is 3.8437696218490602 and perplexity is 46.70118886516805
At time: 391.97683691978455 and batch: 300, loss is 3.8481118202209474 and perplexity is 46.904415597502116
At time: 393.13426446914673 and batch: 350, loss is 3.8668745231628416 and perplexity is 47.79277718496403
At time: 394.29172015190125 and batch: 400, loss is 3.846700143814087 and perplexity is 46.838248454910925
At time: 395.4480457305908 and batch: 450, loss is 3.8803393125534056 and perplexity is 48.440648803335804
At time: 396.60872530937195 and batch: 500, loss is 3.8957463026046755 and perplexity is 49.192752345914066
At time: 397.7672073841095 and batch: 550, loss is 3.845418105125427 and perplexity is 46.77823848405431
At time: 398.92851305007935 and batch: 600, loss is 3.8118786287307738 and perplexity is 45.23533950139659
At time: 400.08368372917175 and batch: 650, loss is 3.838260684013367 and perplexity is 46.44462227242698
At time: 401.2377989292145 and batch: 700, loss is 3.8746767091751098 and perplexity is 48.16712378450604
At time: 402.41518354415894 and batch: 750, loss is 3.8299004077911376 and perplexity is 46.05795099271647
At time: 403.57204699516296 and batch: 800, loss is 3.7972464418411254 and perplexity is 44.57826649062703
At time: 404.727844953537 and batch: 850, loss is 3.7974770402908327 and perplexity is 44.58854735510055
At time: 405.8839192390442 and batch: 900, loss is 3.767680969238281 and perplexity is 43.27958168783994
At time: 407.0398061275482 and batch: 950, loss is 3.8618826198577882 and perplexity is 47.5547947494221
At time: 408.2018427848816 and batch: 1000, loss is 3.818239440917969 and perplexity is 45.52399005293086
At time: 409.3617069721222 and batch: 1050, loss is 3.76652325630188 and perplexity is 43.22950534884374
At time: 410.5180950164795 and batch: 1100, loss is 3.788154191970825 and perplexity is 44.174786801586215
At time: 411.6738200187683 and batch: 1150, loss is 3.7451476097106933 and perplexity is 42.31525290010336
At time: 412.831823348999 and batch: 1200, loss is 3.7949958658218383 and perplexity is 44.47805252495522
At time: 413.99033880233765 and batch: 1250, loss is 3.7758520889282225 and perplexity is 43.634673101459995
At time: 415.1486668586731 and batch: 1300, loss is 3.7772940683364866 and perplexity is 43.69763878826013
At time: 416.30555629730225 and batch: 1350, loss is 3.658469376564026 and perplexity is 38.801906288297694
At time: 417.46181178092957 and batch: 1400, loss is 3.6811200618743896 and perplexity is 39.69082536528374
At time: 418.61915469169617 and batch: 1450, loss is 3.586851863861084 and perplexity is 36.12018548795651
At time: 419.7763035297394 and batch: 1500, loss is 3.5826889419555665 and perplexity is 35.970132522645905
At time: 420.9319717884064 and batch: 1550, loss is 3.5846567296981813 and perplexity is 36.040983795795164
At time: 422.0896408557892 and batch: 1600, loss is 3.6728626346588134 and perplexity is 39.36443070836765
At time: 423.25029373168945 and batch: 1650, loss is 3.6136635541915894 and perplexity is 37.10172832810762
At time: 424.4050705432892 and batch: 1700, loss is 3.626108555793762 and perplexity is 37.56634447438136
At time: 425.56102561950684 and batch: 1750, loss is 3.6144249486923217 and perplexity is 37.12998813709065
At time: 426.71608424186707 and batch: 1800, loss is 3.5652351808547973 and perplexity is 35.34776554452919
At time: 427.87381529808044 and batch: 1850, loss is 3.597977066040039 and perplexity is 36.52427346665563
At time: 429.02892780303955 and batch: 1900, loss is 3.680495662689209 and perplexity is 39.666050181873615
At time: 430.18601059913635 and batch: 1950, loss is 3.6200387573242185 and perplexity is 37.33901495431857
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3891241029251455 and perplexity of 80.56981719783819
finished 9 epochs...
Completing Train Step...
At time: 433.8658266067505 and batch: 50, loss is 3.8534241819381716 and perplexity is 47.154251841985435
At time: 435.017865896225 and batch: 100, loss is 3.8361523580551147 and perplexity is 46.34680502122719
At time: 436.17048716545105 and batch: 150, loss is 3.7969971466064454 and perplexity is 44.567154726333115
At time: 437.3294186592102 and batch: 200, loss is 3.803940382003784 and perplexity is 44.87767172142087
At time: 438.48250913619995 and batch: 250, loss is 3.794197955131531 and perplexity is 44.442577166327595
At time: 439.63518023490906 and batch: 300, loss is 3.7957441568374635 and perplexity is 44.51134750766676
At time: 440.7884039878845 and batch: 350, loss is 3.812647833824158 and perplexity is 45.27014814071706
At time: 441.94095945358276 and batch: 400, loss is 3.7926868772506714 and perplexity is 44.37547168457656
At time: 443.09419989585876 and batch: 450, loss is 3.8277591609954835 and perplexity is 45.95943506383822
At time: 444.24562335014343 and batch: 500, loss is 3.844162874221802 and perplexity is 46.71955783008193
At time: 445.3995590209961 and batch: 550, loss is 3.7960733556747437 and perplexity is 44.52600300366583
At time: 446.5587499141693 and batch: 600, loss is 3.766701192855835 and perplexity is 43.237198142448996
At time: 447.71118092536926 and batch: 650, loss is 3.7938565111160276 and perplexity is 44.42740510467284
At time: 448.86456775665283 and batch: 700, loss is 3.8331118392944337 and perplexity is 46.206100706514874
At time: 450.0202977657318 and batch: 750, loss is 3.7906174993515016 and perplexity is 44.28373701379388
At time: 451.17318964004517 and batch: 800, loss is 3.7577518796920777 and perplexity is 42.85198120047888
At time: 452.3258445262909 and batch: 850, loss is 3.760682578086853 and perplexity is 42.97775164058943
At time: 453.4758634567261 and batch: 900, loss is 3.7317651081085206 and perplexity is 41.75274126187691
At time: 454.6335349082947 and batch: 950, loss is 3.827552247047424 and perplexity is 45.94992639945015
At time: 455.7904965877533 and batch: 1000, loss is 3.7841609621047976 and perplexity is 43.99873845829303
At time: 456.94387006759644 and batch: 1050, loss is 3.7352158975601197 and perplexity is 41.897070061927515
At time: 458.09685039520264 and batch: 1100, loss is 3.7573310422897337 and perplexity is 42.83395127812412
At time: 459.27403020858765 and batch: 1150, loss is 3.7174513578414916 and perplexity is 41.15935983837973
At time: 460.42777276039124 and batch: 1200, loss is 3.7691257858276366 and perplexity is 43.34215794016099
At time: 461.5859339237213 and batch: 1250, loss is 3.7515470123291017 and perplexity is 42.586913546141076
At time: 462.7386939525604 and batch: 1300, loss is 3.754512166976929 and perplexity is 42.71337773105429
At time: 463.8918414115906 and batch: 1350, loss is 3.636837749481201 and perplexity is 37.97157105026856
At time: 465.04443979263306 and batch: 1400, loss is 3.6621373748779296 and perplexity is 38.94449295910758
At time: 466.19709610939026 and batch: 1450, loss is 3.5710048198699953 and perplexity is 35.5522988660432
At time: 467.3497803211212 and batch: 1500, loss is 3.5684321212768553 and perplexity is 35.46095107232206
At time: 468.50287318229675 and batch: 1550, loss is 3.5726308488845824 and perplexity is 35.61015496063141
At time: 469.65603709220886 and batch: 1600, loss is 3.663548469543457 and perplexity is 38.99948611652424
At time: 470.8097620010376 and batch: 1650, loss is 3.6058974933624266 and perplexity is 36.814709992516654
At time: 471.96340823173523 and batch: 1700, loss is 3.621524453163147 and perplexity is 37.39453060293836
At time: 473.1170537471771 and batch: 1750, loss is 3.6122892045974733 and perplexity is 37.05077260634723
At time: 474.2697298526764 and batch: 1800, loss is 3.5663417768478394 and perplexity is 35.38690289086526
At time: 475.4248275756836 and batch: 1850, loss is 3.6006305980682374 and perplexity is 36.62132049786464
At time: 476.58012676239014 and batch: 1900, loss is 3.6837481689453124 and perplexity is 39.795274295444365
At time: 477.7393867969513 and batch: 1950, loss is 3.6241567516326905 and perplexity is 37.49309383562504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389846872728924 and perplexity of 80.62807167855857
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 481.4266173839569 and batch: 50, loss is 3.8453154373168945 and perplexity is 46.773436111350904
At time: 482.6004755496979 and batch: 100, loss is 3.8462296772003173 and perplexity is 46.8162178055143
At time: 483.76078820228577 and batch: 150, loss is 3.816208906173706 and perplexity is 45.4316457952712
At time: 484.9120969772339 and batch: 200, loss is 3.831097140312195 and perplexity is 46.113103035061805
At time: 486.0642626285553 and batch: 250, loss is 3.8237369775772097 and perplexity is 45.77494905321483
At time: 487.22262358665466 and batch: 300, loss is 3.8184619474411012 and perplexity is 45.53412056468733
At time: 488.4158139228821 and batch: 350, loss is 3.829566965103149 and perplexity is 46.04259586590387
At time: 489.56757283210754 and batch: 400, loss is 3.816118378639221 and perplexity is 45.42753316654565
At time: 490.72492694854736 and batch: 450, loss is 3.851790494918823 and perplexity is 47.07727944436703
At time: 491.8779902458191 and batch: 500, loss is 3.8747067213058473 and perplexity is 48.16856940421527
At time: 493.0316424369812 and batch: 550, loss is 3.8367849683761595 and perplexity is 46.37613376428575
At time: 494.182986497879 and batch: 600, loss is 3.8060805797576904 and perplexity is 44.97382166688747
At time: 495.33627343177795 and batch: 650, loss is 3.8222214651107786 and perplexity is 45.705629088177744
At time: 496.4890465736389 and batch: 700, loss is 3.856147518157959 and perplexity is 47.28284374396002
At time: 497.6410484313965 and batch: 750, loss is 3.8071865701675414 and perplexity is 45.023589798810605
At time: 498.7981159687042 and batch: 800, loss is 3.76802282333374 and perplexity is 43.29437951929521
At time: 499.9498221874237 and batch: 850, loss is 3.7696419286727907 and perplexity is 43.36453445911866
At time: 501.10906767845154 and batch: 900, loss is 3.7385736417770388 and perplexity is 42.037986154335094
At time: 502.2630388736725 and batch: 950, loss is 3.8493959712982178 and perplexity is 46.964686643602306
At time: 503.4162893295288 and batch: 1000, loss is 3.8064444732666014 and perplexity is 44.990190326706866
At time: 504.57161831855774 and batch: 1050, loss is 3.7537505722045896 and perplexity is 42.6808598301688
At time: 505.72979521751404 and batch: 1100, loss is 3.7683312940597533 and perplexity is 43.30773662801042
At time: 506.88406205177307 and batch: 1150, loss is 3.7293429231643676 and perplexity is 41.65173078303134
At time: 508.0372304916382 and batch: 1200, loss is 3.776291913986206 and perplexity is 43.65386894518402
At time: 509.19073700904846 and batch: 1250, loss is 3.753731646537781 and perplexity is 42.68005207408023
At time: 510.34326434135437 and batch: 1300, loss is 3.757378840446472 and perplexity is 42.835998710972405
At time: 511.49601650238037 and batch: 1350, loss is 3.6423255968093873 and perplexity is 38.180526067204184
At time: 512.6495771408081 and batch: 1400, loss is 3.6721655797958372 and perplexity is 39.33700110159513
At time: 513.8050992488861 and batch: 1450, loss is 3.5778480434417723 and perplexity is 35.79642554971455
At time: 514.9570903778076 and batch: 1500, loss is 3.5739122200012208 and perplexity is 35.655814031516954
At time: 516.1180367469788 and batch: 1550, loss is 3.5761323595046997 and perplexity is 35.73506285194386
At time: 517.2810242176056 and batch: 1600, loss is 3.659952459335327 and perplexity is 38.85949542117714
At time: 518.4459083080292 and batch: 1650, loss is 3.5933986949920653 and perplexity is 36.357434008373765
At time: 519.6107864379883 and batch: 1700, loss is 3.6023464488983152 and perplexity is 36.684211161107875
At time: 520.7728517055511 and batch: 1750, loss is 3.5955616188049317 and perplexity is 36.436157473903705
At time: 521.9345774650574 and batch: 1800, loss is 3.5467857551574706 and perplexity is 34.70159860352371
At time: 523.0977101325989 and batch: 1850, loss is 3.5718208360671997 and perplexity is 35.58132195781173
At time: 524.2595007419586 and batch: 1900, loss is 3.6603434038162233 and perplexity is 38.87469029642523
At time: 525.420159816742 and batch: 1950, loss is 3.608708801269531 and perplexity is 36.91835309589288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373673407976018 and perplexity of 79.33452516478285
finished 11 epochs...
Completing Train Step...
At time: 529.1095316410065 and batch: 50, loss is 3.8488496780395507 and perplexity is 46.939037158601764
At time: 530.274379491806 and batch: 100, loss is 3.839076113700867 and perplexity is 46.48251004155914
At time: 531.4408383369446 and batch: 150, loss is 3.7999999570846557 and perplexity is 44.70118257493414
At time: 532.6077983379364 and batch: 200, loss is 3.809115352630615 and perplexity is 45.110514311528995
At time: 533.7730650901794 and batch: 250, loss is 3.8005550050735475 and perplexity is 44.726000763429084
At time: 534.9388196468353 and batch: 300, loss is 3.7963330364227295 and perplexity is 44.537567050845865
At time: 536.1049864292145 and batch: 350, loss is 3.8073588752746583 and perplexity is 45.03134826166587
At time: 537.2715911865234 and batch: 400, loss is 3.79135892868042 and perplexity is 44.31658244999023
At time: 538.4367463588715 and batch: 450, loss is 3.8268943405151368 and perplexity is 45.9197055850395
At time: 539.6030976772308 and batch: 500, loss is 3.8492109966278076 and perplexity is 46.95600016958309
At time: 540.7688939571381 and batch: 550, loss is 3.812739219665527 and perplexity is 45.2742853803335
At time: 541.9358131885529 and batch: 600, loss is 3.7839870023727418 and perplexity is 43.991085115246086
At time: 543.1037456989288 and batch: 650, loss is 3.801369209289551 and perplexity is 44.76243169091042
At time: 544.2701272964478 and batch: 700, loss is 3.8379020214080812 and perplexity is 46.42796731013587
At time: 545.4428629875183 and batch: 750, loss is 3.790253610610962 and perplexity is 44.26762559206581
At time: 546.6520247459412 and batch: 800, loss is 3.7509581327438353 and perplexity is 42.56184236483219
At time: 547.8163442611694 and batch: 850, loss is 3.7538403940200804 and perplexity is 42.68469367466432
At time: 548.9833652973175 and batch: 900, loss is 3.7225572776794436 and perplexity is 41.37005366545213
At time: 550.1497950553894 and batch: 950, loss is 3.832904806137085 and perplexity is 46.196535501788276
At time: 551.3169732093811 and batch: 1000, loss is 3.7903537559509277 and perplexity is 44.27205901046959
At time: 552.483541727066 and batch: 1050, loss is 3.7388791608810426 and perplexity is 42.05083152435214
At time: 553.6503608226776 and batch: 1100, loss is 3.7547515344619753 and perplexity is 42.723603148627035
At time: 554.8165392875671 and batch: 1150, loss is 3.717765645980835 and perplexity is 41.17229777001263
At time: 555.9826142787933 and batch: 1200, loss is 3.7648144865036013 and perplexity is 43.15569915256752
At time: 557.1465680599213 and batch: 1250, loss is 3.743645639419556 and perplexity is 42.25174435329986
At time: 558.3152456283569 and batch: 1300, loss is 3.7473995971679686 and perplexity is 42.410653699269055
At time: 559.480076789856 and batch: 1350, loss is 3.6330061054229734 and perplexity is 37.82635588974034
At time: 560.6446175575256 and batch: 1400, loss is 3.6645492792129515 and perplexity is 39.03853671718485
At time: 561.8085107803345 and batch: 1450, loss is 3.5725374174118043 and perplexity is 35.6068280068311
At time: 562.972409248352 and batch: 1500, loss is 3.57091055393219 and perplexity is 35.54894765320455
At time: 564.1372709274292 and batch: 1550, loss is 3.5748691511154176 and perplexity is 35.68995051989471
At time: 565.3019638061523 and batch: 1600, loss is 3.6602421617507934 and perplexity is 38.87075474171188
At time: 566.4660353660583 and batch: 1650, loss is 3.594814772605896 and perplexity is 36.408955427323804
At time: 567.6278223991394 and batch: 1700, loss is 3.605264439582825 and perplexity is 36.791411676532526
At time: 568.7921106815338 and batch: 1750, loss is 3.599827961921692 and perplexity is 36.59193869532458
At time: 569.9571108818054 and batch: 1800, loss is 3.552328543663025 and perplexity is 34.89447627164177
At time: 571.1231873035431 and batch: 1850, loss is 3.5777323818206788 and perplexity is 35.7922855165322
At time: 572.2907931804657 and batch: 1900, loss is 3.666273694038391 and perplexity is 39.10591342466408
At time: 573.4568500518799 and batch: 1950, loss is 3.614462332725525 and perplexity is 37.13137623174613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372586130541424 and perplexity of 79.24831340233203
finished 12 epochs...
Completing Train Step...
At time: 577.1299815177917 and batch: 50, loss is 3.843713183403015 and perplexity is 46.69855319701725
At time: 578.3170833587646 and batch: 100, loss is 3.8316349887847903 and perplexity is 46.137911568113594
At time: 579.4810724258423 and batch: 150, loss is 3.7914005661010743 and perplexity is 44.31842771659147
At time: 580.64435505867 and batch: 200, loss is 3.799197573661804 and perplexity is 44.66532947294508
At time: 581.8069043159485 and batch: 250, loss is 3.7898801136016846 and perplexity is 44.251094853582224
At time: 582.970372915268 and batch: 300, loss is 3.7849827575683594 and perplexity is 44.03491128325646
At time: 584.1339380741119 and batch: 350, loss is 3.7959664487838745 and perplexity is 44.521243121558506
At time: 585.299015045166 and batch: 400, loss is 3.7797125720977784 and perplexity is 43.803449592367606
At time: 586.4626641273499 and batch: 450, loss is 3.8152190113067626 and perplexity is 45.38669549400845
At time: 587.6262800693512 and batch: 500, loss is 3.8379761600494384 and perplexity is 46.43140954415292
At time: 588.7890796661377 and batch: 550, loss is 3.8010640430450437 and perplexity is 44.74877379180718
At time: 589.9522075653076 and batch: 600, loss is 3.773395552635193 and perplexity is 43.52761449386701
At time: 591.1149039268494 and batch: 650, loss is 3.7911648845672605 and perplexity is 44.307983912325255
At time: 592.278284072876 and batch: 700, loss is 3.8286118030548097 and perplexity is 45.998638722165424
At time: 593.4412224292755 and batch: 750, loss is 3.781504650115967 and perplexity is 43.88201917188362
At time: 594.6038098335266 and batch: 800, loss is 3.7421338844299314 and perplexity is 42.18791832476766
At time: 595.7678966522217 and batch: 850, loss is 3.7453417873382566 and perplexity is 42.323470373320156
At time: 596.933830499649 and batch: 900, loss is 3.714288258552551 and perplexity is 41.02937438336935
At time: 598.0994277000427 and batch: 950, loss is 3.824807686805725 and perplexity is 45.82398696158662
At time: 599.2630863189697 and batch: 1000, loss is 3.78242112159729 and perplexity is 43.92225422532084
At time: 600.4258515834808 and batch: 1050, loss is 3.73152907371521 and perplexity is 41.74288734190188
At time: 601.5897476673126 and batch: 1100, loss is 3.7478023624420165 and perplexity is 42.427738678215945
At time: 602.7545492649078 and batch: 1150, loss is 3.7116899251937867 and perplexity is 40.92290477289111
At time: 603.96093916893 and batch: 1200, loss is 3.7590266609191896 and perplexity is 42.90664293513198
At time: 605.1229238510132 and batch: 1250, loss is 3.738442325592041 and perplexity is 42.03246624880271
At time: 606.2889091968536 and batch: 1300, loss is 3.742398943901062 and perplexity is 42.1991021142061
At time: 607.4526104927063 and batch: 1350, loss is 3.628380832672119 and perplexity is 37.651802665901116
At time: 608.6235120296478 and batch: 1400, loss is 3.660554404258728 and perplexity is 38.88289373871456
At time: 609.790869474411 and batch: 1450, loss is 3.569220952987671 and perplexity is 35.48893483081055
At time: 610.9575273990631 and batch: 1500, loss is 3.5684735059738157 and perplexity is 35.462418643403396
At time: 612.1222848892212 and batch: 1550, loss is 3.5731422233581545 and perplexity is 35.628369741768346
At time: 613.2864239215851 and batch: 1600, loss is 3.6591233015060425 and perplexity is 38.82728812061954
At time: 614.4509720802307 and batch: 1650, loss is 3.5940490198135375 and perplexity is 36.381085840007465
At time: 615.615335226059 and batch: 1700, loss is 3.605289077758789 and perplexity is 36.7923181609744
At time: 616.780189037323 and batch: 1750, loss is 3.6001751136779787 and perplexity is 36.60464385629048
At time: 617.9445195198059 and batch: 1800, loss is 3.553296504020691 and perplexity is 34.92826909379183
At time: 619.1088027954102 and batch: 1850, loss is 3.5790539979934692 and perplexity is 35.839620452350474
At time: 620.2723853588104 and batch: 1900, loss is 3.6675237798690796 and perplexity is 39.15482974135939
At time: 621.4370322227478 and batch: 1950, loss is 3.615448708534241 and perplexity is 37.168019792195246
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37267328306686 and perplexity of 79.25522039395813
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 625.0909056663513 and batch: 50, loss is 3.8418030309677125 and perplexity is 46.60943698177704
At time: 626.2788219451904 and batch: 100, loss is 3.836428108215332 and perplexity is 46.359586922362006
At time: 627.4431943893433 and batch: 150, loss is 3.799846043586731 and perplexity is 44.694302989006815
At time: 628.6085538864136 and batch: 200, loss is 3.810304856300354 and perplexity is 45.16420536036547
At time: 629.7743365764618 and batch: 250, loss is 3.8036881399154665 and perplexity is 44.86635311136196
At time: 630.9393723011017 and batch: 300, loss is 3.7968651342391966 and perplexity is 44.56127169906087
At time: 632.1053371429443 and batch: 350, loss is 3.8085750007629393 and perplexity is 45.08614534537006
At time: 633.2947742938995 and batch: 400, loss is 3.7970745849609373 and perplexity is 44.57060606709086
At time: 634.4597387313843 and batch: 450, loss is 3.831163754463196 and perplexity is 46.11617492258496
At time: 635.6240468025208 and batch: 500, loss is 3.8550387811660767 and perplexity is 47.230448557627774
At time: 636.7942054271698 and batch: 550, loss is 3.821139988899231 and perplexity is 45.65622625639383
At time: 637.9603683948517 and batch: 600, loss is 3.792392067909241 and perplexity is 44.362391309196724
At time: 639.1247515678406 and batch: 650, loss is 3.8042919301986693 and perplexity is 44.89345115935914
At time: 640.2889187335968 and batch: 700, loss is 3.8404588413238527 and perplexity is 46.54682714845197
At time: 641.453430891037 and batch: 750, loss is 3.791650137901306 and perplexity is 44.32948972670562
At time: 642.6177108287811 and batch: 800, loss is 3.750689706802368 and perplexity is 42.55041919543092
At time: 643.7831201553345 and batch: 850, loss is 3.754919571876526 and perplexity is 42.73078291565826
At time: 644.9477887153625 and batch: 900, loss is 3.717298994064331 and perplexity is 41.15308912057649
At time: 646.1120295524597 and batch: 950, loss is 3.8313791084289552 and perplexity is 46.1261072931895
At time: 647.2775280475616 and batch: 1000, loss is 3.791095356941223 and perplexity is 44.30490339048125
At time: 648.4426748752594 and batch: 1050, loss is 3.7425162744522096 and perplexity is 42.20405364859254
At time: 649.6058197021484 and batch: 1100, loss is 3.7583660364151 and perplexity is 42.87830711611953
At time: 650.7695858478546 and batch: 1150, loss is 3.7227024936676028 and perplexity is 41.37606169489577
At time: 651.9351997375488 and batch: 1200, loss is 3.773060803413391 and perplexity is 43.51304609730404
At time: 653.1000180244446 and batch: 1250, loss is 3.746963453292847 and perplexity is 42.3921605855405
At time: 654.2635791301727 and batch: 1300, loss is 3.7455668163299563 and perplexity is 42.33299545285282
At time: 655.4287283420563 and batch: 1350, loss is 3.6250582551956176 and perplexity is 37.52690923336362
At time: 656.5934045314789 and batch: 1400, loss is 3.6554111528396604 and perplexity is 38.68342264502609
At time: 657.7575905323029 and batch: 1450, loss is 3.5610340070724487 and perplexity is 35.199574943853975
At time: 658.9219453334808 and batch: 1500, loss is 3.5583742332458494 and perplexity is 35.10607643327698
At time: 660.0866062641144 and batch: 1550, loss is 3.5672358322143554 and perplexity is 35.418554888510016
At time: 661.252405166626 and batch: 1600, loss is 3.6542350006103517 and perplexity is 38.63795179680638
At time: 662.4181218147278 and batch: 1650, loss is 3.587478852272034 and perplexity is 36.142839526826606
At time: 663.583390712738 and batch: 1700, loss is 3.597060842514038 and perplexity is 36.49082439378907
At time: 664.7481639385223 and batch: 1750, loss is 3.590880899429321 and perplexity is 36.26600856593908
At time: 665.9139039516449 and batch: 1800, loss is 3.5414621162414552 and perplexity is 34.51735069257383
At time: 667.0791115760803 and batch: 1850, loss is 3.565945086479187 and perplexity is 35.37286803124288
At time: 668.2469854354858 and batch: 1900, loss is 3.6564116287231445 and perplexity is 38.722143843055626
At time: 669.4142096042633 and batch: 1950, loss is 3.6068579626083372 and perplexity is 36.850086375505974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369963889898256 and perplexity of 79.04077747751498
finished 14 epochs...
Completing Train Step...
At time: 673.0726115703583 and batch: 50, loss is 3.8406104612350465 and perplexity is 46.553885109300744
At time: 674.262629032135 and batch: 100, loss is 3.8312718534469603 and perplexity is 46.12116030368165
At time: 675.4263668060303 and batch: 150, loss is 3.791920199394226 and perplexity is 44.34146303157312
At time: 676.5883691310883 and batch: 200, loss is 3.800923438072205 and perplexity is 44.7424823339991
At time: 677.7492079734802 and batch: 250, loss is 3.7943136262893677 and perplexity is 44.447718188013916
At time: 678.9094090461731 and batch: 300, loss is 3.7885720252990724 and perplexity is 44.193248356438005
At time: 680.0718092918396 and batch: 350, loss is 3.800164976119995 and perplexity is 44.708559729629926
At time: 681.2334747314453 and batch: 400, loss is 3.786882772445679 and perplexity is 44.11865780444004
At time: 682.3953530788422 and batch: 450, loss is 3.8217474365234376 and perplexity is 45.68396844767455
At time: 683.5597286224365 and batch: 500, loss is 3.8442673444747926 and perplexity is 46.72443888906634
At time: 684.7235522270203 and batch: 550, loss is 3.809884009361267 and perplexity is 45.14520214178693
At time: 685.8864033222198 and batch: 600, loss is 3.782193560600281 and perplexity is 43.912260370507354
At time: 687.0515027046204 and batch: 650, loss is 3.7959777688980103 and perplexity is 44.52174710996471
At time: 688.2145700454712 and batch: 700, loss is 3.8337124824523925 and perplexity is 46.2338624213676
At time: 689.3789520263672 and batch: 750, loss is 3.785438070297241 and perplexity is 44.054965504003434
At time: 690.5417094230652 and batch: 800, loss is 3.7446065664291384 and perplexity is 42.292364709123774
At time: 691.7354440689087 and batch: 850, loss is 3.7485716772079467 and perplexity is 42.46039152261334
At time: 692.8989896774292 and batch: 900, loss is 3.7115237092971802 and perplexity is 40.91610330085459
At time: 694.065633058548 and batch: 950, loss is 3.825504937171936 and perplexity is 45.85594889471675
At time: 695.2290546894073 and batch: 1000, loss is 3.784768099784851 and perplexity is 44.025459861250354
At time: 696.3945777416229 and batch: 1050, loss is 3.736146674156189 and perplexity is 41.9360850284772
At time: 697.5572090148926 and batch: 1100, loss is 3.7518392181396485 and perplexity is 42.59935950803514
At time: 698.7203550338745 and batch: 1150, loss is 3.7169812059402467 and perplexity is 41.14001323537515
At time: 699.884768486023 and batch: 1200, loss is 3.7674218797683716 and perplexity is 43.268369856458975
At time: 701.0487205982208 and batch: 1250, loss is 3.742394971847534 and perplexity is 42.198934497446565
At time: 702.2126343250275 and batch: 1300, loss is 3.741722574234009 and perplexity is 42.17056957191999
At time: 703.3771450519562 and batch: 1350, loss is 3.6226938486099245 and perplexity is 37.43828517497233
At time: 704.5410861968994 and batch: 1400, loss is 3.6542821025848387 and perplexity is 38.639771763487815
At time: 705.7046408653259 and batch: 1450, loss is 3.561120810508728 and perplexity is 35.202630520530036
At time: 706.8683667182922 and batch: 1500, loss is 3.559873328208923 and perplexity is 35.15874324204215
At time: 708.0298202037811 and batch: 1550, loss is 3.5699846076965334 and perplexity is 35.51604647365591
At time: 709.193109035492 and batch: 1600, loss is 3.6574674701690673 and perplexity is 38.763049878743864
At time: 710.3548152446747 and batch: 1650, loss is 3.590770525932312 and perplexity is 36.26200598064483
At time: 711.5157947540283 and batch: 1700, loss is 3.600540270805359 and perplexity is 36.61801274361352
At time: 712.6785359382629 and batch: 1750, loss is 3.595125675201416 and perplexity is 36.42027682590123
At time: 713.8412940502167 and batch: 1800, loss is 3.545515012741089 and perplexity is 34.657529816230735
At time: 715.0083751678467 and batch: 1850, loss is 3.569877209663391 and perplexity is 35.51223232493935
At time: 716.1696128845215 and batch: 1900, loss is 3.660525388717651 and perplexity is 38.88176554688172
At time: 717.3350021839142 and batch: 1950, loss is 3.6103857278823854 and perplexity is 36.98031440246409
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369080441497093 and perplexity of 78.97097986486014
finished 15 epochs...
Completing Train Step...
At time: 721.037926197052 and batch: 50, loss is 3.8393817234039305 and perplexity is 46.49671771854198
At time: 722.1941649913788 and batch: 100, loss is 3.8283421897888186 and perplexity is 45.98623855064888
At time: 723.3506848812103 and batch: 150, loss is 3.7883246755599975 and perplexity is 44.182318519790016
At time: 724.5075905323029 and batch: 200, loss is 3.7964341688156127 and perplexity is 44.54207146934239
At time: 725.6671097278595 and batch: 250, loss is 3.7896157121658325 and perplexity is 44.239396347184005
At time: 726.8251869678497 and batch: 300, loss is 3.7839924049377442 and perplexity is 43.99132278058495
At time: 727.9812541007996 and batch: 350, loss is 3.7954574966430665 and perplexity is 44.49858970480183
At time: 729.1415529251099 and batch: 400, loss is 3.781639590263367 and perplexity is 43.88794101755726
At time: 730.2989280223846 and batch: 450, loss is 3.816800136566162 and perplexity is 45.458514307002375
At time: 731.4588770866394 and batch: 500, loss is 3.839163966178894 and perplexity is 46.48659382463381
At time: 732.6130330562592 and batch: 550, loss is 3.804533109664917 and perplexity is 44.90427984372344
At time: 733.7694249153137 and batch: 600, loss is 3.7773581171035766 and perplexity is 43.70043765778037
At time: 734.9274201393127 and batch: 650, loss is 3.7915788984298704 and perplexity is 44.32633182977326
At time: 736.0846350193024 and batch: 700, loss is 3.829721279144287 and perplexity is 46.04970143316671
At time: 737.2407987117767 and batch: 750, loss is 3.781810874938965 and perplexity is 43.89545899313575
At time: 738.3968150615692 and batch: 800, loss is 3.740983214378357 and perplexity is 42.13940186918245
At time: 739.5517613887787 and batch: 850, loss is 3.7449361515045165 and perplexity is 42.30630593861874
At time: 740.7068846225739 and batch: 900, loss is 3.7081772613525392 and perplexity is 40.779408539579286
At time: 741.8624520301819 and batch: 950, loss is 3.822061996459961 and perplexity is 45.69834105429419
At time: 743.0199179649353 and batch: 1000, loss is 3.781300115585327 and perplexity is 43.873044701514594
At time: 744.1829867362976 and batch: 1050, loss is 3.7330331134796144 and perplexity is 41.80571754206067
At time: 745.3399519920349 and batch: 1100, loss is 3.7488422775268555 and perplexity is 42.47188287281175
At time: 746.4970815181732 and batch: 1150, loss is 3.7144136667251586 and perplexity is 41.03452012488627
At time: 747.6539216041565 and batch: 1200, loss is 3.7649278354644777 and perplexity is 43.160591083464766
At time: 748.8121383190155 and batch: 1250, loss is 3.740478210449219 and perplexity is 42.11812667814667
At time: 749.9704611301422 and batch: 1300, loss is 3.7401005697250365 and perplexity is 42.10222416119473
At time: 751.1259741783142 and batch: 1350, loss is 3.6215496921539305 and perplexity is 37.39547441506198
At time: 752.2805383205414 and batch: 1400, loss is 3.6536452960968018 and perplexity is 38.61517353911826
At time: 753.4352512359619 and batch: 1450, loss is 3.5609965038299563 and perplexity is 35.1982548704129
At time: 754.5908014774323 and batch: 1500, loss is 3.560336289405823 and perplexity is 35.17502414431718
At time: 755.7485845088959 and batch: 1550, loss is 3.571015167236328 and perplexity is 35.552666740606796
At time: 756.9075357913971 and batch: 1600, loss is 3.65869026184082 and perplexity is 38.81047800475646
At time: 758.0627593994141 and batch: 1650, loss is 3.5921729373931885 and perplexity is 36.31289590939544
At time: 759.2179439067841 and batch: 1700, loss is 3.6020250844955446 and perplexity is 36.672424055576485
At time: 760.3725655078888 and batch: 1750, loss is 3.597046856880188 and perplexity is 36.49031405004896
At time: 761.5272958278656 and batch: 1800, loss is 3.547421088218689 and perplexity is 34.723652681494265
At time: 762.6820070743561 and batch: 1850, loss is 3.571720070838928 and perplexity is 35.57773677841619
At time: 763.8364973068237 and batch: 1900, loss is 3.662231969833374 and perplexity is 38.948177085931
At time: 764.9952068328857 and batch: 1950, loss is 3.611772155761719 and perplexity is 37.03162049922133
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368669944585756 and perplexity of 78.93856917423963
finished 16 epochs...
Completing Train Step...
At time: 768.6761195659637 and batch: 50, loss is 3.8378049516677857 and perplexity is 46.42346077813411
At time: 769.8294360637665 and batch: 100, loss is 3.8258899211883546 and perplexity is 45.87360610075188
At time: 770.9857378005981 and batch: 150, loss is 3.785567965507507 and perplexity is 44.06068840469149
At time: 772.1388120651245 and batch: 200, loss is 3.793189330101013 and perplexity is 44.397773869238655
At time: 773.2916090488434 and batch: 250, loss is 3.7861581659317016 and perplexity is 44.08670071716208
At time: 774.4504208564758 and batch: 300, loss is 3.7805268144607544 and perplexity is 43.83913074125033
At time: 775.6053943634033 and batch: 350, loss is 3.791962447166443 and perplexity is 44.34333639917555
At time: 776.7638838291168 and batch: 400, loss is 3.7779457330703736 and perplexity is 43.726124278899334
At time: 777.9397428035736 and batch: 450, loss is 3.8132569646835326 and perplexity is 45.29773198519059
At time: 779.0910303592682 and batch: 500, loss is 3.835618243217468 and perplexity is 46.32205711468822
At time: 780.2427506446838 and batch: 550, loss is 3.800803861618042 and perplexity is 44.73713250647424
At time: 781.3950366973877 and batch: 600, loss is 3.7739885568618776 and perplexity is 43.55343420808257
At time: 782.5517981052399 and batch: 650, loss is 3.788403615951538 and perplexity is 44.1858064269797
At time: 783.7078964710236 and batch: 700, loss is 3.826761441230774 and perplexity is 45.913603294533104
At time: 784.8615126609802 and batch: 750, loss is 3.7790655851364137 and perplexity is 43.77511849753129
At time: 786.0193254947662 and batch: 800, loss is 3.7382764196395875 and perplexity is 42.02549339089105
At time: 787.1749682426453 and batch: 850, loss is 3.7422525882720947 and perplexity is 42.19292649000403
At time: 788.3277177810669 and batch: 900, loss is 3.705700092315674 and perplexity is 40.67851606685087
At time: 789.478217124939 and batch: 950, loss is 3.819590172767639 and perplexity is 45.58552230364949
At time: 790.6336960792542 and batch: 1000, loss is 3.7788381385803222 and perplexity is 43.7651631297865
At time: 791.7875411510468 and batch: 1050, loss is 3.73082839012146 and perplexity is 41.713649030184534
At time: 792.9398484230042 and batch: 1100, loss is 3.7467598915100098 and perplexity is 42.38353204000424
At time: 794.091747045517 and batch: 1150, loss is 3.7126402997970582 and perplexity is 40.9618153491624
At time: 795.2440321445465 and batch: 1200, loss is 3.763213257789612 and perplexity is 43.08665230256418
At time: 796.3958239555359 and batch: 1250, loss is 3.7391538619995117 and perplexity is 42.06238452154241
At time: 797.5519015789032 and batch: 1300, loss is 3.738960361480713 and perplexity is 42.05424621572418
At time: 798.7048959732056 and batch: 1350, loss is 3.620622115135193 and perplexity is 37.36080331493355
At time: 799.8580522537231 and batch: 1400, loss is 3.652979302406311 and perplexity is 38.589464639116855
At time: 801.0131261348724 and batch: 1450, loss is 3.5606105804443358 and perplexity is 35.184673661546995
At time: 802.1731300354004 and batch: 1500, loss is 3.560294280052185 and perplexity is 35.173546495326434
At time: 803.3331999778748 and batch: 1550, loss is 3.571278204917908 and perplexity is 35.56201966167164
At time: 804.486846446991 and batch: 1600, loss is 3.659063491821289 and perplexity is 38.82496594220229
At time: 805.6415467262268 and batch: 1650, loss is 3.592711315155029 and perplexity is 36.33245122862325
At time: 806.7955861091614 and batch: 1700, loss is 3.6026501417160035 and perplexity is 36.69535358441139
At time: 807.9490203857422 and batch: 1750, loss is 3.597913312911987 and perplexity is 36.521945004196475
At time: 809.1030349731445 and batch: 1800, loss is 3.5483411931991578 and perplexity is 34.75561679017932
At time: 810.2587368488312 and batch: 1850, loss is 3.5726411724090577 and perplexity is 35.6105225848353
At time: 811.4115896224976 and batch: 1900, loss is 3.6630024766921996 and perplexity is 38.978198487877265
At time: 812.5652222633362 and batch: 1950, loss is 3.6123259353637693 and perplexity is 37.05213353461074
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368491665152616 and perplexity of 78.92449730527407
finished 17 epochs...
Completing Train Step...
At time: 816.2033586502075 and batch: 50, loss is 3.8361287689208985 and perplexity is 46.345711753117726
At time: 817.3569934368134 and batch: 100, loss is 3.8236966800689696 and perplexity is 45.773104473994394
At time: 818.5117394924164 and batch: 150, loss is 3.783193473815918 and perplexity is 43.95619077961841
At time: 819.6639401912689 and batch: 200, loss is 3.790506248474121 and perplexity is 44.27881068323178
At time: 820.8178110122681 and batch: 250, loss is 3.783310127258301 and perplexity is 43.96131871967702
At time: 821.9708490371704 and batch: 300, loss is 3.7776434230804443 and perplexity is 43.71290743260193
At time: 823.1229646205902 and batch: 350, loss is 3.7890776014328003 and perplexity is 44.21559705708772
At time: 824.2757692337036 and batch: 400, loss is 3.7749746513366698 and perplexity is 43.596403191169934
At time: 825.4295027256012 and batch: 450, loss is 3.810383563041687 and perplexity is 45.16776022768845
At time: 826.580824136734 and batch: 500, loss is 3.8328176069259645 and perplexity is 46.19250737596326
At time: 827.7343618869781 and batch: 550, loss is 3.7977902126312255 and perplexity is 44.602513441612324
At time: 828.8881437778473 and batch: 600, loss is 3.7712711763381956 and perplexity is 43.435243611367014
At time: 830.0444955825806 and batch: 650, loss is 3.7858129930496216 and perplexity is 44.07148580965194
At time: 831.1978983879089 and batch: 700, loss is 3.8243277502059936 and perplexity is 45.80199962978281
At time: 832.3509256839752 and batch: 750, loss is 3.7767590141296385 and perplexity is 43.67426443662737
At time: 833.5047926902771 and batch: 800, loss is 3.736032509803772 and perplexity is 41.93129769576359
At time: 834.65695977211 and batch: 850, loss is 3.7400252389907838 and perplexity is 42.099052689191154
At time: 835.8559019565582 and batch: 900, loss is 3.70359721660614 and perplexity is 40.59306408245482
At time: 837.0106298923492 and batch: 950, loss is 3.8175148963928223 and perplexity is 45.49101784153524
At time: 838.166463136673 and batch: 1000, loss is 3.7768236589431763 and perplexity is 43.677087842566564
At time: 839.3215534687042 and batch: 1050, loss is 3.729039640426636 and perplexity is 41.63910044746639
At time: 840.4818043708801 and batch: 1100, loss is 3.745054769515991 and perplexity is 42.311324526143565
At time: 841.6352431774139 and batch: 1150, loss is 3.711166763305664 and perplexity is 40.901501068052156
At time: 842.7907762527466 and batch: 1200, loss is 3.761791172027588 and perplexity is 43.0254229348163
At time: 843.9445643424988 and batch: 1250, loss is 3.7380103492736816 and perplexity is 42.01431313991985
At time: 845.0975856781006 and batch: 1300, loss is 3.737950301170349 and perplexity is 42.011790335848545
At time: 846.2515277862549 and batch: 1350, loss is 3.619725956916809 and perplexity is 37.327337121739205
At time: 847.4049611091614 and batch: 1400, loss is 3.652234683036804 and perplexity is 38.56074087175161
At time: 848.560138463974 and batch: 1450, loss is 3.560045142173767 and perplexity is 35.16478452409094
At time: 849.7138178348541 and batch: 1500, loss is 3.5599602890014648 and perplexity is 35.161800807161455
At time: 850.8742792606354 and batch: 1550, loss is 3.571136894226074 and perplexity is 35.55699472311738
At time: 852.0316157341003 and batch: 1600, loss is 3.658999176025391 and perplexity is 38.822468963915426
At time: 853.187091588974 and batch: 1650, loss is 3.5927959489822388 and perplexity is 36.33552631314888
At time: 854.342366695404 and batch: 1700, loss is 3.6028265953063965 and perplexity is 36.70182918260657
At time: 855.4979038238525 and batch: 1750, loss is 3.598240404129028 and perplexity is 36.53389296556669
At time: 856.6557877063751 and batch: 1800, loss is 3.5487541818618773 and perplexity is 34.76997343024022
At time: 857.8159756660461 and batch: 1850, loss is 3.5730961561203003 and perplexity is 35.626728478989605
At time: 858.975522518158 and batch: 1900, loss is 3.66333046913147 and perplexity is 38.9909851391255
At time: 860.1313502788544 and batch: 1950, loss is 3.6124987411499023 and perplexity is 37.058536910928396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368432333303052 and perplexity of 78.91981470778799
finished 18 epochs...
Completing Train Step...
At time: 863.7693874835968 and batch: 50, loss is 3.834444603919983 and perplexity is 46.26772361831803
At time: 864.9527130126953 and batch: 100, loss is 3.8216623210906984 and perplexity is 45.68008020240807
At time: 866.1099145412445 and batch: 150, loss is 3.7810310173034667 and perplexity is 43.861240128931776
At time: 867.2653958797455 and batch: 200, loss is 3.7881261110305786 and perplexity is 44.173546349454256
At time: 868.4211895465851 and batch: 250, loss is 3.7808091259002685 and perplexity is 43.851508776505206
At time: 869.5774369239807 and batch: 300, loss is 3.7751021575927735 and perplexity is 43.60196235972728
At time: 870.7340278625488 and batch: 350, loss is 3.7865268325805665 and perplexity is 44.10295700976732
At time: 871.8900792598724 and batch: 400, loss is 3.7723915719985963 and perplexity is 43.48393554183791
At time: 873.0458002090454 and batch: 450, loss is 3.8078770780563356 and perplexity is 45.054689678869074
At time: 874.2019083499908 and batch: 500, loss is 3.8304230070114134 and perplexity is 46.082027132530754
At time: 875.3574759960175 and batch: 550, loss is 3.7951507663726805 and perplexity is 44.484942733426486
At time: 876.5136313438416 and batch: 600, loss is 3.768897366523743 and perplexity is 43.332258885225706
At time: 877.6692607402802 and batch: 650, loss is 3.7835462474823 and perplexity is 43.97170010167928
At time: 878.8246872425079 and batch: 700, loss is 3.8221940851211547 and perplexity is 45.704377685659324
At time: 879.980194568634 and batch: 750, loss is 3.7747176122665405 and perplexity is 43.58519865229651
At time: 881.1362755298615 and batch: 800, loss is 3.7340638732910154 and perplexity is 41.84883141179467
At time: 882.2926788330078 and batch: 850, loss is 3.7380733346939086 and perplexity is 42.01695951242908
At time: 883.4477114677429 and batch: 900, loss is 3.701724662780762 and perplexity is 40.517122509555314
At time: 884.605465888977 and batch: 950, loss is 3.81568443775177 and perplexity is 45.4078245789789
At time: 885.7605633735657 and batch: 1000, loss is 3.775050330162048 and perplexity is 43.59970264060182
At time: 886.9147713184357 and batch: 1050, loss is 3.7274461650848387 and perplexity is 41.572802403826074
At time: 888.0709292888641 and batch: 1100, loss is 3.743512496948242 and perplexity is 42.24611922611932
At time: 889.2264127731323 and batch: 1150, loss is 3.7098060846328735 and perplexity is 40.84588511416573
At time: 890.3829672336578 and batch: 1200, loss is 3.7604787397384642 and perplexity is 42.96899201948123
At time: 891.5385410785675 and batch: 1250, loss is 3.7369183349609374 and perplexity is 41.96845795044939
At time: 892.6935386657715 and batch: 1300, loss is 3.73696750164032 and perplexity is 41.97052145089293
At time: 893.857659816742 and batch: 1350, loss is 3.6188163232803343 and perplexity is 37.29339835859368
At time: 895.0134670734406 and batch: 1400, loss is 3.65143452167511 and perplexity is 38.52989839795125
At time: 896.1696684360504 and batch: 1450, loss is 3.5593754196166993 and perplexity is 35.14124175912107
At time: 897.3261806964874 and batch: 1500, loss is 3.5594661808013917 and perplexity is 35.14443136459869
At time: 898.4861426353455 and batch: 1550, loss is 3.570777258872986 and perplexity is 35.544209469917696
At time: 899.6481297016144 and batch: 1600, loss is 3.658701848983765 and perplexity is 38.810927709918246
At time: 900.8021223545074 and batch: 1650, loss is 3.5926355934143066 and perplexity is 36.32970017633005
At time: 901.9605040550232 and batch: 1700, loss is 3.602759237289429 and perplexity is 36.69935710343186
At time: 903.1180119514465 and batch: 1750, loss is 3.5982728958129884 and perplexity is 36.53508003255556
At time: 904.2737553119659 and batch: 1800, loss is 3.548888487815857 and perplexity is 34.7746435582976
At time: 905.4290800094604 and batch: 1850, loss is 3.57329393863678 and perplexity is 35.633775519869886
At time: 906.582811832428 and batch: 1900, loss is 3.663429832458496 and perplexity is 38.99485960561971
At time: 907.7448289394379 and batch: 1950, loss is 3.6124807691574095 and perplexity is 37.05787090116601
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368445108103198 and perplexity of 78.92082289908814
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 911.3824660778046 and batch: 50, loss is 3.8338610315322876 and perplexity is 46.240730929232924
At time: 912.5612182617188 and batch: 100, loss is 3.8227448749542234 and perplexity is 45.72955812614405
At time: 913.7163228988647 and batch: 150, loss is 3.782936110496521 and perplexity is 43.9448795240649
At time: 914.8698287010193 and batch: 200, loss is 3.7907195711135864 and perplexity is 44.288257363558685
At time: 916.0241956710815 and batch: 250, loss is 3.7840487861633303 and perplexity is 43.99380313520054
At time: 917.1796081066132 and batch: 300, loss is 3.7780144023895263 and perplexity is 43.72912702517985
At time: 918.3349938392639 and batch: 350, loss is 3.790001163482666 and perplexity is 44.256451767567896
At time: 919.4890534877777 and batch: 400, loss is 3.7771678829193114 and perplexity is 43.69212513135892
At time: 920.6432435512543 and batch: 450, loss is 3.81322066783905 and perplexity is 45.29608785029595
At time: 921.8209586143494 and batch: 500, loss is 3.8356134128570556 and perplexity is 46.32183336299771
At time: 922.9777932167053 and batch: 550, loss is 3.801625518798828 and perplexity is 44.773906198261024
At time: 924.1345393657684 and batch: 600, loss is 3.774845585823059 and perplexity is 43.59077676209727
At time: 925.2888281345367 and batch: 650, loss is 3.787334704399109 and perplexity is 44.13860094177538
At time: 926.4435474872589 and batch: 700, loss is 3.825911350250244 and perplexity is 45.87458913962887
At time: 927.5961122512817 and batch: 750, loss is 3.7770167207717895 and perplexity is 43.685521035051536
At time: 928.7538447380066 and batch: 800, loss is 3.7356122303009034 and perplexity is 41.9136785335591
At time: 929.9119317531586 and batch: 850, loss is 3.7402052736282347 and perplexity is 42.106632659187184
At time: 931.064954996109 and batch: 900, loss is 3.7011453104019165 and perplexity is 40.49365561670192
At time: 932.2180454730988 and batch: 950, loss is 3.815641279220581 and perplexity is 45.40586488625462
At time: 933.3730676174164 and batch: 1000, loss is 3.7748425722122194 and perplexity is 43.59064539665786
At time: 934.5268633365631 and batch: 1050, loss is 3.7280979681015016 and perplexity is 41.59990851480681
At time: 935.6816248893738 and batch: 1100, loss is 3.7451225662231447 and perplexity is 42.314193191863694
At time: 936.8356325626373 and batch: 1150, loss is 3.711970763206482 and perplexity is 40.934399094086864
At time: 937.9880793094635 and batch: 1200, loss is 3.764810953140259 and perplexity is 43.155546668071516
At time: 939.142838716507 and batch: 1250, loss is 3.7399085330963135 and perplexity is 42.0941397682797
At time: 940.2960300445557 and batch: 1300, loss is 3.7386780166625977 and perplexity is 42.04237409332041
At time: 941.4509394168854 and batch: 1350, loss is 3.616452765464783 and perplexity is 37.20535734143791
At time: 942.6048541069031 and batch: 1400, loss is 3.6478251695632933 and perplexity is 38.39108109875913
At time: 943.7630980014801 and batch: 1450, loss is 3.5543645429611206 and perplexity is 34.965593773863645
At time: 944.9171571731567 and batch: 1500, loss is 3.5527727460861205 and perplexity is 34.9099799256797
At time: 946.0739243030548 and batch: 1550, loss is 3.5641477346420287 and perplexity is 35.30934764324448
At time: 947.2276859283447 and batch: 1600, loss is 3.6524872398376464 and perplexity is 38.57048087900506
At time: 948.3818809986115 and batch: 1650, loss is 3.5867761850357054 and perplexity is 36.11745205817902
At time: 949.5414326190948 and batch: 1700, loss is 3.596796655654907 and perplexity is 36.48118527082625
At time: 950.6959657669067 and batch: 1750, loss is 3.5928804588317873 and perplexity is 36.33859715276714
At time: 951.8534197807312 and batch: 1800, loss is 3.5436740589141844 and perplexity is 34.593785597169514
At time: 953.0108468532562 and batch: 1850, loss is 3.5683985996246337 and perplexity is 35.4597623825763
At time: 954.1677503585815 and batch: 1900, loss is 3.6581648921966554 and perplexity is 38.79009351290272
At time: 955.3238587379456 and batch: 1950, loss is 3.608543643951416 and perplexity is 36.91225626318846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367930993368459 and perplexity of 78.88025896930846
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fad68d45b38>
ELAPSED
4914.225828409195


RESULTS SO FAR:
[{'best_accuracy': -79.15217303895258, 'params': {'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.54003238615967, 'params': {'num_layers': 2, 'dropout': 0.532313874403636, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.08424698132469677, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.66990658508242, 'params': {'num_layers': 2, 'dropout': 0.5310812723449767, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.5433392138601495, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.88059106127103, 'params': {'num_layers': 2, 'dropout': 0.10281409912265316, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.34256577207194716, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -78.88025896930846, 'params': {'num_layers': 2, 'dropout': 0.22078712054788474, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.31840880658536375, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}]
SETTINGS FOR THIS RUN
{'num_layers': 2, 'dropout': 0.22685778667030246, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.31510939884661804, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.712623119354248 and batch: 50, loss is 7.435045785903931 and perplexity is 1694.33529389016
At time: 2.9339914321899414 and batch: 100, loss is 6.530457782745361 and perplexity is 685.712046795444
At time: 4.161386966705322 and batch: 150, loss is 6.163132791519165 and perplexity is 474.91355192270345
At time: 5.383475303649902 and batch: 200, loss is 6.020789022445679 and perplexity is 411.9034686260055
At time: 6.605215549468994 and batch: 250, loss is 5.914425058364868 and perplexity is 370.3413168407213
At time: 7.827902793884277 and batch: 300, loss is 5.829485273361206 and perplexity is 340.18353247306266
At time: 9.05012845993042 and batch: 350, loss is 5.774809150695801 and perplexity is 322.0829595436926
At time: 10.278093814849854 and batch: 400, loss is 5.702162570953369 and perplexity is 299.514422289899
At time: 11.499685525894165 and batch: 450, loss is 5.62432783126831 and perplexity is 277.0859733865883
At time: 12.748926401138306 and batch: 500, loss is 5.592191686630249 and perplexity is 268.32305579457216
At time: 13.970653533935547 and batch: 550, loss is 5.537705535888672 and perplexity is 254.09431980093393
At time: 15.193927526473999 and batch: 600, loss is 5.558369493484497 and perplexity is 259.39953868400875
At time: 16.41579580307007 and batch: 650, loss is 5.637024736404419 and perplexity is 280.6265372421148
At time: 17.637423753738403 and batch: 700, loss is 5.547278060913086 and perplexity is 256.53832301411705
At time: 18.857759714126587 and batch: 750, loss is 5.486212530136108 and perplexity is 241.34140037715719
At time: 20.083807945251465 and batch: 800, loss is 5.477200059890747 and perplexity is 239.17609024022937
At time: 21.304989099502563 and batch: 850, loss is 5.48667462348938 and perplexity is 241.4529484049569
At time: 22.52638602256775 and batch: 900, loss is 5.484201736450196 and perplexity is 240.85660019305303
At time: 23.74949026107788 and batch: 950, loss is 5.519793224334717 and perplexity is 249.5834240751529
At time: 24.971922159194946 and batch: 1000, loss is 5.4802534294128415 and perplexity is 239.90749928738114
At time: 26.19690442085266 and batch: 1050, loss is 5.382634782791138 and perplexity is 217.59483593659218
At time: 27.423905849456787 and batch: 1100, loss is 5.461642580032349 and perplexity is 235.48390802843488
At time: 28.643767595291138 and batch: 1150, loss is 5.363005800247192 and perplexity is 213.36531707712726
At time: 29.868555068969727 and batch: 1200, loss is 5.433757028579712 and perplexity is 229.00802087129793
At time: 31.090962171554565 and batch: 1250, loss is 5.372241840362549 and perplexity is 215.34509629135593
At time: 32.3120059967041 and batch: 1300, loss is 5.391835918426514 and perplexity is 219.6061947379066
At time: 33.535043716430664 and batch: 1350, loss is 5.3382182121276855 and perplexity is 208.1415156639252
At time: 34.75939059257507 and batch: 1400, loss is 5.350358896255493 and perplexity is 210.68389796163854
At time: 35.98394560813904 and batch: 1450, loss is 5.306094789505005 and perplexity is 201.56154913415511
At time: 37.20657682418823 and batch: 1500, loss is 5.27382495880127 and perplexity is 195.1610194899379
At time: 38.430253744125366 and batch: 1550, loss is 5.259034481048584 and perplexity is 192.29573645894013
At time: 39.653637647628784 and batch: 1600, loss is 5.301784934997559 and perplexity is 200.69471748401034
At time: 40.87662434577942 and batch: 1650, loss is 5.282510061264038 and perplexity is 196.86339489236923
At time: 42.09975218772888 and batch: 1700, loss is 5.296493692398071 and perplexity is 199.6355975466678
At time: 43.32702851295471 and batch: 1750, loss is 5.309456071853638 and perplexity is 202.2401943315275
At time: 44.553367376327515 and batch: 1800, loss is 5.277647514343261 and perplexity is 195.908460984754
At time: 45.782485246658325 and batch: 1850, loss is 5.26031530380249 and perplexity is 192.54219101228324
At time: 47.00702500343323 and batch: 1900, loss is 5.290541334152222 and perplexity is 198.45082454621152
At time: 48.234835147857666 and batch: 1950, loss is 5.215651521682739 and perplexity is 184.13174773409332
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.876376271802326 and perplexity of 131.15453334228863
finished 1 epochs...
Completing Train Step...
At time: 51.927913427352905 and batch: 50, loss is 5.092901306152344 and perplexity is 162.86168888541852
At time: 53.1089825630188 and batch: 100, loss is 5.026153211593628 and perplexity is 152.3458418405133
At time: 54.26293730735779 and batch: 150, loss is 4.9517507743835445 and perplexity is 141.42234592375482
At time: 55.41692399978638 and batch: 200, loss is 4.9273466205596925 and perplexity is 138.01282568151402
At time: 56.569884300231934 and batch: 250, loss is 4.933696022033692 and perplexity is 138.89191240423781
At time: 57.72276306152344 and batch: 300, loss is 4.949639492034912 and perplexity is 141.12407839538196
At time: 58.87657713890076 and batch: 350, loss is 4.944004383087158 and perplexity is 140.33106529455637
At time: 60.03302550315857 and batch: 400, loss is 4.901493177413941 and perplexity is 134.4904479302461
At time: 61.20150017738342 and batch: 450, loss is 4.879925651550293 and perplexity is 131.62087771383426
At time: 62.35570192337036 and batch: 500, loss is 4.874224481582641 and perplexity is 130.87261971844106
At time: 63.506515979766846 and batch: 550, loss is 4.8268684387207035 and perplexity is 124.81946816992516
At time: 64.66061067581177 and batch: 600, loss is 4.814289245605469 and perplexity is 123.25917416956379
At time: 65.82330679893494 and batch: 650, loss is 4.870810337066651 and perplexity is 130.4265635649046
At time: 66.9858410358429 and batch: 700, loss is 4.878766851425171 and perplexity is 131.4684437615699
At time: 68.14840197563171 and batch: 750, loss is 4.8347626972198485 and perplexity is 125.80872490409679
At time: 69.31064987182617 and batch: 800, loss is 4.81336929321289 and perplexity is 123.14583373927269
At time: 70.47390031814575 and batch: 850, loss is 4.812549505233765 and perplexity is 123.0449216340108
At time: 71.63605546951294 and batch: 900, loss is 4.8151136302948 and perplexity is 123.36082904117147
At time: 72.80437970161438 and batch: 950, loss is 4.887402153015136 and perplexity is 132.6086292606961
At time: 73.97135996818542 and batch: 1000, loss is 4.84755313873291 and perplexity is 127.42820892133375
At time: 75.1345763206482 and batch: 1050, loss is 4.763200635910034 and perplexity is 117.12018571698373
At time: 76.29811978340149 and batch: 1100, loss is 4.844560956954956 and perplexity is 127.04749043012045
At time: 77.4637930393219 and batch: 1150, loss is 4.758191909790039 and perplexity is 116.5350294506759
At time: 78.62911796569824 and batch: 1200, loss is 4.834984769821167 and perplexity is 125.83666667734113
At time: 79.79320549964905 and batch: 1250, loss is 4.792005958557129 and perplexity is 120.54293042355884
At time: 80.95654058456421 and batch: 1300, loss is 4.821626796722412 and perplexity is 124.16692090698128
At time: 82.12078547477722 and batch: 1350, loss is 4.720122413635254 and perplexity is 112.18198443183879
At time: 83.28532934188843 and batch: 1400, loss is 4.731041898727417 and perplexity is 113.41366636642185
At time: 84.44956851005554 and batch: 1450, loss is 4.664646329879761 and perplexity is 106.12804426563305
At time: 85.6123616695404 and batch: 1500, loss is 4.651988754272461 and perplexity is 104.79318637550759
At time: 86.77541756629944 and batch: 1550, loss is 4.646951723098755 and perplexity is 104.26666698944587
At time: 87.93969821929932 and batch: 1600, loss is 4.731706914901733 and perplexity is 113.48911337290326
At time: 89.10268235206604 and batch: 1650, loss is 4.684038486480713 and perplexity is 108.20618056790903
At time: 90.26605033874512 and batch: 1700, loss is 4.713576784133911 and perplexity is 111.45008072349087
At time: 91.4299111366272 and batch: 1750, loss is 4.7205061435699465 and perplexity is 112.22504027777865
At time: 92.59320735931396 and batch: 1800, loss is 4.669627895355225 and perplexity is 106.65804709277285
At time: 93.75753593444824 and batch: 1850, loss is 4.693177366256714 and perplexity is 109.1995962824396
At time: 94.91954374313354 and batch: 1900, loss is 4.766946306228638 and perplexity is 117.55970194791426
At time: 96.08408999443054 and batch: 1950, loss is 4.690617561340332 and perplexity is 108.92042408463308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5926939498546515 and perplexity of 98.76012694398055
finished 2 epochs...
Completing Train Step...
At time: 99.73203444480896 and batch: 50, loss is 4.629713115692138 and perplexity is 102.48465865234897
At time: 100.91474318504333 and batch: 100, loss is 4.58248158454895 and perplexity is 97.7566849291338
At time: 102.06971216201782 and batch: 150, loss is 4.529491424560547 and perplexity is 92.7113983500665
At time: 103.22392225265503 and batch: 200, loss is 4.527529582977295 and perplexity is 92.5296915717785
At time: 104.37753391265869 and batch: 250, loss is 4.5259553337097165 and perplexity is 92.38414136880182
At time: 105.52994847297668 and batch: 300, loss is 4.554880847930908 and perplexity is 95.09542374400583
At time: 106.68548083305359 and batch: 350, loss is 4.563006362915039 and perplexity is 95.87127084447448
At time: 107.84826898574829 and batch: 400, loss is 4.526906003952027 and perplexity is 92.47200998328324
At time: 109.0014181137085 and batch: 450, loss is 4.53324896812439 and perplexity is 93.06042079108735
At time: 110.15454721450806 and batch: 500, loss is 4.538877277374268 and perplexity is 93.58567036517684
At time: 111.35231876373291 and batch: 550, loss is 4.492650394439697 and perplexity is 89.35796616083877
At time: 112.50536561012268 and batch: 600, loss is 4.473281049728394 and perplexity is 87.64381549055196
At time: 113.65876007080078 and batch: 650, loss is 4.529277286529541 and perplexity is 92.69154743926535
At time: 114.81092023849487 and batch: 700, loss is 4.558632917404175 and perplexity is 95.45289859634529
At time: 115.96391677856445 and batch: 750, loss is 4.524600248336792 and perplexity is 92.25903775232673
At time: 117.11572170257568 and batch: 800, loss is 4.494601821899414 and perplexity is 89.5325120011321
At time: 118.26777982711792 and batch: 850, loss is 4.496311502456665 and perplexity is 89.68571492285284
At time: 119.42603373527527 and batch: 900, loss is 4.479847364425659 and perplexity is 88.22120595348741
At time: 120.57938408851624 and batch: 950, loss is 4.56542366027832 and perplexity is 96.10330054410636
At time: 121.73286557197571 and batch: 1000, loss is 4.535013036727905 and perplexity is 93.22473064194925
At time: 122.88592863082886 and batch: 1050, loss is 4.458189001083374 and perplexity is 86.3310220527569
At time: 124.04350399971008 and batch: 1100, loss is 4.530636310577393 and perplexity is 92.81760311821591
At time: 125.19798374176025 and batch: 1150, loss is 4.457879915237426 and perplexity is 86.30434247912588
At time: 126.35166215896606 and batch: 1200, loss is 4.539270486831665 and perplexity is 93.62247637160195
At time: 127.51006531715393 and batch: 1250, loss is 4.510193901062012 and perplexity is 90.93945005703134
At time: 128.66985964775085 and batch: 1300, loss is 4.528215522766113 and perplexity is 92.59318314208234
At time: 129.82989978790283 and batch: 1350, loss is 4.410394630432129 and perplexity is 82.3019359450206
At time: 130.9890878200531 and batch: 1400, loss is 4.431975908279419 and perplexity is 84.09742164289821
At time: 132.14541029930115 and batch: 1450, loss is 4.369973659515381 and perplexity is 79.04154967942026
At time: 133.30200815200806 and batch: 1500, loss is 4.368544135093689 and perplexity is 78.92863857764209
At time: 134.45866107940674 and batch: 1550, loss is 4.361966133117676 and perplexity is 78.41114972444572
At time: 135.61412978172302 and batch: 1600, loss is 4.460291242599487 and perplexity is 86.51270161169052
At time: 136.78474140167236 and batch: 1650, loss is 4.4054265975952145 and perplexity is 81.89407120629897
At time: 137.9486517906189 and batch: 1700, loss is 4.4317697906494145 and perplexity is 84.08008946795444
At time: 139.10407519340515 and batch: 1750, loss is 4.441618986129761 and perplexity is 84.91230229101305
At time: 140.25886869430542 and batch: 1800, loss is 4.390491743087768 and perplexity is 80.68008310058455
At time: 141.41352605819702 and batch: 1850, loss is 4.427584419250488 and perplexity is 83.72891846943423
At time: 142.56954979896545 and batch: 1900, loss is 4.508266439437866 and perplexity is 90.7643365733991
At time: 143.72501707077026 and batch: 1950, loss is 4.4334994888305665 and perplexity is 84.2256484960804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507454237827035 and perplexity of 90.69064756224577
finished 3 epochs...
Completing Train Step...
At time: 147.4070963859558 and batch: 50, loss is 4.3846164798736575 and perplexity is 80.20745613966999
At time: 148.560879945755 and batch: 100, loss is 4.341493721008301 and perplexity is 76.82220461894947
At time: 149.7175896167755 and batch: 150, loss is 4.291626434326172 and perplexity is 73.08524022968741
At time: 150.87706065177917 and batch: 200, loss is 4.300166988372803 and perplexity is 73.71210173584248
At time: 152.03027939796448 and batch: 250, loss is 4.295958671569824 and perplexity is 73.40254966296484
At time: 153.18486189842224 and batch: 300, loss is 4.328970594406128 and perplexity is 75.86614932013102
At time: 154.33991408348083 and batch: 350, loss is 4.342423162460327 and perplexity is 76.89363955251007
At time: 155.4945774078369 and batch: 400, loss is 4.304158458709717 and perplexity is 74.00690936995386
At time: 156.6500792503357 and batch: 450, loss is 4.319979333877564 and perplexity is 75.187074450681
At time: 157.80533075332642 and batch: 500, loss is 4.327548570632935 and perplexity is 75.7583425222987
At time: 158.9607458114624 and batch: 550, loss is 4.285670471191406 and perplexity is 72.65124095797054
At time: 160.11488151550293 and batch: 600, loss is 4.267890491485596 and perplexity is 71.37091914465056
At time: 161.26982593536377 and batch: 650, loss is 4.318262166976929 and perplexity is 75.05807648229711
At time: 162.4243767261505 and batch: 700, loss is 4.351627569198609 and perplexity is 77.604667160277
At time: 163.5785791873932 and batch: 750, loss is 4.318687505722046 and perplexity is 75.09000838081441
At time: 164.73295903205872 and batch: 800, loss is 4.291318888664246 and perplexity is 73.06276663710901
At time: 165.88519525527954 and batch: 850, loss is 4.295210189819336 and perplexity is 73.3476297499431
At time: 167.04135966300964 and batch: 900, loss is 4.274080562591553 and perplexity is 71.81408039382617
At time: 168.23600220680237 and batch: 950, loss is 4.3615577507019045 and perplexity is 78.37913452736457
At time: 169.38925099372864 and batch: 1000, loss is 4.333500070571899 and perplexity is 76.21056265241909
At time: 170.54290676116943 and batch: 1050, loss is 4.267532043457031 and perplexity is 71.34534096388441
At time: 171.69582152366638 and batch: 1100, loss is 4.32620306968689 and perplexity is 75.65647814543956
At time: 172.85337233543396 and batch: 1150, loss is 4.2646963405609135 and perplexity is 71.14331335440615
At time: 174.00961661338806 and batch: 1200, loss is 4.345472297668457 and perplexity is 77.12845646848506
At time: 175.16178059577942 and batch: 1250, loss is 4.32016954421997 and perplexity is 75.20137717007626
At time: 176.3137710094452 and batch: 1300, loss is 4.337631568908692 and perplexity is 76.52607779159875
At time: 177.47272276878357 and batch: 1350, loss is 4.212770447731018 and perplexity is 67.54340631542297
At time: 178.63481187820435 and batch: 1400, loss is 4.2402036666870115 and perplexity is 69.4219893456125
At time: 179.79852652549744 and batch: 1450, loss is 4.177561354637146 and perplexity is 65.20664328635814
At time: 180.961407661438 and batch: 1500, loss is 4.177898921966553 and perplexity is 65.22865863441396
At time: 182.12378883361816 and batch: 1550, loss is 4.177688040733337 and perplexity is 65.2149045847266
At time: 183.28608417510986 and batch: 1600, loss is 4.278698134422302 and perplexity is 72.14645385710335
At time: 184.4489710330963 and batch: 1650, loss is 4.220811638832092 and perplexity is 68.08872532200256
At time: 185.61180233955383 and batch: 1700, loss is 4.247233901023865 and perplexity is 69.91176178915187
At time: 186.77427172660828 and batch: 1750, loss is 4.2601094245910645 and perplexity is 70.81773223170501
At time: 187.9355435371399 and batch: 1800, loss is 4.201467208862304 and perplexity is 66.78424562983417
At time: 189.09775948524475 and batch: 1850, loss is 4.246794176101685 and perplexity is 69.88102660314854
At time: 190.2680504322052 and batch: 1900, loss is 4.326706581115722 and perplexity is 75.6945816388182
At time: 191.43113827705383 and batch: 1950, loss is 4.25794508934021 and perplexity is 70.66462466526939
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470150685864826 and perplexity of 87.36988742861736
finished 4 epochs...
Completing Train Step...
At time: 195.09869861602783 and batch: 50, loss is 4.207080430984497 and perplexity is 67.16017453396636
At time: 196.25329637527466 and batch: 100, loss is 4.168730735778809 and perplexity is 64.6333632067578
At time: 197.43584609031677 and batch: 150, loss is 4.129573001861572 and perplexity is 62.15137874497946
At time: 198.5946216583252 and batch: 200, loss is 4.1365413475036625 and perplexity is 62.585983513709046
At time: 199.74878811836243 and batch: 250, loss is 4.126898589134217 and perplexity is 61.985382376981356
At time: 200.90749382972717 and batch: 300, loss is 4.158858714103698 and perplexity is 63.998440386621084
At time: 202.0643970966339 and batch: 350, loss is 4.176468563079834 and perplexity is 65.13542493758666
At time: 203.21964812278748 and batch: 400, loss is 4.139431128501892 and perplexity is 62.76710487411244
At time: 204.37275099754333 and batch: 450, loss is 4.1638741254806515 and perplexity is 64.32022515962548
At time: 205.52564978599548 and batch: 500, loss is 4.17656840801239 and perplexity is 65.1419287043752
At time: 206.6793417930603 and batch: 550, loss is 4.134538154602051 and perplexity is 62.460737203935544
At time: 207.83338046073914 and batch: 600, loss is 4.118105101585388 and perplexity is 61.442704202621734
At time: 208.98724055290222 and batch: 650, loss is 4.160296659469605 and perplexity is 64.09053284349287
At time: 210.14206743240356 and batch: 700, loss is 4.200750622749329 and perplexity is 66.73640610946536
At time: 211.29680061340332 and batch: 750, loss is 4.1727938032150265 and perplexity is 64.89650714386781
At time: 212.4508466720581 and batch: 800, loss is 4.13958966255188 and perplexity is 62.77705638626008
At time: 213.60631275177002 and batch: 850, loss is 4.144017019271851 and perplexity is 63.05560897955604
At time: 214.7599573135376 and batch: 900, loss is 4.121634273529053 and perplexity is 61.65992915708156
At time: 215.91482949256897 and batch: 950, loss is 4.211999182701111 and perplexity is 67.49133253205642
At time: 217.06980800628662 and batch: 1000, loss is 4.184449510574341 and perplexity is 65.65734729115579
At time: 218.22467875480652 and batch: 1050, loss is 4.123750081062317 and perplexity is 61.79052781178109
At time: 219.38101243972778 and batch: 1100, loss is 4.174705672264099 and perplexity is 65.02069944915196
At time: 220.53609323501587 and batch: 1150, loss is 4.121135597229004 and perplexity is 61.6291884772095
At time: 221.69054794311523 and batch: 1200, loss is 4.193922367095947 and perplexity is 66.28226512705575
At time: 222.84575271606445 and batch: 1250, loss is 4.179513969421387 and perplexity is 65.33409112984809
At time: 223.99994492530823 and batch: 1300, loss is 4.1911309671401975 and perplexity is 66.09750280784891
At time: 225.15389561653137 and batch: 1350, loss is 4.0655167770385745 and perplexity is 58.2950262708412
At time: 226.30796718597412 and batch: 1400, loss is 4.102910203933716 and perplexity is 60.51614590734591
At time: 227.4639253616333 and batch: 1450, loss is 4.03404402256012 and perplexity is 56.48889231104464
At time: 228.62001824378967 and batch: 1500, loss is 4.0336421251297 and perplexity is 56.46619413185303
At time: 229.77480387687683 and batch: 1550, loss is 4.03434130191803 and perplexity is 56.505687789030674
At time: 230.92978405952454 and batch: 1600, loss is 4.1388539123535155 and perplexity is 62.73088514190506
At time: 232.08493208885193 and batch: 1650, loss is 4.079546489715576 and perplexity is 59.118652852379974
At time: 233.2376606464386 and batch: 1700, loss is 4.110257258415222 and perplexity is 60.96239864255468
At time: 234.39108657836914 and batch: 1750, loss is 4.115924191474915 and perplexity is 61.308849203726936
At time: 235.54523825645447 and batch: 1800, loss is 4.061501989364624 and perplexity is 58.0614533045868
At time: 236.698903799057 and batch: 1850, loss is 4.109602041244507 and perplexity is 60.92246811520821
At time: 237.8534972667694 and batch: 1900, loss is 4.190367951393127 and perplexity is 66.0470886082245
At time: 239.00707268714905 and batch: 1950, loss is 4.119531378746033 and perplexity is 61.530401053455336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.461716195039971 and perplexity of 86.6360659702827
finished 5 epochs...
Completing Train Step...
At time: 242.66615176200867 and batch: 50, loss is 4.072333970069885 and perplexity is 58.69379240619679
At time: 243.82225251197815 and batch: 100, loss is 4.036794514656067 and perplexity is 56.64447843396888
At time: 244.98134994506836 and batch: 150, loss is 3.9975151348114015 and perplexity is 54.46264941087598
At time: 246.1380739212036 and batch: 200, loss is 4.014402503967285 and perplexity is 55.39019009450088
At time: 247.29370856285095 and batch: 250, loss is 4.001220030784607 and perplexity is 54.66480210749104
At time: 248.45024466514587 and batch: 300, loss is 4.023645648956299 and perplexity is 55.90454311025825
At time: 249.60667943954468 and batch: 350, loss is 4.0412392950057985 and perplexity is 56.89681106476747
At time: 250.7638339996338 and batch: 400, loss is 4.012519359588623 and perplexity is 55.28598052102359
At time: 251.92076802253723 and batch: 450, loss is 4.039550266265869 and perplexity is 56.80079182812101
At time: 253.07761883735657 and batch: 500, loss is 4.05406002998352 and perplexity is 57.63096614824739
At time: 254.23408198356628 and batch: 550, loss is 4.018462114334106 and perplexity is 55.61550972994557
At time: 255.4338517189026 and batch: 600, loss is 4.000342497825622 and perplexity is 54.61685298349068
At time: 256.59022402763367 and batch: 650, loss is 4.04243305683136 and perplexity is 56.964772862842004
At time: 257.74774408340454 and batch: 700, loss is 4.078254480361938 and perplexity is 59.042320321710434
At time: 258.90397930145264 and batch: 750, loss is 4.049101886749267 and perplexity is 57.34593077039396
At time: 260.0614056587219 and batch: 800, loss is 4.0190263271331785 and perplexity is 55.64689756623897
At time: 261.2187900543213 and batch: 850, loss is 4.0245449209213255 and perplexity is 55.95483911009676
At time: 262.37533617019653 and batch: 900, loss is 4.003233871459961 and perplexity is 54.77499923196854
At time: 263.5327730178833 and batch: 950, loss is 4.089764919281006 and perplexity is 59.72584965802257
At time: 264.6912670135498 and batch: 1000, loss is 4.067869462966919 and perplexity is 58.43233762074508
At time: 265.851425409317 and batch: 1050, loss is 4.011119661331176 and perplexity is 55.20865096207658
At time: 267.0082423686981 and batch: 1100, loss is 4.055684494972229 and perplexity is 57.72466171700185
At time: 268.1648271083832 and batch: 1150, loss is 4.010190143585205 and perplexity is 55.15735738411482
At time: 269.3220353126526 and batch: 1200, loss is 4.079523787498474 and perplexity is 59.11731074312264
At time: 270.47989106178284 and batch: 1250, loss is 4.065010018348694 and perplexity is 58.26549224364615
At time: 271.6356430053711 and batch: 1300, loss is 4.077220306396485 and perplexity is 58.98129185363942
At time: 272.79278922080994 and batch: 1350, loss is 3.9511273193359373 and perplexity is 51.993947591489245
At time: 273.9499101638794 and batch: 1400, loss is 3.9894929695129395 and perplexity is 54.02748883348371
At time: 275.106561422348 and batch: 1450, loss is 3.9181704473495484 and perplexity is 50.30831881108885
At time: 276.26217579841614 and batch: 1500, loss is 3.9177400875091553 and perplexity is 50.286672789158224
At time: 277.4179193973541 and batch: 1550, loss is 3.922798900604248 and perplexity is 50.54170821234532
At time: 278.5730757713318 and batch: 1600, loss is 4.023983273506165 and perplexity is 55.92342104310879
At time: 279.72760796546936 and batch: 1650, loss is 3.9695085000991823 and perplexity is 52.9584953467688
At time: 280.88423776626587 and batch: 1700, loss is 3.9957747983932497 and perplexity is 54.367948508294276
At time: 282.03952193260193 and batch: 1750, loss is 4.004915380477906 and perplexity is 54.867181367961294
At time: 283.193909406662 and batch: 1800, loss is 3.95261323928833 and perplexity is 52.07126386428937
At time: 284.3490927219391 and batch: 1850, loss is 4.002421607971192 and perplexity is 54.730525564608364
At time: 285.50403451919556 and batch: 1900, loss is 4.075039553642273 and perplexity is 58.85280838524029
At time: 286.65884470939636 and batch: 1950, loss is 4.006745681762696 and perplexity is 54.96769679921278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.467361521166424 and perplexity of 87.12653795154375
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 290.2831892967224 and batch: 50, loss is 3.998767948150635 and perplexity is 54.53092370308998
At time: 291.46793580055237 and batch: 100, loss is 3.989432988166809 and perplexity is 54.02424828916251
At time: 292.62507009506226 and batch: 150, loss is 3.9544820022583007 and perplexity is 52.168663694250704
At time: 293.7835569381714 and batch: 200, loss is 3.9671728801727295 and perplexity is 52.834948764854666
At time: 294.9425754547119 and batch: 250, loss is 3.9628463315963747 and perplexity is 52.60684958939176
At time: 296.0991904735565 and batch: 300, loss is 3.969300274848938 and perplexity is 52.9474691988237
At time: 297.2550654411316 and batch: 350, loss is 3.9802014303207396 and perplexity is 53.52781526663827
At time: 298.4108216762543 and batch: 400, loss is 3.950769429206848 and perplexity is 51.975342800308006
At time: 299.5649721622467 and batch: 450, loss is 3.9684441471099854 and perplexity is 52.902158800247335
At time: 300.7208032608032 and batch: 500, loss is 3.9736324071884157 and perplexity is 53.17734220306203
At time: 301.8804967403412 and batch: 550, loss is 3.935558819770813 and perplexity is 51.190748367504916
At time: 303.0380780696869 and batch: 600, loss is 3.9023115015029908 and perplexity is 49.51677502224921
At time: 304.1934907436371 and batch: 650, loss is 3.941861476898193 and perplexity is 51.51440497948875
At time: 305.3488190174103 and batch: 700, loss is 3.9875257301330564 and perplexity is 53.92130830535593
At time: 306.50898694992065 and batch: 750, loss is 3.9377653932571413 and perplexity is 51.30382923033258
At time: 307.665962934494 and batch: 800, loss is 3.8999333810806274 and perplexity is 49.39915807737999
At time: 308.82300567626953 and batch: 850, loss is 3.8920947742462157 and perplexity is 49.0134511765729
At time: 309.9802894592285 and batch: 900, loss is 3.859539074897766 and perplexity is 47.44347843819991
At time: 311.1353199481964 and batch: 950, loss is 3.951846785545349 and perplexity is 52.0313689399589
At time: 312.31493949890137 and batch: 1000, loss is 3.920056915283203 and perplexity is 50.40331341528748
At time: 313.47707319259644 and batch: 1050, loss is 3.858528733253479 and perplexity is 47.39556852295074
At time: 314.63363003730774 and batch: 1100, loss is 3.8961306047439574 and perplexity is 49.211660858936064
At time: 315.78974413871765 and batch: 1150, loss is 3.84455424785614 and perplexity is 46.73784621178633
At time: 316.9443950653076 and batch: 1200, loss is 3.895438485145569 and perplexity is 49.17761228818709
At time: 318.1017425060272 and batch: 1250, loss is 3.8715706729888915 and perplexity is 48.01774705989347
At time: 319.2583076953888 and batch: 1300, loss is 3.876051387786865 and perplexity is 48.23338363192541
At time: 320.4140293598175 and batch: 1350, loss is 3.755384826660156 and perplexity is 42.75066824233102
At time: 321.5705108642578 and batch: 1400, loss is 3.7799652576446534 and perplexity is 43.81451948952547
At time: 322.72580099105835 and batch: 1450, loss is 3.7008608388900757 and perplexity is 40.48213796356845
At time: 323.88276410102844 and batch: 1500, loss is 3.6872284507751463 and perplexity is 39.93401435269911
At time: 325.03684520721436 and batch: 1550, loss is 3.6936058616638183 and perplexity is 40.189503785280195
At time: 326.1923363208771 and batch: 1600, loss is 3.7761083221435547 and perplexity is 43.64585518659838
At time: 327.35197353363037 and batch: 1650, loss is 3.7150534772872925 and perplexity is 41.06078284496122
At time: 328.51397824287415 and batch: 1700, loss is 3.7284578323364257 and perplexity is 41.61488152802179
At time: 329.67213249206543 and batch: 1750, loss is 3.7195907115936278 and perplexity is 41.24750852627842
At time: 330.8287715911865 and batch: 1800, loss is 3.664419665336609 and perplexity is 39.033477109018996
At time: 331.98457431793213 and batch: 1850, loss is 3.701743688583374 and perplexity is 40.517893387663854
At time: 333.13990926742554 and batch: 1900, loss is 3.7689253282546997 and perplexity is 43.33347054713041
At time: 334.2958257198334 and batch: 1950, loss is 3.6924226808547975 and perplexity is 40.14198045556729
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.409718216297239 and perplexity of 82.24628457602674
finished 7 epochs...
Completing Train Step...
At time: 337.9421544075012 and batch: 50, loss is 3.895234704017639 and perplexity is 49.16759183990991
At time: 339.12074089050293 and batch: 100, loss is 3.8661867809295654 and perplexity is 47.759919373795704
At time: 340.27643156051636 and batch: 150, loss is 3.826128764152527 and perplexity is 45.88456399736641
At time: 341.4551818370819 and batch: 200, loss is 3.839989595413208 and perplexity is 46.52499036397068
At time: 342.6107976436615 and batch: 250, loss is 3.833492693901062 and perplexity is 46.223701864351554
At time: 343.7662401199341 and batch: 300, loss is 3.8369646310806274 and perplexity is 46.384466574425794
At time: 344.9219825267792 and batch: 350, loss is 3.8508692264556883 and perplexity is 47.033928603432166
At time: 346.0776960849762 and batch: 400, loss is 3.8285703325271605 and perplexity is 45.99673117390026
At time: 347.2302031517029 and batch: 450, loss is 3.851352791786194 and perplexity is 47.05667808064819
At time: 348.3898756504059 and batch: 500, loss is 3.8597007322311403 and perplexity is 47.451148644366064
At time: 349.54465436935425 and batch: 550, loss is 3.8237779712677002 and perplexity is 45.77682557577107
At time: 350.69927740097046 and batch: 600, loss is 3.7957518243789674 and perplexity is 44.511688801579616
At time: 351.8595378398895 and batch: 650, loss is 3.8348263692855835 and perplexity is 46.285390404809725
At time: 353.0132186412811 and batch: 700, loss is 3.8826828145980836 and perplexity is 48.55430268488825
At time: 354.16462230682373 and batch: 750, loss is 3.837643485069275 and perplexity is 46.41596554496235
At time: 355.3190679550171 and batch: 800, loss is 3.8025014543533326 and perplexity is 44.8131424363134
At time: 356.47274947166443 and batch: 850, loss is 3.795975995063782 and perplexity is 44.521668135835824
At time: 357.63245916366577 and batch: 900, loss is 3.7655683279037477 and perplexity is 43.18824397051535
At time: 358.79351019859314 and batch: 950, loss is 3.86070698261261 and perplexity is 47.4989204119394
At time: 359.94886350631714 and batch: 1000, loss is 3.8296346282958984 and perplexity is 46.04571136034358
At time: 361.11104559898376 and batch: 1050, loss is 3.774631199836731 and perplexity is 43.58143251210024
At time: 362.2667279243469 and batch: 1100, loss is 3.8133037900924682 and perplexity is 45.29985311967576
At time: 363.42153811454773 and batch: 1150, loss is 3.767113676071167 and perplexity is 43.25503643970692
At time: 364.58295941352844 and batch: 1200, loss is 3.818413372039795 and perplexity is 45.53190878022736
At time: 365.73775482177734 and batch: 1250, loss is 3.8001086854934694 and perplexity is 44.70604312762289
At time: 366.8926854133606 and batch: 1300, loss is 3.8083750438690185 and perplexity is 45.077130961062124
At time: 368.0471897125244 and batch: 1350, loss is 3.6877549695968628 and perplexity is 39.95504589914916
At time: 369.2058162689209 and batch: 1400, loss is 3.7182872772216795 and perplexity is 41.193780129234554
At time: 370.3703079223633 and batch: 1450, loss is 3.642678556442261 and perplexity is 38.194004630222175
At time: 371.540025472641 and batch: 1500, loss is 3.6300339221954347 and perplexity is 37.71409594041604
At time: 372.703134059906 and batch: 1550, loss is 3.641439719200134 and perplexity is 38.14671777126893
At time: 373.86673498153687 and batch: 1600, loss is 3.7269697332382203 and perplexity is 41.553000514307676
At time: 375.02974367141724 and batch: 1650, loss is 3.6686448860168457 and perplexity is 39.19875107733674
At time: 376.1937117576599 and batch: 1700, loss is 3.6887889957427977 and perplexity is 39.99638182880386
At time: 377.3587667942047 and batch: 1750, loss is 3.683899312019348 and perplexity is 39.801289530102544
At time: 378.5251054763794 and batch: 1800, loss is 3.633352723121643 and perplexity is 37.83946944673208
At time: 379.692355632782 and batch: 1850, loss is 3.6760535049438476 and perplexity is 39.49023811141035
At time: 380.8581802845001 and batch: 1900, loss is 3.745145530700684 and perplexity is 42.31516492636048
At time: 382.02383375167847 and batch: 1950, loss is 3.6713945627212525 and perplexity is 39.306683291359434
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418923453397529 and perplexity of 83.00687646971596
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 385.71012473106384 and batch: 50, loss is 3.8546462488174438 and perplexity is 47.21191271692501
At time: 386.90091848373413 and batch: 100, loss is 3.8563760328292847 and perplexity is 47.293649802081895
At time: 388.0649058818817 and batch: 150, loss is 3.827886939048767 and perplexity is 45.96530804619182
At time: 389.22746896743774 and batch: 200, loss is 3.844381022453308 and perplexity is 46.729750730740506
At time: 390.3908426761627 and batch: 250, loss is 3.839669075012207 and perplexity is 46.510080544980866
At time: 391.55393648147583 and batch: 300, loss is 3.845294728279114 and perplexity is 46.772467488525
At time: 392.71669363975525 and batch: 350, loss is 3.8609957313537597 and perplexity is 47.512637645736014
At time: 393.8800995349884 and batch: 400, loss is 3.838101696968079 and perplexity is 46.437238766118845
At time: 395.04069328308105 and batch: 450, loss is 3.8544801759719847 and perplexity is 47.204072751261265
At time: 396.205379486084 and batch: 500, loss is 3.8587293148040773 and perplexity is 47.40507615307228
At time: 397.3675904273987 and batch: 550, loss is 3.8236762428283693 and perplexity is 45.77216900760444
At time: 398.5319414138794 and batch: 600, loss is 3.7888415670394897 and perplexity is 44.20516188703945
At time: 399.7186818122864 and batch: 650, loss is 3.817045822143555 and perplexity is 45.46968418041951
At time: 400.8818304538727 and batch: 700, loss is 3.8628189516067506 and perplexity is 47.59934266612109
At time: 402.04510021209717 and batch: 750, loss is 3.8275907182693483 and perplexity is 45.95169418327024
At time: 403.2083342075348 and batch: 800, loss is 3.7958403253555297 and perplexity is 44.51562830382932
At time: 404.3733401298523 and batch: 850, loss is 3.7849067735671995 and perplexity is 44.031565461622506
At time: 405.5371141433716 and batch: 900, loss is 3.7451051616668702 and perplexity is 42.31345673851592
At time: 406.7004063129425 and batch: 950, loss is 3.8374272632598876 and perplexity is 46.40593048584618
At time: 407.8665385246277 and batch: 1000, loss is 3.8017600917816163 and perplexity is 44.77993196181261
At time: 409.02970337867737 and batch: 1050, loss is 3.741629548072815 and perplexity is 42.16664678818093
At time: 410.1988785266876 and batch: 1100, loss is 3.783740210533142 and perplexity is 43.980229813979484
At time: 411.3618288040161 and batch: 1150, loss is 3.7480981063842775 and perplexity is 42.44028828055683
At time: 412.52503967285156 and batch: 1200, loss is 3.792468762397766 and perplexity is 44.36579379058206
At time: 413.6883704662323 and batch: 1250, loss is 3.765323143005371 and perplexity is 43.17765616334463
At time: 414.85194993019104 and batch: 1300, loss is 3.7691335344314574 and perplexity is 43.34249378267276
At time: 416.01652574539185 and batch: 1350, loss is 3.6424335289001464 and perplexity is 38.18464719360579
At time: 417.1802439689636 and batch: 1400, loss is 3.6679630947113036 and perplexity is 39.172034818155616
At time: 418.3443384170532 and batch: 1450, loss is 3.5935890769958494 and perplexity is 36.364356468447724
At time: 419.50813817977905 and batch: 1500, loss is 3.578115921020508 and perplexity is 35.806015893979946
At time: 420.6722300052643 and batch: 1550, loss is 3.588774676322937 and perplexity is 36.18970464546952
At time: 421.8354218006134 and batch: 1600, loss is 3.6702975463867187 and perplexity is 39.26358686079862
At time: 422.9986147880554 and batch: 1650, loss is 3.5987403917312624 and perplexity is 36.552164026382144
At time: 424.1619493961334 and batch: 1700, loss is 3.611255168914795 and perplexity is 37.012480586470836
At time: 425.3260760307312 and batch: 1750, loss is 3.5995649528503417 and perplexity is 36.58231594899968
At time: 426.4888641834259 and batch: 1800, loss is 3.5455339193344115 and perplexity is 34.6581850782469
At time: 427.6492908000946 and batch: 1850, loss is 3.589556179046631 and perplexity is 36.217998052466925
At time: 428.8136510848999 and batch: 1900, loss is 3.6628359079360964 and perplexity is 38.97170647853797
At time: 429.977906703949 and batch: 1950, loss is 3.590101842880249 and perplexity is 36.23776629704777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.397118572856105 and perplexity of 81.21651172447595
finished 9 epochs...
Completing Train Step...
At time: 433.66552662849426 and batch: 50, loss is 3.840765342712402 and perplexity is 46.56109600220558
At time: 434.8316435813904 and batch: 100, loss is 3.8267426252365113 and perplexity is 45.912739392564546
At time: 435.99610924720764 and batch: 150, loss is 3.7919103479385377 and perplexity is 44.34102620576658
At time: 437.1660990715027 and batch: 200, loss is 3.806012291908264 and perplexity is 44.97075060618461
At time: 438.33164978027344 and batch: 250, loss is 3.794763808250427 and perplexity is 44.46773225360005
At time: 439.49663281440735 and batch: 300, loss is 3.797958073616028 and perplexity is 44.61000109186788
At time: 440.6616654396057 and batch: 350, loss is 3.8147719144821166 and perplexity is 45.36640778219562
At time: 441.82569313049316 and batch: 400, loss is 3.7902849769592284 and perplexity is 44.26901412760358
At time: 442.9966723918915 and batch: 450, loss is 3.807277798652649 and perplexity is 45.02769742006524
At time: 444.16237568855286 and batch: 500, loss is 3.810577917098999 and perplexity is 45.17653961827585
At time: 445.3269877433777 and batch: 550, loss is 3.7775280332565306 and perplexity is 43.7078636989139
At time: 446.49060583114624 and batch: 600, loss is 3.746382336616516 and perplexity is 42.36753295053631
At time: 447.65343594551086 and batch: 650, loss is 3.775180706977844 and perplexity is 43.60538740157421
At time: 448.81770873069763 and batch: 700, loss is 3.8240246248245238 and perplexity is 45.78811798521865
At time: 449.9877347946167 and batch: 750, loss is 3.7898393964767454 and perplexity is 44.24929311290547
At time: 451.1525776386261 and batch: 800, loss is 3.7585910415649413 and perplexity is 42.887956041525385
At time: 452.3174042701721 and batch: 850, loss is 3.7488051366806032 and perplexity is 42.47030546043332
At time: 453.4828608036041 and batch: 900, loss is 3.710973410606384 and perplexity is 40.89359341692353
At time: 454.6473660469055 and batch: 950, loss is 3.804621305465698 and perplexity is 44.90824038729185
At time: 455.8126516342163 and batch: 1000, loss is 3.769354572296143 and perplexity is 43.352075173834734
At time: 457.0223605632782 and batch: 1050, loss is 3.7114813137054443 and perplexity is 40.91436867521412
At time: 458.18840074539185 and batch: 1100, loss is 3.7546958208084105 and perplexity is 42.72122292690821
At time: 459.3548848628998 and batch: 1150, loss is 3.7216727542877197 and perplexity is 41.33347706408266
At time: 460.5197985172272 and batch: 1200, loss is 3.767655539512634 and perplexity is 43.278481113945205
At time: 461.6845693588257 and batch: 1250, loss is 3.7427022075653076 and perplexity is 42.21190150923875
At time: 462.84937047958374 and batch: 1300, loss is 3.74799195766449 and perplexity is 42.43578353737901
At time: 464.0135586261749 and batch: 1350, loss is 3.6226031970977783 and perplexity is 37.43489149163265
At time: 465.188325881958 and batch: 1400, loss is 3.6509891891479493 and perplexity is 38.51274360100451
At time: 466.35678267478943 and batch: 1450, loss is 3.577717638015747 and perplexity is 35.79175780594674
At time: 467.5259418487549 and batch: 1500, loss is 3.5638591384887697 and perplexity is 35.29915897161698
At time: 468.69175934791565 and batch: 1550, loss is 3.5776627397537233 and perplexity is 35.78979295458237
At time: 469.8578748703003 and batch: 1600, loss is 3.660936408042908 and perplexity is 38.89774998865379
At time: 471.02345061302185 and batch: 1650, loss is 3.5920970964431764 and perplexity is 36.3101420093025
At time: 472.1887700557709 and batch: 1700, loss is 3.6077113819122313 and perplexity is 36.881548373797784
At time: 473.354350566864 and batch: 1750, loss is 3.597651333808899 and perplexity is 36.512378270998056
At time: 474.5208601951599 and batch: 1800, loss is 3.5458384799957274 and perplexity is 34.668742205575576
At time: 475.6906774044037 and batch: 1850, loss is 3.5915120458602905 and perplexity is 36.288904952537266
At time: 476.8580274581909 and batch: 1900, loss is 3.6650544452667235 and perplexity is 39.058262642737795
At time: 478.0224471092224 and batch: 1950, loss is 3.5923143863677978 and perplexity is 36.31803269457485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39845453306686 and perplexity of 81.32508626207871
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 481.72082018852234 and batch: 50, loss is 3.8290138244628906 and perplexity is 46.01713487735037
At time: 482.8853666782379 and batch: 100, loss is 3.8290196800231935 and perplexity is 46.01740433424752
At time: 484.04979610443115 and batch: 150, loss is 3.8065034532546997 and perplexity is 44.99284392585073
At time: 485.2132284641266 and batch: 200, loss is 3.825629324913025 and perplexity is 45.86165316737869
At time: 486.40103793144226 and batch: 250, loss is 3.822972173690796 and perplexity is 45.73995357832196
At time: 487.5653564929962 and batch: 300, loss is 3.8267099142074583 and perplexity is 45.911237564175686
At time: 488.72982144355774 and batch: 350, loss is 3.861745162010193 and perplexity is 47.548258418938254
At time: 489.89392828941345 and batch: 400, loss is 3.8420690727233886 and perplexity is 46.62183868783542
At time: 491.05874848365784 and batch: 450, loss is 3.8586440515518188 and perplexity is 47.40103441441424
At time: 492.22355461120605 and batch: 500, loss is 3.8575015258789063 and perplexity is 47.3469084417177
At time: 493.3886675834656 and batch: 550, loss is 3.8189824056625366 and perplexity is 45.55782534022861
At time: 494.5540702342987 and batch: 600, loss is 3.771468553543091 and perplexity is 43.443817584470565
At time: 495.7181043624878 and batch: 650, loss is 3.7805851888656616 and perplexity is 43.84168989911293
At time: 496.8825798034668 and batch: 700, loss is 3.823214154243469 and perplexity is 45.75102309681817
At time: 498.04685044288635 and batch: 750, loss is 3.784480848312378 and perplexity is 44.01281529925038
At time: 499.21169877052307 and batch: 800, loss is 3.7532664251327517 and perplexity is 42.66020101821369
At time: 500.37524008750916 and batch: 850, loss is 3.752135157585144 and perplexity is 42.611968204479716
At time: 501.54810905456543 and batch: 900, loss is 3.720214858055115 and perplexity is 41.2732610486071
At time: 502.7130937576294 and batch: 950, loss is 3.8240353536605833 and perplexity is 45.78860924106529
At time: 503.8771319389343 and batch: 1000, loss is 3.7899445343017577 and perplexity is 44.25394563191527
At time: 505.0483090877533 and batch: 1050, loss is 3.727749857902527 and perplexity is 41.585429682637184
At time: 506.2215690612793 and batch: 1100, loss is 3.761687455177307 and perplexity is 43.020960704875726
At time: 507.3898296356201 and batch: 1150, loss is 3.7339461612701417 and perplexity is 41.843905591197824
At time: 508.5538024902344 and batch: 1200, loss is 3.7846687173843385 and perplexity is 44.02108472277516
At time: 509.7179493904114 and batch: 1250, loss is 3.759573612213135 and perplexity is 42.930117198058234
At time: 510.8810522556305 and batch: 1300, loss is 3.758826284408569 and perplexity is 42.89804631304753
At time: 512.0443649291992 and batch: 1350, loss is 3.6238309955596923 and perplexity is 37.48088222172428
At time: 513.2107808589935 and batch: 1400, loss is 3.650533652305603 and perplexity is 38.495203622750886
At time: 514.3748726844788 and batch: 1450, loss is 3.5715184688568113 and perplexity is 35.57056495911322
At time: 515.5386142730713 and batch: 1500, loss is 3.550208954811096 and perplexity is 34.82059265784571
At time: 516.7028477191925 and batch: 1550, loss is 3.5677971839904785 and perplexity is 35.438442738722166
At time: 517.8666276931763 and batch: 1600, loss is 3.658904585838318 and perplexity is 38.81879691298623
At time: 519.0280575752258 and batch: 1650, loss is 3.589215807914734 and perplexity is 36.20567258920971
At time: 520.1933486461639 and batch: 1700, loss is 3.6001560926437377 and perplexity is 36.60394760472804
At time: 521.3575336933136 and batch: 1750, loss is 3.58558394908905 and perplexity is 36.074417192488156
At time: 522.5293428897858 and batch: 1800, loss is 3.52501754283905 and perplexity is 33.95436926705793
At time: 523.6996128559113 and batch: 1850, loss is 3.5655542516708376 and perplexity is 35.35904578442866
At time: 524.8665904998779 and batch: 1900, loss is 3.643080277442932 and perplexity is 38.209351046264295
At time: 526.0328197479248 and batch: 1950, loss is 3.5774120712280273 and perplexity is 35.78082270427416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379138751362645 and perplexity of 79.76930260900595
finished 11 epochs...
Completing Train Step...
At time: 529.7415273189545 and batch: 50, loss is 3.8273412466049193 and perplexity is 45.94023196744749
At time: 530.8943417072296 and batch: 100, loss is 3.8161875009536743 and perplexity is 45.4306733313045
At time: 532.0480246543884 and batch: 150, loss is 3.7863160800933837 and perplexity is 44.09366318126853
At time: 533.2018902301788 and batch: 200, loss is 3.8027589607238768 and perplexity is 44.82468359187162
At time: 534.3539242744446 and batch: 250, loss is 3.799218235015869 and perplexity is 44.66625232866544
At time: 535.5071127414703 and batch: 300, loss is 3.8006011390686036 and perplexity is 44.72806420012411
At time: 536.6598443984985 and batch: 350, loss is 3.8336256313323975 and perplexity is 46.22984713300328
At time: 537.8126015663147 and batch: 400, loss is 3.817569766044617 and perplexity is 45.49351398632466
At time: 538.9628000259399 and batch: 450, loss is 3.836784315109253 and perplexity is 46.37610346830221
At time: 540.1158576011658 and batch: 500, loss is 3.8402649927139283 and perplexity is 46.537804985208005
At time: 541.2693476676941 and batch: 550, loss is 3.8037226963043214 and perplexity is 44.86790355729533
At time: 542.4245476722717 and batch: 600, loss is 3.757594747543335 and perplexity is 42.84524830558593
At time: 543.5759193897247 and batch: 650, loss is 3.7654233169555664 and perplexity is 43.181981656369935
At time: 544.7718346118927 and batch: 700, loss is 3.809077429771423 and perplexity is 45.10880362428396
At time: 545.9239342212677 and batch: 750, loss is 3.772037148475647 and perplexity is 43.46852654302859
At time: 547.0758686065674 and batch: 800, loss is 3.7407952547073364 and perplexity is 42.131482105391534
At time: 548.2275133132935 and batch: 850, loss is 3.7394554567337037 and perplexity is 42.075072228398284
At time: 549.379682302475 and batch: 900, loss is 3.7080045413970946 and perplexity is 40.77236573018764
At time: 550.5318207740784 and batch: 950, loss is 3.8115723514556885 and perplexity is 45.22148706632787
At time: 551.6851308345795 and batch: 1000, loss is 3.7779118824005127 and perplexity is 43.72464414535397
At time: 552.8380839824677 and batch: 1050, loss is 3.7156566762924195 and perplexity is 41.08555813978842
At time: 553.9908359050751 and batch: 1100, loss is 3.749878649711609 and perplexity is 42.51592236756714
At time: 555.1431849002838 and batch: 1150, loss is 3.721886730194092 and perplexity is 41.34232237860931
At time: 556.2953779697418 and batch: 1200, loss is 3.7723011493682863 and perplexity is 43.48000378777244
At time: 557.4488253593445 and batch: 1250, loss is 3.7493622303009033 and perplexity is 42.49397198828128
At time: 558.6014142036438 and batch: 1300, loss is 3.7493022012710573 and perplexity is 42.491421192930176
At time: 559.7527906894684 and batch: 1350, loss is 3.6157369089126585 and perplexity is 37.17873317329048
At time: 560.9104664325714 and batch: 1400, loss is 3.643780202865601 and perplexity is 38.23610410392566
At time: 562.063805103302 and batch: 1450, loss is 3.566406364440918 and perplexity is 35.38918851956032
At time: 563.2150177955627 and batch: 1500, loss is 3.547116799354553 and perplexity is 34.71308826805936
At time: 564.366913318634 and batch: 1550, loss is 3.565775213241577 and perplexity is 35.366859637973924
At time: 565.5203785896301 and batch: 1600, loss is 3.6583327531814573 and perplexity is 38.79660540273118
At time: 566.6858267784119 and batch: 1650, loss is 3.589676570892334 and perplexity is 36.22235866658607
At time: 567.8376474380493 and batch: 1700, loss is 3.601765899658203 and perplexity is 36.662920350973984
At time: 568.9968979358673 and batch: 1750, loss is 3.5886431884765626 and perplexity is 36.184946451973914
At time: 570.1498515605927 and batch: 1800, loss is 3.5293288612365723 and perplexity is 34.10107338078944
At time: 571.3014717102051 and batch: 1850, loss is 3.570497303009033 and perplexity is 35.534260052810836
At time: 572.4548919200897 and batch: 1900, loss is 3.6481383848190307 and perplexity is 38.40310765439554
At time: 573.6061174869537 and batch: 1950, loss is 3.5817014598846435 and perplexity is 35.934630193532726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377682424146076 and perplexity of 79.6532169524373
finished 12 epochs...
Completing Train Step...
At time: 577.2313396930695 and batch: 50, loss is 3.8205545949935913 and perplexity is 45.629507201137905
At time: 578.4516181945801 and batch: 100, loss is 3.8072409057617187 and perplexity is 45.026036248778375
At time: 579.6081953048706 and batch: 150, loss is 3.7761539602279663 and perplexity is 43.64784714527585
At time: 580.7639408111572 and batch: 200, loss is 3.7923009967803956 and perplexity is 44.35835136010607
At time: 581.9184174537659 and batch: 250, loss is 3.787971549034119 and perplexity is 44.166719325552585
At time: 583.0739161968231 and batch: 300, loss is 3.7887424564361574 and perplexity is 44.20078090387895
At time: 584.2293918132782 and batch: 350, loss is 3.8218168020248413 and perplexity is 45.68713744896045
At time: 585.3859267234802 and batch: 400, loss is 3.806318850517273 and perplexity is 44.98453889028715
At time: 586.5467703342438 and batch: 450, loss is 3.826042094230652 and perplexity is 45.88058735811949
At time: 587.7046945095062 and batch: 500, loss is 3.830014624595642 and perplexity is 46.063211885136326
At time: 588.8598659038544 and batch: 550, loss is 3.793988766670227 and perplexity is 44.43328126432541
At time: 590.0198152065277 and batch: 600, loss is 3.748810157775879 and perplexity is 42.47051870841879
At time: 591.1743748188019 and batch: 650, loss is 3.756417598724365 and perplexity is 42.794842745387875
At time: 592.3282206058502 and batch: 700, loss is 3.800780539512634 and perplexity is 44.736089154520904
At time: 593.4830896854401 and batch: 750, loss is 3.764072422981262 and perplexity is 43.12368676152818
At time: 594.6395933628082 and batch: 800, loss is 3.7327883529663084 and perplexity is 41.79548640531616
At time: 595.7955422401428 and batch: 850, loss is 3.7316254281997683 and perplexity is 41.74690965007628
At time: 596.951849937439 and batch: 900, loss is 3.700360360145569 and perplexity is 40.461882583101975
At time: 598.1082227230072 and batch: 950, loss is 3.804122905731201 and perplexity is 44.88586370893457
At time: 599.2649857997894 and batch: 1000, loss is 3.770583543777466 and perplexity is 43.405386390151826
At time: 600.4229094982147 and batch: 1050, loss is 3.708673300743103 and perplexity is 40.7996417503587
At time: 601.6209526062012 and batch: 1100, loss is 3.74310188293457 and perplexity is 42.22877593848398
At time: 602.778064250946 and batch: 1150, loss is 3.7153084802627565 and perplexity is 41.0712548018949
At time: 603.9348087310791 and batch: 1200, loss is 3.7655075788497925 and perplexity is 43.18562040524252
At time: 605.0910246372223 and batch: 1250, loss is 3.7436530923843385 and perplexity is 42.252059255236006
At time: 606.2463064193726 and batch: 1300, loss is 3.7442008018493653 and perplexity is 42.27520744667007
At time: 607.4006230831146 and batch: 1350, loss is 3.611207642555237 and perplexity is 37.01072155981074
At time: 608.5574440956116 and batch: 1400, loss is 3.63981315612793 and perplexity is 38.084720163994625
At time: 609.711811542511 and batch: 1450, loss is 3.5630873107910155 and perplexity is 35.27192461448285
At time: 610.8671050071716 and batch: 1500, loss is 3.544607720375061 and perplexity is 34.62609956437293
At time: 612.0219388008118 and batch: 1550, loss is 3.5637583208084105 and perplexity is 35.295600371678745
At time: 613.176281452179 and batch: 1600, loss is 3.6568736457824706 and perplexity is 38.74003826753117
At time: 614.3367094993591 and batch: 1650, loss is 3.588813552856445 and perplexity is 36.19111160308345
At time: 615.4911024570465 and batch: 1700, loss is 3.6017262983322142 and perplexity is 36.661468479461675
At time: 616.6451926231384 and batch: 1750, loss is 3.5891031217575073 and perplexity is 36.20159294096008
At time: 617.7996754646301 and batch: 1800, loss is 3.5303252267837526 and perplexity is 34.13506744787426
At time: 618.9558403491974 and batch: 1850, loss is 3.5718981409072876 and perplexity is 35.58407267253621
At time: 620.1156010627747 and batch: 1900, loss is 3.6493893480300903 and perplexity is 38.451178590478946
At time: 621.272171497345 and batch: 1950, loss is 3.5825114107131957 and perplexity is 35.96374726713886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377363621911337 and perplexity of 79.62782737621065
finished 13 epochs...
Completing Train Step...
At time: 624.9035167694092 and batch: 50, loss is 3.814062490463257 and perplexity is 45.334235176224595
At time: 626.081785440445 and batch: 100, loss is 3.7998393201828002 and perplexity is 44.69400249216459
At time: 627.2357039451599 and batch: 150, loss is 3.767961573600769 and perplexity is 43.29172783131894
At time: 628.3909070491791 and batch: 200, loss is 3.7839882135391236 and perplexity is 43.99113839580175
At time: 629.5476093292236 and batch: 250, loss is 3.7792559099197387 and perplexity is 43.78345078036917
At time: 630.7247416973114 and batch: 300, loss is 3.779740557670593 and perplexity is 43.80467547414913
At time: 631.8781046867371 and batch: 350, loss is 3.8128411245346068 and perplexity is 45.27889928554357
At time: 633.0325543880463 and batch: 400, loss is 3.797517318725586 and perplexity is 44.59034334816559
At time: 634.1849477291107 and batch: 450, loss is 3.8178802967071532 and perplexity is 45.50764331104468
At time: 635.3385858535767 and batch: 500, loss is 3.8222797107696533 and perplexity is 45.70829132018925
At time: 636.4930710792542 and batch: 550, loss is 3.7866306781768797 and perplexity is 44.10753714544652
At time: 637.6468346118927 and batch: 600, loss is 3.741940999031067 and perplexity is 42.17978167605991
At time: 638.8030188083649 and batch: 650, loss is 3.7492696762084963 and perplexity is 42.49003917927273
At time: 639.9575431346893 and batch: 700, loss is 3.794210968017578 and perplexity is 44.44315549628277
At time: 641.1139767169952 and batch: 750, loss is 3.757579116821289 and perplexity is 42.84457860865262
At time: 642.2706797122955 and batch: 800, loss is 3.726203427314758 and perplexity is 41.52117040123565
At time: 643.4265294075012 and batch: 850, loss is 3.725301003456116 and perplexity is 41.48371760811556
At time: 644.5809695720673 and batch: 900, loss is 3.6941776847839356 and perplexity is 40.212491644599
At time: 645.7457973957062 and batch: 950, loss is 3.7981005334854125 and perplexity is 44.616356679494025
At time: 646.909065246582 and batch: 1000, loss is 3.7647665119171143 and perplexity is 43.15362882540806
At time: 648.0638573169708 and batch: 1050, loss is 3.7030563831329344 and perplexity is 40.57111593030172
At time: 649.2289643287659 and batch: 1100, loss is 3.7377394676208495 and perplexity is 42.00293377463412
At time: 650.3932592868805 and batch: 1150, loss is 3.710126757621765 and perplexity is 40.85898538656871
At time: 651.556450843811 and batch: 1200, loss is 3.759985690116882 and perplexity is 42.947811396204486
At time: 652.7196815013885 and batch: 1250, loss is 3.7388567113876343 and perplexity is 42.04988751508333
At time: 653.8829169273376 and batch: 1300, loss is 3.739879126548767 and perplexity is 42.09290194315736
At time: 655.0474390983582 and batch: 1350, loss is 3.607174015045166 and perplexity is 36.86173477575799
At time: 656.213958978653 and batch: 1400, loss is 3.636083302497864 and perplexity is 37.942934316843996
At time: 657.3788647651672 and batch: 1450, loss is 3.559809832572937 and perplexity is 35.156510886152695
At time: 658.542240858078 and batch: 1500, loss is 3.541873230934143 and perplexity is 34.53154419997602
At time: 659.7074162960052 and batch: 1550, loss is 3.5613110160827635 and perplexity is 35.20932689389933
At time: 660.8765585422516 and batch: 1600, loss is 3.6546936511993406 and perplexity is 38.65567718072347
At time: 662.0401268005371 and batch: 1650, loss is 3.587154974937439 and perplexity is 36.13113557572053
At time: 663.2075140476227 and batch: 1700, loss is 3.6007431602478026 and perplexity is 36.62544290552768
At time: 664.3794615268707 and batch: 1750, loss is 3.58843692779541 and perplexity is 36.17748368993491
At time: 665.5458209514618 and batch: 1800, loss is 3.5300866889953615 and perplexity is 34.126925915448844
At time: 666.7130422592163 and batch: 1850, loss is 3.5719883394241334 and perplexity is 35.58728244787092
At time: 667.8780488967896 and batch: 1900, loss is 3.6494174098968504 and perplexity is 38.45225761746901
At time: 669.0456576347351 and batch: 1950, loss is 3.582299828529358 and perplexity is 35.95613878389122
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377437147983285 and perplexity of 79.63368231281792
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 672.7467541694641 and batch: 50, loss is 3.811802849769592 and perplexity is 45.231911744238054
At time: 673.9367272853851 and batch: 100, loss is 3.8018403911590575 and perplexity is 44.78352790684514
At time: 675.1002447605133 and batch: 150, loss is 3.772627115249634 and perplexity is 43.49417909573597
At time: 676.2654774188995 and batch: 200, loss is 3.7913639068603517 and perplexity is 44.316803066460764
At time: 677.4501292705536 and batch: 250, loss is 3.7905414581298826 and perplexity is 44.28036975236046
At time: 678.6188824176788 and batch: 300, loss is 3.7900457525253297 and perplexity is 44.258425164379524
At time: 679.787558555603 and batch: 350, loss is 3.829152774810791 and perplexity is 46.023529418502534
At time: 680.955438375473 and batch: 400, loss is 3.8215457725524904 and perplexity is 45.6747565660723
At time: 682.1208963394165 and batch: 450, loss is 3.851984429359436 and perplexity is 47.086410235580466
At time: 683.2858963012695 and batch: 500, loss is 3.8644820928573607 and perplexity is 47.67857296373633
At time: 684.4516713619232 and batch: 550, loss is 3.8392982292175293 and perplexity is 46.49283567499203
At time: 685.6172614097595 and batch: 600, loss is 3.7914099359512328 and perplexity is 44.31884297556389
At time: 686.7799677848816 and batch: 650, loss is 3.7864019107818603 and perplexity is 44.09744793315844
At time: 687.9458334445953 and batch: 700, loss is 3.828370909690857 and perplexity is 45.98755928988082
At time: 689.1553411483765 and batch: 750, loss is 3.786419630050659 and perplexity is 44.09822931461445
At time: 690.3198237419128 and batch: 800, loss is 3.742499132156372 and perplexity is 42.20333018042033
At time: 691.4833781719208 and batch: 850, loss is 3.738542985916138 and perplexity is 42.036697463432056
At time: 692.6467597484589 and batch: 900, loss is 3.697823576927185 and perplexity is 40.35936963991279
At time: 693.8101749420166 and batch: 950, loss is 3.801267466545105 and perplexity is 44.75787766993534
At time: 694.9767274856567 and batch: 1000, loss is 3.772485671043396 and perplexity is 43.48802753115965
At time: 696.1415674686432 and batch: 1050, loss is 3.7133795022964478 and perplexity is 40.99210561939049
At time: 697.3077960014343 and batch: 1100, loss is 3.745013270378113 and perplexity is 42.309568679086574
At time: 698.4728045463562 and batch: 1150, loss is 3.7163543796539305 and perplexity is 41.11423367415722
At time: 699.6381349563599 and batch: 1200, loss is 3.760990571975708 and perplexity is 42.99099056410058
At time: 700.8030228614807 and batch: 1250, loss is 3.740709481239319 and perplexity is 42.127868497036715
At time: 701.9675545692444 and batch: 1300, loss is 3.7440429878234864 and perplexity is 42.268536352398016
At time: 703.1317224502563 and batch: 1350, loss is 3.607429447174072 and perplexity is 36.871151649781815
At time: 704.2970583438873 and batch: 1400, loss is 3.633505845069885 and perplexity is 37.845263943635224
At time: 705.462149143219 and batch: 1450, loss is 3.553436827659607 and perplexity is 34.93317069950965
At time: 706.6286768913269 and batch: 1500, loss is 3.533593564033508 and perplexity is 34.24681487500231
At time: 707.7943599224091 and batch: 1550, loss is 3.5545465755462646 and perplexity is 34.971959230632095
At time: 708.9602930545807 and batch: 1600, loss is 3.649547142982483 and perplexity is 38.457246471101946
At time: 710.1280205249786 and batch: 1650, loss is 3.582272381782532 and perplexity is 35.95515191839637
At time: 711.2949512004852 and batch: 1700, loss is 3.595872540473938 and perplexity is 36.4474880261635
At time: 712.4597570896149 and batch: 1750, loss is 3.584570174217224 and perplexity is 36.037864386111494
At time: 713.6243934631348 and batch: 1800, loss is 3.526294107437134 and perplexity is 33.99774189090251
At time: 714.790534734726 and batch: 1850, loss is 3.5668238162994386 and perplexity is 35.40396488607559
At time: 715.9548590183258 and batch: 1900, loss is 3.648484191894531 and perplexity is 38.41639001717879
At time: 717.1199111938477 and batch: 1950, loss is 3.588615779876709 and perplexity is 36.18395468684739
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370228470203489 and perplexity of 79.06169287732524
finished 15 epochs...
Completing Train Step...
At time: 720.8269970417023 and batch: 50, loss is 3.8183453989028933 and perplexity is 45.52881393874268
At time: 721.9896636009216 and batch: 100, loss is 3.803313217163086 and perplexity is 44.849534847736024
At time: 723.151689529419 and batch: 150, loss is 3.7686668157577516 and perplexity is 43.32226975129307
At time: 724.3183605670929 and batch: 200, loss is 3.7838799953460693 and perplexity is 43.98637801187887
At time: 725.4819254875183 and batch: 250, loss is 3.780623993873596 and perplexity is 43.84339120924679
At time: 726.6444356441498 and batch: 300, loss is 3.7781960916519166 and perplexity is 43.73707285982858
At time: 727.80743932724 and batch: 350, loss is 3.8123776054382326 and perplexity is 45.25791651439515
At time: 728.971079826355 and batch: 400, loss is 3.802673316001892 and perplexity is 44.82084475869759
At time: 730.1342053413391 and batch: 450, loss is 3.831936044692993 and perplexity is 46.15180375004011
At time: 731.2965586185455 and batch: 500, loss is 3.8444844484329224 and perplexity is 46.7345840509281
At time: 732.4597482681274 and batch: 550, loss is 3.819577431678772 and perplexity is 45.58494149815883
At time: 733.6271584033966 and batch: 600, loss is 3.774402313232422 and perplexity is 43.57145844751006
At time: 734.7893476486206 and batch: 650, loss is 3.7712706470489503 and perplexity is 43.43522062156579
At time: 735.9505774974823 and batch: 700, loss is 3.8145466470718383 and perplexity is 45.35618935998287
At time: 737.1125214099884 and batch: 750, loss is 3.773597493171692 and perplexity is 43.53640537127781
At time: 738.2749133110046 and batch: 800, loss is 3.7320124101638794 and perplexity is 41.763068077476575
At time: 739.4380469322205 and batch: 850, loss is 3.728920841217041 and perplexity is 41.63415404906491
At time: 740.6049535274506 and batch: 900, loss is 3.689886450767517 and perplexity is 40.04030015379773
At time: 741.7686812877655 and batch: 950, loss is 3.7947128868103026 and perplexity is 44.4654679502859
At time: 742.9314770698547 and batch: 1000, loss is 3.7653452348709107 and perplexity is 43.17861004885542
At time: 744.0945100784302 and batch: 1050, loss is 3.706232719421387 and perplexity is 40.70018831823016
At time: 745.2585504055023 and batch: 1100, loss is 3.738946852684021 and perplexity is 42.053678117299185
At time: 746.4658770561218 and batch: 1150, loss is 3.7111762523651124 and perplexity is 40.90188918666876
At time: 747.6289653778076 and batch: 1200, loss is 3.7567266511917112 and perplexity is 42.80807064107964
At time: 748.7928795814514 and batch: 1250, loss is 3.7367104148864745 and perplexity is 41.95973277264848
At time: 749.9577367305756 and batch: 1300, loss is 3.739292416572571 and perplexity is 42.06821286103387
At time: 751.1191658973694 and batch: 1350, loss is 3.603975324630737 and perplexity is 36.74401387480322
At time: 752.2805271148682 and batch: 1400, loss is 3.631791706085205 and perplexity is 37.78044746941729
At time: 753.4472110271454 and batch: 1450, loss is 3.553446960449219 and perplexity is 34.93352467177218
At time: 754.6125695705414 and batch: 1500, loss is 3.535513381958008 and perplexity is 34.312625676221025
At time: 755.7746047973633 and batch: 1550, loss is 3.557401809692383 and perplexity is 35.07195505059036
At time: 756.9401309490204 and batch: 1600, loss is 3.653618698120117 and perplexity is 38.61414646729187
At time: 758.1102499961853 and batch: 1650, loss is 3.5871916818618774 and perplexity is 36.13246186292579
At time: 759.2761993408203 and batch: 1700, loss is 3.600949864387512 and perplexity is 36.633014318689206
At time: 760.4418873786926 and batch: 1750, loss is 3.5899190044403078 and perplexity is 36.231141246066514
At time: 761.6063210964203 and batch: 1800, loss is 3.531420373916626 and perplexity is 34.17247084649431
At time: 762.7688512802124 and batch: 1850, loss is 3.572335915565491 and perplexity is 35.59965388806972
At time: 763.9316799640656 and batch: 1900, loss is 3.654334397315979 and perplexity is 38.64179247279929
At time: 765.0986216068268 and batch: 1950, loss is 3.593871898651123 and perplexity is 36.374642550431886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368475199854651 and perplexity of 78.9231978006076
finished 16 epochs...
Completing Train Step...
At time: 768.7959594726562 and batch: 50, loss is 3.818240900039673 and perplexity is 45.52405647802126
At time: 769.964772939682 and batch: 100, loss is 3.8009357023239136 and perplexity is 44.74303107042944
At time: 771.1309413909912 and batch: 150, loss is 3.764977011680603 and perplexity is 43.16271361020848
At time: 772.292610168457 and batch: 200, loss is 3.7796196031570433 and perplexity is 43.7993774213541
At time: 773.4560363292694 and batch: 250, loss is 3.775713758468628 and perplexity is 43.62863751453799
At time: 774.6300950050354 and batch: 300, loss is 3.7729643249511717 and perplexity is 43.50884822803534
At time: 775.8371579647064 and batch: 350, loss is 3.8060986471176146 and perplexity is 44.974634232451116
At time: 777.0061433315277 and batch: 400, loss is 3.796004285812378 and perplexity is 44.52292770497313
At time: 778.1694667339325 and batch: 450, loss is 3.8249976873397826 and perplexity is 45.83269437076197
At time: 779.3365380764008 and batch: 500, loss is 3.8377304029464723 and perplexity is 46.420000097490416
At time: 780.505619764328 and batch: 550, loss is 3.812746205329895 and perplexity is 45.27460165240034
At time: 781.6736662387848 and batch: 600, loss is 3.7684485054016115 and perplexity is 43.312813083436694
At time: 782.838137626648 and batch: 650, loss is 3.765948281288147 and perplexity is 43.20465660779929
At time: 784.0025434494019 and batch: 700, loss is 3.8098561573028564 and perplexity is 45.14394477249015
At time: 785.170414686203 and batch: 750, loss is 3.769319658279419 and perplexity is 43.35056160517963
At time: 786.3359351158142 and batch: 800, loss is 3.7283179473876955 and perplexity is 41.609060639589664
At time: 787.5065910816193 and batch: 850, loss is 3.7255080938339233 and perplexity is 41.492309376473465
At time: 788.6715762615204 and batch: 900, loss is 3.6870319080352782 and perplexity is 39.92616638336026
At time: 789.8360948562622 and batch: 950, loss is 3.7922667121887206 and perplexity is 44.356830578212154
At time: 791.000155210495 and batch: 1000, loss is 3.7626290702819825 and perplexity is 43.06148896931156
At time: 792.1638944149017 and batch: 1050, loss is 3.703816475868225 and perplexity is 40.60196546355078
At time: 793.3304431438446 and batch: 1100, loss is 3.736688117980957 and perplexity is 41.958797210881414
At time: 794.4936847686768 and batch: 1150, loss is 3.7092544841766357 and perplexity is 40.823360718106
At time: 795.6578109264374 and batch: 1200, loss is 3.754805574417114 and perplexity is 42.7259119926089
At time: 796.8215065002441 and batch: 1250, loss is 3.735046443939209 and perplexity is 41.88997105319333
At time: 797.9838280677795 and batch: 1300, loss is 3.737613310813904 and perplexity is 41.9976351528624
At time: 799.1537578105927 and batch: 1350, loss is 3.602832722663879 and perplexity is 36.702054068523225
At time: 800.3183121681213 and batch: 1400, loss is 3.6310677337646484 and perplexity is 37.75310536984707
At time: 801.482421875 and batch: 1450, loss is 3.5533706378936767 and perplexity is 34.93085855763875
At time: 802.6457500457764 and batch: 1500, loss is 3.5360086011886596 and perplexity is 34.32962215645462
At time: 803.8100690841675 and batch: 1550, loss is 3.5583008766174316 and perplexity is 35.103501264326866
At time: 804.9742877483368 and batch: 1600, loss is 3.654958176612854 and perplexity is 38.665903942273864
At time: 806.1386721134186 and batch: 1650, loss is 3.5887741613388062 and perplexity is 36.18968600835072
At time: 807.303085565567 and batch: 1700, loss is 3.6026303291320803 and perplexity is 36.69462656184103
At time: 808.4667065143585 and batch: 1750, loss is 3.5915607023239136 and perplexity is 36.29067068527782
At time: 809.6307685375214 and batch: 1800, loss is 3.5331269693374634 and perplexity is 34.23083922019295
At time: 810.795330286026 and batch: 1850, loss is 3.574029064178467 and perplexity is 35.65998044917759
At time: 811.9689719676971 and batch: 1900, loss is 3.6559313917160035 and perplexity is 38.70355250106887
At time: 813.1329262256622 and batch: 1950, loss is 3.5950025367736815 and perplexity is 36.415792366385546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367809206940407 and perplexity of 78.87065300927445
finished 17 epochs...
Completing Train Step...
At time: 816.8479633331299 and batch: 50, loss is 3.8166165447235105 and perplexity is 45.450169260661205
At time: 818.0107312202454 and batch: 100, loss is 3.798249855041504 and perplexity is 44.623019360729124
At time: 819.177734375 and batch: 150, loss is 3.761818318367004 and perplexity is 43.026590933404194
At time: 820.3414478302002 and batch: 200, loss is 3.77630615234375 and perplexity is 43.65449050900326
At time: 821.5031762123108 and batch: 250, loss is 3.7721290493011477 and perplexity is 43.47252152006923
At time: 822.6652266979218 and batch: 300, loss is 3.769264540672302 and perplexity is 43.34817229180401
At time: 823.827675819397 and batch: 350, loss is 3.8020767307281496 and perplexity is 44.79411327735475
At time: 824.9908857345581 and batch: 400, loss is 3.791836004257202 and perplexity is 44.337729853177265
At time: 826.1579082012177 and batch: 450, loss is 3.8208624792098997 and perplexity is 45.64355796909692
At time: 827.3248353004456 and batch: 500, loss is 3.8338136863708496 and perplexity is 46.238541706187036
At time: 828.4878489971161 and batch: 550, loss is 3.8088430166244507 and perplexity is 45.098230766927024
At time: 829.6506502628326 and batch: 600, loss is 3.765040202140808 and perplexity is 43.165441168122115
At time: 830.818193435669 and batch: 650, loss is 3.7628077554702757 and perplexity is 43.06918410705932
At time: 831.9812090396881 and batch: 700, loss is 3.8070903539657595 and perplexity is 45.01925800840713
At time: 833.1446349620819 and batch: 750, loss is 3.766848406791687 and perplexity is 43.24356372910278
At time: 834.3494546413422 and batch: 800, loss is 3.72599449634552 and perplexity is 41.51249624904088
At time: 835.5120530128479 and batch: 850, loss is 3.723296732902527 and perplexity is 41.400656280951786
At time: 836.6760137081146 and batch: 900, loss is 3.685014696121216 and perplexity is 39.845708022913605
At time: 837.8398377895355 and batch: 950, loss is 3.790467133522034 and perplexity is 44.27707875354583
At time: 839.004034280777 and batch: 1000, loss is 3.760710825920105 and perplexity is 42.97896568609832
At time: 840.1668944358826 and batch: 1050, loss is 3.7021075010299684 and perplexity is 40.53263698337727
At time: 841.3300154209137 and batch: 1100, loss is 3.7350381088256834 and perplexity is 41.889621896984146
At time: 842.493551492691 and batch: 1150, loss is 3.7077677631378174 and perplexity is 40.762712863243046
At time: 843.6604249477386 and batch: 1200, loss is 3.7532922792434693 and perplexity is 42.66130397403196
At time: 844.825332403183 and batch: 1250, loss is 3.733732328414917 and perplexity is 41.834958945968935
At time: 845.9866569042206 and batch: 1300, loss is 3.7364128017425537 and perplexity is 41.94724686273755
At time: 847.1482555866241 and batch: 1350, loss is 3.6019284868240358 and perplexity is 36.66888175589584
At time: 848.3112630844116 and batch: 1400, loss is 3.63029983997345 and perplexity is 37.72412612255113
At time: 849.4742043018341 and batch: 1450, loss is 3.5529119682312014 and perplexity is 34.91484050631206
At time: 850.640275478363 and batch: 1500, loss is 3.535848841667175 and perplexity is 34.32413811052211
At time: 851.8045156002045 and batch: 1550, loss is 3.5583762311935425 and perplexity is 35.106146573451475
At time: 852.9707725048065 and batch: 1600, loss is 3.6552449226379395 and perplexity is 38.67699282630639
At time: 854.1368138790131 and batch: 1650, loss is 3.5892455053329466 and perplexity is 36.20674782017597
At time: 855.3003470897675 and batch: 1700, loss is 3.603171715736389 and perplexity is 36.71449791966983
At time: 856.4647462368011 and batch: 1750, loss is 3.592106971740723 and perplexity is 36.31050058452931
At time: 857.6336777210236 and batch: 1800, loss is 3.533776273727417 and perplexity is 34.253072671728134
At time: 858.7965774536133 and batch: 1850, loss is 3.574649438858032 and perplexity is 35.68210986167591
At time: 859.9601159095764 and batch: 1900, loss is 3.656457757949829 and perplexity is 38.723930106805845
At time: 861.1225779056549 and batch: 1950, loss is 3.5952443838119508 and perplexity is 36.42460048298111
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367542923328489 and perplexity of 78.84965384290777
finished 18 epochs...
Completing Train Step...
At time: 864.7930555343628 and batch: 50, loss is 3.814845142364502 and perplexity is 45.36972998980658
At time: 865.9698185920715 and batch: 100, loss is 3.795874361991882 and perplexity is 44.51714349186771
At time: 867.133551120758 and batch: 150, loss is 3.7592077589035036 and perplexity is 42.91441394531711
At time: 868.2895567417145 and batch: 200, loss is 3.77363311290741 and perplexity is 43.53795615415031
At time: 869.442137002945 and batch: 250, loss is 3.769290246963501 and perplexity is 43.34928662686654
At time: 870.601142168045 and batch: 300, loss is 3.7663378047943117 and perplexity is 43.22148911523964
At time: 871.7516984939575 and batch: 350, loss is 3.7989811277389527 and perplexity is 44.65566289067174
At time: 872.9028866291046 and batch: 400, loss is 3.7886597108840943 and perplexity is 44.1971236371748
At time: 874.0575289726257 and batch: 450, loss is 3.8177594757080078 and perplexity is 45.50214536425148
At time: 875.2084321975708 and batch: 500, loss is 3.83089035987854 and perplexity is 46.103568733406526
At time: 876.3609709739685 and batch: 550, loss is 3.8059595346450807 and perplexity is 44.968378135042414
At time: 877.5085954666138 and batch: 600, loss is 3.7624918842315673 and perplexity is 43.05558193890521
At time: 878.6594445705414 and batch: 650, loss is 3.7603911638259886 and perplexity is 42.965229135568364
At time: 879.8097009658813 and batch: 700, loss is 3.8049419021606443 and perplexity is 44.9226401288673
At time: 880.9599990844727 and batch: 750, loss is 3.7649212169647215 and perplexity is 43.16030542604852
At time: 882.1088969707489 and batch: 800, loss is 3.724091606140137 and perplexity is 41.43357763706808
At time: 883.2565948963165 and batch: 850, loss is 3.7214650917053222 and perplexity is 41.3248945386616
At time: 884.4067440032959 and batch: 900, loss is 3.6832581090927126 and perplexity is 39.775777006998325
At time: 885.555370092392 and batch: 950, loss is 3.7888612508773805 and perplexity is 44.20603202284374
At time: 886.7047817707062 and batch: 1000, loss is 3.7590534257888795 and perplexity is 42.907791341207364
At time: 887.8584682941437 and batch: 1050, loss is 3.7005841398239134 and perplexity is 40.470938143359035
At time: 889.011556148529 and batch: 1100, loss is 3.733562932014465 and perplexity is 41.82787285470657
At time: 890.1611380577087 and batch: 1150, loss is 3.7063812017440796 and perplexity is 40.706232025406415
At time: 891.3540556430817 and batch: 1200, loss is 3.7519118213653564 and perplexity is 42.60245247122671
At time: 892.5018677711487 and batch: 1250, loss is 3.732506537437439 and perplexity is 41.783709447753196
At time: 893.6524348258972 and batch: 1300, loss is 3.7353166007995604 and perplexity is 41.90128944505503
At time: 894.805846452713 and batch: 1350, loss is 3.601037788391113 and perplexity is 36.63623538157437
At time: 895.9586133956909 and batch: 1400, loss is 3.629470343589783 and perplexity is 37.692847071079015
At time: 897.1118342876434 and batch: 1450, loss is 3.5522696495056154 and perplexity is 34.89242125137844
At time: 898.2627599239349 and batch: 1500, loss is 3.535418872833252 and perplexity is 34.30938297323521
At time: 899.4134175777435 and batch: 1550, loss is 3.5581091976165773 and perplexity is 35.096773305102886
At time: 900.5647912025452 and batch: 1600, loss is 3.6551052951812744 and perplexity is 38.67159283316902
At time: 901.7170503139496 and batch: 1650, loss is 3.5892800378799437 and perplexity is 36.20799815298515
At time: 902.8700590133667 and batch: 1700, loss is 3.6032619047164918 and perplexity is 36.717809312115506
At time: 904.0230188369751 and batch: 1750, loss is 3.592235288619995 and perplexity is 36.31516013359214
At time: 905.1749176979065 and batch: 1800, loss is 3.5340004682540895 and perplexity is 34.26075288404146
At time: 906.326771736145 and batch: 1850, loss is 3.5748642587661745 and perplexity is 35.68977591261942
At time: 907.4803521633148 and batch: 1900, loss is 3.6566141939163206 and perplexity is 38.72998839609326
At time: 908.6334264278412 and batch: 1950, loss is 3.5952141857147217 and perplexity is 36.423500545962284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367458609647529 and perplexity of 78.84300601860508
finished 19 epochs...
Completing Train Step...
At time: 912.231113910675 and batch: 50, loss is 3.8131328678131102 and perplexity is 45.29211102719286
At time: 913.4089572429657 and batch: 100, loss is 3.793760976791382 and perplexity is 44.423160965264124
At time: 914.5631260871887 and batch: 150, loss is 3.7569494009017945 and perplexity is 42.81760718849632
At time: 915.7163543701172 and batch: 200, loss is 3.7713454246520994 and perplexity is 43.438468724697294
At time: 916.8751437664032 and batch: 250, loss is 3.766878161430359 and perplexity is 43.244850444859225
At time: 918.0312297344208 and batch: 300, loss is 3.763847031593323 and perplexity is 43.11396814920284
At time: 919.186939239502 and batch: 350, loss is 3.796370463371277 and perplexity is 44.539233987270286
At time: 920.3857388496399 and batch: 400, loss is 3.7859935426712035 and perplexity is 44.07944361810546
At time: 921.5407118797302 and batch: 450, loss is 3.815163803100586 and perplexity is 45.38418984513278
At time: 922.6960470676422 and batch: 500, loss is 3.828432083129883 and perplexity is 45.99037259308383
At time: 923.850821018219 and batch: 550, loss is 3.803545689582825 and perplexity is 44.859962339631416
At time: 925.0098354816437 and batch: 600, loss is 3.7603318214416506 and perplexity is 42.96267955207776
At time: 926.1645841598511 and batch: 650, loss is 3.758302493095398 and perplexity is 42.87558257270635
At time: 927.3242342472076 and batch: 700, loss is 3.8030661296844483 and perplexity is 44.838454458221555
At time: 928.4783980846405 and batch: 750, loss is 3.7632155513763426 and perplexity is 43.08675112565151
At time: 929.6363615989685 and batch: 800, loss is 3.7223699378967283 and perplexity is 41.362304134507916
At time: 930.7943739891052 and batch: 850, loss is 3.7198089170455932 and perplexity is 41.256509939561866
At time: 931.9484670162201 and batch: 900, loss is 3.6816348171234132 and perplexity is 39.711261685378865
At time: 933.105034828186 and batch: 950, loss is 3.787355046272278 and perplexity is 44.13949881272975
At time: 934.2605850696564 and batch: 1000, loss is 3.757525210380554 and perplexity is 42.842269072165045
At time: 935.4133670330048 and batch: 1050, loss is 3.6991453409194945 and perplexity is 40.412750472114446
At time: 936.5688872337341 and batch: 1100, loss is 3.7321702003479005 and perplexity is 41.7696583996042
At time: 937.7243962287903 and batch: 1150, loss is 3.7050452756881715 and perplexity is 40.6518878174099
At time: 938.8839926719666 and batch: 1200, loss is 3.750599422454834 and perplexity is 42.54657773201117
At time: 940.0389184951782 and batch: 1250, loss is 3.7313201904296873 and perplexity is 41.734168861050854
At time: 941.1933915615082 and batch: 1300, loss is 3.734255142211914 and perplexity is 41.85683655816312
At time: 942.3534412384033 and batch: 1350, loss is 3.6001385831832886 and perplexity is 36.603306694966186
At time: 943.5085771083832 and batch: 1400, loss is 3.628608169555664 and perplexity is 37.660363282414096
At time: 944.6628201007843 and batch: 1450, loss is 3.551544589996338 and perplexity is 34.86713133900207
At time: 945.8212332725525 and batch: 1500, loss is 3.5348650598526 and perplexity is 34.29038725211046
At time: 946.9774179458618 and batch: 1550, loss is 3.557679433822632 and perplexity is 35.08169322332073
At time: 948.1358153820038 and batch: 1600, loss is 3.6547636795043945 and perplexity is 38.658384267062374
At time: 949.2941410541534 and batch: 1650, loss is 3.5891041994094848 and perplexity is 36.20163195369932
At time: 950.4530079364777 and batch: 1700, loss is 3.603136868476868 and perplexity is 36.713218542324164
At time: 951.6137075424194 and batch: 1750, loss is 3.5921594429016115 and perplexity is 36.312405888633755
At time: 952.767963886261 and batch: 1800, loss is 3.5340087747573854 and perplexity is 34.26103747228018
At time: 953.9248774051666 and batch: 1850, loss is 3.574879970550537 and perplexity is 35.69033666708772
At time: 955.080197095871 and batch: 1900, loss is 3.656596655845642 and perplexity is 38.72930915277572
At time: 956.2353458404541 and batch: 1950, loss is 3.595058255195618 and perplexity is 36.417821453398
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367467410065407 and perplexity of 78.8436998730579
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fad68d45b38>
ELAPSED
5898.538932561874


RESULTS SO FAR:
[{'best_accuracy': -79.15217303895258, 'params': {'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.54003238615967, 'params': {'num_layers': 2, 'dropout': 0.532313874403636, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.08424698132469677, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.66990658508242, 'params': {'num_layers': 2, 'dropout': 0.5310812723449767, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.5433392138601495, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.88059106127103, 'params': {'num_layers': 2, 'dropout': 0.10281409912265316, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.34256577207194716, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -78.88025896930846, 'params': {'num_layers': 2, 'dropout': 0.22078712054788474, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.31840880658536375, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -78.84300601860508, 'params': {'num_layers': 2, 'dropout': 0.22685778667030246, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.31510939884661804, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -79.15217303895258, 'params': {'num_layers': 2, 'dropout': 0.5177398169450361, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.9841399650223751, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.54003238615967, 'params': {'num_layers': 2, 'dropout': 0.532313874403636, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.08424698132469677, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.66990658508242, 'params': {'num_layers': 2, 'dropout': 0.5310812723449767, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.5433392138601495, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -79.88059106127103, 'params': {'num_layers': 2, 'dropout': 0.10281409912265316, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.34256577207194716, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -78.88025896930846, 'params': {'num_layers': 2, 'dropout': 0.22078712054788474, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.31840880658536375, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}, {'best_accuracy': -78.84300601860508, 'params': {'num_layers': 2, 'dropout': 0.22685778667030246, 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'wordvec_source': 'None', 'rnn_dropout': 0.31510939884661804, 'batch_size': 32, 'data': 'wikitext', 'tie_weights': 'FALSE', 'seq_len': 35}}]
