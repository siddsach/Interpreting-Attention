FALSE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8876922130584717 and batch: 50, loss is 7.145753002166748 and perplexity is 1268.7063042115844
At time: 2.9173340797424316 and batch: 100, loss is 6.271410055160523 and perplexity is 529.2230857526473
At time: 3.95046067237854 and batch: 150, loss is 5.977654685974121 and perplexity is 394.5140230232194
At time: 4.982640981674194 and batch: 200, loss is 5.833333072662353 and perplexity is 341.4950119684187
At time: 6.01725435256958 and batch: 250, loss is 5.742271995544433 and perplexity is 311.7719513971523
At time: 7.052111387252808 and batch: 300, loss is 5.65955846786499 and perplexity is 287.02188518862613
At time: 8.086307764053345 and batch: 350, loss is 5.5959227085113525 and perplexity is 269.3260449106045
At time: 9.120075464248657 and batch: 400, loss is 5.5276258754730225 and perplexity is 251.54600001845694
At time: 10.154843091964722 and batch: 450, loss is 5.453023862838745 and perplexity is 233.46305989021005
At time: 11.189667463302612 and batch: 500, loss is 5.427366914749146 and perplexity is 227.54929921227105
At time: 12.225804090499878 and batch: 550, loss is 5.360936336517334 and perplexity is 212.92422186492038
At time: 13.26323652267456 and batch: 600, loss is 5.36947262763977 and perplexity is 214.74958484041966
At time: 14.299226999282837 and batch: 650, loss is 5.43339958190918 and perplexity is 228.92617734493183
At time: 15.333416223526001 and batch: 700, loss is 5.37095272064209 and perplexity is 215.06766953759185
At time: 16.36689305305481 and batch: 750, loss is 5.316465530395508 and perplexity is 203.662768501981
At time: 17.400570392608643 and batch: 800, loss is 5.288253726959229 and perplexity is 197.99736587793123
At time: 18.436421871185303 and batch: 850, loss is 5.286112213134766 and perplexity is 197.57380547380038
At time: 19.4725923538208 and batch: 900, loss is 5.3057568073272705 and perplexity is 201.49343643391893
At time: 20.509050369262695 and batch: 950, loss is 5.34587140083313 and perplexity is 209.7405730999949
At time: 21.54901361465454 and batch: 1000, loss is 5.306890439987183 and perplexity is 201.72198549508232
At time: 22.587244033813477 and batch: 1050, loss is 5.206566114425659 and perplexity is 182.4664123972064
At time: 23.624986171722412 and batch: 1100, loss is 5.294850339889527 and perplexity is 199.30779530773262
At time: 24.66450309753418 and batch: 1150, loss is 5.189023580551147 and perplexity is 179.2934018706593
At time: 25.709977626800537 and batch: 1200, loss is 5.265608167648315 and perplexity is 193.56399235615453
At time: 26.75042152404785 and batch: 1250, loss is 5.200178308486938 and perplexity is 181.3045671361724
At time: 27.79026198387146 and batch: 1300, loss is 5.22823899269104 and perplexity is 186.46414949391277
At time: 28.831543922424316 and batch: 1350, loss is 5.161834030151367 and perplexity is 174.48417156272197
At time: 29.872836112976074 and batch: 1400, loss is 5.170117444992066 and perplexity is 175.93549901403074
At time: 30.9147789478302 and batch: 1450, loss is 5.111690225601197 and perplexity is 165.95061193100184
At time: 31.955999612808228 and batch: 1500, loss is 5.083812189102173 and perplexity is 161.38812676592767
At time: 32.998053789138794 and batch: 1550, loss is 5.074847269058227 and perplexity is 159.94776114156798
At time: 34.041210412979126 and batch: 1600, loss is 5.135411128997803 and perplexity is 169.93417038007587
At time: 35.08216738700867 and batch: 1650, loss is 5.100580778121948 and perplexity is 164.11719530309708
At time: 36.127795457839966 and batch: 1700, loss is 5.121374044418335 and perplexity is 167.56545388852382
At time: 37.168280601501465 and batch: 1750, loss is 5.140778503417969 and perplexity is 170.84872287653505
At time: 38.20969271659851 and batch: 1800, loss is 5.096924791336059 and perplexity is 163.51828048516504
At time: 39.25032901763916 and batch: 1850, loss is 5.084823160171509 and perplexity is 161.55136799519886
At time: 40.29124927520752 and batch: 1900, loss is 5.140936813354492 and perplexity is 170.87577206803016
At time: 41.33404850959778 and batch: 1950, loss is 5.0588937187194825 and perplexity is 157.41627328384848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.8373058230377906 and perplexity of 126.12907949888576
finished 1 epochs...
Completing Train Step...
At time: 44.643593072891235 and batch: 50, loss is 5.02515721321106 and perplexity is 152.1941811678789
At time: 45.67674541473389 and batch: 100, loss is 4.966993532180786 and perplexity is 143.5945254357307
At time: 46.71044421195984 and batch: 150, loss is 4.909216766357422 and perplexity is 135.5332186493154
At time: 47.74621391296387 and batch: 200, loss is 4.888908891677857 and perplexity is 132.8085864131702
At time: 48.7815465927124 and batch: 250, loss is 4.890433769226075 and perplexity is 133.01125773000075
At time: 49.817129373550415 and batch: 300, loss is 4.906531496047974 and perplexity is 135.16976352735276
At time: 50.85133647918701 and batch: 350, loss is 4.90925030708313 and perplexity is 135.53776460806336
At time: 51.93020415306091 and batch: 400, loss is 4.868720331192017 and perplexity is 130.15425594223396
At time: 52.963258028030396 and batch: 450, loss is 4.857413177490234 and perplexity is 128.69087071751161
At time: 53.99615144729614 and batch: 500, loss is 4.857937679290772 and perplexity is 128.75838701557782
At time: 55.03874611854553 and batch: 550, loss is 4.813977270126343 and perplexity is 123.22072632734942
At time: 56.07656002044678 and batch: 600, loss is 4.793345060348511 and perplexity is 120.70445780429235
At time: 57.11218333244324 and batch: 650, loss is 4.855234889984131 and perplexity is 128.41085009511306
At time: 58.14484477043152 and batch: 700, loss is 4.85334153175354 and perplexity is 128.16795237394984
At time: 59.177000284194946 and batch: 750, loss is 4.816745347976685 and perplexity is 123.56228340079258
At time: 60.21104121208191 and batch: 800, loss is 4.791358184814453 and perplexity is 120.46487116346432
At time: 61.24796962738037 and batch: 850, loss is 4.791808824539185 and perplexity is 120.51916965345465
At time: 62.29018259048462 and batch: 900, loss is 4.8033140182495115 and perplexity is 121.91377325487127
At time: 63.32256507873535 and batch: 950, loss is 4.864737892150879 and perplexity is 129.63695529483763
At time: 64.35668206214905 and batch: 1000, loss is 4.837163133621216 and perplexity is 126.11108349806891
At time: 65.39031887054443 and batch: 1050, loss is 4.762956809997559 and perplexity is 117.09163226200955
At time: 66.42372107505798 and batch: 1100, loss is 4.840030755996704 and perplexity is 126.47324148089602
At time: 67.46174025535583 and batch: 1150, loss is 4.761843090057373 and perplexity is 116.96129756797623
At time: 68.5052387714386 and batch: 1200, loss is 4.833305082321167 and perplexity is 125.62547781657942
At time: 69.54260778427124 and batch: 1250, loss is 4.79724440574646 and perplexity is 121.17604501952617
At time: 70.57786059379578 and batch: 1300, loss is 4.81985933303833 and perplexity is 123.94765421355396
At time: 71.61374998092651 and batch: 1350, loss is 4.718345890045166 and perplexity is 111.98286741052387
At time: 72.64656281471252 and batch: 1400, loss is 4.727494955062866 and perplexity is 113.01210705615073
At time: 73.68129587173462 and batch: 1450, loss is 4.670306386947632 and perplexity is 106.730438236602
At time: 74.71882128715515 and batch: 1500, loss is 4.6529004001617436 and perplexity is 104.88876421304347
At time: 75.7573344707489 and batch: 1550, loss is 4.66067437171936 and perplexity is 105.70734416885213
At time: 76.79634666442871 and batch: 1600, loss is 4.748863935470581 and perplexity is 115.45304788214172
At time: 77.83513689041138 and batch: 1650, loss is 4.701094293594361 and perplexity is 110.0675527923608
At time: 78.87340950965881 and batch: 1700, loss is 4.724873704910278 and perplexity is 112.71626196467587
At time: 79.90929532051086 and batch: 1750, loss is 4.740137329101563 and perplexity is 114.4499179053863
At time: 80.94536900520325 and batch: 1800, loss is 4.700045461654663 and perplexity is 109.95217094612775
At time: 81.9856927394867 and batch: 1850, loss is 4.716224699020386 and perplexity is 111.74558210993965
At time: 83.02092909812927 and batch: 1900, loss is 4.788853883743286 and perplexity is 120.16356829159302
At time: 84.05644702911377 and batch: 1950, loss is 4.713443861007691 and perplexity is 111.43526741488101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.691390636355378 and perplexity of 109.00466029938238
finished 2 epochs...
Completing Train Step...
At time: 87.31605648994446 and batch: 50, loss is 4.683918237686157 and perplexity is 108.19316968741931
At time: 88.38098859786987 and batch: 100, loss is 4.641272640228271 and perplexity is 103.67620617190111
At time: 89.41940069198608 and batch: 150, loss is 4.591682815551758 and perplexity is 98.66031766066813
At time: 90.4584469795227 and batch: 200, loss is 4.583127365112305 and perplexity is 97.81983468444669
At time: 91.49672389030457 and batch: 250, loss is 4.58387806892395 and perplexity is 97.89329597758525
At time: 92.53729772567749 and batch: 300, loss is 4.612471437454223 and perplexity is 100.73279705907157
At time: 93.574392080307 and batch: 350, loss is 4.618649501800537 and perplexity is 101.35705713495861
At time: 94.61123371124268 and batch: 400, loss is 4.577355499267578 and perplexity is 97.25685799758652
At time: 95.64856100082397 and batch: 450, loss is 4.586224260330201 and perplexity is 98.12324203058374
At time: 96.68788123130798 and batch: 500, loss is 4.597084035873413 and perplexity is 99.19464548550796
At time: 97.72596764564514 and batch: 550, loss is 4.5525851154327395 and perplexity is 94.87736049250927
At time: 98.7645354270935 and batch: 600, loss is 4.531091060638428 and perplexity is 92.8598215275836
At time: 99.80304384231567 and batch: 650, loss is 4.5869214153289795 and perplexity is 98.19167298998286
At time: 100.83962368965149 and batch: 700, loss is 4.6035838794708255 and perplexity is 99.84149510018926
At time: 101.87725162506104 and batch: 750, loss is 4.575425157546997 and perplexity is 97.06930011062838
At time: 102.91563367843628 and batch: 800, loss is 4.541184883117676 and perplexity is 93.80187856130665
At time: 103.97962737083435 and batch: 850, loss is 4.542019958496094 and perplexity is 93.88024291606017
At time: 105.01953291893005 and batch: 900, loss is 4.548971672058105 and perplexity is 94.53514518301414
At time: 106.05786633491516 and batch: 950, loss is 4.6222968101501465 and perplexity is 101.72741256540031
At time: 107.09533977508545 and batch: 1000, loss is 4.594101505279541 and perplexity is 98.89923517472884
At time: 108.13602924346924 and batch: 1050, loss is 4.527939519882202 and perplexity is 92.56763068294302
At time: 109.17477250099182 and batch: 1100, loss is 4.601865129470825 and perplexity is 99.67003991699185
At time: 110.2150342464447 and batch: 1150, loss is 4.525435943603515 and perplexity is 92.33617041870181
At time: 111.25691819190979 and batch: 1200, loss is 4.596392755508423 and perplexity is 99.12609787031158
At time: 112.29701209068298 and batch: 1250, loss is 4.573384714126587 and perplexity is 96.87143762814267
At time: 113.33902025222778 and batch: 1300, loss is 4.589504203796387 and perplexity is 98.44560910104337
At time: 114.3797926902771 and batch: 1350, loss is 4.482589960098267 and perplexity is 88.46349314720193
At time: 115.42023825645447 and batch: 1400, loss is 4.4969147777557374 and perplexity is 89.73983642278604
At time: 116.46197438240051 and batch: 1450, loss is 4.428682336807251 and perplexity is 83.82089640188465
At time: 117.50437688827515 and batch: 1500, loss is 4.424740648269653 and perplexity is 83.49115083941358
At time: 118.545907497406 and batch: 1550, loss is 4.432156171798706 and perplexity is 84.11258270653879
At time: 119.58717823028564 and batch: 1600, loss is 4.530802755355835 and perplexity is 92.83305340937697
At time: 120.63315606117249 and batch: 1650, loss is 4.475555849075318 and perplexity is 87.84341452259335
At time: 121.6778883934021 and batch: 1700, loss is 4.505951471328736 and perplexity is 90.55446304777203
At time: 122.72069144248962 and batch: 1750, loss is 4.520688190460205 and perplexity is 91.89882011253222
At time: 123.76184582710266 and batch: 1800, loss is 4.478195877075195 and perplexity is 88.07562998933135
At time: 124.80338215827942 and batch: 1850, loss is 4.502861080169677 and perplexity is 90.2750463116426
At time: 125.8448531627655 and batch: 1900, loss is 4.581027221679688 and perplexity is 97.61461457231849
At time: 126.8862419128418 and batch: 1950, loss is 4.509713172912598 and perplexity is 90.8957434098462
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.633386514353198 and perplexity of 102.86181796436648
finished 3 epochs...
Completing Train Step...
At time: 130.18448638916016 and batch: 50, loss is 4.477012643814087 and perplexity is 87.97147760486912
At time: 131.2198646068573 and batch: 100, loss is 4.438196249008179 and perplexity is 84.62216661420628
At time: 132.25659942626953 and batch: 150, loss is 4.394413137435913 and perplexity is 80.99708265637909
At time: 133.29451179504395 and batch: 200, loss is 4.38686282157898 and perplexity is 80.3878320105462
At time: 134.33358192443848 and batch: 250, loss is 4.387497987747192 and perplexity is 80.43890786088417
At time: 135.3690288066864 and batch: 300, loss is 4.417406787872315 and perplexity is 82.8810782228649
At time: 136.40464687347412 and batch: 350, loss is 4.42081841468811 and perplexity is 83.16432041545595
At time: 137.441743850708 and batch: 400, loss is 4.3757789611816404 and perplexity is 79.50174421108117
At time: 138.47864389419556 and batch: 450, loss is 4.402969207763672 and perplexity is 81.6930726155481
At time: 139.51621198654175 and batch: 500, loss is 4.4221711921691895 and perplexity is 83.27689936530899
At time: 140.55636310577393 and batch: 550, loss is 4.377444801330566 and perplexity is 79.63429177937617
At time: 141.6010458469391 and batch: 600, loss is 4.36041519165039 and perplexity is 78.2896328779569
At time: 142.63730597496033 and batch: 650, loss is 4.409033374786377 and perplexity is 82.18997818891124
At time: 143.6755907535553 and batch: 700, loss is 4.431652021408081 and perplexity is 84.07018800266204
At time: 144.71802520751953 and batch: 750, loss is 4.398555850982666 and perplexity is 81.3333263677496
At time: 145.75778579711914 and batch: 800, loss is 4.364398756027222 and perplexity is 78.60212667690617
At time: 146.8007824420929 and batch: 850, loss is 4.37089690208435 and perplexity is 79.1145578997642
At time: 147.8406322002411 and batch: 900, loss is 4.373182163238526 and perplexity is 79.29556206778595
At time: 148.88798546791077 and batch: 950, loss is 4.452462816238404 and perplexity is 85.8380873272153
At time: 149.93059301376343 and batch: 1000, loss is 4.423936624526977 and perplexity is 83.42404895120586
At time: 150.96699810028076 and batch: 1050, loss is 4.36735954284668 and perplexity is 78.83519568110847
At time: 152.00971221923828 and batch: 1100, loss is 4.434641380310058 and perplexity is 84.32187997895142
At time: 153.04872822761536 and batch: 1150, loss is 4.363698616027832 and perplexity is 78.547113444712
At time: 154.08643412590027 and batch: 1200, loss is 4.43259822845459 and perplexity is 84.14977345317071
At time: 155.12503051757812 and batch: 1250, loss is 4.413232116699219 and perplexity is 82.53579819156757
At time: 156.1626148223877 and batch: 1300, loss is 4.427558450698853 and perplexity is 83.72674417892331
At time: 157.2013885974884 and batch: 1350, loss is 4.315545578002929 and perplexity is 74.85445124757646
At time: 158.24213528633118 and batch: 1400, loss is 4.335841875076294 and perplexity is 76.38924202574445
At time: 159.2787570953369 and batch: 1450, loss is 4.263883662223816 and perplexity is 71.08552021161205
At time: 160.3157660961151 and batch: 1500, loss is 4.261242289543151 and perplexity is 70.89800461883857
At time: 161.3565309047699 and batch: 1550, loss is 4.2739995670318605 and perplexity is 71.80826400774481
At time: 162.39794826507568 and batch: 1600, loss is 4.371178140640259 and perplexity is 79.13681109286054
At time: 163.43863892555237 and batch: 1650, loss is 4.3216023254394536 and perplexity is 75.30920151686864
At time: 164.47564697265625 and batch: 1700, loss is 4.35338828086853 and perplexity is 77.74142696534803
At time: 165.51401114463806 and batch: 1750, loss is 4.363691873550415 and perplexity is 78.54658384435888
At time: 166.5524764060974 and batch: 1800, loss is 4.320569086074829 and perplexity is 75.23142927093498
At time: 167.5912947654724 and batch: 1850, loss is 4.34850700378418 and perplexity is 77.36287418155533
At time: 168.6307327747345 and batch: 1900, loss is 4.430485668182373 and perplexity is 83.97218962916837
At time: 169.66838669776917 and batch: 1950, loss is 4.357796869277954 and perplexity is 78.08491350827195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6146671738735465 and perplexity of 100.95422273744504
finished 4 epochs...
Completing Train Step...
At time: 172.94030714035034 and batch: 50, loss is 4.322980027198792 and perplexity is 75.41302663989792
At time: 174.0128538608551 and batch: 100, loss is 4.285907678604126 and perplexity is 72.6684764149773
At time: 175.05332899093628 and batch: 150, loss is 4.24638708114624 and perplexity is 69.85258417951351
At time: 176.09304356575012 and batch: 200, loss is 4.242328381538391 and perplexity is 69.56964808819968
At time: 177.1339807510376 and batch: 250, loss is 4.239199137687683 and perplexity is 69.35228795851724
At time: 178.1768822669983 and batch: 300, loss is 4.273049411773681 and perplexity is 71.74006741192481
At time: 179.21961164474487 and batch: 350, loss is 4.275742073059082 and perplexity is 71.9334994206255
At time: 180.25898718833923 and batch: 400, loss is 4.226690969467163 and perplexity is 68.49022055578097
At time: 181.30320692062378 and batch: 450, loss is 4.264097604751587 and perplexity is 71.10073005445213
At time: 182.37121152877808 and batch: 500, loss is 4.284353051185608 and perplexity is 72.55559177859169
At time: 183.41303896903992 and batch: 550, loss is 4.246378536224365 and perplexity is 69.8519872971891
At time: 184.4569034576416 and batch: 600, loss is 4.227653460502625 and perplexity is 68.5561735135565
At time: 185.4942183494568 and batch: 650, loss is 4.270815134048462 and perplexity is 71.57995910711516
At time: 186.5337085723877 and batch: 700, loss is 4.298274440765381 and perplexity is 73.57272999948674
At time: 187.57289719581604 and batch: 750, loss is 4.266236214637757 and perplexity is 71.25294948963838
At time: 188.6143033504486 and batch: 800, loss is 4.230355501174927 and perplexity is 68.74166557341577
At time: 189.65858793258667 and batch: 850, loss is 4.2420784282684325 and perplexity is 69.55226110022797
At time: 190.69942378997803 and batch: 900, loss is 4.248000750541687 and perplexity is 69.96539415131726
At time: 191.74375700950623 and batch: 950, loss is 4.320266742706298 and perplexity is 75.2086869853527
At time: 192.78241300582886 and batch: 1000, loss is 4.293279447555542 and perplexity is 73.20615100468217
At time: 193.82458066940308 and batch: 1050, loss is 4.238661689758301 and perplexity is 69.31502472937565
At time: 194.86664819717407 and batch: 1100, loss is 4.302976841926575 and perplexity is 73.91951320832823
At time: 195.90698170661926 and batch: 1150, loss is 4.2359414434432985 and perplexity is 69.12672701297869
At time: 196.9473695755005 and batch: 1200, loss is 4.299860796928406 and perplexity is 73.68953517596252
At time: 197.98675227165222 and batch: 1250, loss is 4.288410482406616 and perplexity is 72.85057914271155
At time: 199.03069853782654 and batch: 1300, loss is 4.2962503910064695 and perplexity is 73.42396573699149
At time: 200.0731921195984 and batch: 1350, loss is 4.185445303916931 and perplexity is 65.72276100434514
At time: 201.11879205703735 and batch: 1400, loss is 4.208307542800903 and perplexity is 67.2426381634281
At time: 202.1662769317627 and batch: 1450, loss is 4.137899346351624 and perplexity is 62.67103294266205
At time: 203.2065715789795 and batch: 1500, loss is 4.1330741596221925 and perplexity is 62.36936190104331
At time: 204.2489025592804 and batch: 1550, loss is 4.151722822189331 and perplexity is 63.54337999522528
At time: 205.287903547287 and batch: 1600, loss is 4.2491930103302 and perplexity is 70.04886082444314
At time: 206.32628536224365 and batch: 1650, loss is 4.197383289337158 and perplexity is 66.51206031489656
At time: 207.36163711547852 and batch: 1700, loss is 4.2296703958511355 and perplexity is 68.69458642129548
At time: 208.40226554870605 and batch: 1750, loss is 4.235536198616028 and perplexity is 69.09871943977593
At time: 209.44904232025146 and batch: 1800, loss is 4.193673205375672 and perplexity is 66.26575218113537
At time: 210.49144792556763 and batch: 1850, loss is 4.226142268180848 and perplexity is 68.45265019205806
At time: 211.5330502986908 and batch: 1900, loss is 4.304850959777832 and perplexity is 74.05817698313012
At time: 212.57783842086792 and batch: 1950, loss is 4.236831202507019 and perplexity is 69.1882605158202
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.610477039425872 and perplexity of 100.53209597267823
finished 5 epochs...
Completing Train Step...
At time: 215.84019112586975 and batch: 50, loss is 4.202161960601806 and perplexity is 66.83066022209924
At time: 216.91709852218628 and batch: 100, loss is 4.164955124855042 and perplexity is 64.38979287733883
At time: 217.96188640594482 and batch: 150, loss is 4.130163402557373 and perplexity is 62.18808379651326
At time: 219.00704145431519 and batch: 200, loss is 4.125467019081116 and perplexity is 61.896709445740704
At time: 220.05314946174622 and batch: 250, loss is 4.121567597389221 and perplexity is 61.65581804808104
At time: 221.1002480983734 and batch: 300, loss is 4.149274878501892 and perplexity is 63.388019613602296
At time: 222.1467206478119 and batch: 350, loss is 4.150667476654053 and perplexity is 63.47635514625913
At time: 223.19438576698303 and batch: 400, loss is 4.107762489318848 and perplexity is 60.81050108782562
At time: 224.24209809303284 and batch: 450, loss is 4.147865715026856 and perplexity is 63.298758438172825
At time: 225.28742003440857 and batch: 500, loss is 4.176903166770935 and perplexity is 65.16373918597873
At time: 226.3329849243164 and batch: 550, loss is 4.134262819290161 and perplexity is 62.443541924719
At time: 227.37555480003357 and batch: 600, loss is 4.122229585647583 and perplexity is 61.69664698833702
At time: 228.42068672180176 and batch: 650, loss is 4.164197025299072 and perplexity is 64.34099750216261
At time: 229.46505188941956 and batch: 700, loss is 4.1899363231658935 and perplexity is 66.01858697195244
At time: 230.51045870780945 and batch: 750, loss is 4.156615309715271 and perplexity is 63.85502693194036
At time: 231.55393505096436 and batch: 800, loss is 4.116887364387512 and perplexity is 61.367928673887825
At time: 232.59997177124023 and batch: 850, loss is 4.131240172386169 and perplexity is 62.25508211326571
At time: 233.6501648426056 and batch: 900, loss is 4.13176176071167 and perplexity is 62.2875621071555
At time: 234.7572557926178 and batch: 950, loss is 4.208053545951843 and perplexity is 67.22556091408768
At time: 235.8036756515503 and batch: 1000, loss is 4.184080061912536 and perplexity is 65.63309475237128
At time: 236.85098600387573 and batch: 1050, loss is 4.1311654424667354 and perplexity is 62.250429969824346
At time: 237.89745116233826 and batch: 1100, loss is 4.190190725326538 and perplexity is 66.0353843796786
At time: 238.9424741268158 and batch: 1150, loss is 4.1306771516799925 and perplexity is 62.22004107831096
At time: 239.99306535720825 and batch: 1200, loss is 4.195381808280945 and perplexity is 66.37907081854088
At time: 241.04377055168152 and batch: 1250, loss is 4.179233860969544 and perplexity is 65.31579306157056
At time: 242.0921995639801 and batch: 1300, loss is 4.189771237373352 and perplexity is 66.00768914076303
At time: 243.13858342170715 and batch: 1350, loss is 4.077681398391723 and perplexity is 59.00849392602893
At time: 244.18460702896118 and batch: 1400, loss is 4.10271053314209 and perplexity is 60.50406380684785
At time: 245.23638343811035 and batch: 1450, loss is 4.031938724517822 and perplexity is 56.37009145613414
At time: 246.28162360191345 and batch: 1500, loss is 4.028254408836364 and perplexity is 56.16278836373162
At time: 247.327210187912 and batch: 1550, loss is 4.043730478286744 and perplexity is 57.03872814656714
At time: 248.37004566192627 and batch: 1600, loss is 4.146333074569702 and perplexity is 63.201818506109646
At time: 249.41628909111023 and batch: 1650, loss is 4.094198951721191 and perplexity is 59.9912640059871
At time: 250.46163272857666 and batch: 1700, loss is 4.124915218353271 and perplexity is 61.86256421796452
At time: 251.50653910636902 and batch: 1750, loss is 4.130797171592713 and perplexity is 62.22750917036155
At time: 252.55248975753784 and batch: 1800, loss is 4.085676183700562 and perplexity is 59.48214501289658
At time: 253.59767532348633 and batch: 1850, loss is 4.1204262495040895 and perplexity is 61.58548745401801
At time: 254.63800525665283 and batch: 1900, loss is 4.197034759521484 and perplexity is 66.48888291801647
At time: 255.68061780929565 and batch: 1950, loss is 4.1312004089355465 and perplexity is 62.252606685598174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.613745684956395 and perplexity of 100.86123738911665
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 258.9528374671936 and batch: 50, loss is 4.127649149894714 and perplexity is 62.03192363655466
At time: 259.9941523075104 and batch: 100, loss is 4.111413731575012 and perplexity is 61.03294080253641
At time: 261.06733775138855 and batch: 150, loss is 4.085516881942749 and perplexity is 59.47267015733818
At time: 262.10675072669983 and batch: 200, loss is 4.075349922180176 and perplexity is 58.87107728022877
At time: 263.1472189426422 and batch: 250, loss is 4.069051032066345 and perplexity is 58.50142027020973
At time: 264.1876003742218 and batch: 300, loss is 4.084363222122192 and perplexity is 59.40409848915098
At time: 265.22887778282166 and batch: 350, loss is 4.093612656593323 and perplexity is 59.95610172892883
At time: 266.269770860672 and batch: 400, loss is 4.038240475654602 and perplexity is 56.726443385347196
At time: 267.31028056144714 and batch: 450, loss is 4.074274110794067 and perplexity is 58.807777160578084
At time: 268.351585149765 and batch: 500, loss is 4.1001027393341065 and perplexity is 60.34648723679748
At time: 269.3948426246643 and batch: 550, loss is 4.060315542221069 and perplexity is 57.99260730830671
At time: 270.4361062049866 and batch: 600, loss is 4.038131408691406 and perplexity is 56.72025674181959
At time: 271.47738337516785 and batch: 650, loss is 4.054356498718262 and perplexity is 57.64805446081332
At time: 272.519095659256 and batch: 700, loss is 4.0802832174301145 and perplexity is 59.162223250171564
At time: 273.56190061569214 and batch: 750, loss is 4.037808527946472 and perplexity is 56.70194581935119
At time: 274.6042511463165 and batch: 800, loss is 3.9957205772399904 and perplexity is 54.36500069534345
At time: 275.64625811576843 and batch: 850, loss is 4.0003114557266235 and perplexity is 54.615157588047815
At time: 276.6873035430908 and batch: 900, loss is 3.9904926681518553 and perplexity is 54.08152704699836
At time: 277.72844338417053 and batch: 950, loss is 4.070829744338989 and perplexity is 58.605570063209726
At time: 278.7687768936157 and batch: 1000, loss is 4.031296634674073 and perplexity is 56.33390841054511
At time: 279.81038212776184 and batch: 1050, loss is 3.9761407709121706 and perplexity is 53.31089775209066
At time: 280.85224962234497 and batch: 1100, loss is 4.018904829025269 and perplexity is 55.64013698418091
At time: 281.8952498435974 and batch: 1150, loss is 3.9628365325927732 and perplexity is 52.60633409720883
At time: 282.9354338645935 and batch: 1200, loss is 4.004681944847107 and perplexity is 54.85437490766874
At time: 283.98156666755676 and batch: 1250, loss is 3.9899316310882567 and perplexity is 54.051193815698134
At time: 285.02404713630676 and batch: 1300, loss is 3.9890763664245608 and perplexity is 54.00498550258237
At time: 286.0735876560211 and batch: 1350, loss is 3.8762673330307007 and perplexity is 48.24380052641375
At time: 287.1200387477875 and batch: 1400, loss is 3.8827987051010133 and perplexity is 48.55992999351532
At time: 288.1611182689667 and batch: 1450, loss is 3.8076973581314086 and perplexity is 45.04659318099517
At time: 289.20301818847656 and batch: 1500, loss is 3.8028032636642455 and perplexity is 44.82666950114632
At time: 290.24236941337585 and batch: 1550, loss is 3.8074050664901735 and perplexity is 45.03342836241919
At time: 291.2819046974182 and batch: 1600, loss is 3.900056014060974 and perplexity is 49.40521641483002
At time: 292.3214395046234 and batch: 1650, loss is 3.8378325128555297 and perplexity is 46.424740281484574
At time: 293.36396050453186 and batch: 1700, loss is 3.859789695739746 and perplexity is 47.455370252818604
At time: 294.4067852497101 and batch: 1750, loss is 3.8511182117462157 and perplexity is 47.04564081783418
At time: 295.44787979125977 and batch: 1800, loss is 3.803745460510254 and perplexity is 44.86892495111724
At time: 296.4938201904297 and batch: 1850, loss is 3.8209556102752686 and perplexity is 45.64780900022626
At time: 297.5345788002014 and batch: 1900, loss is 3.8878652811050416 and perplexity is 48.8065868949027
At time: 298.57827973365784 and batch: 1950, loss is 3.825101180076599 and perplexity is 45.83743796719773
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.524662177507268 and perplexity of 92.2647514549242
finished 7 epochs...
Completing Train Step...
At time: 301.8679189682007 and batch: 50, loss is 4.017688550949097 and perplexity is 55.572504243859086
At time: 302.93913197517395 and batch: 100, loss is 3.9901671409606934 and perplexity is 54.063924904548436
At time: 303.97788071632385 and batch: 150, loss is 3.9618068504333497 and perplexity is 52.5521941717574
At time: 305.01851201057434 and batch: 200, loss is 3.9506168127059937 and perplexity is 51.96741111062788
At time: 306.06077241897583 and batch: 250, loss is 3.947427358627319 and perplexity is 51.80192748080542
At time: 307.1018817424774 and batch: 300, loss is 3.965095572471619 and perplexity is 52.72530823688099
At time: 308.1435465812683 and batch: 350, loss is 3.9777820348739623 and perplexity is 53.398466849686535
At time: 309.18492794036865 and batch: 400, loss is 3.924950404167175 and perplexity is 50.65056593954301
At time: 310.2266080379486 and batch: 450, loss is 3.967278800010681 and perplexity is 52.84054533045445
At time: 311.2655780315399 and batch: 500, loss is 3.9933449983596803 and perplexity is 54.236005627506906
At time: 312.31004214286804 and batch: 550, loss is 3.9573188257217407 and perplexity is 52.31686709753103
At time: 313.3767321109772 and batch: 600, loss is 3.9375291299819946 and perplexity is 51.29170945139676
At time: 314.4155604839325 and batch: 650, loss is 3.9590220832824707 and perplexity is 52.40605212794617
At time: 315.4574155807495 and batch: 700, loss is 3.9927070903778077 and perplexity is 54.20141907930267
At time: 316.49797010421753 and batch: 750, loss is 3.950627999305725 and perplexity is 51.967992452506664
At time: 317.53922390937805 and batch: 800, loss is 3.9095893478393555 and perplexity is 49.87846506775002
At time: 318.5777962207794 and batch: 850, loss is 3.9195026397705077 and perplexity is 50.37538383395922
At time: 319.6194200515747 and batch: 900, loss is 3.910363755226135 and perplexity is 49.91710627962856
At time: 320.6610486507416 and batch: 950, loss is 3.9918276023864747 and perplexity is 54.153770538340346
At time: 321.70319867134094 and batch: 1000, loss is 3.9555822134017946 and perplexity is 52.22609182513018
At time: 322.7452244758606 and batch: 1050, loss is 3.90411602973938 and perplexity is 49.606210110753935
At time: 323.7869143486023 and batch: 1100, loss is 3.9518158864974975 and perplexity is 52.0297612450385
At time: 324.8262665271759 and batch: 1150, loss is 3.898966293334961 and perplexity is 49.351407850008556
At time: 325.8657205104828 and batch: 1200, loss is 3.9427648639678954 and perplexity is 51.560963453846085
At time: 326.9066069126129 and batch: 1250, loss is 3.932174549102783 and perplexity is 51.01779784009972
At time: 327.947546005249 and batch: 1300, loss is 3.934104733467102 and perplexity is 51.11636669321978
At time: 328.98813104629517 and batch: 1350, loss is 3.8249628829956053 and perplexity is 45.83109922165173
At time: 330.02855682373047 and batch: 1400, loss is 3.8370214700698853 and perplexity is 46.38710309555104
At time: 331.06842851638794 and batch: 1450, loss is 3.764080047607422 and perplexity is 43.12401556477187
At time: 332.10697722435 and batch: 1500, loss is 3.7627457904815675 and perplexity is 43.06651540823626
At time: 333.1470527648926 and batch: 1550, loss is 3.768612790107727 and perplexity is 43.319929300731964
At time: 334.1882679462433 and batch: 1600, loss is 3.866173338890076 and perplexity is 47.75927738738827
At time: 335.22745633125305 and batch: 1650, loss is 3.807707724571228 and perplexity is 45.04706015621288
At time: 336.268039226532 and batch: 1700, loss is 3.8353582239151 and perplexity is 46.3100140514953
At time: 337.3102021217346 and batch: 1750, loss is 3.83267210483551 and perplexity is 46.18578675852053
At time: 338.3514301776886 and batch: 1800, loss is 3.786481709480286 and perplexity is 44.10096699251371
At time: 339.3905773162842 and batch: 1850, loss is 3.8101558685302734 and perplexity is 45.157476947359434
At time: 340.4301700592041 and batch: 1900, loss is 3.8800814580917358 and perplexity is 48.42815977616057
At time: 341.47221064567566 and batch: 1950, loss is 3.8211644077301026 and perplexity is 45.657341141673065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.524845566860465 and perplexity of 92.28167337961942
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 344.75048089027405 and batch: 50, loss is 3.979839200973511 and perplexity is 53.50842943232668
At time: 345.81852531433105 and batch: 100, loss is 3.9753559160232546 and perplexity is 53.269072848744365
At time: 346.8571434020996 and batch: 150, loss is 3.9565718460083006 and perplexity is 52.27780205135339
At time: 347.89821887016296 and batch: 200, loss is 3.9487122774124144 and perplexity is 51.86853153176407
At time: 348.93703508377075 and batch: 250, loss is 3.9475436353683473 and perplexity is 51.80795119031373
At time: 349.97898864746094 and batch: 300, loss is 3.9608756637573244 and perplexity is 52.503281045908714
At time: 351.02304434776306 and batch: 350, loss is 3.9772620487213133 and perplexity is 53.37070760418912
At time: 352.0620205402374 and batch: 400, loss is 3.922107276916504 and perplexity is 50.50676445508468
At time: 353.10188364982605 and batch: 450, loss is 3.967276344299316 and perplexity is 52.840415569486076
At time: 354.1426923274994 and batch: 500, loss is 3.9929466915130614 and perplexity is 54.214407356787305
At time: 355.1841289997101 and batch: 550, loss is 3.955537347793579 and perplexity is 52.22374872231848
At time: 356.22842669487 and batch: 600, loss is 3.932386403083801 and perplexity is 51.02860730864896
At time: 357.27277970314026 and batch: 650, loss is 3.9440942096710203 and perplexity is 51.629551377492746
At time: 358.31447196006775 and batch: 700, loss is 3.9743007707595823 and perplexity is 53.21289588147024
At time: 359.35504269599915 and batch: 750, loss is 3.9256597089767458 and perplexity is 50.68650537407147
At time: 360.3939266204834 and batch: 800, loss is 3.8807468938827516 and perplexity is 48.46039633145796
At time: 361.4345226287842 and batch: 850, loss is 3.8929816675186157 and perplexity is 49.056940158870795
At time: 362.47646379470825 and batch: 900, loss is 3.8727789878845216 and perplexity is 48.07580268659625
At time: 363.51504254341125 and batch: 950, loss is 3.9625133800506593 and perplexity is 52.58933697309387
At time: 364.5558514595032 and batch: 1000, loss is 3.9227718544006347 and perplexity is 50.54034126949944
At time: 365.6236095428467 and batch: 1050, loss is 3.870530333518982 and perplexity is 47.9678182783152
At time: 366.6647479534149 and batch: 1100, loss is 3.911797466278076 and perplexity is 49.988724314098604
At time: 367.70370507240295 and batch: 1150, loss is 3.8626649284362795 and perplexity is 47.592011829025196
At time: 368.74494981765747 and batch: 1200, loss is 3.8999314641952516 and perplexity is 49.399063384947056
At time: 369.7865619659424 and batch: 1250, loss is 3.8877163887023927 and perplexity is 48.79932050588331
At time: 370.8276219367981 and batch: 1300, loss is 3.8817713975906374 and perplexity is 48.51006962807865
At time: 371.87022733688354 and batch: 1350, loss is 3.769821438789368 and perplexity is 43.37231953048336
At time: 372.9108946323395 and batch: 1400, loss is 3.783423857688904 and perplexity is 43.96631874370693
At time: 373.9511282444 and batch: 1450, loss is 3.7056272888183592 and perplexity is 40.675554636418184
At time: 374.9917423725128 and batch: 1500, loss is 3.703945207595825 and perplexity is 40.607192561148295
At time: 376.0311920642853 and batch: 1550, loss is 3.7087744092941284 and perplexity is 40.8037671515716
At time: 377.07258796691895 and batch: 1600, loss is 3.79620934009552 and perplexity is 44.532058258094565
At time: 378.11941504478455 and batch: 1650, loss is 3.7333039236068726 and perplexity is 41.81704048686321
At time: 379.16323947906494 and batch: 1700, loss is 3.754551901817322 and perplexity is 42.7150749740207
At time: 380.20609736442566 and batch: 1750, loss is 3.748145170211792 and perplexity is 42.44228572996756
At time: 381.24918508529663 and batch: 1800, loss is 3.702127366065979 and perplexity is 40.533442173668085
At time: 382.29050874710083 and batch: 1850, loss is 3.7263510465621947 and perplexity is 41.52730017758832
At time: 383.3305459022522 and batch: 1900, loss is 3.795294280052185 and perplexity is 44.49132738937249
At time: 384.37333130836487 and batch: 1950, loss is 3.7403719139099123 and perplexity is 42.113649904975674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494875885719477 and perplexity of 89.55705298613542
finished 9 epochs...
Completing Train Step...
At time: 387.65615940093994 and batch: 50, loss is 3.960705199241638 and perplexity is 52.494331862314084
At time: 388.7000079154968 and batch: 100, loss is 3.9422849464416503 and perplexity is 51.536224380646736
At time: 389.74627900123596 and batch: 150, loss is 3.9175720262527465 and perplexity is 50.278222257872
At time: 390.7915909290314 and batch: 200, loss is 3.9060680437088013 and perplexity is 49.70313669610741
At time: 391.86252188682556 and batch: 250, loss is 3.9036467933654784 and perplexity is 49.58293853296095
At time: 392.9083378314972 and batch: 300, loss is 3.9137010908126832 and perplexity is 50.083974707885986
At time: 393.95338129997253 and batch: 350, loss is 3.9308090257644652 and perplexity is 50.94817939010646
At time: 394.9983069896698 and batch: 400, loss is 3.877582144737244 and perplexity is 48.3072737586444
At time: 396.0416057109833 and batch: 450, loss is 3.9235903310775755 and perplexity is 50.58172429328283
At time: 397.0856730937958 and batch: 500, loss is 3.9494656229019167 and perplexity is 51.90762117819634
At time: 398.13163208961487 and batch: 550, loss is 3.9137174224853517 and perplexity is 50.08479266964618
At time: 399.1763541698456 and batch: 600, loss is 3.8922927236557006 and perplexity is 49.02315432062425
At time: 400.22047686576843 and batch: 650, loss is 3.905253129005432 and perplexity is 49.66264937830606
At time: 401.26951837539673 and batch: 700, loss is 3.93929584980011 and perplexity is 51.382407626529954
At time: 402.3165102005005 and batch: 750, loss is 3.8925451755523683 and perplexity is 49.035531871215454
At time: 403.3611481189728 and batch: 800, loss is 3.8480220556259157 and perplexity is 46.9002054305956
At time: 404.4080390930176 and batch: 850, loss is 3.862131805419922 and perplexity is 47.56664619422704
At time: 405.4515845775604 and batch: 900, loss is 3.843590292930603 and perplexity is 46.69281474236184
At time: 406.4973895549774 and batch: 950, loss is 3.9342447566986083 and perplexity is 51.12352467319707
At time: 407.54334592819214 and batch: 1000, loss is 3.895652050971985 and perplexity is 49.18811606718078
At time: 408.58855509757996 and batch: 1050, loss is 3.844980320930481 and perplexity is 46.75776419256618
At time: 409.6338953971863 and batch: 1100, loss is 3.8884740543365477 and perplexity is 48.83630808433986
At time: 410.68467473983765 and batch: 1150, loss is 3.840378956794739 and perplexity is 46.54310892559969
At time: 411.74268555641174 and batch: 1200, loss is 3.8797524785995483 and perplexity is 48.412230525091964
At time: 412.78739953041077 and batch: 1250, loss is 3.8695095014572143 and perplexity is 47.91887617656718
At time: 413.831111907959 and batch: 1300, loss is 3.8654409885406493 and perplexity is 47.7243136683139
At time: 414.87656831741333 and batch: 1350, loss is 3.7550100660324097 and perplexity is 42.734649976759044
At time: 415.92021679878235 and batch: 1400, loss is 3.771926259994507 and perplexity is 43.463706651383006
At time: 416.9644455909729 and batch: 1450, loss is 3.6962048482894896 and perplexity is 40.294091620431
At time: 418.009330034256 and batch: 1500, loss is 3.696504454612732 and perplexity is 40.3061657937288
At time: 419.05462861061096 and batch: 1550, loss is 3.703486566543579 and perplexity is 40.58857270586469
At time: 420.10012793540955 and batch: 1600, loss is 3.792671298980713 and perplexity is 44.37478039688367
At time: 421.14526557922363 and batch: 1650, loss is 3.7323860836029055 and perplexity is 41.77867674283957
At time: 422.19204688072205 and batch: 1700, loss is 3.7557353019714355 and perplexity is 42.76565392199262
At time: 423.23689699172974 and batch: 1750, loss is 3.7514144372940064 and perplexity is 42.58126795882333
At time: 424.28313994407654 and batch: 1800, loss is 3.7068785667419433 and perplexity is 40.7264829160354
At time: 425.32719373703003 and batch: 1850, loss is 3.7333067893981933 and perplexity is 41.81716032594662
At time: 426.3727948665619 and batch: 1900, loss is 3.8031135177612305 and perplexity is 44.840579316690295
At time: 427.41708970069885 and batch: 1950, loss is 3.748600196838379 and perplexity is 42.461602494555734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49453976653343 and perplexity of 89.52695620071785
finished 10 epochs...
Completing Train Step...
At time: 430.6950240135193 and batch: 50, loss is 3.9428836059570314 and perplexity is 51.567086268718775
At time: 431.7588400840759 and batch: 100, loss is 3.9220935535430907 and perplexity is 50.50607133665214
At time: 432.79830050468445 and batch: 150, loss is 3.8965963983535765 and perplexity is 49.234588675483565
At time: 433.83750581741333 and batch: 200, loss is 3.8845643520355226 and perplexity is 48.645745422628835
At time: 434.87675762176514 and batch: 250, loss is 3.8816796112060548 and perplexity is 48.505617268507756
At time: 435.9158411026001 and batch: 300, loss is 3.891466999053955 and perplexity is 48.982691403958455
At time: 436.9560225009918 and batch: 350, loss is 3.9088091135025023 and perplexity is 49.83956335483422
At time: 437.9970064163208 and batch: 400, loss is 3.855771474838257 and perplexity is 47.26506668911443
At time: 439.0360462665558 and batch: 450, loss is 3.902262258529663 and perplexity is 49.5143367290524
At time: 440.0761077404022 and batch: 500, loss is 3.9283974409103393 and perplexity is 50.825461564043906
At time: 441.11600708961487 and batch: 550, loss is 3.8929064083099365 and perplexity is 49.05324831129872
At time: 442.15912985801697 and batch: 600, loss is 3.872242040634155 and perplexity is 48.04999544571808
At time: 443.19699215888977 and batch: 650, loss is 3.886093997955322 and perplexity is 48.72021312872149
At time: 444.25905442237854 and batch: 700, loss is 3.921122350692749 and perplexity is 50.4570435080476
At time: 445.2977738380432 and batch: 750, loss is 3.874964599609375 and perplexity is 48.180992634948566
At time: 446.3382978439331 and batch: 800, loss is 3.830527663230896 and perplexity is 46.086850155651824
At time: 447.37650895118713 and batch: 850, loss is 3.8453665924072267 and perplexity is 46.77582887190074
At time: 448.4144129753113 and batch: 900, loss is 3.8273717308044435 and perplexity is 45.941632439991004
At time: 449.4531195163727 and batch: 950, loss is 3.9182263135910036 and perplexity is 50.31112942628328
At time: 450.4929521083832 and batch: 1000, loss is 3.880349817276001 and perplexity is 48.44115766158652
At time: 451.52955961227417 and batch: 1050, loss is 3.830793242454529 and perplexity is 46.09909149098606
At time: 452.5683615207672 and batch: 1100, loss is 3.874997420310974 and perplexity is 48.18257399488112
At time: 453.6085031032562 and batch: 1150, loss is 3.827701244354248 and perplexity is 45.956773324806484
At time: 454.6482186317444 and batch: 1200, loss is 3.867989764213562 and perplexity is 47.846107384495
At time: 455.68782901763916 and batch: 1250, loss is 3.8584966039657593 and perplexity is 47.39404576155577
At time: 456.7277321815491 and batch: 1300, loss is 3.855085129737854 and perplexity is 47.232637672193604
At time: 457.76680183410645 and batch: 1350, loss is 3.7453095626831057 and perplexity is 42.32210653605729
At time: 458.8034312725067 and batch: 1400, loss is 3.763693218231201 and perplexity is 43.10733715478825
At time: 459.8436772823334 and batch: 1450, loss is 3.688723020553589 and perplexity is 39.993743146989765
At time: 460.88408041000366 and batch: 1500, loss is 3.6896923923492433 and perplexity is 40.032530750366135
At time: 461.92304944992065 and batch: 1550, loss is 3.6979442930221555 and perplexity is 40.364241959488965
At time: 462.9620769023895 and batch: 1600, loss is 3.7876430797576903 and perplexity is 44.15221429757194
At time: 464.0005292892456 and batch: 1650, loss is 3.7285402822494507 and perplexity is 41.61831281283694
At time: 465.03800916671753 and batch: 1700, loss is 3.752701687812805 and perplexity is 42.63611601211329
At time: 466.07628655433655 and batch: 1750, loss is 3.7495369243621828 and perplexity is 42.501396081281406
At time: 467.1145167350769 and batch: 1800, loss is 3.705442714691162 and perplexity is 40.66804767423971
At time: 468.1560003757477 and batch: 1850, loss is 3.7330359745025636 and perplexity is 41.80583714934907
At time: 469.20149183273315 and batch: 1900, loss is 3.8031270694732666 and perplexity is 44.84118698742621
At time: 470.2412497997284 and batch: 1950, loss is 3.749121561050415 and perplexity is 42.483746226455175
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495549543513808 and perplexity of 89.6174041186399
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 473.5172107219696 and batch: 50, loss is 3.9338519239425658 and perplexity is 51.10344562221377
At time: 474.58392000198364 and batch: 100, loss is 3.9228060626983643 and perplexity is 50.542070198112626
At time: 475.62516355514526 and batch: 150, loss is 3.902870798110962 and perplexity is 49.54447733273883
At time: 476.6676731109619 and batch: 200, loss is 3.8917386293411256 and perplexity is 48.99599839369981
At time: 477.7090549468994 and batch: 250, loss is 3.8933613777160643 and perplexity is 49.07557111626314
At time: 478.750629901886 and batch: 300, loss is 3.8979502534866333 and perplexity is 49.30129031807816
At time: 479.78786969184875 and batch: 350, loss is 3.9166516637802125 and perplexity is 50.231969356902226
At time: 480.8279926776886 and batch: 400, loss is 3.866581835746765 and perplexity is 47.77879088740914
At time: 481.87477111816406 and batch: 450, loss is 3.913013372421265 and perplexity is 50.04954287842229
At time: 482.91837763786316 and batch: 500, loss is 3.9374156379699707 and perplexity is 51.2858885824083
At time: 483.96117067337036 and batch: 550, loss is 3.9009191179275513 and perplexity is 49.447876655607836
At time: 485.00246143341064 and batch: 600, loss is 3.880640745162964 and perplexity is 48.45525259543229
At time: 486.04210782051086 and batch: 650, loss is 3.8923123407363893 and perplexity is 49.02411602123102
At time: 487.0816099643707 and batch: 700, loss is 3.925313353538513 and perplexity is 50.66895286716874
At time: 488.12224888801575 and batch: 750, loss is 3.8761730861663817 and perplexity is 48.239253913746666
At time: 489.162305355072 and batch: 800, loss is 3.830470881462097 and perplexity is 46.084233337076114
At time: 490.20316648483276 and batch: 850, loss is 3.8459923171997072 and perplexity is 46.80510682673055
At time: 491.2435305118561 and batch: 900, loss is 3.8177274656295777 and perplexity is 45.50068886032116
At time: 492.285037279129 and batch: 950, loss is 3.9127912664413453 and perplexity is 50.03842781006402
At time: 493.32505226135254 and batch: 1000, loss is 3.873946452140808 and perplexity is 48.131962243584184
At time: 494.36670327186584 and batch: 1050, loss is 3.825554857254028 and perplexity is 45.858238084587775
At time: 495.407918214798 and batch: 1100, loss is 3.8650904750823973 and perplexity is 47.70758858544187
At time: 496.4743127822876 and batch: 1150, loss is 3.8220872926712035 and perplexity is 45.6994970638042
At time: 497.5148997306824 and batch: 1200, loss is 3.86122371673584 and perplexity is 47.523471067467284
At time: 498.5558395385742 and batch: 1250, loss is 3.8491059303283692 and perplexity is 46.9510669355717
At time: 499.597056388855 and batch: 1300, loss is 3.8433760833740234 and perplexity is 46.682813766410966
At time: 500.63929057121277 and batch: 1350, loss is 3.728400936126709 and perplexity is 41.61251386635117
At time: 501.68604946136475 and batch: 1400, loss is 3.7459496545791624 and perplexity is 42.34920524538195
At time: 502.7282626628876 and batch: 1450, loss is 3.6662842226028443 and perplexity is 39.10632515596154
At time: 503.770055770874 and batch: 1500, loss is 3.666384563446045 and perplexity is 39.11024931447556
At time: 504.8114697933197 and batch: 1550, loss is 3.680016722679138 and perplexity is 39.6470570720432
At time: 505.8527693748474 and batch: 1600, loss is 3.768067240715027 and perplexity is 43.29630258496635
At time: 506.8938670158386 and batch: 1650, loss is 3.704052596092224 and perplexity is 40.61155354065574
At time: 507.9345016479492 and batch: 1700, loss is 3.7215328359603883 and perplexity is 41.32769415768579
At time: 508.97267389297485 and batch: 1750, loss is 3.71670241355896 and perplexity is 41.12854531177824
At time: 510.0162572860718 and batch: 1800, loss is 3.672654399871826 and perplexity is 39.356234517919816
At time: 511.0583863258362 and batch: 1850, loss is 3.69920503616333 and perplexity is 40.415162993115246
At time: 512.0992789268494 and batch: 1900, loss is 3.77038920879364 and perplexity is 43.39695202466242
At time: 513.142599105835 and batch: 1950, loss is 3.724216675758362 and perplexity is 41.438760042878855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487677143895349 and perplexity of 88.91466983251902
finished 12 epochs...
Completing Train Step...
At time: 516.4434378147125 and batch: 50, loss is 3.9318327474594117 and perplexity is 51.00036285278018
At time: 517.4887399673462 and batch: 100, loss is 3.9131557893753053 and perplexity is 50.0566712894614
At time: 518.5370016098022 and batch: 150, loss is 3.88989444732666 and perplexity is 48.90572412136136
At time: 519.5831458568573 and batch: 200, loss is 3.877586245536804 and perplexity is 48.307471857497575
At time: 520.6291358470917 and batch: 250, loss is 3.876733465194702 and perplexity is 48.26629375555429
At time: 521.6754055023193 and batch: 300, loss is 3.8812082958221437 and perplexity is 48.48276121151174
At time: 522.7593629360199 and batch: 350, loss is 3.899452791213989 and perplexity is 49.37542304645205
At time: 523.804158449173 and batch: 400, loss is 3.8498994493484497 and perplexity is 46.98833828600516
At time: 524.8521568775177 and batch: 450, loss is 3.8962985372543333 and perplexity is 49.219925790639806
At time: 525.8976521492004 and batch: 500, loss is 3.9219509887695314 and perplexity is 50.49887146326501
At time: 526.9437379837036 and batch: 550, loss is 3.885799241065979 and perplexity is 48.70585462648923
At time: 527.9877982139587 and batch: 600, loss is 3.8661415433883666 and perplexity is 47.75775888134343
At time: 529.0332975387573 and batch: 650, loss is 3.8769245672225954 and perplexity is 48.27551842356818
At time: 530.0787677764893 and batch: 700, loss is 3.9121477890014646 and perplexity is 50.006239567955625
At time: 531.1235222816467 and batch: 750, loss is 3.8641954326629637 and perplexity is 47.664907373525935
At time: 532.1699206829071 and batch: 800, loss is 3.8187276887893677 and perplexity is 45.54622247119557
At time: 533.2208251953125 and batch: 850, loss is 3.834767484664917 and perplexity is 46.2826649873967
At time: 534.2677118778229 and batch: 900, loss is 3.808037805557251 and perplexity is 45.06193178853317
At time: 535.3134775161743 and batch: 950, loss is 3.9036518239974978 and perplexity is 49.58318796710656
At time: 536.3574593067169 and batch: 1000, loss is 3.8647725439071654 and perplexity is 47.69242326662698
At time: 537.4032020568848 and batch: 1050, loss is 3.8169246768951415 and perplexity is 45.46417607788116
At time: 538.4469821453094 and batch: 1100, loss is 3.8574990367889406 and perplexity is 47.34679059114966
At time: 539.4933941364288 and batch: 1150, loss is 3.8151620721817014 and perplexity is 45.384111288849496
At time: 540.5389761924744 and batch: 1200, loss is 3.8545189762115477 and perplexity is 47.205904316124716
At time: 541.5857648849487 and batch: 1250, loss is 3.843129262924194 and perplexity is 46.67129291516718
At time: 542.6389110088348 and batch: 1300, loss is 3.8385845851898193 and perplexity is 46.45966817678243
At time: 543.6817533969879 and batch: 1350, loss is 3.724475021362305 and perplexity is 41.449466947350075
At time: 544.7270822525024 and batch: 1400, loss is 3.7437393188476564 and perplexity is 42.255702657950096
At time: 545.772997379303 and batch: 1450, loss is 3.6658167839050293 and perplexity is 39.08804961793392
At time: 546.8210566043854 and batch: 1500, loss is 3.6671388721466065 and perplexity is 39.13976164511916
At time: 547.8660271167755 and batch: 1550, loss is 3.681752390861511 and perplexity is 39.71593096134654
At time: 548.9129953384399 and batch: 1600, loss is 3.770245623588562 and perplexity is 43.39072131173601
At time: 549.9591498374939 and batch: 1650, loss is 3.7074079608917234 and perplexity is 40.74804898580418
At time: 551.0035471916199 and batch: 1700, loss is 3.725943922996521 and perplexity is 41.51039687616687
At time: 552.0480449199677 and batch: 1750, loss is 3.7219052505493164 and perplexity is 41.34308806019589
At time: 553.0943908691406 and batch: 1800, loss is 3.678243622779846 and perplexity is 39.57682116518235
At time: 554.1400485038757 and batch: 1850, loss is 3.705290880203247 and perplexity is 40.66187333079758
At time: 555.1902256011963 and batch: 1900, loss is 3.77602165222168 and perplexity is 43.64207256766121
At time: 556.2385637760162 and batch: 1950, loss is 3.7296796941757204 and perplexity is 41.66576024075648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487163880813953 and perplexity of 88.86904492489148
finished 13 epochs...
Completing Train Step...
At time: 559.4892930984497 and batch: 50, loss is 3.927631974220276 and perplexity is 50.78657125272742
At time: 560.5587451457977 and batch: 100, loss is 3.907303500175476 and perplexity is 49.76458070563664
At time: 561.6078951358795 and batch: 150, loss is 3.8830362653732298 and perplexity is 48.571467274048885
At time: 562.6500248908997 and batch: 200, loss is 3.8702938842773436 and perplexity is 47.95647766485281
At time: 563.6921865940094 and batch: 250, loss is 3.868831310272217 and perplexity is 47.88638903464108
At time: 564.7321581840515 and batch: 300, loss is 3.873010640144348 and perplexity is 48.086940844971544
At time: 565.7729587554932 and batch: 350, loss is 3.8912141799926756 and perplexity is 48.970309211191896
At time: 566.8157453536987 and batch: 400, loss is 3.8416218090057375 and perplexity is 46.600991093473986
At time: 567.8576054573059 and batch: 450, loss is 3.8880055570602416 and perplexity is 48.81343376571388
At time: 568.899808883667 and batch: 500, loss is 3.9140467929840086 and perplexity is 50.1012918398037
At time: 569.941329240799 and batch: 550, loss is 3.877980041503906 and perplexity is 48.326498891234635
At time: 570.9841809272766 and batch: 600, loss is 3.8585547733306886 and perplexity is 47.396802723283734
At time: 572.0250396728516 and batch: 650, loss is 3.8696049737930296 and perplexity is 47.92345132200183
At time: 573.0671124458313 and batch: 700, loss is 3.905313768386841 and perplexity is 49.665660981953444
At time: 574.1106581687927 and batch: 750, loss is 3.8578746032714846 and perplexity is 47.364575798306525
At time: 575.182279586792 and batch: 800, loss is 3.812468695640564 and perplexity is 45.26203925493532
At time: 576.2261078357697 and batch: 850, loss is 3.8286997413635255 and perplexity is 46.002683942520186
At time: 577.2686862945557 and batch: 900, loss is 3.802665967941284 and perplexity is 44.82051541362383
At time: 578.3096075057983 and batch: 950, loss is 3.898568515777588 and perplexity is 49.331780871385654
At time: 579.3533437252045 and batch: 1000, loss is 3.859818925857544 and perplexity is 47.45675739915438
At time: 580.398885011673 and batch: 1050, loss is 3.8123299407958986 and perplexity is 45.255759363402035
At time: 581.4419603347778 and batch: 1100, loss is 3.8533033514022828 and perplexity is 47.148554512678544
At time: 582.483984708786 and batch: 1150, loss is 3.8113358926773073 and perplexity is 45.210795312868875
At time: 583.5274176597595 and batch: 1200, loss is 3.850941290855408 and perplexity is 47.037318197396495
At time: 584.5754065513611 and batch: 1250, loss is 3.839976849555969 and perplexity is 46.52439736686459
At time: 585.6190519332886 and batch: 1300, loss is 3.83600800037384 and perplexity is 46.34011498681039
At time: 586.6635391712189 and batch: 1350, loss is 3.722245397567749 and perplexity is 41.35715318030108
At time: 587.706800699234 and batch: 1400, loss is 3.742281446456909 and perplexity is 42.194144118843724
At time: 588.7502820491791 and batch: 1450, loss is 3.6650278854370115 and perplexity is 39.057225275709364
At time: 589.7917971611023 and batch: 1500, loss is 3.666801290512085 and perplexity is 39.126551010367514
At time: 590.8324546813965 and batch: 1550, loss is 3.6819995164871218 and perplexity is 39.72574699847927
At time: 591.8729305267334 and batch: 1600, loss is 3.7706543016433716 and perplexity is 43.4084577713225
At time: 592.9129078388214 and batch: 1650, loss is 3.7083595895767214 and perplexity is 40.78684445458949
At time: 593.9536881446838 and batch: 1700, loss is 3.7272448348999023 and perplexity is 41.56443338632598
At time: 594.9948997497559 and batch: 1750, loss is 3.7236478614807127 and perplexity is 41.41519578699633
At time: 596.0363309383392 and batch: 1800, loss is 3.6801734733581544 and perplexity is 39.65327226226516
At time: 597.0849943161011 and batch: 1850, loss is 3.7074448680877685 and perplexity is 40.749552909789195
At time: 598.126965045929 and batch: 1900, loss is 3.7779238176345826 and perplexity is 43.72516601233077
At time: 599.1760923862457 and batch: 1950, loss is 3.731463713645935 and perplexity is 41.74015911305305
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487262672601744 and perplexity of 88.87782489040602
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 602.4847798347473 and batch: 50, loss is 3.9254577064514162 and perplexity is 50.67626760604809
At time: 603.5526044368744 and batch: 100, loss is 3.907701544761658 and perplexity is 49.78439317043072
At time: 604.592148065567 and batch: 150, loss is 3.8851547288894652 and perplexity is 48.67447322404924
At time: 605.6330060958862 and batch: 200, loss is 3.8725300359725954 and perplexity is 48.06383561327473
At time: 606.6728765964508 and batch: 250, loss is 3.8713432502746583 and perplexity is 48.00682797519676
At time: 607.7171974182129 and batch: 300, loss is 3.8738735628128054 and perplexity is 48.128454065056744
At time: 608.7595369815826 and batch: 350, loss is 3.8919410800933836 and perplexity is 49.005918674582524
At time: 609.8003878593445 and batch: 400, loss is 3.8434834623336793 and perplexity is 46.68782678752869
At time: 610.8414976596832 and batch: 450, loss is 3.8902008056640627 and perplexity is 48.92070909296094
At time: 611.8843035697937 and batch: 500, loss is 3.9161170959472655 and perplexity is 50.20512413783302
At time: 612.9258968830109 and batch: 550, loss is 3.879789261817932 and perplexity is 48.41401131549121
At time: 613.9656736850739 and batch: 600, loss is 3.860109224319458 and perplexity is 47.470536022694624
At time: 615.0066983699799 and batch: 650, loss is 3.870913381576538 and perplexity is 47.98619577743989
At time: 616.0471777915955 and batch: 700, loss is 3.9058717489242554 and perplexity is 49.69338118710748
At time: 617.0891029834747 and batch: 750, loss is 3.8578718280792237 and perplexity is 47.36444435268472
At time: 618.1298635005951 and batch: 800, loss is 3.8125758457183836 and perplexity is 45.26688934580294
At time: 619.1717817783356 and batch: 850, loss is 3.8296981763839724 and perplexity is 46.04863757024107
At time: 620.2104625701904 and batch: 900, loss is 3.7988649940490724 and perplexity is 44.65047716489076
At time: 621.2541542053223 and batch: 950, loss is 3.8961063528060915 and perplexity is 49.21046739526659
At time: 622.2939820289612 and batch: 1000, loss is 3.856020941734314 and perplexity is 47.276859229456356
At time: 623.3332419395447 and batch: 1050, loss is 3.8096106100082396 and perplexity is 45.13286115981418
At time: 624.3741090297699 and batch: 1100, loss is 3.8482954025268556 and perplexity is 46.91302720872032
At time: 625.4148671627045 and batch: 1150, loss is 3.80807297706604 and perplexity is 45.06351671253506
At time: 626.4556741714478 and batch: 1200, loss is 3.8485111665725706 and perplexity is 46.92315044534358
At time: 627.526752948761 and batch: 1250, loss is 3.8365656042099 and perplexity is 46.365961618111186
At time: 628.5662360191345 and batch: 1300, loss is 3.8320356702804563 and perplexity is 46.15640187964308
At time: 629.6083254814148 and batch: 1350, loss is 3.7163917636871338 and perplexity is 41.1157707187643
At time: 630.648885011673 and batch: 1400, loss is 3.7355186414718626 and perplexity is 41.909756065016836
At time: 631.692004442215 and batch: 1450, loss is 3.6553458881378176 and perplexity is 38.680898065364765
At time: 632.730105638504 and batch: 1500, loss is 3.6553324127197264 and perplexity is 38.68037682760315
At time: 633.7702007293701 and batch: 1550, loss is 3.671691403388977 and perplexity is 39.31835284538709
At time: 634.8114356994629 and batch: 1600, loss is 3.7613763856887816 and perplexity is 43.00758027786257
At time: 635.8518917560577 and batch: 1650, loss is 3.698573169708252 and perplexity is 40.38963407362669
At time: 636.8921191692352 and batch: 1700, loss is 3.71531934261322 and perplexity is 41.07170093468156
At time: 637.9332644939423 and batch: 1750, loss is 3.712560286521912 and perplexity is 40.95853799127819
At time: 638.9744908809662 and batch: 1800, loss is 3.668539357185364 and perplexity is 39.19461469719752
At time: 640.0152616500854 and batch: 1850, loss is 3.6939475250244143 and perplexity is 40.20323741220913
At time: 641.0557327270508 and batch: 1900, loss is 3.7643404531478883 and perplexity is 43.13524675962131
At time: 642.093772649765 and batch: 1950, loss is 3.720794467926025 and perplexity is 41.29719037228171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4865208825399705 and perplexity of 88.8119206497676
finished 15 epochs...
Completing Train Step...
At time: 645.3917291164398 and batch: 50, loss is 3.9240992403030397 and perplexity is 50.60747235057181
At time: 646.4333937168121 and batch: 100, loss is 3.904582448005676 and perplexity is 49.62935274992659
At time: 647.4769413471222 and batch: 150, loss is 3.8813629055023195 and perplexity is 48.490257695216236
At time: 648.5174672603607 and batch: 200, loss is 3.868905072212219 and perplexity is 47.88992135786988
At time: 649.5578083992004 and batch: 250, loss is 3.867069616317749 and perplexity is 47.80210213823454
At time: 650.5989060401917 and batch: 300, loss is 3.8701358032226563 and perplexity is 47.94889725345996
At time: 651.6417863368988 and batch: 350, loss is 3.8881281805038452 and perplexity is 48.819419804063166
At time: 652.6832208633423 and batch: 400, loss is 3.839551796913147 and perplexity is 46.5046262509883
At time: 653.7528827190399 and batch: 450, loss is 3.886292872428894 and perplexity is 48.729903298991594
At time: 654.8007142543793 and batch: 500, loss is 3.912535057067871 and perplexity is 50.02560913802725
At time: 655.8428509235382 and batch: 550, loss is 3.8760412645339968 and perplexity is 48.23289535565768
At time: 656.8834047317505 and batch: 600, loss is 3.8563668012619017 and perplexity is 47.29321320958218
At time: 657.9260632991791 and batch: 650, loss is 3.867304539680481 and perplexity is 47.813333287992585
At time: 658.9676377773285 and batch: 700, loss is 3.902836174964905 and perplexity is 49.54276197675951
At time: 660.0094649791718 and batch: 750, loss is 3.854943723678589 and perplexity is 47.22595916323363
At time: 661.0524914264679 and batch: 800, loss is 3.809594039916992 and perplexity is 45.132113310382486
At time: 662.1008293628693 and batch: 850, loss is 3.8266735887527465 and perplexity is 45.909569847885244
At time: 663.1435375213623 and batch: 900, loss is 3.7966914224624633 and perplexity is 44.553531553677196
At time: 664.186505317688 and batch: 950, loss is 3.8940679121017454 and perplexity is 49.11025694667676
At time: 665.2289576530457 and batch: 1000, loss is 3.8542448329925536 and perplexity is 47.19296491126605
At time: 666.2711834907532 and batch: 1050, loss is 3.8077549886703492 and perplexity is 45.049189315245215
At time: 667.3139140605927 and batch: 1100, loss is 3.8468314599990845 and perplexity is 46.84439947886565
At time: 668.3553647994995 and batch: 1150, loss is 3.8067888021469116 and perplexity is 45.00568441594512
At time: 669.3978054523468 and batch: 1200, loss is 3.847057065963745 and perplexity is 46.854969047033
At time: 670.4380404949188 and batch: 1250, loss is 3.835280079841614 and perplexity is 46.306395339746395
At time: 671.4802720546722 and batch: 1300, loss is 3.8310337972640993 and perplexity is 46.110182183067224
At time: 672.5229706764221 and batch: 1350, loss is 3.715632381439209 and perplexity is 41.08455998430941
At time: 673.5655646324158 and batch: 1400, loss is 3.7353259325027466 and perplexity is 41.90168045727565
At time: 674.6081042289734 and batch: 1450, loss is 3.6556973838806153 and perplexity is 38.694496626140435
At time: 675.6542224884033 and batch: 1500, loss is 3.6562233638763426 and perplexity is 38.714854510761214
At time: 676.6938576698303 and batch: 1550, loss is 3.6729855966567992 and perplexity is 39.369271335017594
At time: 677.7357602119446 and batch: 1600, loss is 3.7628212928771974 and perplexity is 43.06976715607684
At time: 678.7770991325378 and batch: 1650, loss is 3.700285859107971 and perplexity is 40.458868243153496
At time: 679.8172721862793 and batch: 1700, loss is 3.7170503616333006 and perplexity is 41.14285839988121
At time: 680.8572161197662 and batch: 1750, loss is 3.714398112297058 and perplexity is 41.03388186135727
At time: 681.9053249359131 and batch: 1800, loss is 3.6704053115844726 and perplexity is 39.267818337000044
At time: 682.9489645957947 and batch: 1850, loss is 3.6959054327011107 and perplexity is 40.28202874727653
At time: 683.9907445907593 and batch: 1900, loss is 3.766009974479675 and perplexity is 43.207322123175544
At time: 685.031774520874 and batch: 1950, loss is 3.722404050827026 and perplexity is 41.363715147972584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486269644803779 and perplexity of 88.78961054656402
finished 16 epochs...
Completing Train Step...
At time: 688.287927865982 and batch: 50, loss is 3.9227809953689574 and perplexity is 50.54080325926952
At time: 689.3594417572021 and batch: 100, loss is 3.902465033531189 and perplexity is 49.52437801678485
At time: 690.4032785892487 and batch: 150, loss is 3.878983221054077 and perplexity is 48.37500337193747
At time: 691.4480977058411 and batch: 200, loss is 3.8664183902740477 and perplexity is 47.770982298503306
At time: 692.4933145046234 and batch: 250, loss is 3.864352111816406 and perplexity is 47.67237605594027
At time: 693.5373742580414 and batch: 300, loss is 3.8675383949279785 and perplexity is 47.82451599439865
At time: 694.5835957527161 and batch: 350, loss is 3.885528817176819 and perplexity is 48.6926851806029
At time: 695.6288485527039 and batch: 400, loss is 3.836826810836792 and perplexity is 46.378074296435095
At time: 696.6742537021637 and batch: 450, loss is 3.8835817050933836 and perplexity is 48.597967307994864
At time: 697.7182381153107 and batch: 500, loss is 3.910025005340576 and perplexity is 49.90019972929656
At time: 698.7624945640564 and batch: 550, loss is 3.8735254430770873 and perplexity is 48.11170251628864
At time: 699.807211637497 and batch: 600, loss is 3.853897366523743 and perplexity is 47.17656978693855
At time: 700.8517787456512 and batch: 650, loss is 3.8649970388412473 and perplexity is 47.703131175935155
At time: 701.8970172405243 and batch: 700, loss is 3.900678024291992 and perplexity is 49.43595652424589
At time: 702.9417324066162 and batch: 750, loss is 3.8529124879837036 and perplexity is 47.130129468553086
At time: 703.9870066642761 and batch: 800, loss is 3.8075873374938967 and perplexity is 45.041637398719814
At time: 705.0305500030518 and batch: 850, loss is 3.8246474409103395 and perplexity is 45.81664444408568
At time: 706.1130657196045 and batch: 900, loss is 3.7950865840911865 and perplexity is 44.48208767993263
At time: 707.1570329666138 and batch: 950, loss is 3.8925201320648193 and perplexity is 49.03430386586041
At time: 708.2025215625763 and batch: 1000, loss is 3.8527961492538454 and perplexity is 47.12464672808638
At time: 709.2501068115234 and batch: 1050, loss is 3.806359748840332 and perplexity is 44.986378720114054
At time: 710.3002383708954 and batch: 1100, loss is 3.8456857204437256 and perplexity is 46.790758732466074
At time: 711.3490195274353 and batch: 1150, loss is 3.805805287361145 and perplexity is 44.96144241977346
At time: 712.3958971500397 and batch: 1200, loss is 3.8460512590408324 and perplexity is 46.807865687206345
At time: 713.4397230148315 and batch: 1250, loss is 3.834405303001404 and perplexity is 46.265905290010494
At time: 714.4843809604645 and batch: 1300, loss is 3.8304050636291502 and perplexity is 46.08120027252081
At time: 715.52889585495 and batch: 1350, loss is 3.715164523124695 and perplexity is 41.06534272714991
At time: 716.5744173526764 and batch: 1400, loss is 3.735256428718567 and perplexity is 41.89876823312686
At time: 717.6202402114868 and batch: 1450, loss is 3.655953817367554 and perplexity is 38.7044204631833
At time: 718.6656155586243 and batch: 1500, loss is 3.6568251991271974 and perplexity is 38.73816148771417
At time: 719.7086825370789 and batch: 1550, loss is 3.673826756477356 and perplexity is 39.4024011159961
At time: 720.7533197402954 and batch: 1600, loss is 3.7636856126785276 and perplexity is 43.10700930091166
At time: 721.8041434288025 and batch: 1650, loss is 3.701290249824524 and perplexity is 40.499525169120766
At time: 722.8523275852203 and batch: 1700, loss is 3.7181599855422975 and perplexity is 41.188536837502596
At time: 723.896537065506 and batch: 1750, loss is 3.7156132650375366 and perplexity is 41.08377460286508
At time: 724.9425194263458 and batch: 1800, loss is 3.6716526174545288 and perplexity is 39.31682787590489
At time: 725.9872829914093 and batch: 1850, loss is 3.697181239128113 and perplexity is 40.33345361555844
At time: 727.0290048122406 and batch: 1900, loss is 3.767053484916687 and perplexity is 43.25243294748092
At time: 728.0746126174927 and batch: 1950, loss is 3.7233711433410646 and perplexity is 41.40373703656016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486189589389535 and perplexity of 88.78250274202404
finished 17 epochs...
Completing Train Step...
At time: 731.3563165664673 and batch: 50, loss is 3.921505918502808 and perplexity is 50.47640091793035
At time: 732.4302158355713 and batch: 100, loss is 3.9006913137435912 and perplexity is 49.43661350536283
At time: 733.4743096828461 and batch: 150, loss is 3.8770203971862793 and perplexity is 48.280144886418874
At time: 734.510162115097 and batch: 200, loss is 3.8643745613098144 and perplexity is 47.67344628864534
At time: 735.5475392341614 and batch: 250, loss is 3.8621607303619383 and perplexity is 47.56802207660868
At time: 736.5871331691742 and batch: 300, loss is 3.865385718345642 and perplexity is 47.721676009083495
At time: 737.6268796920776 and batch: 350, loss is 3.8833956956863402 and perplexity is 48.588928469592936
At time: 738.6693544387817 and batch: 400, loss is 3.8346122789382933 and perplexity is 46.275482210165755
At time: 739.7169599533081 and batch: 450, loss is 3.8813885116577147 and perplexity is 48.491499360187
At time: 740.754575252533 and batch: 500, loss is 3.90796603679657 and perplexity is 49.79756248740017
At time: 741.7932000160217 and batch: 550, loss is 3.871481819152832 and perplexity is 48.01348068841281
At time: 742.8313961029053 and batch: 600, loss is 3.8519034147262574 and perplexity is 47.08259570184615
At time: 743.8699970245361 and batch: 650, loss is 3.8631177234649656 and perplexity is 47.613566134859546
At time: 744.9093337059021 and batch: 700, loss is 3.8989077377319337 and perplexity is 49.34851813316703
At time: 745.9473176002502 and batch: 750, loss is 3.8512583017349242 and perplexity is 47.05223190278687
At time: 746.986677646637 and batch: 800, loss is 3.8059615802764895 and perplexity is 44.96847012386321
At time: 748.0236804485321 and batch: 850, loss is 3.8230195903778075 and perplexity is 45.74212246680505
At time: 749.0614020824432 and batch: 900, loss is 3.7937419748306276 and perplexity is 44.42231684612287
At time: 750.1001675128937 and batch: 950, loss is 3.8912297296524048 and perplexity is 48.97107068875731
At time: 751.145013332367 and batch: 1000, loss is 3.851556510925293 and perplexity is 47.06626540312304
At time: 752.1846916675568 and batch: 1050, loss is 3.8051928663253785 and perplexity is 44.93391551652484
At time: 753.2218823432922 and batch: 1100, loss is 3.8446893072128296 and perplexity is 46.74415902152116
At time: 754.2606272697449 and batch: 1150, loss is 3.804942026138306 and perplexity is 44.922645698271516
At time: 755.2974145412445 and batch: 1200, loss is 3.8452168035507204 and perplexity is 46.76882289870334
At time: 756.3348715305328 and batch: 1250, loss is 3.833676857948303 and perplexity is 46.232215392284175
At time: 757.3740277290344 and batch: 1300, loss is 3.8298692655563356 and perplexity is 46.05651666752632
At time: 758.4192318916321 and batch: 1350, loss is 3.714744381904602 and perplexity is 41.04809310784479
At time: 759.4605195522308 and batch: 1400, loss is 3.7351120567321776 and perplexity is 41.89271966136244
At time: 760.5003976821899 and batch: 1450, loss is 3.6560465192794798 and perplexity is 38.708008603271374
At time: 761.5457873344421 and batch: 1500, loss is 3.6571469736099242 and perplexity is 38.75062844525551
At time: 762.5830562114716 and batch: 1550, loss is 3.674326500892639 and perplexity is 39.422097166988394
At time: 763.6214592456818 and batch: 1600, loss is 3.7641869020462035 and perplexity is 43.12862380345404
At time: 764.6690049171448 and batch: 1650, loss is 3.701900353431702 and perplexity is 40.52424161454502
At time: 765.7087173461914 and batch: 1700, loss is 3.7188753271102906 and perplexity is 41.218011250906955
At time: 766.7493607997894 and batch: 1750, loss is 3.7164245367050173 and perplexity is 41.11711822873423
At time: 767.7886798381805 and batch: 1800, loss is 3.6725009298324585 and perplexity is 39.35019497851503
At time: 768.8258917331696 and batch: 1850, loss is 3.6980526733398436 and perplexity is 40.36861688592945
At time: 769.8638451099396 and batch: 1900, loss is 3.7677555465698243 and perplexity is 43.28280948391124
At time: 770.9035129547119 and batch: 1950, loss is 3.7240085983276368 and perplexity is 41.43013846916526
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486183911700581 and perplexity of 88.78199866401994
finished 18 epochs...
Completing Train Step...
At time: 774.2117247581482 and batch: 50, loss is 3.9202614498138426 and perplexity is 50.41362368770696
At time: 775.2529590129852 and batch: 100, loss is 3.8991028881072998 and perplexity is 49.35814945475193
At time: 776.2913649082184 and batch: 150, loss is 3.8752748346328736 and perplexity is 48.19594238517901
At time: 777.3332364559174 and batch: 200, loss is 3.862570004463196 and perplexity is 47.58749442058391
At time: 778.37562251091 and batch: 250, loss is 3.8602542448043824 and perplexity is 47.4774207220474
At time: 779.4168758392334 and batch: 300, loss is 3.863490333557129 and perplexity is 47.63131073582869
At time: 780.4589610099792 and batch: 350, loss is 3.8815232419967653 and perplexity is 48.49803307647189
At time: 781.5012702941895 and batch: 400, loss is 3.8326934576034546 and perplexity is 46.18677296343658
At time: 782.5496349334717 and batch: 450, loss is 3.879491238594055 and perplexity is 48.39958496555859
At time: 783.5897150039673 and batch: 500, loss is 3.9061656665802 and perplexity is 49.70798909587795
At time: 784.6588599681854 and batch: 550, loss is 3.869698557853699 and perplexity is 47.92793640304061
At time: 785.6990077495575 and batch: 600, loss is 3.850174331665039 and perplexity is 47.001256324674756
At time: 786.7397172451019 and batch: 650, loss is 3.8614786529541014 and perplexity is 47.53558806592514
At time: 787.7830228805542 and batch: 700, loss is 3.8973616266250612 and perplexity is 49.27227879360574
At time: 788.8249299526215 and batch: 750, loss is 3.8498154354095457 and perplexity is 46.984390776448436
At time: 789.8662519454956 and batch: 800, loss is 3.8045432233810423 and perplexity is 44.90473399515917
At time: 790.9040338993073 and batch: 850, loss is 3.821610674858093 and perplexity is 45.67772105928146
At time: 791.9444081783295 and batch: 900, loss is 3.792543878555298 and perplexity is 44.36912650370619
At time: 792.9857223033905 and batch: 950, loss is 3.8900860166549682 and perplexity is 48.915093855529896
At time: 794.0267531871796 and batch: 1000, loss is 3.8504486083984375 and perplexity is 47.014149443785584
At time: 795.0672075748444 and batch: 1050, loss is 3.8041602039337157 and perplexity is 44.887537902191234
At time: 796.1077966690063 and batch: 1100, loss is 3.8437806797027587 and perplexity is 46.7017052829373
At time: 797.14759349823 and batch: 1150, loss is 3.804144763946533 and perplexity is 44.88684484453178
At time: 798.1959800720215 and batch: 1200, loss is 3.8444654750823974 and perplexity is 46.73369734769516
At time: 799.2443554401398 and batch: 1250, loss is 3.8330145597457888 and perplexity is 46.20160601651775
At time: 800.2859528064728 and batch: 1300, loss is 3.829363055229187 and perplexity is 46.03320828312689
At time: 801.3272957801819 and batch: 1350, loss is 3.71432252407074 and perplexity is 41.03078030023065
At time: 802.369754076004 and batch: 1400, loss is 3.7349015951156614 and perplexity is 41.883903779597155
At time: 803.4114284515381 and batch: 1450, loss is 3.656012396812439 and perplexity is 38.706687813058025
At time: 804.456428527832 and batch: 1500, loss is 3.657277588844299 and perplexity is 38.75569019823589
At time: 805.4969923496246 and batch: 1550, loss is 3.6745987510681153 and perplexity is 39.43283130097838
At time: 806.5377452373505 and batch: 1600, loss is 3.764460048675537 and perplexity is 43.14040585071375
At time: 807.5783748626709 and batch: 1650, loss is 3.702269682884216 and perplexity is 40.53921117469364
At time: 808.6199948787689 and batch: 1700, loss is 3.719336199760437 and perplexity is 41.23701188308546
At time: 809.6613826751709 and batch: 1750, loss is 3.716973614692688 and perplexity is 41.139700932535504
At time: 810.7012333869934 and batch: 1800, loss is 3.673088231086731 and perplexity is 39.373312185099515
At time: 811.7504594326019 and batch: 1850, loss is 3.6986653137207033 and perplexity is 40.393355908041414
At time: 812.7921230792999 and batch: 1900, loss is 3.7682425451278685 and perplexity is 43.30389328319123
At time: 813.8335053920746 and batch: 1950, loss is 3.72444580078125 and perplexity is 41.448255787536944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486216842296511 and perplexity of 88.784922356283
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 817.1073412895203 and batch: 50, loss is 3.91969482421875 and perplexity is 50.385066129669866
At time: 818.1799747943878 and batch: 100, loss is 3.8991721296310424 and perplexity is 49.3615672065531
At time: 819.2252223491669 and batch: 150, loss is 3.87565411567688 and perplexity is 48.21422565955425
At time: 820.2702121734619 and batch: 200, loss is 3.863127522468567 and perplexity is 47.61403270265153
At time: 821.321170091629 and batch: 250, loss is 3.8607154512405395 and perplexity is 47.499322664326684
At time: 822.3656806945801 and batch: 300, loss is 3.8635594272613525 and perplexity is 47.63460187322157
At time: 823.4103133678436 and batch: 350, loss is 3.881476111412048 and perplexity is 48.49574738967867
At time: 824.4558525085449 and batch: 400, loss is 3.8329317951202393 and perplexity is 46.19778231613176
At time: 825.5000522136688 and batch: 450, loss is 3.8797485780715943 and perplexity is 48.41204169220177
At time: 826.5448853969574 and batch: 500, loss is 3.906657462120056 and perplexity is 49.7324412754541
At time: 827.5918862819672 and batch: 550, loss is 3.8701435327529907 and perplexity is 47.94926787734816
At time: 828.6388471126556 and batch: 600, loss is 3.85019437789917 and perplexity is 47.00219853230731
At time: 829.6838552951813 and batch: 650, loss is 3.8616016483306885 and perplexity is 47.54143508305126
At time: 830.7308113574982 and batch: 700, loss is 3.897429904937744 and perplexity is 49.27564313651833
At time: 831.7745311260223 and batch: 750, loss is 3.8496427726745606 and perplexity is 46.97627902335425
At time: 832.8191568851471 and batch: 800, loss is 3.8043505239486692 and perplexity is 44.89608171207923
At time: 833.8615643978119 and batch: 850, loss is 3.8217402410507204 and perplexity is 45.68363973110861
At time: 834.904294013977 and batch: 900, loss is 3.7913895320892332 and perplexity is 44.317938709233125
At time: 835.9492349624634 and batch: 950, loss is 3.8892489528656005 and perplexity is 48.87416593374032
At time: 837.018187046051 and batch: 1000, loss is 3.849180188179016 and perplexity is 46.95455355034057
At time: 838.0618007183075 and batch: 1050, loss is 3.8032820272445678 and perplexity is 44.84813601621338
At time: 839.1062529087067 and batch: 1100, loss is 3.8421127367019654 and perplexity is 46.62387442724501
At time: 840.1474175453186 and batch: 1150, loss is 3.80277747631073 and perplexity is 44.825513554877425
At time: 841.1924409866333 and batch: 1200, loss is 3.843411102294922 and perplexity is 46.68444857679806
At time: 842.2359302043915 and batch: 1250, loss is 3.831442856788635 and perplexity is 46.12904785059472
At time: 843.2797133922577 and batch: 1300, loss is 3.827452235221863 and perplexity is 45.945331093222855
At time: 844.3261427879333 and batch: 1350, loss is 3.711869215965271 and perplexity is 40.93024252983562
At time: 845.3681075572968 and batch: 1400, loss is 3.7320153379440306 and perplexity is 41.76319035073734
At time: 846.4107649326324 and batch: 1450, loss is 3.6525690937042237 and perplexity is 38.57363815121646
At time: 847.4552705287933 and batch: 1500, loss is 3.653496789932251 and perplexity is 38.6094393735925
At time: 848.5005006790161 and batch: 1550, loss is 3.6709624195098876 and perplexity is 39.2897008447026
At time: 849.5476405620575 and batch: 1600, loss is 3.7611032485961915 and perplexity is 42.99583491654608
At time: 850.5937924385071 and batch: 1650, loss is 3.698706097602844 and perplexity is 40.39500333950214
At time: 851.6393053531647 and batch: 1700, loss is 3.715610303878784 and perplexity is 41.08365294746645
At time: 852.6827855110168 and batch: 1750, loss is 3.7136525249481203 and perplexity is 41.003298920707216
At time: 853.7253589630127 and batch: 1800, loss is 3.669738283157349 and perplexity is 39.24163431961093
At time: 854.769483089447 and batch: 1850, loss is 3.6949202585220338 and perplexity is 40.242363474483305
At time: 855.8129994869232 and batch: 1900, loss is 3.764211573600769 and perplexity is 43.12968786677554
At time: 856.8580431938171 and batch: 1950, loss is 3.721070489883423 and perplexity is 41.30859087692571
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48606326081032 and perplexity of 88.77128768299961
Finished Training.
Improved accuracyfrom -10000000 to -88.77128768299961
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f31229a0b38>
ELAPSED
888.1725769042969


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.77128768299961}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.13481025420142356, 'wordvec_source': 'None', 'rnn_dropout': 0.7333439966881319, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.521543025970459 and batch: 50, loss is 7.191559629440308 and perplexity is 1328.1730488822554
At time: 2.556018590927124 and batch: 100, loss is 6.340835666656494 and perplexity is 567.2701621230979
At time: 3.59592342376709 and batch: 150, loss is 6.049268817901611 and perplexity is 423.8030395330692
At time: 4.636168956756592 and batch: 200, loss is 5.88476453781128 and perplexity is 359.5181051096278
At time: 5.70030403137207 and batch: 250, loss is 5.809579572677612 and perplexity is 333.4788925598452
At time: 6.744173765182495 and batch: 300, loss is 5.750919761657715 and perplexity is 314.4797737455932
At time: 7.78497576713562 and batch: 350, loss is 5.672446041107178 and perplexity is 290.744839148522
At time: 8.831263303756714 and batch: 400, loss is 5.61360333442688 and perplexity is 274.1302434278472
At time: 9.877240419387817 and batch: 450, loss is 5.54755576133728 and perplexity is 256.6095737079564
At time: 10.915533781051636 and batch: 500, loss is 5.51328932762146 and perplexity is 247.96542661134828
At time: 11.95449948310852 and batch: 550, loss is 5.449373216629028 and perplexity is 232.6123226706457
At time: 12.992504119873047 and batch: 600, loss is 5.468376092910766 and perplexity is 237.0748924013961
At time: 14.042906999588013 and batch: 650, loss is 5.541934032440185 and perplexity is 255.1710315876934
At time: 15.083053827285767 and batch: 700, loss is 5.470200309753418 and perplexity is 237.50776311806948
At time: 16.127237558364868 and batch: 750, loss is 5.410285186767578 and perplexity is 223.695373545175
At time: 17.170491695404053 and batch: 800, loss is 5.395464334487915 and perplexity is 220.4044647341193
At time: 18.212323904037476 and batch: 850, loss is 5.403304061889648 and perplexity is 222.1391665657543
At time: 19.25504446029663 and batch: 900, loss is 5.417319078445434 and perplexity is 225.27436930394703
At time: 20.295581817626953 and batch: 950, loss is 5.457094411849976 and perplexity is 234.41531951267595
At time: 21.344533681869507 and batch: 1000, loss is 5.418516149520874 and perplexity is 225.5442002066414
At time: 22.384734869003296 and batch: 1050, loss is 5.313681135177612 and perplexity is 203.09647961519778
At time: 23.42628788948059 and batch: 1100, loss is 5.408675498962403 and perplexity is 223.33558348283051
At time: 24.468608617782593 and batch: 1150, loss is 5.304363489151001 and perplexity is 201.2128874589163
At time: 25.510976552963257 and batch: 1200, loss is 5.379357204437256 and perplexity is 216.8828192949803
At time: 26.557453393936157 and batch: 1250, loss is 5.319161729812622 and perplexity is 204.21262486781245
At time: 27.59931206703186 and batch: 1300, loss is 5.344463033676147 and perplexity is 209.4453892777458
At time: 28.640840530395508 and batch: 1350, loss is 5.291800909042358 and perplexity is 198.700945711838
At time: 29.68816113471985 and batch: 1400, loss is 5.299845352172851 and perplexity is 200.3058307179303
At time: 30.73007583618164 and batch: 1450, loss is 5.244792547225952 and perplexity is 189.57648298257988
At time: 31.772127151489258 and batch: 1500, loss is 5.230240812301636 and perplexity is 186.83779094165766
At time: 32.81528306007385 and batch: 1550, loss is 5.213978681564331 and perplexity is 183.82398225240436
At time: 33.86184740066528 and batch: 1600, loss is 5.264250907897949 and perplexity is 193.30145394692033
At time: 34.90524911880493 and batch: 1650, loss is 5.233422060012817 and perplexity is 187.43311467050486
At time: 35.94830346107483 and batch: 1700, loss is 5.251983985900879 and perplexity is 190.94472455006994
At time: 36.999568700790405 and batch: 1750, loss is 5.263674516677856 and perplexity is 193.19006878983112
At time: 38.04325461387634 and batch: 1800, loss is 5.231016721725464 and perplexity is 186.98281640041066
At time: 39.08951187133789 and batch: 1850, loss is 5.211413269042969 and perplexity is 183.35300229385544
At time: 40.133158445358276 and batch: 1900, loss is 5.2550319385528566 and perplexity is 191.52760287116004
At time: 41.175469636917114 and batch: 1950, loss is 5.179732255935669 and perplexity is 177.63524384358243
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.89296136900436 and perplexity of 133.34788220230158
finished 1 epochs...
Completing Train Step...
At time: 44.45104765892029 and batch: 50, loss is 5.085207290649414 and perplexity is 161.61343671987433
At time: 45.51160669326782 and batch: 100, loss is 5.02585768699646 and perplexity is 152.30082654886374
At time: 46.54805040359497 and batch: 150, loss is 4.962299489974976 and perplexity is 142.92206618361627
At time: 47.58181285858154 and batch: 200, loss is 4.940202283859253 and perplexity is 139.79852568529813
At time: 48.61648893356323 and batch: 250, loss is 4.945015773773194 and perplexity is 140.4730666242633
At time: 49.650558948516846 and batch: 300, loss is 4.97057107925415 and perplexity is 144.10916162866184
At time: 50.68517875671387 and batch: 350, loss is 4.9548515033721925 and perplexity is 141.86153884863438
At time: 51.71960473060608 and batch: 400, loss is 4.9290894031524655 and perplexity is 138.25356174607043
At time: 52.75277638435364 and batch: 450, loss is 4.916273193359375 and perplexity is 136.49298117770013
At time: 53.78675556182861 and batch: 500, loss is 4.906313800811768 and perplexity is 135.14034091645112
At time: 54.81986212730408 and batch: 550, loss is 4.863621873855591 and perplexity is 129.49235878216774
At time: 55.852808237075806 and batch: 600, loss is 4.847594623565674 and perplexity is 127.43349536892316
At time: 56.88611459732056 and batch: 650, loss is 4.921966609954834 and perplexity is 137.2723089957094
At time: 57.920345306396484 and batch: 700, loss is 4.913676843643189 and perplexity is 136.13905731863116
At time: 58.96597456932068 and batch: 750, loss is 4.868787002563477 and perplexity is 130.16293379425792
At time: 60.00123047828674 and batch: 800, loss is 4.844003505706787 and perplexity is 126.97668738446012
At time: 61.0983202457428 and batch: 850, loss is 4.849601621627808 and perplexity is 127.68951097265307
At time: 62.134644746780396 and batch: 900, loss is 4.862679901123047 and perplexity is 129.3704379431903
At time: 63.169970750808716 and batch: 950, loss is 4.927196063995361 and perplexity is 137.9920485087549
At time: 64.20491528511047 and batch: 1000, loss is 4.889009456634522 and perplexity is 132.82194297449735
At time: 65.24058747291565 and batch: 1050, loss is 4.807379102706909 and perplexity is 122.41037171315587
At time: 66.276047706604 and batch: 1100, loss is 4.891955080032349 and perplexity is 133.2137631915587
At time: 67.31159710884094 and batch: 1150, loss is 4.817316246032715 and perplexity is 123.63284500801046
At time: 68.34765315055847 and batch: 1200, loss is 4.890705432891846 and perplexity is 133.04739696450068
At time: 69.38082957267761 and batch: 1250, loss is 4.849744367599487 and perplexity is 127.70773943695909
At time: 70.41466689109802 and batch: 1300, loss is 4.863664693832398 and perplexity is 129.49790376068458
At time: 71.45164322853088 and batch: 1350, loss is 4.778282985687256 and perplexity is 118.9000216386748
At time: 72.49253225326538 and batch: 1400, loss is 4.789264822006226 and perplexity is 120.21295824703162
At time: 73.53371453285217 and batch: 1450, loss is 4.721754674911499 and perplexity is 112.3652442641952
At time: 74.56858849525452 and batch: 1500, loss is 4.716160259246826 and perplexity is 111.73838148193808
At time: 75.60179233551025 and batch: 1550, loss is 4.719491634368897 and perplexity is 112.11124467493185
At time: 76.63498115539551 and batch: 1600, loss is 4.800295600891113 and perplexity is 121.54634141573933
At time: 77.66977667808533 and batch: 1650, loss is 4.753576211929321 and perplexity is 115.99837842679709
At time: 78.71688961982727 and batch: 1700, loss is 4.793086376190185 and perplexity is 120.67323751149083
At time: 79.75608777999878 and batch: 1750, loss is 4.7942297077178955 and perplexity is 120.8112859310056
At time: 80.79292392730713 and batch: 1800, loss is 4.746924724578857 and perplexity is 115.22937701678866
At time: 81.83398079872131 and batch: 1850, loss is 4.770607690811158 and perplexity is 117.99092217796765
At time: 82.86735773086548 and batch: 1900, loss is 4.833542890548706 and perplexity is 125.65535614130769
At time: 83.90591526031494 and batch: 1950, loss is 4.766165580749512 and perplexity is 117.46795591217906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.712154228742732 and perplexity of 111.29164952560528
finished 2 epochs...
Completing Train Step...
At time: 87.26172137260437 and batch: 50, loss is 4.712075185775757 and perplexity is 111.28285305108152
At time: 88.30305647850037 and batch: 100, loss is 4.6730530643463135 and perplexity is 107.02399528776135
At time: 89.35511350631714 and batch: 150, loss is 4.621118583679199 and perplexity is 101.6076252172646
At time: 90.39280605316162 and batch: 200, loss is 4.60790373802185 and perplexity is 100.27372915937704
At time: 91.43314290046692 and batch: 250, loss is 4.616450595855713 and perplexity is 101.13442736014706
At time: 92.4790666103363 and batch: 300, loss is 4.644935865402221 and perplexity is 104.05669193732173
At time: 93.51875519752502 and batch: 350, loss is 4.640554800033569 and perplexity is 103.60180992937798
At time: 94.5558500289917 and batch: 400, loss is 4.607402381896972 and perplexity is 100.22346891129303
At time: 95.59334063529968 and batch: 450, loss is 4.615492706298828 and perplexity is 101.0375981315945
At time: 96.63058400154114 and batch: 500, loss is 4.618990354537964 and perplexity is 101.39161085387089
At time: 97.66766452789307 and batch: 550, loss is 4.577165479660034 and perplexity is 97.23837904333628
At time: 98.7128541469574 and batch: 600, loss is 4.56425365447998 and perplexity is 95.99092487813994
At time: 99.7684576511383 and batch: 650, loss is 4.628210582733154 and perplexity is 102.3307877019691
At time: 100.82145476341248 and batch: 700, loss is 4.637540950775146 and perplexity is 103.29003974151728
At time: 101.87154006958008 and batch: 750, loss is 4.603089942932129 and perplexity is 99.79219191500586
At time: 102.91527795791626 and batch: 800, loss is 4.575588102340698 and perplexity is 97.08511833642342
At time: 103.95454740524292 and batch: 850, loss is 4.583944845199585 and perplexity is 97.89983314556164
At time: 104.99568104743958 and batch: 900, loss is 4.585550146102905 and perplexity is 98.05711804716564
At time: 106.03652000427246 and batch: 950, loss is 4.660754661560059 and perplexity is 105.71583173540424
At time: 107.07906460762024 and batch: 1000, loss is 4.622323999404907 and perplexity is 101.73017849553831
At time: 108.1221604347229 and batch: 1050, loss is 4.557810373306275 and perplexity is 95.37441665982915
At time: 109.15858912467957 and batch: 1100, loss is 4.635274877548218 and perplexity is 103.05624194935702
At time: 110.2032105922699 and batch: 1150, loss is 4.568663730621338 and perplexity is 96.41518699223083
At time: 111.24256157875061 and batch: 1200, loss is 4.63747088432312 and perplexity is 103.28280282843834
At time: 112.28064513206482 and batch: 1250, loss is 4.604270620346069 and perplexity is 99.91008388458532
At time: 113.31901741027832 and batch: 1300, loss is 4.616932487487793 and perplexity is 101.18317493898893
At time: 114.36935138702393 and batch: 1350, loss is 4.518330564498902 and perplexity is 91.68241227303221
At time: 115.41825270652771 and batch: 1400, loss is 4.534153966903687 and perplexity is 93.14467847910579
At time: 116.45767092704773 and batch: 1450, loss is 4.461899585723877 and perplexity is 86.6519556746393
At time: 117.49612426757812 and batch: 1500, loss is 4.467597360610962 and perplexity is 87.14708824904888
At time: 118.54127717018127 and batch: 1550, loss is 4.475880899429321 and perplexity is 87.87197269675167
At time: 119.57939219474792 and batch: 1600, loss is 4.56759108543396 and perplexity is 96.31182315218685
At time: 120.61778330802917 and batch: 1650, loss is 4.51063401222229 and perplexity is 90.97948233259048
At time: 121.65984892845154 and batch: 1700, loss is 4.54917649269104 and perplexity is 94.5545099143657
At time: 122.70309352874756 and batch: 1750, loss is 4.55105523109436 and perplexity is 94.73232008044194
At time: 123.7429735660553 and batch: 1800, loss is 4.499651165008545 and perplexity is 89.98573565156259
At time: 124.78326368331909 and batch: 1850, loss is 4.537797174453735 and perplexity is 93.48464277921249
At time: 125.82115912437439 and batch: 1900, loss is 4.611296606063843 and perplexity is 100.61452249698371
At time: 126.85888409614563 and batch: 1950, loss is 4.549768352508545 and perplexity is 94.61048949374559
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.646547965116279 and perplexity of 104.2245769880016
finished 3 epochs...
Completing Train Step...
At time: 130.15180587768555 and batch: 50, loss is 4.4977490520477295 and perplexity is 89.81473530004082
At time: 131.21949243545532 and batch: 100, loss is 4.467590265274048 and perplexity is 87.14646991329029
At time: 132.26041197776794 and batch: 150, loss is 4.412986650466919 and perplexity is 82.51554092649455
At time: 133.30231165885925 and batch: 200, loss is 4.410653877258301 and perplexity is 82.32327522665314
At time: 134.3427734375 and batch: 250, loss is 4.41802414894104 and perplexity is 82.93226157157146
At time: 135.3853805065155 and batch: 300, loss is 4.43687388420105 and perplexity is 84.5103391937908
At time: 136.4272539615631 and batch: 350, loss is 4.441308555603027 and perplexity is 84.88594701123999
At time: 137.467431306839 and batch: 400, loss is 4.403106679916382 and perplexity is 81.70430391007952
At time: 138.5112373828888 and batch: 450, loss is 4.421397762298584 and perplexity is 83.21251542524918
At time: 139.58052611351013 and batch: 500, loss is 4.435996198654175 and perplexity is 84.43619823150391
At time: 140.6274333000183 and batch: 550, loss is 4.396908531188965 and perplexity is 81.19945466436342
At time: 141.671532869339 and batch: 600, loss is 4.383916635513305 and perplexity is 80.1513430413404
At time: 142.71364665031433 and batch: 650, loss is 4.443144025802613 and perplexity is 85.0418957131583
At time: 143.7580018043518 and batch: 700, loss is 4.457827615737915 and perplexity is 86.29982892323792
At time: 144.80199909210205 and batch: 750, loss is 4.423473310470581 and perplexity is 83.38540636920227
At time: 145.84450316429138 and batch: 800, loss is 4.3970208263397215 and perplexity is 81.20857348135621
At time: 146.88723134994507 and batch: 850, loss is 4.399600820541382 and perplexity is 81.41836163981047
At time: 147.9310302734375 and batch: 900, loss is 4.400924377441406 and perplexity is 81.52619482008052
At time: 148.97415256500244 and batch: 950, loss is 4.483591966629028 and perplexity is 88.55217856933534
At time: 150.01749110221863 and batch: 1000, loss is 4.444109516143799 and perplexity is 85.12404249164487
At time: 151.06080985069275 and batch: 1050, loss is 4.390904941558838 and perplexity is 80.71342687589159
At time: 152.10370683670044 and batch: 1100, loss is 4.45474268913269 and perplexity is 86.03401051092351
At time: 153.14512825012207 and batch: 1150, loss is 4.3958581447601315 and perplexity is 81.11420863762787
At time: 154.19079279899597 and batch: 1200, loss is 4.46395697593689 and perplexity is 86.83041607857722
At time: 155.23425364494324 and batch: 1250, loss is 4.43616283416748 and perplexity is 84.45026947308948
At time: 156.27835512161255 and batch: 1300, loss is 4.448515539169311 and perplexity is 85.49992845590397
At time: 157.32082891464233 and batch: 1350, loss is 4.338376545906067 and perplexity is 76.58310920015896
At time: 158.36418461799622 and batch: 1400, loss is 4.359444856643677 and perplexity is 78.21370255139732
At time: 159.4109923839569 and batch: 1450, loss is 4.285243048667907 and perplexity is 72.62019481660765
At time: 160.45273566246033 and batch: 1500, loss is 4.294648103713989 and perplexity is 73.30641365098391
At time: 161.49584650993347 and batch: 1550, loss is 4.306389837265015 and perplexity is 74.17223117964085
At time: 162.53717398643494 and batch: 1600, loss is 4.405629892349243 and perplexity is 81.910721533766
At time: 163.58110761642456 and batch: 1650, loss is 4.350139188766479 and perplexity is 77.48924780749395
At time: 164.63178181648254 and batch: 1700, loss is 4.381375322341919 and perplexity is 79.94791197806983
At time: 165.67455959320068 and batch: 1750, loss is 4.38637110710144 and perplexity is 80.34831386634664
At time: 166.71687030792236 and batch: 1800, loss is 4.3315025901794435 and perplexity is 76.05848548396865
At time: 167.76017022132874 and batch: 1850, loss is 4.3740628051757815 and perplexity is 79.36542382226152
At time: 168.80240869522095 and batch: 1900, loss is 4.451748952865601 and perplexity is 85.77683252706137
At time: 169.84492421150208 and batch: 1950, loss is 4.387820291519165 and perplexity is 80.46483780273566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.618127725290698 and perplexity of 101.30418519830603
finished 4 epochs...
Completing Train Step...
At time: 173.14868807792664 and batch: 50, loss is 4.344777112007141 and perplexity is 77.07485650459057
At time: 174.2130045890808 and batch: 100, loss is 4.314910516738892 and perplexity is 74.80692917645878
At time: 175.2514955997467 and batch: 150, loss is 4.269086122512817 and perplexity is 71.45630346392026
At time: 176.2867021560669 and batch: 200, loss is 4.266567640304565 and perplexity is 71.27656845968531
At time: 177.32079482078552 and batch: 250, loss is 4.269022307395935 and perplexity is 71.45174361705786
At time: 178.3577492237091 and batch: 300, loss is 4.285002660751343 and perplexity is 72.60273989733508
At time: 179.3947732448578 and batch: 350, loss is 4.2891998195648195 and perplexity is 72.90810551268943
At time: 180.4529585838318 and batch: 400, loss is 4.2432234525680546 and perplexity is 69.63194574100031
At time: 181.49043583869934 and batch: 450, loss is 4.273348588943481 and perplexity is 71.76153361319291
At time: 182.52676820755005 and batch: 500, loss is 4.299257459640503 and perplexity is 73.64508894104634
At time: 183.56866765022278 and batch: 550, loss is 4.257515215873719 and perplexity is 70.63425434627104
At time: 184.61045718193054 and batch: 600, loss is 4.244867568016052 and perplexity is 69.74652286186482
At time: 185.64729928970337 and batch: 650, loss is 4.299994869232178 and perplexity is 73.69941556403583
At time: 186.68893671035767 and batch: 700, loss is 4.316520204544068 and perplexity is 74.92744194604289
At time: 187.72922325134277 and batch: 750, loss is 4.281385469436645 and perplexity is 72.34059629476184
At time: 188.76904225349426 and batch: 800, loss is 4.257130079269409 and perplexity is 70.60705574732837
At time: 189.8038613796234 and batch: 850, loss is 4.262672319412231 and perplexity is 70.9994634103627
At time: 190.84146738052368 and batch: 900, loss is 4.259854164123535 and perplexity is 70.79965757123745
At time: 191.9285192489624 and batch: 950, loss is 4.346074762344361 and perplexity is 77.17493763924013
At time: 192.96628165245056 and batch: 1000, loss is 4.30510293006897 and perplexity is 74.07683979468398
At time: 194.00243544578552 and batch: 1050, loss is 4.259677076339722 and perplexity is 70.78712092685949
At time: 195.0394251346588 and batch: 1100, loss is 4.320017566680908 and perplexity is 75.18994911826547
At time: 196.07625794410706 and batch: 1150, loss is 4.2648510026931765 and perplexity is 71.15431738187704
At time: 197.11075258255005 and batch: 1200, loss is 4.332495584487915 and perplexity is 76.13404863784703
At time: 198.145610332489 and batch: 1250, loss is 4.302945070266723 and perplexity is 73.91716470000638
At time: 199.18426036834717 and batch: 1300, loss is 4.317425365447998 and perplexity is 74.99529404102309
At time: 200.22109365463257 and batch: 1350, loss is 4.206561660766601 and perplexity is 67.12534287118523
At time: 201.25823211669922 and batch: 1400, loss is 4.221899619102478 and perplexity is 68.16284482475567
At time: 202.29664731025696 and batch: 1450, loss is 4.149993419647217 and perplexity is 63.43358288139629
At time: 203.3357310295105 and batch: 1500, loss is 4.165243334770203 and perplexity is 64.40835332860583
At time: 204.37199139595032 and batch: 1550, loss is 4.177212896347046 and perplexity is 65.18392544927464
At time: 205.40781021118164 and batch: 1600, loss is 4.279700264930725 and perplexity is 72.21879025879187
At time: 206.44863772392273 and batch: 1650, loss is 4.219937038421631 and perplexity is 68.02920092871186
At time: 207.48659014701843 and batch: 1700, loss is 4.252056217193603 and perplexity is 70.24971260641516
At time: 208.52478194236755 and batch: 1750, loss is 4.262010159492493 and perplexity is 70.95246597299631
At time: 209.56878185272217 and batch: 1800, loss is 4.204567494392395 and perplexity is 66.99161714955878
At time: 210.60748314857483 and batch: 1850, loss is 4.248261551856995 and perplexity is 69.98364359777435
At time: 211.6466670036316 and batch: 1900, loss is 4.319309959411621 and perplexity is 75.13676298335909
At time: 212.68581986427307 and batch: 1950, loss is 4.257687273025513 and perplexity is 70.6464085204693
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607878077307412 and perplexity of 100.27115609686092
finished 5 epochs...
Completing Train Step...
At time: 215.9839653968811 and batch: 50, loss is 4.2216225385665895 and perplexity is 68.14396084349656
At time: 217.02115178108215 and batch: 100, loss is 4.191726269721985 and perplexity is 66.13686253623173
At time: 218.08828783035278 and batch: 150, loss is 4.151388521194458 and perplexity is 63.522140930393334
At time: 219.13073134422302 and batch: 200, loss is 4.142685389518737 and perplexity is 62.971698136025616
At time: 220.17049312591553 and batch: 250, loss is 4.151277370452881 and perplexity is 63.51508078969957
At time: 221.208842754364 and batch: 300, loss is 4.16175977230072 and perplexity is 64.18437315719241
At time: 222.24725532531738 and batch: 350, loss is 4.164770164489746 and perplexity is 64.37788441905728
At time: 223.286554813385 and batch: 400, loss is 4.118639268875122 and perplexity is 61.47553365282818
At time: 224.32471299171448 and batch: 450, loss is 4.157388372421265 and perplexity is 63.90440995747997
At time: 225.36191296577454 and batch: 500, loss is 4.185503106117249 and perplexity is 65.72656003433724
At time: 226.3981227874756 and batch: 550, loss is 4.141437621116638 and perplexity is 62.893173041618866
At time: 227.43737030029297 and batch: 600, loss is 4.129976973533631 and perplexity is 62.176491213393234
At time: 228.476464509964 and batch: 650, loss is 4.185863609313965 and perplexity is 65.75025894084787
At time: 229.51486587524414 and batch: 700, loss is 4.201162881851197 and perplexity is 66.76392447226796
At time: 230.5544946193695 and batch: 750, loss is 4.1730879163742065 and perplexity is 64.91559686773553
At time: 231.59179496765137 and batch: 800, loss is 4.145018730163574 and perplexity is 63.11880411619918
At time: 232.62762355804443 and batch: 850, loss is 4.146736645698548 and perplexity is 63.22733008287093
At time: 233.66582226753235 and batch: 900, loss is 4.143074722290039 and perplexity is 62.99621985501912
At time: 234.70356130599976 and batch: 950, loss is 4.234529275894165 and perplexity is 69.02917738673268
At time: 235.7427852153778 and batch: 1000, loss is 4.195827612876892 and perplexity is 66.40866951051275
At time: 236.7822780609131 and batch: 1050, loss is 4.148902583122253 and perplexity is 63.36442493914239
At time: 237.82096815109253 and batch: 1100, loss is 4.205778155326843 and perplexity is 67.07277039799885
At time: 238.85870742797852 and batch: 1150, loss is 4.151812462806702 and perplexity is 63.54907631834502
At time: 239.8970968723297 and batch: 1200, loss is 4.2217314910888675 and perplexity is 68.15138570437979
At time: 240.93673586845398 and batch: 1250, loss is 4.195733647346497 and perplexity is 66.40242967782856
At time: 241.97445058822632 and batch: 1300, loss is 4.207731690406799 and perplexity is 67.20392747614652
At time: 243.0118715763092 and batch: 1350, loss is 4.099618186950684 and perplexity is 60.317253285838
At time: 244.0505232810974 and batch: 1400, loss is 4.115788359642028 and perplexity is 61.30052207592476
At time: 245.08829975128174 and batch: 1450, loss is 4.043024544715881 and perplexity is 56.99847680258826
At time: 246.1258466243744 and batch: 1500, loss is 4.059124674797058 and perplexity is 57.923586906660596
At time: 247.16332578659058 and batch: 1550, loss is 4.073867716789246 and perplexity is 58.78388288807655
At time: 248.20048904418945 and batch: 1600, loss is 4.174030523300171 and perplexity is 64.97681560701724
At time: 249.23905444145203 and batch: 1650, loss is 4.112749814987183 and perplexity is 61.11454040213566
At time: 250.27842688560486 and batch: 1700, loss is 4.143687973022461 and perplexity is 63.03486418110456
At time: 251.3177695274353 and batch: 1750, loss is 4.151843776702881 and perplexity is 63.551066318680306
At time: 252.3577582836151 and batch: 1800, loss is 4.09406813621521 and perplexity is 59.98341673171546
At time: 253.39517784118652 and batch: 1850, loss is 4.137590436935425 and perplexity is 62.651676260347806
At time: 254.43458032608032 and batch: 1900, loss is 4.2169934749603275 and perplexity is 67.82924709133732
At time: 255.48056960105896 and batch: 1950, loss is 4.151374430656433 and perplexity is 63.52124587555703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.609295228470203 and perplexity of 100.41335621805293
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 258.7678310871124 and batch: 50, loss is 4.142985835075378 and perplexity is 62.99062054535926
At time: 259.84551906585693 and batch: 100, loss is 4.14200192451477 and perplexity is 62.92867388856778
At time: 260.88862466812134 and batch: 150, loss is 4.112937588691711 and perplexity is 61.12601718327265
At time: 261.9325578212738 and batch: 200, loss is 4.095427002906799 and perplexity is 60.06498160410314
At time: 262.9770016670227 and batch: 250, loss is 4.099391674995422 and perplexity is 60.30359225411211
At time: 264.0206060409546 and batch: 300, loss is 4.106272964477539 and perplexity is 60.71998976201167
At time: 265.06466245651245 and batch: 350, loss is 4.09808009147644 and perplexity is 60.22455090237426
At time: 266.11385846138 and batch: 400, loss is 4.054530057907105 and perplexity is 57.658060678694326
At time: 267.1635251045227 and batch: 450, loss is 4.080522413253784 and perplexity is 59.176376299499694
At time: 268.20874214172363 and batch: 500, loss is 4.107465667724609 and perplexity is 60.79245389647685
At time: 269.2514009475708 and batch: 550, loss is 4.057776379585266 and perplexity is 57.84554143777376
At time: 270.33080410957336 and batch: 600, loss is 4.034113645553589 and perplexity is 56.4928253737393
At time: 271.37354731559753 and batch: 650, loss is 4.069954762458801 and perplexity is 58.55431367880024
At time: 272.41739797592163 and batch: 700, loss is 4.08557240486145 and perplexity is 59.475972345240955
At time: 273.4602692127228 and batch: 750, loss is 4.046448564529419 and perplexity is 57.193975220729904
At time: 274.5029923915863 and batch: 800, loss is 4.01676543712616 and perplexity is 55.52122816748499
At time: 275.5514543056488 and batch: 850, loss is 4.01355357170105 and perplexity is 55.34318752871694
At time: 276.5931749343872 and batch: 900, loss is 4.001083292961121 and perplexity is 54.65732787244652
At time: 277.63876247406006 and batch: 950, loss is 4.089442534446716 and perplexity is 59.70659805325722
At time: 278.6852009296417 and batch: 1000, loss is 4.044056134223938 and perplexity is 57.05730617189602
At time: 279.73008966445923 and batch: 1050, loss is 3.9951791334152222 and perplexity is 54.33557306885567
At time: 280.77208042144775 and batch: 1100, loss is 4.032901620864868 and perplexity is 56.424396151980716
At time: 281.8146188259125 and batch: 1150, loss is 3.983033185005188 and perplexity is 53.679607726339064
At time: 282.8584361076355 and batch: 1200, loss is 4.039887242317199 and perplexity is 56.819935559972116
At time: 283.9009861946106 and batch: 1250, loss is 4.006850304603577 and perplexity is 54.97344797665564
At time: 284.9446704387665 and batch: 1300, loss is 4.00915605545044 and perplexity is 55.1003492960727
At time: 285.9908742904663 and batch: 1350, loss is 3.895080542564392 and perplexity is 49.16001267672163
At time: 287.05213141441345 and batch: 1400, loss is 3.9057737016677856 and perplexity is 49.68850912626738
At time: 288.09317111968994 and batch: 1450, loss is 3.8198379373550413 and perplexity is 45.59681818107599
At time: 289.1356964111328 and batch: 1500, loss is 3.8350144529342653 and perplexity is 46.294096748652514
At time: 290.17843651771545 and batch: 1550, loss is 3.833264560699463 and perplexity is 46.2131579060147
At time: 291.22156858444214 and batch: 1600, loss is 3.928898959159851 and perplexity is 50.85095785345094
At time: 292.267516374588 and batch: 1650, loss is 3.8548373222351073 and perplexity is 47.22093452032822
At time: 293.3127830028534 and batch: 1700, loss is 3.8795840978622436 and perplexity is 48.404079524276604
At time: 294.3585307598114 and batch: 1750, loss is 3.871981282234192 and perplexity is 48.03746763922379
At time: 295.4010305404663 and batch: 1800, loss is 3.8138682079315185 and perplexity is 45.32542838177099
At time: 296.4437551498413 and batch: 1850, loss is 3.8415074491500856 and perplexity is 46.59566211557568
At time: 297.4942467212677 and batch: 1900, loss is 3.9101693058013915 and perplexity is 49.90740087066379
At time: 298.53828144073486 and batch: 1950, loss is 3.8428290462493897 and perplexity is 46.65728351783193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.519334518077762 and perplexity of 91.77450337881481
finished 7 epochs...
Completing Train Step...
At time: 301.83839988708496 and batch: 50, loss is 4.034152059555054 and perplexity is 56.49499553089792
At time: 302.90900111198425 and batch: 100, loss is 4.020526533126831 and perplexity is 55.73044202677733
At time: 303.9516797065735 and batch: 150, loss is 3.986008448600769 and perplexity is 53.83955653597608
At time: 304.9926869869232 and batch: 200, loss is 3.9719865322113037 and perplexity is 53.0898909328508
At time: 306.0332934856415 and batch: 250, loss is 3.977653293609619 and perplexity is 53.391592706052776
At time: 307.07556653022766 and batch: 300, loss is 3.984147129058838 and perplexity is 53.739437123281846
At time: 308.1171567440033 and batch: 350, loss is 3.984825568199158 and perplexity is 53.77590843118752
At time: 309.1574673652649 and batch: 400, loss is 3.943236565589905 and perplexity is 51.58529058106125
At time: 310.1967554092407 and batch: 450, loss is 3.9776051092147826 and perplexity is 53.38902012644848
At time: 311.2372577190399 and batch: 500, loss is 4.004246377944947 and perplexity is 54.830487360210455
At time: 312.2780466079712 and batch: 550, loss is 3.959822406768799 and perplexity is 52.448010710269756
At time: 313.3195369243622 and batch: 600, loss is 3.9384200811386108 and perplexity is 51.337428222829175
At time: 314.361230134964 and batch: 650, loss is 3.977617845535278 and perplexity is 53.38970011044999
At time: 315.40118288993835 and batch: 700, loss is 3.9977739524841307 and perplexity is 54.47674713133808
At time: 316.4382131099701 and batch: 750, loss is 3.9623780822753907 and perplexity is 52.58222223411359
At time: 317.4774980545044 and batch: 800, loss is 3.9319566917419433 and perplexity is 51.006684447917515
At time: 318.5233578681946 and batch: 850, loss is 3.932764101028442 and perplexity is 51.04788434896742
At time: 319.56830859184265 and batch: 900, loss is 3.920511493682861 and perplexity is 50.42623088133513
At time: 320.6105761528015 and batch: 950, loss is 4.011772089004516 and perplexity is 55.244682366436564
At time: 321.65293312072754 and batch: 1000, loss is 3.96901291847229 and perplexity is 52.93225659174655
At time: 322.72086119651794 and batch: 1050, loss is 3.9252460622787475 and perplexity is 50.66554340421411
At time: 323.7603340148926 and batch: 1100, loss is 3.962881269454956 and perplexity is 52.608687592170874
At time: 324.80450320243835 and batch: 1150, loss is 3.9189675855636597 and perplexity is 50.3484374824395
At time: 325.8469626903534 and batch: 1200, loss is 3.9767411851882937 and perplexity is 53.34291598731484
At time: 326.8937530517578 and batch: 1250, loss is 3.949442467689514 and perplexity is 51.90641926011803
At time: 327.93542432785034 and batch: 1300, loss is 3.954376606941223 and perplexity is 52.163165651138215
At time: 328.97541189193726 and batch: 1350, loss is 3.8432310104370115 and perplexity is 46.67604184473306
At time: 330.0152790546417 and batch: 1400, loss is 3.857780055999756 and perplexity is 47.36009781858193
At time: 331.05464696884155 and batch: 1450, loss is 3.7773912858963015 and perplexity is 43.701887172578225
At time: 332.09618401527405 and batch: 1500, loss is 3.795468873977661 and perplexity is 44.49909598302593
At time: 333.1423807144165 and batch: 1550, loss is 3.7974216747283935 and perplexity is 44.58607875343628
At time: 334.1843400001526 and batch: 1600, loss is 3.8985822772979737 and perplexity is 49.33245975636502
At time: 335.2316942214966 and batch: 1650, loss is 3.8253709363937376 and perplexity is 45.849804573560924
At time: 336.2792308330536 and batch: 1700, loss is 3.85570773601532 and perplexity is 47.262054165406006
At time: 337.32104778289795 and batch: 1750, loss is 3.8518934631347657 and perplexity is 47.082127157418746
At time: 338.36421155929565 and batch: 1800, loss is 3.795297341346741 and perplexity is 44.49146359063928
At time: 339.40421414375305 and batch: 1850, loss is 3.8287048864364626 and perplexity is 46.00292063029326
At time: 340.45012044906616 and batch: 1900, loss is 3.901944332122803 and perplexity is 49.49859731600817
At time: 341.4892702102661 and batch: 1950, loss is 3.8370783710479737 and perplexity is 46.38974264218354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5185021688771805 and perplexity of 91.69814672640136
finished 8 epochs...
Completing Train Step...
At time: 344.79609060287476 and batch: 50, loss is 3.9797678232192992 and perplexity is 53.5046102571061
At time: 345.83357095718384 and batch: 100, loss is 3.9638436603546143 and perplexity is 52.659342085154414
At time: 346.8742525577545 and batch: 150, loss is 3.928475332260132 and perplexity is 50.8294205820336
At time: 347.9162735939026 and batch: 200, loss is 3.915316824913025 and perplexity is 50.164962503454795
At time: 348.9905414581299 and batch: 250, loss is 3.9212266302108763 and perplexity is 50.46230541858072
At time: 350.0336947441101 and batch: 300, loss is 3.927835636138916 and perplexity is 50.79691559660862
At time: 351.07186555862427 and batch: 350, loss is 3.929582061767578 and perplexity is 50.88570614233822
At time: 352.11046528816223 and batch: 400, loss is 3.887809705734253 and perplexity is 48.80387452611025
At time: 353.1584384441376 and batch: 450, loss is 3.9259519815444945 and perplexity is 50.701321814261405
At time: 354.20204067230225 and batch: 500, loss is 3.9533305597305297 and perplexity is 52.10862904611259
At time: 355.2416958808899 and batch: 550, loss is 3.9090843343734742 and perplexity is 49.853282130629715
At time: 356.2887771129608 and batch: 600, loss is 3.888566646575928 and perplexity is 48.840830156819635
At time: 357.33466720581055 and batch: 650, loss is 3.9293177127838135 and perplexity is 50.87225633543107
At time: 358.3725337982178 and batch: 700, loss is 3.9498300313949586 and perplexity is 51.926540203124596
At time: 359.4097375869751 and batch: 750, loss is 3.9161412858963014 and perplexity is 50.20633861191623
At time: 360.4507668018341 and batch: 800, loss is 3.885188455581665 and perplexity is 48.67611488070933
At time: 361.4911599159241 and batch: 850, loss is 3.887799286842346 and perplexity is 48.80336604646582
At time: 362.5324823856354 and batch: 900, loss is 3.8749015855789186 and perplexity is 48.17795665206702
At time: 363.57366013526917 and batch: 950, loss is 3.9682068634033203 and perplexity is 52.8896074690887
At time: 364.6207618713379 and batch: 1000, loss is 3.9260866451263428 and perplexity is 50.70814989559798
At time: 365.65948510169983 and batch: 1050, loss is 3.884772205352783 and perplexity is 48.65585765307945
At time: 366.69992899894714 and batch: 1100, loss is 3.922519145011902 and perplexity is 50.527570864419474
At time: 367.73960423469543 and batch: 1150, loss is 3.880126271247864 and perplexity is 48.430330043473525
At time: 368.779577255249 and batch: 1200, loss is 3.9383270597457884 and perplexity is 51.33265296585595
At time: 369.8195102214813 and batch: 1250, loss is 3.9136034297943114 and perplexity is 50.07908369474646
At time: 370.8685166835785 and batch: 1300, loss is 3.919401478767395 and perplexity is 50.37028806734917
At time: 371.9083752632141 and batch: 1350, loss is 3.808852081298828 and perplexity is 45.098639569556745
At time: 372.94534945487976 and batch: 1400, loss is 3.825977072715759 and perplexity is 45.87760422981011
At time: 373.98879861831665 and batch: 1450, loss is 3.7469454526901247 and perplexity is 42.39139750796721
At time: 375.03552412986755 and batch: 1500, loss is 3.765619158744812 and perplexity is 43.19043932107575
At time: 376.0742049217224 and batch: 1550, loss is 3.769259991645813 and perplexity is 43.34797510026851
At time: 377.1188726425171 and batch: 1600, loss is 3.8728657817840575 and perplexity is 48.07997555407184
At time: 378.158301115036 and batch: 1650, loss is 3.7998678636550904 and perplexity is 44.69527823239321
At time: 379.1975431442261 and batch: 1700, loss is 3.832296357154846 and perplexity is 46.168435816258665
At time: 380.2361476421356 and batch: 1750, loss is 3.8297449111938477 and perplexity is 46.050789694852114
At time: 381.2759675979614 and batch: 1800, loss is 3.7743421936035157 and perplexity is 43.56883902633739
At time: 382.3155369758606 and batch: 1850, loss is 3.808576965332031 and perplexity is 45.086233920304686
At time: 383.35477590560913 and batch: 1900, loss is 3.8843595457077025 and perplexity is 48.635783486313365
At time: 384.39904046058655 and batch: 1950, loss is 3.8192535638809204 and perplexity is 45.57018039399279
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.521218091388081 and perplexity of 91.9475302872242
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 387.7024402618408 and batch: 50, loss is 3.953884234428406 and perplexity is 52.137488264128606
At time: 388.77039670944214 and batch: 100, loss is 3.9593584728240967 and perplexity is 52.423683941212445
At time: 389.81303668022156 and batch: 150, loss is 3.9355817890167235 and perplexity is 51.191924193896384
At time: 390.85283374786377 and batch: 200, loss is 3.921381320953369 and perplexity is 50.4701120738669
At time: 391.8917326927185 and batch: 250, loss is 3.931645073890686 and perplexity is 50.9907923307724
At time: 392.93098640441895 and batch: 300, loss is 3.9342604207992555 and perplexity is 51.12432548350496
At time: 393.971125125885 and batch: 350, loss is 3.938454818725586 and perplexity is 51.339211592181954
At time: 395.0136880874634 and batch: 400, loss is 3.899338459968567 and perplexity is 49.369778215538325
At time: 396.05578088760376 and batch: 450, loss is 3.939871196746826 and perplexity is 51.41197884391189
At time: 397.0977580547333 and batch: 500, loss is 3.9623220777511596 and perplexity is 52.57927747423506
At time: 398.13995933532715 and batch: 550, loss is 3.920820264816284 and perplexity is 50.441803449854696
At time: 399.18126702308655 and batch: 600, loss is 3.894633765220642 and perplexity is 49.13805400252354
At time: 400.21960520744324 and batch: 650, loss is 3.924661421775818 and perplexity is 50.63593093260569
At time: 401.28248357772827 and batch: 700, loss is 3.9412176179885865 and perplexity is 51.481247646337266
At time: 402.32942748069763 and batch: 750, loss is 3.9005548191070556 and perplexity is 49.42986613327139
At time: 403.37078404426575 and batch: 800, loss is 3.865543928146362 and perplexity is 47.72922664321134
At time: 404.4117822647095 and batch: 850, loss is 3.8683023023605347 and perplexity is 47.8610634552864
At time: 405.45351457595825 and batch: 900, loss is 3.8479232120513918 and perplexity is 46.89556987574611
At time: 406.4920835494995 and batch: 950, loss is 3.9419899702072145 and perplexity is 51.52102466113012
At time: 407.5299253463745 and batch: 1000, loss is 3.9002474880218507 and perplexity is 49.41467713301664
At time: 408.5693368911743 and batch: 1050, loss is 3.8587599706649782 and perplexity is 47.406529418768265
At time: 409.60956621170044 and batch: 1100, loss is 3.8889526319503784 and perplexity is 48.85968564167278
At time: 410.6512060165405 and batch: 1150, loss is 3.8535076427459716 and perplexity is 47.15818753817128
At time: 411.69141125679016 and batch: 1200, loss is 3.9048612260818483 and perplexity is 49.643190254114664
At time: 412.7334930896759 and batch: 1250, loss is 3.869778022766113 and perplexity is 47.93174514363769
At time: 413.7728543281555 and batch: 1300, loss is 3.869886293411255 and perplexity is 47.93693502555803
At time: 414.8102352619171 and batch: 1350, loss is 3.754787654876709 and perplexity is 42.72514637076243
At time: 415.85410165786743 and batch: 1400, loss is 3.7748992586135866 and perplexity is 43.59311646351595
At time: 416.891478061676 and batch: 1450, loss is 3.6868905210494995 and perplexity is 39.92052174209043
At time: 417.9300045967102 and batch: 1500, loss is 3.699819860458374 and perplexity is 40.44001885742322
At time: 418.97105836868286 and batch: 1550, loss is 3.707835659980774 and perplexity is 40.7654806167166
At time: 420.010484457016 and batch: 1600, loss is 3.8100014209747313 and perplexity is 45.15050302399704
At time: 421.0489852428436 and batch: 1650, loss is 3.729021916389465 and perplexity is 41.638362441042545
At time: 422.0877642631531 and batch: 1700, loss is 3.7554815196990967 and perplexity is 42.75480213421617
At time: 423.12857246398926 and batch: 1750, loss is 3.7477004528045654 and perplexity is 42.42341510306011
At time: 424.16883659362793 and batch: 1800, loss is 3.6940996265411377 and perplexity is 40.20935285066865
At time: 425.2096161842346 and batch: 1850, loss is 3.7212094402313234 and perplexity is 41.314331118794414
At time: 426.25183629989624 and batch: 1900, loss is 3.796668457984924 and perplexity is 44.552508416850486
At time: 427.2923936843872 and batch: 1950, loss is 3.7378168964385985 and perplexity is 42.00618613804998
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49181390806686 and perplexity of 89.28325069343258
finished 10 epochs...
Completing Train Step...
At time: 430.59629559516907 and batch: 50, loss is 3.9369520950317383 and perplexity is 51.262120880025826
At time: 431.66679096221924 and batch: 100, loss is 3.9309622383117677 and perplexity is 50.95598588846272
At time: 432.70909810066223 and batch: 150, loss is 3.8993504571914674 and perplexity is 49.370370519325114
At time: 433.752450466156 and batch: 200, loss is 3.8804367208480834 and perplexity is 48.44536755414783
At time: 434.7987039089203 and batch: 250, loss is 3.8885188198089597 and perplexity is 48.83849431367555
At time: 435.8418552875519 and batch: 300, loss is 3.8902007961273193 and perplexity is 48.92070862641669
At time: 436.8857936859131 and batch: 350, loss is 3.8957833862304687 and perplexity is 49.19457662535904
At time: 437.92942214012146 and batch: 400, loss is 3.855711703300476 and perplexity is 47.26224166782387
At time: 438.97434258461 and batch: 450, loss is 3.8984990072250367 and perplexity is 49.3283520098715
At time: 440.0185809135437 and batch: 500, loss is 3.921547698974609 and perplexity is 50.47850988983215
At time: 441.0614900588989 and batch: 550, loss is 3.8825146675109865 and perplexity is 48.546139106685935
At time: 442.10520339012146 and batch: 600, loss is 3.8568682622909547 and perplexity is 47.31693486019005
At time: 443.1473903656006 and batch: 650, loss is 3.888642439842224 and perplexity is 48.84453210315536
At time: 444.19177865982056 and batch: 700, loss is 3.907626576423645 and perplexity is 49.78066105711266
At time: 445.2359502315521 and batch: 750, loss is 3.8705212688446045 and perplexity is 47.96738346763262
At time: 446.28022861480713 and batch: 800, loss is 3.835984444618225 and perplexity is 46.33902342324294
At time: 447.325012922287 and batch: 850, loss is 3.8402141189575194 and perplexity is 46.535437492475516
At time: 448.36879873275757 and batch: 900, loss is 3.8216899394989015 and perplexity is 45.681341830931856
At time: 449.4132590293884 and batch: 950, loss is 3.9171944856643677 and perplexity is 50.259243771058095
At time: 450.45860409736633 and batch: 1000, loss is 3.8748622703552247 and perplexity is 48.176062562157654
At time: 451.504602432251 and batch: 1050, loss is 3.8347203397750853 and perplexity is 46.28048304768882
At time: 452.5486421585083 and batch: 1100, loss is 3.8661030435562136 and perplexity is 47.7559202510362
At time: 453.6283040046692 and batch: 1150, loss is 3.8324626684188843 and perplexity is 46.17611478570979
At time: 454.6713261604309 and batch: 1200, loss is 3.8855310010910036 and perplexity is 48.692791521364875
At time: 455.71374249458313 and batch: 1250, loss is 3.8538007068634035 and perplexity is 47.17200993610734
At time: 456.75292563438416 and batch: 1300, loss is 3.855485644340515 and perplexity is 47.25155882214901
At time: 457.7950670719147 and batch: 1350, loss is 3.741527967453003 and perplexity is 42.162363691608284
At time: 458.8425340652466 and batch: 1400, loss is 3.763705639839172 and perplexity is 43.107872620556726
At time: 459.886271238327 and batch: 1450, loss is 3.678452548980713 and perplexity is 39.58509066389817
At time: 460.92951345443726 and batch: 1500, loss is 3.6940541458129883 and perplexity is 40.20752414160842
At time: 461.97453117370605 and batch: 1550, loss is 3.7032658100128173 and perplexity is 40.57961350230331
At time: 463.0178813934326 and batch: 1600, loss is 3.807492241859436 and perplexity is 45.03735433928759
At time: 464.05955934524536 and batch: 1650, loss is 3.7282201766967775 and perplexity is 41.60499269184875
At time: 465.1077997684479 and batch: 1700, loss is 3.7567113208770753 and perplexity is 42.80741438491807
At time: 466.1510009765625 and batch: 1750, loss is 3.7507044506072997 and perplexity is 42.55104655513612
At time: 467.1961417198181 and batch: 1800, loss is 3.698740744590759 and perplexity is 40.39640292894031
At time: 468.24055099487305 and batch: 1850, loss is 3.7274448680877685 and perplexity is 41.572748484058124
At time: 469.2841305732727 and batch: 1900, loss is 3.80385196685791 and perplexity is 44.87370403093369
At time: 470.3270001411438 and batch: 1950, loss is 3.745446343421936 and perplexity is 42.32789578097773
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.491857058502907 and perplexity of 89.28710338775377
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 473.63182830810547 and batch: 50, loss is 3.928166880607605 and perplexity is 50.813744581026576
At time: 474.6700987815857 and batch: 100, loss is 3.9297291612625123 and perplexity is 50.893191954577226
At time: 475.70961022377014 and batch: 150, loss is 3.903583207130432 and perplexity is 49.57978584081209
At time: 476.74818992614746 and batch: 200, loss is 3.886746802330017 and perplexity is 48.75202828039324
At time: 477.78735733032227 and batch: 250, loss is 3.8968802309036255 and perplexity is 49.24856503771738
At time: 478.82506704330444 and batch: 300, loss is 3.8965918397903443 and perplexity is 49.23436423700944
At time: 479.9079978466034 and batch: 350, loss is 3.9041551208496093 and perplexity is 49.608149310483924
At time: 480.9463701248169 and batch: 400, loss is 3.8662928247451784 and perplexity is 47.764984286426056
At time: 481.9865138530731 and batch: 450, loss is 3.9100126028060913 and perplexity is 49.8995808441865
At time: 483.0258357524872 and batch: 500, loss is 3.931854920387268 and perplexity is 51.00149369268334
At time: 484.0669069290161 and batch: 550, loss is 3.893792462348938 and perplexity is 49.09673140143006
At time: 485.1049108505249 and batch: 600, loss is 3.8666484785079955 and perplexity is 47.78197510406344
At time: 486.14268040657043 and batch: 650, loss is 3.8948786878585815 and perplexity is 49.15009049827802
At time: 487.18218636512756 and batch: 700, loss is 3.9119006538391115 and perplexity is 49.99388279478079
At time: 488.22006464004517 and batch: 750, loss is 3.872530126571655 and perplexity is 48.06383996781325
At time: 489.2631735801697 and batch: 800, loss is 3.835246353149414 and perplexity is 46.304833604540114
At time: 490.3015670776367 and batch: 850, loss is 3.8428944301605226 and perplexity is 46.66033425324458
At time: 491.3468441963196 and batch: 900, loss is 3.8144087266921995 and perplexity is 45.34993424849096
At time: 492.38966155052185 and batch: 950, loss is 3.912618350982666 and perplexity is 50.02977614039293
At time: 493.42824149131775 and batch: 1000, loss is 3.871085867881775 and perplexity is 47.99447345292421
At time: 494.4669761657715 and batch: 1050, loss is 3.830126991271973 and perplexity is 46.06838814597114
At time: 495.5054974555969 and batch: 1100, loss is 3.858536887168884 and perplexity is 47.395954983982634
At time: 496.54335927963257 and batch: 1150, loss is 3.829074192047119 and perplexity is 46.01991290446657
At time: 497.5805232524872 and batch: 1200, loss is 3.8823692655563353 and perplexity is 48.53908091631883
At time: 498.61535382270813 and batch: 1250, loss is 3.8467720127105713 and perplexity is 46.84161478910655
At time: 499.65791273117065 and batch: 1300, loss is 3.844620318412781 and perplexity is 46.74093430931677
At time: 500.69757080078125 and batch: 1350, loss is 3.7270832538604735 and perplexity is 41.557717904538016
At time: 501.7362172603607 and batch: 1400, loss is 3.7510304737091062 and perplexity is 42.5649214409629
At time: 502.77427983283997 and batch: 1450, loss is 3.6611027240753176 and perplexity is 38.90421984610717
At time: 503.81425619125366 and batch: 1500, loss is 3.6728364992141724 and perplexity is 39.363401914912096
At time: 504.8520565032959 and batch: 1550, loss is 3.6811629486083985 and perplexity is 39.692527611655414
At time: 505.89022994041443 and batch: 1600, loss is 3.780798306465149 and perplexity is 43.851034330517734
At time: 506.92863845825195 and batch: 1650, loss is 3.7013059520721434 and perplexity is 40.50016110768626
At time: 507.9678657054901 and batch: 1700, loss is 3.7279541301727295 and perplexity is 41.593925300445825
At time: 509.0069365501404 and batch: 1750, loss is 3.720357885360718 and perplexity is 41.27916467410809
At time: 510.0471398830414 and batch: 1800, loss is 3.6679731464385985 and perplexity is 39.17242856674612
At time: 511.0857765674591 and batch: 1850, loss is 3.694998002052307 and perplexity is 40.245492179503074
At time: 512.1240439414978 and batch: 1900, loss is 3.773311233520508 and perplexity is 43.52394443867861
At time: 513.160658121109 and batch: 1950, loss is 3.7203765058517457 and perplexity is 41.2799333195798
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483919081577035 and perplexity of 88.58115004886763
finished 12 epochs...
Completing Train Step...
At time: 516.4423403739929 and batch: 50, loss is 3.925359787940979 and perplexity is 50.67130570434456
At time: 517.5088129043579 and batch: 100, loss is 3.9197645664215086 and perplexity is 50.38858021770658
At time: 518.5558557510376 and batch: 150, loss is 3.889409189224243 and perplexity is 48.88199797959374
At time: 519.5938558578491 and batch: 200, loss is 3.8706685447692872 and perplexity is 47.974448428623994
At time: 520.6312665939331 and batch: 250, loss is 3.879993176460266 and perplexity is 48.42388464791689
At time: 521.67125248909 and batch: 300, loss is 3.878560643196106 and perplexity is 48.354565485236535
At time: 522.7131578922272 and batch: 350, loss is 3.8856443977355957 and perplexity is 48.69831343361646
At time: 523.7538814544678 and batch: 400, loss is 3.8464130926132203 and perplexity is 46.824805408958994
At time: 524.7938272953033 and batch: 450, loss is 3.8914031982421875 and perplexity is 48.9795663681753
At time: 525.8331768512726 and batch: 500, loss is 3.913678765296936 and perplexity is 50.082856569801514
At time: 526.8713331222534 and batch: 550, loss is 3.8767565441131593 and perplexity is 48.2674077022664
At time: 527.9111220836639 and batch: 600, loss is 3.8508417224884033 and perplexity is 47.03263500158825
At time: 528.9497420787811 and batch: 650, loss is 3.8794588088989257 and perplexity is 48.39801540722406
At time: 529.9891502857208 and batch: 700, loss is 3.8977493619918824 and perplexity is 49.29138710294217
At time: 531.0302062034607 and batch: 750, loss is 3.86001266002655 and perplexity is 47.465952285265864
At time: 532.0959725379944 and batch: 800, loss is 3.8230246686935425 and perplexity is 45.742354760335154
At time: 533.1366991996765 and batch: 850, loss is 3.8303002166748046 and perplexity is 46.07636905229344
At time: 534.1764850616455 and batch: 900, loss is 3.8041528272628784 and perplexity is 44.88720678282071
At time: 535.2186002731323 and batch: 950, loss is 3.902453031539917 and perplexity is 49.52378362919907
At time: 536.2572114467621 and batch: 1000, loss is 3.860356650352478 and perplexity is 47.4822829222925
At time: 537.2986285686493 and batch: 1050, loss is 3.8200887393951417 and perplexity is 45.60825539027564
At time: 538.3385379314423 and batch: 1100, loss is 3.849235348701477 and perplexity is 46.95714365948157
At time: 539.3786234855652 and batch: 1150, loss is 3.820768780708313 and perplexity is 45.6392814364636
At time: 540.4157536029816 and batch: 1200, loss is 3.87424391746521 and perplexity is 48.14628196305148
At time: 541.4565148353577 and batch: 1250, loss is 3.840494327545166 and perplexity is 46.5484789487695
At time: 542.498245716095 and batch: 1300, loss is 3.8397570180892946 and perplexity is 46.51417096443899
At time: 543.5385432243347 and batch: 1350, loss is 3.7233444929122923 and perplexity is 41.40263362391864
At time: 544.5796196460724 and batch: 1400, loss is 3.748834409713745 and perplexity is 42.471548713289415
At time: 545.6209321022034 and batch: 1450, loss is 3.660394926071167 and perplexity is 38.876693259727695
At time: 546.6601576805115 and batch: 1500, loss is 3.6735692691802977 and perplexity is 39.39225680430688
At time: 547.6985290050507 and batch: 1550, loss is 3.6832746124267577 and perplexity is 39.77643344534987
At time: 548.7383096218109 and batch: 1600, loss is 3.784129886627197 and perplexity is 43.99737119772587
At time: 549.7770173549652 and batch: 1650, loss is 3.705322470664978 and perplexity is 40.66315787844057
At time: 550.8181104660034 and batch: 1700, loss is 3.732850112915039 and perplexity is 41.79806777212545
At time: 551.8593964576721 and batch: 1750, loss is 3.726392192840576 and perplexity is 41.529008906595536
At time: 552.8994035720825 and batch: 1800, loss is 3.67435676574707 and perplexity is 39.42329028907526
At time: 553.940019607544 and batch: 1850, loss is 3.7017538166046142 and perplexity is 40.51830375582681
At time: 554.9785695075989 and batch: 1900, loss is 3.779889349937439 and perplexity is 43.811193756034314
At time: 556.0182936191559 and batch: 1950, loss is 3.726667227745056 and perplexity is 41.54043240445162
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48325564362282 and perplexity of 88.52240144207975
finished 13 epochs...
Completing Train Step...
At time: 559.3191654682159 and batch: 50, loss is 3.9212078285217284 and perplexity is 50.461356650919804
At time: 560.4003343582153 and batch: 100, loss is 3.9139297676086424 and perplexity is 50.09542906037348
At time: 561.4459793567657 and batch: 150, loss is 3.882427430152893 and perplexity is 48.541904254485985
At time: 562.4941563606262 and batch: 200, loss is 3.862936177253723 and perplexity is 47.604922856924944
At time: 563.5380096435547 and batch: 250, loss is 3.871624541282654 and perplexity is 48.02033376366795
At time: 564.5834805965424 and batch: 300, loss is 3.869943389892578 and perplexity is 47.93967213401228
At time: 565.6337797641754 and batch: 350, loss is 3.877062702178955 and perplexity is 48.28218742079907
At time: 566.6816849708557 and batch: 400, loss is 3.837407259941101 and perplexity is 46.40500222250928
At time: 567.726363658905 and batch: 450, loss is 3.8827942752838136 and perplexity is 48.559714882378664
At time: 568.7716856002808 and batch: 500, loss is 3.9050326204299926 and perplexity is 49.65169954554947
At time: 569.8158183097839 and batch: 550, loss is 3.868507437705994 and perplexity is 47.87088245815018
At time: 570.8608827590942 and batch: 600, loss is 3.8428228902816772 and perplexity is 46.656996297985096
At time: 571.9067664146423 and batch: 650, loss is 3.8717636919021605 and perplexity is 48.02701628778797
At time: 572.9522602558136 and batch: 700, loss is 3.890391206741333 and perplexity is 48.93002453548007
At time: 573.998973608017 and batch: 750, loss is 3.8533273363113403 and perplexity is 47.149685380032544
At time: 575.0431425571442 and batch: 800, loss is 3.816589798927307 and perplexity is 45.4489536759527
At time: 576.0867862701416 and batch: 850, loss is 3.8238549757003786 and perplexity is 45.780350729978856
At time: 577.1314382553101 and batch: 900, loss is 3.7983287525177003 and perplexity is 44.62654014322554
At time: 578.1834425926208 and batch: 950, loss is 3.8971285009384156 and perplexity is 49.26079349859005
At time: 579.2336857318878 and batch: 1000, loss is 3.854839677810669 and perplexity is 47.221045752938586
At time: 580.2827537059784 and batch: 1050, loss is 3.8149158573150634 and perplexity is 45.372938421460496
At time: 581.3372654914856 and batch: 1100, loss is 3.8443285846710205 and perplexity is 46.72730039049111
At time: 582.3838503360748 and batch: 1150, loss is 3.8163702917099 and perplexity is 45.4389783974601
At time: 583.4263327121735 and batch: 1200, loss is 3.8701290130615233 and perplexity is 47.948571673826834
At time: 584.4985837936401 and batch: 1250, loss is 3.837277889251709 and perplexity is 46.39899916369882
At time: 585.5434546470642 and batch: 1300, loss is 3.8370568799972533 and perplexity is 46.38874568858434
At time: 586.5888125896454 and batch: 1350, loss is 3.7211870193481444 and perplexity is 41.313404825386975
At time: 587.63272356987 and batch: 1400, loss is 3.747337231636047 and perplexity is 42.40800881876751
At time: 588.6790294647217 and batch: 1450, loss is 3.659546384811401 and perplexity is 38.84371877353811
At time: 589.7221124172211 and batch: 1500, loss is 3.673444890975952 and perplexity is 39.38735757082569
At time: 590.7678337097168 and batch: 1550, loss is 3.6837393760681154 and perplexity is 39.79492438202284
At time: 591.8136525154114 and batch: 1600, loss is 3.7852182149887086 and perplexity is 44.04528085062041
At time: 592.8602957725525 and batch: 1650, loss is 3.7067533826828 and perplexity is 40.72138492868938
At time: 593.9044947624207 and batch: 1700, loss is 3.7347075939178467 and perplexity is 41.87577904022482
At time: 594.9512887001038 and batch: 1750, loss is 3.7287333822250366 and perplexity is 41.62635008399849
At time: 596.001268863678 and batch: 1800, loss is 3.6768648624420166 and perplexity is 39.522291813954055
At time: 597.0493850708008 and batch: 1850, loss is 3.704547290802002 and perplexity is 40.63164883145537
At time: 598.092449426651 and batch: 1900, loss is 3.782479000091553 and perplexity is 43.92479645282949
At time: 599.1362822055817 and batch: 1950, loss is 3.729079594612122 and perplexity is 41.64076413704459
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483236339480378 and perplexity of 88.52069260952685
finished 14 epochs...
Completing Train Step...
At time: 602.4854469299316 and batch: 50, loss is 3.9167929792404177 and perplexity is 50.23906841236024
At time: 603.5303392410278 and batch: 100, loss is 3.9087893104553224 and perplexity is 49.838576389382176
At time: 604.5723788738251 and batch: 150, loss is 3.876766896247864 and perplexity is 48.26790737555911
At time: 605.6192328929901 and batch: 200, loss is 3.8569187784194945 and perplexity is 47.319325188928126
At time: 606.6604914665222 and batch: 250, loss is 3.8653308391571044 and perplexity is 47.71905715408945
At time: 607.7017226219177 and batch: 300, loss is 3.8635867643356323 and perplexity is 47.635904081670475
At time: 608.7470364570618 and batch: 350, loss is 3.8707943773269653 and perplexity is 47.980485555998584
At time: 609.7913372516632 and batch: 400, loss is 3.8309890604019166 and perplexity is 46.10811940434315
At time: 610.8550250530243 and batch: 450, loss is 3.876642289161682 and perplexity is 48.2618932269755
At time: 611.8992419242859 and batch: 500, loss is 3.898874878883362 and perplexity is 49.34689662432306
At time: 612.9405696392059 and batch: 550, loss is 3.8625643968582155 and perplexity is 47.58722756946139
At time: 613.9820241928101 and batch: 600, loss is 3.8370137071609496 and perplexity is 46.38674299809162
At time: 615.0246469974518 and batch: 650, loss is 3.8661538219451903 and perplexity is 47.7583452812997
At time: 616.0655312538147 and batch: 700, loss is 3.885017657279968 and perplexity is 48.667801792905344
At time: 617.1041007041931 and batch: 750, loss is 3.848390669822693 and perplexity is 46.91749669885678
At time: 618.1431896686554 and batch: 800, loss is 3.811789927482605 and perplexity is 45.23132724827004
At time: 619.1867637634277 and batch: 850, loss is 3.8191457843780516 and perplexity is 45.56526912727598
At time: 620.227573633194 and batch: 900, loss is 3.7939062404632566 and perplexity is 44.42961450546335
At time: 621.2673449516296 and batch: 950, loss is 3.8930673933029176 and perplexity is 49.06114578380404
At time: 622.3085248470306 and batch: 1000, loss is 3.850713782310486 and perplexity is 47.0266180228131
At time: 623.3500785827637 and batch: 1050, loss is 3.8110308837890625 and perplexity is 45.197007721229724
At time: 624.3894879817963 and batch: 1100, loss is 3.8405942869186402 and perplexity is 46.553132138122464
At time: 625.4286661148071 and batch: 1150, loss is 3.8129991483688355 and perplexity is 45.28605499618985
At time: 626.4698140621185 and batch: 1200, loss is 3.8669921922683717 and perplexity is 47.79840124918899
At time: 627.5116662979126 and batch: 1250, loss is 3.834709086418152 and perplexity is 46.27996223982445
At time: 628.5531055927277 and batch: 1300, loss is 3.834752230644226 and perplexity is 46.28195899605196
At time: 629.593781709671 and batch: 1350, loss is 3.719139566421509 and perplexity is 41.22890410890695
At time: 630.6332678794861 and batch: 1400, loss is 3.7458064794540404 and perplexity is 42.34314232666206
At time: 631.6729755401611 and batch: 1450, loss is 3.65836416721344 and perplexity is 38.79782417967738
At time: 632.7113609313965 and batch: 1500, loss is 3.6727305173873903 and perplexity is 39.35923033072876
At time: 633.7520320415497 and batch: 1550, loss is 3.6833580255508425 and perplexity is 39.77975146030957
At time: 634.7929723262787 and batch: 1600, loss is 3.785234179496765 and perplexity is 44.04598401747423
At time: 635.8355906009674 and batch: 1650, loss is 3.707003126144409 and perplexity is 40.73155609836167
At time: 636.8772659301758 and batch: 1700, loss is 3.735235710144043 and perplexity is 41.89790015936742
At time: 637.92129778862 and batch: 1750, loss is 3.729561839103699 and perplexity is 41.660850008936016
At time: 638.9609446525574 and batch: 1800, loss is 3.6778453683853147 and perplexity is 39.56106266038691
At time: 640.0018830299377 and batch: 1850, loss is 3.70576886177063 and perplexity is 40.681313602420595
At time: 641.0424699783325 and batch: 1900, loss is 3.7835594177246095 and perplexity is 43.972279223437965
At time: 642.0842115879059 and batch: 1950, loss is 3.7300756692886354 and perplexity is 41.68226211182201
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483442723473837 and perplexity of 88.53896374894191
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 645.3640656471252 and batch: 50, loss is 3.914642300605774 and perplexity is 50.131136426412
At time: 646.4319040775299 and batch: 100, loss is 3.9089021492004394 and perplexity is 49.844200429099196
At time: 647.4719393253326 and batch: 150, loss is 3.878530445098877 and perplexity is 48.35310529141419
At time: 648.5117652416229 and batch: 200, loss is 3.8588304471969606 and perplexity is 47.409870584290516
At time: 649.5527501106262 and batch: 250, loss is 3.8678725576400756 and perplexity is 47.84049983482107
At time: 650.5934896469116 and batch: 300, loss is 3.865577235221863 and perplexity is 47.730816390641515
At time: 651.6334290504456 and batch: 350, loss is 3.8732372760772704 and perplexity is 48.097840308729744
At time: 652.6783411502838 and batch: 400, loss is 3.8340574312210083 and perplexity is 46.249813486270135
At time: 653.7201135158539 and batch: 450, loss is 3.8801749897003175 and perplexity is 48.43268955168038
At time: 654.7608752250671 and batch: 500, loss is 3.9021767139434815 and perplexity is 49.5101012267716
At time: 655.8070993423462 and batch: 550, loss is 3.8665344858169557 and perplexity is 47.77652861857379
At time: 656.8452389240265 and batch: 600, loss is 3.840410599708557 and perplexity is 46.544581708485694
At time: 657.8858506679535 and batch: 650, loss is 3.868602738380432 and perplexity is 47.8754448029282
At time: 658.9304711818695 and batch: 700, loss is 3.8867001914978028 and perplexity is 48.74975596074072
At time: 659.9714922904968 and batch: 750, loss is 3.8495048236846925 and perplexity is 46.96979914007217
At time: 661.0129816532135 and batch: 800, loss is 3.812699761390686 and perplexity is 45.27249897038228
At time: 662.0560314655304 and batch: 850, loss is 3.821148648262024 and perplexity is 45.65662161193251
At time: 663.1435809135437 and batch: 900, loss is 3.792118802070618 and perplexity is 44.35027023934487
At time: 664.1850218772888 and batch: 950, loss is 3.8925775718688964 and perplexity is 49.03712046755927
At time: 665.2240791320801 and batch: 1000, loss is 3.849720973968506 and perplexity is 46.979952772802726
At time: 666.2626476287842 and batch: 1050, loss is 3.80968918800354 and perplexity is 45.13640774890639
At time: 667.3017604351044 and batch: 1100, loss is 3.836068468093872 and perplexity is 46.3429171526291
At time: 668.3393402099609 and batch: 1150, loss is 3.808796138763428 and perplexity is 45.09611670788443
At time: 669.3835716247559 and batch: 1200, loss is 3.8630766010284425 and perplexity is 47.611608189266555
At time: 670.4272954463959 and batch: 1250, loss is 3.830557065010071 and perplexity is 46.08820521096339
At time: 671.4682500362396 and batch: 1300, loss is 3.8284524488449097 and perplexity is 45.991309229443644
At time: 672.5083734989166 and batch: 1350, loss is 3.7116897916793823 and perplexity is 40.92289930909422
At time: 673.548885345459 and batch: 1400, loss is 3.737986612319946 and perplexity is 42.01331585994886
At time: 674.5940842628479 and batch: 1450, loss is 3.649870295524597 and perplexity is 38.469676036276425
At time: 675.6396284103394 and batch: 1500, loss is 3.663599481582642 and perplexity is 39.00147561058184
At time: 676.6861963272095 and batch: 1550, loss is 3.674307017326355 and perplexity is 39.42132909142762
At time: 677.7279653549194 and batch: 1600, loss is 3.7738680982589723 and perplexity is 43.54818813821961
At time: 678.7698616981506 and batch: 1650, loss is 3.6955728006362913 and perplexity is 40.268631881116356
At time: 679.8182694911957 and batch: 1700, loss is 3.7234844827651976 and perplexity is 41.40842997821547
At time: 680.8585526943207 and batch: 1750, loss is 3.717133140563965 and perplexity is 41.14626430267058
At time: 681.9004807472229 and batch: 1800, loss is 3.6657927656173706 and perplexity is 39.08711080118861
At time: 682.9408085346222 and batch: 1850, loss is 3.6934229278564454 and perplexity is 40.18215243876173
At time: 683.9802575111389 and batch: 1900, loss is 3.7698746013641355 and perplexity is 43.37462537595504
At time: 685.0186302661896 and batch: 1950, loss is 3.719448990821838 and perplexity is 41.24166331173963
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482616619731105 and perplexity of 88.46585158288619
finished 16 epochs...
Completing Train Step...
At time: 688.2962837219238 and batch: 50, loss is 3.913199615478516 and perplexity is 50.058865126377015
At time: 689.359680891037 and batch: 100, loss is 3.9062537002563475 and perplexity is 49.71236526551428
At time: 690.4038627147675 and batch: 150, loss is 3.87516713142395 and perplexity is 48.19075180705302
At time: 691.4462614059448 and batch: 200, loss is 3.855379009246826 and perplexity is 47.24652041638727
At time: 692.4862785339355 and batch: 250, loss is 3.8640587186813353 and perplexity is 47.658391359680195
At time: 693.5282564163208 and batch: 300, loss is 3.861735076904297 and perplexity is 47.547778892134986
At time: 694.5667724609375 and batch: 350, loss is 3.8693193435668944 and perplexity is 47.90976489048587
At time: 695.6048691272736 and batch: 400, loss is 3.8300663900375365 and perplexity is 46.06559642937259
At time: 696.6420600414276 and batch: 450, loss is 3.8763972330093384 and perplexity is 48.25006780212221
At time: 697.6834585666656 and batch: 500, loss is 3.8983971643447877 and perplexity is 49.32332852423234
At time: 698.7296454906464 and batch: 550, loss is 3.86287428855896 and perplexity is 47.60197674155158
At time: 699.7705245018005 and batch: 600, loss is 3.837014956474304 and perplexity is 46.386800949705325
At time: 700.8104004859924 and batch: 650, loss is 3.865325541496277 and perplexity is 47.71880435537926
At time: 701.8520836830139 and batch: 700, loss is 3.8838858604431152 and perplexity is 48.61275088787615
At time: 702.8938634395599 and batch: 750, loss is 3.8469582986831665 and perplexity is 46.85034153768565
At time: 703.9325375556946 and batch: 800, loss is 3.8098542499542236 and perplexity is 45.14385866733093
At time: 704.9731106758118 and batch: 850, loss is 3.818234014511108 and perplexity is 45.523743021909155
At time: 706.0135073661804 and batch: 900, loss is 3.7898066949844362 and perplexity is 44.24784611864662
At time: 707.0537073612213 and batch: 950, loss is 3.8902355575561525 and perplexity is 48.92240920970526
At time: 708.096611738205 and batch: 1000, loss is 3.847381491661072 and perplexity is 46.87017246909636
At time: 709.1353554725647 and batch: 1050, loss is 3.8074866676330568 and perplexity is 45.03710329157868
At time: 710.1734764575958 and batch: 1100, loss is 3.8343383502960204 and perplexity is 46.26280776617927
At time: 711.2135193347931 and batch: 1150, loss is 3.8073953914642336 and perplexity is 45.032992664939314
At time: 712.2542543411255 and batch: 1200, loss is 3.8618290519714353 and perplexity is 47.55224740780989
At time: 713.29496717453 and batch: 1250, loss is 3.8296243381500243 and perplexity is 46.04523754569462
At time: 714.3362729549408 and batch: 1300, loss is 3.827857270240784 and perplexity is 45.96394433052352
At time: 715.3756701946259 and batch: 1350, loss is 3.711336212158203 and perplexity is 40.908432367709075
At time: 716.4138870239258 and batch: 1400, loss is 3.7380973052978517 and perplexity is 42.0179666963958
At time: 717.4556503295898 and batch: 1450, loss is 3.650231065750122 and perplexity is 38.48355725379033
At time: 718.4942216873169 and batch: 1500, loss is 3.6643972492218015 and perplexity is 39.03260213992152
At time: 719.5342772006989 and batch: 1550, loss is 3.6753336572647095 and perplexity is 39.46182138424187
At time: 720.5759470462799 and batch: 1600, loss is 3.7751694917678833 and perplexity is 43.60489836074144
At time: 721.6169748306274 and batch: 1650, loss is 3.6969605827331544 and perplexity is 40.324554762917884
At time: 722.6566116809845 and batch: 1700, loss is 3.7250683736801147 and perplexity is 41.474068382572796
At time: 723.6954298019409 and batch: 1750, loss is 3.719087815284729 and perplexity is 41.22677052145939
At time: 724.7373728752136 and batch: 1800, loss is 3.6677830266952514 and perplexity is 39.164981822589695
At time: 725.7773394584656 and batch: 1850, loss is 3.6952939224243164 and perplexity is 40.25740340282042
At time: 726.8184661865234 and batch: 1900, loss is 3.77154673576355 and perplexity is 43.44721425137228
At time: 727.8594274520874 and batch: 1950, loss is 3.72097270488739 and perplexity is 41.30455171401867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482426417151163 and perplexity of 88.44902674979241
finished 17 epochs...
Completing Train Step...
At time: 731.1690499782562 and batch: 50, loss is 3.911962418556213 and perplexity is 49.99697074817073
At time: 732.2132556438446 and batch: 100, loss is 3.904347276687622 and perplexity is 49.61768272190795
At time: 733.2576880455017 and batch: 150, loss is 3.8728476333618165 and perplexity is 48.079102986292035
At time: 734.3015773296356 and batch: 200, loss is 3.8528760385513308 and perplexity is 47.128411633393554
At time: 735.3454990386963 and batch: 250, loss is 3.861463437080383 and perplexity is 47.53486477592276
At time: 736.3880910873413 and batch: 300, loss is 3.8590063190460206 and perplexity is 47.41820937915202
At time: 737.4299402236938 and batch: 350, loss is 3.8665672588348388 and perplexity is 47.778094425258566
At time: 738.4739639759064 and batch: 400, loss is 3.827218437194824 and perplexity is 45.934590421084515
At time: 739.5244681835175 and batch: 450, loss is 3.873712668418884 and perplexity is 48.12071108952696
At time: 740.5676469802856 and batch: 500, loss is 3.895767102241516 and perplexity is 49.193775547939126
At time: 741.6357851028442 and batch: 550, loss is 3.8603172636032106 and perplexity is 47.48041278634992
At time: 742.6788079738617 and batch: 600, loss is 3.834615969657898 and perplexity is 46.27565300031033
At time: 743.7214286327362 and batch: 650, loss is 3.8630286169052126 and perplexity is 47.60932364280344
At time: 744.7642645835876 and batch: 700, loss is 3.8818074321746825 and perplexity is 48.51181769975502
At time: 745.8075497150421 and batch: 750, loss is 3.845060095787048 and perplexity is 46.76149443528586
At time: 746.8543021678925 and batch: 800, loss is 3.8079066038131715 and perplexity is 45.05601997231972
At time: 747.8992989063263 and batch: 850, loss is 3.816202392578125 and perplexity is 45.431349872867685
At time: 748.947761297226 and batch: 900, loss is 3.7881222629547118 and perplexity is 44.17337636662365
At time: 749.992856502533 and batch: 950, loss is 3.8885964345932007 and perplexity is 48.842285049981044
At time: 751.0381627082825 and batch: 1000, loss is 3.845735297203064 and perplexity is 46.79307852415441
At time: 752.0807027816772 and batch: 1050, loss is 3.8060001039505007 and perplexity is 44.97020250791574
At time: 753.1234283447266 and batch: 1100, loss is 3.833088550567627 and perplexity is 46.2050246377889
At time: 754.1733253002167 and batch: 1150, loss is 3.806394991874695 and perplexity is 44.98796420454363
At time: 755.2176783084869 and batch: 1200, loss is 3.8609189128875734 and perplexity is 47.50898793797187
At time: 756.2673842906952 and batch: 1250, loss is 3.828947834968567 and perplexity is 46.014098330080806
At time: 757.3117454051971 and batch: 1300, loss is 3.8274401807785035 and perplexity is 45.94477725116969
At time: 758.3589894771576 and batch: 1350, loss is 3.7111061239242553 and perplexity is 40.899020901527344
At time: 759.4061241149902 and batch: 1400, loss is 3.738209981918335 and perplexity is 42.022701405623245
At time: 760.4505577087402 and batch: 1450, loss is 3.65053653717041 and perplexity is 38.49531467636924
At time: 761.4958844184875 and batch: 1500, loss is 3.664930057525635 and perplexity is 39.05340457582507
At time: 762.5385751724243 and batch: 1550, loss is 3.6760521745681762 and perplexity is 39.490185574593255
At time: 763.5827627182007 and batch: 1600, loss is 3.776026349067688 and perplexity is 43.64227754823692
At time: 764.6260530948639 and batch: 1650, loss is 3.6978688716888426 and perplexity is 40.36119774934285
At time: 765.6684031486511 and batch: 1700, loss is 3.7260921096801756 and perplexity is 41.51654862000914
At time: 766.7113389968872 and batch: 1750, loss is 3.7203148078918455 and perplexity is 41.27738651047643
At time: 767.7562997341156 and batch: 1800, loss is 3.669045033454895 and perplexity is 39.21443949578596
At time: 768.7991635799408 and batch: 1850, loss is 3.6965187072753904 and perplexity is 40.3067402680068
At time: 769.842351436615 and batch: 1900, loss is 3.7726102447509766 and perplexity is 43.493445333435425
At time: 770.8877191543579 and batch: 1950, loss is 3.721928071975708 and perplexity is 41.34403157920305
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482380143986192 and perplexity of 88.44493402807842
finished 18 epochs...
Completing Train Step...
At time: 774.1671705245972 and batch: 50, loss is 3.910767731666565 and perplexity is 49.93727568824861
At time: 775.2303297519684 and batch: 100, loss is 3.9027122974395754 and perplexity is 49.53662512212487
At time: 776.26757645607 and batch: 150, loss is 3.870940294265747 and perplexity is 47.987487232391345
At time: 777.3053970336914 and batch: 200, loss is 3.8508392477035525 and perplexity is 47.03251860607968
At time: 778.3432786464691 and batch: 250, loss is 3.8593502902984618 and perplexity is 47.43452268551405
At time: 779.3816525936127 and batch: 300, loss is 3.8568105363845824 and perplexity is 47.31420352607361
At time: 780.419430732727 and batch: 350, loss is 3.8643722629547117 and perplexity is 47.67333671826271
At time: 781.4585149288177 and batch: 400, loss is 3.824948687553406 and perplexity is 45.8304486335495
At time: 782.4971418380737 and batch: 450, loss is 3.871579480171204 and perplexity is 48.01816996280835
At time: 783.5374987125397 and batch: 500, loss is 3.893669743537903 and perplexity is 49.09070667860773
At time: 784.5799043178558 and batch: 550, loss is 3.8582912254333497 and perplexity is 47.38431304147241
At time: 785.6251690387726 and batch: 600, loss is 3.832684111595154 and perplexity is 46.18634130349024
At time: 786.6674799919128 and batch: 650, loss is 3.861184549331665 and perplexity is 47.52160973292026
At time: 787.7068009376526 and batch: 700, loss is 3.880101318359375 and perplexity is 48.429121581925834
At time: 788.7481422424316 and batch: 750, loss is 3.8434812307357786 and perplexity is 46.6877225991887
At time: 789.788259267807 and batch: 800, loss is 3.806343698501587 and perplexity is 44.985656679291196
At time: 790.8280122280121 and batch: 850, loss is 3.814578638076782 and perplexity is 45.35764037327048
At time: 791.871973991394 and batch: 900, loss is 3.7867349433898925 and perplexity is 44.11213626696249
At time: 792.9122545719147 and batch: 950, loss is 3.887287902832031 and perplexity is 48.77841516570459
At time: 793.9769606590271 and batch: 1000, loss is 3.8444310522079466 and perplexity is 46.732088667186595
At time: 795.0217401981354 and batch: 1050, loss is 3.804824743270874 and perplexity is 44.917377350520916
At time: 796.0597748756409 and batch: 1100, loss is 3.832051649093628 and perplexity is 46.1571394100578
At time: 797.1028454303741 and batch: 1150, loss is 3.8055485916137695 and perplexity is 44.94990248989727
At time: 798.147246837616 and batch: 1200, loss is 3.860141282081604 and perplexity is 47.47205784624037
At time: 799.1880612373352 and batch: 1250, loss is 3.828359785079956 and perplexity is 45.98704769902307
At time: 800.2224636077881 and batch: 1300, loss is 3.827033953666687 and perplexity is 45.92611702740491
At time: 801.2671389579773 and batch: 1350, loss is 3.710844192504883 and perplexity is 40.888309565810594
At time: 802.3058345317841 and batch: 1400, loss is 3.738208270072937 and perplexity is 42.02262946931681
At time: 803.3522472381592 and batch: 1450, loss is 3.6506798124313353 and perplexity is 38.50083049775483
At time: 804.3906586170197 and batch: 1500, loss is 3.6652318239212036 and perplexity is 39.06519135929674
At time: 805.430505990982 and batch: 1550, loss is 3.676500277519226 and perplexity is 39.50788520861969
At time: 806.4687507152557 and batch: 1600, loss is 3.776580767631531 and perplexity is 43.66648034569819
At time: 807.5061225891113 and batch: 1650, loss is 3.6984687089920043 and perplexity is 40.385415163881376
At time: 808.544438123703 and batch: 1700, loss is 3.7267685079574586 and perplexity is 41.544639841330294
At time: 809.5881943702698 and batch: 1750, loss is 3.7211237478256227 and perplexity is 41.31079094605605
At time: 810.6305100917816 and batch: 1800, loss is 3.669889907836914 and perplexity is 39.247584770946496
At time: 811.669221162796 and batch: 1850, loss is 3.697361345291138 and perplexity is 40.340718573342876
At time: 812.7084214687347 and batch: 1900, loss is 3.7733344268798827 and perplexity is 43.52495391686994
At time: 813.7461643218994 and batch: 1950, loss is 3.7225690269470215 and perplexity is 41.37053973613784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482394905977471 and perplexity of 88.44623966106008
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 817.0010628700256 and batch: 50, loss is 3.9101745748519896 and perplexity is 49.90766383597699
At time: 818.066929101944 and batch: 100, loss is 3.902532625198364 and perplexity is 49.52772556519274
At time: 819.1095039844513 and batch: 150, loss is 3.8710303115844726 and perplexity is 47.99180713175435
At time: 820.1760120391846 and batch: 200, loss is 3.8509840679168703 and perplexity is 47.039330358684914
At time: 821.214170217514 and batch: 250, loss is 3.8594468450546264 and perplexity is 47.43910293540463
At time: 822.2543866634369 and batch: 300, loss is 3.8566760301589964 and perplexity is 47.307839899124026
At time: 823.2942464351654 and batch: 350, loss is 3.8643438625335693 and perplexity is 47.67198279464874
At time: 824.3342561721802 and batch: 400, loss is 3.825126543045044 and perplexity is 45.83860055543377
At time: 825.3756394386292 and batch: 450, loss is 3.8719360065460204 and perplexity is 48.03529275905338
At time: 826.4157404899597 and batch: 500, loss is 3.89399067401886 and perplexity is 49.10646391106547
At time: 827.4593591690063 and batch: 550, loss is 3.858979640007019 and perplexity is 47.41694432376991
At time: 828.4989609718323 and batch: 600, loss is 3.8330457735061647 and perplexity is 46.20304816488426
At time: 829.5374438762665 and batch: 650, loss is 3.8613651275634764 and perplexity is 47.53019187602944
At time: 830.5778391361237 and batch: 700, loss is 3.8803827571868896 and perplexity is 48.442753335283776
At time: 831.6173963546753 and batch: 750, loss is 3.843569893836975 and perplexity is 46.69186226097706
At time: 832.6584658622742 and batch: 800, loss is 3.8063875341415407 and perplexity is 44.987628697562506
At time: 833.6985611915588 and batch: 850, loss is 3.8147187852859497 and perplexity is 45.36399756544418
At time: 834.7386333942413 and batch: 900, loss is 3.786125340461731 and perplexity is 44.08525357424329
At time: 835.7859175205231 and batch: 950, loss is 3.887127900123596 and perplexity is 48.77061111151646
At time: 836.825453042984 and batch: 1000, loss is 3.8440120315551756 and perplexity is 46.712511058885475
At time: 837.8628213405609 and batch: 1050, loss is 3.8043809795379637 and perplexity is 44.897449069526516
At time: 838.9025721549988 and batch: 1100, loss is 3.830307583808899 and perplexity is 46.07670850433322
At time: 839.9482069015503 and batch: 1150, loss is 3.8039821577072144 and perplexity is 44.87954655688636
At time: 840.9898266792297 and batch: 1200, loss is 3.8586930227279663 and perplexity is 47.40335575565907
At time: 842.0287399291992 and batch: 1250, loss is 3.826818861961365 and perplexity is 45.91623976287158
At time: 843.074054479599 and batch: 1300, loss is 3.8249107789993286 and perplexity is 45.828711300439195
At time: 844.1212599277496 and batch: 1350, loss is 3.7082921504974364 and perplexity is 40.78409392010034
At time: 845.1725237369537 and batch: 1400, loss is 3.7351063299179077 and perplexity is 41.892479750224645
At time: 846.2246704101562 and batch: 1450, loss is 3.647348566055298 and perplexity is 38.37278813442348
At time: 847.2675590515137 and batch: 1500, loss is 3.6616931772232055 and perplexity is 38.92719774820116
At time: 848.3074162006378 and batch: 1550, loss is 3.673213996887207 and perplexity is 39.37826431262148
At time: 849.3463282585144 and batch: 1600, loss is 3.7730174684524536 and perplexity is 43.51116050200754
At time: 850.385490655899 and batch: 1650, loss is 3.6947568082809448 and perplexity is 40.23578638799924
At time: 851.4259943962097 and batch: 1700, loss is 3.7229870843887327 and perplexity is 41.38783861385248
At time: 852.4659271240234 and batch: 1750, loss is 3.7172867393493654 and perplexity is 41.152584804289496
At time: 853.5065970420837 and batch: 1800, loss is 3.6662287092208863 and perplexity is 39.104154291852744
At time: 854.5473363399506 and batch: 1850, loss is 3.6939343404769898 and perplexity is 40.20270735421314
At time: 855.5869688987732 and batch: 1900, loss is 3.76932186126709 and perplexity is 43.35065710603757
At time: 856.6233439445496 and batch: 1950, loss is 3.7193743324279787 and perplexity is 41.238584390331766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482281068313953 and perplexity of 88.4361717208564
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f31229a0b38>
ELAPSED
1770.618686914444


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.77128768299961}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.13481025420142356, 'wordvec_source': 'None', 'rnn_dropout': 0.7333439966881319, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.4361717208564}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.049255346069296047, 'wordvec_source': 'None', 'rnn_dropout': 0.9817036371865334, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5131866931915283 and batch: 50, loss is 7.1594556713104245 and perplexity is 1286.2106209813987
At time: 2.5512921810150146 and batch: 100, loss is 6.26535213470459 and perplexity is 526.0267856365617
At time: 3.590468645095825 and batch: 150, loss is 5.9939826965332035 and perplexity is 401.0085290505832
At time: 4.630957365036011 and batch: 200, loss is 5.8392260646820064 and perplexity is 343.5133806228396
At time: 5.671350479125977 and batch: 250, loss is 5.742709283828735 and perplexity is 311.90831543189665
At time: 6.710960388183594 and batch: 300, loss is 5.674846868515015 and perplexity is 291.4437059206
At time: 7.751811981201172 and batch: 350, loss is 5.613779525756836 and perplexity is 274.1785470552331
At time: 8.792848825454712 and batch: 400, loss is 5.5438877201080325 and perplexity is 255.67004338317065
At time: 9.833361625671387 and batch: 450, loss is 5.466148309707641 and perplexity is 236.54732880507314
At time: 10.919284343719482 and batch: 500, loss is 5.437964200973511 and perplexity is 229.97352669524568
At time: 11.961578130722046 and batch: 550, loss is 5.375327758789062 and perplexity is 216.01066010169953
At time: 13.002830982208252 and batch: 600, loss is 5.391555128097534 and perplexity is 219.5445400986584
At time: 14.046250104904175 and batch: 650, loss is 5.45247260093689 and perplexity is 233.33439606679227
At time: 15.085557460784912 and batch: 700, loss is 5.38255763053894 and perplexity is 217.57804865252982
At time: 16.129443168640137 and batch: 750, loss is 5.3283919334411625 and perplexity is 206.10627492229403
At time: 17.170471906661987 and batch: 800, loss is 5.300772972106934 and perplexity is 200.4917246055253
At time: 18.212831020355225 and batch: 850, loss is 5.29842583656311 and perplexity is 200.02169517963168
At time: 19.25423574447632 and batch: 900, loss is 5.319055280685425 and perplexity is 204.1908877691007
At time: 20.29708194732666 and batch: 950, loss is 5.357082300186157 and perplexity is 212.10518349369028
At time: 21.341820240020752 and batch: 1000, loss is 5.315493946075439 and perplexity is 203.46498904479066
At time: 22.385512351989746 and batch: 1050, loss is 5.217102184295654 and perplexity is 184.3990546155542
At time: 23.4281108379364 and batch: 1100, loss is 5.3040578651428225 and perplexity is 201.1514013660456
At time: 24.472198724746704 and batch: 1150, loss is 5.205105962753296 and perplexity is 182.2001781784664
At time: 25.51780939102173 and batch: 1200, loss is 5.280218563079834 and perplexity is 196.41279924716036
At time: 26.569570302963257 and batch: 1250, loss is 5.214047288894653 and perplexity is 183.8365943577123
At time: 27.614286422729492 and batch: 1300, loss is 5.244166278839112 and perplexity is 189.4577943937343
At time: 28.659752130508423 and batch: 1350, loss is 5.182371196746826 and perplexity is 178.10463180918867
At time: 29.703177452087402 and batch: 1400, loss is 5.1994259071350095 and perplexity is 181.16820464084418
At time: 30.748453617095947 and batch: 1450, loss is 5.136869020462036 and perplexity is 170.18209663742888
At time: 31.794728755950928 and batch: 1500, loss is 5.113726024627685 and perplexity is 166.28879814800143
At time: 32.83996605873108 and batch: 1550, loss is 5.1014722633361815 and perplexity is 164.2635685912282
At time: 33.88871765136719 and batch: 1600, loss is 5.153559427261353 and perplexity is 173.04634127367697
At time: 34.941508293151855 and batch: 1650, loss is 5.110966720581055 and perplexity is 165.8305892539144
At time: 35.988343477249146 and batch: 1700, loss is 5.139470720291138 and perplexity is 170.62543583685195
At time: 37.03719210624695 and batch: 1750, loss is 5.155305395126343 and perplexity is 173.34873853582687
At time: 38.091243743896484 and batch: 1800, loss is 5.114437322616578 and perplexity is 166.40712111215387
At time: 39.1382474899292 and batch: 1850, loss is 5.103277940750122 and perplexity is 164.5604435565137
At time: 40.18753790855408 and batch: 1900, loss is 5.158286695480347 and perplexity is 173.86631433248513
At time: 41.239176988601685 and batch: 1950, loss is 5.072241048812867 and perplexity is 159.53144478998104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.842397006722384 and perplexity of 126.77286323061854
finished 1 epochs...
Completing Train Step...
At time: 44.52443337440491 and batch: 50, loss is 5.020686502456665 and perplexity is 151.51528371322556
At time: 45.587310791015625 and batch: 100, loss is 4.969977006912232 and perplexity is 144.02357578612921
At time: 46.62787938117981 and batch: 150, loss is 4.909707984924316 and perplexity is 135.59981143721478
At time: 47.66324853897095 and batch: 200, loss is 4.885201263427734 and perplexity is 132.31709324632703
At time: 48.698097467422485 and batch: 250, loss is 4.883349351882934 and perplexity is 132.07228044955912
At time: 49.73954224586487 and batch: 300, loss is 4.902785835266113 and perplexity is 134.6644104766073
At time: 50.77152752876282 and batch: 350, loss is 4.913510217666626 and perplexity is 136.1163749050492
At time: 51.80385756492615 and batch: 400, loss is 4.869769086837769 and perplexity is 130.2908275555795
At time: 52.8379225730896 and batch: 450, loss is 4.855237321853638 and perplexity is 128.41116237392345
At time: 53.887545347213745 and batch: 500, loss is 4.849927320480346 and perplexity is 127.73110607322864
At time: 54.929527282714844 and batch: 550, loss is 4.805413188934327 and perplexity is 122.1699598694044
At time: 55.973923206329346 and batch: 600, loss is 4.789435262680054 and perplexity is 120.23344917083192
At time: 57.01381707191467 and batch: 650, loss is 4.853061075210571 and perplexity is 128.13201187321752
At time: 58.048728704452515 and batch: 700, loss is 4.857236213684082 and perplexity is 128.66809910614737
At time: 59.09579420089722 and batch: 750, loss is 4.818598709106445 and perplexity is 123.79150128009331
At time: 60.140398025512695 and batch: 800, loss is 4.788225603103638 and perplexity is 120.0880955595552
At time: 61.17873525619507 and batch: 850, loss is 4.792675361633301 and perplexity is 120.62364924569488
At time: 62.220497608184814 and batch: 900, loss is 4.8014108753204345 and perplexity is 121.68197456232917
At time: 63.263949394226074 and batch: 950, loss is 4.867216873168945 and perplexity is 129.9587215076399
At time: 64.3136854171753 and batch: 1000, loss is 4.839070053100586 and perplexity is 126.35179661708068
At time: 65.35418200492859 and batch: 1050, loss is 4.769785232543946 and perplexity is 117.8939194643763
At time: 66.39014196395874 and batch: 1100, loss is 4.843218536376953 and perplexity is 126.87705368907288
At time: 67.42949032783508 and batch: 1150, loss is 4.761704626083374 and perplexity is 116.94510376306611
At time: 68.46810054779053 and batch: 1200, loss is 4.8388501739501955 and perplexity is 126.32401754552149
At time: 69.52290058135986 and batch: 1250, loss is 4.797231092453003 and perplexity is 121.17443177801766
At time: 70.57277655601501 and batch: 1300, loss is 4.818909616470337 and perplexity is 123.82999495310159
At time: 71.6158709526062 and batch: 1350, loss is 4.727044448852539 and perplexity is 112.9612058665917
At time: 72.6521966457367 and batch: 1400, loss is 4.7387942028045655 and perplexity is 114.29630039790908
At time: 73.69541692733765 and batch: 1450, loss is 4.668412189483643 and perplexity is 106.52846106387885
At time: 74.7436249256134 and batch: 1500, loss is 4.658793811798096 and perplexity is 105.50874197421841
At time: 75.77963328361511 and batch: 1550, loss is 4.66853593826294 and perplexity is 106.54164464660518
At time: 76.81434679031372 and batch: 1600, loss is 4.753490209579468 and perplexity is 115.98840272264637
At time: 77.84802675247192 and batch: 1650, loss is 4.702613792419434 and perplexity is 110.23492744009377
At time: 78.88179039955139 and batch: 1700, loss is 4.72705397605896 and perplexity is 112.9622820764441
At time: 79.92131114006042 and batch: 1750, loss is 4.738134794235229 and perplexity is 114.22095728166157
At time: 80.96217966079712 and batch: 1800, loss is 4.690071153640747 and perplexity is 108.86092538302584
At time: 81.99929237365723 and batch: 1850, loss is 4.711712770462036 and perplexity is 111.24252974831379
At time: 83.03456091880798 and batch: 1900, loss is 4.791632766723633 and perplexity is 120.49795317943116
At time: 84.07018613815308 and batch: 1950, loss is 4.7132610321044925 and perplexity is 111.4148956894888
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.692897495003634 and perplexity of 109.16903873088177
finished 2 epochs...
Completing Train Step...
At time: 87.36849761009216 and batch: 50, loss is 4.678098077774048 and perplexity is 107.56529707035087
At time: 88.4069311618805 and batch: 100, loss is 4.628419847488403 and perplexity is 102.35220416998979
At time: 89.44361734390259 and batch: 150, loss is 4.5869702625274655 and perplexity is 98.19646949527005
At time: 90.478830575943 and batch: 200, loss is 4.5792790794372555 and perplexity is 97.44411940942354
At time: 91.51210474967957 and batch: 250, loss is 4.575513181686401 and perplexity is 97.07784492830277
At time: 92.54925966262817 and batch: 300, loss is 4.604987049102784 and perplexity is 99.98168798832279
At time: 93.58507871627808 and batch: 350, loss is 4.621274805068969 and perplexity is 101.62349974162512
At time: 94.62232232093811 and batch: 400, loss is 4.573222742080689 and perplexity is 96.85574843384067
At time: 95.65988278388977 and batch: 450, loss is 4.57552583694458 and perplexity is 97.07907348126763
At time: 96.70254874229431 and batch: 500, loss is 4.588106861114502 and perplexity is 98.3081429156541
At time: 97.76829075813293 and batch: 550, loss is 4.541675872802735 and perplexity is 93.8479456244203
At time: 98.80480408668518 and batch: 600, loss is 4.523714065551758 and perplexity is 92.17731559703851
At time: 99.84094190597534 and batch: 650, loss is 4.5857985401153565 and perplexity is 98.08147787345902
At time: 100.8835437297821 and batch: 700, loss is 4.60429967880249 and perplexity is 99.912987159586
At time: 101.92012882232666 and batch: 750, loss is 4.561473722457886 and perplexity is 95.72444719876985
At time: 102.96292686462402 and batch: 800, loss is 4.531970996856689 and perplexity is 92.941568208425
At time: 103.99894499778748 and batch: 850, loss is 4.541171770095826 and perplexity is 93.80064854328809
At time: 105.03525447845459 and batch: 900, loss is 4.542253866195678 and perplexity is 93.9022047961434
At time: 106.07305479049683 and batch: 950, loss is 4.620064105987549 and perplexity is 101.50053871325883
At time: 107.10694670677185 and batch: 1000, loss is 4.592202396392822 and perplexity is 98.71159299118402
At time: 108.14316487312317 and batch: 1050, loss is 4.527907199859619 and perplexity is 92.56463894337573
At time: 109.18547439575195 and batch: 1100, loss is 4.590252799987793 and perplexity is 98.519332700237
At time: 110.22295713424683 and batch: 1150, loss is 4.522438726425171 and perplexity is 92.05983319075223
At time: 111.26379537582397 and batch: 1200, loss is 4.599525680541992 and perplexity is 99.43713948442748
At time: 112.30459475517273 and batch: 1250, loss is 4.566559591293335 and perplexity is 96.21252929025478
At time: 113.33936095237732 and batch: 1300, loss is 4.590555744171143 and perplexity is 98.54918308029725
At time: 114.37996673583984 and batch: 1350, loss is 4.487262315750122 and perplexity is 88.8777931742157
At time: 115.41878056526184 and batch: 1400, loss is 4.499024324417114 and perplexity is 89.92934661512133
At time: 116.458411693573 and batch: 1450, loss is 4.424334087371826 and perplexity is 83.45721350143248
At time: 117.49497723579407 and batch: 1500, loss is 4.42597864151001 and perplexity is 83.59457632660003
At time: 118.53170228004456 and batch: 1550, loss is 4.438257961273194 and perplexity is 84.6273890009195
At time: 119.56852722167969 and batch: 1600, loss is 4.532008142471313 and perplexity is 92.94502064422126
At time: 120.60548996925354 and batch: 1650, loss is 4.4782984161376955 and perplexity is 88.08466164490042
At time: 121.64141869544983 and batch: 1700, loss is 4.502494897842407 and perplexity is 90.24199523681884
At time: 122.67943835258484 and batch: 1750, loss is 4.516457414627075 and perplexity is 91.51083811645563
At time: 123.71544694900513 and batch: 1800, loss is 4.45707935333252 and perplexity is 86.23527815912948
At time: 124.75048089027405 and batch: 1850, loss is 4.491691961288452 and perplexity is 89.27236355248404
At time: 125.78782033920288 and batch: 1900, loss is 4.579627752304077 and perplexity is 97.47810145385708
At time: 126.82308173179626 and batch: 1950, loss is 4.502398929595947 and perplexity is 90.2333352863257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.629360465116279 and perplexity of 102.44852375032997
finished 3 epochs...
Completing Train Step...
At time: 130.09247708320618 and batch: 50, loss is 4.473871774673462 and perplexity is 87.69560417357066
At time: 131.15889024734497 and batch: 100, loss is 4.422492141723633 and perplexity is 83.3036313386337
At time: 132.19394946098328 and batch: 150, loss is 4.386958103179932 and perplexity is 80.39549185679266
At time: 133.23197221755981 and batch: 200, loss is 4.387068881988525 and perplexity is 80.40439846691953
At time: 134.2687954902649 and batch: 250, loss is 4.380703716278076 and perplexity is 79.89423650199898
At time: 135.30333709716797 and batch: 300, loss is 4.410896921157837 and perplexity is 82.34328582811567
At time: 136.33818650245667 and batch: 350, loss is 4.429450092315673 and perplexity is 83.88527506719326
At time: 137.37503814697266 and batch: 400, loss is 4.379303474426269 and perplexity is 79.78244353519194
At time: 138.41131162643433 and batch: 450, loss is 4.392992057800293 and perplexity is 80.88206109842514
At time: 139.44715094566345 and batch: 500, loss is 4.408569393157959 and perplexity is 82.15185239450953
At time: 140.48294281959534 and batch: 550, loss is 4.366920223236084 and perplexity is 78.80056944019086
At time: 141.51708722114563 and batch: 600, loss is 4.347599391937256 and perplexity is 77.2926905749903
At time: 142.55197834968567 and batch: 650, loss is 4.407628736495972 and perplexity is 82.0746120412819
At time: 143.59144616127014 and batch: 700, loss is 4.429387617111206 and perplexity is 83.88003448118667
At time: 144.6315975189209 and batch: 750, loss is 4.391234273910523 and perplexity is 80.74001279613867
At time: 145.67066621780396 and batch: 800, loss is 4.358199882507324 and perplexity is 78.11638910354462
At time: 146.70749950408936 and batch: 850, loss is 4.3635031032562255 and perplexity is 78.53175798200421
At time: 147.74381160736084 and batch: 900, loss is 4.364915885925293 and perplexity is 78.64278469849599
At time: 148.78551626205444 and batch: 950, loss is 4.450402307510376 and perplexity is 85.66139929521005
At time: 149.84714794158936 and batch: 1000, loss is 4.4154711437225345 and perplexity is 82.72080511456907
At time: 150.88262057304382 and batch: 1050, loss is 4.363948879241943 and perplexity is 78.56677335775574
At time: 151.91881585121155 and batch: 1100, loss is 4.416577854156494 and perplexity is 82.81240376993951
At time: 152.95506834983826 and batch: 1150, loss is 4.357360305786133 and perplexity is 78.05083192570089
At time: 153.9931983947754 and batch: 1200, loss is 4.425234928131103 and perplexity is 83.53242903453268
At time: 155.03471446037292 and batch: 1250, loss is 4.405962486267089 and perplexity is 81.93796907248621
At time: 156.0709319114685 and batch: 1300, loss is 4.424144554138183 and perplexity is 83.44139708480238
At time: 157.10712885856628 and batch: 1350, loss is 4.314476313591004 and perplexity is 74.77445482306996
At time: 158.1437783241272 and batch: 1400, loss is 4.3310838794708255 and perplexity is 76.02664564792057
At time: 159.1803834438324 and batch: 1450, loss is 4.255102376937867 and perplexity is 70.464030710871
At time: 160.21692419052124 and batch: 1500, loss is 4.268580393791199 and perplexity is 71.42017509526474
At time: 161.2530779838562 and batch: 1550, loss is 4.276445379257202 and perplexity is 71.984108491371
At time: 162.28906083106995 and batch: 1600, loss is 4.376540565490723 and perplexity is 79.56231614504702
At time: 163.3239390850067 and batch: 1650, loss is 4.315632801055909 and perplexity is 74.86098056609278
At time: 164.35846781730652 and batch: 1700, loss is 4.339261765480042 and perplexity is 76.65093208210116
At time: 165.3962836265564 and batch: 1750, loss is 4.350517997741699 and perplexity is 77.51860699045639
At time: 166.43342852592468 and batch: 1800, loss is 4.290574216842652 and perplexity is 73.00837910653071
At time: 167.4748067855835 and batch: 1850, loss is 4.333322048187256 and perplexity is 76.19699667388042
At time: 168.5182604789734 and batch: 1900, loss is 4.427408494949341 and perplexity is 83.71418981356892
At time: 169.55457210540771 and batch: 1950, loss is 4.346983003616333 and perplexity is 77.24506294329309
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.608247978742733 and perplexity of 100.30825340217261
finished 4 epochs...
Completing Train Step...
At time: 172.80866956710815 and batch: 50, loss is 4.325579953193665 and perplexity is 75.60935003076548
At time: 173.88623642921448 and batch: 100, loss is 4.274604811668396 and perplexity is 71.85173872948833
At time: 174.9256455898285 and batch: 150, loss is 4.243835926055908 and perplexity is 69.67460652464021
At time: 175.99489974975586 and batch: 200, loss is 4.242746753692627 and perplexity is 69.59876018115969
At time: 177.03115129470825 and batch: 250, loss is 4.237867727279663 and perplexity is 69.26001304203233
At time: 178.06893801689148 and batch: 300, loss is 4.267628860473633 and perplexity is 71.35224874133479
At time: 179.1078281402588 and batch: 350, loss is 4.280548801422119 and perplexity is 72.28009654432253
At time: 180.14648532867432 and batch: 400, loss is 4.229252033233642 and perplexity is 68.66585318518769
At time: 181.19137454032898 and batch: 450, loss is 4.250976810455322 and perplexity is 70.17392550317886
At time: 182.22998523712158 and batch: 500, loss is 4.278143720626831 and perplexity is 72.10646595373758
At time: 183.27410244941711 and batch: 550, loss is 4.232662816047668 and perplexity is 68.900457361651
At time: 184.3111333847046 and batch: 600, loss is 4.21521044254303 and perplexity is 67.70841310240526
At time: 185.350914478302 and batch: 650, loss is 4.273510951995849 and perplexity is 71.77318598076435
At time: 186.38964819908142 and batch: 700, loss is 4.297824010848999 and perplexity is 73.53959810322392
At time: 187.42837643623352 and batch: 750, loss is 4.2595700788497926 and perplexity is 70.77954728778839
At time: 188.46933150291443 and batch: 800, loss is 4.226830425262452 and perplexity is 68.49977257998515
At time: 189.51063442230225 and batch: 850, loss is 4.230459232330322 and perplexity is 68.74879659565768
At time: 190.54960370063782 and batch: 900, loss is 4.225674715042114 and perplexity is 68.42065242151807
At time: 191.58695697784424 and batch: 950, loss is 4.315909509658813 and perplexity is 74.88169810966637
At time: 192.62604808807373 and batch: 1000, loss is 4.279643650054932 and perplexity is 72.21470171668864
At time: 193.66894698143005 and batch: 1050, loss is 4.239501972198486 and perplexity is 69.37329340514077
At time: 194.70739102363586 and batch: 1100, loss is 4.286552257537842 and perplexity is 72.71533208348578
At time: 195.74863719940186 and batch: 1150, loss is 4.232248678207397 and perplexity is 68.8719289827939
At time: 196.79822969436646 and batch: 1200, loss is 4.295015711784362 and perplexity is 73.33336663401566
At time: 197.83931636810303 and batch: 1250, loss is 4.280715551376343 and perplexity is 72.29215025206223
At time: 198.8777883052826 and batch: 1300, loss is 4.293985576629638 and perplexity is 73.25786225156803
At time: 199.91712546348572 and batch: 1350, loss is 4.183157172203064 and perplexity is 65.57255058671447
At time: 200.95620846748352 and batch: 1400, loss is 4.200688009262085 and perplexity is 66.73222764116834
At time: 201.99646759033203 and batch: 1450, loss is 4.120688586235047 and perplexity is 61.6016457088303
At time: 203.0386939048767 and batch: 1500, loss is 4.136558527946472 and perplexity is 62.58705877785623
At time: 204.07644033432007 and batch: 1550, loss is 4.151041679382324 and perplexity is 63.500112616313416
At time: 205.1202483177185 and batch: 1600, loss is 4.253279123306275 and perplexity is 70.33567395999441
At time: 206.1609628200531 and batch: 1650, loss is 4.19431700706482 and perplexity is 66.30842792020468
At time: 207.19922924041748 and batch: 1700, loss is 4.2120554685592655 and perplexity is 67.49513144653757
At time: 208.23861742019653 and batch: 1750, loss is 4.222848749160766 and perplexity is 68.22757094152972
At time: 209.27668356895447 and batch: 1800, loss is 4.163568015098572 and perplexity is 64.30053908413618
At time: 210.31602311134338 and batch: 1850, loss is 4.208958587646484 and perplexity is 67.28643039021262
At time: 211.35407161712646 and batch: 1900, loss is 4.301984119415283 and perplexity is 73.84616805525832
At time: 212.39241886138916 and batch: 1950, loss is 4.225749349594116 and perplexity is 68.42575915682629
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.598573764534883 and perplexity of 99.34252871754708
finished 5 epochs...
Completing Train Step...
At time: 215.72591090202332 and batch: 50, loss is 4.205031490325927 and perplexity is 67.02270819999958
At time: 216.75953149795532 and batch: 100, loss is 4.158374223709107 and perplexity is 63.96744126697914
At time: 217.7927451133728 and batch: 150, loss is 4.127748918533325 and perplexity is 62.03811278586267
At time: 218.82581448554993 and batch: 200, loss is 4.126984915733337 and perplexity is 61.99073359521007
At time: 219.860032081604 and batch: 250, loss is 4.119275321960449 and perplexity is 61.51464779369652
At time: 220.89635825157166 and batch: 300, loss is 4.150063300132752 and perplexity is 63.43801580585292
At time: 221.93193173408508 and batch: 350, loss is 4.159424486160279 and perplexity is 64.03465916067557
At time: 222.96855115890503 and batch: 400, loss is 4.109858846664428 and perplexity is 60.9381153442758
At time: 224.0071804523468 and batch: 450, loss is 4.137971096038818 and perplexity is 62.67552973099148
At time: 225.04767155647278 and batch: 500, loss is 4.1613118886947635 and perplexity is 64.15563246541947
At time: 226.08446621894836 and batch: 550, loss is 4.125040521621704 and perplexity is 61.87031628512422
At time: 227.12249660491943 and batch: 600, loss is 4.101960945129394 and perplexity is 60.4587276797304
At time: 228.19283866882324 and batch: 650, loss is 4.161920709609985 and perplexity is 64.19470364876365
At time: 229.2306158542633 and batch: 700, loss is 4.185137739181519 and perplexity is 65.70255010898492
At time: 230.26752543449402 and batch: 750, loss is 4.1498698186874385 and perplexity is 63.42574291419369
At time: 231.30188369750977 and batch: 800, loss is 4.117559385299683 and perplexity is 61.409183065647674
At time: 232.3354413509369 and batch: 850, loss is 4.12105215549469 and perplexity is 61.62404624537995
At time: 233.37612581253052 and batch: 900, loss is 4.115543255805969 and perplexity is 61.2854989240028
At time: 234.41266083717346 and batch: 950, loss is 4.205315179824829 and perplexity is 67.04172453574374
At time: 235.44926071166992 and batch: 1000, loss is 4.170789346694947 and perplexity is 64.76655520201201
At time: 236.48643016815186 and batch: 1050, loss is 4.130083541870118 and perplexity is 62.183117611706294
At time: 237.51894688606262 and batch: 1100, loss is 4.1770039606094365 and perplexity is 65.17030762040568
At time: 238.55252122879028 and batch: 1150, loss is 4.125355944633484 and perplexity is 61.88983468474102
At time: 239.58525943756104 and batch: 1200, loss is 4.188834161758423 and perplexity is 65.94586391685034
At time: 240.62118220329285 and batch: 1250, loss is 4.177855224609375 and perplexity is 65.22580837669419
At time: 241.65567016601562 and batch: 1300, loss is 4.185688114166259 and perplexity is 65.73872110189036
At time: 242.69163370132446 and batch: 1350, loss is 4.07718270778656 and perplexity is 58.97907428074323
At time: 243.72904562950134 and batch: 1400, loss is 4.092113089561463 and perplexity is 59.86626091341521
At time: 244.7711696624756 and batch: 1450, loss is 4.015942859649658 and perplexity is 55.47557643434456
At time: 245.80430102348328 and batch: 1500, loss is 4.029211573600769 and perplexity is 56.2165711412077
At time: 246.83739137649536 and batch: 1550, loss is 4.043691792488098 and perplexity is 57.03652160049634
At time: 247.8711326122284 and batch: 1600, loss is 4.144834876060486 and perplexity is 63.107200531796366
At time: 248.90522813796997 and batch: 1650, loss is 4.086319665908814 and perplexity is 59.52043303242958
At time: 249.9407296180725 and batch: 1700, loss is 4.106673331260681 and perplexity is 60.744304896146296
At time: 250.9745533466339 and batch: 1750, loss is 4.12131856918335 and perplexity is 61.64046592196653
At time: 252.01021552085876 and batch: 1800, loss is 4.055815358161926 and perplexity is 57.732216244652335
At time: 253.04452967643738 and batch: 1850, loss is 4.102387337684632 and perplexity is 60.484512327912505
At time: 254.08169317245483 and batch: 1900, loss is 4.1972921133041385 and perplexity is 66.50599628554036
At time: 255.11715507507324 and batch: 1950, loss is 4.119980616569519 and perplexity is 61.558049046699985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6002370435138085 and perplexity of 99.50790054889657
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 258.4179518222809 and batch: 50, loss is 4.127334899902344 and perplexity is 62.01243316762541
At time: 259.48574662208557 and batch: 100, loss is 4.107713389396667 and perplexity is 60.80751537025431
At time: 260.5253975391388 and batch: 150, loss is 4.073785300254822 and perplexity is 58.77903832380778
At time: 261.5705244541168 and batch: 200, loss is 4.075662870407104 and perplexity is 58.889503762598075
At time: 262.61753153800964 and batch: 250, loss is 4.0735999202728275 and perplexity is 58.76814287667176
At time: 263.6648802757263 and batch: 300, loss is 4.090177021026611 and perplexity is 59.75046785717743
At time: 264.70332646369934 and batch: 350, loss is 4.100339603424072 and perplexity is 60.36078284557081
At time: 265.74693965911865 and batch: 400, loss is 4.040085906982422 and perplexity is 56.831224794797
At time: 266.7925500869751 and batch: 450, loss is 4.066481366157531 and perplexity is 58.35128414737713
At time: 267.83383321762085 and batch: 500, loss is 4.089455080032349 and perplexity is 59.707347112194604
At time: 268.87462973594666 and batch: 550, loss is 4.044787049293518 and perplexity is 57.09902546157814
At time: 269.9175465106964 and batch: 600, loss is 4.010613422393799 and perplexity is 55.1807092664634
At time: 270.95719838142395 and batch: 650, loss is 4.058709778785706 and perplexity is 57.899559626245875
At time: 271.9977169036865 and batch: 700, loss is 4.074728784561157 and perplexity is 58.83452159368919
At time: 273.03603315353394 and batch: 750, loss is 4.027679839134216 and perplexity is 56.13052819589469
At time: 274.0797667503357 and batch: 800, loss is 3.990146961212158 and perplexity is 54.06283391914697
At time: 275.11547350883484 and batch: 850, loss is 3.994198694229126 and perplexity is 54.28232645062083
At time: 276.15258836746216 and batch: 900, loss is 3.978030352592468 and perplexity is 53.41172828160247
At time: 277.1892011165619 and batch: 950, loss is 4.059609265327453 and perplexity is 57.95166293050032
At time: 278.23344230651855 and batch: 1000, loss is 4.015633025169373 and perplexity is 55.4583908504322
At time: 279.27232551574707 and batch: 1050, loss is 3.9733724784851074 and perplexity is 53.16352168171072
At time: 280.33854389190674 and batch: 1100, loss is 4.005648798942566 and perplexity is 54.90743673208966
At time: 281.37445282936096 and batch: 1150, loss is 3.9517002582550047 and perplexity is 52.02374548299111
At time: 282.41483521461487 and batch: 1200, loss is 4.0034179639816285 and perplexity is 54.78508382792237
At time: 283.45396971702576 and batch: 1250, loss is 3.984079384803772 and perplexity is 53.73579670845625
At time: 284.48917508125305 and batch: 1300, loss is 3.9880864095687865 and perplexity is 53.9515493510444
At time: 285.5264608860016 and batch: 1350, loss is 3.8732010746002197 and perplexity is 48.09609912738447
At time: 286.56688499450684 and batch: 1400, loss is 3.874258680343628 and perplexity is 48.14699274600496
At time: 287.6132481098175 and batch: 1450, loss is 3.793862318992615 and perplexity is 44.427663134308084
At time: 288.6612033843994 and batch: 1500, loss is 3.8013973236083984 and perplexity is 44.76369017387799
At time: 289.7074694633484 and batch: 1550, loss is 3.812018337249756 and perplexity is 45.24165970516685
At time: 290.7528922557831 and batch: 1600, loss is 3.904057035446167 and perplexity is 49.60328371377068
At time: 291.80033802986145 and batch: 1650, loss is 3.833692536354065 and perplexity is 46.23294024539861
At time: 292.8398973941803 and batch: 1700, loss is 3.8403028678894042 and perplexity is 46.539567646118414
At time: 293.880300283432 and batch: 1750, loss is 3.8430670881271363 and perplexity is 46.668391227208616
At time: 294.9200849533081 and batch: 1800, loss is 3.7707935333251954 and perplexity is 43.4145020246694
At time: 295.9619755744934 and batch: 1850, loss is 3.803228096961975 and perplexity is 44.84571740878295
At time: 296.9973978996277 and batch: 1900, loss is 3.8884902715682985 and perplexity is 48.8371000804879
At time: 298.03619360923767 and batch: 1950, loss is 3.8157705640792847 and perplexity is 45.41173555656697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.511933934411338 and perplexity of 91.09782548220103
finished 7 epochs...
Completing Train Step...
At time: 301.3969306945801 and batch: 50, loss is 4.01375304222107 and perplexity is 55.35422796419694
At time: 302.4823224544525 and batch: 100, loss is 3.9880966424942015 and perplexity is 53.95210143604965
At time: 303.5211851596832 and batch: 150, loss is 3.955149836540222 and perplexity is 52.20351535257853
At time: 304.5608580112457 and batch: 200, loss is 3.9523458814620973 and perplexity is 52.05734406523995
At time: 305.59992241859436 and batch: 250, loss is 3.948318109512329 and perplexity is 51.84809065044397
At time: 306.6866555213928 and batch: 300, loss is 3.969313259124756 and perplexity is 52.94815668783091
At time: 307.7247431278229 and batch: 350, loss is 3.9852965593338014 and perplexity is 53.80124237287866
At time: 308.7649338245392 and batch: 400, loss is 3.9266836166381838 and perplexity is 50.73843025386017
At time: 309.8107054233551 and batch: 450, loss is 3.959174146652222 and perplexity is 52.41402177475842
At time: 310.84932923316956 and batch: 500, loss is 3.9858322381973266 and perplexity is 53.8300702818106
At time: 311.88864755630493 and batch: 550, loss is 3.9421675634384155 and perplexity is 51.530175258892534
At time: 312.9273302555084 and batch: 600, loss is 3.9132637071609495 and perplexity is 50.06207358608038
At time: 313.9673128128052 and batch: 650, loss is 3.964787039756775 and perplexity is 52.709043263656895
At time: 315.0087003707886 and batch: 700, loss is 3.982757420539856 and perplexity is 53.664806838888396
At time: 316.056663274765 and batch: 750, loss is 3.9402858209609986 and perplexity is 51.43329991504984
At time: 317.09428572654724 and batch: 800, loss is 3.9044318294525144 and perplexity is 49.62187821153725
At time: 318.1338093280792 and batch: 850, loss is 3.912470178604126 and perplexity is 50.02236365864047
At time: 319.17312455177307 and batch: 900, loss is 3.897355523109436 and perplexity is 49.271978060399995
At time: 320.2127830982208 and batch: 950, loss is 3.981344027519226 and perplexity is 53.58901095275506
At time: 321.25884795188904 and batch: 1000, loss is 3.940342378616333 and perplexity is 51.43620894416231
At time: 322.3108329772949 and batch: 1050, loss is 3.9028252840042112 and perplexity is 49.54222241142436
At time: 323.3515453338623 and batch: 1100, loss is 3.9361858129501344 and perplexity is 51.22285468174392
At time: 324.39064359664917 and batch: 1150, loss is 3.8879470729827883 and perplexity is 48.810579040551566
At time: 325.43094849586487 and batch: 1200, loss is 3.942080783843994 and perplexity is 51.52570368520658
At time: 326.4726781845093 and batch: 1250, loss is 3.928571605682373 and perplexity is 50.83431433986918
At time: 327.512291431427 and batch: 1300, loss is 3.9353893852233885 and perplexity is 51.18207562097514
At time: 328.55994391441345 and batch: 1350, loss is 3.8207026433944704 and perplexity is 45.63626307679789
At time: 329.60872650146484 and batch: 1400, loss is 3.8280225515365602 and perplexity is 45.97154193865543
At time: 330.6540479660034 and batch: 1450, loss is 3.7489725494384767 and perplexity is 42.47741612658969
At time: 331.6927914619446 and batch: 1500, loss is 3.7598909664154054 and perplexity is 42.943743413208956
At time: 332.7338116168976 and batch: 1550, loss is 3.7741208839416505 and perplexity is 43.559197888182474
At time: 333.780531167984 and batch: 1600, loss is 3.8700879621505737 and perplexity is 47.946603381681264
At time: 334.820143699646 and batch: 1650, loss is 3.80290967464447 and perplexity is 44.83143980478999
At time: 335.8690767288208 and batch: 1700, loss is 3.814044756889343 and perplexity is 45.333431245342574
At time: 336.90906858444214 and batch: 1750, loss is 3.8228215026855468 and perplexity is 45.73306241269872
At time: 337.94849586486816 and batch: 1800, loss is 3.7557028102874757 and perplexity is 42.764264416454864
At time: 338.98692989349365 and batch: 1850, loss is 3.7900505542755125 and perplexity is 44.25863768279088
At time: 340.02771162986755 and batch: 1900, loss is 3.8798780965805055 and perplexity is 48.41831235372968
At time: 341.0679557323456 and batch: 1950, loss is 3.8111121606826783 and perplexity is 45.20068134290629
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.510388467478197 and perplexity of 90.95714554133647
finished 8 epochs...
Completing Train Step...
At time: 344.36377930641174 and batch: 50, loss is 3.959060754776001 and perplexity is 52.4080787874387
At time: 345.3963305950165 and batch: 100, loss is 3.9301659154891966 and perplexity is 50.915424626026045
At time: 346.43067932128906 and batch: 150, loss is 3.899256534576416 and perplexity is 49.36573374277237
At time: 347.46543884277344 and batch: 200, loss is 3.894781441688538 and perplexity is 49.14531107261394
At time: 348.50437903404236 and batch: 250, loss is 3.8905791568756105 and perplexity is 48.93922180444861
At time: 349.54326343536377 and batch: 300, loss is 3.9121308517456055 and perplexity is 50.00539260665413
At time: 350.578608751297 and batch: 350, loss is 3.9283851480484007 and perplexity is 50.82483677750215
At time: 351.6186156272888 and batch: 400, loss is 3.871179909706116 and perplexity is 47.99898715300098
At time: 352.6509282588959 and batch: 450, loss is 3.9057338523864744 and perplexity is 49.68652911434056
At time: 353.6917202472687 and batch: 500, loss is 3.9334220600128176 and perplexity is 51.08148281510241
At time: 354.7291853427887 and batch: 550, loss is 3.8906857776641846 and perplexity is 48.94444002104984
At time: 355.7663199901581 and batch: 600, loss is 3.863707661628723 and perplexity is 47.6416634816688
At time: 356.80860662460327 and batch: 650, loss is 3.916405715942383 and perplexity is 50.21961643179885
At time: 357.843542098999 and batch: 700, loss is 3.935740599632263 and perplexity is 51.200054660473384
At time: 358.9049758911133 and batch: 750, loss is 3.8947593545913697 and perplexity is 49.14422560734036
At time: 359.93881011009216 and batch: 800, loss is 3.8581788778305053 and perplexity is 47.37898982652059
At time: 360.9783763885498 and batch: 850, loss is 3.8675028610229494 and perplexity is 47.8228166327819
At time: 362.01927733421326 and batch: 900, loss is 3.851606740951538 and perplexity is 47.06862960224589
At time: 363.05711913108826 and batch: 950, loss is 3.9370200395584107 and perplexity is 51.26560397889266
At time: 364.09337306022644 and batch: 1000, loss is 3.898049793243408 and perplexity is 49.30619800077583
At time: 365.1289105415344 and batch: 1050, loss is 3.861855459213257 and perplexity is 47.5535031480866
At time: 366.16296124458313 and batch: 1100, loss is 3.895670976638794 and perplexity is 49.1890469938856
At time: 367.19760274887085 and batch: 1150, loss is 3.849634761810303 and perplexity is 46.975902704266986
At time: 368.23779678344727 and batch: 1200, loss is 3.904203052520752 and perplexity is 49.61052716896958
At time: 369.278502702713 and batch: 1250, loss is 3.8941945362091066 and perplexity is 49.116475882850224
At time: 370.32421350479126 and batch: 1300, loss is 3.901341271400452 and perplexity is 49.46875565522658
At time: 371.36609148979187 and batch: 1350, loss is 3.787675018310547 and perplexity is 44.15362447792146
At time: 372.4000332355499 and batch: 1400, loss is 3.796384916305542 and perplexity is 44.539877714543174
At time: 373.4404733181 and batch: 1450, loss is 3.7177778673171997 and perplexity is 41.17280095358736
At time: 374.47621035575867 and batch: 1500, loss is 3.729364638328552 and perplexity is 41.652635267024344
At time: 375.51292634010315 and batch: 1550, loss is 3.7449057054519654 and perplexity is 42.30501789821287
At time: 376.5561189651489 and batch: 1600, loss is 3.8436875343322754 and perplexity is 46.69735543788362
At time: 377.59117674827576 and batch: 1650, loss is 3.7767876529693605 and perplexity is 43.67551523479716
At time: 378.62582778930664 and batch: 1700, loss is 3.7895363998413085 and perplexity is 44.23588775696324
At time: 379.6592264175415 and batch: 1750, loss is 3.800695080757141 and perplexity is 44.73226622736976
At time: 380.6934988498688 and batch: 1800, loss is 3.7363726902008056 and perplexity is 41.94556432773856
At time: 381.7286169528961 and batch: 1850, loss is 3.7705932331085203 and perplexity is 43.40580696134762
At time: 382.76343750953674 and batch: 1900, loss is 3.861590390205383 and perplexity is 47.540899858630716
At time: 383.7983388900757 and batch: 1950, loss is 3.794546880722046 and perplexity is 44.45808702454523
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.513413540152616 and perplexity of 91.23271411419107
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 387.065407037735 and batch: 50, loss is 3.934230227470398 and perplexity is 51.122781893236194
At time: 388.1246426105499 and batch: 100, loss is 3.9270069789886475 and perplexity is 50.75483980489841
At time: 389.15927171707153 and batch: 150, loss is 3.901890230178833 and perplexity is 49.49591941811
At time: 390.19321298599243 and batch: 200, loss is 3.902794528007507 and perplexity is 49.54069871442669
At time: 391.22920060157776 and batch: 250, loss is 3.902453875541687 and perplexity is 49.523825427377766
At time: 392.26761054992676 and batch: 300, loss is 3.9184117889404297 and perplexity is 50.320461766026376
At time: 393.30215764045715 and batch: 350, loss is 3.9368531465530396 and perplexity is 51.25704882209023
At time: 394.3353593349457 and batch: 400, loss is 3.885763559341431 and perplexity is 48.704116748605976
At time: 395.36951184272766 and batch: 450, loss is 3.9191160583496094 and perplexity is 50.35591341019291
At time: 396.4065988063812 and batch: 500, loss is 3.943093662261963 and perplexity is 51.57791939806019
At time: 397.44013023376465 and batch: 550, loss is 3.8994479417800902 and perplexity is 49.37518360418233
At time: 398.4744999408722 and batch: 600, loss is 3.868338494300842 and perplexity is 47.86279567138396
At time: 399.5110182762146 and batch: 650, loss is 3.908950548171997 and perplexity is 49.84661289551806
At time: 400.5453305244446 and batch: 700, loss is 3.9270634555816653 and perplexity is 50.75770634627524
At time: 401.5782561302185 and batch: 750, loss is 3.8809942197799683 and perplexity is 48.47238332474594
At time: 402.61094641685486 and batch: 800, loss is 3.8428318691253662 and perplexity is 46.6574152257426
At time: 403.6445994377136 and batch: 850, loss is 3.8523881244659424 and perplexity is 47.10542262632188
At time: 404.6787030696869 and batch: 900, loss is 3.8267441511154177 and perplexity is 45.91280944989857
At time: 405.71369194984436 and batch: 950, loss is 3.9151194047927858 and perplexity is 50.155059908043526
At time: 406.74845337867737 and batch: 1000, loss is 3.872426085472107 and perplexity is 48.058839613180204
At time: 407.78541469573975 and batch: 1050, loss is 3.8347199392318725 and perplexity is 46.28046451035916
At time: 408.8183469772339 and batch: 1100, loss is 3.8616796493530274 and perplexity is 47.545143508219795
At time: 409.85155272483826 and batch: 1150, loss is 3.815640187263489 and perplexity is 45.4058153050255
At time: 410.8920228481293 and batch: 1200, loss is 3.8692766666412353 and perplexity is 47.90772029264018
At time: 411.9551899433136 and batch: 1250, loss is 3.8530282545089722 and perplexity is 47.13558587570568
At time: 412.99318385124207 and batch: 1300, loss is 3.856126556396484 and perplexity is 47.281852622655464
At time: 414.02770805358887 and batch: 1350, loss is 3.738098340034485 and perplexity is 42.018010173947694
At time: 415.0656921863556 and batch: 1400, loss is 3.7470272302627565 and perplexity is 42.3948643153075
At time: 416.1033184528351 and batch: 1450, loss is 3.661672759056091 and perplexity is 38.92640293428659
At time: 417.1369490623474 and batch: 1500, loss is 3.668428454399109 and perplexity is 39.19026814624818
At time: 418.17253065109253 and batch: 1550, loss is 3.6797053813934326 and perplexity is 39.63471522768249
At time: 419.208172082901 and batch: 1600, loss is 3.774712905883789 and perplexity is 43.58499352415206
At time: 420.2434241771698 and batch: 1650, loss is 3.7069427585601806 and perplexity is 40.72909730693455
At time: 421.27890944480896 and batch: 1700, loss is 3.7106780862808226 and perplexity is 40.88151832714953
At time: 422.31222558021545 and batch: 1750, loss is 3.7184671354293823 and perplexity is 41.20118983502533
At time: 423.3526871204376 and batch: 1800, loss is 3.6523159456253054 and perplexity is 38.563874544692844
At time: 424.38743686676025 and batch: 1850, loss is 3.6820952129364013 and perplexity is 39.72954879331824
At time: 425.4237048625946 and batch: 1900, loss is 3.7717277812957763 and perplexity is 43.45508088748835
At time: 426.45714688301086 and batch: 1950, loss is 3.7093704557418823 and perplexity is 40.828095341682655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483474234647529 and perplexity of 88.54175375956511
finished 10 epochs...
Completing Train Step...
At time: 429.71922159194946 and batch: 50, loss is 3.9151424884796144 and perplexity is 50.15621768510215
At time: 430.7796530723572 and batch: 100, loss is 3.898622121810913 and perplexity is 49.33442542335637
At time: 431.8132972717285 and batch: 150, loss is 3.868333377838135 and perplexity is 47.86255078380132
At time: 432.85043382644653 and batch: 200, loss is 3.8633526134490968 and perplexity is 47.624751398255135
At time: 433.8853886127472 and batch: 250, loss is 3.8602181100845336 and perplexity is 47.475705169746156
At time: 434.91946482658386 and batch: 300, loss is 3.874417963027954 and perplexity is 48.15466233905225
At time: 435.9538264274597 and batch: 350, loss is 3.8944095754623413 and perplexity is 49.1270389888461
At time: 436.98983240127563 and batch: 400, loss is 3.841883826255798 and perplexity is 46.61320295679996
At time: 438.0579936504364 and batch: 450, loss is 3.8792581367492676 and perplexity is 48.388304247845305
At time: 439.09463381767273 and batch: 500, loss is 3.902808847427368 and perplexity is 49.54140811357087
At time: 440.1295051574707 and batch: 550, loss is 3.8605162000656126 and perplexity is 47.489859311301
At time: 441.1639461517334 and batch: 600, loss is 3.830817975997925 and perplexity is 46.1002316989666
At time: 442.1989507675171 and batch: 650, loss is 3.873377833366394 and perplexity is 48.104601285917425
At time: 443.23060274124146 and batch: 700, loss is 3.893477301597595 and perplexity is 49.081260476715286
At time: 444.2638826370239 and batch: 750, loss is 3.850206050872803 and perplexity is 47.002747190933704
At time: 445.3000183105469 and batch: 800, loss is 3.8120875644683836 and perplexity is 45.244791767845086
At time: 446.3344159126282 and batch: 850, loss is 3.822957534790039 and perplexity is 45.739284000581854
At time: 447.3689434528351 and batch: 900, loss is 3.799670090675354 and perplexity is 44.68643958808837
At time: 448.4044806957245 and batch: 950, loss is 3.8883526277542115 and perplexity is 48.83037841837209
At time: 449.43895530700684 and batch: 1000, loss is 3.846618776321411 and perplexity is 46.83443749911887
At time: 450.4724316596985 and batch: 1050, loss is 3.809638671875 and perplexity is 45.13412768992109
At time: 451.5070128440857 and batch: 1100, loss is 3.838072180747986 and perplexity is 46.43586813458695
At time: 452.5477373600006 and batch: 1150, loss is 3.794380111694336 and perplexity is 44.45067341079606
At time: 453.58259320259094 and batch: 1200, loss is 3.850085072517395 and perplexity is 46.997061219825554
At time: 454.6183316707611 and batch: 1250, loss is 3.8364736318588255 and perplexity is 46.361697427708144
At time: 455.6611201763153 and batch: 1300, loss is 3.8405892753601076 and perplexity is 46.55289883496048
At time: 456.69846773147583 and batch: 1350, loss is 3.723796648979187 and perplexity is 41.421358308818036
At time: 457.7395279407501 and batch: 1400, loss is 3.735684723854065 and perplexity is 41.91671711517953
At time: 458.77214336395264 and batch: 1450, loss is 3.652873978614807 and perplexity is 38.585400464419855
At time: 459.8064742088318 and batch: 1500, loss is 3.6617839670181276 and perplexity is 38.930732100940766
At time: 460.8411376476288 and batch: 1550, loss is 3.6752793121337892 and perplexity is 39.459676884664475
At time: 461.88324069976807 and batch: 1600, loss is 3.7721473932266236 and perplexity is 43.47331898407853
At time: 462.91909074783325 and batch: 1650, loss is 3.7057918739318847 and perplexity is 40.68224977814094
At time: 463.95092487335205 and batch: 1700, loss is 3.712163043022156 and perplexity is 40.94227070955153
At time: 464.98543214797974 and batch: 1750, loss is 3.721815333366394 and perplexity is 41.33937077331069
At time: 466.0194716453552 and batch: 1800, loss is 3.6573334169387817 and perplexity is 38.75785391496754
At time: 467.05738615989685 and batch: 1850, loss is 3.6884074211120605 and perplexity is 39.98112313552698
At time: 468.09748554229736 and batch: 1900, loss is 3.7785330486297606 and perplexity is 43.751812854951815
At time: 469.1331105232239 and batch: 1950, loss is 3.7168819952011107 and perplexity is 41.13593190671317
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483200570039971 and perplexity of 88.51752633051612
finished 11 epochs...
Completing Train Step...
At time: 472.41435647010803 and batch: 50, loss is 3.8993792486190797 and perplexity is 49.371791983237
At time: 473.4542407989502 and batch: 100, loss is 3.8806987380981446 and perplexity is 48.458062739238684
At time: 474.492308139801 and batch: 150, loss is 3.8498958110809327 and perplexity is 46.98816733017129
At time: 475.5332496166229 and batch: 200, loss is 3.8437320804595947 and perplexity is 46.69943567055725
At time: 476.5776057243347 and batch: 250, loss is 3.840064301490784 and perplexity is 46.52846619334119
At time: 477.6167821884155 and batch: 300, loss is 3.8541841983795164 and perplexity is 47.19010347085262
At time: 478.65409207344055 and batch: 350, loss is 3.8743538808822633 and perplexity is 48.151576583836516
At time: 479.69202399253845 and batch: 400, loss is 3.8220504093170167 and perplexity is 45.69781154415184
At time: 480.7297818660736 and batch: 450, loss is 3.860096559524536 and perplexity is 47.4699348218981
At time: 481.76865005493164 and batch: 500, loss is 3.883477125167847 and perplexity is 48.59288520194032
At time: 482.80733346939087 and batch: 550, loss is 3.841742925643921 and perplexity is 46.60663559066561
At time: 483.84490728378296 and batch: 600, loss is 3.812622656822205 and perplexity is 45.26900838845674
At time: 484.8831479549408 and batch: 650, loss is 3.8556695318222047 and perplexity is 47.260248591252115
At time: 485.9188976287842 and batch: 700, loss is 3.876610975265503 and perplexity is 48.260381982723175
At time: 486.95999336242676 and batch: 750, loss is 3.83439266204834 and perplexity is 46.265320448569746
At time: 487.9995102882385 and batch: 800, loss is 3.79626229763031 and perplexity is 44.534416628565246
At time: 489.08346366882324 and batch: 850, loss is 3.807596011161804 and perplexity is 45.04202807661893
At time: 490.1206169128418 and batch: 900, loss is 3.784917936325073 and perplexity is 44.03205697806988
At time: 491.1587116718292 and batch: 950, loss is 3.8740814399719237 and perplexity is 48.13845991131796
At time: 492.1951148509979 and batch: 1000, loss is 3.8326397514343262 and perplexity is 46.184292515404586
At time: 493.23188519477844 and batch: 1050, loss is 3.796506791114807 and perplexity is 44.54530633444361
At time: 494.26930046081543 and batch: 1100, loss is 3.8253032541275025 and perplexity is 45.846701459895016
At time: 495.3079423904419 and batch: 1150, loss is 3.782943077087402 and perplexity is 43.945185671128264
At time: 496.34730410575867 and batch: 1200, loss is 3.8393068361282348 and perplexity is 46.49323583639921
At time: 497.3846163749695 and batch: 1250, loss is 3.826952419281006 and perplexity is 45.92237262231732
At time: 498.42096400260925 and batch: 1300, loss is 3.8314111614227295 and perplexity is 46.127585796714506
At time: 499.45664644241333 and batch: 1350, loss is 3.7151896142959595 and perplexity is 41.06637311762412
At time: 500.49589824676514 and batch: 1400, loss is 3.727995729446411 and perplexity is 41.59565561351753
At time: 501.53473138809204 and batch: 1450, loss is 3.646183590888977 and perplexity is 38.32811081821921
At time: 502.5745587348938 and batch: 1500, loss is 3.6558545875549315 and perplexity is 38.70058002133939
At time: 503.61260986328125 and batch: 1550, loss is 3.670197720527649 and perplexity is 39.25966753513836
At time: 504.65189146995544 and batch: 1600, loss is 3.7675772190093992 and perplexity is 43.27509165425895
At time: 505.6896553039551 and batch: 1650, loss is 3.7017654943466187 and perplexity is 40.51877692088727
At time: 506.732061624527 and batch: 1700, loss is 3.7091959524154663 and perplexity is 40.8209713248347
At time: 507.7708430290222 and batch: 1750, loss is 3.7197416496276854 and perplexity is 41.25373481400515
At time: 508.8097379207611 and batch: 1800, loss is 3.656096868515015 and perplexity is 38.709957570977735
At time: 509.8493185043335 and batch: 1850, loss is 3.687640962600708 and perplexity is 39.950491004034866
At time: 510.88849997520447 and batch: 1900, loss is 3.7781379890441893 and perplexity is 43.734531695665915
At time: 511.9266450405121 and batch: 1950, loss is 3.716854338645935 and perplexity is 41.134794244274666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.484224257358285 and perplexity of 88.60818699583868
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 515.1641683578491 and batch: 50, loss is 3.8924229288101198 and perplexity is 49.029537803574854
At time: 516.2312109470367 and batch: 100, loss is 3.8839636707305907 and perplexity is 48.61653360716304
At time: 517.2635884284973 and batch: 150, loss is 3.8584105825424193 and perplexity is 47.38996903362701
At time: 518.2957751750946 and batch: 200, loss is 3.855055365562439 and perplexity is 47.23123185260225
At time: 519.3259086608887 and batch: 250, loss is 3.854635820388794 and perplexity is 47.211420373429
At time: 520.3552622795105 and batch: 300, loss is 3.864527177810669 and perplexity is 47.680722598429945
At time: 521.3859558105469 and batch: 350, loss is 3.886229090690613 and perplexity is 48.72679532017011
At time: 522.4174537658691 and batch: 400, loss is 3.837045316696167 and perplexity is 46.388209284652234
At time: 523.4500920772552 and batch: 450, loss is 3.876186103820801 and perplexity is 48.23988187977087
At time: 524.4860656261444 and batch: 500, loss is 3.8975525760650633 and perplexity is 49.28168820598143
At time: 525.5209765434265 and batch: 550, loss is 3.85667772769928 and perplexity is 47.30792020615614
At time: 526.5551097393036 and batch: 600, loss is 3.8259317445755006 and perplexity is 45.87552473046113
At time: 527.58717918396 and batch: 650, loss is 3.8663475036621096 and perplexity is 47.76759609543886
At time: 528.6197564601898 and batch: 700, loss is 3.8843993759155273 and perplexity is 48.63772069825687
At time: 529.6526288986206 and batch: 750, loss is 3.840332226753235 and perplexity is 46.5409340150051
At time: 530.6844317913055 and batch: 800, loss is 3.799224033355713 and perplexity is 44.66651131952685
At time: 531.717273235321 and batch: 850, loss is 3.8116996049880982 and perplexity is 45.227242026459614
At time: 532.7523844242096 and batch: 900, loss is 3.7804675340652465 and perplexity is 43.836532017268716
At time: 533.7836940288544 and batch: 950, loss is 3.8745996236801146 and perplexity is 48.16341094103164
At time: 534.8202140331268 and batch: 1000, loss is 3.8316219806671143 and perplexity is 46.137311404634104
At time: 535.8591854572296 and batch: 1050, loss is 3.796438283920288 and perplexity is 44.54225476500607
At time: 536.8968150615692 and batch: 1100, loss is 3.8196115732192992 and perplexity is 45.586497864854636
At time: 537.9306037425995 and batch: 1150, loss is 3.7756104707717895 and perplexity is 43.62413144576765
At time: 538.9642901420593 and batch: 1200, loss is 3.830696029663086 and perplexity is 46.094610287437916
At time: 539.9976749420166 and batch: 1250, loss is 3.815829916000366 and perplexity is 45.414430910298314
At time: 541.0293264389038 and batch: 1300, loss is 3.8198950910568237 and perplexity is 45.59942428249799
At time: 542.0605366230011 and batch: 1350, loss is 3.7010418224334716 and perplexity is 40.489465227378425
At time: 543.0948004722595 and batch: 1400, loss is 3.7140420627593995 and perplexity is 41.01927436734226
At time: 544.1284694671631 and batch: 1450, loss is 3.6297847604751587 and perplexity is 37.70470020197065
At time: 545.1628556251526 and batch: 1500, loss is 3.6374354410171508 and perplexity is 37.99427312063384
At time: 546.1998362541199 and batch: 1550, loss is 3.6531237459182737 and perplexity is 38.59503903949739
At time: 547.236319065094 and batch: 1600, loss is 3.7457913827896117 and perplexity is 42.34250309127667
At time: 548.2676491737366 and batch: 1650, loss is 3.677587103843689 and perplexity is 39.550846759931915
At time: 549.299174785614 and batch: 1700, loss is 3.681889214515686 and perplexity is 39.721365411921845
At time: 550.3319990634918 and batch: 1750, loss is 3.6905039739608765 and perplexity is 40.0650336037653
At time: 551.3646755218506 and batch: 1800, loss is 3.625730109214783 and perplexity is 37.552130309650934
At time: 552.3998076915741 and batch: 1850, loss is 3.655030527114868 and perplexity is 38.66870154103754
At time: 553.4371764659882 and batch: 1900, loss is 3.74663076877594 and perplexity is 42.37805971577604
At time: 554.4692406654358 and batch: 1950, loss is 3.6908775901794435 and perplexity is 40.080005346785946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.476127305141715 and perplexity of 87.89362752061008
finished 13 epochs...
Completing Train Step...
At time: 557.7313511371613 and batch: 50, loss is 3.8911013078689574 and perplexity is 48.964782140324075
At time: 558.7919359207153 and batch: 100, loss is 3.8778233766555785 and perplexity is 48.31892842064443
At time: 559.8258874416351 and batch: 150, loss is 3.8456669425964356 and perplexity is 46.78988011099335
At time: 560.8603639602661 and batch: 200, loss is 3.8398002433776854 and perplexity is 46.51618159634794
At time: 561.8931751251221 and batch: 250, loss is 3.838736128807068 and perplexity is 46.466709376465076
At time: 562.9248960018158 and batch: 300, loss is 3.8484969472885133 and perplexity is 46.922483236482165
At time: 563.9618856906891 and batch: 350, loss is 3.8693619775772095 and perplexity is 47.911807519438824
At time: 564.997932434082 and batch: 400, loss is 3.8187763547897338 and perplexity is 45.54843907761127
At time: 566.0318820476532 and batch: 450, loss is 3.8586960649490356 and perplexity is 47.403499967366066
At time: 567.0712938308716 and batch: 500, loss is 3.8808730602264405 and perplexity is 48.46651078818803
At time: 568.132157087326 and batch: 550, loss is 3.8409287452697756 and perplexity is 46.56870482600015
At time: 569.1650114059448 and batch: 600, loss is 3.810947856903076 and perplexity is 45.193255310200385
At time: 570.2065236568451 and batch: 650, loss is 3.852308974266052 and perplexity is 47.10169437025314
At time: 571.247526884079 and batch: 700, loss is 3.870663266181946 and perplexity is 47.97419519197617
At time: 572.2864599227905 and batch: 750, loss is 3.827910976409912 and perplexity is 45.96641294418084
At time: 573.3227517604828 and batch: 800, loss is 3.7874654483795167 and perplexity is 44.14437217542095
At time: 574.3596909046173 and batch: 850, loss is 3.8001543426513673 and perplexity is 44.70808432509025
At time: 575.3951961994171 and batch: 900, loss is 3.7706845664978026 and perplexity is 43.40977154185847
At time: 576.4312906265259 and batch: 950, loss is 3.864663667678833 and perplexity is 47.68723097812519
At time: 577.4654235839844 and batch: 1000, loss is 3.8223816347122193 and perplexity is 45.71295032687668
At time: 578.4997880458832 and batch: 1050, loss is 3.787718958854675 and perplexity is 44.155564654832155
At time: 579.5342085361481 and batch: 1100, loss is 3.8118719244003296 and perplexity is 45.23503622974943
At time: 580.5698096752167 and batch: 1150, loss is 3.7686871004104616 and perplexity is 43.323148537402496
At time: 581.6048474311829 and batch: 1200, loss is 3.8247386264801024 and perplexity is 45.82082245139804
At time: 582.6414103507996 and batch: 1250, loss is 3.8110310077667235 and perplexity is 45.197013324649376
At time: 583.6802949905396 and batch: 1300, loss is 3.815262670516968 and perplexity is 45.388677084544575
At time: 584.7161259651184 and batch: 1350, loss is 3.697137188911438 and perplexity is 40.33167695731881
At time: 585.7505567073822 and batch: 1400, loss is 3.711394500732422 and perplexity is 40.91081693140105
At time: 586.7846436500549 and batch: 1450, loss is 3.628852047920227 and perplexity is 37.66954895026756
At time: 587.8198359012604 and batch: 1500, loss is 3.6379955291748045 and perplexity is 38.01555922355801
At time: 588.8546397686005 and batch: 1550, loss is 3.654963355064392 and perplexity is 38.666104172302056
At time: 589.8898975849152 and batch: 1600, loss is 3.747915258407593 and perplexity is 42.432528869132774
At time: 590.9224350452423 and batch: 1650, loss is 3.6804435729980467 and perplexity is 39.66398404338274
At time: 591.9575352668762 and batch: 1700, loss is 3.685731291770935 and perplexity is 39.87427151695829
At time: 592.9904942512512 and batch: 1750, loss is 3.6954157733917237 and perplexity is 40.26230910524658
At time: 594.0241453647614 and batch: 1800, loss is 3.6310431289672853 and perplexity is 37.752176473767314
At time: 595.0630888938904 and batch: 1850, loss is 3.660480751991272 and perplexity is 38.88003003088603
At time: 596.1045105457306 and batch: 1900, loss is 3.7518649816513063 and perplexity is 42.60045703126841
At time: 597.1424717903137 and batch: 1950, loss is 3.695970072746277 and perplexity is 40.284632663591864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475674509447674 and perplexity of 87.85383867332423
finished 14 epochs...
Completing Train Step...
At time: 600.4464960098267 and batch: 50, loss is 3.8873305702209473 and perplexity is 48.78049645771651
At time: 601.4856915473938 and batch: 100, loss is 3.872727189064026 and perplexity is 48.07331248121812
At time: 602.5236067771912 and batch: 150, loss is 3.8396586084365847 and perplexity is 46.50959374625321
At time: 603.5618515014648 and batch: 200, loss is 3.8331225872039796 and perplexity is 46.20659732817455
At time: 604.6009340286255 and batch: 250, loss is 3.831512861251831 and perplexity is 46.132277202860465
At time: 605.6384143829346 and batch: 300, loss is 3.840864591598511 and perplexity is 46.56571736844873
At time: 606.6765785217285 and batch: 350, loss is 3.861778826713562 and perplexity is 47.54985914389747
At time: 607.7158887386322 and batch: 400, loss is 3.810653066635132 and perplexity is 45.17993474184164
At time: 608.7553493976593 and batch: 450, loss is 3.850834832191467 and perplexity is 47.03231093388386
At time: 609.7939450740814 and batch: 500, loss is 3.8730859088897707 and perplexity is 48.09056042489907
At time: 610.8324227333069 and batch: 550, loss is 3.833417286872864 and perplexity is 46.220216403777414
At time: 611.8704829216003 and batch: 600, loss is 3.803702087402344 and perplexity is 44.866978888597224
At time: 612.9091799259186 and batch: 650, loss is 3.8454528284072875 and perplexity is 46.779862806214865
At time: 613.9483735561371 and batch: 700, loss is 3.864176058769226 and perplexity is 47.663983927620855
At time: 614.9881408214569 and batch: 750, loss is 3.821871771812439 and perplexity is 45.68964893022913
At time: 616.0273950099945 and batch: 800, loss is 3.7814426469802855 and perplexity is 43.87929843344296
At time: 617.0651924610138 and batch: 850, loss is 3.794290976524353 and perplexity is 44.44671146904253
At time: 618.1141016483307 and batch: 900, loss is 3.7656015062332155 and perplexity is 43.18967690807405
At time: 619.1619622707367 and batch: 950, loss is 3.8596899271011353 and perplexity is 47.450635931306046
At time: 620.2283937931061 and batch: 1000, loss is 3.8175692319869996 and perplexity is 45.49348969017346
At time: 621.2674598693848 and batch: 1050, loss is 3.7831361293792725 and perplexity is 43.95367020889212
At time: 622.308828830719 and batch: 1100, loss is 3.807551050186157 and perplexity is 45.040002988616784
At time: 623.3531267642975 and batch: 1150, loss is 3.764860944747925 and perplexity is 43.15770413715638
At time: 624.3950452804565 and batch: 1200, loss is 3.8213890171051026 and perplexity is 45.667597360309365
At time: 625.4319505691528 and batch: 1250, loss is 3.808285188674927 and perplexity is 45.07308072868046
At time: 626.4826509952545 and batch: 1300, loss is 3.812738914489746 and perplexity is 45.274271563720205
At time: 627.5295910835266 and batch: 1350, loss is 3.694874939918518 and perplexity is 40.24053978809225
At time: 628.5726110935211 and batch: 1400, loss is 3.7097213459014893 and perplexity is 40.84242403232481
At time: 629.6120176315308 and batch: 1450, loss is 3.6278627490997315 and perplexity is 37.63230093766785
At time: 630.6592409610748 and batch: 1500, loss is 3.637634444236755 and perplexity is 38.001834855691236
At time: 631.6977298259735 and batch: 1550, loss is 3.6551244497299193 and perplexity is 38.67233357716941
At time: 632.7336981296539 and batch: 1600, loss is 3.748288426399231 and perplexity is 42.44836628553565
At time: 633.7786598205566 and batch: 1650, loss is 3.68115864276886 and perplexity is 39.692356702368585
At time: 634.8164367675781 and batch: 1700, loss is 3.686891622543335 and perplexity is 39.920565714323246
At time: 635.8650960922241 and batch: 1750, loss is 3.6971318101882935 and perplexity is 40.33146002497791
At time: 636.9030818939209 and batch: 1800, loss is 3.6329222440719606 and perplexity is 37.823183853439026
At time: 637.9534358978271 and batch: 1850, loss is 3.6624469423294066 and perplexity is 38.95655077279903
At time: 639.0002272129059 and batch: 1900, loss is 3.7536749410629273 and perplexity is 42.677631950078386
At time: 640.048184633255 and batch: 1950, loss is 3.6976938247680664 and perplexity is 40.35413326428421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475755700399709 and perplexity of 87.86097189969887
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 643.3596303462982 and batch: 50, loss is 3.885625443458557 and perplexity is 48.69739040104007
At time: 644.4290544986725 and batch: 100, loss is 3.874355983734131 and perplexity is 48.15167783957573
At time: 645.4708516597748 and batch: 150, loss is 3.842129878997803 and perplexity is 46.62467367434398
At time: 646.5375761985779 and batch: 200, loss is 3.83545437335968 and perplexity is 46.31446694769316
At time: 647.5752074718475 and batch: 250, loss is 3.8354217863082884 and perplexity is 46.31295772036933
At time: 648.6128354072571 and batch: 300, loss is 3.8434478044509888 and perplexity is 46.6861620281591
At time: 649.652220249176 and batch: 350, loss is 3.8651581048965453 and perplexity is 47.7108151498961
At time: 650.6887152194977 and batch: 400, loss is 3.8141936349868772 and perplexity is 45.34018090276668
At time: 651.7237257957458 and batch: 450, loss is 3.855192222595215 and perplexity is 47.237696221185004
At time: 652.7590951919556 and batch: 500, loss is 3.8770378494262694 and perplexity is 48.28098749044683
At time: 653.7956295013428 and batch: 550, loss is 3.838319878578186 and perplexity is 46.44737162300309
At time: 654.836416721344 and batch: 600, loss is 3.8074334383010866 and perplexity is 45.034706060458674
At time: 655.8736550807953 and batch: 650, loss is 3.8498148107528687 and perplexity is 46.98436142734419
At time: 656.9110326766968 and batch: 700, loss is 3.8672335290908815 and perplexity is 47.80993815555169
At time: 657.9482250213623 and batch: 750, loss is 3.8237952852249144 and perplexity is 45.77761816063186
At time: 658.9850101470947 and batch: 800, loss is 3.781232557296753 and perplexity is 43.870080813818745
At time: 660.0191013813019 and batch: 850, loss is 3.7962524366378783 and perplexity is 44.53397747718515
At time: 661.0536398887634 and batch: 900, loss is 3.763485326766968 and perplexity is 43.0983764388084
At time: 662.0971641540527 and batch: 950, loss is 3.8599406337738036 and perplexity is 47.462533613708246
At time: 663.1339676380157 and batch: 1000, loss is 3.8169325542449952 and perplexity is 45.46453421651253
At time: 664.1733434200287 and batch: 1050, loss is 3.782650423049927 and perplexity is 43.9323268168036
At time: 665.2125399112701 and batch: 1100, loss is 3.8035536718368532 and perplexity is 44.86032042467568
At time: 666.2587153911591 and batch: 1150, loss is 3.7620466566085815 and perplexity is 43.03641667127215
At time: 667.3049929141998 and batch: 1200, loss is 3.8181999588012694 and perplexity is 45.52219270492475
At time: 668.3476524353027 and batch: 1250, loss is 3.8045324993133547 and perplexity is 44.904252436334446
At time: 669.3815906047821 and batch: 1300, loss is 3.8070321083068848 and perplexity is 45.01663590842609
At time: 670.4179975986481 and batch: 1350, loss is 3.6880278301239016 and perplexity is 39.965949541550216
At time: 671.455495595932 and batch: 1400, loss is 3.7028243780136108 and perplexity is 40.56170431552284
At time: 672.4936051368713 and batch: 1450, loss is 3.6188654947280883 and perplexity is 37.29523217406795
At time: 673.5300397872925 and batch: 1500, loss is 3.6274499464035035 and perplexity is 37.61676942832054
At time: 674.5712320804596 and batch: 1550, loss is 3.645113697052002 and perplexity is 38.28712573742413
At time: 675.6084361076355 and batch: 1600, loss is 3.7379528522491454 and perplexity is 42.011897511372766
At time: 676.6506350040436 and batch: 1650, loss is 3.670512719154358 and perplexity is 39.27203622445478
At time: 677.6928861141205 and batch: 1700, loss is 3.675681834220886 and perplexity is 39.475563473297164
At time: 678.732335805893 and batch: 1750, loss is 3.6867176151275634 and perplexity is 39.91361984418114
At time: 679.767660856247 and batch: 1800, loss is 3.622930464744568 and perplexity is 37.44714472541306
At time: 680.8037917613983 and batch: 1850, loss is 3.651703963279724 and perplexity is 38.54028135433861
At time: 681.8390855789185 and batch: 1900, loss is 3.7423059701919557 and perplexity is 42.19517888954279
At time: 682.8807377815247 and batch: 1950, loss is 3.6880520296096804 and perplexity is 39.96691670868021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47450320221657 and perplexity of 87.75099507928672
finished 16 epochs...
Completing Train Step...
At time: 686.1714344024658 and batch: 50, loss is 3.884651737213135 and perplexity is 48.64999652547165
At time: 687.2333543300629 and batch: 100, loss is 3.871466012001038 and perplexity is 48.01272173803385
At time: 688.2667229175568 and batch: 150, loss is 3.8381156396865843 and perplexity is 46.43788623198084
At time: 689.2995209693909 and batch: 200, loss is 3.8314316034317017 and perplexity is 46.1285287468751
At time: 690.3328931331635 and batch: 250, loss is 3.830532569885254 and perplexity is 46.08707628845076
At time: 691.3698353767395 and batch: 300, loss is 3.83900194644928 and perplexity is 46.47906268938439
At time: 692.4074926376343 and batch: 350, loss is 3.8606220436096192 and perplexity is 47.49488607233529
At time: 693.4449026584625 and batch: 400, loss is 3.809238381385803 and perplexity is 45.11606454336268
At time: 694.4803414344788 and batch: 450, loss is 3.8502642250061037 and perplexity is 47.005481614549886
At time: 695.5127141475677 and batch: 500, loss is 3.872126064300537 and perplexity is 48.0444231065519
At time: 696.5588326454163 and batch: 550, loss is 3.8334226417541504 and perplexity is 46.22046390821196
At time: 697.5965082645416 and batch: 600, loss is 3.8028813791275025 and perplexity is 44.83017129397097
At time: 698.6572134494781 and batch: 650, loss is 3.8451788234710693 and perplexity is 46.767046648815736
At time: 699.6929519176483 and batch: 700, loss is 3.8631731128692626 and perplexity is 47.61620349496444
At time: 700.726663351059 and batch: 750, loss is 3.8203183603286743 and perplexity is 45.61872920291244
At time: 701.7585966587067 and batch: 800, loss is 3.778258261680603 and perplexity is 43.739792079429044
At time: 702.7911667823792 and batch: 850, loss is 3.792798171043396 and perplexity is 44.3804106739586
At time: 703.8321905136108 and batch: 900, loss is 3.760676693916321 and perplexity is 42.97749875291371
At time: 704.8669707775116 and batch: 950, loss is 3.8568520307540894 and perplexity is 47.31616683985061
At time: 705.9021592140198 and batch: 1000, loss is 3.8142464637756346 and perplexity is 45.34257623287645
At time: 706.9369235038757 and batch: 1050, loss is 3.7801933813095094 and perplexity is 43.82451575843473
At time: 707.9718463420868 and batch: 1100, loss is 3.8019235849380495 and perplexity is 44.78725377275059
At time: 709.0068566799164 and batch: 1150, loss is 3.7603671455383303 and perplexity is 42.964197196728435
At time: 710.0406501293182 and batch: 1200, loss is 3.816666088104248 and perplexity is 45.45242107148216
At time: 711.0830907821655 and batch: 1250, loss is 3.803173694610596 and perplexity is 44.843277762668464
At time: 712.1192502975464 and batch: 1300, loss is 3.806023259162903 and perplexity is 44.97124381456237
At time: 713.1545376777649 and batch: 1350, loss is 3.6873704099655153 and perplexity is 39.93968375544719
At time: 714.1876142024994 and batch: 1400, loss is 3.702449026107788 and perplexity is 40.54648225949718
At time: 715.2283568382263 and batch: 1450, loss is 3.6194875335693357 and perplexity is 37.318438473935224
At time: 716.2631740570068 and batch: 1500, loss is 3.628435506820679 and perplexity is 37.653861302430194
At time: 717.2964432239532 and batch: 1550, loss is 3.646591262817383 and perplexity is 38.34373929849852
At time: 718.3352129459381 and batch: 1600, loss is 3.739723048210144 and perplexity is 42.08633266562853
At time: 719.3721165657043 and batch: 1650, loss is 3.6723946475982667 and perplexity is 39.34601297411715
At time: 720.40696144104 and batch: 1700, loss is 3.677809228897095 and perplexity is 39.559632969663234
At time: 721.4395079612732 and batch: 1750, loss is 3.6890394258499146 and perplexity is 40.006399381285554
At time: 722.4727075099945 and batch: 1800, loss is 3.625452089309692 and perplexity is 37.54169152110903
At time: 723.508407831192 and batch: 1850, loss is 3.654066381454468 and perplexity is 38.63143724724368
At time: 724.5402143001556 and batch: 1900, loss is 3.744417042732239 and perplexity is 42.284350063320126
At time: 725.5760140419006 and batch: 1950, loss is 3.6899990701675414 and perplexity is 40.04480972230553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4741724768350295 and perplexity of 87.7219783964998
finished 17 epochs...
Completing Train Step...
At time: 728.8691763877869 and batch: 50, loss is 3.883686413764954 and perplexity is 48.603056203013765
At time: 729.9038829803467 and batch: 100, loss is 3.8695354890823364 and perplexity is 47.92012149053883
At time: 730.9353928565979 and batch: 150, loss is 3.8358337450027467 and perplexity is 46.332040676393255
At time: 731.9687032699585 and batch: 200, loss is 3.828993124961853 and perplexity is 46.016182355477625
At time: 733.0095591545105 and batch: 250, loss is 3.8277460765838622 and perplexity is 45.95883371560611
At time: 734.0427122116089 and batch: 300, loss is 3.8361936473846434 and perplexity is 46.34871868923908
At time: 735.0776727199554 and batch: 350, loss is 3.8578279876708983 and perplexity is 47.36236792162032
At time: 736.1149175167084 and batch: 400, loss is 3.8061974620819092 and perplexity is 44.97907861890929
At time: 737.1544835567474 and batch: 450, loss is 3.847210464477539 and perplexity is 46.86215708095145
At time: 738.1861672401428 and batch: 500, loss is 3.8691749572753906 and perplexity is 47.90284787657952
At time: 739.2239637374878 and batch: 550, loss is 3.8304625797271727 and perplexity is 46.08385075957479
At time: 740.2629330158234 and batch: 600, loss is 3.8001499605178832 and perplexity is 44.707888408726184
At time: 741.2990107536316 and batch: 650, loss is 3.8425086879730226 and perplexity is 46.64233886485363
At time: 742.3335337638855 and batch: 700, loss is 3.8606888580322267 and perplexity is 47.49805952173994
At time: 743.3731484413147 and batch: 750, loss is 3.8180665493011476 and perplexity is 45.51612001703767
At time: 744.4033079147339 and batch: 800, loss is 3.776274127960205 and perplexity is 43.65309252324067
At time: 745.4360122680664 and batch: 850, loss is 3.7906072759628295 and perplexity is 44.283284286252744
At time: 746.4692175388336 and batch: 900, loss is 3.7588922071456907 and perplexity is 42.90087436289302
At time: 747.5041692256927 and batch: 950, loss is 3.8550230884552 and perplexity is 47.22970738966947
At time: 748.542364358902 and batch: 1000, loss is 3.8126108551025393 and perplexity is 45.26847413946274
At time: 749.5890998840332 and batch: 1050, loss is 3.7786991357803346 and perplexity is 43.75908007236035
At time: 750.6553587913513 and batch: 1100, loss is 3.800781307220459 and perplexity is 44.73612349877979
At time: 751.692057132721 and batch: 1150, loss is 3.7593129301071166 and perplexity is 42.91892754323019
At time: 752.7324872016907 and batch: 1200, loss is 3.8157525730133055 and perplexity is 45.410918558385696
At time: 753.7667987346649 and batch: 1250, loss is 3.8024285984039308 and perplexity is 44.80987765120647
At time: 754.8131995201111 and batch: 1300, loss is 3.8054672479629517 and perplexity is 44.946246249432825
At time: 755.8526041507721 and batch: 1350, loss is 3.687001953125 and perplexity is 39.924970416541115
At time: 756.8860325813293 and batch: 1400, loss is 3.7022870445251463 and perplexity is 40.539915008031485
At time: 757.9277813434601 and batch: 1450, loss is 3.6198557090759276 and perplexity is 37.332180738552964
At time: 758.9615669250488 and batch: 1500, loss is 3.6290896463394167 and perplexity is 37.678500238913635
At time: 759.995813369751 and batch: 1550, loss is 3.647516646385193 and perplexity is 38.37923838737725
At time: 761.0312638282776 and batch: 1600, loss is 3.7407415199279783 and perplexity is 42.129218240321265
At time: 762.0639355182648 and batch: 1650, loss is 3.67347195148468 and perplexity is 39.38842342718025
At time: 763.1019148826599 and batch: 1700, loss is 3.6789809036254884 and perplexity is 39.606011156647384
At time: 764.1366930007935 and batch: 1750, loss is 3.690368628501892 and perplexity is 40.05961135034995
At time: 765.1718184947968 and batch: 1800, loss is 3.6268813228607177 and perplexity is 37.595385727833985
At time: 766.2073585987091 and batch: 1850, loss is 3.655403175354004 and perplexity is 38.6831140498077
At time: 767.2512629032135 and batch: 1900, loss is 3.7456095027923584 and perplexity is 42.334802537240336
At time: 768.2862498760223 and batch: 1950, loss is 3.6910914850234984 and perplexity is 40.08857917019494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474064600744913 and perplexity of 87.71251580285605
finished 18 epochs...
Completing Train Step...
At time: 771.5449523925781 and batch: 50, loss is 3.882619848251343 and perplexity is 48.551245494080725
At time: 772.6085667610168 and batch: 100, loss is 3.8678920602798463 and perplexity is 47.841432859954
At time: 773.6449677944183 and batch: 150, loss is 3.834004406929016 and perplexity is 46.24736118767152
At time: 774.6897933483124 and batch: 200, loss is 3.8270444869995117 and perplexity is 45.92660078502869
At time: 775.7352590560913 and batch: 250, loss is 3.8255953550338746 and perplexity is 45.860095279023746
At time: 776.8288443088531 and batch: 300, loss is 3.8339881038665773 and perplexity is 46.24660722020046
At time: 777.8758738040924 and batch: 350, loss is 3.855657992362976 and perplexity is 47.25970323668692
At time: 778.9154603481293 and batch: 400, loss is 3.8038781595230104 and perplexity is 44.874879408228246
At time: 779.9570593833923 and batch: 450, loss is 3.844902639389038 and perplexity is 46.754132118443664
At time: 780.9992642402649 and batch: 500, loss is 3.8669467067718504 and perplexity is 47.796227164620284
At time: 782.0400667190552 and batch: 550, loss is 3.8282493782043456 and perplexity is 45.98197069304142
At time: 783.0777812004089 and batch: 600, loss is 3.798090615272522 and perplexity is 44.61591416716455
At time: 784.1150300502777 and batch: 650, loss is 3.840525441169739 and perplexity is 46.54992726319898
At time: 785.1521098613739 and batch: 700, loss is 3.858817219734192 and perplexity is 47.40924347614003
At time: 786.1932141780853 and batch: 750, loss is 3.8163203620910644 and perplexity is 45.43670970322643
At time: 787.2325048446655 and batch: 800, loss is 3.7746782398223875 and perplexity is 43.58348263027889
At time: 788.2693629264832 and batch: 850, loss is 3.7889278507232667 and perplexity is 44.208976235804684
At time: 789.3165974617004 and batch: 900, loss is 3.7575009870529175 and perplexity is 42.84123130241378
At time: 790.3559792041779 and batch: 950, loss is 3.85366304397583 and perplexity is 47.16551654796643
At time: 791.4000101089478 and batch: 1000, loss is 3.8113734531402588 and perplexity is 45.212493483163065
At time: 792.4452712535858 and batch: 1050, loss is 3.777545523643494 and perplexity is 43.70862817304878
At time: 793.4894843101501 and batch: 1100, loss is 3.7998072910308838 and perplexity is 44.692571004093814
At time: 794.5256109237671 and batch: 1150, loss is 3.7584543132781985 and perplexity is 42.88209244564277
At time: 795.5621843338013 and batch: 1200, loss is 3.8150165843963624 and perplexity is 45.377508935301044
At time: 796.5999383926392 and batch: 1250, loss is 3.801835322380066 and perplexity is 44.783300909615015
At time: 797.6388885974884 and batch: 1300, loss is 3.804993395805359 and perplexity is 44.92495341889709
At time: 798.6754777431488 and batch: 1350, loss is 3.6866466665267943 and perplexity is 39.91078812915587
At time: 799.711715221405 and batch: 1400, loss is 3.702099151611328 and perplexity is 40.532298560835315
At time: 800.7556462287903 and batch: 1450, loss is 3.619985752105713 and perplexity is 37.33703584412419
At time: 801.7899253368378 and batch: 1500, loss is 3.6294337368011473 and perplexity is 37.69146728224818
At time: 802.8268413543701 and batch: 1550, loss is 3.6480375480651857 and perplexity is 38.399235404917924
At time: 803.8675351142883 and batch: 1600, loss is 3.7413089513778686 and perplexity is 42.15313046734333
At time: 804.9043989181519 and batch: 1650, loss is 3.6741047525405883 and perplexity is 39.41335635107381
At time: 805.9499931335449 and batch: 1700, loss is 3.6796812772750855 and perplexity is 39.63375987932995
At time: 806.9886474609375 and batch: 1750, loss is 3.691191830635071 and perplexity is 40.09260208502639
At time: 808.0236055850983 and batch: 1800, loss is 3.627752923965454 and perplexity is 37.62816819210802
At time: 809.0593345165253 and batch: 1850, loss is 3.65623384475708 and perplexity is 38.71526027866051
At time: 810.0964307785034 and batch: 1900, loss is 3.746350646018982 and perplexity is 42.36619031937556
At time: 811.1346571445465 and batch: 1950, loss is 3.691760611534119 and perplexity is 40.11541247772837
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474043593295785 and perplexity of 87.71067320599664
finished 19 epochs...
Completing Train Step...
At time: 814.3813691139221 and batch: 50, loss is 3.881514563560486 and perplexity is 48.497612191208475
At time: 815.4458022117615 and batch: 100, loss is 3.8664024877548218 and perplexity is 47.77022262557924
At time: 816.4833660125732 and batch: 150, loss is 3.8323979234695433 and perplexity is 46.173125212278165
At time: 817.5184020996094 and batch: 200, loss is 3.8253477144241335 and perplexity is 45.848739863155146
At time: 818.5517494678497 and batch: 250, loss is 3.8237604761123656 and perplexity is 45.77602471010255
At time: 819.5831961631775 and batch: 300, loss is 3.832105040550232 and perplexity is 46.159603872753614
At time: 820.6157841682434 and batch: 350, loss is 3.853815670013428 and perplexity is 47.1727157832498
At time: 821.6471059322357 and batch: 400, loss is 3.801938576698303 and perplexity is 44.78792521755462
At time: 822.6791763305664 and batch: 450, loss is 3.8429891538619994 and perplexity is 46.66475430215558
At time: 823.7137246131897 and batch: 500, loss is 3.8650891065597532 and perplexity is 47.70752329657127
At time: 824.7549922466278 and batch: 550, loss is 3.826422066688538 and perplexity is 45.898024030184985
At time: 825.793160200119 and batch: 600, loss is 3.7963748502731325 and perplexity is 44.53942937694708
At time: 826.8274927139282 and batch: 650, loss is 3.8388776683807375 and perplexity is 46.47328672016627
At time: 827.8631551265717 and batch: 700, loss is 3.857258062362671 and perplexity is 47.33538260002351
At time: 828.9315564632416 and batch: 750, loss is 3.8148526430130003 and perplexity is 45.37007029347994
At time: 829.96262383461 and batch: 800, loss is 3.773295593261719 and perplexity is 43.523263718247414
At time: 831.0012094974518 and batch: 850, loss is 3.7875176572799685 and perplexity is 44.1466769647181
At time: 832.040206193924 and batch: 900, loss is 3.756308937072754 and perplexity is 42.790192839732505
At time: 833.0791344642639 and batch: 950, loss is 3.8525195598602293 and perplexity is 47.11161435301493
At time: 834.1172661781311 and batch: 1000, loss is 3.810302691459656 and perplexity is 45.16410758716143
At time: 835.1546936035156 and batch: 1050, loss is 3.776548728942871 and perplexity is 43.66508135134062
At time: 836.1919214725494 and batch: 1100, loss is 3.7989184045791626 and perplexity is 44.65286203423292
At time: 837.229868888855 and batch: 1150, loss is 3.757679500579834 and perplexity is 42.8488797243641
At time: 838.2682716846466 and batch: 1200, loss is 3.8143474531173704 and perplexity is 45.34715558103161
At time: 839.3085973262787 and batch: 1250, loss is 3.8012869930267335 and perplexity is 44.75875164234417
At time: 840.3464572429657 and batch: 1300, loss is 3.80453360080719 and perplexity is 44.90430189811892
At time: 841.3783273696899 and batch: 1350, loss is 3.6862674713134767 and perplexity is 39.89565701834126
At time: 842.4099798202515 and batch: 1400, loss is 3.701862268447876 and perplexity is 40.52269827884773
At time: 843.4408254623413 and batch: 1450, loss is 3.6199602127075194 and perplexity is 37.336082290875034
At time: 844.4744141101837 and batch: 1500, loss is 3.629573493003845 and perplexity is 37.696735266697836
At time: 845.5045642852783 and batch: 1550, loss is 3.648304738998413 and perplexity is 38.40949670326288
At time: 846.5364179611206 and batch: 1600, loss is 3.741611523628235 and perplexity is 42.16588676464229
At time: 847.5683999061584 and batch: 1650, loss is 3.6744770860671996 and perplexity is 39.428033997359925
At time: 848.6019654273987 and batch: 1700, loss is 3.6801144218444826 and perplexity is 39.65093074565176
At time: 849.630429983139 and batch: 1750, loss is 3.6917261505126953 and perplexity is 40.114030083459056
At time: 850.6610813140869 and batch: 1800, loss is 3.6283118677139283 and perplexity is 37.649206100441496
At time: 851.6924567222595 and batch: 1850, loss is 3.656782670021057 and perplexity is 38.73651402336542
At time: 852.7233526706696 and batch: 1900, loss is 3.7468376398086547 and perplexity is 42.38682741561418
At time: 853.7575695514679 and batch: 1950, loss is 3.6921942234039307 and perplexity is 40.13281076852121
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474065168513808 and perplexity of 87.71256560330836
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f31229a0b38>
ELAPSED
2650.8964281082153


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.77128768299961}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.13481025420142356, 'wordvec_source': 'None', 'rnn_dropout': 0.7333439966881319, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.4361717208564}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.049255346069296047, 'wordvec_source': 'None', 'rnn_dropout': 0.9817036371865334, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -87.71067320599664}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.9986437985159311, 'wordvec_source': 'None', 'rnn_dropout': 0.5007125478907719, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4957637786865234 and batch: 50, loss is 12.778175449371338 and perplexity is 354397.8564741749
At time: 2.5174617767333984 and batch: 100, loss is 12.733549747467041 and perplexity is 338930.2955816253
At time: 3.5688557624816895 and batch: 150, loss is 12.617919502258301 and perplexity is 301920.646609449
At time: 4.592331171035767 and batch: 200, loss is 12.460168075561523 and perplexity is 257858.967168772
At time: 5.613280534744263 and batch: 250, loss is 12.423878192901611 and perplexity is 248669.0544709083
At time: 6.63604211807251 and batch: 300, loss is 12.324926834106446 and perplexity is 225241.13853204003
At time: 7.658963441848755 and batch: 350, loss is 12.08298324584961 and perplexity is 176836.92264107993
At time: 8.690518617630005 and batch: 400, loss is 12.142686672210694 and perplexity is 187716.22729810665
At time: 9.717868328094482 and batch: 450, loss is 12.126646690368652 and perplexity is 184729.28173716032
At time: 10.742953538894653 and batch: 500, loss is 12.03645601272583 and perplexity is 168797.66240320008
At time: 11.766132831573486 and batch: 550, loss is 11.834367084503175 and perplexity is 137911.44903278057
At time: 12.789204835891724 and batch: 600, loss is 11.772574291229247 and perplexity is 129647.47188367385
At time: 13.811945915222168 and batch: 650, loss is 11.700003108978272 and perplexity is 120572.08984187547
At time: 14.835326910018921 and batch: 700, loss is 11.492898654937743 and perplexity is 98017.23945007515
At time: 15.864136695861816 and batch: 750, loss is 11.443315601348877 and perplexity is 93275.76516216995
At time: 16.902737379074097 and batch: 800, loss is 11.42063886642456 and perplexity is 91184.37789917341
At time: 17.93453049659729 and batch: 850, loss is 11.350880546569824 and perplexity is 85040.30049396261
At time: 18.959809064865112 and batch: 900, loss is 11.294530334472656 and perplexity is 80380.77699457089
At time: 19.986558437347412 and batch: 950, loss is 11.048605613708496 and perplexity is 62856.2475810216
At time: 21.011692762374878 and batch: 1000, loss is 10.96254747390747 and perplexity is 57673.17697198095
At time: 22.036277770996094 and batch: 1050, loss is 10.982625274658202 and perplexity is 58842.83026870337
At time: 23.067467212677002 and batch: 1100, loss is 10.829894695281983 and perplexity is 50508.38773743435
At time: 24.095377445220947 and batch: 1150, loss is 10.73600944519043 and perplexity is 45982.19085542565
At time: 25.119423627853394 and batch: 1200, loss is 10.715086269378663 and perplexity is 45030.09258551472
At time: 26.145506143569946 and batch: 1250, loss is 10.748083171844483 and perplexity is 46540.73231211228
At time: 27.16979718208313 and batch: 1300, loss is 10.537489967346191 and perplexity is 37702.81229529912
At time: 28.1938214302063 and batch: 1350, loss is 10.50855152130127 and perplexity is 36627.38711150125
At time: 29.218852281570435 and batch: 1400, loss is 10.463197917938233 and perplexity is 35003.31036787452
At time: 30.243576288223267 and batch: 1450, loss is 10.509654541015625 and perplexity is 36667.81013116596
At time: 31.272984266281128 and batch: 1500, loss is 10.460573120117187 and perplexity is 34911.554228428955
At time: 32.30225968360901 and batch: 1550, loss is 10.25845724105835 and perplexity is 28522.74850586882
At time: 33.32570552825928 and batch: 1600, loss is 10.239206829071044 and perplexity is 27978.92505287639
At time: 34.35004949569702 and batch: 1650, loss is 10.181267299652099 and perplexity is 26403.907766855213
At time: 35.373748779296875 and batch: 1700, loss is 10.125376873016357 and perplexity is 24968.663884619436
At time: 36.39800834655762 and batch: 1750, loss is 10.108469524383544 and perplexity is 24550.058703069724
At time: 37.42390704154968 and batch: 1800, loss is 10.049017868041993 and perplexity is 23133.055971307876
At time: 38.45423245429993 and batch: 1850, loss is 9.987104110717773 and perplexity is 21744.23862707237
At time: 39.486369609832764 and batch: 1900, loss is 9.998459625244141 and perplexity is 21992.56290121993
At time: 40.517415285110474 and batch: 1950, loss is 9.842528953552247 and perplexity is 18817.243832408836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 7.721205032703488 and perplexity of 2255.6761069657987
finished 1 epochs...
Completing Train Step...
At time: 43.83094596862793 and batch: 50, loss is 6.694674310684204 and perplexity is 808.0907048386034
At time: 44.869032859802246 and batch: 100, loss is 6.003711948394775 and perplexity is 404.9290831313522
At time: 45.906909465789795 and batch: 150, loss is 5.786926412582398 and perplexity is 326.0094643136946
At time: 46.94675970077515 and batch: 200, loss is 5.688639745712281 and perplexity is 295.49140369497945
At time: 47.98535466194153 and batch: 250, loss is 5.613054990768433 and perplexity is 273.9799670525889
At time: 49.032777309417725 and batch: 300, loss is 5.572446250915528 and perplexity is 263.07686475814603
At time: 50.07437062263489 and batch: 350, loss is 5.522347249984741 and perplexity is 250.2216812577211
At time: 51.11994457244873 and batch: 400, loss is 5.470984296798706 and perplexity is 237.6940391369613
At time: 52.159345865249634 and batch: 450, loss is 5.403518533706665 and perplexity is 222.18681426579988
At time: 53.19833540916443 and batch: 500, loss is 5.3711112594604495 and perplexity is 215.10176881474584
At time: 54.237457513809204 and batch: 550, loss is 5.324750404357911 and perplexity is 205.35709783089354
At time: 55.274799823760986 and batch: 600, loss is 5.3357197952270505 and perplexity is 207.6221404615238
At time: 56.31776022911072 and batch: 650, loss is 5.404854431152343 and perplexity is 222.48383141149225
At time: 57.38675665855408 and batch: 700, loss is 5.346034955978394 and perplexity is 209.774880055359
At time: 58.428943395614624 and batch: 750, loss is 5.283880701065064 and perplexity is 197.13340870033795
At time: 59.474629640579224 and batch: 800, loss is 5.263846044540405 and perplexity is 193.22320911155938
At time: 60.514244079589844 and batch: 850, loss is 5.262312612533569 and perplexity is 192.92714151602254
At time: 61.552581787109375 and batch: 900, loss is 5.282508888244629 and perplexity is 196.8631639679216
At time: 62.597142696380615 and batch: 950, loss is 5.319025382995606 and perplexity is 204.18478302453366
At time: 63.64484000205994 and batch: 1000, loss is 5.287910013198853 and perplexity is 197.92932315304105
At time: 64.68550205230713 and batch: 1050, loss is 5.188362531661987 and perplexity is 179.17491933220873
At time: 65.72971963882446 and batch: 1100, loss is 5.279662923812866 and perplexity is 196.30369489750106
At time: 66.77840852737427 and batch: 1150, loss is 5.176166563034058 and perplexity is 177.00297901652954
At time: 67.82348108291626 and batch: 1200, loss is 5.248056449890137 and perplexity is 190.19625305484462
At time: 68.87317848205566 and batch: 1250, loss is 5.188864860534668 and perplexity is 179.2649466772239
At time: 69.92497992515564 and batch: 1300, loss is 5.2134185409545895 and perplexity is 183.72104380759345
At time: 70.97084140777588 and batch: 1350, loss is 5.160125932693481 and perplexity is 174.18638998521266
At time: 72.01437520980835 and batch: 1400, loss is 5.165326051712036 and perplexity is 175.09453913993818
At time: 73.05807209014893 and batch: 1450, loss is 5.101938762664795 and perplexity is 164.34021531212358
At time: 74.10421776771545 and batch: 1500, loss is 5.082397890090943 and perplexity is 161.16003702938227
At time: 75.14996194839478 and batch: 1550, loss is 5.073957509994507 and perplexity is 159.80550946561422
At time: 76.19801020622253 and batch: 1600, loss is 5.126877155303955 and perplexity is 168.4901271179453
At time: 77.24146699905396 and batch: 1650, loss is 5.086274585723877 and perplexity is 161.78601802605888
At time: 78.2902250289917 and batch: 1700, loss is 5.110568161010742 and perplexity is 165.76450905483932
At time: 79.33445048332214 and batch: 1750, loss is 5.124097900390625 and perplexity is 168.02250023247055
At time: 80.38054847717285 and batch: 1800, loss is 5.09008358001709 and perplexity is 162.40343516814758
At time: 81.42733120918274 and batch: 1850, loss is 5.083418312072754 and perplexity is 161.3245722071357
At time: 82.47153282165527 and batch: 1900, loss is 5.134742488861084 and perplexity is 169.8205835517478
At time: 83.51536393165588 and batch: 1950, loss is 5.057315149307251 and perplexity is 157.1679767980344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.850142509992732 and perplexity of 127.75859542526513
finished 2 epochs...
Completing Train Step...
At time: 86.84937047958374 and batch: 50, loss is 4.985625324249267 and perplexity is 146.29502825793224
At time: 87.91408634185791 and batch: 100, loss is 4.94784987449646 and perplexity is 140.87174612606108
At time: 88.95799422264099 and batch: 150, loss is 4.893885984420776 and perplexity is 133.47123472796773
At time: 89.99577617645264 and batch: 200, loss is 4.873837261199951 and perplexity is 130.82195298277955
At time: 91.03107953071594 and batch: 250, loss is 4.871924180984497 and perplexity is 130.5719193362499
At time: 92.0680410861969 and batch: 300, loss is 4.905186567306519 and perplexity is 134.98809202240787
At time: 93.10396027565002 and batch: 350, loss is 4.889996223449707 and perplexity is 132.95307194637184
At time: 94.13899683952332 and batch: 400, loss is 4.860719003677368 and perplexity is 129.11700434173883
At time: 95.17324805259705 and batch: 450, loss is 4.850070486068725 and perplexity is 127.7493940812594
At time: 96.2072126865387 and batch: 500, loss is 4.838821058273315 and perplexity is 126.32033958978778
At time: 97.24080777168274 and batch: 550, loss is 4.810339069366455 and perplexity is 122.77323910496466
At time: 98.27452611923218 and batch: 600, loss is 4.789411506652832 and perplexity is 120.23059293566698
At time: 99.30866575241089 and batch: 650, loss is 4.862387981414795 and perplexity is 129.3326776744409
At time: 100.34395170211792 and batch: 700, loss is 4.859278774261474 and perplexity is 128.93118008089775
At time: 101.38013744354248 and batch: 750, loss is 4.809279127120972 and perplexity is 122.6431755043519
At time: 102.4133198261261 and batch: 800, loss is 4.783378419876098 and perplexity is 119.50741502633495
At time: 103.44848322868347 and batch: 850, loss is 4.785988264083862 and perplexity is 119.8197181151645
At time: 104.4802918434143 and batch: 900, loss is 4.799538202285767 and perplexity is 121.45431724015641
At time: 105.51324129104614 and batch: 950, loss is 4.8695335197448735 and perplexity is 130.26013893885735
At time: 106.54597353935242 and batch: 1000, loss is 4.841214742660522 and perplexity is 126.62307279377431
At time: 107.58021140098572 and batch: 1050, loss is 4.769174537658691 and perplexity is 117.82194423044736
At time: 108.61384320259094 and batch: 1100, loss is 4.841767110824585 and perplexity is 126.69303466859873
At time: 109.6943416595459 and batch: 1150, loss is 4.765364532470703 and perplexity is 117.37389608654084
At time: 110.72781705856323 and batch: 1200, loss is 4.837186584472656 and perplexity is 126.11404094503018
At time: 111.76843476295471 and batch: 1250, loss is 4.803518877029419 and perplexity is 121.93875092007387
At time: 112.80370593070984 and batch: 1300, loss is 4.8205593490600585 and perplexity is 124.03444993301186
At time: 113.83862018585205 and batch: 1350, loss is 4.73151125907898 and perplexity is 113.46691073916088
At time: 114.87358665466309 and batch: 1400, loss is 4.741208534240723 and perplexity is 114.5725829335977
At time: 115.9092767238617 and batch: 1450, loss is 4.666867933273315 and perplexity is 106.36408078160703
At time: 116.94477581977844 and batch: 1500, loss is 4.669901781082153 and perplexity is 106.68726321028976
At time: 117.97717499732971 and batch: 1550, loss is 4.676801261901855 and perplexity is 107.4258950946966
At time: 119.00896096229553 and batch: 1600, loss is 4.758200178146362 and perplexity is 116.53599300780705
At time: 120.04143166542053 and batch: 1650, loss is 4.7084028434753415 and perplexity is 110.87493379052545
At time: 121.0821053981781 and batch: 1700, loss is 4.73318829536438 and perplexity is 113.65735851494256
At time: 122.1180830001831 and batch: 1750, loss is 4.741835994720459 and perplexity is 114.64449526016189
At time: 123.1526551246643 and batch: 1800, loss is 4.71048936843872 and perplexity is 111.10651862744533
At time: 124.19399118423462 and batch: 1850, loss is 4.72837064743042 and perplexity is 113.11111423933146
At time: 125.22848892211914 and batch: 1900, loss is 4.800647287368775 and perplexity is 121.58909513793681
At time: 126.269211769104 and batch: 1950, loss is 4.735846290588379 and perplexity is 113.95986107813484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.705066485737645 and perplexity of 110.50563175168134
finished 3 epochs...
Completing Train Step...
At time: 129.56281042099 and batch: 50, loss is 4.671149740219116 and perplexity is 106.82048766725944
At time: 130.59522223472595 and batch: 100, loss is 4.634380798339844 and perplexity is 102.96414268429113
At time: 131.62767243385315 and batch: 150, loss is 4.588378849029541 and perplexity is 98.33488517909849
At time: 132.66177606582642 and batch: 200, loss is 4.577337093353272 and perplexity is 97.25506791266662
At time: 133.69566702842712 and batch: 250, loss is 4.572326364517212 and perplexity is 96.76896801387218
At time: 134.72946214675903 and batch: 300, loss is 4.613475208282471 and perplexity is 100.8339604661517
At time: 135.77180409431458 and batch: 350, loss is 4.61446325302124 and perplexity is 100.93363816518358
At time: 136.83383893966675 and batch: 400, loss is 4.578467197418213 and perplexity is 97.36503838758732
At time: 137.86918783187866 and batch: 450, loss is 4.5886604118347165 and perplexity is 98.36257652345945
At time: 138.90312385559082 and batch: 500, loss is 4.593451013565064 and perplexity is 98.83492296122829
At time: 139.93635511398315 and batch: 550, loss is 4.560627040863037 and perplexity is 95.64343337244708
At time: 140.97081971168518 and batch: 600, loss is 4.530789947509765 and perplexity is 92.83186442553288
At time: 142.00524187088013 and batch: 650, loss is 4.599922962188721 and perplexity is 99.47665188320356
At time: 143.04063296318054 and batch: 700, loss is 4.616638889312744 and perplexity is 101.15347210404369
At time: 144.07503056526184 and batch: 750, loss is 4.570570869445801 and perplexity is 96.59923958975281
At time: 145.1188063621521 and batch: 800, loss is 4.541355886459351 and perplexity is 93.81792036755812
At time: 146.15852999687195 and batch: 850, loss is 4.543463163375854 and perplexity is 94.01582915657798
At time: 147.19848251342773 and batch: 900, loss is 4.559861822128296 and perplexity is 95.57027322070488
At time: 148.2333698272705 and batch: 950, loss is 4.632833271026612 and perplexity is 102.80492608899345
At time: 149.2692630290985 and batch: 1000, loss is 4.602514524459838 and perplexity is 99.7347861621369
At time: 150.30516457557678 and batch: 1050, loss is 4.539031486511231 and perplexity is 93.60010324344822
At time: 151.34026956558228 and batch: 1100, loss is 4.604005374908447 and perplexity is 99.88358670494586
At time: 152.37487745285034 and batch: 1150, loss is 4.532008390426636 and perplexity is 92.94504369043673
At time: 153.4079852104187 and batch: 1200, loss is 4.608227996826172 and perplexity is 100.30624907104806
At time: 154.44214701652527 and batch: 1250, loss is 4.585071926116943 and perplexity is 98.01023638431718
At time: 155.48409366607666 and batch: 1300, loss is 4.5990120315551755 and perplexity is 99.38607681374653
At time: 156.51943683624268 and batch: 1350, loss is 4.497638731002808 and perplexity is 89.80482739112864
At time: 157.55425763130188 and batch: 1400, loss is 4.515981645584106 and perplexity is 91.46731044796336
At time: 158.5902864933014 and batch: 1450, loss is 4.4367165184021 and perplexity is 84.49704120309595
At time: 159.62257313728333 and batch: 1500, loss is 4.4460179805755615 and perplexity is 85.28665381863917
At time: 160.65748071670532 and batch: 1550, loss is 4.4569437789916995 and perplexity is 86.2235876606213
At time: 161.69106268882751 and batch: 1600, loss is 4.5496476459503175 and perplexity is 94.5990700763997
At time: 162.72971534729004 and batch: 1650, loss is 4.488569593429565 and perplexity is 88.99405710749525
At time: 163.76598572731018 and batch: 1700, loss is 4.5194633674621585 and perplexity is 91.78632922893888
At time: 164.8008210659027 and batch: 1750, loss is 4.5273904132843015 and perplexity is 92.51681513903502
At time: 165.83681845664978 and batch: 1800, loss is 4.496720933914185 and perplexity is 89.72244259405132
At time: 166.8712341785431 and batch: 1850, loss is 4.517913913726806 and perplexity is 91.64422068200153
At time: 167.90303373336792 and batch: 1900, loss is 4.598656311035156 and perplexity is 99.3507294340865
At time: 168.938702583313 and batch: 1950, loss is 4.536392621994018 and perplexity is 93.35343086283201
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.658111998092297 and perplexity of 105.43682918620686
finished 4 epochs...
Completing Train Step...
At time: 172.2028510570526 and batch: 50, loss is 4.478172159194946 and perplexity is 88.07354104685913
At time: 173.2723627090454 and batch: 100, loss is 4.445802898406982 and perplexity is 85.26831215273832
At time: 174.31082773208618 and batch: 150, loss is 4.404102230072022 and perplexity is 81.78568514538281
At time: 175.34801387786865 and batch: 200, loss is 4.393909778594971 and perplexity is 80.95632231813235
At time: 176.3845853805542 and batch: 250, loss is 4.3885273838043215 and perplexity is 80.52175398889901
At time: 177.4211802482605 and batch: 300, loss is 4.433201122283935 and perplexity is 84.20052212882096
At time: 178.45513153076172 and batch: 350, loss is 4.427519474029541 and perplexity is 83.72348085290011
At time: 179.49014258384705 and batch: 400, loss is 4.387641038894653 and perplexity is 80.45041556202948
At time: 180.52451634407043 and batch: 450, loss is 4.4107293701171875 and perplexity is 82.32949028064608
At time: 181.5561385154724 and batch: 500, loss is 4.424967956542969 and perplexity is 83.51013122586576
At time: 182.5890257358551 and batch: 550, loss is 4.388833131790161 and perplexity is 80.54637711704147
At time: 183.6249716281891 and batch: 600, loss is 4.359323110580444 and perplexity is 78.20418092064313
At time: 184.65946698188782 and batch: 650, loss is 4.426388053894043 and perplexity is 83.62880798834111
At time: 185.6940951347351 and batch: 700, loss is 4.450627450942993 and perplexity is 85.68068756792265
At time: 186.72810792922974 and batch: 750, loss is 4.40281008720398 and perplexity is 81.68007460226356
At time: 187.7598466873169 and batch: 800, loss is 4.374685745239258 and perplexity is 79.41487912666118
At time: 188.83890914916992 and batch: 850, loss is 4.375841522216797 and perplexity is 79.5067180780793
At time: 189.87845540046692 and batch: 900, loss is 4.386467294692993 and perplexity is 80.35604274884814
At time: 190.9110927581787 and batch: 950, loss is 4.468731803894043 and perplexity is 87.24600777664108
At time: 191.9469735622406 and batch: 1000, loss is 4.433506011962891 and perplexity is 84.22619791292257
At time: 192.9817771911621 and batch: 1050, loss is 4.375484170913697 and perplexity is 79.47831132466632
At time: 194.0171446800232 and batch: 1100, loss is 4.432894239425659 and perplexity is 84.17468639639617
At time: 195.05133819580078 and batch: 1150, loss is 4.368121519088745 and perplexity is 78.89528911923452
At time: 196.09818959236145 and batch: 1200, loss is 4.444825048446655 and perplexity is 85.18497329017501
At time: 197.1331272125244 and batch: 1250, loss is 4.426309442520141 and perplexity is 83.62223407124307
At time: 198.1684651374817 and batch: 1300, loss is 4.437524614334106 and perplexity is 84.56535051487997
At time: 199.20521903038025 and batch: 1350, loss is 4.331091122627258 and perplexity is 76.02719632280238
At time: 200.24625158309937 and batch: 1400, loss is 4.352849254608154 and perplexity is 77.69953358652461
At time: 201.28726291656494 and batch: 1450, loss is 4.273344421386719 and perplexity is 71.76123454355145
At time: 202.32275915145874 and batch: 1500, loss is 4.285147428512573 and perplexity is 72.6132511942793
At time: 203.35484266281128 and batch: 1550, loss is 4.295281791687012 and perplexity is 73.35288176524759
At time: 204.3873908519745 and batch: 1600, loss is 4.396868391036987 and perplexity is 81.1961953713274
At time: 205.42268204689026 and batch: 1650, loss is 4.331757574081421 and perplexity is 76.07788164612532
At time: 206.46189379692078 and batch: 1700, loss is 4.369693899154663 and perplexity is 79.01944007980926
At time: 207.4969437122345 and batch: 1750, loss is 4.369297256469727 and perplexity is 78.98810381199534
At time: 208.52939176559448 and batch: 1800, loss is 4.336251916885376 and perplexity is 76.42057123144222
At time: 209.56160473823547 and batch: 1850, loss is 4.362985610961914 and perplexity is 78.49112891591079
At time: 210.59413647651672 and batch: 1900, loss is 4.449219646453858 and perplexity is 85.56015077735756
At time: 211.63015985488892 and batch: 1950, loss is 4.386418085098267 and perplexity is 80.35208855784353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.63046988553779 and perplexity of 102.56224530557598
finished 5 epochs...
Completing Train Step...
At time: 214.92304730415344 and batch: 50, loss is 4.3295063781738286 and perplexity is 75.90680806262918
At time: 215.958425283432 and batch: 100, loss is 4.3036669921875 and perplexity is 73.97054638791188
At time: 216.9954116344452 and batch: 150, loss is 4.263845586776734 and perplexity is 71.082813650176
At time: 218.03226590156555 and batch: 200, loss is 4.2494723510742185 and perplexity is 70.06843105859814
At time: 219.06894969940186 and batch: 250, loss is 4.241203498840332 and perplexity is 69.49143439361852
At time: 220.10738611221313 and batch: 300, loss is 4.287546577453614 and perplexity is 72.78767034408502
At time: 221.14521479606628 and batch: 350, loss is 4.283647079467773 and perplexity is 72.50438765928192
At time: 222.18320083618164 and batch: 400, loss is 4.246172246932983 and perplexity is 69.83757906641087
At time: 223.22088384628296 and batch: 450, loss is 4.276940016746521 and perplexity is 72.01972333755894
At time: 224.2595090866089 and batch: 500, loss is 4.295663614273071 and perplexity is 73.3808948999415
At time: 225.29810667037964 and batch: 550, loss is 4.2593542575836185 and perplexity is 70.7642732045688
At time: 226.33677339553833 and batch: 600, loss is 4.230859436988831 and perplexity is 68.77631569058984
At time: 227.37428212165833 and batch: 650, loss is 4.289112567901611 and perplexity is 72.90174443673335
At time: 228.41339540481567 and batch: 700, loss is 4.316440181732178 and perplexity is 74.92144628134882
At time: 229.45021772384644 and batch: 750, loss is 4.269773149490357 and perplexity is 71.50541273988229
At time: 230.48512387275696 and batch: 800, loss is 4.241921672821045 and perplexity is 69.5413592589062
At time: 231.52226209640503 and batch: 850, loss is 4.244722118377686 and perplexity is 69.73637899306615
At time: 232.55979180335999 and batch: 900, loss is 4.255706081390381 and perplexity is 70.506583003165
At time: 233.59676003456116 and batch: 950, loss is 4.341621332168579 and perplexity is 76.83200861515236
At time: 234.63648128509521 and batch: 1000, loss is 4.300063505172729 and perplexity is 73.70447416634015
At time: 235.67816162109375 and batch: 1050, loss is 4.249872350692749 and perplexity is 70.0964640105039
At time: 236.7212553024292 and batch: 1100, loss is 4.30131049156189 and perplexity is 73.79643997058184
At time: 237.76135969161987 and batch: 1150, loss is 4.245759563446045 and perplexity is 69.8087641968818
At time: 238.80688953399658 and batch: 1200, loss is 4.313255567550659 and perplexity is 74.68322989598877
At time: 239.85258173942566 and batch: 1250, loss is 4.298088603019714 and perplexity is 73.55905867956407
At time: 240.89829063415527 and batch: 1300, loss is 4.314026260375977 and perplexity is 74.7408099108433
At time: 241.9439573287964 and batch: 1350, loss is 4.203183569908142 and perplexity is 66.89896993350798
At time: 242.98682737350464 and batch: 1400, loss is 4.229327116012573 and perplexity is 68.6710090018166
At time: 244.02984595298767 and batch: 1450, loss is 4.1460896015167235 and perplexity is 63.186432439526484
At time: 245.07100367546082 and batch: 1500, loss is 4.1593026924133305 and perplexity is 64.02686061451855
At time: 246.11392283439636 and batch: 1550, loss is 4.170262537002563 and perplexity is 64.73244453869225
At time: 247.1624641418457 and batch: 1600, loss is 4.272446804046631 and perplexity is 71.69684931605035
At time: 248.20832228660583 and batch: 1650, loss is 4.210673551559449 and perplexity is 67.40192319485377
At time: 249.25148916244507 and batch: 1700, loss is 4.246110529899597 and perplexity is 69.83326903121468
At time: 250.2933361530304 and batch: 1750, loss is 4.24871325969696 and perplexity is 70.01526289906231
At time: 251.33521819114685 and batch: 1800, loss is 4.214193382263184 and perplexity is 67.6395845721426
At time: 252.38086462020874 and batch: 1850, loss is 4.240128059387207 and perplexity is 69.41674073487013
At time: 253.4266152381897 and batch: 1900, loss is 4.328905487060547 and perplexity is 75.8612100373229
At time: 254.475022315979 and batch: 1950, loss is 4.262701230049133 and perplexity is 71.00151607974145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.629787143441134 and perplexity of 102.492245641756
finished 6 epochs...
Completing Train Step...
At time: 257.7890567779541 and batch: 50, loss is 4.21405291557312 and perplexity is 67.63008413084387
At time: 258.85490703582764 and batch: 100, loss is 4.185412154197693 and perplexity is 65.72058234938139
At time: 259.8919563293457 and batch: 150, loss is 4.147827043533325 and perplexity is 63.29631062797591
At time: 260.92871475219727 and batch: 200, loss is 4.1336604642868044 and perplexity is 62.40594007078271
At time: 261.96455812454224 and batch: 250, loss is 4.124628119468689 and perplexity is 61.84480609407089
At time: 262.9990749359131 and batch: 300, loss is 4.175757918357849 and perplexity is 65.08915323495847
At time: 264.0305771827698 and batch: 350, loss is 4.166417417526245 and perplexity is 64.48401847547423
At time: 265.06178998947144 and batch: 400, loss is 4.130159058570862 and perplexity is 62.187813652902854
At time: 266.09333968162537 and batch: 450, loss is 4.159511957168579 and perplexity is 64.04026058185595
At time: 267.12247490882874 and batch: 500, loss is 4.184287905693054 and perplexity is 65.64673760065318
At time: 268.1791772842407 and batch: 550, loss is 4.147944617271423 and perplexity is 63.30375304933235
At time: 269.2102007865906 and batch: 600, loss is 4.124333629608154 and perplexity is 61.826596107209305
At time: 270.246187210083 and batch: 650, loss is 4.181858172416687 and perplexity is 65.48742715713836
At time: 271.2765522003174 and batch: 700, loss is 4.2078956651687625 and perplexity is 67.21494812768708
At time: 272.30813932418823 and batch: 750, loss is 4.162837834358215 and perplexity is 64.25360520609458
At time: 273.3369779586792 and batch: 800, loss is 4.133454084396362 and perplexity is 62.39306206863401
At time: 274.37055921554565 and batch: 850, loss is 4.13733922958374 and perplexity is 62.635939675331514
At time: 275.4035325050354 and batch: 900, loss is 4.143436627388001 and perplexity is 63.01902263410909
At time: 276.43526315689087 and batch: 950, loss is 4.234424738883972 and perplexity is 69.02196166007447
At time: 277.47326254844666 and batch: 1000, loss is 4.190675539970398 and perplexity is 66.06740706294447
At time: 278.5082457065582 and batch: 1050, loss is 4.14665714263916 and perplexity is 63.222303516508795
At time: 279.54306960105896 and batch: 1100, loss is 4.190867686271668 and perplexity is 66.0801028905352
At time: 280.573938369751 and batch: 1150, loss is 4.1361900901794435 and perplexity is 62.564003589137144
At time: 281.6054723262787 and batch: 1200, loss is 4.210038661956787 and perplexity is 67.35914399608919
At time: 282.63790702819824 and batch: 1250, loss is 4.193107185363769 and perplexity is 66.22825505236082
At time: 283.6694002151489 and batch: 1300, loss is 4.208741641044616 and perplexity is 67.27183441111892
At time: 284.70434951782227 and batch: 1350, loss is 4.0991237926483155 and perplexity is 60.287440149808525
At time: 285.7368493080139 and batch: 1400, loss is 4.129228262901306 and perplexity is 62.129956436056254
At time: 286.76886510849 and batch: 1450, loss is 4.0446101713180544 and perplexity is 57.08892679469575
At time: 287.7994887828827 and batch: 1500, loss is 4.055150527954101 and perplexity is 57.69384687929806
At time: 288.8335464000702 and batch: 1550, loss is 4.06546637058258 and perplexity is 58.292087899221876
At time: 289.86578345298767 and batch: 1600, loss is 4.1707009601593015 and perplexity is 64.76083096354857
At time: 290.8993651866913 and batch: 1650, loss is 4.110121541023254 and perplexity is 60.95412554621701
At time: 291.9342038631439 and batch: 1700, loss is 4.145638275146484 and perplexity is 63.15792117075288
At time: 292.9661121368408 and batch: 1750, loss is 4.146732912063599 and perplexity is 63.22709401554231
At time: 293.99698400497437 and batch: 1800, loss is 4.106912908554077 and perplexity is 60.75885959572068
At time: 295.02680683135986 and batch: 1850, loss is 4.133799161911011 and perplexity is 62.41459622668714
At time: 296.0604958534241 and batch: 1900, loss is 4.221769723892212 and perplexity is 68.15399137271777
At time: 297.1019973754883 and batch: 1950, loss is 4.160043115615845 and perplexity is 64.07428514264558
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.630260094930959 and perplexity of 102.54073096672734
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 300.45595121383667 and batch: 50, loss is 4.142508034706116 and perplexity is 62.96053079262254
At time: 301.49791502952576 and batch: 100, loss is 4.136898617744446 and perplexity is 62.60834761788524
At time: 302.54327178001404 and batch: 150, loss is 4.103206882476806 and perplexity is 60.5341024128704
At time: 303.5827445983887 and batch: 200, loss is 4.085309467315674 and perplexity is 59.460335934829615
At time: 304.6191346645355 and batch: 250, loss is 4.075814509391785 and perplexity is 58.89843438425509
At time: 305.65904903411865 and batch: 300, loss is 4.116530604362488 and perplexity is 61.346038955038935
At time: 306.6935558319092 and batch: 350, loss is 4.1141287183761595 and perplexity is 61.198869576542336
At time: 307.7391450405121 and batch: 400, loss is 4.071476182937622 and perplexity is 58.64346721356412
At time: 308.7708089351654 and batch: 450, loss is 4.091484446525573 and perplexity is 59.828638232264524
At time: 309.81013655662537 and batch: 500, loss is 4.11353973865509 and perplexity is 61.16283529618128
At time: 310.84467792510986 and batch: 550, loss is 4.069869384765625 and perplexity is 58.54931465997824
At time: 311.88521575927734 and batch: 600, loss is 4.034516549110412 and perplexity is 56.515591119909466
At time: 312.91785883903503 and batch: 650, loss is 4.075223650932312 and perplexity is 58.86364402515057
At time: 313.95149850845337 and batch: 700, loss is 4.0944880104064945 and perplexity is 60.00860750841459
At time: 314.988160610199 and batch: 750, loss is 4.039344778060913 and perplexity is 56.789121134504185
At time: 316.0280270576477 and batch: 800, loss is 4.011152472496033 and perplexity is 55.21046245194317
At time: 317.06157660484314 and batch: 850, loss is 4.0064366865158085 and perplexity is 54.95071466600383
At time: 318.09521198272705 and batch: 900, loss is 4.002311096191407 and perplexity is 54.72447753101528
At time: 319.1298406124115 and batch: 950, loss is 4.091669430732727 and perplexity is 59.839706609178926
At time: 320.19092869758606 and batch: 1000, loss is 4.041135082244873 and perplexity is 56.89088199994602
At time: 321.2320177555084 and batch: 1050, loss is 3.994033107757568 and perplexity is 54.27333877585512
At time: 322.2658414840698 and batch: 1100, loss is 4.0236570835113525 and perplexity is 55.905182357488954
At time: 323.2967519760132 and batch: 1150, loss is 3.9670262241363528 and perplexity is 52.82720076884572
At time: 324.3319227695465 and batch: 1200, loss is 4.02524534702301 and perplexity is 55.99404506876058
At time: 325.3685371875763 and batch: 1250, loss is 3.998586835861206 and perplexity is 54.5210483769519
At time: 326.402250289917 and batch: 1300, loss is 4.007356266975403 and perplexity is 55.00126951051248
At time: 327.4358456134796 and batch: 1350, loss is 3.8937193059921267 and perplexity is 49.09313979480541
At time: 328.474406003952 and batch: 1400, loss is 3.918556876182556 and perplexity is 50.32776315270275
At time: 329.5092821121216 and batch: 1450, loss is 3.8253461503982544 and perplexity is 45.84866815459556
At time: 330.5515868663788 and batch: 1500, loss is 3.833282914161682 and perplexity is 46.21400608524583
At time: 331.5898199081421 and batch: 1550, loss is 3.8343823194503783 and perplexity is 46.26484194743526
At time: 332.62966227531433 and batch: 1600, loss is 3.927204899787903 and perplexity is 50.76488623752488
At time: 333.6685802936554 and batch: 1650, loss is 3.8580150175094605 and perplexity is 47.37122692606989
At time: 334.7146167755127 and batch: 1700, loss is 3.8736890745162964 and perplexity is 48.11957574755069
At time: 335.7608006000519 and batch: 1750, loss is 3.867154402732849 and perplexity is 47.80615527893228
At time: 336.8064966201782 and batch: 1800, loss is 3.8202242183685304 and perplexity is 45.614434768472414
At time: 337.85579228401184 and batch: 1850, loss is 3.838013195991516 and perplexity is 46.43312920699185
At time: 338.8950572013855 and batch: 1900, loss is 3.915047221183777 and perplexity is 50.151439665471976
At time: 339.93027925491333 and batch: 1950, loss is 3.8554853057861327 and perplexity is 47.2515428249294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.542946607013081 and perplexity of 93.96727722281052
finished 8 epochs...
Completing Train Step...
At time: 343.2135465145111 and batch: 50, loss is 4.035139322280884 and perplexity is 56.55079847573267
At time: 344.27921319007874 and batch: 100, loss is 4.01639178276062 and perplexity is 55.5004862935873
At time: 345.32094287872314 and batch: 150, loss is 3.9782648944854735 and perplexity is 53.424257038664095
At time: 346.38998103141785 and batch: 200, loss is 3.96375479221344 and perplexity is 52.65466255524149
At time: 347.43060779571533 and batch: 250, loss is 3.952700343132019 and perplexity is 52.07579966905784
At time: 348.47243571281433 and batch: 300, loss is 3.9969707536697388 and perplexity is 54.43300904017313
At time: 349.51414608955383 and batch: 350, loss is 3.9963789272308348 and perplexity is 54.40080367720671
At time: 350.5539927482605 and batch: 400, loss is 3.9566472148895264 and perplexity is 52.28174231929187
At time: 351.59969329833984 and batch: 450, loss is 3.9857947492599486 and perplexity is 53.82805228750322
At time: 352.63857889175415 and batch: 500, loss is 4.009932675361633 and perplexity is 55.14315794532281
At time: 353.67724227905273 and batch: 550, loss is 3.9669646215438843 and perplexity is 52.82394657655988
At time: 354.7166557312012 and batch: 600, loss is 3.938510608673096 and perplexity is 51.34207588400048
At time: 355.75551891326904 and batch: 650, loss is 3.9799375343322754 and perplexity is 53.513691354621976
At time: 356.79826831817627 and batch: 700, loss is 4.005704321861267 and perplexity is 54.91048543787115
At time: 357.84141778945923 and batch: 750, loss is 3.953943395614624 and perplexity is 52.14057287102434
At time: 358.88621163368225 and batch: 800, loss is 3.9254998445510862 and perplexity is 50.67840305265489
At time: 359.9301567077637 and batch: 850, loss is 3.9260720920562746 and perplexity is 50.70741194170928
At time: 360.9746403694153 and batch: 900, loss is 3.9228395986557008 and perplexity is 50.54376520324414
At time: 362.02037811279297 and batch: 950, loss is 4.015544137954712 and perplexity is 55.45346152762007
At time: 363.0677139759064 and batch: 1000, loss is 3.9651009941101076 and perplexity is 52.72559409521638
At time: 364.11450600624084 and batch: 1050, loss is 3.9245325994491576 and perplexity is 50.6294083143088
At time: 365.1615571975708 and batch: 1100, loss is 3.953690519332886 and perplexity is 52.127389423789836
At time: 366.2070872783661 and batch: 1150, loss is 3.902671537399292 and perplexity is 49.53460604843843
At time: 367.25283646583557 and batch: 1200, loss is 3.962286295890808 and perplexity is 52.577396123530406
At time: 368.3020098209381 and batch: 1250, loss is 3.942593369483948 and perplexity is 51.55212179119659
At time: 369.34700107574463 and batch: 1300, loss is 3.9537456130981443 and perplexity is 52.13026139705947
At time: 370.3932077884674 and batch: 1350, loss is 3.841117191314697 and perplexity is 46.577481341165544
At time: 371.4401822090149 and batch: 1400, loss is 3.870436706542969 and perplexity is 47.9633274067805
At time: 372.48571276664734 and batch: 1450, loss is 3.7821842670440673 and perplexity is 43.91185227134349
At time: 373.5320153236389 and batch: 1500, loss is 3.7932694244384764 and perplexity is 44.401330021933504
At time: 374.5785825252533 and batch: 1550, loss is 3.79795524597168 and perplexity is 44.60987495082877
At time: 375.62599539756775 and batch: 1600, loss is 3.895210614204407 and perplexity is 49.16640741607174
At time: 376.6796178817749 and batch: 1650, loss is 3.828861212730408 and perplexity is 46.010112658522964
At time: 377.72680711746216 and batch: 1700, loss is 3.84861581325531 and perplexity is 46.92806105431635
At time: 378.77644872665405 and batch: 1750, loss is 3.8473692560195922 and perplexity is 46.86959898597842
At time: 379.82352805137634 and batch: 1800, loss is 3.803378839492798 and perplexity is 44.8524780752689
At time: 380.8783583641052 and batch: 1850, loss is 3.826936011314392 and perplexity is 45.92161913574211
At time: 381.92808389663696 and batch: 1900, loss is 3.9060063409805297 and perplexity is 49.700069971583204
At time: 382.97537899017334 and batch: 1950, loss is 3.851835322380066 and perplexity is 47.079389846588384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.543438010992006 and perplexity of 94.01346446409414
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 386.3713331222534 and batch: 50, loss is 3.9993655014038088 and perplexity is 54.5635185715623
At time: 387.41671681404114 and batch: 100, loss is 4.001422762870789 and perplexity is 54.67588554030878
At time: 388.45778369903564 and batch: 150, loss is 3.972549557685852 and perplexity is 53.119790310152695
At time: 389.50345277786255 and batch: 200, loss is 3.9618373250961305 and perplexity is 52.55379570655617
At time: 390.5491030216217 and batch: 250, loss is 3.955243191719055 and perplexity is 52.20838904857883
At time: 391.59145736694336 and batch: 300, loss is 3.9895871829986573 and perplexity is 54.0325791913177
At time: 392.63307189941406 and batch: 350, loss is 3.9943350553512573 and perplexity is 54.289728954262905
At time: 393.67141103744507 and batch: 400, loss is 3.960475082397461 and perplexity is 52.482253422108315
At time: 394.7142400741577 and batch: 450, loss is 3.9897250509262085 and perplexity is 54.04002906456855
At time: 395.7582976818085 and batch: 500, loss is 4.014105134010315 and perplexity is 55.373721164859695
At time: 396.80443572998047 and batch: 550, loss is 3.9697048902511596 and perplexity is 52.96889689506583
At time: 397.8468062877655 and batch: 600, loss is 3.9323039197921754 and perplexity is 51.02439847473269
At time: 398.8866231441498 and batch: 650, loss is 3.9666797637939455 and perplexity is 52.808901408963216
At time: 399.9798460006714 and batch: 700, loss is 3.9877957773208617 and perplexity is 53.93587156932231
At time: 401.0189745426178 and batch: 750, loss is 3.931439661979675 and perplexity is 50.98031929035623
At time: 402.06220173835754 and batch: 800, loss is 3.901440758705139 and perplexity is 49.473677413215114
At time: 403.10572957992554 and batch: 850, loss is 3.9018266868591307 and perplexity is 49.49277438300249
At time: 404.14770317077637 and batch: 900, loss is 3.892045745849609 and perplexity is 49.01104818455747
At time: 405.1945514678955 and batch: 950, loss is 3.9828348398208617 and perplexity is 53.6689616904799
At time: 406.2434768676758 and batch: 1000, loss is 3.93080135345459 and perplexity is 50.9477885013861
At time: 407.2886629104614 and batch: 1050, loss is 3.892423701286316 and perplexity is 49.029575677740354
At time: 408.3335072994232 and batch: 1100, loss is 3.9212815713882447 and perplexity is 50.465077953215605
At time: 409.377610206604 and batch: 1150, loss is 3.8718406772613525 and perplexity is 48.03071380721342
At time: 410.42085909843445 and batch: 1200, loss is 3.9218365383148193 and perplexity is 50.493092175190974
At time: 411.47234439849854 and batch: 1250, loss is 3.8945051050186157 and perplexity is 49.131732297253045
At time: 412.5195631980896 and batch: 1300, loss is 3.90049165725708 and perplexity is 49.42674415007852
At time: 413.5626323223114 and batch: 1350, loss is 3.7842552042007447 and perplexity is 44.00288518701951
At time: 414.60311460494995 and batch: 1400, loss is 3.8139739179611207 and perplexity is 45.330219987402884
At time: 415.64546251296997 and batch: 1450, loss is 3.715590467453003 and perplexity is 41.08283800271676
At time: 416.68855834007263 and batch: 1500, loss is 3.7269046688079834 and perplexity is 41.550296979957494
At time: 417.73078322410583 and batch: 1550, loss is 3.734771628379822 and perplexity is 41.878460619061265
At time: 418.7726032733917 and batch: 1600, loss is 3.8296211338043213 and perplexity is 46.04509000107194
At time: 419.8165545463562 and batch: 1650, loss is 3.75507728099823 and perplexity is 42.737522481333144
At time: 420.8649160861969 and batch: 1700, loss is 3.7683087730407716 and perplexity is 43.30676130463444
At time: 421.89785623550415 and batch: 1750, loss is 3.764663438796997 and perplexity is 43.149181075466316
At time: 422.9339861869812 and batch: 1800, loss is 3.7175049638748168 and perplexity is 41.16156628753383
At time: 423.96996116638184 and batch: 1850, loss is 3.7371203327178955 and perplexity is 41.976936341097485
At time: 425.00512170791626 and batch: 1900, loss is 3.815653319358826 and perplexity is 45.406411582436114
At time: 426.0419867038727 and batch: 1950, loss is 3.7662665033340454 and perplexity is 43.218407469815055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.515688874000727 and perplexity of 91.44053533834293
finished 10 epochs...
Completing Train Step...
At time: 429.3646459579468 and batch: 50, loss is 3.978215274810791 and perplexity is 53.421606210176854
At time: 430.4269437789917 and batch: 100, loss is 3.967257704734802 and perplexity is 52.83943065633032
At time: 431.4698016643524 and batch: 150, loss is 3.9323977756500246 and perplexity is 51.02918763816478
At time: 432.5037467479706 and batch: 200, loss is 3.9180007076263426 and perplexity is 50.29978021566882
At time: 433.5381586551666 and batch: 250, loss is 3.9089966440200805 and perplexity is 49.84891067037209
At time: 434.57111144065857 and batch: 300, loss is 3.944170422554016 and perplexity is 51.63348636439744
At time: 435.61374258995056 and batch: 350, loss is 3.950138177871704 and perplexity is 51.94254364911388
At time: 436.6472256183624 and batch: 400, loss is 3.9152126550674438 and perplexity is 50.15973709922674
At time: 437.6881558895111 and batch: 450, loss is 3.9467990350723268 and perplexity is 51.76938933288809
At time: 438.72315526008606 and batch: 500, loss is 3.972764739990234 and perplexity is 53.131221978942236
At time: 439.7567358016968 and batch: 550, loss is 3.9290551137924195 and perplexity is 50.8588990861043
At time: 440.7891888618469 and batch: 600, loss is 3.892353367805481 and perplexity is 49.026127378285956
At time: 441.83001828193665 and batch: 650, loss is 3.927846894264221 and perplexity is 50.79748747786866
At time: 442.86349725723267 and batch: 700, loss is 3.952775502204895 and perplexity is 52.07971378496906
At time: 443.89775824546814 and batch: 750, loss is 3.898155722618103 and perplexity is 49.311421252141635
At time: 444.93365240097046 and batch: 800, loss is 3.868896098136902 and perplexity is 47.88949159203706
At time: 445.9707806110382 and batch: 850, loss is 3.869880785942078 and perplexity is 47.93667101509294
At time: 447.0147626399994 and batch: 900, loss is 3.8626421976089476 and perplexity is 47.590930035517005
At time: 448.05554366111755 and batch: 950, loss is 3.9548208713531494 and perplexity is 52.18634503775748
At time: 449.08897972106934 and batch: 1000, loss is 3.903256072998047 and perplexity is 49.56356925323149
At time: 450.1284554004669 and batch: 1050, loss is 3.866443643569946 and perplexity is 47.77218868848725
At time: 451.16490411758423 and batch: 1100, loss is 3.896535663604736 and perplexity is 49.23159851591031
At time: 452.2468583583832 and batch: 1150, loss is 3.8484227800369264 and perplexity is 46.919003253914845
At time: 453.283242225647 and batch: 1200, loss is 3.901438283920288 and perplexity is 49.473554976659216
At time: 454.3238904476166 and batch: 1250, loss is 3.8766776609420774 and perplexity is 48.263600366256284
At time: 455.35930275917053 and batch: 1300, loss is 3.884567131996155 and perplexity is 48.64588065607401
At time: 456.3945240974426 and batch: 1350, loss is 3.7702995777130126 and perplexity is 43.39306248327102
At time: 457.43077063560486 and batch: 1400, loss is 3.8022317028045656 and perplexity is 44.80105565202377
At time: 458.46891832351685 and batch: 1450, loss is 3.7071466732025145 and perplexity is 40.737403413084024
At time: 459.50623655319214 and batch: 1500, loss is 3.7201848459243774 and perplexity is 41.27202236868835
At time: 460.54625606536865 and batch: 1550, loss is 3.7297903299331665 and perplexity is 41.670370218709785
At time: 461.5898826122284 and batch: 1600, loss is 3.8264210557937623 and perplexity is 45.89797763213574
At time: 462.62448167800903 and batch: 1650, loss is 3.754293441772461 and perplexity is 42.70403626042133
At time: 463.6607620716095 and batch: 1700, loss is 3.7692201042175295 and perplexity is 43.346246095503474
At time: 464.69757604599 and batch: 1750, loss is 3.7678226709365843 and perplexity is 43.28571491260088
At time: 465.73701429367065 and batch: 1800, loss is 3.72232186794281 and perplexity is 41.360315898241815
At time: 466.7744393348694 and batch: 1850, loss is 3.7440833282470702 and perplexity is 42.27024151745205
At time: 467.8177888393402 and batch: 1900, loss is 3.8233896017074587 and perplexity is 45.759050701986325
At time: 468.8540053367615 and batch: 1950, loss is 3.774952688217163 and perplexity is 43.5954456886715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.515402434593023 and perplexity of 91.41434691643755
finished 11 epochs...
Completing Train Step...
At time: 472.19048404693604 and batch: 50, loss is 3.96111713886261 and perplexity is 52.515960812089446
At time: 473.2333474159241 and batch: 100, loss is 3.947471790313721 and perplexity is 51.80422917893603
At time: 474.2690920829773 and batch: 150, loss is 3.911701354980469 and perplexity is 49.98392006381411
At time: 475.3045332431793 and batch: 200, loss is 3.896444787979126 and perplexity is 49.22712476687585
At time: 476.34029483795166 and batch: 250, loss is 3.886539168357849 and perplexity is 48.74190675393286
At time: 477.382075548172 and batch: 300, loss is 3.922204170227051 and perplexity is 50.51165845979208
At time: 478.4232323169708 and batch: 350, loss is 3.9287023067474367 and perplexity is 50.840958873109514
At time: 479.4901473522186 and batch: 400, loss is 3.892990760803223 and perplexity is 49.05738624961782
At time: 480.535058259964 and batch: 450, loss is 3.9258643198013305 and perplexity is 50.696877442813964
At time: 481.57533407211304 and batch: 500, loss is 3.952326021194458 and perplexity is 52.05631020272065
At time: 482.6143274307251 and batch: 550, loss is 3.908319506645203 and perplexity is 49.815167535518434
At time: 483.6491611003876 and batch: 600, loss is 3.872726354598999 and perplexity is 48.07327236573686
At time: 484.6872522830963 and batch: 650, loss is 3.9083832263946534 and perplexity is 49.81834184664472
At time: 485.7265536785126 and batch: 700, loss is 3.934488682746887 and perplexity is 51.13599655359109
At time: 486.7665104866028 and batch: 750, loss is 3.88034854888916 and perplexity is 48.441096219498554
At time: 487.80780482292175 and batch: 800, loss is 3.8515826225280763 and perplexity is 47.06749439479513
At time: 488.85459423065186 and batch: 850, loss is 3.8531502199172976 and perplexity is 47.141335137282056
At time: 489.8954405784607 and batch: 900, loss is 3.8467222929000853 and perplexity is 46.83928589079304
At time: 490.93450021743774 and batch: 950, loss is 3.9393941068649294 and perplexity is 51.387456559129284
At time: 491.969357252121 and batch: 1000, loss is 3.888092584609985 and perplexity is 48.8176820641059
At time: 493.00480246543884 and batch: 1050, loss is 3.8524214935302736 and perplexity is 47.10699451642596
At time: 494.04309463500977 and batch: 1100, loss is 3.8827340412139892 and perplexity is 48.55679002121082
At time: 495.0858497619629 and batch: 1150, loss is 3.835158472061157 and perplexity is 46.30076446417426
At time: 496.12927770614624 and batch: 1200, loss is 3.889479012489319 and perplexity is 48.8854111994558
At time: 497.16218400001526 and batch: 1250, loss is 3.8656562089920046 and perplexity is 47.73458602201286
At time: 498.1932327747345 and batch: 1300, loss is 3.874437918663025 and perplexity is 48.155623305509174
At time: 499.2265121936798 and batch: 1350, loss is 3.760886507034302 and perplexity is 42.986516941964176
At time: 500.2616376876831 and batch: 1400, loss is 3.793790588378906 and perplexity is 44.42447642505948
At time: 501.2979874610901 and batch: 1450, loss is 3.7001430797576904 and perplexity is 40.453091964609115
At time: 502.3353567123413 and batch: 1500, loss is 3.7137790155410766 and perplexity is 41.00848578033842
At time: 503.3737759590149 and batch: 1550, loss is 3.7242132139205935 and perplexity is 41.438616588862565
At time: 504.4137542247772 and batch: 1600, loss is 3.8216466903686523 and perplexity is 45.679366195351626
At time: 505.44457483291626 and batch: 1650, loss is 3.7504719734191894 and perplexity is 42.541155557242064
At time: 506.47752928733826 and batch: 1700, loss is 3.7661346673965452 and perplexity is 43.2127101061159
At time: 507.52398133277893 and batch: 1750, loss is 3.7657495498657227 and perplexity is 43.196071338045975
At time: 508.5647087097168 and batch: 1800, loss is 3.7210569477081297 and perplexity is 41.30803147253473
At time: 509.60539960861206 and batch: 1850, loss is 3.743891830444336 and perplexity is 42.262147634085586
At time: 510.642272233963 and batch: 1900, loss is 3.8235655450820922 and perplexity is 45.76710241208861
At time: 511.67725348472595 and batch: 1950, loss is 3.775740928649902 and perplexity is 43.629822928631896
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.516363951217296 and perplexity of 91.5022856011734
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 514.9158346652985 and batch: 50, loss is 3.952366690635681 and perplexity is 52.058427346819975
At time: 515.9803853034973 and batch: 100, loss is 3.94644926071167 and perplexity is 51.751284894251384
At time: 517.0176076889038 and batch: 150, loss is 3.916077218055725 and perplexity is 50.203122103256604
At time: 518.0571949481964 and batch: 200, loss is 3.9031283760070803 and perplexity is 49.557240538663784
At time: 519.0916268825531 and batch: 250, loss is 3.8974595642089844 and perplexity is 49.277104637857086
At time: 520.1280331611633 and batch: 300, loss is 3.9287215995788576 and perplexity is 50.841939748620234
At time: 521.1670923233032 and batch: 350, loss is 3.9386392927169798 and perplexity is 51.34868321506654
At time: 522.2067542076111 and batch: 400, loss is 3.9016142177581785 and perplexity is 49.48225981477569
At time: 523.2460851669312 and batch: 450, loss is 3.937268466949463 and perplexity is 51.2783413412292
At time: 524.2840685844421 and batch: 500, loss is 3.965457015037537 and perplexity is 52.74436885203026
At time: 525.3205325603485 and batch: 550, loss is 3.920880618095398 and perplexity is 50.44484786996676
At time: 526.3562693595886 and batch: 600, loss is 3.880856657028198 and perplexity is 48.46571578892374
At time: 527.3941442966461 and batch: 650, loss is 3.9137734746932984 and perplexity is 50.08760011154079
At time: 528.4317491054535 and batch: 700, loss is 3.9382379484176635 and perplexity is 51.32807884877983
At time: 529.4704501628876 and batch: 750, loss is 3.8823069667816164 and perplexity is 48.53605708524322
At time: 530.5072975158691 and batch: 800, loss is 3.8526852464675905 and perplexity is 47.11942076325534
At time: 531.5889666080475 and batch: 850, loss is 3.854452872276306 and perplexity is 47.20278392321904
At time: 532.6300311088562 and batch: 900, loss is 3.840542268753052 and perplexity is 46.55071059256897
At time: 533.6692428588867 and batch: 950, loss is 3.9353383493423464 and perplexity is 51.17946356530711
At time: 534.7062907218933 and batch: 1000, loss is 3.8832451915740966 and perplexity is 48.581616186326904
At time: 535.7466251850128 and batch: 1050, loss is 3.8476256561279296 and perplexity is 46.88161789699535
At time: 536.7894921302795 and batch: 1100, loss is 3.872222752571106 and perplexity is 48.04906866331437
At time: 537.8354408740997 and batch: 1150, loss is 3.8283116483688353 and perplexity is 45.984834087071114
At time: 538.8789637088776 and batch: 1200, loss is 3.8825185298919678 and perplexity is 48.54632661073244
At time: 539.9214279651642 and batch: 1250, loss is 3.8559348583221436 and perplexity is 47.27278965126128
At time: 540.9621021747589 and batch: 1300, loss is 3.8619225454330444 and perplexity is 47.55669343986156
At time: 542.0052366256714 and batch: 1350, loss is 3.7443820810317994 and perplexity is 42.28287175638214
At time: 543.0436248779297 and batch: 1400, loss is 3.77591091632843 and perplexity is 43.63724009134139
At time: 544.0847418308258 and batch: 1450, loss is 3.677435808181763 and perplexity is 39.5448633410357
At time: 545.1284601688385 and batch: 1500, loss is 3.687785754203796 and perplexity is 39.956275918464904
At time: 546.1740915775299 and batch: 1550, loss is 3.6988091564178465 and perplexity is 40.39916661520577
At time: 547.2166154384613 and batch: 1600, loss is 3.796593985557556 and perplexity is 44.54919060694756
At time: 548.2599239349365 and batch: 1650, loss is 3.7220155715942385 and perplexity is 41.347649324468094
At time: 549.3064374923706 and batch: 1700, loss is 3.7355598640441894 and perplexity is 41.91148372857654
At time: 550.3537611961365 and batch: 1750, loss is 3.7331149482727053 and perplexity is 41.80913884429461
At time: 551.4034628868103 and batch: 1800, loss is 3.69055410861969 and perplexity is 40.06704230090762
At time: 552.4484076499939 and batch: 1850, loss is 3.7121874284744263 and perplexity is 40.943269117513026
At time: 553.4963371753693 and batch: 1900, loss is 3.7933911418914796 and perplexity is 44.406734767653
At time: 554.5370757579803 and batch: 1950, loss is 3.746836609840393 and perplexity is 42.386783758549704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5087019099745635 and perplexity of 90.80387037503785
finished 13 epochs...
Completing Train Step...
At time: 557.8819742202759 and batch: 50, loss is 3.948228130340576 and perplexity is 51.843425612071556
At time: 558.9227800369263 and batch: 100, loss is 3.9358762884140015 and perplexity is 51.20700240487003
At time: 559.9593515396118 and batch: 150, loss is 3.901842794418335 and perplexity is 49.493571597216615
At time: 560.9907989501953 and batch: 200, loss is 3.886974630355835 and perplexity is 48.76313662409894
At time: 562.0235183238983 and batch: 250, loss is 3.8805025243759155 and perplexity is 48.44855553512906
At time: 563.055793762207 and batch: 300, loss is 3.911479878425598 and perplexity is 49.97285102321117
At time: 564.0879850387573 and batch: 350, loss is 3.921104226112366 and perplexity is 50.456129003594164
At time: 565.1222529411316 and batch: 400, loss is 3.8848519134521484 and perplexity is 48.659736073584675
At time: 566.1560649871826 and batch: 450, loss is 3.9198403406143187 and perplexity is 50.39239851636185
At time: 567.1889729499817 and batch: 500, loss is 3.9482444286346436 and perplexity is 51.844270578353395
At time: 568.2202107906342 and batch: 550, loss is 3.9056169891357424 and perplexity is 49.680722924302394
At time: 569.253259897232 and batch: 600, loss is 3.8664009284973146 and perplexity is 47.77014813955906
At time: 570.2895138263702 and batch: 650, loss is 3.9000905036926268 and perplexity is 49.40692041193085
At time: 571.3255634307861 and batch: 700, loss is 3.925753502845764 and perplexity is 50.69125968047643
At time: 572.3648653030396 and batch: 750, loss is 3.8706294107437134 and perplexity is 47.97257103206758
At time: 573.4015233516693 and batch: 800, loss is 3.841432976722717 and perplexity is 46.59219215272297
At time: 574.4347658157349 and batch: 850, loss is 3.8432975482940672 and perplexity is 46.67914767185964
At time: 575.4667644500732 and batch: 900, loss is 3.8310896825790404 and perplexity is 46.11275913712679
At time: 576.5019953250885 and batch: 950, loss is 3.9262049484252928 and perplexity is 50.71414919187555
At time: 577.5407023429871 and batch: 1000, loss is 3.874069561958313 and perplexity is 48.13788812543179
At time: 578.5769617557526 and batch: 1050, loss is 3.8383478355407714 and perplexity is 46.44867016858536
At time: 579.6104493141174 and batch: 1100, loss is 3.8642302131652833 and perplexity is 47.66656521177745
At time: 580.6461582183838 and batch: 1150, loss is 3.82090220451355 and perplexity is 45.64537120931244
At time: 581.6784827709198 and batch: 1200, loss is 3.875813136100769 and perplexity is 48.221893315796926
At time: 582.7124485969543 and batch: 1250, loss is 3.8504870462417604 and perplexity is 47.015956601027256
At time: 583.7476918697357 and batch: 1300, loss is 3.8571368646621704 and perplexity is 47.32964600813797
At time: 584.7842555046082 and batch: 1350, loss is 3.740798583030701 and perplexity is 42.131622332821166
At time: 585.8202166557312 and batch: 1400, loss is 3.7735805892944336 and perplexity is 43.53566944344517
At time: 586.8572790622711 and batch: 1450, loss is 3.676874394416809 and perplexity is 39.52266854123884
At time: 587.8913495540619 and batch: 1500, loss is 3.6885351848602297 and perplexity is 39.98623160000612
At time: 588.9229888916016 and batch: 1550, loss is 3.7006060314178466 and perplexity is 40.47182412640072
At time: 589.9551079273224 and batch: 1600, loss is 3.799089550971985 and perplexity is 44.66050486450202
At time: 590.9891622066498 and batch: 1650, loss is 3.725348653793335 and perplexity is 41.485694368344966
At time: 592.0233368873596 and batch: 1700, loss is 3.7398178482055666 and perplexity is 42.09032263889433
At time: 593.0589447021484 and batch: 1750, loss is 3.7385306119918824 and perplexity is 42.036177307739884
At time: 594.0922379493713 and batch: 1800, loss is 3.695813789367676 and perplexity is 40.27833733703376
At time: 595.1278142929077 and batch: 1850, loss is 3.7178233575820925 and perplexity is 41.174673957810526
At time: 596.1587438583374 and batch: 1900, loss is 3.798937926292419 and perplexity is 44.65373374311024
At time: 597.2026178836823 and batch: 1950, loss is 3.7518577766418457 and perplexity is 42.60015009567822
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.508172181595204 and perplexity of 90.75578172603007
finished 14 epochs...
Completing Train Step...
At time: 600.5595004558563 and batch: 50, loss is 3.9441763973236084 and perplexity is 51.633794863503326
At time: 601.6211357116699 and batch: 100, loss is 3.9301675367355347 and perplexity is 50.91550717253869
At time: 602.6564598083496 and batch: 150, loss is 3.8953513717651367 and perplexity is 49.17332844673174
At time: 603.6914038658142 and batch: 200, loss is 3.879823393821716 and perplexity is 48.41566381090997
At time: 604.7266454696655 and batch: 250, loss is 3.872652487754822 and perplexity is 48.069721475966055
At time: 605.7628030776978 and batch: 300, loss is 3.9034948635101316 and perplexity is 49.57540597650657
At time: 606.7971756458282 and batch: 350, loss is 3.9131459474563597 and perplexity is 50.0561786381842
At time: 607.8307015895844 and batch: 400, loss is 3.876543889045715 and perplexity is 48.257144484727405
At time: 608.8665533065796 and batch: 450, loss is 3.911607713699341 and perplexity is 49.97923972464344
At time: 609.9015302658081 and batch: 500, loss is 3.9401781702041627 and perplexity is 51.42776337939889
At time: 610.9699487686157 and batch: 550, loss is 3.897675061225891 and perplexity is 49.287724851179384
At time: 612.0037581920624 and batch: 600, loss is 3.858921670913696 and perplexity is 47.41419568616811
At time: 613.0490119457245 and batch: 650, loss is 3.892795596122742 and perplexity is 49.04781291472399
At time: 614.0853822231293 and batch: 700, loss is 3.919019079208374 and perplexity is 50.351030173744135
At time: 615.1209299564362 and batch: 750, loss is 3.8643071126937865 and perplexity is 47.67023088911023
At time: 616.1594724655151 and batch: 800, loss is 3.8351730585098265 and perplexity is 46.301439832824066
At time: 617.1941437721252 and batch: 850, loss is 3.8372625160217284 and perplexity is 46.39828586669666
At time: 618.2285559177399 and batch: 900, loss is 3.825822892189026 and perplexity is 45.8705313418895
At time: 619.2653410434723 and batch: 950, loss is 3.921086001396179 and perplexity is 50.45520946334239
At time: 620.3017876148224 and batch: 1000, loss is 3.8690115213394165 and perplexity is 47.89501946953993
At time: 621.3375263214111 and batch: 1050, loss is 3.8335454845428467 and perplexity is 46.226142107649075
At time: 622.3784191608429 and batch: 1100, loss is 3.859797296524048 and perplexity is 47.45573095222266
At time: 623.4147787094116 and batch: 1150, loss is 3.8167694759368898 and perplexity is 45.4571205417149
At time: 624.4566080570221 and batch: 1200, loss is 3.8721465492248535 and perplexity is 48.04540730300363
At time: 625.49196600914 and batch: 1250, loss is 3.8474786853790284 and perplexity is 46.8747281768094
At time: 626.5287837982178 and batch: 1300, loss is 3.854502172470093 and perplexity is 47.20511108697808
At time: 627.5637798309326 and batch: 1350, loss is 3.738680567741394 and perplexity is 42.04248134686631
At time: 628.6038632392883 and batch: 1400, loss is 3.7720750522613526 and perplexity is 43.47017419596956
At time: 629.6398475170135 and batch: 1450, loss is 3.6761689043045043 and perplexity is 39.4947955225967
At time: 630.6725375652313 and batch: 1500, loss is 3.6884018850326536 and perplexity is 39.98090179746719
At time: 631.7063984870911 and batch: 1550, loss is 3.700936436653137 and perplexity is 40.48519843832351
At time: 632.7428274154663 and batch: 1600, loss is 3.7997734546661377 and perplexity is 44.691058795543846
At time: 633.7781467437744 and batch: 1650, loss is 3.7263749837875366 and perplexity is 41.52829423782799
At time: 634.8148777484894 and batch: 1700, loss is 3.741165075302124 and perplexity is 42.14706607662218
At time: 635.8517987728119 and batch: 1750, loss is 3.740417060852051 and perplexity is 42.11555125041082
At time: 636.8886966705322 and batch: 1800, loss is 3.6976878595352174 and perplexity is 40.35389254320084
At time: 637.9261810779572 and batch: 1850, loss is 3.719946789741516 and perplexity is 41.262198477949646
At time: 638.9636490345001 and batch: 1900, loss is 3.8009950256347658 and perplexity is 44.74568545390272
At time: 639.9973421096802 and batch: 1950, loss is 3.7537797689437866 and perplexity is 42.682105990293785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.508270973382994 and perplexity of 90.7647480948536
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 643.3207321166992 and batch: 50, loss is 3.942011103630066 and perplexity is 51.5221134882353
At time: 644.3721961975098 and batch: 100, loss is 3.9299254703521727 and perplexity is 50.903183731465965
At time: 645.4163417816162 and batch: 150, loss is 3.896244082450867 and perplexity is 49.217245602229475
At time: 646.4614660739899 and batch: 200, loss is 3.880634455680847 and perplexity is 48.45494783794601
At time: 647.5117802619934 and batch: 250, loss is 3.8745955181121827 and perplexity is 48.16321320328211
At time: 648.554037809372 and batch: 300, loss is 3.9037784719467163 and perplexity is 49.589467973844904
At time: 649.595671415329 and batch: 350, loss is 3.914424486160278 and perplexity is 50.12021832983196
At time: 650.6371848583221 and batch: 400, loss is 3.8782869386672973 and perplexity is 48.34133243273046
At time: 651.6800043582916 and batch: 450, loss is 3.9138612365722656 and perplexity is 50.091996086336216
At time: 652.7197132110596 and batch: 500, loss is 3.942927165031433 and perplexity is 51.56933253218846
At time: 653.7569572925568 and batch: 550, loss is 3.900150098800659 and perplexity is 49.40986491042833
At time: 654.7966532707214 and batch: 600, loss is 3.860344829559326 and perplexity is 47.481721647365056
At time: 655.8359529972076 and batch: 650, loss is 3.8935775804519652 and perplexity is 49.086182536072045
At time: 656.8827002048492 and batch: 700, loss is 3.920006957054138 and perplexity is 50.4007954179081
At time: 657.9313325881958 and batch: 750, loss is 3.8653397607803344 and perplexity is 47.71948288743737
At time: 658.9824929237366 and batch: 800, loss is 3.834923849105835 and perplexity is 46.28990251626298
At time: 660.0283627510071 and batch: 850, loss is 3.8375342321395873 and perplexity is 46.410894741747384
At time: 661.0739846229553 and batch: 900, loss is 3.82278386592865 and perplexity is 45.731341200937166
At time: 662.1234908103943 and batch: 950, loss is 3.9187201690673827 and perplexity is 50.33598198935534
At time: 663.2183270454407 and batch: 1000, loss is 3.866343207359314 and perplexity is 47.76739087182306
At time: 664.2665932178497 and batch: 1050, loss is 3.8306703329086305 and perplexity is 46.093425820774186
At time: 665.3116347789764 and batch: 1100, loss is 3.853648042678833 and perplexity is 47.164809009351686
At time: 666.3570578098297 and batch: 1150, loss is 3.811918869018555 and perplexity is 45.237159821100846
At time: 667.4038927555084 and batch: 1200, loss is 3.8676986837387086 and perplexity is 47.83218234358972
At time: 668.4524652957916 and batch: 1250, loss is 3.8432485485076904 and perplexity is 46.67686045963238
At time: 669.5036237239838 and batch: 1300, loss is 3.8494974040985106 and perplexity is 46.969450644892355
At time: 670.5493478775024 and batch: 1350, loss is 3.7315111637115477 and perplexity is 41.74213973333156
At time: 671.5979890823364 and batch: 1400, loss is 3.7638438177108764 and perplexity is 43.113829586200076
At time: 672.6432301998138 and batch: 1450, loss is 3.6671227645874023 and perplexity is 39.13913120416867
At time: 673.6949546337128 and batch: 1500, loss is 3.67879695892334 and perplexity is 39.59872651072844
At time: 674.7415401935577 and batch: 1550, loss is 3.6916275787353516 and perplexity is 40.1100761670928
At time: 675.789986371994 and batch: 1600, loss is 3.789699521064758 and perplexity is 44.24310415765258
At time: 676.8389196395874 and batch: 1650, loss is 3.715975227355957 and perplexity is 41.098648072825235
At time: 677.8856053352356 and batch: 1700, loss is 3.7301533603668213 and perplexity is 41.685500577505024
At time: 678.9278514385223 and batch: 1750, loss is 3.728726935386658 and perplexity is 41.62608172651223
At time: 679.9671747684479 and batch: 1800, loss is 3.686396069526672 and perplexity is 39.90078785844945
At time: 681.0078384876251 and batch: 1850, loss is 3.7084608983993532 and perplexity is 40.79097673109455
At time: 682.0479891300201 and batch: 1900, loss is 3.7889013719558715 and perplexity is 44.207805652104035
At time: 683.0879712104797 and batch: 1950, loss is 3.7431788539886472 and perplexity is 42.232026456976655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.508220725835756 and perplexity of 90.76018750346633
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 686.3592627048492 and batch: 50, loss is 3.9411476039886475 and perplexity is 51.47764336444426
At time: 687.4185626506805 and batch: 100, loss is 3.928599238395691 and perplexity is 50.835719049311926
At time: 688.4534418582916 and batch: 150, loss is 3.894934573173523 and perplexity is 49.15283734331835
At time: 689.5151181221008 and batch: 200, loss is 3.8797462368011475 and perplexity is 48.41192834665197
At time: 690.5504343509674 and batch: 250, loss is 3.8731489515304567 and perplexity is 48.09359227638728
At time: 691.5905792713165 and batch: 300, loss is 3.901973204612732 and perplexity is 49.500026484392414
At time: 692.6311056613922 and batch: 350, loss is 3.912724981307983 and perplexity is 50.03511111612836
At time: 693.6651463508606 and batch: 400, loss is 3.87721471786499 and perplexity is 48.28952762854234
At time: 694.6974284648895 and batch: 450, loss is 3.912370867729187 and perplexity is 50.01739614060737
At time: 695.7314529418945 and batch: 500, loss is 3.941364092826843 and perplexity is 51.48878890604843
At time: 696.7740862369537 and batch: 550, loss is 3.8986982488632203 and perplexity is 49.33818125069934
At time: 697.8114619255066 and batch: 600, loss is 3.8585350275039674 and perplexity is 47.39586684346991
At time: 698.8498866558075 and batch: 650, loss is 3.892174596786499 and perplexity is 49.01736371090601
At time: 699.8959605693817 and batch: 700, loss is 3.919187183380127 and perplexity is 50.359495103443464
At time: 700.9287884235382 and batch: 750, loss is 3.8647067165374756 and perplexity is 47.68928390317836
At time: 701.9599666595459 and batch: 800, loss is 3.8337453269958495 and perplexity is 46.23538097640907
At time: 702.993462562561 and batch: 850, loss is 3.8361291170120237 and perplexity is 46.34572788565149
At time: 704.0271029472351 and batch: 900, loss is 3.820896334648132 and perplexity is 45.64510327791285
At time: 705.0626521110535 and batch: 950, loss is 3.9172877359390257 and perplexity is 50.263930677868125
At time: 706.0980734825134 and batch: 1000, loss is 3.8647623825073243 and perplexity is 47.69193864730698
At time: 707.1351382732391 and batch: 1050, loss is 3.8290719175338745 and perplexity is 46.01980823168421
At time: 708.1698486804962 and batch: 1100, loss is 3.8515988302230837 and perplexity is 47.068257256571144
At time: 709.2055263519287 and batch: 1150, loss is 3.8100316667556764 and perplexity is 45.151868656873276
At time: 710.2417361736298 and batch: 1200, loss is 3.866107316017151 and perplexity is 47.75612428677587
At time: 711.2793385982513 and batch: 1250, loss is 3.8414870834350587 and perplexity is 46.59471317126255
At time: 712.3140547275543 and batch: 1300, loss is 3.8476456689834593 and perplexity is 46.88255614142977
At time: 713.3493704795837 and batch: 1350, loss is 3.729139289855957 and perplexity is 41.643249966808604
At time: 714.3846459388733 and batch: 1400, loss is 3.7611910343170165 and perplexity is 42.999609502581656
At time: 715.4189159870148 and batch: 1450, loss is 3.664280934333801 and perplexity is 39.02806233120405
At time: 716.4586095809937 and batch: 1500, loss is 3.6760547876358034 and perplexity is 39.490288765253595
At time: 717.5009529590607 and batch: 1550, loss is 3.688939709663391 and perplexity is 40.00241029459428
At time: 718.5374455451965 and batch: 1600, loss is 3.7870063829421996 and perplexity is 44.12411167070769
At time: 719.5730006694794 and batch: 1650, loss is 3.7131411838531494 and perplexity is 40.982337608586555
At time: 720.6111617088318 and batch: 1700, loss is 3.72724600315094 and perplexity is 41.564481944046776
At time: 721.6457226276398 and batch: 1750, loss is 3.7258434200286867 and perplexity is 41.50622516772289
At time: 722.6782824993134 and batch: 1800, loss is 3.6836081457138063 and perplexity is 39.78970242264377
At time: 723.7135441303253 and batch: 1850, loss is 3.705743227005005 and perplexity is 40.68027075984766
At time: 724.7570021152496 and batch: 1900, loss is 3.7856948137283326 and perplexity is 44.06627777911758
At time: 725.793429851532 and batch: 1950, loss is 3.7403556537628173 and perplexity is 42.112965136400746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507930595930232 and perplexity of 90.7338590783571
finished 17 epochs...
Completing Train Step...
At time: 729.1158215999603 and batch: 50, loss is 3.9405040836334226 and perplexity is 51.44452710973507
At time: 730.152040719986 and batch: 100, loss is 3.9278065729141236 and perplexity is 50.795439295885
At time: 731.188601732254 and batch: 150, loss is 3.8940971374511717 and perplexity is 49.1116922320697
At time: 732.2251563072205 and batch: 200, loss is 3.8789559412002563 and perplexity is 48.373683726916845
At time: 733.2622027397156 and batch: 250, loss is 3.872251853942871 and perplexity is 48.050466977470826
At time: 734.3032615184784 and batch: 300, loss is 3.9010856676101686 and perplexity is 49.4561128696213
At time: 735.343770980835 and batch: 350, loss is 3.911749815940857 and perplexity is 49.98634239127805
At time: 736.3768227100372 and batch: 400, loss is 3.8761263132095336 and perplexity is 48.23699767397088
At time: 737.4130187034607 and batch: 450, loss is 3.9112371587753296 and perplexity is 49.96072310218982
At time: 738.4460864067078 and batch: 500, loss is 3.9402295541763306 and perplexity is 51.43040601005488
At time: 739.4955706596375 and batch: 550, loss is 3.89754506111145 and perplexity is 49.28131785777216
At time: 740.5399971008301 and batch: 600, loss is 3.8575571250915526 and perplexity is 47.34954096573075
At time: 741.5823428630829 and batch: 650, loss is 3.8912644720077516 and perplexity is 48.97277208865204
At time: 742.6481130123138 and batch: 700, loss is 3.918272762298584 and perplexity is 50.31346636749556
At time: 743.6912906169891 and batch: 750, loss is 3.863764796257019 and perplexity is 47.64438554816462
At time: 744.7356514930725 and batch: 800, loss is 3.8329876470565796 and perplexity is 46.200362623785665
At time: 745.7767155170441 and batch: 850, loss is 3.835415830612183 and perplexity is 46.31268189528876
At time: 746.8188354969025 and batch: 900, loss is 3.8203307437896727 and perplexity is 45.619294124164156
At time: 747.8611390590668 and batch: 950, loss is 3.916667423248291 and perplexity is 50.23276099225769
At time: 748.9021215438843 and batch: 1000, loss is 3.864254698753357 and perplexity is 47.66773236994733
At time: 749.9422879219055 and batch: 1050, loss is 3.8285385274887087 and perplexity is 45.9952682693606
At time: 750.9878461360931 and batch: 1100, loss is 3.8512536907196044 and perplexity is 47.05201494472494
At time: 752.0219593048096 and batch: 1150, loss is 3.809764976501465 and perplexity is 45.13982869908411
At time: 753.0579695701599 and batch: 1200, loss is 3.865827932357788 and perplexity is 47.7427838696497
At time: 754.0934965610504 and batch: 1250, loss is 3.841291208267212 and perplexity is 46.585587317792566
At time: 755.1285200119019 and batch: 1300, loss is 3.8474590730667115 and perplexity is 46.87380886401558
At time: 756.170339345932 and batch: 1350, loss is 3.7291210794448855 and perplexity is 41.642491633013165
At time: 757.2148225307465 and batch: 1400, loss is 3.7612561416625976 and perplexity is 43.00240918415632
At time: 758.2591252326965 and batch: 1450, loss is 3.66448392868042 and perplexity is 39.03598561138009
At time: 759.2981481552124 and batch: 1500, loss is 3.67633243560791 and perplexity is 39.50125468610957
At time: 760.3395304679871 and batch: 1550, loss is 3.6893607568740845 and perplexity is 40.019256744196255
At time: 761.3881411552429 and batch: 1600, loss is 3.7875038957595826 and perplexity is 44.14606944350329
At time: 762.4316675662994 and batch: 1650, loss is 3.7137315225601197 and perplexity is 41.00653821135248
At time: 763.4755187034607 and batch: 1700, loss is 3.7279189157485964 and perplexity is 41.59246062010802
At time: 764.5199863910675 and batch: 1750, loss is 3.7265928268432615 and perplexity is 41.53734187379035
At time: 765.5581939220428 and batch: 1800, loss is 3.6843760013580322 and perplexity is 39.82026690328381
At time: 766.6028251647949 and batch: 1850, loss is 3.7065152597427367 and perplexity is 40.71168938719794
At time: 767.6463248729706 and batch: 1900, loss is 3.786364893913269 and perplexity is 44.09581561393495
At time: 768.6908347606659 and batch: 1950, loss is 3.740809192657471 and perplexity is 42.132069335980596
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507845714480378 and perplexity of 90.72615778370077
finished 18 epochs...
Completing Train Step...
At time: 772.0344910621643 and batch: 50, loss is 3.9400522041320802 and perplexity is 51.42128563404663
At time: 773.1326022148132 and batch: 100, loss is 3.9271629428863526 and perplexity is 50.762756344872955
At time: 774.1736097335815 and batch: 150, loss is 3.8933625507354734 and perplexity is 49.07562868289434
At time: 775.2151551246643 and batch: 200, loss is 3.8782694959640502 and perplexity is 48.340489236568104
At time: 776.2552330493927 and batch: 250, loss is 3.8714502906799315 and perplexity is 48.01196692055159
At time: 777.2963297367096 and batch: 300, loss is 3.9002712106704713 and perplexity is 49.415849393943475
At time: 778.3389947414398 and batch: 350, loss is 3.9108765602111815 and perplexity is 49.94271058501447
At time: 779.3783094882965 and batch: 400, loss is 3.875197072029114 and perplexity is 48.19219468892568
At time: 780.4241547584534 and batch: 450, loss is 3.9102564430236817 and perplexity is 49.91174985242373
At time: 781.4692823886871 and batch: 500, loss is 3.9392273521423338 and perplexity is 51.378888172495195
At time: 782.5127966403961 and batch: 550, loss is 3.896588521003723 and perplexity is 49.23420083893125
At time: 783.5543410778046 and batch: 600, loss is 3.856707797050476 and perplexity is 47.30934274601049
At time: 784.6019763946533 and batch: 650, loss is 3.8904722690582276 and perplexity is 48.933991077401
At time: 785.6483798027039 and batch: 700, loss is 3.917495970726013 and perplexity is 50.27439846660703
At time: 786.6857604980469 and batch: 750, loss is 3.862991762161255 and perplexity is 47.60756904570341
At time: 787.7324028015137 and batch: 800, loss is 3.8323183059692383 and perplexity is 46.16944916980809
At time: 788.7806577682495 and batch: 850, loss is 3.8347639656066894 and perplexity is 46.28250211629027
At time: 789.8295223712921 and batch: 900, loss is 3.8198031330108644 and perplexity is 45.595231241339
At time: 790.8725101947784 and batch: 950, loss is 3.9161427640914916 and perplexity is 50.20641282673934
At time: 791.9131689071655 and batch: 1000, loss is 3.8638016605377197 and perplexity is 47.646141956541435
At time: 792.9575433731079 and batch: 1050, loss is 3.8280817699432372 and perplexity is 45.97426438073006
At time: 793.9952256679535 and batch: 1100, loss is 3.850935730934143 and perplexity is 47.03705667433783
At time: 795.0790929794312 and batch: 1150, loss is 3.8095168399810793 and perplexity is 45.12862924861371
At time: 796.1231300830841 and batch: 1200, loss is 3.865583071708679 and perplexity is 47.73109497173506
At time: 797.157543182373 and batch: 1250, loss is 3.841111783981323 and perplexity is 46.577229481877154
At time: 798.1939690113068 and batch: 1300, loss is 3.847290062904358 and perplexity is 46.865887383393556
At time: 799.2343490123749 and batch: 1350, loss is 3.7290877294540405 and perplexity is 41.64110287945603
At time: 800.2656788825989 and batch: 1400, loss is 3.761295886039734 and perplexity is 43.0041183220888
At time: 801.2974333763123 and batch: 1450, loss is 3.6646343660354614 and perplexity is 39.04185852354853
At time: 802.3304636478424 and batch: 1500, loss is 3.6765645122528077 and perplexity is 39.510423068608944
At time: 803.367112159729 and batch: 1550, loss is 3.6896975803375245 and perplexity is 40.032738439205275
At time: 804.4011371135712 and batch: 1600, loss is 3.7879309606552125 and perplexity is 44.16492670639355
At time: 805.4335188865662 and batch: 1650, loss is 3.7142140531539916 and perplexity is 41.026329895250704
At time: 806.466285943985 and batch: 1700, loss is 3.7284610080718994 and perplexity is 41.61501368608714
At time: 807.4995210170746 and batch: 1750, loss is 3.727207269668579 and perplexity is 41.56287203809738
At time: 808.531854391098 and batch: 1800, loss is 3.6850049448013307 and perplexity is 39.84531947656304
At time: 809.5659856796265 and batch: 1850, loss is 3.707142558097839 and perplexity is 40.737235774749706
At time: 810.6015367507935 and batch: 1900, loss is 3.7869422101974486 and perplexity is 44.12128019620479
At time: 811.6335363388062 and batch: 1950, loss is 3.741212468147278 and perplexity is 42.14906359333206
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507798873546512 and perplexity of 90.72190818527247
finished 19 epochs...
Completing Train Step...
At time: 814.9311280250549 and batch: 50, loss is 3.939663600921631 and perplexity is 51.40130703948823
At time: 815.9711549282074 and batch: 100, loss is 3.926592049598694 and perplexity is 50.733784498715735
At time: 817.0087733268738 and batch: 150, loss is 3.892711696624756 and perplexity is 49.04369800046518
At time: 818.048326253891 and batch: 200, loss is 3.8776297998428344 and perplexity is 48.30957590173016
At time: 819.0831665992737 and batch: 250, loss is 3.8707091856002807 and perplexity is 47.97639818969427
At time: 820.1251425743103 and batch: 300, loss is 3.8995178651809694 and perplexity is 49.37863620564639
At time: 821.1627607345581 and batch: 350, loss is 3.91008198261261 and perplexity is 49.903042987550855
At time: 822.22585272789 and batch: 400, loss is 3.8743643045425413 and perplexity is 48.15207850212858
At time: 823.264660358429 and batch: 450, loss is 3.909378924369812 and perplexity is 49.86797057225776
At time: 824.3056001663208 and batch: 500, loss is 3.938327808380127 and perplexity is 51.33269139525703
At time: 825.346070766449 and batch: 550, loss is 3.8957371807098387 and perplexity is 49.19230361684707
At time: 826.3888218402863 and batch: 600, loss is 3.8559380674362185 and perplexity is 47.27294135527933
At time: 827.428685426712 and batch: 650, loss is 3.8897547006607054 and perplexity is 48.898890186990194
At time: 828.4664127826691 and batch: 700, loss is 3.916802530288696 and perplexity is 50.23954825041959
At time: 829.5081195831299 and batch: 750, loss is 3.8623102712631225 and perplexity is 47.57513597339357
At time: 830.5513272285461 and batch: 800, loss is 3.831703715324402 and perplexity is 46.14108257608554
At time: 831.5925393104553 and batch: 850, loss is 3.834161024093628 and perplexity is 46.25460488548042
At time: 832.6312685012817 and batch: 900, loss is 3.8193132162094114 and perplexity is 45.57289884244314
At time: 833.6703782081604 and batch: 950, loss is 3.915668773651123 and perplexity is 50.182621105983785
At time: 834.7154927253723 and batch: 1000, loss is 3.863375673294067 and perplexity is 47.625849630301616
At time: 835.7514145374298 and batch: 1050, loss is 3.827665057182312 and perplexity is 45.955110309238634
At time: 836.7978405952454 and batch: 1100, loss is 3.8506334590911866 and perplexity is 47.02284084516031
At time: 837.8473227024078 and batch: 1150, loss is 3.8092725038528443 and perplexity is 45.117604041053674
At time: 838.899557352066 and batch: 1200, loss is 3.8653527212142946 and perplexity is 47.72010135665176
At time: 839.9488878250122 and batch: 1250, loss is 3.8409390687942504 and perplexity is 46.569185581645726
At time: 840.9930436611176 and batch: 1300, loss is 3.8471308898925782 and perplexity is 46.8584281926157
At time: 842.037921667099 and batch: 1350, loss is 3.72904278755188 and perplexity is 41.63923149113675
At time: 843.08904337883 and batch: 1400, loss is 3.7613163995742798 and perplexity is 43.005000497603845
At time: 844.1305384635925 and batch: 1450, loss is 3.66474995136261 and perplexity is 39.04637145034749
At time: 845.1703252792358 and batch: 1500, loss is 3.676761717796326 and perplexity is 39.51821551139602
At time: 846.2091517448425 and batch: 1550, loss is 3.6899793577194213 and perplexity is 40.04402034885167
At time: 847.2464337348938 and batch: 1600, loss is 3.788299517631531 and perplexity is 44.18120699816305
At time: 848.2838730812073 and batch: 1650, loss is 3.714620795249939 and perplexity is 41.0430204248017
At time: 849.321676492691 and batch: 1700, loss is 3.7289169311523436 and perplexity is 41.63399125714722
At time: 850.3606472015381 and batch: 1750, loss is 3.7277303457260134 and perplexity is 41.58461826830907
At time: 851.4006841182709 and batch: 1800, loss is 3.6855379486083986 and perplexity is 39.866562844432934
At time: 852.4413275718689 and batch: 1850, loss is 3.707673263549805 and perplexity is 40.75886098567449
At time: 853.4797358512878 and batch: 1900, loss is 3.78744432926178 and perplexity is 44.14343989507206
At time: 854.5180921554565 and batch: 1950, loss is 3.741574001312256 and perplexity is 42.164304632598395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507764523528343 and perplexity of 90.71879193959988
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f31229a0b38>
ELAPSED
3531.146748304367


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.77128768299961}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.13481025420142356, 'wordvec_source': 'None', 'rnn_dropout': 0.7333439966881319, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.4361717208564}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.049255346069296047, 'wordvec_source': 'None', 'rnn_dropout': 0.9817036371865334, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -87.71067320599664}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.9986437985159311, 'wordvec_source': 'None', 'rnn_dropout': 0.5007125478907719, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -90.71879193959988}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.1789226511740396, 'wordvec_source': 'None', 'rnn_dropout': 0.45869390902326646, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5134484767913818 and batch: 50, loss is 7.186398553848266 and perplexity is 1321.3359060597033
At time: 2.5409274101257324 and batch: 100, loss is 6.369218349456787 and perplexity is 583.6014781487121
At time: 3.5680508613586426 and batch: 150, loss is 6.076697120666504 and perplexity is 435.58812117908417
At time: 4.594849109649658 and batch: 200, loss is 5.907138776779175 and perplexity is 367.6527125820542
At time: 5.623882532119751 and batch: 250, loss is 5.831753931045532 and perplexity is 340.9561685500916
At time: 6.656423330307007 and batch: 300, loss is 5.7573363304138185 and perplexity is 316.5041426416756
At time: 7.68582010269165 and batch: 350, loss is 5.708513755798339 and perplexity is 301.4227473975894
At time: 8.720197439193726 and batch: 400, loss is 5.6498432636260985 and perplexity is 284.24691050224743
At time: 9.750316381454468 and batch: 450, loss is 5.571319351196289 and perplexity is 262.78057049143024
At time: 10.779983282089233 and batch: 500, loss is 5.542095804214478 and perplexity is 255.2123143973281
At time: 11.838443279266357 and batch: 550, loss is 5.485567922592163 and perplexity is 241.18588001999063
At time: 12.869803428649902 and batch: 600, loss is 5.508397521972657 and perplexity is 246.7553899817427
At time: 13.902011394500732 and batch: 650, loss is 5.570621204376221 and perplexity is 262.5971750976705
At time: 14.939266920089722 and batch: 700, loss is 5.498003635406494 and perplexity is 244.20392523638563
At time: 15.984906911849976 and batch: 750, loss is 5.442400979995727 and perplexity is 230.9961352808082
At time: 17.016014099121094 and batch: 800, loss is 5.427560710906983 and perplexity is 227.59340166548182
At time: 18.047780513763428 and batch: 850, loss is 5.42994722366333 and perplexity is 228.13720486034768
At time: 19.08049249649048 and batch: 900, loss is 5.444162034988404 and perplexity is 231.40329058434705
At time: 20.11829423904419 and batch: 950, loss is 5.4816537189483645 and perplexity is 240.24367456455678
At time: 21.154134035110474 and batch: 1000, loss is 5.454636754989624 and perplexity is 233.83991445821812
At time: 22.192041158676147 and batch: 1050, loss is 5.355418529510498 and perplexity is 211.75258251416037
At time: 23.233014822006226 and batch: 1100, loss is 5.441278171539307 and perplexity is 230.7369164205117
At time: 24.26948571205139 and batch: 1150, loss is 5.3484545421600345 and perplexity is 210.28306300469188
At time: 25.301857471466064 and batch: 1200, loss is 5.4220536422729495 and perplexity is 226.3434740593759
At time: 26.337451934814453 and batch: 1250, loss is 5.360371580123902 and perplexity is 212.80400549898147
At time: 27.373542070388794 and batch: 1300, loss is 5.386169319152832 and perplexity is 218.3652935995322
At time: 28.408952951431274 and batch: 1350, loss is 5.329811744689941 and perplexity is 206.39911476933324
At time: 29.451305627822876 and batch: 1400, loss is 5.341758699417114 and perplexity is 208.87974412763785
At time: 30.490288972854614 and batch: 1450, loss is 5.288810539245605 and perplexity is 198.10764394316382
At time: 31.533344507217407 and batch: 1500, loss is 5.274123783111572 and perplexity is 195.21934706139908
At time: 32.571284532547 and batch: 1550, loss is 5.252113208770752 and perplexity is 190.9694005696821
At time: 33.610209941864014 and batch: 1600, loss is 5.302688360214233 and perplexity is 200.87611207852666
At time: 34.65272808074951 and batch: 1650, loss is 5.281712160110474 and perplexity is 196.70638001199748
At time: 35.69197678565979 and batch: 1700, loss is 5.289470081329346 and perplexity is 198.2383473689219
At time: 36.73114252090454 and batch: 1750, loss is 5.313196678161621 and perplexity is 202.99811193010655
At time: 37.76813721656799 and batch: 1800, loss is 5.282632837295532 and perplexity is 196.88756648255622
At time: 38.80919694900513 and batch: 1850, loss is 5.265539388656617 and perplexity is 193.5506796777527
At time: 39.84785485267639 and batch: 1900, loss is 5.303809452056885 and perplexity is 201.10143893160972
At time: 40.886645555496216 and batch: 1950, loss is 5.22345853805542 and perplexity is 185.57489330402015
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.903883539244186 and perplexity of 134.81231329759845
finished 1 epochs...
Completing Train Step...
At time: 44.21972393989563 and batch: 50, loss is 5.107781200408936 and perplexity is 165.3031730601518
At time: 45.27976441383362 and batch: 100, loss is 5.049808797836303 and perplexity is 155.99263550537364
At time: 46.31307291984558 and batch: 150, loss is 4.981274003982544 and perplexity is 145.6598347040734
At time: 47.37080478668213 and batch: 200, loss is 4.956376113891602 and perplexity is 142.07798740100574
At time: 48.408464670181274 and batch: 250, loss is 4.960208492279053 and perplexity is 142.62352870189687
At time: 49.44356036186218 and batch: 300, loss is 4.984323358535766 and perplexity is 146.10468108671841
At time: 50.4794557094574 and batch: 350, loss is 4.982324085235596 and perplexity is 145.81286970134732
At time: 51.514991998672485 and batch: 400, loss is 4.948339939117432 and perplexity is 140.94079930380968
At time: 52.54755401611328 and batch: 450, loss is 4.917053337097168 and perplexity is 136.59950686949145
At time: 53.57820272445679 and batch: 500, loss is 4.918025674819947 and perplexity is 136.73239231723085
At time: 54.61302876472473 and batch: 550, loss is 4.878328084945679 and perplexity is 131.41077246837665
At time: 55.64773368835449 and batch: 600, loss is 4.863136548995971 and perplexity is 129.42952816918248
At time: 56.6842622756958 and batch: 650, loss is 4.932790584564209 and perplexity is 138.766211378336
At time: 57.7239670753479 and batch: 700, loss is 4.9263902759552005 and perplexity is 137.88090095312873
At time: 58.757378578186035 and batch: 750, loss is 4.88290678024292 and perplexity is 132.01384193636835
At time: 59.79047131538391 and batch: 800, loss is 4.856135959625244 and perplexity is 128.52660935947037
At time: 60.82584238052368 and batch: 850, loss is 4.85931097984314 and perplexity is 128.93533245141145
At time: 61.86559581756592 and batch: 900, loss is 4.870697622299194 and perplexity is 130.41186339360098
At time: 62.9015793800354 and batch: 950, loss is 4.93151047706604 and perplexity is 138.58868935853417
At time: 63.938366413116455 and batch: 1000, loss is 4.908190212249756 and perplexity is 135.39415785591208
At time: 64.97085881233215 and batch: 1050, loss is 4.830756759643554 and perplexity is 125.3057511189946
At time: 66.01184010505676 and batch: 1100, loss is 4.908929376602173 and perplexity is 135.4942733872824
At time: 67.0436851978302 and batch: 1150, loss is 4.834209184646607 and perplexity is 125.73910746188109
At time: 68.08388757705688 and batch: 1200, loss is 4.9057783603668215 and perplexity is 135.06800068085286
At time: 69.11788010597229 and batch: 1250, loss is 4.865374107360839 and perplexity is 129.71945853969586
At time: 70.1519706249237 and batch: 1300, loss is 4.888737945556641 and perplexity is 132.78588524085268
At time: 71.18736672401428 and batch: 1350, loss is 4.791349658966064 and perplexity is 120.46384410261486
At time: 72.22568082809448 and batch: 1400, loss is 4.8041688823699955 and perplexity is 122.01803752496183
At time: 73.2666425704956 and batch: 1450, loss is 4.73764045715332 and perplexity is 114.16450758068589
At time: 74.30270457267761 and batch: 1500, loss is 4.733474369049072 and perplexity is 113.68987754548297
At time: 75.34636807441711 and batch: 1550, loss is 4.725949726104736 and perplexity is 112.83761232758265
At time: 76.38381791114807 and batch: 1600, loss is 4.806548833847046 and perplexity is 122.30878037329711
At time: 77.42490005493164 and batch: 1650, loss is 4.774245128631592 and perplexity is 118.4208883342732
At time: 78.46850156784058 and batch: 1700, loss is 4.796100187301636 and perplexity is 121.0374724475091
At time: 79.50907921791077 and batch: 1750, loss is 4.801068449020386 and perplexity is 121.64031458713987
At time: 80.54828786849976 and batch: 1800, loss is 4.760145273208618 and perplexity is 116.76288718621882
At time: 81.58595323562622 and batch: 1850, loss is 4.779235591888428 and perplexity is 119.01334050216394
At time: 82.62192893028259 and batch: 1900, loss is 4.8501818561553955 and perplexity is 127.76362233463648
At time: 83.65993070602417 and batch: 1950, loss is 4.771534357070923 and perplexity is 118.10031106017396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.705543695494186 and perplexity of 110.55837870198464
finished 2 epochs...
Completing Train Step...
At time: 87.02441596984863 and batch: 50, loss is 4.72282000541687 and perplexity is 112.48501417259433
At time: 88.06787443161011 and batch: 100, loss is 4.668492527008056 and perplexity is 106.53701964050312
At time: 89.1112813949585 and batch: 150, loss is 4.6227258205413815 and perplexity is 101.77106404526404
At time: 90.15590047836304 and batch: 200, loss is 4.609832811355591 and perplexity is 100.46735123191739
At time: 91.19866585731506 and batch: 250, loss is 4.616454706192017 and perplexity is 101.13484305750977
At time: 92.24286937713623 and batch: 300, loss is 4.646546688079834 and perplexity is 104.22444388950325
At time: 93.28757834434509 and batch: 350, loss is 4.654998817443848 and perplexity is 105.10909570141835
At time: 94.32837009429932 and batch: 400, loss is 4.618696765899658 and perplexity is 101.36184779816601
At time: 95.37034869194031 and batch: 450, loss is 4.617902345657349 and perplexity is 101.28135587091866
At time: 96.4154155254364 and batch: 500, loss is 4.627916917800904 and perplexity is 102.30074115015668
At time: 97.46294927597046 and batch: 550, loss is 4.598543128967285 and perplexity is 99.33948534941106
At time: 98.51285910606384 and batch: 600, loss is 4.57495457649231 and perplexity is 97.02363188314867
At time: 99.59071755409241 and batch: 650, loss is 4.640946350097656 and perplexity is 103.64238316740399
At time: 100.63351774215698 and batch: 700, loss is 4.643789014816284 and perplexity is 103.9374228641785
At time: 101.67705750465393 and batch: 750, loss is 4.596073751449585 and perplexity is 99.09448128593168
At time: 102.71862053871155 and batch: 800, loss is 4.574123973846436 and perplexity is 96.94307725686829
At time: 103.76207995414734 and batch: 850, loss is 4.580406742095947 and perplexity is 97.55406548358097
At time: 104.81148076057434 and batch: 900, loss is 4.585393342971802 and perplexity is 98.04174358944192
At time: 105.8548002243042 and batch: 950, loss is 4.658661851882934 and perplexity is 105.4948199681723
At time: 106.90268039703369 and batch: 1000, loss is 4.638255071640015 and perplexity is 103.36382765763926
At time: 107.94790172576904 and batch: 1050, loss is 4.569114732742309 and perplexity is 96.45868025309744
At time: 108.99182605743408 and batch: 1100, loss is 4.640108337402344 and perplexity is 103.55556591659719
At time: 110.03300070762634 and batch: 1150, loss is 4.578375883102417 and perplexity is 97.35614797164182
At time: 111.07784390449524 and batch: 1200, loss is 4.645952520370483 and perplexity is 104.16253548422806
At time: 112.12277817726135 and batch: 1250, loss is 4.62019453048706 and perplexity is 101.5137777335482
At time: 113.1706211566925 and batch: 1300, loss is 4.6337854766845705 and perplexity is 102.90286414246577
At time: 114.21758794784546 and batch: 1350, loss is 4.524896612167359 and perplexity is 92.2863840461854
At time: 115.2633261680603 and batch: 1400, loss is 4.533672714233399 and perplexity is 93.09986313848073
At time: 116.30623054504395 and batch: 1450, loss is 4.46990345954895 and perplexity is 87.34828996307087
At time: 117.34860467910767 and batch: 1500, loss is 4.472155475616455 and perplexity is 87.54522137866346
At time: 118.39310646057129 and batch: 1550, loss is 4.473109521865845 and perplexity is 87.62878342346124
At time: 119.4388062953949 and batch: 1600, loss is 4.566386995315551 and perplexity is 96.19592482765984
At time: 120.48678135871887 and batch: 1650, loss is 4.522452735900879 and perplexity is 92.06112290978317
At time: 121.54168319702148 and batch: 1700, loss is 4.555686311721802 and perplexity is 95.17205052041543
At time: 122.59176516532898 and batch: 1750, loss is 4.560516262054444 and perplexity is 95.63283869369211
At time: 123.63444423675537 and batch: 1800, loss is 4.507331476211548 and perplexity is 90.67951491518637
At time: 124.68326544761658 and batch: 1850, loss is 4.540548934936523 and perplexity is 93.74224439137761
At time: 125.73367881774902 and batch: 1900, loss is 4.624576606750488 and perplexity is 101.95959493845741
At time: 126.78074193000793 and batch: 1950, loss is 4.547463579177856 and perplexity is 94.39268485233588
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6437991120094475 and perplexity of 103.93847234571246
finished 3 epochs...
Completing Train Step...
At time: 130.16322660446167 and batch: 50, loss is 4.501828927993774 and perplexity is 90.18191679634606
At time: 131.22541451454163 and batch: 100, loss is 4.457634449005127 and perplexity is 86.28316027721046
At time: 132.26039099693298 and batch: 150, loss is 4.411051912307739 and perplexity is 82.35604929775974
At time: 133.29586839675903 and batch: 200, loss is 4.405306062698364 and perplexity is 81.88420070775518
At time: 134.33185482025146 and batch: 250, loss is 4.4071684741973876 and perplexity is 82.03684488375447
At time: 135.37395811080933 and batch: 300, loss is 4.434631900787354 and perplexity is 84.32108065156429
At time: 136.41051816940308 and batch: 350, loss is 4.450494260787964 and perplexity is 85.66927650380002
At time: 137.4462695121765 and batch: 400, loss is 4.414235544204712 and perplexity is 82.618658446838
At time: 138.48112678527832 and batch: 450, loss is 4.422615127563477 and perplexity is 83.313877135727
At time: 139.51525807380676 and batch: 500, loss is 4.446589736938477 and perplexity is 85.33543094862016
At time: 140.54875349998474 and batch: 550, loss is 4.414715662002563 and perplexity is 82.65833465905857
At time: 141.5848307609558 and batch: 600, loss is 4.386859626770019 and perplexity is 80.38757518719044
At time: 142.62167191505432 and batch: 650, loss is 4.446005153656006 and perplexity is 85.28555986060752
At time: 143.65848422050476 and batch: 700, loss is 4.460932674407959 and perplexity is 86.5682114113135
At time: 144.6939182281494 and batch: 750, loss is 4.4181990051269535 and perplexity is 82.94676405840687
At time: 145.72667264938354 and batch: 800, loss is 4.39413592338562 and perplexity is 80.9746322389633
At time: 146.76144218444824 and batch: 850, loss is 4.396186065673828 and perplexity is 81.1408120447065
At time: 147.7959680557251 and batch: 900, loss is 4.3993734359741214 and perplexity is 81.39985046553937
At time: 148.83130168914795 and batch: 950, loss is 4.478381032943726 and perplexity is 88.0919392189266
At time: 149.86768221855164 and batch: 1000, loss is 4.454634456634522 and perplexity is 86.02469933893326
At time: 150.9018976688385 and batch: 1050, loss is 4.396237459182739 and perplexity is 81.1449822629135
At time: 151.9819495677948 and batch: 1100, loss is 4.462690191268921 and perplexity is 86.72049027963408
At time: 153.01433801651 and batch: 1150, loss is 4.409359264373779 and perplexity is 82.21676741191914
At time: 154.05603098869324 and batch: 1200, loss is 4.470528678894043 and perplexity is 87.40291887946468
At time: 155.10082530975342 and batch: 1250, loss is 4.453750848770142 and perplexity is 85.94872081062245
At time: 156.14257764816284 and batch: 1300, loss is 4.4592584705352785 and perplexity is 86.4233998323958
At time: 157.18219757080078 and batch: 1350, loss is 4.350073347091675 and perplexity is 77.4841459535981
At time: 158.22468733787537 and batch: 1400, loss is 4.360126819610596 and perplexity is 78.26705959173782
At time: 159.26231384277344 and batch: 1450, loss is 4.290372614860535 and perplexity is 72.99366195614486
At time: 160.3045608997345 and batch: 1500, loss is 4.302102127075195 and perplexity is 73.85488298294801
At time: 161.3461172580719 and batch: 1550, loss is 4.307829914093017 and perplexity is 74.27912183795128
At time: 162.38700461387634 and batch: 1600, loss is 4.403064432144165 and perplexity is 81.70085215817373
At time: 163.42764711380005 and batch: 1650, loss is 4.351837568283081 and perplexity is 77.62096578061919
At time: 164.4690592288971 and batch: 1700, loss is 4.393185567855835 and perplexity is 80.89771410501889
At time: 165.50886416435242 and batch: 1750, loss is 4.390274753570557 and perplexity is 80.66257826755532
At time: 166.54597640037537 and batch: 1800, loss is 4.334882869720459 and perplexity is 76.31601944954676
At time: 167.58794283866882 and batch: 1850, loss is 4.377328119277954 and perplexity is 79.62500042883052
At time: 168.6245391368866 and batch: 1900, loss is 4.461576814651489 and perplexity is 86.62399144324694
At time: 169.66822981834412 and batch: 1950, loss is 4.394820575714111 and perplexity is 81.03009069218766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.617824820585029 and perplexity of 101.27350433082965
finished 4 epochs...
Completing Train Step...
At time: 172.96705436706543 and batch: 50, loss is 4.340615305900574 and perplexity is 76.75475246363668
At time: 174.0305881500244 and batch: 100, loss is 4.304724473953247 and perplexity is 74.04881026593806
At time: 175.06661939620972 and batch: 150, loss is 4.267610969543457 and perplexity is 71.35097219465403
At time: 176.10367608070374 and batch: 200, loss is 4.254598188400268 and perplexity is 70.42851250896115
At time: 177.14025855064392 and batch: 250, loss is 4.257296743392945 and perplexity is 70.61882439106806
At time: 178.20614886283875 and batch: 300, loss is 4.284080066680908 and perplexity is 72.53578792950177
At time: 179.23754835128784 and batch: 350, loss is 4.2958132266998295 and perplexity is 73.39187441502067
At time: 180.27005314826965 and batch: 400, loss is 4.262278518676758 and perplexity is 70.97150927399447
At time: 181.3037886619568 and batch: 450, loss is 4.2814739799499515 and perplexity is 72.34699948144326
At time: 182.3386688232422 and batch: 500, loss is 4.3111841583251955 and perplexity is 74.5286904770412
At time: 183.37516117095947 and batch: 550, loss is 4.27637809753418 and perplexity is 71.97926543944774
At time: 184.4154932498932 and batch: 600, loss is 4.24897255897522 and perplexity is 70.03342016017982
At time: 185.44873523712158 and batch: 650, loss is 4.3054663181304935 and perplexity is 74.10376332544931
At time: 186.4802589416504 and batch: 700, loss is 4.321805086135864 and perplexity is 75.32447281117115
At time: 187.51474118232727 and batch: 750, loss is 4.284040660858154 and perplexity is 72.532929653416
At time: 188.55566310882568 and batch: 800, loss is 4.259018421173096 and perplexity is 70.74051197522883
At time: 189.59687972068787 and batch: 850, loss is 4.252788496017456 and perplexity is 70.30117382301859
At time: 190.63323974609375 and batch: 900, loss is 4.258695955276489 and perplexity is 70.71770425016274
At time: 191.66862797737122 and batch: 950, loss is 4.340235233306885 and perplexity is 76.72558562889823
At time: 192.70230650901794 and batch: 1000, loss is 4.315899114608765 and perplexity is 74.88091971471256
At time: 193.7340271472931 and batch: 1050, loss is 4.261996698379517 and perplexity is 70.95151088026422
At time: 194.7676112651825 and batch: 1100, loss is 4.324355549812317 and perplexity is 75.51683033919645
At time: 195.80858707427979 and batch: 1150, loss is 4.276494393348694 and perplexity is 71.98763681351856
At time: 196.85303807258606 and batch: 1200, loss is 4.3342096853256225 and perplexity is 76.26466198463878
At time: 197.89201188087463 and batch: 1250, loss is 4.318965501785279 and perplexity is 75.11088600934718
At time: 198.93370532989502 and batch: 1300, loss is 4.328691110610962 and perplexity is 75.84494892351609
At time: 199.97500681877136 and batch: 1350, loss is 4.211419992446899 and perplexity is 67.45225352819165
At time: 201.01713299751282 and batch: 1400, loss is 4.226175279617309 and perplexity is 68.45490994966923
At time: 202.06489729881287 and batch: 1450, loss is 4.154691300392151 and perplexity is 63.73228737868086
At time: 203.11374378204346 and batch: 1500, loss is 4.169712424278259 and perplexity is 64.69684419027632
At time: 204.16271328926086 and batch: 1550, loss is 4.170136799812317 and perplexity is 64.72430577468155
At time: 205.2054545879364 and batch: 1600, loss is 4.270597810745239 and perplexity is 71.56440480417493
At time: 206.2495355606079 and batch: 1650, loss is 4.220116324424744 and perplexity is 68.041398705654
At time: 207.29203629493713 and batch: 1700, loss is 4.260914206504822 and perplexity is 70.87474800133118
At time: 208.33015847206116 and batch: 1750, loss is 4.262392234802246 and perplexity is 70.97958033794554
At time: 209.37494492530823 and batch: 1800, loss is 4.204487695693969 and perplexity is 66.98627151899481
At time: 210.41767477989197 and batch: 1850, loss is 4.244930419921875 and perplexity is 69.7509067015161
At time: 211.4605348110199 and batch: 1900, loss is 4.334503660202026 and perplexity is 76.28708517498549
At time: 212.50533533096313 and batch: 1950, loss is 4.2685328340530395 and perplexity is 71.4167784512103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607579714752907 and perplexity of 100.24124340122069
finished 5 epochs...
Completing Train Step...
At time: 215.84544682502747 and batch: 50, loss is 4.222194938659668 and perplexity is 68.18297761856367
At time: 216.8802936077118 and batch: 100, loss is 4.178416938781738 and perplexity is 65.26245692970542
At time: 217.91610598564148 and batch: 150, loss is 4.148842735290527 and perplexity is 63.36063282917713
At time: 218.95346236228943 and batch: 200, loss is 4.139294023513794 and perplexity is 62.75849978085982
At time: 219.99046111106873 and batch: 250, loss is 4.140354604721069 and perplexity is 62.82509557520574
At time: 221.03356528282166 and batch: 300, loss is 4.166743178367614 and perplexity is 64.50502826548532
At time: 222.0675539970398 and batch: 350, loss is 4.173963174819947 and perplexity is 64.97243966459446
At time: 223.10366559028625 and batch: 400, loss is 4.136737856864929 and perplexity is 62.598283453840686
At time: 224.14065432548523 and batch: 450, loss is 4.164168848991394 and perplexity is 64.33918463596072
At time: 225.1825726032257 and batch: 500, loss is 4.1954562377929685 and perplexity is 66.38401156425688
At time: 226.2152543067932 and batch: 550, loss is 4.163140525817871 and perplexity is 64.27305716746535
At time: 227.2593650817871 and batch: 600, loss is 4.1371711730957035 and perplexity is 62.625414183748134
At time: 228.29466032981873 and batch: 650, loss is 4.19209849357605 and perplexity is 66.16148483632016
At time: 229.32634830474854 and batch: 700, loss is 4.209546165466309 and perplexity is 67.32597802180283
At time: 230.3871533870697 and batch: 750, loss is 4.174703326225281 and perplexity is 65.02054690824599
At time: 231.4234104156494 and batch: 800, loss is 4.149415974617004 and perplexity is 63.39696404791208
At time: 232.45838522911072 and batch: 850, loss is 4.142051749229431 and perplexity is 62.93180936989984
At time: 233.4970827102661 and batch: 900, loss is 4.148224115371704 and perplexity is 63.32144880089957
At time: 234.53217673301697 and batch: 950, loss is 4.230718026161194 and perplexity is 68.76659066249455
At time: 235.56549191474915 and batch: 1000, loss is 4.200973281860351 and perplexity is 66.7512672327434
At time: 236.60698437690735 and batch: 1050, loss is 4.155215644836426 and perplexity is 63.765713812205334
At time: 237.64234352111816 and batch: 1100, loss is 4.213420557975769 and perplexity is 67.58733125231265
At time: 238.67498397827148 and batch: 1150, loss is 4.1740808057785035 and perplexity is 64.98008288448281
At time: 239.70894527435303 and batch: 1200, loss is 4.227588005065918 and perplexity is 68.55168628613856
At time: 240.745995759964 and batch: 1250, loss is 4.215604109764099 and perplexity is 67.7350729324406
At time: 241.78094696998596 and batch: 1300, loss is 4.22084900856018 and perplexity is 68.09126982669713
At time: 242.82341885566711 and batch: 1350, loss is 4.10041229724884 and perplexity is 60.365170861230716
At time: 243.86613297462463 and batch: 1400, loss is 4.117427554130554 and perplexity is 61.401087954854574
At time: 244.89743185043335 and batch: 1450, loss is 4.044437761306763 and perplexity is 57.079084940623915
At time: 245.93877696990967 and batch: 1500, loss is 4.062550601959228 and perplexity is 58.12236920879333
At time: 246.97973775863647 and batch: 1550, loss is 4.064065055847168 and perplexity is 58.210459544356674
At time: 248.01214623451233 and batch: 1600, loss is 4.163568501472473 and perplexity is 64.30057035824782
At time: 249.0473816394806 and batch: 1650, loss is 4.105842404365539 and perplexity is 60.6938517838083
At time: 250.0905134677887 and batch: 1700, loss is 4.15056990146637 and perplexity is 63.47016173115906
At time: 251.12718081474304 and batch: 1750, loss is 4.15018771648407 and perplexity is 63.445909023326834
At time: 252.16225171089172 and batch: 1800, loss is 4.092606558799743 and perplexity is 59.89581036185914
At time: 253.19581866264343 and batch: 1850, loss is 4.135462794303894 and perplexity is 62.51851759026362
At time: 254.2329442501068 and batch: 1900, loss is 4.2270467519760135 and perplexity is 68.51459251358308
At time: 255.27224040031433 and batch: 1950, loss is 4.157491250038147 and perplexity is 63.910984629072146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.61036746002907 and perplexity of 100.5210803297971
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 258.6062572002411 and batch: 50, loss is 4.148131222724914 and perplexity is 63.3155669771152
At time: 259.67605924606323 and batch: 100, loss is 4.13320378780365 and perplexity is 62.37744725203855
At time: 260.71861839294434 and batch: 150, loss is 4.10525454044342 and perplexity is 60.658182543407165
At time: 261.76165556907654 and batch: 200, loss is 4.0868319368362425 and perplexity is 59.55093143091453
At time: 262.8048348426819 and batch: 250, loss is 4.080326008796692 and perplexity is 59.16475493672096
At time: 263.84707021713257 and batch: 300, loss is 4.109467163085937 and perplexity is 60.91425155902274
At time: 264.88897371292114 and batch: 350, loss is 4.113128676414489 and perplexity is 61.137698730763326
At time: 265.9313049316406 and batch: 400, loss is 4.0655690908432005 and perplexity is 58.29807598522658
At time: 266.9786458015442 and batch: 450, loss is 4.080199398994446 and perplexity is 59.15726457298524
At time: 268.01764965057373 and batch: 500, loss is 4.112032961845398 and perplexity is 61.07074595081011
At time: 269.05860924720764 and batch: 550, loss is 4.076522307395935 and perplexity is 58.94013733545162
At time: 270.0957317352295 and batch: 600, loss is 4.040494956970215 and perplexity is 56.85447636180796
At time: 271.1322476863861 and batch: 650, loss is 4.078469347953797 and perplexity is 59.05500796592866
At time: 272.1695897579193 and batch: 700, loss is 4.099998598098755 and perplexity is 60.340203006296946
At time: 273.20932507514954 and batch: 750, loss is 4.043717722892762 and perplexity is 57.03800059975748
At time: 274.25107860565186 and batch: 800, loss is 4.013210520744324 and perplexity is 55.324205251417304
At time: 275.29525446891785 and batch: 850, loss is 4.012466731071473 and perplexity is 55.28307097841268
At time: 276.3462014198303 and batch: 900, loss is 4.0075627708435055 and perplexity is 55.01262865823054
At time: 277.3854749202728 and batch: 950, loss is 4.094746556282043 and perplexity is 60.02412449222297
At time: 278.42587447166443 and batch: 1000, loss is 4.052070631980896 and perplexity is 57.51642918687911
At time: 279.473028421402 and batch: 1050, loss is 4.00340895652771 and perplexity is 54.78459035602682
At time: 280.51384139060974 and batch: 1100, loss is 4.048501987457275 and perplexity is 57.31153930386578
At time: 281.5543222427368 and batch: 1150, loss is 3.9974431467056273 and perplexity is 54.45872888902662
At time: 282.5984880924225 and batch: 1200, loss is 4.04382933139801 and perplexity is 57.044366881005736
At time: 283.69142413139343 and batch: 1250, loss is 4.02081714630127 and perplexity is 55.7466403810612
At time: 284.72834610939026 and batch: 1300, loss is 4.022795038223267 and perplexity is 55.85701032467819
At time: 285.76540350914 and batch: 1350, loss is 3.897218050956726 and perplexity is 49.26520500107195
At time: 286.8036456108093 and batch: 1400, loss is 3.9023975276947023 and perplexity is 49.52103494506005
At time: 287.8424837589264 and batch: 1450, loss is 3.8232708549499512 and perplexity is 45.75361728569551
At time: 288.8813970088959 and batch: 1500, loss is 3.8418215703964234 and perplexity is 46.61030110212133
At time: 289.9205975532532 and batch: 1550, loss is 3.832809748649597 and perplexity is 46.19214438390044
At time: 290.9630489349365 and batch: 1600, loss is 3.9220302295684815 and perplexity is 50.502873192733865
At time: 292.00662994384766 and batch: 1650, loss is 3.856567211151123 and perplexity is 47.30269218701111
At time: 293.0447795391083 and batch: 1700, loss is 3.889893789291382 and perplexity is 48.90569193968017
At time: 294.0854744911194 and batch: 1750, loss is 3.8669777584075926 and perplexity is 47.79771133869895
At time: 295.1255283355713 and batch: 1800, loss is 3.8105059051513672 and perplexity is 45.17328648480432
At time: 296.1653587818146 and batch: 1850, loss is 3.8392714357376097 and perplexity is 46.491589986821204
At time: 297.20693469047546 and batch: 1900, loss is 3.9170928764343262 and perplexity is 50.25413722743642
At time: 298.2539734840393 and batch: 1950, loss is 3.8535574436187745 and perplexity is 47.1605361155506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5205949650254365 and perplexity of 91.89025320440561
finished 7 epochs...
Completing Train Step...
At time: 301.53877902030945 and batch: 50, loss is 4.0390656328201295 and perplexity is 56.77327093396814
At time: 302.6100389957428 and batch: 100, loss is 4.0143221712112425 and perplexity is 55.385740626594256
At time: 303.6451599597931 and batch: 150, loss is 3.9844731426239015 and perplexity is 53.756959764917156
At time: 304.6859917640686 and batch: 200, loss is 3.9666837358474734 and perplexity is 52.809111169162954
At time: 305.7186539173126 and batch: 250, loss is 3.9628067588806153 and perplexity is 52.60476783467657
At time: 306.751012802124 and batch: 300, loss is 3.989514961242676 and perplexity is 54.02867700448139
At time: 307.7902555465698 and batch: 350, loss is 3.9970021295547484 and perplexity is 54.43471695079897
At time: 308.8345067501068 and batch: 400, loss is 3.9537608575820924 and perplexity is 52.13105610204996
At time: 309.90533113479614 and batch: 450, loss is 3.977211356163025 and perplexity is 53.36800217505615
At time: 310.94906210899353 and batch: 500, loss is 4.011345844268799 and perplexity is 55.221139629241854
At time: 311.9882159233093 and batch: 550, loss is 3.977900152206421 and perplexity is 53.40477450666267
At time: 313.0203711986542 and batch: 600, loss is 3.9457063722610473 and perplexity is 51.71285373919664
At time: 314.053982257843 and batch: 650, loss is 3.9856409549713137 and perplexity is 53.81977447704936
At time: 315.09347772598267 and batch: 700, loss is 4.010211009979248 and perplexity is 55.15850833127637
At time: 316.135525226593 and batch: 750, loss is 3.9595501899719237 and perplexity is 52.43373542386624
At time: 317.18424105644226 and batch: 800, loss is 3.9318152332305907 and perplexity is 50.99946962857731
At time: 318.2311546802521 and batch: 850, loss is 3.933205256462097 and perplexity is 51.07040936867665
At time: 319.2722713947296 and batch: 900, loss is 3.929523072242737 and perplexity is 50.88270450724505
At time: 320.3119239807129 and batch: 950, loss is 4.01755199432373 and perplexity is 55.56491596834282
At time: 321.354257106781 and batch: 1000, loss is 3.9768460273742674 and perplexity is 53.348508868412985
At time: 322.39495730400085 and batch: 1050, loss is 3.9337283420562743 and perplexity is 51.09713055222995
At time: 323.4310870170593 and batch: 1100, loss is 3.9784439992904663 and perplexity is 53.4338264367399
At time: 324.4665334224701 and batch: 1150, loss is 3.934249396324158 and perplexity is 51.12376186775857
At time: 325.5015950202942 and batch: 1200, loss is 3.980617322921753 and perplexity is 53.55008171886149
At time: 326.5414113998413 and batch: 1250, loss is 3.9642078733444213 and perplexity is 52.678524794660454
At time: 327.57525658607483 and batch: 1300, loss is 3.968914132118225 and perplexity is 52.927027865373084
At time: 328.6153826713562 and batch: 1350, loss is 3.845126361846924 and perplexity is 46.76459323794758
At time: 329.6506326198578 and batch: 1400, loss is 3.855153350830078 and perplexity is 47.235860044239836
At time: 330.68509006500244 and batch: 1450, loss is 3.7798603868484495 and perplexity is 43.80992486690639
At time: 331.71979999542236 and batch: 1500, loss is 3.7993642568588255 and perplexity is 44.672775053366976
At time: 332.7598030567169 and batch: 1550, loss is 3.7952739286422728 and perplexity is 44.490421937344884
At time: 333.7979369163513 and batch: 1600, loss is 3.8898284959793092 and perplexity is 48.90249882931973
At time: 334.83854484558105 and batch: 1650, loss is 3.826001596450806 and perplexity is 45.87872933381664
At time: 335.87100410461426 and batch: 1700, loss is 3.8633536529541015 and perplexity is 47.62480090444829
At time: 336.90597653388977 and batch: 1750, loss is 3.847395586967468 and perplexity is 46.87083312319421
At time: 337.94468235969543 and batch: 1800, loss is 3.7949050951004026 and perplexity is 44.47401540326847
At time: 338.98175573349 and batch: 1850, loss is 3.8277438735961913 and perplexity is 45.95873246897359
At time: 340.01601362228394 and batch: 1900, loss is 3.9098338317871093 and perplexity is 49.890661042596975
At time: 341.0513925552368 and batch: 1950, loss is 3.8499346494674684 and perplexity is 46.989992310216074
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.520495889353198 and perplexity of 91.88114956677914
finished 8 epochs...
Completing Train Step...
At time: 344.3818838596344 and batch: 50, loss is 3.9847943019866943 and perplexity is 53.77422708849383
At time: 345.4227726459503 and batch: 100, loss is 3.9573599243164064 and perplexity is 52.319017291430725
At time: 346.4610879421234 and batch: 150, loss is 3.926729974746704 and perplexity is 50.74078244603721
At time: 347.49799823760986 and batch: 200, loss is 3.9097408771514894 and perplexity is 49.88602368991398
At time: 348.5406460762024 and batch: 250, loss is 3.9057669639587402 and perplexity is 49.68817434067783
At time: 349.5804295539856 and batch: 300, loss is 3.933436269760132 and perplexity is 51.08220867522279
At time: 350.6292610168457 and batch: 350, loss is 3.942083468437195 and perplexity is 51.52584201094605
At time: 351.6733012199402 and batch: 400, loss is 3.8989516830444337 and perplexity is 49.35068681686921
At time: 352.7209196090698 and batch: 450, loss is 3.924767475128174 and perplexity is 50.64130132759992
At time: 353.7596597671509 and batch: 500, loss is 3.961236906051636 and perplexity is 52.52225087775913
At time: 354.7985272407532 and batch: 550, loss is 3.927863302230835 and perplexity is 50.79832096818518
At time: 355.84861516952515 and batch: 600, loss is 3.8970443344116212 and perplexity is 49.25664756317108
At time: 356.8837044239044 and batch: 650, loss is 3.9371920919418333 and perplexity is 51.27442510707113
At time: 357.92567801475525 and batch: 700, loss is 3.962261366844177 and perplexity is 52.57608543550788
At time: 358.965856552124 and batch: 750, loss is 3.913148493766785 and perplexity is 50.05630609691599
At time: 360.0078601837158 and batch: 800, loss is 3.885578546524048 and perplexity is 48.695106696261455
At time: 361.0769443511963 and batch: 850, loss is 3.888802757263184 and perplexity is 48.85236336029683
At time: 362.1217303276062 and batch: 900, loss is 3.884986786842346 and perplexity is 48.66629941975546
At time: 363.16522002220154 and batch: 950, loss is 3.9734876108169557 and perplexity is 53.16964287429803
At time: 364.2098398208618 and batch: 1000, loss is 3.9337972259521483 and perplexity is 51.10065044288087
At time: 365.25304651260376 and batch: 1050, loss is 3.8933086967468262 and perplexity is 49.07298583570897
At time: 366.2896168231964 and batch: 1100, loss is 3.936924514770508 and perplexity is 51.260707076837356
At time: 367.3340311050415 and batch: 1150, loss is 3.894495687484741 and perplexity is 49.13126959967856
At time: 368.3732578754425 and batch: 1200, loss is 3.94221809387207 and perplexity is 51.53277916678241
At time: 369.4190139770508 and batch: 1250, loss is 3.9286780738830567 and perplexity is 50.839726865975784
At time: 370.4659614562988 and batch: 1300, loss is 3.93379008769989 and perplexity is 51.10028567484935
At time: 371.5047061443329 and batch: 1350, loss is 3.8105730390548707 and perplexity is 45.17631924565953
At time: 372.54705452919006 and batch: 1400, loss is 3.823157787322998 and perplexity is 45.74844432521719
At time: 373.58682346343994 and batch: 1450, loss is 3.749187808036804 and perplexity is 42.48656073983868
At time: 374.62503480911255 and batch: 1500, loss is 3.768318476676941 and perplexity is 43.30718153972871
At time: 375.6638340950012 and batch: 1550, loss is 3.765937876701355 and perplexity is 43.20420708353838
At time: 376.7057247161865 and batch: 1600, loss is 3.8638449621200563 and perplexity is 47.64820515454994
At time: 377.7499530315399 and batch: 1650, loss is 3.798678684234619 and perplexity is 44.64215911766589
At time: 378.79025769233704 and batch: 1700, loss is 3.8384933710098266 and perplexity is 46.45543058951391
At time: 379.83566451072693 and batch: 1750, loss is 3.825816822052002 and perplexity is 45.87025290232399
At time: 380.88042879104614 and batch: 1800, loss is 3.774083724021912 and perplexity is 43.55757926195927
At time: 381.92153310775757 and batch: 1850, loss is 3.808071174621582 and perplexity is 45.0634354881223
At time: 382.9598276615143 and batch: 1900, loss is 3.891754970550537 and perplexity is 48.99679905411174
At time: 383.99644947052 and batch: 1950, loss is 3.8332208967208863 and perplexity is 46.21114009973097
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.524480207576308 and perplexity of 92.24796357196317
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 387.33639335632324 and batch: 50, loss is 3.960260338783264 and perplexity is 52.47098440334546
At time: 388.4106888771057 and batch: 100, loss is 3.9555596351623534 and perplexity is 52.22491266523561
At time: 389.45532965660095 and batch: 150, loss is 3.9370562267303466 and perplexity is 51.2674591696851
At time: 390.5027961730957 and batch: 200, loss is 3.9254378843307496 and perplexity is 50.675263104912375
At time: 391.55058431625366 and batch: 250, loss is 3.920813789367676 and perplexity is 50.44147681760631
At time: 392.59086060523987 and batch: 300, loss is 3.9447717380523684 and perplexity is 51.66454371668014
At time: 393.63185954093933 and batch: 350, loss is 3.9562192296981813 and perplexity is 52.25937129537645
At time: 394.674067735672 and batch: 400, loss is 3.913514356613159 and perplexity is 50.0746231901112
At time: 395.71287727355957 and batch: 450, loss is 3.937426571846008 and perplexity is 51.28644933902215
At time: 396.7585265636444 and batch: 500, loss is 3.9670833921432496 and perplexity is 52.83022088094968
At time: 397.79879903793335 and batch: 550, loss is 3.9349097347259523 and perplexity is 51.157531999594376
At time: 398.83985710144043 and batch: 600, loss is 3.8955445861816407 and perplexity is 49.18283036061895
At time: 399.88036251068115 and batch: 650, loss is 3.9294727277755737 and perplexity is 50.880142909080504
At time: 400.9200007915497 and batch: 700, loss is 3.951092715263367 and perplexity is 51.992148420283065
At time: 401.9597382545471 and batch: 750, loss is 3.8989385032653807 and perplexity is 49.3500363900071
At time: 403.0013303756714 and batch: 800, loss is 3.8661661958694458 and perplexity is 47.75893624310302
At time: 404.0396771430969 and batch: 850, loss is 3.867019543647766 and perplexity is 47.79970861927511
At time: 405.0804624557495 and batch: 900, loss is 3.8564708995819093 and perplexity is 47.298136609879464
At time: 406.11924624443054 and batch: 950, loss is 3.9513020372390746 and perplexity is 52.003032658627085
At time: 407.16384530067444 and batch: 1000, loss is 3.910808787345886 and perplexity is 49.93932593911237
At time: 408.20394945144653 and batch: 1050, loss is 3.8695722150802614 and perplexity is 47.921881437138964
At time: 409.2458562850952 and batch: 1100, loss is 3.9051783370971678 and perplexity is 49.65893515288832
At time: 410.28603959083557 and batch: 1150, loss is 3.8605487155914306 and perplexity is 47.49140349415236
At time: 411.33129239082336 and batch: 1200, loss is 3.9072342777252196 and perplexity is 49.76113599865112
At time: 412.37899827957153 and batch: 1250, loss is 3.8863009548187257 and perplexity is 48.73029715465816
At time: 413.425252199173 and batch: 1300, loss is 3.883389563560486 and perplexity is 48.58863051708198
At time: 414.4662528038025 and batch: 1350, loss is 3.757842321395874 and perplexity is 42.8558569819332
At time: 415.50679421424866 and batch: 1400, loss is 3.7698427391052247 and perplexity is 43.37324338442796
At time: 416.54840660095215 and batch: 1450, loss is 3.6903277397155763 and perplexity is 40.057973394948775
At time: 417.5883295536041 and batch: 1500, loss is 3.706687955856323 and perplexity is 40.71872074485924
At time: 418.6270568370819 and batch: 1550, loss is 3.709035701751709 and perplexity is 40.81443026120356
At time: 419.66615200042725 and batch: 1600, loss is 3.8014434814453124 and perplexity is 44.76575641667498
At time: 420.7046911716461 and batch: 1650, loss is 3.7275006771087646 and perplexity is 41.57506868319456
At time: 421.74545454978943 and batch: 1700, loss is 3.761484818458557 and perplexity is 43.01224396175696
At time: 422.78518652915955 and batch: 1750, loss is 3.7475448560714724 and perplexity is 42.41681467177951
At time: 423.8235878944397 and batch: 1800, loss is 3.6909032344818113 and perplexity is 40.08103318374099
At time: 424.8610141277313 and batch: 1850, loss is 3.719422402381897 and perplexity is 41.240566774829254
At time: 425.89901328086853 and batch: 1900, loss is 3.804248876571655 and perplexity is 44.891518375064535
At time: 426.9386718273163 and batch: 1950, loss is 3.750328278541565 and perplexity is 42.53504305027875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496552223382994 and perplexity of 89.70730674992559
finished 10 epochs...
Completing Train Step...
At time: 430.23006081581116 and batch: 50, loss is 3.9425225496292113 and perplexity is 51.548471006695515
At time: 431.2909324169159 and batch: 100, loss is 3.923710699081421 and perplexity is 50.58781308090733
At time: 432.3260283470154 and batch: 150, loss is 3.899401535987854 and perplexity is 49.37289236283423
At time: 433.3624897003174 and batch: 200, loss is 3.8840424251556396 and perplexity is 48.62036252508528
At time: 434.40385484695435 and batch: 250, loss is 3.877383337020874 and perplexity is 48.29767085446174
At time: 435.4434549808502 and batch: 300, loss is 3.89952214717865 and perplexity is 49.37884764530477
At time: 436.4855670928955 and batch: 350, loss is 3.912003126144409 and perplexity is 49.99900604569273
At time: 437.5251896381378 and batch: 400, loss is 3.868740396499634 and perplexity is 47.88203570025058
At time: 438.56655287742615 and batch: 450, loss is 3.8958531332015993 and perplexity is 49.19800791773445
At time: 439.61401653289795 and batch: 500, loss is 3.9275858354568483 and perplexity is 50.784228077187116
At time: 440.68702483177185 and batch: 550, loss is 3.8976291942596437 and perplexity is 49.285464224611665
At time: 441.7365765571594 and batch: 600, loss is 3.86045205116272 and perplexity is 47.48681298663789
At time: 442.78107261657715 and batch: 650, loss is 3.894403691291809 and perplexity is 49.12674991782142
At time: 443.8271634578705 and batch: 700, loss is 3.918195519447327 and perplexity is 50.30958016198944
At time: 444.8730790615082 and batch: 750, loss is 3.8690187072753908 and perplexity is 47.89536364131992
At time: 445.9180152416229 and batch: 800, loss is 3.8367144298553466 and perplexity is 46.372862575782754
At time: 446.9620749950409 and batch: 850, loss is 3.839083933830261 and perplexity is 46.48287354222354
At time: 448.00940108299255 and batch: 900, loss is 3.829761667251587 and perplexity is 46.051561331007946
At time: 449.0466809272766 and batch: 950, loss is 3.9247383880615234 and perplexity is 50.63982834211546
At time: 450.080849647522 and batch: 1000, loss is 3.884735417366028 and perplexity is 48.65406773495649
At time: 451.1271753311157 and batch: 1050, loss is 3.845254716873169 and perplexity is 46.77059609378009
At time: 452.1665210723877 and batch: 1100, loss is 3.882444396018982 and perplexity is 48.54272781691947
At time: 453.207478761673 and batch: 1150, loss is 3.8400752258300783 and perplexity is 46.528974488869125
At time: 454.2468774318695 and batch: 1200, loss is 3.8882317781448363 and perplexity is 48.82447764277498
At time: 455.28492498397827 and batch: 1250, loss is 3.869804410934448 and perplexity is 47.93300999128556
At time: 456.3222072124481 and batch: 1300, loss is 3.8687251806259155 and perplexity is 47.881307138784855
At time: 457.35771083831787 and batch: 1350, loss is 3.7446643829345705 and perplexity is 42.294809976545444
At time: 458.3923108577728 and batch: 1400, loss is 3.7586861419677735 and perplexity is 42.89203489736892
At time: 459.4276673793793 and batch: 1450, loss is 3.6822381830215454 and perplexity is 39.735229336356134
At time: 460.4624502658844 and batch: 1500, loss is 3.6997670936584472 and perplexity is 40.43788502333742
At time: 461.4973635673523 and batch: 1550, loss is 3.7038058042526245 and perplexity is 40.601532177294665
At time: 462.5340015888214 and batch: 1600, loss is 3.7988212060928346 and perplexity is 44.64852205455612
At time: 463.57115483283997 and batch: 1650, loss is 3.726540560722351 and perplexity is 41.53517093479146
At time: 464.6049892902374 and batch: 1700, loss is 3.7626032781600953 and perplexity is 43.06037833646227
At time: 465.6410369873047 and batch: 1750, loss is 3.7503963804244993 and perplexity is 42.537939865439334
At time: 466.67644906044006 and batch: 1800, loss is 3.695480728149414 and perplexity is 40.26492441871617
At time: 467.7112309932709 and batch: 1850, loss is 3.725404920578003 and perplexity is 41.48802870064886
At time: 468.7467715740204 and batch: 1900, loss is 3.811296401023865 and perplexity is 45.209009899063226
At time: 469.7802815437317 and batch: 1950, loss is 3.757732753753662 and perplexity is 42.85116162396306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496234556686047 and perplexity of 89.67881425189678
finished 11 epochs...
Completing Train Step...
At time: 473.090656042099 and batch: 50, loss is 3.9270701122283938 and perplexity is 50.7580442235197
At time: 474.123167514801 and batch: 100, loss is 3.9054927682876586 and perplexity is 49.67455192605858
At time: 475.15785217285156 and batch: 150, loss is 3.88040452003479 and perplexity is 48.443807599028325
At time: 476.19324493408203 and batch: 200, loss is 3.864330472946167 and perplexity is 47.67134449074179
At time: 477.2276518344879 and batch: 250, loss is 3.8572565698623658 and perplexity is 47.33531195200326
At time: 478.26184463500977 and batch: 300, loss is 3.8792599964141847 and perplexity is 48.38839423396079
At time: 479.2960681915283 and batch: 350, loss is 3.8922262048721312 and perplexity is 49.019893468487275
At time: 480.3309817314148 and batch: 400, loss is 3.84891716003418 and perplexity is 46.94220480533355
At time: 481.3632781505585 and batch: 450, loss is 3.8770407152175905 and perplexity is 48.28112585388002
At time: 482.39694929122925 and batch: 500, loss is 3.9089041471481325 and perplexity is 49.84430001530394
At time: 483.4310598373413 and batch: 550, loss is 3.8794815921783448 and perplexity is 48.39911808529367
At time: 484.4656894207001 and batch: 600, loss is 3.843071627616882 and perplexity is 46.6686030783729
At time: 485.5022211074829 and batch: 650, loss is 3.8775733041763307 and perplexity is 48.306846697135924
At time: 486.5369563102722 and batch: 700, loss is 3.902010827064514 and perplexity is 49.501888831784846
At time: 487.5709581375122 and batch: 750, loss is 3.853738784790039 and perplexity is 47.1690890378823
At time: 488.60621881484985 and batch: 800, loss is 3.8214923477172853 and perplexity is 45.672316464911304
At time: 489.6407279968262 and batch: 850, loss is 3.8245443868637086 and perplexity is 45.81192309675382
At time: 490.68259286880493 and batch: 900, loss is 3.815271830558777 and perplexity is 45.38909284862853
At time: 491.7188467979431 and batch: 950, loss is 3.91053005695343 and perplexity is 49.925408270923036
At time: 492.7818968296051 and batch: 1000, loss is 3.870945620536804 and perplexity is 47.98774282743638
At time: 493.8251111507416 and batch: 1050, loss is 3.83246798992157 and perplexity is 46.17636051268246
At time: 494.8696336746216 and batch: 1100, loss is 3.870068755149841 and perplexity is 47.945682480078894
At time: 495.91462326049805 and batch: 1150, loss is 3.8286395406723024 and perplexity is 45.99991463250675
At time: 496.95201110839844 and batch: 1200, loss is 3.877391633987427 and perplexity is 48.2980715802838
At time: 497.9975206851959 and batch: 1250, loss is 3.8599854564666747 and perplexity is 47.464661059953876
At time: 499.0398635864258 and batch: 1300, loss is 3.8597647762298584 and perplexity is 47.45418770298471
At time: 500.0776162147522 and batch: 1350, loss is 3.7361028480529783 and perplexity is 41.934247173559804
At time: 501.11927008628845 and batch: 1400, loss is 3.7509530544281007 and perplexity is 42.56162622290723
At time: 502.1624798774719 and batch: 1450, loss is 3.6755556535720824 and perplexity is 39.470582735329195
At time: 503.2110240459442 and batch: 1500, loss is 3.693416657447815 and perplexity is 40.18190048103622
At time: 504.2506744861603 and batch: 1550, loss is 3.6983260679244996 and perplexity is 40.37965495598165
At time: 505.29636216163635 and batch: 1600, loss is 3.7942911863327025 and perplexity is 44.44672079433468
At time: 506.3390471935272 and batch: 1650, loss is 3.7224385929107666 and perplexity is 41.365143961562
At time: 507.37274622917175 and batch: 1700, loss is 3.7595386838912965 and perplexity is 42.92861774729498
At time: 508.41076278686523 and batch: 1750, loss is 3.748068413734436 and perplexity is 42.439028134646364
At time: 509.4560754299164 and batch: 1800, loss is 3.6940740013122557 and perplexity is 40.208322490000334
At time: 510.4966835975647 and batch: 1850, loss is 3.7244898176193235 and perplexity is 41.450080248853595
At time: 511.53897523880005 and batch: 1900, loss is 3.8109771060943602 and perplexity is 45.19457719570165
At time: 512.5853700637817 and batch: 1950, loss is 3.7577217960357667 and perplexity is 42.85069207559509
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497135889807413 and perplexity of 89.75968117601069
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 515.9537658691406 and batch: 50, loss is 3.9198826360702514 and perplexity is 50.3945299309069
At time: 517.0213251113892 and batch: 100, loss is 3.9069662570953367 and perplexity is 49.747800774774454
At time: 518.0575129985809 and batch: 150, loss is 3.889316143989563 and perplexity is 48.87744995420942
At time: 519.1236042976379 and batch: 200, loss is 3.876033778190613 and perplexity is 48.23253426899226
At time: 520.1651539802551 and batch: 250, loss is 3.872381510734558 and perplexity is 48.05669745076105
At time: 521.2069466114044 and batch: 300, loss is 3.8915340948104857 and perplexity is 48.98597804495372
At time: 522.2433414459229 and batch: 350, loss is 3.9081638288497924 and perplexity is 49.80741302367682
At time: 523.2749891281128 and batch: 400, loss is 3.8633663988113405 and perplexity is 47.625407927230164
At time: 524.3093898296356 and batch: 450, loss is 3.8948362493515014 and perplexity is 49.14800468607411
At time: 525.3446297645569 and batch: 500, loss is 3.9244791746139525 and perplexity is 50.626703518765346
At time: 526.3803644180298 and batch: 550, loss is 3.89464476108551 and perplexity is 49.138594320895855
At time: 527.4310009479523 and batch: 600, loss is 3.8544163036346437 and perplexity is 47.20105781308923
At time: 528.4690952301025 and batch: 650, loss is 3.8867014265060424 and perplexity is 48.749816167128195
At time: 529.5029141902924 and batch: 700, loss is 3.90901939868927 and perplexity is 49.8500449787492
At time: 530.5342082977295 and batch: 750, loss is 3.861314616203308 and perplexity is 47.52779112202191
At time: 531.5724763870239 and batch: 800, loss is 3.8256382608413695 and perplexity is 45.8620629856562
At time: 532.6086568832397 and batch: 850, loss is 3.827587294578552 and perplexity is 45.95153685914711
At time: 533.6448640823364 and batch: 900, loss is 3.81184534072876 and perplexity is 45.23383373238632
At time: 534.6810402870178 and batch: 950, loss is 3.9092653369903565 and perplexity is 49.86230652185011
At time: 535.723997592926 and batch: 1000, loss is 3.869162883758545 and perplexity is 47.9022695242301
At time: 536.763555765152 and batch: 1050, loss is 3.8333601713180543 and perplexity is 46.21757658586213
At time: 537.8012294769287 and batch: 1100, loss is 3.866064043045044 and perplexity is 47.7540577820539
At time: 538.8422546386719 and batch: 1150, loss is 3.8275674057006834 and perplexity is 45.950622943731055
At time: 539.8771402835846 and batch: 1200, loss is 3.874930739402771 and perplexity is 48.179361244203335
At time: 540.9198942184448 and batch: 1250, loss is 3.851655979156494 and perplexity is 47.07094723413479
At time: 541.9549186229706 and batch: 1300, loss is 3.8484345388412478 and perplexity is 46.91955496853681
At time: 542.9912979602814 and batch: 1350, loss is 3.7207777547836303 and perplexity is 41.29650017222623
At time: 544.0259432792664 and batch: 1400, loss is 3.7348316287994385 and perplexity is 41.880973419655106
At time: 545.061526298523 and batch: 1450, loss is 3.655227336883545 and perplexity is 38.67631266819039
At time: 546.097330570221 and batch: 1500, loss is 3.668702335357666 and perplexity is 39.20100308443467
At time: 547.1324217319489 and batch: 1550, loss is 3.6757777070999147 and perplexity is 39.47934829064639
At time: 548.1671226024628 and batch: 1600, loss is 3.7676980829238893 and perplexity is 43.28032236733206
At time: 549.2120430469513 and batch: 1650, loss is 3.694200663566589 and perplexity is 40.213415689321124
At time: 550.253208398819 and batch: 1700, loss is 3.7283392572402954 and perplexity is 41.60994733198632
At time: 551.2861993312836 and batch: 1750, loss is 3.717735180854797 and perplexity is 41.1710434698781
At time: 552.3208379745483 and batch: 1800, loss is 3.6655469846725466 and perplexity is 39.077505114661164
At time: 553.3567543029785 and batch: 1850, loss is 3.694400792121887 and perplexity is 40.22146434746293
At time: 554.3920385837555 and batch: 1900, loss is 3.7809746265411377 and perplexity is 43.858766829900475
At time: 555.4350395202637 and batch: 1950, loss is 3.7335002565383912 and perplexity is 41.82525135501496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489242766624273 and perplexity of 89.05398569012294
finished 13 epochs...
Completing Train Step...
At time: 558.7785904407501 and batch: 50, loss is 3.917759461402893 and perplexity is 50.28764704725082
At time: 559.8497257232666 and batch: 100, loss is 3.8981691074371336 and perplexity is 49.3120812810084
At time: 560.9029567241669 and batch: 150, loss is 3.8747427320480345 and perplexity is 48.17030402138185
At time: 561.9553606510162 and batch: 200, loss is 3.8586384773254396 and perplexity is 47.400770191054235
At time: 563.0119006633759 and batch: 250, loss is 3.854557123184204 and perplexity is 47.20770511281313
At time: 564.0654714107513 and batch: 300, loss is 3.8722226572036744 and perplexity is 48.04906408099831
At time: 565.1083879470825 and batch: 350, loss is 3.887957100868225 and perplexity is 48.81106850990045
At time: 566.155515909195 and batch: 400, loss is 3.8441858291625977 and perplexity is 46.72063028707497
At time: 567.200660943985 and batch: 450, loss is 3.875465474128723 and perplexity is 48.20513131119559
At time: 568.2473335266113 and batch: 500, loss is 3.9064576864242553 and perplexity is 49.72250693474738
At time: 569.293865442276 and batch: 550, loss is 3.8780130672454836 and perplexity is 48.328094936053496
At time: 570.3442418575287 and batch: 600, loss is 3.839313349723816 and perplexity is 46.49353867552099
At time: 571.4346106052399 and batch: 650, loss is 3.871811900138855 and perplexity is 48.02933164136602
At time: 572.4764547348022 and batch: 700, loss is 3.895331425666809 and perplexity is 49.172347640469106
At time: 573.5231566429138 and batch: 750, loss is 3.848511896133423 and perplexity is 46.9231846786497
At time: 574.573032617569 and batch: 800, loss is 3.8135879850387573 and perplexity is 45.312728938534676
At time: 575.6216983795166 and batch: 850, loss is 3.815747022628784 and perplexity is 45.41066651102571
At time: 576.6715834140778 and batch: 900, loss is 3.8016273593902588 and perplexity is 44.77398860880494
At time: 577.7183547019958 and batch: 950, loss is 3.8995011711120604 and perplexity is 49.377811882171606
At time: 578.7628710269928 and batch: 1000, loss is 3.8595404767990114 and perplexity is 47.44354494931804
At time: 579.8061201572418 and batch: 1050, loss is 3.8239337253570556 and perplexity is 45.78395605883873
At time: 580.8523278236389 and batch: 1100, loss is 3.8578247022628784 and perplexity is 47.36221231717252
At time: 581.9043600559235 and batch: 1150, loss is 3.8199841165542603 and perplexity is 45.603483974632944
At time: 582.9539284706116 and batch: 1200, loss is 3.8675654554367065 and perplexity is 47.82581016764154
At time: 583.9968862533569 and batch: 1250, loss is 3.8458512353897096 and perplexity is 46.79850394332663
At time: 585.0410046577454 and batch: 1300, loss is 3.8433237791061403 and perplexity is 46.68037211986902
At time: 586.089015007019 and batch: 1350, loss is 3.7170662260055543 and perplexity is 41.14351111067986
At time: 587.1384766101837 and batch: 1400, loss is 3.7322367000579835 and perplexity is 41.77243616213722
At time: 588.1752648353577 and batch: 1450, loss is 3.6543443822860717 and perplexity is 38.64217831186774
At time: 589.2132918834686 and batch: 1500, loss is 3.668983359336853 and perplexity is 39.21202105439394
At time: 590.2509849071503 and batch: 1550, loss is 3.6775390911102295 and perplexity is 39.54894786125435
At time: 591.2892706394196 and batch: 1600, loss is 3.7709294080734255 and perplexity is 43.42040135997781
At time: 592.3288259506226 and batch: 1650, loss is 3.6979153299331666 and perplexity is 40.36307290328694
At time: 593.3721189498901 and batch: 1700, loss is 3.733038921356201 and perplexity is 41.80596034521386
At time: 594.4126150608063 and batch: 1750, loss is 3.723480324745178 and perplexity is 41.4082578014926
At time: 595.4496803283691 and batch: 1800, loss is 3.6715281438827514 and perplexity is 39.31193427447656
At time: 596.4877328872681 and batch: 1850, loss is 3.7005573749542235 and perplexity is 40.469854958469114
At time: 597.5254049301147 and batch: 1900, loss is 3.7870962524414065 and perplexity is 44.12807726071661
At time: 598.561222076416 and batch: 1950, loss is 3.739538059234619 and perplexity is 42.07854787813725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48868777252907 and perplexity of 89.00457496650878
finished 14 epochs...
Completing Train Step...
At time: 601.8652527332306 and batch: 50, loss is 3.9142963695526123 and perplexity is 50.11379750879975
At time: 602.900545835495 and batch: 100, loss is 3.892812418937683 and perplexity is 49.0486380439444
At time: 603.9377753734589 and batch: 150, loss is 3.8681235837936403 and perplexity is 47.85251055891908
At time: 604.9716391563416 and batch: 200, loss is 3.851343746185303 and perplexity is 47.05625242664417
At time: 606.0039727687836 and batch: 250, loss is 3.8467269420623778 and perplexity is 46.83950365474102
At time: 607.0392365455627 and batch: 300, loss is 3.863896064758301 and perplexity is 47.650640165758176
At time: 608.077240228653 and batch: 350, loss is 3.879793224334717 and perplexity is 48.41420315720376
At time: 609.1113486289978 and batch: 400, loss is 3.835981149673462 and perplexity is 46.33887073897193
At time: 610.1436364650726 and batch: 450, loss is 3.8671715688705444 and perplexity is 47.8069759330202
At time: 611.1783399581909 and batch: 500, loss is 3.8983650064468383 and perplexity is 49.321742415170235
At time: 612.2197179794312 and batch: 550, loss is 3.8703239965438843 and perplexity is 47.95792176483306
At time: 613.258043050766 and batch: 600, loss is 3.8322018909454347 and perplexity is 46.164074665126606
At time: 614.289553642273 and batch: 650, loss is 3.864896545410156 and perplexity is 47.6983375654767
At time: 615.3286802768707 and batch: 700, loss is 3.888663477897644 and perplexity is 48.84555970793807
At time: 616.3676228523254 and batch: 750, loss is 3.8422621059417725 and perplexity is 46.63083912006756
At time: 617.4050793647766 and batch: 800, loss is 3.8075624322891235 and perplexity is 45.04051564148594
At time: 618.4437556266785 and batch: 850, loss is 3.8099059772491457 and perplexity is 45.14619389741918
At time: 619.4817357063293 and batch: 900, loss is 3.7964129877090453 and perplexity is 44.54112802897146
At time: 620.5213892459869 and batch: 950, loss is 3.8945216226577757 and perplexity is 49.13254384418084
At time: 621.562438249588 and batch: 1000, loss is 3.854681205749512 and perplexity is 47.21356312939717
At time: 622.6008965969086 and batch: 1050, loss is 3.8193548822402956 and perplexity is 45.574797723812935
At time: 623.6864795684814 and batch: 1100, loss is 3.8537369632720946 and perplexity is 47.16900311861844
At time: 624.7186250686646 and batch: 1150, loss is 3.8162946319580078 and perplexity is 45.43554062568043
At time: 625.7604582309723 and batch: 1200, loss is 3.8640232038497926 and perplexity is 47.65669880999494
At time: 626.7992799282074 and batch: 1250, loss is 3.8430248212814333 and perplexity is 46.66641874320304
At time: 627.8311975002289 and batch: 1300, loss is 3.840931324958801 and perplexity is 46.56882495893188
At time: 628.862930059433 and batch: 1350, loss is 3.715238103866577 and perplexity is 41.068364456702604
At time: 629.8974118232727 and batch: 1400, loss is 3.730782027244568 and perplexity is 41.71171511024124
At time: 630.9311385154724 and batch: 1450, loss is 3.653588643074036 and perplexity is 38.612985934780426
At time: 631.9725475311279 and batch: 1500, loss is 3.668673119544983 and perplexity is 39.19985781200167
At time: 633.011162519455 and batch: 1550, loss is 3.677652983665466 and perplexity is 39.553452448497794
At time: 634.0470175743103 and batch: 1600, loss is 3.7717711400985716 and perplexity is 43.45696508861906
At time: 635.0846290588379 and batch: 1650, loss is 3.6989953088760377 and perplexity is 40.40668771939436
At time: 636.1173667907715 and batch: 1700, loss is 3.7345569562911987 and perplexity is 41.8694714473485
At time: 637.151734828949 and batch: 1750, loss is 3.725388250350952 and perplexity is 41.48733709155519
At time: 638.1906735897064 and batch: 1800, loss is 3.6736075639724732 and perplexity is 39.3937653514791
At time: 639.2273283004761 and batch: 1850, loss is 3.7026922130584716 and perplexity is 40.55634383393332
At time: 640.2619891166687 and batch: 1900, loss is 3.7892902088165283 and perplexity is 44.22499861888332
At time: 641.2952079772949 and batch: 1950, loss is 3.741588373184204 and perplexity is 42.16491061693991
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488735465116279 and perplexity of 89.00881992618815
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 644.6048765182495 and batch: 50, loss is 3.912539587020874 and perplexity is 50.025835752198866
At time: 645.6707293987274 and batch: 100, loss is 3.893239669799805 and perplexity is 49.06959859422232
At time: 646.7091555595398 and batch: 150, loss is 3.8702966737747193 and perplexity is 47.95661143950799
At time: 647.7513470649719 and batch: 200, loss is 3.853998131752014 and perplexity is 47.18132378427698
At time: 648.7861573696136 and batch: 250, loss is 3.8504549169540407 and perplexity is 47.01444603609702
At time: 649.8593099117279 and batch: 300, loss is 3.8657476472854615 and perplexity is 47.73895099065719
At time: 650.8988461494446 and batch: 350, loss is 3.882356200218201 and perplexity is 48.538446740956786
At time: 651.935156583786 and batch: 400, loss is 3.839162287712097 and perplexity is 46.48651579849506
At time: 652.9717507362366 and batch: 450, loss is 3.870676136016846 and perplexity is 47.97481261592082
At time: 654.0077700614929 and batch: 500, loss is 3.9018683004379273 and perplexity is 49.4948339973228
At time: 655.0427429676056 and batch: 550, loss is 3.874216928482056 and perplexity is 48.14498256139349
At time: 656.0841073989868 and batch: 600, loss is 3.8353201580047607 and perplexity is 46.308251252204094
At time: 657.1176238059998 and batch: 650, loss is 3.8673876190185545 and perplexity is 47.81730575308584
At time: 658.1603438854218 and batch: 700, loss is 3.8902115058898925 and perplexity is 48.92123255839658
At time: 659.2082180976868 and batch: 750, loss is 3.844195508956909 and perplexity is 46.72108253535508
At time: 660.2574203014374 and batch: 800, loss is 3.8092619514465333 and perplexity is 45.11712794427604
At time: 661.2945187091827 and batch: 850, loss is 3.811597990989685 and perplexity is 45.22264653904698
At time: 662.332168340683 and batch: 900, loss is 3.7950514698028566 and perplexity is 44.4805257505035
At time: 663.3679099082947 and batch: 950, loss is 3.8933214235305784 and perplexity is 49.073610380961995
At time: 664.4020030498505 and batch: 1000, loss is 3.852280087471008 and perplexity is 47.10033377291339
At time: 665.4370017051697 and batch: 1050, loss is 3.8174474573135377 and perplexity is 45.48795007262121
At time: 666.4731967449188 and batch: 1100, loss is 3.8496786308288575 and perplexity is 46.97796353621735
At time: 667.5090892314911 and batch: 1150, loss is 3.8133665990829466 and perplexity is 45.302698447074164
At time: 668.5429675579071 and batch: 1200, loss is 3.861827244758606 and perplexity is 47.55216147085597
At time: 669.5789761543274 and batch: 1250, loss is 3.8401096630096436 and perplexity is 46.53057684310871
At time: 670.6154351234436 and batch: 1300, loss is 3.8377320098876955 and perplexity is 46.42007469176209
At time: 671.6501395702362 and batch: 1350, loss is 3.7094829225540162 and perplexity is 40.83268740563379
At time: 672.6857368946075 and batch: 1400, loss is 3.724580750465393 and perplexity is 41.45384959399647
At time: 673.7228181362152 and batch: 1450, loss is 3.645237436294556 and perplexity is 38.291863650489276
At time: 674.7630655765533 and batch: 1500, loss is 3.65807785987854 and perplexity is 38.78671766805031
At time: 675.8005363941193 and batch: 1550, loss is 3.6672397518157958 and perplexity is 39.14371025048972
At time: 676.8397870063782 and batch: 1600, loss is 3.7598953533172605 and perplexity is 42.94393180360983
At time: 677.876026391983 and batch: 1650, loss is 3.6872805547714234 and perplexity is 39.93609512864217
At time: 678.9093964099884 and batch: 1700, loss is 3.7221379709243774 and perplexity is 41.35271055878775
At time: 679.9454374313354 and batch: 1750, loss is 3.7117476224899293 and perplexity is 40.92526598196384
At time: 680.9805662631989 and batch: 1800, loss is 3.6610558080673217 and perplexity is 38.90239465823339
At time: 682.0171706676483 and batch: 1850, loss is 3.6914268779754638 and perplexity is 40.10202685210574
At time: 683.0525534152985 and batch: 1900, loss is 3.7782512950897216 and perplexity is 43.7394873632538
At time: 684.0865569114685 and batch: 1950, loss is 3.7321182537078856 and perplexity is 41.767488662551536
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487946550236192 and perplexity of 88.93862723535909
finished 16 epochs...
Completing Train Step...
At time: 687.3924291133881 and batch: 50, loss is 3.9121045112609862 and perplexity is 50.00407545772654
At time: 688.46120262146 and batch: 100, loss is 3.891135334968567 and perplexity is 48.96644829819042
At time: 689.501955986023 and batch: 150, loss is 3.866797933578491 and perplexity is 47.789116896196255
At time: 690.5433216094971 and batch: 200, loss is 3.8495631647109985 and perplexity is 46.972539486295915
At time: 691.5826241970062 and batch: 250, loss is 3.8455990314483643 and perplexity is 46.78670266441014
At time: 692.628814458847 and batch: 300, loss is 3.8613091039657594 and perplexity is 47.527529138269145
At time: 693.6714487075806 and batch: 350, loss is 3.8779140424728396 and perplexity is 48.323309494382684
At time: 694.7173900604248 and batch: 400, loss is 3.8344626998901368 and perplexity is 46.268560885239275
At time: 695.7670543193817 and batch: 450, loss is 3.8665504693984984 and perplexity is 47.77729226471768
At time: 696.8171279430389 and batch: 500, loss is 3.8979145860671998 and perplexity is 49.29953189963708
At time: 697.8576047420502 and batch: 550, loss is 3.8700756931304934 and perplexity is 47.946015127450245
At time: 698.9082245826721 and batch: 600, loss is 3.831661581993103 and perplexity is 46.13913853952152
At time: 699.946973323822 and batch: 650, loss is 3.8640677070617677 and perplexity is 47.658819733357724
At time: 700.9888994693756 and batch: 700, loss is 3.8869421529769896 and perplexity is 48.76155295095403
At time: 702.0691587924957 and batch: 750, loss is 3.840945062637329 and perplexity is 46.569464710872936
At time: 703.112062215805 and batch: 800, loss is 3.806065196990967 and perplexity is 44.973129850401136
At time: 704.1600866317749 and batch: 850, loss is 3.80835036277771 and perplexity is 45.07601842200634
At time: 705.2051892280579 and batch: 900, loss is 3.7923939561843873 and perplexity is 44.362475077676756
At time: 706.2441689968109 and batch: 950, loss is 3.8909701538085937 and perplexity is 48.958360631444236
At time: 707.284627199173 and batch: 1000, loss is 3.8501547050476073 and perplexity is 47.00033385805054
At time: 708.3238890171051 and batch: 1050, loss is 3.8152776288986208 and perplexity is 45.38935603077708
At time: 709.3640170097351 and batch: 1100, loss is 3.847994065284729 and perplexity is 46.8988926962159
At time: 710.4065482616425 and batch: 1150, loss is 3.8119001150131226 and perplexity is 45.23631145111502
At time: 711.4458978176117 and batch: 1200, loss is 3.8605115747451784 and perplexity is 47.4896396559923
At time: 712.4861669540405 and batch: 1250, loss is 3.8389515924453734 and perplexity is 46.476722341403594
At time: 713.5317361354828 and batch: 1300, loss is 3.836613359451294 and perplexity is 46.36817588867181
At time: 714.5788509845734 and batch: 1350, loss is 3.7089690494537355 and perplexity is 40.81170997629381
At time: 715.6300127506256 and batch: 1400, loss is 3.7241819381713865 and perplexity is 41.4373205853495
At time: 716.6754477024078 and batch: 1450, loss is 3.6454328155517577 and perplexity is 38.299345817272474
At time: 717.7140748500824 and batch: 1500, loss is 3.658702321052551 and perplexity is 38.810946031350106
At time: 718.7549529075623 and batch: 1550, loss is 3.668301935195923 and perplexity is 39.18531013839788
At time: 719.7921583652496 and batch: 1600, loss is 3.7613510942459105 and perplexity is 43.00649256785788
At time: 720.8323469161987 and batch: 1650, loss is 3.6888818883895875 and perplexity is 40.00009737114456
At time: 721.8861634731293 and batch: 1700, loss is 3.724107794761658 and perplexity is 41.434248395004026
At time: 722.9256892204285 and batch: 1750, loss is 3.71389711856842 and perplexity is 41.01332929266696
At time: 723.964834690094 and batch: 1800, loss is 3.663252992630005 and perplexity is 38.98796437102903
At time: 725.0065996646881 and batch: 1850, loss is 3.693676543235779 and perplexity is 40.19234454297749
At time: 726.0475640296936 and batch: 1900, loss is 3.7803187370300293 and perplexity is 43.83000975652891
At time: 727.0876557826996 and batch: 1950, loss is 3.7340132570266724 and perplexity is 41.84671323388907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487769122456395 and perplexity of 88.92284845202923
finished 17 epochs...
Completing Train Step...
At time: 730.4075546264648 and batch: 50, loss is 3.911213479042053 and perplexity is 49.95954005959958
At time: 731.4440002441406 and batch: 100, loss is 3.889401469230652 and perplexity is 48.881620612339255
At time: 732.4801969528198 and batch: 150, loss is 3.864511961936951 and perplexity is 47.67999710009565
At time: 733.5149455070496 and batch: 200, loss is 3.8467757940292358 and perplexity is 46.8417919125137
At time: 734.5498669147491 and batch: 250, loss is 3.842753930091858 and perplexity is 46.65377893360029
At time: 735.5943372249603 and batch: 300, loss is 3.858405466079712 and perplexity is 47.38972656523804
At time: 736.6308844089508 and batch: 350, loss is 3.8749314069747927 and perplexity is 48.17939340740766
At time: 737.6647274494171 and batch: 400, loss is 3.831530714035034 and perplexity is 46.13310079975575
At time: 738.6993992328644 and batch: 450, loss is 3.8637163972854616 and perplexity is 47.642079664705236
At time: 739.7324316501617 and batch: 500, loss is 3.8951723861694334 and perplexity is 49.164527916854524
At time: 740.765017747879 and batch: 550, loss is 3.8673322439193725 and perplexity is 47.81465793834932
At time: 741.7977547645569 and batch: 600, loss is 3.8291585445404053 and perplexity is 46.02379496258923
At time: 742.831880569458 and batch: 650, loss is 3.8617279863357545 and perplexity is 47.54744175254496
At time: 743.8653824329376 and batch: 700, loss is 3.8846728229522705 and perplexity is 48.651022357422505
At time: 744.8989090919495 and batch: 750, loss is 3.8388203954696656 and perplexity is 46.47062513596779
At time: 745.9341025352478 and batch: 800, loss is 3.803958101272583 and perplexity is 44.87846692799439
At time: 746.9680023193359 and batch: 850, loss is 3.8063014936447144 and perplexity is 44.98375810615452
At time: 747.999757528305 and batch: 900, loss is 3.7907120323181154 and perplexity is 44.28792348470318
At time: 749.0319905281067 and batch: 950, loss is 3.889401936531067 and perplexity is 48.88164345474618
At time: 750.0633025169373 and batch: 1000, loss is 3.8486853790283204 and perplexity is 46.93132575471387
At time: 751.0961303710938 and batch: 1050, loss is 3.813872103691101 and perplexity is 45.32560495908689
At time: 752.1278977394104 and batch: 1100, loss is 3.846863784790039 and perplexity is 46.84591373876013
At time: 753.1619365215302 and batch: 1150, loss is 3.810888032913208 and perplexity is 45.190551750222276
At time: 754.2342472076416 and batch: 1200, loss is 3.85956467628479 and perplexity is 47.444693072601275
At time: 755.272643327713 and batch: 1250, loss is 3.8381685256958007 and perplexity is 46.440342211403
At time: 756.3038530349731 and batch: 1300, loss is 3.835912380218506 and perplexity is 46.335684149659194
At time: 757.3339052200317 and batch: 1350, loss is 3.7085811948776244 and perplexity is 40.79588403710044
At time: 758.3657746315002 and batch: 1400, loss is 3.723940668106079 and perplexity is 41.42732420626772
At time: 759.4002163410187 and batch: 1450, loss is 3.6455747747421263 and perplexity is 38.304783147326695
At time: 760.4308593273163 and batch: 1500, loss is 3.6591020917892454 and perplexity is 38.82646461356771
At time: 761.4596290588379 and batch: 1550, loss is 3.668983483314514 and perplexity is 39.212025915808894
At time: 762.488273859024 and batch: 1600, loss is 3.762272057533264 and perplexity is 43.04611821271202
At time: 763.5212507247925 and batch: 1650, loss is 3.6898852682113645 and perplexity is 40.040252803922435
At time: 764.5534145832062 and batch: 1700, loss is 3.7253262424468994 and perplexity is 41.48476462849476
At time: 765.584888458252 and batch: 1750, loss is 3.7152668809890748 and perplexity is 41.069546303062346
At time: 766.6268656253815 and batch: 1800, loss is 3.6646266269683836 and perplexity is 39.041556377155736
At time: 767.6567649841309 and batch: 1850, loss is 3.6950544357299804 and perplexity is 40.24776344472385
At time: 768.6895844936371 and batch: 1900, loss is 3.781558656692505 and perplexity is 43.884389153507385
At time: 769.7204115390778 and batch: 1950, loss is 3.7351406717300417 and perplexity is 41.893918438597495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487710074491279 and perplexity of 88.91759789379468
finished 18 epochs...
Completing Train Step...
At time: 772.9667925834656 and batch: 50, loss is 3.910197277069092 and perplexity is 49.908796863457525
At time: 774.0286779403687 and batch: 100, loss is 3.8878457069396974 and perplexity is 48.80563155605095
At time: 775.0623953342438 and batch: 150, loss is 3.8626275396347047 and perplexity is 47.59023245400293
At time: 776.0936274528503 and batch: 200, loss is 3.8446046209335325 and perplexity is 46.7402006002291
At time: 777.125786781311 and batch: 250, loss is 3.840536775588989 and perplexity is 46.55045488258078
At time: 778.1617937088013 and batch: 300, loss is 3.8561112213134767 and perplexity is 47.28112755708023
At time: 779.1941986083984 and batch: 350, loss is 3.872665276527405 and perplexity is 48.07033623263313
At time: 780.2739806175232 and batch: 400, loss is 3.8292085695266724 and perplexity is 46.02609735988841
At time: 781.3153870105743 and batch: 450, loss is 3.8614539909362793 and perplexity is 47.53441575686088
At time: 782.3554637432098 and batch: 500, loss is 3.8929780101776124 and perplexity is 49.05676074124015
At time: 783.3991272449493 and batch: 550, loss is 3.865183334350586 and perplexity is 47.71201888289886
At time: 784.4417645931244 and batch: 600, loss is 3.8271660137176515 and perplexity is 45.93218243325024
At time: 785.4752452373505 and batch: 650, loss is 3.8598450517654417 and perplexity is 47.45799726622356
At time: 786.5131902694702 and batch: 700, loss is 3.88286901473999 and perplexity is 48.56334434469139
At time: 787.5481877326965 and batch: 750, loss is 3.8371685934066773 and perplexity is 46.39392822299802
At time: 788.5813353061676 and batch: 800, loss is 3.8022768783569334 and perplexity is 44.80307961017588
At time: 789.6125900745392 and batch: 850, loss is 3.8046906566619874 and perplexity is 44.91135493548352
At time: 790.6467921733856 and batch: 900, loss is 3.7893608617782593 and perplexity is 44.22812335640297
At time: 791.6807577610016 and batch: 950, loss is 3.888134937286377 and perplexity is 48.81974966738051
At time: 792.7154138088226 and batch: 1000, loss is 3.8474988746643066 and perplexity is 46.875674553622204
At time: 793.7502219676971 and batch: 1050, loss is 3.812750105857849 and perplexity is 45.2747782475941
At time: 794.7859823703766 and batch: 1100, loss is 3.845928807258606 and perplexity is 46.80213433154525
At time: 795.8298907279968 and batch: 1150, loss is 3.81006365776062 and perplexity is 45.153313133631706
At time: 796.8683125972748 and batch: 1200, loss is 3.858771276473999 and perplexity is 47.40706539096602
At time: 797.9070074558258 and batch: 1250, loss is 3.8375243759155273 and perplexity is 46.410437307824274
At time: 798.9471468925476 and batch: 1300, loss is 3.8353499460220335 and perplexity is 46.30963070373773
At time: 799.9895467758179 and batch: 1350, loss is 3.7082043743133544 and perplexity is 40.78051420507395
At time: 801.0305244922638 and batch: 1400, loss is 3.7236964559555052 and perplexity is 41.41720838558422
At time: 802.0717539787292 and batch: 1450, loss is 3.645611081123352 and perplexity is 38.30617388063251
At time: 803.1089913845062 and batch: 1500, loss is 3.6593130302429198 and perplexity is 38.83465547182806
At time: 804.1532995700836 and batch: 1550, loss is 3.669420642852783 and perplexity is 39.22917157437387
At time: 805.1946942806244 and batch: 1600, loss is 3.7628633546829224 and perplexity is 43.07157878635554
At time: 806.2402513027191 and batch: 1650, loss is 3.69053662776947 and perplexity is 40.06634190106422
At time: 807.2861762046814 and batch: 1700, loss is 3.7261225032806395 and perplexity is 41.51781047657662
At time: 808.324022769928 and batch: 1750, loss is 3.7161886405944826 and perplexity is 41.10742000439935
At time: 809.3570210933685 and batch: 1800, loss is 3.665551018714905 and perplexity is 39.07766275529002
At time: 810.3917498588562 and batch: 1850, loss is 3.6959785985946656 and perplexity is 40.284976125726494
At time: 811.4257326126099 and batch: 1900, loss is 3.782392725944519 and perplexity is 43.92100704194832
At time: 812.4631590843201 and batch: 1950, loss is 3.73588782787323 and perplexity is 41.925231433512685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487710074491279 and perplexity of 88.91759789379468
finished 19 epochs...
Completing Train Step...
At time: 815.7541542053223 and batch: 50, loss is 3.909153504371643 and perplexity is 49.85673060132738
At time: 816.8174605369568 and batch: 100, loss is 3.8864138460159303 and perplexity is 48.73579868677552
At time: 817.8557031154633 and batch: 150, loss is 3.8609713745117187 and perplexity is 47.51148040201938
At time: 818.8935730457306 and batch: 200, loss is 3.842723431587219 and perplexity is 46.652356084804566
At time: 819.9290103912354 and batch: 250, loss is 3.838647513389587 and perplexity is 46.462591892053716
At time: 820.9652080535889 and batch: 300, loss is 3.85416558265686 and perplexity is 47.18922500115099
At time: 822.0024514198303 and batch: 350, loss is 3.8707761859893797 and perplexity is 47.97961273472723
At time: 823.0371387004852 and batch: 400, loss is 3.827255744934082 and perplexity is 45.93630416877469
At time: 824.0760164260864 and batch: 450, loss is 3.8595601463317872 and perplexity is 47.44447815085821
At time: 825.1090455055237 and batch: 500, loss is 3.8911084175109862 and perplexity is 48.96513026363463
At time: 826.1566801071167 and batch: 550, loss is 3.8633756017684937 and perplexity is 47.62584622383553
At time: 827.2083578109741 and batch: 600, loss is 3.825477738380432 and perplexity is 45.854701685284915
At time: 828.2539126873016 and batch: 650, loss is 3.8582337284088135 and perplexity is 47.38158866278542
At time: 829.2967677116394 and batch: 700, loss is 3.881327648162842 and perplexity is 48.4885480878776
At time: 830.3399231433868 and batch: 750, loss is 3.8357417488098147 and perplexity is 46.32777850109522
At time: 831.3817150592804 and batch: 800, loss is 3.8009518814086913 and perplexity is 44.7437549775784
At time: 832.4652049541473 and batch: 850, loss is 3.80333176612854 and perplexity is 44.85036676792416
At time: 833.5035774707794 and batch: 900, loss is 3.788187336921692 and perplexity is 44.17625099698952
At time: 834.5438463687897 and batch: 950, loss is 3.887034921646118 and perplexity is 48.766076705154
At time: 835.5888013839722 and batch: 1000, loss is 3.8464546823501586 and perplexity is 46.82675288079528
At time: 836.6394999027252 and batch: 1050, loss is 3.811767854690552 and perplexity is 45.23032887760785
At time: 837.6847500801086 and batch: 1100, loss is 3.8450797414779663 and perplexity is 46.76241310617633
At time: 838.7244901657104 and batch: 1150, loss is 3.8093131017684936 and perplexity is 45.11943575891854
At time: 839.7704739570618 and batch: 1200, loss is 3.8580526447296144 and perplexity is 47.37300940718909
At time: 840.8086593151093 and batch: 1250, loss is 3.8369407415390016 and perplexity is 46.38335848401671
At time: 841.8480479717255 and batch: 1300, loss is 3.834848084449768 and perplexity is 46.286395510574685
At time: 842.8908796310425 and batch: 1350, loss is 3.707833323478699 and perplexity is 40.765385368197826
At time: 843.9323329925537 and batch: 1400, loss is 3.7234400367736815 and perplexity is 41.40658958038742
At time: 844.9744777679443 and batch: 1450, loss is 3.645556845664978 and perplexity is 38.30409638407103
At time: 846.0142531394958 and batch: 1500, loss is 3.6593863439559935 and perplexity is 38.83750268898539
At time: 847.0548543930054 and batch: 1550, loss is 3.669628939628601 and perplexity is 39.237343735418676
At time: 848.0997924804688 and batch: 1600, loss is 3.7632204198837282 and perplexity is 43.08696089432822
At time: 849.14235663414 and batch: 1650, loss is 3.690945339202881 and perplexity is 40.082720819991856
At time: 850.1793193817139 and batch: 1700, loss is 3.726640601158142 and perplexity is 41.539326339243196
At time: 851.2190659046173 and batch: 1750, loss is 3.716813383102417 and perplexity is 41.133109580917285
At time: 852.2517330646515 and batch: 1800, loss is 3.666183204650879 and perplexity is 39.1023749146114
At time: 853.2946214675903 and batch: 1850, loss is 3.6966062498092653 and perplexity is 40.31026897663589
At time: 854.3342890739441 and batch: 1900, loss is 3.782965512275696 and perplexity is 43.94617160070312
At time: 855.3769402503967 and batch: 1950, loss is 3.736397352218628 and perplexity is 41.94659880274964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487744140625 and perplexity of 88.92062702416978
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f31229a0b38>
ELAPSED
4413.361446380615


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.77128768299961}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.13481025420142356, 'wordvec_source': 'None', 'rnn_dropout': 0.7333439966881319, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.4361717208564}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.049255346069296047, 'wordvec_source': 'None', 'rnn_dropout': 0.9817036371865334, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -87.71067320599664}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.9986437985159311, 'wordvec_source': 'None', 'rnn_dropout': 0.5007125478907719, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -90.71879193959988}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.1789226511740396, 'wordvec_source': 'None', 'rnn_dropout': 0.45869390902326646, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.91759789379468}]
SETTINGS FOR THIS RUN
{'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.0, 'wordvec_source': 'None', 'rnn_dropout': 1.0, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5874097347259521 and batch: 50, loss is 7.172589378356934 and perplexity is 1303.2147537007625
At time: 2.6554646492004395 and batch: 100, loss is 6.313297348022461 and perplexity is 551.8616319084861
At time: 3.689948081970215 and batch: 150, loss is 5.979082126617431 and perplexity is 395.07757049363056
At time: 4.724942684173584 and batch: 200, loss is 5.818515062332153 and perplexity is 336.4720424692066
At time: 5.755970239639282 and batch: 250, loss is 5.724957466125488 and perplexity is 306.420231726499
At time: 6.788470506668091 and batch: 300, loss is 5.642429647445678 and perplexity is 282.1474050869965
At time: 7.819386959075928 and batch: 350, loss is 5.577707548141479 and perplexity is 264.4646378790728
At time: 8.852502346038818 and batch: 400, loss is 5.50983943939209 and perplexity is 247.11144751798773
At time: 9.88277554512024 and batch: 450, loss is 5.431593656539917 and perplexity is 228.51312683503258
At time: 10.916159629821777 and batch: 500, loss is 5.398575248718262 and perplexity is 221.09119174046782
At time: 11.95341944694519 and batch: 550, loss is 5.332981939315796 and perplexity is 207.0544784000119
At time: 12.997509002685547 and batch: 600, loss is 5.34543818473816 and perplexity is 209.64972978677312
At time: 14.039994955062866 and batch: 650, loss is 5.4086452293396 and perplexity is 223.3288233012746
At time: 15.073918104171753 and batch: 700, loss is 5.338353748321533 and perplexity is 208.1697282846124
At time: 16.111178636550903 and batch: 750, loss is 5.280797462463379 and perplexity is 196.5265354132869
At time: 17.150176763534546 and batch: 800, loss is 5.261077394485474 and perplexity is 192.6889815488807
At time: 18.188677549362183 and batch: 850, loss is 5.253549222946167 and perplexity is 191.24383233276194
At time: 19.226677894592285 and batch: 900, loss is 5.274852743148804 and perplexity is 195.3617060446022
At time: 20.263417959213257 and batch: 950, loss is 5.307220306396484 and perplexity is 201.7885377781926
At time: 21.30743432044983 and batch: 1000, loss is 5.276357250213623 and perplexity is 195.655850327133
At time: 22.34417963027954 and batch: 1050, loss is 5.174223299026489 and perplexity is 176.65934948775853
At time: 23.38745927810669 and batch: 1100, loss is 5.254887676239013 and perplexity is 191.49997464890853
At time: 24.428388118743896 and batch: 1150, loss is 5.156468133926392 and perplexity is 173.55041506590382
At time: 25.466309785842896 and batch: 1200, loss is 5.230584440231323 and perplexity is 186.9020046571274
At time: 26.50223135948181 and batch: 1250, loss is 5.167412948608399 and perplexity is 175.46032493610676
At time: 27.538029432296753 and batch: 1300, loss is 5.1903596782684325 and perplexity is 179.5331154803658
At time: 28.581302642822266 and batch: 1350, loss is 5.131852760314941 and perplexity is 169.33055652727492
At time: 29.620980739593506 and batch: 1400, loss is 5.13974100112915 and perplexity is 170.67155885543937
At time: 30.668070077896118 and batch: 1450, loss is 5.076281147003174 and perplexity is 160.17727121400512
At time: 31.71572756767273 and batch: 1500, loss is 5.0506285572052 and perplexity is 156.12056435808174
At time: 32.764113664627075 and batch: 1550, loss is 5.042414360046386 and perplexity is 154.84341183432025
At time: 33.808393478393555 and batch: 1600, loss is 5.094357872009278 and perplexity is 163.09908050714657
At time: 34.855229139328 and batch: 1650, loss is 5.070434579849243 and perplexity is 159.2435163314584
At time: 35.90214490890503 and batch: 1700, loss is 5.087658424377441 and perplexity is 162.0100587537657
At time: 36.94788217544556 and batch: 1750, loss is 5.102734804153442 and perplexity is 164.47108902530698
At time: 37.997079372406006 and batch: 1800, loss is 5.0617751121521 and perplexity is 157.8705055966079
At time: 39.03851890563965 and batch: 1850, loss is 5.0545728969573975 and perplexity is 156.73757295203518
At time: 40.08117938041687 and batch: 1900, loss is 5.109547929763794 and perplexity is 165.59547716353686
At time: 41.11842703819275 and batch: 1950, loss is 5.031465682983399 and perplexity is 153.15732835759016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.844415992914244 and perplexity of 127.02907444740528
finished 1 epochs...
Completing Train Step...
At time: 44.45690560340881 and batch: 50, loss is 5.011664896011353 and perplexity is 150.15451982056587
At time: 45.52176809310913 and batch: 100, loss is 4.962659339904786 and perplexity is 142.97350593384087
At time: 46.56624174118042 and batch: 150, loss is 4.901160621643067 and perplexity is 134.4457297917091
At time: 47.60375380516052 and batch: 200, loss is 4.868626070022583 and perplexity is 130.14198802806516
At time: 48.64373016357422 and batch: 250, loss is 4.870101737976074 and perplexity is 130.33417615725773
At time: 49.691802740097046 and batch: 300, loss is 4.899254322052002 and perplexity is 134.18968008325393
At time: 50.73152017593384 and batch: 350, loss is 4.893720102310181 and perplexity is 133.4490960741014
At time: 51.769097566604614 and batch: 400, loss is 4.854062976837159 and perplexity is 128.26045187571083
At time: 52.805630922317505 and batch: 450, loss is 4.839812479019165 and perplexity is 126.44563829668542
At time: 53.86876916885376 and batch: 500, loss is 4.831966075897217 and perplexity is 125.4573770638813
At time: 54.9067280292511 and batch: 550, loss is 4.791727771759033 and perplexity is 120.50940163556054
At time: 55.94070649147034 and batch: 600, loss is 4.781428699493408 and perplexity is 119.27463598413782
At time: 56.970641136169434 and batch: 650, loss is 4.8446865653991695 and perplexity is 127.0634496700213
At time: 58.00393629074097 and batch: 700, loss is 4.8405547523498536 and perplexity is 126.53953036425283
At time: 59.03866267204285 and batch: 750, loss is 4.800622987747192 and perplexity is 121.58614060483357
At time: 60.07673692703247 and batch: 800, loss is 4.772092714309692 and perplexity is 118.16627163682433
At time: 61.11472487449646 and batch: 850, loss is 4.773156862258912 and perplexity is 118.29208496257718
At time: 62.1526620388031 and batch: 900, loss is 4.786763467788696 and perplexity is 119.91263881614209
At time: 63.19156575202942 and batch: 950, loss is 4.850544738769531 and perplexity is 127.80999394511745
At time: 64.23033833503723 and batch: 1000, loss is 4.820478610992431 and perplexity is 124.02443603546189
At time: 65.2682592868805 and batch: 1050, loss is 4.747755565643311 and perplexity is 115.32515409730179
At time: 66.30613970756531 and batch: 1100, loss is 4.823298063278198 and perplexity is 124.37461043316561
At time: 67.3437876701355 and batch: 1150, loss is 4.742672615051269 and perplexity is 114.74044930866914
At time: 68.38261651992798 and batch: 1200, loss is 4.8105772113800045 and perplexity is 122.80248005294607
At time: 69.42069840431213 and batch: 1250, loss is 4.779464778900146 and perplexity is 119.04061993995523
At time: 70.45762872695923 and batch: 1300, loss is 4.793571310043335 and perplexity is 120.7317702406332
At time: 71.49848055839539 and batch: 1350, loss is 4.707836046218872 and perplexity is 110.81210798866971
At time: 72.53735017776489 and batch: 1400, loss is 4.7189545249938964 and perplexity is 112.05104484276836
At time: 73.57703590393066 and batch: 1450, loss is 4.656655883789062 and perplexity is 105.28341283412044
At time: 74.62036061286926 and batch: 1500, loss is 4.642401256561279 and perplexity is 103.79328288644973
At time: 75.65737223625183 and batch: 1550, loss is 4.647368965148925 and perplexity is 104.31018050454786
At time: 76.69402599334717 and batch: 1600, loss is 4.732466526031494 and perplexity is 113.57535371694387
At time: 77.73062586784363 and batch: 1650, loss is 4.689433250427246 and perplexity is 108.79150479306212
At time: 78.7696704864502 and batch: 1700, loss is 4.714656896591187 and perplexity is 111.57052437868128
At time: 79.8088972568512 and batch: 1750, loss is 4.720450859069825 and perplexity is 112.21883614402353
At time: 80.852379322052 and batch: 1800, loss is 4.678805913925171 and perplexity is 107.64146262941149
At time: 81.89263105392456 and batch: 1850, loss is 4.698311614990234 and perplexity is 109.76169591625124
At time: 82.9276704788208 and batch: 1900, loss is 4.778320198059082 and perplexity is 118.90444627281516
At time: 83.96926641464233 and batch: 1950, loss is 4.707542505264282 and perplexity is 110.77958487037776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.700949593477471 and perplexity of 110.05162715685445
finished 2 epochs...
Completing Train Step...
At time: 87.33226656913757 and batch: 50, loss is 4.682327365875244 and perplexity is 108.02118506264856
At time: 88.37103867530823 and batch: 100, loss is 4.640039587020874 and perplexity is 103.54844667666517
At time: 89.41376256942749 and batch: 150, loss is 4.593222675323486 and perplexity is 98.81235774506179
At time: 90.45570683479309 and batch: 200, loss is 4.573352680206299 and perplexity is 96.86833450593436
At time: 91.50386095046997 and batch: 250, loss is 4.573052787780762 and perplexity is 96.83928878165568
At time: 92.54600477218628 and batch: 300, loss is 4.604118604660034 and perplexity is 99.89489713898276
At time: 93.59042406082153 and batch: 350, loss is 4.612105150222778 and perplexity is 100.69590667837122
At time: 94.63327503204346 and batch: 400, loss is 4.570811347961426 and perplexity is 96.62247242488677
At time: 95.67490816116333 and batch: 450, loss is 4.579134092330933 and perplexity is 97.42999229267184
At time: 96.7072217464447 and batch: 500, loss is 4.577667407989502 and perplexity is 97.28719799127119
At time: 97.74805855751038 and batch: 550, loss is 4.5392960166931156 and perplexity is 93.624866570963
At time: 98.78245806694031 and batch: 600, loss is 4.52703013420105 and perplexity is 92.48348926935876
At time: 99.81843852996826 and batch: 650, loss is 4.582739305496216 and perplexity is 97.78188212135797
At time: 100.85379910469055 and batch: 700, loss is 4.597504501342773 and perplexity is 99.23636217827983
At time: 101.88769698143005 and batch: 750, loss is 4.5636102485656735 and perplexity is 95.92918361383079
At time: 102.926593542099 and batch: 800, loss is 4.52823917388916 and perplexity is 92.59537310074751
At time: 103.97149205207825 and batch: 850, loss is 4.530579833984375 and perplexity is 92.81236124424275
At time: 105.00515055656433 and batch: 900, loss is 4.53481008529663 and perplexity is 93.2058124692353
At time: 106.1233241558075 and batch: 950, loss is 4.609524917602539 and perplexity is 100.43642272367903
At time: 107.17984962463379 and batch: 1000, loss is 4.57958724975586 and perplexity is 97.474153422306
At time: 108.21610140800476 and batch: 1050, loss is 4.521125373840332 and perplexity is 91.9390055328976
At time: 109.25021028518677 and batch: 1100, loss is 4.585974788665771 and perplexity is 98.09876611522577
At time: 110.28343677520752 and batch: 1150, loss is 4.5191357135772705 and perplexity is 91.75626000800494
At time: 111.31864929199219 and batch: 1200, loss is 4.580294713973999 and perplexity is 97.54313729697999
At time: 112.35441327095032 and batch: 1250, loss is 4.562198762893677 and perplexity is 95.79387646015216
At time: 113.39830732345581 and batch: 1300, loss is 4.570631074905395 and perplexity is 96.60505556644382
At time: 114.43381237983704 and batch: 1350, loss is 4.473644742965698 and perplexity is 87.67569675068533
At time: 115.4686222076416 and batch: 1400, loss is 4.489714450836182 and perplexity is 89.09600095737063
At time: 116.50571250915527 and batch: 1450, loss is 4.4194558811187745 and perplexity is 83.05108339925553
At time: 117.54167675971985 and batch: 1500, loss is 4.419009828567505 and perplexity is 83.01404651243261
At time: 118.57422661781311 and batch: 1550, loss is 4.422467823028565 and perplexity is 83.30160552765774
At time: 119.60799527168274 and batch: 1600, loss is 4.520275726318359 and perplexity is 91.86092296070325
At time: 120.64212131500244 and batch: 1650, loss is 4.472610664367676 and perplexity is 87.58508004957925
At time: 121.67779588699341 and batch: 1700, loss is 4.498510112762451 and perplexity is 89.88311578423034
At time: 122.711008310318 and batch: 1750, loss is 4.505471391677856 and perplexity is 90.51100012643332
At time: 123.74592161178589 and batch: 1800, loss is 4.454160890579224 and perplexity is 85.98397060604297
At time: 124.77945327758789 and batch: 1850, loss is 4.487853412628174 and perplexity is 88.93034409010015
At time: 125.8114755153656 and batch: 1900, loss is 4.5750901412963865 and perplexity is 97.03678576437723
At time: 126.84474754333496 and batch: 1950, loss is 4.507980794906616 and perplexity is 90.73841393952989
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.642624682049418 and perplexity of 103.81647554216292
finished 3 epochs...
Completing Train Step...
At time: 130.25476813316345 and batch: 50, loss is 4.480102405548096 and perplexity is 88.24370885833763
At time: 131.3009810447693 and batch: 100, loss is 4.439749488830566 and perplexity is 84.75370726389009
At time: 132.3720202445984 and batch: 150, loss is 4.392825450897217 and perplexity is 80.86858671120523
At time: 133.4203155040741 and batch: 200, loss is 4.3787569808959965 and perplexity is 79.73885485752062
At time: 134.4606420993805 and batch: 250, loss is 4.3774850463867185 and perplexity is 79.63749673041178
At time: 135.4992172718048 and batch: 300, loss is 4.409263982772827 and perplexity is 82.20893403988904
At time: 136.53882431983948 and batch: 350, loss is 4.4209208679199214 and perplexity is 83.1728413053428
At time: 137.57880234718323 and batch: 400, loss is 4.379449186325073 and perplexity is 79.79406963354053
At time: 138.61643862724304 and batch: 450, loss is 4.394919271469116 and perplexity is 81.0380884128307
At time: 139.65415906906128 and batch: 500, loss is 4.400743494033813 and perplexity is 81.5114494177929
At time: 140.69379663467407 and batch: 550, loss is 4.364864921569824 and perplexity is 78.63877682179182
At time: 141.734445810318 and batch: 600, loss is 4.353037519454956 and perplexity is 77.7141630543759
At time: 142.774183511734 and batch: 650, loss is 4.406608057022095 and perplexity is 81.9908829070183
At time: 143.81398963928223 and batch: 700, loss is 4.426760702133179 and perplexity is 83.65997792372904
At time: 144.85436296463013 and batch: 750, loss is 4.391527414321899 and perplexity is 80.76368442609046
At time: 145.89262890815735 and batch: 800, loss is 4.357041053771972 and perplexity is 78.02591801752097
At time: 146.93162083625793 and batch: 850, loss is 4.357444696426391 and perplexity is 78.05741896331803
At time: 147.9701864719391 and batch: 900, loss is 4.358377847671509 and perplexity is 78.13029233666585
At time: 149.0100212097168 and batch: 950, loss is 4.440435590744019 and perplexity is 84.81187689748263
At time: 150.05123162269592 and batch: 1000, loss is 4.407228183746338 and perplexity is 82.04174341300283
At time: 151.0915653705597 and batch: 1050, loss is 4.3546576404571535 and perplexity is 77.84017144896961
At time: 152.13248300552368 and batch: 1100, loss is 4.417628517150879 and perplexity is 82.8994574220739
At time: 153.17120885849 and batch: 1150, loss is 4.355446538925171 and perplexity is 77.90160366968223
At time: 154.21092581748962 and batch: 1200, loss is 4.416332635879517 and perplexity is 82.79209914460904
At time: 155.2502806186676 and batch: 1250, loss is 4.405559778213501 and perplexity is 81.9049786356492
At time: 156.29012179374695 and batch: 1300, loss is 4.4076161956787105 and perplexity is 82.07358276502451
At time: 157.33183193206787 and batch: 1350, loss is 4.30891619682312 and perplexity is 74.35985380614378
At time: 158.37233209609985 and batch: 1400, loss is 4.324837150573731 and perplexity is 75.55320806125354
At time: 159.41159510612488 and batch: 1450, loss is 4.25128830909729 and perplexity is 70.19578799056542
At time: 160.45061540603638 and batch: 1500, loss is 4.255876049995423 and perplexity is 70.5185679272259
At time: 161.48893332481384 and batch: 1550, loss is 4.264300594329834 and perplexity is 71.11516422660262
At time: 162.52874398231506 and batch: 1600, loss is 4.367784385681152 and perplexity is 78.8686953646442
At time: 163.5700490474701 and batch: 1650, loss is 4.314572257995605 and perplexity is 74.7816293577901
At time: 164.61021423339844 and batch: 1700, loss is 4.344750204086304 and perplexity is 77.07278260835545
At time: 165.651752948761 and batch: 1750, loss is 4.3454270362854 and perplexity is 77.12496560687349
At time: 166.69110083580017 and batch: 1800, loss is 4.293740997314453 and perplexity is 73.23994708471551
At time: 167.73082900047302 and batch: 1850, loss is 4.335145654678345 and perplexity is 76.3360767867717
At time: 168.77151226997375 and batch: 1900, loss is 4.420399627685547 and perplexity is 83.12949957075645
At time: 169.81261229515076 and batch: 1950, loss is 4.35272647857666 and perplexity is 77.68999453173751
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.620793116369913 and perplexity of 101.57456063789385
finished 4 epochs...
Completing Train Step...
At time: 173.1069769859314 and batch: 50, loss is 4.330992932319641 and perplexity is 76.01973155549807
At time: 174.1645495891571 and batch: 100, loss is 4.29010196685791 and perplexity is 72.97390904049635
At time: 175.2010440826416 and batch: 150, loss is 4.246078300476074 and perplexity is 69.83101838147985
At time: 176.2353036403656 and batch: 200, loss is 4.240479259490967 and perplexity is 69.44112418290304
At time: 177.26634287834167 and batch: 250, loss is 4.229457468986511 and perplexity is 68.67996105551403
At time: 178.30057382583618 and batch: 300, loss is 4.2615789031982425 and perplexity is 70.92187387244495
At time: 179.3347990512848 and batch: 350, loss is 4.271115307807922 and perplexity is 71.6014487576956
At time: 180.36719584465027 and batch: 400, loss is 4.233461771011353 and perplexity is 68.95552772049908
At time: 181.400084733963 and batch: 450, loss is 4.256394438743591 and perplexity is 70.55513343613167
At time: 182.4339725971222 and batch: 500, loss is 4.2659478187561035 and perplexity is 71.23240339529683
At time: 183.46773672103882 and batch: 550, loss is 4.234152235984802 and perplexity is 69.00315553789348
At time: 184.502934217453 and batch: 600, loss is 4.219157128334046 and perplexity is 67.97616495299172
At time: 185.5639054775238 and batch: 650, loss is 4.271128244400025 and perplexity is 71.60237504242359
At time: 186.59766364097595 and batch: 700, loss is 4.2931427478790285 and perplexity is 73.19614443148427
At time: 187.63020658493042 and batch: 750, loss is 4.260243473052978 and perplexity is 70.82722587607688
At time: 188.66218948364258 and batch: 800, loss is 4.221342597007752 and perplexity is 68.1248871867518
At time: 189.69592356681824 and batch: 850, loss is 4.2246361827850345 and perplexity is 68.34963225167975
At time: 190.72946500778198 and batch: 900, loss is 4.222396559715271 and perplexity is 68.19672612843326
At time: 191.76416063308716 and batch: 950, loss is 4.304874906539917 and perplexity is 74.05995045790915
At time: 192.79916429519653 and batch: 1000, loss is 4.275294046401978 and perplexity is 71.90127851379786
At time: 193.83362364768982 and batch: 1050, loss is 4.2274190711975095 and perplexity is 68.54010656271959
At time: 194.86525750160217 and batch: 1100, loss is 4.2866400575637815 and perplexity is 72.7217167718127
At time: 195.89866638183594 and batch: 1150, loss is 4.22784420967102 and perplexity is 68.56925179393849
At time: 196.93161988258362 and batch: 1200, loss is 4.288425283432007 and perplexity is 72.85165741396294
At time: 197.9648892879486 and batch: 1250, loss is 4.278136348724365 and perplexity is 72.10593439386268
At time: 198.99977254867554 and batch: 1300, loss is 4.281239919662475 and perplexity is 72.33006790352889
At time: 200.03444647789001 and batch: 1350, loss is 4.174977512359619 and perplexity is 65.03837708493724
At time: 201.0693323612213 and batch: 1400, loss is 4.195209736824036 and perplexity is 66.36764985775574
At time: 202.10277771949768 and batch: 1450, loss is 4.122799391746521 and perplexity is 61.731812131780174
At time: 203.1351592540741 and batch: 1500, loss is 4.129333310127258 and perplexity is 62.136483358439904
At time: 204.16889214515686 and batch: 1550, loss is 4.14055016040802 and perplexity is 62.837382581286526
At time: 205.20228481292725 and batch: 1600, loss is 4.245528564453125 and perplexity is 69.79264030502843
At time: 206.23722100257874 and batch: 1650, loss is 4.190416526794434 and perplexity is 66.05029694998139
At time: 207.27063393592834 and batch: 1700, loss is 4.222018055915832 and perplexity is 68.17091829297433
At time: 208.3033652305603 and batch: 1750, loss is 4.224476518630982 and perplexity is 68.33872013662648
At time: 209.3366355895996 and batch: 1800, loss is 4.168567652702332 and perplexity is 64.62282345849366
At time: 210.3700089454651 and batch: 1850, loss is 4.21171549320221 and perplexity is 67.47218866533561
At time: 211.40569686889648 and batch: 1900, loss is 4.299682636260986 and perplexity is 73.67640776862225
At time: 212.4403989315033 and batch: 1950, loss is 4.22820816040039 and perplexity is 68.59421216503837
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.620003917605378 and perplexity of 101.49442974389056
finished 5 epochs...
Completing Train Step...
At time: 215.73196029663086 and batch: 50, loss is 4.21112169265747 and perplexity is 67.4321355359133
At time: 216.76286220550537 and batch: 100, loss is 4.168574485778809 and perplexity is 64.62326503269716
At time: 217.7971317768097 and batch: 150, loss is 4.130837149620056 and perplexity is 62.229996953152686
At time: 218.83093929290771 and batch: 200, loss is 4.123246245384216 and perplexity is 61.759403380758634
At time: 219.86340379714966 and batch: 250, loss is 4.110169262886047 and perplexity is 60.95703446004183
At time: 220.89463901519775 and batch: 300, loss is 4.141465878486633 and perplexity is 62.89495026238934
At time: 221.92665243148804 and batch: 350, loss is 4.148902902603149 and perplexity is 63.36444518286887
At time: 222.95572328567505 and batch: 400, loss is 4.108067936897278 and perplexity is 60.829078345170736
At time: 223.98592972755432 and batch: 450, loss is 4.140678353309632 and perplexity is 62.84543840402789
At time: 225.01684260368347 and batch: 500, loss is 4.163428325653076 and perplexity is 64.29155760480995
At time: 226.0491759777069 and batch: 550, loss is 4.12227418422699 and perplexity is 61.69939863250615
At time: 227.0810866355896 and batch: 600, loss is 4.111855344772339 and perplexity is 61.05989970693234
At time: 228.1128580570221 and batch: 650, loss is 4.155540075302124 and perplexity is 63.78640470863007
At time: 229.14414834976196 and batch: 700, loss is 4.181226749420166 and perplexity is 65.44608994165594
At time: 230.1732006072998 and batch: 750, loss is 4.152480173110962 and perplexity is 63.59152286084886
At time: 231.2081298828125 and batch: 800, loss is 4.111234893798828 and perplexity is 61.02202678307791
At time: 232.23842859268188 and batch: 850, loss is 4.1133898878097535 and perplexity is 61.15367068028881
At time: 233.26968264579773 and batch: 900, loss is 4.110399522781372 and perplexity is 60.97107203649935
At time: 234.3009946346283 and batch: 950, loss is 4.197032766342163 and perplexity is 66.48875039388203
At time: 235.33263111114502 and batch: 1000, loss is 4.166102433204651 and perplexity is 64.46371021922018
At time: 236.36589932441711 and batch: 1050, loss is 4.118390340805053 and perplexity is 61.46023257139288
At time: 237.4314730167389 and batch: 1100, loss is 4.177733373641968 and perplexity is 65.21786103304919
At time: 238.46460723876953 and batch: 1150, loss is 4.125607008934021 and perplexity is 61.90537496351946
At time: 239.49609112739563 and batch: 1200, loss is 4.182180490493774 and perplexity is 65.50853834080831
At time: 240.52760338783264 and batch: 1250, loss is 4.173626570701599 and perplexity is 64.95057335417582
At time: 241.56057596206665 and batch: 1300, loss is 4.173399777412414 and perplexity is 64.93584467025683
At time: 242.5952661037445 and batch: 1350, loss is 4.070028309822082 and perplexity is 58.55862035255037
At time: 243.6280858516693 and batch: 1400, loss is 4.090958986282349 and perplexity is 59.7972089196175
At time: 244.66339778900146 and batch: 1450, loss is 4.019080491065979 and perplexity is 55.6499117026873
At time: 245.69711995124817 and batch: 1500, loss is 4.027780017852783 and perplexity is 56.13615156194793
At time: 246.73488450050354 and batch: 1550, loss is 4.036099677085876 and perplexity is 56.60513339299844
At time: 247.77200984954834 and batch: 1600, loss is 4.144288477897644 and perplexity is 63.072728292005564
At time: 248.80650448799133 and batch: 1650, loss is 4.089312195777893 and perplexity is 59.698816481877834
At time: 249.84370589256287 and batch: 1700, loss is 4.12197630405426 and perplexity is 61.68102234208633
At time: 250.87725448608398 and batch: 1750, loss is 4.11839861869812 and perplexity is 61.46074133473172
At time: 251.9105463027954 and batch: 1800, loss is 4.062769899368286 and perplexity is 58.13511669146299
At time: 252.9450376033783 and batch: 1850, loss is 4.105682282447815 and perplexity is 60.68413414589079
At time: 253.9800043106079 and batch: 1900, loss is 4.189824953079223 and perplexity is 66.01123488560839
At time: 255.01753783226013 and batch: 1950, loss is 4.125310201644897 and perplexity is 61.88700372348818
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.616639886900436 and perplexity of 101.15357301355274
finished 6 epochs...
Completing Train Step...
At time: 258.323454618454 and batch: 50, loss is 4.107730841636657 and perplexity is 60.8085766068662
At time: 259.385799407959 and batch: 100, loss is 4.067554078102112 and perplexity is 58.413911851601284
At time: 260.4198172092438 and batch: 150, loss is 4.033605003356934 and perplexity is 56.464098045530974
At time: 261.4541494846344 and batch: 200, loss is 4.027051501274109 and perplexity is 56.09527033800486
At time: 262.48714303970337 and batch: 250, loss is 4.012386555671692 and perplexity is 55.278638813773554
At time: 263.5497064590454 and batch: 300, loss is 4.041352672576904 and perplexity is 56.90326225271276
At time: 264.58559942245483 and batch: 350, loss is 4.047805280685425 and perplexity is 57.27162387261781
At time: 265.61923599243164 and batch: 400, loss is 4.007129464149475 and perplexity is 54.98879648167043
At time: 266.65384316444397 and batch: 450, loss is 4.043543200492859 and perplexity is 57.0280470595903
At time: 267.6889100074768 and batch: 500, loss is 4.066449089050293 and perplexity is 58.34940076711639
At time: 268.72482919692993 and batch: 550, loss is 4.02995069026947 and perplexity is 56.25813710515155
At time: 269.76140308380127 and batch: 600, loss is 4.02328962802887 and perplexity is 55.88464346552784
At time: 270.79714131355286 and batch: 650, loss is 4.058970899581909 and perplexity is 57.91468037944094
At time: 271.83185720443726 and batch: 700, loss is 4.086954913139343 and perplexity is 59.55825523462604
At time: 272.86641335487366 and batch: 750, loss is 4.062141284942627 and perplexity is 58.09858360228985
At time: 273.910062789917 and batch: 800, loss is 4.018196105957031 and perplexity is 55.60071750597709
At time: 274.944566488266 and batch: 850, loss is 4.018428931236267 and perplexity is 55.613664265664106
At time: 275.9801869392395 and batch: 900, loss is 4.01226923942566 and perplexity is 55.27215411177002
At time: 277.0153090953827 and batch: 950, loss is 4.101424918174744 and perplexity is 60.426328856147315
At time: 278.05132937431335 and batch: 1000, loss is 4.068080439567566 and perplexity is 58.44466677724017
At time: 279.0864191055298 and batch: 1050, loss is 4.028982071876526 and perplexity is 56.20367082157921
At time: 280.1207957267761 and batch: 1100, loss is 4.083774576187134 and perplexity is 59.36914079791035
At time: 281.15484976768494 and batch: 1150, loss is 4.035417518615723 and perplexity is 56.566532889127416
At time: 282.1907744407654 and batch: 1200, loss is 4.086992273330688 and perplexity is 59.560480384003526
At time: 283.2273519039154 and batch: 1250, loss is 4.084414706230164 and perplexity is 59.40715693490154
At time: 284.26100516319275 and batch: 1300, loss is 4.0800785779953 and perplexity is 59.15011756493581
At time: 285.29632449150085 and batch: 1350, loss is 3.9808600902557374 and perplexity is 53.56308350757597
At time: 286.3316328525543 and batch: 1400, loss is 4.002554054260254 and perplexity is 54.737774899681
At time: 287.36495327949524 and batch: 1450, loss is 3.928812651634216 and perplexity is 50.84656922249111
At time: 288.3986921310425 and batch: 1500, loss is 3.938669605255127 and perplexity is 51.35023974757642
At time: 289.4331693649292 and batch: 1550, loss is 3.9512966108322143 and perplexity is 52.00275046977955
At time: 290.4689049720764 and batch: 1600, loss is 4.055864725112915 and perplexity is 57.73506637849282
At time: 291.50636649131775 and batch: 1650, loss is 4.001553435325622 and perplexity is 54.68303063931617
At time: 292.54288387298584 and batch: 1700, loss is 4.032050752639771 and perplexity is 56.376406845358055
At time: 293.57775950431824 and batch: 1750, loss is 4.031193990707397 and perplexity is 56.3281263714783
At time: 294.61142921447754 and batch: 1800, loss is 3.9755560636520384 and perplexity is 53.27973559438859
At time: 295.6457803249359 and batch: 1850, loss is 4.015835199356079 and perplexity is 55.469604238989106
At time: 296.6818687915802 and batch: 1900, loss is 4.100519261360168 and perplexity is 60.37162811342803
At time: 297.7168972492218 and batch: 1950, loss is 4.032492141723633 and perplexity is 56.401296268482724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6241943359375 and perplexity of 101.92062620998665
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 300.96535873413086 and batch: 50, loss is 4.046196284294129 and perplexity is 57.17954813111536
At time: 302.0279338359833 and batch: 100, loss is 4.028464641571045 and perplexity is 56.17459686153951
At time: 303.06540751457214 and batch: 150, loss is 4.00231698513031 and perplexity is 54.724799801068905
At time: 304.1023452281952 and batch: 200, loss is 3.990775604248047 and perplexity is 54.09683082803105
At time: 305.1399395465851 and batch: 250, loss is 3.9773277711868285 and perplexity is 53.374215373947536
At time: 306.1783022880554 and batch: 300, loss is 4.001788444519043 and perplexity is 54.695883164412166
At time: 307.2167875766754 and batch: 350, loss is 4.0093475389480595 and perplexity is 55.110901113893235
At time: 308.2528986930847 and batch: 400, loss is 3.956872706413269 and perplexity is 52.29353273830118
At time: 309.29041385650635 and batch: 450, loss is 3.9805958461761475 and perplexity is 53.548931649729184
At time: 310.3276164531708 and batch: 500, loss is 4.003437991142273 and perplexity is 54.78618102858399
At time: 311.3669333457947 and batch: 550, loss is 3.963627142906189 and perplexity is 52.64794165301115
At time: 312.4052333831787 and batch: 600, loss is 3.9461921072006225 and perplexity is 51.73797858059557
At time: 313.44370102882385 and batch: 650, loss is 3.9750031089782714 and perplexity is 53.25028245944937
At time: 314.4806089401245 and batch: 700, loss is 3.993579740524292 and perplexity is 54.24873859929202
At time: 315.5623128414154 and batch: 750, loss is 3.9510998821258543 and perplexity is 51.992521042196486
At time: 316.60056471824646 and batch: 800, loss is 3.908045701980591 and perplexity is 49.80152977740488
At time: 317.6390459537506 and batch: 850, loss is 3.903193960189819 and perplexity is 49.560490816365544
At time: 318.6788697242737 and batch: 900, loss is 3.8782565116882326 and perplexity is 48.339861574397574
At time: 319.7188231945038 and batch: 950, loss is 3.9660191202163695 and perplexity is 52.774025069092
At time: 320.7570536136627 and batch: 1000, loss is 3.9269423389434817 and perplexity is 50.75155911579413
At time: 321.7935154438019 and batch: 1050, loss is 3.8865515565872193 and perplexity is 48.74251058359386
At time: 322.82911705970764 and batch: 1100, loss is 3.9211297988891602 and perplexity is 50.45741932341755
At time: 323.8663640022278 and batch: 1150, loss is 3.8724229240417483 and perplexity is 48.058687678745805
At time: 324.90446519851685 and batch: 1200, loss is 3.9188346242904664 and perplexity is 50.34174353511628
At time: 325.94214034080505 and batch: 1250, loss is 3.905484175682068 and perplexity is 49.67412509405978
At time: 326.99137806892395 and batch: 1300, loss is 3.8923566150665283 and perplexity is 49.02628657917816
At time: 328.03837275505066 and batch: 1350, loss is 3.7922530698776247 and perplexity is 44.356225452657846
At time: 329.08588457107544 and batch: 1400, loss is 3.799033942222595 and perplexity is 44.6580214187307
At time: 330.14720463752747 and batch: 1450, loss is 3.7140887689590456 and perplexity is 41.02119026650204
At time: 331.20538687705994 and batch: 1500, loss is 3.7125842809677123 and perplexity is 40.95952078048878
At time: 332.25585556030273 and batch: 1550, loss is 3.723659725189209 and perplexity is 41.41568712772103
At time: 333.3100645542145 and batch: 1600, loss is 3.8163257789611817 and perplexity is 45.43695582864807
At time: 334.3651638031006 and batch: 1650, loss is 3.750085611343384 and perplexity is 42.524722442844315
At time: 335.42243909835815 and batch: 1700, loss is 3.770039396286011 and perplexity is 43.381773882957894
At time: 336.48249101638794 and batch: 1750, loss is 3.758904638290405 and perplexity is 42.901407673185425
At time: 337.54202222824097 and batch: 1800, loss is 3.700082235336304 and perplexity is 40.450630694513265
At time: 338.59919261932373 and batch: 1850, loss is 3.7276327228546142 and perplexity is 41.58055885661662
At time: 339.65608620643616 and batch: 1900, loss is 3.7965495491027834 and perplexity is 44.54721104283673
At time: 340.71914625167847 and batch: 1950, loss is 3.7310079193115233 and perplexity is 41.72113852008043
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.537851732830669 and perplexity of 93.48974328872724
finished 8 epochs...
Completing Train Step...
At time: 343.9959809780121 and batch: 50, loss is 3.9437518548965453 and perplexity is 51.61187877939644
At time: 345.02753949165344 and batch: 100, loss is 3.9136664342880247 and perplexity is 50.082239001458476
At time: 346.0606689453125 and batch: 150, loss is 3.8820378971099854 and perplexity is 48.52299926111204
At time: 347.09391617774963 and batch: 200, loss is 3.871291732788086 and perplexity is 48.00435484778637
At time: 348.1254584789276 and batch: 250, loss is 3.8555911922454835 and perplexity is 47.256546388398135
At time: 349.15934801101685 and batch: 300, loss is 3.880582208633423 and perplexity is 48.452416276122285
At time: 350.19158148765564 and batch: 350, loss is 3.8927259922027586 and perplexity is 49.044399113486875
At time: 351.2321767807007 and batch: 400, loss is 3.842012434005737 and perplexity is 46.61919816145631
At time: 352.2676899433136 and batch: 450, loss is 3.8746214437484743 and perplexity is 48.16446188141657
At time: 353.3044316768646 and batch: 500, loss is 3.9007686376571655 and perplexity is 49.44043628558718
At time: 354.34003043174744 and batch: 550, loss is 3.8634246015548706 and perplexity is 47.62817993730178
At time: 355.3738613128662 and batch: 600, loss is 3.8495069265365602 and perplexity is 46.969897910705875
At time: 356.41087317466736 and batch: 650, loss is 3.883796224594116 and perplexity is 48.60839363796395
At time: 357.4437403678894 and batch: 700, loss is 3.9029113960266115 and perplexity is 49.54648877608042
At time: 358.4764790534973 and batch: 750, loss is 3.8648834085464476 and perplexity is 47.69771096303279
At time: 359.51221895217896 and batch: 800, loss is 3.822641487121582 and perplexity is 45.724830490635945
At time: 360.5473256111145 and batch: 850, loss is 3.8222277307510377 and perplexity is 45.70591546410459
At time: 361.5821647644043 and batch: 900, loss is 3.8003358030319214 and perplexity is 44.71619780720123
At time: 362.6176314353943 and batch: 950, loss is 3.8898839712142945 and perplexity is 48.90521178218381
At time: 363.6517255306244 and batch: 1000, loss is 3.854398822784424 and perplexity is 47.20023270567919
At time: 364.6851010322571 and batch: 1050, loss is 3.81706036567688 and perplexity is 45.47034547509545
At time: 365.72049927711487 and batch: 1100, loss is 3.8534568881988527 and perplexity is 47.15579410645912
At time: 366.7554771900177 and batch: 1150, loss is 3.8103043937683108 and perplexity is 45.16418447047811
At time: 367.81454205513 and batch: 1200, loss is 3.8574601888656614 and perplexity is 47.34495130238777
At time: 368.8495125770569 and batch: 1250, loss is 3.8515264272689818 and perplexity is 47.064849499068686
At time: 369.8902304172516 and batch: 1300, loss is 3.8392643404006956 and perplexity is 46.49126011449686
At time: 370.9296247959137 and batch: 1350, loss is 3.7409596681594848 and perplexity is 42.13840965728436
At time: 371.9673182964325 and batch: 1400, loss is 3.753966698646545 and perplexity is 42.69008528944043
At time: 373.00789499282837 and batch: 1450, loss is 3.6708921718597414 and perplexity is 39.28694093248313
At time: 374.04730343818665 and batch: 1500, loss is 3.6756136226654053 and perplexity is 39.47287087554335
At time: 375.08757972717285 and batch: 1550, loss is 3.68734983921051 and perplexity is 39.938862174447976
At time: 376.13035893440247 and batch: 1600, loss is 3.7858861970901487 and perplexity is 44.07471213857396
At time: 377.1708686351776 and batch: 1650, loss is 3.7222285223007203 and perplexity is 41.35645527318632
At time: 378.2082085609436 and batch: 1700, loss is 3.748070731163025 and perplexity is 42.439126484177415
At time: 379.2444884777069 and batch: 1750, loss is 3.740244779586792 and perplexity is 42.10829615493079
At time: 380.2815012931824 and batch: 1800, loss is 3.687642731666565 and perplexity is 39.95056167914698
At time: 381.31514835357666 and batch: 1850, loss is 3.7174294900894167 and perplexity is 41.158459785544316
At time: 382.3474690914154 and batch: 1900, loss is 3.789112253189087 and perplexity is 44.21712923172713
At time: 383.38006615638733 and batch: 1950, loss is 3.7284919881820677 and perplexity is 41.616302943766364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.539161575672239 and perplexity of 93.6122803943899
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 386.6513469219208 and batch: 50, loss is 3.908670587539673 and perplexity is 49.832659759508125
At time: 387.71537590026855 and batch: 100, loss is 3.901311197280884 and perplexity is 49.467267948324974
At time: 388.75061678886414 and batch: 150, loss is 3.881685833930969 and perplexity is 48.50591910655995
At time: 389.78475761413574 and batch: 200, loss is 3.879811658859253 and perplexity is 48.41509565824615
At time: 390.8216800689697 and batch: 250, loss is 3.865402727127075 and perplexity is 47.7224877035433
At time: 391.8576877117157 and batch: 300, loss is 3.8846621179580687 and perplexity is 48.65050155129788
At time: 392.89164757728577 and batch: 350, loss is 3.9055740451812744 and perplexity is 49.678589483408715
At time: 393.951140165329 and batch: 400, loss is 3.855788254737854 and perplexity is 47.265859798842044
At time: 394.98483204841614 and batch: 450, loss is 3.8848996782302856 and perplexity is 48.66206035059129
At time: 396.02002024650574 and batch: 500, loss is 3.909102191925049 and perplexity is 49.854172396135496
At time: 397.0552136898041 and batch: 550, loss is 3.8671146631240845 and perplexity is 47.804255518773076
At time: 398.0899746417999 and batch: 600, loss is 3.8456667137145994 and perplexity is 46.78986940164091
At time: 399.124614238739 and batch: 650, loss is 3.8739870262145994 and perplexity is 48.133915192991275
At time: 400.16047382354736 and batch: 700, loss is 3.8953510999679564 and perplexity is 49.17331508156154
At time: 401.19635128974915 and batch: 750, loss is 3.852623691558838 and perplexity is 47.116520420875865
At time: 402.2333354949951 and batch: 800, loss is 3.8073826217651368 and perplexity is 45.032417610845194
At time: 403.2701487541199 and batch: 850, loss is 3.8062037563323976 and perplexity is 44.97936172938784
At time: 404.3068563938141 and batch: 900, loss is 3.778891334533691 and perplexity is 43.767491321288176
At time: 405.343492269516 and batch: 950, loss is 3.8703654623031616 and perplexity is 47.959910417702616
At time: 406.37896728515625 and batch: 1000, loss is 3.8282772874832154 and perplexity is 45.98325403459295
At time: 407.4148225784302 and batch: 1050, loss is 3.7876054191589357 and perplexity is 44.15055153005576
At time: 408.45130944252014 and batch: 1100, loss is 3.814153480529785 and perplexity is 45.33836032897039
At time: 409.4861240386963 and batch: 1150, loss is 3.7758904123306274 and perplexity is 43.63634536263923
At time: 410.5226991176605 and batch: 1200, loss is 3.8184839153289794 and perplexity is 45.53512086412971
At time: 411.5607433319092 and batch: 1250, loss is 3.8073934745788574 and perplexity is 45.03290634193696
At time: 412.5982964038849 and batch: 1300, loss is 3.7896702241897584 and perplexity is 44.24180799194737
At time: 413.6326823234558 and batch: 1350, loss is 3.6911861753463744 and perplexity is 40.092375350428135
At time: 414.669180393219 and batch: 1400, loss is 3.7092506647109986 and perplexity is 40.82320479498032
At time: 415.7059442996979 and batch: 1450, loss is 3.623508448600769 and perplexity is 37.46879482662696
At time: 416.7408130168915 and batch: 1500, loss is 3.6192296504974366 and perplexity is 37.30881592118315
At time: 417.775271654129 and batch: 1550, loss is 3.632349228858948 and perplexity is 37.801516802054316
At time: 418.8103542327881 and batch: 1600, loss is 3.720028281211853 and perplexity is 41.26556113218491
At time: 419.8452274799347 and batch: 1650, loss is 3.6495533895492556 and perplexity is 38.457486697610214
At time: 420.8782341480255 and batch: 1700, loss is 3.6702224826812744 and perplexity is 39.26063970109356
At time: 421.9122841358185 and batch: 1750, loss is 3.6630698680877685 and perplexity is 38.98082537158381
At time: 422.9468491077423 and batch: 1800, loss is 3.6064839935302735 and perplexity is 36.836308159151564
At time: 423.98073291778564 and batch: 1850, loss is 3.634347472190857 and perplexity is 37.877128951517015
At time: 425.01408791542053 and batch: 1900, loss is 3.703910746574402 and perplexity is 40.60579321992701
At time: 426.048095703125 and batch: 1950, loss is 3.6466608476638793 and perplexity is 38.34640753454503
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.508537824763808 and perplexity of 90.78897202516279
finished 10 epochs...
Completing Train Step...
At time: 429.3219940662384 and batch: 50, loss is 3.8916924524307253 and perplexity is 48.99373596210846
At time: 430.3902599811554 and batch: 100, loss is 3.870848088264465 and perplexity is 47.98306270206934
At time: 431.43168783187866 and batch: 150, loss is 3.8411943435668947 and perplexity is 46.5810750373818
At time: 432.47299814224243 and batch: 200, loss is 3.833709692955017 and perplexity is 46.2337334523096
At time: 433.5129826068878 and batch: 250, loss is 3.8170820760726927 and perplexity is 45.471332665009555
At time: 434.551545381546 and batch: 300, loss is 3.8342020606994627 and perplexity is 46.25650305641612
At time: 435.59007120132446 and batch: 350, loss is 3.8540627193450927 and perplexity is 47.184371210830385
At time: 436.6309218406677 and batch: 400, loss is 3.8059154176712036 and perplexity is 44.96639431003943
At time: 437.6717302799225 and batch: 450, loss is 3.83761314868927 and perplexity is 46.41455747395128
At time: 438.712682723999 and batch: 500, loss is 3.862760510444641 and perplexity is 47.596560986503114
At time: 439.7536509037018 and batch: 550, loss is 3.8224730396270754 and perplexity is 45.717128906177564
At time: 440.7936143875122 and batch: 600, loss is 3.804661765098572 and perplexity is 44.910057394968405
At time: 441.83248353004456 and batch: 650, loss is 3.8347956466674806 and perplexity is 46.28396841828026
At time: 442.87210297584534 and batch: 700, loss is 3.858605914115906 and perplexity is 47.39922669497317
At time: 443.9129595756531 and batch: 750, loss is 3.8185654401779177 and perplexity is 45.53883325930372
At time: 444.9523184299469 and batch: 800, loss is 3.773524742126465 and perplexity is 43.5332381674917
At time: 446.0183730125427 and batch: 850, loss is 3.774077515602112 and perplexity is 43.557308839061186
At time: 447.05932569503784 and batch: 900, loss is 3.748195700645447 and perplexity is 42.444430411256185
At time: 448.09868264198303 and batch: 950, loss is 3.8411060857772825 and perplexity is 46.57696407607609
At time: 449.13753366470337 and batch: 1000, loss is 3.8006589126586916 and perplexity is 44.730648375618465
At time: 450.17769622802734 and batch: 1050, loss is 3.762053232192993 and perplexity is 43.036699661793165
At time: 451.21813106536865 and batch: 1100, loss is 3.790527329444885 and perplexity is 44.27974413338425
At time: 452.2591722011566 and batch: 1150, loss is 3.7537078857421875 and perplexity is 42.67903797413494
At time: 453.30088448524475 and batch: 1200, loss is 3.7983234786987303 and perplexity is 44.62630479155217
At time: 454.34061098098755 and batch: 1250, loss is 3.789806685447693 and perplexity is 44.24784569666627
At time: 455.3792543411255 and batch: 1300, loss is 3.773584861755371 and perplexity is 43.5358554482896
At time: 456.41861510276794 and batch: 1350, loss is 3.676285328865051 and perplexity is 39.499393954489314
At time: 457.458349943161 and batch: 1400, loss is 3.6969521713256834 and perplexity is 40.3242155780832
At time: 458.49937438964844 and batch: 1450, loss is 3.6139320945739746 and perplexity is 37.11169297831561
At time: 459.54085183143616 and batch: 1500, loss is 3.61133816242218 and perplexity is 37.0155525095248
At time: 460.5823452472687 and batch: 1550, loss is 3.626610746383667 and perplexity is 37.585214676896015
At time: 461.62202191352844 and batch: 1600, loss is 3.717602324485779 and perplexity is 41.165573997869146
At time: 462.66061663627625 and batch: 1650, loss is 3.6488877725601196 and perplexity is 38.43189725843232
At time: 463.7002854347229 and batch: 1700, loss is 3.6712617444992066 and perplexity is 39.301462994253114
At time: 464.7394425868988 and batch: 1750, loss is 3.6663319158554075 and perplexity is 39.10819030828126
At time: 465.7796959877014 and batch: 1800, loss is 3.6124314308166503 and perplexity is 37.05604257240741
At time: 466.82110023498535 and batch: 1850, loss is 3.6418550491333006 and perplexity is 38.16256453560138
At time: 467.8621995449066 and batch: 1900, loss is 3.7125954008102418 and perplexity is 40.959976246442295
At time: 468.9021508693695 and batch: 1950, loss is 3.6553964757919313 and perplexity is 38.68285489075209
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.508169910519622 and perplexity of 90.75557561302432
finished 11 epochs...
Completing Train Step...
At time: 472.1995849609375 and batch: 50, loss is 3.87442485332489 and perplexity is 48.15499414011773
At time: 473.2333507537842 and batch: 100, loss is 3.851588749885559 and perplexity is 47.06778279504267
At time: 474.26917552948 and batch: 150, loss is 3.8208114910125732 and perplexity is 45.64123074568747
At time: 475.30377078056335 and batch: 200, loss is 3.812096266746521 and perplexity is 45.2451855023205
At time: 476.33676266670227 and batch: 250, loss is 3.7948230695724487 and perplexity is 44.470367548285445
At time: 477.3715374469757 and batch: 300, loss is 3.8118177843093872 and perplexity is 45.232587267068304
At time: 478.4043674468994 and batch: 350, loss is 3.831848087310791 and perplexity is 46.147744536719856
At time: 479.4397006034851 and batch: 400, loss is 3.784059009552002 and perplexity is 43.9942529032482
At time: 480.4733805656433 and batch: 450, loss is 3.8159585285186766 and perplexity is 45.42027215024556
At time: 481.5084800720215 and batch: 500, loss is 3.8422307634353636 and perplexity is 46.62937761559731
At time: 482.54264736175537 and batch: 550, loss is 3.801364097595215 and perplexity is 44.7622028796267
At time: 483.57535576820374 and batch: 600, loss is 3.7847183895111085 and perplexity is 44.02327139798401
At time: 484.6097137928009 and batch: 650, loss is 3.814873080253601 and perplexity is 45.370997541997774
At time: 485.64293217658997 and batch: 700, loss is 3.839979901313782 and perplexity is 46.52453934827438
At time: 486.6789402961731 and batch: 750, loss is 3.800728735923767 and perplexity is 44.73377172457694
At time: 487.71229434013367 and batch: 800, loss is 3.7559776735305785 and perplexity is 42.776020356425164
At time: 488.74791526794434 and batch: 850, loss is 3.7568863344192507 and perplexity is 42.81490691776918
At time: 489.7812328338623 and batch: 900, loss is 3.7316580295562742 and perplexity is 41.74827067814636
At time: 490.8141086101532 and batch: 950, loss is 3.8254376316070555 and perplexity is 45.852862638035546
At time: 491.84800958633423 and batch: 1000, loss is 3.7856339263916015 and perplexity is 44.06359478250504
At time: 492.8815312385559 and batch: 1050, loss is 3.747901635169983 and perplexity is 42.43195080464716
At time: 493.9120433330536 and batch: 1100, loss is 3.777163028717041 and perplexity is 43.69191304146067
At time: 494.9457037448883 and batch: 1150, loss is 3.741308364868164 and perplexity is 42.15310574413049
At time: 495.98061871528625 and batch: 1200, loss is 3.7866475677490232 and perplexity is 44.10828210916826
At time: 497.0141370296478 and batch: 1250, loss is 3.7793724489212037 and perplexity is 43.788553557334296
At time: 498.04683089256287 and batch: 1300, loss is 3.7635436725616453 and perplexity is 43.10089112119089
At time: 499.08024048805237 and batch: 1350, loss is 3.6667781400680544 and perplexity is 39.12564522382296
At time: 500.1150896549225 and batch: 1400, loss is 3.688608031272888 and perplexity is 39.98914455963195
At time: 501.14993262290955 and batch: 1450, loss is 3.6068153619766234 and perplexity is 36.848516571985215
At time: 502.1846251487732 and batch: 1500, loss is 3.6047717189788817 and perplexity is 36.77328825520956
At time: 503.2179825305939 and batch: 1550, loss is 3.6207701063156126 and perplexity is 37.36633279346449
At time: 504.2510311603546 and batch: 1600, loss is 3.713260979652405 and perplexity is 40.98724741455693
At time: 505.28288888931274 and batch: 1650, loss is 3.645286464691162 and perplexity is 38.29374108519055
At time: 506.31604981422424 and batch: 1700, loss is 3.6684298086166383 and perplexity is 39.19032121843221
At time: 507.3500237464905 and batch: 1750, loss is 3.664376301765442 and perplexity is 39.03178451475521
At time: 508.38386154174805 and batch: 1800, loss is 3.6119481801986693 and perplexity is 37.038139543107754
At time: 509.41799449920654 and batch: 1850, loss is 3.641826515197754 and perplexity is 38.16147562298018
At time: 510.45267629623413 and batch: 1900, loss is 3.713303122520447 and perplexity is 40.98897477111375
At time: 511.4851145744324 and batch: 1950, loss is 3.6562823486328124 and perplexity is 38.71713816437601
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509266840025436 and perplexity of 90.8551827027215
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 514.7510061264038 and batch: 50, loss is 3.8662457036972047 and perplexity is 47.762733603337715
At time: 515.8144023418427 and batch: 100, loss is 3.8537867784500124 and perplexity is 47.17135290942814
At time: 516.8480565547943 and batch: 150, loss is 3.827332715988159 and perplexity is 45.939840070606266
At time: 517.8817985057831 and batch: 200, loss is 3.8216959285736083 and perplexity is 45.681615420720064
At time: 518.9136166572571 and batch: 250, loss is 3.8070565605163575 and perplexity is 45.017736678095154
At time: 519.9480309486389 and batch: 300, loss is 3.822156162261963 and perplexity is 45.70264447784422
At time: 520.9828670024872 and batch: 350, loss is 3.8444361734390258 and perplexity is 46.732327993624295
At time: 522.0190663337708 and batch: 400, loss is 3.7995481395721438 and perplexity is 44.68099035975851
At time: 523.0539801120758 and batch: 450, loss is 3.831991186141968 and perplexity is 46.154348697537095
At time: 524.1138563156128 and batch: 500, loss is 3.860570344924927 and perplexity is 47.49243071266572
At time: 525.1479232311249 and batch: 550, loss is 3.815083074569702 and perplexity is 45.38052619404379
At time: 526.1798017024994 and batch: 600, loss is 3.795562496185303 and perplexity is 44.50326228165593
At time: 527.2141525745392 and batch: 650, loss is 3.820950884819031 and perplexity is 45.64759329401213
At time: 528.2481336593628 and batch: 700, loss is 3.84477445602417 and perplexity is 46.74813940055882
At time: 529.2828962802887 and batch: 750, loss is 3.8052471590042116 and perplexity is 44.93635516539563
At time: 530.3186209201813 and batch: 800, loss is 3.7593255376815797 and perplexity is 42.91946865021608
At time: 531.3687725067139 and batch: 850, loss is 3.761340699195862 and perplexity is 43.00604551553879
At time: 532.4166707992554 and batch: 900, loss is 3.7322912645339965 and perplexity is 41.77471551541348
At time: 533.4657015800476 and batch: 950, loss is 3.8295085763931276 and perplexity is 46.03990757660885
At time: 534.5210866928101 and batch: 1000, loss is 3.7880292558670043 and perplexity is 44.16926812058455
At time: 535.5683236122131 and batch: 1050, loss is 3.7470262384414674 and perplexity is 42.39482226719937
At time: 536.6268336772919 and batch: 1100, loss is 3.7702220058441163 and perplexity is 43.389696532870275
At time: 537.6834924221039 and batch: 1150, loss is 3.7369939947128294 and perplexity is 41.971633393690325
At time: 538.7347569465637 and batch: 1200, loss is 3.7804383993148805 and perplexity is 43.835254869456264
At time: 539.7879385948181 and batch: 1250, loss is 3.7709409379959107 and perplexity is 43.42090199672592
At time: 540.8385400772095 and batch: 1300, loss is 3.749739260673523 and perplexity is 42.509996527053204
At time: 541.8819780349731 and batch: 1350, loss is 3.649084963798523 and perplexity is 38.43947643909635
At time: 542.919596195221 and batch: 1400, loss is 3.6711797380447386 and perplexity is 39.29824015276626
At time: 543.9565117359161 and batch: 1450, loss is 3.5877324533462525 and perplexity is 36.15200655209052
At time: 544.9926104545593 and batch: 1500, loss is 3.5836069059371947 and perplexity is 36.003166968612135
At time: 546.024831533432 and batch: 1550, loss is 3.6019703149795532 and perplexity is 36.67041557966286
At time: 547.0564303398132 and batch: 1600, loss is 3.69152147769928 and perplexity is 40.105820672214755
At time: 548.088817358017 and batch: 1650, loss is 3.621026120185852 and perplexity is 37.37590031759678
At time: 549.1251273155212 and batch: 1700, loss is 3.6394558238983152 and perplexity is 38.07111369718352
At time: 550.1635620594025 and batch: 1750, loss is 3.633609027862549 and perplexity is 37.84916912512833
At time: 551.1997990608215 and batch: 1800, loss is 3.5816048049926756 and perplexity is 35.93115710358173
At time: 552.2372119426727 and batch: 1850, loss is 3.6100056886672975 and perplexity is 36.9662631029964
At time: 553.272873878479 and batch: 1900, loss is 3.6849493980407715 and perplexity is 39.84310625961176
At time: 554.3069262504578 and batch: 1950, loss is 3.6325847911834717 and perplexity is 37.810422464100775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499936977652617 and perplexity of 90.01145838836453
finished 13 epochs...
Completing Train Step...
At time: 557.6022922992706 and batch: 50, loss is 3.8630261611938477 and perplexity is 47.609206728189854
At time: 558.6669166088104 and batch: 100, loss is 3.84249605178833 and perplexity is 46.641749487369
At time: 559.7045760154724 and batch: 150, loss is 3.810354733467102 and perplexity is 45.166458079146416
At time: 560.7389736175537 and batch: 200, loss is 3.8029121208190917 and perplexity is 44.83154947045441
At time: 561.7749269008636 and batch: 250, loss is 3.7884500360488893 and perplexity is 44.18785758402267
At time: 562.8105988502502 and batch: 300, loss is 3.8039051055908204 and perplexity is 44.876088626063506
At time: 563.8475360870361 and batch: 350, loss is 3.8267751598358153 and perplexity is 45.914233169443214
At time: 564.8834276199341 and batch: 400, loss is 3.7819573163986204 and perplexity is 43.9018875789172
At time: 565.9219365119934 and batch: 450, loss is 3.8145272064208986 and perplexity is 45.355307614708444
At time: 566.9584589004517 and batch: 500, loss is 3.841510033607483 and perplexity is 46.595782540234936
At time: 567.991800069809 and batch: 550, loss is 3.796950912475586 and perplexity is 44.56509425030199
At time: 569.026344537735 and batch: 600, loss is 3.7777650785446166 and perplexity is 43.71822567013573
At time: 570.0637629032135 and batch: 650, loss is 3.8045461559295655 and perplexity is 44.90486568066361
At time: 571.0996263027191 and batch: 700, loss is 3.829864025115967 and perplexity is 46.05627531172953
At time: 572.1377050876617 and batch: 750, loss is 3.7917299270629883 and perplexity is 44.333026880640105
At time: 573.1728789806366 and batch: 800, loss is 3.745861315727234 and perplexity is 42.34546433044699
At time: 574.206435918808 and batch: 850, loss is 3.748612494468689 and perplexity is 42.46212467485637
At time: 575.2433586120605 and batch: 900, loss is 3.7204522943496703 and perplexity is 41.28306198227734
At time: 576.3072018623352 and batch: 950, loss is 3.8179284858703615 and perplexity is 45.50983633913509
At time: 577.3424527645111 and batch: 1000, loss is 3.7772220849990843 and perplexity is 43.694493399592695
At time: 578.3779375553131 and batch: 1050, loss is 3.7374486446380617 and perplexity is 41.99072013223799
At time: 579.4146881103516 and batch: 1100, loss is 3.7614645099639894 and perplexity is 43.01137045670392
At time: 580.4511289596558 and batch: 1150, loss is 3.7292185640335083 and perplexity is 41.64655133205507
At time: 581.4837982654572 and batch: 1200, loss is 3.7729790878295897 and perplexity is 43.50949054861307
At time: 582.5157074928284 and batch: 1250, loss is 3.764921770095825 and perplexity is 43.16032929936249
At time: 583.5539619922638 and batch: 1300, loss is 3.7446515655517576 and perplexity is 42.294267871249176
At time: 584.5975222587585 and batch: 1350, loss is 3.644901213645935 and perplexity is 38.27899122279421
At time: 585.6428835391998 and batch: 1400, loss is 3.668522391319275 and perplexity is 39.19394973225403
At time: 586.6891272068024 and batch: 1450, loss is 3.586748061180115 and perplexity is 36.11643631045647
At time: 587.7315225601196 and batch: 1500, loss is 3.5842479467391968 and perplexity is 36.02625386667153
At time: 588.7831497192383 and batch: 1550, loss is 3.6037007713317872 and perplexity is 36.73392706932346
At time: 589.8293590545654 and batch: 1600, loss is 3.694308319091797 and perplexity is 40.217745118746876
At time: 590.8716340065002 and batch: 1650, loss is 3.62454315662384 and perplexity is 37.507584153602075
At time: 591.9079089164734 and batch: 1700, loss is 3.643779935836792 and perplexity is 38.23609389378569
At time: 592.9445083141327 and batch: 1750, loss is 3.638814163208008 and perplexity is 38.04669279589191
At time: 593.9840323925018 and batch: 1800, loss is 3.5873267745971678 and perplexity is 36.137343425756036
At time: 595.0220277309418 and batch: 1850, loss is 3.616094121932983 and perplexity is 37.192016273166026
At time: 596.0585329532623 and batch: 1900, loss is 3.6910446166992186 and perplexity is 40.08670032969587
At time: 597.0964727401733 and batch: 1950, loss is 3.6385202264785765 and perplexity is 38.03551111887909
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499124500363372 and perplexity of 89.93835582376035
finished 14 epochs...
Completing Train Step...
At time: 600.4420046806335 and batch: 50, loss is 3.859122371673584 and perplexity is 47.42371270627643
At time: 601.4783573150635 and batch: 100, loss is 3.8364854764938356 and perplexity is 46.36224656834481
At time: 602.5418128967285 and batch: 150, loss is 3.8033264541625975 and perplexity is 44.850128524936146
At time: 603.5759074687958 and batch: 200, loss is 3.794933547973633 and perplexity is 44.47528083479328
At time: 604.6114120483398 and batch: 250, loss is 3.780138831138611 and perplexity is 43.82212518881414
At time: 605.6529784202576 and batch: 300, loss is 3.795743017196655 and perplexity is 44.511296780747614
At time: 606.6902751922607 and batch: 350, loss is 3.818327922821045 and perplexity is 45.52801828041635
At time: 607.7292993068695 and batch: 400, loss is 3.7734703397750855 and perplexity is 43.5308699213919
At time: 608.7695293426514 and batch: 450, loss is 3.806033520698547 and perplexity is 44.97170529095146
At time: 609.8044645786285 and batch: 500, loss is 3.8329488801956177 and perplexity is 46.19857161546755
At time: 610.8423533439636 and batch: 550, loss is 3.7886922931671143 and perplexity is 44.19856370382602
At time: 611.8819305896759 and batch: 600, loss is 3.76990996837616 and perplexity is 43.37615943397963
At time: 612.9209413528442 and batch: 650, loss is 3.7968218183517455 and perplexity is 44.55934152983507
At time: 613.9609115123749 and batch: 700, loss is 3.822803111076355 and perplexity is 45.73222131582228
At time: 615.0000491142273 and batch: 750, loss is 3.785089898109436 and perplexity is 44.039629460227104
At time: 616.0374908447266 and batch: 800, loss is 3.73935998916626 and perplexity is 42.071055615333805
At time: 617.0759103298187 and batch: 850, loss is 3.7423254680633544 and perplexity is 42.196001613735085
At time: 618.1131730079651 and batch: 900, loss is 3.7147926473617554 and perplexity is 41.050074360636565
At time: 619.1532361507416 and batch: 950, loss is 3.812369160652161 and perplexity is 45.2575343225859
At time: 620.1913168430328 and batch: 1000, loss is 3.7719400691986085 and perplexity is 43.464306854723326
At time: 621.2302150726318 and batch: 1050, loss is 3.7327360677719117 and perplexity is 41.79330117731259
At time: 622.2693164348602 and batch: 1100, loss is 3.7570696544647215 and perplexity is 42.82275646792014
At time: 623.3077092170715 and batch: 1150, loss is 3.72516574382782 and perplexity is 41.47810691535022
At time: 624.3460819721222 and batch: 1200, loss is 3.7694244956970215 and perplexity is 43.35510660434877
At time: 625.3834931850433 and batch: 1250, loss is 3.7619817876815795 and perplexity is 43.033625035646864
At time: 626.4199109077454 and batch: 1300, loss is 3.742154445648193 and perplexity is 42.188785768682166
At time: 627.4592061042786 and batch: 1350, loss is 3.6428930616378783 and perplexity is 38.20219832142005
At time: 628.4990301132202 and batch: 1400, loss is 3.6671388578414916 and perplexity is 39.13976108522038
At time: 629.5389919281006 and batch: 1450, loss is 3.5860451316833495 and perplexity is 36.091057922709446
At time: 630.5758810043335 and batch: 1500, loss is 3.584023189544678 and perplexity is 36.01815761680272
At time: 631.6150107383728 and batch: 1550, loss is 3.604011173248291 and perplexity is 36.7453311205146
At time: 632.6539483070374 and batch: 1600, loss is 3.6952071714401247 and perplexity is 40.25391118493308
At time: 633.6920094490051 and batch: 1650, loss is 3.6256960821151734 and perplexity is 37.55085254131183
At time: 634.7309322357178 and batch: 1700, loss is 3.6451803159713747 and perplexity is 38.28967646932919
At time: 635.7708737850189 and batch: 1750, loss is 3.640388216972351 and perplexity is 38.10662749375173
At time: 636.8118183612823 and batch: 1800, loss is 3.5892808723449705 and perplexity is 36.2080283673059
At time: 637.8494780063629 and batch: 1850, loss is 3.6181716823577883 and perplexity is 37.2693652550642
At time: 638.8883547782898 and batch: 1900, loss is 3.693090362548828 and perplexity is 40.16879147069558
At time: 639.9284827709198 and batch: 1950, loss is 3.6404146337509156 and perplexity is 38.107634161388475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499192064861918 and perplexity of 89.94443266895884
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 643.2391893863678 and batch: 50, loss is 3.8568368101119996 and perplexity is 47.31544666289087
At time: 644.3016166687012 and batch: 100, loss is 3.8365748262405397 and perplexity is 46.366389208401486
At time: 645.335574388504 and batch: 150, loss is 3.80454478263855 and perplexity is 44.90480401325736
At time: 646.3685233592987 and batch: 200, loss is 3.795907416343689 and perplexity is 44.518615001509886
At time: 647.4031109809875 and batch: 250, loss is 3.782475929260254 and perplexity is 43.92466156739684
At time: 648.439172744751 and batch: 300, loss is 3.7971984577178954 and perplexity is 44.57612749291374
At time: 649.4736661911011 and batch: 350, loss is 3.8204363346099854 and perplexity is 45.62411135717613
At time: 650.5103135108948 and batch: 400, loss is 3.777471227645874 and perplexity is 43.7053809175446
At time: 651.5462391376495 and batch: 450, loss is 3.8107818126678468 and perplexity is 45.18575185365497
At time: 652.5807123184204 and batch: 500, loss is 3.8379595136642455 and perplexity is 46.43063663545768
At time: 653.6164412498474 and batch: 550, loss is 3.7933368396759035 and perplexity is 44.40432344903918
At time: 654.7013223171234 and batch: 600, loss is 3.772854804992676 and perplexity is 43.50408340170976
At time: 655.73641705513 and batch: 650, loss is 3.797709231376648 and perplexity is 44.598901620363385
At time: 656.7722220420837 and batch: 700, loss is 3.8223287582397463 and perplexity is 45.710533251220845
At time: 657.8083872795105 and batch: 750, loss is 3.784707660675049 and perplexity is 44.02279908205608
At time: 658.8420338630676 and batch: 800, loss is 3.7379046964645384 and perplexity is 42.00987444419686
At time: 659.87628698349 and batch: 850, loss is 3.742210807800293 and perplexity is 42.19116368645422
At time: 660.9113183021545 and batch: 900, loss is 3.7117641735076905 and perplexity is 40.92594334237348
At time: 661.946804523468 and batch: 950, loss is 3.8105818033218384 and perplexity is 45.17671518471707
At time: 662.9812812805176 and batch: 1000, loss is 3.770234580039978 and perplexity is 43.39024212684306
At time: 664.016655921936 and batch: 1050, loss is 3.7309902143478393 and perplexity is 41.72039985537711
At time: 665.0511038303375 and batch: 1100, loss is 3.7533841943740844 and perplexity is 42.66522537357416
At time: 666.0829229354858 and batch: 1150, loss is 3.72216468334198 and perplexity is 41.353815204415014
At time: 667.1159133911133 and batch: 1200, loss is 3.766797800064087 and perplexity is 43.24137536922602
At time: 668.1484067440033 and batch: 1250, loss is 3.75885178565979 and perplexity is 42.89914028085216
At time: 669.1809031963348 and batch: 1300, loss is 3.7375839042663572 and perplexity is 41.99640016556587
At time: 670.2153921127319 and batch: 1350, loss is 3.636870107650757 and perplexity is 37.97279976068221
At time: 671.2497069835663 and batch: 1400, loss is 3.65970742225647 and perplexity is 38.849974570461626
At time: 672.2821846008301 and batch: 1450, loss is 3.5763798904418946 and perplexity is 35.74390948040427
At time: 673.3143668174744 and batch: 1500, loss is 3.5724627780914306 and perplexity is 35.60417043656886
At time: 674.3469331264496 and batch: 1550, loss is 3.593522129058838 and perplexity is 36.36192203129259
At time: 675.3804512023926 and batch: 1600, loss is 3.684867806434631 and perplexity is 39.83985552919638
At time: 676.4144024848938 and batch: 1650, loss is 3.6151376152038575 and perplexity is 37.15645886749086
At time: 677.4487013816833 and batch: 1700, loss is 3.632603259086609 and perplexity is 37.81112074976834
At time: 678.4824550151825 and batch: 1750, loss is 3.6274700927734376 and perplexity is 37.6175272773071
At time: 679.5164186954498 and batch: 1800, loss is 3.5777099180221557 and perplexity is 35.79148149487241
At time: 680.5519416332245 and batch: 1850, loss is 3.6055150604248047 and perplexity is 36.80063352665018
At time: 681.5865244865417 and batch: 1900, loss is 3.680257453918457 and perplexity is 39.6566025061235
At time: 682.6230847835541 and batch: 1950, loss is 3.629542293548584 and perplexity is 37.69555916743931
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.498348644167878 and perplexity of 89.86860365550685
finished 16 epochs...
Completing Train Step...
At time: 685.9345436096191 and batch: 50, loss is 3.855021653175354 and perplexity is 47.22963960187097
At time: 686.9969415664673 and batch: 100, loss is 3.8334330892562867 and perplexity is 46.220946799129884
At time: 688.0345435142517 and batch: 150, loss is 3.8005739498138427 and perplexity is 44.7268480939242
At time: 689.0715174674988 and batch: 200, loss is 3.791730408668518 and perplexity is 44.33304823167614
At time: 690.1083393096924 and batch: 250, loss is 3.778170623779297 and perplexity is 43.73595898381232
At time: 691.1446077823639 and batch: 300, loss is 3.7932191991806032 and perplexity is 44.399100009685185
At time: 692.1832318305969 and batch: 350, loss is 3.8163635683059693 and perplexity is 45.438672893881154
At time: 693.2202317714691 and batch: 400, loss is 3.7732175827026366 and perplexity is 43.51986857654184
At time: 694.2562625408173 and batch: 450, loss is 3.806508855819702 and perplexity is 44.993087003271306
At time: 695.2930464744568 and batch: 500, loss is 3.833734221458435 and perplexity is 46.23486751050692
At time: 696.3297810554504 and batch: 550, loss is 3.7890703296661377 and perplexity is 44.2152755327521
At time: 697.3661661148071 and batch: 600, loss is 3.76881872177124 and perplexity is 43.32885116445173
At time: 698.4045708179474 and batch: 650, loss is 3.7941800117492677 and perplexity is 44.44177972333117
At time: 699.4399042129517 and batch: 700, loss is 3.8191097736358643 and perplexity is 45.56362831766031
At time: 700.4778668880463 and batch: 750, loss is 3.781598482131958 and perplexity is 43.88613690339279
At time: 701.5120558738708 and batch: 800, loss is 3.735111045837402 and perplexity is 41.89267731225241
At time: 702.5481488704681 and batch: 850, loss is 3.7392348003387452 and perplexity is 42.065789118869155
At time: 703.5853009223938 and batch: 900, loss is 3.7092041015625 and perplexity is 40.82130398228752
At time: 704.6210851669312 and batch: 950, loss is 3.8082968616485595 and perplexity is 45.073606868634144
At time: 705.6584768295288 and batch: 1000, loss is 3.768112473487854 and perplexity is 43.298261041078305
At time: 706.7219333648682 and batch: 1050, loss is 3.728969383239746 and perplexity is 41.63617510416872
At time: 707.7579326629639 and batch: 1100, loss is 3.75174147605896 and perplexity is 42.59519596148099
At time: 708.7913482189178 and batch: 1150, loss is 3.7206550884246825 and perplexity is 41.29143479159507
At time: 709.827474117279 and batch: 1200, loss is 3.765354561805725 and perplexity is 43.179012774814815
At time: 710.8634746074677 and batch: 1250, loss is 3.7576188802719117 and perplexity is 42.84628229081049
At time: 711.8992438316345 and batch: 1300, loss is 3.736739573478699 and perplexity is 41.960956277223985
At time: 712.9368808269501 and batch: 1350, loss is 3.636134181022644 and perplexity is 37.94486484647871
At time: 713.972254037857 and batch: 1400, loss is 3.659571385383606 and perplexity is 38.844689900873334
At time: 715.0037930011749 and batch: 1450, loss is 3.576965456008911 and perplexity is 35.76484601228439
At time: 716.0388076305389 and batch: 1500, loss is 3.5735505056381225 and perplexity is 35.642919143727454
At time: 717.0738830566406 and batch: 1550, loss is 3.595000367164612 and perplexity is 36.415713358437856
At time: 718.107595205307 and batch: 1600, loss is 3.6865898418426513 and perplexity is 39.90852027566217
At time: 719.1436305046082 and batch: 1650, loss is 3.617051854133606 and perplexity is 37.22765332741011
At time: 720.1782600879669 and batch: 1700, loss is 3.6346430873870847 and perplexity is 37.88832766159745
At time: 721.210765838623 and batch: 1750, loss is 3.629795536994934 and perplexity is 37.70510652960739
At time: 722.2447311878204 and batch: 1800, loss is 3.580067682266235 and perplexity is 35.87596893177338
At time: 723.279545545578 and batch: 1850, loss is 3.6077473020553588 and perplexity is 36.88287318808776
At time: 724.3136103153229 and batch: 1900, loss is 3.6822103691101074 and perplexity is 39.73412415957612
At time: 725.3551518917084 and batch: 1950, loss is 3.631037464141846 and perplexity is 37.75196261488337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4980729923691865 and perplexity of 89.84383462723372
finished 17 epochs...
Completing Train Step...
At time: 728.6942129135132 and batch: 50, loss is 3.853588523864746 and perplexity is 47.16200189939156
At time: 729.7326936721802 and batch: 100, loss is 3.831346731185913 and perplexity is 46.12461388117949
At time: 730.7767186164856 and batch: 150, loss is 3.7981056070327757 and perplexity is 44.61658304326704
At time: 731.8171329498291 and batch: 200, loss is 3.788897352218628 and perplexity is 44.20762794869836
At time: 732.8846485614777 and batch: 250, loss is 3.7753291082382203 and perplexity is 43.61185897620684
At time: 733.924084186554 and batch: 300, loss is 3.790424132347107 and perplexity is 44.2751748280729
At time: 734.9639360904694 and batch: 350, loss is 3.8135198736190796 and perplexity is 45.30964272934144
At time: 736.0015096664429 and batch: 400, loss is 3.7702747535705567 and perplexity is 43.39198530107645
At time: 737.0396835803986 and batch: 450, loss is 3.803601245880127 and perplexity is 44.86245466226759
At time: 738.0800905227661 and batch: 500, loss is 3.830845160484314 and perplexity is 46.10148492712186
At time: 739.1221919059753 and batch: 550, loss is 3.786245279312134 and perplexity is 44.0905414259798
At time: 740.1629338264465 and batch: 600, loss is 3.7661529397964477 and perplexity is 43.21349971324982
At time: 741.2034430503845 and batch: 650, loss is 3.791685185432434 and perplexity is 44.331043393102625
At time: 742.2431604862213 and batch: 700, loss is 3.8168175983428956 and perplexity is 45.45930810036034
At time: 743.283045053482 and batch: 750, loss is 3.779441223144531 and perplexity is 43.79156518465581
At time: 744.322838306427 and batch: 800, loss is 3.7330856132507324 and perplexity is 41.80791239027706
At time: 745.3636181354523 and batch: 850, loss is 3.7370958948135375 and perplexity is 41.97591052527639
At time: 746.4047467708588 and batch: 900, loss is 3.707369499206543 and perplexity is 40.74648177731132
At time: 747.4456963539124 and batch: 950, loss is 3.806585202217102 and perplexity is 44.99652219450246
At time: 748.4878025054932 and batch: 1000, loss is 3.7665170669555663 and perplexity is 43.229237787292185
At time: 749.5292546749115 and batch: 1050, loss is 3.7275303030014038 and perplexity is 41.57630039996109
At time: 750.569874048233 and batch: 1100, loss is 3.75051100730896 and perplexity is 42.54281613642802
At time: 751.6125843524933 and batch: 1150, loss is 3.719558234214783 and perplexity is 41.2461689370709
At time: 752.6544995307922 and batch: 1200, loss is 3.7643460750579836 and perplexity is 43.135489262782194
At time: 753.6952159404755 and batch: 1250, loss is 3.7567791080474855 and perplexity is 42.81031627676621
At time: 754.7352511882782 and batch: 1300, loss is 3.73614417552948 and perplexity is 41.935980245986
At time: 755.7762887477875 and batch: 1350, loss is 3.6356624698638917 and perplexity is 37.92697005123239
At time: 756.8160388469696 and batch: 1400, loss is 3.659454388618469 and perplexity is 38.840145463659596
At time: 757.8552775382996 and batch: 1450, loss is 3.5772758865356447 and perplexity is 35.77595023572632
At time: 758.8952279090881 and batch: 1500, loss is 3.5741826152801512 and perplexity is 35.665456498877575
At time: 759.9347248077393 and batch: 1550, loss is 3.595878829956055 and perplexity is 36.44771726270854
At time: 760.9758193492889 and batch: 1600, loss is 3.6876447200775146 and perplexity is 39.95064111736025
At time: 762.0164988040924 and batch: 1650, loss is 3.618218336105347 and perplexity is 37.27110405118284
At time: 763.0582973957062 and batch: 1700, loss is 3.635916442871094 and perplexity is 37.936603701162106
At time: 764.0970714092255 and batch: 1750, loss is 3.6311964988708496 and perplexity is 37.75796696546466
At time: 765.1371276378632 and batch: 1800, loss is 3.5815219116210937 and perplexity is 35.92817877226825
At time: 766.1774575710297 and batch: 1850, loss is 3.609150586128235 and perplexity is 36.934666668578295
At time: 767.2186131477356 and batch: 1900, loss is 3.683440809249878 and perplexity is 39.783044711594044
At time: 768.2584962844849 and batch: 1950, loss is 3.6319925880432127 and perplexity is 37.78803764201819
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497965684047965 and perplexity of 89.83419415342853
finished 18 epochs...
Completing Train Step...
At time: 771.5363054275513 and batch: 50, loss is 3.852272381782532 and perplexity is 47.09997083381256
At time: 772.5970914363861 and batch: 100, loss is 3.8296136236190796 and perplexity is 46.044744195215095
At time: 773.6309213638306 and batch: 150, loss is 3.7961186742782593 and perplexity is 44.528020905666
At time: 774.6648030281067 and batch: 200, loss is 3.786606035232544 and perplexity is 44.106450219256445
At time: 775.7004642486572 and batch: 250, loss is 3.7730636310577395 and perplexity is 43.51316913689688
At time: 776.7339813709259 and batch: 300, loss is 3.7881579399108887 and perplexity is 44.174952366349736
At time: 777.7668917179108 and batch: 350, loss is 3.8112222719192506 and perplexity is 45.205658719850405
At time: 778.8006823062897 and batch: 400, loss is 3.7679356479644777 and perplexity is 43.29060548027764
At time: 779.8338034152985 and batch: 450, loss is 3.801305069923401 and perplexity is 44.75956074898562
At time: 780.8702845573425 and batch: 500, loss is 3.8285783386230468 and perplexity is 45.99709942961463
At time: 781.9038605690002 and batch: 550, loss is 3.7840404319763183 and perplexity is 43.99343560427699
At time: 782.936136007309 and batch: 600, loss is 3.764067873954773 and perplexity is 43.123490591180975
At time: 783.9792504310608 and batch: 650, loss is 3.789674072265625 and perplexity is 44.24197823810855
At time: 785.0596566200256 and batch: 700, loss is 3.814960422515869 and perplexity is 45.374960520629685
At time: 786.0951347351074 and batch: 750, loss is 3.77770534992218 and perplexity is 43.715614518722106
At time: 787.1307601928711 and batch: 800, loss is 3.73142560005188 and perplexity is 41.73856827588928
At time: 788.1662945747375 and batch: 850, loss is 3.7353766489028932 and perplexity is 41.90380561355822
At time: 789.1988716125488 and batch: 900, loss is 3.7058784675598146 and perplexity is 40.685772754273025
At time: 790.2350609302521 and batch: 950, loss is 3.805170831680298 and perplexity is 44.93292542455256
At time: 791.2715885639191 and batch: 1000, loss is 3.765202407836914 and perplexity is 43.17244341644143
At time: 792.3069064617157 and batch: 1050, loss is 3.7263489151000977 and perplexity is 41.52721166381634
At time: 793.3411250114441 and batch: 1100, loss is 3.7494735097885132 and perplexity is 42.49870095882448
At time: 794.3761479854584 and batch: 1150, loss is 3.7186278820037844 and perplexity is 41.207813317489396
At time: 795.412807226181 and batch: 1200, loss is 3.7635216331481933 and perplexity is 43.09994121329906
At time: 796.4488081932068 and batch: 1250, loss is 3.75609664440155 and perplexity is 42.78110975956303
At time: 797.4842104911804 and batch: 1300, loss is 3.7356212663650514 and perplexity is 41.91405726995815
At time: 798.5191261768341 and batch: 1350, loss is 3.63526358127594 and perplexity is 37.911844432622246
At time: 799.5530691146851 and batch: 1400, loss is 3.6592850828170778 and perplexity is 38.83357015834009
At time: 800.5866334438324 and batch: 1450, loss is 3.577395839691162 and perplexity is 35.780241931244795
At time: 801.6221160888672 and batch: 1500, loss is 3.5745093631744385 and perplexity is 35.67711201579148
At time: 802.6574366092682 and batch: 1550, loss is 3.5963857650756834 and perplexity is 36.46619857463654
At time: 803.6935884952545 and batch: 1600, loss is 3.6882955551147463 and perplexity is 39.97665085746626
At time: 804.7284903526306 and batch: 1650, loss is 3.618944606781006 and perplexity is 37.2981827931625
At time: 805.7611398696899 and batch: 1700, loss is 3.6367362403869627 and perplexity is 37.967716786109186
At time: 806.7951757907867 and batch: 1750, loss is 3.6320847558975218 and perplexity is 37.79152064487419
At time: 807.8293917179108 and batch: 1800, loss is 3.582471332550049 and perplexity is 35.96230593509168
At time: 808.8658463954926 and batch: 1850, loss is 3.610083999633789 and perplexity is 36.969158080140325
At time: 809.9010038375854 and batch: 1900, loss is 3.6842688703536988 and perplexity is 39.81600114659911
At time: 810.936222076416 and batch: 1950, loss is 3.632647919654846 and perplexity is 37.812809453615664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497940418332122 and perplexity of 89.83192445687894
finished 19 epochs...
Completing Train Step...
At time: 814.2041480541229 and batch: 50, loss is 3.8510168838500975 and perplexity is 47.040874023537285
At time: 815.2653093338013 and batch: 100, loss is 3.828065915107727 and perplexity is 45.97353547210898
At time: 816.2998540401459 and batch: 150, loss is 3.7943807220458985 and perplexity is 44.45070054134231
At time: 817.3342320919037 and batch: 200, loss is 3.7845667934417726 and perplexity is 44.01659814891271
At time: 818.3697981834412 and batch: 250, loss is 3.7711204147338866 and perplexity is 43.428695737952964
At time: 819.4032218456268 and batch: 300, loss is 3.7862013578414917 and perplexity is 44.08860494708577
At time: 820.4371359348297 and batch: 350, loss is 3.8092443418502806 and perplexity is 45.11633345686418
At time: 821.4811038970947 and batch: 400, loss is 3.76594464302063 and perplexity is 43.204499417986526
At time: 822.5237445831299 and batch: 450, loss is 3.7993511867523195 and perplexity is 44.67219117925477
At time: 823.5750193595886 and batch: 500, loss is 3.8266629791259765 and perplexity is 45.909082767067865
At time: 824.6252300739288 and batch: 550, loss is 3.7821729707717897 and perplexity is 43.911356233905714
At time: 825.6764631271362 and batch: 600, loss is 3.762297759056091 and perplexity is 43.04722457771945
At time: 826.7276539802551 and batch: 650, loss is 3.787943472862244 and perplexity is 44.16547931055717
At time: 827.7775139808655 and batch: 700, loss is 3.8133555841445923 and perplexity is 45.302199443391736
At time: 828.8299052715302 and batch: 750, loss is 3.7762101602554323 and perplexity is 43.650300224415155
At time: 829.8813169002533 and batch: 800, loss is 3.7299851465225218 and perplexity is 41.67848908893259
At time: 830.9237501621246 and batch: 850, loss is 3.73390793800354 and perplexity is 41.84230621100572
At time: 831.9588334560394 and batch: 900, loss is 3.7045861148834227 and perplexity is 40.6332263485205
At time: 832.9937953948975 and batch: 950, loss is 3.803934960365295 and perplexity is 44.87742841156815
At time: 834.0263142585754 and batch: 1000, loss is 3.764056739807129 and perplexity is 43.1230104505428
At time: 835.0605537891388 and batch: 1050, loss is 3.7253079795837403 and perplexity is 41.484007004833366
At time: 836.0948665142059 and batch: 1100, loss is 3.7485447931289673 and perplexity is 42.459250029438216
At time: 837.1824314594269 and batch: 1150, loss is 3.717781138420105 and perplexity is 41.17293563427646
At time: 838.2241938114166 and batch: 1200, loss is 3.762789525985718 and perplexity is 43.06839898518893
At time: 839.2674095630646 and batch: 1250, loss is 3.7554829502105713 and perplexity is 42.754863295494964
At time: 840.3015913963318 and batch: 1300, loss is 3.735123314857483 and perplexity is 41.893191297504636
At time: 841.3333687782288 and batch: 1350, loss is 3.6348797130584716 and perplexity is 37.89729407336786
At time: 842.367219209671 and batch: 1400, loss is 3.6590634393692016 and perplexity is 38.82496390575184
At time: 843.4024560451508 and batch: 1450, loss is 3.5773872756958007 and perplexity is 35.779935510730965
At time: 844.4390571117401 and batch: 1500, loss is 3.574642515182495 and perplexity is 35.681862811180004
At time: 845.4730880260468 and batch: 1550, loss is 3.596659483909607 and perplexity is 36.47618142617293
At time: 846.5062131881714 and batch: 1600, loss is 3.6886932325363158 and perplexity is 39.99255183042165
At time: 847.5398452281952 and batch: 1650, loss is 3.6193997287750244 and perplexity is 37.31516187997343
At time: 848.5729205608368 and batch: 1700, loss is 3.6372740364074705 and perplexity is 37.988141164687015
At time: 849.6071178913116 and batch: 1750, loss is 3.6326649236679076 and perplexity is 37.81345242858807
At time: 850.6414630413055 and batch: 1800, loss is 3.583114652633667 and perplexity is 35.98544865204208
At time: 851.6743519306183 and batch: 1850, loss is 3.6107295608520507 and perplexity is 36.99303163996172
At time: 852.7099175453186 and batch: 1900, loss is 3.68484845161438 and perplexity is 39.839084443415906
At time: 853.7444958686829 and batch: 1950, loss is 3.6331149911880494 and perplexity is 37.830474865686284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497959438590116 and perplexity of 89.8336330995076
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f31229a0b38>
ELAPSED
5295.190710544586


RESULTS SO FAR:
[{'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.77128768299961}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.13481025420142356, 'wordvec_source': 'None', 'rnn_dropout': 0.7333439966881319, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.4361717208564}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.049255346069296047, 'wordvec_source': 'None', 'rnn_dropout': 0.9817036371865334, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -87.71067320599664}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.9986437985159311, 'wordvec_source': 'None', 'rnn_dropout': 0.5007125478907719, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -90.71879193959988}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.1789226511740396, 'wordvec_source': 'None', 'rnn_dropout': 0.45869390902326646, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.91759789379468}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.0, 'wordvec_source': 'None', 'rnn_dropout': 1.0, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -89.83192445687894}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.025668578322893487, 'wordvec_source': 'None', 'rnn_dropout': 0.3161989266969156, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.77128768299961}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.13481025420142356, 'wordvec_source': 'None', 'rnn_dropout': 0.7333439966881319, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.4361717208564}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.049255346069296047, 'wordvec_source': 'None', 'rnn_dropout': 0.9817036371865334, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -87.71067320599664}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.9986437985159311, 'wordvec_source': 'None', 'rnn_dropout': 0.5007125478907719, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -90.71879193959988}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.1789226511740396, 'wordvec_source': 'None', 'rnn_dropout': 0.45869390902326646, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -88.91759789379468}, {'params': {'tie_weights': 'FALSE', 'wordvec_dim': 300, 'seq_len': 35, 'data': 'wikitext', 'dropout': 0.0, 'wordvec_source': 'None', 'rnn_dropout': 1.0, 'tune_wordvecs': 'FALSE', 'batch_size': 32, 'num_layers': 1}, 'best_accuracy': -89.83192445687894}]
