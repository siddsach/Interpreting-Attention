FALSE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'name': 'dropout', 'type': 'continuous'}, {'domain': [0, 1], 'name': 'rnn_dropout', 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.930631399154663 and batch: 50, loss is 7.4475944709777835 and perplexity is 1715.7309367319988
At time: 3.1583588123321533 and batch: 100, loss is 6.542727880477905 and perplexity is 694.1776311886586
At time: 4.387998104095459 and batch: 150, loss is 6.24358528137207 and perplexity is 514.7005531552643
At time: 5.615895509719849 and batch: 200, loss is 6.1175747489929195 and perplexity is 453.76287008155737
At time: 6.841753721237183 and batch: 250, loss is 6.051866064071655 and perplexity is 424.9051910141419
At time: 8.071101427078247 and batch: 300, loss is 5.978874387741089 and perplexity is 394.9955060473514
At time: 9.30038833618164 and batch: 350, loss is 5.915760135650634 and perplexity is 370.836081321736
At time: 10.527379274368286 and batch: 400, loss is 5.8601695251464845 and perplexity is 350.78360562178005
At time: 11.7577223777771 and batch: 450, loss is 5.790372076034546 and perplexity is 327.13472072406915
At time: 12.986563444137573 and batch: 500, loss is 5.7633201789855955 and perplexity is 318.4037332667793
At time: 14.212819337844849 and batch: 550, loss is 5.713986854553223 and perplexity is 303.0769866390647
At time: 15.443054437637329 and batch: 600, loss is 5.743341245651245 and perplexity is 312.10549187680346
At time: 16.667133569717407 and batch: 650, loss is 5.82340711593628 and perplexity is 338.122114567014
At time: 17.897775888442993 and batch: 700, loss is 5.730742111206054 and perplexity is 308.19790064738606
At time: 19.130531072616577 and batch: 750, loss is 5.669518337249756 and perplexity is 289.89486919869455
At time: 20.372671365737915 and batch: 800, loss is 5.6705177307128904 and perplexity is 290.1847330558639
At time: 21.6053786277771 and batch: 850, loss is 5.6965524864196775 and perplexity is 297.838825576073
At time: 22.835201263427734 and batch: 900, loss is 5.696503763198852 and perplexity is 297.82431426272603
At time: 24.06464123725891 and batch: 950, loss is 5.72303427696228 and perplexity is 305.83149396595695
At time: 25.294856786727905 and batch: 1000, loss is 5.693886451721191 and perplexity is 297.04583447312666
At time: 26.5249445438385 and batch: 1050, loss is 5.594782581329346 and perplexity is 269.0191539465883
At time: 27.75629234313965 and batch: 1100, loss is 5.678887100219726 and perplexity is 292.6235879147387
At time: 28.988597869873047 and batch: 1150, loss is 5.587756271362305 and perplexity is 267.1355670657577
At time: 30.219122886657715 and batch: 1200, loss is 5.667404499053955 and perplexity is 289.28272556564934
At time: 31.450117349624634 and batch: 1250, loss is 5.603100233078003 and perplexity is 271.26609325796665
At time: 32.67963123321533 and batch: 1300, loss is 5.613791418075562 and perplexity is 274.1818076932906
At time: 33.909889936447144 and batch: 1350, loss is 5.584567699432373 and perplexity is 266.2851426353804
At time: 35.140610456466675 and batch: 1400, loss is 5.60218337059021 and perplexity is 271.0174935361433
At time: 36.371217489242554 and batch: 1450, loss is 5.558946676254273 and perplexity is 259.54930284471385
At time: 37.602466344833374 and batch: 1500, loss is 5.537280626296997 and perplexity is 253.98637562214304
At time: 38.83094000816345 and batch: 1550, loss is 5.520680961608886 and perplexity is 249.8050869583638
At time: 40.062174558639526 and batch: 1600, loss is 5.5503341007232665 and perplexity is 257.3235135177048
At time: 41.29381442070007 and batch: 1650, loss is 5.525304899215699 and perplexity is 250.96284473136186
At time: 42.52638483047485 and batch: 1700, loss is 5.533456287384033 and perplexity is 253.016900624561
At time: 43.75472927093506 and batch: 1750, loss is 5.548849573135376 and perplexity is 256.9417930702461
At time: 44.985756397247314 and batch: 1800, loss is 5.551307582855225 and perplexity is 257.57413532838217
At time: 46.21654558181763 and batch: 1850, loss is 5.515957355499268 and perplexity is 248.6278886228662
At time: 47.44880390167236 and batch: 1900, loss is 5.511806373596191 and perplexity is 247.59797780600962
At time: 48.68086075782776 and batch: 1950, loss is 5.452814788818359 and perplexity is 233.4142539318739
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.021281681504361 and perplexity of 151.60548927706523
finished 1 epochs...
Completing Train Step...
At time: 52.384803771972656 and batch: 50, loss is 5.273710107803344 and perplexity is 195.13860633920436
At time: 53.571006536483765 and batch: 100, loss is 5.198467836380005 and perplexity is 180.99471580280263
At time: 54.73054122924805 and batch: 150, loss is 5.113131217956543 and perplexity is 166.18991787176594
At time: 55.89137578010559 and batch: 200, loss is 5.086477928161621 and perplexity is 161.81891933435992
At time: 57.051308155059814 and batch: 250, loss is 5.092040767669678 and perplexity is 162.7216004191837
At time: 58.21253800392151 and batch: 300, loss is 5.102012214660644 and perplexity is 164.35228687227118
At time: 59.374284505844116 and batch: 350, loss is 5.073478212356568 and perplexity is 159.72893341522365
At time: 60.569616079330444 and batch: 400, loss is 5.039903535842895 and perplexity is 154.4551149247678
At time: 61.728965044021606 and batch: 450, loss is 4.99967544555664 and perplexity is 148.36499876808483
At time: 62.89032793045044 and batch: 500, loss is 4.9867147731781 and perplexity is 146.4544960700073
At time: 64.05239963531494 and batch: 550, loss is 4.939929552078247 and perplexity is 139.76040338322403
At time: 65.21469259262085 and batch: 600, loss is 4.932131261825561 and perplexity is 138.67474981447586
At time: 66.37758374214172 and batch: 650, loss is 4.998356008529663 and perplexity is 148.16936958377866
At time: 67.53957772254944 and batch: 700, loss is 4.9825453948974605 and perplexity is 145.84514306930882
At time: 68.70211601257324 and batch: 750, loss is 4.938024597167969 and perplexity is 139.49441954058486
At time: 69.86455368995667 and batch: 800, loss is 4.913925075531006 and perplexity is 136.1728555685632
At time: 71.02720761299133 and batch: 850, loss is 4.913698043823242 and perplexity is 136.1419435217525
At time: 72.18971300125122 and batch: 900, loss is 4.922311210632325 and perplexity is 137.3196212778441
At time: 73.35152983665466 and batch: 950, loss is 4.981677761077881 and perplexity is 145.71865777015682
At time: 74.51334834098816 and batch: 1000, loss is 4.949940204620361 and perplexity is 141.1665225632933
At time: 75.67292165756226 and batch: 1050, loss is 4.8591592979431155 and perplexity is 128.9157767783633
At time: 76.83097100257874 and batch: 1100, loss is 4.936901035308838 and perplexity is 139.3377769465283
At time: 77.99212336540222 and batch: 1150, loss is 4.8450816822052 and perplexity is 127.11366449412535
At time: 79.15381598472595 and batch: 1200, loss is 4.923149299621582 and perplexity is 137.4347555801025
At time: 80.3130350112915 and batch: 1250, loss is 4.868442087173462 and perplexity is 130.1180463368153
At time: 81.47150111198425 and batch: 1300, loss is 4.895386352539062 and perplexity is 133.67164101727082
At time: 82.63308811187744 and batch: 1350, loss is 4.80619107246399 and perplexity is 122.26503084128402
At time: 83.79548978805542 and batch: 1400, loss is 4.826158056259155 and perplexity is 124.73083009607154
At time: 84.95785975456238 and batch: 1450, loss is 4.76338300704956 and perplexity is 117.14154700649658
At time: 86.11885905265808 and batch: 1500, loss is 4.748673696517944 and perplexity is 115.43108630427388
At time: 87.2793641090393 and batch: 1550, loss is 4.744938306808471 and perplexity is 115.00071052339541
At time: 88.44156885147095 and batch: 1600, loss is 4.815403738021851 and perplexity is 123.39662216257123
At time: 89.6055953502655 and batch: 1650, loss is 4.769483671188355 and perplexity is 117.85837257426027
At time: 90.76528906822205 and batch: 1700, loss is 4.794349002838135 and perplexity is 120.82569898757355
At time: 91.92966365814209 and batch: 1750, loss is 4.80122706413269 and perplexity is 121.65961010953907
At time: 93.09096813201904 and batch: 1800, loss is 4.753743658065796 and perplexity is 116.01780353338613
At time: 94.25288081169128 and batch: 1850, loss is 4.764410533905029 and perplexity is 117.26197495281568
At time: 95.414311170578 and batch: 1900, loss is 4.82651759147644 and perplexity is 124.77568328483962
At time: 96.5750503540039 and batch: 1950, loss is 4.754258594512939 and perplexity is 116.07756071319753
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.620742584938227 and perplexity of 101.5694280596013
finished 2 epochs...
Completing Train Step...
At time: 100.28253173828125 and batch: 50, loss is 4.696853427886963 and perplexity is 109.60175946380869
At time: 101.44360828399658 and batch: 100, loss is 4.641619262695312 and perplexity is 103.7121489031771
At time: 102.60662794113159 and batch: 150, loss is 4.585118560791016 and perplexity is 98.01480716632439
At time: 103.76979303359985 and batch: 200, loss is 4.582737445831299 and perplexity is 97.78170027999133
At time: 104.9338047504425 and batch: 250, loss is 4.5868198204040525 and perplexity is 98.18169772106391
At time: 106.09742212295532 and batch: 300, loss is 4.614360771179199 and perplexity is 100.9232948300316
At time: 107.26088809967041 and batch: 350, loss is 4.612398080825805 and perplexity is 100.725407911733
At time: 108.42239880561829 and batch: 400, loss is 4.576615781784057 and perplexity is 97.18494200137253
At time: 109.58446455001831 and batch: 450, loss is 4.574912576675415 and perplexity is 97.01955699394803
At time: 110.7473452091217 and batch: 500, loss is 4.580968160629272 and perplexity is 97.6088495208926
At time: 111.91052770614624 and batch: 550, loss is 4.537176685333252 and perplexity is 93.42665456782336
At time: 113.07479882240295 and batch: 600, loss is 4.5164227962493895 and perplexity is 91.50767021453353
At time: 114.23888897895813 and batch: 650, loss is 4.583225288391113 and perplexity is 97.82941399240245
At time: 115.40232992172241 and batch: 700, loss is 4.600168581008911 and perplexity is 99.50108822196508
At time: 116.56667757034302 and batch: 750, loss is 4.565253200531006 and perplexity is 96.08692019591426
At time: 117.72799229621887 and batch: 800, loss is 4.54198839187622 and perplexity is 93.87727948089146
At time: 118.89215469360352 and batch: 850, loss is 4.5399824810028075 and perplexity is 93.6891587649872
At time: 120.0831127166748 and batch: 900, loss is 4.534523973464966 and perplexity is 93.1791489980571
At time: 121.24681949615479 and batch: 950, loss is 4.605881023406982 and perplexity is 100.07110901236827
At time: 122.40956020355225 and batch: 1000, loss is 4.583026027679443 and perplexity is 97.80992237576923
At time: 123.57184147834778 and batch: 1050, loss is 4.506861028671264 and perplexity is 90.63686499350236
At time: 124.7371757030487 and batch: 1100, loss is 4.5779390621185305 and perplexity is 97.3136300503336
At time: 125.90055871009827 and batch: 1150, loss is 4.505678749084472 and perplexity is 90.52977019867924
At time: 127.06513094902039 and batch: 1200, loss is 4.585774230957031 and perplexity is 98.07909362426427
At time: 128.2291169166565 and batch: 1250, loss is 4.551688032150269 and perplexity is 94.79228576379032
At time: 129.39225482940674 and batch: 1300, loss is 4.561861143112183 and perplexity is 95.76154001153276
At time: 130.5566267967224 and batch: 1350, loss is 4.451730718612671 and perplexity is 85.77526846486136
At time: 131.7187840938568 and batch: 1400, loss is 4.473960170745849 and perplexity is 87.70335646317615
At time: 132.87810635566711 and batch: 1450, loss is 4.413971567153931 and perplexity is 82.59685189538291
At time: 134.03894972801208 and batch: 1500, loss is 4.409565768241882 and perplexity is 82.23374724555295
At time: 135.19825744628906 and batch: 1550, loss is 4.412588148117066 and perplexity is 82.48266484056978
At time: 136.35959339141846 and batch: 1600, loss is 4.500978813171387 and perplexity is 90.10528438995365
At time: 137.52168703079224 and batch: 1650, loss is 4.447294435501099 and perplexity is 85.39558789791872
At time: 138.68353486061096 and batch: 1700, loss is 4.4746543979644775 and perplexity is 87.76426365966854
At time: 139.84546160697937 and batch: 1750, loss is 4.489001188278198 and perplexity is 89.03247477393894
At time: 141.0071098804474 and batch: 1800, loss is 4.430731716156006 and perplexity is 83.99285335829823
At time: 142.16778206825256 and batch: 1850, loss is 4.466594686508179 and perplexity is 87.05975191278691
At time: 143.32845044136047 and batch: 1900, loss is 4.534354724884033 and perplexity is 93.1633798938036
At time: 144.48857069015503 and batch: 1950, loss is 4.4718509292602535 and perplexity is 87.51856385992083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509674781976744 and perplexity of 90.89225390417474
finished 3 epochs...
Completing Train Step...
At time: 148.16597700119019 and batch: 50, loss is 4.422070560455322 and perplexity is 83.26851948984796
At time: 149.35285472869873 and batch: 100, loss is 4.373236103057861 and perplexity is 79.29983937143545
At time: 150.5128037929535 and batch: 150, loss is 4.325858430862427 and perplexity is 75.63040847831627
At time: 151.67351508140564 and batch: 200, loss is 4.331387252807617 and perplexity is 76.04971360402033
At time: 152.83319735527039 and batch: 250, loss is 4.329183902740478 and perplexity is 75.88233392817061
At time: 153.992933511734 and batch: 300, loss is 4.358531217575074 and perplexity is 78.14227609101714
At time: 155.15082693099976 and batch: 350, loss is 4.351172533035278 and perplexity is 77.56936226338743
At time: 156.31160950660706 and batch: 400, loss is 4.32601375579834 and perplexity is 75.6421566790369
At time: 157.47200727462769 and batch: 450, loss is 4.338403511047363 and perplexity is 76.58517430236218
At time: 158.63380217552185 and batch: 500, loss is 4.350566301345825 and perplexity is 77.52235150899702
At time: 159.79816198349 and batch: 550, loss is 4.3074367713928225 and perplexity is 74.24992528300609
At time: 160.96126055717468 and batch: 600, loss is 4.286579122543335 and perplexity is 72.71728560752223
At time: 162.1244616508484 and batch: 650, loss is 4.345084867477417 and perplexity is 77.09858036368705
At time: 163.28742218017578 and batch: 700, loss is 4.378733692169189 and perplexity is 79.73699786273752
At time: 164.45081305503845 and batch: 750, loss is 4.342684755325317 and perplexity is 76.91375701115722
At time: 165.61483335494995 and batch: 800, loss is 4.320006327629089 and perplexity is 75.1891040592799
At time: 166.77771878242493 and batch: 850, loss is 4.31676290512085 and perplexity is 74.94562908634546
At time: 167.93855929374695 and batch: 900, loss is 4.304837965965271 and perplexity is 74.05721469131173
At time: 169.1023440361023 and batch: 950, loss is 4.385719652175903 and perplexity is 80.29598760746995
At time: 170.26652908325195 and batch: 1000, loss is 4.3633068084716795 and perplexity is 78.51634412037093
At time: 171.42851424217224 and batch: 1050, loss is 4.299879302978516 and perplexity is 73.69089889081152
At time: 172.59032368659973 and batch: 1100, loss is 4.363545980453491 and perplexity is 78.53512527587236
At time: 173.75339436531067 and batch: 1150, loss is 4.295546116828919 and perplexity is 73.37227333885679
At time: 174.91585659980774 and batch: 1200, loss is 4.37764111995697 and perplexity is 79.64992700884615
At time: 176.07720613479614 and batch: 1250, loss is 4.346869029998779 and perplexity is 77.23625954571835
At time: 177.23781871795654 and batch: 1300, loss is 4.35460391998291 and perplexity is 77.83598995036125
At time: 178.4003345966339 and batch: 1350, loss is 4.237104592323303 and perplexity is 69.20717846752149
At time: 179.5631091594696 and batch: 1400, loss is 4.269181294441223 and perplexity is 71.46310442174267
At time: 180.72385358810425 and batch: 1450, loss is 4.202862281799316 and perplexity is 66.87747954246404
At time: 181.8873414993286 and batch: 1500, loss is 4.205242805480957 and perplexity is 67.03687261049795
At time: 183.04804372787476 and batch: 1550, loss is 4.206448431015015 and perplexity is 67.11774271557675
At time: 184.2081334590912 and batch: 1600, loss is 4.30251293182373 and perplexity is 73.88522915232836
At time: 185.37130761146545 and batch: 1650, loss is 4.249242014884949 and perplexity is 70.0522936217892
At time: 186.53541898727417 and batch: 1700, loss is 4.273270998001099 and perplexity is 71.75596578418241
At time: 187.6967055797577 and batch: 1750, loss is 4.2917032289505 and perplexity is 73.09085299876728
At time: 188.85763263702393 and batch: 1800, loss is 4.229545664787293 and perplexity is 68.68601860679834
At time: 190.02159690856934 and batch: 1850, loss is 4.2652812004089355 and perplexity is 71.18493439189281
At time: 191.18184995651245 and batch: 1900, loss is 4.340195970535278 and perplexity is 76.72257322889129
At time: 192.341046333313 and batch: 1950, loss is 4.278299579620361 and perplexity is 72.1177052707997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.466816179142442 and perplexity of 87.07903714226565
finished 4 epochs...
Completing Train Step...
At time: 196.02030777931213 and batch: 50, loss is 4.236733722686767 and perplexity is 69.18151638533529
At time: 197.18412446975708 and batch: 100, loss is 4.192307286262512 and perplexity is 66.17530031271447
At time: 198.34763360023499 and batch: 150, loss is 4.151216387748718 and perplexity is 63.511207586418294
At time: 199.50783586502075 and batch: 200, loss is 4.154323878288269 and perplexity is 63.70887502893779
At time: 200.66645097732544 and batch: 250, loss is 4.148750228881836 and perplexity is 63.35477183567559
At time: 201.8227996826172 and batch: 300, loss is 4.176738753318786 and perplexity is 65.15302627136201
At time: 202.98095297813416 and batch: 350, loss is 4.1716397190093994 and perplexity is 64.8216543115166
At time: 204.13885879516602 and batch: 400, loss is 4.146137228012085 and perplexity is 63.18944185952149
At time: 205.2985875606537 and batch: 450, loss is 4.168609290122986 and perplexity is 64.62551424219613
At time: 206.45827221870422 and batch: 500, loss is 4.184106483459472 and perplexity is 65.63482890317421
At time: 207.61928915977478 and batch: 550, loss is 4.146355257034302 and perplexity is 63.203220493761044
At time: 208.81472730636597 and batch: 600, loss is 4.128168616294861 and perplexity is 62.06415550758252
At time: 209.97350525856018 and batch: 650, loss is 4.177873740196228 and perplexity is 65.22701608199489
At time: 211.132239818573 and batch: 700, loss is 4.219819235801697 and perplexity is 68.02118738262804
At time: 212.29117512702942 and batch: 750, loss is 4.179823389053345 and perplexity is 65.35430990816197
At time: 213.45001578330994 and batch: 800, loss is 4.156445860862732 and perplexity is 63.84420768757807
At time: 214.609215259552 and batch: 850, loss is 4.156326093673706 and perplexity is 63.83656170416585
At time: 215.77025485038757 and batch: 900, loss is 4.140983033180237 and perplexity is 62.86458906133069
At time: 216.93304824829102 and batch: 950, loss is 4.2308700656890865 and perplexity is 68.77704669731884
At time: 218.0916576385498 and batch: 1000, loss is 4.206958513259888 and perplexity is 67.15198701741464
At time: 219.25677490234375 and batch: 1050, loss is 4.141929969787598 and perplexity is 62.92414603590898
At time: 220.41807007789612 and batch: 1100, loss is 4.199780588150024 and perplexity is 66.67170087473797
At time: 221.57789206504822 and batch: 1150, loss is 4.139918050765991 and perplexity is 62.79767501696629
At time: 222.7393832206726 and batch: 1200, loss is 4.221481041908264 and perplexity is 68.13431938288547
At time: 223.89931988716125 and batch: 1250, loss is 4.193945994377136 and perplexity is 66.2838312152729
At time: 225.06015968322754 and batch: 1300, loss is 4.199002089500428 and perplexity is 66.61981724392932
At time: 226.22408819198608 and batch: 1350, loss is 4.079879899024963 and perplexity is 59.13836684783154
At time: 227.38644313812256 and batch: 1400, loss is 4.121007633209229 and perplexity is 61.62130266307748
At time: 228.5479075908661 and batch: 1450, loss is 4.045933375358581 and perplexity is 57.16451709296482
At time: 229.70756101608276 and batch: 1500, loss is 4.049607911109924 and perplexity is 57.374956551605166
At time: 230.86893439292908 and batch: 1550, loss is 4.055804080963135 and perplexity is 57.73156519064415
At time: 232.03783011436462 and batch: 1600, loss is 4.150458450317383 and perplexity is 63.46308830288591
At time: 233.20357418060303 and batch: 1650, loss is 4.100131125450134 and perplexity is 60.34820026349901
At time: 234.3686649799347 and batch: 1700, loss is 4.125037035942078 and perplexity is 61.870100625399104
At time: 235.53277564048767 and batch: 1750, loss is 4.141484837532044 and perplexity is 62.8961427019112
At time: 236.69698524475098 and batch: 1800, loss is 4.077922248840332 and perplexity is 59.022707859910234
At time: 237.8621368408203 and batch: 1850, loss is 4.116319928169251 and perplexity is 61.33311616639145
At time: 239.02913451194763 and batch: 1900, loss is 4.1949549627304075 and perplexity is 66.35074325369081
At time: 240.19513201713562 and batch: 1950, loss is 4.13166341304779 and perplexity is 62.28143657215449
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.457167798419332 and perplexity of 86.24290558309161
finished 5 epochs...
Completing Train Step...
At time: 243.85009598731995 and batch: 50, loss is 4.096644072532654 and perplexity is 60.13812937272549
At time: 245.03987884521484 and batch: 100, loss is 4.051183433532715 and perplexity is 57.46542332966393
At time: 246.20176529884338 and batch: 150, loss is 4.009601011276245 and perplexity is 55.124871972845234
At time: 247.36235857009888 and batch: 200, loss is 4.019767518043518 and perplexity is 55.68815782988094
At time: 248.52899479866028 and batch: 250, loss is 4.010978102684021 and perplexity is 55.20083625326797
At time: 249.69392848014832 and batch: 300, loss is 4.032790503501892 and perplexity is 56.418126770197844
At time: 250.8564100265503 and batch: 350, loss is 4.034090614318847 and perplexity is 56.49152428919975
At time: 252.02234983444214 and batch: 400, loss is 4.010809669494629 and perplexity is 55.19153938333342
At time: 253.1852867603302 and batch: 450, loss is 4.039736790657043 and perplexity is 56.81138754938447
At time: 254.34733057022095 and batch: 500, loss is 4.055849566459655 and perplexity is 57.734191199273944
At time: 255.5126988887787 and batch: 550, loss is 4.021445345878601 and perplexity is 55.78167139906954
At time: 256.6771695613861 and batch: 600, loss is 4.0039986753463745 and perplexity is 54.816907387977
At time: 257.8436086177826 and batch: 650, loss is 4.049373331069947 and perplexity is 57.36149911048882
At time: 259.0076599121094 and batch: 700, loss is 4.09126663684845 and perplexity is 59.81560839495225
At time: 260.1714491844177 and batch: 750, loss is 4.05083131313324 and perplexity is 57.44519214396073
At time: 261.33592796325684 and batch: 800, loss is 4.029513936042786 and perplexity is 56.23357149094391
At time: 262.4991569519043 and batch: 850, loss is 4.028753328323364 and perplexity is 56.19081606449218
At time: 263.6617388725281 and batch: 900, loss is 4.011293630599976 and perplexity is 55.21825640621769
At time: 264.8296639919281 and batch: 950, loss is 4.107735118865967 and perplexity is 60.80883669964856
At time: 265.9936728477478 and batch: 1000, loss is 4.083482127189637 and perplexity is 59.35178089076919
At time: 267.20280599594116 and batch: 1050, loss is 4.026964130401612 and perplexity is 56.09036945939262
At time: 268.3685953617096 and batch: 1100, loss is 4.075655903816223 and perplexity is 58.88909350494722
At time: 269.53321146965027 and batch: 1150, loss is 4.019682316780091 and perplexity is 55.68341333059742
At time: 270.6989402770996 and batch: 1200, loss is 4.09861912727356 and perplexity is 60.257022842158825
At time: 271.86213731765747 and batch: 1250, loss is 4.072661895751953 and perplexity is 58.713042764275606
At time: 273.02858901023865 and batch: 1300, loss is 4.077834396362305 and perplexity is 59.01752279652852
At time: 274.1937847137451 and batch: 1350, loss is 3.9597899389266966 and perplexity is 52.446307864183446
At time: 275.35853266716003 and batch: 1400, loss is 4.0002514314651485 and perplexity is 54.611879451933085
At time: 276.52321600914 and batch: 1450, loss is 3.922538800239563 and perplexity is 50.52856400508814
At time: 277.68752694129944 and batch: 1500, loss is 3.9306742429733275 and perplexity is 50.941312915036605
At time: 278.8501136302948 and batch: 1550, loss is 3.9393444299697875 and perplexity is 51.38490385324396
At time: 280.0168511867523 and batch: 1600, loss is 4.034686465263366 and perplexity is 56.52519484762561
At time: 281.1921401023865 and batch: 1650, loss is 3.983156304359436 and perplexity is 53.686217131843144
At time: 282.35460901260376 and batch: 1700, loss is 4.0096187400817875 and perplexity is 55.12584927964423
At time: 283.5176227092743 and batch: 1750, loss is 4.024729309082031 and perplexity is 55.96515747122541
At time: 284.6812570095062 and batch: 1800, loss is 3.9624261903762816 and perplexity is 52.58475192581474
At time: 285.84633326530457 and batch: 1850, loss is 3.998193941116333 and perplexity is 54.4996315511143
At time: 287.0085651874542 and batch: 1900, loss is 4.076824908256531 and perplexity is 58.95797537049921
At time: 288.1784372329712 and batch: 1950, loss is 4.015553193092346 and perplexity is 55.453963668619984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.462097735737645 and perplexity of 86.669127462088
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 291.8065564632416 and batch: 50, loss is 4.012059116363526 and perplexity is 55.260541377591686
At time: 292.9621193408966 and batch: 100, loss is 4.001690850257874 and perplexity is 54.69054542057655
At time: 294.1216082572937 and batch: 150, loss is 3.9655657529830934 and perplexity is 52.75010447817337
At time: 295.2806496620178 and batch: 200, loss is 3.9749600982666013 and perplexity is 53.24799217615787
At time: 296.4375536441803 and batch: 250, loss is 3.956867985725403 and perplexity is 52.29328587743839
At time: 297.6213903427124 and batch: 300, loss is 3.9708066511154176 and perplexity is 53.027288113360655
At time: 298.7776074409485 and batch: 350, loss is 3.97923077583313 and perplexity is 53.47588346053548
At time: 299.9366271495819 and batch: 400, loss is 3.9430770826339723 and perplexity is 51.577064262432984
At time: 301.09384965896606 and batch: 450, loss is 3.9641745901107788 and perplexity is 52.67677151218939
At time: 302.2528839111328 and batch: 500, loss is 3.9780575895309447 and perplexity is 53.413183073371556
At time: 303.4125826358795 and batch: 550, loss is 3.931989326477051 and perplexity is 51.008349064715205
At time: 304.5709767341614 and batch: 600, loss is 3.9093873500823975 and perplexity is 49.86839074721516
At time: 305.7295687198639 and batch: 650, loss is 3.945648822784424 and perplexity is 51.7098777771626
At time: 306.89066982269287 and batch: 700, loss is 3.9841821575164795 and perplexity is 53.741319565848144
At time: 308.0493140220642 and batch: 750, loss is 3.9416347789764403 and perplexity is 51.502728094552346
At time: 309.2220792770386 and batch: 800, loss is 3.9070070028305053 and perplexity is 49.74982782678663
At time: 310.3834934234619 and batch: 850, loss is 3.8991860008239745 and perplexity is 49.3622519151241
At time: 311.54489398002625 and batch: 900, loss is 3.864375629425049 and perplexity is 47.67349720940679
At time: 312.70744037628174 and batch: 950, loss is 3.9606975221633913 and perplexity is 52.4939288607678
At time: 313.87444615364075 and batch: 1000, loss is 3.9303918743133544 and perplexity is 50.9269307154083
At time: 315.0404779911041 and batch: 1050, loss is 3.871383328437805 and perplexity is 48.00875203923673
At time: 316.2085690498352 and batch: 1100, loss is 3.9047138500213623 and perplexity is 49.63587457539625
At time: 317.37251329421997 and batch: 1150, loss is 3.8487191343307496 and perplexity is 46.93290996254568
At time: 318.53754591941833 and batch: 1200, loss is 3.9108889055252076 and perplexity is 49.94332714726578
At time: 319.69981718063354 and batch: 1250, loss is 3.8746903324127198 and perplexity is 48.1677799811481
At time: 320.8615679740906 and batch: 1300, loss is 3.8869781160354613 and perplexity is 48.76330659706702
At time: 322.0243833065033 and batch: 1350, loss is 3.7654435873031615 and perplexity is 43.18285697901947
At time: 323.18779468536377 and batch: 1400, loss is 3.794335570335388 and perplexity is 44.44869356148911
At time: 324.3506944179535 and batch: 1450, loss is 3.71201470375061 and perplexity is 40.936197813374676
At time: 325.51438903808594 and batch: 1500, loss is 3.707230830192566 and perplexity is 40.740831894601094
At time: 326.6764123439789 and batch: 1550, loss is 3.7109691190719603 and perplexity is 40.89341792103624
At time: 327.83875608444214 and batch: 1600, loss is 3.790732951164246 and perplexity is 44.28884994665022
At time: 328.9994204044342 and batch: 1650, loss is 3.729379515647888 and perplexity is 41.65325495119001
At time: 330.1614122390747 and batch: 1700, loss is 3.744063014984131 and perplexity is 42.26938287964249
At time: 331.3239076137543 and batch: 1750, loss is 3.743961763381958 and perplexity is 42.26510325356623
At time: 332.4897861480713 and batch: 1800, loss is 3.674736542701721 and perplexity is 39.43826518958464
At time: 333.65414571762085 and batch: 1850, loss is 3.696185059547424 and perplexity is 40.29329425893457
At time: 334.8172814846039 and batch: 1900, loss is 3.7649633264541627 and perplexity is 43.16212292274079
At time: 335.9801366329193 and batch: 1950, loss is 3.69846905708313 and perplexity is 40.38542922168845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.412671750090843 and perplexity of 82.48956084240855
finished 7 epochs...
Completing Train Step...
At time: 339.6472952365875 and batch: 50, loss is 3.898864893913269 and perplexity is 49.346403899496
At time: 340.8369092941284 and batch: 100, loss is 3.87941255569458 and perplexity is 48.39577689569706
At time: 342.0037350654602 and batch: 150, loss is 3.83800754070282 and perplexity is 46.43286661498364
At time: 343.1682560443878 and batch: 200, loss is 3.845764608383179 and perplexity is 46.794450104608394
At time: 344.33332896232605 and batch: 250, loss is 3.829086089134216 and perplexity is 46.020460410635465
At time: 345.4975311756134 and batch: 300, loss is 3.8483996629714965 and perplexity is 46.91791863678335
At time: 346.66264748573303 and batch: 350, loss is 3.855256366729736 and perplexity is 47.24072633950701
At time: 347.8258020877838 and batch: 400, loss is 3.8211356019973755 and perplexity is 45.65602596744947
At time: 348.99230313301086 and batch: 450, loss is 3.8499207592010496 and perplexity is 46.98933961123696
At time: 350.15727829933167 and batch: 500, loss is 3.864887208938599 and perplexity is 47.69789223338361
At time: 351.3240809440613 and batch: 550, loss is 3.82470046043396 and perplexity is 45.81907368514602
At time: 352.49061369895935 and batch: 600, loss is 3.8057351970672606 and perplexity is 44.95829116949811
At time: 353.6575872898102 and batch: 650, loss is 3.842129096984863 and perplexity is 46.624637213260115
At time: 354.82258915901184 and batch: 700, loss is 3.8816998863220213 and perplexity is 48.506600735492825
At time: 356.03339862823486 and batch: 750, loss is 3.842963819503784 and perplexity is 46.66357209552935
At time: 357.19736552238464 and batch: 800, loss is 3.8097305727005004 and perplexity is 45.13827574411591
At time: 358.3614957332611 and batch: 850, loss is 3.8058920764923094 and perplexity is 44.96534475363461
At time: 359.5270664691925 and batch: 900, loss is 3.7697355937957764 and perplexity is 43.36859639379983
At time: 360.69388818740845 and batch: 950, loss is 3.870482711791992 and perplexity is 47.965534022359385
At time: 361.8589107990265 and batch: 1000, loss is 3.8423003578186035 and perplexity is 46.632622871297805
At time: 363.0239646434784 and batch: 1050, loss is 3.7883654594421388 and perplexity is 44.18412048300653
At time: 364.18842458724976 and batch: 1100, loss is 3.822105703353882 and perplexity is 45.70033843048825
At time: 365.3521041870117 and batch: 1150, loss is 3.7718370151519776 and perplexity is 43.45982791280844
At time: 366.51641488075256 and batch: 1200, loss is 3.835338397026062 and perplexity is 46.30909587708765
At time: 367.6805000305176 and batch: 1250, loss is 3.8040194511413574 and perplexity is 44.88122030050988
At time: 368.8456299304962 and batch: 1300, loss is 3.816690411567688 and perplexity is 45.453526645229985
At time: 370.01085114479065 and batch: 1350, loss is 3.695608172416687 and perplexity is 40.2700562795117
At time: 371.1755802631378 and batch: 1400, loss is 3.731174807548523 and perplexity is 41.72810186836796
At time: 372.3401300907135 and batch: 1450, loss is 3.652126908302307 and perplexity is 38.5565852220832
At time: 373.50509238243103 and batch: 1500, loss is 3.6496558570861817 and perplexity is 38.461427543449425
At time: 374.6695420742035 and batch: 1550, loss is 3.656653890609741 and perplexity is 38.73152587908509
At time: 375.8315167427063 and batch: 1600, loss is 3.7411222314834593 and perplexity is 42.145260374047815
At time: 376.9987003803253 and batch: 1650, loss is 3.6837575340271 and perplexity is 39.79564698318802
At time: 378.1659471988678 and batch: 1700, loss is 3.7038768482208253 and perplexity is 40.60441677372095
At time: 379.3331413269043 and batch: 1750, loss is 3.7057720470428466 and perplexity is 40.68144318368493
At time: 380.49733424186707 and batch: 1800, loss is 3.642723808288574 and perplexity is 38.19573301855588
At time: 381.66404914855957 and batch: 1850, loss is 3.668758525848389 and perplexity is 39.203205869922016
At time: 382.8308050632477 and batch: 1900, loss is 3.741370983123779 and perplexity is 42.1557453807248
At time: 383.99758553504944 and batch: 1950, loss is 3.678804244995117 and perplexity is 39.599015030943164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419441258630087 and perplexity of 83.04986899460687
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 387.7015166282654 and batch: 50, loss is 3.8562963581085206 and perplexity is 47.2898818438475
At time: 388.8688163757324 and batch: 100, loss is 3.8625865507125856 and perplexity is 47.58828182164867
At time: 390.03847098350525 and batch: 150, loss is 3.837336916923523 and perplexity is 46.401738069428774
At time: 391.20325660705566 and batch: 200, loss is 3.8546259021759033 and perplexity is 47.210952122832985
At time: 392.3679027557373 and batch: 250, loss is 3.839534492492676 and perplexity is 46.5038215223445
At time: 393.53297090530396 and batch: 300, loss is 3.8600921726226805 and perplexity is 47.46972657640973
At time: 394.6963243484497 and batch: 350, loss is 3.8838729524612425 and perplexity is 48.61212339941873
At time: 395.8622455596924 and batch: 400, loss is 3.8476911211013793 and perplexity is 46.88468710132785
At time: 397.0277259349823 and batch: 450, loss is 3.8750112771987917 and perplexity is 48.1832416600296
At time: 398.19267678260803 and batch: 500, loss is 3.87926100730896 and perplexity is 48.38844314956044
At time: 399.357887506485 and batch: 550, loss is 3.826450490951538 and perplexity is 45.89932866623278
At time: 400.52275800704956 and batch: 600, loss is 3.797384066581726 and perplexity is 44.584401985177465
At time: 401.68785977363586 and batch: 650, loss is 3.8325832176208494 and perplexity is 46.18168161502874
At time: 402.84993267059326 and batch: 700, loss is 3.867709856033325 and perplexity is 47.832716741808234
At time: 404.01420998573303 and batch: 750, loss is 3.826812596321106 and perplexity is 45.91595206913249
At time: 405.1796658039093 and batch: 800, loss is 3.7979081439971925 and perplexity is 44.607773787121815
At time: 406.34426164627075 and batch: 850, loss is 3.802487335205078 and perplexity is 44.812509717378326
At time: 407.5078730583191 and batch: 900, loss is 3.7572491693496706 and perplexity is 42.830444480156345
At time: 408.6732933521271 and batch: 950, loss is 3.859612812995911 and perplexity is 47.44697695905487
At time: 409.8375594615936 and batch: 1000, loss is 3.82236102104187 and perplexity is 45.71200802490013
At time: 411.0027701854706 and batch: 1050, loss is 3.7602837228775026 and perplexity is 42.960613158575036
At time: 412.1674757003784 and batch: 1100, loss is 3.793980951309204 and perplexity is 44.432934003547885
At time: 413.3301966190338 and batch: 1150, loss is 3.7453647232055665 and perplexity is 42.32444110995303
At time: 414.54175186157227 and batch: 1200, loss is 3.7970468473434447 and perplexity is 44.569369801813956
At time: 415.7071545124054 and batch: 1250, loss is 3.7556116724014283 and perplexity is 42.76036714939462
At time: 416.8733403682709 and batch: 1300, loss is 3.7626870393753054 and perplexity is 43.063985277137895
At time: 418.03879284858704 and batch: 1350, loss is 3.63964560508728 and perplexity is 38.0783395640513
At time: 419.2057468891144 and batch: 1400, loss is 3.6768215322494506 and perplexity is 39.52057934254024
At time: 420.37020230293274 and batch: 1450, loss is 3.597586336135864 and perplexity is 36.510005128498676
At time: 421.53655791282654 and batch: 1500, loss is 3.6011736726760866 and perplexity is 36.641214008474236
At time: 422.7010889053345 and batch: 1550, loss is 3.605853714942932 and perplexity is 36.81309833797714
At time: 423.8667402267456 and batch: 1600, loss is 3.681515407562256 and perplexity is 39.70652006415111
At time: 425.0326249599457 and batch: 1650, loss is 3.6204132652282714 and perplexity is 37.353001329389045
At time: 426.1994049549103 and batch: 1700, loss is 3.6292672872543337 and perplexity is 37.68519407670091
At time: 427.3658616542816 and batch: 1750, loss is 3.6273931550979612 and perplexity is 37.61463318353506
At time: 428.53259801864624 and batch: 1800, loss is 3.565731029510498 and perplexity is 35.365297032679685
At time: 429.69760489463806 and batch: 1850, loss is 3.58569525718689 and perplexity is 36.07843279072668
At time: 430.8643362522125 and batch: 1900, loss is 3.6568683528900148 and perplexity is 38.73983322121753
At time: 432.0297658443451 and batch: 1950, loss is 3.598441095352173 and perplexity is 36.54122573301862
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.392137820221657 and perplexity of 80.8129981046993
finished 9 epochs...
Completing Train Step...
At time: 435.71018958091736 and batch: 50, loss is 3.8397702169418335 and perplexity is 46.51478490217414
At time: 436.90493392944336 and batch: 100, loss is 3.8273759412765505 and perplexity is 45.94182587636017
At time: 438.07128167152405 and batch: 150, loss is 3.7941076135635377 and perplexity is 44.43856233557651
At time: 439.23819494247437 and batch: 200, loss is 3.8058596229553223 and perplexity is 44.96388549283472
At time: 440.403537273407 and batch: 250, loss is 3.7879670333862303 and perplexity is 44.16651988465003
At time: 441.5709774494171 and batch: 300, loss is 3.80675283908844 and perplexity is 45.00406590298842
At time: 442.73783826828003 and batch: 350, loss is 3.8306691312789916 and perplexity is 46.09337043358084
At time: 443.90268445014954 and batch: 400, loss is 3.7951341342926024 and perplexity is 44.484202862449486
At time: 445.09621238708496 and batch: 450, loss is 3.825976939201355 and perplexity is 45.877598104489536
At time: 446.2615840435028 and batch: 500, loss is 3.8299966716766356 and perplexity is 46.06238492344738
At time: 447.43026185035706 and batch: 550, loss is 3.7797003316879274 and perplexity is 43.80291342347318
At time: 448.59661293029785 and batch: 600, loss is 3.7543087339401247 and perplexity is 42.70468930269695
At time: 449.76192712783813 and batch: 650, loss is 3.7911717557907103 and perplexity is 44.3082883634293
At time: 450.92555475234985 and batch: 700, loss is 3.8295528888702393 and perplexity is 46.04194776416211
At time: 452.0928864479065 and batch: 750, loss is 3.7896748638153075 and perplexity is 44.242013257846246
At time: 453.25859022140503 and batch: 800, loss is 3.760422496795654 and perplexity is 42.96657538488043
At time: 454.4240896701813 and batch: 850, loss is 3.7655045795440674 and perplexity is 43.18549087855824
At time: 455.59132838249207 and batch: 900, loss is 3.7209127950668335 and perplexity is 41.302077239860715
At time: 456.7575271129608 and batch: 950, loss is 3.825812091827393 and perplexity is 45.870035926238046
At time: 457.9222934246063 and batch: 1000, loss is 3.7902965450286867 and perplexity is 44.269526237595926
At time: 459.0897972583771 and batch: 1050, loss is 3.730805492401123 and perplexity is 41.71269389365009
At time: 460.25720262527466 and batch: 1100, loss is 3.768376088142395 and perplexity is 43.30967660179331
At time: 461.4239978790283 and batch: 1150, loss is 3.719800577163696 and perplexity is 41.25616586657625
At time: 462.5902397632599 and batch: 1200, loss is 3.772662754058838 and perplexity is 43.4957292041081
At time: 463.7574813365936 and batch: 1250, loss is 3.733285913467407 and perplexity is 41.81628736291396
At time: 464.92424178123474 and batch: 1300, loss is 3.7425288915634156 and perplexity is 42.20458614519005
At time: 466.0903651714325 and batch: 1350, loss is 3.619862813949585 and perplexity is 37.332445979922724
At time: 467.2563331127167 and batch: 1400, loss is 3.6591832876205443 and perplexity is 38.82961728862871
At time: 468.42093443870544 and batch: 1450, loss is 3.582175221443176 and perplexity is 35.95165867333957
At time: 469.5865240097046 and batch: 1500, loss is 3.587610764503479 and perplexity is 36.147607523911006
At time: 470.7535147666931 and batch: 1550, loss is 3.594389805793762 and perplexity is 36.39348611680732
At time: 471.9169626235962 and batch: 1600, loss is 3.673283786773682 and perplexity is 39.38101261311811
At time: 473.0832624435425 and batch: 1650, loss is 3.6145448112487792 and perplexity is 37.134438899124525
At time: 474.2468087673187 and batch: 1700, loss is 3.6259329462051393 and perplexity is 37.559748043297375
At time: 475.4099671840668 and batch: 1750, loss is 3.6248854875564573 and perplexity is 37.52042635788206
At time: 476.57310938835144 and batch: 1800, loss is 3.565617618560791 and perplexity is 35.36128644818294
At time: 477.73880338668823 and batch: 1850, loss is 3.5871681451797484 and perplexity is 36.13161143466455
At time: 478.9069137573242 and batch: 1900, loss is 3.6594016790390014 and perplexity is 38.83809826987957
At time: 480.07207918167114 and batch: 1950, loss is 3.602486991882324 and perplexity is 36.689367231926774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.392764069313227 and perplexity of 80.863623021599
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 483.74070143699646 and batch: 50, loss is 3.8293673372268677 and perplexity is 46.033405397640024
At time: 484.90259742736816 and batch: 100, loss is 3.830351543426514 and perplexity is 46.078734063341095
At time: 486.0661573410034 and batch: 150, loss is 3.8094213819503784 and perplexity is 45.12432156414222
At time: 487.22895979881287 and batch: 200, loss is 3.828820672035217 and perplexity is 46.00824741437939
At time: 488.3910596370697 and batch: 250, loss is 3.8113630962371827 and perplexity is 45.21202522417509
At time: 489.5524334907532 and batch: 300, loss is 3.8282281875610353 and perplexity is 45.980996315825635
At time: 490.7147464752197 and batch: 350, loss is 3.855589280128479 and perplexity is 47.25645602843859
At time: 491.8776915073395 and batch: 400, loss is 3.8319119739532472 and perplexity is 46.15069285535333
At time: 493.039270401001 and batch: 450, loss is 3.877516188621521 and perplexity is 48.30408770357719
At time: 494.20215797424316 and batch: 500, loss is 3.8902591276168823 and perplexity is 48.92356232745086
At time: 495.36487770080566 and batch: 550, loss is 3.8441400718688965 and perplexity is 46.71849252638246
At time: 496.5278100967407 and batch: 600, loss is 3.794319763183594 and perplexity is 44.44799095979601
At time: 497.6913437843323 and batch: 650, loss is 3.8113500547409056 and perplexity is 45.21143559556128
At time: 498.85371494293213 and batch: 700, loss is 3.840465097427368 and perplexity is 46.547118351131815
At time: 500.01922631263733 and batch: 750, loss is 3.797278046607971 and perplexity is 44.579675398609844
At time: 501.18235540390015 and batch: 800, loss is 3.765642523765564 and perplexity is 43.191448478376216
At time: 502.34834694862366 and batch: 850, loss is 3.778642511367798 and perplexity is 43.75660231030968
At time: 503.55937695503235 and batch: 900, loss is 3.7366358613967896 and perplexity is 41.95660464475191
At time: 504.7223131656647 and batch: 950, loss is 3.8536766958236695 and perplexity is 47.16616044881682
At time: 505.88771510124207 and batch: 1000, loss is 3.819436535835266 and perplexity is 45.578519221821914
At time: 507.05127573013306 and batch: 1050, loss is 3.755448179244995 and perplexity is 42.75337669346055
At time: 508.2156400680542 and batch: 1100, loss is 3.777441964149475 and perplexity is 43.70410196400092
At time: 509.37784576416016 and batch: 1150, loss is 3.7362586212158204 and perplexity is 41.94077991267294
At time: 510.5470323562622 and batch: 1200, loss is 3.7888563013076784 and perplexity is 44.20581322254848
At time: 511.71184611320496 and batch: 1250, loss is 3.747645764350891 and perplexity is 42.421095095527924
At time: 512.8756058216095 and batch: 1300, loss is 3.7523786354064943 and perplexity is 42.62234453681372
At time: 514.0413537025452 and batch: 1350, loss is 3.6178493022918703 and perplexity is 37.25735229111065
At time: 515.2071278095245 and batch: 1400, loss is 3.6513869094848634 and perplexity is 38.52806394876997
At time: 516.3746111392975 and batch: 1450, loss is 3.565425305366516 and perplexity is 35.35448666009785
At time: 517.5405626296997 and batch: 1500, loss is 3.568487596511841 and perplexity is 35.46291833148219
At time: 518.7062826156616 and batch: 1550, loss is 3.579063687324524 and perplexity is 35.839967715980286
At time: 519.8715527057648 and batch: 1600, loss is 3.6605530166625977 and perplexity is 38.8828397849991
At time: 521.038051366806 and batch: 1650, loss is 3.601219935417175 and perplexity is 36.64290917068221
At time: 522.2035796642303 and batch: 1700, loss is 3.609416837692261 and perplexity is 36.944501890609104
At time: 523.3688473701477 and batch: 1750, loss is 3.6092463302612305 and perplexity is 36.938203115510284
At time: 524.5337572097778 and batch: 1800, loss is 3.551900873184204 and perplexity is 34.879556124947015
At time: 525.698695898056 and batch: 1850, loss is 3.5689197635650634 and perplexity is 35.47824754854887
At time: 526.8601093292236 and batch: 1900, loss is 3.6490927600860594 and perplexity is 38.439776125475646
At time: 528.0251243114471 and batch: 1950, loss is 3.599850902557373 and perplexity is 36.592778147287795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369729969113372 and perplexity of 79.02229035915455
finished 11 epochs...
Completing Train Step...
At time: 531.6761546134949 and batch: 50, loss is 3.8349099445343016 and perplexity is 46.28925887947693
At time: 532.8696267604828 and batch: 100, loss is 3.8230843257904055 and perplexity is 45.74508369782326
At time: 534.0334334373474 and batch: 150, loss is 3.7935420083999634 and perplexity is 44.41343476207023
At time: 535.1980485916138 and batch: 200, loss is 3.805345296859741 and perplexity is 44.94076533932584
At time: 536.3627655506134 and batch: 250, loss is 3.788505959510803 and perplexity is 44.19032879109191
At time: 537.5296578407288 and batch: 300, loss is 3.8029565525054934 and perplexity is 44.8335414560547
At time: 538.6936240196228 and batch: 350, loss is 3.8285968685150147 and perplexity is 45.997951758794656
At time: 539.858775138855 and batch: 400, loss is 3.8049636268615723 and perplexity is 44.923616070389976
At time: 541.0233206748962 and batch: 450, loss is 3.8495369863510134 and perplexity is 46.97130983834298
At time: 542.1877617835999 and batch: 500, loss is 3.8608517408370973 and perplexity is 47.50579676901591
At time: 543.3509769439697 and batch: 550, loss is 3.8149322175979616 and perplexity is 45.373680741641266
At time: 544.5178039073944 and batch: 600, loss is 3.770560145378113 and perplexity is 43.4043707854688
At time: 545.6833577156067 and batch: 650, loss is 3.7902263402938843 and perplexity is 44.26641841633974
At time: 546.8483533859253 and batch: 700, loss is 3.8236356449127196 and perplexity is 45.77031079066809
At time: 548.0159764289856 and batch: 750, loss is 3.78195556640625 and perplexity is 43.90181075101611
At time: 549.1828136444092 and batch: 800, loss is 3.7498779487609863 and perplexity is 42.515892566015346
At time: 550.3492624759674 and batch: 850, loss is 3.761783981323242 and perplexity is 43.02511355283296
At time: 551.5165750980377 and batch: 900, loss is 3.7202286434173586 and perplexity is 41.273830019383354
At time: 552.6845333576202 and batch: 950, loss is 3.837295608520508 and perplexity is 46.39982132732105
At time: 553.8532042503357 and batch: 1000, loss is 3.8025423812866213 and perplexity is 44.814976538336175
At time: 555.0214123725891 and batch: 1050, loss is 3.739013714790344 and perplexity is 42.05649000880019
At time: 556.187349319458 and batch: 1100, loss is 3.7627082109451293 and perplexity is 43.06489701896056
At time: 557.356698513031 and batch: 1150, loss is 3.722419271469116 and perplexity is 41.364344735067704
At time: 558.5239233970642 and batch: 1200, loss is 3.7765577459335327 and perplexity is 43.665475080746525
At time: 559.693274974823 and batch: 1250, loss is 3.7363377904891966 and perplexity is 41.94410046518458
At time: 560.8614511489868 and batch: 1300, loss is 3.7424289274215696 and perplexity is 42.20036741081867
At time: 562.028872013092 and batch: 1350, loss is 3.609443717002869 and perplexity is 36.945494946696954
At time: 563.1971592903137 and batch: 1400, loss is 3.6455171871185303 and perplexity is 38.3025773294074
At time: 564.3645009994507 and batch: 1450, loss is 3.56201057434082 and perplexity is 35.23396648669904
At time: 565.5326890945435 and batch: 1500, loss is 3.5669750022888183 and perplexity is 35.40931787417306
At time: 566.6999268531799 and batch: 1550, loss is 3.5788057231903077 and perplexity is 35.83072348212975
At time: 567.8688051700592 and batch: 1600, loss is 3.6617224979400635 and perplexity is 38.92833913827752
At time: 569.0362219810486 and batch: 1650, loss is 3.6037546682357786 and perplexity is 36.735906967618654
At time: 570.2018148899078 and batch: 1700, loss is 3.6134703493118288 and perplexity is 37.094560785571474
At time: 571.3691992759705 and batch: 1750, loss is 3.6141854524612427 and perplexity is 37.12109670964599
At time: 572.5351858139038 and batch: 1800, loss is 3.5566850185394285 and perplexity is 35.046824791143074
At time: 573.7024207115173 and batch: 1850, loss is 3.5743578243255616 and perplexity is 35.67170595692967
At time: 574.8696250915527 and batch: 1900, loss is 3.6543874168395996 and perplexity is 38.64384129654138
At time: 576.0368423461914 and batch: 1950, loss is 3.6047731542587282 and perplexity is 36.773341035206954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3687048623728195 and perplexity of 78.94132558251272
finished 12 epochs...
Completing Train Step...
At time: 579.7345614433289 and batch: 50, loss is 3.8291984272003172 and perplexity is 46.0256305505554
At time: 580.9001579284668 and batch: 100, loss is 3.815493149757385 and perplexity is 45.39913943799389
At time: 582.0657894611359 and batch: 150, loss is 3.784742350578308 and perplexity is 44.02432625518603
At time: 583.2314510345459 and batch: 200, loss is 3.7960177993774415 and perplexity is 44.52352937251881
At time: 584.3965294361115 and batch: 250, loss is 3.7782496976852418 and perplexity is 43.739417493656546
At time: 585.5627422332764 and batch: 300, loss is 3.7922269105911255 and perplexity is 44.35506514062474
At time: 586.7260749340057 and batch: 350, loss is 3.8175192499160766 and perplexity is 45.49121588817037
At time: 587.8959760665894 and batch: 400, loss is 3.793770179748535 and perplexity is 44.4235697915923
At time: 589.0610094070435 and batch: 450, loss is 3.8378415536880492 and perplexity is 46.42516000168353
At time: 590.226375579834 and batch: 500, loss is 3.8489069080352785 and perplexity is 46.941723556368345
At time: 591.3916277885437 and batch: 550, loss is 3.8034844303131106 and perplexity is 44.857214335270314
At time: 592.5822865962982 and batch: 600, loss is 3.760383715629578 and perplexity is 42.96490912329469
At time: 593.7466850280762 and batch: 650, loss is 3.780562844276428 and perplexity is 43.8407102855054
At time: 594.9116213321686 and batch: 700, loss is 3.815049843788147 and perplexity is 45.379018188747224
At time: 596.0776844024658 and batch: 750, loss is 3.7735424613952637 and perplexity is 43.53400955147464
At time: 597.2451250553131 and batch: 800, loss is 3.7414909172058106 and perplexity is 42.16080159454951
At time: 598.4113326072693 and batch: 850, loss is 3.7528695964813235 and perplexity is 42.64327558664417
At time: 599.5771405696869 and batch: 900, loss is 3.711539888381958 and perplexity is 40.91676529131385
At time: 600.7447726726532 and batch: 950, loss is 3.8289061546325684 and perplexity is 46.01218048697019
At time: 601.9113414287567 and batch: 1000, loss is 3.7941126871109008 and perplexity is 44.43878779729922
At time: 603.0764842033386 and batch: 1050, loss is 3.7310345935821534 and perplexity is 41.722251415863084
At time: 604.2419846057892 and batch: 1100, loss is 3.755336670875549 and perplexity is 42.748609599927505
At time: 605.4092059135437 and batch: 1150, loss is 3.715554633140564 and perplexity is 41.081365853840765
At time: 606.5756547451019 and batch: 1200, loss is 3.770565242767334 and perplexity is 43.4045920350045
At time: 607.7424521446228 and batch: 1250, loss is 3.730914077758789 and perplexity is 41.717223527357234
At time: 608.9052538871765 and batch: 1300, loss is 3.737696146965027 and perplexity is 42.00111421940898
At time: 610.0690929889679 and batch: 1350, loss is 3.6053215885162353 and perplexity is 36.79351432655004
At time: 611.2354745864868 and batch: 1400, loss is 3.6422539281845094 and perplexity is 38.177789819456564
At time: 612.3992643356323 and batch: 1450, loss is 3.5595952606201173 and perplexity is 35.14896809422227
At time: 613.5630049705505 and batch: 1500, loss is 3.565039792060852 and perplexity is 35.340859661938794
At time: 614.7276220321655 and batch: 1550, loss is 3.5771483421325683 and perplexity is 35.77138750449062
At time: 615.8919486999512 and batch: 1600, loss is 3.660811800956726 and perplexity is 38.892903355337374
At time: 617.0582747459412 and batch: 1650, loss is 3.603270649909973 and perplexity is 36.71813041786621
At time: 618.2227909564972 and batch: 1700, loss is 3.613881216049194 and perplexity is 37.10980483815807
At time: 619.3883748054504 and batch: 1750, loss is 3.614805746078491 and perplexity is 37.14412983191108
At time: 620.5511744022369 and batch: 1800, loss is 3.5573132705688475 and perplexity is 35.06884994789307
At time: 621.7165727615356 and batch: 1850, loss is 3.575322370529175 and perplexity is 35.706129564397955
At time: 622.8812222480774 and batch: 1900, loss is 3.6552521562576294 and perplexity is 38.67727260197513
At time: 624.0439686775208 and batch: 1950, loss is 3.6053641986846925 and perplexity is 36.79508213779574
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368904433139535 and perplexity of 78.95708153554625
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 627.7411987781525 and batch: 50, loss is 3.826911735534668 and perplexity is 45.9205043661624
At time: 628.9402487277985 and batch: 100, loss is 3.8185190868377688 and perplexity is 45.53672243119801
At time: 630.100346326828 and batch: 150, loss is 3.792090849876404 and perplexity is 44.34903056930354
At time: 631.2649621963501 and batch: 200, loss is 3.806197328567505 and perplexity is 44.9790726135548
At time: 632.4277384281158 and batch: 250, loss is 3.7915254831314087 and perplexity is 44.32396418876355
At time: 633.5934972763062 and batch: 300, loss is 3.8042831087112425 and perplexity is 44.893055134090964
At time: 634.7589282989502 and batch: 350, loss is 3.827666368484497 and perplexity is 45.95517057031471
At time: 635.9256155490875 and batch: 400, loss is 3.8085461711883544 and perplexity is 45.084845549716455
At time: 637.090674161911 and batch: 450, loss is 3.8553390884399414 and perplexity is 47.24463433481695
At time: 638.2571320533752 and batch: 500, loss is 3.8700993394851686 and perplexity is 47.94714888933383
At time: 639.4245822429657 and batch: 550, loss is 3.833620185852051 and perplexity is 46.22959538996472
At time: 640.5897316932678 and batch: 600, loss is 3.7940404653549193 and perplexity is 44.43557846590398
At time: 641.7539069652557 and batch: 650, loss is 3.8108426237106325 and perplexity is 45.18849972989401
At time: 642.9186265468597 and batch: 700, loss is 3.84616072177887 and perplexity is 46.812989684784434
At time: 644.0812788009644 and batch: 750, loss is 3.8003876781463624 and perplexity is 44.71851752524715
At time: 645.2460913658142 and batch: 800, loss is 3.7578333616256714 and perplexity is 42.85547300502298
At time: 646.4075577259064 and batch: 850, loss is 3.761893382072449 and perplexity is 43.02982078997329
At time: 647.5708410739899 and batch: 900, loss is 3.7148573541641237 and perplexity is 41.05273066562499
At time: 648.7338256835938 and batch: 950, loss is 3.835773949623108 and perplexity is 46.329270317259734
At time: 649.8973872661591 and batch: 1000, loss is 3.803933439254761 and perplexity is 44.87736014809095
At time: 651.1116745471954 and batch: 1050, loss is 3.7430626726150513 and perplexity is 42.22712016714841
At time: 652.2742052078247 and batch: 1100, loss is 3.764284062385559 and perplexity is 43.13281439875525
At time: 653.4384274482727 and batch: 1150, loss is 3.7241318368911744 and perplexity is 41.43524457454545
At time: 654.6023740768433 and batch: 1200, loss is 3.779553256034851 and perplexity is 43.79647155510738
At time: 655.7647953033447 and batch: 1250, loss is 3.7417859649658203 and perplexity is 42.17324287991663
At time: 656.9276196956635 and batch: 1300, loss is 3.745938458442688 and perplexity is 42.348731100554744
At time: 658.0919508934021 and batch: 1350, loss is 3.6102414608001707 and perplexity is 36.97497974522283
At time: 659.2557089328766 and batch: 1400, loss is 3.642124767303467 and perplexity is 38.17285906092464
At time: 660.4173426628113 and batch: 1450, loss is 3.5546489429473875 and perplexity is 34.975539402454025
At time: 661.5824642181396 and batch: 1500, loss is 3.5528139686584472 and perplexity is 34.91141903451379
At time: 662.7449617385864 and batch: 1550, loss is 3.5669512367248535 and perplexity is 35.40847636176372
At time: 663.9078273773193 and batch: 1600, loss is 3.652229404449463 and perplexity is 38.56053732605021
At time: 665.0731081962585 and batch: 1650, loss is 3.592638359069824 and perplexity is 36.32980065190473
At time: 666.2382469177246 and batch: 1700, loss is 3.601271505355835 and perplexity is 36.64479889198645
At time: 667.4007947444916 and batch: 1750, loss is 3.6029439878463747 and perplexity is 36.706137956460175
At time: 668.56445479393 and batch: 1800, loss is 3.546091675758362 and perplexity is 34.677521295565185
At time: 669.728422164917 and batch: 1850, loss is 3.565874056816101 and perplexity is 35.370355597573955
At time: 670.8937408924103 and batch: 1900, loss is 3.6467408084869386 and perplexity is 38.34947386744447
At time: 672.0579466819763 and batch: 1950, loss is 3.605077180862427 and perplexity is 36.78452280888075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36224847837936 and perplexity of 78.43329186675103
finished 14 epochs...
Completing Train Step...
At time: 675.7523667812347 and batch: 50, loss is 3.8348250579833985 and perplexity is 46.28532971071594
At time: 676.9172329902649 and batch: 100, loss is 3.8203725528717043 and perplexity is 45.62120146484622
At time: 678.0808346271515 and batch: 150, loss is 3.7896457624435427 and perplexity is 44.24072577330468
At time: 679.2431221008301 and batch: 200, loss is 3.7991697645187377 and perplexity is 44.66408738567842
At time: 680.4051513671875 and batch: 250, loss is 3.7841535711288454 and perplexity is 43.998413265876906
At time: 681.5943241119385 and batch: 300, loss is 3.794701323509216 and perplexity is 44.46495378566477
At time: 682.7565610408783 and batch: 350, loss is 3.8163113307952883 and perplexity is 45.436299352715004
At time: 683.918637752533 and batch: 400, loss is 3.7955842208862305 and perplexity is 44.50422911222131
At time: 685.0814442634583 and batch: 450, loss is 3.8411491298675537 and perplexity is 46.57896898227171
At time: 686.245546579361 and batch: 500, loss is 3.8557698631286623 and perplexity is 47.26499051161434
At time: 687.4082334041595 and batch: 550, loss is 3.81779634475708 and perplexity is 45.50382301600834
At time: 688.5725889205933 and batch: 600, loss is 3.779153308868408 and perplexity is 43.77895878273401
At time: 689.7360951900482 and batch: 650, loss is 3.796630439758301 and perplexity is 44.55081464168623
At time: 690.9020750522614 and batch: 700, loss is 3.8323380947113037 and perplexity is 46.170362814168925
At time: 692.0674047470093 and batch: 750, loss is 3.7879637908935546 and perplexity is 44.166376675264964
At time: 693.2349627017975 and batch: 800, loss is 3.747533497810364 and perplexity is 42.41633289325917
At time: 694.398921251297 and batch: 850, loss is 3.752958745956421 and perplexity is 42.64707738174067
At time: 695.5639355182648 and batch: 900, loss is 3.7070034170150756 and perplexity is 40.73156794597827
At time: 696.7280900478363 and batch: 950, loss is 3.8274149322509765 and perplexity is 45.943617227841045
At time: 697.8934741020203 and batch: 1000, loss is 3.7951785945892333 and perplexity is 44.48618068727116
At time: 699.0581073760986 and batch: 1050, loss is 3.733438935279846 and perplexity is 41.822686656598975
At time: 700.22460770607 and batch: 1100, loss is 3.754632968902588 and perplexity is 42.71853790100857
At time: 701.3897669315338 and batch: 1150, loss is 3.716963405609131 and perplexity is 41.13928093603506
At time: 702.5572662353516 and batch: 1200, loss is 3.7733558368682862 and perplexity is 43.52588579560429
At time: 703.7215354442596 and batch: 1250, loss is 3.7352637672424316 and perplexity is 41.89907570936565
At time: 704.8861339092255 and batch: 1300, loss is 3.7400151252746583 and perplexity is 42.098626913476195
At time: 706.0511183738708 and batch: 1350, loss is 3.6057838296890257 and perplexity is 36.81052573514725
At time: 707.2178246974945 and batch: 1400, loss is 3.6397325468063353 and perplexity is 38.081650304270404
At time: 708.3850991725922 and batch: 1450, loss is 3.5536399269104004 and perplexity is 34.940266320839854
At time: 709.5520780086517 and batch: 1500, loss is 3.553686680793762 and perplexity is 34.94189995216505
At time: 710.7210855484009 and batch: 1550, loss is 3.568591456413269 and perplexity is 35.466601697958176
At time: 711.888573884964 and batch: 1600, loss is 3.654361391067505 and perplexity is 38.64283557382234
At time: 713.057284116745 and batch: 1650, loss is 3.5954310512542724 and perplexity is 36.4314004046331
At time: 714.2222321033478 and batch: 1700, loss is 3.6051793336868285 and perplexity is 36.78828064371339
At time: 715.3879704475403 and batch: 1750, loss is 3.6087582111358643 and perplexity is 36.92017727185036
At time: 716.5524373054504 and batch: 1800, loss is 3.5518315076828 and perplexity is 34.877136770958494
At time: 717.7177112102509 and batch: 1850, loss is 3.571446304321289 and perplexity is 35.56799811843322
At time: 718.8816685676575 and batch: 1900, loss is 3.652550668716431 and perplexity is 38.57292743895185
At time: 720.0454018115997 and batch: 1950, loss is 3.6110256242752077 and perplexity is 37.0039855449873
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360975540515988 and perplexity of 78.33351467833846
finished 15 epochs...
Completing Train Step...
At time: 723.7041907310486 and batch: 50, loss is 3.83570188999176 and perplexity is 46.32593196740164
At time: 724.8928768634796 and batch: 100, loss is 3.819377970695496 and perplexity is 45.57584998763596
At time: 726.0575993061066 and batch: 150, loss is 3.787084445953369 and perplexity is 44.12755626617588
At time: 727.2239255905151 and batch: 200, loss is 3.7958795404434205 and perplexity is 44.51737402233479
At time: 728.3882412910461 and batch: 250, loss is 3.780213403701782 and perplexity is 43.825393238865
At time: 729.5562908649445 and batch: 300, loss is 3.7899340915679933 and perplexity is 44.25348350215597
At time: 730.7197804450989 and batch: 350, loss is 3.8110277795791627 and perplexity is 45.196867420448676
At time: 731.8863568305969 and batch: 400, loss is 3.79006142616272 and perplexity is 44.25911886032337
At time: 733.0508906841278 and batch: 450, loss is 3.8351790046691896 and perplexity is 46.301715149382595
At time: 734.2144157886505 and batch: 500, loss is 3.849762716293335 and perplexity is 46.981913866181834
At time: 735.3815343379974 and batch: 550, loss is 3.8115023469924925 and perplexity is 45.218321471205044
At time: 736.5454726219177 and batch: 600, loss is 3.7732446908950807 and perplexity is 43.52104833750487
At time: 737.7104153633118 and batch: 650, loss is 3.790856900215149 and perplexity is 44.29433984779368
At time: 738.8755609989166 and batch: 700, loss is 3.8267582273483276 and perplexity is 45.91345573384655
At time: 740.0665991306305 and batch: 750, loss is 3.782957000732422 and perplexity is 43.94579755255367
At time: 741.2308211326599 and batch: 800, loss is 3.743134069442749 and perplexity is 42.23013515720023
At time: 742.3953726291656 and batch: 850, loss is 3.748747444152832 and perplexity is 42.46785531183441
At time: 743.5577712059021 and batch: 900, loss is 3.703253207206726 and perplexity is 40.579102088525715
At time: 744.7232928276062 and batch: 950, loss is 3.823385491371155 and perplexity is 45.758862617285544
At time: 745.8891160488129 and batch: 1000, loss is 3.791340808868408 and perplexity is 44.31577944912237
At time: 747.0544586181641 and batch: 1050, loss is 3.729667043685913 and perplexity is 41.665233151815215
At time: 748.2200932502747 and batch: 1100, loss is 3.7513697242736814 and perplexity is 42.579364064288384
At time: 749.3904702663422 and batch: 1150, loss is 3.713912258148193 and perplexity is 41.01395022193783
At time: 750.5572710037231 and batch: 1200, loss is 3.7707579803466795 and perplexity is 43.412958537249594
At time: 751.7222542762756 and batch: 1250, loss is 3.732682523727417 and perplexity is 41.791063454843666
At time: 752.8863916397095 and batch: 1300, loss is 3.737732882499695 and perplexity is 42.002657181137074
At time: 754.0509366989136 and batch: 1350, loss is 3.6039877414703367 and perplexity is 36.74447012216232
At time: 755.214911699295 and batch: 1400, loss is 3.6387478494644165 and perplexity is 38.04416986091489
At time: 756.3772950172424 and batch: 1450, loss is 3.5531943035125733 and perplexity is 34.92469958934847
At time: 757.540497303009 and batch: 1500, loss is 3.5539752054214477 and perplexity is 34.95198300537402
At time: 758.7040860652924 and batch: 1550, loss is 3.569362802505493 and perplexity is 35.493969276162694
At time: 759.868812084198 and batch: 1600, loss is 3.6554040002822874 and perplexity is 38.68314596061573
At time: 761.0328507423401 and batch: 1650, loss is 3.5968627882003785 and perplexity is 36.483597944247265
At time: 762.1976380348206 and batch: 1700, loss is 3.6069130182266234 and perplexity is 36.85211523564484
At time: 763.3612730503082 and batch: 1750, loss is 3.610925416946411 and perplexity is 37.00027766022273
At time: 764.5269215106964 and batch: 1800, loss is 3.5539435148239136 and perplexity is 34.950875373698416
At time: 765.6924273967743 and batch: 1850, loss is 3.5736337327957153 and perplexity is 35.64588572602449
At time: 766.8637447357178 and batch: 1900, loss is 3.65461473941803 and perplexity is 38.652626912731996
At time: 768.0273995399475 and batch: 1950, loss is 3.612978973388672 and perplexity is 37.07633788903433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360555959302325 and perplexity of 78.30065430145973
finished 16 epochs...
Completing Train Step...
At time: 771.694388628006 and batch: 50, loss is 3.834670023918152 and perplexity is 46.27815446410781
At time: 772.8571772575378 and batch: 100, loss is 3.8174910736083985 and perplexity is 45.489934131732525
At time: 774.0228083133698 and batch: 150, loss is 3.7845140171051024 and perplexity is 44.01427517540928
At time: 775.186304807663 and batch: 200, loss is 3.7930613422393797 and perplexity is 44.392091856721926
At time: 776.3496840000153 and batch: 250, loss is 3.7770372343063356 and perplexity is 43.68641718868806
At time: 777.5132827758789 and batch: 300, loss is 3.786433081626892 and perplexity is 44.098822509297506
At time: 778.6766970157623 and batch: 350, loss is 3.8073148775100707 and perplexity is 45.02936702659127
At time: 779.8412570953369 and batch: 400, loss is 3.786316180229187 and perplexity is 44.093667596623135
At time: 781.0040771961212 and batch: 450, loss is 3.831260714530945 and perplexity is 46.12064656681174
At time: 782.168928861618 and batch: 500, loss is 3.8458188724517823 and perplexity is 46.796989430755595
At time: 783.3335430622101 and batch: 550, loss is 3.807536773681641 and perplexity is 45.03935997940068
At time: 784.5023512840271 and batch: 600, loss is 3.7695151472091677 and perplexity is 43.359036988466656
At time: 785.666097164154 and batch: 650, loss is 3.7872890281677245 and perplexity is 44.13658490286866
At time: 786.8317787647247 and batch: 700, loss is 3.823382143974304 and perplexity is 45.75870944446929
At time: 787.9954285621643 and batch: 750, loss is 3.7798317193984987 and perplexity is 43.80866896607974
At time: 789.1594169139862 and batch: 800, loss is 3.7402951431274416 and perplexity is 42.11041693122032
At time: 790.3254361152649 and batch: 850, loss is 3.745931406021118 and perplexity is 42.34843244050322
At time: 791.4902729988098 and batch: 900, loss is 3.7007057428359986 and perplexity is 40.47585983057911
At time: 792.654266834259 and batch: 950, loss is 3.8207108640670775 and perplexity is 45.6366382391177
At time: 793.8182051181793 and batch: 1000, loss is 3.7888506078720092 and perplexity is 44.205561540311166
At time: 794.9840867519379 and batch: 1050, loss is 3.727282552719116 and perplexity is 41.56600113567602
At time: 796.1494948863983 and batch: 1100, loss is 3.7492123508453368 and perplexity is 42.487603492160105
At time: 797.3148241043091 and batch: 1150, loss is 3.7118520402908324 and perplexity is 40.92953953135248
At time: 798.5201516151428 and batch: 1200, loss is 3.768973121643066 and perplexity is 43.33554165000965
At time: 799.6827795505524 and batch: 1250, loss is 3.730965714454651 and perplexity is 41.719377722558
At time: 800.8489243984222 and batch: 1300, loss is 3.736209468841553 and perplexity is 41.9387184744243
At time: 802.0144391059875 and batch: 1350, loss is 3.6027016639709473 and perplexity is 36.69724426047955
At time: 803.1795783042908 and batch: 1400, loss is 3.63791042804718 and perplexity is 38.012324194255086
At time: 804.3455972671509 and batch: 1450, loss is 3.552654995918274 and perplexity is 34.90586951168965
At time: 805.5123710632324 and batch: 1500, loss is 3.553854880332947 and perplexity is 34.947777657935085
At time: 806.6811401844025 and batch: 1550, loss is 3.569534034729004 and perplexity is 35.50004750782279
At time: 807.8471834659576 and batch: 1600, loss is 3.6557673358917238 and perplexity is 38.69720347867205
At time: 809.0147776603699 and batch: 1650, loss is 3.5974581480026244 and perplexity is 36.50532527905367
At time: 810.1826982498169 and batch: 1700, loss is 3.607619342803955 and perplexity is 36.87815398518427
At time: 811.3505234718323 and batch: 1750, loss is 3.6117519474029542 and perplexity is 37.03087215851005
At time: 812.5189881324768 and batch: 1800, loss is 3.554775137901306 and perplexity is 34.97995341754456
At time: 813.6873342990875 and batch: 1850, loss is 3.574606328010559 and perplexity is 35.68057160883807
At time: 814.8547868728638 and batch: 1900, loss is 3.6554303693771364 and perplexity is 38.684166013609506
At time: 816.0231411457062 and batch: 1950, loss is 3.61364058971405 and perplexity is 37.10087631608381
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36039670012718 and perplexity of 78.28818519677836
finished 17 epochs...
Completing Train Step...
At time: 819.7128865718842 and batch: 50, loss is 3.833133406639099 and perplexity is 46.20709726016092
At time: 820.9062895774841 and batch: 100, loss is 3.8154608678817747 and perplexity is 45.39767389227714
At time: 822.069589138031 and batch: 150, loss is 3.7821413183212282 and perplexity is 43.909966353870104
At time: 823.2346544265747 and batch: 200, loss is 3.790578556060791 and perplexity is 44.282012492929084
At time: 824.3973736763 and batch: 250, loss is 3.7743341875076295 and perplexity is 43.56849021143082
At time: 825.5587787628174 and batch: 300, loss is 3.7835556745529173 and perplexity is 43.97211462795519
At time: 826.7216846942902 and batch: 350, loss is 3.8043084383010863 and perplexity is 44.89419227116589
At time: 827.886461019516 and batch: 400, loss is 3.783323202133179 and perplexity is 43.9618935121764
At time: 829.0936901569366 and batch: 450, loss is 3.828182244300842 and perplexity is 45.97888384747517
At time: 830.255865573883 and batch: 500, loss is 3.8427341985702514 and perplexity is 46.65285839263511
At time: 831.4181191921234 and batch: 550, loss is 3.804488487243652 and perplexity is 44.90227615073681
At time: 832.5818777084351 and batch: 600, loss is 3.7666377639770507 and perplexity is 43.234455742423634
At time: 833.7438583374023 and batch: 650, loss is 3.7845722007751466 and perplexity is 44.0168361619764
At time: 834.9075281620026 and batch: 700, loss is 3.8208363342285154 and perplexity is 45.64236463472342
At time: 836.0705714225769 and batch: 750, loss is 3.777413077354431 and perplexity is 43.70283951079911
At time: 837.2327346801758 and batch: 800, loss is 3.738059320449829 and perplexity is 42.016370680629024
At time: 838.3962800502777 and batch: 850, loss is 3.7436950540542604 and perplexity is 42.25383225939884
At time: 839.558456659317 and batch: 900, loss is 3.698647003173828 and perplexity is 40.39261629037604
At time: 840.7206649780273 and batch: 950, loss is 3.818572678565979 and perplexity is 45.5391628882437
At time: 841.8840918540955 and batch: 1000, loss is 3.7868504905700684 and perplexity is 44.11723359440491
At time: 843.0485072135925 and batch: 1050, loss is 3.7253778886795046 and perplexity is 41.48690721562613
At time: 844.209139585495 and batch: 1100, loss is 3.7474431562423707 and perplexity is 42.412501108324406
At time: 845.3714644908905 and batch: 1150, loss is 3.7101452779769897 and perplexity is 40.85974211649962
At time: 846.5325980186462 and batch: 1200, loss is 3.7674722719192504 and perplexity is 43.27055029761916
At time: 847.6944708824158 and batch: 1250, loss is 3.7295328903198244 and perplexity is 41.65964399544948
At time: 848.8555681705475 and batch: 1300, loss is 3.7349285364151 and perplexity is 41.885032201591045
At time: 850.0194594860077 and batch: 1350, loss is 3.6015707063674927 and perplexity is 36.65576469329453
At time: 851.1819384098053 and batch: 1400, loss is 3.637079510688782 and perplexity is 37.980752212919185
At time: 852.3439056873322 and batch: 1450, loss is 3.5520296907424926 and perplexity is 34.884049513608694
At time: 853.5064191818237 and batch: 1500, loss is 3.553507695198059 and perplexity is 34.935646415050336
At time: 854.6694695949554 and batch: 1550, loss is 3.5693721771240234 and perplexity is 35.49430202014446
At time: 855.8311758041382 and batch: 1600, loss is 3.6557579469680785 and perplexity is 38.69684015528892
At time: 856.9933795928955 and batch: 1650, loss is 3.5976056241989136 and perplexity is 36.51070934257097
At time: 858.1558201313019 and batch: 1700, loss is 3.607840280532837 and perplexity is 36.88630266091291
At time: 859.3162572383881 and batch: 1750, loss is 3.6120101499557493 and perplexity is 37.04043485873728
At time: 860.4784018993378 and batch: 1800, loss is 3.55507954120636 and perplexity is 34.99060305178517
At time: 861.6393821239471 and batch: 1850, loss is 3.575050401687622 and perplexity is 35.69641993012283
At time: 862.8020148277283 and batch: 1900, loss is 3.6557250881195067 and perplexity is 38.69556864256838
At time: 863.9636979103088 and batch: 1950, loss is 3.6137973928451537 and perplexity is 37.10669430578444
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360355252997819 and perplexity of 78.28494044348243
finished 18 epochs...
Completing Train Step...
At time: 867.6262912750244 and batch: 50, loss is 3.8314682960510256 and perplexity is 46.130221354473285
At time: 868.787947177887 and batch: 100, loss is 3.8134706258773803 and perplexity is 45.30741138670456
At time: 869.9560482501984 and batch: 150, loss is 3.7799557638168335 and perplexity is 43.81410352399598
At time: 871.1191356182098 and batch: 200, loss is 3.7883317708969115 and perplexity is 44.18263200933771
At time: 872.283255815506 and batch: 250, loss is 3.7719382429122925 and perplexity is 43.464227476526965
At time: 873.4474241733551 and batch: 300, loss is 3.7810434341430663 and perplexity is 43.86178475029632
At time: 874.6120989322662 and batch: 350, loss is 3.8016961717605593 and perplexity is 44.77706971909696
At time: 875.7775468826294 and batch: 400, loss is 3.7807351398468017 and perplexity is 43.84826449644948
At time: 876.94349360466 and batch: 450, loss is 3.825543885231018 and perplexity is 45.85773492970463
At time: 878.1095416545868 and batch: 500, loss is 3.840101318359375 and perplexity is 46.53018856333819
At time: 879.2745282649994 and batch: 550, loss is 3.8019075775146485 and perplexity is 44.78653684995454
At time: 880.4412589073181 and batch: 600, loss is 3.7641922521591185 and perplexity is 43.12885454707851
At time: 881.6069922447205 and batch: 650, loss is 3.7822683954238894 and perplexity is 43.91554665972934
At time: 882.7733750343323 and batch: 700, loss is 3.8186797189712522 and perplexity is 45.544037679590225
At time: 883.9407258033752 and batch: 750, loss is 3.7753323459625245 and perplexity is 43.612000179611194
At time: 885.1109471321106 and batch: 800, loss is 3.736117010116577 and perplexity is 41.93484105324051
At time: 886.2776277065277 and batch: 850, loss is 3.7417487001419065 and perplexity is 42.17167133072877
At time: 887.4875054359436 and batch: 900, loss is 3.696828727722168 and perplexity is 40.31923811882738
At time: 888.6524441242218 and batch: 950, loss is 3.8166917848587034 and perplexity is 45.45358906619261
At time: 889.8174533843994 and batch: 1000, loss is 3.7850891733169556 and perplexity is 44.039597540646405
At time: 890.9803278446198 and batch: 1050, loss is 3.723700108528137 and perplexity is 41.41735966522234
At time: 892.1450643539429 and batch: 1100, loss is 3.745860447883606 and perplexity is 42.34542758122156
At time: 893.3105182647705 and batch: 1150, loss is 3.7086123704910277 and perplexity is 40.79715589363498
At time: 894.4743642807007 and batch: 1200, loss is 3.7661110973358154 and perplexity is 43.21169159191767
At time: 895.6418416500092 and batch: 1250, loss is 3.7282342672348023 and perplexity is 41.605578932710515
At time: 896.8092658519745 and batch: 1300, loss is 3.7337555408477785 and perplexity is 41.83593004841552
At time: 897.9723353385925 and batch: 1350, loss is 3.6005069065093993 and perplexity is 36.616791029779804
At time: 899.136536359787 and batch: 1400, loss is 3.6362389516830445 and perplexity is 37.948840563293075
At time: 900.3014674186707 and batch: 1450, loss is 3.5513473033905028 and perplexity is 34.8602531995097
At time: 901.4659893512726 and batch: 1500, loss is 3.5530268239974974 and perplexity is 34.91885090737795
At time: 902.6305692195892 and batch: 1550, loss is 3.5690179014205934 and perplexity is 35.481729478533026
At time: 903.7942562103271 and batch: 1600, loss is 3.6555308628082277 and perplexity is 38.688053713522
At time: 904.9631707668304 and batch: 1650, loss is 3.5974953317642213 and perplexity is 36.50668270960289
At time: 906.1323778629303 and batch: 1700, loss is 3.6078007221221924 and perplexity is 36.88484352626581
At time: 907.301539182663 and batch: 1750, loss is 3.611982283592224 and perplexity is 37.03940269089583
At time: 908.4666090011597 and batch: 1800, loss is 3.5551195621490477 and perplexity is 34.9920034367267
At time: 909.631175994873 and batch: 1850, loss is 3.575217490196228 and perplexity is 35.70238489001577
At time: 910.7946534156799 and batch: 1900, loss is 3.6557612514495847 and perplexity is 38.69696802849283
At time: 911.9590616226196 and batch: 1950, loss is 3.6137205839157103 and perplexity is 37.103844289774365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36038818359375 and perplexity of 78.28751845567115
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 915.6165502071381 and batch: 50, loss is 3.8310658597946166 and perplexity is 46.11166061589165
At time: 916.804435968399 and batch: 100, loss is 3.8147485065460205 and perplexity is 45.365345860650095
At time: 917.9651834964752 and batch: 150, loss is 3.782338066101074 and perplexity is 43.918606392189645
At time: 919.1305954456329 and batch: 200, loss is 3.7912484121322634 and perplexity is 44.31168500490111
At time: 920.2939274311066 and batch: 250, loss is 3.7757383251190184 and perplexity is 43.62970933718832
At time: 921.4567923545837 and batch: 300, loss is 3.7840766859054566 and perplexity is 43.99503056808562
At time: 922.6196329593658 and batch: 350, loss is 3.8039011192321777 and perplexity is 44.87590973423632
At time: 923.7875573635101 and batch: 400, loss is 3.783927435874939 and perplexity is 43.98846479841355
At time: 924.9524550437927 and batch: 450, loss is 3.8283039951324462 and perplexity is 45.98448215561224
At time: 926.1155736446381 and batch: 500, loss is 3.843722314834595 and perplexity is 46.698979623607585
At time: 927.2787585258484 and batch: 550, loss is 3.8068173360824584 and perplexity is 45.00696862356514
At time: 928.4453127384186 and batch: 600, loss is 3.770441174507141 and perplexity is 43.3992072368345
At time: 929.6087512969971 and batch: 650, loss is 3.788477592468262 and perplexity is 44.189075259934754
At time: 930.7725410461426 and batch: 700, loss is 3.8260007953643798 and perplexity is 45.878692581004046
At time: 931.9358546733856 and batch: 750, loss is 3.783139090538025 and perplexity is 43.95380036288006
At time: 933.0977220535278 and batch: 800, loss is 3.7418630361557006 and perplexity is 42.17649334718358
At time: 934.261310338974 and batch: 850, loss is 3.7461447525024414 and perplexity is 42.357468293403386
At time: 935.4246118068695 and batch: 900, loss is 3.6981820631027222 and perplexity is 40.37384050963048
At time: 936.5907189846039 and batch: 950, loss is 3.8170041847229004 and perplexity is 45.46779097946655
At time: 937.7542893886566 and batch: 1000, loss is 3.7851036834716796 and perplexity is 44.04023656665688
At time: 938.9171302318573 and batch: 1050, loss is 3.7256817388534547 and perplexity is 41.4995149349321
At time: 940.0781335830688 and batch: 1100, loss is 3.748002915382385 and perplexity is 42.436248539271354
At time: 941.2430076599121 and batch: 1150, loss is 3.7091884136199953 and perplexity is 40.82066358504095
At time: 942.4062395095825 and batch: 1200, loss is 3.7676925039291382 and perplexity is 43.2800809073143
At time: 943.5695333480835 and batch: 1250, loss is 3.730724925994873 and perplexity is 41.70933338718185
At time: 944.7321906089783 and batch: 1300, loss is 3.736094059944153 and perplexity is 41.933878652451426
At time: 945.8960900306702 and batch: 1350, loss is 3.600905890464783 and perplexity is 36.631403456766435
At time: 947.0604336261749 and batch: 1400, loss is 3.6342335605621336 and perplexity is 37.872814551801596
At time: 948.2236292362213 and batch: 1450, loss is 3.5472532987594603 and perplexity is 34.717826907353796
At time: 949.3856573104858 and batch: 1500, loss is 3.5462787437438963 and perplexity is 34.68400895641518
At time: 950.5490877628326 and batch: 1550, loss is 3.5629706048965453 and perplexity is 35.267808413168176
At time: 951.712904214859 and batch: 1600, loss is 3.649678921699524 and perplexity is 38.46231465163467
At time: 952.8775105476379 and batch: 1650, loss is 3.5914462661743163 and perplexity is 36.28651795827387
At time: 954.0390648841858 and batch: 1700, loss is 3.6012033319473264 and perplexity is 36.642300776295365
At time: 955.2021532058716 and batch: 1750, loss is 3.604074087142944 and perplexity is 36.74764298512915
At time: 956.3690457344055 and batch: 1800, loss is 3.547808904647827 and perplexity is 34.73712169606758
At time: 957.5427854061127 and batch: 1850, loss is 3.5692870473861693 and perplexity is 35.49128052812941
At time: 958.7039017677307 and batch: 1900, loss is 3.649315767288208 and perplexity is 38.44834942831922
At time: 959.8661308288574 and batch: 1950, loss is 3.6099392890930178 and perplexity is 36.96380864035219
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3598888308502906 and perplexity of 78.24843512754734
Finished Training.
Improved accuracyfrom -10000000 to -78.24843512754734
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f6867fdeb38>
ELAPSED
993.5367493629456


RESULTS SO FAR:
[{'best_accuracy': -78.24843512754734, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.862353544247577, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.936075502546612}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6962976455688477 and batch: 50, loss is 8.609925174713135 and perplexity is 5485.83818302726
At time: 2.9253671169281006 and batch: 100, loss is 7.612334337234497 and perplexity is 2022.9949426413598
At time: 4.157649993896484 and batch: 150, loss is 7.353178644180298 and perplexity is 1561.1509929430338
At time: 5.381725072860718 and batch: 200, loss is 7.258616828918457 and perplexity is 1420.2906729650872
At time: 6.605955123901367 and batch: 250, loss is 7.155793657302857 and perplexity is 1281.5091134180286
At time: 7.830807447433472 and batch: 300, loss is 7.03010368347168 and perplexity is 1130.1477817574116
At time: 9.056068181991577 and batch: 350, loss is 6.977891960144043 and perplexity is 1072.6547829371998
At time: 10.279996156692505 and batch: 400, loss is 6.931369047164917 and perplexity is 1023.8947807692098
At time: 11.530713558197021 and batch: 450, loss is 6.836431226730347 and perplexity is 931.1600987050513
At time: 12.755525588989258 and batch: 500, loss is 6.813572797775269 and perplexity is 910.1166678987307
At time: 13.980298280715942 and batch: 550, loss is 6.762314338684082 and perplexity is 864.6409540030609
At time: 15.205808639526367 and batch: 600, loss is 6.812052431106568 and perplexity is 908.7340081934299
At time: 16.430530071258545 and batch: 650, loss is 6.891009101867676 and perplexity is 983.393260674558
At time: 17.655334949493408 and batch: 700, loss is 6.761018705368042 and perplexity is 863.5214217848726
At time: 18.879350662231445 and batch: 750, loss is 6.704991884231568 and perplexity is 816.4713999927916
At time: 20.104148626327515 and batch: 800, loss is 6.699434518814087 and perplexity is 811.9465548246922
At time: 21.328757524490356 and batch: 850, loss is 6.747469463348389 and perplexity is 851.9002677518662
At time: 22.55402684211731 and batch: 900, loss is 6.719783811569214 and perplexity is 828.6383500912624
At time: 23.779590845108032 and batch: 950, loss is 6.741414165496826 and perplexity is 846.7573445711091
At time: 25.005170106887817 and batch: 1000, loss is 6.72942232131958 and perplexity is 836.6638034826557
At time: 26.229713439941406 and batch: 1050, loss is 6.6257113838195805 and perplexity is 754.2405762937453
At time: 27.452021598815918 and batch: 1100, loss is 6.705491504669189 and perplexity is 816.8794277119678
At time: 28.67668104171753 and batch: 1150, loss is 6.609989881515503 and perplexity is 742.4755059517177
At time: 29.902409076690674 and batch: 1200, loss is 6.70434193611145 and perplexity is 815.9409083559323
At time: 31.128963232040405 and batch: 1250, loss is 6.6202340412139895 and perplexity is 750.1206357136684
At time: 32.35395646095276 and batch: 1300, loss is 6.629943952560425 and perplexity is 757.4397168953444
At time: 33.57959222793579 and batch: 1350, loss is 6.655515441894531 and perplexity is 777.0583483070928
At time: 34.80448770523071 and batch: 1400, loss is 6.677940893173218 and perplexity is 794.6810929029812
At time: 36.02987337112427 and batch: 1450, loss is 6.679229965209961 and perplexity is 795.7061546252262
At time: 37.25532555580139 and batch: 1500, loss is 6.663439645767212 and perplexity is 783.2403785651139
At time: 38.480363845825195 and batch: 1550, loss is 6.635314388275146 and perplexity is 761.5184406615347
At time: 39.70630717277527 and batch: 1600, loss is 6.608607807159424 and perplexity is 741.4500583805489
At time: 40.93179440498352 and batch: 1650, loss is 6.605064468383789 and perplexity is 738.827498691119
At time: 42.15591835975647 and batch: 1700, loss is 6.635939559936523 and perplexity is 761.9946692570527
At time: 43.380290508270264 and batch: 1750, loss is 6.650367317199707 and perplexity is 773.0682346487406
At time: 44.60514998435974 and batch: 1800, loss is 6.654280805587769 and perplexity is 776.0995558595763
At time: 45.83068299293518 and batch: 1850, loss is 6.599588775634766 and perplexity is 734.7929623351832
At time: 47.056225061416626 and batch: 1900, loss is 6.530078535079956 and perplexity is 685.452041408891
At time: 48.28121566772461 and batch: 1950, loss is 6.4914023876190186 and perplexity is 659.4475160854395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.958939521257268 and perplexity of 387.1992898196475
finished 1 epochs...
Completing Train Step...
At time: 51.934077501297 and batch: 50, loss is 6.185699853897095 and perplexity is 485.752800667483
At time: 53.114825963974 and batch: 100, loss is 5.934022464752197 and perplexity is 377.67062931428103
At time: 54.273215770721436 and batch: 150, loss is 5.736037311553955 and perplexity is 309.8341987178071
At time: 55.43095278739929 and batch: 200, loss is 5.649613513946533 and perplexity is 284.1816123670421
At time: 56.58913588523865 and batch: 250, loss is 5.598334197998047 and perplexity is 269.9763055696501
At time: 57.74822187423706 and batch: 300, loss is 5.564194622039795 and perplexity is 260.9149838904142
At time: 58.90718102455139 and batch: 350, loss is 5.496890134811402 and perplexity is 243.93215535635278
At time: 60.06561827659607 and batch: 400, loss is 5.444483795166016 and perplexity is 231.47775892805674
At time: 61.22841167449951 and batch: 450, loss is 5.36316068649292 and perplexity is 213.3983669894802
At time: 62.38561010360718 and batch: 500, loss is 5.339499855041504 and perplexity is 208.4084497831195
At time: 63.542444944381714 and batch: 550, loss is 5.285138759613037 and perplexity is 197.3815701383231
At time: 64.6991171836853 and batch: 600, loss is 5.295001077651977 and perplexity is 199.3378407832733
At time: 65.85473704338074 and batch: 650, loss is 5.357010345458985 and perplexity is 212.0899220721525
At time: 67.0117506980896 and batch: 700, loss is 5.287686548233032 and perplexity is 197.88509782519748
At time: 68.16918063163757 and batch: 750, loss is 5.221882972717285 and perplexity is 185.2827381497069
At time: 69.32531499862671 and batch: 800, loss is 5.204573097229004 and perplexity is 182.10311584787678
At time: 70.48156428337097 and batch: 850, loss is 5.202223081588745 and perplexity is 181.67567312275423
At time: 71.6372742652893 and batch: 900, loss is 5.223404722213745 and perplexity is 185.56490670366438
At time: 72.79309844970703 and batch: 950, loss is 5.252311420440674 and perplexity is 191.00725668511097
At time: 73.95022678375244 and batch: 1000, loss is 5.211641502380371 and perplexity is 183.39485433732585
At time: 75.1066346168518 and batch: 1050, loss is 5.117971134185791 and perplexity is 166.99621277837292
At time: 76.2625720500946 and batch: 1100, loss is 5.200018157958985 and perplexity is 181.27553343896815
At time: 77.41966247558594 and batch: 1150, loss is 5.098268156051636 and perplexity is 163.7380927845074
At time: 78.57707929611206 and batch: 1200, loss is 5.168640813827515 and perplexity is 175.67589888722475
At time: 79.75580048561096 and batch: 1250, loss is 5.095533847808838 and perplexity is 163.2909938993892
At time: 80.91188192367554 and batch: 1300, loss is 5.133724136352539 and perplexity is 169.64773436012686
At time: 82.06823205947876 and batch: 1350, loss is 5.07170991897583 and perplexity is 159.4467353775471
At time: 83.22457575798035 and batch: 1400, loss is 5.078352575302124 and perplexity is 160.5094108293832
At time: 84.38121366500854 and batch: 1450, loss is 5.0212313842773435 and perplexity is 151.5978641331174
At time: 85.53751754760742 and batch: 1500, loss is 4.984504318237304 and perplexity is 146.13112253854766
At time: 86.69406867027283 and batch: 1550, loss is 4.975928392410278 and perplexity is 144.88327125856267
At time: 87.85153698921204 and batch: 1600, loss is 5.036200637817383 and perplexity is 153.88424098097474
At time: 89.0089898109436 and batch: 1650, loss is 4.997148723602295 and perplexity is 147.99059487490237
At time: 90.16923427581787 and batch: 1700, loss is 5.0138743877410885 and perplexity is 150.48665177657855
At time: 91.32968592643738 and batch: 1750, loss is 5.024614572525024 and perplexity is 152.11161681641354
At time: 92.49121952056885 and batch: 1800, loss is 4.982119121551514 and perplexity is 145.782986420985
At time: 93.65273833274841 and batch: 1850, loss is 4.969143209457397 and perplexity is 143.9035393451963
At time: 94.8158450126648 and batch: 1900, loss is 5.032133388519287 and perplexity is 153.25962650231452
At time: 95.97496724128723 and batch: 1950, loss is 4.944330396652222 and perplexity is 140.3768225837855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.75032107331032 and perplexity of 115.62140151435989
finished 2 epochs...
Completing Train Step...
At time: 99.61478090286255 and batch: 50, loss is 4.92927095413208 and perplexity is 138.27866409424962
At time: 100.80076766014099 and batch: 100, loss is 4.874229316711426 and perplexity is 130.87325250594157
At time: 101.96121311187744 and batch: 150, loss is 4.813567981719971 and perplexity is 123.17030383201417
At time: 103.12084913253784 and batch: 200, loss is 4.802600507736206 and perplexity is 121.82681752154122
At time: 104.28063082695007 and batch: 250, loss is 4.806252508163452 and perplexity is 122.27254250971353
At time: 105.43987202644348 and batch: 300, loss is 4.831426830291748 and perplexity is 125.38974296196095
At time: 106.59870505332947 and batch: 350, loss is 4.827677459716797 and perplexity is 124.92049059951906
At time: 107.7822117805481 and batch: 400, loss is 4.792662239074707 and perplexity is 120.62206636517553
At time: 108.94164204597473 and batch: 450, loss is 4.775180549621582 and perplexity is 118.5317135449073
At time: 110.09980583190918 and batch: 500, loss is 4.776168384552002 and perplexity is 118.64886116363819
At time: 111.25719547271729 and batch: 550, loss is 4.737519435882568 and perplexity is 114.15069208290507
At time: 112.41552472114563 and batch: 600, loss is 4.723479747772217 and perplexity is 112.55924978628242
At time: 113.57585644721985 and batch: 650, loss is 4.779918346405029 and perplexity is 119.09462514349804
At time: 114.73453974723816 and batch: 700, loss is 4.786471185684204 and perplexity is 119.8775956192128
At time: 115.89243125915527 and batch: 750, loss is 4.741393814086914 and perplexity is 114.59381289082219
At time: 117.05091190338135 and batch: 800, loss is 4.720263614654541 and perplexity is 112.19782576076574
At time: 118.21100187301636 and batch: 850, loss is 4.720399522781372 and perplexity is 112.21307539335051
At time: 119.37000703811646 and batch: 900, loss is 4.71981065750122 and perplexity is 112.147016461087
At time: 120.52919054031372 and batch: 950, loss is 4.778870897293091 and perplexity is 118.96994489366271
At time: 121.69682383537292 and batch: 1000, loss is 4.757257881164551 and perplexity is 116.42623321460592
At time: 122.8605465888977 and batch: 1050, loss is 4.677460517883301 and perplexity is 107.49673960836877
At time: 124.02471923828125 and batch: 1100, loss is 4.747015399932861 and perplexity is 115.23982595506475
At time: 125.18536639213562 and batch: 1150, loss is 4.667978191375733 and perplexity is 106.48223794443726
At time: 126.34644746780396 and batch: 1200, loss is 4.745457143783569 and perplexity is 115.06039262547928
At time: 127.50496673583984 and batch: 1250, loss is 4.699667005538941 and perplexity is 109.91056674777445
At time: 128.6651463508606 and batch: 1300, loss is 4.733816757202148 and perplexity is 113.72881027735191
At time: 129.82480382919312 and batch: 1350, loss is 4.6330798244476314 and perplexity is 102.83027612015843
At time: 130.98639678955078 and batch: 1400, loss is 4.640024442672729 and perplexity is 103.5468785148132
At time: 132.14949488639832 and batch: 1450, loss is 4.583627490997315 and perplexity is 97.8687691515166
At time: 133.30895686149597 and batch: 1500, loss is 4.571300601959228 and perplexity is 96.66975692191959
At time: 134.47230291366577 and batch: 1550, loss is 4.565039463043213 and perplexity is 96.06638501362912
At time: 135.6333179473877 and batch: 1600, loss is 4.643966207504272 and perplexity is 103.95584144728929
At time: 136.79621767997742 and batch: 1650, loss is 4.605066423416138 and perplexity is 99.98962428111957
At time: 137.95725202560425 and batch: 1700, loss is 4.6341214275360105 and perplexity is 102.93744025490206
At time: 139.11850452423096 and batch: 1750, loss is 4.632511825561523 and perplexity is 102.77188522241626
At time: 140.2782440185547 and batch: 1800, loss is 4.5878807544708256 and perplexity is 98.28591730418727
At time: 141.438871383667 and batch: 1850, loss is 4.6123292446136475 and perplexity is 100.71847459481867
At time: 142.60356950759888 and batch: 1900, loss is 4.687675056457519 and perplexity is 108.6003962775275
At time: 143.76464080810547 and batch: 1950, loss is 4.608574981689453 and perplexity is 100.34105986022742
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5795543581940406 and perplexity of 97.4709473978888
finished 3 epochs...
Completing Train Step...
At time: 147.43356847763062 and batch: 50, loss is 4.599658823013305 and perplexity is 99.45037967231482
At time: 148.5960612297058 and batch: 100, loss is 4.539413681030274 and perplexity is 93.63588352696827
At time: 149.75946354866028 and batch: 150, loss is 4.491083517074585 and perplexity is 89.21806282058056
At time: 150.92291140556335 and batch: 200, loss is 4.489487934112549 and perplexity is 89.07582150872253
At time: 152.08517909049988 and batch: 250, loss is 4.494010133743286 and perplexity is 89.47955234353883
At time: 153.2486457824707 and batch: 300, loss is 4.515825786590576 and perplexity is 91.45305555592147
At time: 154.4116883277893 and batch: 350, loss is 4.525152406692505 and perplexity is 92.30999341741519
At time: 155.57479572296143 and batch: 400, loss is 4.491765422821045 and perplexity is 89.27892187801818
At time: 156.7370467185974 and batch: 450, loss is 4.497291259765625 and perplexity is 89.77362821737168
At time: 157.89990997314453 and batch: 500, loss is 4.504818534851074 and perplexity is 90.45192868679631
At time: 159.06246185302734 and batch: 550, loss is 4.464104280471802 and perplexity is 86.84320753473051
At time: 160.2270209789276 and batch: 600, loss is 4.45138783454895 and perplexity is 85.74586253394403
At time: 161.39028692245483 and batch: 650, loss is 4.5012475109100345 and perplexity is 90.12949872913282
At time: 162.55167746543884 and batch: 700, loss is 4.529412937164307 and perplexity is 92.70412195936444
At time: 163.7150535583496 and batch: 750, loss is 4.48325135231018 and perplexity is 88.52202156559466
At time: 164.87622165679932 and batch: 800, loss is 4.455075387954712 and perplexity is 86.06263868689044
At time: 166.06378722190857 and batch: 850, loss is 4.457420978546143 and perplexity is 86.26474333718973
At time: 167.22772121429443 and batch: 900, loss is 4.4503679370880125 and perplexity is 85.65845512733247
At time: 168.39285469055176 and batch: 950, loss is 4.526120109558105 and perplexity is 92.39936529830706
At time: 169.55795669555664 and batch: 1000, loss is 4.501327590942383 and perplexity is 90.13671659130605
At time: 170.72068738937378 and batch: 1050, loss is 4.436215906143189 and perplexity is 84.45475153467439
At time: 171.88512325286865 and batch: 1100, loss is 4.497114124298096 and perplexity is 89.7577275320949
At time: 173.04946303367615 and batch: 1150, loss is 4.431200323104858 and perplexity is 84.03222221657568
At time: 174.21703243255615 and batch: 1200, loss is 4.514278602600098 and perplexity is 91.31167025522562
At time: 175.38552713394165 and batch: 1250, loss is 4.47149130821228 and perplexity is 87.48709600085976
At time: 176.5529589653015 and batch: 1300, loss is 4.4932515335083005 and perplexity is 89.41169887418751
At time: 177.72647857666016 and batch: 1350, loss is 4.383986740112305 and perplexity is 80.15696221606629
At time: 178.8933229446411 and batch: 1400, loss is 4.401781330108642 and perplexity is 81.59608885384321
At time: 180.06050395965576 and batch: 1450, loss is 4.336267452239991 and perplexity is 76.42175846133813
At time: 181.22909140586853 and batch: 1500, loss is 4.333879146575928 and perplexity is 76.23945772434232
At time: 182.39518404006958 and batch: 1550, loss is 4.33056074142456 and perplexity is 75.98688361847424
At time: 183.56185817718506 and batch: 1600, loss is 4.419546461105346 and perplexity is 83.05860650599091
At time: 184.7291715145111 and batch: 1650, loss is 4.37201979637146 and perplexity is 79.20344508097129
At time: 185.89654731750488 and batch: 1700, loss is 4.405429649353027 and perplexity is 81.89432112755193
At time: 187.06404662132263 and batch: 1750, loss is 4.404393367767334 and perplexity is 81.80949950772663
At time: 188.23238801956177 and batch: 1800, loss is 4.3568059349060055 and perplexity is 78.0075748086624
At time: 189.3997461795807 and batch: 1850, loss is 4.3915737438201905 and perplexity is 80.7674262537479
At time: 190.56815266609192 and batch: 1900, loss is 4.470640783309936 and perplexity is 87.41271768186728
At time: 191.735497713089 and batch: 1950, loss is 4.396155920028686 and perplexity is 81.13836603944846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.500500772165697 and perplexity of 90.06222066311965
finished 4 epochs...
Completing Train Step...
At time: 195.4037446975708 and batch: 50, loss is 4.378674612045288 and perplexity is 79.73228713018102
At time: 196.56294178962708 and batch: 100, loss is 4.326627225875854 and perplexity is 75.68857511546325
At time: 197.72567915916443 and batch: 150, loss is 4.278763227462768 and perplexity is 72.1511502419931
At time: 198.88800191879272 and batch: 200, loss is 4.286349649429321 and perplexity is 72.70060085997494
At time: 200.05339765548706 and batch: 250, loss is 4.282793321609497 and perplexity is 72.44251288535395
At time: 201.20898818969727 and batch: 300, loss is 4.302341508865356 and perplexity is 73.87256461329432
At time: 202.36966848373413 and batch: 350, loss is 4.309421911239624 and perplexity is 74.39746816648312
At time: 203.53047633171082 and batch: 400, loss is 4.289929962158203 and perplexity is 72.96135826461253
At time: 204.69214630126953 and batch: 450, loss is 4.301269388198852 and perplexity is 73.79340675105705
At time: 205.8531572818756 and batch: 500, loss is 4.31745512008667 and perplexity is 74.99752553209782
At time: 207.01569533348083 and batch: 550, loss is 4.275781621932984 and perplexity is 71.93634436578023
At time: 208.17780590057373 and batch: 600, loss is 4.260859603881836 and perplexity is 70.87087815983956
At time: 209.3381793498993 and batch: 650, loss is 4.307433528900146 and perplexity is 74.2496845285575
At time: 210.50430369377136 and batch: 700, loss is 4.337619519233703 and perplexity is 76.52515568278879
At time: 211.66577649116516 and batch: 750, loss is 4.296031947135925 and perplexity is 73.40792847340994
At time: 212.82652163505554 and batch: 800, loss is 4.267068543434143 and perplexity is 71.31228005917163
At time: 213.98778009414673 and batch: 850, loss is 4.269364328384399 and perplexity is 71.47618579266752
At time: 215.14966773986816 and batch: 900, loss is 4.255768189430237 and perplexity is 70.51096216482145
At time: 216.31207942962646 and batch: 950, loss is 4.3405793762207034 and perplexity is 76.75199473949449
At time: 217.47322058677673 and batch: 1000, loss is 4.317732973098755 and perplexity is 75.01836671572455
At time: 218.6357843875885 and batch: 1050, loss is 4.257193698883056 and perplexity is 70.61154788382828
At time: 219.79720830917358 and batch: 1100, loss is 4.313200159072876 and perplexity is 74.67909192654467
At time: 220.95967602729797 and batch: 1150, loss is 4.254583768844604 and perplexity is 70.42749696842652
At time: 222.12089371681213 and batch: 1200, loss is 4.334823036193848 and perplexity is 76.3114533295711
At time: 223.2837312221527 and batch: 1250, loss is 4.303621053695679 and perplexity is 73.96714837062213
At time: 224.44491314888 and batch: 1300, loss is 4.319974012374878 and perplexity is 75.18667434352696
At time: 225.60549569129944 and batch: 1350, loss is 4.202852373123169 and perplexity is 66.87681687846079
At time: 226.7695152759552 and batch: 1400, loss is 4.230153493881225 and perplexity is 68.72778065806307
At time: 227.93112802505493 and batch: 1450, loss is 4.157430853843689 and perplexity is 63.90712476537819
At time: 229.09296679496765 and batch: 1500, loss is 4.157014327049255 and perplexity is 63.88051127855817
At time: 230.25538969039917 and batch: 1550, loss is 4.158036193847656 and perplexity is 63.945822015852414
At time: 231.41705965995789 and batch: 1600, loss is 4.2552215147018435 and perplexity is 70.47242613802696
At time: 232.57786679267883 and batch: 1650, loss is 4.201147065162659 and perplexity is 66.76286849642008
At time: 233.7427487373352 and batch: 1700, loss is 4.229810118675232 and perplexity is 68.70418529348557
At time: 234.90612816810608 and batch: 1750, loss is 4.2346914196014405 and perplexity is 69.04037094092205
At time: 236.0691909790039 and batch: 1800, loss is 4.187552027702331 and perplexity is 65.86136665884544
At time: 237.22821307182312 and batch: 1850, loss is 4.224760508537292 and perplexity is 68.35813039938434
At time: 238.38794374465942 and batch: 1900, loss is 4.304143648147583 and perplexity is 74.00581329414112
At time: 239.5497796535492 and batch: 1950, loss is 4.229987764358521 and perplexity is 68.71639137957398
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.476045262536338 and perplexity of 87.88641679420961
finished 5 epochs...
Completing Train Step...
At time: 243.20542120933533 and batch: 50, loss is 4.215632972717285 and perplexity is 67.73702799489398
At time: 244.36557173728943 and batch: 100, loss is 4.165371541976929 and perplexity is 64.41661147304139
At time: 245.52838110923767 and batch: 150, loss is 4.123164620399475 and perplexity is 61.754362476134744
At time: 246.69070053100586 and batch: 200, loss is 4.128307790756225 and perplexity is 62.07279385409999
At time: 247.8535349369049 and batch: 250, loss is 4.122652921676636 and perplexity is 61.72277093109191
At time: 249.01616668701172 and batch: 300, loss is 4.138032493591308 and perplexity is 62.679377973253104
At time: 250.17844033241272 and batch: 350, loss is 4.1457383346557615 and perplexity is 63.164241037528306
At time: 251.34158301353455 and batch: 400, loss is 4.132539501190186 and perplexity is 62.33602450865716
At time: 252.52809238433838 and batch: 450, loss is 4.152246742248535 and perplexity is 63.576680369239654
At time: 253.68891835212708 and batch: 500, loss is 4.168583583831787 and perplexity is 64.62385298126067
At time: 254.85177063941956 and batch: 550, loss is 4.1307468557357785 and perplexity is 62.22437821868168
At time: 256.0137996673584 and batch: 600, loss is 4.113672394752502 and perplexity is 61.170949457402884
At time: 257.1778199672699 and batch: 650, loss is 4.156931195259094 and perplexity is 63.875200998028795
At time: 258.34046626091003 and batch: 700, loss is 4.188037748336792 and perplexity is 65.89336465405961
At time: 259.5046007633209 and batch: 750, loss is 4.149783873558045 and perplexity is 63.420292014754516
At time: 260.6662075519562 and batch: 800, loss is 4.119543490409851 and perplexity is 61.5311462935005
At time: 261.82801485061646 and batch: 850, loss is 4.127549028396606 and perplexity is 62.02571321833301
At time: 262.99157333374023 and batch: 900, loss is 4.108019280433655 and perplexity is 60.82611868933676
At time: 264.156099319458 and batch: 950, loss is 4.197356657981873 and perplexity is 66.51028903217347
At time: 265.3170039653778 and batch: 1000, loss is 4.1725467014312745 and perplexity is 64.88047308229748
At time: 266.4818801879883 and batch: 1050, loss is 4.11664502620697 and perplexity is 61.35305868356532
At time: 267.64652371406555 and batch: 1100, loss is 4.167519435882569 and perplexity is 64.55512021804071
At time: 268.8091311454773 and batch: 1150, loss is 4.121261901855469 and perplexity is 61.63697302044104
At time: 269.9726848602295 and batch: 1200, loss is 4.194732761383056 and perplexity is 66.33600166700295
At time: 271.1356964111328 and batch: 1250, loss is 4.166865310668945 and perplexity is 64.51290689414253
At time: 272.30034613609314 and batch: 1300, loss is 4.181982040405273 and perplexity is 65.49553945543465
At time: 273.46368932724 and batch: 1350, loss is 4.056662721633911 and perplexity is 57.78115714829342
At time: 274.6252944469452 and batch: 1400, loss is 4.091408791542054 and perplexity is 59.82411206884063
At time: 275.7889778614044 and batch: 1450, loss is 4.017277870178223 and perplexity is 55.549686370728395
At time: 276.9535436630249 and batch: 1500, loss is 4.022158041000366 and perplexity is 55.821440894238776
At time: 278.115033864975 and batch: 1550, loss is 4.022532744407654 and perplexity is 55.842361297569994
At time: 279.2791197299957 and batch: 1600, loss is 4.124438815116882 and perplexity is 61.83309971121021
At time: 280.4404797554016 and batch: 1650, loss is 4.071012277603149 and perplexity is 58.6162685055924
At time: 281.60433435440063 and batch: 1700, loss is 4.097059192657471 and perplexity is 60.163099102857124
At time: 282.7690908908844 and batch: 1750, loss is 4.103611536026001 and perplexity is 60.55860270899067
At time: 283.9325420856476 and batch: 1800, loss is 4.052131791114807 and perplexity is 57.519946949444396
At time: 285.09787344932556 and batch: 1850, loss is 4.093451781272888 and perplexity is 59.94645704766755
At time: 286.26151156425476 and batch: 1900, loss is 4.173284983634948 and perplexity is 64.92839086718749
At time: 287.42650294303894 and batch: 1950, loss is 4.103216800689697 and perplexity is 60.53470280596271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.466000863008721 and perplexity of 87.0080691329874
finished 6 epochs...
Completing Train Step...
At time: 291.0680055618286 and batch: 50, loss is 4.083502345085144 and perplexity is 59.3529808710039
At time: 292.25708508491516 and batch: 100, loss is 4.038129334449768 and perplexity is 56.72013909042336
At time: 293.4215462207794 and batch: 150, loss is 3.9938440799713133 and perplexity is 54.26308057634658
At time: 294.58423113822937 and batch: 200, loss is 4.002574591636658 and perplexity is 54.73889908151146
At time: 295.74835181236267 and batch: 250, loss is 3.9936030817031862 and perplexity is 54.250004843582204
At time: 296.9134097099304 and batch: 300, loss is 4.007550711631775 and perplexity is 55.01196525329378
At time: 298.0770528316498 and batch: 350, loss is 4.016414256095886 and perplexity is 55.50173358863857
At time: 299.2403140068054 and batch: 400, loss is 4.0058251571655275 and perplexity is 54.91712096398095
At time: 300.40307903289795 and batch: 450, loss is 4.033880076408386 and perplexity is 56.47963193365691
At time: 301.56762957572937 and batch: 500, loss is 4.048821601867676 and perplexity is 57.32985982530492
At time: 302.7317159175873 and batch: 550, loss is 4.012670969963073 and perplexity is 55.29436308465798
At time: 303.8959581851959 and batch: 600, loss is 3.9916656970977784 and perplexity is 54.14500346622417
At time: 305.06088042259216 and batch: 650, loss is 4.032340836524964 and perplexity is 56.39276310471789
At time: 306.22525906562805 and batch: 700, loss is 4.066086206436157 and perplexity is 58.32823062540328
At time: 307.38967180252075 and batch: 750, loss is 4.028494849205017 and perplexity is 56.17629378882998
At time: 308.556010723114 and batch: 800, loss is 3.996418604850769 and perplexity is 54.40296221444165
At time: 309.72055172920227 and batch: 850, loss is 4.010213255882263 and perplexity is 55.15863221207568
At time: 310.90564155578613 and batch: 900, loss is 3.9902058124542235 and perplexity is 54.06601567769699
At time: 312.07035541534424 and batch: 950, loss is 4.0848702764511104 and perplexity is 59.43422723225467
At time: 313.2360460758209 and batch: 1000, loss is 4.054141349792481 and perplexity is 57.63565287796417
At time: 314.4012186527252 and batch: 1050, loss is 4.002609052658081 and perplexity is 54.74078547238868
At time: 315.567759513855 and batch: 1100, loss is 4.048463625907898 and perplexity is 57.30934078659043
At time: 316.7315194606781 and batch: 1150, loss is 4.006131558418274 and perplexity is 54.933950216761964
At time: 317.89725065231323 and batch: 1200, loss is 4.076845865249634 and perplexity is 58.95921096532958
At time: 319.0604074001312 and batch: 1250, loss is 4.051617817878723 and perplexity is 57.49039083234866
At time: 320.22619128227234 and batch: 1300, loss is 4.062838563919067 and perplexity is 58.139108650186685
At time: 321.389436006546 and batch: 1350, loss is 3.942110786437988 and perplexity is 51.52724961316532
At time: 322.5557472705841 and batch: 1400, loss is 3.9760985565185547 and perplexity is 53.30864731236974
At time: 323.71976017951965 and batch: 1450, loss is 3.902396574020386 and perplexity is 49.520987718143424
At time: 324.8871383666992 and batch: 1500, loss is 3.903049921989441 and perplexity is 49.55335272654965
At time: 326.05252981185913 and batch: 1550, loss is 3.91110324382782 and perplexity is 49.9540330625362
At time: 327.21916127204895 and batch: 1600, loss is 4.016974945068359 and perplexity is 55.53286152434452
At time: 328.3836421966553 and batch: 1650, loss is 3.962902331352234 and perplexity is 52.60979564261364
At time: 329.5474581718445 and batch: 1700, loss is 3.986497130393982 and perplexity is 53.865873376766615
At time: 330.7123930454254 and batch: 1750, loss is 3.991201639175415 and perplexity is 54.11988287756417
At time: 331.8757994174957 and batch: 1800, loss is 3.9418544960021973 and perplexity is 51.51404536404052
At time: 333.0405900478363 and batch: 1850, loss is 3.983633213043213 and perplexity is 53.71182666121054
At time: 334.20566272735596 and batch: 1900, loss is 4.06333360671997 and perplexity is 58.16789712254996
At time: 335.37090039253235 and batch: 1950, loss is 3.995076451301575 and perplexity is 54.32999406380364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.472147529069767 and perplexity of 87.54452569923858
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 339.01573061943054 and batch: 50, loss is 4.0076328372955325 and perplexity is 55.016483332977415
At time: 340.19711470603943 and batch: 100, loss is 3.983715991973877 and perplexity is 53.71627305281679
At time: 341.36050248146057 and batch: 150, loss is 3.9453182458877563 and perplexity is 51.692786511384405
At time: 342.52206110954285 and batch: 200, loss is 3.941543221473694 and perplexity is 51.49801284924472
At time: 343.68499732017517 and batch: 250, loss is 3.931284155845642 and perplexity is 50.97239215436671
At time: 344.84847497940063 and batch: 300, loss is 3.9395934343338013 and perplexity is 51.39770051169363
At time: 346.01153588294983 and batch: 350, loss is 3.9559887647628784 and perplexity is 52.24732873049966
At time: 347.17145133018494 and batch: 400, loss is 3.9273527574539187 and perplexity is 50.77239277005502
At time: 348.3341681957245 and batch: 450, loss is 3.953769021034241 and perplexity is 52.13148167316896
At time: 349.49702644348145 and batch: 500, loss is 3.97491491317749 and perplexity is 53.24558621524359
At time: 350.65989351272583 and batch: 550, loss is 3.9340461349487303 and perplexity is 51.11337143762663
At time: 351.822881937027 and batch: 600, loss is 3.8962436389923094 and perplexity is 49.21722377642558
At time: 352.9866478443146 and batch: 650, loss is 3.922404336929321 and perplexity is 50.521770223877645
At time: 354.15105414390564 and batch: 700, loss is 3.943626708984375 and perplexity is 51.6054201678906
At time: 355.31291031837463 and batch: 750, loss is 3.896785650253296 and perplexity is 49.24390729667788
At time: 356.4755198955536 and batch: 800, loss is 3.861517643928528 and perplexity is 47.53744156095832
At time: 357.63892245292664 and batch: 850, loss is 3.871884517669678 and perplexity is 48.03281953947663
At time: 358.80148434638977 and batch: 900, loss is 3.8532019424438477 and perplexity is 47.143773469298104
At time: 359.9642391204834 and batch: 950, loss is 3.95952422618866 and perplexity is 52.43237406339709
At time: 361.12669706344604 and batch: 1000, loss is 3.917578225135803 and perplexity is 50.278533927658074
At time: 362.2927813529968 and batch: 1050, loss is 3.851307740211487 and perplexity is 47.05455815095363
At time: 363.45545506477356 and batch: 1100, loss is 3.881877956390381 and perplexity is 48.515239078294
At time: 364.61893939971924 and batch: 1150, loss is 3.8367771673202515 and perplexity is 46.3757719828846
At time: 365.7816035747528 and batch: 1200, loss is 3.883288321495056 and perplexity is 48.58371155277928
At time: 366.94328784942627 and batch: 1250, loss is 3.8604638147354127 and perplexity is 47.48737160450007
At time: 368.10691475868225 and batch: 1300, loss is 3.8722878980636595 and perplexity is 48.052198945519955
At time: 369.26760482788086 and batch: 1350, loss is 3.747308588027954 and perplexity is 42.4067941177797
At time: 370.4313066005707 and batch: 1400, loss is 3.7652651643753052 and perplexity is 43.175152854560736
At time: 371.5961217880249 and batch: 1450, loss is 3.6885255670547483 and perplexity is 39.98584702205806
At time: 372.76055788993835 and batch: 1500, loss is 3.6764434003829956 and perplexity is 39.50563817715346
At time: 373.92346692085266 and batch: 1550, loss is 3.6816019344329836 and perplexity is 39.70995589372338
At time: 375.0871238708496 and batch: 1600, loss is 3.7687199211120603 and perplexity is 43.32457045686702
At time: 376.2495174407959 and batch: 1650, loss is 3.704656286239624 and perplexity is 40.63607773716194
At time: 377.4137156009674 and batch: 1700, loss is 3.722354688644409 and perplexity is 41.36167339510484
At time: 378.5770175457001 and batch: 1750, loss is 3.717881135940552 and perplexity is 41.17705303161074
At time: 379.74057388305664 and batch: 1800, loss is 3.657814078330994 and perplexity is 38.77648779692453
At time: 380.9031915664673 and batch: 1850, loss is 3.6931956386566163 and perplexity is 40.17302050732052
At time: 382.0671977996826 and batch: 1900, loss is 3.7696893882751463 and perplexity is 43.36659257151864
At time: 383.2312409877777 and batch: 1950, loss is 3.690752854347229 and perplexity is 40.07500624575386
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.429900129451308 and perplexity of 83.92303505216688
finished 8 epochs...
Completing Train Step...
At time: 386.85452103614807 and batch: 50, loss is 3.9085465478897095 and perplexity is 49.826478917177496
At time: 388.04558873176575 and batch: 100, loss is 3.8715453052520754 and perplexity is 48.016528973773674
At time: 389.21075677871704 and batch: 150, loss is 3.8273684978485107 and perplexity is 45.94148391295794
At time: 390.3782160282135 and batch: 200, loss is 3.8281688499450683 and perplexity is 45.97826799407132
At time: 391.5422909259796 and batch: 250, loss is 3.8144094467163088 and perplexity is 45.349966901548726
At time: 392.70780515670776 and batch: 300, loss is 3.8214581823349 and perplexity is 45.67075607941059
At time: 393.87414598464966 and batch: 350, loss is 3.838422679901123 and perplexity is 46.452146719691804
At time: 395.0409710407257 and batch: 400, loss is 3.813742880821228 and perplexity is 45.31974823275499
At time: 396.20600175857544 and batch: 450, loss is 3.842554306983948 and perplexity is 46.64446669075417
At time: 397.37153577804565 and batch: 500, loss is 3.8687470149993897 and perplexity is 47.8823526085409
At time: 398.5770924091339 and batch: 550, loss is 3.8326920747756956 and perplexity is 46.18670909512899
At time: 399.73986768722534 and batch: 600, loss is 3.7963360118865968 and perplexity is 44.53769957096451
At time: 400.91071462631226 and batch: 650, loss is 3.822583169937134 and perplexity is 45.722164025013505
At time: 402.07671785354614 and batch: 700, loss is 3.8451105308532716 and perplexity is 46.76385291382892
At time: 403.23982429504395 and batch: 750, loss is 3.802433981895447 and perplexity is 44.810118885451985
At time: 404.40547919273376 and batch: 800, loss is 3.7678833055496215 and perplexity is 43.288339604747435
At time: 405.568811416626 and batch: 850, loss is 3.7840052890777587 and perplexity is 43.991889574598396
At time: 406.73486709594727 and batch: 900, loss is 3.7626805448532106 and perplexity is 43.06370559804222
At time: 407.89947509765625 and batch: 950, loss is 3.8709823513031005 and perplexity is 47.98950548637497
At time: 409.06614685058594 and batch: 1000, loss is 3.831998658180237 and perplexity is 46.154693565885275
At time: 410.2313802242279 and batch: 1050, loss is 3.7714616775512697 and perplexity is 43.44351886616316
At time: 411.397216796875 and batch: 1100, loss is 3.8032619094848634 and perplexity is 44.847233781265324
At time: 412.56319785118103 and batch: 1150, loss is 3.762524571418762 and perplexity is 43.0569893277735
At time: 413.7280161380768 and batch: 1200, loss is 3.811917586326599 and perplexity is 45.23710179579706
At time: 414.8919792175293 and batch: 1250, loss is 3.794310460090637 and perplexity is 44.44757745792779
At time: 416.0575864315033 and batch: 1300, loss is 3.8074570178985594 and perplexity is 45.03576797321957
At time: 417.22159814834595 and batch: 1350, loss is 3.682379994392395 and perplexity is 39.74086464326521
At time: 418.38656425476074 and batch: 1400, loss is 3.7037516117095945 and perplexity is 40.599331936633924
At time: 419.55249094963074 and batch: 1450, loss is 3.631106677055359 and perplexity is 37.75457562863288
At time: 420.71756386756897 and batch: 1500, loss is 3.621799068450928 and perplexity is 37.404801122877664
At time: 421.88847160339355 and batch: 1550, loss is 3.630862011909485 and perplexity is 37.7453395298011
At time: 423.05615878105164 and batch: 1600, loss is 3.7221644163131713 and perplexity is 41.35380416175647
At time: 424.221604347229 and batch: 1650, loss is 3.660975489616394 and perplexity is 38.89927020363443
At time: 425.38850140571594 and batch: 1700, loss is 3.6839704275131226 and perplexity is 39.804120119108525
At time: 426.5537555217743 and batch: 1750, loss is 3.6825563049316408 and perplexity is 39.747871994257316
At time: 427.72121953964233 and batch: 1800, loss is 3.6262152767181397 and perplexity is 37.57035380332499
At time: 428.88816928863525 and batch: 1850, loss is 3.666553339958191 and perplexity is 39.116850763013076
At time: 430.05419087409973 and batch: 1900, loss is 3.7483532285690306 and perplexity is 42.451117120904485
At time: 431.2229290008545 and batch: 1950, loss is 3.673162331581116 and perplexity is 39.376229875097806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.436857285610465 and perplexity of 84.50893645291215
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 434.91024899482727 and batch: 50, loss is 3.8708770799636842 and perplexity is 47.98445383275634
At time: 436.07552123069763 and batch: 100, loss is 3.8681515407562257 and perplexity is 47.85384838846713
At time: 437.2449297904968 and batch: 150, loss is 3.8378596925735473 and perplexity is 46.42600210998246
At time: 438.409147977829 and batch: 200, loss is 3.841379714012146 and perplexity is 46.58971059236538
At time: 439.5731620788574 and batch: 250, loss is 3.831388554573059 and perplexity is 46.126543009103855
At time: 440.73848843574524 and batch: 300, loss is 3.827075228691101 and perplexity is 45.928012668127494
At time: 441.910049200058 and batch: 350, loss is 3.849920039176941 and perplexity is 46.98930577779176
At time: 443.0743899345398 and batch: 400, loss is 3.8298062896728515 and perplexity is 46.05361630902626
At time: 444.2401316165924 and batch: 450, loss is 3.851616244316101 and perplexity is 47.069076914717954
At time: 445.40637707710266 and batch: 500, loss is 3.8685931539535523 and perplexity is 47.874985946427095
At time: 446.5718472003937 and batch: 550, loss is 3.841437258720398 and perplexity is 46.592391660808865
At time: 447.7373101711273 and batch: 600, loss is 3.8171291589736938 and perplexity is 45.473473637665016
At time: 448.9003572463989 and batch: 650, loss is 3.836924033164978 and perplexity is 46.382583499989074
At time: 450.06877088546753 and batch: 700, loss is 3.850408697128296 and perplexity is 47.012273086810794
At time: 451.23724603652954 and batch: 750, loss is 3.792054982185364 and perplexity is 44.347439900504135
At time: 452.40349555015564 and batch: 800, loss is 3.7430440282821653 and perplexity is 42.22633287800246
At time: 453.5683035850525 and batch: 850, loss is 3.749364356994629 and perplexity is 42.49406236004098
At time: 454.7324604988098 and batch: 900, loss is 3.7239656257629394 and perplexity is 41.428358148112224
At time: 455.9204936027527 and batch: 950, loss is 3.8384041023254394 and perplexity is 46.45128375943633
At time: 457.0837037563324 and batch: 1000, loss is 3.8014502000808714 and perplexity is 44.76605718248824
At time: 458.2475016117096 and batch: 1050, loss is 3.7506003952026368 and perplexity is 42.54661911912131
At time: 459.41127347946167 and batch: 1100, loss is 3.784384346008301 and perplexity is 44.00856816609744
At time: 460.5745813846588 and batch: 1150, loss is 3.7407641077041625 and perplexity is 42.13016985642109
At time: 461.74018573760986 and batch: 1200, loss is 3.7764235591888426 and perplexity is 43.65961614589459
At time: 462.90467262268066 and batch: 1250, loss is 3.7500509929656984 and perplexity is 42.52325033142303
At time: 464.0699212551117 and batch: 1300, loss is 3.7650174617767336 and perplexity is 43.16445958143537
At time: 465.23650217056274 and batch: 1350, loss is 3.6366050958633425 and perplexity is 37.96273785446527
At time: 466.4032952785492 and batch: 1400, loss is 3.6568835020065307 and perplexity is 38.74042009991014
At time: 467.56868505477905 and batch: 1450, loss is 3.5750388860702516 and perplexity is 35.69600886617625
At time: 468.73448872566223 and batch: 1500, loss is 3.5694790506362915 and perplexity is 35.49809562358111
At time: 469.8994519710541 and batch: 1550, loss is 3.576592926979065 and perplexity is 35.751525050273415
At time: 471.0699052810669 and batch: 1600, loss is 3.6582287645339964 and perplexity is 38.792571205968244
At time: 472.2354063987732 and batch: 1650, loss is 3.5946665000915528 and perplexity is 36.40355738015888
At time: 473.40023851394653 and batch: 1700, loss is 3.6118172788619995 and perplexity is 37.03329151844718
At time: 474.5661597251892 and batch: 1750, loss is 3.6137070226669312 and perplexity is 37.103341118723115
At time: 475.7324483394623 and batch: 1800, loss is 3.5523941898345948 and perplexity is 34.896767035607056
At time: 476.90353631973267 and batch: 1850, loss is 3.5856319427490235 and perplexity is 36.07614857734804
At time: 478.06750226020813 and batch: 1900, loss is 3.672119994163513 and perplexity is 39.33520794039769
At time: 479.23240542411804 and batch: 1950, loss is 3.6052158308029174 and perplexity is 36.78962333436478
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.420708518804505 and perplexity of 83.15518150115324
finished 10 epochs...
Completing Train Step...
At time: 482.9005630016327 and batch: 50, loss is 3.8710927629470824 and perplexity is 47.99480437909395
At time: 484.0639078617096 and batch: 100, loss is 3.846775298118591 and perplexity is 46.84176868317624
At time: 485.25265288352966 and batch: 150, loss is 3.804602026939392 and perplexity is 44.907374630943465
At time: 486.41742730140686 and batch: 200, loss is 3.8033652877807618 and perplexity is 44.85187025152045
At time: 487.5824763774872 and batch: 250, loss is 3.793261342048645 and perplexity is 44.4009711545255
At time: 488.75160908699036 and batch: 300, loss is 3.7867187309265136 and perplexity is 44.11142110636597
At time: 489.91528034210205 and batch: 350, loss is 3.8076912689208986 and perplexity is 45.04631888364166
At time: 491.08110642433167 and batch: 400, loss is 3.7850229740142822 and perplexity is 44.03668224649549
At time: 492.24344968795776 and batch: 450, loss is 3.8085196924209597 and perplexity is 45.083651774383036
At time: 493.41006803512573 and batch: 500, loss is 3.8224947118759154 and perplexity is 45.7181197099079
At time: 494.57349920272827 and batch: 550, loss is 3.7938739252090454 and perplexity is 44.42817877437423
At time: 495.7370185852051 and batch: 600, loss is 3.773006491661072 and perplexity is 43.51068289169726
At time: 496.90289664268494 and batch: 650, loss is 3.794730100631714 and perplexity is 44.466233377498114
At time: 498.06674098968506 and batch: 700, loss is 3.8120183992385863 and perplexity is 45.24166250964451
At time: 499.23358845710754 and batch: 750, loss is 3.7560912275314333 and perplexity is 42.780878020475654
At time: 500.39699959754944 and batch: 800, loss is 3.7081343078613282 and perplexity is 40.77765695923151
At time: 501.5609018802643 and batch: 850, loss is 3.717050061225891 and perplexity is 41.14284604026356
At time: 502.7253592014313 and batch: 900, loss is 3.693162384033203 and perplexity is 40.171684590865
At time: 503.8894305229187 and batch: 950, loss is 3.808027114868164 and perplexity is 45.061450048005845
At time: 505.05658650398254 and batch: 1000, loss is 3.7713899421691894 and perplexity is 43.44040254051513
At time: 506.22789883613586 and batch: 1050, loss is 3.722418522834778 and perplexity is 41.36431376831045
At time: 507.3946120738983 and batch: 1100, loss is 3.7574429321289062 and perplexity is 42.83874423018007
At time: 508.55923223495483 and batch: 1150, loss is 3.7180979156494143 and perplexity is 41.185980348774386
At time: 509.7241265773773 and batch: 1200, loss is 3.754327073097229 and perplexity is 42.70547247788453
At time: 510.89010882377625 and batch: 1250, loss is 3.7302069425582887 and perplexity is 41.68773423782005
At time: 512.0554192066193 and batch: 1300, loss is 3.7462070417404174 and perplexity is 42.360106790000096
At time: 513.2210228443146 and batch: 1350, loss is 3.618077554702759 and perplexity is 37.2658573422067
At time: 514.3853652477264 and batch: 1400, loss is 3.639477024078369 and perplexity is 38.07192082020429
At time: 515.5548141002655 and batch: 1450, loss is 3.559204273223877 and perplexity is 35.13522797698795
At time: 516.720016002655 and batch: 1500, loss is 3.556054720878601 and perplexity is 35.02474181961151
At time: 517.885027885437 and batch: 1550, loss is 3.5657167482376098 and perplexity is 35.36479197482843
At time: 519.0504994392395 and batch: 1600, loss is 3.6486809730529783 and perplexity is 38.42395038275408
At time: 520.2157678604126 and batch: 1650, loss is 3.588005485534668 and perplexity is 36.161878561181844
At time: 521.3815929889679 and batch: 1700, loss is 3.608004012107849 and perplexity is 36.89234260779548
At time: 522.5448756217957 and batch: 1750, loss is 3.6111075496673584 and perplexity is 37.007017235198724
At time: 523.7118139266968 and batch: 1800, loss is 3.5519289636611937 and perplexity is 34.88053592207718
At time: 524.8765549659729 and batch: 1850, loss is 3.5869107007980348 and perplexity is 36.12231075155411
At time: 526.0425465106964 and batch: 1900, loss is 3.6753251934051514 and perplexity is 39.461487386341226
At time: 527.2092521190643 and batch: 1950, loss is 3.6089388227462766 and perplexity is 36.92684608673871
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4232691565225295 and perplexity of 83.36838464686713
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 530.8717200756073 and batch: 50, loss is 3.86453230381012 and perplexity is 47.680967010414214
At time: 532.0341794490814 and batch: 100, loss is 3.8667944717407225 and perplexity is 47.78895145831282
At time: 533.1966314315796 and batch: 150, loss is 3.8405605363845825 and perplexity is 46.55156097156474
At time: 534.3592491149902 and batch: 200, loss is 3.852983555793762 and perplexity is 47.13347902266352
At time: 535.5216026306152 and batch: 250, loss is 3.8488214588165284 and perplexity is 46.93771259413291
At time: 536.6866898536682 and batch: 300, loss is 3.843571033477783 and perplexity is 46.69191547295902
At time: 537.8506507873535 and batch: 350, loss is 3.8651726341247556 and perplexity is 47.711508356253375
At time: 539.013439655304 and batch: 400, loss is 3.837024097442627 and perplexity is 46.38722497192138
At time: 540.175060749054 and batch: 450, loss is 3.859249711036682 and perplexity is 47.429751996159695
At time: 541.3401696681976 and batch: 500, loss is 3.8668591451644896 and perplexity is 47.792042233366296
At time: 542.502956867218 and batch: 550, loss is 3.8338779163360597 and perplexity is 46.24151170149251
At time: 543.6902077198029 and batch: 600, loss is 3.8036625480651853 and perplexity is 44.8652049130628
At time: 544.8523774147034 and batch: 650, loss is 3.8253722190856934 and perplexity is 45.849863384774146
At time: 546.0144720077515 and batch: 700, loss is 3.8445130681991575 and perplexity is 46.73592160293886
At time: 547.1777808666229 and batch: 750, loss is 3.787442922592163 and perplexity is 44.14337779988006
At time: 548.3411431312561 and batch: 800, loss is 3.7381897497177126 and perplexity is 42.021851202498475
At time: 549.5043747425079 and batch: 850, loss is 3.7371841955184935 and perplexity is 41.97961719141515
At time: 550.6663913726807 and batch: 900, loss is 3.7038234281539917 and perplexity is 40.60224774099861
At time: 551.8275191783905 and batch: 950, loss is 3.8144023990631104 and perplexity is 45.3496472918357
At time: 552.9915082454681 and batch: 1000, loss is 3.77675407409668 and perplexity is 43.67404868485451
At time: 554.1535220146179 and batch: 1050, loss is 3.728499827384949 and perplexity is 41.616629183687024
At time: 555.3233726024628 and batch: 1100, loss is 3.7712551069259646 and perplexity is 43.434545638140094
At time: 556.4872119426727 and batch: 1150, loss is 3.736181421279907 and perplexity is 41.93754221212827
At time: 557.650102853775 and batch: 1200, loss is 3.778091745376587 and perplexity is 43.732509297281354
At time: 558.8132991790771 and batch: 1250, loss is 3.749687662124634 and perplexity is 42.50780312950768
At time: 559.9765367507935 and batch: 1300, loss is 3.760695514678955 and perplexity is 42.978307629828166
At time: 561.1398501396179 and batch: 1350, loss is 3.625145297050476 and perplexity is 37.53017578731179
At time: 562.30104637146 and batch: 1400, loss is 3.653335647583008 and perplexity is 38.603218259084855
At time: 563.4677038192749 and batch: 1450, loss is 3.5641717386245726 and perplexity is 35.31019521838149
At time: 564.6313560009003 and batch: 1500, loss is 3.5604845809936525 and perplexity is 35.180240691274946
At time: 565.7947652339935 and batch: 1550, loss is 3.5719223165512086 and perplexity is 35.584932950805246
At time: 566.9578039646149 and batch: 1600, loss is 3.648994011878967 and perplexity is 38.43598045391319
At time: 568.1188545227051 and batch: 1650, loss is 3.58532169342041 and perplexity is 36.06495771254187
At time: 569.2796804904938 and batch: 1700, loss is 3.5998166751861573 and perplexity is 36.59152569412055
At time: 570.442953824997 and batch: 1750, loss is 3.6057446002960205 and perplexity is 36.80908170889079
At time: 571.6059906482697 and batch: 1800, loss is 3.549226655960083 and perplexity is 34.78640522357401
At time: 572.7689337730408 and batch: 1850, loss is 3.577241506576538 and perplexity is 35.774720281163226
At time: 573.9328317642212 and batch: 1900, loss is 3.6659324264526365 and perplexity is 39.09257012094894
At time: 575.0967471599579 and batch: 1950, loss is 3.6047216510772704 and perplexity is 36.77144713992204
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399842160247093 and perplexity of 81.43801349453916
finished 12 epochs...
Completing Train Step...
At time: 578.7172062397003 and batch: 50, loss is 3.8756865310668944 and perplexity is 48.21578856781426
At time: 579.9099154472351 and batch: 100, loss is 3.8633760738372804 and perplexity is 47.62586870651628
At time: 581.0747482776642 and batch: 150, loss is 3.8237691736221313 and perplexity is 45.77642284925591
At time: 582.2399673461914 and batch: 200, loss is 3.8273408079147337 and perplexity is 45.94021181392302
At time: 583.4048948287964 and batch: 250, loss is 3.817380633354187 and perplexity is 45.48491048925423
At time: 584.5698294639587 and batch: 300, loss is 3.808515582084656 and perplexity is 45.08346646579328
At time: 585.7333314418793 and batch: 350, loss is 3.8320208263397215 and perplexity is 46.15571674183413
At time: 586.897474527359 and batch: 400, loss is 3.807599997520447 and perplexity is 45.042207630654715
At time: 588.0643880367279 and batch: 450, loss is 3.831662139892578 and perplexity is 46.139164280529876
At time: 589.2282299995422 and batch: 500, loss is 3.841497564315796 and perplexity is 46.59520152745347
At time: 590.3922388553619 and batch: 550, loss is 3.807845587730408 and perplexity is 45.05327091434531
At time: 591.5565750598907 and batch: 600, loss is 3.7776236152648925 and perplexity is 43.71204158396959
At time: 592.7220921516418 and batch: 650, loss is 3.7994160079956054 and perplexity is 44.675086980081
At time: 593.888014793396 and batch: 700, loss is 3.8207668924331664 and perplexity is 45.63919525702412
At time: 595.0568854808807 and batch: 750, loss is 3.766725902557373 and perplexity is 43.238266533910185
At time: 596.220380783081 and batch: 800, loss is 3.7199966669082642 and perplexity is 41.264256570829026
At time: 597.3839898109436 and batch: 850, loss is 3.7203549432754515 and perplexity is 41.27904322746454
At time: 598.5493748188019 and batch: 900, loss is 3.688761396408081 and perplexity is 39.99527797050725
At time: 599.7143433094025 and batch: 950, loss is 3.8012247562408445 and perplexity is 44.75596608818442
At time: 600.9174106121063 and batch: 1000, loss is 3.763761420249939 and perplexity is 43.110277262464116
At time: 602.0844762325287 and batch: 1050, loss is 3.7161605167388916 and perplexity is 41.10626392151226
At time: 603.2513520717621 and batch: 1100, loss is 3.756967153549194 and perplexity is 42.818367321126395
At time: 604.4157581329346 and batch: 1150, loss is 3.7234300994873046 and perplexity is 41.40617811329331
At time: 605.5802013874054 and batch: 1200, loss is 3.7661279153823854 and perplexity is 43.21241833427041
At time: 606.7440190315247 and batch: 1250, loss is 3.738696813583374 and perplexity is 42.043164367922834
At time: 607.9092350006104 and batch: 1300, loss is 3.7504387378692625 and perplexity is 42.53974170203785
At time: 609.0744273662567 and batch: 1350, loss is 3.6167515468597413 and perplexity is 37.21647527083683
At time: 610.2397367954254 and batch: 1400, loss is 3.646566605567932 and perplexity is 38.34279385900979
At time: 611.4043526649475 and batch: 1450, loss is 3.559123616218567 and perplexity is 35.13239418900239
At time: 612.5701081752777 and batch: 1500, loss is 3.556774001121521 and perplexity is 35.049943486859874
At time: 613.7348453998566 and batch: 1550, loss is 3.569275074005127 and perplexity is 35.490855580048006
At time: 614.8987739086151 and batch: 1600, loss is 3.6469026947021486 and perplexity is 38.35568262116643
At time: 616.0650837421417 and batch: 1650, loss is 3.5844405603408815 and perplexity is 36.033193681513914
At time: 617.2305538654327 and batch: 1700, loss is 3.599869799613953 and perplexity is 36.593469649620516
At time: 618.3959515094757 and batch: 1750, loss is 3.6075350427627564 and perplexity is 36.875045286317544
At time: 619.5599193572998 and batch: 1800, loss is 3.55215696811676 and perplexity is 34.888489746399195
At time: 620.7246477603912 and batch: 1850, loss is 3.5818722295761107 and perplexity is 35.9407672632417
At time: 621.8901460170746 and batch: 1900, loss is 3.6708913803100587 and perplexity is 39.2869098349298
At time: 623.0558490753174 and batch: 1950, loss is 3.6092139863967896 and perplexity is 36.93700841059682
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.398798033248546 and perplexity of 81.35302624240482
finished 13 epochs...
Completing Train Step...
At time: 626.6749408245087 and batch: 50, loss is 3.8696844244003294 and perplexity is 47.92725902057325
At time: 627.8653428554535 and batch: 100, loss is 3.854869647026062 and perplexity is 47.222460951835934
At time: 629.0316371917725 and batch: 150, loss is 3.813683481216431 and perplexity is 45.31705633757001
At time: 630.2191188335419 and batch: 200, loss is 3.8159101247787475 and perplexity is 45.41807369241211
At time: 631.3840403556824 and batch: 250, loss is 3.804913053512573 and perplexity is 44.92134419012492
At time: 632.5486776828766 and batch: 300, loss is 3.7952956676483156 and perplexity is 44.49138912540905
At time: 633.7126607894897 and batch: 350, loss is 3.8187621450424194 and perplexity is 45.547791850399896
At time: 634.8843314647675 and batch: 400, loss is 3.7946965408325197 and perplexity is 44.46474112467504
At time: 636.0494763851166 and batch: 450, loss is 3.8193028211593627 and perplexity is 45.57242511234103
At time: 637.2131586074829 and batch: 500, loss is 3.8303754997253416 and perplexity is 46.07983795248642
At time: 638.3759644031525 and batch: 550, loss is 3.7974519681930543 and perplexity is 44.58742944069576
At time: 639.5417704582214 and batch: 600, loss is 3.767007827758789 and perplexity is 43.250458209401174
At time: 640.7071623802185 and batch: 650, loss is 3.7892482900619506 and perplexity is 44.223144800875154
At time: 641.8711943626404 and batch: 700, loss is 3.8114667081832887 and perplexity is 45.21670997278973
At time: 643.0321781635284 and batch: 750, loss is 3.7578027391433717 and perplexity is 42.8541606841528
At time: 644.1992299556732 and batch: 800, loss is 3.7120888090133666 and perplexity is 40.93923151347507
At time: 645.3633985519409 and batch: 850, loss is 3.7126602602005003 and perplexity is 40.9626329716825
At time: 646.5279653072357 and batch: 900, loss is 3.6820747089385986 and perplexity is 39.72873418708844
At time: 647.6922960281372 and batch: 950, loss is 3.7943128538131714 and perplexity is 44.44768385322289
At time: 648.8567640781403 and batch: 1000, loss is 3.756881251335144 and perplexity is 42.814689286549424
At time: 650.0228700637817 and batch: 1050, loss is 3.7092980670928957 and perplexity is 40.825139957989585
At time: 651.1891164779663 and batch: 1100, loss is 3.749383153915405 and perplexity is 42.494861125071765
At time: 652.3527019023895 and batch: 1150, loss is 3.716383490562439 and perplexity is 41.115430564273304
At time: 653.5162045955658 and batch: 1200, loss is 3.7596142959594725 and perplexity is 42.9318637915853
At time: 654.6808731555939 and batch: 1250, loss is 3.732710247039795 and perplexity is 41.7922220576105
At time: 655.8442504405975 and batch: 1300, loss is 3.745057578086853 and perplexity is 42.311443360663645
At time: 657.0074536800385 and batch: 1350, loss is 3.6121853685379026 and perplexity is 37.046925599848194
At time: 658.1707499027252 and batch: 1400, loss is 3.642416229248047 and perplexity is 38.18398661820768
At time: 659.3357195854187 and batch: 1450, loss is 3.5553492212295534 and perplexity is 35.00004059092843
At time: 660.5010080337524 and batch: 1500, loss is 3.5538175916671753 and perplexity is 34.946474526230716
At time: 661.6696212291718 and batch: 1550, loss is 3.566543221473694 and perplexity is 35.39403211032562
At time: 662.8339793682098 and batch: 1600, loss is 3.6446203565597535 and perplexity is 38.26824180645294
At time: 663.999929189682 and batch: 1650, loss is 3.582785348892212 and perplexity is 35.97360046009707
At time: 665.1656301021576 and batch: 1700, loss is 3.5988437604904173 and perplexity is 36.55594257351048
At time: 666.3305671215057 and batch: 1750, loss is 3.6070643854141236 and perplexity is 36.85769385888109
At time: 667.4961807727814 and batch: 1800, loss is 3.5522638463974 and perplexity is 34.892218767469544
At time: 668.660614490509 and batch: 1850, loss is 3.5826652526855467 and perplexity is 35.969280426556736
At time: 669.82435297966 and batch: 1900, loss is 3.6718438339233397 and perplexity is 39.32434661972708
At time: 670.9905655384064 and batch: 1950, loss is 3.6101699590682985 and perplexity is 36.97233606465011
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399065452398256 and perplexity of 81.37478450866773
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 674.6380093097687 and batch: 50, loss is 3.8691276836395265 and perplexity is 47.90058338831787
At time: 675.8288645744324 and batch: 100, loss is 3.865579400062561 and perplexity is 47.73091972036724
At time: 676.9912033081055 and batch: 150, loss is 3.831646890640259 and perplexity is 46.138460698136534
At time: 678.1540234088898 and batch: 200, loss is 3.8413191747665407 and perplexity is 46.58689017180707
At time: 679.3144760131836 and batch: 250, loss is 3.8343109607696535 and perplexity is 46.26154066713885
At time: 680.4781963825226 and batch: 300, loss is 3.8243452072143556 and perplexity is 45.8027992026524
At time: 681.6416234970093 and batch: 350, loss is 3.8509700679779053 and perplexity is 47.03867181554073
At time: 682.8054263591766 and batch: 400, loss is 3.833807120323181 and perplexity is 46.2382381027148
At time: 683.9697525501251 and batch: 450, loss is 3.859204177856445 and perplexity is 47.42759241788007
At time: 685.1336109638214 and batch: 500, loss is 3.870294017791748 and perplexity is 47.95648406773379
At time: 686.3022136688232 and batch: 550, loss is 3.8389244174957273 and perplexity is 46.47545935597511
At time: 687.4660844802856 and batch: 600, loss is 3.799377484321594 and perplexity is 44.67336596474389
At time: 688.6490340232849 and batch: 650, loss is 3.812163972854614 and perplexity is 45.24824898144778
At time: 689.8117189407349 and batch: 700, loss is 3.8388845825195315 and perplexity is 46.47360804403171
At time: 690.9752669334412 and batch: 750, loss is 3.7854958724975587 and perplexity is 44.0575120515418
At time: 692.1380288600922 and batch: 800, loss is 3.7403063106536867 and perplexity is 42.11088720303247
At time: 693.3019406795502 and batch: 850, loss is 3.7445913124084473 and perplexity is 42.29171958543781
At time: 694.4662895202637 and batch: 900, loss is 3.707961769104004 and perplexity is 40.77062183990599
At time: 695.6317341327667 and batch: 950, loss is 3.8138011264801026 and perplexity is 45.32238798822724
At time: 696.7945668697357 and batch: 1000, loss is 3.773781208992004 and perplexity is 43.54440443245858
At time: 697.9582235813141 and batch: 1050, loss is 3.721784720420837 and perplexity is 41.33810527277431
At time: 699.1211156845093 and batch: 1100, loss is 3.754110722541809 and perplexity is 42.696234124591925
At time: 700.2855110168457 and batch: 1150, loss is 3.7230280876159667 and perplexity is 41.38953568359632
At time: 701.4490439891815 and batch: 1200, loss is 3.7689523458480836 and perplexity is 43.334641329033346
At time: 702.6130468845367 and batch: 1250, loss is 3.7447505474090574 and perplexity is 42.29845444363014
At time: 703.7768902778625 and batch: 1300, loss is 3.7590097856521605 and perplexity is 42.90591888018445
At time: 704.9394207000732 and batch: 1350, loss is 3.6210187292099 and perplexity is 37.375624074237194
At time: 706.1020133495331 and batch: 1400, loss is 3.6525325536727906 and perplexity is 38.57222869501687
At time: 707.2653224468231 and batch: 1450, loss is 3.561997985839844 and perplexity is 35.23352294666928
At time: 708.4275915622711 and batch: 1500, loss is 3.557241373062134 and perplexity is 35.06632867565618
At time: 709.5923988819122 and batch: 1550, loss is 3.574283785820007 and perplexity is 35.66906497489843
At time: 710.7544062137604 and batch: 1600, loss is 3.655921025276184 and perplexity is 38.70315128510067
At time: 711.9174621105194 and batch: 1650, loss is 3.5840844345092773 and perplexity is 36.02036361514335
At time: 713.0787665843964 and batch: 1700, loss is 3.593101305961609 and perplexity is 36.346623313894774
At time: 714.2412810325623 and batch: 1750, loss is 3.6019555139541626 and perplexity is 36.669872823927456
At time: 715.4023597240448 and batch: 1800, loss is 3.5468133163452147 and perplexity is 34.702555033977966
At time: 716.5647139549255 and batch: 1850, loss is 3.5762280464172362 and perplexity is 35.73848239337754
At time: 717.7273514270782 and batch: 1900, loss is 3.6679572296142577 and perplexity is 39.171805071043664
At time: 718.8912725448608 and batch: 1950, loss is 3.6122639894485475 and perplexity is 37.04983837737656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38811517759811 and perplexity of 80.48856926211484
finished 15 epochs...
Completing Train Step...
At time: 722.5637800693512 and batch: 50, loss is 3.8740806770324707 and perplexity is 48.1384231846017
At time: 723.7310066223145 and batch: 100, loss is 3.863666286468506 and perplexity is 47.63969234098765
At time: 724.8967719078064 and batch: 150, loss is 3.8248826360702513 and perplexity is 45.82742156441592
At time: 726.0637855529785 and batch: 200, loss is 3.8286245107650756 and perplexity is 45.99922326325301
At time: 727.2289657592773 and batch: 250, loss is 3.8205928802490234 and perplexity is 45.631254171917746
At time: 728.3951969146729 and batch: 300, loss is 3.8098188161849977 and perplexity is 45.142259078600844
At time: 729.5596034526825 and batch: 350, loss is 3.8352915382385255 and perplexity is 46.30692593984366
At time: 730.7262163162231 and batch: 400, loss is 3.8168021392822267 and perplexity is 45.45860534759041
At time: 731.8911378383636 and batch: 450, loss is 3.8437369441986085 and perplexity is 46.699662804976796
At time: 733.0560626983643 and batch: 500, loss is 3.8553079557418823 and perplexity is 47.24316350477687
At time: 734.2202379703522 and batch: 550, loss is 3.822012839317322 and perplexity is 45.69609470963701
At time: 735.385413646698 and batch: 600, loss is 3.7829440069198608 and perplexity is 43.9452265328073
At time: 736.5517311096191 and batch: 650, loss is 3.7966570472717285 and perplexity is 44.55200004385525
At time: 737.719820022583 and batch: 700, loss is 3.822654767036438 and perplexity is 45.7254377165236
At time: 738.8897562026978 and batch: 750, loss is 3.7702054357528687 and perplexity is 43.38897756759619
At time: 740.0548989772797 and batch: 800, loss is 3.7264946413040163 and perplexity is 41.53326370769141
At time: 741.2195785045624 and batch: 850, loss is 3.731934642791748 and perplexity is 41.759820399703365
At time: 742.3855187892914 and batch: 900, loss is 3.696667819023132 and perplexity is 40.31275092461255
At time: 743.5494339466095 and batch: 950, loss is 3.803993444442749 and perplexity is 44.880053103317884
At time: 744.7146122455597 and batch: 1000, loss is 3.7640599250793456 and perplexity is 43.123147809288646
At time: 745.9022440910339 and batch: 1050, loss is 3.7124928522109983 and perplexity is 40.95577607361778
At time: 747.0673031806946 and batch: 1100, loss is 3.7465462255477906 and perplexity is 42.3744770892505
At time: 748.2344925403595 and batch: 1150, loss is 3.7161979150772093 and perplexity is 41.10780125622407
At time: 749.4020416736603 and batch: 1200, loss is 3.762861089706421 and perplexity is 43.07148123035219
At time: 750.571031332016 and batch: 1250, loss is 3.738641848564148 and perplexity is 42.040853528093294
At time: 751.7352013587952 and batch: 1300, loss is 3.7535643482208254 and perplexity is 42.67291237044752
At time: 752.8987481594086 and batch: 1350, loss is 3.617462010383606 and perplexity is 37.24292561389296
At time: 754.0697178840637 and batch: 1400, loss is 3.6502306604385377 and perplexity is 38.48354165596193
At time: 755.2356176376343 and batch: 1450, loss is 3.5613779640197754 and perplexity is 35.21168416460478
At time: 756.4000670909882 and batch: 1500, loss is 3.558322319984436 and perplexity is 35.104254009658284
At time: 757.5660119056702 and batch: 1550, loss is 3.57716335773468 and perplexity is 35.77192463744505
At time: 758.7307872772217 and batch: 1600, loss is 3.659063711166382 and perplexity is 38.82497445826898
At time: 759.8970482349396 and batch: 1650, loss is 3.5882717847824095 and perplexity is 36.17150972456847
At time: 761.0632836818695 and batch: 1700, loss is 3.597462410926819 and perplexity is 36.50548089881973
At time: 762.2272005081177 and batch: 1750, loss is 3.607568645477295 and perplexity is 36.87628440875672
At time: 763.3960783481598 and batch: 1800, loss is 3.5531814670562745 and perplexity is 34.92425128284578
At time: 764.5612423419952 and batch: 1850, loss is 3.582871799468994 and perplexity is 35.97671053303764
At time: 765.7263834476471 and batch: 1900, loss is 3.675103497505188 and perplexity is 39.45273990605731
At time: 766.8907334804535 and batch: 1950, loss is 3.618953070640564 and perplexity is 37.2984984810794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385985760356105 and perplexity of 80.31735786988439
finished 16 epochs...
Completing Train Step...
At time: 770.5565490722656 and batch: 50, loss is 3.8742013120651246 and perplexity is 48.14423071514325
At time: 771.7231531143188 and batch: 100, loss is 3.8611103773117064 and perplexity is 47.51808508985123
At time: 772.8871910572052 and batch: 150, loss is 3.8206207227706908 and perplexity is 45.63252467878771
At time: 774.0519123077393 and batch: 200, loss is 3.822416024208069 and perplexity is 45.714522399223455
At time: 775.238174200058 and batch: 250, loss is 3.8137064456939695 and perplexity is 45.31809703204185
At time: 776.4017674922943 and batch: 300, loss is 3.802725796699524 and perplexity is 44.82319704962336
At time: 777.5664277076721 and batch: 350, loss is 3.827956128120422 and perplexity is 45.968488453207314
At time: 778.7295713424683 and batch: 400, loss is 3.809208664894104 and perplexity is 45.11472387212531
At time: 779.891274690628 and batch: 450, loss is 3.8365826988220215 and perplexity is 46.366754233015385
At time: 781.0582976341248 and batch: 500, loss is 3.8487219476699828 and perplexity is 46.93304200092833
At time: 782.2223896980286 and batch: 550, loss is 3.814953646659851 and perplexity is 45.374653067472
At time: 783.3875992298126 and batch: 600, loss is 3.776238317489624 and perplexity is 43.65152931344491
At time: 784.5532145500183 and batch: 650, loss is 3.7901681089401245 and perplexity is 44.263840797919094
At time: 785.7187161445618 and batch: 700, loss is 3.8162350034713746 and perplexity is 45.43283145392627
At time: 786.8834459781647 and batch: 750, loss is 3.764583911895752 and perplexity is 43.1457496912496
At time: 788.0474772453308 and batch: 800, loss is 3.721571583747864 and perplexity is 41.32929554542078
At time: 789.2115652561188 and batch: 850, loss is 3.7274295806884767 and perplexity is 41.57211294971024
At time: 790.3824095726013 and batch: 900, loss is 3.6931039094924927 and perplexity is 40.169335638736605
At time: 791.5456149578094 and batch: 950, loss is 3.8009345960617065 and perplexity is 44.74298157293251
At time: 792.7098784446716 and batch: 1000, loss is 3.7612003755569456 and perplexity is 43.00001117412693
At time: 793.8788111209869 and batch: 1050, loss is 3.7098104190826415 and perplexity is 40.84606215898668
At time: 795.049019575119 and batch: 1100, loss is 3.743903384208679 and perplexity is 42.262635923800765
At time: 796.2146441936493 and batch: 1150, loss is 3.7137868928909303 and perplexity is 41.00880881980023
At time: 797.3826351165771 and batch: 1200, loss is 3.7606925773620605 and perplexity is 42.97818138910447
At time: 798.5514850616455 and batch: 1250, loss is 3.736490612030029 and perplexity is 41.9505109170616
At time: 799.7193479537964 and batch: 1300, loss is 3.751649842262268 and perplexity is 42.59129298077941
At time: 800.8871681690216 and batch: 1350, loss is 3.6159429359436035 and perplexity is 37.18639378642006
At time: 802.0609602928162 and batch: 1400, loss is 3.649081130027771 and perplexity is 38.43932907123835
At time: 803.2331709861755 and batch: 1450, loss is 3.560683913230896 and perplexity is 35.18725394631938
At time: 804.4033811092377 and batch: 1500, loss is 3.5584460258483888 and perplexity is 35.108596880342716
At time: 805.5767860412598 and batch: 1550, loss is 3.5778821897506714 and perplexity is 35.79764788638788
At time: 806.7515664100647 and batch: 1600, loss is 3.659793677330017 and perplexity is 38.853325722400356
At time: 807.9210684299469 and batch: 1650, loss is 3.589528818130493 and perplexity is 36.21700710841617
At time: 809.0921959877014 and batch: 1700, loss is 3.5988962411880494 and perplexity is 36.55786110522184
At time: 810.2588756084442 and batch: 1750, loss is 3.609270091056824 and perplexity is 36.93908080703138
At time: 811.4239315986633 and batch: 1800, loss is 3.5551866483688355 and perplexity is 34.99435099670365
At time: 812.5886430740356 and batch: 1850, loss is 3.585048336982727 and perplexity is 36.05510047150791
At time: 813.7547233104706 and batch: 1900, loss is 3.6772570037841796 and perplexity is 39.53779317767548
At time: 814.9188778400421 and batch: 1950, loss is 3.620851263999939 and perplexity is 37.36936548156707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385243402525436 and perplexity of 80.25775577610877
finished 17 epochs...
Completing Train Step...
At time: 818.5811986923218 and batch: 50, loss is 3.8726395082473757 and perplexity is 48.0690975587073
At time: 819.7471454143524 and batch: 100, loss is 3.8583130979537965 and perplexity is 47.38534946716285
At time: 820.9148917198181 and batch: 150, loss is 3.817244501113892 and perplexity is 45.478718947933466
At time: 822.0809552669525 and batch: 200, loss is 3.818378643989563 and perplexity is 45.530327573268366
At time: 823.2490174770355 and batch: 250, loss is 3.8093319225311277 and perplexity is 45.12028494910032
At time: 824.4150094985962 and batch: 300, loss is 3.798280110359192 and perplexity is 44.62436946477989
At time: 825.5769293308258 and batch: 350, loss is 3.823407516479492 and perplexity is 45.75987047229109
At time: 826.7417109012604 and batch: 400, loss is 3.8046152496337893 and perplexity is 44.907968431360196
At time: 827.9097905158997 and batch: 450, loss is 3.8322617053985595 and perplexity is 46.16683602659055
At time: 829.0717346668243 and batch: 500, loss is 3.8446861124038696 and perplexity is 46.744009683101645
At time: 830.2369039058685 and batch: 550, loss is 3.81083860874176 and perplexity is 45.18831829983842
At time: 831.4020948410034 and batch: 600, loss is 3.7723693370819094 and perplexity is 43.48296869090288
At time: 832.5657207965851 and batch: 650, loss is 3.7863795137405396 and perplexity is 44.09646029185511
At time: 833.7657017707825 and batch: 700, loss is 3.8126266765594483 and perplexity is 45.269190358341476
At time: 834.9298851490021 and batch: 750, loss is 3.7614432859420774 and perplexity is 43.01045759212225
At time: 836.0925109386444 and batch: 800, loss is 3.7187696409225466 and perplexity is 41.213655306617085
At time: 837.2572348117828 and batch: 850, loss is 3.7248178148269653 and perplexity is 41.46367798932029
At time: 838.4217112064362 and batch: 900, loss is 3.6910346651077273 and perplexity is 40.086301405214925
At time: 839.5857131481171 and batch: 950, loss is 3.799025983810425 and perplexity is 44.65766601320377
At time: 840.7504618167877 and batch: 1000, loss is 3.759348759651184 and perplexity is 42.920465336384964
At time: 841.9165766239166 and batch: 1050, loss is 3.7080533933639526 and perplexity is 40.77435758909973
At time: 843.0857949256897 and batch: 1100, loss is 3.7420234727859496 and perplexity is 42.18326054449057
At time: 844.2484736442566 and batch: 1150, loss is 3.7120226716995237 and perplexity is 40.93652399220706
At time: 845.4160034656525 and batch: 1200, loss is 3.7590803718566894 and perplexity is 42.90894755304003
At time: 846.5797207355499 and batch: 1250, loss is 3.7349529314041137 and perplexity is 41.88605399895476
At time: 847.7476818561554 and batch: 1300, loss is 3.750245895385742 and perplexity is 42.531539023537576
At time: 848.9104752540588 and batch: 1350, loss is 3.6146852493286135 and perplexity is 37.13965435463495
At time: 850.0745778083801 and batch: 1400, loss is 3.6479540348052977 and perplexity is 38.39602869349538
At time: 851.2409241199493 and batch: 1450, loss is 3.559822473526001 and perplexity is 35.15695530076562
At time: 852.4070508480072 and batch: 1500, loss is 3.5580672073364257 and perplexity is 35.09529961269998
At time: 853.572482585907 and batch: 1550, loss is 3.5777607011795043 and perplexity is 35.793299145461525
At time: 854.7404656410217 and batch: 1600, loss is 3.6597248220443728 and perplexity is 38.85065055766018
At time: 855.9067153930664 and batch: 1650, loss is 3.5897768688201905 and perplexity is 36.22599187630105
At time: 857.0743110179901 and batch: 1700, loss is 3.599294967651367 and perplexity is 36.57244059830848
At time: 858.2423181533813 and batch: 1750, loss is 3.609759044647217 and perplexity is 36.95714671955427
At time: 859.4105582237244 and batch: 1800, loss is 3.5558246994018554 and perplexity is 35.016686303281936
At time: 860.5772478580475 and batch: 1850, loss is 3.5858030796051024 and perplexity is 36.08232306432107
At time: 861.7437558174133 and batch: 1900, loss is 3.6779042291641235 and perplexity is 39.563391323878406
At time: 862.9115788936615 and batch: 1950, loss is 3.6213387966156008 and perplexity is 37.38758870791358
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38492545194404 and perplexity of 80.2322418322998
finished 18 epochs...
Completing Train Step...
At time: 866.5693233013153 and batch: 50, loss is 3.870780210494995 and perplexity is 47.97980582933666
At time: 867.7588815689087 and batch: 100, loss is 3.855773506164551 and perplexity is 47.26516269998469
At time: 868.9237351417542 and batch: 150, loss is 3.8144799852371216 and perplexity is 45.353165933959055
At time: 870.0935678482056 and batch: 200, loss is 3.8153494119644167 and perplexity is 45.3926143348516
At time: 871.2626378536224 and batch: 250, loss is 3.8060785293579102 and perplexity is 44.97372945266794
At time: 872.428929567337 and batch: 300, loss is 3.794985156059265 and perplexity is 44.47757617812374
At time: 873.5938985347748 and batch: 350, loss is 3.8200389623641966 and perplexity is 45.60598520323778
At time: 874.7583990097046 and batch: 400, loss is 3.801245813369751 and perplexity is 44.756908530254194
At time: 875.9193122386932 and batch: 450, loss is 3.8291040658950806 and perplexity is 46.02128771688326
At time: 877.0845296382904 and batch: 500, loss is 3.8416506099700927 and perplexity is 46.60233326628523
At time: 878.249579668045 and batch: 550, loss is 3.8078195905685424 and perplexity is 45.05209967239333
At time: 879.4122061729431 and batch: 600, loss is 3.769535331726074 and perplexity is 43.359912178514406
At time: 880.5751497745514 and batch: 650, loss is 3.7835719394683838 and perplexity is 43.97282983649888
At time: 881.739021062851 and batch: 700, loss is 3.8099800634384153 and perplexity is 45.14953873078652
At time: 882.9020228385925 and batch: 750, loss is 3.7590861082077027 and perplexity is 42.909193694530785
At time: 884.0661327838898 and batch: 800, loss is 3.716613521575928 and perplexity is 41.124889476315886
At time: 885.2310271263123 and batch: 850, loss is 3.7227526807785036 and perplexity is 41.37813829200146
At time: 886.395339012146 and batch: 900, loss is 3.6892922830581667 and perplexity is 40.01651656679306
At time: 887.560786485672 and batch: 950, loss is 3.7973353242874146 and perplexity is 44.58222889209541
At time: 888.7272131443024 and batch: 1000, loss is 3.75768039226532 and perplexity is 42.84891793210527
At time: 889.8910157680511 and batch: 1050, loss is 3.706469802856445 and perplexity is 40.709838802623956
At time: 891.0985958576202 and batch: 1100, loss is 3.7403626918792723 and perplexity is 42.113261533396674
At time: 892.263396024704 and batch: 1150, loss is 3.7104597234725953 and perplexity is 40.87259229859482
At time: 893.4284904003143 and batch: 1200, loss is 3.757657766342163 and perplexity is 42.84794844674858
At time: 894.5932085514069 and batch: 1250, loss is 3.733621425628662 and perplexity is 41.83031958972249
At time: 895.7585294246674 and batch: 1300, loss is 3.749022002220154 and perplexity is 42.479516804917374
At time: 896.9223544597626 and batch: 1350, loss is 3.6135514688491823 and perplexity is 37.09757000123217
At time: 898.0843591690063 and batch: 1400, loss is 3.646884412765503 and perplexity is 38.35498141141651
At time: 899.2474949359894 and batch: 1450, loss is 3.5589655017852784 and perplexity is 35.12683968953997
At time: 900.411388874054 and batch: 1500, loss is 3.557529230117798 and perplexity is 35.07642421874864
At time: 901.5795731544495 and batch: 1550, loss is 3.57735267162323 and perplexity is 35.778697400667916
At time: 902.7435309886932 and batch: 1600, loss is 3.6594028186798098 and perplexity is 38.8381425313865
At time: 903.9062104225159 and batch: 1650, loss is 3.5896452856063843 and perplexity is 36.22122545746388
At time: 905.0700244903564 and batch: 1700, loss is 3.599280204772949 and perplexity is 36.571900687799804
At time: 906.23264336586 and batch: 1750, loss is 3.6097844886779784 and perplexity is 36.95808707029536
At time: 907.3991186618805 and batch: 1800, loss is 3.5559346199035646 and perplexity is 35.020535566561186
At time: 908.5631227493286 and batch: 1850, loss is 3.585998578071594 and perplexity is 36.08937779271943
At time: 909.7282371520996 and batch: 1900, loss is 3.677996907234192 and perplexity is 39.567058152546345
At time: 910.8922526836395 and batch: 1950, loss is 3.6213286113739014 and perplexity is 37.3872079082253
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384796284520349 and perplexity of 80.22187910960287
finished 19 epochs...
Completing Train Step...
At time: 914.5314929485321 and batch: 50, loss is 3.8689177799224854 and perplexity is 47.89052993298196
At time: 915.7191233634949 and batch: 100, loss is 3.853468294143677 and perplexity is 47.15633196591223
At time: 916.8824465274811 and batch: 150, loss is 3.812061657905579 and perplexity is 45.24361964598846
At time: 918.046516418457 and batch: 200, loss is 3.8128033304214477 and perplexity is 45.27718804203792
At time: 919.2124834060669 and batch: 250, loss is 3.8033543062210082 and perplexity is 44.85137771073166
At time: 920.4024169445038 and batch: 300, loss is 3.792228045463562 and perplexity is 44.35511547799415
At time: 921.5675933361053 and batch: 350, loss is 3.8172219228744506 and perplexity is 45.47769213011949
At time: 922.7342932224274 and batch: 400, loss is 3.7984437322616578 and perplexity is 44.63167158638527
At time: 923.9003281593323 and batch: 450, loss is 3.8264799547195434 and perplexity is 45.90068105332732
At time: 925.0648620128632 and batch: 500, loss is 3.8390794467926024 and perplexity is 46.4826649722874
At time: 926.2304022312164 and batch: 550, loss is 3.8052936887741087 and perplexity is 44.938446092306286
At time: 927.3953454494476 and batch: 600, loss is 3.767166452407837 and perplexity is 43.257319342313814
At time: 928.5606834888458 and batch: 650, loss is 3.7812162494659423 and perplexity is 43.86936539379668
At time: 929.7245910167694 and batch: 700, loss is 3.807754969596863 and perplexity is 45.04918845600013
At time: 930.8898968696594 and batch: 750, loss is 3.7570615243911742 and perplexity is 42.8224083171758
At time: 932.0582225322723 and batch: 800, loss is 3.7147366905212404 and perplexity is 41.047777392438576
At time: 933.2217094898224 and batch: 850, loss is 3.720922713279724 and perplexity is 41.30248688468707
At time: 934.3868045806885 and batch: 900, loss is 3.6876696443557737 and perplexity is 39.95163687066525
At time: 935.5520687103271 and batch: 950, loss is 3.795734028816223 and perplexity is 44.51089669807668
At time: 936.7195174694061 and batch: 1000, loss is 3.7560998678207396 and perplexity is 42.781247661235426
At time: 937.8924713134766 and batch: 1050, loss is 3.7049704122543337 and perplexity is 40.64884459141049
At time: 939.0589556694031 and batch: 1100, loss is 3.738828763961792 and perplexity is 42.04871234539188
At time: 940.2222168445587 and batch: 1150, loss is 3.7090237855911257 and perplexity is 40.81394391279617
At time: 941.3833773136139 and batch: 1200, loss is 3.756357865333557 and perplexity is 42.792286540667746
At time: 942.5485167503357 and batch: 1250, loss is 3.732410178184509 and perplexity is 41.77968339470303
At time: 943.7139184474945 and batch: 1300, loss is 3.74791081905365 and perplexity is 42.43234049653655
At time: 944.8802638053894 and batch: 1350, loss is 3.612503671646118 and perplexity is 37.05871962835484
At time: 946.0452969074249 and batch: 1400, loss is 3.6458762645721436 and perplexity is 38.31633339093963
At time: 947.2124989032745 and batch: 1450, loss is 3.55813579082489 and perplexity is 35.097706653316806
At time: 948.3800325393677 and batch: 1500, loss is 3.556926202774048 and perplexity is 35.05527855217213
At time: 949.5453991889954 and batch: 1550, loss is 3.5768204641342165 and perplexity is 35.759660776130545
At time: 950.7105345726013 and batch: 1600, loss is 3.6589705038070677 and perplexity is 38.8213558535672
At time: 951.8760316371918 and batch: 1650, loss is 3.589329032897949 and perplexity is 36.20977220796616
At time: 953.041759967804 and batch: 1700, loss is 3.5990608739852905 and perplexity is 36.56388022361529
At time: 954.2077233791351 and batch: 1750, loss is 3.609586229324341 and perplexity is 36.95076051014467
At time: 955.3755526542664 and batch: 1800, loss is 3.5557921743392944 and perplexity is 35.015547401890764
At time: 956.5420138835907 and batch: 1850, loss is 3.585928158760071 and perplexity is 36.086836493061305
At time: 957.71151471138 and batch: 1900, loss is 3.677842450141907 and perplexity is 39.56094721174505
At time: 958.877897977829 and batch: 1950, loss is 3.6211057567596434 and perplexity is 37.37887692476227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384776128724564 and perplexity of 80.22026219008522
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f6867fdeb38>
ELAPSED
1979.155421257019


RESULTS SO FAR:
[{'best_accuracy': -78.24843512754734, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}}, {'best_accuracy': -80.22026219008522, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.862353544247577, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.936075502546612}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.3679014798345962, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.3008932223994304}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6890935897827148 and batch: 50, loss is 7.441168975830078 and perplexity is 1704.7418588653159
At time: 2.9171559810638428 and batch: 100, loss is 6.5518199062347415 and perplexity is 700.51789131908
At time: 4.145088195800781 and batch: 150, loss is 6.1944904804229735 and perplexity is 490.0416955398649
At time: 5.372264623641968 and batch: 200, loss is 6.053447370529175 and perplexity is 425.57762786076944
At time: 6.605898857116699 and batch: 250, loss is 5.953166770935058 and perplexity is 384.9705242375966
At time: 7.8355183601379395 and batch: 300, loss is 5.872796573638916 and perplexity is 355.24105017930947
At time: 9.063889265060425 and batch: 350, loss is 5.818042554855347 and perplexity is 336.31309446842016
At time: 10.296124696731567 and batch: 400, loss is 5.755462446212769 and perplexity is 315.9116058752433
At time: 11.52522897720337 and batch: 450, loss is 5.6782676792144775 and perplexity is 292.44238684342156
At time: 12.780385971069336 and batch: 500, loss is 5.645869741439819 and perplexity is 283.11969009775686
At time: 14.009071111679077 and batch: 550, loss is 5.5963764572143555 and perplexity is 269.4482789838465
At time: 15.238203763961792 and batch: 600, loss is 5.620613470077514 and perplexity is 276.05868504158735
At time: 16.467791080474854 and batch: 650, loss is 5.692173709869385 and perplexity is 296.53750708158304
At time: 17.69911527633667 and batch: 700, loss is 5.606265068054199 and perplexity is 272.12596563713635
At time: 18.930582523345947 and batch: 750, loss is 5.54581166267395 and perplexity is 256.16241135443727
At time: 20.161355018615723 and batch: 800, loss is 5.536982183456421 and perplexity is 253.91058651665512
At time: 21.393355131149292 and batch: 850, loss is 5.5485631942749025 and perplexity is 256.86822090759745
At time: 22.626710414886475 and batch: 900, loss is 5.549813327789306 and perplexity is 257.1895412841776
At time: 23.858425855636597 and batch: 950, loss is 5.586741304397583 and perplexity is 266.86457083945635
At time: 25.091086387634277 and batch: 1000, loss is 5.55399673461914 and perplexity is 258.26772343260075
At time: 26.32210373878479 and batch: 1050, loss is 5.449345512390137 and perplexity is 232.6058784125564
At time: 27.554076194763184 and batch: 1100, loss is 5.538511781692505 and perplexity is 254.29926488700735
At time: 28.786102771759033 and batch: 1150, loss is 5.438019580841065 and perplexity is 229.98626295135782
At time: 30.01764440536499 and batch: 1200, loss is 5.5140199375152585 and perplexity is 248.1466588023047
At time: 31.249531507492065 and batch: 1250, loss is 5.446886901855469 and perplexity is 232.03469359769028
At time: 32.481826305389404 and batch: 1300, loss is 5.467542371749878 and perplexity is 236.87732041830148
At time: 33.713295698165894 and batch: 1350, loss is 5.4131597232818605 and perplexity is 224.33931914366661
At time: 34.947330474853516 and batch: 1400, loss is 5.427659492492676 and perplexity is 227.6158848130339
At time: 36.17780351638794 and batch: 1450, loss is 5.383565549850464 and perplexity is 217.79746032558643
At time: 37.40856456756592 and batch: 1500, loss is 5.3683607959747315 and perplexity is 214.51095213622108
At time: 38.64380860328674 and batch: 1550, loss is 5.347588262557983 and perplexity is 210.10097795622275
At time: 39.875378131866455 and batch: 1600, loss is 5.3866321849823 and perplexity is 218.46639082770247
At time: 41.106165170669556 and batch: 1650, loss is 5.357544622421265 and perplexity is 212.20326710757175
At time: 42.337719678878784 and batch: 1700, loss is 5.365660200119018 and perplexity is 213.93242628174897
At time: 43.567896366119385 and batch: 1750, loss is 5.38409234046936 and perplexity is 217.91222421012029
At time: 44.79750919342041 and batch: 1800, loss is 5.368112869262696 and perplexity is 214.45777573336
At time: 46.02784180641174 and batch: 1850, loss is 5.345221891403198 and perplexity is 209.60438885119157
At time: 47.259124994277954 and batch: 1900, loss is 5.3572935962677 and perplexity is 212.1500052229987
At time: 48.49003481864929 and batch: 1950, loss is 5.2944310283660885 and perplexity is 199.22424077136324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.919891783248547 and perplexity of 136.98778801090998
finished 1 epochs...
Completing Train Step...
At time: 52.134400606155396 and batch: 50, loss is 5.14903790473938 and perplexity is 172.26567457529868
At time: 53.31836748123169 and batch: 100, loss is 5.07414101600647 and perplexity is 159.83483742819237
At time: 54.4766960144043 and batch: 150, loss is 5.000466194152832 and perplexity is 148.48236457989455
At time: 55.636011838912964 and batch: 200, loss is 4.981693515777588 and perplexity is 145.72095354193618
At time: 56.792975664138794 and batch: 250, loss is 4.983723039627075 and perplexity is 146.0169980055529
At time: 57.950055837631226 and batch: 300, loss is 4.989982185363769 and perplexity is 146.93380590007698
At time: 59.10737752914429 and batch: 350, loss is 4.980329208374023 and perplexity is 145.52228092224377
At time: 60.26435947418213 and batch: 400, loss is 4.9437590503692626 and perplexity is 140.2966417156902
At time: 61.42118191719055 and batch: 450, loss is 4.922325611114502 and perplexity is 137.32159876084125
At time: 62.57688236236572 and batch: 500, loss is 4.913202524185181 and perplexity is 136.07449922654004
At time: 63.7341423034668 and batch: 550, loss is 4.866555089950562 and perplexity is 129.8727454585546
At time: 64.89107012748718 and batch: 600, loss is 4.845702447891235 and perplexity is 127.19259679196577
At time: 66.04831218719482 and batch: 650, loss is 4.91195369720459 and perplexity is 135.9046717851524
At time: 67.20712614059448 and batch: 700, loss is 4.906364374160766 and perplexity is 135.14717558890072
At time: 68.36623764038086 and batch: 750, loss is 4.8740506267547605 and perplexity is 130.84986885939628
At time: 69.5261218547821 and batch: 800, loss is 4.840190563201904 and perplexity is 126.49345443119427
At time: 70.68522477149963 and batch: 850, loss is 4.8376031017303465 and perplexity is 126.16658056058958
At time: 71.84497737884521 and batch: 900, loss is 4.844151620864868 and perplexity is 126.99549594946704
At time: 73.00613212585449 and batch: 950, loss is 4.902344799041748 and perplexity is 134.60503168851506
At time: 74.16525959968567 and batch: 1000, loss is 4.876286897659302 and perplexity is 131.14281204206583
At time: 75.3251211643219 and batch: 1050, loss is 4.786912326812744 and perplexity is 119.93049022316579
At time: 76.48610758781433 and batch: 1100, loss is 4.8693804264068605 and perplexity is 130.24019850578986
At time: 77.6477472782135 and batch: 1150, loss is 4.784875087738037 and perplexity is 119.68641184965169
At time: 78.80870246887207 and batch: 1200, loss is 4.865626306533813 and perplexity is 129.75217780557065
At time: 79.96852660179138 and batch: 1250, loss is 4.816620492935181 and perplexity is 123.5468569898229
At time: 81.1297037601471 and batch: 1300, loss is 4.8436563777923585 and perplexity is 126.93261788110718
At time: 82.2889838218689 and batch: 1350, loss is 4.7401887226104735 and perplexity is 114.45580003941248
At time: 83.44901585578918 and batch: 1400, loss is 4.760987977981568 and perplexity is 116.86132529986266
At time: 84.60915660858154 and batch: 1450, loss is 4.691989908218384 and perplexity is 109.07000330239228
At time: 85.76787900924683 and batch: 1500, loss is 4.680013761520386 and perplexity is 107.77155566165595
At time: 86.92881774902344 and batch: 1550, loss is 4.675639247894287 and perplexity is 107.30113719907028
At time: 88.0878632068634 and batch: 1600, loss is 4.756997690200806 and perplexity is 116.39594410142824
At time: 89.24884748458862 and batch: 1650, loss is 4.713075218200683 and perplexity is 111.3941951760594
At time: 90.40629887580872 and batch: 1700, loss is 4.735224304199218 and perplexity is 113.88900163472275
At time: 91.56578922271729 and batch: 1750, loss is 4.742856044769287 and perplexity is 114.76149804735411
At time: 92.72360229492188 and batch: 1800, loss is 4.692883148193359 and perplexity is 109.16747251463033
At time: 93.88085985183716 and batch: 1850, loss is 4.712027263641358 and perplexity is 111.27752026702147
At time: 95.04038190841675 and batch: 1900, loss is 4.775085945129394 and perplexity is 118.52050044275254
At time: 96.19584369659424 and batch: 1950, loss is 4.702803440093994 and perplexity is 110.25583522023145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.603117051235465 and perplexity of 99.79489714868187
finished 2 epochs...
Completing Train Step...
At time: 99.85910487174988 and batch: 50, loss is 4.652878465652466 and perplexity is 104.88646355470375
At time: 101.04552555084229 and batch: 100, loss is 4.59842619895935 and perplexity is 99.3278702616903
At time: 102.206303358078 and batch: 150, loss is 4.544458465576172 and perplexity is 94.10944990094005
At time: 103.36775088310242 and batch: 200, loss is 4.54253547668457 and perplexity is 93.92865236572575
At time: 104.52864241600037 and batch: 250, loss is 4.539535055160522 and perplexity is 93.64724919062624
At time: 105.68881154060364 and batch: 300, loss is 4.559058179855347 and perplexity is 95.49349976243765
At time: 106.84997057914734 and batch: 350, loss is 4.582010183334351 and perplexity is 97.71061316911798
At time: 108.00945544242859 and batch: 400, loss is 4.542212591171265 and perplexity is 93.89832906033405
At time: 109.16907095909119 and batch: 450, loss is 4.545777168273926 and perplexity is 94.23363414946418
At time: 110.3296160697937 and batch: 500, loss is 4.550344820022583 and perplexity is 94.66504509067983
At time: 111.51486659049988 and batch: 550, loss is 4.5029588794708255 and perplexity is 90.2838755798241
At time: 112.67486381530762 and batch: 600, loss is 4.480759315490722 and perplexity is 88.30169607216428
At time: 113.83452463150024 and batch: 650, loss is 4.535028991699218 and perplexity is 93.22621805171806
At time: 114.99627184867859 and batch: 700, loss is 4.562164106369019 and perplexity is 95.79055663483766
At time: 116.15504693984985 and batch: 750, loss is 4.5309285545349125 and perplexity is 92.84473246587957
At time: 117.31411290168762 and batch: 800, loss is 4.506429634094238 and perplexity is 90.59777317407124
At time: 118.47474980354309 and batch: 850, loss is 4.503403348922729 and perplexity is 90.32401292376967
At time: 119.63637113571167 and batch: 900, loss is 4.493512573242188 and perplexity is 89.43504192686763
At time: 120.7978310585022 and batch: 950, loss is 4.5660855579376225 and perplexity is 96.1669321502702
At time: 121.96022534370422 and batch: 1000, loss is 4.553247308731079 and perplexity is 94.9402084512435
At time: 123.11996793746948 and batch: 1050, loss is 4.475100421905518 and perplexity is 87.80341735352187
At time: 124.2793550491333 and batch: 1100, loss is 4.538799800872803 and perplexity is 93.57841995572149
At time: 125.44140481948853 and batch: 1150, loss is 4.480385398864746 and perplexity is 88.26868477202255
At time: 126.60412526130676 and batch: 1200, loss is 4.552712898254395 and perplexity is 94.88948496397732
At time: 127.7648823261261 and batch: 1250, loss is 4.526562995910645 and perplexity is 92.44029677950914
At time: 128.92838096618652 and batch: 1300, loss is 4.53382755279541 and perplexity is 93.11427970350383
At time: 130.09264874458313 and batch: 1350, loss is 4.4111189365386965 and perplexity is 82.36156933361461
At time: 131.2530484199524 and batch: 1400, loss is 4.439852132797241 and perplexity is 84.76240716708269
At time: 132.4150357246399 and batch: 1450, loss is 4.374320240020752 and perplexity is 79.38585787794533
At time: 133.57828497886658 and batch: 1500, loss is 4.37256112575531 and perplexity is 79.2463318399799
At time: 134.74040174484253 and batch: 1550, loss is 4.368257846832275 and perplexity is 78.90604546915313
At time: 135.9049093723297 and batch: 1600, loss is 4.468957643508912 and perplexity is 87.26571360653095
At time: 137.07189321517944 and batch: 1650, loss is 4.414670238494873 and perplexity is 82.65458011283148
At time: 138.2342004776001 and batch: 1700, loss is 4.441115217208862 and perplexity is 84.86953688496254
At time: 139.3959527015686 and batch: 1750, loss is 4.450972738265992 and perplexity is 85.71027713132224
At time: 140.55716490745544 and batch: 1800, loss is 4.398273591995239 and perplexity is 81.3103725450188
At time: 141.7190134525299 and batch: 1850, loss is 4.431453924179078 and perplexity is 84.05353558083065
At time: 142.8804588317871 and batch: 1900, loss is 4.507339286804199 and perplexity is 90.68022317870512
At time: 144.04817056655884 and batch: 1950, loss is 4.439666051864624 and perplexity is 84.7466359667115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.506572208848111 and perplexity of 90.61069105014253
finished 3 epochs...
Completing Train Step...
At time: 147.720778465271 and batch: 50, loss is 4.39594603061676 and perplexity is 81.12133774260789
At time: 148.88360977172852 and batch: 100, loss is 4.349494371414185 and perplexity is 77.43929750203402
At time: 150.04814791679382 and batch: 150, loss is 4.303156681060791 and perplexity is 73.93280802501364
At time: 151.20832085609436 and batch: 200, loss is 4.308275022506714 and perplexity is 74.31219145928071
At time: 152.37130093574524 and batch: 250, loss is 4.3017361450195315 and perplexity is 73.82785836661706
At time: 153.53127145767212 and batch: 300, loss is 4.322183418273926 and perplexity is 75.35297587149005
At time: 154.6976101398468 and batch: 350, loss is 4.342610025405884 and perplexity is 76.90800946705191
At time: 155.85909628868103 and batch: 400, loss is 4.302908935546875 and perplexity is 73.91449377222487
At time: 157.0204918384552 and batch: 450, loss is 4.318995952606201 and perplexity is 75.11317323231012
At time: 158.1823341846466 and batch: 500, loss is 4.327306327819824 and perplexity is 75.73999283091963
At time: 159.34522461891174 and batch: 550, loss is 4.28561900138855 and perplexity is 72.64750170915121
At time: 160.50799655914307 and batch: 600, loss is 4.262483744621277 and perplexity is 70.98607596369938
At time: 161.67014598846436 and batch: 650, loss is 4.316335573196411 and perplexity is 74.91360926847216
At time: 162.831862449646 and batch: 700, loss is 4.350953121185302 and perplexity is 77.55234449313028
At time: 163.99398469924927 and batch: 750, loss is 4.323430976867676 and perplexity is 75.44704178827423
At time: 165.15815782546997 and batch: 800, loss is 4.294809813499451 and perplexity is 73.31826897394343
At time: 166.31957244873047 and batch: 850, loss is 4.292220010757446 and perplexity is 73.12863478347981
At time: 167.48289155960083 and batch: 900, loss is 4.279816389083862 and perplexity is 72.22717709159875
At time: 168.66791820526123 and batch: 950, loss is 4.362242155075073 and perplexity is 78.43279591074835
At time: 169.8297758102417 and batch: 1000, loss is 4.344612369537353 and perplexity is 77.06216004822298
At time: 170.99184799194336 and batch: 1050, loss is 4.277813787460327 and perplexity is 72.08267956327539
At time: 172.15405869483948 and batch: 1100, loss is 4.3338073635101315 and perplexity is 76.23398521875117
At time: 173.31795191764832 and batch: 1150, loss is 4.2894203042984005 and perplexity is 72.92418240919928
At time: 174.4789001941681 and batch: 1200, loss is 4.355406126976013 and perplexity is 77.89845557764613
At time: 175.642333984375 and batch: 1250, loss is 4.336569604873657 and perplexity is 76.44485298578661
At time: 176.80543780326843 and batch: 1300, loss is 4.336134786605835 and perplexity is 76.41162059277681
At time: 177.96986770629883 and batch: 1350, loss is 4.20742160320282 and perplexity is 67.1830916288108
At time: 179.13468170166016 and batch: 1400, loss is 4.240222783088684 and perplexity is 69.42331645693048
At time: 180.29987597465515 and batch: 1450, loss is 4.175048241615295 and perplexity is 65.04297736362408
At time: 181.46304607391357 and batch: 1500, loss is 4.1725055122375485 and perplexity is 64.87780076295837
At time: 182.62713623046875 and batch: 1550, loss is 4.174459075927734 and perplexity is 65.00466755966376
At time: 183.79089760780334 and batch: 1600, loss is 4.279386849403381 and perplexity is 72.19615931518855
At time: 184.95450901985168 and batch: 1650, loss is 4.225686898231507 and perplexity is 68.42148600836273
At time: 186.11851620674133 and batch: 1700, loss is 4.249835729598999 and perplexity is 70.09389704832657
At time: 187.28241991996765 and batch: 1750, loss is 4.260950698852539 and perplexity is 70.87733443447182
At time: 188.44441413879395 and batch: 1800, loss is 4.209211001396179 and perplexity is 67.30341655409146
At time: 189.6075074672699 and batch: 1850, loss is 4.246566410064697 and perplexity is 69.86511189114277
At time: 190.77063250541687 and batch: 1900, loss is 4.32628643989563 and perplexity is 75.66278590475105
At time: 191.94133400917053 and batch: 1950, loss is 4.261073627471924 and perplexity is 70.88604782289099
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47078119322311 and perplexity of 87.424992155676
finished 4 epochs...
Completing Train Step...
At time: 195.58582663536072 and batch: 50, loss is 4.222579674720764 and perplexity is 68.20921511573846
At time: 196.75032114982605 and batch: 100, loss is 4.184016785621643 and perplexity is 65.62894186496655
At time: 197.93503952026367 and batch: 150, loss is 4.140457310676575 and perplexity is 62.83154841804354
At time: 199.09833550453186 and batch: 200, loss is 4.141831908226013 and perplexity is 62.91797589841892
At time: 200.26314973831177 and batch: 250, loss is 4.13215853691101 and perplexity is 62.312281232970676
At time: 201.4277160167694 and batch: 300, loss is 4.151805734634399 and perplexity is 63.54864875064824
At time: 202.59073138237 and batch: 350, loss is 4.171254277229309 and perplexity is 64.79667415219816
At time: 203.75866413116455 and batch: 400, loss is 4.135049471855163 and perplexity is 62.492682622935966
At time: 204.92452549934387 and batch: 450, loss is 4.157740664482117 and perplexity is 63.92692693980562
At time: 206.0899474620819 and batch: 500, loss is 4.171991214752198 and perplexity is 64.84444285185106
At time: 207.2540352344513 and batch: 550, loss is 4.131382517814636 and perplexity is 62.26394447034639
At time: 208.41684222221375 and batch: 600, loss is 4.11035551071167 and perplexity is 60.96838863247856
At time: 209.5801079273224 and batch: 650, loss is 4.161048665046692 and perplexity is 64.13874740816824
At time: 210.74405717849731 and batch: 700, loss is 4.196882901191711 and perplexity is 66.47878679391772
At time: 211.90848422050476 and batch: 750, loss is 4.16969063282013 and perplexity is 64.69543436706614
At time: 213.07225680351257 and batch: 800, loss is 4.139751462936402 and perplexity is 62.78721455989855
At time: 214.23602294921875 and batch: 850, loss is 4.137854843139649 and perplexity is 62.6682439424585
At time: 215.4026780128479 and batch: 900, loss is 4.124134864807129 and perplexity is 61.814308377360526
At time: 216.56746888160706 and batch: 950, loss is 4.214650745391846 and perplexity is 67.67052749970162
At time: 217.73149967193604 and batch: 1000, loss is 4.194573917388916 and perplexity is 66.32546542837414
At time: 218.89623093605042 and batch: 1050, loss is 4.135168657302857 and perplexity is 62.500131285169196
At time: 220.05828428268433 and batch: 1100, loss is 4.1799263715744015 and perplexity is 65.36104060632441
At time: 221.22321462631226 and batch: 1150, loss is 4.1426946687698365 and perplexity is 62.97228246893583
At time: 222.38928270339966 and batch: 1200, loss is 4.207693333625794 and perplexity is 67.2013497992536
At time: 223.55336618423462 and batch: 1250, loss is 4.19173460483551 and perplexity is 66.13741379678655
At time: 224.71737790107727 and batch: 1300, loss is 4.1901257038116455 and perplexity is 66.03109079853884
At time: 225.88225054740906 and batch: 1350, loss is 4.059397568702698 and perplexity is 57.93939605753258
At time: 227.04806876182556 and batch: 1400, loss is 4.095751352310181 and perplexity is 60.08446680488637
At time: 228.21347641944885 and batch: 1450, loss is 4.022577195167542 and perplexity is 55.84484358813306
At time: 229.37790536880493 and batch: 1500, loss is 4.0284771156311034 and perplexity is 56.175297591204995
At time: 230.54490327835083 and batch: 1550, loss is 4.0332224082946775 and perplexity is 56.44249929247559
At time: 231.71083283424377 and batch: 1600, loss is 4.140571279525757 and perplexity is 62.838709665380875
At time: 232.874507188797 and batch: 1650, loss is 4.0816720724105835 and perplexity is 59.24444808455648
At time: 234.03740119934082 and batch: 1700, loss is 4.110304780006409 and perplexity is 60.965295741577556
At time: 235.20599794387817 and batch: 1750, loss is 4.120017738342285 and perplexity is 61.560334233023426
At time: 236.3720245361328 and batch: 1800, loss is 4.067958769798278 and perplexity is 58.43755626069355
At time: 237.53784227371216 and batch: 1850, loss is 4.1094656085968015 and perplexity is 60.91415686855408
At time: 238.7032012939453 and batch: 1900, loss is 4.189890828132629 and perplexity is 66.01558352246363
At time: 239.86838722229004 and batch: 1950, loss is 4.126412281990051 and perplexity is 61.95524577111488
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.462789846021075 and perplexity of 86.72913281922752
finished 5 epochs...
Completing Train Step...
At time: 243.53250765800476 and batch: 50, loss is 4.086590423583984 and perplexity is 59.53655082841258
At time: 244.69572973251343 and batch: 100, loss is 4.049765524864196 and perplexity is 57.38400034660298
At time: 245.85857033729553 and batch: 150, loss is 4.011399450302124 and perplexity is 55.224099894836414
At time: 247.01985836029053 and batch: 200, loss is 4.013377695083618 and perplexity is 55.33345481200024
At time: 248.18148493766785 and batch: 250, loss is 4.001037001609802 and perplexity is 54.65479776944125
At time: 249.3438024520874 and batch: 300, loss is 4.020014667510987 and perplexity is 55.70192282936898
At time: 250.50411987304688 and batch: 350, loss is 4.036272211074829 and perplexity is 56.61490054501655
At time: 251.66739988327026 and batch: 400, loss is 4.007383666038513 and perplexity is 55.002776514412076
At time: 252.82808256149292 and batch: 450, loss is 4.030072278976441 and perplexity is 56.26497787517049
At time: 253.99000716209412 and batch: 500, loss is 4.046457104682922 and perplexity is 57.19446366814347
At time: 255.15293884277344 and batch: 550, loss is 4.0100365829467775 and perplexity is 55.14888803539689
At time: 256.3377606868744 and batch: 600, loss is 3.992760214805603 and perplexity is 54.20429857516206
At time: 257.50049209594727 and batch: 650, loss is 4.039806118011475 and perplexity is 56.81532626911378
At time: 258.663213968277 and batch: 700, loss is 4.073837242126465 and perplexity is 58.78209149636475
At time: 259.82699704170227 and batch: 750, loss is 4.050907182693481 and perplexity is 57.449550650763584
At time: 260.99010276794434 and batch: 800, loss is 4.02127022266388 and perplexity is 55.771903588761724
At time: 262.1527955532074 and batch: 850, loss is 4.013421449661255 and perplexity is 55.33587595691242
At time: 263.3140661716461 and batch: 900, loss is 4.002375469207764 and perplexity is 54.72800042409094
At time: 264.482120513916 and batch: 950, loss is 4.094381647109985 and perplexity is 60.00222513453226
At time: 265.64610385894775 and batch: 1000, loss is 4.072667279243469 and perplexity is 58.71335884629406
At time: 266.8076994419098 and batch: 1050, loss is 4.020550446510315 and perplexity is 55.73177474614411
At time: 267.9706139564514 and batch: 1100, loss is 4.059979996681213 and perplexity is 57.97315141193197
At time: 269.1330964565277 and batch: 1150, loss is 4.024132618904114 and perplexity is 55.93177357236951
At time: 270.2957093715668 and batch: 1200, loss is 4.0945787572860715 and perplexity is 60.01405334938654
At time: 271.4567537307739 and batch: 1250, loss is 4.077307586669922 and perplexity is 58.98643998158182
At time: 272.6180338859558 and batch: 1300, loss is 4.070684304237366 and perplexity is 58.59704708295062
At time: 273.78174352645874 and batch: 1350, loss is 3.9433587694168093 and perplexity is 51.59159488617949
At time: 274.9477479457855 and batch: 1400, loss is 3.9788324308395384 and perplexity is 53.45458585226052
At time: 276.11275124549866 and batch: 1450, loss is 3.9059894847869874 and perplexity is 49.69923222464533
At time: 277.27512979507446 and batch: 1500, loss is 3.912170581817627 and perplexity is 50.00737936397061
At time: 278.44091057777405 and batch: 1550, loss is 3.917229971885681 and perplexity is 50.261027313351
At time: 279.60374331474304 and batch: 1600, loss is 4.029868655204773 and perplexity is 56.25352215453083
At time: 280.7660472393036 and batch: 1650, loss is 3.968836269378662 and perplexity is 52.92290698242026
At time: 281.9274604320526 and batch: 1700, loss is 3.99716459274292 and perplexity is 54.443561306883694
At time: 283.089896440506 and batch: 1750, loss is 4.009635124206543 and perplexity is 55.1267524758351
At time: 284.25268626213074 and batch: 1800, loss is 3.954966263771057 and perplexity is 52.193933088253424
At time: 285.4145164489746 and batch: 1850, loss is 3.9967398262023925 and perplexity is 54.42044041453175
At time: 286.5774745941162 and batch: 1900, loss is 4.075292601585388 and perplexity is 58.8677028517763
At time: 287.7401237487793 and batch: 1950, loss is 4.013582854270935 and perplexity is 55.34480814320119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465961686954942 and perplexity of 87.00466056695937
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 291.3808214664459 and batch: 50, loss is 4.010489463806152 and perplexity is 55.17386956760584
At time: 292.5668795108795 and batch: 100, loss is 4.006399493217469 and perplexity is 54.948670905686605
At time: 293.73019647598267 and batch: 150, loss is 3.9713662099838256 and perplexity is 53.056968305825144
At time: 294.8951358795166 and batch: 200, loss is 3.966610288619995 and perplexity is 52.805232628797754
At time: 296.05897545814514 and batch: 250, loss is 3.9548293781280517 and perplexity is 52.18678897713593
At time: 297.22385835647583 and batch: 300, loss is 3.9671529865264894 and perplexity is 52.83389769552966
At time: 298.3883876800537 and batch: 350, loss is 3.9773347759246827 and perplexity is 53.37458924764385
At time: 299.5575702190399 and batch: 400, loss is 3.9524259519577027 and perplexity is 52.061512489460824
At time: 300.7234709262848 and batch: 450, loss is 3.96427574634552 and perplexity is 52.68210036557271
At time: 301.8896470069885 and batch: 500, loss is 3.975939311981201 and perplexity is 53.30015887737794
At time: 303.0533058643341 and batch: 550, loss is 3.941133375167847 and perplexity is 51.47691090349262
At time: 304.2185001373291 and batch: 600, loss is 3.909666938781738 and perplexity is 49.88233533500613
At time: 305.3818130493164 and batch: 650, loss is 3.936257939338684 and perplexity is 51.2265493345027
At time: 306.5451877117157 and batch: 700, loss is 3.9668558692932128 and perplexity is 52.81820216584478
At time: 307.7079803943634 and batch: 750, loss is 3.9310444498062136 and perplexity is 50.960175228417164
At time: 308.87136363983154 and batch: 800, loss is 3.8952364778518676 and perplexity is 49.167679055144596
At time: 310.0355544090271 and batch: 850, loss is 3.885355620384216 and perplexity is 48.684252493984616
At time: 311.1997375488281 and batch: 900, loss is 3.8664399194717407 and perplexity is 47.77201078049636
At time: 312.36386489868164 and batch: 950, loss is 3.9625204849243163 and perplexity is 52.5897106150161
At time: 313.55173444747925 and batch: 1000, loss is 3.926569871902466 and perplexity is 50.73265935273125
At time: 314.7169499397278 and batch: 1050, loss is 3.8643687963485718 and perplexity is 47.67317145386739
At time: 315.88271164894104 and batch: 1100, loss is 3.892574872970581 and perplexity is 49.03698812153604
At time: 317.0489354133606 and batch: 1150, loss is 3.860394616127014 and perplexity is 47.484085658161305
At time: 318.21300768852234 and batch: 1200, loss is 3.9095973348617554 and perplexity is 49.87886344975873
At time: 319.3788378238678 and batch: 1250, loss is 3.876519451141357 and perplexity is 48.255965195655634
At time: 320.54389691352844 and batch: 1300, loss is 3.876153998374939 and perplexity is 48.238333141716396
At time: 321.7094621658325 and batch: 1350, loss is 3.7479155254364014 and perplexity is 42.43254019984191
At time: 322.87482714653015 and batch: 1400, loss is 3.7693555545806885 and perplexity is 43.352117757929115
At time: 324.0393114089966 and batch: 1450, loss is 3.688700385093689 and perplexity is 39.992837880466105
At time: 325.2036509513855 and batch: 1500, loss is 3.687539162635803 and perplexity is 39.94642425245382
At time: 326.36789989471436 and batch: 1550, loss is 3.689389190673828 and perplexity is 40.02039465990596
At time: 327.53438234329224 and batch: 1600, loss is 3.7875499725341797 and perplexity is 44.14810359885769
At time: 328.6997470855713 and batch: 1650, loss is 3.713549461364746 and perplexity is 40.999073191553414
At time: 329.8638525009155 and batch: 1700, loss is 3.730262908935547 and perplexity is 41.69006741457057
At time: 331.02910327911377 and batch: 1750, loss is 3.7257876777648926 and perplexity is 41.50391158125336
At time: 332.19566535949707 and batch: 1800, loss is 3.6670038223266603 and perplexity is 39.13447618426456
At time: 333.3622977733612 and batch: 1850, loss is 3.694944477081299 and perplexity is 40.24333809835003
At time: 334.52714109420776 and batch: 1900, loss is 3.76974901676178 and perplexity is 43.36917853290185
At time: 335.69510674476624 and batch: 1950, loss is 3.7037816190719606 and perplexity is 40.60055023377801
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.403403774527616 and perplexity of 81.72858142466664
finished 7 epochs...
Completing Train Step...
At time: 339.33946561813354 and batch: 50, loss is 3.9046075773239135 and perplexity is 49.63059991739593
At time: 340.524121761322 and batch: 100, loss is 3.8863382387161254 and perplexity is 48.73211404392767
At time: 341.68881845474243 and batch: 150, loss is 3.843244404792786 and perplexity is 46.67666704443073
At time: 342.8846278190613 and batch: 200, loss is 3.839211401939392 and perplexity is 46.48879900386662
At time: 344.04662466049194 and batch: 250, loss is 3.82380747795105 and perplexity is 45.77817631799594
At time: 345.2096416950226 and batch: 300, loss is 3.840018606185913 and perplexity is 46.526340109469714
At time: 346.3739650249481 and batch: 350, loss is 3.850314474105835 and perplexity is 47.00784365702821
At time: 347.5377449989319 and batch: 400, loss is 3.8270539665222167 and perplexity is 45.92703614934712
At time: 348.70125341415405 and batch: 450, loss is 3.8465535640716553 and perplexity is 46.83138341966629
At time: 349.8671817779541 and batch: 500, loss is 3.863331255912781 and perplexity is 47.62373426175942
At time: 351.03082633018494 and batch: 550, loss is 3.827580227851868 and perplexity is 45.951212133342786
At time: 352.1948227882385 and batch: 600, loss is 3.803291277885437 and perplexity is 44.84855089213226
At time: 353.35804080963135 and batch: 650, loss is 3.8285560464859008 and perplexity is 45.99607406739463
At time: 354.52320742607117 and batch: 700, loss is 3.8619762802124025 and perplexity is 47.55924895695001
At time: 355.68674874305725 and batch: 750, loss is 3.832838463783264 and perplexity is 46.193470816545044
At time: 356.84936690330505 and batch: 800, loss is 3.7960280752182007 and perplexity is 44.523986891567375
At time: 358.0122072696686 and batch: 850, loss is 3.7913756942749024 and perplexity is 44.317325450068836
At time: 359.17595767974854 and batch: 900, loss is 3.770353569984436 and perplexity is 43.39540543652863
At time: 360.3457486629486 and batch: 950, loss is 3.8701983499526977 and perplexity is 47.9518963939845
At time: 361.51004242897034 and batch: 1000, loss is 3.8375172996520996 and perplexity is 46.41010889650605
At time: 362.6739010810852 and batch: 1050, loss is 3.780500135421753 and perplexity is 43.83796117097307
At time: 363.8423800468445 and batch: 1100, loss is 3.8071179389953613 and perplexity is 45.02049988310044
At time: 365.0088219642639 and batch: 1150, loss is 3.7826512241363526 and perplexity is 43.93236201040836
At time: 366.1776211261749 and batch: 1200, loss is 3.8334584522247312 and perplexity is 46.22211911441166
At time: 367.34419798851013 and batch: 1250, loss is 3.805246043205261 and perplexity is 44.936305025485666
At time: 368.51036405563354 and batch: 1300, loss is 3.8079680490493772 and perplexity is 45.05878853516603
At time: 369.677209854126 and batch: 1350, loss is 3.6810244512557984 and perplexity is 39.687030682327055
At time: 370.8418800830841 and batch: 1400, loss is 3.707966685295105 and perplexity is 40.77082227656695
At time: 372.0096414089203 and batch: 1450, loss is 3.6295092248916627 and perplexity is 37.694312646536254
At time: 373.17563796043396 and batch: 1500, loss is 3.629412522315979 and perplexity is 37.69066768565611
At time: 374.34399676322937 and batch: 1550, loss is 3.6341032123565675 and perplexity is 37.86787822011301
At time: 375.51436710357666 and batch: 1600, loss is 3.7366734743118286 and perplexity is 41.958182784636776
At time: 376.6801288127899 and batch: 1650, loss is 3.6688843297958376 and perplexity is 39.20813809821349
At time: 377.846697807312 and batch: 1700, loss is 3.691462197303772 and perplexity is 40.10344325377098
At time: 379.01326966285706 and batch: 1750, loss is 3.688290009498596 and perplexity is 39.97642916292035
At time: 380.1790862083435 and batch: 1800, loss is 3.633308448791504 and perplexity is 37.83779416665573
At time: 381.3441677093506 and batch: 1850, loss is 3.667410764694214 and perplexity is 39.15040490147108
At time: 382.51592564582825 and batch: 1900, loss is 3.7469860744476318 and perplexity is 42.39311955601324
At time: 383.6815149784088 and batch: 1950, loss is 3.684900245666504 and perplexity is 39.8411479244697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.407824139262354 and perplexity of 82.09065121452292
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 387.322482585907 and batch: 50, loss is 3.860920858383179 and perplexity is 47.50908036658903
At time: 388.5099210739136 and batch: 100, loss is 3.873427891731262 and perplexity is 48.107009383872644
At time: 389.6872534751892 and batch: 150, loss is 3.8502845621109008 and perplexity is 47.006437579676266
At time: 390.85269570350647 and batch: 200, loss is 3.850430407524109 and perplexity is 47.01329375294708
At time: 392.0132908821106 and batch: 250, loss is 3.8363741636276245 and perplexity is 46.35708614101161
At time: 393.17338466644287 and batch: 300, loss is 3.8535091924667357 and perplexity is 47.15826062025034
At time: 394.33826971054077 and batch: 350, loss is 3.8679851865768433 and perplexity is 47.84588836289829
At time: 395.50151896476746 and batch: 400, loss is 3.843557815551758 and perplexity is 46.691298306753154
At time: 396.6623296737671 and batch: 450, loss is 3.8585171461105348 and perplexity is 47.39501934690504
At time: 397.82303380966187 and batch: 500, loss is 3.881531596183777 and perplexity is 48.498438239802304
At time: 398.98280596733093 and batch: 550, loss is 3.844872317314148 and perplexity is 46.75271445764146
At time: 400.14349007606506 and batch: 600, loss is 3.8148039960861206 and perplexity is 45.367863232671645
At time: 401.32686495780945 and batch: 650, loss is 3.8315900325775147 and perplexity is 46.135837429220935
At time: 402.4879004955292 and batch: 700, loss is 3.8617298078536986 and perplexity is 47.547528361142184
At time: 403.64756774902344 and batch: 750, loss is 3.822146944999695 and perplexity is 45.70222322652511
At time: 404.81378173828125 and batch: 800, loss is 3.7828727626800536 and perplexity is 43.94209580007447
At time: 405.9741623401642 and batch: 850, loss is 3.7762126970291137 and perplexity is 43.6504109554884
At time: 407.13419342041016 and batch: 900, loss is 3.7499584102630616 and perplexity is 42.51931359622205
At time: 408.29857754707336 and batch: 950, loss is 3.8600986623764038 and perplexity is 47.47003464424416
At time: 409.46720457077026 and batch: 1000, loss is 3.8254764223098756 and perplexity is 45.85464133730186
At time: 410.6281213760376 and batch: 1050, loss is 3.758788728713989 and perplexity is 42.89643527737409
At time: 411.7902467250824 and batch: 1100, loss is 3.7820281267166136 and perplexity is 43.904996395604016
At time: 412.95052790641785 and batch: 1150, loss is 3.7522125148773195 and perplexity is 42.61526467845579
At time: 414.11019587516785 and batch: 1200, loss is 3.796346755027771 and perplexity is 44.53817804832876
At time: 415.27163338661194 and batch: 1250, loss is 3.764404330253601 and perplexity is 43.13800220234244
At time: 416.43041467666626 and batch: 1300, loss is 3.7616574287414553 and perplexity is 43.0196689581522
At time: 417.58779311180115 and batch: 1350, loss is 3.631152768135071 and perplexity is 37.756315817890965
At time: 418.74741768836975 and batch: 1400, loss is 3.6580709743499757 and perplexity is 38.78645060191734
At time: 419.91519141197205 and batch: 1450, loss is 3.578907880783081 and perplexity is 35.83438404956221
At time: 421.07638692855835 and batch: 1500, loss is 3.574424443244934 and perplexity is 35.674082446591406
At time: 422.23730754852295 and batch: 1550, loss is 3.580662794113159 and perplexity is 35.89732550004764
At time: 423.3988428115845 and batch: 1600, loss is 3.68075749874115 and perplexity is 39.67643754368289
At time: 424.5582194328308 and batch: 1650, loss is 3.613228983879089 and perplexity is 37.08560852128221
At time: 425.7188768386841 and batch: 1700, loss is 3.6171494817733763 and perplexity is 37.23128795275571
At time: 426.8782157897949 and batch: 1750, loss is 3.6121519136428835 and perplexity is 37.04568621957325
At time: 428.0398533344269 and batch: 1800, loss is 3.549096269607544 and perplexity is 34.781869846761
At time: 429.20010232925415 and batch: 1850, loss is 3.5790708541870115 and perplexity is 35.84022457702091
At time: 430.3613977432251 and batch: 1900, loss is 3.6587968826293946 and perplexity is 38.81461622913273
At time: 431.5206425189972 and batch: 1950, loss is 3.600396099090576 and perplexity is 36.612733842467584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382114144258721 and perplexity of 80.00700107311319
finished 9 epochs...
Completing Train Step...
At time: 435.1944811344147 and batch: 50, loss is 3.848162636756897 and perplexity is 46.906799177985654
At time: 436.3566358089447 and batch: 100, loss is 3.8405862998962403 and perplexity is 46.552760318698155
At time: 437.5176486968994 and batch: 150, loss is 3.8095654153823855 and perplexity is 45.1308214431328
At time: 438.6809663772583 and batch: 200, loss is 3.802444281578064 and perplexity is 44.81058041783135
At time: 439.8430917263031 and batch: 250, loss is 3.7872700309753418 and perplexity is 44.135746439638396
At time: 441.0050811767578 and batch: 300, loss is 3.799306025505066 and perplexity is 44.670173772938206
At time: 442.1680281162262 and batch: 350, loss is 3.813737778663635 and perplexity is 45.31951700484732
At time: 443.33310437202454 and batch: 400, loss is 3.79045147895813 and perplexity is 44.276385620612366
At time: 444.4957480430603 and batch: 450, loss is 3.8082053565979006 and perplexity is 45.06948259465308
At time: 445.65858244895935 and batch: 500, loss is 3.8323078966140747 and perplexity is 46.168968578115305
At time: 446.82069540023804 and batch: 550, loss is 3.7963385343551637 and perplexity is 44.53781191605342
At time: 447.984365940094 and batch: 600, loss is 3.7689322566986085 and perplexity is 43.333770781690546
At time: 449.1440980434418 and batch: 650, loss is 3.7864280986785888 and perplexity is 44.098602767692185
At time: 450.3048052787781 and batch: 700, loss is 3.8188398027420045 and perplexity is 45.551329124482685
At time: 451.4661512374878 and batch: 750, loss is 3.782829542160034 and perplexity is 43.94019664088487
At time: 452.6273603439331 and batch: 800, loss is 3.743524880409241 and perplexity is 42.24664238252835
At time: 453.79026556015015 and batch: 850, loss is 3.7389328193664553 and perplexity is 42.053087968820236
At time: 454.95317554473877 and batch: 900, loss is 3.714348201751709 and perplexity is 41.03183388904391
At time: 456.1157078742981 and batch: 950, loss is 3.8255616283416747 and perplexity is 45.85854859578841
At time: 457.27801728248596 and batch: 1000, loss is 3.7914554262161255 and perplexity is 44.320859097327194
At time: 458.47781324386597 and batch: 1050, loss is 3.7273070287704466 and perplexity is 41.56701851970415
At time: 459.63788866996765 and batch: 1100, loss is 3.7519514989852905 and perplexity is 42.604142868679375
At time: 460.80089831352234 and batch: 1150, loss is 3.7251730298995973 and perplexity is 41.478409128915374
At time: 461.961452960968 and batch: 1200, loss is 3.7708324432373046 and perplexity is 43.41619131199224
At time: 463.120977640152 and batch: 1250, loss is 3.741134052276611 and perplexity is 42.14575856739754
At time: 464.2864623069763 and batch: 1300, loss is 3.7409100246429445 and perplexity is 42.13631781037131
At time: 465.44675183296204 and batch: 1350, loss is 3.6109738826751707 and perplexity is 37.002070949100016
At time: 466.6078279018402 and batch: 1400, loss is 3.640788426399231 and perplexity is 38.121881177431746
At time: 467.76865100860596 and batch: 1450, loss is 3.5631964778900147 and perplexity is 35.275775358352575
At time: 468.9324188232422 and batch: 1500, loss is 3.560890030860901 and perplexity is 35.19450740721659
At time: 470.09313106536865 and batch: 1550, loss is 3.569029841423035 and perplexity is 35.48215313299884
At time: 471.2528040409088 and batch: 1600, loss is 3.6711634969711304 and perplexity is 39.29760191233814
At time: 472.415066242218 and batch: 1650, loss is 3.6058014488220214 and perplexity is 36.81117431040947
At time: 473.5747308731079 and batch: 1700, loss is 3.613889217376709 and perplexity is 37.110101767048505
At time: 474.7361469268799 and batch: 1750, loss is 3.610731644630432 and perplexity is 36.99310872532163
At time: 475.8986177444458 and batch: 1800, loss is 3.5498987150192263 and perplexity is 34.809791599972364
At time: 477.059579372406 and batch: 1850, loss is 3.581500325202942 and perplexity is 35.927403219948566
At time: 478.2204875946045 and batch: 1900, loss is 3.662676568031311 and perplexity is 38.96549722524241
At time: 479.3802969455719 and batch: 1950, loss is 3.60393470287323 and perplexity is 36.742521298697504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383324627543605 and perplexity of 80.10390685016476
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 483.0192711353302 and batch: 50, loss is 3.8365906858444214 and perplexity is 46.367124566798985
At time: 484.175897359848 and batch: 100, loss is 3.8426237440109254 and perplexity is 46.6477056562969
At time: 485.3327054977417 and batch: 150, loss is 3.824370541572571 and perplexity is 45.803959601873586
At time: 486.49156165122986 and batch: 200, loss is 3.8266377067565918 and perplexity is 45.90792255043083
At time: 487.67094326019287 and batch: 250, loss is 3.815555062294006 and perplexity is 45.40195030088984
At time: 488.83018040657043 and batch: 300, loss is 3.82513813495636 and perplexity is 45.83913191550598
At time: 489.9885015487671 and batch: 350, loss is 3.842969284057617 and perplexity is 46.66382709182783
At time: 491.1472580432892 and batch: 400, loss is 3.8246659946441652 and perplexity is 45.81749452179752
At time: 492.3041229248047 and batch: 450, loss is 3.8479542970657348 and perplexity is 46.897027647865634
At time: 493.46130084991455 and batch: 500, loss is 3.871983165740967 and perplexity is 48.03755811820475
At time: 494.6200428009033 and batch: 550, loss is 3.8341862106323243 and perplexity is 46.25576989354745
At time: 495.77724385261536 and batch: 600, loss is 3.7996640729904176 and perplexity is 44.68617067998309
At time: 496.9350574016571 and batch: 650, loss is 3.807568726539612 and perplexity is 45.04079913866571
At time: 498.09301590919495 and batch: 700, loss is 3.8379633808135987 and perplexity is 46.43081619001129
At time: 499.2594769001007 and batch: 750, loss is 3.7975664710998536 and perplexity is 44.592535123275596
At time: 500.4216547012329 and batch: 800, loss is 3.7520045042037964 and perplexity is 42.60640117043175
At time: 501.5807468891144 and batch: 850, loss is 3.7531977462768555 and perplexity is 42.65727126502266
At time: 502.7362208366394 and batch: 900, loss is 3.7195061588287355 and perplexity is 41.24402108282618
At time: 503.8913595676422 and batch: 950, loss is 3.837676157951355 and perplexity is 46.41748211310644
At time: 505.04868507385254 and batch: 1000, loss is 3.804394073486328 and perplexity is 44.898036958255204
At time: 506.20450806617737 and batch: 1050, loss is 3.741270833015442 and perplexity is 42.15152368966283
At time: 507.3601851463318 and batch: 1100, loss is 3.7642438411712646 and perplexity is 43.131079579472704
At time: 508.5170876979828 and batch: 1150, loss is 3.7358198881149294 and perplexity is 41.922383140179676
At time: 509.67394828796387 and batch: 1200, loss is 3.7842765045166016 and perplexity is 44.003822472354805
At time: 510.83046555519104 and batch: 1250, loss is 3.7561196279525757 and perplexity is 42.78209303268162
At time: 511.9870767593384 and batch: 1300, loss is 3.7553314113616945 and perplexity is 42.74838476361431
At time: 513.1422386169434 and batch: 1350, loss is 3.6104238128662107 and perplexity is 36.98172282395964
At time: 514.3002688884735 and batch: 1400, loss is 3.636665577888489 and perplexity is 37.96503398716749
At time: 515.4634613990784 and batch: 1450, loss is 3.552284059524536 and perplexity is 34.892924055451566
At time: 516.6200141906738 and batch: 1500, loss is 3.5465402507781985 and perplexity is 34.69308025478755
At time: 517.7785658836365 and batch: 1550, loss is 3.5567308187484743 and perplexity is 35.04842997980361
At time: 518.9360840320587 and batch: 1600, loss is 3.6606622314453126 and perplexity is 38.8870865978007
At time: 520.0986828804016 and batch: 1650, loss is 3.5943225383758546 and perplexity is 36.39103810330428
At time: 521.2581293582916 and batch: 1700, loss is 3.5958192253112795 and perplexity is 36.44554487421108
At time: 522.4171986579895 and batch: 1750, loss is 3.5967863750457765 and perplexity is 36.48081022394772
At time: 523.5772044658661 and batch: 1800, loss is 3.5371580123901367 and perplexity is 34.3691036946181
At time: 524.7339565753937 and batch: 1850, loss is 3.5638393115997316 and perplexity is 35.29845910604702
At time: 525.8891844749451 and batch: 1900, loss is 3.6466583108901975 and perplexity is 38.34631025851099
At time: 527.0469143390656 and batch: 1950, loss is 3.5906104278564452 and perplexity is 36.25620096795834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364268316224564 and perplexity of 78.59187449967447
finished 11 epochs...
Completing Train Step...
At time: 530.6835119724274 and batch: 50, loss is 3.840940580368042 and perplexity is 46.569255974459345
At time: 531.8402225971222 and batch: 100, loss is 3.8319152069091795 and perplexity is 46.150842058750754
At time: 532.9973065853119 and batch: 150, loss is 3.803290133476257 and perplexity is 44.84849956706828
At time: 534.1549906730652 and batch: 200, loss is 3.8005429697036743 and perplexity is 44.72546247270622
At time: 535.3113021850586 and batch: 250, loss is 3.787664542198181 and perplexity is 44.15316192201296
At time: 536.4670498371124 and batch: 300, loss is 3.7957442378997803 and perplexity is 44.51135111585987
At time: 537.6301934719086 and batch: 350, loss is 3.813590111732483 and perplexity is 45.31282530493347
At time: 538.7881236076355 and batch: 400, loss is 3.7941370153427125 and perplexity is 44.439868927581124
At time: 539.9462013244629 and batch: 450, loss is 3.8182231187820435 and perplexity is 45.523247010241384
At time: 541.1032025814056 and batch: 500, loss is 3.8430020236968994 and perplexity is 46.66535487370372
At time: 542.2614986896515 and batch: 550, loss is 3.807328062057495 and perplexity is 45.029960722330124
At time: 543.4206495285034 and batch: 600, loss is 3.7761936712265016 and perplexity is 43.64958047928589
At time: 544.5814423561096 and batch: 650, loss is 3.786546621322632 and perplexity is 44.103829760443205
At time: 545.7622463703156 and batch: 700, loss is 3.8195283889770506 and perplexity is 45.58270594428919
At time: 546.9199693202972 and batch: 750, loss is 3.7811117506027223 and perplexity is 43.86478133450151
At time: 548.0774505138397 and batch: 800, loss is 3.7364245748519895 and perplexity is 41.94774071517248
At time: 549.236795425415 and batch: 850, loss is 3.7372384166717527 and perplexity is 41.98189343638241
At time: 550.3949770927429 and batch: 900, loss is 3.704231014251709 and perplexity is 40.61880002572534
At time: 551.5520541667938 and batch: 950, loss is 3.821159176826477 and perplexity is 45.6571023131464
At time: 552.7096638679504 and batch: 1000, loss is 3.78860417842865 and perplexity is 44.19466933052312
At time: 553.8681073188782 and batch: 1050, loss is 3.7267928314208985 and perplexity is 41.54565036314824
At time: 555.0261750221252 and batch: 1100, loss is 3.7502935457229616 and perplexity is 42.533565714000375
At time: 556.1847131252289 and batch: 1150, loss is 3.723303475379944 and perplexity is 41.40093542488287
At time: 557.3441340923309 and batch: 1200, loss is 3.7717980194091796 and perplexity is 43.458133197580665
At time: 558.5032336711884 and batch: 1250, loss is 3.7448315477371215 and perplexity is 42.30188077108163
At time: 559.662006855011 and batch: 1300, loss is 3.744999370574951 and perplexity is 42.308980588497256
At time: 560.8209064006805 and batch: 1350, loss is 3.6030924463272096 and perplexity is 36.71158769845871
At time: 561.9808955192566 and batch: 1400, loss is 3.631640520095825 and perplexity is 37.77473602684333
At time: 563.1397976875305 and batch: 1450, loss is 3.5489931297302246 and perplexity is 34.77828263396759
At time: 564.297122001648 and batch: 1500, loss is 3.5454721879959106 and perplexity is 34.65604564812763
At time: 565.4566996097565 and batch: 1550, loss is 3.55722647190094 and perplexity is 35.065806150533234
At time: 566.617467880249 and batch: 1600, loss is 3.6625091505050658 and perplexity is 38.95897426413228
At time: 567.7763493061066 and batch: 1650, loss is 3.5967747831344603 and perplexity is 36.48038734408186
At time: 568.9350373744965 and batch: 1700, loss is 3.599872393608093 and perplexity is 36.59356457298948
At time: 570.093332529068 and batch: 1750, loss is 3.6021203565597535 and perplexity is 36.6759180795546
At time: 571.2518439292908 and batch: 1800, loss is 3.5429050016403196 and perplexity is 34.56719122233497
At time: 572.4092309474945 and batch: 1850, loss is 3.569971413612366 and perplexity is 35.51557787504081
At time: 573.5681073665619 and batch: 1900, loss is 3.6528954553604125 and perplexity is 38.58622916214855
At time: 574.7307841777802 and batch: 1950, loss is 3.596296067237854 and perplexity is 36.46292778216424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363047045330669 and perplexity of 78.49595111699152
finished 12 epochs...
Completing Train Step...
At time: 578.3661596775055 and batch: 50, loss is 3.835035309791565 and perplexity is 46.29506230809144
At time: 579.5530138015747 and batch: 100, loss is 3.8238988494873047 and perplexity is 45.78235933139434
At time: 580.709144115448 and batch: 150, loss is 3.79404269695282 and perplexity is 44.43567762835824
At time: 581.8649709224701 and batch: 200, loss is 3.7900768947601318 and perplexity is 44.25980349210995
At time: 583.0210843086243 and batch: 250, loss is 3.7768588161468504 and perplexity is 43.678623433833124
At time: 584.174742937088 and batch: 300, loss is 3.7840596866607665 and perplexity is 43.99428269215252
At time: 585.3285620212555 and batch: 350, loss is 3.8021258401870726 and perplexity is 44.79631314603747
At time: 586.4822351932526 and batch: 400, loss is 3.7823768043518067 and perplexity is 43.920307755129585
At time: 587.6360113620758 and batch: 450, loss is 3.8064956951141355 and perplexity is 44.9924948663972
At time: 588.7891955375671 and batch: 500, loss is 3.8313282537460327 and perplexity is 46.123761624273286
At time: 589.9424052238464 and batch: 550, loss is 3.7960594701766968 and perplexity is 44.52538474223053
At time: 591.0951776504517 and batch: 600, loss is 3.7656732177734376 and perplexity is 43.1927742173819
At time: 592.2477581501007 and batch: 650, loss is 3.776434679031372 and perplexity is 43.66010163665031
At time: 593.402220249176 and batch: 700, loss is 3.810155234336853 and perplexity is 45.157448308793754
At time: 594.5555739402771 and batch: 750, loss is 3.7722304010391237 and perplexity is 43.4769277589657
At time: 595.7101199626923 and batch: 800, loss is 3.7278823041915894 and perplexity is 41.590937883240024
At time: 596.8630921840668 and batch: 850, loss is 3.728718295097351 and perplexity is 41.62572206667719
At time: 598.0171236991882 and batch: 900, loss is 3.696026544570923 and perplexity is 40.28690767453997
At time: 599.1691026687622 and batch: 950, loss is 3.8128267765045165 and perplexity is 45.27824962719483
At time: 600.3236782550812 and batch: 1000, loss is 3.780554943084717 and perplexity is 43.84036389301714
At time: 601.4762094020844 and batch: 1050, loss is 3.719466733932495 and perplexity is 41.24239507362728
At time: 602.6532990932465 and batch: 1100, loss is 3.7432836389541624 and perplexity is 42.236451970272164
At time: 603.8068473339081 and batch: 1150, loss is 3.716938090324402 and perplexity is 41.13823949660684
At time: 604.9601407051086 and batch: 1200, loss is 3.765557723045349 and perplexity is 43.1877859677321
At time: 606.1137585639954 and batch: 1250, loss is 3.7390607452392577 and perplexity is 42.05846799091736
At time: 607.2672255039215 and batch: 1300, loss is 3.7398222923278808 and perplexity is 42.09050969385202
At time: 608.420777797699 and batch: 1350, loss is 3.5989494848251344 and perplexity is 36.55980763053071
At time: 609.5742185115814 and batch: 1400, loss is 3.628314981460571 and perplexity is 37.6493233307131
At time: 610.7277638912201 and batch: 1450, loss is 3.54621253490448 and perplexity is 34.681712644454784
At time: 611.8805723190308 and batch: 1500, loss is 3.543523588180542 and perplexity is 34.58858063647819
At time: 613.0367259979248 and batch: 1550, loss is 3.555734353065491 and perplexity is 35.01352281686966
At time: 614.1901602745056 and batch: 1600, loss is 3.6614785528182985 and perplexity is 38.91884391804974
At time: 615.3424906730652 and batch: 1650, loss is 3.5960795736312865 and perplexity is 36.45503464586027
At time: 616.4952239990234 and batch: 1700, loss is 3.5999180936813353 and perplexity is 36.59523693978401
At time: 617.6486690044403 and batch: 1750, loss is 3.6026911783218383 and perplexity is 36.69685946807037
At time: 618.8026032447815 and batch: 1800, loss is 3.543863263130188 and perplexity is 34.60033150648931
At time: 619.9568033218384 and batch: 1850, loss is 3.5712857007980348 and perplexity is 35.562286231307176
At time: 621.1101291179657 and batch: 1900, loss is 3.654306254386902 and perplexity is 38.64070499487678
At time: 622.263444185257 and batch: 1950, loss is 3.5974804162979126 and perplexity is 36.50613819946771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363064078397529 and perplexity of 78.49728815516204
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 625.8779475688934 and batch: 50, loss is 3.8325314331054687 and perplexity is 46.179290180947
At time: 627.0575032234192 and batch: 100, loss is 3.825689659118652 and perplexity is 45.86442027726614
At time: 628.2141208648682 and batch: 150, loss is 3.7986449146270753 and perplexity is 44.64065159492695
At time: 629.3705518245697 and batch: 200, loss is 3.7979345750808715 and perplexity is 44.6089528345052
At time: 630.5260746479034 and batch: 250, loss is 3.7876996326446535 and perplexity is 44.15471130336206
At time: 631.7041742801666 and batch: 300, loss is 3.7949521064758303 and perplexity is 44.476106237049464
At time: 632.859790802002 and batch: 350, loss is 3.8165179252624513 and perplexity is 45.44568721047598
At time: 634.0170738697052 and batch: 400, loss is 3.7987630367279053 and perplexity is 44.64592495391975
At time: 635.1751124858856 and batch: 450, loss is 3.825737943649292 and perplexity is 45.86663487273723
At time: 636.332133769989 and batch: 500, loss is 3.848901672363281 and perplexity is 46.94147778554421
At time: 637.4881091117859 and batch: 550, loss is 3.812112455368042 and perplexity is 45.24591796543302
At time: 638.6434397697449 and batch: 600, loss is 3.7796390151977537 and perplexity is 43.80022766490415
At time: 639.8008205890656 and batch: 650, loss is 3.7906039428710936 and perplexity is 44.28313668624983
At time: 640.957414150238 and batch: 700, loss is 3.8222248697280885 and perplexity is 45.705784698618594
At time: 642.1175830364227 and batch: 750, loss is 3.782718343734741 and perplexity is 43.935310831863504
At time: 643.273323059082 and batch: 800, loss is 3.7378371477127077 and perplexity is 42.007036825453476
At time: 644.4267852306366 and batch: 850, loss is 3.7391544342041017 and perplexity is 42.06240858983879
At time: 645.5828244686127 and batch: 900, loss is 3.6998537826538085 and perplexity is 40.44139069491401
At time: 646.7390296459198 and batch: 950, loss is 3.815950183868408 and perplexity is 45.41989313554073
At time: 647.8956985473633 and batch: 1000, loss is 3.7827791595458984 and perplexity is 43.93798287468059
At time: 649.0521647930145 and batch: 1050, loss is 3.7252927160263063 and perplexity is 41.483373816142226
At time: 650.2093369960785 and batch: 1100, loss is 3.747370500564575 and perplexity is 42.40941971125123
At time: 651.3662836551666 and batch: 1150, loss is 3.723190121650696 and perplexity is 41.39624274042977
At time: 652.5220901966095 and batch: 1200, loss is 3.7733668661117554 and perplexity is 43.52636585584328
At time: 653.6773037910461 and batch: 1250, loss is 3.748053579330444 and perplexity is 42.43839858162753
At time: 654.8339877128601 and batch: 1300, loss is 3.75151397228241 and perplexity is 42.58550649577368
At time: 655.9970500469208 and batch: 1350, loss is 3.6065227460861204 and perplexity is 36.83773568790071
At time: 657.1524972915649 and batch: 1400, loss is 3.6348805236816406 and perplexity is 37.897324793804934
At time: 658.3087019920349 and batch: 1450, loss is 3.547622256278992 and perplexity is 34.73063867400655
At time: 659.4642701148987 and batch: 1500, loss is 3.54075439453125 and perplexity is 34.49293065642408
At time: 660.6209001541138 and batch: 1550, loss is 3.5541327476501463 and perplexity is 34.95748985244321
At time: 661.7769384384155 and batch: 1600, loss is 3.659119334220886 and perplexity is 38.82713408200127
At time: 662.9328153133392 and batch: 1650, loss is 3.5872377824783324 and perplexity is 36.13412763008785
At time: 664.0876429080963 and batch: 1700, loss is 3.587128324508667 and perplexity is 36.13017267829628
At time: 665.2447974681854 and batch: 1750, loss is 3.5910787630081176 and perplexity is 36.27318499813647
At time: 666.4008147716522 and batch: 1800, loss is 3.531969861984253 and perplexity is 34.19125337137986
At time: 667.5572102069855 and batch: 1850, loss is 3.5610044384002686 and perplexity is 35.19853415454904
At time: 668.7142541408539 and batch: 1900, loss is 3.6446973514556884 and perplexity is 38.27118837918252
At time: 669.8716151714325 and batch: 1950, loss is 3.591703944206238 and perplexity is 36.295869401585655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3601940066315406 and perplexity of 78.27231829896637
finished 14 epochs...
Completing Train Step...
At time: 673.4818198680878 and batch: 50, loss is 3.8354076385498046 and perplexity is 46.31230250046379
At time: 674.6635270118713 and batch: 100, loss is 3.824776530265808 and perplexity is 45.82255926694883
At time: 675.8187823295593 and batch: 150, loss is 3.7943778800964356 and perplexity is 44.45057421487729
At time: 676.9742255210876 and batch: 200, loss is 3.7916566848754885 and perplexity is 44.329779951680415
At time: 678.1300048828125 and batch: 250, loss is 3.779745922088623 and perplexity is 43.80491046137032
At time: 679.2862136363983 and batch: 300, loss is 3.7855776071548464 and perplexity is 44.06111322435859
At time: 680.4418196678162 and batch: 350, loss is 3.8059505796432496 and perplexity is 44.96797544493692
At time: 681.5973987579346 and batch: 400, loss is 3.7876634407043457 and perplexity is 44.153113287604086
At time: 682.7512633800507 and batch: 450, loss is 3.8145720100402833 and perplexity is 45.357339742170886
At time: 683.9066805839539 and batch: 500, loss is 3.8379371213912963 and perplexity is 46.42959695960933
At time: 685.062077999115 and batch: 550, loss is 3.8022852897644044 and perplexity is 44.80345646871939
At time: 686.2171609401703 and batch: 600, loss is 3.7700500202178957 and perplexity is 43.382234770416886
At time: 687.3728995323181 and batch: 650, loss is 3.781165752410889 and perplexity is 43.86715017596868
At time: 688.5273141860962 and batch: 700, loss is 3.8148577213287354 and perplexity is 45.370300697606844
At time: 689.7202568054199 and batch: 750, loss is 3.7763493776321413 and perplexity is 43.65637752772825
At time: 690.8731575012207 and batch: 800, loss is 3.7319400453567506 and perplexity is 41.760046010457
At time: 692.0286874771118 and batch: 850, loss is 3.733806824684143 and perplexity is 41.838075610422145
At time: 693.1832232475281 and batch: 900, loss is 3.6961098384857176 and perplexity is 40.29026346855183
At time: 694.3392796516418 and batch: 950, loss is 3.8115611743927 and perplexity is 45.220981625743164
At time: 695.4946625232697 and batch: 1000, loss is 3.778114328384399 and perplexity is 43.73349692003217
At time: 696.6507687568665 and batch: 1050, loss is 3.7207421350479124 and perplexity is 41.2950292280015
At time: 697.8061509132385 and batch: 1100, loss is 3.7425520610809326 and perplexity is 42.205564016416396
At time: 698.9617323875427 and batch: 1150, loss is 3.718905143737793 and perplexity is 41.21924025131705
At time: 700.1175034046173 and batch: 1200, loss is 3.7678779935836793 and perplexity is 43.28810965917249
At time: 701.2733287811279 and batch: 1250, loss is 3.743008198738098 and perplexity is 42.22481995485165
At time: 702.4283080101013 and batch: 1300, loss is 3.7466573667526246 and perplexity is 42.37918690141066
At time: 703.5835502147675 and batch: 1350, loss is 3.602697796821594 and perplexity is 36.69710234702954
At time: 704.7393872737885 and batch: 1400, loss is 3.632052617073059 and perplexity is 37.790306089343304
At time: 705.8954153060913 and batch: 1450, loss is 3.5460948848724367 and perplexity is 34.67763257986542
At time: 707.0510234832764 and batch: 1500, loss is 3.5405316591262816 and perplexity is 34.48524871509768
At time: 708.2072455883026 and batch: 1550, loss is 3.554942445755005 and perplexity is 34.985806328078624
At time: 709.3622200489044 and batch: 1600, loss is 3.660939726829529 and perplexity is 38.89787908220026
At time: 710.5176587104797 and batch: 1650, loss is 3.5902384233474733 and perplexity is 36.242716006108886
At time: 711.6725387573242 and batch: 1700, loss is 3.5907114362716674 and perplexity is 36.25986333432189
At time: 712.8278894424438 and batch: 1750, loss is 3.5956005382537843 and perplexity is 36.43757557666661
At time: 713.9851784706116 and batch: 1800, loss is 3.5370652866363526 and perplexity is 34.365916941320464
At time: 715.1413331031799 and batch: 1850, loss is 3.566288404464722 and perplexity is 35.38501425792769
At time: 716.2981858253479 and batch: 1900, loss is 3.64983127117157 and perplexity is 38.468174811350295
At time: 717.453625202179 and batch: 1950, loss is 3.596054883003235 and perplexity is 36.454134559271125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35932986237282 and perplexity of 78.20470894081816
finished 15 epochs...
Completing Train Step...
At time: 721.0762326717377 and batch: 50, loss is 3.8349465560913085 and perplexity is 46.29095363234079
At time: 722.2303836345673 and batch: 100, loss is 3.822842583656311 and perplexity is 45.734026520212524
At time: 723.3846182823181 and batch: 150, loss is 3.7912655019760133 and perplexity is 44.312442291145075
At time: 724.5383892059326 and batch: 200, loss is 3.7877651500701903 and perplexity is 44.15760430114183
At time: 725.6921985149384 and batch: 250, loss is 3.775337414741516 and perplexity is 43.61222123976174
At time: 726.8458726406097 and batch: 300, loss is 3.78077663898468 and perplexity is 43.85008419938134
At time: 727.9993889331818 and batch: 350, loss is 3.8010924816131593 and perplexity is 44.750046400954254
At time: 729.1540451049805 and batch: 400, loss is 3.7823867654800414 and perplexity is 43.92074525312623
At time: 730.3094840049744 and batch: 450, loss is 3.809219183921814 and perplexity is 45.11519843765182
At time: 731.464191198349 and batch: 500, loss is 3.8325647115707397 and perplexity is 46.18082698242258
At time: 732.6184587478638 and batch: 550, loss is 3.7970339107513427 and perplexity is 44.56879322978604
At time: 733.7736327648163 and batch: 600, loss is 3.765065369606018 and perplexity is 43.166527546531626
At time: 734.926769733429 and batch: 650, loss is 3.7763261461257933 and perplexity is 43.65536333609724
At time: 736.0791954994202 and batch: 700, loss is 3.8107680225372316 and perplexity is 45.185128740531376
At time: 737.2355480194092 and batch: 750, loss is 3.772844977378845 and perplexity is 43.50365586247887
At time: 738.3891642093658 and batch: 800, loss is 3.7286865425109865 and perplexity is 41.62440036332614
At time: 739.5437986850739 and batch: 850, loss is 3.730593647956848 and perplexity is 41.70385822711945
At time: 740.6989226341248 and batch: 900, loss is 3.6934449100494384 and perplexity is 40.18303574029993
At time: 741.8531458377838 and batch: 950, loss is 3.8086557674407957 and perplexity is 45.08978695060516
At time: 743.0061213970184 and batch: 1000, loss is 3.775362467765808 and perplexity is 43.613313871486696
At time: 744.1597759723663 and batch: 1050, loss is 3.718169083595276 and perplexity is 41.18891157469754
At time: 745.314915895462 and batch: 1100, loss is 3.739892392158508 and perplexity is 42.09346033487109
At time: 746.5084590911865 and batch: 1150, loss is 3.7166031789779663 and perplexity is 41.12446414031736
At time: 747.6630954742432 and batch: 1200, loss is 3.765274624824524 and perplexity is 43.17556131283392
At time: 748.8168556690216 and batch: 1250, loss is 3.7406333827972413 and perplexity is 42.12466275385362
At time: 749.9706890583038 and batch: 1300, loss is 3.7444848346710207 and perplexity is 42.28721669855732
At time: 751.1251294612885 and batch: 1350, loss is 3.601064739227295 and perplexity is 36.6372227720579
At time: 752.2789487838745 and batch: 1400, loss is 3.630924777984619 and perplexity is 37.74770873096995
At time: 753.433375120163 and batch: 1450, loss is 3.5455845975875855 and perplexity is 34.65994153903165
At time: 754.5951812267303 and batch: 1500, loss is 3.5405436038970945 and perplexity is 34.48566063595016
At time: 755.7494571208954 and batch: 1550, loss is 3.5555059051513673 and perplexity is 35.0055249641972
At time: 756.9052557945251 and batch: 1600, loss is 3.661985559463501 and perplexity is 38.93858103354135
At time: 758.0595462322235 and batch: 1650, loss is 3.5917904567718506 and perplexity is 36.29900958619949
At time: 759.2153227329254 and batch: 1700, loss is 3.5924998807907103 and perplexity is 36.324770111948204
At time: 760.3700735569 and batch: 1750, loss is 3.597725338935852 and perplexity is 36.51508047417456
At time: 761.5246562957764 and batch: 1800, loss is 3.5393490839004516 and perplexity is 34.444491418345194
At time: 762.6767604351044 and batch: 1850, loss is 3.568631763458252 and perplexity is 35.46803128067915
At time: 763.8301725387573 and batch: 1900, loss is 3.6520043849945067 and perplexity is 38.55186143111746
At time: 764.9838588237762 and batch: 1950, loss is 3.5978026485443113 and perplexity is 36.51790354987291
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358955418786337 and perplexity of 78.17543117090118
finished 16 epochs...
Completing Train Step...
At time: 768.6001989841461 and batch: 50, loss is 3.833534183502197 and perplexity is 46.22561970708988
At time: 769.7567911148071 and batch: 100, loss is 3.820685396194458 and perplexity is 45.63547598582836
At time: 770.9121835231781 and batch: 150, loss is 3.788593792915344 and perplexity is 44.19421034858013
At time: 772.0687172412872 and batch: 200, loss is 3.7846793127059937 and perplexity is 44.02155114279833
At time: 773.2250983715057 and batch: 250, loss is 3.772037663459778 and perplexity is 43.46854892863572
At time: 774.3812735080719 and batch: 300, loss is 3.77726083278656 and perplexity is 43.69618649733849
At time: 775.5597324371338 and batch: 350, loss is 3.7976156187057497 and perplexity is 44.594726793474976
At time: 776.7162852287292 and batch: 400, loss is 3.778709735870361 and perplexity is 43.75954392500703
At time: 777.8791539669037 and batch: 450, loss is 3.805536870956421 and perplexity is 44.94937565057978
At time: 779.0361762046814 and batch: 500, loss is 3.8288964080810546 and perplexity is 46.01173202906827
At time: 780.1938433647156 and batch: 550, loss is 3.793376054763794 and perplexity is 44.40606480262939
At time: 781.3493113517761 and batch: 600, loss is 3.7616339254379274 and perplexity is 43.018657865697065
At time: 782.5058770179749 and batch: 650, loss is 3.77300612449646 and perplexity is 43.51066691611719
At time: 783.6625778675079 and batch: 700, loss is 3.8078320169448854 and perplexity is 45.052659510217275
At time: 784.8196632862091 and batch: 750, loss is 3.770222158432007 and perplexity is 43.389703153613056
At time: 785.9754519462585 and batch: 800, loss is 3.7262420558929445 and perplexity is 41.52277433599155
At time: 787.132187128067 and batch: 850, loss is 3.728123526573181 and perplexity is 41.60097175847784
At time: 788.288740158081 and batch: 900, loss is 3.691268706321716 and perplexity is 40.09568434981517
At time: 789.4456515312195 and batch: 950, loss is 3.8064193534851074 and perplexity is 44.98906019715085
At time: 790.6021456718445 and batch: 1000, loss is 3.773298182487488 and perplexity is 43.52337640994927
At time: 791.7579610347748 and batch: 1050, loss is 3.716287112236023 and perplexity is 41.11146811883564
At time: 792.9134192466736 and batch: 1100, loss is 3.738019013404846 and perplexity is 42.014677159016635
At time: 794.069774389267 and batch: 1150, loss is 3.714965891838074 and perplexity is 41.05718667533883
At time: 795.2268497943878 and batch: 1200, loss is 3.7635352182388306 and perplexity is 43.100526733884074
At time: 796.3838086128235 and batch: 1250, loss is 3.739018425941467 and perplexity is 42.056688143747046
At time: 797.5411696434021 and batch: 1300, loss is 3.743005495071411 and perplexity is 42.2247057931669
At time: 798.6977257728577 and batch: 1350, loss is 3.5998888206481934 and perplexity is 36.594165701879504
At time: 799.8550517559052 and batch: 1400, loss is 3.6300573778152465 and perplexity is 37.71498055828655
At time: 801.0119812488556 and batch: 1450, loss is 3.5450503969192506 and perplexity is 34.64143111967644
At time: 802.1694207191467 and batch: 1500, loss is 3.5403078413009643 and perplexity is 34.477531165419556
At time: 803.3264923095703 and batch: 1550, loss is 3.555567002296448 and perplexity is 35.007663767171266
At time: 804.482036113739 and batch: 1600, loss is 3.6623214864730835 and perplexity is 38.95166375192154
At time: 805.638837814331 and batch: 1650, loss is 3.5924517345428466 and perplexity is 36.323021252663644
At time: 806.7952423095703 and batch: 1700, loss is 3.5933035802841187 and perplexity is 36.35397604611051
At time: 807.9513351917267 and batch: 1750, loss is 3.5987040328979494 and perplexity is 36.550835056503125
At time: 809.1070818901062 and batch: 1800, loss is 3.540410165786743 and perplexity is 34.48105924156819
At time: 810.2696228027344 and batch: 1850, loss is 3.5697383451461793 and perplexity is 35.507301278324064
At time: 811.4255321025848 and batch: 1900, loss is 3.6529893112182616 and perplexity is 38.58985087574459
At time: 812.581137418747 and batch: 1950, loss is 3.5985362339019775 and perplexity is 36.54470237762178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358784804233285 and perplexity of 78.16209444240467
finished 17 epochs...
Completing Train Step...
At time: 816.2198195457458 and batch: 50, loss is 3.8318732309341432 and perplexity is 46.14890487281451
At time: 817.3749077320099 and batch: 100, loss is 3.8185794353485107 and perplexity is 45.539470587503544
At time: 818.5296251773834 and batch: 150, loss is 3.786221299171448 and perplexity is 44.08948414127045
At time: 819.6851077079773 and batch: 200, loss is 3.7820479488372802 and perplexity is 43.90586669436599
At time: 820.8410866260529 and batch: 250, loss is 3.769301061630249 and perplexity is 43.349755437490174
At time: 821.996506690979 and batch: 300, loss is 3.7743648529052733 and perplexity is 43.56982627699328
At time: 823.1518008708954 and batch: 350, loss is 3.794740104675293 and perplexity is 44.46667822185973
At time: 824.307133436203 and batch: 400, loss is 3.7757346391677857 and perplexity is 43.62954852050378
At time: 825.461852312088 and batch: 450, loss is 3.802584104537964 and perplexity is 44.816846403874365
At time: 826.6159162521362 and batch: 500, loss is 3.8259639358520507 and perplexity is 45.877001545934775
At time: 827.7700691223145 and batch: 550, loss is 3.790444459915161 and perplexity is 44.27607484384986
At time: 828.9250087738037 and batch: 600, loss is 3.758901524543762 and perplexity is 42.90127408927927
At time: 830.0810842514038 and batch: 650, loss is 3.7703637742996214 and perplexity is 43.39584825918264
At time: 831.2361941337585 and batch: 700, loss is 3.8054298400878905 and perplexity is 44.94456493731601
At time: 832.391325712204 and batch: 750, loss is 3.7680224704742433 and perplexity is 43.29436424246494
At time: 833.5677089691162 and batch: 800, loss is 3.7241719341278077 and perplexity is 41.43690604666211
At time: 834.7216374874115 and batch: 850, loss is 3.7260270738601684 and perplexity is 41.51384864502426
At time: 835.877242565155 and batch: 900, loss is 3.689364266395569 and perplexity is 40.01939719288405
At time: 837.0323781967163 and batch: 950, loss is 3.8045121526718138 and perplexity is 44.90333879490126
At time: 838.1876037120819 and batch: 1000, loss is 3.771533532142639 and perplexity is 43.44664059461285
At time: 839.3433110713959 and batch: 1050, loss is 3.71468647480011 and perplexity is 41.04571620044856
At time: 840.4986786842346 and batch: 1100, loss is 3.7364557456970213 and perplexity is 41.949048282076625
At time: 841.6534554958344 and batch: 1150, loss is 3.7135765838623045 and perplexity is 41.00018520389616
At time: 842.8100905418396 and batch: 1200, loss is 3.7621042728424072 and perplexity is 43.03889633895198
At time: 843.9640552997589 and batch: 1250, loss is 3.737675471305847 and perplexity is 42.00024582766353
At time: 845.1185736656189 and batch: 1300, loss is 3.7417660760879516 and perplexity is 42.17240410978079
At time: 846.2733731269836 and batch: 1350, loss is 3.5988356351852415 and perplexity is 36.5556455465278
At time: 847.4285795688629 and batch: 1400, loss is 3.629222583770752 and perplexity is 37.683509454900744
At time: 848.5836291313171 and batch: 1450, loss is 3.544418578147888 and perplexity is 34.61955092611455
At time: 849.7382383346558 and batch: 1500, loss is 3.5398900842666627 and perplexity is 34.463130942356514
At time: 850.8932723999023 and batch: 1550, loss is 3.5553174877166747 and perplexity is 34.99892993431219
At time: 852.0482804775238 and batch: 1600, loss is 3.662260103225708 and perplexity is 38.9492728456913
At time: 853.2032389640808 and batch: 1650, loss is 3.5926342821121215 and perplexity is 36.32965253714606
At time: 854.3590235710144 and batch: 1700, loss is 3.593601007461548 and perplexity is 36.36479031474321
At time: 855.5149621963501 and batch: 1750, loss is 3.5991164016723634 and perplexity is 36.56591058768471
At time: 856.6706736087799 and batch: 1800, loss is 3.540890293121338 and perplexity is 34.49761851559779
At time: 857.8255250453949 and batch: 1850, loss is 3.57025945186615 and perplexity is 35.525809193508884
At time: 858.9800918102264 and batch: 1900, loss is 3.653430814743042 and perplexity is 38.60689219255089
At time: 860.1349930763245 and batch: 1950, loss is 3.5988115310668944 and perplexity is 36.55476441554078
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358726040152616 and perplexity of 78.15750145373428
finished 18 epochs...
Completing Train Step...
At time: 863.7468926906586 and batch: 50, loss is 3.8301636743545533 and perplexity is 46.07007810745416
At time: 864.9260129928589 and batch: 100, loss is 3.816572666168213 and perplexity is 45.448175016648605
At time: 866.0837581157684 and batch: 150, loss is 3.78405526638031 and perplexity is 43.994088225514346
At time: 867.2404961585999 and batch: 200, loss is 3.7797018003463747 and perplexity is 43.80297775503923
At time: 868.3965215682983 and batch: 250, loss is 3.7668923902511597 and perplexity is 43.245465772464435
At time: 869.5523278713226 and batch: 300, loss is 3.7718243169784547 and perplexity is 43.45927605587613
At time: 870.709148645401 and batch: 350, loss is 3.792199740409851 and perplexity is 44.35386002183614
At time: 871.8648693561554 and batch: 400, loss is 3.773141541481018 and perplexity is 43.51655939838917
At time: 873.0195369720459 and batch: 450, loss is 3.8000217342376708 and perplexity is 44.70215605002675
At time: 874.1750874519348 and batch: 500, loss is 3.823426995277405 and perplexity is 45.76076182824178
At time: 875.3301155567169 and batch: 550, loss is 3.787906641960144 and perplexity is 44.163852686067706
At time: 876.482581615448 and batch: 600, loss is 3.7565447807312013 and perplexity is 42.80028582549406
At time: 877.6354629993439 and batch: 650, loss is 3.7680802392959594 and perplexity is 43.296865379117335
At time: 878.7884795665741 and batch: 700, loss is 3.8033225679397584 and perplexity is 44.84995422768101
At time: 879.9420390129089 and batch: 750, loss is 3.766065230369568 and perplexity is 43.209709648171156
At time: 881.0949990749359 and batch: 800, loss is 3.7223103523254393 and perplexity is 41.35983961141197
At time: 882.2470672130585 and batch: 850, loss is 3.7241472482681273 and perplexity is 41.435883153639395
At time: 883.4003994464874 and batch: 900, loss is 3.68762412071228 and perplexity is 39.94981816798867
At time: 884.5541779994965 and batch: 950, loss is 3.8027870512008666 and perplexity is 44.82594275629981
At time: 885.7081713676453 and batch: 1000, loss is 3.76992479801178 and perplexity is 43.37680269138826
At time: 886.863094329834 and batch: 1050, loss is 3.713221492767334 and perplexity is 40.98562898778242
At time: 888.0165274143219 and batch: 1100, loss is 3.7350346136093138 and perplexity is 41.88947548394784
At time: 889.1708090305328 and batch: 1150, loss is 3.7122983503341676 and perplexity is 40.94781087295275
At time: 890.347238779068 and batch: 1200, loss is 3.7608049726486206 and perplexity is 42.98301220559294
At time: 891.5013906955719 and batch: 1250, loss is 3.7364496183395386 and perplexity is 41.94879124604922
At time: 892.657603263855 and batch: 1300, loss is 3.7406275939941405 and perplexity is 42.12441890318105
At time: 893.8110122680664 and batch: 1350, loss is 3.5978233289718626 and perplexity is 36.51865876354065
At time: 894.9645044803619 and batch: 1400, loss is 3.6283816576004027 and perplexity is 37.651833725950866
At time: 896.1218175888062 and batch: 1450, loss is 3.543714108467102 and perplexity is 34.59517109056042
At time: 897.2769348621368 and batch: 1500, loss is 3.5393581867218016 and perplexity is 34.44480496182413
At time: 898.4332106113434 and batch: 1550, loss is 3.554886302947998 and perplexity is 34.983842181842824
At time: 899.5891852378845 and batch: 1600, loss is 3.6619751501083373 and perplexity is 38.93817571013138
At time: 900.747230052948 and batch: 1650, loss is 3.5925459671020508 and perplexity is 36.32644422518951
At time: 901.902468919754 and batch: 1700, loss is 3.5936185693740845 and perplexity is 36.36542895561799
At time: 903.0598905086517 and batch: 1750, loss is 3.5992204761505127 and perplexity is 36.56971636378582
At time: 904.2158007621765 and batch: 1800, loss is 3.541059637069702 and perplexity is 34.503460973204845
At time: 905.373363494873 and batch: 1850, loss is 3.5704684019088746 and perplexity is 35.533233088442266
At time: 906.5294985771179 and batch: 1900, loss is 3.6535921144485473 and perplexity is 38.61311997514826
At time: 907.6871826648712 and batch: 1950, loss is 3.598852849006653 and perplexity is 36.55627481429785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358735692223838 and perplexity of 78.15825583914548
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 911.2951731681824 and batch: 50, loss is 3.8295550775527953 and perplexity is 46.042048535480305
At time: 912.470502614975 and batch: 100, loss is 3.817271499633789 and perplexity is 45.4799468226072
At time: 913.6240994930267 and batch: 150, loss is 3.7855123186111452 and perplexity is 44.058236632347594
At time: 914.7781126499176 and batch: 200, loss is 3.7820204210281374 and perplexity is 43.90465807868272
At time: 915.9318342208862 and batch: 250, loss is 3.7697897958755493 and perplexity is 43.3709471256279
At time: 917.085275888443 and batch: 300, loss is 3.7744983053207397 and perplexity is 43.5756411635481
At time: 918.239741563797 and batch: 350, loss is 3.795752401351929 and perplexity is 44.51171448362793
At time: 919.4150130748749 and batch: 400, loss is 3.777653923034668 and perplexity is 43.71336641853863
At time: 920.5673661231995 and batch: 450, loss is 3.8054145908355714 and perplexity is 44.94387957153058
At time: 921.7210133075714 and batch: 500, loss is 3.8283066082000734 and perplexity is 45.98460231633091
At time: 922.8740332126617 and batch: 550, loss is 3.7925819826126097 and perplexity is 44.37081717965596
At time: 924.02623295784 and batch: 600, loss is 3.7600462293624877 and perplexity is 42.95041150301028
At time: 925.1809024810791 and batch: 650, loss is 3.7718664455413817 and perplexity is 43.46110697128886
At time: 926.3333904743195 and batch: 700, loss is 3.8069426298141478 and perplexity is 45.01260806790215
At time: 927.4858055114746 and batch: 750, loss is 3.7695437479019165 and perplexity is 43.36027710469545
At time: 928.6399548053741 and batch: 800, loss is 3.7266318082809446 and perplexity is 41.53896109065362
At time: 929.7934279441833 and batch: 850, loss is 3.728732109069824 and perplexity is 41.62629708722764
At time: 930.94682264328 and batch: 900, loss is 3.6901738595962525 and perplexity is 40.05180974346677
At time: 932.101312160492 and batch: 950, loss is 3.8050381755828857 and perplexity is 44.92696519335966
At time: 933.2558128833771 and batch: 1000, loss is 3.770646414756775 and perplexity is 43.408115415088794
At time: 934.4102475643158 and batch: 1050, loss is 3.715173668861389 and perplexity is 41.0657183016792
At time: 935.5681562423706 and batch: 1100, loss is 3.7358632469177246 and perplexity is 41.92420088393027
At time: 936.7219250202179 and batch: 1150, loss is 3.713564314842224 and perplexity is 40.99968217488644
At time: 937.8770482540131 and batch: 1200, loss is 3.762010989189148 and perplexity is 43.0348817007222
At time: 939.030158996582 and batch: 1250, loss is 3.7369506120681764 and perplexity is 41.96981259272916
At time: 940.185578584671 and batch: 1300, loss is 3.742423095703125 and perplexity is 42.20012131087527
At time: 941.3382041454315 and batch: 1350, loss is 3.5975987815856936 and perplexity is 36.51045951476329
At time: 942.4930927753448 and batch: 1400, loss is 3.6277952432632445 and perplexity is 37.629760623458104
At time: 943.648068189621 and batch: 1450, loss is 3.541037940979004 and perplexity is 34.50271239110685
At time: 944.801913022995 and batch: 1500, loss is 3.534561834335327 and perplexity is 34.2799911079662
At time: 945.9540657997131 and batch: 1550, loss is 3.5502604055404663 and perplexity is 34.822384248824
At time: 947.10715675354 and batch: 1600, loss is 3.657516121864319 and perplexity is 38.764935812710156
At time: 948.261087179184 and batch: 1650, loss is 3.586494836807251 and perplexity is 36.10729190636354
At time: 949.4143104553223 and batch: 1700, loss is 3.5879854583740234 and perplexity is 36.16115434868267
At time: 950.5688869953156 and batch: 1750, loss is 3.593278479576111 and perplexity is 36.353063547025094
At time: 951.7221987247467 and batch: 1800, loss is 3.5346242809295654 and perplexity is 34.28213184350153
At time: 952.8779978752136 and batch: 1850, loss is 3.5644641494750977 and perplexity is 35.32052181232798
At time: 954.0351655483246 and batch: 1900, loss is 3.647787594795227 and perplexity is 38.389638589892165
At time: 955.1887729167938 and batch: 1950, loss is 3.5949274015426638 and perplexity is 36.413056360199924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3585565611373545 and perplexity of 78.14425651975347
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f6867fdeb38>
ELAPSED
2962.005961418152


RESULTS SO FAR:
[{'best_accuracy': -78.24843512754734, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}}, {'best_accuracy': -80.22026219008522, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.862353544247577, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.936075502546612}}, {'best_accuracy': -78.14425651975347, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.3679014798345962, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.3008932223994304}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.12560107942970977, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.9438108012791336}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.67020845413208 and batch: 50, loss is 8.189984884262085 and perplexity is 3604.667758838457
At time: 2.8929290771484375 and batch: 100, loss is 7.396096572875977 and perplexity is 1629.6109313337888
At time: 4.11647367477417 and batch: 150, loss is 7.102034959793091 and perplexity is 1214.4358898777823
At time: 5.339130401611328 and batch: 200, loss is 6.990981016159058 and perplexity is 1086.7871091143932
At time: 6.561617374420166 and batch: 250, loss is 6.895863618850708 and perplexity is 988.1787662204092
At time: 7.783535003662109 and batch: 300, loss is 6.793812141418457 and perplexity is 892.3086932861185
At time: 9.004148721694946 and batch: 350, loss is 6.74711124420166 and perplexity is 851.595155416657
At time: 10.224680662155151 and batch: 400, loss is 6.724044256210327 and perplexity is 832.17624906922
At time: 11.44729995727539 and batch: 450, loss is 6.637145462036133 and perplexity is 762.9141144976528
At time: 12.670820713043213 and batch: 500, loss is 6.624156455993653 and perplexity is 753.0686979634486
At time: 13.921972036361694 and batch: 550, loss is 6.584080095291138 and perplexity is 723.4852040116754
At time: 15.145482778549194 and batch: 600, loss is 6.638793277740478 and perplexity is 764.1722926947908
At time: 16.368247509002686 and batch: 650, loss is 6.729463815689087 and perplexity is 836.6985210399567
At time: 17.590980768203735 and batch: 700, loss is 6.606544675827027 and perplexity is 739.9219264441778
At time: 18.814000368118286 and batch: 750, loss is 6.541285247802734 and perplexity is 693.1769098657302
At time: 20.037227392196655 and batch: 800, loss is 6.543045892715454 and perplexity is 694.3984232758413
At time: 21.260026931762695 and batch: 850, loss is 6.596619148254394 and perplexity is 732.6141377850461
At time: 22.48302173614502 and batch: 900, loss is 6.580251426696777 and perplexity is 720.7205148491051
At time: 23.706212997436523 and batch: 950, loss is 6.590329122543335 and perplexity is 728.0204384112568
At time: 24.92946434020996 and batch: 1000, loss is 6.590615863800049 and perplexity is 728.2292218386608
At time: 26.15189480781555 and batch: 1050, loss is 6.491548843383789 and perplexity is 659.5441030484201
At time: 27.374631643295288 and batch: 1100, loss is 6.564565849304199 and perplexity is 709.5037977537245
At time: 28.598977088928223 and batch: 1150, loss is 6.469096145629883 and perplexity is 644.9005672630286
At time: 29.821080446243286 and batch: 1200, loss is 6.56575909614563 and perplexity is 710.3509162295867
At time: 31.044094562530518 and batch: 1250, loss is 6.479881591796875 and perplexity is 651.8937521332344
At time: 32.26596641540527 and batch: 1300, loss is 6.49236159324646 and perplexity is 660.0803653216227
At time: 33.4888916015625 and batch: 1350, loss is 6.514880657196045 and perplexity is 675.1133867906873
At time: 34.7122962474823 and batch: 1400, loss is 6.534541730880737 and perplexity is 688.5181853923928
At time: 35.93475365638733 and batch: 1450, loss is 6.533822727203369 and perplexity is 688.0233162128601
At time: 37.157532691955566 and batch: 1500, loss is 6.512573747634888 and perplexity is 673.5577563031577
At time: 38.38096618652344 and batch: 1550, loss is 6.487785167694092 and perplexity is 657.0664583916796
At time: 39.60310959815979 and batch: 1600, loss is 6.466661500930786 and perplexity is 643.3323732876935
At time: 40.83084058761597 and batch: 1650, loss is 6.459841527938843 and perplexity is 638.9597912707851
At time: 42.05326271057129 and batch: 1700, loss is 6.489703664779663 and perplexity is 658.3282484603998
At time: 43.27659296989441 and batch: 1750, loss is 6.504554166793823 and perplexity is 668.1777071291957
At time: 44.49937558174133 and batch: 1800, loss is 6.505923271179199 and perplexity is 669.0931386759155
At time: 45.72205448150635 and batch: 1850, loss is 6.447478113174438 and perplexity is 631.108699511076
At time: 46.94495677947998 and batch: 1900, loss is 6.390004549026489 and perplexity is 595.8592902615467
At time: 48.16826367378235 and batch: 1950, loss is 6.346401062011719 and perplexity is 570.4360463757208
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.813244345021802 and perplexity of 334.703258924339
finished 1 epochs...
Completing Train Step...
At time: 51.79738640785217 and batch: 50, loss is 6.041318950653076 and perplexity is 420.4472184693201
At time: 52.97747349739075 and batch: 100, loss is 5.833042230606079 and perplexity is 341.3957052989084
At time: 54.130796670913696 and batch: 150, loss is 5.657127513885498 and perplexity is 286.32499559108686
At time: 55.302923917770386 and batch: 200, loss is 5.575260610580444 and perplexity is 263.81830051915813
At time: 56.45720052719116 and batch: 250, loss is 5.533497171401978 and perplexity is 253.0272451835285
At time: 57.611135959625244 and batch: 300, loss is 5.500670204162597 and perplexity is 244.85598078263732
At time: 58.76584053039551 and batch: 350, loss is 5.441036643981934 and perplexity is 230.68119382623485
At time: 59.919448375701904 and batch: 400, loss is 5.3959033489227295 and perplexity is 220.50124671842474
At time: 61.072410106658936 and batch: 450, loss is 5.3157278919219975 and perplexity is 203.51259440221838
At time: 62.22769093513489 and batch: 500, loss is 5.288217573165894 and perplexity is 197.99020765148367
At time: 63.38211989402771 and batch: 550, loss is 5.230609321594239 and perplexity is 186.9066550915893
At time: 64.53682136535645 and batch: 600, loss is 5.240632085800171 and perplexity is 188.7893957961707
At time: 65.69108748435974 and batch: 650, loss is 5.300510358810425 and perplexity is 200.43907972572916
At time: 66.84617972373962 and batch: 700, loss is 5.244223670959473 and perplexity is 189.46866809030277
At time: 68.00001287460327 and batch: 750, loss is 5.1781527614593506 and perplexity is 177.35489142296728
At time: 69.15385556221008 and batch: 800, loss is 5.15655779838562 and perplexity is 173.56597706768832
At time: 70.3093249797821 and batch: 850, loss is 5.156428632736206 and perplexity is 173.54355975334877
At time: 71.46491479873657 and batch: 900, loss is 5.169157075881958 and perplexity is 175.76661710287172
At time: 72.6208107471466 and batch: 950, loss is 5.2108590698242185 and perplexity is 183.25141635525264
At time: 73.77448534965515 and batch: 1000, loss is 5.172302913665772 and perplexity is 176.32042099998208
At time: 74.92859029769897 and batch: 1050, loss is 5.071179094314576 and perplexity is 159.36211957831557
At time: 76.08360862731934 and batch: 1100, loss is 5.15747522354126 and perplexity is 173.72528392609948
At time: 77.23880410194397 and batch: 1150, loss is 5.053422746658325 and perplexity is 156.5574048157076
At time: 78.3935227394104 and batch: 1200, loss is 5.1232238864898685 and perplexity is 167.87571038915368
At time: 79.54820346832275 and batch: 1250, loss is 5.05528754234314 and perplexity is 156.84962476920597
At time: 80.7016429901123 and batch: 1300, loss is 5.100716190338135 and perplexity is 164.13942028096022
At time: 81.8569495677948 and batch: 1350, loss is 5.033198146820069 and perplexity is 153.42289786865365
At time: 83.01148343086243 and batch: 1400, loss is 5.0410787296295165 and perplexity is 154.63673631540135
At time: 84.16578483581543 and batch: 1450, loss is 4.979566478729248 and perplexity is 145.41132908311647
At time: 85.31876397132874 and batch: 1500, loss is 4.949442119598388 and perplexity is 141.09622714080234
At time: 86.47261023521423 and batch: 1550, loss is 4.938073787689209 and perplexity is 139.5012815125628
At time: 87.6272394657135 and batch: 1600, loss is 4.998658990859985 and perplexity is 148.21426908619188
At time: 88.78020691871643 and batch: 1650, loss is 4.962667570114136 and perplexity is 142.97468264056855
At time: 89.93519115447998 and batch: 1700, loss is 4.974873600006103 and perplexity is 144.73053005383989
At time: 91.08961296081543 and batch: 1750, loss is 4.995556316375732 and perplexity is 147.75512111697597
At time: 92.24420666694641 and batch: 1800, loss is 4.953022689819336 and perplexity is 141.60233763135125
At time: 93.3977119922638 and batch: 1850, loss is 4.939751148223877 and perplexity is 139.73547181258238
At time: 94.5524730682373 and batch: 1900, loss is 4.9958804416656495 and perplexity is 147.8030200506533
At time: 95.70779275894165 and batch: 1950, loss is 4.914734697341919 and perplexity is 136.28314872433333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.712574377725291 and perplexity of 111.33841842318513
finished 2 epochs...
Completing Train Step...
At time: 99.30720257759094 and batch: 50, loss is 4.880164766311646 and perplexity is 131.65235397166683
At time: 100.4834578037262 and batch: 100, loss is 4.8227998065948485 and perplexity is 124.31265538831761
At time: 101.6381266117096 and batch: 150, loss is 4.767316284179688 and perplexity is 117.60320449256193
At time: 102.7918426990509 and batch: 200, loss is 4.7515989112854005 and perplexity is 115.7692413695206
At time: 103.94500660896301 and batch: 250, loss is 4.76274941444397 and perplexity is 117.06735049616815
At time: 105.09891200065613 and batch: 300, loss is 4.780346603393554 and perplexity is 119.14563917178889
At time: 106.25187635421753 and batch: 350, loss is 4.786776056289673 and perplexity is 119.91414834601429
At time: 107.40532279014587 and batch: 400, loss is 4.763440837860108 and perplexity is 117.14832159299677
At time: 108.55846285820007 and batch: 450, loss is 4.737127456665039 and perplexity is 114.10595615229238
At time: 109.71216702461243 and batch: 500, loss is 4.742164421081543 and perplexity is 114.68215371823516
At time: 110.86663866043091 and batch: 550, loss is 4.688962211608887 and perplexity is 108.74027183849934
At time: 112.0199842453003 and batch: 600, loss is 4.676151571273803 and perplexity is 107.35612416465737
At time: 113.19713950157166 and batch: 650, loss is 4.7420048332214355 and perplexity is 114.66385329903198
At time: 114.35016798973083 and batch: 700, loss is 4.737715358734131 and perplexity is 114.17305900302968
At time: 115.50314235687256 and batch: 750, loss is 4.698345146179199 and perplexity is 109.76537641812358
At time: 116.65630006790161 and batch: 800, loss is 4.674758358001709 and perplexity is 107.20665833069899
At time: 117.81025695800781 and batch: 850, loss is 4.68758152961731 and perplexity is 108.59023970058185
At time: 118.96328639984131 and batch: 900, loss is 4.677643241882325 and perplexity is 107.51638363717514
At time: 120.11681699752808 and batch: 950, loss is 4.749536218643189 and perplexity is 115.53069111965586
At time: 121.26987266540527 and batch: 1000, loss is 4.7178768825531 and perplexity is 111.93035892112533
At time: 122.42384314537048 and batch: 1050, loss is 4.639007205963135 and perplexity is 103.44160038429182
At time: 123.57800698280334 and batch: 1100, loss is 4.715239057540893 and perplexity is 111.6354952910419
At time: 124.73173356056213 and batch: 1150, loss is 4.6406942558288575 and perplexity is 103.61625880964164
At time: 125.8842465877533 and batch: 1200, loss is 4.715561590194702 and perplexity is 111.671507190792
At time: 127.03760147094727 and batch: 1250, loss is 4.667085428237915 and perplexity is 106.38721694950007
At time: 128.19207000732422 and batch: 1300, loss is 4.704098901748657 and perplexity is 110.39875998374912
At time: 129.34569334983826 and batch: 1350, loss is 4.600646848678589 and perplexity is 99.5486877573115
At time: 130.5001392364502 and batch: 1400, loss is 4.61225248336792 and perplexity is 100.71074361596455
At time: 131.65421509742737 and batch: 1450, loss is 4.555533390045166 and perplexity is 95.15749776362536
At time: 132.80923104286194 and batch: 1500, loss is 4.536627779006958 and perplexity is 93.37538615815103
At time: 133.96492958068848 and batch: 1550, loss is 4.540278587341309 and perplexity is 93.71690482643596
At time: 135.1199288368225 and batch: 1600, loss is 4.621580314636231 and perplexity is 101.65455143610811
At time: 136.27246165275574 and batch: 1650, loss is 4.575260591506958 and perplexity is 97.05332711464224
At time: 137.42617392539978 and batch: 1700, loss is 4.600062112808228 and perplexity is 99.49049508406223
At time: 138.58105087280273 and batch: 1750, loss is 4.615013837814331 and perplexity is 100.98922599297074
At time: 139.73793649673462 and batch: 1800, loss is 4.564851818084716 and perplexity is 96.04836033197351
At time: 140.89690804481506 and batch: 1850, loss is 4.587228660583496 and perplexity is 98.22184655064638
At time: 142.05606532096863 and batch: 1900, loss is 4.662404365539551 and perplexity is 105.89037549689701
At time: 143.21513438224792 and batch: 1950, loss is 4.5917794799804685 and perplexity is 98.66985506486762
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.555934036609738 and perplexity of 95.19562992644752
finished 3 epochs...
Completing Train Step...
At time: 146.87877464294434 and batch: 50, loss is 4.562947673797607 and perplexity is 95.86564440930843
At time: 148.04387974739075 and batch: 100, loss is 4.502444505691528 and perplexity is 90.23744786315619
At time: 149.2027871608734 and batch: 150, loss is 4.45480242729187 and perplexity is 86.03915017785391
At time: 150.36049246788025 and batch: 200, loss is 4.449672384262085 and perplexity is 85.59889586251273
At time: 151.5171160697937 and batch: 250, loss is 4.459296207427979 and perplexity is 86.42666124449948
At time: 152.6744360923767 and batch: 300, loss is 4.4824937725067135 and perplexity is 88.45498446607706
At time: 153.83054614067078 and batch: 350, loss is 4.498690795898438 and perplexity is 89.8993576147307
At time: 154.9865357875824 and batch: 400, loss is 4.466816415786743 and perplexity is 87.079057749026
At time: 156.14292311668396 and batch: 450, loss is 4.46963210105896 and perplexity is 87.32459047867684
At time: 157.29985928535461 and batch: 500, loss is 4.479680843353272 and perplexity is 88.20651648675157
At time: 158.4556074142456 and batch: 550, loss is 4.426602334976196 and perplexity is 83.6467299799193
At time: 159.61188507080078 and batch: 600, loss is 4.415356254577636 and perplexity is 82.71130193792055
At time: 160.76862168312073 and batch: 650, loss is 4.476104679107666 and perplexity is 87.89163885889896
At time: 161.92501997947693 and batch: 700, loss is 4.487986154556275 and perplexity is 88.942149658971
At time: 163.08231854438782 and batch: 750, loss is 4.457236995697022 and perplexity is 86.24887356385968
At time: 164.23810124397278 and batch: 800, loss is 4.4283856010437015 and perplexity is 83.796027434128
At time: 165.395010471344 and batch: 850, loss is 4.437216033935547 and perplexity is 84.53925933113479
At time: 166.55222058296204 and batch: 900, loss is 4.420731735229492 and perplexity is 83.15711208959742
At time: 167.70829153060913 and batch: 950, loss is 4.501520051956176 and perplexity is 90.1540660646563
At time: 168.8657009601593 and batch: 1000, loss is 4.470122375488281 and perplexity is 87.36741398921778
At time: 170.0455985069275 and batch: 1050, loss is 4.40711989402771 and perplexity is 82.03285961671348
At time: 171.2016236782074 and batch: 1100, loss is 4.465801048278808 and perplexity is 86.9906853759766
At time: 172.35800766944885 and batch: 1150, loss is 4.406228618621826 and perplexity is 81.95977831908219
At time: 173.51426362991333 and batch: 1200, loss is 4.479662733078003 and perplexity is 88.20491905692249
At time: 174.67119479179382 and batch: 1250, loss is 4.441721696853637 and perplexity is 84.92102414295356
At time: 175.8269658088684 and batch: 1300, loss is 4.467719478607178 and perplexity is 87.15773112667209
At time: 176.98503303527832 and batch: 1350, loss is 4.347442898750305 and perplexity is 77.28059574191842
At time: 178.1415250301361 and batch: 1400, loss is 4.377891654968262 and perplexity is 79.66988460414247
At time: 179.29668593406677 and batch: 1450, loss is 4.313997864723206 and perplexity is 74.73868762688919
At time: 180.45376324653625 and batch: 1500, loss is 4.305294260978699 and perplexity is 74.09101433980281
At time: 181.610205411911 and batch: 1550, loss is 4.311820402145385 and perplexity is 74.57612398382173
At time: 182.76687264442444 and batch: 1600, loss is 4.400936574935913 and perplexity is 81.52718924145871
At time: 183.9238736629486 and batch: 1650, loss is 4.352505826950074 and perplexity is 77.67285399918735
At time: 185.0812108516693 and batch: 1700, loss is 4.379738426208496 and perplexity is 79.81715259903537
At time: 186.2369465827942 and batch: 1750, loss is 4.38804349899292 and perplexity is 80.48280016049937
At time: 187.39307928085327 and batch: 1800, loss is 4.332071943283081 and perplexity is 76.10180194874862
At time: 188.5500054359436 and batch: 1850, loss is 4.3691457080841065 and perplexity is 78.97613419939007
At time: 189.70736932754517 and batch: 1900, loss is 4.448311185836792 and perplexity is 85.48245804572286
At time: 190.8639097213745 and batch: 1950, loss is 4.378645648956299 and perplexity is 79.72997787029536
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497425735828489 and perplexity of 89.78570143320444
finished 4 epochs...
Completing Train Step...
At time: 194.49429178237915 and batch: 50, loss is 4.3486831092834475 and perplexity is 77.37649940884137
At time: 195.65006494522095 and batch: 100, loss is 4.300888996124268 and perplexity is 73.76534166217948
At time: 196.8054838180542 and batch: 150, loss is 4.2532798767089846 and perplexity is 70.33572695110173
At time: 197.960786819458 and batch: 200, loss is 4.254941987991333 and perplexity is 70.4527299654983
At time: 199.13811874389648 and batch: 250, loss is 4.256261487007141 and perplexity is 70.54575363217027
At time: 200.29389643669128 and batch: 300, loss is 4.286615695953369 and perplexity is 72.71994517525974
At time: 201.44961261749268 and batch: 350, loss is 4.303031749725342 and perplexity is 73.9235720775152
At time: 202.6047124862671 and batch: 400, loss is 4.269089326858521 and perplexity is 71.4565324349861
At time: 203.76021361351013 and batch: 450, loss is 4.281974935531617 and perplexity is 72.38325119414098
At time: 204.91621208190918 and batch: 500, loss is 4.297805299758911 and perplexity is 73.53822211005198
At time: 206.07182002067566 and batch: 550, loss is 4.243509640693665 and perplexity is 69.65187642886158
At time: 207.22779536247253 and batch: 600, loss is 4.233423891067505 and perplexity is 68.95291573845223
At time: 208.38309168815613 and batch: 650, loss is 4.291213817596436 and perplexity is 73.05509025749106
At time: 209.53820657730103 and batch: 700, loss is 4.30884391784668 and perplexity is 74.35447934625498
At time: 210.6937747001648 and batch: 750, loss is 4.280303592681885 and perplexity is 72.26237500573176
At time: 211.84883880615234 and batch: 800, loss is 4.249629545211792 and perplexity is 70.07944627093022
At time: 213.00408720970154 and batch: 850, loss is 4.253188695907593 and perplexity is 70.32931397552642
At time: 214.15929055213928 and batch: 900, loss is 4.235558400154114 and perplexity is 69.100253554657
At time: 215.31428456306458 and batch: 950, loss is 4.32058424949646 and perplexity is 75.23257004546593
At time: 216.46992993354797 and batch: 1000, loss is 4.297184171676636 and perplexity is 73.4925596377688
At time: 217.62481260299683 and batch: 1050, loss is 4.233030486106872 and perplexity is 68.9257946544849
At time: 218.78131747245789 and batch: 1100, loss is 4.289333782196045 and perplexity is 72.91787312857471
At time: 219.93686842918396 and batch: 1150, loss is 4.233072018623352 and perplexity is 68.92865737563484
At time: 221.09221935272217 and batch: 1200, loss is 4.3093887424469 and perplexity is 74.39500053320675
At time: 222.24705624580383 and batch: 1250, loss is 4.27825131893158 and perplexity is 72.11422490465311
At time: 223.40244555473328 and batch: 1300, loss is 4.292680683135987 and perplexity is 73.162330886441
At time: 224.55792665481567 and batch: 1350, loss is 4.169905390739441 and perplexity is 64.70932971595444
At time: 225.71433424949646 and batch: 1400, loss is 4.2082549095153805 and perplexity is 67.23909905559259
At time: 226.86916732788086 and batch: 1450, loss is 4.144484224319458 and perplexity is 63.08507576132986
At time: 228.02421045303345 and batch: 1500, loss is 4.135899043083191 and perplexity is 62.54579716715421
At time: 229.1807816028595 and batch: 1550, loss is 4.14451690196991 and perplexity is 63.08713726706669
At time: 230.3376123905182 and batch: 1600, loss is 4.23989438533783 and perplexity is 69.40052173902109
At time: 231.49252247810364 and batch: 1650, loss is 4.190899457931518 and perplexity is 66.08220239843938
At time: 232.6493046283722 and batch: 1700, loss is 4.215045228004455 and perplexity is 67.69722761220518
At time: 233.80417656898499 and batch: 1750, loss is 4.223179035186767 and perplexity is 68.25010927664339
At time: 234.9598786830902 and batch: 1800, loss is 4.167316980361939 and perplexity is 64.54205200047866
At time: 236.1163535118103 and batch: 1850, loss is 4.210117664337158 and perplexity is 67.36446573901704
At time: 237.26986742019653 and batch: 1900, loss is 4.2864502334594725 and perplexity is 72.70791374717751
At time: 238.42515778541565 and batch: 1950, loss is 4.220387349128723 and perplexity is 68.05984210479201
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479086232739825 and perplexity of 88.1540835460098
finished 5 epochs...
Completing Train Step...
At time: 242.05950045585632 and batch: 50, loss is 4.1930606174469 and perplexity is 66.22517101229435
At time: 243.21573400497437 and batch: 100, loss is 4.1464254188537595 and perplexity is 63.207655102274735
At time: 244.37237405776978 and batch: 150, loss is 4.099991688728332 and perplexity is 60.339786094923305
At time: 245.52932906150818 and batch: 200, loss is 4.102585186958313 and perplexity is 60.49648032863666
At time: 246.68615555763245 and batch: 250, loss is 4.103786931037903 and perplexity is 60.5692253173826
At time: 247.84305047988892 and batch: 300, loss is 4.1309317779541015 and perplexity is 62.23588595272071
At time: 249.00003862380981 and batch: 350, loss is 4.147842011451721 and perplexity is 63.29725804907862
At time: 250.15589952468872 and batch: 400, loss is 4.114417285919189 and perplexity is 61.216532132269826
At time: 251.31228494644165 and batch: 450, loss is 4.137324032783508 and perplexity is 62.63498781670152
At time: 252.4688742160797 and batch: 500, loss is 4.153235125541687 and perplexity is 63.63954956226257
At time: 253.6303722858429 and batch: 550, loss is 4.100665793418885 and perplexity is 60.38047514055425
At time: 254.79321002960205 and batch: 600, loss is 4.0966357421875 and perplexity is 60.13762840343752
At time: 255.95109295845032 and batch: 650, loss is 4.148155164718628 and perplexity is 63.31708289616875
At time: 257.130663394928 and batch: 700, loss is 4.1674677276611325 and perplexity is 64.55178227388996
At time: 258.2872986793518 and batch: 750, loss is 4.143046827316284 and perplexity is 62.99446260162899
At time: 259.44485664367676 and batch: 800, loss is 4.111211414337158 and perplexity is 61.02059403555917
At time: 260.60150384902954 and batch: 850, loss is 4.115641565322876 and perplexity is 61.29152416795997
At time: 261.75739312171936 and batch: 900, loss is 4.090120162963867 and perplexity is 59.74707065790702
At time: 262.9138252735138 and batch: 950, loss is 4.183754596710205 and perplexity is 65.61173693970903
At time: 264.0691981315613 and batch: 1000, loss is 4.164558305740356 and perplexity is 64.36424684564652
At time: 265.22535943984985 and batch: 1050, loss is 4.104939570426941 and perplexity is 60.63908004316721
At time: 266.3817982673645 and batch: 1100, loss is 4.152534861564636 and perplexity is 63.59500067799826
At time: 267.53826093673706 and batch: 1150, loss is 4.1041576957702635 and perplexity is 60.59168641363054
At time: 268.6942174434662 and batch: 1200, loss is 4.174068684577942 and perplexity is 64.9792952526392
At time: 269.8502974510193 and batch: 1250, loss is 4.148893580436707 and perplexity is 63.36385449171762
At time: 271.01203989982605 and batch: 1300, loss is 4.157807674407959 and perplexity is 63.93121082196887
At time: 272.1692109107971 and batch: 1350, loss is 4.033803687095642 and perplexity is 56.47531765817384
At time: 273.3261983394623 and batch: 1400, loss is 4.0743870306015015 and perplexity is 58.81441809839035
At time: 274.48341822624207 and batch: 1450, loss is 4.009145665168762 and perplexity is 55.099776790897224
At time: 275.63941049575806 and batch: 1500, loss is 4.003850040435791 and perplexity is 54.80876028733568
At time: 276.7965438365936 and batch: 1550, loss is 4.011181325912475 and perplexity is 55.212055485390415
At time: 277.9528715610504 and batch: 1600, loss is 4.1039099645614625 and perplexity is 60.57667782103715
At time: 279.1078987121582 and batch: 1650, loss is 4.058765645027161 and perplexity is 57.902794347379114
At time: 280.264208316803 and batch: 1700, loss is 4.090671672821045 and perplexity is 59.78003084441077
At time: 281.42013454437256 and batch: 1750, loss is 4.098888750076294 and perplexity is 60.2732716999748
At time: 282.57574558258057 and batch: 1800, loss is 4.03323679447174 and perplexity is 56.443311290105044
At time: 283.7302532196045 and batch: 1850, loss is 4.082555961608887 and perplexity is 59.29683676176005
At time: 284.8866949081421 and batch: 1900, loss is 4.159470262527466 and perplexity is 64.0375905018386
At time: 286.04428482055664 and batch: 1950, loss is 4.087541227340698 and perplexity is 59.59318532448125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475947038517442 and perplexity of 87.87778466109411
finished 6 epochs...
Completing Train Step...
At time: 289.6332995891571 and batch: 50, loss is 4.066999416351319 and perplexity is 58.38152087283193
At time: 290.80818724632263 and batch: 100, loss is 4.023292551040649 and perplexity is 55.88480681723771
At time: 291.96107029914856 and batch: 150, loss is 3.9759235906600954 and perplexity is 53.29932093505203
At time: 293.11416506767273 and batch: 200, loss is 3.981353211402893 and perplexity is 53.58950311025743
At time: 294.2670292854309 and batch: 250, loss is 3.9781462717056275 and perplexity is 53.41792008064418
At time: 295.4196927547455 and batch: 300, loss is 4.005595359802246 and perplexity is 54.90450260427286
At time: 296.57303380966187 and batch: 350, loss is 4.021540579795837 and perplexity is 55.78698395911076
At time: 297.72608709335327 and batch: 400, loss is 3.990940809249878 and perplexity is 54.10576863333179
At time: 298.8783390522003 and batch: 450, loss is 4.019016933441162 and perplexity is 55.646374838876746
At time: 300.03054308891296 and batch: 500, loss is 4.03806122303009 and perplexity is 56.716275932789664
At time: 301.1829299926758 and batch: 550, loss is 3.9853220891952517 and perplexity is 53.80261592867556
At time: 302.3356235027313 and batch: 600, loss is 3.9816268491744995 and perplexity is 53.60416922898054
At time: 303.4877555370331 and batch: 650, loss is 4.031411986351014 and perplexity is 56.34040699615307
At time: 304.63979411125183 and batch: 700, loss is 4.05391921043396 and perplexity is 57.62285115294205
At time: 305.791974067688 and batch: 750, loss is 4.028828263282776 and perplexity is 56.19502687877992
At time: 306.94378995895386 and batch: 800, loss is 3.9938429307937624 and perplexity is 54.26301821846837
At time: 308.0962002277374 and batch: 850, loss is 3.999694809913635 and perplexity is 54.58148976142446
At time: 309.2490553855896 and batch: 900, loss is 3.9766549110412597 and perplexity is 53.33831407125378
At time: 310.40179920196533 and batch: 950, loss is 4.0696780967712405 and perplexity is 58.538115950127846
At time: 311.55380034446716 and batch: 1000, loss is 4.050818405151367 and perplexity is 57.444450647247486
At time: 312.707181930542 and batch: 1050, loss is 3.9928747749328615 and perplexity is 54.21050858220759
At time: 313.902907371521 and batch: 1100, loss is 4.037980785369873 and perplexity is 56.7117139917358
At time: 315.055526971817 and batch: 1150, loss is 3.9967266654968263 and perplexity is 54.41972420785157
At time: 316.2091338634491 and batch: 1200, loss is 4.060979800224304 and perplexity is 58.03114215896428
At time: 317.3603675365448 and batch: 1250, loss is 4.043820638656616 and perplexity is 57.04387101123168
At time: 318.5126121044159 and batch: 1300, loss is 4.045245928764343 and perplexity is 57.12523304476765
At time: 319.6721878051758 and batch: 1350, loss is 3.9174010610580443 and perplexity is 50.269627166566075
At time: 320.82519936561584 and batch: 1400, loss is 3.967973484992981 and perplexity is 52.87726561679106
At time: 321.9769878387451 and batch: 1450, loss is 3.897456703186035 and perplexity is 49.276963655131524
At time: 323.12881684303284 and batch: 1500, loss is 3.893374547958374 and perplexity is 49.07621745768245
At time: 324.2810318470001 and batch: 1550, loss is 3.9027219104766844 and perplexity is 49.537101321829276
At time: 325.4339292049408 and batch: 1600, loss is 3.9990998697280884 and perplexity is 54.54902669752654
At time: 326.58693861961365 and batch: 1650, loss is 3.952957758903503 and perplexity is 52.08920652669958
At time: 327.73889803886414 and batch: 1700, loss is 3.9870078659057615 and perplexity is 53.89339161784645
At time: 328.88817524909973 and batch: 1750, loss is 3.996543273925781 and perplexity is 54.409745004212134
At time: 330.0423333644867 and batch: 1800, loss is 3.9280791234970094 and perplexity is 50.80928550928409
At time: 331.1951940059662 and batch: 1850, loss is 3.9774934911727904 and perplexity is 53.38306128112159
At time: 332.3474338054657 and batch: 1900, loss is 4.052824635505676 and perplexity is 57.55981313098678
At time: 333.50029826164246 and batch: 1950, loss is 3.9847832775115966 and perplexity is 53.77363425913422
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479648323946221 and perplexity of 88.20364810977662
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 337.095041513443 and batch: 50, loss is 3.994032454490662 and perplexity is 54.273303320890584
At time: 338.27630400657654 and batch: 100, loss is 3.9777467393875123 and perplexity is 53.39658215808414
At time: 339.43242931365967 and batch: 150, loss is 3.9402462816238404 and perplexity is 51.43126631666717
At time: 340.58795046806335 and batch: 200, loss is 3.934034752845764 and perplexity is 51.112789663280886
At time: 341.7429373264313 and batch: 250, loss is 3.9360571765899657 and perplexity is 51.21626598394234
At time: 342.92064023017883 and batch: 300, loss is 3.945605731010437 and perplexity is 51.70764955480591
At time: 344.07652711868286 and batch: 350, loss is 3.9641020917892456 and perplexity is 52.67295267310235
At time: 345.2328870296478 and batch: 400, loss is 3.935608367919922 and perplexity is 51.19328483717619
At time: 346.38766646385193 and batch: 450, loss is 3.954552187919617 and perplexity is 52.1723253149072
At time: 347.5427634716034 and batch: 500, loss is 3.9634889793395995 and perplexity is 52.640668128098426
At time: 348.69929575920105 and batch: 550, loss is 3.904383044242859 and perplexity is 49.61945745685419
At time: 349.85416293144226 and batch: 600, loss is 3.8890842962265015 and perplexity is 48.866119140336075
At time: 351.0097920894623 and batch: 650, loss is 3.9338536834716797 and perplexity is 51.10353554029327
At time: 352.1655442714691 and batch: 700, loss is 3.9526437854766847 and perplexity is 52.072854467216544
At time: 353.3208613395691 and batch: 750, loss is 3.905636444091797 and perplexity is 49.68168946998567
At time: 354.476802110672 and batch: 800, loss is 3.875461287498474 and perplexity is 48.20492949455715
At time: 355.63313698768616 and batch: 850, loss is 3.873796167373657 and perplexity is 48.12472928636115
At time: 356.78870248794556 and batch: 900, loss is 3.8406521320343017 and perplexity is 46.55582508732162
At time: 357.94461011886597 and batch: 950, loss is 3.9336017847061155 and perplexity is 51.090664243974594
At time: 359.1001513004303 and batch: 1000, loss is 3.900740313529968 and perplexity is 49.43903594821289
At time: 360.2565813064575 and batch: 1050, loss is 3.8378961992263796 and perplexity is 46.42769699886105
At time: 361.4121685028076 and batch: 1100, loss is 3.8677148389816285 and perplexity is 47.832955090356805
At time: 362.5680093765259 and batch: 1150, loss is 3.8387323331832888 and perplexity is 46.46653300665274
At time: 363.72445368766785 and batch: 1200, loss is 3.886455101966858 and perplexity is 48.73780936997059
At time: 364.88045835494995 and batch: 1250, loss is 3.8607469415664672 and perplexity is 47.50081845703011
At time: 366.03615975379944 and batch: 1300, loss is 3.8556564712524413 and perplexity is 47.25963134950913
At time: 367.1921968460083 and batch: 1350, loss is 3.722196521759033 and perplexity is 41.35513186539032
At time: 368.34876537323 and batch: 1400, loss is 3.759685616493225 and perplexity is 42.934925824217515
At time: 369.50446581840515 and batch: 1450, loss is 3.6786520195007326 and perplexity is 39.592987510085756
At time: 370.6596043109894 and batch: 1500, loss is 3.6738850831985475 and perplexity is 39.40469939588518
At time: 371.81655716896057 and batch: 1550, loss is 3.670712766647339 and perplexity is 39.279893282711946
At time: 372.98292541503906 and batch: 1600, loss is 3.753259706497192 and perplexity is 42.659914400832996
At time: 374.13837814331055 and batch: 1650, loss is 3.692306480407715 and perplexity is 40.137316210490496
At time: 375.2939512729645 and batch: 1700, loss is 3.718689374923706 and perplexity is 41.21034738416666
At time: 376.4489426612854 and batch: 1750, loss is 3.727541184425354 and perplexity is 41.57675281177347
At time: 377.60501861572266 and batch: 1800, loss is 3.6549564838409423 and perplexity is 38.66583848977314
At time: 378.76072549819946 and batch: 1850, loss is 3.6965121746063234 and perplexity is 40.30647695827152
At time: 379.9177680015564 and batch: 1900, loss is 3.7547297954559324 and perplexity is 42.7226743900552
At time: 381.0716333389282 and batch: 1950, loss is 3.6731669759750365 and perplexity is 39.37641275424513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.438753349836483 and perplexity of 84.66932282748303
finished 8 epochs...
Completing Train Step...
At time: 384.6839315891266 and batch: 50, loss is 3.8855114507675172 and perplexity is 48.69183957084468
At time: 385.8687970638275 and batch: 100, loss is 3.857005467414856 and perplexity is 47.32342743149702
At time: 387.02322244644165 and batch: 150, loss is 3.815080027580261 and perplexity is 45.380387920270316
At time: 388.1775462627411 and batch: 200, loss is 3.8080136966705322 and perplexity is 45.060845408620125
At time: 389.3321006298065 and batch: 250, loss is 3.8080485248565674 and perplexity is 45.06241482345669
At time: 390.48615050315857 and batch: 300, loss is 3.82075843334198 and perplexity is 45.63880919254266
At time: 391.6407382488251 and batch: 350, loss is 3.8416213893890383 and perplexity is 46.60097153892403
At time: 392.79637384414673 and batch: 400, loss is 3.8185769844055177 and perplexity is 45.53935897299398
At time: 393.9516487121582 and batch: 450, loss is 3.844992814064026 and perplexity is 46.75834834720746
At time: 395.1068353652954 and batch: 500, loss is 3.8565359115600586 and perplexity is 47.30121165525956
At time: 396.2661712169647 and batch: 550, loss is 3.798678603172302 and perplexity is 44.64215549886919
At time: 397.426301240921 and batch: 600, loss is 3.7861993741989135 and perplexity is 44.088517491138525
At time: 398.58592343330383 and batch: 650, loss is 3.8312325859069825 and perplexity is 46.11934927473316
At time: 399.74447202682495 and batch: 700, loss is 3.85387592792511 and perplexity is 47.17555839823544
At time: 400.9264771938324 and batch: 750, loss is 3.8097143888473513 and perplexity is 45.13754523880107
At time: 402.0836408138275 and batch: 800, loss is 3.7797795343399048 and perplexity is 43.80638286777343
At time: 403.23961186408997 and batch: 850, loss is 3.783274893760681 and perplexity is 43.95976983594499
At time: 404.3987500667572 and batch: 900, loss is 3.7515982723236085 and perplexity is 42.58909660704688
At time: 405.55282068252563 and batch: 950, loss is 3.8470501375198363 and perplexity is 46.85464441613271
At time: 406.7072401046753 and batch: 1000, loss is 3.8162133407592775 and perplexity is 45.43184726623886
At time: 407.8618178367615 and batch: 1050, loss is 3.757800359725952 and perplexity is 42.85405871633768
At time: 409.0167589187622 and batch: 1100, loss is 3.7855632305145264 and perplexity is 44.06047977813509
At time: 410.17290902137756 and batch: 1150, loss is 3.760044174194336 and perplexity is 42.95032323278316
At time: 411.3276309967041 and batch: 1200, loss is 3.8108038902282715 and perplexity is 45.186749455834125
At time: 412.48383712768555 and batch: 1250, loss is 3.7899375581741332 and perplexity is 44.2536369118195
At time: 413.63919854164124 and batch: 1300, loss is 3.7881984758377074 and perplexity is 44.17674307527986
At time: 414.79461097717285 and batch: 1350, loss is 3.6581786108016967 and perplexity is 38.7906256625253
At time: 415.9503803253174 and batch: 1400, loss is 3.6994403839111327 and perplexity is 40.42467573005945
At time: 417.10582995414734 and batch: 1450, loss is 3.620952033996582 and perplexity is 37.373131382142915
At time: 418.25993275642395 and batch: 1500, loss is 3.6194201707839966 and perplexity is 37.31592468464399
At time: 419.41493248939514 and batch: 1550, loss is 3.618888745307922 and perplexity is 37.296099319921815
At time: 420.5701730251312 and batch: 1600, loss is 3.7061906814575196 and perplexity is 40.698477401146235
At time: 421.72664046287537 and batch: 1650, loss is 3.6490273332595824 and perplexity is 38.437261215185465
At time: 422.8837413787842 and batch: 1700, loss is 3.67685519695282 and perplexity is 39.52190981351562
At time: 424.0425479412079 and batch: 1750, loss is 3.6893471479415894 and perplexity is 40.018712128538546
At time: 425.201425075531 and batch: 1800, loss is 3.624586100578308 and perplexity is 37.509194912174095
At time: 426.370756149292 and batch: 1850, loss is 3.674636945724487 and perplexity is 39.43433745318299
At time: 427.5430290699005 and batch: 1900, loss is 3.7375734996795655 and perplexity is 41.995963212648576
At time: 428.7036395072937 and batch: 1950, loss is 3.656094961166382 and perplexity is 38.709883737663496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.444813715025436 and perplexity of 85.184007858462
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 432.3969712257385 and batch: 50, loss is 3.8453406429290773 and perplexity is 46.77461507930022
At time: 433.5624670982361 and batch: 100, loss is 3.8480128145217893 and perplexity is 46.89977202291625
At time: 434.7199399471283 and batch: 150, loss is 3.8210071182250975 and perplexity is 45.65016028583648
At time: 435.8768563270569 and batch: 200, loss is 3.8159867668151857 and perplexity is 45.42155475946733
At time: 437.0339877605438 and batch: 250, loss is 3.8193612051010133 and perplexity is 45.57508588782219
At time: 438.20138144493103 and batch: 300, loss is 3.830614833831787 and perplexity is 46.090867749178535
At time: 439.3715465068817 and batch: 350, loss is 3.852554144859314 and perplexity is 47.11324373633015
At time: 440.53512263298035 and batch: 400, loss is 3.8209880208969116 and perplexity is 45.649288498068195
At time: 441.6931936740875 and batch: 450, loss is 3.849357805252075 and perplexity is 46.96289422140985
At time: 442.85849356651306 and batch: 500, loss is 3.8654571294784548 and perplexity is 47.72508398970946
At time: 444.0183997154236 and batch: 550, loss is 3.81782977104187 and perplexity is 45.50534406517687
At time: 445.1881332397461 and batch: 600, loss is 3.797864532470703 and perplexity is 44.60582841643428
At time: 446.34862208366394 and batch: 650, loss is 3.8300954151153563 and perplexity is 46.06693350629806
At time: 447.5076422691345 and batch: 700, loss is 3.854671859741211 and perplexity is 47.21312187310624
At time: 448.6653711795807 and batch: 750, loss is 3.8086639404296876 and perplexity is 45.090155470439
At time: 449.8231780529022 and batch: 800, loss is 3.7704324913024903 and perplexity is 43.39883039427248
At time: 450.98379397392273 and batch: 850, loss is 3.766456756591797 and perplexity is 43.226630694853895
At time: 452.1467535495758 and batch: 900, loss is 3.733001084327698 and perplexity is 41.80437856182585
At time: 453.3180525302887 and batch: 950, loss is 3.83367311000824 and perplexity is 46.232042117036606
At time: 454.4815766811371 and batch: 1000, loss is 3.7903519821166993 and perplexity is 44.271980479245606
At time: 455.6392159461975 and batch: 1050, loss is 3.730881404876709 and perplexity is 41.71586052769891
At time: 456.79967856407166 and batch: 1100, loss is 3.750370054244995 and perplexity is 42.5368200187394
At time: 458.0035467147827 and batch: 1150, loss is 3.728715767860413 and perplexity is 41.62561686874773
At time: 459.16496419906616 and batch: 1200, loss is 3.771125564575195 and perplexity is 43.42891938942013
At time: 460.32335901260376 and batch: 1250, loss is 3.7495595979690552 and perplexity is 42.50235975215259
At time: 461.4821083545685 and batch: 1300, loss is 3.7520376539230345 and perplexity is 42.60781358407872
At time: 462.64027881622314 and batch: 1350, loss is 3.62004093170166 and perplexity is 37.339096143518645
At time: 463.7985281944275 and batch: 1400, loss is 3.6578219747543335 and perplexity is 38.77679399369673
At time: 464.9578855037689 and batch: 1450, loss is 3.57480920791626 and perplexity is 35.68781121420182
At time: 466.1146430969238 and batch: 1500, loss is 3.5769765758514405 and perplexity is 35.76524371395132
At time: 467.27448558807373 and batch: 1550, loss is 3.578253092765808 and perplexity is 35.81092780455234
At time: 468.4341723918915 and batch: 1600, loss is 3.6528043079376222 and perplexity is 38.58271228708471
At time: 469.5958824157715 and batch: 1650, loss is 3.5820837020874023 and perplexity is 35.94836855125601
At time: 470.75948309898376 and batch: 1700, loss is 3.5972785425186156 and perplexity is 36.49876931119954
At time: 471.91662311553955 and batch: 1750, loss is 3.602147979736328 and perplexity is 36.67693119890847
At time: 473.07574486732483 and batch: 1800, loss is 3.5394283437728884 and perplexity is 34.447221592536366
At time: 474.2349009513855 and batch: 1850, loss is 3.594240093231201 and perplexity is 36.388037962578984
At time: 475.3943018913269 and batch: 1900, loss is 3.6763957214355467 and perplexity is 39.503754634809894
At time: 476.55529141426086 and batch: 1950, loss is 3.5952972269058225 and perplexity is 36.42652532242046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.421991392623546 and perplexity of 83.26192756264253
finished 10 epochs...
Completing Train Step...
At time: 480.2327690124512 and batch: 50, loss is 3.850169453620911 and perplexity is 47.00102705103153
At time: 481.3932731151581 and batch: 100, loss is 3.826821455955505 and perplexity is 45.91635886948295
At time: 482.5543305873871 and batch: 150, loss is 3.7807444286346437 and perplexity is 43.848671795567284
At time: 483.71575450897217 and batch: 200, loss is 3.7680500316619874 and perplexity is 43.295557503009846
At time: 484.8811528682709 and batch: 250, loss is 3.7677451181411743 and perplexity is 43.28235811457431
At time: 486.04490780830383 and batch: 300, loss is 3.775857381820679 and perplexity is 43.634904055703295
At time: 487.2322037220001 and batch: 350, loss is 3.7984193563461304 and perplexity is 44.63058366178847
At time: 488.39299154281616 and batch: 400, loss is 3.769497289657593 and perplexity is 43.35826270914078
At time: 489.55448627471924 and batch: 450, loss is 3.8027173852920533 and perplexity is 44.8228200250345
At time: 490.7167856693268 and batch: 500, loss is 3.8193957138061525 and perplexity is 45.57665865215966
At time: 491.8775975704193 and batch: 550, loss is 3.771928172111511 and perplexity is 43.46378975915502
At time: 493.04039239883423 and batch: 600, loss is 3.754123497009277 and perplexity is 42.69677954972952
At time: 494.2020843029022 and batch: 650, loss is 3.7904597425460818 and perplexity is 44.27675150393088
At time: 495.36319065093994 and batch: 700, loss is 3.815192394256592 and perplexity is 45.38548745013476
At time: 496.5240249633789 and batch: 750, loss is 3.772222862243652 and perplexity is 43.476599996535064
At time: 497.6855306625366 and batch: 800, loss is 3.7338565015792846 and perplexity is 41.84015404774189
At time: 498.8473844528198 and batch: 850, loss is 3.7314517164230345 and perplexity is 41.73965835006416
At time: 500.00865721702576 and batch: 900, loss is 3.698576807975769 and perplexity is 40.389781022187684
At time: 501.1721408367157 and batch: 950, loss is 3.800800929069519 and perplexity is 44.737001312854744
At time: 502.33357405662537 and batch: 1000, loss is 3.7598619794845582 and perplexity is 42.942498623929716
At time: 503.4937074184418 and batch: 1050, loss is 3.7022999572753905 and perplexity is 40.54043849320871
At time: 504.6544609069824 and batch: 1100, loss is 3.7214674043655394 and perplexity is 41.32499010921169
At time: 505.8158280849457 and batch: 1150, loss is 3.700848789215088 and perplexity is 40.48165016990207
At time: 506.97566270828247 and batch: 1200, loss is 3.7452426671981813 and perplexity is 42.31927547291127
At time: 508.1351354122162 and batch: 1250, loss is 3.726173219680786 and perplexity is 41.51991616386195
At time: 509.2950704097748 and batch: 1300, loss is 3.7299631071090698 and perplexity is 41.677570529601795
At time: 510.45654034614563 and batch: 1350, loss is 3.5994756698608397 and perplexity is 36.57904991627159
At time: 511.6161890029907 and batch: 1400, loss is 3.639814019203186 and perplexity is 38.08475303398842
At time: 512.7751002311707 and batch: 1450, loss is 3.5587708234786986 and perplexity is 35.12000192147786
At time: 513.9340960979462 and batch: 1500, loss is 3.5652529335021974 and perplexity is 35.34839306651735
At time: 515.0919229984283 and batch: 1550, loss is 3.5695232439041136 and perplexity is 35.49966443509337
At time: 516.2515339851379 and batch: 1600, loss is 3.647750835418701 and perplexity is 38.38822743664927
At time: 517.4116089344025 and batch: 1650, loss is 3.5787230730056763 and perplexity is 35.82776218859589
At time: 518.5708765983582 and batch: 1700, loss is 3.59530638217926 and perplexity is 36.426858818746794
At time: 519.7292494773865 and batch: 1750, loss is 3.6001334095001223 and perplexity is 36.60311732154438
At time: 520.8875622749329 and batch: 1800, loss is 3.5387412118911743 and perplexity is 34.423559938613046
At time: 522.0458626747131 and batch: 1850, loss is 3.5944883918762205 and perplexity is 36.39707418489446
At time: 523.2051422595978 and batch: 1900, loss is 3.674979734420776 and perplexity is 39.447857415420316
At time: 524.3643050193787 and batch: 1950, loss is 3.5950116300582886 and perplexity is 36.4161235070553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.428407465025436 and perplexity of 83.79785956897005
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 528.0136065483093 and batch: 50, loss is 3.8424515247344972 and perplexity is 46.63967271391535
At time: 529.1729202270508 and batch: 100, loss is 3.8437226819992065 and perplexity is 46.698996769823445
At time: 530.3314952850342 and batch: 150, loss is 3.8181034088134767 and perplexity is 45.51779774994463
At time: 531.4902350902557 and batch: 200, loss is 3.8083981800079347 and perplexity is 45.07817388389054
At time: 532.6491410732269 and batch: 250, loss is 3.806814875602722 and perplexity is 45.00685788496708
At time: 533.8081455230713 and batch: 300, loss is 3.8118417024612428 and perplexity is 45.233669159897765
At time: 534.9666433334351 and batch: 350, loss is 3.8341633796691896 and perplexity is 46.25471384182563
At time: 536.1255054473877 and batch: 400, loss is 3.7996917390823364 and perplexity is 44.68740698879046
At time: 537.2831358909607 and batch: 450, loss is 3.827762608528137 and perplexity is 45.95959351076446
At time: 538.4416539669037 and batch: 500, loss is 3.844009737968445 and perplexity is 46.712403919812814
At time: 539.6081335544586 and batch: 550, loss is 3.79748405456543 and perplexity is 44.58886011251247
At time: 540.7685444355011 and batch: 600, loss is 3.7723171043395998 and perplexity is 43.480697515519765
At time: 541.9270720481873 and batch: 650, loss is 3.8046325063705444 and perplexity is 44.90874340303635
At time: 543.0853066444397 and batch: 700, loss is 3.8313584089279176 and perplexity is 46.12515251566546
At time: 544.2437841892242 and batch: 750, loss is 3.7923015356063843 and perplexity is 44.358375261545035
At time: 545.4295942783356 and batch: 800, loss is 3.760166258811951 and perplexity is 42.95556712666435
At time: 546.5987777709961 and batch: 850, loss is 3.7605137777328492 and perplexity is 42.97049759315832
At time: 547.7634618282318 and batch: 900, loss is 3.730029149055481 and perplexity is 41.680323088372425
At time: 548.9282476902008 and batch: 950, loss is 3.8411316442489625 and perplexity is 46.57815452730636
At time: 550.0925340652466 and batch: 1000, loss is 3.79494656085968 and perplexity is 44.47585959032032
At time: 551.2590658664703 and batch: 1050, loss is 3.7334551763534547 and perplexity is 41.82336590744735
At time: 552.4229073524475 and batch: 1100, loss is 3.7441911029815675 and perplexity is 42.27479742701029
At time: 553.5846092700958 and batch: 1150, loss is 3.7152593994140624 and perplexity is 41.069239039320365
At time: 554.7474222183228 and batch: 1200, loss is 3.7495530652999878 and perplexity is 42.50208209920866
At time: 555.9070630073547 and batch: 1250, loss is 3.7223639917373657 and perplexity is 41.362058188387145
At time: 557.0653195381165 and batch: 1300, loss is 3.7218478393554686 and perplexity is 41.34071457228604
At time: 558.2257387638092 and batch: 1350, loss is 3.586246314048767 and perplexity is 36.098319537542686
At time: 559.3865282535553 and batch: 1400, loss is 3.6330357360839844 and perplexity is 37.827476726274476
At time: 560.5465812683105 and batch: 1450, loss is 3.551198034286499 and perplexity is 34.85505002909521
At time: 561.7053270339966 and batch: 1500, loss is 3.5584942960739134 and perplexity is 35.110291621134415
At time: 562.8652918338776 and batch: 1550, loss is 3.5706631183624267 and perplexity is 35.54015266722855
At time: 564.0244405269623 and batch: 1600, loss is 3.6567170286178587 and perplexity is 38.73397138768191
At time: 565.184784412384 and batch: 1650, loss is 3.5915739059448244 and perplexity is 36.29114985669954
At time: 566.3425350189209 and batch: 1700, loss is 3.6065010976791383 and perplexity is 36.836938218238245
At time: 567.5019476413727 and batch: 1750, loss is 3.610254421234131 and perplexity is 36.97545896011141
At time: 568.6640365123749 and batch: 1800, loss is 3.5390344429016114 and perplexity is 34.43365547396636
At time: 569.8238203525543 and batch: 1850, loss is 3.580260896682739 and perplexity is 35.88290135587762
At time: 570.9831523895264 and batch: 1900, loss is 3.66706871509552 and perplexity is 39.13701581118285
At time: 572.1415827274323 and batch: 1950, loss is 3.594174737930298 and perplexity is 36.38565988911937
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.405471021075582 and perplexity of 81.89770930677133
finished 12 epochs...
Completing Train Step...
At time: 575.773717880249 and batch: 50, loss is 3.8541744565963745 and perplexity is 47.18964375733738
At time: 576.955319404602 and batch: 100, loss is 3.8397309970855713 and perplexity is 46.5129606347702
At time: 578.1150345802307 and batch: 150, loss is 3.798057026863098 and perplexity is 44.614415614739805
At time: 579.2752923965454 and batch: 200, loss is 3.7886252975463868 and perplexity is 44.19560269280391
At time: 580.434645652771 and batch: 250, loss is 3.785986051559448 and perplexity is 44.079113415304
At time: 581.5940227508545 and batch: 300, loss is 3.791821208000183 and perplexity is 44.3370738255841
At time: 582.7547817230225 and batch: 350, loss is 3.8133909797668455 and perplexity is 45.30380297130924
At time: 583.9137871265411 and batch: 400, loss is 3.7783708286285402 and perplexity is 43.74471601145763
At time: 585.0737807750702 and batch: 450, loss is 3.8052505970001222 and perplexity is 44.9365096566665
At time: 586.2348201274872 and batch: 500, loss is 3.8203984451293946 and perplexity is 45.622382716043255
At time: 587.3945336341858 and batch: 550, loss is 3.7728493547439577 and perplexity is 43.50384629428111
At time: 588.554628610611 and batch: 600, loss is 3.7503681898117067 and perplexity is 42.53674071175011
At time: 589.7151892185211 and batch: 650, loss is 3.784209523200989 and perplexity is 44.00087513714292
At time: 590.8765437602997 and batch: 700, loss is 3.8112379789352415 and perplexity is 45.20636877143118
At time: 592.0361421108246 and batch: 750, loss is 3.773718948364258 and perplexity is 43.54169341489948
At time: 593.1954498291016 and batch: 800, loss is 3.741044807434082 and perplexity is 42.14199744364386
At time: 594.3564610481262 and batch: 850, loss is 3.741365923881531 and perplexity is 42.155532105136274
At time: 595.5193009376526 and batch: 900, loss is 3.7124556255340577 and perplexity is 40.95425145455146
At time: 596.6791620254517 and batch: 950, loss is 3.8239638900756834 and perplexity is 45.785337139820776
At time: 597.8423845767975 and batch: 1000, loss is 3.7783448266983033 and perplexity is 43.74357857919145
At time: 599.0020914077759 and batch: 1050, loss is 3.718189125061035 and perplexity is 41.189737069130544
At time: 600.1633846759796 and batch: 1100, loss is 3.730387473106384 and perplexity is 41.695260826700036
At time: 601.322331905365 and batch: 1150, loss is 3.7036904430389406 and perplexity is 40.59684860542173
At time: 602.5067713260651 and batch: 1200, loss is 3.7394593715667725 and perplexity is 42.07523694560484
At time: 603.6670045852661 and batch: 1250, loss is 3.7139937257766724 and perplexity is 41.017291667304946
At time: 604.8290026187897 and batch: 1300, loss is 3.714992709159851 and perplexity is 41.05828773388882
At time: 605.9896404743195 and batch: 1350, loss is 3.5813366174697876 and perplexity is 35.92152210761422
At time: 607.1507999897003 and batch: 1400, loss is 3.6287326574325562 and perplexity is 37.6650518329099
At time: 608.3122611045837 and batch: 1450, loss is 3.547751965522766 and perplexity is 34.73514385105999
At time: 609.4749691486359 and batch: 1500, loss is 3.5555534601211547 and perplexity is 35.00718969046195
At time: 610.6368019580841 and batch: 1550, loss is 3.568039116859436 and perplexity is 35.44701750006181
At time: 611.8001465797424 and batch: 1600, loss is 3.654207606315613 and perplexity is 38.636893351864494
At time: 612.9618246555328 and batch: 1650, loss is 3.59026095867157 and perplexity is 36.24353275666306
At time: 614.1280283927917 and batch: 1700, loss is 3.605493607521057 and perplexity is 36.79984405466954
At time: 615.288813829422 and batch: 1750, loss is 3.6102757596969606 and perplexity is 36.97624796798612
At time: 616.4526424407959 and batch: 1800, loss is 3.5407404565811156 and perplexity is 34.49244989902699
At time: 617.6161768436432 and batch: 1850, loss is 3.582657227516174 and perplexity is 35.96899176814737
At time: 618.7815401554108 and batch: 1900, loss is 3.6705421161651612 and perplexity is 39.273190721897244
At time: 619.9438815116882 and batch: 1950, loss is 3.597762713432312 and perplexity is 36.51644523242389
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.404356774618459 and perplexity of 81.80650589530497
finished 13 epochs...
Completing Train Step...
At time: 623.6006076335907 and batch: 50, loss is 3.8479672384262087 and perplexity is 46.89763456313273
At time: 624.7818677425385 and batch: 100, loss is 3.8317853021621704 and perplexity is 46.14484723467534
At time: 625.9393842220306 and batch: 150, loss is 3.788687767982483 and perplexity is 44.198363697617346
At time: 627.0963923931122 and batch: 200, loss is 3.777892370223999 and perplexity is 43.72379099070289
At time: 628.2527966499329 and batch: 250, loss is 3.774834213256836 and perplexity is 43.59028102592074
At time: 629.4089615345001 and batch: 300, loss is 3.7806212520599365 and perplexity is 43.843270999002684
At time: 630.5668845176697 and batch: 350, loss is 3.8023474073410033 and perplexity is 44.80623963729943
At time: 631.7471294403076 and batch: 400, loss is 3.767567491531372 and perplexity is 43.274670698803185
At time: 632.9031817913055 and batch: 450, loss is 3.7942234468460083 and perplexity is 44.44371009825549
At time: 634.0691170692444 and batch: 500, loss is 3.8089763593673704 and perplexity is 45.10424468966588
At time: 635.2293400764465 and batch: 550, loss is 3.7613162851333617 and perplexity is 43.00499557607239
At time: 636.3879706859589 and batch: 600, loss is 3.739590735435486 and perplexity is 42.080764474557895
At time: 637.5451874732971 and batch: 650, loss is 3.7741139268875123 and perplexity is 43.558894845538696
At time: 638.7050704956055 and batch: 700, loss is 3.801604948043823 and perplexity is 44.77298517467912
At time: 639.8653266429901 and batch: 750, loss is 3.764944272041321 and perplexity is 43.161300501666894
At time: 641.0234849452972 and batch: 800, loss is 3.7322063350677492 and perplexity is 41.77116776177867
At time: 642.1822237968445 and batch: 850, loss is 3.732391080856323 and perplexity is 41.77888552199637
At time: 643.3421201705933 and batch: 900, loss is 3.7043817901611327 and perplexity is 40.62492482396332
At time: 644.5009002685547 and batch: 950, loss is 3.8155654001235964 and perplexity is 45.402419660941185
At time: 645.6584055423737 and batch: 1000, loss is 3.7705441188812254 and perplexity is 43.403675171029654
At time: 646.8174781799316 and batch: 1050, loss is 3.7106834697723388 and perplexity is 40.88173841304902
At time: 647.974004983902 and batch: 1100, loss is 3.7231572914123534 and perplexity is 41.394883714222814
At time: 649.1329846382141 and batch: 1150, loss is 3.6968649005889893 and perplexity is 40.32069660763689
At time: 650.2961194515228 and batch: 1200, loss is 3.7333873748779296 and perplexity is 41.82053031765707
At time: 651.4553589820862 and batch: 1250, loss is 3.7089565563201905 and perplexity is 40.81120011333577
At time: 652.6197843551636 and batch: 1300, loss is 3.7103667211532594 and perplexity is 40.86879122947063
At time: 653.7792398929596 and batch: 1350, loss is 3.5775677442550657 and perplexity is 35.78639324683482
At time: 654.9384806156158 and batch: 1400, loss is 3.6248468160629272 and perplexity is 37.51897541501216
At time: 656.097825050354 and batch: 1450, loss is 3.5443891429901124 and perplexity is 34.61853190916845
At time: 657.257562160492 and batch: 1500, loss is 3.552618637084961 and perplexity is 34.904600398070315
At time: 658.4169812202454 and batch: 1550, loss is 3.5653138160705566 and perplexity is 35.350545232988665
At time: 659.5753495693207 and batch: 1600, loss is 3.6517471075057983 and perplexity is 38.54194418082076
At time: 660.7335050106049 and batch: 1650, loss is 3.5885177659988403 and perplexity is 36.1804083309308
At time: 661.8927097320557 and batch: 1700, loss is 3.604211835861206 and perplexity is 36.75270527450342
At time: 663.0563204288483 and batch: 1750, loss is 3.6093575286865236 and perplexity is 36.942310813910446
At time: 664.2168309688568 and batch: 1800, loss is 3.540349159240723 and perplexity is 34.478955735405215
At time: 665.3761665821075 and batch: 1850, loss is 3.5826871967315674 and perplexity is 35.97006974676216
At time: 666.5360555648804 and batch: 1900, loss is 3.6708390378952025 and perplexity is 39.284853517013595
At time: 667.696605682373 and batch: 1950, loss is 3.5981222009658813 and perplexity is 36.52957479907159
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.404354787427326 and perplexity of 81.80634333030332
finished 14 epochs...
Completing Train Step...
At time: 671.3055231571198 and batch: 50, loss is 3.8415678691864015 and perplexity is 46.598477512225195
At time: 672.5079174041748 and batch: 100, loss is 3.824500312805176 and perplexity is 45.80990402386846
At time: 673.6700937747955 and batch: 150, loss is 3.780716395378113 and perplexity is 43.84744259173168
At time: 674.8326623439789 and batch: 200, loss is 3.769553818702698 and perplexity is 43.360713779606826
At time: 675.9953911304474 and batch: 250, loss is 3.7660995817184446 and perplexity is 43.21119398547648
At time: 677.1644563674927 and batch: 300, loss is 3.7718851280212404 and perplexity is 43.46191894012926
At time: 678.326441526413 and batch: 350, loss is 3.793639135360718 and perplexity is 44.41774871350245
At time: 679.4888203144073 and batch: 400, loss is 3.7592108345031736 and perplexity is 42.91454593307745
At time: 680.6502659320831 and batch: 450, loss is 3.7857550144195558 and perplexity is 44.06893067935192
At time: 681.8107903003693 and batch: 500, loss is 3.800246033668518 and perplexity is 44.712183842758485
At time: 682.9700362682343 and batch: 550, loss is 3.752506146430969 and perplexity is 42.62777970214551
At time: 684.1295790672302 and batch: 600, loss is 3.7311935424804688 and perplexity is 41.728883648839975
At time: 685.2867739200592 and batch: 650, loss is 3.76633734703064 and perplexity is 43.22146933001661
At time: 686.4462609291077 and batch: 700, loss is 3.794128837585449 and perplexity is 44.43950551060619
At time: 687.6080384254456 and batch: 750, loss is 3.7581010818481446 and perplexity is 42.86694781774125
At time: 688.7704689502716 and batch: 800, loss is 3.72527370929718 and perplexity is 41.48258536038587
At time: 689.9537122249603 and batch: 850, loss is 3.7254758787155153 and perplexity is 41.490972718344295
At time: 691.1151070594788 and batch: 900, loss is 3.6981458044052125 and perplexity is 40.372376633299424
At time: 692.2730293273926 and batch: 950, loss is 3.8090552520751952 and perplexity is 45.107803226033276
At time: 693.4330163002014 and batch: 1000, loss is 3.764595456123352 and perplexity is 43.14624777847902
At time: 694.5920560359955 and batch: 1050, loss is 3.704911527633667 and perplexity is 40.64645107008768
At time: 695.7531042098999 and batch: 1100, loss is 3.717453737258911 and perplexity is 41.15945777379402
At time: 696.9123668670654 and batch: 1150, loss is 3.6914147472381593 and perplexity is 40.101540387903206
At time: 698.0740337371826 and batch: 1200, loss is 3.7283709716796873 and perplexity is 41.611266989065065
At time: 699.2367897033691 and batch: 1250, loss is 3.704517822265625 and perplexity is 40.63045149387571
At time: 700.3987696170807 and batch: 1300, loss is 3.7061641311645506 and perplexity is 40.697396858992256
At time: 701.5608308315277 and batch: 1350, loss is 3.5738893651962282 and perplexity is 35.65499913415261
At time: 702.7266590595245 and batch: 1400, loss is 3.62092924118042 and perplexity is 37.37227955293775
At time: 703.8931283950806 and batch: 1450, loss is 3.540871467590332 and perplexity is 34.49696908572374
At time: 705.0580604076385 and batch: 1500, loss is 3.5494539546966553 and perplexity is 34.79431302821417
At time: 706.226080417633 and batch: 1550, loss is 3.5623114204406736 and perplexity is 35.24456808274338
At time: 707.3936357498169 and batch: 1600, loss is 3.6488059329986573 and perplexity is 38.42875213751394
At time: 708.55979347229 and batch: 1650, loss is 3.5862706470489503 and perplexity is 36.09919792864551
At time: 709.7251162528992 and batch: 1700, loss is 3.602309641838074 and perplexity is 36.6828609479866
At time: 710.8901405334473 and batch: 1750, loss is 3.607728486061096 and perplexity is 36.88217920668645
At time: 712.0543704032898 and batch: 1800, loss is 3.5391380548477174 and perplexity is 34.43722339685809
At time: 713.2193167209625 and batch: 1850, loss is 3.581726899147034 and perplexity is 35.935544355646876
At time: 714.387766122818 and batch: 1900, loss is 3.6699934291839598 and perplexity is 39.251647944099226
At time: 715.5513746738434 and batch: 1950, loss is 3.597127552032471 and perplexity is 36.4932587603084
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4048640761264535 and perplexity of 81.848016987539
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 719.1820812225342 and batch: 50, loss is 3.8395852851867676 and perplexity is 46.50618363671374
At time: 720.3424808979034 and batch: 100, loss is 3.8307815313339235 and perplexity is 46.098551622127054
At time: 721.5025670528412 and batch: 150, loss is 3.792578125 and perplexity is 44.37064601456225
At time: 722.6652634143829 and batch: 200, loss is 3.785976037979126 and perplexity is 44.07867202777122
At time: 723.8285005092621 and batch: 250, loss is 3.787540121078491 and perplexity is 44.14766867791366
At time: 724.990255355835 and batch: 300, loss is 3.7966418838500977 and perplexity is 44.551324488215975
At time: 726.1499099731445 and batch: 350, loss is 3.8224727869033814 and perplexity is 45.71711735237733
At time: 727.3128662109375 and batch: 400, loss is 3.7928089714050293 and perplexity is 44.380890001031766
At time: 728.4741060733795 and batch: 450, loss is 3.820141940116882 and perplexity is 45.61068184692377
At time: 729.6316480636597 and batch: 500, loss is 3.8380540084838866 and perplexity is 46.43502429739477
At time: 730.791469335556 and batch: 550, loss is 3.792350797653198 and perplexity is 44.36056049972797
At time: 731.952098608017 and batch: 600, loss is 3.7611617755889895 and perplexity is 42.99835140710718
At time: 733.1131644248962 and batch: 650, loss is 3.783180718421936 and perplexity is 43.955630104662895
At time: 734.2736456394196 and batch: 700, loss is 3.804728379249573 and perplexity is 44.91304913995835
At time: 735.4338290691376 and batch: 750, loss is 3.7618908977508543 and perplexity is 43.02971389019308
At time: 736.594801902771 and batch: 800, loss is 3.726821417808533 and perplexity is 41.54683802018937
At time: 737.7555763721466 and batch: 850, loss is 3.7284575510025024 and perplexity is 41.61486982034555
At time: 738.9169230461121 and batch: 900, loss is 3.700342335700989 and perplexity is 40.46115328671436
At time: 740.0795197486877 and batch: 950, loss is 3.817772808074951 and perplexity is 45.50275201959426
At time: 741.2378935813904 and batch: 1000, loss is 3.7807279586791993 and perplexity is 43.84794961584367
At time: 742.3992562294006 and batch: 1050, loss is 3.725717806816101 and perplexity is 41.50101176488026
At time: 743.5588431358337 and batch: 1100, loss is 3.742728443145752 and perplexity is 42.21300897750399
At time: 744.7209289073944 and batch: 1150, loss is 3.7159930753707884 and perplexity is 41.09938160865165
At time: 745.8817963600159 and batch: 1200, loss is 3.7551094484329224 and perplexity is 42.73889725990791
At time: 747.043318271637 and batch: 1250, loss is 3.7302141189575195 and perplexity is 41.68803340671745
At time: 748.2040913105011 and batch: 1300, loss is 3.7301787662506105 and perplexity is 41.68655964794164
At time: 749.3614730834961 and batch: 1350, loss is 3.58877121925354 and perplexity is 36.189579535365354
At time: 750.5212621688843 and batch: 1400, loss is 3.6316044473648073 and perplexity is 37.773373413528105
At time: 751.6838393211365 and batch: 1450, loss is 3.5439211750030517 and perplexity is 34.60233533451072
At time: 752.8448340892792 and batch: 1500, loss is 3.5447478771209715 and perplexity is 34.630952985923386
At time: 754.006757736206 and batch: 1550, loss is 3.5553392791748046 and perplexity is 34.999692620338436
At time: 755.1671657562256 and batch: 1600, loss is 3.640881700515747 and perplexity is 38.12543712805499
At time: 756.3277864456177 and batch: 1650, loss is 3.5742110300064085 and perplexity is 35.666469937459055
At time: 757.4890828132629 and batch: 1700, loss is 3.5870319414138794 and perplexity is 36.126690508252196
At time: 758.653785943985 and batch: 1750, loss is 3.594808368682861 and perplexity is 36.40872226792203
At time: 759.8160228729248 and batch: 1800, loss is 3.529914045333862 and perplexity is 34.12103462656456
At time: 760.9785449504852 and batch: 1850, loss is 3.5719245958328245 and perplexity is 35.58501405898116
At time: 762.1445937156677 and batch: 1900, loss is 3.6620784425735473 and perplexity is 38.9421979380206
At time: 763.308342218399 and batch: 1950, loss is 3.5977907943725587 and perplexity is 36.51747066293795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.398449423146802 and perplexity of 81.32467069845097
finished 16 epochs...
Completing Train Step...
At time: 766.9711220264435 and batch: 50, loss is 3.8449031066894532 and perplexity is 46.75415396667412
At time: 768.1316590309143 and batch: 100, loss is 3.8309289026260376 and perplexity is 46.10534572585982
At time: 769.2946212291718 and batch: 150, loss is 3.787953486442566 and perplexity is 44.165921567346004
At time: 770.4557027816772 and batch: 200, loss is 3.7782627725601197 and perplexity is 43.73998938480621
At time: 771.6147501468658 and batch: 250, loss is 3.7786263751983644 and perplexity is 43.75589625205752
At time: 772.7734961509705 and batch: 300, loss is 3.7872377014160157 and perplexity is 44.13431957347058
At time: 773.9307682514191 and batch: 350, loss is 3.8135463428497314 and perplexity is 45.310842056598155
At time: 775.0914881229401 and batch: 400, loss is 3.7824437856674193 and perplexity is 43.92324969365149
At time: 776.2735443115234 and batch: 450, loss is 3.810130624771118 and perplexity is 45.15633701727543
At time: 777.4348707199097 and batch: 500, loss is 3.827571315765381 and perplexity is 45.95080261399091
At time: 778.5945470333099 and batch: 550, loss is 3.7808702564239502 and perplexity is 43.854189524137865
At time: 779.7552132606506 and batch: 600, loss is 3.751245503425598 and perplexity is 42.57407514807709
At time: 780.915937423706 and batch: 650, loss is 3.7737973356246948 and perplexity is 43.54510666273688
At time: 782.0758655071259 and batch: 700, loss is 3.7953343963623047 and perplexity is 44.49311225306051
At time: 783.2346391677856 and batch: 750, loss is 3.754333953857422 and perplexity is 42.705766325010515
At time: 784.3932778835297 and batch: 800, loss is 3.7193189001083375 and perplexity is 41.236298503296894
At time: 785.5528173446655 and batch: 850, loss is 3.7212134408950805 and perplexity is 41.31449640387219
At time: 786.7121267318726 and batch: 900, loss is 3.6929962921142576 and perplexity is 40.16501295275196
At time: 787.8760502338409 and batch: 950, loss is 3.810222797393799 and perplexity is 45.16049938711431
At time: 789.04097032547 and batch: 1000, loss is 3.7721911239624024 and perplexity is 43.47522014587375
At time: 790.2039270401001 and batch: 1050, loss is 3.7172192764282226 and perplexity is 41.14980862435168
At time: 791.3642628192902 and batch: 1100, loss is 3.7343592548370363 and perplexity is 41.86119461015669
At time: 792.526572227478 and batch: 1150, loss is 3.709232506752014 and perplexity is 40.82246353563194
At time: 793.6891388893127 and batch: 1200, loss is 3.748311257362366 and perplexity is 42.44933543368469
At time: 794.8513195514679 and batch: 1250, loss is 3.7239327573776246 and perplexity is 41.42699648725158
At time: 796.0123918056488 and batch: 1300, loss is 3.7235185384750364 and perplexity is 41.40984019570453
At time: 797.1729156970978 and batch: 1350, loss is 3.5827820110321045 and perplexity is 35.973480385451566
At time: 798.3329937458038 and batch: 1400, loss is 3.6267992877960205 and perplexity is 37.59230171443384
At time: 799.4925396442413 and batch: 1450, loss is 3.5409731245040894 and perplexity is 34.50047611938908
At time: 800.6549298763275 and batch: 1500, loss is 3.544120945930481 and perplexity is 34.60924856564002
At time: 801.8213384151459 and batch: 1550, loss is 3.5560590028762817 and perplexity is 35.02489179579586
At time: 802.9810597896576 and batch: 1600, loss is 3.643016700744629 and perplexity is 38.20692189909986
At time: 804.1388807296753 and batch: 1650, loss is 3.577615361213684 and perplexity is 35.78809732661238
At time: 805.2989575862885 and batch: 1700, loss is 3.591423568725586 and perplexity is 36.28569435623978
At time: 806.4646050930023 and batch: 1750, loss is 3.6004898595809935 and perplexity is 36.61616683128502
At time: 807.6234283447266 and batch: 1800, loss is 3.5351785945892336 and perplexity is 34.30114016526442
At time: 808.7826228141785 and batch: 1850, loss is 3.577185397148132 and perplexity is 35.77271303837003
At time: 809.9446587562561 and batch: 1900, loss is 3.6671194648742675 and perplexity is 39.13900205647643
At time: 811.1052711009979 and batch: 1950, loss is 3.602466511726379 and perplexity is 36.68861583565873
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3968937363735465 and perplexity of 81.1982533423063
finished 17 epochs...
Completing Train Step...
At time: 814.7469511032104 and batch: 50, loss is 3.8441358947753907 and perplexity is 46.718297379278305
At time: 815.9091114997864 and batch: 100, loss is 3.8276682186126707 and perplexity is 45.955255593349165
At time: 817.0694518089294 and batch: 150, loss is 3.7837985038757322 and perplexity is 43.9827936433096
At time: 818.2307758331299 and batch: 200, loss is 3.7733945989608766 and perplexity is 43.52757298271881
At time: 819.3915109634399 and batch: 250, loss is 3.7734020519256593 and perplexity is 43.52789739339624
At time: 820.553165435791 and batch: 300, loss is 3.781967239379883 and perplexity is 43.902323218686455
At time: 821.714587688446 and batch: 350, loss is 3.8083462476730348 and perplexity is 45.07583292985385
At time: 822.8772573471069 and batch: 400, loss is 3.776952600479126 and perplexity is 43.68271999646028
At time: 824.039880990982 and batch: 450, loss is 3.8047697591781615 and perplexity is 44.91490767717726
At time: 825.201248884201 and batch: 500, loss is 3.822074227333069 and perplexity is 45.69889998832299
At time: 826.3608400821686 and batch: 550, loss is 3.775203323364258 and perplexity is 43.606373609017595
At time: 827.5245282649994 and batch: 600, loss is 3.7464040756225585 and perplexity is 42.36845398860231
At time: 828.68732213974 and batch: 650, loss is 3.7694599628448486 and perplexity is 43.35664431359269
At time: 829.8487727642059 and batch: 700, loss is 3.7907893228530884 and perplexity is 44.29134665428976
At time: 831.0079090595245 and batch: 750, loss is 3.750656719207764 and perplexity is 42.54901558260329
At time: 832.1673715114594 and batch: 800, loss is 3.716091065406799 and perplexity is 41.10340913586104
At time: 833.3272716999054 and batch: 850, loss is 3.7181141805648803 and perplexity is 41.186650240710996
At time: 834.5106048583984 and batch: 900, loss is 3.6899584245681765 and perplexity is 40.043182110090775
At time: 835.6687541007996 and batch: 950, loss is 3.807127809524536 and perplexity is 45.02094426145113
At time: 836.8298044204712 and batch: 1000, loss is 3.7687606763839723 and perplexity is 43.32633619749784
At time: 837.9911451339722 and batch: 1050, loss is 3.713797240257263 and perplexity is 41.00923315516333
At time: 839.1516723632812 and batch: 1100, loss is 3.730970244407654 and perplexity is 41.71956670980644
At time: 840.3152894973755 and batch: 1150, loss is 3.7065449237823485 and perplexity is 40.712897078276995
At time: 841.4742012023926 and batch: 1200, loss is 3.745547499656677 and perplexity is 42.33217772810862
At time: 842.6327965259552 and batch: 1250, loss is 3.721525664329529 and perplexity is 41.32739777178181
At time: 843.7941393852234 and batch: 1300, loss is 3.721203508377075 and perplexity is 41.31408604893071
At time: 844.9522547721863 and batch: 1350, loss is 3.5810393571853636 and perplexity is 35.91084565265721
At time: 846.1112561225891 and batch: 1400, loss is 3.625447864532471 and perplexity is 37.541532916160875
At time: 847.274772644043 and batch: 1450, loss is 3.540238561630249 and perplexity is 34.47514265615186
At time: 848.4326369762421 and batch: 1500, loss is 3.5441233682632447 and perplexity is 34.609332400858285
At time: 849.5903623104095 and batch: 1550, loss is 3.556625790596008 and perplexity is 35.04474910125731
At time: 850.7511954307556 and batch: 1600, loss is 3.6440297412872313 and perplexity is 38.24564667156217
At time: 851.9158501625061 and batch: 1650, loss is 3.5790175437927245 and perplexity is 35.838313971445395
At time: 853.0835757255554 and batch: 1700, loss is 3.5929941272735597 and perplexity is 36.342727939247276
At time: 854.248019695282 and batch: 1750, loss is 3.6024292945861816 and perplexity is 36.687250415708185
At time: 855.4116966724396 and batch: 1800, loss is 3.536910948753357 and perplexity is 34.360613387732684
At time: 856.576584815979 and batch: 1850, loss is 3.578877158164978 and perplexity is 35.83328314037758
At time: 857.7371044158936 and batch: 1900, loss is 3.6685113525390625 and perplexity is 39.193517081245254
At time: 858.9021732807159 and batch: 1950, loss is 3.6035427904129027 and perplexity is 36.728124268148804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.396338742278343 and perplexity of 81.15320129412723
finished 18 epochs...
Completing Train Step...
At time: 862.5889928340912 and batch: 50, loss is 3.842302622795105 and perplexity is 46.632728493212426
At time: 863.7766568660736 and batch: 100, loss is 3.8246572494506834 and perplexity is 45.817093840695094
At time: 864.9427165985107 and batch: 150, loss is 3.7804747724533083 and perplexity is 43.83684932424714
At time: 866.1083550453186 and batch: 200, loss is 3.7698608684539794 and perplexity is 43.37402972021175
At time: 867.276270866394 and batch: 250, loss is 3.7696813583374023 and perplexity is 43.36624434187825
At time: 868.441695690155 and batch: 300, loss is 3.7783302736282347 and perplexity is 43.74294198045958
At time: 869.6076517105103 and batch: 350, loss is 3.8048065376281737 and perplexity is 44.91655960824161
At time: 870.772109746933 and batch: 400, loss is 3.773410634994507 and perplexity is 43.52827099793969
At time: 871.9399907588959 and batch: 450, loss is 3.801304621696472 and perplexity is 44.75954068654967
At time: 873.1040358543396 and batch: 500, loss is 3.8185136461257936 and perplexity is 45.53647467968094
At time: 874.2718634605408 and batch: 550, loss is 3.7716200733184815 and perplexity is 43.4504006806751
At time: 875.4369814395905 and batch: 600, loss is 3.743377866744995 and perplexity is 42.240432005345944
At time: 876.6053540706635 and batch: 650, loss is 3.766655640602112 and perplexity is 43.235228635487005
At time: 877.7712981700897 and batch: 700, loss is 3.787880482673645 and perplexity is 44.162697406303096
At time: 878.9332892894745 and batch: 750, loss is 3.7481851816177367 and perplexity is 42.44398393946478
At time: 880.0930938720703 and batch: 800, loss is 3.713970742225647 and perplexity is 41.01634895512246
At time: 881.2574942111969 and batch: 850, loss is 3.7159605598449708 and perplexity is 41.09804526237398
At time: 882.4203267097473 and batch: 900, loss is 3.6878879690170288 and perplexity is 39.96036025048144
At time: 883.5814719200134 and batch: 950, loss is 3.8050977182388306 and perplexity is 44.929640343832816
At time: 884.745120048523 and batch: 1000, loss is 3.766600642204285 and perplexity is 43.23285083257064
At time: 885.906985282898 and batch: 1050, loss is 3.711612830162048 and perplexity is 40.91974994186127
At time: 887.0671539306641 and batch: 1100, loss is 3.728855185508728 and perplexity is 41.631420618924444
At time: 888.230890750885 and batch: 1150, loss is 3.704771876335144 and perplexity is 40.64077513675034
At time: 889.3942658901215 and batch: 1200, loss is 3.7437354707717896 and perplexity is 42.255540055113315
At time: 890.5573723316193 and batch: 1250, loss is 3.72000714302063 and perplexity is 41.264688862081904
At time: 891.7177405357361 and batch: 1300, loss is 3.719846849441528 and perplexity is 41.25807492751347
At time: 892.8800895214081 and batch: 1350, loss is 3.5800589179992675 and perplexity is 35.87565450658179
At time: 894.0439176559448 and batch: 1400, loss is 3.6245754766464233 and perplexity is 37.508796419159076
At time: 895.2066514492035 and batch: 1450, loss is 3.5396273565292358 and perplexity is 34.45407771125892
At time: 896.3737280368805 and batch: 1500, loss is 3.543806939125061 and perplexity is 34.59838273212205
At time: 897.5426206588745 and batch: 1550, loss is 3.5565478897094724 and perplexity is 35.04201919056651
At time: 898.7095775604248 and batch: 1600, loss is 3.644165816307068 and perplexity is 38.250851302793784
At time: 899.8732154369354 and batch: 1650, loss is 3.579307780265808 and perplexity is 35.84871706689956
At time: 901.0400831699371 and batch: 1700, loss is 3.593350954055786 and perplexity is 36.35569831186571
At time: 902.2039949893951 and batch: 1750, loss is 3.6029711151123047 and perplexity is 36.70713370713172
At time: 903.364547252655 and batch: 1800, loss is 3.537384133338928 and perplexity is 34.37687614767875
At time: 904.5285346508026 and batch: 1850, loss is 3.5793466567993164 and perplexity is 35.8501107678408
At time: 905.687150478363 and batch: 1900, loss is 3.6688039970397948 and perplexity is 39.20498852692931
At time: 906.8511333465576 and batch: 1950, loss is 3.6036130142211915 and perplexity is 36.73070354746857
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3961366165515985 and perplexity of 81.13679980197563
finished 19 epochs...
Completing Train Step...
At time: 910.493891954422 and batch: 50, loss is 3.840385551452637 and perplexity is 46.54341586249263
At time: 911.6777551174164 and batch: 100, loss is 3.82210563659668 and perplexity is 45.70033537966163
At time: 912.8418431282043 and batch: 150, loss is 3.7777740144729615 and perplexity is 43.718616334813156
At time: 914.00688123703 and batch: 200, loss is 3.7670897674560546 and perplexity is 43.254002284051666
At time: 915.1668217182159 and batch: 250, loss is 3.766791729927063 and perplexity is 43.24111288894907
At time: 916.329258441925 and batch: 300, loss is 3.7755156803131102 and perplexity is 43.619996490318684
At time: 917.4909815788269 and batch: 350, loss is 3.8020299959182737 and perplexity is 44.79201988190477
At time: 918.6529529094696 and batch: 400, loss is 3.77069149017334 and perplexity is 43.41007209807225
At time: 919.8160247802734 and batch: 450, loss is 3.7986399126052857 and perplexity is 44.64042830197343
At time: 921.0174119472504 and batch: 500, loss is 3.815788631439209 and perplexity is 45.41255603414996
At time: 922.1773250102997 and batch: 550, loss is 3.7688914585113524 and perplexity is 43.332002878459555
At time: 923.3408970832825 and batch: 600, loss is 3.7410545253753664 and perplexity is 42.142406979090545
At time: 924.5004510879517 and batch: 650, loss is 3.7644353532791137 and perplexity is 43.13934049444415
At time: 925.6645057201385 and batch: 700, loss is 3.785627179145813 and perplexity is 44.063297475603726
At time: 926.8302628993988 and batch: 750, loss is 3.746206007003784 and perplexity is 42.36006295846849
At time: 927.9933316707611 and batch: 800, loss is 3.712232666015625 and perplexity is 40.94512133223105
At time: 929.1542959213257 and batch: 850, loss is 3.714163179397583 and perplexity is 41.02424278482731
At time: 930.318466424942 and batch: 900, loss is 3.6861586809158324 and perplexity is 39.891316990030944
At time: 931.4792048931122 and batch: 950, loss is 3.8034263610839845 and perplexity is 44.85460958704171
At time: 932.6432752609253 and batch: 1000, loss is 3.7648682260513304 and perplexity is 43.158018382638545
At time: 933.8042120933533 and batch: 1050, loss is 3.709851288795471 and perplexity is 40.84773155993108
At time: 934.9682722091675 and batch: 1100, loss is 3.727166395187378 and perplexity is 41.56117321198516
At time: 936.1309700012207 and batch: 1150, loss is 3.703289427757263 and perplexity is 40.58057191256242
At time: 937.2928335666656 and batch: 1200, loss is 3.7422377061843872 and perplexity is 42.192298575843715
At time: 938.4567315578461 and batch: 1250, loss is 3.718744134902954 and perplexity is 41.21260412372317
At time: 939.6194295883179 and batch: 1300, loss is 3.7187449884414674 and perplexity is 41.21263930028302
At time: 940.7822060585022 and batch: 1350, loss is 3.5792093753814695 and perplexity is 35.84518955160813
At time: 941.9435904026031 and batch: 1400, loss is 3.6237262153625487 and perplexity is 37.47695517323802
At time: 943.1057784557343 and batch: 1450, loss is 3.5389337062835695 and perplexity is 34.4301869186753
At time: 944.2689180374146 and batch: 1500, loss is 3.5432679748535154 and perplexity is 34.579740464185626
At time: 945.4312529563904 and batch: 1550, loss is 3.5561113071441652 and perplexity is 35.026723795029206
At time: 946.5933675765991 and batch: 1600, loss is 3.6438742113113403 and perplexity is 38.239698789606365
At time: 947.7575106620789 and batch: 1650, loss is 3.57910710811615 and perplexity is 35.841523949536565
At time: 948.919676065445 and batch: 1700, loss is 3.5932057762145995 and perplexity is 36.35042065317878
At time: 950.0812947750092 and batch: 1750, loss is 3.6029594278335573 and perplexity is 36.70670470313501
At time: 951.241485118866 and batch: 1800, loss is 3.5373653316497804 and perplexity is 34.37622981041568
At time: 952.4034562110901 and batch: 1850, loss is 3.579347152709961 and perplexity is 35.85012854629675
At time: 953.5672087669373 and batch: 1900, loss is 3.6687123012542724 and perplexity is 39.201393759524976
At time: 954.7304861545563 and batch: 1950, loss is 3.603349027633667 and perplexity is 36.72100841413059
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.396094033884448 and perplexity of 81.13334485419696
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f6867fdeb38>
ELAPSED
3942.9653403759003


RESULTS SO FAR:
[{'best_accuracy': -78.24843512754734, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}}, {'best_accuracy': -80.22026219008522, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.862353544247577, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.936075502546612}}, {'best_accuracy': -78.14425651975347, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.3679014798345962, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.3008932223994304}}, {'best_accuracy': -81.13334485419696, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.12560107942970977, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.9438108012791336}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.8553086698259572, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.5482996063691655}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6811847686767578 and batch: 50, loss is 7.447224893569946 and perplexity is 1715.0969584990873
At time: 2.908682346343994 and batch: 100, loss is 6.653835153579712 and perplexity is 775.7537625915102
At time: 4.1376988887786865 and batch: 150, loss is 6.426424837112426 and perplexity is 617.9606838772926
At time: 5.366602420806885 and batch: 200, loss is 6.3238002300262455 and perplexity is 557.6883144283887
At time: 6.5937182903289795 and batch: 250, loss is 6.260171575546265 and perplexity is 523.3087193852098
At time: 7.819817781448364 and batch: 300, loss is 6.193564329147339 and perplexity is 489.5880529017069
At time: 9.047808647155762 and batch: 350, loss is 6.147248983383179 and perplexity is 467.4297094857105
At time: 10.274710893630981 and batch: 400, loss is 6.101268711090088 and perplexity is 446.4237937643599
At time: 11.503273725509644 and batch: 450, loss is 6.036341066360474 and perplexity is 418.35948143239403
At time: 12.7325599193573 and batch: 500, loss is 6.020165977478027 and perplexity is 411.6469141734992
At time: 13.959678411483765 and batch: 550, loss is 5.970908098220825 and perplexity is 391.86135782789756
At time: 15.186021089553833 and batch: 600, loss is 6.012382249832154 and perplexity is 408.4552045211424
At time: 16.413998126983643 and batch: 650, loss is 6.0935178565979005 and perplexity is 442.9770029398083
At time: 17.648576736450195 and batch: 700, loss is 5.998268003463745 and perplexity is 402.73066097585297
At time: 18.8788743019104 and batch: 750, loss is 5.942850713729858 and perplexity is 381.0195605099033
At time: 20.10743546485901 and batch: 800, loss is 5.953298578262329 and perplexity is 385.02126951770066
At time: 21.336329460144043 and batch: 850, loss is 5.986550168991089 and perplexity is 398.0390710728965
At time: 22.56503176689148 and batch: 900, loss is 5.973853101730347 and perplexity is 393.0170918870659
At time: 23.792973041534424 and batch: 950, loss is 5.993186445236206 and perplexity is 400.6893525784231
At time: 25.021434783935547 and batch: 1000, loss is 5.979296779632568 and perplexity is 395.16238418778187
At time: 26.2493417263031 and batch: 1050, loss is 5.875223264694214 and perplexity is 356.10415728183955
At time: 27.478317499160767 and batch: 1100, loss is 5.9598027610778805 and perplexity is 387.5336799738161
At time: 28.70704221725464 and batch: 1150, loss is 5.870855178833008 and perplexity is 354.55205607084
At time: 29.93583393096924 and batch: 1200, loss is 5.951890153884888 and perplexity is 384.4793778721576
At time: 31.16517400741577 and batch: 1250, loss is 5.8894141674041744 and perplexity is 361.1936233814045
At time: 32.39371371269226 and batch: 1300, loss is 5.899416999816895 and perplexity is 364.82471297881796
At time: 33.621976375579834 and batch: 1350, loss is 5.88415638923645 and perplexity is 359.2995311558358
At time: 34.851900815963745 and batch: 1400, loss is 5.902076263427734 and perplexity is 365.7961691689396
At time: 36.08104395866394 and batch: 1450, loss is 5.873091030120849 and perplexity is 355.3456686112154
At time: 37.30883860588074 and batch: 1500, loss is 5.858361015319824 and perplexity is 350.14978333365383
At time: 38.53814244270325 and batch: 1550, loss is 5.836007528305053 and perplexity is 342.4095476275411
At time: 39.76744222640991 and batch: 1600, loss is 5.844674119949341 and perplexity is 345.38996773907576
At time: 40.997222661972046 and batch: 1650, loss is 5.836347208023072 and perplexity is 342.5258769623652
At time: 42.228397846221924 and batch: 1700, loss is 5.849141817092896 and perplexity is 346.9365176973035
At time: 43.455486536026 and batch: 1750, loss is 5.857606582641601 and perplexity is 349.88571851692257
At time: 44.68169164657593 and batch: 1800, loss is 5.871922426223755 and perplexity is 354.93065281982615
At time: 45.91504883766174 and batch: 1850, loss is 5.830995798110962 and perplexity is 340.697776409641
At time: 47.14448380470276 and batch: 1900, loss is 5.805427589416504 and perplexity is 332.09716422143333
At time: 48.37257647514343 and batch: 1950, loss is 5.741341819763184 and perplexity is 311.4820835136324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.264962981468023 and perplexity of 193.43914782159908
finished 1 epochs...
Completing Train Step...
At time: 52.03417420387268 and batch: 50, loss is 5.546182975769043 and perplexity is 256.25754547342285
At time: 53.191917419433594 and batch: 100, loss is 5.466814699172974 and perplexity is 236.70501398707816
At time: 54.35067057609558 and batch: 150, loss is 5.357859659194946 and perplexity is 212.27012947170473
At time: 55.509438276290894 and batch: 200, loss is 5.3093688011169435 and perplexity is 202.22254545090564
At time: 56.66726303100586 and batch: 250, loss is 5.293569145202636 and perplexity is 199.05260672736202
At time: 57.82552361488342 and batch: 300, loss is 5.292191877365112 and perplexity is 198.77864667563054
At time: 58.98370838165283 and batch: 350, loss is 5.248370180130005 and perplexity is 190.2559327321077
At time: 60.14032578468323 and batch: 400, loss is 5.207615242004395 and perplexity is 182.6579433953038
At time: 61.342374086380005 and batch: 450, loss is 5.160253925323486 and perplexity is 174.20868598620936
At time: 62.49974298477173 and batch: 500, loss is 5.131838808059692 and perplexity is 169.32819400061013
At time: 63.65811586380005 and batch: 550, loss is 5.078170337677002 and perplexity is 160.48016264068508
At time: 64.81623864173889 and batch: 600, loss is 5.083908777236939 and perplexity is 161.40371569690612
At time: 65.97471332550049 and batch: 650, loss is 5.149104290008545 and perplexity is 172.2771108580693
At time: 67.13348007202148 and batch: 700, loss is 5.112517261505127 and perplexity is 166.08791581514282
At time: 68.2916841506958 and batch: 750, loss is 5.057846240997314 and perplexity is 157.25146957365305
At time: 69.45067572593689 and batch: 800, loss is 5.035358657836914 and perplexity is 153.75472806205292
At time: 70.60844135284424 and batch: 850, loss is 5.036891489028931 and perplexity is 153.99058882633375
At time: 71.76704359054565 and batch: 900, loss is 5.046380586624146 and perplexity is 155.45877541874248
At time: 72.92569422721863 and batch: 950, loss is 5.098454446792602 and perplexity is 163.76859851651616
At time: 74.08399987220764 and batch: 1000, loss is 5.0574258518218995 and perplexity is 157.18537665137416
At time: 75.24316191673279 and batch: 1050, loss is 4.963704500198364 and perplexity is 143.12301428176133
At time: 76.40171194076538 and batch: 1100, loss is 5.041373596191407 and perplexity is 154.68234024138658
At time: 77.56656384468079 and batch: 1150, loss is 4.94951940536499 and perplexity is 141.10713229228259
At time: 78.73416900634766 and batch: 1200, loss is 5.023929786682129 and perplexity is 152.00748859151395
At time: 79.89252185821533 and batch: 1250, loss is 4.962457342147827 and perplexity is 142.94462852302203
At time: 81.05038976669312 and batch: 1300, loss is 5.000432319641114 and perplexity is 148.47733489748512
At time: 82.20770144462585 and batch: 1350, loss is 4.913647041320801 and perplexity is 136.1350001190127
At time: 83.36667728424072 and batch: 1400, loss is 4.9316168212890625 and perplexity is 138.60342824870767
At time: 84.52581191062927 and batch: 1450, loss is 4.869741439819336 and perplexity is 130.2872254524624
At time: 85.68475461006165 and batch: 1500, loss is 4.839295978546143 and perplexity is 126.38034592791477
At time: 86.84470510482788 and batch: 1550, loss is 4.834859895706177 and perplexity is 125.82095391603544
At time: 88.00272130966187 and batch: 1600, loss is 4.90526083946228 and perplexity is 134.99811825133472
At time: 89.16197967529297 and batch: 1650, loss is 4.859406633377075 and perplexity is 128.94766616148164
At time: 90.3271849155426 and batch: 1700, loss is 4.886893053054809 and perplexity is 132.5411353948204
At time: 91.48533010482788 and batch: 1750, loss is 4.897945070266724 and perplexity is 134.0141069648282
At time: 92.64482021331787 and batch: 1800, loss is 4.845484027862549 and perplexity is 127.1648184151131
At time: 93.80304789543152 and batch: 1850, loss is 4.847262992858886 and perplexity is 127.39124151551049
At time: 94.9683849811554 and batch: 1900, loss is 4.911952238082886 and perplexity is 135.90447348384086
At time: 96.13105487823486 and batch: 1950, loss is 4.828364562988281 and perplexity is 125.00635337220342
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.668687261537064 and perplexity of 106.5577680969996
finished 2 epochs...
Completing Train Step...
At time: 99.74675011634827 and batch: 50, loss is 4.780505352020263 and perplexity is 119.16455487976738
At time: 100.93602871894836 and batch: 100, loss is 4.728971223831177 and perplexity is 113.17906650842903
At time: 102.09640860557556 and batch: 150, loss is 4.672643365859986 and perplexity is 106.98015669980597
At time: 103.26130986213684 and batch: 200, loss is 4.659272127151489 and perplexity is 105.55922049678567
At time: 104.4180064201355 and batch: 250, loss is 4.671212501525879 and perplexity is 106.8271920710409
At time: 105.57403445243835 and batch: 300, loss is 4.69298900604248 and perplexity is 109.17902936014532
At time: 106.73068737983704 and batch: 350, loss is 4.69515440940857 and perplexity is 109.41570215137826
At time: 107.88970875740051 and batch: 400, loss is 4.658876190185547 and perplexity is 105.5174339722557
At time: 109.04572534561157 and batch: 450, loss is 4.658181734085083 and perplexity is 105.44418218454778
At time: 110.2018232345581 and batch: 500, loss is 4.657618036270142 and perplexity is 105.38476027902468
At time: 111.36050868034363 and batch: 550, loss is 4.614120283126831 and perplexity is 100.89902690160973
At time: 112.51868510246277 and batch: 600, loss is 4.596262092590332 and perplexity is 99.11314661124798
At time: 113.67673397064209 and batch: 650, loss is 4.650090370178223 and perplexity is 104.59443736797381
At time: 114.83642911911011 and batch: 700, loss is 4.668470888137818 and perplexity is 106.5347143247018
At time: 115.99429512023926 and batch: 750, loss is 4.626619558334351 and perplexity is 102.16810637128675
At time: 117.1523551940918 and batch: 800, loss is 4.60836046218872 and perplexity is 100.31953705477648
At time: 118.30945563316345 and batch: 850, loss is 4.605124053955078 and perplexity is 99.99538690310523
At time: 119.46653437614441 and batch: 900, loss is 4.597665138244629 and perplexity is 99.25230448047833
At time: 120.66854500770569 and batch: 950, loss is 4.667387771606445 and perplexity is 106.41938728203945
At time: 121.82938194274902 and batch: 1000, loss is 4.644717912673951 and perplexity is 104.03401496876253
At time: 122.98651099205017 and batch: 1050, loss is 4.569697980880737 and perplexity is 96.51495600855976
At time: 124.14420080184937 and batch: 1100, loss is 4.636920299530029 and perplexity is 103.22595253970157
At time: 125.30261278152466 and batch: 1150, loss is 4.5680943202972415 and perplexity is 96.36030281664881
At time: 126.4600772857666 and batch: 1200, loss is 4.642466840744018 and perplexity is 103.80009030730875
At time: 127.61814475059509 and batch: 1250, loss is 4.604784412384033 and perplexity is 99.96143007970109
At time: 128.77794909477234 and batch: 1300, loss is 4.623967733383179 and perplexity is 101.8975333522985
At time: 129.93572092056274 and batch: 1350, loss is 4.518491601943969 and perplexity is 91.69717776332881
At time: 131.0942006111145 and batch: 1400, loss is 4.538235015869141 and perplexity is 93.5255831895752
At time: 132.25271677970886 and batch: 1450, loss is 4.472774724960328 and perplexity is 87.59945048849875
At time: 133.4096131324768 and batch: 1500, loss is 4.463466987609864 and perplexity is 86.78788061006041
At time: 134.5668032169342 and batch: 1550, loss is 4.462119903564453 and perplexity is 86.67104874959048
At time: 135.7253544330597 and batch: 1600, loss is 4.549420900344849 and perplexity is 94.5776225846326
At time: 136.88382983207703 and batch: 1650, loss is 4.501073598861694 and perplexity is 90.11382548631535
At time: 138.04226517677307 and batch: 1700, loss is 4.53124475479126 and perplexity is 92.87409463600399
At time: 139.20068335533142 and batch: 1750, loss is 4.5440763568878175 and perplexity is 94.07349673192321
At time: 140.3648133277893 and batch: 1800, loss is 4.485845136642456 and perplexity is 88.75192663137696
At time: 141.52784419059753 and batch: 1850, loss is 4.511495027542114 and perplexity is 91.05785079404993
At time: 142.69123148918152 and batch: 1900, loss is 4.593654556274414 and perplexity is 98.85504213671253
At time: 143.85167837142944 and batch: 1950, loss is 4.516695032119751 and perplexity is 91.53258527601197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.534581667877907 and perplexity of 93.18452506944007
finished 3 epochs...
Completing Train Step...
At time: 147.52091598510742 and batch: 50, loss is 4.4837144756317135 and perplexity is 88.56302767296036
At time: 148.67852592468262 and batch: 100, loss is 4.432918643951416 and perplexity is 84.17674066476502
At time: 149.86406445503235 and batch: 150, loss is 4.38527666091919 and perplexity is 80.26042506454003
At time: 151.02169847488403 and batch: 200, loss is 4.378449697494506 and perplexity is 79.714356195178
At time: 152.1762342453003 and batch: 250, loss is 4.385400915145874 and perplexity is 80.27039838119033
At time: 153.33454728126526 and batch: 300, loss is 4.410452728271484 and perplexity is 82.30671764857576
At time: 154.49392437934875 and batch: 350, loss is 4.423209571838379 and perplexity is 83.36341731598972
At time: 155.65190172195435 and batch: 400, loss is 4.387105550765991 and perplexity is 80.4073468519707
At time: 156.81053638458252 and batch: 450, loss is 4.399451875686646 and perplexity is 81.406235696834
At time: 157.9680666923523 and batch: 500, loss is 4.4069637966156 and perplexity is 82.02005549899016
At time: 159.12474846839905 and batch: 550, loss is 4.364525537490845 and perplexity is 78.61209260130407
At time: 160.28365325927734 and batch: 600, loss is 4.350419430732727 and perplexity is 77.5109665897776
At time: 161.4392969608307 and batch: 650, loss is 4.394429636001587 and perplexity is 80.99841900309055
At time: 162.59945130348206 and batch: 700, loss is 4.423513669967651 and perplexity is 83.38877183017999
At time: 163.75441455841064 and batch: 750, loss is 4.3881338024139405 and perplexity is 80.49006836085394
At time: 164.9074239730835 and batch: 800, loss is 4.363004817962646 and perplexity is 78.49263650955947
At time: 166.06261205673218 and batch: 850, loss is 4.362282867431641 and perplexity is 78.43598915970398
At time: 167.21712636947632 and batch: 900, loss is 4.345445547103882 and perplexity is 77.12639326632576
At time: 168.37139105796814 and batch: 950, loss is 4.424465484619141 and perplexity is 83.46818027004095
At time: 169.52679443359375 and batch: 1000, loss is 4.407123365402222 and perplexity is 82.03314438398573
At time: 170.68068480491638 and batch: 1050, loss is 4.346779737472534 and perplexity is 77.22936323288498
At time: 171.8385889530182 and batch: 1100, loss is 4.404343776702881 and perplexity is 81.80544258815797
At time: 172.9943745136261 and batch: 1150, loss is 4.342989201545715 and perplexity is 76.93717667860962
At time: 174.15008115768433 and batch: 1200, loss is 4.419564619064331 and perplexity is 83.06011469445392
At time: 175.3062686920166 and batch: 1250, loss is 4.390508356094361 and perplexity is 80.68142345047059
At time: 176.46036648750305 and batch: 1300, loss is 4.395865497589111 and perplexity is 81.11480505872447
At time: 177.61560821533203 and batch: 1350, loss is 4.282249498367309 and perplexity is 72.4031276733919
At time: 178.76946592330933 and batch: 1400, loss is 4.313307523727417 and perplexity is 74.68711025188547
At time: 179.92390131950378 and batch: 1450, loss is 4.2424592733383175 and perplexity is 69.5787547806409
At time: 181.07873916625977 and batch: 1500, loss is 4.242213740348816 and perplexity is 69.56167299813018
At time: 182.23613452911377 and batch: 1550, loss is 4.24154218673706 and perplexity is 69.51497428748748
At time: 183.3954176902771 and batch: 1600, loss is 4.334268999099732 and perplexity is 76.26918566372916
At time: 184.55750274658203 and batch: 1650, loss is 4.282469868659973 and perplexity is 72.41908493001513
At time: 185.71894764900208 and batch: 1700, loss is 4.3174547815322875 and perplexity is 74.99750014136116
At time: 186.87762117385864 and batch: 1750, loss is 4.330971641540527 and perplexity is 76.01811305341487
At time: 188.03516840934753 and batch: 1800, loss is 4.268055601119995 and perplexity is 71.38270414389896
At time: 189.19559121131897 and batch: 1850, loss is 4.306616258621216 and perplexity is 74.18902725824069
At time: 190.35602521896362 and batch: 1900, loss is 4.391002759933472 and perplexity is 80.72132251828289
At time: 191.5216429233551 and batch: 1950, loss is 4.31940598487854 and perplexity is 75.14397837253239
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489565543241279 and perplexity of 89.08273487388745
finished 4 epochs...
Completing Train Step...
At time: 195.14922642707825 and batch: 50, loss is 4.288772110939026 and perplexity is 72.87692875483077
At time: 196.33490467071533 and batch: 100, loss is 4.237940111160278 and perplexity is 69.26502653199353
At time: 197.49448323249817 and batch: 150, loss is 4.196317753791809 and perplexity is 66.44122709479534
At time: 198.65486907958984 and batch: 200, loss is 4.19402440071106 and perplexity is 66.28902849122389
At time: 199.8147428035736 and batch: 250, loss is 4.195726051330566 and perplexity is 66.40192528583056
At time: 200.97683095932007 and batch: 300, loss is 4.213815894126892 and perplexity is 67.61405625004542
At time: 202.13640999794006 and batch: 350, loss is 4.2336209201812744 and perplexity is 68.96650280881225
At time: 203.3011496067047 and batch: 400, loss is 4.199028816223144 and perplexity is 66.6215977971063
At time: 204.4600625038147 and batch: 450, loss is 4.224308061599731 and perplexity is 68.32720896830864
At time: 205.61840963363647 and batch: 500, loss is 4.230473704338074 and perplexity is 68.74979153597434
At time: 206.77743577957153 and batch: 550, loss is 4.191031045913697 and perplexity is 66.09089859425576
At time: 207.93774724006653 and batch: 600, loss is 4.178503837585449 and perplexity is 65.26812840555851
At time: 209.12352013587952 and batch: 650, loss is 4.216694436073303 and perplexity is 67.80896654126713
At time: 210.28275775909424 and batch: 700, loss is 4.251553311347961 and perplexity is 70.21439249737979
At time: 211.4439709186554 and batch: 750, loss is 4.220284328460694 and perplexity is 68.05283089554834
At time: 212.60345029830933 and batch: 800, loss is 4.189712371826172 and perplexity is 66.00380367638475
At time: 213.76372623443604 and batch: 850, loss is 4.188393921852112 and perplexity is 65.91683830548298
At time: 214.92228984832764 and batch: 900, loss is 4.170830354690552 and perplexity is 64.7692112030814
At time: 216.0801603794098 and batch: 950, loss is 4.25431116104126 and perplexity is 70.40830049985537
At time: 217.24076509475708 and batch: 1000, loss is 4.242091512680053 and perplexity is 69.55317115659513
At time: 218.39885187149048 and batch: 1050, loss is 4.186093349456787 and perplexity is 65.76536615002726
At time: 219.56074166297913 and batch: 1100, loss is 4.231181583404541 and perplexity is 68.79847530330359
At time: 220.71959233283997 and batch: 1150, loss is 4.182022037506104 and perplexity is 65.49815913951973
At time: 221.8781452178955 and batch: 1200, loss is 4.256634855270386 and perplexity is 70.57209809547047
At time: 223.04531335830688 and batch: 1250, loss is 4.230276832580566 and perplexity is 68.73625797591795
At time: 224.205712556839 and batch: 1300, loss is 4.228842425346374 and perplexity is 68.63773286968173
At time: 225.3705050945282 and batch: 1350, loss is 4.113076324462891 and perplexity is 61.13449813669792
At time: 226.5337312221527 and batch: 1400, loss is 4.150683541297912 and perplexity is 63.47737487948886
At time: 227.70151495933533 and batch: 1450, loss is 4.077103695869446 and perplexity is 58.974414415109585
At time: 228.8654260635376 and batch: 1500, loss is 4.08721396446228 and perplexity is 59.57368587801437
At time: 230.03006052970886 and batch: 1550, loss is 4.0856808042526245 and perplexity is 59.48241985387937
At time: 231.19755053520203 and batch: 1600, loss is 4.18240424156189 and perplexity is 65.52319758618249
At time: 232.36558270454407 and batch: 1650, loss is 4.127220144271851 and perplexity is 62.00531730005959
At time: 233.52825593948364 and batch: 1700, loss is 4.16108745098114 and perplexity is 64.14123513766495
At time: 234.6924638748169 and batch: 1750, loss is 4.177698249816895 and perplexity is 65.21557037253521
At time: 235.8588194847107 and batch: 1800, loss is 4.11182119846344 and perplexity is 61.05781477233224
At time: 237.01954674720764 and batch: 1850, loss is 4.158250799179077 and perplexity is 63.959546602811216
At time: 238.1810178756714 and batch: 1900, loss is 4.242446327209473 and perplexity is 69.57785401094743
At time: 239.34245896339417 and batch: 1950, loss is 4.168008179664612 and perplexity is 64.58667884305898
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470759050236192 and perplexity of 87.42305632665101
finished 5 epochs...
Completing Train Step...
At time: 243.05486512184143 and batch: 50, loss is 4.142589211463928 and perplexity is 62.965641931832494
At time: 244.21314907073975 and batch: 100, loss is 4.095146245956421 and perplexity is 60.04812031011696
At time: 245.373863697052 and batch: 150, loss is 4.054435224533081 and perplexity is 57.65259302952241
At time: 246.53462934494019 and batch: 200, loss is 4.051930594444275 and perplexity is 57.508375291757524
At time: 247.69438791275024 and batch: 250, loss is 4.0516785049438475 and perplexity is 57.493879861309516
At time: 248.85450315475464 and batch: 300, loss is 4.065574851036072 and perplexity is 58.29841179435544
At time: 250.01468205451965 and batch: 350, loss is 4.088474268913269 and perplexity is 59.648814191818126
At time: 251.17706394195557 and batch: 400, loss is 4.057109804153442 and perplexity is 57.80699586920253
At time: 252.33786487579346 and batch: 450, loss is 4.088622841835022 and perplexity is 59.65767704879568
At time: 253.4998209476471 and batch: 500, loss is 4.095167889595031 and perplexity is 60.049419983996955
At time: 254.66144394874573 and batch: 550, loss is 4.058935036659241 and perplexity is 57.91260342698017
At time: 255.8217339515686 and batch: 600, loss is 4.046432409286499 and perplexity is 57.19305124563023
At time: 256.98225355148315 and batch: 650, loss is 4.084041714668274 and perplexity is 59.3850026985774
At time: 258.1435377597809 and batch: 700, loss is 4.11466537475586 and perplexity is 61.23172115454705
At time: 259.3034977912903 and batch: 750, loss is 4.085668277740479 and perplexity is 59.48167475129139
At time: 260.46616792678833 and batch: 800, loss is 4.057872042655945 and perplexity is 57.851075384585755
At time: 261.62768149375916 and batch: 850, loss is 4.056978240013122 and perplexity is 57.79939104175878
At time: 262.79032492637634 and batch: 900, loss is 4.043139343261719 and perplexity is 57.0050205204376
At time: 263.9595003128052 and batch: 950, loss is 4.125478715896606 and perplexity is 61.897433444364786
At time: 265.12170243263245 and batch: 1000, loss is 4.109982104301452 and perplexity is 60.945626895296336
At time: 266.283456325531 and batch: 1050, loss is 4.056670451164246 and perplexity is 57.78160377122647
At time: 267.4751331806183 and batch: 1100, loss is 4.100019507408142 and perplexity is 60.341464691460516
At time: 268.63514590263367 and batch: 1150, loss is 4.054378819465637 and perplexity is 57.64934122283434
At time: 269.79548621177673 and batch: 1200, loss is 4.128087725639343 and perplexity is 62.05913530040601
At time: 270.9566011428833 and batch: 1250, loss is 4.106466798782349 and perplexity is 60.7317605197667
At time: 272.11638140678406 and batch: 1300, loss is 4.10306101322174 and perplexity is 60.525272992431496
At time: 273.27877378463745 and batch: 1350, loss is 3.983695974349976 and perplexity is 53.71519779142757
At time: 274.4429829120636 and batch: 1400, loss is 4.026813292503357 and perplexity is 56.08190954400502
At time: 275.60477018356323 and batch: 1450, loss is 3.9533315229415895 and perplexity is 52.108679237744575
At time: 276.7674837112427 and batch: 1500, loss is 3.9612789297103883 and perplexity is 52.524458101284395
At time: 277.92941522598267 and batch: 1550, loss is 3.9639338207244874 and perplexity is 52.66409008495158
At time: 279.0912821292877 and batch: 1600, loss is 4.06319794178009 and perplexity is 58.16000631354903
At time: 280.25366830825806 and batch: 1650, loss is 4.007147965431213 and perplexity is 54.98981385429788
At time: 281.4161112308502 and batch: 1700, loss is 4.040093746185303 and perplexity is 56.83167030804435
At time: 282.57807993888855 and batch: 1750, loss is 4.050020151138305 and perplexity is 57.39861368119522
At time: 283.7397232055664 and batch: 1800, loss is 3.989053874015808 and perplexity is 54.003770814034446
At time: 284.90598130226135 and batch: 1850, loss is 4.036997547149658 and perplexity is 56.65598027125738
At time: 286.0678918361664 and batch: 1900, loss is 4.1209787130355835 and perplexity is 61.61952059007328
At time: 287.2296802997589 and batch: 1950, loss is 4.045060520172119 and perplexity is 57.11464251754605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.472168536518895 and perplexity of 87.54636480572601
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 290.8762893676758 and batch: 50, loss is 4.058199529647827 and perplexity is 57.87002396177751
At time: 292.06445956230164 and batch: 100, loss is 4.042074332237243 and perplexity is 56.94434186258807
At time: 293.22603940963745 and batch: 150, loss is 4.0084019374847415 and perplexity is 55.058812796431056
At time: 294.38862776756287 and batch: 200, loss is 4.003655676841736 and perplexity is 54.79810849489441
At time: 295.5509467124939 and batch: 250, loss is 4.007468800544739 and perplexity is 55.00745934796422
At time: 296.7391719818115 and batch: 300, loss is 4.006493368148804 and perplexity is 54.95382945052006
At time: 297.90143942832947 and batch: 350, loss is 4.021540803909302 and perplexity is 55.786996461726424
At time: 299.06360387802124 and batch: 400, loss is 3.9828539419174196 and perplexity is 53.66998688995997
At time: 300.2247910499573 and batch: 450, loss is 4.008927731513977 and perplexity is 55.08777000355241
At time: 301.38702034950256 and batch: 500, loss is 4.012824444770813 and perplexity is 55.30285002765081
At time: 302.54869318008423 and batch: 550, loss is 3.974296336174011 and perplexity is 53.2126599048532
At time: 303.71042227745056 and batch: 600, loss is 3.9453763341903687 and perplexity is 51.695789344824064
At time: 304.87023520469666 and batch: 650, loss is 3.980555381774902 and perplexity is 53.54676486811171
At time: 306.02876138687134 and batch: 700, loss is 3.996211495399475 and perplexity is 54.391696013497274
At time: 307.18832659721375 and batch: 750, loss is 3.9596260261535643 and perplexity is 52.43771194893027
At time: 308.3469808101654 and batch: 800, loss is 3.920751714706421 and perplexity is 50.438345777199785
At time: 309.50767254829407 and batch: 850, loss is 3.919236855506897 and perplexity is 50.36199662879584
At time: 310.6697087287903 and batch: 900, loss is 3.900165066719055 and perplexity is 49.410604478789146
At time: 311.83165884017944 and batch: 950, loss is 3.9905288934707643 and perplexity is 54.08348620304803
At time: 312.9940822124481 and batch: 1000, loss is 3.956057782173157 and perplexity is 52.250934830263006
At time: 314.15603733062744 and batch: 1050, loss is 3.902503318786621 and perplexity is 49.526274106543255
At time: 315.3186581134796 and batch: 1100, loss is 3.9291141700744627 and perplexity is 50.861902712283765
At time: 316.48117327690125 and batch: 1150, loss is 3.886759629249573 and perplexity is 48.752653622748774
At time: 317.64685130119324 and batch: 1200, loss is 3.9422074270248415 and perplexity is 51.53222947743151
At time: 318.8085081577301 and batch: 1250, loss is 3.9113840103149413 and perplexity is 49.96806045003472
At time: 319.96972012519836 and batch: 1300, loss is 3.9103596591949463 and perplexity is 49.91690181802312
At time: 321.13086438179016 and batch: 1350, loss is 3.7839465808868407 and perplexity is 43.98930696615729
At time: 322.2918679714203 and batch: 1400, loss is 3.8168694829940795 and perplexity is 45.461666801893855
At time: 323.4537534713745 and batch: 1450, loss is 3.733565454483032 and perplexity is 41.827978364334136
At time: 324.61582112312317 and batch: 1500, loss is 3.729280934333801 and perplexity is 41.64914892097317
At time: 325.78081822395325 and batch: 1550, loss is 3.7339781761169433 and perplexity is 41.8452452388691
At time: 326.9416084289551 and batch: 1600, loss is 3.8176587200164795 and perplexity is 45.497560995083816
At time: 328.1025245189667 and batch: 1650, loss is 3.749204545021057 and perplexity is 42.487271842687576
At time: 329.26749658584595 and batch: 1700, loss is 3.773719940185547 and perplexity is 43.541736600499384
At time: 330.4310154914856 and batch: 1750, loss is 3.770007538795471 and perplexity is 43.380391870520654
At time: 331.6006941795349 and batch: 1800, loss is 3.703612332344055 and perplexity is 40.59367768121015
At time: 332.76146483421326 and batch: 1850, loss is 3.740709547996521 and perplexity is 42.127871309375436
At time: 333.926958322525 and batch: 1900, loss is 3.8166529035568235 and perplexity is 45.45182180583152
At time: 335.08730387687683 and batch: 1950, loss is 3.7407977390289306 and perplexity is 42.13158677367234
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.396812545421511 and perplexity of 81.19166104643485
finished 7 epochs...
Completing Train Step...
At time: 338.76766562461853 and batch: 50, loss is 3.944603443145752 and perplexity is 51.65584956873089
At time: 339.9300591945648 and batch: 100, loss is 3.9184111166000366 and perplexity is 50.320427933558705
At time: 341.0933132171631 and batch: 150, loss is 3.8774007081985475 and perplexity is 48.29850984917052
At time: 342.2566223144531 and batch: 200, loss is 3.8746976804733277 and perplexity is 48.16813392221514
At time: 343.42283511161804 and batch: 250, loss is 3.8786449909210203 and perplexity is 48.35864425483948
At time: 344.58454942703247 and batch: 300, loss is 3.8814402055740356 and perplexity is 48.49400614048928
At time: 345.74865460395813 and batch: 350, loss is 3.8962166547775268 and perplexity is 49.21589570620674
At time: 346.9120228290558 and batch: 400, loss is 3.864207134246826 and perplexity is 47.665465131700174
At time: 348.07590532302856 and batch: 450, loss is 3.894958200454712 and perplexity is 49.15399870494735
At time: 349.23628211021423 and batch: 500, loss is 3.9009174346923827 and perplexity is 49.447793423272884
At time: 350.4005811214447 and batch: 550, loss is 3.865368480682373 and perplexity is 47.72085340599173
At time: 351.5621705055237 and batch: 600, loss is 3.841214780807495 and perplexity is 46.582027035747835
At time: 352.7206017971039 and batch: 650, loss is 3.8753453588485716 and perplexity is 48.19934148607361
At time: 353.88267612457275 and batch: 700, loss is 3.8954154586791994 and perplexity is 49.17647991458893
At time: 355.0421917438507 and batch: 750, loss is 3.863379034996033 and perplexity is 47.62600973448305
At time: 356.22946429252625 and batch: 800, loss is 3.8235949754714964 and perplexity is 45.768449375555235
At time: 357.39178466796875 and batch: 850, loss is 3.8267143154144287 and perplexity is 45.91143962947914
At time: 358.5536313056946 and batch: 900, loss is 3.8078915309906005 and perplexity is 45.05534085604303
At time: 359.7124400138855 and batch: 950, loss is 3.8996198415756225 and perplexity is 49.383671917697036
At time: 360.87423753738403 and batch: 1000, loss is 3.8698252487182616 and perplexity is 47.934008819391934
At time: 362.03520488739014 and batch: 1050, loss is 3.8201543378829954 and perplexity is 45.61124732099488
At time: 363.19491171836853 and batch: 1100, loss is 3.845455584526062 and perplexity is 46.77999173725069
At time: 364.35354590415955 and batch: 1150, loss is 3.8114142751693727 and perplexity is 45.21433918656077
At time: 365.5161669254303 and batch: 1200, loss is 3.8660695552825928 and perplexity is 47.754321014489804
At time: 366.67646956443787 and batch: 1250, loss is 3.840714192390442 and perplexity is 46.5587144480634
At time: 367.8379530906677 and batch: 1300, loss is 3.8426837587356566 and perplexity is 46.65050528951997
At time: 368.9978229999542 and batch: 1350, loss is 3.7171334505081175 and perplexity is 41.14627705571658
At time: 370.1629889011383 and batch: 1400, loss is 3.756188349723816 and perplexity is 42.78503319491762
At time: 371.32408475875854 and batch: 1450, loss is 3.672437744140625 and perplexity is 39.34770868777136
At time: 372.48453068733215 and batch: 1500, loss is 3.6717667770385742 and perplexity is 39.321316524827466
At time: 373.6435856819153 and batch: 1550, loss is 3.6822583866119385 and perplexity is 39.73603213876354
At time: 374.80712389945984 and batch: 1600, loss is 3.768875756263733 and perplexity is 43.33132247396246
At time: 375.96792435646057 and batch: 1650, loss is 3.7038406133651733 and perplexity is 40.60294550519608
At time: 377.1297285556793 and batch: 1700, loss is 3.7339726305007934 and perplexity is 41.845013181844756
At time: 378.2924258708954 and batch: 1750, loss is 3.7331988763809205 and perplexity is 41.812647953478304
At time: 379.45366740226746 and batch: 1800, loss is 3.6713392782211303 and perplexity is 39.3045103010891
At time: 380.61374711990356 and batch: 1850, loss is 3.7146680212020873 and perplexity is 41.044958766289966
At time: 381.7728714942932 and batch: 1900, loss is 3.7949556875228883 and perplexity is 44.47626550836404
At time: 382.9330322742462 and batch: 1950, loss is 3.721796727180481 and perplexity is 41.33860161244816
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.402340911155523 and perplexity of 81.641761256179
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 386.627454996109 and batch: 50, loss is 3.9022773551940917 and perplexity is 49.51508423602083
At time: 387.8161232471466 and batch: 100, loss is 3.903678379058838 and perplexity is 49.58450466918694
At time: 388.97939705848694 and batch: 150, loss is 3.8747446537017822 and perplexity is 48.17039658811604
At time: 390.1406855583191 and batch: 200, loss is 3.883374123573303 and perplexity is 48.587880315041126
At time: 391.3025119304657 and batch: 250, loss is 3.889623899459839 and perplexity is 48.89249457171889
At time: 392.4645049571991 and batch: 300, loss is 3.8948393058776856 and perplexity is 49.148154908466914
At time: 393.6267590522766 and batch: 350, loss is 3.916674838066101 and perplexity is 50.23313346040943
At time: 394.7889699935913 and batch: 400, loss is 3.8810068941116334 and perplexity is 48.47299768370208
At time: 395.95154547691345 and batch: 450, loss is 3.9083056974411012 and perplexity is 49.81447963245229
At time: 397.1156449317932 and batch: 500, loss is 3.9085214805603026 and perplexity is 49.825229916071926
At time: 398.28036618232727 and batch: 550, loss is 3.873021655082703 and perplexity is 48.087470522577796
At time: 399.44152450561523 and batch: 600, loss is 3.8373729276657103 and perplexity is 46.40340906054207
At time: 400.6051661968231 and batch: 650, loss is 3.8724180364608767 and perplexity is 48.058452788597215
At time: 401.76836347579956 and batch: 700, loss is 3.8885750770568848 and perplexity is 48.841241910243824
At time: 402.93011021614075 and batch: 750, loss is 3.8541611766815187 and perplexity is 47.18901708704728
At time: 404.0962872505188 and batch: 800, loss is 3.8023213481903078 and perplexity is 44.805072039961985
At time: 405.26480078697205 and batch: 850, loss is 3.8070374584197997 and perplexity is 45.01687675315552
At time: 406.4244303703308 and batch: 900, loss is 3.783460454940796 and perplexity is 43.96792781959246
At time: 407.58982014656067 and batch: 950, loss is 3.8866524362564085 and perplexity is 48.74742795996447
At time: 408.75497126579285 and batch: 1000, loss is 3.849379286766052 and perplexity is 46.96390306631418
At time: 409.91945576667786 and batch: 1050, loss is 3.7963973569869993 and perplexity is 44.54043182442072
At time: 411.0812277793884 and batch: 1100, loss is 3.820545291900635 and perplexity is 45.629082707565416
At time: 412.24686551094055 and batch: 1150, loss is 3.7809595108032226 and perplexity is 43.85810387728631
At time: 413.40814113616943 and batch: 1200, loss is 3.8263457012176514 and perplexity is 45.89451913979517
At time: 414.59317278862 and batch: 1250, loss is 3.797052845954895 and perplexity is 44.56963715694786
At time: 415.7525818347931 and batch: 1300, loss is 3.7964229917526247 and perplexity is 44.54157362258619
At time: 416.91472864151 and batch: 1350, loss is 3.669657835960388 and perplexity is 39.2384775671034
At time: 418.0772886276245 and batch: 1400, loss is 3.7065430593490603 and perplexity is 40.71282117186718
At time: 419.240425825119 and batch: 1450, loss is 3.62366238117218 and perplexity is 37.474562938501045
At time: 420.4010624885559 and batch: 1500, loss is 3.615513105392456 and perplexity is 37.17041337296466
At time: 421.56619095802307 and batch: 1550, loss is 3.626894783973694 and perplexity is 37.59589180697484
At time: 422.72651720046997 and batch: 1600, loss is 3.7101144552230836 and perplexity is 40.85848272613273
At time: 423.8880708217621 and batch: 1650, loss is 3.6339630937576293 and perplexity is 37.862572597788905
At time: 425.04871940612793 and batch: 1700, loss is 3.6562223196029664 and perplexity is 38.714814081890495
At time: 426.2087347507477 and batch: 1750, loss is 3.6569823169708253 and perplexity is 38.744248422283725
At time: 427.3709783554077 and batch: 1800, loss is 3.592692980766296 and perplexity is 36.331785101445334
At time: 428.53164887428284 and batch: 1850, loss is 3.6257049942016604 and perplexity is 37.55118719924859
At time: 429.69604444503784 and batch: 1900, loss is 3.713781294822693 and perplexity is 41.008579250332694
At time: 430.8579652309418 and batch: 1950, loss is 3.6481848526000977 and perplexity is 38.40489220305601
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375892532703489 and perplexity of 79.51077385790647
finished 9 epochs...
Completing Train Step...
At time: 434.56078338623047 and batch: 50, loss is 3.8922031545639038 and perplexity is 49.01876355785599
At time: 435.7274808883667 and batch: 100, loss is 3.8716864585876465 and perplexity is 48.023307145370374
At time: 436.8924858570099 and batch: 150, loss is 3.830015926361084 and perplexity is 46.06327184867272
At time: 438.05967116355896 and batch: 200, loss is 3.8333113622665405 and perplexity is 46.215320804837425
At time: 439.2210924625397 and batch: 250, loss is 3.8372453689575194 and perplexity is 46.397490279130736
At time: 440.38398814201355 and batch: 300, loss is 3.843244404792786 and perplexity is 46.67666704443073
At time: 441.54331731796265 and batch: 350, loss is 3.869970932006836 and perplexity is 47.94099251212261
At time: 442.7092628479004 and batch: 400, loss is 3.83431414604187 and perplexity is 46.26168802297372
At time: 443.8943781852722 and batch: 450, loss is 3.864097247123718 and perplexity is 47.66022759863924
At time: 445.0509977340698 and batch: 500, loss is 3.8652209663391113 and perplexity is 47.713814414830495
At time: 446.2111585140228 and batch: 550, loss is 3.8296139144897463 and perplexity is 46.044757588282486
At time: 447.3711678981781 and batch: 600, loss is 3.7938607931137085 and perplexity is 44.427595343125766
At time: 448.5340778827667 and batch: 650, loss is 3.8294047355651855 and perplexity is 46.03512700270139
At time: 449.6969702243805 and batch: 700, loss is 3.8477939224243163 and perplexity is 46.88950715693716
At time: 450.8602910041809 and batch: 750, loss is 3.815625982284546 and perplexity is 45.40517032095621
At time: 452.0194339752197 and batch: 800, loss is 3.765913758277893 and perplexity is 43.20316507874241
At time: 453.18183422088623 and batch: 850, loss is 3.7714777135849 and perplexity is 43.44421553347859
At time: 454.3455767631531 and batch: 900, loss is 3.749202675819397 and perplexity is 42.48719242548274
At time: 455.51108837127686 and batch: 950, loss is 3.8528456258773804 and perplexity is 47.12697835417178
At time: 456.6734757423401 and batch: 1000, loss is 3.817198843955994 and perplexity is 45.47664256628266
At time: 457.83658146858215 and batch: 1050, loss is 3.7660379123687746 and perplexity is 43.20852926141168
At time: 458.9970099925995 and batch: 1100, loss is 3.790680103302002 and perplexity is 44.2865094374553
At time: 460.1573269367218 and batch: 1150, loss is 3.754095377922058 and perplexity is 42.695578972141035
At time: 461.31946897506714 and batch: 1200, loss is 3.7994272184371947 and perplexity is 44.67558781034135
At time: 462.4819014072418 and batch: 1250, loss is 3.7745759534835814 and perplexity is 43.579024863396434
At time: 463.64147758483887 and batch: 1300, loss is 3.775153303146362 and perplexity is 43.60419246325918
At time: 464.8047263622284 and batch: 1350, loss is 3.649854831695557 and perplexity is 38.469081152382564
At time: 465.96616649627686 and batch: 1400, loss is 3.6894532775878908 and perplexity is 40.02295952568558
At time: 467.1294496059418 and batch: 1450, loss is 3.6073395347595216 and perplexity is 36.86783662454292
At time: 468.29130458831787 and batch: 1500, loss is 3.6019626903533934 and perplexity is 36.67013598251885
At time: 469.45596194267273 and batch: 1550, loss is 3.6157138252258303 and perplexity is 37.17787496096263
At time: 470.6194517612457 and batch: 1600, loss is 3.7015551710128785 and perplexity is 40.51025577277574
At time: 471.78726148605347 and batch: 1650, loss is 3.627494020462036 and perplexity is 37.61842738855438
At time: 472.9460253715515 and batch: 1700, loss is 3.6532034063339234 and perplexity is 38.598113658810384
At time: 474.10757184028625 and batch: 1750, loss is 3.655918402671814 and perplexity is 38.70304978218007
At time: 475.27093029022217 and batch: 1800, loss is 3.593484697341919 and perplexity is 36.360560967594125
At time: 476.4342098236084 and batch: 1850, loss is 3.627837839126587 and perplexity is 37.63136352973757
At time: 477.5954577922821 and batch: 1900, loss is 3.717085738182068 and perplexity is 41.144313917963274
At time: 478.7585303783417 and batch: 1950, loss is 3.651840443611145 and perplexity is 38.54554170366986
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376687976925872 and perplexity of 79.57404540474602
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 482.4241621494293 and batch: 50, loss is 3.8817754316329958 and perplexity is 48.51026532014905
At time: 483.6096465587616 and batch: 100, loss is 3.8783807611465453 and perplexity is 48.34586814916221
At time: 484.76967215538025 and batch: 150, loss is 3.8442681503295897 and perplexity is 46.724476542194736
At time: 485.9291088581085 and batch: 200, loss is 3.850198965072632 and perplexity is 47.00241414003958
At time: 487.0888693332672 and batch: 250, loss is 3.8574180698394773 and perplexity is 47.34295722113885
At time: 488.2470860481262 and batch: 300, loss is 3.857182307243347 and perplexity is 47.33179683828803
At time: 489.4094088077545 and batch: 350, loss is 3.890026717185974 and perplexity is 48.91219330243994
At time: 490.56957173347473 and batch: 400, loss is 3.858122935295105 and perplexity is 47.376339399841484
At time: 491.7328727245331 and batch: 450, loss is 3.8944608688354494 and perplexity is 49.12955894501462
At time: 492.8917324542999 and batch: 500, loss is 3.899575071334839 and perplexity is 49.381461048305454
At time: 494.0545961856842 and batch: 550, loss is 3.8729440689086916 and perplexity is 48.083739744452345
At time: 495.21771216392517 and batch: 600, loss is 3.833314051628113 and perplexity is 46.21544509471239
At time: 496.37835478782654 and batch: 650, loss is 3.8568794441223146 and perplexity is 47.31746395313424
At time: 497.5376274585724 and batch: 700, loss is 3.8735231351852417 and perplexity is 48.11159147981085
At time: 498.70167565345764 and batch: 750, loss is 3.842013955116272 and perplexity is 46.61926907446369
At time: 499.87078309059143 and batch: 800, loss is 3.7925650787353518 and perplexity is 44.370067147147765
At time: 501.0316741466522 and batch: 850, loss is 3.791269221305847 and perplexity is 44.3126071040402
At time: 502.19383478164673 and batch: 900, loss is 3.7577951526641846 and perplexity is 42.853835573187915
At time: 503.39022064208984 and batch: 950, loss is 3.8638711166381836 and perplexity is 47.64945138669261
At time: 504.550484418869 and batch: 1000, loss is 3.8313814878463743 and perplexity is 46.12621704658324
At time: 505.7107582092285 and batch: 1050, loss is 3.7782719230651853 and perplexity is 43.74038962963186
At time: 506.8692717552185 and batch: 1100, loss is 3.8062498950958252 and perplexity is 44.98143706939424
At time: 508.029422044754 and batch: 1150, loss is 3.77195689201355 and perplexity is 43.46503805286449
At time: 509.1909897327423 and batch: 1200, loss is 3.8171879291534423 and perplexity is 45.47614620041722
At time: 510.354923248291 and batch: 1250, loss is 3.7864547634124754 and perplexity is 44.09977866087713
At time: 511.51525020599365 and batch: 1300, loss is 3.776369390487671 and perplexity is 43.65725122524723
At time: 512.6745789051056 and batch: 1350, loss is 3.639753861427307 and perplexity is 38.082462008863175
At time: 513.8371112346649 and batch: 1400, loss is 3.6792678308486937 and perplexity is 39.617376829933356
At time: 514.9967122077942 and batch: 1450, loss is 3.5951125812530518 and perplexity is 36.419799943799205
At time: 516.1584289073944 and batch: 1500, loss is 3.5878819704055784 and perplexity is 36.15741229791446
At time: 517.3164200782776 and batch: 1550, loss is 3.603349919319153 and perplexity is 36.721041157735414
At time: 518.4827270507812 and batch: 1600, loss is 3.6901103258132935 and perplexity is 40.049265181313096
At time: 519.642774105072 and batch: 1650, loss is 3.6150798177719117 and perplexity is 37.1543113816483
At time: 520.802726984024 and batch: 1700, loss is 3.632721757888794 and perplexity is 37.815601587768185
At time: 521.9673616886139 and batch: 1750, loss is 3.6379115867614744 and perplexity is 38.012368239704
At time: 523.1298196315765 and batch: 1800, loss is 3.5776012563705444 and perplexity is 35.78759254467326
At time: 524.2908511161804 and batch: 1850, loss is 3.6075749301910403 and perplexity is 36.87651616637648
At time: 525.4511504173279 and batch: 1900, loss is 3.7017834424972533 and perplexity is 40.519504164525294
At time: 526.6125707626343 and batch: 1950, loss is 3.6461760091781614 and perplexity is 38.32782022666847
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360892930141715 and perplexity of 78.32704378465793
finished 11 epochs...
Completing Train Step...
At time: 530.2826280593872 and batch: 50, loss is 3.892062253952026 and perplexity is 49.01185727063868
At time: 531.4426724910736 and batch: 100, loss is 3.880140309333801 and perplexity is 48.43100991738069
At time: 532.6383104324341 and batch: 150, loss is 3.8348419094085693 and perplexity is 46.28610969105794
At time: 533.8041298389435 and batch: 200, loss is 3.8294690799713136 and perplexity is 46.03808920090883
At time: 534.9651784896851 and batch: 250, loss is 3.832575407028198 and perplexity is 46.18132091013435
At time: 536.1252958774567 and batch: 300, loss is 3.8311883115768435 and perplexity is 46.11730741663886
At time: 537.2869646549225 and batch: 350, loss is 3.863632173538208 and perplexity is 47.63806723920206
At time: 538.4481387138367 and batch: 400, loss is 3.8340695762634276 and perplexity is 46.25037519562779
At time: 539.6094665527344 and batch: 450, loss is 3.870407991409302 and perplexity is 47.96195015319701
At time: 540.7704420089722 and batch: 500, loss is 3.8755536222457887 and perplexity is 48.209380690038195
At time: 541.934876203537 and batch: 550, loss is 3.8494658517837523 and perplexity is 46.96796867338152
At time: 543.0976102352142 and batch: 600, loss is 3.810567145347595 and perplexity is 45.17605299044272
At time: 544.26464676857 and batch: 650, loss is 3.8336449527740477 and perplexity is 46.23074036892643
At time: 545.4245827198029 and batch: 700, loss is 3.8523796892166136 and perplexity is 47.10502528201314
At time: 546.585512638092 and batch: 750, loss is 3.823152871131897 and perplexity is 45.748219417675166
At time: 547.7448637485504 and batch: 800, loss is 3.7736576986312866 and perplexity is 43.53902657947701
At time: 548.9048476219177 and batch: 850, loss is 3.77297616481781 and perplexity is 43.50936337004554
At time: 550.0680072307587 and batch: 900, loss is 3.740787034034729 and perplexity is 42.13113575769429
At time: 551.2287333011627 and batch: 950, loss is 3.848858313560486 and perplexity is 46.939442503390005
At time: 552.3922612667084 and batch: 1000, loss is 3.8166551399230957 and perplexity is 45.45192345286648
At time: 553.5532727241516 and batch: 1050, loss is 3.764674606323242 and perplexity is 43.14966294776909
At time: 554.7160928249359 and batch: 1100, loss is 3.7929054832458498 and perplexity is 44.38517348912335
At time: 555.8784534931183 and batch: 1150, loss is 3.759613208770752 and perplexity is 42.93181711657262
At time: 557.0397322177887 and batch: 1200, loss is 3.8047484970092773 and perplexity is 44.9139526989773
At time: 558.2017974853516 and batch: 1250, loss is 3.7757341718673705 and perplexity is 43.629528132402406
At time: 559.3643565177917 and batch: 1300, loss is 3.7677005434036257 and perplexity is 43.28042885781924
At time: 560.5274906158447 and batch: 1350, loss is 3.632870054244995 and perplexity is 37.82120991952851
At time: 561.6897211074829 and batch: 1400, loss is 3.673851499557495 and perplexity is 39.40337606482615
At time: 562.853551864624 and batch: 1450, loss is 3.591261420249939 and perplexity is 36.27981116320041
At time: 564.013195514679 and batch: 1500, loss is 3.585538988113403 and perplexity is 36.07279528795676
At time: 565.1759595870972 and batch: 1550, loss is 3.602111330032349 and perplexity is 36.6755870248691
At time: 566.3410716056824 and batch: 1600, loss is 3.6901767444610596 and perplexity is 40.05192528768982
At time: 567.504762172699 and batch: 1650, loss is 3.6162884187698365 and perplexity is 37.199243266352326
At time: 568.668867111206 and batch: 1700, loss is 3.6357847929000853 and perplexity is 37.931609677123454
At time: 569.8311157226562 and batch: 1750, loss is 3.6428670740127562 and perplexity is 38.20120554991117
At time: 570.9991464614868 and batch: 1800, loss is 3.583123469352722 and perplexity is 35.985765927031586
At time: 572.1641802787781 and batch: 1850, loss is 3.614390950202942 and perplexity is 37.12872579504228
At time: 573.327488899231 and batch: 1900, loss is 3.7092889165878296 and perplexity is 40.82476638904875
At time: 574.4911756515503 and batch: 1950, loss is 3.6532922077178953 and perplexity is 38.6015413769128
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359358818586482 and perplexity of 78.20697348586583
finished 12 epochs...
Completing Train Step...
At time: 578.152592420578 and batch: 50, loss is 3.8878696632385252 and perplexity is 48.80680077234998
At time: 579.3470656871796 and batch: 100, loss is 3.8737238121032713 and perplexity is 48.121247334531695
At time: 580.5081412792206 and batch: 150, loss is 3.827162733078003 and perplexity is 45.932031746558586
At time: 581.6682960987091 and batch: 200, loss is 3.8201693725585937 and perplexity is 45.61193307645702
At time: 582.8316540718079 and batch: 250, loss is 3.822187294960022 and perplexity is 45.70406734662401
At time: 583.9971210956573 and batch: 300, loss is 3.8200807571411133 and perplexity is 45.60789133504831
At time: 585.1595857143402 and batch: 350, loss is 3.852191824913025 and perplexity is 47.09617676042971
At time: 586.318445444107 and batch: 400, loss is 3.8228004074096678 and perplexity is 45.732097671306114
At time: 587.4802892208099 and batch: 450, loss is 3.859109411239624 and perplexity is 47.42309807836268
At time: 588.6486382484436 and batch: 500, loss is 3.86416898727417 and perplexity is 47.6636468731859
At time: 589.8114442825317 and batch: 550, loss is 3.838031015396118 and perplexity is 46.43395662508016
At time: 590.9719839096069 and batch: 600, loss is 3.799909462928772 and perplexity is 44.697137562177794
At time: 592.1625761985779 and batch: 650, loss is 3.8232501792907714 and perplexity is 45.752671309277645
At time: 593.3226521015167 and batch: 700, loss is 3.842839827537537 and perplexity is 46.65778654616134
At time: 594.4855842590332 and batch: 750, loss is 3.8143799448013307 and perplexity is 45.34862901041621
At time: 595.6445124149323 and batch: 800, loss is 3.7652155780792236 and perplexity is 43.17301201172659
At time: 596.8044655323029 and batch: 850, loss is 3.764669575691223 and perplexity is 43.14944587823906
At time: 597.9671654701233 and batch: 900, loss is 3.7327244091033935 and perplexity is 41.79281392590824
At time: 599.1292798519135 and batch: 950, loss is 3.8411277294158936 and perplexity is 46.57797218196366
At time: 600.2951471805573 and batch: 1000, loss is 3.809053730964661 and perplexity is 45.10773461213079
At time: 601.4558272361755 and batch: 1050, loss is 3.757609076499939 and perplexity is 42.84586223768808
At time: 602.617354631424 and batch: 1100, loss is 3.7860892248153686 and perplexity is 44.083661435566135
At time: 603.7839689254761 and batch: 1150, loss is 3.753357925415039 and perplexity is 42.664104617236774
At time: 604.9471273422241 and batch: 1200, loss is 3.7985586977005004 and perplexity is 44.63680298105635
At time: 606.114748954773 and batch: 1250, loss is 3.7705356073379517 and perplexity is 43.40330574034241
At time: 607.2771682739258 and batch: 1300, loss is 3.763212552070618 and perplexity is 43.086621895506
At time: 608.4445745944977 and batch: 1350, loss is 3.6287890672683716 and perplexity is 37.66717657222731
At time: 609.6079518795013 and batch: 1400, loss is 3.670239319801331 and perplexity is 39.26130074276271
At time: 610.770898103714 and batch: 1450, loss is 3.5880671882629396 and perplexity is 36.164109916588146
At time: 611.9330723285675 and batch: 1500, loss is 3.5829357624053957 and perplexity is 35.97901178268196
At time: 613.0966610908508 and batch: 1550, loss is 3.599958872795105 and perplexity is 36.59672929154279
At time: 614.26584815979 and batch: 1600, loss is 3.6887755584716797 and perplexity is 39.99584439018835
At time: 615.4268646240234 and batch: 1650, loss is 3.615307273864746 and perplexity is 37.16276331733282
At time: 616.5934698581696 and batch: 1700, loss is 3.63578577041626 and perplexity is 37.93164675590357
At time: 617.7596065998077 and batch: 1750, loss is 3.6434982013702393 and perplexity is 38.22532298560875
At time: 618.9216012954712 and batch: 1800, loss is 3.584037084579468 and perplexity is 36.01865809383294
At time: 620.0853273868561 and batch: 1850, loss is 3.6159302616119384 and perplexity is 37.18592247671856
At time: 621.2513606548309 and batch: 1900, loss is 3.7111157274246214 and perplexity is 40.89941367717555
At time: 622.4164400100708 and batch: 1950, loss is 3.6548389911651613 and perplexity is 38.661295803819044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359198707757995 and perplexity of 78.19445270493053
finished 13 epochs...
Completing Train Step...
At time: 626.1101260185242 and batch: 50, loss is 3.882498712539673 and perplexity is 48.54536456060806
At time: 627.2740495204926 and batch: 100, loss is 3.8674256086349486 and perplexity is 47.81912234869406
At time: 628.4424428939819 and batch: 150, loss is 3.820449652671814 and perplexity is 45.62471898595827
At time: 629.6058299541473 and batch: 200, loss is 3.8128634452819825 and perplexity is 45.27990995569538
At time: 630.7678916454315 and batch: 250, loss is 3.814331750869751 and perplexity is 45.34644353435621
At time: 631.9327600002289 and batch: 300, loss is 3.8117181062698364 and perplexity is 45.228078796147216
At time: 633.0962114334106 and batch: 350, loss is 3.8434572553634645 and perplexity is 46.68660325707526
At time: 634.2605473995209 and batch: 400, loss is 3.8142013120651246 and perplexity is 45.34052898421935
At time: 635.4237351417542 and batch: 450, loss is 3.850675048828125 and perplexity is 47.024796553409566
At time: 636.5872085094452 and batch: 500, loss is 3.8556274461746214 and perplexity is 47.258259654938335
At time: 637.7495610713959 and batch: 550, loss is 3.829576630592346 and perplexity is 46.043040892267506
At time: 638.9173085689545 and batch: 600, loss is 3.792006106376648 and perplexity is 44.34527243648323
At time: 640.0794818401337 and batch: 650, loss is 3.8156395387649535 and perplexity is 45.405785859430324
At time: 641.2439181804657 and batch: 700, loss is 3.8358009576797487 and perplexity is 46.33052159771385
At time: 642.4058146476746 and batch: 750, loss is 3.807733030319214 and perplexity is 45.04820012018846
At time: 643.5695834159851 and batch: 800, loss is 3.7588744831085203 and perplexity is 42.9001139929396
At time: 644.734530210495 and batch: 850, loss is 3.758469066619873 and perplexity is 42.88272510447124
At time: 645.8956890106201 and batch: 900, loss is 3.726678342819214 and perplexity is 41.54089413200442
At time: 647.058114528656 and batch: 950, loss is 3.8352003479003907 and perplexity is 46.3027033881401
At time: 648.2206780910492 and batch: 1000, loss is 3.803242034912109 and perplexity is 44.84634247051195
At time: 649.3810772895813 and batch: 1050, loss is 3.752128629684448 and perplexity is 42.61169003869073
At time: 650.5676400661469 and batch: 1100, loss is 3.7808191061019896 and perplexity is 43.85194642559247
At time: 651.7358684539795 and batch: 1150, loss is 3.7484665155410766 and perplexity is 42.45592655184087
At time: 652.900196313858 and batch: 1200, loss is 3.7936701726913453 and perplexity is 44.41912734324938
At time: 654.0657241344452 and batch: 1250, loss is 3.766371717453003 and perplexity is 43.22295489570226
At time: 655.230550289154 and batch: 1300, loss is 3.7594209718704223 and perplexity is 42.923564830346976
At time: 656.3910889625549 and batch: 1350, loss is 3.6251733541488647 and perplexity is 37.53122878991842
At time: 657.5529804229736 and batch: 1400, loss is 3.666876358985901 and perplexity is 39.12948829108475
At time: 658.7197589874268 and batch: 1450, loss is 3.584856653213501 and perplexity is 36.048189956287665
At time: 659.8817257881165 and batch: 1500, loss is 3.5800668525695802 and perplexity is 35.87593916561431
At time: 661.0448229312897 and batch: 1550, loss is 3.5973054218292235 and perplexity is 36.49975038614191
At time: 662.2075524330139 and batch: 1600, loss is 3.6866948556900025 and perplexity is 39.91271144297986
At time: 663.3677930831909 and batch: 1650, loss is 3.6134775829315187 and perplexity is 37.094829114487254
At time: 664.5327274799347 and batch: 1700, loss is 3.6346675109863282 and perplexity is 37.88925304222878
At time: 665.7014417648315 and batch: 1750, loss is 3.6427145767211915 and perplexity is 38.19538041370034
At time: 666.8690228462219 and batch: 1800, loss is 3.583510928153992 and perplexity is 35.99971163027871
At time: 668.0315234661102 and batch: 1850, loss is 3.6158509349822996 and perplexity is 37.18297275981557
At time: 669.2000751495361 and batch: 1900, loss is 3.711319451332092 and perplexity is 40.907746714333754
At time: 670.3623087406158 and batch: 1950, loss is 3.65484778881073 and perplexity is 38.661635933692914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359509845112646 and perplexity of 78.21878570534993
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 674.0270571708679 and batch: 50, loss is 3.8812854719161987 and perplexity is 48.48650306604005
At time: 675.2135989665985 and batch: 100, loss is 3.874893317222595 and perplexity is 48.17755830120133
At time: 676.3739719390869 and batch: 150, loss is 3.833013348579407 and perplexity is 46.20155005871965
At time: 677.5366888046265 and batch: 200, loss is 3.8257475471496583 and perplexity is 45.8670753550971
At time: 678.6981916427612 and batch: 250, loss is 3.829250259399414 and perplexity is 46.02801622202841
At time: 679.8848598003387 and batch: 300, loss is 3.822243027687073 and perplexity is 45.70661462991741
At time: 681.0420377254486 and batch: 350, loss is 3.85412787437439 and perplexity is 47.18744561007419
At time: 682.2042841911316 and batch: 400, loss is 3.827067980766296 and perplexity is 45.92767978655159
At time: 683.3691716194153 and batch: 450, loss is 3.865573682785034 and perplexity is 47.73064683023268
At time: 684.5274684429169 and batch: 500, loss is 3.8704673528671263 and perplexity is 47.96479732898362
At time: 685.6883645057678 and batch: 550, loss is 3.848348407745361 and perplexity is 46.91551390988176
At time: 686.8484914302826 and batch: 600, loss is 3.8116045999526977 and perplexity is 45.22294541483292
At time: 688.013326883316 and batch: 650, loss is 3.8292834424972533 and perplexity is 46.02954359953547
At time: 689.1748733520508 and batch: 700, loss is 3.8500084352493285 and perplexity is 46.99345963145621
At time: 690.3334457874298 and batch: 750, loss is 3.820802688598633 and perplexity is 45.64082899444989
At time: 691.4931666851044 and batch: 800, loss is 3.7738176155090333 and perplexity is 43.54598976141805
At time: 692.6578335762024 and batch: 850, loss is 3.773359456062317 and perplexity is 43.5260433245154
At time: 693.8194818496704 and batch: 900, loss is 3.7354961824417114 and perplexity is 41.90881482311147
At time: 694.9797501564026 and batch: 950, loss is 3.8439871168136595 and perplexity is 46.711347243245015
At time: 696.1402952671051 and batch: 1000, loss is 3.8124377155303955 and perplexity is 45.260637053693046
At time: 697.3015580177307 and batch: 1050, loss is 3.7578817653656005 and perplexity is 42.857547420397175
At time: 698.4601509571075 and batch: 1100, loss is 3.783603925704956 and perplexity is 43.97423638433175
At time: 699.6222295761108 and batch: 1150, loss is 3.754096341133118 and perplexity is 42.69562009701471
At time: 700.7817659378052 and batch: 1200, loss is 3.8009720706939696 and perplexity is 44.74465833113106
At time: 701.9408707618713 and batch: 1250, loss is 3.7770418453216554 and perplexity is 43.686618627891406
At time: 703.1041285991669 and batch: 1300, loss is 3.767677011489868 and perplexity is 43.27941039848316
At time: 704.2692835330963 and batch: 1350, loss is 3.6285936975479127 and perplexity is 37.659818265288514
At time: 705.4283385276794 and batch: 1400, loss is 3.6702392530441283 and perplexity is 39.26129812178819
At time: 706.5895755290985 and batch: 1450, loss is 3.585770215988159 and perplexity is 36.08113728816202
At time: 707.7500529289246 and batch: 1500, loss is 3.5790803718566893 and perplexity is 35.840565694062924
At time: 708.9102776050568 and batch: 1550, loss is 3.5954673290252686 and perplexity is 36.4327220786076
At time: 710.0721402168274 and batch: 1600, loss is 3.6813971853256224 and perplexity is 39.70182614800829
At time: 711.2344295978546 and batch: 1650, loss is 3.603543281555176 and perplexity is 36.728142306887676
At time: 712.3994286060333 and batch: 1700, loss is 3.622191505432129 and perplexity is 37.41948303078614
At time: 713.5601778030396 and batch: 1750, loss is 3.629449701309204 and perplexity is 37.692069012784444
At time: 714.7218215465546 and batch: 1800, loss is 3.5702453660964966 and perplexity is 35.52530878866814
At time: 715.8818209171295 and batch: 1850, loss is 3.603624882698059 and perplexity is 36.73113948756092
At time: 717.0427076816559 and batch: 1900, loss is 3.697728309631348 and perplexity is 40.35552489504762
At time: 718.208208322525 and batch: 1950, loss is 3.644541311264038 and perplexity is 38.26521700151271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356003588299418 and perplexity of 77.94501079809372
finished 15 epochs...
Completing Train Step...
At time: 721.8931610584259 and batch: 50, loss is 3.8801582050323487 and perplexity is 48.431876631889736
At time: 723.0552651882172 and batch: 100, loss is 3.871223497390747 and perplexity is 48.001079363312584
At time: 724.2187919616699 and batch: 150, loss is 3.8282591676712037 and perplexity is 45.9824208342229
At time: 725.3822588920593 and batch: 200, loss is 3.8198429441452024 and perplexity is 45.597046475348144
At time: 726.5452525615692 and batch: 250, loss is 3.822462921142578 and perplexity is 45.716666320457804
At time: 727.708996295929 and batch: 300, loss is 3.8155507612228394 and perplexity is 45.40175502429043
At time: 728.871993303299 and batch: 350, loss is 3.847246346473694 and perplexity is 46.86383861885992
At time: 730.0362513065338 and batch: 400, loss is 3.8204488706588746 and perplexity is 45.624683306851615
At time: 731.1974391937256 and batch: 450, loss is 3.858662233352661 and perplexity is 47.4018962584166
At time: 732.3631222248077 and batch: 500, loss is 3.863426933288574 and perplexity is 47.628290993663654
At time: 733.5300896167755 and batch: 550, loss is 3.840893063545227 and perplexity is 46.56704320394692
At time: 734.7015202045441 and batch: 600, loss is 3.8039838218688966 and perplexity is 44.8796212437702
At time: 735.8647525310516 and batch: 650, loss is 3.821260566711426 and perplexity is 45.66173171618038
At time: 737.0300652980804 and batch: 700, loss is 3.8420380640029905 and perplexity is 46.62039302668927
At time: 738.1914534568787 and batch: 750, loss is 3.813575882911682 and perplexity is 45.31218056144921
At time: 739.396449804306 and batch: 800, loss is 3.766295976638794 and perplexity is 43.21968127788073
At time: 740.5621535778046 and batch: 850, loss is 3.765909447669983 and perplexity is 43.202978847238654
At time: 741.7232782840729 and batch: 900, loss is 3.7290526485443114 and perplexity is 41.63964209730783
At time: 742.8904299736023 and batch: 950, loss is 3.8382537078857424 and perplexity is 46.44429826994468
At time: 744.0568141937256 and batch: 1000, loss is 3.8064050674438477 and perplexity is 44.98841748617154
At time: 745.2170076370239 and batch: 1050, loss is 3.75260817527771 and perplexity is 42.632129187230355
At time: 746.3811659812927 and batch: 1100, loss is 3.7792258787155153 and perplexity is 43.782135930360546
At time: 747.54341340065 and batch: 1150, loss is 3.7499548244476317 and perplexity is 42.51916113008464
At time: 748.7061986923218 and batch: 1200, loss is 3.7967729902267457 and perplexity is 44.55716583385496
At time: 749.869158744812 and batch: 1250, loss is 3.7724735260009767 and perplexity is 43.48749937042783
At time: 751.0352613925934 and batch: 1300, loss is 3.763572072982788 and perplexity is 43.10211522203277
At time: 752.1973543167114 and batch: 1350, loss is 3.6255472993850706 and perplexity is 37.54526603855092
At time: 753.3676965236664 and batch: 1400, loss is 3.667848062515259 and perplexity is 39.16752903212714
At time: 754.5310027599335 and batch: 1450, loss is 3.584642868041992 and perplexity is 36.04048421153161
At time: 755.6942579746246 and batch: 1500, loss is 3.5793379592895507 and perplexity is 35.84979896250827
At time: 756.8555402755737 and batch: 1550, loss is 3.596512713432312 and perplexity is 36.47082819247306
At time: 758.0213918685913 and batch: 1600, loss is 3.683280644416809 and perplexity is 39.77667337712433
At time: 759.1827821731567 and batch: 1650, loss is 3.6058677196502686 and perplexity is 36.81361389825564
At time: 760.344747543335 and batch: 1700, loss is 3.6247824144363405 and perplexity is 37.516559209772176
At time: 761.5063078403473 and batch: 1750, loss is 3.6328658628463746 and perplexity is 37.821051396093644
At time: 762.668869972229 and batch: 1800, loss is 3.574040718078613 and perplexity is 35.660396029450524
At time: 763.8319983482361 and batch: 1850, loss is 3.607531342506409 and perplexity is 36.8749088394496
At time: 764.9934344291687 and batch: 1900, loss is 3.7015221405029295 and perplexity is 40.5089177204678
At time: 766.1624217033386 and batch: 1950, loss is 3.647652654647827 and perplexity is 38.38445863590195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354897574491279 and perplexity of 77.85885019606633
finished 16 epochs...
Completing Train Step...
At time: 769.8285002708435 and batch: 50, loss is 3.8792050552368162 and perplexity is 48.38573579164025
At time: 771.023268699646 and batch: 100, loss is 3.8690130043029787 and perplexity is 47.895090496161274
At time: 772.1873681545258 and batch: 150, loss is 3.825594172477722 and perplexity is 45.860041046917985
At time: 773.3496947288513 and batch: 200, loss is 3.8164952325820924 and perplexity is 45.444655937723645
At time: 774.5170407295227 and batch: 250, loss is 3.8188568592071532 and perplexity is 45.552106075766375
At time: 775.6775646209717 and batch: 300, loss is 3.81184681892395 and perplexity is 45.2339005968712
At time: 776.8452837467194 and batch: 350, loss is 3.8434946537017822 and perplexity is 46.68834929110796
At time: 778.0052974224091 and batch: 400, loss is 3.8166736555099487 and perplexity is 45.45276502969393
At time: 779.1757147312164 and batch: 450, loss is 3.854621534347534 and perplexity is 47.21074591394731
At time: 780.3391392230988 and batch: 500, loss is 3.8592806816101075 and perplexity is 47.43122094552342
At time: 781.5018029212952 and batch: 550, loss is 3.836530966758728 and perplexity is 46.36435564719312
At time: 782.6630222797394 and batch: 600, loss is 3.7997153759002686 and perplexity is 44.688463269376825
At time: 783.8262584209442 and batch: 650, loss is 3.8169090127944947 and perplexity is 45.463463928028865
At time: 784.9919006824493 and batch: 700, loss is 3.837837982177734 and perplexity is 46.4249941940418
At time: 786.1536600589752 and batch: 750, loss is 3.809668469429016 and perplexity is 45.135472596566245
At time: 787.314861536026 and batch: 800, loss is 3.7623439407348633 and perplexity is 43.049212616722066
At time: 788.4796631336212 and batch: 850, loss is 3.762092924118042 and perplexity is 43.038407905152
At time: 789.6465330123901 and batch: 900, loss is 3.7256030893325804 and perplexity is 41.496251146315345
At time: 790.8109200000763 and batch: 950, loss is 3.8350846862792967 and perplexity is 46.29734825210302
At time: 791.9721219539642 and batch: 1000, loss is 3.8031773567199707 and perplexity is 44.84344198395706
At time: 793.1317460536957 and batch: 1050, loss is 3.7498119115829467 and perplexity is 42.513085029150375
At time: 794.2915077209473 and batch: 1100, loss is 3.7767960453033447 and perplexity is 43.67588177584601
At time: 795.4528033733368 and batch: 1150, loss is 3.7476443099975585 and perplexity is 42.421033400311764
At time: 796.6135108470917 and batch: 1200, loss is 3.794455499649048 and perplexity is 44.454024582467476
At time: 797.8173263072968 and batch: 1250, loss is 3.7701780796051025 and perplexity is 43.387790628549546
At time: 798.974187374115 and batch: 1300, loss is 3.7616047048568726 and perplexity is 43.01740085388343
At time: 800.1304030418396 and batch: 1350, loss is 3.624083242416382 and perplexity is 37.490337848976644
At time: 801.2898423671722 and batch: 1400, loss is 3.666676125526428 and perplexity is 39.12165404264234
At time: 802.447508096695 and batch: 1450, loss is 3.584108662605286 and perplexity is 36.02123633054335
At time: 803.6077425479889 and batch: 1500, loss is 3.579346704483032 and perplexity is 35.850112477307334
At time: 804.7712638378143 and batch: 1550, loss is 3.5969268798828127 and perplexity is 36.485936314355
At time: 805.9333472251892 and batch: 1600, loss is 3.6841231393814087 and perplexity is 39.810199144815265
At time: 807.0925600528717 and batch: 1650, loss is 3.606932454109192 and perplexity is 36.85283149598952
At time: 808.2583839893341 and batch: 1700, loss is 3.625996174812317 and perplexity is 37.562122968932925
At time: 809.4207167625427 and batch: 1750, loss is 3.634456148147583 and perplexity is 37.881245508425195
At time: 810.5847890377045 and batch: 1800, loss is 3.5757005548477174 and perplexity is 35.71963561640262
At time: 811.7454555034637 and batch: 1850, loss is 3.609310727119446 and perplexity is 36.940581896331224
At time: 812.9105231761932 and batch: 1900, loss is 3.703233685493469 and perplexity is 40.57830992266276
At time: 814.0728666782379 and batch: 1950, loss is 3.6490044021606445 and perplexity is 38.43637981665139
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354439384992733 and perplexity of 77.82318426004028
finished 17 epochs...
Completing Train Step...
At time: 817.7566230297089 and batch: 50, loss is 3.8778876638412476 and perplexity is 48.32203480841654
At time: 818.9166448116302 and batch: 100, loss is 3.8670038890838625 and perplexity is 47.79896034153896
At time: 820.0783586502075 and batch: 150, loss is 3.823355112075806 and perplexity is 45.75747251639851
At time: 821.2421712875366 and batch: 200, loss is 3.8138929796218872 and perplexity is 45.32655118315548
At time: 822.4093029499054 and batch: 250, loss is 3.8160853433609008 and perplexity is 45.426032480132015
At time: 823.5716989040375 and batch: 300, loss is 3.808986291885376 and perplexity is 45.10469269061326
At time: 824.7319521903992 and batch: 350, loss is 3.840596070289612 and perplexity is 46.55321515970099
At time: 825.8948709964752 and batch: 400, loss is 3.813739972114563 and perplexity is 45.319616411092966
At time: 827.0822398662567 and batch: 450, loss is 3.851624150276184 and perplexity is 47.069449042432204
At time: 828.2448954582214 and batch: 500, loss is 3.8562056684494017 and perplexity is 47.285593335047956
At time: 829.4068472385406 and batch: 550, loss is 3.833343462944031 and perplexity is 46.21680437175732
At time: 830.5694694519043 and batch: 600, loss is 3.7966913414001464 and perplexity is 44.55352794206485
At time: 831.7328424453735 and batch: 650, loss is 3.8138890743255613 and perplexity is 45.32637416988732
At time: 832.8994288444519 and batch: 700, loss is 3.8349475193023683 and perplexity is 46.290998220320766
At time: 834.0648155212402 and batch: 750, loss is 3.806961998939514 and perplexity is 45.01347993119447
At time: 835.2281308174133 and batch: 800, loss is 3.7596325159072874 and perplexity is 42.9326460150292
At time: 836.3882768154144 and batch: 850, loss is 3.7595005512237547 and perplexity is 42.926980795797256
At time: 837.5591506958008 and batch: 900, loss is 3.723184094429016 and perplexity is 41.39599323684996
At time: 838.7206084728241 and batch: 950, loss is 3.8328276872634888 and perplexity is 46.192973014375596
At time: 839.8894257545471 and batch: 1000, loss is 3.8008786916732786 and perplexity is 44.74048031382757
At time: 841.0542821884155 and batch: 1050, loss is 3.747797408103943 and perplexity is 42.42752847737554
At time: 842.217627286911 and batch: 1100, loss is 3.774964451789856 and perplexity is 43.59595852988235
At time: 843.3829700946808 and batch: 1150, loss is 3.7459133958816526 and perplexity is 42.34766974619695
At time: 844.5519542694092 and batch: 1200, loss is 3.792728147506714 and perplexity is 44.37730310944641
At time: 845.7149956226349 and batch: 1250, loss is 3.7685702276229858 and perplexity is 43.318085536139996
At time: 846.880514383316 and batch: 1300, loss is 3.7602369499206545 and perplexity is 42.958603810661536
At time: 848.042750120163 and batch: 1350, loss is 3.622987790107727 and perplexity is 37.449291458114246
At time: 849.2050383090973 and batch: 1400, loss is 3.6657409620285035 and perplexity is 39.085086001017075
At time: 850.3688180446625 and batch: 1450, loss is 3.5835317182540893 and perplexity is 36.000460075667085
At time: 851.5315191745758 and batch: 1500, loss is 3.579034113883972 and perplexity is 35.838907820498115
At time: 852.6932396888733 and batch: 1550, loss is 3.596865243911743 and perplexity is 36.48368753754336
At time: 853.8601431846619 and batch: 1600, loss is 3.684333910942078 and perplexity is 39.818590886958795
At time: 855.0250155925751 and batch: 1650, loss is 3.6072914266586302 and perplexity is 36.86606302560152
At time: 856.1932406425476 and batch: 1700, loss is 3.626489853858948 and perplexity is 37.58067118004454
At time: 857.3594417572021 and batch: 1750, loss is 3.6351498889923097 and perplexity is 37.90753439346581
At time: 858.5212750434875 and batch: 1800, loss is 3.5764062929153444 and perplexity is 35.7448532204838
At time: 859.6907105445862 and batch: 1850, loss is 3.6101364040374757 and perplexity is 36.97109547758795
At time: 860.8550534248352 and batch: 1900, loss is 3.704010400772095 and perplexity is 40.609839959305965
At time: 862.0181748867035 and batch: 1950, loss is 3.649571189880371 and perplexity is 38.458171259699995
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354221077852471 and perplexity of 77.8061967575524
finished 18 epochs...
Completing Train Step...
At time: 865.7390959262848 and batch: 50, loss is 3.8764235877990725 and perplexity is 48.25133943927058
At time: 866.9313225746155 and batch: 100, loss is 3.8650908422470094 and perplexity is 47.70760610198334
At time: 868.0911667346954 and batch: 150, loss is 3.821308078765869 and perplexity is 45.66390125040276
At time: 869.2553310394287 and batch: 200, loss is 3.811637592315674 and perplexity is 45.224437451275676
At time: 870.4166920185089 and batch: 250, loss is 3.8137022495269775 and perplexity is 45.31790687013791
At time: 871.5776617527008 and batch: 300, loss is 3.8065139865875244 and perplexity is 44.99331785294654
At time: 872.7413518428802 and batch: 350, loss is 3.8380798530578613 and perplexity is 46.43622440632332
At time: 873.910306930542 and batch: 400, loss is 3.811217427253723 and perplexity is 45.20543971408446
At time: 875.078253030777 and batch: 450, loss is 3.849129528999329 and perplexity is 46.952174931425084
At time: 876.2474110126495 and batch: 500, loss is 3.8536563968658446 and perplexity is 47.16520303463239
At time: 877.4153442382812 and batch: 550, loss is 3.830735988616943 and perplexity is 46.096452216644
At time: 878.5842924118042 and batch: 600, loss is 3.794245095252991 and perplexity is 44.44467224419394
At time: 879.7575237751007 and batch: 650, loss is 3.811458721160889 and perplexity is 45.21634882735657
At time: 880.9242963790894 and batch: 700, loss is 3.832634072303772 and perplexity is 46.18403022952262
At time: 882.0967342853546 and batch: 750, loss is 3.804789171218872 and perplexity is 44.91577957565623
At time: 883.2595081329346 and batch: 800, loss is 3.757470269203186 and perplexity is 42.83991533212032
At time: 884.4272606372833 and batch: 850, loss is 3.757443766593933 and perplexity is 42.83877997762884
At time: 885.5899329185486 and batch: 900, loss is 3.7212191152572633 and perplexity is 41.31473083795332
At time: 886.7782869338989 and batch: 950, loss is 3.830992889404297 and perplexity is 46.10829595278011
At time: 887.9469985961914 and batch: 1000, loss is 3.7990060901641844 and perplexity is 44.65677761823092
At time: 889.1085727214813 and batch: 1050, loss is 3.7461206197738646 and perplexity is 42.35644610445202
At time: 890.271674156189 and batch: 1100, loss is 3.773401756286621 and perplexity is 43.52788452485242
At time: 891.4340898990631 and batch: 1150, loss is 3.7444388389587404 and perplexity is 42.285271712635776
At time: 892.6079225540161 and batch: 1200, loss is 3.791258521080017 and perplexity is 44.31213295167383
At time: 893.7771332263947 and batch: 1250, loss is 3.767237620353699 and perplexity is 43.26039798642399
At time: 894.9406394958496 and batch: 1300, loss is 3.75909631729126 and perplexity is 42.9096317603107
At time: 896.1023325920105 and batch: 1350, loss is 3.6220183324813844 and perplexity is 37.413003549546
At time: 897.2674975395203 and batch: 1400, loss is 3.664879894256592 and perplexity is 39.05144557851955
At time: 898.4345836639404 and batch: 1450, loss is 3.582899432182312 and perplexity is 35.977704680901354
At time: 899.5984382629395 and batch: 1500, loss is 3.578556218147278 and perplexity is 35.82178465111363
At time: 900.7616009712219 and batch: 1550, loss is 3.596554036140442 and perplexity is 36.47233529700032
At time: 901.9316029548645 and batch: 1600, loss is 3.6842208385467528 and perplexity is 39.814088758046786
At time: 903.095466375351 and batch: 1650, loss is 3.6072847747802737 and perplexity is 36.865817797850404
At time: 904.2583332061768 and batch: 1700, loss is 3.626613907814026 and perplexity is 37.58533350012256
At time: 905.4269645214081 and batch: 1750, loss is 3.63538938999176 and perplexity is 37.916614373128446
At time: 906.5908436775208 and batch: 1800, loss is 3.576648111343384 and perplexity is 35.75349802989506
At time: 907.7659845352173 and batch: 1850, loss is 3.610495376586914 and perplexity is 36.98436946834367
At time: 908.9324498176575 and batch: 1900, loss is 3.704329738616943 and perplexity is 40.62281028892654
At time: 910.0962452888489 and batch: 1950, loss is 3.6497455549240114 and perplexity is 38.46487760506914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354127112100291 and perplexity of 77.79888598323639
finished 19 epochs...
Completing Train Step...
At time: 913.8208198547363 and batch: 50, loss is 3.874900178909302 and perplexity is 48.17788888164686
At time: 914.9820277690887 and batch: 100, loss is 3.863249225616455 and perplexity is 47.619827832950726
At time: 916.2033138275146 and batch: 150, loss is 3.8193863296508788 and perplexity is 45.576230955724796
At time: 917.3779857158661 and batch: 200, loss is 3.809582052230835 and perplexity is 45.13157228401535
At time: 918.5479781627655 and batch: 250, loss is 3.811550145149231 and perplexity is 45.22048287527733
At time: 919.7140779495239 and batch: 300, loss is 3.8042771148681642 and perplexity is 44.8927860529696
At time: 920.8772685527802 and batch: 350, loss is 3.835795941352844 and perplexity is 46.33028918925477
At time: 922.0397715568542 and batch: 400, loss is 3.8089499568939207 and perplexity is 45.103053841763725
At time: 923.201907157898 and batch: 450, loss is 3.8469166803359984 and perplexity is 46.84839174448046
At time: 924.363025188446 and batch: 500, loss is 3.851412754058838 and perplexity is 47.05949979060621
At time: 925.5343828201294 and batch: 550, loss is 3.8284560203552247 and perplexity is 45.99147348817228
At time: 926.7013611793518 and batch: 600, loss is 3.792112627029419 and perplexity is 44.34999637544453
At time: 927.8598229885101 and batch: 650, loss is 3.809344744682312 and perplexity is 45.120863491924496
At time: 929.0185549259186 and batch: 700, loss is 3.8306176805496217 and perplexity is 46.090998957060535
At time: 930.1780333518982 and batch: 750, loss is 3.8028927564620973 and perplexity is 44.83068134473123
At time: 931.3359940052032 and batch: 800, loss is 3.755589861869812 and perplexity is 42.759434533225445
At time: 932.4941580295563 and batch: 850, loss is 3.75565899848938 and perplexity is 42.76239087817839
At time: 933.6541569232941 and batch: 900, loss is 3.719488191604614 and perplexity is 41.2432800489129
At time: 934.8133888244629 and batch: 950, loss is 3.829362998008728 and perplexity is 46.03320564908566
At time: 935.9733345508575 and batch: 1000, loss is 3.797339005470276 and perplexity is 44.58239300773439
At time: 937.1329307556152 and batch: 1050, loss is 3.7446161031723024 and perplexity is 42.292768042467046
At time: 938.2921705245972 and batch: 1100, loss is 3.771977491378784 and perplexity is 43.46593341428016
At time: 939.452169418335 and batch: 1150, loss is 3.7430979919433596 and perplexity is 42.22861162700763
At time: 940.6123566627502 and batch: 1200, loss is 3.7899259185791014 and perplexity is 44.25312182040489
At time: 941.769855260849 and batch: 1250, loss is 3.7660369300842285 and perplexity is 43.20848681836197
At time: 942.9286797046661 and batch: 1300, loss is 3.758046770095825 and perplexity is 42.86461970191127
At time: 944.083603143692 and batch: 1350, loss is 3.6210805940628052 and perplexity is 37.37793638324739
At time: 945.2455382347107 and batch: 1400, loss is 3.664033145904541 and perplexity is 39.018392826987046
At time: 946.4039237499237 and batch: 1450, loss is 3.5822185039520265 and perplexity is 35.95321478500025
At time: 947.5674753189087 and batch: 1500, loss is 3.5779791355133055 and perplexity is 35.80111848488992
At time: 948.7256543636322 and batch: 1550, loss is 3.596100859642029 and perplexity is 36.4558106363782
At time: 949.8887345790863 and batch: 1600, loss is 3.683923783302307 and perplexity is 39.80226353063825
At time: 951.0450179576874 and batch: 1650, loss is 3.6070782375335693 and perplexity is 36.85820441959508
At time: 952.2062945365906 and batch: 1700, loss is 3.626532015800476 and perplexity is 37.582255687508145
At time: 953.3641710281372 and batch: 1750, loss is 3.6353747272491455 and perplexity is 37.91605841564701
At time: 954.5252509117126 and batch: 1800, loss is 3.5766447496414187 and perplexity is 35.7533778374925
At time: 955.6827297210693 and batch: 1850, loss is 3.6106018161773683 and perplexity is 36.98830627899564
At time: 956.8425681591034 and batch: 1900, loss is 3.7044020175933836 and perplexity is 40.625746570188774
At time: 958.0000674724579 and batch: 1950, loss is 3.6497122478485107 and perplexity is 38.46359647382211
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354102981922239 and perplexity of 77.79700870491497
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f6867fdeb38>
ELAPSED
4927.573845148087


RESULTS SO FAR:
[{'best_accuracy': -78.24843512754734, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}}, {'best_accuracy': -80.22026219008522, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.862353544247577, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.936075502546612}}, {'best_accuracy': -78.14425651975347, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.3679014798345962, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.3008932223994304}}, {'best_accuracy': -81.13334485419696, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.12560107942970977, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.9438108012791336}}, {'best_accuracy': -77.79700870491497, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.8553086698259572, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.5482996063691655}}]
SETTINGS FOR THIS RUN
{'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 1.0, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.13646949770690217}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.668114423751831 and batch: 50, loss is 7.700027656555176 and perplexity is 2208.4090680298677
At time: 2.8864669799804688 and batch: 100, loss is 6.9868036556243895 and perplexity is 1082.256676748009
At time: 4.102205753326416 and batch: 150, loss is 6.8120186901092525 and perplexity is 908.7033471189696
At time: 5.322377681732178 and batch: 200, loss is 6.765585041046142 and perplexity is 867.4735670055175
At time: 6.541075229644775 and batch: 250, loss is 6.764965000152588 and perplexity is 866.9358646358525
At time: 7.787060737609863 and batch: 300, loss is 6.741002445220947 and perplexity is 846.4087891621883
At time: 9.00162148475647 and batch: 350, loss is 6.746366968154907 and perplexity is 850.9615693516635
At time: 10.214537858963013 and batch: 400, loss is 6.754985361099243 and perplexity is 858.3271848300236
At time: 11.432262897491455 and batch: 450, loss is 6.705053234100342 and perplexity is 816.5214919425908
At time: 12.6498122215271 and batch: 500, loss is 6.713971920013428 and perplexity is 823.8363616962912
At time: 13.860044956207275 and batch: 550, loss is 6.704262599945069 and perplexity is 815.8761773000605
At time: 15.07379937171936 and batch: 600, loss is 6.758292608261108 and perplexity is 861.1705842966816
At time: 16.28900933265686 and batch: 650, loss is 6.83670823097229 and perplexity is 931.4180697302055
At time: 17.505630493164062 and batch: 700, loss is 6.76931471824646 and perplexity is 870.7150043903133
At time: 18.720894813537598 and batch: 750, loss is 6.732507638931274 and perplexity is 839.2491633278628
At time: 19.934346914291382 and batch: 800, loss is 6.7512069416046145 and perplexity is 855.0901838868995
At time: 21.151041269302368 and batch: 850, loss is 6.788190469741822 and perplexity is 887.30650029535
At time: 22.365849256515503 and batch: 900, loss is 6.8240256690979 and perplexity is 919.6798948321103
At time: 23.581099271774292 and batch: 950, loss is 6.787203578948975 and perplexity is 886.431257635274
At time: 24.79873013496399 and batch: 1000, loss is 6.815037260055542 and perplexity is 911.4504758468515
At time: 26.01136589050293 and batch: 1050, loss is 6.7364343166351315 and perplexity is 842.55110288905
At time: 27.230164051055908 and batch: 1100, loss is 6.804465761184693 and perplexity is 901.8658294718822
At time: 28.448731660842896 and batch: 1150, loss is 6.7258327293396 and perplexity is 833.6659056377995
At time: 29.662497997283936 and batch: 1200, loss is 6.814591035842896 and perplexity is 911.0438553046137
At time: 30.881409168243408 and batch: 1250, loss is 6.770782508850098 and perplexity is 871.9939700895036
At time: 32.09704232215881 and batch: 1300, loss is 6.807518186569214 and perplexity is 904.6229133789328
At time: 33.31016445159912 and batch: 1350, loss is 6.793758249282837 and perplexity is 892.2606061607748
At time: 34.524948596954346 and batch: 1400, loss is 6.785890884399414 and perplexity is 885.2684075552792
At time: 35.74223852157593 and batch: 1450, loss is 6.80936487197876 and perplexity is 906.2950107579381
At time: 36.95908761024475 and batch: 1500, loss is 6.783639621734619 and perplexity is 883.2776775099229
At time: 38.17088341712952 and batch: 1550, loss is 6.7790710067749025 and perplexity is 879.2515258700718
At time: 39.38972568511963 and batch: 1600, loss is 6.7813460159301755 and perplexity is 881.2541082240839
At time: 40.602577209472656 and batch: 1650, loss is 6.767044792175293 and perplexity is 868.7407872125023
At time: 41.816593647003174 and batch: 1700, loss is 6.795823974609375 and perplexity is 894.1056765409903
At time: 43.03438901901245 and batch: 1750, loss is 6.82897255897522 and perplexity is 924.2407216472961
At time: 44.253223180770874 and batch: 1800, loss is 6.832228298187256 and perplexity is 927.2547121273017
At time: 45.47207021713257 and batch: 1850, loss is 6.785901174545288 and perplexity is 885.2775171432
At time: 46.69116806983948 and batch: 1900, loss is 6.772652463912964 and perplexity is 873.6260851439769
At time: 47.908939599990845 and batch: 1950, loss is 6.729682674407959 and perplexity is 836.8816598463852
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.628953374818314 and perplexity of 756.6897854648108
finished 1 epochs...
Completing Train Step...
At time: 51.54677653312683 and batch: 50, loss is 6.746943349838257 and perplexity is 851.4521893920919
At time: 52.72527742385864 and batch: 100, loss is 6.39421555519104 and perplexity is 598.3737478886777
At time: 53.87957978248596 and batch: 150, loss is 6.108838090896606 and perplexity is 449.8157663831667
At time: 55.03267955780029 and batch: 200, loss is 5.997496194839478 and perplexity is 402.4199498986234
At time: 56.18562579154968 and batch: 250, loss is 5.908785190582275 and perplexity is 368.25851965051066
At time: 57.33923387527466 and batch: 300, loss is 5.847761745452881 and perplexity is 346.4580506836626
At time: 58.493714332580566 and batch: 350, loss is 5.774260835647583 and perplexity is 321.90640501837515
At time: 59.646729707717896 and batch: 400, loss is 5.701899042129517 and perplexity is 299.4355020058076
At time: 60.8003613948822 and batch: 450, loss is 5.6080888080596925 and perplexity is 272.6227054716757
At time: 61.95334053039551 and batch: 500, loss is 5.5666685390472415 and perplexity is 261.5612649998547
At time: 63.107081174850464 and batch: 550, loss is 5.508169374465942 and perplexity is 246.69909977622925
At time: 64.26167917251587 and batch: 600, loss is 5.5304390239715575 and perplexity is 252.25463254765756
At time: 65.41400790214539 and batch: 650, loss is 5.6112962818145755 and perplexity is 273.49853950091915
At time: 66.56768250465393 and batch: 700, loss is 5.517248725891113 and perplexity is 248.94916671668182
At time: 67.72225213050842 and batch: 750, loss is 5.447933797836304 and perplexity is 232.27773698420646
At time: 68.87630343437195 and batch: 800, loss is 5.440600957870483 and perplexity is 230.5807111249601
At time: 70.02984309196472 and batch: 850, loss is 5.456002025604248 and perplexity is 234.1593872557416
At time: 71.20576977729797 and batch: 900, loss is 5.465333681106568 and perplexity is 236.35470905295278
At time: 72.35946798324585 and batch: 950, loss is 5.484502620697022 and perplexity is 240.92908105342295
At time: 73.51327633857727 and batch: 1000, loss is 5.451359539031983 and perplexity is 233.07482492559896
At time: 74.66759085655212 and batch: 1050, loss is 5.342603416442871 and perplexity is 209.05626294756829
At time: 75.82195401191711 and batch: 1100, loss is 5.429473886489868 and perplexity is 228.02924459345704
At time: 76.975594997406 and batch: 1150, loss is 5.324123516082763 and perplexity is 205.2284022171454
At time: 78.13035845756531 and batch: 1200, loss is 5.4002992630004885 and perplexity is 221.47268486801275
At time: 79.28352999687195 and batch: 1250, loss is 5.336628894805909 and perplexity is 207.81097548389323
At time: 80.4360682964325 and batch: 1300, loss is 5.368477230072021 and perplexity is 214.53592997939995
At time: 81.5887439250946 and batch: 1350, loss is 5.311789960861206 and perplexity is 202.71275173172404
At time: 82.74275755882263 and batch: 1400, loss is 5.321904010772705 and perplexity is 204.77340181334128
At time: 83.89632225036621 and batch: 1450, loss is 5.276602754592895 and perplexity is 195.70389059202495
At time: 85.05001378059387 and batch: 1500, loss is 5.25383752822876 and perplexity is 191.2989768887383
At time: 86.20752239227295 and batch: 1550, loss is 5.229482088088989 and perplexity is 186.69608634998303
At time: 87.36720156669617 and batch: 1600, loss is 5.2612442111969 and perplexity is 192.7211279723164
At time: 88.52077388763428 and batch: 1650, loss is 5.2375414848327635 and perplexity is 188.2068238193625
At time: 89.67695879936218 and batch: 1700, loss is 5.226406755447388 and perplexity is 186.12281573231022
At time: 90.83100008964539 and batch: 1750, loss is 5.243554658889771 and perplexity is 189.3419536559892
At time: 91.98430514335632 and batch: 1800, loss is 5.221333475112915 and perplexity is 185.1809536966801
At time: 93.13841915130615 and batch: 1850, loss is 5.185611019134521 and perplexity is 178.68259492605236
At time: 94.29211211204529 and batch: 1900, loss is 5.205335054397583 and perplexity is 182.24192349844407
At time: 95.44624519348145 and batch: 1950, loss is 5.1339070510864255 and perplexity is 169.67876826850483
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.9352079169694765 and perplexity of 139.1020612046465
finished 2 epochs...
Completing Train Step...
At time: 99.0726387500763 and batch: 50, loss is 5.18149585723877 and perplexity is 177.94879800209256
At time: 100.25188446044922 and batch: 100, loss is 5.159605083465576 and perplexity is 174.09568876135887
At time: 101.40919017791748 and batch: 150, loss is 5.100974998474121 and perplexity is 164.18190639600397
At time: 102.56656813621521 and batch: 200, loss is 5.080356750488281 and perplexity is 160.83142238370982
At time: 103.73043489456177 and batch: 250, loss is 5.112965755462646 and perplexity is 166.16242194832918
At time: 104.88743472099304 and batch: 300, loss is 5.130833349227905 and perplexity is 169.15802703475686
At time: 106.04508590698242 and batch: 350, loss is 5.11708173751831 and perplexity is 166.8477529328781
At time: 107.20192360877991 and batch: 400, loss is 5.085504312515258 and perplexity is 161.66144657402958
At time: 108.35836958885193 and batch: 450, loss is 5.051296443939209 and perplexity is 156.22487004023586
At time: 109.51435470581055 and batch: 500, loss is 5.055267744064331 and perplexity is 156.84651944734378
At time: 110.67043137550354 and batch: 550, loss is 5.021019687652588 and perplexity is 151.5657747736847
At time: 111.83059883117676 and batch: 600, loss is 5.013039197921753 and perplexity is 150.36101932784274
At time: 112.98747086524963 and batch: 650, loss is 5.094867420196533 and perplexity is 163.18220852502884
At time: 114.1427366733551 and batch: 700, loss is 5.064771575927734 and perplexity is 158.34426829977355
At time: 115.29947257041931 and batch: 750, loss is 5.014605236053467 and perplexity is 150.59667489227186
At time: 116.45429825782776 and batch: 800, loss is 5.007484292984008 and perplexity is 149.52809371223722
At time: 117.61082482337952 and batch: 850, loss is 5.013298559188843 and perplexity is 150.40002221003635
At time: 118.7670464515686 and batch: 900, loss is 5.031909847259522 and perplexity is 153.22537048129476
At time: 119.92425012588501 and batch: 950, loss is 5.078224134445191 and perplexity is 160.48879618701991
At time: 121.08087468147278 and batch: 1000, loss is 5.053710823059082 and perplexity is 156.6025118062166
At time: 122.23836731910706 and batch: 1050, loss is 4.963849859237671 and perplexity is 143.14382001773424
At time: 123.3947401046753 and batch: 1100, loss is 5.044983320236206 and perplexity is 155.24170978171458
At time: 124.55213761329651 and batch: 1150, loss is 4.955666971206665 and perplexity is 141.97726955143375
At time: 125.70996022224426 and batch: 1200, loss is 5.040003852844238 and perplexity is 154.47061017594476
At time: 126.86707067489624 and batch: 1250, loss is 4.987300014495849 and perplexity is 146.5402323780454
At time: 128.02394199371338 and batch: 1300, loss is 5.01732232093811 and perplexity is 151.00641523887296
At time: 129.18218159675598 and batch: 1350, loss is 4.947020893096924 and perplexity is 140.75501445967743
At time: 130.33881878852844 and batch: 1400, loss is 4.960914916992188 and perplexity is 142.7243170827565
At time: 131.49578523635864 and batch: 1450, loss is 4.902177610397339 and perplexity is 134.58252913687443
At time: 132.6519525051117 and batch: 1500, loss is 4.8764385318756105 and perplexity is 131.16269928734965
At time: 133.8088448047638 and batch: 1550, loss is 4.872667684555053 and perplexity is 130.669036123356
At time: 134.96490931510925 and batch: 1600, loss is 4.93309986114502 and perplexity is 138.8091351550404
At time: 136.12178301811218 and batch: 1650, loss is 4.897801914215088 and perplexity is 133.9949234075655
At time: 137.27942490577698 and batch: 1700, loss is 4.929354820251465 and perplexity is 138.29026147550783
At time: 138.43703746795654 and batch: 1750, loss is 4.93349142074585 and perplexity is 138.8634978470157
At time: 139.59337782859802 and batch: 1800, loss is 4.905364856719971 and perplexity is 135.0121611157261
At time: 140.75695538520813 and batch: 1850, loss is 4.892988328933716 and perplexity is 133.35147730024707
At time: 141.91364932060242 and batch: 1900, loss is 4.941798477172852 and perplexity is 140.0218493436972
At time: 143.07051014900208 and batch: 1950, loss is 4.873154125213623 and perplexity is 130.73261431759815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.762611566587936 and perplexity of 117.05121412509831
finished 3 epochs...
Completing Train Step...
At time: 146.69458413124084 and batch: 50, loss is 4.905585279464722 and perplexity is 135.04192414695797
At time: 147.85442543029785 and batch: 100, loss is 4.870779399871826 and perplexity is 130.42252859531294
At time: 149.01140022277832 and batch: 150, loss is 4.823586320877075 and perplexity is 124.41046752752197
At time: 150.16802644729614 and batch: 200, loss is 4.813067674636841 and perplexity is 123.1086962692108
At time: 151.32393074035645 and batch: 250, loss is 4.833200798034668 and perplexity is 125.61237773633741
At time: 152.47901344299316 and batch: 300, loss is 4.854389190673828 and perplexity is 128.30229903500026
At time: 153.6361424922943 and batch: 350, loss is 4.857177457809448 and perplexity is 128.66053932153994
At time: 154.7914800643921 and batch: 400, loss is 4.831841917037964 and perplexity is 125.44180138600933
At time: 155.94548559188843 and batch: 450, loss is 4.814890785217285 and perplexity is 123.333341750479
At time: 157.0990240573883 and batch: 500, loss is 4.825978698730469 and perplexity is 124.70846068875534
At time: 158.2944850921631 and batch: 550, loss is 4.788069334030151 and perplexity is 120.069330970326
At time: 159.45018696784973 and batch: 600, loss is 4.767068119049072 and perplexity is 117.57402309901012
At time: 160.60627603530884 and batch: 650, loss is 4.839133682250977 and perplexity is 126.35983653033355
At time: 161.7623062133789 and batch: 700, loss is 4.842212972640991 and perplexity is 126.74953484986277
At time: 162.91778373718262 and batch: 750, loss is 4.805931854248047 and perplexity is 122.23334162550556
At time: 164.07533931732178 and batch: 800, loss is 4.788400077819825 and perplexity is 120.10904972387813
At time: 165.23127436637878 and batch: 850, loss is 4.795665121078491 and perplexity is 120.98482458499618
At time: 166.3869936466217 and batch: 900, loss is 4.800852127075196 and perplexity is 121.61400396356002
At time: 167.54629921913147 and batch: 950, loss is 4.863482465744019 and perplexity is 129.47430775522596
At time: 168.70735144615173 and batch: 1000, loss is 4.839052877426147 and perplexity is 126.34962645839433
At time: 169.86366176605225 and batch: 1050, loss is 4.754835891723633 and perplexity is 116.14459131164847
At time: 171.01950669288635 and batch: 1100, loss is 4.832597312927246 and perplexity is 125.53659540611939
At time: 172.17640352249146 and batch: 1150, loss is 4.749310188293457 and perplexity is 115.50458062813021
At time: 173.3325970172882 and batch: 1200, loss is 4.842262582778931 and perplexity is 126.75582306774888
At time: 174.48746967315674 and batch: 1250, loss is 4.798763837814331 and perplexity is 121.3603037370393
At time: 175.64303493499756 and batch: 1300, loss is 4.815104675292969 and perplexity is 123.35972434966783
At time: 176.79991936683655 and batch: 1350, loss is 4.733003940582275 and perplexity is 113.63640716867867
At time: 177.95545411109924 and batch: 1400, loss is 4.748454647064209 and perplexity is 115.40580395701818
At time: 179.11157035827637 and batch: 1450, loss is 4.689000301361084 and perplexity is 108.74441380739026
At time: 180.26659870147705 and batch: 1500, loss is 4.667513027191162 and perplexity is 106.43271773945835
At time: 181.42618608474731 and batch: 1550, loss is 4.6684030914306645 and perplexity is 106.52749186670528
At time: 182.58505725860596 and batch: 1600, loss is 4.745952377319336 and perplexity is 115.11738850251588
At time: 183.7406027317047 and batch: 1650, loss is 4.706376180648804 and perplexity is 110.65045523182707
At time: 184.896568775177 and batch: 1700, loss is 4.737588291168213 and perplexity is 114.15855223201828
At time: 186.05168747901917 and batch: 1750, loss is 4.737370090484619 and perplexity is 114.13364547531769
At time: 187.20715498924255 and batch: 1800, loss is 4.700952873229981 and perplexity is 110.0519880995467
At time: 188.37583422660828 and batch: 1850, loss is 4.7054932594299315 and perplexity is 110.55280271310916
At time: 189.5314109325409 and batch: 1900, loss is 4.772048788070679 and perplexity is 118.1610811509332
At time: 190.68707013130188 and batch: 1950, loss is 4.7030957984924315 and perplexity is 110.28807415206639
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.668748012808866 and perplexity of 106.5642418135731
finished 4 epochs...
Completing Train Step...
At time: 194.31107568740845 and batch: 50, loss is 4.725038719177246 and perplexity is 112.73486329071922
At time: 195.46622395515442 and batch: 100, loss is 4.682599992752075 and perplexity is 108.05063855568827
At time: 196.61978387832642 and batch: 150, loss is 4.643358926773072 and perplexity is 103.89273023293438
At time: 197.77439665794373 and batch: 200, loss is 4.640638275146484 and perplexity is 103.6104584631237
At time: 198.92719864845276 and batch: 250, loss is 4.65363525390625 and perplexity is 104.96587044161265
At time: 200.08021354675293 and batch: 300, loss is 4.679291696548462 and perplexity is 107.69376568443155
At time: 201.23330307006836 and batch: 350, loss is 4.689865980148316 and perplexity is 108.83859229793258
At time: 202.3857080936432 and batch: 400, loss is 4.661288948059082 and perplexity is 105.77232936865077
At time: 203.5412859916687 and batch: 450, loss is 4.652729806900024 and perplexity is 104.87087242279145
At time: 204.69985675811768 and batch: 500, loss is 4.663271083831787 and perplexity is 105.98219240626158
At time: 205.85337567329407 and batch: 550, loss is 4.62554973602295 and perplexity is 102.05886309744224
At time: 207.01158332824707 and batch: 600, loss is 4.609557332992554 and perplexity is 100.43967846226104
At time: 208.16679096221924 and batch: 650, loss is 4.67447940826416 and perplexity is 107.17675723213983
At time: 209.32082891464233 and batch: 700, loss is 4.684241762161255 and perplexity is 108.22817848864827
At time: 210.47420001029968 and batch: 750, loss is 4.648976564407349 and perplexity is 104.4780043339615
At time: 211.6294138431549 and batch: 800, loss is 4.632938442230224 and perplexity is 102.81573877538919
At time: 212.78495955467224 and batch: 850, loss is 4.636255626678467 and perplexity is 103.15736384851738
At time: 213.93932938575745 and batch: 900, loss is 4.638889760971069 and perplexity is 103.42945239972936
At time: 215.1358072757721 and batch: 950, loss is 4.707975740432739 and perplexity is 110.82758888025252
At time: 216.28962564468384 and batch: 1000, loss is 4.683838872909546 and perplexity is 108.18458330140903
At time: 217.4437336921692 and batch: 1050, loss is 4.60635929107666 and perplexity is 100.11898123543344
At time: 218.59764957427979 and batch: 1100, loss is 4.680869188308716 and perplexity is 107.86378577982163
At time: 219.7519769668579 and batch: 1150, loss is 4.602022724151611 and perplexity is 99.68574862288824
At time: 220.9075849056244 and batch: 1200, loss is 4.69733362197876 and perplexity is 109.65440221951228
At time: 222.06244921684265 and batch: 1250, loss is 4.659388570785523 and perplexity is 105.57151291169893
At time: 223.21728205680847 and batch: 1300, loss is 4.672014894485474 and perplexity is 106.91294385656563
At time: 224.37220215797424 and batch: 1350, loss is 4.579226884841919 and perplexity is 97.43903348577307
At time: 225.52639818191528 and batch: 1400, loss is 4.591660261154175 and perplexity is 98.65809246173201
At time: 226.68038058280945 and batch: 1450, loss is 4.5228453540802 and perplexity is 92.09727487674155
At time: 227.84072995185852 and batch: 1500, loss is 4.515548315048218 and perplexity is 91.42768345572362
At time: 228.99741530418396 and batch: 1550, loss is 4.519937992095947 and perplexity is 91.8299036217581
At time: 230.15238451957703 and batch: 1600, loss is 4.602588214874268 and perplexity is 99.74213593066261
At time: 231.30661940574646 and batch: 1650, loss is 4.5626491451263425 and perplexity is 95.83703003718072
At time: 232.4608027935028 and batch: 1700, loss is 4.59353087425232 and perplexity is 98.84281630128046
At time: 233.61560988426208 and batch: 1750, loss is 4.599124212265014 and perplexity is 99.39722663977759
At time: 234.7702181339264 and batch: 1800, loss is 4.547384223937988 and perplexity is 94.38519459538712
At time: 235.92434549331665 and batch: 1850, loss is 4.560230779647827 and perplexity is 95.60554109742738
At time: 237.07821416854858 and batch: 1900, loss is 4.641412010192871 and perplexity is 103.6906565280346
At time: 238.2317430973053 and batch: 1950, loss is 4.568748540878296 and perplexity is 96.42336433577076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6127580509629365 and perplexity of 100.7616725773383
finished 5 epochs...
Completing Train Step...
At time: 241.85314297676086 and batch: 50, loss is 4.5815989208221435 and perplexity is 97.67043671897692
At time: 243.00964093208313 and batch: 100, loss is 4.543597383499145 and perplexity is 94.02844881964612
At time: 244.18951606750488 and batch: 150, loss is 4.50979115486145 and perplexity is 90.90283191344375
At time: 245.34676432609558 and batch: 200, loss is 4.503031072616577 and perplexity is 90.2903936920915
At time: 246.50428533554077 and batch: 250, loss is 4.5119639492034915 and perplexity is 91.10055980553342
At time: 247.65825200080872 and batch: 300, loss is 4.540825567245483 and perplexity is 93.76818011205447
At time: 248.81539797782898 and batch: 350, loss is 4.548298473358154 and perplexity is 94.47152566286908
At time: 249.97247743606567 and batch: 400, loss is 4.516235151290894 and perplexity is 91.49050087247468
At time: 251.13049840927124 and batch: 450, loss is 4.518481206893921 and perplexity is 91.69622457153092
At time: 252.28681445121765 and batch: 500, loss is 4.535323657989502 and perplexity is 93.25369272327951
At time: 253.44326186180115 and batch: 550, loss is 4.498125801086426 and perplexity is 89.84857929017092
At time: 254.60005021095276 and batch: 600, loss is 4.477811040878296 and perplexity is 88.04174181996213
At time: 255.75684118270874 and batch: 650, loss is 4.543702630996704 and perplexity is 94.03834559938025
At time: 256.9144332408905 and batch: 700, loss is 4.556211328506469 and perplexity is 95.22203056340254
At time: 258.0719394683838 and batch: 750, loss is 4.518425188064575 and perplexity is 91.69108800024868
At time: 259.2282438278198 and batch: 800, loss is 4.505366287231445 and perplexity is 90.50148751778839
At time: 260.3845708370209 and batch: 850, loss is 4.501530857086181 and perplexity is 90.1550401963234
At time: 261.5406255722046 and batch: 900, loss is 4.500071754455567 and perplexity is 90.02359066251118
At time: 262.6973969936371 and batch: 950, loss is 4.57494553565979 and perplexity is 97.02275471270751
At time: 263.85547256469727 and batch: 1000, loss is 4.552382211685181 and perplexity is 94.85811147342199
At time: 265.0138330459595 and batch: 1050, loss is 4.480450954437256 and perplexity is 88.27447146586043
At time: 266.1736636161804 and batch: 1100, loss is 4.55373062133789 and perplexity is 94.98610534126067
At time: 267.3320896625519 and batch: 1150, loss is 4.478907833099365 and perplexity is 88.13835829193162
At time: 268.48911905288696 and batch: 1200, loss is 4.571701955795288 and perplexity is 96.7085634867521
At time: 269.6457893848419 and batch: 1250, loss is 4.53627028465271 and perplexity is 93.34201095085336
At time: 270.8023028373718 and batch: 1300, loss is 4.544312343597412 and perplexity is 94.09569944654682
At time: 271.9582402706146 and batch: 1350, loss is 4.442506113052368 and perplexity is 84.98766370306232
At time: 273.11584210395813 and batch: 1400, loss is 4.4602425670623775 and perplexity is 86.50849066195873
At time: 274.2719888687134 and batch: 1450, loss is 4.390600872039795 and perplexity is 80.68888811393498
At time: 275.43707394599915 and batch: 1500, loss is 4.392460317611694 and perplexity is 80.83906428858138
At time: 276.5937485694885 and batch: 1550, loss is 4.3925133228302 and perplexity is 80.84334929441064
At time: 277.7513630390167 and batch: 1600, loss is 4.481128730773926 and perplexity is 88.33432209413066
At time: 278.9083435535431 and batch: 1650, loss is 4.435226669311524 and perplexity is 84.37124709349129
At time: 280.0659282207489 and batch: 1700, loss is 4.469593982696534 and perplexity is 87.32126187172915
At time: 281.2227532863617 and batch: 1750, loss is 4.479345960617065 and perplexity is 88.1769825926309
At time: 282.3810911178589 and batch: 1800, loss is 4.424589948654175 and perplexity is 83.47856970309627
At time: 283.5429346561432 and batch: 1850, loss is 4.442788982391358 and perplexity is 85.01170750778354
At time: 284.700572013855 and batch: 1900, loss is 4.5268214893341066 and perplexity is 92.46419507693278
At time: 285.8577024936676 and batch: 1950, loss is 4.45206660270691 and perplexity is 85.80408385226198
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.575257483194041 and perplexity of 97.05302544300075
finished 6 epochs...
Completing Train Step...
At time: 289.4888186454773 and batch: 50, loss is 4.460919961929322 and perplexity is 86.56711092177021
At time: 290.6673843860626 and batch: 100, loss is 4.422551889419555 and perplexity is 83.30860868735924
At time: 291.8254961967468 and batch: 150, loss is 4.388419914245605 and perplexity is 80.5131008165154
At time: 292.9796440601349 and batch: 200, loss is 4.386248788833618 and perplexity is 80.33848640082363
At time: 294.1350064277649 and batch: 250, loss is 4.393219404220581 and perplexity is 80.90045143589084
At time: 295.2948760986328 and batch: 300, loss is 4.421220264434814 and perplexity is 83.19774669227036
At time: 296.45231461524963 and batch: 350, loss is 4.420784273147583 and perplexity is 83.16148110590954
At time: 297.60774302482605 and batch: 400, loss is 4.391700363159179 and perplexity is 80.77765361934945
At time: 298.7646231651306 and batch: 450, loss is 4.405839691162109 and perplexity is 81.92790810870329
At time: 299.92152643203735 and batch: 500, loss is 4.4229445648193355 and perplexity is 83.341328352264
At time: 301.07713532447815 and batch: 550, loss is 4.380481977462768 and perplexity is 79.8765228126259
At time: 302.2558789253235 and batch: 600, loss is 4.364872255325317 and perplexity is 78.63935354146811
At time: 303.412184715271 and batch: 650, loss is 4.4257924842834475 and perplexity is 83.57901604049019
At time: 304.56914162635803 and batch: 700, loss is 4.4434217357635495 and perplexity is 85.06551597433389
At time: 305.7261326313019 and batch: 750, loss is 4.409600696563721 and perplexity is 82.23661958250538
At time: 306.8831584453583 and batch: 800, loss is 4.39392484664917 and perplexity is 80.95754218157526
At time: 308.0437309741974 and batch: 850, loss is 4.387639322280884 and perplexity is 80.4502774598569
At time: 309.2075560092926 and batch: 900, loss is 4.378651151657104 and perplexity is 79.73041660171589
At time: 310.3676745891571 and batch: 950, loss is 4.456662034988403 and perplexity is 86.19929810373439
At time: 311.5282917022705 and batch: 1000, loss is 4.438417673110962 and perplexity is 84.6409060761321
At time: 312.68754601478577 and batch: 1050, loss is 4.371754207611084 and perplexity is 79.18241232932957
At time: 313.8481991291046 and batch: 1100, loss is 4.433410549163819 and perplexity is 84.21815782808522
At time: 315.0077166557312 and batch: 1150, loss is 4.370356340408325 and perplexity is 79.07180315857626
At time: 316.1676905155182 and batch: 1200, loss is 4.4647986030578615 and perplexity is 86.90352567286735
At time: 317.33153676986694 and batch: 1250, loss is 4.435039701461792 and perplexity is 84.35547385743304
At time: 318.49653792381287 and batch: 1300, loss is 4.437427997589111 and perplexity is 84.55718048066129
At time: 319.657851934433 and batch: 1350, loss is 4.327937202453613 and perplexity is 75.7877903466949
At time: 320.81787633895874 and batch: 1400, loss is 4.3510222911834715 and perplexity is 77.55770897418532
At time: 321.97519731521606 and batch: 1450, loss is 4.277975974082946 and perplexity is 72.0943713577238
At time: 323.1311466693878 and batch: 1500, loss is 4.27998613357544 and perplexity is 72.23943829765888
At time: 324.28925347328186 and batch: 1550, loss is 4.28485876083374 and perplexity is 72.59229312070927
At time: 325.445912361145 and batch: 1600, loss is 4.378642578125 and perplexity is 79.72973303335974
At time: 326.60898876190186 and batch: 1650, loss is 4.331985683441162 and perplexity is 76.09523770246224
At time: 327.7675278186798 and batch: 1700, loss is 4.363840894699097 and perplexity is 78.55828981870557
At time: 328.9239842891693 and batch: 1750, loss is 4.3727791881561275 and perplexity is 79.26361436962335
At time: 330.08373737335205 and batch: 1800, loss is 4.31613356590271 and perplexity is 74.8984777013974
At time: 331.24032735824585 and batch: 1850, loss is 4.338562068939209 and perplexity is 76.59731844889588
At time: 332.39722514152527 and batch: 1900, loss is 4.420922136306762 and perplexity is 83.17294680074714
At time: 333.5560920238495 and batch: 1950, loss is 4.344601221084595 and perplexity is 77.06130092916116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.548143111827762 and perplexity of 94.45684956214383
finished 7 epochs...
Completing Train Step...
At time: 337.1980550289154 and batch: 50, loss is 4.35354218006134 and perplexity is 77.75339222890447
At time: 338.3757908344269 and batch: 100, loss is 4.31799430847168 and perplexity is 75.03797423052343
At time: 339.5328514575958 and batch: 150, loss is 4.2861425399780275 and perplexity is 72.68554543753606
At time: 340.6911337375641 and batch: 200, loss is 4.281633377075195 and perplexity is 72.3585323043056
At time: 341.8494460582733 and batch: 250, loss is 4.288785429000854 and perplexity is 72.87789934073695
At time: 343.01140117645264 and batch: 300, loss is 4.308107843399048 and perplexity is 74.2997690518363
At time: 344.1711804866791 and batch: 350, loss is 4.310848131179809 and perplexity is 74.50365102113487
At time: 345.33395552635193 and batch: 400, loss is 4.28071590423584 and perplexity is 72.29217576103852
At time: 346.4916636943817 and batch: 450, loss is 4.297434096336365 and perplexity is 73.51092953617854
At time: 347.64944982528687 and batch: 500, loss is 4.316204204559326 and perplexity is 74.90376861611414
At time: 348.8077290058136 and batch: 550, loss is 4.277982158660889 and perplexity is 72.09481723236142
At time: 349.9652523994446 and batch: 600, loss is 4.26903422832489 and perplexity is 71.4525953932942
At time: 351.1263587474823 and batch: 650, loss is 4.323732471466064 and perplexity is 75.46979209321246
At time: 352.2846665382385 and batch: 700, loss is 4.33898289680481 and perplexity is 76.6295595184239
At time: 353.44155406951904 and batch: 750, loss is 4.311859402656555 and perplexity is 74.57903254749553
At time: 354.60112953186035 and batch: 800, loss is 4.287929449081421 and perplexity is 72.81554401359207
At time: 355.7599182128906 and batch: 850, loss is 4.283487987518311 and perplexity is 72.492853712408
At time: 356.92135286331177 and batch: 900, loss is 4.2688894462585445 and perplexity is 71.44225108774044
At time: 358.08111119270325 and batch: 950, loss is 4.357638549804688 and perplexity is 78.07255212444498
At time: 359.2393419742584 and batch: 1000, loss is 4.337066421508789 and perplexity is 76.48284149630078
At time: 360.4267921447754 and batch: 1050, loss is 4.277385368347168 and perplexity is 72.05180457981149
At time: 361.58646154403687 and batch: 1100, loss is 4.33068920135498 and perplexity is 75.99664551524957
At time: 362.7704060077667 and batch: 1150, loss is 4.274672431945801 and perplexity is 71.85659752826807
At time: 363.9307243824005 and batch: 1200, loss is 4.3654463005065915 and perplexity is 78.68450904283608
At time: 365.0915906429291 and batch: 1250, loss is 4.33939829826355 and perplexity is 76.66139816168207
At time: 366.260071516037 and batch: 1300, loss is 4.340466823577881 and perplexity is 76.74335658577728
At time: 367.41662645339966 and batch: 1350, loss is 4.225149888992309 and perplexity is 68.3847529021081
At time: 368.5744802951813 and batch: 1400, loss is 4.250649681091309 and perplexity is 70.15097330593221
At time: 369.73430728912354 and batch: 1450, loss is 4.181150741577149 and perplexity is 65.44111571456813
At time: 370.89230132102966 and batch: 1500, loss is 4.187549891471863 and perplexity is 65.86122596393758
At time: 372.0489673614502 and batch: 1550, loss is 4.188632011413574 and perplexity is 65.93253428505844
At time: 373.2055838108063 and batch: 1600, loss is 4.285167593955993 and perplexity is 72.61471548745182
At time: 374.36101508140564 and batch: 1650, loss is 4.237996182441711 and perplexity is 69.26891041967593
At time: 375.5212252140045 and batch: 1700, loss is 4.264675397872924 and perplexity is 71.14182343779353
At time: 376.6810884475708 and batch: 1750, loss is 4.278457260131836 and perplexity is 72.12907772403672
At time: 377.8398551940918 and batch: 1800, loss is 4.21761191368103 and perplexity is 67.8712082980148
At time: 378.9977340698242 and batch: 1850, loss is 4.241047143936157 and perplexity is 69.4805699164322
At time: 380.15607047080994 and batch: 1900, loss is 4.320270805358887 and perplexity is 75.20899253274024
At time: 381.31438970565796 and batch: 1950, loss is 4.250419788360595 and perplexity is 70.13484796073756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5443816428960755 and perplexity of 94.10222043847315
finished 8 epochs...
Completing Train Step...
At time: 384.9354770183563 and batch: 50, loss is 4.259649620056153 and perplexity is 70.78517740227537
At time: 386.11628770828247 and batch: 100, loss is 4.220288724899292 and perplexity is 68.05313008629848
At time: 387.27816820144653 and batch: 150, loss is 4.185511660575867 and perplexity is 65.72712229188005
At time: 388.45507645606995 and batch: 200, loss is 4.191085548400879 and perplexity is 66.09450081077324
At time: 389.60994005203247 and batch: 250, loss is 4.188570585250854 and perplexity is 65.92848442686382
At time: 390.7657516002655 and batch: 300, loss is 4.215703730583191 and perplexity is 67.74182109201038
At time: 391.9197301864624 and batch: 350, loss is 4.208458003997802 and perplexity is 67.25275633242563
At time: 393.076886177063 and batch: 400, loss is 4.183359050750733 and perplexity is 65.58578961428672
At time: 394.23115587234497 and batch: 450, loss is 4.202934970855713 and perplexity is 66.88234098003072
At time: 395.3864517211914 and batch: 500, loss is 4.225953378677368 and perplexity is 68.43972142604396
At time: 396.54123997688293 and batch: 550, loss is 4.185358772277832 and perplexity is 65.71707415215916
At time: 397.6983554363251 and batch: 600, loss is 4.177268652915955 and perplexity is 65.18755998262928
At time: 398.85427355766296 and batch: 650, loss is 4.230719203948975 and perplexity is 68.76667165499248
At time: 400.0089626312256 and batch: 700, loss is 4.251328649520874 and perplexity is 70.19861977550414
At time: 401.1624414920807 and batch: 750, loss is 4.225056591033936 and perplexity is 68.37837304189708
At time: 402.3199288845062 and batch: 800, loss is 4.197553734779358 and perplexity is 66.52339795862598
At time: 403.47594952583313 and batch: 850, loss is 4.19170081615448 and perplexity is 66.13517913856091
At time: 404.63014221191406 and batch: 900, loss is 4.182099080085754 and perplexity is 65.50320548105127
At time: 405.7847237586975 and batch: 950, loss is 4.269351811408996 and perplexity is 71.4752911326073
At time: 406.94030570983887 and batch: 1000, loss is 4.2453353977203365 and perplexity is 69.77915999074406
At time: 408.0970175266266 and batch: 1050, loss is 4.186028785705567 and perplexity is 65.76112022835605
At time: 409.25241327285767 and batch: 1100, loss is 4.241318979263306 and perplexity is 69.49945975723261
At time: 410.40780687332153 and batch: 1150, loss is 4.188496470451355 and perplexity is 65.92359833152744
At time: 411.5654237270355 and batch: 1200, loss is 4.279443016052246 and perplexity is 72.2002144453987
At time: 412.71988916397095 and batch: 1250, loss is 4.2529229640960695 and perplexity is 70.31062772239643
At time: 413.87326836586 and batch: 1300, loss is 4.24988293170929 and perplexity is 70.09720570627294
At time: 415.0269238948822 and batch: 1350, loss is 4.134466190338134 and perplexity is 62.45624242469263
At time: 416.1810693740845 and batch: 1400, loss is 4.166237053871154 and perplexity is 64.47238895101037
At time: 417.33682560920715 and batch: 1450, loss is 4.0906979894638065 and perplexity is 59.781604074827776
At time: 418.4922740459442 and batch: 1500, loss is 4.0979526996612545 and perplexity is 60.216879276177636
At time: 419.65010833740234 and batch: 1550, loss is 4.10066517829895 and perplexity is 60.38043799933176
At time: 420.80452132225037 and batch: 1600, loss is 4.201906390190125 and perplexity is 66.81358246513096
At time: 421.9618287086487 and batch: 1650, loss is 4.146999020576477 and perplexity is 63.24392152237647
At time: 423.1177716255188 and batch: 1700, loss is 4.181808695793152 and perplexity is 65.48418714051182
At time: 424.2714502811432 and batch: 1750, loss is 4.190822095870971 and perplexity is 66.07709034083857
At time: 425.42592430114746 and batch: 1800, loss is 4.133402056694031 and perplexity is 62.38981598541702
At time: 426.5803337097168 and batch: 1850, loss is 4.155834541320801 and perplexity is 63.80519040300893
At time: 427.7362642288208 and batch: 1900, loss is 4.233803052902221 and perplexity is 68.97906500958219
At time: 428.8944282531738 and batch: 1950, loss is 4.164261198043823 and perplexity is 64.34512657305783
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.533077648074128 and perplexity of 93.04447904072977
finished 9 epochs...
Completing Train Step...
At time: 432.52967143058777 and batch: 50, loss is 4.170371470451355 and perplexity is 64.73949645121213
At time: 433.6870319843292 and batch: 100, loss is 4.131329293251038 and perplexity is 62.26063058726482
At time: 434.84427309036255 and batch: 150, loss is 4.099738993644714 and perplexity is 60.32454045396095
At time: 436.0015172958374 and batch: 200, loss is 4.102592749595642 and perplexity is 60.49693784330706
At time: 437.1591281890869 and batch: 250, loss is 4.101719069480896 and perplexity is 60.444105954156434
At time: 438.3163433074951 and batch: 300, loss is 4.126874356269837 and perplexity is 61.983880311816414
At time: 439.4749448299408 and batch: 350, loss is 4.123899698257446 and perplexity is 61.79977342887224
At time: 440.6316924095154 and batch: 400, loss is 4.09421142578125 and perplexity is 59.99201234528471
At time: 441.78923082351685 and batch: 450, loss is 4.121575241088867 and perplexity is 61.65628932843676
At time: 442.9468114376068 and batch: 500, loss is 4.1449804830551145 and perplexity is 63.1163900506181
At time: 444.1028137207031 and batch: 550, loss is 4.100857419967651 and perplexity is 60.39204675129684
At time: 445.261994600296 and batch: 600, loss is 4.091971492767334 and perplexity is 59.85778464291391
At time: 446.45951747894287 and batch: 650, loss is 4.151549482345581 and perplexity is 63.53236635024491
At time: 447.6170859336853 and batch: 700, loss is 4.166855635643006 and perplexity is 64.51228273311429
At time: 448.7747995853424 and batch: 750, loss is 4.14631920337677 and perplexity is 63.20094182757179
At time: 449.93398332595825 and batch: 800, loss is 4.1161996936798095 and perplexity is 61.325742253791546
At time: 451.0927474498749 and batch: 850, loss is 4.10879186630249 and perplexity is 60.87313024698643
At time: 452.24979853630066 and batch: 900, loss is 4.100529661178589 and perplexity is 60.37225597066296
At time: 453.40740060806274 and batch: 950, loss is 4.189921407699585 and perplexity is 66.01760228128633
At time: 454.56376791000366 and batch: 1000, loss is 4.166455235481262 and perplexity is 64.48645717529729
At time: 455.72037959098816 and batch: 1050, loss is 4.107408528327942 and perplexity is 60.78898035157834
At time: 456.88127183914185 and batch: 1100, loss is 4.159039740562439 and perplexity is 64.01002684634543
At time: 458.04228043556213 and batch: 1150, loss is 4.106408581733704 and perplexity is 60.72822499882503
At time: 459.20696997642517 and batch: 1200, loss is 4.193170218467713 and perplexity is 66.23242975641642
At time: 460.3760211467743 and batch: 1250, loss is 4.17279483795166 and perplexity is 64.89657429469587
At time: 461.53587555885315 and batch: 1300, loss is 4.168551650047302 and perplexity is 64.62178933001724
At time: 462.7000558376312 and batch: 1350, loss is 4.051885714530945 and perplexity is 57.50579437877471
At time: 463.8659460544586 and batch: 1400, loss is 4.087874217033386 and perplexity is 59.61303254522532
At time: 465.0289342403412 and batch: 1450, loss is 4.010733938217163 and perplexity is 55.187359815814595
At time: 466.2141532897949 and batch: 1500, loss is 4.018274755477905 and perplexity is 55.605090647739665
At time: 467.38457202911377 and batch: 1550, loss is 4.018578200340271 and perplexity is 55.62196628710167
At time: 468.56152057647705 and batch: 1600, loss is 4.119788479804993 and perplexity is 61.54622261850781
At time: 469.7365937232971 and batch: 1650, loss is 4.068940176963806 and perplexity is 58.494935448711395
At time: 470.90607810020447 and batch: 1700, loss is 4.103720355033874 and perplexity is 60.56519299462331
At time: 472.0745475292206 and batch: 1750, loss is 4.114433078765869 and perplexity is 61.21749892321026
At time: 473.2381236553192 and batch: 1800, loss is 4.050151090621949 and perplexity is 57.40612991810783
At time: 474.4063003063202 and batch: 1850, loss is 4.077365670204163 and perplexity is 58.98986622199135
At time: 475.5636055469513 and batch: 1900, loss is 4.153708300590515 and perplexity is 63.66966933463452
At time: 476.7318923473358 and batch: 1950, loss is 4.085268931388855 and perplexity is 59.45792570385434
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.534349450399709 and perplexity of 93.16288850631268
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 480.4345672130585 and batch: 50, loss is 4.113180503845215 and perplexity is 61.140867422720895
At time: 481.5949332714081 and batch: 100, loss is 4.106948428153991 and perplexity is 60.761017764433205
At time: 482.7569739818573 and batch: 150, loss is 4.07729817867279 and perplexity is 58.98588503993412
At time: 483.9160580635071 and batch: 200, loss is 4.067558794021607 and perplexity is 58.41418732755652
At time: 485.0766644477844 and batch: 250, loss is 4.067337403297424 and perplexity is 58.40125639976808
At time: 486.2441439628601 and batch: 300, loss is 4.091946225166321 and perplexity is 59.856272199402056
At time: 487.41014981269836 and batch: 350, loss is 4.091698813438415 and perplexity is 59.84146488749804
At time: 488.58147406578064 and batch: 400, loss is 4.053736262321472 and perplexity is 57.612310125347406
At time: 489.7419624328613 and batch: 450, loss is 4.058211545944214 and perplexity is 57.87071934931536
At time: 490.89879059791565 and batch: 500, loss is 4.08543493270874 and perplexity is 59.467796617268455
At time: 492.05532693862915 and batch: 550, loss is 4.036326251029968 and perplexity is 56.617960094370424
At time: 493.213506937027 and batch: 600, loss is 4.018032231330872 and perplexity is 55.59160670571647
At time: 494.36911249160767 and batch: 650, loss is 4.067384176254272 and perplexity is 58.40398806309703
At time: 495.52816224098206 and batch: 700, loss is 4.08632490158081 and perplexity is 59.52074466270982
At time: 496.68459248542786 and batch: 750, loss is 4.044505014419555 and perplexity is 57.082923815848226
At time: 497.84194922447205 and batch: 800, loss is 4.014046096801758 and perplexity is 55.3704521514324
At time: 498.99749636650085 and batch: 850, loss is 4.010527234077454 and perplexity is 55.175953538984004
At time: 500.15478515625 and batch: 900, loss is 3.980598545074463 and perplexity is 53.549076173045634
At time: 501.3161127567291 and batch: 950, loss is 4.064780960083008 and perplexity is 58.25214757945461
At time: 502.47518491744995 and batch: 1000, loss is 4.032720198631287 and perplexity is 56.41416044052326
At time: 503.6572799682617 and batch: 1050, loss is 3.9720156383514404 and perplexity is 53.09143619714436
At time: 504.81946086883545 and batch: 1100, loss is 4.011289973258972 and perplexity is 55.218054454593656
At time: 505.9753682613373 and batch: 1150, loss is 3.961600980758667 and perplexity is 52.54137638220501
At time: 507.13912892341614 and batch: 1200, loss is 4.025778551101684 and perplexity is 56.02390928312559
At time: 508.2988097667694 and batch: 1250, loss is 3.9989651966094972 and perplexity is 54.54168090463659
At time: 509.45817518234253 and batch: 1300, loss is 4.000678415298462 and perplexity is 54.63520282056225
At time: 510.61384677886963 and batch: 1350, loss is 3.874183077812195 and perplexity is 48.14335284906692
At time: 511.7712199687958 and batch: 1400, loss is 3.902137017250061 and perplexity is 49.50813587847116
At time: 512.9310536384583 and batch: 1450, loss is 3.8189943742752077 and perplexity is 45.55837060745729
At time: 514.0912477970123 and batch: 1500, loss is 3.821659302711487 and perplexity is 45.6799423228117
At time: 515.2506589889526 and batch: 1550, loss is 3.8241401720046997 and perplexity is 45.793408978811215
At time: 516.4064064025879 and batch: 1600, loss is 3.9117852687835692 and perplexity is 49.988114580627
At time: 517.563206911087 and batch: 1650, loss is 3.8454299116134645 and perplexity is 46.778790774027684
At time: 518.7194004058838 and batch: 1700, loss is 3.8782242345809936 and perplexity is 48.338301328681865
At time: 519.8772518634796 and batch: 1750, loss is 3.869995846748352 and perplexity is 47.94218696443875
At time: 521.0351054668427 and batch: 1800, loss is 3.801679005622864 and perplexity is 44.776301076349895
At time: 522.1908204555511 and batch: 1850, loss is 3.8160314559936523 and perplexity is 45.423584656791085
At time: 523.3484649658203 and batch: 1900, loss is 3.8838926458358767 and perplexity is 48.61308074560325
At time: 524.5072264671326 and batch: 1950, loss is 3.804400954246521 and perplexity is 44.89834589194351
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.504517453215843 and perplexity of 90.42469937152661
finished 11 epochs...
Completing Train Step...
At time: 528.1469881534576 and batch: 50, loss is 4.012831606864929 and perplexity is 55.303246113285994
At time: 529.3011066913605 and batch: 100, loss is 3.99418728351593 and perplexity is 54.28170705409597
At time: 530.456625699997 and batch: 150, loss is 3.9677289819717405 and perplexity is 52.86433854601114
At time: 531.6127762794495 and batch: 200, loss is 3.9576313352584838 and perplexity is 52.33321917238812
At time: 532.7913250923157 and batch: 250, loss is 3.959976282119751 and perplexity is 52.4560817872785
At time: 533.94713139534 and batch: 300, loss is 3.979588580131531 and perplexity is 53.49502078500275
At time: 535.1029071807861 and batch: 350, loss is 3.979538097381592 and perplexity is 53.49232027741058
At time: 536.2576901912689 and batch: 400, loss is 3.945448932647705 and perplexity is 51.69954251561684
At time: 537.4120151996613 and batch: 450, loss is 3.954892373085022 and perplexity is 52.190076585212246
At time: 538.568413734436 and batch: 500, loss is 3.9839307260513306 and perplexity is 53.7278090056918
At time: 539.7236058712006 and batch: 550, loss is 3.9380033349990846 and perplexity is 51.316038005258996
At time: 540.8821256160736 and batch: 600, loss is 3.9245550441741943 and perplexity is 50.63054469020996
At time: 542.0394167900085 and batch: 650, loss is 3.9733200454711914 and perplexity is 53.16073423111642
At time: 543.1936783790588 and batch: 700, loss is 3.99378484249115 and perplexity is 54.259866263392176
At time: 544.3469517230988 and batch: 750, loss is 3.9592135334014893 and perplexity is 52.41608623334805
At time: 545.5014896392822 and batch: 800, loss is 3.928836998939514 and perplexity is 50.84780721450616
At time: 546.6571850776672 and batch: 850, loss is 3.9280977296829223 and perplexity is 50.810230885091265
At time: 547.8125219345093 and batch: 900, loss is 3.89909405708313 and perplexity is 49.35771357366576
At time: 548.9700832366943 and batch: 950, loss is 3.9848369216918944 and perplexity is 53.77651897903921
At time: 550.124433517456 and batch: 1000, loss is 3.9565690660476687 and perplexity is 52.27765672132377
At time: 551.2779357433319 and batch: 1050, loss is 3.8992701816558837 and perplexity is 49.36640744546077
At time: 552.4311380386353 and batch: 1100, loss is 3.9396243333816527 and perplexity is 51.399288676237454
At time: 553.5854606628418 and batch: 1150, loss is 3.8943477773666384 and perplexity is 49.12400312519533
At time: 554.7427327632904 and batch: 1200, loss is 3.962538523674011 and perplexity is 52.59065927619872
At time: 555.8998682498932 and batch: 1250, loss is 3.939298253059387 and perplexity is 51.382531111926156
At time: 557.0552966594696 and batch: 1300, loss is 3.942816767692566 and perplexity is 51.56363972935068
At time: 558.2106068134308 and batch: 1350, loss is 3.8144655418395996 and perplexity is 45.35251088488517
At time: 559.3690407276154 and batch: 1400, loss is 3.8486428260803223 and perplexity is 46.92932873093947
At time: 560.5235617160797 and batch: 1450, loss is 3.7652325344085695 and perplexity is 43.17374407374364
At time: 561.6806797981262 and batch: 1500, loss is 3.771734776496887 and perplexity is 43.455384865581635
At time: 562.8398125171661 and batch: 1550, loss is 3.7774244070053102 and perplexity is 43.70333465151808
At time: 563.9956369400024 and batch: 1600, loss is 3.869238648414612 and perplexity is 47.90589896069521
At time: 565.1544504165649 and batch: 1650, loss is 3.8034466695785523 and perplexity is 44.85552052588672
At time: 566.3117034435272 and batch: 1700, loss is 3.8431359481811525 and perplexity is 46.671604925795826
At time: 567.468132019043 and batch: 1750, loss is 3.839318871498108 and perplexity is 46.49379540305639
At time: 568.6257228851318 and batch: 1800, loss is 3.7729128313064577 and perplexity is 43.50660785654571
At time: 569.7815234661102 and batch: 1850, loss is 3.7908329725265504 and perplexity is 44.29327999930304
At time: 570.9368019104004 and batch: 1900, loss is 3.8609606218338013 and perplexity is 47.51096952911987
At time: 572.0921785831451 and batch: 1950, loss is 3.7863635778427125 and perplexity is 44.09575758076854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.511404773800872 and perplexity of 91.04963285320181
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 575.7067494392395 and batch: 50, loss is 3.9728479862213133 and perplexity is 53.13564513702768
At time: 576.8859927654266 and batch: 100, loss is 3.97612012386322 and perplexity is 53.30979705073833
At time: 578.0437846183777 and batch: 150, loss is 3.9748231506347658 and perplexity is 53.24070048903039
At time: 579.2034394741058 and batch: 200, loss is 3.9759864044189452 and perplexity is 53.302668970894366
At time: 580.3608827590942 and batch: 250, loss is 3.980253930091858 and perplexity is 53.53062553845691
At time: 581.5194284915924 and batch: 300, loss is 4.0187759733200075 and perplexity is 55.632967896987786
At time: 582.6779246330261 and batch: 350, loss is 4.008384265899658 and perplexity is 55.057839828533105
At time: 583.8378384113312 and batch: 400, loss is 3.973759722709656 and perplexity is 53.18411293510328
At time: 584.9983649253845 and batch: 450, loss is 3.9736294555664062 and perplexity is 53.177185243880025
At time: 586.1567068099976 and batch: 500, loss is 3.986296844482422 and perplexity is 53.855085881543104
At time: 587.3174991607666 and batch: 550, loss is 3.955013952255249 and perplexity is 52.196422197156856
At time: 588.4753715991974 and batch: 600, loss is 3.925389413833618 and perplexity is 50.6728069092444
At time: 589.6333954334259 and batch: 650, loss is 3.975833978652954 and perplexity is 53.294544889922456
At time: 590.8160572052002 and batch: 700, loss is 3.991689567565918 and perplexity is 54.14629594823033
At time: 591.9746754169464 and batch: 750, loss is 3.9433043718338014 and perplexity is 51.58878850444505
At time: 593.1374819278717 and batch: 800, loss is 3.908834738731384 and perplexity is 49.84084052141634
At time: 594.296783208847 and batch: 850, loss is 3.9192424201965332 and perplexity is 50.36227687845629
At time: 595.4578995704651 and batch: 900, loss is 3.892830901145935 and perplexity is 49.04954457946459
At time: 596.6215896606445 and batch: 950, loss is 3.988941912651062 and perplexity is 53.99772481661805
At time: 597.7819430828094 and batch: 1000, loss is 3.942866268157959 and perplexity is 51.56619221668877
At time: 598.94016289711 and batch: 1050, loss is 3.87711980342865 and perplexity is 48.28494447275361
At time: 600.0999462604523 and batch: 1100, loss is 3.914636182785034 and perplexity is 50.130829734044006
At time: 601.2597646713257 and batch: 1150, loss is 3.866137886047363 and perplexity is 47.75758421525305
At time: 602.4188964366913 and batch: 1200, loss is 3.9246394062042236 and perplexity is 50.63481616591416
At time: 603.5759227275848 and batch: 1250, loss is 3.8914675283432008 and perplexity is 48.982717329977106
At time: 604.7349398136139 and batch: 1300, loss is 3.9008693075180054 and perplexity is 49.44541369796141
At time: 605.8923366069794 and batch: 1350, loss is 3.7779197311401367 and perplexity is 43.7249873300478
At time: 607.0519099235535 and batch: 1400, loss is 3.8076437187194823 and perplexity is 45.04417697303022
At time: 608.2113246917725 and batch: 1450, loss is 3.7255035257339477 and perplexity is 41.49211983588893
At time: 609.3722689151764 and batch: 1500, loss is 3.7286966943740847 and perplexity is 41.62482293068509
At time: 610.532142162323 and batch: 1550, loss is 3.7326338577270506 and perplexity is 41.789029700422006
At time: 611.6924934387207 and batch: 1600, loss is 3.823917169570923 and perplexity is 45.783198075728436
At time: 612.8511147499084 and batch: 1650, loss is 3.745231819152832 and perplexity is 42.318816393981855
At time: 614.0187430381775 and batch: 1700, loss is 3.7695441246032715 and perplexity is 43.36029343857366
At time: 615.1793646812439 and batch: 1750, loss is 3.7653795957565306 and perplexity is 43.180093729626684
At time: 616.3443615436554 and batch: 1800, loss is 3.7059707927703855 and perplexity is 40.68952925021678
At time: 617.5079438686371 and batch: 1850, loss is 3.72274796962738 and perplexity is 41.37794335379795
At time: 618.670093536377 and batch: 1900, loss is 3.803233413696289 and perplexity is 44.84595584218137
At time: 619.8320624828339 and batch: 1950, loss is 3.7206114196777342 and perplexity is 41.289631685748
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49259033203125 and perplexity of 89.35259926735313
finished 13 epochs...
Completing Train Step...
At time: 623.4954714775085 and batch: 50, loss is 3.9564865112304686 and perplexity is 52.27334112706849
At time: 624.6854972839355 and batch: 100, loss is 3.943585448265076 and perplexity is 51.60329093506189
At time: 625.8506586551666 and batch: 150, loss is 3.9317429876327514 and perplexity is 50.9957852744953
At time: 627.021497964859 and batch: 200, loss is 3.9299727201461794 and perplexity is 50.905588953234236
At time: 628.1835095882416 and batch: 250, loss is 3.9351881885528566 and perplexity is 51.17177899362759
At time: 629.3431913852692 and batch: 300, loss is 3.975162777900696 and perplexity is 53.25878555349035
At time: 630.502851486206 and batch: 350, loss is 3.959568214416504 and perplexity is 52.43468052134193
At time: 631.6614384651184 and batch: 400, loss is 3.9210482168197633 and perplexity is 50.453303070641205
At time: 632.8196561336517 and batch: 450, loss is 3.9279119539260865 and perplexity is 50.80079245273669
At time: 633.9795045852661 and batch: 500, loss is 3.9468181896209718 and perplexity is 51.77038096167146
At time: 635.1362590789795 and batch: 550, loss is 3.918301978111267 and perplexity is 50.31493633777748
At time: 636.2949604988098 and batch: 600, loss is 3.890390844345093 and perplexity is 48.930006803426366
At time: 637.4528822898865 and batch: 650, loss is 3.9385441160202026 and perplexity is 51.343796249580585
At time: 638.6118056774139 and batch: 700, loss is 3.9565459489822388 and perplexity is 52.27644822928127
At time: 639.7678825855255 and batch: 750, loss is 3.91090190410614 and perplexity is 49.943976343865046
At time: 640.9267494678497 and batch: 800, loss is 3.8768010663986208 and perplexity is 48.26955672540996
At time: 642.0839929580688 and batch: 850, loss is 3.8895464515686036 and perplexity is 48.88870809774618
At time: 643.2434787750244 and batch: 900, loss is 3.8633138132095337 and perplexity is 47.62290358233984
At time: 644.4034397602081 and batch: 950, loss is 3.957472867965698 and perplexity is 52.32492672588124
At time: 645.5633096694946 and batch: 1000, loss is 3.9144944381713866 and perplexity is 50.12372446253041
At time: 646.7270050048828 and batch: 1050, loss is 3.8515877819061277 and perplexity is 47.0677372344191
At time: 647.8856427669525 and batch: 1100, loss is 3.8909130096435547 and perplexity is 48.955563026738425
At time: 649.0647513866425 and batch: 1150, loss is 3.845424299240112 and perplexity is 46.77852823472563
At time: 650.2237854003906 and batch: 1200, loss is 3.906518969535828 and perplexity is 49.72555417805884
At time: 651.3801515102386 and batch: 1250, loss is 3.8750951433181764 and perplexity is 48.18728277098078
At time: 652.5361034870148 and batch: 1300, loss is 3.8850308799743654 and perplexity is 48.668445316629985
At time: 653.7096090316772 and batch: 1350, loss is 3.7621925592422487 and perplexity is 43.04269625590092
At time: 654.8752815723419 and batch: 1400, loss is 3.7943229484558105 and perplexity is 44.44813253897218
At time: 656.0409452915192 and batch: 1450, loss is 3.7124987173080446 and perplexity is 40.95601628392348
At time: 657.205424785614 and batch: 1500, loss is 3.7154344367980956 and perplexity is 41.076428320664185
At time: 658.366091966629 and batch: 1550, loss is 3.7207776737213134 and perplexity is 41.296496824636385
At time: 659.5334913730621 and batch: 1600, loss is 3.8137727642059325 and perplexity is 45.32110256046199
At time: 660.6970067024231 and batch: 1650, loss is 3.7372779750823977 and perplexity is 41.9835542062111
At time: 661.8559803962708 and batch: 1700, loss is 3.7646324586868287 and perplexity is 43.1478443297893
At time: 663.015686750412 and batch: 1750, loss is 3.7620432710647584 and perplexity is 43.03627096984417
At time: 664.178938627243 and batch: 1800, loss is 3.7035974502563476 and perplexity is 40.593073567033784
At time: 665.3447375297546 and batch: 1850, loss is 3.7224772787094116 and perplexity is 41.36674423614596
At time: 666.5134220123291 and batch: 1900, loss is 3.804575548171997 and perplexity is 44.90618555475899
At time: 667.6773512363434 and batch: 1950, loss is 3.723047947883606 and perplexity is 41.39035769901516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492679187863372 and perplexity of 89.36053911965912
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 671.3956489562988 and batch: 50, loss is 3.9482576704025267 and perplexity is 51.844957092695786
At time: 672.5878117084503 and batch: 100, loss is 3.946993017196655 and perplexity is 51.7794326430859
At time: 673.7539849281311 and batch: 150, loss is 3.9451711130142213 and perplexity is 51.68518136266137
At time: 674.9164326190948 and batch: 200, loss is 3.954119253158569 and perplexity is 52.14974299040304
At time: 676.0788195133209 and batch: 250, loss is 3.9634902238845826 and perplexity is 52.64073364181862
At time: 677.2649335861206 and batch: 300, loss is 4.008802704811096 and perplexity is 55.08088299183893
At time: 678.4265682697296 and batch: 350, loss is 4.025675616264343 and perplexity is 56.01814276792908
At time: 679.5899488925934 and batch: 400, loss is 3.9894859981536865 and perplexity is 54.02711218976237
At time: 680.7519836425781 and batch: 450, loss is 3.9901707649230955 and perplexity is 54.06412083053461
At time: 681.9148471355438 and batch: 500, loss is 3.9901204538345336 and perplexity is 54.06140087418604
At time: 683.0770757198334 and batch: 550, loss is 3.9523015546798708 and perplexity is 52.05503658182831
At time: 684.2432851791382 and batch: 600, loss is 3.914769148826599 and perplexity is 50.1374958752095
At time: 685.4018287658691 and batch: 650, loss is 3.9631591033935547 and perplexity is 52.62330610171412
At time: 686.565896987915 and batch: 700, loss is 3.9829487657546996 and perplexity is 53.675076325359726
At time: 687.7282929420471 and batch: 750, loss is 3.9384612703323363 and perplexity is 51.33954281365447
At time: 688.90456366539 and batch: 800, loss is 3.9008053064346315 and perplexity is 49.44224923918235
At time: 690.0709311962128 and batch: 850, loss is 3.9153449440002444 and perplexity is 50.16637311624328
At time: 691.2425351142883 and batch: 900, loss is 3.889432291984558 and perplexity is 48.88312730172196
At time: 692.4015181064606 and batch: 950, loss is 3.994579939842224 and perplexity is 54.30302529486994
At time: 693.5683302879333 and batch: 1000, loss is 3.956802864074707 and perplexity is 52.28988056322278
At time: 694.728497505188 and batch: 1050, loss is 3.8870625162124632 and perplexity is 48.76742240245992
At time: 695.8892381191254 and batch: 1100, loss is 3.91563045501709 and perplexity is 50.180698213332356
At time: 697.0499868392944 and batch: 1150, loss is 3.866967854499817 and perplexity is 47.79723795691813
At time: 698.2093517780304 and batch: 1200, loss is 3.921620192527771 and perplexity is 50.482169389015816
At time: 699.3691785335541 and batch: 1250, loss is 3.8788463258743286 and perplexity is 48.36838152041565
At time: 700.5287432670593 and batch: 1300, loss is 3.877441782951355 and perplexity is 48.30049373926716
At time: 701.6886467933655 and batch: 1350, loss is 3.7569600486755372 and perplexity is 42.8180631031171
At time: 702.8473265171051 and batch: 1400, loss is 3.79620156288147 and perplexity is 44.53171192409216
At time: 704.0067803859711 and batch: 1450, loss is 3.7224181699752807 and perplexity is 41.36429917252207
At time: 705.1662077903748 and batch: 1500, loss is 3.7307248306274414 and perplexity is 41.70932940947004
At time: 706.3267507553101 and batch: 1550, loss is 3.7345642709732054 and perplexity is 41.86977771033804
At time: 707.4886293411255 and batch: 1600, loss is 3.8274316024780273 and perplexity is 45.94438312475559
At time: 708.6494855880737 and batch: 1650, loss is 3.7450923204421995 and perplexity is 42.312913385400016
At time: 709.8102188110352 and batch: 1700, loss is 3.7636106204986572 and perplexity is 43.103776733526644
At time: 710.9707679748535 and batch: 1750, loss is 3.7519564628601074 and perplexity is 42.60435435083615
At time: 712.135317325592 and batch: 1800, loss is 3.6856958770751955 and perplexity is 39.87285940676955
At time: 713.3022592067719 and batch: 1850, loss is 3.701527042388916 and perplexity is 40.50911629105059
At time: 714.4744358062744 and batch: 1900, loss is 3.7941605997085572 and perplexity is 44.440917026067325
At time: 715.637274980545 and batch: 1950, loss is 3.7282283973693846 and perplexity is 41.605334714278314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4774683752725295 and perplexity of 88.0115781114965
finished 15 epochs...
Completing Train Step...
At time: 719.3239409923553 and batch: 50, loss is 3.960748620033264 and perplexity is 52.496611257245625
At time: 720.4869124889374 and batch: 100, loss is 3.9456139850616454 and perplexity is 51.708076354154606
At time: 721.6459939479828 and batch: 150, loss is 3.932326259613037 and perplexity is 51.025538363386595
At time: 722.8043975830078 and batch: 200, loss is 3.9348995304107666 and perplexity is 51.15700997467719
At time: 723.9628682136536 and batch: 250, loss is 3.940938882827759 and perplexity is 51.466900012182904
At time: 725.1208095550537 and batch: 300, loss is 3.9813931035995482 and perplexity is 53.59164095589556
At time: 726.2820041179657 and batch: 350, loss is 4.0043891382217405 and perplexity is 54.838315534525606
At time: 727.4412684440613 and batch: 400, loss is 3.9735968589782713 and perplexity is 53.17545187732553
At time: 728.600476026535 and batch: 450, loss is 3.9791349840164183 and perplexity is 53.47076115384998
At time: 729.7621006965637 and batch: 500, loss is 3.9790887880325316 and perplexity is 53.468291076483574
At time: 730.9234330654144 and batch: 550, loss is 3.93981472492218 and perplexity is 51.4090755976345
At time: 732.0818989276886 and batch: 600, loss is 3.899700937271118 and perplexity is 49.387676883307876
At time: 733.2406806945801 and batch: 650, loss is 3.940947480201721 and perplexity is 51.46734249427107
At time: 734.4013257026672 and batch: 700, loss is 3.9612896490097045 and perplexity is 52.52502112968983
At time: 735.6032853126526 and batch: 750, loss is 3.918457856178284 and perplexity is 50.322779944103104
At time: 736.7612075805664 and batch: 800, loss is 3.880352272987366 and perplexity is 48.44127661923399
At time: 737.9276571273804 and batch: 850, loss is 3.895465683937073 and perplexity is 49.17894987800071
At time: 739.0993106365204 and batch: 900, loss is 3.871512756347656 and perplexity is 48.01496611379638
At time: 740.2741239070892 and batch: 950, loss is 3.9780859470367433 and perplexity is 53.41469775949654
At time: 741.4442830085754 and batch: 1000, loss is 3.9418140029907227 and perplexity is 51.511959447443296
At time: 742.6006219387054 and batch: 1050, loss is 3.8733451795578 and perplexity is 48.103030513120544
At time: 743.7571477890015 and batch: 1100, loss is 3.9039059543609618 and perplexity is 49.59579016191869
At time: 744.9150636196136 and batch: 1150, loss is 3.858450231552124 and perplexity is 47.39184803621918
At time: 746.0748150348663 and batch: 1200, loss is 3.9137063789367676 and perplexity is 50.08423955885917
At time: 747.2407417297363 and batch: 1250, loss is 3.8712352991104124 and perplexity is 48.001645861937696
At time: 748.4138622283936 and batch: 1300, loss is 3.8717145109176636 and perplexity is 48.024654329926676
At time: 749.5895798206329 and batch: 1350, loss is 3.7517081928253173 and perplexity is 42.59377827921441
At time: 750.7667059898376 and batch: 1400, loss is 3.7920514965057373 and perplexity is 44.347285319805785
At time: 751.9428293704987 and batch: 1450, loss is 3.7190474033355714 and perplexity is 41.22510450096894
At time: 753.1202571392059 and batch: 1500, loss is 3.72900906085968 and perplexity is 41.63782716127464
At time: 754.2944986820221 and batch: 1550, loss is 3.7338985061645507 and perplexity is 41.841911562971724
At time: 755.4720783233643 and batch: 1600, loss is 3.827316222190857 and perplexity is 45.93908235444487
At time: 756.6511614322662 and batch: 1650, loss is 3.7444247341156007 and perplexity is 42.284675289717384
At time: 757.8241550922394 and batch: 1700, loss is 3.7635410976409913 and perplexity is 43.10078013995902
At time: 758.9960803985596 and batch: 1750, loss is 3.7533357095718385 and perplexity is 42.663156808706525
At time: 760.1748461723328 and batch: 1800, loss is 3.6885020875930787 and perplexity is 39.984908186917295
At time: 761.3505685329437 and batch: 1850, loss is 3.704340867996216 and perplexity is 40.62326239810521
At time: 762.5264751911163 and batch: 1900, loss is 3.7965107917785645 and perplexity is 44.545484545592714
At time: 763.7052459716797 and batch: 1950, loss is 3.730030574798584 and perplexity is 41.68038251384797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47605349518532 and perplexity of 87.8871403352077
finished 16 epochs...
Completing Train Step...
At time: 767.5511581897736 and batch: 50, loss is 3.9545974063873293 and perplexity is 52.17468452085437
At time: 768.7293214797974 and batch: 100, loss is 3.937570080757141 and perplexity is 51.2938099296652
At time: 769.9045922756195 and batch: 150, loss is 3.9239359951019286 and perplexity is 50.59921159785268
At time: 771.0801725387573 and batch: 200, loss is 3.926694560050964 and perplexity is 50.738985508484454
At time: 772.2595837116241 and batch: 250, loss is 3.9322700452804566 and perplexity is 51.022670077423086
At time: 773.4364919662476 and batch: 300, loss is 3.972525568008423 and perplexity is 53.11851599880328
At time: 774.6149175167084 and batch: 350, loss is 3.9961089754104613 and perplexity is 54.3861200632476
At time: 775.7924883365631 and batch: 400, loss is 3.9652662801742555 and perplexity is 52.734309621401906
At time: 776.9716749191284 and batch: 450, loss is 3.971172351837158 and perplexity is 53.04668377718363
At time: 778.1475007534027 and batch: 500, loss is 3.970700211524963 and perplexity is 53.021644210903624
At time: 779.3247683048248 and batch: 550, loss is 3.9311667251586915 and perplexity is 50.96640678278054
At time: 780.5094089508057 and batch: 600, loss is 3.891584029197693 and perplexity is 48.98842419082203
At time: 781.6886682510376 and batch: 650, loss is 3.932067828178406 and perplexity is 51.01235346407412
At time: 782.8667340278625 and batch: 700, loss is 3.95290225982666 and perplexity is 52.08631570404359
At time: 784.041345834732 and batch: 750, loss is 3.910181655883789 and perplexity is 49.908017234982864
At time: 785.2168207168579 and batch: 800, loss is 3.8717219734191897 and perplexity is 48.02501271532012
At time: 786.394314289093 and batch: 850, loss is 3.886865429878235 and perplexity is 48.7578119570237
At time: 787.5667831897736 and batch: 900, loss is 3.863429751396179 and perplexity is 47.62842521550184
At time: 788.7426855564117 and batch: 950, loss is 3.9708765029907225 and perplexity is 53.03099229824833
At time: 789.9199697971344 and batch: 1000, loss is 3.9352752065658567 and perplexity is 51.176232053902716
At time: 791.0942211151123 and batch: 1050, loss is 3.8668441820144652 and perplexity is 47.79132711921858
At time: 792.268886089325 and batch: 1100, loss is 3.897209224700928 and perplexity is 49.2647701756896
At time: 793.4970610141754 and batch: 1150, loss is 3.852365493774414 and perplexity is 47.1043566100955
At time: 794.6744275093079 and batch: 1200, loss is 3.9079227018356324 and perplexity is 49.795404558732216
At time: 795.8480484485626 and batch: 1250, loss is 3.8658360624313355 and perplexity is 47.743172023571766
At time: 797.0249376296997 and batch: 1300, loss is 3.866902527809143 and perplexity is 47.794115623526025
At time: 798.203807592392 and batch: 1350, loss is 3.747173089981079 and perplexity is 42.40104846927337
At time: 799.3790211677551 and batch: 1400, loss is 3.788715295791626 and perplexity is 44.19958039848414
At time: 800.5545148849487 and batch: 1450, loss is 3.716634225845337 and perplexity is 41.12574094592152
At time: 801.7321245670319 and batch: 1500, loss is 3.7277787160873412 and perplexity is 41.586629779968774
At time: 802.9074954986572 and batch: 1550, loss is 3.73331901550293 and perplexity is 41.817671590053926
At time: 804.0814225673676 and batch: 1600, loss is 3.826752338409424 and perplexity is 45.913185353107
At time: 805.2589435577393 and batch: 1650, loss is 3.7437053871154786 and perplexity is 42.25426887309006
At time: 806.4348721504211 and batch: 1700, loss is 3.7631440210342406 and perplexity is 43.08366922582942
At time: 807.6098136901855 and batch: 1750, loss is 3.753571982383728 and perplexity is 42.67323814365559
At time: 808.7857661247253 and batch: 1800, loss is 3.6891229009628295 and perplexity is 40.009739059379285
At time: 809.9613671302795 and batch: 1850, loss is 3.7048190021514893 and perplexity is 40.64269041158466
At time: 811.1380774974823 and batch: 1900, loss is 3.796125121116638 and perplexity is 44.52830797154543
At time: 812.3133676052094 and batch: 1950, loss is 3.7291904735565184 and perplexity is 41.64538147699414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475648392078488 and perplexity of 87.85154419214827
finished 17 epochs...
Completing Train Step...
At time: 816.1794800758362 and batch: 50, loss is 3.9481949472427367 and perplexity is 51.841705315149696
At time: 817.353756904602 and batch: 100, loss is 3.930286693572998 and perplexity is 50.921574464823706
At time: 818.5292148590088 and batch: 150, loss is 3.9168476963043215 and perplexity is 50.24181742188521
At time: 819.7022397518158 and batch: 200, loss is 3.92014591217041 and perplexity is 50.407799352900625
At time: 820.8760793209076 and batch: 250, loss is 3.925722360610962 and perplexity is 50.68968106594597
At time: 822.0493636131287 and batch: 300, loss is 3.9659556007385253 and perplexity is 52.770672997037934
At time: 823.254227399826 and batch: 350, loss is 3.9894918107986452 and perplexity is 54.02742623109638
At time: 824.4309463500977 and batch: 400, loss is 3.9584804439544676 and perplexity is 52.377674634965175
At time: 825.6054239273071 and batch: 450, loss is 3.9648449993133545 and perplexity is 52.71209834496691
At time: 826.7781474590302 and batch: 500, loss is 3.964299354553223 and perplexity is 52.6833441102216
At time: 827.9528639316559 and batch: 550, loss is 3.924433751106262 and perplexity is 50.62440392853684
At time: 829.1270678043365 and batch: 600, loss is 3.8851187086105345 and perplexity is 48.672719987523124
At time: 830.3015983104706 and batch: 650, loss is 3.925354037284851 and perplexity is 50.67101431192776
At time: 831.4777097702026 and batch: 700, loss is 3.9465178537368772 and perplexity is 51.75483479318841
At time: 832.6561126708984 and batch: 750, loss is 3.903866181373596 and perplexity is 49.59381762841022
At time: 833.8313548564911 and batch: 800, loss is 3.8651775121688843 and perplexity is 47.71174109566424
At time: 835.0047988891602 and batch: 850, loss is 3.880343542098999 and perplexity is 48.44085368570177
At time: 836.1802687644958 and batch: 900, loss is 3.857264070510864 and perplexity is 47.335666998871304
At time: 837.3570330142975 and batch: 950, loss is 3.965447716712952 and perplexity is 52.74387842004875
At time: 838.5323383808136 and batch: 1000, loss is 3.9303227281570434 and perplexity is 50.92340943563949
At time: 839.7096555233002 and batch: 1050, loss is 3.8618310832977296 and perplexity is 47.55234400203851
At time: 840.8860988616943 and batch: 1100, loss is 3.8917017221450805 and perplexity is 48.99419012215098
At time: 842.0592234134674 and batch: 1150, loss is 3.8471239805221558 and perplexity is 46.85810443149639
At time: 843.2337863445282 and batch: 1200, loss is 3.90298113822937 and perplexity is 49.54994437784586
At time: 844.4109408855438 and batch: 1250, loss is 3.861263060569763 and perplexity is 47.525340859802576
At time: 845.5866837501526 and batch: 1300, loss is 3.8626182794570925 and perplexity is 47.589791762038246
At time: 846.7607173919678 and batch: 1350, loss is 3.7429303455352785 and perplexity is 42.221532745341236
At time: 847.9366285800934 and batch: 1400, loss is 3.7854071617126466 and perplexity is 44.05360384841888
At time: 849.1174771785736 and batch: 1450, loss is 3.7140543365478518 and perplexity is 41.01977783232802
At time: 850.2946045398712 and batch: 1500, loss is 3.726092667579651 and perplexity is 41.5165717820763
At time: 851.4688789844513 and batch: 1550, loss is 3.7320799160003664 and perplexity is 41.76588742348149
At time: 852.6451508998871 and batch: 1600, loss is 3.825539255142212 and perplexity is 45.857522604810995
At time: 853.8227701187134 and batch: 1650, loss is 3.7425575160980227 and perplexity is 42.20579424911736
At time: 855.0012106895447 and batch: 1700, loss is 3.7623652410507202 and perplexity is 43.05012958831405
At time: 856.173816204071 and batch: 1750, loss is 3.753331127166748 and perplexity is 42.66296130928752
At time: 857.3540115356445 and batch: 1800, loss is 3.6891021871566774 and perplexity is 40.00891031398348
At time: 858.5284333229065 and batch: 1850, loss is 3.704760317802429 and perplexity is 40.64030539173615
At time: 859.6995403766632 and batch: 1900, loss is 3.7953065156936647 and perplexity is 44.49187177263381
At time: 860.8781282901764 and batch: 1950, loss is 3.7279771041870116 and perplexity is 41.59488089085656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47544058866279 and perplexity of 87.8332902378735
finished 18 epochs...
Completing Train Step...
At time: 864.7047445774078 and batch: 50, loss is 3.942143077850342 and perplexity is 51.52891352769497
At time: 865.907793045044 and batch: 100, loss is 3.923544850349426 and perplexity is 50.57942385194419
At time: 867.083770275116 and batch: 150, loss is 3.910353546142578 and perplexity is 49.91659667432093
At time: 868.2572660446167 and batch: 200, loss is 3.9141764402389527 and perplexity is 50.107787755839624
At time: 869.4325976371765 and batch: 250, loss is 3.9198334503173826 and perplexity is 50.392051298968966
At time: 870.6086578369141 and batch: 300, loss is 3.9602871704101563 and perplexity is 52.47239230410969
At time: 871.7805669307709 and batch: 350, loss is 3.9836761713027955 and perplexity is 53.71413407736384
At time: 872.9605917930603 and batch: 400, loss is 3.9525700855255126 and perplexity is 52.069016841803055
At time: 874.1305778026581 and batch: 450, loss is 3.9592953062057497 and perplexity is 52.420372618960194
At time: 875.30881690979 and batch: 500, loss is 3.9586981439590456 and perplexity is 52.38907849623828
At time: 876.4828727245331 and batch: 550, loss is 3.9184160614013672 and perplexity is 50.320676758692905
At time: 877.659937620163 and batch: 600, loss is 3.879098596572876 and perplexity is 48.38058498503296
At time: 878.8350191116333 and batch: 650, loss is 3.9193083333969114 and perplexity is 50.3655965267068
At time: 880.0069336891174 and batch: 700, loss is 3.940857787132263 and perplexity is 51.46272643736317
At time: 881.1795077323914 and batch: 750, loss is 3.8984216976165773 and perplexity is 49.32453860170011
At time: 882.4006769657135 and batch: 800, loss is 3.8595859146118165 and perplexity is 47.44570072920885
At time: 883.5736041069031 and batch: 850, loss is 3.8747943592071534 and perplexity is 48.17279098152916
At time: 884.7481026649475 and batch: 900, loss is 3.8519364833831786 and perplexity is 47.084152685793924
At time: 885.9239583015442 and batch: 950, loss is 3.960698962211609 and perplexity is 52.494004454610916
At time: 887.0983600616455 and batch: 1000, loss is 3.9259285354614257 and perplexity is 50.700133080794075
At time: 888.2708604335785 and batch: 1050, loss is 3.8573337984085083 and perplexity is 47.33896773048993
At time: 889.4451172351837 and batch: 1100, loss is 3.8867109394073487 and perplexity is 48.750279921523905
At time: 890.619877576828 and batch: 1150, loss is 3.842292141914368 and perplexity is 46.63223974370791
At time: 891.7931685447693 and batch: 1200, loss is 3.898504114151001 and perplexity is 49.328603926756415
At time: 892.9696311950684 and batch: 1250, loss is 3.8571896505355836 and perplexity is 47.33214441078045
At time: 894.1426775455475 and batch: 1300, loss is 3.858684139251709 and perplexity is 47.40293465094414
At time: 895.31716132164 and batch: 1350, loss is 3.73889048576355 and perplexity is 42.05130774777507
At time: 896.4900593757629 and batch: 1400, loss is 3.7820969581604005 and perplexity is 43.9080185439036
At time: 897.6632866859436 and batch: 1450, loss is 3.711249756813049 and perplexity is 40.90489576795019
At time: 898.8371684551239 and batch: 1500, loss is 3.7239814376831055 and perplexity is 41.4290132151828
At time: 900.0103034973145 and batch: 1550, loss is 3.7302939319610595 and perplexity is 41.69136078665764
At time: 901.183221578598 and batch: 1600, loss is 3.8238099718093874 and perplexity is 45.77829048242499
At time: 902.3568201065063 and batch: 1650, loss is 3.7410324478149413 and perplexity is 42.14147658782443
At time: 903.5308923721313 and batch: 1700, loss is 3.7612944889068602 and perplexity is 43.00405823966335
At time: 904.705296754837 and batch: 1750, loss is 3.7528319787979125 and perplexity is 42.641671475575215
At time: 905.8788945674896 and batch: 1800, loss is 3.6888628435134887 and perplexity is 39.999335581500304
At time: 907.0538582801819 and batch: 1850, loss is 3.7045970153808594 and perplexity is 40.6336692733142
At time: 908.2272486686707 and batch: 1900, loss is 3.794503026008606 and perplexity is 44.456137370629754
At time: 909.3976762294769 and batch: 1950, loss is 3.7268160676956175 and perplexity is 41.5466157405093
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4752980786700585 and perplexity of 87.82077400818517
finished 19 epochs...
Completing Train Step...
At time: 913.2341709136963 and batch: 50, loss is 3.9364987134933473 and perplexity is 51.23888484859192
At time: 914.4368462562561 and batch: 100, loss is 3.91723406791687 and perplexity is 50.261233184508086
At time: 915.6131265163422 and batch: 150, loss is 3.904254789352417 and perplexity is 49.613093926859925
At time: 916.7868134975433 and batch: 200, loss is 3.9085286617279054 and perplexity is 49.82558772068352
At time: 917.9638779163361 and batch: 250, loss is 3.914285545349121 and perplexity is 50.11325506979354
At time: 919.1405107975006 and batch: 300, loss is 3.955048851966858 and perplexity is 52.19824386902629
At time: 920.3129167556763 and batch: 350, loss is 3.978289680480957 and perplexity is 53.42558122846839
At time: 921.4919877052307 and batch: 400, loss is 3.9471758604049683 and perplexity is 51.78890102626339
At time: 922.6678833961487 and batch: 450, loss is 3.9541718912124635 and perplexity is 52.152488123633745
At time: 923.8418045043945 and batch: 500, loss is 3.953505334854126 and perplexity is 52.11773713410498
At time: 925.021555185318 and batch: 550, loss is 3.9127215433120726 and perplexity is 50.03493909591666
At time: 926.1974141597748 and batch: 600, loss is 3.873252239227295 and perplexity is 48.09856000931461
At time: 927.3706276416779 and batch: 650, loss is 3.91357741355896 and perplexity is 50.0777808424666
At time: 928.5478479862213 and batch: 700, loss is 3.9355748319625854 and perplexity is 51.19156805014719
At time: 929.7211966514587 and batch: 750, loss is 3.8934863901138304 and perplexity is 49.081706554575064
At time: 930.8981120586395 and batch: 800, loss is 3.8545724678039552 and perplexity is 47.20842950265514
At time: 932.071014881134 and batch: 850, loss is 3.8698309230804444 and perplexity is 47.93428081509055
At time: 933.2450897693634 and batch: 900, loss is 3.847087273597717 and perplexity is 46.85638444616556
At time: 934.4245488643646 and batch: 950, loss is 3.9562780904769896 and perplexity is 52.262447413201386
At time: 935.5974209308624 and batch: 1000, loss is 3.921868853569031 and perplexity is 50.494723898665185
At time: 936.7726271152496 and batch: 1050, loss is 3.853178815841675 and perplexity is 47.14268320661124
At time: 937.9494497776031 and batch: 1100, loss is 3.882078366279602 and perplexity is 48.524962986334344
At time: 939.1240065097809 and batch: 1150, loss is 3.8377821254730224 and perplexity is 46.42240111927084
At time: 940.2991361618042 and batch: 1200, loss is 3.8944105339050292 and perplexity is 49.12708607431996
At time: 941.524781703949 and batch: 1250, loss is 3.853479766845703 and perplexity is 47.15687297956096
At time: 942.6988441944122 and batch: 1300, loss is 3.855046634674072 and perplexity is 47.23081948378969
At time: 943.8739714622498 and batch: 1350, loss is 3.735030212402344 and perplexity is 41.88929112010209
At time: 945.0494930744171 and batch: 1400, loss is 3.778829002380371 and perplexity is 43.764763284331785
At time: 946.2262210845947 and batch: 1450, loss is 3.7082937383651733 and perplexity is 40.78415867989867
At time: 947.40296626091 and batch: 1500, loss is 3.721557388305664 and perplexity is 41.32870886195882
At time: 948.57715010643 and batch: 1550, loss is 3.728089542388916 and perplexity is 41.59955800741073
At time: 949.7533559799194 and batch: 1600, loss is 3.821685290336609 and perplexity is 45.68112945145364
At time: 950.9278886318207 and batch: 1650, loss is 3.739223608970642 and perplexity is 42.06531834777286
At time: 952.1047704219818 and batch: 1700, loss is 3.7599788093566895 and perplexity is 42.947515883630146
At time: 953.2804095745087 and batch: 1750, loss is 3.752127604484558 and perplexity is 42.611646353213196
At time: 954.4539682865143 and batch: 1800, loss is 3.6885080623626707 and perplexity is 39.98514708824455
At time: 955.6308965682983 and batch: 1850, loss is 3.704418625831604 and perplexity is 40.626421297868696
At time: 956.8061163425446 and batch: 1900, loss is 3.79383101940155 and perplexity is 44.426272588381885
At time: 957.9817552566528 and batch: 1950, loss is 3.725880479812622 and perplexity is 41.50776340796283
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475178563317587 and perplexity of 87.8102787046127
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f6867fdeb38>
ELAPSED
5912.761422395706


RESULTS SO FAR:
[{'best_accuracy': -78.24843512754734, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}}, {'best_accuracy': -80.22026219008522, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.862353544247577, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.936075502546612}}, {'best_accuracy': -78.14425651975347, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.3679014798345962, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.3008932223994304}}, {'best_accuracy': -81.13334485419696, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.12560107942970977, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.9438108012791336}}, {'best_accuracy': -77.79700870491497, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.8553086698259572, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.5482996063691655}}, {'best_accuracy': -87.8102787046127, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 1.0, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.13646949770690217}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -78.24843512754734, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.5382739547561661, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.41301920006531956}}, {'best_accuracy': -80.22026219008522, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.862353544247577, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.936075502546612}}, {'best_accuracy': -78.14425651975347, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.3679014798345962, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.3008932223994304}}, {'best_accuracy': -81.13334485419696, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.12560107942970977, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.9438108012791336}}, {'best_accuracy': -77.79700870491497, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 0.8553086698259572, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.5482996063691655}}, {'best_accuracy': -87.8102787046127, 'params': {'batch_size': 32, 'seq_len': 35, 'tie_weights': 'FALSE', 'rnn_dropout': 1.0, 'num_layers': 2, 'data': 'wikitext', 'wordvec_dim': 300, 'tune_wordvecs': 'FALSE', 'wordvec_source': 'None', 'dropout': 0.13646949770690217}}]
