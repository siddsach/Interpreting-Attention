TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6873881816864014 and batch: 50, loss is 7.181902093887329 and perplexity is 1315.4079095503912
At time: 2.717395544052124 and batch: 100, loss is 6.406095733642578 and perplexity is 605.5249293414058
At time: 3.7473864555358887 and batch: 150, loss is 6.171624908447265 and perplexity is 478.9637463584293
At time: 4.778686761856079 and batch: 200, loss is 6.0402374172210695 and perplexity is 419.9927365591427
At time: 5.8061723709106445 and batch: 250, loss is 5.96741660118103 and perplexity is 390.4955607826864
At time: 6.832658767700195 and batch: 300, loss is 5.901971817016602 and perplexity is 365.7579650670393
At time: 7.861169338226318 and batch: 350, loss is 5.849404582977295 and perplexity is 347.02769275652935
At time: 8.890758037567139 and batch: 400, loss is 5.7991581153869625 and perplexity is 330.0216028127864
At time: 9.92332935333252 and batch: 450, loss is 5.734031896591187 and perplexity is 309.21347519187435
At time: 10.955360889434814 and batch: 500, loss is 5.707747898101807 and perplexity is 301.19198884197186
At time: 11.990618228912354 and batch: 550, loss is 5.650197219848633 and perplexity is 284.3475392729951
At time: 13.023102283477783 and batch: 600, loss is 5.686866960525513 and perplexity is 294.96802496779054
At time: 14.059457302093506 and batch: 650, loss is 5.769547414779663 and perplexity is 320.39269483046183
At time: 15.095536947250366 and batch: 700, loss is 5.675787401199341 and perplexity is 291.7179471978855
At time: 16.132030963897705 and batch: 750, loss is 5.631150312423706 and perplexity is 278.9828505651412
At time: 17.168603897094727 and batch: 800, loss is 5.624936599731445 and perplexity is 277.25470594308155
At time: 18.204336881637573 and batch: 850, loss is 5.63341197013855 and perplexity is 279.6145283316201
At time: 19.239190101623535 and batch: 900, loss is 5.649245977401733 and perplexity is 284.0771844308541
At time: 20.27631974220276 and batch: 950, loss is 5.680775489807129 and perplexity is 293.176697329849
At time: 21.315330505371094 and batch: 1000, loss is 5.646924934387207 and perplexity is 283.4185936707517
At time: 22.352259159088135 and batch: 1050, loss is 5.553384304046631 and perplexity is 258.10960080738545
At time: 23.389251470565796 and batch: 1100, loss is 5.644324131011963 and perplexity is 282.68243535220455
At time: 24.428398370742798 and batch: 1150, loss is 5.5478502464294435 and perplexity is 256.68515252979165
At time: 25.4680073261261 and batch: 1200, loss is 5.620763130187989 and perplexity is 276.100003106644
At time: 26.506839990615845 and batch: 1250, loss is 5.555910453796387 and perplexity is 258.76244855929195
At time: 27.545950412750244 and batch: 1300, loss is 5.580181818008423 and perplexity is 265.11980495928657
At time: 28.58417558670044 and batch: 1350, loss is 5.5471373462677 and perplexity is 256.502226854655
At time: 29.623870849609375 and batch: 1400, loss is 5.559781503677368 and perplexity is 259.7660721902815
At time: 30.663310050964355 and batch: 1450, loss is 5.514335689544677 and perplexity is 248.22502398474663
At time: 31.703901767730713 and batch: 1500, loss is 5.502305412292481 and perplexity is 245.25669881246355
At time: 32.74348521232605 and batch: 1550, loss is 5.492084541320801 and perplexity is 242.7627287234657
At time: 33.781219244003296 and batch: 1600, loss is 5.521339769363403 and perplexity is 249.96971470983502
At time: 34.81904458999634 and batch: 1650, loss is 5.497654275894165 and perplexity is 244.11862517321802
At time: 35.856889724731445 and batch: 1700, loss is 5.5135163402557374 and perplexity is 248.02172428595296
At time: 36.89477801322937 and batch: 1750, loss is 5.530786371231079 and perplexity is 252.34226772201225
At time: 37.93492889404297 and batch: 1800, loss is 5.521348314285278 and perplexity is 249.9718506906442
At time: 38.97761678695679 and batch: 1850, loss is 5.495207138061524 and perplexity is 243.52196360421178
At time: 40.01774525642395 and batch: 1900, loss is 5.500554637908936 and perplexity is 244.82768532928284
At time: 41.05786418914795 and batch: 1950, loss is 5.437179450988769 and perplexity is 229.7931257677513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.997957167514535 and perplexity of 148.11028534539497
finished 1 epochs...
Completing Train Step...
At time: 44.389954805374146 and batch: 50, loss is 5.231904554367065 and perplexity is 187.14889956434706
At time: 45.425119400024414 and batch: 100, loss is 5.16181715965271 and perplexity is 174.48122795256998
At time: 46.463183879852295 and batch: 150, loss is 5.091319732666015 and perplexity is 162.60431473805153
At time: 47.4993896484375 and batch: 200, loss is 5.064565954208374 and perplexity is 158.31171262626634
At time: 48.53528952598572 and batch: 250, loss is 5.07320990562439 and perplexity is 159.686082815874
At time: 49.599759578704834 and batch: 300, loss is 5.093567695617676 and perplexity is 162.97025436862748
At time: 50.63869333267212 and batch: 350, loss is 5.076146926879883 and perplexity is 160.15577364364987
At time: 51.67549252510071 and batch: 400, loss is 5.049198961257934 and perplexity is 155.89753449127213
At time: 52.71424317359924 and batch: 450, loss is 5.0216081428527835 and perplexity is 151.65499068923216
At time: 53.754366874694824 and batch: 500, loss is 5.0083726978302 and perplexity is 149.66099422132007
At time: 54.79146146774292 and batch: 550, loss is 4.966816492080689 and perplexity is 143.5691056967971
At time: 55.82955813407898 and batch: 600, loss is 4.963043851852417 and perplexity is 143.0284915256982
At time: 56.8662805557251 and batch: 650, loss is 5.036550874710083 and perplexity is 153.9381463586464
At time: 57.905494928359985 and batch: 700, loss is 5.018671865463257 and perplexity is 151.21034269346
At time: 58.944440603256226 and batch: 750, loss is 4.97281735420227 and perplexity is 144.43323427008494
At time: 59.9816780090332 and batch: 800, loss is 4.948747043609619 and perplexity is 140.9981886172698
At time: 61.02005934715271 and batch: 850, loss is 4.952358980178833 and perplexity is 141.50838597650596
At time: 62.05497336387634 and batch: 900, loss is 4.968509511947632 and perplexity is 143.81237691841898
At time: 63.091859340667725 and batch: 950, loss is 5.030278224945068 and perplexity is 152.975568394425
At time: 64.13060998916626 and batch: 1000, loss is 4.998972940444946 and perplexity is 148.2608081995422
At time: 65.16944479942322 and batch: 1050, loss is 4.9201598072052 and perplexity is 137.0245089406905
At time: 66.20825409889221 and batch: 1100, loss is 4.993571443557739 and perplexity is 147.46213685778733
At time: 67.24701237678528 and batch: 1150, loss is 4.913860321044922 and perplexity is 136.1640380507722
At time: 68.28576016426086 and batch: 1200, loss is 4.991285085678101 and perplexity is 147.1253707698354
At time: 69.32264041900635 and batch: 1250, loss is 4.94299506187439 and perplexity is 140.18949762918632
At time: 70.36004090309143 and batch: 1300, loss is 4.968440093994141 and perplexity is 143.80239410402385
At time: 71.39734482765198 and batch: 1350, loss is 4.884760189056396 and perplexity is 132.2587444366344
At time: 72.4354395866394 and batch: 1400, loss is 4.89339991569519 and perplexity is 133.40637429959105
At time: 73.4731912612915 and batch: 1450, loss is 4.82927152633667 and perplexity is 125.11978098259505
At time: 74.51273536682129 and batch: 1500, loss is 4.816152601242066 and perplexity is 123.48906396321973
At time: 75.55195808410645 and batch: 1550, loss is 4.816049194335937 and perplexity is 123.4762950013854
At time: 76.58964896202087 and batch: 1600, loss is 4.888489866256714 and perplexity is 132.7529478971075
At time: 77.62798404693604 and batch: 1650, loss is 4.856311645507812 and perplexity is 128.54919165390626
At time: 78.66587424278259 and batch: 1700, loss is 4.874609689712525 and perplexity is 130.92304262656936
At time: 79.7051465511322 and batch: 1750, loss is 4.884236993789673 and perplexity is 132.18956538621632
At time: 80.74584126472473 and batch: 1800, loss is 4.846637830734253 and perplexity is 127.31162622513003
At time: 81.78454279899597 and batch: 1850, loss is 4.860386123657227 and perplexity is 129.07403102360928
At time: 82.82190108299255 and batch: 1900, loss is 4.925167827606201 and perplexity is 137.71245165466073
At time: 83.8595564365387 and batch: 1950, loss is 4.8495988845825195 and perplexity is 127.68916148115699
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.7262317746184594 and perplexity of 112.8694424970467
finished 2 epochs...
Completing Train Step...
At time: 87.16337323188782 and batch: 50, loss is 4.775779695510864 and perplexity is 118.60275261308504
At time: 88.23227190971375 and batch: 100, loss is 4.731648960113525 and perplexity is 113.48253632596139
At time: 89.27615857124329 and batch: 150, loss is 4.682361145019531 and perplexity is 108.02483398747327
At time: 90.31723761558533 and batch: 200, loss is 4.662476749420166 and perplexity is 105.89804053060432
At time: 91.35875797271729 and batch: 250, loss is 4.677371730804444 and perplexity is 107.48719571056596
At time: 92.40149641036987 and batch: 300, loss is 4.703155021667481 and perplexity is 110.29460595540291
At time: 93.44604349136353 and batch: 350, loss is 4.700939626693725 and perplexity is 110.05053030155176
At time: 94.48833346366882 and batch: 400, loss is 4.6749567031860355 and perplexity is 107.22792436404457
At time: 95.5301353931427 and batch: 450, loss is 4.676985120773315 and perplexity is 107.44564811436261
At time: 96.57168674468994 and batch: 500, loss is 4.6733833694458005 and perplexity is 107.05935169805223
At time: 97.61340713500977 and batch: 550, loss is 4.6434702301025395 and perplexity is 103.90429448327464
At time: 98.6548228263855 and batch: 600, loss is 4.623016319274902 and perplexity is 101.80063270509943
At time: 99.69708609580994 and batch: 650, loss is 4.684988536834717 and perplexity is 108.30903073674665
At time: 100.74036002159119 and batch: 700, loss is 4.694665603637695 and perplexity is 109.36223219401884
At time: 101.81735897064209 and batch: 750, loss is 4.655272130966186 and perplexity is 105.13782736479155
At time: 102.86015510559082 and batch: 800, loss is 4.626223726272583 and perplexity is 102.12767296204267
At time: 103.90146017074585 and batch: 850, loss is 4.639278697967529 and perplexity is 103.46968776429492
At time: 104.94253540039062 and batch: 900, loss is 4.6385733509063725 and perplexity is 103.39673145689483
At time: 105.9833505153656 and batch: 950, loss is 4.71346375465393 and perplexity is 111.43748429072039
At time: 107.02555871009827 and batch: 1000, loss is 4.68415638923645 and perplexity is 108.21893912690564
At time: 108.06866216659546 and batch: 1050, loss is 4.624303531646729 and perplexity is 101.93175611270841
At time: 109.11197924613953 and batch: 1100, loss is 4.689644680023194 and perplexity is 108.81450896875911
At time: 110.1548080444336 and batch: 1150, loss is 4.6169328689575195 and perplexity is 101.1832135373144
At time: 111.19636678695679 and batch: 1200, loss is 4.697017450332641 and perplexity is 109.61973808685511
At time: 112.23918151855469 and batch: 1250, loss is 4.660259685516357 and perplexity is 105.66351787937604
At time: 113.28768157958984 and batch: 1300, loss is 4.675848512649536 and perplexity is 107.32359389489977
At time: 114.33060812950134 and batch: 1350, loss is 4.581564865112305 and perplexity is 97.6671105395622
At time: 115.37333083152771 and batch: 1400, loss is 4.599555282592774 and perplexity is 99.44008307124793
At time: 116.41615605354309 and batch: 1450, loss is 4.524560241699219 and perplexity is 92.25534685227124
At time: 117.45843148231506 and batch: 1500, loss is 4.524618434906006 and perplexity is 92.26071564295985
At time: 118.50004196166992 and batch: 1550, loss is 4.527539806365967 and perplexity is 92.5306375436146
At time: 119.54252767562866 and batch: 1600, loss is 4.6220590686798095 and perplexity is 101.70323061540351
At time: 120.58457231521606 and batch: 1650, loss is 4.56965892791748 and perplexity is 96.51118688712717
At time: 121.62768125534058 and batch: 1700, loss is 4.599213857650756 and perplexity is 99.40613754190608
At time: 122.67117691040039 and batch: 1750, loss is 4.608503465652466 and perplexity is 100.33388412187233
At time: 123.71409201622009 and batch: 1800, loss is 4.563891773223877 and perplexity is 95.95619384630423
At time: 124.75514364242554 and batch: 1850, loss is 4.594754934310913 and perplexity is 98.9638799242504
At time: 125.79612493515015 and batch: 1900, loss is 4.667830724716186 and perplexity is 106.46653652225314
At time: 126.83733248710632 and batch: 1950, loss is 4.6040449047088625 and perplexity is 99.88753516123339
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6536164039789245 and perplexity of 104.96389186123126
finished 3 epochs...
Completing Train Step...
At time: 130.1577546596527 and batch: 50, loss is 4.538248748779297 and perplexity is 93.52686757682558
At time: 131.1969084739685 and batch: 100, loss is 4.5003942775726316 and perplexity is 90.05263003426366
At time: 132.23337697982788 and batch: 150, loss is 4.4560866546630855 and perplexity is 86.14971498949146
At time: 133.2703881263733 and batch: 200, loss is 4.442546195983887 and perplexity is 84.99107032603975
At time: 134.30742168426514 and batch: 250, loss is 4.450645551681519 and perplexity is 85.68223846568118
At time: 135.3456835746765 and batch: 300, loss is 4.477287178039551 and perplexity is 87.99563210180264
At time: 136.38489365577698 and batch: 350, loss is 4.479360647201538 and perplexity is 88.17827762084407
At time: 137.42317724227905 and batch: 400, loss is 4.456447067260743 and perplexity is 86.18077002803562
At time: 138.45982956886292 and batch: 450, loss is 4.467305727005005 and perplexity is 87.12167693503083
At time: 139.495774269104 and batch: 500, loss is 4.4752195358276365 and perplexity is 87.81387658584599
At time: 140.53332805633545 and batch: 550, loss is 4.445172758102417 and perplexity is 85.2145980780277
At time: 141.56994438171387 and batch: 600, loss is 4.424731931686401 and perplexity is 83.49042308501828
At time: 142.60773754119873 and batch: 650, loss is 4.47992130279541 and perplexity is 88.22772912678653
At time: 143.644864320755 and batch: 700, loss is 4.49698920249939 and perplexity is 89.74651553564976
At time: 144.68216133117676 and batch: 750, loss is 4.463271284103394 and perplexity is 86.77089757937948
At time: 145.71843957901 and batch: 800, loss is 4.428779811859131 and perplexity is 83.82906724633033
At time: 146.75475931167603 and batch: 850, loss is 4.441580553054809 and perplexity is 84.909038912846
At time: 147.79221892356873 and batch: 900, loss is 4.435808048248291 and perplexity is 84.42031302098663
At time: 148.82843041419983 and batch: 950, loss is 4.519202003479004 and perplexity is 91.76234272307335
At time: 149.86716651916504 and batch: 1000, loss is 4.493470010757446 and perplexity is 89.43123543026776
At time: 150.90483283996582 and batch: 1050, loss is 4.437543096542359 and perplexity is 84.56691348374265
At time: 151.94292783737183 and batch: 1100, loss is 4.4876248645782475 and perplexity is 88.91002155580533
At time: 152.98049998283386 and batch: 1150, loss is 4.426162166595459 and perplexity is 83.60991943624312
At time: 154.0628604888916 and batch: 1200, loss is 4.504398584365845 and perplexity is 90.41395133031715
At time: 155.10090398788452 and batch: 1250, loss is 4.475277280807495 and perplexity is 87.81894754279045
At time: 156.14036870002747 and batch: 1300, loss is 4.4911754608154295 and perplexity is 89.22626624014796
At time: 157.1803708076477 and batch: 1350, loss is 4.388351058959961 and perplexity is 80.5075572548145
At time: 158.2187647819519 and batch: 1400, loss is 4.409074296951294 and perplexity is 82.1933416495728
At time: 159.25796818733215 and batch: 1450, loss is 4.331363849639892 and perplexity is 76.0479338206438
At time: 160.29517149925232 and batch: 1500, loss is 4.336446781158447 and perplexity is 76.43546432152134
At time: 161.33385562896729 and batch: 1550, loss is 4.340691480636597 and perplexity is 76.76059945933795
At time: 162.3732569217682 and batch: 1600, loss is 4.445277757644654 and perplexity is 85.22354604157562
At time: 163.41296219825745 and batch: 1650, loss is 4.3837626886367795 and perplexity is 80.13900494216013
At time: 164.45209670066833 and batch: 1700, loss is 4.419529180526734 and perplexity is 83.05717121761309
At time: 165.4909508228302 and batch: 1750, loss is 4.425988349914551 and perplexity is 83.59538790050397
At time: 166.53103804588318 and batch: 1800, loss is 4.377873725891114 and perplexity is 79.66845620943994
At time: 167.56880593299866 and batch: 1850, loss is 4.417423458099365 and perplexity is 82.8824598807733
At time: 168.60735273361206 and batch: 1900, loss is 4.495806999206543 and perplexity is 89.64047959982796
At time: 169.64605069160461 and batch: 1950, loss is 4.429641618728637 and perplexity is 83.90134285168082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.61861941315407 and perplexity of 101.35400748417972
finished 4 epochs...
Completing Train Step...
At time: 172.92707657814026 and batch: 50, loss is 4.370323987007141 and perplexity is 79.0692449581898
At time: 173.99151849746704 and batch: 100, loss is 4.33968602180481 and perplexity is 76.6834586241441
At time: 175.03090572357178 and batch: 150, loss is 4.296606388092041 and perplexity is 73.45010910801079
At time: 176.0693337917328 and batch: 200, loss is 4.286053743362427 and perplexity is 72.67909149364652
At time: 177.10926246643066 and batch: 250, loss is 4.288771047592163 and perplexity is 72.8768512614184
At time: 178.14937949180603 and batch: 300, loss is 4.317509679794312 and perplexity is 75.0016174867916
At time: 179.1904149055481 and batch: 350, loss is 4.317705020904541 and perplexity is 75.01626981707513
At time: 180.25889444351196 and batch: 400, loss is 4.293420581817627 and perplexity is 73.21648362991087
At time: 181.29506087303162 and batch: 450, loss is 4.311569175720215 and perplexity is 74.55739084401858
At time: 182.33655619621277 and batch: 500, loss is 4.333419981002808 and perplexity is 76.20445922570971
At time: 183.3750216960907 and batch: 550, loss is 4.2954858303070065 and perplexity is 73.36785011302416
At time: 184.41754841804504 and batch: 600, loss is 4.283216586112976 and perplexity is 72.47318171965775
At time: 185.4589021205902 and batch: 650, loss is 4.329251871109009 and perplexity is 75.88749170188876
At time: 186.49876499176025 and batch: 700, loss is 4.352490358352661 and perplexity is 77.67165251837157
At time: 187.53849983215332 and batch: 750, loss is 4.3162868690490725 and perplexity is 74.90996075385831
At time: 188.5770502090454 and batch: 800, loss is 4.283517713546753 and perplexity is 72.49500866906831
At time: 189.61776447296143 and batch: 850, loss is 4.292144651412964 and perplexity is 73.12312406514434
At time: 190.6592869758606 and batch: 900, loss is 4.28571741104126 and perplexity is 72.65465127635206
At time: 191.6975531578064 and batch: 950, loss is 4.373966636657715 and perplexity is 79.35779173405602
At time: 192.73787450790405 and batch: 1000, loss is 4.345163011550904 and perplexity is 77.10460539622395
At time: 193.7766604423523 and batch: 1050, loss is 4.293415813446045 and perplexity is 73.21613450734337
At time: 194.81655168533325 and batch: 1100, loss is 4.343528299331665 and perplexity is 76.97866452221182
At time: 195.8559274673462 and batch: 1150, loss is 4.287790446281433 and perplexity is 72.80542315252187
At time: 196.89467549324036 and batch: 1200, loss is 4.359585385322571 and perplexity is 78.2246945920187
At time: 197.93573880195618 and batch: 1250, loss is 4.337478752136231 and perplexity is 76.51438421689146
At time: 198.97627782821655 and batch: 1300, loss is 4.34608606338501 and perplexity is 77.17580980127563
At time: 200.01599884033203 and batch: 1350, loss is 4.2453617811203 and perplexity is 69.78100102651749
At time: 201.0572600364685 and batch: 1400, loss is 4.267844200134277 and perplexity is 71.36761536482733
At time: 202.09731674194336 and batch: 1450, loss is 4.1860114145278935 and perplexity is 65.75997789017448
At time: 203.1365749835968 and batch: 1500, loss is 4.195414142608643 and perplexity is 66.38121717586935
At time: 204.17894077301025 and batch: 1550, loss is 4.1968187856674195 and perplexity is 66.47452460828576
At time: 205.22069692611694 and batch: 1600, loss is 4.305368728637696 and perplexity is 74.09653192963182
At time: 206.26145243644714 and batch: 1650, loss is 4.246369361877441 and perplexity is 69.85134645376397
At time: 207.30338859558105 and batch: 1700, loss is 4.278987264633178 and perplexity is 72.16731659239922
At time: 208.34455490112305 and batch: 1750, loss is 4.286214599609375 and perplexity is 72.69078331986223
At time: 209.3831160068512 and batch: 1800, loss is 4.234545283317566 and perplexity is 69.03028237484612
At time: 210.42562317848206 and batch: 1850, loss is 4.281822910308838 and perplexity is 72.37224795065923
At time: 211.46625638008118 and batch: 1900, loss is 4.359093551635742 and perplexity is 78.18623051181697
At time: 212.5065004825592 and batch: 1950, loss is 4.2951884460449214 and perplexity is 73.3460349129669
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607648414789244 and perplexity of 100.2481302148443
finished 5 epochs...
Completing Train Step...
At time: 215.81823468208313 and batch: 50, loss is 4.2399121141433715 and perplexity is 69.40175213828222
At time: 216.88836884498596 and batch: 100, loss is 4.2124773645401 and perplexity is 67.52361337900471
At time: 217.93211317062378 and batch: 150, loss is 4.173488850593567 and perplexity is 64.94162897012163
At time: 218.9783194065094 and batch: 200, loss is 4.163786654472351 and perplexity is 64.3145992507322
At time: 220.02506518363953 and batch: 250, loss is 4.159786758422851 and perplexity is 64.05786134403273
At time: 221.07059359550476 and batch: 300, loss is 4.191212816238403 and perplexity is 66.1029130502561
At time: 222.1149024963379 and batch: 350, loss is 4.189246292114258 and perplexity is 65.97304781048136
At time: 223.1591510772705 and batch: 400, loss is 4.163644833564758 and perplexity is 64.30547874264964
At time: 224.2029628753662 and batch: 450, loss is 4.190747199058532 and perplexity is 66.07214156272295
At time: 225.24693965911865 and batch: 500, loss is 4.21391119480133 and perplexity is 67.62050022226013
At time: 226.29083514213562 and batch: 550, loss is 4.174117369651794 and perplexity is 64.98245885143685
At time: 227.33624482154846 and batch: 600, loss is 4.163551473617554 and perplexity is 64.29947546678642
At time: 228.38232731819153 and batch: 650, loss is 4.208574075698852 and perplexity is 67.26056292730703
At time: 229.4293191432953 and batch: 700, loss is 4.230763139724732 and perplexity is 68.7696930384308
At time: 230.4730224609375 and batch: 750, loss is 4.199147882461548 and perplexity is 66.62953065241071
At time: 231.5176203250885 and batch: 800, loss is 4.166366000175476 and perplexity is 64.48070296331542
At time: 232.58910155296326 and batch: 850, loss is 4.170588774681091 and perplexity is 64.75356614626875
At time: 233.63416409492493 and batch: 900, loss is 4.165247325897217 and perplexity is 64.40861039103768
At time: 234.67919731140137 and batch: 950, loss is 4.255499815940857 and perplexity is 70.49204143089098
At time: 235.72341895103455 and batch: 1000, loss is 4.2245750951766965 and perplexity is 68.34545706364214
At time: 236.76908779144287 and batch: 1050, loss is 4.179070925712585 and perplexity is 65.30515168299604
At time: 237.81157660484314 and batch: 1100, loss is 4.223252515792847 and perplexity is 68.25512452029736
At time: 238.85587239265442 and batch: 1150, loss is 4.172395324707031 and perplexity is 64.87065243214258
At time: 239.90064311027527 and batch: 1200, loss is 4.241385984420776 and perplexity is 69.5041167354968
At time: 240.94650650024414 and batch: 1250, loss is 4.220607070922852 and perplexity is 68.07479797841293
At time: 241.99120330810547 and batch: 1300, loss is 4.236243958473206 and perplexity is 69.14764205026546
At time: 243.03680849075317 and batch: 1350, loss is 4.127153878211975 and perplexity is 62.00120858812634
At time: 244.08050537109375 and batch: 1400, loss is 4.154928312301636 and perplexity is 63.74739448001908
At time: 245.12495064735413 and batch: 1450, loss is 4.073048367500305 and perplexity is 58.73573808183084
At time: 246.1697268486023 and batch: 1500, loss is 4.0827147579193115 and perplexity is 59.30625362831971
At time: 247.2164924144745 and batch: 1550, loss is 4.081649956703186 and perplexity is 59.24313786616595
At time: 248.26286482810974 and batch: 1600, loss is 4.195836181640625 and perplexity is 66.40923855314962
At time: 249.3082993030548 and batch: 1650, loss is 4.131382431983948 and perplexity is 62.263939126189406
At time: 250.3536946773529 and batch: 1700, loss is 4.1698185205459595 and perplexity is 64.70370864811713
At time: 251.39803385734558 and batch: 1750, loss is 4.168996076583863 and perplexity is 64.65051535086567
At time: 252.4425220489502 and batch: 1800, loss is 4.119673547744751 and perplexity is 61.53914939082024
At time: 253.48776698112488 and batch: 1850, loss is 4.170761585235596 and perplexity is 64.76475721288
At time: 254.53333020210266 and batch: 1900, loss is 4.250243139266968 and perplexity is 70.1224597976247
At time: 255.5792636871338 and batch: 1950, loss is 4.185103888511658 and perplexity is 65.70032607129495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.605872433684593 and perplexity of 100.07024943301444
finished 6 epochs...
Completing Train Step...
At time: 258.88627767562866 and batch: 50, loss is 4.133769316673279 and perplexity is 62.41273347602207
At time: 259.9240679740906 and batch: 100, loss is 4.11061574935913 and perplexity is 60.9842570281695
At time: 260.9630661010742 and batch: 150, loss is 4.072995748519897 and perplexity is 58.73264754849056
At time: 262.0020318031311 and batch: 200, loss is 4.059655046463012 and perplexity is 57.95431608416854
At time: 263.0398738384247 and batch: 250, loss is 4.051731247901916 and perplexity is 57.49691233857445
At time: 264.0783655643463 and batch: 300, loss is 4.081033082008362 and perplexity is 59.206603543282526
At time: 265.11589765548706 and batch: 350, loss is 4.084691214561462 and perplexity is 59.423585779984386
At time: 266.1554388999939 and batch: 400, loss is 4.056734304428101 and perplexity is 57.78529343301527
At time: 267.19552540779114 and batch: 450, loss is 4.089194693565369 and perplexity is 59.6918021509639
At time: 268.236825466156 and batch: 500, loss is 4.112307996749878 and perplexity is 61.08754484762478
At time: 269.2779424190521 and batch: 550, loss is 4.072962298393249 and perplexity is 58.73068296684961
At time: 270.3190357685089 and batch: 600, loss is 4.064770212173462 and perplexity is 58.251521494006155
At time: 271.360547542572 and batch: 650, loss is 4.1091488122940065 and perplexity is 60.89486254521676
At time: 272.40094900131226 and batch: 700, loss is 4.129435482025147 and perplexity is 62.1428322852082
At time: 273.44788336753845 and batch: 750, loss is 4.100490007400513 and perplexity is 60.36986203008745
At time: 274.48625802993774 and batch: 800, loss is 4.067068295478821 and perplexity is 58.385542279545795
At time: 275.53117847442627 and batch: 850, loss is 4.071532325744629 and perplexity is 58.64675971485038
At time: 276.5710759162903 and batch: 900, loss is 4.064031929969787 and perplexity is 58.20853130374904
At time: 277.6112196445465 and batch: 950, loss is 4.156386795043946 and perplexity is 63.84043678854296
At time: 278.65195965766907 and batch: 1000, loss is 4.125984539985657 and perplexity is 61.928750577063695
At time: 279.69518995285034 and batch: 1050, loss is 4.08217143535614 and perplexity is 59.274039954586634
At time: 280.7396948337555 and batch: 1100, loss is 4.122646484375 and perplexity is 61.722373604276484
At time: 281.78017950057983 and batch: 1150, loss is 4.076786766052246 and perplexity is 58.95572662624472
At time: 282.8218083381653 and batch: 1200, loss is 4.142552952766419 and perplexity is 62.96335892105795
At time: 283.86413979530334 and batch: 1250, loss is 4.124847950935364 and perplexity is 61.85840302296246
At time: 284.9066879749298 and batch: 1300, loss is 4.137629952430725 and perplexity is 62.65415202128174
At time: 285.94665908813477 and batch: 1350, loss is 4.029112038612365 and perplexity is 56.21097590391664
At time: 286.9944508075714 and batch: 1400, loss is 4.056519408226013 and perplexity is 57.77287692709772
At time: 288.03435349464417 and batch: 1450, loss is 3.977841753959656 and perplexity is 53.40165585252545
At time: 289.0763249397278 and batch: 1500, loss is 3.9866455078125 and perplexity is 53.873866448985524
At time: 290.11891651153564 and batch: 1550, loss is 3.9868102979660036 and perplexity is 53.8827450632415
At time: 291.1605260372162 and batch: 1600, loss is 4.102634682655334 and perplexity is 60.499474718201924
At time: 292.20514726638794 and batch: 1650, loss is 4.035231399536133 and perplexity is 56.55600575777088
At time: 293.2442207336426 and batch: 1700, loss is 4.0755622720718385 and perplexity is 58.883579874526575
At time: 294.2846806049347 and batch: 1750, loss is 4.074908952713013 and perplexity is 58.84512265566827
At time: 295.32468485832214 and batch: 1800, loss is 4.024718227386475 and perplexity is 55.96453728582494
At time: 296.36496233940125 and batch: 1850, loss is 4.070639872550965 and perplexity is 58.59444357517014
At time: 297.4046664237976 and batch: 1900, loss is 4.151680822372437 and perplexity is 63.54071124094461
At time: 298.44438004493713 and batch: 1950, loss is 4.0851083183288575 and perplexity is 59.44837675132971
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607977436864099 and perplexity of 100.28111948945006
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 301.7322950363159 and batch: 50, loss is 4.0636253786087035 and perplexity is 58.18487135593869
At time: 302.80426716804504 and batch: 100, loss is 4.067966918945313 and perplexity is 58.43803247887224
At time: 303.8440399169922 and batch: 150, loss is 4.035198540687561 and perplexity is 56.5541474230734
At time: 304.8863797187805 and batch: 200, loss is 4.026152639389038 and perplexity is 56.04487109193933
At time: 305.93389534950256 and batch: 250, loss is 4.018444309234619 and perplexity is 55.6145194990774
At time: 306.97383666038513 and batch: 300, loss is 4.043233304023743 and perplexity is 57.01037700725076
At time: 308.012348651886 and batch: 350, loss is 4.029759302139282 and perplexity is 56.24737099576874
At time: 309.05569410324097 and batch: 400, loss is 3.9974909257888793 and perplexity is 54.4613309393293
At time: 310.09841299057007 and batch: 450, loss is 4.023281917572022 and perplexity is 55.88421257105712
At time: 311.17626190185547 and batch: 500, loss is 4.0457652759552 and perplexity is 57.15490857936226
At time: 312.21859216690063 and batch: 550, loss is 4.002254037857056 and perplexity is 54.721355132559424
At time: 313.2591519355774 and batch: 600, loss is 3.9788239669799803 and perplexity is 53.45413342206779
At time: 314.2980692386627 and batch: 650, loss is 4.009905171394348 and perplexity is 55.14164131056753
At time: 315.34290599823 and batch: 700, loss is 4.025222177505493 and perplexity is 55.992747728781936
At time: 316.38531517982483 and batch: 750, loss is 3.980875654220581 and perplexity is 53.563917168012104
At time: 317.4317698478699 and batch: 800, loss is 3.9515926837921143 and perplexity is 52.01814935751872
At time: 318.47160601615906 and batch: 850, loss is 3.954486312866211 and perplexity is 52.16888857338977
At time: 319.51071310043335 and batch: 900, loss is 3.9382757186889648 and perplexity is 51.330017560855936
At time: 320.55149579048157 and batch: 950, loss is 4.025342359542846 and perplexity is 55.99947745566902
At time: 321.60123348236084 and batch: 1000, loss is 3.985162854194641 and perplexity is 53.7940493511629
At time: 322.6443145275116 and batch: 1050, loss is 3.93455162525177 and perplexity is 51.13921528260022
At time: 323.69208097457886 and batch: 1100, loss is 3.9554450607299803 and perplexity is 52.21892936828422
At time: 324.74069261550903 and batch: 1150, loss is 3.9180571603775025 and perplexity is 50.30261985679676
At time: 325.7849979400635 and batch: 1200, loss is 3.970206789970398 and perplexity is 52.995488642182835
At time: 326.8261194229126 and batch: 1250, loss is 3.9462121725082397 and perplexity is 51.73901672946664
At time: 327.86753487586975 and batch: 1300, loss is 3.9555827808380126 and perplexity is 52.22612146011462
At time: 328.91029238700867 and batch: 1350, loss is 3.832630615234375 and perplexity is 46.18387056840106
At time: 329.95283579826355 and batch: 1400, loss is 3.850784673690796 and perplexity is 47.02995192284704
At time: 330.9960880279541 and batch: 1450, loss is 3.7607184982299806 and perplexity is 42.979295435306156
At time: 332.03860664367676 and batch: 1500, loss is 3.7687562322616577 and perplexity is 43.32614365038818
At time: 333.08427715301514 and batch: 1550, loss is 3.760062394142151 and perplexity is 42.95110579256018
At time: 334.12652587890625 and batch: 1600, loss is 3.866376323699951 and perplexity is 47.76897277920388
At time: 335.16680455207825 and batch: 1650, loss is 3.7962636375427246 and perplexity is 44.53447630082293
At time: 336.20568799972534 and batch: 1700, loss is 3.819402327537537 and perplexity is 45.57696008493418
At time: 337.24437856674194 and batch: 1750, loss is 3.8098209953308104 and perplexity is 45.14235745027287
At time: 338.2854208946228 and batch: 1800, loss is 3.7488699436187742 and perplexity is 42.47305792008168
At time: 339.3258943557739 and batch: 1850, loss is 3.783783392906189 and perplexity is 43.982129025675945
At time: 340.36635518074036 and batch: 1900, loss is 3.8549042654037478 and perplexity is 47.2240957451212
At time: 341.4134945869446 and batch: 1950, loss is 3.7934816789627077 and perplexity is 44.410755405367304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.522294297329215 and perplexity of 92.04653803239762
finished 8 epochs...
Completing Train Step...
At time: 344.69253063201904 and batch: 50, loss is 3.961822543144226 and perplexity is 52.55301886461728
At time: 345.7613070011139 and batch: 100, loss is 3.956072907447815 and perplexity is 52.251725145980316
At time: 346.80020451545715 and batch: 150, loss is 3.917633113861084 and perplexity is 50.281293728034626
At time: 347.84473276138306 and batch: 200, loss is 3.9072977542877196 and perplexity is 49.764294764763164
At time: 348.88568353652954 and batch: 250, loss is 3.901298637390137 and perplexity is 49.46664664874572
At time: 349.9253261089325 and batch: 300, loss is 3.9264903974533083 and perplexity is 50.72862756278915
At time: 350.96510434150696 and batch: 350, loss is 3.9194084215164184 and perplexity is 50.37063777683142
At time: 352.0048267841339 and batch: 400, loss is 3.8901989793777467 and perplexity is 48.920619749820936
At time: 353.0471770763397 and batch: 450, loss is 3.9220882558822634 and perplexity is 50.505803773325205
At time: 354.0896406173706 and batch: 500, loss is 3.9450608348846434 and perplexity is 51.679481931800865
At time: 355.1320581436157 and batch: 550, loss is 3.9047805166244505 and perplexity is 49.63918374084969
At time: 356.1736226081848 and batch: 600, loss is 3.8856325721740723 and perplexity is 48.69773755211994
At time: 357.21416544914246 and batch: 650, loss is 3.922452840805054 and perplexity is 50.524220784972755
At time: 358.25623083114624 and batch: 700, loss is 3.940285339355469 and perplexity is 51.433275144494154
At time: 359.2974398136139 and batch: 750, loss is 3.9000201416015625 and perplexity is 49.40344415999723
At time: 360.33859276771545 and batch: 800, loss is 3.8694692945480345 and perplexity is 47.916949545396946
At time: 361.37949109077454 and batch: 850, loss is 3.8761956977844236 and perplexity is 48.24034469366289
At time: 362.42264676094055 and batch: 900, loss is 3.8601898765563964 and perplexity is 47.47436478201044
At time: 363.4943974018097 and batch: 950, loss is 3.9503718757629396 and perplexity is 51.95468393055392
At time: 364.5331652164459 and batch: 1000, loss is 3.911330637931824 and perplexity is 49.965393606737265
At time: 365.5760028362274 and batch: 1050, loss is 3.8657219314575197 and perplexity is 47.737723359792234
At time: 366.6170973777771 and batch: 1100, loss is 3.888568596839905 and perplexity is 48.84092540942417
At time: 367.658748626709 and batch: 1150, loss is 3.8591705131530762 and perplexity is 47.42599580892465
At time: 368.70089197158813 and batch: 1200, loss is 3.909219274520874 and perplexity is 49.860009793774495
At time: 369.7425253391266 and batch: 1250, loss is 3.89052809715271 and perplexity is 48.93672304513783
At time: 370.7823567390442 and batch: 1300, loss is 3.902126269340515 and perplexity is 49.50760377236447
At time: 371.82180619239807 and batch: 1350, loss is 3.7834209251403808 and perplexity is 43.96618981053288
At time: 372.8619363307953 and batch: 1400, loss is 3.8076882791519164 and perplexity is 45.04618420575603
At time: 373.90738344192505 and batch: 1450, loss is 3.7198970174789427 and perplexity is 41.260144816080775
At time: 374.95031929016113 and batch: 1500, loss is 3.73108238697052 and perplexity is 41.72424551128044
At time: 375.99264430999756 and batch: 1550, loss is 3.7255824184417725 and perplexity is 41.49539339070428
At time: 377.03320360183716 and batch: 1600, loss is 3.8348080015182493 and perplexity is 46.28454025333551
At time: 378.0726761817932 and batch: 1650, loss is 3.765866446495056 and perplexity is 43.20112110833064
At time: 379.11257433891296 and batch: 1700, loss is 3.7959917545318604 and perplexity is 44.52236977917236
At time: 380.1550316810608 and batch: 1750, loss is 3.792070326805115 and perplexity is 44.348120400327325
At time: 381.2008001804352 and batch: 1800, loss is 3.735198016166687 and perplexity is 41.8963208906322
At time: 382.24284982681274 and batch: 1850, loss is 3.774063787460327 and perplexity is 43.556710882254116
At time: 383.2832760810852 and batch: 1900, loss is 3.8493624782562255 and perplexity is 46.96311367972221
At time: 384.32288241386414 and batch: 1950, loss is 3.7913817596435546 and perplexity is 44.317594251800564
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.523212379632994 and perplexity of 92.13108313383165
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 387.6913893222809 and batch: 50, loss is 3.9280600214004515 and perplexity is 50.80831495467609
At time: 388.73485374450684 and batch: 100, loss is 3.943541417121887 and perplexity is 51.6010188331917
At time: 389.80451798439026 and batch: 150, loss is 3.9149470281600953 and perplexity is 50.14641509280767
At time: 390.84793496131897 and batch: 200, loss is 3.9104164743423464 and perplexity is 49.9197379347241
At time: 391.8943293094635 and batch: 250, loss is 3.9118885469436644 and perplexity is 49.99327752773276
At time: 392.94318652153015 and batch: 300, loss is 3.9331172418594362 and perplexity is 51.0659146246928
At time: 393.9942538738251 and batch: 350, loss is 3.9271534872055054 and perplexity is 50.76227635071937
At time: 395.0363812446594 and batch: 400, loss is 3.9012563371658326 and perplexity is 49.46455424275184
At time: 396.0841007232666 and batch: 450, loss is 3.929283676147461 and perplexity is 50.870524844408976
At time: 397.1285300254822 and batch: 500, loss is 3.953863010406494 and perplexity is 52.13638170867807
At time: 398.1717617511749 and batch: 550, loss is 3.9123172855377195 and perplexity is 50.014716170710635
At time: 399.2193274497986 and batch: 600, loss is 3.886056728363037 and perplexity is 48.71839738007845
At time: 400.2652952671051 and batch: 650, loss is 3.9133486223220824 and perplexity is 50.0663247956191
At time: 401.3113503456116 and batch: 700, loss is 3.927454128265381 and perplexity is 50.77753986958842
At time: 402.3615732192993 and batch: 750, loss is 3.881715087890625 and perplexity is 48.50733811751629
At time: 403.40565252304077 and batch: 800, loss is 3.8474479961395263 and perplexity is 46.873289649123556
At time: 404.450453042984 and batch: 850, loss is 3.8552360486984254 and perplexity is 47.23976651070105
At time: 405.4944031238556 and batch: 900, loss is 3.8377010440826416 and perplexity is 46.41863727903403
At time: 406.54444646835327 and batch: 950, loss is 3.9293269872665406 and perplexity is 50.87272815148166
At time: 407.5938444137573 and batch: 1000, loss is 3.8842670488357545 and perplexity is 48.63128503652562
At time: 408.6429100036621 and batch: 1050, loss is 3.8372771644592287 and perplexity is 46.398965534065326
At time: 409.6876697540283 and batch: 1100, loss is 3.854477620124817 and perplexity is 47.203952105019795
At time: 410.7301869392395 and batch: 1150, loss is 3.826484651565552 and perplexity is 45.90089664226421
At time: 411.77503395080566 and batch: 1200, loss is 3.870574059486389 and perplexity is 47.969915763430784
At time: 412.82474970817566 and batch: 1250, loss is 3.8492043161392213 and perplexity is 46.9556864816077
At time: 413.8732180595398 and batch: 1300, loss is 3.858750081062317 and perplexity is 47.406060589347035
At time: 414.92085099220276 and batch: 1350, loss is 3.7376539754867553 and perplexity is 41.999343007680864
At time: 415.96615052223206 and batch: 1400, loss is 3.7604987096786497 and perplexity is 42.96985011624973
At time: 417.0150167942047 and batch: 1450, loss is 3.6622309827804567 and perplexity is 38.94813864203816
At time: 418.06260108947754 and batch: 1500, loss is 3.6729946517944336 and perplexity is 39.36962783080215
At time: 419.10997319221497 and batch: 1550, loss is 3.666552677154541 and perplexity is 39.116824836230215
At time: 420.15666937828064 and batch: 1600, loss is 3.77160165309906 and perplexity is 43.449600322132035
At time: 421.2037584781647 and batch: 1650, loss is 3.695401487350464 and perplexity is 40.26173392034606
At time: 422.24680972099304 and batch: 1700, loss is 3.7214578437805175 and perplexity is 41.32459502001887
At time: 423.2989618778229 and batch: 1750, loss is 3.717076621055603 and perplexity is 41.143938801759965
At time: 424.3477830886841 and batch: 1800, loss is 3.658609948158264 and perplexity is 38.80736111751216
At time: 425.40130376815796 and batch: 1850, loss is 3.6866363668441773 and perplexity is 39.91037706282207
At time: 426.4519536495209 and batch: 1900, loss is 3.7638660669326782 and perplexity is 43.11478884602862
At time: 427.49496150016785 and batch: 1950, loss is 3.708263931274414 and perplexity is 40.782943040896775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4952137082122094 and perplexity of 89.58731248389869
finished 10 epochs...
Completing Train Step...
At time: 430.8009555339813 and batch: 50, loss is 3.9107266092300415 and perplexity is 49.93522218802172
At time: 431.8706374168396 and batch: 100, loss is 3.9116763830184937 and perplexity is 49.98267188284774
At time: 432.9122977256775 and batch: 150, loss is 3.876325454711914 and perplexity is 48.24660461869695
At time: 433.95549988746643 and batch: 200, loss is 3.8647702741622925 and perplexity is 47.69231501711664
At time: 434.9945237636566 and batch: 250, loss is 3.864916958808899 and perplexity is 47.69931126059898
At time: 436.0345392227173 and batch: 300, loss is 3.883944888114929 and perplexity is 48.61562047007308
At time: 437.07392859458923 and batch: 350, loss is 3.8801848888397217 and perplexity is 48.43316899599901
At time: 438.11260437965393 and batch: 400, loss is 3.8544979381561277 and perplexity is 47.204911206140146
At time: 439.15410828590393 and batch: 450, loss is 3.8846125268936156 and perplexity is 48.648088980961234
At time: 440.19855284690857 and batch: 500, loss is 3.9089370727539063 and perplexity is 49.84594119609461
At time: 441.23969626426697 and batch: 550, loss is 3.8699616146087648 and perplexity is 47.94054582889241
At time: 442.31303191185 and batch: 600, loss is 3.8460048627853394 and perplexity is 46.80569402788965
At time: 443.3518958091736 and batch: 650, loss is 3.875774178504944 and perplexity is 48.22001474335979
At time: 444.3960499763489 and batch: 700, loss is 3.89245219707489 and perplexity is 49.03097283406919
At time: 445.43534564971924 and batch: 750, loss is 3.8499062347412107 and perplexity is 46.98865712141733
At time: 446.47484588623047 and batch: 800, loss is 3.8155483388900757 and perplexity is 45.40164504626491
At time: 447.5150122642517 and batch: 850, loss is 3.8246786832809447 and perplexity is 45.81807588703201
At time: 448.5568082332611 and batch: 900, loss is 3.8078078746795656 and perplexity is 45.051571850087356
At time: 449.5946469306946 and batch: 950, loss is 3.901173162460327 and perplexity is 49.46044021411366
At time: 450.6353991031647 and batch: 1000, loss is 3.8562626743316653 and perplexity is 47.288288968847134
At time: 451.68184447288513 and batch: 1050, loss is 3.812236480712891 and perplexity is 45.251529954018906
At time: 452.72713136672974 and batch: 1100, loss is 3.8312120819091797 and perplexity is 46.11840365339151
At time: 453.77788615226746 and batch: 1150, loss is 3.805452742576599 and perplexity is 44.945594291494345
At time: 454.8258035182953 and batch: 1200, loss is 3.8506414175033568 and perplexity is 47.0232150737983
At time: 455.8705430030823 and batch: 1250, loss is 3.832214059829712 and perplexity is 46.164636433827006
At time: 456.9130024909973 and batch: 1300, loss is 3.8433837699890137 and perplexity is 46.68317260060616
At time: 457.9525818824768 and batch: 1350, loss is 3.723613681793213 and perplexity is 41.413780252737986
At time: 458.9962637424469 and batch: 1400, loss is 3.7492078733444214 and perplexity is 42.487413254302474
At time: 460.03858947753906 and batch: 1450, loss is 3.653262372016907 and perplexity is 38.60038969004736
At time: 461.07715702056885 and batch: 1500, loss is 3.6664772129058836 and perplexity is 39.11387302581356
At time: 462.1182487010956 and batch: 1550, loss is 3.6623303270339966 and perplexity is 38.952008107999745
At time: 463.15655040740967 and batch: 1600, loss is 3.769383206367493 and perplexity is 43.353316538021005
At time: 464.19364404678345 and batch: 1650, loss is 3.6949012088775635 and perplexity is 40.24159687906818
At time: 465.23224925994873 and batch: 1700, loss is 3.722885265350342 and perplexity is 41.38362475845274
At time: 466.2734920978546 and batch: 1750, loss is 3.7208829975128173 and perplexity is 41.300846557318934
At time: 467.31794929504395 and batch: 1800, loss is 3.664454960823059 and perplexity is 39.03485483889507
At time: 468.36393547058105 and batch: 1850, loss is 3.6938972091674804 and perplexity is 40.20121460275734
At time: 469.4118366241455 and batch: 1900, loss is 3.7724391174316407 and perplexity is 43.4860030535337
At time: 470.4547758102417 and batch: 1950, loss is 3.716616168022156 and perplexity is 41.12499831126853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494761480287064 and perplexity of 89.54680775882892
finished 11 epochs...
Completing Train Step...
At time: 473.7896945476532 and batch: 50, loss is 3.8939008474349976 and perplexity is 49.10205304327634
At time: 474.8535633087158 and batch: 100, loss is 3.892922921180725 and perplexity is 49.054058327937675
At time: 475.8941035270691 and batch: 150, loss is 3.8563797426223756 and perplexity is 47.29382525206262
At time: 476.93314599990845 and batch: 200, loss is 3.8440571880340575 and perplexity is 46.71462047903126
At time: 477.9714756011963 and batch: 250, loss is 3.843063917160034 and perplexity is 46.66824324350994
At time: 479.0123426914215 and batch: 300, loss is 3.8620505809783934 and perplexity is 47.562782776858604
At time: 480.0522229671478 and batch: 350, loss is 3.858665819168091 and perplexity is 47.402066233172356
At time: 481.0933825969696 and batch: 400, loss is 3.8330813455581665 and perplexity is 46.20469173134856
At time: 482.14195728302 and batch: 450, loss is 3.8639866495132447 and perplexity is 47.6549567828274
At time: 483.19668650627136 and batch: 500, loss is 3.888388957977295 and perplexity is 48.832152469138904
At time: 484.23611664772034 and batch: 550, loss is 3.849728560447693 and perplexity is 46.980309186588606
At time: 485.27474308013916 and batch: 600, loss is 3.8268736839294433 and perplexity is 45.91875705050284
At time: 486.3229727745056 and batch: 650, loss is 3.857205324172974 and perplexity is 47.332886283462756
At time: 487.3642055988312 and batch: 700, loss is 3.8744454622268676 and perplexity is 48.15598657189811
At time: 488.40550327301025 and batch: 750, loss is 3.833221411705017 and perplexity is 46.21116389774092
At time: 489.44518971443176 and batch: 800, loss is 3.7985814952850343 and perplexity is 44.637820603945265
At time: 490.4847912788391 and batch: 850, loss is 3.808587083816528 and perplexity is 45.08669012697169
At time: 491.52289867401123 and batch: 900, loss is 3.7919469356536863 and perplexity is 44.342648572281966
At time: 492.5610725879669 and batch: 950, loss is 3.8859016418457033 and perplexity is 48.71084239935166
At time: 493.59872913360596 and batch: 1000, loss is 3.8414239358901976 and perplexity is 46.59177092242114
At time: 494.67964911460876 and batch: 1050, loss is 3.798649339675903 and perplexity is 44.64084913242702
At time: 495.71822333335876 and batch: 1100, loss is 3.8180091333389283 and perplexity is 45.51350674023302
At time: 496.75657510757446 and batch: 1150, loss is 3.7936395406723022 and perplexity is 44.4177667165342
At time: 497.7936944961548 and batch: 1200, loss is 3.838996629714966 and perplexity is 46.47881557321383
At time: 498.830242395401 and batch: 1250, loss is 3.8218939685821534 and perplexity is 45.69066310410041
At time: 499.86934185028076 and batch: 1300, loss is 3.8336165714263917 and perplexity is 46.2294282968309
At time: 500.9078814983368 and batch: 1350, loss is 3.7145359897613526 and perplexity is 41.03953989898746
At time: 501.94588017463684 and batch: 1400, loss is 3.7413011407852172 and perplexity is 42.152801227698056
At time: 502.9843580722809 and batch: 1450, loss is 3.6461935091018676 and perplexity is 38.328490966467186
At time: 504.02273654937744 and batch: 1500, loss is 3.6603897428512573 and perplexity is 38.87649175379939
At time: 505.06166219711304 and batch: 1550, loss is 3.6574599838256834 and perplexity is 38.7627596863281
At time: 506.09783458709717 and batch: 1600, loss is 3.7650779581069944 and perplexity is 43.16707095182611
At time: 507.13709592819214 and batch: 1650, loss is 3.691277265548706 and perplexity is 40.09602753934755
At time: 508.17743492126465 and batch: 1700, loss is 3.7201476001739504 and perplexity is 41.27048518987045
At time: 509.21706986427307 and batch: 1750, loss is 3.7195885372161865 and perplexity is 41.24741883872389
At time: 510.253484249115 and batch: 1800, loss is 3.6640821170806883 and perplexity is 39.0203036503624
At time: 511.2945923805237 and batch: 1850, loss is 3.6941601705551146 and perplexity is 40.21178735998639
At time: 512.3337051868439 and batch: 1900, loss is 3.7732870197296142 and perplexity is 43.52289057174821
At time: 513.3767428398132 and batch: 1950, loss is 3.717366771697998 and perplexity is 41.155878474102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4957025572311045 and perplexity of 89.63111785994708
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 516.6746425628662 and batch: 50, loss is 3.885938911437988 and perplexity is 48.71265786641838
At time: 517.7147243022919 and batch: 100, loss is 3.894362835884094 and perplexity is 49.12474286542356
At time: 518.7603874206543 and batch: 150, loss is 3.8637845659255983 and perplexity is 47.64532747118728
At time: 519.8036496639252 and batch: 200, loss is 3.853548302650452 and perplexity is 47.160105024554184
At time: 520.8673801422119 and batch: 250, loss is 3.854837665557861 and perplexity is 47.22095073235228
At time: 521.9100358486176 and batch: 300, loss is 3.872055048942566 and perplexity is 48.04101133579197
At time: 522.9524233341217 and batch: 350, loss is 3.869461078643799 and perplexity is 47.91655586594544
At time: 524.0015785694122 and batch: 400, loss is 3.8457383584976195 and perplexity is 46.7932217717702
At time: 525.0469079017639 and batch: 450, loss is 3.8774557638168337 and perplexity is 48.30116902669322
At time: 526.0887494087219 and batch: 500, loss is 3.904892578125 and perplexity is 49.644746693956364
At time: 527.1333720684052 and batch: 550, loss is 3.867491898536682 and perplexity is 47.82229237868487
At time: 528.1798737049103 and batch: 600, loss is 3.8431790685653686 and perplexity is 46.67361746672267
At time: 529.223060131073 and batch: 650, loss is 3.8674880981445314 and perplexity is 47.822110635565636
At time: 530.265881061554 and batch: 700, loss is 3.8837512874603273 and perplexity is 48.60620936515363
At time: 531.3089897632599 and batch: 750, loss is 3.838795471191406 and perplexity is 46.469466903610126
At time: 532.3509180545807 and batch: 800, loss is 3.801281900405884 and perplexity is 44.75852370357276
At time: 533.39475440979 and batch: 850, loss is 3.8107698345184327 and perplexity is 45.1852106152094
At time: 534.4387259483337 and batch: 900, loss is 3.7896259355545046 and perplexity is 44.23984862603938
At time: 535.4807832241058 and batch: 950, loss is 3.884455904960632 and perplexity is 48.64047021987721
At time: 536.524209022522 and batch: 1000, loss is 3.839840779304504 and perplexity is 46.518067211098334
At time: 537.5653047561646 and batch: 1050, loss is 3.798713722229004 and perplexity is 44.643723316789426
At time: 538.617604970932 and batch: 1100, loss is 3.813459944725037 and perplexity is 45.30692745392573
At time: 539.6634917259216 and batch: 1150, loss is 3.791126832962036 and perplexity is 44.306297954490034
At time: 540.7063143253326 and batch: 1200, loss is 3.834917826652527 and perplexity is 46.28962373832591
At time: 541.7476210594177 and batch: 1250, loss is 3.812915105819702 and perplexity is 45.282249200614395
At time: 542.7898547649384 and batch: 1300, loss is 3.821700973510742 and perplexity is 45.68184588217937
At time: 543.8307685852051 and batch: 1350, loss is 3.700350675582886 and perplexity is 40.4614907293613
At time: 544.8719532489777 and batch: 1400, loss is 3.7280539798736574 and perplexity is 41.59807864879934
At time: 545.9139075279236 and batch: 1450, loss is 3.629701271057129 and perplexity is 37.70155238990014
At time: 546.953770160675 and batch: 1500, loss is 3.6377281045913694 and perplexity is 38.00539428770604
At time: 547.9955453872681 and batch: 1550, loss is 3.6364505672454834 and perplexity is 37.956871978289016
At time: 549.0368378162384 and batch: 1600, loss is 3.743296880722046 and perplexity is 42.23701125926836
At time: 550.0784137248993 and batch: 1650, loss is 3.6655049228668215 and perplexity is 39.0758614788002
At time: 551.1216135025024 and batch: 1700, loss is 3.6894863271713256 and perplexity is 40.02428228968401
At time: 552.16783618927 and batch: 1750, loss is 3.688747444152832 and perplexity is 39.99471995007309
At time: 553.2082016468048 and batch: 1800, loss is 3.6369869899749756 and perplexity is 37.977238369167715
At time: 554.2492771148682 and batch: 1850, loss is 3.6668725061416625 and perplexity is 39.12933753155167
At time: 555.2893064022064 and batch: 1900, loss is 3.746849365234375 and perplexity is 42.38732442212436
At time: 556.3303823471069 and batch: 1950, loss is 3.6950057458877565 and perplexity is 40.24580383517879
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488671307231105 and perplexity of 89.00310949172648
finished 13 epochs...
Completing Train Step...
At time: 559.5945994853973 and batch: 50, loss is 3.883794264793396 and perplexity is 48.60829837529245
At time: 560.6587018966675 and batch: 100, loss is 3.8833631896972656 and perplexity is 48.58734906408516
At time: 561.700085401535 and batch: 150, loss is 3.847919626235962 and perplexity is 46.89540171718955
At time: 562.7378118038177 and batch: 200, loss is 3.8353197956085205 and perplexity is 46.308234470270996
At time: 563.7754275798798 and batch: 250, loss is 3.8361541175842286 and perplexity is 46.346886569851705
At time: 564.8139986991882 and batch: 300, loss is 3.852182559967041 and perplexity is 47.09574041891732
At time: 565.8535006046295 and batch: 350, loss is 3.850565242767334 and perplexity is 47.019633229227864
At time: 566.9053990840912 and batch: 400, loss is 3.8271304416656493 and perplexity is 45.930548560328425
At time: 567.9442775249481 and batch: 450, loss is 3.8596756744384764 and perplexity is 47.449959638218665
At time: 568.981921672821 and batch: 500, loss is 3.8869900417327883 and perplexity is 48.76388813696979
At time: 570.0247232913971 and batch: 550, loss is 3.8503271245956423 and perplexity is 47.00843833303672
At time: 571.066358089447 and batch: 600, loss is 3.825975203514099 and perplexity is 45.87751847539627
At time: 572.1053488254547 and batch: 650, loss is 3.851181774139404 and perplexity is 47.04863124639204
At time: 573.1806855201721 and batch: 700, loss is 3.8682903146743772 and perplexity is 47.86048971531744
At time: 574.2217781543732 and batch: 750, loss is 3.8255095195770266 and perplexity is 45.85615902573184
At time: 575.2604234218597 and batch: 800, loss is 3.7884501028060913 and perplexity is 44.1878605338805
At time: 576.3007230758667 and batch: 850, loss is 3.798949556350708 and perplexity is 44.654253071656385
At time: 577.3416526317596 and batch: 900, loss is 3.778283944129944 and perplexity is 43.74091543884856
At time: 578.3822541236877 and batch: 950, loss is 3.8740624952316285 and perplexity is 48.13754794933519
At time: 579.4223539829254 and batch: 1000, loss is 3.8296241569519043 and perplexity is 46.045229202384895
At time: 580.462397813797 and batch: 1050, loss is 3.788731746673584 and perplexity is 44.200307526544805
At time: 581.5057566165924 and batch: 1100, loss is 3.8045378637313845 and perplexity is 44.90449332216193
At time: 582.5499300956726 and batch: 1150, loss is 3.78292254447937 and perplexity is 43.944283371119305
At time: 583.5899469852448 and batch: 1200, loss is 3.82693687915802 and perplexity is 45.92165898854396
At time: 584.6347870826721 and batch: 1250, loss is 3.8063114309310913 and perplexity is 44.9842051248622
At time: 585.6746470928192 and batch: 1300, loss is 3.8159079551696777 and perplexity is 45.41797515305439
At time: 586.7180926799774 and batch: 1350, loss is 3.6958455848693847 and perplexity is 40.27961802733738
At time: 587.7603929042816 and batch: 1400, loss is 3.7254145860672 and perplexity is 41.488429704680016
At time: 588.7998461723328 and batch: 1450, loss is 3.6290916633605956 and perplexity is 37.678576237323256
At time: 589.8400142192841 and batch: 1500, loss is 3.638313403129578 and perplexity is 38.02764530053409
At time: 590.8854401111603 and batch: 1550, loss is 3.6384127807617186 and perplexity is 38.03142458566504
At time: 591.9341416358948 and batch: 1600, loss is 3.746643991470337 and perplexity is 42.378620071613504
At time: 592.9798820018768 and batch: 1650, loss is 3.669720854759216 and perplexity is 39.2409504067444
At time: 594.0221614837646 and batch: 1700, loss is 3.694811644554138 and perplexity is 40.23799282906971
At time: 595.0630598068237 and batch: 1750, loss is 3.694987473487854 and perplexity is 40.24506845447532
At time: 596.1013441085815 and batch: 1800, loss is 3.6434214973449706 and perplexity is 38.22239106191517
At time: 597.140202999115 and batch: 1850, loss is 3.6738386869430544 and perplexity is 39.40287120779525
At time: 598.1789054870605 and batch: 1900, loss is 3.7538210010528563 and perplexity is 42.68386589982544
At time: 599.2262938022614 and batch: 1950, loss is 3.7016307592391966 and perplexity is 40.51331798688951
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488075149890989 and perplexity of 88.950065447579
finished 14 epochs...
Completing Train Step...
At time: 602.5013654232025 and batch: 50, loss is 3.8806032228469847 and perplexity is 48.45343447624379
At time: 603.580245256424 and batch: 100, loss is 3.8778637742996214 and perplexity is 48.32088043094335
At time: 604.6212482452393 and batch: 150, loss is 3.841110305786133 and perplexity is 46.57716063169145
At time: 605.6590225696564 and batch: 200, loss is 3.8276720237731934 and perplexity is 45.955430460806255
At time: 606.6974966526031 and batch: 250, loss is 3.827888836860657 and perplexity is 45.96539527978273
At time: 607.7379772663116 and batch: 300, loss is 3.843648681640625 and perplexity is 46.69554115517701
At time: 608.7801916599274 and batch: 350, loss is 3.8423583126068115 and perplexity is 46.635325533395246
At time: 609.8190786838531 and batch: 400, loss is 3.8186591482162475 and perplexity is 45.54310081398525
At time: 610.8567450046539 and batch: 450, loss is 3.8515418672561648 and perplexity is 47.065576185351716
At time: 611.8959965705872 and batch: 500, loss is 3.8787216472625734 and perplexity is 48.36235139367656
At time: 612.9374146461487 and batch: 550, loss is 3.842339873313904 and perplexity is 46.63446561889602
At time: 613.9776065349579 and batch: 600, loss is 3.8183702182769776 and perplexity is 45.52994394943047
At time: 615.0169606208801 and batch: 650, loss is 3.843748326301575 and perplexity is 46.70019434837238
At time: 616.0589232444763 and batch: 700, loss is 3.861205062866211 and perplexity is 47.52258457910192
At time: 617.0956509113312 and batch: 750, loss is 3.8190990447998048 and perplexity is 45.56313947558417
At time: 618.1348860263824 and batch: 800, loss is 3.7820814990997316 and perplexity is 43.90733977242768
At time: 619.1759259700775 and batch: 850, loss is 3.7928864574432373 and perplexity is 44.384329033606875
At time: 620.2160873413086 and batch: 900, loss is 3.7725171184539796 and perplexity is 43.489395138520635
At time: 621.2566320896149 and batch: 950, loss is 3.8687213325500487 and perplexity is 47.88112288823689
At time: 622.2972490787506 and batch: 1000, loss is 3.8244507408142088 and perplexity is 45.80763319200528
At time: 623.3420643806458 and batch: 1050, loss is 3.7839581298828127 and perplexity is 43.98981500141989
At time: 624.3800835609436 and batch: 1100, loss is 3.800273966789246 and perplexity is 44.71343281103147
At time: 625.4453327655792 and batch: 1150, loss is 3.779066257476807 and perplexity is 43.77514792932156
At time: 626.4897649288177 and batch: 1200, loss is 3.823206605911255 and perplexity is 45.750677754200076
At time: 627.529807806015 and batch: 1250, loss is 3.8033202266693116 and perplexity is 44.84984922193156
At time: 628.5707182884216 and batch: 1300, loss is 3.8134254837036132 and perplexity is 45.30536615783019
At time: 629.6144149303436 and batch: 1350, loss is 3.693876094818115 and perplexity is 40.20036578922841
At time: 630.6527717113495 and batch: 1400, loss is 3.7241877031326296 and perplexity is 41.43755947058527
At time: 631.6924645900726 and batch: 1450, loss is 3.628592400550842 and perplexity is 37.659769420646214
At time: 632.7364182472229 and batch: 1500, loss is 3.638317894935608 and perplexity is 38.0278161137242
At time: 633.7834930419922 and batch: 1550, loss is 3.639087371826172 and perplexity is 38.05708890034438
At time: 634.8231430053711 and batch: 1600, loss is 3.747752766609192 and perplexity is 42.425634491361215
At time: 635.8635406494141 and batch: 1650, loss is 3.6711029195785523 and perplexity is 39.2952214381819
At time: 636.9040563106537 and batch: 1700, loss is 3.696453742980957 and perplexity is 40.304121854117014
At time: 637.9438285827637 and batch: 1750, loss is 3.697043328285217 and perplexity is 40.327891578514844
At time: 638.9827837944031 and batch: 1800, loss is 3.645522212982178 and perplexity is 38.302769833422154
At time: 640.0216867923737 and batch: 1850, loss is 3.6761877393722533 and perplexity is 39.495539416751726
At time: 641.0631585121155 and batch: 1900, loss is 3.7562853717803955 and perplexity is 42.78918448820926
At time: 642.1027722358704 and batch: 1950, loss is 3.7038747024536134 and perplexity is 40.604329646188255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488069472202035 and perplexity of 88.94956041820868
finished 15 epochs...
Completing Train Step...
At time: 645.4271335601807 and batch: 50, loss is 3.8766518306732176 and perplexity is 48.26235372058335
At time: 646.4658505916595 and batch: 100, loss is 3.872938370704651 and perplexity is 48.08346575427287
At time: 647.5056746006012 and batch: 150, loss is 3.835595645904541 and perplexity is 46.321010372494996
At time: 648.5451610088348 and batch: 200, loss is 3.8219381093978884 and perplexity is 45.69267997175407
At time: 649.5886318683624 and batch: 250, loss is 3.8218058252334597 and perplexity is 45.68663595353626
At time: 650.631288766861 and batch: 300, loss is 3.837484264373779 and perplexity is 46.40857575096586
At time: 651.6971414089203 and batch: 350, loss is 3.836359853744507 and perplexity is 46.356422781273565
At time: 652.7368774414062 and batch: 400, loss is 3.812592010498047 and perplexity is 45.26762108100941
At time: 653.7769734859467 and batch: 450, loss is 3.8456931638717653 and perplexity is 46.79110701740784
At time: 654.8179504871368 and batch: 500, loss is 3.8728206157684326 and perplexity is 48.077804022184814
At time: 655.8577575683594 and batch: 550, loss is 3.8366339635849 and perplexity is 46.369131274605294
At time: 656.8985438346863 and batch: 600, loss is 3.812988448143005 and perplexity is 45.28557042776693
At time: 657.9381551742554 and batch: 650, loss is 3.838473906517029 and perplexity is 46.45452636691994
At time: 658.9787812232971 and batch: 700, loss is 3.856142773628235 and perplexity is 47.28261940963461
At time: 660.0210433006287 and batch: 750, loss is 3.814440622329712 and perplexity is 45.35138073662318
At time: 661.0625104904175 and batch: 800, loss is 3.777432165145874 and perplexity is 43.70367370944663
At time: 662.1099207401276 and batch: 850, loss is 3.7884107351303102 and perplexity is 44.18612099475458
At time: 663.1483333110809 and batch: 900, loss is 3.7682411575317385 and perplexity is 43.303833194918184
At time: 664.186240196228 and batch: 950, loss is 3.864694232940674 and perplexity is 47.68868857310229
At time: 665.228193283081 and batch: 1000, loss is 3.8205596446990966 and perplexity is 45.629737617293394
At time: 666.2676661014557 and batch: 1050, loss is 3.7803955936431883 and perplexity is 43.833378512087435
At time: 667.31787109375 and batch: 1100, loss is 3.7970125007629396 and perplexity is 44.56783902265467
At time: 668.3570914268494 and batch: 1150, loss is 3.776132230758667 and perplexity is 43.64689871102584
At time: 669.3961634635925 and batch: 1200, loss is 3.820364446640015 and perplexity is 45.6208316503161
At time: 670.436591386795 and batch: 1250, loss is 3.8009279584884643 and perplexity is 44.742684589100875
At time: 671.4810256958008 and batch: 1300, loss is 3.8113223028182985 and perplexity is 45.210180908709745
At time: 672.5236055850983 and batch: 1350, loss is 3.6920211696624756 and perplexity is 40.12586623636858
At time: 673.5661671161652 and batch: 1400, loss is 3.7227542781829834 and perplexity is 41.37820438967773
At time: 674.610799074173 and batch: 1450, loss is 3.62757239818573 and perplexity is 37.62137595081133
At time: 675.6514890193939 and batch: 1500, loss is 3.6376356792449953 and perplexity is 38.0018817882994
At time: 676.6913924217224 and batch: 1550, loss is 3.638844828605652 and perplexity is 38.04785953074463
At time: 677.7331473827362 and batch: 1600, loss is 3.747735929489136 and perplexity is 42.42492017187339
At time: 678.7785387039185 and batch: 1650, loss is 3.6712650299072265 and perplexity is 39.30159211580694
At time: 679.8203387260437 and batch: 1700, loss is 3.696746201515198 and perplexity is 40.31591086233233
At time: 680.8683905601501 and batch: 1750, loss is 3.6976342248916625 and perplexity is 40.35172823459972
At time: 681.9093790054321 and batch: 1800, loss is 3.646195650100708 and perplexity is 38.32857302780975
At time: 682.9503378868103 and batch: 1850, loss is 3.6770503091812134 and perplexity is 39.5296217737341
At time: 683.9927456378937 and batch: 1900, loss is 3.757272176742554 and perplexity is 42.831429908355894
At time: 685.03142619133 and batch: 1950, loss is 3.7047286319732664 and perplexity is 40.63901769036344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488269610737645 and perplexity of 88.96736443454938
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 688.2936940193176 and batch: 50, loss is 3.874880967140198 and perplexity is 48.17696330806073
At time: 689.3597292900085 and batch: 100, loss is 3.873693723678589 and perplexity is 48.11979946378783
At time: 690.4012751579285 and batch: 150, loss is 3.8377116441726686 and perplexity is 46.41912932337598
At time: 691.443409204483 and batch: 200, loss is 3.824244146347046 and perplexity is 45.798170565930725
At time: 692.4853208065033 and batch: 250, loss is 3.824725699424744 and perplexity is 45.82023012691815
At time: 693.5295517444611 and batch: 300, loss is 3.8389477062225343 and perplexity is 46.47654172285471
At time: 694.5709629058838 and batch: 350, loss is 3.838035225868225 and perplexity is 46.43415213437093
At time: 695.6163132190704 and batch: 400, loss is 3.8149043560028075 and perplexity is 45.37241657612871
At time: 696.6626920700073 and batch: 450, loss is 3.848519215583801 and perplexity is 46.92352813182848
At time: 697.7084975242615 and batch: 500, loss is 3.8766121816635133 and perplexity is 48.2604402039871
At time: 698.7512531280518 and batch: 550, loss is 3.841848068237305 and perplexity is 46.6115361908269
At time: 699.7946655750275 and batch: 600, loss is 3.817115969657898 and perplexity is 45.47287387761609
At time: 700.8388564586639 and batch: 650, loss is 3.8414690780639646 and perplexity is 46.59387422371368
At time: 701.8823320865631 and batch: 700, loss is 3.858706340789795 and perplexity is 47.4039870806859
At time: 702.9273736476898 and batch: 750, loss is 3.8169618749618532 and perplexity is 45.4658672887906
At time: 703.9993958473206 and batch: 800, loss is 3.778529739379883 and perplexity is 43.75166806951004
At time: 705.042962551117 and batch: 850, loss is 3.789296646118164 and perplexity is 44.225283309455584
At time: 706.084543466568 and batch: 900, loss is 3.7656468248367307 and perplexity is 43.19163424826942
At time: 707.1408381462097 and batch: 950, loss is 3.8619294691085817 and perplexity is 47.557022708116435
At time: 708.1896498203278 and batch: 1000, loss is 3.8177861976623535 and perplexity is 45.50336128674838
At time: 709.2315580844879 and batch: 1050, loss is 3.778123183250427 and perplexity is 43.73388417600288
At time: 710.2729244232178 and batch: 1100, loss is 3.7938712310791014 and perplexity is 44.428059079248676
At time: 711.3170568943024 and batch: 1150, loss is 3.774211006164551 and perplexity is 43.56312371682346
At time: 712.361869096756 and batch: 1200, loss is 3.8187073612213136 and perplexity is 45.545296636668695
At time: 713.404310464859 and batch: 1250, loss is 3.7969279289245605 and perplexity is 44.56406999795486
At time: 714.445559501648 and batch: 1300, loss is 3.8064386892318725 and perplexity is 44.98993010263613
At time: 715.4869060516357 and batch: 1350, loss is 3.6848916673660277 and perplexity is 39.84080615659739
At time: 716.5301685333252 and batch: 1400, loss is 3.7158558797836303 and perplexity is 41.093743341641535
At time: 717.5746147632599 and batch: 1450, loss is 3.620544285774231 and perplexity is 37.357895660638434
At time: 718.6212019920349 and batch: 1500, loss is 3.6281266450881957 and perplexity is 37.64223326141453
At time: 719.669440984726 and batch: 1550, loss is 3.6300332307815553 and perplexity is 37.714069864375666
At time: 720.7118554115295 and batch: 1600, loss is 3.7384371519088746 and perplexity is 42.03224878670218
At time: 721.7566838264465 and batch: 1650, loss is 3.6606083869934083 and perplexity is 38.88499280030688
At time: 722.800281047821 and batch: 1700, loss is 3.6832277297973635 and perplexity is 39.77456866527527
At time: 723.8423421382904 and batch: 1750, loss is 3.683033471107483 and perplexity is 39.76684286010247
At time: 724.8854911327362 and batch: 1800, loss is 3.632098150253296 and perplexity is 37.79202684133704
At time: 725.930073261261 and batch: 1850, loss is 3.6636256980895996 and perplexity is 39.00249810644163
At time: 726.9784002304077 and batch: 1900, loss is 3.7451607847213744 and perplexity is 42.31581040768487
At time: 728.0232784748077 and batch: 1950, loss is 3.695579237937927 and perplexity is 40.26889110328058
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487834415879361 and perplexity of 88.92865471873793
finished 17 epochs...
Completing Train Step...
At time: 731.3048756122589 and batch: 50, loss is 3.874325699806213 and perplexity is 48.15021963971504
At time: 732.3728549480438 and batch: 100, loss is 3.8718795824050902 and perplexity is 48.03258248538827
At time: 733.4149699211121 and batch: 150, loss is 3.83453209400177 and perplexity is 46.27177176232516
At time: 734.4616672992706 and batch: 200, loss is 3.8212112092971804 and perplexity is 45.6594780267915
At time: 735.5019450187683 and batch: 250, loss is 3.821225380897522 and perplexity is 45.66012509925091
At time: 736.5430917739868 and batch: 300, loss is 3.835266695022583 and perplexity is 46.30577554117275
At time: 737.5816652774811 and batch: 350, loss is 3.8343950939178466 and perplexity is 46.26543295992857
At time: 738.6239218711853 and batch: 400, loss is 3.811479926109314 and perplexity is 45.21730764786726
At time: 739.6646573543549 and batch: 450, loss is 3.8446722650527954 and perplexity is 46.74336240687048
At time: 740.7056250572205 and batch: 500, loss is 3.872643027305603 and perplexity is 48.06926671695819
At time: 741.7432420253754 and batch: 550, loss is 3.8376753425598142 and perplexity is 46.4174442646996
At time: 742.7825500965118 and batch: 600, loss is 3.8131990528106687 and perplexity is 45.295108784652804
At time: 743.8268284797668 and batch: 650, loss is 3.83806058883667 and perplexity is 46.4353298572415
At time: 744.8728969097137 and batch: 700, loss is 3.8554623556137084 and perplexity is 47.2504584063181
At time: 745.9190278053284 and batch: 750, loss is 3.814021348953247 and perplexity is 45.332370095700675
At time: 746.9602432250977 and batch: 800, loss is 3.775902090072632 and perplexity is 43.63685493959774
At time: 748.0024240016937 and batch: 850, loss is 3.786750717163086 and perplexity is 44.11283208728288
At time: 749.0451745986938 and batch: 900, loss is 3.763411965370178 and perplexity is 43.0952147976861
At time: 750.0871102809906 and batch: 950, loss is 3.8599065923690796 and perplexity is 47.46091794989216
At time: 751.1276414394379 and batch: 1000, loss is 3.8159614849090575 and perplexity is 45.42040643049973
At time: 752.1744945049286 and batch: 1050, loss is 3.7763658809661864 and perplexity is 43.657098009454955
At time: 753.2213323116302 and batch: 1100, loss is 3.792091226577759 and perplexity is 44.34904727564659
At time: 754.2627382278442 and batch: 1150, loss is 3.772523045539856 and perplexity is 43.48965290466423
At time: 755.3062505722046 and batch: 1200, loss is 3.817238521575928 and perplexity is 45.47844700702001
At time: 756.3856189250946 and batch: 1250, loss is 3.7957144165039063 and perplexity is 44.51002374502947
At time: 757.4249143600464 and batch: 1300, loss is 3.805372886657715 and perplexity is 44.94200526306689
At time: 758.4683883190155 and batch: 1350, loss is 3.684294943809509 and perplexity is 39.817039300879635
At time: 759.514627456665 and batch: 1400, loss is 3.715493931770325 and perplexity is 41.07887223432597
At time: 760.5556252002716 and batch: 1450, loss is 3.620747199058533 and perplexity is 37.365476843076834
At time: 761.6052625179291 and batch: 1500, loss is 3.6288300275802614 and perplexity is 37.66871946312615
At time: 762.6567301750183 and batch: 1550, loss is 3.630941047668457 and perplexity is 37.74832287925259
At time: 763.7069725990295 and batch: 1600, loss is 3.739683384895325 and perplexity is 42.084663415270654
At time: 764.75710105896 and batch: 1650, loss is 3.6620427846908568 and perplexity is 38.940809366451724
At time: 765.8130934238434 and batch: 1700, loss is 3.6849328899383544 and perplexity is 39.84244853096195
At time: 766.8659009933472 and batch: 1750, loss is 3.6849346685409547 and perplexity is 39.84251939490753
At time: 767.9283578395844 and batch: 1800, loss is 3.634192843437195 and perplexity is 37.871272511073656
At time: 768.9811728000641 and batch: 1850, loss is 3.665951385498047 and perplexity is 39.093311285786946
At time: 770.0437994003296 and batch: 1900, loss is 3.747475852966309 and perplexity is 42.413887880836
At time: 771.1015167236328 and batch: 1950, loss is 3.697668809890747 and perplexity is 40.35312382321685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48776969022529 and perplexity of 88.92289893967097
finished 18 epochs...
Completing Train Step...
At time: 774.463139295578 and batch: 50, loss is 3.8735612535476687 and perplexity is 48.11342544984556
At time: 775.509030342102 and batch: 100, loss is 3.8704091548919677 and perplexity is 47.96200595612709
At time: 776.5528938770294 and batch: 150, loss is 3.8324723720550535 and perplexity is 46.17656286410138
At time: 777.5934271812439 and batch: 200, loss is 3.8189940452575684 and perplexity is 45.55835561795221
At time: 778.6389355659485 and batch: 250, loss is 3.81881422996521 and perplexity is 45.5501642654047
At time: 779.6853775978088 and batch: 300, loss is 3.832727952003479 and perplexity is 46.18836617593731
At time: 780.73504114151 and batch: 350, loss is 3.831902570724487 and perplexity is 46.1502588918713
At time: 781.7797651290894 and batch: 400, loss is 3.8089526891708374 and perplexity is 45.103177075964965
At time: 782.8484425544739 and batch: 450, loss is 3.842121706008911 and perplexity is 46.62429261296116
At time: 783.8913300037384 and batch: 500, loss is 3.8700042390823364 and perplexity is 47.94258931297201
At time: 784.9339504241943 and batch: 550, loss is 3.8350126266479494 and perplexity is 46.29401220245432
At time: 785.9798710346222 and batch: 600, loss is 3.8106566667556763 and perplexity is 45.18009739534568
At time: 787.0265762805939 and batch: 650, loss is 3.835686902999878 and perplexity is 46.32523768623791
At time: 788.0699172019958 and batch: 700, loss is 3.8531729888916018 and perplexity is 47.142408509350204
At time: 789.1198697090149 and batch: 750, loss is 3.8119945335388183 and perplexity is 45.24058279859414
At time: 790.1704063415527 and batch: 800, loss is 3.7739816331863403 and perplexity is 43.5531326592795
At time: 791.2206935882568 and batch: 850, loss is 3.784920072555542 and perplexity is 44.03215104079208
At time: 792.267315864563 and batch: 900, loss is 3.7617608547210692 and perplexity is 43.02411853965407
At time: 793.3193521499634 and batch: 950, loss is 3.8584366464614868 and perplexity is 47.39120421804132
At time: 794.3660106658936 and batch: 1000, loss is 3.81455810546875 and perplexity is 45.356709072180486
At time: 795.407881975174 and batch: 1050, loss is 3.775048727989197 and perplexity is 43.59963278639788
At time: 796.4537315368652 and batch: 1100, loss is 3.7908550357818602 and perplexity is 44.29425726402896
At time: 797.5036664009094 and batch: 1150, loss is 3.7713791370391845 and perplexity is 43.43993316385405
At time: 798.5511655807495 and batch: 1200, loss is 3.8161974477767946 and perplexity is 45.4311252244238
At time: 799.592170715332 and batch: 1250, loss is 3.7948807144165038 and perplexity is 44.47293110957517
At time: 800.6351184844971 and batch: 1300, loss is 3.804699029922485 and perplexity is 44.91173099153212
At time: 801.6754050254822 and batch: 1350, loss is 3.683904519081116 and perplexity is 39.80149677841515
At time: 802.7184462547302 and batch: 1400, loss is 3.71532479763031 and perplexity is 41.071924982123164
At time: 803.7594811916351 and batch: 1450, loss is 3.6209248161315917 and perplexity is 37.372114179141796
At time: 804.8004925251007 and batch: 1500, loss is 3.6293161392211912 and perplexity is 37.68703511752183
At time: 805.8413953781128 and batch: 1550, loss is 3.6316038179397583 and perplexity is 37.77334963802818
At time: 806.8806903362274 and batch: 1600, loss is 3.7404960584640503 and perplexity is 42.118878409804736
At time: 807.9226260185242 and batch: 1650, loss is 3.662981939315796 and perplexity is 38.97739798616352
At time: 808.9651503562927 and batch: 1700, loss is 3.6860601329803466 and perplexity is 39.88738597679757
At time: 810.0077583789825 and batch: 1750, loss is 3.686187381744385 and perplexity is 39.89246192031075
At time: 811.0577023029327 and batch: 1800, loss is 3.6354825592041013 and perplexity is 37.92014719879697
At time: 812.1059670448303 and batch: 1850, loss is 3.667337384223938 and perplexity is 39.147532131751795
At time: 813.1592338085175 and batch: 1900, loss is 3.748827977180481 and perplexity is 42.47127551451821
At time: 814.2013373374939 and batch: 1950, loss is 3.6988873147964476 and perplexity is 40.40232427196231
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487748682776163 and perplexity of 88.92103091601648
finished 19 epochs...
Completing Train Step...
At time: 817.5053219795227 and batch: 50, loss is 3.8726436424255373 and perplexity is 48.06929628533146
At time: 818.5815052986145 and batch: 100, loss is 3.869009690284729 and perplexity is 47.894931771220314
At time: 819.6265270709991 and batch: 150, loss is 3.830737509727478 and perplexity is 46.09652233449642
At time: 820.6708109378815 and batch: 200, loss is 3.8171394538879393 and perplexity is 45.47394178558633
At time: 821.7133145332336 and batch: 250, loss is 3.8168172311782835 and perplexity is 45.459291409314176
At time: 822.7614605426788 and batch: 300, loss is 3.8306567239761353 and perplexity is 46.09279854272202
At time: 823.8101871013641 and batch: 350, loss is 3.8298938417434694 and perplexity is 46.0576485750076
At time: 824.8658893108368 and batch: 400, loss is 3.8068846702575683 and perplexity is 45.00999923270225
At time: 825.9110503196716 and batch: 450, loss is 3.8400999402999876 and perplexity is 46.53012444201922
At time: 826.9584095478058 and batch: 500, loss is 3.867937560081482 and perplexity is 47.84360968518127
At time: 828.0022728443146 and batch: 550, loss is 3.8329582166671754 and perplexity is 46.19900294913101
At time: 829.0466470718384 and batch: 600, loss is 3.808700542449951 and perplexity is 45.0918058914274
At time: 830.0909993648529 and batch: 650, loss is 3.833821792602539 and perplexity is 46.23891652803828
At time: 831.1349358558655 and batch: 700, loss is 3.8513730573654175 and perplexity is 47.057631721148844
At time: 832.1797368526459 and batch: 750, loss is 3.8103938913345337 and perplexity is 45.16822673595242
At time: 833.2266564369202 and batch: 800, loss is 3.772416319847107 and perplexity is 43.48501168900344
At time: 834.2713429927826 and batch: 850, loss is 3.7834287071228028 and perplexity is 43.966531955980436
At time: 835.3615052700043 and batch: 900, loss is 3.760400514602661 and perplexity is 42.965630895709076
At time: 836.406683921814 and batch: 950, loss is 3.8572254180908203 and perplexity is 47.33383739614693
At time: 837.4525208473206 and batch: 1000, loss is 3.813390464782715 and perplexity is 45.30377964057567
At time: 838.4994688034058 and batch: 1050, loss is 3.773967342376709 and perplexity is 43.55251025419916
At time: 839.5479063987732 and batch: 1100, loss is 3.7898743104934693 and perplexity is 44.25083806043524
At time: 840.5943350791931 and batch: 1150, loss is 3.7704887199401855 and perplexity is 43.40127071999057
At time: 841.6388983726501 and batch: 1200, loss is 3.815361804962158 and perplexity is 45.393176888904385
At time: 842.6840348243713 and batch: 1250, loss is 3.7942144298553466 and perplexity is 44.44330935154333
At time: 843.7308194637299 and batch: 1300, loss is 3.8041589307785033 and perplexity is 44.88748075342476
At time: 844.7760488986969 and batch: 1350, loss is 3.6835542726516723 and perplexity is 39.78755888727279
At time: 845.8230428695679 and batch: 1400, loss is 3.715159468650818 and perplexity is 41.065135163972414
At time: 846.8707554340363 and batch: 1450, loss is 3.620991311073303 and perplexity is 37.374599318319454
At time: 847.9154975414276 and batch: 1500, loss is 3.629594211578369 and perplexity is 37.69751629740766
At time: 848.9606952667236 and batch: 1550, loss is 3.632037401199341 and perplexity is 37.78973108119271
At time: 850.0052816867828 and batch: 1600, loss is 3.741026964187622 and perplexity is 42.141245500305736
At time: 851.0503821372986 and batch: 1650, loss is 3.6636009311676023 and perplexity is 39.0015321465753
At time: 852.0973517894745 and batch: 1700, loss is 3.6868077087402344 and perplexity is 39.91721596837917
At time: 853.1465227603912 and batch: 1750, loss is 3.6870253467559815 and perplexity is 39.925904417490784
At time: 854.1923115253448 and batch: 1800, loss is 3.6363183736801146 and perplexity is 37.951854655688145
At time: 855.236823797226 and batch: 1850, loss is 3.6682224798202516 and perplexity is 39.18219677854827
At time: 856.2800924777985 and batch: 1900, loss is 3.749685077667236 and perplexity is 42.507693270043376
At time: 857.3249709606171 and batch: 1950, loss is 3.6996470642089845 and perplexity is 40.433031577544675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487763444767442 and perplexity of 88.9223435771881
Annealing...
Finished Training.
Improved accuracyfrom -10000000 to -88.92103091601648
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea7e1b2b38>
ELAPSED
890.723495721817


RESULTS SO FAR:
[{'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.92103091601648}]
SETTINGS FOR THIS RUN
{'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.6813262795645527, 'dropout': 0.19794812537896078, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.526005506515503 and batch: 50, loss is 7.194832487106323 and perplexity is 1332.527091421274
At time: 2.560519218444824 and batch: 100, loss is 6.352868719100952 and perplexity is 574.1373877158647
At time: 3.623347759246826 and batch: 150, loss is 6.0649439716339115 and perplexity is 430.49855686573613
At time: 4.660719394683838 and batch: 200, loss is 5.9247773742675784 and perplexity is 374.1951206238164
At time: 5.694461107254028 and batch: 250, loss is 5.846360683441162 and perplexity is 345.972981355648
At time: 6.729729175567627 and batch: 300, loss is 5.765721340179443 and perplexity is 319.16919058049916
At time: 7.767898321151733 and batch: 350, loss is 5.717127914428711 and perplexity is 304.03046628537055
At time: 8.80909776687622 and batch: 400, loss is 5.653704824447632 and perplexity is 285.3466692615527
At time: 9.844709157943726 and batch: 450, loss is 5.584487266540528 and perplexity is 266.26372541263885
At time: 10.881081104278564 and batch: 500, loss is 5.565077152252197 and perplexity is 261.14535088453
At time: 11.916658639907837 and batch: 550, loss is 5.5046610832214355 and perplexity is 245.8351239100987
At time: 12.952717781066895 and batch: 600, loss is 5.527103967666626 and perplexity is 251.41475045044584
At time: 13.987433195114136 and batch: 650, loss is 5.604977703094482 and perplexity is 271.77586560595415
At time: 15.024373531341553 and batch: 700, loss is 5.5225855731964115 and perplexity is 250.28132199903217
At time: 16.06153130531311 and batch: 750, loss is 5.463846158981323 and perplexity is 236.00338755786072
At time: 17.09972620010376 and batch: 800, loss is 5.453303184509277 and perplexity is 233.5282802904176
At time: 18.14096760749817 and batch: 850, loss is 5.466361675262451 and perplexity is 236.59780524189742
At time: 19.181495428085327 and batch: 900, loss is 5.482070770263672 and perplexity is 240.34388940094027
At time: 20.222625970840454 and batch: 950, loss is 5.5170198249816895 and perplexity is 248.89218854744632
At time: 21.263219118118286 and batch: 1000, loss is 5.482273235321045 and perplexity is 240.39255556672984
At time: 22.30480933189392 and batch: 1050, loss is 5.382229795455933 and perplexity is 217.50673062580353
At time: 23.344117879867554 and batch: 1100, loss is 5.469286975860595 and perplexity is 237.2909382600237
At time: 24.384703874588013 and batch: 1150, loss is 5.367805852890014 and perplexity is 214.3919437912202
At time: 25.422720909118652 and batch: 1200, loss is 5.441360101699829 and perplexity is 230.75582150755037
At time: 26.474046230316162 and batch: 1250, loss is 5.381728935241699 and perplexity is 217.39781743552373
At time: 27.51322317123413 and batch: 1300, loss is 5.400992174148559 and perplexity is 221.62619894001472
At time: 28.55629253387451 and batch: 1350, loss is 5.3618918132781985 and perplexity is 213.1277632347769
At time: 29.601546049118042 and batch: 1400, loss is 5.365181741714477 and perplexity is 213.83009299745277
At time: 30.64210343360901 and batch: 1450, loss is 5.316172285079956 and perplexity is 203.60305410507692
At time: 31.68288803100586 and batch: 1500, loss is 5.299206476211548 and perplexity is 200.17790100773541
At time: 32.72553825378418 and batch: 1550, loss is 5.2833168315887455 and perplexity is 197.02228252168374
At time: 33.76752805709839 and batch: 1600, loss is 5.325344095230102 and perplexity is 205.4790526635689
At time: 34.80891680717468 and batch: 1650, loss is 5.296607656478882 and perplexity is 199.65835013050332
At time: 35.85188174247742 and batch: 1700, loss is 5.318747577667236 and perplexity is 204.12806728216987
At time: 36.89586877822876 and batch: 1750, loss is 5.327290763854981 and perplexity is 205.879441874576
At time: 37.93798851966858 and batch: 1800, loss is 5.303490571975708 and perplexity is 201.03732191180197
At time: 38.9809844493866 and batch: 1850, loss is 5.290737476348877 and perplexity is 198.48975294449204
At time: 40.02357196807861 and batch: 1900, loss is 5.3248092079162594 and perplexity is 205.36917391403304
At time: 41.071807622909546 and batch: 1950, loss is 5.248332576751709 and perplexity is 190.2487786008068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.911721588844477 and perplexity of 135.87313083525342
finished 1 epochs...
Completing Train Step...
At time: 44.4174485206604 and batch: 50, loss is 5.117214012145996 and perplexity is 166.86982411697417
At time: 45.45208930969238 and batch: 100, loss is 5.056482133865356 and perplexity is 157.03710796183861
At time: 46.48712611198425 and batch: 150, loss is 4.991272268295288 and perplexity is 147.12348501972195
At time: 47.5204222202301 and batch: 200, loss is 4.962624435424805 and perplexity is 142.96851560505812
At time: 48.55465579032898 and batch: 250, loss is 4.975161561965942 and perplexity is 144.7722129421778
At time: 49.58946180343628 and batch: 300, loss is 4.993201694488525 and perplexity is 147.4076229487945
At time: 50.623544454574585 and batch: 350, loss is 4.986212491989136 and perplexity is 146.38095320273763
At time: 51.66031813621521 and batch: 400, loss is 4.953772277832031 and perplexity is 141.7085208380669
At time: 52.69611048698425 and batch: 450, loss is 4.935593366622925 and perplexity is 139.155688380556
At time: 53.732154846191406 and batch: 500, loss is 4.928493814468384 and perplexity is 138.1712440053513
At time: 54.76725792884827 and batch: 550, loss is 4.897209157943726 and perplexity is 133.9155206119624
At time: 55.802818298339844 and batch: 600, loss is 4.8791501998901365 and perplexity is 131.5188516489531
At time: 56.85410761833191 and batch: 650, loss is 4.951303911209107 and perplexity is 141.35916360329642
At time: 57.92093586921692 and batch: 700, loss is 4.9353441143035885 and perplexity is 139.12100782476236
At time: 58.95739698410034 and batch: 750, loss is 4.8986515617370605 and perplexity is 134.1088202414251
At time: 59.9917688369751 and batch: 800, loss is 4.87141791343689 and perplexity is 130.50583174127507
At time: 61.034305810928345 and batch: 850, loss is 4.8725602912902835 and perplexity is 130.65500390245887
At time: 62.06898522377014 and batch: 900, loss is 4.890575008392334 and perplexity is 133.0300454558958
At time: 63.105366945266724 and batch: 950, loss is 4.958507423400879 and perplexity is 142.38112248921178
At time: 64.14302515983582 and batch: 1000, loss is 4.922626180648804 and perplexity is 137.3628796534089
At time: 65.18992495536804 and batch: 1050, loss is 4.835287561416626 and perplexity is 125.87477473151971
At time: 66.23463678359985 and batch: 1100, loss is 4.922681760787964 and perplexity is 137.37051451354685
At time: 67.27538800239563 and batch: 1150, loss is 4.844645643234253 and perplexity is 127.05825006496936
At time: 68.31472301483154 and batch: 1200, loss is 4.909283323287964 and perplexity is 135.54223962453602
At time: 69.35256338119507 and batch: 1250, loss is 4.870459384918213 and perplexity is 130.38079811341967
At time: 70.38862872123718 and batch: 1300, loss is 4.889145240783692 and perplexity is 132.839979313512
At time: 71.42759990692139 and batch: 1350, loss is 4.8026917457580565 and perplexity is 121.8379332664618
At time: 72.46528601646423 and batch: 1400, loss is 4.805480213165283 and perplexity is 122.1781484914256
At time: 73.50408983230591 and batch: 1450, loss is 4.752149028778076 and perplexity is 115.83294557510412
At time: 74.54197382926941 and batch: 1500, loss is 4.750892839431763 and perplexity is 115.68752881753383
At time: 75.57884240150452 and batch: 1550, loss is 4.746454095840454 and perplexity is 115.1751595196131
At time: 76.61547327041626 and batch: 1600, loss is 4.823578281402588 and perplexity is 124.40946733676287
At time: 77.6536455154419 and batch: 1650, loss is 4.784587430953979 and perplexity is 119.65198819266024
At time: 78.69087362289429 and batch: 1700, loss is 4.808179225921631 and perplexity is 122.50835428712499
At time: 79.7284734249115 and batch: 1750, loss is 4.816229639053344 and perplexity is 123.49857765687668
At time: 80.76654529571533 and batch: 1800, loss is 4.777316246032715 and perplexity is 118.78513181605247
At time: 81.80715155601501 and batch: 1850, loss is 4.796086988449097 and perplexity is 121.03587490230149
At time: 82.84346890449524 and batch: 1900, loss is 4.864766302108765 and perplexity is 129.64063832759516
At time: 83.88091564178467 and batch: 1950, loss is 4.784557085037232 and perplexity is 119.64835729847955
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.7094295058139535 and perplexity of 110.98882336240774
finished 2 epochs...
Completing Train Step...
At time: 87.1997983455658 and batch: 50, loss is 4.728373079299927 and perplexity is 113.11138931113551
At time: 88.26867389678955 and batch: 100, loss is 4.6826445007324216 and perplexity is 108.05544777840913
At time: 89.30881762504578 and batch: 150, loss is 4.627678728103637 and perplexity is 102.27637706934371
At time: 90.34748673439026 and batch: 200, loss is 4.61412109375 and perplexity is 100.89910869273177
At time: 91.38633584976196 and batch: 250, loss is 4.621919355392456 and perplexity is 101.68902231528703
At time: 92.42632818222046 and batch: 300, loss is 4.647558889389038 and perplexity is 104.32999341773288
At time: 93.46430802345276 and batch: 350, loss is 4.658644361495972 and perplexity is 105.49297483908454
At time: 94.50395703315735 and batch: 400, loss is 4.621943740844727 and perplexity is 101.69150207832212
At time: 95.5433247089386 and batch: 450, loss is 4.630486850738525 and perplexity is 102.56398530941513
At time: 96.58223247528076 and batch: 500, loss is 4.630227060317993 and perplexity is 102.5373436293166
At time: 97.62134766578674 and batch: 550, loss is 4.600674057006836 and perplexity is 99.55139634753253
At time: 98.65931582450867 and batch: 600, loss is 4.584279613494873 and perplexity is 97.93261239223293
At time: 99.69912600517273 and batch: 650, loss is 4.651179761886596 and perplexity is 104.70844376832311
At time: 100.73955154418945 and batch: 700, loss is 4.648002185821533 and perplexity is 104.37625278416571
At time: 101.78023386001587 and batch: 750, loss is 4.610990648269653 and perplexity is 100.5837434084082
At time: 102.81859016418457 and batch: 800, loss is 4.580622930526733 and perplexity is 97.57515782379244
At time: 103.85843849182129 and batch: 850, loss is 4.5896416187286375 and perplexity is 98.45913792725847
At time: 104.8954164981842 and batch: 900, loss is 4.6038527679443355 and perplexity is 99.86834493704376
At time: 105.93404960632324 and batch: 950, loss is 4.675837469100952 and perplexity is 107.32240866812094
At time: 106.97443222999573 and batch: 1000, loss is 4.641551122665406 and perplexity is 103.70508219501475
At time: 108.01416826248169 and batch: 1050, loss is 4.572476444244384 and perplexity is 96.78349216405341
At time: 109.05460453033447 and batch: 1100, loss is 4.645346536636352 and perplexity is 104.09943380324593
At time: 110.14240884780884 and batch: 1150, loss is 4.582501964569092 and perplexity is 97.75867723264317
At time: 111.18166637420654 and batch: 1200, loss is 4.6500390434265135 and perplexity is 104.58906901302814
At time: 112.2186164855957 and batch: 1250, loss is 4.6201142311096195 and perplexity is 101.50562656766569
At time: 113.2565369606018 and batch: 1300, loss is 4.633858509063721 and perplexity is 102.91037965789013
At time: 114.29610252380371 and batch: 1350, loss is 4.534220409393311 and perplexity is 93.15086744904218
At time: 115.33856987953186 and batch: 1400, loss is 4.538308801651001 and perplexity is 93.53248430245368
At time: 116.38444089889526 and batch: 1450, loss is 4.477393989562988 and perplexity is 88.00503155129911
At time: 117.42381596565247 and batch: 1500, loss is 4.484290981292725 and perplexity is 88.61409947994854
At time: 118.45982503890991 and batch: 1550, loss is 4.488160333633423 and perplexity is 88.95764286977558
At time: 119.49761891365051 and batch: 1600, loss is 4.576583490371704 and perplexity is 97.18180381300441
At time: 120.53830909729004 and batch: 1650, loss is 4.530996370315552 and perplexity is 92.85102901739033
At time: 121.57766795158386 and batch: 1700, loss is 4.563258037567139 and perplexity is 95.89540224971478
At time: 122.61670565605164 and batch: 1750, loss is 4.564576301574707 and perplexity is 96.02190106809213
At time: 123.65662670135498 and batch: 1800, loss is 4.521707420349121 and perplexity is 91.99253388657408
At time: 124.69475436210632 and batch: 1850, loss is 4.558418712615967 and perplexity is 95.43245431812691
At time: 125.73295021057129 and batch: 1900, loss is 4.637794075012207 and perplexity is 103.3161882632955
At time: 126.7724084854126 and batch: 1950, loss is 4.557445592880249 and perplexity is 95.33963228420346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.635878735919332 and perplexity of 103.11849211700448
finished 3 epochs...
Completing Train Step...
At time: 130.0925440788269 and batch: 50, loss is 4.506294240951538 and perplexity is 90.58550768718973
At time: 131.1367530822754 and batch: 100, loss is 4.469881935119629 and perplexity is 87.34640986121133
At time: 132.18066835403442 and batch: 150, loss is 4.421991176605225 and perplexity is 83.26190957654264
At time: 133.2234079837799 and batch: 200, loss is 4.416661014556885 and perplexity is 82.81929076895317
At time: 134.26652812957764 and batch: 250, loss is 4.412736406326294 and perplexity is 82.4948944793012
At time: 135.30883288383484 and batch: 300, loss is 4.43977047920227 and perplexity is 84.75548629438003
At time: 136.35213613510132 and batch: 350, loss is 4.4532005310058596 and perplexity is 85.9014347151256
At time: 137.42162418365479 and batch: 400, loss is 4.41533055305481 and perplexity is 82.7091761588238
At time: 138.46485257148743 and batch: 450, loss is 4.434190673828125 and perplexity is 84.28388412420831
At time: 139.50662994384766 and batch: 500, loss is 4.446029872894287 and perplexity is 85.28766808074035
At time: 140.54705095291138 and batch: 550, loss is 4.412986936569214 and perplexity is 82.51556453438361
At time: 141.58861017227173 and batch: 600, loss is 4.395440368652344 and perplexity is 81.0803281369816
At time: 142.6309154033661 and batch: 650, loss is 4.460573377609253 and perplexity is 86.53711331714109
At time: 143.67513918876648 and batch: 700, loss is 4.462959222793579 and perplexity is 86.74382396396068
At time: 144.71745467185974 and batch: 750, loss is 4.430828437805176 and perplexity is 84.00097767848602
At time: 145.7572660446167 and batch: 800, loss is 4.399472818374634 and perplexity is 81.40794058008085
At time: 146.79591393470764 and batch: 850, loss is 4.409380712509155 and perplexity is 82.21853082718769
At time: 147.83795595169067 and batch: 900, loss is 4.415802640914917 and perplexity is 82.74823137482915
At time: 148.8820207118988 and batch: 950, loss is 4.492958984375 and perplexity is 89.38554538495177
At time: 149.92493867874146 and batch: 1000, loss is 4.457005805969239 and perplexity is 86.2289360150259
At time: 150.96846771240234 and batch: 1050, loss is 4.402178716659546 and perplexity is 81.62852048568045
At time: 152.01006245613098 and batch: 1100, loss is 4.468739929199219 and perplexity is 87.2467166799597
At time: 153.0521845817566 and batch: 1150, loss is 4.405734128952027 and perplexity is 81.91926007411675
At time: 154.09346532821655 and batch: 1200, loss is 4.474690408706665 and perplexity is 87.76742417284633
At time: 155.1357719898224 and batch: 1250, loss is 4.448226976394653 and perplexity is 85.47525991869759
At time: 156.1774764060974 and batch: 1300, loss is 4.462438230514526 and perplexity is 86.69864287194198
At time: 157.22076392173767 and batch: 1350, loss is 4.354479274749756 and perplexity is 77.82628866986782
At time: 158.26436471939087 and batch: 1400, loss is 4.357880668640137 and perplexity is 78.09145724839684
At time: 159.30889797210693 and batch: 1450, loss is 4.29890221118927 and perplexity is 73.61893128376778
At time: 160.3502914905548 and batch: 1500, loss is 4.312006206512451 and perplexity is 74.58998184072203
At time: 161.39292168617249 and batch: 1550, loss is 4.313664903640747 and perplexity is 74.7138066949763
At time: 162.43580794334412 and batch: 1600, loss is 4.411513051986694 and perplexity is 82.3940356977379
At time: 163.47926020622253 and batch: 1650, loss is 4.360613059997559 and perplexity is 78.30512545090924
At time: 164.52441477775574 and batch: 1700, loss is 4.398116750717163 and perplexity is 81.29762072230021
At time: 165.56720876693726 and batch: 1750, loss is 4.400318832397461 and perplexity is 81.47684198104712
At time: 166.6092336177826 and batch: 1800, loss is 4.3486988067626955 and perplexity is 77.37771403436837
At time: 167.65264129638672 and batch: 1850, loss is 4.392627687454223 and perplexity is 80.85259544236352
At time: 168.69785237312317 and batch: 1900, loss is 4.472422037124634 and perplexity is 87.56856067544885
At time: 169.74377012252808 and batch: 1950, loss is 4.392455186843872 and perplexity is 80.83864952317559
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6144312658975295 and perplexity of 100.93040964004892
finished 4 epochs...
Completing Train Step...
At time: 173.03107714653015 and batch: 50, loss is 4.351052703857422 and perplexity is 77.56006774736883
At time: 174.09375286102295 and batch: 100, loss is 4.315056076049805 and perplexity is 74.81781881404606
At time: 175.13290452957153 and batch: 150, loss is 4.274426355361938 and perplexity is 71.83891747763278
At time: 176.1708288192749 and batch: 200, loss is 4.264840173721313 and perplexity is 71.15354685794816
At time: 177.2114315032959 and batch: 250, loss is 4.264849128723145 and perplexity is 71.15418404094358
At time: 178.24909138679504 and batch: 300, loss is 4.287029724121094 and perplexity is 72.7500595145799
At time: 179.2880892753601 and batch: 350, loss is 4.29904052734375 and perplexity is 73.62911467548744
At time: 180.32722353935242 and batch: 400, loss is 4.26167236328125 and perplexity is 70.92850254641752
At time: 181.36472606658936 and batch: 450, loss is 4.289702644348145 and perplexity is 72.94477473337037
At time: 182.4035451412201 and batch: 500, loss is 4.305391454696656 and perplexity is 74.09821587091979
At time: 183.44562339782715 and batch: 550, loss is 4.276362380981445 and perplexity is 71.97813418241641
At time: 184.4851851463318 and batch: 600, loss is 4.25624834060669 and perplexity is 70.54482621553902
At time: 185.52859020233154 and batch: 650, loss is 4.3233952140808105 and perplexity is 75.44434364004609
At time: 186.56976437568665 and batch: 700, loss is 4.322849245071411 and perplexity is 75.40316460874448
At time: 187.61274433135986 and batch: 750, loss is 4.287551107406617 and perplexity is 72.7880000695577
At time: 188.6517848968506 and batch: 800, loss is 4.26040853023529 and perplexity is 70.83891738326804
At time: 189.7351257801056 and batch: 850, loss is 4.270303621292114 and perplexity is 71.54335440761649
At time: 190.77642440795898 and batch: 900, loss is 4.276368436813354 and perplexity is 71.97857007121796
At time: 191.8160216808319 and batch: 950, loss is 4.354700937271118 and perplexity is 77.84354175335298
At time: 192.8567168712616 and batch: 1000, loss is 4.316292924880981 and perplexity is 74.91041439736253
At time: 193.8998167514801 and batch: 1050, loss is 4.269007835388184 and perplexity is 71.45070957435274
At time: 194.94085574150085 and batch: 1100, loss is 4.332750148773194 and perplexity is 76.15343211458969
At time: 195.98208570480347 and batch: 1150, loss is 4.271144275665283 and perplexity is 71.60352292829204
At time: 197.02396440505981 and batch: 1200, loss is 4.338730320930481 and perplexity is 76.61020718449835
At time: 198.06662940979004 and batch: 1250, loss is 4.317219791412353 and perplexity is 74.97987854034032
At time: 199.10847449302673 and batch: 1300, loss is 4.326739330291748 and perplexity is 75.69706061458844
At time: 200.14861941337585 and batch: 1350, loss is 4.218759942054748 and perplexity is 67.94917111409923
At time: 201.18963479995728 and batch: 1400, loss is 4.222765216827392 and perplexity is 68.221871971356
At time: 202.2280478477478 and batch: 1450, loss is 4.1607544898986815 and perplexity is 64.11988215763624
At time: 203.26580834388733 and batch: 1500, loss is 4.173725557327271 and perplexity is 64.95700291048236
At time: 204.30693697929382 and batch: 1550, loss is 4.181129875183106 and perplexity is 65.43975020870765
At time: 205.34888219833374 and batch: 1600, loss is 4.282084503173828 and perplexity is 72.39118249080873
At time: 206.39049983024597 and batch: 1650, loss is 4.2289308738708495 and perplexity is 68.64380404436665
At time: 207.4309995174408 and batch: 1700, loss is 4.267290263175965 and perplexity is 71.32809315246776
At time: 208.47420287132263 and batch: 1750, loss is 4.270052347183228 and perplexity is 71.52537967337821
At time: 209.51072549819946 and batch: 1800, loss is 4.218379430770874 and perplexity is 67.92332060627726
At time: 210.54831647872925 and batch: 1850, loss is 4.260930824279785 and perplexity is 70.87592579173014
At time: 211.59137558937073 and batch: 1900, loss is 4.343287181854248 and perplexity is 76.96010585830632
At time: 212.63319277763367 and batch: 1950, loss is 4.262437515258789 and perplexity is 70.98279439851495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.604895303415698 and perplexity of 99.97251552043593
finished 5 epochs...
Completing Train Step...
At time: 215.9649498462677 and batch: 50, loss is 4.227423324584961 and perplexity is 68.54039809096872
At time: 217.00600123405457 and batch: 100, loss is 4.191214561462402 and perplexity is 66.10302841474703
At time: 218.04598212242126 and batch: 150, loss is 4.158857507705688 and perplexity is 63.998363179076534
At time: 219.08594274520874 and batch: 200, loss is 4.147742438316345 and perplexity is 63.290955656413665
At time: 220.12706446647644 and batch: 250, loss is 4.1454527759552 and perplexity is 63.146206514015795
At time: 221.1691324710846 and batch: 300, loss is 4.164132723808288 and perplexity is 64.33686041311664
At time: 222.21034622192383 and batch: 350, loss is 4.172979445457458 and perplexity is 64.90855579531473
At time: 223.25148344039917 and batch: 400, loss is 4.140231924057007 and perplexity is 62.81738862351744
At time: 224.2910647392273 and batch: 450, loss is 4.168478484153748 and perplexity is 64.61706139202182
At time: 225.33353900909424 and batch: 500, loss is 4.1902279996871945 and perplexity is 66.03784585228671
At time: 226.37206506729126 and batch: 550, loss is 4.163037128448487 and perplexity is 64.26641184599224
At time: 227.4142529964447 and batch: 600, loss is 4.145874981880188 and perplexity is 63.17287284549195
At time: 228.456316947937 and batch: 650, loss is 4.205227718353272 and perplexity is 67.03586122427075
At time: 229.49974846839905 and batch: 700, loss is 4.205680289268494 and perplexity is 67.06620657153056
At time: 230.53922414779663 and batch: 750, loss is 4.176266942024231 and perplexity is 65.12229358827634
At time: 231.5785617828369 and batch: 800, loss is 4.14635009765625 and perplexity is 63.20289440529363
At time: 232.61665868759155 and batch: 850, loss is 4.161607699394226 and perplexity is 64.17461319514659
At time: 233.6551513671875 and batch: 900, loss is 4.160152268409729 and perplexity is 64.0812794116001
At time: 234.69511032104492 and batch: 950, loss is 4.239716730117798 and perplexity is 69.38819346918439
At time: 235.73691511154175 and batch: 1000, loss is 4.206187081336975 and perplexity is 67.10020380712118
At time: 236.78229689598083 and batch: 1050, loss is 4.162281560897827 and perplexity is 64.21787257026409
At time: 237.82209730148315 and batch: 1100, loss is 4.2229187250137326 and perplexity is 68.23234539104831
At time: 238.86188507080078 and batch: 1150, loss is 4.162219710350037 and perplexity is 64.2139007824976
At time: 239.90201330184937 and batch: 1200, loss is 4.225429821014404 and perplexity is 68.40389866389934
At time: 240.94122099876404 and batch: 1250, loss is 4.208492407798767 and perplexity is 67.25507012267018
At time: 241.9806010723114 and batch: 1300, loss is 4.217024297714233 and perplexity is 67.83133780774868
At time: 243.01977682113647 and batch: 1350, loss is 4.108935165405273 and perplexity is 60.88185393696796
At time: 244.059472322464 and batch: 1400, loss is 4.114880647659302 and perplexity is 61.24490410385771
At time: 245.0976278781891 and batch: 1450, loss is 4.052405672073364 and perplexity is 57.53570272515608
At time: 246.13782000541687 and batch: 1500, loss is 4.071435961723328 and perplexity is 58.64110854953685
At time: 247.17754244804382 and batch: 1550, loss is 4.070530519485474 and perplexity is 58.5880364434706
At time: 248.21649289131165 and batch: 1600, loss is 4.177644205093384 and perplexity is 65.21204591030599
At time: 249.25438475608826 and batch: 1650, loss is 4.122203965187072 and perplexity is 61.69506631207815
At time: 250.29227089881897 and batch: 1700, loss is 4.159715566635132 and perplexity is 64.05330111269362
At time: 251.3306908607483 and batch: 1750, loss is 4.163522009849548 and perplexity is 64.29758098986771
At time: 252.36730551719666 and batch: 1800, loss is 4.1100851345062255 and perplexity is 60.951906459202206
At time: 253.4064428806305 and batch: 1850, loss is 4.153226976394653 and perplexity is 63.63903095632914
At time: 254.44686698913574 and batch: 1900, loss is 4.231342535018921 and perplexity is 68.80954942014515
At time: 255.48695516586304 and batch: 1950, loss is 4.154036264419556 and perplexity is 63.690554107721155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.608994310955668 and perplexity of 100.38314462630022
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 258.7887942790985 and batch: 50, loss is 4.1535700416564945 and perplexity is 63.66086704253465
At time: 259.8577666282654 and batch: 100, loss is 4.136600337028503 and perplexity is 62.58967554003259
At time: 260.90120220184326 and batch: 150, loss is 4.112427115440369 and perplexity is 61.094821949383146
At time: 261.9454274177551 and batch: 200, loss is 4.0979440927505495 and perplexity is 60.21636099710516
At time: 262.98944759368896 and batch: 250, loss is 4.093899550437928 and perplexity is 59.973305233133075
At time: 264.0329575538635 and batch: 300, loss is 4.10491494178772 and perplexity is 60.63758660353288
At time: 265.0739166736603 and batch: 350, loss is 4.11401138305664 and perplexity is 61.19168920888996
At time: 266.11677527427673 and batch: 400, loss is 4.074327087402343 and perplexity is 58.8108926796764
At time: 267.161235332489 and batch: 450, loss is 4.09637378692627 and perplexity is 60.12187709843801
At time: 268.2028179168701 and batch: 500, loss is 4.11130533695221 and perplexity is 61.02632551847671
At time: 269.2736322879791 and batch: 550, loss is 4.08405915260315 and perplexity is 59.38603825941605
At time: 270.3150746822357 and batch: 600, loss is 4.054211101531982 and perplexity is 57.639673205220504
At time: 271.36080408096313 and batch: 650, loss is 4.097788686752319 and perplexity is 60.20700374052036
At time: 272.4036178588867 and batch: 700, loss is 4.0927372169494625 and perplexity is 59.90363674889644
At time: 273.4438762664795 and batch: 750, loss is 4.05739474773407 and perplexity is 57.82346994857094
At time: 274.4855477809906 and batch: 800, loss is 4.02405704498291 and perplexity is 55.9275467486416
At time: 275.52804374694824 and batch: 850, loss is 4.032453908920288 and perplexity is 56.39913993003576
At time: 276.56954288482666 and batch: 900, loss is 4.013165616989136 and perplexity is 55.3217210426243
At time: 277.61334013938904 and batch: 950, loss is 4.0985020780563355 and perplexity is 60.24997021756302
At time: 278.6579113006592 and batch: 1000, loss is 4.0545815753936765 and perplexity is 57.66103115357615
At time: 279.7074100971222 and batch: 1050, loss is 4.002672204971313 and perplexity is 54.74424258878071
At time: 280.7482981681824 and batch: 1100, loss is 4.050897693634033 and perplexity is 57.44900551114861
At time: 281.79099917411804 and batch: 1150, loss is 3.9902962923049925 and perplexity is 54.070907784042376
At time: 282.83621549606323 and batch: 1200, loss is 4.043296189308166 and perplexity is 57.013962233751755
At time: 283.881224155426 and batch: 1250, loss is 4.016623110771179 and perplexity is 55.51332659577015
At time: 284.9256389141083 and batch: 1300, loss is 4.021041979789734 and perplexity is 55.75917550179289
At time: 285.96890783309937 and batch: 1350, loss is 3.904346046447754 and perplexity is 49.617621680294036
At time: 287.0105412006378 and batch: 1400, loss is 3.9027515411376954 and perplexity is 49.53856916063243
At time: 288.0554563999176 and batch: 1450, loss is 3.8293643856048583 and perplexity is 46.033269524628004
At time: 289.09945917129517 and batch: 1500, loss is 3.8466725826263426 and perplexity is 46.83695755494109
At time: 290.15053367614746 and batch: 1550, loss is 3.839738030433655 and perplexity is 46.51328777776319
At time: 291.19537568092346 and batch: 1600, loss is 3.934020857810974 and perplexity is 51.112079454224514
At time: 292.2441017627716 and batch: 1650, loss is 3.868755693435669 and perplexity is 47.88276815429006
At time: 293.29040718078613 and batch: 1700, loss is 3.8959274816513063 and perplexity is 49.201665849330894
At time: 294.3345561027527 and batch: 1750, loss is 3.885772533416748 and perplexity is 48.7045538249791
At time: 295.3819947242737 and batch: 1800, loss is 3.826141381263733 and perplexity is 45.88514293166524
At time: 296.42909598350525 and batch: 1850, loss is 3.8562612104415894 and perplexity is 47.28821974404088
At time: 297.4746549129486 and batch: 1900, loss is 3.9212778997421265 and perplexity is 50.464892663648186
At time: 298.52428126335144 and batch: 1950, loss is 3.8513570070266723 and perplexity is 47.056876436280476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.52285525299782 and perplexity of 92.09818654459082
finished 7 epochs...
Completing Train Step...
At time: 301.8688111305237 and batch: 50, loss is 4.04192307472229 and perplexity is 56.93572925432457
At time: 302.91147089004517 and batch: 100, loss is 4.019527473449707 and perplexity is 55.67479179294122
At time: 303.95289492607117 and batch: 150, loss is 3.9904428148269653 and perplexity is 54.07883097026469
At time: 304.9995744228363 and batch: 200, loss is 3.9779286098480227 and perplexity is 53.4062943022202
At time: 306.0377309322357 and batch: 250, loss is 3.976151852607727 and perplexity is 53.311488530502785
At time: 307.07666873931885 and batch: 300, loss is 3.988451805114746 and perplexity is 53.971266608954615
At time: 308.11614656448364 and batch: 350, loss is 3.9992655420303347 and perplexity is 54.55806470901823
At time: 309.15430998802185 and batch: 400, loss is 3.961385545730591 and perplexity is 52.53005834850318
At time: 310.19640707969666 and batch: 450, loss is 3.992924242019653 and perplexity is 54.2131902844681
At time: 311.237340927124 and batch: 500, loss is 4.008974056243897 and perplexity is 55.09032198872925
At time: 312.27775979042053 and batch: 550, loss is 3.986023602485657 and perplexity is 53.84037242060013
At time: 313.3300726413727 and batch: 600, loss is 3.9596567058563235 and perplexity is 52.43932074702484
At time: 314.37101340293884 and batch: 650, loss is 4.005445146560669 and perplexity is 54.896255840361576
At time: 315.4112114906311 and batch: 700, loss is 4.004866709709168 and perplexity is 54.86451100505047
At time: 316.4508924484253 and batch: 750, loss is 3.9718709897994997 and perplexity is 53.08375715317268
At time: 317.49193477630615 and batch: 800, loss is 3.9387261486053466 and perplexity is 51.353143344255095
At time: 318.5298955440521 and batch: 850, loss is 3.951040425300598 and perplexity is 51.98942982385618
At time: 319.5696403980255 and batch: 900, loss is 3.93313054561615 and perplexity is 51.066593997716424
At time: 320.61072039604187 and batch: 950, loss is 4.023299298286438 and perplexity is 55.88518388703725
At time: 321.6868498325348 and batch: 1000, loss is 3.980961813926697 and perplexity is 53.56853241819517
At time: 322.73359417915344 and batch: 1050, loss is 3.933258638381958 and perplexity is 51.073135677943995
At time: 323.7751920223236 and batch: 1100, loss is 3.982160291671753 and perplexity is 53.63277159905884
At time: 324.81750750541687 and batch: 1150, loss is 3.926725597381592 and perplexity is 50.74056033559249
At time: 325.86024498939514 and batch: 1200, loss is 3.979074659347534 and perplexity is 53.46753564517824
At time: 326.90497183799744 and batch: 1250, loss is 3.959061093330383 and perplexity is 52.40809653042644
At time: 327.9467189311981 and batch: 1300, loss is 3.966705946922302 and perplexity is 52.810284129309075
At time: 328.98916888237 and batch: 1350, loss is 3.85191246509552 and perplexity is 47.083021818651346
At time: 330.0316550731659 and batch: 1400, loss is 3.8549406147003173 and perplexity is 47.225812338980965
At time: 331.0767812728882 and batch: 1450, loss is 3.7860620832443237 and perplexity is 44.08246495197466
At time: 332.11988139152527 and batch: 1500, loss is 3.8054921770095826 and perplexity is 44.947366730467664
At time: 333.16309118270874 and batch: 1550, loss is 3.801293044090271 and perplexity is 44.75902248121364
At time: 334.2088611125946 and batch: 1600, loss is 3.899755988121033 and perplexity is 49.390395791734036
At time: 335.25031089782715 and batch: 1650, loss is 3.8367645597457884 and perplexity is 46.37518730057176
At time: 336.29303336143494 and batch: 1700, loss is 3.87012433052063 and perplexity is 47.948347153204864
At time: 337.33457350730896 and batch: 1750, loss is 3.8645126104354857 and perplexity is 47.68002802051393
At time: 338.3775055408478 and batch: 1800, loss is 3.8082152938842775 and perplexity is 45.06993046523379
At time: 339.4183020591736 and batch: 1850, loss is 3.843224329948425 and perplexity is 46.675730027009806
At time: 340.46012783050537 and batch: 1900, loss is 3.911176404953003 and perplexity is 49.957687889496476
At time: 341.50409412384033 and batch: 1950, loss is 3.84623450756073 and perplexity is 46.81644394526562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.52272835664971 and perplexity of 92.08650036253333
finished 8 epochs...
Completing Train Step...
At time: 344.8790988922119 and batch: 50, loss is 3.987338662147522 and perplexity is 53.91122229824779
At time: 345.94861602783203 and batch: 100, loss is 3.962970185279846 and perplexity is 52.61336554499345
At time: 346.99206590652466 and batch: 150, loss is 3.934764919281006 and perplexity is 51.150124135235025
At time: 348.0637285709381 and batch: 200, loss is 3.9214636850357056 and perplexity is 50.474269169528625
At time: 349.10632157325745 and batch: 250, loss is 3.920184364318848 and perplexity is 50.40973767834992
At time: 350.1474895477295 and batch: 300, loss is 3.9339526653289796 and perplexity is 51.10859411350499
At time: 351.18907380104065 and batch: 350, loss is 3.943938822746277 and perplexity is 51.62152944354629
At time: 352.23151898384094 and batch: 400, loss is 3.905756826400757 and perplexity is 49.687670626482586
At time: 353.27384996414185 and batch: 450, loss is 3.9397845697402953 and perplexity is 51.40752537098312
At time: 354.3154842853546 and batch: 500, loss is 3.9575688457489013 and perplexity is 52.32994899736405
At time: 355.3586382865906 and batch: 550, loss is 3.9345192241668703 and perplexity is 51.13755834338761
At time: 356.39946699142456 and batch: 600, loss is 3.910229902267456 and perplexity is 49.910425174417156
At time: 357.44023418426514 and batch: 650, loss is 3.9571153831481936 and perplexity is 52.30622470204366
At time: 358.4818649291992 and batch: 700, loss is 3.95788498878479 and perplexity is 52.34649536167908
At time: 359.52566623687744 and batch: 750, loss is 3.9251395654678345 and perplexity is 50.66014797272162
At time: 360.56824254989624 and batch: 800, loss is 3.892391529083252 and perplexity is 49.02799831364927
At time: 361.609849691391 and batch: 850, loss is 3.9064700746536256 and perplexity is 49.72312291238358
At time: 362.6515598297119 and batch: 900, loss is 3.8878706979751585 and perplexity is 48.80685127456082
At time: 363.6912431716919 and batch: 950, loss is 3.9802979373931886 and perplexity is 53.532981328660995
At time: 364.73380875587463 and batch: 1000, loss is 3.9391627883911133 and perplexity is 51.37557106582482
At time: 365.77689480781555 and batch: 1050, loss is 3.8932730913162232 and perplexity is 49.071238602023
At time: 366.81959772109985 and batch: 1100, loss is 3.9422770977020263 and perplexity is 51.53581988782775
At time: 367.8638184070587 and batch: 1150, loss is 3.888543629646301 and perplexity is 48.83970600380633
At time: 368.9086413383484 and batch: 1200, loss is 3.9400016260147095 and perplexity is 51.41868490799695
At time: 369.9511253833771 and batch: 1250, loss is 3.9231181859970095 and perplexity is 50.557848017967714
At time: 370.9925425052643 and batch: 1300, loss is 3.932115521430969 and perplexity is 51.01478646715018
At time: 372.03338599205017 and batch: 1350, loss is 3.8168395233154295 and perplexity is 45.460304805368175
At time: 373.07412242889404 and batch: 1400, loss is 3.8231058979034422 and perplexity is 45.74607052658362
At time: 374.11668038368225 and batch: 1450, loss is 3.75539888381958 and perplexity is 42.75126919951385
At time: 375.15917229652405 and batch: 1500, loss is 3.775153555870056 and perplexity is 43.604203483073164
At time: 376.2007350921631 and batch: 1550, loss is 3.772661066055298 and perplexity is 43.495655783225196
At time: 377.24154782295227 and batch: 1600, loss is 3.8718863105773926 and perplexity is 48.03290565796654
At time: 378.28285694122314 and batch: 1650, loss is 3.8098395442962647 and perplexity is 45.14319480206772
At time: 379.32638573646545 and batch: 1700, loss is 3.845441098213196 and perplexity is 46.779314072562954
At time: 380.3738043308258 and batch: 1750, loss is 3.84156662940979 and perplexity is 46.59841974055845
At time: 381.41743636131287 and batch: 1800, loss is 3.7864066886901857 and perplexity is 44.09765862722539
At time: 382.46002197265625 and batch: 1850, loss is 3.822691102027893 and perplexity is 45.727099180096765
At time: 383.5009706020355 and batch: 1900, loss is 3.892387380599976 and perplexity is 49.0277949222401
At time: 384.54153990745544 and batch: 1950, loss is 3.8294339179992676 and perplexity is 46.03647043936289
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.526065986101018 and perplexity of 92.39436446055694
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 387.904794216156 and batch: 50, loss is 3.961777982711792 and perplexity is 52.55067713154566
At time: 388.9464662075043 and batch: 100, loss is 3.9576608085632325 and perplexity is 52.33476162803579
At time: 389.98844170570374 and batch: 150, loss is 3.940908031463623 and perplexity is 51.465312212602704
At time: 391.0308654308319 and batch: 200, loss is 3.9307220458984373 and perplexity is 50.9437481170073
At time: 392.06893825531006 and batch: 250, loss is 3.932415499687195 and perplexity is 51.030092089398494
At time: 393.11107993125916 and batch: 300, loss is 3.9475957584381103 and perplexity is 51.81065165014542
At time: 394.154629945755 and batch: 350, loss is 3.958079471588135 and perplexity is 52.356676844871906
At time: 395.19697618484497 and batch: 400, loss is 3.9207314538955687 and perplexity is 50.43732386576871
At time: 396.237722158432 and batch: 450, loss is 3.951071333885193 and perplexity is 51.99103676837999
At time: 397.28378915786743 and batch: 500, loss is 3.9682577228546143 and perplexity is 52.892297473909245
At time: 398.3256528377533 and batch: 550, loss is 3.9471362733840945 and perplexity is 51.786850898536926
At time: 399.36624121665955 and batch: 600, loss is 3.916474390029907 and perplexity is 50.22306533655696
At time: 400.40748023986816 and batch: 650, loss is 3.9529583644866944 and perplexity is 52.089238071057046
At time: 401.49481749534607 and batch: 700, loss is 3.949667558670044 and perplexity is 51.91810424196775
At time: 402.5378098487854 and batch: 750, loss is 3.910912480354309 and perplexity is 49.9445045665467
At time: 403.5803108215332 and batch: 800, loss is 3.873742437362671 and perplexity is 48.12214361359263
At time: 404.62070178985596 and batch: 850, loss is 3.8882356452941895 and perplexity is 48.8246664546872
At time: 405.66269302368164 and batch: 900, loss is 3.861813850402832 and perplexity is 47.55152454455301
At time: 406.70377707481384 and batch: 950, loss is 3.9590072345733645 and perplexity is 52.40527397150004
At time: 407.74603295326233 and batch: 1000, loss is 3.9158287239074707 and perplexity is 50.19064847106633
At time: 408.7901291847229 and batch: 1050, loss is 3.8692465353012087 and perplexity is 47.90627679057757
At time: 409.8347382545471 and batch: 1100, loss is 3.9099903392791746 and perplexity is 49.89846991589188
At time: 410.8795645236969 and batch: 1150, loss is 3.8564530324935915 and perplexity is 47.2972915374449
At time: 411.92493414878845 and batch: 1200, loss is 3.9054757928848267 and perplexity is 49.673708687686315
At time: 412.96723341941833 and batch: 1250, loss is 3.8795625019073485 and perplexity is 48.40303420324586
At time: 414.0112340450287 and batch: 1300, loss is 3.882033066749573 and perplexity is 48.52276487810339
At time: 415.0561270713806 and batch: 1350, loss is 3.7629294776916504 and perplexity is 43.074426902897535
At time: 416.1010935306549 and batch: 1400, loss is 3.7723638153076173 and perplexity is 43.482728588427115
At time: 417.14669394493103 and batch: 1450, loss is 3.7000674390792847 and perplexity is 40.450032181012816
At time: 418.1921970844269 and batch: 1500, loss is 3.7147353410720827 and perplexity is 41.04772200058732
At time: 419.2342085838318 and batch: 1550, loss is 3.7133892440795897 and perplexity is 40.992504957539104
At time: 420.27558064460754 and batch: 1600, loss is 3.812216725349426 and perplexity is 45.25063600242753
At time: 421.3188261985779 and batch: 1650, loss is 3.741843843460083 and perplexity is 42.17568387435255
At time: 422.3634920120239 and batch: 1700, loss is 3.770294442176819 and perplexity is 43.3928396372003
At time: 423.4089844226837 and batch: 1750, loss is 3.761996040344238 and perplexity is 43.03423838375838
At time: 424.45059847831726 and batch: 1800, loss is 3.7050722551345827 and perplexity is 40.652984597633974
At time: 425.4950222969055 and batch: 1850, loss is 3.7331840896606447 and perplexity is 41.81202968612011
At time: 426.5375306606293 and batch: 1900, loss is 3.801968674659729 and perplexity is 44.78927326308678
At time: 427.5861678123474 and batch: 1950, loss is 3.7475074625015257 and perplexity is 42.41522858530807
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497370946130087 and perplexity of 89.78078223646405
finished 10 epochs...
Completing Train Step...
At time: 430.9697935581207 and batch: 50, loss is 3.943518581390381 and perplexity is 51.59984049963428
At time: 432.04819798469543 and batch: 100, loss is 3.927759008407593 and perplexity is 50.79302329333932
At time: 433.09628438949585 and batch: 150, loss is 3.9056668281555176 and perplexity is 49.68319902453736
At time: 434.14106822013855 and batch: 200, loss is 3.891558747291565 and perplexity is 48.98718568573622
At time: 435.18559885025024 and batch: 250, loss is 3.890935869216919 and perplexity is 48.956682142814245
At time: 436.2309458255768 and batch: 300, loss is 3.902953462600708 and perplexity is 49.54857307096101
At time: 437.2798728942871 and batch: 350, loss is 3.915365252494812 and perplexity is 50.16739193010445
At time: 438.32684779167175 and batch: 400, loss is 3.8768270921707155 and perplexity is 48.270812994240025
At time: 439.3704822063446 and batch: 450, loss is 3.9109732723236084 and perplexity is 49.94754088362589
At time: 440.4153640270233 and batch: 500, loss is 3.9279762935638427 and perplexity is 50.80406106247028
At time: 441.4605393409729 and batch: 550, loss is 3.9078041696548462 and perplexity is 49.7895025506326
At time: 442.5058445930481 and batch: 600, loss is 3.879830069541931 and perplexity is 48.415987021414416
At time: 443.5520875453949 and batch: 650, loss is 3.9178385829925535 and perplexity is 50.29162604323565
At time: 444.59788823127747 and batch: 700, loss is 3.916569356918335 and perplexity is 50.22783509128008
At time: 445.64738154411316 and batch: 750, loss is 3.8809800291061403 and perplexity is 48.47169547384506
At time: 446.6946134567261 and batch: 800, loss is 3.8444893074035646 and perplexity is 46.73481113345168
At time: 447.73862075805664 and batch: 850, loss is 3.8599222993850706 and perplexity is 47.46166342514393
At time: 448.7831687927246 and batch: 900, loss is 3.8350201511383055 and perplexity is 46.29436054261322
At time: 449.82879424095154 and batch: 950, loss is 3.9336606073379516 and perplexity is 51.093669619698865
At time: 450.8760540485382 and batch: 1000, loss is 3.8911534452438357 and perplexity is 48.967335102078145
At time: 451.92385959625244 and batch: 1050, loss is 3.8457311391830444 and perplexity is 46.792883958001646
At time: 452.9709758758545 and batch: 1100, loss is 3.887988262176514 and perplexity is 48.812589550352875
At time: 454.0612223148346 and batch: 1150, loss is 3.8366573572158815 and perplexity is 46.3702160296394
At time: 455.1085443496704 and batch: 1200, loss is 3.88697687625885 and perplexity is 48.7632461414975
At time: 456.15356278419495 and batch: 1250, loss is 3.8633102893829347 and perplexity is 47.622735767781144
At time: 457.1989583969116 and batch: 1300, loss is 3.8674353408813475 and perplexity is 47.819587738439985
At time: 458.2457070350647 and batch: 1350, loss is 3.7497474193572997 and perplexity is 42.51034335408704
At time: 459.29289293289185 and batch: 1400, loss is 3.761609716415405 and perplexity is 43.01761643864594
At time: 460.3394582271576 and batch: 1450, loss is 3.691282773017883 and perplexity is 40.09624836759146
At time: 461.38642144203186 and batch: 1500, loss is 3.707652797698975 and perplexity is 40.75802682944144
At time: 462.43112802505493 and batch: 1550, loss is 3.708323163986206 and perplexity is 40.78535879675312
At time: 463.4752588272095 and batch: 1600, loss is 3.808897967338562 and perplexity is 45.100709015002955
At time: 464.52313137054443 and batch: 1650, loss is 3.740249605178833 and perplexity is 42.10849935287985
At time: 465.5698654651642 and batch: 1700, loss is 3.770918860435486 and perplexity is 43.41994337972039
At time: 466.6166830062866 and batch: 1750, loss is 3.764655966758728 and perplexity is 43.14885866433858
At time: 467.6647460460663 and batch: 1800, loss is 3.7088713598251344 and perplexity is 40.80772329023576
At time: 468.71174812316895 and batch: 1850, loss is 3.738401336669922 and perplexity is 42.03074341862588
At time: 469.7580966949463 and batch: 1900, loss is 3.808117318153381 and perplexity is 45.06551492216657
At time: 470.8055076599121 and batch: 1950, loss is 3.7546371984481812 and perplexity is 42.71871858139439
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.497211119186047 and perplexity of 89.76643399505396
finished 11 epochs...
Completing Train Step...
At time: 474.14977741241455 and batch: 50, loss is 3.927886972427368 and perplexity is 50.79952338865676
At time: 475.189888715744 and batch: 100, loss is 3.9101122045516967 and perplexity is 49.90455117706637
At time: 476.2316644191742 and batch: 150, loss is 3.887560338973999 and perplexity is 48.791705979310436
At time: 477.27275371551514 and batch: 200, loss is 3.8720325803756714 and perplexity is 48.03993193524143
At time: 478.31571340560913 and batch: 250, loss is 3.871227140426636 and perplexity is 48.00125423328594
At time: 479.35774779319763 and batch: 300, loss is 3.8833000087738037 and perplexity is 48.58427936747688
At time: 480.40161299705505 and batch: 350, loss is 3.8957576990127563 and perplexity is 49.19331296978896
At time: 481.4731857776642 and batch: 400, loss is 3.8572175693511963 and perplexity is 47.33346588663974
At time: 482.51925468444824 and batch: 450, loss is 3.892314314842224 and perplexity is 49.02421280012003
At time: 483.5601043701172 and batch: 500, loss is 3.9093832063674925 and perplexity is 49.86818410724926
At time: 484.60228729248047 and batch: 550, loss is 3.8891927862167357 and perplexity is 48.8714209127138
At time: 485.64506578445435 and batch: 600, loss is 3.8623221349716186 and perplexity is 47.57570039428648
At time: 486.6848180294037 and batch: 650, loss is 3.9007313203811647 and perplexity is 49.43859133760514
At time: 487.7328317165375 and batch: 700, loss is 3.9003482818603517 and perplexity is 49.41965807902327
At time: 488.7762358188629 and batch: 750, loss is 3.86515127658844 and perplexity is 47.71048936686258
At time: 489.81451320648193 and batch: 800, loss is 3.8288673782348632 and perplexity is 46.010396334952055
At time: 490.8577558994293 and batch: 850, loss is 3.844939641952515 and perplexity is 46.75586217319321
At time: 491.900972366333 and batch: 900, loss is 3.8204042768478392 and perplexity is 45.62264877370981
At time: 492.9455335140228 and batch: 950, loss is 3.919983401298523 and perplexity is 50.39960820307136
At time: 493.98742842674255 and batch: 1000, loss is 3.8779132986068725 and perplexity is 48.323273548330704
At time: 495.0293595790863 and batch: 1050, loss is 3.833007822036743 and perplexity is 46.20129472458766
At time: 496.06873321533203 and batch: 1100, loss is 3.8758212232589724 and perplexity is 48.222283295453956
At time: 497.1064393520355 and batch: 1150, loss is 3.8256465435028075 and perplexity is 45.862442847169895
At time: 498.14551615715027 and batch: 1200, loss is 3.8763892793655397 and perplexity is 48.2496840397958
At time: 499.1854724884033 and batch: 1250, loss is 3.8536463880538943 and perplexity is 47.164730969347026
At time: 500.2232418060303 and batch: 1300, loss is 3.8585142517089843 and perplexity is 47.394882166886084
At time: 501.26292419433594 and batch: 1350, loss is 3.74119571685791 and perplexity is 42.14835754808483
At time: 502.3038773536682 and batch: 1400, loss is 3.7539904069900514 and perplexity is 42.691097412644616
At time: 503.34361839294434 and batch: 1450, loss is 3.684343166351318 and perplexity is 39.81895942601832
At time: 504.3856408596039 and batch: 1500, loss is 3.7013195991516112 and perplexity is 40.500713820374806
At time: 505.42590618133545 and batch: 1550, loss is 3.702902956008911 and perplexity is 40.56489169816135
At time: 506.4674425125122 and batch: 1600, loss is 3.804189443588257 and perplexity is 44.88885041748135
At time: 507.50571393966675 and batch: 1650, loss is 3.7360337495803835 and perplexity is 41.931349681238
At time: 508.5455913543701 and batch: 1700, loss is 3.767820715904236 and perplexity is 43.285630287710724
At time: 509.5869092941284 and batch: 1750, loss is 3.7624207401275633 and perplexity is 43.05251889706578
At time: 510.6259455680847 and batch: 1800, loss is 3.707089076042175 and perplexity is 40.735057121898336
At time: 511.66279220581055 and batch: 1850, loss is 3.737302470207214 and perplexity is 41.98458261120703
At time: 512.7024931907654 and batch: 1900, loss is 3.8075145196914675 and perplexity is 45.03835768507885
At time: 513.7413165569305 and batch: 1950, loss is 3.7545196342468263 and perplexity is 42.713696684564894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4982555300690406 and perplexity of 89.86023601104255
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 517.1071438789368 and batch: 50, loss is 3.9206264925003054 and perplexity is 50.43203017170403
At time: 518.1852104663849 and batch: 100, loss is 3.911065363883972 and perplexity is 49.95214084240764
At time: 519.2214076519012 and batch: 150, loss is 3.895562162399292 and perplexity is 49.18369481634699
At time: 520.2596988677979 and batch: 200, loss is 3.8833152437210083 and perplexity is 48.58501955204634
At time: 521.2986915111542 and batch: 250, loss is 3.885267930030823 and perplexity is 48.679983541854426
At time: 522.343908071518 and batch: 300, loss is 3.8953878355026244 and perplexity is 49.175121522762545
At time: 523.3847453594208 and batch: 350, loss is 3.9089624786376955 and perplexity is 49.847207592370886
At time: 524.4260125160217 and batch: 400, loss is 3.872864394187927 and perplexity is 48.079908838530095
At time: 525.465646982193 and batch: 450, loss is 3.909663758277893 and perplexity is 49.88217668429909
At time: 526.5071897506714 and batch: 500, loss is 3.9278542947769166 and perplexity is 50.79786340671067
At time: 527.5484428405762 and batch: 550, loss is 3.9090475273132324 and perplexity is 49.85144721164027
At time: 528.5944488048553 and batch: 600, loss is 3.8790754652023316 and perplexity is 48.379465888737684
At time: 529.63600897789 and batch: 650, loss is 3.9145750331878664 and perplexity is 50.127764347724614
At time: 530.6836867332458 and batch: 700, loss is 3.9111396932601927 and perplexity is 49.95585389186996
At time: 531.7550191879272 and batch: 750, loss is 3.871069450378418 and perplexity is 47.993685509963235
At time: 532.80175948143 and batch: 800, loss is 3.830455098152161 and perplexity is 46.08350598107823
At time: 533.8960866928101 and batch: 850, loss is 3.8457212018966676 and perplexity is 46.79241896602374
At time: 534.9401512145996 and batch: 900, loss is 3.815810260772705 and perplexity is 45.41353828809205
At time: 535.9848935604095 and batch: 950, loss is 3.9173874998092653 and perplexity is 50.2689454522685
At time: 537.0285472869873 and batch: 1000, loss is 3.87287700176239 and perplexity is 48.08051501338215
At time: 538.0752487182617 and batch: 1050, loss is 3.8292525815963745 and perplexity is 46.028123108271885
At time: 539.1189420223236 and batch: 1100, loss is 3.8668024826049803 and perplexity is 47.789334290649386
At time: 540.1625137329102 and batch: 1150, loss is 3.820217475891113 and perplexity is 45.614127215212925
At time: 541.2066829204559 and batch: 1200, loss is 3.8719138145446776 and perplexity is 48.03422677160021
At time: 542.2494668960571 and batch: 1250, loss is 3.8469982051849367 and perplexity is 46.85221120822892
At time: 543.2944073677063 and batch: 1300, loss is 3.848843331336975 and perplexity is 46.9387392514391
At time: 544.3382461071014 and batch: 1350, loss is 3.7260624408721923 and perplexity is 41.515316891772045
At time: 545.3828375339508 and batch: 1400, loss is 3.737252268791199 and perplexity is 41.98247497861265
At time: 546.4247522354126 and batch: 1450, loss is 3.6639004373550415 and perplexity is 39.01321509624333
At time: 547.4666037559509 and batch: 1500, loss is 3.6784069395065306 and perplexity is 39.58328524989984
At time: 548.5118677616119 and batch: 1550, loss is 3.6813429594039917 and perplexity is 39.69967333826456
At time: 549.5568726062775 and batch: 1600, loss is 3.78159423828125 and perplexity is 43.88595065757481
At time: 550.6010890007019 and batch: 1650, loss is 3.7115949964523316 and perplexity is 40.91902019742618
At time: 551.6462574005127 and batch: 1700, loss is 3.7398489904403687 and perplexity is 42.091633446015464
At time: 552.6890864372253 and batch: 1750, loss is 3.7341081953048705 and perplexity is 41.85068627738571
At time: 553.7333459854126 and batch: 1800, loss is 3.6804135990142823 and perplexity is 39.662795173586666
At time: 554.7790985107422 and batch: 1850, loss is 3.7060453414916994 and perplexity is 40.69256271566232
At time: 555.8238651752472 and batch: 1900, loss is 3.775951986312866 and perplexity is 43.639032308915695
At time: 556.8670988082886 and batch: 1950, loss is 3.7280091524124144 and perplexity is 41.596213954336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4901642555414245 and perplexity of 89.1360857723129
finished 13 epochs...
Completing Train Step...
At time: 560.2614059448242 and batch: 50, loss is 3.9190786409378053 and perplexity is 50.354029257494346
At time: 561.3076410293579 and batch: 100, loss is 3.9037197923660276 and perplexity is 49.586558170031495
At time: 562.3542377948761 and batch: 150, loss is 3.8826820993423463 and perplexity is 48.554267956157105
At time: 563.4032354354858 and batch: 200, loss is 3.8677361679077147 and perplexity is 47.83397532680065
At time: 564.4498238563538 and batch: 250, loss is 3.8694348430633543 and perplexity is 47.915298763779866
At time: 565.4961082935333 and batch: 300, loss is 3.877287549972534 and perplexity is 48.293044784691226
At time: 566.5450820922852 and batch: 350, loss is 3.8909668588638304 and perplexity is 48.95819931661602
At time: 567.5921330451965 and batch: 400, loss is 3.8550625085830688 and perplexity is 47.23156922747067
At time: 568.6405596733093 and batch: 450, loss is 3.8917046213150024 and perplexity is 48.994332164839236
At time: 569.6884667873383 and batch: 500, loss is 3.9100972604751587 and perplexity is 49.903805405206434
At time: 570.7368938922882 and batch: 550, loss is 3.8919305992126465 and perplexity is 49.005405052085095
At time: 571.7849037647247 and batch: 600, loss is 3.862671127319336 and perplexity is 47.592306847255344
At time: 572.8333804607391 and batch: 650, loss is 3.8994262981414796 and perplexity is 49.37411495711682
At time: 573.8796968460083 and batch: 700, loss is 3.8974035596847534 and perplexity is 49.2743449743339
At time: 574.9263827800751 and batch: 750, loss is 3.8586074447631837 and perplexity is 47.399299246526006
At time: 575.9745705127716 and batch: 800, loss is 3.818822593688965 and perplexity is 45.55054523598877
At time: 577.0226035118103 and batch: 850, loss is 3.8347305154800413 and perplexity is 46.28095398662559
At time: 578.0703926086426 and batch: 900, loss is 3.8059343004226687 and perplexity is 44.967243407304096
At time: 579.1184916496277 and batch: 950, loss is 3.9080952978134156 and perplexity is 49.80399978700072
At time: 580.1678621768951 and batch: 1000, loss is 3.8639399814605713 and perplexity is 47.65273287068734
At time: 581.2110493183136 and batch: 1050, loss is 3.8208916187286377 and perplexity is 45.64488801978805
At time: 582.258358001709 and batch: 1100, loss is 3.8594710350036623 and perplexity is 47.44025049876664
At time: 583.3086702823639 and batch: 1150, loss is 3.8131729412078856 and perplexity is 45.29392607220553
At time: 584.3567163944244 and batch: 1200, loss is 3.8657160997390747 and perplexity is 47.73744496764214
At time: 585.4057803153992 and batch: 1250, loss is 3.841908736228943 and perplexity is 46.61436410489582
At time: 586.45539021492 and batch: 1300, loss is 3.8447378396987917 and perplexity is 46.746427686814215
At time: 587.5025923252106 and batch: 1350, loss is 3.7227240705490114 and perplexity is 41.37695447090375
At time: 588.5499286651611 and batch: 1400, loss is 3.735627112388611 and perplexity is 41.91430230124065
At time: 589.5960290431976 and batch: 1450, loss is 3.6634445285797117 and perplexity is 38.99543268301425
At time: 590.645429611206 and batch: 1500, loss is 3.679490451812744 and perplexity is 39.626197470349695
At time: 591.6951365470886 and batch: 1550, loss is 3.683585343360901 and perplexity is 39.78879513415132
At time: 592.7439813613892 and batch: 1600, loss is 3.7846267223358154 and perplexity is 44.019236094003084
At time: 593.7928597927094 and batch: 1650, loss is 3.7153844165802004 and perplexity is 41.07437372015544
At time: 594.84050989151 and batch: 1700, loss is 3.7441954803466797 and perplexity is 42.27498247963869
At time: 595.8879923820496 and batch: 1750, loss is 3.739424443244934 and perplexity is 42.073767353852716
At time: 596.9380605220795 and batch: 1800, loss is 3.68614230632782 and perplexity is 39.89066379149789
At time: 597.9869186878204 and batch: 1850, loss is 3.7117552185058593 and perplexity is 40.92557685211687
At time: 599.0366702079773 and batch: 1900, loss is 3.781433401107788 and perplexity is 43.8788927329199
At time: 600.0856401920319 and batch: 1950, loss is 3.733293557167053 and perplexity is 41.816606995276466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489649856922238 and perplexity of 89.09024608381895
finished 14 epochs...
Completing Train Step...
At time: 603.4254434108734 and batch: 50, loss is 3.9155562019348142 and perplexity is 50.17697228015199
At time: 604.4967200756073 and batch: 100, loss is 3.8985671186447144 and perplexity is 49.33171194838104
At time: 605.5412545204163 and batch: 150, loss is 3.8764892768859864 and perplexity is 48.25450912980662
At time: 606.5860221385956 and batch: 200, loss is 3.8607556343078615 and perplexity is 47.50123137115565
At time: 607.6284635066986 and batch: 250, loss is 3.8620136260986326 and perplexity is 47.561025132416965
At time: 608.677314043045 and batch: 300, loss is 3.869395360946655 and perplexity is 47.913407003707995
At time: 609.7201280593872 and batch: 350, loss is 3.8832243633270265 and perplexity is 48.58060432695957
At time: 610.7638728618622 and batch: 400, loss is 3.8471526384353636 and perplexity is 46.859447306228176
At time: 611.8068156242371 and batch: 450, loss is 3.8838960266113283 and perplexity is 48.61324509579107
At time: 612.8509883880615 and batch: 500, loss is 3.9022415113449096 and perplexity is 49.513309456616895
At time: 613.9223220348358 and batch: 550, loss is 3.883993091583252 and perplexity is 48.61796396807631
At time: 614.9676003456116 and batch: 600, loss is 3.8551070928573608 and perplexity is 47.2336750596515
At time: 616.0115129947662 and batch: 650, loss is 3.892323851585388 and perplexity is 49.0246803336757
At time: 617.0528357028961 and batch: 700, loss is 3.8907224416732786 and perplexity is 48.94623455334105
At time: 618.0948710441589 and batch: 750, loss is 3.8524266338348387 and perplexity is 47.107236661347265
At time: 619.1356151103973 and batch: 800, loss is 3.8129108238220213 and perplexity is 45.28205530254347
At time: 620.1779582500458 and batch: 850, loss is 3.8290638160705566 and perplexity is 46.01943540540614
At time: 621.2179131507874 and batch: 900, loss is 3.8007409238815306 and perplexity is 44.73431694121985
At time: 622.2590010166168 and batch: 950, loss is 3.903172879219055 and perplexity is 49.55944604412003
At time: 623.3017780780792 and batch: 1000, loss is 3.8592126512527467 and perplexity is 47.42799429236887
At time: 624.3447766304016 and batch: 1050, loss is 3.8164222955703737 and perplexity is 45.44134146119644
At time: 625.3858482837677 and batch: 1100, loss is 3.8554382610321043 and perplexity is 47.24931994000769
At time: 626.4290583133698 and batch: 1150, loss is 3.809473695755005 and perplexity is 45.12668225083214
At time: 627.4728450775146 and batch: 1200, loss is 3.862225570678711 and perplexity is 47.57110650222486
At time: 628.5149343013763 and batch: 1250, loss is 3.8389923000335693 and perplexity is 46.47861433518636
At time: 629.558931350708 and batch: 1300, loss is 3.8423111248016357 and perplexity is 46.633124966660034
At time: 630.5993230342865 and batch: 1350, loss is 3.7206573343276976 and perplexity is 41.291527528257106
At time: 631.6396327018738 and batch: 1400, loss is 3.734275302886963 and perplexity is 41.857680428750015
At time: 632.6806375980377 and batch: 1450, loss is 3.6626118564605714 and perplexity is 38.96297578829626
At time: 633.721274137497 and batch: 1500, loss is 3.679242649078369 and perplexity is 39.61637920681018
At time: 634.7636125087738 and batch: 1550, loss is 3.6839417362213136 and perplexity is 39.80297810386601
At time: 635.8050734996796 and batch: 1600, loss is 3.785321855545044 and perplexity is 44.049845964593096
At time: 636.8442261219025 and batch: 1650, loss is 3.716424374580383 and perplexity is 41.11711156263702
At time: 637.8843312263489 and batch: 1700, loss is 3.7454690647125246 and perplexity is 42.32885753632389
At time: 638.9234433174133 and batch: 1750, loss is 3.7411539268493654 and perplexity is 42.14659620466628
At time: 639.9645817279816 and batch: 1800, loss is 3.688087658882141 and perplexity is 39.96834072621325
At time: 641.0058722496033 and batch: 1850, loss is 3.713728222846985 and perplexity is 41.006402901762975
At time: 642.0498867034912 and batch: 1900, loss is 3.7833683490753174 and perplexity is 43.96387830204236
At time: 643.0930972099304 and batch: 1950, loss is 3.735080943107605 and perplexity is 41.89141624728764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489722247456395 and perplexity of 89.0966956077606
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 646.4244084358215 and batch: 50, loss is 3.9136443853378298 and perplexity is 50.08113475283889
At time: 647.4643659591675 and batch: 100, loss is 3.8988580083847046 and perplexity is 49.34606412459218
At time: 648.5078003406525 and batch: 150, loss is 3.8784310579299928 and perplexity is 48.34829985197599
At time: 649.5499639511108 and batch: 200, loss is 3.8634048318862915 and perplexity is 47.62723835327683
At time: 650.5885446071625 and batch: 250, loss is 3.865880079269409 and perplexity is 47.74527357329529
At time: 651.6286294460297 and batch: 300, loss is 3.871465663909912 and perplexity is 48.012705025234396
At time: 652.6726224422455 and batch: 350, loss is 3.885122137069702 and perplexity is 48.672886860242244
At time: 653.7167146205902 and batch: 400, loss is 3.8506408405303953 and perplexity is 47.02318794268247
At time: 654.760660648346 and batch: 450, loss is 3.88772524356842 and perplexity is 48.79975261924177
At time: 655.805727481842 and batch: 500, loss is 3.9067278242111207 and perplexity is 49.73594067712716
At time: 656.848738193512 and batch: 550, loss is 3.8895096015930175 and perplexity is 48.88690658323943
At time: 657.8935527801514 and batch: 600, loss is 3.859045009613037 and perplexity is 47.420044052051836
At time: 658.9356784820557 and batch: 650, loss is 3.895729732513428 and perplexity is 49.191937224272316
At time: 659.9775698184967 and batch: 700, loss is 3.8939735746383666 and perplexity is 49.10562422813342
At time: 661.0203197002411 and batch: 750, loss is 3.8547484350204466 and perplexity is 47.216737369524324
At time: 662.0656735897064 and batch: 800, loss is 3.8145687103271486 and perplexity is 45.357190076208106
At time: 663.1095366477966 and batch: 850, loss is 3.8313408708572387 and perplexity is 46.12434357657421
At time: 664.1483929157257 and batch: 900, loss is 3.800158987045288 and perplexity is 44.70829196752747
At time: 665.1889541149139 and batch: 950, loss is 3.902157745361328 and perplexity is 49.509162099256045
At time: 666.2749381065369 and batch: 1000, loss is 3.8573992919921873 and perplexity is 47.34206823066459
At time: 667.3218491077423 and batch: 1050, loss is 3.8146896028518675 and perplexity is 45.36267375289166
At time: 668.3647825717926 and batch: 1100, loss is 3.8521094846725465 and perplexity is 47.0922990095593
At time: 669.4079616069794 and batch: 1150, loss is 3.8065766668319703 and perplexity is 44.99613813349501
At time: 670.45263838768 and batch: 1200, loss is 3.8582777070999144 and perplexity is 47.38367248885872
At time: 671.496502161026 and batch: 1250, loss is 3.8350133657455445 and perplexity is 46.294046418260045
At time: 672.538140296936 and batch: 1300, loss is 3.836949095726013 and perplexity is 46.38374598088632
At time: 673.581561088562 and batch: 1350, loss is 3.713434681892395 and perplexity is 40.99436760962288
At time: 674.6236305236816 and batch: 1400, loss is 3.7254020166397095 and perplexity is 41.48790822214853
At time: 675.6664438247681 and batch: 1450, loss is 3.6525204181671143 and perplexity is 38.571760604356854
At time: 676.7089660167694 and batch: 1500, loss is 3.668255271911621 and perplexity is 39.18348166579204
At time: 677.7526533603668 and batch: 1550, loss is 3.6734462690353396 and perplexity is 39.38741184898094
At time: 678.7950422763824 and batch: 1600, loss is 3.7743779897689818 and perplexity is 43.57039865162248
At time: 679.8372547626495 and batch: 1650, loss is 3.705879774093628 and perplexity is 40.68582591164557
At time: 680.8814857006073 and batch: 1700, loss is 3.733343563079834 and perplexity is 41.818698125162655
At time: 681.9254686832428 and batch: 1750, loss is 3.728644347190857 and perplexity is 41.62264404548207
At time: 682.9707071781158 and batch: 1800, loss is 3.676246690750122 and perplexity is 39.497867801850084
At time: 684.0117297172546 and batch: 1850, loss is 3.70214364528656 and perplexity is 40.53410203188512
At time: 685.053816318512 and batch: 1900, loss is 3.7718168592453 and perplexity is 43.45895194940076
At time: 686.0944652557373 and batch: 1950, loss is 3.7250943994522094 and perplexity is 41.47514779127053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489306924509448 and perplexity of 89.05969938879862
finished 16 epochs...
Completing Train Step...
At time: 689.380527973175 and batch: 50, loss is 3.912621169090271 and perplexity is 50.0299171298842
At time: 690.4492974281311 and batch: 100, loss is 3.896543335914612 and perplexity is 49.23197623743881
At time: 691.4913194179535 and batch: 150, loss is 3.87477744102478 and perplexity is 48.17197599235999
At time: 692.5626530647278 and batch: 200, loss is 3.859102702140808 and perplexity is 47.42277991317883
At time: 693.6035339832306 and batch: 250, loss is 3.861211142539978 and perplexity is 47.522873501791004
At time: 694.6445021629333 and batch: 300, loss is 3.866859073638916 and perplexity is 47.79203881501319
At time: 695.6875927448273 and batch: 350, loss is 3.8804722356796266 and perplexity is 48.447088113768075
At time: 696.7322201728821 and batch: 400, loss is 3.8459613609313963 and perplexity is 46.80365793771152
At time: 697.7757658958435 and batch: 450, loss is 3.882889676094055 and perplexity is 48.56434773950919
At time: 698.8212070465088 and batch: 500, loss is 3.9017852258682253 and perplexity is 49.490722406072706
At time: 699.8635721206665 and batch: 550, loss is 3.8843958282470705 and perplexity is 48.637548148055416
At time: 700.9060142040253 and batch: 600, loss is 3.8545976543426512 and perplexity is 47.20961853456532
At time: 701.9505367279053 and batch: 650, loss is 3.891719365119934 and perplexity is 48.995054533040644
At time: 702.9938116073608 and batch: 700, loss is 3.8904263973236084 and perplexity is 48.931746441831486
At time: 704.0399146080017 and batch: 750, loss is 3.851496796607971 and perplexity is 47.063454957128364
At time: 705.0845830440521 and batch: 800, loss is 3.8114047718048094 and perplexity is 45.21390950025373
At time: 706.1304457187653 and batch: 850, loss is 3.8280575561523436 and perplexity is 45.97315118298328
At time: 707.1716864109039 and batch: 900, loss is 3.7972652769088744 and perplexity is 44.57910613320385
At time: 708.2153253555298 and batch: 950, loss is 3.899533829689026 and perplexity is 49.37942451757439
At time: 709.2590036392212 and batch: 1000, loss is 3.8549664402008057 and perplexity is 47.22703198496951
At time: 710.3034698963165 and batch: 1050, loss is 3.812412614822388 and perplexity is 45.259500993916134
At time: 711.3457942008972 and batch: 1100, loss is 3.8501536321640013 and perplexity is 47.00028343218992
At time: 712.3893086910248 and batch: 1150, loss is 3.804889874458313 and perplexity is 44.92030296791783
At time: 713.4334485530853 and batch: 1200, loss is 3.856960825920105 and perplexity is 47.32131489011359
At time: 714.4757115840912 and batch: 1250, loss is 3.833815546035767 and perplexity is 46.238627694460824
At time: 715.5197763442993 and batch: 1300, loss is 3.836174726486206 and perplexity is 46.34784173813644
At time: 716.5650770664215 and batch: 1350, loss is 3.7129803991317747 and perplexity is 40.97574880455658
At time: 717.6061239242554 and batch: 1400, loss is 3.725621991157532 and perplexity is 41.497035508603574
At time: 718.6488938331604 and batch: 1450, loss is 3.6532403945922853 and perplexity is 38.59954136221465
At time: 719.6945676803589 and batch: 1500, loss is 3.6693541526794435 and perplexity is 39.22656330666897
At time: 720.7380738258362 and batch: 1550, loss is 3.674901161193848 and perplexity is 39.44475799173523
At time: 721.781094789505 and batch: 1600, loss is 3.7761217021942137 and perplexity is 43.64643917425872
At time: 722.8262491226196 and batch: 1650, loss is 3.7078916883468627 and perplexity is 40.76776470397462
At time: 723.8697891235352 and batch: 1700, loss is 3.735497307777405 and perplexity is 41.9088619846232
At time: 724.9146361351013 and batch: 1750, loss is 3.7310011100769045 and perplexity is 41.7208544320269
At time: 725.9580600261688 and batch: 1800, loss is 3.6787017297744753 and perplexity is 39.59495573725332
At time: 727.0027520656586 and batch: 1850, loss is 3.7043959283828736 and perplexity is 40.62549919221895
At time: 728.0471119880676 and batch: 1900, loss is 3.773815131187439 and perplexity is 43.54588157930972
At time: 729.0898489952087 and batch: 1950, loss is 3.7268440103530884 and perplexity is 41.5477766795818
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489222610828488 and perplexity of 89.05219075426275
finished 17 epochs...
Completing Train Step...
At time: 732.4052023887634 and batch: 50, loss is 3.911740860939026 and perplexity is 49.98589476549465
At time: 733.4494996070862 and batch: 100, loss is 3.8950029897689817 and perplexity is 49.15620032814719
At time: 734.4955806732178 and batch: 150, loss is 3.8726616525650024 and perplexity is 48.0701620278576
At time: 735.5394759178162 and batch: 200, loss is 3.8565034914016723 and perplexity is 47.29967816734392
At time: 736.5849723815918 and batch: 250, loss is 3.8583904933929443 and perplexity is 47.38901701901809
At time: 737.6312432289124 and batch: 300, loss is 3.863950433731079 and perplexity is 47.653230952544774
At time: 738.6794064044952 and batch: 350, loss is 3.877564492225647 and perplexity is 48.30642102146066
At time: 739.7270247936249 and batch: 400, loss is 3.8429375505447387 and perplexity is 46.66234630816521
At time: 740.7738325595856 and batch: 450, loss is 3.879765410423279 and perplexity is 48.412856587571575
At time: 741.8196218013763 and batch: 500, loss is 3.898694090843201 and perplexity is 49.33797610198049
At time: 742.8644771575928 and batch: 550, loss is 3.8812327861785887 and perplexity is 48.4839485861548
At time: 743.9134616851807 and batch: 600, loss is 3.851768798828125 and perplexity is 47.07625806252241
At time: 744.9604425430298 and batch: 650, loss is 3.889074568748474 and perplexity is 48.86564379854779
At time: 746.0474560260773 and batch: 700, loss is 3.8880149793624876 and perplexity is 48.81389370280732
At time: 747.0957701206207 and batch: 750, loss is 3.8492915868759154 and perplexity is 46.95978451777564
At time: 748.1410524845123 and batch: 800, loss is 3.8092965602874758 and perplexity is 45.11868942280117
At time: 749.185506105423 and batch: 850, loss is 3.825928907394409 and perplexity is 45.875394573474445
At time: 750.2291097640991 and batch: 900, loss is 3.7954179525375364 and perplexity is 44.49683008266618
At time: 751.2799291610718 and batch: 950, loss is 3.8978509378433226 and perplexity is 49.29639417185015
At time: 752.3232138156891 and batch: 1000, loss is 3.8533770990371705 and perplexity is 47.152031735279124
At time: 753.367689371109 and batch: 1050, loss is 3.8109881925582885 and perplexity is 45.195078246528915
At time: 754.417028427124 and batch: 1100, loss is 3.8489065837860106 and perplexity is 46.94170833555132
At time: 755.4612164497375 and batch: 1150, loss is 3.8038026905059814 and perplexity is 44.871492872980866
At time: 756.5038914680481 and batch: 1200, loss is 3.8560640144348146 and perplexity is 47.27889561531055
At time: 757.5469415187836 and batch: 1250, loss is 3.833061623573303 and perplexity is 46.20378049210337
At time: 758.5906758308411 and batch: 1300, loss is 3.835707468986511 and perplexity is 46.32619042025387
At time: 759.6383700370789 and batch: 1350, loss is 3.7127012395858765 and perplexity is 40.96431162960002
At time: 760.6837029457092 and batch: 1400, loss is 3.7257739448547365 and perplexity is 41.50334161567814
At time: 761.7258744239807 and batch: 1450, loss is 3.6536662864685057 and perplexity is 38.61598409447116
At time: 762.7701058387756 and batch: 1500, loss is 3.670030975341797 and perplexity is 39.25312172033544
At time: 763.8118522167206 and batch: 1550, loss is 3.675828695297241 and perplexity is 39.48136132276736
At time: 764.8544991016388 and batch: 1600, loss is 3.7772144412994386 and perplexity is 43.69415941328542
At time: 765.8978846073151 and batch: 1650, loss is 3.70913028717041 and perplexity is 40.81829089375577
At time: 766.9450249671936 and batch: 1700, loss is 3.7367678356170653 and perplexity is 41.96214220033457
At time: 767.9912040233612 and batch: 1750, loss is 3.7324601078033446 and perplexity is 41.78176949044854
At time: 769.0454113483429 and batch: 1800, loss is 3.680175528526306 and perplexity is 39.653353756491164
At time: 770.089478969574 and batch: 1850, loss is 3.7057781076431273 and perplexity is 40.68168973839804
At time: 771.1358444690704 and batch: 1900, loss is 3.775027384757996 and perplexity is 43.59870223928552
At time: 772.1814303398132 and batch: 1950, loss is 3.7279230785369872 and perplexity is 41.59263376108061
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489203874454942 and perplexity of 89.05052225478255
finished 18 epochs...
Completing Train Step...
At time: 775.4680409431458 and batch: 50, loss is 3.910779972076416 and perplexity is 49.93788694471089
At time: 776.5554583072662 and batch: 100, loss is 3.8936087560653685 and perplexity is 49.087712851776374
At time: 777.5988490581512 and batch: 150, loss is 3.8709238290786745 and perplexity is 47.98669711594165
At time: 778.6395075321198 and batch: 200, loss is 3.854480528831482 and perplexity is 47.20408940766958
At time: 779.6815140247345 and batch: 250, loss is 3.8562236404418946 and perplexity is 47.28644315901288
At time: 780.7207143306732 and batch: 300, loss is 3.861692371368408 and perplexity is 47.54574838211438
At time: 781.7634847164154 and batch: 350, loss is 3.8753235292434693 and perplexity is 48.19828932496695
At time: 782.8065519332886 and batch: 400, loss is 3.8406183385848998 and perplexity is 46.554251831985184
At time: 783.8469152450562 and batch: 450, loss is 3.8774124431610106 and perplexity is 48.29907663369622
At time: 784.8881270885468 and batch: 500, loss is 3.896373543739319 and perplexity is 49.223617742723064
At time: 785.9274985790253 and batch: 550, loss is 3.8788754606246947 and perplexity is 48.36979074166541
At time: 786.9721064567566 and batch: 600, loss is 3.8496216344833374 and perplexity is 46.975286040280274
At time: 788.0176124572754 and batch: 650, loss is 3.887040686607361 and perplexity is 48.76635784050655
At time: 789.0602207183838 and batch: 700, loss is 3.8861454153060913 and perplexity is 48.72271825741246
At time: 790.0993599891663 and batch: 750, loss is 3.847566819190979 and perplexity is 46.87885960734446
At time: 791.1365013122559 and batch: 800, loss is 3.8076469326019287 and perplexity is 45.04432173995254
At time: 792.1734008789062 and batch: 850, loss is 3.8242940044403078 and perplexity is 45.8004540323142
At time: 793.2120487689972 and batch: 900, loss is 3.7939841461181643 and perplexity is 44.43307595851032
At time: 794.2520985603333 and batch: 950, loss is 3.8965443420410155 and perplexity is 49.23202577105492
At time: 795.289226770401 and batch: 1000, loss is 3.8521363306045533 and perplexity is 47.09356326318651
At time: 796.3285202980042 and batch: 1050, loss is 3.809868140220642 and perplexity is 45.14448573191001
At time: 797.3660929203033 and batch: 1100, loss is 3.8479172945022584 and perplexity is 46.89529236972831
At time: 798.4482772350311 and batch: 1150, loss is 3.802925219535828 and perplexity is 44.83213671006781
At time: 799.4861176013947 and batch: 1200, loss is 3.8553071641921997 and perplexity is 47.243126109480585
At time: 800.5261602401733 and batch: 1250, loss is 3.8324371767044068 and perplexity is 46.174937692379125
At time: 801.5646297931671 and batch: 1300, loss is 3.8352795743942263 and perplexity is 46.30637193430576
At time: 802.6028323173523 and batch: 1350, loss is 3.712406587600708 and perplexity is 40.952243191939175
At time: 803.641627073288 and batch: 1400, loss is 3.72578134059906 and perplexity is 41.50364856491637
At time: 804.680150270462 and batch: 1450, loss is 3.653845720291138 and perplexity is 38.62291372979882
At time: 805.7183139324188 and batch: 1500, loss is 3.6703924703598023 and perplexity is 39.26731409336003
At time: 806.7573573589325 and batch: 1550, loss is 3.6763824224472046 and perplexity is 39.5032292783309
At time: 807.7970416545868 and batch: 1600, loss is 3.777883186340332 and perplexity is 43.723389438336866
At time: 808.8355309963226 and batch: 1650, loss is 3.709891424179077 and perplexity is 40.849371032206875
At time: 809.8763778209686 and batch: 1700, loss is 3.7375425910949707 and perplexity is 41.99466519692699
At time: 810.9194793701172 and batch: 1750, loss is 3.733390865325928 and perplexity is 41.82067629029815
At time: 811.9618213176727 and batch: 1800, loss is 3.681115527153015 and perplexity is 39.69064537885768
At time: 813.0029516220093 and batch: 1850, loss is 3.706676092147827 and perplexity is 40.718237672691515
At time: 814.0477094650269 and batch: 1900, loss is 3.7758252668380736 and perplexity is 43.633502744020234
At time: 815.0891480445862 and batch: 1950, loss is 3.728632402420044 and perplexity is 41.62214687550762
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489218920330669 and perplexity of 89.0518621079534
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 818.3995490074158 and batch: 50, loss is 3.9103393030166624 and perplexity is 49.9158857110124
At time: 819.4394602775574 and batch: 100, loss is 3.893656916618347 and perplexity is 49.09007700010065
At time: 820.4802420139313 and batch: 150, loss is 3.8711782693862915 and perplexity is 47.998908419375375
At time: 821.5240497589111 and batch: 200, loss is 3.8548828983306884 and perplexity is 47.2230867151973
At time: 822.5651264190674 and batch: 250, loss is 3.856742343902588 and perplexity is 47.310977163109676
At time: 823.6059412956238 and batch: 300, loss is 3.861628756523132 and perplexity is 47.54272386289071
At time: 824.6501438617706 and batch: 350, loss is 3.875096917152405 and perplexity is 48.18736824730814
At time: 825.7376868724823 and batch: 400, loss is 3.840880117416382 and perplexity is 46.56644034490801
At time: 826.778003692627 and batch: 450, loss is 3.877583861351013 and perplexity is 48.307356683646866
At time: 827.8194391727448 and batch: 500, loss is 3.896678466796875 and perplexity is 49.238629447340266
At time: 828.8620388507843 and batch: 550, loss is 3.879374222755432 and perplexity is 48.39392177888258
At time: 829.9046199321747 and batch: 600, loss is 3.849680404663086 and perplexity is 46.97804686741096
At time: 830.9484484195709 and batch: 650, loss is 3.8866907215118407 and perplexity is 48.74929430342207
At time: 831.9902398586273 and batch: 700, loss is 3.8861210107803346 and perplexity is 48.72152921708886
At time: 833.0317645072937 and batch: 750, loss is 3.8475673389434815 and perplexity is 46.87888397275538
At time: 834.0736036300659 and batch: 800, loss is 3.80783399105072 and perplexity is 45.05274844902307
At time: 835.115843296051 and batch: 850, loss is 3.8245367097854612 and perplexity is 45.81157139638557
At time: 836.1602659225464 and batch: 900, loss is 3.7935728311538695 and perplexity is 44.41480372753756
At time: 837.2022271156311 and batch: 950, loss is 3.895840845108032 and perplexity is 49.19740337172421
At time: 838.2453107833862 and batch: 1000, loss is 3.851458878517151 and perplexity is 47.06167043460205
At time: 839.2871632575989 and batch: 1050, loss is 3.8091207933425903 and perplexity is 45.110759745512084
At time: 840.3297712802887 and batch: 1100, loss is 3.8467584562301638 and perplexity is 46.840979785977616
At time: 841.3708086013794 and batch: 1150, loss is 3.8016519927978516 and perplexity is 44.775091558300545
At time: 842.41259765625 and batch: 1200, loss is 3.853718276023865 and perplexity is 47.16812166798439
At time: 843.4556248188019 and batch: 1250, loss is 3.830753917694092 and perplexity is 46.097278690901014
At time: 844.5007016658783 and batch: 1300, loss is 3.8334676027297974 and perplexity is 46.22254207208192
At time: 845.5451900959015 and batch: 1350, loss is 3.7100414562225343 and perplexity is 40.855500206591564
At time: 846.5887742042542 and batch: 1400, loss is 3.7226775884628296 and perplexity is 41.375031228438594
At time: 847.6330573558807 and batch: 1450, loss is 3.6502769804000854 and perplexity is 38.48532425341626
At time: 848.6718280315399 and batch: 1500, loss is 3.6666696548461912 and perplexity is 39.1214008997477
At time: 849.7139205932617 and batch: 1550, loss is 3.672729740142822 and perplexity is 39.35919973899266
At time: 850.7547605037689 and batch: 1600, loss is 3.774068970680237 and perplexity is 43.556936646850254
At time: 851.7959728240967 and batch: 1650, loss is 3.706154775619507 and perplexity is 40.69701611444383
At time: 852.8365337848663 and batch: 1700, loss is 3.7334606075286865 and perplexity is 41.823593058093216
At time: 853.8767783641815 and batch: 1750, loss is 3.729323773384094 and perplexity is 41.65093316917593
At time: 854.9150094985962 and batch: 1800, loss is 3.677147855758667 and perplexity is 39.53347794112108
At time: 855.9565246105194 and batch: 1850, loss is 3.7031856966018677 and perplexity is 40.576362661270345
At time: 856.9987225532532 and batch: 1900, loss is 3.772307777404785 and perplexity is 43.480291975779565
At time: 858.0404984951019 and batch: 1950, loss is 3.7257590913772582 and perplexity is 41.502725151306514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489244186046512 and perplexity of 89.05411209542036
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea7e1b2b38>
ELAPSED
1776.1410038471222


RESULTS SO FAR:
[{'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.92103091601648}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.6813262795645527, 'dropout': 0.19794812537896078, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.05052225478255}]
SETTINGS FOR THIS RUN
{'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.8407924036871192, 'dropout': 0.37893501344260494, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.513329267501831 and batch: 50, loss is 7.264113302230835 and perplexity is 1428.1187564628897
At time: 2.5492897033691406 and batch: 100, loss is 6.429466199874878 and perplexity is 619.8429874229273
At time: 3.5868465900421143 and batch: 150, loss is 6.1746971321105955 and perplexity is 480.43749279403556
At time: 4.624281883239746 and batch: 200, loss is 6.053630905151367 and perplexity is 425.65574325813316
At time: 5.663142442703247 and batch: 250, loss is 5.991716537475586 and perplexity is 400.1008088479375
At time: 6.703234672546387 and batch: 300, loss is 5.912480144500733 and perplexity is 369.62173486844233
At time: 7.744823932647705 and batch: 350, loss is 5.8665484523773195 and perplexity is 353.02838073256555
At time: 8.784825563430786 and batch: 400, loss is 5.814039716720581 and perplexity is 334.9695783213922
At time: 9.825630187988281 and batch: 450, loss is 5.747483463287353 and perplexity is 313.40098199826514
At time: 10.892060041427612 and batch: 500, loss is 5.717085094451904 and perplexity is 304.0174479865792
At time: 11.93114686012268 and batch: 550, loss is 5.6653089427948 and perplexity is 288.67715206769924
At time: 12.971506118774414 and batch: 600, loss is 5.700535507202148 and perplexity is 299.02748947321373
At time: 14.010509967803955 and batch: 650, loss is 5.77700101852417 and perplexity is 322.78969707546446
At time: 15.050983190536499 and batch: 700, loss is 5.694816637039184 and perplexity is 297.32227069565033
At time: 16.091269493103027 and batch: 750, loss is 5.632951812744141 and perplexity is 279.48589123774894
At time: 17.1357638835907 and batch: 800, loss is 5.635465021133423 and perplexity is 280.18918091086954
At time: 18.178956985473633 and batch: 850, loss is 5.647927122116089 and perplexity is 283.7027746850427
At time: 19.221468210220337 and batch: 900, loss is 5.658692655563354 and perplexity is 286.77348565879277
At time: 20.26349925994873 and batch: 950, loss is 5.694607343673706 and perplexity is 297.26004962844013
At time: 21.306476593017578 and batch: 1000, loss is 5.661708402633667 and perplexity is 287.6396273336772
At time: 22.353472471237183 and batch: 1050, loss is 5.559432554244995 and perplexity is 259.67544278030107
At time: 23.404049158096313 and batch: 1100, loss is 5.648274269104004 and perplexity is 283.8012783453729
At time: 24.45071315765381 and batch: 1150, loss is 5.558524332046509 and perplexity is 259.43970684527505
At time: 25.493717908859253 and batch: 1200, loss is 5.635872020721435 and perplexity is 280.3032410016962
At time: 26.539995431900024 and batch: 1250, loss is 5.569763917922973 and perplexity is 262.37215056582124
At time: 27.5873966217041 and batch: 1300, loss is 5.592866344451904 and perplexity is 268.50414312201656
At time: 28.63411831855774 and batch: 1350, loss is 5.558304281234741 and perplexity is 259.38262320805967
At time: 29.679269790649414 and batch: 1400, loss is 5.570103569030762 and perplexity is 262.4612806931301
At time: 30.723296880722046 and batch: 1450, loss is 5.531041059494019 and perplexity is 252.40654452077035
At time: 31.770304679870605 and batch: 1500, loss is 5.517908544540405 and perplexity is 249.1134822228635
At time: 32.816449880599976 and batch: 1550, loss is 5.498007335662842 and perplexity is 244.20482885518192
At time: 33.86259651184082 and batch: 1600, loss is 5.529704608917236 and perplexity is 252.0694409600611
At time: 34.90947246551514 and batch: 1650, loss is 5.51025053024292 and perplexity is 247.2130536564437
At time: 35.957486629486084 and batch: 1700, loss is 5.525163230895996 and perplexity is 250.9272937651232
At time: 37.00438380241394 and batch: 1750, loss is 5.542958240509034 and perplexity is 255.4325137003688
At time: 38.050522804260254 and batch: 1800, loss is 5.535681600570679 and perplexity is 253.58056940714425
At time: 39.098012924194336 and batch: 1850, loss is 5.50035436630249 and perplexity is 244.778658204974
At time: 40.14319968223572 and batch: 1900, loss is 5.515260953903198 and perplexity is 248.45480403958697
At time: 41.188305616378784 and batch: 1950, loss is 5.44505467414856 and perplexity is 231.6099424423604
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.02281976744186 and perplexity of 151.83885096733167
finished 1 epochs...
Completing Train Step...
At time: 44.47062420845032 and batch: 50, loss is 5.243305807113647 and perplexity is 189.29484143675006
At time: 45.52966594696045 and batch: 100, loss is 5.168389520645142 and perplexity is 175.63175827787651
At time: 46.56182503700256 and batch: 150, loss is 5.104962348937988 and perplexity is 164.8378640941596
At time: 47.59424591064453 and batch: 200, loss is 5.084721193313599 and perplexity is 161.53489594962895
At time: 48.62613487243652 and batch: 250, loss is 5.083707342147827 and perplexity is 161.3712065993981
At time: 49.66006946563721 and batch: 300, loss is 5.099668636322021 and perplexity is 163.96756540139265
At time: 50.69304323196411 and batch: 350, loss is 5.088615808486939 and perplexity is 162.16523888123643
At time: 51.72484540939331 and batch: 400, loss is 5.055019130706787 and perplexity is 156.8075301543553
At time: 52.757667779922485 and batch: 450, loss is 5.027444553375244 and perplexity is 152.5426994692219
At time: 53.789573192596436 and batch: 500, loss is 5.016550035476684 and perplexity is 150.88984020019976
At time: 54.82185220718384 and batch: 550, loss is 4.973825445175171 and perplexity is 144.57890952435704
At time: 55.85402202606201 and batch: 600, loss is 4.971712169647216 and perplexity is 144.273697065599
At time: 56.888314723968506 and batch: 650, loss is 5.044708404541016 and perplexity is 155.1990372650885
At time: 57.92201566696167 and batch: 700, loss is 5.024313106536865 and perplexity is 152.06576724892926
At time: 58.963449239730835 and batch: 750, loss is 4.987525892257691 and perplexity is 146.57333629633342
At time: 59.996039152145386 and batch: 800, loss is 4.963099670410156 and perplexity is 143.03647539263272
At time: 61.027714252471924 and batch: 850, loss is 4.961864862442017 and perplexity is 142.8599618156972
At time: 62.060503244400024 and batch: 900, loss is 4.9773110580444335 and perplexity is 145.08373493387668
At time: 63.097105979919434 and batch: 950, loss is 5.045004091262817 and perplexity is 155.24493434488832
At time: 64.1343641281128 and batch: 1000, loss is 5.010316467285156 and perplexity is 149.95218360131503
At time: 65.17062163352966 and batch: 1050, loss is 4.927893085479736 and perplexity is 138.088265459984
At time: 66.20501637458801 and batch: 1100, loss is 5.002856292724609 and perplexity is 148.8376765135383
At time: 67.23893880844116 and batch: 1150, loss is 4.921280727386475 and perplexity is 137.17818859331234
At time: 68.27397513389587 and batch: 1200, loss is 4.999321403503418 and perplexity is 148.31248061666037
At time: 69.30851125717163 and batch: 1250, loss is 4.948573236465454 and perplexity is 140.97368425435212
At time: 70.34466695785522 and batch: 1300, loss is 4.969984121322632 and perplexity is 144.02460043259956
At time: 71.38045597076416 and batch: 1350, loss is 4.89404112815857 and perplexity is 133.49194356059266
At time: 72.42323350906372 and batch: 1400, loss is 4.904589967727661 and perplexity is 134.90758220200698
At time: 73.45860242843628 and batch: 1450, loss is 4.847905187606812 and perplexity is 127.47307777633935
At time: 74.49511623382568 and batch: 1500, loss is 4.837777919769287 and perplexity is 126.18863868280572
At time: 75.53024196624756 and batch: 1550, loss is 4.8332975959777835 and perplexity is 125.62453734463513
At time: 76.56554579734802 and batch: 1600, loss is 4.904247817993164 and perplexity is 134.8614315042496
At time: 77.60188388824463 and batch: 1650, loss is 4.861440448760987 and perplexity is 129.2101887794182
At time: 78.63706946372986 and batch: 1700, loss is 4.8935549926757815 and perplexity is 133.42706416152822
At time: 79.67495918273926 and batch: 1750, loss is 4.896942491531372 and perplexity is 133.8798146015308
At time: 80.71192288398743 and batch: 1800, loss is 4.8581414318084715 and perplexity is 128.78462453399663
At time: 81.74684286117554 and batch: 1850, loss is 4.877170248031616 and perplexity is 131.2587082748635
At time: 82.78953266143799 and batch: 1900, loss is 4.931409854888916 and perplexity is 138.57474496445545
At time: 83.82966756820679 and batch: 1950, loss is 4.859086494445801 and perplexity is 128.90639160059587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.732522653978925 and perplexity of 113.58172864733088
finished 2 epochs...
Completing Train Step...
At time: 87.13349962234497 and batch: 50, loss is 4.774583024978638 and perplexity is 118.4609090809065
At time: 88.17357444763184 and batch: 100, loss is 4.724670543670654 and perplexity is 112.69336471516486
At time: 89.20891118049622 and batch: 150, loss is 4.682743072509766 and perplexity is 108.06609952092033
At time: 90.24545764923096 and batch: 200, loss is 4.680755949020385 and perplexity is 107.85157205303322
At time: 91.2789397239685 and batch: 250, loss is 4.678799724578857 and perplexity is 107.64079640118334
At time: 92.31643557548523 and batch: 300, loss is 4.709230575561524 and perplexity is 110.96674652370771
At time: 93.35580229759216 and batch: 350, loss is 4.7103854942321775 and perplexity is 111.09497812537178
At time: 94.39435243606567 and batch: 400, loss is 4.68231276512146 and perplexity is 108.01960788343605
At time: 95.43527960777283 and batch: 450, loss is 4.688903312683106 and perplexity is 108.73386734190974
At time: 96.47313141822815 and batch: 500, loss is 4.680627183914185 and perplexity is 107.83768542797945
At time: 97.53600931167603 and batch: 550, loss is 4.642612915039063 and perplexity is 103.81525393980748
At time: 98.57330250740051 and batch: 600, loss is 4.631151657104493 and perplexity is 102.63219316976556
At time: 99.61188244819641 and batch: 650, loss is 4.693845825195313 and perplexity is 109.27261613133228
At time: 100.64958691596985 and batch: 700, loss is 4.701105346679688 and perplexity is 110.06876938513709
At time: 101.688148021698 and batch: 750, loss is 4.667560977935791 and perplexity is 106.4378213898878
At time: 102.72503590583801 and batch: 800, loss is 4.64012149810791 and perplexity is 103.55692878987813
At time: 103.76275038719177 and batch: 850, loss is 4.644620742797851 and perplexity is 104.0239064875458
At time: 104.7999906539917 and batch: 900, loss is 4.650301628112793 and perplexity is 104.61653610696445
At time: 105.8374924659729 and batch: 950, loss is 4.734247407913208 and perplexity is 113.77779821795447
At time: 106.87540817260742 and batch: 1000, loss is 4.6972017574310305 and perplexity is 109.63994364466477
At time: 107.91528868675232 and batch: 1050, loss is 4.6289276504516605 and perplexity is 102.40419212126395
At time: 108.95251035690308 and batch: 1100, loss is 4.693759183883667 and perplexity is 109.26314901867121
At time: 109.9892725944519 and batch: 1150, loss is 4.6281770324707034 and perplexity is 102.32735453477706
At time: 111.02684164047241 and batch: 1200, loss is 4.702308740615845 and perplexity is 110.2013052051821
At time: 112.06522798538208 and batch: 1250, loss is 4.673879632949829 and perplexity is 107.11249453239884
At time: 113.10543942451477 and batch: 1300, loss is 4.686313171386718 and perplexity is 108.45259568570799
At time: 114.14344143867493 and batch: 1350, loss is 4.597075958251953 and perplexity is 99.19384423194693
At time: 115.18212676048279 and batch: 1400, loss is 4.6080324077606205 and perplexity is 100.2866321840101
At time: 116.22137999534607 and batch: 1450, loss is 4.534045009613037 and perplexity is 93.13453024017265
At time: 117.26097130775452 and batch: 1500, loss is 4.536638565063477 and perplexity is 93.37639331577525
At time: 118.29863214492798 and batch: 1550, loss is 4.544994821548462 and perplexity is 94.15993960546024
At time: 119.33732223510742 and batch: 1600, loss is 4.633103866577148 and perplexity is 102.83274840869456
At time: 120.37686276435852 and batch: 1650, loss is 4.583013410568237 and perplexity is 97.80868830488683
At time: 121.41514182090759 and batch: 1700, loss is 4.615813426971435 and perplexity is 101.07000817503354
At time: 122.45463991165161 and batch: 1750, loss is 4.6161806011199955 and perplexity is 101.10712528303445
At time: 123.49183535575867 and batch: 1800, loss is 4.580066070556641 and perplexity is 97.52083725020515
At time: 124.52932167053223 and batch: 1850, loss is 4.611337385177612 and perplexity is 100.61862555170235
At time: 125.56770610809326 and batch: 1900, loss is 4.6833304500579835 and perplexity is 108.12959376722424
At time: 126.60518598556519 and batch: 1950, loss is 4.6083553028106685 and perplexity is 100.31901946969403
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.651646529796512 and perplexity of 104.75732971808009
finished 3 epochs...
Completing Train Step...
At time: 129.88986039161682 and batch: 50, loss is 4.537015008926391 and perplexity is 93.41155090299385
At time: 130.95287442207336 and batch: 100, loss is 4.495120601654053 and perplexity is 89.5789717058754
At time: 131.99062824249268 and batch: 150, loss is 4.458899345397949 and perplexity is 86.39236858944572
At time: 133.02952909469604 and batch: 200, loss is 4.463157119750977 and perplexity is 86.76099200149139
At time: 134.06748223304749 and batch: 250, loss is 4.458323154449463 and perplexity is 86.34260442685303
At time: 135.10481429100037 and batch: 300, loss is 4.489792213439942 and perplexity is 89.10292956377941
At time: 136.14455270767212 and batch: 350, loss is 4.494049882888794 and perplexity is 89.48310914997442
At time: 137.18261003494263 and batch: 400, loss is 4.458329439163208 and perplexity is 86.34314706711102
At time: 138.21878004074097 and batch: 450, loss is 4.475989465713501 and perplexity is 87.8815131481872
At time: 139.25613689422607 and batch: 500, loss is 4.483545980453491 and perplexity is 88.54810648693794
At time: 140.29821181297302 and batch: 550, loss is 4.442155647277832 and perplexity is 84.95788365442532
At time: 141.33904576301575 and batch: 600, loss is 4.432193050384521 and perplexity is 84.1156847168368
At time: 142.38422060012817 and batch: 650, loss is 4.494451227188111 and perplexity is 89.5190298935276
At time: 143.422461271286 and batch: 700, loss is 4.5024112033843995 and perplexity is 90.23444279799102
At time: 144.4627709388733 and batch: 750, loss is 4.473939170837403 and perplexity is 87.70151472005823
At time: 145.50358319282532 and batch: 800, loss is 4.44547966003418 and perplexity is 85.24075461633304
At time: 146.5424506664276 and batch: 850, loss is 4.446370773315429 and perplexity is 85.31674763904256
At time: 147.58091497421265 and batch: 900, loss is 4.4475605678558345 and perplexity is 85.41831745121065
At time: 148.62052941322327 and batch: 950, loss is 4.53866491317749 and perplexity is 93.56579822959955
At time: 149.6931495666504 and batch: 1000, loss is 4.5000845813751225 and perplexity is 90.02474539527256
At time: 150.733145236969 and batch: 1050, loss is 4.441923971176148 and perplexity is 84.93820322296376
At time: 151.77017259597778 and batch: 1100, loss is 4.496113967895508 and perplexity is 89.66800064416222
At time: 152.80963325500488 and batch: 1150, loss is 4.444620161056519 and perplexity is 85.16752175117993
At time: 153.8485872745514 and batch: 1200, loss is 4.514143495559693 and perplexity is 91.29933423906307
At time: 154.88851070404053 and batch: 1250, loss is 4.490490436553955 and perplexity is 89.16516501331344
At time: 155.92851948738098 and batch: 1300, loss is 4.5025572681427 and perplexity is 90.24762383268761
At time: 156.97075390815735 and batch: 1350, loss is 4.404481449127197 and perplexity is 81.81670571705472
At time: 158.0120415687561 and batch: 1400, loss is 4.423422107696533 and perplexity is 83.38113691438593
At time: 159.05011582374573 and batch: 1450, loss is 4.341717658042907 and perplexity is 76.83940988201967
At time: 160.0883069038391 and batch: 1500, loss is 4.344349784851074 and perplexity is 77.0419273616158
At time: 161.13107419013977 and batch: 1550, loss is 4.3585646438598635 and perplexity is 78.14488814064721
At time: 162.17342591285706 and batch: 1600, loss is 4.452141828536988 and perplexity is 85.8105387784794
At time: 163.2150366306305 and batch: 1650, loss is 4.400244417190552 and perplexity is 81.47077909058126
At time: 164.26276922225952 and batch: 1700, loss is 4.4391398620605464 and perplexity is 84.70205488102097
At time: 165.30388975143433 and batch: 1750, loss is 4.435426092147827 and perplexity is 84.38807432470044
At time: 166.3441298007965 and batch: 1800, loss is 4.398731670379639 and perplexity is 81.34762760132568
At time: 167.383540391922 and batch: 1850, loss is 4.433757381439209 and perplexity is 84.24737246939132
At time: 168.4236204624176 and batch: 1900, loss is 4.51204216003418 and perplexity is 91.1076851346273
At time: 169.46559381484985 and batch: 1950, loss is 4.435958919525146 and perplexity is 84.43305058224648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6206327216569765 and perplexity of 101.55826992190599
finished 4 epochs...
Completing Train Step...
At time: 172.75747442245483 and batch: 50, loss is 4.375045304298401 and perplexity is 79.44343859998287
At time: 173.82659459114075 and batch: 100, loss is 4.327513437271119 and perplexity is 75.75568092379599
At time: 174.8688621520996 and batch: 150, loss is 4.2952980709075925 and perplexity is 73.35407590270985
At time: 175.93840289115906 and batch: 200, loss is 4.304472093582153 and perplexity is 74.03012415782675
At time: 176.98312091827393 and batch: 250, loss is 4.299869022369385 and perplexity is 73.69014130737771
At time: 178.02550172805786 and batch: 300, loss is 4.329781742095947 and perplexity is 75.92771293710483
At time: 179.06679105758667 and batch: 350, loss is 4.336188554763794 and perplexity is 76.4157292153183
At time: 180.10801196098328 and batch: 400, loss is 4.294493293762207 and perplexity is 73.29506596701114
At time: 181.14962911605835 and batch: 450, loss is 4.326673612594605 and perplexity is 75.69208614154162
At time: 182.1924388408661 and batch: 500, loss is 4.335422229766846 and perplexity is 76.35719236385151
At time: 183.2405149936676 and batch: 550, loss is 4.300483465194702 and perplexity is 73.73543359933761
At time: 184.2878167629242 and batch: 600, loss is 4.28595878124237 and perplexity is 72.67219006072706
At time: 185.33055686950684 and batch: 650, loss is 4.345782232284546 and perplexity is 77.15236495187209
At time: 186.3723168373108 and batch: 700, loss is 4.3579194402694705 and perplexity is 78.09448504012722
At time: 187.4139440059662 and batch: 750, loss is 4.331307621002197 and perplexity is 76.04365786914212
At time: 188.45893716812134 and batch: 800, loss is 4.297215843200684 and perplexity is 73.49488729599875
At time: 189.5055332183838 and batch: 850, loss is 4.301790933609009 and perplexity is 73.83190340165099
At time: 190.55077981948853 and batch: 900, loss is 4.2992818069458005 and perplexity is 73.64688202233869
At time: 191.59391236305237 and batch: 950, loss is 4.393206233978272 and perplexity is 80.89938596435879
At time: 192.63644766807556 and batch: 1000, loss is 4.351905679702758 and perplexity is 77.6262528348476
At time: 193.67841625213623 and batch: 1050, loss is 4.302436771392823 and perplexity is 73.87960223571532
At time: 194.72046327590942 and batch: 1100, loss is 4.349947919845581 and perplexity is 77.47442794001982
At time: 195.76396703720093 and batch: 1150, loss is 4.303338866233826 and perplexity is 73.94627871347922
At time: 196.81303334236145 and batch: 1200, loss is 4.367230944633484 and perplexity is 78.82505826764749
At time: 197.8616235256195 and batch: 1250, loss is 4.352805519104004 and perplexity is 77.69613543256152
At time: 198.90417885780334 and batch: 1300, loss is 4.363540410995483 and perplexity is 78.53468787900803
At time: 199.94747257232666 and batch: 1350, loss is 4.2580740976333615 and perplexity is 70.67374157594952
At time: 200.98874139785767 and batch: 1400, loss is 4.287636480331421 and perplexity is 72.79421445928082
At time: 202.03135466575623 and batch: 1450, loss is 4.198485636711121 and perplexity is 66.58542013649617
At time: 203.08014702796936 and batch: 1500, loss is 4.207025718688965 and perplexity is 67.15650014716724
At time: 204.1245288848877 and batch: 1550, loss is 4.217672853469849 and perplexity is 67.87534448114315
At time: 205.16855645179749 and batch: 1600, loss is 4.3184100532531735 and perplexity is 75.06917736254384
At time: 206.21235990524292 and batch: 1650, loss is 4.262849082946778 and perplexity is 71.01201463573281
At time: 207.25566577911377 and batch: 1700, loss is 4.300523715019226 and perplexity is 73.73840149732948
At time: 208.29714941978455 and batch: 1750, loss is 4.297015008926391 and perplexity is 73.48012848573151
At time: 209.34088611602783 and batch: 1800, loss is 4.25758999824524 and perplexity is 70.6395367408342
At time: 210.3839728832245 and batch: 1850, loss is 4.294361343383789 and perplexity is 73.28539529335923
At time: 211.42967128753662 and batch: 1900, loss is 4.380108976364136 and perplexity is 79.84673433777417
At time: 212.47378540039062 and batch: 1950, loss is 4.294880638122558 and perplexity is 73.32346189660163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.609256052416424 and perplexity of 100.40942249606397
finished 5 epochs...
Completing Train Step...
At time: 215.78081345558167 and batch: 50, loss is 4.242128186225891 and perplexity is 69.55572196477898
At time: 216.81728553771973 and batch: 100, loss is 4.199469041824341 and perplexity is 66.65093278658215
At time: 217.8555085659027 and batch: 150, loss is 4.166836481094361 and perplexity is 64.51104704129108
At time: 218.8932912349701 and batch: 200, loss is 4.175764145851136 and perplexity is 65.0895585784854
At time: 219.93160009384155 and batch: 250, loss is 4.17156596660614 and perplexity is 64.81687373501956
At time: 220.9690079689026 and batch: 300, loss is 4.200949301719666 and perplexity is 66.74966654715662
At time: 222.00766134262085 and batch: 350, loss is 4.207773356437683 and perplexity is 67.20672765540004
At time: 223.04564237594604 and batch: 400, loss is 4.167452654838562 and perplexity is 64.55080930366185
At time: 224.0854229927063 and batch: 450, loss is 4.203587341308594 and perplexity is 66.92598727833531
At time: 225.12465238571167 and batch: 500, loss is 4.211904020309448 and perplexity is 67.4849102010232
At time: 226.16327691078186 and batch: 550, loss is 4.182079787254334 and perplexity is 65.50194175094093
At time: 227.2005693912506 and batch: 600, loss is 4.17095003604889 and perplexity is 64.77696333414016
At time: 228.26464700698853 and batch: 650, loss is 4.227308344841004 and perplexity is 68.53251778659188
At time: 229.29987621307373 and batch: 700, loss is 4.2389380693435665 and perplexity is 69.33418463474443
At time: 230.33767294883728 and batch: 750, loss is 4.208384499549866 and perplexity is 67.24781313737486
At time: 231.3751037120819 and batch: 800, loss is 4.180608415603638 and perplexity is 65.40563491972853
At time: 232.41412377357483 and batch: 850, loss is 4.184027791023254 and perplexity is 65.62966414180357
At time: 233.4530565738678 and batch: 900, loss is 4.180658383369446 and perplexity is 65.40890317482972
At time: 234.491553068161 and batch: 950, loss is 4.274285101890564 and perplexity is 71.82877069781013
At time: 235.53009939193726 and batch: 1000, loss is 4.231123256683349 and perplexity is 68.79446263084033
At time: 236.5662965774536 and batch: 1050, loss is 4.183664960861206 and perplexity is 65.6058560395378
At time: 237.61240315437317 and batch: 1100, loss is 4.233153805732727 and perplexity is 68.93429508181744
At time: 238.65088605880737 and batch: 1150, loss is 4.185840010643005 and perplexity is 65.74870734042955
At time: 239.69057416915894 and batch: 1200, loss is 4.252646274566651 and perplexity is 70.2911761990393
At time: 240.72943496704102 and batch: 1250, loss is 4.2400721836090085 and perplexity is 69.41286212882267
At time: 241.77600598335266 and batch: 1300, loss is 4.240438904762268 and perplexity is 69.4383219617179
At time: 242.81397557258606 and batch: 1350, loss is 4.140172672271729 and perplexity is 62.81366669136163
At time: 243.85335040092468 and batch: 1400, loss is 4.172206587791443 and perplexity is 64.85841010061667
At time: 244.8914976119995 and batch: 1450, loss is 4.081789960861206 and perplexity is 59.25143273244574
At time: 245.93130493164062 and batch: 1500, loss is 4.089315824508667 and perplexity is 59.699033113203406
At time: 246.97118091583252 and batch: 1550, loss is 4.104086403846741 and perplexity is 60.58736686973275
At time: 248.01162552833557 and batch: 1600, loss is 4.2053127145767215 and perplexity is 67.04155926146291
At time: 249.05081939697266 and batch: 1650, loss is 4.152697200775147 and perplexity is 63.605325478238036
At time: 250.08852171897888 and batch: 1700, loss is 4.188820629119873 and perplexity is 65.9449715013485
At time: 251.12742686271667 and batch: 1750, loss is 4.184306778907776 and perplexity is 65.6479765773194
At time: 252.166419506073 and batch: 1800, loss is 4.143289937973022 and perplexity is 63.0097790885281
At time: 253.205393075943 and batch: 1850, loss is 4.174519357681274 and perplexity is 65.00858627312482
At time: 254.2457993030548 and batch: 1900, loss is 4.263228516578675 and perplexity is 71.03896409479661
At time: 255.2844660282135 and batch: 1950, loss is 4.182593593597412 and perplexity is 65.5356057117342
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.60517578125 and perplexity of 100.0005595277562
finished 6 epochs...
Completing Train Step...
At time: 258.56738805770874 and batch: 50, loss is 4.131141805648804 and perplexity is 62.248958585134496
At time: 259.63446974754333 and batch: 100, loss is 4.094196720123291 and perplexity is 59.991130129757686
At time: 260.67489528656006 and batch: 150, loss is 4.065279760360718 and perplexity is 58.28121101466665
At time: 261.7150311470032 and batch: 200, loss is 4.070763387680054 and perplexity is 58.601681322408666
At time: 262.75649976730347 and batch: 250, loss is 4.065127291679382 and perplexity is 58.27232563266506
At time: 263.7946479320526 and batch: 300, loss is 4.094018793106079 and perplexity is 59.980457036458496
At time: 264.83300137519836 and batch: 350, loss is 4.103336057662964 and perplexity is 60.54192242188314
At time: 265.8721613883972 and batch: 400, loss is 4.056968331336975 and perplexity is 57.798818329148865
At time: 266.91269850730896 and batch: 450, loss is 4.096716389656067 and perplexity is 60.14247854650714
At time: 267.95325326919556 and batch: 500, loss is 4.114432096481323 and perplexity is 61.21743879023664
At time: 268.9933092594147 and batch: 550, loss is 4.08450409412384 and perplexity is 59.41246745287373
At time: 270.0334084033966 and batch: 600, loss is 4.072470054626465 and perplexity is 58.701780268410396
At time: 271.0718915462494 and batch: 650, loss is 4.1249582481384275 and perplexity is 61.86522620808406
At time: 272.1101236343384 and batch: 700, loss is 4.139266633987427 and perplexity is 62.75678087881539
At time: 273.154168844223 and batch: 750, loss is 4.110536575317383 and perplexity is 60.97942884919335
At time: 274.2042644023895 and batch: 800, loss is 4.077167901992798 and perplexity is 58.97820105519759
At time: 275.2479600906372 and batch: 850, loss is 4.082043251991272 and perplexity is 59.26644249564024
At time: 276.28836250305176 and batch: 900, loss is 4.073839654922486 and perplexity is 58.78223332573231
At time: 277.3298885822296 and batch: 950, loss is 4.170912261009216 and perplexity is 64.77451642799659
At time: 278.3683021068573 and batch: 1000, loss is 4.131779656410218 and perplexity is 62.2886767965643
At time: 279.40628457069397 and batch: 1050, loss is 4.083697080612183 and perplexity is 59.364540130477856
At time: 280.4727804660797 and batch: 1100, loss is 4.135053119659424 and perplexity is 62.492910584425665
At time: 281.51273560523987 and batch: 1150, loss is 4.090823349952697 and perplexity is 59.7890987957024
At time: 282.55390548706055 and batch: 1200, loss is 4.1542902755737305 and perplexity is 63.7067342737644
At time: 283.59442925453186 and batch: 1250, loss is 4.140970129966735 and perplexity is 62.8637779113496
At time: 284.63552832603455 and batch: 1300, loss is 4.143713045120239 and perplexity is 63.036444617195095
At time: 285.6747751235962 and batch: 1350, loss is 4.045009422302246 and perplexity is 57.111724155536514
At time: 286.7202658653259 and batch: 1400, loss is 4.0795801162719725 and perplexity is 59.120640842518625
At time: 287.7602651119232 and batch: 1450, loss is 3.978578066825867 and perplexity is 53.44099065839133
At time: 288.79937267303467 and batch: 1500, loss is 3.9899760770797728 and perplexity is 54.05359622798831
At time: 289.8388864994049 and batch: 1550, loss is 4.006615653038025 and perplexity is 54.96054988436206
At time: 290.8788683414459 and batch: 1600, loss is 4.109761414527893 and perplexity is 60.932178302735366
At time: 291.9181377887726 and batch: 1650, loss is 4.0550334978103635 and perplexity is 57.68709535517862
At time: 292.9581923484802 and batch: 1700, loss is 4.093207063674927 and perplexity is 59.93178888954399
At time: 293.9967956542969 and batch: 1750, loss is 4.090357317924499 and perplexity is 59.76124165239118
At time: 295.0368776321411 and batch: 1800, loss is 4.046265325546265 and perplexity is 57.18349601499675
At time: 296.07884764671326 and batch: 1850, loss is 4.079045205116272 and perplexity is 59.08902500878475
At time: 297.11888456344604 and batch: 1900, loss is 4.165252742767334 and perplexity is 64.40895928505954
At time: 298.15994119644165 and batch: 1950, loss is 4.0858829927444456 and perplexity is 59.49444773054764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.611993550145349 and perplexity of 100.68466963442827
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 301.452481508255 and batch: 50, loss is 4.069729633331299 and perplexity is 58.541132880996685
At time: 302.52478647232056 and batch: 100, loss is 4.05343982219696 and perplexity is 57.595234056101546
At time: 303.5778968334198 and batch: 150, loss is 4.023978281021118 and perplexity is 55.92314184696241
At time: 304.62238359451294 and batch: 200, loss is 4.033514103889465 and perplexity is 56.45896572235379
At time: 305.6672029495239 and batch: 250, loss is 4.032296442985535 and perplexity is 56.39025968593374
At time: 306.7364385128021 and batch: 300, loss is 4.049015889167785 and perplexity is 57.340999371087136
At time: 307.7793822288513 and batch: 350, loss is 4.0584262132644655 and perplexity is 57.88314363505543
At time: 308.82364892959595 and batch: 400, loss is 4.0022876262664795 and perplexity is 54.72319316670798
At time: 309.8746016025543 and batch: 450, loss is 4.0426544570922855 and perplexity is 56.97738627467221
At time: 310.92285346984863 and batch: 500, loss is 4.049070239067078 and perplexity is 57.34411593331993
At time: 311.96745800971985 and batch: 550, loss is 4.014099130630493 and perplexity is 55.37338873637725
At time: 313.01104974746704 and batch: 600, loss is 3.9911204195022583 and perplexity is 54.1154874568653
At time: 314.0561237335205 and batch: 650, loss is 4.027654843330383 and perplexity is 56.12912518575762
At time: 315.1003451347351 and batch: 700, loss is 4.041135187149048 and perplexity is 56.89088796803738
At time: 316.1453969478607 and batch: 750, loss is 3.9966809272766115 and perplexity is 54.417235203443475
At time: 317.190087556839 and batch: 800, loss is 3.9668842792510985 and perplexity is 52.819702750059584
At time: 318.23543405532837 and batch: 850, loss is 3.968694319725037 and perplexity is 52.91539512727049
At time: 319.2814440727234 and batch: 900, loss is 3.947670884132385 and perplexity is 51.81454410753142
At time: 320.32543325424194 and batch: 950, loss is 4.0377694272995 and perplexity is 56.69972877992917
At time: 321.36812448501587 and batch: 1000, loss is 3.9835225248336794 and perplexity is 53.70588172430991
At time: 322.41348242759705 and batch: 1050, loss is 3.9428040313720705 and perplexity is 51.56298300249132
At time: 323.47198009490967 and batch: 1100, loss is 3.9765430307388305 and perplexity is 53.332346898355205
At time: 324.51970887184143 and batch: 1150, loss is 3.930417594909668 and perplexity is 50.928240603280194
At time: 325.5648527145386 and batch: 1200, loss is 3.980633430480957 and perplexity is 53.550944286920085
At time: 326.6089680194855 and batch: 1250, loss is 3.9575389194488526 and perplexity is 52.3283829790415
At time: 327.6506028175354 and batch: 1300, loss is 3.9522308921813964 and perplexity is 52.05135837284252
At time: 328.6955599784851 and batch: 1350, loss is 3.854195251464844 and perplexity is 47.19062506997553
At time: 329.73890566825867 and batch: 1400, loss is 3.876668405532837 and perplexity is 48.26315366895067
At time: 330.7843725681305 and batch: 1450, loss is 3.766817693710327 and perplexity is 43.24223560640716
At time: 331.82877254486084 and batch: 1500, loss is 3.773969655036926 and perplexity is 43.55261097647345
At time: 332.8740372657776 and batch: 1550, loss is 3.7792374181747435 and perplexity is 43.78264115544804
At time: 333.9188914299011 and batch: 1600, loss is 3.8694227600097655 and perplexity is 47.91471980415499
At time: 334.9623465538025 and batch: 1650, loss is 3.8059070444107057 and perplexity is 44.96601779628255
At time: 336.00750160217285 and batch: 1700, loss is 3.834439687728882 and perplexity is 46.267496157906045
At time: 337.05473709106445 and batch: 1750, loss is 3.8174946165084838 and perplexity is 45.49009529830954
At time: 338.10005950927734 and batch: 1800, loss is 3.7691264390945434 and perplexity is 43.34218625416769
At time: 339.1455509662628 and batch: 1850, loss is 3.793001194000244 and perplexity is 44.38942183086468
At time: 340.1907012462616 and batch: 1900, loss is 3.8739571142196656 and perplexity is 48.13247543309703
At time: 341.23478412628174 and batch: 1950, loss is 3.795070424079895 and perplexity is 44.481368854701586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.527298328488372 and perplexity of 92.50829613923406
finished 8 epochs...
Completing Train Step...
At time: 344.5192790031433 and batch: 50, loss is 3.9675296115875245 and perplexity is 52.853800013094485
At time: 345.55917096138 and batch: 100, loss is 3.9440753269195556 and perplexity is 51.628576478710265
At time: 346.60100769996643 and batch: 150, loss is 3.9084701347351074 and perplexity is 49.822671664204684
At time: 347.6416881084442 and batch: 200, loss is 3.9144766616821287 and perplexity is 50.122833446600524
At time: 348.677814245224 and batch: 250, loss is 3.9133294439315796 and perplexity is 50.065364613298534
At time: 349.71851348876953 and batch: 300, loss is 3.931765604019165 and perplexity is 50.996938627922816
At time: 350.75638794898987 and batch: 350, loss is 3.9447008037567137 and perplexity is 51.66087905863778
At time: 351.79787516593933 and batch: 400, loss is 3.89252317905426 and perplexity is 49.034453273094144
At time: 352.8395974636078 and batch: 450, loss is 3.9394372701644897 and perplexity is 51.38967465918031
At time: 353.88194966316223 and batch: 500, loss is 3.9479475831985473 and perplexity is 51.82888312720478
At time: 354.92187428474426 and batch: 550, loss is 3.916902241706848 and perplexity is 50.244557956781264
At time: 355.96129417419434 and batch: 600, loss is 3.898958420753479 and perplexity is 49.35101932855835
At time: 357.00175881385803 and batch: 650, loss is 3.938814625740051 and perplexity is 51.35768712424362
At time: 358.04099583625793 and batch: 700, loss is 3.953305721282959 and perplexity is 52.10733476473609
At time: 359.126677274704 and batch: 750, loss is 3.913099856376648 and perplexity is 50.05387154803308
At time: 360.1666581630707 and batch: 800, loss is 3.8848516368865966 and perplexity is 48.65972261597978
At time: 361.2079243659973 and batch: 850, loss is 3.8883770751953124 and perplexity is 48.83157221076493
At time: 362.2466721534729 and batch: 900, loss is 3.8697868156433106 and perplexity is 47.93216660343952
At time: 363.2904772758484 and batch: 950, loss is 3.9626432704925536 and perplexity is 52.59616826896265
At time: 364.33196783065796 and batch: 1000, loss is 3.9117396545410155 and perplexity is 49.985834462647034
At time: 365.37132239341736 and batch: 1050, loss is 3.875199542045593 and perplexity is 48.19231372458775
At time: 366.41195130348206 and batch: 1100, loss is 3.9088373804092407 and perplexity is 49.840972185035
At time: 367.4530348777771 and batch: 1150, loss is 3.868957829475403 and perplexity is 47.89244796570268
At time: 368.4940369129181 and batch: 1200, loss is 3.9213476514816286 and perplexity is 50.46841280046167
At time: 369.53270149230957 and batch: 1250, loss is 3.9034041595458984 and perplexity is 49.57090949458348
At time: 370.5722451210022 and batch: 1300, loss is 3.8992377138137817 and perplexity is 49.36480465075848
At time: 371.6115357875824 and batch: 1350, loss is 3.8044601821899415 and perplexity is 44.90100520738578
At time: 372.6517713069916 and batch: 1400, loss is 3.83309588432312 and perplexity is 46.2053634953847
At time: 373.69148111343384 and batch: 1450, loss is 3.7262897539138793 and perplexity is 41.5247549373861
At time: 374.73106360435486 and batch: 1500, loss is 3.73488395690918 and perplexity is 41.88316502916917
At time: 375.77074909210205 and batch: 1550, loss is 3.74410400390625 and perplexity is 42.271115491594074
At time: 376.80934739112854 and batch: 1600, loss is 3.839726791381836 and perplexity is 46.51276501544927
At time: 377.84834909439087 and batch: 1650, loss is 3.7771508502960205 and perplexity is 43.69138094618851
At time: 378.88979959487915 and batch: 1700, loss is 3.811534700393677 and perplexity is 45.219784461366714
At time: 379.9307425022125 and batch: 1750, loss is 3.7995112800598143 and perplexity is 44.679343470595406
At time: 380.9706747531891 and batch: 1800, loss is 3.7553610754013063 and perplexity is 42.74965287220179
At time: 382.0083076953888 and batch: 1850, loss is 3.7830161571502687 and perplexity is 43.94839730541158
At time: 383.0531244277954 and batch: 1900, loss is 3.8681836128234863 and perplexity is 47.85538318492324
At time: 384.092570066452 and batch: 1950, loss is 3.792428994178772 and perplexity is 44.364029477060775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.527790016351744 and perplexity of 92.55379252980197
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 387.3478813171387 and batch: 50, loss is 3.9352339124679565 and perplexity is 51.17411882119844
At time: 388.4129738807678 and batch: 100, loss is 3.9351110744476316 and perplexity is 51.16783307982249
At time: 389.4565246105194 and batch: 150, loss is 3.9087697792053224 and perplexity is 49.837602989192966
At time: 390.4938349723816 and batch: 200, loss is 3.915220994949341 and perplexity is 50.16015542725453
At time: 391.53304386138916 and batch: 250, loss is 3.919643211364746 and perplexity is 50.38246567971663
At time: 392.57323718070984 and batch: 300, loss is 3.9333575677871706 and perplexity is 51.07818856281429
At time: 393.6121287345886 and batch: 350, loss is 3.9493016147613527 and perplexity is 51.89910860385062
At time: 394.6532895565033 and batch: 400, loss is 3.8976465320587157 and perplexity is 49.28631873349519
At time: 395.69325375556946 and batch: 450, loss is 3.948830871582031 and perplexity is 51.874683201959215
At time: 396.7345063686371 and batch: 500, loss is 3.956509494781494 and perplexity is 52.27454256787819
At time: 397.7736520767212 and batch: 550, loss is 3.9259760904312135 and perplexity is 50.70254418142042
At time: 398.8146345615387 and batch: 600, loss is 3.899044227600098 and perplexity is 49.35525416559076
At time: 399.8556709289551 and batch: 650, loss is 3.934901671409607 and perplexity is 51.15711950189347
At time: 400.8960556983948 and batch: 700, loss is 3.94718544960022 and perplexity is 51.78939764252827
At time: 401.9360270500183 and batch: 750, loss is 3.9015185022354126 and perplexity is 49.47752382106755
At time: 402.9776883125305 and batch: 800, loss is 3.8653994750976564 and perplexity is 47.72233250886171
At time: 404.0175869464874 and batch: 850, loss is 3.8706945753097535 and perplexity is 47.97569724569878
At time: 405.0571024417877 and batch: 900, loss is 3.8485548448562623 and perplexity is 46.92520001278091
At time: 406.09690952301025 and batch: 950, loss is 3.9422250318527223 and perplexity is 51.53313670144751
At time: 407.1367437839508 and batch: 1000, loss is 3.886493363380432 and perplexity is 48.73967418312657
At time: 408.17630767822266 and batch: 1050, loss is 3.8529101991653443 and perplexity is 47.13002159637094
At time: 409.21806287765503 and batch: 1100, loss is 3.8784126091003417 and perplexity is 48.347407890655944
At time: 410.25859689712524 and batch: 1150, loss is 3.83740882396698 and perplexity is 46.40507480119043
At time: 411.2967984676361 and batch: 1200, loss is 3.883697304725647 and perplexity is 48.603585539870934
At time: 412.3599765300751 and batch: 1250, loss is 3.861049175262451 and perplexity is 47.51517697465927
At time: 413.4009804725647 and batch: 1300, loss is 3.853297963142395 and perplexity is 47.14830046469794
At time: 414.44227480888367 and batch: 1350, loss is 3.755392141342163 and perplexity is 42.75098095101847
At time: 415.4823508262634 and batch: 1400, loss is 3.7839149141311648 and perplexity is 43.987913989576874
At time: 416.5255243778229 and batch: 1450, loss is 3.67232928276062 and perplexity is 39.343441212419364
At time: 417.56555366516113 and batch: 1500, loss is 3.6769371318817137 and perplexity is 39.52514817105141
At time: 418.6047637462616 and batch: 1550, loss is 3.6865411472320555 and perplexity is 39.90657699312197
At time: 419.6432955265045 and batch: 1600, loss is 3.7817302322387696 and perplexity is 43.89191928752385
At time: 420.6838071346283 and batch: 1650, loss is 3.7099046230316164 and perplexity is 40.84991020058965
At time: 421.72515988349915 and batch: 1700, loss is 3.7365971279144286 and perplexity is 41.95497955081895
At time: 422.76476669311523 and batch: 1750, loss is 3.721968069076538 and perplexity is 41.345685253673714
At time: 423.81270575523376 and batch: 1800, loss is 3.6739961194992063 and perplexity is 39.409074990855125
At time: 424.852219581604 and batch: 1850, loss is 3.698584885597229 and perplexity is 40.39010727686732
At time: 425.88994455337524 and batch: 1900, loss is 3.7835660409927367 and perplexity is 43.972570464597915
At time: 426.9333817958832 and batch: 1950, loss is 3.712456669807434 and perplexity is 40.95429422200823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.500698923510174 and perplexity of 90.08006838144689
finished 10 epochs...
Completing Train Step...
At time: 430.1805953979492 and batch: 50, loss is 3.9167964124679564 and perplexity is 50.23924089480952
At time: 431.24669075012207 and batch: 100, loss is 3.9054639530181885 and perplexity is 49.6731205610817
At time: 432.285117149353 and batch: 150, loss is 3.8725006437301634 and perplexity is 48.06242293012725
At time: 433.3203589916229 and batch: 200, loss is 3.8731235027313233 and perplexity is 48.09236836779141
At time: 434.3593966960907 and batch: 250, loss is 3.875809712409973 and perplexity is 48.221728219227245
At time: 435.3989017009735 and batch: 300, loss is 3.8848818731307984 and perplexity is 48.66119392547891
At time: 436.43899512290955 and batch: 350, loss is 3.9022932767868044 and perplexity is 49.515872601301176
At time: 437.47883796691895 and batch: 400, loss is 3.850269012451172 and perplexity is 47.0057066512497
At time: 438.5438950061798 and batch: 450, loss is 3.9039843606948854 and perplexity is 49.5996789384537
At time: 439.5817039012909 and batch: 500, loss is 3.9126744937896727 and perplexity is 50.03258503130814
At time: 440.61748337745667 and batch: 550, loss is 3.8827035284042357 and perplexity is 48.55530843971838
At time: 441.65443229675293 and batch: 600, loss is 3.858028812408447 and perplexity is 47.37188041186758
At time: 442.69903016090393 and batch: 650, loss is 3.8953757667541504 and perplexity is 49.17452804417099
At time: 443.73838353157043 and batch: 700, loss is 3.9111644411087036 and perplexity is 49.95709020707231
At time: 444.77763509750366 and batch: 750, loss is 3.8672707366943357 and perplexity is 47.81171708186634
At time: 445.81769943237305 and batch: 800, loss is 3.8325689172744752 and perplexity is 46.18102120570755
At time: 446.8544714450836 and batch: 850, loss is 3.838710289001465 and perplexity is 46.46550870124044
At time: 447.89519739151 and batch: 900, loss is 3.8190876340866087 and perplexity is 45.56261957063355
At time: 448.9356563091278 and batch: 950, loss is 3.914096574783325 and perplexity is 50.1037860343418
At time: 449.9824388027191 and batch: 1000, loss is 3.858802947998047 and perplexity is 47.408566868754505
At time: 451.02201533317566 and batch: 1050, loss is 3.8264654541015624 and perplexity is 45.90001546991199
At time: 452.06271290779114 and batch: 1100, loss is 3.8532391023635864 and perplexity is 47.14552536068627
At time: 453.1008322238922 and batch: 1150, loss is 3.81527615070343 and perplexity is 45.38928893649887
At time: 454.14077949523926 and batch: 1200, loss is 3.863444137573242 and perplexity is 47.629110411388886
At time: 455.1809916496277 and batch: 1250, loss is 3.843473343849182 and perplexity is 46.68735437986716
At time: 456.2217195034027 and batch: 1300, loss is 3.8371849918365477 and perplexity is 46.3946890168143
At time: 457.2618656158447 and batch: 1350, loss is 3.741307396888733 and perplexity is 42.15306494081092
At time: 458.3029806613922 and batch: 1400, loss is 3.7726078462600707 and perplexity is 43.49334101492743
At time: 459.344069480896 and batch: 1450, loss is 3.6631345176696777 and perplexity is 38.98334554710983
At time: 460.3826389312744 and batch: 1500, loss is 3.66968909740448 and perplexity is 39.23970423774977
At time: 461.4236731529236 and batch: 1550, loss is 3.6816638231277468 and perplexity is 39.71241356711307
At time: 462.46366453170776 and batch: 1600, loss is 3.7786583852767945 and perplexity is 43.7572969041457
At time: 463.5023651123047 and batch: 1650, loss is 3.7090767288208006 and perplexity is 40.81610479200414
At time: 464.54224491119385 and batch: 1700, loss is 3.738367547988892 and perplexity is 42.02932327923551
At time: 465.58355712890625 and batch: 1750, loss is 3.7255820846557617 and perplexity is 41.495379540124766
At time: 466.62489199638367 and batch: 1800, loss is 3.6800419092178345 and perplexity is 39.64805565675574
At time: 467.66389751434326 and batch: 1850, loss is 3.706268105506897 and perplexity is 40.701628564056456
At time: 468.70447063446045 and batch: 1900, loss is 3.7918819522857667 and perplexity is 44.339767131259144
At time: 469.74591517448425 and batch: 1950, loss is 3.7209420442581176 and perplexity is 41.30328530988578
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.500502191587936 and perplexity of 90.06234849952922
finished 11 epochs...
Completing Train Step...
At time: 473.0252163410187 and batch: 50, loss is 3.900396857261658 and perplexity is 49.42205871705238
At time: 474.0687665939331 and batch: 100, loss is 3.8869278478622435 and perplexity is 48.76085541633304
At time: 475.11211252212524 and batch: 150, loss is 3.8530776834487916 and perplexity is 47.13791579532554
At time: 476.1524739265442 and batch: 200, loss is 3.8525607919692995 and perplexity is 47.11355690428387
At time: 477.19606471061707 and batch: 250, loss is 3.8547437143325807 and perplexity is 47.21651447457126
At time: 478.2389419078827 and batch: 300, loss is 3.8633963441848755 and perplexity is 47.62683410921397
At time: 479.28210258483887 and batch: 350, loss is 3.880844388008118 and perplexity is 48.46512116573125
At time: 480.32567739486694 and batch: 400, loss is 3.8284607982635497 and perplexity is 45.991693231741294
At time: 481.36798548698425 and batch: 450, loss is 3.8829156303405763 and perplexity is 48.565608206919734
At time: 482.4123787879944 and batch: 500, loss is 3.8923995685577393 and perplexity is 49.028392474575305
At time: 483.45654034614563 and batch: 550, loss is 3.8625282716751097 and perplexity is 47.585508503202924
At time: 484.4998724460602 and batch: 600, loss is 3.8389742279052737 and perplexity is 46.47777437529504
At time: 485.5428490638733 and batch: 650, loss is 3.8762881135940552 and perplexity is 48.24480307018373
At time: 486.5863769054413 and batch: 700, loss is 3.893190360069275 and perplexity is 49.067179045192574
At time: 487.6291596889496 and batch: 750, loss is 3.8499171257019045 and perplexity is 46.98916887582183
At time: 488.67010402679443 and batch: 800, loss is 3.8157469606399537 and perplexity is 45.41066369607169
At time: 489.7481265068054 and batch: 850, loss is 3.8221242952346803 and perplexity is 45.70118809363119
At time: 490.79205346107483 and batch: 900, loss is 3.8030885791778566 and perplexity is 44.83946107010827
At time: 491.834899187088 and batch: 950, loss is 3.8989778757095337 and perplexity is 49.35197945981026
At time: 492.8796434402466 and batch: 1000, loss is 3.8438543319702148 and perplexity is 46.70514509609892
At time: 493.93049335479736 and batch: 1050, loss is 3.8123699235916138 and perplexity is 45.25756885135755
At time: 494.97217655181885 and batch: 1100, loss is 3.8395608139038084 and perplexity is 46.50504558465947
At time: 496.01442646980286 and batch: 1150, loss is 3.802952094078064 and perplexity is 44.8333415694093
At time: 497.0655024051666 and batch: 1200, loss is 3.851543264389038 and perplexity is 47.065641942261344
At time: 498.10799074172974 and batch: 1250, loss is 3.832843155860901 and perplexity is 46.19368756040493
At time: 499.1501610279083 and batch: 1300, loss is 3.82757803440094 and perplexity is 45.95111134172443
At time: 500.19501519203186 and batch: 1350, loss is 3.7322278690338133 and perplexity is 41.77206727037267
At time: 501.2391483783722 and batch: 1400, loss is 3.764748296737671 and perplexity is 43.15284278147436
At time: 502.28828740119934 and batch: 1450, loss is 3.656099963188171 and perplexity is 38.710077365829676
At time: 503.3353440761566 and batch: 1500, loss is 3.6632563304901122 and perplexity is 38.98809450761716
At time: 504.3794927597046 and batch: 1550, loss is 3.67636531829834 and perplexity is 39.50255361499502
At time: 505.4254672527313 and batch: 1600, loss is 3.774313235282898 and perplexity is 43.56757736419582
At time: 506.4707043170929 and batch: 1650, loss is 3.7053570985794066 and perplexity is 40.66456598317171
At time: 507.5140552520752 and batch: 1700, loss is 3.735891094207764 and perplexity is 41.925368375567615
At time: 508.5584661960602 and batch: 1750, loss is 3.7241087102890016 and perplexity is 41.43428632920876
At time: 509.5995337963104 and batch: 1800, loss is 3.6795619773864745 and perplexity is 39.629031858222916
At time: 510.6425926685333 and batch: 1850, loss is 3.706433482170105 and perplexity is 40.70836022018957
At time: 511.6872193813324 and batch: 1900, loss is 3.792505588531494 and perplexity is 44.36742764132115
At time: 512.7381119728088 and batch: 1950, loss is 3.7214759826660155 and perplexity is 41.32534460891452
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5015531318132265 and perplexity of 90.1570483976015
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 515.9946904182434 and batch: 50, loss is 3.8924994373321535 and perplexity is 49.03328912455039
At time: 517.0575003623962 and batch: 100, loss is 3.8894681978225707 and perplexity is 48.88488252288356
At time: 518.0940659046173 and batch: 150, loss is 3.862627639770508 and perplexity is 47.59023721948932
At time: 519.1326560974121 and batch: 200, loss is 3.8619091510772705 and perplexity is 47.556056452856225
At time: 520.1718616485596 and batch: 250, loss is 3.8679330778121948 and perplexity is 47.84339523771959
At time: 521.2125117778778 and batch: 300, loss is 3.8749836111068725 and perplexity is 48.18190863647673
At time: 522.252284526825 and batch: 350, loss is 3.8930350303649903 and perplexity is 49.05955804668045
At time: 523.2911508083344 and batch: 400, loss is 3.843444657325745 and perplexity is 46.68601510119124
At time: 524.3261449337006 and batch: 450, loss is 3.8990725088119507 and perplexity is 49.356650011727886
At time: 525.3663096427917 and batch: 500, loss is 3.90992066860199 and perplexity is 49.89499357680321
At time: 526.4079458713531 and batch: 550, loss is 3.8802582740783693 and perplexity is 48.43672340608327
At time: 527.4488301277161 and batch: 600, loss is 3.8526546573638916 and perplexity is 47.11797944445182
At time: 528.4907159805298 and batch: 650, loss is 3.8873666381835936 and perplexity is 48.78225590257022
At time: 529.5334742069244 and batch: 700, loss is 3.9034086227416993 and perplexity is 49.57113073975231
At time: 530.5723657608032 and batch: 750, loss is 3.858267374038696 and perplexity is 47.38318287299977
At time: 531.6114232540131 and batch: 800, loss is 3.820002484321594 and perplexity is 45.60432161650898
At time: 532.6511242389679 and batch: 850, loss is 3.8247466230392457 and perplexity is 45.821188861779774
At time: 533.6908140182495 and batch: 900, loss is 3.7969812822341917 and perplexity is 44.56644770200851
At time: 534.7300102710724 and batch: 950, loss is 3.895512661933899 and perplexity is 49.18126026082013
At time: 535.7683634757996 and batch: 1000, loss is 3.839442238807678 and perplexity is 46.499531571327516
At time: 536.8072273731232 and batch: 1050, loss is 3.8099822664260863 and perplexity is 45.14963819477325
At time: 537.8428752422333 and batch: 1100, loss is 3.8334143018722533 and perplexity is 46.220078436609136
At time: 538.8797011375427 and batch: 1150, loss is 3.797924757003784 and perplexity is 44.60851486251752
At time: 539.9192335605621 and batch: 1200, loss is 3.8450394582748415 and perplexity is 46.7605294043316
At time: 540.9581480026245 and batch: 1250, loss is 3.823689589500427 and perplexity is 45.77277991781036
At time: 541.9981608390808 and batch: 1300, loss is 3.8169033622741697 and perplexity is 45.463207036527685
At time: 543.0423576831818 and batch: 1350, loss is 3.7174421691894532 and perplexity is 41.15898164108161
At time: 544.0858449935913 and batch: 1400, loss is 3.747460193634033 and perplexity is 42.4132237128728
At time: 545.1225140094757 and batch: 1450, loss is 3.636756191253662 and perplexity is 37.96847428252199
At time: 546.1602823734283 and batch: 1500, loss is 3.6384130477905274 and perplexity is 38.0314347411524
At time: 547.1982185840607 and batch: 1550, loss is 3.6526431941986086 and perplexity is 38.57649658277798
At time: 548.2372400760651 and batch: 1600, loss is 3.749605755805969 and perplexity is 42.5043216144198
At time: 549.2763676643372 and batch: 1650, loss is 3.6803582429885866 and perplexity is 39.6605996596459
At time: 550.3158819675446 and batch: 1700, loss is 3.707296509742737 and perplexity is 40.74350782198942
At time: 551.3543245792389 and batch: 1750, loss is 3.6962586307525633 and perplexity is 40.29625879420311
At time: 552.3932857513428 and batch: 1800, loss is 3.6521574783325197 and perplexity is 38.5577639160746
At time: 553.4339253902435 and batch: 1850, loss is 3.6775172901153566 and perplexity is 39.5480856642432
At time: 554.4779741764069 and batch: 1900, loss is 3.76445415019989 and perplexity is 43.1401513888309
At time: 555.5158650875092 and batch: 1950, loss is 3.6951248931884764 and perplexity is 40.25059929974871
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493677609465843 and perplexity of 89.4498031664858
finished 13 epochs...
Completing Train Step...
At time: 558.7611398696899 and batch: 50, loss is 3.887563691139221 and perplexity is 48.79186953744447
At time: 559.8261909484863 and batch: 100, loss is 3.8779469299316407 and perplexity is 48.324898751365986
At time: 560.8666729927063 and batch: 150, loss is 3.847743954658508 and perplexity is 46.88716425156004
At time: 561.9076492786407 and batch: 200, loss is 3.8462406826019286 and perplexity is 46.816733039628346
At time: 562.9477396011353 and batch: 250, loss is 3.850456504821777 and perplexity is 47.0145206888783
At time: 563.9877886772156 and batch: 300, loss is 3.856573076248169 and perplexity is 47.30296962270493
At time: 565.0272028446198 and batch: 350, loss is 3.875458879470825 and perplexity is 48.20481341589388
At time: 566.066065788269 and batch: 400, loss is 3.8251198863983156 and perplexity is 45.83829542507892
At time: 567.1045897006989 and batch: 450, loss is 3.880715808868408 and perplexity is 48.45888996275578
At time: 568.1441690921783 and batch: 500, loss is 3.891807141304016 and perplexity is 48.99935532071705
At time: 569.2096872329712 and batch: 550, loss is 3.8622076606750486 and perplexity is 47.57025451116279
At time: 570.2502245903015 and batch: 600, loss is 3.8361473846435548 and perplexity is 46.34657452006452
At time: 571.2902743816376 and batch: 650, loss is 3.871408014297485 and perplexity is 48.009937191181166
At time: 572.328070640564 and batch: 700, loss is 3.888785080909729 and perplexity is 48.851499836286976
At time: 573.3662357330322 and batch: 750, loss is 3.844521894454956 and perplexity is 46.73633410795835
At time: 574.4038870334625 and batch: 800, loss is 3.8069157552719117 and perplexity is 45.011398390920306
At time: 575.4441027641296 and batch: 850, loss is 3.8120469760894777 and perplexity is 45.2429553923613
At time: 576.4829630851746 and batch: 900, loss is 3.786803092956543 and perplexity is 44.115142592371825
At time: 577.524169921875 and batch: 950, loss is 3.885412850379944 and perplexity is 48.687038773275475
At time: 578.5618417263031 and batch: 1000, loss is 3.829792160987854 and perplexity is 46.052965636585014
At time: 579.6010088920593 and batch: 1050, loss is 3.800710344314575 and perplexity is 44.732949006095275
At time: 580.6403405666351 and batch: 1100, loss is 3.8253429412841795 and perplexity is 45.84852102122535
At time: 581.6805741786957 and batch: 1150, loss is 3.7908718681335447 and perplexity is 44.29500284681976
At time: 582.7207112312317 and batch: 1200, loss is 3.8381692695617677 and perplexity is 46.44037675680592
At time: 583.7608528137207 and batch: 1250, loss is 3.8176441764831544 and perplexity is 45.49689930460094
At time: 584.8010709285736 and batch: 1300, loss is 3.811972246170044 and perplexity is 45.23957451627775
At time: 585.8398633003235 and batch: 1350, loss is 3.71332848072052 and perplexity is 40.99001419091564
At time: 586.8771908283234 and batch: 1400, loss is 3.7454867649078367 and perplexity is 42.32960677200041
At time: 587.9150233268738 and batch: 1450, loss is 3.636217670440674 and perplexity is 37.94803297341266
At time: 588.9554336071014 and batch: 1500, loss is 3.6400998878479003 and perplexity is 38.095641827030626
At time: 589.9934692382812 and batch: 1550, loss is 3.6551175260543824 and perplexity is 38.672065823406385
At time: 591.0338127613068 and batch: 1600, loss is 3.7534718465805055 and perplexity is 42.66896523861692
At time: 592.0738897323608 and batch: 1650, loss is 3.684394669532776 and perplexity is 39.82101028192345
At time: 593.1143915653229 and batch: 1700, loss is 3.712397584915161 and perplexity is 40.951874513430816
At time: 594.1520712375641 and batch: 1750, loss is 3.7022817087173463 and perplexity is 40.539698695413875
At time: 595.1908609867096 and batch: 1800, loss is 3.658295221328735 and perplexity is 38.79514932157597
At time: 596.2326271533966 and batch: 1850, loss is 3.6840467500686644 and perplexity is 39.807158187212195
At time: 597.2736551761627 and batch: 1900, loss is 3.770810327529907 and perplexity is 43.41523114282633
At time: 598.3139736652374 and batch: 1950, loss is 3.7009569644927978 and perplexity is 40.48602952051581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493043411609738 and perplexity of 89.39309227795138
finished 14 epochs...
Completing Train Step...
At time: 601.608106136322 and batch: 50, loss is 3.883725414276123 and perplexity is 48.60495178401413
At time: 602.6514949798584 and batch: 100, loss is 3.872443885803223 and perplexity is 48.059695084052166
At time: 603.7008211612701 and batch: 150, loss is 3.841227898597717 and perplexity is 46.58263809301446
At time: 604.7510857582092 and batch: 200, loss is 3.8391243696212767 and perplexity is 46.484753151985394
At time: 605.7969760894775 and batch: 250, loss is 3.842607593536377 and perplexity is 46.64695227979767
At time: 606.842159986496 and batch: 300, loss is 3.848388423919678 and perplexity is 46.91739132682781
At time: 607.886696100235 and batch: 350, loss is 3.867379674911499 and perplexity is 47.816925888798664
At time: 608.9305667877197 and batch: 400, loss is 3.8166422986984254 and perplexity is 45.45133979825315
At time: 609.9760777950287 and batch: 450, loss is 3.872272596359253 and perplexity is 48.05146367060109
At time: 611.021689414978 and batch: 500, loss is 3.8835644149780273 and perplexity is 48.597127050798115
At time: 612.0679438114166 and batch: 550, loss is 3.8537581253051756 and perplexity is 47.1700013211848
At time: 613.1128561496735 and batch: 600, loss is 3.828383560180664 and perplexity is 45.9881410587107
At time: 614.1561682224274 and batch: 650, loss is 3.8638608026504517 and perplexity is 47.64895993337001
At time: 615.1997623443604 and batch: 700, loss is 3.8816714906692504 and perplexity is 48.50522337845681
At time: 616.2461607456207 and batch: 750, loss is 3.837706456184387 and perplexity is 46.41888850210169
At time: 617.2921161651611 and batch: 800, loss is 3.8004873991012573 and perplexity is 44.72297712087013
At time: 618.3374817371368 and batch: 850, loss is 3.8057861614227293 and perplexity is 44.96058249821809
At time: 619.3813323974609 and batch: 900, loss is 3.781348690986633 and perplexity is 43.875175904029085
At time: 620.427356004715 and batch: 950, loss is 3.8802722263336182 and perplexity is 48.43739921232615
At time: 621.4981572628021 and batch: 1000, loss is 3.824741716384888 and perplexity is 45.82096403359534
At time: 622.5443961620331 and batch: 1050, loss is 3.7959600400924685 and perplexity is 44.5209577995646
At time: 623.5899803638458 and batch: 1100, loss is 3.820939474105835 and perplexity is 45.64707242538873
At time: 624.6370124816895 and batch: 1150, loss is 3.7870283794403075 and perplexity is 44.12508225732128
At time: 625.6865246295929 and batch: 1200, loss is 3.8345135259628296 and perplexity is 46.27091259424178
At time: 626.7338335514069 and batch: 1250, loss is 3.814571876525879 and perplexity is 45.35733368631308
At time: 627.7792830467224 and batch: 1300, loss is 3.8093991804122926 and perplexity is 45.12331974591942
At time: 628.8244545459747 and batch: 1350, loss is 3.7111804151535033 and perplexity is 40.90205945293262
At time: 629.8680555820465 and batch: 1400, loss is 3.7441533517837526 and perplexity is 42.27320153289368
At time: 630.9144306182861 and batch: 1450, loss is 3.635438685417175 and perplexity is 37.918483534834444
At time: 631.9593653678894 and batch: 1500, loss is 3.6401627922058104 and perplexity is 38.098038284291945
At time: 633.00381731987 and batch: 1550, loss is 3.655691661834717 and perplexity is 38.69427521508818
At time: 634.0494983196259 and batch: 1600, loss is 3.754496998786926 and perplexity is 42.7127298513388
At time: 635.0955188274384 and batch: 1650, loss is 3.685625419616699 and perplexity is 39.87005016539993
At time: 636.1390326023102 and batch: 1700, loss is 3.7140193510055544 and perplexity is 41.0183427582592
At time: 637.1835753917694 and batch: 1750, loss is 3.704304280281067 and perplexity is 40.621776112942214
At time: 638.2338480949402 and batch: 1800, loss is 3.6605176401138304 and perplexity is 38.88146426865189
At time: 639.2865285873413 and batch: 1850, loss is 3.686518449783325 and perplexity is 39.90567122591601
At time: 640.3337459564209 and batch: 1900, loss is 3.773189878463745 and perplexity is 43.51866290840741
At time: 641.3783233165741 and batch: 1950, loss is 3.7030872011184695 and perplexity is 40.57236626963197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493098769077035 and perplexity of 89.3980409901065
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 644.62846159935 and batch: 50, loss is 3.881525673866272 and perplexity is 48.49815101750307
At time: 645.696042060852 and batch: 100, loss is 3.8727823734283446 and perplexity is 48.075965449608596
At time: 646.734756231308 and batch: 150, loss is 3.8433177614212037 and perplexity is 46.68009121294208
At time: 647.8022937774658 and batch: 200, loss is 3.841046528816223 and perplexity is 46.57419017624369
At time: 648.8411684036255 and batch: 250, loss is 3.845154981613159 and perplexity is 46.765931648826545
At time: 649.8884291648865 and batch: 300, loss is 3.850648202896118 and perplexity is 47.02353414586399
At time: 650.9296519756317 and batch: 350, loss is 3.8699658203125 and perplexity is 47.94074745304905
At time: 651.9721722602844 and batch: 400, loss is 3.8206922721862795 and perplexity is 45.63578977606682
At time: 653.0135569572449 and batch: 450, loss is 3.8763752603530883 and perplexity is 48.249007631615775
At time: 654.0556449890137 and batch: 500, loss is 3.888651661872864 and perplexity is 48.84498255100403
At time: 655.0955526828766 and batch: 550, loss is 3.8582694721221924 and perplexity is 47.383282286978044
At time: 656.1356163024902 and batch: 600, loss is 3.831638011932373 and perplexity is 46.13805105004027
At time: 657.1740789413452 and batch: 650, loss is 3.8668619203567505 and perplexity is 47.79217486565607
At time: 658.2131679058075 and batch: 700, loss is 3.883668508529663 and perplexity is 48.60218596164756
At time: 659.2532818317413 and batch: 750, loss is 3.8398101425170896 and perplexity is 46.51664206879325
At time: 660.294784784317 and batch: 800, loss is 3.801711072921753 and perplexity is 44.77773695440191
At time: 661.334990978241 and batch: 850, loss is 3.8068566513061524 and perplexity is 45.00873811738816
At time: 662.3770334720612 and batch: 900, loss is 3.7787404823303223 and perplexity is 43.76088939675638
At time: 663.4255182743073 and batch: 950, loss is 3.878240203857422 and perplexity is 48.339073262541454
At time: 664.4671242237091 and batch: 1000, loss is 3.821653742790222 and perplexity is 45.67968834663505
At time: 665.5060238838196 and batch: 1050, loss is 3.79291748046875 and perplexity is 44.38570599113745
At time: 666.5443563461304 and batch: 1100, loss is 3.815968780517578 and perplexity is 45.42073780121267
At time: 667.5837666988373 and batch: 1150, loss is 3.783605923652649 and perplexity is 43.97432424264366
At time: 668.6238887310028 and batch: 1200, loss is 3.8311536502838135 and perplexity is 46.11570895883521
At time: 669.6649858951569 and batch: 1250, loss is 3.8107819843292234 and perplexity is 45.185759610304004
At time: 670.7036409378052 and batch: 1300, loss is 3.804509596824646 and perplexity is 44.903224028976645
At time: 671.7429525852203 and batch: 1350, loss is 3.7053923416137695 and perplexity is 40.665999151122456
At time: 672.7840564250946 and batch: 1400, loss is 3.7362472438812255 and perplexity is 41.94030274110118
At time: 673.8244071006775 and batch: 1450, loss is 3.6268740558624266 and perplexity is 37.59511252322284
At time: 674.8643088340759 and batch: 1500, loss is 3.6286884689331056 and perplexity is 37.66338750755997
At time: 675.9057929515839 and batch: 1550, loss is 3.64524694442749 and perplexity is 38.29222773635005
At time: 676.9460418224335 and batch: 1600, loss is 3.742032427787781 and perplexity is 42.183638297357376
At time: 677.9838383197784 and batch: 1650, loss is 3.673699960708618 and perplexity is 39.39740537498258
At time: 679.0247623920441 and batch: 1700, loss is 3.70049880027771 and perplexity is 40.4674845192309
At time: 680.0666491985321 and batch: 1750, loss is 3.690983633995056 and perplexity is 40.08425580884632
At time: 681.1076989173889 and batch: 1800, loss is 3.648463683128357 and perplexity is 38.41560215249777
At time: 682.1480958461761 and batch: 1850, loss is 3.6751821517944334 and perplexity is 39.45584315531373
At time: 683.1922805309296 and batch: 1900, loss is 3.761893219947815 and perplexity is 43.0298138137799
At time: 684.2335855960846 and batch: 1950, loss is 3.6942520332336426 and perplexity is 40.21548149215552
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492552575399709 and perplexity of 89.34922567787343
finished 16 epochs...
Completing Train Step...
At time: 687.482884645462 and batch: 50, loss is 3.8801575899124146 and perplexity is 48.43184684048613
At time: 688.5485124588013 and batch: 100, loss is 3.869789228439331 and perplexity is 47.93228225411986
At time: 689.5881638526917 and batch: 150, loss is 3.8391596698760986 and perplexity is 46.486394104579844
At time: 690.6293671131134 and batch: 200, loss is 3.8370563793182373 and perplexity is 46.38872246271861
At time: 691.6660695075989 and batch: 250, loss is 3.8407628107070924 and perplexity is 46.560978109412524
At time: 692.7036120891571 and batch: 300, loss is 3.8463086128234862 and perplexity is 46.819913418697034
At time: 693.7438192367554 and batch: 350, loss is 3.865850558280945 and perplexity is 47.743864106429456
At time: 694.7825953960419 and batch: 400, loss is 3.8164158868789673 and perplexity is 45.44105024259508
At time: 695.8225109577179 and batch: 450, loss is 3.8721929454803465 and perplexity is 48.047636481708494
At time: 696.8627536296844 and batch: 500, loss is 3.8841431522369385 and perplexity is 48.625260158952166
At time: 697.90300822258 and batch: 550, loss is 3.853883357048035 and perplexity is 47.17590887255968
At time: 698.9416427612305 and batch: 600, loss is 3.8275571393966676 and perplexity is 45.95015120308772
At time: 700.0064916610718 and batch: 650, loss is 3.862865686416626 and perplexity is 47.60156726433347
At time: 701.0531413555145 and batch: 700, loss is 3.8802785205841066 and perplexity is 48.437704090409284
At time: 702.094945192337 and batch: 750, loss is 3.8364935398101805 and perplexity is 46.36262040331252
At time: 703.1347970962524 and batch: 800, loss is 3.7985378313064575 and perplexity is 44.63587158165404
At time: 704.1766512393951 and batch: 850, loss is 3.803477559089661 and perplexity is 44.85690611238621
At time: 705.2172651290894 and batch: 900, loss is 3.7762351417541504 and perplexity is 43.65139068795491
At time: 706.2539339065552 and batch: 950, loss is 3.8757696676254274 and perplexity is 48.21979722917359
At time: 707.2935061454773 and batch: 1000, loss is 3.8195144605636595 and perplexity is 45.582071053938826
At time: 708.3345727920532 and batch: 1050, loss is 3.7909111833572386 and perplexity is 44.296744348998764
At time: 709.3740253448486 and batch: 1100, loss is 3.8144888734817504 and perplexity is 45.35356904578404
At time: 710.4142525196075 and batch: 1150, loss is 3.782020301818848 and perplexity is 43.90465284483994
At time: 711.4540765285492 and batch: 1200, loss is 3.829782738685608 and perplexity is 46.05253171366774
At time: 712.4946238994598 and batch: 1250, loss is 3.809540982246399 and perplexity is 45.12971876910625
At time: 713.5315191745758 and batch: 1300, loss is 3.803732089996338 and perplexity is 44.868325034542394
At time: 714.5724604129791 and batch: 1350, loss is 3.704767951965332 and perplexity is 40.6406156476322
At time: 715.6143085956573 and batch: 1400, loss is 3.73632125377655 and perplexity is 41.943406853383024
At time: 716.6537539958954 and batch: 1450, loss is 3.627229247093201 and perplexity is 37.6084683493068
At time: 717.6994817256927 and batch: 1500, loss is 3.629819703102112 and perplexity is 37.70601772626294
At time: 718.7388367652893 and batch: 1550, loss is 3.646481547355652 and perplexity is 38.339532628209504
At time: 719.7750205993652 and batch: 1600, loss is 3.7438222312927247 and perplexity is 42.259206326822415
At time: 720.8111305236816 and batch: 1650, loss is 3.67560124874115 and perplexity is 39.472382444250904
At time: 721.8495268821716 and batch: 1700, loss is 3.7026092767715455 and perplexity is 40.55298038084252
At time: 722.8866958618164 and batch: 1750, loss is 3.6933792781829835 and perplexity is 40.18039853920763
At time: 723.9253125190735 and batch: 1800, loss is 3.6510116958618166 and perplexity is 38.513610406059406
At time: 724.9665608406067 and batch: 1850, loss is 3.6777565336227416 and perplexity is 39.55754841887405
At time: 726.0049624443054 and batch: 1900, loss is 3.764261393547058 and perplexity is 43.131836639033935
At time: 727.0407962799072 and batch: 1950, loss is 3.6962866973876953 and perplexity is 40.29738979046743
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492358114553053 and perplexity of 89.33185244106193
finished 17 epochs...
Completing Train Step...
At time: 730.2965083122253 and batch: 50, loss is 3.879057183265686 and perplexity is 48.37858142649223
At time: 731.3356554508209 and batch: 100, loss is 3.8678709650039673 and perplexity is 47.84042364237426
At time: 732.3732266426086 and batch: 150, loss is 3.8367364501953123 and perplexity is 46.37388373322493
At time: 733.4127566814423 and batch: 200, loss is 3.834542741775513 and perplexity is 46.2722644563046
At time: 734.4488291740417 and batch: 250, loss is 3.8379368591308594 and perplexity is 46.42958478296454
At time: 735.4889016151428 and batch: 300, loss is 3.843415770530701 and perplexity is 46.684666511319904
At time: 736.5291082859039 and batch: 350, loss is 3.8630467557907107 and perplexity is 47.610187230705876
At time: 737.5698752403259 and batch: 400, loss is 3.813414626121521 and perplexity is 45.30487425376837
At time: 738.6106057167053 and batch: 450, loss is 3.8691916942596434 and perplexity is 47.903649632499565
At time: 739.6511392593384 and batch: 500, loss is 3.881154942512512 and perplexity is 48.48017456474472
At time: 740.6895453929901 and batch: 550, loss is 3.8509162616729737 and perplexity is 47.03614090651149
At time: 741.7285892963409 and batch: 600, loss is 3.8248139953613283 and perplexity is 45.82427604566818
At time: 742.7721033096313 and batch: 650, loss is 3.860224137306213 and perplexity is 47.47599131720794
At time: 743.8165597915649 and batch: 700, loss is 3.877831768989563 and perplexity is 48.31933393093111
At time: 744.8571994304657 and batch: 750, loss is 3.834193959236145 and perplexity is 46.256128312571406
At time: 745.8988337516785 and batch: 800, loss is 3.7963781547546387 and perplexity is 44.53957655691094
At time: 746.9403250217438 and batch: 850, loss is 3.801319303512573 and perplexity is 44.76019784271891
At time: 747.9770972728729 and batch: 900, loss is 3.774564390182495 and perplexity is 43.57852094892435
At time: 749.0160610675812 and batch: 950, loss is 3.874149422645569 and perplexity is 48.14173260376982
At time: 750.0562942028046 and batch: 1000, loss is 3.8180407238006593 and perplexity is 45.51494455563645
At time: 751.0971984863281 and batch: 1050, loss is 3.7895279693603516 and perplexity is 44.23551482872587
At time: 752.1703214645386 and batch: 1100, loss is 3.8133811569213867 and perplexity is 45.30335796123959
At time: 753.2103214263916 and batch: 1150, loss is 3.781020402908325 and perplexity is 43.860774570868465
At time: 754.2505497932434 and batch: 1200, loss is 3.8287991952896117 and perplexity is 46.007259317564504
At time: 755.2879061698914 and batch: 1250, loss is 3.808694214820862 and perplexity is 45.09152056810747
At time: 756.327877998352 and batch: 1300, loss is 3.8031917905807493 and perplexity is 44.844089252626766
At time: 757.3682670593262 and batch: 1350, loss is 3.7043324661254884 and perplexity is 40.62292108813983
At time: 758.4088113307953 and batch: 1400, loss is 3.736364469528198 and perplexity is 41.94521950840421
At time: 759.4498834609985 and batch: 1450, loss is 3.627519416809082 and perplexity is 37.61938277132322
At time: 760.4917771816254 and batch: 1500, loss is 3.630579500198364 and perplexity is 37.73467753548374
At time: 761.5385401248932 and batch: 1550, loss is 3.6473635244369507 and perplexity is 38.37336213352652
At time: 762.5778939723969 and batch: 1600, loss is 3.7449810886383057 and perplexity is 42.30820710546501
At time: 763.6199893951416 and batch: 1650, loss is 3.6767809629440307 and perplexity is 39.51897605260891
At time: 764.6620001792908 and batch: 1700, loss is 3.703927602767944 and perplexity is 40.606477684805185
At time: 765.7034914493561 and batch: 1750, loss is 3.6949048614501954 and perplexity is 40.24174386469205
At time: 766.7450337409973 and batch: 1800, loss is 3.6525471782684327 and perplexity is 38.57279280238946
At time: 767.7865493297577 and batch: 1850, loss is 3.679341206550598 and perplexity is 39.620283889418324
At time: 768.8331973552704 and batch: 1900, loss is 3.7656606340408327 and perplexity is 43.19223069448047
At time: 769.874365568161 and batch: 1950, loss is 3.6975098609924317 and perplexity is 40.34671024837039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492280897983285 and perplexity of 89.32495480815466
finished 18 epochs...
Completing Train Step...
At time: 773.1601786613464 and batch: 50, loss is 3.877956371307373 and perplexity is 48.32535500704616
At time: 774.2300848960876 and batch: 100, loss is 3.866235499382019 and perplexity is 47.762246219836605
At time: 775.2750942707062 and batch: 150, loss is 3.834821286201477 and perplexity is 46.285155132875346
At time: 776.3175292015076 and batch: 200, loss is 3.8325248336791993 and perplexity is 46.178985425131884
At time: 777.3626828193665 and batch: 250, loss is 3.835692410469055 and perplexity is 46.32549282175917
At time: 778.4334967136383 and batch: 300, loss is 3.8411360073089598 and perplexity is 46.57835775103246
At time: 779.4776668548584 and batch: 350, loss is 3.8608095121383665 and perplexity is 47.50379070339326
At time: 780.5235223770142 and batch: 400, loss is 3.811031141281128 and perplexity is 45.19701935910209
At time: 781.5684204101562 and batch: 450, loss is 3.8668003702163696 and perplexity is 47.78923334111054
At time: 782.6128935813904 and batch: 500, loss is 3.8788363933563232 and perplexity is 48.367901102981186
At time: 783.6618928909302 and batch: 550, loss is 3.84857177734375 and perplexity is 46.925994579869965
At time: 784.7070229053497 and batch: 600, loss is 3.822656331062317 and perplexity is 45.72550923234745
At time: 785.7522599697113 and batch: 650, loss is 3.8581535959243776 and perplexity is 47.37779201048897
At time: 786.7944238185883 and batch: 700, loss is 3.875876717567444 and perplexity is 48.22495943197284
At time: 787.841394662857 and batch: 750, loss is 3.8323600816726686 and perplexity is 46.17137797131239
At time: 788.8874905109406 and batch: 800, loss is 3.7946518516540526 and perplexity is 44.46275407632353
At time: 789.9325263500214 and batch: 850, loss is 3.79962251663208 and perplexity is 44.684313724046014
At time: 790.975531578064 and batch: 900, loss is 3.773194212913513 and perplexity is 43.51885153827456
At time: 792.0205924510956 and batch: 950, loss is 3.8728568983078 and perplexity is 48.07954843864769
At time: 793.0638599395752 and batch: 1000, loss is 3.8168403339385986 and perplexity is 45.46034165655946
At time: 794.1096966266632 and batch: 1050, loss is 3.7883966398239135 and perplexity is 44.185498182230056
At time: 795.1557202339172 and batch: 1100, loss is 3.81243070602417 and perplexity is 45.260319800087736
At time: 796.2014045715332 and batch: 1150, loss is 3.7802035999298096 and perplexity is 43.82496358680919
At time: 797.2452983856201 and batch: 1200, loss is 3.8279725027084353 and perplexity is 45.96924117443005
At time: 798.2888576984406 and batch: 1250, loss is 3.8079937934875487 and perplexity is 45.05994856329363
At time: 799.3329615592957 and batch: 1300, loss is 3.8027048206329344 and perplexity is 44.822256845118225
At time: 800.3777830600739 and batch: 1350, loss is 3.7039425802230834 and perplexity is 40.6070858710576
At time: 801.421056509018 and batch: 1400, loss is 3.7362941884994507 and perplexity is 41.94227165881629
At time: 802.4668846130371 and batch: 1450, loss is 3.6276527547836306 and perplexity is 37.62439919805838
At time: 803.5123689174652 and batch: 1500, loss is 3.6310356760025027 and perplexity is 37.751895109174086
At time: 804.5547361373901 and batch: 1550, loss is 3.6479443550109862 and perplexity is 38.39565702963407
At time: 805.5978219509125 and batch: 1600, loss is 3.7457330560684206 and perplexity is 42.34003346392766
At time: 806.641252040863 and batch: 1650, loss is 3.677542643547058 and perplexity is 39.54908835664282
At time: 807.6847767829895 and batch: 1700, loss is 3.7047880697250366 and perplexity is 40.64143325399623
At time: 808.7281351089478 and batch: 1750, loss is 3.6959212827682495 and perplexity is 40.2826672251966
At time: 809.7715349197388 and batch: 1800, loss is 3.6535583257675173 and perplexity is 38.611815310795414
At time: 810.8158314228058 and batch: 1850, loss is 3.680396089553833 and perplexity is 39.66210070552315
At time: 811.8571834564209 and batch: 1900, loss is 3.7665836715698244 and perplexity is 43.232117149888026
At time: 812.9006567001343 and batch: 1950, loss is 3.6983193016052245 and perplexity is 40.379381735268346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492270110374273 and perplexity of 89.32399121066462
finished 19 epochs...
Completing Train Step...
At time: 816.1509835720062 and batch: 50, loss is 3.876848349571228 and perplexity is 48.27183911715121
At time: 817.2119855880737 and batch: 100, loss is 3.8647513675689695 and perplexity is 47.691413326435956
At time: 818.2495450973511 and batch: 150, loss is 3.8331511878967284 and perplexity is 46.207918887766375
At time: 819.2885332107544 and batch: 200, loss is 3.8307689952850343 and perplexity is 46.09797373205244
At time: 820.3277492523193 and batch: 250, loss is 3.8337675189971923 and perplexity is 46.23640704343098
At time: 821.3668420314789 and batch: 300, loss is 3.8391923761367797 and perplexity is 46.48791452556706
At time: 822.4050562381744 and batch: 350, loss is 3.8588918685913085 and perplexity is 47.412782654078434
At time: 823.4436941146851 and batch: 400, loss is 3.80901168346405 and perplexity is 45.10583798450665
At time: 824.4808838367462 and batch: 450, loss is 3.8647774505615233 and perplexity is 47.69265727743755
At time: 825.5187139511108 and batch: 500, loss is 3.876892924308777 and perplexity is 48.273990869667415
At time: 826.5565457344055 and batch: 550, loss is 3.8465971660614016 and perplexity is 46.83342540568296
At time: 827.5952687263489 and batch: 600, loss is 3.8208411169052123 and perplexity is 45.642582927919165
At time: 828.6338098049164 and batch: 650, loss is 3.856406192779541 and perplexity is 47.29507619771727
At time: 829.6728417873383 and batch: 700, loss is 3.8742175006866457 and perplexity is 48.145010110181374
At time: 830.7392644882202 and batch: 750, loss is 3.830796060562134 and perplexity is 46.09922140336943
At time: 831.7809360027313 and batch: 800, loss is 3.7931726217269897 and perplexity is 44.397032060824266
At time: 832.8172032833099 and batch: 850, loss is 3.798176283836365 and perplexity is 44.61973651218085
At time: 833.8556027412415 and batch: 900, loss is 3.771980447769165 and perplexity is 43.46606191673756
At time: 834.8948678970337 and batch: 950, loss is 3.871728367805481 and perplexity is 48.02531980678489
At time: 835.9342124462128 and batch: 1000, loss is 3.815781102180481 and perplexity is 45.412214112553286
At time: 836.9737284183502 and batch: 1050, loss is 3.787398924827576 and perplexity is 44.141435632661356
At time: 838.0145480632782 and batch: 1100, loss is 3.8115617513656614 and perplexity is 45.22100771703438
At time: 839.0537977218628 and batch: 1150, loss is 3.7794606113433837 and perplexity is 43.79241423246041
At time: 840.0915131568909 and batch: 1200, loss is 3.8272230100631712 and perplexity is 45.93480047439936
At time: 841.1300098896027 and batch: 1250, loss is 3.8073606061935426 and perplexity is 45.03142620734442
At time: 842.1680793762207 and batch: 1300, loss is 3.802234492301941 and perplexity is 44.801180624625225
At time: 843.207261800766 and batch: 1350, loss is 3.7035592126846315 and perplexity is 40.591521416147515
At time: 844.2467494010925 and batch: 1400, loss is 3.7361417531967165 and perplexity is 41.935878663210104
At time: 845.2861182689667 and batch: 1450, loss is 3.6276608896255493 and perplexity is 37.624705267843055
At time: 846.323712348938 and batch: 1500, loss is 3.6312844228744505 and perplexity is 37.76128694303882
At time: 847.3625752925873 and batch: 1550, loss is 3.648308777809143 and perplexity is 38.40965183226356
At time: 848.4020659923553 and batch: 1600, loss is 3.746214609146118 and perplexity is 42.36042734732659
At time: 849.4421174526215 and batch: 1650, loss is 3.6780389165878296 and perplexity is 39.56872037399886
At time: 850.4818820953369 and batch: 1700, loss is 3.705363368988037 and perplexity is 40.66482096741664
At time: 851.52077293396 and batch: 1750, loss is 3.6966174030303955 and perplexity is 40.3107185684868
At time: 852.5601768493652 and batch: 1800, loss is 3.6542566776275636 and perplexity is 38.638789361430426
At time: 853.5980169773102 and batch: 1850, loss is 3.681134672164917 and perplexity is 39.691405264009845
At time: 854.6357743740082 and batch: 1900, loss is 3.76723014831543 and perplexity is 43.26007474428234
At time: 855.6742269992828 and batch: 1950, loss is 3.6988834047317507 and perplexity is 40.40216629656935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.492291969476744 and perplexity of 89.32594377428218
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea7e1b2b38>
ELAPSED
2658.968440055847


RESULTS SO FAR:
[{'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.92103091601648}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.6813262795645527, 'dropout': 0.19794812537896078, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.05052225478255}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.8407924036871192, 'dropout': 0.37893501344260494, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.32399121066462}]
SETTINGS FOR THIS RUN
{'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.320185930278277, 'dropout': 0.14646798116639437, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5050499439239502 and batch: 50, loss is 7.142215156555176 and perplexity is 1264.225747612957
At time: 2.5366082191467285 and batch: 100, loss is 6.348721857070923 and perplexity is 571.7614489326999
At time: 3.595197916030884 and batch: 150, loss is 6.024619636535644 and perplexity is 413.4843377733581
At time: 4.629115104675293 and batch: 200, loss is 5.894395809173584 and perplexity is 362.99744990082763
At time: 5.663574934005737 and batch: 250, loss is 5.7963384246826175 and perplexity is 329.0923546789423
At time: 6.697406530380249 and batch: 300, loss is 5.757495384216309 and perplexity is 316.5544878327577
At time: 7.730847120285034 and batch: 350, loss is 5.682852697372437 and perplexity is 293.78631911981233
At time: 8.766095638275146 and batch: 400, loss is 5.616222038269043 and perplexity is 274.8490501096997
At time: 9.799654483795166 and batch: 450, loss is 5.546409978866577 and perplexity is 256.31572333303905
At time: 10.836338996887207 and batch: 500, loss is 5.515792675018311 and perplexity is 248.5869478337555
At time: 11.874583005905151 and batch: 550, loss is 5.457389192581177 and perplexity is 234.48443081780664
At time: 12.91390585899353 and batch: 600, loss is 5.482460823059082 and perplexity is 240.43765449234007
At time: 13.950643539428711 and batch: 650, loss is 5.547771978378296 and perplexity is 256.66506306933627
At time: 14.988774299621582 and batch: 700, loss is 5.466661005020142 and perplexity is 236.66863660604926
At time: 16.026447534561157 and batch: 750, loss is 5.412259283065796 and perplexity is 224.1374059177021
At time: 17.065624237060547 and batch: 800, loss is 5.397134580612183 and perplexity is 220.7729020419523
At time: 18.105223655700684 and batch: 850, loss is 5.406321506500245 and perplexity is 222.81047150008754
At time: 19.146553993225098 and batch: 900, loss is 5.418450775146485 and perplexity is 225.52945587761158
At time: 20.18711256980896 and batch: 950, loss is 5.450660324096679 and perplexity is 232.9119124890095
At time: 21.22617745399475 and batch: 1000, loss is 5.420088863372802 and perplexity is 225.8991957745806
At time: 22.267086029052734 and batch: 1050, loss is 5.314157257080078 and perplexity is 203.19320132129047
At time: 23.307306051254272 and batch: 1100, loss is 5.409409074783325 and perplexity is 223.4994771736999
At time: 24.34917974472046 and batch: 1150, loss is 5.310570602416992 and perplexity is 202.46572286512497
At time: 25.390817403793335 and batch: 1200, loss is 5.380633096694947 and perplexity is 217.15971501193235
At time: 26.43044114112854 and batch: 1250, loss is 5.319263277053833 and perplexity is 204.23336314942793
At time: 27.470998525619507 and batch: 1300, loss is 5.34056960105896 and perplexity is 208.63151318159825
At time: 28.51275134086609 and batch: 1350, loss is 5.2940072917938235 and perplexity is 199.13984005756413
At time: 29.557684183120728 and batch: 1400, loss is 5.304040241241455 and perplexity is 201.1478563248268
At time: 30.599787712097168 and batch: 1450, loss is 5.250291624069214 and perplexity is 190.6218502733964
At time: 31.641515016555786 and batch: 1500, loss is 5.233000192642212 and perplexity is 187.35405943183983
At time: 32.6884286403656 and batch: 1550, loss is 5.211155090332031 and perplexity is 183.30567056236234
At time: 33.73255276679993 and batch: 1600, loss is 5.259827032089233 and perplexity is 192.44820105498948
At time: 34.77192568778992 and batch: 1650, loss is 5.237841691970825 and perplexity is 188.2633333331603
At time: 35.817442655563354 and batch: 1700, loss is 5.25423529624939 and perplexity is 191.3750846397351
At time: 36.86222767829895 and batch: 1750, loss is 5.267006998062134 and perplexity is 193.8349450199142
At time: 37.90300273895264 and batch: 1800, loss is 5.23224949836731 and perplexity is 187.2134665897679
At time: 38.94605350494385 and batch: 1850, loss is 5.221759424209595 and perplexity is 185.259848157949
At time: 39.988959312438965 and batch: 1900, loss is 5.258977012634277 and perplexity is 192.28468584542162
At time: 41.0364875793457 and batch: 1950, loss is 5.188284215927124 and perplexity is 179.16088766618944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.886719885537791 and perplexity of 132.51818556264138
finished 1 epochs...
Completing Train Step...
At time: 44.34808921813965 and batch: 50, loss is 5.076339187622071 and perplexity is 160.18656827176048
At time: 45.38518023490906 and batch: 100, loss is 5.0259358596801755 and perplexity is 152.31273277857207
At time: 46.42306327819824 and batch: 150, loss is 4.955590038299561 and perplexity is 141.9663472474921
At time: 47.46330142021179 and batch: 200, loss is 4.93301157951355 and perplexity is 138.79688139902473
At time: 48.50167369842529 and batch: 250, loss is 4.929961700439453 and perplexity is 138.3742125669394
At time: 49.53835916519165 and batch: 300, loss is 4.961320848464966 and perplexity is 142.7822651356646
At time: 50.57641410827637 and batch: 350, loss is 4.9464507579803465 and perplexity is 140.67478795524653
At time: 51.61467909812927 and batch: 400, loss is 4.914160099029541 and perplexity is 136.20486315060398
At time: 52.65300941467285 and batch: 450, loss is 4.894589490890503 and perplexity is 133.56516564175007
At time: 53.692304849624634 and batch: 500, loss is 4.893016242980957 and perplexity is 133.35519973163798
At time: 54.730759620666504 and batch: 550, loss is 4.839868412017823 and perplexity is 126.45271097819882
At time: 55.767781019210815 and batch: 600, loss is 4.839491949081421 and perplexity is 126.40511517889736
At time: 56.80556893348694 and batch: 650, loss is 4.909690418243408 and perplexity is 135.5974294195182
At time: 57.87088060379028 and batch: 700, loss is 4.904221134185791 and perplexity is 134.8578329358013
At time: 58.912681102752686 and batch: 750, loss is 4.861526823043823 and perplexity is 129.22134969881043
At time: 59.957581758499146 and batch: 800, loss is 4.836813297271728 and perplexity is 126.06697297317042
At time: 60.9983766078949 and batch: 850, loss is 4.840350828170776 and perplexity is 126.5137285253013
At time: 62.04337024688721 and batch: 900, loss is 4.8546374320983885 and perplexity is 128.33415293405213
At time: 63.090044260025024 and batch: 950, loss is 4.91714563369751 and perplexity is 136.61211512142435
At time: 64.1307966709137 and batch: 1000, loss is 4.884286975860595 and perplexity is 132.19617265956984
At time: 65.17113280296326 and batch: 1050, loss is 4.802440376281738 and perplexity is 121.80731077792159
At time: 66.212327003479 and batch: 1100, loss is 4.880647258758545 and perplexity is 131.7158905648052
At time: 67.2532958984375 and batch: 1150, loss is 4.807995004653931 and perplexity is 122.48578772147884
At time: 68.29395818710327 and batch: 1200, loss is 4.875561723709106 and perplexity is 131.04774516519495
At time: 69.33416652679443 and batch: 1250, loss is 4.843398838043213 and perplexity is 126.89993189569063
At time: 70.37382435798645 and batch: 1300, loss is 4.856234683990478 and perplexity is 128.53929869375798
At time: 71.41479802131653 and batch: 1350, loss is 4.775736198425293 and perplexity is 118.59759385120208
At time: 72.4563639163971 and batch: 1400, loss is 4.7815367698669435 and perplexity is 119.28752673514352
At time: 73.49800324440002 and batch: 1450, loss is 4.720373735427857 and perplexity is 112.21018175241609
At time: 74.53973579406738 and batch: 1500, loss is 4.712532176971435 and perplexity is 111.33371995713466
At time: 75.58130717277527 and batch: 1550, loss is 4.70698395729065 and perplexity is 110.71772643478867
At time: 76.62208080291748 and batch: 1600, loss is 4.780482053756714 and perplexity is 119.16177858490357
At time: 77.66187620162964 and batch: 1650, loss is 4.747059841156005 and perplexity is 115.24494746768741
At time: 78.70740008354187 and batch: 1700, loss is 4.774259805679321 and perplexity is 118.42262641605834
At time: 79.75168013572693 and batch: 1750, loss is 4.781680517196655 and perplexity is 119.3046752310753
At time: 80.79297351837158 and batch: 1800, loss is 4.73563063621521 and perplexity is 113.93528778549187
At time: 81.8374695777893 and batch: 1850, loss is 4.758673439025879 and perplexity is 116.59115798703692
At time: 82.87808036804199 and batch: 1900, loss is 4.832784605026245 and perplexity is 125.56010962051882
At time: 83.91747426986694 and batch: 1950, loss is 4.760947437286377 and perplexity is 116.85658775652634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6993047669876455 and perplexity of 109.87076011348776
finished 2 epochs...
Completing Train Step...
At time: 87.19568037986755 and batch: 50, loss is 4.700807781219482 and perplexity is 110.0360215936682
At time: 88.25865650177002 and batch: 100, loss is 4.653456373214722 and perplexity is 104.94709575338582
At time: 89.29544043540955 and batch: 150, loss is 4.602641248703003 and perplexity is 99.74742577828648
At time: 90.33274459838867 and batch: 200, loss is 4.596008024215698 and perplexity is 99.08796829382615
At time: 91.369708776474 and batch: 250, loss is 4.589123363494873 and perplexity is 98.40812418392728
At time: 92.4047782421112 and batch: 300, loss is 4.6280813407897945 and perplexity is 102.31756312670427
At time: 93.43991684913635 and batch: 350, loss is 4.625109100341797 and perplexity is 102.01390222719297
At time: 94.47678756713867 and batch: 400, loss is 4.595847578048706 and perplexity is 99.07207128445955
At time: 95.51152205467224 and batch: 450, loss is 4.603888940811157 and perplexity is 99.87195752672336
At time: 96.54840779304504 and batch: 500, loss is 4.611801481246948 and perplexity is 100.6653330978788
At time: 97.58378744125366 and batch: 550, loss is 4.561505479812622 and perplexity is 95.72748720226744
At time: 98.62781262397766 and batch: 600, loss is 4.54701494216919 and perplexity is 94.3503462985949
At time: 99.66764068603516 and batch: 650, loss is 4.618851308822632 and perplexity is 101.37751376490368
At time: 100.70467782020569 and batch: 700, loss is 4.622735414505005 and perplexity is 101.77204043783415
At time: 101.7437732219696 and batch: 750, loss is 4.58932861328125 and perplexity is 98.42832450337848
At time: 102.78043866157532 and batch: 800, loss is 4.560774660110473 and perplexity is 95.65755322625922
At time: 103.81810569763184 and batch: 850, loss is 4.572036409378052 and perplexity is 96.74091342176847
At time: 104.85358667373657 and batch: 900, loss is 4.569683322906494 and perplexity is 96.51354130518887
At time: 105.89114618301392 and batch: 950, loss is 4.64889949798584 and perplexity is 104.46995289829279
At time: 106.9287977218628 and batch: 1000, loss is 4.618202619552612 and perplexity is 101.31177258460757
At time: 107.971195936203 and batch: 1050, loss is 4.548330755233764 and perplexity is 94.47457543013506
At time: 109.00922513008118 and batch: 1100, loss is 4.612798452377319 and perplexity is 100.76574357366246
At time: 110.07428574562073 and batch: 1150, loss is 4.553826303482055 and perplexity is 94.99519425030182
At time: 111.111971616745 and batch: 1200, loss is 4.615324630737304 and perplexity is 101.02061760759906
At time: 112.14990496635437 and batch: 1250, loss is 4.601272802352906 and perplexity is 99.61102013074044
At time: 113.18728494644165 and batch: 1300, loss is 4.610085773468017 and perplexity is 100.49276888003037
At time: 114.22491931915283 and batch: 1350, loss is 4.50581955909729 and perplexity is 90.54251859431112
At time: 115.26340818405151 and batch: 1400, loss is 4.523390245437622 and perplexity is 92.14747156049162
At time: 116.30377960205078 and batch: 1450, loss is 4.457653408050537 and perplexity is 86.2847961390714
At time: 117.34082007408142 and batch: 1500, loss is 4.454054393768311 and perplexity is 85.97481407496312
At time: 118.37845635414124 and batch: 1550, loss is 4.457382917404175 and perplexity is 86.26146006502968
At time: 119.41417074203491 and batch: 1600, loss is 4.5399392795562745 and perplexity is 93.68511134523192
At time: 120.45158195495605 and batch: 1650, loss is 4.501663131713867 and perplexity is 90.16696620943645
At time: 121.49108743667603 and batch: 1700, loss is 4.52971568107605 and perplexity is 92.73219181665597
At time: 122.52978587150574 and batch: 1750, loss is 4.5454222679138185 and perplexity is 94.20019653263243
At time: 123.568284034729 and batch: 1800, loss is 4.493195371627808 and perplexity is 89.4066774860473
At time: 124.6080551147461 and batch: 1850, loss is 4.523828535079956 and perplexity is 92.18786769480081
At time: 125.64364624023438 and batch: 1900, loss is 4.613529806137085 and perplexity is 100.83946593435742
At time: 126.6803970336914 and batch: 1950, loss is 4.540939769744873 and perplexity is 93.77888928408196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.634945323855378 and perplexity of 103.02228497988209
finished 3 epochs...
Completing Train Step...
At time: 130.0856020450592 and batch: 50, loss is 4.488035621643067 and perplexity is 88.94654947682984
At time: 131.12468433380127 and batch: 100, loss is 4.441459722518921 and perplexity is 84.89877992798422
At time: 132.1644093990326 and batch: 150, loss is 4.398636531829834 and perplexity is 81.33988867414665
At time: 133.20090675354004 and batch: 200, loss is 4.396895112991333 and perplexity is 81.19836512134306
At time: 134.23850297927856 and batch: 250, loss is 4.382303657531739 and perplexity is 80.0221648985786
At time: 135.27683687210083 and batch: 300, loss is 4.424222631454468 and perplexity is 83.44791221949258
At time: 136.3177888393402 and batch: 350, loss is 4.426632022857666 and perplexity is 83.6492133109865
At time: 137.38236665725708 and batch: 400, loss is 4.389790935516357 and perplexity is 80.62356169511335
At time: 138.42390990257263 and batch: 450, loss is 4.413181476593017 and perplexity is 82.53161867580815
At time: 139.45928287506104 and batch: 500, loss is 4.428474445343017 and perplexity is 83.80347256419462
At time: 140.49432969093323 and batch: 550, loss is 4.379609289169312 and perplexity is 79.80684591377438
At time: 141.53554964065552 and batch: 600, loss is 4.36217246055603 and perplexity is 78.42732976524256
At time: 142.5763623714447 and batch: 650, loss is 4.431181755065918 and perplexity is 84.03066191748722
At time: 143.6163785457611 and batch: 700, loss is 4.447444334030151 and perplexity is 85.40838953038114
At time: 144.6536741256714 and batch: 750, loss is 4.410524759292603 and perplexity is 82.3126464990209
At time: 145.69191813468933 and batch: 800, loss is 4.3764549827575685 and perplexity is 79.55550727594019
At time: 146.72983527183533 and batch: 850, loss is 4.387435340881348 and perplexity is 80.43386877325793
At time: 147.76773047447205 and batch: 900, loss is 4.380014390945434 and perplexity is 79.83918235813407
At time: 148.8081123828888 and batch: 950, loss is 4.463769197463989 and perplexity is 86.81411272640183
At time: 149.84763956069946 and batch: 1000, loss is 4.430805959701538 and perplexity is 83.9990895170253
At time: 150.88579106330872 and batch: 1050, loss is 4.375852308273315 and perplexity is 79.50757564665895
At time: 151.92742371559143 and batch: 1100, loss is 4.434437913894653 and perplexity is 84.30472505357666
At time: 152.96769404411316 and batch: 1150, loss is 4.383759059906006 and perplexity is 80.13871413981435
At time: 154.00640678405762 and batch: 1200, loss is 4.440779695510864 and perplexity is 84.84106609039033
At time: 155.04805612564087 and batch: 1250, loss is 4.435533981323243 and perplexity is 84.39717937561365
At time: 156.09286737442017 and batch: 1300, loss is 4.44025221824646 and perplexity is 84.79632615762587
At time: 157.13531231880188 and batch: 1350, loss is 4.331415047645569 and perplexity is 76.05182742286274
At time: 158.17575216293335 and batch: 1400, loss is 4.349829044342041 and perplexity is 77.46521867577576
At time: 159.21620535850525 and batch: 1450, loss is 4.279589490890503 and perplexity is 72.2107907346929
At time: 160.25315475463867 and batch: 1500, loss is 4.283530650138855 and perplexity is 72.4959465134911
At time: 161.29390835762024 and batch: 1550, loss is 4.2912548828125 and perplexity is 73.0580903421562
At time: 162.3315737247467 and batch: 1600, loss is 4.373128414154053 and perplexity is 79.29130011846101
At time: 163.37077283859253 and batch: 1650, loss is 4.337557144165039 and perplexity is 76.52038256981173
At time: 164.4101529121399 and batch: 1700, loss is 4.359437913894653 and perplexity is 78.2131595351753
At time: 165.45105743408203 and batch: 1750, loss is 4.377248134613037 and perplexity is 79.61863190454774
At time: 166.4904978275299 and batch: 1800, loss is 4.322339630126953 and perplexity is 75.36474781891697
At time: 167.53007864952087 and batch: 1850, loss is 4.356573905944824 and perplexity is 77.98947689181688
At time: 168.5686981678009 and batch: 1900, loss is 4.4482958984375 and perplexity is 85.48115125124309
At time: 169.60786271095276 and batch: 1950, loss is 4.381572332382202 and perplexity is 79.96366407103848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.608788210846657 and perplexity of 100.3624577811036
finished 4 epochs...
Completing Train Step...
At time: 172.8701651096344 and batch: 50, loss is 4.332018485069275 and perplexity is 76.09773379108822
At time: 173.93598866462708 and batch: 100, loss is 4.287041683197021 and perplexity is 72.75092954326769
At time: 174.97300791740417 and batch: 150, loss is 4.251281242370606 and perplexity is 70.19529193787008
At time: 176.0119297504425 and batch: 200, loss is 4.249302473068237 and perplexity is 70.05652898422662
At time: 177.05068230628967 and batch: 250, loss is 4.227785205841064 and perplexity is 68.56520606482336
At time: 178.09130954742432 and batch: 300, loss is 4.270420122146606 and perplexity is 71.55168975506635
At time: 179.1301019191742 and batch: 350, loss is 4.274447231292725 and perplexity is 71.8404171975558
At time: 180.17118620872498 and batch: 400, loss is 4.235868535041809 and perplexity is 69.12168727753374
At time: 181.21058130264282 and batch: 450, loss is 4.264884805679321 and perplexity is 71.15672265093401
At time: 182.25309920310974 and batch: 500, loss is 4.2836525249481205 and perplexity is 72.50478248157502
At time: 183.29240155220032 and batch: 550, loss is 4.236928482055664 and perplexity is 69.19499144596033
At time: 184.3330888748169 and batch: 600, loss is 4.22369800567627 and perplexity is 68.28553826176699
At time: 185.37393879890442 and batch: 650, loss is 4.288857164382935 and perplexity is 72.88312745220944
At time: 186.4120898246765 and batch: 700, loss is 4.308669171333313 and perplexity is 74.34148729542684
At time: 187.45131587982178 and batch: 750, loss is 4.272379288673401 and perplexity is 71.69200883991448
At time: 188.49183750152588 and batch: 800, loss is 4.237661561965942 and perplexity is 69.24573550153261
At time: 189.58819890022278 and batch: 850, loss is 4.2506203985214235 and perplexity is 70.1489191352297
At time: 190.62684845924377 and batch: 900, loss is 4.2374052238464355 and perplexity is 69.22798745475792
At time: 191.66691660881042 and batch: 950, loss is 4.323146533966065 and perplexity is 75.42558446462637
At time: 192.70531249046326 and batch: 1000, loss is 4.290329179763794 and perplexity is 72.99049153823054
At time: 193.743469953537 and batch: 1050, loss is 4.247368793487549 and perplexity is 69.92119299502512
At time: 194.78243207931519 and batch: 1100, loss is 4.297890019416809 and perplexity is 73.54445250698639
At time: 195.81970834732056 and batch: 1150, loss is 4.248715300559997 and perplexity is 70.01540579077019
At time: 196.8610553741455 and batch: 1200, loss is 4.306565070152283 and perplexity is 74.1852297327193
At time: 197.900643825531 and batch: 1250, loss is 4.299427347183228 and perplexity is 73.6576013870645
At time: 198.94191646575928 and batch: 1300, loss is 4.306893568038941 and perplexity is 74.20960342704208
At time: 199.98125195503235 and batch: 1350, loss is 4.196356210708618 and perplexity is 66.44378226867018
At time: 201.02024698257446 and batch: 1400, loss is 4.213055291175842 and perplexity is 67.56264835230694
At time: 202.06138730049133 and batch: 1450, loss is 4.147148518562317 and perplexity is 63.253377068035626
At time: 203.10088849067688 and batch: 1500, loss is 4.14844211101532 and perplexity is 63.33525410557906
At time: 204.13996624946594 and batch: 1550, loss is 4.157493801116943 and perplexity is 63.91114767123784
At time: 205.17945194244385 and batch: 1600, loss is 4.244414138793945 and perplexity is 69.71490491905021
At time: 206.21973156929016 and batch: 1650, loss is 4.208575296401977 and perplexity is 67.26064503253652
At time: 207.258953332901 and batch: 1700, loss is 4.232224144935608 and perplexity is 68.87023934976771
At time: 208.29783844947815 and batch: 1750, loss is 4.24992199420929 and perplexity is 70.09994393185146
At time: 209.3473060131073 and batch: 1800, loss is 4.188424487113952 and perplexity is 65.91885310169673
At time: 210.3854205608368 and batch: 1850, loss is 4.219441728591919 and perplexity is 67.99551374027091
At time: 211.42296767234802 and batch: 1900, loss is 4.3166969108581545 and perplexity is 74.94068326801127
At time: 212.46373009681702 and batch: 1950, loss is 4.2449469566345215 and perplexity is 69.75206016175424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.59823849700218 and perplexity of 99.30922797569215
finished 5 epochs...
Completing Train Step...
At time: 215.76449513435364 and batch: 50, loss is 4.2046208000183105 and perplexity is 66.99518827482169
At time: 216.80734777450562 and batch: 100, loss is 4.164306225776673 and perplexity is 64.3480239534581
At time: 217.8491177558899 and batch: 150, loss is 4.132803874015808 and perplexity is 62.35250663821216
At time: 218.89645099639893 and batch: 200, loss is 4.128178558349609 and perplexity is 62.064772555881845
At time: 219.93825554847717 and batch: 250, loss is 4.10468346118927 and perplexity is 60.62355180315203
At time: 220.98448181152344 and batch: 300, loss is 4.146312303543091 and perplexity is 63.20050575308927
At time: 222.03074526786804 and batch: 350, loss is 4.150286283493042 and perplexity is 63.45216300502383
At time: 223.0744559764862 and batch: 400, loss is 4.111923670768737 and perplexity is 61.06407182795035
At time: 224.1175675392151 and batch: 450, loss is 4.1508055639266965 and perplexity is 63.485121028233095
At time: 225.16062355041504 and batch: 500, loss is 4.16830087184906 and perplexity is 64.60558562597464
At time: 226.2048797607422 and batch: 550, loss is 4.132168545722961 and perplexity is 62.312904907996874
At time: 227.24750113487244 and batch: 600, loss is 4.109020504951477 and perplexity is 60.887049788457645
At time: 228.28977346420288 and batch: 650, loss is 4.175246424674988 and perplexity is 65.05586905730499
At time: 229.33472681045532 and batch: 700, loss is 4.194945678710938 and perplexity is 66.3501272549581
At time: 230.37939763069153 and batch: 750, loss is 4.162508273124695 and perplexity is 64.232433197633
At time: 231.42201352119446 and batch: 800, loss is 4.122220530509948 and perplexity is 61.69608831923638
At time: 232.47209930419922 and batch: 850, loss is 4.135978965759278 and perplexity is 62.55079619440696
At time: 233.51507425308228 and batch: 900, loss is 4.120746846199036 and perplexity is 61.60523472303787
At time: 234.5564022064209 and batch: 950, loss is 4.211432771682739 and perplexity is 67.45311552195524
At time: 235.6098084449768 and batch: 1000, loss is 4.176231517791748 and perplexity is 65.11998672186813
At time: 236.65477991104126 and batch: 1050, loss is 4.13808171749115 and perplexity is 62.68246337261366
At time: 237.70706272125244 and batch: 1100, loss is 4.182681140899658 and perplexity is 65.54134342837246
At time: 238.75604820251465 and batch: 1150, loss is 4.139994277954101 and perplexity is 62.802462089602905
At time: 239.8032946586609 and batch: 1200, loss is 4.19249397277832 and perplexity is 66.18765550220014
At time: 240.85123658180237 and batch: 1250, loss is 4.1918572473526 and perplexity is 66.14552555310138
At time: 241.8929135799408 and batch: 1300, loss is 4.194287090301514 and perplexity is 66.30644421633455
At time: 242.94127082824707 and batch: 1350, loss is 4.086770734786987 and perplexity is 59.54728690340332
At time: 243.99033880233765 and batch: 1400, loss is 4.10581934928894 and perplexity is 60.69245249853672
At time: 245.03533053398132 and batch: 1450, loss is 4.036503310203552 and perplexity is 56.62798571113227
At time: 246.0849678516388 and batch: 1500, loss is 4.04502772808075 and perplexity is 57.11276963967804
At time: 247.12812280654907 and batch: 1550, loss is 4.052494502067566 and perplexity is 57.540813848302676
At time: 248.17812275886536 and batch: 1600, loss is 4.14042582988739 and perplexity is 62.829570462447634
At time: 249.221449136734 and batch: 1650, loss is 4.100710568428039 and perplexity is 60.38317873740777
At time: 250.26536297798157 and batch: 1700, loss is 4.123274393081665 and perplexity is 61.76114179022564
At time: 251.31280326843262 and batch: 1750, loss is 4.142704882621765 and perplexity is 62.97292566178931
At time: 252.35735702514648 and batch: 1800, loss is 4.076678857803345 and perplexity is 58.949365160255304
At time: 253.4010875225067 and batch: 1850, loss is 4.113189673423767 and perplexity is 61.14142806127785
At time: 254.44331908226013 and batch: 1900, loss is 4.2102241563797 and perplexity is 67.37163990055708
At time: 255.48733401298523 and batch: 1950, loss is 4.140577039718628 and perplexity is 62.83907162951081
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.599575876635174 and perplexity of 99.44213096562211
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 258.81810998916626 and batch: 50, loss is 4.129387354850769 and perplexity is 62.13984159824969
At time: 259.88240814208984 and batch: 100, loss is 4.117592248916626 and perplexity is 61.4112012266786
At time: 260.9200737476349 and batch: 150, loss is 4.087847485542297 and perplexity is 59.61143902127577
At time: 261.9670114517212 and batch: 200, loss is 4.0832382106781 and perplexity is 59.33730577685227
At time: 263.00767064094543 and batch: 250, loss is 4.058317947387695 and perplexity is 57.87687720498595
At time: 264.0529115200043 and batch: 300, loss is 4.085455627441406 and perplexity is 59.46902730015598
At time: 265.0914418697357 and batch: 350, loss is 4.083097629547119 and perplexity is 59.32896465761248
At time: 266.12957549095154 and batch: 400, loss is 4.042199578285217 and perplexity is 56.95147436301024
At time: 267.17113399505615 and batch: 450, loss is 4.078403153419495 and perplexity is 59.05109897655645
At time: 268.2104687690735 and batch: 500, loss is 4.088579339981079 and perplexity is 59.65508188568973
At time: 269.27651596069336 and batch: 550, loss is 4.049001922607422 and perplexity is 57.34019852015071
At time: 270.31466579437256 and batch: 600, loss is 4.0094495868682865 and perplexity is 55.11652535369985
At time: 271.35742568969727 and batch: 650, loss is 4.060774393081665 and perplexity is 58.01922337201323
At time: 272.40057730674744 and batch: 700, loss is 4.077501192092895 and perplexity is 58.99786118181162
At time: 273.4446556568146 and batch: 750, loss is 4.034741911888123 and perplexity is 56.528329065783716
At time: 274.48215317726135 and batch: 800, loss is 3.997524733543396 and perplexity is 54.46317218576038
At time: 275.5224823951721 and batch: 850, loss is 4.0019154405593875 and perplexity is 54.7028297660833
At time: 276.5665216445923 and batch: 900, loss is 3.980234661102295 and perplexity is 53.52959406732984
At time: 277.612277507782 and batch: 950, loss is 4.069054589271546 and perplexity is 58.50162837213628
At time: 278.65170311927795 and batch: 1000, loss is 4.02391001701355 and perplexity is 55.919324439481365
At time: 279.69592905044556 and batch: 1050, loss is 3.9765748453140257 and perplexity is 53.33404367130685
At time: 280.73842549324036 and batch: 1100, loss is 4.008573436737061 and perplexity is 55.06825615140025
At time: 281.7746331691742 and batch: 1150, loss is 3.9609818696975707 and perplexity is 52.508857502359376
At time: 282.8134334087372 and batch: 1200, loss is 4.015769991874695 and perplexity is 55.46598732372955
At time: 283.8515667915344 and batch: 1250, loss is 4.003748922348023 and perplexity is 54.80321841049921
At time: 284.89204835891724 and batch: 1300, loss is 4.000780463218689 and perplexity is 54.64077851387037
At time: 285.93049812316895 and batch: 1350, loss is 3.8846655607223513 and perplexity is 48.65066904379527
At time: 286.96984028816223 and batch: 1400, loss is 3.8912335729598997 and perplexity is 48.971258900002
At time: 288.0120141506195 and batch: 1450, loss is 3.812941484451294 and perplexity is 45.28344370013828
At time: 289.05466198921204 and batch: 1500, loss is 3.8159336614608765 and perplexity is 45.419142695755866
At time: 290.09253454208374 and batch: 1550, loss is 3.8164244413375856 and perplexity is 45.44143896784163
At time: 291.1331515312195 and batch: 1600, loss is 3.8919994163513185 and perplexity is 49.00877757988277
At time: 292.1740303039551 and batch: 1650, loss is 3.840115098953247 and perplexity is 46.53082978138774
At time: 293.2135260105133 and batch: 1700, loss is 3.8567916107177735 and perplexity is 47.31330808169582
At time: 294.2508227825165 and batch: 1750, loss is 3.861960039138794 and perplexity is 47.5584765499593
At time: 295.2880413532257 and batch: 1800, loss is 3.793031620979309 and perplexity is 44.39077248742152
At time: 296.325820684433 and batch: 1850, loss is 3.8148240423202515 and perplexity is 45.36877269659566
At time: 297.36433362960815 and batch: 1900, loss is 3.9020001554489134 and perplexity is 49.50136056947444
At time: 298.40274930000305 and batch: 1950, loss is 3.834403872489929 and perplexity is 46.26583910614943
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.514179744276889 and perplexity of 91.30264378279315
finished 7 epochs...
Completing Train Step...
At time: 301.7406394481659 and batch: 50, loss is 4.019414286613465 and perplexity is 55.668490496018386
At time: 302.7785587310791 and batch: 100, loss is 3.9962988805770876 and perplexity is 54.396449249192216
At time: 303.81916785240173 and batch: 150, loss is 3.969429383277893 and perplexity is 52.95430560469841
At time: 304.8664348125458 and batch: 200, loss is 3.960970320701599 and perplexity is 52.50825108127739
At time: 305.9059317111969 and batch: 250, loss is 3.9393678092956543 and perplexity is 51.38610521169921
At time: 306.95446395874023 and batch: 300, loss is 3.965595188140869 and perplexity is 52.751657208673684
At time: 307.99583888053894 and batch: 350, loss is 3.9687061214447024 and perplexity is 52.91601962361484
At time: 309.03839445114136 and batch: 400, loss is 3.9300553035736083 and perplexity is 50.90979308483869
At time: 310.0823290348053 and batch: 450, loss is 3.972336392402649 and perplexity is 53.1084682217885
At time: 311.12557077407837 and batch: 500, loss is 3.9856411695480345 and perplexity is 53.819786025521324
At time: 312.16602993011475 and batch: 550, loss is 3.9476893186569213 and perplexity is 51.81549929282026
At time: 313.20742630958557 and batch: 600, loss is 3.912738404273987 and perplexity is 50.03578274023145
At time: 314.2500693798065 and batch: 650, loss is 3.96752076625824 and perplexity is 52.85333250589706
At time: 315.2930016517639 and batch: 700, loss is 3.988165621757507 and perplexity is 53.95582314061925
At time: 316.3406629562378 and batch: 750, loss is 3.95038010597229 and perplexity is 51.95511153023902
At time: 317.3803915977478 and batch: 800, loss is 3.913478446006775 and perplexity is 50.072825012315
At time: 318.41923236846924 and batch: 850, loss is 3.921048140525818 and perplexity is 50.453299221359806
At time: 319.46012258529663 and batch: 900, loss is 3.9003163957595826 and perplexity is 49.41808230394859
At time: 320.50135684013367 and batch: 950, loss is 3.9932260656356813 and perplexity is 54.229555575187554
At time: 321.57806396484375 and batch: 1000, loss is 3.9510984373092652 and perplexity is 51.992445922593845
At time: 322.6163718700409 and batch: 1050, loss is 3.9063909006118775 and perplexity is 49.71918628761558
At time: 323.6605725288391 and batch: 1100, loss is 3.940299935340881 and perplexity is 51.43402586930664
At time: 324.6997015476227 and batch: 1150, loss is 3.899493908882141 and perplexity is 49.3774532904509
At time: 325.73989844322205 and batch: 1200, loss is 3.9525293111801147 and perplexity is 52.06689380500883
At time: 326.78020453453064 and batch: 1250, loss is 3.944629650115967 and perplexity is 51.65720332978087
At time: 327.8214485645294 and batch: 1300, loss is 3.947437119483948 and perplexity is 51.80243311446036
At time: 328.8605737686157 and batch: 1350, loss is 3.8332122325897218 and perplexity is 46.210739722086345
At time: 329.89756441116333 and batch: 1400, loss is 3.846334171295166 and perplexity is 46.82111007942055
At time: 330.94447898864746 and batch: 1450, loss is 3.7682906436920165 and perplexity is 43.30597618837214
At time: 331.9844927787781 and batch: 1500, loss is 3.7762536001205445 and perplexity is 43.652196428754145
At time: 333.02543473243713 and batch: 1550, loss is 3.77787070274353 and perplexity is 43.72284361657921
At time: 334.06523609161377 and batch: 1600, loss is 3.858837561607361 and perplexity is 47.410207878766705
At time: 335.1060616970062 and batch: 1650, loss is 3.8101679849624634 and perplexity is 45.15802409818149
At time: 336.1456067562103 and batch: 1700, loss is 3.8303033018112185 and perplexity is 46.076511204396695
At time: 337.18678188323975 and batch: 1750, loss is 3.8407202625274657 and perplexity is 46.55899706669751
At time: 338.22682547569275 and batch: 1800, loss is 3.7763073015213013 and perplexity is 43.654540675792596
At time: 339.2692301273346 and batch: 1850, loss is 3.8021169662475587 and perplexity is 44.79591562802795
At time: 340.31037425994873 and batch: 1900, loss is 3.8935017728805543 and perplexity is 49.08246157282453
At time: 341.3563048839569 and batch: 1950, loss is 3.8291990041732786 and perplexity is 46.02565710610742
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.513253429324128 and perplexity of 91.21810793808373
finished 8 epochs...
Completing Train Step...
At time: 344.6384551525116 and batch: 50, loss is 3.965821328163147 and perplexity is 52.7635878185534
At time: 345.7142975330353 and batch: 100, loss is 3.939620099067688 and perplexity is 51.39907103597241
At time: 346.76118206977844 and batch: 150, loss is 3.9137558555603027 and perplexity is 50.086717619227386
At time: 347.8338694572449 and batch: 200, loss is 3.9042564868927 and perplexity is 49.613178147156916
At time: 348.8799443244934 and batch: 250, loss is 3.8825584840774536 and perplexity is 48.54826627841917
At time: 349.9310963153839 and batch: 300, loss is 3.9102144289016723 and perplexity is 49.90965289812688
At time: 350.97983288764954 and batch: 350, loss is 3.9130729627609253 and perplexity is 50.052525436547214
At time: 352.0390079021454 and batch: 400, loss is 3.875781970024109 and perplexity is 48.220390451992465
At time: 353.1009991168976 and batch: 450, loss is 3.9201509618759154 and perplexity is 50.40805389808522
At time: 354.1493396759033 and batch: 500, loss is 3.9339875745773316 and perplexity is 51.11037830725208
At time: 355.19399785995483 and batch: 550, loss is 3.897152614593506 and perplexity is 49.261981370695864
At time: 356.24069261550903 and batch: 600, loss is 3.8635324573516847 and perplexity is 47.63331718963597
At time: 357.2879514694214 and batch: 650, loss is 3.9188847017288206 and perplexity is 50.34426458379811
At time: 358.3311903476715 and batch: 700, loss is 3.9395491313934325 and perplexity is 51.39542349287246
At time: 359.3769338130951 and batch: 750, loss is 3.903831648826599 and perplexity is 49.592105057142106
At time: 360.4212682247162 and batch: 800, loss is 3.8667803764343263 and perplexity is 47.78827786314694
At time: 361.4664635658264 and batch: 850, loss is 3.876299304962158 and perplexity is 48.2453429985552
At time: 362.510981798172 and batch: 900, loss is 3.85465576171875 and perplexity is 47.2123618413274
At time: 363.55717515945435 and batch: 950, loss is 3.950259976387024 and perplexity is 51.94887055910859
At time: 364.6004068851471 and batch: 1000, loss is 3.909086728096008 and perplexity is 49.853401465697374
At time: 365.64463114738464 and batch: 1050, loss is 3.86451895236969 and perplexity is 47.680330405073356
At time: 366.6890985965729 and batch: 1100, loss is 3.8999860858917237 and perplexity is 49.4017617192864
At time: 367.74091935157776 and batch: 1150, loss is 3.862209916114807 and perplexity is 47.57036180312713
At time: 368.7866098880768 and batch: 1200, loss is 3.914644455909729 and perplexity is 50.13124447436506
At time: 369.8319363594055 and batch: 1250, loss is 3.9088194227218627 and perplexity is 49.84007716447416
At time: 370.87653374671936 and batch: 1300, loss is 3.913247027397156 and perplexity is 50.0612385694819
At time: 371.91928029060364 and batch: 1350, loss is 3.7991555976867675 and perplexity is 44.66345464153933
At time: 372.96449732780457 and batch: 1400, loss is 3.8160215187072755 and perplexity is 45.42313327186486
At time: 374.0096619129181 and batch: 1450, loss is 3.7376403045654296 and perplexity is 41.998768841891575
At time: 375.0549397468567 and batch: 1500, loss is 3.746665735244751 and perplexity is 42.37954155278651
At time: 376.101753950119 and batch: 1550, loss is 3.7487338304519655 and perplexity is 42.46727717109108
At time: 377.14884543418884 and batch: 1600, loss is 3.831738142967224 and perplexity is 46.14267113214085
At time: 378.1941223144531 and batch: 1650, loss is 3.7835938262939455 and perplexity is 43.97379227268727
At time: 379.241854429245 and batch: 1700, loss is 3.805377049446106 and perplexity is 44.94219234751406
At time: 380.29361367225647 and batch: 1750, loss is 3.8177736234664916 and perplexity is 45.50278912216845
At time: 381.3454577922821 and batch: 1800, loss is 3.755144786834717 and perplexity is 42.740407610918076
At time: 382.3906648159027 and batch: 1850, loss is 3.782605695724487 and perplexity is 43.930361885268134
At time: 383.43620896339417 and batch: 1900, loss is 3.874517307281494 and perplexity is 48.159446465670605
At time: 384.4873926639557 and batch: 1950, loss is 3.8116722869873048 and perplexity is 45.22600652550183
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.516752589026162 and perplexity of 91.53785376007369
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 387.8098464012146 and batch: 50, loss is 3.941034474372864 and perplexity is 51.471820047829986
At time: 388.86195635795593 and batch: 100, loss is 3.9367129135131838 and perplexity is 51.24986139428907
At time: 389.9091594219208 and batch: 150, loss is 3.9214036798477174 and perplexity is 50.47124054238612
At time: 390.9490075111389 and batch: 200, loss is 3.913180584907532 and perplexity is 50.05791248665552
At time: 391.993337392807 and batch: 250, loss is 3.900774760246277 and perplexity is 49.440738989990706
At time: 393.0335144996643 and batch: 300, loss is 3.9204633378982545 and perplexity is 50.42380262509005
At time: 394.0800721645355 and batch: 350, loss is 3.918238487243652 and perplexity is 50.311741900225286
At time: 395.12109661102295 and batch: 400, loss is 3.8869106435775755 and perplexity is 48.76001652791205
At time: 396.1618609428406 and batch: 450, loss is 3.9327929162979127 and perplexity is 51.049355328704074
At time: 397.20181918144226 and batch: 500, loss is 3.9440672397613525 and perplexity is 51.62815895193279
At time: 398.2414755821228 and batch: 550, loss is 3.907628746032715 and perplexity is 49.780769061803575
At time: 399.2834632396698 and batch: 600, loss is 3.8668331241607667 and perplexity is 47.7907986526371
At time: 400.32991790771484 and batch: 650, loss is 3.9128955173492432 and perplexity is 50.04364463351757
At time: 401.4066798686981 and batch: 700, loss is 3.9258010149002076 and perplexity is 50.6936681835822
At time: 402.4473810195923 and batch: 750, loss is 3.8834708595275877 and perplexity is 48.59258073735633
At time: 403.486985206604 and batch: 800, loss is 3.8459193229675295 and perplexity is 46.801690448585205
At time: 404.5336539745331 and batch: 850, loss is 3.853144292831421 and perplexity is 47.141055727368396
At time: 405.579984664917 and batch: 900, loss is 3.827414703369141 and perplexity is 45.9436067121828
At time: 406.6194579601288 and batch: 950, loss is 3.929570631980896 and perplexity is 50.885124532895695
At time: 407.65762424468994 and batch: 1000, loss is 3.881646099090576 and perplexity is 48.50399176989759
At time: 408.6988627910614 and batch: 1050, loss is 3.8396627616882326 and perplexity is 46.50978691270121
At time: 409.74067091941833 and batch: 1100, loss is 3.86547091960907 and perplexity is 47.72574212938921
At time: 410.7814042568207 and batch: 1150, loss is 3.825939168930054 and perplexity is 45.87586532788641
At time: 411.8225326538086 and batch: 1200, loss is 3.87480854511261 and perplexity is 48.17347436103476
At time: 412.8633031845093 and batch: 1250, loss is 3.864958920478821 and perplexity is 47.70131284534822
At time: 413.9015865325928 and batch: 1300, loss is 3.863419017791748 and perplexity is 47.627913993569535
At time: 414.9410719871521 and batch: 1350, loss is 3.746426281929016 and perplexity is 42.369394845922166
At time: 415.9817657470703 and batch: 1400, loss is 3.762177653312683 and perplexity is 43.04205466928394
At time: 417.0207476615906 and batch: 1450, loss is 3.680704298019409 and perplexity is 39.674326784716904
At time: 418.0602431297302 and batch: 1500, loss is 3.6865999603271487 and perplexity is 39.90892409144889
At time: 419.103168964386 and batch: 1550, loss is 3.690265693664551 and perplexity is 40.05548803299178
At time: 420.1438217163086 and batch: 1600, loss is 3.7706226396560667 and perplexity is 43.40708339504148
At time: 421.18564081192017 and batch: 1650, loss is 3.715448408126831 and perplexity is 41.077002216956565
At time: 422.2284073829651 and batch: 1700, loss is 3.7310007858276366 and perplexity is 41.72084090407258
At time: 423.27004194259644 and batch: 1750, loss is 3.739396920204163 and perplexity is 42.0726093717741
At time: 424.30948996543884 and batch: 1800, loss is 3.671656403541565 and perplexity is 39.31697673311901
At time: 425.34970259666443 and batch: 1850, loss is 3.694284448623657 and perplexity is 40.216785113801286
At time: 426.39255595207214 and batch: 1900, loss is 3.7855801486968996 and perplexity is 44.06122520767307
At time: 427.4323675632477 and batch: 1950, loss is 3.7247523498535156 and perplexity is 41.46096365958932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485620401071948 and perplexity of 88.7319831575997
finished 10 epochs...
Completing Train Step...
At time: 430.73826575279236 and batch: 50, loss is 3.9231615114212035 and perplexity is 50.560038505631
At time: 431.8056285381317 and batch: 100, loss is 3.90486732006073 and perplexity is 49.64349277958947
At time: 432.8442885875702 and batch: 150, loss is 3.883970012664795 and perplexity is 48.61684193099811
At time: 433.88368558883667 and batch: 200, loss is 3.871266417503357 and perplexity is 48.00313961925716
At time: 434.92799282073975 and batch: 250, loss is 3.857694835662842 and perplexity is 47.35606194706116
At time: 435.96603202819824 and batch: 300, loss is 3.8764561653137206 and perplexity is 48.252911373592674
At time: 437.0059869289398 and batch: 350, loss is 3.8751563692092894 and perplexity is 48.19023317062825
At time: 438.05255699157715 and batch: 400, loss is 3.8436960935592652 and perplexity is 46.69775513285918
At time: 439.09318804740906 and batch: 450, loss is 3.891876950263977 and perplexity is 49.002776034147594
At time: 440.1353576183319 and batch: 500, loss is 3.9040053367614744 and perplexity is 49.6007193555338
At time: 441.18039894104004 and batch: 550, loss is 3.869194841384888 and perplexity is 47.90380039152185
At time: 442.2268579006195 and batch: 600, loss is 3.829614462852478 and perplexity is 46.044782837518454
At time: 443.2731099128723 and batch: 650, loss is 3.8773508405685426 and perplexity is 48.29610137700447
At time: 444.317387342453 and batch: 700, loss is 3.893500623703003 and perplexity is 49.08240516839393
At time: 445.3577299118042 and batch: 750, loss is 3.853814172744751 and perplexity is 47.17264515307292
At time: 446.39903712272644 and batch: 800, loss is 3.816645803451538 and perplexity is 45.45149909425693
At time: 447.439884185791 and batch: 850, loss is 3.8262297344207763 and perplexity is 45.88919720800607
At time: 448.48010778427124 and batch: 900, loss is 3.801247057914734 and perplexity is 44.756964232274825
At time: 449.51869797706604 and batch: 950, loss is 3.904456868171692 and perplexity is 49.62312069536589
At time: 450.5588364601135 and batch: 1000, loss is 3.857545619010925 and perplexity is 47.34899616122902
At time: 451.60694909095764 and batch: 1050, loss is 3.8170957803726195 and perplexity is 45.47195582206043
At time: 452.64830470085144 and batch: 1100, loss is 3.84467405796051 and perplexity is 46.74344621348069
At time: 453.7172873020172 and batch: 1150, loss is 3.8069578313827517 and perplexity is 45.013292335352695
At time: 454.76021456718445 and batch: 1200, loss is 3.856679744720459 and perplexity is 47.30801562732936
At time: 455.7980840206146 and batch: 1250, loss is 3.8493716812133787 and perplexity is 46.963545881233955
At time: 456.83856439590454 and batch: 1300, loss is 3.8494515800476075 and perplexity is 46.96729836370861
At time: 457.880252122879 and batch: 1350, loss is 3.7335337591171265 and perplexity is 41.826652632264675
At time: 458.92869806289673 and batch: 1400, loss is 3.7521901893615723 and perplexity is 42.61431328131339
At time: 459.9717562198639 and batch: 1450, loss is 3.6723525428771975 and perplexity is 39.34435635609165
At time: 461.0120255947113 and batch: 1500, loss is 3.680113968849182 and perplexity is 39.65091278397055
At time: 462.0544431209564 and batch: 1550, loss is 3.685463271141052 and perplexity is 39.863585821647554
At time: 463.09370160102844 and batch: 1600, loss is 3.7674794006347656 and perplexity is 43.27085876216189
At time: 464.135057926178 and batch: 1650, loss is 3.714316658973694 and perplexity is 41.030539651428036
At time: 465.1756980419159 and batch: 1700, loss is 3.731660919189453 and perplexity is 41.748391315508776
At time: 466.22238993644714 and batch: 1750, loss is 3.741576380729675 and perplexity is 42.16440495919866
At time: 467.26272225379944 and batch: 1800, loss is 3.675950083732605 and perplexity is 39.48615419433808
At time: 468.3057553768158 and batch: 1850, loss is 3.6999598217010496 and perplexity is 40.44567928882759
At time: 469.3459711074829 and batch: 1900, loss is 3.792352137565613 and perplexity is 44.360619939033526
At time: 470.3906445503235 and batch: 1950, loss is 3.7312308073043825 and perplexity is 41.730438697315385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485512524981831 and perplexity of 88.72241161446796
finished 11 epochs...
Completing Train Step...
At time: 473.6902987957001 and batch: 50, loss is 3.9073397731781006 and perplexity is 49.76638584914198
At time: 474.73078989982605 and batch: 100, loss is 3.8866573333740235 and perplexity is 48.74766668243714
At time: 475.773628950119 and batch: 150, loss is 3.8653797483444214 and perplexity is 47.7213911114699
At time: 476.8126449584961 and batch: 200, loss is 3.8514274978637695 and perplexity is 47.06019363180622
At time: 477.8538818359375 and batch: 250, loss is 3.83784875869751 and perplexity is 46.42549449660557
At time: 478.8956971168518 and batch: 300, loss is 3.85663480758667 and perplexity is 47.30588978846675
At time: 479.94215846061707 and batch: 350, loss is 3.8553536796569823 and perplexity is 47.24532369655985
At time: 481.0361490249634 and batch: 400, loss is 3.8242520666122437 and perplexity is 45.79853330102367
At time: 482.0749080181122 and batch: 450, loss is 3.872949380874634 and perplexity is 48.08399516431863
At time: 483.1155562400818 and batch: 500, loss is 3.885285577774048 and perplexity is 48.680842641284734
At time: 484.15439462661743 and batch: 550, loss is 3.8508165788650515 and perplexity is 47.031452445595455
At time: 485.1947977542877 and batch: 600, loss is 3.8118353986740114 and perplexity is 45.233384017370426
At time: 486.2413864135742 and batch: 650, loss is 3.859980230331421 and perplexity is 47.464413003863584
At time: 487.28232312202454 and batch: 700, loss is 3.8773054122924804 and perplexity is 48.29390741821265
At time: 488.3235409259796 and batch: 750, loss is 3.8382818365097044 and perplexity is 46.44560470251989
At time: 489.37157583236694 and batch: 800, loss is 3.801079750061035 and perplexity is 44.74947666703275
At time: 490.4103217124939 and batch: 850, loss is 3.8119025659561157 and perplexity is 45.23642232287147
At time: 491.44792222976685 and batch: 900, loss is 3.7869139242172243 and perplexity is 44.12003220019617
At time: 492.4928967952728 and batch: 950, loss is 3.890959038734436 and perplexity is 48.95781645865945
At time: 493.5342025756836 and batch: 1000, loss is 3.844213604927063 and perplexity is 46.721928006319985
At time: 494.5790252685547 and batch: 1050, loss is 3.8045459318161012 and perplexity is 44.904855616879736
At time: 495.6230368614197 and batch: 1100, loss is 3.832942695617676 and perplexity is 46.198285897684116
At time: 496.66192173957825 and batch: 1150, loss is 3.7961493921279907 and perplexity is 44.52938873172924
At time: 497.6997377872467 and batch: 1200, loss is 3.8459679746627806 and perplexity is 46.803967485556555
At time: 498.7378418445587 and batch: 1250, loss is 3.8398395013809203 and perplexity is 46.51800776460115
At time: 499.7844593524933 and batch: 1300, loss is 3.8405657625198364 and perplexity is 46.551804256954384
At time: 500.8255512714386 and batch: 1350, loss is 3.725086464881897 and perplexity is 41.47481870509974
At time: 501.8685817718506 and batch: 1400, loss is 3.745002031326294 and perplexity is 42.30909316232393
At time: 502.9120669364929 and batch: 1450, loss is 3.6657774353027346 and perplexity is 39.08651158807489
At time: 503.9527680873871 and batch: 1500, loss is 3.674118151664734 and perplexity is 39.413884459066644
At time: 504.9998185634613 and batch: 1550, loss is 3.6801402378082275 and perplexity is 39.65195438585542
At time: 506.0379195213318 and batch: 1600, loss is 3.7627279996871947 and perplexity is 43.06574922753178
At time: 507.08037519454956 and batch: 1650, loss is 3.710489287376404 and perplexity is 40.87380066984394
At time: 508.12031531333923 and batch: 1700, loss is 3.7286090326309203 and perplexity is 41.62117418607807
At time: 509.1696255207062 and batch: 1750, loss is 3.739083652496338 and perplexity is 42.05943144609104
At time: 510.20976090431213 and batch: 1800, loss is 3.6744502067565916 and perplexity is 39.42697421323065
At time: 511.2505021095276 and batch: 1850, loss is 3.699121103286743 and perplexity is 40.41177097458042
At time: 512.2897653579712 and batch: 1900, loss is 3.7920253086090088 and perplexity is 44.34612397288433
At time: 513.3300466537476 and batch: 1950, loss is 3.7307304763793945 and perplexity is 41.70956489066275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4866159838299415 and perplexity of 88.82036717961778
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 516.6182110309601 and batch: 50, loss is 3.8998423337936403 and perplexity is 49.394660622801226
At time: 517.6974084377289 and batch: 100, loss is 3.887838740348816 and perplexity is 48.805291548367535
At time: 518.7377798557281 and batch: 150, loss is 3.872016682624817 and perplexity is 48.039168214443194
At time: 519.7800767421722 and batch: 200, loss is 3.8593761825561526 and perplexity is 47.43575088829926
At time: 520.8227934837341 and batch: 250, loss is 3.850991463661194 and perplexity is 47.03967825083186
At time: 521.8704090118408 and batch: 300, loss is 3.8665956926345824 and perplexity is 47.77945295734161
At time: 522.91459441185 and batch: 350, loss is 3.8648783588409423 and perplexity is 47.69747010424728
At time: 523.9603953361511 and batch: 400, loss is 3.8362918949127196 and perplexity is 46.3532725599794
At time: 525.0039551258087 and batch: 450, loss is 3.885596251487732 and perplexity is 48.695968848989274
At time: 526.0459904670715 and batch: 500, loss is 3.8988671588897703 and perplexity is 49.346515668067845
At time: 527.0919394493103 and batch: 550, loss is 3.8657962608337404 and perplexity is 47.741271806867054
At time: 528.1401121616364 and batch: 600, loss is 3.827172107696533 and perplexity is 45.932462343852855
At time: 529.1835505962372 and batch: 650, loss is 3.872110676765442 and perplexity is 48.04368382699309
At time: 530.2257895469666 and batch: 700, loss is 3.8889785957336427 and perplexity is 48.860954240429884
At time: 531.2677655220032 and batch: 750, loss is 3.84537787437439 and perplexity is 46.77635659824299
At time: 532.3099088668823 and batch: 800, loss is 3.8093940877914427 and perplexity is 45.12308995054559
At time: 533.3778421878815 and batch: 850, loss is 3.8193826055526734 and perplexity is 45.57606122568094
At time: 534.4215161800385 and batch: 900, loss is 3.785705451965332 and perplexity is 44.06674656911782
At time: 535.4635503292084 and batch: 950, loss is 3.8942983150482178 and perplexity is 49.121573398201114
At time: 536.5105118751526 and batch: 1000, loss is 3.8446638631820678 and perplexity is 46.742969676832004
At time: 537.557042837143 and batch: 1050, loss is 3.8077634382247925 and perplexity is 45.04956996243111
At time: 538.6000986099243 and batch: 1100, loss is 3.828784017562866 and perplexity is 46.006561037253434
At time: 539.6424028873444 and batch: 1150, loss is 3.7931279277801515 and perplexity is 44.39504782657553
At time: 540.6832666397095 and batch: 1200, loss is 3.840890760421753 and perplexity is 46.5669359544201
At time: 541.7250077724457 and batch: 1250, loss is 3.8326275873184206 and perplexity is 46.18373072773424
At time: 542.7667443752289 and batch: 1300, loss is 3.8289129543304443 and perplexity is 46.012493356959816
At time: 543.8088207244873 and batch: 1350, loss is 3.709662857055664 and perplexity is 40.84003527594093
At time: 544.8512370586395 and batch: 1400, loss is 3.728153305053711 and perplexity is 41.60221059065055
At time: 545.8930428028107 and batch: 1450, loss is 3.6455135202407836 and perplexity is 38.30243687879645
At time: 546.9381160736084 and batch: 1500, loss is 3.6506770133972166 and perplexity is 38.50072273276749
At time: 547.9823038578033 and batch: 1550, loss is 3.6577044200897215 and perplexity is 38.77223586860375
At time: 549.0258529186249 and batch: 1600, loss is 3.7385436630249025 and perplexity is 42.03672592685798
At time: 550.0692329406738 and batch: 1650, loss is 3.6839549589157103 and perplexity is 39.80350440996114
At time: 551.117015838623 and batch: 1700, loss is 3.700831069946289 and perplexity is 40.480932871016314
At time: 552.1592977046967 and batch: 1750, loss is 3.7120899772644043 and perplexity is 40.939279340802706
At time: 553.2082600593567 and batch: 1800, loss is 3.6473003435134888 and perplexity is 38.37093774565892
At time: 554.2489099502563 and batch: 1850, loss is 3.6706521034240724 and perplexity is 39.277510510049915
At time: 555.2919726371765 and batch: 1900, loss is 3.762667245864868 and perplexity is 43.063132898131656
At time: 556.3442404270172 and batch: 1950, loss is 3.7044293212890627 and perplexity is 40.62685581835308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47838617369186 and perplexity of 88.09239207856284
finished 13 epochs...
Completing Train Step...
At time: 559.665833234787 and batch: 50, loss is 3.8963018703460692 and perplexity is 49.22008984544111
At time: 560.7042169570923 and batch: 100, loss is 3.8779388761520384 and perplexity is 48.32450955484939
At time: 561.7477905750275 and batch: 150, loss is 3.8573889446258547 and perplexity is 47.34157836747606
At time: 562.7946701049805 and batch: 200, loss is 3.843219394683838 and perplexity is 46.675499670500756
At time: 563.8367555141449 and batch: 250, loss is 3.832949414253235 and perplexity is 46.19859628817321
At time: 564.8763043880463 and batch: 300, loss is 3.848798155784607 and perplexity is 46.93661881586223
At time: 565.9138441085815 and batch: 350, loss is 3.8469630670547486 and perplexity is 46.85056493805548
At time: 566.9535903930664 and batch: 400, loss is 3.818744111061096 and perplexity is 45.546970449778925
At time: 567.9914515018463 and batch: 450, loss is 3.868453288078308 and perplexity is 47.86829033786989
At time: 569.031286239624 and batch: 500, loss is 3.882352647781372 and perplexity is 48.53827431149725
At time: 570.0709750652313 and batch: 550, loss is 3.8498361110687256 and perplexity is 46.98536221974148
At time: 571.108564376831 and batch: 600, loss is 3.810355710983276 and perplexity is 45.1665022301113
At time: 572.1480975151062 and batch: 650, loss is 3.85538272857666 and perplexity is 47.24669614210699
At time: 573.188116312027 and batch: 700, loss is 3.8743219900131227 and perplexity is 48.150041012694246
At time: 574.2279510498047 and batch: 750, loss is 3.8320545148849487 and perplexity is 46.157271686976856
At time: 575.2659327983856 and batch: 800, loss is 3.7954984378814696 and perplexity is 44.50041156946598
At time: 576.3030738830566 and batch: 850, loss is 3.8054410076141356 and perplexity is 44.945066859727135
At time: 577.3424551486969 and batch: 900, loss is 3.7739156913757324 and perplexity is 43.55026078154374
At time: 578.3825993537903 and batch: 950, loss is 3.8819387006759642 and perplexity is 48.51818619134095
At time: 579.4222605228424 and batch: 1000, loss is 3.8330276727676393 and perplexity is 46.202211863159214
At time: 580.4637212753296 and batch: 1050, loss is 3.796775527000427 and perplexity is 44.55727886544393
At time: 581.5042276382446 and batch: 1100, loss is 3.820216403007507 and perplexity is 45.614078276589886
At time: 582.5415794849396 and batch: 1150, loss is 3.7853612661361695 and perplexity is 44.051582029270996
At time: 583.5802617073059 and batch: 1200, loss is 3.8335804653167727 and perplexity is 46.22775916215835
At time: 584.6186430454254 and batch: 1250, loss is 3.8267694330215454 and perplexity is 45.91397022791042
At time: 585.657655954361 and batch: 1300, loss is 3.824232692718506 and perplexity is 45.79764601370128
At time: 586.6957037448883 and batch: 1350, loss is 3.705820093154907 and perplexity is 40.68339781581877
At time: 587.7345411777496 and batch: 1400, loss is 3.7261184644699097 and perplexity is 41.51764279433681
At time: 588.7771747112274 and batch: 1450, loss is 3.645253210067749 and perplexity is 38.292467662425395
At time: 589.8193080425262 and batch: 1500, loss is 3.652093744277954 and perplexity is 38.555306551754974
At time: 590.8587851524353 and batch: 1550, loss is 3.6602880239486693 and perplexity is 38.87253748083728
At time: 591.8972599506378 and batch: 1600, loss is 3.7424253845214843 and perplexity is 42.200217899398226
At time: 592.9363536834717 and batch: 1650, loss is 3.6882535648345947 and perplexity is 39.974972261939826
At time: 593.9753754138947 and batch: 1700, loss is 3.7059176540374756 and perplexity is 40.68736711763672
At time: 595.0134477615356 and batch: 1750, loss is 3.7177555561065674 and perplexity is 41.171882348800594
At time: 596.0520849227905 and batch: 1800, loss is 3.6534657669067383 and perplexity is 38.608241610549
At time: 597.0895836353302 and batch: 1850, loss is 3.67697181224823 and perplexity is 39.52651894144587
At time: 598.1283283233643 and batch: 1900, loss is 3.768874158859253 and perplexity is 43.33125325636911
At time: 599.169440984726 and batch: 1950, loss is 3.709883699417114 and perplexity is 40.849055481758086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4779847610828485 and perplexity of 88.05703777793023
finished 14 epochs...
Completing Train Step...
At time: 602.4765346050262 and batch: 50, loss is 3.8927231788635255 and perplexity is 49.04426113514877
At time: 603.5410959720612 and batch: 100, loss is 3.87229305267334 and perplexity is 48.05244663648818
At time: 604.5797982215881 and batch: 150, loss is 3.8507948780059813 and perplexity is 47.03043183374819
At time: 605.6181514263153 and batch: 200, loss is 3.835966901779175 and perplexity is 46.338210512343686
At time: 606.6570174694061 and batch: 250, loss is 3.8250920486450197 and perplexity is 45.83701940768018
At time: 607.7014436721802 and batch: 300, loss is 3.8407947206497193 and perplexity is 46.562463891258126
At time: 608.7477335929871 and batch: 350, loss is 3.839116039276123 and perplexity is 46.48436591956015
At time: 609.7895171642303 and batch: 400, loss is 3.8108388328552247 and perplexity is 45.18832842715013
At time: 610.8273146152496 and batch: 450, loss is 3.860574369430542 and perplexity is 47.4926218466044
At time: 611.8663463592529 and batch: 500, loss is 3.8745690202713012 and perplexity is 48.16193699903071
At time: 612.9324698448181 and batch: 550, loss is 3.8421083736419677 and perplexity is 46.62367100492733
At time: 613.9705426692963 and batch: 600, loss is 3.8026725912094115 and perplexity is 44.8208122728981
At time: 615.0104825496674 and batch: 650, loss is 3.847877206802368 and perplexity is 46.893412483001946
At time: 616.0496451854706 and batch: 700, loss is 3.8674846696853638 and perplexity is 47.82194667969306
At time: 617.0921165943146 and batch: 750, loss is 3.8256332588195803 and perplexity is 45.86183358319159
At time: 618.1295924186707 and batch: 800, loss is 3.7889724159240723 and perplexity is 44.210946461609474
At time: 619.1758189201355 and batch: 850, loss is 3.7992515420913695 and perplexity is 44.66774005567985
At time: 620.2157485485077 and batch: 900, loss is 3.768289713859558 and perplexity is 43.305935921088555
At time: 621.2582564353943 and batch: 950, loss is 3.8764768552780153 and perplexity is 48.253909734934105
At time: 622.3057808876038 and batch: 1000, loss is 3.827841305732727 and perplexity is 45.96321054462121
At time: 623.3464760780334 and batch: 1050, loss is 3.7919735288619996 and perplexity is 44.343827801252274
At time: 624.3853313922882 and batch: 1100, loss is 3.816103377342224 and perplexity is 45.42685169974023
At time: 625.4240210056305 and batch: 1150, loss is 3.781733889579773 and perplexity is 43.89207981553353
At time: 626.4649345874786 and batch: 1200, loss is 3.830097546577454 and perplexity is 46.06703169632542
At time: 627.512068271637 and batch: 1250, loss is 3.823896803855896 and perplexity is 45.78226567765792
At time: 628.5583031177521 and batch: 1300, loss is 3.8219225120544436 and perplexity is 45.69196729288959
At time: 629.6038451194763 and batch: 1350, loss is 3.7038650131225586 and perplexity is 40.60393621930208
At time: 630.644109249115 and batch: 1400, loss is 3.72491304397583 and perplexity is 41.467626728098544
At time: 631.6813676357269 and batch: 1450, loss is 3.6447102403640748 and perplexity is 38.27168165620227
At time: 632.7199268341064 and batch: 1500, loss is 3.6521496868133543 and perplexity is 38.557463493688445
At time: 633.762610912323 and batch: 1550, loss is 3.6607465600967406 and perplexity is 38.89036603164463
At time: 634.8056199550629 and batch: 1600, loss is 3.7433837985992433 and perplexity is 42.24068257017514
At time: 635.8453152179718 and batch: 1650, loss is 3.689444732666016 and perplexity is 40.022617534084375
At time: 636.8890783786774 and batch: 1700, loss is 3.707385802268982 and perplexity is 40.74714607516292
At time: 637.933767080307 and batch: 1750, loss is 3.719441909790039 and perplexity is 41.24137127924421
At time: 638.979531288147 and batch: 1800, loss is 3.6555148220062255 and perplexity is 38.68743313108986
At time: 640.0193405151367 and batch: 1850, loss is 3.6790680170059202 and perplexity is 39.6094615204489
At time: 641.0668971538544 and batch: 1900, loss is 3.7709293508529664 and perplexity is 43.42039887544259
At time: 642.1104733943939 and batch: 1950, loss is 3.7115715312957764 and perplexity is 40.91806003747636
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4781579305959305 and perplexity of 88.07228789267505
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 645.443056344986 and batch: 50, loss is 3.890706238746643 and perplexity is 48.94544148751851
At time: 646.4857919216156 and batch: 100, loss is 3.872194085121155 and perplexity is 48.04769123878698
At time: 647.5303661823273 and batch: 150, loss is 3.851825017929077 and perplexity is 47.078904721822596
At time: 648.5753059387207 and batch: 200, loss is 3.837000513076782 and perplexity is 46.386130971537824
At time: 649.61949467659 and batch: 250, loss is 3.827044038772583 and perplexity is 45.92658019949408
At time: 650.6640453338623 and batch: 300, loss is 3.841583881378174 and perplexity is 46.599223661957154
At time: 651.7098219394684 and batch: 350, loss is 3.840488996505737 and perplexity is 46.54823079765431
At time: 652.7586467266083 and batch: 400, loss is 3.8132449531555177 and perplexity is 45.297187893481535
At time: 653.8000862598419 and batch: 450, loss is 3.8638138341903687 and perplexity is 47.646721987654225
At time: 654.8448128700256 and batch: 500, loss is 3.877414722442627 and perplexity is 48.29918672101913
At time: 655.8895123004913 and batch: 550, loss is 3.845400819778442 and perplexity is 46.77742991295901
At time: 656.9385137557983 and batch: 600, loss is 3.8052443504333495 and perplexity is 44.9362289586351
At time: 657.9849770069122 and batch: 650, loss is 3.8501955318450927 and perplexity is 47.00225277033396
At time: 659.0282037258148 and batch: 700, loss is 3.8707131147384644 and perplexity is 47.976586695962645
At time: 660.0771970748901 and batch: 750, loss is 3.827738170623779 and perplexity is 45.9584703683376
At time: 661.1226572990417 and batch: 800, loss is 3.79167697429657 and perplexity is 44.33067938637678
At time: 662.1671135425568 and batch: 850, loss is 3.8019117164611815 and perplexity is 44.78672221941957
At time: 663.212982416153 and batch: 900, loss is 3.7669980716705322 and perplexity is 43.250036256172045
At time: 664.2620549201965 and batch: 950, loss is 3.8758057880401613 and perplexity is 48.22153897970407
At time: 665.3522713184357 and batch: 1000, loss is 3.826186957359314 and perplexity is 45.88723424498183
At time: 666.3944439888 and batch: 1050, loss is 3.7924541902542113 and perplexity is 44.365147290576466
At time: 667.438378572464 and batch: 1100, loss is 3.8136185884475706 and perplexity is 45.314115683722285
At time: 668.4829037189484 and batch: 1150, loss is 3.7797851276397707 and perplexity is 43.806627890694095
At time: 669.533139705658 and batch: 1200, loss is 3.827983536720276 and perplexity is 45.96974840237985
At time: 670.5831110477448 and batch: 1250, loss is 3.8211346530914305 and perplexity is 45.65598264419557
At time: 671.6371800899506 and batch: 1300, loss is 3.8185946559906006 and perplexity is 45.54016373276136
At time: 672.6880438327789 and batch: 1350, loss is 3.697978129386902 and perplexity is 40.365607761809386
At time: 673.7378580570221 and batch: 1400, loss is 3.7185474109649657 and perplexity is 41.20449741536312
At time: 674.7859547138214 and batch: 1450, loss is 3.6360614776611326 and perplexity is 37.94210622753392
At time: 675.8347680568695 and batch: 1500, loss is 3.6414915037155153 and perplexity is 38.14869323171079
At time: 676.8880186080933 and batch: 1550, loss is 3.649887890815735 and perplexity is 38.47035292738129
At time: 677.9346587657928 and batch: 1600, loss is 3.7307688331604005 and perplexity is 41.71116476599195
At time: 678.9888803958893 and batch: 1650, loss is 3.6772715759277346 and perplexity is 39.53836933227141
At time: 680.0353639125824 and batch: 1700, loss is 3.694695792198181 and perplexity is 40.23333143282357
At time: 681.0848293304443 and batch: 1750, loss is 3.7062102222442626 and perplexity is 40.69927268918415
At time: 682.138069152832 and batch: 1800, loss is 3.6433583879470826 and perplexity is 38.2199789459438
At time: 683.1833853721619 and batch: 1850, loss is 3.6671507215499877 and perplexity is 39.140225430690926
At time: 684.2290437221527 and batch: 1900, loss is 3.7589512205123903 and perplexity is 42.90340616262781
At time: 685.2756838798523 and batch: 1950, loss is 3.7018373107910154 and perplexity is 40.52168693986939
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477663971656977 and perplexity of 88.02879454164547
finished 16 epochs...
Completing Train Step...
At time: 688.5609638690948 and batch: 50, loss is 3.889889426231384 and perplexity is 48.9054785616775
At time: 689.6339802742004 and batch: 100, loss is 3.8699008321762083 and perplexity is 47.93763197445532
At time: 690.6735365390778 and batch: 150, loss is 3.848512830734253 and perplexity is 46.92322853311754
At time: 691.7406554222107 and batch: 200, loss is 3.833794984817505 and perplexity is 46.237676981718614
At time: 692.7849631309509 and batch: 250, loss is 3.8232333612442018 and perplexity is 45.75190184519134
At time: 693.824464559555 and batch: 300, loss is 3.837953176498413 and perplexity is 46.43034239774593
At time: 694.8625731468201 and batch: 350, loss is 3.836642084121704 and perplexity is 46.36950781837126
At time: 695.9019045829773 and batch: 400, loss is 3.8092634105682373 and perplexity is 45.11719377570467
At time: 696.9428396224976 and batch: 450, loss is 3.8597286891937257 and perplexity is 47.45247525289724
At time: 697.9824078083038 and batch: 500, loss is 3.87326753616333 and perplexity is 48.099295775537925
At time: 699.0267832279205 and batch: 550, loss is 3.841341519355774 and perplexity is 46.58793114836166
At time: 700.0679709911346 and batch: 600, loss is 3.801207971572876 and perplexity is 44.755214880458425
At time: 701.1080522537231 and batch: 650, loss is 3.8462816095352172 and perplexity is 46.818649144148125
At time: 702.1466729640961 and batch: 700, loss is 3.8671253061294557 and perplexity is 47.804764302428815
At time: 703.1907758712769 and batch: 750, loss is 3.8244376373291016 and perplexity is 45.80703295629854
At time: 704.2312417030334 and batch: 800, loss is 3.7881922197341917 and perplexity is 44.17646670186671
At time: 705.2688245773315 and batch: 850, loss is 3.798321805000305 and perplexity is 44.62623010063862
At time: 706.317643404007 and batch: 900, loss is 3.7643461418151856 and perplexity is 43.13549214238686
At time: 707.3579547405243 and batch: 950, loss is 3.8730369901657102 and perplexity is 48.088207953584146
At time: 708.394778251648 and batch: 1000, loss is 3.8235950374603274 and perplexity is 45.768452212688
At time: 709.4335720539093 and batch: 1050, loss is 3.7898469257354734 and perplexity is 44.2496262785361
At time: 710.4803237915039 and batch: 1100, loss is 3.8116618490219114 and perplexity is 45.22553446047454
At time: 711.5197825431824 and batch: 1150, loss is 3.7780027341842652 and perplexity is 43.728616787726615
At time: 712.5592720508575 and batch: 1200, loss is 3.8263075447082517 and perplexity is 45.892767998553154
At time: 713.5990273952484 and batch: 1250, loss is 3.819790630340576 and perplexity is 45.5946611827597
At time: 714.6382694244385 and batch: 1300, loss is 3.817442774772644 and perplexity is 45.48773707393351
At time: 715.6838307380676 and batch: 1350, loss is 3.6972571992874146 and perplexity is 40.33651746748413
At time: 716.72669672966 and batch: 1400, loss is 3.718230938911438 and perplexity is 41.19145940664303
At time: 717.7697389125824 and batch: 1450, loss is 3.6365767192840575 and perplexity is 37.96166061710889
At time: 718.8095848560333 and batch: 1500, loss is 3.6425358724594115 and perplexity is 38.18855534629258
At time: 719.8572573661804 and batch: 1550, loss is 3.6513403701782225 and perplexity is 38.526270921111035
At time: 720.8976390361786 and batch: 1600, loss is 3.7326247024536134 and perplexity is 41.788647112179774
At time: 721.9361839294434 and batch: 1650, loss is 3.6791517877578737 and perplexity is 39.612779773809294
At time: 722.975429058075 and batch: 1700, loss is 3.6967803239822388 and perplexity is 40.31728656414299
At time: 724.0145621299744 and batch: 1750, loss is 3.7084833145141602 and perplexity is 40.7918911165605
At time: 725.0583081245422 and batch: 1800, loss is 3.6457593631744385 and perplexity is 38.31185441981539
At time: 726.1011168956757 and batch: 1850, loss is 3.6696312618255615 and perplexity is 39.237434852364835
At time: 727.1418659687042 and batch: 1900, loss is 3.7610671806335447 and perplexity is 42.9942841723446
At time: 728.1825063228607 and batch: 1950, loss is 3.703694934844971 and perplexity is 40.59703095900065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477578238553779 and perplexity of 88.02124788342246
finished 17 epochs...
Completing Train Step...
At time: 731.5003201961517 and batch: 50, loss is 3.8890024042129516 and perplexity is 48.8621175592963
At time: 732.548020362854 and batch: 100, loss is 3.868218951225281 and perplexity is 47.85707434756358
At time: 733.5927891731262 and batch: 150, loss is 3.8463303327560423 and perplexity is 46.820930355102625
At time: 734.6342716217041 and batch: 200, loss is 3.8314740657806396 and perplexity is 46.13048751414537
At time: 735.6725597381592 and batch: 250, loss is 3.820614290237427 and perplexity is 45.632231146998876
At time: 736.7121708393097 and batch: 300, loss is 3.8354026222229005 and perplexity is 46.31207018339746
At time: 737.753785610199 and batch: 350, loss is 3.8340620517730715 and perplexity is 46.25002718643496
At time: 738.7989130020142 and batch: 400, loss is 3.8065891075134277 and perplexity is 44.9966979195984
At time: 739.8453464508057 and batch: 450, loss is 3.857001838684082 and perplexity is 47.32325570783113
At time: 740.8852066993713 and batch: 500, loss is 3.870551323890686 and perplexity is 47.968825151217985
At time: 741.9325129985809 and batch: 550, loss is 3.83864296913147 and perplexity is 46.46238075452309
At time: 742.9715855121613 and batch: 600, loss is 3.7985368824005126 and perplexity is 44.63582922643023
At time: 744.0102322101593 and batch: 650, loss is 3.8436831283569335 and perplexity is 46.69714969094029
At time: 745.0768156051636 and batch: 700, loss is 3.8647165155410765 and perplexity is 47.689751212932634
At time: 746.118314743042 and batch: 750, loss is 3.822197585105896 and perplexity is 45.704537650563765
At time: 747.1637532711029 and batch: 800, loss is 3.7858470058441163 and perplexity is 44.07298482953464
At time: 748.2055006027222 and batch: 850, loss is 3.7960015392303466 and perplexity is 44.52280541926783
At time: 749.2441000938416 and batch: 900, loss is 3.762516751289368 and perplexity is 43.056652617862184
At time: 750.2848434448242 and batch: 950, loss is 3.871148109436035 and perplexity is 47.99746079651531
At time: 751.3220827579498 and batch: 1000, loss is 3.821833124160767 and perplexity is 45.687883166713775
At time: 752.3621113300323 and batch: 1050, loss is 3.7881507062911988 and perplexity is 44.174632822700225
At time: 753.40394115448 and batch: 1100, loss is 3.810380082130432 and perplexity is 45.16760300299716
At time: 754.4516863822937 and batch: 1150, loss is 3.7768483686447145 and perplexity is 43.67816710370527
At time: 755.4896552562714 and batch: 1200, loss is 3.8252137994766233 and perplexity is 45.84260044265223
At time: 756.528436422348 and batch: 1250, loss is 3.8189408111572267 and perplexity is 45.55593042442991
At time: 757.5662853717804 and batch: 1300, loss is 3.816795449256897 and perplexity is 45.458301229386464
At time: 758.6070365905762 and batch: 1350, loss is 3.696880660057068 and perplexity is 40.32133204537505
At time: 759.6543951034546 and batch: 1400, loss is 3.718113536834717 and perplexity is 41.18662372763045
At time: 760.6953027248383 and batch: 1450, loss is 3.636903238296509 and perplexity is 37.974057844899754
At time: 761.7422935962677 and batch: 1500, loss is 3.6431894731521606 and perplexity is 38.21352357125772
At time: 762.7857625484467 and batch: 1550, loss is 3.6522576808929443 and perplexity is 38.56162769632034
At time: 763.8300693035126 and batch: 1600, loss is 3.7338268661499026 and perplexity is 41.83891411518433
At time: 764.8699493408203 and batch: 1650, loss is 3.680333962440491 and perplexity is 39.65963669023911
At time: 765.9109778404236 and batch: 1700, loss is 3.698100323677063 and perplexity is 40.37054050996745
At time: 766.951452255249 and batch: 1750, loss is 3.7099207782745363 and perplexity is 40.850570146142964
At time: 767.9924764633179 and batch: 1800, loss is 3.6472707843780516 and perplexity is 38.369803550676245
At time: 769.0336871147156 and batch: 1850, loss is 3.6711446189880372 and perplexity is 39.296860059875996
At time: 770.0724382400513 and batch: 1900, loss is 3.7623472356796266 and perplexity is 43.04935446173342
At time: 771.1121633052826 and batch: 1950, loss is 3.7047970151901244 and perplexity is 40.64179681214462
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4775904455850295 and perplexity of 88.02232236810423
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 774.4113035202026 and batch: 50, loss is 3.888561511039734 and perplexity is 48.840579333612666
At time: 775.478946685791 and batch: 100, loss is 3.868034896850586 and perplexity is 47.84826685422352
At time: 776.5198066234589 and batch: 150, loss is 3.846170520782471 and perplexity is 46.81344840768644
At time: 777.5679907798767 and batch: 200, loss is 3.83136559009552 and perplexity is 46.12548374930569
At time: 778.6093509197235 and batch: 250, loss is 3.8205351209640503 and perplexity is 45.628618619418894
At time: 779.6519610881805 and batch: 300, loss is 3.8350022077560424 and perplexity is 46.29352987265791
At time: 780.6922948360443 and batch: 350, loss is 3.833808174133301 and perplexity is 46.23828682906372
At time: 781.7379224300385 and batch: 400, loss is 3.8065524911880493 and perplexity is 44.99505033603083
At time: 782.779114484787 and batch: 450, loss is 3.857285327911377 and perplexity is 47.33667324279827
At time: 783.8211376667023 and batch: 500, loss is 3.8706133794784545 and perplexity is 47.97180197722069
At time: 784.8614974021912 and batch: 550, loss is 3.8389038372039797 and perplexity is 46.474502887304695
At time: 785.8990020751953 and batch: 600, loss is 3.7981004905700684 and perplexity is 44.61635476476776
At time: 786.9395751953125 and batch: 650, loss is 3.843309984207153 and perplexity is 46.67972817329254
At time: 787.97780418396 and batch: 700, loss is 3.8647619104385376 and perplexity is 47.691916133436685
At time: 789.0246067047119 and batch: 750, loss is 3.8220848083496093 and perplexity is 45.699383531697826
At time: 790.0663771629333 and batch: 800, loss is 3.785595722198486 and perplexity is 44.061911400576946
At time: 791.1076090335846 and batch: 850, loss is 3.795558524131775 and perplexity is 44.50308551266705
At time: 792.1466264724731 and batch: 900, loss is 3.761429772377014 and perplexity is 43.00987637143236
At time: 793.1863477230072 and batch: 950, loss is 3.8701462745666504 and perplexity is 47.94939934548603
At time: 794.2264387607574 and batch: 1000, loss is 3.8204583644866945 and perplexity is 45.625116461795415
At time: 795.2666993141174 and batch: 1050, loss is 3.7872156858444215 and perplexity is 44.133347941893796
At time: 796.3066165447235 and batch: 1100, loss is 3.8091973161697386 and perplexity is 45.11421188046449
At time: 797.3751463890076 and batch: 1150, loss is 3.775584487915039 and perplexity is 43.62299798093482
At time: 798.4160907268524 and batch: 1200, loss is 3.8241129779815672 and perplexity is 45.79216368872043
At time: 799.4546744823456 and batch: 1250, loss is 3.817361092567444 and perplexity is 45.48402168700231
At time: 800.4947786331177 and batch: 1300, loss is 3.8151375675201415 and perplexity is 45.38299918018814
At time: 801.540613412857 and batch: 1350, loss is 3.6945439624786376 and perplexity is 40.22722328110704
At time: 802.5803325176239 and batch: 1400, loss is 3.715507755279541 and perplexity is 41.079440092419766
At time: 803.6196575164795 and batch: 1450, loss is 3.6334455823898315 and perplexity is 37.84298335532051
At time: 804.6571872234344 and batch: 1500, loss is 3.6394809436798097 and perplexity is 38.072070047252446
At time: 805.6960139274597 and batch: 1550, loss is 3.6486619758605956 and perplexity is 38.42322044250999
At time: 806.7333190441132 and batch: 1600, loss is 3.7300041723251343 and perplexity is 41.67928206318264
At time: 807.7701013088226 and batch: 1650, loss is 3.676520504951477 and perplexity is 39.50868435977348
At time: 808.8143849372864 and batch: 1700, loss is 3.69420063495636 and perplexity is 40.2134145388061
At time: 809.8553123474121 and batch: 1750, loss is 3.7059339237213136 and perplexity is 40.688029093620976
At time: 810.894385099411 and batch: 1800, loss is 3.64360285282135 and perplexity is 38.22932353045613
At time: 811.9327874183655 and batch: 1850, loss is 3.667590413093567 and perplexity is 39.157438840844705
At time: 812.9698832035065 and batch: 1900, loss is 3.758734006881714 and perplexity is 42.8940879700627
At time: 814.007167339325 and batch: 1950, loss is 3.7018537855148317 and perplexity is 40.52235452896945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477508402979651 and perplexity of 88.01510108367621
finished 19 epochs...
Completing Train Step...
At time: 817.2891654968262 and batch: 50, loss is 3.8882387685775757 and perplexity is 48.82481894819491
At time: 818.3304612636566 and batch: 100, loss is 3.8675448226928713 and perplexity is 47.824823400131535
At time: 819.3712582588196 and batch: 150, loss is 3.845582914352417 and perplexity is 46.78594860471089
At time: 820.4124312400818 and batch: 200, loss is 3.8306699848175048 and perplexity is 46.0934097760645
At time: 821.4566576480865 and batch: 250, loss is 3.819860134124756 and perplexity is 45.59783029438166
At time: 822.4963135719299 and batch: 300, loss is 3.8343006992340087 and perplexity is 46.26106595512596
At time: 823.5377821922302 and batch: 350, loss is 3.8330236721038817 and perplexity is 46.20202702401443
At time: 824.6065378189087 and batch: 400, loss is 3.805740008354187 and perplexity is 44.958507477257
At time: 825.6471173763275 and batch: 450, loss is 3.856402416229248 and perplexity is 47.29489758582067
At time: 826.691980600357 and batch: 500, loss is 3.8697847509384156 and perplexity is 47.932067637762664
At time: 827.7331147193909 and batch: 550, loss is 3.8380517625808714 and perplexity is 46.4349200089508
At time: 828.7763726711273 and batch: 600, loss is 3.797396945953369 and perplexity is 44.58497620795792
At time: 829.8214225769043 and batch: 650, loss is 3.8426138162612915 and perplexity is 46.64724255185295
At time: 830.8675134181976 and batch: 700, loss is 3.864079656600952 and perplexity is 47.659389237694256
At time: 831.9119806289673 and batch: 750, loss is 3.8214620113372804 and perplexity is 45.67093095317913
At time: 832.9548835754395 and batch: 800, loss is 3.7850107097625734 and perplexity is 44.0361421728518
At time: 833.9991180896759 and batch: 850, loss is 3.795009980201721 and perplexity is 44.47868030951538
At time: 835.0418090820312 and batch: 900, loss is 3.7609711933135985 and perplexity is 42.990157464292885
At time: 836.0952322483063 and batch: 950, loss is 3.869663677215576 and perplexity is 47.9262646751906
At time: 837.14169049263 and batch: 1000, loss is 3.820011830329895 and perplexity is 45.604747836869095
At time: 838.1852674484253 and batch: 1050, loss is 3.7867979431152343 and perplexity is 44.114915406973154
At time: 839.2296059131622 and batch: 1100, loss is 3.808849868774414 and perplexity is 45.09853978782605
At time: 840.2743163108826 and batch: 1150, loss is 3.775297274589539 and perplexity is 43.61047067370733
At time: 841.3168649673462 and batch: 1200, loss is 3.823851819038391 and perplexity is 45.78020621711403
At time: 842.3584413528442 and batch: 1250, loss is 3.8172320461273195 and perplexity is 45.478152514627105
At time: 843.4035594463348 and batch: 1300, loss is 3.8150446033477783 and perplexity is 45.37878038333152
At time: 844.4476404190063 and batch: 1350, loss is 3.6945727348327635 and perplexity is 40.22838072967196
At time: 845.4902634620667 and batch: 1400, loss is 3.7156173467636107 and perplexity is 41.08394229592133
At time: 846.5385546684265 and batch: 1450, loss is 3.6337845849990846 and perplexity is 37.85581440017585
At time: 847.5824394226074 and batch: 1500, loss is 3.6398550176620486 and perplexity is 38.086314482177244
At time: 848.6254324913025 and batch: 1550, loss is 3.649125723838806 and perplexity is 38.44104326563621
At time: 849.6699390411377 and batch: 1600, loss is 3.730483093261719 and perplexity is 41.69924792463742
At time: 850.7152864933014 and batch: 1650, loss is 3.677053298950195 and perplexity is 39.52973995834781
At time: 851.759299993515 and batch: 1700, loss is 3.694814095497131 and perplexity is 40.23809145021715
At time: 852.802975654602 and batch: 1750, loss is 3.7065185356140136 and perplexity is 40.71182275367028
At time: 853.847761631012 and batch: 1800, loss is 3.644205641746521 and perplexity is 38.25237469009096
At time: 854.8930866718292 and batch: 1850, loss is 3.6681696224212645 and perplexity is 39.18012576427465
At time: 855.9364247322083 and batch: 1900, loss is 3.7592091798782348 and perplexity is 42.914474925658254
At time: 856.9802324771881 and batch: 1950, loss is 3.702254695892334 and perplexity is 40.53860361841759
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477489382721657 and perplexity of 88.0134270296668
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea7e1b2b38>
ELAPSED
3541.837370157242


RESULTS SO FAR:
[{'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.92103091601648}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.6813262795645527, 'dropout': 0.19794812537896078, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.05052225478255}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.8407924036871192, 'dropout': 0.37893501344260494, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.32399121066462}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.320185930278277, 'dropout': 0.14646798116639437, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.0134270296668}]
SETTINGS FOR THIS RUN
{'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.21124919513989482, 'dropout': 0.14686417520406692, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4971339702606201 and batch: 50, loss is 7.141192417144776 and perplexity is 1262.9334350793558
At time: 2.528632402420044 and batch: 100, loss is 6.330129671096802 and perplexity is 561.2293643620069
At time: 3.5622241497039795 and batch: 150, loss is 6.024391736984253 and perplexity is 413.39011561527377
At time: 4.59478235244751 and batch: 200, loss is 5.910917167663574 and perplexity is 369.0444758970486
At time: 5.6285247802734375 and batch: 250, loss is 5.812986183166504 and perplexity is 334.6168624626559
At time: 6.6604955196380615 and batch: 300, loss is 5.7318884372711185 and perplexity is 308.5513985072917
At time: 7.693579435348511 and batch: 350, loss is 5.690059843063355 and perplexity is 295.9113283510068
At time: 8.726565599441528 and batch: 400, loss is 5.6197536277771 and perplexity is 275.821420126615
At time: 9.76443886756897 and batch: 450, loss is 5.551866645812988 and perplexity is 257.7181757464016
At time: 10.799713850021362 and batch: 500, loss is 5.517687387466431 and perplexity is 249.05839510572494
At time: 11.877284526824951 and batch: 550, loss is 5.461511640548706 and perplexity is 235.4530759057267
At time: 12.915780067443848 and batch: 600, loss is 5.475465202331543 and perplexity is 238.76151351186115
At time: 13.951218843460083 and batch: 650, loss is 5.544513483047485 and perplexity is 255.83008228903378
At time: 14.988214254379272 and batch: 700, loss is 5.465647268295288 and perplexity is 236.42883848411793
At time: 16.023622274398804 and batch: 750, loss is 5.417718086242676 and perplexity is 225.36427346885662
At time: 17.064725637435913 and batch: 800, loss is 5.39551570892334 and perplexity is 220.41578817992547
At time: 18.104288339614868 and batch: 850, loss is 5.3980193519592286 and perplexity is 220.96832201813274
At time: 19.144118547439575 and batch: 900, loss is 5.414192008972168 and perplexity is 224.57102098326325
At time: 20.183287858963013 and batch: 950, loss is 5.455275382995605 and perplexity is 233.9892988719653
At time: 21.22104525566101 and batch: 1000, loss is 5.4151261520385745 and perplexity is 224.78090045889698
At time: 22.25984239578247 and batch: 1050, loss is 5.3123388671875 and perplexity is 202.8240525876475
At time: 23.29970383644104 and batch: 1100, loss is 5.405864267349243 and perplexity is 222.70861711694505
At time: 24.339436292648315 and batch: 1150, loss is 5.302697343826294 and perplexity is 200.8779166796957
At time: 25.379292488098145 and batch: 1200, loss is 5.380583839416504 and perplexity is 217.1490185788242
At time: 26.41891598701477 and batch: 1250, loss is 5.319082593917846 and perplexity is 204.19646495844188
At time: 27.458640336990356 and batch: 1300, loss is 5.347354173660278 and perplexity is 210.05180140595303
At time: 28.497780561447144 and batch: 1350, loss is 5.290651321411133 and perplexity is 198.47265280882542
At time: 29.536587953567505 and batch: 1400, loss is 5.299486837387085 and perplexity is 200.23403098734428
At time: 30.575593948364258 and batch: 1450, loss is 5.2521326541900635 and perplexity is 190.97311408585713
At time: 31.615479946136475 and batch: 1500, loss is 5.2232682991027835 and perplexity is 185.53959308852686
At time: 32.66294050216675 and batch: 1550, loss is 5.2127499294281 and perplexity is 183.5982468563482
At time: 33.70403003692627 and batch: 1600, loss is 5.2595072364807125 and perplexity is 192.38666680514027
At time: 34.74421811103821 and batch: 1650, loss is 5.228551473617554 and perplexity is 186.52242508863998
At time: 35.784303188323975 and batch: 1700, loss is 5.260415945053101 and perplexity is 192.56156967431207
At time: 36.82324981689453 and batch: 1750, loss is 5.275330858230591 and perplexity is 195.4551337554848
At time: 37.86429452896118 and batch: 1800, loss is 5.232461652755737 and perplexity is 187.25318896176648
At time: 38.911892890930176 and batch: 1850, loss is 5.2209765625 and perplexity is 185.11487207201827
At time: 39.95060467720032 and batch: 1900, loss is 5.262736654281616 and perplexity is 193.00896802605868
At time: 41.00096654891968 and batch: 1950, loss is 5.183206062316895 and perplexity is 178.25338732094335
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.879262241097384 and perplexity of 131.53358800539175
finished 1 epochs...
Completing Train Step...
At time: 44.281781911849976 and batch: 50, loss is 5.082945337295532 and perplexity is 161.2482877952591
At time: 45.34485697746277 and batch: 100, loss is 5.019411220550537 and perplexity is 151.32218216902763
At time: 46.383769035339355 and batch: 150, loss is 4.9582306671142575 and perplexity is 142.34172307073655
At time: 47.4479660987854 and batch: 200, loss is 4.931279726028443 and perplexity is 138.55671356403113
At time: 48.48400044441223 and batch: 250, loss is 4.935052194595337 and perplexity is 139.08040158791525
At time: 49.51728534698486 and batch: 300, loss is 4.960733165740967 and perplexity is 142.69837911674736
At time: 50.5496883392334 and batch: 350, loss is 4.960270385742188 and perplexity is 142.63235643919958
At time: 51.58263278007507 and batch: 400, loss is 4.927478685379028 and perplexity is 138.0310535240055
At time: 52.6167049407959 and batch: 450, loss is 4.911742115020752 and perplexity is 135.8759198197115
At time: 53.6512975692749 and batch: 500, loss is 4.902065172195434 and perplexity is 134.56739776997827
At time: 54.68431067466736 and batch: 550, loss is 4.860651044845581 and perplexity is 129.10822999911036
At time: 55.72184228897095 and batch: 600, loss is 4.842314586639405 and perplexity is 126.76241503128824
At time: 56.75360608100891 and batch: 650, loss is 4.911488847732544 and perplexity is 135.84151125143225
At time: 57.79194188117981 and batch: 700, loss is 4.905425872802734 and perplexity is 135.02039928025047
At time: 58.82854890823364 and batch: 750, loss is 4.861496315002442 and perplexity is 129.21740746866163
At time: 59.86172938346863 and batch: 800, loss is 4.837485847473144 and perplexity is 126.15178785917274
At time: 60.89628982543945 and batch: 850, loss is 4.842096977233886 and perplexity is 126.73483333863794
At time: 61.930381774902344 and batch: 900, loss is 4.854338731765747 and perplexity is 128.29582520441923
At time: 62.96351075172424 and batch: 950, loss is 4.921548004150391 and perplexity is 137.2148580358661
At time: 63.99546194076538 and batch: 1000, loss is 4.890928688049317 and perplexity is 133.07710379803964
At time: 65.02916955947876 and batch: 1050, loss is 4.808433141708374 and perplexity is 122.53946504187515
At time: 66.06262755393982 and batch: 1100, loss is 4.893378582000732 and perplexity is 133.40352827912113
At time: 67.0981433391571 and batch: 1150, loss is 4.812808780670166 and perplexity is 123.07682829589254
At time: 68.13333058357239 and batch: 1200, loss is 4.885933170318603 and perplexity is 132.41397248762118
At time: 69.16805219650269 and batch: 1250, loss is 4.840605697631836 and perplexity is 126.54597712052366
At time: 70.20517659187317 and batch: 1300, loss is 4.863677015304566 and perplexity is 129.4994993753317
At time: 71.2407238483429 and batch: 1350, loss is 4.770459175109863 and perplexity is 117.97339997460739
At time: 72.27468943595886 and batch: 1400, loss is 4.782920560836792 and perplexity is 119.45271000065193
At time: 73.3098304271698 and batch: 1450, loss is 4.725686616897583 and perplexity is 112.80792761819752
At time: 74.34791111946106 and batch: 1500, loss is 4.714897260665894 and perplexity is 111.5973451477837
At time: 75.38346195220947 and batch: 1550, loss is 4.72092984199524 and perplexity is 112.27259992538521
At time: 76.42085480690002 and batch: 1600, loss is 4.797030839920044 and perplexity is 121.15016872057474
At time: 77.45702791213989 and batch: 1650, loss is 4.7587028503417965 and perplexity is 116.59458713684536
At time: 78.49039721488953 and batch: 1700, loss is 4.785901393890381 and perplexity is 119.80930980516146
At time: 79.52640700340271 and batch: 1750, loss is 4.793312253952027 and perplexity is 120.7004979909462
At time: 80.56550574302673 and batch: 1800, loss is 4.745201120376587 and perplexity is 115.03093824241722
At time: 81.60241675376892 and batch: 1850, loss is 4.770250453948974 and perplexity is 117.94877899915934
At time: 82.63896894454956 and batch: 1900, loss is 4.835788898468017 and perplexity is 125.93789624118183
At time: 83.67760562896729 and batch: 1950, loss is 4.769479713439941 and perplexity is 117.85790612139627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6995148414789245 and perplexity of 109.8938435820641
finished 2 epochs...
Completing Train Step...
At time: 87.01960134506226 and batch: 50, loss is 4.70980583190918 and perplexity is 111.03059921309585
At time: 88.06129384040833 and batch: 100, loss is 4.660150194168091 and perplexity is 105.65194927168368
At time: 89.10413002967834 and batch: 150, loss is 4.6087746334075925 and perplexity is 100.36109512519941
At time: 90.15499424934387 and batch: 200, loss is 4.59633547782898 and perplexity is 99.12042032005334
At time: 91.19622373580933 and batch: 250, loss is 4.60398775100708 and perplexity is 99.88182638197745
At time: 92.2434892654419 and batch: 300, loss is 4.636743192672729 and perplexity is 103.20767213449582
At time: 93.28540372848511 and batch: 350, loss is 4.6471666431427 and perplexity is 104.28907839434109
At time: 94.32631039619446 and batch: 400, loss is 4.607878637313843 and perplexity is 100.27121224936886
At time: 95.36826753616333 and batch: 450, loss is 4.616853713989258 and perplexity is 101.17520470023204
At time: 96.41074132919312 and batch: 500, loss is 4.621187477111817 and perplexity is 101.61462555648184
At time: 97.45218324661255 and batch: 550, loss is 4.586807041168213 and perplexity is 98.18044304201058
At time: 98.49510931968689 and batch: 600, loss is 4.5605673122406 and perplexity is 95.63772089252762
At time: 99.58319997787476 and batch: 650, loss is 4.623422546386719 and perplexity is 101.84199528283575
At time: 100.62506127357483 and batch: 700, loss is 4.638325233459472 and perplexity is 103.37108010627333
At time: 101.66750597953796 and batch: 750, loss is 4.589676465988159 and perplexity is 98.46256901817179
At time: 102.70805740356445 and batch: 800, loss is 4.56608229637146 and perplexity is 96.16661849596981
At time: 103.7511932849884 and batch: 850, loss is 4.573540096282959 and perplexity is 96.88649089048606
At time: 104.79225373268127 and batch: 900, loss is 4.575703344345093 and perplexity is 97.09630726476226
At time: 105.84015893936157 and batch: 950, loss is 4.653154935836792 and perplexity is 104.91546554352385
At time: 106.88765454292297 and batch: 1000, loss is 4.623199663162231 and perplexity is 101.81929893994989
At time: 107.92978286743164 and batch: 1050, loss is 4.553255634307861 and perplexity is 94.94099888652914
At time: 108.97365546226501 and batch: 1100, loss is 4.62780839920044 and perplexity is 102.28964021924028
At time: 110.01544785499573 and batch: 1150, loss is 4.559942636489868 and perplexity is 95.5779969834118
At time: 111.05984354019165 and batch: 1200, loss is 4.62721661567688 and perplexity is 102.22912480330679
At time: 112.10825514793396 and batch: 1250, loss is 4.602976121902466 and perplexity is 99.7808341113605
At time: 113.14819145202637 and batch: 1300, loss is 4.611062240600586 and perplexity is 100.59094469082798
At time: 114.19034337997437 and batch: 1350, loss is 4.508526506423951 and perplexity is 90.78794445053735
At time: 115.23258447647095 and batch: 1400, loss is 4.528555459976197 and perplexity is 92.62466436094807
At time: 116.27691864967346 and batch: 1450, loss is 4.4652085113525395 and perplexity is 86.93915545084928
At time: 117.31912159919739 and batch: 1500, loss is 4.4601762580871585 and perplexity is 86.50275456277471
At time: 118.36500334739685 and batch: 1550, loss is 4.472820501327515 and perplexity is 87.6034605648924
At time: 119.40741658210754 and batch: 1600, loss is 4.560830564498901 and perplexity is 95.66290105275293
At time: 120.44921731948853 and batch: 1650, loss is 4.512926235198974 and perplexity is 91.18826679124894
At time: 121.49127340316772 and batch: 1700, loss is 4.545869169235229 and perplexity is 94.24230413321035
At time: 122.53829789161682 and batch: 1750, loss is 4.551143465042114 and perplexity is 94.74067905578976
At time: 123.5809338092804 and batch: 1800, loss is 4.501947708129883 and perplexity is 90.19262925289864
At time: 124.62792992591858 and batch: 1850, loss is 4.541599531173706 and perplexity is 93.84078139283835
At time: 125.67473864555359 and batch: 1900, loss is 4.610232124328613 and perplexity is 100.50747715949804
At time: 126.71767973899841 and batch: 1950, loss is 4.553138036727905 and perplexity is 94.92983471127428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.635339639353198 and perplexity of 103.06291627371843
finished 3 epochs...
Completing Train Step...
At time: 130.01210069656372 and batch: 50, loss is 4.4980709266662595 and perplexity is 89.84364903675326
At time: 131.07704901695251 and batch: 100, loss is 4.4523400211334225 and perplexity is 85.8275474774048
At time: 132.11624598503113 and batch: 150, loss is 4.411245622634888 and perplexity is 82.37200406026311
At time: 133.15161108970642 and batch: 200, loss is 4.398906135559082 and perplexity is 81.36182116787803
At time: 134.1874372959137 and batch: 250, loss is 4.396106243133545 and perplexity is 81.13433543746149
At time: 135.22633385658264 and batch: 300, loss is 4.432335243225098 and perplexity is 84.12764621538332
At time: 136.26522064208984 and batch: 350, loss is 4.446796827316284 and perplexity is 85.35310492524772
At time: 137.30748891830444 and batch: 400, loss is 4.399859943389893 and perplexity is 81.43946173123948
At time: 138.3462905883789 and batch: 450, loss is 4.4194519901275635 and perplexity is 83.05076024884865
At time: 139.38546657562256 and batch: 500, loss is 4.433333749771118 and perplexity is 84.21169017306885
At time: 140.4234495162964 and batch: 550, loss is 4.3995341968536374 and perplexity is 81.41293742900038
At time: 141.4606454372406 and batch: 600, loss is 4.379734001159668 and perplexity is 79.81679940501927
At time: 142.4979727268219 and batch: 650, loss is 4.436980295181274 and perplexity is 84.51933250030832
At time: 143.5360975265503 and batch: 700, loss is 4.454981727600098 and perplexity is 86.05457840710221
At time: 144.57587933540344 and batch: 750, loss is 4.411668205261231 and perplexity is 82.40682039394679
At time: 145.61351704597473 and batch: 800, loss is 4.390653648376465 and perplexity is 80.69314669023463
At time: 146.65357089042664 and batch: 850, loss is 4.3944753074645995 and perplexity is 81.00211840386598
At time: 147.6911334991455 and batch: 900, loss is 4.400312509536743 and perplexity is 81.47632681595222
At time: 148.72723770141602 and batch: 950, loss is 4.473273544311524 and perplexity is 87.64315768964914
At time: 149.76520776748657 and batch: 1000, loss is 4.445319232940673 and perplexity is 85.22708078667733
At time: 150.80375266075134 and batch: 1050, loss is 4.381834144592285 and perplexity is 79.98460227547446
At time: 151.86874055862427 and batch: 1100, loss is 4.45249309539795 and perplexity is 85.84068647170636
At time: 152.90732955932617 and batch: 1150, loss is 4.388387928009033 and perplexity is 80.51052554661233
At time: 153.95165371894836 and batch: 1200, loss is 4.454077186584473 and perplexity is 85.9767737054276
At time: 154.98896837234497 and batch: 1250, loss is 4.429621849060059 and perplexity is 83.89968416633523
At time: 156.02783155441284 and batch: 1300, loss is 4.436203022003173 and perplexity is 84.45366341484042
At time: 157.06796789169312 and batch: 1350, loss is 4.330596709251404 and perplexity is 75.98961675069876
At time: 158.10859274864197 and batch: 1400, loss is 4.356232290267944 and perplexity is 77.96283901409635
At time: 159.14716339111328 and batch: 1450, loss is 4.288190035820008 and perplexity is 72.83452125122582
At time: 160.1866602897644 and batch: 1500, loss is 4.287917695045471 and perplexity is 72.81468814210001
At time: 161.22395062446594 and batch: 1550, loss is 4.3046432209014895 and perplexity is 74.04279381855564
At time: 162.26163125038147 and batch: 1600, loss is 4.393308868408203 and perplexity is 80.90768945282367
At time: 163.30000185966492 and batch: 1650, loss is 4.341482124328613 and perplexity is 76.82131374161523
At time: 164.33970046043396 and batch: 1700, loss is 4.379547233581543 and perplexity is 79.80189360670397
At time: 165.37995386123657 and batch: 1750, loss is 4.382016649246216 and perplexity is 79.99920116977509
At time: 166.42222809791565 and batch: 1800, loss is 4.332339496612549 and perplexity is 76.12216596334696
At time: 167.4655442237854 and batch: 1850, loss is 4.3724542999267575 and perplexity is 79.2378667370752
At time: 168.50392079353333 and batch: 1900, loss is 4.448237409591675 and perplexity is 85.4761517035769
At time: 169.54343581199646 and batch: 1950, loss is 4.390108699798584 and perplexity is 80.64918505420451
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.613173657794332 and perplexity of 100.80355852024334
finished 4 epochs...
Completing Train Step...
At time: 172.83083271980286 and batch: 50, loss is 4.340880575180054 and perplexity is 76.77511584228937
At time: 173.89441013336182 and batch: 100, loss is 4.29934850692749 and perplexity is 73.65179443184807
At time: 174.93520736694336 and batch: 150, loss is 4.267155561447144 and perplexity is 71.31848578208584
At time: 175.9705948829651 and batch: 200, loss is 4.250701990127563 and perplexity is 70.15464293171462
At time: 177.0084068775177 and batch: 250, loss is 4.246712226867675 and perplexity is 69.87530014118941
At time: 178.07776641845703 and batch: 300, loss is 4.276446018218994 and perplexity is 71.98415448648065
At time: 179.12412571907043 and batch: 350, loss is 4.293859739303588 and perplexity is 73.24864425806614
At time: 180.16402554512024 and batch: 400, loss is 4.245444312095642 and perplexity is 69.7867603582509
At time: 181.20111346244812 and batch: 450, loss is 4.276644124984741 and perplexity is 71.99841644715978
At time: 182.23996877670288 and batch: 500, loss is 4.294266967773438 and perplexity is 73.27847926580586
At time: 183.27846693992615 and batch: 550, loss is 4.260497636795044 and perplexity is 70.84522987673087
At time: 184.3160524368286 and batch: 600, loss is 4.240338530540466 and perplexity is 69.43135249397108
At time: 185.35637140274048 and batch: 650, loss is 4.293857431411743 and perplexity is 73.24847520831243
At time: 186.396324634552 and batch: 700, loss is 4.319509353637695 and perplexity is 75.15174631380903
At time: 187.44271874427795 and batch: 750, loss is 4.274325461387634 and perplexity is 71.83166972937197
At time: 188.48240637779236 and batch: 800, loss is 4.25380190372467 and perplexity is 70.372453686078
At time: 189.52025771141052 and batch: 850, loss is 4.25704794883728 and perplexity is 70.60125699745866
At time: 190.55997824668884 and batch: 900, loss is 4.262411079406738 and perplexity is 70.9809179326672
At time: 191.5987949371338 and batch: 950, loss is 4.339823160171509 and perplexity is 76.6939755895359
At time: 192.64154529571533 and batch: 1000, loss is 4.307092695236206 and perplexity is 74.22438204874662
At time: 193.68181133270264 and batch: 1050, loss is 4.2524716186523435 and perplexity is 70.27890050143532
At time: 194.72258973121643 and batch: 1100, loss is 4.316791572570801 and perplexity is 74.94777761721264
At time: 195.76348900794983 and batch: 1150, loss is 4.253023729324341 and perplexity is 70.31771294581488
At time: 196.80523204803467 and batch: 1200, loss is 4.317560811042785 and perplexity is 75.00545251117519
At time: 197.84456419944763 and batch: 1250, loss is 4.297445521354676 and perplexity is 73.51176940469229
At time: 198.88354206085205 and batch: 1300, loss is 4.30500545501709 and perplexity is 74.06961950278678
At time: 199.92458987236023 and batch: 1350, loss is 4.195357937812805 and perplexity is 66.37748633795698
At time: 200.96336245536804 and batch: 1400, loss is 4.221808786392212 and perplexity is 68.15665369000381
At time: 202.0027346611023 and batch: 1450, loss is 4.152752571105957 and perplexity is 63.608847423655796
At time: 203.04313611984253 and batch: 1500, loss is 4.158868269920349 and perplexity is 63.99905194690533
At time: 204.0822410583496 and batch: 1550, loss is 4.173513617515564 and perplexity is 64.94323739429845
At time: 205.11966490745544 and batch: 1600, loss is 4.264116172790527 and perplexity is 71.1020502678333
At time: 206.15959405899048 and batch: 1650, loss is 4.20901554107666 and perplexity is 67.29026269235796
At time: 207.2001073360443 and batch: 1700, loss is 4.255071063041687 and perplexity is 70.46182424207564
At time: 208.23971843719482 and batch: 1750, loss is 4.252117867469788 and perplexity is 70.254043654103
At time: 209.2797245979309 and batch: 1800, loss is 4.199214634895324 and perplexity is 66.63397848419326
At time: 210.31955361366272 and batch: 1850, loss is 4.24443452835083 and perplexity is 69.71632638956129
At time: 211.35869908332825 and batch: 1900, loss is 4.323793840408325 and perplexity is 75.47442373664398
At time: 212.39765000343323 and batch: 1950, loss is 4.262022266387939 and perplexity is 70.95332499228351
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.606428847202035 and perplexity of 100.12594536604084
finished 5 epochs...
Completing Train Step...
At time: 215.70220017433167 and batch: 50, loss is 4.217613530158997 and perplexity is 67.87131801041626
At time: 216.74336552619934 and batch: 100, loss is 4.176865568161011 and perplexity is 65.16128916602683
At time: 217.78579425811768 and batch: 150, loss is 4.145964970588684 and perplexity is 63.17855794652494
At time: 218.82736229896545 and batch: 200, loss is 4.1335335540771485 and perplexity is 62.398020622384614
At time: 219.86852765083313 and batch: 250, loss is 4.124941267967224 and perplexity is 61.864175734870145
At time: 220.90826892852783 and batch: 300, loss is 4.152339897155762 and perplexity is 63.5826031248638
At time: 221.9481921195984 and batch: 350, loss is 4.163766584396362 and perplexity is 64.31330846479118
At time: 222.98862743377686 and batch: 400, loss is 4.120095739364624 and perplexity is 61.56513618930544
At time: 224.02826595306396 and batch: 450, loss is 4.159177565574646 and perplexity is 64.01884963706358
At time: 225.0648295879364 and batch: 500, loss is 4.181393532752991 and perplexity is 65.45700616895388
At time: 226.10841536521912 and batch: 550, loss is 4.149324107170105 and perplexity is 63.39114019819902
At time: 227.15361309051514 and batch: 600, loss is 4.131900773048401 and perplexity is 62.29622144857703
At time: 228.1912624835968 and batch: 650, loss is 4.183307185173034 and perplexity is 65.58238805763219
At time: 229.23175382614136 and batch: 700, loss is 4.207673563957214 and perplexity is 67.20002126397237
At time: 230.31789827346802 and batch: 750, loss is 4.164897875785828 and perplexity is 64.38610672714506
At time: 231.35658431053162 and batch: 800, loss is 4.144841418266297 and perplexity is 63.1076133934409
At time: 232.39533829689026 and batch: 850, loss is 4.144065232276916 and perplexity is 63.058649153238555
At time: 233.43546175956726 and batch: 900, loss is 4.146122903823852 and perplexity is 63.188536728544605
At time: 234.48217034339905 and batch: 950, loss is 4.224494795799256 and perplexity is 68.33996918632855
At time: 235.52368569374084 and batch: 1000, loss is 4.193329524993897 and perplexity is 66.24298185520843
At time: 236.56521654129028 and batch: 1050, loss is 4.143900666236878 and perplexity is 63.04827269488697
At time: 237.60533785820007 and batch: 1100, loss is 4.200900955200195 and perplexity is 66.74643951111186
At time: 238.64516973495483 and batch: 1150, loss is 4.1464473295211794 and perplexity is 63.209040039356466
At time: 239.6831018924713 and batch: 1200, loss is 4.206140313148499 and perplexity is 67.09706572552447
At time: 240.72182822227478 and batch: 1250, loss is 4.190535998344421 and perplexity is 66.05818855273674
At time: 241.76867055892944 and batch: 1300, loss is 4.195714683532715 and perplexity is 66.4011704464574
At time: 242.81075525283813 and batch: 1350, loss is 4.0850569534301755 and perplexity is 59.44532326990262
At time: 243.85221934318542 and batch: 1400, loss is 4.113581295013428 and perplexity is 61.16537705369451
At time: 244.8929033279419 and batch: 1450, loss is 4.03842396736145 and perplexity is 56.73685317229299
At time: 245.93705558776855 and batch: 1500, loss is 4.047452530860901 and perplexity is 57.25142488015153
At time: 246.9820122718811 and batch: 1550, loss is 4.064651947021485 and perplexity is 58.244632776319406
At time: 248.0269479751587 and batch: 1600, loss is 4.154508056640625 and perplexity is 63.72060990519299
At time: 249.07064270973206 and batch: 1650, loss is 4.098327960968017 and perplexity is 60.239480581416444
At time: 250.11072754859924 and batch: 1700, loss is 4.146474008560181 and perplexity is 63.21072641829628
At time: 251.1509826183319 and batch: 1750, loss is 4.147312822341919 and perplexity is 63.263770690792875
At time: 252.19856095314026 and batch: 1800, loss is 4.091045618057251 and perplexity is 59.80238948235784
At time: 253.24511051177979 and batch: 1850, loss is 4.136328692436218 and perplexity is 62.572675702200804
At time: 254.28495526313782 and batch: 1900, loss is 4.217435741424561 and perplexity is 67.85925232728574
At time: 255.329336643219 and batch: 1950, loss is 4.153490796089172 and perplexity is 63.65582240089501
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6088958030523255 and perplexity of 100.37325658022546
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 258.60518860816956 and batch: 50, loss is 4.140688481330872 and perplexity is 62.84607490718616
At time: 259.6739640235901 and batch: 100, loss is 4.122114911079406 and perplexity is 61.68957235763357
At time: 260.71574115753174 and batch: 150, loss is 4.09132034778595 and perplexity is 59.818821233637806
At time: 261.7593619823456 and batch: 200, loss is 4.0793188238143925 and perplexity is 59.10519508299729
At time: 262.8109521865845 and batch: 250, loss is 4.071954822540283 and perplexity is 58.6715430179698
At time: 263.85535740852356 and batch: 300, loss is 4.096593770980835 and perplexity is 60.13510440757541
At time: 264.90077900886536 and batch: 350, loss is 4.102367601394653 and perplexity is 60.48331859981793
At time: 265.9449853897095 and batch: 400, loss is 4.05934139251709 and perplexity is 57.936141334685445
At time: 266.98752784729004 and batch: 450, loss is 4.08668553352356 and perplexity is 59.542213615453804
At time: 268.03742384910583 and batch: 500, loss is 4.102102980613709 and perplexity is 60.46731557427587
At time: 269.0867259502411 and batch: 550, loss is 4.067355666160584 and perplexity is 58.40232298366146
At time: 270.13290548324585 and batch: 600, loss is 4.03882125377655 and perplexity is 56.75939843145993
At time: 271.17704606056213 and batch: 650, loss is 4.075263314247131 and perplexity is 58.865978798697064
At time: 272.2212917804718 and batch: 700, loss is 4.094767665863037 and perplexity is 60.0253915897144
At time: 273.2649073600769 and batch: 750, loss is 4.038842296600341 and perplexity is 56.760592822046235
At time: 274.30852794647217 and batch: 800, loss is 4.015497856140136 and perplexity is 55.450895100186
At time: 275.35004138946533 and batch: 850, loss is 4.015462746620178 and perplexity is 55.448948280053955
At time: 276.39200925827026 and batch: 900, loss is 4.001957688331604 and perplexity is 54.70514088759438
At time: 277.445339679718 and batch: 950, loss is 4.080238099098206 and perplexity is 59.1595540095628
At time: 278.49302673339844 and batch: 1000, loss is 4.040205016136169 and perplexity is 56.83799431703675
At time: 279.5365436077118 and batch: 1050, loss is 3.984266653060913 and perplexity is 53.74586065975184
At time: 280.5794599056244 and batch: 1100, loss is 4.022135910987854 and perplexity is 55.82020557872216
At time: 281.6219108104706 and batch: 1150, loss is 3.9744629430770875 and perplexity is 53.2215262399002
At time: 282.66515135765076 and batch: 1200, loss is 4.017605457305908 and perplexity is 55.56788671386671
At time: 283.752596616745 and batch: 1250, loss is 3.987509455680847 and perplexity is 53.92043077274155
At time: 284.79639649391174 and batch: 1300, loss is 3.993451228141785 and perplexity is 54.24176741259811
At time: 285.84716987609863 and batch: 1350, loss is 3.8789167165756226 and perplexity is 48.371786324543194
At time: 286.89300084114075 and batch: 1400, loss is 3.898652682304382 and perplexity is 49.335933130780354
At time: 287.9410412311554 and batch: 1450, loss is 3.818215403556824 and perplexity is 45.52289578949285
At time: 288.983366727829 and batch: 1500, loss is 3.8286582136154177 and perplexity is 46.00077359431564
At time: 290.0279703140259 and batch: 1550, loss is 3.8275857162475586 and perplexity is 45.95146433246953
At time: 291.07582330703735 and batch: 1600, loss is 3.9087625455856325 and perplexity is 49.837242484230565
At time: 292.12447237968445 and batch: 1650, loss is 3.8432239580154417 and perplexity is 46.675712666769506
At time: 293.16985511779785 and batch: 1700, loss is 3.880691499710083 and perplexity is 48.457711982245335
At time: 294.21732473373413 and batch: 1750, loss is 3.864303259849548 and perplexity is 47.670047223489625
At time: 295.26192021369934 and batch: 1800, loss is 3.7981142234802245 and perplexity is 44.61696748136642
At time: 296.30913186073303 and batch: 1850, loss is 3.8362966871261595 and perplexity is 46.35349469528741
At time: 297.3581714630127 and batch: 1900, loss is 3.9095210075378417 and perplexity is 49.87505647488171
At time: 298.4029517173767 and batch: 1950, loss is 3.8502099657058717 and perplexity is 47.00293119920291
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.520602346021076 and perplexity of 91.89093144846689
finished 7 epochs...
Completing Train Step...
At time: 301.69187664985657 and batch: 50, loss is 4.0336972522735595 and perplexity is 56.469307037662155
At time: 302.7545795440674 and batch: 100, loss is 4.007412648200988 and perplexity is 55.004370636918054
At time: 303.793110370636 and batch: 150, loss is 3.9748572540283202 and perplexity is 53.242516208553205
At time: 304.8322250843048 and batch: 200, loss is 3.957666211128235 and perplexity is 52.33504437075114
At time: 305.87287640571594 and batch: 250, loss is 3.9509459924697876 and perplexity is 51.984520546627806
At time: 306.91245698928833 and batch: 300, loss is 3.977481985092163 and perplexity is 53.38244705484803
At time: 307.95200967788696 and batch: 350, loss is 3.9855706214904787 and perplexity is 53.81598927808731
At time: 308.98960280418396 and batch: 400, loss is 3.9444009256362915 and perplexity is 51.64538941394517
At time: 310.0549581050873 and batch: 450, loss is 3.980395264625549 and perplexity is 53.53819179912995
At time: 311.09973764419556 and batch: 500, loss is 3.9980669164657594 and perplexity is 54.49270919412442
At time: 312.13970041275024 and batch: 550, loss is 3.9649543285369875 and perplexity is 52.71786163279718
At time: 313.17842531204224 and batch: 600, loss is 3.9425496435165406 and perplexity is 51.549867674081455
At time: 314.2160439491272 and batch: 650, loss is 3.9803305435180665 and perplexity is 53.53472686019264
At time: 315.2544448375702 and batch: 700, loss is 4.00561680316925 and perplexity is 54.90567995429549
At time: 316.29345440864563 and batch: 750, loss is 3.953490376472473 and perplexity is 52.11695754293277
At time: 317.33278632164 and batch: 800, loss is 3.932390012741089 and perplexity is 51.02879150476566
At time: 318.37252163887024 and batch: 850, loss is 3.9354336214065553 and perplexity is 51.184339770725465
At time: 319.4104833602905 and batch: 900, loss is 3.92281831741333 and perplexity is 50.54268958057187
At time: 320.45075130462646 and batch: 950, loss is 4.00482852935791 and perplexity is 54.862416298737294
At time: 321.48973989486694 and batch: 1000, loss is 3.9656383657455443 and perplexity is 52.75393494804791
At time: 322.5277817249298 and batch: 1050, loss is 3.913802618980408 and perplexity is 50.089059900211204
At time: 323.5642423629761 and batch: 1100, loss is 3.953997015953064 and perplexity is 52.143368741145224
At time: 324.6029951572418 and batch: 1150, loss is 3.9105567502975465 and perplexity is 49.92674096481311
At time: 325.6437101364136 and batch: 1200, loss is 3.9556541585922242 and perplexity is 52.22984937641919
At time: 326.684285402298 and batch: 1250, loss is 3.9302720737457277 and perplexity is 50.92083000564265
At time: 327.7236204147339 and batch: 1300, loss is 3.9399671506881715 and perplexity is 51.41691226260103
At time: 328.76390266418457 and batch: 1350, loss is 3.8268117809295656 and perplexity is 45.915914629668855
At time: 329.8029067516327 and batch: 1400, loss is 3.852221384048462 and perplexity is 47.097568903272304
At time: 330.84136390686035 and batch: 1450, loss is 3.774979257583618 and perplexity is 43.596604007431594
At time: 331.8810441493988 and batch: 1500, loss is 3.787956132888794 and perplexity is 44.166038450237195
At time: 332.9190709590912 and batch: 1550, loss is 3.790169987678528 and perplexity is 44.26392395817481
At time: 333.95874786376953 and batch: 1600, loss is 3.8747534561157226 and perplexity is 48.17082060575267
At time: 334.99696254730225 and batch: 1650, loss is 3.813015637397766 and perplexity is 45.28680172541724
At time: 336.03663063049316 and batch: 1700, loss is 3.8553193950653077 and perplexity is 47.243703937694924
At time: 337.0752465724945 and batch: 1750, loss is 3.8441821765899657 and perplexity is 46.72045963689109
At time: 338.11735129356384 and batch: 1800, loss is 3.781094880104065 and perplexity is 43.86404132000913
At time: 339.160085439682 and batch: 1850, loss is 3.821753406524658 and perplexity is 45.68424118183606
At time: 340.2014923095703 and batch: 1900, loss is 3.900677466392517 and perplexity is 49.43592894395939
At time: 341.24166202545166 and batch: 1950, loss is 3.844718327522278 and perplexity is 46.74551557116452
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.52068353697311 and perplexity of 91.89839246355388
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 344.5563554763794 and batch: 50, loss is 3.9979714441299437 and perplexity is 54.48750689623445
At time: 345.60293436050415 and batch: 100, loss is 3.9936333513259887 and perplexity is 54.25164699561939
At time: 346.6485023498535 and batch: 150, loss is 3.9717081785202026 and perplexity is 53.075115222281674
At time: 347.68993282318115 and batch: 200, loss is 3.9572054052352907 and perplexity is 52.31093362951007
At time: 348.73020458221436 and batch: 250, loss is 3.954374990463257 and perplexity is 52.163081330598445
At time: 349.77189111709595 and batch: 300, loss is 3.9737839555740355 and perplexity is 53.18540175411501
At time: 350.8125047683716 and batch: 350, loss is 3.982558364868164 and perplexity is 53.65412561783094
At time: 351.85452461242676 and batch: 400, loss is 3.942755451202393 and perplexity is 51.560478124872155
At time: 352.8961036205292 and batch: 450, loss is 3.983002853393555 and perplexity is 53.67797956201744
At time: 353.9394772052765 and batch: 500, loss is 3.998784785270691 and perplexity is 54.53184185452862
At time: 354.981648683548 and batch: 550, loss is 3.968448781967163 and perplexity is 52.902403994765976
At time: 356.0234160423279 and batch: 600, loss is 3.936772198677063 and perplexity is 51.25289984078714
At time: 357.066721200943 and batch: 650, loss is 3.9665625381469725 and perplexity is 52.802711214161505
At time: 358.1094079017639 and batch: 700, loss is 3.9908080005645754 and perplexity is 54.09858339447394
At time: 359.1486301422119 and batch: 750, loss is 3.9302177906036375 and perplexity is 50.91806593801392
At time: 360.19816303253174 and batch: 800, loss is 3.9040580368041993 and perplexity is 49.60333338444213
At time: 361.26563119888306 and batch: 850, loss is 3.9091104650497437 and perplexity is 49.854584847626406
At time: 362.305641412735 and batch: 900, loss is 3.8862584590911866 and perplexity is 48.72822636922745
At time: 363.34717988967896 and batch: 950, loss is 3.975277419090271 and perplexity is 53.26489155401442
At time: 364.3875241279602 and batch: 1000, loss is 3.9406544303894044 and perplexity is 51.452262208958004
At time: 365.4269549846649 and batch: 1050, loss is 3.8878997135162354 and perplexity is 48.80826745230429
At time: 366.46801710128784 and batch: 1100, loss is 3.9227987051010134 and perplexity is 50.54169833127885
At time: 367.5080614089966 and batch: 1150, loss is 3.879734992980957 and perplexity is 48.411384014694754
At time: 368.54974913597107 and batch: 1200, loss is 3.920896444320679 and perplexity is 50.44564622781089
At time: 369.59074425697327 and batch: 1250, loss is 3.8863808250427248 and perplexity is 48.73418940984302
At time: 370.6299386024475 and batch: 1300, loss is 3.889434938430786 and perplexity is 48.883256668461
At time: 371.66946744918823 and batch: 1350, loss is 3.7721107625961303 and perplexity is 43.47172655816047
At time: 372.7140688896179 and batch: 1400, loss is 3.7985469627380373 and perplexity is 44.636279172922336
At time: 373.75453877449036 and batch: 1450, loss is 3.713794765472412 and perplexity is 41.009131666259954
At time: 374.79440546035767 and batch: 1500, loss is 3.723557434082031 and perplexity is 41.411450887898724
At time: 375.83512926101685 and batch: 1550, loss is 3.727616286277771 and perplexity is 41.57987542018249
At time: 376.8765904903412 and batch: 1600, loss is 3.8086482954025267 and perplexity is 45.08945003925023
At time: 377.91615176200867 and batch: 1650, loss is 3.741709661483765 and perplexity is 42.17002503740318
At time: 378.95558285713196 and batch: 1700, loss is 3.7775170516967775 and perplexity is 43.707383721032464
At time: 379.9941008090973 and batch: 1750, loss is 3.765334963798523 and perplexity is 43.17816656050356
At time: 381.0338990688324 and batch: 1800, loss is 3.6991397953033447 and perplexity is 40.41252635913419
At time: 382.07476687431335 and batch: 1850, loss is 3.733069033622742 and perplexity is 41.807219236388704
At time: 383.1159768104553 and batch: 1900, loss is 3.808679156303406 and perplexity is 45.090841561770304
At time: 384.1559143066406 and batch: 1950, loss is 3.759010281562805 and perplexity is 42.90594015769161
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.491404830577761 and perplexity of 89.2467343949274
finished 9 epochs...
Completing Train Step...
At time: 387.4325201511383 and batch: 50, loss is 3.9791806364059448 and perplexity is 53.47320227758759
At time: 388.5047035217285 and batch: 100, loss is 3.962817807197571 and perplexity is 52.605349032035605
At time: 389.5522155761719 and batch: 150, loss is 3.93249342918396 and perplexity is 51.03406899375195
At time: 390.6019141674042 and batch: 200, loss is 3.912728190422058 and perplexity is 50.03527168476533
At time: 391.6470034122467 and batch: 250, loss is 3.908667163848877 and perplexity is 49.83248914818164
At time: 392.692506313324 and batch: 300, loss is 3.926296787261963 and perplexity is 50.7188069342176
At time: 393.73474502563477 and batch: 350, loss is 3.9365595102310182 and perplexity is 51.24200010033022
At time: 394.78114104270935 and batch: 400, loss is 3.896786050796509 and perplexity is 49.24392702099467
At time: 395.8254454135895 and batch: 450, loss is 3.9396745109558107 and perplexity is 51.40186783256404
At time: 396.8706090450287 and batch: 500, loss is 3.95721622467041 and perplexity is 52.31149960732428
At time: 397.91635966300964 and batch: 550, loss is 3.9264337253570556 and perplexity is 50.72575274658684
At time: 398.9619765281677 and batch: 600, loss is 3.8980750370025636 and perplexity is 49.30744269027329
At time: 400.00612020492554 and batch: 650, loss is 3.9301140975952147 and perplexity is 50.9127863643059
At time: 401.05030369758606 and batch: 700, loss is 3.956321883201599 and perplexity is 52.26473617828363
At time: 402.1023783683777 and batch: 750, loss is 3.898233151435852 and perplexity is 49.31523952501097
At time: 403.14818000793457 and batch: 800, loss is 3.873811264038086 and perplexity is 48.12545581473398
At time: 404.193421125412 and batch: 850, loss is 3.8786375093460084 and perplexity is 48.358282457368425
At time: 405.24032163619995 and batch: 900, loss is 3.8592257499694824 and perplexity is 47.42861554230023
At time: 406.28491377830505 and batch: 950, loss is 3.9483470344543456 and perplexity is 51.849590375149326
At time: 407.3288698196411 and batch: 1000, loss is 3.9136931133270263 and perplexity is 50.08357516528979
At time: 408.3739159107208 and batch: 1050, loss is 3.8621914911270143 and perplexity is 47.569485327866154
At time: 409.4268889427185 and batch: 1100, loss is 3.897751474380493 and perplexity is 49.29149122561686
At time: 410.47194361686707 and batch: 1150, loss is 3.8568533992767335 and perplexity is 47.316231593140664
At time: 411.51690888404846 and batch: 1200, loss is 3.89952796459198 and perplexity is 49.37913490330684
At time: 412.56264090538025 and batch: 1250, loss is 3.867699317932129 and perplexity is 47.83221267845467
At time: 413.60709142684937 and batch: 1300, loss is 3.873033113479614 and perplexity is 48.08802153105834
At time: 414.65264534950256 and batch: 1350, loss is 3.7571636772155763 and perplexity is 42.826782970570896
At time: 415.708553314209 and batch: 1400, loss is 3.786401777267456 and perplexity is 44.09744204551434
At time: 416.76292419433594 and batch: 1450, loss is 3.7044690561294558 and perplexity is 40.62847015205713
At time: 417.81320309638977 and batch: 1500, loss is 3.71624831199646 and perplexity is 41.109873014969246
At time: 418.8634555339813 and batch: 1550, loss is 3.7226948738098145 and perplexity is 41.375746416391
At time: 419.91230869293213 and batch: 1600, loss is 3.8054290580749512 and perplexity is 44.94452979009842
At time: 420.96346616744995 and batch: 1650, loss is 3.740729193687439 and perplexity is 42.12869894864396
At time: 422.0152540206909 and batch: 1700, loss is 3.778316707611084 and perplexity is 43.742348566983594
At time: 423.0642716884613 and batch: 1750, loss is 3.7685439872741697 and perplexity is 43.31694886937881
At time: 424.11392974853516 and batch: 1800, loss is 3.7040630388259888 and perplexity is 40.611977638511505
At time: 425.16704773902893 and batch: 1850, loss is 3.7390743923187255 and perplexity is 42.05904197008889
At time: 426.21806716918945 and batch: 1900, loss is 3.8160949993133544 and perplexity is 45.426471113859506
At time: 427.2658793926239 and batch: 1950, loss is 3.7667592048645018 and perplexity is 43.239706491918845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.490770916606104 and perplexity of 89.19017757104405
finished 10 epochs...
Completing Train Step...
At time: 430.56972217559814 and batch: 50, loss is 3.9616470336914062 and perplexity is 52.54379612239521
At time: 431.6375346183777 and batch: 100, loss is 3.9434239721298217 and perplexity is 51.594958907805186
At time: 432.68177795410156 and batch: 150, loss is 3.912299633026123 and perplexity is 50.013833293145964
At time: 433.72322368621826 and batch: 200, loss is 3.8912739753723145 and perplexity is 48.97323749697032
At time: 434.76324009895325 and batch: 250, loss is 3.8862438869476317 and perplexity is 48.72751629969125
At time: 435.80270528793335 and batch: 300, loss is 3.9038939237594605 and perplexity is 49.595193498320235
At time: 436.84270763397217 and batch: 350, loss is 3.914666814804077 and perplexity is 50.132365366094696
At time: 437.88325023651123 and batch: 400, loss is 3.874898533821106 and perplexity is 48.17780962483575
At time: 438.9240972995758 and batch: 450, loss is 3.9188255739212035 and perplexity is 50.34128792580967
At time: 439.96497559547424 and batch: 500, loss is 3.9365750646591184 and perplexity is 51.24279714653528
At time: 441.0307629108429 and batch: 550, loss is 3.905695524215698 and perplexity is 49.68462475706288
At time: 442.069087266922 and batch: 600, loss is 3.8780289125442504 and perplexity is 48.32886071522358
At time: 443.10806488990784 and batch: 650, loss is 3.9107028436660767 and perplexity is 49.93403546340636
At time: 444.14796018600464 and batch: 700, loss is 3.937815341949463 and perplexity is 51.30639185351304
At time: 445.1887366771698 and batch: 750, loss is 3.8806764698028564 and perplexity is 48.45698367280304
At time: 446.22919511795044 and batch: 800, loss is 3.8570437145233156 and perplexity is 47.32523745037244
At time: 447.271116733551 and batch: 850, loss is 3.8618926906585695 and perplexity is 47.55527366669775
At time: 448.3173408508301 and batch: 900, loss is 3.843551745414734 and perplexity is 46.69101488503482
At time: 449.3544511795044 and batch: 950, loss is 3.933090858459473 and perplexity is 51.06456735001568
At time: 450.39437222480774 and batch: 1000, loss is 3.8986418056488037 and perplexity is 49.3353965237463
At time: 451.43261337280273 and batch: 1050, loss is 3.847769136428833 and perplexity is 46.888344968227614
At time: 452.4737641811371 and batch: 1100, loss is 3.8836333560943603 and perplexity is 48.60047750647833
At time: 453.51342940330505 and batch: 1150, loss is 3.8437323808670043 and perplexity is 46.69944969941586
At time: 454.5543406009674 and batch: 1200, loss is 3.8869938802719117 and perplexity is 48.764075319421465
At time: 455.6014289855957 and batch: 1250, loss is 3.8564133071899414 and perplexity is 47.29541267549617
At time: 456.6407115459442 and batch: 1300, loss is 3.862684283256531 and perplexity is 47.5929329727738
At time: 457.6855962276459 and batch: 1350, loss is 3.7479606962203977 and perplexity is 42.43445695424002
At time: 458.7305443286896 and batch: 1400, loss is 3.7778821086883543 and perplexity is 43.723342319765145
At time: 459.7711250782013 and batch: 1450, loss is 3.6971911668777464 and perplexity is 40.333854037975435
At time: 460.8188555240631 and batch: 1500, loss is 3.709586853981018 and perplexity is 40.83693142564389
At time: 461.85977578163147 and batch: 1550, loss is 3.71727436542511 and perplexity is 41.15207558847272
At time: 462.89883184432983 and batch: 1600, loss is 3.800645728111267 and perplexity is 44.730058626151425
At time: 463.93841528892517 and batch: 1650, loss is 3.7368244314193726 and perplexity is 41.96451714864435
At time: 464.9766438007355 and batch: 1700, loss is 3.775072627067566 and perplexity is 43.60067478989013
At time: 466.0247564315796 and batch: 1750, loss is 3.7664833211898805 and perplexity is 43.22777900817698
At time: 467.07170701026917 and batch: 1800, loss is 3.702800211906433 and perplexity is 40.56072410887298
At time: 468.11177277565 and batch: 1850, loss is 3.738340487480164 and perplexity is 42.028185959754374
At time: 469.15405774116516 and batch: 1900, loss is 3.8161382627487184 and perplexity is 45.428436461569895
At time: 470.193886756897 and batch: 1950, loss is 3.7669671154022217 and perplexity is 43.248697417168096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4914465615915695 and perplexity of 89.25045882934444
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 473.5431933403015 and batch: 50, loss is 3.9533541345596315 and perplexity is 52.10985751261747
At time: 474.58637595176697 and batch: 100, loss is 3.9450526666641235 and perplexity is 51.67905980412011
At time: 475.6255748271942 and batch: 150, loss is 3.920506615638733 and perplexity is 50.425984900555626
At time: 476.66589426994324 and batch: 200, loss is 3.9007007265090943 and perplexity is 49.43707884280307
At time: 477.70946407318115 and batch: 250, loss is 3.8993828296661377 and perplexity is 49.371968786264
At time: 478.7603397369385 and batch: 300, loss is 3.911661581993103 and perplexity is 49.98193209352694
At time: 479.8050043582916 and batch: 350, loss is 3.9225345516204833 and perplexity is 50.528349328923085
At time: 480.8479151725769 and batch: 400, loss is 3.8852322053909303 and perplexity is 48.67824449803596
At time: 481.8921413421631 and batch: 450, loss is 3.930514888763428 and perplexity is 50.933195849127266
At time: 482.93318343162537 and batch: 500, loss is 3.950644335746765 and perplexity is 51.968841431485956
At time: 483.97354006767273 and batch: 550, loss is 3.9197221660614012 and perplexity is 50.38644376905347
At time: 485.01313757896423 and batch: 600, loss is 3.88832727432251 and perplexity is 48.829140416401756
At time: 486.0554368495941 and batch: 650, loss is 3.917836318016052 and perplexity is 50.291512134013445
At time: 487.0969638824463 and batch: 700, loss is 3.942129235267639 and perplexity is 51.528200239384766
At time: 488.139741897583 and batch: 750, loss is 3.8851143074035646 and perplexity is 48.67250576928008
At time: 489.1882674694061 and batch: 800, loss is 3.8600451517105103 and perplexity is 47.46749455904179
At time: 490.23044538497925 and batch: 850, loss is 3.8646553230285643 and perplexity is 47.686833046520704
At time: 491.27142095565796 and batch: 900, loss is 3.8389724111557006 and perplexity is 46.47768993689499
At time: 492.3163378238678 and batch: 950, loss is 3.928412857055664 and perplexity is 50.82624510278514
At time: 493.38603234291077 and batch: 1000, loss is 3.8934757328033447 and perplexity is 49.081183478376445
At time: 494.4300708770752 and batch: 1050, loss is 3.844401216506958 and perplexity is 46.73069440336208
At time: 495.473032951355 and batch: 1100, loss is 3.876130895614624 and perplexity is 48.237218715941026
At time: 496.51387906074524 and batch: 1150, loss is 3.8381386470794676 and perplexity is 46.43895465896487
At time: 497.56319093704224 and batch: 1200, loss is 3.8813680362701417 and perplexity is 48.49050648810836
At time: 498.6041610240936 and batch: 1250, loss is 3.8489619207382204 and perplexity is 46.944306018495396
At time: 499.6507167816162 and batch: 1300, loss is 3.8526659059524535 and perplexity is 47.11850945819741
At time: 500.6929874420166 and batch: 1350, loss is 3.732096643447876 and perplexity is 41.766586066014305
At time: 501.7422230243683 and batch: 1400, loss is 3.763110628128052 and perplexity is 43.08223056092543
At time: 502.7867486476898 and batch: 1450, loss is 3.6792591428756714 and perplexity is 39.617032636727416
At time: 503.83091974258423 and batch: 1500, loss is 3.6870846796035766 and perplexity is 39.928273405371385
At time: 504.8742492198944 and batch: 1550, loss is 3.6975077295303347 and perplexity is 40.34662425097841
At time: 505.91821932792664 and batch: 1600, loss is 3.777078413963318 and perplexity is 43.68821621740411
At time: 506.960173368454 and batch: 1650, loss is 3.7111447525024412 and perplexity is 40.90060080306845
At time: 508.00963735580444 and batch: 1700, loss is 3.744120683670044 and perplexity is 42.271820569696025
At time: 509.0521457195282 and batch: 1750, loss is 3.7363244104385376 and perplexity is 41.943539254750036
At time: 510.0947608947754 and batch: 1800, loss is 3.6753804874420166 and perplexity is 39.463669431606014
At time: 511.1371293067932 and batch: 1850, loss is 3.7101281261444092 and perplexity is 40.85904130305369
At time: 512.1801869869232 and batch: 1900, loss is 3.787136116027832 and perplexity is 44.12983639920084
At time: 513.2222471237183 and batch: 1950, loss is 3.7403708124160766 and perplexity is 42.113603517075454
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.484057901071948 and perplexity of 88.5934476929328
finished 12 epochs...
Completing Train Step...
At time: 516.5502774715424 and batch: 50, loss is 3.9477754068374633 and perplexity is 51.81996018689063
At time: 517.6173114776611 and batch: 100, loss is 3.9334827709197997 and perplexity is 51.084584112394445
At time: 518.668726682663 and batch: 150, loss is 3.905152053833008 and perplexity is 49.6576299711301
At time: 519.748988866806 and batch: 200, loss is 3.8837756299972535 and perplexity is 48.60739257800108
At time: 520.7887923717499 and batch: 250, loss is 3.8821063661575317 and perplexity is 48.526321698396295
At time: 521.8295867443085 and batch: 300, loss is 3.8944439601898195 and perplexity is 49.12872823773556
At time: 522.8700304031372 and batch: 350, loss is 3.9049020338058473 and perplexity is 49.645216121056215
At time: 523.9181108474731 and batch: 400, loss is 3.8672095251083376 and perplexity is 47.8087905404045
At time: 524.9599895477295 and batch: 450, loss is 3.9132379913330078 and perplexity is 50.06078621496261
At time: 525.999368429184 and batch: 500, loss is 3.9335967826843263 and perplexity is 51.090408687997964
At time: 527.0382301807404 and batch: 550, loss is 3.9035850143432618 and perplexity is 49.579875442118116
At time: 528.0797176361084 and batch: 600, loss is 3.873245105743408 and perplexity is 48.09821690023559
At time: 529.1252822875977 and batch: 650, loss is 3.9031487131118774 and perplexity is 49.55824839970653
At time: 530.1656534671783 and batch: 700, loss is 3.929146828651428 and perplexity is 50.86356381677261
At time: 531.2047419548035 and batch: 750, loss is 3.873264751434326 and perplexity is 48.09916183222041
At time: 532.2465579509735 and batch: 800, loss is 3.8489399099349977 and perplexity is 46.94327274798479
At time: 533.2852292060852 and batch: 850, loss is 3.853338737487793 and perplexity is 47.15022294497968
At time: 534.3252704143524 and batch: 900, loss is 3.8291869068145754 and perplexity is 46.025100320591676
At time: 535.3668200969696 and batch: 950, loss is 3.9188973808288576 and perplexity is 50.344902907811736
At time: 536.40700340271 and batch: 1000, loss is 3.8836402797698977 and perplexity is 48.60081400158043
At time: 537.4450035095215 and batch: 1050, loss is 3.8349263668060303 and perplexity is 46.2900190605063
At time: 538.494621515274 and batch: 1100, loss is 3.867602143287659 and perplexity is 47.827564826023774
At time: 539.5366857051849 and batch: 1150, loss is 3.830885648727417 and perplexity is 46.10335153303855
At time: 540.5847215652466 and batch: 1200, loss is 3.8742551708221438 and perplexity is 48.14682377339604
At time: 541.6328029632568 and batch: 1250, loss is 3.8431262874603274 and perplexity is 46.67115404662809
At time: 542.6741576194763 and batch: 1300, loss is 3.8477676105499268 and perplexity is 46.88827342234566
At time: 543.7151613235474 and batch: 1350, loss is 3.728878908157349 and perplexity is 41.63240823820179
At time: 544.7564194202423 and batch: 1400, loss is 3.7602328872680664 and perplexity is 42.95842928513311
At time: 545.7962610721588 and batch: 1450, loss is 3.6778415966033937 and perplexity is 39.5609134449674
At time: 546.8368725776672 and batch: 1500, loss is 3.687312068939209 and perplexity is 39.93735370127609
At time: 547.8753178119659 and batch: 1550, loss is 3.698596968650818 and perplexity is 40.39059531564649
At time: 548.9154245853424 and batch: 1600, loss is 3.779278154373169 and perplexity is 43.78442473013352
At time: 549.9625220298767 and batch: 1650, loss is 3.714538588523865 and perplexity is 41.039646551143846
At time: 551.0036513805389 and batch: 1700, loss is 3.7484437084197997 and perplexity is 42.454958265417034
At time: 552.0446634292603 and batch: 1750, loss is 3.7419837856292726 and perplexity is 42.181586444040555
At time: 553.0849859714508 and batch: 1800, loss is 3.681290864944458 and perplexity is 39.69760525910654
At time: 554.1254556179047 and batch: 1850, loss is 3.71619104385376 and perplexity is 41.10751879630656
At time: 555.1705024242401 and batch: 1900, loss is 3.7928027009963987 and perplexity is 44.38061171558856
At time: 556.2107646465302 and batch: 1950, loss is 3.745635132789612 and perplexity is 42.335887592018004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4835730264353195 and perplexity of 88.55050138980302
finished 13 epochs...
Completing Train Step...
At time: 559.4851236343384 and batch: 50, loss is 3.9436166429519655 and perplexity is 51.60490070867314
At time: 560.5532188415527 and batch: 100, loss is 3.9275971269607544 and perplexity is 50.784801510734276
At time: 561.5953049659729 and batch: 150, loss is 3.898385829925537 and perplexity is 49.32276947611625
At time: 562.6390209197998 and batch: 200, loss is 3.8764913845062257 and perplexity is 48.254610832093874
At time: 563.6824524402618 and batch: 250, loss is 3.8742726278305053 and perplexity is 48.14766428023758
At time: 564.7304067611694 and batch: 300, loss is 3.8863099002838135 and perplexity is 48.73073307177981
At time: 565.7781317234039 and batch: 350, loss is 3.896847438812256 and perplexity is 49.246950100751576
At time: 566.827175617218 and batch: 400, loss is 3.8588006830215456 and perplexity is 47.40845948958618
At time: 567.8707597255707 and batch: 450, loss is 3.905087823867798 and perplexity is 49.654440565713436
At time: 568.9192359447479 and batch: 500, loss is 3.9255979299545287 and perplexity is 50.68337410805414
At time: 569.9648542404175 and batch: 550, loss is 3.8954883432388305 and perplexity is 49.180064251291526
At time: 571.0095529556274 and batch: 600, loss is 3.8657986164093017 and perplexity is 47.74138426517264
At time: 572.082047700882 and batch: 650, loss is 3.896018328666687 and perplexity is 49.20613587686631
At time: 573.1332652568817 and batch: 700, loss is 3.922546696662903 and perplexity is 50.52896300159561
At time: 574.1833593845367 and batch: 750, loss is 3.867079219818115 and perplexity is 47.80256120794425
At time: 575.2288749217987 and batch: 800, loss is 3.843046298027039 and perplexity is 46.66742099676924
At time: 576.2735376358032 and batch: 850, loss is 3.8473420333862305 and perplexity is 46.868323089436124
At time: 577.3175885677338 and batch: 900, loss is 3.8240043449401857 and perplexity is 45.78718941689751
At time: 578.3691186904907 and batch: 950, loss is 3.9138582944869995 and perplexity is 50.091848711629375
At time: 579.4165782928467 and batch: 1000, loss is 3.8787001037597655 and perplexity is 48.36130951044646
At time: 580.4621121883392 and batch: 1050, loss is 3.830154633522034 and perplexity is 46.069661597476625
At time: 581.5072512626648 and batch: 1100, loss is 3.8631275510787964 and perplexity is 47.61403406489994
At time: 582.5509376525879 and batch: 1150, loss is 3.826957497596741 and perplexity is 45.92260583121695
At time: 583.5949609279633 and batch: 1200, loss is 3.870605540275574 and perplexity is 47.971425918006446
At time: 584.642980337143 and batch: 1250, loss is 3.84008403301239 and perplexity is 46.52938427983479
At time: 585.6936674118042 and batch: 1300, loss is 3.8450971937179563 and perplexity is 46.76322922215388
At time: 586.7410852909088 and batch: 1350, loss is 3.7266747188568115 and perplexity is 41.54074358963869
At time: 587.786257982254 and batch: 1400, loss is 3.758492727279663 and perplexity is 42.883739750044356
At time: 588.8305034637451 and batch: 1450, loss is 3.6767411756515505 and perplexity is 39.517403730829606
At time: 589.8729710578918 and batch: 1500, loss is 3.686837692260742 and perplexity is 39.918412844985966
At time: 590.9204876422882 and batch: 1550, loss is 3.6986011123657225 and perplexity is 40.390762683105066
At time: 591.9666299819946 and batch: 1600, loss is 3.7797372007369994 and perplexity is 43.80452842500928
At time: 593.0105061531067 and batch: 1650, loss is 3.7154091501235964 and perplexity is 41.075389647524005
At time: 594.0551540851593 and batch: 1700, loss is 3.7496552324295043 and perplexity is 42.506424636763725
At time: 595.0991625785828 and batch: 1750, loss is 3.743797402381897 and perplexity is 42.258157089782635
At time: 596.1423625946045 and batch: 1800, loss is 3.683189091682434 and perplexity is 39.77303188060934
At time: 597.1855454444885 and batch: 1850, loss is 3.7182248067855834 and perplexity is 41.191206816204264
At time: 598.2344615459442 and batch: 1900, loss is 3.7947083854675294 and perplexity is 44.46526779642357
At time: 599.2791950702667 and batch: 1950, loss is 3.7474088621139527 and perplexity is 42.41104663350499
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483651946311773 and perplexity of 88.55749006020147
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 602.6009690761566 and batch: 50, loss is 3.941442370414734 and perplexity is 51.49281948199723
At time: 603.6379175186157 and batch: 100, loss is 3.9276727294921874 and perplexity is 50.7886411154269
At time: 604.6771793365479 and batch: 150, loss is 3.899910445213318 and perplexity is 49.39802507783834
At time: 605.715714931488 and batch: 200, loss is 3.878275456428528 and perplexity is 48.34077736919573
At time: 606.7547771930695 and batch: 250, loss is 3.877441267967224 and perplexity is 48.30046886528578
At time: 607.7934293746948 and batch: 300, loss is 3.8878152418136596 and perplexity is 48.80414470898284
At time: 608.8338952064514 and batch: 350, loss is 3.8979493045806883 and perplexity is 49.30124353581288
At time: 609.8757829666138 and batch: 400, loss is 3.861229681968689 and perplexity is 47.52375455688353
At time: 610.9146595001221 and batch: 450, loss is 3.9077585458755495 and perplexity is 49.787231017175294
At time: 611.9551243782043 and batch: 500, loss is 3.9290991973876954 and perplexity is 50.86114117864718
At time: 612.9973125457764 and batch: 550, loss is 3.898941831588745 and perplexity is 49.350200643159596
At time: 614.0391347408295 and batch: 600, loss is 3.8690078687667846 and perplexity is 47.8948445298221
At time: 615.0811479091644 and batch: 650, loss is 3.8985663843154907 and perplexity is 49.33167572267661
At time: 616.1223039627075 and batch: 700, loss is 3.923767385482788 and perplexity is 50.59068080326358
At time: 617.1628425121307 and batch: 750, loss is 3.8683713769912718 and perplexity is 47.864369554753736
At time: 618.2035474777222 and batch: 800, loss is 3.844421820640564 and perplexity is 46.73165725875243
At time: 619.2449748516083 and batch: 850, loss is 3.84878191947937 and perplexity is 46.93585674477898
At time: 620.287162065506 and batch: 900, loss is 3.8231817865371704 and perplexity is 45.7495422651054
At time: 621.3288593292236 and batch: 950, loss is 3.912717113494873 and perplexity is 50.03471745077379
At time: 622.3710670471191 and batch: 1000, loss is 3.8759194231033325 and perplexity is 48.22701894868466
At time: 623.4148805141449 and batch: 1050, loss is 3.8277264547348024 and perplexity is 45.95793192715539
At time: 624.4835839271545 and batch: 1100, loss is 3.8581067371368407 and perplexity is 47.37557199661317
At time: 625.5240278244019 and batch: 1150, loss is 3.822459464073181 and perplexity is 45.71650827504292
At time: 626.569699048996 and batch: 1200, loss is 3.867072124481201 and perplexity is 47.80222203387041
At time: 627.614554643631 and batch: 1250, loss is 3.8357151889801027 and perplexity is 46.326548059527525
At time: 628.6573522090912 and batch: 1300, loss is 3.8403058004379274 and perplexity is 46.539704125858904
At time: 629.6990242004395 and batch: 1350, loss is 3.7191100549697875 and perplexity is 41.227687402047295
At time: 630.741302728653 and batch: 1400, loss is 3.750757489204407 and perplexity is 42.55330346280192
At time: 631.7847027778625 and batch: 1450, loss is 3.6684783601760866 and perplexity is 39.19222401583417
At time: 632.8226866722107 and batch: 1500, loss is 3.676750884056091 and perplexity is 39.51778738363375
At time: 633.8622364997864 and batch: 1550, loss is 3.6895054292678835 and perplexity is 40.025046844691246
At time: 634.900283575058 and batch: 1600, loss is 3.7697330856323243 and perplexity is 43.3684876184078
At time: 635.9432380199432 and batch: 1650, loss is 3.7045442962646487 and perplexity is 40.6315271586474
At time: 636.9822223186493 and batch: 1700, loss is 3.7365732526779176 and perplexity is 41.953977877717
At time: 638.0194158554077 and batch: 1750, loss is 3.730566201210022 and perplexity is 41.70271360758913
At time: 639.0557692050934 and batch: 1800, loss is 3.6706634616851805 and perplexity is 39.27795663680357
At time: 640.0935654640198 and batch: 1850, loss is 3.7069053983688356 and perplexity is 40.727575688490006
At time: 641.1321477890015 and batch: 1900, loss is 3.7838037109375 and perplexity is 43.98302266502907
At time: 642.1695826053619 and batch: 1950, loss is 3.7385346364974974 and perplexity is 42.03634648291192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483152593568314 and perplexity of 88.51327967379362
finished 15 epochs...
Completing Train Step...
At time: 645.4401290416718 and batch: 50, loss is 3.940003170967102 and perplexity is 51.41876434747859
At time: 646.5014152526855 and batch: 100, loss is 3.9246662616729737 and perplexity is 50.636176005896864
At time: 647.5404317378998 and batch: 150, loss is 3.8958836936950685 and perplexity is 49.19951145610843
At time: 648.5777816772461 and batch: 200, loss is 3.8739336109161377 and perplexity is 48.131344174211584
At time: 649.6158993244171 and batch: 250, loss is 3.872849268913269 and perplexity is 48.079181622203066
At time: 650.679012298584 and batch: 300, loss is 3.884059720039368 and perplexity is 48.62120341587351
At time: 651.7181422710419 and batch: 350, loss is 3.893921036720276 and perplexity is 49.10304438864022
At time: 652.7564730644226 and batch: 400, loss is 3.8567879676818846 and perplexity is 47.313135717930415
At time: 653.7927494049072 and batch: 450, loss is 3.9034482192993165 and perplexity is 49.57309362474829
At time: 654.8304121494293 and batch: 500, loss is 3.9245072031021118 and perplexity is 50.62812252861172
At time: 655.8682973384857 and batch: 550, loss is 3.8946087646484373 and perplexity is 49.13682553841266
At time: 656.906986951828 and batch: 600, loss is 3.8646416425704957 and perplexity is 47.68618067326318
At time: 657.9494025707245 and batch: 650, loss is 3.8947135162353517 and perplexity is 49.14197296845977
At time: 658.9879236221313 and batch: 700, loss is 3.9204354333877562 and perplexity is 50.422395593191695
At time: 660.0313785076141 and batch: 750, loss is 3.865275855064392 and perplexity is 47.716433437158756
At time: 661.0751850605011 and batch: 800, loss is 3.8414909839630127 and perplexity is 46.594894915598225
At time: 662.1185119152069 and batch: 850, loss is 3.8457206773757933 and perplexity is 46.792394422429666
At time: 663.1656157970428 and batch: 900, loss is 3.820636134147644 and perplexity is 45.633227944245995
At time: 664.206428527832 and batch: 950, loss is 3.9103839778900147 and perplexity is 49.918115746697715
At time: 665.2464671134949 and batch: 1000, loss is 3.8736335611343384 and perplexity is 48.11690454130709
At time: 666.2866942882538 and batch: 1050, loss is 3.8253967809677123 and perplexity is 45.85098955753959
At time: 667.3240432739258 and batch: 1100, loss is 3.856241321563721 and perplexity is 47.28727924376654
At time: 668.3649928569794 and batch: 1150, loss is 3.820960144996643 and perplexity is 45.648016000790776
At time: 669.405266046524 and batch: 1200, loss is 3.8655053186416626 and perplexity is 47.72738387698533
At time: 670.4467391967773 and batch: 1250, loss is 3.8346663331985473 and perplexity is 46.27798366473105
At time: 671.4864044189453 and batch: 1300, loss is 3.8395213174819944 and perplexity is 46.50320883803528
At time: 672.5272011756897 and batch: 1350, loss is 3.718913083076477 and perplexity is 41.21956750612479
At time: 673.5664072036743 and batch: 1400, loss is 3.750710926055908 and perplexity is 42.55132209314343
At time: 674.6047949790955 and batch: 1450, loss is 3.668697547912598 and perplexity is 39.20081541223501
At time: 675.645745754242 and batch: 1500, loss is 3.6775946760177614 and perplexity is 39.55114624696217
At time: 676.6892280578613 and batch: 1550, loss is 3.6905681848526 and perplexity is 40.067606297896546
At time: 677.7311975955963 and batch: 1600, loss is 3.7711436986923217 and perplexity is 43.42970694167178
At time: 678.7728869915009 and batch: 1650, loss is 3.706281099319458 and perplexity is 40.702157436824976
At time: 679.8148121833801 and batch: 1700, loss is 3.738421893119812 and perplexity is 42.0316074303773
At time: 680.8544895648956 and batch: 1750, loss is 3.7327128982543947 and perplexity is 41.79233285790666
At time: 681.8949596881866 and batch: 1800, loss is 3.672973246574402 and perplexity is 39.368785124275064
At time: 682.93505859375 and batch: 1850, loss is 3.7093895483016968 and perplexity is 40.82887486197657
At time: 683.9767367839813 and batch: 1900, loss is 3.7861099004745484 and perplexity is 44.08457290374795
At time: 685.0167067050934 and batch: 1950, loss is 3.740531659126282 and perplexity is 42.12037789645977
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483062886082849 and perplexity of 88.50533972618553
finished 16 epochs...
Completing Train Step...
At time: 688.2906999588013 and batch: 50, loss is 3.938770742416382 and perplexity is 51.35543342768686
At time: 689.3615736961365 and batch: 100, loss is 3.922670340538025 and perplexity is 50.53521098464149
At time: 690.4075741767883 and batch: 150, loss is 3.8935217905044555 and perplexity is 49.0834440969143
At time: 691.4523594379425 and batch: 200, loss is 3.871299648284912 and perplexity is 48.00473482760866
At time: 692.4984004497528 and batch: 250, loss is 3.8700489473342894 and perplexity is 47.944732790249496
At time: 693.5474326610565 and batch: 300, loss is 3.8813832330703737 and perplexity is 48.4912433942479
At time: 694.5911023616791 and batch: 350, loss is 3.8912260580062865 and perplexity is 48.9708908846458
At time: 695.6339042186737 and batch: 400, loss is 3.8538203763961794 and perplexity is 47.17293779662814
At time: 696.6790504455566 and batch: 450, loss is 3.9005201959609987 and perplexity is 49.42815474542367
At time: 697.7233293056488 and batch: 500, loss is 3.9215201997756957 and perplexity is 50.477121790333726
At time: 698.7756206989288 and batch: 550, loss is 3.8917369937896726 and perplexity is 48.995918258288974
At time: 699.819477558136 and batch: 600, loss is 3.861913352012634 and perplexity is 47.55625623319516
At time: 700.8640291690826 and batch: 650, loss is 3.8921497011184694 and perplexity is 49.01614340608158
At time: 701.9054400920868 and batch: 700, loss is 3.918123903274536 and perplexity is 50.30597731141626
At time: 702.9940869808197 and batch: 750, loss is 3.8631550645828248 and perplexity is 47.6153441118399
At time: 704.0380072593689 and batch: 800, loss is 3.8394672679901123 and perplexity is 46.50069543115149
At time: 705.083181142807 and batch: 850, loss is 3.8436104917526244 and perplexity is 46.693757891741704
At time: 706.1299557685852 and batch: 900, loss is 3.8188209676742555 and perplexity is 45.55047117019241
At time: 707.1747481822968 and batch: 950, loss is 3.908653507232666 and perplexity is 49.83180860964943
At time: 708.2186150550842 and batch: 1000, loss is 3.8720169734954832 and perplexity is 48.03918218763009
At time: 709.2621548175812 and batch: 1050, loss is 3.8238397359848024 and perplexity is 45.77965305577094
At time: 710.305047750473 and batch: 1100, loss is 3.8549475193023683 and perplexity is 47.22613841554742
At time: 711.3558123111725 and batch: 1150, loss is 3.819913558959961 and perplexity is 45.600266416024965
At time: 712.4025392532349 and batch: 1200, loss is 3.8644942569732668 and perplexity is 47.67915293495151
At time: 713.4472270011902 and batch: 1250, loss is 3.8339427423477175 and perplexity is 46.24450945143418
At time: 714.4927206039429 and batch: 1300, loss is 3.838971996307373 and perplexity is 46.477670655707044
At time: 715.5371885299683 and batch: 1350, loss is 3.718723163604736 and perplexity is 41.21173985097424
At time: 716.5827496051788 and batch: 1400, loss is 3.7506626558303835 and perplexity is 42.549268180801434
At time: 717.6286373138428 and batch: 1450, loss is 3.6688669204711912 and perplexity is 39.20745551695021
At time: 718.6727004051208 and batch: 1500, loss is 3.6780889320373533 and perplexity is 39.57069947082773
At time: 719.718786239624 and batch: 1550, loss is 3.6912494707107544 and perplexity is 40.0949130922476
At time: 720.7657468318939 and batch: 1600, loss is 3.772022271156311 and perplexity is 43.46787985268867
At time: 721.8112788200378 and batch: 1650, loss is 3.707348556518555 and perplexity is 40.7456284453924
At time: 722.8527665138245 and batch: 1700, loss is 3.739563236236572 and perplexity is 42.079607303155875
At time: 723.8962383270264 and batch: 1750, loss is 3.7340975522994997 and perplexity is 41.85024086267717
At time: 724.9427015781403 and batch: 1800, loss is 3.6744058656692506 and perplexity is 39.42522601708222
At time: 725.9872765541077 and batch: 1850, loss is 3.7108654499053957 and perplexity is 40.88917875422163
At time: 727.0319051742554 and batch: 1900, loss is 3.787437791824341 and perplexity is 44.14315131103871
At time: 728.0789878368378 and batch: 1950, loss is 3.7416616535186766 and perplexity is 42.16800058890863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483050962936047 and perplexity of 88.50428447031817
finished 17 epochs...
Completing Train Step...
At time: 731.3765923976898 and batch: 50, loss is 3.937545938491821 and perplexity is 51.29257159584476
At time: 732.416056394577 and batch: 100, loss is 3.9209786319732665 and perplexity is 50.44979240743767
At time: 733.455703496933 and batch: 150, loss is 3.891619658470154 and perplexity is 48.990169643829375
At time: 734.5004994869232 and batch: 200, loss is 3.869226489067078 and perplexity is 47.90531645976223
At time: 735.5407545566559 and batch: 250, loss is 3.8678455924987794 and perplexity is 47.83920982637605
At time: 736.5812623500824 and batch: 300, loss is 3.8791823196411133 and perplexity is 48.38463572561887
At time: 737.6202399730682 and batch: 350, loss is 3.8890614032745363 and perplexity is 48.865000463422824
At time: 738.6590480804443 and batch: 400, loss is 3.8514792346954345 and perplexity is 47.062628440106366
At time: 739.7027044296265 and batch: 450, loss is 3.8982212257385256 and perplexity is 49.314651409897664
At time: 740.7425646781921 and batch: 500, loss is 3.919216413497925 and perplexity is 50.36096713893136
At time: 741.7827751636505 and batch: 550, loss is 3.889476523399353 and perplexity is 48.88528951942073
At time: 742.8228712081909 and batch: 600, loss is 3.8598042154312133 and perplexity is 47.45605929515547
At time: 743.863737821579 and batch: 650, loss is 3.890141477584839 and perplexity is 48.917806807350566
At time: 744.9023017883301 and batch: 700, loss is 3.9162766122817994 and perplexity is 50.21313331399053
At time: 745.9414558410645 and batch: 750, loss is 3.8614522647857665 and perplexity is 47.534333705375566
At time: 746.9811751842499 and batch: 800, loss is 3.837828540802002 and perplexity is 46.42455588029739
At time: 748.0210294723511 and batch: 850, loss is 3.8419240856170656 and perplexity is 46.61507961235385
At time: 749.0651612281799 and batch: 900, loss is 3.8173605966567994 and perplexity is 45.4839991309974
At time: 750.104814529419 and batch: 950, loss is 3.907257180213928 and perplexity is 49.76227566555701
At time: 751.1450912952423 and batch: 1000, loss is 3.8707244873046873 and perplexity is 47.97713231597454
At time: 752.1831130981445 and batch: 1050, loss is 3.8226027202606203 and perplexity is 45.723057916848596
At time: 753.2231097221375 and batch: 1100, loss is 3.8538842678070067 and perplexity is 47.17595183846151
At time: 754.2639906406403 and batch: 1150, loss is 3.819028964042664 and perplexity is 45.5599464881568
At time: 755.3482689857483 and batch: 1200, loss is 3.8636709785461427 and perplexity is 47.63991587064711
At time: 756.3875710964203 and batch: 1250, loss is 3.833311424255371 and perplexity is 46.2153236696712
At time: 757.4274570941925 and batch: 1300, loss is 3.8384580039978027 and perplexity is 46.453787628795155
At time: 758.4669680595398 and batch: 1350, loss is 3.7184565973281862 and perplexity is 41.20075565500517
At time: 759.5052218437195 and batch: 1400, loss is 3.7505128622055053 and perplexity is 42.54289504902388
At time: 760.5449182987213 and batch: 1450, loss is 3.6688889408111574 and perplexity is 39.20831888795573
At time: 761.5849587917328 and batch: 1500, loss is 3.678333530426025 and perplexity is 39.5803795839787
At time: 762.6293406486511 and batch: 1550, loss is 3.691645803451538 and perplexity is 40.11080716850828
At time: 763.6698410511017 and batch: 1600, loss is 3.7725557851791383 and perplexity is 43.49107676352103
At time: 764.7116100788116 and batch: 1650, loss is 3.7080095624923706 and perplexity is 40.77257045263456
At time: 765.7536871433258 and batch: 1700, loss is 3.7402839994430543 and perplexity is 42.109947668639286
At time: 766.7982137203217 and batch: 1750, loss is 3.7350160312652587 and perplexity is 41.88869708653436
At time: 767.8388879299164 and batch: 1800, loss is 3.675340247154236 and perplexity is 39.462081434142156
At time: 768.8790380954742 and batch: 1850, loss is 3.7118177938461305 and perplexity is 40.92813786414145
At time: 769.919615983963 and batch: 1900, loss is 3.788283495903015 and perplexity is 44.180499144529556
At time: 770.9590606689453 and batch: 1950, loss is 3.742376294136047 and perplexity is 42.198146325283616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483073673691861 and perplexity of 88.50629449233573
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 774.2360515594482 and batch: 50, loss is 3.9369422817230224 and perplexity is 51.26161783147649
At time: 775.2994594573975 and batch: 100, loss is 3.9208581972122194 and perplexity is 50.44371686460482
At time: 776.3414509296417 and batch: 150, loss is 3.8917340421676636 and perplexity is 48.99577364107172
At time: 777.3834714889526 and batch: 200, loss is 3.8692953205108642 and perplexity is 47.90861396534394
At time: 778.4262173175812 and batch: 250, loss is 3.86813413143158 and perplexity is 47.853015292536824
At time: 779.4645900726318 and batch: 300, loss is 3.8791355514526367 and perplexity is 48.38237291677003
At time: 780.5012781620026 and batch: 350, loss is 3.8888259363174438 and perplexity is 48.85349572500141
At time: 781.5663468837738 and batch: 400, loss is 3.851621928215027 and perplexity is 47.06934445135399
At time: 782.6044769287109 and batch: 450, loss is 3.8983839321136475 and perplexity is 49.322675870866746
At time: 783.64324259758 and batch: 500, loss is 3.91945556640625 and perplexity is 50.37301255097895
At time: 784.6827342510223 and batch: 550, loss is 3.8896516370773315 and perplexity is 48.8938507518401
At time: 785.7242200374603 and batch: 600, loss is 3.8597668552398683 and perplexity is 47.454286360818514
At time: 786.7623326778412 and batch: 650, loss is 3.890206632614136 and perplexity is 48.92099415232088
At time: 787.8009369373322 and batch: 700, loss is 3.9161530113220215 and perplexity is 50.20692730606164
At time: 788.840901851654 and batch: 750, loss is 3.8615198040008547 and perplexity is 47.53754424538123
At time: 789.8825304508209 and batch: 800, loss is 3.8380619192123415 and perplexity is 46.43539163371573
At time: 790.923089504242 and batch: 850, loss is 3.8419912242889405 and perplexity is 46.618209391951815
At time: 791.9642062187195 and batch: 900, loss is 3.816655502319336 and perplexity is 45.45193992447563
At time: 793.0050563812256 and batch: 950, loss is 3.9065405416488646 and perplexity is 49.72662687490452
At time: 794.0435800552368 and batch: 1000, loss is 3.8693907928466795 and perplexity is 47.91318813097455
At time: 795.0823547840118 and batch: 1050, loss is 3.8212882041931153 and perplexity is 45.662993708893666
At time: 796.1201989650726 and batch: 1100, loss is 3.8519225692749024 and perplexity is 47.08349755635314
At time: 797.158983707428 and batch: 1150, loss is 3.817128801345825 and perplexity is 45.47345737508647
At time: 798.2000226974487 and batch: 1200, loss is 3.8621489238739013 and perplexity is 47.5674604686404
At time: 799.2416415214539 and batch: 1250, loss is 3.8312991523742674 and perplexity is 46.122419379069726
At time: 800.2810509204865 and batch: 1300, loss is 3.8363654470443724 and perplexity is 46.356682067372006
At time: 801.323566198349 and batch: 1350, loss is 3.7157084798812865 and perplexity is 41.08768657428046
At time: 802.3657360076904 and batch: 1400, loss is 3.7476111364364626 and perplexity is 42.41962616691011
At time: 803.4060206413269 and batch: 1450, loss is 3.6657950353622435 and perplexity is 39.08719951905863
At time: 804.444094657898 and batch: 1500, loss is 3.6747593879699707 and perplexity is 39.43916617762381
At time: 805.4851279258728 and batch: 1550, loss is 3.688294138908386 and perplexity is 39.976594242319145
At time: 806.526006937027 and batch: 1600, loss is 3.7690766716003417 and perplexity is 43.340029275838745
At time: 807.5702228546143 and batch: 1650, loss is 3.704256772994995 and perplexity is 40.61984632844345
At time: 808.6081192493439 and batch: 1700, loss is 3.7362520599365237 and perplexity is 41.94050472840479
At time: 809.6479015350342 and batch: 1750, loss is 3.731000847816467 and perplexity is 41.7208434902988
At time: 810.6880176067352 and batch: 1800, loss is 3.6713606691360474 and perplexity is 39.30535106951718
At time: 811.7290077209473 and batch: 1850, loss is 3.7081849861145018 and perplexity is 40.779723552019924
At time: 812.7753410339355 and batch: 1900, loss is 3.7846540212631226 and perplexity is 44.02043778833173
At time: 813.8159840106964 and batch: 1950, loss is 3.739531240463257 and perplexity is 42.078260955118246
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4830055414244185 and perplexity of 88.50026456322776
finished 19 epochs...
Completing Train Step...
At time: 817.1276264190674 and batch: 50, loss is 3.9365011644363403 and perplexity is 51.23901043233161
At time: 818.2004778385162 and batch: 100, loss is 3.920294609069824 and perplexity is 50.41529539367588
At time: 819.2459366321564 and batch: 150, loss is 3.891149392127991 and perplexity is 48.967136632198574
At time: 820.2874381542206 and batch: 200, loss is 3.8686194086074828 and perplexity is 47.87624290411547
At time: 821.3295474052429 and batch: 250, loss is 3.8674659824371336 and perplexity is 47.82105302745459
At time: 822.3677291870117 and batch: 300, loss is 3.8785442781448363 and perplexity is 48.35377416676825
At time: 823.4106500148773 and batch: 350, loss is 3.888185405731201 and perplexity is 48.82221358639749
At time: 824.4519689083099 and batch: 400, loss is 3.8508933210372924 and perplexity is 47.03506187991592
At time: 825.4919059276581 and batch: 450, loss is 3.8976679372787477 and perplexity is 49.287373729283416
At time: 826.5375354290009 and batch: 500, loss is 3.9187469053268433 and perplexity is 50.33732780322095
At time: 827.5799322128296 and batch: 550, loss is 3.8889034461975096 and perplexity is 48.8572825003502
At time: 828.6184692382812 and batch: 600, loss is 3.859088659286499 and perplexity is 47.42211396666548
At time: 829.6572644710541 and batch: 650, loss is 3.8895508241653443 and perplexity is 48.88892186881923
At time: 830.6983988285065 and batch: 700, loss is 3.9155767488479616 and perplexity is 50.17800327263525
At time: 831.7404248714447 and batch: 750, loss is 3.8609485912322996 and perplexity is 47.51039794701675
At time: 832.7801949977875 and batch: 800, loss is 3.8374871730804445 and perplexity is 46.40871074009579
At time: 833.8560388088226 and batch: 850, loss is 3.841452956199646 and perplexity is 46.59312304965054
At time: 834.8980464935303 and batch: 900, loss is 3.8162468576431277 and perplexity is 45.43337002570571
At time: 835.9367945194244 and batch: 950, loss is 3.9061670112609863 and perplexity is 49.70805593730075
At time: 836.9788756370544 and batch: 1000, loss is 3.8690498161315916 and perplexity is 47.896853634475995
At time: 838.0267028808594 and batch: 1050, loss is 3.820949602127075 and perplexity is 45.647534742248965
At time: 839.0737874507904 and batch: 1100, loss is 3.851676416397095 and perplexity is 47.0719092442391
At time: 840.1152005195618 and batch: 1150, loss is 3.816913595199585 and perplexity is 45.463672260514734
At time: 841.1548125743866 and batch: 1200, loss is 3.861942267417908 and perplexity is 47.557631361498544
At time: 842.1941146850586 and batch: 1250, loss is 3.8312048006057737 and perplexity is 46.11806785252445
At time: 843.2317111492157 and batch: 1300, loss is 3.836306290626526 and perplexity is 46.35393985322823
At time: 844.2702741622925 and batch: 1350, loss is 3.7157586145401003 and perplexity is 41.08974654306579
At time: 845.3122217655182 and batch: 1400, loss is 3.7476684713363646 and perplexity is 42.42205836165443
At time: 846.3538672924042 and batch: 1450, loss is 3.6659181213378904 and perplexity is 39.092010901247505
At time: 847.3939197063446 and batch: 1500, loss is 3.6749795866012573 and perplexity is 39.44785158425744
At time: 848.4348735809326 and batch: 1550, loss is 3.6885896158218383 and perplexity is 39.98840814827848
At time: 849.4748291969299 and batch: 1600, loss is 3.769446792602539 and perplexity is 43.35607329984155
At time: 850.5218303203583 and batch: 1650, loss is 3.7046989583969117 and perplexity is 40.637811803260604
At time: 851.565128326416 and batch: 1700, loss is 3.73666729927063 and perplexity is 41.9579236919294
At time: 852.616037607193 and batch: 1750, loss is 3.73147735118866 and perplexity is 41.740728350137786
At time: 853.657516002655 and batch: 1800, loss is 3.6718480157852174 and perplexity is 39.324511069056925
At time: 854.6991350650787 and batch: 1850, loss is 3.7087381887435913 and perplexity is 40.80228924342686
At time: 855.7416951656342 and batch: 1900, loss is 3.785159149169922 and perplexity is 44.04267935687371
At time: 856.7812612056732 and batch: 1950, loss is 3.7399811363220214 and perplexity is 42.09719604955688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483001567042151 and perplexity of 88.49991283004455
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea7e1b2b38>
ELAPSED
4424.9675924777985


RESULTS SO FAR:
[{'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.92103091601648}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.6813262795645527, 'dropout': 0.19794812537896078, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.05052225478255}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.8407924036871192, 'dropout': 0.37893501344260494, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.32399121066462}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.320185930278277, 'dropout': 0.14646798116639437, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.0134270296668}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.21124919513989482, 'dropout': 0.14686417520406692, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.49991283004455}]
SETTINGS FOR THIS RUN
{'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.337532812168398, 'dropout': 0.10201283915037553, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5236449241638184 and batch: 50, loss is 7.237746410369873 and perplexity is 1390.9557925614781
At time: 2.5929782390594482 and batch: 100, loss is 6.304192676544189 and perplexity is 546.8599170850433
At time: 3.6339986324310303 and batch: 150, loss is 6.037804002761841 and perplexity is 418.9719626479361
At time: 4.6758873462677 and batch: 200, loss is 5.864698696136474 and perplexity is 352.3759678705162
At time: 5.714522361755371 and batch: 250, loss is 5.766967144012451 and perplexity is 319.56706056401896
At time: 6.7527756690979 and batch: 300, loss is 5.736707487106323 and perplexity is 310.04191161735486
At time: 7.789167404174805 and batch: 350, loss is 5.64996561050415 and perplexity is 284.2816893518417
At time: 8.827035903930664 and batch: 400, loss is 5.593220233917236 and perplexity is 268.5991807250769
At time: 9.862216711044312 and batch: 450, loss is 5.514241151809692 and perplexity is 248.2015584624186
At time: 10.899546384811401 and batch: 500, loss is 5.476452360153198 and perplexity is 238.9973251799513
At time: 11.938251733779907 and batch: 550, loss is 5.416194477081299 and perplexity is 225.02116784296322
At time: 12.977141857147217 and batch: 600, loss is 5.433315935134888 and perplexity is 228.90702920949698
At time: 14.016448020935059 and batch: 650, loss is 5.49263352394104 and perplexity is 242.89603783122038
At time: 15.059611558914185 and batch: 700, loss is 5.431015281677246 and perplexity is 228.3809988001312
At time: 16.09975242614746 and batch: 750, loss is 5.374726686477661 and perplexity is 215.8808610881494
At time: 17.139426946640015 and batch: 800, loss is 5.3491463947296145 and perplexity is 210.42859822082232
At time: 18.17984676361084 and batch: 850, loss is 5.347494068145752 and perplexity is 210.08118855013538
At time: 19.219720602035522 and batch: 900, loss is 5.375297183990479 and perplexity is 216.00405572023934
At time: 20.261467933654785 and batch: 950, loss is 5.40723934173584 and perplexity is 223.0150686805776
At time: 21.304003715515137 and batch: 1000, loss is 5.366911420822143 and perplexity is 214.2002704937504
At time: 22.350662231445312 and batch: 1050, loss is 5.272915410995483 and perplexity is 194.98359191454853
At time: 23.392696857452393 and batch: 1100, loss is 5.3636830615997315 and perplexity is 213.5098701049201
At time: 24.43666100502014 and batch: 1150, loss is 5.2656587219238284 and perplexity is 193.57377809090687
At time: 25.481337785720825 and batch: 1200, loss is 5.341181364059448 and perplexity is 208.75918527064687
At time: 26.52420687675476 and batch: 1250, loss is 5.276549320220948 and perplexity is 195.6934335569285
At time: 27.56922483444214 and batch: 1300, loss is 5.291331300735473 and perplexity is 198.60765600367125
At time: 28.612473726272583 and batch: 1350, loss is 5.237800483703613 and perplexity is 188.25557548725888
At time: 29.654927968978882 and batch: 1400, loss is 5.2549405193328855 and perplexity is 191.51009436742171
At time: 30.69714879989624 and batch: 1450, loss is 5.196558446884155 and perplexity is 180.6494561161486
At time: 31.744701147079468 and batch: 1500, loss is 5.181718130111694 and perplexity is 177.98835558878426
At time: 32.788997173309326 and batch: 1550, loss is 5.168976802825927 and perplexity is 175.7349339735515
At time: 33.836567401885986 and batch: 1600, loss is 5.215769205093384 and perplexity is 184.15341826128045
At time: 34.882853269577026 and batch: 1650, loss is 5.189818630218506 and perplexity is 179.4360057112324
At time: 35.93087816238403 and batch: 1700, loss is 5.210968627929687 and perplexity is 183.27149413307455
At time: 36.977970600128174 and batch: 1750, loss is 5.224506349563598 and perplexity is 185.76944272061212
At time: 38.026610374450684 and batch: 1800, loss is 5.1802864837646485 and perplexity is 177.73372152614348
At time: 39.072848081588745 and batch: 1850, loss is 5.175178565979004 and perplexity is 176.8281869557645
At time: 40.11784243583679 and batch: 1900, loss is 5.218247156143189 and perplexity is 184.61030725788652
At time: 41.16366505622864 and batch: 1950, loss is 5.1479505348205565 and perplexity is 172.0784598669872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.86073480650436 and perplexity of 129.11904477154238
finished 1 epochs...
Completing Train Step...
At time: 44.47309350967407 and batch: 50, loss is 5.062316207885742 and perplexity is 157.95595176884905
At time: 45.50577640533447 and batch: 100, loss is 5.006837606430054 and perplexity is 149.43142716444223
At time: 46.53905177116394 and batch: 150, loss is 4.949455518722534 and perplexity is 141.09811771933227
At time: 47.571892738342285 and batch: 200, loss is 4.917488670349121 and perplexity is 136.6589861227411
At time: 48.60499978065491 and batch: 250, loss is 4.924999742507935 and perplexity is 137.68930618895024
At time: 49.63812875747681 and batch: 300, loss is 4.952363138198852 and perplexity is 141.5089743724311
At time: 50.66953206062317 and batch: 350, loss is 4.942131175994873 and perplexity is 140.0684421982952
At time: 51.701860666275024 and batch: 400, loss is 4.907836503982544 and perplexity is 135.3462762914981
At time: 52.73399329185486 and batch: 450, loss is 4.88470383644104 and perplexity is 132.25129152047927
At time: 53.767127990722656 and batch: 500, loss is 4.881047267913818 and perplexity is 131.76858866608487
At time: 54.83543658256531 and batch: 550, loss is 4.83296238899231 and perplexity is 125.58243417920211
At time: 55.8735613822937 and batch: 600, loss is 4.824082469940185 and perplexity is 124.47220897964215
At time: 56.90560531616211 and batch: 650, loss is 4.890973548889161 and perplexity is 133.0830738825905
At time: 57.93552899360657 and batch: 700, loss is 4.884810581207275 and perplexity is 132.26540940716876
At time: 58.96747064590454 and batch: 750, loss is 4.843855142593384 and perplexity is 126.95785012520186
At time: 60.00006365776062 and batch: 800, loss is 4.824243631362915 and perplexity is 124.49227071447706
At time: 61.03354096412659 and batch: 850, loss is 4.822008142471313 and perplexity is 124.21428046403227
At time: 62.06744718551636 and batch: 900, loss is 4.8391022109985355 and perplexity is 126.35585989059489
At time: 63.10183930397034 and batch: 950, loss is 4.899409427642822 and perplexity is 134.21049526709916
At time: 64.13518238067627 and batch: 1000, loss is 4.867836179733277 and perplexity is 130.0392307243317
At time: 65.16679048538208 and batch: 1050, loss is 4.796792707443237 and perplexity is 121.12132236559505
At time: 66.19862198829651 and batch: 1100, loss is 4.873083763122558 and perplexity is 130.7234160210939
At time: 67.24324059486389 and batch: 1150, loss is 4.80000410079956 and perplexity is 121.5109158096233
At time: 68.27968144416809 and batch: 1200, loss is 4.871624507904053 and perplexity is 130.5327963093147
At time: 69.31318354606628 and batch: 1250, loss is 4.8318964290618895 and perplexity is 125.44863965887015
At time: 70.3472650051117 and batch: 1300, loss is 4.841865615844727 and perplexity is 126.70551518321714
At time: 71.3816065788269 and batch: 1350, loss is 4.752487087249756 and perplexity is 115.87211050330033
At time: 72.41743588447571 and batch: 1400, loss is 4.77124810218811 and perplexity is 118.06650910768909
At time: 73.45228958129883 and batch: 1450, loss is 4.703553609848022 and perplexity is 110.33857684427034
At time: 74.48750758171082 and batch: 1500, loss is 4.693055810928345 and perplexity is 109.18632329637316
At time: 75.52216362953186 and batch: 1550, loss is 4.699712171554565 and perplexity is 109.91553108225824
At time: 76.55643463134766 and batch: 1600, loss is 4.782807950973511 and perplexity is 119.43925920467055
At time: 77.60065484046936 and batch: 1650, loss is 4.739651117324829 and perplexity is 114.39428453335084
At time: 78.63675904273987 and batch: 1700, loss is 4.7648834609985355 and perplexity is 117.31744443328515
At time: 79.67033624649048 and batch: 1750, loss is 4.774707546234131 and perplexity is 118.47566090047063
At time: 80.70582032203674 and batch: 1800, loss is 4.728823928833008 and perplexity is 113.16239702573074
At time: 81.74015831947327 and batch: 1850, loss is 4.750477027893067 and perplexity is 115.63943460792487
At time: 82.77706503868103 and batch: 1900, loss is 4.830840797424316 and perplexity is 125.31628197872418
At time: 83.81376814842224 and batch: 1950, loss is 4.756202878952027 and perplexity is 116.30346805111495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.697002748001453 and perplexity of 109.61812643300857
finished 2 epochs...
Completing Train Step...
At time: 87.09879970550537 and batch: 50, loss is 4.714223566055298 and perplexity is 111.52218793714732
At time: 88.1620614528656 and batch: 100, loss is 4.662409563064575 and perplexity is 105.8909258662037
At time: 89.19877481460571 and batch: 150, loss is 4.620879917144776 and perplexity is 101.58337777112504
At time: 90.23656845092773 and batch: 200, loss is 4.599128789901734 and perplexity is 99.3976816452135
At time: 91.27445769309998 and batch: 250, loss is 4.606345701217651 and perplexity is 100.11762064183951
At time: 92.31061673164368 and batch: 300, loss is 4.634612684249878 and perplexity is 102.98802138667864
At time: 93.3479974269867 and batch: 350, loss is 4.638605899810791 and perplexity is 103.40009696199569
At time: 94.3851797580719 and batch: 400, loss is 4.604460697174073 and perplexity is 99.92907628136574
At time: 95.4236626625061 and batch: 450, loss is 4.603835668563843 and perplexity is 99.8666372648146
At time: 96.46040368080139 and batch: 500, loss is 4.606449193954468 and perplexity is 100.12798262458905
At time: 97.49825286865234 and batch: 550, loss is 4.570435199737549 and perplexity is 96.58613488807596
At time: 98.53569769859314 and batch: 600, loss is 4.550760154724121 and perplexity is 94.70437093505723
At time: 99.57169318199158 and batch: 650, loss is 4.6138234710693355 and perplexity is 100.86908329786691
At time: 100.60933446884155 and batch: 700, loss is 4.626048049926758 and perplexity is 102.10973312149802
At time: 101.64732122421265 and batch: 750, loss is 4.586649932861328 and perplexity is 98.1650192904665
At time: 102.68484330177307 and batch: 800, loss is 4.564711074829102 and perplexity is 96.03484312429418
At time: 103.72318387031555 and batch: 850, loss is 4.571547155380249 and perplexity is 96.6935941196485
At time: 104.76218128204346 and batch: 900, loss is 4.569484367370605 and perplexity is 96.49434131189378
At time: 105.80018997192383 and batch: 950, loss is 4.644747934341431 and perplexity is 104.03713829024996
At time: 106.83803391456604 and batch: 1000, loss is 4.612349910736084 and perplexity is 100.72055607665426
At time: 107.90159440040588 and batch: 1050, loss is 4.548384523391723 and perplexity is 94.47965529059603
At time: 108.94157099723816 and batch: 1100, loss is 4.615609874725342 and perplexity is 101.04943724155774
At time: 109.97983908653259 and batch: 1150, loss is 4.5575069808959965 and perplexity is 95.34548517469828
At time: 111.02487897872925 and batch: 1200, loss is 4.626074352264404 and perplexity is 102.11241888149631
At time: 112.06560850143433 and batch: 1250, loss is 4.5989866542816165 and perplexity is 99.38355469808961
At time: 113.10447406768799 and batch: 1300, loss is 4.604527225494385 and perplexity is 99.93572461610992
At time: 114.13890671730042 and batch: 1350, loss is 4.504594068527222 and perplexity is 90.4316275534243
At time: 115.17508172988892 and batch: 1400, loss is 4.521289558410644 and perplexity is 91.95410173826407
At time: 116.21769380569458 and batch: 1450, loss is 4.450099477767944 and perplexity is 85.63546240315452
At time: 117.25658798217773 and batch: 1500, loss is 4.44664532661438 and perplexity is 85.34017484942439
At time: 118.29988551139832 and batch: 1550, loss is 4.455446691513061 and perplexity is 86.09459998418033
At time: 119.3406081199646 and batch: 1600, loss is 4.557345943450928 and perplexity is 95.33013221760058
At time: 120.37850975990295 and batch: 1650, loss is 4.503415794372558 and perplexity is 90.325137053736
At time: 121.41623115539551 and batch: 1700, loss is 4.5332466506958005 and perplexity is 93.06020513045756
At time: 122.46168851852417 and batch: 1750, loss is 4.538834209442139 and perplexity is 93.5816399106696
At time: 123.5000274181366 and batch: 1800, loss is 4.49058271408081 and perplexity is 89.17339333386121
At time: 124.53967332839966 and batch: 1850, loss is 4.527685956954956 and perplexity is 92.54416193906627
At time: 125.57766199111938 and batch: 1900, loss is 4.609479722976684 and perplexity is 100.43188363970368
At time: 126.61669945716858 and batch: 1950, loss is 4.5388995552062985 and perplexity is 93.58775527424525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.637854855559593 and perplexity of 103.32246806861507
finished 3 epochs...
Completing Train Step...
At time: 129.92952013015747 and batch: 50, loss is 4.503624048233032 and perplexity is 90.34394957104695
At time: 130.9748523235321 and batch: 100, loss is 4.454633283615112 and perplexity is 86.02459843035042
At time: 132.01772165298462 and batch: 150, loss is 4.415599479675293 and perplexity is 82.73142184914617
At time: 133.06230664253235 and batch: 200, loss is 4.406365795135498 and perplexity is 81.97102204690336
At time: 134.13391160964966 and batch: 250, loss is 4.406357450485229 and perplexity is 81.97033803024617
At time: 135.17423725128174 and batch: 300, loss is 4.438216190338135 and perplexity is 84.62385410957775
At time: 136.21736860275269 and batch: 350, loss is 4.446989555358886 and perplexity is 85.3695564473739
At time: 137.2625117301941 and batch: 400, loss is 4.4090891933441165 and perplexity is 82.19456604299688
At time: 138.31130599975586 and batch: 450, loss is 4.418857164382935 and perplexity is 83.00137420804204
At time: 139.3546061515808 and batch: 500, loss is 4.430581407546997 and perplexity is 83.98022945810744
At time: 140.40412878990173 and batch: 550, loss is 4.390249147415161 and perplexity is 80.66051283548555
At time: 141.44687032699585 and batch: 600, loss is 4.37062364578247 and perplexity is 79.09294230168133
At time: 142.4937789440155 and batch: 650, loss is 4.430574569702149 and perplexity is 83.97965521629136
At time: 143.53839635849 and batch: 700, loss is 4.449616107940674 and perplexity is 85.59407880708112
At time: 144.583331823349 and batch: 750, loss is 4.407729883193969 and perplexity is 82.08291403713197
At time: 145.63376641273499 and batch: 800, loss is 4.388638763427735 and perplexity is 80.53072297100651
At time: 146.67910027503967 and batch: 850, loss is 4.390378398895264 and perplexity is 80.67093899993947
At time: 147.72418546676636 and batch: 900, loss is 4.3847412109375 and perplexity is 80.21746112495566
At time: 148.77219033241272 and batch: 950, loss is 4.469862728118897 and perplexity is 87.3447322147645
At time: 149.81933498382568 and batch: 1000, loss is 4.443027830123901 and perplexity is 85.0320147864386
At time: 150.86437344551086 and batch: 1050, loss is 4.380598888397217 and perplexity is 79.88586179745253
At time: 151.9099645614624 and batch: 1100, loss is 4.443141384124756 and perplexity is 85.04167106016222
At time: 152.95597624778748 and batch: 1150, loss is 4.3939742088317875 and perplexity is 80.96153852118992
At time: 154.00054836273193 and batch: 1200, loss is 4.455232019424439 and perplexity is 86.07611986023697
At time: 155.0462944507599 and batch: 1250, loss is 4.4352279472351075 and perplexity is 84.37135491356665
At time: 156.0905201435089 and batch: 1300, loss is 4.43575798034668 and perplexity is 84.41608637887073
At time: 157.13469672203064 and batch: 1350, loss is 4.334036402702331 and perplexity is 76.25144778887397
At time: 158.18592810630798 and batch: 1400, loss is 4.34734016418457 and perplexity is 77.27265676128594
At time: 159.23341345787048 and batch: 1450, loss is 4.278963351249695 and perplexity is 72.16559084831687
At time: 160.27801060676575 and batch: 1500, loss is 4.279664454460144 and perplexity is 72.21620411623363
At time: 161.32351231575012 and batch: 1550, loss is 4.2878688621520995 and perplexity is 72.81113247701549
At time: 162.37004590034485 and batch: 1600, loss is 4.396782293319702 and perplexity is 81.1892048651913
At time: 163.4185712337494 and batch: 1650, loss is 4.339797506332397 and perplexity is 76.69200811986197
At time: 164.46308374404907 and batch: 1700, loss is 4.369984331130982 and perplexity is 79.04239318495571
At time: 165.5104637145996 and batch: 1750, loss is 4.3719770622253415 and perplexity is 79.20006046169603
At time: 166.5580940246582 and batch: 1800, loss is 4.325261154174805 and perplexity is 75.5852496859463
At time: 167.60429620742798 and batch: 1850, loss is 4.364429388046265 and perplexity is 78.60453445562473
At time: 168.650071144104 and batch: 1900, loss is 4.447970018386841 and perplexity is 85.45329918780534
At time: 169.69486451148987 and batch: 1950, loss is 4.382839775085449 and perplexity is 80.0650776879886
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.606422317859739 and perplexity of 100.1252916116051
finished 4 epochs...
Completing Train Step...
At time: 173.0256781578064 and batch: 50, loss is 4.349147815704345 and perplexity is 77.4124651210447
At time: 174.09330821037292 and batch: 100, loss is 4.296810960769653 and perplexity is 73.46513653054954
At time: 175.13200449943542 and batch: 150, loss is 4.265694227218628 and perplexity is 71.21434175083861
At time: 176.17330956459045 and batch: 200, loss is 4.262909936904907 and perplexity is 71.0163361293868
At time: 177.2116823196411 and batch: 250, loss is 4.254988384246826 and perplexity is 70.45599878418788
At time: 178.25881171226501 and batch: 300, loss is 4.288199548721313 and perplexity is 72.83521412213375
At time: 179.30739045143127 and batch: 350, loss is 4.294441576004028 and perplexity is 73.29127540853425
At time: 180.35061979293823 and batch: 400, loss is 4.25824164390564 and perplexity is 70.68558368992186
At time: 181.39221787452698 and batch: 450, loss is 4.275082902908325 and perplexity is 71.88609862927768
At time: 182.43733930587769 and batch: 500, loss is 4.2928653335571285 and perplexity is 73.17584158899096
At time: 183.4773142337799 and batch: 550, loss is 4.256124663352966 and perplexity is 70.53610196467508
At time: 184.51681971549988 and batch: 600, loss is 4.240204396247864 and perplexity is 69.4220399931967
At time: 185.55749821662903 and batch: 650, loss is 4.294598560333252 and perplexity is 73.30278189338749
At time: 186.5961730480194 and batch: 700, loss is 4.313316917419433 and perplexity is 74.68781184289202
At time: 187.67087960243225 and batch: 750, loss is 4.2696047067642215 and perplexity is 71.49336918757982
At time: 188.7104308605194 and batch: 800, loss is 4.253669581413269 and perplexity is 70.36314245640257
At time: 189.75103640556335 and batch: 850, loss is 4.2567488384246825 and perplexity is 70.5801425842761
At time: 190.78753399848938 and batch: 900, loss is 4.248722805976867 and perplexity is 70.01593128755002
At time: 191.82783317565918 and batch: 950, loss is 4.335038394927978 and perplexity is 76.32788943732595
At time: 192.86740803718567 and batch: 1000, loss is 4.305541019439698 and perplexity is 74.10929918035191
At time: 193.9149739742279 and batch: 1050, loss is 4.253128652572632 and perplexity is 70.32509129574298
At time: 194.9565806388855 and batch: 1100, loss is 4.308748550415039 and perplexity is 74.34738868864302
At time: 195.9956681728363 and batch: 1150, loss is 4.26367048740387 and perplexity is 71.07036818371293
At time: 197.0386016368866 and batch: 1200, loss is 4.322419023513794 and perplexity is 75.37073151902467
At time: 198.07664847373962 and batch: 1250, loss is 4.306737904548645 and perplexity is 74.19805260020348
At time: 199.11366868019104 and batch: 1300, loss is 4.304624671936035 and perplexity is 74.04142041406861
At time: 200.15399646759033 and batch: 1350, loss is 4.19823646068573 and perplexity is 66.56883071308671
At time: 201.1943392753601 and batch: 1400, loss is 4.215713148117065 and perplexity is 67.74245905590925
At time: 202.23348712921143 and batch: 1450, loss is 4.141522583961486 and perplexity is 62.89851685153146
At time: 203.27481055259705 and batch: 1500, loss is 4.148666715621948 and perplexity is 63.34948109307679
At time: 204.3150770664215 and batch: 1550, loss is 4.160618438720703 and perplexity is 64.11115916553698
At time: 205.3533821105957 and batch: 1600, loss is 4.266875376701355 and perplexity is 71.29850622939063
At time: 206.3961579799652 and batch: 1650, loss is 4.216190385818481 and perplexity is 67.77479602695448
At time: 207.43652367591858 and batch: 1700, loss is 4.2450043487548825 and perplexity is 69.75606349526528
At time: 208.48101902008057 and batch: 1750, loss is 4.243739361763001 and perplexity is 69.66787877036319
At time: 209.52018117904663 and batch: 1800, loss is 4.197151002883911 and perplexity is 66.4966122585644
At time: 210.55990743637085 and batch: 1850, loss is 4.230489683151245 and perplexity is 68.7508900848256
At time: 211.6004285812378 and batch: 1900, loss is 4.319201889038086 and perplexity is 75.12864336407036
At time: 212.63914728164673 and batch: 1950, loss is 4.253234906196594 and perplexity is 70.33256398854195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607807673964389 and perplexity of 100.26409692076064
Annealing...
finished 5 epochs...
Completing Train Step...
At time: 215.9694402217865 and batch: 50, loss is 4.252005105018616 and perplexity is 70.24612208257213
At time: 217.0085117816925 and batch: 100, loss is 4.223836932182312 and perplexity is 68.29502559201647
At time: 218.0486912727356 and batch: 150, loss is 4.195409107208252 and perplexity is 66.38088292070398
At time: 219.0846495628357 and batch: 200, loss is 4.1895225143432615 and perplexity is 65.99127354986302
At time: 220.12347221374512 and batch: 250, loss is 4.182791795730591 and perplexity is 65.54859629592366
At time: 221.16448163986206 and batch: 300, loss is 4.205817561149598 and perplexity is 67.0754135077774
At time: 222.2031171321869 and batch: 350, loss is 4.2093170499801635 and perplexity is 67.310554364585
At time: 223.2447965145111 and batch: 400, loss is 4.165166459083557 and perplexity is 64.40340208253562
At time: 224.2864055633545 and batch: 450, loss is 4.180887203216553 and perplexity is 65.42387174254102
At time: 225.3274848461151 and batch: 500, loss is 4.195181040763855 and perplexity is 66.36574539500681
At time: 226.3686761856079 and batch: 550, loss is 4.157026391029358 and perplexity is 63.88128193642378
At time: 227.4101357460022 and batch: 600, loss is 4.126165618896485 and perplexity is 61.939965583137
At time: 228.45156240463257 and batch: 650, loss is 4.168099017143249 and perplexity is 64.59254600059353
At time: 229.49315190315247 and batch: 700, loss is 4.186690759658814 and perplexity is 65.80466678883775
At time: 230.53632497787476 and batch: 750, loss is 4.1279510879516605 and perplexity is 62.05065626295021
At time: 231.58049893379211 and batch: 800, loss is 4.108301434516907 and perplexity is 60.843283448532915
At time: 232.62177157402039 and batch: 850, loss is 4.1057200574874875 and perplexity is 60.686426534762894
At time: 233.66074013710022 and batch: 900, loss is 4.089901947975159 and perplexity is 59.73403437396607
At time: 234.70270371437073 and batch: 950, loss is 4.171033325195313 and perplexity is 64.78235877681195
At time: 235.74181127548218 and batch: 1000, loss is 4.135060043334961 and perplexity is 62.493343266559776
At time: 236.78250360488892 and batch: 1050, loss is 4.078847346305847 and perplexity is 59.07733488112282
At time: 237.8232865333557 and batch: 1100, loss is 4.121394124031067 and perplexity is 61.64512333392528
At time: 238.86244320869446 and batch: 1150, loss is 4.074911932945252 and perplexity is 58.84529802806123
At time: 239.94989609718323 and batch: 1200, loss is 4.125891752243042 and perplexity is 61.923004614676266
At time: 240.98789834976196 and batch: 1250, loss is 4.097837653160095 and perplexity is 60.209951933397086
At time: 242.02893090248108 and batch: 1300, loss is 4.100024156570434 and perplexity is 60.341745229374965
At time: 243.0727469921112 and batch: 1350, loss is 3.9833726835250856 and perplexity is 53.697834967596485
At time: 244.11654353141785 and batch: 1400, loss is 3.9868128442764283 and perplexity is 53.88288226561165
At time: 245.15652298927307 and batch: 1450, loss is 3.9125075912475586 and perplexity is 50.02423516250442
At time: 246.19666194915771 and batch: 1500, loss is 3.9100466060638426 and perplexity is 49.90127762134344
At time: 247.23526191711426 and batch: 1550, loss is 3.9170043992996217 and perplexity is 50.249691082061496
At time: 248.27472043037415 and batch: 1600, loss is 4.00815936088562 and perplexity is 55.045458436664305
At time: 249.31519389152527 and batch: 1650, loss is 3.951923813819885 and perplexity is 52.035376980894355
At time: 250.35610938072205 and batch: 1700, loss is 3.966005492210388 and perplexity is 52.77330586926333
At time: 251.3967845439911 and batch: 1750, loss is 3.9513289403915404 and perplexity is 52.00443172296292
At time: 252.43706059455872 and batch: 1800, loss is 3.8983017921447756 and perplexity is 49.31862467419089
At time: 253.4782817363739 and batch: 1850, loss is 3.9231454515457154 and perplexity is 50.559226524228094
At time: 254.52053499221802 and batch: 1900, loss is 4.002143683433533 and perplexity is 54.71531672214817
At time: 255.56418085098267 and batch: 1950, loss is 3.9397946119308473 and perplexity is 51.40804161774082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507851959938227 and perplexity of 90.72672441186448
finished 6 epochs...
Completing Train Step...
At time: 258.87042260169983 and batch: 50, loss is 4.133902020454407 and perplexity is 62.42101643132248
At time: 259.9354901313782 and batch: 100, loss is 4.10054714679718 and perplexity is 60.37331162613373
At time: 260.97668623924255 and batch: 150, loss is 4.0692883968353275 and perplexity is 58.5153080944922
At time: 262.01716899871826 and batch: 200, loss is 4.064101896286011 and perplexity is 58.212604082734146
At time: 263.0595107078552 and batch: 250, loss is 4.056696395874024 and perplexity is 57.783102917614194
At time: 264.1026134490967 and batch: 300, loss is 4.0817957830429075 and perplexity is 59.25177770605741
At time: 265.1447765827179 and batch: 350, loss is 4.090770950317383 and perplexity is 59.785965950810414
At time: 266.18571162223816 and batch: 400, loss is 4.0502981758117675 and perplexity is 57.41457413061768
At time: 267.25838685035706 and batch: 450, loss is 4.072985095977783 and perplexity is 58.73202189982145
At time: 268.29902482032776 and batch: 500, loss is 4.088446078300476 and perplexity is 59.647132678895204
At time: 269.33946990966797 and batch: 550, loss is 4.052448859214783 and perplexity is 57.538187581342825
At time: 270.37920594215393 and batch: 600, loss is 4.028303551673889 and perplexity is 56.16554843033331
At time: 271.42162704467773 and batch: 650, loss is 4.069567074775696 and perplexity is 58.531617292433296
At time: 272.4685146808624 and batch: 700, loss is 4.0935400152206425 and perplexity is 59.95174659358208
At time: 273.511883020401 and batch: 750, loss is 4.039569749832153 and perplexity is 56.801898520894696
At time: 274.55661058425903 and batch: 800, loss is 4.02203718662262 and perplexity is 55.814695036376044
At time: 275.60244631767273 and batch: 850, loss is 4.023289370536804 and perplexity is 55.884629075677395
At time: 276.650146484375 and batch: 900, loss is 4.006766290664673 and perplexity is 54.96882963476123
At time: 277.69218945503235 and batch: 950, loss is 4.093304600715637 and perplexity is 59.937634743965766
At time: 278.73593163490295 and batch: 1000, loss is 4.056155643463135 and perplexity is 57.75186501215038
At time: 279.77869749069214 and batch: 1050, loss is 4.003189134597778 and perplexity is 54.772548825189006
At time: 280.82177901268005 and batch: 1100, loss is 4.04818482875824 and perplexity is 57.293365332789314
At time: 281.86673974990845 and batch: 1150, loss is 4.008048639297486 and perplexity is 55.03936405348273
At time: 282.9088191986084 and batch: 1200, loss is 4.059537491798401 and perplexity is 57.947503684401006
At time: 283.95687913894653 and batch: 1250, loss is 4.0387579870224 and perplexity is 56.75580756214617
At time: 285.0046799182892 and batch: 1300, loss is 4.042744860649109 and perplexity is 56.98253746588945
At time: 286.0487937927246 and batch: 1350, loss is 3.9268844985961913 and perplexity is 50.74862371288252
At time: 287.0921802520752 and batch: 1400, loss is 3.936215319633484 and perplexity is 51.22436612059594
At time: 288.1359522342682 and batch: 1450, loss is 3.863689522743225 and perplexity is 47.640799322827434
At time: 289.18312096595764 and batch: 1500, loss is 3.867287583351135 and perplexity is 47.81252255623976
At time: 290.2245945930481 and batch: 1550, loss is 3.874916424751282 and perplexity is 48.178671578374335
At time: 291.2674467563629 and batch: 1600, loss is 3.97118266582489 and perplexity is 53.04723090285084
At time: 292.3086693286896 and batch: 1650, loss is 3.918371114730835 and perplexity is 50.31841506264191
At time: 293.3549680709839 and batch: 1700, loss is 3.937375612258911 and perplexity is 51.283835869331384
At time: 294.3961844444275 and batch: 1750, loss is 3.927932119369507 and perplexity is 50.801816883571625
At time: 295.4440791606903 and batch: 1800, loss is 3.8776751136779786 and perplexity is 48.311765043487284
At time: 296.4896025657654 and batch: 1850, loss is 3.9072430610656737 and perplexity is 49.76157306956945
At time: 297.5318639278412 and batch: 1900, loss is 3.990475544929504 and perplexity is 54.08060100491408
At time: 298.57521772384644 and batch: 1950, loss is 3.931207709312439 and perplexity is 50.96849564063684
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.505654694313227 and perplexity of 90.52759255195774
finished 7 epochs...
Completing Train Step...
At time: 301.93954277038574 and batch: 50, loss is 4.075569105148316 and perplexity is 58.883982231905776
At time: 302.98590445518494 and batch: 100, loss is 4.039393229484558 and perplexity is 56.79187271492914
At time: 304.0304546356201 and batch: 150, loss is 4.009379143714905 and perplexity is 55.11264290859794
At time: 305.0758047103882 and batch: 200, loss is 4.004277310371399 and perplexity is 54.83218342645965
At time: 306.12589478492737 and batch: 250, loss is 3.9963362646102905 and perplexity is 54.398482845868855
At time: 307.17911744117737 and batch: 300, loss is 4.021145057678223 and perplexity is 55.764923336099706
At time: 308.22597670555115 and batch: 350, loss is 4.032124614715576 and perplexity is 56.3805710775816
At time: 309.2740333080292 and batch: 400, loss is 3.9915281534194946 and perplexity is 54.13755667542797
At time: 310.3215184211731 and batch: 450, loss is 4.016618175506592 and perplexity is 55.51305262349135
At time: 311.3693370819092 and batch: 500, loss is 4.033582639694214 and perplexity is 56.462835315606185
At time: 312.41704845428467 and batch: 550, loss is 3.998708734512329 and perplexity is 54.52769482429511
At time: 313.46188163757324 and batch: 600, loss is 3.976698150634766 and perplexity is 53.34062044813556
At time: 314.5121371746063 and batch: 650, loss is 4.017944993972779 and perplexity is 55.58675725234515
At time: 315.56261563301086 and batch: 700, loss is 4.04337751865387 and perplexity is 57.01859933055965
At time: 316.6073627471924 and batch: 750, loss is 3.9911886835098267 and perplexity is 54.1191817230019
At time: 317.6499788761139 and batch: 800, loss is 3.974001712799072 and perplexity is 53.19698452068322
At time: 318.69206523895264 and batch: 850, loss is 3.976055064201355 and perplexity is 53.30632884618945
At time: 319.76273941993713 and batch: 900, loss is 3.9588298416137695 and perplexity is 52.39597846935454
At time: 320.8118939399719 and batch: 950, loss is 4.047729601860047 and perplexity is 57.26728978739695
At time: 321.8573830127716 and batch: 1000, loss is 4.01063452243805 and perplexity is 55.18187359415434
At time: 322.90463614463806 and batch: 1050, loss is 3.9587360429763794 and perplexity is 52.39106402845693
At time: 323.95036935806274 and batch: 1100, loss is 4.0042587089538575 and perplexity is 54.831163479607284
At time: 324.9980888366699 and batch: 1150, loss is 3.9664700508117674 and perplexity is 52.797827857937484
At time: 326.0440306663513 and batch: 1200, loss is 4.018120484352112 and perplexity is 55.5965130494605
At time: 327.086772441864 and batch: 1250, loss is 4.000132331848144 and perplexity is 54.60537558531818
At time: 328.13116455078125 and batch: 1300, loss is 4.004609303474426 and perplexity is 54.85039035530134
At time: 329.1743223667145 and batch: 1350, loss is 3.888653335571289 and perplexity is 48.845064302842815
At time: 330.21673488616943 and batch: 1400, loss is 3.9017038440704344 and perplexity is 49.48669492599333
At time: 331.2608997821808 and batch: 1450, loss is 3.8292872667312623 and perplexity is 46.029719627618114
At time: 332.3034780025482 and batch: 1500, loss is 3.8348629903793334 and perplexity is 46.28708545746814
At time: 333.3480923175812 and batch: 1550, loss is 3.842925510406494 and perplexity is 46.66178449044703
At time: 334.3915865421295 and batch: 1600, loss is 3.941173849105835 and perplexity is 51.47899441895611
At time: 335.4364960193634 and batch: 1650, loss is 3.889434061050415 and perplexity is 48.883213779269944
At time: 336.4808988571167 and batch: 1700, loss is 3.910032000541687 and perplexity is 49.90054879245002
At time: 337.5298044681549 and batch: 1750, loss is 3.902586727142334 and perplexity is 49.53040518391185
At time: 338.5724849700928 and batch: 1800, loss is 3.853107385635376 and perplexity is 47.139315915288904
At time: 339.6161983013153 and batch: 1850, loss is 3.884107575416565 and perplexity is 48.623530257578246
At time: 340.65971660614014 and batch: 1900, loss is 3.969375739097595 and perplexity is 52.951464990572894
At time: 341.7050242424011 and batch: 1950, loss is 3.910832624435425 and perplexity is 49.94051636148433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.507793479742006 and perplexity of 90.721418850355
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 345.00366592407227 and batch: 50, loss is 4.047217202186585 and perplexity is 57.2379535633875
At time: 346.068062543869 and batch: 100, loss is 4.02950692653656 and perplexity is 56.233177322755886
At time: 347.1103398799896 and batch: 150, loss is 4.006066675186157 and perplexity is 54.93038604014785
At time: 348.1528329849243 and batch: 200, loss is 4.0050102853775025 and perplexity is 54.87238877940071
At time: 349.1914050579071 and batch: 250, loss is 3.999352526664734 and perplexity is 54.56281062873853
At time: 350.22749161720276 and batch: 300, loss is 4.018716707229614 and perplexity is 55.629670846186166
At time: 351.2711296081543 and batch: 350, loss is 4.033094925880432 and perplexity is 56.43530432502539
At time: 352.31250071525574 and batch: 400, loss is 3.991339750289917 and perplexity is 54.127357951088584
At time: 353.35140776634216 and batch: 450, loss is 4.01710015296936 and perplexity is 55.539815112685574
At time: 354.39003562927246 and batch: 500, loss is 4.034467391967773 and perplexity is 56.51281304321717
At time: 355.43649768829346 and batch: 550, loss is 3.998446798324585 and perplexity is 54.51341391821108
At time: 356.4790461063385 and batch: 600, loss is 3.9686454725265503 and perplexity is 52.91281042159005
At time: 357.52053713798523 and batch: 650, loss is 4.006544399261474 and perplexity is 54.95663387713833
At time: 358.5611126422882 and batch: 700, loss is 4.026592741012573 and perplexity is 56.069541959143834
At time: 359.6032660007477 and batch: 750, loss is 3.972311086654663 and perplexity is 53.10712428928044
At time: 360.6438944339752 and batch: 800, loss is 3.9526669549942017 and perplexity is 52.07406098410743
At time: 361.68465185165405 and batch: 850, loss is 3.952201523780823 and perplexity is 52.04982973014643
At time: 362.72419452667236 and batch: 900, loss is 3.9293005752563475 and perplexity is 50.87138451821128
At time: 363.7629659175873 and batch: 950, loss is 4.021538324356079 and perplexity is 55.78685813507108
At time: 364.8037085533142 and batch: 1000, loss is 3.982095203399658 and perplexity is 53.629280848232504
At time: 365.8476839065552 and batch: 1050, loss is 3.92634024143219 and perplexity is 50.72101092577379
At time: 366.8890299797058 and batch: 1100, loss is 3.9650018310546873 and perplexity is 52.72036592343207
At time: 367.9288113117218 and batch: 1150, loss is 3.925407609939575 and perplexity is 50.673728965396954
At time: 368.96615386009216 and batch: 1200, loss is 3.970140962600708 and perplexity is 52.9920002033787
At time: 370.0114965438843 and batch: 1250, loss is 3.9464751863479615 and perplexity is 51.75262659663334
At time: 371.04926323890686 and batch: 1300, loss is 3.947307815551758 and perplexity is 51.79573528919856
At time: 372.0891921520233 and batch: 1350, loss is 3.8281656646728517 and perplexity is 45.97812154100495
At time: 373.13031482696533 and batch: 1400, loss is 3.8450602865219117 and perplexity is 46.76150335433397
At time: 374.17009115219116 and batch: 1450, loss is 3.765811505317688 and perplexity is 43.19874765307414
At time: 375.21614933013916 and batch: 1500, loss is 3.76955132484436 and perplexity is 43.360605644264076
At time: 376.2553310394287 and batch: 1550, loss is 3.778317651748657 and perplexity is 43.742389865797904
At time: 377.2938599586487 and batch: 1600, loss is 3.8702564430236817 and perplexity is 47.954682147821245
At time: 378.3331027030945 and batch: 1650, loss is 3.8113340663909914 and perplexity is 45.21071274508746
At time: 379.37295031547546 and batch: 1700, loss is 3.823685426712036 and perplexity is 45.77258937581009
At time: 380.41251969337463 and batch: 1750, loss is 3.8177066707611083 and perplexity is 45.49974268931883
At time: 381.45331048965454 and batch: 1800, loss is 3.7637992763519286 and perplexity is 43.111909280407694
At time: 382.49327087402344 and batch: 1850, loss is 3.791649146080017 and perplexity is 44.329445759795775
At time: 383.53005480766296 and batch: 1900, loss is 3.8734839010238646 and perplexity is 48.10970389889569
At time: 384.56815099716187 and batch: 1950, loss is 3.8163729429244997 and perplexity is 45.43909886610272
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482616619731105 and perplexity of 88.46585158288619
finished 9 epochs...
Completing Train Step...
At time: 387.8770079612732 and batch: 50, loss is 4.025370087623596 and perplexity is 56.00103023522956
At time: 388.9229784011841 and batch: 100, loss is 3.9987233114242553 and perplexity is 54.52848967549334
At time: 389.96783804893494 and batch: 150, loss is 3.9710459995269773 and perplexity is 53.03998162956578
At time: 391.00973987579346 and batch: 200, loss is 3.966308579444885 and perplexity is 52.789303208766746
At time: 392.0497307777405 and batch: 250, loss is 3.959087820053101 and perplexity is 52.40949724580875
At time: 393.0915095806122 and batch: 300, loss is 3.975548267364502 and perplexity is 53.279320211869255
At time: 394.1308550834656 and batch: 350, loss is 3.9908421993255616 and perplexity is 54.10043353063315
At time: 395.17134165763855 and batch: 400, loss is 3.9507795190811157 and perplexity is 51.975867227627575
At time: 396.2112081050873 and batch: 450, loss is 3.9783405113220214 and perplexity is 53.42829696471757
At time: 397.2561414241791 and batch: 500, loss is 3.9960718059539797 and perplexity is 54.38409859829332
At time: 398.2967357635498 and batch: 550, loss is 3.9602902364730834 and perplexity is 52.47255318801307
At time: 399.3642592430115 and batch: 600, loss is 3.932748293876648 and perplexity is 51.04707743368828
At time: 400.40300369262695 and batch: 650, loss is 3.97100510597229 and perplexity is 53.037812680524716
At time: 401.44349360466003 and batch: 700, loss is 3.993848805427551 and perplexity is 54.26333699476503
At time: 402.48158407211304 and batch: 750, loss is 3.941819705963135 and perplexity is 51.512253219564606
At time: 403.5270941257477 and batch: 800, loss is 3.923127112388611 and perplexity is 50.5582993191319
At time: 404.56578493118286 and batch: 850, loss is 3.9236304426193236 and perplexity is 50.58375324492043
At time: 405.60510206222534 and batch: 900, loss is 3.902414379119873 and perplexity is 49.52186945210611
At time: 406.6460416316986 and batch: 950, loss is 3.9959811878204348 and perplexity is 54.37917063606856
At time: 407.68483304977417 and batch: 1000, loss is 3.9573016214370726 and perplexity is 52.31596703099907
At time: 408.7274100780487 and batch: 1050, loss is 3.9025952768325807 and perplexity is 49.53082865534425
At time: 409.7750267982483 and batch: 1100, loss is 3.9433365058898926 and perplexity is 51.59044628810404
At time: 410.81846928596497 and batch: 1150, loss is 3.9062854528427122 and perplexity is 49.7139437867467
At time: 411.8548080921173 and batch: 1200, loss is 3.952894716262817 and perplexity is 52.085922789077735
At time: 412.896005153656 and batch: 1250, loss is 3.9315158224105833 and perplexity is 50.984202121298374
At time: 413.9378116130829 and batch: 1300, loss is 3.933955750465393 and perplexity is 51.10875179073296
At time: 414.9794225692749 and batch: 1350, loss is 3.8157541084289552 and perplexity is 45.410988283074246
At time: 416.01919865608215 and batch: 1400, loss is 3.834781999588013 and perplexity is 46.283336781595175
At time: 417.06002974510193 and batch: 1450, loss is 3.756645693778992 and perplexity is 42.804605150717485
At time: 418.1030123233795 and batch: 1500, loss is 3.7622893190383913 and perplexity is 43.04686125991528
At time: 419.1487560272217 and batch: 1550, loss is 3.772651071548462 and perplexity is 43.495221067768526
At time: 420.1873152256012 and batch: 1600, loss is 3.866523337364197 and perplexity is 47.775995987170525
At time: 421.22713470458984 and batch: 1650, loss is 3.809501972198486 and perplexity is 45.12795829095316
At time: 422.27331590652466 and batch: 1700, loss is 3.824176301956177 and perplexity is 45.795063522344705
At time: 423.315411567688 and batch: 1750, loss is 3.8194206380844116 and perplexity is 45.5777946316387
At time: 424.3557164669037 and batch: 1800, loss is 3.7678348207473755 and perplexity is 43.286240829041915
At time: 425.394535779953 and batch: 1850, loss is 3.7969562673568724 and perplexity is 44.565332891730165
At time: 426.43484377861023 and batch: 1900, loss is 3.8793069982528685 and perplexity is 48.39066863091074
At time: 427.4764404296875 and batch: 1950, loss is 3.8224296951293946 and perplexity is 45.71514736313452
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482559275072674 and perplexity of 88.46077868429761
finished 10 epochs...
Completing Train Step...
At time: 430.80451560020447 and batch: 50, loss is 4.008961033821106 and perplexity is 55.08960458393582
At time: 431.87413716316223 and batch: 100, loss is 3.980306749343872 and perplexity is 53.533453060730835
At time: 432.9169623851776 and batch: 150, loss is 3.9523042392730714 and perplexity is 52.055176328613165
At time: 433.96302700042725 and batch: 200, loss is 3.946190147399902 and perplexity is 51.73787718456724
At time: 435.0083227157593 and batch: 250, loss is 3.938768858909607 and perplexity is 51.35533669947116
At time: 436.05539536476135 and batch: 300, loss is 3.955236568450928 and perplexity is 52.208043259564796
At time: 437.1016933917999 and batch: 350, loss is 3.970995283126831 and perplexity is 53.03729170084603
At time: 438.1541883945465 and batch: 400, loss is 3.931220326423645 and perplexity is 50.96913871987123
At time: 439.2023642063141 and batch: 450, loss is 3.9593691778182984 and perplexity is 52.42424513944887
At time: 440.2484428882599 and batch: 500, loss is 3.97718692779541 and perplexity is 53.366698497803554
At time: 441.29537081718445 and batch: 550, loss is 3.9415997505187987 and perplexity is 51.500924065019234
At time: 442.3457067012787 and batch: 600, loss is 3.9148762941360475 and perplexity is 50.14286816052246
At time: 443.3910458087921 and batch: 650, loss is 3.9531842947006224 and perplexity is 52.10100793329147
At time: 444.4375853538513 and batch: 700, loss is 3.9768050622940065 and perplexity is 53.346323487227856
At time: 445.4838287830353 and batch: 750, loss is 3.925982403755188 and perplexity is 50.70286428401862
At time: 446.5266664028168 and batch: 800, loss is 3.9075214052200318 and perplexity is 49.775425840374474
At time: 447.57080245018005 and batch: 850, loss is 3.908339776992798 and perplexity is 49.81617731651416
At time: 448.6155881881714 and batch: 900, loss is 3.8876616191864013 and perplexity is 48.79664786390882
At time: 449.66241478919983 and batch: 950, loss is 3.9820540380477905 and perplexity is 53.62707322545507
At time: 450.70594096183777 and batch: 1000, loss is 3.943454747200012 and perplexity is 51.59654677072022
At time: 451.7766888141632 and batch: 1050, loss is 3.88931809425354 and perplexity is 48.877545278232304
At time: 452.82267570495605 and batch: 1100, loss is 3.9307622575759886 and perplexity is 50.94579669176788
At time: 453.8660044670105 and batch: 1150, loss is 3.8949087381362917 and perplexity is 49.151567494338934
At time: 454.9165804386139 and batch: 1200, loss is 3.94180260181427 and perplexity is 51.511372153852136
At time: 455.96278500556946 and batch: 1250, loss is 3.921655869483948 and perplexity is 50.483970471289204
At time: 457.0074145793915 and batch: 1300, loss is 3.924844708442688 and perplexity is 50.64521267419394
At time: 458.05496740341187 and batch: 1350, loss is 3.8068099355697633 and perplexity is 45.00663555015494
At time: 459.097665309906 and batch: 1400, loss is 3.8268693685531616 and perplexity is 45.918558894215344
At time: 460.1427755355835 and batch: 1450, loss is 3.7492223501205446 and perplexity is 42.488028339524426
At time: 461.1863794326782 and batch: 1500, loss is 3.7559573602676393 and perplexity is 42.775151444701415
At time: 462.2341573238373 and batch: 1550, loss is 3.7667809009552 and perplexity is 43.24064463468964
At time: 463.27950978279114 and batch: 1600, loss is 3.8614398431777954 and perplexity is 47.53374325618429
At time: 464.32387709617615 and batch: 1650, loss is 3.804994568824768 and perplexity is 44.92500611677031
At time: 465.3714499473572 and batch: 1700, loss is 3.820690689086914 and perplexity is 45.63571753013417
At time: 466.4173192977905 and batch: 1750, loss is 3.8165048265457155 and perplexity is 45.44509193419104
At time: 467.4632725715637 and batch: 1800, loss is 3.765998182296753 and perplexity is 43.20681261753359
At time: 468.5114233493805 and batch: 1850, loss is 3.795696187019348 and perplexity is 44.50921235763453
At time: 469.5577893257141 and batch: 1900, loss is 3.8783728075027466 and perplexity is 48.345483624877
At time: 470.6087124347687 and batch: 1950, loss is 3.8215104961395263 and perplexity is 45.67314535291672
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483498648710029 and perplexity of 88.54391544986295
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 473.9484853744507 and batch: 50, loss is 4.000804200172424 and perplexity is 54.64207553489561
At time: 474.9891834259033 and batch: 100, loss is 3.9795773363113405 and perplexity is 53.49441929998946
At time: 476.03498697280884 and batch: 150, loss is 3.955946478843689 and perplexity is 52.245119450890144
At time: 477.0797555446625 and batch: 200, loss is 3.951818375587463 and perplexity is 52.02989075195631
At time: 478.11993503570557 and batch: 250, loss is 3.947222213745117 and perplexity is 51.791301670447105
At time: 479.18528866767883 and batch: 300, loss is 3.962464871406555 and perplexity is 52.58678599753565
At time: 480.2249176502228 and batch: 350, loss is 3.9803364658355713 and perplexity is 53.535043910781475
At time: 481.26260590553284 and batch: 400, loss is 3.943193545341492 and perplexity is 51.58307141678084
At time: 482.30200719833374 and batch: 450, loss is 3.9700326538085937 and perplexity is 52.986261014652875
At time: 483.3423001766205 and batch: 500, loss is 3.98874249458313 and perplexity is 53.98695776827007
At time: 484.3823866844177 and batch: 550, loss is 3.9526219081878664 and perplexity is 52.07171526680112
At time: 485.4296524524689 and batch: 600, loss is 3.921880383491516 and perplexity is 50.49530610227402
At time: 486.471054315567 and batch: 650, loss is 3.9574620819091795 and perplexity is 52.32436234930795
At time: 487.51091027259827 and batch: 700, loss is 3.9765538454055784 and perplexity is 53.332923673032596
At time: 488.5501174926758 and batch: 750, loss is 3.9264020776748656 and perplexity is 50.72414741948764
At time: 489.58871722221375 and batch: 800, loss is 3.9074747371673584 and perplexity is 49.7731029723818
At time: 490.62891483306885 and batch: 850, loss is 3.908875751495361 and perplexity is 49.84288467396294
At time: 491.66792154312134 and batch: 900, loss is 3.88133514881134 and perplexity is 48.488911784796976
At time: 492.70895075798035 and batch: 950, loss is 3.9786404752731324 and perplexity is 53.444325931712186
At time: 493.7519791126251 and batch: 1000, loss is 3.9395528411865235 and perplexity is 51.3956141596131
At time: 494.7949559688568 and batch: 1050, loss is 3.8866364097595216 and perplexity is 48.74664671572234
At time: 495.83468985557556 and batch: 1100, loss is 3.923507151603699 and perplexity is 50.57751710704653
At time: 496.87618374824524 and batch: 1150, loss is 3.8894898509979248 and perplexity is 48.88594104727716
At time: 497.91824650764465 and batch: 1200, loss is 3.932440118789673 and perplexity is 51.0313484199299
At time: 498.9595685005188 and batch: 1250, loss is 3.9083774280548096 and perplexity is 49.8180529838057
At time: 500.00313115119934 and batch: 1300, loss is 3.907737488746643 and perplexity is 49.7861826520717
At time: 501.04624104499817 and batch: 1350, loss is 3.7853293800354004 and perplexity is 44.050177418481276
At time: 502.0877857208252 and batch: 1400, loss is 3.8049753141403198 and perplexity is 44.92414110828146
At time: 503.12806248664856 and batch: 1450, loss is 3.72636785030365 and perplexity is 41.52799799746682
At time: 504.17030692100525 and batch: 1500, loss is 3.732155213356018 and perplexity is 41.76903240276374
At time: 505.21249079704285 and batch: 1550, loss is 3.7437594509124756 and perplexity is 42.25655336105816
At time: 506.25377464294434 and batch: 1600, loss is 3.8365113639831545 and perplexity is 46.363446786042886
At time: 507.29455280303955 and batch: 1650, loss is 3.777937903404236 and perplexity is 43.72578191928502
At time: 508.3372948169708 and batch: 1700, loss is 3.7889516830444334 and perplexity is 44.210029850879785
At time: 509.37833881378174 and batch: 1750, loss is 3.7853211402893066 and perplexity is 44.04981445769931
At time: 510.4202330112457 and batch: 1800, loss is 3.736775460243225 and perplexity is 41.96246214720144
At time: 511.46268820762634 and batch: 1850, loss is 3.7656498336791993 and perplexity is 43.191764205288344
At time: 512.5060114860535 and batch: 1900, loss is 3.848343434333801 and perplexity is 46.91528058030276
At time: 513.5471699237823 and batch: 1950, loss is 3.793563361167908 and perplexity is 44.41438312196134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475641578851744 and perplexity of 87.85094564169685
finished 12 epochs...
Completing Train Step...
At time: 516.8732852935791 and batch: 50, loss is 3.995460658073425 and perplexity is 54.350872025907925
At time: 517.9391257762909 and batch: 100, loss is 3.9679779958724977 and perplexity is 52.877504140303394
At time: 518.9800882339478 and batch: 150, loss is 3.9428216409683228 and perplexity is 51.56389101379839
At time: 520.021470785141 and batch: 200, loss is 3.9374962282180785 and perplexity is 51.29002189144355
At time: 521.0679881572723 and batch: 250, loss is 3.9317083501815797 and perplexity is 50.99401894106371
At time: 522.1099896430969 and batch: 300, loss is 3.946019902229309 and perplexity is 51.72906981056756
At time: 523.1526536941528 and batch: 350, loss is 3.963239622116089 and perplexity is 52.62754343368695
At time: 524.1933298110962 and batch: 400, loss is 3.926212821006775 and perplexity is 50.71454844471894
At time: 525.2415244579315 and batch: 450, loss is 3.9537612771987916 and perplexity is 52.131077977116234
At time: 526.2865839004517 and batch: 500, loss is 3.9730137252807616 and perplexity is 53.144452518719284
At time: 527.335366487503 and batch: 550, loss is 3.937549705505371 and perplexity is 51.29276481602091
At time: 528.3776459693909 and batch: 600, loss is 3.908384237289429 and perplexity is 49.818392207771666
At time: 529.4194812774658 and batch: 650, loss is 3.9439818906784057 and perplexity is 51.623752723948435
At time: 530.459007024765 and batch: 700, loss is 3.9653913164138794 and perplexity is 52.74090373341902
At time: 531.5418989658356 and batch: 750, loss is 3.9154592418670653 and perplexity is 50.1721073533759
At time: 532.582578420639 and batch: 800, loss is 3.8964338207244875 and perplexity is 49.22658488342393
At time: 533.6231791973114 and batch: 850, loss is 3.8979750156402586 and perplexity is 49.302511139317964
At time: 534.668206691742 and batch: 900, loss is 3.871672568321228 and perplexity is 48.02264009347261
At time: 535.7169806957245 and batch: 950, loss is 3.9695823526382448 and perplexity is 52.96240661054169
At time: 536.7572202682495 and batch: 1000, loss is 3.9308599424362183 and perplexity is 50.95077356787577
At time: 537.7951095104218 and batch: 1050, loss is 3.878227071762085 and perplexity is 48.33843847339094
At time: 538.833997964859 and batch: 1100, loss is 3.9160807514190674 and perplexity is 50.2032994894413
At time: 539.8738164901733 and batch: 1150, loss is 3.8832244634628297 and perplexity is 48.580609191617654
At time: 540.9143130779266 and batch: 1200, loss is 3.9267025136947633 and perplexity is 50.739389069906814
At time: 541.9555592536926 and batch: 1250, loss is 3.9040212488174437 and perplexity is 49.60150861123562
At time: 542.99738073349 and batch: 1300, loss is 3.904119601249695 and perplexity is 49.60638728016142
At time: 544.0392060279846 and batch: 1350, loss is 3.782632689476013 and perplexity is 43.93154774654666
At time: 545.080114364624 and batch: 1400, loss is 3.8037530374526978 and perplexity is 44.869264921667074
At time: 546.1208562850952 and batch: 1450, loss is 3.725976977348328 and perplexity is 41.51176899810603
At time: 547.1638340950012 and batch: 1500, loss is 3.732908163070679 and perplexity is 41.80049422689242
At time: 548.2061967849731 and batch: 1550, loss is 3.745676693916321 and perplexity is 42.33764715577103
At time: 549.2495648860931 and batch: 1600, loss is 3.8390267992019655 and perplexity is 46.4802178363887
At time: 550.2909219264984 and batch: 1650, loss is 3.7807072496414182 and perplexity is 43.84704157640079
At time: 551.3391036987305 and batch: 1700, loss is 3.79269211769104 and perplexity is 44.375704232199084
At time: 552.3805456161499 and batch: 1750, loss is 3.789978823661804 and perplexity is 44.25546309740683
At time: 553.4295947551727 and batch: 1800, loss is 3.741778678894043 and perplexity is 42.17293560376134
At time: 554.4738564491272 and batch: 1850, loss is 3.7709376430511474 and perplexity is 43.42075892748797
At time: 555.520886182785 and batch: 1900, loss is 3.853026032447815 and perplexity is 47.13548113766755
At time: 556.5706105232239 and batch: 1950, loss is 3.797960467338562 and perplexity is 44.610107875960544
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475114405432413 and perplexity of 87.80464516355441
finished 13 epochs...
Completing Train Step...
At time: 559.9244091510773 and batch: 50, loss is 3.9912269115448 and perplexity is 54.121250632518446
At time: 560.9641079902649 and batch: 100, loss is 3.9621993494033814 and perplexity is 52.57282490234812
At time: 562.007093667984 and batch: 150, loss is 3.9366060590744016 and perplexity is 51.24438541168386
At time: 563.0472741127014 and batch: 200, loss is 3.9307290172576903 and perplexity is 50.94410326541505
At time: 564.0946590900421 and batch: 250, loss is 3.92439444065094 and perplexity is 50.62241389928274
At time: 565.1435968875885 and batch: 300, loss is 3.9384105157852174 and perplexity is 51.3369371645345
At time: 566.1831884384155 and batch: 350, loss is 3.9557926654815674 and perplexity is 52.23708407140316
At time: 567.2217407226562 and batch: 400, loss is 3.9185648107528688 and perplexity is 50.32816248346243
At time: 568.2623085975647 and batch: 450, loss is 3.94629949092865 and perplexity is 51.743534695929014
At time: 569.3027381896973 and batch: 500, loss is 3.965559573173523 and perplexity is 52.749778493580145
At time: 570.3432610034943 and batch: 550, loss is 3.930187668800354 and perplexity is 50.916532217147484
At time: 571.3840320110321 and batch: 600, loss is 3.9015330410003664 and perplexity is 49.47824316838607
At time: 572.4225564002991 and batch: 650, loss is 3.937201781272888 and perplexity is 51.27492192435755
At time: 573.4622836112976 and batch: 700, loss is 3.9592820024490356 and perplexity is 52.419675235714934
At time: 574.5037038326263 and batch: 750, loss is 3.9096158647537234 and perplexity is 49.87978770827312
At time: 575.5459578037262 and batch: 800, loss is 3.8906617259979246 and perplexity is 48.94326283986982
At time: 576.5861947536469 and batch: 850, loss is 3.892276258468628 and perplexity is 49.02234715186259
At time: 577.6262419223785 and batch: 900, loss is 3.86642680644989 and perplexity is 47.77138434918236
At time: 578.666365146637 and batch: 950, loss is 3.96468466758728 and perplexity is 52.70364760073357
At time: 579.7067770957947 and batch: 1000, loss is 3.926111159324646 and perplexity is 50.709392980476665
At time: 580.7468600273132 and batch: 1050, loss is 3.873685007095337 and perplexity is 48.119380025377765
At time: 581.788736820221 and batch: 1100, loss is 3.9119386100769042 and perplexity is 49.99578041049728
At time: 582.8300025463104 and batch: 1150, loss is 3.8796567630767824 and perplexity is 48.40759694489531
At time: 583.9176707267761 and batch: 1200, loss is 3.9234676361083984 and perplexity is 50.575518550894216
At time: 584.9573583602905 and batch: 1250, loss is 3.9014328289031983 and perplexity is 49.47328509830743
At time: 586.0038068294525 and batch: 1300, loss is 3.901962494850159 and perplexity is 49.49949635370019
At time: 587.0430424213409 and batch: 1350, loss is 3.780821232795715 and perplexity is 43.85203968535096
At time: 588.084431886673 and batch: 1400, loss is 3.802637777328491 and perplexity is 44.81925191363812
At time: 589.124591588974 and batch: 1450, loss is 3.7251257944107055 and perplexity is 41.47644992225412
At time: 590.1648488044739 and batch: 1500, loss is 3.7325944232940675 and perplexity is 41.78738180622296
At time: 591.2063932418823 and batch: 1550, loss is 3.7457928323745726 and perplexity is 42.34256447037685
At time: 592.2460453510284 and batch: 1600, loss is 3.8394594526290895 and perplexity is 46.50033201284901
At time: 593.286847114563 and batch: 1650, loss is 3.7813158988952638 and perplexity is 43.873737168841686
At time: 594.3244392871857 and batch: 1700, loss is 3.793752088546753 and perplexity is 44.42276612309701
At time: 595.3705418109894 and batch: 1750, loss is 3.791362648010254 and perplexity is 44.316747278284
At time: 596.4109134674072 and batch: 1800, loss is 3.743372235298157 and perplexity is 42.240194131268474
At time: 597.451563835144 and batch: 1850, loss is 3.772718000411987 and perplexity is 43.49813225090337
At time: 598.4917840957642 and batch: 1900, loss is 3.8545517778396605 and perplexity is 47.20745277203862
At time: 599.5332508087158 and batch: 1950, loss is 3.7993297004699706 and perplexity is 44.671231350253564
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475226255904796 and perplexity of 87.81446670385515
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 602.8226776123047 and batch: 50, loss is 3.9889301300048827 and perplexity is 53.99708858428031
At time: 603.8935356140137 and batch: 100, loss is 3.961417317390442 and perplexity is 52.5317273421622
At time: 604.9380083084106 and batch: 150, loss is 3.936967206001282 and perplexity is 51.26289550622585
At time: 605.9825830459595 and batch: 200, loss is 3.9313391637802124 and perplexity is 50.97519611749864
At time: 607.026757478714 and batch: 250, loss is 3.9256911754608153 and perplexity is 50.68810032527899
At time: 608.0708048343658 and batch: 300, loss is 3.939159326553345 and perplexity is 51.37539321224038
At time: 609.1137127876282 and batch: 350, loss is 3.9576531076431274 and perplexity is 52.3343586037696
At time: 610.1589615345001 and batch: 400, loss is 3.9213658475875857 and perplexity is 50.46933113740353
At time: 611.2306027412415 and batch: 450, loss is 3.9494636964797976 and perplexity is 51.907521182303064
At time: 612.2757449150085 and batch: 500, loss is 3.9691666889190675 and perplexity is 52.940396634324564
At time: 613.3207068443298 and batch: 550, loss is 3.933689208030701 and perplexity is 51.09513095494259
At time: 614.3666958808899 and batch: 600, loss is 3.903509659767151 and perplexity is 49.57613951238201
At time: 615.4144716262817 and batch: 650, loss is 3.938296413421631 and perplexity is 51.33107983283879
At time: 616.4604797363281 and batch: 700, loss is 3.959573106765747 and perplexity is 52.43493705073901
At time: 617.5047705173492 and batch: 750, loss is 3.9090762329101563 and perplexity is 49.85287824772928
At time: 618.5535717010498 and batch: 800, loss is 3.8903422737121582 and perplexity is 48.92763029974103
At time: 619.5974996089935 and batch: 850, loss is 3.892041630744934 and perplexity is 49.01084649937892
At time: 620.6423985958099 and batch: 900, loss is 3.8628486347198487 and perplexity is 47.60075558376264
At time: 621.6845903396606 and batch: 950, loss is 3.960906157493591 and perplexity is 52.50488209152488
At time: 622.726405620575 and batch: 1000, loss is 3.921756615638733 and perplexity is 50.48905679340187
At time: 623.7715845108032 and batch: 1050, loss is 3.87095477104187 and perplexity is 47.988181941529284
At time: 624.8160665035248 and batch: 1100, loss is 3.907748055458069 and perplexity is 49.78670873107624
At time: 625.8597745895386 and batch: 1150, loss is 3.8767608785629273 and perplexity is 48.26761691537393
At time: 626.9031953811646 and batch: 1200, loss is 3.920881357192993 and perplexity is 50.44488515364628
At time: 627.946772813797 and batch: 1250, loss is 3.897365217208862 and perplexity is 49.27245571016943
At time: 628.9971930980682 and batch: 1300, loss is 3.897272753715515 and perplexity is 49.26790001740955
At time: 630.0403718948364 and batch: 1350, loss is 3.7743712043762208 and perplexity is 43.5701030103579
At time: 631.0840344429016 and batch: 1400, loss is 3.7947955989837645 and perplexity is 44.469145937889145
At time: 632.1353211402893 and batch: 1450, loss is 3.7160406160354613 and perplexity is 41.10133554701637
At time: 633.1852684020996 and batch: 1500, loss is 3.7226356363296507 and perplexity is 41.37329549402735
At time: 634.2342841625214 and batch: 1550, loss is 3.7353908109664915 and perplexity is 41.90439906212055
At time: 635.2791538238525 and batch: 1600, loss is 3.8290373849868775 and perplexity is 46.01821907793257
At time: 636.3218593597412 and batch: 1650, loss is 3.770703902244568 and perplexity is 43.41061091032303
At time: 637.3662519454956 and batch: 1700, loss is 3.781747970581055 and perplexity is 43.892697864317036
At time: 638.4116096496582 and batch: 1750, loss is 3.779056262969971 and perplexity is 43.77471042049269
At time: 639.4567084312439 and batch: 1800, loss is 3.7318912076950075 and perplexity is 41.75800659725606
At time: 640.5006442070007 and batch: 1850, loss is 3.7613912534713747 and perplexity is 43.00821970996945
At time: 641.5444419384003 and batch: 1900, loss is 3.843719253540039 and perplexity is 46.69883666449431
At time: 642.5867774486542 and batch: 1950, loss is 3.7901945543289184 and perplexity is 44.26501138787679
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474172192950581 and perplexity of 87.72195349359788
finished 15 epochs...
Completing Train Step...
At time: 645.9115009307861 and batch: 50, loss is 3.987588953971863 and perplexity is 53.924717525231316
At time: 646.9497730731964 and batch: 100, loss is 3.9587644863128664 and perplexity is 52.392554226313
At time: 647.9886593818665 and batch: 150, loss is 3.933822822570801 and perplexity is 51.101958463483534
At time: 649.0269069671631 and batch: 200, loss is 3.927907176017761 and perplexity is 50.80054973178734
At time: 650.0645177364349 and batch: 250, loss is 3.9218162584304808 and perplexity is 50.49206819150494
At time: 651.1030957698822 and batch: 300, loss is 3.9354236030578615 and perplexity is 51.183826990730594
At time: 652.1430070400238 and batch: 350, loss is 3.9535286617279053 and perplexity is 52.11895289216063
At time: 653.1812715530396 and batch: 400, loss is 3.917121019363403 and perplexity is 50.25555154595768
At time: 654.2242293357849 and batch: 450, loss is 3.9453004026412963 and perplexity is 51.69186415248345
At time: 655.2691900730133 and batch: 500, loss is 3.9650605010986326 and perplexity is 52.72345912035573
At time: 656.3155333995819 and batch: 550, loss is 3.9297691679000852 and perplexity is 50.8952280607913
At time: 657.3547286987305 and batch: 600, loss is 3.9001619672775267 and perplexity is 49.41045133374701
At time: 658.3962728977203 and batch: 650, loss is 3.935075435638428 and perplexity is 51.16600955167637
At time: 659.4414298534393 and batch: 700, loss is 3.9567342376708985 and perplexity is 52.286292219893106
At time: 660.4893128871918 and batch: 750, loss is 3.9065442085266113 and perplexity is 49.72680921670034
At time: 661.5333023071289 and batch: 800, loss is 3.887693514823914 and perplexity is 48.79820428892236
At time: 662.5775444507599 and batch: 850, loss is 3.88944908618927 and perplexity is 48.883948261862486
At time: 663.6566548347473 and batch: 900, loss is 3.860866289138794 and perplexity is 47.50648790270704
At time: 664.7000095844269 and batch: 950, loss is 3.959138026237488 and perplexity is 52.41212859274551
At time: 665.7448761463165 and batch: 1000, loss is 3.920176167488098 and perplexity is 50.409324479955494
At time: 666.7920436859131 and batch: 1050, loss is 3.8692547035217286 and perplexity is 47.906668101208844
At time: 667.8339021205902 and batch: 1100, loss is 3.906323947906494 and perplexity is 49.715857565018894
At time: 668.8747749328613 and batch: 1150, loss is 3.8754667139053343 and perplexity is 48.20519107482698
At time: 669.9149045944214 and batch: 1200, loss is 3.9195098733901976 and perplexity is 50.37574823164556
At time: 670.9554295539856 and batch: 1250, loss is 3.8963669395446776 and perplexity is 49.22329266144399
At time: 671.9999079704285 and batch: 1300, loss is 3.8963466548919676 and perplexity is 49.22229419417393
At time: 673.0491247177124 and batch: 1350, loss is 3.7737310981750487 and perplexity is 43.54222244144976
At time: 674.0945475101471 and batch: 1400, loss is 3.7946805906295777 and perplexity is 44.464031908686415
At time: 675.1448175907135 and batch: 1450, loss is 3.716298570632935 and perplexity is 41.11193919305384
At time: 676.186708688736 and batch: 1500, loss is 3.7232962465286255 and perplexity is 41.40063614475796
At time: 677.2292900085449 and batch: 1550, loss is 3.7365305376052858 and perplexity is 41.952185848778356
At time: 678.2707982063293 and batch: 1600, loss is 3.8302787160873413 and perplexity is 46.07537839394054
At time: 679.3111438751221 and batch: 1650, loss is 3.7720447158813477 and perplexity is 43.468855488248785
At time: 680.3525080680847 and batch: 1700, loss is 3.7832099628448486 and perplexity is 43.956915580495476
At time: 681.3945074081421 and batch: 1750, loss is 3.780856008529663 and perplexity is 43.85356469873271
At time: 682.4375538825989 and batch: 1800, loss is 3.7339824724197386 and perplexity is 41.84542501909938
At time: 683.480669260025 and batch: 1850, loss is 3.763531346321106 and perplexity is 43.10035985251375
At time: 684.5261650085449 and batch: 1900, loss is 3.8456305503845214 and perplexity is 46.78817735474463
At time: 685.5681834220886 and batch: 1950, loss is 3.7919076251983643 and perplexity is 44.34090547683756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473943665970204 and perplexity of 87.70190895089982
finished 16 epochs...
Completing Train Step...
At time: 688.8764653205872 and batch: 50, loss is 3.98649706363678 and perplexity is 53.865869780831744
At time: 689.9430556297302 and batch: 100, loss is 3.9569397497177126 and perplexity is 52.297038787064224
At time: 690.9847152233124 and batch: 150, loss is 3.9317974615097047 and perplexity is 50.99856328829137
At time: 692.0256903171539 and batch: 200, loss is 3.9256181716918945 and perplexity is 50.684400037984915
At time: 693.0657370090485 and batch: 250, loss is 3.919303331375122 and perplexity is 50.36534459752563
At time: 694.1085793972015 and batch: 300, loss is 3.932865662574768 and perplexity is 51.0530691143205
At time: 695.1498925685883 and batch: 350, loss is 3.950867257118225 and perplexity is 51.9804276882552
At time: 696.1921632289886 and batch: 400, loss is 3.9143137454986574 and perplexity is 50.114668291006694
At time: 697.2341458797455 and batch: 450, loss is 3.942555932998657 and perplexity is 51.55019189707189
At time: 698.2750327587128 and batch: 500, loss is 3.962349090576172 and perplexity is 52.58069780824028
At time: 699.3157877922058 and batch: 550, loss is 3.927181673049927 and perplexity is 50.7637071485071
At time: 700.3582921028137 and batch: 600, loss is 3.8978512334823607 and perplexity is 49.29640874579086
At time: 701.4009852409363 and batch: 650, loss is 3.932856421470642 and perplexity is 51.05259732977277
At time: 702.4444763660431 and batch: 700, loss is 3.9547933244705202 and perplexity is 52.184907486435996
At time: 703.4906940460205 and batch: 750, loss is 3.9047490882873537 and perplexity is 49.637623688364926
At time: 704.5318112373352 and batch: 800, loss is 3.885856204032898 and perplexity is 48.70862913549645
At time: 705.5787682533264 and batch: 850, loss is 3.887628197669983 and perplexity is 48.795017033193645
At time: 706.6181349754333 and batch: 900, loss is 3.8593589639663697 and perplexity is 47.43493411859551
At time: 707.658607006073 and batch: 950, loss is 3.957765135765076 and perplexity is 52.340221852095574
At time: 708.7001876831055 and batch: 1000, loss is 3.9188708877563476 and perplexity is 50.343569134316446
At time: 709.7412972450256 and batch: 1050, loss is 3.8679666566848754 and perplexity is 47.84500179196988
At time: 710.7811331748962 and batch: 1100, loss is 3.905181436538696 and perplexity is 49.65908906809271
At time: 711.8218901157379 and batch: 1150, loss is 3.8745065689086915 and perplexity is 48.15892931435718
At time: 712.8602561950684 and batch: 1200, loss is 3.918545083999634 and perplexity is 50.32716968201276
At time: 713.9062230587006 and batch: 1250, loss is 3.8956558752059935 and perplexity is 49.188304174406746
At time: 714.9562110900879 and batch: 1300, loss is 3.8957653570175172 and perplexity is 49.19368969385637
At time: 715.9990422725677 and batch: 1350, loss is 3.773301029205322 and perplexity is 43.52350030889746
At time: 717.0422985553741 and batch: 1400, loss is 3.7946202898025514 and perplexity is 44.4613507716276
At time: 718.090264081955 and batch: 1450, loss is 3.716409845352173 and perplexity is 41.116514167079636
At time: 719.1380789279938 and batch: 1500, loss is 3.723728213310242 and perplexity is 41.41852370744858
At time: 720.1796312332153 and batch: 1550, loss is 3.7372488927841188 and perplexity is 41.982333245719126
At time: 721.2252976894379 and batch: 1600, loss is 3.831057405471802 and perplexity is 46.111270774675205
At time: 722.26771235466 and batch: 1650, loss is 3.772876296043396 and perplexity is 43.50501836021927
At time: 723.3095626831055 and batch: 1700, loss is 3.7841411066055297 and perplexity is 43.99786485004678
At time: 724.350926399231 and batch: 1750, loss is 3.7819956398010253 and perplexity is 43.90357008086061
At time: 725.3954911231995 and batch: 1800, loss is 3.735233464241028 and perplexity is 41.89780606085279
At time: 726.4437508583069 and batch: 1850, loss is 3.76482057094574 and perplexity is 43.15596173172079
At time: 727.4862532615662 and batch: 1900, loss is 3.846715931892395 and perplexity is 46.8389879466829
At time: 728.5296669006348 and batch: 1950, loss is 3.7928898239135744 and perplexity is 44.38447845238551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473872694858285 and perplexity of 87.69568486977175
finished 17 epochs...
Completing Train Step...
At time: 731.8978314399719 and batch: 50, loss is 3.9853801345825195 and perplexity is 53.8057390129926
At time: 732.9499416351318 and batch: 100, loss is 3.9553560256958007 and perplexity is 52.214280261092874
At time: 733.9980220794678 and batch: 150, loss is 3.9300931310653686 and perplexity is 50.91171891104148
At time: 735.047863483429 and batch: 200, loss is 3.923747706413269 and perplexity is 50.589685235534986
At time: 736.0951826572418 and batch: 250, loss is 3.9172745990753173 and perplexity is 50.26327037179855
At time: 737.1423377990723 and batch: 300, loss is 3.9308065938949586 and perplexity is 50.948055490933235
At time: 738.1918222904205 and batch: 350, loss is 3.948788242340088 and perplexity is 51.8724718706723
At time: 739.2372570037842 and batch: 400, loss is 3.912142152786255 and perplexity is 50.00595772282187
At time: 740.2829222679138 and batch: 450, loss is 3.940430898666382 and perplexity is 51.44076228148021
At time: 741.32839012146 and batch: 500, loss is 3.9602402448654175 and perplexity is 52.46993006628845
At time: 742.3767681121826 and batch: 550, loss is 3.925145297050476 and perplexity is 50.66043833637847
At time: 743.4473350048065 and batch: 600, loss is 3.895996232032776 and perplexity is 49.2050485989083
At time: 744.4936258792877 and batch: 650, loss is 3.9310642433166505 and perplexity is 50.96118391916014
At time: 745.5435531139374 and batch: 700, loss is 3.9532047605514524 and perplexity is 52.10207423565928
At time: 746.5974314212799 and batch: 750, loss is 3.903264193534851 and perplexity is 49.56397173765394
At time: 747.6422526836395 and batch: 800, loss is 3.8843572664260866 and perplexity is 48.63567263179253
At time: 748.6926918029785 and batch: 850, loss is 3.8861441612243652 and perplexity is 48.722657155180165
At time: 749.7382690906525 and batch: 900, loss is 3.8580726909637453 and perplexity is 47.37395906714567
At time: 750.7865509986877 and batch: 950, loss is 3.956592173576355 and perplexity is 52.27886474273326
At time: 751.8327684402466 and batch: 1000, loss is 3.917739119529724 and perplexity is 50.28662411271686
At time: 752.8815851211548 and batch: 1050, loss is 3.8668736839294433 and perplexity is 47.79273707568605
At time: 753.9328327178955 and batch: 1100, loss is 3.9041898584365846 and perplexity is 49.609872607816705
At time: 754.9786553382874 and batch: 1150, loss is 3.8736791801452637 and perplexity is 48.119099636969715
At time: 756.023313999176 and batch: 1200, loss is 3.9177450132369995 and perplexity is 50.286920488232624
At time: 757.068391084671 and batch: 1250, loss is 3.8950491666793825 and perplexity is 49.158470262014255
At time: 758.1140222549438 and batch: 1300, loss is 3.895277557373047 and perplexity is 49.16969888134415
At time: 759.1600329875946 and batch: 1350, loss is 3.7729169654846193 and perplexity is 43.50678772098559
At time: 760.2067046165466 and batch: 1400, loss is 3.7945108366012574 and perplexity is 44.45648460076564
At time: 761.2528865337372 and batch: 1450, loss is 3.716397566795349 and perplexity is 41.11600931872345
At time: 762.297369480133 and batch: 1500, loss is 3.7239562129974364 and perplexity is 41.427968194527075
At time: 763.3450591564178 and batch: 1550, loss is 3.737671346664429 and perplexity is 42.000072592067276
At time: 764.3926703929901 and batch: 1600, loss is 3.831531925201416 and perplexity is 46.133156674650365
At time: 765.4401724338531 and batch: 1650, loss is 3.7733892154693605 and perplexity is 43.5273386530297
At time: 766.4857168197632 and batch: 1700, loss is 3.78474317073822 and perplexity is 44.024362362188384
At time: 767.5338592529297 and batch: 1750, loss is 3.7827573919296267 and perplexity is 43.9370264599391
At time: 768.5790722370148 and batch: 1800, loss is 3.7360368728637696 and perplexity is 41.93148064493033
At time: 769.6276941299438 and batch: 1850, loss is 3.765655584335327 and perplexity is 43.19201258698602
At time: 770.6763942241669 and batch: 1900, loss is 3.8473955535888673 and perplexity is 46.87083155871141
At time: 771.723210811615 and batch: 1950, loss is 3.793498058319092 and perplexity is 44.411482830914736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4738684365915695 and perplexity of 87.69531143895088
finished 18 epochs...
Completing Train Step...
At time: 775.0726597309113 and batch: 50, loss is 3.984254250526428 and perplexity is 53.745194078995226
At time: 776.1445410251617 and batch: 100, loss is 3.9539040660858156 and perplexity is 52.13852224718682
At time: 777.1927919387817 and batch: 150, loss is 3.928562126159668 and perplexity is 50.833832457116216
At time: 778.2345325946808 and batch: 200, loss is 3.922100319862366 and perplexity is 50.5064130780123
At time: 779.276064157486 and batch: 250, loss is 3.9155084323883056 and perplexity is 50.17457540619024
At time: 780.3184430599213 and batch: 300, loss is 3.929027752876282 and perplexity is 50.85750755906837
At time: 781.3602778911591 and batch: 350, loss is 3.947021818161011 and perplexity is 51.78092396215541
At time: 782.4022970199585 and batch: 400, loss is 3.9103176689147947 and perplexity is 49.9148058373372
At time: 783.4424538612366 and batch: 450, loss is 3.93864737033844 and perplexity is 51.34909799196724
At time: 784.4883916378021 and batch: 500, loss is 3.958466401100159 and perplexity is 52.3769391080757
At time: 785.5300736427307 and batch: 550, loss is 3.9234168577194213 and perplexity is 50.572950472742505
At time: 786.5706386566162 and batch: 600, loss is 3.8944009828567503 and perplexity is 49.126616861389806
At time: 787.6200811862946 and batch: 650, loss is 3.9295125579833985 and perplexity is 50.88216951610656
At time: 788.6595330238342 and batch: 700, loss is 3.951807417869568 and perplexity is 52.02932062621497
At time: 789.6990323066711 and batch: 750, loss is 3.90195538520813 and perplexity is 49.49914443125152
At time: 790.7352964878082 and batch: 800, loss is 3.8830476903915407 and perplexity is 48.57202220712193
At time: 791.774661064148 and batch: 850, loss is 3.8848514223098753 and perplexity is 48.65971217473716
At time: 792.8153059482574 and batch: 900, loss is 3.856920351982117 and perplexity is 47.319399648908146
At time: 793.8583080768585 and batch: 950, loss is 3.9555380535125733 and perplexity is 52.22378557762291
At time: 794.9017980098724 and batch: 1000, loss is 3.916717457771301 and perplexity is 50.235274427372154
At time: 795.9789774417877 and batch: 1050, loss is 3.8658936262130736 and perplexity is 47.745920380207764
At time: 797.0179579257965 and batch: 1100, loss is 3.90328980922699 and perplexity is 49.56524136935633
At time: 798.0575885772705 and batch: 1150, loss is 3.872922348976135 and perplexity is 48.082695380209834
At time: 799.0970623493195 and batch: 1200, loss is 3.917022409439087 and perplexity is 50.25059609415564
At time: 800.1380863189697 and batch: 1250, loss is 3.894484586715698 and perplexity is 49.13072420782908
At time: 801.1793646812439 and batch: 1300, loss is 3.894816837310791 and perplexity is 49.14705063226641
At time: 802.2210147380829 and batch: 1350, loss is 3.772530655860901 and perplexity is 43.489983876144365
At time: 803.2618126869202 and batch: 1400, loss is 3.794339671134949 and perplexity is 44.44887583704588
At time: 804.304892539978 and batch: 1450, loss is 3.716290235519409 and perplexity is 41.111596521801516
At time: 805.3449697494507 and batch: 1500, loss is 3.724036841392517 and perplexity is 41.43130859977799
At time: 806.3865263462067 and batch: 1550, loss is 3.7378926420211793 and perplexity is 42.00936804159706
At time: 807.4336993694305 and batch: 1600, loss is 3.8318028116226195 and perplexity is 46.14565521312653
At time: 808.4746856689453 and batch: 1650, loss is 3.773692750930786 and perplexity is 43.54055274922431
At time: 809.516144990921 and batch: 1700, loss is 3.785129675865173 and perplexity is 44.041381292692286
At time: 810.5573818683624 and batch: 1750, loss is 3.783268733024597 and perplexity is 43.95949901223896
At time: 811.5974481105804 and batch: 1800, loss is 3.736564989089966 and perplexity is 41.95363118876333
At time: 812.6408426761627 and batch: 1850, loss is 3.7662130069732664 and perplexity is 43.21609550413819
At time: 813.6890580654144 and batch: 1900, loss is 3.847834029197693 and perplexity is 46.891387781487076
At time: 814.7360401153564 and batch: 1950, loss is 3.7938840579986572 and perplexity is 44.42862895804339
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473899947765261 and perplexity of 87.69807486468075
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 818.056875705719 and batch: 50, loss is 3.9836654806137086 and perplexity is 53.71355983932635
At time: 819.0920696258545 and batch: 100, loss is 3.953658199310303 and perplexity is 52.12570469261188
At time: 820.1327488422394 and batch: 150, loss is 3.928530201911926 and perplexity is 50.832209651158756
At time: 821.1729731559753 and batch: 200, loss is 3.9221372270584105 and perplexity is 50.508277162500136
At time: 822.2190980911255 and batch: 250, loss is 3.915549187660217 and perplexity is 50.17662032632432
At time: 823.2844443321228 and batch: 300, loss is 3.9288951683044435 and perplexity is 50.85076508518777
At time: 824.322687625885 and batch: 350, loss is 3.9471759510040285 and perplexity is 51.788905718289364
At time: 825.3589947223663 and batch: 400, loss is 3.910706596374512 and perplexity is 49.93422285163405
At time: 826.3981413841248 and batch: 450, loss is 3.9391326808929445 and perplexity is 51.37402429919779
At time: 827.4379692077637 and batch: 500, loss is 3.9590793323516844 and perplexity is 52.40905241153256
At time: 828.4756610393524 and batch: 550, loss is 3.9241199493408203 and perplexity is 50.60852039348064
At time: 829.5152430534363 and batch: 600, loss is 3.8945366764068603 and perplexity is 49.13328347873488
At time: 830.5546147823334 and batch: 650, loss is 3.9294838905334473 and perplexity is 50.880710874966404
At time: 831.5937936306 and batch: 700, loss is 3.9517369079589844 and perplexity is 52.02565217280257
At time: 832.6324687004089 and batch: 750, loss is 3.901740355491638 and perplexity is 49.488501788541114
At time: 833.6726920604706 and batch: 800, loss is 3.8827766227722167 and perplexity is 48.558857689014395
At time: 834.7161166667938 and batch: 850, loss is 3.8844440174102783 and perplexity is 48.639892007275
At time: 835.7584543228149 and batch: 900, loss is 3.855597233772278 and perplexity is 47.25683189095179
At time: 836.7988657951355 and batch: 950, loss is 3.9540966749191284 and perplexity is 52.1485655543113
At time: 837.8372871875763 and batch: 1000, loss is 3.91488365650177 and perplexity is 50.14323733201522
At time: 838.8748326301575 and batch: 1050, loss is 3.8645755529403685 and perplexity is 47.6830292153608
At time: 839.9145278930664 and batch: 1100, loss is 3.9014980220794677 and perplexity is 49.4765105240402
At time: 840.9554703235626 and batch: 1150, loss is 3.871530089378357 and perplexity is 48.015798365890845
At time: 841.9985952377319 and batch: 1200, loss is 3.9158411169052125 and perplexity is 50.19127048751381
At time: 843.0475606918335 and batch: 1250, loss is 3.8927348852157593 and perplexity is 49.044835267905164
At time: 844.0915405750275 and batch: 1300, loss is 3.8931634521484373 and perplexity is 49.06585876718615
At time: 845.1387343406677 and batch: 1350, loss is 3.770271129608154 and perplexity is 43.391828050438086
At time: 846.1795148849487 and batch: 1400, loss is 3.7915828609466553 and perplexity is 44.32650747395515
At time: 847.2248067855835 and batch: 1450, loss is 3.7130923748016356 and perplexity is 40.98033734837486
At time: 848.2678439617157 and batch: 1500, loss is 3.720692377090454 and perplexity is 41.292974522813324
At time: 849.3085680007935 and batch: 1550, loss is 3.7343588924407958 and perplexity is 41.861179439819885
At time: 850.3512890338898 and batch: 1600, loss is 3.8284003925323487 and perplexity is 45.98891515378922
At time: 851.3937292098999 and batch: 1650, loss is 3.7701470756530764 and perplexity is 43.38644545642331
At time: 852.4356033802032 and batch: 1700, loss is 3.781350769996643 and perplexity is 43.875267121053795
At time: 853.4747297763824 and batch: 1750, loss is 3.779365496635437 and perplexity is 43.788249127854904
At time: 854.5170912742615 and batch: 1800, loss is 3.732691946029663 and perplexity is 41.791457224729825
At time: 855.559431552887 and batch: 1850, loss is 3.762658705711365 and perplexity is 43.062765133936765
At time: 856.6049809455872 and batch: 1900, loss is 3.844228506088257 and perplexity is 46.722624222487696
At time: 857.6465682983398 and batch: 1950, loss is 3.791049070358276 and perplexity is 44.30285271535525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473735862554506 and perplexity of 87.68368608810873
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fea7e1b2b38>
ELAPSED
5309.330080986023


RESULTS SO FAR:
[{'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.92103091601648}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.6813262795645527, 'dropout': 0.19794812537896078, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.05052225478255}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.8407924036871192, 'dropout': 0.37893501344260494, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.32399121066462}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.320185930278277, 'dropout': 0.14646798116639437, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.0134270296668}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.21124919513989482, 'dropout': 0.14686417520406692, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.49991283004455}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.337532812168398, 'dropout': 0.10201283915037553, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -87.68368608810873}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.7699727966075124, 'dropout': 0.3712884461632415, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.92103091601648}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.6813262795645527, 'dropout': 0.19794812537896078, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.05052225478255}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.8407924036871192, 'dropout': 0.37893501344260494, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -89.32399121066462}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.320185930278277, 'dropout': 0.14646798116639437, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.0134270296668}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.21124919513989482, 'dropout': 0.14686417520406692, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -88.49991283004455}, {'params': {'seq_len': 35, 'wordvec_dim': 300, 'num_layers': 1, 'tune_wordvecs': 'TRUE', 'batch_size': 32, 'data': 'wikitext', 'rnn_dropout': 0.337532812168398, 'dropout': 0.10201283915037553, 'tie_weights': 'FALSE', 'wordvec_source': 'None'}, 'best_accuracy': -87.68368608810873}]
