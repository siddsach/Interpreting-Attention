FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'domain': [0, 1], 'type': 'continuous'}, {'name': 'rnn_dropout', 'domain': [0, 1], 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9566168785095215 and batch: 50, loss is 7.441354236602783 and perplexity is 1705.057709915853
At time: 3.1755363941192627 and batch: 100, loss is 6.48797833442688 and perplexity is 657.1933940321485
At time: 4.394618272781372 and batch: 150, loss is 6.156811332702636 and perplexity is 471.92087447225896
At time: 5.613252878189087 and batch: 200, loss is 6.009421463012695 and perplexity is 407.2476442816261
At time: 6.833296298980713 and batch: 250, loss is 5.924694690704346 and perplexity is 374.16418211696964
At time: 8.051323175430298 and batch: 300, loss is 5.832824153900146 and perplexity is 341.32126296544175
At time: 9.270040273666382 and batch: 350, loss is 5.766439466476441 and perplexity is 319.3984766877844
At time: 10.488011837005615 and batch: 400, loss is 5.699767589569092 and perplexity is 298.7979491365946
At time: 11.70703673362732 and batch: 450, loss is 5.623529968261718 and perplexity is 276.86498490976606
At time: 12.925228595733643 and batch: 500, loss is 5.592827320098877 and perplexity is 268.49366512599596
At time: 14.144560813903809 and batch: 550, loss is 5.536174030303955 and perplexity is 253.70547076934972
At time: 15.363608360290527 and batch: 600, loss is 5.553114385604858 and perplexity is 258.0399416676951
At time: 16.579939365386963 and batch: 650, loss is 5.627625017166138 and perplexity is 278.0010851683072
At time: 17.79881739616394 and batch: 700, loss is 5.536455669403076 and perplexity is 253.77693421255688
At time: 19.018009901046753 and batch: 750, loss is 5.484772024154663 and perplexity is 240.99399692479247
At time: 20.235380172729492 and batch: 800, loss is 5.473898668289184 and perplexity is 238.38777828384812
At time: 21.450668334960938 and batch: 850, loss is 5.476077404022217 and perplexity is 238.90772846605523
At time: 22.67105197906494 and batch: 900, loss is 5.481767330169678 and perplexity is 240.27097049236934
At time: 23.893070220947266 and batch: 950, loss is 5.517992897033691 and perplexity is 249.13449645248912
At time: 25.110214710235596 and batch: 1000, loss is 5.467714395523071 and perplexity is 236.91807245380272
At time: 26.327245235443115 and batch: 1050, loss is 5.374773454666138 and perplexity is 215.8909576810471
At time: 27.54297423362732 and batch: 1100, loss is 5.463366708755493 and perplexity is 235.89026280141144
At time: 28.758873224258423 and batch: 1150, loss is 5.372606868743897 and perplexity is 215.42371771193822
At time: 29.975483417510986 and batch: 1200, loss is 5.4375698852539065 and perplexity is 229.88286239493107
At time: 31.192341566085815 and batch: 1250, loss is 5.370143795013428 and perplexity is 214.893766134749
At time: 32.40939784049988 and batch: 1300, loss is 5.390687665939331 and perplexity is 219.35417609680397
At time: 33.62992835044861 and batch: 1350, loss is 5.337111654281617 and perplexity is 207.91132242123274
At time: 34.851773262023926 and batch: 1400, loss is 5.350821151733398 and perplexity is 210.78131026052753
At time: 36.07110786437988 and batch: 1450, loss is 5.304156723022461 and perplexity is 201.1712877500177
At time: 37.292020320892334 and batch: 1500, loss is 5.275913972854614 and perplexity is 195.56913973836552
At time: 38.51307511329651 and batch: 1550, loss is 5.258820867538452 and perplexity is 192.25466387867692
At time: 39.73593831062317 and batch: 1600, loss is 5.306263256072998 and perplexity is 201.59550837699527
At time: 40.95844769477844 and batch: 1650, loss is 5.275697603225708 and perplexity is 195.52682909370915
At time: 42.18199324607849 and batch: 1700, loss is 5.286390361785888 and perplexity is 197.6287680048126
At time: 43.40333151817322 and batch: 1750, loss is 5.301632575988769 and perplexity is 200.66414216505692
At time: 44.62633442878723 and batch: 1800, loss is 5.274926052093506 and perplexity is 195.37602833007696
At time: 45.84544634819031 and batch: 1850, loss is 5.261387548446655 and perplexity is 192.7487540686468
At time: 47.06541848182678 and batch: 1900, loss is 5.288821277618408 and perplexity is 198.1097713083217
At time: 48.29249453544617 and batch: 1950, loss is 5.213572301864624 and perplexity is 183.74929509439792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.878257857921511 and perplexity of 131.40154420492317
finished 1 epochs...
Completing Train Step...
At time: 52.03181576728821 and batch: 50, loss is 5.106904878616333 and perplexity is 165.15837774012613
At time: 53.22632455825806 and batch: 100, loss is 5.033755578994751 and perplexity is 153.5084445692852
At time: 54.39393854141235 and batch: 150, loss is 4.958168992996216 and perplexity is 142.3329445412124
At time: 55.56169366836548 and batch: 200, loss is 4.939037141799926 and perplexity is 139.63573539851177
At time: 56.727333307266235 and batch: 250, loss is 4.949393968582154 and perplexity is 141.08943337764325
At time: 57.89596199989319 and batch: 300, loss is 4.959398813247681 and perplexity is 142.5080961592876
At time: 59.06186819076538 and batch: 350, loss is 4.9498884391784665 and perplexity is 141.15921520500802
At time: 60.27512812614441 and batch: 400, loss is 4.914443454742432 and perplexity is 136.24346304519327
At time: 61.44641876220703 and batch: 450, loss is 4.890380020141602 and perplexity is 133.0041086888021
At time: 62.61560273170471 and batch: 500, loss is 4.890454730987549 and perplexity is 133.01404590948113
At time: 63.780677795410156 and batch: 550, loss is 4.850910911560058 and perplexity is 127.85680305684612
At time: 64.94426321983337 and batch: 600, loss is 4.8250273323059085 and perplexity is 124.58987366519813
At time: 66.10854196548462 and batch: 650, loss is 4.88566650390625 and perplexity is 132.3786668362573
At time: 67.27079677581787 and batch: 700, loss is 4.888713569641113 and perplexity is 132.78264850278015
At time: 68.43336081504822 and batch: 750, loss is 4.844252996444702 and perplexity is 127.00837084409413
At time: 69.59767317771912 and batch: 800, loss is 4.8263952350616455 and perplexity is 124.76041711355535
At time: 70.76000547409058 and batch: 850, loss is 4.818653364181518 and perplexity is 123.7982672987861
At time: 71.92816233634949 and batch: 900, loss is 4.828352451324463 and perplexity is 125.0048393464449
At time: 73.09216928482056 and batch: 950, loss is 4.897161636352539 and perplexity is 133.90915688454677
At time: 74.25882267951965 and batch: 1000, loss is 4.851112546920777 and perplexity is 127.88258610875091
At time: 75.42580890655518 and batch: 1050, loss is 4.770672607421875 and perplexity is 117.9985819973529
At time: 76.59422755241394 and batch: 1100, loss is 4.850323877334595 and perplexity is 127.78176876349731
At time: 77.76176333427429 and batch: 1150, loss is 4.765525617599487 and perplexity is 117.39280479862313
At time: 78.92966508865356 and batch: 1200, loss is 4.843123092651367 and perplexity is 126.8649446482526
At time: 80.09751796722412 and batch: 1250, loss is 4.795333337783814 and perplexity is 120.94469049956713
At time: 81.26523351669312 and batch: 1300, loss is 4.820582332611084 and perplexity is 124.03730071788132
At time: 82.43145179748535 and batch: 1350, loss is 4.720192136764527 and perplexity is 112.18980638352372
At time: 83.5982723236084 and batch: 1400, loss is 4.740766077041626 and perplexity is 114.52190068264984
At time: 84.76384329795837 and batch: 1450, loss is 4.677804079055786 and perplexity is 107.53367765914365
At time: 85.93175339698792 and batch: 1500, loss is 4.6611341381072995 and perplexity is 105.75595602685213
At time: 87.09633898735046 and batch: 1550, loss is 4.656479425430298 and perplexity is 105.26483633492414
At time: 88.27357649803162 and batch: 1600, loss is 4.737067222595215 and perplexity is 114.09908329315434
At time: 89.44329714775085 and batch: 1650, loss is 4.694187345504761 and perplexity is 109.3099413223003
At time: 90.60885071754456 and batch: 1700, loss is 4.717159070968628 and perplexity is 111.85004284219214
At time: 91.77589106559753 and batch: 1750, loss is 4.729216623306274 and perplexity is 113.20684400009371
At time: 92.94155478477478 and batch: 1800, loss is 4.683415575027466 and perplexity is 108.13879868737251
At time: 94.10668540000916 and batch: 1850, loss is 4.693215970993042 and perplexity is 109.2038119854337
At time: 95.27270197868347 and batch: 1900, loss is 4.760881099700928 and perplexity is 116.84883602976905
At time: 96.44102334976196 and batch: 1950, loss is 4.692686939239502 and perplexity is 109.14605498027777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.615276673782703 and perplexity of 101.01577308259192
finished 2 epochs...
Completing Train Step...
At time: 100.15299487113953 and batch: 50, loss is 4.651960201263428 and perplexity is 104.79019425742763
At time: 101.32159066200256 and batch: 100, loss is 4.593350305557251 and perplexity is 98.82496999421465
At time: 102.4883964061737 and batch: 150, loss is 4.539682550430298 and perplexity is 93.66106273560058
At time: 103.65559101104736 and batch: 200, loss is 4.5357708168029784 and perplexity is 93.29540125834451
At time: 104.82407307624817 and batch: 250, loss is 4.538342351913452 and perplexity is 93.53562239449131
At time: 105.9917643070221 and batch: 300, loss is 4.557041501998901 and perplexity is 95.30111419109554
At time: 107.1589674949646 and batch: 350, loss is 4.56599720954895 and perplexity is 96.1584363320726
At time: 108.3292818069458 and batch: 400, loss is 4.525673446655273 and perplexity is 92.35810314540555
At time: 109.49810361862183 and batch: 450, loss is 4.530971727371216 and perplexity is 92.84874092284355
At time: 110.66645574569702 and batch: 500, loss is 4.543492164611816 and perplexity is 94.01855577136092
At time: 111.83383202552795 and batch: 550, loss is 4.509470710754394 and perplexity is 90.8737073032965
At time: 113.00336527824402 and batch: 600, loss is 4.478148508071899 and perplexity is 88.07145803333557
At time: 114.17180943489075 and batch: 650, loss is 4.538299589157105 and perplexity is 93.53162263898194
At time: 115.3402931690216 and batch: 700, loss is 4.561894464492798 and perplexity is 95.76473097141904
At time: 116.50893044471741 and batch: 750, loss is 4.523522500991821 and perplexity is 92.15965938134661
At time: 117.67808508872986 and batch: 800, loss is 4.500261363983154 and perplexity is 90.04066161136454
At time: 118.84520220756531 and batch: 850, loss is 4.492636089324951 and perplexity is 89.35668789402226
At time: 120.05071949958801 and batch: 900, loss is 4.4860254001617434 and perplexity is 88.76792680809584
At time: 121.21842122077942 and batch: 950, loss is 4.5691984748840335 and perplexity is 96.46675824779929
At time: 122.38595819473267 and batch: 1000, loss is 4.53821099281311 and perplexity is 93.52333644623687
At time: 123.5550217628479 and batch: 1050, loss is 4.468383207321167 and perplexity is 87.21559941776579
At time: 124.72241950035095 and batch: 1100, loss is 4.532997140884399 and perplexity is 93.03698859272392
At time: 125.8902575969696 and batch: 1150, loss is 4.466859645843506 and perplexity is 87.08282226300483
At time: 127.05917024612427 and batch: 1200, loss is 4.544475688934326 and perplexity is 94.11107079565994
At time: 128.2267782688141 and batch: 1250, loss is 4.507714014053345 and perplexity is 90.71420989676581
At time: 129.3948791027069 and batch: 1300, loss is 4.522387638092041 and perplexity is 92.05513012746313
At time: 130.56403708457947 and batch: 1350, loss is 4.4069147872924805 and perplexity is 82.01603585008884
At time: 131.72977948188782 and batch: 1400, loss is 4.441873664855957 and perplexity is 84.93393040199189
At time: 132.8994197845459 and batch: 1450, loss is 4.367429113388061 and perplexity is 78.84068047913986
At time: 134.06771755218506 and batch: 1500, loss is 4.372727818489075 and perplexity is 79.25954272872413
At time: 135.23695516586304 and batch: 1550, loss is 4.368554363250732 and perplexity is 78.92944587628125
At time: 136.40409874916077 and batch: 1600, loss is 4.460194206237793 and perplexity is 86.5043071411768
At time: 137.5699303150177 and batch: 1650, loss is 4.408820848464966 and perplexity is 82.17251251121377
At time: 138.7370104789734 and batch: 1700, loss is 4.444968338012695 and perplexity is 85.19718028257734
At time: 139.9034788608551 and batch: 1750, loss is 4.449227352142334 and perplexity is 85.56081007976557
At time: 141.06971049308777 and batch: 1800, loss is 4.403375997543335 and perplexity is 81.72631128267405
At time: 142.23761320114136 and batch: 1850, loss is 4.428019971847534 and perplexity is 83.76539476041643
At time: 143.402845621109 and batch: 1900, loss is 4.504916334152222 and perplexity is 90.4607752547964
At time: 144.569331407547 and batch: 1950, loss is 4.439973316192627 and perplexity is 84.772679585795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.517888694585756 and perplexity of 91.64190952261657
finished 3 epochs...
Completing Train Step...
At time: 148.22832655906677 and batch: 50, loss is 4.401209750175476 and perplexity is 81.54946349315917
At time: 149.4557764530182 and batch: 100, loss is 4.349160318374634 and perplexity is 77.41343298962279
At time: 150.62241101264954 and batch: 150, loss is 4.304246206283569 and perplexity is 74.01340358162086
At time: 151.78627634048462 and batch: 200, loss is 4.303453636169434 and perplexity is 73.95476601015953
At time: 152.94905257225037 and batch: 250, loss is 4.302732772827149 and perplexity is 73.90147394081289
At time: 154.11333322525024 and batch: 300, loss is 4.326295547485351 and perplexity is 75.6634750135003
At time: 155.28345108032227 and batch: 350, loss is 4.330040693283081 and perplexity is 75.94737705441965
At time: 156.44464492797852 and batch: 400, loss is 4.2931159973144535 and perplexity is 73.19418641948509
At time: 157.60853838920593 and batch: 450, loss is 4.312586326599121 and perplexity is 74.63326554111029
At time: 158.7687270641327 and batch: 500, loss is 4.333754844665528 and perplexity is 76.22998160306149
At time: 159.93395280838013 and batch: 550, loss is 4.292933111190796 and perplexity is 73.18080144245714
At time: 161.09466361999512 and batch: 600, loss is 4.2689998865127565 and perplexity is 71.45014162382044
At time: 162.25929284095764 and batch: 650, loss is 4.32541784286499 and perplexity is 75.59709396762517
At time: 163.419828414917 and batch: 700, loss is 4.3582528209686275 and perplexity is 78.12052457444811
At time: 164.58452677726746 and batch: 750, loss is 4.316456966400146 and perplexity is 74.92270382350205
At time: 165.74693846702576 and batch: 800, loss is 4.298409457206726 and perplexity is 73.58266419829633
At time: 166.91090607643127 and batch: 850, loss is 4.286317777633667 and perplexity is 72.69828379820505
At time: 168.0749635696411 and batch: 900, loss is 4.269613428115845 and perplexity is 71.49399270911019
At time: 169.2372088432312 and batch: 950, loss is 4.361933116912842 and perplexity is 78.40856092860149
At time: 170.40135788917542 and batch: 1000, loss is 4.3351907062530515 and perplexity is 76.33951592470656
At time: 171.56475257873535 and batch: 1050, loss is 4.274394969940186 and perplexity is 71.83666281829142
At time: 172.72792291641235 and batch: 1100, loss is 4.326361465454101 and perplexity is 75.66846276047103
At time: 173.89271783828735 and batch: 1150, loss is 4.271237678527832 and perplexity is 71.61021121464982
At time: 175.05862283706665 and batch: 1200, loss is 4.348790354728699 and perplexity is 77.3847981309646
At time: 176.22233057022095 and batch: 1250, loss is 4.321414108276367 and perplexity is 75.29502836646176
At time: 177.3845329284668 and batch: 1300, loss is 4.328221406936645 and perplexity is 75.80933263753333
At time: 178.54930877685547 and batch: 1350, loss is 4.199100856781006 and perplexity is 66.62639742705916
At time: 179.71333575248718 and batch: 1400, loss is 4.245878043174744 and perplexity is 69.81703561031239
At time: 180.87804651260376 and batch: 1450, loss is 4.1732732629776 and perplexity is 64.92762986822564
At time: 182.04257154464722 and batch: 1500, loss is 4.180441212654114 and perplexity is 65.39469981887048
At time: 183.20758724212646 and batch: 1550, loss is 4.181068272590637 and perplexity is 65.43571907460971
At time: 184.373370885849 and batch: 1600, loss is 4.27531976222992 and perplexity is 71.90312753847942
At time: 185.53720688819885 and batch: 1650, loss is 4.220681171417237 and perplexity is 68.07984254149828
At time: 186.70313477516174 and batch: 1700, loss is 4.262228803634644 and perplexity is 70.96798101012662
At time: 187.8651294708252 and batch: 1750, loss is 4.261938891410828 and perplexity is 70.94740950704143
At time: 189.03054094314575 and batch: 1800, loss is 4.217491593360901 and perplexity is 67.86304250377016
At time: 190.19701647758484 and batch: 1850, loss is 4.248287038803101 and perplexity is 69.98542728985734
At time: 191.36240696907043 and batch: 1900, loss is 4.328264694213868 and perplexity is 75.8126142881576
At time: 192.52678728103638 and batch: 1950, loss is 4.264811449050903 and perplexity is 71.15150302512049
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488382028978925 and perplexity of 88.97736655139005
finished 4 epochs...
Completing Train Step...
At time: 196.23875641822815 and batch: 50, loss is 4.224938950538635 and perplexity is 68.37032944935994
At time: 197.4089081287384 and batch: 100, loss is 4.179345569610596 and perplexity is 65.3230898075999
At time: 198.57652306556702 and batch: 150, loss is 4.132668681144715 and perplexity is 62.34407759360607
At time: 199.7454912662506 and batch: 200, loss is 4.141471529006958 and perplexity is 62.89530565258823
At time: 200.91362047195435 and batch: 250, loss is 4.138983397483826 and perplexity is 62.739008384650376
At time: 202.08325338363647 and batch: 300, loss is 4.156888337135315 and perplexity is 63.87246348542072
At time: 203.25363874435425 and batch: 350, loss is 4.161561017036438 and perplexity is 64.17161744281744
At time: 204.42334961891174 and batch: 400, loss is 4.133287811279297 and perplexity is 62.3826886421555
At time: 205.5935173034668 and batch: 450, loss is 4.151808581352234 and perplexity is 63.548829655977514
At time: 206.76148390769958 and batch: 500, loss is 4.17798047542572 and perplexity is 65.23397847408515
At time: 207.92852473258972 and batch: 550, loss is 4.135265340805054 and perplexity is 62.506174308875266
At time: 209.14266085624695 and batch: 600, loss is 4.11784984588623 and perplexity is 61.42702260369623
At time: 210.3108253479004 and batch: 650, loss is 4.171573963165283 and perplexity is 64.8173920490562
At time: 211.47837662696838 and batch: 700, loss is 4.204287695884704 and perplexity is 66.9728756171012
At time: 212.6473844051361 and batch: 750, loss is 4.170794801712036 and perplexity is 64.76690850564111
At time: 213.8135964870453 and batch: 800, loss is 4.148194284439087 and perplexity is 63.31955989120126
At time: 214.9824776649475 and batch: 850, loss is 4.133225660324097 and perplexity is 62.37881161895004
At time: 216.1469383239746 and batch: 900, loss is 4.1190012121200565 and perplexity is 61.49778833418541
At time: 217.3143355846405 and batch: 950, loss is 4.213694715499878 and perplexity is 67.60586336795335
At time: 218.47969102859497 and batch: 1000, loss is 4.185079402923584 and perplexity is 65.69871737986944
At time: 219.64769744873047 and batch: 1050, loss is 4.132612338066101 and perplexity is 62.340565035296244
At time: 220.81570148468018 and batch: 1100, loss is 4.177225160598755 and perplexity is 65.18472488624592
At time: 221.98340582847595 and batch: 1150, loss is 4.130521340370178 and perplexity is 62.2103472474377
At time: 223.15290451049805 and batch: 1200, loss is 4.204328899383545 and perplexity is 66.97563519075568
At time: 224.3189046382904 and batch: 1250, loss is 4.179479694366455 and perplexity is 65.3318518386618
At time: 225.48541164398193 and batch: 1300, loss is 4.181017999649048 and perplexity is 65.43242951121553
At time: 226.6517186164856 and batch: 1350, loss is 4.05125696182251 and perplexity is 57.46964881930834
At time: 227.8175265789032 and batch: 1400, loss is 4.101843409538269 and perplexity is 60.45162204502453
At time: 228.98389744758606 and batch: 1450, loss is 4.027857322692871 and perplexity is 56.140491325907774
At time: 230.1502549648285 and batch: 1500, loss is 4.034815282821655 and perplexity is 56.532476754216326
At time: 231.31623458862305 and batch: 1550, loss is 4.035030512809754 and perplexity is 56.544645548013015
At time: 232.48102378845215 and batch: 1600, loss is 4.1363784694671635 and perplexity is 62.57579046173665
At time: 233.6484489440918 and batch: 1650, loss is 4.080121908187866 and perplexity is 59.15268060644837
At time: 234.81420636177063 and batch: 1700, loss is 4.122824664115906 and perplexity is 61.733372260653155
At time: 235.9798846244812 and batch: 1750, loss is 4.120378198623658 and perplexity is 61.58252828821984
At time: 237.14856147766113 and batch: 1800, loss is 4.070105037689209 and perplexity is 58.56311360296846
At time: 238.31515836715698 and batch: 1850, loss is 4.110866966247559 and perplexity is 60.99957922798034
At time: 239.48207116127014 and batch: 1900, loss is 4.189808301925659 and perplexity is 66.01013573155045
At time: 240.65497255325317 and batch: 1950, loss is 4.121886053085327 and perplexity is 61.675455821250914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485125022710756 and perplexity of 88.68803813880214
finished 5 epochs...
Completing Train Step...
At time: 244.37376809120178 and batch: 50, loss is 4.092105507850647 and perplexity is 59.86580702645798
At time: 245.56560564041138 and batch: 100, loss is 4.052778358459473 and perplexity is 57.557149494488165
At time: 246.731698513031 and batch: 150, loss is 4.002858333587646 and perplexity is 54.75443300724077
At time: 247.89714932441711 and batch: 200, loss is 4.01355975151062 and perplexity is 55.34352954013364
At time: 249.0620996952057 and batch: 250, loss is 4.0101069068908695 and perplexity is 55.15276645908725
At time: 250.2277340888977 and batch: 300, loss is 4.023699135780334 and perplexity is 55.90753334668679
At time: 251.39424061775208 and batch: 350, loss is 4.03052303314209 and perplexity is 56.290345265126696
At time: 252.560072183609 and batch: 400, loss is 4.003647060394287 and perplexity is 54.797636331906446
At time: 253.7257423400879 and batch: 450, loss is 4.026587042808533 and perplexity is 56.069222464363584
At time: 254.89212322235107 and batch: 500, loss is 4.055940890312195 and perplexity is 57.73946394879776
At time: 256.0584375858307 and batch: 550, loss is 4.011834330558777 and perplexity is 55.248120988343175
At time: 257.224730014801 and batch: 600, loss is 3.9965629100799562 and perplexity is 54.410813412843346
At time: 258.3907642364502 and batch: 650, loss is 4.051121439933777 and perplexity is 57.46186095168069
At time: 259.556693315506 and batch: 700, loss is 4.080488214492798 and perplexity is 59.17435257535519
At time: 260.72334933280945 and batch: 750, loss is 4.047043180465698 and perplexity is 57.227993782842574
At time: 261.8921070098877 and batch: 800, loss is 4.025980291366577 and perplexity is 56.035212701563665
At time: 263.0584247112274 and batch: 850, loss is 4.012719216346741 and perplexity is 55.29703090206978
At time: 264.2225012779236 and batch: 900, loss is 3.9945340013504027 and perplexity is 54.30053075308475
At time: 265.38835072517395 and batch: 950, loss is 4.08921516418457 and perplexity is 59.693024091622085
At time: 266.55268454551697 and batch: 1000, loss is 4.062706198692322 and perplexity is 58.13141356317962
At time: 267.7660050392151 and batch: 1050, loss is 4.016033587455749 and perplexity is 55.48060984001756
At time: 268.93040561676025 and batch: 1100, loss is 4.0570072746276855 and perplexity is 57.80106924916261
At time: 270.0973126888275 and batch: 1150, loss is 4.012424840927124 and perplexity is 55.2807552110936
At time: 271.26128935813904 and batch: 1200, loss is 4.091716051101685 and perplexity is 59.84249642340992
At time: 272.42443656921387 and batch: 1250, loss is 4.068635106086731 and perplexity is 58.477093069183184
At time: 273.58752036094666 and batch: 1300, loss is 4.068242073059082 and perplexity is 58.454114156277754
At time: 274.75071382522583 and batch: 1350, loss is 3.935717906951904 and perplexity is 51.19889280718145
At time: 275.9127953052521 and batch: 1400, loss is 3.9879162406921385 and perplexity is 53.94236925760316
At time: 277.0788300037384 and batch: 1450, loss is 3.9100057888031006 and perplexity is 49.89924082945183
At time: 278.2458529472351 and batch: 1500, loss is 3.9168669271469114 and perplexity is 50.242783623657886
At time: 279.41354060173035 and batch: 1550, loss is 3.9246358013153078 and perplexity is 50.63463363335561
At time: 280.57863903045654 and batch: 1600, loss is 4.021321845054627 and perplexity is 55.77478274207524
At time: 281.74445128440857 and batch: 1650, loss is 3.9687218952178953 and perplexity is 52.91685431548976
At time: 282.9095211029053 and batch: 1700, loss is 4.01172447681427 and perplexity is 55.24205210872629
At time: 284.0724756717682 and batch: 1750, loss is 4.008793444633484 and perplexity is 55.080372935441
At time: 285.23515796661377 and batch: 1800, loss is 3.954208827018738 and perplexity is 52.15441445340686
At time: 286.3984706401825 and batch: 1850, loss is 3.997634449005127 and perplexity is 54.4691479656558
At time: 287.56116914749146 and batch: 1900, loss is 4.077611131668091 and perplexity is 59.004347738165485
At time: 288.7239227294922 and batch: 1950, loss is 4.0077093935012815 and perplexity is 55.020695347420904
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487413699127907 and perplexity of 88.89124881321078
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 292.4715938568115 and batch: 50, loss is 4.014478511810303 and perplexity is 55.39440034337825
At time: 293.6332380771637 and batch: 100, loss is 3.999612650871277 and perplexity is 54.5770055827056
At time: 294.794193983078 and batch: 150, loss is 3.957697148323059 and perplexity is 52.33666349526043
At time: 295.95697045326233 and batch: 200, loss is 3.9635001277923583 and perplexity is 52.641254993371554
At time: 297.1181170940399 and batch: 250, loss is 3.963834481239319 and perplexity is 52.65885872120047
At time: 298.31334400177 and batch: 300, loss is 3.9766785430908205 and perplexity is 53.33957457982954
At time: 299.47627305984497 and batch: 350, loss is 3.976624598503113 and perplexity is 53.33669727607852
At time: 300.63940954208374 and batch: 400, loss is 3.937722768783569 and perplexity is 51.301642478224316
At time: 301.8016119003296 and batch: 450, loss is 3.9502616214752195 and perplexity is 51.94895601965261
At time: 302.97106289863586 and batch: 500, loss is 3.974357123374939 and perplexity is 53.21589465181735
At time: 304.13547706604004 and batch: 550, loss is 3.9286504697799685 and perplexity is 50.83832350028381
At time: 305.29772567749023 and batch: 600, loss is 3.901199049949646 and perplexity is 49.46172063730481
At time: 306.46150040626526 and batch: 650, loss is 3.944673056602478 and perplexity is 51.659445636145385
At time: 307.6261703968048 and batch: 700, loss is 3.97857834815979 and perplexity is 53.44100569315701
At time: 308.79032135009766 and batch: 750, loss is 3.936948380470276 and perplexity is 51.261930464080784
At time: 309.95320296287537 and batch: 800, loss is 3.9047442865371704 and perplexity is 49.63738534146853
At time: 311.1162140369415 and batch: 850, loss is 3.885666904449463 and perplexity is 48.69940948495694
At time: 312.28140473365784 and batch: 900, loss is 3.8599132680892945 and perplexity is 47.46123478675909
At time: 313.4442322254181 and batch: 950, loss is 3.951187586784363 and perplexity is 51.99708122847136
At time: 314.60826539993286 and batch: 1000, loss is 3.90755033493042 and perplexity is 49.77686584985791
At time: 315.77295541763306 and batch: 1050, loss is 3.8642933130264283 and perplexity is 47.66957306031999
At time: 316.9376919269562 and batch: 1100, loss is 3.890326771736145 and perplexity is 48.92687183066865
At time: 318.09976029396057 and batch: 1150, loss is 3.8492688179016112 and perplexity is 46.95871530382112
At time: 319.2634334564209 and batch: 1200, loss is 3.912698464393616 and perplexity is 50.03378435696239
At time: 320.4267110824585 and batch: 1250, loss is 3.882819051742554 and perplexity is 48.56091803505576
At time: 321.59327840805054 and batch: 1300, loss is 3.880214424133301 and perplexity is 48.434599504989436
At time: 322.7577152252197 and batch: 1350, loss is 3.7400525188446045 and perplexity is 42.100201160859505
At time: 323.9222719669342 and batch: 1400, loss is 3.7714282941818236 and perplexity is 43.44206859933034
At time: 325.087069272995 and batch: 1450, loss is 3.6913226413726807 and perplexity is 40.097846970914055
At time: 326.2529606819153 and batch: 1500, loss is 3.686738805770874 and perplexity is 39.91446564842404
At time: 327.4173016548157 and batch: 1550, loss is 3.6907515811920164 and perplexity is 40.07495522408323
At time: 328.5824863910675 and batch: 1600, loss is 3.7801590156555176 and perplexity is 43.823009726167854
At time: 329.74589681625366 and batch: 1650, loss is 3.7116839599609377 and perplexity is 40.92266065896338
At time: 330.90996527671814 and batch: 1700, loss is 3.7411678791046143 and perplexity is 42.147184248836666
At time: 332.0733947753906 and batch: 1750, loss is 3.730785622596741 and perplexity is 41.71186507881638
At time: 333.236209154129 and batch: 1800, loss is 3.6703910779953004 and perplexity is 39.26725941898386
At time: 334.3997287750244 and batch: 1850, loss is 3.698161211013794 and perplexity is 40.3729986394952
At time: 335.5616693496704 and batch: 1900, loss is 3.771025094985962 and perplexity is 43.424556322909666
At time: 336.7252314090729 and batch: 1950, loss is 3.696381607055664 and perplexity is 40.30121458385452
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411659418150436 and perplexity of 82.4060962792672
finished 7 epochs...
Completing Train Step...
At time: 340.4960916042328 and batch: 50, loss is 3.911455488204956 and perplexity is 49.97163218921249
At time: 341.69054555892944 and batch: 100, loss is 3.8778404426574706 and perplexity is 48.31975303860473
At time: 342.8584430217743 and batch: 150, loss is 3.8326733779907225 and perplexity is 46.18584556023311
At time: 344.02501106262207 and batch: 200, loss is 3.837340097427368 and perplexity is 46.40188565056982
At time: 345.1924784183502 and batch: 250, loss is 3.83547043800354 and perplexity is 46.31521097908653
At time: 346.3594398498535 and batch: 300, loss is 3.8469856548309327 and perplexity is 46.851623200082244
At time: 347.52673983573914 and batch: 350, loss is 3.8513233423233033 and perplexity is 47.055292307158545
At time: 348.69327569007874 and batch: 400, loss is 3.819418067932129 and perplexity is 45.57767748991633
At time: 349.8595540523529 and batch: 450, loss is 3.8354138851165773 and perplexity is 46.3125917942573
At time: 351.0266902446747 and batch: 500, loss is 3.861328706741333 and perplexity is 47.528460818888135
At time: 352.1954526901245 and batch: 550, loss is 3.8180700397491454 and perplexity is 45.51627888896492
At time: 353.3616464138031 and batch: 600, loss is 3.798419227600098 and perplexity is 44.63057791577827
At time: 354.5289194583893 and batch: 650, loss is 3.837619185447693 and perplexity is 46.414837668267786
At time: 355.6926577091217 and batch: 700, loss is 3.8763880443573 and perplexity is 48.24962445107525
At time: 356.89777159690857 and batch: 750, loss is 3.837742109298706 and perplexity is 46.42054350954293
At time: 358.06725430488586 and batch: 800, loss is 3.806135792732239 and perplexity is 44.97630487391049
At time: 359.23491978645325 and batch: 850, loss is 3.790338187217712 and perplexity is 44.271369755959384
At time: 360.4032723903656 and batch: 900, loss is 3.764978904724121 and perplexity is 43.162795319181036
At time: 361.56956911087036 and batch: 950, loss is 3.8577741718292238 and perplexity is 47.35981914450983
At time: 362.73891830444336 and batch: 1000, loss is 3.817694306373596 and perplexity is 45.499180116346466
At time: 363.9085433483124 and batch: 1050, loss is 3.7805318593978883 and perplexity is 43.839351907466806
At time: 365.07974219322205 and batch: 1100, loss is 3.8068624210357664 and perplexity is 45.00899780638654
At time: 366.2467453479767 and batch: 1150, loss is 3.7726683044433593 and perplexity is 43.4959706228002
At time: 367.412978887558 and batch: 1200, loss is 3.8386658906936644 and perplexity is 46.46344575707897
At time: 368.5801455974579 and batch: 1250, loss is 3.8134308576583864 and perplexity is 45.3056096274731
At time: 369.74604845046997 and batch: 1300, loss is 3.8108302402496337 and perplexity is 45.18794014333483
At time: 370.91260623931885 and batch: 1350, loss is 3.673055634498596 and perplexity is 39.372028770376296
At time: 372.07941222190857 and batch: 1400, loss is 3.708697600364685 and perplexity is 40.80063317825953
At time: 373.2476329803467 and batch: 1450, loss is 3.6310520792007446 and perplexity is 37.752514366072454
At time: 374.41494369506836 and batch: 1500, loss is 3.6295936918258667 and perplexity is 37.69749670403432
At time: 375.58079290390015 and batch: 1550, loss is 3.639312324523926 and perplexity is 38.06565090814844
At time: 376.74710631370544 and batch: 1600, loss is 3.7303063106536865 and perplexity is 41.69187687439226
At time: 377.91332387924194 and batch: 1650, loss is 3.6667317247390745 and perplexity is 39.1238292362735
At time: 379.0810580253601 and batch: 1700, loss is 3.69963942527771 and perplexity is 40.432722713574925
At time: 380.2485513687134 and batch: 1750, loss is 3.69498046875 and perplexity is 40.24478654930821
At time: 381.4176506996155 and batch: 1800, loss is 3.6387534236907957 and perplexity is 38.04438192832116
At time: 382.58428406715393 and batch: 1850, loss is 3.671491599082947 and perplexity is 39.31049765395924
At time: 383.7505021095276 and batch: 1900, loss is 3.7480137872695924 and perplexity is 42.43670990388693
At time: 384.9163842201233 and batch: 1950, loss is 3.6763986778259277 and perplexity is 39.503871423502744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419923294422238 and perplexity of 83.08991165421797
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 388.60584902763367 and batch: 50, loss is 3.8737609577178955 and perplexity is 48.1230348610396
At time: 389.77079820632935 and batch: 100, loss is 3.8695966386795044 and perplexity is 47.923051876259265
At time: 390.9352400302887 and batch: 150, loss is 3.836502819061279 and perplexity is 46.36305061570485
At time: 392.1006941795349 and batch: 200, loss is 3.840740456581116 and perplexity is 46.55993729107561
At time: 393.2659068107605 and batch: 250, loss is 3.840478820800781 and perplexity is 46.547757139001405
At time: 394.4309117794037 and batch: 300, loss is 3.8579988574981687 and perplexity is 47.370461412693224
At time: 395.5969250202179 and batch: 350, loss is 3.8771831941604615 and perplexity is 48.28800538773502
At time: 396.7627248764038 and batch: 400, loss is 3.8467843389511107 and perplexity is 46.842192173676175
At time: 397.9283423423767 and batch: 450, loss is 3.850697193145752 and perplexity is 47.02583789697068
At time: 399.09440517425537 and batch: 500, loss is 3.8704322528839112 and perplexity is 47.96311379494864
At time: 400.25945496559143 and batch: 550, loss is 3.82383171081543 and perplexity is 45.77928566777553
At time: 401.42371916770935 and batch: 600, loss is 3.7959298944473265 and perplexity is 44.519615706798625
At time: 402.58761072158813 and batch: 650, loss is 3.8200662755966186 and perplexity is 45.607230867122944
At time: 403.7580041885376 and batch: 700, loss is 3.860924072265625 and perplexity is 47.50923305543381
At time: 404.9212279319763 and batch: 750, loss is 3.823289170265198 and perplexity is 45.754455285293865
At time: 406.0869879722595 and batch: 800, loss is 3.7943858766555785 and perplexity is 44.45092966794413
At time: 407.2519760131836 and batch: 850, loss is 3.7826567029953004 and perplexity is 43.93260271028244
At time: 408.4174313545227 and batch: 900, loss is 3.7563676548004152 and perplexity is 42.79270545638909
At time: 409.5836274623871 and batch: 950, loss is 3.8533808851242064 and perplexity is 47.15221025731314
At time: 410.74978828430176 and batch: 1000, loss is 3.791861443519592 and perplexity is 44.33885778666761
At time: 411.91424107551575 and batch: 1050, loss is 3.7468628454208375 and perplexity is 42.38789581501245
At time: 413.0777313709259 and batch: 1100, loss is 3.7650797271728518 and perplexity is 43.16714731728504
At time: 414.24202585220337 and batch: 1150, loss is 3.7397797775268553 and perplexity is 42.08872026224626
At time: 415.4526643753052 and batch: 1200, loss is 3.8052151203155518 and perplexity is 44.934915486565814
At time: 416.61910247802734 and batch: 1250, loss is 3.779008412361145 and perplexity is 43.77261582406214
At time: 417.7836060523987 and batch: 1300, loss is 3.7801935052871705 and perplexity is 43.82452119169602
At time: 418.9495851993561 and batch: 1350, loss is 3.642071690559387 and perplexity is 38.17083302362167
At time: 420.11488795280457 and batch: 1400, loss is 3.671427788734436 and perplexity is 39.30798931743357
At time: 421.27959156036377 and batch: 1450, loss is 3.5861542987823487 and perplexity is 36.0949980938673
At time: 422.44465017318726 and batch: 1500, loss is 3.5721192836761473 and perplexity is 35.591942703062415
At time: 423.60917925834656 and batch: 1550, loss is 3.582584228515625 and perplexity is 35.96636616353195
At time: 424.7819275856018 and batch: 1600, loss is 3.6670164823532105 and perplexity is 39.134971630908254
At time: 425.94997215270996 and batch: 1650, loss is 3.602133798599243 and perplexity is 36.676411082007206
At time: 427.11368322372437 and batch: 1700, loss is 3.6228876399993895 and perplexity is 37.44554109532031
At time: 428.2801969051361 and batch: 1750, loss is 3.6182724952697756 and perplexity is 37.27312267769866
At time: 429.4455723762512 and batch: 1800, loss is 3.559989233016968 and perplexity is 35.16281854559778
At time: 430.61099100112915 and batch: 1850, loss is 3.593259596824646 and perplexity is 36.35237710764209
At time: 431.77652502059937 and batch: 1900, loss is 3.6763163709640505 and perplexity is 39.500620117618105
At time: 432.94574761390686 and batch: 1950, loss is 3.601390175819397 and perplexity is 36.64914780529677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389009129723838 and perplexity of 80.5605543605254
finished 9 epochs...
Completing Train Step...
At time: 436.59658336639404 and batch: 50, loss is 3.859525594711304 and perplexity is 47.44283889557474
At time: 437.78981018066406 and batch: 100, loss is 3.8365804624557494 and perplexity is 46.36665054008602
At time: 438.95659589767456 and batch: 150, loss is 3.7939983415603638 and perplexity is 44.433706710148726
At time: 440.123416185379 and batch: 200, loss is 3.7934181356430052 and perplexity is 44.40793348819629
At time: 441.28975009918213 and batch: 250, loss is 3.7905107975006103 and perplexity is 44.27901210917264
At time: 442.4580018520355 and batch: 300, loss is 3.8033126401901245 and perplexity is 44.84950897077455
At time: 443.62311244010925 and batch: 350, loss is 3.8236238813400267 and perplexity is 45.7697723714568
At time: 444.7886598110199 and batch: 400, loss is 3.793902587890625 and perplexity is 44.42945222336576
At time: 445.98104667663574 and batch: 450, loss is 3.801672730445862 and perplexity is 44.776020098016744
At time: 447.14891028404236 and batch: 500, loss is 3.821530303955078 and perplexity is 45.674050047115514
At time: 448.3163216114044 and batch: 550, loss is 3.778121256828308 and perplexity is 43.7337999261622
At time: 449.4815471172333 and batch: 600, loss is 3.7544554615020753 and perplexity is 42.71095571735882
At time: 450.6485331058502 and batch: 650, loss is 3.7803371572494506 and perplexity is 43.830817122361765
At time: 451.8144519329071 and batch: 700, loss is 3.8230588674545287 and perplexity is 45.74391911894196
At time: 452.97890162467957 and batch: 750, loss is 3.7876388454437255 and perplexity is 44.152027343630174
At time: 454.14616870880127 and batch: 800, loss is 3.7573176527023318 and perplexity is 42.83337775302935
At time: 455.3132655620575 and batch: 850, loss is 3.743888063430786 and perplexity is 42.26198843230265
At time: 456.48078870773315 and batch: 900, loss is 3.7180348587036134 and perplexity is 41.18338336852346
At time: 457.64743161201477 and batch: 950, loss is 3.815188069343567 and perplexity is 45.385291162273404
At time: 458.81347846984863 and batch: 1000, loss is 3.7572274875640868 and perplexity is 42.829515849709885
At time: 459.9818060398102 and batch: 1050, loss is 3.71530620098114 and perplexity is 41.071161189045554
At time: 461.1500041484833 and batch: 1100, loss is 3.7356386041641234 and perplexity is 41.91478397376109
At time: 462.31682443618774 and batch: 1150, loss is 3.7127147817611696 and perplexity is 40.96486637924512
At time: 463.48316168785095 and batch: 1200, loss is 3.780410785675049 and perplexity is 43.8340444352287
At time: 464.6515007019043 and batch: 1250, loss is 3.757520203590393 and perplexity is 42.842054570450756
At time: 465.81875109672546 and batch: 1300, loss is 3.7598774814605713 and perplexity is 42.94316432267314
At time: 466.9865963459015 and batch: 1350, loss is 3.6233216094970704 and perplexity is 37.461794844540435
At time: 468.15431928634644 and batch: 1400, loss is 3.654018564224243 and perplexity is 38.62959004307936
At time: 469.3206613063812 and batch: 1450, loss is 3.5691053581237795 and perplexity is 35.484832729314626
At time: 470.4852705001831 and batch: 1500, loss is 3.557628149986267 and perplexity is 35.079894145638264
At time: 471.65049171447754 and batch: 1550, loss is 3.5710344552993774 and perplexity is 35.55335248929782
At time: 472.82004594802856 and batch: 1600, loss is 3.6581510639190675 and perplexity is 38.78955711643069
At time: 473.98659324645996 and batch: 1650, loss is 3.594241728782654 and perplexity is 36.388097477136014
At time: 475.1537218093872 and batch: 1700, loss is 3.6181968593597413 and perplexity is 37.27030359775829
At time: 476.32127952575684 and batch: 1750, loss is 3.6159263324737547 and perplexity is 37.1857763683777
At time: 477.4867994785309 and batch: 1800, loss is 3.5595359659194945 and perplexity is 35.14688400847015
At time: 478.6528172492981 and batch: 1850, loss is 3.5951266431808473 and perplexity is 36.420312079997146
At time: 479.81905364990234 and batch: 1900, loss is 3.679464702606201 and perplexity is 39.62517714034291
At time: 480.99066185951233 and batch: 1950, loss is 3.604750995635986 and perplexity is 36.77252619764386
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3899439612100295 and perplexity of 80.63590011559167
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 484.711421251297 and batch: 50, loss is 3.848454418182373 and perplexity is 46.92048770764656
At time: 485.8776578903198 and batch: 100, loss is 3.8425602102279663 and perplexity is 46.6447420452359
At time: 487.0402021408081 and batch: 150, loss is 3.811996397972107 and perplexity is 45.240667146721336
At time: 488.20379424095154 and batch: 200, loss is 3.8169544506073 and perplexity is 45.46552973532483
At time: 489.36745500564575 and batch: 250, loss is 3.815689482688904 and perplexity is 45.40805365917713
At time: 490.52982330322266 and batch: 300, loss is 3.8241382598876954 and perplexity is 45.79332141653894
At time: 491.69303846359253 and batch: 350, loss is 3.8509565591812134 and perplexity is 47.038036383978486
At time: 492.85676169395447 and batch: 400, loss is 3.833889961242676 and perplexity is 46.24206867953711
At time: 494.02022075653076 and batch: 450, loss is 3.8484968519210816 and perplexity is 46.92247876160566
At time: 495.1841495037079 and batch: 500, loss is 3.872474160194397 and perplexity is 48.06115008408535
At time: 496.34774351119995 and batch: 550, loss is 3.8276571798324586 and perplexity is 45.954748306183
At time: 497.5104470252991 and batch: 600, loss is 3.7938395881652833 and perplexity is 44.42665326824622
At time: 498.67396092414856 and batch: 650, loss is 3.8036265325546266 and perplexity is 44.86358909889889
At time: 499.84014558792114 and batch: 700, loss is 3.8373712158203124 and perplexity is 46.40332962514781
At time: 501.0029356479645 and batch: 750, loss is 3.802651925086975 and perplexity is 44.81988601007513
At time: 502.16910099983215 and batch: 800, loss is 3.774490852355957 and perplexity is 43.57531639703936
At time: 503.3328216075897 and batch: 850, loss is 3.7672410440444946 and perplexity is 43.26054609690394
At time: 504.54249238967896 and batch: 900, loss is 3.736305446624756 and perplexity is 41.942743852824215
At time: 505.7059054374695 and batch: 950, loss is 3.8515175771713257 and perplexity is 47.064432972397604
At time: 506.8690209388733 and batch: 1000, loss is 3.7945930767059326 and perplexity is 44.46014085705609
At time: 508.0321538448334 and batch: 1050, loss is 3.742397265434265 and perplexity is 42.19903128447379
At time: 509.19557547569275 and batch: 1100, loss is 3.746292676925659 and perplexity is 42.36373446091783
At time: 510.3590717315674 and batch: 1150, loss is 3.7143462800979616 and perplexity is 41.03175504014232
At time: 511.52285051345825 and batch: 1200, loss is 3.772800645828247 and perplexity is 43.50172732070574
At time: 512.6850235462189 and batch: 1250, loss is 3.7497714281082155 and perplexity is 42.51136398658398
At time: 513.8484802246094 and batch: 1300, loss is 3.756872968673706 and perplexity is 42.81433466844208
At time: 515.0101101398468 and batch: 1350, loss is 3.6252786207199095 and perplexity is 37.53517978163026
At time: 516.1718695163727 and batch: 1400, loss is 3.669000296592712 and perplexity is 39.21268520405171
At time: 517.3352208137512 and batch: 1450, loss is 3.5815549421310426 and perplexity is 35.92936551793393
At time: 518.4952530860901 and batch: 1500, loss is 3.569364948272705 and perplexity is 35.494045438039905
At time: 519.6584053039551 and batch: 1550, loss is 3.5824320268630983 and perplexity is 35.96089243973196
At time: 520.8172855377197 and batch: 1600, loss is 3.6615141010284424 and perplexity is 38.92022743788257
At time: 521.9773182868958 and batch: 1650, loss is 3.592962551116943 and perplexity is 36.34158039369563
At time: 523.1374161243439 and batch: 1700, loss is 3.6049455070495604 and perplexity is 36.779679569378935
At time: 524.2975068092346 and batch: 1750, loss is 3.5984302759170532 and perplexity is 36.540830379736356
At time: 525.4575200080872 and batch: 1800, loss is 3.5396750783920288 and perplexity is 34.45572196326119
At time: 526.6170835494995 and batch: 1850, loss is 3.57622859954834 and perplexity is 35.73850216144921
At time: 527.7766876220703 and batch: 1900, loss is 3.663315467834473 and perplexity is 38.99040022816445
At time: 528.9356024265289 and batch: 1950, loss is 3.6010039186477663 and perplexity is 36.63499454269837
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36989377043968 and perplexity of 79.03523537529975
finished 11 epochs...
Completing Train Step...
At time: 532.5794715881348 and batch: 50, loss is 3.859182138442993 and perplexity is 47.42654715308029
At time: 533.7655999660492 and batch: 100, loss is 3.838846926689148 and perplexity is 46.471858074678366
At time: 534.9289102554321 and batch: 150, loss is 3.7968313455581666 and perplexity is 44.559766057902095
At time: 536.0938646793365 and batch: 200, loss is 3.796949152946472 and perplexity is 44.56501583679018
At time: 537.2574725151062 and batch: 250, loss is 3.793998079299927 and perplexity is 44.43369505694692
At time: 538.4224011898041 and batch: 300, loss is 3.8003872346878054 and perplexity is 44.71849769444229
At time: 539.5892238616943 and batch: 350, loss is 3.824732551574707 and perplexity is 45.82054409508199
At time: 540.7540016174316 and batch: 400, loss is 3.804782299995422 and perplexity is 44.91547095035867
At time: 541.9230763912201 and batch: 450, loss is 3.820592188835144 and perplexity is 45.63122262184618
At time: 543.1029980182648 and batch: 500, loss is 3.844080753326416 and perplexity is 46.715721335691214
At time: 544.2737979888916 and batch: 550, loss is 3.8002676582336425 and perplexity is 44.71315073474411
At time: 545.4386110305786 and batch: 600, loss is 3.7689852857589723 and perplexity is 43.33606879176724
At time: 546.6049132347107 and batch: 650, loss is 3.7811638164520263 and perplexity is 43.86706525105273
At time: 547.7699823379517 and batch: 700, loss is 3.8177556705474855 and perplexity is 45.501972221613684
At time: 548.9364867210388 and batch: 750, loss is 3.7862114191055296 and perplexity is 44.08904853641273
At time: 550.1022815704346 and batch: 800, loss is 3.7583454608917237 and perplexity is 42.877424881585384
At time: 551.2681665420532 and batch: 850, loss is 3.7513400650024415 and perplexity is 42.57810121010814
At time: 552.4344065189362 and batch: 900, loss is 3.7215178489685057 and perplexity is 41.3270747845102
At time: 553.60040974617 and batch: 950, loss is 3.8356537294387816 and perplexity is 46.323700938625066
At time: 554.7684531211853 and batch: 1000, loss is 3.778967866897583 and perplexity is 43.7708410790414
At time: 555.9352593421936 and batch: 1050, loss is 3.7271344661712646 and perplexity is 41.559846225800776
At time: 557.1015462875366 and batch: 1100, loss is 3.732821717262268 and perplexity is 41.79688090555751
At time: 558.2677402496338 and batch: 1150, loss is 3.7021568059921264 and perplexity is 40.53463549277771
At time: 559.4347660541534 and batch: 1200, loss is 3.7609990215301514 and perplexity is 42.9913538203506
At time: 560.6009104251862 and batch: 1250, loss is 3.740321660041809 and perplexity is 42.11153358434509
At time: 561.7688212394714 and batch: 1300, loss is 3.7486792516708376 and perplexity is 42.46495942211579
At time: 562.934255361557 and batch: 1350, loss is 3.617432041168213 and perplexity is 37.24180948935813
At time: 564.1007254123688 and batch: 1400, loss is 3.661743903160095 and perplexity is 38.92917241686046
At time: 565.2667229175568 and batch: 1450, loss is 3.5756110906600953 and perplexity is 35.71644013116292
At time: 566.4323079586029 and batch: 1500, loss is 3.5649910831451415 and perplexity is 35.339138288907826
At time: 567.5972421169281 and batch: 1550, loss is 3.579358286857605 and perplexity is 35.8505277091432
At time: 568.7639331817627 and batch: 1600, loss is 3.6607198572158812 and perplexity is 38.88932756069906
At time: 569.9289076328278 and batch: 1650, loss is 3.5935970973968505 and perplexity is 36.36464812633835
At time: 571.0926208496094 and batch: 1700, loss is 3.6077136850357054 and perplexity is 36.881633316655424
At time: 572.2571046352386 and batch: 1750, loss is 3.6030325078964234 and perplexity is 36.70938732944438
At time: 573.4227879047394 and batch: 1800, loss is 3.5446004819869996 and perplexity is 34.62584892813433
At time: 574.5875391960144 and batch: 1850, loss is 3.5819496297836304 and perplexity is 35.9435491937459
At time: 575.7522792816162 and batch: 1900, loss is 3.668622012138367 and perplexity is 39.19785446012267
At time: 576.9176075458527 and batch: 1950, loss is 3.60554060459137 and perplexity is 36.80157358016908
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368526582939681 and perplexity of 78.92725322218013
finished 12 epochs...
Completing Train Step...
At time: 580.583820104599 and batch: 50, loss is 3.8533470106124876 and perplexity is 47.15061302626708
At time: 581.7457456588745 and batch: 100, loss is 3.8307607889175417 and perplexity is 46.09759543669154
At time: 582.9067468643188 and batch: 150, loss is 3.787994680404663 and perplexity is 44.167740974119056
At time: 584.068874835968 and batch: 200, loss is 3.787194609642029 and perplexity is 44.13241778832239
At time: 585.2309503555298 and batch: 250, loss is 3.7832455444335937 and perplexity is 43.958479665214305
At time: 586.3930134773254 and batch: 300, loss is 3.7887641906738283 and perplexity is 44.20174158459615
At time: 587.5555074214935 and batch: 350, loss is 3.8125906085968015 and perplexity is 45.26755762031952
At time: 588.7186424732208 and batch: 400, loss is 3.7916248178482057 and perplexity is 44.32836731588163
At time: 589.8804068565369 and batch: 450, loss is 3.8083325815200806 and perplexity is 45.07521692083574
At time: 591.0436890125275 and batch: 500, loss is 3.831840124130249 and perplexity is 46.147377055361666
At time: 592.2054240703583 and batch: 550, loss is 3.7881761980056763 and perplexity is 44.175758924180364
At time: 593.4117240905762 and batch: 600, loss is 3.7580517864227296 and perplexity is 42.86483472539565
At time: 594.5738453865051 and batch: 650, loss is 3.770859479904175 and perplexity is 43.41736515696188
At time: 595.7379097938538 and batch: 700, loss is 3.8083590984344484 and perplexity is 45.07641219235033
At time: 596.8993060588837 and batch: 750, loss is 3.7777850818634033 and perplexity is 43.719100188487204
At time: 598.0639605522156 and batch: 800, loss is 3.749947943687439 and perplexity is 42.51886856693984
At time: 599.2277927398682 and batch: 850, loss is 3.7425959968566893 and perplexity is 42.20741839134911
At time: 600.3899207115173 and batch: 900, loss is 3.7132282972335817 and perplexity is 40.98590787406035
At time: 601.5532202720642 and batch: 950, loss is 3.8273221588134767 and perplexity is 45.93935507824984
At time: 602.7242665290833 and batch: 1000, loss is 3.7713362550735474 and perplexity is 43.438070414072314
At time: 603.8907384872437 and batch: 1050, loss is 3.7199605560302733 and perplexity is 41.262766509198485
At time: 605.0569257736206 and batch: 1100, loss is 3.7262359619140626 and perplexity is 41.52252129785263
At time: 606.2213277816772 and batch: 1150, loss is 3.695801601409912 and perplexity is 40.27784642935109
At time: 607.3886306285858 and batch: 1200, loss is 3.7545568704605103 and perplexity is 42.715287210514276
At time: 608.5545945167542 and batch: 1250, loss is 3.734826474189758 and perplexity is 41.88075754014048
At time: 609.7189962863922 and batch: 1300, loss is 3.7434221267700196 and perplexity is 42.242301609297606
At time: 610.8835175037384 and batch: 1350, loss is 3.6124305391311644 and perplexity is 37.05600953008681
At time: 612.048038482666 and batch: 1400, loss is 3.6573140239715576 and perplexity is 38.757102292465014
At time: 613.2126405239105 and batch: 1450, loss is 3.57197793006897 and perplexity is 35.586912009136626
At time: 614.3774461746216 and batch: 1500, loss is 3.562409462928772 and perplexity is 35.2480237172869
At time: 615.5419154167175 and batch: 1550, loss is 3.5773239803314207 and perplexity is 35.77767087834644
At time: 616.7066407203674 and batch: 1600, loss is 3.6597338628768923 and perplexity is 38.85100180147292
At time: 617.8704755306244 and batch: 1650, loss is 3.5931351709365846 and perplexity is 36.34785421222581
At time: 619.0363936424255 and batch: 1700, loss is 3.6078806591033934 and perplexity is 36.88779210715813
At time: 620.2017087936401 and batch: 1750, loss is 3.6039571237564085 and perplexity is 36.743345107710454
At time: 621.37206864357 and batch: 1800, loss is 3.5455386018753052 and perplexity is 34.65834736699579
At time: 622.5483272075653 and batch: 1850, loss is 3.5831341886520387 and perplexity is 35.98615167129515
At time: 623.7169167995453 and batch: 1900, loss is 3.669583492279053 and perplexity is 39.23556054266359
At time: 624.8804087638855 and batch: 1950, loss is 3.606158871650696 and perplexity is 36.824333816072105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368571436682413 and perplexity of 78.93079348428714
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 628.5107152462006 and batch: 50, loss is 3.8514115953445436 and perplexity is 47.059445262122715
At time: 629.7014286518097 and batch: 100, loss is 3.8352694606781004 and perplexity is 46.30590360717346
At time: 630.8737132549286 and batch: 150, loss is 3.798062038421631 and perplexity is 44.61463920305534
At time: 632.0361154079437 and batch: 200, loss is 3.7999331045150755 and perplexity is 44.69819428590424
At time: 633.199346780777 and batch: 250, loss is 3.797841634750366 and perplexity is 44.60480705634324
At time: 634.3626081943512 and batch: 300, loss is 3.8014176750183104 and perplexity is 44.764601187356064
At time: 635.5251142978668 and batch: 350, loss is 3.8253943586349486 and perplexity is 45.850878491319854
At time: 636.687212228775 and batch: 400, loss is 3.810817756652832 and perplexity is 45.18737603883081
At time: 637.8496968746185 and batch: 450, loss is 3.8339531135559084 and perplexity is 46.24498906535648
At time: 639.0208265781403 and batch: 500, loss is 3.8636330699920656 and perplexity is 47.63810994455034
At time: 640.1843943595886 and batch: 550, loss is 3.8223766803741457 and perplexity is 45.712723850027444
At time: 641.3479025363922 and batch: 600, loss is 3.792028465270996 and perplexity is 44.3462639588291
At time: 642.5103363990784 and batch: 650, loss is 3.7999626207351684 and perplexity is 44.69951362711543
At time: 643.6731042861938 and batch: 700, loss is 3.8280375099182127 and perplexity is 45.97222960366806
At time: 644.8352506160736 and batch: 750, loss is 3.792093596458435 and perplexity is 44.349152377721275
At time: 645.9972739219666 and batch: 800, loss is 3.75888560295105 and perplexity is 42.90059103810403
At time: 647.1612408161163 and batch: 850, loss is 3.751435704231262 and perplexity is 42.58217354160673
At time: 648.3249685764313 and batch: 900, loss is 3.718524446487427 and perplexity is 41.2035511864726
At time: 649.4873697757721 and batch: 950, loss is 3.8372107982635497 and perplexity is 46.39588631341859
At time: 650.6499624252319 and batch: 1000, loss is 3.7904926490783692 and perplexity is 44.278208522256406
At time: 651.8597021102905 and batch: 1050, loss is 3.746001334190369 and perplexity is 42.35139389239767
At time: 653.023425579071 and batch: 1100, loss is 3.753542909622192 and perplexity is 42.67199753281315
At time: 654.1865477561951 and batch: 1150, loss is 3.7206936740875243 and perplexity is 41.293028079715036
At time: 655.3489074707031 and batch: 1200, loss is 3.776694645881653 and perplexity is 43.67145329121875
At time: 656.5124046802521 and batch: 1250, loss is 3.7466006088256836 and perplexity is 42.376781614876876
At time: 657.6757073402405 and batch: 1300, loss is 3.7459653568267823 and perplexity is 42.349870228310074
At time: 658.8387372493744 and batch: 1350, loss is 3.6047994756698607 and perplexity is 36.77430897417376
At time: 660.0022678375244 and batch: 1400, loss is 3.6496023607254027 and perplexity is 38.459370052080125
At time: 661.1648917198181 and batch: 1450, loss is 3.5619111919403075 and perplexity is 35.23046502452475
At time: 662.3291964530945 and batch: 1500, loss is 3.552586598396301 and perplexity is 34.90348211835957
At time: 663.4921441078186 and batch: 1550, loss is 3.572127094268799 and perplexity is 35.59222069831421
At time: 664.6559777259827 and batch: 1600, loss is 3.6559002780914307 and perplexity is 38.70234831200016
At time: 665.818888425827 and batch: 1650, loss is 3.5899948501586914 and perplexity is 36.23388932721596
At time: 666.9819822311401 and batch: 1700, loss is 3.6038036346435547 and perplexity is 36.73770583706098
At time: 668.1454427242279 and batch: 1750, loss is 3.5997385597229004 and perplexity is 36.58866744177798
At time: 669.309103012085 and batch: 1800, loss is 3.539366579055786 and perplexity is 34.445094035344404
At time: 670.4716567993164 and batch: 1850, loss is 3.573020420074463 and perplexity is 35.624030353622445
At time: 671.6346983909607 and batch: 1900, loss is 3.656924319267273 and perplexity is 38.742001410010786
At time: 672.7974872589111 and batch: 1950, loss is 3.5999004459381103 and perplexity is 36.594591122137864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364023607830669 and perplexity of 78.57264476122762
finished 14 epochs...
Completing Train Step...
At time: 676.4570360183716 and batch: 50, loss is 3.853824090957642 and perplexity is 47.173113023730394
At time: 677.6230866909027 and batch: 100, loss is 3.8318910455703734 and perplexity is 46.149727006090224
At time: 678.7889482975006 and batch: 150, loss is 3.7920130252838136 and perplexity is 44.34557925836788
At time: 679.9545323848724 and batch: 200, loss is 3.7916640138626097 and perplexity is 44.33010484525734
At time: 681.1225411891937 and batch: 250, loss is 3.788826251029968 and perplexity is 44.20448484554389
At time: 682.3142590522766 and batch: 300, loss is 3.7931109142303465 and perplexity is 44.394292515643514
At time: 683.4851422309875 and batch: 350, loss is 3.8161056566238405 and perplexity is 45.4269552404462
At time: 684.6526942253113 and batch: 400, loss is 3.800133981704712 and perplexity is 44.707174035437454
At time: 685.8196382522583 and batch: 450, loss is 3.8229119777679443 and perplexity is 45.73720030247394
At time: 686.986789226532 and batch: 500, loss is 3.852196373939514 and perplexity is 47.096391002672625
At time: 688.1508898735046 and batch: 550, loss is 3.811156964302063 and perplexity is 45.2027065423969
At time: 689.3174395561218 and batch: 600, loss is 3.780073838233948 and perplexity is 43.81927715416163
At time: 690.4842417240143 and batch: 650, loss is 3.7879194021224976 and perplexity is 44.16441622759356
At time: 691.6509039402008 and batch: 700, loss is 3.818608603477478 and perplexity is 45.54079890802696
At time: 692.8168032169342 and batch: 750, loss is 3.7831393575668333 and perplexity is 43.953812099812566
At time: 693.9845566749573 and batch: 800, loss is 3.750056629180908 and perplexity is 42.523490002288725
At time: 695.1511967182159 and batch: 850, loss is 3.743009910583496 and perplexity is 42.22489223727723
At time: 696.3178186416626 and batch: 900, loss is 3.711426224708557 and perplexity is 40.9121148057678
At time: 697.4847085475922 and batch: 950, loss is 3.8296813917160035 and perplexity is 46.04786466563553
At time: 698.6527283191681 and batch: 1000, loss is 3.782789602279663 and perplexity is 43.93844170973366
At time: 699.8188104629517 and batch: 1050, loss is 3.738327202796936 and perplexity is 42.027627632325874
At time: 700.9849557876587 and batch: 1100, loss is 3.7459959745407105 and perplexity is 42.35116690437215
At time: 702.151269197464 and batch: 1150, loss is 3.7139448738098144 and perplexity is 41.0152879408752
At time: 703.319051027298 and batch: 1200, loss is 3.7694398021697997 and perplexity is 43.355770223186624
At time: 704.4853584766388 and batch: 1250, loss is 3.7407799768447876 and perplexity is 42.130838431315944
At time: 705.651921749115 and batch: 1300, loss is 3.7407561254501345 and perplexity is 42.12983356404524
At time: 706.8174951076508 and batch: 1350, loss is 3.6015069246292115 and perplexity is 36.65342679946263
At time: 707.9842064380646 and batch: 1400, loss is 3.6474548816680907 and perplexity is 38.37686797778024
At time: 709.1496231555939 and batch: 1450, loss is 3.5612879371643067 and perplexity is 35.20851431009184
At time: 710.3141977787018 and batch: 1500, loss is 3.553580780029297 and perplexity is 34.93819977417755
At time: 711.4785482883453 and batch: 1550, loss is 3.574052863121033 and perplexity is 35.66082912910301
At time: 712.6444683074951 and batch: 1600, loss is 3.6585899639129638 and perplexity is 38.806585589437326
At time: 713.8111088275909 and batch: 1650, loss is 3.5932551288604735 and perplexity is 36.352214686886434
At time: 714.977781534195 and batch: 1700, loss is 3.6080838871002197 and perplexity is 36.895289501069776
At time: 716.1444048881531 and batch: 1750, loss is 3.604902639389038 and perplexity is 36.778102944354394
At time: 717.3099157810211 and batch: 1800, loss is 3.544815263748169 and perplexity is 34.63328672767235
At time: 718.4757089614868 and batch: 1850, loss is 3.5790188932418823 and perplexity is 35.83836233346063
At time: 719.6406071186066 and batch: 1900, loss is 3.662425274848938 and perplexity is 38.95570669164062
At time: 720.8065214157104 and batch: 1950, loss is 3.6046698570251463 and perplexity is 36.76954264699333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362913619640262 and perplexity of 78.48547843919724
finished 15 epochs...
Completing Train Step...
At time: 724.461186170578 and batch: 50, loss is 3.853445544242859 and perplexity is 47.155259176240044
At time: 725.6515007019043 and batch: 100, loss is 3.829339232444763 and perplexity is 46.03211165699202
At time: 726.8156967163086 and batch: 150, loss is 3.788345928192139 and perplexity is 44.18325752033074
At time: 727.9813356399536 and batch: 200, loss is 3.78741662979126 and perplexity is 44.142217162094646
At time: 729.1463584899902 and batch: 250, loss is 3.7840494537353515 and perplexity is 43.99383250424242
At time: 730.3102061748505 and batch: 300, loss is 3.78856080532074 and perplexity is 44.192752511930685
At time: 731.4725911617279 and batch: 350, loss is 3.8113476133346555 and perplexity is 45.21132521621458
At time: 732.6363158226013 and batch: 400, loss is 3.794694905281067 and perplexity is 44.464668400362555
At time: 733.800568819046 and batch: 450, loss is 3.8173339891433717 and perplexity is 45.48278893098005
At time: 734.9648892879486 and batch: 500, loss is 3.8462733697891234 and perplexity is 46.81826337195605
At time: 736.1293244361877 and batch: 550, loss is 3.8052049112319946 and perplexity is 44.934456744600645
At time: 737.2930791378021 and batch: 600, loss is 3.7742149877548217 and perplexity is 43.56329716767832
At time: 738.4579873085022 and batch: 650, loss is 3.7823467826843262 and perplexity is 43.91898921404702
At time: 739.6244721412659 and batch: 700, loss is 3.8138859415054323 and perplexity is 45.326232170732375
At time: 740.8163900375366 and batch: 750, loss is 3.7786132764816283 and perplexity is 43.7553231097207
At time: 741.988222360611 and batch: 800, loss is 3.7456402349472047 and perplexity is 42.336103596939374
At time: 743.1542778015137 and batch: 850, loss is 3.7386774444580078 and perplexity is 42.04235003648787
At time: 744.3201313018799 and batch: 900, loss is 3.7076214504241944 and perplexity is 40.75674919640017
At time: 745.484662771225 and batch: 950, loss is 3.825843820571899 and perplexity is 45.87149134797768
At time: 746.650253534317 and batch: 1000, loss is 3.7790030002593995 and perplexity is 43.77237892285271
At time: 747.8156299591064 and batch: 1050, loss is 3.7346480226516725 and perplexity is 41.87328452134693
At time: 748.9803950786591 and batch: 1100, loss is 3.7426140308380127 and perplexity is 42.20817956600757
At time: 750.1461143493652 and batch: 1150, loss is 3.7110195541381836 and perplexity is 40.89548043528827
At time: 751.3114063739777 and batch: 1200, loss is 3.766365761756897 and perplexity is 43.22269747368466
At time: 752.4771485328674 and batch: 1250, loss is 3.738287034034729 and perplexity is 42.025939468451334
At time: 753.6409039497375 and batch: 1300, loss is 3.738734316825867 and perplexity is 42.04474115247837
At time: 754.8057942390442 and batch: 1350, loss is 3.600235061645508 and perplexity is 36.60683829606724
At time: 755.9712204933167 and batch: 1400, loss is 3.646569261550903 and perplexity is 38.34289569695257
At time: 757.1366128921509 and batch: 1450, loss is 3.5609866189956665 and perplexity is 35.19790694321582
At time: 758.30144739151 and batch: 1500, loss is 3.553906579017639 and perplexity is 34.94958445877713
At time: 759.4665365219116 and batch: 1550, loss is 3.574792814254761 and perplexity is 35.6872261651007
At time: 760.6314084529877 and batch: 1600, loss is 3.659747076034546 and perplexity is 38.85151514927619
At time: 761.796026468277 and batch: 1650, loss is 3.594631481170654 and perplexity is 36.402282589183585
At time: 762.9616694450378 and batch: 1700, loss is 3.609913220405579 and perplexity is 36.96284505493795
At time: 764.1267795562744 and batch: 1750, loss is 3.607115421295166 and perplexity is 36.85957497176209
At time: 765.2931549549103 and batch: 1800, loss is 3.547098784446716 and perplexity is 34.71246292060627
At time: 766.4577829837799 and batch: 1850, loss is 3.5815033960342406 and perplexity is 35.927513547112255
At time: 767.6247355937958 and batch: 1900, loss is 3.664674119949341 and perplexity is 39.04341062108073
At time: 768.788754940033 and batch: 1950, loss is 3.606384735107422 and perplexity is 36.83265202675398
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362401492096657 and perplexity of 78.4452941545333
finished 16 epochs...
Completing Train Step...
At time: 772.4657294750214 and batch: 50, loss is 3.8520460891723634 and perplexity is 47.08931366433854
At time: 773.6327035427094 and batch: 100, loss is 3.8268907356262205 and perplexity is 45.91954004990017
At time: 774.797464132309 and batch: 150, loss is 3.7854604530334472 and perplexity is 44.055951585710446
At time: 775.9634416103363 and batch: 200, loss is 3.7842623519897463 and perplexity is 44.00319971148236
At time: 777.1366231441498 and batch: 250, loss is 3.780621485710144 and perplexity is 43.84328124299326
At time: 778.3104221820831 and batch: 300, loss is 3.785090298652649 and perplexity is 44.03964710000533
At time: 779.4752810001373 and batch: 350, loss is 3.8077835130691526 and perplexity is 45.05047433461413
At time: 780.6415467262268 and batch: 400, loss is 3.7907875776290894 and perplexity is 44.291269356036075
At time: 781.8150775432587 and batch: 450, loss is 3.813475422859192 and perplexity is 45.307628726054205
At time: 782.9873046875 and batch: 500, loss is 3.8422517871856687 and perplexity is 46.63035795029431
At time: 784.1545624732971 and batch: 550, loss is 3.8011573791503905 and perplexity is 44.75295066299537
At time: 785.3227725028992 and batch: 600, loss is 3.7703668117523192 and perplexity is 43.395980072219196
At time: 786.4898905754089 and batch: 650, loss is 3.778770098686218 and perplexity is 43.76218545402322
At time: 787.6565301418304 and batch: 700, loss is 3.8107139968872072 and perplexity is 45.18268765052107
At time: 788.8310196399689 and batch: 750, loss is 3.7755473375320436 and perplexity is 43.621377399955215
At time: 790.0063133239746 and batch: 800, loss is 3.74267107963562 and perplexity is 42.21058756058695
At time: 791.1725425720215 and batch: 850, loss is 3.7357051229476927 and perplexity is 41.91757218693784
At time: 792.3385119438171 and batch: 900, loss is 3.7049053382873534 and perplexity is 40.64619949590412
At time: 793.5041253566742 and batch: 950, loss is 3.8231472778320312 and perplexity is 45.747963534881244
At time: 794.6714012622833 and batch: 1000, loss is 3.776428256034851 and perplexity is 43.65982120886999
At time: 795.8363208770752 and batch: 1050, loss is 3.7322054719924926 and perplexity is 41.7711317101329
At time: 797.0002844333649 and batch: 1100, loss is 3.740410256385803 and perplexity is 42.11526467753882
At time: 798.167078256607 and batch: 1150, loss is 3.709105486869812 and perplexity is 40.817278600424345
At time: 799.360550403595 and batch: 1200, loss is 3.764412660598755 and perplexity is 43.1383615582868
At time: 800.5278618335724 and batch: 1250, loss is 3.7366617155075073 and perplexity is 41.95768940947649
At time: 801.6961817741394 and batch: 1300, loss is 3.737402901649475 and perplexity is 41.988799395136695
At time: 802.8638463020325 and batch: 1350, loss is 3.599264883995056 and perplexity is 36.57134038212441
At time: 804.0300705432892 and batch: 1400, loss is 3.6457449531555177 and perplexity is 38.31130234924599
At time: 805.1967115402222 and batch: 1450, loss is 3.5604153776168825 and perplexity is 35.17780618406256
At time: 806.3637194633484 and batch: 1500, loss is 3.553695125579834 and perplexity is 34.94219503028102
At time: 807.5296542644501 and batch: 1550, loss is 3.5747884368896483 and perplexity is 35.68706994942382
At time: 808.6962833404541 and batch: 1600, loss is 3.6600250720977785 and perplexity is 38.86231721893516
At time: 809.8627688884735 and batch: 1650, loss is 3.595021653175354 and perplexity is 36.41648851195352
At time: 811.0294671058655 and batch: 1700, loss is 3.610574026107788 and perplexity is 36.98727838567317
At time: 812.196656703949 and batch: 1750, loss is 3.6080125999450683 and perplexity is 36.89265943458885
At time: 813.3629324436188 and batch: 1800, loss is 3.5480482292175295 and perplexity is 34.74543613765559
At time: 814.53062748909 and batch: 1850, loss is 3.5825871801376343 and perplexity is 35.96647232280659
At time: 815.6990661621094 and batch: 1900, loss is 3.665625743865967 and perplexity is 39.08058294864715
At time: 816.8660144805908 and batch: 1950, loss is 3.606996970176697 and perplexity is 36.8552091724524
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3621388989825585 and perplexity of 78.42469766482144
finished 17 epochs...
Completing Train Step...
At time: 820.5127918720245 and batch: 50, loss is 3.8503616428375245 and perplexity is 47.01006100968741
At time: 821.7024066448212 and batch: 100, loss is 3.8245970010757446 and perplexity is 45.814333518400076
At time: 822.8646941184998 and batch: 150, loss is 3.7829767799377443 and perplexity is 43.94666677410275
At time: 824.0304114818573 and batch: 200, loss is 3.7816174697875975 and perplexity is 43.88697020615886
At time: 825.1933591365814 and batch: 250, loss is 3.7778204393386843 and perplexity is 43.720646012819486
At time: 826.354727268219 and batch: 300, loss is 3.7821904182434083 and perplexity is 43.912122382731
At time: 827.5167527198792 and batch: 350, loss is 3.8048133850097656 and perplexity is 44.916867170118046
At time: 828.6809778213501 and batch: 400, loss is 3.787638382911682 and perplexity is 44.15200692190747
At time: 829.8703153133392 and batch: 450, loss is 3.8104409551620484 and perplexity is 45.17035257560936
At time: 831.0335030555725 and batch: 500, loss is 3.8391462898254396 and perplexity is 46.485772118432884
At time: 832.1966996192932 and batch: 550, loss is 3.7980361127853395 and perplexity is 44.61348255513956
At time: 833.3608422279358 and batch: 600, loss is 3.767424864768982 and perplexity is 43.26849901276217
At time: 834.5242795944214 and batch: 650, loss is 3.7760282135009766 and perplexity is 43.642358916427824
At time: 835.6882126331329 and batch: 700, loss is 3.808223400115967 and perplexity is 45.070295814013164
At time: 836.8507444858551 and batch: 750, loss is 3.7731248426437376 and perplexity is 43.51583272851206
At time: 838.0137519836426 and batch: 800, loss is 3.740320224761963 and perplexity is 42.111473142553024
At time: 839.1765789985657 and batch: 850, loss is 3.7333171796798705 and perplexity is 41.8175948202786
At time: 840.3458759784698 and batch: 900, loss is 3.7026583623886107 and perplexity is 40.55497099776327
At time: 841.5079307556152 and batch: 950, loss is 3.8209165287017823 and perplexity is 45.64602504688441
At time: 842.6735453605652 and batch: 1000, loss is 3.774318051338196 and perplexity is 43.567787188562875
At time: 843.8374149799347 and batch: 1050, loss is 3.7302273082733155 and perplexity is 41.68858324698096
At time: 845.0000674724579 and batch: 1100, loss is 3.7386111402511597 and perplexity is 42.039562544226925
At time: 846.162529706955 and batch: 1150, loss is 3.707513003349304 and perplexity is 40.752329485824454
At time: 847.3267011642456 and batch: 1200, loss is 3.762826085090637 and perplexity is 43.069973556088414
At time: 848.4898626804352 and batch: 1250, loss is 3.7353213262557983 and perplexity is 41.90148744823244
At time: 849.6528186798096 and batch: 1300, loss is 3.736257314682007 and perplexity is 41.94072511566161
At time: 850.8155248165131 and batch: 1350, loss is 3.5983346843719484 and perplexity is 36.537337552245994
At time: 851.9786794185638 and batch: 1400, loss is 3.6448735427856445 and perplexity is 38.27793202483055
At time: 853.1425185203552 and batch: 1450, loss is 3.559683437347412 and perplexity is 35.15206755184462
At time: 854.3171982765198 and batch: 1500, loss is 3.553218207359314 and perplexity is 34.92553443399287
At time: 855.483868598938 and batch: 1550, loss is 3.574423050880432 and perplexity is 35.67403277529995
At time: 856.6480054855347 and batch: 1600, loss is 3.6598820638656617 and perplexity is 38.85675998502828
At time: 857.8114030361176 and batch: 1650, loss is 3.594951281547546 and perplexity is 36.41392591454603
At time: 858.9759962558746 and batch: 1700, loss is 3.6107012271881103 and perplexity is 36.991983506683894
At time: 860.1386954784393 and batch: 1750, loss is 3.6083143949508667 and perplexity is 36.90379513522173
At time: 861.3012039661407 and batch: 1800, loss is 3.5484013032913206 and perplexity is 34.75770601629891
At time: 862.467193365097 and batch: 1850, loss is 3.5830518198013306 and perplexity is 35.98318765541354
At time: 863.6297543048859 and batch: 1900, loss is 3.6660101985931397 and perplexity is 39.095610552033904
At time: 864.7914443016052 and batch: 1950, loss is 3.6071639823913575 and perplexity is 36.861364956589334
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362016260901163 and perplexity of 78.41508040009927
finished 18 epochs...
Completing Train Step...
At time: 868.4500935077667 and batch: 50, loss is 3.8486228084564207 and perplexity is 46.92838932668933
At time: 869.6157047748566 and batch: 100, loss is 3.8224504137039186 and perplexity is 45.716094525633935
At time: 870.7809011936188 and batch: 150, loss is 3.7807319355010987 and perplexity is 43.84812399167667
At time: 871.946994304657 and batch: 200, loss is 3.7792618703842162 and perplexity is 43.78371175085
At time: 873.1117534637451 and batch: 250, loss is 3.775361223220825 and perplexity is 43.6132595927895
At time: 874.2762334346771 and batch: 300, loss is 3.779634704589844 and perplexity is 43.800038859703264
At time: 875.4414260387421 and batch: 350, loss is 3.8022006702423097 and perplexity is 44.799665382047046
At time: 876.6063075065613 and batch: 400, loss is 3.784925322532654 and perplexity is 44.032382209184036
At time: 877.7837665081024 and batch: 450, loss is 3.8078601360321045 and perplexity is 45.05392636769085
At time: 878.9505262374878 and batch: 500, loss is 3.8365338134765623 and perplexity is 46.364487633619085
At time: 880.1162977218628 and batch: 550, loss is 3.7954164505004884 and perplexity is 44.49676324682907
At time: 881.2802932262421 and batch: 600, loss is 3.7649526309967043 and perplexity is 43.16166128655997
At time: 882.4431803226471 and batch: 650, loss is 3.773707585334778 and perplexity is 43.5411986521646
At time: 883.6092617511749 and batch: 700, loss is 3.806084394454956 and perplexity is 44.97399322872923
At time: 884.7747008800507 and batch: 750, loss is 3.771035828590393 and perplexity is 43.42502242742131
At time: 885.9407026767731 and batch: 800, loss is 3.7382811594009397 and perplexity is 42.025692582172496
At time: 887.1074392795563 and batch: 850, loss is 3.731231789588928 and perplexity is 41.73047968850054
At time: 888.3176264762878 and batch: 900, loss is 3.7006574773788454 and perplexity is 40.47390629184532
At time: 889.483434677124 and batch: 950, loss is 3.818929224014282 and perplexity is 45.55540256441031
At time: 890.6507797241211 and batch: 1000, loss is 3.77243577003479 and perplexity is 43.48585748886766
At time: 891.8172042369843 and batch: 1050, loss is 3.728470177650452 and perplexity is 41.61539527997362
At time: 892.984281539917 and batch: 1100, loss is 3.7369894933700563 and perplexity is 41.97144446540688
At time: 894.1508107185364 and batch: 1150, loss is 3.706055507659912 and perplexity is 40.69297640520271
At time: 895.3163628578186 and batch: 1200, loss is 3.76139479637146 and perplexity is 43.00837208406465
At time: 896.4814274311066 and batch: 1250, loss is 3.734102873802185 and perplexity is 41.85046356943886
At time: 897.647058725357 and batch: 1300, loss is 3.7351764011383057 and perplexity is 41.89541531025418
At time: 898.8128440380096 and batch: 1350, loss is 3.5974040031433105 and perplexity is 36.50334875686197
At time: 899.9777407646179 and batch: 1400, loss is 3.643970136642456 and perplexity is 38.24336712131468
At time: 901.1432070732117 and batch: 1450, loss is 3.5588779258728027 and perplexity is 35.1237635592012
At time: 902.3101541996002 and batch: 1500, loss is 3.552614049911499 and perplexity is 34.90444028498091
At time: 903.4763312339783 and batch: 1550, loss is 3.573882875442505 and perplexity is 35.65476774274006
At time: 904.641339302063 and batch: 1600, loss is 3.6595337104797365 and perplexity is 38.84322645848317
At time: 905.8084559440613 and batch: 1650, loss is 3.5946575021743774 and perplexity is 36.40322982543834
At time: 906.9752309322357 and batch: 1700, loss is 3.610563635826111 and perplexity is 36.986894079428794
At time: 908.1418659687042 and batch: 1750, loss is 3.6083182382583616 and perplexity is 36.90393696812672
At time: 909.3089368343353 and batch: 1800, loss is 3.548455228805542 and perplexity is 34.75958039400694
At time: 910.4755847454071 and batch: 1850, loss is 3.583203148841858 and perplexity is 35.988633368713444
At time: 911.6431696414948 and batch: 1900, loss is 3.6661151599884034 and perplexity is 39.099714297229774
At time: 912.808696269989 and batch: 1950, loss is 3.6071234512329102 and perplexity is 36.859870953042744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361971974927326 and perplexity of 78.41160778879484
finished 19 epochs...
Completing Train Step...
At time: 916.4405145645142 and batch: 50, loss is 3.8468993043899538 and perplexity is 46.847577716425505
At time: 917.6314060688019 and batch: 100, loss is 3.8204246234893797 and perplexity is 45.623577050834164
At time: 918.7964053153992 and batch: 150, loss is 3.7786453199386596 and perplexity is 43.75672520400051
At time: 919.9607801437378 and batch: 200, loss is 3.7770922136306764 and perplexity is 43.68881910441521
At time: 921.1244881153107 and batch: 250, loss is 3.7731133556365966 and perplexity is 43.51533286470173
At time: 922.2949078083038 and batch: 300, loss is 3.7773035049438475 and perplexity is 43.6980511476656
At time: 923.4604058265686 and batch: 350, loss is 3.7998233699798583 and perplexity is 44.6932896194398
At time: 924.623699426651 and batch: 400, loss is 3.782485914230347 and perplexity is 43.92510015601858
At time: 925.7880909442902 and batch: 450, loss is 3.80555344581604 and perplexity is 44.95012068634557
At time: 926.9531228542328 and batch: 500, loss is 3.8342134094238283 and perplexity is 46.25702801169821
At time: 928.1180398464203 and batch: 550, loss is 3.7930956172943113 and perplexity is 44.3936134241846
At time: 929.2832872867584 and batch: 600, loss is 3.76275408744812 and perplexity is 43.06687273115648
At time: 930.4474980831146 and batch: 650, loss is 3.7716314458847044 and perplexity is 43.450894826044106
At time: 931.6131031513214 and batch: 700, loss is 3.80415358543396 and perplexity is 44.88724081501572
At time: 932.7779049873352 and batch: 750, loss is 3.769145050048828 and perplexity is 43.34299290112088
At time: 933.9429633617401 and batch: 800, loss is 3.736425728797913 and perplexity is 41.9477891206248
At time: 935.1070601940155 and batch: 850, loss is 3.729330792427063 and perplexity is 41.651225519891554
At time: 936.2713539600372 and batch: 900, loss is 3.6988096046447754 and perplexity is 40.39918472320421
At time: 937.4350600242615 and batch: 950, loss is 3.8170957660675047 and perplexity is 45.47195517157888
At time: 938.5997025966644 and batch: 1000, loss is 3.770692911148071 and perplexity is 43.410133782731606
At time: 939.7648639678955 and batch: 1050, loss is 3.7268450593948366 and perplexity is 41.54782026495694
At time: 940.9297077655792 and batch: 1100, loss is 3.735469088554382 and perplexity is 41.9076793657866
At time: 942.1017837524414 and batch: 1150, loss is 3.7046753787994384 and perplexity is 40.63685359131326
At time: 943.2656943798065 and batch: 1200, loss is 3.760049195289612 and perplexity is 42.95053889098967
At time: 944.4376113414764 and batch: 1250, loss is 3.7329511213302613 and perplexity is 41.80228994194422
At time: 945.6046781539917 and batch: 1300, loss is 3.7341265630722047 and perplexity is 41.85145498811376
At time: 946.7682356834412 and batch: 1350, loss is 3.596470527648926 and perplexity is 36.46928967446704
At time: 947.9309296607971 and batch: 1400, loss is 3.6430527114868165 and perplexity is 38.20829778348732
At time: 949.0962197780609 and batch: 1450, loss is 3.5580409479141237 and perplexity is 35.09437804250664
At time: 950.2610125541687 and batch: 1500, loss is 3.551946406364441 and perplexity is 34.881144338220565
At time: 951.4250621795654 and batch: 1550, loss is 3.573253755569458 and perplexity is 35.6323436742374
At time: 952.5880601406097 and batch: 1600, loss is 3.659077911376953 and perplexity is 38.825525784996174
At time: 953.7538070678711 and batch: 1650, loss is 3.594245796203613 and perplexity is 36.38824548314736
At time: 954.9179878234863 and batch: 1700, loss is 3.6102794790267945 and perplexity is 36.97638549510408
At time: 956.0823049545288 and batch: 1750, loss is 3.6081548357009887 and perplexity is 36.897907263097025
At time: 957.2476246356964 and batch: 1800, loss is 3.548340244293213 and perplexity is 34.75558381038357
At time: 958.4121663570404 and batch: 1850, loss is 3.5831748723983763 and perplexity is 35.987615752543356
At time: 959.5773522853851 and batch: 1900, loss is 3.6660649490356447 and perplexity is 39.097751112609416
At time: 960.7416398525238 and batch: 1950, loss is 3.606970343589783 and perplexity is 36.854227857086734
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361991562954215 and perplexity of 78.41314373251964
Annealing...
Finished Training.
Improved accuracyfrom -10000000 to -78.41160778879484
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f1288f88b38>
ELAPSED
994.0603904724121


RESULTS SO FAR:
[{'best_accuracy': -78.41160778879484, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.10008266219030648, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.21726970941698143, 'batch_size': 32}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.688995361328125 and batch: 50, loss is 7.454767017364502 and perplexity is 1728.081335418999
At time: 2.905242919921875 and batch: 100, loss is 6.486519298553467 and perplexity is 656.2352244663481
At time: 4.1243510246276855 and batch: 150, loss is 6.141525545120239 and perplexity is 464.76204578766306
At time: 5.3453874588012695 and batch: 200, loss is 5.985348930358887 and perplexity is 397.56121822870716
At time: 6.5652546882629395 and batch: 250, loss is 5.885038194656372 and perplexity is 359.61650316306196
At time: 7.785137176513672 and batch: 300, loss is 5.80733847618103 and perplexity is 332.7323710079138
At time: 9.005846500396729 and batch: 350, loss is 5.738272314071655 and perplexity is 310.52745335636155
At time: 10.225783824920654 and batch: 400, loss is 5.671025238037109 and perplexity is 290.3320413101135
At time: 11.474454879760742 and batch: 450, loss is 5.591620960235596 and perplexity is 268.1699604362727
At time: 12.703719854354858 and batch: 500, loss is 5.550910549163818 and perplexity is 257.4718900173816
At time: 13.924158096313477 and batch: 550, loss is 5.491627836227417 and perplexity is 242.65188306258966
At time: 15.143953084945679 and batch: 600, loss is 5.509555997848511 and perplexity is 247.0414157932861
At time: 16.364046812057495 and batch: 650, loss is 5.575938529968262 and perplexity is 263.9972086957502
At time: 17.600849151611328 and batch: 700, loss is 5.504513311386108 and perplexity is 245.7987990866096
At time: 18.83639359474182 and batch: 750, loss is 5.435571575164795 and perplexity is 229.42394383520195
At time: 20.068811655044556 and batch: 800, loss is 5.429351444244385 and perplexity is 228.00132588996246
At time: 21.3021240234375 and batch: 850, loss is 5.429208354949951 and perplexity is 227.96870367511144
At time: 22.533203840255737 and batch: 900, loss is 5.431751260757446 and perplexity is 228.54914430576065
At time: 23.764966249465942 and batch: 950, loss is 5.470389461517334 and perplexity is 237.55269237949753
At time: 24.9976544380188 and batch: 1000, loss is 5.4257047080993654 and perplexity is 227.17137943136782
At time: 26.22998881340027 and batch: 1050, loss is 5.325609893798828 and perplexity is 205.53367596074548
At time: 27.462059497833252 and batch: 1100, loss is 5.407339792251587 and perplexity is 223.0374717844288
At time: 28.69374680519104 and batch: 1150, loss is 5.3108517456054685 and perplexity is 202.5226527263548
At time: 29.926364183425903 and batch: 1200, loss is 5.38330415725708 and perplexity is 217.7405371225755
At time: 31.160146713256836 and batch: 1250, loss is 5.326444540023804 and perplexity is 205.70529547831978
At time: 32.39323019981384 and batch: 1300, loss is 5.344966096878052 and perplexity is 209.55078005278767
At time: 33.62678909301758 and batch: 1350, loss is 5.284416933059692 and perplexity is 197.2391462886985
At time: 34.860013246536255 and batch: 1400, loss is 5.302172794342041 and perplexity is 200.77257390326847
At time: 36.09325861930847 and batch: 1450, loss is 5.248608894348145 and perplexity is 190.30135494958526
At time: 37.325693130493164 and batch: 1500, loss is 5.2216786289215085 and perplexity is 185.2448806398068
At time: 38.558531284332275 and batch: 1550, loss is 5.209097862243652 and perplexity is 182.92895661424032
At time: 39.79204058647156 and batch: 1600, loss is 5.253441610336304 and perplexity is 191.22325319215176
At time: 41.024590253829956 and batch: 1650, loss is 5.220710735321045 and perplexity is 185.06567004770025
At time: 42.25655174255371 and batch: 1700, loss is 5.235995950698853 and perplexity is 187.91616841569538
At time: 43.49031209945679 and batch: 1750, loss is 5.248425874710083 and perplexity is 190.26652925147027
At time: 44.72364330291748 and batch: 1800, loss is 5.224184017181397 and perplexity is 185.70957286311503
At time: 45.95635414123535 and batch: 1850, loss is 5.199439859390258 and perplexity is 181.170732363512
At time: 47.19245219230652 and batch: 1900, loss is 5.243888463973999 and perplexity is 189.40516751274365
At time: 48.4277024269104 and batch: 1950, loss is 5.1599914169311525 and perplexity is 174.16296074601277
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.847241778706396 and perplexity of 127.38853904695239
finished 1 epochs...
Completing Train Step...
At time: 52.11868166923523 and batch: 50, loss is 5.057944202423096 and perplexity is 157.26687490637065
At time: 53.30859017372131 and batch: 100, loss is 4.996362829208374 and perplexity is 147.8743355857828
At time: 54.47891306877136 and batch: 150, loss is 4.931050720214844 and perplexity is 138.5249869040453
At time: 55.646711587905884 and batch: 200, loss is 4.907010583877564 and perplexity is 135.2345372308949
At time: 56.81785440444946 and batch: 250, loss is 4.9126443195343015 and perplexity is 135.99856300415374
At time: 57.9892303943634 and batch: 300, loss is 4.929360475540161 and perplexity is 138.29104354907176
At time: 59.15664792060852 and batch: 350, loss is 4.926531658172608 and perplexity is 137.90039623875447
At time: 60.32325887680054 and batch: 400, loss is 4.894258422851562 and perplexity is 133.5209538032574
At time: 61.48921179771423 and batch: 450, loss is 4.864756536483765 and perplexity is 129.63937231191818
At time: 62.65755820274353 and batch: 500, loss is 4.860153665542603 and perplexity is 129.0440302048126
At time: 63.824259519577026 and batch: 550, loss is 4.820338382720947 and perplexity is 124.0070455225241
At time: 64.99093914031982 and batch: 600, loss is 4.798572578430176 and perplexity is 121.33709465963335
At time: 66.15517854690552 and batch: 650, loss is 4.86207498550415 and perplexity is 129.29220340968615
At time: 67.320636510849 and batch: 700, loss is 4.86071662902832 and perplexity is 129.1166977345314
At time: 68.48700547218323 and batch: 750, loss is 4.8153159809112545 and perplexity is 123.38579370669687
At time: 69.65755701065063 and batch: 800, loss is 4.802946453094482 and perplexity is 121.86897023442366
At time: 70.8248963356018 and batch: 850, loss is 4.801688394546509 and perplexity is 121.7157483359559
At time: 71.99141812324524 and batch: 900, loss is 4.799353456497192 and perplexity is 121.43188113909346
At time: 73.15904092788696 and batch: 950, loss is 4.869744415283203 and perplexity is 130.28761311797084
At time: 74.3250777721405 and batch: 1000, loss is 4.831213436126709 and perplexity is 125.36298837719481
At time: 75.49034571647644 and batch: 1050, loss is 4.75228853225708 and perplexity is 115.84910580117281
At time: 76.66358971595764 and batch: 1100, loss is 4.828988656997681 and perplexity is 125.08439343811571
At time: 77.83056735992432 and batch: 1150, loss is 4.739142971038818 and perplexity is 114.33617026904864
At time: 78.9976212978363 and batch: 1200, loss is 4.826392269134521 and perplexity is 124.76004708379894
At time: 80.19979071617126 and batch: 1250, loss is 4.78083251953125 and perplexity is 119.2035480288832
At time: 81.36644124984741 and batch: 1300, loss is 4.8067735576629635 and perplexity is 122.33626915771941
At time: 82.53172421455383 and batch: 1350, loss is 4.700152740478516 and perplexity is 109.96396711843535
At time: 83.69861912727356 and batch: 1400, loss is 4.727784156799316 and perplexity is 113.04479508024009
At time: 84.86334657669067 and batch: 1450, loss is 4.6611661529541015 and perplexity is 105.75934184178062
At time: 86.03017520904541 and batch: 1500, loss is 4.646071662902832 and perplexity is 104.17494641180156
At time: 87.20046877861023 and batch: 1550, loss is 4.642657527923584 and perplexity is 103.81988554105676
At time: 88.36699938774109 and batch: 1600, loss is 4.726586351394653 and perplexity is 112.9094704761746
At time: 89.53188872337341 and batch: 1650, loss is 4.6697776508331295 and perplexity is 106.67402091564149
At time: 90.69756388664246 and batch: 1700, loss is 4.702244539260864 and perplexity is 110.19423035917706
At time: 91.86440134048462 and batch: 1750, loss is 4.7036159896850585 and perplexity is 110.34545996139433
At time: 93.03097558021545 and batch: 1800, loss is 4.659220972061157 and perplexity is 105.55382074343943
At time: 94.19722080230713 and batch: 1850, loss is 4.670010118484497 and perplexity is 106.6988220573656
At time: 95.36515784263611 and batch: 1900, loss is 4.746358337402344 and perplexity is 115.16413105427122
At time: 96.53136777877808 and batch: 1950, loss is 4.671435480117798 and perplexity is 106.85101490379965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.597311046511628 and perplexity of 99.2171662814205
finished 2 epochs...
Completing Train Step...
At time: 100.19416928291321 and batch: 50, loss is 4.6427248668670655 and perplexity is 103.82687689785415
At time: 101.38517355918884 and batch: 100, loss is 4.592948045730591 and perplexity is 98.78522467342398
At time: 102.55115365982056 and batch: 150, loss is 4.5396410179138185 and perplexity is 93.65717283674825
At time: 103.72254395484924 and batch: 200, loss is 4.530064573287964 and perplexity is 92.76455100077992
At time: 104.88812494277954 and batch: 250, loss is 4.528957118988037 and perplexity is 92.6618753646746
At time: 106.05282974243164 and batch: 300, loss is 4.556752290725708 and perplexity is 95.2735560197826
At time: 107.21838593482971 and batch: 350, loss is 4.5654104042053225 and perplexity is 96.10202660018281
At time: 108.40492820739746 and batch: 400, loss is 4.528772897720337 and perplexity is 92.64480664878596
At time: 109.5699245929718 and batch: 450, loss is 4.529064321517945 and perplexity is 92.67180948461154
At time: 110.73457145690918 and batch: 500, loss is 4.537008666992188 and perplexity is 93.41095849496268
At time: 111.89944410324097 and batch: 550, loss is 4.495599422454834 and perplexity is 89.62187425133668
At time: 113.06463527679443 and batch: 600, loss is 4.4720686912536625 and perplexity is 87.53762415207555
At time: 114.23065876960754 and batch: 650, loss is 4.530090627670288 and perplexity is 92.76696795534376
At time: 115.39545845985413 and batch: 700, loss is 4.552772312164307 and perplexity is 94.89512288677241
At time: 116.56080937385559 and batch: 750, loss is 4.511778802871704 and perplexity is 91.08369443239079
At time: 117.7259635925293 and batch: 800, loss is 4.493312606811523 and perplexity is 89.41715970873841
At time: 118.89059209823608 and batch: 850, loss is 4.493287591934204 and perplexity is 89.41492297743399
At time: 120.05535554885864 and batch: 900, loss is 4.481943645477295 and perplexity is 88.40633637077845
At time: 121.221266746521 and batch: 950, loss is 4.55979398727417 and perplexity is 95.56379044504374
At time: 122.38681364059448 and batch: 1000, loss is 4.532996330261231 and perplexity is 93.036913174816
At time: 123.55146932601929 and batch: 1050, loss is 4.46211573600769 and perplexity is 86.6706875438278
At time: 124.71493744850159 and batch: 1100, loss is 4.52454255104065 and perplexity is 92.25371480886491
At time: 125.88035321235657 and batch: 1150, loss is 4.459463243484497 and perplexity is 86.44109881893596
At time: 127.04586696624756 and batch: 1200, loss is 4.547718076705933 and perplexity is 94.41671061441815
At time: 128.2111439704895 and batch: 1250, loss is 4.509499912261963 and perplexity is 90.87636099129374
At time: 129.3766484260559 and batch: 1300, loss is 4.522144222259522 and perplexity is 92.03272517829583
At time: 130.54155564308167 and batch: 1350, loss is 4.402934293746949 and perplexity is 81.69022043203553
At time: 131.70709109306335 and batch: 1400, loss is 4.435219373703003 and perplexity is 84.37063155614744
At time: 132.87106108665466 and batch: 1450, loss is 4.36374041557312 and perplexity is 78.55039674695747
At time: 134.03759908676147 and batch: 1500, loss is 4.362560052871704 and perplexity is 78.45773348734228
At time: 135.20375800132751 and batch: 1550, loss is 4.364223899841309 and perplexity is 78.58838381037845
At time: 136.36991453170776 and batch: 1600, loss is 4.463907051086426 and perplexity is 86.82608119124893
At time: 137.53493809700012 and batch: 1650, loss is 4.400707321166992 and perplexity is 81.50850096831599
At time: 138.70759296417236 and batch: 1700, loss is 4.431346502304077 and perplexity is 84.04450687738695
At time: 139.87354946136475 and batch: 1750, loss is 4.432735395431519 and perplexity is 84.16131681487045
At time: 141.0389232635498 and batch: 1800, loss is 4.384606971740722 and perplexity is 80.20669352014016
At time: 142.2159354686737 and batch: 1850, loss is 4.4166353321075436 and perplexity is 82.81716379402658
At time: 143.3837525844574 and batch: 1900, loss is 4.502654809951782 and perplexity is 90.2564271785217
At time: 144.55013012886047 and batch: 1950, loss is 4.428090438842774 and perplexity is 83.77129766406777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509397710755814 and perplexity of 90.86707376491947
finished 3 epochs...
Completing Train Step...
At time: 148.21143293380737 and batch: 50, loss is 4.402100348472596 and perplexity is 81.62212365718374
At time: 149.37697458267212 and batch: 100, loss is 4.355673065185547 and perplexity is 77.91925242751692
At time: 150.54450798034668 and batch: 150, loss is 4.305257749557495 and perplexity is 74.088309220955
At time: 151.7098207473755 and batch: 200, loss is 4.304218044281006 and perplexity is 74.0113192453092
At time: 152.875070810318 and batch: 250, loss is 4.3027685928344725 and perplexity is 73.90412113956175
At time: 154.04139184951782 and batch: 300, loss is 4.3240446186065675 and perplexity is 75.49335345012254
At time: 155.21107268333435 and batch: 350, loss is 4.340470972061158 and perplexity is 76.74367495496907
At time: 156.37772607803345 and batch: 400, loss is 4.300094966888428 and perplexity is 73.70679307203025
At time: 157.54424738883972 and batch: 450, loss is 4.317904977798462 and perplexity is 75.03127133715998
At time: 158.71145367622375 and batch: 500, loss is 4.32704460144043 and perplexity is 75.72017227071555
At time: 159.879239320755 and batch: 550, loss is 4.291509504318237 and perplexity is 73.07669487158157
At time: 161.0458288192749 and batch: 600, loss is 4.266055221557617 and perplexity is 71.24005436584052
At time: 162.2124674320221 and batch: 650, loss is 4.321985082626343 and perplexity is 75.33803217220641
At time: 163.37890481948853 and batch: 700, loss is 4.351186494827271 and perplexity is 77.57044527824877
At time: 164.54490756988525 and batch: 750, loss is 4.3171156311035155 and perplexity is 74.97206901976305
At time: 165.7117259502411 and batch: 800, loss is 4.294749131202698 and perplexity is 73.31381998797686
At time: 166.92075657844543 and batch: 850, loss is 4.294770154953003 and perplexity is 73.31536133562459
At time: 168.08715653419495 and batch: 900, loss is 4.274140644073486 and perplexity is 71.81839521981921
At time: 169.25331139564514 and batch: 950, loss is 4.366227912902832 and perplexity is 78.74603387164827
At time: 170.418616771698 and batch: 1000, loss is 4.342154951095581 and perplexity is 76.87301857001992
At time: 171.5855906009674 and batch: 1050, loss is 4.279223308563233 and perplexity is 72.18435326005107
At time: 172.7521984577179 and batch: 1100, loss is 4.332962465286255 and perplexity is 76.16960246230909
At time: 173.91857242584229 and batch: 1150, loss is 4.2711609268188475 and perplexity is 71.60471521947454
At time: 175.0916244983673 and batch: 1200, loss is 4.357886433601379 and perplexity is 78.09190744391893
At time: 176.2568802833557 and batch: 1250, loss is 4.324963979721069 and perplexity is 75.56279101789688
At time: 177.42485165596008 and batch: 1300, loss is 4.3359693431854245 and perplexity is 76.39897983860047
At time: 178.59110236167908 and batch: 1350, loss is 4.206461791992187 and perplexity is 67.11863948019587
At time: 179.7607958316803 and batch: 1400, loss is 4.243238248825073 and perplexity is 69.63297604078848
At time: 180.92979168891907 and batch: 1450, loss is 4.174180808067322 and perplexity is 64.986581366425
At time: 182.0978546142578 and batch: 1500, loss is 4.1748988056182865 and perplexity is 65.03325832765833
At time: 183.26507568359375 and batch: 1550, loss is 4.177212800979614 and perplexity is 65.18391923285134
At time: 184.43168425559998 and batch: 1600, loss is 4.280029730796814 and perplexity is 72.24258780509669
At time: 185.59874320030212 and batch: 1650, loss is 4.218828921318054 and perplexity is 67.95385835952443
At time: 186.765953540802 and batch: 1700, loss is 4.252862286567688 and perplexity is 70.30636157671819
At time: 187.93331670761108 and batch: 1750, loss is 4.256270384788513 and perplexity is 70.54638133565541
At time: 189.1009247303009 and batch: 1800, loss is 4.2019823455810545 and perplexity is 66.81865750964258
At time: 190.26825404167175 and batch: 1850, loss is 4.2411483669281 and perplexity is 69.4876033035653
At time: 191.43524408340454 and batch: 1900, loss is 4.333846845626831 and perplexity is 76.23699515727102
At time: 192.60184288024902 and batch: 1950, loss is 4.257735176086426 and perplexity is 70.64979278073747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477525436046512 and perplexity of 88.01660026354553
finished 4 epochs...
Completing Train Step...
At time: 196.25639843940735 and batch: 50, loss is 4.231047630310059 and perplexity is 68.78926015185385
At time: 197.42158937454224 and batch: 100, loss is 4.187669281959534 and perplexity is 65.86908963723855
At time: 198.58633065223694 and batch: 150, loss is 4.143333950042725 and perplexity is 63.01255234034512
At time: 199.74972319602966 and batch: 200, loss is 4.145665097236633 and perplexity is 63.15961522092702
At time: 200.91350531578064 and batch: 250, loss is 4.134390068054199 and perplexity is 62.45148829382322
At time: 202.07913994789124 and batch: 300, loss is 4.1559846353530885 and perplexity is 63.81476790006197
At time: 203.24235725402832 and batch: 350, loss is 4.175471835136413 and perplexity is 65.07053498363211
At time: 204.40683317184448 and batch: 400, loss is 4.1345267009735105 and perplexity is 62.460021805950184
At time: 205.57448029518127 and batch: 450, loss is 4.162129912376404 and perplexity is 64.20813476322056
At time: 206.7481906414032 and batch: 500, loss is 4.177120876312256 and perplexity is 65.17792749815709
At time: 207.9133026599884 and batch: 550, loss is 4.145018610954285 and perplexity is 63.11879659185183
At time: 209.07762169837952 and batch: 600, loss is 4.118531799316406 and perplexity is 61.468927259354125
At time: 210.24180507659912 and batch: 650, loss is 4.169828000068665 and perplexity is 64.70432201129957
At time: 211.406907081604 and batch: 700, loss is 4.204053239822388 and perplexity is 66.95717526099575
At time: 212.57144951820374 and batch: 750, loss is 4.167576289176941 and perplexity is 64.55879049362632
At time: 213.736403465271 and batch: 800, loss is 4.147474465370178 and perplexity is 63.273997664803645
At time: 214.9011263847351 and batch: 850, loss is 4.142009868621826 and perplexity is 62.92917380267571
At time: 216.06436347961426 and batch: 900, loss is 4.128328309059143 and perplexity is 62.07406749555369
At time: 217.22664499282837 and batch: 950, loss is 4.216573271751404 and perplexity is 67.80075101154206
At time: 218.39173483848572 and batch: 1000, loss is 4.195250473022461 and perplexity is 66.3703534785766
At time: 219.5543270111084 and batch: 1050, loss is 4.140406188964843 and perplexity is 62.828336443839184
At time: 220.7214195728302 and batch: 1100, loss is 4.185369582176208 and perplexity is 65.717784550892
At time: 221.88711738586426 and batch: 1150, loss is 4.130443320274353 and perplexity is 62.205493779520644
At time: 223.05274105072021 and batch: 1200, loss is 4.213631501197815 and perplexity is 67.60158984556045
At time: 224.21728014945984 and batch: 1250, loss is 4.187641019821167 and perplexity is 65.86722806221931
At time: 225.38206791877747 and batch: 1300, loss is 4.196140604019165 and perplexity is 66.42945808899044
At time: 226.5480043888092 and batch: 1350, loss is 4.063764495849609 and perplexity is 58.192966437773855
At time: 227.71244192123413 and batch: 1400, loss is 4.105183820724488 and perplexity is 60.653892965467406
At time: 228.8774073123932 and batch: 1450, loss is 4.032750034332276 and perplexity is 56.41584362165502
At time: 230.04206228256226 and batch: 1500, loss is 4.036698975563049 and perplexity is 56.63906693038405
At time: 231.20626950263977 and batch: 1550, loss is 4.040286793708801 and perplexity is 56.84264258030451
At time: 232.37022399902344 and batch: 1600, loss is 4.15038200378418 and perplexity is 63.45823695523549
At time: 233.53559470176697 and batch: 1650, loss is 4.081091132164001 and perplexity is 59.21004059559286
At time: 234.70528388023376 and batch: 1700, loss is 4.117187509536743 and perplexity is 61.38635072450389
At time: 235.86986422538757 and batch: 1750, loss is 4.118852562904358 and perplexity is 61.488647415594365
At time: 237.03324604034424 and batch: 1800, loss is 4.066035561561584 and perplexity is 58.32527667428105
At time: 238.19573521614075 and batch: 1850, loss is 4.105307593345642 and perplexity is 60.66140072140067
At time: 239.35930037498474 and batch: 1900, loss is 4.196132192611694 and perplexity is 66.42889932610038
At time: 240.52418112754822 and batch: 1950, loss is 4.123163576126099 and perplexity is 61.75429798773182
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.472366120094477 and perplexity of 87.56366423849911
finished 5 epochs...
Completing Train Step...
At time: 244.20110249519348 and batch: 50, loss is 4.0976526641845705 and perplexity is 60.19881478622903
At time: 245.36750864982605 and batch: 100, loss is 4.056485362052918 and perplexity is 57.77091001521277
At time: 246.5337462425232 and batch: 150, loss is 4.017859921455384 and perplexity is 55.5820285481161
At time: 247.6998839378357 and batch: 200, loss is 4.021695885658264 and perplexity is 55.79564867759012
At time: 248.86495280265808 and batch: 250, loss is 4.009716506004334 and perplexity is 55.131238972615044
At time: 250.03070306777954 and batch: 300, loss is 4.02537082195282 and perplexity is 56.001071358437734
At time: 251.1944191455841 and batch: 350, loss is 4.045039381980896 and perplexity is 57.113435230070856
At time: 252.36097812652588 and batch: 400, loss is 4.0087594270706175 and perplexity is 55.078499267260966
At time: 253.5496256351471 and batch: 450, loss is 4.03858913898468 and perplexity is 56.74622526440891
At time: 254.71532225608826 and batch: 500, loss is 4.057939524650574 and perplexity is 57.85497942226876
At time: 255.87997150421143 and batch: 550, loss is 4.027405481338501 and perplexity is 56.11513046024754
At time: 257.0467264652252 and batch: 600, loss is 4.002943286895752 and perplexity is 54.759084775046915
At time: 258.2119171619415 and batch: 650, loss is 4.051091351509094 and perplexity is 57.460132040815566
At time: 259.37859773635864 and batch: 700, loss is 4.082979965209961 and perplexity is 59.32198416499734
At time: 260.5437808036804 and batch: 750, loss is 4.048741693496704 and perplexity is 57.32527887262892
At time: 261.7093470096588 and batch: 800, loss is 4.025923137664795 and perplexity is 56.03201017324668
At time: 262.8724389076233 and batch: 850, loss is 4.02548577785492 and perplexity is 56.00750938215161
At time: 264.0392255783081 and batch: 900, loss is 4.0041083288192745 and perplexity is 54.82291858181384
At time: 265.20393776893616 and batch: 950, loss is 4.100882329940796 and perplexity is 60.39355113429656
At time: 266.37005949020386 and batch: 1000, loss is 4.077317242622375 and perplexity is 58.987009554591566
At time: 267.53927063941956 and batch: 1050, loss is 4.023644604682922 and perplexity is 55.90448473066275
At time: 268.70878624916077 and batch: 1100, loss is 4.0712583541870115 and perplexity is 58.630694371566136
At time: 269.87370133399963 and batch: 1150, loss is 4.014767074584961 and perplexity is 55.41038741176734
At time: 271.0392324924469 and batch: 1200, loss is 4.097411112785339 and perplexity is 60.18427543435645
At time: 272.2043330669403 and batch: 1250, loss is 4.078557186126709 and perplexity is 59.06019547775715
At time: 273.3691520690918 and batch: 1300, loss is 4.08017936706543 and perplexity is 59.156079550729714
At time: 274.53494358062744 and batch: 1350, loss is 3.944735279083252 and perplexity is 51.662660115013665
At time: 275.7021281719208 and batch: 1400, loss is 3.9913393592834474 and perplexity is 54.12733678694559
At time: 276.8675649166107 and batch: 1450, loss is 3.916944189071655 and perplexity is 50.24666562778876
At time: 278.03257751464844 and batch: 1500, loss is 3.925803575515747 and perplexity is 50.6937979907429
At time: 279.19634437561035 and batch: 1550, loss is 3.9287963676452637 and perplexity is 50.84574124426104
At time: 280.36003732681274 and batch: 1600, loss is 4.038443841934204 and perplexity is 56.73798080421475
At time: 281.52419233322144 and batch: 1650, loss is 3.969992651939392 and perplexity is 52.9841415075627
At time: 282.69047927856445 and batch: 1700, loss is 4.007506499290466 and perplexity is 55.009533099275934
At time: 283.85522055625916 and batch: 1750, loss is 4.005888118743896 and perplexity is 54.92057874144873
At time: 285.01898431777954 and batch: 1800, loss is 3.9609497117996217 and perplexity is 52.50716895502861
At time: 286.1835699081421 and batch: 1850, loss is 3.9958530616760255 and perplexity is 54.37220368893235
At time: 287.3489615917206 and batch: 1900, loss is 4.085198683738708 and perplexity is 59.453749070992096
At time: 288.5151391029358 and batch: 1950, loss is 4.013681240081787 and perplexity is 55.35025355489804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4807214071584305 and perplexity of 88.29834876557344
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 292.166451215744 and batch: 50, loss is 4.021001267433166 and perplexity is 55.75690546056761
At time: 293.355021238327 and batch: 100, loss is 4.008673439025879 and perplexity is 55.073763378419656
At time: 294.5211908817291 and batch: 150, loss is 3.979598331451416 and perplexity is 53.49554243460606
At time: 295.68746519088745 and batch: 200, loss is 3.9828786516189574 and perplexity is 53.671313075702315
At time: 296.85447239875793 and batch: 250, loss is 3.9671399974823 and perplexity is 52.833211438154706
At time: 298.0203459262848 and batch: 300, loss is 3.9755626773834227 and perplexity is 53.28008797341331
At time: 299.1869831085205 and batch: 350, loss is 3.989391951560974 and perplexity is 54.0220313628678
At time: 300.35291361808777 and batch: 400, loss is 3.9479409885406493 and perplexity is 51.82854133457833
At time: 301.51800870895386 and batch: 450, loss is 3.9665365028381347 and perplexity is 52.80133649716324
At time: 302.68357729911804 and batch: 500, loss is 3.9872137355804442 and perplexity is 53.904487774988304
At time: 303.84855818748474 and batch: 550, loss is 3.9545066738128662 and perplexity is 52.16995079216094
At time: 305.0149862766266 and batch: 600, loss is 3.9242936611175536 and perplexity is 50.617312453096076
At time: 306.178249835968 and batch: 650, loss is 3.950933132171631 and perplexity is 51.98385201449282
At time: 307.3451597690582 and batch: 700, loss is 3.9728050899505614 and perplexity is 53.13336586489379
At time: 308.5115373134613 and batch: 750, loss is 3.929778938293457 and perplexity is 50.895725329619445
At time: 309.6767086982727 and batch: 800, loss is 3.9068088054656984 and perplexity is 49.739968519088436
At time: 310.8507306575775 and batch: 850, loss is 3.899379849433899 and perplexity is 49.37182164655019
At time: 312.0564589500427 and batch: 900, loss is 3.8721433973312376 and perplexity is 48.04525586922973
At time: 313.2240846157074 and batch: 950, loss is 3.96258996963501 and perplexity is 52.59336492280144
At time: 314.3931703567505 and batch: 1000, loss is 3.9262457132339477 and perplexity is 50.71621658660165
At time: 315.5628843307495 and batch: 1050, loss is 3.8691382074356078 and perplexity is 47.90108748694213
At time: 316.7316908836365 and batch: 1100, loss is 3.905077910423279 and perplexity is 49.653948321611686
At time: 317.90044021606445 and batch: 1150, loss is 3.853446559906006 and perplexity is 47.1553070701233
At time: 319.06973218917847 and batch: 1200, loss is 3.916785945892334 and perplexity is 50.23871506474732
At time: 320.23780512809753 and batch: 1250, loss is 3.8871097993850707 and perplexity is 48.769728335426485
At time: 321.4050757884979 and batch: 1300, loss is 3.8900982189178466 and perplexity is 48.915690734005466
At time: 322.5725407600403 and batch: 1350, loss is 3.7482090473175047 and perplexity is 42.44499690692997
At time: 323.73977541923523 and batch: 1400, loss is 3.77704047203064 and perplexity is 43.686558633491735
At time: 324.9076271057129 and batch: 1450, loss is 3.6983643102645876 and perplexity is 40.381199198006634
At time: 326.07591223716736 and batch: 1500, loss is 3.695820732116699 and perplexity is 40.27861698039171
At time: 327.2451238632202 and batch: 1550, loss is 3.701099367141724 and perplexity is 40.49179524888178
At time: 328.4141540527344 and batch: 1600, loss is 3.7952893447875975 and perplexity is 44.4911078134418
At time: 329.58428287506104 and batch: 1650, loss is 3.7189153957366945 and perplexity is 41.219662833088975
At time: 330.75274109840393 and batch: 1700, loss is 3.7388501501083375 and perplexity is 42.049611614932076
At time: 331.9215657711029 and batch: 1750, loss is 3.7258031368255615 and perplexity is 41.50455319769988
At time: 333.0902681350708 and batch: 1800, loss is 3.674464449882507 and perplexity is 39.427535780588066
At time: 334.2599217891693 and batch: 1850, loss is 3.6931568336486817 and perplexity is 40.17146162318743
At time: 335.4350345134735 and batch: 1900, loss is 3.7701305246353147 and perplexity is 43.38572737253647
At time: 336.60455322265625 and batch: 1950, loss is 3.696041669845581 and perplexity is 40.28751702969199
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411902707122093 and perplexity of 82.4261472126758
finished 7 epochs...
Completing Train Step...
At time: 340.3493106365204 and batch: 50, loss is 3.9072898912429808 and perplexity is 49.76390346742542
At time: 341.55566477775574 and batch: 100, loss is 3.8905112314224244 and perplexity is 48.93589769852594
At time: 342.72915029525757 and batch: 150, loss is 3.854167504310608 and perplexity is 47.18931568258919
At time: 343.8992533683777 and batch: 200, loss is 3.852069630622864 and perplexity is 47.090422228133825
At time: 345.06934118270874 and batch: 250, loss is 3.839875922203064 and perplexity is 46.51970201954131
At time: 346.2360489368439 and batch: 300, loss is 3.846297206878662 and perplexity is 46.81937939639343
At time: 347.40274024009705 and batch: 350, loss is 3.8643514823913576 and perplexity is 47.6723460497621
At time: 348.5704312324524 and batch: 400, loss is 3.825520396232605 and perplexity is 45.85665779009216
At time: 349.7367956638336 and batch: 450, loss is 3.85327543258667 and perplexity is 47.147238199253735
At time: 350.90354800224304 and batch: 500, loss is 3.8742372846603392 and perplexity is 48.145962619217045
At time: 352.07028579711914 and batch: 550, loss is 3.8438985538482666 and perplexity is 46.70721053099812
At time: 353.23758721351624 and batch: 600, loss is 3.8157577466964723 and perplexity is 45.41115350069838
At time: 354.4060320854187 and batch: 650, loss is 3.8451447677612305 and perplexity is 46.765453990964744
At time: 355.57283186912537 and batch: 700, loss is 3.869432258605957 and perplexity is 47.91517492889155
At time: 356.7415084838867 and batch: 750, loss is 3.83144248008728 and perplexity is 46.12903047372316
At time: 357.9058747291565 and batch: 800, loss is 3.8077256965637205 and perplexity is 45.04786974891479
At time: 359.07044076919556 and batch: 850, loss is 3.803867692947388 and perplexity is 44.87440972436736
At time: 360.23405361175537 and batch: 900, loss is 3.7763539361953735 and perplexity is 43.656576538539305
At time: 361.3986294269562 and batch: 950, loss is 3.8688298988342287 and perplexity is 47.88632144602017
At time: 362.56257247924805 and batch: 1000, loss is 3.838629026412964 and perplexity is 46.46173294714322
At time: 363.72637844085693 and batch: 1050, loss is 3.7857961750030515 and perplexity is 44.070744619583884
At time: 364.890811920166 and batch: 1100, loss is 3.821193356513977 and perplexity is 45.6586628853054
At time: 366.0521206855774 and batch: 1150, loss is 3.7735706043243407 and perplexity is 43.53523474325804
At time: 367.21493220329285 and batch: 1200, loss is 3.8379925870895386 and perplexity is 46.432172281044146
At time: 368.38512134552 and batch: 1250, loss is 3.8140696716308593 and perplexity is 45.33456073013444
At time: 369.5472569465637 and batch: 1300, loss is 3.8184084463119508 and perplexity is 45.531684502988846
At time: 370.7107746601105 and batch: 1350, loss is 3.679275245666504 and perplexity is 39.61767058665375
At time: 371.8751392364502 and batch: 1400, loss is 3.714555377960205 and perplexity is 41.040335589461314
At time: 373.0386097431183 and batch: 1450, loss is 3.6385660648345945 and perplexity is 38.03725464413895
At time: 374.213210105896 and batch: 1500, loss is 3.6373045158386232 and perplexity is 37.98929903926585
At time: 375.3769898414612 and batch: 1550, loss is 3.6471665048599244 and perplexity is 38.3658025746649
At time: 376.54001474380493 and batch: 1600, loss is 3.746762399673462 and perplexity is 42.383638344963586
At time: 377.7032675743103 and batch: 1650, loss is 3.674194436073303 and perplexity is 39.416891238615754
At time: 378.8659608364105 and batch: 1700, loss is 3.697352466583252 and perplexity is 40.340360401476815
At time: 380.0293071269989 and batch: 1750, loss is 3.6890721273422242 and perplexity is 40.00770767163866
At time: 381.19221472740173 and batch: 1800, loss is 3.6410154628753664 and perplexity is 38.13053721757916
At time: 382.3560621738434 and batch: 1850, loss is 3.666549468040466 and perplexity is 39.11669930607849
At time: 383.51827025413513 and batch: 1900, loss is 3.7460223484039306 and perplexity is 42.35228388298475
At time: 384.68589520454407 and batch: 1950, loss is 3.675459928512573 and perplexity is 39.46680459228236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418320482830668 and perplexity of 82.9568408528758
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 388.3487231731415 and batch: 50, loss is 3.8622680854797364 and perplexity is 47.57312902134556
At time: 389.54213857650757 and batch: 100, loss is 3.87120210647583 and perplexity is 48.00005258728989
At time: 390.70929169654846 and batch: 150, loss is 3.8546056604385375 and perplexity is 47.20999650081108
At time: 391.8766083717346 and batch: 200, loss is 3.862303500175476 and perplexity is 47.5748138390687
At time: 393.04369616508484 and batch: 250, loss is 3.8612550401687624 and perplexity is 47.524959689039754
At time: 394.21377396583557 and batch: 300, loss is 3.870583624839783 and perplexity is 47.970374614821864
At time: 395.39721941947937 and batch: 350, loss is 3.888414444923401 and perplexity is 48.833397067437566
At time: 396.57077288627625 and batch: 400, loss is 3.8487927293777466 and perplexity is 46.936364119362935
At time: 397.73740458488464 and batch: 450, loss is 3.8685111951828004 and perplexity is 47.871062332218656
At time: 398.90457701683044 and batch: 500, loss is 3.88228994846344 and perplexity is 48.53523109020926
At time: 400.09705233573914 and batch: 550, loss is 3.8537267017364503 and perplexity is 47.16851909469505
At time: 401.26548528671265 and batch: 600, loss is 3.8176629114151 and perplexity is 45.49775169389786
At time: 402.43279242515564 and batch: 650, loss is 3.846178722381592 and perplexity is 46.813832354398244
At time: 403.60097217559814 and batch: 700, loss is 3.869261393547058 and perplexity is 47.90698859910395
At time: 404.7688570022583 and batch: 750, loss is 3.8192450189590454 and perplexity is 45.56979100202516
At time: 405.9359829425812 and batch: 800, loss is 3.783514938354492 and perplexity is 43.970323407652536
At time: 407.102313041687 and batch: 850, loss is 3.776212592124939 and perplexity is 43.65040637637831
At time: 408.26773953437805 and batch: 900, loss is 3.7509332275390626 and perplexity is 42.560782366632374
At time: 409.4336574077606 and batch: 950, loss is 3.857613306045532 and perplexity is 47.35220118283877
At time: 410.60124826431274 and batch: 1000, loss is 3.822259612083435 and perplexity is 45.70737265281645
At time: 411.7667558193207 and batch: 1050, loss is 3.7609679460525514 and perplexity is 42.9900178642558
At time: 412.93803668022156 and batch: 1100, loss is 3.7839447498321532 and perplexity is 43.98922641940431
At time: 414.11038994789124 and batch: 1150, loss is 3.7410608673095704 and perplexity is 42.14267424431029
At time: 415.2769911289215 and batch: 1200, loss is 3.8040779972076417 and perplexity is 44.88384799632839
At time: 416.4417836666107 and batch: 1250, loss is 3.779163918495178 and perplexity is 43.77942326361105
At time: 417.61228609085083 and batch: 1300, loss is 3.7781940841674806 and perplexity is 43.73698505842367
At time: 418.77807688713074 and batch: 1350, loss is 3.632273120880127 and perplexity is 37.79863991449258
At time: 419.9433159828186 and batch: 1400, loss is 3.6594226789474487 and perplexity is 38.838913874951295
At time: 421.10969161987305 and batch: 1450, loss is 3.5783699131011963 and perplexity is 35.81511149351425
At time: 422.2744119167328 and batch: 1500, loss is 3.570859222412109 and perplexity is 35.54712291851784
At time: 423.43931245803833 and batch: 1550, loss is 3.583850703239441 and perplexity is 36.01194551364072
At time: 424.6040289402008 and batch: 1600, loss is 3.6839003276824953 and perplexity is 39.801329954826066
At time: 425.76813864707947 and batch: 1650, loss is 3.609012384414673 and perplexity is 36.92956258705939
At time: 426.9336566925049 and batch: 1700, loss is 3.6246945667266846 and perplexity is 37.513263610728956
At time: 428.0981512069702 and batch: 1750, loss is 3.619092001914978 and perplexity is 37.30368076898971
At time: 429.27104687690735 and batch: 1800, loss is 3.562586536407471 and perplexity is 35.25426576009759
At time: 430.44764518737793 and batch: 1850, loss is 3.584794955253601 and perplexity is 36.045965925119084
At time: 431.6116986274719 and batch: 1900, loss is 3.6649152135848997 and perplexity is 39.05282487370458
At time: 432.7761232852936 and batch: 1950, loss is 3.590414595603943 and perplexity is 36.2491015296278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39084103606468 and perplexity of 80.70826900927167
finished 9 epochs...
Completing Train Step...
At time: 436.4399437904358 and batch: 50, loss is 3.845544390678406 and perplexity is 46.784146272794985
At time: 437.60653352737427 and batch: 100, loss is 3.8351155424118044 and perplexity is 46.298776831255545
At time: 438.7726595401764 and batch: 150, loss is 3.809433331489563 and perplexity is 45.124860782212636
At time: 439.93762373924255 and batch: 200, loss is 3.8177372121810915 and perplexity is 45.501132337290244
At time: 441.103755235672 and batch: 250, loss is 3.8125663805007934 and perplexity is 45.26646088687338
At time: 442.27255511283875 and batch: 300, loss is 3.816514186859131 and perplexity is 45.44551731648559
At time: 443.4408459663391 and batch: 350, loss is 3.836525349617004 and perplexity is 46.364095212767964
At time: 444.606840133667 and batch: 400, loss is 3.794812569618225 and perplexity is 44.469900613913275
At time: 445.7732629776001 and batch: 450, loss is 3.8201562643051146 and perplexity is 45.61133518759523
At time: 446.9390478134155 and batch: 500, loss is 3.833037700653076 and perplexity is 46.202675175969716
At time: 448.10532546043396 and batch: 550, loss is 3.805522294044495 and perplexity is 44.94872043226534
At time: 449.27230429649353 and batch: 600, loss is 3.773684678077698 and perplexity is 43.540201254157374
At time: 450.4374563694 and batch: 650, loss is 3.802919979095459 and perplexity is 44.83190177054436
At time: 451.6025342941284 and batch: 700, loss is 3.828059825897217 and perplexity is 45.97325553042591
At time: 452.7677435874939 and batch: 750, loss is 3.7794680833816527 and perplexity is 43.792741452277944
At time: 453.93389439582825 and batch: 800, loss is 3.744641828536987 and perplexity is 42.29385605334315
At time: 455.10408449172974 and batch: 850, loss is 3.740926947593689 and perplexity is 42.13703088723583
At time: 456.2694993019104 and batch: 900, loss is 3.7158110094070436 and perplexity is 41.09189949126988
At time: 457.45915699005127 and batch: 950, loss is 3.823517909049988 and perplexity is 45.76492230085513
At time: 458.62446331977844 and batch: 1000, loss is 3.790013813972473 and perplexity is 44.25701163690119
At time: 459.79005789756775 and batch: 1050, loss is 3.7314240646362307 and perplexity is 41.73850418988757
At time: 460.95542883872986 and batch: 1100, loss is 3.7557951545715333 and perplexity is 42.768213634176696
At time: 462.12088322639465 and batch: 1150, loss is 3.7140343761444092 and perplexity is 41.01895906918481
At time: 463.28726267814636 and batch: 1200, loss is 3.777435293197632 and perplexity is 43.703810417013834
At time: 464.4537127017975 and batch: 1250, loss is 3.7553148460388184 and perplexity is 42.74767662868353
At time: 465.6185562610626 and batch: 1300, loss is 3.7559630250930787 and perplexity is 42.77539375915382
At time: 466.78448390960693 and batch: 1350, loss is 3.612125210762024 and perplexity is 37.04469700623525
At time: 467.94977855682373 and batch: 1400, loss is 3.641806173324585 and perplexity is 38.16069935497851
At time: 469.1152880191803 and batch: 1450, loss is 3.5635434770584107 and perplexity is 35.28801814706235
At time: 470.2798902988434 and batch: 1500, loss is 3.5579659652709963 and perplexity is 35.091746671936896
At time: 471.4454598426819 and batch: 1550, loss is 3.5728221702575684 and perplexity is 35.61696859614699
At time: 472.6127564907074 and batch: 1600, loss is 3.67580189704895 and perplexity is 39.48030330562033
At time: 473.77856397628784 and batch: 1650, loss is 3.6036761093139646 and perplexity is 36.733021147730355
At time: 474.95036816596985 and batch: 1700, loss is 3.6221656227111816 and perplexity is 37.41851452528269
At time: 476.11538529396057 and batch: 1750, loss is 3.6177718114852904 and perplexity is 37.25446530068963
At time: 477.2799210548401 and batch: 1800, loss is 3.5630136013031004 and perplexity is 35.269324834797125
At time: 478.44155764579773 and batch: 1850, loss is 3.5874398708343507 and perplexity is 36.141430654440015
At time: 479.61090564727783 and batch: 1900, loss is 3.667290697097778 and perplexity is 39.14570448864435
At time: 480.7773721218109 and batch: 1950, loss is 3.592957968711853 and perplexity is 36.34141386223421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3917236328125 and perplexity of 80.77953330921501
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 484.42855191230774 and batch: 50, loss is 3.8327439785003663 and perplexity is 46.1891064195758
At time: 485.59250378608704 and batch: 100, loss is 3.8326489782333373 and perplexity is 46.18471865055503
At time: 486.78010272979736 and batch: 150, loss is 3.814549288749695 and perplexity is 45.356309176582215
At time: 487.9447269439697 and batch: 200, loss is 3.8323018980026244 and perplexity is 46.1686916292424
At time: 489.10886240005493 and batch: 250, loss is 3.8355494642257693 and perplexity is 46.318871239868336
At time: 490.27933859825134 and batch: 300, loss is 3.8414236879348755 and perplexity is 46.59175936974501
At time: 491.45267248153687 and batch: 350, loss is 3.8766688299179077 and perplexity is 48.2631741511169
At time: 492.62240839004517 and batch: 400, loss is 3.8453660440444946 and perplexity is 46.77580322178646
At time: 493.791827917099 and batch: 450, loss is 3.8761007261276244 and perplexity is 48.235763445750564
At time: 494.963125705719 and batch: 500, loss is 3.880436577796936 and perplexity is 48.445360623982914
At time: 496.13209223747253 and batch: 550, loss is 3.849182620048523 and perplexity is 46.95466773782641
At time: 497.3013072013855 and batch: 600, loss is 3.8094867658615112 and perplexity is 45.1272720652299
At time: 498.47116470336914 and batch: 650, loss is 3.8265321588516237 and perplexity is 45.9030773210906
At time: 499.64117980003357 and batch: 700, loss is 3.8498313570022584 and perplexity is 46.98513884873747
At time: 500.8110547065735 and batch: 750, loss is 3.7985954761505125 and perplexity is 44.638444683672944
At time: 501.9812970161438 and batch: 800, loss is 3.7606205844879153 and perplexity is 42.97508737767545
At time: 503.1501290798187 and batch: 850, loss is 3.752348551750183 and perplexity is 42.62106232013647
At time: 504.3201687335968 and batch: 900, loss is 3.716825637817383 and perplexity is 41.13361365853952
At time: 505.48987889289856 and batch: 950, loss is 3.831896800994873 and perplexity is 46.14999261812404
At time: 506.6600317955017 and batch: 1000, loss is 3.797123031616211 and perplexity is 44.572765416184524
At time: 507.8306231498718 and batch: 1050, loss is 3.743877024650574 and perplexity is 42.26152191407592
At time: 508.99954414367676 and batch: 1100, loss is 3.7646914672851564 and perplexity is 43.150390498726246
At time: 510.1689920425415 and batch: 1150, loss is 3.7239806032180787 and perplexity is 41.428978644134595
At time: 511.34000754356384 and batch: 1200, loss is 3.785749635696411 and perplexity is 44.06869364541199
At time: 512.5091416835785 and batch: 1250, loss is 3.7664538764953615 and perplexity is 43.226506198168195
At time: 513.6794016361237 and batch: 1300, loss is 3.76791259765625 and perplexity is 43.28960762997839
At time: 514.8543193340302 and batch: 1350, loss is 3.6257190132141113 and perplexity is 37.55171363349952
At time: 516.0299706459045 and batch: 1400, loss is 3.6532081937789918 and perplexity is 38.5982984456016
At time: 517.1995193958282 and batch: 1450, loss is 3.5622511816024782 and perplexity is 35.242445054854386
At time: 518.3697962760925 and batch: 1500, loss is 3.5482577800750734 and perplexity is 34.75271783651044
At time: 519.5360193252563 and batch: 1550, loss is 3.559038338661194 and perplexity is 35.12939831198364
At time: 520.7024939060211 and batch: 1600, loss is 3.654895281791687 and perplexity is 38.663472133635054
At time: 521.8667738437653 and batch: 1650, loss is 3.5796295833587646 and perplexity is 35.86025515132627
At time: 523.0337810516357 and batch: 1700, loss is 3.5947022247314453 and perplexity is 36.404857907367386
At time: 524.2001564502716 and batch: 1750, loss is 3.600755367279053 and perplexity is 36.62588999618259
At time: 525.3665466308594 and batch: 1800, loss is 3.5447788858413696 and perplexity is 34.63202686411135
At time: 526.5326001644135 and batch: 1850, loss is 3.5710665798187256 and perplexity is 35.55449464200321
At time: 527.6982314586639 and batch: 1900, loss is 3.664797239303589 and perplexity is 39.04821791651353
At time: 528.8644111156464 and batch: 1950, loss is 3.5988492918014527 and perplexity is 36.556144776358266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373808536973111 and perplexity of 79.34524628395395
finished 11 epochs...
Completing Train Step...
At time: 532.5330657958984 and batch: 50, loss is 3.8470683813095095 and perplexity is 46.855499230208146
At time: 533.6968560218811 and batch: 100, loss is 3.82651798248291 and perplexity is 45.90242658675394
At time: 534.8617470264435 and batch: 150, loss is 3.7957566928863526 and perplexity is 44.51190550759279
At time: 536.0250537395477 and batch: 200, loss is 3.801340732574463 and perplexity is 44.7611570220458
At time: 537.1874396800995 and batch: 250, loss is 3.8057498836517336 and perplexity is 44.95895145808782
At time: 538.351108789444 and batch: 300, loss is 3.8064215660095213 and perplexity is 44.98915973665501
At time: 539.5148162841797 and batch: 350, loss is 3.8409713888168335 and perplexity is 46.57069072309837
At time: 540.6793868541718 and batch: 400, loss is 3.809134392738342 and perplexity is 45.11137322875801
At time: 541.8442625999451 and batch: 450, loss is 3.8407985162734986 and perplexity is 46.562640625188706
At time: 543.0083663463593 and batch: 500, loss is 3.8482450675964355 and perplexity is 46.91066590418852
At time: 544.1714901924133 and batch: 550, loss is 3.8199457550048828 and perplexity is 45.60173458788547
At time: 545.3570265769958 and batch: 600, loss is 3.7843191194534302 and perplexity is 44.00569773242645
At time: 546.5192906856537 and batch: 650, loss is 3.8034180355072023 and perplexity is 44.85423614810011
At time: 547.6841881275177 and batch: 700, loss is 3.830427565574646 and perplexity is 46.08223720084413
At time: 548.8488156795502 and batch: 750, loss is 3.783203806877136 and perplexity is 43.95664498397531
At time: 550.0135176181793 and batch: 800, loss is 3.746201753616333 and perplexity is 42.35988278509144
At time: 551.1773023605347 and batch: 850, loss is 3.7380062198638915 and perplexity is 42.01413964596206
At time: 552.3410785198212 and batch: 900, loss is 3.703735728263855 and perplexity is 40.5986870844693
At time: 553.503443479538 and batch: 950, loss is 3.818191800117493 and perplexity is 45.521821305264716
At time: 554.6669418811798 and batch: 1000, loss is 3.7828528881073 and perplexity is 43.94122247837302
At time: 555.8298854827881 and batch: 1050, loss is 3.7294627952575685 and perplexity is 41.6567239624512
At time: 556.9929676055908 and batch: 1100, loss is 3.750626063346863 and perplexity is 42.54771122589331
At time: 558.155699968338 and batch: 1150, loss is 3.7100979328155517 and perplexity is 40.85780765120694
At time: 559.3202328681946 and batch: 1200, loss is 3.7723761796951294 and perplexity is 43.48326622905726
At time: 560.4838166236877 and batch: 1250, loss is 3.754931011199951 and perplexity is 42.7312717297001
At time: 561.6475837230682 and batch: 1300, loss is 3.757576060295105 and perplexity is 42.844447653276404
At time: 562.8128600120544 and batch: 1350, loss is 3.616053328514099 and perplexity is 37.1904991146123
At time: 563.9769282341003 and batch: 1400, loss is 3.6456956672668457 and perplexity is 38.30941418919373
At time: 565.1410958766937 and batch: 1450, loss is 3.5574818086624145 and perplexity is 35.07476088310175
At time: 566.3052806854248 and batch: 1500, loss is 3.5459218311309812 and perplexity is 34.67163200502859
At time: 567.4695575237274 and batch: 1550, loss is 3.5583239507675173 and perplexity is 35.10431125712849
At time: 568.6332895755768 and batch: 1600, loss is 3.6557651567459106 and perplexity is 38.69711915191499
At time: 569.7952711582184 and batch: 1650, loss is 3.5822886419296265 and perplexity is 35.955736559208525
At time: 570.9584028720856 and batch: 1700, loss is 3.5986968326568602 and perplexity is 36.550571882626166
At time: 572.1358020305634 and batch: 1750, loss is 3.6060878229141236 and perplexity is 36.82171758662035
At time: 573.3005728721619 and batch: 1800, loss is 3.5511339044570924 and perplexity is 34.85281485235441
At time: 574.4638447761536 and batch: 1850, loss is 3.578114585876465 and perplexity is 35.80596808782304
At time: 575.6349439620972 and batch: 1900, loss is 3.67202392578125 and perplexity is 39.33142925211401
At time: 576.7993240356445 and batch: 1950, loss is 3.6054531478881837 and perplexity is 36.79835517660923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372966535701308 and perplexity of 79.27846560432539
finished 12 epochs...
Completing Train Step...
At time: 580.575258731842 and batch: 50, loss is 3.841926684379578 and perplexity is 46.615200754032664
At time: 581.7662448883057 and batch: 100, loss is 3.818525791168213 and perplexity is 45.53702772545593
At time: 582.9330909252167 and batch: 150, loss is 3.7859519290924073 and perplexity is 44.0776093528706
At time: 584.0991077423096 and batch: 200, loss is 3.790403752326965 and perplexity is 44.274272508312805
At time: 585.2650194168091 and batch: 250, loss is 3.7940049505233766 and perplexity is 44.4340003718433
At time: 586.4318559169769 and batch: 300, loss is 3.7943186283111574 and perplexity is 44.44794051702484
At time: 587.5970892906189 and batch: 350, loss is 3.828715214729309 and perplexity is 46.00339576438297
At time: 588.7621462345123 and batch: 400, loss is 3.7967567300796508 and perplexity is 44.55644133367462
At time: 589.9259302616119 and batch: 450, loss is 3.829063391685486 and perplexity is 46.019415875448935
At time: 591.0917482376099 and batch: 500, loss is 3.8364657068252566 and perplexity is 46.361330011155616
At time: 592.2564656734467 and batch: 550, loss is 3.8082139015197756 and perplexity is 45.06986771150619
At time: 593.4211158752441 and batch: 600, loss is 3.773482074737549 and perplexity is 43.531380757513745
At time: 594.5887703895569 and batch: 650, loss is 3.7929079294204713 and perplexity is 44.38528206314111
At time: 595.7569150924683 and batch: 700, loss is 3.820669231414795 and perplexity is 45.634738304376484
At time: 596.9231090545654 and batch: 750, loss is 3.7741422176361086 and perplexity is 43.56012717671361
At time: 598.0890073776245 and batch: 800, loss is 3.7375161933898924 and perplexity is 41.993556648771886
At time: 599.2558825016022 and batch: 850, loss is 3.7295805835723876 and perplexity is 41.66163092675348
At time: 600.4220249652863 and batch: 900, loss is 3.6957336902618407 and perplexity is 40.27511120743531
At time: 601.5876326560974 and batch: 950, loss is 3.810290198326111 and perplexity is 45.163543349458465
At time: 602.7977442741394 and batch: 1000, loss is 3.774825315475464 and perplexity is 43.589893170855746
At time: 603.962504863739 and batch: 1050, loss is 3.7219218683242796 and perplexity is 41.34377509603805
At time: 605.1283228397369 and batch: 1100, loss is 3.743437647819519 and perplexity is 42.24295725924003
At time: 606.2943162918091 and batch: 1150, loss is 3.7033090591430664 and perplexity is 40.5813685732455
At time: 607.4604082107544 and batch: 1200, loss is 3.765889058113098 and perplexity is 43.20209796662426
At time: 608.6261148452759 and batch: 1250, loss is 3.7494323205947877 and perplexity is 42.49695050764769
At time: 609.7917394638062 and batch: 1300, loss is 3.7525414085388182 and perplexity is 42.629282874013086
At time: 610.95942735672 and batch: 1350, loss is 3.6114127445220947 and perplexity is 37.01831331011233
At time: 612.1261298656464 and batch: 1400, loss is 3.641961808204651 and perplexity is 38.166638953038195
At time: 613.2926733493805 and batch: 1450, loss is 3.554803605079651 and perplexity is 34.98094921229065
At time: 614.4578342437744 and batch: 1500, loss is 3.5441332387924196 and perplexity is 34.60967401496943
At time: 615.6232995986938 and batch: 1550, loss is 3.557052803039551 and perplexity is 35.05971684068244
At time: 616.7901782989502 and batch: 1600, loss is 3.655088572502136 and perplexity is 38.67094614593749
At time: 617.9553406238556 and batch: 1650, loss is 3.5820671367645263 and perplexity is 35.94777305985636
At time: 619.1197240352631 and batch: 1700, loss is 3.5988824367523193 and perplexity is 36.55735644806104
At time: 620.2833025455475 and batch: 1750, loss is 3.6065211582183836 and perplexity is 36.83767719449516
At time: 621.4475779533386 and batch: 1800, loss is 3.5521242141723635 and perplexity is 34.8873470294603
At time: 622.6127223968506 and batch: 1850, loss is 3.579554123878479 and perplexity is 35.85754925720361
At time: 623.777233839035 and batch: 1900, loss is 3.673371229171753 and perplexity is 39.38445633386088
At time: 624.943026304245 and batch: 1950, loss is 3.606723575592041 and perplexity is 36.845134535086686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37324701353561 and perplexity of 79.3007045752883
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 628.577189207077 and batch: 50, loss is 3.8403045082092286 and perplexity is 46.53964398595646
At time: 629.7653050422668 and batch: 100, loss is 3.8214683389663695 and perplexity is 45.67121994280467
At time: 630.9306342601776 and batch: 150, loss is 3.7900974273681642 and perplexity is 44.26071227063642
At time: 632.1165008544922 and batch: 200, loss is 3.7948667192459107 and perplexity is 44.472308707672845
At time: 633.2812323570251 and batch: 250, loss is 3.79839081287384 and perplexity is 44.629309768141184
At time: 634.4474680423737 and batch: 300, loss is 3.796547360420227 and perplexity is 44.547113543239675
At time: 635.6133146286011 and batch: 350, loss is 3.834633059501648 and perplexity is 46.27644385074726
At time: 636.7861232757568 and batch: 400, loss is 3.8106143951416014 and perplexity is 45.17818760007007
At time: 637.9513499736786 and batch: 450, loss is 3.848524947166443 and perplexity is 46.92379707867856
At time: 639.1172580718994 and batch: 500, loss is 3.8573298168182375 and perplexity is 47.33877924649182
At time: 640.2821829319 and batch: 550, loss is 3.83157723903656 and perplexity is 46.13524719227093
At time: 641.4491145610809 and batch: 600, loss is 3.795212755203247 and perplexity is 44.48770038847537
At time: 642.6140706539154 and batch: 650, loss is 3.8097461032867432 and perplexity is 45.138976773443886
At time: 643.7860057353973 and batch: 700, loss is 3.8364790964126585 and perplexity is 46.361950774391744
At time: 644.9510147571564 and batch: 750, loss is 3.7905435609817504 and perplexity is 44.2804628675166
At time: 646.1206676959991 and batch: 800, loss is 3.7542567157745363 and perplexity is 42.70246794087348
At time: 647.284613609314 and batch: 850, loss is 3.7463718366622927 and perplexity is 42.367088095715246
At time: 648.4499588012695 and batch: 900, loss is 3.7080204248428346 and perplexity is 40.773013340989536
At time: 649.6161139011383 and batch: 950, loss is 3.8252566289901733 and perplexity is 45.844563900975736
At time: 650.7812886238098 and batch: 1000, loss is 3.7830648708343504 and perplexity is 43.950538245899935
At time: 651.9464645385742 and batch: 1050, loss is 3.729405360221863 and perplexity is 41.654331475729975
At time: 653.1130192279816 and batch: 1100, loss is 3.7470465755462645 and perplexity is 42.39568446390994
At time: 654.2883322238922 and batch: 1150, loss is 3.7046966552734375 and perplexity is 40.63771820947008
At time: 655.4533064365387 and batch: 1200, loss is 3.7674207973480223 and perplexity is 43.26832302192031
At time: 656.6203362941742 and batch: 1250, loss is 3.7485051012039183 and perplexity is 42.457564773514164
At time: 657.7879824638367 and batch: 1300, loss is 3.7503026628494265 and perplexity is 42.533953499665735
At time: 658.9547579288483 and batch: 1350, loss is 3.6079041385650634 and perplexity is 36.888658222826926
At time: 660.1214270591736 and batch: 1400, loss is 3.6423355770111083 and perplexity is 38.18090711845763
At time: 661.2882356643677 and batch: 1450, loss is 3.555245280265808 and perplexity is 34.99640284203712
At time: 662.4550468921661 and batch: 1500, loss is 3.545326828956604 and perplexity is 34.65100844473644
At time: 663.6222603321075 and batch: 1550, loss is 3.5615482759475707 and perplexity is 35.21768164512252
At time: 664.788984298706 and batch: 1600, loss is 3.6538729906082152 and perplexity is 38.62396700326417
At time: 665.9543299674988 and batch: 1650, loss is 3.5755311489105224 and perplexity is 35.7135850105735
At time: 667.1207277774811 and batch: 1700, loss is 3.588319764137268 and perplexity is 36.17324525190372
At time: 668.2864038944244 and batch: 1750, loss is 3.5923325204849244 and perplexity is 36.3186912960051
At time: 669.4549672603607 and batch: 1800, loss is 3.5384003639221193 and perplexity is 34.41182873751193
At time: 670.6201028823853 and batch: 1850, loss is 3.563971462249756 and perplexity is 35.30312412859883
At time: 671.7847566604614 and batch: 1900, loss is 3.6586745738983155 and perplexity is 38.809869152984774
At time: 672.9511168003082 and batch: 1950, loss is 3.598332152366638 and perplexity is 36.537245039630406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369913642351017 and perplexity of 79.03680597209494
finished 14 epochs...
Completing Train Step...
At time: 676.5914344787598 and batch: 50, loss is 3.8442572927474976 and perplexity is 46.72396923010906
At time: 677.8041248321533 and batch: 100, loss is 3.8217621803283692 and perplexity is 45.68464200815926
At time: 678.969758272171 and batch: 150, loss is 3.7881304693222044 and perplexity is 44.173738871070924
At time: 680.1348032951355 and batch: 200, loss is 3.7892248153686525 and perplexity is 44.222106688299014
At time: 681.3002948760986 and batch: 250, loss is 3.791747016906738 and perplexity is 44.3337845316165
At time: 682.4655594825745 and batch: 300, loss is 3.78992814540863 and perplexity is 44.25322036467302
At time: 683.6297292709351 and batch: 350, loss is 3.8272338247299196 and perplexity is 45.93529724664485
At time: 684.7950179576874 and batch: 400, loss is 3.8019374895095823 and perplexity is 44.78787652465397
At time: 685.95885014534 and batch: 450, loss is 3.838466024398804 and perplexity is 46.45416020829408
At time: 687.1221017837524 and batch: 500, loss is 3.8468205881118775 and perplexity is 46.84389019460668
At time: 688.288985490799 and batch: 550, loss is 3.8203694343566896 and perplexity is 45.6210591946663
At time: 689.451854467392 and batch: 600, loss is 3.784912462234497 and perplexity is 44.03181594326146
At time: 690.6562607288361 and batch: 650, loss is 3.8003809452056885 and perplexity is 44.718216439135226
At time: 691.821964263916 and batch: 700, loss is 3.827341928482056 and perplexity is 45.94026329305199
At time: 692.9859945774078 and batch: 750, loss is 3.7823266553878785 and perplexity is 43.91810525242733
At time: 694.1494207382202 and batch: 800, loss is 3.746501798629761 and perplexity is 42.372594563648015
At time: 695.3140637874603 and batch: 850, loss is 3.7390867710113525 and perplexity is 42.05956260926403
At time: 696.4766356945038 and batch: 900, loss is 3.70144100189209 and perplexity is 40.50563101649845
At time: 697.6401550769806 and batch: 950, loss is 3.818019399642944 and perplexity is 45.51397399812854
At time: 698.8044762611389 and batch: 1000, loss is 3.7770664405822756 and perplexity is 43.687693124875885
At time: 699.9689638614655 and batch: 1050, loss is 3.7235763931274413 and perplexity is 41.41223601691923
At time: 701.1322922706604 and batch: 1100, loss is 3.7419680881500246 and perplexity is 42.180924304659676
At time: 702.2971107959747 and batch: 1150, loss is 3.7003599500656126 and perplexity is 40.46186599049834
At time: 703.4612956047058 and batch: 1200, loss is 3.7634434604644778 and perplexity is 43.096572106914195
At time: 704.6251528263092 and batch: 1250, loss is 3.7455745553970337 and perplexity is 42.33332307201195
At time: 705.7887864112854 and batch: 1300, loss is 3.748017177581787 and perplexity is 42.436853777825895
At time: 706.967125415802 and batch: 1350, loss is 3.6061380195617674 and perplexity is 36.82356595979437
At time: 708.1398694515228 and batch: 1400, loss is 3.6412983465194704 and perplexity is 38.14132524870575
At time: 709.3067622184753 and batch: 1450, loss is 3.5551850175857544 and perplexity is 34.99429392855465
At time: 710.4700846672058 and batch: 1500, loss is 3.5459132242202758 and perplexity is 34.67133359067213
At time: 711.6356945037842 and batch: 1550, loss is 3.5624823427200316 and perplexity is 35.25059267950931
At time: 712.7975869178772 and batch: 1600, loss is 3.655356616973877 and perplexity is 38.68131306860499
At time: 713.967221736908 and batch: 1650, loss is 3.5773261308670046 and perplexity is 35.7777478195835
At time: 715.1343247890472 and batch: 1700, loss is 3.5908433866500853 and perplexity is 36.26464815268259
At time: 716.300594329834 and batch: 1750, loss is 3.595982480049133 and perplexity is 36.45149526778721
At time: 717.4640123844147 and batch: 1800, loss is 3.54209246635437 and perplexity is 34.539115567505426
At time: 718.6274263858795 and batch: 1850, loss is 3.568370723724365 and perplexity is 35.458773923553736
At time: 719.791796207428 and batch: 1900, loss is 3.6638395500183107 and perplexity is 39.01083975779357
At time: 720.9567720890045 and batch: 1950, loss is 3.6030925273895265 and perplexity is 36.71159067438518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3691045716751455 and perplexity of 78.97288547165645
finished 15 epochs...
Completing Train Step...
At time: 724.6343460083008 and batch: 50, loss is 3.84483540058136 and perplexity is 46.75098853203268
At time: 725.8012683391571 and batch: 100, loss is 3.820792064666748 and perplexity is 45.64034411196717
At time: 726.9694087505341 and batch: 150, loss is 3.7859702920913696 and perplexity is 44.07841875739693
At time: 728.135899066925 and batch: 200, loss is 3.7856760835647583 and perplexity is 44.06545241825626
At time: 729.3026022911072 and batch: 250, loss is 3.787609872817993 and perplexity is 44.15074816199734
At time: 730.4704093933105 and batch: 300, loss is 3.785557770729065 and perplexity is 44.060239218024876
At time: 731.6385865211487 and batch: 350, loss is 3.822658476829529 and perplexity is 45.725607348751176
At time: 732.80428647995 and batch: 400, loss is 3.7969181537628174 and perplexity is 44.56363437909182
At time: 733.971298456192 and batch: 450, loss is 3.8329416942596435 and perplexity is 46.19823963668261
At time: 735.1369371414185 and batch: 500, loss is 3.841142659187317 and perplexity is 46.57866758563278
At time: 736.303350687027 and batch: 550, loss is 3.814486360549927 and perplexity is 45.35345507550027
At time: 737.469141960144 and batch: 600, loss is 3.7795978879928587 and perplexity is 43.798426321008904
At time: 738.6355068683624 and batch: 650, loss is 3.7954737091064454 and perplexity is 44.49931114240596
At time: 739.8016653060913 and batch: 700, loss is 3.82284526348114 and perplexity is 45.734149079556545
At time: 740.9687638282776 and batch: 750, loss is 3.7782180881500245 and perplexity is 43.73803493285007
At time: 742.1360170841217 and batch: 800, loss is 3.742656259536743 and perplexity is 42.20996200014109
At time: 743.3025786876678 and batch: 850, loss is 3.7353738355636597 and perplexity is 41.90368772410368
At time: 744.4684801101685 and batch: 900, loss is 3.69814368724823 and perplexity is 40.37229115873081
At time: 745.6349942684174 and batch: 950, loss is 3.8146285152435304 and perplexity is 45.35990274028244
At time: 746.8013033866882 and batch: 1000, loss is 3.7740140914916993 and perplexity is 43.55454634310146
At time: 748.0107524394989 and batch: 1050, loss is 3.720681586265564 and perplexity is 41.292528939960164
At time: 749.1759114265442 and batch: 1100, loss is 3.7393685722351075 and perplexity is 42.07141671565032
At time: 750.3419065475464 and batch: 1150, loss is 3.698135676383972 and perplexity is 40.37196774308199
At time: 751.5094723701477 and batch: 1200, loss is 3.761318874359131 and perplexity is 43.0051069258593
At time: 752.6765804290771 and batch: 1250, loss is 3.743852481842041 and perplexity is 42.26048471036327
At time: 753.8419053554535 and batch: 1300, loss is 3.7465088748931885 and perplexity is 42.37289440435014
At time: 755.008588552475 and batch: 1350, loss is 3.604802341461182 and perplexity is 36.77441436182027
At time: 756.1756384372711 and batch: 1400, loss is 3.6403221464157105 and perplexity is 38.104109850833474
At time: 757.3416695594788 and batch: 1450, loss is 3.554732503890991 and perplexity is 34.97846211364009
At time: 758.5072948932648 and batch: 1500, loss is 3.5459789657592773 and perplexity is 34.67361301242714
At time: 759.67365026474 and batch: 1550, loss is 3.562822723388672 and perplexity is 35.26259334209644
At time: 760.8478527069092 and batch: 1600, loss is 3.6559759330749513 and perplexity is 38.70527644828657
At time: 762.0140523910522 and batch: 1650, loss is 3.5782383108139038 and perplexity is 35.81039845305232
At time: 763.184070110321 and batch: 1700, loss is 3.592101607322693 and perplexity is 36.310305800347756
At time: 764.3527896404266 and batch: 1750, loss is 3.597792615890503 and perplexity is 36.51753718022663
At time: 765.5187544822693 and batch: 1800, loss is 3.5439068698883056 and perplexity is 34.60184034767371
At time: 766.685877084732 and batch: 1850, loss is 3.5705100107192993 and perplexity is 35.53471161476127
At time: 767.8520085811615 and batch: 1900, loss is 3.6661195039749144 and perplexity is 39.099884146230174
At time: 769.0186982154846 and batch: 1950, loss is 3.6051696586608886 and perplexity is 36.78792471786568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368811886809593 and perplexity of 78.94977468554352
finished 16 epochs...
Completing Train Step...
At time: 772.6931259632111 and batch: 50, loss is 3.8440295362472536 and perplexity is 46.713328754164486
At time: 773.8618636131287 and batch: 100, loss is 3.819125385284424 and perplexity is 45.5643396465652
At time: 775.0293526649475 and batch: 150, loss is 3.783714051246643 and perplexity is 43.97907933759539
At time: 776.192342042923 and batch: 200, loss is 3.7827703189849853 and perplexity is 43.937594439983584
At time: 777.3796401023865 and batch: 250, loss is 3.7843281602859498 and perplexity is 44.00609558236799
At time: 778.5505340099335 and batch: 300, loss is 3.782056803703308 and perplexity is 43.906255476654714
At time: 779.7159059047699 and batch: 350, loss is 3.8191572713851927 and perplexity is 45.56579253885404
At time: 780.8817405700684 and batch: 400, loss is 3.793267345428467 and perplexity is 44.40123771121991
At time: 782.047550201416 and batch: 450, loss is 3.8290989542007448 and perplexity is 46.02105247072876
At time: 783.2111706733704 and batch: 500, loss is 3.8372571849823 and perplexity is 46.398038516264606
At time: 784.3831973075867 and batch: 550, loss is 3.8105142068862916 and perplexity is 45.17366150301103
At time: 785.5713527202606 and batch: 600, loss is 3.7759829902648927 and perplexity is 43.640385312354006
At time: 786.7538964748383 and batch: 650, loss is 3.792110242843628 and perplexity is 44.34989063693939
At time: 787.9194107055664 and batch: 700, loss is 3.819781765937805 and perplexity is 45.594257015110124
At time: 789.0853998661041 and batch: 750, loss is 3.7754338073730467 and perplexity is 43.61642533915278
At time: 790.2504091262817 and batch: 800, loss is 3.7400162601470948 and perplexity is 42.0986746900746
At time: 791.4152984619141 and batch: 850, loss is 3.732789616584778 and perplexity is 41.79553921889809
At time: 792.5810918807983 and batch: 900, loss is 3.695842580795288 and perplexity is 40.27949702456199
At time: 793.7468478679657 and batch: 950, loss is 3.812348666191101 and perplexity is 45.2566068033156
At time: 794.9132630825043 and batch: 1000, loss is 3.771852397918701 and perplexity is 43.46049645034504
At time: 796.0794086456299 and batch: 1050, loss is 3.7186571979522705 and perplexity is 41.20902138132952
At time: 797.2449493408203 and batch: 1100, loss is 3.737502627372742 and perplexity is 41.992986967326345
At time: 798.4113442897797 and batch: 1150, loss is 3.696509699821472 and perplexity is 40.30637720853636
At time: 799.5772881507874 and batch: 1200, loss is 3.7597257804870607 and perplexity is 42.93665029694428
At time: 800.7421724796295 and batch: 1250, loss is 3.742485566139221 and perplexity is 42.20275765320274
At time: 801.9076204299927 and batch: 1300, loss is 3.7452194499969482 and perplexity is 42.31829294918235
At time: 803.0728175640106 and batch: 1350, loss is 3.603584051132202 and perplexity is 36.7296397282389
At time: 804.2392463684082 and batch: 1400, loss is 3.6393241405487062 and perplexity is 38.0661006954802
At time: 805.4034061431885 and batch: 1450, loss is 3.554069972038269 and perplexity is 34.95529544350643
At time: 806.5703959465027 and batch: 1500, loss is 3.545725493431091 and perplexity is 34.66482532477512
At time: 807.737407207489 and batch: 1550, loss is 3.5627625036239623 and perplexity is 35.260469900959535
At time: 808.9034905433655 and batch: 1600, loss is 3.656086916923523 and perplexity is 38.70957234721012
At time: 810.0681517124176 and batch: 1650, loss is 3.5786209869384766 and perplexity is 35.82410485994181
At time: 811.2341403961182 and batch: 1700, loss is 3.592669324874878 and perplexity is 36.330925650847526
At time: 812.3989453315735 and batch: 1750, loss is 3.598683223724365 and perplexity is 36.55007447174538
At time: 813.5653388500214 and batch: 1800, loss is 3.5447964239120484 and perplexity is 34.632634248372405
At time: 814.7310378551483 and batch: 1850, loss is 3.5715937757492067 and perplexity is 35.57324376868618
At time: 815.8962423801422 and batch: 1900, loss is 3.6671663236618044 and perplexity is 39.14083610562852
At time: 817.0617470741272 and batch: 1950, loss is 3.606084427833557 and perplexity is 36.82159257413477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368705430141715 and perplexity of 78.94137040295472
finished 17 epochs...
Completing Train Step...
At time: 820.7324986457825 and batch: 50, loss is 3.842706866264343 and perplexity is 46.65158327986399
At time: 821.8977620601654 and batch: 100, loss is 3.8172508478164673 and perplexity is 45.4790075887521
At time: 823.0631468296051 and batch: 150, loss is 3.7815121173858643 and perplexity is 43.882346851987855
At time: 824.2298898696899 and batch: 200, loss is 3.780208582878113 and perplexity is 43.82518196488122
At time: 825.3970499038696 and batch: 250, loss is 3.781533784866333 and perplexity is 43.883297682182196
At time: 826.5648052692413 and batch: 300, loss is 3.7790852689743044 and perplexity is 43.77598016834791
At time: 827.7326567173004 and batch: 350, loss is 3.8162354898452757 and perplexity is 45.43285355127512
At time: 828.9014530181885 and batch: 400, loss is 3.7902932929992676 and perplexity is 44.26938227202832
At time: 830.0684242248535 and batch: 450, loss is 3.8260729360580443 and perplexity is 45.88200242109691
At time: 831.236341714859 and batch: 500, loss is 3.834205069541931 and perplexity is 46.25664223515635
At time: 832.4027631282806 and batch: 550, loss is 3.8074090385437014 and perplexity is 45.033607237962435
At time: 833.5688581466675 and batch: 600, loss is 3.7731169414520265 and perplexity is 43.51548890293352
At time: 834.7374002933502 and batch: 650, loss is 3.789419708251953 and perplexity is 44.23072610208104
At time: 835.9263486862183 and batch: 700, loss is 3.817306318283081 and perplexity is 45.48153040049431
At time: 837.0929310321808 and batch: 750, loss is 3.7731640577316283 and perplexity is 43.51753923917741
At time: 838.2616987228394 and batch: 800, loss is 3.737859148979187 and perplexity is 42.007961043631624
At time: 839.428591966629 and batch: 850, loss is 3.730669240951538 and perplexity is 41.70701086581016
At time: 840.5954239368439 and batch: 900, loss is 3.693923487663269 and perplexity is 40.202271044086764
At time: 841.7612807750702 and batch: 950, loss is 3.8104847717285155 and perplexity is 45.172331828727046
At time: 842.9287767410278 and batch: 1000, loss is 3.770031800270081 and perplexity is 43.38144435556395
At time: 844.095787525177 and batch: 1050, loss is 3.716974129676819 and perplexity is 41.13972211883409
At time: 845.2629852294922 and batch: 1100, loss is 3.735915994644165 and perplexity is 41.926412348534086
At time: 846.4305584430695 and batch: 1150, loss is 3.6950996017456053 and perplexity is 40.24958131688917
At time: 847.5995166301727 and batch: 1200, loss is 3.7583244323730467 and perplexity is 42.87652324233554
At time: 848.7662608623505 and batch: 1250, loss is 3.7412456369400022 and perplexity is 42.15046165007171
At time: 849.9354205131531 and batch: 1300, loss is 3.7440189123153687 and perplexity is 42.267518728157896
At time: 851.1027483940125 and batch: 1350, loss is 3.6024271059036255 and perplexity is 36.68717011905104
At time: 852.2691330909729 and batch: 1400, loss is 3.6383272123336794 and perplexity is 38.02817043567539
At time: 853.4357850551605 and batch: 1450, loss is 3.553320527076721 and perplexity is 34.929108187636075
At time: 854.6033890247345 and batch: 1500, loss is 3.5453048658370974 and perplexity is 34.65024740885434
At time: 855.7706613540649 and batch: 1550, loss is 3.56248770236969 and perplexity is 35.25078161084262
At time: 856.936936378479 and batch: 1600, loss is 3.6559359884262084 and perplexity is 38.70373041049252
At time: 858.10156083107 and batch: 1650, loss is 3.5787019443511965 and perplexity is 35.82700520418488
At time: 859.2686371803284 and batch: 1700, loss is 3.5928670740127564 and perplexity is 36.338110770475495
At time: 860.4384624958038 and batch: 1750, loss is 3.5990987968444825 and perplexity is 36.56526685678891
At time: 861.604362487793 and batch: 1800, loss is 3.5452089977264403 and perplexity is 34.64692571432629
At time: 862.7695989608765 and batch: 1850, loss is 3.5721463060379026 and perplexity is 35.59290449440859
At time: 863.9359877109528 and batch: 1900, loss is 3.667635130882263 and perplexity is 39.159189914072435
At time: 865.1036441326141 and batch: 1950, loss is 3.606446762084961 and perplexity is 36.834936715689395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368693790879361 and perplexity of 78.94045158898112
finished 18 epochs...
Completing Train Step...
At time: 868.7568168640137 and batch: 50, loss is 3.8411996841430662 and perplexity is 46.58132380782548
At time: 869.9430341720581 and batch: 100, loss is 3.815351800918579 and perplexity is 45.39272277585609
At time: 871.1082201004028 and batch: 150, loss is 3.7794097900390624 and perplexity is 43.79018870140241
At time: 872.2729709148407 and batch: 200, loss is 3.777878203392029 and perplexity is 43.72317156749047
At time: 873.4362227916718 and batch: 250, loss is 3.7790485715866087 and perplexity is 43.77437373370807
At time: 874.6098930835724 and batch: 300, loss is 3.7764607667922974 and perplexity is 43.66124064580082
At time: 875.7848744392395 and batch: 350, loss is 3.813669662475586 and perplexity is 45.31643011723942
At time: 876.9569358825684 and batch: 400, loss is 3.787707362174988 and perplexity is 44.15505259986152
At time: 878.1208543777466 and batch: 450, loss is 3.823500003814697 and perplexity is 45.76410287648928
At time: 879.2860481739044 and batch: 500, loss is 3.8316037940979 and perplexity is 46.136472332856826
At time: 880.4510250091553 and batch: 550, loss is 3.8047664403915404 and perplexity is 44.91475861442993
At time: 881.6164577007294 and batch: 600, loss is 3.7706472730636595 and perplexity is 43.40815267258909
At time: 882.7820992469788 and batch: 650, loss is 3.7870848417282104 and perplexity is 44.12757373075591
At time: 883.9445512294769 and batch: 700, loss is 3.8151303815841673 and perplexity is 45.38267306203345
At time: 885.1070086956024 and batch: 750, loss is 3.7711449003219606 and perplexity is 43.42975912812621
At time: 886.271270275116 and batch: 800, loss is 3.735942535400391 and perplexity is 41.927525121990506
At time: 887.4417903423309 and batch: 850, loss is 3.728786644935608 and perplexity is 41.62856727528144
At time: 888.6220507621765 and batch: 900, loss is 3.6921887969970704 and perplexity is 40.132592992152404
At time: 889.7856132984161 and batch: 950, loss is 3.808818063735962 and perplexity is 45.09710544984367
At time: 890.9496870040894 and batch: 1000, loss is 3.7683761978149413 and perplexity is 43.309681351676076
At time: 892.1114468574524 and batch: 1050, loss is 3.7154593229293824 and perplexity is 41.077450566771994
At time: 893.297559261322 and batch: 1100, loss is 3.7344637537002563 and perplexity is 41.865569285976825
At time: 894.463808298111 and batch: 1150, loss is 3.6937889528274535 and perplexity is 40.196862801959064
At time: 895.6284236907959 and batch: 1200, loss is 3.7570124530792235 and perplexity is 42.82030701697599
At time: 896.7916173934937 and batch: 1250, loss is 3.740064778327942 and perplexity is 42.100717290737876
At time: 897.9547572135925 and batch: 1300, loss is 3.7428677177429197 and perplexity is 42.21888858675516
At time: 899.1178879737854 and batch: 1350, loss is 3.601309633255005 and perplexity is 36.64619610781998
At time: 900.2812530994415 and batch: 1400, loss is 3.6373390483856203 and perplexity is 37.99061092917163
At time: 901.4446973800659 and batch: 1450, loss is 3.5525327253341676 and perplexity is 34.901601811548126
At time: 902.6100287437439 and batch: 1500, loss is 3.544785509109497 and perplexity is 34.63225624207068
At time: 903.7735543251038 and batch: 1550, loss is 3.5620834589004517 and perplexity is 35.23653459241699
At time: 904.935129404068 and batch: 1600, loss is 3.655637664794922 and perplexity is 38.69218589517861
At time: 906.0976259708405 and batch: 1650, loss is 3.5785969257354737 and perplexity is 35.82324289925233
At time: 907.2615044116974 and batch: 1700, loss is 3.5928475046157837 and perplexity is 36.33739966251859
At time: 908.4269418716431 and batch: 1750, loss is 3.599244589805603 and perplexity is 36.570598203945124
At time: 909.5911455154419 and batch: 1800, loss is 3.5453514432907105 and perplexity is 34.65186136673244
At time: 910.7561750411987 and batch: 1850, loss is 3.572402868270874 and perplexity is 35.60203746100068
At time: 911.921293258667 and batch: 1900, loss is 3.6678006267547607 and perplexity is 39.165671134666404
At time: 913.0855555534363 and batch: 1950, loss is 3.606521897315979 and perplexity is 36.83770442114386
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3687482966933135 and perplexity of 78.94475441981237
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 916.7398526668549 and batch: 50, loss is 3.840807099342346 and perplexity is 46.56304027725404
At time: 917.930046081543 and batch: 100, loss is 3.8164312124252318 and perplexity is 45.44174665684933
At time: 919.0958125591278 and batch: 150, loss is 3.78112998008728 and perplexity is 43.86558097414397
At time: 920.262323141098 and batch: 200, loss is 3.7796947717666627 and perplexity is 43.80266988340041
At time: 921.4296958446503 and batch: 250, loss is 3.780551166534424 and perplexity is 43.84019832799068
At time: 922.6182994842529 and batch: 300, loss is 3.7771200561523437 and perplexity is 43.69003552824182
At time: 923.7843189239502 and batch: 350, loss is 3.814802131652832 and perplexity is 45.36777864739605
At time: 924.9509086608887 and batch: 400, loss is 3.790906882286072 and perplexity is 44.29655382595859
At time: 926.1165516376495 and batch: 450, loss is 3.8281787252426147 and perplexity is 45.97872204539037
At time: 927.2823739051819 and batch: 500, loss is 3.836820502281189 and perplexity is 46.37778171869752
At time: 928.4491007328033 and batch: 550, loss is 3.8109485292434693 and perplexity is 45.19328569546164
At time: 929.6152830123901 and batch: 600, loss is 3.7757886409759522 and perplexity is 43.63190465863067
At time: 930.7811012268066 and batch: 650, loss is 3.7906665134429933 and perplexity is 44.28590759412555
At time: 931.9477691650391 and batch: 700, loss is 3.818542232513428 and perplexity is 45.537776421603596
At time: 933.1126549243927 and batch: 750, loss is 3.775328559875488 and perplexity is 43.611835061095256
At time: 934.2801399230957 and batch: 800, loss is 3.7400558376312256 and perplexity is 42.10034088267572
At time: 935.4514305591583 and batch: 850, loss is 3.7337889289855957 and perplexity is 41.83732689553262
At time: 936.6187806129456 and batch: 900, loss is 3.695904226303101 and perplexity is 40.28198015114652
At time: 937.7849340438843 and batch: 950, loss is 3.814282784461975 and perplexity is 45.34422313627382
At time: 938.9517867565155 and batch: 1000, loss is 3.7729914951324464 and perplexity is 43.51003038738842
At time: 940.1175451278687 and batch: 1050, loss is 3.719853096008301 and perplexity is 41.258332649638355
At time: 941.2849051952362 and batch: 1100, loss is 3.737861328125 and perplexity is 42.00805258520379
At time: 942.4500887393951 and batch: 1150, loss is 3.6957647228240966 and perplexity is 40.276361066724284
At time: 943.6160020828247 and batch: 1200, loss is 3.758688416481018 and perplexity is 42.892132455981326
At time: 944.783168554306 and batch: 1250, loss is 3.739225730895996 and perplexity is 42.06540760733309
At time: 945.9492921829224 and batch: 1300, loss is 3.741231932640076 and perplexity is 42.149884011461296
At time: 947.1159067153931 and batch: 1350, loss is 3.5962090826034547 and perplexity is 36.4597562056632
At time: 948.2806038856506 and batch: 1400, loss is 3.6312831258773803 and perplexity is 37.761237966792045
At time: 949.447075843811 and batch: 1450, loss is 3.5460046243667604 and perplexity is 34.67450270046748
At time: 950.6137628555298 and batch: 1500, loss is 3.5386873626708986 and perplexity is 34.42170630666
At time: 951.7788496017456 and batch: 1550, loss is 3.557437553405762 and perplexity is 35.07320867490378
At time: 952.9440588951111 and batch: 1600, loss is 3.6513710165023805 and perplexity is 38.52745162779035
At time: 954.1104755401611 and batch: 1650, loss is 3.57397331237793 and perplexity is 35.657992396479706
At time: 955.2858328819275 and batch: 1700, loss is 3.5881701040267946 and perplexity is 36.1678319651098
At time: 956.4518358707428 and batch: 1750, loss is 3.5945421504974364 and perplexity is 36.39903089401346
At time: 957.6189720630646 and batch: 1800, loss is 3.5407305335998536 and perplexity is 34.49210763279111
At time: 958.7852599620819 and batch: 1850, loss is 3.5672179651260376 and perplexity is 35.41792206771508
At time: 959.9509568214417 and batch: 1900, loss is 3.661081829071045 and perplexity is 38.903406950760015
At time: 961.1179633140564 and batch: 1950, loss is 3.6016883277893066 and perplexity is 36.660076450027944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3682858489280525 and perplexity of 78.90825503473185
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f1288f88b38>
ELAPSED
1981.847573518753


RESULTS SO FAR:
[{'best_accuracy': -78.41160778879484, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}}, {'best_accuracy': -78.90825503473185, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.10008266219030648, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.21726970941698143, 'batch_size': 32}}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.6593070000175439, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.4915447901082358, 'batch_size': 32}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6692135334014893 and batch: 50, loss is 7.392211399078369 and perplexity is 1623.2918928730007
At time: 2.888793706893921 and batch: 100, loss is 6.6057501220703125 and perplexity is 739.3342521981535
At time: 4.10672664642334 and batch: 150, loss is 6.293202104568482 and perplexity is 540.8825214727211
At time: 5.325584411621094 and batch: 200, loss is 6.192063617706299 and perplexity is 488.8538735427917
At time: 6.5469279289245605 and batch: 250, loss is 6.115773363113403 and perplexity is 452.94620384110016
At time: 7.767431974411011 and batch: 300, loss is 6.056805534362793 and perplexity is 427.0091896231751
At time: 8.987553596496582 and batch: 350, loss is 5.996957712173462 and perplexity is 402.20331206423793
At time: 10.206594944000244 and batch: 400, loss is 5.941534547805786 and perplexity is 380.51840542192565
At time: 11.42496395111084 and batch: 450, loss is 5.87889497756958 and perplexity is 357.41407284639195
At time: 12.669451475143433 and batch: 500, loss is 5.859103593826294 and perplexity is 350.4098936009969
At time: 13.889201641082764 and batch: 550, loss is 5.805167579650879 and perplexity is 332.010826940354
At time: 15.109033823013306 and batch: 600, loss is 5.837010459899902 and perplexity is 342.753133248872
At time: 16.340644598007202 and batch: 650, loss is 5.92336407661438 and perplexity is 373.66664507259384
At time: 17.57351589202881 and batch: 700, loss is 5.821266784667968 and perplexity is 337.39919515218827
At time: 18.80799102783203 and batch: 750, loss is 5.766492681503296 and perplexity is 319.41547393854944
At time: 20.04225254058838 and batch: 800, loss is 5.772627267837525 and perplexity is 321.38097835417176
At time: 21.27659821510315 and batch: 850, loss is 5.803197889328003 and perplexity is 331.35751205266655
At time: 22.50975775718689 and batch: 900, loss is 5.798915405273437 and perplexity is 329.94151295180467
At time: 23.744199991226196 and batch: 950, loss is 5.8220359897613525 and perplexity is 337.6588241727842
At time: 24.97782063484192 and batch: 1000, loss is 5.799827280044556 and perplexity is 330.24251551087275
At time: 26.21312713623047 and batch: 1050, loss is 5.697198991775513 and perplexity is 298.0314422291235
At time: 27.447111129760742 and batch: 1100, loss is 5.78578519821167 and perplexity is 325.63762983980456
At time: 28.681050539016724 and batch: 1150, loss is 5.702354173660279 and perplexity is 299.57181556214573
At time: 29.914915084838867 and batch: 1200, loss is 5.779228973388672 and perplexity is 323.50965967555186
At time: 31.14905047416687 and batch: 1250, loss is 5.711942558288574 and perplexity is 302.4580403577185
At time: 32.382750511169434 and batch: 1300, loss is 5.725595273971558 and perplexity is 306.61573129344004
At time: 33.615742921829224 and batch: 1350, loss is 5.69624701499939 and perplexity is 297.7478582216783
At time: 34.8505597114563 and batch: 1400, loss is 5.720039529800415 and perplexity is 304.91697602588476
At time: 36.0849084854126 and batch: 1450, loss is 5.683571567535401 and perplexity is 293.99758926771915
At time: 37.31899833679199 and batch: 1500, loss is 5.663570661544799 and perplexity is 288.1757858709309
At time: 38.55298829078674 and batch: 1550, loss is 5.644295644760132 and perplexity is 282.6743829038554
At time: 39.78771638870239 and batch: 1600, loss is 5.666417655944824 and perplexity is 288.99738971534947
At time: 41.02178072929382 and batch: 1650, loss is 5.645349807739258 and perplexity is 282.9725248909732
At time: 42.25748419761658 and batch: 1700, loss is 5.656188840866089 and perplexity is 286.0563561449682
At time: 43.4914448261261 and batch: 1750, loss is 5.671468782424927 and perplexity is 290.4608450206099
At time: 44.72445893287659 and batch: 1800, loss is 5.667199392318725 and perplexity is 289.22339781471885
At time: 45.957412004470825 and batch: 1850, loss is 5.639921569824219 and perplexity is 281.44064417045144
At time: 47.189364433288574 and batch: 1900, loss is 5.627252750396728 and perplexity is 277.8976138630984
At time: 48.42390489578247 and batch: 1950, loss is 5.570647201538086 and perplexity is 262.6040019676761
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.104057276526163 and perplexity of 164.68874138454856
finished 1 epochs...
Completing Train Step...
At time: 52.09781074523926 and batch: 50, loss is 5.363793926239014 and perplexity is 213.5335421118225
At time: 53.28746509552002 and batch: 100, loss is 5.290324678421021 and perplexity is 198.40783369498737
At time: 54.45111966133118 and batch: 150, loss is 5.193892250061035 and perplexity is 180.16845062275237
At time: 55.61435413360596 and batch: 200, loss is 5.162454147338867 and perplexity is 174.59240575192666
At time: 56.77702856063843 and batch: 250, loss is 5.15918981552124 and perplexity is 174.02340741167177
At time: 57.94025540351868 and batch: 300, loss is 5.167190208435058 and perplexity is 175.42124722516576
At time: 59.102649450302124 and batch: 350, loss is 5.14100359916687 and perplexity is 170.88718452637437
At time: 60.266008138656616 and batch: 400, loss is 5.101162347793579 and perplexity is 164.21266864598792
At time: 61.42964267730713 and batch: 450, loss is 5.0586452293396 and perplexity is 157.37716187130334
At time: 62.593348264694214 and batch: 500, loss is 5.046368827819824 and perplexity is 155.45694742016985
At time: 63.75722074508667 and batch: 550, loss is 4.998997974395752 and perplexity is 148.2645197997789
At time: 64.92133045196533 and batch: 600, loss is 4.991773366928101 and perplexity is 147.19722687134748
At time: 66.08521318435669 and batch: 650, loss is 5.051441640853882 and perplexity is 156.24755505621818
At time: 67.25008463859558 and batch: 700, loss is 5.033041620254517 and perplexity is 153.39888498874913
At time: 68.41419124603271 and batch: 750, loss is 4.976998996734619 and perplexity is 145.03846697707678
At time: 69.57843518257141 and batch: 800, loss is 4.95706729888916 and perplexity is 142.17622352013558
At time: 70.74309992790222 and batch: 850, loss is 4.958243799209595 and perplexity is 142.34359232808802
At time: 71.9055905342102 and batch: 900, loss is 4.977169437408447 and perplexity is 145.06318953792442
At time: 73.06718254089355 and batch: 950, loss is 5.031852979660034 and perplexity is 153.21665717004973
At time: 74.22906684875488 and batch: 1000, loss is 4.993511047363281 and perplexity is 147.45323097483788
At time: 75.39351511001587 and batch: 1050, loss is 4.902187004089355 and perplexity is 134.5837933696418
At time: 76.55452871322632 and batch: 1100, loss is 4.981317596435547 and perplexity is 145.66618451197297
At time: 77.72046184539795 and batch: 1150, loss is 4.896366415023803 and perplexity is 133.8027117961909
At time: 78.88378930091858 and batch: 1200, loss is 4.9660383987426755 and perplexity is 143.45743898130743
At time: 80.04745364189148 and batch: 1250, loss is 4.91273717880249 and perplexity is 136.01119231755433
At time: 81.21128439903259 and batch: 1300, loss is 4.94143985748291 and perplexity is 139.97164375439505
At time: 82.37423133850098 and batch: 1350, loss is 4.858184642791748 and perplexity is 128.79018956448806
At time: 83.53677082061768 and batch: 1400, loss is 4.870369901657105 and perplexity is 130.36913173639908
At time: 84.70019221305847 and batch: 1450, loss is 4.815184020996094 and perplexity is 123.36951280206436
At time: 85.86752796173096 and batch: 1500, loss is 4.787210016250611 and perplexity is 119.96619757797089
At time: 87.0314393043518 and batch: 1550, loss is 4.780441942214966 and perplexity is 119.15699891810769
At time: 88.19447040557861 and batch: 1600, loss is 4.850315294265747 and perplexity is 127.78067200848531
At time: 89.35636639595032 and batch: 1650, loss is 4.80785834312439 and perplexity is 122.46904977012488
At time: 90.51942205429077 and batch: 1700, loss is 4.835490627288818 and perplexity is 125.9003381978835
At time: 91.68327164649963 and batch: 1750, loss is 4.847413005828858 and perplexity is 127.41035328746956
At time: 92.84868836402893 and batch: 1800, loss is 4.7922797203063965 and perplexity is 120.57593498454044
At time: 94.01294612884521 and batch: 1850, loss is 4.804886503219604 and perplexity is 122.10563163864015
At time: 95.18752360343933 and batch: 1900, loss is 4.866057319641113 and perplexity is 129.80811474881747
At time: 96.35825490951538 and batch: 1950, loss is 4.785168027877807 and perplexity is 119.72147793974945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.656116574309593 and perplexity of 105.2266477998845
finished 2 epochs...
Completing Train Step...
At time: 99.98983955383301 and batch: 50, loss is 4.728738145828247 and perplexity is 113.15269003164143
At time: 101.20380854606628 and batch: 100, loss is 4.678164367675781 and perplexity is 107.57242779966863
At time: 102.37021207809448 and batch: 150, loss is 4.6196005916595455 and perplexity is 101.45350266104938
At time: 103.53665494918823 and batch: 200, loss is 4.612584457397461 and perplexity is 100.7441825174572
At time: 104.70365715026855 and batch: 250, loss is 4.614719505310059 and perplexity is 100.95950595518084
At time: 105.86899065971375 and batch: 300, loss is 4.639937524795532 and perplexity is 103.5378788310647
At time: 107.03575563430786 and batch: 350, loss is 4.650966310501099 and perplexity is 104.68609599109433
At time: 108.20275664329529 and batch: 400, loss is 4.6213623142242435 and perplexity is 101.63239311736373
At time: 109.36950516700745 and batch: 450, loss is 4.617314100265503 and perplexity is 101.22179509993971
At time: 110.53638529777527 and batch: 500, loss is 4.616853141784668 and perplexity is 101.17514680733214
At time: 111.73323559761047 and batch: 550, loss is 4.570676040649414 and perplexity is 96.60939958230858
At time: 112.89897036552429 and batch: 600, loss is 4.5489546489715575 and perplexity is 94.53353591675328
At time: 114.06569814682007 and batch: 650, loss is 4.606842918395996 and perplexity is 100.16741322051455
At time: 115.23173069953918 and batch: 700, loss is 4.626341867446899 and perplexity is 102.13973915799984
At time: 116.3976559638977 and batch: 750, loss is 4.583194856643677 and perplexity is 97.82643691768298
At time: 117.57232570648193 and batch: 800, loss is 4.558094081878662 and perplexity is 95.4014790381548
At time: 118.74068999290466 and batch: 850, loss is 4.566306743621826 and perplexity is 96.18820525152164
At time: 119.90688228607178 and batch: 900, loss is 4.563539876937866 and perplexity is 95.92243315854867
At time: 121.07695031166077 and batch: 950, loss is 4.6317175769805905 and perplexity is 102.69029120567392
At time: 122.24288034439087 and batch: 1000, loss is 4.6075340843200685 and perplexity is 100.23666945425241
At time: 123.40951037406921 and batch: 1050, loss is 4.534698839187622 and perplexity is 93.1954442619832
At time: 124.5766749382019 and batch: 1100, loss is 4.601888637542725 and perplexity is 99.672382994997
At time: 125.74405837059021 and batch: 1150, loss is 4.536203231811523 and perplexity is 93.33575231364904
At time: 126.9123523235321 and batch: 1200, loss is 4.611768350601197 and perplexity is 100.66199804563503
At time: 128.08456587791443 and batch: 1250, loss is 4.573102025985718 and perplexity is 96.84405709179505
At time: 129.25118708610535 and batch: 1300, loss is 4.593811521530151 and perplexity is 98.87056016154594
At time: 130.41898250579834 and batch: 1350, loss is 4.483825044631958 and perplexity is 88.57282053977255
At time: 131.58510088920593 and batch: 1400, loss is 4.503391695022583 and perplexity is 90.32296030287584
At time: 132.75044012069702 and batch: 1450, loss is 4.44172025680542 and perplexity is 84.92090185267216
At time: 133.91760516166687 and batch: 1500, loss is 4.434678030014038 and perplexity is 84.324970407523
At time: 135.0846836566925 and batch: 1550, loss is 4.426980800628662 and perplexity is 83.67839338553561
At time: 136.25113344192505 and batch: 1600, loss is 4.521192922592163 and perplexity is 91.94521610772186
At time: 137.41963386535645 and batch: 1650, loss is 4.471464776992798 and perplexity is 87.484774892305
At time: 138.58655524253845 and batch: 1700, loss is 4.509115629196167 and perplexity is 90.84144545383818
At time: 139.7542064189911 and batch: 1750, loss is 4.517547950744629 and perplexity is 91.61068842585793
At time: 140.9207866191864 and batch: 1800, loss is 4.450629043579101 and perplexity is 85.68082402618812
At time: 142.08774185180664 and batch: 1850, loss is 4.480518093109131 and perplexity is 88.28039829559266
At time: 143.2547528743744 and batch: 1900, loss is 4.559204139709473 and perplexity is 95.5074389969925
At time: 144.4226851463318 and batch: 1950, loss is 4.494492502212524 and perplexity is 89.5227248699265
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.531099257358285 and perplexity of 92.86058267664615
finished 3 epochs...
Completing Train Step...
At time: 148.08450865745544 and batch: 50, loss is 4.44478967666626 and perplexity is 85.18196019929631
At time: 149.2509274482727 and batch: 100, loss is 4.3996447086334225 and perplexity is 81.42193501477364
At time: 150.41743993759155 and batch: 150, loss is 4.345251426696778 and perplexity is 77.11142291253901
At time: 151.58302187919617 and batch: 200, loss is 4.345328130722046 and perplexity is 77.11733789591919
At time: 152.74889945983887 and batch: 250, loss is 4.34459529876709 and perplexity is 77.06084454902114
At time: 153.91486859321594 and batch: 300, loss is 4.371393804550171 and perplexity is 79.15387988745411
At time: 155.08090496063232 and batch: 350, loss is 4.385358572006226 and perplexity is 80.26699955246107
At time: 156.2465260028839 and batch: 400, loss is 4.35388180732727 and perplexity is 77.77980388572949
At time: 157.41241312026978 and batch: 450, loss is 4.368119897842408 and perplexity is 78.8951612106397
At time: 158.57887983322144 and batch: 500, loss is 4.377056999206543 and perplexity is 79.60341541922503
At time: 159.74523186683655 and batch: 550, loss is 4.331504793167114 and perplexity is 76.05865304005897
At time: 160.9126274585724 and batch: 600, loss is 4.306130485534668 and perplexity is 74.15299697746033
At time: 162.07787561416626 and batch: 650, loss is 4.367463598251343 and perplexity is 78.84339933610664
At time: 163.245836019516 and batch: 700, loss is 4.392588129043579 and perplexity is 80.84939710545235
At time: 164.41233038902283 and batch: 750, loss is 4.358636894226074 and perplexity is 78.15053434140044
At time: 165.5795316696167 and batch: 800, loss is 4.329371786117553 and perplexity is 75.89659229674264
At time: 166.74604439735413 and batch: 850, loss is 4.336864986419678 and perplexity is 76.46743671989184
At time: 167.91374564170837 and batch: 900, loss is 4.323151187896729 and perplexity is 75.42593549088357
At time: 169.1225085258484 and batch: 950, loss is 4.4020584869384765 and perplexity is 81.61870690138521
At time: 170.2885925769806 and batch: 1000, loss is 4.383552436828613 and perplexity is 80.12215734264758
At time: 171.4551568031311 and batch: 1050, loss is 4.316732778549194 and perplexity is 74.94337126549087
At time: 172.6209626197815 and batch: 1100, loss is 4.374227313995362 and perplexity is 79.37848120844815
At time: 173.78732562065125 and batch: 1150, loss is 4.313983154296875 and perplexity is 74.73758819701739
At time: 174.95141077041626 and batch: 1200, loss is 4.394441366195679 and perplexity is 80.99936913583917
At time: 176.11720609664917 and batch: 1250, loss is 4.364614524841309 and perplexity is 78.61908839440298
At time: 177.2823555469513 and batch: 1300, loss is 4.375077352523804 and perplexity is 79.4459846620081
At time: 178.44737672805786 and batch: 1350, loss is 4.259501914978028 and perplexity is 70.77472284423173
At time: 179.6235387325287 and batch: 1400, loss is 4.290550217628479 and perplexity is 73.00662698382902
At time: 180.79671597480774 and batch: 1450, loss is 4.217921032905578 and perplexity is 67.8921918363335
At time: 181.9704773426056 and batch: 1500, loss is 4.221554851531982 and perplexity is 68.13934853695909
At time: 183.1399655342102 and batch: 1550, loss is 4.216146235466003 and perplexity is 67.77180381187493
At time: 184.30524516105652 and batch: 1600, loss is 4.316286334991455 and perplexity is 74.90992074763382
At time: 185.47041606903076 and batch: 1650, loss is 4.265481443405151 and perplexity is 71.19919010369644
At time: 186.63924837112427 and batch: 1700, loss is 4.301077747344971 and perplexity is 73.77926627456624
At time: 187.80504775047302 and batch: 1750, loss is 4.309938659667969 and perplexity is 74.43592287608068
At time: 188.97011065483093 and batch: 1800, loss is 4.243949818611145 and perplexity is 69.68254239552215
At time: 190.13555073738098 and batch: 1850, loss is 4.280211610794067 and perplexity is 72.25572848174514
At time: 191.3019618988037 and batch: 1900, loss is 4.364204568862915 and perplexity is 78.58686463471261
At time: 192.46691703796387 and batch: 1950, loss is 4.296063222885132 and perplexity is 73.41022439727382
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.484022699400436 and perplexity of 88.59032911037899
finished 4 epochs...
Completing Train Step...
At time: 196.12477445602417 and batch: 50, loss is 4.2535509538650516 and perplexity is 70.354795944401
At time: 197.29144430160522 and batch: 100, loss is 4.216475720405579 and perplexity is 67.79413727962739
At time: 198.48027539253235 and batch: 150, loss is 4.162705235481262 and perplexity is 64.24508581504739
At time: 199.64589667320251 and batch: 200, loss is 4.165416469573975 and perplexity is 64.41950562161782
At time: 200.81317472457886 and batch: 250, loss is 4.164800176620483 and perplexity is 64.37981656553481
At time: 201.9794144630432 and batch: 300, loss is 4.18990620136261 and perplexity is 66.0165984030124
At time: 203.14698696136475 and batch: 350, loss is 4.205609083175659 and perplexity is 67.06143121901847
At time: 204.31394839286804 and batch: 400, loss is 4.177020506858826 and perplexity is 65.1713859534895
At time: 205.48130989074707 and batch: 450, loss is 4.196870417594909 and perplexity is 66.47795690472753
At time: 206.64925718307495 and batch: 500, loss is 4.206772718429566 and perplexity is 67.139511684343
At time: 207.8153088092804 and batch: 550, loss is 4.165115795135498 and perplexity is 64.40013923457276
At time: 208.98311400413513 and batch: 600, loss is 4.139224367141724 and perplexity is 62.754128403697415
At time: 210.1509828567505 and batch: 650, loss is 4.199318995475769 and perplexity is 66.64093280773754
At time: 211.31907510757446 and batch: 700, loss is 4.226856036186218 and perplexity is 68.50152694490409
At time: 212.48674273490906 and batch: 750, loss is 4.195973844528198 and perplexity is 66.41838126998232
At time: 213.6532106399536 and batch: 800, loss is 4.165352234840393 and perplexity is 64.41536778473457
At time: 214.82082056999207 and batch: 850, loss is 4.171489419937134 and perplexity is 64.81191240912867
At time: 215.9872329235077 and batch: 900, loss is 4.153974223136902 and perplexity is 63.68660278662512
At time: 217.154235124588 and batch: 950, loss is 4.2356755876541134 and perplexity is 69.10835171511276
At time: 218.3193769454956 and batch: 1000, loss is 4.218927278518676 and perplexity is 67.96054243951247
At time: 219.48668932914734 and batch: 1050, loss is 4.165129823684692 and perplexity is 64.40104268143114
At time: 220.65389585494995 and batch: 1100, loss is 4.213201632499695 and perplexity is 67.5725362831986
At time: 221.8215615749359 and batch: 1150, loss is 4.158926720619202 and perplexity is 64.00279284554553
At time: 222.99074983596802 and batch: 1200, loss is 4.239592590332031 and perplexity is 69.37958016835012
At time: 224.15672612190247 and batch: 1250, loss is 4.2097593116760255 and perplexity is 67.34032982829589
At time: 225.32436299324036 and batch: 1300, loss is 4.216989879608154 and perplexity is 67.82900322174478
At time: 226.49048519134521 and batch: 1350, loss is 4.096297221183777 and perplexity is 60.11727399850004
At time: 227.65697574615479 and batch: 1400, loss is 4.134948906898498 and perplexity is 62.48639836500946
At time: 228.8247528076172 and batch: 1450, loss is 4.060089545249939 and perplexity is 57.979502635571045
At time: 229.99156308174133 and batch: 1500, loss is 4.062589073181153 and perplexity is 58.12460529037006
At time: 231.1583981513977 and batch: 1550, loss is 4.066306734085083 and perplexity is 58.34109503139558
At time: 232.32498049736023 and batch: 1600, loss is 4.16546555519104 and perplexity is 64.42266777040966
At time: 233.49187588691711 and batch: 1650, loss is 4.112872424125672 and perplexity is 61.12203406266977
At time: 234.65852761268616 and batch: 1700, loss is 4.148213348388672 and perplexity is 63.32076702360509
At time: 235.82510495185852 and batch: 1750, loss is 4.161605567932129 and perplexity is 64.17447640953672
At time: 236.9913682937622 and batch: 1800, loss is 4.094066934585571 and perplexity is 59.9833446539074
At time: 238.1586320400238 and batch: 1850, loss is 4.134352903366089 and perplexity is 62.44916734686767
At time: 239.32635116577148 and batch: 1900, loss is 4.217866172790528 and perplexity is 67.8884673650417
At time: 240.49447798728943 and batch: 1950, loss is 4.151260204315186 and perplexity is 63.51399049043515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4647125953851745 and perplexity of 86.89605162429329
finished 5 epochs...
Completing Train Step...
At time: 244.16922521591187 and batch: 50, loss is 4.113630638122559 and perplexity is 61.16839521803171
At time: 245.333557844162 and batch: 100, loss is 4.073531575202942 and perplexity is 58.76412650109113
At time: 246.4997591972351 and batch: 150, loss is 4.023340883255005 and perplexity is 55.887507918974634
At time: 247.66334462165833 and batch: 200, loss is 4.030874962806702 and perplexity is 56.310158993771694
At time: 248.82460260391235 and batch: 250, loss is 4.023822298049927 and perplexity is 55.91441946942765
At time: 249.98624348640442 and batch: 300, loss is 4.050409517288208 and perplexity is 57.42096710996585
At time: 251.14891052246094 and batch: 350, loss is 4.061966223716736 and perplexity is 58.08841368322709
At time: 252.31108951568604 and batch: 400, loss is 4.035725317001343 and perplexity is 56.583946656458075
At time: 253.47294402122498 and batch: 450, loss is 4.061436462402344 and perplexity is 58.05764883857508
At time: 254.63509964942932 and batch: 500, loss is 4.076984043121338 and perplexity is 58.9673583865018
At time: 255.79770755767822 and batch: 550, loss is 4.035879654884338 and perplexity is 56.59268037695119
At time: 256.98394322395325 and batch: 600, loss is 4.010151586532593 and perplexity is 55.15523071998343
At time: 258.14698934555054 and batch: 650, loss is 4.062284092903138 and perplexity is 58.106881134985386
At time: 259.3109652996063 and batch: 700, loss is 4.102785205841064 and perplexity is 60.508581977281125
At time: 260.47355699539185 and batch: 750, loss is 4.067831506729126 and perplexity is 58.43011979113406
At time: 261.63677310943604 and batch: 800, loss is 4.03702407836914 and perplexity is 56.657483443445315
At time: 262.79858660697937 and batch: 850, loss is 4.038975172042846 and perplexity is 56.768135412035704
At time: 263.96208906173706 and batch: 900, loss is 4.025081672668457 and perplexity is 55.984881029554685
At time: 265.12450909614563 and batch: 950, loss is 4.11187445640564 and perplexity is 61.061066672496196
At time: 266.28685545921326 and batch: 1000, loss is 4.0945020771026615 and perplexity is 60.009451637200854
At time: 267.4633936882019 and batch: 1050, loss is 4.039439086914062 and perplexity is 56.79447710394342
At time: 268.63410353660583 and batch: 1100, loss is 4.083096103668213 and perplexity is 59.32887412886587
At time: 269.7963035106659 and batch: 1150, loss is 4.0347198963165285 and perplexity is 56.5270845760072
At time: 270.9601032733917 and batch: 1200, loss is 4.116022005081176 and perplexity is 61.31484633665912
At time: 272.1226222515106 and batch: 1250, loss is 4.084643626213074 and perplexity is 59.420757976967586
At time: 273.2840175628662 and batch: 1300, loss is 4.093805904388428 and perplexity is 59.96768923298477
At time: 274.4469110965729 and batch: 1350, loss is 3.975404825210571 and perplexity is 53.27167825952025
At time: 275.6107921600342 and batch: 1400, loss is 4.017529315948487 and perplexity is 55.56365586061676
At time: 276.7743728160858 and batch: 1450, loss is 3.936539430618286 and perplexity is 51.24097119114268
At time: 277.93904757499695 and batch: 1500, loss is 3.937587203979492 and perplexity is 51.2946882524977
At time: 279.10389590263367 and batch: 1550, loss is 3.941836743354797 and perplexity is 51.51313086147446
At time: 280.2697117328644 and batch: 1600, loss is 4.044961333274841 and perplexity is 57.10897777430441
At time: 281.4326984882355 and batch: 1650, loss is 3.9954043006896973 and perplexity is 54.34780903926899
At time: 282.5964767932892 and batch: 1700, loss is 4.02916573047638 and perplexity is 56.21399405701539
At time: 283.7607593536377 and batch: 1750, loss is 4.044617881774903 and perplexity is 57.089366978099314
At time: 284.9260804653168 and batch: 1800, loss is 3.9742556762695314 and perplexity is 53.21049632717008
At time: 286.09091877937317 and batch: 1850, loss is 4.012814812660217 and perplexity is 55.30231734704848
At time: 287.25434041023254 and batch: 1900, loss is 4.099802894592285 and perplexity is 60.32839537242288
At time: 288.41809821128845 and batch: 1950, loss is 4.029563097953797 and perplexity is 56.23633610873774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.467455770803053 and perplexity of 87.1347499830708
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 292.07072925567627 and batch: 50, loss is 4.029898719787598 and perplexity is 56.25521341863029
At time: 293.2599289417267 and batch: 100, loss is 4.017119646072388 and perplexity is 55.54089776657582
At time: 294.4269948005676 and batch: 150, loss is 3.9707600021362306 and perplexity is 53.02481450219728
At time: 295.59330224990845 and batch: 200, loss is 3.988984670639038 and perplexity is 54.000033700047744
At time: 296.7599108219147 and batch: 250, loss is 3.9700634908676147 and perplexity is 52.987894980304304
At time: 297.92573380470276 and batch: 300, loss is 3.99813364982605 and perplexity is 54.49634579706031
At time: 299.09311294555664 and batch: 350, loss is 4.007502398490906 and perplexity is 55.00930751666932
At time: 300.259840965271 and batch: 400, loss is 3.9735384035110473 and perplexity is 53.172343572290785
At time: 301.4261178970337 and batch: 450, loss is 3.98430748462677 and perplexity is 53.748055232204514
At time: 302.59361457824707 and batch: 500, loss is 3.997552556991577 and perplexity is 54.46468756009083
At time: 303.76186299324036 and batch: 550, loss is 3.9483808279037476 and perplexity is 51.85134258126456
At time: 304.92727637290955 and batch: 600, loss is 3.920185751914978 and perplexity is 50.40980762675537
At time: 306.0930197238922 and batch: 650, loss is 3.9656694984436034 and perplexity is 52.755577345942086
At time: 307.260377407074 and batch: 700, loss is 3.9996113872528074 and perplexity is 54.57693661823692
At time: 308.42539739608765 and batch: 750, loss is 3.948215641975403 and perplexity is 51.84277817648341
At time: 309.5901606082916 and batch: 800, loss is 3.9134927558898926 and perplexity is 50.073541553715096
At time: 310.75451493263245 and batch: 850, loss is 3.9058947229385375 and perplexity is 49.69452285667091
At time: 311.9198212623596 and batch: 900, loss is 3.8829218101501466 and perplexity is 48.56590833405748
At time: 313.08295941352844 and batch: 950, loss is 3.9739682149887083 and perplexity is 53.19520256802975
At time: 314.2717230319977 and batch: 1000, loss is 3.942234869003296 and perplexity is 51.5336436431662
At time: 315.43720412254333 and batch: 1050, loss is 3.8810193300247193 and perplexity is 48.473600493436535
At time: 316.6015179157257 and batch: 1100, loss is 3.912078561782837 and perplexity is 50.002777894898685
At time: 317.76573300361633 and batch: 1150, loss is 3.866656193733215 and perplexity is 47.78234375418491
At time: 318.9294993877411 and batch: 1200, loss is 3.926630263328552 and perplexity is 50.73572326289472
At time: 320.0937306880951 and batch: 1250, loss is 3.892921848297119 and perplexity is 49.05400569867092
At time: 321.25745582580566 and batch: 1300, loss is 3.8934536266326902 and perplexity is 49.080098493351024
At time: 322.4209158420563 and batch: 1350, loss is 3.77432252407074 and perplexity is 43.56798205605829
At time: 323.5851557254791 and batch: 1400, loss is 3.806983618736267 and perplexity is 45.0144531240018
At time: 324.7508499622345 and batch: 1450, loss is 3.7223431205749513 and perplexity is 41.361194923161605
At time: 325.91882586479187 and batch: 1500, loss is 3.7137743759155275 and perplexity is 41.00829551676144
At time: 327.0831344127655 and batch: 1550, loss is 3.709309597015381 and perplexity is 40.82561067140239
At time: 328.24764251708984 and batch: 1600, loss is 3.8071672344207763 and perplexity is 45.02271924249626
At time: 329.4178190231323 and batch: 1650, loss is 3.742514424324036 and perplexity is 42.203975565756075
At time: 330.58560252189636 and batch: 1700, loss is 3.758574209213257 and perplexity is 42.88723414244191
At time: 331.75246596336365 and batch: 1750, loss is 3.7589727640151978 and perplexity is 42.904330462235215
At time: 332.92034912109375 and batch: 1800, loss is 3.6913790607452395 and perplexity is 40.10010933010095
At time: 334.0877368450165 and batch: 1850, loss is 3.71378005027771 and perplexity is 41.008528213342885
At time: 335.253221988678 and batch: 1900, loss is 3.788848667144775 and perplexity is 44.205475749457236
At time: 336.42076659202576 and batch: 1950, loss is 3.7224649238586425 and perplexity is 41.36623315935127
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.41114871002907 and perplexity of 82.36402156151182
finished 7 epochs...
Completing Train Step...
At time: 340.0494759082794 and batch: 50, loss is 3.924319624900818 and perplexity is 50.6186266870872
At time: 341.2388620376587 and batch: 100, loss is 3.899983968734741 and perplexity is 49.40165712811234
At time: 342.4058873653412 and batch: 150, loss is 3.8477816200256347 and perplexity is 46.88893030707445
At time: 343.5941002368927 and batch: 200, loss is 3.8605489921569824 and perplexity is 47.49141662864039
At time: 344.75886392593384 and batch: 250, loss is 3.839106726646423 and perplexity is 46.48393302988918
At time: 345.9249622821808 and batch: 300, loss is 3.8676287603378294 and perplexity is 47.82883787165857
At time: 347.0916404724121 and batch: 350, loss is 3.8778857707977297 and perplexity is 48.32194333278835
At time: 348.2586269378662 and batch: 400, loss is 3.8499066400527955 and perplexity is 46.988676166468274
At time: 349.4236629009247 and batch: 450, loss is 3.8668148374557494 and perplexity is 47.789924724390254
At time: 350.58958101272583 and batch: 500, loss is 3.8862714672088625 and perplexity is 48.7288602358529
At time: 351.7559039592743 and batch: 550, loss is 3.8405674791336057 and perplexity is 46.55188416849114
At time: 352.92242455482483 and batch: 600, loss is 3.8188311147689817 and perplexity is 45.550933377483226
At time: 354.0884277820587 and batch: 650, loss is 3.8624412775039674 and perplexity is 47.58136902139031
At time: 355.2531056404114 and batch: 700, loss is 3.8999468517303466 and perplexity is 49.39982352061684
At time: 356.41811299324036 and batch: 750, loss is 3.849187455177307 and perplexity is 46.9548947702408
At time: 357.5833258628845 and batch: 800, loss is 3.81556800365448 and perplexity is 45.40253786769685
At time: 358.74753856658936 and batch: 850, loss is 3.8121473598480224 and perplexity is 45.24749727823323
At time: 359.9119324684143 and batch: 900, loss is 3.7891051626205443 and perplexity is 44.21681570825309
At time: 361.0772089958191 and batch: 950, loss is 3.881370520591736 and perplexity is 48.49062695427038
At time: 362.24272203445435 and batch: 1000, loss is 3.8548973035812377 and perplexity is 47.223766980492826
At time: 363.40845465660095 and batch: 1050, loss is 3.798841800689697 and perplexity is 44.64944158233696
At time: 364.5734932422638 and batch: 1100, loss is 3.8282086277008056 and perplexity is 45.980096942760305
At time: 365.7393252849579 and batch: 1150, loss is 3.7904059791564944 and perplexity is 44.27437109967998
At time: 366.90467381477356 and batch: 1200, loss is 3.850644187927246 and perplexity is 47.023345348217156
At time: 368.0677590370178 and batch: 1250, loss is 3.8216231155395506 and perplexity is 45.67828932479366
At time: 369.23143911361694 and batch: 1300, loss is 3.8236981582641603 and perplexity is 45.7731721356273
At time: 370.3960015773773 and batch: 1350, loss is 3.706706838607788 and perplexity is 40.719489633602386
At time: 371.5610525608063 and batch: 1400, loss is 3.743237509727478 and perplexity is 42.23450368034179
At time: 372.7265856266022 and batch: 1450, loss is 3.663416428565979 and perplexity is 38.99433692621581
At time: 373.8927044868469 and batch: 1500, loss is 3.656738634109497 and perplexity is 38.734808263217374
At time: 375.05787801742554 and batch: 1550, loss is 3.6564712715148926 and perplexity is 38.72445340869068
At time: 376.2233281135559 and batch: 1600, loss is 3.7578249549865723 and perplexity is 42.85511273604233
At time: 377.3898742198944 and batch: 1650, loss is 3.6971160697937013 and perplexity is 40.33082519687887
At time: 378.5547742843628 and batch: 1700, loss is 3.71831328868866 and perplexity is 41.194851653822084
At time: 379.72044110298157 and batch: 1750, loss is 3.7217408275604247 and perplexity is 41.33629086490991
At time: 380.88496923446655 and batch: 1800, loss is 3.6592392921447754 and perplexity is 38.83179198376685
At time: 382.0498459339142 and batch: 1850, loss is 3.6864893198013307 and perplexity is 39.904508791362645
At time: 383.2177150249481 and batch: 1900, loss is 3.7658402633666994 and perplexity is 43.199989982639785
At time: 384.38129472732544 and batch: 1950, loss is 3.7029961919784546 and perplexity is 40.56867398148794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416499931867732 and perplexity of 82.80595108930696
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 388.0132200717926 and batch: 50, loss is 3.8823632907867434 and perplexity is 48.538790907360514
At time: 389.2014842033386 and batch: 100, loss is 3.8875599336624145 and perplexity is 48.791686203470775
At time: 390.3630259037018 and batch: 150, loss is 3.8509471082687377 and perplexity is 47.037591833714295
At time: 391.5254280567169 and batch: 200, loss is 3.8731715726852416 and perplexity is 48.09468022128757
At time: 392.68815183639526 and batch: 250, loss is 3.858245735168457 and perplexity is 47.382157565547345
At time: 393.85235810279846 and batch: 300, loss is 3.883565607070923 and perplexity is 48.597184983122546
At time: 395.0148124694824 and batch: 350, loss is 3.903664197921753 and perplexity is 49.58380150951474
At time: 396.1774482727051 and batch: 400, loss is 3.8760735464096068 and perplexity is 48.234452429118356
At time: 397.34034037590027 and batch: 450, loss is 3.8820145177841185 and perplexity is 48.521864839361335
At time: 398.5041570663452 and batch: 500, loss is 3.89081814289093 and perplexity is 48.95091899173691
At time: 399.6658046245575 and batch: 550, loss is 3.844654712677002 and perplexity is 46.74254195700812
At time: 400.82846236228943 and batch: 600, loss is 3.8158911228179933 and perplexity is 45.41721066815788
At time: 402.0135762691498 and batch: 650, loss is 3.863645100593567 and perplexity is 47.638683063114826
At time: 403.17538356781006 and batch: 700, loss is 3.907969822883606 and perplexity is 49.79775102566286
At time: 404.3397719860077 and batch: 750, loss is 3.8581194829940797 and perplexity is 47.37617584273871
At time: 405.50306820869446 and batch: 800, loss is 3.817435941696167 and perplexity is 45.48742625380925
At time: 406.66766357421875 and batch: 850, loss is 3.810917820930481 and perplexity is 45.19189790720795
At time: 407.83221316337585 and batch: 900, loss is 3.774394450187683 and perplexity is 43.571115844529906
At time: 408.9955711364746 and batch: 950, loss is 3.863274517059326 and perplexity is 47.621032222336204
At time: 410.1619529724121 and batch: 1000, loss is 3.8269601488113403 and perplexity is 45.92272758206137
At time: 411.3263397216797 and batch: 1050, loss is 3.7629450130462647 and perplexity is 43.07509608459225
At time: 412.4894289970398 and batch: 1100, loss is 3.787166042327881 and perplexity is 44.13115706168719
At time: 413.6521084308624 and batch: 1150, loss is 3.7579631423950195 and perplexity is 42.861035182204354
At time: 414.81358551979065 and batch: 1200, loss is 3.8084084749221803 and perplexity is 45.07863796221384
At time: 415.97646713256836 and batch: 1250, loss is 3.787127470970154 and perplexity is 44.1294548958689
At time: 417.1404621601105 and batch: 1300, loss is 3.7822365045547484 and perplexity is 43.91414617710898
At time: 418.30414628982544 and batch: 1350, loss is 3.6643007373809815 and perplexity is 39.028835213416436
At time: 419.46781826019287 and batch: 1400, loss is 3.696534833908081 and perplexity is 40.307390285243336
At time: 420.6308789253235 and batch: 1450, loss is 3.6159824752807617 and perplexity is 37.18786414084991
At time: 421.7942976951599 and batch: 1500, loss is 3.6041910076141357 and perplexity is 36.75193978804936
At time: 422.95828557014465 and batch: 1550, loss is 3.5961830711364744 and perplexity is 36.458807846252704
At time: 424.1224100589752 and batch: 1600, loss is 3.6949955654144286 and perplexity is 40.24539411593186
At time: 425.2865059375763 and batch: 1650, loss is 3.6371645021438597 and perplexity is 37.98398038949648
At time: 426.4516155719757 and batch: 1700, loss is 3.653663935661316 and perplexity is 38.61589331584481
At time: 427.6172239780426 and batch: 1750, loss is 3.647680983543396 and perplexity is 38.38554604062453
At time: 428.7814598083496 and batch: 1800, loss is 3.5806737995147704 and perplexity is 35.89772056670547
At time: 429.94612979888916 and batch: 1850, loss is 3.605693025588989 and perplexity is 36.80718334023988
At time: 431.1101453304291 and batch: 1900, loss is 3.6881522369384765 and perplexity is 39.97092188731458
At time: 432.2748830318451 and batch: 1950, loss is 3.6295490360260008 and perplexity is 37.69581332975255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3878534361373545 and perplexity of 80.46750482326077
finished 9 epochs...
Completing Train Step...
At time: 435.9455318450928 and batch: 50, loss is 3.8733531427383423 and perplexity is 48.1034135677623
At time: 437.112624168396 and batch: 100, loss is 3.8599751567840577 and perplexity is 47.464172191527034
At time: 438.279248714447 and batch: 150, loss is 3.8111828184127807 and perplexity is 45.20387523328426
At time: 439.4452588558197 and batch: 200, loss is 3.8249147081375123 and perplexity is 45.82889136813243
At time: 440.612832069397 and batch: 250, loss is 3.808958077430725 and perplexity is 45.103420104259556
At time: 441.778746843338 and batch: 300, loss is 3.8309014320373533 and perplexity is 46.10407920226739
At time: 442.9444272518158 and batch: 350, loss is 3.847487812042236 and perplexity is 46.87515598861867
At time: 444.110390663147 and batch: 400, loss is 3.8198586082458497 and perplexity is 45.59776071766732
At time: 445.2772216796875 and batch: 450, loss is 3.8308657026290893 and perplexity is 46.10243196022661
At time: 446.4519097805023 and batch: 500, loss is 3.8408198499679567 and perplexity is 46.563633988932985
At time: 447.6197512149811 and batch: 550, loss is 3.7967674779891967 and perplexity is 44.55692022484929
At time: 448.7870743274689 and batch: 600, loss is 3.7719440126419066 and perplexity is 43.46447825409085
At time: 449.9536454677582 and batch: 650, loss is 3.8204959869384765 and perplexity is 45.62683302282996
At time: 451.1201891899109 and batch: 700, loss is 3.867127051353455 and perplexity is 47.80484773252355
At time: 452.2861957550049 and batch: 750, loss is 3.8204313278198243 and perplexity is 45.62388292739613
At time: 453.45228600502014 and batch: 800, loss is 3.780632643699646 and perplexity is 43.843770448594356
At time: 454.6192719936371 and batch: 850, loss is 3.77569450378418 and perplexity is 43.6277974669772
At time: 455.78638219833374 and batch: 900, loss is 3.7400174283981324 and perplexity is 42.098723871923724
At time: 456.9528486728668 and batch: 950, loss is 3.82992094039917 and perplexity is 46.05889669227979
At time: 458.13671231269836 and batch: 1000, loss is 3.794454894065857 and perplexity is 44.453997661865564
At time: 459.3294470310211 and batch: 1050, loss is 3.733232259750366 and perplexity is 41.81404382385174
At time: 460.49613213539124 and batch: 1100, loss is 3.756771082878113 and perplexity is 42.809972718105755
At time: 461.66267561912537 and batch: 1150, loss is 3.730186128616333 and perplexity is 41.68686656076928
At time: 462.82714581489563 and batch: 1200, loss is 3.7834549617767332 and perplexity is 43.96768629721481
At time: 463.99360752105713 and batch: 1250, loss is 3.764220266342163 and perplexity is 43.13006278362809
At time: 465.1605107784271 and batch: 1300, loss is 3.7610125017166136 and perplexity is 42.991933355722466
At time: 466.3271358013153 and batch: 1350, loss is 3.6450299406051636 and perplexity is 38.283919078103764
At time: 467.49371242523193 and batch: 1400, loss is 3.6794233608245848 and perplexity is 39.62353899878515
At time: 468.6612174510956 and batch: 1450, loss is 3.602387285232544 and perplexity is 36.6857092404036
At time: 469.82692646980286 and batch: 1500, loss is 3.592328906059265 and perplexity is 36.3185600250326
At time: 470.993212223053 and batch: 1550, loss is 3.5853618478775022 and perplexity is 36.066405910414474
At time: 472.1598308086395 and batch: 1600, loss is 3.686059217453003 and perplexity is 39.88734945882175
At time: 473.32987880706787 and batch: 1650, loss is 3.6292520475387575 and perplexity is 37.684619769437894
At time: 474.49760341644287 and batch: 1700, loss is 3.6490177059173585 and perplexity is 38.436891168298885
At time: 475.66504669189453 and batch: 1750, loss is 3.645720534324646 and perplexity is 38.31036684345548
At time: 476.8313751220703 and batch: 1800, loss is 3.5814618968963625 and perplexity is 35.92602261721031
At time: 477.9982967376709 and batch: 1850, loss is 3.6087715911865232 and perplexity is 36.920671268997445
At time: 479.16597509384155 and batch: 1900, loss is 3.691530842781067 and perplexity is 40.10619626826423
At time: 480.3319354057312 and batch: 1950, loss is 3.6338924312591554 and perplexity is 37.85989722833576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.387828170421511 and perplexity of 80.46547177983255
finished 10 epochs...
Completing Train Step...
At time: 484.00555205345154 and batch: 50, loss is 3.8523315143585206 and perplexity is 47.1027560587649
At time: 485.17024970054626 and batch: 100, loss is 3.836731028556824 and perplexity is 46.373632311473585
At time: 486.3348753452301 and batch: 150, loss is 3.7868972063064574 and perplexity is 44.11929461160031
At time: 487.5030369758606 and batch: 200, loss is 3.799476728439331 and perplexity is 44.67779975354548
At time: 488.692706823349 and batch: 250, loss is 3.782867021560669 and perplexity is 43.941843523980644
At time: 489.85689878463745 and batch: 300, loss is 3.804659595489502 and perplexity is 44.90995995780626
At time: 491.02253818511963 and batch: 350, loss is 3.821046161651611 and perplexity is 45.65194265930969
At time: 492.18606066703796 and batch: 400, loss is 3.7932829666137695 and perplexity is 44.40193131659932
At time: 493.35165143013 and batch: 450, loss is 3.8060541677474977 and perplexity is 44.97263383353779
At time: 494.5169720649719 and batch: 500, loss is 3.8168573904037477 and perplexity is 45.461117055905355
At time: 495.68247866630554 and batch: 550, loss is 3.772570781707764 and perplexity is 43.49172898358918
At time: 496.8481025695801 and batch: 600, loss is 3.748708825111389 and perplexity is 42.466215275638646
At time: 498.012686252594 and batch: 650, loss is 3.797505888938904 and perplexity is 44.58983369296568
At time: 499.1777272224426 and batch: 700, loss is 3.8445880603790283 and perplexity is 46.73942656299879
At time: 500.341281414032 and batch: 750, loss is 3.799634051322937 and perplexity is 44.6848291467636
At time: 501.50770449638367 and batch: 800, loss is 3.7603068494796754 and perplexity is 42.961606703073265
At time: 502.67281436920166 and batch: 850, loss is 3.7570278358459475 and perplexity is 42.82096571683618
At time: 503.83901500701904 and batch: 900, loss is 3.7207657051086427 and perplexity is 41.29600256581904
At time: 505.00423884391785 and batch: 950, loss is 3.8120187091827393 and perplexity is 45.241676532035456
At time: 506.17116928100586 and batch: 1000, loss is 3.7766028833389282 and perplexity is 43.66744607147941
At time: 507.33554577827454 and batch: 1050, loss is 3.7159109258651735 and perplexity is 41.09600545344806
At time: 508.5020966529846 and batch: 1100, loss is 3.7383583927154542 and perplexity is 42.02893849104992
At time: 509.66629576683044 and batch: 1150, loss is 3.7126967525482177 and perplexity is 40.96412782160345
At time: 510.83147835731506 and batch: 1200, loss is 3.7672460079193115 and perplexity is 43.260760837372246
At time: 511.99608969688416 and batch: 1250, loss is 3.7491944551467897 and perplexity is 42.48684315361944
At time: 513.1604535579681 and batch: 1300, loss is 3.7466402101516723 and perplexity is 42.37845982484941
At time: 514.3268074989319 and batch: 1350, loss is 3.6312232398986817 and perplexity is 37.75897666581032
At time: 515.4930648803711 and batch: 1400, loss is 3.667255382537842 and perplexity is 39.14432209972631
At time: 516.6582996845245 and batch: 1450, loss is 3.592038450241089 and perplexity is 36.30801261981731
At time: 517.8236269950867 and batch: 1500, loss is 3.5826233196258546 and perplexity is 35.96777215619694
At time: 518.9879355430603 and batch: 1550, loss is 3.57567409992218 and perplexity is 35.71869066860149
At time: 520.1532940864563 and batch: 1600, loss is 3.6768063831329347 and perplexity is 39.51998064521388
At time: 521.3184080123901 and batch: 1650, loss is 3.619989204406738 and perplexity is 37.3371647430338
At time: 522.4839842319489 and batch: 1700, loss is 3.641482629776001 and perplexity is 38.14835470401654
At time: 523.6503238677979 and batch: 1750, loss is 3.639449896812439 and perplexity is 38.070888047091955
At time: 524.8155992031097 and batch: 1800, loss is 3.5769996547698977 and perplexity is 35.76606914661961
At time: 525.9815728664398 and batch: 1850, loss is 3.6055821800231933 and perplexity is 36.803103653288964
At time: 527.147224187851 and batch: 1900, loss is 3.688313031196594 and perplexity is 39.97734949879339
At time: 528.3132438659668 and batch: 1950, loss is 3.6310341691970827 and perplexity is 37.751838224456776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389455963844477 and perplexity of 80.59655960857891
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 531.9868931770325 and batch: 50, loss is 3.8442947673797607 and perplexity is 46.72572022648261
At time: 533.1527707576752 and batch: 100, loss is 3.8458638906478884 and perplexity is 46.79909619422395
At time: 534.321097612381 and batch: 150, loss is 3.8037844276428223 and perplexity is 44.87067339852978
At time: 535.4876048564911 and batch: 200, loss is 3.824145631790161 and perplexity is 45.79365900168232
At time: 536.6549997329712 and batch: 250, loss is 3.818011541366577 and perplexity is 45.51361633814761
At time: 537.8220002651215 and batch: 300, loss is 3.834517502784729 and perplexity is 46.27109660578618
At time: 538.9900217056274 and batch: 350, loss is 3.8533253145217894 and perplexity is 47.149590053387676
At time: 540.156280040741 and batch: 400, loss is 3.8334390211105345 and perplexity is 46.22122097586268
At time: 541.3221797943115 and batch: 450, loss is 3.849147820472717 and perplexity is 46.953033763738
At time: 542.4876978397369 and batch: 500, loss is 3.862481265068054 and perplexity is 47.58327172247532
At time: 543.654659986496 and batch: 550, loss is 3.822734761238098 and perplexity is 45.72909563271338
At time: 544.821634054184 and batch: 600, loss is 3.7852830410003664 and perplexity is 44.0481362230605
At time: 545.988543510437 and batch: 650, loss is 3.816193037033081 and perplexity is 45.43092483981575
At time: 547.1991288661957 and batch: 700, loss is 3.8514596605300904 and perplexity is 47.061707237451664
At time: 548.3662495613098 and batch: 750, loss is 3.809903287887573 and perplexity is 45.146072483143435
At time: 549.5333476066589 and batch: 800, loss is 3.776255326271057 and perplexity is 43.65227177908042
At time: 550.7010662555695 and batch: 850, loss is 3.7839066553115845 and perplexity is 43.98755070283169
At time: 551.8683841228485 and batch: 900, loss is 3.7488462257385256 and perplexity is 42.47205056112639
At time: 553.0389862060547 and batch: 950, loss is 3.854384207725525 and perplexity is 47.199542876539105
At time: 554.206036567688 and batch: 1000, loss is 3.818347339630127 and perplexity is 45.52890229783755
At time: 555.372095823288 and batch: 1050, loss is 3.757186007499695 and perplexity is 42.82773931548021
At time: 556.5380058288574 and batch: 1100, loss is 3.768470573425293 and perplexity is 43.313768922168215
At time: 557.7042553424835 and batch: 1150, loss is 3.7342156600952148 and perplexity is 41.85518399428105
At time: 558.8715331554413 and batch: 1200, loss is 3.775088629722595 and perplexity is 43.601372522030594
At time: 560.039274930954 and batch: 1250, loss is 3.750677103996277 and perplexity is 42.549882944127845
At time: 561.2065646648407 and batch: 1300, loss is 3.74398063659668 and perplexity is 42.2659009394626
At time: 562.3748142719269 and batch: 1350, loss is 3.6235029315948486 and perplexity is 37.4685881116343
At time: 563.5424346923828 and batch: 1400, loss is 3.660050230026245 and perplexity is 38.8632949266303
At time: 564.7114102840424 and batch: 1450, loss is 3.586996111869812 and perplexity is 36.125396128591284
At time: 565.8794150352478 and batch: 1500, loss is 3.5852923727035524 and perplexity is 36.06390027763075
At time: 567.049220085144 and batch: 1550, loss is 3.584421629905701 and perplexity is 36.03251156393298
At time: 568.2185695171356 and batch: 1600, loss is 3.682493977546692 and perplexity is 39.74539469054137
At time: 569.3863835334778 and batch: 1650, loss is 3.6211332941055296 and perplexity is 37.37990625399741
At time: 570.5537328720093 and batch: 1700, loss is 3.634157133102417 and perplexity is 37.8699201394008
At time: 571.7214393615723 and batch: 1750, loss is 3.6287928867340087 and perplexity is 37.667320440988625
At time: 572.8902397155762 and batch: 1800, loss is 3.5584184074401857 and perplexity is 35.10762725017252
At time: 574.0577487945557 and batch: 1850, loss is 3.5856269073486327 and perplexity is 36.075966919952755
At time: 575.2266130447388 and batch: 1900, loss is 3.6701242685317994 and perplexity is 39.25678394010572
At time: 576.3932869434357 and batch: 1950, loss is 3.6222274541854858 and perplexity is 37.42082823873148
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373213231286337 and perplexity of 79.29802566436891
finished 12 epochs...
Completing Train Step...
At time: 580.0529615879059 and batch: 50, loss is 3.8521374368667605 and perplexity is 47.09361536104456
At time: 581.2400460243225 and batch: 100, loss is 3.838304252624512 and perplexity is 46.44664584419633
At time: 582.4052815437317 and batch: 150, loss is 3.788616404533386 and perplexity is 44.195209662482206
At time: 583.5717499256134 and batch: 200, loss is 3.802461929321289 and perplexity is 44.81137123042634
At time: 584.7335000038147 and batch: 250, loss is 3.795900197029114 and perplexity is 44.518293608783864
At time: 585.9013197422028 and batch: 300, loss is 3.813576617240906 and perplexity is 45.3122138355198
At time: 587.0725276470184 and batch: 350, loss is 3.8291922569274903 and perplexity is 46.02534656073402
At time: 588.2370092868805 and batch: 400, loss is 3.808573064804077 and perplexity is 45.08605806053192
At time: 589.4015207290649 and batch: 450, loss is 3.8245616960525513 and perplexity is 45.8127160708448
At time: 590.5658977031708 and batch: 500, loss is 3.8378811120986938 and perplexity is 46.426996543552214
At time: 591.7282526493073 and batch: 550, loss is 3.798343687057495 and perplexity is 44.62720662504199
At time: 592.8948318958282 and batch: 600, loss is 3.7620948696136476 and perplexity is 43.0384916362669
At time: 594.0591526031494 and batch: 650, loss is 3.794477701187134 and perplexity is 44.45501154114327
At time: 595.2242214679718 and batch: 700, loss is 3.832178626060486 and perplexity is 46.163000675733926
At time: 596.3889083862305 and batch: 750, loss is 3.7923011016845702 and perplexity is 44.358356013482556
At time: 597.5528194904327 and batch: 800, loss is 3.7595135307312013 and perplexity is 42.927537970480074
At time: 598.7168378829956 and batch: 850, loss is 3.7673779344558715 and perplexity is 43.266468456203384
At time: 599.8816499710083 and batch: 900, loss is 3.733061280250549 and perplexity is 41.806895090714235
At time: 601.0453524589539 and batch: 950, loss is 3.8384457063674926 and perplexity is 46.45321636080102
At time: 602.2091937065125 and batch: 1000, loss is 3.8029483556747437 and perplexity is 44.83317396460961
At time: 603.3727746009827 and batch: 1050, loss is 3.7425844192504885 and perplexity is 42.20692973330897
At time: 604.5778765678406 and batch: 1100, loss is 3.755175347328186 and perplexity is 42.74171379882451
At time: 605.7407457828522 and batch: 1150, loss is 3.721618661880493 and perplexity is 41.33124129727876
At time: 606.9049911499023 and batch: 1200, loss is 3.7634666204452514 and perplexity is 43.09757023425386
At time: 608.0682830810547 and batch: 1250, loss is 3.7412930631637575 and perplexity is 42.152460734701464
At time: 609.232442855835 and batch: 1300, loss is 3.734977250099182 and perplexity is 41.88707262551536
At time: 610.3967757225037 and batch: 1350, loss is 3.6154883670806885 and perplexity is 37.16949385106387
At time: 611.5626866817474 and batch: 1400, loss is 3.653224940299988 and perplexity is 38.59894483822933
At time: 612.7283942699432 and batch: 1450, loss is 3.5810851526260374 and perplexity is 35.91249024331593
At time: 613.8934717178345 and batch: 1500, loss is 3.579931035041809 and perplexity is 35.87106691512637
At time: 615.0576856136322 and batch: 1550, loss is 3.579918885231018 and perplexity is 35.87063109109807
At time: 616.2224502563477 and batch: 1600, loss is 3.679320044517517 and perplexity is 39.61944545253152
At time: 617.3875954151154 and batch: 1650, loss is 3.619244384765625 and perplexity is 37.30936564333258
At time: 618.5509057044983 and batch: 1700, loss is 3.6340062856674193 and perplexity is 37.86420798992657
At time: 619.7149908542633 and batch: 1750, loss is 3.630831422805786 and perplexity is 37.744184951354924
At time: 620.8783595561981 and batch: 1800, loss is 3.562023024559021 and perplexity is 35.23440516000066
At time: 622.0439245700836 and batch: 1850, loss is 3.5906217813491823 and perplexity is 36.256612604809455
At time: 623.2076392173767 and batch: 1900, loss is 3.6753500747680663 and perplexity is 39.4624692541451
At time: 624.3717620372772 and batch: 1950, loss is 3.627489848136902 and perplexity is 37.61827043257171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37210324309593 and perplexity of 79.21005462479859
finished 13 epochs...
Completing Train Step...
At time: 628.0109314918518 and batch: 50, loss is 3.8474759674072265 and perplexity is 46.87460077279314
At time: 629.198502779007 and batch: 100, loss is 3.8311373233795165 and perplexity is 46.11495603821489
At time: 630.3642508983612 and batch: 150, loss is 3.780441012382507 and perplexity is 43.835369414091325
At time: 631.530905008316 and batch: 200, loss is 3.7930881547927857 and perplexity is 44.39328213801281
At time: 632.6968686580658 and batch: 250, loss is 3.7860296297073366 and perplexity is 44.08103434328214
At time: 633.8868134021759 and batch: 300, loss is 3.8034616708755493 and perplexity is 44.85619342191923
At time: 635.0534162521362 and batch: 350, loss is 3.8186463642120363 and perplexity is 45.5425185945142
At time: 636.2216792106628 and batch: 400, loss is 3.797629699707031 and perplexity is 44.59535473630112
At time: 637.3877046108246 and batch: 450, loss is 3.814241313934326 and perplexity is 45.3423427264056
At time: 638.5546319484711 and batch: 500, loss is 3.8272327756881714 and perplexity is 45.9352490586256
At time: 639.7209734916687 and batch: 550, loss is 3.7877194452285767 and perplexity is 44.15558613095163
At time: 640.887393951416 and batch: 600, loss is 3.752046389579773 and perplexity is 42.60818579293831
At time: 642.0557515621185 and batch: 650, loss is 3.784256772994995 and perplexity is 44.00295421854694
At time: 643.2209820747375 and batch: 700, loss is 3.823023591041565 and perplexity is 45.74230546602266
At time: 644.3866519927979 and batch: 750, loss is 3.7833015537261963 and perplexity is 43.9609418175153
At time: 645.5527830123901 and batch: 800, loss is 3.7509495639801025 and perplexity is 42.56147766402345
At time: 646.7202217578888 and batch: 850, loss is 3.75899019241333 and perplexity is 42.905078222504216
At time: 647.8860304355621 and batch: 900, loss is 3.7248895454406736 and perplexity is 41.46665231106275
At time: 649.0533850193024 and batch: 950, loss is 3.8306472873687745 and perplexity is 46.092363585132276
At time: 650.2195298671722 and batch: 1000, loss is 3.79560350894928 and perplexity is 44.505087520876884
At time: 651.3845491409302 and batch: 1050, loss is 3.7357830286026 and perplexity is 41.92083793005946
At time: 652.5490815639496 and batch: 1100, loss is 3.74899760723114 and perplexity is 42.47848053021162
At time: 653.7147896289825 and batch: 1150, loss is 3.7161903619766234 and perplexity is 41.10749076603891
At time: 654.8819768428802 and batch: 1200, loss is 3.758490734100342 and perplexity is 42.883654275146256
At time: 656.0492396354675 and batch: 1250, loss is 3.736815638542175 and perplexity is 41.964148161420646
At time: 657.2156097888947 and batch: 1300, loss is 3.730323634147644 and perplexity is 41.69259912962534
At time: 658.3833820819855 and batch: 1350, loss is 3.6108923673629763 and perplexity is 36.9990548366661
At time: 659.5507056713104 and batch: 1400, loss is 3.6489776468276975 and perplexity is 38.4353514522693
At time: 660.7186448574066 and batch: 1450, loss is 3.577164373397827 and perplexity is 35.771960969689054
At time: 661.8843729496002 and batch: 1500, loss is 3.5761315202713013 and perplexity is 35.73503286189821
At time: 663.0507373809814 and batch: 1550, loss is 3.576701908111572 and perplexity is 35.75542150427838
At time: 664.2175190448761 and batch: 1600, loss is 3.6769542694091797 and perplexity is 39.52582554016799
At time: 665.3860039710999 and batch: 1650, loss is 3.617419981956482 and perplexity is 37.24136038520018
At time: 666.5527257919312 and batch: 1700, loss is 3.6328565740585326 and perplexity is 37.82070008600289
At time: 667.7196469306946 and batch: 1750, loss is 3.6305783224105834 and perplexity is 37.7346330920678
At time: 668.8852541446686 and batch: 1800, loss is 3.562321891784668 and perplexity is 35.244937142671986
At time: 670.0519473552704 and batch: 1850, loss is 3.5914519834518432 and perplexity is 36.28672541896058
At time: 671.2163052558899 and batch: 1900, loss is 3.676235113143921 and perplexity is 39.49741051373806
At time: 672.3829870223999 and batch: 1950, loss is 3.628332242965698 and perplexity is 37.649973220309825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372178472474564 and perplexity of 79.21601377213825
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 676.0406613349915 and batch: 50, loss is 3.845741858482361 and perplexity is 46.79338554761902
At time: 677.231981754303 and batch: 100, loss is 3.8353695821762086 and perplexity is 46.31054005571408
At time: 678.4035873413086 and batch: 150, loss is 3.787751941680908 and perplexity is 44.15702105416633
At time: 679.567919254303 and batch: 200, loss is 3.8031975984573365 and perplexity is 44.84434970231914
At time: 680.7318127155304 and batch: 250, loss is 3.801621870994568 and perplexity is 44.773742872113154
At time: 681.897786617279 and batch: 300, loss is 3.816903371810913 and perplexity is 45.463207470098624
At time: 683.0641663074493 and batch: 350, loss is 3.8329674577713013 and perplexity is 46.19942988090043
At time: 684.2295286655426 and batch: 400, loss is 3.820969343185425 and perplexity is 45.64843588179053
At time: 685.3948793411255 and batch: 450, loss is 3.8416318321228027 and perplexity is 46.60145818300391
At time: 686.564530134201 and batch: 500, loss is 3.8599460744857788 and perplexity is 47.46279184438573
At time: 687.733237028122 and batch: 550, loss is 3.8278527069091797 and perplexity is 45.96373458228228
At time: 688.898679971695 and batch: 600, loss is 3.7864859771728514 and perplexity is 44.10115520228429
At time: 690.0665552616119 and batch: 650, loss is 3.804970498085022 and perplexity is 44.92392475165468
At time: 691.2335028648376 and batch: 700, loss is 3.8298961305618286 and perplexity is 46.05775399271988
At time: 692.4429829120636 and batch: 750, loss is 3.7849247598648073 and perplexity is 44.03235743358533
At time: 693.6090478897095 and batch: 800, loss is 3.7474541521072386 and perplexity is 42.41296747301934
At time: 694.7759997844696 and batch: 850, loss is 3.754033703804016 and perplexity is 42.69294584116249
At time: 695.9438815116882 and batch: 900, loss is 3.7181782960891723 and perplexity is 41.189291029041875
At time: 697.1093027591705 and batch: 950, loss is 3.8305503129959106 and perplexity is 46.087894023799755
At time: 698.2743320465088 and batch: 1000, loss is 3.804010815620422 and perplexity is 44.880832729465816
At time: 699.4403011798859 and batch: 1050, loss is 3.7523826026916502 and perplexity is 42.62251363214394
At time: 700.6065537929535 and batch: 1100, loss is 3.770179896354675 and perplexity is 43.38786945337123
At time: 701.7753574848175 and batch: 1150, loss is 3.744132056236267 and perplexity is 42.272301311508464
At time: 702.9406609535217 and batch: 1200, loss is 3.7925082063674926 and perplexity is 44.36754378812242
At time: 704.1066992282867 and batch: 1250, loss is 3.7695938968658447 and perplexity is 43.36245163219259
At time: 705.2722225189209 and batch: 1300, loss is 3.7614966201782227 and perplexity is 43.012751583197776
At time: 706.4391837120056 and batch: 1350, loss is 3.6289793729782103 and perplexity is 37.67434553312797
At time: 707.6062273979187 and batch: 1400, loss is 3.660259475708008 and perplexity is 38.871427754122614
At time: 708.7721083164215 and batch: 1450, loss is 3.5761955261230467 and perplexity is 35.73732018631398
At time: 709.9378249645233 and batch: 1500, loss is 3.5682007122039794 and perplexity is 35.452746035907666
At time: 711.1068081855774 and batch: 1550, loss is 3.5695558166503907 and perplexity is 35.50082077548843
At time: 712.2719452381134 and batch: 1600, loss is 3.667871527671814 and perplexity is 39.168448115110934
At time: 713.4382081031799 and batch: 1650, loss is 3.607049655914307 and perplexity is 36.85715096748442
At time: 714.6024966239929 and batch: 1700, loss is 3.6218174839019777 and perplexity is 37.405489955504336
At time: 715.7677917480469 and batch: 1750, loss is 3.6210185575485228 and perplexity is 37.37561765828665
At time: 716.9334828853607 and batch: 1800, loss is 3.5512897109985353 and perplexity is 34.85824557195594
At time: 718.099246263504 and batch: 1850, loss is 3.580510210990906 and perplexity is 35.891848591894814
At time: 719.2639632225037 and batch: 1900, loss is 3.6663864135742186 and perplexity is 39.11032167351664
At time: 720.4304735660553 and batch: 1950, loss is 3.622344994544983 and perplexity is 37.42522695484361
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3686097610828485 and perplexity of 78.93381851758924
finished 15 epochs...
Completing Train Step...
At time: 724.0983047485352 and batch: 50, loss is 3.8459234714508055 and perplexity is 46.801884605018046
At time: 725.262745141983 and batch: 100, loss is 3.830852360725403 and perplexity is 46.10181687012294
At time: 726.4272212982178 and batch: 150, loss is 3.7811168384552003 and perplexity is 43.865004512605665
At time: 727.5927538871765 and batch: 200, loss is 3.795008964538574 and perplexity is 44.47863513418191
At time: 728.756505727768 and batch: 250, loss is 3.7926184511184693 and perplexity is 44.37243534656815
At time: 729.919839143753 and batch: 300, loss is 3.808894648551941 and perplexity is 45.100559335621654
At time: 731.0838334560394 and batch: 350, loss is 3.825595679283142 and perplexity is 45.86011014912845
At time: 732.2496721744537 and batch: 400, loss is 3.8144177913665773 and perplexity is 45.35034533274115
At time: 733.4145562648773 and batch: 450, loss is 3.8353044319152834 and perplexity is 46.307523010227584
At time: 734.5777187347412 and batch: 500, loss is 3.8502391386032104 and perplexity is 47.00430243089071
At time: 735.7409036159515 and batch: 550, loss is 3.8209439849853517 and perplexity is 45.64727833429714
At time: 736.9098289012909 and batch: 600, loss is 3.778449926376343 and perplexity is 43.74817625681941
At time: 738.0769696235657 and batch: 650, loss is 3.795123519897461 and perplexity is 44.48373069204866
At time: 739.2413511276245 and batch: 700, loss is 3.8231852149963377 and perplexity is 45.74969911581185
At time: 740.4054284095764 and batch: 750, loss is 3.7789629125595092 and perplexity is 43.77062422403412
At time: 741.5697567462921 and batch: 800, loss is 3.7424235439300535 and perplexity is 42.200140226110264
At time: 742.7382378578186 and batch: 850, loss is 3.749325323104858 and perplexity is 42.492403683867416
At time: 743.9086396694183 and batch: 900, loss is 3.7136640214920043 and perplexity is 41.00377031964237
At time: 745.0728180408478 and batch: 950, loss is 3.8248087882995607 and perplexity is 45.82403743645358
At time: 746.2355809211731 and batch: 1000, loss is 3.7961638307571413 and perplexity is 44.53003167970107
At time: 747.4009206295013 and batch: 1050, loss is 3.7441686296463015 and perplexity is 42.27384738198979
At time: 748.5651206970215 and batch: 1100, loss is 3.761422109603882 and perplexity is 43.00954679777002
At time: 749.8088157176971 and batch: 1150, loss is 3.7350451231002806 and perplexity is 41.88991572332539
At time: 750.9742958545685 and batch: 1200, loss is 3.782456774711609 and perplexity is 43.92382021838799
At time: 752.1434459686279 and batch: 1250, loss is 3.760665955543518 and perplexity is 42.97703724698788
At time: 753.3108694553375 and batch: 1300, loss is 3.7532220029830934 and perplexity is 42.658306002470255
At time: 754.4778990745544 and batch: 1350, loss is 3.622993049621582 and perplexity is 37.449488423699506
At time: 755.6564445495605 and batch: 1400, loss is 3.655814251899719 and perplexity is 38.69901903956896
At time: 756.8292074203491 and batch: 1450, loss is 3.573874969482422 and perplexity is 35.6544858586838
At time: 757.9922451972961 and batch: 1500, loss is 3.567434811592102 and perplexity is 35.42560315172867
At time: 759.1558222770691 and batch: 1550, loss is 3.5704150009155273 and perplexity is 35.531335629162065
At time: 760.3192784786224 and batch: 1600, loss is 3.669892191886902 and perplexity is 39.247674414494384
At time: 761.484334230423 and batch: 1650, loss is 3.6106951904296873 and perplexity is 36.99176019568992
At time: 762.6476383209229 and batch: 1700, loss is 3.6264747285842898 and perplexity is 37.580102766369826
At time: 763.8114953041077 and batch: 1750, loss is 3.625890736579895 and perplexity is 37.55816269386693
At time: 764.9758996963501 and batch: 1800, loss is 3.5559210872650144 and perplexity is 35.02006164951821
At time: 766.1394057273865 and batch: 1850, loss is 3.5854473304748535 and perplexity is 36.069489092246144
At time: 767.3022317886353 and batch: 1900, loss is 3.6707149600982665 and perplexity is 39.27997944132479
At time: 768.4659025669098 and batch: 1950, loss is 3.6259560012817382 and perplexity is 37.56061399614782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3674495253452035 and perplexity of 78.8422897881554
finished 16 epochs...
Completing Train Step...
At time: 772.1390006542206 and batch: 50, loss is 3.84479896068573 and perplexity is 46.74928496192913
At time: 773.3060913085938 and batch: 100, loss is 3.8280258226394652 and perplexity is 45.971692316545756
At time: 774.4721028804779 and batch: 150, loss is 3.777806577682495 and perplexity is 43.720039976456434
At time: 775.639536857605 and batch: 200, loss is 3.7910920429229735 and perplexity is 44.304756563466164
At time: 776.8053476810455 and batch: 250, loss is 3.7882614231109617 and perplexity is 44.179523968321604
At time: 777.973281621933 and batch: 300, loss is 3.80443576335907 and perplexity is 44.89990879072032
At time: 779.1818768978119 and batch: 350, loss is 3.821240949630737 and perplexity is 45.660835975090855
At time: 780.3497257232666 and batch: 400, loss is 3.8100442552566527 and perplexity is 45.15243705479357
At time: 781.5170803070068 and batch: 450, loss is 3.831060109138489 and perplexity is 46.11139544435042
At time: 782.6850507259369 and batch: 500, loss is 3.8455555057525634 and perplexity is 46.78466628494018
At time: 783.8524315357208 and batch: 550, loss is 3.8165556478500364 and perplexity is 45.44740157172701
At time: 785.020628452301 and batch: 600, loss is 3.774148693084717 and perplexity is 43.56040924899179
At time: 786.1870815753937 and batch: 650, loss is 3.7907564067840576 and perplexity is 44.28988878125967
At time: 787.3552875518799 and batch: 700, loss is 3.8195084142684936 and perplexity is 45.581795452116154
At time: 788.5216982364655 and batch: 750, loss is 3.7755345821380617 and perplexity is 43.62082099564903
At time: 789.6899662017822 and batch: 800, loss is 3.7393360805511473 and perplexity is 42.07004976668199
At time: 790.8563508987427 and batch: 850, loss is 3.746232671737671 and perplexity is 42.36119249333401
At time: 792.0223801136017 and batch: 900, loss is 3.710661392211914 and perplexity is 40.88083585396213
At time: 793.1891996860504 and batch: 950, loss is 3.8214600181579588 and perplexity is 45.67083992291468
At time: 794.3555834293365 and batch: 1000, loss is 3.792175226211548 and perplexity is 44.3527727358431
At time: 795.5229294300079 and batch: 1050, loss is 3.740243854522705 and perplexity is 42.10825720207626
At time: 796.689918756485 and batch: 1100, loss is 3.75752046585083 and perplexity is 42.842065806228184
At time: 797.8565189838409 and batch: 1150, loss is 3.7312084197998048 and perplexity is 41.729504467385595
At time: 799.0224914550781 and batch: 1200, loss is 3.7784166431427 and perplexity is 43.74672020027887
At time: 800.1888971328735 and batch: 1250, loss is 3.757199902534485 and perplexity is 42.828334412542404
At time: 801.3554909229279 and batch: 1300, loss is 3.750269021987915 and perplexity is 42.53252264489424
At time: 802.5224828720093 and batch: 1350, loss is 3.620952067375183 and perplexity is 37.373132629605784
At time: 803.6904690265656 and batch: 1400, loss is 3.654371657371521 and perplexity is 38.64323229495682
At time: 804.8585467338562 and batch: 1450, loss is 3.573299946784973 and perplexity is 35.633989613517045
At time: 806.0262455940247 and batch: 1500, loss is 3.5675966548919678 and perplexity is 35.431337012223416
At time: 807.1927301883698 and batch: 1550, loss is 3.5710953664779663 and perplexity is 35.555518151856596
At time: 808.3599097728729 and batch: 1600, loss is 3.670869402885437 and perplexity is 39.286046419318154
At time: 809.5264773368835 and batch: 1650, loss is 3.6122218132019044 and perplexity is 37.04827578720739
At time: 810.6935894489288 and batch: 1700, loss is 3.6282814073562624 and perplexity is 37.648059309623754
At time: 811.8630483150482 and batch: 1750, loss is 3.627718057632446 and perplexity is 37.626856258736645
At time: 813.0298266410828 and batch: 1800, loss is 3.5576478624343872 and perplexity is 35.080585663047394
At time: 814.1966044902802 and batch: 1850, loss is 3.5872570085525513 and perplexity is 36.13482235418589
At time: 815.3621461391449 and batch: 1900, loss is 3.67217791557312 and perplexity is 39.337486357072684
At time: 816.5348002910614 and batch: 1950, loss is 3.6270584726333617 and perplexity is 37.60204633181296
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366922068041425 and perplexity of 78.80071481203628
finished 17 epochs...
Completing Train Step...
At time: 820.3369352817535 and batch: 50, loss is 3.8431412315368654 and perplexity is 46.67185150913774
At time: 821.5030148029327 and batch: 100, loss is 3.825539507865906 and perplexity is 45.85753419409497
At time: 822.6676635742188 and batch: 150, loss is 3.7750942659378053 and perplexity is 43.60161826944213
At time: 823.8334419727325 and batch: 200, loss is 3.7880552053451537 and perplexity is 44.17041430491389
At time: 824.998199224472 and batch: 250, loss is 3.7849220037460327 and perplexity is 44.032236075345565
At time: 826.1625463962555 and batch: 300, loss is 3.801068744659424 and perplexity is 44.748984183780124
At time: 827.3254668712616 and batch: 350, loss is 3.817919669151306 and perplexity is 45.50943509346268
At time: 828.4891090393066 and batch: 400, loss is 3.8067365074157715 and perplexity is 45.003330917317136
At time: 829.655341386795 and batch: 450, loss is 3.8278939294815064 and perplexity is 45.96562936470914
At time: 830.8187010288239 and batch: 500, loss is 3.842465624809265 and perplexity is 46.640330341424054
At time: 831.9815390110016 and batch: 550, loss is 3.8134279346466062 and perplexity is 45.305477198835995
At time: 833.1477208137512 and batch: 600, loss is 3.7712668275833128 and perplexity is 43.435054722549985
At time: 834.3117742538452 and batch: 650, loss is 3.7879187631607056 and perplexity is 44.164388008228045
At time: 835.4774677753448 and batch: 700, loss is 3.8168937969207763 and perplexity is 45.46277216696583
At time: 836.6431457996368 and batch: 750, loss is 3.7730170679092407 and perplexity is 43.51114307391101
At time: 837.8453848361969 and batch: 800, loss is 3.7369905138015747 and perplexity is 41.97148729441354
At time: 839.0089244842529 and batch: 850, loss is 3.743805561065674 and perplexity is 42.25850186212977
At time: 840.1724269390106 and batch: 900, loss is 3.708256025314331 and perplexity is 40.78262061385158
At time: 841.3354461193085 and batch: 950, loss is 3.8189902019500734 and perplexity is 45.55818052351908
At time: 842.5017132759094 and batch: 1000, loss is 3.789494957923889 and perplexity is 44.23405457494138
At time: 843.6666111946106 and batch: 1050, loss is 3.737660913467407 and perplexity is 41.999634399320875
At time: 844.8451261520386 and batch: 1100, loss is 3.7550663566589355 and perplexity is 42.737055604687114
At time: 846.031153678894 and batch: 1150, loss is 3.728898787498474 and perplexity is 41.6332358712734
At time: 847.21191239357 and batch: 1200, loss is 3.776101522445679 and perplexity is 43.64555840897858
At time: 848.3845853805542 and batch: 1250, loss is 3.7552295684814454 and perplexity is 42.74403136666899
At time: 849.5490281581879 and batch: 1300, loss is 3.7486451625823975 and perplexity is 42.463511855031705
At time: 850.7145416736603 and batch: 1350, loss is 3.6197461175918577 and perplexity is 37.3280896736393
At time: 851.8800754547119 and batch: 1400, loss is 3.6534422540664675 and perplexity is 38.607333831803146
At time: 853.0457279682159 and batch: 1450, loss is 3.572816319465637 and perplexity is 35.616760209284124
At time: 854.2104601860046 and batch: 1500, loss is 3.567492651939392 and perplexity is 35.427652240177345
At time: 855.3765158653259 and batch: 1550, loss is 3.5711818170547485 and perplexity is 35.55859207977812
At time: 856.5423748493195 and batch: 1600, loss is 3.6711093950271607 and perplexity is 39.29547589319274
At time: 857.7084093093872 and batch: 1650, loss is 3.6126900005340574 and perplexity is 37.06562538172234
At time: 858.8739030361176 and batch: 1700, loss is 3.6288748216629028 and perplexity is 37.67040683665067
At time: 860.0403244495392 and batch: 1750, loss is 3.6283329725265503 and perplexity is 37.650000688266395
At time: 861.2068665027618 and batch: 1800, loss is 3.558257360458374 and perplexity is 35.10197372801887
At time: 862.371707201004 and batch: 1850, loss is 3.5879075002670286 and perplexity is 36.158335403424154
At time: 863.5388903617859 and batch: 1900, loss is 3.672682356834412 and perplexity is 39.357334814076154
At time: 864.7048125267029 and batch: 1950, loss is 3.627360472679138 and perplexity is 37.613403866428115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366678211300872 and perplexity of 78.78150106936455
finished 18 epochs...
Completing Train Step...
At time: 868.370893239975 and batch: 50, loss is 3.8414135122299196 and perplexity is 46.59128526816045
At time: 869.5604867935181 and batch: 100, loss is 3.823348250389099 and perplexity is 45.757158544034795
At time: 870.727358341217 and batch: 150, loss is 3.772766876220703 and perplexity is 43.500258309250746
At time: 871.8949451446533 and batch: 200, loss is 3.785517244338989 and perplexity is 44.058453651765014
At time: 873.0619242191315 and batch: 250, loss is 3.78216269493103 and perplexity is 43.91090501011987
At time: 874.2274439334869 and batch: 300, loss is 3.798310055732727 and perplexity is 44.625705778200384
At time: 875.3942086696625 and batch: 350, loss is 3.8151884508132934 and perplexity is 45.38530847539131
At time: 876.5614428520203 and batch: 400, loss is 3.804050850868225 and perplexity is 44.882629580694186
At time: 877.7269220352173 and batch: 450, loss is 3.8253435850143434 and perplexity is 45.8485505353108
At time: 878.8929493427277 and batch: 500, loss is 3.840024862289429 and perplexity is 46.52663118398014
At time: 880.0601003170013 and batch: 550, loss is 3.81092915058136 and perplexity is 45.19240991853427
At time: 881.2270522117615 and batch: 600, loss is 3.7689911794662474 and perplexity is 43.33632420262381
At time: 882.3947937488556 and batch: 650, loss is 3.785679020881653 and perplexity is 44.06558185264421
At time: 883.5612914562225 and batch: 700, loss is 3.814757308959961 and perplexity is 45.365745186960424
At time: 884.7285375595093 and batch: 750, loss is 3.7709361600875853 and perplexity is 43.42069453613238
At time: 885.8953964710236 and batch: 800, loss is 3.7350322580337525 and perplexity is 41.889376810239334
At time: 887.0608832836151 and batch: 850, loss is 3.741762523651123 and perplexity is 42.17225429524538
At time: 888.2267272472382 and batch: 900, loss is 3.7062158727645875 and perplexity is 40.69950266190142
At time: 889.3917047977448 and batch: 950, loss is 3.8169665145874023 and perplexity is 45.466078233879436
At time: 890.5587873458862 and batch: 1000, loss is 3.787389349937439 and perplexity is 44.1410129852881
At time: 891.7250535488129 and batch: 1050, loss is 3.735644106864929 and perplexity is 41.915014618911215
At time: 892.8917229175568 and batch: 1100, loss is 3.7531691694259646 and perplexity is 42.65605227195988
At time: 894.058315038681 and batch: 1150, loss is 3.727145357131958 and perplexity is 41.56029885491722
At time: 895.2479667663574 and batch: 1200, loss is 3.774384560585022 and perplexity is 43.57068494563741
At time: 896.4153444766998 and batch: 1250, loss is 3.753740816116333 and perplexity is 42.680443433964626
At time: 897.5810351371765 and batch: 1300, loss is 3.7473980808258056 and perplexity is 42.410589390255446
At time: 898.7477989196777 and batch: 1350, loss is 3.618722467422485 and perplexity is 37.289898318950804
At time: 899.9149851799011 and batch: 1400, loss is 3.6525767278671264 and perplexity is 38.5739326297779
At time: 901.0810463428497 and batch: 1450, loss is 3.572239065170288 and perplexity is 35.59620621447854
At time: 902.2463557720184 and batch: 1500, loss is 3.5671396255493164 and perplexity is 35.41514755137059
At time: 903.4125697612762 and batch: 1550, loss is 3.5709155559539796 and perplexity is 35.54912547026003
At time: 904.5782341957092 and batch: 1600, loss is 3.6709689331054687 and perplexity is 39.28995676275788
At time: 905.7437951564789 and batch: 1650, loss is 3.612673807144165 and perplexity is 37.065025168458675
At time: 906.9143035411835 and batch: 1700, loss is 3.628949565887451 and perplexity is 37.67322258722733
At time: 908.0824930667877 and batch: 1750, loss is 3.6284436130523683 and perplexity is 37.654166534591056
At time: 909.2485966682434 and batch: 1800, loss is 3.5584075117111205 and perplexity is 35.10724472906181
At time: 910.4305188655853 and batch: 1850, loss is 3.588094892501831 and perplexity is 36.16511182960713
At time: 911.5979425907135 and batch: 1900, loss is 3.6728157138824464 and perplexity is 39.36258374204846
At time: 912.7658004760742 and batch: 1950, loss is 3.627371225357056 and perplexity is 37.61380831341972
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366590207122093 and perplexity of 78.77456827312196
finished 19 epochs...
Completing Train Step...
At time: 916.3930585384369 and batch: 50, loss is 3.8397327613830567 and perplexity is 46.513042697542076
At time: 917.5809388160706 and batch: 100, loss is 3.821373291015625 and perplexity is 45.66687919323404
At time: 918.7498412132263 and batch: 150, loss is 3.770699157714844 and perplexity is 43.410404947877815
At time: 919.9162895679474 and batch: 200, loss is 3.78329692363739 and perplexity is 43.960738274921894
At time: 921.0786325931549 and batch: 250, loss is 3.7797708320617676 and perplexity is 43.80600165410425
At time: 922.2448434829712 and batch: 300, loss is 3.7959191179275513 and perplexity is 44.51913594286467
At time: 923.4080500602722 and batch: 350, loss is 3.812813024520874 and perplexity is 45.27762696572802
At time: 924.5974252223969 and batch: 400, loss is 3.8017248582839964 and perplexity is 44.77835423598097
At time: 925.7637670040131 and batch: 450, loss is 3.823136124610901 and perplexity is 45.74745330057306
At time: 926.9307839870453 and batch: 500, loss is 3.8379063177108765 and perplexity is 46.42816677917009
At time: 928.0942590236664 and batch: 550, loss is 3.8087439250946047 and perplexity is 45.09376213565239
At time: 929.2567672729492 and batch: 600, loss is 3.7669978094100953 and perplexity is 43.250024913400125
At time: 930.4193370342255 and batch: 650, loss is 3.7837261390686034 and perplexity is 43.979610952089416
At time: 931.5847866535187 and batch: 700, loss is 3.812873406410217 and perplexity is 45.28036099693134
At time: 932.748553276062 and batch: 750, loss is 3.769096121788025 and perplexity is 43.340872255740386
At time: 933.9126772880554 and batch: 800, loss is 3.7332970571517943 and perplexity is 41.816753353019
At time: 935.0758366584778 and batch: 850, loss is 3.7399596881866457 and perplexity is 42.096293152879824
At time: 936.2382340431213 and batch: 900, loss is 3.7044154977798462 and perplexity is 40.62629421651891
At time: 937.4022026062012 and batch: 950, loss is 3.815206446647644 and perplexity is 45.386125229233656
At time: 938.5675959587097 and batch: 1000, loss is 3.785589962005615 and perplexity is 44.061657596199986
At time: 939.7306842803955 and batch: 1050, loss is 3.733922119140625 and perplexity is 41.84289958669341
At time: 940.8948194980621 and batch: 1100, loss is 3.751542959213257 and perplexity is 42.58674093679681
At time: 942.0586521625519 and batch: 1150, loss is 3.7256469440460207 and perplexity is 41.498070992422335
At time: 943.2240831851959 and batch: 1200, loss is 3.7729233598709104 and perplexity is 43.507065921082024
At time: 944.3881039619446 and batch: 1250, loss is 3.752442269325256 and perplexity is 42.62505684992006
At time: 945.5512249469757 and batch: 1300, loss is 3.746277775764465 and perplexity is 42.363103196785154
At time: 946.715363740921 and batch: 1350, loss is 3.6177404594421385 and perplexity is 37.253297315395386
At time: 947.8819494247437 and batch: 1400, loss is 3.6517038345336914 and perplexity is 38.54027639243061
At time: 949.0468149185181 and batch: 1450, loss is 3.5715836906433105 and perplexity is 35.57288501056477
At time: 950.2126588821411 and batch: 1500, loss is 3.566631908416748 and perplexity is 35.397171238033614
At time: 951.3777151107788 and batch: 1550, loss is 3.5704600954055787 and perplexity is 35.532937932750364
At time: 952.5474290847778 and batch: 1600, loss is 3.6706321954727175 and perplexity is 39.276728583064646
At time: 953.710102558136 and batch: 1650, loss is 3.6124224424362184 and perplexity is 37.055709500096356
At time: 954.878858089447 and batch: 1700, loss is 3.628781142234802 and perplexity is 37.66687805977138
At time: 956.0478231906891 and batch: 1750, loss is 3.6283198022842407 and perplexity is 37.649504831899655
At time: 957.2110593318939 and batch: 1800, loss is 3.558341693878174 and perplexity is 35.10493412233342
At time: 958.3819713592529 and batch: 1850, loss is 3.588069758415222 and perplexity is 36.16420286397724
At time: 959.5580453872681 and batch: 1900, loss is 3.6727761220932007 and perplexity is 39.36102533777898
At time: 960.7316823005676 and batch: 1950, loss is 3.627253866195679 and perplexity is 37.60939424744047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366592762082122 and perplexity of 78.77476953925228
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f1288f88b38>
ELAPSED
2969.458331823349


RESULTS SO FAR:
[{'best_accuracy': -78.41160778879484, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}}, {'best_accuracy': -78.90825503473185, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.10008266219030648, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.21726970941698143, 'batch_size': 32}}, {'best_accuracy': -78.77456827312196, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.6593070000175439, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.4915447901082358, 'batch_size': 32}}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.4010388534776912, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.9900218516510327, 'batch_size': 32}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.744795799255371 and batch: 50, loss is 9.890640487670899 and perplexity is 19744.702128192548
At time: 2.970456600189209 and batch: 100, loss is 9.130788822174072 and perplexity is 9235.304109315717
At time: 4.197675466537476 and batch: 150, loss is 8.53913688659668 and perplexity is 5110.931144194773
At time: 5.418584108352661 and batch: 200, loss is 8.225083179473877 and perplexity is 3733.431935174931
At time: 6.63604736328125 and batch: 250, loss is 7.991317481994629 and perplexity is 2955.187802583907
At time: 7.8526692390441895 and batch: 300, loss is 7.7702675056457515 and perplexity is 2369.1049525473823
At time: 9.069995641708374 and batch: 350, loss is 7.649833631515503 and perplexity is 2100.2961372667187
At time: 10.28746747970581 and batch: 400, loss is 7.531956272125244 and perplexity is 1866.7538122983522
At time: 11.505447626113892 and batch: 450, loss is 7.404426364898682 and perplexity is 1643.241944405643
At time: 12.72201657295227 and batch: 500, loss is 7.333485717773438 and perplexity is 1530.7080999895418
At time: 13.973034143447876 and batch: 550, loss is 7.2541584968566895 and perplexity is 1413.9726399305464
At time: 15.18974757194519 and batch: 600, loss is 7.269360618591309 and perplexity is 1435.6322429587908
At time: 16.40595579147339 and batch: 650, loss is 7.301951513290406 and perplexity is 1483.1915731917168
At time: 17.625096321105957 and batch: 700, loss is 7.147496109008789 and perplexity is 1270.9197234036237
At time: 18.8559787273407 and batch: 750, loss is 7.088373746871948 and perplexity is 1197.9580326345715
At time: 20.08478283882141 and batch: 800, loss is 7.052588615417481 and perplexity is 1155.8469166469724
At time: 21.31529712677002 and batch: 850, loss is 7.056873712539673 and perplexity is 1160.810459980749
At time: 22.545439958572388 and batch: 900, loss is 7.004340772628784 and perplexity is 1101.4037401409141
At time: 23.77556586265564 and batch: 950, loss is 6.980112190246582 and perplexity is 1075.0389691174853
At time: 25.006683349609375 and batch: 1000, loss is 6.953985290527344 and perplexity is 1047.3152778601702
At time: 26.235636472702026 and batch: 1050, loss is 6.849507503509521 and perplexity is 943.416163089298
At time: 27.4644296169281 and batch: 1100, loss is 6.874714336395264 and perplexity is 967.4989468684319
At time: 28.694108963012695 and batch: 1150, loss is 6.780664529800415 and perplexity is 880.6537503635471
At time: 29.923796892166138 and batch: 1200, loss is 6.837874965667725 and perplexity is 932.505421710407
At time: 31.15545153617859 and batch: 1250, loss is 6.762861261367798 and perplexity is 865.1139750952667
At time: 32.38589000701904 and batch: 1300, loss is 6.7770725440979005 and perplexity is 877.496129143577
At time: 33.61584711074829 and batch: 1350, loss is 6.770771617889404 and perplexity is 871.9844732891653
At time: 34.84438872337341 and batch: 1400, loss is 6.764600849151611 and perplexity is 866.6202265464133
At time: 36.07567310333252 and batch: 1450, loss is 6.769552850723267 and perplexity is 870.9223746007126
At time: 37.307666540145874 and batch: 1500, loss is 6.74107174873352 and perplexity is 846.4674502970379
At time: 38.539578914642334 and batch: 1550, loss is 6.723306827545166 and perplexity is 831.5628046622345
At time: 39.770280838012695 and batch: 1600, loss is 6.717335987091064 and perplexity is 826.6124693661532
At time: 41.00146126747131 and batch: 1650, loss is 6.711414403915406 and perplexity is 821.7320789545997
At time: 42.2303261756897 and batch: 1700, loss is 6.731362085342408 and perplexity is 838.288308897057
At time: 43.459705114364624 and batch: 1750, loss is 6.752338895797729 and perplexity is 856.0586548350067
At time: 44.69135785102844 and batch: 1800, loss is 6.75340651512146 and perplexity is 856.9730876433671
At time: 45.923182010650635 and batch: 1850, loss is 6.704098644256592 and perplexity is 815.7424207250749
At time: 47.15261363983154 and batch: 1900, loss is 6.686711120605469 and perplexity is 801.6812785646928
At time: 48.384753704071045 and batch: 1950, loss is 6.645664520263672 and perplexity is 769.4411870424105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.4628122728924415 and perplexity of 640.8608001544443
finished 1 epochs...
Completing Train Step...
At time: 52.06249213218689 and batch: 50, loss is 6.655942430496216 and perplexity is 777.3902142111012
At time: 53.252411127090454 and batch: 100, loss is 6.351078701019287 and perplexity is 573.1105906772951
At time: 54.416759967803955 and batch: 150, loss is 6.0542636966705325 and perplexity is 425.9251798421528
At time: 55.603546380996704 and batch: 200, loss is 5.919861326217651 and perplexity is 372.3600737158789
At time: 56.76900267601013 and batch: 250, loss is 5.832815465927124 and perplexity is 341.3182975883986
At time: 57.937177419662476 and batch: 300, loss is 5.7598002243041995 and perplexity is 317.28493676694615
At time: 59.105024337768555 and batch: 350, loss is 5.694677076339722 and perplexity is 297.2807790869525
At time: 60.27035045623779 and batch: 400, loss is 5.63253867149353 and perplexity is 279.3704479359521
At time: 61.43546676635742 and batch: 450, loss is 5.543443393707276 and perplexity is 255.55646766722595
At time: 62.59922385215759 and batch: 500, loss is 5.511279773712158 and perplexity is 247.4676270639653
At time: 63.76550054550171 and batch: 550, loss is 5.460057201385498 and perplexity is 235.1108726482659
At time: 64.93140935897827 and batch: 600, loss is 5.472815999984741 and perplexity is 238.12982305730475
At time: 66.09791994094849 and batch: 650, loss is 5.552879209518433 and perplexity is 257.9792639793225
At time: 67.26386427879333 and batch: 700, loss is 5.470216226577759 and perplexity is 237.5115435175006
At time: 68.4280652999878 and batch: 750, loss is 5.401266260147095 and perplexity is 221.68695190344081
At time: 69.59380602836609 and batch: 800, loss is 5.380043048858642 and perplexity is 217.03161818730064
At time: 70.75773119926453 and batch: 850, loss is 5.391579542160034 and perplexity is 219.5499001382119
At time: 71.92231488227844 and batch: 900, loss is 5.405486249923706 and perplexity is 222.62444528906877
At time: 73.08875131607056 and batch: 950, loss is 5.42888934135437 and perplexity is 227.89599015818905
At time: 74.2559585571289 and batch: 1000, loss is 5.391333990097046 and perplexity is 219.49599582573242
At time: 75.42203521728516 and batch: 1050, loss is 5.295956916809082 and perplexity is 199.52846678637232
At time: 76.58729934692383 and batch: 1100, loss is 5.379024562835693 and perplexity is 216.81068704437726
At time: 77.75255703926086 and batch: 1150, loss is 5.27799207687378 and perplexity is 195.9759753306098
At time: 78.917551279068 and batch: 1200, loss is 5.33900149345398 and perplexity is 208.3046128935397
At time: 80.08252382278442 and batch: 1250, loss is 5.267418985366821 and perplexity is 193.91481900887212
At time: 81.2487051486969 and batch: 1300, loss is 5.292781467437744 and perplexity is 198.89587914851685
At time: 82.4150218963623 and batch: 1350, loss is 5.2339763355255124 and perplexity is 187.5370330532819
At time: 83.57992124557495 and batch: 1400, loss is 5.229254684448242 and perplexity is 186.65363580712074
At time: 84.74714660644531 and batch: 1450, loss is 5.16465461730957 and perplexity is 174.97701410226773
At time: 85.91140007972717 and batch: 1500, loss is 5.136490592956543 and perplexity is 170.11770723524754
At time: 87.07729697227478 and batch: 1550, loss is 5.134364280700684 and perplexity is 169.7563681654016
At time: 88.2430031299591 and batch: 1600, loss is 5.174829721450806 and perplexity is 176.76651216839525
At time: 89.41462659835815 and batch: 1650, loss is 5.146599941253662 and perplexity is 171.84620867987346
At time: 90.58108353614807 and batch: 1700, loss is 5.15209023475647 and perplexity is 172.79228955721717
At time: 91.74762034416199 and batch: 1750, loss is 5.167403364181519 and perplexity is 175.4586432575111
At time: 92.91307258605957 and batch: 1800, loss is 5.143000602722168 and perplexity is 171.22878781939687
At time: 94.07943987846375 and batch: 1850, loss is 5.117594041824341 and perplexity is 166.93325165396868
At time: 95.24509024620056 and batch: 1900, loss is 5.159370470046997 and perplexity is 174.05484836769824
At time: 96.41045904159546 and batch: 1950, loss is 5.07636474609375 and perplexity is 160.1906624479493
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.857242460029069 and perplexity of 128.66890281399333
finished 2 epochs...
Completing Train Step...
At time: 100.11083841323853 and batch: 50, loss is 5.094261970520019 and perplexity is 163.08343981242422
At time: 101.30072045326233 and batch: 100, loss is 5.052291412353515 and perplexity is 156.38038620546158
At time: 102.4643201828003 and batch: 150, loss is 4.988919591903686 and perplexity is 146.77775792132618
At time: 103.62849855422974 and batch: 200, loss is 4.9664770698547365 and perplexity is 143.520383420543
At time: 104.7917685508728 and batch: 250, loss is 4.978727416992188 and perplexity is 145.28937117301072
At time: 105.95554280281067 and batch: 300, loss is 5.006618919372559 and perplexity is 149.3987520182844
At time: 107.11981248855591 and batch: 350, loss is 4.9893528079986575 and perplexity is 146.8413581837755
At time: 108.28494834899902 and batch: 400, loss is 4.95998797416687 and perplexity is 142.59208109810518
At time: 109.44870376586914 and batch: 450, loss is 4.931956939697265 and perplexity is 138.65057784386318
At time: 110.61229920387268 and batch: 500, loss is 4.934581747055054 and perplexity is 139.0149869433724
At time: 111.77655720710754 and batch: 550, loss is 4.888784923553467 and perplexity is 132.79212340227505
At time: 112.94012665748596 and batch: 600, loss is 4.871659135818481 and perplexity is 130.53731646607673
At time: 114.12625503540039 and batch: 650, loss is 4.945740737915039 and perplexity is 140.57494148380914
At time: 115.28998875617981 and batch: 700, loss is 4.935325365066529 and perplexity is 139.11839943645936
At time: 116.45350074768066 and batch: 750, loss is 4.894188899993896 and perplexity is 133.51167136766512
At time: 117.61671042442322 and batch: 800, loss is 4.870852031707764 and perplexity is 130.4320017670352
At time: 118.78349447250366 and batch: 850, loss is 4.875330333709717 and perplexity is 131.017425535486
At time: 119.94905066490173 and batch: 900, loss is 4.894738693237304 and perplexity is 133.58509536465843
At time: 121.11379790306091 and batch: 950, loss is 4.9439092540740965 and perplexity is 140.31771637375792
At time: 122.27743554115295 and batch: 1000, loss is 4.916012525558472 and perplexity is 136.45740648924715
At time: 123.44279789924622 and batch: 1050, loss is 4.826060123443604 and perplexity is 124.71861545281115
At time: 124.60567855834961 and batch: 1100, loss is 4.9008731937408445 and perplexity is 134.40709189070375
At time: 125.77098345756531 and batch: 1150, loss is 4.814723510742187 and perplexity is 123.3127129558591
At time: 126.9349594116211 and batch: 1200, loss is 4.890981760025024 and perplexity is 133.08416665027772
At time: 128.09912395477295 and batch: 1250, loss is 4.8439184665679935 and perplexity is 126.96588985543085
At time: 129.26370334625244 and batch: 1300, loss is 4.8785780334472655 and perplexity is 131.44362249928446
At time: 130.4268171787262 and batch: 1350, loss is 4.7888593673706055 and perplexity is 120.16422722562557
At time: 131.59062337875366 and batch: 1400, loss is 4.790169649124145 and perplexity is 120.32177941632689
At time: 132.75498390197754 and batch: 1450, loss is 4.728974180221558 and perplexity is 113.17940111042714
At time: 133.91843485832214 and batch: 1500, loss is 4.715535945892334 and perplexity is 111.6686434896147
At time: 135.08230090141296 and batch: 1550, loss is 4.718270645141602 and perplexity is 111.97444158746885
At time: 136.2462124824524 and batch: 1600, loss is 4.7889718914031985 and perplexity is 120.17774934981412
At time: 137.40838432312012 and batch: 1650, loss is 4.753130702972412 and perplexity is 115.94671162008822
At time: 138.5716872215271 and batch: 1700, loss is 4.778957986831665 and perplexity is 118.98030638244983
At time: 139.73597359657288 and batch: 1750, loss is 4.775051126480102 and perplexity is 118.51637379085636
At time: 140.89925622940063 and batch: 1800, loss is 4.743479948043824 and perplexity is 114.83312046218292
At time: 142.06233310699463 and batch: 1850, loss is 4.744835290908814 and perplexity is 114.98886423192823
At time: 143.22579836845398 and batch: 1900, loss is 4.8079038429260255 and perplexity is 122.47462221436753
At time: 144.39098644256592 and batch: 1950, loss is 4.744449834823609 and perplexity is 114.94454961569717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.662549963662791 and perplexity of 105.90579405926813
finished 3 epochs...
Completing Train Step...
At time: 148.08524298667908 and batch: 50, loss is 4.744611530303955 and perplexity is 114.96313713257872
At time: 149.25064134597778 and batch: 100, loss is 4.697662487030029 and perplexity is 109.6904696504538
At time: 150.41860222816467 and batch: 150, loss is 4.645551815032959 and perplexity is 104.12080536158926
At time: 151.59510469436646 and batch: 200, loss is 4.641347370147705 and perplexity is 103.68395417593581
At time: 152.77297806739807 and batch: 250, loss is 4.653179292678833 and perplexity is 104.91802098406686
At time: 153.9396448135376 and batch: 300, loss is 4.68220272064209 and perplexity is 108.00772157594804
At time: 155.10903692245483 and batch: 350, loss is 4.685920925140381 and perplexity is 108.41006390415585
At time: 156.2769570350647 and batch: 400, loss is 4.650040645599365 and perplexity is 104.58923658292929
At time: 157.44284749031067 and batch: 450, loss is 4.638526420593262 and perplexity is 103.39187912977448
At time: 158.61074042320251 and batch: 500, loss is 4.652672481536865 and perplexity is 104.86486083425496
At time: 159.77812504768372 and batch: 550, loss is 4.608431549072265 and perplexity is 100.326668711505
At time: 160.94550156593323 and batch: 600, loss is 4.579096384048462 and perplexity is 97.42631844426904
At time: 162.11250185966492 and batch: 650, loss is 4.649270181655884 and perplexity is 104.50868538214853
At time: 163.27841901779175 and batch: 700, loss is 4.657562503814697 and perplexity is 105.3789081670125
At time: 164.44592761993408 and batch: 750, loss is 4.624208145141601 and perplexity is 101.92203366243398
At time: 165.6143193244934 and batch: 800, loss is 4.598679752349853 and perplexity is 99.35305837309717
At time: 166.7811529636383 and batch: 850, loss is 4.6073111724853515 and perplexity is 100.21432800453773
At time: 167.94882559776306 and batch: 900, loss is 4.608624353408813 and perplexity is 100.34601399317114
At time: 169.11597514152527 and batch: 950, loss is 4.671667423248291 and perplexity is 106.87580113707996
At time: 170.28279495239258 and batch: 1000, loss is 4.651306085586548 and perplexity is 104.721671761843
At time: 171.4733064174652 and batch: 1050, loss is 4.5713384819030765 and perplexity is 96.67341883623973
At time: 172.64144110679626 and batch: 1100, loss is 4.639318170547486 and perplexity is 103.47377206042661
At time: 173.80857110023499 and batch: 1150, loss is 4.563970832824707 and perplexity is 95.96378040457812
At time: 174.9772448539734 and batch: 1200, loss is 4.643767929077148 and perplexity is 103.93523128989908
At time: 176.14303493499756 and batch: 1250, loss is 4.610578756332398 and perplexity is 100.54232230657387
At time: 177.31039810180664 and batch: 1300, loss is 4.634870643615723 and perplexity is 103.01459153822755
At time: 178.48330569267273 and batch: 1350, loss is 4.529917554855347 and perplexity is 92.75091390436617
At time: 179.65225267410278 and batch: 1400, loss is 4.538759450912476 and perplexity is 93.57464414636623
At time: 180.81983518600464 and batch: 1450, loss is 4.475012989044189 and perplexity is 87.79574078510528
At time: 181.98942923545837 and batch: 1500, loss is 4.465452728271484 and perplexity is 86.96039005634856
At time: 183.15738081932068 and batch: 1550, loss is 4.468466558456421 and perplexity is 87.2228692399589
At time: 184.3236026763916 and batch: 1600, loss is 4.557780771255493 and perplexity is 95.37159342329096
At time: 185.48958277702332 and batch: 1650, loss is 4.507879314422607 and perplexity is 90.7292062285745
At time: 186.65754413604736 and batch: 1700, loss is 4.542266178131103 and perplexity is 93.90336092114215
At time: 187.82396268844604 and batch: 1750, loss is 4.541999082565308 and perplexity is 93.87828309906347
At time: 188.9917459487915 and batch: 1800, loss is 4.494826278686523 and perplexity is 89.5526104366485
At time: 190.15943670272827 and batch: 1850, loss is 4.517062740325928 and perplexity is 91.56624874753862
At time: 191.3267993927002 and batch: 1900, loss is 4.592916898727417 and perplexity is 98.78214785763458
At time: 192.49186944961548 and batch: 1950, loss is 4.5188875579833985 and perplexity is 91.73349300380774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.579506949491279 and perplexity of 97.46632653625112
finished 4 epochs...
Completing Train Step...
At time: 196.1877942085266 and batch: 50, loss is 4.515577630996704 and perplexity is 91.43036378427006
At time: 197.35379242897034 and batch: 100, loss is 4.468077630996704 and perplexity is 87.18895246700588
At time: 198.519305229187 and batch: 150, loss is 4.420295715332031 and perplexity is 83.12086183760084
At time: 199.6842966079712 and batch: 200, loss is 4.428181934356689 and perplexity is 83.77896271265234
At time: 200.87151622772217 and batch: 250, loss is 4.435949850082397 and perplexity is 84.43228482500062
At time: 202.03511667251587 and batch: 300, loss is 4.463826465606689 and perplexity is 86.81908455176007
At time: 203.1991322040558 and batch: 350, loss is 4.46501501083374 and perplexity is 86.92233430666813
At time: 204.3633451461792 and batch: 400, loss is 4.427892026901245 and perplexity is 83.75467808706964
At time: 205.5274739265442 and batch: 450, loss is 4.428570327758789 and perplexity is 83.81150822882742
At time: 206.69114470481873 and batch: 500, loss is 4.452397756576538 and perplexity is 85.83250291194064
At time: 207.85613417625427 and batch: 550, loss is 4.405749263763428 and perplexity is 81.92049991605047
At time: 209.0202853679657 and batch: 600, loss is 4.382536053657532 and perplexity is 80.04076390076291
At time: 210.18447518348694 and batch: 650, loss is 4.44571008682251 and perplexity is 85.26039863282101
At time: 211.34875631332397 and batch: 700, loss is 4.460709323883057 and perplexity is 86.54887851494155
At time: 212.51197052001953 and batch: 750, loss is 4.433515386581421 and perplexity is 84.22698750509933
At time: 213.67643523216248 and batch: 800, loss is 4.401664161682129 and perplexity is 81.58652892857423
At time: 214.83955430984497 and batch: 850, loss is 4.412346477508545 and perplexity is 82.46273361325828
At time: 216.00275468826294 and batch: 900, loss is 4.400248165130615 and perplexity is 81.47108443875041
At time: 217.16670942306519 and batch: 950, loss is 4.476802320480346 and perplexity is 87.95297709603776
At time: 218.33091473579407 and batch: 1000, loss is 4.453048515319824 and perplexity is 85.88837734208386
At time: 219.49475932121277 and batch: 1050, loss is 4.385169763565063 and perplexity is 80.25184589601292
At time: 220.65906834602356 and batch: 1100, loss is 4.449156122207642 and perplexity is 85.55471580590135
At time: 221.8227264881134 and batch: 1150, loss is 4.375023584365845 and perplexity is 79.44171311259329
At time: 222.98801851272583 and batch: 1200, loss is 4.462205762863159 and perplexity is 86.67849058452505
At time: 224.1512370109558 and batch: 1250, loss is 4.430100011825561 and perplexity is 83.93981146426631
At time: 225.3164360523224 and batch: 1300, loss is 4.448036260604859 and perplexity is 85.45895999137048
At time: 226.48238158226013 and batch: 1350, loss is 4.330725035667419 and perplexity is 75.99936885158344
At time: 227.64838123321533 and batch: 1400, loss is 4.3540818309783935 and perplexity is 77.79536324215414
At time: 228.81324172019958 and batch: 1450, loss is 4.282826533317566 and perplexity is 72.4449188648968
At time: 229.97984862327576 and batch: 1500, loss is 4.275943832397461 and perplexity is 71.94801414006677
At time: 231.1479458808899 and batch: 1550, loss is 4.283777837753296 and perplexity is 72.51386882856234
At time: 232.3171887397766 and batch: 1600, loss is 4.3749790859222415 and perplexity is 79.43817815865313
At time: 233.48151445388794 and batch: 1650, loss is 4.329236664772034 and perplexity is 75.88633773989152
At time: 234.6441192626953 and batch: 1700, loss is 4.3534117603302 and perplexity is 77.74325231363164
At time: 235.80689883232117 and batch: 1750, loss is 4.361052808761596 and perplexity is 78.33956760543649
At time: 236.9714982509613 and batch: 1800, loss is 4.3072943592071535 and perplexity is 74.23935194176498
At time: 238.13592886924744 and batch: 1850, loss is 4.348997173309326 and perplexity is 77.40080440021602
At time: 239.31435108184814 and batch: 1900, loss is 4.426497879028321 and perplexity is 83.6379930377733
At time: 240.4888939857483 and batch: 1950, loss is 4.350302963256836 and perplexity is 77.50193960883004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.535502021257267 and perplexity of 93.2703272400941
finished 5 epochs...
Completing Train Step...
At time: 244.1754448413849 and batch: 50, loss is 4.337002992630005 and perplexity is 76.47799042926894
At time: 245.34178018569946 and batch: 100, loss is 4.292348566055298 and perplexity is 73.13803646121073
At time: 246.50802087783813 and batch: 150, loss is 4.248865909576416 and perplexity is 70.02595153629277
At time: 247.67355823516846 and batch: 200, loss is 4.261050148010254 and perplexity is 70.88438347618724
At time: 248.83804512023926 and batch: 250, loss is 4.264513301849365 and perplexity is 71.13029256568501
At time: 250.00290155410767 and batch: 300, loss is 4.286041555404663 and perplexity is 72.67820568934717
At time: 251.17112064361572 and batch: 350, loss is 4.289971981048584 and perplexity is 72.96442408433825
At time: 252.33647108078003 and batch: 400, loss is 4.252961382865906 and perplexity is 70.31332902210994
At time: 253.50223183631897 and batch: 450, loss is 4.268037748336792 and perplexity is 71.38142977533299
At time: 254.66901683807373 and batch: 500, loss is 4.294920625686646 and perplexity is 73.32639398185643
At time: 255.83402132987976 and batch: 550, loss is 4.245263090133667 and perplexity is 69.77411461049715
At time: 257.0023102760315 and batch: 600, loss is 4.22316611289978 and perplexity is 68.24922733484277
At time: 258.1855425834656 and batch: 650, loss is 4.282997426986694 and perplexity is 72.45730030081566
At time: 259.3846061229706 and batch: 700, loss is 4.302096128463745 and perplexity is 73.85443995753006
At time: 260.55163311958313 and batch: 750, loss is 4.2768697261810305 and perplexity is 72.0146612083911
At time: 261.7179102897644 and batch: 800, loss is 4.245877213478089 and perplexity is 69.81697768337548
At time: 262.8879978656769 and batch: 850, loss is 4.2500102186203 and perplexity is 70.10612873093784
At time: 264.0551064014435 and batch: 900, loss is 4.240626001358033 and perplexity is 69.4513148507973
At time: 265.222993850708 and batch: 950, loss is 4.326675691604614 and perplexity is 75.69224350630992
At time: 266.39008927345276 and batch: 1000, loss is 4.3029537105560305 and perplexity is 73.91780336845329
At time: 267.55622839927673 and batch: 1050, loss is 4.236723546981811 and perplexity is 69.18081241821783
At time: 268.7240297794342 and batch: 1100, loss is 4.288292732238769 and perplexity is 72.84200147981032
At time: 269.89116382598877 and batch: 1150, loss is 4.223383374214173 and perplexity is 68.26405686256282
At time: 271.05763125419617 and batch: 1200, loss is 4.305404124259948 and perplexity is 74.09915466890271
At time: 272.2244653701782 and batch: 1250, loss is 4.286624093055725 and perplexity is 72.72055581464647
At time: 273.3912296295166 and batch: 1300, loss is 4.293662204742431 and perplexity is 73.23417654825066
At time: 274.55775141716003 and batch: 1350, loss is 4.172796773910522 and perplexity is 64.89669993191563
At time: 275.7251126766205 and batch: 1400, loss is 4.201987242698669 and perplexity is 66.81898472926846
At time: 276.89055466651917 and batch: 1450, loss is 4.1277573823928835 and perplexity is 62.038637869958656
At time: 278.0563323497772 and batch: 1500, loss is 4.1220544862747195 and perplexity is 61.68584488988953
At time: 279.2222762107849 and batch: 1550, loss is 4.131106247901917 and perplexity is 62.246745191773
At time: 280.39054441452026 and batch: 1600, loss is 4.2253551149368285 and perplexity is 68.39878866781554
At time: 281.55592799186707 and batch: 1650, loss is 4.178170070648194 and perplexity is 65.24634769728254
At time: 282.7218475341797 and batch: 1700, loss is 4.202652096748352 and perplexity is 66.86342437316306
At time: 283.8869671821594 and batch: 1750, loss is 4.213873038291931 and perplexity is 67.61792010923219
At time: 285.0510950088501 and batch: 1800, loss is 4.158435955047607 and perplexity is 63.971390184633734
At time: 286.2155773639679 and batch: 1850, loss is 4.210175695419312 and perplexity is 67.3683750852933
At time: 287.38107800483704 and batch: 1900, loss is 4.2849413108825685 and perplexity is 72.59828586539824
At time: 288.54617834091187 and batch: 1950, loss is 4.2050262594223025 and perplexity is 67.02235761158926
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.524402991006541 and perplexity of 92.24084077565068
finished 6 epochs...
Completing Train Step...
At time: 292.1727662086487 and batch: 50, loss is 4.188544898033142 and perplexity is 65.92679092928164
At time: 293.3578100204468 and batch: 100, loss is 4.146444053649902 and perplexity is 63.20883297501689
At time: 294.5214376449585 and batch: 150, loss is 4.107058835029602 and perplexity is 60.767726568905765
At time: 295.68680596351624 and batch: 200, loss is 4.1232576131820675 and perplexity is 61.7601054531622
At time: 296.8495132923126 and batch: 250, loss is 4.119244213104248 and perplexity is 61.51273417312946
At time: 298.0152838230133 and batch: 300, loss is 4.140654020309448 and perplexity is 62.843909204568746
At time: 299.18025040626526 and batch: 350, loss is 4.141671471595764 and perplexity is 62.90788236009195
At time: 300.343811750412 and batch: 400, loss is 4.112742319107055 and perplexity is 61.114082296583724
At time: 301.5065960884094 and batch: 450, loss is 4.1313639879226685 and perplexity is 62.262790736871196
At time: 302.67210936546326 and batch: 500, loss is 4.159707250595093 and perplexity is 64.0527684450918
At time: 303.8378040790558 and batch: 550, loss is 4.1135150861740115 and perplexity is 61.16132749912696
At time: 305.00301694869995 and batch: 600, loss is 4.088357706069946 and perplexity is 59.64186176164045
At time: 306.166552066803 and batch: 650, loss is 4.149989800453186 and perplexity is 63.43335330336722
At time: 307.33055114746094 and batch: 700, loss is 4.172534966468811 and perplexity is 64.87971171684858
At time: 308.4935841560364 and batch: 750, loss is 4.147235107421875 and perplexity is 63.25885434295122
At time: 309.6560366153717 and batch: 800, loss is 4.112375130653382 and perplexity is 61.09164603062854
At time: 310.8190631866455 and batch: 850, loss is 4.120027565956116 and perplexity is 61.560939227188406
At time: 311.9840474128723 and batch: 900, loss is 4.106704502105713 and perplexity is 60.74619837697135
At time: 313.14833545684814 and batch: 950, loss is 4.197013845443726 and perplexity is 66.48749237889002
At time: 314.3136661052704 and batch: 1000, loss is 4.172204937934875 and perplexity is 64.85830309363105
At time: 315.47850918769836 and batch: 1050, loss is 4.108658561706543 and perplexity is 60.86501611979203
At time: 316.68542194366455 and batch: 1100, loss is 4.152633671760559 and perplexity is 63.601284822938666
At time: 317.8502082824707 and batch: 1150, loss is 4.097519154548645 and perplexity is 60.19077820087651
At time: 319.01956129074097 and batch: 1200, loss is 4.178767600059509 and perplexity is 65.28534595915649
At time: 320.18574023246765 and batch: 1250, loss is 4.1598849201202395 and perplexity is 64.0641496810652
At time: 321.34995770454407 and batch: 1300, loss is 4.165946726799011 and perplexity is 64.45367358801187
At time: 322.51550698280334 and batch: 1350, loss is 4.045292024612427 and perplexity is 57.127866341523365
At time: 323.68082571029663 and batch: 1400, loss is 4.077586803436279 and perplexity is 59.00291228417694
At time: 324.8464312553406 and batch: 1450, loss is 3.9994847679138186 and perplexity is 54.57002656008101
At time: 326.01143765449524 and batch: 1500, loss is 4.0041102695465085 and perplexity is 54.82302497824822
At time: 327.176561832428 and batch: 1550, loss is 4.0060622501373295 and perplexity is 54.93014297104529
At time: 328.3410863876343 and batch: 1600, loss is 4.10462718963623 and perplexity is 60.62014051772132
At time: 329.50550413131714 and batch: 1650, loss is 4.051713652610779 and perplexity is 57.495900672562684
At time: 330.6699924468994 and batch: 1700, loss is 4.078204393386841 and perplexity is 59.03936314454144
At time: 331.83459877967834 and batch: 1750, loss is 4.093997287750244 and perplexity is 59.97916714925658
At time: 332.99817633628845 and batch: 1800, loss is 4.032916822433472 and perplexity is 56.42525389782928
At time: 334.1638195514679 and batch: 1850, loss is 4.0834898757934575 and perplexity is 59.35224078598714
At time: 335.32773184776306 and batch: 1900, loss is 4.166289868354798 and perplexity is 64.47579411686232
At time: 336.4917457103729 and batch: 1950, loss is 4.088758025169373 and perplexity is 59.66574231763143
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.510364621184593 and perplexity of 90.95497657639945
finished 7 epochs...
Completing Train Step...
At time: 340.1683397293091 and batch: 50, loss is 4.061559557914734 and perplexity is 58.064795914484506
At time: 341.35865473747253 and batch: 100, loss is 4.023431782722473 and perplexity is 55.89258829458079
At time: 342.52556228637695 and batch: 150, loss is 3.988170886039734 and perplexity is 53.95610718004766
At time: 343.69233441352844 and batch: 200, loss is 4.006420569419861 and perplexity is 54.94982902720015
At time: 344.85979437828064 and batch: 250, loss is 3.996872215270996 and perplexity is 54.42764556288213
At time: 346.04896998405457 and batch: 300, loss is 4.019413795471191 and perplexity is 55.668463154876115
At time: 347.2160220146179 and batch: 350, loss is 4.01872944355011 and perplexity is 55.63037936801512
At time: 348.3825182914734 and batch: 400, loss is 3.988853306770325 and perplexity is 53.992940512614744
At time: 349.54924964904785 and batch: 450, loss is 4.016514806747437 and perplexity is 55.50731460469581
At time: 350.71622252464294 and batch: 500, loss is 4.049258546829224 and perplexity is 57.354915292233215
At time: 351.8807990550995 and batch: 550, loss is 4.003475260734558 and perplexity is 54.78822292526388
At time: 353.04424476623535 and batch: 600, loss is 3.982452144622803 and perplexity is 53.64842676611525
At time: 354.210209608078 and batch: 650, loss is 4.0362475919723515 and perplexity is 56.61350675413529
At time: 355.3757176399231 and batch: 700, loss is 4.058043742179871 and perplexity is 57.861009239482556
At time: 356.5410108566284 and batch: 750, loss is 4.032335629463196 and perplexity is 56.392469464881664
At time: 357.70778822898865 and batch: 800, loss is 3.9980966806411744 and perplexity is 54.494331148817665
At time: 358.883260011673 and batch: 850, loss is 4.0076317739486695 and perplexity is 55.016424831403555
At time: 360.049560546875 and batch: 900, loss is 3.994287223815918 and perplexity is 54.287132255276425
At time: 361.2155923843384 and batch: 950, loss is 4.084124927520752 and perplexity is 59.38994449965419
At time: 362.3822383880615 and batch: 1000, loss is 4.058027949333191 and perplexity is 57.86009545665051
At time: 363.5478069782257 and batch: 1050, loss is 3.9998838806152346 and perplexity is 54.59181049763166
At time: 364.71345615386963 and batch: 1100, loss is 4.0375324058532716 and perplexity is 56.68629132075891
At time: 365.88051867485046 and batch: 1150, loss is 3.9925338363647462 and perplexity is 54.1920292793673
At time: 367.0485632419586 and batch: 1200, loss is 4.069137530326843 and perplexity is 58.50648076015841
At time: 368.21425700187683 and batch: 1250, loss is 4.054803628921508 and perplexity is 57.67383641063586
At time: 369.3797399997711 and batch: 1300, loss is 4.057873992919922 and perplexity is 57.85118820956413
At time: 370.54490876197815 and batch: 1350, loss is 3.9356733846664427 and perplexity is 51.19661336620391
At time: 371.7110242843628 and batch: 1400, loss is 3.970766520500183 and perplexity is 53.02516013836321
At time: 372.8762776851654 and batch: 1450, loss is 3.8925395250320434 and perplexity is 49.03525479572878
At time: 374.03946447372437 and batch: 1500, loss is 3.893484477996826 and perplexity is 49.08161270469909
At time: 375.2048327922821 and batch: 1550, loss is 3.901809024810791 and perplexity is 49.491900246948404
At time: 376.36961698532104 and batch: 1600, loss is 3.9989249324798584 and perplexity is 54.53948487553683
At time: 377.5355987548828 and batch: 1650, loss is 3.9477881145477296 and perplexity is 51.820618704114814
At time: 378.70118618011475 and batch: 1700, loss is 3.9755519151687624 and perplexity is 53.279514564755
At time: 379.86622738838196 and batch: 1750, loss is 3.9844215869903565 and perplexity is 53.75418836224035
At time: 381.0316903591156 and batch: 1800, loss is 3.9238409042358398 and perplexity is 50.59440030375711
At time: 382.19691014289856 and batch: 1850, loss is 3.9747260856628417 and perplexity is 53.235532932730614
At time: 383.3631594181061 and batch: 1900, loss is 4.056944665908813 and perplexity is 57.797450511550906
At time: 384.5293848514557 and batch: 1950, loss is 3.984864869117737 and perplexity is 53.77802191531695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.522927927416425 and perplexity of 92.10487996996996
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 388.17894744873047 and batch: 50, loss is 3.990791907310486 and perplexity is 54.09771277923104
At time: 389.36841654777527 and batch: 100, loss is 3.963302450180054 and perplexity is 52.630850024224365
At time: 390.53102588653564 and batch: 150, loss is 3.937648878097534 and perplexity is 51.29785190471264
At time: 391.6949143409729 and batch: 200, loss is 3.95699387550354 and perplexity is 52.299869481991124
At time: 392.8585093021393 and batch: 250, loss is 3.946040697097778 and perplexity is 51.73014552095488
At time: 394.0234761238098 and batch: 300, loss is 3.973120632171631 and perplexity is 53.15013433061202
At time: 395.1859962940216 and batch: 350, loss is 3.9682836294174195 and perplexity is 52.89366774928515
At time: 396.35013365745544 and batch: 400, loss is 3.9293518590927126 and perplexity is 50.8739934648684
At time: 397.514924287796 and batch: 450, loss is 3.9488429260253906 and perplexity is 51.875308526158626
At time: 398.6790156364441 and batch: 500, loss is 3.976487202644348 and perplexity is 53.329369538164535
At time: 399.84167671203613 and batch: 550, loss is 3.9175860929489135 and perplexity is 50.278929511322666
At time: 401.0059678554535 and batch: 600, loss is 3.8954358100891113 and perplexity is 49.17748073547372
At time: 402.17107629776 and batch: 650, loss is 3.9431283235549928 and perplexity is 51.57970718642167
At time: 403.3327078819275 and batch: 700, loss is 3.9646755027770997 and perplexity is 52.70316458402087
At time: 404.51919651031494 and batch: 750, loss is 3.918195004463196 and perplexity is 50.309554253360695
At time: 405.6839282512665 and batch: 800, loss is 3.880215425491333 and perplexity is 48.43464800538896
At time: 406.84928917884827 and batch: 850, loss is 3.8885955286026 and perplexity is 48.842240799349916
At time: 408.0157322883606 and batch: 900, loss is 3.8713888835906984 and perplexity is 48.00901873593529
At time: 409.1813442707062 and batch: 950, loss is 3.9554426431655885 and perplexity is 52.2188031258126
At time: 410.3471534252167 and batch: 1000, loss is 3.9223519945144654 and perplexity is 50.5191258616281
At time: 411.51382851600647 and batch: 1050, loss is 3.847444033622742 and perplexity is 46.87310391329457
At time: 412.6798093318939 and batch: 1100, loss is 3.8726216888427736 and perplexity is 48.068241003640715
At time: 413.84686946868896 and batch: 1150, loss is 3.819262638092041 and perplexity is 45.57059390930666
At time: 415.01374316215515 and batch: 1200, loss is 3.886598858833313 and perplexity is 48.744816268356324
At time: 416.1879532337189 and batch: 1250, loss is 3.8649716138839723 and perplexity is 47.70191834128132
At time: 417.3517246246338 and batch: 1300, loss is 3.8772717666625978 and perplexity is 48.2922825666128
At time: 418.5179567337036 and batch: 1350, loss is 3.7637265491485596 and perplexity is 43.10877398582582
At time: 419.68358278274536 and batch: 1400, loss is 3.777351965904236 and perplexity is 43.70016884850382
At time: 420.85224175453186 and batch: 1450, loss is 3.6874163913726807 and perplexity is 39.94152028053069
At time: 422.01897048950195 and batch: 1500, loss is 3.674096312522888 and perplexity is 39.41302370305236
At time: 423.1896014213562 and batch: 1550, loss is 3.6798614406585695 and perplexity is 39.64090107488166
At time: 424.3562362194061 and batch: 1600, loss is 3.7674318408966063 and perplexity is 43.268800860386264
At time: 425.524507522583 and batch: 1650, loss is 3.707761888504028 and perplexity is 40.762473397936105
At time: 426.6910128593445 and batch: 1700, loss is 3.7268925952911376 and perplexity is 41.54979532477534
At time: 427.85714292526245 and batch: 1750, loss is 3.7254128360748293 and perplexity is 41.4883571003081
At time: 429.0265188217163 and batch: 1800, loss is 3.656108651161194 and perplexity is 38.71041367939848
At time: 430.193546295166 and batch: 1850, loss is 3.693782205581665 and perplexity is 40.19659158476081
At time: 431.3597822189331 and batch: 1900, loss is 3.763585386276245 and perplexity is 43.10268905696115
At time: 432.52822279930115 and batch: 1950, loss is 3.694512367248535 and perplexity is 40.22595231280946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495958621002907 and perplexity of 89.65407208080391
finished 9 epochs...
Completing Train Step...
At time: 436.221608877182 and batch: 50, loss is 3.9039648294448854 and perplexity is 49.59871020418476
At time: 437.38528180122375 and batch: 100, loss is 3.86042977809906 and perplexity is 47.485755321608
At time: 438.54900550842285 and batch: 150, loss is 3.8243106269836424 and perplexity is 45.80121535867367
At time: 439.71176314353943 and batch: 200, loss is 3.840195727348328 and perplexity is 46.53458163876588
At time: 440.87772011756897 and batch: 250, loss is 3.828978590965271 and perplexity is 46.0155135613007
At time: 442.04089164733887 and batch: 300, loss is 3.855967626571655 and perplexity is 47.27433872320773
At time: 443.20577335357666 and batch: 350, loss is 3.8507369327545167 and perplexity is 47.02770672250348
At time: 444.3703637123108 and batch: 400, loss is 3.815750207901001 and perplexity is 45.410811156590455
At time: 445.53359818458557 and batch: 450, loss is 3.8391697359085084 and perplexity is 46.48686204048464
At time: 446.69815969467163 and batch: 500, loss is 3.870135350227356 and perplexity is 47.94887553283977
At time: 447.85996890068054 and batch: 550, loss is 3.8189201879501344 and perplexity is 45.55499092473027
At time: 449.02417373657227 and batch: 600, loss is 3.797377324104309 and perplexity is 44.58410137686736
At time: 450.18829917907715 and batch: 650, loss is 3.84496506690979 and perplexity is 46.75705095410361
At time: 451.35286593437195 and batch: 700, loss is 3.868601989746094 and perplexity is 47.87540896173969
At time: 452.5204691886902 and batch: 750, loss is 3.8266973543167113 and perplexity is 45.91066092766907
At time: 453.68435621261597 and batch: 800, loss is 3.7891466283798216 and perplexity is 44.21864923010318
At time: 454.84732270240784 and batch: 850, loss is 3.8022425031661986 and perplexity is 44.80153952223933
At time: 456.01028847694397 and batch: 900, loss is 3.7853208208084106 and perplexity is 44.04980038462737
At time: 457.1739881038666 and batch: 950, loss is 3.8706101036071776 and perplexity is 47.971644828029895
At time: 458.3373866081238 and batch: 1000, loss is 3.8402023315429688 and perplexity is 46.53488896321537
At time: 459.5034890174866 and batch: 1050, loss is 3.769686393737793 and perplexity is 43.36646270883174
At time: 460.668030500412 and batch: 1100, loss is 3.794844036102295 and perplexity is 44.47129994734847
At time: 461.87766790390015 and batch: 1150, loss is 3.7485205602645872 and perplexity is 42.45822113265719
At time: 463.0425052642822 and batch: 1200, loss is 3.8152657175064086 and perplexity is 45.38881538357508
At time: 464.2089591026306 and batch: 1250, loss is 3.796728982925415 and perplexity is 44.55520503637669
At time: 465.3732399940491 and batch: 1300, loss is 3.80915846824646 and perplexity is 45.11245932106445
At time: 466.5382556915283 and batch: 1350, loss is 3.700155301094055 and perplexity is 40.45358635847408
At time: 467.70287251472473 and batch: 1400, loss is 3.7192741346359255 and perplexity is 41.234452582230944
At time: 468.8664872646332 and batch: 1450, loss is 3.6322698259353636 and perplexity is 37.79851537026712
At time: 470.0308048725128 and batch: 1500, loss is 3.620207905769348 and perplexity is 37.34533132482783
At time: 471.1947455406189 and batch: 1550, loss is 3.627865891456604 and perplexity is 37.63241919197313
At time: 472.3600261211395 and batch: 1600, loss is 3.7222621631622315 and perplexity is 41.35784656337273
At time: 473.5240077972412 and batch: 1650, loss is 3.6659963846206667 and perplexity is 39.09507049007613
At time: 474.6915497779846 and batch: 1700, loss is 3.6880451107025145 and perplexity is 39.96664018225043
At time: 475.85547828674316 and batch: 1750, loss is 3.689293956756592 and perplexity is 40.01658354242986
At time: 477.01995038986206 and batch: 1800, loss is 3.6266819858551025 and perplexity is 37.5878923230993
At time: 478.18816089630127 and batch: 1850, loss is 3.6681028032302856 and perplexity is 39.177507867432475
At time: 479.353800535202 and batch: 1900, loss is 3.7378807878494262 and perplexity is 42.00887005828465
At time: 480.51710081100464 and batch: 1950, loss is 3.6747518587112427 and perplexity is 39.438869231055534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.502342898346657 and perplexity of 90.22827954146317
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 484.2213041782379 and batch: 50, loss is 3.87036967754364 and perplexity is 47.96011258068444
At time: 485.3878300189972 and batch: 100, loss is 3.8635448217391968 and perplexity is 47.633906150069244
At time: 486.5527226924896 and batch: 150, loss is 3.8369230031967163 and perplexity is 46.382535727424774
At time: 487.72029733657837 and batch: 200, loss is 3.8554380798339842 and perplexity is 47.24931137852052
At time: 488.8863995075226 and batch: 250, loss is 3.8463605356216433 and perplexity is 46.822344502725
At time: 490.0534942150116 and batch: 300, loss is 3.8714551401138304 and perplexity is 48.01219975197608
At time: 491.2427384853363 and batch: 350, loss is 3.8762982225418092 and perplexity is 48.24529077684247
At time: 492.4087061882019 and batch: 400, loss is 3.8451847648620605 and perplexity is 46.76732451095082
At time: 493.5735864639282 and batch: 450, loss is 3.8660226488113403 and perplexity is 47.75208108033807
At time: 494.73883605003357 and batch: 500, loss is 3.894210014343262 and perplexity is 49.11723612013668
At time: 495.9043998718262 and batch: 550, loss is 3.840858483314514 and perplexity is 46.56543293269124
At time: 497.0693898200989 and batch: 600, loss is 3.802188220024109 and perplexity is 44.799107619909854
At time: 498.236248254776 and batch: 650, loss is 3.85187304019928 and perplexity is 47.08116561199209
At time: 499.40087604522705 and batch: 700, loss is 3.88430362701416 and perplexity is 48.633063912879614
At time: 500.56730103492737 and batch: 750, loss is 3.839096341133118 and perplexity is 46.483450272891055
At time: 501.7334370613098 and batch: 800, loss is 3.7974902534484865 and perplexity is 44.58913651449863
At time: 502.89945888519287 and batch: 850, loss is 3.7985545682907103 and perplexity is 44.6366186577857
At time: 504.0649197101593 and batch: 900, loss is 3.7787965726852417 and perplexity is 43.7633440294142
At time: 505.2314507961273 and batch: 950, loss is 3.869849987030029 and perplexity is 47.93519464051392
At time: 506.39657640457153 and batch: 1000, loss is 3.8355652332305907 and perplexity is 46.31960164813114
At time: 507.56322026252747 and batch: 1050, loss is 3.765810604095459 and perplexity is 43.19870872142004
At time: 508.72788095474243 and batch: 1100, loss is 3.791022787094116 and perplexity is 44.301688307076574
At time: 509.8929615020752 and batch: 1150, loss is 3.732119164466858 and perplexity is 41.7675267026839
At time: 511.06014704704285 and batch: 1200, loss is 3.782876977920532 and perplexity is 43.94228102696579
At time: 512.2253546714783 and batch: 1250, loss is 3.748208174705505 and perplexity is 42.444959868932514
At time: 513.3908152580261 and batch: 1300, loss is 3.7576506996154784 and perplexity is 42.84764565307779
At time: 514.557858467102 and batch: 1350, loss is 3.663398852348328 and perplexity is 38.99365155928593
At time: 515.7237803936005 and batch: 1400, loss is 3.6938265228271483 and perplexity is 40.19837302645166
At time: 516.8910336494446 and batch: 1450, loss is 3.614149932861328 and perplexity is 37.119778206558955
At time: 518.0558853149414 and batch: 1500, loss is 3.5947951555252073 and perplexity is 36.40824119691297
At time: 519.2233803272247 and batch: 1550, loss is 3.5871039485931395 and perplexity is 36.129291982993
At time: 520.3922863006592 and batch: 1600, loss is 3.6771321296691895 and perplexity is 39.53285623899809
At time: 521.5593678951263 and batch: 1650, loss is 3.612129774093628 and perplexity is 37.04486605385756
At time: 522.7304456233978 and batch: 1700, loss is 3.6328175401687623 and perplexity is 37.81922382577697
At time: 523.8985109329224 and batch: 1750, loss is 3.6374315309524534 and perplexity is 37.99412456085825
At time: 525.0619921684265 and batch: 1800, loss is 3.574565329551697 and perplexity is 35.67910879037765
At time: 526.2276451587677 and batch: 1850, loss is 3.624913048744202 and perplexity is 37.52146047964791
At time: 527.3940908908844 and batch: 1900, loss is 3.6945078277587893 and perplexity is 40.225769707925885
At time: 528.5593094825745 and batch: 1950, loss is 3.622092161178589 and perplexity is 37.41576580482217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477126010628634 and perplexity of 87.98145121638382
finished 11 epochs...
Completing Train Step...
At time: 532.2333450317383 and batch: 50, loss is 3.8725335597991943 and perplexity is 48.06400498219553
At time: 533.3965399265289 and batch: 100, loss is 3.8449635887145996 and perplexity is 46.75698183810687
At time: 534.5620889663696 and batch: 150, loss is 3.8063553285598757 and perplexity is 44.98617986814289
At time: 535.7258138656616 and batch: 200, loss is 3.8146845054626466 and perplexity is 45.36244252227677
At time: 536.890872001648 and batch: 250, loss is 3.802925181388855 and perplexity is 44.832134999857544
At time: 538.0552589893341 and batch: 300, loss is 3.8234719753265383 and perplexity is 45.76282019584959
At time: 539.2220892906189 and batch: 350, loss is 3.8280964851379395 and perplexity is 45.97494090595931
At time: 540.3940618038177 and batch: 400, loss is 3.797477297782898 and perplexity is 44.588558836299185
At time: 541.5587522983551 and batch: 450, loss is 3.8196138763427734 and perplexity is 45.58660285630888
At time: 542.724098443985 and batch: 500, loss is 3.849530348777771 and perplexity is 46.97099806386835
At time: 543.8909103870392 and batch: 550, loss is 3.7954980993270873 and perplexity is 44.500396503659175
At time: 545.0573756694794 and batch: 600, loss is 3.7586883211135866 and perplexity is 42.89212836546903
At time: 546.2232778072357 and batch: 650, loss is 3.808082966804504 and perplexity is 45.06396688752985
At time: 547.3889338970184 and batch: 700, loss is 3.8421971464157103 and perplexity is 46.627810101241316
At time: 548.5547919273376 and batch: 750, loss is 3.8015297079086303 and perplexity is 44.769616575950096
At time: 549.7429518699646 and batch: 800, loss is 3.759983334541321 and perplexity is 42.94771022950871
At time: 550.9181082248688 and batch: 850, loss is 3.762795705795288 and perplexity is 43.06866514051555
At time: 552.0837905406952 and batch: 900, loss is 3.745021004676819 and perplexity is 42.309895915194325
At time: 553.263338804245 and batch: 950, loss is 3.8384918451309202 and perplexity is 46.45535970420637
At time: 554.4407749176025 and batch: 1000, loss is 3.806458144187927 and perplexity is 44.99080538826347
At time: 555.6087772846222 and batch: 1050, loss is 3.7388643980026246 and perplexity is 42.050210737621285
At time: 556.774346113205 and batch: 1100, loss is 3.7648747539520264 and perplexity is 43.15830011481634
At time: 557.9402379989624 and batch: 1150, loss is 3.7086811876296997 and perplexity is 40.79996353377531
At time: 559.1055035591125 and batch: 1200, loss is 3.760733165740967 and perplexity is 42.97992583921735
At time: 560.2709362506866 and batch: 1250, loss is 3.728006796836853 and perplexity is 41.59611597142637
At time: 561.4370801448822 and batch: 1300, loss is 3.737249341011047 and perplexity is 41.982352063335625
At time: 562.602108001709 and batch: 1350, loss is 3.6404983520507814 and perplexity is 38.11082460127962
At time: 563.769031047821 and batch: 1400, loss is 3.673133511543274 and perplexity is 39.375095067015415
At time: 564.9350616931915 and batch: 1450, loss is 3.595453634262085 and perplexity is 36.432223144523
At time: 566.1031014919281 and batch: 1500, loss is 3.5796339893341065 and perplexity is 35.8604131510743
At time: 567.2742383480072 and batch: 1550, loss is 3.57443145275116 and perplexity is 35.6743325051708
At time: 568.4387526512146 and batch: 1600, loss is 3.6668753385543824 and perplexity is 39.12944836214197
At time: 569.6050088405609 and batch: 1650, loss is 3.603597559928894 and perplexity is 36.73013590482593
At time: 570.7715792655945 and batch: 1700, loss is 3.6278528928756715 and perplexity is 37.6319300271058
At time: 571.9374694824219 and batch: 1750, loss is 3.633131198883057 and perplexity is 37.83108801545376
At time: 573.103844165802 and batch: 1800, loss is 3.5726958084106446 and perplexity is 35.61246825455508
At time: 574.2688684463501 and batch: 1850, loss is 3.6269798469543457 and perplexity is 37.599089961612556
At time: 575.4354629516602 and batch: 1900, loss is 3.69915415763855 and perplexity is 40.413106781552344
At time: 576.6000385284424 and batch: 1950, loss is 3.6247632122039795 and perplexity is 37.51583881500146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.476835596838662 and perplexity of 87.95590389951496
finished 12 epochs...
Completing Train Step...
At time: 580.2767722606659 and batch: 50, loss is 3.8489763641357424 and perplexity is 46.944984058665206
At time: 581.4747302532196 and batch: 100, loss is 3.8203687191009523 and perplexity is 45.62102656395364
At time: 582.6410045623779 and batch: 150, loss is 3.781509952545166 and perplexity is 43.882251853800284
At time: 583.8081984519958 and batch: 200, loss is 3.7898257398605346 and perplexity is 44.24868882141813
At time: 584.9739711284637 and batch: 250, loss is 3.778393044471741 and perplexity is 43.745687848004444
At time: 586.1403386592865 and batch: 300, loss is 3.7986095476150514 and perplexity is 44.639072816383745
At time: 587.3067557811737 and batch: 350, loss is 3.8025126028060914 and perplexity is 44.8136420362997
At time: 588.4715738296509 and batch: 400, loss is 3.7722667169570925 and perplexity is 43.47850669217776
At time: 589.6356127262115 and batch: 450, loss is 3.796427345275879 and perplexity is 44.54176753578485
At time: 590.806755065918 and batch: 500, loss is 3.8262972974777223 and perplexity is 45.89229772718933
At time: 591.9730973243713 and batch: 550, loss is 3.7727699518203734 and perplexity is 43.500392098836606
At time: 593.140457868576 and batch: 600, loss is 3.7368937063217165 and perplexity is 41.96742433716817
At time: 594.3064789772034 and batch: 650, loss is 3.7853868770599366 and perplexity is 44.052710245427434
At time: 595.4720437526703 and batch: 700, loss is 3.8195200395584106 and perplexity is 45.58232535678336
At time: 596.6377611160278 and batch: 750, loss is 3.7807577562332155 and perplexity is 43.84925619695721
At time: 597.8042330741882 and batch: 800, loss is 3.7397347831726075 and perplexity is 42.086826550060444
At time: 598.9736795425415 and batch: 850, loss is 3.7436711406707763 and perplexity is 42.25282183938568
At time: 600.1390082836151 and batch: 900, loss is 3.725358080863953 and perplexity is 41.48608545875882
At time: 601.3060019016266 and batch: 950, loss is 3.819088306427002 and perplexity is 45.5626502042334
At time: 602.4743890762329 and batch: 1000, loss is 3.7877227878570556 and perplexity is 44.155733726918015
At time: 603.6420533657074 and batch: 1050, loss is 3.7208011770248413 and perplexity is 41.297467440142185
At time: 604.809552192688 and batch: 1100, loss is 3.747500796318054 and perplexity is 42.41494583855476
At time: 605.9759347438812 and batch: 1150, loss is 3.693073744773865 and perplexity is 40.168123960304655
At time: 607.1688599586487 and batch: 1200, loss is 3.746631064414978 and perplexity is 42.3780722443867
At time: 608.3352406024933 and batch: 1250, loss is 3.7148283195495604 and perplexity is 41.051538732717084
At time: 609.5020864009857 and batch: 1300, loss is 3.7237354278564454 and perplexity is 41.418822524379465
At time: 610.6678886413574 and batch: 1350, loss is 3.625598030090332 and perplexity is 37.54717078469044
At time: 611.8359513282776 and batch: 1400, loss is 3.659086546897888 and perplexity is 38.82586106508457
At time: 613.0011751651764 and batch: 1450, loss is 3.582235803604126 and perplexity is 35.95383676848793
At time: 614.1672520637512 and batch: 1500, loss is 3.56814724445343 and perplexity is 35.45085050800159
At time: 615.3355669975281 and batch: 1550, loss is 3.563903603553772 and perplexity is 35.300728585911436
At time: 616.5020127296448 and batch: 1600, loss is 3.6578189373016357 and perplexity is 38.77667621119808
At time: 617.6688315868378 and batch: 1650, loss is 3.594915299415588 and perplexity is 36.412615687431185
At time: 618.8344705104828 and batch: 1700, loss is 3.6204942083358764 and perplexity is 37.35602491976277
At time: 620.0011494159698 and batch: 1750, loss is 3.6261225509643555 and perplexity is 37.56687022545983
At time: 621.168123960495 and batch: 1800, loss is 3.56696900844574 and perplexity is 35.40910563691427
At time: 622.3344597816467 and batch: 1850, loss is 3.6230053234100343 and perplexity is 37.44994807361888
At time: 623.5033602714539 and batch: 1900, loss is 3.697479147911072 and perplexity is 40.34547109560513
At time: 624.6708626747131 and batch: 1950, loss is 3.6219674158096313 and perplexity is 37.41109865242089
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.478257290152616 and perplexity of 88.0810391509097
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 628.3193252086639 and batch: 50, loss is 3.841688084602356 and perplexity is 46.604079704310344
At time: 629.5057642459869 and batch: 100, loss is 3.834666862487793 and perplexity is 46.2780081591766
At time: 630.670990228653 and batch: 150, loss is 3.8099535369873045 and perplexity is 45.14834108963936
At time: 631.835531949997 and batch: 200, loss is 3.82743595123291 and perplexity is 45.94458292605049
At time: 632.9988188743591 and batch: 250, loss is 3.8244488286972045 and perplexity is 45.80754560253466
At time: 634.1608855724335 and batch: 300, loss is 3.8427943086624143 and perplexity is 46.65566278453804
At time: 635.323887348175 and batch: 350, loss is 3.8516470623016357 and perplexity is 47.07052751120156
At time: 636.5260751247406 and batch: 400, loss is 3.825583539009094 and perplexity is 45.85955339820294
At time: 637.689555644989 and batch: 450, loss is 3.846969199180603 and perplexity is 46.8508522324969
At time: 638.8581092357635 and batch: 500, loss is 3.8797929286956787 and perplexity is 48.41418884407742
At time: 640.02592420578 and batch: 550, loss is 3.8349654483795166 and perplexity is 46.291828182639335
At time: 641.1895928382874 and batch: 600, loss is 3.7914891910552977 and perplexity is 44.32235560927119
At time: 642.3660764694214 and batch: 650, loss is 3.8201901388168333 and perplexity is 45.61288027547295
At time: 643.5301764011383 and batch: 700, loss is 3.8531628227233887 and perplexity is 47.14192925413143
At time: 644.6941080093384 and batch: 750, loss is 3.8167101383209228 and perplexity is 45.45442330457784
At time: 645.8597099781036 and batch: 800, loss is 3.780323276519775 and perplexity is 43.83020872286036
At time: 647.0287334918976 and batch: 850, loss is 3.790051908493042 and perplexity is 44.25869761865445
At time: 648.1937808990479 and batch: 900, loss is 3.7664259386062624 and perplexity is 43.22529855770143
At time: 649.3664329051971 and batch: 950, loss is 3.869451198577881 and perplexity is 47.91608244955363
At time: 650.5447402000427 and batch: 1000, loss is 3.828583974838257 and perplexity is 45.99735867989665
At time: 651.708281993866 and batch: 1050, loss is 3.7609379625320436 and perplexity is 42.9887288914976
At time: 652.8786630630493 and batch: 1100, loss is 3.7869679975509642 and perplexity is 44.122417981924954
At time: 654.0407094955444 and batch: 1150, loss is 3.7363832569122315 and perplexity is 41.94600755675414
At time: 655.2055585384369 and batch: 1200, loss is 3.7835327196121216 and perplexity is 43.97110526225225
At time: 656.3694241046906 and batch: 1250, loss is 3.7438338947296144 and perplexity is 42.25969921728281
At time: 657.5334751605988 and batch: 1300, loss is 3.740361280441284 and perplexity is 42.113202093181485
At time: 658.7061750888824 and batch: 1350, loss is 3.625404691696167 and perplexity is 37.53991217669191
At time: 659.8711354732513 and batch: 1400, loss is 3.6587664556503294 and perplexity is 38.81343523558443
At time: 661.0355927944183 and batch: 1450, loss is 3.5822718238830564 and perplexity is 35.955131859041565
At time: 662.1991205215454 and batch: 1500, loss is 3.5803901958465576 and perplexity is 35.887541284981324
At time: 663.3690962791443 and batch: 1550, loss is 3.5846501064300536 and perplexity is 36.040745087486414
At time: 664.5330064296722 and batch: 1600, loss is 3.6811308574676516 and perplexity is 39.691253853603506
At time: 665.697592496872 and batch: 1650, loss is 3.6091179895401 and perplexity is 36.93346274408302
At time: 666.8613131046295 and batch: 1700, loss is 3.6223586702346804 and perplexity is 37.42573877413404
At time: 668.0267310142517 and batch: 1750, loss is 3.6236371612548828 and perplexity is 37.47361784504063
At time: 669.1908996105194 and batch: 1800, loss is 3.5570423650741576 and perplexity is 35.05935089048125
At time: 670.3561365604401 and batch: 1850, loss is 3.614352970123291 and perplexity is 37.127315669857744
At time: 671.5215518474579 and batch: 1900, loss is 3.707413954734802 and perplexity is 40.748293223947535
At time: 672.685417175293 and batch: 1950, loss is 3.6517675352096557 and perplexity is 38.54273151228423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.454419513081396 and perplexity of 86.00621087146038
finished 14 epochs...
Completing Train Step...
At time: 676.3311369419098 and batch: 50, loss is 3.8765383529663087 and perplexity is 48.25687733008311
At time: 677.5252497196198 and batch: 100, loss is 3.8451359939575194 and perplexity is 46.765043681850955
At time: 678.6920330524445 and batch: 150, loss is 3.802611117362976 and perplexity is 44.81805704985527
At time: 679.857809305191 and batch: 200, loss is 3.8144410276412963 and perplexity is 45.35139911806688
At time: 681.02512383461 and batch: 250, loss is 3.806694021224976 and perplexity is 45.00141893782999
At time: 682.1906490325928 and batch: 300, loss is 3.8145045900344847 and perplexity is 45.35428185314506
At time: 683.3558177947998 and batch: 350, loss is 3.825080041885376 and perplexity is 45.83646905690934
At time: 684.5202407836914 and batch: 400, loss is 3.799032368659973 and perplexity is 44.65795114659271
At time: 685.6863384246826 and batch: 450, loss is 3.8198242378234863 and perplexity is 45.59619353030523
At time: 686.8527102470398 and batch: 500, loss is 3.853169550895691 and perplexity is 47.14224643422114
At time: 688.0186438560486 and batch: 550, loss is 3.810440363883972 and perplexity is 45.170325867378075
At time: 689.1848502159119 and batch: 600, loss is 3.7698484230041505 and perplexity is 43.37348991426006
At time: 690.35023188591 and batch: 650, loss is 3.799794912338257 and perplexity is 44.6920177719188
At time: 691.5162706375122 and batch: 700, loss is 3.831856551170349 and perplexity is 46.148135126401485
At time: 692.6830008029938 and batch: 750, loss is 3.797174196243286 and perplexity is 44.57504602344746
At time: 693.8495819568634 and batch: 800, loss is 3.759609913825989 and perplexity is 42.93167565883968
At time: 695.0562019348145 and batch: 850, loss is 3.766578311920166 and perplexity is 43.23188544150706
At time: 696.2203044891357 and batch: 900, loss is 3.743660569190979 and perplexity is 42.252375166894225
At time: 697.3849258422852 and batch: 950, loss is 3.846887240409851 and perplexity is 46.84701255158914
At time: 698.5497024059296 and batch: 1000, loss is 3.807972822189331 and perplexity is 45.05900360758315
At time: 699.7199065685272 and batch: 1050, loss is 3.7425120878219604 and perplexity is 42.203876956194776
At time: 700.8859899044037 and batch: 1100, loss is 3.7715632057189943 and perplexity is 43.44792983094795
At time: 702.0522620677948 and batch: 1150, loss is 3.723560094833374 and perplexity is 41.41156107361887
At time: 703.2198259830475 and batch: 1200, loss is 3.7724333429336547 and perplexity is 43.485751944421665
At time: 704.3858270645142 and batch: 1250, loss is 3.735624828338623 and perplexity is 41.91420656698832
At time: 705.5518765449524 and batch: 1300, loss is 3.7336503982543947 and perplexity is 41.83153154147287
At time: 706.7171831130981 and batch: 1350, loss is 3.6179186964035033 and perplexity is 37.25993782168395
At time: 707.8849186897278 and batch: 1400, loss is 3.6511869764328004 and perplexity is 38.52036168534879
At time: 709.0548627376556 and batch: 1450, loss is 3.5754582929611205 and perplexity is 35.71098315821238
At time: 710.2209312915802 and batch: 1500, loss is 3.5742372941970824 and perplexity is 35.66740670072777
At time: 711.3876218795776 and batch: 1550, loss is 3.579411015510559 and perplexity is 35.85241810901568
At time: 712.5553960800171 and batch: 1600, loss is 3.6771309661865232 and perplexity is 39.53281024323187
At time: 713.7226822376251 and batch: 1650, loss is 3.6064626932144166 and perplexity is 36.835523542509094
At time: 714.8895018100739 and batch: 1700, loss is 3.6217627906799317 and perplexity is 37.40344418468187
At time: 716.0562002658844 and batch: 1750, loss is 3.624539685249329 and perplexity is 37.507453950956446
At time: 717.2227642536163 and batch: 1800, loss is 3.55909779548645 and perplexity is 35.131487056574876
At time: 718.3933207988739 and batch: 1850, loss is 3.6163918018341064 and perplexity is 37.2030892369104
At time: 719.5589189529419 and batch: 1900, loss is 3.710337257385254 and perplexity is 40.867587098626394
At time: 720.7231867313385 and batch: 1950, loss is 3.653928737640381 and perplexity is 38.62612023481264
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.453579215116279 and perplexity of 85.93397038349596
finished 15 epochs...
Completing Train Step...
At time: 724.4039216041565 and batch: 50, loss is 3.86910418510437 and perplexity is 47.8994578079999
At time: 725.5697550773621 and batch: 100, loss is 3.83637797832489 and perplexity is 46.357262979598644
At time: 726.7327868938446 and batch: 150, loss is 3.7931160974502562 and perplexity is 44.3945226216207
At time: 727.8971173763275 and batch: 200, loss is 3.804755153656006 and perplexity is 44.91425167628869
At time: 729.0619721412659 and batch: 250, loss is 3.7965799808502196 and perplexity is 44.548566712939774
At time: 730.2259948253632 and batch: 300, loss is 3.8038068628311157 and perplexity is 44.87168009182896
At time: 731.3899257183075 and batch: 350, loss is 3.8151923561096193 and perplexity is 45.38548571881584
At time: 732.5548272132874 and batch: 400, loss is 3.7889139890670775 and perplexity is 44.20836343042289
At time: 733.7197637557983 and batch: 450, loss is 3.8098106241226195 and perplexity is 45.141889271913314
At time: 734.8916115760803 and batch: 500, loss is 3.842471661567688 and perplexity is 46.64061189868094
At time: 736.0671761035919 and batch: 550, loss is 3.79938880443573 and perplexity is 44.673871675207785
At time: 737.233803987503 and batch: 600, loss is 3.759928011894226 and perplexity is 42.94533431421371
At time: 738.3964183330536 and batch: 650, loss is 3.790587010383606 and perplexity is 44.28238686894013
At time: 739.5609474182129 and batch: 700, loss is 3.822685031890869 and perplexity is 45.726821611181464
At time: 740.7242453098297 and batch: 750, loss is 3.7887869358062742 and perplexity is 44.202746970496605
At time: 741.8881709575653 and batch: 800, loss is 3.7510629987716673 and perplexity is 42.566305890210195
At time: 743.0517330169678 and batch: 850, loss is 3.7581772327423097 and perplexity is 42.87021229844268
At time: 744.2152371406555 and batch: 900, loss is 3.7358231687545778 and perplexity is 41.92252067263756
At time: 745.3779962062836 and batch: 950, loss is 3.8393977594375612 and perplexity is 46.49746334744948
At time: 746.5414288043976 and batch: 1000, loss is 3.8005303621292112 and perplexity is 44.724898596662264
At time: 747.706022977829 and batch: 1050, loss is 3.7347675943374634 and perplexity is 41.87829167991798
At time: 748.8709332942963 and batch: 1100, loss is 3.763953604698181 and perplexity is 43.118563183500456
At time: 750.034517288208 and batch: 1150, loss is 3.7168642044067384 and perplexity is 41.135200072317275
At time: 751.2007794380188 and batch: 1200, loss is 3.765588626861572 and perplexity is 43.18912065575609
At time: 752.3658406734467 and batch: 1250, loss is 3.7300596475601195 and perplexity is 41.68159429528433
At time: 753.5298082828522 and batch: 1300, loss is 3.7289703941345214 and perplexity is 41.63621719398188
At time: 754.6960275173187 and batch: 1350, loss is 3.613303108215332 and perplexity is 37.08835756928243
At time: 755.8622796535492 and batch: 1400, loss is 3.647019386291504 and perplexity is 38.36015866788573
At time: 757.0294601917267 and batch: 1450, loss is 3.5720125246047973 and perplexity is 35.58814314313425
At time: 758.195681810379 and batch: 1500, loss is 3.5708211708068847 and perplexity is 35.54577031916413
At time: 759.3632991313934 and batch: 1550, loss is 3.5763785457611084 and perplexity is 35.74386141628828
At time: 760.5294744968414 and batch: 1600, loss is 3.6750021457672117 and perplexity is 39.44874150492577
At time: 761.6957414150238 and batch: 1650, loss is 3.604598054885864 and perplexity is 36.76690260995213
At time: 762.8617353439331 and batch: 1700, loss is 3.6201070976257324 and perplexity is 37.341566801054775
At time: 764.0299518108368 and batch: 1750, loss is 3.623467626571655 and perplexity is 37.467265305612976
At time: 765.1968457698822 and batch: 1800, loss is 3.558175525665283 and perplexity is 35.09910128279634
At time: 766.3767926692963 and batch: 1850, loss is 3.615332384109497 and perplexity is 37.163696495131454
At time: 767.5429399013519 and batch: 1900, loss is 3.709498891830444 and perplexity is 40.833339479312826
At time: 768.7129075527191 and batch: 1950, loss is 3.6527732753753663 and perplexity is 38.58151498524143
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.453926405795785 and perplexity of 85.96381103696466
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 772.4135279655457 and batch: 50, loss is 3.868625841140747 and perplexity is 47.87655087063102
At time: 773.5773613452911 and batch: 100, loss is 3.846428408622742 and perplexity is 46.825522583616596
At time: 774.7487463951111 and batch: 150, loss is 3.809612150192261 and perplexity is 45.1329306727793
At time: 775.9119288921356 and batch: 200, loss is 3.8273816776275633 and perplexity is 45.94208941555545
At time: 777.0750415325165 and batch: 250, loss is 3.8258229446411134 and perplexity is 45.87053374789469
At time: 778.2387442588806 and batch: 300, loss is 3.8304109239578246 and perplexity is 46.08147032429141
At time: 779.4011080265045 and batch: 350, loss is 3.850879292488098 and perplexity is 47.03440205086472
At time: 780.5634458065033 and batch: 400, loss is 3.834900488853455 and perplexity is 46.288821185087684
At time: 781.7673599720001 and batch: 450, loss is 3.8552913808822633 and perplexity is 47.242380462463245
At time: 782.9277844429016 and batch: 500, loss is 3.888226294517517 and perplexity is 48.8242099082696
At time: 784.09046459198 and batch: 550, loss is 3.8505593729019165 and perplexity is 47.019357231118875
At time: 785.255398273468 and batch: 600, loss is 3.8051667165756227 and perplexity is 44.93274052124152
At time: 786.4196879863739 and batch: 650, loss is 3.8273291778564453 and perplexity is 45.93967752968873
At time: 787.5828642845154 and batch: 700, loss is 3.8508180141448975 and perplexity is 47.031519948939724
At time: 788.7469892501831 and batch: 750, loss is 3.812537236213684 and perplexity is 45.265141647365105
At time: 789.9105153083801 and batch: 800, loss is 3.7713623571395876 and perplexity is 43.439204252252615
At time: 791.075991153717 and batch: 850, loss is 3.7795701122283933 and perplexity is 43.79720980313039
At time: 792.2392842769623 and batch: 900, loss is 3.755320529937744 and perplexity is 42.74791960284731
At time: 793.4030480384827 and batch: 950, loss is 3.866024398803711 and perplexity is 47.75216464618876
At time: 794.5687022209167 and batch: 1000, loss is 3.8332509803771972 and perplexity is 46.212530320698825
At time: 795.7340502738953 and batch: 1050, loss is 3.7701365327835084 and perplexity is 43.385988041199084
At time: 796.8985612392426 and batch: 1100, loss is 3.795135464668274 and perplexity is 44.48426204319011
At time: 798.0639412403107 and batch: 1150, loss is 3.757039575576782 and perplexity is 42.8214684263986
At time: 799.2290141582489 and batch: 1200, loss is 3.8067030048370363 and perplexity is 45.00182321493583
At time: 800.3943457603455 and batch: 1250, loss is 3.7674225854873655 and perplexity is 43.2684003917802
At time: 801.5579390525818 and batch: 1300, loss is 3.765253028869629 and perplexity is 43.17462890542739
At time: 802.7310874462128 and batch: 1350, loss is 3.6373852634429933 and perplexity is 37.992366708006756
At time: 803.8971827030182 and batch: 1400, loss is 3.6690368032455445 and perplexity is 39.21411675406747
At time: 805.0629291534424 and batch: 1450, loss is 3.5804125308990478 and perplexity is 35.88834284405107
At time: 806.2266118526459 and batch: 1500, loss is 3.569850788116455 and perplexity is 35.511294049221576
At time: 807.3904058933258 and batch: 1550, loss is 3.5784274435043333 and perplexity is 35.81717201058749
At time: 808.5542311668396 and batch: 1600, loss is 3.682365908622742 and perplexity is 39.74030486654247
At time: 809.7169389724731 and batch: 1650, loss is 3.6116165018081663 and perplexity is 37.02585682966479
At time: 810.8792171478271 and batch: 1700, loss is 3.626457204818726 and perplexity is 37.57944422722914
At time: 812.0438504219055 and batch: 1750, loss is 3.6337639808654787 and perplexity is 37.855034421953604
At time: 813.2086186408997 and batch: 1800, loss is 3.5667013835906984 and perplexity is 35.39963054809223
At time: 814.3720018863678 and batch: 1850, loss is 3.613171310424805 and perplexity is 37.08346972781095
At time: 815.5351989269257 and batch: 1900, loss is 3.702329182624817 and perplexity is 40.54162331900296
At time: 816.6999497413635 and batch: 1950, loss is 3.6533732080459593 and perplexity is 38.60466824106491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.444870208030523 and perplexity of 85.18882029498452
finished 17 epochs...
Completing Train Step...
At time: 820.3884091377258 and batch: 50, loss is 3.8773726558685304 and perplexity is 48.29715498243657
At time: 821.5545344352722 and batch: 100, loss is 3.8477131795883177 and perplexity is 46.88572131799247
At time: 822.7211530208588 and batch: 150, loss is 3.8065415477752684 and perplexity is 44.99455793931616
At time: 823.8885056972504 and batch: 200, loss is 3.8189189052581787 and perplexity is 45.55493249174734
At time: 825.0536060333252 and batch: 250, loss is 3.8137142992019655 and perplexity is 45.318452939476806
At time: 826.2172901630402 and batch: 300, loss is 3.8177204227447508 and perplexity is 45.50036840533844
At time: 827.3843088150024 and batch: 350, loss is 3.8349319314956665 and perplexity is 46.29027665081233
At time: 828.5508515834808 and batch: 400, loss is 3.8166704559326172 and perplexity is 45.45261960028994
At time: 829.7185730934143 and batch: 450, loss is 3.8363075160980227 and perplexity is 46.353996658695095
At time: 830.8862702846527 and batch: 500, loss is 3.869728193283081 and perplexity is 47.92935678906208
At time: 832.0530416965485 and batch: 550, loss is 3.829878420829773 and perplexity is 46.0569383294602
At time: 833.2200062274933 and batch: 600, loss is 3.787481927871704 and perplexity is 44.14509965825159
At time: 834.3864080905914 and batch: 650, loss is 3.812794575691223 and perplexity is 45.27679165420641
At time: 835.5520346164703 and batch: 700, loss is 3.8387905073165896 and perplexity is 46.46923623556613
At time: 836.7175641059875 and batch: 750, loss is 3.8027278709411623 and perplexity is 44.823290023861475
At time: 837.8850095272064 and batch: 800, loss is 3.7627556848526003 and perplexity is 43.06694152642688
At time: 839.0530798435211 and batch: 850, loss is 3.7705431509017946 and perplexity is 43.4036331571852
At time: 840.2436990737915 and batch: 900, loss is 3.744825940132141 and perplexity is 42.30164355950943
At time: 841.409619808197 and batch: 950, loss is 3.852057008743286 and perplexity is 47.089827862246196
At time: 842.5762913227081 and batch: 1000, loss is 3.8166036128997805 and perplexity is 45.449581510884165
At time: 843.7434067726135 and batch: 1050, loss is 3.7526872301101686 and perplexity is 42.63549959628241
At time: 844.910885810852 and batch: 1100, loss is 3.7783712673187257 and perplexity is 43.744735201839426
At time: 846.0780062675476 and batch: 1150, loss is 3.740052008628845 and perplexity is 42.10017968067888
At time: 847.2446141242981 and batch: 1200, loss is 3.791166286468506 and perplexity is 44.30804602778662
At time: 848.4123220443726 and batch: 1250, loss is 3.755065469741821 and perplexity is 42.73701770047789
At time: 849.5806148052216 and batch: 1300, loss is 3.7537295246124267 and perplexity is 42.679961510291704
At time: 850.747314453125 and batch: 1350, loss is 3.6310788011550903 and perplexity is 37.75352320051673
At time: 851.9157259464264 and batch: 1400, loss is 3.664760084152222 and perplexity is 39.04676710101902
At time: 853.0836560726166 and batch: 1450, loss is 3.5802707052230835 and perplexity is 35.88325331648935
At time: 854.2509367465973 and batch: 1500, loss is 3.5718046379089357 and perplexity is 35.58074561059531
At time: 855.4179713726044 and batch: 1550, loss is 3.5815811729431153 and perplexity is 35.93030798672953
At time: 856.583336353302 and batch: 1600, loss is 3.686680989265442 and perplexity is 39.912158000214774
At time: 857.749841928482 and batch: 1650, loss is 3.616144480705261 and perplexity is 37.193889264604465
At time: 858.9169464111328 and batch: 1700, loss is 3.632201662063599 and perplexity is 37.7959389649224
At time: 860.0843105316162 and batch: 1750, loss is 3.640881657600403 and perplexity is 38.12543549188877
At time: 861.2517786026001 and batch: 1800, loss is 3.574038128852844 and perplexity is 35.66030369675373
At time: 862.4199340343475 and batch: 1850, loss is 3.620718688964844 and perplexity is 37.364411565016965
At time: 863.5867803096771 and batch: 1900, loss is 3.7089919900894164 and perplexity is 40.81264623360302
At time: 864.7523267269135 and batch: 1950, loss is 3.658896985054016 and perplexity is 38.81850186080535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.442338242641715 and perplexity of 84.9733979864854
finished 18 epochs...
Completing Train Step...
At time: 868.412228345871 and batch: 50, loss is 3.8771404457092284 and perplexity is 48.2859411944124
At time: 869.599000453949 and batch: 100, loss is 3.845095796585083 and perplexity is 46.763163887754715
At time: 870.76487159729 and batch: 150, loss is 3.8026272201538087 and perplexity is 44.818778751464166
At time: 871.9291775226593 and batch: 200, loss is 3.8134421062469483 and perplexity is 45.30611925450164
At time: 873.0925166606903 and batch: 250, loss is 3.807165699005127 and perplexity is 45.02265011396163
At time: 874.2579219341278 and batch: 300, loss is 3.810807476043701 and perplexity is 45.18691148746804
At time: 875.4238994121552 and batch: 350, loss is 3.8269721555709837 and perplexity is 45.92327896852379
At time: 876.5894641876221 and batch: 400, loss is 3.80833251953125 and perplexity is 45.075214126675846
At time: 877.7546052932739 and batch: 450, loss is 3.8282230997085573 and perplexity is 45.98076237189472
At time: 878.9231626987457 and batch: 500, loss is 3.8617026710510256 and perplexity is 47.54623809075445
At time: 880.0883376598358 and batch: 550, loss is 3.8217142629623413 and perplexity is 45.68245297289312
At time: 881.2519879341125 and batch: 600, loss is 3.780411500930786 and perplexity is 43.83407578779168
At time: 882.4228994846344 and batch: 650, loss is 3.8065187072753908 and perplexity is 44.99353025285753
At time: 883.5848543643951 and batch: 700, loss is 3.8335999345779417 and perplexity is 46.22865919123616
At time: 884.7488172054291 and batch: 750, loss is 3.798225598335266 and perplexity is 44.62193696638476
At time: 885.9135465621948 and batch: 800, loss is 3.7584194135665894 and perplexity is 42.88059589909789
At time: 887.0781271457672 and batch: 850, loss is 3.765575313568115 and perplexity is 43.188545670146134
At time: 888.241443157196 and batch: 900, loss is 3.7397793531417847 and perplexity is 42.08870240042553
At time: 889.403694152832 and batch: 950, loss is 3.846026425361633 and perplexity is 46.80670329011922
At time: 890.5677239894867 and batch: 1000, loss is 3.8103384828567504 and perplexity is 45.16572410259901
At time: 891.7340469360352 and batch: 1050, loss is 3.7466115808486937 and perplexity is 42.37724657645063
At time: 892.8985328674316 and batch: 1100, loss is 3.7731573963165284 and perplexity is 43.51724935174994
At time: 894.0624408721924 and batch: 1150, loss is 3.7348841762542726 and perplexity is 41.8831742160369
At time: 895.2252376079559 and batch: 1200, loss is 3.786699876785278 and perplexity is 44.110589431242616
At time: 896.3883171081543 and batch: 1250, loss is 3.7521818351745604 and perplexity is 42.61395727485793
At time: 897.5499153137207 and batch: 1300, loss is 3.7514700365066527 and perplexity is 42.583635509611696
At time: 898.7166731357574 and batch: 1350, loss is 3.6301589250564574 and perplexity is 37.71881060497661
At time: 899.8808689117432 and batch: 1400, loss is 3.6642659664154054 and perplexity is 39.0274781667238
At time: 901.0443687438965 and batch: 1450, loss is 3.580960602760315 and perplexity is 35.9080176260161
At time: 902.2094297409058 and batch: 1500, loss is 3.573221459388733 and perplexity is 35.631192904209286
At time: 903.373526096344 and batch: 1550, loss is 3.583072533607483 and perplexity is 35.98393301190694
At time: 904.5380892753601 and batch: 1600, loss is 3.688407793045044 and perplexity is 39.98113800582815
At time: 905.7024834156036 and batch: 1650, loss is 3.617469458580017 and perplexity is 37.24320300755088
At time: 906.8659980297089 and batch: 1700, loss is 3.6335962629318237 and perplexity is 37.848685986190056
At time: 908.0300779342651 and batch: 1750, loss is 3.6425662565231325 and perplexity is 38.189715687419486
At time: 909.1924345493317 and batch: 1800, loss is 3.5759403848648073 and perplexity is 35.72820328457388
At time: 910.354754447937 and batch: 1850, loss is 3.62244469165802 and perplexity is 37.42895832792624
At time: 911.5166928768158 and batch: 1900, loss is 3.710279927253723 and perplexity is 40.86524422164204
At time: 912.6805830001831 and batch: 1950, loss is 3.6593827199935913 and perplexity is 38.83736194359088
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.441274243731831 and perplexity of 84.88303446552753
finished 19 epochs...
Completing Train Step...
At time: 916.3275198936462 and batch: 50, loss is 3.874758186340332 and perplexity is 48.17104846509266
At time: 917.5148158073425 and batch: 100, loss is 3.8417469024658204 and perplexity is 46.60682093732323
At time: 918.6799194812775 and batch: 150, loss is 3.798868107795715 and perplexity is 44.65061619538058
At time: 919.8447902202606 and batch: 200, loss is 3.8091968584060667 and perplexity is 45.11419122882193
At time: 921.0090279579163 and batch: 250, loss is 3.802529969215393 and perplexity is 44.81442029510736
At time: 922.1738829612732 and batch: 300, loss is 3.8061119890213013 and perplexity is 44.9752342836923
At time: 923.340099811554 and batch: 350, loss is 3.821978144645691 and perplexity is 45.694509326138586
At time: 924.5059490203857 and batch: 400, loss is 3.8033085680007934 and perplexity is 44.84932633545448
At time: 925.6709325313568 and batch: 450, loss is 3.8235807752609254 and perplexity is 45.76779945855109
At time: 926.857625246048 and batch: 500, loss is 3.857277722358704 and perplexity is 47.33631322260563
At time: 928.022979259491 and batch: 550, loss is 3.8173399353027344 and perplexity is 45.48305937969536
At time: 929.188752412796 and batch: 600, loss is 3.776556525230408 and perplexity is 43.665421778197185
At time: 930.3544409275055 and batch: 650, loss is 3.8029434490203857 and perplexity is 44.832953984260875
At time: 931.5214166641235 and batch: 700, loss is 3.8304047775268555 and perplexity is 46.08118708858555
At time: 932.6888952255249 and batch: 750, loss is 3.7953833961486816 and perplexity is 44.49529245947054
At time: 933.8548593521118 and batch: 800, loss is 3.7554957103729247 and perplexity is 42.75540885797274
At time: 935.0212659835815 and batch: 850, loss is 3.762307949066162 and perplexity is 43.04766323160635
At time: 936.1869678497314 and batch: 900, loss is 3.7365712213516233 and perplexity is 41.95389265558514
At time: 937.3523573875427 and batch: 950, loss is 3.842527141571045 and perplexity is 46.643199591767605
At time: 938.5177674293518 and batch: 1000, loss is 3.8069151258468628 and perplexity is 45.01137005962759
At time: 939.6848301887512 and batch: 1050, loss is 3.7434244537353516 and perplexity is 42.24239990578336
At time: 940.8514580726624 and batch: 1100, loss is 3.7704521226882934 and perplexity is 43.39968238181818
At time: 942.0170600414276 and batch: 1150, loss is 3.7323174142837523 and perplexity is 41.775807928053425
At time: 943.182473897934 and batch: 1200, loss is 3.7844537115097046 and perplexity is 44.011620948372006
At time: 944.346283197403 and batch: 1250, loss is 3.750749363899231 and perplexity is 42.552957705629744
At time: 945.5109710693359 and batch: 1300, loss is 3.7504180335998534 and perplexity is 42.53886095688268
At time: 946.6763551235199 and batch: 1350, loss is 3.6294824504852294 and perplexity is 37.69330341720005
At time: 947.8424663543701 and batch: 1400, loss is 3.663739366531372 and perplexity is 39.00693171160234
At time: 949.0097393989563 and batch: 1450, loss is 3.580907678604126 and perplexity is 35.90611727477051
At time: 950.1733114719391 and batch: 1500, loss is 3.5735036945343017 and perplexity is 35.641250698390124
At time: 951.3375205993652 and batch: 1550, loss is 3.583301167488098 and perplexity is 35.99216109872511
At time: 952.5015256404877 and batch: 1600, loss is 3.688742508888245 and perplexity is 39.994522566035116
At time: 953.6661758422852 and batch: 1650, loss is 3.617509331703186 and perplexity is 37.24468803997785
At time: 954.8294081687927 and batch: 1700, loss is 3.6336560916900633 and perplexity is 37.85095049381428
At time: 955.993846654892 and batch: 1750, loss is 3.6427290296554564 and perplexity is 38.19593245301197
At time: 957.1579446792603 and batch: 1800, loss is 3.5762927532196045 and perplexity is 35.7407949911143
At time: 958.3257632255554 and batch: 1850, loss is 3.6226043033599855 and perplexity is 37.434932904461235
At time: 959.4903593063354 and batch: 1900, loss is 3.7102383089065554 and perplexity is 40.863543513111516
At time: 960.6567802429199 and batch: 1950, loss is 3.6588309383392335 and perplexity is 38.81593811094922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.440784259175145 and perplexity of 84.84145327741672
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f1288f88b38>
ELAPSED
3957.205621242523


RESULTS SO FAR:
[{'best_accuracy': -78.41160778879484, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}}, {'best_accuracy': -78.90825503473185, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.10008266219030648, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.21726970941698143, 'batch_size': 32}}, {'best_accuracy': -78.77456827312196, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.6593070000175439, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.4915447901082358, 'batch_size': 32}}, {'best_accuracy': -84.84145327741672, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.4010388534776912, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.9900218516510327, 'batch_size': 32}}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.45364638623135345, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.002155165347015542, 'batch_size': 32}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6781160831451416 and batch: 50, loss is 7.460187520980835 and perplexity is 1737.4738396009718
At time: 2.89518141746521 and batch: 100, loss is 6.55039496421814 and perplexity is 699.5204047913701
At time: 4.1127769947052 and batch: 150, loss is 6.140177917480469 and perplexity is 464.1361414465638
At time: 5.330751657485962 and batch: 200, loss is 5.947087202072144 and perplexity is 382.63716950763614
At time: 6.549006700515747 and batch: 250, loss is 5.860927248001099 and perplexity is 351.0495031023608
At time: 7.767064809799194 and batch: 300, loss is 5.751094017028809 and perplexity is 314.53457831012486
At time: 8.984485864639282 and batch: 350, loss is 5.682362871170044 and perplexity is 293.64245012108216
At time: 10.200808048248291 and batch: 400, loss is 5.60063793182373 and perplexity is 270.5989760750909
At time: 11.41807222366333 and batch: 450, loss is 5.529174909591675 and perplexity is 251.93595530394208
At time: 12.636412620544434 and batch: 500, loss is 5.487481603622436 and perplexity is 241.6478747776644
At time: 13.852828025817871 and batch: 550, loss is 5.428162965774536 and perplexity is 227.73051218305193
At time: 15.070714712142944 and batch: 600, loss is 5.436783533096314 and perplexity is 229.7021645654685
At time: 16.290140867233276 and batch: 650, loss is 5.501667404174805 and perplexity is 245.1002729534969
At time: 17.514886140823364 and batch: 700, loss is 5.429385852813721 and perplexity is 228.00917122436564
At time: 18.748931407928467 and batch: 750, loss is 5.3708011913299565 and perplexity is 215.0350829505386
At time: 19.981221437454224 and batch: 800, loss is 5.3493568706512455 and perplexity is 210.4728930353028
At time: 21.213303089141846 and batch: 850, loss is 5.349716958999633 and perplexity is 210.54869551871275
At time: 22.444249629974365 and batch: 900, loss is 5.356314086914063 and perplexity is 211.94230404773683
At time: 23.677306413650513 and batch: 950, loss is 5.3853777885437015 and perplexity is 218.1925191728206
At time: 24.908987283706665 and batch: 1000, loss is 5.351618757247925 and perplexity is 210.94949766063306
At time: 26.143290519714355 and batch: 1050, loss is 5.247509784698487 and perplexity is 190.09230779793276
At time: 27.378159284591675 and batch: 1100, loss is 5.3327333354949955 and perplexity is 207.00301026342058
At time: 28.61127281188965 and batch: 1150, loss is 5.219197816848755 and perplexity is 184.78589247059637
At time: 29.843083381652832 and batch: 1200, loss is 5.290302066802979 and perplexity is 198.40334742355645
At time: 31.075579404830933 and batch: 1250, loss is 5.237222270965576 and perplexity is 188.14675517918164
At time: 32.309624433517456 and batch: 1300, loss is 5.2622304534912105 and perplexity is 192.9112914579523
At time: 33.55345892906189 and batch: 1350, loss is 5.188252410888672 and perplexity is 179.15518953788325
At time: 34.786497354507446 and batch: 1400, loss is 5.203971548080444 and perplexity is 181.99360481502495
At time: 36.02081489562988 and batch: 1450, loss is 5.150895853042602 and perplexity is 172.58603280543866
At time: 37.25827145576477 and batch: 1500, loss is 5.117523365020752 and perplexity is 166.92145376225258
At time: 38.49125790596008 and batch: 1550, loss is 5.107688980102539 and perplexity is 165.2879294537797
At time: 39.724963665008545 and batch: 1600, loss is 5.15720682144165 and perplexity is 173.67866195213614
At time: 40.959572553634644 and batch: 1650, loss is 5.1275444507598875 and perplexity is 168.6025973353997
At time: 42.19289803504944 and batch: 1700, loss is 5.145347661972046 and perplexity is 171.63114392179529
At time: 43.425307512283325 and batch: 1750, loss is 5.158605909347534 and perplexity is 173.9218237302702
At time: 44.65782809257507 and batch: 1800, loss is 5.1218788623809814 and perplexity is 167.65006529444764
At time: 45.88994097709656 and batch: 1850, loss is 5.107389373779297 and perplexity is 165.2384155626675
At time: 47.12466788291931 and batch: 1900, loss is 5.158309888839722 and perplexity is 173.87034692316118
At time: 48.35742473602295 and batch: 1950, loss is 5.069887742996216 and perplexity is 159.15645991312107
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.82874273255814 and perplexity of 125.0536359109329
finished 1 epochs...
Completing Train Step...
At time: 52.04391670227051 and batch: 50, loss is 5.0250161933898925 and perplexity is 152.17272028490842
At time: 53.20409870147705 and batch: 100, loss is 4.970217733383179 and perplexity is 144.0582502466242
At time: 54.3653838634491 and batch: 150, loss is 4.892115783691406 and perplexity is 133.23517285099965
At time: 55.52918481826782 and batch: 200, loss is 4.869324913024903 and perplexity is 130.23296863258312
At time: 56.69308543205261 and batch: 250, loss is 4.8817486000061034 and perplexity is 131.86103461993943
At time: 57.85783505439758 and batch: 300, loss is 4.893237180709839 and perplexity is 133.3846661816067
At time: 59.02252006530762 and batch: 350, loss is 4.889791803359985 and perplexity is 132.92589644517966
At time: 60.190231800079346 and batch: 400, loss is 4.854003219604492 and perplexity is 128.252787615046
At time: 61.38729238510132 and batch: 450, loss is 4.833710327148437 and perplexity is 125.67639720835116
At time: 62.55170941352844 and batch: 500, loss is 4.828379735946656 and perplexity is 125.00825010278912
At time: 63.717379570007324 and batch: 550, loss is 4.782034368515014 and perplexity is 119.34689881768757
At time: 64.88334393501282 and batch: 600, loss is 4.752174491882324 and perplexity is 115.83589507902428
At time: 66.04838514328003 and batch: 650, loss is 4.824233064651489 and perplexity is 124.49095524752776
At time: 67.21337890625 and batch: 700, loss is 4.829115571975708 and perplexity is 125.100269528596
At time: 68.37841701507568 and batch: 750, loss is 4.790086154937744 and perplexity is 120.31173366663486
At time: 69.54234075546265 and batch: 800, loss is 4.765329294204712 and perplexity is 117.3697601068429
At time: 70.70608282089233 and batch: 850, loss is 4.771735076904297 and perplexity is 118.12401851412986
At time: 71.86987137794495 and batch: 900, loss is 4.7636037445068355 and perplexity is 117.16740738779649
At time: 73.03619885444641 and batch: 950, loss is 4.8274679851531985 and perplexity is 124.89432567480503
At time: 74.20161485671997 and batch: 1000, loss is 4.797289352416993 and perplexity is 121.1814916017001
At time: 75.36630821228027 and batch: 1050, loss is 4.716273345947266 and perplexity is 111.75101832132809
At time: 76.53073978424072 and batch: 1100, loss is 4.790459432601929 and perplexity is 120.35665173248576
At time: 77.69645428657532 and batch: 1150, loss is 4.704157657623291 and perplexity is 110.40524675001643
At time: 78.86245226860046 and batch: 1200, loss is 4.789887208938598 and perplexity is 120.28780050935347
At time: 80.02738523483276 and batch: 1250, loss is 4.749858341217041 and perplexity is 115.56791215778469
At time: 81.19062852859497 and batch: 1300, loss is 4.767858104705811 and perplexity is 117.66694158816787
At time: 82.35416746139526 and batch: 1350, loss is 4.6639720153808595 and perplexity is 106.0565047094354
At time: 83.51780009269714 and batch: 1400, loss is 4.6799721431732175 and perplexity is 107.76707048097109
At time: 84.683021068573 and batch: 1450, loss is 4.614987373352051 and perplexity is 100.98655340277323
At time: 85.84662127494812 and batch: 1500, loss is 4.599025983810424 and perplexity is 99.38746348333198
At time: 87.01086354255676 and batch: 1550, loss is 4.604362106323242 and perplexity is 99.91922467435955
At time: 88.17395329475403 and batch: 1600, loss is 4.68677619934082 and perplexity is 108.50282389684094
At time: 89.33893394470215 and batch: 1650, loss is 4.640908498764038 and perplexity is 103.6384602392262
At time: 90.51093029975891 and batch: 1700, loss is 4.671158561706543 and perplexity is 106.82142998700465
At time: 91.68525671958923 and batch: 1750, loss is 4.670303325653077 and perplexity is 106.73011150379263
At time: 92.85606098175049 and batch: 1800, loss is 4.626924076080322 and perplexity is 102.19922311030824
At time: 94.02098345756531 and batch: 1850, loss is 4.642087869644165 and perplexity is 103.76076052581608
At time: 95.18656086921692 and batch: 1900, loss is 4.717976274490357 and perplexity is 111.94148444922106
At time: 96.35121464729309 and batch: 1950, loss is 4.639884805679321 and perplexity is 103.5324205494775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5903504837390985 and perplexity of 98.52895690828801
finished 2 epochs...
Completing Train Step...
At time: 100.08287763595581 and batch: 50, loss is 4.616041536331177 and perplexity is 101.09306581961972
At time: 101.2844591140747 and batch: 100, loss is 4.565598936080932 and perplexity is 96.12014660355308
At time: 102.44917726516724 and batch: 150, loss is 4.5167240715026855 and perplexity is 91.53524336440124
At time: 103.61363863945007 and batch: 200, loss is 4.507157173156738 and perplexity is 90.66371057614026
At time: 104.77665400505066 and batch: 250, loss is 4.511934175491333 and perplexity is 91.097847444067
At time: 105.94200587272644 and batch: 300, loss is 4.534016103744507 and perplexity is 93.13183814459472
At time: 107.1079523563385 and batch: 350, loss is 4.543102626800537 and perplexity is 93.98193912117401
At time: 108.27558755874634 and batch: 400, loss is 4.505129470825195 and perplexity is 90.48005781830649
At time: 109.438631772995 and batch: 450, loss is 4.507995090484619 and perplexity is 90.73971110687611
At time: 110.60490036010742 and batch: 500, loss is 4.51498929977417 and perplexity is 91.37658826702712
At time: 111.76714134216309 and batch: 550, loss is 4.4755798435211185 and perplexity is 87.84552230192948
At time: 112.92970275878906 and batch: 600, loss is 4.441809673309326 and perplexity is 84.92849552231901
At time: 114.09446454048157 and batch: 650, loss is 4.508467960357666 and perplexity is 90.78262932911494
At time: 115.2564013004303 and batch: 700, loss is 4.52661376953125 and perplexity is 92.44499042722215
At time: 116.4184799194336 and batch: 750, loss is 4.494560918807983 and perplexity is 89.52884991950347
At time: 117.58060073852539 and batch: 800, loss is 4.472740087509155 and perplexity is 87.59641631935799
At time: 118.74218034744263 and batch: 850, loss is 4.476197957992554 and perplexity is 87.89983767534491
At time: 119.90444684028625 and batch: 900, loss is 4.453954334259033 and perplexity is 85.96621190762808
At time: 121.12012505531311 and batch: 950, loss is 4.533599805831909 and perplexity is 93.09307562371686
At time: 122.28310799598694 and batch: 1000, loss is 4.5072932529449465 and perplexity is 90.67604891415382
At time: 123.44510006904602 and batch: 1050, loss is 4.44145770072937 and perplexity is 84.8986082806916
At time: 124.60530114173889 and batch: 1100, loss is 4.501577253341675 and perplexity is 90.15922314963832
At time: 125.76688194274902 and batch: 1150, loss is 4.434596405029297 and perplexity is 84.31808766400593
At time: 126.92951345443726 and batch: 1200, loss is 4.519920921325683 and perplexity is 91.82833602795006
At time: 128.10396528244019 and batch: 1250, loss is 4.490417957305908 and perplexity is 89.15870262339871
At time: 129.27129364013672 and batch: 1300, loss is 4.502231330871582 and perplexity is 90.21821356166275
At time: 130.43993997573853 and batch: 1350, loss is 4.3770739412307735 and perplexity is 79.60476407364234
At time: 131.60595846176147 and batch: 1400, loss is 4.406500377655029 and perplexity is 81.98205465596051
At time: 132.77018404006958 and batch: 1450, loss is 4.335666809082031 and perplexity is 76.37587003766257
At time: 133.933935880661 and batch: 1500, loss is 4.3324862241745 and perplexity is 76.13333600262547
At time: 135.09891319274902 and batch: 1550, loss is 4.338297538757324 and perplexity is 76.5770588260737
At time: 136.26396489143372 and batch: 1600, loss is 4.432284717559814 and perplexity is 84.12339571747006
At time: 137.4288945198059 and batch: 1650, loss is 4.381307296752929 and perplexity is 79.94247365924357
At time: 138.59451603889465 and batch: 1700, loss is 4.406558361053467 and perplexity is 81.98680839191789
At time: 139.76066184043884 and batch: 1750, loss is 4.416510200500488 and perplexity is 82.80680139757443
At time: 140.92483639717102 and batch: 1800, loss is 4.361101160049438 and perplexity is 78.34335551599364
At time: 142.0910062789917 and batch: 1850, loss is 4.38954942703247 and perplexity is 80.60409277201248
At time: 143.25407719612122 and batch: 1900, loss is 4.473481121063233 and perplexity is 87.66135225995146
At time: 144.41781330108643 and batch: 1950, loss is 4.398175067901612 and perplexity is 81.30236190888809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.505060524164244 and perplexity of 90.47381973548721
finished 3 epochs...
Completing Train Step...
At time: 148.1030924320221 and batch: 50, loss is 4.375046982765197 and perplexity is 79.44357194326868
At time: 149.26611995697021 and batch: 100, loss is 4.33066499710083 and perplexity is 75.99480609538793
At time: 150.47612404823303 and batch: 150, loss is 4.291434841156006 and perplexity is 73.0712389381382
At time: 151.63891434669495 and batch: 200, loss is 4.287693843841553 and perplexity is 72.79839031070912
At time: 152.80362844467163 and batch: 250, loss is 4.2933609628677365 and perplexity is 73.21211867016062
At time: 153.9664387702942 and batch: 300, loss is 4.309003639221191 and perplexity is 74.36635629437322
At time: 155.12879920005798 and batch: 350, loss is 4.318521308898926 and perplexity is 75.07752969696095
At time: 156.2915735244751 and batch: 400, loss is 4.281314878463745 and perplexity is 72.33548988192467
At time: 157.4559290409088 and batch: 450, loss is 4.294532194137573 and perplexity is 73.29791722804696
At time: 158.6187105178833 and batch: 500, loss is 4.309150190353393 and perplexity is 74.37725556671674
At time: 159.78027987480164 and batch: 550, loss is 4.272212123870849 and perplexity is 71.68002546103973
At time: 160.94243812561035 and batch: 600, loss is 4.241289248466492 and perplexity is 69.49739351363158
At time: 162.10500073432922 and batch: 650, loss is 4.308703184127808 and perplexity is 74.34401590015887
At time: 163.2675678730011 and batch: 700, loss is 4.334289264678955 and perplexity is 76.27073131861529
At time: 164.43031573295593 and batch: 750, loss is 4.298336420059204 and perplexity is 73.57729012665204
At time: 165.59270930290222 and batch: 800, loss is 4.277005114555359 and perplexity is 72.02441181634451
At time: 166.75438690185547 and batch: 850, loss is 4.279304714202881 and perplexity is 72.1902297126857
At time: 167.91616940498352 and batch: 900, loss is 4.250640892982483 and perplexity is 70.15035681425348
At time: 169.07888793945312 and batch: 950, loss is 4.337512855529785 and perplexity is 76.51699366154419
At time: 170.24159288406372 and batch: 1000, loss is 4.316196298599243 and perplexity is 74.90317643225028
At time: 171.4027395248413 and batch: 1050, loss is 4.257949361801147 and perplexity is 70.66492657776286
At time: 172.56601572036743 and batch: 1100, loss is 4.312852306365967 and perplexity is 74.65311911988596
At time: 173.7281289100647 and batch: 1150, loss is 4.253335938453675 and perplexity is 70.33967020520048
At time: 174.89243912696838 and batch: 1200, loss is 4.330660057067871 and perplexity is 75.99443067946841
At time: 176.0549235343933 and batch: 1250, loss is 4.3118679809570315 and perplexity is 74.57967231158999
At time: 177.21838688850403 and batch: 1300, loss is 4.310391912460327 and perplexity is 74.46966881311837
At time: 178.3816363811493 and batch: 1350, loss is 4.189618000984192 and perplexity is 65.99757513575885
At time: 179.54413866996765 and batch: 1400, loss is 4.221808452606201 and perplexity is 68.15663094027003
At time: 180.70694303512573 and batch: 1450, loss is 4.149188985824585 and perplexity is 63.382575280706035
At time: 181.8678810596466 and batch: 1500, loss is 4.147337603569031 and perplexity is 63.265338464087876
At time: 183.02869415283203 and batch: 1550, loss is 4.156929545402527 and perplexity is 63.875095613195846
At time: 184.18995118141174 and batch: 1600, loss is 4.258846011161804 and perplexity is 70.72831665408833
At time: 185.3511700630188 and batch: 1650, loss is 4.206663517951966 and perplexity is 67.13218041789743
At time: 186.51257276535034 and batch: 1700, loss is 4.234874439239502 and perplexity is 69.05300784098846
At time: 187.67598271369934 and batch: 1750, loss is 4.238864312171936 and perplexity is 69.32907092997696
At time: 188.8365821838379 and batch: 1800, loss is 4.1839395523071286 and perplexity is 65.62387331999102
At time: 189.9966881275177 and batch: 1850, loss is 4.219087796211243 and perplexity is 67.97145218455054
At time: 191.1563901901245 and batch: 1900, loss is 4.301818685531616 and perplexity is 73.83395240735193
At time: 192.3180091381073 and batch: 1950, loss is 4.2285538053512575 and perplexity is 68.61792550609414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474161689226017 and perplexity of 87.72103209119926
finished 4 epochs...
Completing Train Step...
At time: 195.99483728408813 and batch: 50, loss is 4.2077749156951905 and perplexity is 67.20683244807637
At time: 197.18455982208252 and batch: 100, loss is 4.166936044692993 and perplexity is 64.51747031304276
At time: 198.3488142490387 and batch: 150, loss is 4.1260570669174195 and perplexity is 61.93324224221231
At time: 199.51431274414062 and batch: 200, loss is 4.13099458694458 and perplexity is 62.23979504865085
At time: 200.67709517478943 and batch: 250, loss is 4.131018052101135 and perplexity is 62.24125553232077
At time: 201.84359526634216 and batch: 300, loss is 4.142774572372437 and perplexity is 62.97731438220038
At time: 203.00768184661865 and batch: 350, loss is 4.150411653518677 and perplexity is 63.46011850300642
At time: 204.17277812957764 and batch: 400, loss is 4.113219132423401 and perplexity is 61.14322925311527
At time: 205.33801460266113 and batch: 450, loss is 4.1379083776474 and perplexity is 62.67159894585302
At time: 206.50323796272278 and batch: 500, loss is 4.15634551525116 and perplexity is 63.837801522932956
At time: 207.66745162010193 and batch: 550, loss is 4.119507069587708 and perplexity is 61.528905319374395
At time: 208.8327386379242 and batch: 600, loss is 4.098002753257751 and perplexity is 60.219893422989045
At time: 210.02404713630676 and batch: 650, loss is 4.15652889251709 and perplexity is 63.8495089978488
At time: 211.1894736289978 and batch: 700, loss is 4.184757375717163 and perplexity is 65.67756401160901
At time: 212.35727214813232 and batch: 750, loss is 4.152878346443177 and perplexity is 63.6168483510398
At time: 213.52118229866028 and batch: 800, loss is 4.126629796028137 and perplexity is 61.96872337253379
At time: 214.68615770339966 and batch: 850, loss is 4.13084424495697 and perplexity is 62.230438497513646
At time: 215.85061621665955 and batch: 900, loss is 4.1011793899536135 and perplexity is 60.41149430833842
At time: 217.01487588882446 and batch: 950, loss is 4.189519662857055 and perplexity is 65.99108537692506
At time: 218.17936158180237 and batch: 1000, loss is 4.175296354293823 and perplexity is 65.0591173531424
At time: 219.34363842010498 and batch: 1050, loss is 4.114338293075561 and perplexity is 61.211696655306206
At time: 220.5080783367157 and batch: 1100, loss is 4.166405172348022 and perplexity is 64.48322886200998
At time: 221.67276668548584 and batch: 1150, loss is 4.111809887886047 and perplexity is 61.05712417709834
At time: 222.83626222610474 and batch: 1200, loss is 4.190517983436584 and perplexity is 66.0569985312772
At time: 224.00179433822632 and batch: 1250, loss is 4.171925096511841 and perplexity is 64.84015559312736
At time: 225.16559505462646 and batch: 1300, loss is 4.16669047832489 and perplexity is 64.50162893731296
At time: 226.32921385765076 and batch: 1350, loss is 4.044002728462219 and perplexity is 57.05425906436557
At time: 227.49293041229248 and batch: 1400, loss is 4.083075180053711 and perplexity is 59.32763276736167
At time: 228.65826201438904 and batch: 1450, loss is 4.007121448516846 and perplexity is 54.98835571344561
At time: 229.8226180076599 and batch: 1500, loss is 4.009213719367981 and perplexity is 55.10352668968061
At time: 230.98706698417664 and batch: 1550, loss is 4.02285481929779 and perplexity is 55.860349616587314
At time: 232.15080094337463 and batch: 1600, loss is 4.1230607509613035 and perplexity is 61.74794841831777
At time: 233.3145706653595 and batch: 1650, loss is 4.071473460197449 and perplexity is 58.643307542857436
At time: 234.47856640815735 and batch: 1700, loss is 4.1045738697052006 and perplexity is 60.616908342180366
At time: 235.64276552200317 and batch: 1750, loss is 4.110608525276184 and perplexity is 60.983816474429624
At time: 236.8068859577179 and batch: 1800, loss is 4.050520677566528 and perplexity is 57.42735039542852
At time: 237.97116708755493 and batch: 1850, loss is 4.091260380744934 and perplexity is 59.815234183484854
At time: 239.13488841056824 and batch: 1900, loss is 4.168767390251159 and perplexity is 64.63573235200202
At time: 240.2996883392334 and batch: 1950, loss is 4.092778367996216 and perplexity is 59.90610189697435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.475797999182412 and perplexity of 87.86468839045831
Annealing...
finished 5 epochs...
Completing Train Step...
At time: 243.97029852867126 and batch: 50, loss is 4.109617080688476 and perplexity is 60.92338436214381
At time: 245.1335039138794 and batch: 100, loss is 4.0959938049316404 and perplexity is 60.099036207495764
At time: 246.29713129997253 and batch: 150, loss is 4.06306526184082 and perplexity is 58.15229015934416
At time: 247.46125531196594 and batch: 200, loss is 4.065199580192566 and perplexity is 58.276538204703236
At time: 248.6253101825714 and batch: 250, loss is 4.063903336524963 and perplexity is 58.201046549446026
At time: 249.78883028030396 and batch: 300, loss is 4.064069700241089 and perplexity is 58.210729897288935
At time: 250.9539189338684 and batch: 350, loss is 4.07053475856781 and perplexity is 58.588284803507385
At time: 252.1195650100708 and batch: 400, loss is 4.0260880136489865 and perplexity is 56.0412492677017
At time: 253.28420066833496 and batch: 450, loss is 4.043280386924744 and perplexity is 57.01306128437871
At time: 254.4491367340088 and batch: 500, loss is 4.049091958999634 and perplexity is 57.34536145717681
At time: 255.61339473724365 and batch: 550, loss is 4.015638074874878 and perplexity is 55.458670899680875
At time: 256.77830958366394 and batch: 600, loss is 3.981421046257019 and perplexity is 53.59313846968426
At time: 257.9429061412811 and batch: 650, loss is 4.025935592651368 and perplexity is 56.03270805552708
At time: 259.1057348251343 and batch: 700, loss is 4.055339341163635 and perplexity is 57.7047412681676
At time: 260.270140171051 and batch: 750, loss is 4.007831358909607 and perplexity is 55.02740637824381
At time: 261.43514347076416 and batch: 800, loss is 3.979165415763855 and perplexity is 53.47238838730831
At time: 262.59883522987366 and batch: 850, loss is 3.9759530544281008 and perplexity is 53.300891357014066
At time: 263.76281571388245 and batch: 900, loss is 3.9402889585494996 and perplexity is 51.43346129183338
At time: 264.9266836643219 and batch: 950, loss is 4.039517154693604 and perplexity is 56.79891109573483
At time: 266.09079241752625 and batch: 1000, loss is 4.009484791755677 and perplexity is 55.11846575892393
At time: 267.25550985336304 and batch: 1050, loss is 3.9490568113327025 and perplexity is 51.88640507911716
At time: 268.44786524772644 and batch: 1100, loss is 3.9882400846481323 and perplexity is 53.95984099676509
At time: 269.6129834651947 and batch: 1150, loss is 3.944311361312866 and perplexity is 51.640764036721755
At time: 270.7788429260254 and batch: 1200, loss is 3.992839159965515 and perplexity is 54.208577911095205
At time: 271.94626927375793 and batch: 1250, loss is 3.9653638935089113 and perplexity is 52.739457444458814
At time: 273.1125581264496 and batch: 1300, loss is 3.9639620637893676 and perplexity is 52.665577501269205
At time: 274.2767310142517 and batch: 1350, loss is 3.8304163646697997 and perplexity is 46.081721040980874
At time: 275.4416890144348 and batch: 1400, loss is 3.8552421045303347 and perplexity is 47.24005258765269
At time: 276.60466957092285 and batch: 1450, loss is 3.772590789794922 and perplexity is 43.49259917859878
At time: 277.7670865058899 and batch: 1500, loss is 3.772820439338684 and perplexity is 43.502588381121164
At time: 278.93019223213196 and batch: 1550, loss is 3.779056396484375 and perplexity is 43.774716265047445
At time: 280.0917811393738 and batch: 1600, loss is 3.8665012741088867 and perplexity is 47.77494190480164
At time: 281.25415992736816 and batch: 1650, loss is 3.8038534784317015 and perplexity is 44.87377186089989
At time: 282.4190618991852 and batch: 1700, loss is 3.8315181350708007 and perplexity is 46.13252049678063
At time: 283.58420968055725 and batch: 1750, loss is 3.8166260147094726 and perplexity is 45.450599675164085
At time: 284.74855852127075 and batch: 1800, loss is 3.74942108631134 and perplexity is 42.496473087541766
At time: 285.913640499115 and batch: 1850, loss is 3.7820181226730347 and perplexity is 43.90455717030376
At time: 287.07720470428467 and batch: 1900, loss is 3.8489094591140747 and perplexity is 46.94184330855672
At time: 288.23998856544495 and batch: 1950, loss is 3.7671910333633423 and perplexity is 43.258382661624495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.401982932867006 and perplexity of 81.61254050872164
finished 6 epochs...
Completing Train Step...
At time: 291.9018952846527 and batch: 50, loss is 3.990402660369873 and perplexity is 54.076659507764134
At time: 293.09019231796265 and batch: 100, loss is 3.9685363578796387 and perplexity is 52.90703717394246
At time: 294.25580310821533 and batch: 150, loss is 3.9301545667648314 and perplexity is 50.914846804184805
At time: 295.42246532440186 and batch: 200, loss is 3.9313978576660156 and perplexity is 50.97818813764414
At time: 296.5882742404938 and batch: 250, loss is 3.927692346572876 and perplexity is 50.789637450070295
At time: 297.78038692474365 and batch: 300, loss is 3.9309130811691286 and perplexity is 50.95348109936073
At time: 298.9469392299652 and batch: 350, loss is 3.9400128650665285 and perplexity is 51.41926280850861
At time: 300.11348700523376 and batch: 400, loss is 3.900146894454956 and perplexity is 49.40970658439368
At time: 301.27857398986816 and batch: 450, loss is 3.926318883895874 and perplexity is 50.71992766150893
At time: 302.4418125152588 and batch: 500, loss is 3.935210886001587 and perplexity is 51.172940475639024
At time: 303.6072850227356 and batch: 550, loss is 3.901649775505066 and perplexity is 49.484019323727495
At time: 304.77932143211365 and batch: 600, loss is 3.8714055109024046 and perplexity is 48.00981700349102
At time: 305.9468996524811 and batch: 650, loss is 3.9165330743789672 and perplexity is 50.226012730936155
At time: 307.1114151477814 and batch: 700, loss is 3.9492745351791383 and perplexity is 51.89770321670107
At time: 308.2771534919739 and batch: 750, loss is 3.9061301136016846 and perplexity is 49.70622186022501
At time: 309.44308590888977 and batch: 800, loss is 3.878950262069702 and perplexity is 48.37340900723165
At time: 310.6093821525574 and batch: 850, loss is 3.88020712852478 and perplexity is 48.43424614640156
At time: 311.7754762172699 and batch: 900, loss is 3.844763746261597 and perplexity is 46.747638741766075
At time: 312.94963359832764 and batch: 950, loss is 3.947795562744141 and perplexity is 51.82100467569846
At time: 314.12383103370667 and batch: 1000, loss is 3.921108341217041 and perplexity is 50.45633663627374
At time: 315.2883026599884 and batch: 1050, loss is 3.8666234016418457 and perplexity is 47.78077689689308
At time: 316.4533998966217 and batch: 1100, loss is 3.9013139295578 and perplexity is 49.46740310678394
At time: 317.6188316345215 and batch: 1150, loss is 3.863601818084717 and perplexity is 47.636621186015475
At time: 318.7849826812744 and batch: 1200, loss is 3.9151378679275513 and perplexity is 50.15598593622245
At time: 319.9499442577362 and batch: 1250, loss is 3.89339693069458 and perplexity is 49.07731593000517
At time: 321.1228713989258 and batch: 1300, loss is 3.891068596839905 and perplexity is 48.96318047810908
At time: 322.2873899936676 and batch: 1350, loss is 3.759697585105896 and perplexity is 42.93543969878993
At time: 323.45454812049866 and batch: 1400, loss is 3.7897029638290407 and perplexity is 44.24325647649353
At time: 324.619517326355 and batch: 1450, loss is 3.7099258422851564 and perplexity is 40.850777014387816
At time: 325.7837743759155 and batch: 1500, loss is 3.713607573509216 and perplexity is 41.00145580484658
At time: 326.94859981536865 and batch: 1550, loss is 3.722738070487976 and perplexity is 41.3775337497958
At time: 328.11301016807556 and batch: 1600, loss is 3.814592080116272 and perplexity is 45.35825007656136
At time: 329.2790243625641 and batch: 1650, loss is 3.7542098426818846 and perplexity is 42.700466391047016
At time: 330.4456162452698 and batch: 1700, loss is 3.7853885316848754 and perplexity is 44.05278313620074
At time: 331.6140720844269 and batch: 1750, loss is 3.775736379623413 and perplexity is 43.629624455863095
At time: 332.7776107788086 and batch: 1800, loss is 3.7141939210891723 and perplexity is 41.02550395883189
At time: 333.9430215358734 and batch: 1850, loss is 3.7507503128051756 and perplexity is 42.55299808440342
At time: 335.10950756073 and batch: 1900, loss is 3.8227847051620483 and perplexity is 45.73137958022215
At time: 336.27285385131836 and batch: 1950, loss is 3.7442259311676027 and perplexity is 42.27626980715969
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4039573492005815 and perplexity of 81.77383682236602
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 339.94709181785583 and batch: 50, loss is 3.9443537521362306 and perplexity is 51.64295317762785
At time: 341.1118311882019 and batch: 100, loss is 3.9488102626800536 and perplexity is 51.8736141327142
At time: 342.27664494514465 and batch: 150, loss is 3.916520843505859 and perplexity is 50.225398426704466
At time: 343.4398386478424 and batch: 200, loss is 3.9263438892364504 and perplexity is 50.721195946431
At time: 344.6024606227875 and batch: 250, loss is 3.935812540054321 and perplexity is 51.20373814650924
At time: 345.7645673751831 and batch: 300, loss is 3.941204786300659 and perplexity is 51.48058705927159
At time: 346.92782402038574 and batch: 350, loss is 3.954233331680298 and perplexity is 52.15569249534082
At time: 348.08989810943604 and batch: 400, loss is 3.912748875617981 and perplexity is 50.03630668486773
At time: 349.25318241119385 and batch: 450, loss is 3.9346166610717774 and perplexity is 51.14254127155371
At time: 350.4164559841156 and batch: 500, loss is 3.941814980506897 and perplexity is 51.51200980124143
At time: 351.58001136779785 and batch: 550, loss is 3.9089779663085937 and perplexity is 49.847979615495674
At time: 352.7426197528839 and batch: 600, loss is 3.864633812904358 and perplexity is 47.685807307850794
At time: 353.90580105781555 and batch: 650, loss is 3.8983849239349366 and perplexity is 49.322724790170966
At time: 355.0678925514221 and batch: 700, loss is 3.9247653007507326 and perplexity is 50.64119121441644
At time: 356.23148584365845 and batch: 750, loss is 3.8728151750564574 and perplexity is 48.07754244541231
At time: 357.42156863212585 and batch: 800, loss is 3.847807598114014 and perplexity is 46.890148407671866
At time: 358.5842876434326 and batch: 850, loss is 3.850343933105469 and perplexity is 47.00922848147497
At time: 359.74759912490845 and batch: 900, loss is 3.8131131887435914 and perplexity is 45.29121972936129
At time: 360.9094662666321 and batch: 950, loss is 3.917214484214783 and perplexity is 50.26024889312894
At time: 362.07286834716797 and batch: 1000, loss is 3.891141095161438 and perplexity is 48.966730355189185
At time: 363.2360372543335 and batch: 1050, loss is 3.8285736322402952 and perplexity is 45.996882950168676
At time: 364.3985826969147 and batch: 1100, loss is 3.8570678663253783 and perplexity is 47.326380453942654
At time: 365.562153339386 and batch: 1150, loss is 3.8331926536560057 and perplexity is 46.20983497393339
At time: 366.72534465789795 and batch: 1200, loss is 3.881836495399475 and perplexity is 48.51322763010639
At time: 367.8889045715332 and batch: 1250, loss is 3.855919518470764 and perplexity is 47.27206449925561
At time: 369.05318999290466 and batch: 1300, loss is 3.8550859785079954 and perplexity is 47.232677761863165
At time: 370.21473956108093 and batch: 1350, loss is 3.7130632066726683 and perplexity is 40.97914204604241
At time: 371.37814569473267 and batch: 1400, loss is 3.737073149681091 and perplexity is 41.97495578848979
At time: 372.5415093898773 and batch: 1450, loss is 3.6465957450866697 and perplexity is 38.3439111658487
At time: 373.70405411720276 and batch: 1500, loss is 3.6480307388305664 and perplexity is 38.398973936405056
At time: 374.86686086654663 and batch: 1550, loss is 3.662783188819885 and perplexity is 38.96965197877136
At time: 376.0294692516327 and batch: 1600, loss is 3.753078579902649 and perplexity is 42.65218825554038
At time: 377.1928482055664 and batch: 1650, loss is 3.688394331932068 and perplexity is 39.98059981883484
At time: 378.35695600509644 and batch: 1700, loss is 3.711188039779663 and perplexity is 40.90237131703404
At time: 379.5177209377289 and batch: 1750, loss is 3.701278419494629 and perplexity is 40.49904604921151
At time: 380.6820914745331 and batch: 1800, loss is 3.6349457359313964 and perplexity is 37.89979624419801
At time: 381.8451542854309 and batch: 1850, loss is 3.6617063331604003 and perplexity is 38.92770987533866
At time: 383.00924587249756 and batch: 1900, loss is 3.7317894077301026 and perplexity is 41.753755850016596
At time: 384.18172430992126 and batch: 1950, loss is 3.6575971269607543 and perplexity is 38.76807609726179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370232728470204 and perplexity of 79.06202954381727
finished 8 epochs...
Completing Train Step...
At time: 387.82068943977356 and batch: 50, loss is 3.925135064125061 and perplexity is 50.659919934543865
At time: 389.0102515220642 and batch: 100, loss is 3.9140865325927736 and perplexity is 50.10328288510145
At time: 390.1744318008423 and batch: 150, loss is 3.8708034324645997 and perplexity is 47.980920027866155
At time: 391.3393349647522 and batch: 200, loss is 3.878022575378418 and perplexity is 48.32855444818916
At time: 392.50570726394653 and batch: 250, loss is 3.883997621536255 and perplexity is 48.61818420566702
At time: 393.6697680950165 and batch: 300, loss is 3.8879200410842896 and perplexity is 48.809259615766635
At time: 394.8332555294037 and batch: 350, loss is 3.900701632499695 and perplexity is 49.43712363235212
At time: 395.9979360103607 and batch: 400, loss is 3.8619722080230714 and perplexity is 47.559055287078145
At time: 397.16294169425964 and batch: 450, loss is 3.889108862876892 and perplexity is 48.8673196319469
At time: 398.3271894454956 and batch: 500, loss is 3.8985143518447876 and perplexity is 49.329108940483415
At time: 399.49207854270935 and batch: 550, loss is 3.866917247772217 and perplexity is 47.79481915632112
At time: 400.65732049942017 and batch: 600, loss is 3.825398473739624 and perplexity is 45.851067172872526
At time: 401.8242437839508 and batch: 650, loss is 3.8574915170669555 and perplexity is 47.34643455778617
At time: 403.0006785392761 and batch: 700, loss is 3.8872580480575563 and perplexity is 48.77695891885865
At time: 404.17139172554016 and batch: 750, loss is 3.836463747024536 and perplexity is 46.361239152276696
At time: 405.3383285999298 and batch: 800, loss is 3.8116379976272583 and perplexity is 45.22445578126778
At time: 406.5028946399689 and batch: 850, loss is 3.815720405578613 and perplexity is 45.40945782912273
At time: 407.67012310028076 and batch: 900, loss is 3.778515114784241 and perplexity is 43.751028223734615
At time: 408.83462500572205 and batch: 950, loss is 3.8854448986053467 and perplexity is 48.6885991314715
At time: 410.00222086906433 and batch: 1000, loss is 3.859443416595459 and perplexity is 47.43894029265609
At time: 411.1668772697449 and batch: 1050, loss is 3.798752121925354 and perplexity is 44.64543765512356
At time: 412.3335416316986 and batch: 1100, loss is 3.8280203676223756 and perplexity is 45.97144154086253
At time: 413.5008521080017 and batch: 1150, loss is 3.8066749572753906 and perplexity is 45.00056104122557
At time: 414.66477727890015 and batch: 1200, loss is 3.856767792701721 and perplexity is 47.312181185984706
At time: 415.8762409687042 and batch: 1250, loss is 3.8325271081924437 and perplexity is 46.179090459965295
At time: 417.0408573150635 and batch: 1300, loss is 3.8330565071105958 and perplexity is 46.203544092788306
At time: 418.2058436870575 and batch: 1350, loss is 3.692733187675476 and perplexity is 40.1544467496288
At time: 419.3710539340973 and batch: 1400, loss is 3.718454694747925 and perplexity is 41.20067726733528
At time: 420.5380713939667 and batch: 1450, loss is 3.6314300966262816 and perplexity is 37.76678817206439
At time: 421.70208740234375 and batch: 1500, loss is 3.634411997795105 and perplexity is 37.87957307500321
At time: 422.8671190738678 and batch: 1550, loss is 3.6512102365493773 and perplexity is 38.52125768387265
At time: 424.03212428092957 and batch: 1600, loss is 3.7427323913574218 and perplexity is 42.21317564372766
At time: 425.1979660987854 and batch: 1650, loss is 3.6803260326385496 and perplexity is 39.659322198422025
At time: 426.36371541023254 and batch: 1700, loss is 3.705622992515564 and perplexity is 40.67537988229449
At time: 427.5286023616791 and batch: 1750, loss is 3.69795804977417 and perplexity is 40.3647972441753
At time: 428.69498205184937 and batch: 1800, loss is 3.6335871267318725 and perplexity is 37.84834019460661
At time: 429.85995507240295 and batch: 1850, loss is 3.6623274421691896 and perplexity is 38.95189573688448
At time: 431.0248599052429 and batch: 1900, loss is 3.7340997743606565 and perplexity is 41.85033385657511
At time: 432.18771266937256 and batch: 1950, loss is 3.6598153924942016 and perplexity is 38.85416943790821
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370548691860465 and perplexity of 79.08701419762299
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 435.8706955909729 and batch: 50, loss is 3.9126294565200808 and perplexity is 50.030331751028875
At time: 437.0355975627899 and batch: 100, loss is 3.9166342544555666 and perplexity is 50.23109485985231
At time: 438.2004244327545 and batch: 150, loss is 3.8797369813919067 and perplexity is 48.41148027651652
At time: 439.3654897212982 and batch: 200, loss is 3.8925831079483033 and perplexity is 49.03739194170352
At time: 440.5311243534088 and batch: 250, loss is 3.901942210197449 and perplexity is 49.49849228379097
At time: 441.6975827217102 and batch: 300, loss is 3.906095018386841 and perplexity is 49.70447744030034
At time: 442.86140990257263 and batch: 350, loss is 3.9335147523880005 and perplexity is 51.08621789852209
At time: 444.0251986980438 and batch: 400, loss is 3.9033139514923096 and perplexity is 49.56643800100875
At time: 445.21626710891724 and batch: 450, loss is 3.928923420906067 and perplexity is 50.85220177189095
At time: 446.3818871974945 and batch: 500, loss is 3.9388618755340574 and perplexity is 51.360113821710904
At time: 447.5466024875641 and batch: 550, loss is 3.911458125114441 and perplexity is 49.971763960057125
At time: 448.711745262146 and batch: 600, loss is 3.869077286720276 and perplexity is 47.8981694073139
At time: 449.8755843639374 and batch: 650, loss is 3.8902543687820437 and perplexity is 48.92332950885199
At time: 451.03913378715515 and batch: 700, loss is 3.9170174169540406 and perplexity is 50.25034521943232
At time: 452.20385670661926 and batch: 750, loss is 3.8610048055648805 and perplexity is 47.513068787397046
At time: 453.3678026199341 and batch: 800, loss is 3.828252840042114 and perplexity is 45.98212987543976
At time: 454.5310101509094 and batch: 850, loss is 3.823575577735901 and perplexity is 45.76756157988627
At time: 455.6954073905945 and batch: 900, loss is 3.7808971214294433 and perplexity is 43.85536768300587
At time: 456.8582992553711 and batch: 950, loss is 3.8880431842803955 and perplexity is 48.815270514088304
At time: 458.02247738838196 and batch: 1000, loss is 3.856800775527954 and perplexity is 47.31374170117042
At time: 459.1868784427643 and batch: 1050, loss is 3.797835087776184 and perplexity is 44.604515030779
At time: 460.35169744491577 and batch: 1100, loss is 3.818816614151001 and perplexity is 45.55027286558858
At time: 461.5151300430298 and batch: 1150, loss is 3.799698133468628 and perplexity is 44.68769273824671
At time: 462.6795988082886 and batch: 1200, loss is 3.8548652648925783 and perplexity is 47.22225401716202
At time: 463.84329175949097 and batch: 1250, loss is 3.8337309217453 and perplexity is 46.23471494895902
At time: 465.007937669754 and batch: 1300, loss is 3.8396664094924926 and perplexity is 46.509956571609486
At time: 466.17190289497375 and batch: 1350, loss is 3.7027190637588503 and perplexity is 40.55743281478994
At time: 467.33656430244446 and batch: 1400, loss is 3.7316830778121948 and perplexity is 41.74931641261141
At time: 468.5014486312866 and batch: 1450, loss is 3.6392553663253784 and perplexity is 38.06348281899199
At time: 469.6651198863983 and batch: 1500, loss is 3.6326089906692505 and perplexity is 37.811337467952754
At time: 470.8315591812134 and batch: 1550, loss is 3.644247646331787 and perplexity is 38.2539814989717
At time: 472.0157518386841 and batch: 1600, loss is 3.7307488441467287 and perplexity is 41.71033100928219
At time: 473.18210220336914 and batch: 1650, loss is 3.6671311140060423 and perplexity is 39.139457994524555
At time: 474.34455919265747 and batch: 1700, loss is 3.689103465080261 and perplexity is 40.008961442346205
At time: 475.5095603466034 and batch: 1750, loss is 3.681991138458252 and perplexity is 39.72541417641824
At time: 476.6738657951355 and batch: 1800, loss is 3.618749499320984 and perplexity is 37.29090634932161
At time: 477.8383014202118 and batch: 1850, loss is 3.644284338951111 and perplexity is 38.255385163504364
At time: 479.00131344795227 and batch: 1900, loss is 3.7182809019088747 and perplexity is 41.19351750683777
At time: 480.16426944732666 and batch: 1950, loss is 3.649649419784546 and perplexity is 38.461179956435885
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35353890352471 and perplexity of 77.75313746748407
finished 10 epochs...
Completing Train Step...
At time: 483.8202745914459 and batch: 50, loss is 3.9183271646499636 and perplexity is 50.316203612827636
At time: 485.00930881500244 and batch: 100, loss is 3.906667594909668 and perplexity is 49.73294520637153
At time: 486.17196679115295 and batch: 150, loss is 3.8638858127593996 and perplexity is 47.65015165395166
At time: 487.3344099521637 and batch: 200, loss is 3.8724018812179564 and perplexity is 48.05767639888944
At time: 488.4973199367523 and batch: 250, loss is 3.877289891242981 and perplexity is 48.29315785190213
At time: 489.6604070663452 and batch: 300, loss is 3.8783648920059206 and perplexity is 48.345100947869355
At time: 490.82291746139526 and batch: 350, loss is 3.900520567893982 and perplexity is 49.428173129388135
At time: 491.98615741729736 and batch: 400, loss is 3.8706139278411866 and perplexity is 47.9718282831763
At time: 493.1506760120392 and batch: 450, loss is 3.8988820791244505 and perplexity is 49.34725193515489
At time: 494.31427001953125 and batch: 500, loss is 3.911166648864746 and perplexity is 49.95720050026183
At time: 495.4779670238495 and batch: 550, loss is 3.8848697900772096 and perplexity is 48.66060595321727
At time: 496.6413881778717 and batch: 600, loss is 3.8462000942230223 and perplexity is 46.814832862891386
At time: 497.80466079711914 and batch: 650, loss is 3.8684546375274658 and perplexity is 47.86835493373755
At time: 498.967613697052 and batch: 700, loss is 3.8975072050094606 and perplexity is 49.279452294488856
At time: 500.1360981464386 and batch: 750, loss is 3.844115586280823 and perplexity is 46.71734861062383
At time: 501.29873871803284 and batch: 800, loss is 3.812428379058838 and perplexity is 45.26021448101518
At time: 502.46119952201843 and batch: 850, loss is 3.8097034692764282 and perplexity is 45.13705235886557
At time: 503.62329387664795 and batch: 900, loss is 3.768475341796875 and perplexity is 43.31397545880548
At time: 504.8125259876251 and batch: 950, loss is 3.8774658679962157 and perplexity is 48.301657072835084
At time: 505.9758462905884 and batch: 1000, loss is 3.845798020362854 and perplexity is 46.79601362594422
At time: 507.1396780014038 and batch: 1050, loss is 3.7862328338623046 and perplexity is 44.08999270277309
At time: 508.30265522003174 and batch: 1100, loss is 3.8078243064880373 and perplexity is 45.05231213496944
At time: 509.4665913581848 and batch: 1150, loss is 3.789350037574768 and perplexity is 44.22764462478667
At time: 510.6314425468445 and batch: 1200, loss is 3.8440159368515014 and perplexity is 46.7126934854395
At time: 511.7954478263855 and batch: 1250, loss is 3.8241343212127688 and perplexity is 45.79314105188726
At time: 512.9606964588165 and batch: 1300, loss is 3.83106303691864 and perplexity is 46.11153044857638
At time: 514.1233851909637 and batch: 1350, loss is 3.694514899253845 and perplexity is 40.22605416526326
At time: 515.2861111164093 and batch: 1400, loss is 3.7248233366012573 and perplexity is 41.46390694302358
At time: 516.4478449821472 and batch: 1450, loss is 3.6341705083847047 and perplexity is 37.87042666366031
At time: 517.6103322505951 and batch: 1500, loss is 3.6295911931991576 and perplexity is 37.69740251217987
At time: 518.7748205661774 and batch: 1550, loss is 3.6430584192276 and perplexity is 38.208515867169226
At time: 519.9374513626099 and batch: 1600, loss is 3.7310825634002684 and perplexity is 41.72425287267923
At time: 521.1005265712738 and batch: 1650, loss is 3.668854956626892 and perplexity is 39.20698644786298
At time: 522.2635352611542 and batch: 1700, loss is 3.691994194984436 and perplexity is 40.124783868644116
At time: 523.4271862506866 and batch: 1750, loss is 3.685833148956299 and perplexity is 39.87833320487598
At time: 524.590571641922 and batch: 1800, loss is 3.6233761501312256 and perplexity is 37.463838090307306
At time: 525.7536005973816 and batch: 1850, loss is 3.649531283378601 and perplexity is 38.45663655924302
At time: 526.9144639968872 and batch: 1900, loss is 3.7233519411087035 and perplexity is 41.40294200001423
At time: 528.076740026474 and batch: 1950, loss is 3.654782247543335 and perplexity is 38.65910208411103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35212771393532 and perplexity of 77.64349043392015
finished 11 epochs...
Completing Train Step...
At time: 531.7531604766846 and batch: 50, loss is 3.9121528816223146 and perplexity is 50.00649423142233
At time: 532.9187893867493 and batch: 100, loss is 3.898058743476868 and perplexity is 49.30663930473383
At time: 534.1111497879028 and batch: 150, loss is 3.8544995641708373 and perplexity is 47.204987962082534
At time: 535.2777316570282 and batch: 200, loss is 3.862387247085571 and perplexity is 47.578798249564784
At time: 536.4434974193573 and batch: 250, loss is 3.866301779747009 and perplexity is 47.76541202386298
At time: 537.6084702014923 and batch: 300, loss is 3.8664307451248168 and perplexity is 47.771572505506654
At time: 538.7742686271667 and batch: 350, loss is 3.8877273845672606 and perplexity is 48.79985709956739
At time: 539.9396376609802 and batch: 400, loss is 3.8580403232574465 and perplexity is 47.372425705568205
At time: 541.1051027774811 and batch: 450, loss is 3.8863870811462404 and perplexity is 48.73449429693042
At time: 542.2684164047241 and batch: 500, loss is 3.8987655735015867 and perplexity is 49.341503037727506
At time: 543.4344570636749 and batch: 550, loss is 3.872466778755188 and perplexity is 48.06079532493702
At time: 544.6001422405243 and batch: 600, loss is 3.8351894187927247 and perplexity is 46.302197343674855
At time: 545.7672667503357 and batch: 650, loss is 3.85803337097168 and perplexity is 47.3720963600721
At time: 546.9332418441772 and batch: 700, loss is 3.8879508781433105 and perplexity is 48.810764772993366
At time: 548.0995986461639 and batch: 750, loss is 3.8355112743377684 and perplexity is 46.317102361140215
At time: 549.2667098045349 and batch: 800, loss is 3.8043140459060667 and perplexity is 44.894444020767914
At time: 550.4358797073364 and batch: 850, loss is 3.8020548009872437 and perplexity is 44.793130964827434
At time: 551.6023550033569 and batch: 900, loss is 3.7612165117263796 and perplexity is 43.00070503519101
At time: 552.7704255580902 and batch: 950, loss is 3.870845007896423 and perplexity is 47.98291489680409
At time: 553.9406094551086 and batch: 1000, loss is 3.8388132190704347 and perplexity is 46.47029164540594
At time: 555.1087923049927 and batch: 1050, loss is 3.779591097831726 and perplexity is 43.79812892364652
At time: 556.2753875255585 and batch: 1100, loss is 3.8015811920166014 and perplexity is 44.7719215590582
At time: 557.4416356086731 and batch: 1150, loss is 3.7833149909973143 and perplexity is 43.96153253657792
At time: 558.6080048084259 and batch: 1200, loss is 3.837927474975586 and perplexity is 46.42914908257601
At time: 559.7727992534637 and batch: 1250, loss is 3.8186954832077027 and perplexity is 45.54475565222825
At time: 560.9393830299377 and batch: 1300, loss is 3.825831732749939 and perplexity is 45.870936864908465
At time: 562.1086714267731 and batch: 1350, loss is 3.6897801542282105 and perplexity is 40.03604423465733
At time: 563.2756233215332 and batch: 1400, loss is 3.720480170249939 and perplexity is 41.28421280083591
At time: 564.4435496330261 and batch: 1450, loss is 3.6309120655059814 and perplexity is 37.747228867079215
At time: 565.6105329990387 and batch: 1500, loss is 3.6272728347778322 and perplexity is 37.6101076510911
At time: 566.7771465778351 and batch: 1550, loss is 3.64146758556366 and perplexity is 38.14778079638491
At time: 567.9444379806519 and batch: 1600, loss is 3.730073847770691 and perplexity is 41.68218618690276
At time: 569.1122031211853 and batch: 1650, loss is 3.6684519338607786 and perplexity is 39.19118832344953
At time: 570.2794511318207 and batch: 1700, loss is 3.691928210258484 and perplexity is 40.122136333126065
At time: 571.4468884468079 and batch: 1750, loss is 3.6862031602859497 and perplexity is 39.89309137014517
At time: 572.6150250434875 and batch: 1800, loss is 3.6240970039367677 and perplexity is 37.49085377657519
At time: 573.779862165451 and batch: 1850, loss is 3.6505291652679444 and perplexity is 38.495030893710066
At time: 574.9439632892609 and batch: 1900, loss is 3.724553418159485 and perplexity is 41.45271658018232
At time: 576.109139919281 and batch: 1950, loss is 3.655705909729004 and perplexity is 38.6948265309585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351905148528343 and perplexity of 77.62621160177908
finished 12 epochs...
Completing Train Step...
At time: 579.7635300159454 and batch: 50, loss is 3.9059392642974853 and perplexity is 49.69673636754724
At time: 580.9552230834961 and batch: 100, loss is 3.8906241989135744 and perplexity is 48.94142617637937
At time: 582.1202266216278 and batch: 150, loss is 3.8467091941833496 and perplexity is 46.8386723602733
At time: 583.2854473590851 and batch: 200, loss is 3.8543564748764036 and perplexity is 47.1982339168886
At time: 584.450662612915 and batch: 250, loss is 3.857927041053772 and perplexity is 47.3670595567412
At time: 585.6151614189148 and batch: 300, loss is 3.857452878952026 and perplexity is 47.34460521614761
At time: 586.7804629802704 and batch: 350, loss is 3.8782048511505125 and perplexity is 48.33736437565919
At time: 587.9488995075226 and batch: 400, loss is 3.848712100982666 and perplexity is 46.93257986821418
At time: 589.1176693439484 and batch: 450, loss is 3.8771498012542724 and perplexity is 48.28639293782339
At time: 590.282389163971 and batch: 500, loss is 3.8896330070495604 and perplexity is 48.89293986652769
At time: 591.4466078281403 and batch: 550, loss is 3.8632796239852905 and perplexity is 47.621275420043105
At time: 592.6110265254974 and batch: 600, loss is 3.8268768882751463 and perplexity is 45.91890419031043
At time: 593.8126063346863 and batch: 650, loss is 3.85038067817688 and perplexity is 47.010955870668816
At time: 594.976674079895 and batch: 700, loss is 3.8807809782028198 and perplexity is 48.46204809926668
At time: 596.1444373130798 and batch: 750, loss is 3.8289956045150757 and perplexity is 46.01629645519234
At time: 597.3121607303619 and batch: 800, loss is 3.7981329441070555 and perplexity is 44.61780274678329
At time: 598.476948261261 and batch: 850, loss is 3.7960516738891603 and perplexity is 44.525037610881576
At time: 599.6415858268738 and batch: 900, loss is 3.7553975486755373 and perplexity is 42.75121212044956
At time: 600.8060803413391 and batch: 950, loss is 3.8654275608062743 and perplexity is 47.72367284320915
At time: 601.9702363014221 and batch: 1000, loss is 3.833137435913086 and perplexity is 46.20728344159101
At time: 603.1326920986176 and batch: 1050, loss is 3.774282875061035 and perplexity is 43.56625466295987
At time: 604.2971510887146 and batch: 1100, loss is 3.7964714670181277 and perplexity is 44.54373283952735
At time: 605.4611346721649 and batch: 1150, loss is 3.7782642459869384 and perplexity is 43.740053832527096
At time: 606.6270754337311 and batch: 1200, loss is 3.8328527450561523 and perplexity is 46.19413052281814
At time: 607.791403055191 and batch: 1250, loss is 3.814014015197754 and perplexity is 45.332037640401545
At time: 608.9563539028168 and batch: 1300, loss is 3.821247797012329 and perplexity is 45.66114863332903
At time: 610.1207928657532 and batch: 1350, loss is 3.6855265522003173 and perplexity is 39.86610851140285
At time: 611.2868180274963 and batch: 1400, loss is 3.716503171920776 and perplexity is 41.12035160932466
At time: 612.452306509018 and batch: 1450, loss is 3.6277011585235597 and perplexity is 37.62622040376838
At time: 613.6174714565277 and batch: 1500, loss is 3.624679193496704 and perplexity is 37.512686915132996
At time: 614.7819268703461 and batch: 1550, loss is 3.63937376499176 and perplexity is 38.06798975139773
At time: 615.9460117816925 and batch: 1600, loss is 3.728321785926819 and perplexity is 41.60922035790336
At time: 617.1097614765167 and batch: 1650, loss is 3.667101421356201 and perplexity is 39.1382958575569
At time: 618.2747213840485 and batch: 1700, loss is 3.6907307147979735 and perplexity is 40.07411901300066
At time: 619.4387919902802 and batch: 1750, loss is 3.6853375482559203 and perplexity is 39.85857437165993
At time: 620.6095542907715 and batch: 1800, loss is 3.62346981048584 and perplexity is 37.46734713099448
At time: 621.7722878456116 and batch: 1850, loss is 3.6501443338394166 and perplexity is 38.480219646079604
At time: 622.9352667331696 and batch: 1900, loss is 3.724456100463867 and perplexity is 41.44868269361508
At time: 624.0995059013367 and batch: 1950, loss is 3.6553652334213256 and perplexity is 38.6816463655422
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352118629632995 and perplexity of 77.64278510018318
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 627.759984254837 and batch: 50, loss is 3.904082293510437 and perplexity is 49.60453661252157
At time: 628.9252927303314 and batch: 100, loss is 3.8943724393844605 and perplexity is 49.125214637175
At time: 630.0907859802246 and batch: 150, loss is 3.8540499305725096 and perplexity is 47.18376778449604
At time: 631.2566413879395 and batch: 200, loss is 3.8646693658828735 and perplexity is 47.68750271047163
At time: 632.4281086921692 and batch: 250, loss is 3.8690063619613646 and perplexity is 47.89477236166515
At time: 633.6010184288025 and batch: 300, loss is 3.86549382686615 and perplexity is 47.72683540775546
At time: 634.7683103084564 and batch: 350, loss is 3.890834593772888 and perplexity is 48.95172428415085
At time: 635.9352602958679 and batch: 400, loss is 3.8681522703170774 and perplexity is 47.85388330077426
At time: 637.1019375324249 and batch: 450, loss is 3.895560793876648 and perplexity is 49.18362750739298
At time: 638.266679763794 and batch: 500, loss is 3.9125316667556764 and perplexity is 50.02543953588206
At time: 639.4331555366516 and batch: 550, loss is 3.8886192512512205 and perplexity is 48.84339948040968
At time: 640.6028606891632 and batch: 600, loss is 3.8515347957611086 and perplexity is 47.065243362539185
At time: 641.7704706192017 and batch: 650, loss is 3.8732326221466065 and perplexity is 48.09761646523673
At time: 642.9340772628784 and batch: 700, loss is 3.903300018310547 and perplexity is 49.56574738762999
At time: 644.1008341312408 and batch: 750, loss is 3.85443021774292 and perplexity is 47.201714578287536
At time: 645.2649285793304 and batch: 800, loss is 3.822690386772156 and perplexity is 45.72706647353842
At time: 646.4291598796844 and batch: 850, loss is 3.821698579788208 and perplexity is 45.68173653264636
At time: 647.5938632488251 and batch: 900, loss is 3.7802651929855347 and perplexity is 43.827662983364725
At time: 648.7600755691528 and batch: 950, loss is 3.8924641275405882 and perplexity is 49.03155779989818
At time: 649.9262917041779 and batch: 1000, loss is 3.8618952894210814 and perplexity is 47.555397251720784
At time: 651.0916709899902 and batch: 1050, loss is 3.800287847518921 and perplexity is 44.71405347041275
At time: 652.2844369411469 and batch: 1100, loss is 3.8107062005996704 and perplexity is 45.1823353946696
At time: 653.4510238170624 and batch: 1150, loss is 3.7876876163482667 and perplexity is 44.154180730451934
At time: 654.6179909706116 and batch: 1200, loss is 3.836181197166443 and perplexity is 46.34814164117029
At time: 655.7852649688721 and batch: 1250, loss is 3.814351534843445 and perplexity is 45.3473406760767
At time: 656.9515101909637 and batch: 1300, loss is 3.8167780685424804 and perplexity is 45.45751113850112
At time: 658.1183476448059 and batch: 1350, loss is 3.6826495265960695 and perplexity is 39.751577529757526
At time: 659.2828152179718 and batch: 1400, loss is 3.7142810106277464 and perplexity is 41.029077006626714
At time: 660.4480137825012 and batch: 1450, loss is 3.6241261386871337 and perplexity is 37.49194607915289
At time: 661.6144723892212 and batch: 1500, loss is 3.620950264930725 and perplexity is 37.3730652666707
At time: 662.7799777984619 and batch: 1550, loss is 3.637030906677246 and perplexity is 37.97890624086167
At time: 663.9452946186066 and batch: 1600, loss is 3.720797748565674 and perplexity is 41.297325853704066
At time: 665.1124165058136 and batch: 1650, loss is 3.659071044921875 and perplexity is 38.82525919218277
At time: 666.2779676914215 and batch: 1700, loss is 3.682489423751831 and perplexity is 39.74521369857937
At time: 667.44349193573 and batch: 1750, loss is 3.6744027137756348 and perplexity is 39.42510175315986
At time: 668.6092562675476 and batch: 1800, loss is 3.6149619245529174 and perplexity is 37.14993139847024
At time: 669.7745411396027 and batch: 1850, loss is 3.643141384124756 and perplexity is 38.2116859642602
At time: 670.9421265125275 and batch: 1900, loss is 3.7223153257369996 and perplexity is 41.36004531142794
At time: 672.1082315444946 and batch: 1950, loss is 3.657782130241394 and perplexity is 38.77524898200703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346371105105378 and perplexity of 77.19781126239042
finished 14 epochs...
Completing Train Step...
At time: 675.7629024982452 and batch: 50, loss is 3.911944727897644 and perplexity is 49.9960862766552
At time: 676.9518885612488 and batch: 100, loss is 3.8939589262008667 and perplexity is 49.10490491273446
At time: 678.1144828796387 and batch: 150, loss is 3.8510293197631835 and perplexity is 47.041459023395625
At time: 679.277583360672 and batch: 200, loss is 3.8575532579422 and perplexity is 47.3493578583381
At time: 680.4414234161377 and batch: 250, loss is 3.8604764318466187 and perplexity is 47.48797076172829
At time: 681.6287808418274 and batch: 300, loss is 3.8560420751571653 and perplexity is 47.27785836187104
At time: 682.7915923595428 and batch: 350, loss is 3.8802647161483765 and perplexity is 48.43703543985144
At time: 683.9554958343506 and batch: 400, loss is 3.8539845514297486 and perplexity is 47.18068305104577
At time: 685.1181435585022 and batch: 450, loss is 3.883589277267456 and perplexity is 48.59833530165613
At time: 686.2805368900299 and batch: 500, loss is 3.8983688068389895 and perplexity is 49.32192985748917
At time: 687.4436955451965 and batch: 550, loss is 3.874244017601013 and perplexity is 48.14628678421834
At time: 688.6049823760986 and batch: 600, loss is 3.8376035499572754 and perplexity is 46.41411195519165
At time: 689.7665717601776 and batch: 650, loss is 3.859364423751831 and perplexity is 47.435193103866176
At time: 690.9308786392212 and batch: 700, loss is 3.8904068183898928 and perplexity is 48.93078841978987
At time: 692.101469039917 and batch: 750, loss is 3.8420084047317506 and perplexity is 46.61901032031232
At time: 693.2647089958191 and batch: 800, loss is 3.810950345993042 and perplexity is 45.19336780041869
At time: 694.4270823001862 and batch: 850, loss is 3.809709186553955 and perplexity is 45.13731042065836
At time: 695.5910885334015 and batch: 900, loss is 3.7685978698730467 and perplexity is 43.319282962042244
At time: 696.7620692253113 and batch: 950, loss is 3.8816267919540404 and perplexity is 48.50305530574621
At time: 697.9264471530914 and batch: 1000, loss is 3.850908613204956 and perplexity is 47.03578115346787
At time: 699.0898017883301 and batch: 1050, loss is 3.7897278833389283 and perplexity is 44.244359010497995
At time: 700.2532184123993 and batch: 1100, loss is 3.8022730493545533 and perplexity is 44.80290805940585
At time: 701.4172461032867 and batch: 1150, loss is 3.7801843452453614 and perplexity is 43.82411975908822
At time: 702.5814335346222 and batch: 1200, loss is 3.830008053779602 and perplexity is 46.06290921323921
At time: 703.7455101013184 and batch: 1250, loss is 3.809423818588257 and perplexity is 45.12443151590735
At time: 704.9091589450836 and batch: 1300, loss is 3.8123486614227295 and perplexity is 45.256606587515286
At time: 706.071286201477 and batch: 1350, loss is 3.6786050176620484 and perplexity is 39.59112661060697
At time: 707.2357292175293 and batch: 1400, loss is 3.71165593624115 and perplexity is 40.921513869856824
At time: 708.3992414474487 and batch: 1450, loss is 3.6236042261123655 and perplexity is 37.4723836664203
At time: 709.5638949871063 and batch: 1500, loss is 3.621690340042114 and perplexity is 37.400734379458854
At time: 710.7268173694611 and batch: 1550, loss is 3.6390746068954467 and perplexity is 38.05660310734152
At time: 711.8913197517395 and batch: 1600, loss is 3.723894724845886 and perplexity is 41.42542094365398
At time: 713.0542345046997 and batch: 1650, loss is 3.6627329206466674 and perplexity is 38.967693094790626
At time: 714.218994140625 and batch: 1700, loss is 3.6872005891799926 and perplexity is 39.932901742857965
At time: 715.3816788196564 and batch: 1750, loss is 3.679935598373413 and perplexity is 39.64384086252233
At time: 716.5428805351257 and batch: 1800, loss is 3.620579595565796 and perplexity is 37.35921478343635
At time: 717.7041165828705 and batch: 1850, loss is 3.649158492088318 and perplexity is 38.44230293197186
At time: 718.8666203022003 and batch: 1900, loss is 3.728656392097473 and perplexity is 41.62314538936202
At time: 720.0294106006622 and batch: 1950, loss is 3.6638749122619627 and perplexity is 39.012219293005735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345096463935319 and perplexity of 77.09947443931262
finished 15 epochs...
Completing Train Step...
At time: 723.675891160965 and batch: 50, loss is 3.9129163932800295 and perplexity is 50.04468935208393
At time: 724.8399293422699 and batch: 100, loss is 3.892512755393982 and perplexity is 49.033942157275156
At time: 726.005352973938 and batch: 150, loss is 3.848976101875305 and perplexity is 46.94497174685477
At time: 727.1707997322083 and batch: 200, loss is 3.8544292736053465 and perplexity is 47.2016700133963
At time: 728.3358795642853 and batch: 250, loss is 3.8567644643783567 and perplexity is 47.312023716008696
At time: 729.5015308856964 and batch: 300, loss is 3.8520642137527465 and perplexity is 47.09016714612371
At time: 730.6653139591217 and batch: 350, loss is 3.874901599884033 and perplexity is 48.17795734125821
At time: 731.8289651870728 and batch: 400, loss is 3.8482302379608155 and perplexity is 46.909970241264695
At time: 732.9954144954681 and batch: 450, loss is 3.878015365600586 and perplexity is 48.32820601130472
At time: 734.1610932350159 and batch: 500, loss is 3.8926799201965334 and perplexity is 49.04213959167636
At time: 735.3261396884918 and batch: 550, loss is 3.868261704444885 and perplexity is 47.85912043531088
At time: 736.4919562339783 and batch: 600, loss is 3.8323205280303956 and perplexity is 46.16955176126173
At time: 737.6569511890411 and batch: 650, loss is 3.85415762424469 and perplexity is 47.18884945134283
At time: 738.8222053050995 and batch: 700, loss is 3.8855876827239992 and perplexity is 48.695551586525184
At time: 739.9870793819427 and batch: 750, loss is 3.8373673820495604 and perplexity is 46.403151725760914
At time: 741.180187702179 and batch: 800, loss is 3.8066328048706053 and perplexity is 44.9986641993395
At time: 742.3450617790222 and batch: 850, loss is 3.8055392265319825 and perplexity is 44.949481532355286
At time: 743.5105049610138 and batch: 900, loss is 3.764832272529602 and perplexity is 43.156466727780774
At time: 744.6751596927643 and batch: 950, loss is 3.87775239944458 and perplexity is 48.31549899957352
At time: 745.8421094417572 and batch: 1000, loss is 3.8475118398666384 and perplexity is 46.87628231016706
At time: 747.0071489810944 and batch: 1050, loss is 3.7863557815551756 and perplexity is 44.0954137989034
At time: 748.1729869842529 and batch: 1100, loss is 3.7995912408828736 and perplexity is 44.68291621051077
At time: 749.3375055789948 and batch: 1150, loss is 3.7778142309188842 and perplexity is 43.720374577537704
At time: 750.5025374889374 and batch: 1200, loss is 3.8278616952896116 and perplexity is 45.96414772367151
At time: 751.6668181419373 and batch: 1250, loss is 3.8076969671249388 and perplexity is 45.046575567489235
At time: 752.8331673145294 and batch: 1300, loss is 3.8108492565155028 and perplexity is 45.188799457389116
At time: 753.9982240200043 and batch: 1350, loss is 3.677308969497681 and perplexity is 39.539847840693774
At time: 755.1634120941162 and batch: 1400, loss is 3.710686740875244 and perplexity is 40.88187214164105
At time: 756.3278362751007 and batch: 1450, loss is 3.6233378934860228 and perplexity is 37.46240487696069
At time: 757.49343085289 and batch: 1500, loss is 3.621961221694946 and perplexity is 37.41086692450301
At time: 758.6579120159149 and batch: 1550, loss is 3.6397585535049437 and perplexity is 38.08264069515072
At time: 759.8235993385315 and batch: 1600, loss is 3.7249858283996584 and perplexity is 41.470645035259025
At time: 760.9891848564148 and batch: 1650, loss is 3.6639804887771605 and perplexity is 39.016338284599385
At time: 762.1559584140778 and batch: 1700, loss is 3.6886447048187256 and perplexity is 39.99061113024997
At time: 763.3211488723755 and batch: 1750, loss is 3.6815779972076417 and perplexity is 39.70900535893747
At time: 764.4849052429199 and batch: 1800, loss is 3.6222511672973634 and perplexity is 37.42171561353923
At time: 765.650009393692 and batch: 1850, loss is 3.651014657020569 and perplexity is 38.5137244511428
At time: 766.8155987262726 and batch: 1900, loss is 3.7304387521743774 and perplexity is 41.69739897563563
At time: 767.9792954921722 and batch: 1950, loss is 3.665524091720581 and perplexity is 39.07661052545357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3446828442950585 and perplexity of 77.06759117665709
finished 16 epochs...
Completing Train Step...
At time: 771.7408313751221 and batch: 50, loss is 3.911803197860718 and perplexity is 49.98901082942427
At time: 772.937816619873 and batch: 100, loss is 3.890528402328491 and perplexity is 48.93673797944279
At time: 774.1094114780426 and batch: 150, loss is 3.8467279624938966 and perplexity is 46.83955145127127
At time: 775.2710373401642 and batch: 200, loss is 3.8517312145233156 and perplexity is 47.07448876733918
At time: 776.4348745346069 and batch: 250, loss is 3.8538057136535646 and perplexity is 47.172246117053824
At time: 777.5991134643555 and batch: 300, loss is 3.8489839458465576 and perplexity is 46.94533998330782
At time: 778.7626054286957 and batch: 350, loss is 3.871095271110535 and perplexity is 47.99492475805916
At time: 779.9278028011322 and batch: 400, loss is 3.8444961977005003 and perplexity is 46.735133151287016
At time: 781.0911107063293 and batch: 450, loss is 3.8743222522735596 and perplexity is 48.150053640546695
At time: 782.2550077438354 and batch: 500, loss is 3.888982791900635 and perplexity is 48.86115926958343
At time: 783.4194598197937 and batch: 550, loss is 3.8644707107543947 and perplexity is 47.67803028439801
At time: 784.5836856365204 and batch: 600, loss is 3.8290372610092165 and perplexity is 46.01821337270176
At time: 785.7510237693787 and batch: 650, loss is 3.850978422164917 and perplexity is 47.03906478704333
At time: 786.9155399799347 and batch: 700, loss is 3.8825740098953245 and perplexity is 48.54902003581069
At time: 788.0795066356659 and batch: 750, loss is 3.8345056915283204 and perplexity is 46.27055008922739
At time: 789.2426340579987 and batch: 800, loss is 3.8039855051040647 and perplexity is 44.87969678679059
At time: 790.4065384864807 and batch: 850, loss is 3.803014917373657 and perplexity is 44.83615823615437
At time: 791.5698893070221 and batch: 900, loss is 3.762464337348938 and perplexity is 43.05439590817881
At time: 792.7380077838898 and batch: 950, loss is 3.8754059791564943 and perplexity is 48.20226343355995
At time: 793.9021074771881 and batch: 1000, loss is 3.8455279064178467 and perplexity is 46.78337507709409
At time: 795.0656273365021 and batch: 1050, loss is 3.784409008026123 and perplexity is 44.00965351957333
At time: 796.2291610240936 and batch: 1100, loss is 3.797939829826355 and perplexity is 44.60918724381452
At time: 797.3935520648956 and batch: 1150, loss is 3.776321864128113 and perplexity is 43.65517640433291
At time: 798.5585997104645 and batch: 1200, loss is 3.8264427900314333 and perplexity is 45.89897520053087
At time: 799.7497653961182 and batch: 1250, loss is 3.8065034484863283 and perplexity is 44.99284371130814
At time: 800.9139726161957 and batch: 1300, loss is 3.809741244316101 and perplexity is 45.13875744501378
At time: 802.0790679454803 and batch: 1350, loss is 3.6763248348236086 and perplexity is 39.50095444673409
At time: 803.2422871589661 and batch: 1400, loss is 3.709770317077637 and perplexity is 40.84442418284085
At time: 804.4068605899811 and batch: 1450, loss is 3.622771534919739 and perplexity is 37.441193730169346
At time: 805.569412946701 and batch: 1500, loss is 3.6217381048202513 and perplexity is 37.40252085990374
At time: 806.732764005661 and batch: 1550, loss is 3.6397329568862915 and perplexity is 38.081665920795096
At time: 807.8960793018341 and batch: 1600, loss is 3.725209002494812 and perplexity is 41.479901241774535
At time: 809.0604491233826 and batch: 1650, loss is 3.6643006658554076 and perplexity is 39.0288324218567
At time: 810.2232508659363 and batch: 1700, loss is 3.6890092945098876 and perplexity is 40.00519395302321
At time: 811.385260105133 and batch: 1750, loss is 3.6820216941833497 and perplexity is 39.726628033798264
At time: 812.554939031601 and batch: 1800, loss is 3.6227474784851075 and perplexity is 37.44029303937361
At time: 813.7198894023895 and batch: 1850, loss is 3.6516517400741577 and perplexity is 38.538268709856695
At time: 814.8839979171753 and batch: 1900, loss is 3.731000008583069 and perplexity is 41.72080847678823
At time: 816.0488641262054 and batch: 1950, loss is 3.665970139503479 and perplexity is 39.09404444883401
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3445162041242735 and perplexity of 77.0547496900849
finished 17 epochs...
Completing Train Step...
At time: 819.6855473518372 and batch: 50, loss is 3.9102490043640135 and perplexity is 49.911378577284026
At time: 820.8481094837189 and batch: 100, loss is 3.8885337495803833 and perplexity is 48.83922346667536
At time: 822.010452747345 and batch: 150, loss is 3.8445692682266235 and perplexity is 46.73854823682435
At time: 823.1714105606079 and batch: 200, loss is 3.8493423652648926 and perplexity is 46.9621691205228
At time: 824.3324153423309 and batch: 250, loss is 3.851259026527405 and perplexity is 47.052266005903114
At time: 825.4955995082855 and batch: 300, loss is 3.846366677284241 and perplexity is 46.82263207065004
At time: 826.6573770046234 and batch: 350, loss is 3.8680476713180543 and perplexity is 47.84887809425598
At time: 827.8198313713074 and batch: 400, loss is 3.841574831008911 and perplexity is 46.5988019236841
At time: 829.006863117218 and batch: 450, loss is 3.8714305639266966 and perplexity is 48.01101980966957
At time: 830.1684799194336 and batch: 500, loss is 3.8860921907424926 and perplexity is 48.72012508100682
At time: 831.3308806419373 and batch: 550, loss is 3.86151695728302 and perplexity is 47.53740891959882
At time: 832.4916315078735 and batch: 600, loss is 3.8264324378967287 and perplexity is 45.89850005061621
At time: 833.653379201889 and batch: 650, loss is 3.8484742498397826 and perplexity is 46.92141822791112
At time: 834.8155407905579 and batch: 700, loss is 3.880165057182312 and perplexity is 48.43220849550841
At time: 835.977062702179 and batch: 750, loss is 3.83224289894104 and perplexity is 46.165967800114174
At time: 837.1390116214752 and batch: 800, loss is 3.8018784618377683 and perplexity is 44.78523287860213
At time: 838.3021323680878 and batch: 850, loss is 3.800998730659485 and perplexity is 44.74585123808052
At time: 839.4639563560486 and batch: 900, loss is 3.7605389404296874 and perplexity is 42.97157886036599
At time: 840.625705242157 and batch: 950, loss is 3.8735223054885863 and perplexity is 48.11155156180087
At time: 841.7900042533875 and batch: 1000, loss is 3.8438986015319823 and perplexity is 46.707212758171515
At time: 842.9535481929779 and batch: 1050, loss is 3.782832398414612 and perplexity is 43.94032214545191
At time: 844.1161324977875 and batch: 1100, loss is 3.796552662849426 and perplexity is 44.54734975178151
At time: 845.2785828113556 and batch: 1150, loss is 3.7750407886505126 and perplexity is 43.59928663552079
At time: 846.4432525634766 and batch: 1200, loss is 3.825209336280823 and perplexity is 45.84239583860705
At time: 847.6051597595215 and batch: 1250, loss is 3.805432081222534 and perplexity is 44.94466566425041
At time: 848.7678623199463 and batch: 1300, loss is 3.808693084716797 and perplexity is 45.09146961002558
At time: 849.930074930191 and batch: 1350, loss is 3.6753674936294556 and perplexity is 39.46315665141394
At time: 851.0924642086029 and batch: 1400, loss is 3.7088207054138183 and perplexity is 40.8056562513881
At time: 852.2545347213745 and batch: 1450, loss is 3.6220439100265502 and perplexity is 37.41396049457217
At time: 853.4312658309937 and batch: 1500, loss is 3.6212626314163208 and perplexity is 37.38474118321156
At time: 854.6034233570099 and batch: 1550, loss is 3.6393867778778075 and perplexity is 38.06848512903356
At time: 855.7677733898163 and batch: 1600, loss is 3.725064573287964 and perplexity is 41.47391076514836
At time: 856.9298088550568 and batch: 1650, loss is 3.6642370128631594 and perplexity is 39.02634819895404
At time: 858.0918653011322 and batch: 1700, loss is 3.6889615440368653 and perplexity is 40.00328373169596
At time: 859.2517895698547 and batch: 1750, loss is 3.6820286893844605 and perplexity is 39.72690593052278
At time: 860.4134664535522 and batch: 1800, loss is 3.622813010215759 and perplexity is 37.44274664696628
At time: 861.5739362239838 and batch: 1850, loss is 3.6518382596969605 and perplexity is 38.5454575236065
At time: 862.737105846405 and batch: 1900, loss is 3.731140971183777 and perplexity is 41.726689964979954
At time: 863.9018037319183 and batch: 1950, loss is 3.665990824699402 and perplexity is 39.09485312516664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344458575581395 and perplexity of 77.05030926508726
finished 18 epochs...
Completing Train Step...
At time: 867.5260095596313 and batch: 50, loss is 3.9086194801330567 and perplexity is 49.83011300658256
At time: 868.7177608013153 and batch: 100, loss is 3.8866211414337157 and perplexity is 48.74590244172027
At time: 869.8828773498535 and batch: 150, loss is 3.8425360441207888 and perplexity is 46.643614837020536
At time: 871.0485899448395 and batch: 200, loss is 3.8471708202362063 and perplexity is 46.86029930311209
At time: 872.215895652771 and batch: 250, loss is 3.8489757061004637 and perplexity is 46.9449531672197
At time: 873.3824112415314 and batch: 300, loss is 3.844029912948608 and perplexity is 46.713346351142015
At time: 874.5484488010406 and batch: 350, loss is 3.8654322099685667 and perplexity is 47.723894718825164
At time: 875.7145648002625 and batch: 400, loss is 3.839063606262207 and perplexity is 46.481928668051786
At time: 876.8796186447144 and batch: 450, loss is 3.8689434719085694 and perplexity is 47.89176035161643
At time: 878.0460300445557 and batch: 500, loss is 3.8836120128631593 and perplexity is 48.59944022631992
At time: 879.2113029956818 and batch: 550, loss is 3.858972430229187 and perplexity is 47.41660245936825
At time: 880.3771049976349 and batch: 600, loss is 3.8241477680206297 and perplexity is 45.79375682759644
At time: 881.5438332557678 and batch: 650, loss is 3.84628577709198 and perplexity is 46.818844263932576
At time: 882.7104697227478 and batch: 700, loss is 3.8780469369888304 and perplexity is 48.32973182394576
At time: 883.8757691383362 and batch: 750, loss is 3.830261158943176 and perplexity is 46.074569448981016
At time: 885.0415606498718 and batch: 800, loss is 3.8000188064575195 and perplexity is 44.70202517213314
At time: 886.2065155506134 and batch: 850, loss is 3.799210867881775 and perplexity is 44.66592326760716
At time: 887.3726572990417 and batch: 900, loss is 3.758812837600708 and perplexity is 42.89746947513947
At time: 888.5642666816711 and batch: 950, loss is 3.8718381357192992 and perplexity is 48.03059173528955
At time: 889.7295482158661 and batch: 1000, loss is 3.842400951385498 and perplexity is 46.63731404911327
At time: 890.894152879715 and batch: 1050, loss is 3.7813954973220825 and perplexity is 43.87722958829269
At time: 892.0597257614136 and batch: 1100, loss is 3.7952699565887453 and perplexity is 44.490245219358464
At time: 893.2259223461151 and batch: 1150, loss is 3.7738402032852174 and perplexity is 43.546973379597326
At time: 894.3907535076141 and batch: 1200, loss is 3.824049434661865 and perplexity is 45.789253995070084
At time: 895.5564141273499 and batch: 1250, loss is 3.8044029092788696 and perplexity is 44.89843366974792
At time: 896.7220141887665 and batch: 1300, loss is 3.80765585899353 and perplexity is 45.04472382500239
At time: 897.889347076416 and batch: 1350, loss is 3.6744041204452516 and perplexity is 39.42515721129164
At time: 899.0558650493622 and batch: 1400, loss is 3.707847456932068 and perplexity is 40.76596152794255
At time: 900.2226755619049 and batch: 1450, loss is 3.621230568885803 and perplexity is 37.38354255302214
At time: 901.3884136676788 and batch: 1500, loss is 3.620654559135437 and perplexity is 37.362015468508865
At time: 902.5531754493713 and batch: 1550, loss is 3.638877511024475 and perplexity is 38.04910304714559
At time: 903.7170832157135 and batch: 1600, loss is 3.724734444618225 and perplexity is 41.46022129792573
At time: 904.8822886943817 and batch: 1650, loss is 3.66398078918457 and perplexity is 39.016350005398266
At time: 906.047506570816 and batch: 1700, loss is 3.6887127780914306 and perplexity is 39.99333351468683
At time: 907.2111129760742 and batch: 1750, loss is 3.6818298292160034 and perplexity is 39.719006616772624
At time: 908.3756186962128 and batch: 1800, loss is 3.6226737976074217 and perplexity is 37.43753450734843
At time: 909.5407202243805 and batch: 1850, loss is 3.651806893348694 and perplexity is 38.54424851232295
At time: 910.7066445350647 and batch: 1900, loss is 3.7310870599746706 and perplexity is 41.72444048930846
At time: 911.8730375766754 and batch: 1950, loss is 3.665810465812683 and perplexity is 39.087802656806964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344465672692587 and perplexity of 77.05085610163998
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 915.5168199539185 and batch: 50, loss is 3.908404173851013 and perplexity is 49.819385425116586
At time: 916.6809196472168 and batch: 100, loss is 3.8881186485290526 and perplexity is 48.81895446080203
At time: 917.8711712360382 and batch: 150, loss is 3.8450964641571046 and perplexity is 46.76319510554499
At time: 919.035834312439 and batch: 200, loss is 3.850329203605652 and perplexity is 47.00853606415214
At time: 920.2002854347229 and batch: 250, loss is 3.852099509239197 and perplexity is 47.091829245812306
At time: 921.3654365539551 and batch: 300, loss is 3.8457709693908693 and perplexity is 46.79474776541209
At time: 922.5298643112183 and batch: 350, loss is 3.868559899330139 and perplexity is 47.873393908269996
At time: 923.6952424049377 and batch: 400, loss is 3.842855110168457 and perplexity is 46.658499605341376
At time: 924.8594391345978 and batch: 450, loss is 3.8733599281311033 and perplexity is 48.103739969423884
At time: 926.023820400238 and batch: 500, loss is 3.8884479188919068 and perplexity is 48.83503174239242
At time: 927.1876058578491 and batch: 550, loss is 3.864644365310669 and perplexity is 47.68631051051977
At time: 928.3524508476257 and batch: 600, loss is 3.829125418663025 and perplexity is 46.022270409251945
At time: 929.5161345005035 and batch: 650, loss is 3.851119303703308 and perplexity is 47.045692189683386
At time: 930.6793658733368 and batch: 700, loss is 3.882682304382324 and perplexity is 48.55427791172415
At time: 931.8462529182434 and batch: 750, loss is 3.8361317205429075 and perplexity is 46.345848548342445
At time: 933.0101809501648 and batch: 800, loss is 3.8042992210388182 and perplexity is 44.89377847152847
At time: 934.1744539737701 and batch: 850, loss is 3.804681348800659 and perplexity is 44.91093690876519
At time: 935.339437007904 and batch: 900, loss is 3.7623003339767456 and perplexity is 43.04733542104983
At time: 936.5029563903809 and batch: 950, loss is 3.8764315128326414 and perplexity is 48.25172183427063
At time: 937.6670823097229 and batch: 1000, loss is 3.849632773399353 and perplexity is 46.97580929696054
At time: 938.8312668800354 and batch: 1050, loss is 3.789963278770447 and perplexity is 44.25477515638802
At time: 939.994236946106 and batch: 1100, loss is 3.8019078588485717 and perplexity is 44.78654944992843
At time: 941.1599769592285 and batch: 1150, loss is 3.779987015724182 and perplexity is 43.81547281969632
At time: 942.3251185417175 and batch: 1200, loss is 3.828610119819641 and perplexity is 45.99856129570418
At time: 943.4879233837128 and batch: 1250, loss is 3.8074372243881225 and perplexity is 45.03487656609823
At time: 944.6512818336487 and batch: 1300, loss is 3.809067978858948 and perplexity is 45.10837730694359
At time: 945.8144476413727 and batch: 1350, loss is 3.6742992401123047 and perplexity is 39.42102250450534
At time: 946.9774160385132 and batch: 1400, loss is 3.7064905071258547 and perplexity is 40.71068167881968
At time: 948.1427359580994 and batch: 1450, loss is 3.6168160009384156 and perplexity is 37.2188741017683
At time: 949.306939125061 and batch: 1500, loss is 3.6159561538696288 and perplexity is 37.186885316670775
At time: 950.4715843200684 and batch: 1550, loss is 3.6341167974472044 and perplexity is 37.86839266216522
At time: 951.6360459327698 and batch: 1600, loss is 3.7189048194885252 and perplexity is 41.219226886010745
At time: 952.7989075183868 and batch: 1650, loss is 3.6573611307144165 and perplexity is 38.75892805631921
At time: 953.9635944366455 and batch: 1700, loss is 3.680791611671448 and perplexity is 39.677791046317125
At time: 955.1275014877319 and batch: 1750, loss is 3.673705358505249 and perplexity is 39.397618034738535
At time: 956.2914106845856 and batch: 1800, loss is 3.6150914096832274 and perplexity is 37.1547420736271
At time: 957.4556522369385 and batch: 1850, loss is 3.6453896045684813 and perplexity is 38.29769090063641
At time: 958.6199972629547 and batch: 1900, loss is 3.7253808403015136 and perplexity is 41.48702966947528
At time: 959.7856159210205 and batch: 1950, loss is 3.6625809717178344 and perplexity is 38.96177244539533
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344268656885901 and perplexity of 77.0356773603443
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f1288f88b38>
ELAPSED
4942.647481203079


RESULTS SO FAR:
[{'best_accuracy': -78.41160778879484, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}}, {'best_accuracy': -78.90825503473185, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.10008266219030648, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.21726970941698143, 'batch_size': 32}}, {'best_accuracy': -78.77456827312196, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.6593070000175439, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.4915447901082358, 'batch_size': 32}}, {'best_accuracy': -84.84145327741672, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.4010388534776912, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.9900218516510327, 'batch_size': 32}}, {'best_accuracy': -77.0356773603443, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.45364638623135345, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.002155165347015542, 'batch_size': 32}}]
SETTINGS FOR THIS RUN
{'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.914303714397061, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.0, 'batch_size': 32}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6634376049041748 and batch: 50, loss is 7.465014448165894 and perplexity is 1745.8807728149939
At time: 2.873400926589966 and batch: 100, loss is 6.594952383041382 and perplexity is 731.3940591004383
At time: 4.082495212554932 and batch: 150, loss is 6.326230783462524 and perplexity is 559.0454543097774
At time: 5.294342994689941 and batch: 200, loss is 6.213542509078979 and perplexity is 499.46748909775306
At time: 6.5071189403533936 and batch: 250, loss is 6.098780527114868 and perplexity is 445.3143900072489
At time: 7.742180347442627 and batch: 300, loss is 6.020285911560059 and perplexity is 411.69628762899276
At time: 8.9515700340271 and batch: 350, loss is 5.973093738555908 and perplexity is 392.7187624650859
At time: 10.161616086959839 and batch: 400, loss is 5.911191730499268 and perplexity is 369.14581570628405
At time: 11.374665975570679 and batch: 450, loss is 5.837734422683716 and perplexity is 343.00136360530763
At time: 12.583707332611084 and batch: 500, loss is 5.816396837234497 and perplexity is 335.76007326591605
At time: 13.791703939437866 and batch: 550, loss is 5.755353736877441 and perplexity is 315.87726520115615
At time: 14.999051094055176 and batch: 600, loss is 5.791366157531738 and perplexity is 327.46008098754544
At time: 16.207621574401855 and batch: 650, loss is 5.872303199768067 and perplexity is 355.06582675618154
At time: 17.428929090499878 and batch: 700, loss is 5.7688355636596675 and perplexity is 320.16470408916814
At time: 18.652408599853516 and batch: 750, loss is 5.719590444564819 and perplexity is 304.7800730567209
At time: 19.875850915908813 and batch: 800, loss is 5.7188980007171635 and perplexity is 304.569103021126
At time: 21.097668647766113 and batch: 850, loss is 5.735413579940796 and perplexity is 309.64100558982324
At time: 22.31812024116516 and batch: 900, loss is 5.734644222259521 and perplexity is 309.40287252023427
At time: 23.53969645500183 and batch: 950, loss is 5.7572510719299315 and perplexity is 316.47715912863305
At time: 24.761330604553223 and batch: 1000, loss is 5.728412551879883 and perplexity is 307.48077097599617
At time: 25.984620571136475 and batch: 1050, loss is 5.634663400650024 and perplexity is 279.96466552431366
At time: 27.20737075805664 and batch: 1100, loss is 5.7226318359375 and perplexity is 305.70843958884103
At time: 28.431251525878906 and batch: 1150, loss is 5.625975980758667 and perplexity is 277.5430290369669
At time: 29.6559100151062 and batch: 1200, loss is 5.695960693359375 and perplexity is 297.6626187701334
At time: 30.87830352783203 and batch: 1250, loss is 5.637802181243896 and perplexity is 280.84479372550925
At time: 32.102924823760986 and batch: 1300, loss is 5.651687688827515 and perplexity is 284.77166645519054
At time: 33.32801795005798 and batch: 1350, loss is 5.62509482383728 and perplexity is 277.29857779171846
At time: 34.55250120162964 and batch: 1400, loss is 5.642638483047485 and perplexity is 282.2063336631143
At time: 35.77781343460083 and batch: 1450, loss is 5.601933116912842 and perplexity is 270.94967889754
At time: 37.00608015060425 and batch: 1500, loss is 5.584971017837525 and perplexity is 266.3925619950699
At time: 38.23297739028931 and batch: 1550, loss is 5.562535276412964 and perplexity is 260.48239475962066
At time: 39.45708107948303 and batch: 1600, loss is 5.58050573348999 and perplexity is 265.2056952784339
At time: 40.68381690979004 and batch: 1650, loss is 5.571623315811157 and perplexity is 262.86045862730276
At time: 41.91018629074097 and batch: 1700, loss is 5.581593837738037 and perplexity is 265.4944237769383
At time: 43.135239124298096 and batch: 1750, loss is 5.602156457901001 and perplexity is 271.0101998247165
At time: 44.36041569709778 and batch: 1800, loss is 5.6011214923858645 and perplexity is 270.72985871036474
At time: 45.58928084373474 and batch: 1850, loss is 5.572823963165283 and perplexity is 263.1762508810889
At time: 46.815632820129395 and batch: 1900, loss is 5.567933139801025 and perplexity is 261.8922448072821
At time: 48.04145789146423 and batch: 1950, loss is 5.4981409740448 and perplexity is 244.2374661741271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.134829215116279 and perplexity of 169.83531209368073
finished 1 epochs...
Completing Train Step...
At time: 51.71512579917908 and batch: 50, loss is 5.382743339538575 and perplexity is 217.61845860641736
At time: 52.90376091003418 and batch: 100, loss is 5.303484716415405 and perplexity is 201.03614472908703
At time: 54.06848669052124 and batch: 150, loss is 5.206902017593384 and perplexity is 182.527713738215
At time: 55.232253074645996 and batch: 200, loss is 5.171940383911132 and perplexity is 176.25651118632356
At time: 56.396379470825195 and batch: 250, loss is 5.172479801177978 and perplexity is 176.3516126392284
At time: 57.56001257896423 and batch: 300, loss is 5.19102822303772 and perplexity is 179.65318153592884
At time: 58.72359299659729 and batch: 350, loss is 5.149529628753662 and perplexity is 172.35040257401238
At time: 59.88596439361572 and batch: 400, loss is 5.115169496536255 and perplexity is 166.52900468082092
At time: 61.04727339744568 and batch: 450, loss is 5.072616596221923 and perplexity is 159.5913676619704
At time: 62.20928192138672 and batch: 500, loss is 5.053294067382812 and perplexity is 156.53726041839084
At time: 63.3718056678772 and batch: 550, loss is 5.002740230560303 and perplexity is 148.8204030930864
At time: 64.53480076789856 and batch: 600, loss is 5.0063934230804445 and perplexity is 149.3650669517293
At time: 65.69938683509827 and batch: 650, loss is 5.059458656311035 and perplexity is 157.50522877893434
At time: 66.86292290687561 and batch: 700, loss is 5.042829475402832 and perplexity is 154.90770305563052
At time: 68.0262622833252 and batch: 750, loss is 4.986974229812622 and perplexity is 146.49249959058784
At time: 69.18839192390442 and batch: 800, loss is 4.968148050308227 and perplexity is 143.7604036546278
At time: 70.35011982917786 and batch: 850, loss is 4.967327489852905 and perplexity is 143.64248793745116
At time: 71.53598117828369 and batch: 900, loss is 4.980529527664185 and perplexity is 145.5514347622016
At time: 72.69937634468079 and batch: 950, loss is 5.034206781387329 and perplexity is 153.57772357500704
At time: 73.86301708221436 and batch: 1000, loss is 5.0029690647125244 and perplexity is 148.85446218065414
At time: 75.026287317276 and batch: 1050, loss is 4.908676347732544 and perplexity is 135.45999376149635
At time: 76.19014573097229 and batch: 1100, loss is 4.993026065826416 and perplexity is 147.3817362184837
At time: 77.35448002815247 and batch: 1150, loss is 4.891832094192505 and perplexity is 133.19738079243606
At time: 78.51814842224121 and batch: 1200, loss is 4.970152502059936 and perplexity is 144.04885344282292
At time: 79.68078088760376 and batch: 1250, loss is 4.9128373432159425 and perplexity is 136.02481648117256
At time: 80.84416818618774 and batch: 1300, loss is 4.9434528732299805 and perplexity is 140.25369266662284
At time: 82.0075306892395 and batch: 1350, loss is 4.855941171646118 and perplexity is 128.50157635911225
At time: 83.16926884651184 and batch: 1400, loss is 4.875795173645019 and perplexity is 131.07834182416042
At time: 84.33552193641663 and batch: 1450, loss is 4.813601799011231 and perplexity is 123.17446918848354
At time: 85.51485419273376 and batch: 1500, loss is 4.783417224884033 and perplexity is 119.51205260250335
At time: 86.67991280555725 and batch: 1550, loss is 4.779933729171753 and perplexity is 119.09645716242537
At time: 87.84470677375793 and batch: 1600, loss is 4.8514933586120605 and perplexity is 127.93129456643918
At time: 89.00573921203613 and batch: 1650, loss is 4.8093949317932125 and perplexity is 122.6573789794923
At time: 90.17600274085999 and batch: 1700, loss is 4.838831939697266 and perplexity is 126.32171414243493
At time: 91.33727431297302 and batch: 1750, loss is 4.848874835968018 and perplexity is 127.59674178291446
At time: 92.49895477294922 and batch: 1800, loss is 4.799118452072143 and perplexity is 121.40334746258522
At time: 93.65859270095825 and batch: 1850, loss is 4.805137319564819 and perplexity is 122.1362615679808
At time: 94.81900525093079 and batch: 1900, loss is 4.871201009750366 and perplexity is 130.47752761500317
At time: 95.98006987571716 and batch: 1950, loss is 4.787093420028686 and perplexity is 119.95221078799392
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.662345566860465 and perplexity of 105.8841494657329
finished 2 epochs...
Completing Train Step...
At time: 99.57724642753601 and batch: 50, loss is 4.7489195728302 and perplexity is 115.45947156358253
At time: 100.76066756248474 and batch: 100, loss is 4.691281251907348 and perplexity is 108.99273753687712
At time: 101.92280077934265 and batch: 150, loss is 4.644903993606567 and perplexity is 104.05337551655028
At time: 103.08707308769226 and batch: 200, loss is 4.627791500091552 and perplexity is 102.28791163007801
At time: 104.25695419311523 and batch: 250, loss is 4.631763744354248 and perplexity is 102.69503225615908
At time: 105.41991972923279 and batch: 300, loss is 4.662721967697143 and perplexity is 105.92401184982945
At time: 106.58768939971924 and batch: 350, loss is 4.6577144241333 and perplexity is 105.39491858043807
At time: 107.75441765785217 and batch: 400, loss is 4.618598070144653 and perplexity is 101.35184430772799
At time: 108.9155478477478 and batch: 450, loss is 4.618627834320068 and perplexity is 101.35486100669516
At time: 110.08046269416809 and batch: 500, loss is 4.622771816253662 and perplexity is 101.77574518549973
At time: 111.24430727958679 and batch: 550, loss is 4.580229272842407 and perplexity is 97.53675417255798
At time: 112.40750455856323 and batch: 600, loss is 4.558025302886963 and perplexity is 95.39491764626557
At time: 113.56961250305176 and batch: 650, loss is 4.611714563369751 and perplexity is 100.65658386105667
At time: 114.73378324508667 and batch: 700, loss is 4.638753023147583 and perplexity is 103.41531064840203
At time: 115.91029191017151 and batch: 750, loss is 4.595383768081665 and perplexity is 99.02613132487156
At time: 117.07399535179138 and batch: 800, loss is 4.567135505676269 and perplexity is 96.26795542851465
At time: 118.24130821228027 and batch: 850, loss is 4.56764066696167 and perplexity is 96.31659855790026
At time: 119.4059190750122 and batch: 900, loss is 4.569798984527588 and perplexity is 96.52470486341892
At time: 120.56952929496765 and batch: 950, loss is 4.63604513168335 and perplexity is 103.13565202491307
At time: 121.73449087142944 and batch: 1000, loss is 4.615745639801025 and perplexity is 101.06315715737419
At time: 122.89839482307434 and batch: 1050, loss is 4.53709231376648 and perplexity is 93.41877234712152
At time: 124.06450700759888 and batch: 1100, loss is 4.61391206741333 and perplexity is 100.87802032575733
At time: 125.22905921936035 and batch: 1150, loss is 4.542030839920044 and perplexity is 93.88126447234188
At time: 126.39724898338318 and batch: 1200, loss is 4.613174629211426 and perplexity is 100.80365644259082
At time: 127.55958318710327 and batch: 1250, loss is 4.574501037597656 and perplexity is 96.97963786964135
At time: 128.72450280189514 and batch: 1300, loss is 4.592999629974365 and perplexity is 98.79032056596758
At time: 129.89566040039062 and batch: 1350, loss is 4.4726801776885985 and perplexity is 87.59116859097168
At time: 131.0764183998108 and batch: 1400, loss is 4.5062792873382564 and perplexity is 90.58415311666671
At time: 132.2436008453369 and batch: 1450, loss is 4.442782068252564 and perplexity is 85.01111972707072
At time: 133.40718245506287 and batch: 1500, loss is 4.436283960342407 and perplexity is 84.46049923073546
At time: 134.57171487808228 and batch: 1550, loss is 4.433955888748169 and perplexity is 84.26409784858728
At time: 135.73725080490112 and batch: 1600, loss is 4.521620006561279 and perplexity is 91.98449282218895
At time: 136.90203022956848 and batch: 1650, loss is 4.476648387908935 and perplexity is 87.93943931008992
At time: 138.06663846969604 and batch: 1700, loss is 4.501933317184449 and perplexity is 90.19133130503184
At time: 139.23208141326904 and batch: 1750, loss is 4.512923498153686 and perplexity is 91.18801720517455
At time: 140.39613509178162 and batch: 1800, loss is 4.462360134124756 and perplexity is 86.69187228531834
At time: 141.56158781051636 and batch: 1850, loss is 4.481531143188477 and perplexity is 88.36987607517415
At time: 142.7250897884369 and batch: 1900, loss is 4.563866786956787 and perplexity is 95.95379628916898
At time: 143.89043617248535 and batch: 1950, loss is 4.492281436920166 and perplexity is 89.32500294868017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525541083757267 and perplexity of 92.34587916823729
finished 3 epochs...
Completing Train Step...
At time: 147.54234051704407 and batch: 50, loss is 4.46145770072937 and perplexity is 86.61367393436817
At time: 148.70739269256592 and batch: 100, loss is 4.406511335372925 and perplexity is 81.98295299710982
At time: 149.87232494354248 and batch: 150, loss is 4.365800228118896 and perplexity is 78.71236259202631
At time: 151.03670024871826 and batch: 200, loss is 4.363148622512817 and perplexity is 78.50392491948737
At time: 152.20168113708496 and batch: 250, loss is 4.361933431625366 and perplexity is 78.40858560476153
At time: 153.3660991191864 and batch: 300, loss is 4.3875402736663816 and perplexity is 80.44230936595903
At time: 154.53119039535522 and batch: 350, loss is 4.386076908111573 and perplexity is 80.32467895042429
At time: 155.69513535499573 and batch: 400, loss is 4.352857265472412 and perplexity is 77.70015602943424
At time: 156.85927367210388 and batch: 450, loss is 4.369228067398072 and perplexity is 78.98263888747951
At time: 158.02441692352295 and batch: 500, loss is 4.382526712417603 and perplexity is 80.04001622427532
At time: 159.2108633518219 and batch: 550, loss is 4.342937154769897 and perplexity is 76.93317245082743
At time: 160.37624645233154 and batch: 600, loss is 4.324193391799927 and perplexity is 75.50458567289883
At time: 161.5420572757721 and batch: 650, loss is 4.369533214569092 and perplexity is 79.00674389389594
At time: 162.7059257030487 and batch: 700, loss is 4.40091272354126 and perplexity is 81.52524472748293
At time: 163.86979055404663 and batch: 750, loss is 4.364293088912964 and perplexity is 78.59382145580781
At time: 165.0327489376068 and batch: 800, loss is 4.335577483177185 and perplexity is 76.36904799865998
At time: 166.1981499195099 and batch: 850, loss is 4.337735061645508 and perplexity is 76.53399809466704
At time: 167.3612561225891 and batch: 900, loss is 4.325364847183227 and perplexity is 75.593087754248
At time: 168.52457356452942 and batch: 950, loss is 4.404439954757691 and perplexity is 81.81331085487021
At time: 169.68899250030518 and batch: 1000, loss is 4.386145420074463 and perplexity is 80.33018234036959
At time: 170.8535509109497 and batch: 1050, loss is 4.3156486511230465 and perplexity is 74.86216712706427
At time: 172.01887369155884 and batch: 1100, loss is 4.387580995559692 and perplexity is 80.44558519579724
At time: 173.18364191055298 and batch: 1150, loss is 4.327517795562744 and perplexity is 75.75601108986523
At time: 174.34864687919617 and batch: 1200, loss is 4.393897190093994 and perplexity is 80.95530320580434
At time: 175.5152668952942 and batch: 1250, loss is 4.368981418609619 and perplexity is 78.96316031757068
At time: 176.68112206459045 and batch: 1300, loss is 4.378923921585083 and perplexity is 79.75216762808816
At time: 177.84654211997986 and batch: 1350, loss is 4.244955291748047 and perplexity is 69.75264155551733
At time: 179.01159000396729 and batch: 1400, loss is 4.283854198455811 and perplexity is 72.51940624994616
At time: 180.1773443222046 and batch: 1450, loss is 4.223854398727417 and perplexity is 68.29621848057918
At time: 181.3424952030182 and batch: 1500, loss is 4.222742428779602 and perplexity is 68.22031734579069
At time: 182.50655460357666 and batch: 1550, loss is 4.225114498138428 and perplexity is 68.38233275013631
At time: 183.6705560684204 and batch: 1600, loss is 4.319283819198608 and perplexity is 75.13479891804026
At time: 184.83512949943542 and batch: 1650, loss is 4.271786499023437 and perplexity is 71.649523152871
At time: 186.00327706336975 and batch: 1700, loss is 4.294696173667908 and perplexity is 73.30993757160674
At time: 187.16868472099304 and batch: 1750, loss is 4.303097801208496 and perplexity is 73.92845500035135
At time: 188.3341042995453 and batch: 1800, loss is 4.2511763715744015 and perplexity is 70.1879308877011
At time: 189.4986116886139 and batch: 1850, loss is 4.2800914478302 and perplexity is 72.24704654088872
At time: 190.6636607646942 and batch: 1900, loss is 4.365408477783203 and perplexity is 78.68153303669625
At time: 191.82680988311768 and batch: 1950, loss is 4.292881355285645 and perplexity is 73.17701400185086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4813235260719475 and perplexity of 88.35153088076947
finished 4 epochs...
Completing Train Step...
At time: 195.48042035102844 and batch: 50, loss is 4.2655003643035885 and perplexity is 71.20053726908596
At time: 196.64359164237976 and batch: 100, loss is 4.2206955575943 and perplexity is 68.0808219572125
At time: 197.80655193328857 and batch: 150, loss is 4.177254815101623 and perplexity is 65.18665793551871
At time: 198.96911311149597 and batch: 200, loss is 4.177833285331726 and perplexity is 65.22437738527185
At time: 200.13084149360657 and batch: 250, loss is 4.177930736541748 and perplexity is 65.2307338894905
At time: 201.29378581047058 and batch: 300, loss is 4.203765468597412 and perplexity is 66.93790968482216
At time: 202.4587960243225 and batch: 350, loss is 4.205929841995239 and perplexity is 67.08294521475311
At time: 203.621169090271 and batch: 400, loss is 4.174992265701294 and perplexity is 65.03933662541458
At time: 204.78482937812805 and batch: 450, loss is 4.199560918807983 and perplexity is 66.65705675456508
At time: 205.95908522605896 and batch: 500, loss is 4.214021372795105 and perplexity is 67.62795092375679
At time: 207.14116597175598 and batch: 550, loss is 4.177863812446594 and perplexity is 65.22636852772425
At time: 208.31279969215393 and batch: 600, loss is 4.158054070472717 and perplexity is 63.94696516155458
At time: 209.48353242874146 and batch: 650, loss is 4.198405876159668 and perplexity is 66.58010945846145
At time: 210.65548419952393 and batch: 700, loss is 4.233578820228576 and perplexity is 68.9635993834237
At time: 211.82232904434204 and batch: 750, loss is 4.199213056564331 and perplexity is 66.63387331380282
At time: 212.98321270942688 and batch: 800, loss is 4.1646757364273075 and perplexity is 64.37180562717647
At time: 214.14368772506714 and batch: 850, loss is 4.167380423545837 and perplexity is 64.54614688364775
At time: 215.30537462234497 and batch: 900, loss is 4.154695210456848 and perplexity is 63.732536576534976
At time: 216.50968980789185 and batch: 950, loss is 4.2405690622329715 and perplexity is 69.44736046627602
At time: 217.67130780220032 and batch: 1000, loss is 4.222421255111694 and perplexity is 68.19841029441523
At time: 218.83166575431824 and batch: 1050, loss is 4.1572525644302365 and perplexity is 63.89573181723954
At time: 219.9929072856903 and batch: 1100, loss is 4.219177346229554 and perplexity is 67.97753930188495
At time: 221.15429210662842 and batch: 1150, loss is 4.170734629631043 and perplexity is 64.76301146322457
At time: 222.31653213500977 and batch: 1200, loss is 4.231878819465638 and perplexity is 68.84646080790166
At time: 223.48035264015198 and batch: 1250, loss is 4.214886674880981 and perplexity is 67.68649485619521
At time: 224.64263725280762 and batch: 1300, loss is 4.214592528343201 and perplexity is 67.66658803598342
At time: 225.804025888443 and batch: 1350, loss is 4.0852210283279415 and perplexity is 59.45507755543562
At time: 226.9663496017456 and batch: 1400, loss is 4.127041239738464 and perplexity is 61.994225259938226
At time: 228.1299135684967 and batch: 1450, loss is 4.064760355949402 and perplexity is 58.25094735678789
At time: 229.29211163520813 and batch: 1500, loss is 4.06422721862793 and perplexity is 58.21989987976064
At time: 230.45656204223633 and batch: 1550, loss is 4.074781627655029 and perplexity is 58.83763067398268
At time: 231.61901473999023 and batch: 1600, loss is 4.168139133453369 and perplexity is 64.59513726717601
At time: 232.7807264328003 and batch: 1650, loss is 4.121819925308228 and perplexity is 61.67137749530266
At time: 233.94623398780823 and batch: 1700, loss is 4.139551596641541 and perplexity is 62.774666765942136
At time: 235.11543035507202 and batch: 1750, loss is 4.153554735183715 and perplexity is 63.65989262666363
At time: 236.28201031684875 and batch: 1800, loss is 4.095544075965881 and perplexity is 60.07201400688764
At time: 237.45619678497314 and batch: 1850, loss is 4.1283740234375 and perplexity is 62.07690523782363
At time: 238.61856412887573 and batch: 1900, loss is 4.2172619819641115 and perplexity is 67.84746216457069
At time: 239.7814280986786 and batch: 1950, loss is 4.145326952934266 and perplexity is 63.138261767378125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4659063294876455 and perplexity of 86.99984434261563
finished 5 epochs...
Completing Train Step...
At time: 243.59341144561768 and batch: 50, loss is 4.117550315856934 and perplexity is 61.4086261211032
At time: 244.75720047950745 and batch: 100, loss is 4.077094697952271 and perplexity is 58.973883770600594
At time: 245.96789860725403 and batch: 150, loss is 4.0364535570144655 and perplexity is 56.6251683583383
At time: 247.1393527984619 and batch: 200, loss is 4.037867178916931 and perplexity is 56.705271541027855
At time: 248.30552625656128 and batch: 250, loss is 4.033832612037659 and perplexity is 56.47695122708781
At time: 249.47046899795532 and batch: 300, loss is 4.061637444496155 and perplexity is 58.06931855906356
At time: 250.6380226612091 and batch: 350, loss is 4.065465502738952 and perplexity is 58.29203731082678
At time: 251.80489897727966 and batch: 400, loss is 4.034807782173157 and perplexity is 56.53205272556972
At time: 252.9695496559143 and batch: 450, loss is 4.06348030090332 and perplexity is 58.176430640608956
At time: 254.13463950157166 and batch: 500, loss is 4.084103627204895 and perplexity is 59.388679488550245
At time: 255.3014132976532 and batch: 550, loss is 4.047208142280579 and perplexity is 57.23743499525734
At time: 256.4677414894104 and batch: 600, loss is 4.033328223228454 and perplexity is 56.448472067799266
At time: 257.63562297821045 and batch: 650, loss is 4.06497522354126 and perplexity is 58.26346494233344
At time: 258.80290722846985 and batch: 700, loss is 4.101468925476074 and perplexity is 60.42898811432252
At time: 259.9684820175171 and batch: 750, loss is 4.068899598121643 and perplexity is 58.492561840117965
At time: 261.1437978744507 and batch: 800, loss is 4.031873860359192 and perplexity is 56.366435176161986
At time: 262.3136327266693 and batch: 850, loss is 4.039618396759034 and perplexity is 56.80466182591132
At time: 263.4842622280121 and batch: 900, loss is 4.026950244903564 and perplexity is 56.0895906220843
At time: 264.6495010852814 and batch: 950, loss is 4.111059598922729 and perplexity is 61.01133087195025
At time: 265.8143994808197 and batch: 1000, loss is 4.092435340881348 and perplexity is 59.88555600377836
At time: 266.97900128364563 and batch: 1050, loss is 4.035282664299011 and perplexity is 56.55890516231341
At time: 268.1444365978241 and batch: 1100, loss is 4.0872774505615235 and perplexity is 59.57746809900628
At time: 269.31099152565 and batch: 1150, loss is 4.044680404663086 and perplexity is 57.092936481794005
At time: 270.4761712551117 and batch: 1200, loss is 4.106316123008728 and perplexity is 60.72261040413473
At time: 271.64096450805664 and batch: 1250, loss is 4.091778683662414 and perplexity is 59.846244629580035
At time: 272.8054370880127 and batch: 1300, loss is 4.0914317321777345 and perplexity is 59.82548448774255
At time: 273.970192193985 and batch: 1350, loss is 3.9643842220306396 and perplexity is 52.68781540246908
At time: 275.1351668834686 and batch: 1400, loss is 4.009577941894531 and perplexity is 55.12360029080031
At time: 276.3023872375488 and batch: 1450, loss is 3.9395203161239625 and perplexity is 51.39394254123209
At time: 277.46754264831543 and batch: 1500, loss is 3.9433357429504396 and perplexity is 51.59040692773218
At time: 278.6337580680847 and batch: 1550, loss is 3.95349730014801 and perplexity is 52.117318385085944
At time: 279.79997992515564 and batch: 1600, loss is 4.0485969829559325 and perplexity is 57.31698390072278
At time: 280.9672050476074 and batch: 1650, loss is 4.007243261337281 and perplexity is 54.99505440813131
At time: 282.1331424713135 and batch: 1700, loss is 4.019034852981568 and perplexity is 55.64737200527344
At time: 283.2998559474945 and batch: 1750, loss is 4.033883457183838 and perplexity is 56.479822878932836
At time: 284.46402168273926 and batch: 1800, loss is 3.9744724369049074 and perplexity is 53.222031518305144
At time: 285.6288480758667 and batch: 1850, loss is 4.014808592796325 and perplexity is 55.412687999701475
At time: 286.80055117607117 and batch: 1900, loss is 4.0984925937652585 and perplexity is 60.249398792017885
At time: 287.97558856010437 and batch: 1950, loss is 4.023948845863342 and perplexity is 55.921495764685275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.460870787154796 and perplexity of 86.56285410827411
finished 6 epochs...
Completing Train Step...
At time: 291.62447357177734 and batch: 50, loss is 3.998537392616272 and perplexity is 54.518352746043874
At time: 292.8134117126465 and batch: 100, loss is 3.9560148668289186 and perplexity is 52.24869251152328
At time: 293.97858691215515 and batch: 150, loss is 3.9253740692138672 and perplexity is 50.67202936025628
At time: 295.14497232437134 and batch: 200, loss is 3.926057538986206 and perplexity is 50.70667399855998
At time: 296.3120741844177 and batch: 250, loss is 3.9190656089782716 and perplexity is 50.35337305009855
At time: 297.4752185344696 and batch: 300, loss is 3.942976016998291 and perplexity is 51.5718518570487
At time: 298.6393506526947 and batch: 350, loss is 3.955372052192688 and perplexity is 52.215117079798574
At time: 299.803466796875 and batch: 400, loss is 3.923127679824829 and perplexity is 50.55832800775019
At time: 300.9665274620056 and batch: 450, loss is 3.9522946453094483 and perplexity is 52.05467691554075
At time: 302.13163709640503 and batch: 500, loss is 3.9766453313827514 and perplexity is 53.337803110866986
At time: 303.29476022720337 and batch: 550, loss is 3.9356662225723267 and perplexity is 51.19624669255364
At time: 304.48300313949585 and batch: 600, loss is 3.9352742433547974 and perplexity is 51.17618276041377
At time: 305.6476209163666 and batch: 650, loss is 3.959019646644592 and perplexity is 52.40592443353006
At time: 306.811723947525 and batch: 700, loss is 3.9923806238174437 and perplexity is 54.18372701653958
At time: 307.97618770599365 and batch: 750, loss is 3.9643474864959716 and perplexity is 52.685879922950434
At time: 309.14243364334106 and batch: 800, loss is 3.9251263427734373 and perplexity is 50.65947811349554
At time: 310.3056004047394 and batch: 850, loss is 3.9319053745269774 and perplexity is 51.0040669940878
At time: 311.4699492454529 and batch: 900, loss is 3.9216285371780395 and perplexity is 50.48259064682179
At time: 312.636620759964 and batch: 950, loss is 4.008262457847596 and perplexity is 55.05113374874836
At time: 313.8109667301178 and batch: 1000, loss is 3.9884238815307618 and perplexity is 53.96975955879995
At time: 314.99056339263916 and batch: 1050, loss is 3.932690749168396 and perplexity is 51.04414002902708
At time: 316.1606078147888 and batch: 1100, loss is 3.979239091873169 and perplexity is 53.476328169972554
At time: 317.32606768608093 and batch: 1150, loss is 3.941430950164795 and perplexity is 51.49223142448657
At time: 318.4917302131653 and batch: 1200, loss is 4.002939848899842 and perplexity is 54.75889651386103
At time: 319.6575846672058 and batch: 1250, loss is 3.991764087677002 and perplexity is 54.150331086566794
At time: 320.8225119113922 and batch: 1300, loss is 3.992815556526184 and perplexity is 54.20729841731554
At time: 321.98818707466125 and batch: 1350, loss is 3.8624994945526123 and perplexity is 47.584139148898764
At time: 323.1520471572876 and batch: 1400, loss is 3.911436243057251 and perplexity is 49.970670487024016
At time: 324.3156394958496 and batch: 1450, loss is 3.8342362880706786 and perplexity is 46.258086322012744
At time: 325.4804344177246 and batch: 1500, loss is 3.8432421922683715 and perplexity is 46.676563771279554
At time: 326.64553022384644 and batch: 1550, loss is 3.8491317892074584 and perplexity is 46.95228105323249
At time: 327.8101177215576 and batch: 1600, loss is 3.9510699701309204 and perplexity is 51.99096586542981
At time: 328.9768395423889 and batch: 1650, loss is 3.904562244415283 and perplexity is 49.62835006894107
At time: 330.1431441307068 and batch: 1700, loss is 3.9201147508621217 and perplexity is 50.40622860439827
At time: 331.30944442749023 and batch: 1750, loss is 3.934468083381653 and perplexity is 51.13494319537077
At time: 332.47578263282776 and batch: 1800, loss is 3.879274024963379 and perplexity is 48.38907305769118
At time: 333.64228653907776 and batch: 1850, loss is 3.917748098373413 and perplexity is 50.28707563048146
At time: 334.8077096939087 and batch: 1900, loss is 3.9971639013290403 and perplexity is 54.44352366386277
At time: 335.97337102890015 and batch: 1950, loss is 3.927692189216614 and perplexity is 50.78962945800341
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.484486566587936 and perplexity of 88.6314327897702
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 339.5986385345459 and batch: 50, loss is 3.9400486278533937 and perplexity is 51.42110173752762
At time: 340.7892527580261 and batch: 100, loss is 3.9145993995666504 and perplexity is 50.12898579469937
At time: 341.9562191963196 and batch: 150, loss is 3.8843488836288453 and perplexity is 48.63526493051901
At time: 343.12311840057373 and batch: 200, loss is 3.889262571334839 and perplexity is 48.87483152959784
At time: 344.28922843933105 and batch: 250, loss is 3.8793279838562014 and perplexity is 48.391684148943234
At time: 345.45580983161926 and batch: 300, loss is 3.9023837184906007 and perplexity is 49.520351103702836
At time: 346.62239503860474 and batch: 350, loss is 3.915351905822754 and perplexity is 50.166722366844574
At time: 347.78845024108887 and batch: 400, loss is 3.877188215255737 and perplexity is 48.28824784701944
At time: 348.9552481174469 and batch: 450, loss is 3.9000675773620603 and perplexity is 49.40578770552567
At time: 350.1233832836151 and batch: 500, loss is 3.9097296524047853 and perplexity is 49.88546373507667
At time: 351.290953874588 and batch: 550, loss is 3.865491509437561 and perplexity is 47.72672480435078
At time: 352.45765709877014 and batch: 600, loss is 3.848793773651123 and perplexity is 46.93641313378395
At time: 353.625848531723 and batch: 650, loss is 3.8771956539154053 and perplexity is 48.288607048197136
At time: 354.7950613498688 and batch: 700, loss is 3.9076053428649904 and perplexity is 49.77960404774832
At time: 355.96270966529846 and batch: 750, loss is 3.862619185447693 and perplexity is 47.589834877961785
At time: 357.1286242008209 and batch: 800, loss is 3.813910012245178 and perplexity is 45.32732321980175
At time: 358.29565477371216 and batch: 850, loss is 3.816143579483032 and perplexity is 45.428677993138926
At time: 359.4617040157318 and batch: 900, loss is 3.791134991645813 and perplexity is 44.30665943703898
At time: 360.6307747364044 and batch: 950, loss is 3.882767243385315 and perplexity is 48.55840223883654
At time: 361.79550337791443 and batch: 1000, loss is 3.8506839513778686 and perplexity is 47.02521519586356
At time: 363.00097036361694 and batch: 1050, loss is 3.7858068132400513 and perplexity is 44.0712134571037
At time: 364.1662290096283 and batch: 1100, loss is 3.8203218460083006 and perplexity is 45.61888821546454
At time: 365.33310198783875 and batch: 1150, loss is 3.782385816574097 and perplexity is 43.92070357648974
At time: 366.49995136260986 and batch: 1200, loss is 3.827516837120056 and perplexity is 45.94829934470089
At time: 367.6660408973694 and batch: 1250, loss is 3.807494602203369 and perplexity is 45.03746064305913
At time: 368.83200788497925 and batch: 1300, loss is 3.812212438583374 and perplexity is 45.250442023953056
At time: 369.99711561203003 and batch: 1350, loss is 3.6834148502349855 and perplexity is 39.78201199634811
At time: 371.16248202323914 and batch: 1400, loss is 3.716951470375061 and perplexity is 41.138789932017744
At time: 372.3301270008087 and batch: 1450, loss is 3.635253977775574 and perplexity is 37.91148034795861
At time: 373.4964542388916 and batch: 1500, loss is 3.6242690896987915 and perplexity is 37.49730597386598
At time: 374.66329860687256 and batch: 1550, loss is 3.627925271987915 and perplexity is 37.634653891367435
At time: 375.82936668395996 and batch: 1600, loss is 3.716057562828064 and perplexity is 41.102032088727626
At time: 376.9950888156891 and batch: 1650, loss is 3.666446928977966 and perplexity is 39.112688522038084
At time: 378.1611752510071 and batch: 1700, loss is 3.6711180591583252 and perplexity is 39.29581635582495
At time: 379.3285183906555 and batch: 1750, loss is 3.664727053642273 and perplexity is 39.04547738768988
At time: 380.4951436519623 and batch: 1800, loss is 3.604969630241394 and perplexity is 36.78056682334641
At time: 381.6620903015137 and batch: 1850, loss is 3.630716209411621 and perplexity is 37.7398365661976
At time: 382.82914757728577 and batch: 1900, loss is 3.7037321758270263 and perplexity is 40.59854286045427
At time: 383.9959862232208 and batch: 1950, loss is 3.6249044227600096 and perplexity is 37.52113682151888
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411478867641715 and perplexity of 82.39121915973838
finished 8 epochs...
Completing Train Step...
At time: 387.60010623931885 and batch: 50, loss is 3.8292424058914185 and perplexity is 46.027654742054445
At time: 388.79034972190857 and batch: 100, loss is 3.795625982284546 and perplexity is 44.50608770986854
At time: 389.95559763908386 and batch: 150, loss is 3.76192419052124 and perplexity is 43.03114649242491
At time: 391.1422371864319 and batch: 200, loss is 3.7642658710479737 and perplexity is 43.13202976230434
At time: 392.30450558662415 and batch: 250, loss is 3.7575672245025635 and perplexity is 42.844069090297836
At time: 393.4680573940277 and batch: 300, loss is 3.7765349769592285 and perplexity is 43.66448087398501
At time: 394.6326992511749 and batch: 350, loss is 3.792463150024414 and perplexity is 44.365544793881966
At time: 395.79568219184875 and batch: 400, loss is 3.7569817304611206 and perplexity is 42.81899148524485
At time: 396.9594235420227 and batch: 450, loss is 3.7875328063964844 and perplexity is 44.147345752936985
At time: 398.12223863601685 and batch: 500, loss is 3.7978291606903074 and perplexity is 44.604250656771406
At time: 399.2866280078888 and batch: 550, loss is 3.75762460231781 and perplexity is 42.84652745990577
At time: 400.4488320350647 and batch: 600, loss is 3.745898880958557 and perplexity is 42.34705507748826
At time: 401.61328625679016 and batch: 650, loss is 3.7735704803466796 and perplexity is 43.5352293458618
At time: 402.7779266834259 and batch: 700, loss is 3.8108088397979736 and perplexity is 45.186973111353666
At time: 403.94024562835693 and batch: 750, loss is 3.7684883213043214 and perplexity is 43.314537656521004
At time: 405.10323905944824 and batch: 800, loss is 3.7214290046691896 and perplexity is 41.32340327260706
At time: 406.2693901062012 and batch: 850, loss is 3.7233390188217164 and perplexity is 41.402406982772426
At time: 407.43387746810913 and batch: 900, loss is 3.70121084690094 and perplexity is 40.4963095160864
At time: 408.5986285209656 and batch: 950, loss is 3.7935367250442504 and perplexity is 44.41320011071583
At time: 409.7635703086853 and batch: 1000, loss is 3.764131464958191 and perplexity is 43.12623294441213
At time: 410.92673778533936 and batch: 1050, loss is 3.7049050331115723 and perplexity is 40.646187091670335
At time: 412.090261220932 and batch: 1100, loss is 3.7401429176330567 and perplexity is 42.1040071400634
At time: 413.25250124931335 and batch: 1150, loss is 3.7073384284973145 and perplexity is 40.74521577489182
At time: 414.4157872200012 and batch: 1200, loss is 3.756007204055786 and perplexity is 42.77728357342421
At time: 415.57890796661377 and batch: 1250, loss is 3.7399826288223266 and perplexity is 42.09725887968171
At time: 416.74261236190796 and batch: 1300, loss is 3.745175004005432 and perplexity is 42.316412112491086
At time: 417.9071352481842 and batch: 1350, loss is 3.6184146928787233 and perplexity is 37.27842320347356
At time: 419.0711987018585 and batch: 1400, loss is 3.658455557823181 and perplexity is 38.80137009851515
At time: 420.23538994789124 and batch: 1450, loss is 3.579404592514038 and perplexity is 35.852187829798446
At time: 421.3988890647888 and batch: 1500, loss is 3.571218705177307 and perplexity is 35.55990379367396
At time: 422.5625584125519 and batch: 1550, loss is 3.577916874885559 and perplexity is 35.79888955416707
At time: 423.72612023353577 and batch: 1600, loss is 3.6696493864059447 and perplexity is 39.23814602085164
At time: 424.89010429382324 and batch: 1650, loss is 3.6236909866333007 and perplexity is 37.475634930986544
At time: 426.0548565387726 and batch: 1700, loss is 3.63500271320343 and perplexity is 37.90195573271894
At time: 427.2185242176056 and batch: 1750, loss is 3.6303051710128784 and perplexity is 37.72432723189095
At time: 428.38271927833557 and batch: 1800, loss is 3.575063400268555 and perplexity is 35.696883935942004
At time: 429.54729986190796 and batch: 1850, loss is 3.6057182931900025 and perplexity is 36.80811338121285
At time: 430.7117774486542 and batch: 1900, loss is 3.682435941696167 and perplexity is 39.74308809968919
At time: 431.8764898777008 and batch: 1950, loss is 3.608904013633728 and perplexity is 36.9255607183686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.41800906159157 and perplexity of 82.93101035299759
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 435.5201816558838 and batch: 50, loss is 3.790960741043091 and perplexity is 44.298939647536
At time: 436.6866567134857 and batch: 100, loss is 3.7900263929367064 and perplexity is 44.25756834776906
At time: 437.8539209365845 and batch: 150, loss is 3.7693318700790406 and perplexity is 43.35109099678385
At time: 439.0195698738098 and batch: 200, loss is 3.7756161499023437 and perplexity is 43.624379193608945
At time: 440.18609833717346 and batch: 250, loss is 3.773146877288818 and perplexity is 43.516791595005714
At time: 441.3504042625427 and batch: 300, loss is 3.791479058265686 and perplexity is 44.321906502442054
At time: 442.51729130744934 and batch: 350, loss is 3.814466691017151 and perplexity is 45.35256300300252
At time: 443.6820225715637 and batch: 400, loss is 3.781367053985596 and perplexity is 43.8759815912361
At time: 444.8466589450836 and batch: 450, loss is 3.8102176284790037 and perplexity is 45.16026595694415
At time: 446.0120379924774 and batch: 500, loss is 3.814938678741455 and perplexity is 45.37397390845046
At time: 447.1786677837372 and batch: 550, loss is 3.777061185836792 and perplexity is 43.687463557770904
At time: 448.3444664478302 and batch: 600, loss is 3.751468982696533 and perplexity is 42.583590634569305
At time: 449.53263878822327 and batch: 650, loss is 3.7703893327713014 and perplexity is 43.396957404915376
At time: 450.69878005981445 and batch: 700, loss is 3.8101336193084716 and perplexity is 45.15647223981585
At time: 451.8649537563324 and batch: 750, loss is 3.7736161661148073 and perplexity is 43.537218331688905
At time: 453.03189992904663 and batch: 800, loss is 3.72963294506073 and perplexity is 41.66381244886896
At time: 454.19854736328125 and batch: 850, loss is 3.722186918258667 and perplexity is 41.35473471327334
At time: 455.36479663848877 and batch: 900, loss is 3.6928059959411623 and perplexity is 40.157370431689046
At time: 456.52910351753235 and batch: 950, loss is 3.781894202232361 and perplexity is 43.89911683532294
At time: 457.6951358318329 and batch: 1000, loss is 3.750180902481079 and perplexity is 42.52877486510297
At time: 458.86134004592896 and batch: 1050, loss is 3.688123106956482 and perplexity is 39.96975755203831
At time: 460.0263979434967 and batch: 1100, loss is 3.713411636352539 and perplexity is 40.993422883176166
At time: 461.1928548812866 and batch: 1150, loss is 3.6834879684448243 and perplexity is 39.7849208921944
At time: 462.35818886756897 and batch: 1200, loss is 3.7231286096572878 and perplexity is 41.3936964533336
At time: 463.52433371543884 and batch: 1250, loss is 3.7007126426696777 and perplexity is 40.476139108243444
At time: 464.690593957901 and batch: 1300, loss is 3.7023211336135864 and perplexity is 40.54129700033484
At time: 465.8569996356964 and batch: 1350, loss is 3.578432946205139 and perplexity is 35.817369102311034
At time: 467.030287027359 and batch: 1400, loss is 3.618843951225281 and perplexity is 37.29442871278361
At time: 468.1968688964844 and batch: 1450, loss is 3.5392418050765992 and perplexity is 34.44079645201701
At time: 469.3634331226349 and batch: 1500, loss is 3.5255254745483398 and perplexity is 33.97162014864159
At time: 470.5288553237915 and batch: 1550, loss is 3.532030644416809 and perplexity is 34.19333166209305
At time: 471.6951127052307 and batch: 1600, loss is 3.615919256210327 and perplexity is 37.185513232959366
At time: 472.86098980903625 and batch: 1650, loss is 3.569285259246826 and perplexity is 35.49121706483109
At time: 474.0276117324829 and batch: 1700, loss is 3.5724969720840454 and perplexity is 35.605387906124776
At time: 475.19379687309265 and batch: 1750, loss is 3.5643022727966307 and perplexity is 35.314804706320835
At time: 476.36109805107117 and batch: 1800, loss is 3.4996632385253905 and perplexity is 33.10430182783098
At time: 477.52775025367737 and batch: 1850, loss is 3.52728217124939 and perplexity is 34.03135043031987
At time: 478.69295024871826 and batch: 1900, loss is 3.614821057319641 and perplexity is 37.14469855899419
At time: 479.86045026779175 and batch: 1950, loss is 3.5449704551696777 and perplexity is 34.63866193375328
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382728754087936 and perplexity of 80.05618927660704
finished 10 epochs...
Completing Train Step...
At time: 483.501793384552 and batch: 50, loss is 3.780074801445007 and perplexity is 43.81931936139433
At time: 484.6669371128082 and batch: 100, loss is 3.7591190576553344 and perplexity is 42.910607552054124
At time: 485.833589553833 and batch: 150, loss is 3.7303034591674806 and perplexity is 41.691757990749956
At time: 486.9993860721588 and batch: 200, loss is 3.728711652755737 and perplexity is 41.62544557532957
At time: 488.16472005844116 and batch: 250, loss is 3.7245657730102537 and perplexity is 41.45322872547335
At time: 489.33057975769043 and batch: 300, loss is 3.7403037691116334 and perplexity is 42.110780176577755
At time: 490.49621653556824 and batch: 350, loss is 3.763748912811279 and perplexity is 43.10973806668763
At time: 491.661420583725 and batch: 400, loss is 3.731011371612549 and perplexity is 41.72128255425835
At time: 492.82703971862793 and batch: 450, loss is 3.7622788190841674 and perplexity is 43.046409272215506
At time: 493.9946074485779 and batch: 500, loss is 3.7666259002685547 and perplexity is 43.233942824486284
At time: 495.16113233566284 and batch: 550, loss is 3.7261060190200808 and perplexity is 41.5171260918117
At time: 496.327045917511 and batch: 600, loss is 3.7060354137420655 and perplexity is 40.69215873209305
At time: 497.49268913269043 and batch: 650, loss is 3.7251067781448364 and perplexity is 41.47566120255436
At time: 498.65816473960876 and batch: 700, loss is 3.769126739501953 and perplexity is 43.34219927448355
At time: 499.8218505382538 and batch: 750, loss is 3.7345676946640016 and perplexity is 41.86992105975602
At time: 500.9870774745941 and batch: 800, loss is 3.6913005256652833 and perplexity is 40.096960188469126
At time: 502.1532402038574 and batch: 850, loss is 3.6854067420959473 and perplexity is 39.861332434898095
At time: 503.31725025177 and batch: 900, loss is 3.6577756643295287 and perplexity is 38.774998265475105
At time: 504.483008146286 and batch: 950, loss is 3.7475893974304197 and perplexity is 42.41870401642389
At time: 505.6487259864807 and batch: 1000, loss is 3.7169220066070556 and perplexity is 41.13757784611156
At time: 506.84089517593384 and batch: 1050, loss is 3.6563661003112795 and perplexity is 38.72038092547417
At time: 508.005895614624 and batch: 1100, loss is 3.6828240823745726 and perplexity is 39.758517002964915
At time: 509.170535326004 and batch: 1150, loss is 3.6542163467407227 and perplexity is 38.63723105621315
At time: 510.33697843551636 and batch: 1200, loss is 3.697975115776062 and perplexity is 40.365486115759566
At time: 511.501211643219 and batch: 1250, loss is 3.6777799940109253 and perplexity is 39.55847646520167
At time: 512.6667768955231 and batch: 1300, loss is 3.6805853939056394 and perplexity is 39.6696096245016
At time: 513.8320474624634 and batch: 1350, loss is 3.5582883405685424 and perplexity is 35.103061207877126
At time: 514.9978513717651 and batch: 1400, loss is 3.601189594268799 and perplexity is 36.64179739960441
At time: 516.1625642776489 and batch: 1450, loss is 3.524539756774902 and perplexity is 33.93815021753165
At time: 517.3281242847443 and batch: 1500, loss is 3.5124017143249513 and perplexity is 33.528697513782134
At time: 518.4932489395142 and batch: 1550, loss is 3.5209703063964843 and perplexity is 33.81722561996158
At time: 519.6589796543121 and batch: 1600, loss is 3.6074066972732544 and perplexity is 36.87031284428015
At time: 520.824455499649 and batch: 1650, loss is 3.5630727195739746 and perplexity is 35.27140995793009
At time: 521.9903166294098 and batch: 1700, loss is 3.5708031463623047 and perplexity is 35.54512963217099
At time: 523.1552264690399 and batch: 1750, loss is 3.5643293762207033 and perplexity is 35.315761871419994
At time: 524.3197164535522 and batch: 1800, loss is 3.501267228126526 and perplexity is 33.15744339158002
At time: 525.482607126236 and batch: 1850, loss is 3.5305847549438476 and perplexity is 34.14392760880463
At time: 526.653932094574 and batch: 1900, loss is 3.6191946840286255 and perplexity is 37.30751138644248
At time: 527.837513923645 and batch: 1950, loss is 3.5497698974609375 and perplexity is 34.80530777641772
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383347338299418 and perplexity of 80.10572609109106
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 531.4650905132294 and batch: 50, loss is 3.7708176040649413 and perplexity is 43.41554705642613
At time: 532.6311311721802 and batch: 100, loss is 3.7663081312179565 and perplexity is 43.22020659811072
At time: 533.7954843044281 and batch: 150, loss is 3.7493790340423585 and perplexity is 42.49468605199943
At time: 534.9592809677124 and batch: 200, loss is 3.7549452781677246 and perplexity is 42.7318813797257
At time: 536.1636090278625 and batch: 250, loss is 3.757627592086792 and perplexity is 42.84665556131604
At time: 537.3280606269836 and batch: 300, loss is 3.7656800603866576 and perplexity is 43.193069769840946
At time: 538.4922552108765 and batch: 350, loss is 3.797056589126587 and perplexity is 44.56980398906423
At time: 539.6564619541168 and batch: 400, loss is 3.7749249792099 and perplexity is 43.59423771888616
At time: 540.820104598999 and batch: 450, loss is 3.806460390090942 and perplexity is 44.99090643336241
At time: 541.9839582443237 and batch: 500, loss is 3.8111393356323244 and perplexity is 45.20190968583576
At time: 543.1485667228699 and batch: 550, loss is 3.7653471088409423 and perplexity is 43.17869096435248
At time: 544.3131914138794 and batch: 600, loss is 3.7402145195007326 and perplexity is 42.10702197354384
At time: 545.4784173965454 and batch: 650, loss is 3.7438920593261718 and perplexity is 42.262157307124625
At time: 546.6444473266602 and batch: 700, loss is 3.7816528511047363 and perplexity is 43.88852301243998
At time: 547.8084924221039 and batch: 750, loss is 3.7434854888916016 and perplexity is 42.24497825594619
At time: 548.9734725952148 and batch: 800, loss is 3.70606342792511 and perplexity is 40.693298705643876
At time: 550.1389346122742 and batch: 850, loss is 3.7051325273513793 and perplexity is 40.65543491697742
At time: 551.3043360710144 and batch: 900, loss is 3.687861557006836 and perplexity is 39.95930483097714
At time: 552.4682462215424 and batch: 950, loss is 3.79391387462616 and perplexity is 44.4299536896729
At time: 553.6330895423889 and batch: 1000, loss is 3.767437210083008 and perplexity is 43.26903317926714
At time: 554.797443151474 and batch: 1050, loss is 3.701144242286682 and perplexity is 40.49361236483456
At time: 555.9619443416595 and batch: 1100, loss is 3.7164679861068723 and perplexity is 41.118904781739325
At time: 557.1256067752838 and batch: 1150, loss is 3.679906044006348 and perplexity is 39.64266923121111
At time: 558.2893357276917 and batch: 1200, loss is 3.7164410400390624 and perplexity is 41.11779680387069
At time: 559.4528028964996 and batch: 1250, loss is 3.6952478885650635 and perplexity is 40.25555024183269
At time: 560.6175367832184 and batch: 1300, loss is 3.6900864124298094 and perplexity is 40.04830747932755
At time: 561.782292842865 and batch: 1350, loss is 3.5544735479354856 and perplexity is 34.96940540525624
At time: 562.9476265907288 and batch: 1400, loss is 3.5962541913986206 and perplexity is 36.46140089843245
At time: 564.1105012893677 and batch: 1450, loss is 3.5122857332229613 and perplexity is 33.524809043995056
At time: 565.2733829021454 and batch: 1500, loss is 3.4974760007858277 and perplexity is 33.031973977467985
At time: 566.43896484375 and batch: 1550, loss is 3.5082836246490476 and perplexity is 33.39090724178059
At time: 567.6043500900269 and batch: 1600, loss is 3.589046015739441 and perplexity is 36.1995256711669
At time: 568.768434047699 and batch: 1650, loss is 3.547811679840088 and perplexity is 34.737218098392646
At time: 569.9342029094696 and batch: 1700, loss is 3.557895302772522 and perplexity is 35.089267089049024
At time: 571.0988216400146 and batch: 1750, loss is 3.557117681503296 and perplexity is 35.061991535038935
At time: 572.2640991210938 and batch: 1800, loss is 3.4917336988449095 and perplexity is 32.84283796693944
At time: 573.4284203052521 and batch: 1850, loss is 3.510254168510437 and perplexity is 33.45677036084213
At time: 574.5935189723969 and batch: 1900, loss is 3.6048904037475586 and perplexity is 36.777652943425494
At time: 575.7578227519989 and batch: 1950, loss is 3.549643793106079 and perplexity is 34.80091895226566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365767226108285 and perplexity of 78.70976496866443
finished 12 epochs...
Completing Train Step...
At time: 579.3685240745544 and batch: 50, loss is 3.7865059328079225 and perplexity is 44.10203527762492
At time: 580.5572330951691 and batch: 100, loss is 3.7667025756835937 and perplexity is 43.23725793208813
At time: 581.724582195282 and batch: 150, loss is 3.7414063692092894 and perplexity is 42.15723713392909
At time: 582.8920962810516 and batch: 200, loss is 3.7398643779754637 and perplexity is 42.0922811374855
At time: 584.0589792728424 and batch: 250, loss is 3.738732213973999 and perplexity is 42.04465273870887
At time: 585.2245862483978 and batch: 300, loss is 3.7411272859573366 and perplexity is 42.14547339670378
At time: 586.397881269455 and batch: 350, loss is 3.7719873428344726 and perplexity is 43.466361619106365
At time: 587.5669796466827 and batch: 400, loss is 3.7462040615081786 and perplexity is 42.35998054723232
At time: 588.7331535816193 and batch: 450, loss is 3.7788381004333496 and perplexity is 43.76516146027805
At time: 589.9013786315918 and batch: 500, loss is 3.784026918411255 and perplexity is 43.99284110013953
At time: 591.0681681632996 and batch: 550, loss is 3.7400139236450194 and perplexity is 42.09857632654873
At time: 592.23428606987 and batch: 600, loss is 3.7144541692733766 and perplexity is 41.03618216117436
At time: 593.4004607200623 and batch: 650, loss is 3.7182643365859986 and perplexity is 41.192835128571794
At time: 594.6081955432892 and batch: 700, loss is 3.758624243736267 and perplexity is 42.889380038429444
At time: 595.7766795158386 and batch: 750, loss is 3.723253273963928 and perplexity is 41.39885709146824
At time: 596.9450843334198 and batch: 800, loss is 3.6860697793960573 and perplexity is 39.88777074896014
At time: 598.112753868103 and batch: 850, loss is 3.6863841342926027 and perplexity is 39.90031163604872
At time: 599.2813572883606 and batch: 900, loss is 3.66912974357605 and perplexity is 39.21776149640822
At time: 600.448490858078 and batch: 950, loss is 3.7744074392318727 and perplexity is 43.57168179535457
At time: 601.6164085865021 and batch: 1000, loss is 3.7484085178375244 and perplexity is 42.45346427700251
At time: 602.783625125885 and batch: 1050, loss is 3.683447790145874 and perplexity is 39.78332243386097
At time: 603.9502258300781 and batch: 1100, loss is 3.7002105474472047 and perplexity is 40.45582133332874
At time: 605.1193222999573 and batch: 1150, loss is 3.664584517478943 and perplexity is 39.03991239176366
At time: 606.2859988212585 and batch: 1200, loss is 3.702776799201965 and perplexity is 40.559774483743105
At time: 607.4520647525787 and batch: 1250, loss is 3.6833138847351075 and perplexity is 39.777995588383476
At time: 608.6208233833313 and batch: 1300, loss is 3.6800179958343504 and perplexity is 39.647107548932695
At time: 609.7968547344208 and batch: 1350, loss is 3.5459394454956055 and perplexity is 34.672242729175586
At time: 610.9637188911438 and batch: 1400, loss is 3.5892859220504763 and perplexity is 36.20821120764774
At time: 612.1431541442871 and batch: 1450, loss is 3.5071973180770875 and perplexity is 33.35465417433791
At time: 613.3116106987 and batch: 1500, loss is 3.494870262145996 and perplexity is 32.94601333065294
At time: 614.4785270690918 and batch: 1550, loss is 3.507466335296631 and perplexity is 33.36362835771353
At time: 615.646909236908 and batch: 1600, loss is 3.590020761489868 and perplexity is 36.23482820768591
At time: 616.8131129741669 and batch: 1650, loss is 3.550438070297241 and perplexity is 34.828571508864634
At time: 617.980220079422 and batch: 1700, loss is 3.5619473552703855 and perplexity is 35.23173909849747
At time: 619.1466300487518 and batch: 1750, loss is 3.5625208950042726 and perplexity is 35.251951696574395
At time: 620.3146193027496 and batch: 1800, loss is 3.498003587722778 and perplexity is 33.04940581344032
At time: 621.4807381629944 and batch: 1850, loss is 3.516887583732605 and perplexity is 33.67944072663713
At time: 622.6484763622284 and batch: 1900, loss is 3.612393617630005 and perplexity is 37.054641391844996
At time: 623.8157801628113 and batch: 1950, loss is 3.556330862045288 and perplexity is 35.03441492819078
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36451785065407 and perplexity of 78.61148832530219
finished 13 epochs...
Completing Train Step...
At time: 627.4209568500519 and batch: 50, loss is 3.781368498802185 and perplexity is 43.876044984027956
At time: 628.6067984104156 and batch: 100, loss is 3.7594022512435914 and perplexity is 42.922761281829025
At time: 629.7718884944916 and batch: 150, loss is 3.73369966506958 and perplexity is 41.83359249857422
At time: 630.9368968009949 and batch: 200, loss is 3.730247111320496 and perplexity is 41.68940881613625
At time: 632.1019999980927 and batch: 250, loss is 3.72861216545105 and perplexity is 41.62130457793462
At time: 633.2670998573303 and batch: 300, loss is 3.730257611274719 and perplexity is 41.68984655531854
At time: 634.4333262443542 and batch: 350, loss is 3.7612405252456664 and perplexity is 43.00173764584898
At time: 635.5985305309296 and batch: 400, loss is 3.735041732788086 and perplexity is 41.889773703674024
At time: 636.7627246379852 and batch: 450, loss is 3.7678369283676147 and perplexity is 43.286332060095305
At time: 637.9292528629303 and batch: 500, loss is 3.7729513263702392 and perplexity is 43.50828267842605
At time: 639.094621181488 and batch: 550, loss is 3.7287651395797727 and perplexity is 41.627672047755404
At time: 640.2607531547546 and batch: 600, loss is 3.7038133335113526 and perplexity is 40.60183787788603
At time: 641.4274022579193 and batch: 650, loss is 3.7076481485366823 and perplexity is 40.75783733920047
At time: 642.5934846401215 and batch: 700, loss is 3.7485809755325317 and perplexity is 42.46078633495127
At time: 643.7596299648285 and batch: 750, loss is 3.7136942243576048 and perplexity is 41.00500876970872
At time: 644.9234189987183 and batch: 800, loss is 3.676475076675415 and perplexity is 39.50688958912051
At time: 646.0918569564819 and batch: 850, loss is 3.677017636299133 and perplexity is 39.528330248162256
At time: 647.2590427398682 and batch: 900, loss is 3.660069818496704 and perplexity is 38.86405620659104
At time: 648.4260108470917 and batch: 950, loss is 3.765282220840454 and perplexity is 43.17588927633105
At time: 649.5934407711029 and batch: 1000, loss is 3.7394390058517457 and perplexity is 42.07438006204507
At time: 650.7606563568115 and batch: 1050, loss is 3.67524685382843 and perplexity is 39.458396111208764
At time: 651.9271187782288 and batch: 1100, loss is 3.692687921524048 and perplexity is 40.15262915349982
At time: 653.1334874629974 and batch: 1150, loss is 3.6575019645690916 and perplexity is 38.764387009954184
At time: 654.3003284931183 and batch: 1200, loss is 3.6967093181610107 and perplexity is 40.31442390373479
At time: 655.4660160541534 and batch: 1250, loss is 3.677603392601013 and perplexity is 39.551490999323654
At time: 656.6313724517822 and batch: 1300, loss is 3.674982852935791 and perplexity is 39.44798043434778
At time: 657.7974119186401 and batch: 1350, loss is 3.5415502691268923 and perplexity is 34.520393630754945
At time: 658.9621267318726 and batch: 1400, loss is 3.58547589302063 and perplexity is 36.070519343392704
At time: 660.1276047229767 and batch: 1450, loss is 3.5041655588150022 and perplexity is 33.253684028538025
At time: 661.2937331199646 and batch: 1500, loss is 3.492451062202454 and perplexity is 32.86640666810526
At time: 662.4597864151001 and batch: 1550, loss is 3.5058963394165037 and perplexity is 33.31128869592346
At time: 663.6258957386017 and batch: 1600, loss is 3.588949246406555 and perplexity is 36.19602283670313
At time: 664.7917604446411 and batch: 1650, loss is 3.5501751375198363 and perplexity is 34.81941513963231
At time: 665.9630270004272 and batch: 1700, loss is 3.562581295967102 and perplexity is 35.25408101270421
At time: 667.1284365653992 and batch: 1750, loss is 3.5636856317520142 and perplexity is 35.2930348610362
At time: 668.2946333885193 and batch: 1800, loss is 3.499526400566101 and perplexity is 33.09977221264387
At time: 669.4615242481232 and batch: 1850, loss is 3.5185980129241945 and perplexity is 33.73709631906027
At time: 670.626225233078 and batch: 1900, loss is 3.6143614053726196 and perplexity is 37.1276288493432
At time: 671.7905166149139 and batch: 1950, loss is 3.5578189659118653 and perplexity is 35.086588586792224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3645116051962205 and perplexity of 78.6109973620985
finished 14 epochs...
Completing Train Step...
At time: 675.3941287994385 and batch: 50, loss is 3.775386347770691 and perplexity is 43.61435537007035
At time: 676.5870959758759 and batch: 100, loss is 3.7525515174865722 and perplexity is 42.62971381338462
At time: 677.7548961639404 and batch: 150, loss is 3.726811103820801 and perplexity is 41.54640950882157
At time: 678.9223725795746 and batch: 200, loss is 3.722341465950012 and perplexity is 41.36112648595359
At time: 680.0876214504242 and batch: 250, loss is 3.720675253868103 and perplexity is 41.29226746008265
At time: 681.2766392230988 and batch: 300, loss is 3.7219377374649047 and perplexity is 41.34443119142484
At time: 682.4428811073303 and batch: 350, loss is 3.752873921394348 and perplexity is 42.64346001550099
At time: 683.6082184314728 and batch: 400, loss is 3.7266293478012087 and perplexity is 41.53885888500734
At time: 684.7734220027924 and batch: 450, loss is 3.759601187705994 and perplexity is 42.93130103352081
At time: 685.9412050247192 and batch: 500, loss is 3.764643154144287 and perplexity is 43.14830581819066
At time: 687.1079483032227 and batch: 550, loss is 3.7203594732284544 and perplexity is 41.2792302200139
At time: 688.274266242981 and batch: 600, loss is 3.6958878946304323 and perplexity is 40.281322284404304
At time: 689.4412648677826 and batch: 650, loss is 3.699832601547241 and perplexity is 40.440534110579705
At time: 690.6083948612213 and batch: 700, loss is 3.7411201572418213 and perplexity is 42.14517295468457
At time: 691.7764608860016 and batch: 750, loss is 3.7064166975021364 and perplexity is 40.70767694961398
At time: 692.9442510604858 and batch: 800, loss is 3.6692166042327883 and perplexity is 39.22116812487646
At time: 694.1122241020203 and batch: 850, loss is 3.6699479675292968 and perplexity is 39.24986353979673
At time: 695.2787222862244 and batch: 900, loss is 3.6533743715286255 and perplexity is 38.604713156953366
At time: 696.4482626914978 and batch: 950, loss is 3.758619899749756 and perplexity is 42.88919372794576
At time: 697.6152901649475 and batch: 1000, loss is 3.732955822944641 and perplexity is 41.802486480653734
At time: 698.7845511436462 and batch: 1050, loss is 3.669314088821411 and perplexity is 39.224991770686664
At time: 699.952730178833 and batch: 1100, loss is 3.687107353210449 and perplexity is 39.92917873360917
At time: 701.1213779449463 and batch: 1150, loss is 3.652185974121094 and perplexity is 38.55886266561783
At time: 702.2970316410065 and batch: 1200, loss is 3.692022647857666 and perplexity is 40.12592555027489
At time: 703.4709661006927 and batch: 1250, loss is 3.6730977630615236 and perplexity is 39.37368749230747
At time: 704.6388323307037 and batch: 1300, loss is 3.6708076763153077 and perplexity is 39.28362150126045
At time: 705.8126225471497 and batch: 1350, loss is 3.5378182697296143 and perplexity is 34.391803640662076
At time: 706.9942800998688 and batch: 1400, loss is 3.5820679759979246 and perplexity is 35.94780322844076
At time: 708.1748046875 and batch: 1450, loss is 3.501186237335205 and perplexity is 33.15475805274688
At time: 709.342365026474 and batch: 1500, loss is 3.4897115659713744 and perplexity is 32.77649248692172
At time: 710.5102663040161 and batch: 1550, loss is 3.5037651109695434 and perplexity is 33.24037032831442
At time: 711.6788032054901 and batch: 1600, loss is 3.587067370414734 and perplexity is 36.12797046347471
At time: 712.8474898338318 and batch: 1650, loss is 3.5488365030288698 and perplexity is 34.77283585284666
At time: 714.0143711566925 and batch: 1700, loss is 3.5619142961502077 and perplexity is 35.23057438745281
At time: 715.1816666126251 and batch: 1750, loss is 3.5633334493637085 and perplexity is 35.280607464211876
At time: 716.3491778373718 and batch: 1800, loss is 3.499452199935913 and perplexity is 33.09731627980362
At time: 717.516604423523 and batch: 1850, loss is 3.518710060119629 and perplexity is 33.74087667787027
At time: 718.6840705871582 and batch: 1900, loss is 3.6146264266967774 and perplexity is 37.13746976667256
At time: 719.8523874282837 and batch: 1950, loss is 3.557820825576782 and perplexity is 35.08665383615074
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364958155432412 and perplexity of 78.64610896050065
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 723.507566690445 and batch: 50, loss is 3.773799843788147 and perplexity is 43.54521588111889
At time: 724.6698100566864 and batch: 100, loss is 3.7582337951660154 and perplexity is 42.87263721013385
At time: 725.8390548229218 and batch: 150, loss is 3.7386694669723513 and perplexity is 42.042014645581276
At time: 727.0022592544556 and batch: 200, loss is 3.7376486253738403 and perplexity is 41.99911830705451
At time: 728.1660857200623 and batch: 250, loss is 3.7401784753799436 and perplexity is 42.1055042903097
At time: 729.3285708427429 and batch: 300, loss is 3.7344333267211915 and perplexity is 41.86429546255602
At time: 730.4923667907715 and batch: 350, loss is 3.767737545967102 and perplexity is 43.28203037426526
At time: 731.6558485031128 and batch: 400, loss is 3.7458832168579104 and perplexity is 42.34639175415062
At time: 732.8198544979095 and batch: 450, loss is 3.7832170152664184 and perplexity is 43.957225584288196
At time: 733.983635187149 and batch: 500, loss is 3.7938286590576173 and perplexity is 44.42616772722268
At time: 735.1470682621002 and batch: 550, loss is 3.7545976066589355 and perplexity is 42.71702730437203
At time: 736.3101377487183 and batch: 600, loss is 3.7334495973587036 and perplexity is 41.82313257575935
At time: 737.4747936725616 and batch: 650, loss is 3.7272706270217895 and perplexity is 41.565505435083196
At time: 738.6385354995728 and batch: 700, loss is 3.7641818428039553 and perplexity is 43.12840560585035
At time: 739.8257853984833 and batch: 750, loss is 3.7207312774658203 and perplexity is 41.29458086626573
At time: 740.9892866611481 and batch: 800, loss is 3.676916465759277 and perplexity is 39.524331347940304
At time: 742.1531548500061 and batch: 850, loss is 3.672377471923828 and perplexity is 39.34533718561142
At time: 743.3170113563538 and batch: 900, loss is 3.6525091981887816 and perplexity is 38.57132783246647
At time: 744.4798073768616 and batch: 950, loss is 3.7628433465957642 and perplexity is 43.070717015074365
At time: 745.6427719593048 and batch: 1000, loss is 3.7423926973342896 and perplexity is 42.1988385155203
At time: 746.8069291114807 and batch: 1050, loss is 3.682729415893555 and perplexity is 39.75475338221694
At time: 747.9704644680023 and batch: 1100, loss is 3.7033796739578246 and perplexity is 40.58423432025084
At time: 749.134432554245 and batch: 1150, loss is 3.6686389446258545 and perplexity is 39.198518182922086
At time: 750.2982804775238 and batch: 1200, loss is 3.707971839904785 and perplexity is 40.77103243478376
At time: 751.4619624614716 and batch: 1250, loss is 3.6881210470199584 and perplexity is 39.96967521695969
At time: 752.6258208751678 and batch: 1300, loss is 3.6857622051239014 and perplexity is 39.875504183440796
At time: 753.7898247241974 and batch: 1350, loss is 3.5525967931747435 and perplexity is 34.90383795344046
At time: 754.9555358886719 and batch: 1400, loss is 3.5955536651611326 and perplexity is 36.435867674838235
At time: 756.1194605827332 and batch: 1450, loss is 3.508507266044617 and perplexity is 33.398375665968736
At time: 757.2823724746704 and batch: 1500, loss is 3.4911392736434936 and perplexity is 32.823321157582214
At time: 758.4456758499146 and batch: 1550, loss is 3.504243893623352 and perplexity is 33.256289051533976
At time: 759.610447883606 and batch: 1600, loss is 3.58403311252594 and perplexity is 36.01851502607912
At time: 760.7743942737579 and batch: 1650, loss is 3.5364049291610717 and perplexity is 34.34323064253128
At time: 761.9387514591217 and batch: 1700, loss is 3.544781527519226 and perplexity is 34.632118350890686
At time: 763.1012077331543 and batch: 1750, loss is 3.5481764841079713 and perplexity is 34.749892695542336
At time: 764.263710975647 and batch: 1800, loss is 3.4871239137649535 and perplexity is 32.69178796400673
At time: 765.4279310703278 and batch: 1850, loss is 3.506265320777893 and perplexity is 33.32358220847514
At time: 766.592648267746 and batch: 1900, loss is 3.6017217683792113 and perplexity is 36.6613024051086
At time: 767.7581272125244 and batch: 1950, loss is 3.5521482467651366 and perplexity is 34.88818547293934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362153377089389 and perplexity of 78.42583311419196
finished 16 epochs...
Completing Train Step...
At time: 771.4012706279755 and batch: 50, loss is 3.7776813745498656 and perplexity is 43.71456643315223
At time: 772.5683767795563 and batch: 100, loss is 3.7583932876586914 and perplexity is 42.87947561923305
At time: 773.7356421947479 and batch: 150, loss is 3.7356538581848144 and perplexity is 41.91542334761959
At time: 774.9148061275482 and batch: 200, loss is 3.730991172790527 and perplexity is 41.72043984200845
At time: 776.0907032489777 and batch: 250, loss is 3.732780685424805 and perplexity is 41.79516593791809
At time: 777.2562756538391 and batch: 300, loss is 3.726519966125488 and perplexity is 41.53431554349867
At time: 778.4227876663208 and batch: 350, loss is 3.758946084976196 and perplexity is 42.90318583119837
At time: 779.5889000892639 and batch: 400, loss is 3.7361471462249756 and perplexity is 41.936104825198655
At time: 780.7546303272247 and batch: 450, loss is 3.7738959884643553 and perplexity is 43.54940272306827
At time: 781.9203217029572 and batch: 500, loss is 3.7848503494262697 and perplexity is 44.02908108845751
At time: 783.0881478786469 and batch: 550, loss is 3.746406636238098 and perplexity is 42.368562478062884
At time: 784.253675699234 and batch: 600, loss is 3.725956473350525 and perplexity is 41.51091784961171
At time: 785.4225022792816 and batch: 650, loss is 3.720482392311096 and perplexity is 41.284304536983505
At time: 786.5895664691925 and batch: 700, loss is 3.757513222694397 and perplexity is 42.841755495567455
At time: 787.7561943531036 and batch: 750, loss is 3.7137714290618895 and perplexity is 41.008174671494665
At time: 788.9224631786346 and batch: 800, loss is 3.6696359014511106 and perplexity is 39.23761689979237
At time: 790.0898523330688 and batch: 850, loss is 3.665509729385376 and perplexity is 39.0760492981048
At time: 791.2562155723572 and batch: 900, loss is 3.646568064689636 and perplexity is 38.34284980585331
At time: 792.4223823547363 and batch: 950, loss is 3.7561145877838134 and perplexity is 42.781877404256136
At time: 793.5888104438782 and batch: 1000, loss is 3.735298824310303 and perplexity is 41.90054459385377
At time: 794.7552289962769 and batch: 1050, loss is 3.6758330726623534 and perplexity is 39.48153414747926
At time: 795.9216117858887 and batch: 1100, loss is 3.696592535972595 and perplexity is 40.309716171981556
At time: 797.1105542182922 and batch: 1150, loss is 3.6628248357772826 and perplexity is 38.97127498000341
At time: 798.2770175933838 and batch: 1200, loss is 3.7018561506271364 and perplexity is 40.522450369002094
At time: 799.442622423172 and batch: 1250, loss is 3.68278724193573 and perplexity is 39.75705230873095
At time: 800.608781337738 and batch: 1300, loss is 3.680484204292297 and perplexity is 39.665595675130675
At time: 801.7737331390381 and batch: 1350, loss is 3.5480283975601195 and perplexity is 34.744747084902095
At time: 802.9402365684509 and batch: 1400, loss is 3.591858158111572 and perplexity is 36.30146716096865
At time: 804.105635881424 and batch: 1450, loss is 3.5065200662612916 and perplexity is 33.33207232189651
At time: 805.270806312561 and batch: 1500, loss is 3.4906388235092165 and perplexity is 32.80689883172182
At time: 806.436928987503 and batch: 1550, loss is 3.504727644920349 and perplexity is 33.272380716364026
At time: 807.6032600402832 and batch: 1600, loss is 3.5847090816497804 and perplexity is 36.04287066102454
At time: 808.7696361541748 and batch: 1650, loss is 3.538251352310181 and perplexity is 34.40670135747108
At time: 809.9391176700592 and batch: 1700, loss is 3.5474034690856935 and perplexity is 34.72304088622924
At time: 811.1062135696411 and batch: 1750, loss is 3.5519953870773318 and perplexity is 34.882852883379236
At time: 812.272824048996 and batch: 1800, loss is 3.4914304065704345 and perplexity is 32.83287849830352
At time: 813.4386534690857 and batch: 1850, loss is 3.5106812477111817 and perplexity is 33.47106210322307
At time: 814.6053578853607 and batch: 1900, loss is 3.6064426851272584 and perplexity is 36.83478654151655
At time: 815.7716171741486 and batch: 1950, loss is 3.5566407871246337 and perplexity is 35.04527465478111
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361306549781977 and perplexity of 78.35944808939736
finished 17 epochs...
Completing Train Step...
At time: 819.4161462783813 and batch: 50, loss is 3.77739399433136 and perplexity is 43.702005536461854
At time: 820.5813603401184 and batch: 100, loss is 3.756457872390747 and perplexity is 42.796566285313865
At time: 821.7462501525879 and batch: 150, loss is 3.7328296184539793 and perplexity is 41.79721115203114
At time: 822.9108150005341 and batch: 200, loss is 3.727215633392334 and perplexity is 41.56321965993128
At time: 824.0766708850861 and batch: 250, loss is 3.728536787033081 and perplexity is 41.618167348082935
At time: 825.2409148216248 and batch: 300, loss is 3.7220159435272215 and perplexity is 41.34766470302551
At time: 826.4305121898651 and batch: 350, loss is 3.753993730545044 and perplexity is 42.69123929909035
At time: 827.5961892604828 and batch: 400, loss is 3.7308586835861206 and perplexity is 41.71491270027768
At time: 828.7616803646088 and batch: 450, loss is 3.7687277460098265 and perplexity is 43.32490946852798
At time: 829.9279115200043 and batch: 500, loss is 3.779774603843689 and perplexity is 43.806166881100935
At time: 831.093985080719 and batch: 550, loss is 3.7417033672332765 and perplexity is 42.16975960953783
At time: 832.2601239681244 and batch: 600, loss is 3.7217233276367185 and perplexity is 41.33556748930301
At time: 833.4257354736328 and batch: 650, loss is 3.7165803575515746 and perplexity is 41.12352563209517
At time: 834.591121673584 and batch: 700, loss is 3.7536968564987183 and perplexity is 42.678567259229915
At time: 835.7560577392578 and batch: 750, loss is 3.7101028680801393 and perplexity is 40.85800929579575
At time: 836.9209561347961 and batch: 800, loss is 3.666199450492859 and perplexity is 39.10301017077542
At time: 838.0873126983643 and batch: 850, loss is 3.662246012687683 and perplexity is 38.948724033347766
At time: 839.2520430088043 and batch: 900, loss is 3.6434681844711303 and perplexity is 38.22417559716589
At time: 840.4172673225403 and batch: 950, loss is 3.7527046728134157 and perplexity is 42.63624328113557
At time: 841.5823564529419 and batch: 1000, loss is 3.7317653465270997 and perplexity is 41.75275121650735
At time: 842.744565486908 and batch: 1050, loss is 3.6725817680358888 and perplexity is 39.35337610615831
At time: 843.9069766998291 and batch: 1100, loss is 3.693439202308655 and perplexity is 40.18280638660258
At time: 845.077005147934 and batch: 1150, loss is 3.6600022077560426 and perplexity is 38.86142866779172
At time: 846.2466187477112 and batch: 1200, loss is 3.6990643453598024 and perplexity is 40.409477351327176
At time: 847.4131488800049 and batch: 1250, loss is 3.6803613901138306 and perplexity is 39.66072447671668
At time: 848.5808453559875 and batch: 1300, loss is 3.6783396577835084 and perplexity is 39.58062210785674
At time: 849.7464945316315 and batch: 1350, loss is 3.546263380050659 and perplexity is 34.68347608603477
At time: 850.9126889705658 and batch: 1400, loss is 3.5904388570785524 and perplexity is 36.249980996952715
At time: 852.0778477191925 and batch: 1450, loss is 3.505650119781494 and perplexity is 33.303087812229776
At time: 853.2425329685211 and batch: 1500, loss is 3.4903985404968263 and perplexity is 32.79901683823584
At time: 854.4084882736206 and batch: 1550, loss is 3.505018105506897 and perplexity is 33.28204643526999
At time: 855.5751466751099 and batch: 1600, loss is 3.585275721549988 and perplexity is 36.063299777088616
At time: 856.7414469718933 and batch: 1650, loss is 3.539188852310181 and perplexity is 34.43897276485229
At time: 857.9070241451263 and batch: 1700, loss is 3.548664302825928 and perplexity is 34.76684847898423
At time: 859.0728976726532 and batch: 1750, loss is 3.5537807083129884 and perplexity is 34.945185606803165
At time: 860.2381684780121 and batch: 1800, loss is 3.493364577293396 and perplexity is 32.89644434442803
At time: 861.4055194854736 and batch: 1850, loss is 3.5125821161270143 and perplexity is 33.5347466968598
At time: 862.5706210136414 and batch: 1900, loss is 3.608280611038208 and perplexity is 36.90254840169
At time: 863.7359507083893 and batch: 1950, loss is 3.558128080368042 and perplexity is 35.09743603500748
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360915357013082 and perplexity of 78.3288004348914
finished 18 epochs...
Completing Train Step...
At time: 867.3527026176453 and batch: 50, loss is 3.775987253189087 and perplexity is 43.64057134840492
At time: 868.5389866828918 and batch: 100, loss is 3.7542110300064087 and perplexity is 42.70051709038805
At time: 869.7031388282776 and batch: 150, loss is 3.7302942943572996 and perplexity is 41.69137589545277
At time: 870.866247177124 and batch: 200, loss is 3.7242829751968385 and perplexity is 41.44150750047731
At time: 872.0304706096649 and batch: 250, loss is 3.7252796030044557 and perplexity is 41.48282984732148
At time: 873.1935698986053 and batch: 300, loss is 3.7186752700805665 and perplexity is 41.20976612278039
At time: 874.3573679924011 and batch: 350, loss is 3.750439529418945 and perplexity is 42.53977537437022
At time: 875.5203311443329 and batch: 400, loss is 3.7271658849716185 and perplexity is 41.56115200682501
At time: 876.6832971572876 and batch: 450, loss is 3.765169630050659 and perplexity is 43.171028342510645
At time: 877.8466317653656 and batch: 500, loss is 3.7762797355651854 and perplexity is 43.653337313226054
At time: 879.0102908611298 and batch: 550, loss is 3.7384241914749143 and perplexity is 42.031704034047706
At time: 880.1741805076599 and batch: 600, loss is 3.718774952888489 and perplexity is 41.21387423273189
At time: 881.3379769325256 and batch: 650, loss is 3.7138348817825317 and perplexity is 41.010776834302426
At time: 882.5026879310608 and batch: 700, loss is 3.7510644721984865 and perplexity is 42.566368608593095
At time: 883.6653122901917 and batch: 750, loss is 3.7075865268707275 and perplexity is 40.75532585074476
At time: 884.8493101596832 and batch: 800, loss is 3.663852572441101 and perplexity is 39.01134777675011
At time: 886.0126340389252 and batch: 850, loss is 3.6599434185028077 and perplexity is 38.85914410057536
At time: 887.1815762519836 and batch: 900, loss is 3.6411859607696533 and perplexity is 38.13703894813272
At time: 888.3434267044067 and batch: 950, loss is 3.750252513885498 and perplexity is 42.53182051944976
At time: 889.5098078250885 and batch: 1000, loss is 3.7292396640777588 and perplexity is 41.647430085401886
At time: 890.6729140281677 and batch: 1050, loss is 3.67025417804718 and perplexity is 39.26188410115533
At time: 891.8356313705444 and batch: 1100, loss is 3.6912465381622312 and perplexity is 40.09479551214183
At time: 892.998085975647 and batch: 1150, loss is 3.658014636039734 and perplexity is 38.78426550038319
At time: 894.1611883640289 and batch: 1200, loss is 3.6971991539001463 and perplexity is 40.334176186657615
At time: 895.3236479759216 and batch: 1250, loss is 3.678713421821594 and perplexity is 39.59541868604788
At time: 896.4854702949524 and batch: 1300, loss is 3.676946210861206 and perplexity is 39.52550702069008
At time: 897.64794921875 and batch: 1350, loss is 3.5451044034957886 and perplexity is 34.643302035298014
At time: 898.8106677532196 and batch: 1400, loss is 3.589462022781372 and perplexity is 36.21458806157368
At time: 899.9743208885193 and batch: 1450, loss is 3.5049118757247926 and perplexity is 33.27851107851259
At time: 901.1368699073792 and batch: 1500, loss is 3.489992547035217 and perplexity is 32.78570335462883
At time: 902.3004879951477 and batch: 1550, loss is 3.5049172258377075 and perplexity is 33.278689122780776
At time: 903.4630746841431 and batch: 1600, loss is 3.5853920793533325 and perplexity is 36.06749626757451
At time: 904.6261575222015 and batch: 1650, loss is 3.5394813871383666 and perplexity is 34.44904883756219
At time: 905.7890043258667 and batch: 1700, loss is 3.549152035713196 and perplexity is 34.783809550274
At time: 906.9529376029968 and batch: 1750, loss is 3.55455837726593 and perplexity is 34.972371962326555
At time: 908.1150162220001 and batch: 1800, loss is 3.494232482910156 and perplexity is 32.925007746621624
At time: 909.2768504619598 and batch: 1850, loss is 3.5134317541122435 and perplexity is 33.563251199017635
At time: 910.4395439624786 and batch: 1900, loss is 3.6090391492843628 and perplexity is 36.93055101521725
At time: 911.6024405956268 and batch: 1950, loss is 3.558600468635559 and perplexity is 35.11401956863532
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360720612281977 and perplexity of 78.31354779894639
finished 19 epochs...
Completing Train Step...
At time: 915.2053985595703 and batch: 50, loss is 3.7743326663970946 and perplexity is 43.56842393899178
At time: 916.3951222896576 and batch: 100, loss is 3.752059268951416 and perplexity is 42.60873456313207
At time: 917.5627238750458 and batch: 150, loss is 3.728028988838196 and perplexity is 41.59703908273067
At time: 918.7295136451721 and batch: 200, loss is 3.72178804397583 and perplexity is 41.338242662468794
At time: 919.8969125747681 and batch: 250, loss is 3.722562828063965 and perplexity is 41.37028328579488
At time: 921.063800573349 and batch: 300, loss is 3.715938410758972 and perplexity is 41.097134988316
At time: 922.2306950092316 and batch: 350, loss is 3.7476001453399657 and perplexity is 42.41915993126777
At time: 923.3965077400208 and batch: 400, loss is 3.7242584943771364 and perplexity is 41.44049299082207
At time: 924.5594878196716 and batch: 450, loss is 3.7623778486251833 and perplexity is 43.050672349449925
At time: 925.7234559059143 and batch: 500, loss is 3.7735374402999877 and perplexity is 43.533790963613704
At time: 926.8890407085419 and batch: 550, loss is 3.735811653137207 and perplexity is 41.92203791170992
At time: 928.0548341274261 and batch: 600, loss is 3.716403074264526 and perplexity is 41.116235764501035
At time: 929.220577955246 and batch: 650, loss is 3.711606855392456 and perplexity is 40.91950545651398
At time: 930.3863215446472 and batch: 700, loss is 3.748944001197815 and perplexity is 42.47620348840085
At time: 931.5509123802185 and batch: 750, loss is 3.7055354928970337 and perplexity is 40.67182095777576
At time: 932.7153923511505 and batch: 800, loss is 3.661912932395935 and perplexity is 38.935753141277715
At time: 933.8797841072083 and batch: 850, loss is 3.6580171251296996 and perplexity is 38.78436203802942
At time: 935.0429441928864 and batch: 900, loss is 3.6392559003829956 and perplexity is 38.06350314709036
At time: 936.2075433731079 and batch: 950, loss is 3.748213949203491 and perplexity is 42.44520496797545
At time: 937.3713381290436 and batch: 1000, loss is 3.7271508979797363 and perplexity is 41.56052913484477
At time: 938.536247253418 and batch: 1050, loss is 3.6683209133148194 and perplexity is 39.186053808929394
At time: 939.7007083892822 and batch: 1100, loss is 3.6894412803649903 and perplexity is 40.02247936419932
At time: 940.8650686740875 and batch: 1150, loss is 3.656367359161377 and perplexity is 38.720429668660145
At time: 942.0307648181915 and batch: 1200, loss is 3.6956896018981933 and perplexity is 40.273335582828935
At time: 943.2356715202332 and batch: 1250, loss is 3.677348804473877 and perplexity is 39.541422940963145
At time: 944.399569272995 and batch: 1300, loss is 3.6757824087142943 and perplexity is 39.479533907754366
At time: 945.5638530254364 and batch: 1350, loss is 3.544094409942627 and perplexity is 34.60833018722553
At time: 946.7304561138153 and batch: 1400, loss is 3.5885809326171874 and perplexity is 36.182693797157306
At time: 947.8945202827454 and batch: 1450, loss is 3.5041770553588867 and perplexity is 33.25406633317336
At time: 949.0590918064117 and batch: 1500, loss is 3.489467167854309 and perplexity is 32.76848295267132
At time: 950.2245254516602 and batch: 1550, loss is 3.504590768814087 and perplexity is 33.267826834111446
At time: 951.3917479515076 and batch: 1600, loss is 3.585226049423218 and perplexity is 36.061508480779466
At time: 952.5576777458191 and batch: 1650, loss is 3.5394299745559694 and perplexity is 34.44727776852833
At time: 953.7237782478333 and batch: 1700, loss is 3.549253544807434 and perplexity is 34.78734060248953
At time: 954.8895273208618 and batch: 1750, loss is 3.5548541164398193 and perplexity is 34.98271619224125
At time: 956.0558075904846 and batch: 1800, loss is 3.494602699279785 and perplexity is 32.93719938009148
At time: 957.2230727672577 and batch: 1850, loss is 3.5138036584854127 and perplexity is 33.57573584031878
At time: 958.3901076316833 and batch: 1900, loss is 3.609334206581116 and perplexity is 36.941449251490404
At time: 959.5567889213562 and batch: 1950, loss is 3.5586734914779665 and perplexity is 35.11658378777472
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360641124636628 and perplexity of 78.3073230868301
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f1288f88b38>
ELAPSED
5928.840839147568


RESULTS SO FAR:
[{'best_accuracy': -78.41160778879484, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}}, {'best_accuracy': -78.90825503473185, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.10008266219030648, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.21726970941698143, 'batch_size': 32}}, {'best_accuracy': -78.77456827312196, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.6593070000175439, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.4915447901082358, 'batch_size': 32}}, {'best_accuracy': -84.84145327741672, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.4010388534776912, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.9900218516510327, 'batch_size': 32}}, {'best_accuracy': -77.0356773603443, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.45364638623135345, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.002155165347015542, 'batch_size': 32}}, {'best_accuracy': -78.3073230868301, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.914303714397061, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.0, 'batch_size': 32}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -78.41160778879484, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.448808021214942, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.16996592128822285, 'batch_size': 32}}, {'best_accuracy': -78.90825503473185, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.10008266219030648, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.21726970941698143, 'batch_size': 32}}, {'best_accuracy': -78.77456827312196, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.6593070000175439, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.4915447901082358, 'batch_size': 32}}, {'best_accuracy': -84.84145327741672, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.4010388534776912, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.9900218516510327, 'batch_size': 32}}, {'best_accuracy': -77.0356773603443, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.45364638623135345, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.002155165347015542, 'batch_size': 32}}, {'best_accuracy': -78.3073230868301, 'params': {'wordvec_source': 'None', 'num_layers': 2, 'wordvec_dim': 300, 'rnn_dropout': 0.914303714397061, 'data': 'wikitext', 'seq_len': 35, 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'dropout': 0.0, 'batch_size': 32}}]
