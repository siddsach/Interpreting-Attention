TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'domain': [0, 1], 'type': 'continuous'}, {'name': 'rnn_dropout', 'domain': [0, 1], 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6259994506835938 and batch: 50, loss is 7.48451979637146 and perplexity is 1780.2690728269677
At time: 2.612698554992676 and batch: 100, loss is 6.648424053192139 and perplexity is 771.5674176870372
At time: 3.598618984222412 and batch: 150, loss is 6.420037660598755 and perplexity is 614.0262382858992
At time: 4.585084676742554 and batch: 200, loss is 6.2445406818389895 and perplexity is 515.1925332856728
At time: 5.571365594863892 and batch: 250, loss is 6.160475206375122 and perplexity is 473.6531043376506
At time: 6.558767795562744 and batch: 300, loss is 6.091833028793335 and perplexity is 442.23129134268964
At time: 7.545346975326538 and batch: 350, loss is 6.032529573440552 and perplexity is 416.76794222789107
At time: 8.532479286193848 and batch: 400, loss is 5.969976453781128 and perplexity is 391.4964523802045
At time: 9.519500255584717 and batch: 450, loss is 5.870634355545044 and perplexity is 354.47377136392544
At time: 10.506949186325073 and batch: 500, loss is 5.853495569229126 and perplexity is 348.45028619764264
At time: 11.49401068687439 and batch: 550, loss is 5.809559593200683 and perplexity is 333.4722298925636
At time: 12.486288785934448 and batch: 600, loss is 5.834732694625854 and perplexity is 341.9733105281005
At time: 13.47379446029663 and batch: 650, loss is 5.896322736740112 and perplexity is 363.6975940405033
At time: 14.462469339370728 and batch: 700, loss is 5.813813924789429 and perplexity is 334.89395343149204
At time: 15.449992179870605 and batch: 750, loss is 5.7345703506469725 and perplexity is 309.38001727530127
At time: 16.437855005264282 and batch: 800, loss is 5.7467163562774655 and perplexity is 313.16066209539434
At time: 17.426740646362305 and batch: 850, loss is 5.762674837112427 and perplexity is 318.1983202930546
At time: 18.41542935371399 and batch: 900, loss is 5.7450927639007565 and perplexity is 312.6526293623674
At time: 19.403488636016846 and batch: 950, loss is 5.752995347976684 and perplexity is 315.1331815291236
At time: 20.391600847244263 and batch: 1000, loss is 5.7299741268157955 and perplexity is 307.9613003348806
At time: 21.379591941833496 and batch: 1050, loss is 5.637725429534912 and perplexity is 280.8232392348142
At time: 22.36773109436035 and batch: 1100, loss is 5.708295135498047 and perplexity is 301.35685746873884
At time: 23.355207204818726 and batch: 1150, loss is 5.61961630821228 and perplexity is 275.78354704965204
At time: 24.343547344207764 and batch: 1200, loss is 5.690013904571533 and perplexity is 295.89773494310197
At time: 25.332439422607422 and batch: 1250, loss is 5.637567710876465 and perplexity is 280.77895166284134
At time: 26.32137942314148 and batch: 1300, loss is 5.651235990524292 and perplexity is 284.64306462344786
At time: 27.310378074645996 and batch: 1350, loss is 5.609911270141602 and perplexity is 273.12000303039514
At time: 28.298008918762207 and batch: 1400, loss is 5.612063541412353 and perplexity is 273.70846440347924
At time: 29.285919427871704 and batch: 1450, loss is 5.590867433547974 and perplexity is 267.9679633289289
At time: 30.275134801864624 and batch: 1500, loss is 5.558027057647705 and perplexity is 259.3107261930739
At time: 31.262924909591675 and batch: 1550, loss is 5.532914896011352 and perplexity is 252.8799565309407
At time: 32.24972605705261 and batch: 1600, loss is 5.558226156234741 and perplexity is 259.3623597321739
At time: 33.23690390586853 and batch: 1650, loss is 5.552970876693726 and perplexity is 258.00291329365206
At time: 34.225977182388306 and batch: 1700, loss is 5.562809991836548 and perplexity is 260.5539631210494
At time: 35.21264624595642 and batch: 1750, loss is 5.563156642913818 and perplexity is 260.6443000898516
At time: 36.20001697540283 and batch: 1800, loss is 5.552072267532349 and perplexity is 257.7711736493823
At time: 37.188058376312256 and batch: 1850, loss is 5.530248947143555 and perplexity is 252.20668934384435
At time: 38.17351722717285 and batch: 1900, loss is 5.551088428497314 and perplexity is 257.51769301915476
At time: 39.16565752029419 and batch: 1950, loss is 5.477487735748291 and perplexity is 239.24490532483776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.97676632903343 and perplexity of 145.00472513585177
finished 1 epochs...
Completing Train Step...
At time: 42.422019481658936 and batch: 50, loss is 5.252796192169189 and perplexity is 191.0998740504195
At time: 43.429433822631836 and batch: 100, loss is 5.179292192459107 and perplexity is 177.55709025814718
At time: 44.41096019744873 and batch: 150, loss is 5.097638692855835 and perplexity is 163.63505811301778
At time: 45.3914737701416 and batch: 200, loss is 5.052591733932495 and perplexity is 156.42735766288635
At time: 46.37250781059265 and batch: 250, loss is 5.070328178405762 and perplexity is 159.226573492843
At time: 47.39602065086365 and batch: 300, loss is 5.083335752487183 and perplexity is 161.31125386709766
At time: 48.38125467300415 and batch: 350, loss is 5.078910865783691 and perplexity is 160.59904672475665
At time: 49.364482402801514 and batch: 400, loss is 5.019449987411499 and perplexity is 151.32804856873452
At time: 50.34702157974243 and batch: 450, loss is 4.982000980377197 and perplexity is 145.76576446510498
At time: 51.34163761138916 and batch: 500, loss is 4.980437994003296 and perplexity is 145.53811251625643
At time: 52.32227110862732 and batch: 550, loss is 4.946135263442994 and perplexity is 140.6304128285265
At time: 53.301968574523926 and batch: 600, loss is 4.919849100112915 and perplexity is 136.98194106735832
At time: 54.28228998184204 and batch: 650, loss is 4.980461387634278 and perplexity is 145.54151722097845
At time: 55.26752209663391 and batch: 700, loss is 4.986886529922486 and perplexity is 146.47965277780816
At time: 56.24842715263367 and batch: 750, loss is 4.9260721778869625 and perplexity is 137.8370482799837
At time: 57.23009538650513 and batch: 800, loss is 4.929238386154175 and perplexity is 138.27416071110613
At time: 58.212944746017456 and batch: 850, loss is 4.9283297157287596 and perplexity is 138.14857213862095
At time: 59.19521522521973 and batch: 900, loss is 4.910284204483032 and perplexity is 135.6779692165811
At time: 60.177643060684204 and batch: 950, loss is 4.9583228492736815 and perplexity is 142.35484504294192
At time: 61.16101098060608 and batch: 1000, loss is 4.928791017532348 and perplexity is 138.21231502533564
At time: 62.15204572677612 and batch: 1050, loss is 4.846414518356323 and perplexity is 127.283199137318
At time: 63.134644746780396 and batch: 1100, loss is 4.916743383407593 and perplexity is 136.55717390931065
At time: 64.11626696586609 and batch: 1150, loss is 4.84661602973938 and perplexity is 127.3088507352737
At time: 65.09991598129272 and batch: 1200, loss is 4.915487909317017 and perplexity is 136.38583749230662
At time: 66.08273983001709 and batch: 1250, loss is 4.88633173942566 and perplexity is 132.46675912526007
At time: 67.06476545333862 and batch: 1300, loss is 4.890805692672729 and perplexity is 133.0607369360876
At time: 68.05072164535522 and batch: 1350, loss is 4.796390218734741 and perplexity is 121.07258221032383
At time: 69.0379204750061 and batch: 1400, loss is 4.7912138652801515 and perplexity is 120.4474869838268
At time: 70.02221035957336 and batch: 1450, loss is 4.74737099647522 and perplexity is 115.28081212555473
At time: 71.00677847862244 and batch: 1500, loss is 4.729983892440796 and perplexity is 113.29373744837915
At time: 71.99265146255493 and batch: 1550, loss is 4.730880470275879 and perplexity is 113.39535965152908
At time: 72.97875833511353 and batch: 1600, loss is 4.786036653518677 and perplexity is 119.82551626388718
At time: 73.96354150772095 and batch: 1650, loss is 4.765337715148926 and perplexity is 117.37074847520665
At time: 74.94928765296936 and batch: 1700, loss is 4.774075498580933 and perplexity is 118.4008022966319
At time: 75.93674564361572 and batch: 1750, loss is 4.7705301094055175 and perplexity is 117.9817686314494
At time: 76.92600321769714 and batch: 1800, loss is 4.7162402153015135 and perplexity is 111.74731599925815
At time: 77.9093599319458 and batch: 1850, loss is 4.745749025344849 and perplexity is 115.09398153427338
At time: 78.89566349983215 and batch: 1900, loss is 4.848254175186157 and perplexity is 127.5175720607089
At time: 79.88163733482361 and batch: 1950, loss is 4.760352983474731 and perplexity is 116.78714255554581
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614802586755087 and perplexity of 100.96789416527244
finished 2 epochs...
Completing Train Step...
At time: 83.17491745948792 and batch: 50, loss is 4.721894025802612 and perplexity is 112.38090355215611
At time: 84.19471883773804 and batch: 100, loss is 4.671113433837891 and perplexity is 106.8166094723136
At time: 85.18476629257202 and batch: 150, loss is 4.613046779632568 and perplexity is 100.79076956137601
At time: 86.17472338676453 and batch: 200, loss is 4.598190593719482 and perplexity is 99.30447085161177
At time: 87.16371941566467 and batch: 250, loss is 4.606121225357056 and perplexity is 100.09514917503043
At time: 88.15397763252258 and batch: 300, loss is 4.628547315597534 and perplexity is 102.36525164347144
At time: 89.14318680763245 and batch: 350, loss is 4.638134355545044 and perplexity is 103.35135073310116
At time: 90.13278603553772 and batch: 400, loss is 4.586521072387695 and perplexity is 98.15237051456768
At time: 91.12321281433105 and batch: 450, loss is 4.580096845626831 and perplexity is 97.52383850699822
At time: 92.11288690567017 and batch: 500, loss is 4.584378929138183 and perplexity is 97.94233911563362
At time: 93.10388255119324 and batch: 550, loss is 4.55608736038208 and perplexity is 95.2102267985335
At time: 94.0954077243805 and batch: 600, loss is 4.532692594528198 and perplexity is 93.0086588309379
At time: 95.08338665962219 and batch: 650, loss is 4.589468984603882 and perplexity is 98.44214198724005
At time: 96.07875800132751 and batch: 700, loss is 4.623164205551148 and perplexity is 101.81568873485227
At time: 97.09265446662903 and batch: 750, loss is 4.571013326644898 and perplexity is 96.64199007566928
At time: 98.08438110351562 and batch: 800, loss is 4.5760221195220945 and perplexity is 97.12726409116856
At time: 99.07675814628601 and batch: 850, loss is 4.5776928043365475 and perplexity is 97.28966876208862
At time: 100.06661081314087 and batch: 900, loss is 4.540737628936768 and perplexity is 93.75993465943495
At time: 101.05930233001709 and batch: 950, loss is 4.606002569198608 and perplexity is 100.08327297375627
At time: 102.05014085769653 and batch: 1000, loss is 4.585334606170655 and perplexity is 98.03598510016386
At time: 103.04565906524658 and batch: 1050, loss is 4.517843084335327 and perplexity is 91.63772980749312
At time: 104.03844380378723 and batch: 1100, loss is 4.5745557594299315 and perplexity is 96.98494491832336
At time: 105.03000092506409 and batch: 1150, loss is 4.524328422546387 and perplexity is 92.23396277463486
At time: 106.02219295501709 and batch: 1200, loss is 4.587822227478028 and perplexity is 98.28016509334451
At time: 107.01317119598389 and batch: 1250, loss is 4.582912034988404 and perplexity is 97.7987733949705
At time: 108.00428628921509 and batch: 1300, loss is 4.572637615203857 and perplexity is 96.79909210944193
At time: 109.0033495426178 and batch: 1350, loss is 4.461186866760254 and perplexity is 86.59021918559156
At time: 109.99933981895447 and batch: 1400, loss is 4.472287158966065 and perplexity is 87.55675038572937
At time: 110.99187350273132 and batch: 1450, loss is 4.420290555953979 and perplexity is 83.12043298675692
At time: 111.98354935646057 and batch: 1500, loss is 4.414963302612304 and perplexity is 82.67880675421016
At time: 112.97598695755005 and batch: 1550, loss is 4.428260278701782 and perplexity is 83.78552657773615
At time: 113.96577763557434 and batch: 1600, loss is 4.4950344944000244 and perplexity is 89.5712586386834
At time: 114.9582302570343 and batch: 1650, loss is 4.464877805709839 and perplexity is 86.91040893514953
At time: 115.94949150085449 and batch: 1700, loss is 4.469974880218506 and perplexity is 87.35452865920782
At time: 116.94121646881104 and batch: 1750, loss is 4.469070892333985 and perplexity is 87.27559690569151
At time: 117.93303751945496 and batch: 1800, loss is 4.417677965164184 and perplexity is 82.90355673689815
At time: 118.92551231384277 and batch: 1850, loss is 4.462586078643799 and perplexity is 86.7114620517236
At time: 119.91822147369385 and batch: 1900, loss is 4.565997810363769 and perplexity is 96.1584941055035
At time: 120.90990161895752 and batch: 1950, loss is 4.486495561599732 and perplexity is 88.80967187690297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.514157885174418 and perplexity of 91.30064801075977
finished 3 epochs...
Completing Train Step...
At time: 124.16189360618591 and batch: 50, loss is 4.471598148345947 and perplexity is 87.4964436332329
At time: 125.14921712875366 and batch: 100, loss is 4.422915744781494 and perplexity is 83.33892648663821
At time: 126.13631510734558 and batch: 150, loss is 4.3770707416534425 and perplexity is 79.60450937245123
At time: 127.12443232536316 and batch: 200, loss is 4.365882825851441 and perplexity is 78.71886432321004
At time: 128.1211862564087 and batch: 250, loss is 4.369665622711182 and perplexity is 79.01720572266787
At time: 129.1098029613495 and batch: 300, loss is 4.387664070129395 and perplexity is 80.45226845577248
At time: 130.09801149368286 and batch: 350, loss is 4.40265233039856 and perplexity is 81.66719003096897
At time: 131.08587622642517 and batch: 400, loss is 4.347194452285766 and perplexity is 77.2613980360287
At time: 132.0837800502777 and batch: 450, loss is 4.3608275985717775 and perplexity is 78.32192672307355
At time: 133.07192659378052 and batch: 500, loss is 4.370271434783936 and perplexity is 79.06508980276237
At time: 134.0657422542572 and batch: 550, loss is 4.341376056671143 and perplexity is 76.81316591694083
At time: 135.0582354068756 and batch: 600, loss is 4.318537759780884 and perplexity is 75.07876479869893
At time: 136.0473051071167 and batch: 650, loss is 4.38188871383667 and perplexity is 79.98896709387436
At time: 137.03602862358093 and batch: 700, loss is 4.413249425888061 and perplexity is 82.53722683164897
At time: 138.02562737464905 and batch: 750, loss is 4.365637235641479 and perplexity is 78.69953411454514
At time: 139.02359676361084 and batch: 800, loss is 4.369097309112549 and perplexity is 78.97231192821498
At time: 140.01267075538635 and batch: 850, loss is 4.375792055130005 and perplexity is 79.50278520963015
At time: 141.00016951560974 and batch: 900, loss is 4.338427896499634 and perplexity is 76.58704188924565
At time: 141.9879469871521 and batch: 950, loss is 4.4065468311309814 and perplexity is 81.98586309582193
At time: 142.97580456733704 and batch: 1000, loss is 4.388198833465577 and perplexity is 80.49530288484716
At time: 143.9635136127472 and batch: 1050, loss is 4.331013469696045 and perplexity is 76.0212928173712
At time: 144.9531216621399 and batch: 1100, loss is 4.376679134368897 and perplexity is 79.57334176982673
At time: 145.94227075576782 and batch: 1150, loss is 4.336011056900024 and perplexity is 76.40216679031052
At time: 146.9749071598053 and batch: 1200, loss is 4.394266567230225 and perplexity is 80.98521176729453
At time: 147.96243119239807 and batch: 1250, loss is 4.400246572494507 and perplexity is 81.47095468506288
At time: 148.95143795013428 and batch: 1300, loss is 4.383321809768677 and perplexity is 80.1036811357024
At time: 149.94051361083984 and batch: 1350, loss is 4.269212894439697 and perplexity is 71.46536269141382
At time: 150.92903852462769 and batch: 1400, loss is 4.287516803741455 and perplexity is 72.78550321720135
At time: 151.91743421554565 and batch: 1450, loss is 4.231934242248535 and perplexity is 68.85027657609153
At time: 152.90502667427063 and batch: 1500, loss is 4.228667225837707 and perplexity is 68.6257086259585
At time: 153.89320993423462 and batch: 1550, loss is 4.249329662322998 and perplexity is 70.05843379493588
At time: 154.88077688217163 and batch: 1600, loss is 4.323617296218872 and perplexity is 75.46110034179952
At time: 155.86882781982422 and batch: 1650, loss is 4.288168983459473 and perplexity is 72.83298792876515
At time: 156.86182141304016 and batch: 1700, loss is 4.2878669738769535 and perplexity is 72.81099498969348
At time: 157.85584473609924 and batch: 1750, loss is 4.289507346153259 and perplexity is 72.93053014155544
At time: 158.84379696846008 and batch: 1800, loss is 4.240442247390747 and perplexity is 69.43855406861834
At time: 159.8323073387146 and batch: 1850, loss is 4.290899696350098 and perplexity is 73.03214570536238
At time: 160.82015538215637 and batch: 1900, loss is 4.393473720550537 and perplexity is 80.92102835820458
At time: 161.80892300605774 and batch: 1950, loss is 4.317195701599121 and perplexity is 74.97807231082606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.471307514989099 and perplexity of 87.47101794306329
finished 4 epochs...
Completing Train Step...
At time: 165.07001781463623 and batch: 50, loss is 4.30820788860321 and perplexity is 74.30720275924746
At time: 166.08500218391418 and batch: 100, loss is 4.263919124603271 and perplexity is 71.08804111800197
At time: 167.07571148872375 and batch: 150, loss is 4.220703301429748 and perplexity is 68.08134916593625
At time: 168.06786823272705 and batch: 200, loss is 4.2110971307754514 and perplexity is 67.43047929609625
At time: 169.058575630188 and batch: 250, loss is 4.214670915603637 and perplexity is 67.67189244233887
At time: 170.049946308136 and batch: 300, loss is 4.233234820365905 and perplexity is 68.93987999467366
At time: 171.04184913635254 and batch: 350, loss is 4.242994790077209 and perplexity is 69.6160253471126
At time: 172.07897329330444 and batch: 400, loss is 4.190032844543457 and perplexity is 66.02495948444866
At time: 173.07282209396362 and batch: 450, loss is 4.215202169418335 and perplexity is 67.70785294457791
At time: 174.06467938423157 and batch: 500, loss is 4.229738254547119 and perplexity is 68.69924810451722
At time: 175.05760312080383 and batch: 550, loss is 4.201327095031738 and perplexity is 66.77488888887721
At time: 176.04875874519348 and batch: 600, loss is 4.179813613891602 and perplexity is 65.35367106233441
At time: 177.0402729511261 and batch: 650, loss is 4.2388773536682125 and perplexity is 69.32997509069317
At time: 178.03834891319275 and batch: 700, loss is 4.266947202682495 and perplexity is 71.30362749847222
At time: 179.0325207710266 and batch: 750, loss is 4.226121764183045 and perplexity is 68.45124665345804
At time: 180.0244529247284 and batch: 800, loss is 4.226338133811951 and perplexity is 68.46605902671068
At time: 181.02278232574463 and batch: 850, loss is 4.237404823303223 and perplexity is 69.22795972596298
At time: 182.01998805999756 and batch: 900, loss is 4.203872818946838 and perplexity is 66.94509587852997
At time: 183.01501083374023 and batch: 950, loss is 4.272294836044312 and perplexity is 71.68595451693862
At time: 184.0112910270691 and batch: 1000, loss is 4.252719869613648 and perplexity is 70.29634947181643
At time: 185.0084512233734 and batch: 1050, loss is 4.201802968978882 and perplexity is 66.80667288080988
At time: 186.0039131641388 and batch: 1100, loss is 4.240704212188721 and perplexity is 69.45674690824427
At time: 187.00478649139404 and batch: 1150, loss is 4.206206908226013 and perplexity is 67.10153420860532
At time: 188.00129652023315 and batch: 1200, loss is 4.263039312362671 and perplexity is 71.02552449474392
At time: 188.99187350273132 and batch: 1250, loss is 4.270652132034302 and perplexity is 71.568292380483
At time: 189.97953581809998 and batch: 1300, loss is 4.2537554740905765 and perplexity is 70.36918639465323
At time: 190.96723890304565 and batch: 1350, loss is 4.137968721389771 and perplexity is 62.675380898781235
At time: 191.95533752441406 and batch: 1400, loss is 4.163105340003967 and perplexity is 64.27079570742269
At time: 192.9451150894165 and batch: 1450, loss is 4.102676753997803 and perplexity is 60.50202006586468
At time: 193.93972325325012 and batch: 1500, loss is 4.104874815940857 and perplexity is 60.63515351783383
At time: 194.92926287651062 and batch: 1550, loss is 4.123763217926025 and perplexity is 61.79133955085524
At time: 195.91741824150085 and batch: 1600, loss is 4.20003842830658 and perplexity is 66.6888937329387
At time: 196.90675806999207 and batch: 1650, loss is 4.165105776786804 and perplexity is 64.3994940547538
At time: 197.89597821235657 and batch: 1700, loss is 4.163078980445862 and perplexity is 64.2691015799771
At time: 198.89161467552185 and batch: 1750, loss is 4.164475493431091 and perplexity is 64.35891691442612
At time: 199.8903889656067 and batch: 1800, loss is 4.114739952087402 and perplexity is 61.23628782319936
At time: 200.88662338256836 and batch: 1850, loss is 4.165962672233581 and perplexity is 64.4547013380408
At time: 201.8772292137146 and batch: 1900, loss is 4.267654762268067 and perplexity is 71.3540969165495
At time: 202.8678789138794 and batch: 1950, loss is 4.194539737701416 and perplexity is 66.32319848343447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.461017839298692 and perplexity of 86.57558429753031
finished 5 epochs...
Completing Train Step...
At time: 206.1121323108673 and batch: 50, loss is 4.18735282421112 and perplexity is 65.84824815134071
At time: 207.14175748825073 and batch: 100, loss is 4.149760637283325 and perplexity is 63.41881838054743
At time: 208.13626646995544 and batch: 150, loss is 4.106374144554138 and perplexity is 60.726133726045006
At time: 209.1361424922943 and batch: 200, loss is 4.097714514732361 and perplexity is 60.202538231047235
At time: 210.13441705703735 and batch: 250, loss is 4.100536689758301 and perplexity is 60.37268030336767
At time: 211.13666343688965 and batch: 300, loss is 4.120772614479065 and perplexity is 61.6068222044307
At time: 212.14083170890808 and batch: 350, loss is 4.1287265968322755 and perplexity is 62.09879576182191
At time: 213.13792872428894 and batch: 400, loss is 4.0792125749588015 and perplexity is 59.09891555726236
At time: 214.13224339485168 and batch: 450, loss is 4.109482188224792 and perplexity is 60.91516681098653
At time: 215.12876439094543 and batch: 500, loss is 4.124975533485412 and perplexity is 61.86629557922756
At time: 216.12373113632202 and batch: 550, loss is 4.09859076499939 and perplexity is 60.255313840192
At time: 217.13235211372375 and batch: 600, loss is 4.0779722929000854 and perplexity is 59.02566166973886
At time: 218.13040375709534 and batch: 650, loss is 4.134952096939087 and perplexity is 62.486597699474444
At time: 219.1265354156494 and batch: 700, loss is 4.165452923774719 and perplexity is 64.42185402601193
At time: 220.1207709312439 and batch: 750, loss is 4.12237108707428 and perplexity is 61.70537776960272
At time: 221.11563420295715 and batch: 800, loss is 4.120719833374023 and perplexity is 61.603570614088696
At time: 222.15454077720642 and batch: 850, loss is 4.136047158241272 and perplexity is 62.55506183389082
At time: 223.14849758148193 and batch: 900, loss is 4.1026088857650755 and perplexity is 60.49791404002232
At time: 224.15202260017395 and batch: 950, loss is 4.170807857513427 and perplexity is 64.7677540950552
At time: 225.14796447753906 and batch: 1000, loss is 4.1522832775115965 and perplexity is 63.5790032024139
At time: 226.1434726715088 and batch: 1050, loss is 4.103477191925049 and perplexity is 60.55046756442138
At time: 227.13885688781738 and batch: 1100, loss is 4.136911301612854 and perplexity is 62.60914173896391
At time: 228.13497591018677 and batch: 1150, loss is 4.107793340682983 and perplexity is 60.81237720367816
At time: 229.13597798347473 and batch: 1200, loss is 4.16507321357727 and perplexity is 64.39739703467804
At time: 230.13074469566345 and batch: 1250, loss is 4.174377074241638 and perplexity is 64.99933728586849
At time: 231.12552046775818 and batch: 1300, loss is 4.155102982521057 and perplexity is 63.75853022391351
At time: 232.1209979057312 and batch: 1350, loss is 4.042064089775085 and perplexity is 56.943758615308354
At time: 233.11498475074768 and batch: 1400, loss is 4.067319850921631 and perplexity is 58.40023132796523
At time: 234.11040711402893 and batch: 1450, loss is 4.002957301139832 and perplexity is 54.75985218760388
At time: 235.10415601730347 and batch: 1500, loss is 4.009681077003479 and perplexity is 55.129285762502704
At time: 236.09972047805786 and batch: 1550, loss is 4.029023709297181 and perplexity is 56.20601104618365
At time: 237.0932810306549 and batch: 1600, loss is 4.10326813697815 and perplexity is 60.53781051269571
At time: 238.08668184280396 and batch: 1650, loss is 4.07119665145874 and perplexity is 58.62707680937083
At time: 239.0846655368805 and batch: 1700, loss is 4.066799821853638 and perplexity is 58.36986940532256
At time: 240.07948184013367 and batch: 1750, loss is 4.0684054088592525 and perplexity is 58.46366258556567
At time: 241.07507348060608 and batch: 1800, loss is 4.020371842384338 and perplexity is 55.721821710079546
At time: 242.07048082351685 and batch: 1850, loss is 4.071831860542297 and perplexity is 58.66432909134393
At time: 243.06591749191284 and batch: 1900, loss is 4.171619734764099 and perplexity is 64.82035891261988
At time: 244.0686514377594 and batch: 1950, loss is 4.098241410255432 and perplexity is 60.234267037067596
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.461487951944041 and perplexity of 86.61629414284384
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 247.32170939445496 and batch: 50, loss is 4.131904401779175 and perplexity is 62.29644750520303
At time: 248.3106987476349 and batch: 100, loss is 4.121264338493347 and perplexity is 61.63712320760717
At time: 249.29938101768494 and batch: 150, loss is 4.0738800477981565 and perplexity is 58.78460775712943
At time: 250.28975343704224 and batch: 200, loss is 4.064101953506469 and perplexity is 58.21260741368614
At time: 251.28136372566223 and batch: 250, loss is 4.071806182861328 and perplexity is 58.66282274675706
At time: 252.2764675617218 and batch: 300, loss is 4.09404935836792 and perplexity is 59.9822903828514
At time: 253.2709231376648 and batch: 350, loss is 4.0961212682724 and perplexity is 60.10669711965956
At time: 254.26332020759583 and batch: 400, loss is 4.039280757904053 and perplexity is 56.785485602436104
At time: 255.25223231315613 and batch: 450, loss is 4.05108642578125 and perplexity is 57.4598490085403
At time: 256.2542905807495 and batch: 500, loss is 4.0718699550628665 and perplexity is 58.666563923402336
At time: 257.24868059158325 and batch: 550, loss is 4.041771378517151 and perplexity is 56.92709297532178
At time: 258.24651980400085 and batch: 600, loss is 3.99733877658844 and perplexity is 54.45304532171304
At time: 259.2352659702301 and batch: 650, loss is 4.052582831382751 and perplexity is 57.5458966134604
At time: 260.2298254966736 and batch: 700, loss is 4.085901880264283 and perplexity is 59.495571443721396
At time: 261.2204349040985 and batch: 750, loss is 4.025406875610352 and perplexity is 56.00309043828327
At time: 262.2100598812103 and batch: 800, loss is 4.02534330368042 and perplexity is 55.99953032690474
At time: 263.2109229564667 and batch: 850, loss is 4.035391340255737 and perplexity is 56.565052089448855
At time: 264.20220851898193 and batch: 900, loss is 3.993409848213196 and perplexity is 54.239522938574446
At time: 265.1921284198761 and batch: 950, loss is 4.069605965614318 and perplexity is 58.53389368038076
At time: 266.18500304222107 and batch: 1000, loss is 4.03491952419281 and perplexity is 56.53837008426706
At time: 267.1757769584656 and batch: 1050, loss is 3.9815628337860107 and perplexity is 53.60073784709452
At time: 268.1692039966583 and batch: 1100, loss is 4.009227089881897 and perplexity is 55.104263457076485
At time: 269.16034388542175 and batch: 1150, loss is 3.9724924325942994 and perplexity is 53.11675592393859
At time: 270.15028858184814 and batch: 1200, loss is 4.024444169998169 and perplexity is 55.94920189238357
At time: 271.14333391189575 and batch: 1250, loss is 4.020573253631592 and perplexity is 55.73304584198468
At time: 272.13219714164734 and batch: 1300, loss is 4.009479446411133 and perplexity is 55.11817113252116
At time: 273.1255180835724 and batch: 1350, loss is 3.8951327085494993 and perplexity is 49.162577224101284
At time: 274.1146705150604 and batch: 1400, loss is 3.902661714553833 and perplexity is 49.5341194800481
At time: 275.1080300807953 and batch: 1450, loss is 3.835879769325256 and perplexity is 46.33417312624778
At time: 276.09773659706116 and batch: 1500, loss is 3.8358851528167723 and perplexity is 46.33442256654714
At time: 277.09203696250916 and batch: 1550, loss is 3.851510705947876 and perplexity is 47.06410958327315
At time: 278.08570075035095 and batch: 1600, loss is 3.914491586685181 and perplexity is 50.1235815356253
At time: 279.07808232307434 and batch: 1650, loss is 3.875999298095703 and perplexity is 48.230871235303866
At time: 280.0719630718231 and batch: 1700, loss is 3.8606329345703125 and perplexity is 47.4954033400894
At time: 281.067022562027 and batch: 1750, loss is 3.8508269596099853 and perplexity is 47.03194066964122
At time: 282.0575940608978 and batch: 1800, loss is 3.804626841545105 and perplexity is 44.90848900356483
At time: 283.0485360622406 and batch: 1850, loss is 3.836479358673096 and perplexity is 46.36196293329883
At time: 284.0402090549469 and batch: 1900, loss is 3.9361849355697633 and perplexity is 51.222809739836386
At time: 285.0291385650635 and batch: 1950, loss is 3.861363353729248 and perplexity is 47.53010756542299
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383272960574128 and perplexity of 80.09976823097043
finished 7 epochs...
Completing Train Step...
At time: 288.2577087879181 and batch: 50, loss is 4.039250807762146 and perplexity is 56.783784894552404
At time: 289.27301478385925 and batch: 100, loss is 4.01905086517334 and perplexity is 55.648263048799386
At time: 290.2676920890808 and batch: 150, loss is 3.9666682577133177 and perplexity is 52.80829378898141
At time: 291.2589192390442 and batch: 200, loss is 3.9588670253753664 and perplexity is 52.39792678514921
At time: 292.25723147392273 and batch: 250, loss is 3.9649211263656614 and perplexity is 52.71611131438065
At time: 293.24898624420166 and batch: 300, loss is 3.982512979507446 and perplexity is 53.651690561244145
At time: 294.25076723098755 and batch: 350, loss is 3.9908435773849487 and perplexity is 54.10050808429479
At time: 295.2466661930084 and batch: 400, loss is 3.9362587976455687 and perplexity is 51.22659330262154
At time: 296.2455198764801 and batch: 450, loss is 3.957829923629761 and perplexity is 52.34361297315708
At time: 297.2789468765259 and batch: 500, loss is 3.9818614721298218 and perplexity is 53.61674747309734
At time: 298.26924896240234 and batch: 550, loss is 3.9512166118621828 and perplexity is 51.99859046970324
At time: 299.26570177078247 and batch: 600, loss is 3.914023036956787 and perplexity is 50.10010164628812
At time: 300.2564334869385 and batch: 650, loss is 3.9720371055603025 and perplexity is 53.09257593432744
At time: 301.25135469436646 and batch: 700, loss is 4.006341428756714 and perplexity is 54.94548043336868
At time: 302.2468972206116 and batch: 750, loss is 3.951631021499634 and perplexity is 52.02014365234261
At time: 303.2441544532776 and batch: 800, loss is 3.949134292602539 and perplexity is 51.890425459420015
At time: 304.232971906662 and batch: 850, loss is 3.9660959434509278 and perplexity is 52.77807949613357
At time: 305.22704315185547 and batch: 900, loss is 3.9240034198760987 and perplexity is 50.602623353284976
At time: 306.22668981552124 and batch: 950, loss is 4.002611255645752 and perplexity is 54.74090606579698
At time: 307.21668767929077 and batch: 1000, loss is 3.9710506296157835 and perplexity is 53.04022720995953
At time: 308.2080307006836 and batch: 1050, loss is 3.923782606124878 and perplexity is 50.591450831769315
At time: 309.20184874534607 and batch: 1100, loss is 3.950896382331848 and perplexity is 51.98194165136297
At time: 310.19311904907227 and batch: 1150, loss is 3.919694113731384 and perplexity is 50.385030331729666
At time: 311.1906199455261 and batch: 1200, loss is 3.9713606643676758 and perplexity is 53.0566740730607
At time: 312.18568444252014 and batch: 1250, loss is 3.969647707939148 and perplexity is 52.96586809767431
At time: 313.1805167198181 and batch: 1300, loss is 3.9610470390319823 and perplexity is 52.5122795811596
At time: 314.1712567806244 and batch: 1350, loss is 3.845855779647827 and perplexity is 46.79871660829126
At time: 315.16615056991577 and batch: 1400, loss is 3.859927940368652 and perplexity is 47.4619311563632
At time: 316.15816378593445 and batch: 1450, loss is 3.794321050643921 and perplexity is 44.44804818485783
At time: 317.1481034755707 and batch: 1500, loss is 3.795769691467285 and perplexity is 44.51248410295944
At time: 318.1437408924103 and batch: 1550, loss is 3.8173988342285154 and perplexity is 45.48573836192787
At time: 319.1333758831024 and batch: 1600, loss is 3.882939829826355 and perplexity is 48.56678348388537
At time: 320.1259694099426 and batch: 1650, loss is 3.8461073064804077 and perplexity is 46.8104892217506
At time: 321.11773681640625 and batch: 1700, loss is 3.836573238372803 and perplexity is 46.36631558476644
At time: 322.11554884910583 and batch: 1750, loss is 3.8314714288711547 and perplexity is 46.13036587238568
At time: 323.1070237159729 and batch: 1800, loss is 3.787970576286316 and perplexity is 44.16667636249431
At time: 324.10002994537354 and batch: 1850, loss is 3.8242655658721922 and perplexity is 45.79915155150291
At time: 325.08847999572754 and batch: 1900, loss is 3.925947723388672 and perplexity is 50.70110592059236
At time: 326.0832860469818 and batch: 1950, loss is 3.8536314010620116 and perplexity is 47.16402411720365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381857228833575 and perplexity of 79.98644868064423
finished 8 epochs...
Completing Train Step...
At time: 329.3087203502655 and batch: 50, loss is 3.9906535863876345 and perplexity is 54.090230451168445
At time: 330.3268566131592 and batch: 100, loss is 3.970752491950989 and perplexity is 53.02441627751333
At time: 331.3196952342987 and batch: 150, loss is 3.918170437812805 and perplexity is 50.30831833131133
At time: 332.318470954895 and batch: 200, loss is 3.9104598140716553 and perplexity is 49.921901489536964
At time: 333.3076550960541 and batch: 250, loss is 3.915009355545044 and perplexity is 50.14954068512895
At time: 334.3066306114197 and batch: 300, loss is 3.932447032928467 and perplexity is 51.03170125897551
At time: 335.3032991886139 and batch: 350, loss is 3.941965727806091 and perplexity is 51.519775682923175
At time: 336.30584168434143 and batch: 400, loss is 3.8878656911849974 and perplexity is 48.8066069095098
At time: 337.30033111572266 and batch: 450, loss is 3.913051290512085 and perplexity is 50.05144069751527
At time: 338.28903818130493 and batch: 500, loss is 3.938209056854248 and perplexity is 51.326595921756926
At time: 339.2831642627716 and batch: 550, loss is 3.907063913345337 and perplexity is 49.75265919566761
At time: 340.2737708091736 and batch: 600, loss is 3.872018609046936 and perplexity is 48.03926075824857
At time: 341.2655997276306 and batch: 650, loss is 3.930236692428589 and perplexity is 50.91902839147918
At time: 342.2592601776123 and batch: 700, loss is 3.964528799057007 and perplexity is 52.69543340082626
At time: 343.2484748363495 and batch: 750, loss is 3.912751088142395 and perplexity is 50.036417391540326
At time: 344.2426300048828 and batch: 800, loss is 3.908527340888977 and perplexity is 49.82552190915109
At time: 345.23302268981934 and batch: 850, loss is 3.9280554676055908 and perplexity is 50.80808358455938
At time: 346.2255985736847 and batch: 900, loss is 3.886059646606445 and perplexity is 48.71853955242791
At time: 347.2460057735443 and batch: 950, loss is 3.9656208181381225 and perplexity is 52.7530092508294
At time: 348.23829436302185 and batch: 1000, loss is 3.93530770778656 and perplexity is 51.17789537094523
At time: 349.2279462814331 and batch: 1050, loss is 3.890745840072632 and perplexity is 48.947379830282735
At time: 350.22301054000854 and batch: 1100, loss is 3.91640193939209 and perplexity is 50.21942677524983
At time: 351.2131757736206 and batch: 1150, loss is 3.8871816921234132 and perplexity is 48.773234650782534
At time: 352.2047607898712 and batch: 1200, loss is 3.938722643852234 and perplexity is 51.35296336448151
At time: 353.19792008399963 and batch: 1250, loss is 3.93750328540802 and perplexity is 51.29038385614736
At time: 354.18777799606323 and batch: 1300, loss is 3.929969811439514 and perplexity is 50.90544088402369
At time: 355.1847231388092 and batch: 1350, loss is 3.8147659635543825 and perplexity is 45.36613781078465
At time: 356.17399430274963 and batch: 1400, loss is 3.831438183784485 and perplexity is 46.128832289866324
At time: 357.1657543182373 and batch: 1450, loss is 3.766486349105835 and perplexity is 43.22790989845688
At time: 358.16065788269043 and batch: 1500, loss is 3.7682820987701415 and perplexity is 43.30560614376989
At time: 359.15077471733093 and batch: 1550, loss is 3.792394742965698 and perplexity is 44.36250998125678
At time: 360.1445724964142 and batch: 1600, loss is 3.8583574867248536 and perplexity is 47.387452891275665
At time: 361.13673758506775 and batch: 1650, loss is 3.822330746650696 and perplexity is 45.71062414263604
At time: 362.1260304450989 and batch: 1700, loss is 3.814642548561096 and perplexity is 45.360539294668826
At time: 363.1223680973053 and batch: 1750, loss is 3.8114869689941404 and perplexity is 45.217626109278626
At time: 364.11395239830017 and batch: 1800, loss is 3.76897780418396 and perplexity is 43.33574457093067
At time: 365.1047923564911 and batch: 1850, loss is 3.8082474279403686 and perplexity is 45.071378768177176
At time: 366.10151171684265 and batch: 1900, loss is 3.9100421667099 and perplexity is 49.90105609240161
At time: 367.08963561058044 and batch: 1950, loss is 3.83868860244751 and perplexity is 46.46450103540539
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384296931776889 and perplexity of 80.181830094309
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 370.34637117385864 and batch: 50, loss is 3.9779614067077635 and perplexity is 53.408045889686846
At time: 371.3443968296051 and batch: 100, loss is 3.9913587236404418 and perplexity is 54.12838493816664
At time: 372.36579394340515 and batch: 150, loss is 3.948211917877197 and perplexity is 51.84258510924572
At time: 373.36334347724915 and batch: 200, loss is 3.9487640333175658 and perplexity is 51.871216104033
At time: 374.35785484313965 and batch: 250, loss is 3.9520473957061766 and perplexity is 52.04180800830661
At time: 375.35216879844666 and batch: 300, loss is 3.959323592185974 and perplexity is 52.42185540155433
At time: 376.3463065624237 and batch: 350, loss is 3.9746385526657106 and perplexity is 53.2308732709192
At time: 377.3482835292816 and batch: 400, loss is 3.9231544160842895 and perplexity is 50.5596797663961
At time: 378.35071182250977 and batch: 450, loss is 3.9470916032791137 and perplexity is 51.7845376261381
At time: 379.3443684577942 and batch: 500, loss is 3.967793641090393 and perplexity is 52.86775681805972
At time: 380.3412790298462 and batch: 550, loss is 3.94377562046051 and perplexity is 51.613105379378275
At time: 381.33402156829834 and batch: 600, loss is 3.889984908103943 and perplexity is 48.910148371286475
At time: 382.32720470428467 and batch: 650, loss is 3.945805382728577 and perplexity is 51.71797410650344
At time: 383.3216280937195 and batch: 700, loss is 3.984308009147644 and perplexity is 53.748083424188806
At time: 384.3161358833313 and batch: 750, loss is 3.925223541259766 and perplexity is 50.664402377397984
At time: 385.3187253475189 and batch: 800, loss is 3.9178323459625246 and perplexity is 50.29131237383201
At time: 386.3127236366272 and batch: 850, loss is 3.934314136505127 and perplexity is 51.1270717364933
At time: 387.315571308136 and batch: 900, loss is 3.8823765754699706 and perplexity is 48.539435734105105
At time: 388.309476852417 and batch: 950, loss is 3.966735830307007 and perplexity is 52.811862302926556
At time: 389.30333042144775 and batch: 1000, loss is 3.932437176704407 and perplexity is 51.031198281572465
At time: 390.3012113571167 and batch: 1050, loss is 3.8930871963500975 and perplexity is 49.06211735360868
At time: 391.29452443122864 and batch: 1100, loss is 3.910905122756958 and perplexity is 49.94413709634406
At time: 392.2889542579651 and batch: 1150, loss is 3.8840379190444945 and perplexity is 48.620143436821444
At time: 393.283105134964 and batch: 1200, loss is 3.9249668550491332 and perplexity is 50.65139919287824
At time: 394.28207182884216 and batch: 1250, loss is 3.9187921905517578 and perplexity is 50.33960739204756
At time: 395.28142738342285 and batch: 1300, loss is 3.912887077331543 and perplexity is 50.043222266053476
At time: 396.28235268592834 and batch: 1350, loss is 3.798892092704773 and perplexity is 44.651687149192725
At time: 397.2826597690582 and batch: 1400, loss is 3.810704689025879 and perplexity is 45.1822670982872
At time: 398.27800369262695 and batch: 1450, loss is 3.7425670528411867 and perplexity is 42.20619675685646
At time: 399.27883434295654 and batch: 1500, loss is 3.743533201217651 and perplexity is 42.24699391020809
At time: 400.27252101898193 and batch: 1550, loss is 3.767504262924194 and perplexity is 43.27193458814995
At time: 401.26575994491577 and batch: 1600, loss is 3.8340984201431274 and perplexity is 46.25170925512564
At time: 402.26795530319214 and batch: 1650, loss is 3.7957089710235596 and perplexity is 44.50978136722988
At time: 403.2622616291046 and batch: 1700, loss is 3.771350693702698 and perplexity is 43.438697604789915
At time: 404.26158237457275 and batch: 1750, loss is 3.760169687271118 and perplexity is 42.9557143983247
At time: 405.26100492477417 and batch: 1800, loss is 3.7207690572738645 and perplexity is 41.29614099707466
At time: 406.2639203071594 and batch: 1850, loss is 3.7597277212142943 and perplexity is 42.936733625351685
At time: 407.2608871459961 and batch: 1900, loss is 3.864694094657898 and perplexity is 47.68868197857851
At time: 408.25581336021423 and batch: 1950, loss is 3.7963700008392336 and perplexity is 44.53921338645214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357134867823401 and perplexity of 78.0332382883734
finished 10 epochs...
Completing Train Step...
At time: 411.4938189983368 and batch: 50, loss is 3.9715242910385133 and perplexity is 53.06535627030513
At time: 412.52350544929504 and batch: 100, loss is 3.964624490737915 and perplexity is 52.70047615669561
At time: 413.52068281173706 and batch: 150, loss is 3.9134186935424804 and perplexity is 50.069833127013474
At time: 414.5141758918762 and batch: 200, loss is 3.910080919265747 and perplexity is 49.90298992333486
At time: 415.51019740104675 and batch: 250, loss is 3.9100486421585083 and perplexity is 49.90137922517206
At time: 416.505735874176 and batch: 300, loss is 3.915996150970459 and perplexity is 50.19905244743623
At time: 417.5047483444214 and batch: 350, loss is 3.9329394340515136 and perplexity is 51.05683551354616
At time: 418.50116872787476 and batch: 400, loss is 3.8815874004364015 and perplexity is 48.50114473441799
At time: 419.50053095817566 and batch: 450, loss is 3.907857174873352 and perplexity is 49.792141724038956
At time: 420.4997351169586 and batch: 500, loss is 3.9320614337921143 and perplexity is 51.012027272423325
At time: 421.4942977428436 and batch: 550, loss is 3.9069137811660766 and perplexity is 49.74519028119479
At time: 422.5239293575287 and batch: 600, loss is 3.8562008333206177 and perplexity is 47.285364703667284
At time: 423.5233817100525 and batch: 650, loss is 3.914015212059021 and perplexity is 50.09970961964844
At time: 424.52102303504944 and batch: 700, loss is 3.9551200580596926 and perplexity is 52.201960834358744
At time: 425.5226583480835 and batch: 750, loss is 3.8970091724395752 and perplexity is 49.254915632755605
At time: 426.522522687912 and batch: 800, loss is 3.889657440185547 and perplexity is 48.89413448897035
At time: 427.52639293670654 and batch: 850, loss is 3.90722327709198 and perplexity is 49.76058859765531
At time: 428.52481627464294 and batch: 900, loss is 3.8564114952087403 and perplexity is 47.29532697717515
At time: 429.5233643054962 and batch: 950, loss is 3.9416805839538576 and perplexity is 51.5050872298793
At time: 430.5206229686737 and batch: 1000, loss is 3.9097735834121705 and perplexity is 49.887655301890945
At time: 431.5160086154938 and batch: 1050, loss is 3.872633318901062 and perplexity is 48.06880004333624
At time: 432.509468793869 and batch: 1100, loss is 3.890780334472656 and perplexity is 48.949068269903435
At time: 433.50239610671997 and batch: 1150, loss is 3.865790271759033 and perplexity is 47.7409858816798
At time: 434.5016288757324 and batch: 1200, loss is 3.9077050495147705 and perplexity is 49.784567652743405
At time: 435.50437092781067 and batch: 1250, loss is 3.903824796676636 and perplexity is 49.591765245765494
At time: 436.5035083293915 and batch: 1300, loss is 3.8992714786529543 and perplexity is 49.36647147358814
At time: 437.5024735927582 and batch: 1350, loss is 3.7853421926498414 and perplexity is 44.050741820036315
At time: 438.49969506263733 and batch: 1400, loss is 3.7986653327941893 and perplexity is 44.64156308451673
At time: 439.4921224117279 and batch: 1450, loss is 3.7325419569015503 and perplexity is 41.78518943056037
At time: 440.49115204811096 and batch: 1500, loss is 3.734348874092102 and perplexity is 41.86076006202827
At time: 441.48996210098267 and batch: 1550, loss is 3.7608814096450804 and perplexity is 42.98629782351452
At time: 442.4860107898712 and batch: 1600, loss is 3.8291994619369505 and perplexity is 46.025678174986034
At time: 443.4819166660309 and batch: 1650, loss is 3.7913083362579347 and perplexity is 44.31434042344308
At time: 444.4810311794281 and batch: 1700, loss is 3.7698360013961794 and perplexity is 43.37295114911818
At time: 445.4786059856415 and batch: 1750, loss is 3.760816955566406 and perplexity is 42.98352727058036
At time: 446.4759044647217 and batch: 1800, loss is 3.7230201244354246 and perplexity is 41.38920609256341
At time: 447.4775140285492 and batch: 1850, loss is 3.764449315071106 and perplexity is 43.13994280114745
At time: 448.4796550273895 and batch: 1900, loss is 3.869497718811035 and perplexity is 47.91831156873018
At time: 449.47734665870667 and batch: 1950, loss is 3.8011522483825684 and perplexity is 44.752721046585215
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355726233194041 and perplexity of 77.92339534912628
finished 11 epochs...
Completing Train Step...
At time: 452.7426829338074 and batch: 50, loss is 3.957456612586975 and perplexity is 52.32407617129371
At time: 453.76380014419556 and batch: 100, loss is 3.9491117000579834 and perplexity is 51.88925313591375
At time: 454.758305311203 and batch: 150, loss is 3.897205562591553 and perplexity is 49.26458976304323
At time: 455.7576496601105 and batch: 200, loss is 3.8930263137817382 and perplexity is 49.059130416822164
At time: 456.75302743911743 and batch: 250, loss is 3.891603865623474 and perplexity is 48.989395955700765
At time: 457.7483003139496 and batch: 300, loss is 3.8975389766693116 and perplexity is 49.281018009357346
At time: 458.7422170639038 and batch: 350, loss is 3.9143857860565188 and perplexity is 50.11827870971414
At time: 459.73729276657104 and batch: 400, loss is 3.8630545854568483 and perplexity is 47.61056000403599
At time: 460.7320041656494 and batch: 450, loss is 3.890563645362854 and perplexity is 48.93846268897283
At time: 461.7330629825592 and batch: 500, loss is 3.915811176300049 and perplexity is 50.18976775299799
At time: 462.7260572910309 and batch: 550, loss is 3.8901686334609984 and perplexity is 48.919135231291385
At time: 463.7297172546387 and batch: 600, loss is 3.8402268648147584 and perplexity is 46.53603063029836
At time: 464.7224802970886 and batch: 650, loss is 3.8988874626159666 and perplexity is 49.34751759638212
At time: 465.7241048812866 and batch: 700, loss is 3.940264930725098 and perplexity is 51.43222547250418
At time: 466.7198541164398 and batch: 750, loss is 3.8826966667175293 and perplexity is 48.55497526954699
At time: 467.71636295318604 and batch: 800, loss is 3.875279927253723 and perplexity is 48.19618782946504
At time: 468.7121636867523 and batch: 850, loss is 3.89376492023468 and perplexity is 49.09537919226554
At time: 469.705206155777 and batch: 900, loss is 3.843716526031494 and perplexity is 46.698709293191975
At time: 470.69738388061523 and batch: 950, loss is 3.9292906951904296 and perplexity is 50.87088190806182
At time: 471.6959364414215 and batch: 1000, loss is 3.89787549495697 and perplexity is 49.297604763868506
At time: 472.7182807922363 and batch: 1050, loss is 3.8615756130218504 and perplexity is 47.54019734321881
At time: 473.7181658744812 and batch: 1100, loss is 3.8795552587509157 and perplexity is 48.40268361376699
At time: 474.7150514125824 and batch: 1150, loss is 3.854958596229553 and perplexity is 47.22666153894116
At time: 475.7073748111725 and batch: 1200, loss is 3.897474570274353 and perplexity is 49.27784409885864
At time: 476.70042514801025 and batch: 1250, loss is 3.8943855714797975 and perplexity is 49.12585975841295
At time: 477.6962893009186 and batch: 1300, loss is 3.890665988922119 and perplexity is 48.943471481733845
At time: 478.69262981414795 and batch: 1350, loss is 3.7766090536117556 and perplexity is 43.667715512366605
At time: 479.6873803138733 and batch: 1400, loss is 3.7905112409591677 and perplexity is 44.27903174508383
At time: 480.6905324459076 and batch: 1450, loss is 3.7248733758926393 and perplexity is 41.46598181945718
At time: 481.68632793426514 and batch: 1500, loss is 3.727176308631897 and perplexity is 41.561585228412184
At time: 482.6782808303833 and batch: 1550, loss is 3.754599905014038 and perplexity is 42.71712548338254
At time: 483.6748535633087 and batch: 1600, loss is 3.823750810623169 and perplexity is 45.775582264568484
At time: 484.66768622398376 and batch: 1650, loss is 3.785864839553833 and perplexity is 44.07377082136099
At time: 485.6608076095581 and batch: 1700, loss is 3.765862021446228 and perplexity is 43.200929941683285
At time: 486.6693284511566 and batch: 1750, loss is 3.7577886819839477 and perplexity is 42.85355828061813
At time: 487.65876173973083 and batch: 1800, loss is 3.7203728485107423 and perplexity is 41.27978234506313
At time: 488.6554388999939 and batch: 1850, loss is 3.7632182216644288 and perplexity is 43.08686617984333
At time: 489.65539932250977 and batch: 1900, loss is 3.8683167934417724 and perplexity is 47.86175701887028
At time: 490.6530282497406 and batch: 1950, loss is 3.7997803544998168 and perplexity is 44.69136715748029
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356006711028343 and perplexity of 77.94525419961349
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 493.90232729911804 and batch: 50, loss is 3.9573347091674806 and perplexity is 52.317698076250245
At time: 494.89616441726685 and batch: 100, loss is 3.9705593538284303 and perplexity is 53.01417623020731
At time: 495.89024591445923 and batch: 150, loss is 3.9277966356277467 and perplexity is 50.794934529566085
At time: 496.88416624069214 and batch: 200, loss is 3.933551993370056 and perplexity is 51.08812043487207
At time: 497.9207866191864 and batch: 250, loss is 3.9385124492645263 and perplexity is 51.342170383872336
At time: 498.91601157188416 and batch: 300, loss is 3.931670346260071 and perplexity is 50.99208100519526
At time: 499.9131712913513 and batch: 350, loss is 3.943424344062805 and perplexity is 51.59497809767575
At time: 500.9068579673767 and batch: 400, loss is 3.8885536289215086 and perplexity is 48.84019436790935
At time: 501.90189838409424 and batch: 450, loss is 3.9205020666122437 and perplexity is 50.425755511936316
At time: 502.8964982032776 and batch: 500, loss is 3.9434327936172484 and perplexity is 51.595414054094
At time: 503.89996004104614 and batch: 550, loss is 3.9249395990371703 and perplexity is 50.65001865654994
At time: 504.89911699295044 and batch: 600, loss is 3.8759298610687254 and perplexity is 48.22752234326665
At time: 505.8946759700775 and batch: 650, loss is 3.9254269886016844 and perplexity is 50.67471096398327
At time: 506.893456697464 and batch: 700, loss is 3.965582571029663 and perplexity is 52.75099163934717
At time: 507.88925218582153 and batch: 750, loss is 3.908070878982544 and perplexity is 49.802783646401615
At time: 508.8890299797058 and batch: 800, loss is 3.8971297979354858 and perplexity is 49.26085738973632
At time: 509.8882668018341 and batch: 850, loss is 3.9117886209487915 and perplexity is 49.988282149327084
At time: 510.8831651210785 and batch: 900, loss is 3.861536431312561 and perplexity is 47.53833467351847
At time: 511.882287979126 and batch: 950, loss is 3.9515516138076783 and perplexity is 52.01601301680426
At time: 512.8819501399994 and batch: 1000, loss is 3.912329549789429 and perplexity is 50.01532956754034
At time: 513.8774619102478 and batch: 1050, loss is 3.8751648807525636 and perplexity is 48.190643345628885
At time: 514.8761439323425 and batch: 1100, loss is 3.893711276054382 and perplexity is 49.092745581531936
At time: 515.8754575252533 and batch: 1150, loss is 3.874875044822693 and perplexity is 48.17667798963247
At time: 516.8748731613159 and batch: 1200, loss is 3.9111766958236696 and perplexity is 49.95770242072457
At time: 517.8743159770966 and batch: 1250, loss is 3.907148127555847 and perplexity is 49.756849253011254
At time: 518.8735284805298 and batch: 1300, loss is 3.896400685310364 and perplexity is 49.22495376717193
At time: 519.8729832172394 and batch: 1350, loss is 3.7795699310302733 and perplexity is 43.79720186715903
At time: 520.875251531601 and batch: 1400, loss is 3.794273509979248 and perplexity is 44.44593514533176
At time: 521.8749084472656 and batch: 1450, loss is 3.7202039623260497 and perplexity is 41.27281134878698
At time: 522.8742015361786 and batch: 1500, loss is 3.726290712356567 and perplexity is 41.52479473650291
At time: 523.874293088913 and batch: 1550, loss is 3.75166467666626 and perplexity is 42.591924801912356
At time: 524.8752336502075 and batch: 1600, loss is 3.8242605829238894 and perplexity is 45.798923337267006
At time: 525.8787398338318 and batch: 1650, loss is 3.7878112983703613 and perplexity is 44.15964214654114
At time: 526.8764090538025 and batch: 1700, loss is 3.76220871925354 and perplexity is 43.04339183197867
At time: 527.8749339580536 and batch: 1750, loss is 3.7508349990844727 and perplexity is 42.556601892078504
At time: 528.8739552497864 and batch: 1800, loss is 3.7076454877853395 and perplexity is 40.75772889287432
At time: 529.8738222122192 and batch: 1850, loss is 3.746127824783325 and perplexity is 42.35675128414633
At time: 530.8739833831787 and batch: 1900, loss is 3.8570523834228516 and perplexity is 47.32564770987966
At time: 531.8687236309052 and batch: 1950, loss is 3.7951100063323975 and perplexity is 44.4831295623214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343310546875 and perplexity of 76.96190405378412
finished 13 epochs...
Completing Train Step...
At time: 535.1420125961304 and batch: 50, loss is 3.967622718811035 and perplexity is 52.858721312766406
At time: 536.1643385887146 and batch: 100, loss is 3.9663382005691528 and perplexity is 52.790866910436286
At time: 537.1546673774719 and batch: 150, loss is 3.9158843660354616 and perplexity is 50.193441263250236
At time: 538.152735710144 and batch: 200, loss is 3.9152172660827635 and perplexity is 50.15996838707617
At time: 539.1467974185944 and batch: 250, loss is 3.917956175804138 and perplexity is 50.297540324672916
At time: 540.1368024349213 and batch: 300, loss is 3.9107635116577146 and perplexity is 49.9370649529479
At time: 541.1347413063049 and batch: 350, loss is 3.921477265357971 and perplexity is 50.47495463102444
At time: 542.1323184967041 and batch: 400, loss is 3.8655461645126343 and perplexity is 47.72933338336336
At time: 543.1313142776489 and batch: 450, loss is 3.897391185760498 and perplexity is 49.273735261093734
At time: 544.1233284473419 and batch: 500, loss is 3.922407684326172 and perplexity is 50.521939340575244
At time: 545.1202790737152 and batch: 550, loss is 3.9046070766448975 and perplexity is 49.630575068402216
At time: 546.1186473369598 and batch: 600, loss is 3.8575423765182495 and perplexity is 47.34884263270467
At time: 547.1196072101593 and batch: 650, loss is 3.9079823970794676 and perplexity is 49.7983771962745
At time: 548.1561689376831 and batch: 700, loss is 3.949624581336975 and perplexity is 51.91587298825645
At time: 549.1565115451813 and batch: 750, loss is 3.893149938583374 and perplexity is 49.0651957169914
At time: 550.1533105373383 and batch: 800, loss is 3.883598275184631 and perplexity is 48.59877258741936
At time: 551.149564743042 and batch: 850, loss is 3.898693799972534 and perplexity is 49.33796175101258
At time: 552.141881942749 and batch: 900, loss is 3.848680033683777 and perplexity is 46.9310748912783
At time: 553.1334898471832 and batch: 950, loss is 3.939227042198181 and perplexity is 51.37887224791171
At time: 554.13401222229 and batch: 1000, loss is 3.900145664215088 and perplexity is 49.409645798640156
At time: 555.1319799423218 and batch: 1050, loss is 3.86449059009552 and perplexity is 47.678978101647175
At time: 556.1322293281555 and batch: 1100, loss is 3.88350679397583 and perplexity is 48.594326916307594
At time: 557.1232900619507 and batch: 1150, loss is 3.866119818687439 and perplexity is 47.75672136958462
At time: 558.1154890060425 and batch: 1200, loss is 3.903310036659241 and perplexity is 49.566243957057985
At time: 559.1130526065826 and batch: 1250, loss is 3.900325722694397 and perplexity is 49.41854322533037
At time: 560.111661195755 and batch: 1300, loss is 3.8904714012145996 and perplexity is 48.93394861036707
At time: 561.1096131801605 and batch: 1350, loss is 3.774116315841675 and perplexity is 43.558998905866154
At time: 562.1027178764343 and batch: 1400, loss is 3.7906038188934326 and perplexity is 44.28313119613046
At time: 563.0952138900757 and batch: 1450, loss is 3.718577060699463 and perplexity is 41.20571913588334
At time: 564.0917236804962 and batch: 1500, loss is 3.7258092308044435 and perplexity is 41.50480612634124
At time: 565.0844740867615 and batch: 1550, loss is 3.7525116491317747 and perplexity is 42.628014270708604
At time: 566.0777413845062 and batch: 1600, loss is 3.8260826158523558 and perplexity is 45.88244655159249
At time: 567.0717718601227 and batch: 1650, loss is 3.7897544527053832 and perplexity is 44.245534570702986
At time: 568.0700769424438 and batch: 1700, loss is 3.7648871517181397 and perplexity is 43.15883518464384
At time: 569.0682246685028 and batch: 1750, loss is 3.754661259651184 and perplexity is 42.719746457520124
At time: 570.0681049823761 and batch: 1800, loss is 3.712333869934082 and perplexity is 40.94926534864338
At time: 571.0606405735016 and batch: 1850, loss is 3.7517425870895384 and perplexity is 42.595243286072495
At time: 572.0535864830017 and batch: 1900, loss is 3.862852220535278 and perplexity is 47.60092627159249
At time: 573.0510394573212 and batch: 1950, loss is 3.8005218172073363 and perplexity is 44.724516427530695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341796023346657 and perplexity of 76.8454316616612
finished 14 epochs...
Completing Train Step...
At time: 576.3104281425476 and batch: 50, loss is 3.964413628578186 and perplexity is 52.68936479199881
At time: 577.3314318656921 and batch: 100, loss is 3.9613605308532716 and perplexity is 52.52874433197307
At time: 578.3278453350067 and batch: 150, loss is 3.910208516120911 and perplexity is 49.90935779416386
At time: 579.3189775943756 and batch: 200, loss is 3.908615608215332 and perplexity is 49.82992006885831
At time: 580.3104455471039 and batch: 250, loss is 3.910644464492798 and perplexity is 49.93112044078667
At time: 581.3060371875763 and batch: 300, loss is 3.9032239580154418 and perplexity is 49.561977545626036
At time: 582.2976324558258 and batch: 350, loss is 3.9134760332107543 and perplexity is 50.07270419694782
At time: 583.2938888072968 and batch: 400, loss is 3.8569850301742554 and perplexity is 47.322460281107524
At time: 584.2954657077789 and batch: 450, loss is 3.8889786291122435 and perplexity is 48.860955871340195
At time: 585.2898194789886 and batch: 500, loss is 3.914423928260803 and perplexity is 50.12019036779626
At time: 586.2896957397461 and batch: 550, loss is 3.896613292694092 and perplexity is 49.235420468416066
At time: 587.2903263568878 and batch: 600, loss is 3.8502974033355715 and perplexity is 47.007041203777824
At time: 588.2870216369629 and batch: 650, loss is 3.9009284591674804 and perplexity is 49.44833856224505
At time: 589.279972076416 and batch: 700, loss is 3.943072910308838 and perplexity is 51.57684906660034
At time: 590.2724027633667 and batch: 750, loss is 3.8868543195724485 and perplexity is 48.75727024583267
At time: 591.2680926322937 and batch: 800, loss is 3.8775245475769045 and perplexity is 48.3044914769787
At time: 592.2665882110596 and batch: 850, loss is 3.8927583265304566 and perplexity is 49.045984956798016
At time: 593.2668778896332 and batch: 900, loss is 3.8429044914245605 and perplexity is 46.66080371754929
At time: 594.2587037086487 and batch: 950, loss is 3.9339193296432495 and perplexity is 51.10689040187088
At time: 595.2566318511963 and batch: 1000, loss is 3.8950054359436037 and perplexity is 49.15632057294402
At time: 596.257346868515 and batch: 1050, loss is 3.859944014549255 and perplexity is 47.462694074148
At time: 597.2505404949188 and batch: 1100, loss is 3.879200077056885 and perplexity is 48.385494919340914
At time: 598.2781846523285 and batch: 1150, loss is 3.8623462772369384 and perplexity is 47.57684899333301
At time: 599.2725343704224 and batch: 1200, loss is 3.8997823286056517 and perplexity is 49.391696775828905
At time: 600.2702012062073 and batch: 1250, loss is 3.8972241067886353 and perplexity is 49.26550334377577
At time: 601.2670159339905 and batch: 1300, loss is 3.8878770637512208 and perplexity is 48.80716196903524
At time: 602.2606153488159 and batch: 1350, loss is 3.771565523147583 and perplexity is 43.44803051853932
At time: 603.2520377635956 and batch: 1400, loss is 3.788715615272522 and perplexity is 44.199594519407945
At time: 604.2487878799438 and batch: 1450, loss is 3.7172757959365845 and perplexity is 41.15213445703116
At time: 605.2477951049805 and batch: 1500, loss is 3.7248035001754762 and perplexity is 41.46308445546854
At time: 606.2399599552155 and batch: 1550, loss is 3.752055492401123 and perplexity is 42.60857364940692
At time: 607.2304480075836 and batch: 1600, loss is 3.8259479284286497 and perplexity is 45.876267179224335
At time: 608.2276074886322 and batch: 1650, loss is 3.789569363594055 and perplexity is 44.237345961863596
At time: 609.2269961833954 and batch: 1700, loss is 3.765071725845337 and perplexity is 43.16680192418328
At time: 610.2196340560913 and batch: 1750, loss is 3.7554583406448363 and perplexity is 42.75381112982293
At time: 611.2126984596252 and batch: 1800, loss is 3.71349488735199 and perplexity is 40.9968357686632
At time: 612.2079939842224 and batch: 1850, loss is 3.7531558084487915 and perplexity is 42.65548234922655
At time: 613.2045221328735 and batch: 1900, loss is 3.86422562122345 and perplexity is 47.66634633018515
At time: 614.2003183364868 and batch: 1950, loss is 3.8016722440719604 and perplexity is 44.77599832013445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341375874364099 and perplexity of 76.81315191336088
finished 15 epochs...
Completing Train Step...
At time: 617.5008671283722 and batch: 50, loss is 3.9604324865341187 and perplexity is 52.48001794282507
At time: 618.4930050373077 and batch: 100, loss is 3.956717486381531 and perplexity is 52.28541636441805
At time: 619.4896488189697 and batch: 150, loss is 3.9053661823272705 and perplexity is 49.66826422317202
At time: 620.4844672679901 and batch: 200, loss is 3.903550958633423 and perplexity is 49.57818699301704
At time: 621.4877581596375 and batch: 250, loss is 3.905231685638428 and perplexity is 49.661584455306844
At time: 622.4855380058289 and batch: 300, loss is 3.8976801013946534 and perplexity is 49.28797327025658
At time: 623.4998753070831 and batch: 350, loss is 3.9077258634567262 and perplexity is 49.785603876628734
At time: 624.4890201091766 and batch: 400, loss is 3.8510130882263183 and perplexity is 47.04069547441609
At time: 625.4849216938019 and batch: 450, loss is 3.883211054801941 and perplexity is 48.57995779507042
At time: 626.4776136875153 and batch: 500, loss is 3.9089174938201903 and perplexity is 49.844965275269686
At time: 627.4697830677032 and batch: 550, loss is 3.8911608600616456 and perplexity is 48.96769818729267
At time: 628.4687077999115 and batch: 600, loss is 3.8452976322174073 and perplexity is 46.77260331308163
At time: 629.4682416915894 and batch: 650, loss is 3.8960506439208986 and perplexity is 49.20772601134861
At time: 630.4711501598358 and batch: 700, loss is 3.938425211906433 and perplexity is 51.3376916239297
At time: 631.4674611091614 and batch: 750, loss is 3.8823075914382934 and perplexity is 48.536087403624826
At time: 632.4682803153992 and batch: 800, loss is 3.873114743232727 and perplexity is 48.09194710460323
At time: 633.4663496017456 and batch: 850, loss is 3.888466410636902 and perplexity is 48.83593479569572
At time: 634.4659607410431 and batch: 900, loss is 3.8387029647827147 and perplexity is 46.465168378936674
At time: 635.4615023136139 and batch: 950, loss is 3.9301002168655397 and perplexity is 50.91207966258616
At time: 636.4522366523743 and batch: 1000, loss is 3.8912770700454713 and perplexity is 48.973389053368315
At time: 637.4485545158386 and batch: 1050, loss is 3.856609501838684 and perplexity is 47.30469269268828
At time: 638.446329832077 and batch: 1100, loss is 3.876014385223389 and perplexity is 48.23159890610581
At time: 639.4456312656403 and batch: 1150, loss is 3.8594107151031496 and perplexity is 47.43738899387996
At time: 640.438018321991 and batch: 1200, loss is 3.8969238710403444 and perplexity is 49.25071429872552
At time: 641.4293878078461 and batch: 1250, loss is 3.894644684791565 and perplexity is 49.13859057191877
At time: 642.4265284538269 and batch: 1300, loss is 3.8856442165374756 and perplexity is 48.698304609574414
At time: 643.4248530864716 and batch: 1350, loss is 3.7693339681625364 and perplexity is 43.35118195108781
At time: 644.4174275398254 and batch: 1400, loss is 3.7868611669540404 and perplexity is 44.11770460944491
At time: 645.4100461006165 and batch: 1450, loss is 3.715693130493164 and perplexity is 41.08705590827237
At time: 646.4063091278076 and batch: 1500, loss is 3.7233875513076784 and perplexity is 41.40441639326856
At time: 647.406023979187 and batch: 1550, loss is 3.7509210729599 and perplexity is 42.56026506137769
At time: 648.4029002189636 and batch: 1600, loss is 3.8250408411026 and perplexity is 45.83467226666065
At time: 649.3955810070038 and batch: 1650, loss is 3.788584899902344 and perplexity is 44.19381733064052
At time: 650.3886806964874 and batch: 1700, loss is 3.7643434047698974 and perplexity is 43.13537407875291
At time: 651.3849194049835 and batch: 1750, loss is 3.7551559019088745 and perplexity is 42.74088267635838
At time: 652.3807306289673 and batch: 1800, loss is 3.7134249019622803 and perplexity is 40.993966689533046
At time: 653.3729135990143 and batch: 1850, loss is 3.753235921859741 and perplexity is 42.65889976230173
At time: 654.3664367198944 and batch: 1900, loss is 3.8643315553665163 and perplexity is 47.67139609120308
At time: 655.3641920089722 and batch: 1950, loss is 3.8016064405441283 and perplexity is 44.77305199842303
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341347485919331 and perplexity of 76.8109713383921
finished 16 epochs...
Completing Train Step...
At time: 658.637847661972 and batch: 50, loss is 3.9565723276138307 and perplexity is 52.277827228638024
At time: 659.6590223312378 and batch: 100, loss is 3.9525111532211303 and perplexity is 52.06594838507015
At time: 660.6546428203583 and batch: 150, loss is 3.9010611629486083 and perplexity is 49.454900979161884
At time: 661.6523010730743 and batch: 200, loss is 3.8991920518875123 and perplexity is 49.36255061015052
At time: 662.6473767757416 and batch: 250, loss is 3.9006461095809937 and perplexity is 49.43437881515669
At time: 663.6432814598083 and batch: 300, loss is 3.8930286407470702 and perplexity is 49.059244575850684
At time: 664.6493062973022 and batch: 350, loss is 3.902920894622803 and perplexity is 49.546959400405136
At time: 665.6462779045105 and batch: 400, loss is 3.8461013650894165 and perplexity is 46.810211103157854
At time: 666.6410281658173 and batch: 450, loss is 3.8785067272186278 and perplexity is 48.35195847185333
At time: 667.6376748085022 and batch: 500, loss is 3.9044089460372926 and perplexity is 49.62074270648622
At time: 668.6320035457611 and batch: 550, loss is 3.886729111671448 and perplexity is 48.75116583253504
At time: 669.6250066757202 and batch: 600, loss is 3.8412065076828004 and perplexity is 46.581641658423784
At time: 670.6247248649597 and batch: 650, loss is 3.89205783367157 and perplexity is 49.01164062496267
At time: 671.6217188835144 and batch: 700, loss is 3.934557776451111 and perplexity is 51.139529851075054
At time: 672.615466594696 and batch: 750, loss is 3.8784752607345583 and perplexity is 48.350437029659695
At time: 673.6354374885559 and batch: 800, loss is 3.8694045114517213 and perplexity is 47.91384543758746
At time: 674.6410727500916 and batch: 850, loss is 3.884859538078308 and perplexity is 48.660107087295685
At time: 675.6425979137421 and batch: 900, loss is 3.8351726150512695 and perplexity is 46.301419300058924
At time: 676.6412343978882 and batch: 950, loss is 3.926867437362671 and perplexity is 50.747757886148584
At time: 677.6369462013245 and batch: 1000, loss is 3.888090901374817 and perplexity is 48.81759989253578
At time: 678.6329987049103 and batch: 1050, loss is 3.853733205795288 and perplexity is 47.16882588251622
At time: 679.635666847229 and batch: 1100, loss is 3.873232889175415 and perplexity is 48.09762930868766
At time: 680.6313750743866 and batch: 1150, loss is 3.8567785596847535 and perplexity is 47.31269059817917
At time: 681.6268827915192 and batch: 1200, loss is 3.89431254863739 and perplexity is 49.12227257947227
At time: 682.6301374435425 and batch: 1250, loss is 3.892235794067383 and perplexity is 49.02036353207072
At time: 683.6320900917053 and batch: 1300, loss is 3.883499002456665 and perplexity is 48.593948294153144
At time: 684.6406357288361 and batch: 1350, loss is 3.7671795082092285 and perplexity is 43.257884104970586
At time: 685.6382038593292 and batch: 1400, loss is 3.7849754190444944 and perplexity is 44.03458813319484
At time: 686.6390836238861 and batch: 1450, loss is 3.7139710664749144 and perplexity is 41.01636225464572
At time: 687.6382896900177 and batch: 1500, loss is 3.7217841005325316 and perplexity is 41.338079647774215
At time: 688.6366045475006 and batch: 1550, loss is 3.7494795894622803 and perplexity is 42.49895933784726
At time: 689.6331939697266 and batch: 1600, loss is 3.8237959432601927 and perplexity is 45.77764828392947
At time: 690.6297056674957 and batch: 1650, loss is 3.787262454032898 and perplexity is 44.13541202689483
At time: 691.6287643909454 and batch: 1700, loss is 3.7632174348831176 and perplexity is 43.08683227991559
At time: 692.6262407302856 and batch: 1750, loss is 3.754360499382019 and perplexity is 42.70689998702769
At time: 693.6229629516602 and batch: 1800, loss is 3.712789855003357 and perplexity is 40.96794186002169
At time: 694.6268699169159 and batch: 1850, loss is 3.75272234916687 and perplexity is 42.63699694110274
At time: 695.6231074333191 and batch: 1900, loss is 3.8638958501815797 and perplexity is 47.65062994104114
At time: 696.6271538734436 and batch: 1950, loss is 3.801037082672119 and perplexity is 44.74756736444077
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341480343840843 and perplexity of 76.82117696232736
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 699.9290525913239 and batch: 50, loss is 3.9576773595809938 and perplexity is 52.33562782877326
At time: 701.0537397861481 and batch: 100, loss is 3.9615728425979615 and perplexity is 52.539897985312464
At time: 702.0445754528046 and batch: 150, loss is 3.914298405647278 and perplexity is 50.11389954533942
At time: 703.0423865318298 and batch: 200, loss is 3.916223196983337 and perplexity is 50.21045123612048
At time: 704.0367906093597 and batch: 250, loss is 3.923324818611145 and perplexity is 50.56829599767825
At time: 705.0299913883209 and batch: 300, loss is 3.913042469024658 and perplexity is 50.05099917130793
At time: 706.0229570865631 and batch: 350, loss is 3.922337212562561 and perplexity is 50.518379095858705
At time: 707.0206518173218 and batch: 400, loss is 3.8594049215316772 and perplexity is 47.437114162772495
At time: 708.0137195587158 and batch: 450, loss is 3.894842391014099 and perplexity is 49.14830653746317
At time: 709.0065319538116 and batch: 500, loss is 3.9168459939956666 and perplexity is 50.24173189487737
At time: 710.0028476715088 and batch: 550, loss is 3.8987473678588866 and perplexity is 49.34060475212988
At time: 711.0003402233124 and batch: 600, loss is 3.85703763961792 and perplexity is 47.32494995490536
At time: 711.9997224807739 and batch: 650, loss is 3.906537356376648 and perplexity is 49.72646848231377
At time: 712.9927506446838 and batch: 700, loss is 3.945245428085327 and perplexity is 51.68902249331463
At time: 713.9848914146423 and batch: 750, loss is 3.887506594657898 and perplexity is 48.78908377290615
At time: 714.980694770813 and batch: 800, loss is 3.8783115005493163 and perplexity is 48.34251980141626
At time: 715.9731950759888 and batch: 850, loss is 3.8937511157989504 and perplexity is 49.094701462936705
At time: 716.9658424854279 and batch: 900, loss is 3.839711594581604 and perplexity is 46.51205817562196
At time: 717.962055683136 and batch: 950, loss is 3.9337327766418455 and perplexity is 51.09735714733025
At time: 718.9604742527008 and batch: 1000, loss is 3.8947703218460084 and perplexity is 49.14476458753218
At time: 719.9601972103119 and batch: 1050, loss is 3.859947762489319 and perplexity is 47.462871961814
At time: 720.9525713920593 and batch: 1100, loss is 3.8773012733459473 and perplexity is 48.29370753272563
At time: 721.9463860988617 and batch: 1150, loss is 3.8663049602508544 and perplexity is 47.765563942181174
At time: 722.9426114559174 and batch: 1200, loss is 3.9042174243927 and perplexity is 49.611240170236904
At time: 723.9856915473938 and batch: 1250, loss is 3.900937070846558 and perplexity is 49.44876439730123
At time: 724.9805009365082 and batch: 1300, loss is 3.8903311920166015 and perplexity is 48.927088101641985
At time: 725.9758813381195 and batch: 1350, loss is 3.7704919242858885 and perplexity is 43.40140979288873
At time: 726.9721069335938 and batch: 1400, loss is 3.787818078994751 and perplexity is 44.15994157750288
At time: 727.9655401706696 and batch: 1450, loss is 3.710518727302551 and perplexity is 40.87500400923003
At time: 728.9607350826263 and batch: 1500, loss is 3.7155469465255737 and perplexity is 41.0810500784118
At time: 729.95973944664 and batch: 1550, loss is 3.743533926010132 and perplexity is 42.2470245305227
At time: 730.9600963592529 and batch: 1600, loss is 3.8178939485549925 and perplexity is 45.508264578707404
At time: 731.9523570537567 and batch: 1650, loss is 3.7815367221832275 and perplexity is 43.883426581523175
At time: 732.9443864822388 and batch: 1700, loss is 3.755827617645264 and perplexity is 42.76960204438513
At time: 733.9406008720398 and batch: 1750, loss is 3.748299250602722 and perplexity is 42.44882575777688
At time: 734.9401197433472 and batch: 1800, loss is 3.705438747406006 and perplexity is 40.66788633281789
At time: 735.9337337017059 and batch: 1850, loss is 3.7417803764343263 and perplexity is 42.17300719407916
At time: 736.9257943630219 and batch: 1900, loss is 3.8539843463897707 and perplexity is 47.18067337712055
At time: 737.9191884994507 and batch: 1950, loss is 3.7934784936904906 and perplexity is 44.41061394524726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337575513263081 and perplexity of 76.52178819313133
finished 18 epochs...
Completing Train Step...
At time: 741.2211978435516 and batch: 50, loss is 3.956759629249573 and perplexity is 52.28761986825107
At time: 742.218145608902 and batch: 100, loss is 3.9555935430526734 and perplexity is 52.226683531869234
At time: 743.2108309268951 and batch: 150, loss is 3.9066769456863404 and perplexity is 49.73341025020968
At time: 744.2034418582916 and batch: 200, loss is 3.905963544845581 and perplexity is 49.697943046194155
At time: 745.1992671489716 and batch: 250, loss is 3.9109633588790893 and perplexity is 49.9470457339048
At time: 746.198976278305 and batch: 300, loss is 3.902440366744995 and perplexity is 49.52315642460738
At time: 747.1926558017731 and batch: 350, loss is 3.9125709915161133 and perplexity is 50.02740681298865
At time: 748.1847071647644 and batch: 400, loss is 3.8515957307815554 and perplexity is 47.06811137148602
At time: 749.2051486968994 and batch: 450, loss is 3.8860440111160277 and perplexity is 48.71777782012463
At time: 750.1993892192841 and batch: 500, loss is 3.910233988761902 and perplexity is 49.91062913350916
At time: 751.1920528411865 and batch: 550, loss is 3.892913889884949 and perplexity is 49.053615308228416
At time: 752.1843535900116 and batch: 600, loss is 3.851074080467224 and perplexity is 47.04356467934558
At time: 753.1774089336395 and batch: 650, loss is 3.8993983459472656 and perplexity is 49.37273486155483
At time: 754.1702332496643 and batch: 700, loss is 3.9388746500015257 and perplexity is 51.36076992400476
At time: 755.1603252887726 and batch: 750, loss is 3.8819253206253053 and perplexity is 48.51753701989481
At time: 756.1602420806885 and batch: 800, loss is 3.872914276123047 and perplexity is 48.08230721724073
At time: 757.1562502384186 and batch: 850, loss is 3.88817578792572 and perplexity is 48.82174402610214
At time: 758.1458578109741 and batch: 900, loss is 3.8355404806137083 and perplexity is 46.3184551309671
At time: 759.1447596549988 and batch: 950, loss is 3.929895825386047 and perplexity is 50.90167473067582
At time: 760.1388890743256 and batch: 1000, loss is 3.890791583061218 and perplexity is 48.949618880929684
At time: 761.1457116603851 and batch: 1050, loss is 3.8556336879730226 and perplexity is 47.25855463238849
At time: 762.1450669765472 and batch: 1100, loss is 3.8735905647277833 and perplexity is 48.114835731793264
At time: 763.14346575737 and batch: 1150, loss is 3.862644853591919 and perplexity is 47.591056436384626
At time: 764.1377394199371 and batch: 1200, loss is 3.9006771993637086 and perplexity is 49.43591574314395
At time: 765.1321482658386 and batch: 1250, loss is 3.897344608306885 and perplexity is 49.27144026942311
At time: 766.1250534057617 and batch: 1300, loss is 3.8870799207687377 and perplexity is 48.768271185193804
At time: 767.1193311214447 and batch: 1350, loss is 3.7677353382110597 and perplexity is 43.28193481820666
At time: 768.1173920631409 and batch: 1400, loss is 3.785732488632202 and perplexity is 44.06793800317099
At time: 769.117356300354 and batch: 1450, loss is 3.7102566003799438 and perplexity is 40.864290974366305
At time: 770.111501455307 and batch: 1500, loss is 3.7167461681365968 and perplexity is 41.130344913277284
At time: 771.1047894954681 and batch: 1550, loss is 3.7454814815521242 and perplexity is 42.32938313022145
At time: 772.0987501144409 and batch: 1600, loss is 3.820630979537964 and perplexity is 45.63299272337374
At time: 773.0963342189789 and batch: 1650, loss is 3.784388585090637 and perplexity is 44.00875472243681
At time: 774.0959365367889 and batch: 1700, loss is 3.7591489934921265 and perplexity is 42.91189213622591
At time: 775.0939462184906 and batch: 1750, loss is 3.7519867849349975 and perplexity is 42.60564622284544
At time: 776.0976655483246 and batch: 1800, loss is 3.709182734489441 and perplexity is 40.820431759821425
At time: 777.0958979129791 and batch: 1850, loss is 3.7454404783248902 and perplexity is 42.32764752448925
At time: 778.0913848876953 and batch: 1900, loss is 3.857674407958984 and perplexity is 47.355094581332395
At time: 779.0938985347748 and batch: 1950, loss is 3.796565637588501 and perplexity is 44.54792774577066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336663108648255 and perplexity of 76.45200120227682
finished 19 epochs...
Completing Train Step...
At time: 782.3106670379639 and batch: 50, loss is 3.9561357164382933 and perplexity is 52.255007127155366
At time: 783.3304619789124 and batch: 100, loss is 3.953364381790161 and perplexity is 52.110391497076186
At time: 784.324214220047 and batch: 150, loss is 3.9036548709869385 and perplexity is 49.583339046786904
At time: 785.3178520202637 and batch: 200, loss is 3.9021127223968506 and perplexity is 49.506933100187986
At time: 786.3155381679535 and batch: 250, loss is 3.906741404533386 and perplexity is 49.736616111816026
At time: 787.3098530769348 and batch: 300, loss is 3.898579993247986 and perplexity is 49.3323470786896
At time: 788.3044323921204 and batch: 350, loss is 3.9090339756011963 and perplexity is 49.85077164376064
At time: 789.2997980117798 and batch: 400, loss is 3.848153281211853 and perplexity is 46.906360341365854
At time: 790.2971215248108 and batch: 450, loss is 3.8825196170806886 and perplexity is 48.54637938977986
At time: 791.2949934005737 and batch: 500, loss is 3.90724555015564 and perplexity is 49.761696930755825
At time: 792.2900807857513 and batch: 550, loss is 3.8900969982147218 and perplexity is 48.91563102250538
At time: 793.2836630344391 and batch: 600, loss is 3.84824077129364 and perplexity is 46.91046436219641
At time: 794.2783796787262 and batch: 650, loss is 3.8962642192840575 and perplexity is 49.218236691672935
At time: 795.2761979103088 and batch: 700, loss is 3.936051230430603 and perplexity is 51.21596144476826
At time: 796.2732694149017 and batch: 750, loss is 3.87939395904541 and perplexity is 48.39487690478126
At time: 797.267991065979 and batch: 800, loss is 3.8704497241973876 and perplexity is 47.96395178086539
At time: 798.2629683017731 and batch: 850, loss is 3.885667600631714 and perplexity is 48.699443388633256
At time: 799.3041756153107 and batch: 900, loss is 3.8333731508255005 and perplexity is 46.218176471134676
At time: 800.2985672950745 and batch: 950, loss is 3.927974739074707 and perplexity is 50.8039820881707
At time: 801.2971549034119 and batch: 1000, loss is 3.8887763452529907 and perplexity is 48.85107308821721
At time: 802.2917740345001 and batch: 1050, loss is 3.853709216117859 and perplexity is 47.16769433117142
At time: 803.2880237102509 and batch: 1100, loss is 3.8719178009033204 and perplexity is 48.03441825363691
At time: 804.2968096733093 and batch: 1150, loss is 3.8610220909118653 and perplexity is 47.513890074375446
At time: 805.2957813739777 and batch: 1200, loss is 3.8992051172256468 and perplexity is 49.363195552778606
At time: 806.301148891449 and batch: 1250, loss is 3.895969104766846 and perplexity is 49.203713818574414
At time: 807.3109867572784 and batch: 1300, loss is 3.8859507036209107 and perplexity is 48.713232298377484
At time: 808.3210108280182 and batch: 1350, loss is 3.7668103885650637 and perplexity is 43.24191971674835
At time: 809.3211851119995 and batch: 1400, loss is 3.7850873184204104 and perplexity is 44.03951585182484
At time: 810.3187141418457 and batch: 1450, loss is 3.710364499092102 and perplexity is 40.86870041661799
At time: 811.3161940574646 and batch: 1500, loss is 3.7174609088897705 and perplexity is 41.15975295529001
At time: 812.3158288002014 and batch: 1550, loss is 3.7465208387374878 and perplexity is 42.37340135009381
At time: 813.3125824928284 and batch: 1600, loss is 3.8219374656677245 and perplexity is 45.692650558007166
At time: 814.3092765808105 and batch: 1650, loss is 3.7856071186065674 and perplexity is 44.06241355096145
At time: 815.3054213523865 and batch: 1700, loss is 3.7604785490036012 and perplexity is 42.9689838237972
At time: 816.3081774711609 and batch: 1750, loss is 3.7534544801712038 and perplexity is 42.668224238336386
At time: 817.3087801933289 and batch: 1800, loss is 3.7106067609786986 and perplexity is 40.878602544489326
At time: 818.3059661388397 and batch: 1850, loss is 3.746884799003601 and perplexity is 42.388826391406106
At time: 819.3015856742859 and batch: 1900, loss is 3.8590510082244873 and perplexity is 47.42032850732423
At time: 820.2981128692627 and batch: 1950, loss is 3.797665863037109 and perplexity is 44.59696748199535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336295762172965 and perplexity of 76.42392198682246
Finished Training.
Improved accuracyfrom -10000000 to -76.42392198682246
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fcae8787b38>
ELAPSED
851.6719098091125


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.42392198682246}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.7974071334468391, 'wordvec_source': 'gigavec', 'dropout': 0.589069126925909, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.457517147064209 and batch: 50, loss is 7.468115177154541 and perplexity is 1751.3026775224491
At time: 2.4490089416503906 and batch: 100, loss is 6.664204196929932 and perplexity is 783.8394348826563
At time: 3.4675304889678955 and batch: 150, loss is 6.39237756729126 and perplexity is 597.2749542745246
At time: 4.459108114242554 and batch: 200, loss is 6.28043911933899 and perplexity is 534.0231122224258
At time: 5.451125383377075 and batch: 250, loss is 6.198183469772339 and perplexity is 491.8547600556386
At time: 6.441918611526489 and batch: 300, loss is 6.10984314918518 and perplexity is 450.26808471256896
At time: 7.433446407318115 and batch: 350, loss is 6.051217527389526 and perplexity is 424.62971374955333
At time: 8.425106525421143 and batch: 400, loss is 5.996302127838135 and perplexity is 401.9397202859932
At time: 9.416643857955933 and batch: 450, loss is 5.9001023483276365 and perplexity is 365.0748307516713
At time: 10.408748388290405 and batch: 500, loss is 5.8906396293640135 and perplexity is 361.6365237503445
At time: 11.400310516357422 and batch: 550, loss is 5.832899408340454 and perplexity is 341.34694987256614
At time: 12.391857147216797 and batch: 600, loss is 5.867280712127686 and perplexity is 353.28698387729474
At time: 13.382645606994629 and batch: 650, loss is 5.934317111968994 and perplexity is 377.78192530979686
At time: 14.374155759811401 and batch: 700, loss is 5.848768424987793 and perplexity is 346.80699852284687
At time: 15.365974426269531 and batch: 750, loss is 5.7758252143859865 and perplexity is 322.410382657312
At time: 16.35667872428894 and batch: 800, loss is 5.786666460037232 and perplexity is 325.9247283378415
At time: 17.34786629676819 and batch: 850, loss is 5.806609182357788 and perplexity is 332.4897998085351
At time: 18.339208602905273 and batch: 900, loss is 5.789187955856323 and perplexity is 326.7475831542016
At time: 19.33251976966858 and batch: 950, loss is 5.808640832901001 and perplexity is 333.16598954896864
At time: 20.324718952178955 and batch: 1000, loss is 5.775492830276489 and perplexity is 322.3032363772267
At time: 21.316043615341187 and batch: 1050, loss is 5.681409521102905 and perplexity is 293.36263947148797
At time: 22.3067786693573 and batch: 1100, loss is 5.756974048614502 and perplexity is 316.38949971916435
At time: 23.29586958885193 and batch: 1150, loss is 5.66257646560669 and perplexity is 287.8894250481271
At time: 24.28798532485962 and batch: 1200, loss is 5.73993613243103 and perplexity is 311.044544688083
At time: 25.28028178215027 and batch: 1250, loss is 5.680220642089844 and perplexity is 293.01407402833024
At time: 26.272993326187134 and batch: 1300, loss is 5.687432136535644 and perplexity is 295.1347809380564
At time: 27.26404333114624 and batch: 1350, loss is 5.65410906791687 and perplexity is 285.46204210685903
At time: 28.25583267211914 and batch: 1400, loss is 5.665187339782715 and perplexity is 288.64205019077804
At time: 29.248030424118042 and batch: 1450, loss is 5.6438758850097654 and perplexity is 282.5557524753341
At time: 30.24255633354187 and batch: 1500, loss is 5.603862924575806 and perplexity is 271.47306451851415
At time: 31.23355770111084 and batch: 1550, loss is 5.58774055480957 and perplexity is 267.13136864852294
At time: 32.22495245933533 and batch: 1600, loss is 5.602215003967285 and perplexity is 271.0260668703113
At time: 33.215877294540405 and batch: 1650, loss is 5.601331472396851 and perplexity is 270.7867125379458
At time: 34.20740008354187 and batch: 1700, loss is 5.618622465133667 and perplexity is 275.50959763413545
At time: 35.198864221572876 and batch: 1750, loss is 5.612427911758423 and perplexity is 273.80821382313775
At time: 36.19304704666138 and batch: 1800, loss is 5.611449594497681 and perplexity is 273.540473510261
At time: 37.186585664749146 and batch: 1850, loss is 5.5740651035308835 and perplexity is 263.5030923354295
At time: 38.18080997467041 and batch: 1900, loss is 5.596482095718383 and perplexity is 269.4767446004573
At time: 39.1766791343689 and batch: 1950, loss is 5.526179027557373 and perplexity is 251.18231437499193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.008736827761628 and perplexity of 149.7155001919087
finished 1 epochs...
Completing Train Step...
At time: 42.570823669433594 and batch: 50, loss is 5.290742311477661 and perplexity is 198.4907126703301
At time: 43.58328628540039 and batch: 100, loss is 5.204326314926147 and perplexity is 182.0581815663112
At time: 44.59824728965759 and batch: 150, loss is 5.115541591644287 and perplexity is 166.5909808386056
At time: 45.60945272445679 and batch: 200, loss is 5.075053663253784 and perplexity is 159.98077683806673
At time: 46.61306285858154 and batch: 250, loss is 5.0914214324951175 and perplexity is 162.62085240999662
At time: 47.619024991989136 and batch: 300, loss is 5.0994906330108645 and perplexity is 163.9383812293456
At time: 48.63074851036072 and batch: 350, loss is 5.089127702713013 and perplexity is 162.24827158085628
At time: 49.63078856468201 and batch: 400, loss is 5.042552537918091 and perplexity is 154.86480924570535
At time: 50.62059807777405 and batch: 450, loss is 5.0064569854736325 and perplexity is 149.37456125458053
At time: 51.60896110534668 and batch: 500, loss is 5.002920780181885 and perplexity is 148.8472749863307
At time: 52.60033321380615 and batch: 550, loss is 4.959899854660034 and perplexity is 142.57951650784108
At time: 53.59060573577881 and batch: 600, loss is 4.9286384010314945 and perplexity is 138.19122315496622
At time: 54.58392643928528 and batch: 650, loss is 5.002007293701172 and perplexity is 148.71136709740003
At time: 55.64589476585388 and batch: 700, loss is 5.003199272155761 and perplexity is 148.8887335304157
At time: 56.64336037635803 and batch: 750, loss is 4.94464596748352 and perplexity is 140.42112840482798
At time: 57.642345666885376 and batch: 800, loss is 4.946173639297485 and perplexity is 140.63580974434123
At time: 58.63739609718323 and batch: 850, loss is 4.951057071685791 and perplexity is 141.32427488087126
At time: 59.63521432876587 and batch: 900, loss is 4.940183048248291 and perplexity is 139.79583660110816
At time: 60.629873514175415 and batch: 950, loss is 4.983557081222534 and perplexity is 145.9927672682308
At time: 61.627686500549316 and batch: 1000, loss is 4.948041419982911 and perplexity is 140.89873205763416
At time: 62.624515771865845 and batch: 1050, loss is 4.864155225753784 and perplexity is 129.56144219877376
At time: 63.618674755096436 and batch: 1100, loss is 4.931645040512085 and perplexity is 138.60733958494828
At time: 64.61474585533142 and batch: 1150, loss is 4.861171655654907 and perplexity is 129.1754626387217
At time: 65.6058738231659 and batch: 1200, loss is 4.930697002410889 and perplexity is 138.47599681472886
At time: 66.59891891479492 and batch: 1250, loss is 4.90469066619873 and perplexity is 134.92116787328706
At time: 67.59204983711243 and batch: 1300, loss is 4.905795412063599 and perplexity is 135.0703038390811
At time: 68.59472799301147 and batch: 1350, loss is 4.809883165359497 and perplexity is 122.7172790504853
At time: 69.59246945381165 and batch: 1400, loss is 4.816567869186401 and perplexity is 123.54035566212174
At time: 70.58350777626038 and batch: 1450, loss is 4.771326627731323 and perplexity is 118.07578070847597
At time: 71.57759308815002 and batch: 1500, loss is 4.748096122741699 and perplexity is 115.36443558556753
At time: 72.56943774223328 and batch: 1550, loss is 4.750356712341309 and perplexity is 115.62552222249998
At time: 73.56465077400208 and batch: 1600, loss is 4.814269151687622 and perplexity is 123.25669743472788
At time: 74.56628060340881 and batch: 1650, loss is 4.788171873092652 and perplexity is 120.08164339820037
At time: 75.56731414794922 and batch: 1700, loss is 4.793573484420777 and perplexity is 120.73203275735631
At time: 76.56561613082886 and batch: 1750, loss is 4.794150333404541 and perplexity is 120.8016969987019
At time: 77.5649254322052 and batch: 1800, loss is 4.744132251739502 and perplexity is 114.90805096711236
At time: 78.5594961643219 and batch: 1850, loss is 4.771019363403321 and perplexity is 118.03950580634033
At time: 79.55221462249756 and batch: 1900, loss is 4.862803859710693 and perplexity is 129.38647551393765
At time: 80.54546523094177 and batch: 1950, loss is 4.783638534545898 and perplexity is 119.53850470139814
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6335193722747094 and perplexity of 102.87548487956299
finished 2 epochs...
Completing Train Step...
At time: 83.87755870819092 and batch: 50, loss is 4.740045509338379 and perplexity is 114.43940962346919
At time: 84.91214084625244 and batch: 100, loss is 4.68574649810791 and perplexity is 108.39115590749995
At time: 85.91987442970276 and batch: 150, loss is 4.629082431793213 and perplexity is 102.42004360622649
At time: 86.93094611167908 and batch: 200, loss is 4.614563274383545 and perplexity is 100.94373419007589
At time: 87.92245507240295 and batch: 250, loss is 4.622728261947632 and perplexity is 101.77131251007923
At time: 88.91360998153687 and batch: 300, loss is 4.64653021812439 and perplexity is 104.22272733169208
At time: 89.90393996238708 and batch: 350, loss is 4.646911106109619 and perplexity is 104.26243207737082
At time: 90.89988660812378 and batch: 400, loss is 4.589617366790772 and perplexity is 98.45675013131758
At time: 91.89226722717285 and batch: 450, loss is 4.591762495040894 and perplexity is 98.66817917757395
At time: 92.88433694839478 and batch: 500, loss is 4.604544506072998 and perplexity is 99.93745157817685
At time: 93.87761497497559 and batch: 550, loss is 4.569058122634888 and perplexity is 96.45321987140446
At time: 94.86986517906189 and batch: 600, loss is 4.539647979736328 and perplexity is 93.65782486363193
At time: 95.86224913597107 and batch: 650, loss is 4.6124684715271 and perplexity is 100.7324982933796
At time: 96.85575985908508 and batch: 700, loss is 4.634890241622925 and perplexity is 103.01661043871758
At time: 97.84997057914734 and batch: 750, loss is 4.58534405708313 and perplexity is 98.03691163405679
At time: 98.8431944847107 and batch: 800, loss is 4.580417308807373 and perplexity is 97.55509631468558
At time: 99.83575654029846 and batch: 850, loss is 4.5977756214141845 and perplexity is 99.26327079544846
At time: 100.82883167266846 and batch: 900, loss is 4.56468074798584 and perplexity is 96.03193073482103
At time: 101.82112574577332 and batch: 950, loss is 4.624977254867554 and perplexity is 102.00045304250098
At time: 102.81364226341248 and batch: 1000, loss is 4.602279815673828 and perplexity is 99.71138027844452
At time: 103.80682444572449 and batch: 1050, loss is 4.537870817184448 and perplexity is 93.49152749708806
At time: 104.79963302612305 and batch: 1100, loss is 4.590336809158325 and perplexity is 98.52760957532035
At time: 105.84216356277466 and batch: 1150, loss is 4.540312089920044 and perplexity is 93.72004463701431
At time: 106.83415699005127 and batch: 1200, loss is 4.603888101577759 and perplexity is 99.87187371087622
At time: 107.82600426673889 and batch: 1250, loss is 4.59282922744751 and perplexity is 98.77348787992115
At time: 108.81711435317993 and batch: 1300, loss is 4.579256324768067 and perplexity is 97.44190212594884
At time: 109.80925512313843 and batch: 1350, loss is 4.4709306335449215 and perplexity is 87.4380579508921
At time: 110.80191826820374 and batch: 1400, loss is 4.491504058837891 and perplexity is 89.25559063249091
At time: 111.79415988922119 and batch: 1450, loss is 4.442605209350586 and perplexity is 84.99608608323595
At time: 112.787593126297 and batch: 1500, loss is 4.433928546905517 and perplexity is 84.26179394437932
At time: 113.7807412147522 and batch: 1550, loss is 4.442970924377441 and perplexity is 85.02717611383962
At time: 114.77431654930115 and batch: 1600, loss is 4.518330059051514 and perplexity is 91.68236593240812
At time: 115.76732540130615 and batch: 1650, loss is 4.485929021835327 and perplexity is 88.75937191613032
At time: 116.77029514312744 and batch: 1700, loss is 4.487977781295776 and perplexity is 88.94140492630055
At time: 117.77234959602356 and batch: 1750, loss is 4.4896988105773925 and perplexity is 89.09460748375574
At time: 118.76594114303589 and batch: 1800, loss is 4.444277324676514 and perplexity is 85.13832823091509
At time: 119.766676902771 and batch: 1850, loss is 4.485130758285522 and perplexity is 88.68854681713454
At time: 120.76776933670044 and batch: 1900, loss is 4.578486576080322 and perplexity is 97.36692521004943
At time: 121.76760601997375 and batch: 1950, loss is 4.50567403793335 and perplexity is 90.5293437002554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.520805323401163 and perplexity of 91.90958512205889
finished 3 epochs...
Completing Train Step...
At time: 125.14915299415588 and batch: 50, loss is 4.477640810012818 and perplexity is 88.0267556736424
At time: 126.14539957046509 and batch: 100, loss is 4.4337436389923095 and perplexity is 84.24621471230397
At time: 127.14788293838501 and batch: 150, loss is 4.387449941635132 and perplexity is 80.43504317694533
At time: 128.167142868042 and batch: 200, loss is 4.381928100585937 and perplexity is 79.99211766131035
At time: 129.17107224464417 and batch: 250, loss is 4.381552791595459 and perplexity is 79.96210153339831
At time: 130.16986894607544 and batch: 300, loss is 4.401710872650146 and perplexity is 81.59034000332645
At time: 131.1691653728485 and batch: 350, loss is 4.402818689346313 and perplexity is 81.68077722891314
At time: 132.22324395179749 and batch: 400, loss is 4.348872194290161 and perplexity is 77.39113152806513
At time: 133.2204728126526 and batch: 450, loss is 4.366039581298828 and perplexity is 78.73120490120603
At time: 134.21813774108887 and batch: 500, loss is 4.387835111618042 and perplexity is 80.46603030842452
At time: 135.2150444984436 and batch: 550, loss is 4.34677752494812 and perplexity is 77.22919236122236
At time: 136.21108317375183 and batch: 600, loss is 4.331146783828736 and perplexity is 76.0314282056694
At time: 137.20718693733215 and batch: 650, loss is 4.398034772872925 and perplexity is 81.29095639177916
At time: 138.20464396476746 and batch: 700, loss is 4.420045490264893 and perplexity is 83.10006551635585
At time: 139.2018473148346 and batch: 750, loss is 4.37891263961792 and perplexity is 79.75126787182731
At time: 140.19973611831665 and batch: 800, loss is 4.371412887573242 and perplexity is 79.15539039718267
At time: 141.19703149795532 and batch: 850, loss is 4.391074476242065 and perplexity is 80.72711176114773
At time: 142.19435453414917 and batch: 900, loss is 4.354214973449707 and perplexity is 77.80572179863955
At time: 143.19171595573425 and batch: 950, loss is 4.420383815765381 and perplexity is 83.12818514413762
At time: 144.18860578536987 and batch: 1000, loss is 4.399196844100953 and perplexity is 81.38547718260983
At time: 145.18622374534607 and batch: 1050, loss is 4.349894037246704 and perplexity is 77.47025352896098
At time: 146.18405389785767 and batch: 1100, loss is 4.386138048171997 and perplexity is 80.32959015628305
At time: 147.18200659751892 and batch: 1150, loss is 4.34699013710022 and perplexity is 77.24561397167032
At time: 148.17942190170288 and batch: 1200, loss is 4.407687168121338 and perplexity is 82.07940793437936
At time: 149.1780354976654 and batch: 1250, loss is 4.401339159011841 and perplexity is 81.56001739720551
At time: 150.17702078819275 and batch: 1300, loss is 4.386676292419434 and perplexity is 80.37283873418866
At time: 151.17361044883728 and batch: 1350, loss is 4.280209503173828 and perplexity is 72.25557619426988
At time: 152.17221236228943 and batch: 1400, loss is 4.302821054458618 and perplexity is 73.90799837148981
At time: 153.16966938972473 and batch: 1450, loss is 4.2499184846878055 and perplexity is 70.0996979150239
At time: 154.1675524711609 and batch: 1500, loss is 4.2456361770629885 and perplexity is 69.80015127733131
At time: 155.16505551338196 and batch: 1550, loss is 4.257417211532593 and perplexity is 70.62733222191756
At time: 156.16945433616638 and batch: 1600, loss is 4.337700366973877 and perplexity is 76.53134281879679
At time: 157.16888785362244 and batch: 1650, loss is 4.301952257156372 and perplexity is 73.84381518701618
At time: 158.1669421195984 and batch: 1700, loss is 4.305408062934876 and perplexity is 74.09944652196012
At time: 159.17364883422852 and batch: 1750, loss is 4.305294466018677 and perplexity is 74.09102953142431
At time: 160.1800696849823 and batch: 1800, loss is 4.259692802429199 and perplexity is 70.7882341402102
At time: 161.17701506614685 and batch: 1850, loss is 4.308609600067139 and perplexity is 74.33705881080591
At time: 162.1741645336151 and batch: 1900, loss is 4.39936149597168 and perplexity is 81.39887855692835
At time: 163.17186832427979 and batch: 1950, loss is 4.329987335205078 and perplexity is 75.94332475646301
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482915266170058 and perplexity of 88.4922755399443
finished 4 epochs...
Completing Train Step...
At time: 166.458815574646 and batch: 50, loss is 4.311827893257141 and perplexity is 74.5766826439933
At time: 167.47982096672058 and batch: 100, loss is 4.272007284164428 and perplexity is 71.66534404938741
At time: 168.47404789924622 and batch: 150, loss is 4.23014066696167 and perplexity is 68.72689909800324
At time: 169.46675443649292 and batch: 200, loss is 4.229935512542725 and perplexity is 68.71280091715437
At time: 170.45929074287415 and batch: 250, loss is 4.222024111747742 and perplexity is 68.17133112584668
At time: 171.45336151123047 and batch: 300, loss is 4.2424204587936405 and perplexity is 69.57605416536681
At time: 172.44684195518494 and batch: 350, loss is 4.248091344833374 and perplexity is 69.97173290376605
At time: 173.44017910957336 and batch: 400, loss is 4.189172224998474 and perplexity is 65.96816155806812
At time: 174.43614315986633 and batch: 450, loss is 4.217714281082153 and perplexity is 67.87815645284556
At time: 175.43811964988708 and batch: 500, loss is 4.241348190307617 and perplexity is 69.50148993868291
At time: 176.43111276626587 and batch: 550, loss is 4.197491507530213 and perplexity is 66.5192585193615
At time: 177.42373037338257 and batch: 600, loss is 4.188177380561829 and perplexity is 65.90256613357798
At time: 178.4163055419922 and batch: 650, loss is 4.250973434448242 and perplexity is 70.17368859590943
At time: 179.40997791290283 and batch: 700, loss is 4.277852430343628 and perplexity is 72.08546509966996
At time: 180.40334725379944 and batch: 750, loss is 4.235406632423401 and perplexity is 69.08976716175151
At time: 181.3964066505432 and batch: 800, loss is 4.230045790672302 and perplexity is 68.72037885415021
At time: 182.43450450897217 and batch: 850, loss is 4.248779926300049 and perplexity is 70.01993073439678
At time: 183.42774605751038 and batch: 900, loss is 4.2092436170578 and perplexity is 67.30561173535018
At time: 184.42064118385315 and batch: 950, loss is 4.28295597076416 and perplexity is 72.45429655711256
At time: 185.41157269477844 and batch: 1000, loss is 4.258731255531311 and perplexity is 70.72020064720462
At time: 186.40531992912292 and batch: 1050, loss is 4.215337524414062 and perplexity is 67.71701816098884
At time: 187.39914083480835 and batch: 1100, loss is 4.244889268875122 and perplexity is 69.74803643775093
At time: 188.39356207847595 and batch: 1150, loss is 4.212520341873169 and perplexity is 67.52651542618763
At time: 189.38763976097107 and batch: 1200, loss is 4.272508363723755 and perplexity is 71.70126308679886
At time: 190.38189935684204 and batch: 1250, loss is 4.267345304489136 and perplexity is 71.33201925242872
At time: 191.37529850006104 and batch: 1300, loss is 4.25279194355011 and perplexity is 70.30141618902874
At time: 192.36889743804932 and batch: 1350, loss is 4.147614941596985 and perplexity is 63.28288678159079
At time: 193.3613440990448 and batch: 1400, loss is 4.174323816299438 and perplexity is 64.99587564710096
At time: 194.35414242744446 and batch: 1450, loss is 4.114890427589416 and perplexity is 61.24550307766869
At time: 195.3468999862671 and batch: 1500, loss is 4.113940286636352 and perplexity is 61.18733885348502
At time: 196.34071373939514 and batch: 1550, loss is 4.123811664581299 and perplexity is 61.79433320709712
At time: 197.33399319648743 and batch: 1600, loss is 4.208306164741516 and perplexity is 67.24254549914319
At time: 198.32817840576172 and batch: 1650, loss is 4.173359632492065 and perplexity is 64.93323787826984
At time: 199.3223774433136 and batch: 1700, loss is 4.174528975486755 and perplexity is 65.00921151606892
At time: 200.31711268424988 and batch: 1750, loss is 4.177667465209961 and perplexity is 65.21356276773716
At time: 201.31218767166138 and batch: 1800, loss is 4.1322472333908085 and perplexity is 62.31780835807888
At time: 202.30827951431274 and batch: 1850, loss is 4.182145500183106 and perplexity is 65.50624621680163
At time: 203.30225944519043 and batch: 1900, loss is 4.273759126663208 and perplexity is 71.79100047778242
At time: 204.29651522636414 and batch: 1950, loss is 4.20482581615448 and perplexity is 67.00892477751795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4666569199672965 and perplexity of 87.06517011089322
finished 5 epochs...
Completing Train Step...
At time: 207.5686433315277 and batch: 50, loss is 4.190244336128234 and perplexity is 66.03892468447398
At time: 208.56133604049683 and batch: 100, loss is 4.15405827999115 and perplexity is 63.69195630711004
At time: 209.557288646698 and batch: 150, loss is 4.114703164100647 and perplexity is 61.23403510489076
At time: 210.55124235153198 and batch: 200, loss is 4.115991010665893 and perplexity is 61.31294594829961
At time: 211.54554080963135 and batch: 250, loss is 4.108208589553833 and perplexity is 60.83763471835996
At time: 212.53867363929749 and batch: 300, loss is 4.126375160217285 and perplexity is 61.95294592524716
At time: 213.53593373298645 and batch: 350, loss is 4.135669445991516 and perplexity is 62.531438482447356
At time: 214.53064370155334 and batch: 400, loss is 4.075278649330139 and perplexity is 58.86688152028992
At time: 215.52498078346252 and batch: 450, loss is 4.109905729293823 and perplexity is 60.94097235032495
At time: 216.5195643901825 and batch: 500, loss is 4.133192887306214 and perplexity is 62.37676731054056
At time: 217.5138840675354 and batch: 550, loss is 4.091748485565185 and perplexity is 59.84443741415329
At time: 218.50856041908264 and batch: 600, loss is 4.082532138824463 and perplexity is 59.29542416282692
At time: 219.50288844108582 and batch: 650, loss is 4.139805631637573 and perplexity is 62.79061575387975
At time: 220.4968297481537 and batch: 700, loss is 4.171658606529236 and perplexity is 64.82287864336048
At time: 221.49053120613098 and batch: 750, loss is 4.1273367214202885 and perplexity is 62.01254612448808
At time: 222.48784160614014 and batch: 800, loss is 4.123417325019837 and perplexity is 61.769970060831284
At time: 223.4816710948944 and batch: 850, loss is 4.140789952278137 and perplexity is 62.85245228149252
At time: 224.47576785087585 and batch: 900, loss is 4.101445088386535 and perplexity is 60.427547680290054
At time: 225.4713487625122 and batch: 950, loss is 4.179684472084046 and perplexity is 65.34523171607094
At time: 226.46794986724854 and batch: 1000, loss is 4.151246562004089 and perplexity is 63.51312401872823
At time: 227.46823835372925 and batch: 1050, loss is 4.114730157852173 and perplexity is 61.23568806352897
At time: 228.4708125591278 and batch: 1100, loss is 4.140763301849365 and perplexity is 62.85077725900996
At time: 229.4717571735382 and batch: 1150, loss is 4.111491060256958 and perplexity is 61.03766058188875
At time: 230.46712160110474 and batch: 1200, loss is 4.170150995254517 and perplexity is 64.72522457134443
At time: 231.45986032485962 and batch: 1250, loss is 4.165431261062622 and perplexity is 64.42045848905103
At time: 232.4521484375 and batch: 1300, loss is 4.150753087997437 and perplexity is 63.481789674921664
At time: 233.44565868377686 and batch: 1350, loss is 4.0503940629959105 and perplexity is 57.42007971641317
At time: 234.4405641555786 and batch: 1400, loss is 4.076306972503662 and perplexity is 58.92744683373089
At time: 235.4368941783905 and batch: 1450, loss is 4.013078098297119 and perplexity is 55.31687956982129
At time: 236.43188524246216 and batch: 1500, loss is 4.017226414680481 and perplexity is 55.5468281075041
At time: 237.43500399589539 and batch: 1550, loss is 4.027204828262329 and perplexity is 56.1038719162694
At time: 238.43012809753418 and batch: 1600, loss is 4.111133813858032 and perplexity is 61.015858991948654
At time: 239.42763662338257 and batch: 1650, loss is 4.075285458564759 and perplexity is 58.86728236006223
At time: 240.4224796295166 and batch: 1700, loss is 4.075614342689514 and perplexity is 58.886646058729944
At time: 241.41815090179443 and batch: 1750, loss is 4.0774754667282105 and perplexity is 58.99634345983916
At time: 242.41305136680603 and batch: 1800, loss is 4.0341926860809325 and perplexity is 56.4972907729194
At time: 243.40888619422913 and batch: 1850, loss is 4.087789607048035 and perplexity is 59.60798890078927
At time: 244.40856671333313 and batch: 1900, loss is 4.176995825767517 and perplexity is 65.16977747241171
At time: 245.4047749042511 and batch: 1950, loss is 4.109012336730957 and perplexity is 60.88655245163932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465447572220204 and perplexity of 86.959941685274
finished 6 epochs...
Completing Train Step...
At time: 248.64682936668396 and batch: 50, loss is 4.097485775947571 and perplexity is 60.18876915043243
At time: 249.672518491745 and batch: 100, loss is 4.060695815086365 and perplexity is 58.014664516866944
At time: 250.671626329422 and batch: 150, loss is 4.025486888885498 and perplexity is 56.00757160824174
At time: 251.67099285125732 and batch: 200, loss is 4.025441212654114 and perplexity is 56.00501345186558
At time: 252.67103600502014 and batch: 250, loss is 4.017565231323243 and perplexity is 55.56565148597641
At time: 253.67116165161133 and batch: 300, loss is 4.035063920021057 and perplexity is 56.54653457848834
At time: 254.671142578125 and batch: 350, loss is 4.049430375099182 and perplexity is 57.36477133485061
At time: 255.671128988266 and batch: 400, loss is 3.987240595817566 and perplexity is 53.90593568175733
At time: 256.6704797744751 and batch: 450, loss is 4.025865993499756 and perplexity is 56.028808362293155
At time: 257.6702094078064 and batch: 500, loss is 4.050554909706116 and perplexity is 57.42931629015162
At time: 258.69614028930664 and batch: 550, loss is 4.010297980308533 and perplexity is 55.163305693519874
At time: 259.69588708877563 and batch: 600, loss is 4.0014838600158695 and perplexity is 54.679226182870885
At time: 260.69919538497925 and batch: 650, loss is 4.055480680465698 and perplexity is 57.71289779242932
At time: 261.70171451568604 and batch: 700, loss is 4.088880214691162 and perplexity is 59.67303329158368
At time: 262.70151019096375 and batch: 750, loss is 4.04484516620636 and perplexity is 57.102343977094264
At time: 263.6983075141907 and batch: 800, loss is 4.03764506816864 and perplexity is 56.69267808935607
At time: 264.6954941749573 and batch: 850, loss is 4.054862914085388 and perplexity is 57.67725571483502
At time: 265.6927897930145 and batch: 900, loss is 4.016919665336609 and perplexity is 55.52979176750457
At time: 266.6908829212189 and batch: 950, loss is 4.098984432220459 and perplexity is 60.27903905175879
At time: 267.6941170692444 and batch: 1000, loss is 4.069427862167358 and perplexity is 58.523469520469234
At time: 268.69898772239685 and batch: 1050, loss is 4.036330246925354 and perplexity is 56.61818633426795
At time: 269.704735994339 and batch: 1100, loss is 4.0562892293930055 and perplexity is 57.75958036405956
At time: 270.705605506897 and batch: 1150, loss is 4.030552821159363 and perplexity is 56.292022067877966
At time: 271.7079141139984 and batch: 1200, loss is 4.088948006629944 and perplexity is 59.67707877932768
At time: 272.71323442459106 and batch: 1250, loss is 4.085201106071472 and perplexity is 59.45389308793082
At time: 273.71294140815735 and batch: 1300, loss is 4.073122220039368 and perplexity is 58.740076025404015
At time: 274.71745920181274 and batch: 1350, loss is 3.9726640129089357 and perplexity is 53.12587049555065
At time: 275.71718764305115 and batch: 1400, loss is 3.998693461418152 and perplexity is 54.52686202403655
At time: 276.7161674499512 and batch: 1450, loss is 3.937593207359314 and perplexity is 51.29499619491846
At time: 277.71630477905273 and batch: 1500, loss is 3.940620808601379 and perplexity is 51.45053232098572
At time: 278.72597312927246 and batch: 1550, loss is 3.9504923009872437 and perplexity is 51.96094096176454
At time: 279.73581171035767 and batch: 1600, loss is 4.035765824317932 and perplexity is 56.586238766722445
At time: 280.7374732494354 and batch: 1650, loss is 3.997396025657654 and perplexity is 54.456162797109016
At time: 281.7440221309662 and batch: 1700, loss is 3.996826572418213 and perplexity is 54.42516138656125
At time: 282.7438952922821 and batch: 1750, loss is 3.997562689781189 and perplexity is 54.4652394421072
At time: 283.7434575557709 and batch: 1800, loss is 3.9546878433227537 and perplexity is 52.17940325279978
At time: 284.742134809494 and batch: 1850, loss is 4.010243911743164 and perplexity is 55.16032317335104
At time: 285.7419674396515 and batch: 1900, loss is 4.0966960191726685 and perplexity is 60.14125342762453
At time: 286.7405662536621 and batch: 1950, loss is 4.033029246330261 and perplexity is 56.4315978013463
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470856138717297 and perplexity of 87.43154451044903
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 289.97978234291077 and batch: 50, loss is 4.06093985080719 and perplexity is 58.02882389496753
At time: 290.9708602428436 and batch: 100, loss is 4.047115144729614 and perplexity is 57.23211230148185
At time: 291.9656488895416 and batch: 150, loss is 4.020319528579712 and perplexity is 55.71890676583178
At time: 292.9642741680145 and batch: 200, loss is 4.018086256980896 and perplexity is 55.59461015953571
At time: 293.95804023742676 and batch: 250, loss is 4.010730805397034 and perplexity is 55.18718692401374
At time: 294.95410442352295 and batch: 300, loss is 4.029608244895935 and perplexity is 56.23887506466274
At time: 295.948917388916 and batch: 350, loss is 4.037679085731506 and perplexity is 56.69460666889963
At time: 296.9437758922577 and batch: 400, loss is 3.9663686418533324 and perplexity is 52.792473956678144
At time: 297.9438695907593 and batch: 450, loss is 3.9896535158157347 and perplexity is 54.03616344338487
At time: 298.9430456161499 and batch: 500, loss is 4.003241877555848 and perplexity is 54.77543776762007
At time: 299.93675804138184 and batch: 550, loss is 3.9752606773376464 and perplexity is 53.26399981384111
At time: 300.93190574645996 and batch: 600, loss is 3.9405908155441285 and perplexity is 51.44898918536603
At time: 301.9306228160858 and batch: 650, loss is 3.993154373168945 and perplexity is 54.22566786393983
At time: 302.93258571624756 and batch: 700, loss is 4.021551694869995 and perplexity is 55.787604039020636
At time: 303.92700815200806 and batch: 750, loss is 3.9586175298690796 and perplexity is 52.384855368575224
At time: 304.92433857917786 and batch: 800, loss is 3.9571892118453977 and perplexity is 52.310086545024745
At time: 305.9238669872284 and batch: 850, loss is 3.9777914237976075 and perplexity is 53.398968206168156
At time: 306.91914415359497 and batch: 900, loss is 3.927453246116638 and perplexity is 50.77749507626522
At time: 307.91286420822144 and batch: 950, loss is 4.006441097259522 and perplexity is 54.95095704005762
At time: 308.9337565898895 and batch: 1000, loss is 3.967735614776611 and perplexity is 52.8646891860162
At time: 309.9271385669708 and batch: 1050, loss is 3.9219086265563963 and perplexity is 50.496732264619915
At time: 310.9246256351471 and batch: 1100, loss is 3.9447989225387574 and perplexity is 51.66594820985573
At time: 311.9241373538971 and batch: 1150, loss is 3.9123609352111814 and perplexity is 50.01689934438684
At time: 312.92343497276306 and batch: 1200, loss is 3.957602815628052 and perplexity is 52.331726669600926
At time: 313.9211423397064 and batch: 1250, loss is 3.9467673397064207 and perplexity is 51.76774850915384
At time: 314.9157655239105 and batch: 1300, loss is 3.933603005409241 and perplexity is 51.09072661054617
At time: 315.9110207557678 and batch: 1350, loss is 3.8299904680252075 and perplexity is 46.06209916935373
At time: 316.9051456451416 and batch: 1400, loss is 3.8493166971206665 and perplexity is 46.96096370426311
At time: 317.9035642147064 and batch: 1450, loss is 3.77896342754364 and perplexity is 43.770646765216796
At time: 318.90417551994324 and batch: 1500, loss is 3.7778133869171144 and perplexity is 43.720337677479755
At time: 319.9038772583008 and batch: 1550, loss is 3.7806976890563964 and perplexity is 43.84662237503575
At time: 320.9028778076172 and batch: 1600, loss is 3.853740816116333 and perplexity is 47.16918485379043
At time: 321.90361523628235 and batch: 1650, loss is 3.813741617202759 and perplexity is 45.319690965920294
At time: 322.90249586105347 and batch: 1700, loss is 3.801226797103882 and perplexity is 44.75605742907451
At time: 323.9032473564148 and batch: 1750, loss is 3.788458890914917 and perplexity is 44.18824886331399
At time: 324.90123105049133 and batch: 1800, loss is 3.7469314908981324 and perplexity is 42.390805652224635
At time: 325.89901900291443 and batch: 1850, loss is 3.7877730417251585 and perplexity is 44.157952779094224
At time: 326.89285612106323 and batch: 1900, loss is 3.8712506246566774 and perplexity is 48.0023815190193
At time: 327.88675451278687 and batch: 1950, loss is 3.8056309413909912 and perplexity is 44.95360425677119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4006432821584305 and perplexity of 81.503281411854
finished 8 epochs...
Completing Train Step...
At time: 331.12328362464905 and batch: 50, loss is 3.982300224304199 and perplexity is 53.64027709909403
At time: 332.144198179245 and batch: 100, loss is 3.9492283630371094 and perplexity is 51.89530704389582
At time: 333.142733335495 and batch: 150, loss is 3.9158428382873534 and perplexity is 50.19135688594481
At time: 334.16805052757263 and batch: 200, loss is 3.9128274869918824 and perplexity is 50.04024026229113
At time: 335.1640393733978 and batch: 250, loss is 3.90334858417511 and perplexity is 49.56815464945947
At time: 336.16204714775085 and batch: 300, loss is 3.923848581314087 and perplexity is 50.59478872241808
At time: 337.1583077907562 and batch: 350, loss is 3.934224834442139 and perplexity is 51.12250618737221
At time: 338.15394401550293 and batch: 400, loss is 3.8670352840423585 and perplexity is 47.80046101147165
At time: 339.14881443977356 and batch: 450, loss is 3.899547176361084 and perplexity is 49.38008357295794
At time: 340.1431460380554 and batch: 500, loss is 3.9178475761413574 and perplexity is 50.29207832534597
At time: 341.1398591995239 and batch: 550, loss is 3.890194983482361 and perplexity is 48.92042426853278
At time: 342.1325888633728 and batch: 600, loss is 3.86140625 and perplexity is 47.53214647351645
At time: 343.1255769729614 and batch: 650, loss is 3.9147355937957764 and perplexity is 50.13581353821562
At time: 344.12228417396545 and batch: 700, loss is 3.9447805643081666 and perplexity is 51.66499972317109
At time: 345.1191554069519 and batch: 750, loss is 3.883893065452576 and perplexity is 48.61310114446801
At time: 346.11646604537964 and batch: 800, loss is 3.885593056678772 and perplexity is 48.69581327492019
At time: 347.10790157318115 and batch: 850, loss is 3.9077862024307253 and perplexity is 49.788607979517906
At time: 348.1018855571747 and batch: 900, loss is 3.85818480014801 and perplexity is 47.37927042077228
At time: 349.1013984680176 and batch: 950, loss is 3.93915385723114 and perplexity is 51.375112224429905
At time: 350.09748578071594 and batch: 1000, loss is 3.905315089225769 and perplexity is 49.665726582335175
At time: 351.0926105976105 and batch: 1050, loss is 3.865867495536804 and perplexity is 47.74467276331973
At time: 352.0867462158203 and batch: 1100, loss is 3.8877181577682496 and perplexity is 48.79940683517142
At time: 353.0820333957672 and batch: 1150, loss is 3.8582844829559324 and perplexity is 47.38399355488886
At time: 354.0818819999695 and batch: 1200, loss is 3.904368019104004 and perplexity is 49.618711923216885
At time: 355.08254170417786 and batch: 1250, loss is 3.8986159420013426 and perplexity is 49.334120546944035
At time: 356.0873701572418 and batch: 1300, loss is 3.886951656341553 and perplexity is 48.762016351970324
At time: 357.09280800819397 and batch: 1350, loss is 3.7841717910766604 and perplexity is 43.999214921973596
At time: 358.09731912612915 and batch: 1400, loss is 3.8081174421310426 and perplexity is 45.06552050928407
At time: 359.09443759918213 and batch: 1450, loss is 3.7385161924362182 and perplexity is 42.03557116911142
At time: 360.0949532985687 and batch: 1500, loss is 3.742343430519104 and perplexity is 42.19675956435418
At time: 361.09196972846985 and batch: 1550, loss is 3.74848265171051 and perplexity is 42.45661163339245
At time: 362.09653544425964 and batch: 1600, loss is 3.823900761604309 and perplexity is 45.78244687270581
At time: 363.1000759601593 and batch: 1650, loss is 3.786397862434387 and perplexity is 44.097269411727886
At time: 364.10191106796265 and batch: 1700, loss is 3.7781369829177858 and perplexity is 43.73448769322096
At time: 365.1037483215332 and batch: 1750, loss is 3.7698037910461424 and perplexity is 43.37155411367915
At time: 366.1064507961273 and batch: 1800, loss is 3.7308170890808103 and perplexity is 41.7131776252049
At time: 367.1043493747711 and batch: 1850, loss is 3.7759937906265257 and perplexity is 43.64085664684247
At time: 368.1199240684509 and batch: 1900, loss is 3.861817646026611 and perplexity is 47.55170503259285
At time: 369.1217043399811 and batch: 1950, loss is 3.7982908344268798 and perplexity is 44.62484802210459
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399860044967297 and perplexity of 81.43947000364903
finished 9 epochs...
Completing Train Step...
At time: 372.37891721725464 and batch: 50, loss is 3.938097505569458 and perplexity is 51.32087069337217
At time: 373.37517619132996 and batch: 100, loss is 3.9025634765625 and perplexity is 49.52925358665963
At time: 374.368469953537 and batch: 150, loss is 3.8696376132965087 and perplexity is 47.92501554518559
At time: 375.36195635795593 and batch: 200, loss is 3.8661474275588987 and perplexity is 47.758039896967695
At time: 376.3586161136627 and batch: 250, loss is 3.8560897302627564 and perplexity is 47.28011144688846
At time: 377.3569633960724 and batch: 300, loss is 3.8774187421798705 and perplexity is 48.29938087144904
At time: 378.35014724731445 and batch: 350, loss is 3.8895930290222167 and perplexity is 48.890985262311666
At time: 379.3430857658386 and batch: 400, loss is 3.821534857749939 and perplexity is 45.674258037843465
At time: 380.34191703796387 and batch: 450, loss is 3.8561597061157227 and perplexity is 47.28342002877437
At time: 381.3393077850342 and batch: 500, loss is 3.877409176826477 and perplexity is 48.29891887301192
At time: 382.3390209674835 and batch: 550, loss is 3.8480590343475343 and perplexity is 46.90193977230274
At time: 383.33726263046265 and batch: 600, loss is 3.821853451728821 and perplexity is 45.6888118997075
At time: 384.3381996154785 and batch: 650, loss is 3.875389838218689 and perplexity is 48.20148541010281
At time: 385.36145281791687 and batch: 700, loss is 3.905680341720581 and perplexity is 49.68387042621644
At time: 386.36022448539734 and batch: 750, loss is 3.844901919364929 and perplexity is 46.75409845435347
At time: 387.35846853256226 and batch: 800, loss is 3.847436661720276 and perplexity is 46.87275837061791
At time: 388.3580367565155 and batch: 850, loss is 3.870817947387695 and perplexity is 47.98161647228482
At time: 389.3582339286804 and batch: 900, loss is 3.821971821784973 and perplexity is 45.69422040703393
At time: 390.35825419425964 and batch: 950, loss is 3.903723945617676 and perplexity is 49.586764115913624
At time: 391.357497215271 and batch: 1000, loss is 3.8709633207321166 and perplexity is 47.988592227374276
At time: 392.358101606369 and batch: 1050, loss is 3.8336295080184937 and perplexity is 46.230026351956276
At time: 393.3584542274475 and batch: 1100, loss is 3.855357065200806 and perplexity is 47.24548364794444
At time: 394.35814332962036 and batch: 1150, loss is 3.8265241956710816 and perplexity is 45.90271178805386
At time: 395.3532540798187 and batch: 1200, loss is 3.872910714149475 and perplexity is 48.082135949638186
At time: 396.34820675849915 and batch: 1250, loss is 3.8692535400390624 and perplexity is 47.90661236266334
At time: 397.3418209552765 and batch: 1300, loss is 3.857417802810669 and perplexity is 47.342944579207085
At time: 398.3387129306793 and batch: 1350, loss is 3.7565208053588868 and perplexity is 42.79925968500732
At time: 399.3451499938965 and batch: 1400, loss is 3.7826136493682863 and perplexity is 43.93071129310807
At time: 400.3405702114105 and batch: 1450, loss is 3.712885799407959 and perplexity is 40.97187269337894
At time: 401.3375012874603 and batch: 1500, loss is 3.718103537559509 and perplexity is 41.186211893303934
At time: 402.3365156650543 and batch: 1550, loss is 3.7256065654754638 and perplexity is 41.49639539346416
At time: 403.3306245803833 and batch: 1600, loss is 3.8023264598846436 and perplexity is 44.80530107038031
At time: 404.32546067237854 and batch: 1650, loss is 3.7647284078598022 and perplexity is 43.15198452838947
At time: 405.3198070526123 and batch: 1700, loss is 3.7579205513000487 and perplexity is 42.8592097226588
At time: 406.31956577301025 and batch: 1750, loss is 3.751483449935913 and perplexity is 42.584206706025086
At time: 407.3190121650696 and batch: 1800, loss is 3.7134572792053224 and perplexity is 40.99529398264275
At time: 408.318083524704 and batch: 1850, loss is 3.760058574676514 and perplexity is 42.95094174260082
At time: 409.3186354637146 and batch: 1900, loss is 3.8474216985702516 and perplexity is 46.87205701174963
At time: 410.3173520565033 and batch: 1950, loss is 3.7846201038360596 and perplexity is 44.01894475366386
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.402741755995639 and perplexity of 81.67449349475272
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 413.54821395874023 and batch: 50, loss is 3.9357673025131223 and perplexity is 51.20142186768708
At time: 414.5732822418213 and batch: 100, loss is 3.9330540132522582 and perplexity is 51.06268590011177
At time: 415.57118797302246 and batch: 150, loss is 3.910430417060852 and perplexity is 49.9204339564302
At time: 416.5686264038086 and batch: 200, loss is 3.910901255607605 and perplexity is 49.94394395528004
At time: 417.5665669441223 and batch: 250, loss is 3.9056793069839477 and perplexity is 49.68381901652222
At time: 418.5647099018097 and batch: 300, loss is 3.9157826042175294 and perplexity is 50.18833374729848
At time: 419.5629425048828 and batch: 350, loss is 3.9376728105545045 and perplexity is 51.29907960303688
At time: 420.5613474845886 and batch: 400, loss is 3.8757186460494997 and perplexity is 48.217337041889884
At time: 421.56015181541443 and batch: 450, loss is 3.9025392627716062 and perplexity is 49.52805431018973
At time: 422.55750799179077 and batch: 500, loss is 3.9130938816070557 and perplexity is 50.053572488576776
At time: 423.55983805656433 and batch: 550, loss is 3.893487401008606 and perplexity is 49.081756171040865
At time: 424.5586338043213 and batch: 600, loss is 3.8574515199661255 and perplexity is 47.34454087554037
At time: 425.557893037796 and batch: 650, loss is 3.898434338569641 and perplexity is 49.32516211481836
At time: 426.5564911365509 and batch: 700, loss is 3.9358752822875975 and perplexity is 51.20695088417877
At time: 427.5567309856415 and batch: 750, loss is 3.8585644245147703 and perplexity is 47.3972601607591
At time: 428.5574760437012 and batch: 800, loss is 3.854340662956238 and perplexity is 47.19748762808209
At time: 429.55783343315125 and batch: 850, loss is 3.8827391386032106 and perplexity is 48.55703753469974
At time: 430.5579481124878 and batch: 900, loss is 3.8369797801971437 and perplexity is 46.38516926343702
At time: 431.5571343898773 and batch: 950, loss is 3.925460515022278 and perplexity is 50.67640993413654
At time: 432.55801153182983 and batch: 1000, loss is 3.8836261081695556 and perplexity is 48.600125255148434
At time: 433.5566415786743 and batch: 1050, loss is 3.8315856504440307 and perplexity is 46.13563525626589
At time: 434.5578486919403 and batch: 1100, loss is 3.860533790588379 and perplexity is 47.490694690099744
At time: 435.5848779678345 and batch: 1150, loss is 3.835693984031677 and perplexity is 46.32556571788047
At time: 436.5824453830719 and batch: 1200, loss is 3.874002528190613 and perplexity is 48.13466136957362
At time: 437.58147525787354 and batch: 1250, loss is 3.8579371786117553 and perplexity is 47.36753974548792
At time: 438.57970690727234 and batch: 1300, loss is 3.8476239013671876 and perplexity is 46.88153563104492
At time: 439.5778720378876 and batch: 1350, loss is 3.7394618463516234 and perplexity is 42.07534107289268
At time: 440.57830023765564 and batch: 1400, loss is 3.7629600048065184 and perplexity is 43.07574186094631
At time: 441.5782108306885 and batch: 1450, loss is 3.6897457456588745 and perplexity is 40.0346666753534
At time: 442.57775592803955 and batch: 1500, loss is 3.6985446405410767 and perplexity is 40.388481807440726
At time: 443.5781123638153 and batch: 1550, loss is 3.708178915977478 and perplexity is 40.77947601426147
At time: 444.5773413181305 and batch: 1600, loss is 3.782013511657715 and perplexity is 43.90435472618478
At time: 445.57687616348267 and batch: 1650, loss is 3.737057318687439 and perplexity is 41.97429128849102
At time: 446.5778377056122 and batch: 1700, loss is 3.7204560804367066 and perplexity is 41.28321828383901
At time: 447.5772020816803 and batch: 1750, loss is 3.7089224815368653 and perplexity is 40.80980950422716
At time: 448.57688450813293 and batch: 1800, loss is 3.674033689498901 and perplexity is 39.410555617603904
At time: 449.576908826828 and batch: 1850, loss is 3.7194888257980345 and perplexity is 41.24330620513804
At time: 450.5849668979645 and batch: 1900, loss is 3.8096572828292845 and perplexity is 45.13496768692474
At time: 451.5906970500946 and batch: 1950, loss is 3.7503499603271484 and perplexity is 42.53596529595988
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373478095476018 and perplexity of 79.31903165342408
finished 11 epochs...
Completing Train Step...
At time: 454.8428764343262 and batch: 50, loss is 3.932776441574097 and perplexity is 51.048514311601835
At time: 455.8349585533142 and batch: 100, loss is 3.910069913864136 and perplexity is 49.90244072391125
At time: 456.83335423469543 and batch: 150, loss is 3.8747781801223753 and perplexity is 48.17201159616476
At time: 457.8280439376831 and batch: 200, loss is 3.867865552902222 and perplexity is 47.84016472583461
At time: 458.8222088813782 and batch: 250, loss is 3.8600168514251707 and perplexity is 47.466151234409736
At time: 459.81551337242126 and batch: 300, loss is 3.8724967670440673 and perplexity is 48.06223660756168
At time: 460.8151071071625 and batch: 350, loss is 3.8953991079330446 and perplexity is 49.17567584902261
At time: 461.83691668510437 and batch: 400, loss is 3.832854166030884 and perplexity is 46.194196163557
At time: 462.8342113494873 and batch: 450, loss is 3.862285737991333 and perplexity is 47.573968813969486
At time: 463.83396220207214 and batch: 500, loss is 3.874135384559631 and perplexity is 48.14105679073391
At time: 464.8338780403137 and batch: 550, loss is 3.8544095230102537 and perplexity is 47.20073776153046
At time: 465.8336412906647 and batch: 600, loss is 3.822493462562561 and perplexity is 45.718062593686085
At time: 466.8391697406769 and batch: 650, loss is 3.86528799533844 and perplexity is 47.717012731253654
At time: 467.84224939346313 and batch: 700, loss is 3.903677849769592 and perplexity is 49.58447842464881
At time: 468.83734011650085 and batch: 750, loss is 3.8298794555664064 and perplexity is 46.056985986286165
At time: 469.8341701030731 and batch: 800, loss is 3.82682599067688 and perplexity is 45.916567087849074
At time: 470.83305048942566 and batch: 850, loss is 3.85602810382843 and perplexity is 47.27719783198422
At time: 471.83329033851624 and batch: 900, loss is 3.810882272720337 and perplexity is 45.190291444677946
At time: 472.83215165138245 and batch: 950, loss is 3.8998716068267822 and perplexity is 49.39610657550228
At time: 473.83356380462646 and batch: 1000, loss is 3.8599538373947144 and perplexity is 47.46316029514677
At time: 474.83259630203247 and batch: 1050, loss is 3.811171541213989 and perplexity is 45.20336546307149
At time: 475.8325226306915 and batch: 1100, loss is 3.839770164489746 and perplexity is 46.51478246237664
At time: 476.8318133354187 and batch: 1150, loss is 3.81614444732666 and perplexity is 45.428717418144764
At time: 477.82863426208496 and batch: 1200, loss is 3.8559088706970215 and perplexity is 47.271561159688204
At time: 478.82142543792725 and batch: 1250, loss is 3.8427121925354 and perplexity is 46.651831759503516
At time: 479.8140649795532 and batch: 1300, loss is 3.83308876991272 and perplexity is 46.20503477263543
At time: 480.81673073768616 and batch: 1350, loss is 3.7251980686187744 and perplexity is 41.47944770815576
At time: 481.81433296203613 and batch: 1400, loss is 3.752109479904175 and perplexity is 42.610874042002536
At time: 482.8121931552887 and batch: 1450, loss is 3.680721335411072 and perplexity is 39.67500273751951
At time: 483.8113021850586 and batch: 1500, loss is 3.6917727470397947 and perplexity is 40.115899301498104
At time: 484.811119556427 and batch: 1550, loss is 3.7026917934417725 and perplexity is 40.55632681581776
At time: 485.8107874393463 and batch: 1600, loss is 3.778866882324219 and perplexity is 43.76642112250672
At time: 486.8070459365845 and batch: 1650, loss is 3.7343120765686035 and perplexity is 41.85921971806682
At time: 487.80063557624817 and batch: 1700, loss is 3.720003719329834 and perplexity is 41.2645475847883
At time: 488.79515767097473 and batch: 1750, loss is 3.710063452720642 and perplexity is 40.85639889440851
At time: 489.7933475971222 and batch: 1800, loss is 3.676416826248169 and perplexity is 39.504588362947146
At time: 490.793199300766 and batch: 1850, loss is 3.7232102870941164 and perplexity is 41.397077522437414
At time: 491.79235649108887 and batch: 1900, loss is 3.813682909011841 and perplexity is 45.31703040694979
At time: 492.7922661304474 and batch: 1950, loss is 3.753785572052002 and perplexity is 42.68235367989239
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373027003088663 and perplexity of 79.28325951095005
finished 12 epochs...
Completing Train Step...
At time: 496.0158553123474 and batch: 50, loss is 3.918387975692749 and perplexity is 50.319263486674444
At time: 497.03814816474915 and batch: 100, loss is 3.894702091217041 and perplexity is 49.14141152372605
At time: 498.0331439971924 and batch: 150, loss is 3.8580971813201903 and perplexity is 47.37511928649647
At time: 499.0292308330536 and batch: 200, loss is 3.850798153877258 and perplexity is 47.03058589964132
At time: 500.023154258728 and batch: 250, loss is 3.8418117904663087 and perplexity is 46.609845258863
At time: 501.01824474334717 and batch: 300, loss is 3.853918333053589 and perplexity is 47.1775589262664
At time: 502.01283407211304 and batch: 350, loss is 3.877294964790344 and perplexity is 48.29340287014736
At time: 503.01121520996094 and batch: 400, loss is 3.8144395256042483 and perplexity is 45.35133099863638
At time: 504.0109829902649 and batch: 450, loss is 3.8442289638519287 and perplexity is 46.72264561041261
At time: 505.0111927986145 and batch: 500, loss is 3.856841926574707 and perplexity is 47.315688751228514
At time: 506.01014494895935 and batch: 550, loss is 3.836730833053589 and perplexity is 46.37362324527934
At time: 507.010324716568 and batch: 600, loss is 3.8064636993408203 and perplexity is 44.99105531976039
At time: 508.0102663040161 and batch: 650, loss is 3.8497554445266724 and perplexity is 46.981572225909005
At time: 509.008682012558 and batch: 700, loss is 3.888327784538269 and perplexity is 48.82916532980505
At time: 510.00938391685486 and batch: 750, loss is 3.8155389785766602 and perplexity is 45.401220074626636
At time: 511.00517678260803 and batch: 800, loss is 3.8128478479385377 and perplexity is 45.27920371489641
At time: 512.0268037319183 and batch: 850, loss is 3.842451844215393 and perplexity is 46.63968761440216
At time: 513.019749879837 and batch: 900, loss is 3.7982006549835203 and perplexity is 44.62082395959654
At time: 514.0125648975372 and batch: 950, loss is 3.8866935682296755 and perplexity is 48.74943307910512
At time: 515.0110785961151 and batch: 1000, loss is 3.8479469633102417 and perplexity is 46.89668371779266
At time: 516.0107591152191 and batch: 1050, loss is 3.8004044675827027 and perplexity is 44.71926833025315
At time: 517.008866071701 and batch: 1100, loss is 3.82895049571991 and perplexity is 46.014220762317606
At time: 518.0050592422485 and batch: 1150, loss is 3.806005892753601 and perplexity is 44.970462832316926
At time: 518.9977688789368 and batch: 1200, loss is 3.8458854961395263 and perplexity is 46.800107322628364
At time: 519.991425037384 and batch: 1250, loss is 3.8341011953353883 and perplexity is 46.25183761268933
At time: 520.9913537502289 and batch: 1300, loss is 3.824256086349487 and perplexity is 45.79871739946368
At time: 521.9899232387543 and batch: 1350, loss is 3.7164175128936767 and perplexity is 41.116829430867156
At time: 522.9878444671631 and batch: 1400, loss is 3.7447998619079588 and perplexity is 42.3005404221494
At time: 523.9855201244354 and batch: 1450, loss is 3.673902015686035 and perplexity is 39.40536662111354
At time: 524.9798760414124 and batch: 1500, loss is 3.685771884918213 and perplexity is 39.8758901719875
At time: 525.9740860462189 and batch: 1550, loss is 3.697275071144104 and perplexity is 40.3372383623855
At time: 526.9712834358215 and batch: 1600, loss is 3.774725193977356 and perplexity is 43.585529103921225
At time: 527.9700224399567 and batch: 1650, loss is 3.730107226371765 and perplexity is 41.68357750318736
At time: 528.9691936969757 and batch: 1700, loss is 3.716804962158203 and perplexity is 41.132763202754575
At time: 529.9686670303345 and batch: 1750, loss is 3.707207431793213 and perplexity is 40.739878635498876
At time: 530.9693973064423 and batch: 1800, loss is 3.6740111827850344 and perplexity is 39.40966862548696
At time: 531.9691476821899 and batch: 1850, loss is 3.721541237831116 and perplexity is 41.32804138908827
At time: 532.9704620838165 and batch: 1900, loss is 3.812144408226013 and perplexity is 45.24736372492149
At time: 533.9693531990051 and batch: 1950, loss is 3.7516901159286498 and perplexity is 42.59300832284501
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373933446130088 and perplexity of 79.35515785078724
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 537.2293634414673 and batch: 50, loss is 3.920708889961243 and perplexity is 50.43618581414494
At time: 538.2324430942535 and batch: 100, loss is 3.9206292152404787 and perplexity is 50.43216748520553
At time: 539.2321343421936 and batch: 150, loss is 3.8955818128585817 and perplexity is 49.184661308035665
At time: 540.2326860427856 and batch: 200, loss is 3.897918119430542 and perplexity is 49.29970609310364
At time: 541.2332293987274 and batch: 250, loss is 3.8908718633651733 and perplexity is 48.95354872895452
At time: 542.2344584465027 and batch: 300, loss is 3.8948826360702515 and perplexity is 49.150284553621994
At time: 543.2342593669891 and batch: 350, loss is 3.915543851852417 and perplexity is 50.17635259423649
At time: 544.2343556880951 and batch: 400, loss is 3.8661177253723142 and perplexity is 47.7566213998221
At time: 545.234433889389 and batch: 450, loss is 3.8968916606903075 and perplexity is 49.249127941527085
At time: 546.234317779541 and batch: 500, loss is 3.9110771465301513 and perplexity is 49.95272941427653
At time: 547.2334659099579 and batch: 550, loss is 3.892003607749939 and perplexity is 49.008982995636
At time: 548.2331366539001 and batch: 600, loss is 3.8600023794174194 and perplexity is 47.46546430887176
At time: 549.2325022220612 and batch: 650, loss is 3.8893433475494383 and perplexity is 48.878779612931446
At time: 550.2319197654724 and batch: 700, loss is 3.921721305847168 and perplexity is 50.487274066804204
At time: 551.2319750785828 and batch: 750, loss is 3.851393213272095 and perplexity is 47.05858021994117
At time: 552.2318875789642 and batch: 800, loss is 3.837215533256531 and perplexity is 46.39610599813475
At time: 553.2316119670868 and batch: 850, loss is 3.860434556007385 and perplexity is 47.485982204735684
At time: 554.2311561107635 and batch: 900, loss is 3.811654500961304 and perplexity is 45.225202141727266
At time: 555.2302033901215 and batch: 950, loss is 3.9067448663711546 and perplexity is 49.736788292210186
At time: 556.2301096916199 and batch: 1000, loss is 3.8709910774230956 and perplexity is 47.98992425038544
At time: 557.2294397354126 and batch: 1050, loss is 3.8174587297439575 and perplexity is 45.48846283526338
At time: 558.2288918495178 and batch: 1100, loss is 3.840649652481079 and perplexity is 46.5557096498186
At time: 559.2287521362305 and batch: 1150, loss is 3.82628746509552 and perplexity is 45.89184649879627
At time: 560.2289180755615 and batch: 1200, loss is 3.864247889518738 and perplexity is 47.66740779027894
At time: 561.2292678356171 and batch: 1250, loss is 3.8527474880218504 and perplexity is 47.122353640511946
At time: 562.2288806438446 and batch: 1300, loss is 3.840283899307251 and perplexity is 46.53868486487872
At time: 563.2286841869354 and batch: 1350, loss is 3.724992370605469 and perplexity is 41.47091634564142
At time: 564.2277927398682 and batch: 1400, loss is 3.746349587440491 and perplexity is 42.36614547146148
At time: 565.2293181419373 and batch: 1450, loss is 3.667056136131287 and perplexity is 39.13652351115708
At time: 566.2281081676483 and batch: 1500, loss is 3.6784332180023194 and perplexity is 39.58432545276201
At time: 567.2281377315521 and batch: 1550, loss is 3.6959937810897827 and perplexity is 40.28558775682285
At time: 568.2281718254089 and batch: 1600, loss is 3.777428274154663 and perplexity is 43.703503659167175
At time: 569.2279736995697 and batch: 1650, loss is 3.7306722021102905 and perplexity is 41.70713436707328
At time: 570.2366449832916 and batch: 1700, loss is 3.7145260429382323 and perplexity is 41.039131687973345
At time: 571.2420792579651 and batch: 1750, loss is 3.7024700832366944 and perplexity is 40.54733606099009
At time: 572.2528443336487 and batch: 1800, loss is 3.6690119218826296 and perplexity is 39.2131410655354
At time: 573.2521200180054 and batch: 1850, loss is 3.713464865684509 and perplexity is 40.99560499376704
At time: 574.2519211769104 and batch: 1900, loss is 3.8106091737747194 and perplexity is 45.17795170879339
At time: 575.2521710395813 and batch: 1950, loss is 3.755963897705078 and perplexity is 42.77543108549199
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347793082303779 and perplexity of 77.30766287450564
finished 14 epochs...
Completing Train Step...
At time: 578.4780657291412 and batch: 50, loss is 3.9258129024505615 and perplexity is 50.694270810697226
At time: 579.5056073665619 and batch: 100, loss is 3.908569884300232 and perplexity is 49.827641701911965
At time: 580.5055549144745 and batch: 150, loss is 3.8717926931381226 and perplexity is 48.02840915081717
At time: 581.5065112113953 and batch: 200, loss is 3.8703401470184327 and perplexity is 47.95869631428257
At time: 582.5056562423706 and batch: 250, loss is 3.8632441997528075 and perplexity is 47.61958850279054
At time: 583.5051231384277 and batch: 300, loss is 3.8714006471633913 and perplexity is 48.0095834968389
At time: 584.5068740844727 and batch: 350, loss is 3.8917327737808227 and perplexity is 48.99571149551659
At time: 585.506341457367 and batch: 400, loss is 3.837683629989624 and perplexity is 46.41782894760492
At time: 586.5055780410767 and batch: 450, loss is 3.872439007759094 and perplexity is 48.05946064731053
At time: 587.5060751438141 and batch: 500, loss is 3.8856412267684934 and perplexity is 48.69815901311146
At time: 588.5481505393982 and batch: 550, loss is 3.867803273200989 and perplexity is 47.837185347446905
At time: 589.5461826324463 and batch: 600, loss is 3.8379849767684937 and perplexity is 46.431818918650876
At time: 590.5458397865295 and batch: 650, loss is 3.8684068965911864 and perplexity is 47.8660697082047
At time: 591.5447442531586 and batch: 700, loss is 3.9035740280151368 and perplexity is 49.57933074433023
At time: 592.5447673797607 and batch: 750, loss is 3.835621476173401 and perplexity is 46.32220687209966
At time: 593.5452437400818 and batch: 800, loss is 3.8230354166030884 and perplexity is 45.742846397668565
At time: 594.5450122356415 and batch: 850, loss is 3.848029670715332 and perplexity is 46.900562581213464
At time: 595.545254945755 and batch: 900, loss is 3.799831523895264 and perplexity is 44.6936540462283
At time: 596.5447688102722 and batch: 950, loss is 3.8959941387176515 and perplexity is 49.20494559734368
At time: 597.5447180271149 and batch: 1000, loss is 3.8600644302368163 and perplexity is 47.46840967120531
At time: 598.5449018478394 and batch: 1050, loss is 3.80828115940094 and perplexity is 45.07289911725465
At time: 599.5448851585388 and batch: 1100, loss is 3.8322370862960815 and perplexity is 46.165699454514076
At time: 600.5451619625092 and batch: 1150, loss is 3.817722272872925 and perplexity is 45.50045258692984
At time: 601.5451719760895 and batch: 1200, loss is 3.8563947963714598 and perplexity is 47.29453720679997
At time: 602.5441546440125 and batch: 1250, loss is 3.8455898761749268 and perplexity is 46.78627432131481
At time: 603.5443115234375 and batch: 1300, loss is 3.8340656852722166 and perplexity is 46.25019523617451
At time: 604.5445327758789 and batch: 1350, loss is 3.7196349191665647 and perplexity is 41.24933201882586
At time: 605.5399439334869 and batch: 1400, loss is 3.7428090667724607 and perplexity is 42.216412480581575
At time: 606.5347421169281 and batch: 1450, loss is 3.6653235006332396 and perplexity is 39.06877289176467
At time: 607.5290234088898 and batch: 1500, loss is 3.6783140087127686 and perplexity is 39.57960691469981
At time: 608.5247159004211 and batch: 1550, loss is 3.6962937259674074 and perplexity is 40.297673024879124
At time: 609.5251824855804 and batch: 1600, loss is 3.7787999534606933 and perplexity is 43.763491983703474
At time: 610.5245802402496 and batch: 1650, loss is 3.73246150970459 and perplexity is 41.78182806440427
At time: 611.5235412120819 and batch: 1700, loss is 3.71778648853302 and perplexity is 41.17315591472041
At time: 612.5244002342224 and batch: 1750, loss is 3.7067050409317015 and perplexity is 40.71941643321541
At time: 613.5231914520264 and batch: 1800, loss is 3.673886432647705 and perplexity is 39.404752570559474
At time: 614.5232951641083 and batch: 1850, loss is 3.7187905359268187 and perplexity is 41.21451647511782
At time: 615.5268168449402 and batch: 1900, loss is 3.8166232204437254 and perplexity is 45.45047267428765
At time: 616.5281677246094 and batch: 1950, loss is 3.7609934425354004 and perplexity is 42.991113972482346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34609744049782 and perplexity of 77.17668784416475
finished 15 epochs...
Completing Train Step...
At time: 619.8331151008606 and batch: 50, loss is 3.92196713924408 and perplexity is 50.499687050589344
At time: 620.831536769867 and batch: 100, loss is 3.9026279878616332 and perplexity is 49.53244888621896
At time: 621.8353757858276 and batch: 150, loss is 3.8644531202316283 and perplexity is 47.677191610297214
At time: 622.8310568332672 and batch: 200, loss is 3.8625351715087892 and perplexity is 47.58583683642988
At time: 623.8239715099335 and batch: 250, loss is 3.8549171543121337 and perplexity is 47.224704416087405
At time: 624.8162100315094 and batch: 300, loss is 3.8631703090667724 and perplexity is 47.61606998872167
At time: 625.8078529834747 and batch: 350, loss is 3.8835356569290163 and perplexity is 48.59572951233193
At time: 626.8033013343811 and batch: 400, loss is 3.828602590560913 and perplexity is 45.998214961938885
At time: 627.8007159233093 and batch: 450, loss is 3.863731951713562 and perplexity is 47.642820715771244
At time: 628.7936670780182 and batch: 500, loss is 3.876866226196289 and perplexity is 48.272702062433375
At time: 629.7865519523621 and batch: 550, loss is 3.8592198276519776 and perplexity is 47.42833465581192
At time: 630.7820234298706 and batch: 600, loss is 3.829989109039307 and perplexity is 46.06203657165293
At time: 631.7775075435638 and batch: 650, loss is 3.8607791376113894 and perplexity is 47.50234782013458
At time: 632.7681894302368 and batch: 700, loss is 3.896498212814331 and perplexity is 49.22975478815773
At time: 633.7631833553314 and batch: 750, loss is 3.829426436424255 and perplexity is 46.03612601534441
At time: 634.7614905834198 and batch: 800, loss is 3.817207899093628 and perplexity is 45.477054365404676
At time: 635.7579076290131 and batch: 850, loss is 3.8423983955383303 and perplexity is 46.63719485141858
At time: 636.749852180481 and batch: 900, loss is 3.7943789958953857 and perplexity is 44.450623812809
At time: 637.7427163124084 and batch: 950, loss is 3.890950002670288 and perplexity is 48.95737407468809
At time: 638.7659697532654 and batch: 1000, loss is 3.8552201128005983 and perplexity is 47.23901370860686
At time: 639.7624914646149 and batch: 1050, loss is 3.803850951194763 and perplexity is 44.873658454389385
At time: 640.7612943649292 and batch: 1100, loss is 3.8281198740005493 and perplexity is 45.976016220110786
At time: 641.7608876228333 and batch: 1150, loss is 3.81370879650116 and perplexity is 45.31820356627542
At time: 642.7613484859467 and batch: 1200, loss is 3.852619557380676 and perplexity is 47.116325633188715
At time: 643.7595698833466 and batch: 1250, loss is 3.8422714853286744 and perplexity is 46.63127649080036
At time: 644.7529661655426 and batch: 1300, loss is 3.8310911083221435 and perplexity is 46.11282488212196
At time: 645.7634508609772 and batch: 1350, loss is 3.716953225135803 and perplexity is 41.13886212081463
At time: 646.76336145401 and batch: 1400, loss is 3.740790457725525 and perplexity is 42.13128000192294
At time: 647.7637913227081 and batch: 1450, loss is 3.6641843509674072 and perplexity is 39.02429305158805
At time: 648.7647264003754 and batch: 1500, loss is 3.6776460647583007 and perplexity is 39.553178782778964
At time: 649.7631394863129 and batch: 1550, loss is 3.695737261772156 and perplexity is 40.2752550506673
At time: 650.7612888813019 and batch: 1600, loss is 3.778677921295166 and perplexity is 43.758151755852076
At time: 651.7605767250061 and batch: 1650, loss is 3.732345852851868 and perplexity is 41.77699598910607
At time: 652.7550275325775 and batch: 1700, loss is 3.718267102241516 and perplexity is 41.19294905392108
At time: 653.7493426799774 and batch: 1750, loss is 3.7074432468414305 and perplexity is 40.74948684477932
At time: 654.7441866397858 and batch: 1800, loss is 3.674919900894165 and perplexity is 39.445497181605155
At time: 655.7420399188995 and batch: 1850, loss is 3.719961681365967 and perplexity is 41.26281294368858
At time: 656.741290807724 and batch: 1900, loss is 3.817982792854309 and perplexity is 45.51230790819774
At time: 657.7413930892944 and batch: 1950, loss is 3.7617231225967407 and perplexity is 43.02249517889082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34566536836846 and perplexity of 77.14334915118962
finished 16 epochs...
Completing Train Step...
At time: 660.9819281101227 and batch: 50, loss is 3.917788896560669 and perplexity is 50.289127293861384
At time: 662.0072014331818 and batch: 100, loss is 3.8976784467697145 and perplexity is 49.28789171721429
At time: 663.0023484230042 and batch: 150, loss is 3.858820538520813 and perplexity is 47.409400817564084
At time: 664.0283496379852 and batch: 200, loss is 3.856837739944458 and perplexity is 47.31549065834942
At time: 665.0220115184784 and batch: 250, loss is 3.848977131843567 and perplexity is 46.94502009871062
At time: 666.0212399959564 and batch: 300, loss is 3.8572023248672487 and perplexity is 47.332744317878834
At time: 667.0219209194183 and batch: 350, loss is 3.877695598602295 and perplexity is 48.312754716474444
At time: 668.0219740867615 and batch: 400, loss is 3.8223347520828246 and perplexity is 45.71080723380528
At time: 669.0206029415131 and batch: 450, loss is 3.8576627731323243 and perplexity is 47.35454361622068
At time: 670.0204656124115 and batch: 500, loss is 3.8709427404403685 and perplexity is 47.98760461830833
At time: 671.0155839920044 and batch: 550, loss is 3.85338502407074 and perplexity is 47.15240541819421
At time: 672.0081758499146 and batch: 600, loss is 3.8245557069778444 and perplexity is 45.81244169588736
At time: 673.0022900104523 and batch: 650, loss is 3.855538191795349 and perplexity is 47.25404183653952
At time: 674.0015041828156 and batch: 700, loss is 3.891588635444641 and perplexity is 48.98864984412115
At time: 675.0012509822845 and batch: 750, loss is 3.824997191429138 and perplexity is 45.8326716418466
At time: 675.9994475841522 and batch: 800, loss is 3.8129857206344604 and perplexity is 45.28544691115508
At time: 676.9988956451416 and batch: 850, loss is 3.8382097768783567 and perplexity is 46.44225796995091
At time: 677.999315738678 and batch: 900, loss is 3.790365762710571 and perplexity is 44.27259057763224
At time: 679.0009410381317 and batch: 950, loss is 3.8870788049697875 and perplexity is 48.76821676963838
At time: 680.0009887218475 and batch: 1000, loss is 3.851611590385437 and perplexity is 47.068857859007316
At time: 681.0005207061768 and batch: 1050, loss is 3.800465841293335 and perplexity is 44.72201300191182
At time: 682.0001845359802 and batch: 1100, loss is 3.824906044006348 and perplexity is 45.82849430232661
At time: 682.9988751411438 and batch: 1150, loss is 3.810623092651367 and perplexity is 45.17858053950671
At time: 684.0002653598785 and batch: 1200, loss is 3.849595060348511 and perplexity is 46.974037729281996
At time: 685.0001378059387 and batch: 1250, loss is 3.8396287536621094 and perplexity is 46.50820523354795
At time: 685.9999799728394 and batch: 1300, loss is 3.8285953283309935 and perplexity is 45.99788091353891
At time: 686.9998457431793 and batch: 1350, loss is 3.7145902824401857 and perplexity is 41.04176810603377
At time: 687.9994399547577 and batch: 1400, loss is 3.7388565158843994 and perplexity is 42.049879294195094
At time: 688.9980878829956 and batch: 1450, loss is 3.662806358337402 and perplexity is 38.970554897265565
At time: 689.9977781772614 and batch: 1500, loss is 3.6764790487289427 and perplexity is 39.50704651291233
At time: 690.9983909130096 and batch: 1550, loss is 3.6945614767074586 and perplexity is 40.227927836070265
At time: 691.9953124523163 and batch: 1600, loss is 3.77783353805542 and perplexity is 43.72121870092784
At time: 692.9907758235931 and batch: 1650, loss is 3.7314325046539305 and perplexity is 41.7388564650883
At time: 693.9850766658783 and batch: 1700, loss is 3.7177570104599 and perplexity is 41.171942227308435
At time: 694.9809441566467 and batch: 1750, loss is 3.707078857421875 and perplexity is 40.734640867943476
At time: 695.9794445037842 and batch: 1800, loss is 3.6747691774368287 and perplexity is 39.43955226792382
At time: 696.9818093776703 and batch: 1850, loss is 3.7199315309524534 and perplexity is 41.26156887157034
At time: 697.9814982414246 and batch: 1900, loss is 3.8180568647384643 and perplexity is 45.51567921545475
At time: 698.9791841506958 and batch: 1950, loss is 3.7613443183898925 and perplexity is 43.00620116304366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345621934047965 and perplexity of 77.13999855500451
finished 17 epochs...
Completing Train Step...
At time: 702.2283601760864 and batch: 50, loss is 3.9138249492645265 and perplexity is 50.090178415638356
At time: 703.2266294956207 and batch: 100, loss is 3.89333025932312 and perplexity is 49.07404398711821
At time: 704.2259504795074 and batch: 150, loss is 3.8540098381042482 and perplexity is 47.18187610870492
At time: 705.2247786521912 and batch: 200, loss is 3.85206084728241 and perplexity is 47.0900086187397
At time: 706.2226843833923 and batch: 250, loss is 3.844019274711609 and perplexity is 46.71284940613582
At time: 707.2230942249298 and batch: 300, loss is 3.852231001853943 and perplexity is 47.098021880706966
At time: 708.2389438152313 and batch: 350, loss is 3.872870545387268 and perplexity is 48.08020458854327
At time: 709.249222278595 and batch: 400, loss is 3.8172082042694093 and perplexity is 45.4770682439024
At time: 710.2628898620605 and batch: 450, loss is 3.852702035903931 and perplexity is 47.12021187841181
At time: 711.2610957622528 and batch: 500, loss is 3.866180410385132 and perplexity is 47.75961511807634
At time: 712.2601640224457 and batch: 550, loss is 3.8486471939086915 and perplexity is 46.929533710640506
At time: 713.2595245838165 and batch: 600, loss is 3.8201317834854125 and perplexity is 45.6102185983897
At time: 714.2585635185242 and batch: 650, loss is 3.8512824821472167 and perplexity is 47.05336965890921
At time: 715.3069040775299 and batch: 700, loss is 3.8875676870346068 and perplexity is 48.79206450504035
At time: 716.3067591190338 and batch: 750, loss is 3.8212646675109863 and perplexity is 45.661918966173666
At time: 717.3053092956543 and batch: 800, loss is 3.8094082117080688 and perplexity is 45.12372726980667
At time: 718.3038628101349 and batch: 850, loss is 3.834625210762024 and perplexity is 46.27608064041413
At time: 719.3023147583008 and batch: 900, loss is 3.7869480657577514 and perplexity is 44.12153855177803
At time: 720.3013761043549 and batch: 950, loss is 3.8837124919891357 and perplexity is 48.60432370093633
At time: 721.2995853424072 and batch: 1000, loss is 3.8484858465194702 and perplexity is 46.92196236372388
At time: 722.2995727062225 and batch: 1050, loss is 3.7975122499465943 and perplexity is 44.59011733014282
At time: 723.3011405467987 and batch: 1100, loss is 3.8220618200302123 and perplexity is 45.698332991748075
At time: 724.2993078231812 and batch: 1150, loss is 3.8078977823257447 and perplexity is 45.055622512959125
At time: 725.2978537082672 and batch: 1200, loss is 3.846871004104614 and perplexity is 46.84625193536874
At time: 726.2989389896393 and batch: 1250, loss is 3.837249255180359 and perplexity is 46.39767059046752
At time: 727.297726392746 and batch: 1300, loss is 3.8262804317474366 and perplexity is 45.89152372660074
At time: 728.2997550964355 and batch: 1350, loss is 3.7123470640182497 and perplexity is 40.9498056402613
At time: 729.3006031513214 and batch: 1400, loss is 3.7369343852996826 and perplexity is 41.96913156382195
At time: 730.3014566898346 and batch: 1450, loss is 3.6612740993499755 and perplexity is 38.91088763879973
At time: 731.3009302616119 and batch: 1500, loss is 3.6750556802749634 and perplexity is 39.4508534304136
At time: 732.3021740913391 and batch: 1550, loss is 3.693116111755371 and perplexity is 40.16982579852024
At time: 733.3021717071533 and batch: 1600, loss is 3.7766562843322755 and perplexity is 43.66977801874016
At time: 734.3005788326263 and batch: 1650, loss is 3.730198540687561 and perplexity is 41.68738398433745
At time: 735.3001718521118 and batch: 1700, loss is 3.7168059301376344 and perplexity is 41.13280301844258
At time: 736.2983570098877 and batch: 1750, loss is 3.706212568283081 and perplexity is 40.699368171369755
At time: 737.2965869903564 and batch: 1800, loss is 3.674087109565735 and perplexity is 39.41266098835297
At time: 738.2983024120331 and batch: 1850, loss is 3.7194037294387816 and perplexity is 41.23979669926163
At time: 739.2973408699036 and batch: 1900, loss is 3.8176130723953245 and perplexity is 45.495484187057066
At time: 740.2968802452087 and batch: 1950, loss is 3.7605388927459718 and perplexity is 42.97157681132149
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345754224200581 and perplexity of 77.15020409221734
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 743.5260608196259 and batch: 50, loss is 3.9150980710983276 and perplexity is 50.15398992673329
At time: 744.5451376438141 and batch: 100, loss is 3.9025656938552857 and perplexity is 49.529363407638044
At time: 745.5411989688873 and batch: 150, loss is 3.8657084941864013 and perplexity is 47.737081899370615
At time: 746.5373015403748 and batch: 200, loss is 3.8676612091064455 and perplexity is 47.830389883732146
At time: 747.5361950397491 and batch: 250, loss is 3.862280125617981 and perplexity is 47.57370181184393
At time: 748.5343041419983 and batch: 300, loss is 3.8707005691528322 and perplexity is 47.97598480536146
At time: 749.532961845398 and batch: 350, loss is 3.891106519699097 and perplexity is 48.96503733711643
At time: 750.5358600616455 and batch: 400, loss is 3.8375700187683104 and perplexity is 46.412555660925385
At time: 751.5398728847504 and batch: 450, loss is 3.8756650352478026 and perplexity is 48.21475214108529
At time: 752.5407409667969 and batch: 500, loss is 3.893694906234741 and perplexity is 49.091941948718755
At time: 753.5361588001251 and batch: 550, loss is 3.8821243047714233 and perplexity is 48.52719220115261
At time: 754.5378749370575 and batch: 600, loss is 3.8524591302871705 and perplexity is 47.10876750429126
At time: 755.5352146625519 and batch: 650, loss is 3.879194393157959 and perplexity is 48.38521990185991
At time: 756.5353202819824 and batch: 700, loss is 3.910476269721985 and perplexity is 49.92272299365084
At time: 757.5361788272858 and batch: 750, loss is 3.840663557052612 and perplexity is 46.55635699151421
At time: 758.5441589355469 and batch: 800, loss is 3.8256744575500488 and perplexity is 45.863723071434165
At time: 759.5579040050507 and batch: 850, loss is 3.849447798728943 and perplexity is 46.96712076572246
At time: 760.5569067001343 and batch: 900, loss is 3.79707106590271 and perplexity is 44.57044922080885
At time: 761.556051492691 and batch: 950, loss is 3.89208930015564 and perplexity is 49.01318287323608
At time: 762.5592300891876 and batch: 1000, loss is 3.85598828792572 and perplexity is 47.27531548514885
At time: 763.5559988021851 and batch: 1050, loss is 3.806148624420166 and perplexity is 44.976881999521495
At time: 764.5626256465912 and batch: 1100, loss is 3.82289647102356 and perplexity is 45.73649107289892
At time: 765.62153673172 and batch: 1150, loss is 3.8112604808807373 and perplexity is 45.207386014122264
At time: 766.6165041923523 and batch: 1200, loss is 3.850879044532776 and perplexity is 47.03439038843585
At time: 767.620231628418 and batch: 1250, loss is 3.842479958534241 and perplexity is 46.640998875883234
At time: 768.6218731403351 and batch: 1300, loss is 3.8306284093856813 and perplexity is 46.0914934624849
At time: 769.6256382465363 and batch: 1350, loss is 3.7144402742385862 and perplexity is 41.03561196595702
At time: 770.6306273937225 and batch: 1400, loss is 3.736687574386597 and perplexity is 41.95877440232209
At time: 771.6418051719666 and batch: 1450, loss is 3.657969937324524 and perplexity is 38.78253193228938
At time: 772.6417391300201 and batch: 1500, loss is 3.6662299633026123 and perplexity is 39.1042033316888
At time: 773.6363227367401 and batch: 1550, loss is 3.6868389225006104 and perplexity is 39.91846195423913
At time: 774.6473190784454 and batch: 1600, loss is 3.772296290397644 and perplexity is 43.479792520223775
At time: 775.653395652771 and batch: 1650, loss is 3.7267245054244995 and perplexity is 41.54281181216565
At time: 776.6556482315063 and batch: 1700, loss is 3.7137714433670044 and perplexity is 41.00817525812132
At time: 777.6610863208771 and batch: 1750, loss is 3.7002420091629027 and perplexity is 40.457094162900454
At time: 778.6588706970215 and batch: 1800, loss is 3.6676208925247193 and perplexity is 39.15863235549469
At time: 779.6565051078796 and batch: 1850, loss is 3.7096777725219727 and perplexity is 40.840644428654024
At time: 780.6581544876099 and batch: 1900, loss is 3.8087504577636717 and perplexity is 45.09405671923962
At time: 781.6549077033997 and batch: 1950, loss is 3.7589966249465943 and perplexity is 42.905354211734746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338914596202762 and perplexity of 76.62432585210745
finished 19 epochs...
Completing Train Step...
At time: 785.1171073913574 and batch: 50, loss is 3.9178552627563477 and perplexity is 50.29246490267485
At time: 786.1133570671082 and batch: 100, loss is 3.898648910522461 and perplexity is 49.33574704675065
At time: 787.1120226383209 and batch: 150, loss is 3.858837537765503 and perplexity is 47.410206748419284
At time: 788.1133618354797 and batch: 200, loss is 3.8578612995147705 and perplexity is 47.36394567570475
At time: 789.1122071743011 and batch: 250, loss is 3.852333745956421 and perplexity is 47.10286117329371
At time: 790.1122584342957 and batch: 300, loss is 3.860601615905762 and perplexity is 47.4939158707774
At time: 791.105815410614 and batch: 350, loss is 3.8809568071365357 and perplexity is 48.470569878675406
At time: 792.143248796463 and batch: 400, loss is 3.8257715034484865 and perplexity is 45.86817417362244
At time: 793.1348781585693 and batch: 450, loss is 3.8649072790145875 and perplexity is 47.698849543311844
At time: 794.1322374343872 and batch: 500, loss is 3.880998773574829 and perplexity is 48.47260405853861
At time: 795.1368081569672 and batch: 550, loss is 3.8671474933624266 and perplexity is 47.8058249696381
At time: 796.133127450943 and batch: 600, loss is 3.838770742416382 and perplexity is 46.468317784825786
At time: 797.1327269077301 and batch: 650, loss is 3.8666471147537234 and perplexity is 47.78190994123519
At time: 798.1325566768646 and batch: 700, loss is 3.8997557067871096 and perplexity is 49.390381896542166
At time: 799.1319286823273 and batch: 750, loss is 3.8319836902618407 and perplexity is 46.15400273136857
At time: 800.1325991153717 and batch: 800, loss is 3.8184022283554078 and perplexity is 45.53140138983347
At time: 801.1334636211395 and batch: 850, loss is 3.8422591352462767 and perplexity is 46.63070059424958
At time: 802.1318550109863 and batch: 900, loss is 3.7907556295394897 and perplexity is 44.289854357197584
At time: 803.1307542324066 and batch: 950, loss is 3.8865036392211914 and perplexity is 48.740175026830414
At time: 804.124725818634 and batch: 1000, loss is 3.8510655641555784 and perplexity is 47.043164043393816
At time: 805.1189773082733 and batch: 1050, loss is 3.8009638452529906 and perplexity is 44.7442902880985
At time: 806.1144549846649 and batch: 1100, loss is 3.8191638469696043 and perplexity is 45.56609216155426
At time: 807.1126899719238 and batch: 1150, loss is 3.8082258605957033 and perplexity is 45.07040670869915
At time: 808.1130864620209 and batch: 1200, loss is 3.8479366302490234 and perplexity is 46.896199133992496
At time: 809.1145882606506 and batch: 1250, loss is 3.8393714952468874 and perplexity is 46.496242145243286
At time: 810.1121029853821 and batch: 1300, loss is 3.8283390617370605 and perplexity is 45.986094703539514
At time: 811.1178588867188 and batch: 1350, loss is 3.71287962436676 and perplexity is 40.97161969115822
At time: 812.116231918335 and batch: 1400, loss is 3.735708999633789 and perplexity is 41.91773468852211
At time: 813.112268447876 and batch: 1450, loss is 3.6576708555221558 and perplexity is 38.77093451711304
At time: 814.1118805408478 and batch: 1500, loss is 3.6674710607528684 and perplexity is 39.152765587750686
At time: 815.1120595932007 and batch: 1550, loss is 3.6882105445861817 and perplexity is 39.97325256569396
At time: 816.1108710765839 and batch: 1600, loss is 3.774667115211487 and perplexity is 43.58299778368981
At time: 817.1071949005127 and batch: 1650, loss is 3.72907687664032 and perplexity is 41.640650958775666
At time: 818.1125452518463 and batch: 1700, loss is 3.71728723526001 and perplexity is 41.15260521229941
At time: 819.1119525432587 and batch: 1750, loss is 3.7046726989746093 and perplexity is 40.636744691809945
At time: 820.1072173118591 and batch: 1800, loss is 3.6722635555267336 and perplexity is 39.34085536183823
At time: 821.1008880138397 and batch: 1850, loss is 3.7150506353378296 and perplexity is 41.06066615245728
At time: 822.093879699707 and batch: 1900, loss is 3.814190468788147 and perplexity is 45.34003734697074
At time: 823.0920515060425 and batch: 1950, loss is 3.7637112808227537 and perplexity is 43.10811579204428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3374542946039245 and perplexity of 76.51251288675175
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fcae8787b38>
ELAPSED
1701.0994107723236


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.42392198682246}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.7974071334468391, 'wordvec_source': 'gigavec', 'dropout': 0.589069126925909, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.51251288675175}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.014077492312028927, 'wordvec_source': 'gigavec', 'dropout': 0.3289390596927714, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5058119297027588 and batch: 50, loss is 7.551957597732544 and perplexity is 1904.46726538087
At time: 2.5021259784698486 and batch: 100, loss is 6.625715541839599 and perplexity is 754.2437124476808
At time: 3.499268054962158 and batch: 150, loss is 6.354453716278076 and perplexity is 575.0481154144295
At time: 4.496684312820435 and batch: 200, loss is 6.174705686569214 and perplexity is 480.44160269426555
At time: 5.494892597198486 and batch: 250, loss is 6.048772315979004 and perplexity is 423.5926727372153
At time: 6.492677211761475 and batch: 300, loss is 5.95925386428833 and perplexity is 387.32102234991856
At time: 7.492136240005493 and batch: 350, loss is 5.876891231536865 and perplexity is 356.6986228453177
At time: 8.490075588226318 and batch: 400, loss is 5.7992619705200195 and perplexity is 330.055879030108
At time: 9.488738536834717 and batch: 450, loss is 5.705287942886352 and perplexity is 300.45198060490065
At time: 10.518368005752563 and batch: 500, loss is 5.68009430885315 and perplexity is 292.97705895012786
At time: 11.51755166053772 and batch: 550, loss is 5.627809896469116 and perplexity is 278.0524865665412
At time: 12.516961574554443 and batch: 600, loss is 5.6338889789581295 and perplexity is 279.74793874415894
At time: 13.515665769577026 and batch: 650, loss is 5.679353971481323 and perplexity is 292.76023735476747
At time: 14.514066696166992 and batch: 700, loss is 5.604371137619019 and perplexity is 271.6110657348224
At time: 15.51238465309143 and batch: 750, loss is 5.532959070205688 and perplexity is 252.89112754601769
At time: 16.511046886444092 and batch: 800, loss is 5.535313892364502 and perplexity is 253.48734289197395
At time: 17.510405778884888 and batch: 850, loss is 5.540447864532471 and perplexity is 254.79208624751897
At time: 18.51250386238098 and batch: 900, loss is 5.535310249328614 and perplexity is 253.48641943016872
At time: 19.51623296737671 and batch: 950, loss is 5.545651950836182 and perplexity is 256.1215024518576
At time: 20.515009880065918 and batch: 1000, loss is 5.516436891555786 and perplexity is 248.74714325127883
At time: 21.512141704559326 and batch: 1050, loss is 5.409269142150879 and perplexity is 223.46820449159392
At time: 22.510663747787476 and batch: 1100, loss is 5.48916919708252 and perplexity is 242.0560224475854
At time: 23.510390043258667 and batch: 1150, loss is 5.393134183883667 and perplexity is 219.8914870272024
At time: 24.50919532775879 and batch: 1200, loss is 5.462986755371094 and perplexity is 235.80065252265553
At time: 25.507948875427246 and batch: 1250, loss is 5.40805492401123 and perplexity is 223.1970300098695
At time: 26.5051109790802 and batch: 1300, loss is 5.424823637008667 and perplexity is 226.97131344543737
At time: 27.502408504486084 and batch: 1350, loss is 5.37050048828125 and perplexity is 214.970430966528
At time: 28.49887990951538 and batch: 1400, loss is 5.371765413284302 and perplexity is 215.2425244922464
At time: 29.496829986572266 and batch: 1450, loss is 5.340463848114013 and perplexity is 208.60945095126405
At time: 30.504920959472656 and batch: 1500, loss is 5.295756864547729 and perplexity is 199.48855465777632
At time: 31.503424882888794 and batch: 1550, loss is 5.281051034927368 and perplexity is 196.57637544987423
At time: 32.50244164466858 and batch: 1600, loss is 5.310937042236328 and perplexity is 202.53992796305442
At time: 33.50195670127869 and batch: 1650, loss is 5.297327795028687 and perplexity is 199.80218358901584
At time: 34.50144171714783 and batch: 1700, loss is 5.317694244384765 and perplexity is 203.9131655964338
At time: 35.500327348709106 and batch: 1750, loss is 5.3068256664276126 and perplexity is 201.70891966720288
At time: 36.500417709350586 and batch: 1800, loss is 5.283693561553955 and perplexity is 197.09652070231917
At time: 37.49986481666565 and batch: 1850, loss is 5.2696906852722165 and perplexity is 194.3558360243654
At time: 38.494959115982056 and batch: 1900, loss is 5.3317751216888425 and perplexity is 206.8047521230842
At time: 39.49259352684021 and batch: 1950, loss is 5.253850994110107 and perplexity is 191.30155291540706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.861673328488372 and perplexity of 129.24028271695457
finished 1 epochs...
Completing Train Step...
At time: 42.731032371520996 and batch: 50, loss is 5.123746471405029 and perplexity is 167.96346263002658
At time: 43.747721672058105 and batch: 100, loss is 5.058188486099243 and perplexity is 157.30529732950322
At time: 44.74014496803284 and batch: 150, loss is 4.989377899169922 and perplexity is 146.84504265166598
At time: 45.72819375991821 and batch: 200, loss is 4.958551683425903 and perplexity is 142.38742442071697
At time: 46.7207396030426 and batch: 250, loss is 4.971520357131958 and perplexity is 144.2460262187714
At time: 47.710673809051514 and batch: 300, loss is 4.982427787780762 and perplexity is 145.82799165113212
At time: 48.70138382911682 and batch: 350, loss is 4.983758096694946 and perplexity is 146.02211702309063
At time: 49.69326686859131 and batch: 400, loss is 4.926014499664307 and perplexity is 137.82909831329496
At time: 50.684876441955566 and batch: 450, loss is 4.899115400314331 and perplexity is 134.17103951453936
At time: 51.67812204360962 and batch: 500, loss is 4.8968205165863035 and perplexity is 133.86348561438285
At time: 52.67071485519409 and batch: 550, loss is 4.866631231307983 and perplexity is 129.8826345221645
At time: 53.66187596321106 and batch: 600, loss is 4.829480276107788 and perplexity is 125.14590243456628
At time: 54.65354013442993 and batch: 650, loss is 4.902196102142334 and perplexity is 134.58501782569402
At time: 55.64551854133606 and batch: 700, loss is 4.914107437133789 and perplexity is 136.19769053316335
At time: 56.638704776763916 and batch: 750, loss is 4.852839689254761 and perplexity is 128.1036483850539
At time: 57.63001275062561 and batch: 800, loss is 4.858143539428711 and perplexity is 128.78489596336385
At time: 58.62094235420227 and batch: 850, loss is 4.853448657989502 and perplexity is 128.18168325971453
At time: 59.6132390499115 and batch: 900, loss is 4.832764568328858 and perplexity is 125.55759383580249
At time: 60.60575580596924 and batch: 950, loss is 4.883754692077637 and perplexity is 132.12582550467974
At time: 61.599674701690674 and batch: 1000, loss is 4.862769231796265 and perplexity is 129.38199520770766
At time: 62.593637228012085 and batch: 1050, loss is 4.7810031700134275 and perplexity is 119.22389190762856
At time: 63.58710765838623 and batch: 1100, loss is 4.8360652732849125 and perplexity is 125.97270711439843
At time: 64.58110809326172 and batch: 1150, loss is 4.77567702293396 and perplexity is 118.59057598795972
At time: 65.57442736625671 and batch: 1200, loss is 4.849322423934937 and perplexity is 127.65386533210754
At time: 66.56767511367798 and batch: 1250, loss is 4.8202997589111325 and perplexity is 124.00225599047776
At time: 67.56052899360657 and batch: 1300, loss is 4.822992992401123 and perplexity is 124.33667314874945
At time: 68.55442094802856 and batch: 1350, loss is 4.719634513854981 and perplexity is 112.12726421635995
At time: 69.54680156707764 and batch: 1400, loss is 4.720755138397217 and perplexity is 112.25298721147459
At time: 70.54512977600098 and batch: 1450, loss is 4.678133888244629 and perplexity is 107.56914910322827
At time: 71.53883028030396 and batch: 1500, loss is 4.666255950927734 and perplexity is 106.29900775576718
At time: 72.5324854850769 and batch: 1550, loss is 4.669368658065796 and perplexity is 106.63040093336129
At time: 73.52635145187378 and batch: 1600, loss is 4.729383707046509 and perplexity is 113.22576060329379
At time: 74.521657705307 and batch: 1650, loss is 4.702812328338623 and perplexity is 110.25681520542174
At time: 75.51378178596497 and batch: 1700, loss is 4.712303056716919 and perplexity is 111.30821406895117
At time: 76.50896883010864 and batch: 1750, loss is 4.698617448806763 and perplexity is 109.79526988838829
At time: 77.50397372245789 and batch: 1800, loss is 4.6655221366882325 and perplexity is 106.22103264335401
At time: 78.49792432785034 and batch: 1850, loss is 4.687094554901123 and perplexity is 108.53737187311546
At time: 79.49453115463257 and batch: 1900, loss is 4.792744903564453 and perplexity is 120.63203793888565
At time: 80.48740839958191 and batch: 1950, loss is 4.70442753791809 and perplexity is 110.43504697162211
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.603995957485465 and perplexity of 99.88264606339013
finished 2 epochs...
Completing Train Step...
At time: 83.88640594482422 and batch: 50, loss is 4.684121360778809 and perplexity is 108.21514845077162
At time: 84.8806254863739 and batch: 100, loss is 4.6277738952636716 and perplexity is 102.28611088485043
At time: 85.87546372413635 and batch: 150, loss is 4.579557638168335 and perplexity is 97.47126710061508
At time: 86.86994123458862 and batch: 200, loss is 4.576799602508545 and perplexity is 97.20280824986354
At time: 87.86306858062744 and batch: 250, loss is 4.584434947967529 and perplexity is 97.94782588449402
At time: 88.86454677581787 and batch: 300, loss is 4.592297811508178 and perplexity is 98.72101201856792
At time: 89.864098072052 and batch: 350, loss is 4.608364057540894 and perplexity is 100.31989773949044
At time: 90.85860753059387 and batch: 400, loss is 4.543725280761719 and perplexity is 94.04047556993201
At time: 91.85542249679565 and batch: 450, loss is 4.554828605651855 and perplexity is 95.09045587210953
At time: 92.84813785552979 and batch: 500, loss is 4.565059251785279 and perplexity is 96.06828606535296
At time: 93.87992882728577 and batch: 550, loss is 4.5296924114227295 and perplexity is 92.73003399580669
At time: 94.87366318702698 and batch: 600, loss is 4.500970478057861 and perplexity is 90.10453335530899
At time: 95.86692214012146 and batch: 650, loss is 4.572745208740234 and perplexity is 96.80950762639118
At time: 96.86119771003723 and batch: 700, loss is 4.600240039825439 and perplexity is 99.50819870602304
At time: 97.85723114013672 and batch: 750, loss is 4.549381809234619 and perplexity is 94.57392551262468
At time: 98.85169982910156 and batch: 800, loss is 4.549509725570679 and perplexity is 94.58602383643316
At time: 99.8464617729187 and batch: 850, loss is 4.550154361724854 and perplexity is 94.64701706418549
At time: 100.8389482498169 and batch: 900, loss is 4.5152280807495115 and perplexity is 91.39840986308423
At time: 101.83281183242798 and batch: 950, loss is 4.58138032913208 and perplexity is 97.64908910643564
At time: 102.82454419136047 and batch: 1000, loss is 4.565163555145264 and perplexity is 96.07830683296841
At time: 103.8179144859314 and batch: 1050, loss is 4.500174865722657 and perplexity is 90.03287358759124
At time: 104.81230330467224 and batch: 1100, loss is 4.539476480484009 and perplexity is 93.64176399394688
At time: 105.80606317520142 and batch: 1150, loss is 4.500786571502686 and perplexity is 90.08796406462119
At time: 106.80007719993591 and batch: 1200, loss is 4.57070595741272 and perplexity is 96.61228986608275
At time: 107.79324197769165 and batch: 1250, loss is 4.55945013999939 and perplexity is 95.5309367447829
At time: 108.78699588775635 and batch: 1300, loss is 4.545712099075318 and perplexity is 94.22750264189646
At time: 109.78015661239624 and batch: 1350, loss is 4.437440404891968 and perplexity is 84.55822961371662
At time: 110.77366638183594 and batch: 1400, loss is 4.44731068611145 and perplexity is 85.39697563961919
At time: 111.76635885238647 and batch: 1450, loss is 4.4018883657455445 and perplexity is 81.60482301060709
At time: 112.75993490219116 and batch: 1500, loss is 4.40185429573059 and perplexity is 81.6020427804283
At time: 113.7532525062561 and batch: 1550, loss is 4.408970890045166 and perplexity is 82.18484272983952
At time: 114.74582648277283 and batch: 1600, loss is 4.479251518249511 and perplexity is 88.16865534285986
At time: 115.73881244659424 and batch: 1650, loss is 4.452684097290039 and perplexity is 85.85708377114845
At time: 116.73239088058472 and batch: 1700, loss is 4.45650541305542 and perplexity is 86.18579846024134
At time: 117.72570753097534 and batch: 1750, loss is 4.443668270111084 and perplexity is 85.08649013113113
At time: 118.71911239624023 and batch: 1800, loss is 4.406454839706421 and perplexity is 81.97832144637077
At time: 119.71328687667847 and batch: 1850, loss is 4.438002557754516 and perplexity is 84.60577762792002
At time: 120.70684838294983 and batch: 1900, loss is 4.547855911254882 and perplexity is 94.42972539606167
At time: 121.70099878311157 and batch: 1950, loss is 4.464509286880493 and perplexity is 86.87838671374897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.516211789153343 and perplexity of 91.4883634837758
finished 3 epochs...
Completing Train Step...
At time: 124.93690037727356 and batch: 50, loss is 4.451504545211792 and perplexity is 85.75587057440747
At time: 125.95675802230835 and batch: 100, loss is 4.4021072101593015 and perplexity is 81.62268372454605
At time: 126.9497230052948 and batch: 150, loss is 4.36071855545044 and perplexity is 78.31338672133715
At time: 127.94491863250732 and batch: 200, loss is 4.365204124450684 and perplexity is 78.66545584598221
At time: 128.93781232833862 and batch: 250, loss is 4.370602655410766 and perplexity is 79.09128212884714
At time: 129.93045258522034 and batch: 300, loss is 4.371454563140869 and perplexity is 79.15868931174981
At time: 130.92394757270813 and batch: 350, loss is 4.390280637741089 and perplexity is 80.66305290131781
At time: 131.9172284603119 and batch: 400, loss is 4.324232425689697 and perplexity is 75.50753296809495
At time: 132.91015601158142 and batch: 450, loss is 4.360076036453247 and perplexity is 78.26308504425626
At time: 133.90419745445251 and batch: 500, loss is 4.374375247955323 and perplexity is 79.3902248501293
At time: 134.89682054519653 and batch: 550, loss is 4.334176940917969 and perplexity is 76.26216478434206
At time: 135.89068746566772 and batch: 600, loss is 4.3080514049530025 and perplexity is 74.2955758066607
At time: 136.88371205329895 and batch: 650, loss is 4.377521543502808 and perplexity is 79.6404033224158
At time: 137.87668561935425 and batch: 700, loss is 4.413054084777832 and perplexity is 82.5211054927558
At time: 138.8695604801178 and batch: 750, loss is 4.367677154541016 and perplexity is 78.86023863793952
At time: 139.86492204666138 and batch: 800, loss is 4.363310050964356 and perplexity is 78.51659870945444
At time: 140.85885405540466 and batch: 850, loss is 4.363450145721435 and perplexity is 78.52759924381796
At time: 141.8524465560913 and batch: 900, loss is 4.328305444717407 and perplexity is 75.81570375331269
At time: 142.84567165374756 and batch: 950, loss is 4.403883495330811 and perplexity is 81.76779773107855
At time: 143.88240337371826 and batch: 1000, loss is 4.385114431381226 and perplexity is 80.2474055089718
At time: 144.8752634525299 and batch: 1050, loss is 4.3303107643127445 and perplexity is 75.96789101072893
At time: 145.8696117401123 and batch: 1100, loss is 4.361062049865723 and perplexity is 78.34029155288297
At time: 146.86049485206604 and batch: 1150, loss is 4.330677723884582 and perplexity is 75.9957732710059
At time: 147.8544466495514 and batch: 1200, loss is 4.3976782703399655 and perplexity is 81.26198112510367
At time: 148.84798574447632 and batch: 1250, loss is 4.395214433670044 and perplexity is 81.06201132376145
At time: 149.84196639060974 and batch: 1300, loss is 4.3735408592224125 and perplexity is 79.32401016924457
At time: 150.8357129096985 and batch: 1350, loss is 4.265257444381714 and perplexity is 71.18324334074002
At time: 151.82968831062317 and batch: 1400, loss is 4.278841075897216 and perplexity is 72.15676731472038
At time: 152.82454466819763 and batch: 1450, loss is 4.229542603492737 and perplexity is 68.68580833898537
At time: 153.81903386116028 and batch: 1500, loss is 4.233933277130127 and perplexity is 68.98804833997566
At time: 154.81345891952515 and batch: 1550, loss is 4.241639966964722 and perplexity is 69.52177180982541
At time: 155.80806612968445 and batch: 1600, loss is 4.316640672683715 and perplexity is 74.9364688592995
At time: 156.8015878200531 and batch: 1650, loss is 4.291313600540161 and perplexity is 73.06238027315464
At time: 157.79611015319824 and batch: 1700, loss is 4.293910169601441 and perplexity is 73.25233830215844
At time: 158.78930616378784 and batch: 1750, loss is 4.28128231048584 and perplexity is 72.33313409965015
At time: 159.78331685066223 and batch: 1800, loss is 4.241592707633973 and perplexity is 69.51848633505246
At time: 160.77682185173035 and batch: 1850, loss is 4.282031698226929 and perplexity is 72.38735997918596
At time: 161.77272963523865 and batch: 1900, loss is 4.388495559692383 and perplexity is 80.51919149636132
At time: 162.76729106903076 and batch: 1950, loss is 4.308430767059326 and perplexity is 74.32376607961179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486662824763808 and perplexity of 88.82452770600356
finished 4 epochs...
Completing Train Step...
At time: 165.99650740623474 and batch: 50, loss is 4.298505368232727 and perplexity is 73.58972192556702
At time: 167.0199704170227 and batch: 100, loss is 4.257243790626526 and perplexity is 70.61508502796099
At time: 168.01614475250244 and batch: 150, loss is 4.216518402099609 and perplexity is 67.79703091000393
At time: 169.03894209861755 and batch: 200, loss is 4.221976728439331 and perplexity is 68.16810101916631
At time: 170.03488564491272 and batch: 250, loss is 4.227113218307495 and perplexity is 68.51914657854472
At time: 171.03195118904114 and batch: 300, loss is 4.222048578262329 and perplexity is 68.17299906111826
At time: 172.02835607528687 and batch: 350, loss is 4.244565439224243 and perplexity is 69.72545361215344
At time: 173.02534890174866 and batch: 400, loss is 4.180562357902527 and perplexity is 65.40262255591624
At time: 174.02283430099487 and batch: 450, loss is 4.2220651817321775 and perplexity is 68.17413097884953
At time: 175.0199224948883 and batch: 500, loss is 4.238804664611816 and perplexity is 69.32493574337876
At time: 176.01796579360962 and batch: 550, loss is 4.200699090957642 and perplexity is 66.73296715149638
At time: 177.01564526557922 and batch: 600, loss is 4.17827190876007 and perplexity is 65.25299260048534
At time: 178.01291060447693 and batch: 650, loss is 4.240337023735046 and perplexity is 69.43124787451164
At time: 179.0104365348816 and batch: 700, loss is 4.277959723472595 and perplexity is 72.0931997897057
At time: 180.00811338424683 and batch: 750, loss is 4.237166147232056 and perplexity is 69.21143864019305
At time: 181.00593638420105 and batch: 800, loss is 4.232059779167176 and perplexity is 68.85892037020675
At time: 182.00462889671326 and batch: 850, loss is 4.233847131729126 and perplexity is 68.98210559286098
At time: 183.00266933441162 and batch: 900, loss is 4.19488525390625 and perplexity is 66.34611818260262
At time: 184.00081491470337 and batch: 950, loss is 4.276622858047485 and perplexity is 71.9968852776364
At time: 184.99794554710388 and batch: 1000, loss is 4.257790031433106 and perplexity is 70.65366840591174
At time: 185.99454355239868 and batch: 1050, loss is 4.209734344482422 and perplexity is 67.33864855023225
At time: 186.9918885231018 and batch: 1100, loss is 4.234995131492615 and perplexity is 69.06134250704368
At time: 187.9883110523224 and batch: 1150, loss is 4.206327357292175 and perplexity is 67.10961701251209
At time: 188.98596739768982 and batch: 1200, loss is 4.271702070236206 and perplexity is 71.64347412588506
At time: 189.98406434059143 and batch: 1250, loss is 4.276207408905029 and perplexity is 71.9669804457868
At time: 190.98121404647827 and batch: 1300, loss is 4.2476891422271725 and perplexity is 69.94359574922949
At time: 191.97847747802734 and batch: 1350, loss is 4.1439777135849 and perplexity is 63.053130584236854
At time: 192.97543740272522 and batch: 1400, loss is 4.161302371025085 and perplexity is 64.15502185620747
At time: 193.9736590385437 and batch: 1450, loss is 4.10592408657074 and perplexity is 60.69880959394379
At time: 194.97219491004944 and batch: 1500, loss is 4.115134124755859 and perplexity is 61.26043025200726
At time: 195.97004294395447 and batch: 1550, loss is 4.124415559768677 and perplexity is 61.8316617776657
At time: 196.9676079750061 and batch: 1600, loss is 4.200488519668579 and perplexity is 66.71891658395532
At time: 197.96515560150146 and batch: 1650, loss is 4.175471792221069 and perplexity is 65.07053219110777
At time: 198.96333980560303 and batch: 1700, loss is 4.173166227340698 and perplexity is 64.92068066992277
At time: 199.96375823020935 and batch: 1750, loss is 4.165768446922303 and perplexity is 64.4421838192589
At time: 200.96334838867188 and batch: 1800, loss is 4.123676991462707 and perplexity is 61.78601173188489
At time: 201.9639801979065 and batch: 1850, loss is 4.169442648887634 and perplexity is 64.67939292792909
At time: 202.95975303649902 and batch: 1900, loss is 4.267974061965942 and perplexity is 71.37688389588135
At time: 203.95426607131958 and batch: 1950, loss is 4.1947667694091795 and perplexity is 66.3382576618413
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473723087754361 and perplexity of 87.68256595369775
finished 5 epochs...
Completing Train Step...
At time: 207.1913480758667 and batch: 50, loss is 4.186293659210205 and perplexity is 65.77854091377701
At time: 208.18437027931213 and batch: 100, loss is 4.150383453369141 and perplexity is 63.458328943408134
At time: 209.17535734176636 and batch: 150, loss is 4.1099857997894285 and perplexity is 60.94585211954388
At time: 210.16912865638733 and batch: 200, loss is 4.112684555053711 and perplexity is 61.110552201431155
At time: 211.16133379936218 and batch: 250, loss is 4.117795004844665 and perplexity is 61.42365397416683
At time: 212.15153193473816 and batch: 300, loss is 4.111346931457519 and perplexity is 61.02886393108914
At time: 213.1473729610443 and batch: 350, loss is 4.13964509010315 and perplexity is 62.780536061205524
At time: 214.13779497146606 and batch: 400, loss is 4.072372379302979 and perplexity is 58.69604683304559
At time: 215.13093185424805 and batch: 450, loss is 4.122672662734986 and perplexity is 61.72398941594142
At time: 216.1268448829651 and batch: 500, loss is 4.13745304107666 and perplexity is 62.643068770815205
At time: 217.1176404953003 and batch: 550, loss is 4.102684035301208 and perplexity is 60.502460601033256
At time: 218.1099238395691 and batch: 600, loss is 4.082740144729614 and perplexity is 59.307759244041655
At time: 219.13052558898926 and batch: 650, loss is 4.141753606796264 and perplexity is 62.91304952382277
At time: 220.1244158744812 and batch: 700, loss is 4.1776576375961305 and perplexity is 65.21292187717499
At time: 221.11762261390686 and batch: 750, loss is 4.1367635869979855 and perplexity is 62.5998941367245
At time: 222.10897397994995 and batch: 800, loss is 4.134099931716919 and perplexity is 62.433371476052585
At time: 223.1020770072937 and batch: 850, loss is 4.134109420776367 and perplexity is 62.433963912836916
At time: 224.09281849861145 and batch: 900, loss is 4.098967247009277 and perplexity is 60.278003152643926
At time: 225.0884063243866 and batch: 950, loss is 4.179537410736084 and perplexity is 65.33562266478926
At time: 226.08209371566772 and batch: 1000, loss is 4.157530131340027 and perplexity is 63.9134696196685
At time: 227.0755820274353 and batch: 1050, loss is 4.114293198585511 and perplexity is 61.20893640729686
At time: 228.0693461894989 and batch: 1100, loss is 4.139757146835327 and perplexity is 62.787571437094165
At time: 229.06767463684082 and batch: 1150, loss is 4.108667287826538 and perplexity is 60.86554723754352
At time: 230.0620276927948 and batch: 1200, loss is 4.176387214660645 and perplexity is 65.13012648924789
At time: 231.056711435318 and batch: 1250, loss is 4.183075261116028 and perplexity is 65.56717968778729
At time: 232.0514006614685 and batch: 1300, loss is 4.150911440849304 and perplexity is 63.49184299332316
At time: 233.0494565963745 and batch: 1350, loss is 4.049985070228576 and perplexity is 57.396600120929065
At time: 234.04413080215454 and batch: 1400, loss is 4.070723066329956 and perplexity is 58.59931847113673
At time: 235.0377917289734 and batch: 1450, loss is 4.014332442283631 and perplexity is 55.38630950046697
At time: 236.0316641330719 and batch: 1500, loss is 4.025091619491577 and perplexity is 55.98543790403323
At time: 237.02817153930664 and batch: 1550, loss is 4.03532651424408 and perplexity is 56.56138532157495
At time: 238.0248532295227 and batch: 1600, loss is 4.109305529594422 and perplexity is 60.904406571521484
At time: 239.01794171333313 and batch: 1650, loss is 4.088242874145508 and perplexity is 59.635013365092114
At time: 240.0127079486847 and batch: 1700, loss is 4.083321790695191 and perplexity is 59.34226539714288
At time: 241.00963234901428 and batch: 1750, loss is 4.079934844970703 and perplexity is 59.141616350600195
At time: 242.0025451183319 and batch: 1800, loss is 4.0299817943573 and perplexity is 56.25988699040336
At time: 242.99563813209534 and batch: 1850, loss is 4.083409252166748 and perplexity is 59.347455785976294
At time: 243.99088263511658 and batch: 1900, loss is 4.175623993873597 and perplexity is 65.08043678736695
At time: 244.98882937431335 and batch: 1950, loss is 4.108230285644531 and perplexity is 60.83895467151953
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.472083938953489 and perplexity of 87.5389589096681
finished 6 epochs...
Completing Train Step...
At time: 248.21962070465088 and batch: 50, loss is 4.099799461364746 and perplexity is 60.32818825167007
At time: 249.2394814491272 and batch: 100, loss is 4.066520476341248 and perplexity is 58.353566321448056
At time: 250.23301911354065 and batch: 150, loss is 4.0246219730377195 and perplexity is 55.959150714979685
At time: 251.22718477249146 and batch: 200, loss is 4.0244619750976565 and perplexity is 55.9501980823581
At time: 252.2250063419342 and batch: 250, loss is 4.034937920570374 and perplexity is 56.53941019503706
At time: 253.21968245506287 and batch: 300, loss is 4.024321064949036 and perplexity is 55.942314687069214
At time: 254.21454334259033 and batch: 350, loss is 4.054599900245666 and perplexity is 57.66208779311896
At time: 255.20931100845337 and batch: 400, loss is 3.990336847305298 and perplexity is 54.07310067419011
At time: 256.20701575279236 and batch: 450, loss is 4.041855616569519 and perplexity is 56.93188860474541
At time: 257.20629239082336 and batch: 500, loss is 4.054935607910156 and perplexity is 57.6814486475534
At time: 258.2004294395447 and batch: 550, loss is 4.022076420783996 and perplexity is 55.81688492208717
At time: 259.20192980766296 and batch: 600, loss is 4.0052945518493654 and perplexity is 54.887989377020084
At time: 260.1961917877197 and batch: 650, loss is 4.062254376411438 and perplexity is 58.10515442799043
At time: 261.1913161277771 and batch: 700, loss is 4.100130195617676 and perplexity is 60.3481441498097
At time: 262.18756437301636 and batch: 750, loss is 4.057315950393677 and perplexity is 57.818913792435545
At time: 263.18155097961426 and batch: 800, loss is 4.0544942235946655 and perplexity is 57.65599457875219
At time: 264.1765434741974 and batch: 850, loss is 4.060316066741944 and perplexity is 57.9926377266478
At time: 265.18847846984863 and batch: 900, loss is 4.020967907905579 and perplexity is 55.75504546756613
At time: 266.188081741333 and batch: 950, loss is 4.10242290019989 and perplexity is 60.4866633475527
At time: 267.19176506996155 and batch: 1000, loss is 4.078108310699463 and perplexity is 59.033690756382946
At time: 268.1870062351227 and batch: 1050, loss is 4.039840111732483 and perplexity is 56.81725766629145
At time: 269.2159540653229 and batch: 1100, loss is 4.064899544715882 and perplexity is 58.25905579858567
At time: 270.21550846099854 and batch: 1150, loss is 4.033967351913452 and perplexity is 56.48456143716916
At time: 271.20923805236816 and batch: 1200, loss is 4.099720349311829 and perplexity is 60.32341575363223
At time: 272.20592522621155 and batch: 1250, loss is 4.104966082572937 and perplexity is 60.64068773662198
At time: 273.2013900279999 and batch: 1300, loss is 4.074799175262451 and perplexity is 58.83866314268605
At time: 274.1939344406128 and batch: 1350, loss is 3.9756787252426147 and perplexity is 53.28627137233835
At time: 275.1867275238037 and batch: 1400, loss is 3.9987276792526245 and perplexity is 54.52872784709762
At time: 276.1852295398712 and batch: 1450, loss is 3.9390072631835937 and perplexity is 51.367581490779635
At time: 277.1806671619415 and batch: 1500, loss is 3.9536592769622803 and perplexity is 52.125760866010886
At time: 278.17609190940857 and batch: 1550, loss is 3.9647246551513673 and perplexity is 52.705755133356895
At time: 279.17051792144775 and batch: 1600, loss is 4.034522843360901 and perplexity is 56.515946844316005
At time: 280.1665143966675 and batch: 1650, loss is 4.017118868827819 and perplexity is 55.54085459773149
At time: 281.164669752121 and batch: 1700, loss is 4.010326800346374 and perplexity is 55.16489552498682
At time: 282.17569303512573 and batch: 1750, loss is 4.006988677978516 and perplexity is 54.98105536450201
At time: 283.1764032840729 and batch: 1800, loss is 3.955704860687256 and perplexity is 52.2324976063406
At time: 284.17138862609863 and batch: 1850, loss is 4.0099922561645505 and perplexity is 55.1464435168261
At time: 285.1662187576294 and batch: 1900, loss is 4.101634993553161 and perplexity is 60.43902427349875
At time: 286.1643271446228 and batch: 1950, loss is 4.036264815330505 and perplexity is 56.614481837235545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4819855446039245 and perplexity of 88.41004059666227
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 289.4432611465454 and batch: 50, loss is 4.063368716239929 and perplexity is 58.169939405346526
At time: 290.46901416778564 and batch: 100, loss is 4.0578040027618405 and perplexity is 57.84713933744838
At time: 291.4689722061157 and batch: 150, loss is 4.020811100006103 and perplexity is 55.74630332143788
At time: 292.46883940696716 and batch: 200, loss is 4.01692898273468 and perplexity is 55.5303091630897
At time: 293.4689621925354 and batch: 250, loss is 4.021941618919373 and perplexity is 55.809361209038855
At time: 294.4961130619049 and batch: 300, loss is 4.019668841362 and perplexity is 55.68266297837774
At time: 295.49494218826294 and batch: 350, loss is 4.042652254104614 and perplexity is 56.97726075433096
At time: 296.4950144290924 and batch: 400, loss is 3.9655540084838865 and perplexity is 52.74948495825114
At time: 297.49533915519714 and batch: 450, loss is 4.001087741851807 and perplexity is 54.65757103746433
At time: 298.4960045814514 and batch: 500, loss is 4.013984956741333 and perplexity is 55.367066902130325
At time: 299.49633407592773 and batch: 550, loss is 3.9762158155441285 and perplexity is 53.31489859891097
At time: 300.49648237228394 and batch: 600, loss is 3.9541110610961914 and perplexity is 52.14931577820535
At time: 301.49770283699036 and batch: 650, loss is 3.9963116359710695 and perplexity is 54.39714310175878
At time: 302.49708437919617 and batch: 700, loss is 4.039229464530945 and perplexity is 56.7825729580363
At time: 303.49692606925964 and batch: 750, loss is 3.9816736125946046 and perplexity is 53.60667600187776
At time: 304.49800658226013 and batch: 800, loss is 3.9832829999923707 and perplexity is 53.69301937200049
At time: 305.49869871139526 and batch: 850, loss is 3.982770118713379 and perplexity is 53.665488288244276
At time: 306.498939037323 and batch: 900, loss is 3.9352624940872194 and perplexity is 51.1755814812812
At time: 307.49998021125793 and batch: 950, loss is 4.01567319393158 and perplexity is 55.46061859008913
At time: 308.5002703666687 and batch: 1000, loss is 3.973468317985535 and perplexity is 53.168617091236506
At time: 309.5002691745758 and batch: 1050, loss is 3.9329371309280394 and perplexity is 51.05671792348519
At time: 310.50063276290894 and batch: 1100, loss is 3.953105955123901 and perplexity is 52.09692652225332
At time: 311.5009415149689 and batch: 1150, loss is 3.92163254737854 and perplexity is 50.482793092537996
At time: 312.50061225891113 and batch: 1200, loss is 3.9644800853729247 and perplexity is 52.69286647465373
At time: 313.5009641647339 and batch: 1250, loss is 3.9657488822937013 and perplexity is 52.75976545301778
At time: 314.50031423568726 and batch: 1300, loss is 3.943231348991394 and perplexity is 51.58502148201311
At time: 315.4999885559082 and batch: 1350, loss is 3.8375675106048583 and perplexity is 46.41243925079554
At time: 316.4991555213928 and batch: 1400, loss is 3.8502295923233034 and perplexity is 47.00385371680465
At time: 317.49908351898193 and batch: 1450, loss is 3.7937254810333254 and perplexity is 44.42158415947552
At time: 318.49890089035034 and batch: 1500, loss is 3.796902770996094 and perplexity is 44.562948872372324
At time: 319.5008990764618 and batch: 1550, loss is 3.803873448371887 and perplexity is 44.87466799638771
At time: 320.50081491470337 and batch: 1600, loss is 3.8649075269699096 and perplexity is 47.698861370496914
At time: 321.50084114074707 and batch: 1650, loss is 3.8334767913818357 and perplexity is 46.22296679688867
At time: 322.4997489452362 and batch: 1700, loss is 3.806866374015808 and perplexity is 45.00917572640821
At time: 323.49885082244873 and batch: 1750, loss is 3.8089492321014404 and perplexity is 45.10302115142131
At time: 324.4987049102783 and batch: 1800, loss is 3.750896997451782 and perplexity is 42.55924041370522
At time: 325.49755597114563 and batch: 1850, loss is 3.7939437675476073 and perplexity is 44.43128185063967
At time: 326.4969036579132 and batch: 1900, loss is 3.8794318151474 and perplexity is 48.39670898085458
At time: 327.4963912963867 and batch: 1950, loss is 3.813066725730896 and perplexity is 45.289115411730855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.398728197674418 and perplexity of 81.34734510548518
finished 8 epochs...
Completing Train Step...
At time: 330.76971673965454 and batch: 50, loss is 3.981850142478943 and perplexity is 53.61614001750835
At time: 331.76324915885925 and batch: 100, loss is 3.9629609107971193 and perplexity is 52.6128775855063
At time: 332.7593493461609 and batch: 150, loss is 3.9211985731124877 and perplexity is 50.46088961257447
At time: 333.7535479068756 and batch: 200, loss is 3.914463381767273 and perplexity is 50.12216782405974
At time: 334.7478094100952 and batch: 250, loss is 3.9181481170654298 and perplexity is 50.307195424579085
At time: 335.7424702644348 and batch: 300, loss is 3.9137006282806395 and perplexity is 50.08395154244816
At time: 336.7404851913452 and batch: 350, loss is 3.9396927690505983 and perplexity is 51.40280634130685
At time: 337.7405252456665 and batch: 400, loss is 3.8680743885040285 and perplexity is 47.850156498708294
At time: 338.73463773727417 and batch: 450, loss is 3.9150307083129885 and perplexity is 50.150611528066406
At time: 339.7323999404907 and batch: 500, loss is 3.9289719438552857 and perplexity is 50.85466933056131
At time: 340.7321150302887 and batch: 550, loss is 3.8940663862228395 and perplexity is 49.110182010428794
At time: 341.7239422798157 and batch: 600, loss is 3.873559398651123 and perplexity is 48.113336204501664
At time: 342.7218794822693 and batch: 650, loss is 3.9198606538772585 and perplexity is 50.39342216079982
At time: 343.71993017196655 and batch: 700, loss is 3.959920539855957 and perplexity is 52.45315784802418
At time: 344.7411165237427 and batch: 750, loss is 3.9091051959991456 and perplexity is 49.85432216198835
At time: 345.73543190956116 and batch: 800, loss is 3.91212685585022 and perplexity is 50.00519279073578
At time: 346.7293870449066 and batch: 850, loss is 3.9135450077056886 and perplexity is 50.0761580555425
At time: 347.7230088710785 and batch: 900, loss is 3.8678200101852416 and perplexity is 47.837986004365035
At time: 348.72083353996277 and batch: 950, loss is 3.9525702571868897 and perplexity is 52.069025780042956
At time: 349.72019720077515 and batch: 1000, loss is 3.913039050102234 and perplexity is 50.05082805111702
At time: 350.719975233078 and batch: 1050, loss is 3.8775963830947875 and perplexity is 48.307961579776844
At time: 351.7166736125946 and batch: 1100, loss is 3.896225733757019 and perplexity is 49.21634253834293
At time: 352.71060276031494 and batch: 1150, loss is 3.8683711385726927 and perplexity is 47.86435814300012
At time: 353.7043607234955 and batch: 1200, loss is 3.9140282487869262 and perplexity is 50.10036276018828
At time: 354.7005708217621 and batch: 1250, loss is 3.919281268119812 and perplexity is 50.36423338632749
At time: 355.69774079322815 and batch: 1300, loss is 3.8976455163955688 and perplexity is 49.28626867522303
At time: 356.6922607421875 and batch: 1350, loss is 3.7923850631713867 and perplexity is 44.362080563363364
At time: 357.68634390830994 and batch: 1400, loss is 3.8111044788360595 and perplexity is 45.20033411953881
At time: 358.68113255500793 and batch: 1450, loss is 3.755646324157715 and perplexity is 42.76184889688823
At time: 359.6803047657013 and batch: 1500, loss is 3.7601142644882204 and perplexity is 42.95333373906338
At time: 360.6786251068115 and batch: 1550, loss is 3.7711805963516234 and perplexity is 43.43130942576587
At time: 361.6788737773895 and batch: 1600, loss is 3.8352980756759645 and perplexity is 46.307228669464514
At time: 362.67865324020386 and batch: 1650, loss is 3.8049609756469724 and perplexity is 44.923496968401054
At time: 363.67918705940247 and batch: 1700, loss is 3.785037751197815 and perplexity is 44.03733298943928
At time: 364.6790008544922 and batch: 1750, loss is 3.788559355735779 and perplexity is 44.19268845082769
At time: 365.6761109828949 and batch: 1800, loss is 3.7346821308135985 and perplexity is 41.874712766473024
At time: 366.6706564426422 and batch: 1850, loss is 3.781627974510193 and perplexity is 43.88743122902788
At time: 367.66463255882263 and batch: 1900, loss is 3.871049418449402 and perplexity is 47.99272411349123
At time: 368.6600205898285 and batch: 1950, loss is 3.808846592903137 and perplexity is 45.09839205105691
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.398636786882268 and perplexity of 81.33990942008583
finished 9 epochs...
Completing Train Step...
At time: 371.8999397754669 and batch: 50, loss is 3.9371289825439453 and perplexity is 51.27118931108121
At time: 372.9200508594513 and batch: 100, loss is 3.9176486253738405 and perplexity is 50.28207367301275
At time: 373.91865515708923 and batch: 150, loss is 3.876735692024231 and perplexity is 48.26640123648214
At time: 374.9144027233124 and batch: 200, loss is 3.867526984214783 and perplexity is 47.82397028567638
At time: 375.90779066085815 and batch: 250, loss is 3.8706804084777833 and perplexity is 47.975017586871566
At time: 376.900018453598 and batch: 300, loss is 3.8675863361358642 and perplexity is 47.82680881442182
At time: 377.898898601532 and batch: 350, loss is 3.892759470939636 and perplexity is 49.04604108550553
At time: 378.89769434928894 and batch: 400, loss is 3.8230466842651367 and perplexity is 45.743361815506674
At time: 379.893239736557 and batch: 450, loss is 3.8739497423172 and perplexity is 48.13212060649057
At time: 380.88826084136963 and batch: 500, loss is 3.888322377204895 and perplexity is 48.828901294943606
At time: 381.8833453655243 and batch: 550, loss is 3.8537098217010497 and perplexity is 47.1677228951429
At time: 382.88036465644836 and batch: 600, loss is 3.8338773107528685 and perplexity is 46.241483698418776
At time: 383.8776664733887 and batch: 650, loss is 3.8810821390151977 and perplexity is 48.47664516696381
At time: 384.878134727478 and batch: 700, loss is 3.920468010902405 and perplexity is 50.42403825627954
At time: 385.87219762802124 and batch: 750, loss is 3.8719553661346438 and perplexity is 48.03622271156232
At time: 386.86631989479065 and batch: 800, loss is 3.8745182037353514 and perplexity is 48.15948963841151
At time: 387.8605899810791 and batch: 850, loss is 3.8762424659729002 and perplexity is 48.2426008599537
At time: 388.8588514328003 and batch: 900, loss is 3.832951226234436 and perplexity is 46.198679999237044
At time: 389.8577501773834 and batch: 950, loss is 3.918316903114319 and perplexity is 50.31568729395987
At time: 390.8581655025482 and batch: 1000, loss is 3.879800271987915 and perplexity is 48.41454436491984
At time: 391.8538484573364 and batch: 1050, loss is 3.8467869329452515 and perplexity is 46.84231368220581
At time: 392.84745812416077 and batch: 1100, loss is 3.863638982772827 and perplexity is 47.638391619083066
At time: 393.8427143096924 and batch: 1150, loss is 3.83724627494812 and perplexity is 46.39753231483987
At time: 394.83812952041626 and batch: 1200, loss is 3.884501643180847 and perplexity is 48.642694999293816
At time: 395.859338760376 and batch: 1250, loss is 3.8901997423171997 and perplexity is 48.920657073306046
At time: 396.8574814796448 and batch: 1300, loss is 3.8698563385009765 and perplexity is 47.935499100476925
At time: 397.8562853336334 and batch: 1350, loss is 3.7635048627853394 and perplexity is 43.09921841770672
At time: 398.8573944568634 and batch: 1400, loss is 3.7856610012054444 and perplexity is 44.06478781228148
At time: 399.85625886917114 and batch: 1450, loss is 3.730262041091919 and perplexity is 41.690031234126906
At time: 400.85726618766785 and batch: 1500, loss is 3.7364411640167234 and perplexity is 41.94843659892547
At time: 401.856187582016 and batch: 1550, loss is 3.7480219125747682 and perplexity is 42.4370547165064
At time: 402.85406827926636 and batch: 1600, loss is 3.8135309505462645 and perplexity is 45.31014462373444
At time: 403.8486406803131 and batch: 1650, loss is 3.7833752965927125 and perplexity is 43.964183742912645
At time: 404.84286069869995 and batch: 1700, loss is 3.766334881782532 and perplexity is 43.22136277850246
At time: 405.83857440948486 and batch: 1750, loss is 3.768914794921875 and perplexity is 43.333014103666635
At time: 406.83694076538086 and batch: 1800, loss is 3.7179490423202513 and perplexity is 41.179849311150335
At time: 407.83740854263306 and batch: 1850, loss is 3.7668909788131715 and perplexity is 43.245404734214304
At time: 408.836608171463 and batch: 1900, loss is 3.85767897605896 and perplexity is 47.355310904632894
At time: 409.8355050086975 and batch: 1950, loss is 3.7961527633666994 and perplexity is 44.52953885118125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.402293786337209 and perplexity of 81.63791399366444
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 413.0584683418274 and batch: 50, loss is 3.9321896171569826 and perplexity is 51.01856658483444
At time: 414.08227133750916 and batch: 100, loss is 3.9473467874526977 and perplexity is 51.79775390679777
At time: 415.0769348144531 and batch: 150, loss is 3.920516862869263 and perplexity is 50.426501629895114
At time: 416.0728118419647 and batch: 200, loss is 3.914553461074829 and perplexity is 50.12668299758935
At time: 417.0674171447754 and batch: 250, loss is 3.9188793802261355 and perplexity is 50.34399667737178
At time: 418.06159806251526 and batch: 300, loss is 3.9161709690093995 and perplexity is 50.207828914461786
At time: 419.05694675445557 and batch: 350, loss is 3.935545563697815 and perplexity is 51.190069783705425
At time: 420.05974864959717 and batch: 400, loss is 3.867597107887268 and perplexity is 47.82732399569149
At time: 421.0988926887512 and batch: 450, loss is 3.9171076440811157 and perplexity is 50.25487936826453
At time: 422.09653210639954 and batch: 500, loss is 3.9289496088027955 and perplexity is 50.85353350153689
At time: 423.09700417518616 and batch: 550, loss is 3.894495339393616 and perplexity is 49.13125249752262
At time: 424.09510374069214 and batch: 600, loss is 3.8635507297515868 and perplexity is 47.63418757260828
At time: 425.09557843208313 and batch: 650, loss is 3.903086848258972 and perplexity is 49.55518258079323
At time: 426.09468245506287 and batch: 700, loss is 3.9493383502960206 and perplexity is 51.901015180373314
At time: 427.0938584804535 and batch: 750, loss is 3.894007453918457 and perplexity is 49.10728791951283
At time: 428.10287284851074 and batch: 800, loss is 3.9015778207778933 and perplexity is 49.48045884271591
At time: 429.1096770763397 and batch: 850, loss is 3.901893754005432 and perplexity is 49.49609383345469
At time: 430.11157846450806 and batch: 900, loss is 3.852201910018921 and perplexity is 47.09665173275471
At time: 431.1049156188965 and batch: 950, loss is 3.930412850379944 and perplexity is 50.92799897330206
At time: 432.09916281700134 and batch: 1000, loss is 3.886003432273865 and perplexity is 48.71580094921777
At time: 433.0963132381439 and batch: 1050, loss is 3.844435954093933 and perplexity is 46.73231774311861
At time: 434.09465622901917 and batch: 1100, loss is 3.863675413131714 and perplexity is 47.64012713439907
At time: 435.09499621391296 and batch: 1150, loss is 3.842143664360046 and perplexity is 46.62531641679027
At time: 436.0950195789337 and batch: 1200, loss is 3.8811871147155763 and perplexity is 48.4817343038554
At time: 437.092702627182 and batch: 1250, loss is 3.8845093488693236 and perplexity is 48.64306982619229
At time: 438.0853590965271 and batch: 1300, loss is 3.8692811012268065 and perplexity is 47.9079327439964
At time: 439.0788447856903 and batch: 1350, loss is 3.753178472518921 and perplexity is 42.65644910702521
At time: 440.08161330223083 and batch: 1400, loss is 3.7712232875823974 and perplexity is 43.43316360139762
At time: 441.07623529434204 and batch: 1450, loss is 3.7100187587738036 and perplexity is 40.85457290149402
At time: 442.0738637447357 and batch: 1500, loss is 3.7236062240600587 and perplexity is 41.41347140096762
At time: 443.07409286499023 and batch: 1550, loss is 3.7387306451797486 and perplexity is 42.04458677935113
At time: 444.073961019516 and batch: 1600, loss is 3.8062013006210327 and perplexity is 44.979251273193675
At time: 445.074321269989 and batch: 1650, loss is 3.767604284286499 and perplexity is 43.276262922456375
At time: 446.07308530807495 and batch: 1700, loss is 3.7313020038604736 and perplexity is 41.73340986660206
At time: 447.0740559101105 and batch: 1750, loss is 3.7320939016342165 and perplexity is 41.7664715499751
At time: 448.0738627910614 and batch: 1800, loss is 3.686612982749939 and perplexity is 39.909443805715476
At time: 449.0735423564911 and batch: 1850, loss is 3.723198890686035 and perplexity is 41.396605747136874
At time: 450.0688238143921 and batch: 1900, loss is 3.8118985414505007 and perplexity is 45.23624026900217
At time: 451.0618007183075 and batch: 1950, loss is 3.7556268310546876 and perplexity is 42.76101534388634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3716609511264535 and perplexity of 79.17502840021615
finished 11 epochs...
Completing Train Step...
At time: 454.33775997161865 and batch: 50, loss is 3.9294314432144164 and perplexity is 50.87804238806873
At time: 455.334440946579 and batch: 100, loss is 3.921839370727539 and perplexity is 50.49323519267006
At time: 456.33425283432007 and batch: 150, loss is 3.883002405166626 and perplexity is 48.569822661975536
At time: 457.334192276001 and batch: 200, loss is 3.873766932487488 and perplexity is 48.12332238594393
At time: 458.33493542671204 and batch: 250, loss is 3.877777500152588 and perplexity is 48.316711768026764
At time: 459.3347945213318 and batch: 300, loss is 3.8722819089889526 and perplexity is 48.05191115817243
At time: 460.33474040031433 and batch: 350, loss is 3.8941503667831423 and perplexity is 49.11430648421599
At time: 461.3419258594513 and batch: 400, loss is 3.8240109205245973 and perplexity is 45.78749049541638
At time: 462.3401234149933 and batch: 450, loss is 3.8762865352630613 and perplexity is 48.24472692397584
At time: 463.3361642360687 and batch: 500, loss is 3.889373154640198 and perplexity is 48.88023656886529
At time: 464.3368031978607 and batch: 550, loss is 3.856842346191406 and perplexity is 47.31570860568581
At time: 465.34109258651733 and batch: 600, loss is 3.828085169792175 and perplexity is 45.9744206865497
At time: 466.34456968307495 and batch: 650, loss is 3.871589102745056 and perplexity is 48.01863202341818
At time: 467.3446555137634 and batch: 700, loss is 3.9180824327468873 and perplexity is 50.303891139250894
At time: 468.34544253349304 and batch: 750, loss is 3.8665135288238526 and perplexity is 47.77552737668459
At time: 469.34571051597595 and batch: 800, loss is 3.8737364625930786 and perplexity is 48.12185609573117
At time: 470.388249874115 and batch: 850, loss is 3.8743537521362303 and perplexity is 48.151570384512446
At time: 471.3876769542694 and batch: 900, loss is 3.8246791982650756 and perplexity is 45.81809948262008
At time: 472.3879590034485 and batch: 950, loss is 3.90564377784729 and perplexity is 49.68205382468477
At time: 473.388060092926 and batch: 1000, loss is 3.862049770355225 and perplexity is 47.56274422138055
At time: 474.38832092285156 and batch: 1050, loss is 3.8239866971969603 and perplexity is 45.786381383465674
At time: 475.3880217075348 and batch: 1100, loss is 3.8434091138839723 and perplexity is 46.68435574902162
At time: 476.38814520835876 and batch: 1150, loss is 3.8239885139465333 and perplexity is 45.78646456593006
At time: 477.38825821876526 and batch: 1200, loss is 3.8638599634170534 and perplexity is 47.64891994478822
At time: 478.38793992996216 and batch: 1250, loss is 3.870435185432434 and perplexity is 47.96325444931338
At time: 479.3881242275238 and batch: 1300, loss is 3.8558094787597654 and perplexity is 47.26686298113183
At time: 480.38815331459045 and batch: 1350, loss is 3.740042929649353 and perplexity is 42.09979745574605
At time: 481.38789892196655 and batch: 1400, loss is 3.7611133670806884 and perplexity is 42.99626997143616
At time: 482.38741421699524 and batch: 1450, loss is 3.70102303981781 and perplexity is 40.48870473645675
At time: 483.3876895904541 and batch: 1500, loss is 3.715443449020386 and perplexity is 41.07679851223522
At time: 484.38674998283386 and batch: 1550, loss is 3.7322117996215822 and perplexity is 41.77139602319725
At time: 485.3866882324219 and batch: 1600, loss is 3.801414661407471 and perplexity is 44.764466284471965
At time: 486.3869466781616 and batch: 1650, loss is 3.763053002357483 and perplexity is 43.07974798572236
At time: 487.38774728775024 and batch: 1700, loss is 3.730619120597839 and perplexity is 41.70492054805801
At time: 488.3880569934845 and batch: 1750, loss is 3.7326731729507445 and perplexity is 41.79067267776943
At time: 489.38824915885925 and batch: 1800, loss is 3.6883461141586302 and perplexity is 39.97867208980666
At time: 490.38919711112976 and batch: 1850, loss is 3.7263053178787233 and perplexity is 41.52540123224155
At time: 491.3942623138428 and batch: 1900, loss is 3.8150586080551148 and perplexity is 45.379415904320204
At time: 492.39640188217163 and batch: 1950, loss is 3.759515433311462 and perplexity is 42.92761964364416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370979344567587 and perplexity of 79.12108056924646
finished 12 epochs...
Completing Train Step...
At time: 495.7576129436493 and batch: 50, loss is 3.915452175140381 and perplexity is 50.17175280205882
At time: 496.7930374145508 and batch: 100, loss is 3.9057827520370485 and perplexity is 49.68895882765807
At time: 497.79115200042725 and batch: 150, loss is 3.8658254861831667 and perplexity is 47.742667082606275
At time: 498.79055666923523 and batch: 200, loss is 3.856187496185303 and perplexity is 47.28473405656534
At time: 499.798935174942 and batch: 250, loss is 3.859932417869568 and perplexity is 47.46214366767918
At time: 500.7914915084839 and batch: 300, loss is 3.8541977071762084 and perplexity is 47.1907409566721
At time: 501.7886712551117 and batch: 350, loss is 3.8757556200027468 and perplexity is 48.21911986041409
At time: 502.79043436050415 and batch: 400, loss is 3.8052770853042603 and perplexity is 44.937699964365734
At time: 503.79691338539124 and batch: 450, loss is 3.8587180471420286 and perplexity is 47.40454201170406
At time: 504.78939056396484 and batch: 500, loss is 3.872301664352417 and perplexity is 48.05286045051928
At time: 505.7877883911133 and batch: 550, loss is 3.839988293647766 and perplexity is 46.52492979938545
At time: 506.78113198280334 and batch: 600, loss is 3.8118239498138426 and perplexity is 45.232866149646355
At time: 507.77227425575256 and batch: 650, loss is 3.8562058353424074 and perplexity is 47.285601226683404
At time: 508.76871395111084 and batch: 700, loss is 3.903190951347351 and perplexity is 49.56034169688038
At time: 509.76858496665955 and batch: 750, loss is 3.8526759004592894 and perplexity is 47.118980386815636
At time: 510.7676885128021 and batch: 800, loss is 3.8601564979553222 and perplexity is 47.47278018057317
At time: 511.7643699645996 and batch: 850, loss is 3.8609548377990723 and perplexity is 47.510694724816844
At time: 512.7569665908813 and batch: 900, loss is 3.811479997634888 and perplexity is 45.217310882061255
At time: 513.7498579025269 and batch: 950, loss is 3.8931577968597413 and perplexity is 49.06558128637432
At time: 514.7468872070312 and batch: 1000, loss is 3.8492361974716185 and perplexity is 46.95718351531994
At time: 515.7400147914886 and batch: 1050, loss is 3.8128683280944826 and perplexity is 45.280131049545496
At time: 516.7304856777191 and batch: 1100, loss is 3.832360463142395 and perplexity is 46.17139558429868
At time: 517.7279722690582 and batch: 1150, loss is 3.813720693588257 and perplexity is 45.31874272409753
At time: 518.7233891487122 and batch: 1200, loss is 3.8538404512405395 and perplexity is 47.173884795517814
At time: 519.7140889167786 and batch: 1250, loss is 3.861905083656311 and perplexity is 47.55586302274883
At time: 520.7087485790253 and batch: 1300, loss is 3.8472853755950926 and perplexity is 46.86566770900024
At time: 521.7059299945831 and batch: 1350, loss is 3.731307806968689 and perplexity is 41.73365205079842
At time: 522.7081627845764 and batch: 1400, loss is 3.7537437772750852 and perplexity is 42.680569817720375
At time: 523.7046389579773 and batch: 1450, loss is 3.6941207313537596 and perplexity is 40.21020147048117
At time: 524.6996917724609 and batch: 1500, loss is 3.708852882385254 and perplexity is 40.806969274948166
At time: 525.6904292106628 and batch: 1550, loss is 3.7264112710952757 and perplexity is 41.529801215162784
At time: 526.692137002945 and batch: 1600, loss is 3.7966046857833864 and perplexity is 44.54966729589795
At time: 527.6881909370422 and batch: 1650, loss is 3.7580265951156617 and perplexity is 42.86375491778261
At time: 528.6845123767853 and batch: 1700, loss is 3.727259244918823 and perplexity is 41.56503233491293
At time: 529.6763322353363 and batch: 1750, loss is 3.7295296478271482 and perplexity is 41.659508914577934
At time: 530.6693568229675 and batch: 1800, loss is 3.685616660118103 and perplexity is 39.86970092528106
At time: 531.6656978130341 and batch: 1850, loss is 3.7242089796066282 and perplexity is 41.43844112512113
At time: 532.6600332260132 and batch: 1900, loss is 3.8132191562652586 and perplexity is 45.29601938196845
At time: 533.65016746521 and batch: 1950, loss is 3.757985095977783 and perplexity is 42.861976145816286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371783305323401 and perplexity of 79.18471638990536
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 536.9129421710968 and batch: 50, loss is 3.9169214248657225 and perplexity is 50.245521815364015
At time: 537.9463365077972 and batch: 100, loss is 3.928593134880066 and perplexity is 50.83540877365329
At time: 538.9468703269958 and batch: 150, loss is 3.8991423797607423 and perplexity is 49.36009872817452
At time: 539.9470863342285 and batch: 200, loss is 3.8969034576416015 and perplexity is 49.24970893451765
At time: 540.9476823806763 and batch: 250, loss is 3.90599063873291 and perplexity is 49.69928957490481
At time: 541.9465494155884 and batch: 300, loss is 3.902111501693726 and perplexity is 49.50687266695694
At time: 542.9523911476135 and batch: 350, loss is 3.9258678483963014 and perplexity is 50.69705633187636
At time: 543.9485592842102 and batch: 400, loss is 3.8559145879745484 and perplexity is 47.27183142509508
At time: 544.9461362361908 and batch: 450, loss is 3.903570222854614 and perplexity is 49.57914208737708
At time: 545.9378020763397 and batch: 500, loss is 3.922114176750183 and perplexity is 50.50711294456134
At time: 546.9724810123444 and batch: 550, loss is 3.8971973133087157 and perplexity is 49.26418336718466
At time: 547.9668049812317 and batch: 600, loss is 3.859942469596863 and perplexity is 47.462620746601885
At time: 548.9623470306396 and batch: 650, loss is 3.892943272590637 and perplexity is 49.05505665734522
At time: 549.9553408622742 and batch: 700, loss is 3.9322353553771974 and perplexity is 51.020900136633784
At time: 550.9542498588562 and batch: 750, loss is 3.880247502326965 and perplexity is 48.43620166054997
At time: 551.9468050003052 and batch: 800, loss is 3.8836455297470094 and perplexity is 48.601069155411324
At time: 552.9409017562866 and batch: 850, loss is 3.8873945331573485 and perplexity is 48.783616701297966
At time: 553.932829618454 and batch: 900, loss is 3.8366809606552126 and perplexity is 46.37131053913727
At time: 554.9265236854553 and batch: 950, loss is 3.927389979362488 and perplexity is 50.77428265058881
At time: 555.9211416244507 and batch: 1000, loss is 3.8818022489547728 and perplexity is 48.511566252987315
At time: 556.9104697704315 and batch: 1050, loss is 3.833761148452759 and perplexity is 46.2361124932837
At time: 557.9059188365936 and batch: 1100, loss is 3.847226610183716 and perplexity is 46.86291370967863
At time: 558.9029352664948 and batch: 1150, loss is 3.830811038017273 and perplexity is 46.09991185756056
At time: 559.8985633850098 and batch: 1200, loss is 3.868669686317444 and perplexity is 47.87865007248318
At time: 560.8948135375977 and batch: 1250, loss is 3.875772099494934 and perplexity is 48.21991449357067
At time: 561.8867454528809 and batch: 1300, loss is 3.859716143608093 and perplexity is 47.45187993753977
At time: 562.8859260082245 and batch: 1350, loss is 3.7404070472717286 and perplexity is 42.11512952506705
At time: 563.8819351196289 and batch: 1400, loss is 3.7597854423522947 and perplexity is 42.93921205400674
At time: 564.8747365474701 and batch: 1450, loss is 3.6914339303970336 and perplexity is 40.102309669502176
At time: 565.867748260498 and batch: 1500, loss is 3.7043344736099244 and perplexity is 40.623002638103515
At time: 566.8656499385834 and batch: 1550, loss is 3.7311270427703858 and perplexity is 41.726108782440164
At time: 567.8656487464905 and batch: 1600, loss is 3.803443851470947 and perplexity is 44.85539411838131
At time: 568.8654246330261 and batch: 1650, loss is 3.766923675537109 and perplexity is 43.24681874039103
At time: 569.865690946579 and batch: 1700, loss is 3.7327867126464844 and perplexity is 41.79541784740749
At time: 570.865965127945 and batch: 1750, loss is 3.7308430433273316 and perplexity is 41.714260273349765
At time: 571.8662655353546 and batch: 1800, loss is 3.6824270057678223 and perplexity is 39.74273295988848
At time: 572.8651344776154 and batch: 1850, loss is 3.714740114212036 and perplexity is 41.0479179275768
At time: 573.8649594783783 and batch: 1900, loss is 3.806817898750305 and perplexity is 45.006993947546384
At time: 574.8653018474579 and batch: 1950, loss is 3.7553903102874755 and perplexity is 42.75090267170607
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354534486282703 and perplexity of 77.83058569719053
finished 14 epochs...
Completing Train Step...
At time: 578.141931772232 and batch: 50, loss is 3.9246943759918214 and perplexity is 50.6375996275063
At time: 579.141227722168 and batch: 100, loss is 3.9156629276275634 and perplexity is 50.182327738056046
At time: 580.142340183258 and batch: 150, loss is 3.8772814989089968 and perplexity is 48.29275256129296
At time: 581.1429471969604 and batch: 200, loss is 3.868272695541382 and perplexity is 47.85964646241265
At time: 582.1499903202057 and batch: 250, loss is 3.877374320030212 and perplexity is 48.29723535677811
At time: 583.1627638339996 and batch: 300, loss is 3.8721030616760252 and perplexity is 48.04331797143785
At time: 584.1703314781189 and batch: 350, loss is 3.897735776901245 and perplexity is 49.29071747952919
At time: 585.1689512729645 and batch: 400, loss is 3.8290764617919923 and perplexity is 46.0200173580465
At time: 586.1679198741913 and batch: 450, loss is 3.8813801050186156 and perplexity is 48.49109171136598
At time: 587.1678812503815 and batch: 500, loss is 3.898736906051636 and perplexity is 49.34008856293347
At time: 588.1679830551147 and batch: 550, loss is 3.8735389709472656 and perplexity is 48.11235336955665
At time: 589.1688179969788 and batch: 600, loss is 3.837871999740601 and perplexity is 46.426573486062054
At time: 590.1681044101715 and batch: 650, loss is 3.8738227462768555 and perplexity is 48.126008405881024
At time: 591.1671991348267 and batch: 700, loss is 3.91566312789917 and perplexity is 50.18233778815244
At time: 592.1666786670685 and batch: 750, loss is 3.865570297241211 and perplexity is 47.730485236309676
At time: 593.1670079231262 and batch: 800, loss is 3.870309133529663 and perplexity is 47.957208970856996
At time: 594.1670882701874 and batch: 850, loss is 3.874000062942505 and perplexity is 48.13454270583703
At time: 595.1665871143341 and batch: 900, loss is 3.8231188011169435 and perplexity is 45.74666080170668
At time: 596.1665415763855 and batch: 950, loss is 3.9132277822494506 and perplexity is 50.06027514282199
At time: 597.218535900116 and batch: 1000, loss is 3.8677385568618776 and perplexity is 47.83408960011163
At time: 598.2176659107208 and batch: 1050, loss is 3.822516875267029 and perplexity is 45.719132989704825
At time: 599.2165489196777 and batch: 1100, loss is 3.8375176048278807 and perplexity is 46.410123059749445
At time: 600.214430809021 and batch: 1150, loss is 3.8219096279144287 and perplexity is 45.69137859497788
At time: 601.2129237651825 and batch: 1200, loss is 3.861033935546875 and perplexity is 47.514452862394265
At time: 602.2191944122314 and batch: 1250, loss is 3.868912353515625 and perplexity is 47.89027006018688
At time: 603.2186987400055 and batch: 1300, loss is 3.854134979248047 and perplexity is 47.18778087210444
At time: 604.2181868553162 and batch: 1350, loss is 3.7358079385757446 and perplexity is 41.92188219001269
At time: 605.2180118560791 and batch: 1400, loss is 3.7564210367202757 and perplexity is 42.79498987413514
At time: 606.2177319526672 and batch: 1450, loss is 3.6898150062561035 and perplexity is 40.03743959630317
At time: 607.2166709899902 and batch: 1500, loss is 3.705557470321655 and perplexity is 40.67271482947754
At time: 608.2157402038574 and batch: 1550, loss is 3.733626046180725 and perplexity is 41.830512869338506
At time: 609.2149415016174 and batch: 1600, loss is 3.806523404121399 and perplexity is 44.99374158103678
At time: 610.2158708572388 and batch: 1650, loss is 3.7691734218597412 and perplexity is 43.34422263776472
At time: 611.2155060768127 and batch: 1700, loss is 3.736030864715576 and perplexity is 41.93122871513745
At time: 612.2136797904968 and batch: 1750, loss is 3.735191559791565 and perplexity is 41.89605039314151
At time: 613.2111203670502 and batch: 1800, loss is 3.687033462524414 and perplexity is 39.92622844820037
At time: 614.2102706432343 and batch: 1850, loss is 3.720443172454834 and perplexity is 41.282685404244965
At time: 615.2099747657776 and batch: 1900, loss is 3.8125386238098145 and perplexity is 45.26520445714408
At time: 616.2096574306488 and batch: 1950, loss is 3.760477933883667 and perplexity is 42.968957392726836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352766737827035 and perplexity of 77.69312233564011
finished 15 epochs...
Completing Train Step...
At time: 619.4633646011353 and batch: 50, loss is 3.9204451560974123 and perplexity is 50.422885837887456
At time: 620.4840703010559 and batch: 100, loss is 3.909014401435852 and perplexity is 49.849795866064
At time: 621.4815394878387 and batch: 150, loss is 3.8696578216552733 and perplexity is 47.92598404087934
At time: 622.520987033844 and batch: 200, loss is 3.859892702102661 and perplexity is 47.4602587096759
At time: 623.5259759426117 and batch: 250, loss is 3.8684352254867553 and perplexity is 47.867425720301824
At time: 624.5234162807465 and batch: 300, loss is 3.862773423194885 and perplexity is 47.59717559297574
At time: 625.5222611427307 and batch: 350, loss is 3.8887789106369017 and perplexity is 48.8511984101349
At time: 626.521698474884 and batch: 400, loss is 3.820063362121582 and perplexity is 45.60709799178788
At time: 627.5207223892212 and batch: 450, loss is 3.8729060077667237 and perplexity is 48.08190965723541
At time: 628.5202865600586 and batch: 500, loss is 3.889993181228638 and perplexity is 48.91055301271663
At time: 629.5238361358643 and batch: 550, loss is 3.8646732425689696 and perplexity is 47.68768758030869
At time: 630.5282337665558 and batch: 600, loss is 3.829782724380493 and perplexity is 46.052531054880994
At time: 631.5239365100861 and batch: 650, loss is 3.865880584716797 and perplexity is 47.745297706025205
At time: 632.5355842113495 and batch: 700, loss is 3.9084158992767333 and perplexity is 49.81996958204454
At time: 633.540922164917 and batch: 750, loss is 3.85881010055542 and perplexity is 47.408905962461695
At time: 634.5431795120239 and batch: 800, loss is 3.863904585838318 and perplexity is 47.65104620240583
At time: 635.5421376228333 and batch: 850, loss is 3.867523808479309 and perplexity is 47.82381840963861
At time: 636.5410010814667 and batch: 900, loss is 3.8170767641067505 and perplexity is 45.47109112348062
At time: 637.5405087471008 and batch: 950, loss is 3.9075121307373046 and perplexity is 49.77496420118802
At time: 638.5405721664429 and batch: 1000, loss is 3.8621604299545287 and perplexity is 47.56800778682453
At time: 639.5415909290314 and batch: 1050, loss is 3.8179460048675535 and perplexity is 45.510633632814
At time: 640.5423197746277 and batch: 1100, loss is 3.833296232223511 and perplexity is 46.214621570334764
At time: 641.5412483215332 and batch: 1150, loss is 3.8181191873550415 and perplexity is 45.5185159600745
At time: 642.5408954620361 and batch: 1200, loss is 3.857576117515564 and perplexity is 47.350440256829344
At time: 643.5416691303253 and batch: 1250, loss is 3.865895571708679 and perplexity is 47.7460132697764
At time: 644.5406708717346 and batch: 1300, loss is 3.851686806678772 and perplexity is 47.07239833717614
At time: 645.5409510135651 and batch: 1350, loss is 3.7334291744232178 and perplexity is 41.82227843334302
At time: 646.5413765907288 and batch: 1400, loss is 3.754500737190247 and perplexity is 42.71288952904838
At time: 647.5403451919556 and batch: 1450, loss is 3.6885592889785768 and perplexity is 39.987195444481124
At time: 648.5400397777557 and batch: 1500, loss is 3.7050068235397338 and perplexity is 40.650324695038165
At time: 649.5394639968872 and batch: 1550, loss is 3.7334785652160645 and perplexity is 41.824344119846025
At time: 650.5390288829803 and batch: 1600, loss is 3.8067261600494384 and perplexity is 45.00286525377513
At time: 651.5398485660553 and batch: 1650, loss is 3.768882122039795 and perplexity is 43.33159831233576
At time: 652.540046453476 and batch: 1700, loss is 3.7363631200790404 and perplexity is 41.94516290550126
At time: 653.5402343273163 and batch: 1750, loss is 3.736069893836975 and perplexity is 41.93286528609015
At time: 654.540186882019 and batch: 1800, loss is 3.6879386949539184 and perplexity is 39.96238732860588
At time: 655.5396709442139 and batch: 1850, loss is 3.7216712617874146 and perplexity is 41.333415373901566
At time: 656.539412021637 and batch: 1900, loss is 3.813681502342224 and perplexity is 45.316966660904825
At time: 657.5395214557648 and batch: 1950, loss is 3.761300730705261 and perplexity is 43.00432666316302
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35237185456032 and perplexity of 77.66244867834652
finished 16 epochs...
Completing Train Step...
At time: 660.7836079597473 and batch: 50, loss is 3.916095371246338 and perplexity is 50.20403345837348
At time: 661.80517578125 and batch: 100, loss is 3.903922004699707 and perplexity is 49.59658619753943
At time: 662.799706697464 and batch: 150, loss is 3.8640621757507323 and perplexity is 47.65855611833126
At time: 663.7966697216034 and batch: 200, loss is 3.854095792770386 and perplexity is 47.18593178541326
At time: 664.7897729873657 and batch: 250, loss is 3.8623581314086914 and perplexity is 47.57741298081524
At time: 665.7831871509552 and batch: 300, loss is 3.8564696168899535 and perplexity is 47.29807594097902
At time: 666.778110742569 and batch: 350, loss is 3.8826642274856566 and perplexity is 48.55340020899267
At time: 667.7731778621674 and batch: 400, loss is 3.8139973068237305 and perplexity is 45.331280222089035
At time: 668.7652671337128 and batch: 450, loss is 3.8670135974884032 and perplexity is 47.79942439543519
At time: 669.7607583999634 and batch: 500, loss is 3.884067406654358 and perplexity is 48.621577149780904
At time: 670.7591445446014 and batch: 550, loss is 3.8586530113220214 and perplexity is 47.401459118692586
At time: 671.7556817531586 and batch: 600, loss is 3.8243143224716185 and perplexity is 45.801384616827065
At time: 672.7788436412811 and batch: 650, loss is 3.860460467338562 and perplexity is 47.487212645687954
At time: 673.7778217792511 and batch: 700, loss is 3.9034207248687744 and perplexity is 49.57173065950593
At time: 674.7708566188812 and batch: 750, loss is 3.854032526016235 and perplexity is 47.18294657910077
At time: 675.763386964798 and batch: 800, loss is 3.859336676597595 and perplexity is 47.43387693050702
At time: 676.7590479850769 and batch: 850, loss is 3.8629088592529297 and perplexity is 47.603622403367545
At time: 677.7576825618744 and batch: 900, loss is 3.8127985858917235 and perplexity is 45.27697322358303
At time: 678.7560834884644 and batch: 950, loss is 3.9034749126434325 and perplexity is 49.57441691405674
At time: 679.7587547302246 and batch: 1000, loss is 3.8581677436828614 and perplexity is 47.3784623047894
At time: 680.758543252945 and batch: 1050, loss is 3.814614953994751 and perplexity is 45.35928760752776
At time: 681.7576537132263 and batch: 1100, loss is 3.830066986083984 and perplexity is 46.06562388661589
At time: 682.7577576637268 and batch: 1150, loss is 3.8151891088485717 and perplexity is 45.385338340535235
At time: 683.7526960372925 and batch: 1200, loss is 3.8547855710983274 and perplexity is 47.21849084651898
At time: 684.7453808784485 and batch: 1250, loss is 3.8634002733230592 and perplexity is 47.62702124199408
At time: 685.7413418292999 and batch: 1300, loss is 3.8494727087020872 and perplexity is 46.968290730011226
At time: 686.7387564182281 and batch: 1350, loss is 3.7311582469940188 and perplexity is 41.72741083358459
At time: 687.7439806461334 and batch: 1400, loss is 3.7524933862686156 and perplexity is 42.62723576822609
At time: 688.740701675415 and batch: 1450, loss is 3.6869794940948486 and perplexity is 39.92407375049591
At time: 689.7407400608063 and batch: 1500, loss is 3.7037559223175047 and perplexity is 40.59950694481251
At time: 690.7378370761871 and batch: 1550, loss is 3.7323713445663453 and perplexity is 41.778060969933584
At time: 691.7373440265656 and batch: 1600, loss is 3.8059129190444945 and perplexity is 44.966281955945966
At time: 692.737113237381 and batch: 1650, loss is 3.7676772928237914 and perplexity is 43.279422574451196
At time: 693.7404520511627 and batch: 1700, loss is 3.735666036605835 and perplexity is 41.9159338144007
At time: 694.7385997772217 and batch: 1750, loss is 3.735754380226135 and perplexity is 41.919636983315385
At time: 695.7370314598083 and batch: 1800, loss is 3.687654495239258 and perplexity is 39.95103164324764
At time: 696.740734577179 and batch: 1850, loss is 3.721566276550293 and perplexity is 41.329076203265906
At time: 697.7400290966034 and batch: 1900, loss is 3.813523144721985 and perplexity is 45.30979094208782
At time: 698.7384526729584 and batch: 1950, loss is 3.760990171432495 and perplexity is 42.99097334435453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3523914425872094 and perplexity of 77.6639699473788
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 702.1531035900116 and batch: 50, loss is 3.917233772277832 and perplexity is 50.26121832532765
At time: 703.1469531059265 and batch: 100, loss is 3.91316593170166 and perplexity is 50.05717898313244
At time: 704.1533875465393 and batch: 150, loss is 3.877856578826904 and perplexity is 48.32053274061743
At time: 705.1537976264954 and batch: 200, loss is 3.8697967433929445 and perplexity is 47.932642464351076
At time: 706.1477012634277 and batch: 250, loss is 3.8806179666519167 and perplexity is 48.45414886949642
At time: 707.1535966396332 and batch: 300, loss is 3.8747059392929075 and perplexity is 48.16853173578543
At time: 708.1550333499908 and batch: 350, loss is 3.9010544204711914 and perplexity is 49.45456753173301
At time: 709.1550314426422 and batch: 400, loss is 3.835615677833557 and perplexity is 46.321938280980596
At time: 710.1542675495148 and batch: 450, loss is 3.891502089500427 and perplexity is 48.98441025862674
At time: 711.1454515457153 and batch: 500, loss is 3.909554376602173 and perplexity is 49.87672078661785
At time: 712.1380429267883 and batch: 550, loss is 3.8890458440780638 and perplexity is 48.86424016919478
At time: 713.135812997818 and batch: 600, loss is 3.850892310142517 and perplexity is 47.03501433244164
At time: 714.1362979412079 and batch: 650, loss is 3.8795996570587157 and perplexity is 48.404832658719045
At time: 715.1347332000732 and batch: 700, loss is 3.9180548334121705 and perplexity is 50.30250280448043
At time: 716.1364364624023 and batch: 750, loss is 3.8662902021408083 and perplexity is 47.764859017933794
At time: 717.1339526176453 and batch: 800, loss is 3.864570164680481 and perplexity is 47.682772287499354
At time: 718.1289522647858 and batch: 850, loss is 3.8713335371017457 and perplexity is 48.00636167884026
At time: 719.1219401359558 and batch: 900, loss is 3.8177835369110107 and perplexity is 45.50324021377981
At time: 720.1169586181641 and batch: 950, loss is 3.914590678215027 and perplexity is 50.12854860409417
At time: 721.1134588718414 and batch: 1000, loss is 3.8706192064285276 and perplexity is 47.97208150733013
At time: 722.1091871261597 and batch: 1050, loss is 3.8285770082473753 and perplexity is 45.9970382362333
At time: 723.1369411945343 and batch: 1100, loss is 3.8399560832977295 and perplexity is 46.52343123924589
At time: 724.1346633434296 and batch: 1150, loss is 3.8258590698242188 and perplexity is 45.87219085925702
At time: 725.1352410316467 and batch: 1200, loss is 3.863965859413147 and perplexity is 47.65396604180458
At time: 726.1296973228455 and batch: 1250, loss is 3.8718286848068235 and perplexity is 48.03013780451594
At time: 727.1232118606567 and batch: 1300, loss is 3.8575006771087645 and perplexity is 47.346868255092566
At time: 728.1161799430847 and batch: 1350, loss is 3.737930836677551 and perplexity is 42.0109726056165
At time: 729.1151940822601 and batch: 1400, loss is 3.7584149169921877 and perplexity is 42.88040308374155
At time: 730.1134333610535 and batch: 1450, loss is 3.6868775129318236 and perplexity is 39.92000245462341
At time: 731.113746881485 and batch: 1500, loss is 3.696595478057861 and perplexity is 40.309834766778046
At time: 732.1129424571991 and batch: 1550, loss is 3.7258060646057127 and perplexity is 41.5046747140848
At time: 733.1092276573181 and batch: 1600, loss is 3.7988186073303223 and perplexity is 44.64840602380154
At time: 734.1016857624054 and batch: 1650, loss is 3.759042253494263 and perplexity is 42.907311965399025
At time: 735.0952384471893 and batch: 1700, loss is 3.7282086324691774 and perplexity is 41.60451239711614
At time: 736.0938191413879 and batch: 1750, loss is 3.726657872200012 and perplexity is 41.540043772883045
At time: 737.0919229984283 and batch: 1800, loss is 3.680649070739746 and perplexity is 39.67213574007939
At time: 738.0850312709808 and batch: 1850, loss is 3.7154462718963623 and perplexity is 41.0769144671066
At time: 739.0791764259338 and batch: 1900, loss is 3.8090093994140624 and perplexity is 45.10573496063561
At time: 740.0824019908905 and batch: 1950, loss is 3.7586950206756593 and perplexity is 42.892415724908034
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346630007721657 and perplexity of 77.21780056522701
finished 18 epochs...
Completing Train Step...
At time: 743.5058221817017 and batch: 50, loss is 3.9193595314025877 and perplexity is 50.36817521081485
At time: 744.5285561084747 and batch: 100, loss is 3.9077763319015504 and perplexity is 49.788116542035645
At time: 745.5265896320343 and batch: 150, loss is 3.8693204355239867 and perplexity is 47.909817205921996
At time: 746.5216600894928 and batch: 200, loss is 3.8582300567626953 and perplexity is 47.3814146946787
At time: 747.5189564228058 and batch: 250, loss is 3.8688088417053224 and perplexity is 47.885313108193024
At time: 748.5411021709442 and batch: 300, loss is 3.86180449962616 and perplexity is 47.55107990294545
At time: 749.5416769981384 and batch: 350, loss is 3.8895623207092287 and perplexity is 48.88948392568581
At time: 750.5540053844452 and batch: 400, loss is 3.8232241678237915 and perplexity is 45.75148123065656
At time: 751.5585913658142 and batch: 450, loss is 3.879232759475708 and perplexity is 48.387076300192376
At time: 752.5553026199341 and batch: 500, loss is 3.8975887966156004 and perplexity is 49.28347324818706
At time: 753.5526151657104 and batch: 550, loss is 3.8768096113204957 and perplexity is 48.26996918676334
At time: 754.5483827590942 and batch: 600, loss is 3.84068500995636 and perplexity is 46.55735577127291
At time: 755.5419731140137 and batch: 650, loss is 3.871325068473816 and perplexity is 48.0059551325464
At time: 756.5359151363373 and batch: 700, loss is 3.9114308643341062 and perplexity is 49.970401709344955
At time: 757.5331795215607 and batch: 750, loss is 3.8599864196777345 and perplexity is 47.46470677846237
At time: 758.5280213356018 and batch: 800, loss is 3.8595586395263672 and perplexity is 47.44440666131524
At time: 759.5219917297363 and batch: 850, loss is 3.8656255769729615 and perplexity is 47.73312383765977
At time: 760.5165481567383 and batch: 900, loss is 3.8124872255325317 and perplexity is 45.262877963403525
At time: 761.5130145549774 and batch: 950, loss is 3.907449927330017 and perplexity is 49.771868125111325
At time: 762.5133767127991 and batch: 1000, loss is 3.8643855619430543 and perplexity is 47.673970729627825
At time: 763.5121510028839 and batch: 1050, loss is 3.8221945905685426 and perplexity is 45.704400786823484
At time: 764.511509180069 and batch: 1100, loss is 3.8342001152038576 and perplexity is 46.25641306468026
At time: 765.5097017288208 and batch: 1150, loss is 3.8200428676605225 and perplexity is 45.606163308472006
At time: 766.5043449401855 and batch: 1200, loss is 3.8593883657455446 and perplexity is 47.436328810556745
At time: 767.4989361763 and batch: 1250, loss is 3.867604522705078 and perplexity is 47.82767862790003
At time: 768.4937534332275 and batch: 1300, loss is 3.85343487739563 and perplexity is 47.15475618097706
At time: 769.5073757171631 and batch: 1350, loss is 3.7339440965652466 and perplexity is 41.84381919597031
At time: 770.5169916152954 and batch: 1400, loss is 3.7555141115188597 and perplexity is 42.756195613729226
At time: 771.5215663909912 and batch: 1450, loss is 3.686214542388916 and perplexity is 39.893545440002924
At time: 772.5168342590332 and batch: 1500, loss is 3.6979663801193237 and perplexity is 40.36513349826895
At time: 773.5131893157959 and batch: 1550, loss is 3.7288427257537844 and perplexity is 41.630901904857105
At time: 774.5128591060638 and batch: 1600, loss is 3.801696901321411 and perplexity is 44.777102386706
At time: 775.5130233764648 and batch: 1650, loss is 3.7625884342193605 and perplexity is 43.05973915550222
At time: 776.5159296989441 and batch: 1700, loss is 3.732763104438782 and perplexity is 41.79443114414913
At time: 777.5141642093658 and batch: 1750, loss is 3.7319183444976805 and perplexity is 41.75913979141667
At time: 778.5136103630066 and batch: 1800, loss is 3.685408048629761 and perplexity is 39.8613845151108
At time: 779.5127010345459 and batch: 1850, loss is 3.720782356262207 and perplexity is 41.29669019762427
At time: 780.5129380226135 and batch: 1900, loss is 3.8145343828201295 and perplexity is 45.355633103671046
At time: 781.5142965316772 and batch: 1950, loss is 3.7633819007873535 and perplexity is 43.09391917750771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34545160337936 and perplexity of 77.12686036642448
finished 19 epochs...
Completing Train Step...
At time: 784.7986948490143 and batch: 50, loss is 3.9198931217193604 and perplexity is 50.39505835303519
At time: 785.8279266357422 and batch: 100, loss is 3.905784034729004 and perplexity is 49.6890225633267
At time: 786.8164818286896 and batch: 150, loss is 3.866520628929138 and perplexity is 47.77586658916326
At time: 787.8115355968475 and batch: 200, loss is 3.8544247007369994 and perplexity is 47.20145416686709
At time: 788.8065509796143 and batch: 250, loss is 3.864652271270752 and perplexity is 47.68668751807748
At time: 789.798576593399 and batch: 300, loss is 3.857007622718811 and perplexity is 47.323529427977235
At time: 790.79163813591 and batch: 350, loss is 3.884905571937561 and perplexity is 48.66234715137558
At time: 791.7894353866577 and batch: 400, loss is 3.818171582221985 and perplexity is 45.520900959142
At time: 792.7812447547913 and batch: 450, loss is 3.8745195293426513 and perplexity is 48.159553479024844
At time: 793.7730906009674 and batch: 500, loss is 3.8926050519943236 and perplexity is 49.038468032295846
At time: 794.7678682804108 and batch: 550, loss is 3.8716947269439697 and perplexity is 48.02370422082725
At time: 795.7604522705078 and batch: 600, loss is 3.8363095903396607 and perplexity is 46.35409280818477
At time: 796.7517309188843 and batch: 650, loss is 3.8676130247116087 and perplexity is 47.82808526086467
At time: 797.7528364658356 and batch: 700, loss is 3.908279356956482 and perplexity is 49.81316751219873
At time: 798.7836306095123 and batch: 750, loss is 3.85703369140625 and perplexity is 47.32476310635452
At time: 799.7779405117035 and batch: 800, loss is 3.8571427202224733 and perplexity is 47.329923150545696
At time: 800.7706491947174 and batch: 850, loss is 3.8630192565917967 and perplexity is 47.608878006698276
At time: 801.7670185565948 and batch: 900, loss is 3.81008264541626 and perplexity is 45.15417049733212
At time: 802.758100271225 and batch: 950, loss is 3.9046422243118286 and perplexity is 49.632319497980454
At time: 803.7512481212616 and batch: 1000, loss is 3.8617882204055785 and perplexity is 47.55030581472763
At time: 804.7477474212646 and batch: 1050, loss is 3.819691052436829 and perplexity is 45.59012118802239
At time: 805.7482988834381 and batch: 1100, loss is 3.83192334651947 and perplexity is 46.15121771014852
At time: 806.747697353363 and batch: 1150, loss is 3.8178461265563963 and perplexity is 45.50608833457919
At time: 807.7442734241486 and batch: 1200, loss is 3.857570266723633 and perplexity is 47.350163220066
At time: 808.7401518821716 and batch: 1250, loss is 3.8660681533813475 and perplexity is 47.75425406769463
At time: 809.7359519004822 and batch: 1300, loss is 3.85203471660614 and perplexity is 47.08877814104562
At time: 810.7325971126556 and batch: 1350, loss is 3.7327421379089354 and perplexity is 41.79355486914738
At time: 811.7311570644379 and batch: 1400, loss is 3.7547592401504515 and perplexity is 42.723932364671896
At time: 812.7321059703827 and batch: 1450, loss is 3.6861222171783448 and perplexity is 39.88986243003969
At time: 813.7309889793396 and batch: 1500, loss is 3.698861794471741 and perplexity is 40.40129320468462
At time: 814.7306871414185 and batch: 1550, loss is 3.7303734159469606 and perplexity is 41.69467471389093
At time: 815.7312772274017 and batch: 1600, loss is 3.803157606124878 and perplexity is 44.84255630803821
At time: 816.7309560775757 and batch: 1650, loss is 3.7640705728530883 and perplexity is 43.12360697725415
At time: 817.731910943985 and batch: 1700, loss is 3.7346487045288086 and perplexity is 41.87331307379199
At time: 818.7340242862701 and batch: 1750, loss is 3.734073815345764 and perplexity is 41.84924747723601
At time: 819.729843378067 and batch: 1800, loss is 3.6872884702682494 and perplexity is 39.93641124392751
At time: 820.727646112442 and batch: 1850, loss is 3.7229083156585694 and perplexity is 41.38457867475298
At time: 821.719804763794 and batch: 1900, loss is 3.816533827781677 and perplexity is 45.446409917137
At time: 822.7108175754547 and batch: 1950, loss is 3.7649567222595213 and perplexity is 43.16183787262114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34492556549782 and perplexity of 77.08629938542906
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fcae8787b38>
ELAPSED
2551.2007615566254


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.42392198682246}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.7974071334468391, 'wordvec_source': 'gigavec', 'dropout': 0.589069126925909, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.51251288675175}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.014077492312028927, 'wordvec_source': 'gigavec', 'dropout': 0.3289390596927714, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -77.08629938542906}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5708626383639636, 'wordvec_source': 'gigavec', 'dropout': 0.49301208999077983, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.460524559020996 and batch: 50, loss is 7.459219636917115 and perplexity is 1735.7929799303545
At time: 2.4505977630615234 and batch: 100, loss is 6.680099058151245 and perplexity is 796.3979978220194
At time: 3.4824411869049072 and batch: 150, loss is 6.403009004592896 and perplexity is 603.6587196752495
At time: 4.47359299659729 and batch: 200, loss is 6.224975080490112 and perplexity is 505.2104527030925
At time: 5.464428663253784 and batch: 250, loss is 6.133945121765136 and perplexity is 461.2522723123939
At time: 6.455918788909912 and batch: 300, loss is 6.04504096031189 and perplexity is 422.0150429965323
At time: 7.4476377964019775 and batch: 350, loss is 5.97713532447815 and perplexity is 394.3091808282192
At time: 8.439534187316895 and batch: 400, loss is 5.911899318695069 and perplexity is 369.4071113619657
At time: 9.430672883987427 and batch: 450, loss is 5.816900062561035 and perplexity is 335.9290787587794
At time: 10.421586990356445 and batch: 500, loss is 5.800014295578003 and perplexity is 330.3042817665224
At time: 11.4167640209198 and batch: 550, loss is 5.748815145492554 and perplexity is 313.8186105216032
At time: 12.407296180725098 and batch: 600, loss is 5.768058338165283 and perplexity is 319.91596059616194
At time: 13.399709701538086 and batch: 650, loss is 5.82765266418457 and perplexity is 339.5606799066952
At time: 14.391855001449585 and batch: 700, loss is 5.744533739089966 and perplexity is 312.47789762963225
At time: 15.383130311965942 and batch: 750, loss is 5.667726736068726 and perplexity is 289.37595818825474
At time: 16.373898029327393 and batch: 800, loss is 5.680815143585205 and perplexity is 293.18832312404385
At time: 17.36458659172058 and batch: 850, loss is 5.688345212936401 and perplexity is 295.4043846072164
At time: 18.35569429397583 and batch: 900, loss is 5.683668489456177 and perplexity is 294.0260854597051
At time: 19.34726858139038 and batch: 950, loss is 5.700762548446655 and perplexity is 299.09538875424255
At time: 20.338804721832275 and batch: 1000, loss is 5.673475275039673 and perplexity is 291.0442376517908
At time: 21.329978466033936 and batch: 1050, loss is 5.565819835662841 and perplexity is 261.3393712433316
At time: 22.321367502212524 and batch: 1100, loss is 5.641394453048706 and perplexity is 281.855478800428
At time: 23.3136944770813 and batch: 1150, loss is 5.55128568649292 and perplexity is 257.5684954535413
At time: 24.304330587387085 and batch: 1200, loss is 5.623935785293579 and perplexity is 276.9773642373486
At time: 25.295021295547485 and batch: 1250, loss is 5.570021543502808 and perplexity is 262.439753050934
At time: 26.28675651550293 and batch: 1300, loss is 5.581200246810913 and perplexity is 265.38994814221735
At time: 27.279397010803223 and batch: 1350, loss is 5.5364345455169675 and perplexity is 253.77157351412112
At time: 28.27080726623535 and batch: 1400, loss is 5.536807289123535 and perplexity is 253.8661828770994
At time: 29.26265525817871 and batch: 1450, loss is 5.516451463699341 and perplexity is 248.7507680567697
At time: 30.25481414794922 and batch: 1500, loss is 5.479785890579223 and perplexity is 239.79535943189944
At time: 31.2472984790802 and batch: 1550, loss is 5.464444694519043 and perplexity is 236.14468625426352
At time: 32.24766969680786 and batch: 1600, loss is 5.48589864730835 and perplexity is 241.26565934347835
At time: 33.24920892715454 and batch: 1650, loss is 5.479267444610596 and perplexity is 239.67107071578215
At time: 34.249706506729126 and batch: 1700, loss is 5.490137090682984 and perplexity is 242.29042034047743
At time: 35.25215554237366 and batch: 1750, loss is 5.484823608398438 and perplexity is 241.00642873851828
At time: 36.25516724586487 and batch: 1800, loss is 5.471283435821533 and perplexity is 237.7651533355462
At time: 37.25206899642944 and batch: 1850, loss is 5.446361703872681 and perplexity is 231.91286144047797
At time: 38.24460196495056 and batch: 1900, loss is 5.484684476852417 and perplexity is 240.97289947403019
At time: 39.23562788963318 and batch: 1950, loss is 5.4228354167938235 and perplexity is 226.5204928057187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.9437000363372094 and perplexity of 140.28836248947673
finished 1 epochs...
Completing Train Step...
At time: 42.68430709838867 and batch: 50, loss is 5.216841669082641 and perplexity is 184.35102211343212
At time: 43.68477964401245 and batch: 100, loss is 5.150050659179687 and perplexity is 172.44022577596968
At time: 44.68869638442993 and batch: 150, loss is 5.058189640045166 and perplexity is 157.30547885141445
At time: 45.67729425430298 and batch: 200, loss is 5.016502752304077 and perplexity is 150.8827058185103
At time: 46.6747362613678 and batch: 250, loss is 5.046281909942627 and perplexity is 155.44343601950408
At time: 47.66915535926819 and batch: 300, loss is 5.057247695922851 and perplexity is 157.157375643626
At time: 48.65888738632202 and batch: 350, loss is 5.046214017868042 and perplexity is 155.4328830003894
At time: 49.65240740776062 and batch: 400, loss is 4.98515661239624 and perplexity is 146.22647411147443
At time: 50.645132541656494 and batch: 450, loss is 4.956915826797485 and perplexity is 142.15468942112125
At time: 51.64315462112427 and batch: 500, loss is 4.953755865097046 and perplexity is 141.70619503275572
At time: 52.63529109954834 and batch: 550, loss is 4.918798246383667 and perplexity is 136.83806869139917
At time: 53.63327097892761 and batch: 600, loss is 4.891253185272217 and perplexity is 133.12029395581783
At time: 54.630378007888794 and batch: 650, loss is 4.952069711685181 and perplexity is 141.46745797873098
At time: 55.656182527542114 and batch: 700, loss is 4.964082231521607 and perplexity is 143.17708653908213
At time: 56.65111708641052 and batch: 750, loss is 4.902503490447998 and perplexity is 134.62639404524847
At time: 57.65227127075195 and batch: 800, loss is 4.90575288772583 and perplexity is 135.06456018598155
At time: 58.64457106590271 and batch: 850, loss is 4.904730024337769 and perplexity is 134.92647822387352
At time: 59.638434171676636 and batch: 900, loss is 4.883609580993652 and perplexity is 132.10665397395286
At time: 60.632529973983765 and batch: 950, loss is 4.936079406738282 and perplexity is 139.22334006677391
At time: 61.62776780128479 and batch: 1000, loss is 4.909809617996216 and perplexity is 135.61359356294818
At time: 62.62064003944397 and batch: 1050, loss is 4.825246934890747 and perplexity is 124.61723692791135
At time: 63.61438250541687 and batch: 1100, loss is 4.889961404800415 and perplexity is 132.94844278057857
At time: 64.60868573188782 and batch: 1150, loss is 4.830168647766113 and perplexity is 125.232078984302
At time: 65.6018579006195 and batch: 1200, loss is 4.890958547592163 and perplexity is 133.08107747884821
At time: 66.59503769874573 and batch: 1250, loss is 4.8694570446014405 and perplexity is 130.2501776569485
At time: 67.58940625190735 and batch: 1300, loss is 4.86401704788208 and perplexity is 129.54354091124526
At time: 68.58452892303467 and batch: 1350, loss is 4.767179107666015 and perplexity is 117.58707320141535
At time: 69.57992100715637 and batch: 1400, loss is 4.7766842269897465 and perplexity is 118.71008106997179
At time: 70.5740647315979 and batch: 1450, loss is 4.729550809860229 and perplexity is 113.24468252738559
At time: 71.56870317459106 and batch: 1500, loss is 4.706844873428345 and perplexity is 110.70232845660051
At time: 72.56329321861267 and batch: 1550, loss is 4.714194889068604 and perplexity is 111.51898986270349
At time: 73.5578887462616 and batch: 1600, loss is 4.770185813903809 and perplexity is 117.9411550311671
At time: 74.55275273323059 and batch: 1650, loss is 4.749825658798218 and perplexity is 115.56413518059779
At time: 75.55811262130737 and batch: 1700, loss is 4.750802698135376 and perplexity is 115.67710106370318
At time: 76.55759406089783 and batch: 1750, loss is 4.745910005569458 and perplexity is 115.11251088066109
At time: 77.55711960792542 and batch: 1800, loss is 4.699292802810669 and perplexity is 109.86944560813275
At time: 78.55737400054932 and batch: 1850, loss is 4.731484861373901 and perplexity is 113.46391551264871
At time: 79.55688834190369 and batch: 1900, loss is 4.8307967948913575 and perplexity is 125.3107678662145
At time: 80.55729818344116 and batch: 1950, loss is 4.751056852340699 and perplexity is 115.7065046217587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.610163914880087 and perplexity of 100.50062183370991
finished 2 epochs...
Completing Train Step...
At time: 83.93406128883362 and batch: 50, loss is 4.71134726524353 and perplexity is 111.20187745293663
At time: 84.95583152770996 and batch: 100, loss is 4.65996901512146 and perplexity is 105.63280908619252
At time: 85.94977927207947 and batch: 150, loss is 4.602985248565674 and perplexity is 99.78174478158377
At time: 86.9464213848114 and batch: 200, loss is 4.582302722930908 and perplexity is 97.73920157389018
At time: 87.94129633903503 and batch: 250, loss is 4.600136346817017 and perplexity is 99.49788093648604
At time: 88.93667078018188 and batch: 300, loss is 4.6208264446258545 and perplexity is 101.57794599726171
At time: 89.93189096450806 and batch: 350, loss is 4.627968845367431 and perplexity is 102.30605351662652
At time: 90.92866492271423 and batch: 400, loss is 4.56665337562561 and perplexity is 96.2215529412027
At time: 91.9281907081604 and batch: 450, loss is 4.5705952453613286 and perplexity is 96.60159431335626
At time: 92.92583346366882 and batch: 500, loss is 4.576985168457031 and perplexity is 97.2208474548513
At time: 93.9231345653534 and batch: 550, loss is 4.5498466968536375 and perplexity is 94.61790198094327
At time: 94.9193868637085 and batch: 600, loss is 4.527628660202026 and perplexity is 92.53885961098909
At time: 95.91607308387756 and batch: 650, loss is 4.5821459865570064 and perplexity is 97.72388348632954
At time: 96.91208100318909 and batch: 700, loss is 4.612230129241944 and perplexity is 100.70849234047736
At time: 97.90845942497253 and batch: 750, loss is 4.561139001846313 and perplexity is 95.6924116150452
At time: 98.90492391586304 and batch: 800, loss is 4.565324268341064 and perplexity is 96.09374912556348
At time: 99.9020926952362 and batch: 850, loss is 4.567232894897461 and perplexity is 96.2773313462688
At time: 100.8981385231018 and batch: 900, loss is 4.534268493652344 and perplexity is 93.15534664717036
At time: 101.89503860473633 and batch: 950, loss is 4.601661949157715 and perplexity is 99.64979098423572
At time: 102.89134502410889 and batch: 1000, loss is 4.578171129226685 and perplexity is 97.33621596366581
At time: 103.88811373710632 and batch: 1050, loss is 4.50998703956604 and perplexity is 90.92064013194138
At time: 104.88412380218506 and batch: 1100, loss is 4.564915590286255 and perplexity is 96.0544857426794
At time: 105.92710995674133 and batch: 1150, loss is 4.522044219970703 and perplexity is 92.02352215530114
At time: 106.9251720905304 and batch: 1200, loss is 4.580190191268921 and perplexity is 97.53294235721847
At time: 107.92203116416931 and batch: 1250, loss is 4.5770533084869385 and perplexity is 97.22747231201092
At time: 108.9179253578186 and batch: 1300, loss is 4.562903146743775 and perplexity is 95.86137588963214
At time: 109.91437458992004 and batch: 1350, loss is 4.455823345184326 and perplexity is 86.12703393914111
At time: 110.90990161895752 and batch: 1400, loss is 4.474712610244751 and perplexity is 87.76937276628763
At time: 111.90478944778442 and batch: 1450, loss is 4.423752746582031 and perplexity is 83.40871051876859
At time: 112.90240621566772 and batch: 1500, loss is 4.406628293991089 and perplexity is 81.99254217076266
At time: 113.89878845214844 and batch: 1550, loss is 4.422589206695557 and perplexity is 83.31171759571058
At time: 114.89546418190002 and batch: 1600, loss is 4.490849714279175 and perplexity is 89.19720582639887
At time: 115.89956331253052 and batch: 1650, loss is 4.468805017471314 and perplexity is 87.25239560280797
At time: 116.90069055557251 and batch: 1700, loss is 4.467658548355103 and perplexity is 87.15242074592733
At time: 117.89089941978455 and batch: 1750, loss is 4.463667421340943 and perplexity is 86.8052775721943
At time: 118.88111662864685 and batch: 1800, loss is 4.417704439163208 and perplexity is 82.90575155463091
At time: 119.8711347579956 and batch: 1850, loss is 4.461854133605957 and perplexity is 86.64801724923753
At time: 120.86645865440369 and batch: 1900, loss is 4.562013177871704 and perplexity is 95.77610020103923
At time: 121.85604000091553 and batch: 1950, loss is 4.487662258148194 and perplexity is 88.91334628107658
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.506951478470204 and perplexity of 90.64506345048635
finished 3 epochs...
Completing Train Step...
At time: 125.19179940223694 and batch: 50, loss is 4.4674476051330565 and perplexity is 87.13403847236222
At time: 126.18051743507385 and batch: 100, loss is 4.417579174041748 and perplexity is 82.89536700601717
At time: 127.16957068443298 and batch: 150, loss is 4.370332927703857 and perplexity is 79.0699518954888
At time: 128.1589229106903 and batch: 200, loss is 4.354414072036743 and perplexity is 77.82121435013434
At time: 129.1479208469391 and batch: 250, loss is 4.366464967727661 and perplexity is 78.76470321165485
At time: 130.14089703559875 and batch: 300, loss is 4.388123140335083 and perplexity is 80.4892101739729
At time: 131.12976217269897 and batch: 350, loss is 4.398597640991211 and perplexity is 81.33672535917498
At time: 132.15881991386414 and batch: 400, loss is 4.333726711273194 and perplexity is 76.2278370252487
At time: 133.1467888355255 and batch: 450, loss is 4.359756193161011 and perplexity is 78.23805712419467
At time: 134.13546705245972 and batch: 500, loss is 4.372549057006836 and perplexity is 79.2453754417047
At time: 135.1243176460266 and batch: 550, loss is 4.340214900970459 and perplexity is 76.72402563433796
At time: 136.1158802509308 and batch: 600, loss is 4.325985870361328 and perplexity is 75.64004739385068
At time: 137.11103749275208 and batch: 650, loss is 4.3758079719543455 and perplexity is 79.50405065156778
At time: 138.10614848136902 and batch: 700, loss is 4.411911239624024 and perplexity is 82.42685051693651
At time: 139.10035943984985 and batch: 750, loss is 4.3627974319458005 and perplexity is 78.4763599221487
At time: 140.09574961662292 and batch: 800, loss is 4.366465520858765 and perplexity is 78.76474677887411
At time: 141.08936405181885 and batch: 850, loss is 4.369968862533569 and perplexity is 79.04117051945349
At time: 142.08333158493042 and batch: 900, loss is 4.334428787231445 and perplexity is 76.28137354812739
At time: 143.0757429599762 and batch: 950, loss is 4.408644313812256 and perplexity is 82.15800749561188
At time: 144.07139015197754 and batch: 1000, loss is 4.387045879364013 and perplexity is 80.40254897600416
At time: 145.0662341117859 and batch: 1050, loss is 4.328733863830567 and perplexity is 75.84819160859043
At time: 146.06211018562317 and batch: 1100, loss is 4.373694477081298 and perplexity is 79.33619668985465
At time: 147.05599308013916 and batch: 1150, loss is 4.335289359092712 and perplexity is 76.34704740622578
At time: 148.05039715766907 and batch: 1200, loss is 4.395639820098877 and perplexity is 81.09650133854448
At time: 149.04600477218628 and batch: 1250, loss is 4.400768842697143 and perplexity is 81.51351565026975
At time: 150.04038643836975 and batch: 1300, loss is 4.378592824935913 and perplexity is 79.72576632355533
At time: 151.0346601009369 and batch: 1350, loss is 4.273722257614136 and perplexity is 71.78835366065596
At time: 152.02901768684387 and batch: 1400, loss is 4.296377878189087 and perplexity is 73.43332694822448
At time: 153.0218951702118 and batch: 1450, loss is 4.239534802436829 and perplexity is 69.37557098428444
At time: 154.01545214653015 and batch: 1500, loss is 4.226718344688416 and perplexity is 68.49209551638593
At time: 155.01032137870789 and batch: 1550, loss is 4.247293214797974 and perplexity is 69.91590864257975
At time: 156.00387477874756 and batch: 1600, loss is 4.319334230422974 and perplexity is 75.1385866507175
At time: 156.9950065612793 and batch: 1650, loss is 4.295443277359009 and perplexity is 73.36472816113823
At time: 157.99093914031982 and batch: 1700, loss is 4.2968051052093506 and perplexity is 73.46470635227193
At time: 158.98359489440918 and batch: 1750, loss is 4.292074809074402 and perplexity is 73.11801715349804
At time: 159.9793245792389 and batch: 1800, loss is 4.24475064277649 and perplexity is 69.73836820972215
At time: 160.97484850883484 and batch: 1850, loss is 4.290690984725952 and perplexity is 73.01690463816662
At time: 161.97024703025818 and batch: 1900, loss is 4.390298137664795 and perplexity is 80.66446451094096
At time: 162.9644272327423 and batch: 1950, loss is 4.316798181533813 and perplexity is 74.94827294593956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465451830486918 and perplexity of 86.96031198468758
finished 4 epochs...
Completing Train Step...
At time: 166.26255655288696 and batch: 50, loss is 4.305852661132812 and perplexity is 74.13239832696564
At time: 167.28431868553162 and batch: 100, loss is 4.261780643463135 and perplexity is 70.93618311339316
At time: 168.2841489315033 and batch: 150, loss is 4.220499496459961 and perplexity is 68.06747526245971
At time: 169.2814905643463 and batch: 200, loss is 4.206317324638366 and perplexity is 67.10894372833476
At time: 170.27734375 and batch: 250, loss is 4.21041998386383 and perplexity is 67.38483441118231
At time: 171.27351999282837 and batch: 300, loss is 4.232528257369995 and perplexity is 68.8911868309465
At time: 172.26991963386536 and batch: 350, loss is 4.245968389511108 and perplexity is 69.82334360864357
At time: 173.26518726348877 and batch: 400, loss is 4.184126210212708 and perplexity is 65.63612367801845
At time: 174.2585573196411 and batch: 450, loss is 4.21883918762207 and perplexity is 67.95455599807447
At time: 175.2491102218628 and batch: 500, loss is 4.230238437652588 and perplexity is 68.7336189029073
At time: 176.23908400535583 and batch: 550, loss is 4.199009876251221 and perplexity is 66.6203359978638
At time: 177.22865223884583 and batch: 600, loss is 4.189193515777588 and perplexity is 65.96956608657611
At time: 178.22308945655823 and batch: 650, loss is 4.236040635108948 and perplexity is 69.13358414825169
At time: 179.21319794654846 and batch: 700, loss is 4.273476128578186 and perplexity is 71.77068663665003
At time: 180.20423316955566 and batch: 750, loss is 4.226914601325989 and perplexity is 68.50553886388226
At time: 181.20880389213562 and batch: 800, loss is 4.229494938850403 and perplexity is 68.68253453252048
At time: 182.24025750160217 and batch: 850, loss is 4.233417530059814 and perplexity is 68.9524771298199
At time: 183.23374128341675 and batch: 900, loss is 4.198699717521667 and perplexity is 66.59967632314311
At time: 184.22792601585388 and batch: 950, loss is 4.276212759017945 and perplexity is 71.96736547828834
At time: 185.2221474647522 and batch: 1000, loss is 4.253366584777832 and perplexity is 70.34182589056647
At time: 186.21866583824158 and batch: 1050, loss is 4.202506089210511 and perplexity is 66.85366252186796
At time: 187.21355605125427 and batch: 1100, loss is 4.236750965118408 and perplexity is 69.18270925318629
At time: 188.2088279724121 and batch: 1150, loss is 4.203811478614807 and perplexity is 66.9409895700634
At time: 189.20388984680176 and batch: 1200, loss is 4.261116271018982 and perplexity is 70.88907071986013
At time: 190.20343470573425 and batch: 1250, loss is 4.272861566543579 and perplexity is 71.72659264807895
At time: 191.19850492477417 and batch: 1300, loss is 4.246642832756042 and perplexity is 69.87045137505088
At time: 192.19281840324402 and batch: 1350, loss is 4.142413759231568 and perplexity is 62.95459543848784
At time: 193.189124584198 and batch: 1400, loss is 4.170075421333313 and perplexity is 64.72033321715452
At time: 194.18865275382996 and batch: 1450, loss is 4.111490902900695 and perplexity is 61.03765097723138
At time: 195.18562817573547 and batch: 1500, loss is 4.102450747489929 and perplexity is 60.48834776066345
At time: 196.18402361869812 and batch: 1550, loss is 4.122977747917175 and perplexity is 61.742823363330885
At time: 197.18113803863525 and batch: 1600, loss is 4.195310044288635 and perplexity is 66.3743073623375
At time: 198.1771011352539 and batch: 1650, loss is 4.168616542816162 and perplexity is 64.62598295292196
At time: 199.17227387428284 and batch: 1700, loss is 4.177186622619629 and perplexity is 65.18221284708368
At time: 200.1696960926056 and batch: 1750, loss is 4.168150959014892 and perplexity is 64.59590114546248
At time: 201.16311621665955 and batch: 1800, loss is 4.122797532081604 and perplexity is 61.73169733140163
At time: 202.17194938659668 and batch: 1850, loss is 4.16933844089508 and perplexity is 64.6726531694069
At time: 203.167329788208 and batch: 1900, loss is 4.267840595245361 and perplexity is 71.36735809296543
At time: 204.1610631942749 and batch: 1950, loss is 4.194534754753112 and perplexity is 66.32286799918847
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.460131552053053 and perplexity of 86.49888745412117
finished 5 epochs...
Completing Train Step...
At time: 207.46823859214783 and batch: 50, loss is 4.1908031797409055 and perplexity is 66.07584042982508
At time: 208.46115612983704 and batch: 100, loss is 4.149943027496338 and perplexity is 63.43038640725623
At time: 209.4556040763855 and batch: 150, loss is 4.107434391975403 and perplexity is 60.79055259666758
At time: 210.44845986366272 and batch: 200, loss is 4.097310762405396 and perplexity is 60.17823622247366
At time: 211.44210529327393 and batch: 250, loss is 4.09853964805603 and perplexity is 60.25223385144778
At time: 212.43814301490784 and batch: 300, loss is 4.120358242988586 and perplexity is 61.58129938202038
At time: 213.43114042282104 and batch: 350, loss is 4.137312293052673 and perplexity is 62.634252503119924
At time: 214.4254059791565 and batch: 400, loss is 4.0786357021331785 and perplexity is 59.06483283049821
At time: 215.42907404899597 and batch: 450, loss is 4.116467266082764 and perplexity is 61.34215352551315
At time: 216.42900109291077 and batch: 500, loss is 4.134132237434387 and perplexity is 62.43538846349202
At time: 217.42840814590454 and batch: 550, loss is 4.096802248954773 and perplexity is 60.147642559223634
At time: 218.42812633514404 and batch: 600, loss is 4.0877633380889895 and perplexity is 59.60642308153637
At time: 219.42968916893005 and batch: 650, loss is 4.127892422676086 and perplexity is 62.04701615087611
At time: 220.43062615394592 and batch: 700, loss is 4.171461200714111 and perplexity is 64.81008349312324
At time: 221.4316999912262 and batch: 750, loss is 4.126255836486816 and perplexity is 61.94555390965603
At time: 222.43214559555054 and batch: 800, loss is 4.128857183456421 and perplexity is 62.106905563428214
At time: 223.4326000213623 and batch: 850, loss is 4.128317942619324 and perplexity is 62.07342401180398
At time: 224.4326684474945 and batch: 900, loss is 4.094371924400329 and perplexity is 60.00164175315459
At time: 225.43294286727905 and batch: 950, loss is 4.178315668106079 and perplexity is 65.25584809124342
At time: 226.43347644805908 and batch: 1000, loss is 4.155361571311951 and perplexity is 63.77501959704493
At time: 227.4336473941803 and batch: 1050, loss is 4.106550769805908 and perplexity is 60.736860441979964
At time: 228.43344926834106 and batch: 1100, loss is 4.1363907194137575 and perplexity is 62.576557016523005
At time: 229.43375277519226 and batch: 1150, loss is 4.103819365501404 and perplexity is 60.57118987957002
At time: 230.4338047504425 and batch: 1200, loss is 4.159288601875305 and perplexity is 64.02595844796045
At time: 231.43466567993164 and batch: 1250, loss is 4.1732538175582885 and perplexity is 64.92636733551325
At time: 232.43319487571716 and batch: 1300, loss is 4.148366045951843 and perplexity is 63.330436688676116
At time: 233.4339189529419 and batch: 1350, loss is 4.042843928337097 and perplexity is 56.988182873766036
At time: 234.43438506126404 and batch: 1400, loss is 4.071448884010315 and perplexity is 58.641866331666904
At time: 235.43501996994019 and batch: 1450, loss is 4.01328809261322 and perplexity is 55.32849701987196
At time: 236.43546438217163 and batch: 1500, loss is 4.010229740142822 and perplexity is 55.15954146883535
At time: 237.43598079681396 and batch: 1550, loss is 4.027090673446655 and perplexity is 56.0974677546521
At time: 238.43646025657654 and batch: 1600, loss is 4.102389154434204 and perplexity is 60.48462221322421
At time: 239.43667793273926 and batch: 1650, loss is 4.071580867767334 and perplexity is 58.64960661628868
At time: 240.43809819221497 and batch: 1700, loss is 4.087637181282044 and perplexity is 59.598903799841196
At time: 241.43848872184753 and batch: 1750, loss is 4.075365839004516 and perplexity is 58.872014328281956
At time: 242.43726873397827 and batch: 1800, loss is 4.0317758417129514 and perplexity is 56.3609104852584
At time: 243.44125366210938 and batch: 1850, loss is 4.076838326454163 and perplexity is 58.958766485572376
At time: 244.44104623794556 and batch: 1900, loss is 4.170288152694702 and perplexity is 64.73410272630068
At time: 245.4407181739807 and batch: 1950, loss is 4.100572247505188 and perplexity is 60.37482705801941
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465587243368459 and perplexity of 86.97208832842942
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 248.7545645236969 and batch: 50, loss is 4.132619385719299 and perplexity is 62.34100439152699
At time: 249.78226256370544 and batch: 100, loss is 4.124057383537292 and perplexity is 61.80951911179497
At time: 250.78039383888245 and batch: 150, loss is 4.078786807060242 and perplexity is 59.07375849209381
At time: 251.77829551696777 and batch: 200, loss is 4.068905324935913 and perplexity is 58.49289681711497
At time: 252.77445602416992 and batch: 250, loss is 4.066261019706726 and perplexity is 58.33842806546334
At time: 253.77379488945007 and batch: 300, loss is 4.083619289398193 and perplexity is 59.35992227044997
At time: 254.77417588233948 and batch: 350, loss is 4.1039442491531375 and perplexity is 60.5787547033036
At time: 255.76295518875122 and batch: 400, loss is 4.0333589172363284 and perplexity is 56.45020472423634
At time: 256.75654458999634 and batch: 450, loss is 4.068493571281433 and perplexity is 58.46881711088313
At time: 257.75434970855713 and batch: 500, loss is 4.078305978775024 and perplexity is 59.04536098580593
At time: 258.78343749046326 and batch: 550, loss is 4.041010003089905 and perplexity is 56.883766581504645
At time: 259.77908730506897 and batch: 600, loss is 4.0187343311309816 and perplexity is 55.63065126665766
At time: 260.7777717113495 and batch: 650, loss is 4.050153074264526 and perplexity is 57.40624379146428
At time: 261.7794146537781 and batch: 700, loss is 4.088631591796875 and perplexity is 59.658199053477844
At time: 262.77759647369385 and batch: 750, loss is 4.024583654403687 and perplexity is 55.95700647784503
At time: 263.7727565765381 and batch: 800, loss is 4.029112739562988 and perplexity is 56.21101530504902
At time: 264.76944184303284 and batch: 850, loss is 4.031134181022644 and perplexity is 56.32475750474371
At time: 265.76568627357483 and batch: 900, loss is 3.987409029006958 and perplexity is 53.915015995122985
At time: 266.76235723495483 and batch: 950, loss is 4.066098599433899 and perplexity is 58.328953491512934
At time: 267.7572572231293 and batch: 1000, loss is 4.038787231445313 and perplexity is 56.75746737725532
At time: 268.7571814060211 and batch: 1050, loss is 3.9832308101654053 and perplexity is 53.69021721573287
At time: 269.7571506500244 and batch: 1100, loss is 4.004145212173462 and perplexity is 54.824940672228
At time: 270.76623582839966 and batch: 1150, loss is 3.9727124166488648 and perplexity is 53.128442048605514
At time: 271.76046347618103 and batch: 1200, loss is 4.012350039482117 and perplexity is 55.27662028537387
At time: 272.75971388816833 and batch: 1250, loss is 4.019641213417053 and perplexity is 55.68112460208166
At time: 273.7579038143158 and batch: 1300, loss is 3.9941142654418944 and perplexity is 54.277743653093225
At time: 274.75494933128357 and batch: 1350, loss is 3.88963782787323 and perplexity is 48.89317557133762
At time: 275.7591452598572 and batch: 1400, loss is 3.905941324234009 and perplexity is 49.696838739775025
At time: 276.7578823566437 and batch: 1450, loss is 3.8376228761672975 and perplexity is 46.41500897273523
At time: 277.757159948349 and batch: 1500, loss is 3.8359860706329347 and perplexity is 46.339098771237914
At time: 278.75657200813293 and batch: 1550, loss is 3.841521854400635 and perplexity is 46.59633334259755
At time: 279.7571749687195 and batch: 1600, loss is 3.911098961830139 and perplexity is 49.95381915994044
At time: 280.7645320892334 and batch: 1650, loss is 3.874039101600647 and perplexity is 48.13642185047393
At time: 281.76098823547363 and batch: 1700, loss is 3.8762269163131715 and perplexity is 48.2418507097582
At time: 282.75754380226135 and batch: 1750, loss is 3.8604674482345582 and perplexity is 47.487544150137694
At time: 283.757187128067 and batch: 1800, loss is 3.81583701133728 and perplexity is 45.41475314212955
At time: 284.75728821754456 and batch: 1850, loss is 3.8450820541381834 and perplexity is 46.762521251873835
At time: 285.7570266723633 and batch: 1900, loss is 3.932669758796692 and perplexity is 51.0430686047994
At time: 286.756356716156 and batch: 1950, loss is 3.8588063526153564 and perplexity is 47.408728277056646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388232421875 and perplexity of 80.49800663944428
finished 7 epochs...
Completing Train Step...
At time: 290.0835950374603 and batch: 50, loss is 4.041595244407654 and perplexity is 56.91706705547349
At time: 291.0765919685364 and batch: 100, loss is 4.024358654022217 and perplexity is 55.94441754635193
At time: 292.07740116119385 and batch: 150, loss is 3.9740572643280028 and perplexity is 53.199939776591584
At time: 293.07993388175964 and batch: 200, loss is 3.9633663368225096 and perplexity is 52.634212539930786
At time: 294.0824136734009 and batch: 250, loss is 3.961004605293274 and perplexity is 52.5100513360856
At time: 295.0779695510864 and batch: 300, loss is 3.977210865020752 and perplexity is 53.36797596378069
At time: 296.0775282382965 and batch: 350, loss is 4.000538172721863 and perplexity is 54.62754117620262
At time: 297.08040952682495 and batch: 400, loss is 3.9351554107666016 and perplexity is 51.1701017234822
At time: 298.07696986198425 and batch: 450, loss is 3.9763655614852906 and perplexity is 53.32288288637203
At time: 299.072793006897 and batch: 500, loss is 3.987826862335205 and perplexity is 53.93754819272246
At time: 300.065304517746 and batch: 550, loss is 3.9525711297988892 and perplexity is 52.06907121611948
At time: 301.05934977531433 and batch: 600, loss is 3.935276913642883 and perplexity is 51.17631941574732
At time: 302.0551769733429 and batch: 650, loss is 3.9689704847335814 and perplexity is 52.930010525855906
At time: 303.0565004348755 and batch: 700, loss is 4.00773202419281 and perplexity is 55.02194051789449
At time: 304.0628764629364 and batch: 750, loss is 3.9502057313919066 and perplexity is 51.946052669307655
At time: 305.0580155849457 and batch: 800, loss is 3.955675902366638 and perplexity is 52.230985062828715
At time: 306.05956292152405 and batch: 850, loss is 3.9605290842056275 and perplexity is 52.485087635215386
At time: 307.05417037010193 and batch: 900, loss is 3.9158436059951782 and perplexity is 50.19139541825703
At time: 308.0607817173004 and batch: 950, loss is 3.9996142101287844 and perplexity is 54.577090682377644
At time: 309.096399307251 and batch: 1000, loss is 3.975161061286926 and perplexity is 53.25869412880417
At time: 310.0945370197296 and batch: 1050, loss is 3.9229709196090696 and perplexity is 50.55040309451505
At time: 311.09783029556274 and batch: 1100, loss is 3.94663733959198 and perplexity is 51.76101913334259
At time: 312.0967950820923 and batch: 1150, loss is 3.915654125213623 and perplexity is 50.18188601437892
At time: 313.09683895111084 and batch: 1200, loss is 3.9585266876220704 and perplexity is 52.380096826745884
At time: 314.09545707702637 and batch: 1250, loss is 3.967928957939148 and perplexity is 52.8749112003564
At time: 315.09584164619446 and batch: 1300, loss is 3.944408721923828 and perplexity is 51.645792057820536
At time: 316.0927278995514 and batch: 1350, loss is 3.8406119298934938 and perplexity is 46.55395348110757
At time: 317.08992767333984 and batch: 1400, loss is 3.8613017797470093 and perplexity is 47.52718103752386
At time: 318.09387588500977 and batch: 1450, loss is 3.795539016723633 and perplexity is 44.50221738128189
At time: 319.08968448638916 and batch: 1500, loss is 3.79881667137146 and perplexity is 44.648319586407894
At time: 320.08535528182983 and batch: 1550, loss is 3.8071834421157837 and perplexity is 45.02344896291167
At time: 321.0812394618988 and batch: 1600, loss is 3.8804601287841796 and perplexity is 48.44650157348816
At time: 322.0764937400818 and batch: 1650, loss is 3.845288486480713 and perplexity is 46.77217554512335
At time: 323.08288645744324 and batch: 1700, loss is 3.851968755722046 and perplexity is 47.08567222604411
At time: 324.0854709148407 and batch: 1750, loss is 3.8394686365127564 and perplexity is 46.500759068449696
At time: 325.08154582977295 and batch: 1800, loss is 3.7974598264694213 and perplexity is 44.58777982241549
At time: 326.0845744609833 and batch: 1850, loss is 3.8310622453689573 and perplexity is 46.11149394902353
At time: 327.0853991508484 and batch: 1900, loss is 3.923035078048706 and perplexity is 50.553646433543264
At time: 328.08247566223145 and batch: 1950, loss is 3.8495530796051027 and perplexity is 46.97206576564977
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386637559047965 and perplexity of 80.36972568345979
finished 8 epochs...
Completing Train Step...
At time: 331.36703538894653 and batch: 50, loss is 3.99277943611145 and perplexity is 54.20534046257639
At time: 332.3964624404907 and batch: 100, loss is 3.975306262969971 and perplexity is 53.26642794229622
At time: 333.3971333503723 and batch: 150, loss is 3.924671854972839 and perplexity is 50.63645923000538
At time: 334.42699003219604 and batch: 200, loss is 3.914402599334717 and perplexity is 50.11912136936081
At time: 335.42729592323303 and batch: 250, loss is 3.911511869430542 and perplexity is 49.974449730507324
At time: 336.42817401885986 and batch: 300, loss is 3.928955421447754 and perplexity is 50.8538290959311
At time: 337.42883706092834 and batch: 350, loss is 3.949977912902832 and perplexity is 51.93421974600568
At time: 338.42937207221985 and batch: 400, loss is 3.887980718612671 and perplexity is 48.81222133085611
At time: 339.4296863079071 and batch: 450, loss is 3.930855736732483 and perplexity is 50.95055928446765
At time: 340.4303753376007 and batch: 500, loss is 3.944477996826172 and perplexity is 51.649369938949064
At time: 341.42871856689453 and batch: 550, loss is 3.909198408126831 and perplexity is 49.85896940601776
At time: 342.4304587841034 and batch: 600, loss is 3.894253134727478 and perplexity is 49.11935411989398
At time: 343.43275332450867 and batch: 650, loss is 3.927169418334961 and perplexity is 50.76308505755716
At time: 344.4422388076782 and batch: 700, loss is 3.9661529874801635 and perplexity is 52.78109025631549
At time: 345.44867420196533 and batch: 750, loss is 3.9109337902069092 and perplexity is 49.94556888791743
At time: 346.44923853874207 and batch: 800, loss is 3.9164422273635866 and perplexity is 50.22145005484097
At time: 347.45011854171753 and batch: 850, loss is 3.9216038608551025 and perplexity is 50.48134493748212
At time: 348.45148944854736 and batch: 900, loss is 3.8771043395996094 and perplexity is 48.284197808400215
At time: 349.45324540138245 and batch: 950, loss is 3.9619966745376587 and perplexity is 52.56217079181705
At time: 350.4561858177185 and batch: 1000, loss is 3.9386417484283447 and perplexity is 51.34880931276632
At time: 351.4591031074524 and batch: 1050, loss is 3.8881718254089357 and perplexity is 48.82155056950528
At time: 352.4606819152832 and batch: 1100, loss is 3.912037615776062 and perplexity is 50.000730522732376
At time: 353.46214056015015 and batch: 1150, loss is 3.8819446039199828 and perplexity is 48.51847260687877
At time: 354.4638195037842 and batch: 1200, loss is 3.926074380874634 and perplexity is 50.70752800189751
At time: 355.4664297103882 and batch: 1250, loss is 3.936165900230408 and perplexity is 51.221834705550336
At time: 356.46743512153625 and batch: 1300, loss is 3.9126884746551513 and perplexity is 50.03328453503883
At time: 357.4684774875641 and batch: 1350, loss is 3.8094683074951172 and perplexity is 45.1264390971954
At time: 358.46975588798523 and batch: 1400, loss is 3.831831774711609 and perplexity is 46.14699175320001
At time: 359.47143840789795 and batch: 1450, loss is 3.7670658588409425 and perplexity is 43.252968153121365
At time: 360.47573924064636 and batch: 1500, loss is 3.7717444133758544 and perplexity is 43.455803641883904
At time: 361.4784195423126 and batch: 1550, loss is 3.781621379852295 and perplexity is 43.88714180738722
At time: 362.48080945014954 and batch: 1600, loss is 3.856381559371948 and perplexity is 47.29391117317748
At time: 363.48190093040466 and batch: 1650, loss is 3.822020897865295 and perplexity is 45.69646295529218
At time: 364.484493970871 and batch: 1700, loss is 3.8301812553405763 and perplexity is 46.07088807197341
At time: 365.4865427017212 and batch: 1750, loss is 3.8185320281982422 and perplexity is 45.537311742151005
At time: 366.4881684780121 and batch: 1800, loss is 3.7778760480880735 and perplexity is 43.723077330867405
At time: 367.49069595336914 and batch: 1850, loss is 3.8139531898498533 and perplexity is 45.32928038729732
At time: 368.4956567287445 and batch: 1900, loss is 3.907099289894104 and perplexity is 49.75441930417502
At time: 369.4987075328827 and batch: 1950, loss is 3.8334076738357545 and perplexity is 46.219772089257525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388749375454215 and perplexity of 80.53963113013396
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 372.8446846008301 and batch: 50, loss is 3.982289743423462 and perplexity is 53.6397149046932
At time: 373.83390045166016 and batch: 100, loss is 3.9969328880310058 and perplexity is 54.43094793854038
At time: 374.83017110824585 and batch: 150, loss is 3.958577961921692 and perplexity is 52.38278264838102
At time: 375.82683658599854 and batch: 200, loss is 3.949759702682495 and perplexity is 51.922888404824064
At time: 376.81693863868713 and batch: 250, loss is 3.955144748687744 and perplexity is 52.20324974946926
At time: 377.8101398944855 and batch: 300, loss is 3.972478928565979 and perplexity is 53.11603863860544
At time: 378.80680227279663 and batch: 350, loss is 3.9818003225326537 and perplexity is 53.61346893082969
At time: 379.797070980072 and batch: 400, loss is 3.9183150482177735 and perplexity is 50.31559396365189
At time: 380.79054522514343 and batch: 450, loss is 3.95952308177948 and perplexity is 52.43231405934122
At time: 381.7873306274414 and batch: 500, loss is 3.9725766134262086 and perplexity is 53.12122752484949
At time: 382.7786936759949 and batch: 550, loss is 3.9384670066833496 and perplexity is 51.33983731613759
At time: 383.7707962989807 and batch: 600, loss is 3.923480978012085 and perplexity is 50.57619332909303
At time: 384.76734709739685 and batch: 650, loss is 3.9534888792037965 and perplexity is 52.116879509903136
At time: 385.8219017982483 and batch: 700, loss is 3.9846986675262452 and perplexity is 53.769084665200516
At time: 386.8150017261505 and batch: 750, loss is 3.9230514764785767 and perplexity is 50.55447544076619
At time: 387.8105854988098 and batch: 800, loss is 3.9283956336975097 and perplexity is 50.825369711700695
At time: 388.8137164115906 and batch: 850, loss is 3.9323163175582887 and perplexity is 51.02503106721241
At time: 389.8153929710388 and batch: 900, loss is 3.8806212759017944 and perplexity is 48.45430921664796
At time: 390.81171345710754 and batch: 950, loss is 3.961656699180603 and perplexity is 52.54430398634335
At time: 391.81354665756226 and batch: 1000, loss is 3.9337255811691283 and perplexity is 51.09698947901375
At time: 392.81827425956726 and batch: 1050, loss is 3.8805916929244995 and perplexity is 48.452875815120805
At time: 393.81702184677124 and batch: 1100, loss is 3.8980459356307984 and perplexity is 49.306007796931546
At time: 394.81414127349854 and batch: 1150, loss is 3.877698335647583 and perplexity is 48.31288695085307
At time: 395.81189250946045 and batch: 1200, loss is 3.9176914405822756 and perplexity is 50.28422655656536
At time: 396.8095283508301 and batch: 1250, loss is 3.918930869102478 and perplexity is 50.346588899926026
At time: 397.80903792381287 and batch: 1300, loss is 3.9019473600387573 and perplexity is 49.49874719382762
At time: 398.8093612194061 and batch: 1350, loss is 3.7934104061126708 and perplexity is 44.40759023705389
At time: 399.81060433387756 and batch: 1400, loss is 3.8120273780822753 and perplexity is 45.24206872928411
At time: 400.8108160495758 and batch: 1450, loss is 3.7442296743392944 and perplexity is 42.27642805479224
At time: 401.81083846092224 and batch: 1500, loss is 3.745038537979126 and perplexity is 42.3106377538934
At time: 402.81096863746643 and batch: 1550, loss is 3.7497606563568113 and perplexity is 42.51090606720556
At time: 403.810640335083 and batch: 1600, loss is 3.8231511163711547 and perplexity is 45.748139140566124
At time: 404.8094160556793 and batch: 1650, loss is 3.7892216491699218 and perplexity is 44.2219666725426
At time: 405.8093111515045 and batch: 1700, loss is 3.787443017959595 and perplexity is 44.143382009720824
At time: 406.8099858760834 and batch: 1750, loss is 3.777736644744873 and perplexity is 43.716982612534395
At time: 407.809805393219 and batch: 1800, loss is 3.7308018016815185 and perplexity is 41.712539944077065
At time: 408.81014943122864 and batch: 1850, loss is 3.7621786832809447 and perplexity is 43.04209900125701
At time: 409.81058955192566 and batch: 1900, loss is 3.8605083274841308 and perplexity is 47.48948544498566
At time: 410.8106393814087 and batch: 1950, loss is 3.789445595741272 and perplexity is 44.23187113935158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35841547056686 and perplexity of 78.1332318797749
finished 10 epochs...
Completing Train Step...
At time: 414.09081530570984 and batch: 50, loss is 3.969846262931824 and perplexity is 52.97638577936107
At time: 415.1143493652344 and batch: 100, loss is 3.9659815883636473 and perplexity is 52.772044399324884
At time: 416.1102707386017 and batch: 150, loss is 3.921596908569336 and perplexity is 50.480993977966214
At time: 417.1106400489807 and batch: 200, loss is 3.909436674118042 and perplexity is 49.87085051816033
At time: 418.10861349105835 and batch: 250, loss is 3.9148858547210694 and perplexity is 50.143347557968404
At time: 419.10938572883606 and batch: 300, loss is 3.929942526817322 and perplexity is 50.904051967249764
At time: 420.1091811656952 and batch: 350, loss is 3.9407093811035154 and perplexity is 51.45508962519257
At time: 421.1087248325348 and batch: 400, loss is 3.877336540222168 and perplexity is 48.295410730964484
At time: 422.1100444793701 and batch: 450, loss is 3.919950833320618 and perplexity is 50.39796681647344
At time: 423.1094822883606 and batch: 500, loss is 3.9337491607666015 and perplexity is 51.09819433966277
At time: 424.1097779273987 and batch: 550, loss is 3.901877498626709 and perplexity is 49.49528926224343
At time: 425.1090602874756 and batch: 600, loss is 3.888232111930847 and perplexity is 48.82449393970532
At time: 426.1080186367035 and batch: 650, loss is 3.9211585760116576 and perplexity is 50.458871363646985
At time: 427.10871410369873 and batch: 700, loss is 3.9545542192459107 and perplexity is 52.17243129403106
At time: 428.1106140613556 and batch: 750, loss is 3.895014176368713 and perplexity is 49.1567502219603
At time: 429.1096875667572 and batch: 800, loss is 3.9016494798660277 and perplexity is 49.48400469432178
At time: 430.11094856262207 and batch: 850, loss is 3.9062103414535523 and perplexity is 49.71020984360084
At time: 431.1111490726471 and batch: 900, loss is 3.852655220031738 and perplexity is 47.11800595623131
At time: 432.10958552360535 and batch: 950, loss is 3.9354468822479247 and perplexity is 51.18501852263617
At time: 433.11013317108154 and batch: 1000, loss is 3.909772825241089 and perplexity is 49.88761747852771
At time: 434.10868787765503 and batch: 1050, loss is 3.8602594709396363 and perplexity is 47.477668846117965
At time: 435.11032819747925 and batch: 1100, loss is 3.879056477546692 and perplexity is 48.37854728482045
At time: 436.13699984550476 and batch: 1150, loss is 3.858999948501587 and perplexity is 47.4179073003044
At time: 437.1317045688629 and batch: 1200, loss is 3.9006952238082886 and perplexity is 49.43680680609796
At time: 438.1294000148773 and batch: 1250, loss is 3.9036086130142214 and perplexity is 49.58104547509045
At time: 439.1287450790405 and batch: 1300, loss is 3.887617645263672 and perplexity is 48.79450213106469
At time: 440.1296925544739 and batch: 1350, loss is 3.7797755908966066 and perplexity is 43.806210120127105
At time: 441.1297724246979 and batch: 1400, loss is 3.7997578811645507 and perplexity is 44.69036280468829
At time: 442.12936210632324 and batch: 1450, loss is 3.7341560411453245 and perplexity is 41.8526887065478
At time: 443.1291649341583 and batch: 1500, loss is 3.7368423461914064 and perplexity is 41.965268940136646
At time: 444.1288387775421 and batch: 1550, loss is 3.7443611288070677 and perplexity is 42.28198584543174
At time: 445.1278188228607 and batch: 1600, loss is 3.8198254823684694 and perplexity is 45.59625027685445
At time: 446.1283130645752 and batch: 1650, loss is 3.7855414724349976 and perplexity is 44.05952111714135
At time: 447.12781953811646 and batch: 1700, loss is 3.7862669706344603 and perplexity is 44.091497818498084
At time: 448.1283073425293 and batch: 1750, loss is 3.777954521179199 and perplexity is 43.726508550526525
At time: 449.12949323654175 and batch: 1800, loss is 3.7331047439575196 and perplexity is 41.808712212840945
At time: 450.1291253566742 and batch: 1850, loss is 3.765599179267883 and perplexity is 43.1895764073101
At time: 451.13317608833313 and batch: 1900, loss is 3.865297784805298 and perplexity is 47.71747985765481
At time: 452.1296148300171 and batch: 1950, loss is 3.7934271144866942 and perplexity is 44.40833222187971
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35703125 and perplexity of 78.0251530729625
finished 11 epochs...
Completing Train Step...
At time: 455.4187150001526 and batch: 50, loss is 3.954762101173401 and perplexity is 52.18327812700152
At time: 456.4106204509735 and batch: 100, loss is 3.949270558357239 and perplexity is 51.897496829188775
At time: 457.40803694725037 and batch: 150, loss is 3.904430642127991 and perplexity is 49.62181929429932
At time: 458.40191531181335 and batch: 200, loss is 3.8914110231399537 and perplexity is 48.97994962977425
At time: 459.39448165893555 and batch: 250, loss is 3.8965773487091067 and perplexity is 49.233650783006965
At time: 460.3874156475067 and batch: 300, loss is 3.9116745805740356 and perplexity is 49.98258179193899
At time: 461.38527941703796 and batch: 350, loss is 3.922312912940979 and perplexity is 50.51715153327845
At time: 462.4258601665497 and batch: 400, loss is 3.859197177886963 and perplexity is 47.42726042734249
At time: 463.4183497428894 and batch: 450, loss is 3.9019802474975585 and perplexity is 49.5003751086055
At time: 464.4101650714874 and batch: 500, loss is 3.9160194969177247 and perplexity is 50.20022440554764
At time: 465.4060552120209 and batch: 550, loss is 3.8848844718933107 and perplexity is 48.6613203845298
At time: 466.3975923061371 and batch: 600, loss is 3.8725236892700194 and perplexity is 48.063530567373455
At time: 467.39093923568726 and batch: 650, loss is 3.905757575035095 and perplexity is 49.68770782439292
At time: 468.38768672943115 and batch: 700, loss is 3.939623084068298 and perplexity is 51.39922446245981
At time: 469.37853240966797 and batch: 750, loss is 3.8808437395095825 and perplexity is 48.46508973618135
At time: 470.3684706687927 and batch: 800, loss is 3.8880647230148315 and perplexity is 48.816321944559526
At time: 471.365407705307 and batch: 850, loss is 3.892942967414856 and perplexity is 49.05504168693227
At time: 472.3618528842926 and batch: 900, loss is 3.8388744735717775 and perplexity is 46.47313824713063
At time: 473.35484528541565 and batch: 950, loss is 3.922302393913269 and perplexity is 50.51662014475648
At time: 474.3471248149872 and batch: 1000, loss is 3.8973678302764894 and perplexity is 49.272584462596576
At time: 475.3461883068085 and batch: 1050, loss is 3.8491237640380858 and perplexity is 46.95190425473655
At time: 476.3437240123749 and batch: 1100, loss is 3.867957444190979 and perplexity is 47.844561022213206
At time: 477.34006905555725 and batch: 1150, loss is 3.8480337285995483 and perplexity is 46.900752898652236
At time: 478.3346862792969 and batch: 1200, loss is 3.890828046798706 and perplexity is 48.951403799524904
At time: 479.3297197818756 and batch: 1250, loss is 3.894448857307434 and perplexity is 49.12896882748509
At time: 480.3271963596344 and batch: 1300, loss is 3.8786909055709837 and perplexity is 48.36086467603769
At time: 481.3271746635437 and batch: 1350, loss is 3.771328401565552 and perplexity is 43.43772927417859
At time: 482.32656049728394 and batch: 1400, loss is 3.791821312904358 and perplexity is 44.3370784767285
At time: 483.3267595767975 and batch: 1450, loss is 3.7267709398269653 and perplexity is 41.54474087259593
At time: 484.3266863822937 and batch: 1500, loss is 3.730398626327515 and perplexity is 41.69572586575747
At time: 485.32665634155273 and batch: 1550, loss is 3.7390525102615357 and perplexity is 42.058121641796525
At time: 486.3277289867401 and batch: 1600, loss is 3.8152209186553954 and perplexity is 45.38678206234261
At time: 487.3266746997833 and batch: 1650, loss is 3.7804257345199583 and perplexity is 43.83469970845849
At time: 488.32549238204956 and batch: 1700, loss is 3.7822147178649903 and perplexity is 43.91318944365229
At time: 489.3254678249359 and batch: 1750, loss is 3.7744975757598875 and perplexity is 43.57560937247779
At time: 490.327761888504 and batch: 1800, loss is 3.7306183767318726 and perplexity is 41.70488952519852
At time: 491.32696509361267 and batch: 1850, loss is 3.763522219657898 and perplexity is 43.09996649184028
At time: 492.3253507614136 and batch: 1900, loss is 3.8639666748046877 and perplexity is 47.6540048984612
At time: 493.32412028312683 and batch: 1950, loss is 3.7914277076721192 and perplexity is 44.31963060467
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357240472837936 and perplexity of 78.04147942478205
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 496.5879588127136 and batch: 50, loss is 3.955108709335327 and perplexity is 52.201368412055515
At time: 497.6144280433655 and batch: 100, loss is 3.970539584159851 and perplexity is 53.013128167873205
At time: 498.6136825084686 and batch: 150, loss is 3.937489948272705 and perplexity is 51.28969979391924
At time: 499.6126787662506 and batch: 200, loss is 3.9300167417526244 and perplexity is 50.907829948362725
At time: 500.61151099205017 and batch: 250, loss is 3.941176075935364 and perplexity is 51.47910905402863
At time: 501.6140537261963 and batch: 300, loss is 3.957768144607544 and perplexity is 52.340379335814795
At time: 502.6156585216522 and batch: 350, loss is 3.972072892189026 and perplexity is 53.09447597262816
At time: 503.6160237789154 and batch: 400, loss is 3.911722655296326 and perplexity is 49.98498474843826
At time: 504.6158649921417 and batch: 450, loss is 3.953956627845764 and perplexity is 52.14126281170107
At time: 505.61541533470154 and batch: 500, loss is 3.96531503200531 and perplexity is 52.73688057822425
At time: 506.61543369293213 and batch: 550, loss is 3.925682611465454 and perplexity is 50.6876662344817
At time: 507.61546754837036 and batch: 600, loss is 3.8989982652664184 and perplexity is 49.352985735061544
At time: 508.6150817871094 and batch: 650, loss is 3.921850571632385 and perplexity is 50.49380076576028
At time: 509.6143488883972 and batch: 700, loss is 3.9606689643859863 and perplexity is 52.4924297722377
At time: 510.6149868965149 and batch: 750, loss is 3.905033211708069 and perplexity is 49.65172890351954
At time: 511.61433959007263 and batch: 800, loss is 3.908657660484314 and perplexity is 49.83201557412047
At time: 512.6615467071533 and batch: 850, loss is 3.9164840364456177 and perplexity is 50.223549811460174
At time: 513.6609671115875 and batch: 900, loss is 3.8619913053512573 and perplexity is 47.55996354663781
At time: 514.6652762889862 and batch: 950, loss is 3.946147713661194 and perplexity is 51.735681799585
At time: 515.6646852493286 and batch: 1000, loss is 3.913544006347656 and perplexity is 50.0761079114045
At time: 516.665030002594 and batch: 1050, loss is 3.8659095621109008 and perplexity is 47.74668126037924
At time: 517.6671028137207 and batch: 1100, loss is 3.879037070274353 and perplexity is 48.37760839828857
At time: 518.6664617061615 and batch: 1150, loss is 3.8601526498794554 and perplexity is 47.4725975020649
At time: 519.6657922267914 and batch: 1200, loss is 3.8994706106185912 and perplexity is 49.376302894931875
At time: 520.6656262874603 and batch: 1250, loss is 3.902132067680359 and perplexity is 49.50789083510824
At time: 521.6661818027496 and batch: 1300, loss is 3.884387331008911 and perplexity is 48.6371348649812
At time: 522.6672205924988 and batch: 1350, loss is 3.7757408380508424 and perplexity is 43.62981897581113
At time: 523.6686952114105 and batch: 1400, loss is 3.80188467502594 and perplexity is 44.78551113854575
At time: 524.6685521602631 and batch: 1450, loss is 3.7346970415115357 and perplexity is 41.87533715232129
At time: 525.6730921268463 and batch: 1500, loss is 3.7408778619766236 and perplexity is 42.134962615835036
At time: 526.6705160140991 and batch: 1550, loss is 3.747856101989746 and perplexity is 42.43001878696916
At time: 527.6648573875427 and batch: 1600, loss is 3.8211022233963012 and perplexity is 45.65450205860519
At time: 528.6658227443695 and batch: 1650, loss is 3.785076084136963 and perplexity is 44.03902110219995
At time: 529.6629116535187 and batch: 1700, loss is 3.772943549156189 and perplexity is 43.5079443065145
At time: 530.663336277008 and batch: 1750, loss is 3.7635546731948852 and perplexity is 43.10136526089434
At time: 531.6568658351898 and batch: 1800, loss is 3.721787524223328 and perplexity is 41.33822117681931
At time: 532.653890132904 and batch: 1850, loss is 3.7480120134353636 and perplexity is 42.436634628265104
At time: 533.6554687023163 and batch: 1900, loss is 3.8547101974487306 and perplexity is 47.21493195066059
At time: 534.6555523872375 and batch: 1950, loss is 3.786201972961426 and perplexity is 44.08863206687388
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342755836664244 and perplexity of 76.91922433829762
finished 13 epochs...
Completing Train Step...
At time: 537.937695980072 and batch: 50, loss is 3.962401795387268 and perplexity is 52.583469137016095
At time: 538.9327235221863 and batch: 100, loss is 3.960301609039307 and perplexity is 52.4731499389924
At time: 539.9296245574951 and batch: 150, loss is 3.9184716796875 and perplexity is 50.32347558632353
At time: 540.9238340854645 and batch: 200, loss is 3.9057672023773193 and perplexity is 49.68818618726317
At time: 541.9214894771576 and batch: 250, loss is 3.9145669460296633 and perplexity is 50.127358958203196
At time: 542.9180901050568 and batch: 300, loss is 3.930822324752808 and perplexity is 50.94885695385569
At time: 543.9152245521545 and batch: 350, loss is 3.9480649614334107 and perplexity is 51.83496706707527
At time: 544.9105520248413 and batch: 400, loss is 3.888963236808777 and perplexity is 48.86020379446787
At time: 545.9074153900146 and batch: 450, loss is 3.9322294902801516 and perplexity is 51.02060089498066
At time: 546.9041810035706 and batch: 500, loss is 3.942497663497925 and perplexity is 51.54718818064079
At time: 547.9019980430603 and batch: 550, loss is 3.9061584091186523 and perplexity is 49.707628343367546
At time: 548.9011332988739 and batch: 600, loss is 3.88142502784729 and perplexity is 48.493270117300874
At time: 549.9007575511932 and batch: 650, loss is 3.9074971961975096 and perplexity is 49.77422084055525
At time: 550.8977806568146 and batch: 700, loss is 3.9474741411209107 and perplexity is 51.804350960833595
At time: 551.8933713436127 and batch: 750, loss is 3.892650580406189 and perplexity is 49.0407007266908
At time: 552.888017654419 and batch: 800, loss is 3.897285475730896 and perplexity is 49.26852680837838
At time: 553.8795459270477 and batch: 850, loss is 3.9042896032333374 and perplexity is 49.614821181270024
At time: 554.8713390827179 and batch: 900, loss is 3.8496012783050535 and perplexity is 46.974329812715304
At time: 555.8611795902252 and batch: 950, loss is 3.934639673233032 and perplexity is 51.143718185502046
At time: 556.8562223911285 and batch: 1000, loss is 3.9025890493392943 and perplexity is 49.53052020340177
At time: 557.8444490432739 and batch: 1050, loss is 3.8559132289886473 and perplexity is 47.2717671833863
At time: 558.83984375 and batch: 1100, loss is 3.870233063697815 and perplexity is 47.95356101278621
At time: 559.8320860862732 and batch: 1150, loss is 3.852768301963806 and perplexity is 47.12333445265269
At time: 560.82208943367 and batch: 1200, loss is 3.8926929378509523 and perplexity is 49.04277800945687
At time: 561.8176217079163 and batch: 1250, loss is 3.8960049152374268 and perplexity is 49.20547585827013
At time: 562.8070905208588 and batch: 1300, loss is 3.8795492267608642 and perplexity is 48.40239165014153
At time: 563.8011274337769 and batch: 1350, loss is 3.771484112739563 and perplexity is 43.44449354062251
At time: 564.7927873134613 and batch: 1400, loss is 3.7980019855499267 and perplexity is 44.61196004629748
At time: 565.783237695694 and batch: 1450, loss is 3.7320330047607424 and perplexity is 41.76392817988409
At time: 566.7772808074951 and batch: 1500, loss is 3.7405290269851683 and perplexity is 42.1202670298273
At time: 567.7665300369263 and batch: 1550, loss is 3.748626685142517 and perplexity is 42.46272724529311
At time: 568.7598977088928 and batch: 1600, loss is 3.822710976600647 and perplexity is 45.72800799568737
At time: 569.7528657913208 and batch: 1650, loss is 3.787122163772583 and perplexity is 44.12922069275456
At time: 570.7421083450317 and batch: 1700, loss is 3.77518150806427 and perplexity is 43.60542233327216
At time: 571.7375826835632 and batch: 1750, loss is 3.766753659248352 and perplexity is 43.2394667017691
At time: 572.726744890213 and batch: 1800, loss is 3.725864725112915 and perplexity is 41.50710947076613
At time: 573.7191386222839 and batch: 1850, loss is 3.752422342300415 and perplexity is 42.624207467816206
At time: 574.7166316509247 and batch: 1900, loss is 3.8599445056915282 and perplexity is 47.46271738508917
At time: 575.7236664295197 and batch: 1950, loss is 3.790554633140564 and perplexity is 44.28095315054806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341198446584302 and perplexity of 76.79952433534893
finished 14 epochs...
Completing Train Step...
At time: 579.002968788147 and batch: 50, loss is 3.958202533721924 and perplexity is 52.363120365711126
At time: 580.0257217884064 and batch: 100, loss is 3.954205150604248 and perplexity is 52.15422271251432
At time: 581.021461725235 and batch: 150, loss is 3.9116434717178343 and perplexity is 49.9810269151748
At time: 582.0206913948059 and batch: 200, loss is 3.897956624031067 and perplexity is 49.301604395139194
At time: 583.0172686576843 and batch: 250, loss is 3.906270136833191 and perplexity is 49.713182373341255
At time: 584.01402592659 and batch: 300, loss is 3.9222704362869263 and perplexity is 50.51500577928159
At time: 585.0104978084564 and batch: 350, loss is 3.939852137565613 and perplexity is 51.41099898302827
At time: 586.0066862106323 and batch: 400, loss is 3.8804312992095946 and perplexity is 48.4451049015905
At time: 587.0029006004333 and batch: 450, loss is 3.923958077430725 and perplexity is 50.600328958616956
At time: 587.9986855983734 and batch: 500, loss is 3.93423481464386 and perplexity is 51.12301640284247
At time: 589.019704580307 and batch: 550, loss is 3.8982499265670776 and perplexity is 49.31606680156424
At time: 590.0190777778625 and batch: 600, loss is 3.8739493465423585 and perplexity is 48.13210155701194
At time: 591.0138580799103 and batch: 650, loss is 3.900615916252136 and perplexity is 49.432886249233135
At time: 592.0074138641357 and batch: 700, loss is 3.9411554527282715 and perplexity is 51.47804740064907
At time: 593.004490852356 and batch: 750, loss is 3.8867346239089966 and perplexity is 48.75143456128252
At time: 594.0014729499817 and batch: 800, loss is 3.891580095291138 and perplexity is 48.988231475318045
At time: 594.9991002082825 and batch: 850, loss is 3.8986772775650023 and perplexity is 49.33714657583608
At time: 595.9965875148773 and batch: 900, loss is 3.843888602256775 and perplexity is 46.70674572223199
At time: 596.9925451278687 and batch: 950, loss is 3.929327383041382 and perplexity is 50.87274828563156
At time: 597.9884567260742 and batch: 1000, loss is 3.8976742744445803 and perplexity is 49.28768607253387
At time: 598.984610080719 and batch: 1050, loss is 3.8515965700149537 and perplexity is 47.06815087263365
At time: 599.9816522598267 and batch: 1100, loss is 3.86622004032135 and perplexity is 47.76150786608176
At time: 600.9794273376465 and batch: 1150, loss is 3.8492370319366453 and perplexity is 46.95722269946369
At time: 601.9758875370026 and batch: 1200, loss is 3.889432554244995 and perplexity is 48.88314012183397
At time: 602.9734039306641 and batch: 1250, loss is 3.8929790925979613 and perplexity is 49.05681384130496
At time: 603.9702413082123 and batch: 1300, loss is 3.8770485734939575 and perplexity is 48.28150526180103
At time: 604.9674246311188 and batch: 1350, loss is 3.769055528640747 and perplexity is 43.3391129490379
At time: 605.9656772613525 and batch: 1400, loss is 3.7956762170791625 and perplexity is 44.50832352020109
At time: 606.9627165794373 and batch: 1450, loss is 3.7301788997650145 and perplexity is 41.68656521369818
At time: 607.9594578742981 and batch: 1500, loss is 3.739688515663147 and perplexity is 42.08487934246145
At time: 608.958270072937 and batch: 1550, loss is 3.748325853347778 and perplexity is 42.449955028087224
At time: 609.9559042453766 and batch: 1600, loss is 3.822782588005066 and perplexity is 45.731282759815066
At time: 610.9573810100555 and batch: 1650, loss is 3.787301559448242 and perplexity is 44.137137994260634
At time: 611.958131313324 and batch: 1700, loss is 3.775405101776123 and perplexity is 43.61517332159779
At time: 612.9476792812347 and batch: 1750, loss is 3.767280945777893 and perplexity is 43.26227230212002
At time: 613.9388649463654 and batch: 1800, loss is 3.726788892745972 and perplexity is 41.54548672865909
At time: 614.9346129894257 and batch: 1850, loss is 3.7533319568634034 and perplexity is 42.662996706618515
At time: 615.927493095398 and batch: 1900, loss is 3.860999231338501 and perplexity is 47.512803939533796
At time: 616.9214971065521 and batch: 1950, loss is 3.7912619495391846 and perplexity is 44.31228487427271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340770916606105 and perplexity of 76.76669725416494
finished 15 epochs...
Completing Train Step...
At time: 620.2631511688232 and batch: 50, loss is 3.9539917421340944 and perplexity is 52.14309374718316
At time: 621.2576653957367 and batch: 100, loss is 3.949253211021423 and perplexity is 51.89659655369199
At time: 622.2529990673065 and batch: 150, loss is 3.9065230560302733 and perplexity is 49.72575738167499
At time: 623.2577364444733 and batch: 200, loss is 3.8923430109024046 and perplexity is 49.025619622065875
At time: 624.2566635608673 and batch: 250, loss is 3.9003520345687868 and perplexity is 49.41984353693899
At time: 625.2526576519012 and batch: 300, loss is 3.916210913658142 and perplexity is 50.20983448860761
At time: 626.2482590675354 and batch: 350, loss is 3.9338390588760377 and perplexity is 51.10278817721507
At time: 627.2433896064758 and batch: 400, loss is 3.8742578744888307 and perplexity is 48.146953946535525
At time: 628.2392599582672 and batch: 450, loss is 3.917991714477539 and perplexity is 50.2993278642946
At time: 629.234368801117 and batch: 500, loss is 3.928378953933716 and perplexity is 50.824521963609314
At time: 630.2438805103302 and batch: 550, loss is 3.892722501754761 and perplexity is 49.04422792686095
At time: 631.2456922531128 and batch: 600, loss is 3.8686076259613036 and perplexity is 47.87567879860828
At time: 632.249913930893 and batch: 650, loss is 3.895620446205139 and perplexity is 49.18656151280668
At time: 633.2520990371704 and batch: 700, loss is 3.936506791114807 and perplexity is 51.23929873857937
At time: 634.253146648407 and batch: 750, loss is 3.882367434501648 and perplexity is 48.53899203868856
At time: 635.2608160972595 and batch: 800, loss is 3.887332339286804 and perplexity is 48.78058275370361
At time: 636.2614462375641 and batch: 850, loss is 3.8945705318450927 and perplexity is 49.134946935737226
At time: 637.2646889686584 and batch: 900, loss is 3.839723300933838 and perplexity is 46.512602665345085
At time: 638.2655429840088 and batch: 950, loss is 3.9254366874694826 and perplexity is 50.67520245368907
At time: 639.2998046875 and batch: 1000, loss is 3.8940430212020876 and perplexity is 49.1090345634121
At time: 640.2998855113983 and batch: 1050, loss is 3.8483629512786863 and perplexity is 46.91619623218345
At time: 641.3010196685791 and batch: 1100, loss is 3.8631011772155763 and perplexity is 47.612778315437716
At time: 642.3026914596558 and batch: 1150, loss is 3.8463988161087035 and perplexity is 46.82413691918494
At time: 643.3037211894989 and batch: 1200, loss is 3.8867928123474123 and perplexity is 48.75427141366537
At time: 644.3046073913574 and batch: 1250, loss is 3.8904658699035646 and perplexity is 48.933677942225714
At time: 645.3056335449219 and batch: 1300, loss is 3.874822745323181 and perplexity is 48.174158439371645
At time: 646.3071203231812 and batch: 1350, loss is 3.76684232711792 and perplexity is 43.24330082314198
At time: 647.307831287384 and batch: 1400, loss is 3.793540759086609 and perplexity is 44.41337927580772
At time: 648.3066005706787 and batch: 1450, loss is 3.7282920408248903 and perplexity is 41.607982705809775
At time: 649.3036775588989 and batch: 1500, loss is 3.7384291791915896 and perplexity is 42.03191367680162
At time: 650.299026966095 and batch: 1550, loss is 3.7474296283721924 and perplexity is 42.41192736139627
At time: 651.294629573822 and batch: 1600, loss is 3.822111029624939 and perplexity is 45.70058184352637
At time: 652.2942132949829 and batch: 1650, loss is 3.7866553354263304 and perplexity is 44.10862472940093
At time: 653.2943842411041 and batch: 1700, loss is 3.774759840965271 and perplexity is 43.587039237382
At time: 654.293377161026 and batch: 1750, loss is 3.766850652694702 and perplexity is 43.24366085006201
At time: 655.2933418750763 and batch: 1800, loss is 3.7266041660308837 and perplexity is 41.537812876173575
At time: 656.2906119823456 and batch: 1850, loss is 3.7531387567520142 and perplexity is 42.65475500707687
At time: 657.286961555481 and batch: 1900, loss is 3.8608699321746824 and perplexity is 47.50666097086266
At time: 658.28378033638 and batch: 1950, loss is 3.790927391052246 and perplexity is 44.29746230293917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340699093840843 and perplexity of 76.76118385568428
finished 16 epochs...
Completing Train Step...
At time: 661.5524158477783 and batch: 50, loss is 3.9500429821014404 and perplexity is 51.93759917401205
At time: 662.5776507854462 and batch: 100, loss is 3.9448865365982058 and perplexity is 51.670475071619116
At time: 663.5735356807709 and batch: 150, loss is 3.9021218109130857 and perplexity is 49.50738304679789
At time: 664.7203891277313 and batch: 200, loss is 3.887616171836853 and perplexity is 48.79443023598961
At time: 665.7130196094513 and batch: 250, loss is 3.8954219961166383 and perplexity is 49.176801403800695
At time: 666.705677986145 and batch: 300, loss is 3.911190824508667 and perplexity is 49.95840826235157
At time: 667.7021009922028 and batch: 350, loss is 3.9288338565826417 and perplexity is 50.847647432800755
At time: 668.6936495304108 and batch: 400, loss is 3.8691811466217043 and perplexity is 47.90314436481198
At time: 669.687949180603 and batch: 450, loss is 3.913086791038513 and perplexity is 50.053217581548495
At time: 670.6878483295441 and batch: 500, loss is 3.9236105918884276 and perplexity is 50.58274913041329
At time: 671.6843638420105 and batch: 550, loss is 3.888214945793152 and perplexity is 48.82365581891312
At time: 672.6805603504181 and batch: 600, loss is 3.864198169708252 and perplexity is 47.66503783471461
At time: 673.6776864528656 and batch: 650, loss is 3.8914356517791746 and perplexity is 48.98115595413774
At time: 674.6734564304352 and batch: 700, loss is 3.932566885948181 and perplexity is 51.037817929015915
At time: 675.672306060791 and batch: 750, loss is 3.878648910522461 and perplexity is 48.358833801822655
At time: 676.6801567077637 and batch: 800, loss is 3.883704733848572 and perplexity is 48.60394662322376
At time: 677.6766662597656 and batch: 850, loss is 3.89107581615448 and perplexity is 48.963533959987494
At time: 678.6768684387207 and batch: 900, loss is 3.8361947679519655 and perplexity is 46.34877062612776
At time: 679.6830658912659 and batch: 950, loss is 3.9221294593811034 and perplexity is 50.507884832025546
At time: 680.6815648078918 and batch: 1000, loss is 3.8909270858764646 and perplexity is 48.95625214149589
At time: 681.679178237915 and batch: 1050, loss is 3.8455395555496215 and perplexity is 46.78392006596955
At time: 682.6733872890472 and batch: 1100, loss is 3.86032030582428 and perplexity is 47.4805572324818
At time: 683.6701922416687 and batch: 1150, loss is 3.8438218212127686 and perplexity is 46.70362670113743
At time: 684.6611738204956 and batch: 1200, loss is 3.8843639278411866 and perplexity is 48.63599661527569
At time: 685.6517283916473 and batch: 1250, loss is 3.888120074272156 and perplexity is 48.81902406413928
At time: 686.6531224250793 and batch: 1300, loss is 3.872680912017822 and perplexity is 48.071087841790515
At time: 687.6488840579987 and batch: 1350, loss is 3.76469012260437 and perplexity is 43.150332475264236
At time: 688.6424043178558 and batch: 1400, loss is 3.791461033821106 and perplexity is 44.32110763189424
At time: 689.6331629753113 and batch: 1450, loss is 3.7263319635391237 and perplexity is 41.526507718722236
At time: 690.6293611526489 and batch: 1500, loss is 3.7369416046142576 and perplexity is 41.969434553278845
At time: 691.620612859726 and batch: 1550, loss is 3.7462371587753296 and perplexity is 42.361382570026436
At time: 692.6124637126923 and batch: 1600, loss is 3.821090536117554 and perplexity is 45.65396848483157
At time: 693.6095743179321 and batch: 1650, loss is 3.7856304264068603 and perplexity is 44.06344056086555
At time: 694.6036691665649 and batch: 1700, loss is 3.773710503578186 and perplexity is 43.54132571616596
At time: 695.602561712265 and batch: 1750, loss is 3.765984754562378 and perplexity is 43.206232451825734
At time: 696.6034021377563 and batch: 1800, loss is 3.7259232091903685 and perplexity is 41.50953704675786
At time: 697.5993070602417 and batch: 1850, loss is 3.7524629068374633 and perplexity is 42.62593653412834
At time: 698.5964324474335 and batch: 1900, loss is 3.8602439546585083 and perplexity is 47.47693217497606
At time: 699.5927250385284 and batch: 1950, loss is 3.790156660079956 and perplexity is 44.26333403029624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340783407521802 and perplexity of 76.7676561464974
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 702.9448485374451 and batch: 50, loss is 3.951675763130188 and perplexity is 52.02247117045937
At time: 703.939350605011 and batch: 100, loss is 3.9548191595077515 and perplexity is 52.18625570287936
At time: 704.9342353343964 and batch: 150, loss is 3.918371253013611 and perplexity is 50.318422020812505
At time: 705.9298717975616 and batch: 200, loss is 3.907152132987976 and perplexity is 49.75704855109303
At time: 706.9284672737122 and batch: 250, loss is 3.9164016246795654 and perplexity is 50.21941097056973
At time: 707.9368989467621 and batch: 300, loss is 3.929127607345581 and perplexity is 50.862586162051954
At time: 708.9288954734802 and batch: 350, loss is 3.949048624038696 and perplexity is 51.88598027160286
At time: 709.9223816394806 and batch: 400, loss is 3.893712124824524 and perplexity is 49.09278725000624
At time: 710.9106845855713 and batch: 450, loss is 3.941612892150879 and perplexity is 51.50160087566228
At time: 711.9071176052094 and batch: 500, loss is 3.953919515609741 and perplexity is 52.13932776875617
At time: 712.895366191864 and batch: 550, loss is 3.9203705263137816 and perplexity is 50.41912292924162
At time: 713.8908038139343 and batch: 600, loss is 3.8855408239364624 and perplexity is 48.693269825480094
At time: 714.889720916748 and batch: 650, loss is 3.902053165435791 and perplexity is 49.503984705500734
At time: 715.9280731678009 and batch: 700, loss is 3.9460894775390627 and perplexity is 51.73266900182886
At time: 716.9221363067627 and batch: 750, loss is 3.891909294128418 and perplexity is 49.004360998924675
At time: 717.9146902561188 and batch: 800, loss is 3.893118863105774 and perplexity is 49.06367101629148
At time: 718.9094731807709 and batch: 850, loss is 3.9014880657196045 and perplexity is 49.47601792054892
At time: 719.9074060916901 and batch: 900, loss is 3.8451806640625 and perplexity is 46.767132727920256
At time: 720.9097142219543 and batch: 950, loss is 3.9336295461654665 and perplexity is 51.092082615061145
At time: 721.9078052043915 and batch: 1000, loss is 3.902515697479248 and perplexity is 49.5268871808619
At time: 722.9030694961548 and batch: 1050, loss is 3.8568201160430906 and perplexity is 47.314656782156995
At time: 723.8956038951874 and batch: 1100, loss is 3.866900143623352 and perplexity is 47.794001673610495
At time: 724.8898639678955 and batch: 1150, loss is 3.8526634263992308 and perplexity is 47.11839262549028
At time: 725.8844759464264 and batch: 1200, loss is 3.8931908941268922 and perplexity is 49.0672052499003
At time: 726.8772313594818 and batch: 1250, loss is 3.894144892692566 and perplexity is 49.11403762878957
At time: 727.8716111183167 and batch: 1300, loss is 3.8759645652770995 and perplexity is 48.22919607029394
At time: 728.8698499202728 and batch: 1350, loss is 3.7619979858398436 and perplexity is 43.03432210676148
At time: 729.870283126831 and batch: 1400, loss is 3.789744272232056 and perplexity is 44.24508413251127
At time: 730.8676283359528 and batch: 1450, loss is 3.721366562843323 and perplexity is 41.3208230444136
At time: 731.8683881759644 and batch: 1500, loss is 3.73284396648407 and perplexity is 41.797810863976785
At time: 732.8675074577332 and batch: 1550, loss is 3.7434295511245725 and perplexity is 42.242615232286106
At time: 733.8630952835083 and batch: 1600, loss is 3.814815011024475 and perplexity is 45.36836295964065
At time: 734.856597661972 and batch: 1650, loss is 3.7796154737472536 and perplexity is 43.79919655614963
At time: 735.8492364883423 and batch: 1700, loss is 3.7674336338043215 and perplexity is 43.2688784374227
At time: 736.8477063179016 and batch: 1750, loss is 3.761181364059448 and perplexity is 42.999193687292944
At time: 737.8466956615448 and batch: 1800, loss is 3.721499676704407 and perplexity is 41.32632378481649
At time: 738.8444263935089 and batch: 1850, loss is 3.745018033981323 and perplexity is 42.309770225563796
At time: 739.8404741287231 and batch: 1900, loss is 3.8504404640197754 and perplexity is 47.01376654430928
At time: 740.8337473869324 and batch: 1950, loss is 3.7864167642593385 and perplexity is 44.09810293847271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336419535792151 and perplexity of 76.43338183766707
finished 18 epochs...
Completing Train Step...
At time: 744.152184009552 and batch: 50, loss is 3.9559592723846437 and perplexity is 52.24578785524114
At time: 745.1953589916229 and batch: 100, loss is 3.952393469810486 and perplexity is 52.0598214472123
At time: 746.1895356178284 and batch: 150, loss is 3.913026714324951 and perplexity is 50.050210639057504
At time: 747.1874577999115 and batch: 200, loss is 3.8977713203430175 and perplexity is 49.2924694724116
At time: 748.1856164932251 and batch: 250, loss is 3.9042513465881346 and perplexity is 49.61292312096623
At time: 749.1784284114838 and batch: 300, loss is 3.9165495157241823 and perplexity is 50.22683852093877
At time: 750.1728489398956 and batch: 350, loss is 3.9361753034591676 and perplexity is 51.222316358444104
At time: 751.1844086647034 and batch: 400, loss is 3.880971269607544 and perplexity is 48.47127088795618
At time: 752.1858713626862 and batch: 450, loss is 3.928776516914368 and perplexity is 50.84473192915225
At time: 753.1823952198029 and batch: 500, loss is 3.941788682937622 and perplexity is 51.51065517840691
At time: 754.1754703521729 and batch: 550, loss is 3.9081697416305543 and perplexity is 49.80770752486101
At time: 755.1804525852203 and batch: 600, loss is 3.8760910987854005 and perplexity is 48.23529906578381
At time: 756.1766011714935 and batch: 650, loss is 3.895060830116272 and perplexity is 49.15904362207341
At time: 757.1702885627747 and batch: 700, loss is 3.938744263648987 and perplexity is 51.354073617113784
At time: 758.1721892356873 and batch: 750, loss is 3.8854352188110353 and perplexity is 48.688127838127606
At time: 759.1736521720886 and batch: 800, loss is 3.887988772392273 and perplexity is 48.81261445531165
At time: 760.1701109409332 and batch: 850, loss is 3.895999789237976 and perplexity is 49.205223631674365
At time: 761.1677494049072 and batch: 900, loss is 3.8410631799697876 and perplexity is 46.57496569669309
At time: 762.1671161651611 and batch: 950, loss is 3.9297223615646364 and perplexity is 50.89284589742454
At time: 763.1668055057526 and batch: 1000, loss is 3.897523488998413 and perplexity is 49.280254767079306
At time: 764.1672008037567 and batch: 1050, loss is 3.8514254093170166 and perplexity is 47.060095344494265
At time: 765.1659758090973 and batch: 1100, loss is 3.8626662158966063 and perplexity is 47.592073101891735
At time: 766.2256853580475 and batch: 1150, loss is 3.8486766242980956 and perplexity is 46.93091488541632
At time: 767.2232329845428 and batch: 1200, loss is 3.888979687690735 and perplexity is 48.86100759452453
At time: 768.2171771526337 and batch: 1250, loss is 3.891098880767822 and perplexity is 48.96466329798998
At time: 769.2127456665039 and batch: 1300, loss is 3.8737819242477416 and perplexity is 48.1240438446637
At time: 770.2067224979401 and batch: 1350, loss is 3.7612368774414064 and perplexity is 43.00158078421331
At time: 771.2061791419983 and batch: 1400, loss is 3.7897388887405397 and perplexity is 44.244845940117365
At time: 772.2061505317688 and batch: 1450, loss is 3.722412724494934 and perplexity is 41.36407392465716
At time: 773.2062270641327 and batch: 1500, loss is 3.735082950592041 and perplexity is 41.891500343738166
At time: 774.2029061317444 and batch: 1550, loss is 3.746212863922119 and perplexity is 42.360353418956684
At time: 775.1984639167786 and batch: 1600, loss is 3.817604365348816 and perplexity is 45.49508805748488
At time: 776.191370010376 and batch: 1650, loss is 3.782793936729431 and perplexity is 43.93863215911488
At time: 777.1931900978088 and batch: 1700, loss is 3.770785331726074 and perplexity is 43.41414595778791
At time: 778.202094078064 and batch: 1750, loss is 3.7652129316329956 and perplexity is 43.172897756822984
At time: 779.1982421875 and batch: 1800, loss is 3.725312423706055 and perplexity is 41.48419136524426
At time: 780.1896340847015 and batch: 1850, loss is 3.7492714023590086 and perplexity is 42.490112523538926
At time: 781.1932289600372 and batch: 1900, loss is 3.8549113988876345 and perplexity is 47.2244326186488
At time: 782.1978793144226 and batch: 1950, loss is 3.7903575992584226 and perplexity is 44.27222916193278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335509118368459 and perplexity of 76.3638272217617
finished 19 epochs...
Completing Train Step...
At time: 785.5197176933289 and batch: 50, loss is 3.9560972356796267 and perplexity is 52.25299635352528
At time: 786.5195555686951 and batch: 100, loss is 3.950856647491455 and perplexity is 51.97987619824363
At time: 787.5162811279297 and batch: 150, loss is 3.9107624101638794 and perplexity is 49.937009947609
At time: 788.5126910209656 and batch: 200, loss is 3.894152088165283 and perplexity is 49.1143910287788
At time: 789.5181884765625 and batch: 250, loss is 3.899907560348511 and perplexity is 49.397882571419814
At time: 790.5164847373962 and batch: 300, loss is 3.912248239517212 and perplexity is 50.01126297280838
At time: 791.5116169452667 and batch: 350, loss is 3.9318764352798463 and perplexity is 51.00259099614561
At time: 792.5397119522095 and batch: 400, loss is 3.8765840625762937 and perplexity is 48.25908318353893
At time: 793.5343744754791 and batch: 450, loss is 3.9242897415161133 and perplexity is 50.617114053794104
At time: 794.5278520584106 and batch: 500, loss is 3.937442078590393 and perplexity is 51.28724463104864
At time: 795.5248005390167 and batch: 550, loss is 3.9038344860076903 and perplexity is 49.59224575912445
At time: 796.5324602127075 and batch: 600, loss is 3.8725981855392457 and perplexity is 48.06711125445883
At time: 797.5337207317352 and batch: 650, loss is 3.8921632957458496 and perplexity is 49.01680976681626
At time: 798.5341167449951 and batch: 700, loss is 3.9357968378067016 and perplexity is 51.2029341390462
At time: 799.5335426330566 and batch: 750, loss is 3.882733039855957 and perplexity is 48.55674139850347
At time: 800.5335655212402 and batch: 800, loss is 3.8857546710968016 and perplexity is 48.70368385642569
At time: 801.5339045524597 and batch: 850, loss is 3.8935810995101927 and perplexity is 49.08635527351049
At time: 802.5351731777191 and batch: 900, loss is 3.8387781476974485 and perplexity is 46.46866189705379
At time: 803.5356597900391 and batch: 950, loss is 3.9277077674865724 and perplexity is 50.790420678725106
At time: 804.5359928607941 and batch: 1000, loss is 3.8953387403488158 and perplexity is 49.172707321871094
At time: 805.5365400314331 and batch: 1050, loss is 3.849274959564209 and perplexity is 46.95900370929218
At time: 806.5367615222931 and batch: 1100, loss is 3.8609629106521606 and perplexity is 47.51107827322364
At time: 807.5383720397949 and batch: 1150, loss is 3.8470885658264162 and perplexity is 46.85644499536941
At time: 808.5392200946808 and batch: 1200, loss is 3.8874475860595705 and perplexity is 48.7862048823995
At time: 809.5398590564728 and batch: 1250, loss is 3.8899609804153443 and perplexity is 48.908978078488204
At time: 810.539865732193 and batch: 1300, loss is 3.8730354833602907 and perplexity is 48.08813549406638
At time: 811.5404183864594 and batch: 1350, loss is 3.7609855794906615 and perplexity is 42.990775932758815
At time: 812.5395205020905 and batch: 1400, loss is 3.789708123207092 and perplexity is 44.24348474476878
At time: 813.5408751964569 and batch: 1450, loss is 3.7227256631851198 and perplexity is 41.377020369387964
At time: 814.5413036346436 and batch: 1500, loss is 3.7359972953796388 and perplexity is 41.92982113526035
At time: 815.5436203479767 and batch: 1550, loss is 3.74737774848938 and perplexity is 42.40972709265025
At time: 816.5432484149933 and batch: 1600, loss is 3.81879608631134 and perplexity is 45.549337826487886
At time: 817.5436570644379 and batch: 1650, loss is 3.7840664386749268 and perplexity is 43.99457974317507
At time: 818.5446243286133 and batch: 1700, loss is 3.7720045375823976 and perplexity is 43.46710901866329
At time: 819.5487115383148 and batch: 1750, loss is 3.7666509675979616 and perplexity is 43.235026597556214
At time: 820.5546429157257 and batch: 1800, loss is 3.7267733430862426 and perplexity is 41.54484071549984
At time: 821.5534052848816 and batch: 1850, loss is 3.750851340293884 and perplexity is 42.55729732410395
At time: 822.5503685474396 and batch: 1900, loss is 3.856476893424988 and perplexity is 47.29842010833784
At time: 823.5477955341339 and batch: 1950, loss is 3.7916078996658324 and perplexity is 44.32761736682298
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3350645553234015 and perplexity of 76.32988623121379
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fcae8787b38>
ELAPSED
3401.1306445598602


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.42392198682246}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.7974071334468391, 'wordvec_source': 'gigavec', 'dropout': 0.589069126925909, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.51251288675175}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.014077492312028927, 'wordvec_source': 'gigavec', 'dropout': 0.3289390596927714, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -77.08629938542906}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5708626383639636, 'wordvec_source': 'gigavec', 'dropout': 0.49301208999077983, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.32988623121379}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.4614530027327207, 'wordvec_source': 'gigavec', 'dropout': 0.04151275008878008, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5010831356048584 and batch: 50, loss is 7.533037738800049 and perplexity is 1868.773736379837
At time: 2.4917845726013184 and batch: 100, loss is 6.661456871032715 and perplexity is 781.6889279282999
At time: 3.483062982559204 and batch: 150, loss is 6.374575862884521 and perplexity is 586.7365214238151
At time: 4.472866773605347 and batch: 200, loss is 6.121593637466431 and perplexity is 455.5901618312583
At time: 5.4637556076049805 and batch: 250, loss is 5.97666296005249 and perplexity is 394.12296718229834
At time: 6.4550697803497314 and batch: 300, loss is 5.844963521957397 and perplexity is 345.4899387545106
At time: 7.447486162185669 and batch: 350, loss is 5.7438161754608155 and perplexity is 312.2537552831952
At time: 8.438395261764526 and batch: 400, loss is 5.653229494094848 and perplexity is 285.21106755894255
At time: 9.42950177192688 and batch: 450, loss is 5.547736358642578 and perplexity is 256.65592089044384
At time: 10.420495986938477 and batch: 500, loss is 5.5063011169433596 and perplexity is 246.2386325968278
At time: 11.438722848892212 and batch: 550, loss is 5.448684673309327 and perplexity is 232.45221413694676
At time: 12.429869651794434 and batch: 600, loss is 5.437788076400757 and perplexity is 229.93302627277635
At time: 13.42158317565918 and batch: 650, loss is 5.489772682189941 and perplexity is 242.20214373887111
At time: 14.413299083709717 and batch: 700, loss is 5.423644790649414 and perplexity is 226.70390678557845
At time: 15.40524172782898 and batch: 750, loss is 5.355249328613281 and perplexity is 211.71675681816643
At time: 16.39705181121826 and batch: 800, loss is 5.3414122581481935 and perplexity is 208.80739209761867
At time: 17.3889479637146 and batch: 850, loss is 5.345258588790894 and perplexity is 209.61208092585062
At time: 18.381151914596558 and batch: 900, loss is 5.336303415298462 and perplexity is 207.74334827618293
At time: 19.380090951919556 and batch: 950, loss is 5.357206735610962 and perplexity is 212.13157853450667
At time: 20.37226128578186 and batch: 1000, loss is 5.316453809738159 and perplexity is 203.6603814544456
At time: 21.361048936843872 and batch: 1050, loss is 5.213415279388427 and perplexity is 183.7204445902309
At time: 22.3497097492218 and batch: 1100, loss is 5.2865684127807615 and perplexity is 197.66395913638644
At time: 23.338001251220703 and batch: 1150, loss is 5.177187843322754 and perplexity is 177.18384100971375
At time: 24.326093435287476 and batch: 1200, loss is 5.2588037109375 and perplexity is 192.2513654704225
At time: 25.316745042800903 and batch: 1250, loss is 5.216631660461426 and perplexity is 184.3123108744476
At time: 26.307796239852905 and batch: 1300, loss is 5.226721000671387 and perplexity is 186.1813131290137
At time: 27.302385091781616 and batch: 1350, loss is 5.153980369567871 and perplexity is 173.11919913310913
At time: 28.29339075088501 and batch: 1400, loss is 5.146424627304077 and perplexity is 171.81608428299924
At time: 29.285097122192383 and batch: 1450, loss is 5.105710411071778 and perplexity is 164.96121919138938
At time: 30.27729845046997 and batch: 1500, loss is 5.060595407485962 and perplexity is 157.68437483576005
At time: 31.268611907958984 and batch: 1550, loss is 5.058576421737671 and perplexity is 157.36633349873804
At time: 32.26516079902649 and batch: 1600, loss is 5.094249811172485 and perplexity is 163.08145683625833
At time: 33.27025246620178 and batch: 1650, loss is 5.070980033874512 and perplexity is 159.33040004181998
At time: 34.273751974105835 and batch: 1700, loss is 5.082540960311889 and perplexity is 161.18309588096602
At time: 35.263367891311646 and batch: 1750, loss is 5.079222993850708 and perplexity is 160.6491820186847
At time: 36.264832496643066 and batch: 1800, loss is 5.036133947372437 and perplexity is 153.8739787146749
At time: 37.263028383255005 and batch: 1850, loss is 5.033116607666016 and perplexity is 153.4103884053616
At time: 38.25992703437805 and batch: 1900, loss is 5.126686000823975 and perplexity is 168.45792255343576
At time: 39.25330424308777 and batch: 1950, loss is 5.036566486358643 and perplexity is 153.94054960564657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.808229810138082 and perplexity of 122.51455143297288
finished 1 epochs...
Completing Train Step...
At time: 42.48224234580994 and batch: 50, loss is 5.029609489440918 and perplexity is 152.87330239883434
At time: 43.50251913070679 and batch: 100, loss is 4.980848655700684 and perplexity is 145.5978917182512
At time: 44.491353273391724 and batch: 150, loss is 4.9227815437316895 and perplexity is 137.38422243176294
At time: 45.52044630050659 and batch: 200, loss is 4.887597713470459 and perplexity is 132.63456480051437
At time: 46.50942277908325 and batch: 250, loss is 4.9074060916900635 and perplexity is 135.28803412541197
At time: 47.49932622909546 and batch: 300, loss is 4.91428994178772 and perplexity is 136.22254951391113
At time: 48.48663330078125 and batch: 350, loss is 4.910789918899536 and perplexity is 135.74660087416257
At time: 49.478270292282104 and batch: 400, loss is 4.856858501434326 and perplexity is 128.61950876612312
At time: 50.46748161315918 and batch: 450, loss is 4.830472354888916 and perplexity is 125.27011863485696
At time: 51.45798993110657 and batch: 500, loss is 4.832773962020874 and perplexity is 125.558773290709
At time: 52.447218894958496 and batch: 550, loss is 4.794539251327515 and perplexity is 120.84868808103504
At time: 53.43861794471741 and batch: 600, loss is 4.7649563217163085 and perplexity is 117.32599257790203
At time: 54.42877674102783 and batch: 650, loss is 4.842912006378174 and perplexity is 126.83816802607605
At time: 55.41924548149109 and batch: 700, loss is 4.847740936279297 and perplexity is 127.45214187351414
At time: 56.410820960998535 and batch: 750, loss is 4.7965200328826905 and perplexity is 121.08830016460783
At time: 57.40172863006592 and batch: 800, loss is 4.79274435043335 and perplexity is 120.63197121357183
At time: 58.39342141151428 and batch: 850, loss is 4.786340398788452 and perplexity is 119.86191822583274
At time: 59.38329577445984 and batch: 900, loss is 4.769094371795655 and perplexity is 117.81249931118857
At time: 60.37560486793518 and batch: 950, loss is 4.82178144454956 and perplexity is 124.18612453636477
At time: 61.36895251274109 and batch: 1000, loss is 4.797340288162231 and perplexity is 121.18766422848628
At time: 62.36467432975769 and batch: 1050, loss is 4.716971387863159 and perplexity is 111.82905244863747
At time: 63.355799436569214 and batch: 1100, loss is 4.7789665222167965 and perplexity is 118.98132192952185
At time: 64.34783720970154 and batch: 1150, loss is 4.71703932762146 and perplexity is 111.83665034552857
At time: 65.340336561203 and batch: 1200, loss is 4.784617900848389 and perplexity is 119.65563403165022
At time: 66.33272361755371 and batch: 1250, loss is 4.771294021606446 and perplexity is 118.0719307775912
At time: 67.32302570343018 and batch: 1300, loss is 4.768194780349732 and perplexity is 117.70656385104647
At time: 68.31318283081055 and batch: 1350, loss is 4.659125299453735 and perplexity is 105.54372261725027
At time: 69.30439400672913 and batch: 1400, loss is 4.660524635314942 and perplexity is 105.69151711618818
At time: 70.29535627365112 and batch: 1450, loss is 4.617172536849975 and perplexity is 101.2074668111042
At time: 71.2867693901062 and batch: 1500, loss is 4.6007648468017575 and perplexity is 99.56043500869391
At time: 72.27879738807678 and batch: 1550, loss is 4.612913665771484 and perplexity is 100.77735380580938
At time: 73.26857995986938 and batch: 1600, loss is 4.672128162384033 and perplexity is 106.92505434689699
At time: 74.2589054107666 and batch: 1650, loss is 4.645551176071167 and perplexity is 104.12073883239415
At time: 75.24977588653564 and batch: 1700, loss is 4.650230836868286 and perplexity is 104.60913043430898
At time: 76.24132943153381 and batch: 1750, loss is 4.637852306365967 and perplexity is 103.32220467997377
At time: 77.23395276069641 and batch: 1800, loss is 4.600326747894287 and perplexity is 99.51682724384385
At time: 78.22462344169617 and batch: 1850, loss is 4.631321792602539 and perplexity is 102.64965603455056
At time: 79.21577882766724 and batch: 1900, loss is 4.735659923553467 and perplexity is 113.938624695669
At time: 80.20716166496277 and batch: 1950, loss is 4.656554546356201 and perplexity is 105.27274422391488
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5948489166969475 and perplexity of 98.9731812228892
finished 2 epochs...
Completing Train Step...
At time: 83.44456791877747 and batch: 50, loss is 4.65644962310791 and perplexity is 105.26169924508211
At time: 84.441565990448 and batch: 100, loss is 4.618482532501221 and perplexity is 101.34013503092334
At time: 85.44020104408264 and batch: 150, loss is 4.578510427474976 and perplexity is 97.36924757470456
At time: 86.43809175491333 and batch: 200, loss is 4.55831506729126 and perplexity is 95.42256370297841
At time: 87.4373710155487 and batch: 250, loss is 4.566185932159424 and perplexity is 96.17658531570423
At time: 88.43534231185913 and batch: 300, loss is 4.57626259803772 and perplexity is 97.15062392011986
At time: 89.4334487915039 and batch: 350, loss is 4.586146478652954 and perplexity is 98.11561013705632
At time: 90.43092799186707 and batch: 400, loss is 4.529091653823852 and perplexity is 92.67434245347314
At time: 91.42887282371521 and batch: 450, loss is 4.535275735855103 and perplexity is 93.24922391436188
At time: 92.4275336265564 and batch: 500, loss is 4.544565782546997 and perplexity is 94.11954998397492
At time: 93.42584538459778 and batch: 550, loss is 4.507125377655029 and perplexity is 90.66082792380364
At time: 94.42330431938171 and batch: 600, loss is 4.481879053115844 and perplexity is 88.40062618116437
At time: 95.44836330413818 and batch: 650, loss is 4.55637484550476 and perplexity is 95.23760225709505
At time: 96.4455156326294 and batch: 700, loss is 4.576641511917114 and perplexity is 97.1874426150318
At time: 97.44384050369263 and batch: 750, loss is 4.528407621383667 and perplexity is 92.61097187309942
At time: 98.44081664085388 and batch: 800, loss is 4.527704839706421 and perplexity is 92.54590944397447
At time: 99.43829822540283 and batch: 850, loss is 4.522360210418701 and perplexity is 92.05260530404993
At time: 100.43598079681396 and batch: 900, loss is 4.5031452465057376 and perplexity is 90.30070308601378
At time: 101.43377566337585 and batch: 950, loss is 4.567986526489258 and perplexity is 96.34991633247915
At time: 102.4315812587738 and batch: 1000, loss is 4.542686605453492 and perplexity is 93.94284876003901
At time: 103.4289391040802 and batch: 1050, loss is 4.473117017745972 and perplexity is 87.62944028077933
At time: 104.42636156082153 and batch: 1100, loss is 4.5232465457916256 and perplexity is 92.13423095280699
At time: 105.4235258102417 and batch: 1150, loss is 4.482919225692749 and perplexity is 88.49262592781098
At time: 106.42026281356812 and batch: 1200, loss is 4.543350648880005 and perplexity is 94.00525160803352
At time: 107.4188551902771 and batch: 1250, loss is 4.5470959663391115 and perplexity is 94.357991266795
At time: 108.41732120513916 and batch: 1300, loss is 4.5276391887664795 and perplexity is 92.53983391746594
At time: 109.41410875320435 and batch: 1350, loss is 4.416393842697143 and perplexity is 82.79716674060644
At time: 110.41114902496338 and batch: 1400, loss is 4.4231399822235105 and perplexity is 83.35761628973249
At time: 111.4113438129425 and batch: 1450, loss is 4.380133228302002 and perplexity is 79.8486707992955
At time: 112.41004800796509 and batch: 1500, loss is 4.367958741188049 and perplexity is 78.88244775487046
At time: 113.40805530548096 and batch: 1550, loss is 4.387486915588379 and perplexity is 80.43801723345219
At time: 114.40735840797424 and batch: 1600, loss is 4.455573215484619 and perplexity is 86.10549370404381
At time: 115.40736031532288 and batch: 1650, loss is 4.422980871200561 and perplexity is 83.34435422923202
At time: 116.4075722694397 and batch: 1700, loss is 4.429114646911621 and perplexity is 83.85714085621403
At time: 117.4027669429779 and batch: 1750, loss is 4.4188456630706785 and perplexity is 83.00041958880925
At time: 118.39809060096741 and batch: 1800, loss is 4.378830728530883 and perplexity is 79.74473562631869
At time: 119.39309644699097 and batch: 1850, loss is 4.420337142944336 and perplexity is 83.12430540776846
At time: 120.38929319381714 and batch: 1900, loss is 4.520417490005493 and perplexity is 91.87394642695119
At time: 121.3919849395752 and batch: 1950, loss is 4.445264940261841 and perplexity is 85.22245370576178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.518971713753634 and perplexity of 91.74121323141414
finished 3 epochs...
Completing Train Step...
At time: 124.59417033195496 and batch: 50, loss is 4.447082052230835 and perplexity is 85.37745322951311
At time: 125.61329531669617 and batch: 100, loss is 4.415908126831055 and perplexity is 82.75696060822202
At time: 126.60255026817322 and batch: 150, loss is 4.372740821838379 and perplexity is 79.26057337494481
At time: 127.59309315681458 and batch: 200, loss is 4.361434144973755 and perplexity is 78.36944701609784
At time: 128.58267378807068 and batch: 250, loss is 4.364149227142334 and perplexity is 78.58251562275065
At time: 129.5725634098053 and batch: 300, loss is 4.374723033905029 and perplexity is 79.41784045675787
At time: 130.56272959709167 and batch: 350, loss is 4.386526432037353 and perplexity is 80.36079493233396
At time: 131.55359554290771 and batch: 400, loss is 4.330292510986328 and perplexity is 75.9665043566727
At time: 132.54403972625732 and batch: 450, loss is 4.3516302490234375 and perplexity is 77.60487512746954
At time: 133.5343053340912 and batch: 500, loss is 4.367393836975098 and perplexity is 78.83789931179209
At time: 134.52481985092163 and batch: 550, loss is 4.330126361846924 and perplexity is 75.95388363584028
At time: 135.51612496376038 and batch: 600, loss is 4.308168907165527 and perplexity is 74.3043062141098
At time: 136.5041708946228 and batch: 650, loss is 4.3780694103240965 and perplexity is 79.68404761156751
At time: 137.49351167678833 and batch: 700, loss is 4.399076175689697 and perplexity is 81.37565711887662
At time: 138.48353910446167 and batch: 750, loss is 4.356027460098266 and perplexity is 77.94687150792184
At time: 139.47314763069153 and batch: 800, loss is 4.355937299728393 and perplexity is 77.93984410595758
At time: 140.46269941329956 and batch: 850, loss is 4.351169681549072 and perplexity is 77.56914107573627
At time: 141.45258235931396 and batch: 900, loss is 4.327063722610474 and perplexity is 75.72162014284774
At time: 142.4419379234314 and batch: 950, loss is 4.40538405418396 and perplexity is 81.89058722725906
At time: 143.43121218681335 and batch: 1000, loss is 4.374693384170532 and perplexity is 79.41548577378204
At time: 144.4218099117279 and batch: 1050, loss is 4.317417306900024 and perplexity is 74.99468969028335
At time: 145.457994222641 and batch: 1100, loss is 4.356560764312744 and perplexity is 77.9884519895399
At time: 146.45300722122192 and batch: 1150, loss is 4.326797828674317 and perplexity is 75.70148889972212
At time: 147.44447803497314 and batch: 1200, loss is 4.382772169113159 and perplexity is 80.05966499353237
At time: 148.43657302856445 and batch: 1250, loss is 4.39295994758606 and perplexity is 80.87946399981256
At time: 149.42919754981995 and batch: 1300, loss is 4.363867149353028 and perplexity is 78.5603523664938
At time: 150.42252922058105 and batch: 1350, loss is 4.2601867771148685 and perplexity is 70.82321037389454
At time: 151.41873383522034 and batch: 1400, loss is 4.27083607673645 and perplexity is 71.5814581995624
At time: 152.41263127326965 and batch: 1450, loss is 4.221993923187256 and perplexity is 68.16927316255719
At time: 153.41000747680664 and batch: 1500, loss is 4.215482630729675 and perplexity is 67.72684504095243
At time: 154.40360522270203 and batch: 1550, loss is 4.237676782608032 and perplexity is 69.24678947410997
At time: 155.39687252044678 and batch: 1600, loss is 4.310707015991211 and perplexity is 74.49313816614897
At time: 156.39028096199036 and batch: 1650, loss is 4.273197259902954 and perplexity is 71.75067483080976
At time: 157.3826675415039 and batch: 1700, loss is 4.284263978004455 and perplexity is 72.54912930904219
At time: 158.375803232193 and batch: 1750, loss is 4.27129096031189 and perplexity is 71.61402683611075
At time: 159.369047164917 and batch: 1800, loss is 4.231939363479614 and perplexity is 68.85062917517061
At time: 160.36235880851746 and batch: 1850, loss is 4.2744780445098876 and perplexity is 71.84263086603691
At time: 161.35681986808777 and batch: 1900, loss is 4.371136531829834 and perplexity is 79.13351837279372
At time: 162.35074949264526 and batch: 1950, loss is 4.2989148426055905 and perplexity is 73.61986120101099
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495573957576308 and perplexity of 89.61959207025346
finished 4 epochs...
Completing Train Step...
At time: 165.55058026313782 and batch: 50, loss is 4.306354303359985 and perplexity is 74.16959559744879
At time: 166.56836867332458 and batch: 100, loss is 4.275599718093872 and perplexity is 71.92326005864737
At time: 167.56030559539795 and batch: 150, loss is 4.229736194610596 and perplexity is 68.69910658857273
At time: 168.55273962020874 and batch: 200, loss is 4.224317684173584 and perplexity is 68.32786645508641
At time: 169.54797530174255 and batch: 250, loss is 4.222227220535278 and perplexity is 68.18517872849367
At time: 170.5666003227234 and batch: 300, loss is 4.232007975578308 and perplexity is 68.85535332339974
At time: 171.55810832977295 and batch: 350, loss is 4.247065925598145 and perplexity is 69.90001931745346
At time: 172.54995465278625 and batch: 400, loss is 4.192787232398987 and perplexity is 66.20706851533289
At time: 173.54446458816528 and batch: 450, loss is 4.219249548912049 and perplexity is 67.98244763976741
At time: 174.53779482841492 and batch: 500, loss is 4.242801289558411 and perplexity is 69.6025559133045
At time: 175.53031539916992 and batch: 550, loss is 4.203806843757629 and perplexity is 66.94067930885639
At time: 176.5262336730957 and batch: 600, loss is 4.187236561775207 and perplexity is 65.84059291862664
At time: 177.5183126926422 and batch: 650, loss is 4.249931764602661 and perplexity is 70.10062883922491
At time: 178.5111107826233 and batch: 700, loss is 4.271020870208741 and perplexity is 71.59468720805428
At time: 179.5097041130066 and batch: 750, loss is 4.230065088272095 and perplexity is 68.72170500531467
At time: 180.50563764572144 and batch: 800, loss is 4.22841157913208 and perplexity is 68.60816693196064
At time: 181.49879932403564 and batch: 850, loss is 4.228278374671936 and perplexity is 68.59902862676796
At time: 182.49248719215393 and batch: 900, loss is 4.203214826583863 and perplexity is 66.90106100559704
At time: 183.4870843887329 and batch: 950, loss is 4.2850663948059085 and perplexity is 72.60736731178167
At time: 184.4781210422516 and batch: 1000, loss is 4.249676599502563 and perplexity is 70.08274388715503
At time: 185.47061014175415 and batch: 1050, loss is 4.203544721603394 and perplexity is 66.92313497326995
At time: 186.46946787834167 and batch: 1100, loss is 4.237357783317566 and perplexity is 69.22470332032164
At time: 187.4638123512268 and batch: 1150, loss is 4.212858138084411 and perplexity is 67.54932948029054
At time: 188.456472158432 and batch: 1200, loss is 4.2659207582473755 and perplexity is 71.23047583630351
At time: 189.45030999183655 and batch: 1250, loss is 4.280500402450562 and perplexity is 72.27659834664098
At time: 190.44433116912842 and batch: 1300, loss is 4.2434833097457885 and perplexity is 69.65004245307911
At time: 191.43947792053223 and batch: 1350, loss is 4.139168801307679 and perplexity is 62.750641515089725
At time: 192.43184304237366 and batch: 1400, loss is 4.156517481803894 and perplexity is 63.84878043357061
At time: 193.42963814735413 and batch: 1450, loss is 4.106602411270142 and perplexity is 60.739997063375306
At time: 194.42492961883545 and batch: 1500, loss is 4.1052987670898435 and perplexity is 60.66086531072366
At time: 195.41722321510315 and batch: 1550, loss is 4.127407298088074 and perplexity is 62.016922917802376
At time: 196.40968346595764 and batch: 1600, loss is 4.202203555107117 and perplexity is 66.8334400681635
At time: 197.40802574157715 and batch: 1650, loss is 4.16194715499878 and perplexity is 64.19640132510794
At time: 198.40304017066956 and batch: 1700, loss is 4.176558380126953 and perplexity is 65.14127547185231
At time: 199.3962471485138 and batch: 1750, loss is 4.16243754863739 and perplexity is 64.22789055236677
At time: 200.3896656036377 and batch: 1800, loss is 4.122343120574951 and perplexity is 61.70365211032718
At time: 201.38784313201904 and batch: 1850, loss is 4.168712029457092 and perplexity is 64.63215416558045
At time: 202.38091230392456 and batch: 1900, loss is 4.263658285140991 and perplexity is 71.06950096968848
At time: 203.37414002418518 and batch: 1950, loss is 4.190960431098938 and perplexity is 66.08623176246999
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.490186966297238 and perplexity of 89.13811014317848
finished 5 epochs...
Completing Train Step...
At time: 206.6087281703949 and batch: 50, loss is 4.199311475753785 and perplexity is 66.64043168833416
At time: 207.60514521598816 and batch: 100, loss is 4.171627798080444 and perplexity is 64.82088158178664
At time: 208.59765577316284 and batch: 150, loss is 4.12638578414917 and perplexity is 61.953604112620965
At time: 209.59032201766968 and batch: 200, loss is 4.118324980735779 and perplexity is 61.45621565760872
At time: 210.58257961273193 and batch: 250, loss is 4.117798085212708 and perplexity is 61.423843181919
At time: 211.5749282836914 and batch: 300, loss is 4.123870058059692 and perplexity is 61.79794169851322
At time: 212.56842851638794 and batch: 350, loss is 4.142549276351929 and perplexity is 62.963127442078374
At time: 213.5679488182068 and batch: 400, loss is 4.085837359428406 and perplexity is 59.491732863556415
At time: 214.56230425834656 and batch: 450, loss is 4.116186032295227 and perplexity is 61.32490446496449
At time: 215.55364775657654 and batch: 500, loss is 4.142775421142578 and perplexity is 62.977367835487094
At time: 216.54859614372253 and batch: 550, loss is 4.105647945404053 and perplexity is 60.68205046789483
At time: 217.5419943332672 and batch: 600, loss is 4.095448594093323 and perplexity is 60.06627849232514
At time: 218.5346236228943 and batch: 650, loss is 4.1479466438293455 and perplexity is 63.303881338184596
At time: 219.52839183807373 and batch: 700, loss is 4.16983615398407 and perplexity is 64.70484960701857
At time: 220.54818153381348 and batch: 750, loss is 4.133259930610657 and perplexity is 62.38094939533036
At time: 221.5436761379242 and batch: 800, loss is 4.128068423271179 and perplexity is 62.05793742368945
At time: 222.5373022556305 and batch: 850, loss is 4.135753054618835 and perplexity is 62.53666686874922
At time: 223.5303554534912 and batch: 900, loss is 4.10633960723877 and perplexity is 60.72403644463085
At time: 224.5260922908783 and batch: 950, loss is 4.191094303131104 and perplexity is 66.09507945283013
At time: 225.52032351493835 and batch: 1000, loss is 4.156492323875427 and perplexity is 63.84717415072524
At time: 226.51392006874084 and batch: 1050, loss is 4.111382269859314 and perplexity is 61.03102063171079
At time: 227.5085165500641 and batch: 1100, loss is 4.142099676132202 and perplexity is 62.934825568886666
At time: 228.50385665893555 and batch: 1150, loss is 4.123298206329346 and perplexity is 61.76261254110373
At time: 229.49758315086365 and batch: 1200, loss is 4.174895377159118 and perplexity is 65.03303536416979
At time: 230.49048042297363 and batch: 1250, loss is 4.1929497718811035 and perplexity is 66.21783065257422
At time: 231.48593091964722 and batch: 1300, loss is 4.154089884757996 and perplexity is 63.693969308349104
At time: 232.48310780525208 and batch: 1350, loss is 4.047115559577942 and perplexity is 57.23213604413287
At time: 233.47527146339417 and batch: 1400, loss is 4.069524593353272 and perplexity is 58.52913083888834
At time: 234.46877431869507 and batch: 1450, loss is 4.015975499153138 and perplexity is 55.47738715916503
At time: 235.46577787399292 and batch: 1500, loss is 4.0174158096313475 and perplexity is 55.55734939259199
At time: 236.4590892791748 and batch: 1550, loss is 4.041398944854737 and perplexity is 56.90589535719269
At time: 237.45181107521057 and batch: 1600, loss is 4.11865996837616 and perplexity is 61.4768061788711
At time: 238.4475064277649 and batch: 1650, loss is 4.0763757705688475 and perplexity is 58.93150106751948
At time: 239.4446907043457 and batch: 1700, loss is 4.0934659862518314 and perplexity is 59.94730859187571
At time: 240.4416298866272 and batch: 1750, loss is 4.079356665611267 and perplexity is 59.107431772103766
At time: 241.43377542495728 and batch: 1800, loss is 4.037532296180725 and perplexity is 56.68628510382933
At time: 242.42676663398743 and batch: 1850, loss is 4.084096307754517 and perplexity is 59.38824479764855
At time: 243.42518496513367 and batch: 1900, loss is 4.179502348899842 and perplexity is 65.33333191804572
At time: 244.42010402679443 and batch: 1950, loss is 4.107380614280701 and perplexity is 60.78728350879207
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.496397506359012 and perplexity of 89.69342857601832
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 247.6199927330017 and batch: 50, loss is 4.14617751121521 and perplexity is 63.191987383913876
At time: 248.64249515533447 and batch: 100, loss is 4.146108064651489 and perplexity is 63.18759906991379
At time: 249.6387734413147 and batch: 150, loss is 4.10436782836914 and perplexity is 60.60442003999511
At time: 250.6352927684784 and batch: 200, loss is 4.093526129722595 and perplexity is 59.95091413950135
At time: 251.6318244934082 and batch: 250, loss is 4.086512007713318 and perplexity is 59.5318824009847
At time: 252.62908673286438 and batch: 300, loss is 4.097307291030884 and perplexity is 60.17802732164083
At time: 253.62538862228394 and batch: 350, loss is 4.110971932411194 and perplexity is 61.005982455850486
At time: 254.62566876411438 and batch: 400, loss is 4.039840612411499 and perplexity is 56.81728611350726
At time: 255.62604665756226 and batch: 450, loss is 4.061451330184936 and perplexity is 58.05851203349273
At time: 256.6225776672363 and batch: 500, loss is 4.0821668863296505 and perplexity is 59.27377031602202
At time: 257.61866331100464 and batch: 550, loss is 4.043229465484619 and perplexity is 57.01015817110816
At time: 258.61706733703613 and batch: 600, loss is 4.018878684043885 and perplexity is 55.63868229285176
At time: 259.61419892311096 and batch: 650, loss is 4.060612421035767 and perplexity is 58.00982664072667
At time: 260.6109654903412 and batch: 700, loss is 4.088937301635742 and perplexity is 59.67643993996474
At time: 261.6066997051239 and batch: 750, loss is 4.045848965644836 and perplexity is 57.15969205608349
At time: 262.60606360435486 and batch: 800, loss is 4.037883996963501 and perplexity is 56.706225220944866
At time: 263.6061944961548 and batch: 850, loss is 4.041242127418518 and perplexity is 56.89697222024706
At time: 264.6065528392792 and batch: 900, loss is 4.000975232124329 and perplexity is 54.651421874969095
At time: 265.60561060905457 and batch: 950, loss is 4.0773306703567505 and perplexity is 58.98780162180527
At time: 266.60648584365845 and batch: 1000, loss is 4.040382599830627 and perplexity is 56.848088714326806
At time: 267.60556292533875 and batch: 1050, loss is 3.987695369720459 and perplexity is 53.93045626975558
At time: 268.6053581237793 and batch: 1100, loss is 4.0147008228302 and perplexity is 55.40671649797288
At time: 269.60550570487976 and batch: 1150, loss is 3.994916934967041 and perplexity is 54.32132823348446
At time: 270.60578536987305 and batch: 1200, loss is 4.030725584030152 and perplexity is 56.30174807933556
At time: 271.63453698158264 and batch: 1250, loss is 4.042108807563782 and perplexity is 56.94630507120923
At time: 272.63165068626404 and batch: 1300, loss is 4.0072378730773925 and perplexity is 54.99475808128394
At time: 273.62888169288635 and batch: 1350, loss is 3.891051344871521 and perplexity is 48.962335774153935
At time: 274.6256947517395 and batch: 1400, loss is 3.907386269569397 and perplexity is 49.76869986028799
At time: 275.6266222000122 and batch: 1450, loss is 3.8487777805328367 and perplexity is 46.93566248017944
At time: 276.62436866760254 and batch: 1500, loss is 3.846453170776367 and perplexity is 46.826682098756386
At time: 277.6253402233124 and batch: 1550, loss is 3.8700989866256714 and perplexity is 47.94713197072996
At time: 278.62547159194946 and batch: 1600, loss is 3.9331100273132322 and perplexity is 51.06554620862127
At time: 279.62558341026306 and batch: 1650, loss is 3.883266038894653 and perplexity is 48.58262899340981
At time: 280.62576031684875 and batch: 1700, loss is 3.87837815284729 and perplexity is 48.34574204883477
At time: 281.62624168395996 and batch: 1750, loss is 3.8657564401626585 and perplexity is 47.73937075523623
At time: 282.62539172172546 and batch: 1800, loss is 3.821210279464722 and perplexity is 45.659435571146524
At time: 283.62528824806213 and batch: 1850, loss is 3.859465627670288 and perplexity is 47.43999397421038
At time: 284.62454104423523 and batch: 1900, loss is 3.948985571861267 and perplexity is 51.88270885070489
At time: 285.62583017349243 and batch: 1950, loss is 3.8699313735961915 and perplexity is 47.939096080164276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.406342546329942 and perplexity of 81.96911634070332
finished 7 epochs...
Completing Train Step...
At time: 288.8244924545288 and batch: 50, loss is 4.057348284721375 and perplexity is 57.82078335836667
At time: 289.8459334373474 and batch: 100, loss is 4.038592014312744 and perplexity is 56.746388428657546
At time: 290.8426282405853 and batch: 150, loss is 3.9909381580352785 and perplexity is 54.105625187518235
At time: 291.8390769958496 and batch: 200, loss is 3.9852074337005616 and perplexity is 53.796447516758555
At time: 292.830518245697 and batch: 250, loss is 3.982295579910278 and perplexity is 53.64002797309567
At time: 293.82510805130005 and batch: 300, loss is 3.9905754852294923 and perplexity is 54.08600610649129
At time: 294.820641040802 and batch: 350, loss is 4.00621726512909 and perplexity is 54.93865862671543
At time: 295.81390380859375 and batch: 400, loss is 3.942343592643738 and perplexity is 51.539246873104574
At time: 296.8332197666168 and batch: 450, loss is 3.9719209814071657 and perplexity is 53.086410961867244
At time: 297.8247175216675 and batch: 500, loss is 3.993571677207947 and perplexity is 54.248301176314904
At time: 298.8218228816986 and batch: 550, loss is 3.9597410488128664 and perplexity is 52.443743820900686
At time: 299.8170018196106 and batch: 600, loss is 3.9380556774139404 and perplexity is 51.31872408090625
At time: 300.8132252693176 and batch: 650, loss is 3.979834303855896 and perplexity is 53.50816739589597
At time: 301.8060691356659 and batch: 700, loss is 4.010660843849182 and perplexity is 55.1833260780519
At time: 302.8034656047821 and batch: 750, loss is 3.972508888244629 and perplexity is 53.11763000189246
At time: 303.8015158176422 and batch: 800, loss is 3.9657510805130003 and perplexity is 52.75988143067988
At time: 304.79645442962646 and batch: 850, loss is 3.970912413597107 and perplexity is 53.03289670753298
At time: 305.78919410705566 and batch: 900, loss is 3.932057247161865 and perplexity is 51.01181370437394
At time: 306.7835166454315 and batch: 950, loss is 4.012880573272705 and perplexity is 55.30595418088812
At time: 307.78274178504944 and batch: 1000, loss is 3.9764881706237794 and perplexity is 53.32942115992232
At time: 308.7821943759918 and batch: 1050, loss is 3.9289520311355592 and perplexity is 50.85365668586643
At time: 309.78025126457214 and batch: 1100, loss is 3.953691477775574 and perplexity is 52.12743938492901
At time: 310.77451753616333 and batch: 1150, loss is 3.940215311050415 and perplexity is 51.42967348552292
At time: 311.76761054992676 and batch: 1200, loss is 3.976735897064209 and perplexity is 53.3426339041019
At time: 312.7637538909912 and batch: 1250, loss is 3.9920509958267214 and perplexity is 54.16586948680578
At time: 313.7616446018219 and batch: 1300, loss is 3.9577464199066164 and perplexity is 52.339242269078554
At time: 314.7617292404175 and batch: 1350, loss is 3.8435457611083983 and perplexity is 46.69073547253466
At time: 315.7607514858246 and batch: 1400, loss is 3.865875730514526 and perplexity is 47.74506594125518
At time: 316.7588562965393 and batch: 1450, loss is 3.807538614273071 and perplexity is 45.039442878536974
At time: 317.75508880615234 and batch: 1500, loss is 3.809488515853882 and perplexity is 45.127351037680825
At time: 318.7464475631714 and batch: 1550, loss is 3.834265422821045 and perplexity is 46.259434059443066
At time: 319.7419590950012 and batch: 1600, loss is 3.903079810142517 and perplexity is 49.55483380687463
At time: 320.73968958854675 and batch: 1650, loss is 3.853762526512146 and perplexity is 47.170208926580266
At time: 321.7348942756653 and batch: 1700, loss is 3.854225168228149 and perplexity is 47.19203688185429
At time: 322.7292125225067 and batch: 1750, loss is 3.8449638938903807 and perplexity is 46.7569961072075
At time: 323.72271704673767 and batch: 1800, loss is 3.8025980472564695 and perplexity is 44.817471276904286
At time: 324.72182631492615 and batch: 1850, loss is 3.844332413673401 and perplexity is 46.727479309778076
At time: 325.71974658966064 and batch: 1900, loss is 3.937960648536682 and perplexity is 51.31384755188372
At time: 326.7158236503601 and batch: 1950, loss is 3.858931231498718 and perplexity is 47.414648995784155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.404328386173692 and perplexity of 81.80418356879451
finished 8 epochs...
Completing Train Step...
At time: 329.93177008628845 and batch: 50, loss is 4.0103526782989505 and perplexity is 55.16632309800835
At time: 330.9231071472168 and batch: 100, loss is 3.9897259092330932 and perplexity is 54.040075447517445
At time: 331.9200475215912 and batch: 150, loss is 3.9424063205718993 and perplexity is 51.54247992468019
At time: 332.91705870628357 and batch: 200, loss is 3.9365570878982545 and perplexity is 51.24187597530484
At time: 333.91102838516235 and batch: 250, loss is 3.933049564361572 and perplexity is 51.06245872830939
At time: 334.9041085243225 and batch: 300, loss is 3.9421190214157105 and perplexity is 51.52767394066514
At time: 335.90153193473816 and batch: 350, loss is 3.9575153589248657 and perplexity is 52.32715010944271
At time: 336.8995358943939 and batch: 400, loss is 3.8960006761550905 and perplexity is 49.205267272648676
At time: 337.8982210159302 and batch: 450, loss is 3.9291204738616945 and perplexity is 50.86222333590724
At time: 338.89261293411255 and batch: 500, loss is 3.9507679462432863 and perplexity is 51.975265722825675
At time: 339.88473176956177 and batch: 550, loss is 3.9185953521728516 and perplexity is 50.32969960048255
At time: 340.8815429210663 and batch: 600, loss is 3.897469563484192 and perplexity is 49.27759737565129
At time: 341.87955927848816 and batch: 650, loss is 3.93937198638916 and perplexity is 51.38631985671387
At time: 342.877268075943 and batch: 700, loss is 3.970078272819519 and perplexity is 52.98867825060853
At time: 343.86976981163025 and batch: 750, loss is 3.933609070777893 and perplexity is 51.091036495577555
At time: 344.8621199131012 and batch: 800, loss is 3.9268881368637083 and perplexity is 50.74880835028759
At time: 345.8857524394989 and batch: 850, loss is 3.9331587505340577 and perplexity is 51.06803434712034
At time: 346.8805696964264 and batch: 900, loss is 3.894360466003418 and perplexity is 49.124626445782674
At time: 347.87615871429443 and batch: 950, loss is 3.976649703979492 and perplexity is 53.338036336080926
At time: 348.8703701496124 and batch: 1000, loss is 3.9400913763046264 and perplexity is 51.42329995697248
At time: 349.86349272727966 and batch: 1050, loss is 3.8947601985931395 and perplexity is 49.14426708517125
At time: 350.8613586425781 and batch: 1100, loss is 3.9184734582901 and perplexity is 50.323565091867664
At time: 351.8584520816803 and batch: 1150, loss is 3.9078616285324097 and perplexity is 49.79236348175576
At time: 352.8492434024811 and batch: 1200, loss is 3.9448499727249144 and perplexity is 51.66858583345484
At time: 353.84317994117737 and batch: 1250, loss is 3.961210165023804 and perplexity is 52.52084639756531
At time: 354.83958077430725 and batch: 1300, loss is 3.9263901138305664 and perplexity is 50.72354056731586
At time: 355.83831310272217 and batch: 1350, loss is 3.8138538360595704 and perplexity is 45.32477697519927
At time: 356.8355484008789 and batch: 1400, loss is 3.8391206407547 and perplexity is 46.4845798168662
At time: 357.8270082473755 and batch: 1450, loss is 3.7795240116119384 and perplexity is 43.795190771299126
At time: 358.82105922698975 and batch: 1500, loss is 3.7848331212997435 and perplexity is 44.028322556411744
At time: 359.81953835487366 and batch: 1550, loss is 3.8086414432525633 and perplexity is 45.089141080635315
At time: 360.82010865211487 and batch: 1600, loss is 3.8799865531921385 and perplexity is 48.4235639246072
At time: 361.81990909576416 and batch: 1650, loss is 3.8309028482437135 and perplexity is 46.104144495203826
At time: 362.8186538219452 and batch: 1700, loss is 3.8332421588897705 and perplexity is 46.212122659241736
At time: 363.81679487228394 and batch: 1750, loss is 3.825105838775635 and perplexity is 45.83765151052321
At time: 364.81058645248413 and batch: 1800, loss is 3.7830777072906496 and perplexity is 43.95110241868444
At time: 365.8041100502014 and batch: 1850, loss is 3.8267129039764405 and perplexity is 45.91137482837488
At time: 366.7996082305908 and batch: 1900, loss is 3.9219743490219114 and perplexity is 50.50005114342606
At time: 367.7976915836334 and batch: 1950, loss is 3.8423690891265867 and perplexity is 46.63582810261105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.405695005904796 and perplexity of 81.91605520572831
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 370.99296474456787 and batch: 50, loss is 4.003656039237976 and perplexity is 54.79812835352649
At time: 372.01953768730164 and batch: 100, loss is 4.010912261009216 and perplexity is 55.1972018574071
At time: 373.01755833625793 and batch: 150, loss is 3.976792125701904 and perplexity is 53.34563337206461
At time: 374.0158450603485 and batch: 200, loss is 3.973323564529419 and perplexity is 53.160921307164756
At time: 375.01325392723083 and batch: 250, loss is 3.9704933977127075 and perplexity is 53.01067973637377
At time: 376.0105984210968 and batch: 300, loss is 3.9744507026672364 and perplexity is 53.220874790593136
At time: 377.00831055641174 and batch: 350, loss is 3.99683069229126 and perplexity is 54.42538561177862
At time: 378.0061984062195 and batch: 400, loss is 3.9365922355651857 and perplexity is 51.24367703934596
At time: 379.00438141822815 and batch: 450, loss is 3.96763623714447 and perplexity is 52.85943587941592
At time: 380.00236558914185 and batch: 500, loss is 3.9790045547485353 and perplexity is 53.46378745641655
At time: 381.0088691711426 and batch: 550, loss is 3.9585478353500365 and perplexity is 52.38120455849738
At time: 382.00636625289917 and batch: 600, loss is 3.921694040298462 and perplexity is 50.485897522340316
At time: 383.00402784347534 and batch: 650, loss is 3.954161510467529 and perplexity is 52.1519467447668
At time: 384.00200390815735 and batch: 700, loss is 3.981230821609497 and perplexity is 53.58294470339279
At time: 384.9991157054901 and batch: 750, loss is 3.941883578300476 and perplexity is 51.515543532658334
At time: 385.9992322921753 and batch: 800, loss is 3.9353595924377442 and perplexity is 51.18055078708198
At time: 387.0003168582916 and batch: 850, loss is 3.9419036436080934 and perplexity is 51.51657721825696
At time: 387.9991536140442 and batch: 900, loss is 3.913932104110718 and perplexity is 50.095546108584195
At time: 388.99787187576294 and batch: 950, loss is 3.9920018482208253 and perplexity is 54.16320742941663
At time: 389.99834871292114 and batch: 1000, loss is 3.946895775794983 and perplexity is 51.77439778328027
At time: 390.998085975647 and batch: 1050, loss is 3.894285397529602 and perplexity is 49.12093887346057
At time: 391.99882221221924 and batch: 1100, loss is 3.91256865978241 and perplexity is 50.02729016253409
At time: 392.9996244907379 and batch: 1150, loss is 3.906834979057312 and perplexity is 49.741270409748836
At time: 393.99987983703613 and batch: 1200, loss is 3.9338493824005125 and perplexity is 51.1033157408227
At time: 394.9996221065521 and batch: 1250, loss is 3.9464380168914794 and perplexity is 51.75070301538068
At time: 395.99839782714844 and batch: 1300, loss is 3.91981746673584 and perplexity is 50.39124585994484
At time: 396.9973990917206 and batch: 1350, loss is 3.8005335474014283 and perplexity is 44.725041057866065
At time: 397.99830508232117 and batch: 1400, loss is 3.8178574085235595 and perplexity is 45.50660173566959
At time: 398.9985065460205 and batch: 1450, loss is 3.757861685752869 and perplexity is 42.85668686608217
At time: 399.99797344207764 and batch: 1500, loss is 3.7627662563323976 and perplexity is 43.06739681013566
At time: 400.9987881183624 and batch: 1550, loss is 3.7853411197662354 and perplexity is 44.05069455874294
At time: 401.9985861778259 and batch: 1600, loss is 3.8551223421096803 and perplexity is 47.23439534337235
At time: 402.9985978603363 and batch: 1650, loss is 3.8069070386886597 and perplexity is 45.01100604702889
At time: 403.9979946613312 and batch: 1700, loss is 3.7921074199676514 and perplexity is 44.34976544287525
At time: 404.9973659515381 and batch: 1750, loss is 3.781993203163147 and perplexity is 43.9034631038891
At time: 405.99854922294617 and batch: 1800, loss is 3.737174825668335 and perplexity is 41.979223850535135
At time: 406.99839758872986 and batch: 1850, loss is 3.7786097860336305 and perplexity is 43.7551703843073
At time: 407.99816036224365 and batch: 1900, loss is 3.885466442108154 and perplexity is 48.6896480657424
At time: 408.9968366622925 and batch: 1950, loss is 3.810916166305542 and perplexity is 45.19182313162851
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36656494140625 and perplexity of 78.77257800240723
finished 10 epochs...
Completing Train Step...
At time: 412.20079159736633 and batch: 50, loss is 3.9988467645645143 and perplexity is 54.53522180432003
At time: 413.2225830554962 and batch: 100, loss is 3.985046181678772 and perplexity is 53.787773430207174
At time: 414.2175257205963 and batch: 150, loss is 3.938429822921753 and perplexity is 51.337928343358044
At time: 415.2165997028351 and batch: 200, loss is 3.9324899339675903 and perplexity is 51.03389061895032
At time: 416.20983242988586 and batch: 250, loss is 3.9284447479248046 and perplexity is 50.82786602176273
At time: 417.20353269577026 and batch: 300, loss is 3.9310971689224243 and perplexity is 50.96286187463534
At time: 418.19779896736145 and batch: 350, loss is 3.954813852310181 and perplexity is 52.18597874084481
At time: 419.1965718269348 and batch: 400, loss is 3.8945834922790525 and perplexity is 49.13558375009879
At time: 420.1955986022949 and batch: 450, loss is 3.9266147565841676 and perplexity is 50.734936523102824
At time: 421.19578671455383 and batch: 500, loss is 3.941045732498169 and perplexity is 51.4723995272917
At time: 422.21699142456055 and batch: 550, loss is 3.919785189628601 and perplexity is 50.389619402547126
At time: 423.2205934524536 and batch: 600, loss is 3.88796706199646 and perplexity is 48.81155472563479
At time: 424.22131752967834 and batch: 650, loss is 3.921982545852661 and perplexity is 50.50046508549464
At time: 425.22341299057007 and batch: 700, loss is 3.951594662666321 and perplexity is 52.01825229499462
At time: 426.22246289253235 and batch: 750, loss is 3.9145408916473388 and perplexity is 50.12605293784183
At time: 427.2181565761566 and batch: 800, loss is 3.9079832458496093 and perplexity is 49.79841946366811
At time: 428.21647906303406 and batch: 850, loss is 3.9170342254638673 and perplexity is 50.251189859952284
At time: 429.21571803092957 and batch: 900, loss is 3.886957983970642 and perplexity is 48.76232490089963
At time: 430.21527671813965 and batch: 950, loss is 3.9689033937454226 and perplexity is 52.9264595182681
At time: 431.2150890827179 and batch: 1000, loss is 3.9248489475250246 and perplexity is 50.64542736387547
At time: 432.2150249481201 and batch: 1050, loss is 3.8735002422332765 and perplexity is 48.11049007606537
At time: 433.2122206687927 and batch: 1100, loss is 3.8906605195999147 and perplexity is 48.94320379485054
At time: 434.20763540267944 and batch: 1150, loss is 3.886070885658264 and perplexity is 48.71908710569547
At time: 435.2037835121155 and batch: 1200, loss is 3.9154520559310915 and perplexity is 50.17174682112017
At time: 436.1980836391449 and batch: 1250, loss is 3.929489755630493 and perplexity is 50.88100929614858
At time: 437.19828724861145 and batch: 1300, loss is 3.903879222869873 and perplexity is 49.594464410215686
At time: 438.1970384120941 and batch: 1350, loss is 3.785643291473389 and perplexity is 44.06400744360632
At time: 439.19635343551636 and batch: 1400, loss is 3.8062531900405885 and perplexity is 44.98158528098893
At time: 440.19566106796265 and batch: 1450, loss is 3.747440505027771 and perplexity is 42.41238866383131
At time: 441.19459772109985 and batch: 1500, loss is 3.7533388566970824 and perplexity is 42.66329107521558
At time: 442.19483971595764 and batch: 1550, loss is 3.7790926551818846 and perplexity is 43.776303508018586
At time: 443.19464325904846 and batch: 1600, loss is 3.8507269287109374 and perplexity is 47.027236257629276
At time: 444.1946551799774 and batch: 1650, loss is 3.8029765129089355 and perplexity is 44.8344363605612
At time: 445.1935930252075 and batch: 1700, loss is 3.7902194690704345 and perplexity is 44.26611425293247
At time: 446.1931300163269 and batch: 1750, loss is 3.7818402910232543 and perplexity is 43.89675024464909
At time: 447.19231033325195 and batch: 1800, loss is 3.738523259162903 and perplexity is 42.035868224053516
At time: 448.18784642219543 and batch: 1850, loss is 3.782165598869324 and perplexity is 43.91103252486359
At time: 449.18030619621277 and batch: 1900, loss is 3.8898525619506836 and perplexity is 48.903675729618264
At time: 450.1750056743622 and batch: 1950, loss is 3.8144574308395387 and perplexity is 45.352143032158445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365029410428779 and perplexity of 78.65171308836754
finished 11 epochs...
Completing Train Step...
At time: 453.5146996974945 and batch: 50, loss is 3.984091386795044 and perplexity is 53.73644164888961
At time: 454.5129325389862 and batch: 100, loss is 3.9680376625061036 and perplexity is 52.880659257095594
At time: 455.5128057003021 and batch: 150, loss is 3.921743841171265 and perplexity is 50.488411826707924
At time: 456.5083198547363 and batch: 200, loss is 3.915027823448181 and perplexity is 50.15046685054082
At time: 457.5005648136139 and batch: 250, loss is 3.910486307144165 and perplexity is 49.92322409161276
At time: 458.49404096603394 and batch: 300, loss is 3.9132372665405275 and perplexity is 50.06074993129435
At time: 459.5041069984436 and batch: 350, loss is 3.93714403629303 and perplexity is 51.271961140509816
At time: 460.50826811790466 and batch: 400, loss is 3.8766476631164553 and perplexity is 48.26215258490386
At time: 461.5004484653473 and batch: 450, loss is 3.909354591369629 and perplexity is 49.866757149683856
At time: 462.4929802417755 and batch: 500, loss is 3.9240823793411255 and perplexity is 50.60661906710154
At time: 463.491956949234 and batch: 550, loss is 3.9035869026184082 and perplexity is 49.57996906265307
At time: 464.4917514324188 and batch: 600, loss is 3.8724875259399414 and perplexity is 48.06179246148087
At time: 465.4874930381775 and batch: 650, loss is 3.9067103385925295 and perplexity is 49.735071021041456
At time: 466.48121070861816 and batch: 700, loss is 3.936335048675537 and perplexity is 51.230499532047745
At time: 467.47557735443115 and batch: 750, loss is 3.900152897834778 and perplexity is 49.41000321051957
At time: 468.4822177886963 and batch: 800, loss is 3.8939101791381834 and perplexity is 49.102511251199076
At time: 469.47934103012085 and batch: 850, loss is 3.9037920951843263 and perplexity is 49.59014354755181
At time: 470.4743232727051 and batch: 900, loss is 3.8736986541748046 and perplexity is 48.12003671886188
At time: 471.47419238090515 and batch: 950, loss is 3.9573611974716187 and perplexity is 52.3190839017027
At time: 472.51263403892517 and batch: 1000, loss is 3.9138365030288695 and perplexity is 50.090757149098934
At time: 473.51164984703064 and batch: 1050, loss is 3.8627487134933474 and perplexity is 47.595999495503364
At time: 474.51107263565063 and batch: 1100, loss is 3.8794763040542604 and perplexity is 48.39886214542838
At time: 475.50955176353455 and batch: 1150, loss is 3.8750847578048706 and perplexity is 48.18678232391309
At time: 476.5031590461731 and batch: 1200, loss is 3.9048226976394655 and perplexity is 49.64127761616498
At time: 477.49649238586426 and batch: 1250, loss is 3.919781150817871 and perplexity is 50.38941588882258
At time: 478.4925706386566 and batch: 1300, loss is 3.8946282863616943 and perplexity is 49.1377847827942
At time: 479.4973027706146 and batch: 1350, loss is 3.776949028968811 and perplexity is 43.682563983453825
At time: 480.49277567863464 and batch: 1400, loss is 3.7987482357025146 and perplexity is 44.645264153341195
At time: 481.49251198768616 and batch: 1450, loss is 3.7404056692123415 and perplexity is 42.11507148795746
At time: 482.49207401275635 and batch: 1500, loss is 3.74635721206665 and perplexity is 42.366468498713985
At time: 483.49075150489807 and batch: 1550, loss is 3.773053774833679 and perplexity is 43.51274026346582
At time: 484.4896001815796 and batch: 1600, loss is 3.845301003456116 and perplexity is 46.77276099495821
At time: 485.4854826927185 and batch: 1650, loss is 3.797713665962219 and perplexity is 44.599099398447535
At time: 486.4786174297333 and batch: 1700, loss is 3.7859906005859374 and perplexity is 44.07931393281463
At time: 487.47268557548523 and batch: 1750, loss is 3.7783059310913085 and perplexity is 43.7418771792392
At time: 488.4703269004822 and batch: 1800, loss is 3.7356198453903198 and perplexity is 41.91399771118418
At time: 489.4663391113281 and batch: 1850, loss is 3.780254602432251 and perplexity is 43.82719882662245
At time: 490.4585771560669 and batch: 1900, loss is 3.888232536315918 and perplexity is 48.82451466009603
At time: 491.4522268772125 and batch: 1950, loss is 3.812274875640869 and perplexity is 45.25326741660706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3650856195494185 and perplexity of 78.65613415624806
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 494.67210364341736 and batch: 50, loss is 3.9857404899597166 and perplexity is 53.825131694288636
At time: 495.69428420066833 and batch: 100, loss is 3.991710181236267 and perplexity is 54.147412113629734
At time: 496.6900327205658 and batch: 150, loss is 3.9584952640533446 and perplexity is 52.37845088303423
At time: 497.71223187446594 and batch: 200, loss is 3.9556086969375612 and perplexity is 52.22747497501626
At time: 498.70807790756226 and batch: 250, loss is 3.9608725929260253 and perplexity is 52.50311981743753
At time: 499.7003195285797 and batch: 300, loss is 3.953199281692505 and perplexity is 52.10178877652567
At time: 500.6926863193512 and batch: 350, loss is 3.9717410039901733 and perplexity is 53.07685746647743
At time: 501.69029688835144 and batch: 400, loss is 3.9160597991943358 and perplexity is 50.202247629647566
At time: 502.6865849494934 and batch: 450, loss is 3.9533218431472776 and perplexity is 52.10817483888893
At time: 503.67918610572815 and batch: 500, loss is 3.9670063352584837 and perplexity is 52.82615010554975
At time: 504.67180490493774 and batch: 550, loss is 3.953120718002319 and perplexity is 52.097695628522615
At time: 505.6695954799652 and batch: 600, loss is 3.915909881591797 and perplexity is 50.194721993167654
At time: 506.6660957336426 and batch: 650, loss is 3.940675640106201 and perplexity is 51.45335350844104
At time: 507.658141374588 and batch: 700, loss is 3.969469499588013 and perplexity is 52.95642997865498
At time: 508.6506245136261 and batch: 750, loss is 3.9197193241119384 and perplexity is 50.38630057353014
At time: 509.64978313446045 and batch: 800, loss is 3.9143384647369386 and perplexity is 50.115907102744735
At time: 510.64826464653015 and batch: 850, loss is 3.919204831123352 and perplexity is 50.36038384272409
At time: 511.6442606449127 and batch: 900, loss is 3.8824046802520753 and perplexity is 48.540799943540215
At time: 512.6360249519348 and batch: 950, loss is 3.9751890325546264 and perplexity is 53.26018386282979
At time: 513.6305360794067 and batch: 1000, loss is 3.932530903816223 and perplexity is 51.03598151255563
At time: 514.6259832382202 and batch: 1050, loss is 3.882106981277466 and perplexity is 48.526351547913286
At time: 515.6162657737732 and batch: 1100, loss is 3.8991283559799195 and perplexity is 49.35940651782228
At time: 516.6102876663208 and batch: 1150, loss is 3.899165449142456 and perplexity is 49.36123744826825
At time: 517.6094682216644 and batch: 1200, loss is 3.920806407928467 and perplexity is 50.441104488285724
At time: 518.6088786125183 and batch: 1250, loss is 3.937889533042908 and perplexity is 51.310198472032205
At time: 519.6074967384338 and batch: 1300, loss is 3.9116699504852295 and perplexity is 49.98235036868229
At time: 520.6037013530731 and batch: 1350, loss is 3.7947072792053222 and perplexity is 44.46521860620548
At time: 521.5966167449951 and batch: 1400, loss is 3.81606671333313 and perplexity is 45.42518619976853
At time: 522.5904037952423 and batch: 1450, loss is 3.749917006492615 and perplexity is 42.51755317276669
At time: 523.5884697437286 and batch: 1500, loss is 3.7558102941513063 and perplexity is 42.76886113186016
At time: 524.5870599746704 and batch: 1550, loss is 3.7742672824859618 and perplexity is 43.56557535815944
At time: 525.580043554306 and batch: 1600, loss is 3.8429511070251463 and perplexity is 46.66297888963649
At time: 526.5730228424072 and batch: 1650, loss is 3.7952172231674193 and perplexity is 44.487899158370865
At time: 527.5698437690735 and batch: 1700, loss is 3.782700514793396 and perplexity is 43.93452751876655
At time: 528.5672597885132 and batch: 1750, loss is 3.770545787811279 and perplexity is 43.40374760878803
At time: 529.5641801357269 and batch: 1800, loss is 3.7259601402282714 and perplexity is 41.51107006535168
At time: 530.5575926303864 and batch: 1850, loss is 3.7645915365219116 and perplexity is 43.146078662715524
At time: 531.5504684448242 and batch: 1900, loss is 3.8754140615463255 and perplexity is 48.20265302461817
At time: 532.5480625629425 and batch: 1950, loss is 3.8091176080703737 and perplexity is 45.11061605569124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351130143986192 and perplexity of 77.56607424157144
finished 13 epochs...
Completing Train Step...
At time: 535.7458353042603 and batch: 50, loss is 3.9944327068328858 and perplexity is 54.295030685589246
At time: 536.7672734260559 and batch: 100, loss is 3.9852849674224853 and perplexity is 53.80061871726306
At time: 537.7683465480804 and batch: 150, loss is 3.9460542964935303 and perplexity is 51.73084902445974
At time: 538.7660801410675 and batch: 200, loss is 3.9361308002471924 and perplexity is 51.22003685156441
At time: 539.7639253139496 and batch: 250, loss is 3.940773034095764 and perplexity is 51.45836499985623
At time: 540.7692611217499 and batch: 300, loss is 3.932337212562561 and perplexity is 51.026097246593416
At time: 541.7692883014679 and batch: 350, loss is 3.95064884185791 and perplexity is 51.969075609389144
At time: 542.7684445381165 and batch: 400, loss is 3.8931494140625 and perplexity is 49.065169981278814
At time: 543.768049955368 and batch: 450, loss is 3.9316658401489257 and perplexity is 50.99185122972843
At time: 544.7693557739258 and batch: 500, loss is 3.946144847869873 and perplexity is 51.73553353612955
At time: 545.7683968544006 and batch: 550, loss is 3.932560906410217 and perplexity is 51.037512747358434
At time: 546.7696318626404 and batch: 600, loss is 3.8966433429718017 and perplexity is 49.23690002870478
At time: 547.7928011417389 and batch: 650, loss is 3.9245698070526123 and perplexity is 50.631292148302755
At time: 548.7893874645233 and batch: 700, loss is 3.953567023277283 and perplexity is 52.12095229429534
At time: 549.7896416187286 and batch: 750, loss is 3.907683753967285 and perplexity is 49.78350747440749
At time: 550.7884862422943 and batch: 800, loss is 3.9013572835922243 and perplexity is 49.46954776477057
At time: 551.7888224124908 and batch: 850, loss is 3.9075349283218386 and perplexity is 49.77609896307694
At time: 552.7885165214539 and batch: 900, loss is 3.870841188430786 and perplexity is 47.98273162805946
At time: 553.7894079685211 and batch: 950, loss is 3.9654037761688232 and perplexity is 52.74156087624896
At time: 554.7897386550903 and batch: 1000, loss is 3.923368182182312 and perplexity is 50.570488867125505
At time: 555.7883281707764 and batch: 1050, loss is 3.8738095283508303 and perplexity is 48.12537228406614
At time: 556.7890558242798 and batch: 1100, loss is 3.889957518577576 and perplexity is 48.90880876383374
At time: 557.7889490127563 and batch: 1150, loss is 3.8904617977142335 and perplexity is 48.93347867543019
At time: 558.7881135940552 and batch: 1200, loss is 3.913493161201477 and perplexity is 50.073561849105666
At time: 559.7875864505768 and batch: 1250, loss is 3.930489583015442 and perplexity is 50.93190696281717
At time: 560.7884838581085 and batch: 1300, loss is 3.904173369407654 and perplexity is 49.60905459593616
At time: 561.7884719371796 and batch: 1350, loss is 3.787757086753845 and perplexity is 44.1572482458448
At time: 562.7886316776276 and batch: 1400, loss is 3.810909776687622 and perplexity is 45.19153437406811
At time: 563.7893824577332 and batch: 1450, loss is 3.7468812465667725 and perplexity is 42.388675808045576
At time: 564.7895452976227 and batch: 1500, loss is 3.7540650463104246 and perplexity is 42.69428396606109
At time: 565.7888600826263 and batch: 1550, loss is 3.773985033035278 and perplexity is 43.553280733603025
At time: 566.7896933555603 and batch: 1600, loss is 3.844471187591553 and perplexity is 46.73396431513166
At time: 567.7892589569092 and batch: 1650, loss is 3.7973091888427732 and perplexity is 44.581063730946276
At time: 568.788094997406 and batch: 1700, loss is 3.7851640033721923 and perplexity is 44.042893149466735
At time: 569.7883126735687 and batch: 1750, loss is 3.7741788101196287 and perplexity is 43.56172117911353
At time: 570.7897763252258 and batch: 1800, loss is 3.7302869939804078 and perplexity is 41.69107153380657
At time: 571.7890751361847 and batch: 1850, loss is 3.7697414779663085 and perplexity is 43.36885158276753
At time: 572.7884795665741 and batch: 1900, loss is 3.8810926198959352 and perplexity is 48.477153247562924
At time: 573.787778377533 and batch: 1950, loss is 3.8139229297637938 and perplexity is 45.32790874012496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349797022619913 and perplexity of 77.46273814578436
finished 14 epochs...
Completing Train Step...
At time: 577.0086958408356 and batch: 50, loss is 3.9906910991668703 and perplexity is 54.092259564100765
At time: 578.022050857544 and batch: 100, loss is 3.9797566175460815 and perplexity is 53.504010705287115
At time: 579.0255107879639 and batch: 150, loss is 3.939557638168335 and perplexity is 51.395860704030746
At time: 580.0286753177643 and batch: 200, loss is 3.928834848403931 and perplexity is 50.84769786460499
At time: 581.0275509357452 and batch: 250, loss is 3.9327451610565185 and perplexity is 51.04691751262704
At time: 582.0343701839447 and batch: 300, loss is 3.924003086090088 and perplexity is 50.60260646284001
At time: 583.0380923748016 and batch: 350, loss is 3.9424712657928467 and perplexity is 51.54582747112946
At time: 584.0430581569672 and batch: 400, loss is 3.8848325967788697 and perplexity is 48.65879613843936
At time: 585.041051864624 and batch: 450, loss is 3.9233842039108278 and perplexity is 50.5712991002597
At time: 586.0358533859253 and batch: 500, loss is 3.938073534965515 and perplexity is 51.31964051585089
At time: 587.0328831672668 and batch: 550, loss is 3.9242120218276977 and perplexity is 50.613180260329926
At time: 588.0300681591034 and batch: 600, loss is 3.889072451591492 and perplexity is 48.86554034241835
At time: 589.034820318222 and batch: 650, loss is 3.917770619392395 and perplexity is 50.2882081594191
At time: 590.0340852737427 and batch: 700, loss is 3.946879992485046 and perplexity is 51.77358061836207
At time: 591.0500195026398 and batch: 750, loss is 3.902053780555725 and perplexity is 49.50401515639791
At time: 592.0534675121307 and batch: 800, loss is 3.8954571723937987 and perplexity is 49.178531291022054
At time: 593.0472917556763 and batch: 850, loss is 3.9019038391113283 and perplexity is 49.49659300931956
At time: 594.0453238487244 and batch: 900, loss is 3.8652014255523683 and perplexity is 47.71288205846784
At time: 595.0473835468292 and batch: 950, loss is 3.9603128671646117 and perplexity is 52.473740691614935
At time: 596.0483856201172 and batch: 1000, loss is 3.91887619972229 and perplexity is 50.34383655835137
At time: 597.0523192882538 and batch: 1050, loss is 3.8696386671066283 and perplexity is 47.92506604907856
At time: 598.0962061882019 and batch: 1100, loss is 3.885594964027405 and perplexity is 48.69590615490164
At time: 599.0887746810913 and batch: 1150, loss is 3.8863994884490967 and perplexity is 48.735098964311845
At time: 600.0954325199127 and batch: 1200, loss is 3.9100050926208496 and perplexity is 49.89920609049811
At time: 601.1001279354095 and batch: 1250, loss is 3.927269220352173 and perplexity is 50.768151568665616
At time: 602.0942268371582 and batch: 1300, loss is 3.900926294326782 and perplexity is 49.44823151458514
At time: 603.0867607593536 and batch: 1350, loss is 3.7845642232894896 and perplexity is 44.016485019697875
At time: 604.0845184326172 and batch: 1400, loss is 3.8084053421020507 and perplexity is 45.07849673917063
At time: 605.0831592082977 and batch: 1450, loss is 3.745120301246643 and perplexity is 42.31409735131897
At time: 606.0873651504517 and batch: 1500, loss is 3.752776336669922 and perplexity is 42.639298868242314
At time: 607.0875599384308 and batch: 1550, loss is 3.773155813217163 and perplexity is 43.51718045967464
At time: 608.0855801105499 and batch: 1600, loss is 3.8444186067581176 and perplexity is 46.73150706894082
At time: 609.0845575332642 and batch: 1650, loss is 3.797413830757141 and perplexity is 44.58572902288792
At time: 610.0845582485199 and batch: 1700, loss is 3.785426964759827 and perplexity is 44.05447625265246
At time: 611.0844502449036 and batch: 1750, loss is 3.774817552566528 and perplexity is 43.589554787797965
At time: 612.0833094120026 and batch: 1800, loss is 3.7310355567932127 and perplexity is 41.722291603216426
At time: 613.0829148292542 and batch: 1850, loss is 3.7707707929611205 and perplexity is 43.41351477431249
At time: 614.0795192718506 and batch: 1900, loss is 3.8821390867233276 and perplexity is 48.52790953307555
At time: 615.0725347995758 and batch: 1950, loss is 3.8144050359725954 and perplexity is 45.34976687490845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3494958212209305 and perplexity of 77.4394097741313
finished 15 epochs...
Completing Train Step...
At time: 618.2650566101074 and batch: 50, loss is 3.9863338327407836 and perplexity is 53.857077924214636
At time: 619.2868392467499 and batch: 100, loss is 3.9746933078765867 and perplexity is 53.23378801840835
At time: 620.2897930145264 and batch: 150, loss is 3.934302315711975 and perplexity is 51.12646737752585
At time: 621.2973155975342 and batch: 200, loss is 3.923218150138855 and perplexity is 50.56290224247479
At time: 622.2936630249023 and batch: 250, loss is 3.926853132247925 and perplexity is 50.74703193884131
At time: 623.3350801467896 and batch: 300, loss is 3.917951078414917 and perplexity is 50.29728393918647
At time: 624.3255589008331 and batch: 350, loss is 3.9364944648742677 and perplexity is 51.23866715455058
At time: 625.3242108821869 and batch: 400, loss is 3.8788333129882813 and perplexity is 48.36775211227385
At time: 626.333624124527 and batch: 450, loss is 3.9175948810577395 and perplexity is 50.279371369968416
At time: 627.335611820221 and batch: 500, loss is 3.9324785757064817 and perplexity is 51.03331096598722
At time: 628.3370869159698 and batch: 550, loss is 3.918671073913574 and perplexity is 50.33351079723975
At time: 629.3318073749542 and batch: 600, loss is 3.884025115966797 and perplexity is 48.61952095333222
At time: 630.3243019580841 and batch: 650, loss is 3.9130465030670165 and perplexity is 50.051201079565914
At time: 631.32231092453 and batch: 700, loss is 3.9421567869186402 and perplexity is 51.52961994593201
At time: 632.3204696178436 and batch: 750, loss is 3.8978873109817505 and perplexity is 49.29818726902945
At time: 633.3142907619476 and batch: 800, loss is 3.891169033050537 and perplexity is 48.96809840138146
At time: 634.3060643672943 and batch: 850, loss is 3.897643666267395 and perplexity is 49.286177489393125
At time: 635.3034987449646 and batch: 900, loss is 3.8609132814407348 and perplexity is 47.50872039438527
At time: 636.3015987873077 and batch: 950, loss is 3.9562711572647093 and perplexity is 52.26208506781529
At time: 637.300473690033 and batch: 1000, loss is 3.9153130626678467 and perplexity is 50.16477377092154
At time: 638.2931137084961 and batch: 1050, loss is 3.8663294506073 and perplexity is 47.76673375219241
At time: 639.2853133678436 and batch: 1100, loss is 3.882292366027832 and perplexity is 48.535348427397544
At time: 640.2823193073273 and batch: 1150, loss is 3.8833222675323484 and perplexity is 48.58536080525608
At time: 641.2823116779327 and batch: 1200, loss is 3.9072957944869997 and perplexity is 49.76419723675802
At time: 642.2766530513763 and batch: 1250, loss is 3.924833950996399 and perplexity is 50.6446678639692
At time: 643.269501209259 and batch: 1300, loss is 3.898425269126892 and perplexity is 49.32471476511308
At time: 644.2636337280273 and batch: 1350, loss is 3.7819938802719117 and perplexity is 43.90349283131883
At time: 645.2617251873016 and batch: 1400, loss is 3.8062938833236695 and perplexity is 44.98341576661618
At time: 646.2606592178345 and batch: 1450, loss is 3.7434110927581785 and perplexity is 42.24183550981293
At time: 647.2566990852356 and batch: 1500, loss is 3.751255307197571 and perplexity is 42.57449253664779
At time: 648.2493796348572 and batch: 1550, loss is 3.771873798370361 and perplexity is 43.461426534550526
At time: 649.2439110279083 and batch: 1600, loss is 3.843624768257141 and perplexity is 46.6944245201457
At time: 650.2423055171967 and batch: 1650, loss is 3.7966678810119627 and perplexity is 44.552482711265185
At time: 651.2419021129608 and batch: 1700, loss is 3.784785408973694 and perplexity is 44.02622191284421
At time: 652.2405171394348 and batch: 1750, loss is 3.7743830108642578 and perplexity is 43.57061742329456
At time: 653.2390866279602 and batch: 1800, loss is 3.730630416870117 and perplexity is 41.70539166085676
At time: 654.2306213378906 and batch: 1850, loss is 3.770570092201233 and perplexity is 43.404802523214855
At time: 655.222808599472 and batch: 1900, loss is 3.881928825378418 and perplexity is 48.51770706218168
At time: 656.2203290462494 and batch: 1950, loss is 3.813767423629761 and perplexity is 45.3208605203079
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349523074127907 and perplexity of 77.4415202519204
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 659.510071516037 and batch: 50, loss is 3.9878390312194822 and perplexity is 53.93820455649821
At time: 660.5536344051361 and batch: 100, loss is 3.9856053733825685 and perplexity is 53.8178595180364
At time: 661.5528011322021 and batch: 150, loss is 3.95150297164917 and perplexity is 52.013482907189626
At time: 662.553124666214 and batch: 200, loss is 3.943440890312195 and perplexity is 51.595831808113445
At time: 663.5525817871094 and batch: 250, loss is 3.955220913887024 and perplexity is 52.20722597181245
At time: 664.5525996685028 and batch: 300, loss is 3.9453228235244753 and perplexity is 51.69302314272365
At time: 665.5534241199493 and batch: 350, loss is 3.9610838079452515 and perplexity is 52.514210436110595
At time: 666.5539238452911 and batch: 400, loss is 3.902177782058716 and perplexity is 49.510154109293225
At time: 667.5543308258057 and batch: 450, loss is 3.9435244178771973 and perplexity is 51.60014166230196
At time: 668.5542643070221 and batch: 500, loss is 3.9598455381393434 and perplexity is 52.449223918671336
At time: 669.5546205043793 and batch: 550, loss is 3.947118015289307 and perplexity is 51.785905377936196
At time: 670.5536508560181 and batch: 600, loss is 3.913573269844055 and perplexity is 50.077573334849646
At time: 671.5534298419952 and batch: 650, loss is 3.9375092506408693 and perplexity is 51.29068981614255
At time: 672.5517981052399 and batch: 700, loss is 3.9686440420150757 and perplexity is 52.91273472926173
At time: 673.5908770561218 and batch: 750, loss is 3.9172723722457885 and perplexity is 50.26315844418849
At time: 674.590304851532 and batch: 800, loss is 3.912156763076782 and perplexity is 50.006688329729464
At time: 675.591796875 and batch: 850, loss is 3.9172791051864624 and perplexity is 50.26349686419166
At time: 676.591579914093 and batch: 900, loss is 3.872268042564392 and perplexity is 48.051244854591
At time: 677.5910427570343 and batch: 950, loss is 3.9696673727035523 and perplexity is 52.96690966923302
At time: 678.5916092395782 and batch: 1000, loss is 3.925570569038391 and perplexity is 50.68198738347671
At time: 679.5960845947266 and batch: 1050, loss is 3.8740208625793455 and perplexity is 48.13554389725696
At time: 680.6030647754669 and batch: 1100, loss is 3.8833562421798704 and perplexity is 48.58701150380496
At time: 681.605634689331 and batch: 1150, loss is 3.8894191932678224 and perplexity is 48.88248699967786
At time: 682.6078555583954 and batch: 1200, loss is 3.9163252401351927 and perplexity is 50.215575130245405
At time: 683.609561920166 and batch: 1250, loss is 3.9320993041992187 and perplexity is 51.01395915524372
At time: 684.6172749996185 and batch: 1300, loss is 3.900851917266846 and perplexity is 49.44455383727514
At time: 685.6216032505035 and batch: 1350, loss is 3.7846087646484374 and perplexity is 44.01844561742028
At time: 686.6216287612915 and batch: 1400, loss is 3.811625123023987 and perplexity is 45.223873538089514
At time: 687.619606256485 and batch: 1450, loss is 3.7409899377822877 and perplexity is 42.13968519035506
At time: 688.6207754611969 and batch: 1500, loss is 3.750016174316406 and perplexity is 42.521769755058955
At time: 689.6207406520844 and batch: 1550, loss is 3.770044379234314 and perplexity is 43.381990052633036
At time: 690.6202425956726 and batch: 1600, loss is 3.8421736001968383 and perplexity is 46.62671220554485
At time: 691.6201450824738 and batch: 1650, loss is 3.7948464155197144 and perplexity is 44.47140576326012
At time: 692.6211831569672 and batch: 1700, loss is 3.7799023151397706 and perplexity is 43.811761780708025
At time: 693.6217684745789 and batch: 1750, loss is 3.7715931797027586 and perplexity is 43.44923215800916
At time: 694.6203460693359 and batch: 1800, loss is 3.7260010194778443 and perplexity is 41.51276704143024
At time: 695.6219494342804 and batch: 1850, loss is 3.7636320924758913 and perplexity is 43.104702266775845
At time: 696.6200873851776 and batch: 1900, loss is 3.8721146106719972 and perplexity is 48.043872826727586
At time: 697.6213190555573 and batch: 1950, loss is 3.806053652763367 and perplexity is 44.97261067335101
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345500999273256 and perplexity of 77.13067021073017
finished 17 epochs...
Completing Train Step...
At time: 700.8650379180908 and batch: 50, loss is 3.9882140827178953 and perplexity is 53.95843795498487
At time: 701.8631129264832 and batch: 100, loss is 3.980818967819214 and perplexity is 53.560880908362854
At time: 702.8588387966156 and batch: 150, loss is 3.9435468101501465 and perplexity is 51.60129711969489
At time: 703.8575718402863 and batch: 200, loss is 3.93228018283844 and perplexity is 51.02318732532127
At time: 704.8565800189972 and batch: 250, loss is 3.9419875717163086 and perplexity is 51.520901088569204
At time: 705.8544681072235 and batch: 300, loss is 3.9322390508651734 and perplexity is 51.02108868410516
At time: 706.8460068702698 and batch: 350, loss is 3.9487360954284667 and perplexity is 51.86976695199328
At time: 707.838695526123 and batch: 400, loss is 3.8889901065826415 and perplexity is 48.861516674733124
At time: 708.8366203308105 and batch: 450, loss is 3.9304430150985716 and perplexity is 50.929535225231554
At time: 709.834089756012 and batch: 500, loss is 3.946999111175537 and perplexity is 51.7797481868164
At time: 710.8261904716492 and batch: 550, loss is 3.9338695573806763 and perplexity is 51.10434675960443
At time: 711.8192710876465 and batch: 600, loss is 3.902134003639221 and perplexity is 49.50798668044102
At time: 712.8181641101837 and batch: 650, loss is 3.928151397705078 and perplexity is 50.8129578428627
At time: 713.816333770752 and batch: 700, loss is 3.9585029029846193 and perplexity is 52.37885099994903
At time: 714.8199656009674 and batch: 750, loss is 3.9109992837905883 and perplexity is 49.948840109333624
At time: 715.819338798523 and batch: 800, loss is 3.9060233497619627 and perplexity is 49.70091531639968
At time: 716.8241767883301 and batch: 850, loss is 3.9105913734436033 and perplexity is 49.928469615583175
At time: 717.8193356990814 and batch: 900, loss is 3.866169819831848 and perplexity is 47.75910932000595
At time: 718.8163421154022 and batch: 950, loss is 3.9627507305145264 and perplexity is 52.60182055805263
At time: 719.8144648075104 and batch: 1000, loss is 3.918878755569458 and perplexity is 50.3439652296679
At time: 720.8154156208038 and batch: 1050, loss is 3.86878764629364 and perplexity is 47.884298170024216
At time: 721.8084700107574 and batch: 1100, loss is 3.879841938018799 and perplexity is 48.41656164884639
At time: 722.8008399009705 and batch: 1150, loss is 3.886147003173828 and perplexity is 48.72279562270626
At time: 723.8199439048767 and batch: 1200, loss is 3.9130160713195803 and perplexity is 50.04967795723154
At time: 724.8183073997498 and batch: 1250, loss is 3.930152111053467 and perplexity is 50.91472177217041
At time: 725.8173289299011 and batch: 1300, loss is 3.9004028987884523 and perplexity is 49.42235730264631
At time: 726.8163347244263 and batch: 1350, loss is 3.784028239250183 and perplexity is 43.992899207634984
At time: 727.8148818016052 and batch: 1400, loss is 3.8121531057357787 and perplexity is 45.24775726602078
At time: 728.81094789505 and batch: 1450, loss is 3.7424533700942995 and perplexity is 42.20139891319466
At time: 729.8025434017181 and batch: 1500, loss is 3.752267632484436 and perplexity is 42.61761359460423
At time: 730.7960629463196 and batch: 1550, loss is 3.7727421045303347 and perplexity is 43.49918074766753
At time: 731.7927997112274 and batch: 1600, loss is 3.8455141830444335 and perplexity is 46.78273305577374
At time: 732.7854735851288 and batch: 1650, loss is 3.798489899635315 and perplexity is 44.63373216100965
At time: 733.778028011322 and batch: 1700, loss is 3.7838580322265627 and perplexity is 43.9854119444109
At time: 734.7763350009918 and batch: 1750, loss is 3.7759230375289916 and perplexity is 43.637769030286165
At time: 735.7742612361908 and batch: 1800, loss is 3.7299410581588743 and perplexity is 41.67665159305575
At time: 736.7734687328339 and batch: 1850, loss is 3.768092517852783 and perplexity is 43.29739700540298
At time: 737.7673637866974 and batch: 1900, loss is 3.876411108970642 and perplexity is 48.25073732284103
At time: 738.7603464126587 and batch: 1950, loss is 3.8092705106735227 and perplexity is 45.11751411366788
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344399811500727 and perplexity of 77.04578160753123
finished 18 epochs...
Completing Train Step...
At time: 742.0775232315063 and batch: 50, loss is 3.987331953048706 and perplexity is 53.91086060374342
At time: 743.119960308075 and batch: 100, loss is 3.9786461925506593 and perplexity is 53.444631488629256
At time: 744.1151864528656 and batch: 150, loss is 3.9404688692092895 and perplexity is 51.442715552234766
At time: 745.1227250099182 and batch: 200, loss is 3.92827552318573 and perplexity is 50.81926541713555
At time: 746.1243538856506 and batch: 250, loss is 3.937286124229431 and perplexity is 51.27924678525237
At time: 747.1240501403809 and batch: 300, loss is 3.927527303695679 and perplexity is 50.781255673868976
At time: 748.1251475811005 and batch: 350, loss is 3.9443877792358397 and perplexity is 51.64471046743731
At time: 749.1659700870514 and batch: 400, loss is 3.884212555885315 and perplexity is 48.628635046523854
At time: 750.1647520065308 and batch: 450, loss is 3.9254860258102418 and perplexity is 50.67770274577539
At time: 751.1615052223206 and batch: 500, loss is 3.94217360496521 and perplexity is 51.53048658076751
At time: 752.1609189510345 and batch: 550, loss is 3.928905749320984 and perplexity is 50.851303140820804
At time: 753.1664836406708 and batch: 600, loss is 3.897772440910339 and perplexity is 49.29252470797303
At time: 754.1600832939148 and batch: 650, loss is 3.9244320440292357 and perplexity is 50.624317508853686
At time: 755.1619641780853 and batch: 700, loss is 3.9551050090789794 and perplexity is 52.20117525396807
At time: 756.1659371852875 and batch: 750, loss is 3.9082102584838867 and perplexity is 49.809725617324716
At time: 757.1731941699982 and batch: 800, loss is 3.903202438354492 and perplexity is 49.56091100014915
At time: 758.1760535240173 and batch: 850, loss is 3.9075597667694093 and perplexity is 49.77733533945608
At time: 759.1746206283569 and batch: 900, loss is 3.863590145111084 and perplexity is 47.63606512823784
At time: 760.1725602149963 and batch: 950, loss is 3.960073881149292 and perplexity is 52.46120169979966
At time: 761.1667709350586 and batch: 1000, loss is 3.916422781944275 and perplexity is 50.22047348718113
At time: 762.1581466197968 and batch: 1050, loss is 3.86696120262146 and perplexity is 47.79692001656289
At time: 763.1535987854004 and batch: 1100, loss is 3.8781727361679077 and perplexity is 48.33581204696974
At time: 764.1617963314056 and batch: 1150, loss is 3.8846715545654296 and perplexity is 48.65096064914509
At time: 765.1545243263245 and batch: 1200, loss is 3.911777210235596 and perplexity is 49.987711750630666
At time: 766.1571369171143 and batch: 1250, loss is 3.9292721557617187 and perplexity is 50.8699387997156
At time: 767.15505027771 and batch: 1300, loss is 3.900101318359375 and perplexity is 49.40745473419942
At time: 768.1525852680206 and batch: 1350, loss is 3.783659954071045 and perplexity is 43.976700257969135
At time: 769.1523928642273 and batch: 1400, loss is 3.812053265571594 and perplexity is 45.24323994801499
At time: 770.1517922878265 and batch: 1450, loss is 3.7427664279937742 and perplexity is 42.21461246268843
At time: 771.1511099338531 and batch: 1500, loss is 3.7529556465148928 and perplexity is 42.64694519982282
At time: 772.1472842693329 and batch: 1550, loss is 3.7736389303207396 and perplexity is 43.538209433173506
At time: 773.1404848098755 and batch: 1600, loss is 3.8468270540237426 and perplexity is 46.84419308405132
At time: 774.1349618434906 and batch: 1650, loss is 3.7998852491378785 and perplexity is 44.69605528813835
At time: 775.1322634220123 and batch: 1700, loss is 3.785280327796936 and perplexity is 44.04801671166833
At time: 776.1366295814514 and batch: 1750, loss is 3.777493691444397 and perplexity is 43.70636271744335
At time: 777.1337285041809 and batch: 1800, loss is 3.7314713764190675 and perplexity is 41.7404789596483
At time: 778.1330728530884 and batch: 1850, loss is 3.769821662902832 and perplexity is 43.37232925080523
At time: 779.1322791576385 and batch: 1900, loss is 3.8779731464385985 and perplexity is 48.32616567801745
At time: 780.1288032531738 and batch: 1950, loss is 3.8102307653427125 and perplexity is 45.16085922509992
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343894781068314 and perplexity of 77.00688096696082
finished 19 epochs...
Completing Train Step...
At time: 783.4433178901672 and batch: 50, loss is 3.98604483127594 and perplexity is 53.84151539870699
At time: 784.4763910770416 and batch: 100, loss is 3.9768450117111205 and perplexity is 53.3484546843261
At time: 785.472357749939 and batch: 150, loss is 3.9382706117630004 and perplexity is 51.329755422925864
At time: 786.468344449997 and batch: 200, loss is 3.925725064277649 and perplexity is 50.68981811413331
At time: 787.4613585472107 and batch: 250, loss is 3.9344375705718995 and perplexity is 51.133382948381175
At time: 788.4559273719788 and batch: 300, loss is 3.9246020698547364 and perplexity is 50.63292568201367
At time: 789.4527232646942 and batch: 350, loss is 3.941665377616882 and perplexity is 51.50430403212174
At time: 790.4465820789337 and batch: 400, loss is 3.881267538070679 and perplexity is 48.485633524381406
At time: 791.4526393413544 and batch: 450, loss is 3.9224513387680053 and perplexity is 50.524144895778285
At time: 792.450982093811 and batch: 500, loss is 3.939269919395447 and perplexity is 51.38107527718189
At time: 793.4432954788208 and batch: 550, loss is 3.925947861671448 and perplexity is 50.701112931682516
At time: 794.436580657959 and batch: 600, loss is 3.8951457214355467 and perplexity is 49.16321697527899
At time: 795.4327688217163 and batch: 650, loss is 3.9220834302902223 and perplexity is 50.50556005350854
At time: 796.426641702652 and batch: 700, loss is 3.9529836988449096 and perplexity is 52.09055773518985
At time: 797.4188339710236 and batch: 750, loss is 3.9063916969299317 and perplexity is 49.71922587991702
At time: 798.4133248329163 and batch: 800, loss is 3.9014068031311036 and perplexity is 49.471997534619675
At time: 799.471985578537 and batch: 850, loss is 3.905663652420044 and perplexity is 49.683041244090305
At time: 800.4866995811462 and batch: 900, loss is 3.8619686937332154 and perplexity is 47.55888815106627
At time: 801.4800848960876 and batch: 950, loss is 3.9584557819366455 and perplexity is 52.37638291174816
At time: 802.4713406562805 and batch: 1000, loss is 3.9150132179260253 and perplexity is 50.14973438213517
At time: 803.4687640666962 and batch: 1050, loss is 3.8658143949508665 and perplexity is 47.74213756053157
At time: 804.4609899520874 and batch: 1100, loss is 3.876976203918457 and perplexity is 48.27801127619137
At time: 805.4525272846222 and batch: 1150, loss is 3.8835797786712645 and perplexity is 48.59787368788587
At time: 806.4614670276642 and batch: 1200, loss is 3.910836911201477 and perplexity is 49.94073044525337
At time: 807.4524085521698 and batch: 1250, loss is 3.9285077047348023 and perplexity is 50.831066082798216
At time: 808.4479765892029 and batch: 1300, loss is 3.8996452379226683 and perplexity is 49.38492609849319
At time: 809.4400153160095 and batch: 1350, loss is 3.7831846714019775 and perplexity is 43.95580386073484
At time: 810.4324052333832 and batch: 1400, loss is 3.8117015743255616 and perplexity is 45.2273310942494
At time: 811.428388595581 and batch: 1450, loss is 3.7426284074783327 and perplexity is 42.208786382185735
At time: 812.4210379123688 and batch: 1500, loss is 3.7530514574050904 and perplexity is 42.65103143735652
At time: 813.4129710197449 and batch: 1550, loss is 3.7738557720184325 and perplexity is 43.5476513560858
At time: 814.4090938568115 and batch: 1600, loss is 3.847314190864563 and perplexity is 46.867018175301126
At time: 815.4005842208862 and batch: 1650, loss is 3.800383200645447 and perplexity is 44.71831729849225
At time: 816.3924465179443 and batch: 1700, loss is 3.7857542562484743 and perplexity is 44.06889726757576
At time: 817.3911046981812 and batch: 1750, loss is 3.7780978155136107 and perplexity is 43.73277476041088
At time: 818.3809089660645 and batch: 1800, loss is 3.7320980501174925 and perplexity is 41.76664481784322
At time: 819.3713483810425 and batch: 1850, loss is 3.7705604076385497 and perplexity is 43.404382168719536
At time: 820.3687565326691 and batch: 1900, loss is 3.8786211156845094 and perplexity is 48.35748969455331
At time: 821.363498210907 and batch: 1950, loss is 3.810499544143677 and perplexity is 45.172999138095506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.343600392896076 and perplexity of 76.98421438857322
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fcae8787b38>
ELAPSED
4248.806109666824


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.42392198682246}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.7974071334468391, 'wordvec_source': 'gigavec', 'dropout': 0.589069126925909, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.51251288675175}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.014077492312028927, 'wordvec_source': 'gigavec', 'dropout': 0.3289390596927714, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -77.08629938542906}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5708626383639636, 'wordvec_source': 'gigavec', 'dropout': 0.49301208999077983, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.32988623121379}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.4614530027327207, 'wordvec_source': 'gigavec', 'dropout': 0.04151275008878008, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.98421438857322}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5891111345668675, 'wordvec_source': 'gigavec', 'dropout': 0.49737964351637065, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4654321670532227 and batch: 50, loss is 7.523883323669434 and perplexity is 1851.7442721313823
At time: 2.484179735183716 and batch: 100, loss is 6.653748102188111 and perplexity is 775.6862350861612
At time: 3.4772770404815674 and batch: 150, loss is 6.403803367614746 and perplexity is 604.1384343485499
At time: 4.470140695571899 and batch: 200, loss is 6.218726625442505 and perplexity is 502.06350990398886
At time: 5.463413238525391 and batch: 250, loss is 6.135903568267822 and perplexity is 462.1564953591785
At time: 6.456599950790405 and batch: 300, loss is 6.047662696838379 and perplexity is 423.12290687851174
At time: 7.449452638626099 and batch: 350, loss is 5.977136421203613 and perplexity is 394.3096132773754
At time: 8.442206382751465 and batch: 400, loss is 5.908418283462525 and perplexity is 368.12342776234544
At time: 9.439591407775879 and batch: 450, loss is 5.817466497421265 and perplexity is 336.1194146008922
At time: 10.432133674621582 and batch: 500, loss is 5.794958143234253 and perplexity is 328.63842795236775
At time: 11.425715923309326 and batch: 550, loss is 5.7486152076721195 and perplexity is 313.75587258465606
At time: 12.418696403503418 and batch: 600, loss is 5.772867479324341 and perplexity is 321.4581870296508
At time: 13.41152286529541 and batch: 650, loss is 5.821037349700927 and perplexity is 337.3217928587047
At time: 14.403234958648682 and batch: 700, loss is 5.748713092803955 and perplexity is 313.78658612278304
At time: 15.395929098129272 and batch: 750, loss is 5.667712135314941 and perplexity is 289.37173311198273
At time: 16.39912462234497 and batch: 800, loss is 5.677306432723999 and perplexity is 292.16141268974553
At time: 17.39185118675232 and batch: 850, loss is 5.7044025421142575 and perplexity is 300.1860779218869
At time: 18.38566780090332 and batch: 900, loss is 5.686871852874756 and perplexity is 294.96946805791424
At time: 19.377949714660645 and batch: 950, loss is 5.696896896362305 and perplexity is 297.941421895484
At time: 20.371958255767822 and batch: 1000, loss is 5.673465032577514 and perplexity is 291.04125665746665
At time: 21.365652084350586 and batch: 1050, loss is 5.561887245178223 and perplexity is 260.3136487139758
At time: 22.36840295791626 and batch: 1100, loss is 5.642481822967529 and perplexity is 282.1621266591452
At time: 23.359452962875366 and batch: 1150, loss is 5.544084415435791 and perplexity is 255.7203374322921
At time: 24.354600191116333 and batch: 1200, loss is 5.6197398853302 and perplexity is 275.8176296914402
At time: 25.34843420982361 and batch: 1250, loss is 5.574829607009888 and perplexity is 263.7046183901179
At time: 26.342106819152832 and batch: 1300, loss is 5.580054225921631 and perplexity is 265.08597992807097
At time: 27.33573865890503 and batch: 1350, loss is 5.53819655418396 and perplexity is 254.219115396638
At time: 28.330049991607666 and batch: 1400, loss is 5.538623313903809 and perplexity is 254.32762902808145
At time: 29.327178955078125 and batch: 1450, loss is 5.508196706771851 and perplexity is 246.70584272364138
At time: 30.321158170700073 and batch: 1500, loss is 5.476847152709961 and perplexity is 239.09169817267048
At time: 31.31510043144226 and batch: 1550, loss is 5.456893615722656 and perplexity is 234.3682545497226
At time: 32.31004214286804 and batch: 1600, loss is 5.479919281005859 and perplexity is 239.82734797063435
At time: 33.30378174781799 and batch: 1650, loss is 5.476718235015869 and perplexity is 239.0608770090048
At time: 34.29791831970215 and batch: 1700, loss is 5.490426540374756 and perplexity is 242.3605613786256
At time: 35.293133020401 and batch: 1750, loss is 5.483077602386475 and perplexity is 240.58599720981584
At time: 36.300336837768555 and batch: 1800, loss is 5.469552640914917 and perplexity is 237.3539865445187
At time: 37.30995059013367 and batch: 1850, loss is 5.447895946502686 and perplexity is 232.2689451284847
At time: 38.31953167915344 and batch: 1900, loss is 5.476263751983643 and perplexity is 238.95225258258418
At time: 39.31600999832153 and batch: 1950, loss is 5.411922674179078 and perplexity is 224.0619719716047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.941306890443314 and perplexity of 139.9530333766084
finished 1 epochs...
Completing Train Step...
At time: 42.761651039123535 and batch: 50, loss is 5.211227951049804 and perplexity is 183.31902683165913
At time: 43.75017690658569 and batch: 100, loss is 5.142843961715698 and perplexity is 171.201968470296
At time: 44.75215172767639 and batch: 150, loss is 5.058715543746948 and perplexity is 157.38822814222505
At time: 45.74304509162903 and batch: 200, loss is 5.0252266693115235 and perplexity is 152.20475234932837
At time: 46.7318696975708 and batch: 250, loss is 5.043458557128906 and perplexity is 155.00518331916234
At time: 47.72295784950256 and batch: 300, loss is 5.052774038314819 and perplexity is 156.45587765528452
At time: 48.710400104522705 and batch: 350, loss is 5.047316427230835 and perplexity is 155.60432814990074
At time: 49.69939088821411 and batch: 400, loss is 4.989919109344482 and perplexity is 146.92453819279027
At time: 50.68995118141174 and batch: 450, loss is 4.957550373077392 and perplexity is 142.2449217757396
At time: 51.68025732040405 and batch: 500, loss is 4.95722336769104 and perplexity is 142.19841452461293
At time: 52.69660043716431 and batch: 550, loss is 4.922435321807861 and perplexity is 137.33666523511607
At time: 53.687368869781494 and batch: 600, loss is 4.891387453079224 and perplexity is 133.13816892574505
At time: 54.67940926551819 and batch: 650, loss is 4.954028739929199 and perplexity is 141.74486836318965
At time: 55.671945571899414 and batch: 700, loss is 4.963317861557007 and perplexity is 143.06768809028344
At time: 56.67276477813721 and batch: 750, loss is 4.909782218933105 and perplexity is 135.60987792844216
At time: 57.67196559906006 and batch: 800, loss is 4.9105440044403075 and perplexity is 135.71322292644462
At time: 58.66389727592468 and batch: 850, loss is 4.9141238498687745 and perplexity is 136.19992592810812
At time: 59.65443706512451 and batch: 900, loss is 4.890851230621338 and perplexity is 133.06679638705444
At time: 60.645485639572144 and batch: 950, loss is 4.940837984085083 and perplexity is 139.88742389295857
At time: 61.6357045173645 and batch: 1000, loss is 4.9175803852081295 and perplexity is 136.6715203571646
At time: 62.62843656539917 and batch: 1050, loss is 4.8339667224884035 and perplexity is 125.70862418218555
At time: 63.62924599647522 and batch: 1100, loss is 4.895473890304565 and perplexity is 133.68334284620508
At time: 64.62222361564636 and batch: 1150, loss is 4.8304103660583495 and perplexity is 125.26235352737532
At time: 65.61608815193176 and batch: 1200, loss is 4.900557308197022 and perplexity is 134.3646413384991
At time: 66.61224269866943 and batch: 1250, loss is 4.8814277076721195 and perplexity is 131.81872821304256
At time: 67.61227321624756 and batch: 1300, loss is 4.875860948562622 and perplexity is 131.0869637748443
At time: 68.6113076210022 and batch: 1350, loss is 4.772621183395386 and perplexity is 118.22873536197623
At time: 69.6084771156311 and batch: 1400, loss is 4.769222841262818 and perplexity is 117.82763559245441
At time: 70.60080170631409 and batch: 1450, loss is 4.734300584793091 and perplexity is 113.78384872713578
At time: 71.60722208023071 and batch: 1500, loss is 4.718799161911011 and perplexity is 112.03363759925752
At time: 72.60764575004578 and batch: 1550, loss is 4.7126435279846195 and perplexity is 111.34611776989516
At time: 73.60389494895935 and batch: 1600, loss is 4.778222436904907 and perplexity is 118.89282260509188
At time: 74.59443783760071 and batch: 1650, loss is 4.762749662399292 and perplexity is 117.06737952364435
At time: 75.59049844741821 and batch: 1700, loss is 4.763990697860717 and perplexity is 117.21275448209012
At time: 76.58362030982971 and batch: 1750, loss is 4.753324527740478 and perplexity is 115.96918714266208
At time: 77.57231020927429 and batch: 1800, loss is 4.714669427871704 and perplexity is 111.5719225089799
At time: 78.56429767608643 and batch: 1850, loss is 4.73746768951416 and perplexity is 114.14478535196578
At time: 79.5552270412445 and batch: 1900, loss is 4.838249158859253 and perplexity is 126.24811771538452
At time: 80.54791593551636 and batch: 1950, loss is 4.758048715591431 and perplexity is 116.51834350521779
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614119560773982 and perplexity of 100.89895401693654
finished 2 epochs...
Completing Train Step...
At time: 83.80968236923218 and batch: 50, loss is 4.723884935379028 and perplexity is 112.60486664039571
At time: 84.83815503120422 and batch: 100, loss is 4.657130517959595 and perplexity is 105.33339580031532
At time: 85.82881903648376 and batch: 150, loss is 4.610187692642212 and perplexity is 100.5030115420001
At time: 86.81958532333374 and batch: 200, loss is 4.598099203109741 and perplexity is 99.29539577016553
At time: 87.8105616569519 and batch: 250, loss is 4.6107644271850585 and perplexity is 100.56099181842347
At time: 88.80890727043152 and batch: 300, loss is 4.6243169975280765 and perplexity is 101.93312872288348
At time: 89.79980897903442 and batch: 350, loss is 4.633661231994629 and perplexity is 102.89007980222591
At time: 90.79046249389648 and batch: 400, loss is 4.579486570358276 and perplexity is 97.46434027725856
At time: 91.78118205070496 and batch: 450, loss is 4.581643943786621 and perplexity is 97.67483423057358
At time: 92.77225351333618 and batch: 500, loss is 4.592016077041626 and perplexity is 98.6932028244975
At time: 93.76348733901978 and batch: 550, loss is 4.5605106544494625 and perplexity is 95.63230242401308
At time: 94.75462555885315 and batch: 600, loss is 4.528523216247558 and perplexity is 92.62167784455369
At time: 95.74635672569275 and batch: 650, loss is 4.587004842758179 and perplexity is 98.19986521055243
At time: 96.73737621307373 and batch: 700, loss is 4.620796709060669 and perplexity is 101.57492556453448
At time: 97.7277774810791 and batch: 750, loss is 4.578292922973633 and perplexity is 97.34807162808002
At time: 98.71827864646912 and batch: 800, loss is 4.576122989654541 and perplexity is 97.13706182530268
At time: 99.70817828178406 and batch: 850, loss is 4.572669849395752 and perplexity is 96.80221240024201
At time: 100.69816970825195 and batch: 900, loss is 4.544067850112915 and perplexity is 94.07269647326606
At time: 101.69934916496277 and batch: 950, loss is 4.6086147689819335 and perplexity is 100.34505223874629
At time: 102.71034908294678 and batch: 1000, loss is 4.58903751373291 and perplexity is 98.39967623252333
At time: 103.78919672966003 and batch: 1050, loss is 4.526766443252564 and perplexity is 92.45910542539477
At time: 104.7871425151825 and batch: 1100, loss is 4.575244998931884 and perplexity is 97.05181381515119
At time: 105.77835512161255 and batch: 1150, loss is 4.530768375396729 and perplexity is 92.8298618676599
At time: 106.76915431022644 and batch: 1200, loss is 4.59320447921753 and perplexity is 98.81055976128867
At time: 107.76073026657104 and batch: 1250, loss is 4.589925956726074 and perplexity is 98.48713758186028
At time: 108.75091028213501 and batch: 1300, loss is 4.576128873825073 and perplexity is 97.13763339802108
At time: 109.7417049407959 and batch: 1350, loss is 4.459364976882934 and perplexity is 86.43260496325769
At time: 110.73542523384094 and batch: 1400, loss is 4.466949939727783 and perplexity is 87.09068566428395
At time: 111.72641706466675 and batch: 1450, loss is 4.42738410949707 and perplexity is 83.71214843007897
At time: 112.71671414375305 and batch: 1500, loss is 4.422341299057007 and perplexity is 83.29106654442033
At time: 113.70794558525085 and batch: 1550, loss is 4.424100112915039 and perplexity is 83.43768892945316
At time: 114.7002215385437 and batch: 1600, loss is 4.500242700576782 and perplexity is 90.03898116158844
At time: 115.69208312034607 and batch: 1650, loss is 4.4848172569274904 and perplexity is 88.66074719510281
At time: 116.68346977233887 and batch: 1700, loss is 4.483130760192871 and perplexity is 88.51134715122365
At time: 117.67559385299683 and batch: 1750, loss is 4.469907350540161 and perplexity is 87.34862983516064
At time: 118.66846990585327 and batch: 1800, loss is 4.432870779037476 and perplexity is 84.17271164874238
At time: 119.65925645828247 and batch: 1850, loss is 4.468677558898926 and perplexity is 87.24127524573447
At time: 120.65032625198364 and batch: 1900, loss is 4.5734293746948245 and perplexity is 96.8757640582028
At time: 121.64041233062744 and batch: 1950, loss is 4.499588384628296 and perplexity is 89.98008649019151
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.515968216297239 and perplexity of 91.4660821154602
finished 3 epochs...
Completing Train Step...
At time: 124.95508027076721 and batch: 50, loss is 4.474691753387451 and perplexity is 87.76754219209462
At time: 125.95290780067444 and batch: 100, loss is 4.418837108612061 and perplexity is 82.99970956819153
At time: 126.95130634307861 and batch: 150, loss is 4.3798487091064455 and perplexity is 79.8259555513287
At time: 127.95043087005615 and batch: 200, loss is 4.377021427154541 and perplexity is 79.60058381275554
At time: 128.98743152618408 and batch: 250, loss is 4.381902656555176 and perplexity is 79.99008236530108
At time: 129.98414087295532 and batch: 300, loss is 4.393273162841797 and perplexity is 80.9048006495186
At time: 130.97938871383667 and batch: 350, loss is 4.405617504119873 and perplexity is 81.90970681124514
At time: 131.97746300697327 and batch: 400, loss is 4.351059656143189 and perplexity is 77.5606069689983
At time: 132.9747757911682 and batch: 450, loss is 4.372120199203491 and perplexity is 79.21139773039158
At time: 133.9721601009369 and batch: 500, loss is 4.38654390335083 and perplexity is 80.36219895323849
At time: 134.9695656299591 and batch: 550, loss is 4.352878284454346 and perplexity is 77.70178922477405
At time: 135.96820163726807 and batch: 600, loss is 4.326379199028015 and perplexity is 75.66980464464648
At time: 136.9645619392395 and batch: 650, loss is 4.386273002624511 and perplexity is 80.34043172368574
At time: 137.961932182312 and batch: 700, loss is 4.42043179512024 and perplexity is 83.13217367651427
At time: 138.95961833000183 and batch: 750, loss is 4.3793167304992675 and perplexity is 79.7835011440973
At time: 139.9574213027954 and batch: 800, loss is 4.379418897628784 and perplexity is 79.79165281180111
At time: 140.95549607276917 and batch: 850, loss is 4.37451416015625 and perplexity is 79.40125388701148
At time: 141.95457792282104 and batch: 900, loss is 4.344231672286988 and perplexity is 77.0328282794015
At time: 142.951886177063 and batch: 950, loss is 4.41840181350708 and perplexity is 82.96358806322918
At time: 143.9485695362091 and batch: 1000, loss is 4.3906666278839115 and perplexity is 80.69419405433011
At time: 144.9474174976349 and batch: 1050, loss is 4.344901084899902 and perplexity is 77.08441228982754
At time: 145.94521403312683 and batch: 1100, loss is 4.3828380584716795 and perplexity is 80.06494024729177
At time: 146.94296216964722 and batch: 1150, loss is 4.346892094612121 and perplexity is 77.23804099072484
At time: 147.94067978858948 and batch: 1200, loss is 4.406283855438232 and perplexity is 81.96430564134617
At time: 148.94262170791626 and batch: 1250, loss is 4.411533794403076 and perplexity is 82.39574476685878
At time: 149.94115114212036 and batch: 1300, loss is 4.390484809875488 and perplexity is 80.67952373038078
At time: 150.93864941596985 and batch: 1350, loss is 4.273495140075684 and perplexity is 71.77205111784983
At time: 151.93518614768982 and batch: 1400, loss is 4.2839997863769534 and perplexity is 72.52996496813687
At time: 152.93245005607605 and batch: 1450, loss is 4.240707125663757 and perplexity is 69.45694926903728
At time: 153.93105912208557 and batch: 1500, loss is 4.235942730903625 and perplexity is 69.12681601095453
At time: 154.92947244644165 and batch: 1550, loss is 4.248147268295288 and perplexity is 69.97564607472415
At time: 155.9293429851532 and batch: 1600, loss is 4.330380640029907 and perplexity is 75.97319950705997
At time: 156.9261350631714 and batch: 1650, loss is 4.30885977268219 and perplexity is 74.35565823363997
At time: 157.92517924308777 and batch: 1700, loss is 4.309688205718994 and perplexity is 74.41728243963368
At time: 158.92311573028564 and batch: 1750, loss is 4.296715841293335 and perplexity is 73.45814889757041
At time: 159.92003655433655 and batch: 1800, loss is 4.263312473297119 and perplexity is 71.04492854347795
At time: 160.91755890846252 and batch: 1850, loss is 4.297851819992065 and perplexity is 73.5416432048647
At time: 161.91726660728455 and batch: 1900, loss is 4.407676057815552 and perplexity is 82.0784960121243
At time: 162.9267725944519 and batch: 1950, loss is 4.332078514099121 and perplexity is 76.10230200133238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4786865234375 and perplexity of 88.11885457992028
finished 4 epochs...
Completing Train Step...
At time: 166.38643288612366 and batch: 50, loss is 4.315321674346924 and perplexity is 74.83769293846721
At time: 167.4160237312317 and batch: 100, loss is 4.269421558380127 and perplexity is 71.48027649152932
At time: 168.40574026107788 and batch: 150, loss is 4.2292091751098635 and perplexity is 68.66291035861497
At time: 169.4011104106903 and batch: 200, loss is 4.227538480758667 and perplexity is 68.54829139542981
At time: 170.4438178539276 and batch: 250, loss is 4.2301324224472046 and perplexity is 68.72633248042519
At time: 171.44553899765015 and batch: 300, loss is 4.2388625955581665 and perplexity is 69.32895191884134
At time: 172.44112944602966 and batch: 350, loss is 4.252478790283203 and perplexity is 70.27940451757426
At time: 173.43646550178528 and batch: 400, loss is 4.194196810722351 and perplexity is 66.30045836865891
At time: 174.42543053627014 and batch: 450, loss is 4.228448958396911 and perplexity is 68.61073150273253
At time: 175.42000007629395 and batch: 500, loss is 4.246870908737183 and perplexity is 69.88638896422252
At time: 176.4129240512848 and batch: 550, loss is 4.210147109031677 and perplexity is 67.36644929433461
At time: 177.41196632385254 and batch: 600, loss is 4.190885353088379 and perplexity is 66.08127032591361
At time: 178.40679264068604 and batch: 650, loss is 4.248077554702759 and perplexity is 69.9707679910831
At time: 179.39875316619873 and batch: 700, loss is 4.281830382347107 and perplexity is 72.37278872088585
At time: 180.4517059326172 and batch: 750, loss is 4.243693866729736 and perplexity is 69.66470929999922
At time: 181.44331240653992 and batch: 800, loss is 4.241664519309998 and perplexity is 69.52347875332572
At time: 182.44193148612976 and batch: 850, loss is 4.233742961883545 and perplexity is 68.9749201118352
At time: 183.43891167640686 and batch: 900, loss is 4.207854361534118 and perplexity is 67.21217196336022
At time: 184.43313241004944 and batch: 950, loss is 4.286905460357666 and perplexity is 72.74101988005611
At time: 185.42605829238892 and batch: 1000, loss is 4.253780183792114 and perplexity is 70.37092521772928
At time: 186.42025876045227 and batch: 1050, loss is 4.215536136627197 and perplexity is 67.73046892353132
At time: 187.41647028923035 and batch: 1100, loss is 4.247177028656006 and perplexity is 69.90778585477922
At time: 188.41103076934814 and batch: 1150, loss is 4.218598690032959 and perplexity is 67.93821505624514
At time: 189.40455269813538 and batch: 1200, loss is 4.274975738525391 and perplexity is 71.87839541263911
At time: 190.39915776252747 and batch: 1250, loss is 4.284795579910278 and perplexity is 72.58770681747865
At time: 191.39648056030273 and batch: 1300, loss is 4.258773431777954 and perplexity is 70.7231834227305
At time: 192.39085125923157 and batch: 1350, loss is 4.145880885124207 and perplexity is 63.17324577147647
At time: 193.3887813091278 and batch: 1400, loss is 4.159621982574463 and perplexity is 64.04730702515616
At time: 194.3827519416809 and batch: 1450, loss is 4.112374167442322 and perplexity is 61.09158718650779
At time: 195.37902545928955 and batch: 1500, loss is 4.108711791038513 and perplexity is 60.8682560101683
At time: 196.37543606758118 and batch: 1550, loss is 4.124296574592591 and perplexity is 61.82430516417404
At time: 197.37813234329224 and batch: 1600, loss is 4.209679818153381 and perplexity is 67.33497692102534
At time: 198.3724319934845 and batch: 1650, loss is 4.185490236282349 and perplexity is 65.72571414980426
At time: 199.37032437324524 and batch: 1700, loss is 4.1853117179870605 and perplexity is 65.71398195459452
At time: 200.36316585540771 and batch: 1750, loss is 4.173687024116516 and perplexity is 64.95449995682294
At time: 201.36717581748962 and batch: 1800, loss is 4.139649300575257 and perplexity is 62.78080039745796
At time: 202.35991168022156 and batch: 1850, loss is 4.176143221855163 and perplexity is 65.11423714548602
At time: 203.3727090358734 and batch: 1900, loss is 4.284220294952393 and perplexity is 72.54596021086792
At time: 204.3715193271637 and batch: 1950, loss is 4.206840381622315 and perplexity is 67.14405471175932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470761037427326 and perplexity of 87.423230053146
finished 5 epochs...
Completing Train Step...
At time: 207.79037976264954 and batch: 50, loss is 4.198796515464783 and perplexity is 66.60612334684761
At time: 208.7839789390564 and batch: 100, loss is 4.153451886177063 and perplexity is 63.65334560662639
At time: 209.77716851234436 and batch: 150, loss is 4.1180515956878665 and perplexity is 61.43941674353723
At time: 210.77592039108276 and batch: 200, loss is 4.116180891990662 and perplexity is 61.3245892370883
At time: 211.76981401443481 and batch: 250, loss is 4.1181595468521115 and perplexity is 61.44604955810881
At time: 212.76747751235962 and batch: 300, loss is 4.123619775772095 and perplexity is 61.78247670368399
At time: 213.76053285598755 and batch: 350, loss is 4.1396762561798095 and perplexity is 62.78249271469561
At time: 214.76349878311157 and batch: 400, loss is 4.08237024307251 and perplexity is 59.28582526257626
At time: 215.75728273391724 and batch: 450, loss is 4.121200757026672 and perplexity is 61.63320435349658
At time: 216.75671672821045 and batch: 500, loss is 4.1430038022995 and perplexity is 62.99175232212359
At time: 217.74980330467224 and batch: 550, loss is 4.1050506639480595 and perplexity is 60.645817026297244
At time: 218.74334836006165 and batch: 600, loss is 4.088698668479919 and perplexity is 59.66220086179926
At time: 219.73715782165527 and batch: 650, loss is 4.14245370388031 and perplexity is 62.95711018791441
At time: 220.74074578285217 and batch: 700, loss is 4.180480237007141 and perplexity is 65.39725185451778
At time: 221.74174451828003 and batch: 750, loss is 4.140399355888366 and perplexity is 62.82790713447809
At time: 222.7359139919281 and batch: 800, loss is 4.137789282798767 and perplexity is 62.664135525699265
At time: 223.73201537132263 and batch: 850, loss is 4.1266819095611575 and perplexity is 61.97195286579492
At time: 224.72682428359985 and batch: 900, loss is 4.103817443847657 and perplexity is 60.57107348282785
At time: 225.73262190818787 and batch: 950, loss is 4.186590538024903 and perplexity is 65.79807206808556
At time: 226.73106813430786 and batch: 1000, loss is 4.150551047325134 and perplexity is 63.46896506704659
At time: 227.72366285324097 and batch: 1050, loss is 4.117071967124939 and perplexity is 61.379258407228974
At time: 228.7171196937561 and batch: 1100, loss is 4.141775641441345 and perplexity is 62.91443580581305
At time: 229.71457958221436 and batch: 1150, loss is 4.119197583198547 and perplexity is 61.509865907009555
At time: 230.7719464302063 and batch: 1200, loss is 4.178542242050171 and perplexity is 65.27063504122604
At time: 231.76570653915405 and batch: 1250, loss is 4.185820293426514 and perplexity is 65.74741097171331
At time: 232.7574212551117 and batch: 1300, loss is 4.161055879592896 and perplexity is 64.13921014179408
At time: 233.75613069534302 and batch: 1350, loss is 4.048677053451538 and perplexity is 57.321573483772966
At time: 234.7569546699524 and batch: 1400, loss is 4.067205920219421 and perplexity is 58.393578127609885
At time: 235.76021218299866 and batch: 1450, loss is 4.013642439842224 and perplexity is 55.34810599346343
At time: 236.76174998283386 and batch: 1500, loss is 4.014250102043152 and perplexity is 55.38174916617558
At time: 237.75563669204712 and batch: 1550, loss is 4.029821887016296 and perplexity is 56.25089134072391
At time: 238.75437116622925 and batch: 1600, loss is 4.1172727823257445 and perplexity is 61.39158553302698
At time: 239.75040078163147 and batch: 1650, loss is 4.08889262676239 and perplexity is 59.67377396211988
At time: 240.7544186115265 and batch: 1700, loss is 4.090643572807312 and perplexity is 59.77835104832435
At time: 241.75168991088867 and batch: 1750, loss is 4.077550182342529 and perplexity is 59.00075157255869
At time: 242.74464082717896 and batch: 1800, loss is 4.044497790336609 and perplexity is 57.08251144556128
At time: 243.74557781219482 and batch: 1850, loss is 4.084356417655945 and perplexity is 59.40369427734308
At time: 244.74053978919983 and batch: 1900, loss is 4.1910154914855955 and perplexity is 66.08987059612042
At time: 245.73518419265747 and batch: 1950, loss is 4.113512926101684 and perplexity is 61.161195386378616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473810240279796 and perplexity of 87.69020804376616
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 248.9995138645172 and batch: 50, loss is 4.14179057598114 and perplexity is 62.91537541097454
At time: 250.0195860862732 and batch: 100, loss is 4.122503442764282 and perplexity is 61.71354536795642
At time: 251.01421236991882 and batch: 150, loss is 4.0907651233673095 and perplexity is 59.785617581986685
At time: 252.0094063282013 and batch: 200, loss is 4.089706883430481 and perplexity is 59.72238351812053
At time: 253.00194334983826 and batch: 250, loss is 4.084211711883545 and perplexity is 59.39509884179882
At time: 253.99467372894287 and batch: 300, loss is 4.089448194503785 and perplexity is 59.706935996965946
At time: 254.9921214580536 and batch: 350, loss is 4.0965127182006835 and perplexity is 60.130230487703514
At time: 255.98678946495056 and batch: 400, loss is 4.036180267333984 and perplexity is 56.60969539856686
At time: 257.01997447013855 and batch: 450, loss is 4.066904773712158 and perplexity is 58.375995753078406
At time: 258.0148754119873 and batch: 500, loss is 4.087155079841613 and perplexity is 59.570178007400564
At time: 259.01076221466064 and batch: 550, loss is 4.044414625167847 and perplexity is 57.077764366262095
At time: 260.003821849823 and batch: 600, loss is 4.010534949302674 and perplexity is 55.176379235534434
At time: 260.99709939956665 and batch: 650, loss is 4.059440102577209 and perplexity is 57.941860496944464
At time: 261.9949839115143 and batch: 700, loss is 4.095677924156189 and perplexity is 60.08005507537986
At time: 262.9966833591461 and batch: 750, loss is 4.042081780433655 and perplexity is 56.944765996810304
At time: 263.99511313438416 and batch: 800, loss is 4.042632946968078 and perplexity is 56.976160697197656
At time: 264.99719524383545 and batch: 850, loss is 4.031636514663696 and perplexity is 56.3530584329215
At time: 265.99402022361755 and batch: 900, loss is 3.9940171146392824 and perplexity is 54.2724707828693
At time: 266.99195408821106 and batch: 950, loss is 4.080983247756958 and perplexity is 59.20365310003397
At time: 267.99101400375366 and batch: 1000, loss is 4.039187760353088 and perplexity is 56.780204936893014
At time: 268.9848210811615 and batch: 1050, loss is 3.9937013292312624 and perplexity is 54.25533503429095
At time: 269.9788613319397 and batch: 1100, loss is 4.00963529586792 and perplexity is 55.126761938970134
At time: 270.97378277778625 and batch: 1150, loss is 3.9837914085388184 and perplexity is 53.72032430237564
At time: 271.97108912467957 and batch: 1200, loss is 4.032474060058593 and perplexity is 56.40027644835583
At time: 272.9729540348053 and batch: 1250, loss is 4.025559058189392 and perplexity is 56.01161378155615
At time: 273.9717342853546 and batch: 1300, loss is 4.016256966590881 and perplexity is 55.493004434955644
At time: 274.9662036895752 and batch: 1350, loss is 3.892744345664978 and perplexity is 49.04529925627342
At time: 275.965754032135 and batch: 1400, loss is 3.8993183612823485 and perplexity is 49.36878595782887
At time: 276.959703207016 and batch: 1450, loss is 3.8431583404541017 and perplexity is 46.672650020813286
At time: 277.95312333106995 and batch: 1500, loss is 3.8395798349380494 and perplexity is 46.505930167136725
At time: 278.95120882987976 and batch: 1550, loss is 3.851878619194031 and perplexity is 47.08142827830063
At time: 279.94839572906494 and batch: 1600, loss is 3.925668888092041 and perplexity is 50.686970633483554
At time: 280.9409649372101 and batch: 1650, loss is 3.882951283454895 and perplexity is 48.56733975296841
At time: 281.94469022750854 and batch: 1700, loss is 3.8752998876571656 and perplexity is 48.19714985441968
At time: 282.93980646133423 and batch: 1750, loss is 3.8583294630050657 and perplexity is 47.38612493718157
At time: 283.9330151081085 and batch: 1800, loss is 3.8240845680236815 and perplexity is 45.790862753758375
At time: 284.93171405792236 and batch: 1850, loss is 3.8511220979690552 and perplexity is 47.04582364803329
At time: 285.93069338798523 and batch: 1900, loss is 3.9492574977874755 and perplexity is 51.89681902273716
At time: 286.9251916408539 and batch: 1950, loss is 3.8686669492721557 and perplexity is 47.878519026628936
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3962927529978195 and perplexity of 81.14946920260631
finished 7 epochs...
Completing Train Step...
At time: 290.30577969551086 and batch: 50, loss is 4.05174421787262 and perplexity is 57.49765807667912
At time: 291.2981147766113 and batch: 100, loss is 4.022041668891907 and perplexity is 55.814945213430065
At time: 292.29231333732605 and batch: 150, loss is 3.980613946914673 and perplexity is 53.54990093371164
At time: 293.2917354106903 and batch: 200, loss is 3.98061056137085 and perplexity is 53.549719638482195
At time: 294.28991174697876 and batch: 250, loss is 3.974126443862915 and perplexity is 53.20362025098797
At time: 295.2854700088501 and batch: 300, loss is 3.9818440198898317 and perplexity is 53.61581174891822
At time: 296.2809545993805 and batch: 350, loss is 3.9957487869262693 and perplexity is 54.36653433658928
At time: 297.2768247127533 and batch: 400, loss is 3.9385416507720947 and perplexity is 51.343669674540045
At time: 298.2724368572235 and batch: 450, loss is 3.9772470235824584 and perplexity is 53.3699057079209
At time: 299.27009320259094 and batch: 500, loss is 4.000832357406616 and perplexity is 54.64361412627433
At time: 300.2652382850647 and batch: 550, loss is 3.9581235790252687 and perplexity is 52.35898621463419
At time: 301.26000690460205 and batch: 600, loss is 3.928659830093384 and perplexity is 50.83879936515241
At time: 302.25573921203613 and batch: 650, loss is 3.9776444816589356 and perplexity is 53.39112222404388
At time: 303.2542247772217 and batch: 700, loss is 4.017103419303894 and perplexity is 55.53999652459799
At time: 304.250449180603 and batch: 750, loss is 3.969319767951965 and perplexity is 52.94850131935541
At time: 305.2464849948883 and batch: 800, loss is 3.9685758924484253 and perplexity is 52.90912887218984
At time: 306.2428925037384 and batch: 850, loss is 3.957871923446655 and perplexity is 52.34581144148484
At time: 307.3787751197815 and batch: 900, loss is 3.9221414136886597 and perplexity is 50.50848862242379
At time: 308.37416791915894 and batch: 950, loss is 4.012265610694885 and perplexity is 55.27195354436733
At time: 309.37269496917725 and batch: 1000, loss is 3.9735329151153564 and perplexity is 53.172051742230295
At time: 310.3739378452301 and batch: 1050, loss is 3.9330658435821535 and perplexity is 51.0632899921046
At time: 311.3747444152832 and batch: 1100, loss is 3.949836058616638 and perplexity is 51.92685317683663
At time: 312.3729588985443 and batch: 1150, loss is 3.9279900646209716 and perplexity is 50.80476069291487
At time: 313.371604681015 and batch: 1200, loss is 3.9778467559814454 and perplexity is 53.401922969439696
At time: 314.3714487552643 and batch: 1250, loss is 3.974982204437256 and perplexity is 53.24916929837071
At time: 315.37251138687134 and batch: 1300, loss is 3.9666091442108153 and perplexity is 52.805172198039365
At time: 316.37072110176086 and batch: 1350, loss is 3.8444608449935913 and perplexity is 46.733480967027134
At time: 317.3714294433594 and batch: 1400, loss is 3.8561912202835082 and perplexity is 47.28491014988648
At time: 318.3726441860199 and batch: 1450, loss is 3.8000754833221437 and perplexity is 44.704558814561025
At time: 319.37172293663025 and batch: 1500, loss is 3.801682262420654 and perplexity is 44.77644690394576
At time: 320.37015318870544 and batch: 1550, loss is 3.815913648605347 and perplexity is 45.41823373811027
At time: 321.37143182754517 and batch: 1600, loss is 3.8943233394622805 and perplexity is 49.12280265217386
At time: 322.37170910835266 and batch: 1650, loss is 3.853503909111023 and perplexity is 47.15801146704286
At time: 323.3717405796051 and batch: 1700, loss is 3.8501536083221435 and perplexity is 47.000282311615855
At time: 324.37072014808655 and batch: 1750, loss is 3.837163281440735 and perplexity is 46.393681780685924
At time: 325.37104630470276 and batch: 1800, loss is 3.8049328470230104 and perplexity is 44.92223335001978
At time: 326.3715274333954 and batch: 1850, loss is 3.8377659368515014 and perplexity is 46.42164961067198
At time: 327.3722207546234 and batch: 1900, loss is 3.93795777797699 and perplexity is 51.3137002526327
At time: 328.3722245693207 and batch: 1950, loss is 3.858765473365784 and perplexity is 47.40679028343362
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.395772960574128 and perplexity of 81.10729928407974
finished 8 epochs...
Completing Train Step...
At time: 331.7273392677307 and batch: 50, loss is 4.004112949371338 and perplexity is 54.82317189454864
At time: 332.7519898414612 and batch: 100, loss is 3.9738220834732054 and perplexity is 53.18742964040968
At time: 333.7507860660553 and batch: 150, loss is 3.9309511041641234 and perplexity is 50.95541854015095
At time: 334.7464361190796 and batch: 200, loss is 3.931390881538391 and perplexity is 50.977832508538086
At time: 335.73962211608887 and batch: 250, loss is 3.9245743989944457 and perplexity is 50.63152464478506
At time: 336.73285818099976 and batch: 300, loss is 3.9325519371032716 and perplexity is 51.0370549782938
At time: 337.72963881492615 and batch: 350, loss is 3.947289447784424 and perplexity is 51.794783925921095
At time: 338.73361372947693 and batch: 400, loss is 3.8916508674621584 and perplexity is 48.99169860150058
At time: 339.734233379364 and batch: 450, loss is 3.9321672201156614 and perplexity is 51.017423932686555
At time: 340.73470544815063 and batch: 500, loss is 3.956217851638794 and perplexity is 52.25929927890887
At time: 341.73237442970276 and batch: 550, loss is 3.9155073070526125 and perplexity is 50.17451894298142
At time: 342.73863101005554 and batch: 600, loss is 3.886772756576538 and perplexity is 48.753293618974006
At time: 343.7354383468628 and batch: 650, loss is 3.935892481803894 and perplexity is 51.20783162653914
At time: 344.7366828918457 and batch: 700, loss is 3.974538049697876 and perplexity is 53.225523679004475
At time: 345.72981786727905 and batch: 750, loss is 3.929512343406677 and perplexity is 50.882158597978616
At time: 346.73273396492004 and batch: 800, loss is 3.927739968299866 and perplexity is 50.79205619791087
At time: 347.72956013679504 and batch: 850, loss is 3.917723436355591 and perplexity is 50.28583546501859
At time: 348.7390830516815 and batch: 900, loss is 3.8829482126235964 and perplexity is 48.5671906110904
At time: 349.73743319511414 and batch: 950, loss is 3.974863204956055 and perplexity is 53.24283305186233
At time: 350.7314715385437 and batch: 1000, loss is 3.9372445058822634 and perplexity is 51.2771126721666
At time: 351.7291340827942 and batch: 1050, loss is 3.8987321949005125 and perplexity is 49.33985611486735
At time: 352.7285976409912 and batch: 1100, loss is 3.915249466896057 and perplexity is 50.16158360485854
At time: 353.72921895980835 and batch: 1150, loss is 3.8942162799835205 and perplexity is 49.11754387203284
At time: 354.728600025177 and batch: 1200, loss is 3.943715853691101 and perplexity is 51.61002072299147
At time: 355.73011684417725 and batch: 1250, loss is 3.9431971597671507 and perplexity is 51.58325786029467
At time: 356.72964811325073 and batch: 1300, loss is 3.934845895767212 and perplexity is 51.154266260261615
At time: 357.7292618751526 and batch: 1350, loss is 3.813763904571533 and perplexity is 45.32070103384142
At time: 358.7294189929962 and batch: 1400, loss is 3.8279236364364624 and perplexity is 45.96699488387281
At time: 359.727432012558 and batch: 1450, loss is 3.7722361373901365 and perplexity is 43.4771771585996
At time: 360.7255129814148 and batch: 1500, loss is 3.774964714050293 and perplexity is 43.595969963378984
At time: 361.71741366386414 and batch: 1550, loss is 3.789931788444519 and perplexity is 44.25338158103667
At time: 362.7098364830017 and batch: 1600, loss is 3.870361747741699 and perplexity is 47.95973226799851
At time: 363.7087650299072 and batch: 1650, loss is 3.83003577709198 and perplexity is 46.0641862473621
At time: 364.7077658176422 and batch: 1700, loss is 3.8278899431228637 and perplexity is 45.965446129590475
At time: 365.70610189437866 and batch: 1750, loss is 3.8167072916030884 and perplexity is 45.45429390884454
At time: 366.70079255104065 and batch: 1800, loss is 3.7848883438110352 and perplexity is 44.03075397808526
At time: 367.6941604614258 and batch: 1850, loss is 3.820048007965088 and perplexity is 45.606397738644
At time: 368.6879086494446 and batch: 1900, loss is 3.921107521057129 and perplexity is 50.456295254026095
At time: 369.6859302520752 and batch: 1950, loss is 3.8416719818115235 and perplexity is 46.603329254605114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39882443450218 and perplexity of 81.35517409263738
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 373.1250648498535 and batch: 50, loss is 3.993973145484924 and perplexity is 54.27008452068539
At time: 374.1167013645172 and batch: 100, loss is 3.997855792045593 and perplexity is 54.48120566687301
At time: 375.1091887950897 and batch: 150, loss is 3.9617592430114748 and perplexity is 52.54969235683196
At time: 376.1115186214447 and batch: 200, loss is 3.971170787811279 and perplexity is 53.04660081086229
At time: 377.1054902076721 and batch: 250, loss is 3.9589732933044433 and perplexity is 52.40349530018863
At time: 378.10242462158203 and batch: 300, loss is 3.9638904476165773 and perplexity is 52.66180592922516
At time: 379.0999176502228 and batch: 350, loss is 3.9799083518981933 and perplexity is 53.512129717637826
At time: 380.0946433544159 and batch: 400, loss is 3.9280677127838133 and perplexity is 50.80870574240723
At time: 381.09215450286865 and batch: 450, loss is 3.96314350605011 and perplexity is 52.622485324336644
At time: 382.0871889591217 and batch: 500, loss is 3.979211897850037 and perplexity is 53.474873953240376
At time: 383.0902864933014 and batch: 550, loss is 3.9445720052719118 and perplexity is 51.65422564417555
At time: 384.125155210495 and batch: 600, loss is 3.9050718688964845 and perplexity is 49.65364833685864
At time: 385.12147665023804 and batch: 650, loss is 3.941535439491272 and perplexity is 51.49761209417329
At time: 386.1146836280823 and batch: 700, loss is 3.9813382244110107 and perplexity is 53.58869997082768
At time: 387.1164872646332 and batch: 750, loss is 3.9330105447769164 and perplexity is 51.06046633124981
At time: 388.10914611816406 and batch: 800, loss is 3.9308541679382323 and perplexity is 50.950479353585884
At time: 389.107120513916 and batch: 850, loss is 3.9227007007598877 and perplexity is 50.53674526814934
At time: 390.11203050613403 and batch: 900, loss is 3.8847750854492187 and perplexity is 48.65599778684344
At time: 391.1174199581146 and batch: 950, loss is 3.9776720714569094 and perplexity is 53.3925952946404
At time: 392.11482191085815 and batch: 1000, loss is 3.939954218864441 and perplexity is 51.41624735245414
At time: 393.10845255851746 and batch: 1050, loss is 3.8986099672317507 and perplexity is 49.333825787821304
At time: 394.1099343299866 and batch: 1100, loss is 3.9151959133148195 and perplexity is 50.15889734434603
At time: 395.1102828979492 and batch: 1150, loss is 3.8976119327545167 and perplexity is 49.28461349066076
At time: 396.1068811416626 and batch: 1200, loss is 3.9303870725631715 and perplexity is 50.92668617759653
At time: 397.1077473163605 and batch: 1250, loss is 3.9275351476669313 and perplexity is 50.78165400214089
At time: 398.11032342910767 and batch: 1300, loss is 3.9193549871444704 and perplexity is 50.36794632534585
At time: 399.10729718208313 and batch: 1350, loss is 3.8008127069473265 and perplexity is 44.73752822289262
At time: 400.10479736328125 and batch: 1400, loss is 3.806667366027832 and perplexity is 45.00021943212306
At time: 401.1077227592468 and batch: 1450, loss is 3.741442918777466 and perplexity is 42.158777990900504
At time: 402.1097512245178 and batch: 1500, loss is 3.7522649574279785 and perplexity is 42.61749959023426
At time: 403.1139872074127 and batch: 1550, loss is 3.7663687372207644 and perplexity is 43.22282608145057
At time: 404.1074969768524 and batch: 1600, loss is 3.8356796073913575 and perplexity is 46.324899716671986
At time: 405.1121287345886 and batch: 1650, loss is 3.7941803455352785 and perplexity is 44.44179455737802
At time: 406.1072852611542 and batch: 1700, loss is 3.7863699293136595 and perplexity is 44.09603765458114
At time: 407.1054196357727 and batch: 1750, loss is 3.7697762775421144 and perplexity is 43.37036082666617
At time: 408.10672879219055 and batch: 1800, loss is 3.7341287612915037 and perplexity is 41.851546986890924
At time: 409.11501288414 and batch: 1850, loss is 3.766109390258789 and perplexity is 43.21161782629464
At time: 410.1134696006775 and batch: 1900, loss is 3.8726745557785036 and perplexity is 48.070782291422965
At time: 411.1106741428375 and batch: 1950, loss is 3.792565007209778 and perplexity is 44.370063973553364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366001998546512 and perplexity of 78.72824602143443
finished 10 epochs...
Completing Train Step...
At time: 414.47041273117065 and batch: 50, loss is 3.9858014822006225 and perplexity is 53.82841470980594
At time: 415.5072205066681 and batch: 100, loss is 3.9693871212005614 and perplexity is 52.95206769302964
At time: 416.51470851898193 and batch: 150, loss is 3.9224218225479124 and perplexity is 50.52265363600582
At time: 417.51384139060974 and batch: 200, loss is 3.927922258377075 and perplexity is 50.80131592970976
At time: 418.51269698143005 and batch: 250, loss is 3.9165884923934935 and perplexity is 50.22879623396667
At time: 419.5104672908783 and batch: 300, loss is 3.9212590265274048 and perplexity is 50.463940237880735
At time: 420.50773000717163 and batch: 350, loss is 3.9398926734924316 and perplexity is 51.41308301775958
At time: 421.50670742988586 and batch: 400, loss is 3.887241311073303 and perplexity is 48.77614254649713
At time: 422.5063762664795 and batch: 450, loss is 3.9264233922958374 and perplexity is 50.72522859698641
At time: 423.50541853904724 and batch: 500, loss is 3.9441581344604493 and perplexity is 51.63285189118406
At time: 424.50763297080994 and batch: 550, loss is 3.9118685007095335 and perplexity is 49.99227536083134
At time: 425.50542163848877 and batch: 600, loss is 3.874203052520752 and perplexity is 48.14431450811344
At time: 426.51193857192993 and batch: 650, loss is 3.9116724157333373 and perplexity is 49.98247358772885
At time: 427.5157072544098 and batch: 700, loss is 3.9518646144866945 and perplexity is 52.03229661245354
At time: 428.5198154449463 and batch: 750, loss is 3.9062304973602293 and perplexity is 49.711211808049065
At time: 429.52466225624084 and batch: 800, loss is 3.9048310136795044 and perplexity is 49.641690436733725
At time: 430.52949619293213 and batch: 850, loss is 3.8970354843139647 and perplexity is 49.2562116389589
At time: 431.53504633903503 and batch: 900, loss is 3.8587389326095582 and perplexity is 47.405532088066074
At time: 432.5360338687897 and batch: 950, loss is 3.9538958930969237 and perplexity is 52.138096121365024
At time: 433.54068875312805 and batch: 1000, loss is 3.916925015449524 and perplexity is 50.24570222644463
At time: 434.5791690349579 and batch: 1050, loss is 3.8776131534576415 and perplexity is 48.3087717286145
At time: 435.577965259552 and batch: 1100, loss is 3.89468590259552 and perplexity is 49.14061599845313
At time: 436.58360719680786 and batch: 1150, loss is 3.878537859916687 and perplexity is 48.35346382220969
At time: 437.586727142334 and batch: 1200, loss is 3.9138423919677736 and perplexity is 50.09105213137601
At time: 438.5922496318817 and batch: 1250, loss is 3.912600808143616 and perplexity is 50.0288984837807
At time: 439.5938813686371 and batch: 1300, loss is 3.9047385549545286 and perplexity is 49.63710084150764
At time: 440.59925961494446 and batch: 1350, loss is 3.7857544374465943 and perplexity is 44.06890525277782
At time: 441.5989134311676 and batch: 1400, loss is 3.7944493103027344 and perplexity is 44.45374944196577
At time: 442.6059944629669 and batch: 1450, loss is 3.7313467979431154 and perplexity is 41.73527931828242
At time: 443.6052315235138 and batch: 1500, loss is 3.744005727767944 and perplexity is 42.266961453726424
At time: 444.6045069694519 and batch: 1550, loss is 3.7595479345321654 and perplexity is 42.929014866357555
At time: 445.60470819473267 and batch: 1600, loss is 3.8308141899108885 and perplexity is 46.100057159807406
At time: 446.60559034347534 and batch: 1650, loss is 3.7909933280944825 and perplexity is 44.30038324288002
At time: 447.6134753227234 and batch: 1700, loss is 3.7855300951004027 and perplexity is 44.05901984007912
At time: 448.627464056015 and batch: 1750, loss is 3.7713223457336427 and perplexity is 43.43746622338807
At time: 449.6269602775574 and batch: 1800, loss is 3.736441149711609 and perplexity is 41.94843599884829
At time: 450.6333763599396 and batch: 1850, loss is 3.7696127223968507 and perplexity is 43.36326796105418
At time: 451.63914585113525 and batch: 1900, loss is 3.8766466617584228 and perplexity is 48.262104257233894
At time: 452.6469326019287 and batch: 1950, loss is 3.795797739028931 and perplexity is 44.51373258710971
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3647722111191865 and perplexity of 78.63148652330375
finished 11 epochs...
Completing Train Step...
At time: 456.0737986564636 and batch: 50, loss is 3.970436301231384 and perplexity is 53.00765309949424
At time: 457.0707337856293 and batch: 100, loss is 3.9530667304992675 and perplexity is 52.094883079942804
At time: 458.07250452041626 and batch: 150, loss is 3.905505838394165 and perplexity is 49.67520118198582
At time: 459.0757169723511 and batch: 200, loss is 3.9105333852767945 and perplexity is 49.9255744391024
At time: 460.0785701274872 and batch: 250, loss is 3.898728332519531 and perplexity is 49.3396655459135
At time: 461.1031274795532 and batch: 300, loss is 3.9031725835800173 and perplexity is 49.55943139241526
At time: 462.10523319244385 and batch: 350, loss is 3.9218650388717653 and perplexity is 50.4945312769474
At time: 463.103253364563 and batch: 400, loss is 3.8690784072875974 and perplexity is 47.898223080467375
At time: 464.10589361190796 and batch: 450, loss is 3.9091697454452516 and perplexity is 49.857540334734416
At time: 465.1084499359131 and batch: 500, loss is 3.9273909521102905 and perplexity is 50.774332041184714
At time: 466.10863876342773 and batch: 550, loss is 3.8966849994659425 and perplexity is 49.23895110806243
At time: 467.1149263381958 and batch: 600, loss is 3.859581050872803 and perplexity is 47.44546996626436
At time: 468.10861992836 and batch: 650, loss is 3.897462763786316 and perplexity is 49.277262304016276
At time: 469.10279154777527 and batch: 700, loss is 3.9370024681091307 and perplexity is 51.26470317584677
At time: 470.10058641433716 and batch: 750, loss is 3.8924104833602904 and perplexity is 49.02892761271902
At time: 471.10292530059814 and batch: 800, loss is 3.891153254508972 and perplexity is 48.96732576230106
At time: 472.1005103588104 and batch: 850, loss is 3.8834739923477173 and perplexity is 48.592732969409866
At time: 473.09991550445557 and batch: 900, loss is 3.8453639936447144 and perplexity is 46.77570731278814
At time: 474.09847593307495 and batch: 950, loss is 3.9409549903869627 and perplexity is 51.467729024998555
At time: 475.0960786342621 and batch: 1000, loss is 3.9045009183883668 and perplexity is 49.625306652730195
At time: 476.08796215057373 and batch: 1050, loss is 3.8666757011413573 and perplexity is 47.78327587295809
At time: 477.086816072464 and batch: 1100, loss is 3.883413257598877 and perplexity is 48.58978179159793
At time: 478.08291578292847 and batch: 1150, loss is 3.8679611396789553 and perplexity is 47.84473783153988
At time: 479.08077812194824 and batch: 1200, loss is 3.9039414882659913 and perplexity is 49.597552525327814
At time: 480.0794062614441 and batch: 1250, loss is 3.90328236579895 and perplexity is 49.564872435422
At time: 481.0803210735321 and batch: 1300, loss is 3.895379247665405 and perplexity is 49.17469921663703
At time: 482.0791800022125 and batch: 1350, loss is 3.7763404750823977 and perplexity is 43.655988876385685
At time: 483.07910561561584 and batch: 1400, loss is 3.786154770851135 and perplexity is 44.08655103951532
At time: 484.07957768440247 and batch: 1450, loss is 3.723844666481018 and perplexity is 41.42334730671945
At time: 485.0784287452698 and batch: 1500, loss is 3.7374965524673462 and perplexity is 41.9927318646781
At time: 486.07923102378845 and batch: 1550, loss is 3.753492293357849 and perplexity is 42.66983769036803
At time: 487.07915353775024 and batch: 1600, loss is 3.825426502227783 and perplexity is 45.852352326976245
At time: 488.07490849494934 and batch: 1650, loss is 3.786374497413635 and perplexity is 44.096239090149766
At time: 489.0681622028351 and batch: 1700, loss is 3.781826581954956 and perplexity is 43.896148465226844
At time: 490.0633451938629 and batch: 1750, loss is 3.768915419578552 and perplexity is 43.33304117193168
At time: 491.05964064598083 and batch: 1800, loss is 3.734069299697876 and perplexity is 41.8490585011967
At time: 492.05850481987 and batch: 1850, loss is 3.7677248430252077 and perplexity is 43.281480568640426
At time: 493.0644268989563 and batch: 1900, loss is 3.8752809047698973 and perplexity is 48.1962349420412
At time: 494.06381821632385 and batch: 1950, loss is 3.7938054466247557 and perplexity is 44.42513649975571
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365216206395349 and perplexity of 78.66640628340835
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 497.3260004520416 and batch: 50, loss is 3.969691014289856 and perplexity is 52.96816190580158
At time: 498.37824392318726 and batch: 100, loss is 3.9743928861618043 and perplexity is 53.217797834546985
At time: 499.37875056266785 and batch: 150, loss is 3.9353173208236694 and perplexity is 51.17838734831731
At time: 500.37843012809753 and batch: 200, loss is 3.94482759475708 and perplexity is 51.667429608440045
At time: 501.37374114990234 and batch: 250, loss is 3.9407652711868284 and perplexity is 51.45796553480526
At time: 502.36846113204956 and batch: 300, loss is 3.9334388542175294 and perplexity is 51.08234069518548
At time: 503.37016558647156 and batch: 350, loss is 3.9540969371795653 and perplexity is 52.148579230818676
At time: 504.37382888793945 and batch: 400, loss is 3.9045027351379393 and perplexity is 49.625396809566745
At time: 505.3751564025879 and batch: 450, loss is 3.9494443941116333 and perplexity is 51.90651925388853
At time: 506.38122487068176 and batch: 500, loss is 3.9633311796188355 and perplexity is 52.63236210072862
At time: 507.3799057006836 and batch: 550, loss is 3.936696910858154 and perplexity is 51.249041266998994
At time: 508.37704825401306 and batch: 600, loss is 3.8988557195663454 and perplexity is 49.345951180543906
At time: 509.3774907588959 and batch: 650, loss is 3.928685941696167 and perplexity is 50.8401268650189
At time: 510.3775737285614 and batch: 700, loss is 3.9607229471206664 and perplexity is 52.495263533633214
At time: 511.4014720916748 and batch: 750, loss is 3.915328607559204 and perplexity is 50.1655535829408
At time: 512.4022827148438 and batch: 800, loss is 3.9141820764541624 and perplexity is 50.108070174910985
At time: 513.4018776416779 and batch: 850, loss is 3.905485653877258 and perplexity is 49.67419852216685
At time: 514.4031112194061 and batch: 900, loss is 3.86224045753479 and perplexity is 47.57181469171222
At time: 515.40669465065 and batch: 950, loss is 3.960227108001709 and perplexity is 52.469240780495916
At time: 516.4068381786346 and batch: 1000, loss is 3.920934209823608 and perplexity is 50.44755136898536
At time: 517.4021346569061 and batch: 1050, loss is 3.8755879735946657 and perplexity is 48.21103677573765
At time: 518.4010355472565 and batch: 1100, loss is 3.8903995084762575 and perplexity is 48.93043074125971
At time: 519.3982775211334 and batch: 1150, loss is 3.883271198272705 and perplexity is 48.582879650206166
At time: 520.407543182373 and batch: 1200, loss is 3.914249906539917 and perplexity is 50.11146912488216
At time: 521.4115424156189 and batch: 1250, loss is 3.9134401893615722 and perplexity is 50.0709094306563
At time: 522.4042432308197 and batch: 1300, loss is 3.902723264694214 and perplexity is 49.53716840588568
At time: 523.3983001708984 and batch: 1350, loss is 3.7868648195266723 and perplexity is 44.117865752859636
At time: 524.3950891494751 and batch: 1400, loss is 3.801412434577942 and perplexity is 44.7643666017476
At time: 525.3921751976013 and batch: 1450, loss is 3.7244628286361694 and perplexity is 41.44896156843211
At time: 526.3842804431915 and batch: 1500, loss is 3.7337302780151367 and perplexity is 41.83487316766625
At time: 527.3778693675995 and batch: 1550, loss is 3.7529078578948973 and perplexity is 42.64490720986145
At time: 528.3755724430084 and batch: 1600, loss is 3.825263419151306 and perplexity is 45.84487519400856
At time: 529.3737955093384 and batch: 1650, loss is 3.7852825212478636 and perplexity is 44.048113328937404
At time: 530.3659300804138 and batch: 1700, loss is 3.7737696838378905 and perplexity is 43.543902579378674
At time: 531.3641550540924 and batch: 1750, loss is 3.7613569259643556 and perplexity is 43.00674337034515
At time: 532.3582055568695 and batch: 1800, loss is 3.725639910697937 and perplexity is 41.497779123070664
At time: 533.3551931381226 and batch: 1850, loss is 3.7516587448120116 and perplexity is 42.591672153571615
At time: 534.3514423370361 and batch: 1900, loss is 3.862606239318848 and perplexity is 47.58921877781581
At time: 535.3434581756592 and batch: 1950, loss is 3.798215379714966 and perplexity is 44.62148099408355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346072174781977 and perplexity of 77.17473794453286
finished 13 epochs...
Completing Train Step...
At time: 538.6622800827026 and batch: 50, loss is 3.9773517370224 and perplexity is 53.37549454694511
At time: 539.6553845405579 and batch: 100, loss is 3.963779258728027 and perplexity is 52.65595084707092
At time: 540.6535663604736 and batch: 150, loss is 3.9164773082733153 and perplexity is 50.22321189990017
At time: 541.6453115940094 and batch: 200, loss is 3.920057635307312 and perplexity is 50.40334970690136
At time: 542.6371948719025 and batch: 250, loss is 3.914530644416809 and perplexity is 50.125539287253574
At time: 543.6347763538361 and batch: 300, loss is 3.9104092597961424 and perplexity is 49.91937778776743
At time: 544.6328775882721 and batch: 350, loss is 3.932139754295349 and perplexity is 51.016022716530884
At time: 545.6243057250977 and batch: 400, loss is 3.8819423151016235 and perplexity is 48.518361557034986
At time: 546.6163227558136 and batch: 450, loss is 3.927611289024353 and perplexity is 50.78552073341595
At time: 547.6144418716431 and batch: 500, loss is 3.942557330131531 and perplexity is 51.55026391958996
At time: 548.6148164272308 and batch: 550, loss is 3.914714312553406 and perplexity is 50.134746597169226
At time: 549.6196711063385 and batch: 600, loss is 3.878446226119995 and perplexity is 48.3490332137363
At time: 550.6184256076813 and batch: 650, loss is 3.9071299409866334 and perplexity is 49.75594435485698
At time: 551.6143889427185 and batch: 700, loss is 3.945009608268738 and perplexity is 51.67683463463636
At time: 552.6127042770386 and batch: 750, loss is 3.901693902015686 and perplexity is 49.4862029290088
At time: 553.6082761287689 and batch: 800, loss is 3.901871476173401 and perplexity is 49.49499118007248
At time: 554.6004612445831 and batch: 850, loss is 3.8938366031646727 and perplexity is 49.09889861903505
At time: 555.5969250202179 and batch: 900, loss is 3.852361674308777 and perplexity is 47.104176696967656
At time: 556.5925817489624 and batch: 950, loss is 3.9507785081863402 and perplexity is 51.975814685521506
At time: 557.5876138210297 and batch: 1000, loss is 3.910936827659607 and perplexity is 49.945720595450794
At time: 558.5791711807251 and batch: 1050, loss is 3.8673116111755372 and perplexity is 47.813671400938034
At time: 559.5754055976868 and batch: 1100, loss is 3.8821716499328613 and perplexity is 48.52948978329078
At time: 560.5746359825134 and batch: 1150, loss is 3.875390329360962 and perplexity is 48.201509083895736
At time: 561.6283872127533 and batch: 1200, loss is 3.907288680076599 and perplexity is 49.76384319509501
At time: 562.6228997707367 and batch: 1250, loss is 3.9075035429000855 and perplexity is 49.77453674373334
At time: 563.6161971092224 and batch: 1300, loss is 3.897595601081848 and perplexity is 49.28380859705828
At time: 564.6150336265564 and batch: 1350, loss is 3.7818054437637327 and perplexity is 43.89522058985346
At time: 565.615051984787 and batch: 1400, loss is 3.797651529312134 and perplexity is 44.59632824591005
At time: 566.6147751808167 and batch: 1450, loss is 3.721935648918152 and perplexity is 41.3443448417375
At time: 567.6150600910187 and batch: 1500, loss is 3.7332204389572143 and perplexity is 41.8135495516102
At time: 568.6179103851318 and batch: 1550, loss is 3.7529952144622802 and perplexity is 42.648632685291666
At time: 569.6185748577118 and batch: 1600, loss is 3.8262630319595337 and perplexity is 45.8907252307682
At time: 570.6153852939606 and batch: 1650, loss is 3.7868374156951905 and perplexity is 44.116656770866655
At time: 571.6204183101654 and batch: 1700, loss is 3.7763420438766477 and perplexity is 43.65605736370374
At time: 572.6186189651489 and batch: 1750, loss is 3.7650928831100465 and perplexity is 43.167715225299695
At time: 573.6166007518768 and batch: 1800, loss is 3.730244083404541 and perplexity is 41.68928258430125
At time: 574.6145899295807 and batch: 1850, loss is 3.7565256690979005 and perplexity is 42.799467849942644
At time: 575.6211705207825 and batch: 1900, loss is 3.868128924369812 and perplexity is 47.85276611957914
At time: 576.6187477111816 and batch: 1950, loss is 3.802940859794617 and perplexity is 44.832837901771406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344729401344477 and perplexity of 77.07117929983363
finished 14 epochs...
Completing Train Step...
At time: 579.9062337875366 and batch: 50, loss is 3.9733795976638793 and perplexity is 53.163900163672956
At time: 580.9438905715942 and batch: 100, loss is 3.958475875854492 and perplexity is 52.377435369057444
At time: 581.9404520988464 and batch: 150, loss is 3.9103252506256103 and perplexity is 49.91518427839509
At time: 582.9422266483307 and batch: 200, loss is 3.912969126701355 and perplexity is 50.04732844935635
At time: 583.9399254322052 and batch: 250, loss is 3.9066928100585936 and perplexity is 49.734199245801754
At time: 584.9366755485535 and batch: 300, loss is 3.902740330696106 and perplexity is 49.53801381450928
At time: 585.9453432559967 and batch: 350, loss is 3.9243814897537233 and perplexity is 50.621758297848785
At time: 586.9444968700409 and batch: 400, loss is 3.8737783432006836 and perplexity is 48.123871510506646
At time: 587.9738974571228 and batch: 450, loss is 3.9196280574798585 and perplexity is 50.38170219541627
At time: 588.9731483459473 and batch: 500, loss is 3.9344918966293334 and perplexity is 51.136160898936886
At time: 589.974193572998 and batch: 550, loss is 3.9066951179504397 and perplexity is 49.734314027087116
At time: 590.9733798503876 and batch: 600, loss is 3.871028070449829 and perplexity is 47.991699575773296
At time: 591.9747531414032 and batch: 650, loss is 3.9000068712234497 and perplexity is 49.40278856196318
At time: 592.9732875823975 and batch: 700, loss is 3.938686852455139 and perplexity is 51.35112540306953
At time: 593.9734563827515 and batch: 750, loss is 3.895882682800293 and perplexity is 49.19946172060449
At time: 594.9812383651733 and batch: 800, loss is 3.896405930519104 and perplexity is 49.225211963006814
At time: 595.9794275760651 and batch: 850, loss is 3.8884154319763184 and perplexity is 48.83344526860841
At time: 596.9773852825165 and batch: 900, loss is 3.84732638835907 and perplexity is 46.8675898389843
At time: 597.9779071807861 and batch: 950, loss is 3.9462271118164063 and perplexity is 51.73978968035546
At time: 598.9803731441498 and batch: 1000, loss is 3.906335864067078 and perplexity is 49.716449990690904
At time: 599.9776995182037 and batch: 1050, loss is 3.863143253326416 and perplexity is 47.61478171812289
At time: 600.9754433631897 and batch: 1100, loss is 3.8783669900894164 and perplexity is 48.34520238003416
At time: 601.9735598564148 and batch: 1150, loss is 3.871752967834473 and perplexity is 48.02650124557615
At time: 602.9754090309143 and batch: 1200, loss is 3.904093918800354 and perplexity is 49.60511328299286
At time: 603.9746475219727 and batch: 1250, loss is 3.904619822502136 and perplexity is 49.631207656658134
At time: 604.9731292724609 and batch: 1300, loss is 3.8949529457092287 and perplexity is 49.1537404138733
At time: 605.9731872081757 and batch: 1350, loss is 3.7790649223327635 and perplexity is 43.77508948323258
At time: 606.9730799198151 and batch: 1400, loss is 3.7952111387252807 and perplexity is 44.487628475146046
At time: 607.9731040000916 and batch: 1450, loss is 3.720041890144348 and perplexity is 41.266122716242
At time: 608.9734721183777 and batch: 1500, loss is 3.7320631170272827 and perplexity is 41.76518580535609
At time: 609.9736204147339 and batch: 1550, loss is 3.7520260572433473 and perplexity is 42.607319477777416
At time: 610.9741480350494 and batch: 1600, loss is 3.8258266830444336 and perplexity is 45.87070523077089
At time: 611.9731612205505 and batch: 1650, loss is 3.786600031852722 and perplexity is 44.106185432278
At time: 612.9722013473511 and batch: 1700, loss is 3.7765766286849978 and perplexity is 43.666299612844774
At time: 613.9724869728088 and batch: 1750, loss is 3.765826826095581 and perplexity is 43.199409496562154
At time: 614.9719800949097 and batch: 1800, loss is 3.7312619352340697 and perplexity is 41.73173769969449
At time: 615.9742426872253 and batch: 1850, loss is 3.7577591800689696 and perplexity is 42.85229403723412
At time: 616.9722321033478 and batch: 1900, loss is 3.869603085517883 and perplexity is 47.92336082942521
At time: 617.9736378192902 and batch: 1950, loss is 3.803900089263916 and perplexity is 44.87586351349738
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34446538880814 and perplexity of 77.05083422810337
finished 15 epochs...
Completing Train Step...
At time: 621.3814609050751 and batch: 50, loss is 3.969370551109314 and perplexity is 52.95119027970565
At time: 622.3751542568207 and batch: 100, loss is 3.9541420841217043 and perplexity is 52.15093363285447
At time: 623.3711240291595 and batch: 150, loss is 3.9055789279937745 and perplexity is 49.67883205523865
At time: 624.3700275421143 and batch: 200, loss is 3.9078564167022707 and perplexity is 49.79210397309133
At time: 625.3685762882233 and batch: 250, loss is 3.901095404624939 and perplexity is 49.45659442686726
At time: 626.3628196716309 and batch: 300, loss is 3.897271447181702 and perplexity is 49.267835647274325
At time: 627.357321023941 and batch: 350, loss is 3.9188264846801757 and perplexity is 50.3413337746102
At time: 628.351170539856 and batch: 400, loss is 3.868033995628357 and perplexity is 47.848223732321244
At time: 629.3553216457367 and batch: 450, loss is 3.914028453826904 and perplexity is 50.10037303276661
At time: 630.3602480888367 and batch: 500, loss is 3.928795795440674 and perplexity is 50.84571215010285
At time: 631.3600380420685 and batch: 550, loss is 3.9011073684692383 and perplexity is 49.457186121402025
At time: 632.3511600494385 and batch: 600, loss is 3.8658765172958374 and perplexity is 47.74510350619554
At time: 633.3505825996399 and batch: 650, loss is 3.8951797533035277 and perplexity is 49.16489011985857
At time: 634.3488929271698 and batch: 700, loss is 3.934126601219177 and perplexity is 51.11748450547558
At time: 635.3487343788147 and batch: 750, loss is 3.891621527671814 and perplexity is 48.99026121642139
At time: 636.348769903183 and batch: 800, loss is 3.8923648691177366 and perplexity is 49.02669124632821
At time: 637.3483102321625 and batch: 850, loss is 3.8844044399261475 and perplexity is 48.63796700081467
At time: 638.371896982193 and batch: 900, loss is 3.843542513847351 and perplexity is 46.69058385577427
At time: 639.3692359924316 and batch: 950, loss is 3.942730174064636 and perplexity is 51.55917484003552
At time: 640.3688931465149 and batch: 1000, loss is 3.902884850502014 and perplexity is 49.54517355600057
At time: 641.3688986301422 and batch: 1050, loss is 3.859912486076355 and perplexity is 47.46119767147389
At time: 642.3678729534149 and batch: 1100, loss is 3.8753746509552003 and perplexity is 48.20075336700223
At time: 643.3679518699646 and batch: 1150, loss is 3.8689326429367066 and perplexity is 47.891241735899165
At time: 644.3673882484436 and batch: 1200, loss is 3.901534423828125 and perplexity is 49.478311588321475
At time: 645.3626420497894 and batch: 1250, loss is 3.902202229499817 and perplexity is 49.511364520665374
At time: 646.3557262420654 and batch: 1300, loss is 3.8926113414764405 and perplexity is 49.0387764598335
At time: 647.3502466678619 and batch: 1350, loss is 3.7766508531570433 and perplexity is 43.66954084116747
At time: 648.3488626480103 and batch: 1400, loss is 3.7929330492019653 and perplexity is 44.38639702573184
At time: 649.3507463932037 and batch: 1450, loss is 3.7180593156814576 and perplexity is 41.18439060193495
At time: 650.3514087200165 and batch: 1500, loss is 3.730475721359253 and perplexity is 41.69894052298189
At time: 651.3489947319031 and batch: 1550, loss is 3.750536904335022 and perplexity is 42.54391788311217
At time: 652.3487775325775 and batch: 1600, loss is 3.824696626663208 and perplexity is 45.818898025658164
At time: 653.3479382991791 and batch: 1650, loss is 3.7855909633636475 and perplexity is 44.061701717716836
At time: 654.3522062301636 and batch: 1700, loss is 3.7758891010284423 and perplexity is 43.636288142241725
At time: 655.3495650291443 and batch: 1750, loss is 3.765512375831604 and perplexity is 43.18582756637498
At time: 656.3511538505554 and batch: 1800, loss is 3.731121845245361 and perplexity is 41.72589191050919
At time: 657.3496162891388 and batch: 1850, loss is 3.757800273895264 and perplexity is 42.85405503814448
At time: 658.3487501144409 and batch: 1900, loss is 3.8698643255233764 and perplexity is 47.93588196391096
At time: 659.3471369743347 and batch: 1950, loss is 3.8038132095336916 and perplexity is 44.871964879940315
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344537495457849 and perplexity of 77.05639030592951
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 662.6314556598663 and batch: 50, loss is 3.9711271286010743 and perplexity is 53.04428488872286
At time: 663.6570210456848 and batch: 100, loss is 3.9649103307724 and perplexity is 52.71554221575645
At time: 664.6494193077087 and batch: 150, loss is 3.9205971002578734 and perplexity is 50.43054788303089
At time: 665.6484534740448 and batch: 200, loss is 3.9227447509765625 and perplexity is 50.53897147176045
At time: 666.6436502933502 and batch: 250, loss is 3.9162703704833985 and perplexity is 50.21281989471346
At time: 667.6408383846283 and batch: 300, loss is 3.913590922355652 and perplexity is 50.07845733759609
At time: 668.6341648101807 and batch: 350, loss is 3.937575521469116 and perplexity is 51.294089005270315
At time: 669.6289989948273 and batch: 400, loss is 3.890603895187378 and perplexity is 48.940432493150404
At time: 670.6304311752319 and batch: 450, loss is 3.9399773359298704 and perplexity is 51.41743595894682
At time: 671.631462097168 and batch: 500, loss is 3.955874891281128 and perplexity is 52.2413794840021
At time: 672.6351599693298 and batch: 550, loss is 3.930082049369812 and perplexity is 50.91115472599831
At time: 673.6304309368134 and batch: 600, loss is 3.888913187980652 and perplexity is 48.85775845971959
At time: 674.6287066936493 and batch: 650, loss is 3.917001414299011 and perplexity is 50.2495410869268
At time: 675.6282367706299 and batch: 700, loss is 3.9515690660476683 and perplexity is 52.01692082066834
At time: 676.62815284729 and batch: 750, loss is 3.907098250389099 and perplexity is 49.75436758423403
At time: 677.6276528835297 and batch: 800, loss is 3.906807293891907 and perplexity is 49.73989333351246
At time: 678.6261565685272 and batch: 850, loss is 3.8977136993408203 and perplexity is 49.28962927274818
At time: 679.6293354034424 and batch: 900, loss is 3.8507055377960206 and perplexity is 47.0262303127788
At time: 680.6332104206085 and batch: 950, loss is 3.953240628242493 and perplexity is 52.10394305027536
At time: 681.6294617652893 and batch: 1000, loss is 3.911803059577942 and perplexity is 49.989003916805565
At time: 682.6306610107422 and batch: 1050, loss is 3.865503177642822 and perplexity is 47.72728169282118
At time: 683.6285035610199 and batch: 1100, loss is 3.8775107717514037 and perplexity is 48.30382604731664
At time: 684.6261763572693 and batch: 1150, loss is 3.873482174873352 and perplexity is 48.10962085437731
At time: 685.625415802002 and batch: 1200, loss is 3.9066991090774534 and perplexity is 49.73451252344746
At time: 686.6254343986511 and batch: 1250, loss is 3.9068827772140504 and perplexity is 49.74364800761019
At time: 687.6278014183044 and batch: 1300, loss is 3.8946836233139037 and perplexity is 49.14050399327812
At time: 688.628317117691 and batch: 1350, loss is 3.7776287317276003 and perplexity is 43.71226523557238
At time: 689.6271314620972 and batch: 1400, loss is 3.797237138748169 and perplexity is 44.57785177679909
At time: 690.6262514591217 and batch: 1450, loss is 3.7218387842178347 and perplexity is 41.340340228120574
At time: 691.625072479248 and batch: 1500, loss is 3.7269540309906004 and perplexity is 41.55234804392689
At time: 692.6244373321533 and batch: 1550, loss is 3.751293420791626 and perplexity is 42.57611523449666
At time: 693.6288316249847 and batch: 1600, loss is 3.825019760131836 and perplexity is 45.83370603745917
At time: 694.6311490535736 and batch: 1650, loss is 3.782990369796753 and perplexity is 43.94726400716626
At time: 695.6328155994415 and batch: 1700, loss is 3.7694507741928103 and perplexity is 43.35624592630486
At time: 696.6299998760223 and batch: 1750, loss is 3.7580556869506836 and perplexity is 42.86500192120781
At time: 697.6322402954102 and batch: 1800, loss is 3.7238202238082887 and perplexity is 41.42233482177184
At time: 698.6296668052673 and batch: 1850, loss is 3.7494763469696046 and perplexity is 42.498821535506295
At time: 699.6337530612946 and batch: 1900, loss is 3.8601682329177858 and perplexity is 47.47333727513536
At time: 700.6380927562714 and batch: 1950, loss is 3.803105845451355 and perplexity is 44.84023528719054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338588980741279 and perplexity of 76.59937984850696
finished 17 epochs...
Completing Train Step...
At time: 703.9326608181 and batch: 50, loss is 3.9754831552505494 and perplexity is 53.27585119563902
At time: 704.9310290813446 and batch: 100, loss is 3.9611740732192993 and perplexity is 52.5189508596516
At time: 705.9296119213104 and batch: 150, loss is 3.913719744682312 and perplexity is 50.08490897653453
At time: 706.9282133579254 and batch: 200, loss is 3.912357392311096 and perplexity is 50.0167221398238
At time: 707.9270651340485 and batch: 250, loss is 3.9056879568099974 and perplexity is 49.68424877477286
At time: 708.9267227649689 and batch: 300, loss is 3.9036634016036986 and perplexity is 49.58376202505413
At time: 709.929098367691 and batch: 350, loss is 3.9273849725723267 and perplexity is 50.7740284350464
At time: 710.9324882030487 and batch: 400, loss is 3.879502034187317 and perplexity is 48.4001074706123
At time: 711.93488073349 and batch: 450, loss is 3.9283241701126097 and perplexity is 50.82173767835784
At time: 712.9351851940155 and batch: 500, loss is 3.944618234634399 and perplexity is 51.65661364129422
At time: 713.9329741001129 and batch: 550, loss is 3.9168578433990477 and perplexity is 50.24232723295235
At time: 714.9896461963654 and batch: 600, loss is 3.877844562530518 and perplexity is 48.319952110262996
At time: 715.9871454238892 and batch: 650, loss is 3.9051308012008668 and perplexity is 49.656574627001774
At time: 716.9862127304077 and batch: 700, loss is 3.94198778629303 and perplexity is 51.520912143756426
At time: 717.9866988658905 and batch: 750, loss is 3.898507194519043 and perplexity is 49.32875587724554
At time: 718.9846334457397 and batch: 800, loss is 3.899059147834778 and perplexity is 49.35599056305921
At time: 719.9862668514252 and batch: 850, loss is 3.8908256769180296 and perplexity is 48.95128779067641
At time: 720.9858613014221 and batch: 900, loss is 3.845895791053772 and perplexity is 46.800589128199995
At time: 721.9866471290588 and batch: 950, loss is 3.948696093559265 and perplexity is 51.867692105859284
At time: 722.986921787262 and batch: 1000, loss is 3.9078385829925537 and perplexity is 49.7912160030808
At time: 723.985312461853 and batch: 1050, loss is 3.861836061477661 and perplexity is 47.55258072675234
At time: 724.985021352768 and batch: 1100, loss is 3.8738748359680177 and perplexity is 48.12851534008791
At time: 725.9864699840546 and batch: 1150, loss is 3.8695923280715943 and perplexity is 47.922845299218004
At time: 726.9857151508331 and batch: 1200, loss is 3.903307819366455 and perplexity is 49.56613405430468
At time: 727.9864776134491 and batch: 1250, loss is 3.903418116569519 and perplexity is 49.5716013617664
At time: 728.9851613044739 and batch: 1300, loss is 3.8917207956314086 and perplexity is 48.99512462107848
At time: 729.9866390228271 and batch: 1350, loss is 3.775584969520569 and perplexity is 43.623018990016945
At time: 730.9860742092133 and batch: 1400, loss is 3.796231164932251 and perplexity is 44.53303017360126
At time: 731.9844534397125 and batch: 1450, loss is 3.721664266586304 and perplexity is 41.33312623935971
At time: 732.9872784614563 and batch: 1500, loss is 3.7287031412124634 and perplexity is 41.62509128005607
At time: 733.9853029251099 and batch: 1550, loss is 3.753921375274658 and perplexity is 42.68815047467546
At time: 734.9861538410187 and batch: 1600, loss is 3.827148742675781 and perplexity is 45.93138914345472
At time: 735.9839124679565 and batch: 1650, loss is 3.785590982437134 and perplexity is 44.06170255812711
At time: 736.9843814373016 and batch: 1700, loss is 3.7729241609573365 and perplexity is 43.50710077401593
At time: 737.9850656986237 and batch: 1750, loss is 3.761734251976013 and perplexity is 43.02297399522137
At time: 738.9845049381256 and batch: 1800, loss is 3.7273093366622927 and perplexity is 41.56711445199795
At time: 739.9845216274261 and batch: 1850, loss is 3.753266773223877 and perplexity is 42.66021586785365
At time: 740.9845583438873 and batch: 1900, loss is 3.864510598182678 and perplexity is 47.67993207634022
At time: 741.986353635788 and batch: 1950, loss is 3.8077808952331544 and perplexity is 45.05035640001505
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337400640443314 and perplexity of 76.50840778222556
finished 18 epochs...
Completing Train Step...
At time: 745.3814265727997 and batch: 50, loss is 3.9754654216766356 and perplexity is 53.27490643277106
At time: 746.4041774272919 and batch: 100, loss is 3.958891625404358 and perplexity is 52.39921579152196
At time: 747.4014678001404 and batch: 150, loss is 3.910641222000122 and perplexity is 49.930958539756816
At time: 748.4019658565521 and batch: 200, loss is 3.908479471206665 and perplexity is 49.82313683433312
At time: 749.4017226696014 and batch: 250, loss is 3.9018776416778564 and perplexity is 49.49529634260186
At time: 750.3978958129883 and batch: 300, loss is 3.900079197883606 and perplexity is 49.40636182988197
At time: 751.3923749923706 and batch: 350, loss is 3.9237070751190184 and perplexity is 50.587629752906885
At time: 752.3866040706635 and batch: 400, loss is 3.875517935752869 and perplexity is 48.20766029701311
At time: 753.3833041191101 and batch: 450, loss is 3.92416597366333 and perplexity is 50.610849669946234
At time: 754.3806083202362 and batch: 500, loss is 3.9404812049865723 and perplexity is 51.44335014203071
At time: 755.38343501091 and batch: 550, loss is 3.9122829246520996 and perplexity is 50.01299765029409
At time: 756.3823351860046 and batch: 600, loss is 3.873850355148315 and perplexity is 48.12733712900316
At time: 757.3825168609619 and batch: 650, loss is 3.8995666551589965 and perplexity is 49.381045446994804
At time: 758.3808352947235 and batch: 700, loss is 3.9383271169662475 and perplexity is 51.332655903134
At time: 759.3783674240112 and batch: 750, loss is 3.8951335334777832 and perplexity is 49.162617779718474
At time: 760.3721449375153 and batch: 800, loss is 3.8959537172317504 and perplexity is 49.20295670052631
At time: 761.3651556968689 and batch: 850, loss is 3.887840986251831 and perplexity is 48.80540116044207
At time: 762.3688311576843 and batch: 900, loss is 3.8436482095718385 and perplexity is 46.69551911167478
At time: 763.3634870052338 and batch: 950, loss is 3.946594696044922 and perplexity is 51.75881190694973
At time: 764.3623757362366 and batch: 1000, loss is 3.905928540229797 and perplexity is 49.69620341924024
At time: 765.3876543045044 and batch: 1050, loss is 3.860116233825684 and perplexity is 47.4708687688786
At time: 766.382833480835 and batch: 1100, loss is 3.872289319038391 and perplexity is 48.05226722652897
At time: 767.38747215271 and batch: 1150, loss is 3.8680404233932495 and perplexity is 47.84853129044237
At time: 768.3829123973846 and batch: 1200, loss is 3.9019998359680175 and perplexity is 49.50134475473794
At time: 769.3826878070831 and batch: 1250, loss is 3.9022144412994386 and perplexity is 49.51196914721968
At time: 770.3818938732147 and batch: 1300, loss is 3.8907144260406494 and perplexity is 48.94584221987869
At time: 771.383759021759 and batch: 1350, loss is 3.7748201179504393 and perplexity is 43.58966661188394
At time: 772.3841831684113 and batch: 1400, loss is 3.795784797668457 and perplexity is 44.513156522577795
At time: 773.3804361820221 and batch: 1450, loss is 3.7215616416931154 and perplexity is 41.32888464934434
At time: 774.379522562027 and batch: 1500, loss is 3.7293545818328857 and perplexity is 41.65221638958451
At time: 775.3771657943726 and batch: 1550, loss is 3.7548654317855834 and perplexity is 42.72846952980919
At time: 776.3730239868164 and batch: 1600, loss is 3.8280709981918335 and perplexity is 45.97376916005039
At time: 777.366760969162 and batch: 1650, loss is 3.786666178703308 and perplexity is 44.10910301402906
At time: 778.3670210838318 and batch: 1700, loss is 3.774259853363037 and perplexity is 43.565251705347045
At time: 779.3641562461853 and batch: 1750, loss is 3.763207783699036 and perplexity is 43.08641644297243
At time: 780.3621950149536 and batch: 1800, loss is 3.7287457466125487 and perplexity is 41.62686477150353
At time: 781.3616869449615 and batch: 1850, loss is 3.7547679138183594 and perplexity is 42.72430293948006
At time: 782.3607804775238 and batch: 1900, loss is 3.866045756340027 and perplexity is 47.75318452567037
At time: 783.3656890392303 and batch: 1950, loss is 3.8092233419418333 and perplexity is 45.115386027940104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336922011264535 and perplexity of 76.47179738793942
finished 19 epochs...
Completing Train Step...
At time: 786.7306034564972 and batch: 50, loss is 3.9743961572647093 and perplexity is 53.217971915724796
At time: 787.7335615158081 and batch: 100, loss is 3.956982126235962 and perplexity is 52.29925500044015
At time: 788.7342915534973 and batch: 150, loss is 3.9084595155715944 and perplexity is 49.82214259191679
At time: 789.7369983196259 and batch: 200, loss is 3.9060792112350464 and perplexity is 49.70369176029026
At time: 790.7471430301666 and batch: 250, loss is 3.89942186832428 and perplexity is 49.3738962392976
At time: 791.7837996482849 and batch: 300, loss is 3.897714638710022 and perplexity is 49.28967557392962
At time: 792.7803192138672 and batch: 350, loss is 3.9213383293151853 and perplexity is 50.46794232771033
At time: 793.7783889770508 and batch: 400, loss is 3.873021559715271 and perplexity is 48.08746593659945
At time: 794.7720332145691 and batch: 450, loss is 3.921649169921875 and perplexity is 50.48363225192832
At time: 795.770498752594 and batch: 500, loss is 3.9379297637939454 and perplexity is 51.3122627613763
At time: 796.7643620967865 and batch: 550, loss is 3.909613699913025 and perplexity is 49.87967972659555
At time: 797.7599000930786 and batch: 600, loss is 3.871422333717346 and perplexity is 48.01062467055145
At time: 798.7581865787506 and batch: 650, loss is 3.8969902658462523 and perplexity is 49.25398439889984
At time: 799.7497172355652 and batch: 700, loss is 3.9361400318145754 and perplexity is 51.220509694968506
At time: 800.741694688797 and batch: 750, loss is 3.8930376625061034 and perplexity is 49.05968717853012
At time: 801.7384793758392 and batch: 800, loss is 3.8940139484405516 and perplexity is 49.107606848914884
At time: 802.73703789711 and batch: 850, loss is 3.8859330701828 and perplexity is 48.71237332418394
At time: 803.7314293384552 and batch: 900, loss is 3.84210298538208 and perplexity is 46.62341978514787
At time: 804.7234380245209 and batch: 950, loss is 3.9451475048065188 and perplexity is 51.683961182567806
At time: 805.7202024459839 and batch: 1000, loss is 3.9045848178863527 and perplexity is 49.62947036571003
At time: 806.7167053222656 and batch: 1050, loss is 3.8589130735397337 and perplexity is 47.41378805034896
At time: 807.7126233577728 and batch: 1100, loss is 3.8711860942840577 and perplexity is 47.99928400739611
At time: 808.7090077400208 and batch: 1150, loss is 3.8670194244384763 and perplexity is 47.79970292110614
At time: 809.704341173172 and batch: 1200, loss is 3.9011047792434694 and perplexity is 49.45705806574704
At time: 810.7059180736542 and batch: 1250, loss is 3.9014293003082274 and perplexity is 49.473110527430435
At time: 811.7003071308136 and batch: 1300, loss is 3.8900739192962646 and perplexity is 48.914502115672754
At time: 812.6983978748322 and batch: 1350, loss is 3.774228868484497 and perplexity is 43.56390186222687
At time: 813.6963016986847 and batch: 1400, loss is 3.7953389739990233 and perplexity is 44.49331592683105
At time: 814.6936240196228 and batch: 1450, loss is 3.7212829208374023 and perplexity is 41.31736703242379
At time: 815.68408036232 and batch: 1500, loss is 3.729470481872559 and perplexity is 41.65704416288069
At time: 816.678689956665 and batch: 1550, loss is 3.755112648010254 and perplexity is 42.73903400653352
At time: 817.6768352985382 and batch: 1600, loss is 3.8283947038650514 and perplexity is 45.98865353889567
At time: 818.6752090454102 and batch: 1650, loss is 3.78704665184021 and perplexity is 44.12588853583631
At time: 819.6720147132874 and batch: 1700, loss is 3.7747637367248537 and perplexity is 43.58720904233854
At time: 820.667778968811 and batch: 1750, loss is 3.763853497505188 and perplexity is 43.1142469212223
At time: 821.6614234447479 and batch: 1800, loss is 3.7293989133834837 and perplexity is 41.65406293785277
At time: 822.6600902080536 and batch: 1850, loss is 3.755432405471802 and perplexity is 42.75270231671208
At time: 823.6580212116241 and batch: 1900, loss is 3.8666365242004392 and perplexity is 47.78140390705153
At time: 824.6586401462555 and batch: 1950, loss is 3.809678626060486 and perplexity is 45.13593102325567
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3366878065952035 and perplexity of 76.4538894330642
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fcae8787b38>
ELAPSED
5101.814687252045


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.42392198682246}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.7974071334468391, 'wordvec_source': 'gigavec', 'dropout': 0.589069126925909, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.51251288675175}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.014077492312028927, 'wordvec_source': 'gigavec', 'dropout': 0.3289390596927714, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -77.08629938542906}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5708626383639636, 'wordvec_source': 'gigavec', 'dropout': 0.49301208999077983, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.32988623121379}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.4614530027327207, 'wordvec_source': 'gigavec', 'dropout': 0.04151275008878008, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.98421438857322}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5891111345668675, 'wordvec_source': 'gigavec', 'dropout': 0.49737964351637065, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.4538894330642}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.12068322203302329, 'wordvec_source': 'gigavec', 'dropout': 0.5541179785005527, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.42392198682246}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.7974071334468391, 'wordvec_source': 'gigavec', 'dropout': 0.589069126925909, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.51251288675175}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.014077492312028927, 'wordvec_source': 'gigavec', 'dropout': 0.3289390596927714, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -77.08629938542906}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5708626383639636, 'wordvec_source': 'gigavec', 'dropout': 0.49301208999077983, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.32988623121379}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.4614530027327207, 'wordvec_source': 'gigavec', 'dropout': 0.04151275008878008, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.98421438857322}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'seq_len': 35, 'rnn_dropout': 0.5891111345668675, 'wordvec_source': 'gigavec', 'dropout': 0.49737964351637065, 'batch_size': 32, 'tune_wordvecs': 'TRUE', 'num_layers': 1, 'tie_weights': 'FALSE'}, 'best_accuracy': -76.4538894330642}]
Exception ignored in: <bound method DropoutDescriptor.__del__ of <torch.backends.cudnn.DropoutDescriptor object at 0x7fcae0190208>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 215, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroyDropoutDescriptor'
Exception ignored in: <bound method CuDNNHandle.__del__ of <torch.backends.cudnn.CuDNNHandle object at 0x7fcae01902b0>>
Traceback (most recent call last):
  File "/home-nfs/siddsach/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py", line 91, in __del__
AttributeError: 'NoneType' object has no attribute 'cudnnDestroy'
