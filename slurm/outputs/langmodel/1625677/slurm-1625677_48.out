TRUE
FALSE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.4631025791168213 and batch: 50, loss is 7.666082544326782 and perplexity is 2134.7024415852884
At time: 4.063328504562378 and batch: 100, loss is 7.04394154548645 and perplexity is 1145.8953156323078
At time: 5.667116403579712 and batch: 150, loss is 6.741086254119873 and perplexity is 846.4797287234907
At time: 7.272048473358154 and batch: 200, loss is 6.458200225830078 and perplexity is 637.9119253854349
At time: 8.878843307495117 and batch: 250, loss is 6.317685813903808 and perplexity is 554.2887796836469
At time: 10.490549325942993 and batch: 300, loss is 6.232965011596679 and perplexity is 509.2632185139647
At time: 12.100813150405884 and batch: 350, loss is 6.164508686065674 and perplexity is 475.5674326211464
At time: 13.709754705429077 and batch: 400, loss is 6.102129573822022 and perplexity is 446.80826883744675
At time: 15.317895650863647 and batch: 450, loss is 5.995601091384888 and perplexity is 401.65804463405067
At time: 16.923572540283203 and batch: 500, loss is 5.9645891284942625 and perplexity is 389.3930047084034
At time: 18.527517795562744 and batch: 550, loss is 5.903979291915894 and perplexity is 366.4929524886972
At time: 20.132473707199097 and batch: 600, loss is 5.928790798187256 and perplexity is 375.6999419946794
At time: 21.737123489379883 and batch: 650, loss is 5.987441339492798 and perplexity is 398.39394985682964
At time: 23.342531204223633 and batch: 700, loss is 5.901669950485229 and perplexity is 365.6475716416812
At time: 24.94870138168335 and batch: 750, loss is 5.824507942199707 and perplexity is 338.4945332174821
At time: 26.557777404785156 and batch: 800, loss is 5.827433271408081 and perplexity is 339.4861909178158
At time: 28.16575050354004 and batch: 850, loss is 5.853487215042114 and perplexity is 348.4473751909471
At time: 29.78228449821472 and batch: 900, loss is 5.830509004592895 and perplexity is 340.53196730113893
At time: 31.400815963745117 and batch: 950, loss is 5.83647798538208 and perplexity is 342.57067452113586
At time: 33.01664400100708 and batch: 1000, loss is 5.809028806686402 and perplexity is 333.29527429702557
At time: 34.63524103164673 and batch: 1050, loss is 5.7059500026702885 and perplexity is 300.65096364032763
At time: 36.259551763534546 and batch: 1100, loss is 5.779226999282837 and perplexity is 323.50902103387557
At time: 37.87741255760193 and batch: 1150, loss is 5.676593036651611 and perplexity is 291.95306021318515
At time: 39.49358010292053 and batch: 1200, loss is 5.74471640586853 and perplexity is 312.5349821741311
At time: 41.11419868469238 and batch: 1250, loss is 5.690039081573486 and perplexity is 295.90518485473547
At time: 42.74034285545349 and batch: 1300, loss is 5.701161870956421 and perplexity is 299.21484812535965
At time: 44.36234521865845 and batch: 1350, loss is 5.665895042419433 and perplexity is 288.8463952299985
At time: 45.98214340209961 and batch: 1400, loss is 5.666031293869018 and perplexity is 288.88575365131607
At time: 47.59838390350342 and batch: 1450, loss is 5.632349443435669 and perplexity is 279.3175882100947
At time: 49.217949867248535 and batch: 1500, loss is 5.593702526092529 and perplexity is 268.72875525210924
At time: 50.84331488609314 and batch: 1550, loss is 5.574610567092895 and perplexity is 263.6468628780073
At time: 52.4655966758728 and batch: 1600, loss is 5.593312425613403 and perplexity is 268.62394448062577
At time: 54.084805965423584 and batch: 1650, loss is 5.587688770294189 and perplexity is 267.1175357382229
At time: 55.703608989715576 and batch: 1700, loss is 5.603196964263916 and perplexity is 271.2923344180145
At time: 57.32741928100586 and batch: 1750, loss is 5.597613582611084 and perplexity is 269.7818265704367
At time: 58.95297193527222 and batch: 1800, loss is 5.594510955810547 and perplexity is 268.9460914026056
At time: 60.572399854660034 and batch: 1850, loss is 5.561677579879761 and perplexity is 260.25907569635825
At time: 62.191527366638184 and batch: 1900, loss is 5.572050123214722 and perplexity is 262.97267336248564
At time: 63.81033396720886 and batch: 1950, loss is 5.508755359649658 and perplexity is 246.84370415740878
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.037552802507268 and perplexity of 154.09245855846243
finished 1 epochs...
Completing Train Step...
At time: 68.25248718261719 and batch: 50, loss is 5.326318712234497 and perplexity is 205.67941366410088
At time: 69.60518836975098 and batch: 100, loss is 5.257229375839233 and perplexity is 191.94893552357786
At time: 70.95694780349731 and batch: 150, loss is 5.1642128849029545 and perplexity is 174.89973815362785
At time: 72.31782913208008 and batch: 200, loss is 5.114364671707153 and perplexity is 166.395031922621
At time: 73.68214273452759 and batch: 250, loss is 5.138350038528443 and perplexity is 170.4343261292413
At time: 75.0411446094513 and batch: 300, loss is 5.13319959640503 and perplexity is 169.55877068099213
At time: 76.42958927154541 and batch: 350, loss is 5.114653272628784 and perplexity is 166.44306061241738
At time: 77.78370141983032 and batch: 400, loss is 5.060182638168335 and perplexity is 157.6193009951251
At time: 79.13810086250305 and batch: 450, loss is 5.0177319145202635 and perplexity is 151.0682791660877
At time: 80.49474024772644 and batch: 500, loss is 5.015620250701904 and perplexity is 150.74961032601595
At time: 81.85643792152405 and batch: 550, loss is 4.972695264816284 and perplexity is 144.4156015816009
At time: 83.21498203277588 and batch: 600, loss is 4.948892393112183 and perplexity is 141.0186841233174
At time: 84.57156348228455 and batch: 650, loss is 5.015157098770142 and perplexity is 150.67980651891293
At time: 85.92638897895813 and batch: 700, loss is 5.01395037651062 and perplexity is 150.49808750656604
At time: 87.28293466567993 and batch: 750, loss is 4.950090837478638 and perplexity is 141.1877884817128
At time: 88.64139151573181 and batch: 800, loss is 4.955279331207276 and perplexity is 141.92224414846416
At time: 90.00247716903687 and batch: 850, loss is 4.94806544303894 and perplexity is 140.90211691642608
At time: 91.36131286621094 and batch: 900, loss is 4.941187763214112 and perplexity is 139.9363621525419
At time: 92.7165424823761 and batch: 950, loss is 4.979870777130127 and perplexity is 145.45558425107308
At time: 94.07485580444336 and batch: 1000, loss is 4.9418492603302 and perplexity is 140.02896027586095
At time: 95.43089199066162 and batch: 1050, loss is 4.865646324157715 and perplexity is 129.75477516186274
At time: 96.78830003738403 and batch: 1100, loss is 4.924101400375366 and perplexity is 137.56566962627798
At time: 98.14681577682495 and batch: 1150, loss is 4.839129066467285 and perplexity is 126.35925328200682
At time: 99.50206398963928 and batch: 1200, loss is 4.923454151153565 and perplexity is 137.47665916274988
At time: 100.85664224624634 and batch: 1250, loss is 4.8906028366088865 and perplexity is 133.03374749631905
At time: 102.21023344993591 and batch: 1300, loss is 4.8975405025482175 and perplexity is 133.95990014922896
At time: 103.56614661216736 and batch: 1350, loss is 4.8082942771911625 and perplexity is 122.52244983965403
At time: 104.92594814300537 and batch: 1400, loss is 4.8072202777862545 and perplexity is 122.39093143942209
At time: 106.28408598899841 and batch: 1450, loss is 4.766280717849732 and perplexity is 117.48148161063148
At time: 107.63896417617798 and batch: 1500, loss is 4.7341298007965085 and perplexity is 113.76441792598584
At time: 108.99167251586914 and batch: 1550, loss is 4.7315766143798825 and perplexity is 113.47432664558649
At time: 110.34549045562744 and batch: 1600, loss is 4.782686290740966 and perplexity is 119.42472908050786
At time: 111.70133399963379 and batch: 1650, loss is 4.7592790412902835 and perplexity is 116.66178724078281
At time: 113.06043076515198 and batch: 1700, loss is 4.7780192184448245 and perplexity is 118.86866384360347
At time: 114.42403268814087 and batch: 1750, loss is 4.766243562698365 and perplexity is 117.4771166494903
At time: 115.78630757331848 and batch: 1800, loss is 4.7231244945526125 and perplexity is 112.5192698523202
At time: 117.14669418334961 and batch: 1850, loss is 4.739500179290771 and perplexity is 114.37701938795223
At time: 118.50799083709717 and batch: 1900, loss is 4.839619846343994 and perplexity is 126.4212830809971
At time: 119.87236261367798 and batch: 1950, loss is 4.752629642486572 and perplexity is 115.8886298568857
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.601855184865553 and perplexity of 99.6690487427158
finished 2 epochs...
Completing Train Step...
At time: 124.21291971206665 and batch: 50, loss is 4.722091627120972 and perplexity is 112.40311236102916
At time: 125.57534146308899 and batch: 100, loss is 4.658711719512939 and perplexity is 105.50008087599531
At time: 126.93570327758789 and batch: 150, loss is 4.601506395339966 and perplexity is 99.6342912843602
At time: 128.29364323616028 and batch: 200, loss is 4.5892613506317135 and perplexity is 98.42170417613583
At time: 129.6561689376831 and batch: 250, loss is 4.5985275077819825 and perplexity is 99.33793356102296
At time: 131.02352380752563 and batch: 300, loss is 4.62100305557251 and perplexity is 101.5958873587374
At time: 132.3871352672577 and batch: 350, loss is 4.629400577545166 and perplexity is 102.45263329187476
At time: 133.74663424491882 and batch: 400, loss is 4.567507772445679 and perplexity is 96.30379946063678
At time: 135.1075623035431 and batch: 450, loss is 4.5708121490478515 and perplexity is 96.62254982786884
At time: 136.46940660476685 and batch: 500, loss is 4.577012987136841 and perplexity is 97.22355204809638
At time: 137.82826113700867 and batch: 550, loss is 4.546007051467895 and perplexity is 94.25529936840127
At time: 139.18622851371765 and batch: 600, loss is 4.520906190872193 and perplexity is 91.91885627704468
At time: 140.5401713848114 and batch: 650, loss is 4.57952260017395 and perplexity is 97.46785196273585
At time: 141.89536261558533 and batch: 700, loss is 4.607848224639892 and perplexity is 100.26816278005556
At time: 143.25068616867065 and batch: 750, loss is 4.556756525039673 and perplexity is 95.27395943878547
At time: 144.64981341362 and batch: 800, loss is 4.561467390060425 and perplexity is 95.72384103544272
At time: 146.01591396331787 and batch: 850, loss is 4.552533235549927 and perplexity is 94.87243839384539
At time: 147.37197494506836 and batch: 900, loss is 4.528982887268066 and perplexity is 92.6642631325912
At time: 148.72603631019592 and batch: 950, loss is 4.586896352767944 and perplexity is 98.18921208602379
At time: 150.08046126365662 and batch: 1000, loss is 4.5619237422943115 and perplexity is 95.76753479324911
At time: 151.43246698379517 and batch: 1050, loss is 4.496607151031494 and perplexity is 89.71223429666665
At time: 152.78947710990906 and batch: 1100, loss is 4.543990526199341 and perplexity is 94.06542268543676
At time: 154.1481237411499 and batch: 1150, loss is 4.490706691741943 and perplexity is 89.1844495279484
At time: 155.5046362876892 and batch: 1200, loss is 4.565757427215576 and perplexity is 96.13538200195632
At time: 156.8595039844513 and batch: 1250, loss is 4.557494258880615 and perplexity is 95.34427219568511
At time: 158.21412086486816 and batch: 1300, loss is 4.546057033538818 and perplexity is 94.26001056119577
At time: 159.56793999671936 and batch: 1350, loss is 4.433737668991089 and perplexity is 84.24571176380061
At time: 160.9262306690216 and batch: 1400, loss is 4.445698413848877 and perplexity is 85.25940339624452
At time: 162.2855453491211 and batch: 1450, loss is 4.403298034667968 and perplexity is 81.71993991282176
At time: 163.64094877243042 and batch: 1500, loss is 4.393483743667603 and perplexity is 80.92183944320972
At time: 164.9953920841217 and batch: 1550, loss is 4.398075475692749 and perplexity is 81.29426523026956
At time: 166.35035610198975 and batch: 1600, loss is 4.460345191955566 and perplexity is 86.51736904213645
At time: 167.70574069023132 and batch: 1650, loss is 4.432320337295533 and perplexity is 84.12639222396031
At time: 169.06591939926147 and batch: 1700, loss is 4.4453341579437256 and perplexity is 85.22835281061066
At time: 170.4249460697174 and batch: 1750, loss is 4.438446836471558 and perplexity is 84.64337452539111
At time: 171.77897667884827 and batch: 1800, loss is 4.395296831130981 and perplexity is 81.06869090285937
At time: 173.13278126716614 and batch: 1850, loss is 4.430809392929077 and perplexity is 83.9993779055077
At time: 174.48695397377014 and batch: 1900, loss is 4.541909351348877 and perplexity is 93.86985966445266
At time: 175.8435299396515 and batch: 1950, loss is 4.460555486679077 and perplexity is 86.53556510153861
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.491440316133721 and perplexity of 89.24990142110647
finished 3 epochs...
Completing Train Step...
At time: 180.14565896987915 and batch: 50, loss is 4.444509334564209 and perplexity is 85.15808345650176
At time: 181.51828360557556 and batch: 100, loss is 4.379891872406006 and perplexity is 79.82940117732262
At time: 182.8726954460144 and batch: 150, loss is 4.327001295089722 and perplexity is 75.7168931773828
At time: 184.2299952507019 and batch: 200, loss is 4.328177299499512 and perplexity is 75.80598895590103
At time: 185.58854484558105 and batch: 250, loss is 4.3299390411376955 and perplexity is 75.93965723298051
At time: 186.94572067260742 and batch: 300, loss is 4.358875741958618 and perplexity is 78.16920264867768
At time: 188.30017685890198 and batch: 350, loss is 4.369831771850586 and perplexity is 79.03033545411338
At time: 189.6548535823822 and batch: 400, loss is 4.310632524490356 and perplexity is 74.48758926715905
At time: 191.00970077514648 and batch: 450, loss is 4.32739149093628 and perplexity is 75.74644335941912
At time: 192.36913800239563 and batch: 500, loss is 4.332766170501709 and perplexity is 76.15465223397872
At time: 193.72614693641663 and batch: 550, loss is 4.298816032409668 and perplexity is 73.6125871674822
At time: 195.0814905166626 and batch: 600, loss is 4.282267332077026 and perplexity is 72.40441890126708
At time: 196.43424940109253 and batch: 650, loss is 4.336647138595581 and perplexity is 76.45078026953979
At time: 197.78858971595764 and batch: 700, loss is 4.371916074752807 and perplexity is 79.19523039747209
At time: 199.1464283466339 and batch: 750, loss is 4.327041206359863 and perplexity is 75.71991519506655
At time: 200.51598405838013 and batch: 800, loss is 4.327745018005371 and perplexity is 75.77322651153973
At time: 201.88138914108276 and batch: 850, loss is 4.322414970397949 and perplexity is 75.37042603333761
At time: 203.24103450775146 and batch: 900, loss is 4.288156423568726 and perplexity is 72.83207316013869
At time: 204.60022068023682 and batch: 950, loss is 4.364536256790161 and perplexity is 78.61293527237092
At time: 205.95618057250977 and batch: 1000, loss is 4.340756502151489 and perplexity is 76.76559071206648
At time: 207.31299471855164 and batch: 1050, loss is 4.285529298782349 and perplexity is 72.64098533118627
At time: 208.67117547988892 and batch: 1100, loss is 4.3167402458190915 and perplexity is 74.94393088996057
At time: 210.02838706970215 and batch: 1150, loss is 4.2801852750778195 and perplexity is 72.25382560043955
At time: 211.41208148002625 and batch: 1200, loss is 4.353061056137085 and perplexity is 77.71599220945464
At time: 212.767094373703 and batch: 1250, loss is 4.351322088241577 and perplexity is 77.58096403289412
At time: 214.12332820892334 and batch: 1300, loss is 4.327317695617676 and perplexity is 75.74085383274132
At time: 215.4889702796936 and batch: 1350, loss is 4.210740461349487 and perplexity is 67.40643319426279
At time: 216.8484649658203 and batch: 1400, loss is 4.23689567565918 and perplexity is 69.19272144487174
At time: 218.20316815376282 and batch: 1450, loss is 4.1895221328735355 and perplexity is 65.99124837619479
At time: 219.55801343917847 and batch: 1500, loss is 4.182301578521728 and perplexity is 65.51647112080279
At time: 220.91272687911987 and batch: 1550, loss is 4.190662975311279 and perplexity is 66.0665769537109
At time: 222.26725721359253 and batch: 1600, loss is 4.259239807128906 and perplexity is 70.75617466477274
At time: 223.62691259384155 and batch: 1650, loss is 4.225790777206421 and perplexity is 68.42859393136689
At time: 224.9841799736023 and batch: 1700, loss is 4.239544677734375 and perplexity is 69.37625609207313
At time: 226.33990836143494 and batch: 1750, loss is 4.239428915977478 and perplexity is 69.36822543961118
At time: 227.69491982460022 and batch: 1800, loss is 4.194200949668884 and perplexity is 66.3007327832791
At time: 229.05287098884583 and batch: 1850, loss is 4.23420223236084 and perplexity is 69.0066055318484
At time: 230.4091353416443 and batch: 1900, loss is 4.345920286178589 and perplexity is 77.16301687154088
At time: 231.76996541023254 and batch: 1950, loss is 4.266639261245728 and perplexity is 71.28167353741429
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.439407703488372 and perplexity of 84.72474463883295
finished 4 epochs...
Completing Train Step...
At time: 236.0690896511078 and batch: 50, loss is 4.259040012359619 and perplexity is 70.74203936330662
At time: 237.442524433136 and batch: 100, loss is 4.191942181587219 and perplexity is 66.15114381127553
At time: 238.79953622817993 and batch: 150, loss is 4.145926485061645 and perplexity is 63.17612653321222
At time: 240.15703320503235 and batch: 200, loss is 4.1496381664276125 and perplexity is 63.41105189918558
At time: 241.5128800868988 and batch: 250, loss is 4.151981983184815 and perplexity is 63.559850094952765
At time: 242.8676507472992 and batch: 300, loss is 4.175988135337829 and perplexity is 65.10413958823598
At time: 244.22151589393616 and batch: 350, loss is 4.193942122459411 and perplexity is 66.28357457022878
At time: 245.59461116790771 and batch: 400, loss is 4.131862306594849 and perplexity is 62.29382517995647
At time: 246.95306396484375 and batch: 450, loss is 4.157756724357605 and perplexity is 63.927953606536654
At time: 248.31215405464172 and batch: 500, loss is 4.16549889087677 and perplexity is 64.42481538001216
At time: 249.66738200187683 and batch: 550, loss is 4.128195996284485 and perplexity is 62.06585484678018
At time: 251.02207589149475 and batch: 600, loss is 4.11539469242096 and perplexity is 61.276394819115744
At time: 252.3758602142334 and batch: 650, loss is 4.168303170204163 and perplexity is 64.60573411272266
At time: 253.73194479942322 and batch: 700, loss is 4.207427935600281 and perplexity is 67.18351706019664
At time: 255.09134769439697 and batch: 750, loss is 4.162887692451477 and perplexity is 64.25680884819845
At time: 256.4490168094635 and batch: 800, loss is 4.162283024787903 and perplexity is 64.21796657823924
At time: 257.8039150238037 and batch: 850, loss is 4.159108319282532 and perplexity is 64.01441672258399
At time: 259.15859150886536 and batch: 900, loss is 4.1229129409790035 and perplexity is 61.7388221296499
At time: 260.5124659538269 and batch: 950, loss is 4.206182589530945 and perplexity is 67.099902406698
At time: 261.8678026199341 and batch: 1000, loss is 4.1824664831161495 and perplexity is 65.52727597876176
At time: 263.22582364082336 and batch: 1050, loss is 4.130769419670105 and perplexity is 62.2257822613056
At time: 264.5841734409332 and batch: 1100, loss is 4.154037442207336 and perplexity is 63.69062912172167
At time: 265.93793082237244 and batch: 1150, loss is 4.127388410568237 and perplexity is 62.01575158300237
At time: 267.2914996147156 and batch: 1200, loss is 4.199322719573974 and perplexity is 66.6411809855779
At time: 268.64506816864014 and batch: 1250, loss is 4.201107172966004 and perplexity is 66.76020523206283
At time: 270.00270414352417 and batch: 1300, loss is 4.17243923664093 and perplexity is 64.87350109048874
At time: 271.3625535964966 and batch: 1350, loss is 4.0503803157806395 and perplexity is 57.4192903556422
At time: 272.71796917915344 and batch: 1400, loss is 4.089161410331726 and perplexity is 59.68981544782848
At time: 274.072553396225 and batch: 1450, loss is 4.034482011795044 and perplexity is 56.51363925682197
At time: 275.42648935317993 and batch: 1500, loss is 4.031886386871338 and perplexity is 56.36714125541918
At time: 276.7823781967163 and batch: 1550, loss is 4.044950904846192 and perplexity is 57.10838222050979
At time: 278.1407220363617 and batch: 1600, loss is 4.114562544822693 and perplexity is 61.225425024473914
At time: 279.4995651245117 and batch: 1650, loss is 4.077241497039795 and perplexity is 58.982541718399744
At time: 280.8553509712219 and batch: 1700, loss is 4.086426248550415 and perplexity is 59.526777215495315
At time: 282.21068930625916 and batch: 1750, loss is 4.090811696052551 and perplexity is 59.788402023575266
At time: 283.57373237609863 and batch: 1800, loss is 4.0487684059143065 and perplexity is 57.32681018986983
At time: 284.93895196914673 and batch: 1850, loss is 4.089933671951294 and perplexity is 59.73592940510579
At time: 286.29981422424316 and batch: 1900, loss is 4.199659361839294 and perplexity is 66.66361900028862
At time: 287.6577978134155 and batch: 1950, loss is 4.122223715782166 and perplexity is 61.696284838385424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.424195471475291 and perplexity of 83.44564580671235
finished 5 epochs...
Completing Train Step...
At time: 291.9357500076294 and batch: 50, loss is 4.118138012886047 and perplexity is 61.44472639520936
At time: 293.31462693214417 and batch: 100, loss is 4.053504118919372 and perplexity is 57.59893735993178
At time: 294.6737117767334 and batch: 150, loss is 4.011476268768311 and perplexity is 55.228342288431854
At time: 296.0292065143585 and batch: 200, loss is 4.014319071769714 and perplexity is 55.385568961995716
At time: 297.38369846343994 and batch: 250, loss is 4.015974922180176 and perplexity is 55.47735515022188
At time: 298.7405581474304 and batch: 300, loss is 4.036215209960938 and perplexity is 56.611673524595396
At time: 300.09572768211365 and batch: 350, loss is 4.053932042121887 and perplexity is 57.623590556129415
At time: 301.45372247695923 and batch: 400, loss is 3.9992781496047973 and perplexity is 54.558752558217634
At time: 302.8121693134308 and batch: 450, loss is 4.025320143699646 and perplexity is 55.99823339387754
At time: 304.1695764064789 and batch: 500, loss is 4.0371830272674565 and perplexity is 56.666489803776585
At time: 305.52527117729187 and batch: 550, loss is 4.001379761695862 and perplexity is 54.67353446354028
At time: 306.87943816185 and batch: 600, loss is 3.9880733776092527 and perplexity is 53.950846261217805
At time: 308.23412466049194 and batch: 650, loss is 4.037963423728943 and perplexity is 56.71072939186809
At time: 309.5919394493103 and batch: 700, loss is 4.085421986579895 and perplexity is 59.467026744494795
At time: 310.9507734775543 and batch: 750, loss is 4.039726758003235 and perplexity is 56.81081758325997
At time: 312.30542254447937 and batch: 800, loss is 4.032681374549866 and perplexity is 56.41197025508127
At time: 313.6863520145416 and batch: 850, loss is 4.027900524139405 and perplexity is 56.14291672873226
At time: 315.04236483573914 and batch: 900, loss is 3.994490613937378 and perplexity is 54.29817484463827
At time: 316.39747428894043 and batch: 950, loss is 4.080850105285645 and perplexity is 59.195771104075334
At time: 317.7556140422821 and batch: 1000, loss is 4.060405430793762 and perplexity is 57.99782041530025
At time: 319.1143271923065 and batch: 1050, loss is 4.013539090156555 and perplexity is 55.342386079687365
At time: 320.47032856941223 and batch: 1100, loss is 4.032184529304504 and perplexity is 56.383949197519584
At time: 321.82496523857117 and batch: 1150, loss is 4.010008201599121 and perplexity is 55.14732285784374
At time: 323.1803545951843 and batch: 1200, loss is 4.076511101722717 and perplexity is 58.93947687523369
At time: 324.53545212745667 and batch: 1250, loss is 4.08056179523468 and perplexity is 59.17870682831073
At time: 325.8934214115143 and batch: 1300, loss is 4.052146210670471 and perplexity is 57.520776367501135
At time: 327.25281405448914 and batch: 1350, loss is 3.9272859144210814 and perplexity is 50.76899910276064
At time: 328.6083736419678 and batch: 1400, loss is 3.971424126625061 and perplexity is 53.060041276210754
At time: 329.96281361579895 and batch: 1450, loss is 3.9091773986816407 and perplexity is 49.857921907736504
At time: 331.3168342113495 and batch: 1500, loss is 3.9110667514801025 and perplexity is 49.95221015585307
At time: 332.6750957965851 and batch: 1550, loss is 3.928860912322998 and perplexity is 50.849023172158155
At time: 334.03464007377625 and batch: 1600, loss is 3.9997447538375854 and perplexity is 54.58421584327324
At time: 335.39456820487976 and batch: 1650, loss is 3.9601617813110352 and perplexity is 52.46581325058937
At time: 336.74888038635254 and batch: 1700, loss is 3.968267602920532 and perplexity is 52.8928200558764
At time: 338.1037902832031 and batch: 1750, loss is 3.974522433280945 and perplexity is 53.22469249352541
At time: 339.45922017097473 and batch: 1800, loss is 3.9341903162002563 and perplexity is 51.1207415587941
At time: 340.8172323703766 and batch: 1850, loss is 3.9747775983810425 and perplexity is 53.23827531036991
At time: 342.17704129219055 and batch: 1900, loss is 4.081263790130615 and perplexity is 59.220264563404555
At time: 343.53362560272217 and batch: 1950, loss is 4.005220937728882 and perplexity is 54.883948994673396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.42872683502907 and perplexity of 83.8246263657136
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 347.8172810077667 and batch: 50, loss is 4.0430233716964725 and perplexity is 56.998409942307916
At time: 349.17434787750244 and batch: 100, loss is 4.012321472167969 and perplexity is 55.275041203352316
At time: 350.53320026397705 and batch: 150, loss is 3.975484457015991 and perplexity is 53.27592054834612
At time: 351.8875319957733 and batch: 200, loss is 3.9762253522872926 and perplexity is 53.31540705183022
At time: 353.2414200305939 and batch: 250, loss is 3.977113437652588 and perplexity is 53.36277671561695
At time: 354.59827709198 and batch: 300, loss is 4.002891960144043 and perplexity is 54.75627424122729
At time: 355.95450711250305 and batch: 350, loss is 4.015111665725708 and perplexity is 55.42948463055203
At time: 357.31501364707947 and batch: 400, loss is 3.9590931129455567 and perplexity is 52.40977464437546
At time: 358.6733434200287 and batch: 450, loss is 3.976624779701233 and perplexity is 53.33670694058867
At time: 360.0381062030792 and batch: 500, loss is 3.9857687091827394 and perplexity is 53.82665061911549
At time: 361.4013161659241 and batch: 550, loss is 3.9517352199554443 and perplexity is 52.02556435339165
At time: 362.76221227645874 and batch: 600, loss is 3.92273211479187 and perplexity is 50.53833285601761
At time: 364.1285367012024 and batch: 650, loss is 3.963708734512329 and perplexity is 52.65223745837905
At time: 365.4993841648102 and batch: 700, loss is 4.007541899681091 and perplexity is 55.01148049270479
At time: 366.86509585380554 and batch: 750, loss is 3.9456708097457884 and perplexity is 51.7110147327465
At time: 368.22427105903625 and batch: 800, loss is 3.9408924770355225 and perplexity is 51.464511705329954
At time: 369.58167815208435 and batch: 850, loss is 3.933918309211731 and perplexity is 51.10683825081571
At time: 370.93752908706665 and batch: 900, loss is 3.8862962913513184 and perplexity is 48.73006990303552
At time: 372.29667115211487 and batch: 950, loss is 3.9865935182571413 and perplexity is 53.87106564343034
At time: 373.65622115135193 and batch: 1000, loss is 3.945981240272522 and perplexity is 51.727069902166335
At time: 375.0136344432831 and batch: 1050, loss is 3.892119460105896 and perplexity is 49.01466113068542
At time: 376.36961460113525 and batch: 1100, loss is 3.8997363662719726 and perplexity is 49.389426670350794
At time: 377.72606134414673 and batch: 1150, loss is 3.8810088634490967 and perplexity is 48.47309314348638
At time: 379.0833923816681 and batch: 1200, loss is 3.928315668106079 and perplexity is 50.82130559344899
At time: 380.4438455104828 and batch: 1250, loss is 3.929426727294922 and perplexity is 50.87780245188255
At time: 381.8004381656647 and batch: 1300, loss is 3.8992907333374025 and perplexity is 49.367422018569876
At time: 383.15573954582214 and batch: 1350, loss is 3.7703181409835818 and perplexity is 43.39386800790728
At time: 384.50985169410706 and batch: 1400, loss is 3.7964365482330322 and perplexity is 44.54217745364923
At time: 385.8670961856842 and batch: 1450, loss is 3.7296582078933715 and perplexity is 41.664865008085314
At time: 387.2286777496338 and batch: 1500, loss is 3.7181672763824465 and perplexity is 41.18883713763537
At time: 388.59648752212524 and batch: 1550, loss is 3.7342027378082276 and perplexity is 41.854643133076166
At time: 389.9613530635834 and batch: 1600, loss is 3.8111910009384156 and perplexity is 45.20424511666543
At time: 391.32094979286194 and batch: 1650, loss is 3.7673017311096193 and perplexity is 43.26317153214642
At time: 392.67674350738525 and batch: 1700, loss is 3.7543325090408324 and perplexity is 42.70570462305543
At time: 394.03362584114075 and batch: 1750, loss is 3.7415430688858033 and perplexity is 42.16300040851793
At time: 395.3932914733887 and batch: 1800, loss is 3.698288474082947 and perplexity is 40.37813695816514
At time: 396.7529981136322 and batch: 1850, loss is 3.7338664054870607 and perplexity is 41.840568430820916
At time: 398.1101989746094 and batch: 1900, loss is 3.8317229986190795 and perplexity is 46.141972336756325
At time: 399.46647357940674 and batch: 1950, loss is 3.76060595035553 and perplexity is 42.974458479159196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357136287245639 and perplexity of 78.03334905056576
finished 7 epochs...
Completing Train Step...
At time: 403.7884476184845 and batch: 50, loss is 3.955814437866211 and perplexity is 52.23822140967146
At time: 405.14731764793396 and batch: 100, loss is 3.9086387014389037 and perplexity is 49.83107081563019
At time: 406.50341749191284 and batch: 150, loss is 3.8642065858840944 and perplexity is 47.665438993742676
At time: 407.85939264297485 and batch: 200, loss is 3.8610154151916505 and perplexity is 47.51357288599772
At time: 409.2155306339264 and batch: 250, loss is 3.8615615224838256 and perplexity is 47.53952748097981
At time: 410.5733504295349 and batch: 300, loss is 3.8858212184906007 and perplexity is 48.70692506750063
At time: 411.934618473053 and batch: 350, loss is 3.900351185798645 and perplexity is 49.41980159086919
At time: 413.29500818252563 and batch: 400, loss is 3.8490262460708617 and perplexity is 46.9473258237196
At time: 414.6700236797333 and batch: 450, loss is 3.8731367921829225 and perplexity is 48.093007493239924
At time: 416.02783608436584 and batch: 500, loss is 3.883465790748596 and perplexity is 48.59233443292817
At time: 417.3837401866913 and batch: 550, loss is 3.8541472339630127 and perplexity is 47.1883591484522
At time: 418.7414803504944 and batch: 600, loss is 3.82646568775177 and perplexity is 45.90002619446139
At time: 420.1023988723755 and batch: 650, loss is 3.8679294776916504 and perplexity is 47.843222996039536
At time: 421.4617199897766 and batch: 700, loss is 3.913303699493408 and perplexity is 50.06407572520564
At time: 422.8196368217468 and batch: 750, loss is 3.85745201587677 and perplexity is 47.344564354207975
At time: 424.1783609390259 and batch: 800, loss is 3.8524363946914675 and perplexity is 47.10769647057455
At time: 425.53421807289124 and batch: 850, loss is 3.8482597160339354 and perplexity is 46.911353077179086
At time: 426.889413356781 and batch: 900, loss is 3.8028412866592407 and perplexity is 44.82837397778086
At time: 428.2488648891449 and batch: 950, loss is 3.905121855735779 and perplexity is 49.65613042783386
At time: 429.6072850227356 and batch: 1000, loss is 3.8676465463638308 and perplexity is 47.829688564177765
At time: 430.96178674697876 and batch: 1050, loss is 3.8165436458587645 and perplexity is 45.4468561156833
At time: 432.3228249549866 and batch: 1100, loss is 3.82397668838501 and perplexity is 45.78592311847787
At time: 433.68005776405334 and batch: 1150, loss is 3.8092891788482666 and perplexity is 45.11835638316715
At time: 435.03584361076355 and batch: 1200, loss is 3.859264636039734 and perplexity is 47.430459890635625
At time: 436.3911738395691 and batch: 1250, loss is 3.86425895690918 and perplexity is 47.66793534701164
At time: 437.7472381591797 and batch: 1300, loss is 3.838372144699097 and perplexity is 46.44979931038667
At time: 439.1034872531891 and batch: 1350, loss is 3.709632568359375 and perplexity is 40.83879830324927
At time: 440.45930790901184 and batch: 1400, loss is 3.7394381952285767 and perplexity is 42.074345955591596
At time: 441.81507778167725 and batch: 1450, loss is 3.6742452239990233 and perplexity is 39.41889319159719
At time: 443.1712772846222 and batch: 1500, loss is 3.664703788757324 and perplexity is 39.044569009717385
At time: 444.5279107093811 and batch: 1550, loss is 3.683671598434448 and perplexity is 39.79222726761931
At time: 445.8841235637665 and batch: 1600, loss is 3.766763424873352 and perplexity is 43.239888964247946
At time: 447.2403955459595 and batch: 1650, loss is 3.7250505590438845 and perplexity is 41.473329543712666
At time: 448.596825838089 and batch: 1700, loss is 3.716770977973938 and perplexity is 41.13136536310292
At time: 449.95638036727905 and batch: 1750, loss is 3.7070372438430788 and perplexity is 40.73294578902538
At time: 451.3151526451111 and batch: 1800, loss is 3.6671325397491454 and perplexity is 39.13951379737663
At time: 452.6711187362671 and batch: 1850, loss is 3.707494535446167 and perplexity is 40.75157688270043
At time: 454.0274169445038 and batch: 1900, loss is 3.807269268035889 and perplexity is 45.02731330767332
At time: 455.3846061229706 and batch: 1950, loss is 3.7380585956573484 and perplexity is 42.01634022749053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36244379087936 and perplexity of 78.44861236516248
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 459.6996395587921 and batch: 50, loss is 3.922547755241394 and perplexity is 50.529016490497334
At time: 461.0549325942993 and batch: 100, loss is 3.911759467124939 and perplexity is 49.986824820998066
At time: 462.40983986854553 and batch: 150, loss is 3.8849292039871215 and perplexity is 48.66349715596361
At time: 463.766704082489 and batch: 200, loss is 3.881140275001526 and perplexity is 48.47946348646657
At time: 465.12308502197266 and batch: 250, loss is 3.8818637132644653 and perplexity is 48.514548074556025
At time: 466.4783697128296 and batch: 300, loss is 3.9046149349212644 and perplexity is 49.630965080709764
At time: 467.83428931236267 and batch: 350, loss is 3.927712025642395 and perplexity is 50.79063695271112
At time: 469.19039011001587 and batch: 400, loss is 3.88167631149292 and perplexity is 48.50545721414941
At time: 470.55186343193054 and batch: 450, loss is 3.9067388582229614 and perplexity is 49.73648946711317
At time: 471.91340470314026 and batch: 500, loss is 3.9152459955215453 and perplexity is 50.16140947551798
At time: 473.27510237693787 and batch: 550, loss is 3.88828818321228 and perplexity is 48.8272316683991
At time: 474.63081908226013 and batch: 600, loss is 3.845411148071289 and perplexity is 46.77791304644874
At time: 475.98861837387085 and batch: 650, loss is 3.881896958351135 and perplexity is 48.51616097172182
At time: 477.34395003318787 and batch: 700, loss is 3.927198338508606 and perplexity is 50.764553156020504
At time: 478.6984930038452 and batch: 750, loss is 3.871277494430542 and perplexity is 48.00367134948433
At time: 480.0549111366272 and batch: 800, loss is 3.8628300619125366 and perplexity is 47.59987151231114
At time: 481.41109895706177 and batch: 850, loss is 3.853763155937195 and perplexity is 47.17023861670067
At time: 482.7863800525665 and batch: 900, loss is 3.803847222328186 and perplexity is 44.87349112681614
At time: 484.1429271697998 and batch: 950, loss is 3.9133345890045166 and perplexity is 50.065622203913755
At time: 485.49884033203125 and batch: 1000, loss is 3.8717698574066164 and perplexity is 48.02731239948374
At time: 486.85543608665466 and batch: 1050, loss is 3.8133794498443603 and perplexity is 45.303280624984005
At time: 488.21287727355957 and batch: 1100, loss is 3.8134078121185304 and perplexity is 45.30456554727147
At time: 489.56903648376465 and batch: 1150, loss is 3.802110319137573 and perplexity is 44.79561786563949
At time: 490.9261245727539 and batch: 1200, loss is 3.8428533458709717 and perplexity is 46.658417285940466
At time: 492.28316712379456 and batch: 1250, loss is 3.8424768924713133 and perplexity is 46.64085587186491
At time: 493.6394889354706 and batch: 1300, loss is 3.816365761756897 and perplexity is 45.438772561489664
At time: 494.99517273902893 and batch: 1350, loss is 3.6919915676116943 and perplexity is 40.12467844601921
At time: 496.3496503829956 and batch: 1400, loss is 3.715921149253845 and perplexity is 41.0964255960323
At time: 497.70124864578247 and batch: 1450, loss is 3.641182932853699 and perplexity is 38.13692347255886
At time: 499.0570487976074 and batch: 1500, loss is 3.62769314289093 and perplexity is 37.62591880701713
At time: 500.4169783592224 and batch: 1550, loss is 3.6369097328186033 and perplexity is 37.97430446905829
At time: 501.7755653858185 and batch: 1600, loss is 3.722489285469055 and perplexity is 41.36724091968301
At time: 503.13558435440063 and batch: 1650, loss is 3.6853080415725707 and perplexity is 39.85739829467833
At time: 504.4905638694763 and batch: 1700, loss is 3.6724833154678347 and perplexity is 39.349501855937135
At time: 505.84651613235474 and batch: 1750, loss is 3.660815134048462 and perplexity is 38.89303298916818
At time: 507.2030575275421 and batch: 1800, loss is 3.6131579160690306 and perplexity is 37.08297302195061
At time: 508.558153629303 and batch: 1850, loss is 3.6487135171890257 and perplexity is 38.42520087737084
At time: 509.9146418571472 and batch: 1900, loss is 3.752636594772339 and perplexity is 42.63334078801326
At time: 511.26948714256287 and batch: 1950, loss is 3.688016185760498 and perplexity is 39.96548416621948
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3324934138808135 and perplexity of 76.13388338091977
finished 9 epochs...
Completing Train Step...
At time: 515.5344789028168 and batch: 50, loss is 3.9205698204040527 and perplexity is 50.429172163821335
At time: 516.9198424816132 and batch: 100, loss is 3.8871390628814697 and perplexity is 48.77115552907824
At time: 518.2782816886902 and batch: 150, loss is 3.8486729097366332 and perplexity is 46.930740557972264
At time: 519.6344134807587 and batch: 200, loss is 3.838979320526123 and perplexity is 46.47801106958056
At time: 520.9922502040863 and batch: 250, loss is 3.833888683319092 and perplexity is 46.24200958574474
At time: 522.3505301475525 and batch: 300, loss is 3.8507604503631594 and perplexity is 47.02881271471064
At time: 523.707001209259 and batch: 350, loss is 3.874754476547241 and perplexity is 48.17086976080136
At time: 525.0632932186127 and batch: 400, loss is 3.828531560897827 and perplexity is 45.99494784026024
At time: 526.419588804245 and batch: 450, loss is 3.854635329246521 and perplexity is 47.2113971859104
At time: 527.7766697406769 and batch: 500, loss is 3.8646262311935424 and perplexity is 47.68544576922032
At time: 529.1324851512909 and batch: 550, loss is 3.838103857040405 and perplexity is 46.43733907402155
At time: 530.488570690155 and batch: 600, loss is 3.7983814239501954 and perplexity is 44.62889074892652
At time: 531.8436019420624 and batch: 650, loss is 3.8367073059082033 and perplexity is 46.372532219137604
At time: 533.1992537975311 and batch: 700, loss is 3.884552278518677 and perplexity is 48.64515810094752
At time: 534.5538384914398 and batch: 750, loss is 3.8308558225631715 and perplexity is 46.10197646741002
At time: 535.909916639328 and batch: 800, loss is 3.8224351024627685 and perplexity is 45.71539456084489
At time: 537.2657284736633 and batch: 850, loss is 3.814097285270691 and perplexity is 45.33581259965063
At time: 538.6207540035248 and batch: 900, loss is 3.7655320024490355 and perplexity is 43.18667516640883
At time: 539.9772458076477 and batch: 950, loss is 3.8746667814254763 and perplexity is 48.16664559573422
At time: 541.3321576118469 and batch: 1000, loss is 3.8363857746124266 and perplexity is 46.357624395559085
At time: 542.6860103607178 and batch: 1050, loss is 3.7802995347976687 and perplexity is 43.82916813057777
At time: 544.0408370494843 and batch: 1100, loss is 3.7831101560592653 and perplexity is 43.95252860097603
At time: 545.3965816497803 and batch: 1150, loss is 3.7737824440002443 and perplexity is 43.54445821019007
At time: 546.7517206668854 and batch: 1200, loss is 3.8160407400131224 and perplexity is 45.42400637219305
At time: 548.1057629585266 and batch: 1250, loss is 3.8197746229171754 and perplexity is 45.59393133555484
At time: 549.461457490921 and batch: 1300, loss is 3.794250798225403 and perplexity is 44.44492571165637
At time: 550.8160107135773 and batch: 1350, loss is 3.67093318939209 and perplexity is 39.288552418903066
At time: 552.1717884540558 and batch: 1400, loss is 3.6972644329071045 and perplexity is 40.33680924756642
At time: 553.5369846820831 and batch: 1450, loss is 3.6253323411941527 and perplexity is 37.5371962434511
At time: 554.8986601829529 and batch: 1500, loss is 3.6137560558319093 and perplexity is 37.10516045757303
At time: 556.2562508583069 and batch: 1550, loss is 3.625983247756958 and perplexity is 37.56163740442837
At time: 557.6115689277649 and batch: 1600, loss is 3.7141953134536743 and perplexity is 41.02556108132704
At time: 558.9703760147095 and batch: 1650, loss is 3.679801888465881 and perplexity is 39.63854044259363
At time: 560.3291425704956 and batch: 1700, loss is 3.668575587272644 and perplexity is 39.19603474723303
At time: 561.6843726634979 and batch: 1750, loss is 3.6591819095611573 and perplexity is 38.82956377914698
At time: 563.0391354560852 and batch: 1800, loss is 3.6137495470046996 and perplexity is 37.104918947281
At time: 564.3957116603851 and batch: 1850, loss is 3.6508323621749876 and perplexity is 38.50670423758503
At time: 565.7534503936768 and batch: 1900, loss is 3.7553373861312864 and perplexity is 42.74864017612671
At time: 567.105714559555 and batch: 1950, loss is 3.689956202507019 and perplexity is 40.04309313179005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333510287972384 and perplexity of 76.21134133023689
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 571.373382806778 and batch: 50, loss is 3.9125045251846315 and perplexity is 50.02408178528667
At time: 572.7481620311737 and batch: 100, loss is 3.897096710205078 and perplexity is 49.25922748673241
At time: 574.1020517349243 and batch: 150, loss is 3.8726949167251585 and perplexity is 48.07176106802124
At time: 575.4567384719849 and batch: 200, loss is 3.87078519821167 and perplexity is 47.98004513961106
At time: 576.8117792606354 and batch: 250, loss is 3.8694033002853394 and perplexity is 47.91378740598378
At time: 578.1660859584808 and batch: 300, loss is 3.8842181634902953 and perplexity is 48.628907737464495
At time: 579.5195791721344 and batch: 350, loss is 3.909459767341614 and perplexity is 49.872002210159145
At time: 580.8765189647675 and batch: 400, loss is 3.8680679845809935 and perplexity is 47.849850070970035
At time: 582.2314560413361 and batch: 450, loss is 3.8996864318847657 and perplexity is 49.38696050116934
At time: 583.6029944419861 and batch: 500, loss is 3.902692046165466 and perplexity is 49.53562195250884
At time: 584.9592952728271 and batch: 550, loss is 3.8791606187820435 and perplexity is 48.38358574885059
At time: 586.3152441978455 and batch: 600, loss is 3.8322983264923094 and perplexity is 46.168526737578475
At time: 587.6696619987488 and batch: 650, loss is 3.8624433708190917 and perplexity is 47.58146862429397
At time: 589.0250442028046 and batch: 700, loss is 3.90719717502594 and perplexity is 49.75928976043678
At time: 590.3818740844727 and batch: 750, loss is 3.855305066108704 and perplexity is 47.243026989561386
At time: 591.7377533912659 and batch: 800, loss is 3.845911703109741 and perplexity is 46.80133382771844
At time: 593.0934920310974 and batch: 850, loss is 3.840322232246399 and perplexity is 46.54046886364642
At time: 594.4491415023804 and batch: 900, loss is 3.7853843688964846 and perplexity is 44.0525997541682
At time: 595.8029670715332 and batch: 950, loss is 3.895219254493713 and perplexity is 49.16683222989122
At time: 597.1565525531769 and batch: 1000, loss is 3.8601618671417235 and perplexity is 47.473035071463215
At time: 598.5115463733673 and batch: 1050, loss is 3.799287338256836 and perplexity is 44.66933901811208
At time: 599.8659040927887 and batch: 1100, loss is 3.7953970289230345 and perplexity is 44.49589905788721
At time: 601.2212865352631 and batch: 1150, loss is 3.7939380264282225 and perplexity is 44.43102676607838
At time: 602.5749289989471 and batch: 1200, loss is 3.8297131967544558 and perplexity is 46.04932924303221
At time: 603.9300103187561 and batch: 1250, loss is 3.824843783378601 and perplexity is 45.825641080325276
At time: 605.2867524623871 and batch: 1300, loss is 3.7976247215270997 and perplexity is 44.595132733153726
At time: 606.6425259113312 and batch: 1350, loss is 3.67205322265625 and perplexity is 39.33258155695976
At time: 607.9961521625519 and batch: 1400, loss is 3.7019267749786375 and perplexity is 40.525312341841946
At time: 609.3528299331665 and batch: 1450, loss is 3.6236721801757814 and perplexity is 37.47493015367741
At time: 610.7082116603851 and batch: 1500, loss is 3.6110096883773806 and perplexity is 37.003395857953066
At time: 612.0631215572357 and batch: 1550, loss is 3.627699794769287 and perplexity is 37.62616909088453
At time: 613.4187517166138 and batch: 1600, loss is 3.707306213378906 and perplexity is 40.743903184083806
At time: 614.7729349136353 and batch: 1650, loss is 3.668673439025879 and perplexity is 39.19987033560936
At time: 616.1286194324493 and batch: 1700, loss is 3.6574407386779786 and perplexity is 38.762013698470845
At time: 617.482417345047 and batch: 1750, loss is 3.646732039451599 and perplexity is 38.34913758102733
At time: 618.8382847309113 and batch: 1800, loss is 3.5986214685440063 and perplexity is 36.54781738499837
At time: 620.1947684288025 and batch: 1850, loss is 3.6299641847610475 and perplexity is 37.711465947830455
At time: 621.5499832630157 and batch: 1900, loss is 3.739048566818237 and perplexity is 42.057955788305605
At time: 622.9051294326782 and batch: 1950, loss is 3.6835132884979247 and perplexity is 39.78592826125725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3183233216751455 and perplexity of 75.0626667766707
finished 11 epochs...
Completing Train Step...
At time: 627.1958115100861 and batch: 50, loss is 3.918429203033447 and perplexity is 50.321338058858146
At time: 628.5628476142883 and batch: 100, loss is 3.8862534284591677 and perplexity is 48.72798123606824
At time: 629.9234962463379 and batch: 150, loss is 3.8544971418380736 and perplexity is 47.204873616032074
At time: 631.2782635688782 and batch: 200, loss is 3.8473208570480346 and perplexity is 46.86733060048439
At time: 632.6338376998901 and batch: 250, loss is 3.844689378738403 and perplexity is 46.74416236492406
At time: 633.9891006946564 and batch: 300, loss is 3.8589041376113893 and perplexity is 47.41336436602941
At time: 635.3449244499207 and batch: 350, loss is 3.8818405437469483 and perplexity is 48.51342402890643
At time: 636.7004780769348 and batch: 400, loss is 3.8392248010635375 and perplexity is 46.48942191722907
At time: 638.0550560951233 and batch: 450, loss is 3.871922016143799 and perplexity is 48.034620730687834
At time: 639.4094405174255 and batch: 500, loss is 3.876168532371521 and perplexity is 48.239034242580274
At time: 640.7662215232849 and batch: 550, loss is 3.8510315132141115 and perplexity is 47.041562206640734
At time: 642.1209659576416 and batch: 600, loss is 3.8063233709335327 and perplexity is 44.98474223958779
At time: 643.4762454032898 and batch: 650, loss is 3.8394117879867555 and perplexity is 46.49811564397684
At time: 644.831785440445 and batch: 700, loss is 3.8861344289779662 and perplexity is 48.722182976582936
At time: 646.1878035068512 and batch: 750, loss is 3.8348727655410766 and perplexity is 46.28753792342657
At time: 647.5465748310089 and batch: 800, loss is 3.826346116065979 and perplexity is 45.89453817906364
At time: 648.9053068161011 and batch: 850, loss is 3.821071844100952 and perplexity is 45.653115128070226
At time: 650.2613711357117 and batch: 900, loss is 3.7677747344970705 and perplexity is 43.283639999278535
At time: 651.6340684890747 and batch: 950, loss is 3.8768901872634887 and perplexity is 48.27385874174898
At time: 652.9887645244598 and batch: 1000, loss is 3.8422035694122316 and perplexity is 46.62810959246521
At time: 654.3432631492615 and batch: 1050, loss is 3.7835220861434937 and perplexity is 43.970637699369824
At time: 655.6975967884064 and batch: 1100, loss is 3.7817920064926147 and perplexity is 43.89463076183646
At time: 657.0531418323517 and batch: 1150, loss is 3.7808240461349487 and perplexity is 43.85216305618822
At time: 658.4073193073273 and batch: 1200, loss is 3.8178347730636597 and perplexity is 45.50557168446871
At time: 659.7624113559723 and batch: 1250, loss is 3.8148972845077513 and perplexity is 45.372095726443646
At time: 661.1181371212006 and batch: 1300, loss is 3.7881206274032593 and perplexity is 44.173304118852855
At time: 662.4741549491882 and batch: 1350, loss is 3.6640884590148928 and perplexity is 39.02055111534549
At time: 663.8284020423889 and batch: 1400, loss is 3.695335655212402 and perplexity is 40.25908349156266
At time: 665.1832571029663 and batch: 1450, loss is 3.6192894172668457 and perplexity is 37.311045815217355
At time: 666.5399911403656 and batch: 1500, loss is 3.6086189365386963 and perplexity is 36.915035587094806
At time: 667.8942265510559 and batch: 1550, loss is 3.6262927722930907 and perplexity is 37.57326545231259
At time: 669.2498164176941 and batch: 1600, loss is 3.7083742141723635 and perplexity is 40.7874409500589
At time: 670.6057419776917 and batch: 1650, loss is 3.670910859107971 and perplexity is 39.28767510416032
At time: 671.9606747627258 and batch: 1700, loss is 3.66169536113739 and perplexity is 38.92728276195332
At time: 673.3158388137817 and batch: 1750, loss is 3.6525011825561524 and perplexity is 38.571018660111655
At time: 674.669510602951 and batch: 1800, loss is 3.6052996778488158 and perplexity is 36.79270816492624
At time: 676.0241084098816 and batch: 1850, loss is 3.637414698600769 and perplexity is 37.99348503577407
At time: 677.379842042923 and batch: 1900, loss is 3.7464486503601075 and perplexity is 42.37034259341093
At time: 678.7357220649719 and batch: 1950, loss is 3.6898257875442506 and perplexity is 40.03787125380304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317188919422239 and perplexity of 74.97756379800177
finished 12 epochs...
Completing Train Step...
At time: 683.023467540741 and batch: 50, loss is 3.913681721687317 and perplexity is 50.0830046344958
At time: 684.3741524219513 and batch: 100, loss is 3.87910834312439 and perplexity is 48.38105653119476
At time: 685.7473142147064 and batch: 150, loss is 3.846311011314392 and perplexity is 46.82002571596826
At time: 687.1044099330902 and batch: 200, loss is 3.837858157157898 and perplexity is 46.42593082682701
At time: 688.4588282108307 and batch: 250, loss is 3.8343945741653442 and perplexity is 46.26540891336026
At time: 689.8142139911652 and batch: 300, loss is 3.848297357559204 and perplexity is 46.913118925295734
At time: 691.1734137535095 and batch: 350, loss is 3.8706750154495237 and perplexity is 47.97475885694364
At time: 692.53591132164 and batch: 400, loss is 3.8277036428451536 and perplexity is 45.956883551841536
At time: 693.8974633216858 and batch: 450, loss is 3.8607045888900755 and perplexity is 47.49880671283933
At time: 695.2594652175903 and batch: 500, loss is 3.864988055229187 and perplexity is 47.70270263143554
At time: 696.6215314865112 and batch: 550, loss is 3.839590005874634 and perplexity is 46.50640317840874
At time: 697.984129190445 and batch: 600, loss is 3.7959639120101927 and perplexity is 44.521130181383924
At time: 699.3466033935547 and batch: 650, loss is 3.829373908042908 and perplexity is 46.033707875672356
At time: 700.705575466156 and batch: 700, loss is 3.8766512870788574 and perplexity is 48.26232748544719
At time: 702.0664584636688 and batch: 750, loss is 3.8255067968368532 and perplexity is 45.856034171495445
At time: 703.428581237793 and batch: 800, loss is 3.8171175146102905 and perplexity is 45.47294413109566
At time: 704.7872123718262 and batch: 850, loss is 3.811859803199768 and perplexity is 45.23448793012592
At time: 706.1415371894836 and batch: 900, loss is 3.7589416122436523 and perplexity is 42.90299393715201
At time: 707.4985511302948 and batch: 950, loss is 3.8681614875793455 and perplexity is 47.85432438459998
At time: 708.854202747345 and batch: 1000, loss is 3.8338564682006835 and perplexity is 46.24051991792553
At time: 710.2087898254395 and batch: 1050, loss is 3.775775852203369 and perplexity is 43.63134666369266
At time: 711.5773096084595 and batch: 1100, loss is 3.775030741691589 and perplexity is 43.59884859747935
At time: 712.9347233772278 and batch: 1150, loss is 3.774271626472473 and perplexity is 43.56576460684221
At time: 714.2905766963959 and batch: 1200, loss is 3.8118086433410645 and perplexity is 45.232173799310694
At time: 715.6463215351105 and batch: 1250, loss is 3.809761838912964 and perplexity is 45.13968706909884
At time: 717.0051038265228 and batch: 1300, loss is 3.783162121772766 and perplexity is 43.95481268483145
At time: 718.3655104637146 and batch: 1350, loss is 3.659610710144043 and perplexity is 38.84621748903375
At time: 719.7253906726837 and batch: 1400, loss is 3.691396551132202 and perplexity is 40.100810702664006
At time: 721.08252120018 and batch: 1450, loss is 3.6160325098037718 and perplexity is 37.18972486444378
At time: 722.4393377304077 and batch: 1500, loss is 3.6063977384567263 and perplexity is 36.83313097770807
At time: 723.7946357727051 and batch: 1550, loss is 3.624576573371887 and perplexity is 37.50883755603378
At time: 725.1507837772369 and batch: 1600, loss is 3.707643208503723 and perplexity is 40.757635994638
At time: 726.5112736225128 and batch: 1650, loss is 3.6705674934387207 and perplexity is 39.27418738104794
At time: 727.8693962097168 and batch: 1700, loss is 3.6619227075576783 and perplexity is 38.93613374642249
At time: 729.2248368263245 and batch: 1750, loss is 3.6532493209838868 and perplexity is 38.599885918374305
At time: 730.5794017314911 and batch: 1800, loss is 3.60648551940918 and perplexity is 36.83636436694005
At time: 731.9354453086853 and batch: 1850, loss is 3.6389297437667847 and perplexity is 38.05109050804498
At time: 733.2933473587036 and batch: 1900, loss is 3.747736735343933 and perplexity is 42.4249543602126
At time: 734.6533896923065 and batch: 1950, loss is 3.690570707321167 and perplexity is 40.06770736730146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317257335574128 and perplexity of 74.98269364987524
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 738.9643979072571 and batch: 50, loss is 3.9120018529891967 and perplexity is 49.998942389238096
At time: 740.3212473392487 and batch: 100, loss is 3.883174629211426 and perplexity is 48.57818827364867
At time: 741.6815927028656 and batch: 150, loss is 3.8545912170410155 and perplexity is 47.209314632988864
At time: 743.0430419445038 and batch: 200, loss is 3.84909969329834 and perplexity is 46.950774101270525
At time: 744.3978264331818 and batch: 250, loss is 3.848704891204834 and perplexity is 46.932241495960035
At time: 745.7521452903748 and batch: 300, loss is 3.863518724441528 and perplexity is 47.63266305006217
At time: 747.1080069541931 and batch: 350, loss is 3.8884480094909666 and perplexity is 48.83503616680058
At time: 748.4638381004333 and batch: 400, loss is 3.849228734970093 and perplexity is 46.95683309857382
At time: 749.8255457878113 and batch: 450, loss is 3.887530837059021 and perplexity is 48.79026655178204
At time: 751.1899106502533 and batch: 500, loss is 3.89141104221344 and perplexity is 48.97995056399266
At time: 752.5860545635223 and batch: 550, loss is 3.8723558664321898 and perplexity is 48.055465086082435
At time: 753.940815448761 and batch: 600, loss is 3.824643363952637 and perplexity is 45.81645765194498
At time: 755.2970621585846 and batch: 650, loss is 3.8506721162796023 and perplexity is 47.02465865111411
At time: 756.6554439067841 and batch: 700, loss is 3.8967991256713868 and perplexity is 49.244570883388164
At time: 758.0136020183563 and batch: 750, loss is 3.8413743019104003 and perplexity is 46.58945844479367
At time: 759.370582818985 and batch: 800, loss is 3.8301957511901854 and perplexity is 46.07155591347871
At time: 760.72718501091 and batch: 850, loss is 3.823868203163147 and perplexity is 45.78095629186867
At time: 762.081648349762 and batch: 900, loss is 3.7650983476638795 and perplexity is 43.16795111824792
At time: 763.4379343986511 and batch: 950, loss is 3.8777495861053466 and perplexity is 48.3153630718758
At time: 764.7971239089966 and batch: 1000, loss is 3.8423683261871338 and perplexity is 46.63579252231144
At time: 766.1572866439819 and batch: 1050, loss is 3.787322311401367 and perplexity is 44.13805393558311
At time: 767.5142560005188 and batch: 1100, loss is 3.7812534761428833 and perplexity is 43.87099853488782
At time: 768.868818283081 and batch: 1150, loss is 3.7801015424728392 and perplexity is 43.82049115070031
At time: 770.2241387367249 and batch: 1200, loss is 3.8199558782577516 and perplexity is 45.60219622811261
At time: 771.5793261528015 and batch: 1250, loss is 3.8119203281402587 and perplexity is 45.23722582767072
At time: 772.9378831386566 and batch: 1300, loss is 3.782260384559631 and perplexity is 43.91519485965534
At time: 774.2968420982361 and batch: 1350, loss is 3.652889370918274 and perplexity is 38.58599438718411
At time: 775.6535670757294 and batch: 1400, loss is 3.6862378883361817 and perplexity is 39.89447680348274
At time: 777.00852394104 and batch: 1450, loss is 3.607733435630798 and perplexity is 36.88236175805498
At time: 778.3611378669739 and batch: 1500, loss is 3.600062494277954 and perplexity is 36.600521695383264
At time: 779.7192192077637 and batch: 1550, loss is 3.6237241983413697 and perplexity is 37.47687958150195
At time: 781.079083442688 and batch: 1600, loss is 3.7044274187088013 and perplexity is 40.62677852257265
At time: 782.4380927085876 and batch: 1650, loss is 3.6613827896118165 and perplexity is 38.91511710321229
At time: 783.7921175956726 and batch: 1700, loss is 3.6485087203979494 and perplexity is 38.4173323252893
At time: 785.1517539024353 and batch: 1750, loss is 3.640129637718201 and perplexity is 38.09677518429253
At time: 786.5140664577484 and batch: 1800, loss is 3.593667802810669 and perplexity is 36.367219394732714
At time: 787.8769953250885 and batch: 1850, loss is 3.626002788543701 and perplexity is 37.56237139554598
At time: 789.2360799312592 and batch: 1900, loss is 3.735244698524475 and perplexity is 41.89827675532584
At time: 790.5925056934357 and batch: 1950, loss is 3.6857993364334107 and perplexity is 39.87698484061767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312493186773255 and perplexity of 74.62631453546679
finished 14 epochs...
Completing Train Step...
At time: 794.9071598052979 and batch: 50, loss is 3.9148797273635862 and perplexity is 50.14304031269382
At time: 796.265095949173 and batch: 100, loss is 3.8805064296722414 and perplexity is 48.44874474146444
At time: 797.624080657959 and batch: 150, loss is 3.8477910375595092 and perplexity is 46.88937188724326
At time: 798.9792249202728 and batch: 200, loss is 3.8399269819259643 and perplexity is 46.52207736327752
At time: 800.3325264453888 and batch: 250, loss is 3.8388525009155274 and perplexity is 46.47211712005754
At time: 801.6863443851471 and batch: 300, loss is 3.8531478309631346 and perplexity is 47.141222518927755
At time: 803.0420961380005 and batch: 350, loss is 3.8776356840133666 and perplexity is 48.30986016434943
At time: 804.399717092514 and batch: 400, loss is 3.8371798276901243 and perplexity is 46.39444942846558
At time: 805.7567365169525 and batch: 450, loss is 3.874767804145813 and perplexity is 48.171511767094586
At time: 807.1122326850891 and batch: 500, loss is 3.8791357421875 and perplexity is 48.382382144976205
At time: 808.469929933548 and batch: 550, loss is 3.8585017490386964 and perplexity is 47.3942896080053
At time: 809.830066204071 and batch: 600, loss is 3.8116492462158202 and perplexity is 45.224964495424956
At time: 811.1962878704071 and batch: 650, loss is 3.8386386680603026 and perplexity is 46.46218091694662
At time: 812.5636146068573 and batch: 700, loss is 3.885607805252075 and perplexity is 48.696531473988024
At time: 813.9284336566925 and batch: 750, loss is 3.831598091125488 and perplexity is 46.13620921857819
At time: 815.2895238399506 and batch: 800, loss is 3.821445550918579 and perplexity is 45.67017919672029
At time: 816.6457903385162 and batch: 850, loss is 3.815848164558411 and perplexity is 45.41525966573862
At time: 818.0004727840424 and batch: 900, loss is 3.758974452018738 and perplexity is 42.90440288495804
At time: 819.359578371048 and batch: 950, loss is 3.870940055847168 and perplexity is 47.98747579128418
At time: 820.7364408969879 and batch: 1000, loss is 3.836237044334412 and perplexity is 46.35073012590066
At time: 822.0914106369019 and batch: 1050, loss is 3.781047849655151 and perplexity is 43.86197842296453
At time: 823.4457471370697 and batch: 1100, loss is 3.775755400657654 and perplexity is 43.630454344336435
At time: 824.8013353347778 and batch: 1150, loss is 3.7755137729644774 and perplexity is 43.61991329185736
At time: 826.1566722393036 and batch: 1200, loss is 3.8153008222579956 and perplexity is 45.39040877463158
At time: 827.5163285732269 and batch: 1250, loss is 3.8083865022659302 and perplexity is 45.07764747567953
At time: 828.8739545345306 and batch: 1300, loss is 3.78014328956604 and perplexity is 43.822320567014614
At time: 830.2286274433136 and batch: 1350, loss is 3.651783380508423 and perplexity is 38.543342238218905
At time: 831.5855071544647 and batch: 1400, loss is 3.685672764778137 and perplexity is 39.8719378640479
At time: 832.940000295639 and batch: 1450, loss is 3.608116822242737 and perplexity is 36.896504672698526
At time: 834.2975609302521 and batch: 1500, loss is 3.60038649559021 and perplexity is 36.61238223375307
At time: 835.6607451438904 and batch: 1550, loss is 3.6254154920578 and perplexity is 37.540317623508564
At time: 837.0238630771637 and batch: 1600, loss is 3.706716995239258 and perplexity is 40.71990320855249
At time: 838.3829066753387 and batch: 1650, loss is 3.6650056409835816 and perplexity is 39.05635647874361
At time: 839.7443406581879 and batch: 1700, loss is 3.653004946708679 and perplexity is 38.5904542517052
At time: 841.1084570884705 and batch: 1750, loss is 3.645093126296997 and perplexity is 38.28633815044139
At time: 842.4735260009766 and batch: 1800, loss is 3.598540549278259 and perplexity is 36.54486008210392
At time: 843.8439416885376 and batch: 1850, loss is 3.630770206451416 and perplexity is 37.74187446067416
At time: 845.207498550415 and batch: 1900, loss is 3.7404292488098143 and perplexity is 42.11606455609871
At time: 846.5681142807007 and batch: 1950, loss is 3.6906043767929075 and perplexity is 40.06905644855367
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311091081486192 and perplexity of 74.52175390493865
finished 15 epochs...
Completing Train Step...
At time: 851.0619225502014 and batch: 50, loss is 3.9145243072509768 and perplexity is 50.1252216344052
At time: 852.4490711688995 and batch: 100, loss is 3.8779442214965822 and perplexity is 48.32476786669326
At time: 853.8087315559387 and batch: 150, loss is 3.844146800041199 and perplexity is 46.718806857507325
At time: 855.2125537395477 and batch: 200, loss is 3.8355273103713987 and perplexity is 46.317845109706695
At time: 856.5697422027588 and batch: 250, loss is 3.8340499448776244 and perplexity is 46.24946724558097
At time: 857.9268343448639 and batch: 300, loss is 3.8480851554870608 and perplexity is 46.90316492041666
At time: 859.2862207889557 and batch: 350, loss is 3.8721790885925294 and perplexity is 48.046970695612764
At time: 860.6437258720398 and batch: 400, loss is 3.8312810373306276 and perplexity is 46.121583876997505
At time: 862.0051109790802 and batch: 450, loss is 3.868644061088562 and perplexity is 47.8774231868362
At time: 863.3682496547699 and batch: 500, loss is 3.8732837724685667 and perplexity is 48.100076736725754
At time: 864.7340593338013 and batch: 550, loss is 3.8520450162887574 and perplexity is 47.08926314301299
At time: 866.1011846065521 and batch: 600, loss is 3.8057907724380495 and perplexity is 44.960789812630765
At time: 867.4641811847687 and batch: 650, loss is 3.8330537128448485 and perplexity is 46.203414987988026
At time: 868.8264894485474 and batch: 700, loss is 3.8804521274566652 and perplexity is 48.446113938712955
At time: 870.1880404949188 and batch: 750, loss is 3.8268415546417236 and perplexity is 45.91728173724634
At time: 871.5453581809998 and batch: 800, loss is 3.8170312643051147 and perplexity is 45.46902224492148
At time: 872.9044141769409 and batch: 850, loss is 3.811663432121277 and perplexity is 45.225606057046114
At time: 874.2694158554077 and batch: 900, loss is 3.7556425952911376 and perplexity is 42.76168944395639
At time: 875.632580280304 and batch: 950, loss is 3.8674174213409422 and perplexity is 47.81873084108297
At time: 876.9934265613556 and batch: 1000, loss is 3.833102197647095 and perplexity is 46.205655205734644
At time: 878.3575131893158 and batch: 1050, loss is 3.7779648017883303 and perplexity is 43.72695808798036
At time: 879.7160494327545 and batch: 1100, loss is 3.773153443336487 and perplexity is 43.51707732927179
At time: 881.0753974914551 and batch: 1150, loss is 3.7732632207870482 and perplexity is 43.521854785300555
At time: 882.4373774528503 and batch: 1200, loss is 3.813034176826477 and perplexity is 45.28764132463219
At time: 883.7960705757141 and batch: 1250, loss is 3.8065492916107178 and perplexity is 44.994906371118056
At time: 885.1538252830505 and batch: 1300, loss is 3.7789249277114867 and perplexity is 43.76896163510191
At time: 886.5095472335815 and batch: 1350, loss is 3.651063241958618 and perplexity is 38.51559568351579
At time: 887.8710563182831 and batch: 1400, loss is 3.6852432346343993 and perplexity is 39.854815342428886
At time: 889.2367401123047 and batch: 1450, loss is 3.6081976985931394 and perplexity is 36.89948884801204
At time: 890.6015846729279 and batch: 1500, loss is 3.600636887550354 and perplexity is 36.621550827729315
At time: 891.965921163559 and batch: 1550, loss is 3.6262613582611083 and perplexity is 37.572085143089225
At time: 893.3253841400146 and batch: 1600, loss is 3.7078844022750856 and perplexity is 40.767467668196915
At time: 894.687148809433 and batch: 1650, loss is 3.6666288948059083 and perplexity is 39.11980634236843
At time: 896.0497536659241 and batch: 1700, loss is 3.6550396394729616 and perplexity is 38.669053905698426
At time: 897.4149720668793 and batch: 1750, loss is 3.6474487733840943 and perplexity is 38.37663356168768
At time: 898.7767698764801 and batch: 1800, loss is 3.60084255695343 and perplexity is 36.629083534824915
At time: 900.1339478492737 and batch: 1850, loss is 3.6330392169952392 and perplexity is 37.82760840059313
At time: 901.4899322986603 and batch: 1900, loss is 3.742687530517578 and perplexity is 42.211281967692074
At time: 902.8474366664886 and batch: 1950, loss is 3.692452654838562 and perplexity is 40.14318368867049
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310575263444767 and perplexity of 74.48332415202788
finished 16 epochs...
Completing Train Step...
At time: 907.2038555145264 and batch: 50, loss is 3.9132435750961303 and perplexity is 50.06106574331497
At time: 908.5920882225037 and batch: 100, loss is 3.8756379079818726 and perplexity is 48.213444224422396
At time: 909.9530072212219 and batch: 150, loss is 3.841439437866211 and perplexity is 46.592493192534704
At time: 911.3175134658813 and batch: 200, loss is 3.8324098587036133 and perplexity is 46.17367630262401
At time: 912.6756761074066 and batch: 250, loss is 3.8306514739990236 and perplexity is 46.092556557219865
At time: 914.0384469032288 and batch: 300, loss is 3.844561138153076 and perplexity is 46.73816825053435
At time: 915.4020533561707 and batch: 350, loss is 3.8684671831130983 and perplexity is 47.868955474050516
At time: 916.7661211490631 and batch: 400, loss is 3.82741042137146 and perplexity is 45.94340998218661
At time: 918.1230998039246 and batch: 450, loss is 3.864717879295349 and perplexity is 47.689816250078955
At time: 919.4813599586487 and batch: 500, loss is 3.8694872665405273 and perplexity is 47.91781071619292
At time: 920.8396625518799 and batch: 550, loss is 3.847987003326416 and perplexity is 46.89856149936019
At time: 922.2528147697449 and batch: 600, loss is 3.8021440744400024 and perplexity is 44.79712998078886
At time: 923.6191844940186 and batch: 650, loss is 3.829486484527588 and perplexity is 46.03889048039603
At time: 924.9783539772034 and batch: 700, loss is 3.8771430349349973 and perplexity is 48.28606621777748
At time: 926.3378958702087 and batch: 750, loss is 3.8236861991882325 and perplexity is 45.772624734059484
At time: 927.6966664791107 and batch: 800, loss is 3.8140411901474 and perplexity is 45.33326955298028
At time: 929.0564563274384 and batch: 850, loss is 3.8087259101867676 and perplexity is 45.09294978300075
At time: 930.4200720787048 and batch: 900, loss is 3.7531667041778562 and perplexity is 42.65594711433732
At time: 931.7821304798126 and batch: 950, loss is 3.8649169111251833 and perplexity is 47.69930898611864
At time: 933.1402304172516 and batch: 1000, loss is 3.8308943700790405 and perplexity is 46.10375361833165
At time: 934.4982743263245 and batch: 1050, loss is 3.7757916975021364 and perplexity is 43.63203802089353
At time: 935.857753276825 and batch: 1100, loss is 3.771317234039307 and perplexity is 43.437244184905516
At time: 937.2180602550507 and batch: 1150, loss is 3.7715991973876952 and perplexity is 43.449493622585734
At time: 938.5795731544495 and batch: 1200, loss is 3.811423535346985 and perplexity is 45.214757881310845
At time: 939.9396560192108 and batch: 1250, loss is 3.8051763010025024 and perplexity is 44.933171177871344
At time: 941.2975890636444 and batch: 1300, loss is 3.7778647136688233 and perplexity is 43.722581757986546
At time: 942.659072637558 and batch: 1350, loss is 3.6502917575836182 and perplexity is 38.48589296231802
At time: 944.0203154087067 and batch: 1400, loss is 3.684645848274231 and perplexity is 39.83101372944361
At time: 945.3832569122314 and batch: 1450, loss is 3.607906336784363 and perplexity is 36.888739312276485
At time: 946.7469456195831 and batch: 1500, loss is 3.600576286315918 and perplexity is 36.619331583787336
At time: 948.1072723865509 and batch: 1550, loss is 3.6265044832229614 and perplexity is 37.5812209653846
At time: 949.4659581184387 and batch: 1600, loss is 3.7083424854278566 and perplexity is 40.78614683629632
At time: 950.8256256580353 and batch: 1650, loss is 3.6672757482528686 and perplexity is 39.14511930995296
At time: 952.1821167469025 and batch: 1700, loss is 3.6559025287628173 and perplexity is 38.70243541836613
At time: 953.5417807102203 and batch: 1750, loss is 3.6485444021224978 and perplexity is 38.4187031464157
At time: 954.9070827960968 and batch: 1800, loss is 3.6019349670410157 and perplexity is 36.66911937897595
At time: 956.2681362628937 and batch: 1850, loss is 3.634144344329834 and perplexity is 37.86943583270124
At time: 957.6243069171906 and batch: 1900, loss is 3.743686304092407 and perplexity is 42.25346254159593
At time: 958.9846601486206 and batch: 1950, loss is 3.69312135219574 and perplexity is 40.17003630664854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310375692678052 and perplexity of 74.4684609410999
finished 17 epochs...
Completing Train Step...
At time: 963.3821358680725 and batch: 50, loss is 3.9116675662994385 and perplexity is 49.9822312016148
At time: 964.7576315402985 and batch: 100, loss is 3.873510465621948 and perplexity is 48.11098193081881
At time: 966.1130530834198 and batch: 150, loss is 3.8391365146636964 and perplexity is 46.48531771471261
At time: 967.4691696166992 and batch: 200, loss is 3.829848189353943 and perplexity is 46.05554598128875
At time: 968.8253796100616 and batch: 250, loss is 3.8278883838653566 and perplexity is 45.9653744576794
At time: 970.1890363693237 and batch: 300, loss is 3.841707482337952 and perplexity is 46.60498372669411
At time: 971.5513331890106 and batch: 350, loss is 3.8655084943771363 and perplexity is 47.727535446772045
At time: 972.9071135520935 and batch: 400, loss is 3.82438289642334 and perplexity is 45.80452550645493
At time: 974.263988494873 and batch: 450, loss is 3.861704497337341 and perplexity is 47.54632492387772
At time: 975.6193914413452 and batch: 500, loss is 3.8665464067459108 and perplexity is 47.77709816257192
At time: 976.977034330368 and batch: 550, loss is 3.8449230098724367 and perplexity is 46.75508453241634
At time: 978.3413441181183 and batch: 600, loss is 3.799396653175354 and perplexity is 44.67422231017058
At time: 979.7044067382812 and batch: 650, loss is 3.8267680311203005 and perplexity is 45.913905861103515
At time: 981.0628066062927 and batch: 700, loss is 3.8746008586883547 and perplexity is 48.16347042327776
At time: 982.4188597202301 and batch: 750, loss is 3.8212265872955324 and perplexity is 45.660180183568215
At time: 983.7765386104584 and batch: 800, loss is 3.8116810798645018 and perplexity is 45.226404193971646
At time: 985.1373291015625 and batch: 850, loss is 3.8063657474517822 and perplexity is 44.986648576729934
At time: 986.5028781890869 and batch: 900, loss is 3.7510949850082396 and perplexity is 42.567667447915845
At time: 987.8636400699615 and batch: 950, loss is 3.8628701305389406 and perplexity is 47.601778811990826
At time: 989.2195775508881 and batch: 1000, loss is 3.829079670906067 and perplexity is 46.020165041768884
At time: 990.6098263263702 and batch: 1050, loss is 3.7739938640594484 and perplexity is 43.553665355376175
At time: 991.9682147502899 and batch: 1100, loss is 3.769774651527405 and perplexity is 43.37029030587885
At time: 993.3273231983185 and batch: 1150, loss is 3.770155501365662 and perplexity is 43.386811019682895
At time: 994.699036359787 and batch: 1200, loss is 3.8100534200668337 and perplexity is 45.15285087020466
At time: 996.0621280670166 and batch: 1250, loss is 3.8039842462539672 and perplexity is 44.87964029001547
At time: 997.416140794754 and batch: 1300, loss is 3.7768505001068116 and perplexity is 43.678260202162136
At time: 998.7704799175262 and batch: 1350, loss is 3.6494627714157106 and perplexity is 38.45400190983972
At time: 1000.1252937316895 and batch: 1400, loss is 3.6839313983917235 and perplexity is 39.80256662958807
At time: 1001.482664346695 and batch: 1450, loss is 3.607398090362549 and perplexity is 36.86999550615547
At time: 1002.8457717895508 and batch: 1500, loss is 3.600293197631836 and perplexity is 36.608966532580894
At time: 1004.2046978473663 and batch: 1550, loss is 3.6263995504379274 and perplexity is 37.57727767009782
At time: 1005.5624055862427 and batch: 1600, loss is 3.70840238571167 and perplexity is 40.78859001124018
At time: 1006.9181177616119 and batch: 1650, loss is 3.6674380254745484 and perplexity is 39.15147218660655
At time: 1008.2746164798737 and batch: 1700, loss is 3.656192831993103 and perplexity is 38.71367249138839
At time: 1009.6302766799927 and batch: 1750, loss is 3.649010977745056 and perplexity is 38.43663255914232
At time: 1010.9882476329803 and batch: 1800, loss is 3.6024247217178345 and perplexity is 36.6870826501256
At time: 1012.3494064807892 and batch: 1850, loss is 3.6346683740615844 and perplexity is 37.889285743519665
At time: 1013.7081406116486 and batch: 1900, loss is 3.7440947580337522 and perplexity is 42.27072466005669
At time: 1015.063360452652 and batch: 1950, loss is 3.6932728481292725 and perplexity is 40.17612236479375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310322606286337 and perplexity of 74.46450778414228
finished 18 epochs...
Completing Train Step...
At time: 1019.4826157093048 and batch: 50, loss is 3.910020570755005 and perplexity is 49.899978443081494
At time: 1020.8418498039246 and batch: 100, loss is 3.871521954536438 and perplexity is 48.01540776655025
At time: 1022.2002992630005 and batch: 150, loss is 3.8370612478256225 and perplexity is 46.388948307106276
At time: 1023.564553976059 and batch: 200, loss is 3.827587480545044 and perplexity is 45.95154540459402
At time: 1025.0009891986847 and batch: 250, loss is 3.8254812383651733 and perplexity is 45.85486217632198
At time: 1026.359040260315 and batch: 300, loss is 3.8392214727401734 and perplexity is 46.489267185657425
At time: 1027.7200145721436 and batch: 350, loss is 3.862950744628906 and perplexity is 47.605616340747865
At time: 1029.0797662734985 and batch: 400, loss is 3.821785125732422 and perplexity is 45.68569027275552
At time: 1030.4367892742157 and batch: 450, loss is 3.8591501998901365 and perplexity is 47.425032441986204
At time: 1031.7926115989685 and batch: 500, loss is 3.8640403747558594 and perplexity is 47.65751712571926
At time: 1033.146628856659 and batch: 550, loss is 3.842351632118225 and perplexity is 46.63501398767594
At time: 1034.5067341327667 and batch: 600, loss is 3.797090268135071 and perplexity is 44.57130508114841
At time: 1035.8693811893463 and batch: 650, loss is 3.8244762086868285 and perplexity is 45.808799829828246
At time: 1037.2288608551025 and batch: 700, loss is 3.8724441003799437 and perplexity is 48.05970539654505
At time: 1038.5836200714111 and batch: 750, loss is 3.8191266584396364 and perplexity is 45.56439765707865
At time: 1039.9406719207764 and batch: 800, loss is 3.8096483612060545 and perplexity is 45.1345650115448
At time: 1041.2973716259003 and batch: 850, loss is 3.804323558807373 and perplexity is 44.89487109921446
At time: 1042.6592395305634 and batch: 900, loss is 3.749254541397095 and perplexity is 42.489396105409725
At time: 1044.0196723937988 and batch: 950, loss is 3.8610671091079714 and perplexity is 47.516029112144025
At time: 1045.3800282478333 and batch: 1000, loss is 3.82746798992157 and perplexity is 45.94605495381926
At time: 1046.736998796463 and batch: 1050, loss is 3.7723874759674074 and perplexity is 43.483757430646484
At time: 1048.0952787399292 and batch: 1100, loss is 3.7683726358413696 and perplexity is 43.309527084010455
At time: 1049.4522943496704 and batch: 1150, loss is 3.768819932937622 and perplexity is 43.3289036429314
At time: 1050.8130848407745 and batch: 1200, loss is 3.808789677619934 and perplexity is 45.09582533634465
At time: 1052.1729474067688 and batch: 1250, loss is 3.802874975204468 and perplexity is 44.829884205923626
At time: 1053.5275392532349 and batch: 1300, loss is 3.7758541345596313 and perplexity is 43.6347623620091
At time: 1054.8861508369446 and batch: 1350, loss is 3.6485953187942504 and perplexity is 38.420659348714196
At time: 1056.2438523769379 and batch: 1400, loss is 3.6831464529037476 and perplexity is 39.771336043259765
At time: 1057.6038875579834 and batch: 1450, loss is 3.6067655420303346 and perplexity is 36.84668082659753
At time: 1058.965586423874 and batch: 1500, loss is 3.5998632383346556 and perplexity is 36.59322955043337
At time: 1060.3247697353363 and batch: 1550, loss is 3.626086778640747 and perplexity is 37.56552639525727
At time: 1061.6793460845947 and batch: 1600, loss is 3.708226923942566 and perplexity is 40.78143380091656
At time: 1063.0341815948486 and batch: 1650, loss is 3.6673348808288573 and perplexity is 39.1474341301351
At time: 1064.387850522995 and batch: 1700, loss is 3.656174511909485 and perplexity is 38.71296326016779
At time: 1065.7449057102203 and batch: 1750, loss is 3.6491334056854248 and perplexity is 38.44133856496866
At time: 1067.1071991920471 and batch: 1800, loss is 3.6025845527648928 and perplexity is 36.69294685358749
At time: 1068.4646117687225 and batch: 1850, loss is 3.6348737812042238 and perplexity is 37.89706927280978
At time: 1069.8224577903748 and batch: 1900, loss is 3.7441979694366454 and perplexity is 42.27508770600434
At time: 1071.17685008049 and batch: 1950, loss is 3.6931739759445192 and perplexity is 40.1721502601692
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31034673646439 and perplexity of 74.46630464765298
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 1075.528476715088 and batch: 50, loss is 3.9096077823638917 and perplexity is 49.879384562013335
At time: 1076.8838102817535 and batch: 100, loss is 3.872838945388794 and perplexity is 48.078685278156875
At time: 1078.239307641983 and batch: 150, loss is 3.8395399618148804 and perplexity is 46.50407586742369
At time: 1079.5932326316833 and batch: 200, loss is 3.8306683349609374 and perplexity is 46.0933337286124
At time: 1080.9506430625916 and batch: 250, loss is 3.8291794633865357 and perplexity is 46.024757737344416
At time: 1082.3073770999908 and batch: 300, loss is 3.843220019340515 and perplexity is 46.67552882667239
At time: 1083.665554523468 and batch: 350, loss is 3.8683519840240477 and perplexity is 47.86344133160429
At time: 1085.0205483436584 and batch: 400, loss is 3.82835307598114 and perplexity is 45.98673916841078
At time: 1086.3761048316956 and batch: 450, loss is 3.8669412517547608 and perplexity is 47.795966436095426
At time: 1087.7294328212738 and batch: 500, loss is 3.8720777225494385 and perplexity is 48.042100611145614
At time: 1089.085322380066 and batch: 550, loss is 3.853414011001587 and perplexity is 47.15377224151926
At time: 1090.4438343048096 and batch: 600, loss is 3.806128587722778 and perplexity is 44.97598082037578
At time: 1091.8363921642303 and batch: 650, loss is 3.830966739654541 and perplexity is 46.10709024814376
At time: 1093.191888809204 and batch: 700, loss is 3.879265670776367 and perplexity is 48.38866880801411
At time: 1094.5482304096222 and batch: 750, loss is 3.8243502283096316 and perplexity is 45.80302918344848
At time: 1095.9034810066223 and batch: 800, loss is 3.8132995557785034 and perplexity is 45.299661306281195
At time: 1097.2602422237396 and batch: 850, loss is 3.807393808364868 and perplexity is 45.03292137329363
At time: 1098.6198675632477 and batch: 900, loss is 3.74979606628418 and perplexity is 42.512411401953514
At time: 1099.9777710437775 and batch: 950, loss is 3.8620079135894776 and perplexity is 47.5607534404015
At time: 1101.3335163593292 and batch: 1000, loss is 3.829154162406921 and perplexity is 46.02359328061815
At time: 1102.693148612976 and batch: 1050, loss is 3.7750840282440183 and perplexity is 43.601171891710614
At time: 1104.0535888671875 and batch: 1100, loss is 3.7697230529785157 and perplexity is 43.36805251956792
At time: 1105.4228148460388 and batch: 1150, loss is 3.7695995235443114 and perplexity is 43.36269561945186
At time: 1106.785855770111 and batch: 1200, loss is 3.8099392461776733 and perplexity is 45.14769588790192
At time: 1108.137963294983 and batch: 1250, loss is 3.8022511291503904 and perplexity is 44.80192598127781
At time: 1109.501136302948 and batch: 1300, loss is 3.7740628862380983 and perplexity is 43.55667162799574
At time: 1110.8553643226624 and batch: 1350, loss is 3.6444650411605837 and perplexity is 38.26229862074732
At time: 1112.2106037139893 and batch: 1400, loss is 3.6791525936126708 and perplexity is 39.61281169597076
At time: 1113.5640828609467 and batch: 1450, loss is 3.601585922241211 and perplexity is 36.6563224470245
At time: 1114.92050075531 and batch: 1500, loss is 3.5949616289138793 and perplexity is 36.41430270472648
At time: 1116.2766325473785 and batch: 1550, loss is 3.6218953704833985 and perplexity is 37.40840345470311
At time: 1117.633368730545 and batch: 1600, loss is 3.7044972562789917 and perplexity is 40.629615897145854
At time: 1118.9868850708008 and batch: 1650, loss is 3.6620873689651487 and perplexity is 38.94254555288069
At time: 1120.3409595489502 and batch: 1700, loss is 3.6498940658569334 and perplexity is 38.470590484129
At time: 1121.6950614452362 and batch: 1750, loss is 3.6433864879608153 and perplexity is 38.221052942966644
At time: 1123.049252986908 and batch: 1800, loss is 3.597108497619629 and perplexity is 36.49256340931481
At time: 1124.4029965400696 and batch: 1850, loss is 3.629613847732544 and perplexity is 37.69825653891742
At time: 1125.7592616081238 and batch: 1900, loss is 3.738289489746094 and perplexity is 42.02604267215523
At time: 1127.1131582260132 and batch: 1950, loss is 3.6889940023422243 and perplexity is 40.00458219156747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.309695789425872 and perplexity of 74.4178468006303
Finished Training.
Improved accuracyfrom -10000000 to -74.4178468006303
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa20428cb38>
ELAPSED
1173.1530220508575


RESULTS SO FAR:
[{'best_accuracy': -74.4178468006303, 'params': {'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'dropout': 0.9649993788704626, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.2039606990300309, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.242833137512207 and batch: 50, loss is 8.180068063735963 and perplexity is 3569.0975786711747
At time: 3.8464930057525635 and batch: 100, loss is 7.433834352493286 and perplexity is 1692.2839622830022
At time: 5.4507505893707275 and batch: 150, loss is 7.167388973236084 and perplexity is 1296.4551007231478
At time: 7.0568201541900635 and batch: 200, loss is 7.063237028121948 and perplexity is 1168.2206148415762
At time: 8.660010814666748 and batch: 250, loss is 6.952105865478516 and perplexity is 1045.3487758183837
At time: 10.26702356338501 and batch: 300, loss is 6.8074316310882566 and perplexity is 904.5446166961323
At time: 11.870371103286743 and batch: 350, loss is 6.732621479034424 and perplexity is 839.3447089775443
At time: 13.476085186004639 and batch: 400, loss is 6.692210865020752 and perplexity is 806.1024672591936
At time: 15.083103895187378 and batch: 450, loss is 6.590072736740113 and perplexity is 727.8338082320788
At time: 16.690298557281494 and batch: 500, loss is 6.570393629074097 and perplexity is 713.6507015170955
At time: 18.29646897315979 and batch: 550, loss is 6.519819173812866 and perplexity is 678.455691690797
At time: 19.90321135520935 and batch: 600, loss is 6.562336912155152 and perplexity is 707.9241195372588
At time: 21.509626865386963 and batch: 650, loss is 6.638604364395142 and perplexity is 764.0279439856922
At time: 23.116039514541626 and batch: 700, loss is 6.509945707321167 and perplexity is 671.7899433253241
At time: 24.72315764427185 and batch: 750, loss is 6.446128826141358 and perplexity is 630.2577269585818
At time: 26.330447673797607 and batch: 800, loss is 6.43913007736206 and perplexity is 625.8621113085534
At time: 27.9365074634552 and batch: 850, loss is 6.491015520095825 and perplexity is 659.1924466004466
At time: 29.540438652038574 and batch: 900, loss is 6.47990463256836 and perplexity is 651.9087724412486
At time: 31.145444631576538 and batch: 950, loss is 6.48160228729248 and perplexity is 653.0164283911321
At time: 32.75179982185364 and batch: 1000, loss is 6.47696930885315 and perplexity is 649.9980148792848
At time: 34.35932183265686 and batch: 1050, loss is 6.384714479446411 and perplexity is 592.7154759858503
At time: 35.96565532684326 and batch: 1100, loss is 6.44931655883789 and perplexity is 632.2700257533605
At time: 37.572049140930176 and batch: 1150, loss is 6.358360300064087 and perplexity is 577.2989827966791
At time: 39.18055701255798 and batch: 1200, loss is 6.4498334407806395 and perplexity is 632.5969191879929
At time: 40.7942636013031 and batch: 1250, loss is 6.3785058212280275 and perplexity is 589.0469084003345
At time: 42.41109251976013 and batch: 1300, loss is 6.388986701965332 and perplexity is 595.253105188273
At time: 44.02772808074951 and batch: 1350, loss is 6.399197626113891 and perplexity is 601.3623268134811
At time: 45.64494228363037 and batch: 1400, loss is 6.425560550689697 and perplexity is 617.4268195874982
At time: 47.26051712036133 and batch: 1450, loss is 6.424694900512695 and perplexity is 616.8925752195637
At time: 48.87587237358093 and batch: 1500, loss is 6.415750503540039 and perplexity is 611.3994461227835
At time: 50.49330973625183 and batch: 1550, loss is 6.381971111297608 and perplexity is 591.0916675982406
At time: 52.10909414291382 and batch: 1600, loss is 6.363876323699952 and perplexity is 580.4921763999653
At time: 53.724475622177124 and batch: 1650, loss is 6.368245782852173 and perplexity is 583.0341627613793
At time: 55.34393668174744 and batch: 1700, loss is 6.3944040966033935 and perplexity is 598.4865767563429
At time: 56.966739892959595 and batch: 1750, loss is 6.408438692092895 and perplexity is 606.9453123909575
At time: 58.589508056640625 and batch: 1800, loss is 6.414389638900757 and perplexity is 610.5679801207385
At time: 60.2096061706543 and batch: 1850, loss is 6.358265419006347 and perplexity is 577.2442106570197
At time: 61.82881045341492 and batch: 1900, loss is 6.312534885406494 and perplexity is 551.4410184163781
At time: 63.44830083847046 and batch: 1950, loss is 6.265228319168091 and perplexity is 525.9616593797896
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.35525753997093 and perplexity of 575.510538542565
finished 1 epochs...
Completing Train Step...
At time: 67.86762690544128 and batch: 50, loss is 6.117591543197632 and perplexity is 453.77049073207957
At time: 69.21869039535522 and batch: 100, loss is 5.93625412940979 and perplexity is 378.51440467156476
At time: 70.57112240791321 and batch: 150, loss is 5.771095027923584 and perplexity is 320.8889226615114
At time: 71.92347836494446 and batch: 200, loss is 5.692243661880493 and perplexity is 296.5582512021104
At time: 73.27746939659119 and batch: 250, loss is 5.653132581710816 and perplexity is 285.1834284137423
At time: 74.63121938705444 and batch: 300, loss is 5.616846046447754 and perplexity is 275.020611687226
At time: 76.00200891494751 and batch: 350, loss is 5.554618473052979 and perplexity is 258.42834833064074
At time: 77.35405564308167 and batch: 400, loss is 5.496514329910278 and perplexity is 243.84050167985734
At time: 78.70465540885925 and batch: 450, loss is 5.41356499671936 and perplexity is 224.4302563366721
At time: 80.05584788322449 and batch: 500, loss is 5.390328006744385 and perplexity is 219.27529753597102
At time: 81.41310214996338 and batch: 550, loss is 5.331172256469727 and perplexity is 206.68011430455917
At time: 82.76620292663574 and batch: 600, loss is 5.345527439117432 and perplexity is 209.66844277836563
At time: 84.11953020095825 and batch: 650, loss is 5.405612192153931 and perplexity is 222.65248487385776
At time: 85.47231698036194 and batch: 700, loss is 5.346115951538086 and perplexity is 209.79187157728808
At time: 86.82752799987793 and batch: 750, loss is 5.261825895309448 and perplexity is 192.83326340114718
At time: 88.18171095848083 and batch: 800, loss is 5.2537600040435795 and perplexity is 191.2841471662676
At time: 89.5358407497406 and batch: 850, loss is 5.256677522659301 and perplexity is 191.84303711599867
At time: 90.89117431640625 and batch: 900, loss is 5.254288558959961 and perplexity is 191.3852780669411
At time: 92.24679899215698 and batch: 950, loss is 5.265184049606323 and perplexity is 193.48191578102478
At time: 93.6007091999054 and batch: 1000, loss is 5.222563819885254 and perplexity is 185.40893033116956
At time: 94.95467567443848 and batch: 1050, loss is 5.130327196121216 and perplexity is 169.07242883857563
At time: 96.30759167671204 and batch: 1100, loss is 5.2022936725616455 and perplexity is 181.68849823793573
At time: 97.66115427017212 and batch: 1150, loss is 5.094571657180786 and perplexity is 163.13395239945962
At time: 99.0146541595459 and batch: 1200, loss is 5.165039768218994 and perplexity is 175.04441963819602
At time: 100.36827158927917 and batch: 1250, loss is 5.118128490447998 and perplexity is 167.02249274582297
At time: 101.72140884399414 and batch: 1300, loss is 5.137020540237427 and perplexity is 170.20788454412647
At time: 103.0740134716034 and batch: 1350, loss is 5.066339139938354 and perplexity is 158.5926777240178
At time: 104.42818355560303 and batch: 1400, loss is 5.060321559906006 and perplexity is 157.64119926334732
At time: 105.78064012527466 and batch: 1450, loss is 5.018753547668457 and perplexity is 151.22269439215032
At time: 107.13490986824036 and batch: 1500, loss is 4.97025972366333 and perplexity is 144.06429941991243
At time: 108.48904180526733 and batch: 1550, loss is 4.962546396255493 and perplexity is 142.95735889619837
At time: 109.84236693382263 and batch: 1600, loss is 5.004111137390137 and perplexity is 149.02456190948885
At time: 111.19741368293762 and batch: 1650, loss is 4.989221649169922 and perplexity is 146.82209990620032
At time: 112.55215239524841 and batch: 1700, loss is 5.001347904205322 and perplexity is 148.61334070636065
At time: 113.90401911735535 and batch: 1750, loss is 4.9898747539520265 and perplexity is 146.91802144176492
At time: 115.2562882900238 and batch: 1800, loss is 4.946535806655884 and perplexity is 140.68675266842797
At time: 116.60875630378723 and batch: 1850, loss is 4.95121470451355 and perplexity is 141.34655398186442
At time: 117.96193289756775 and batch: 1900, loss is 5.029694414138794 and perplexity is 152.8862856691462
At time: 119.31389999389648 and batch: 1950, loss is 4.946653156280518 and perplexity is 140.70326317477642
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.7212433571039245 and perplexity of 112.30780460006349
finished 2 epochs...
Completing Train Step...
At time: 123.62958526611328 and batch: 50, loss is 4.957748928070068 and perplexity is 142.27316801926452
At time: 125.00812339782715 and batch: 100, loss is 4.886677160263061 and perplexity is 132.51252380770742
At time: 126.36885952949524 and batch: 150, loss is 4.817286233901978 and perplexity is 123.62913457858191
At time: 127.7225821018219 and batch: 200, loss is 4.799426746368408 and perplexity is 121.4407811921616
At time: 129.0767252445221 and batch: 250, loss is 4.822143716812134 and perplexity is 124.23112187483247
At time: 130.42986154556274 and batch: 300, loss is 4.843354272842407 and perplexity is 126.8942767007568
At time: 131.7816939353943 and batch: 350, loss is 4.847454919815063 and perplexity is 127.41569367517737
At time: 133.13625717163086 and batch: 400, loss is 4.803655624389648 and perplexity is 121.9554268625414
At time: 134.48863101005554 and batch: 450, loss is 4.768778076171875 and perplexity is 117.77524162576196
At time: 135.84288430213928 and batch: 500, loss is 4.775552988052368 and perplexity is 118.57586753210886
At time: 137.19624781608582 and batch: 550, loss is 4.738357067108154 and perplexity is 114.24634832375021
At time: 138.54849529266357 and batch: 600, loss is 4.712459392547608 and perplexity is 111.32561689136708
At time: 139.90030169487 and batch: 650, loss is 4.78209225654602 and perplexity is 119.35380777463783
At time: 141.2540180683136 and batch: 700, loss is 4.7927835750579835 and perplexity is 120.63670305016315
At time: 142.60795760154724 and batch: 750, loss is 4.739988307952881 and perplexity is 114.43286371790242
At time: 143.98057675361633 and batch: 800, loss is 4.737600536346435 and perplexity is 114.15995013239474
At time: 145.3302822113037 and batch: 850, loss is 4.737538499832153 and perplexity is 114.15286826668732
At time: 146.68726897239685 and batch: 900, loss is 4.72010648727417 and perplexity is 112.18019779527494
At time: 148.04719257354736 and batch: 950, loss is 4.775006055831909 and perplexity is 118.5110323014412
At time: 149.39954018592834 and batch: 1000, loss is 4.7462492847442626 and perplexity is 115.15157278443289
At time: 150.75682425498962 and batch: 1050, loss is 4.672972917556763 and perplexity is 107.01541800185969
At time: 152.1145555973053 and batch: 1100, loss is 4.727901792526245 and perplexity is 113.05809396908171
At time: 153.47375392913818 and batch: 1150, loss is 4.664310178756714 and perplexity is 106.09237519980049
At time: 154.83018970489502 and batch: 1200, loss is 4.7407075309753415 and perplexity is 114.51519607212762
At time: 156.18516063690186 and batch: 1250, loss is 4.712025833129883 and perplexity is 111.27736108336572
At time: 157.54122710227966 and batch: 1300, loss is 4.717007904052735 and perplexity is 111.83313609407583
At time: 158.89535903930664 and batch: 1350, loss is 4.610593023300171 and perplexity is 100.54375675087864
At time: 160.25012063980103 and batch: 1400, loss is 4.612267150878906 and perplexity is 100.71222080273627
At time: 161.60501503944397 and batch: 1450, loss is 4.5650779724121096 and perplexity is 96.07008454072093
At time: 162.9576771259308 and batch: 1500, loss is 4.545739965438843 and perplexity is 94.23012845632493
At time: 164.3123550415039 and batch: 1550, loss is 4.552225713729858 and perplexity is 94.84326753448396
At time: 165.6659517288208 and batch: 1600, loss is 4.621322050094604 and perplexity is 101.62830105989381
At time: 167.02072501182556 and batch: 1650, loss is 4.594572877883911 and perplexity is 98.94586455382586
At time: 168.3751504421234 and batch: 1700, loss is 4.6071333408355715 and perplexity is 100.19650830975691
At time: 169.72830510139465 and batch: 1750, loss is 4.591677942276001 and perplexity is 98.65983686290541
At time: 171.08025312423706 and batch: 1800, loss is 4.555165023803711 and perplexity is 95.12245140917106
At time: 172.4343991279602 and batch: 1850, loss is 4.588520431518555 and perplexity is 98.34880866253648
At time: 173.78678226470947 and batch: 1900, loss is 4.680014238357544 and perplexity is 107.77160705115054
At time: 175.14178371429443 and batch: 1950, loss is 4.607275848388672 and perplexity is 100.21078808644917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.536683264444041 and perplexity of 93.38056727600178
finished 3 epochs...
Completing Train Step...
At time: 179.4470920562744 and batch: 50, loss is 4.6182050704956055 and perplexity is 101.31202089429102
At time: 180.818829536438 and batch: 100, loss is 4.5486453342437745 and perplexity is 94.50429982363501
At time: 182.17286562919617 and batch: 150, loss is 4.493202590942383 and perplexity is 89.4073229433071
At time: 183.52685713768005 and batch: 200, loss is 4.488539419174194 and perplexity is 88.9913718186031
At time: 184.88725519180298 and batch: 250, loss is 4.499704647064209 and perplexity is 89.99054840238244
At time: 186.24682712554932 and batch: 300, loss is 4.5295540237426755 and perplexity is 92.71720218943312
At time: 187.60068798065186 and batch: 350, loss is 4.5427225399017335 and perplexity is 93.94622460512969
At time: 188.9551339149475 and batch: 400, loss is 4.492429552078247 and perplexity is 89.33823431547125
At time: 190.30855345726013 and batch: 450, loss is 4.484966936111451 and perplexity is 88.67401885661323
At time: 191.66180109977722 and batch: 500, loss is 4.499253225326538 and perplexity is 89.94993388047746
At time: 193.0168240070343 and batch: 550, loss is 4.462278928756714 and perplexity is 86.684832725752
At time: 194.36965131759644 and batch: 600, loss is 4.433932285308838 and perplexity is 84.26210894953846
At time: 195.72282814979553 and batch: 650, loss is 4.498302764892578 and perplexity is 89.86448064368005
At time: 197.07581543922424 and batch: 700, loss is 4.529863605499267 and perplexity is 92.74591018726012
At time: 198.42966842651367 and batch: 750, loss is 4.47465950012207 and perplexity is 87.76471144791506
At time: 199.7923891544342 and batch: 800, loss is 4.47453049659729 and perplexity is 87.75339022104178
At time: 201.1531183719635 and batch: 850, loss is 4.471689872741699 and perplexity is 87.50446955973659
At time: 202.51364588737488 and batch: 900, loss is 4.444921016693115 and perplexity is 85.19314873497169
At time: 203.87178492546082 and batch: 950, loss is 4.516006107330322 and perplexity is 91.4695479254648
At time: 205.22470903396606 and batch: 1000, loss is 4.49123685836792 and perplexity is 89.2317446826927
At time: 206.57803773880005 and batch: 1050, loss is 4.424463376998902 and perplexity is 83.46800435100026
At time: 207.93133449554443 and batch: 1100, loss is 4.470096893310547 and perplexity is 87.36518770561173
At time: 209.28579545021057 and batch: 1150, loss is 4.429186029434204 and perplexity is 83.86312700411554
At time: 210.63843297958374 and batch: 1200, loss is 4.495959596633911 and perplexity is 89.65415955013898
At time: 212.02544808387756 and batch: 1250, loss is 4.480189619064331 and perplexity is 88.25140523808204
At time: 213.37676787376404 and batch: 1300, loss is 4.475860710144043 and perplexity is 87.87019864233544
At time: 214.72821807861328 and batch: 1350, loss is 4.35974419593811 and perplexity is 78.23711849041456
At time: 216.0782186985016 and batch: 1400, loss is 4.371838855743408 and perplexity is 79.18911525633727
At time: 217.42820715904236 and batch: 1450, loss is 4.321023492813111 and perplexity is 75.2656227076019
At time: 218.7767355442047 and batch: 1500, loss is 4.309561629295349 and perplexity is 74.40786356228153
At time: 220.12656426429749 and batch: 1550, loss is 4.321409378051758 and perplexity is 75.294672204908
At time: 221.47685527801514 and batch: 1600, loss is 4.400514249801636 and perplexity is 81.49276552982603
At time: 222.8343539237976 and batch: 1650, loss is 4.368898077011108 and perplexity is 78.95657967579079
At time: 224.1956605911255 and batch: 1700, loss is 4.377774076461792 and perplexity is 79.66051768878485
At time: 225.5499665737152 and batch: 1750, loss is 4.368121538162232 and perplexity is 78.89529062404279
At time: 226.90387153625488 and batch: 1800, loss is 4.331793632507324 and perplexity is 76.08062494424273
At time: 228.2610683441162 and batch: 1850, loss is 4.37321738243103 and perplexity is 79.29835484263053
At time: 229.618727684021 and batch: 1900, loss is 4.461878719329834 and perplexity is 86.65014757965187
At time: 230.97793006896973 and batch: 1950, loss is 4.392271480560303 and perplexity is 80.82380031929073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.46543706849564 and perplexity of 86.95902828679549
finished 4 epochs...
Completing Train Step...
At time: 235.26635003089905 and batch: 50, loss is 4.406473779678345 and perplexity is 81.97987412818118
At time: 236.64324140548706 and batch: 100, loss is 4.337531185150146 and perplexity is 76.51839620184315
At time: 238.00048065185547 and batch: 150, loss is 4.288059072494507 and perplexity is 72.82498322469098
At time: 239.35721707344055 and batch: 200, loss is 4.286473608016967 and perplexity is 72.7096132823506
At time: 240.71061158180237 and batch: 250, loss is 4.291218328475952 and perplexity is 73.05541980094452
At time: 242.06479668617249 and batch: 300, loss is 4.31866572380066 and perplexity is 75.08837279396812
At time: 243.41759872436523 and batch: 350, loss is 4.338135986328125 and perplexity is 76.56468861544515
At time: 244.79436993598938 and batch: 400, loss is 4.284126281738281 and perplexity is 72.53914025256583
At time: 246.1507487297058 and batch: 450, loss is 4.294424457550049 and perplexity is 73.29002078594768
At time: 247.5040454864502 and batch: 500, loss is 4.306601095199585 and perplexity is 74.18790230726904
At time: 248.85626602172852 and batch: 550, loss is 4.271865434646607 and perplexity is 71.65517907585482
At time: 250.20840668678284 and batch: 600, loss is 4.2423844909667965 and perplexity is 69.5735517109023
At time: 251.56270623207092 and batch: 650, loss is 4.304390287399292 and perplexity is 74.02406828365999
At time: 252.92050862312317 and batch: 700, loss is 4.342456035614013 and perplexity is 76.89616733048835
At time: 254.27814149856567 and batch: 750, loss is 4.291270351409912 and perplexity is 73.05922045708401
At time: 255.63251161575317 and batch: 800, loss is 4.290074272155762 and perplexity is 72.97188807780597
At time: 256.9865791797638 and batch: 850, loss is 4.286573963165283 and perplexity is 72.71691043252271
At time: 258.3402478694916 and batch: 900, loss is 4.252938313484192 and perplexity is 70.31170695579323
At time: 259.6984541416168 and batch: 950, loss is 4.334173717498779 and perplexity is 76.26191895981287
At time: 261.05486488342285 and batch: 1000, loss is 4.313585615158081 and perplexity is 74.70788298545328
At time: 262.40890645980835 and batch: 1050, loss is 4.255861349105835 and perplexity is 70.517531249165
At time: 263.76437425613403 and batch: 1100, loss is 4.291940832138062 and perplexity is 73.10822168176688
At time: 265.1192328929901 and batch: 1150, loss is 4.257806181907654 and perplexity is 70.65480950539968
At time: 266.47375440597534 and batch: 1200, loss is 4.325905685424805 and perplexity is 75.6339824446138
At time: 267.83270025253296 and batch: 1250, loss is 4.309863128662109 and perplexity is 74.43030086827439
At time: 269.1927545070648 and batch: 1300, loss is 4.300567007064819 and perplexity is 73.74159385267033
At time: 270.5473268032074 and batch: 1350, loss is 4.1827160215377805 and perplexity is 65.54362959212585
At time: 271.9016137123108 and batch: 1400, loss is 4.206822633743286 and perplexity is 67.14286305777351
At time: 273.25565218925476 and batch: 1450, loss is 4.152548899650574 and perplexity is 63.5958934363493
At time: 274.61278557777405 and batch: 1500, loss is 4.142287616729736 and perplexity is 62.94665468916096
At time: 275.9703187942505 and batch: 1550, loss is 4.157286505699158 and perplexity is 63.89790055626077
At time: 277.32721281051636 and batch: 1600, loss is 4.243742389678955 and perplexity is 69.6680897191642
At time: 278.6815996170044 and batch: 1650, loss is 4.206212363243103 and perplexity is 67.10190024961953
At time: 280.0355498790741 and batch: 1700, loss is 4.215948915481567 and perplexity is 67.75843239986834
At time: 281.38990330696106 and batch: 1750, loss is 4.2084585332870486 and perplexity is 67.25279192859577
At time: 282.74913334846497 and batch: 1800, loss is 4.167885308265686 and perplexity is 64.57874347500244
At time: 284.1076760292053 and batch: 1850, loss is 4.213900632858277 and perplexity is 67.61978602215922
At time: 285.4632682800293 and batch: 1900, loss is 4.301636343002319 and perplexity is 73.82049056509246
At time: 286.81735038757324 and batch: 1950, loss is 4.2304276275634765 and perplexity is 68.74662384030528
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.441008244004361 and perplexity of 84.86045860421244
finished 5 epochs...
Completing Train Step...
At time: 291.16547107696533 and batch: 50, loss is 4.249188351631164 and perplexity is 70.04853448864294
At time: 292.52234745025635 and batch: 100, loss is 4.181180644035339 and perplexity is 65.44307259405232
At time: 293.8776824474335 and batch: 150, loss is 4.137942643165588 and perplexity is 62.673746457459174
At time: 295.23255705833435 and batch: 200, loss is 4.136401286125183 and perplexity is 62.57721824843654
At time: 296.59049367904663 and batch: 250, loss is 4.133916101455688 and perplexity is 62.421895387923115
At time: 297.9464032649994 and batch: 300, loss is 4.163468332290649 and perplexity is 64.29412974530509
At time: 299.30502676963806 and batch: 350, loss is 4.182768316268921 and perplexity is 65.54705726823724
At time: 300.6591863632202 and batch: 400, loss is 4.128845000267029 and perplexity is 62.10614890784446
At time: 302.013432264328 and batch: 450, loss is 4.149010782241821 and perplexity is 63.37128128505134
At time: 303.3658525943756 and batch: 500, loss is 4.164107694625854 and perplexity is 64.33525013425219
At time: 304.7191390991211 and batch: 550, loss is 4.1266453123092655 and perplexity is 61.96968490412648
At time: 306.0777471065521 and batch: 600, loss is 4.1013256502151485 and perplexity is 60.420330755490454
At time: 307.4376211166382 and batch: 650, loss is 4.159610676765442 and perplexity is 64.04658292262788
At time: 308.7934846878052 and batch: 700, loss is 4.198863091468811 and perplexity is 66.61055786399848
At time: 310.1471405029297 and batch: 750, loss is 4.152497868537903 and perplexity is 63.59264814995195
At time: 311.5001790523529 and batch: 800, loss is 4.150002808570862 and perplexity is 63.434178457258376
At time: 312.8771262168884 and batch: 850, loss is 4.150027861595154 and perplexity is 63.43576769517976
At time: 314.2353174686432 and batch: 900, loss is 4.112615160942077 and perplexity is 61.10631163608651
At time: 315.59156680107117 and batch: 950, loss is 4.195092425346375 and perplexity is 66.35986462733942
At time: 316.9450566768646 and batch: 1000, loss is 4.172350559234619 and perplexity is 64.86774853173853
At time: 318.2985167503357 and batch: 1050, loss is 4.126349492073059 and perplexity is 61.9513557285047
At time: 319.6532130241394 and batch: 1100, loss is 4.157605876922608 and perplexity is 63.918310966012555
At time: 321.0099415779114 and batch: 1150, loss is 4.122517986297607 and perplexity is 61.71444290748678
At time: 322.36643838882446 and batch: 1200, loss is 4.192762818336487 and perplexity is 66.20545215155526
At time: 323.72312355041504 and batch: 1250, loss is 4.178290147781372 and perplexity is 65.254182762061
At time: 325.0831139087677 and batch: 1300, loss is 4.167075080871582 and perplexity is 64.52644119919174
At time: 326.4435076713562 and batch: 1350, loss is 4.046928925514221 and perplexity is 57.22145557470824
At time: 327.80700945854187 and batch: 1400, loss is 4.075383090972901 and perplexity is 58.873029995172985
At time: 329.17667055130005 and batch: 1450, loss is 4.027299275398255 and perplexity is 56.1091710165247
At time: 330.5339665412903 and batch: 1500, loss is 4.012153224945068 and perplexity is 55.26574211346911
At time: 331.88810634613037 and batch: 1550, loss is 4.035378313064575 and perplexity is 56.564315210501924
At time: 333.24367904663086 and batch: 1600, loss is 4.121124720573425 and perplexity is 61.62851816139824
At time: 334.602707862854 and batch: 1650, loss is 4.082708144187928 and perplexity is 59.30586139398589
At time: 335.96263670921326 and batch: 1700, loss is 4.089262547492981 and perplexity is 59.6958526116044
At time: 337.3201925754547 and batch: 1750, loss is 4.08669303894043 and perplexity is 59.54266050626541
At time: 338.678683757782 and batch: 1800, loss is 4.042284722328186 and perplexity is 56.956323648231496
At time: 340.03199577331543 and batch: 1850, loss is 4.085900287628174 and perplexity is 59.49547668900148
At time: 341.39061403274536 and batch: 1900, loss is 4.172051448822021 and perplexity is 64.84834881418428
At time: 342.7485363483429 and batch: 1950, loss is 4.102857551574707 and perplexity is 60.51295967338787
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.439952477743459 and perplexity of 84.77091307302638
finished 6 epochs...
Completing Train Step...
At time: 347.12736463546753 and batch: 50, loss is 4.124392490386963 and perplexity is 61.83023537591134
At time: 348.4826428890228 and batch: 100, loss is 4.058147253990174 and perplexity is 57.86699884728711
At time: 349.8372106552124 and batch: 150, loss is 4.017195353507995 and perplexity is 55.545102784690634
At time: 351.19426012039185 and batch: 200, loss is 4.018864026069641 and perplexity is 55.637866748456915
At time: 352.5547037124634 and batch: 250, loss is 4.016209306716919 and perplexity is 55.49035970838266
At time: 353.90986609458923 and batch: 300, loss is 4.039153003692627 and perplexity is 56.77823148088469
At time: 355.26409101486206 and batch: 350, loss is 4.062392148971558 and perplexity is 58.11316027535249
At time: 356.6190187931061 and batch: 400, loss is 4.006208643913269 and perplexity is 54.93818499072419
At time: 357.9733257293701 and batch: 450, loss is 4.030795722007752 and perplexity is 56.30569710856803
At time: 359.33537435531616 and batch: 500, loss is 4.0529002714157105 and perplexity is 57.56416688448235
At time: 360.69492959976196 and batch: 550, loss is 4.011024098396302 and perplexity is 55.20337531344242
At time: 362.04971051216125 and batch: 600, loss is 3.9868437004089357 and perplexity is 53.88454490861795
At time: 363.4049758911133 and batch: 650, loss is 4.047358779907227 and perplexity is 57.24605775606025
At time: 364.7584590911865 and batch: 700, loss is 4.08432970046997 and perplexity is 59.40210719899672
At time: 366.1159965991974 and batch: 750, loss is 4.043828859329223 and perplexity is 57.04433995214703
At time: 367.47805643081665 and batch: 800, loss is 4.037057867050171 and perplexity is 56.65939785742398
At time: 368.83601450920105 and batch: 850, loss is 4.041302108764649 and perplexity is 56.900385079584524
At time: 370.1914050579071 and batch: 900, loss is 3.997810878753662 and perplexity is 54.47875879152717
At time: 371.55644130706787 and batch: 950, loss is 4.083388781547546 and perplexity is 59.346240919242845
At time: 372.9195284843445 and batch: 1000, loss is 4.063607640266419 and perplexity is 58.183839261928625
At time: 374.28667664527893 and batch: 1050, loss is 4.019886617660522 and perplexity is 55.69479066312626
At time: 375.6566834449768 and batch: 1100, loss is 4.0437541103363035 and perplexity is 57.04007610454497
At time: 377.0153577327728 and batch: 1150, loss is 4.016498236656189 and perplexity is 55.50639485104812
At time: 378.37013506889343 and batch: 1200, loss is 4.0841583204269405 and perplexity is 59.39192773561224
At time: 379.7264988422394 and batch: 1250, loss is 4.076424221992493 and perplexity is 58.93435645181693
At time: 381.08055448532104 and batch: 1300, loss is 4.061487884521484 and perplexity is 58.06063436267101
At time: 382.44055795669556 and batch: 1350, loss is 3.939351749420166 and perplexity is 51.385279963874396
At time: 383.80034613609314 and batch: 1400, loss is 3.9721231126785277 and perplexity is 53.09714247015718
At time: 385.15520668029785 and batch: 1450, loss is 3.922899718284607 and perplexity is 50.54680396699545
At time: 386.50983357429504 and batch: 1500, loss is 3.9087644815444946 and perplexity is 49.83733896717521
At time: 387.86333084106445 and batch: 1550, loss is 3.933166208267212 and perplexity is 51.06841520031335
At time: 389.2196846008301 and batch: 1600, loss is 4.019207973480224 and perplexity is 55.657006540007586
At time: 390.57883763313293 and batch: 1650, loss is 3.9802820444107057 and perplexity is 53.53213053668731
At time: 391.93544602394104 and batch: 1700, loss is 3.988398985862732 and perplexity is 53.96841596230726
At time: 393.29050755500793 and batch: 1750, loss is 3.9890498447418214 and perplexity is 54.00355321848391
At time: 394.644659280777 and batch: 1800, loss is 3.9372370624542237 and perplexity is 51.27673099608884
At time: 395.99947142601013 and batch: 1850, loss is 3.983026313781738 and perplexity is 53.67923888302688
At time: 397.3617386817932 and batch: 1900, loss is 4.071567893028259 and perplexity is 58.6488456578826
At time: 398.7223074436188 and batch: 1950, loss is 3.9986891078948976 and perplexity is 54.526624640591464
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.454422351925872 and perplexity of 86.00645503006358
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 403.0513825416565 and batch: 50, loss is 4.0622379064559935 and perplexity is 58.10419744656663
At time: 404.4068145751953 and batch: 100, loss is 4.035290207862854 and perplexity is 56.55933181963464
At time: 405.7641968727112 and batch: 150, loss is 3.9938476419448854 and perplexity is 54.26327386034977
At time: 407.1249084472656 and batch: 200, loss is 3.993273181915283 and perplexity is 54.232110730284944
At time: 408.47919154167175 and batch: 250, loss is 3.993453984260559 and perplexity is 54.24191690955763
At time: 409.83403491973877 and batch: 300, loss is 4.017233471870423 and perplexity is 55.54722011340394
At time: 411.18842816352844 and batch: 350, loss is 4.028493065834045 and perplexity is 56.17619360574766
At time: 412.5437035560608 and batch: 400, loss is 3.967853207588196 and perplexity is 52.87090605897375
At time: 413.9206295013428 and batch: 450, loss is 3.985384283065796 and perplexity is 53.805962225664075
At time: 415.276739358902 and batch: 500, loss is 3.9932163047790525 and perplexity is 54.22902625085388
At time: 416.64842557907104 and batch: 550, loss is 3.9551143550872805 and perplexity is 52.20166312886515
At time: 418.0097224712372 and batch: 600, loss is 3.9150771379470823 and perplexity is 50.15294005666518
At time: 419.36186265945435 and batch: 650, loss is 3.9683375787734985 and perplexity is 52.89652140557664
At time: 420.7231423854828 and batch: 700, loss is 4.005094604492188 and perplexity is 54.877015765712194
At time: 422.08571600914 and batch: 750, loss is 3.954246039390564 and perplexity is 52.15635527898101
At time: 423.4554924964905 and batch: 800, loss is 3.945162787437439 and perplexity is 51.68475105550671
At time: 424.822922706604 and batch: 850, loss is 3.938401207923889 and perplexity is 51.33645932966616
At time: 426.1783425807953 and batch: 900, loss is 3.894992165565491 and perplexity is 49.15566825431165
At time: 427.53456830978394 and batch: 950, loss is 3.9851962518692017 and perplexity is 53.79584597731782
At time: 428.88690090179443 and batch: 1000, loss is 3.9545874881744383 and perplexity is 52.174167043791996
At time: 430.24421072006226 and batch: 1050, loss is 3.9033610725402834 and perplexity is 49.568773678541035
At time: 431.60295057296753 and batch: 1100, loss is 3.908458194732666 and perplexity is 49.82207678493481
At time: 432.95830154418945 and batch: 1150, loss is 3.8963996171951294 and perplexity is 49.22490118927698
At time: 434.31364464759827 and batch: 1200, loss is 3.9385503816604612 and perplexity is 51.344117952345236
At time: 435.6668303012848 and batch: 1250, loss is 3.9283421659469604 and perplexity is 50.82265226615988
At time: 437.02211928367615 and batch: 1300, loss is 3.9172507429122927 and perplexity is 50.26207129732912
At time: 438.3793742656708 and batch: 1350, loss is 3.7840847396850585 and perplexity is 43.99538489579223
At time: 439.7372627258301 and batch: 1400, loss is 3.810931510925293 and perplexity is 45.19251658829071
At time: 441.0917925834656 and batch: 1450, loss is 3.750081653594971 and perplexity is 42.5245541410246
At time: 442.44566321372986 and batch: 1500, loss is 3.7334611320495608 and perplexity is 41.82361499544657
At time: 443.79893136024475 and batch: 1550, loss is 3.757723078727722 and perplexity is 42.85074703986835
At time: 445.1575517654419 and batch: 1600, loss is 3.8283631563186646 and perplexity is 45.9872027325997
At time: 446.51571822166443 and batch: 1650, loss is 3.7811071920394896 and perplexity is 43.864581374577874
At time: 447.8730926513672 and batch: 1700, loss is 3.7805073738098143 and perplexity is 43.83827848829627
At time: 449.2269649505615 and batch: 1750, loss is 3.7697609996795656 and perplexity is 43.36969822531635
At time: 450.5801339149475 and batch: 1800, loss is 3.7177727937698366 and perplexity is 41.172592061961566
At time: 451.93274188041687 and batch: 1850, loss is 3.7501183366775512 and perplexity is 42.52611410136775
At time: 453.28978753089905 and batch: 1900, loss is 3.8256541299819946 and perplexity is 45.86279078295782
At time: 454.64903712272644 and batch: 1950, loss is 3.7493077325820923 and perplexity is 42.491656226847134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.390988939861918 and perplexity of 80.72020695153839
finished 8 epochs...
Completing Train Step...
At time: 458.9595944881439 and batch: 50, loss is 3.977068462371826 and perplexity is 53.3603767637216
At time: 460.33205580711365 and batch: 100, loss is 3.9326545286178587 and perplexity is 51.04229121565626
At time: 461.68848180770874 and batch: 150, loss is 3.8837885093688964 and perplexity is 48.60801861470616
At time: 463.04336619377136 and batch: 200, loss is 3.8830039834976198 and perplexity is 48.56989932129251
At time: 464.4040558338165 and batch: 250, loss is 3.8832380676269533 and perplexity is 48.58127009469383
At time: 465.767050743103 and batch: 300, loss is 3.9070423555374147 and perplexity is 49.75158664895796
At time: 467.1272003650665 and batch: 350, loss is 3.921745481491089 and perplexity is 50.48849464391865
At time: 468.49436831474304 and batch: 400, loss is 3.8629135847091676 and perplexity is 47.60384735273347
At time: 469.853631734848 and batch: 450, loss is 3.8872646570205687 and perplexity is 48.77728128504125
At time: 471.2039325237274 and batch: 500, loss is 3.8973820543289186 and perplexity is 49.27328532340583
At time: 472.55620861053467 and batch: 550, loss is 3.861977982521057 and perplexity is 47.55932991754002
At time: 473.911906003952 and batch: 600, loss is 3.82658597946167 and perplexity is 45.90554791919898
At time: 475.26680040359497 and batch: 650, loss is 3.880353331565857 and perplexity is 48.44132789815464
At time: 476.6214315891266 and batch: 700, loss is 3.9180162954330444 and perplexity is 50.30056428503091
At time: 477.98471450805664 and batch: 750, loss is 3.8683858919143677 and perplexity is 47.865064307438985
At time: 479.3578374385834 and batch: 800, loss is 3.861457462310791 and perplexity is 47.534580766906586
At time: 480.71960067749023 and batch: 850, loss is 3.855928297042847 and perplexity is 47.27247948230279
At time: 482.1157555580139 and batch: 900, loss is 3.8146946001052857 and perplexity is 45.36290044223454
At time: 483.4753043651581 and batch: 950, loss is 3.9077861881256104 and perplexity is 49.78860726728615
At time: 484.839879989624 and batch: 1000, loss is 3.8798187589645385 and perplexity is 48.41543941174308
At time: 486.2092468738556 and batch: 1050, loss is 3.832384023666382 and perplexity is 46.17248341938678
At time: 487.56956219673157 and batch: 1100, loss is 3.8364160442352295 and perplexity is 46.35902764460138
At time: 488.9238660335541 and batch: 1150, loss is 3.8273458671569824 and perplexity is 45.94044423717149
At time: 490.2779817581177 and batch: 1200, loss is 3.87289598941803 and perplexity is 48.081427958311515
At time: 491.6327464580536 and batch: 1250, loss is 3.8662353706359864 and perplexity is 47.7622400706373
At time: 492.99355363845825 and batch: 1300, loss is 3.8568191003799437 and perplexity is 47.3146087264282
At time: 494.35276460647583 and batch: 1350, loss is 3.726866145133972 and perplexity is 41.54869634069302
At time: 495.70839190483093 and batch: 1400, loss is 3.757637391090393 and perplexity is 42.847075417905266
At time: 497.06255745887756 and batch: 1450, loss is 3.6964473867416383 and perplexity is 40.303865672287145
At time: 498.41690731048584 and batch: 1500, loss is 3.68226122379303 and perplexity is 39.7361448772425
At time: 499.7721960544586 and batch: 1550, loss is 3.7114931106567384 and perplexity is 40.91485134287561
At time: 501.1297354698181 and batch: 1600, loss is 3.7847701358795165 and perplexity is 44.02554950134558
At time: 502.4884579181671 and batch: 1650, loss is 3.7413226318359376 and perplexity is 42.15370714542177
At time: 503.8422839641571 and batch: 1700, loss is 3.744284839630127 and perplexity is 42.27876031057044
At time: 505.1958918571472 and batch: 1750, loss is 3.736007933616638 and perplexity is 41.93026719700757
At time: 506.5508427619934 and batch: 1800, loss is 3.6886902809143067 and perplexity is 39.992433787699674
At time: 507.90804624557495 and batch: 1850, loss is 3.7249217414855957 and perplexity is 41.467987394755426
At time: 509.26610803604126 and batch: 1900, loss is 3.804440426826477 and perplexity is 44.900118180469775
At time: 510.6208827495575 and batch: 1950, loss is 3.7307788515090943 and perplexity is 41.711582645078224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.393620832576308 and perplexity of 80.93293369030111
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 514.9178562164307 and batch: 50, loss is 3.9465193557739258 and perplexity is 51.75491253092609
At time: 516.2979214191437 and batch: 100, loss is 3.93921507358551 and perplexity is 51.37825731777023
At time: 517.6553266048431 and batch: 150, loss is 3.9034940242767333 and perplexity is 49.5753643711876
At time: 519.0097193717957 and batch: 200, loss is 3.901795954704285 and perplexity is 49.491253386768264
At time: 520.362690448761 and batch: 250, loss is 3.90366587638855 and perplexity is 49.5838847343491
At time: 521.7162456512451 and batch: 300, loss is 3.9351593923568724 and perplexity is 51.17030546226698
At time: 523.0719497203827 and batch: 350, loss is 3.962149200439453 and perplexity is 52.570188495755566
At time: 524.4317514896393 and batch: 400, loss is 3.9011446237564087 and perplexity is 49.45902869739625
At time: 525.7887289524078 and batch: 450, loss is 3.9243359375 and perplexity is 50.61945241519036
At time: 527.1431274414062 and batch: 500, loss is 3.925995864868164 and perplexity is 50.7035468055967
At time: 528.4986536502838 and batch: 550, loss is 3.8963501691818236 and perplexity is 49.222467175887054
At time: 529.8526759147644 and batch: 600, loss is 3.85035080909729 and perplexity is 47.00955171765681
At time: 531.2085976600647 and batch: 650, loss is 3.894865550994873 and perplexity is 49.14944482447896
At time: 532.5674197673798 and batch: 700, loss is 3.9304347896575926 and perplexity is 50.92911630906836
At time: 533.9216363430023 and batch: 750, loss is 3.8706367301940916 and perplexity is 47.97292216620582
At time: 535.2784831523895 and batch: 800, loss is 3.8634702348709107 and perplexity is 47.63035341868048
At time: 536.6335427761078 and batch: 850, loss is 3.86071316242218 and perplexity is 47.499213947129334
At time: 537.9885876178741 and batch: 900, loss is 3.8219051265716555 and perplexity is 45.69117292288394
At time: 539.3468241691589 and batch: 950, loss is 3.9124276494979857 and perplexity is 50.02023629746475
At time: 540.7060143947601 and batch: 1000, loss is 3.8765504026412962 and perplexity is 48.257458813274184
At time: 542.060295343399 and batch: 1050, loss is 3.827094540596008 and perplexity is 45.92889963410519
At time: 543.4150583744049 and batch: 1100, loss is 3.8289819240570067 and perplexity is 46.01566693548426
At time: 544.7712512016296 and batch: 1150, loss is 3.8156220436096193 and perplexity is 45.404991485102514
At time: 546.1267623901367 and batch: 1200, loss is 3.854676547050476 and perplexity is 47.21334317612849
At time: 547.4868376255035 and batch: 1250, loss is 3.839190182685852 and perplexity is 46.48781255671965
At time: 548.8442738056183 and batch: 1300, loss is 3.8351273918151856 and perplexity is 46.299325447388654
At time: 550.1978578567505 and batch: 1350, loss is 3.7086610794067383 and perplexity is 40.799143127260244
At time: 551.5522699356079 and batch: 1400, loss is 3.734267315864563 and perplexity is 41.85734611185392
At time: 552.9077126979828 and batch: 1450, loss is 3.666693329811096 and perplexity is 39.12232710850497
At time: 554.2647564411163 and batch: 1500, loss is 3.6506006717681885 and perplexity is 38.497783637064416
At time: 555.6249401569366 and batch: 1550, loss is 3.6697409772872924 and perplexity is 39.2417400418154
At time: 556.9801058769226 and batch: 1600, loss is 3.7421528053283692 and perplexity is 42.18871656563728
At time: 558.3343665599823 and batch: 1650, loss is 3.6965785312652586 and perplexity is 40.30915165015674
At time: 559.6880838871002 and batch: 1700, loss is 3.691112084388733 and perplexity is 40.08940497798453
At time: 561.0428988933563 and batch: 1750, loss is 3.687764296531677 and perplexity is 39.955418558995646
At time: 562.4107439517975 and batch: 1800, loss is 3.6405627155303955 and perplexity is 38.113277625503656
At time: 563.7695744037628 and batch: 1850, loss is 3.6707799243927 and perplexity is 39.28253132036418
At time: 565.1236772537231 and batch: 1900, loss is 3.7578374910354615 and perplexity is 42.85564997319815
At time: 566.4769756793976 and batch: 1950, loss is 3.693293809890747 and perplexity is 40.176964535914394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371063090479651 and perplexity of 79.12770691376296
finished 10 epochs...
Completing Train Step...
At time: 570.8108921051025 and batch: 50, loss is 3.9454404640197756 and perplexity is 51.69910469328103
At time: 572.1839995384216 and batch: 100, loss is 3.9145706367492674 and perplexity is 50.12754396457101
At time: 573.5379414558411 and batch: 150, loss is 3.8666688299179075 and perplexity is 47.78294754452042
At time: 574.8927316665649 and batch: 200, loss is 3.8594023418426513 and perplexity is 47.43699178992751
At time: 576.2491767406464 and batch: 250, loss is 3.8555581045150755 and perplexity is 47.25498280239912
At time: 577.6079227924347 and batch: 300, loss is 3.880041074752808 and perplexity is 48.426204124858806
At time: 578.967068195343 and batch: 350, loss is 3.9082635688781737 and perplexity is 49.81238106421753
At time: 580.3252823352814 and batch: 400, loss is 3.8464573717117307 and perplexity is 46.82687881503437
At time: 581.6842625141144 and batch: 450, loss is 3.8707330894470213 and perplexity is 47.97754502387059
At time: 583.041873216629 and batch: 500, loss is 3.875294919013977 and perplexity is 48.19691038057428
At time: 584.41619181633 and batch: 550, loss is 3.84660502910614 and perplexity is 46.83379366044998
At time: 585.7739326953888 and batch: 600, loss is 3.806361951828003 and perplexity is 44.9864778246609
At time: 587.131395816803 and batch: 650, loss is 3.854210810661316 and perplexity is 47.19135932389482
At time: 588.4861516952515 and batch: 700, loss is 3.892175722122192 and perplexity is 49.01741887192601
At time: 589.8414912223816 and batch: 750, loss is 3.8357232856750487 and perplexity is 46.32692315297357
At time: 591.1969799995422 and batch: 800, loss is 3.8295627355575563 and perplexity is 46.04240112705727
At time: 592.5558276176453 and batch: 850, loss is 3.827926664352417 and perplexity is 45.967134068280714
At time: 593.9137079715729 and batch: 900, loss is 3.7892720556259154 and perplexity is 44.2241958013404
At time: 595.26930975914 and batch: 950, loss is 3.8801320791244507 and perplexity is 48.430611321670284
At time: 596.6221866607666 and batch: 1000, loss is 3.8449555444717407 and perplexity is 46.756605715102424
At time: 597.9822642803192 and batch: 1050, loss is 3.79916157245636 and perplexity is 44.66372149618721
At time: 599.344407081604 and batch: 1100, loss is 3.8007850313186644 and perplexity is 44.736290100807246
At time: 600.7181723117828 and batch: 1150, loss is 3.788411564826965 and perplexity is 44.18615765584657
At time: 602.0802376270294 and batch: 1200, loss is 3.8304672479629516 and perplexity is 46.08406589035787
At time: 603.4348523616791 and batch: 1250, loss is 3.8168646335601806 and perplexity is 45.46144633908033
At time: 604.7870221138 and batch: 1300, loss is 3.813778018951416 and perplexity is 45.321340711946696
At time: 606.140722990036 and batch: 1350, loss is 3.687986035346985 and perplexity is 39.9642792085107
At time: 607.4985663890839 and batch: 1400, loss is 3.7156569147109986 and perplexity is 41.08556793534998
At time: 608.858039855957 and batch: 1450, loss is 3.6491567611694338 and perplexity is 38.44223639152135
At time: 610.2179462909698 and batch: 1500, loss is 3.6359608030319213 and perplexity is 37.938286612330366
At time: 611.5726499557495 and batch: 1550, loss is 3.6583070039749144 and perplexity is 38.79560643378689
At time: 612.9336249828339 and batch: 1600, loss is 3.732580099105835 and perplexity is 41.78678324018722
At time: 614.2876069545746 and batch: 1650, loss is 3.688362159729004 and perplexity is 39.97931357554961
At time: 615.6418495178223 and batch: 1700, loss is 3.6853436470031737 and perplexity is 39.85881745977217
At time: 616.9978015422821 and batch: 1750, loss is 3.68451331615448 and perplexity is 39.825735190557914
At time: 618.3518240451813 and batch: 1800, loss is 3.638838610649109 and perplexity is 38.04762295154303
At time: 619.7057950496674 and batch: 1850, loss is 3.67079686164856 and perplexity is 39.2831966642825
At time: 621.0590271949768 and batch: 1900, loss is 3.758200416564941 and perplexity is 42.87120620536202
At time: 622.4135451316833 and batch: 1950, loss is 3.6925259828567505 and perplexity is 40.14612741670172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373371354923692 and perplexity of 79.31056554802186
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 626.7430341243744 and batch: 50, loss is 3.9362535667419434 and perplexity is 51.22632534194975
At time: 628.0971286296844 and batch: 100, loss is 3.9276400279998778 and perplexity is 50.786980278226125
At time: 629.4496574401855 and batch: 150, loss is 3.896024394035339 and perplexity is 49.20643433112547
At time: 630.8029456138611 and batch: 200, loss is 3.8988777112960817 and perplexity is 49.34703639529869
At time: 632.1566722393036 and batch: 250, loss is 3.9034181594848634 and perplexity is 49.57160348914877
At time: 633.5118446350098 and batch: 300, loss is 3.9257488536834715 and perplexity is 50.691024009131205
At time: 634.8664057254791 and batch: 350, loss is 3.950603265762329 and perplexity is 51.96670711580567
At time: 636.2212109565735 and batch: 400, loss is 3.8894292974472044 and perplexity is 48.882980919590466
At time: 637.5754790306091 and batch: 450, loss is 3.9160676193237305 and perplexity is 50.20264021925498
At time: 638.930032491684 and batch: 500, loss is 3.9149589776992797 and perplexity is 50.14701432294003
At time: 640.2853035926819 and batch: 550, loss is 3.8840643119812013 and perplexity is 48.62142668212408
At time: 641.6394138336182 and batch: 600, loss is 3.8287756061553955 and perplexity is 46.00617405894975
At time: 642.9935030937195 and batch: 650, loss is 3.866473650932312 and perplexity is 47.77362222737249
At time: 644.3465597629547 and batch: 700, loss is 3.9028764581680297 and perplexity is 49.54475775810155
At time: 645.7008545398712 and batch: 750, loss is 3.8522972106933593 and perplexity is 47.10114028930646
At time: 647.0565600395203 and batch: 800, loss is 3.848453221321106 and perplexity is 46.9204315503658
At time: 648.4109246730804 and batch: 850, loss is 3.8468626642227175 and perplexity is 46.845861244789454
At time: 649.7658021450043 and batch: 900, loss is 3.813820090293884 and perplexity is 45.32324748170279
At time: 651.1554028987885 and batch: 950, loss is 3.9215844821929933 and perplexity is 50.48036668603439
At time: 652.5093500614166 and batch: 1000, loss is 3.8862791061401367 and perplexity is 48.72923247368906
At time: 653.8632299900055 and batch: 1050, loss is 3.833524103164673 and perplexity is 46.22515373958953
At time: 655.2156443595886 and batch: 1100, loss is 3.8339141035079956 and perplexity is 46.24318508130429
At time: 656.5724053382874 and batch: 1150, loss is 3.824556474685669 and perplexity is 45.8124768664708
At time: 657.9265322685242 and batch: 1200, loss is 3.8597114849090577 and perplexity is 47.45165887402741
At time: 659.281058549881 and batch: 1250, loss is 3.838202977180481 and perplexity is 46.441942177701684
At time: 660.636125087738 and batch: 1300, loss is 3.828764071464539 and perplexity is 46.00564339501501
At time: 661.9898748397827 and batch: 1350, loss is 3.6935173368453977 and perplexity is 40.18594617422595
At time: 663.3439335823059 and batch: 1400, loss is 3.7183410787582396 and perplexity is 41.19599647752317
At time: 664.6991541385651 and batch: 1450, loss is 3.6503871059417725 and perplexity is 38.48956270397321
At time: 666.052716255188 and batch: 1500, loss is 3.6346408033370974 and perplexity is 37.88824112286196
At time: 667.407500743866 and batch: 1550, loss is 3.65376784324646 and perplexity is 38.619906008538436
At time: 668.7630546092987 and batch: 1600, loss is 3.724513783454895 and perplexity is 41.45107364656502
At time: 670.119211435318 and batch: 1650, loss is 3.68126145362854 and perplexity is 39.69643771746664
At time: 671.4748687744141 and batch: 1700, loss is 3.668028655052185 and perplexity is 39.17460303429696
At time: 672.8285973072052 and batch: 1750, loss is 3.6648668336868284 and perplexity is 39.05093554772086
At time: 674.1830451488495 and batch: 1800, loss is 3.62126492023468 and perplexity is 37.38482675019146
At time: 675.5372638702393 and batch: 1850, loss is 3.65280725479126 and perplexity is 38.58282598485829
At time: 676.8915460109711 and batch: 1900, loss is 3.747480216026306 and perplexity is 42.414072935577245
At time: 678.2457582950592 and batch: 1950, loss is 3.6984355783462526 and perplexity is 40.38407719116212
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36421267487282 and perplexity of 78.58750166319763
finished 12 epochs...
Completing Train Step...
At time: 682.5732750892639 and batch: 50, loss is 3.9513421630859376 and perplexity is 52.00511936621713
At time: 683.9337184429169 and batch: 100, loss is 3.929024882316589 and perplexity is 50.85736156976664
At time: 685.3111562728882 and batch: 150, loss is 3.8878421497344973 and perplexity is 48.80545794471337
At time: 686.6641154289246 and batch: 200, loss is 3.8877532720565795 and perplexity is 48.80112042169887
At time: 688.0181925296783 and batch: 250, loss is 3.8884072351455687 and perplexity is 48.83304499076312
At time: 689.3754434585571 and batch: 300, loss is 3.9076843881607055 and perplexity is 49.78353904679039
At time: 690.7293825149536 and batch: 350, loss is 3.9298980236053467 and perplexity is 50.901786623842575
At time: 692.0836501121521 and batch: 400, loss is 3.8710891819000244 and perplexity is 47.99463250774867
At time: 693.4385623931885 and batch: 450, loss is 3.898976306915283 and perplexity is 49.35190203676936
At time: 694.7933328151703 and batch: 500, loss is 3.899357695579529 and perplexity is 49.370727882519034
At time: 696.1476056575775 and batch: 550, loss is 3.8655604028701784 and perplexity is 47.730012975515535
At time: 697.5050168037415 and batch: 600, loss is 3.80975031375885 and perplexity is 45.139166830246644
At time: 698.8589174747467 and batch: 650, loss is 3.844255976676941 and perplexity is 46.72390773810934
At time: 700.2170474529266 and batch: 700, loss is 3.883655571937561 and perplexity is 48.6015572190594
At time: 701.578905582428 and batch: 750, loss is 3.8342703914642335 and perplexity is 46.25966390663602
At time: 702.9350736141205 and batch: 800, loss is 3.830976905822754 and perplexity is 46.107558982961656
At time: 704.2890706062317 and batch: 850, loss is 3.8299234342575073 and perplexity is 46.05901155678653
At time: 705.6426703929901 and batch: 900, loss is 3.7977014923095704 and perplexity is 44.59855646780775
At time: 706.9967892169952 and batch: 950, loss is 3.9048436737060546 and perplexity is 49.64231890583086
At time: 708.3522827625275 and batch: 1000, loss is 3.8693876886367797 and perplexity is 47.91303939861247
At time: 709.7085800170898 and batch: 1050, loss is 3.8175096845626832 and perplexity is 45.49078075069524
At time: 711.0635476112366 and batch: 1100, loss is 3.8195184803009035 and perplexity is 45.58225428225577
At time: 712.4141345024109 and batch: 1150, loss is 3.8109270477294923 and perplexity is 45.19231488569058
At time: 713.7686243057251 and batch: 1200, loss is 3.846406407356262 and perplexity is 46.82449237414918
At time: 715.1214530467987 and batch: 1250, loss is 3.8262158536911013 and perplexity is 45.88856023688544
At time: 716.4759795665741 and batch: 1300, loss is 3.8184726142883303 and perplexity is 45.53460627278558
At time: 717.8296728134155 and batch: 1350, loss is 3.684451656341553 and perplexity is 39.823279618882204
At time: 719.1839294433594 and batch: 1400, loss is 3.711674385070801 and perplexity is 40.92226883085933
At time: 720.5391368865967 and batch: 1450, loss is 3.6445040941238402 and perplexity is 38.263792906067415
At time: 721.8938763141632 and batch: 1500, loss is 3.6309845733642576 and perplexity is 37.74996593702857
At time: 723.2479450702667 and batch: 1550, loss is 3.652115058898926 and perplexity is 38.556128352258725
At time: 724.6018061637878 and batch: 1600, loss is 3.724141502380371 and perplexity is 41.435645068389725
At time: 725.9552698135376 and batch: 1650, loss is 3.681739592552185 and perplexity is 39.71542266782957
At time: 727.3102829456329 and batch: 1700, loss is 3.6707519245147706 and perplexity is 39.28143142968092
At time: 728.6659772396088 and batch: 1750, loss is 3.66917320728302 and perplexity is 39.21946608274547
At time: 730.019650220871 and batch: 1800, loss is 3.626856207847595 and perplexity is 37.59444153108489
At time: 731.3729770183563 and batch: 1850, loss is 3.657989835739136 and perplexity is 38.78330365086743
At time: 732.7273304462433 and batch: 1900, loss is 3.7516489887237547 and perplexity is 42.59125662748604
At time: 734.0818870067596 and batch: 1950, loss is 3.700075387954712 and perplexity is 40.45035371455756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363744265534157 and perplexity of 78.55069916350655
finished 13 epochs...
Completing Train Step...
At time: 738.4066610336304 and batch: 50, loss is 3.9444768953323366 and perplexity is 51.649313047517815
At time: 739.760675907135 and batch: 100, loss is 3.9204503679275513 and perplexity is 50.423148634088385
At time: 741.1155326366425 and batch: 150, loss is 3.879157085418701 and perplexity is 48.38341479236436
At time: 742.470520734787 and batch: 200, loss is 3.8802304887771606 and perplexity is 48.43537759583082
At time: 743.8246486186981 and batch: 250, loss is 3.8811251020431516 and perplexity is 48.4787279151655
At time: 745.1818623542786 and batch: 300, loss is 3.901329698562622 and perplexity is 49.468183164652416
At time: 746.5373911857605 and batch: 350, loss is 3.923813853263855 and perplexity is 50.59303169456311
At time: 747.891574382782 and batch: 400, loss is 3.865439496040344 and perplexity is 47.72424243981434
At time: 749.2460489273071 and batch: 450, loss is 3.8950099897384645 and perplexity is 49.1565444212537
At time: 750.600284576416 and batch: 500, loss is 3.8958415031433105 and perplexity is 49.19743574536187
At time: 751.9890065193176 and batch: 550, loss is 3.861893210411072 and perplexity is 47.555298383676664
At time: 753.3449308872223 and batch: 600, loss is 3.8039338397979736 and perplexity is 44.87737812341657
At time: 754.6987535953522 and batch: 650, loss is 3.834160189628601 and perplexity is 46.25456628764641
At time: 756.0563063621521 and batch: 700, loss is 3.873438010215759 and perplexity is 48.107496156363986
At time: 757.410594701767 and batch: 750, loss is 3.8238797092437746 and perplexity is 45.78148305427346
At time: 758.765722990036 and batch: 800, loss is 3.820754599571228 and perplexity is 45.638634224146216
At time: 760.1193192005157 and batch: 850, loss is 3.8201125288009643 and perplexity is 45.60934039647775
At time: 761.4736049175262 and batch: 900, loss is 3.7876572513580324 and perplexity is 44.152840009540846
At time: 762.8275420665741 and batch: 950, loss is 3.8949356079101562 and perplexity is 49.152888203586095
At time: 764.180698633194 and batch: 1000, loss is 3.8593819332122803 and perplexity is 47.43602367577513
At time: 765.5350708961487 and batch: 1050, loss is 3.8082716703414916 and perplexity is 45.07247141986464
At time: 766.8908240795135 and batch: 1100, loss is 3.811161689758301 and perplexity is 45.20292014631319
At time: 768.2443659305573 and batch: 1150, loss is 3.8032582330703737 and perplexity is 44.8470689045483
At time: 769.5986545085907 and batch: 1200, loss is 3.8395081663131716 and perplexity is 46.50259727050647
At time: 770.9528253078461 and batch: 1250, loss is 3.819931836128235 and perplexity is 45.60109986738413
At time: 772.3129930496216 and batch: 1300, loss is 3.8128514194488528 and perplexity is 45.27936543032832
At time: 773.6749513149261 and batch: 1350, loss is 3.679261417388916 and perplexity is 39.61712274629535
At time: 775.034640789032 and batch: 1400, loss is 3.7074546003341675 and perplexity is 40.7499494964086
At time: 776.3962526321411 and batch: 1450, loss is 3.6405780124664306 and perplexity is 38.11386064633279
At time: 777.7580289840698 and batch: 1500, loss is 3.628255968093872 and perplexity is 37.64710158294647
At time: 779.1149327754974 and batch: 1550, loss is 3.6504676437377928 and perplexity is 38.49266269335465
At time: 780.4694292545319 and batch: 1600, loss is 3.723329014778137 and perplexity is 41.40199279336047
At time: 781.8237533569336 and batch: 1650, loss is 3.681566219329834 and perplexity is 39.70853767387866
At time: 783.1772992610931 and batch: 1700, loss is 3.6718471384048463 and perplexity is 39.32447656651795
At time: 784.530969619751 and batch: 1750, loss is 3.6710558891296388 and perplexity is 39.29337340973465
At time: 785.8846595287323 and batch: 1800, loss is 3.6292783975601197 and perplexity is 37.685612773056626
At time: 787.2385354042053 and batch: 1850, loss is 3.6599922466278074 and perplexity is 38.86104156604535
At time: 788.5929501056671 and batch: 1900, loss is 3.7524348068237305 and perplexity is 42.62473876155516
At time: 789.9486863613129 and batch: 1950, loss is 3.697943787574768 and perplexity is 40.36422155749347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362589991369913 and perplexity of 78.46008242921752
finished 14 epochs...
Completing Train Step...
At time: 794.2170162200928 and batch: 50, loss is 3.936128692626953 and perplexity is 51.21992889929185
At time: 795.5895502567291 and batch: 100, loss is 3.9112211990356447 and perplexity is 49.95992574841743
At time: 796.9438736438751 and batch: 150, loss is 3.870003843307495 and perplexity is 47.942570338505085
At time: 798.2972526550293 and batch: 200, loss is 3.8718512582778932 and perplexity is 48.03122202367939
At time: 799.6500172615051 and batch: 250, loss is 3.8730624151229858 and perplexity is 48.089430609759745
At time: 801.0034084320068 and batch: 300, loss is 3.8942471742630005 and perplexity is 49.119061346601114
At time: 802.3572838306427 and batch: 350, loss is 3.9177037477493286 and perplexity is 50.284845416749924
At time: 803.7119748592377 and batch: 400, loss is 3.8600964450836184 and perplexity is 47.46992938939551
At time: 805.070965051651 and batch: 450, loss is 3.8915704536437987 and perplexity is 48.987759150343386
At time: 806.427895784378 and batch: 500, loss is 3.8934687566757202 and perplexity is 49.080841082970835
At time: 807.7827227115631 and batch: 550, loss is 3.860822319984436 and perplexity is 47.504399128528604
At time: 809.137716293335 and batch: 600, loss is 3.802284560203552 and perplexity is 44.80342378188343
At time: 810.4924771785736 and batch: 650, loss is 3.8289351081848144 and perplexity is 46.013512722328244
At time: 811.8544065952301 and batch: 700, loss is 3.867437410354614 and perplexity is 47.81968669990082
At time: 813.2134683132172 and batch: 750, loss is 3.816634831428528 and perplexity is 45.451000402098856
At time: 814.5671343803406 and batch: 800, loss is 3.8127701663970948 and perplexity is 45.2756864931699
At time: 815.9223923683167 and batch: 850, loss is 3.812456431388855 and perplexity is 45.261484153297005
At time: 817.2762956619263 and batch: 900, loss is 3.779141969680786 and perplexity is 43.77846236772094
At time: 818.6309914588928 and batch: 950, loss is 3.8861342811584474 and perplexity is 48.72217577449382
At time: 820.0201187133789 and batch: 1000, loss is 3.8504723739624023 and perplexity is 47.01526677483839
At time: 821.3744118213654 and batch: 1050, loss is 3.800141143798828 and perplexity is 44.7074942335722
At time: 822.7288327217102 and batch: 1100, loss is 3.803194842338562 and perplexity is 44.84422610613532
At time: 824.0815968513489 and batch: 1150, loss is 3.795875506401062 and perplexity is 44.51719443772453
At time: 825.4353637695312 and batch: 1200, loss is 3.8332602405548095 and perplexity is 46.212958258918896
At time: 826.7892067432404 and batch: 1250, loss is 3.81427930355072 and perplexity is 45.34406529733187
At time: 828.1431171894073 and batch: 1300, loss is 3.807729916572571 and perplexity is 45.048059851724936
At time: 829.4970331192017 and batch: 1350, loss is 3.6746306085586546 and perplexity is 39.43408755203888
At time: 830.8501822948456 and batch: 1400, loss is 3.7034164476394653 and perplexity is 40.58572677940481
At time: 832.2050852775574 and batch: 1450, loss is 3.6367170286178587 and perplexity is 37.96698736610763
At time: 833.5604810714722 and batch: 1500, loss is 3.625210404396057 and perplexity is 37.5326193569828
At time: 834.9172570705414 and batch: 1550, loss is 3.64812726020813 and perplexity is 38.40268043714182
At time: 836.2720694541931 and batch: 1600, loss is 3.7217476654052732 and perplexity is 41.33657351701983
At time: 837.6272037029266 and batch: 1650, loss is 3.6807079029083254 and perplexity is 39.67446980651558
At time: 838.9812271595001 and batch: 1700, loss is 3.6720981884002684 and perplexity is 39.33435021551786
At time: 840.3348534107208 and batch: 1750, loss is 3.6720807456970217 and perplexity is 39.33366412410331
At time: 841.6888451576233 and batch: 1800, loss is 3.630974893569946 and perplexity is 37.749600526891584
At time: 843.0427289009094 and batch: 1850, loss is 3.661731786727905 and perplexity is 38.9287007370402
At time: 844.3999736309052 and batch: 1900, loss is 3.7537557888031006 and perplexity is 42.68108247965937
At time: 845.754093170166 and batch: 1950, loss is 3.6963592338562012 and perplexity is 40.300312926828546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360650208938954 and perplexity of 78.30803445745848
finished 15 epochs...
Completing Train Step...
At time: 850.0633125305176 and batch: 50, loss is 3.928320093154907 and perplexity is 50.82153048070533
At time: 851.4368054866791 and batch: 100, loss is 3.9023205471038818 and perplexity is 49.51722293325928
At time: 852.7927227020264 and batch: 150, loss is 3.8608347845077513 and perplexity is 47.50499125190938
At time: 854.1640906333923 and batch: 200, loss is 3.862987504005432 and perplexity is 47.60736632568766
At time: 855.5192501544952 and batch: 250, loss is 3.864210982322693 and perplexity is 47.66564855237914
At time: 856.8756520748138 and batch: 300, loss is 3.8861000299453736 and perplexity is 48.72050700944873
At time: 858.2308745384216 and batch: 350, loss is 3.910804147720337 and perplexity is 49.93909423987734
At time: 859.5848994255066 and batch: 400, loss is 3.8538871240615844 and perplexity is 47.17608658518234
At time: 860.9382996559143 and batch: 450, loss is 3.886913080215454 and perplexity is 48.76013533856003
At time: 862.293214559555 and batch: 500, loss is 3.889884214401245 and perplexity is 48.90522367529458
At time: 863.6468598842621 and batch: 550, loss is 3.8586205434799195 and perplexity is 47.39992012058663
At time: 865.0016987323761 and batch: 600, loss is 3.8009006929397584 and perplexity is 44.74146467188591
At time: 866.3549814224243 and batch: 650, loss is 3.8257236957550047 and perplexity is 45.86598137442773
At time: 867.7108643054962 and batch: 700, loss is 3.8638196086883543 and perplexity is 47.646997124348744
At time: 869.0639505386353 and batch: 750, loss is 3.811791491508484 and perplexity is 45.23139799129172
At time: 870.4187309741974 and batch: 800, loss is 3.806648836135864 and perplexity is 44.99938559064397
At time: 871.7726459503174 and batch: 850, loss is 3.8064125871658323 and perplexity is 44.98875578783554
At time: 873.1278371810913 and batch: 900, loss is 3.7718253993988036 and perplexity is 43.45932309710634
At time: 874.4806795120239 and batch: 950, loss is 3.8780643796920775 and perplexity is 48.33057483246812
At time: 875.8343892097473 and batch: 1000, loss is 3.8422243928909303 and perplexity is 46.629080562021514
At time: 877.189385175705 and batch: 1050, loss is 3.7925270414352417 and perplexity is 44.368379461685485
At time: 878.5438733100891 and batch: 1100, loss is 3.7953178691864013 and perplexity is 44.49237691364437
At time: 879.8973367214203 and batch: 1150, loss is 3.788458380699158 and perplexity is 44.188226317778806
At time: 881.2521834373474 and batch: 1200, loss is 3.8269845247268677 and perplexity is 45.92384700423311
At time: 882.6049349308014 and batch: 1250, loss is 3.8087036991119385 and perplexity is 45.09194823124166
At time: 883.9580063819885 and batch: 1300, loss is 3.8027297592163087 and perplexity is 44.82337466264592
At time: 885.3125994205475 and batch: 1350, loss is 3.6701387786865234 and perplexity is 39.257353566247325
At time: 886.6667940616608 and batch: 1400, loss is 3.6994482946395872 and perplexity is 40.424995519956894
At time: 888.0215046405792 and batch: 1450, loss is 3.632757124900818 and perplexity is 37.81693903625487
At time: 889.374406337738 and batch: 1500, loss is 3.6218206024169923 and perplexity is 37.405606605268275
At time: 890.7289772033691 and batch: 1550, loss is 3.645212755203247 and perplexity is 38.290918577168895
At time: 892.0844073295593 and batch: 1600, loss is 3.71939603805542 and perplexity is 41.239479509395274
At time: 893.4385840892792 and batch: 1650, loss is 3.6792021656036376 and perplexity is 39.61477543058704
At time: 894.7933511734009 and batch: 1700, loss is 3.671611337661743 and perplexity is 39.31520491889508
At time: 896.1485044956207 and batch: 1750, loss is 3.6723606777191162 and perplexity is 39.34467641751283
At time: 897.5021314620972 and batch: 1800, loss is 3.631914358139038 and perplexity is 37.78508160308134
At time: 898.8529987335205 and batch: 1850, loss is 3.6633894634246826 and perplexity is 38.99328545258747
At time: 900.206324338913 and batch: 1900, loss is 3.7560055875778198 and perplexity is 42.77721442494375
At time: 901.5630745887756 and batch: 1950, loss is 3.696241979598999 and perplexity is 40.29558782059612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358280057685319 and perplexity of 78.12265235002045
finished 16 epochs...
Completing Train Step...
At time: 905.8932399749756 and batch: 50, loss is 3.921693549156189 and perplexity is 50.485872726587935
At time: 907.266194820404 and batch: 100, loss is 3.8941904497146607 and perplexity is 49.11627516905443
At time: 908.627564907074 and batch: 150, loss is 3.852107539176941 and perplexity is 47.092207391787646
At time: 909.9843626022339 and batch: 200, loss is 3.854315037727356 and perplexity is 47.196278197155
At time: 911.3408262729645 and batch: 250, loss is 3.855118532180786 and perplexity is 47.23421538402755
At time: 912.695698261261 and batch: 300, loss is 3.8775339555740356 and perplexity is 48.30494592763366
At time: 914.0502290725708 and batch: 350, loss is 3.9033979892730715 and perplexity is 49.57060362949126
At time: 915.4050142765045 and batch: 400, loss is 3.8469594955444335 and perplexity is 46.85039761107834
At time: 916.764999628067 and batch: 450, loss is 3.8811437463760377 and perplexity is 48.47963177713256
At time: 918.122968673706 and batch: 500, loss is 3.8848222875595093 and perplexity is 48.65829450682187
At time: 919.4777257442474 and batch: 550, loss is 3.854414200782776 and perplexity is 47.20095855636101
At time: 920.8312361240387 and batch: 600, loss is 3.7979570865631103 and perplexity is 44.609957059457884
At time: 922.2065670490265 and batch: 650, loss is 3.8224466228485108 and perplexity is 45.71592122285826
At time: 923.5635414123535 and batch: 700, loss is 3.860778503417969 and perplexity is 47.502317694467685
At time: 924.9223136901855 and batch: 750, loss is 3.808078656196594 and perplexity is 45.06377263485639
At time: 926.2788171768188 and batch: 800, loss is 3.802018280029297 and perplexity is 44.791495106646906
At time: 927.6338303089142 and batch: 850, loss is 3.801519808769226 and perplexity is 44.76917339746808
At time: 928.9872395992279 and batch: 900, loss is 3.765624442100525 and perplexity is 43.19066751213288
At time: 930.3409411907196 and batch: 950, loss is 3.8708340072631837 and perplexity is 47.98238705725884
At time: 931.6987025737762 and batch: 1000, loss is 3.8347178220748903 and perplexity is 46.280366527454305
At time: 933.056401014328 and batch: 1050, loss is 3.78540874004364 and perplexity is 44.05367337964208
At time: 934.4105429649353 and batch: 1100, loss is 3.787680196762085 and perplexity is 44.15385312591806
At time: 935.7648289203644 and batch: 1150, loss is 3.7811012744903563 and perplexity is 43.864321804530384
At time: 937.1174697875977 and batch: 1200, loss is 3.820704526901245 and perplexity is 45.63634903308951
At time: 938.4718174934387 and batch: 1250, loss is 3.803190598487854 and perplexity is 44.84403579433843
At time: 939.830085515976 and batch: 1300, loss is 3.797936840057373 and perplexity is 44.60905387284955
At time: 941.1880059242249 and batch: 1350, loss is 3.6658267974853516 and perplexity is 39.08844103121813
At time: 942.5425095558167 and batch: 1400, loss is 3.6957031297683716 and perplexity is 40.27388039896944
At time: 943.8951535224915 and batch: 1450, loss is 3.6289222383499147 and perplexity is 37.672193084889905
At time: 945.2496168613434 and batch: 1500, loss is 3.6183469581604 and perplexity is 37.27589824549297
At time: 946.6070120334625 and batch: 1550, loss is 3.6419946718215943 and perplexity is 38.167893267451305
At time: 947.9647717475891 and batch: 1600, loss is 3.716464109420776 and perplexity is 41.11874537696185
At time: 949.3204944133759 and batch: 1650, loss is 3.6770783138275145 and perplexity is 39.53072880231119
At time: 950.6742029190063 and batch: 1700, loss is 3.670520610809326 and perplexity is 39.27234614703746
At time: 952.0310163497925 and batch: 1750, loss is 3.6719440269470214 and perplexity is 39.32828684230733
At time: 953.3850028514862 and batch: 1800, loss is 3.632147765159607 and perplexity is 37.793901935724
At time: 954.741809129715 and batch: 1850, loss is 3.66452552318573 and perplexity is 39.0376093276595
At time: 956.1003739833832 and batch: 1900, loss is 3.758518557548523 and perplexity is 42.884847462878014
At time: 957.4569907188416 and batch: 1950, loss is 3.697189064025879 and perplexity is 40.33376922194433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35590337708939 and perplexity of 77.93720022560593
finished 17 epochs...
Completing Train Step...
At time: 961.7884712219238 and batch: 50, loss is 3.9161992120742797 and perplexity is 50.20924695745616
At time: 963.1464281082153 and batch: 100, loss is 3.886879119873047 and perplexity is 48.758479455785455
At time: 964.502922296524 and batch: 150, loss is 3.844014801979065 and perplexity is 46.712640472521315
At time: 965.857419013977 and batch: 200, loss is 3.846140742301941 and perplexity is 46.81205439508039
At time: 967.2116730213165 and batch: 250, loss is 3.8462797260284423 and perplexity is 46.818560960988314
At time: 968.5648829936981 and batch: 300, loss is 3.8690553522109985 and perplexity is 47.897118795995034
At time: 969.9187710285187 and batch: 350, loss is 3.895906505584717 and perplexity is 49.2006338027359
At time: 971.2757878303528 and batch: 400, loss is 3.839747180938721 and perplexity is 46.51371339978597
At time: 972.6326084136963 and batch: 450, loss is 3.8746640253067017 and perplexity is 48.16651284292092
At time: 973.9868257045746 and batch: 500, loss is 3.878727059364319 and perplexity is 48.36261313635124
At time: 975.3426356315613 and batch: 550, loss is 3.848657464981079 and perplexity is 46.93001572975379
At time: 976.6961193084717 and batch: 600, loss is 3.793370566368103 and perplexity is 44.40582108524349
At time: 978.0532746315002 and batch: 650, loss is 3.818203077316284 and perplexity is 45.52233466678755
At time: 979.4113306999207 and batch: 700, loss is 3.85788592338562 and perplexity is 47.365111973745314
At time: 980.7691326141357 and batch: 750, loss is 3.8051762533187867 and perplexity is 44.93316903529084
At time: 982.1231002807617 and batch: 800, loss is 3.7984406185150146 and perplexity is 44.63153261488405
At time: 983.476126909256 and batch: 850, loss is 3.7974345970153807 and perplexity is 44.5866549112642
At time: 984.8299791812897 and batch: 900, loss is 3.7604192876815796 and perplexity is 42.96643750045987
At time: 986.1867151260376 and batch: 950, loss is 3.864332842826843 and perplexity is 47.67145746627377
At time: 987.5465774536133 and batch: 1000, loss is 3.8278573894500734 and perplexity is 45.96394980985299
At time: 988.9217565059662 and batch: 1050, loss is 3.7787214422225954 and perplexity is 43.760056192640214
At time: 990.2764611244202 and batch: 1100, loss is 3.7803559637069704 and perplexity is 43.83164143251319
At time: 991.6308219432831 and batch: 1150, loss is 3.7739703273773193 and perplexity is 43.55264025866288
At time: 992.9857776165009 and batch: 1200, loss is 3.8146415662765505 and perplexity is 45.36049473773397
At time: 994.3438181877136 and batch: 1250, loss is 3.7979378414154055 and perplexity is 44.60909854250634
At time: 995.7009630203247 and batch: 1300, loss is 3.7934833335876466 and perplexity is 44.410828888571544
At time: 997.0549230575562 and batch: 1350, loss is 3.6618618392944335 and perplexity is 38.933763843710544
At time: 998.4077422618866 and batch: 1400, loss is 3.6922920083999635 and perplexity is 40.13673534714232
At time: 999.7623932361603 and batch: 1450, loss is 3.6254536151885985 and perplexity is 37.54174880522793
At time: 1001.1194221973419 and batch: 1500, loss is 3.6149674749374388 and perplexity is 37.15013759544667
At time: 1002.4775850772858 and batch: 1550, loss is 3.6387043046951293 and perplexity is 38.04251327238372
At time: 1003.8355448246002 and batch: 1600, loss is 3.7131939792633055 and perplexity is 40.984501345026935
At time: 1005.1888041496277 and batch: 1650, loss is 3.6747226238250734 and perplexity is 39.437716257056536
At time: 1006.5377078056335 and batch: 1700, loss is 3.669084696769714 and perplexity is 39.215994901291204
At time: 1007.8923237323761 and batch: 1750, loss is 3.6711474800109865 and perplexity is 39.29697248925529
At time: 1009.2452349662781 and batch: 1800, loss is 3.6320553731918337 and perplexity is 37.79041024405895
At time: 1010.5950412750244 and batch: 1850, loss is 3.6650614452362063 and perplexity is 39.05853605034127
At time: 1011.9490950107574 and batch: 1900, loss is 3.7605935287475587 and perplexity is 42.973924670598585
At time: 1013.3072280883789 and batch: 1950, loss is 3.6986618280410766 and perplexity is 40.39321510998906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.353845498728198 and perplexity of 77.7769798612828
finished 18 epochs...
Completing Train Step...
At time: 1017.6476695537567 and batch: 50, loss is 3.9116546010971067 and perplexity is 49.981583176075176
At time: 1019.0024406909943 and batch: 100, loss is 3.880378499031067 and perplexity is 48.44254705893078
At time: 1020.3631820678711 and batch: 150, loss is 3.8366719102859497 and perplexity is 46.3708908635528
At time: 1021.7229747772217 and batch: 200, loss is 3.838539319038391 and perplexity is 46.45756517400522
At time: 1023.0960674285889 and batch: 250, loss is 3.837895669937134 and perplexity is 46.42767242518683
At time: 1024.4522697925568 and batch: 300, loss is 3.8609943485260008 and perplexity is 47.5125719439872
At time: 1025.813452720642 and batch: 350, loss is 3.8886550951004026 and perplexity is 48.84515024723112
At time: 1027.1747386455536 and batch: 400, loss is 3.8326510858535765 and perplexity is 46.18481599050537
At time: 1028.5393579006195 and batch: 450, loss is 3.8680923795700073 and perplexity is 47.85101738177504
At time: 1029.9077217578888 and batch: 500, loss is 3.8722476959228516 and perplexity is 48.05026718308257
At time: 1031.270572900772 and batch: 550, loss is 3.8421206521987914 and perplexity is 46.62424347983568
At time: 1032.6247520446777 and batch: 600, loss is 3.7881322431564333 and perplexity is 44.173817228030444
At time: 1033.979041814804 and batch: 650, loss is 3.814101748466492 and perplexity is 45.336014942710605
At time: 1035.3364589214325 and batch: 700, loss is 3.8548063230514527 and perplexity is 47.219470732594914
At time: 1036.696694135666 and batch: 750, loss is 3.802187194824219 and perplexity is 44.7990616918932
At time: 1038.0650672912598 and batch: 800, loss is 3.7963614082336425 and perplexity is 44.5388306802024
At time: 1039.4259655475616 and batch: 850, loss is 3.7944247198104857 and perplexity is 44.452656315825
At time: 1040.7851989269257 and batch: 900, loss is 3.7561512660980223 and perplexity is 42.78344660017557
At time: 1042.1442370414734 and batch: 950, loss is 3.858439679145813 and perplexity is 47.39134794082148
At time: 1043.5055487155914 and batch: 1000, loss is 3.821842851638794 and perplexity is 45.688327596754974
At time: 1044.8636949062347 and batch: 1050, loss is 3.7724657917022704 and perplexity is 43.4871630264184
At time: 1046.2211763858795 and batch: 1100, loss is 3.773515329360962 and perplexity is 43.53282840125776
At time: 1047.5745911598206 and batch: 1150, loss is 3.76729341506958 and perplexity is 43.2628117553757
At time: 1048.9304704666138 and batch: 1200, loss is 3.8090343999862672 and perplexity is 45.10686264391565
At time: 1050.2866044044495 and batch: 1250, loss is 3.79307373046875 and perplexity is 44.39264179954448
At time: 1051.645959854126 and batch: 1300, loss is 3.78939989566803 and perplexity is 44.229849785789234
At time: 1053.0034937858582 and batch: 1350, loss is 3.6582844352722166 and perplexity is 38.794730877159424
At time: 1054.3593447208405 and batch: 1400, loss is 3.689210238456726 and perplexity is 40.01323356231853
At time: 1055.7144997119904 and batch: 1450, loss is 3.6224153566360475 and perplexity is 37.42786036471575
At time: 1057.0680644512177 and batch: 1500, loss is 3.6118481302261354 and perplexity is 37.03443406363341
At time: 1058.4241073131561 and batch: 1550, loss is 3.6356344175338746 and perplexity is 37.92590612627482
At time: 1059.7819201946259 and batch: 1600, loss is 3.7101886224746705 and perplexity is 40.86151319988011
At time: 1061.1403062343597 and batch: 1650, loss is 3.6725279331207275 and perplexity is 39.35125757752024
At time: 1062.4946541786194 and batch: 1700, loss is 3.667973289489746 and perplexity is 39.17243417040737
At time: 1063.850251674652 and batch: 1750, loss is 3.6704605770111085 and perplexity is 39.26998854970181
At time: 1065.203696489334 and batch: 1800, loss is 3.632692074775696 and perplexity is 37.81447911964864
At time: 1066.560066461563 and batch: 1850, loss is 3.6650593280792236 and perplexity is 39.05845335737647
At time: 1067.91841006279 and batch: 1900, loss is 3.76207549571991 and perplexity is 43.03765782118045
At time: 1069.2745745182037 and batch: 1950, loss is 3.7003329849243163 and perplexity is 40.460774945274956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352174554869186 and perplexity of 77.64712741269976
finished 19 epochs...
Completing Train Step...
At time: 1073.5810508728027 and batch: 50, loss is 3.907654800415039 and perplexity is 49.7820660858896
At time: 1074.9389824867249 and batch: 100, loss is 3.8744462394714354 and perplexity is 48.156024000891634
At time: 1076.297667503357 and batch: 150, loss is 3.829898648262024 and perplexity is 46.057869952482086
At time: 1077.6526386737823 and batch: 200, loss is 3.8313685607910157 and perplexity is 46.12562077427603
At time: 1079.0090131759644 and batch: 250, loss is 3.8300835371017454 and perplexity is 46.06638632588457
At time: 1080.366435289383 and batch: 300, loss is 3.8534231615066528 and perplexity is 47.154203724325164
At time: 1081.7279016971588 and batch: 350, loss is 3.8818367958068847 and perplexity is 48.51324220384162
At time: 1083.0855994224548 and batch: 400, loss is 3.8259276866912844 and perplexity is 45.87533857327112
At time: 1084.4414629936218 and batch: 450, loss is 3.8618627071380613 and perplexity is 47.553847813550654
At time: 1085.796029806137 and batch: 500, loss is 3.8658585500717164 and perplexity is 47.74424566692669
At time: 1087.1509654521942 and batch: 550, loss is 3.835675139427185 and perplexity is 46.32469273914215
At time: 1088.5048534870148 and batch: 600, loss is 3.782997522354126 and perplexity is 43.947578343617614
At time: 1089.861650943756 and batch: 650, loss is 3.811286826133728 and perplexity is 45.20857702983259
At time: 1091.257939338684 and batch: 700, loss is 3.8529286098480227 and perplexity is 47.130889300230656
At time: 1092.6138479709625 and batch: 750, loss is 3.8002744817733767 and perplexity is 44.713455837745734
At time: 1093.9681596755981 and batch: 800, loss is 3.7940552949905397 and perplexity is 44.43623743422733
At time: 1095.3220627307892 and batch: 850, loss is 3.7932980346679686 and perplexity is 44.402600372347614
At time: 1096.681560754776 and batch: 900, loss is 3.7560168647766115 and perplexity is 42.777696834814684
At time: 1098.0384922027588 and batch: 950, loss is 3.8548197031021116 and perplexity is 47.220102535732174
At time: 1099.3961389064789 and batch: 1000, loss is 3.817920894622803 and perplexity is 45.509490864012385
At time: 1100.7513434886932 and batch: 1050, loss is 3.7665266227722167 and perplexity is 43.22965087993613
At time: 1102.1044764518738 and batch: 1100, loss is 3.767058892250061 and perplexity is 43.25266682843744
At time: 1103.4594135284424 and batch: 1150, loss is 3.7611089038848875 and perplexity is 42.99607807109281
At time: 1104.816696882248 and batch: 1200, loss is 3.8039492177963257 and perplexity is 44.87806825296978
At time: 1106.1761980056763 and batch: 1250, loss is 3.788541216850281 and perplexity is 44.191886851982105
At time: 1107.5338139533997 and batch: 1300, loss is 3.7856537199020384 and perplexity is 44.064466964359994
At time: 1108.8893356323242 and batch: 1350, loss is 3.654994258880615 and perplexity is 38.66729912094359
At time: 1110.2444043159485 and batch: 1400, loss is 3.6864432525634765 and perplexity is 39.90267054320653
At time: 1111.597237586975 and batch: 1450, loss is 3.6197875499725343 and perplexity is 37.32963629730051
At time: 1112.9559738636017 and batch: 1500, loss is 3.6090298223495485 and perplexity is 36.9302065679816
At time: 1114.3139452934265 and batch: 1550, loss is 3.6323658227920532 and perplexity is 37.802144083099925
At time: 1115.6698305606842 and batch: 1600, loss is 3.707222204208374 and perplexity is 40.74048046634492
At time: 1117.0231766700745 and batch: 1650, loss is 3.6691910886764525 and perplexity is 39.22016738771885
At time: 1118.3756062984467 and batch: 1700, loss is 3.6663054847717285 and perplexity is 39.1071566500911
At time: 1119.7305245399475 and batch: 1750, loss is 3.6700542116165162 and perplexity is 39.25403382725227
At time: 1121.0871586799622 and batch: 1800, loss is 3.632333154678345 and perplexity is 37.80090917852971
At time: 1122.443809747696 and batch: 1850, loss is 3.6646328735351563 and perplexity is 39.04180025360625
At time: 1123.79745388031 and batch: 1900, loss is 3.762957887649536 and perplexity is 43.0756506629352
At time: 1125.1519193649292 and batch: 1950, loss is 3.7033153915405275 and perplexity is 40.58162555141446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350671670603198 and perplexity of 77.53052041197337
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa20428cb38>
ELAPSED
2338.8512761592865


RESULTS SO FAR:
[{'best_accuracy': -74.4178468006303, 'params': {'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}}, {'best_accuracy': -77.53052041197337, 'params': {'dropout': 0.9649993788704626, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.2039606990300309, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'dropout': 0.18248612094762118, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.031083902810406072, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.193058490753174 and batch: 50, loss is 7.68480260848999 and perplexity is 2175.040596682539
At time: 3.79598069190979 and batch: 100, loss is 7.01830810546875 and perplexity is 1116.895349150931
At time: 5.399463176727295 and batch: 150, loss is 6.666307382583618 and perplexity is 785.4897295666221
At time: 7.005941152572632 and batch: 200, loss is 6.352218084335327 and perplexity is 573.7639554683466
At time: 8.62013292312622 and batch: 250, loss is 6.191824531555175 and perplexity is 488.73700932256963
At time: 10.23527193069458 and batch: 300, loss is 6.05613977432251 and perplexity is 426.7249985799076
At time: 11.841454982757568 and batch: 350, loss is 5.957563753128052 and perplexity is 386.66695964246816
At time: 13.45037317276001 and batch: 400, loss is 5.8512457084655765 and perplexity is 347.6672028152897
At time: 15.059136867523193 and batch: 450, loss is 5.7300591468811035 and perplexity is 307.98748433781446
At time: 16.67202353477478 and batch: 500, loss is 5.6840603637695315 and perplexity is 294.14132930913036
At time: 18.2824490070343 and batch: 550, loss is 5.623487148284912 and perplexity is 276.85312981135314
At time: 19.888336420059204 and batch: 600, loss is 5.621559514999389 and perplexity is 276.3199725340755
At time: 21.494274616241455 and batch: 650, loss is 5.675349235534668 and perplexity is 291.5901544089052
At time: 23.10239052772522 and batch: 700, loss is 5.591797637939453 and perplexity is 268.2173442748367
At time: 24.715861082077026 and batch: 750, loss is 5.495379076004029 and perplexity is 243.56383786937297
At time: 26.32746648788452 and batch: 800, loss is 5.4880930614471435 and perplexity is 241.7956774444646
At time: 27.938226222991943 and batch: 850, loss is 5.485736694335937 and perplexity is 241.226588816686
At time: 29.54855513572693 and batch: 900, loss is 5.4669968795776365 and perplexity is 236.7481409306347
At time: 31.15952229499817 and batch: 950, loss is 5.473415670394897 and perplexity is 238.27266529081774
At time: 32.77436804771423 and batch: 1000, loss is 5.431030521392822 and perplexity is 228.38447928811658
At time: 34.38493895530701 and batch: 1050, loss is 5.331205835342407 and perplexity is 206.68705450632444
At time: 35.99372100830078 and batch: 1100, loss is 5.40053771018982 and perplexity is 221.52550070387676
At time: 37.60877227783203 and batch: 1150, loss is 5.295419855117798 and perplexity is 199.42133646091253
At time: 39.23253345489502 and batch: 1200, loss is 5.368383741378784 and perplexity is 214.51587423316104
At time: 40.85902690887451 and batch: 1250, loss is 5.321765718460083 and perplexity is 204.74508518407208
At time: 42.4792914390564 and batch: 1300, loss is 5.326632890701294 and perplexity is 205.7440438591138
At time: 44.097557067871094 and batch: 1350, loss is 5.253399095535278 and perplexity is 191.21512354640723
At time: 45.71697187423706 and batch: 1400, loss is 5.259406538009643 and perplexity is 192.36729473732407
At time: 47.3423638343811 and batch: 1450, loss is 5.219527530670166 and perplexity is 184.84682897859804
At time: 48.96633243560791 and batch: 1500, loss is 5.165360536575317 and perplexity is 175.10057735529463
At time: 50.58274745941162 and batch: 1550, loss is 5.153061428070068 and perplexity is 172.96018579012906
At time: 52.201926946640015 and batch: 1600, loss is 5.187149839401245 and perplexity is 178.95776699031018
At time: 53.82338881492615 and batch: 1650, loss is 5.177141389846802 and perplexity is 177.1756103955881
At time: 55.447983264923096 and batch: 1700, loss is 5.181819477081299 and perplexity is 178.00639508335675
At time: 57.07070732116699 and batch: 1750, loss is 5.17308611869812 and perplexity is 176.45857013350155
At time: 58.68943786621094 and batch: 1800, loss is 5.139332599639893 and perplexity is 170.60187056799776
At time: 60.30997610092163 and batch: 1850, loss is 5.123450746536255 and perplexity is 167.9137990008285
At time: 61.93444800376892 and batch: 1900, loss is 5.1865781307220455 and perplexity is 178.85548452238487
At time: 63.559125900268555 and batch: 1950, loss is 5.103977956771851 and perplexity is 164.67567883211
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.818696629723838 and perplexity of 123.8036236138301
finished 1 epochs...
Completing Train Step...
At time: 67.96893906593323 and batch: 50, loss is 5.054979038238526 and perplexity is 156.8012434794544
At time: 69.32524919509888 and batch: 100, loss is 5.0030318641662594 and perplexity is 148.86381045309523
At time: 70.68421816825867 and batch: 150, loss is 4.928871231079102 and perplexity is 138.22340196998442
At time: 72.0394515991211 and batch: 200, loss is 4.903425798416138 and perplexity is 134.7506183189111
At time: 73.391916513443 and batch: 250, loss is 4.913304738998413 and perplexity is 136.08840876693256
At time: 74.74642181396484 and batch: 300, loss is 4.934865789413452 and perplexity is 139.05447869651636
At time: 76.11599516868591 and batch: 350, loss is 4.928507232666016 and perplexity is 138.1730980268492
At time: 77.47300171852112 and batch: 400, loss is 4.869391927719116 and perplexity is 130.24169644759522
At time: 78.83170580863953 and batch: 450, loss is 4.84405707359314 and perplexity is 126.98348943940357
At time: 80.18741583824158 and batch: 500, loss is 4.841041049957275 and perplexity is 126.60108119991231
At time: 81.53920698165894 and batch: 550, loss is 4.813495788574219 and perplexity is 123.16141210128215
At time: 82.8912901878357 and batch: 600, loss is 4.7745280265808105 and perplexity is 118.45439409986031
At time: 84.24523067474365 and batch: 650, loss is 4.839758853912354 and perplexity is 126.43885781762955
At time: 85.60199236869812 and batch: 700, loss is 4.852461290359497 and perplexity is 128.05518327617585
At time: 86.9582302570343 and batch: 750, loss is 4.791373405456543 and perplexity is 120.46670473010668
At time: 88.31922006607056 and batch: 800, loss is 4.788516054153442 and perplexity is 120.1229803388946
At time: 89.67693424224854 and batch: 850, loss is 4.781094989776611 and perplexity is 119.23483951974525
At time: 91.029132604599 and batch: 900, loss is 4.772775430679321 and perplexity is 118.2469732298235
At time: 92.38344764709473 and batch: 950, loss is 4.819993257522583 and perplexity is 123.96425495081661
At time: 93.74005055427551 and batch: 1000, loss is 4.790871419906616 and perplexity is 120.40624736071733
At time: 95.10337495803833 and batch: 1050, loss is 4.718846254348755 and perplexity is 112.03891366059172
At time: 96.46440863609314 and batch: 1100, loss is 4.7695618724823 and perplexity is 117.86758961188531
At time: 97.8235604763031 and batch: 1150, loss is 4.711945714950562 and perplexity is 111.26844610092691
At time: 99.1842737197876 and batch: 1200, loss is 4.781324758529663 and perplexity is 119.26223910780604
At time: 100.55174279212952 and batch: 1250, loss is 4.757523975372314 and perplexity is 116.45721768310699
At time: 101.92110824584961 and batch: 1300, loss is 4.764352436065674 and perplexity is 117.25516248332917
At time: 103.2793800830841 and batch: 1350, loss is 4.645212841033936 and perplexity is 104.08551709705432
At time: 104.63205981254578 and batch: 1400, loss is 4.657798719406128 and perplexity is 105.40380324831695
At time: 105.98584342002869 and batch: 1450, loss is 4.606618299484253 and perplexity is 100.1449162518817
At time: 107.33948373794556 and batch: 1500, loss is 4.5887714290618895 and perplexity is 98.37349707013587
At time: 108.69652676582336 and batch: 1550, loss is 4.594211254119873 and perplexity is 98.91008984673194
At time: 110.05290746688843 and batch: 1600, loss is 4.655659456253051 and perplexity is 105.17855779138885
At time: 111.40759563446045 and batch: 1650, loss is 4.624682378768921 and perplexity is 101.97037998098044
At time: 112.76049947738647 and batch: 1700, loss is 4.638811616897583 and perplexity is 103.42137031678799
At time: 114.11482667922974 and batch: 1750, loss is 4.622671957015991 and perplexity is 101.76558244460236
At time: 115.46821308135986 and batch: 1800, loss is 4.587906055450439 and perplexity is 98.2884040656359
At time: 116.82624650001526 and batch: 1850, loss is 4.616307973861694 and perplexity is 101.12000439499353
At time: 118.18238568305969 and batch: 1900, loss is 4.707451877593994 and perplexity is 110.76954562960881
At time: 119.5355806350708 and batch: 1950, loss is 4.62619086265564 and perplexity is 102.12431673246836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.558937817950581 and perplexity of 95.48200667459236
finished 2 epochs...
Completing Train Step...
At time: 123.8356990814209 and batch: 50, loss is 4.6275816249847415 and perplexity is 102.26644619630808
At time: 125.22433280944824 and batch: 100, loss is 4.566661233901978 and perplexity is 96.22230907972917
At time: 126.58639168739319 and batch: 150, loss is 4.511238374710083 and perplexity is 91.0344835375295
At time: 127.9677107334137 and batch: 200, loss is 4.501833219528198 and perplexity is 90.18230381597685
At time: 129.33170747756958 and batch: 250, loss is 4.514047842025757 and perplexity is 91.29060155275997
At time: 130.69059014320374 and batch: 300, loss is 4.535387172698974 and perplexity is 93.25961589258225
At time: 132.05043649673462 and batch: 350, loss is 4.540030498504638 and perplexity is 93.69365759235008
At time: 133.40463042259216 and batch: 400, loss is 4.491580200195313 and perplexity is 89.26238693305564
At time: 134.75724959373474 and batch: 450, loss is 4.494589300155639 and perplexity is 89.5313909049764
At time: 136.11069774627686 and batch: 500, loss is 4.500018539428711 and perplexity is 90.01880018218037
At time: 137.46460270881653 and batch: 550, loss is 4.472338628768921 and perplexity is 87.56125703038752
At time: 138.8192892074585 and batch: 600, loss is 4.43938214302063 and perplexity is 84.72257906240739
At time: 140.17304682731628 and batch: 650, loss is 4.5002727031707765 and perplexity is 90.04168260510883
At time: 141.5266251564026 and batch: 700, loss is 4.5274093723297115 and perplexity is 92.51856918616191
At time: 142.87862181663513 and batch: 750, loss is 4.475728092193603 and perplexity is 87.85854624936206
At time: 144.2499966621399 and batch: 800, loss is 4.475957050323486 and perplexity is 87.87866448083399
At time: 145.60297322273254 and batch: 850, loss is 4.473063802719116 and perplexity is 87.62477720183544
At time: 146.9567859172821 and batch: 900, loss is 4.453203172683716 and perplexity is 85.90166163934323
At time: 148.3107442855835 and batch: 950, loss is 4.513468141555786 and perplexity is 91.23769568439587
At time: 149.6627025604248 and batch: 1000, loss is 4.494267168045044 and perplexity is 89.5025546138567
At time: 151.01662468910217 and batch: 1050, loss is 4.433702182769776 and perplexity is 84.24272225487175
At time: 152.37045550346375 and batch: 1100, loss is 4.471547784805298 and perplexity is 87.49203711350224
At time: 153.72377705574036 and batch: 1150, loss is 4.431530389785767 and perplexity is 84.05996303115953
At time: 155.07691717147827 and batch: 1200, loss is 4.496928701400757 and perplexity is 89.74108593711135
At time: 156.43192219734192 and batch: 1250, loss is 4.482569742202759 and perplexity is 88.4617046196214
At time: 157.78451704978943 and batch: 1300, loss is 4.4773915576934815 and perplexity is 88.00481753480668
At time: 159.13803625106812 and batch: 1350, loss is 4.35222400188446 and perplexity is 77.6509669263204
At time: 160.4921531677246 and batch: 1400, loss is 4.37527268409729 and perplexity is 79.46150448690581
At time: 161.8463170528412 and batch: 1450, loss is 4.3263066339492795 and perplexity is 75.66431385853663
At time: 163.20012974739075 and batch: 1500, loss is 4.3121850967407225 and perplexity is 74.60332645317509
At time: 164.55428862571716 and batch: 1550, loss is 4.324172163009644 and perplexity is 75.50298281889756
At time: 165.90828037261963 and batch: 1600, loss is 4.400050048828125 and perplexity is 81.45494528750879
At time: 167.2614164352417 and batch: 1650, loss is 4.360344324111939 and perplexity is 78.28408488097732
At time: 168.61643958091736 and batch: 1700, loss is 4.3687032699584964 and perplexity is 78.94119987531528
At time: 169.9700427055359 and batch: 1750, loss is 4.358100786209106 and perplexity is 78.10864844209608
At time: 171.32430005073547 and batch: 1800, loss is 4.322087984085083 and perplexity is 75.34578496449555
At time: 172.67774033546448 and batch: 1850, loss is 4.360519981384277 and perplexity is 78.29783725761213
At time: 174.03079175949097 and batch: 1900, loss is 4.454357872009277 and perplexity is 86.00090951980559
At time: 175.39379024505615 and batch: 1950, loss is 4.37725193977356 and perplexity is 79.61893486679914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.46630121275436 and perplexity of 87.03420590931067
finished 3 epochs...
Completing Train Step...
At time: 179.66975212097168 and batch: 50, loss is 4.382254991531372 and perplexity is 80.0182706346322
At time: 181.04213166236877 and batch: 100, loss is 4.32573016166687 and perplexity is 75.62070804880759
At time: 182.39584708213806 and batch: 150, loss is 4.279261131286621 and perplexity is 72.18708352050997
At time: 183.74942326545715 and batch: 200, loss is 4.274603319168091 and perplexity is 71.85163149082642
At time: 185.10167622566223 and batch: 250, loss is 4.279388046264648 and perplexity is 72.19624572402697
At time: 186.45579433441162 and batch: 300, loss is 4.2970115661621096 and perplexity is 73.47987551140523
At time: 187.81097888946533 and batch: 350, loss is 4.3073227596282955 and perplexity is 74.24146040056584
At time: 189.16417264938354 and batch: 400, loss is 4.258204379081726 and perplexity is 70.68294965317118
At time: 190.5177640914917 and batch: 450, loss is 4.281882219314575 and perplexity is 72.37654040401743
At time: 191.87237405776978 and batch: 500, loss is 4.285303354263306 and perplexity is 72.62457435274794
At time: 193.22584748268127 and batch: 550, loss is 4.257019805908203 and perplexity is 70.59927009924894
At time: 194.5821647644043 and batch: 600, loss is 4.232016649246216 and perplexity is 68.85595055445822
At time: 195.93990898132324 and batch: 650, loss is 4.293107852935791 and perplexity is 73.19359030074253
At time: 197.29513001441956 and batch: 700, loss is 4.325701780319214 and perplexity is 75.61856186165843
At time: 198.65105366706848 and batch: 750, loss is 4.277271366119384 and perplexity is 72.04359098176671
At time: 200.00654578208923 and batch: 800, loss is 4.275458860397339 and perplexity is 71.91312982738562
At time: 201.36444854736328 and batch: 850, loss is 4.272976999282837 and perplexity is 71.73487272303262
At time: 202.72111415863037 and batch: 900, loss is 4.240964965820313 and perplexity is 69.47486036871182
At time: 204.07810401916504 and batch: 950, loss is 4.316109752655029 and perplexity is 74.89669414663315
At time: 205.43418169021606 and batch: 1000, loss is 4.300129718780518 and perplexity is 73.70935456705756
At time: 206.78963136672974 and batch: 1050, loss is 4.243374252319336 and perplexity is 69.642447012874
At time: 208.14481711387634 and batch: 1100, loss is 4.274386048316956 and perplexity is 71.83602192151055
At time: 209.50118446350098 and batch: 1150, loss is 4.242137455940247 and perplexity is 69.55636672944182
At time: 210.8581326007843 and batch: 1200, loss is 4.305253491401673 and perplexity is 74.08799374206139
At time: 212.26354455947876 and batch: 1250, loss is 4.293042955398559 and perplexity is 73.18884037112187
At time: 213.6192066669464 and batch: 1300, loss is 4.282889280319214 and perplexity is 72.44946470895775
At time: 214.9747712612152 and batch: 1350, loss is 4.162107453346253 and perplexity is 64.2066927269794
At time: 216.3298020362854 and batch: 1400, loss is 4.187174887657165 and perplexity is 65.83653238334328
At time: 217.6855137348175 and batch: 1450, loss is 4.1385907506942745 and perplexity is 62.71437895007914
At time: 219.04043793678284 and batch: 1500, loss is 4.127190165519714 and perplexity is 62.00345848588369
At time: 220.40089511871338 and batch: 1550, loss is 4.144023017883301 and perplexity is 63.055987226788545
At time: 221.75870823860168 and batch: 1600, loss is 4.222012519836426 and perplexity is 68.17054089440211
At time: 223.11769437789917 and batch: 1650, loss is 4.182628927230835 and perplexity is 65.53792136371251
At time: 224.4762110710144 and batch: 1700, loss is 4.189771466255188 and perplexity is 66.0077042487258
At time: 225.82980036735535 and batch: 1750, loss is 4.178790168762207 and perplexity is 65.28681938134652
At time: 227.1877362728119 and batch: 1800, loss is 4.143075971603394 and perplexity is 62.996298557087066
At time: 228.54752326011658 and batch: 1850, loss is 4.183163595199585 and perplexity is 65.57297176033137
At time: 229.90743374824524 and batch: 1900, loss is 4.280141849517822 and perplexity is 72.25068800572727
At time: 231.26882314682007 and batch: 1950, loss is 4.205005655288696 and perplexity is 67.02097668820483
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.427527139353198 and perplexity of 83.7241226229382
finished 4 epochs...
Completing Train Step...
At time: 235.71347641944885 and batch: 50, loss is 4.206335940361023 and perplexity is 67.1101930214472
At time: 237.11867427825928 and batch: 100, loss is 4.157534418106079 and perplexity is 63.913743602347544
At time: 238.47290587425232 and batch: 150, loss is 4.114882011413574 and perplexity is 61.24498762691429
At time: 239.8256278038025 and batch: 200, loss is 4.111591668128967 and perplexity is 61.04380175995257
At time: 241.18024373054504 and batch: 250, loss is 4.111402173042297 and perplexity is 61.032235355370425
At time: 242.53382682800293 and batch: 300, loss is 4.1295648860931395 and perplexity is 62.15087434082863
At time: 243.88725066184998 and batch: 350, loss is 4.144123578071595 and perplexity is 63.06232846756996
At time: 245.2760133743286 and batch: 400, loss is 4.091691246032715 and perplexity is 59.84101204456897
At time: 246.63040161132812 and batch: 450, loss is 4.126576347351074 and perplexity is 61.965411314763585
At time: 247.9846007823944 and batch: 500, loss is 4.127359461784363 and perplexity is 62.01395632839835
At time: 249.33836483955383 and batch: 550, loss is 4.099324531555176 and perplexity is 60.29954339939752
At time: 250.69267559051514 and batch: 600, loss is 4.077898607254029 and perplexity is 59.02131248596297
At time: 252.0486946105957 and batch: 650, loss is 4.138936281204224 and perplexity is 62.736052425626795
At time: 253.4045376777649 and batch: 700, loss is 4.173958067893982 and perplexity is 64.9721078560026
At time: 254.76175999641418 and batch: 750, loss is 4.132992076873779 and perplexity is 62.36424266250514
At time: 256.1177098751068 and batch: 800, loss is 4.127670097351074 and perplexity is 62.03322306117772
At time: 257.47638297080994 and batch: 850, loss is 4.124501004219055 and perplexity is 61.83694517573757
At time: 258.8339276313782 and batch: 900, loss is 4.090496692657471 and perplexity is 59.76957143995601
At time: 260.1922359466553 and batch: 950, loss is 4.170020070075989 and perplexity is 64.7167509644785
At time: 261.55129957199097 and batch: 1000, loss is 4.151864352226258 and perplexity is 63.55237392858329
At time: 262.9076271057129 and batch: 1050, loss is 4.10508777141571 and perplexity is 60.64806748074477
At time: 264.26831889152527 and batch: 1100, loss is 4.129109864234924 and perplexity is 62.12260076753111
At time: 265.6242048740387 and batch: 1150, loss is 4.098803615570068 and perplexity is 60.26814058317064
At time: 266.9816780090332 and batch: 1200, loss is 4.162688488960266 and perplexity is 64.2440099423775
At time: 268.3353934288025 and batch: 1250, loss is 4.153024768829345 and perplexity is 63.626163963766366
At time: 269.690416097641 and batch: 1300, loss is 4.13936399936676 and perplexity is 62.76289151406872
At time: 271.0452072620392 and batch: 1350, loss is 4.01915997505188 and perplexity is 55.654335155278986
At time: 272.39944434165955 and batch: 1400, loss is 4.045960192680359 and perplexity is 57.16605011276961
At time: 273.7536828517914 and batch: 1450, loss is 3.9967689323425293 and perplexity is 54.422024406548594
At time: 275.1082594394684 and batch: 1500, loss is 3.990665922164917 and perplexity is 54.09089770031995
At time: 276.4616105556488 and batch: 1550, loss is 4.007205853462219 and perplexity is 54.99299719848516
At time: 277.81459498405457 and batch: 1600, loss is 4.090227260589599 and perplexity is 59.75346976997767
At time: 279.1672329902649 and batch: 1650, loss is 4.046494846343994 and perplexity is 57.19662232294178
At time: 280.52035689353943 and batch: 1700, loss is 4.053535881042481 and perplexity is 57.60076685352527
At time: 281.87682247161865 and batch: 1750, loss is 4.039845380783081 and perplexity is 56.81755704008567
At time: 283.2313802242279 and batch: 1800, loss is 4.009397826194763 and perplexity is 55.1136725590572
At time: 284.5854296684265 and batch: 1850, loss is 4.0510458612442015 and perplexity is 57.45751822364032
At time: 285.938205242157 and batch: 1900, loss is 4.1454968786239625 and perplexity is 63.1489914916573
At time: 287.291796207428 and batch: 1950, loss is 4.0716722965240475 and perplexity is 58.6549691220432
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.420363315316134 and perplexity of 83.12648099646506
finished 5 epochs...
Completing Train Step...
At time: 291.65001821517944 and batch: 50, loss is 4.075118365287781 and perplexity is 58.85744685469222
At time: 293.0021002292633 and batch: 100, loss is 4.0316637420654295 and perplexity is 56.35459280117069
At time: 294.35553002357483 and batch: 150, loss is 3.986513547897339 and perplexity is 53.86675772718301
At time: 295.7081468105316 and batch: 200, loss is 3.982922897338867 and perplexity is 53.67368785412435
At time: 297.0607364177704 and batch: 250, loss is 3.9826879119873047 and perplexity is 53.66107680547818
At time: 298.41347217559814 and batch: 300, loss is 4.001623530387878 and perplexity is 54.686863784093866
At time: 299.7702350616455 and batch: 350, loss is 4.016626510620117 and perplexity is 55.513515333015484
At time: 301.1279926300049 and batch: 400, loss is 3.96409677028656 and perplexity is 52.67267237458905
At time: 302.48141407966614 and batch: 450, loss is 4.003897137641907 and perplexity is 54.81134168760381
At time: 303.83234310150146 and batch: 500, loss is 4.0033406639099125 and perplexity is 54.78084910068797
At time: 305.1855103969574 and batch: 550, loss is 3.980599274635315 and perplexity is 53.54911524036953
At time: 306.5380084514618 and batch: 600, loss is 3.957642331123352 and perplexity is 52.33379462455806
At time: 307.89035987854004 and batch: 650, loss is 4.018865919113159 and perplexity is 55.63797207345958
At time: 309.2424440383911 and batch: 700, loss is 4.057770085334778 and perplexity is 57.845177344592194
At time: 310.6001431941986 and batch: 750, loss is 4.0171732997894285 and perplexity is 55.54387782213359
At time: 311.9593458175659 and batch: 800, loss is 4.007673139572144 and perplexity is 55.018700667188384
At time: 313.4468092918396 and batch: 850, loss is 4.005470323562622 and perplexity is 54.89763798090106
At time: 314.8080298900604 and batch: 900, loss is 3.9713860082626344 and perplexity is 53.0580187528749
At time: 316.16717767715454 and batch: 950, loss is 4.053367400169373 and perplexity is 57.59106304351025
At time: 317.529305934906 and batch: 1000, loss is 4.036358036994934 and perplexity is 56.61975977946864
At time: 318.88807702064514 and batch: 1050, loss is 3.993429431915283 and perplexity is 54.240585159634094
At time: 320.2488203048706 and batch: 1100, loss is 4.014613094329834 and perplexity is 55.401855963031174
At time: 321.60892629623413 and batch: 1150, loss is 3.987637453079224 and perplexity is 53.92733288931687
At time: 322.96474862098694 and batch: 1200, loss is 4.050262670516968 and perplexity is 57.41253564542611
At time: 324.32298707962036 and batch: 1250, loss is 4.040185966491699 and perplexity is 56.836911583765506
At time: 325.6835768222809 and batch: 1300, loss is 4.025976223945618 and perplexity is 56.034984783228595
At time: 327.0428771972656 and batch: 1350, loss is 3.906693444252014 and perplexity is 49.73423078691369
At time: 328.403404712677 and batch: 1400, loss is 3.9378002452850343 and perplexity is 51.30561730397875
At time: 329.7577702999115 and batch: 1450, loss is 3.8864647436141966 and perplexity is 48.73827928500597
At time: 331.11114144325256 and batch: 1500, loss is 3.8828969621658325 and perplexity is 48.56470158412171
At time: 332.4640407562256 and batch: 1550, loss is 3.902637867927551 and perplexity is 49.53293827249661
At time: 333.8165109157562 and batch: 1600, loss is 3.9853585004806518 and perplexity is 53.8045749867451
At time: 335.1708183288574 and batch: 1650, loss is 3.941488780975342 and perplexity is 51.49520934807376
At time: 336.5257980823517 and batch: 1700, loss is 3.9484153270721434 and perplexity is 51.853131440320716
At time: 337.87807059288025 and batch: 1750, loss is 3.934330039024353 and perplexity is 51.127884792199374
At time: 339.2319145202637 and batch: 1800, loss is 3.904283962249756 and perplexity is 49.61454130566773
At time: 340.58591079711914 and batch: 1850, loss is 3.945058374404907 and perplexity is 51.67935477563922
At time: 341.94130516052246 and batch: 1900, loss is 4.038225345611572 and perplexity is 56.72558511831066
At time: 343.2940676212311 and batch: 1950, loss is 3.9644503498077395 and perplexity is 52.69129964578325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.426453204487645 and perplexity of 83.63425663231303
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 347.61719012260437 and batch: 50, loss is 4.00993745803833 and perplexity is 55.143421677849965
At time: 348.970370054245 and batch: 100, loss is 3.990677418708801 and perplexity is 54.09151956227373
At time: 350.3239531517029 and batch: 150, loss is 3.9501115894317627 and perplexity is 51.94116259627177
At time: 351.6823444366455 and batch: 200, loss is 3.9562053728103637 and perplexity is 52.25864714814821
At time: 353.04182720184326 and batch: 250, loss is 3.956977586746216 and perplexity is 52.2990175890472
At time: 354.39662885665894 and batch: 300, loss is 3.9740327405929565 and perplexity is 53.19863513136148
At time: 355.7498013973236 and batch: 350, loss is 3.9916440868377685 and perplexity is 54.14383339126388
At time: 357.1014304161072 and batch: 400, loss is 3.933973927497864 and perplexity is 51.109680804617135
At time: 358.4550747871399 and batch: 450, loss is 3.958344988822937 and perplexity is 52.37058029065175
At time: 359.80880665779114 and batch: 500, loss is 3.951850538253784 and perplexity is 52.031564198882386
At time: 361.164489030838 and batch: 550, loss is 3.929146399497986 and perplexity is 50.863541988503805
At time: 362.51668882369995 and batch: 600, loss is 3.8817069292068482 and perplexity is 48.50694236309817
At time: 363.8698751926422 and batch: 650, loss is 3.9387885999679564 and perplexity is 51.35635051817639
At time: 365.2238781452179 and batch: 700, loss is 3.977485728263855 and perplexity is 53.38264687488669
At time: 366.57760977745056 and batch: 750, loss is 3.9324307823181153 and perplexity is 51.030871969421014
At time: 367.934109210968 and batch: 800, loss is 3.9197727251052856 and perplexity is 50.388991323875594
At time: 369.2869095802307 and batch: 850, loss is 3.9146765089035034 and perplexity is 50.13285135658465
At time: 370.64245200157166 and batch: 900, loss is 3.86539080619812 and perplexity is 47.7219188105487
At time: 371.99530482292175 and batch: 950, loss is 3.9692362356185913 and perplexity is 52.94407859221448
At time: 373.3496358394623 and batch: 1000, loss is 3.9267794132232665 and perplexity is 50.743291055031314
At time: 374.70253562927246 and batch: 1050, loss is 3.8795810174942016 and perplexity is 48.403930422126585
At time: 376.05713653564453 and batch: 1100, loss is 3.8876323986053465 and perplexity is 48.79522201833683
At time: 377.4125769138336 and batch: 1150, loss is 3.850672035217285 and perplexity is 47.02465483918646
At time: 378.7732403278351 and batch: 1200, loss is 3.8987244939804078 and perplexity is 49.33947615404046
At time: 380.13132309913635 and batch: 1250, loss is 3.8895593786239626 and perplexity is 48.88934008886708
At time: 381.48975372314453 and batch: 1300, loss is 3.88141676902771 and perplexity is 48.49286962178596
At time: 382.8428430557251 and batch: 1350, loss is 3.754955348968506 and perplexity is 42.73231172615705
At time: 384.19478034973145 and batch: 1400, loss is 3.773811264038086 and perplexity is 43.545713181207546
At time: 385.54782938957214 and batch: 1450, loss is 3.7095948219299317 and perplexity is 40.83725681352361
At time: 386.90182733535767 and batch: 1500, loss is 3.699462742805481 and perplexity is 40.4255795912178
At time: 388.256395816803 and batch: 1550, loss is 3.716537637710571 and perplexity is 41.12176887914304
At time: 389.60969257354736 and batch: 1600, loss is 3.7955429649353025 and perplexity is 44.50239308580274
At time: 390.9612331390381 and batch: 1650, loss is 3.750068063735962 and perplexity is 42.523976242256204
At time: 392.3144145011902 and batch: 1700, loss is 3.7427607345581055 and perplexity is 42.21437211719229
At time: 393.666051864624 and batch: 1750, loss is 3.706590762138367 and perplexity is 40.71476333332052
At time: 395.0320863723755 and batch: 1800, loss is 3.67072557926178 and perplexity is 39.28039656406403
At time: 396.3961751461029 and batch: 1850, loss is 3.7049166774749756 and perplexity is 40.646660393399436
At time: 397.7585480213165 and batch: 1900, loss is 3.788793907165527 and perplexity is 44.20305512479983
At time: 399.11728286743164 and batch: 1950, loss is 3.7156551599502565 and perplexity is 41.08549584007156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365505484647529 and perplexity of 78.68916605571816
finished 7 epochs...
Completing Train Step...
At time: 403.4958908557892 and batch: 50, loss is 3.935160813331604 and perplexity is 51.170378174029715
At time: 404.84986662864685 and batch: 100, loss is 3.897325415611267 and perplexity is 49.27049462674212
At time: 406.21585631370544 and batch: 150, loss is 3.843364591598511 and perplexity is 46.68227730107735
At time: 407.58235359191895 and batch: 200, loss is 3.8433563613891604 and perplexity is 46.68189309774324
At time: 408.9418525695801 and batch: 250, loss is 3.8395059394836424 and perplexity is 46.50249371726498
At time: 410.29959988594055 and batch: 300, loss is 3.856666226387024 and perplexity is 47.30737610612261
At time: 411.6545124053955 and batch: 350, loss is 3.8760790252685546 and perplexity is 48.234716699603595
At time: 413.01531410217285 and batch: 400, loss is 3.8216064023971557 and perplexity is 45.67752590341942
At time: 414.3930277824402 and batch: 450, loss is 3.8550363636016844 and perplexity is 47.230334375115135
At time: 415.7536242008209 and batch: 500, loss is 3.848875436782837 and perplexity is 46.9402462647825
At time: 417.114057302475 and batch: 550, loss is 3.830389723777771 and perplexity is 46.08049339917893
At time: 418.4734263420105 and batch: 600, loss is 3.7880620527267457 and perplexity is 44.17071675763122
At time: 419.8393783569336 and batch: 650, loss is 3.844779601097107 and perplexity is 46.74837992376446
At time: 421.2084364891052 and batch: 700, loss is 3.8861340999603273 and perplexity is 48.72216694612796
At time: 422.57503747940063 and batch: 750, loss is 3.8422432136535645 and perplexity is 46.629958165137175
At time: 423.9371774196625 and batch: 800, loss is 3.830691547393799 and perplexity is 46.09440367944497
At time: 425.2989602088928 and batch: 850, loss is 3.827935175895691 and perplexity is 45.967525321196604
At time: 426.6599202156067 and batch: 900, loss is 3.779717445373535 and perplexity is 43.803663059176706
At time: 428.02576637268066 and batch: 950, loss is 3.888485507965088 and perplexity is 48.83686744047526
At time: 429.3961112499237 and batch: 1000, loss is 3.8474583625793457 and perplexity is 46.87377556077843
At time: 430.7585895061493 and batch: 1050, loss is 3.8056981801986693 and perplexity is 44.956626985143444
At time: 432.1140921115875 and batch: 1100, loss is 3.8131478214263916 and perplexity is 45.29278831296978
At time: 433.4665095806122 and batch: 1150, loss is 3.7811797571182253 and perplexity is 43.867764526870474
At time: 434.8211646080017 and batch: 1200, loss is 3.830927233695984 and perplexity is 46.10526877932691
At time: 436.17811584472656 and batch: 1250, loss is 3.824140329360962 and perplexity is 45.79341618469145
At time: 437.5352864265442 and batch: 1300, loss is 3.817626280784607 and perplexity is 45.496085113091425
At time: 438.8884599208832 and batch: 1350, loss is 3.6923546171188355 and perplexity is 40.13924833538878
At time: 440.2410674095154 and batch: 1400, loss is 3.716228723526001 and perplexity is 41.109067743323166
At time: 441.5947542190552 and batch: 1450, loss is 3.6526581621170044 and perplexity is 38.57707399695216
At time: 442.9521515369415 and batch: 1500, loss is 3.646395468711853 and perplexity is 38.33623255527192
At time: 444.3115944862366 and batch: 1550, loss is 3.6676705646514893 and perplexity is 39.160577496354435
At time: 445.6687602996826 and batch: 1600, loss is 3.751265621185303 and perplexity is 42.57493165170602
At time: 447.0224633216858 and batch: 1650, loss is 3.7078263998031615 and perplexity is 40.76510312287347
At time: 448.37686562538147 and batch: 1700, loss is 3.7041029500961304 and perplexity is 40.61359854646806
At time: 449.729882478714 and batch: 1750, loss is 3.6709686422348025 and perplexity is 39.289945334463646
At time: 451.08671522140503 and batch: 1800, loss is 3.6386683702468874 and perplexity is 38.041146260221105
At time: 452.44499492645264 and batch: 1850, loss is 3.678598198890686 and perplexity is 39.590856648687044
At time: 453.8007483482361 and batch: 1900, loss is 3.7640467739105223 and perplexity is 43.12258069322074
At time: 455.15489387512207 and batch: 1950, loss is 3.695262351036072 and perplexity is 40.256132440771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369669785610465 and perplexity of 79.0175346640216
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 459.46213603019714 and batch: 50, loss is 3.906057062149048 and perplexity is 49.702590881138796
At time: 460.8412787914276 and batch: 100, loss is 3.8987011766433715 and perplexity is 49.338325702258565
At time: 462.1965296268463 and batch: 150, loss is 3.8600623655319213 and perplexity is 47.46831166304868
At time: 463.54889035224915 and batch: 200, loss is 3.871398005485535 and perplexity is 48.0094566711528
At time: 464.9017539024353 and batch: 250, loss is 3.8717206716537476 and perplexity is 48.02495019805891
At time: 466.25901198387146 and batch: 300, loss is 3.885397205352783 and perplexity is 48.686277069189934
At time: 467.6157491207123 and batch: 350, loss is 3.9010121250152587 and perplexity is 49.45247587248546
At time: 468.97310614585876 and batch: 400, loss is 3.858821110725403 and perplexity is 47.4094279454486
At time: 470.3260917663574 and batch: 450, loss is 3.8916751527786255 and perplexity is 48.99288839485258
At time: 471.6798849105835 and batch: 500, loss is 3.88792772769928 and perplexity is 48.80963479519519
At time: 473.03314542770386 and batch: 550, loss is 3.87032986164093 and perplexity is 47.95820304352319
At time: 474.38984394073486 and batch: 600, loss is 3.820008187294006 and perplexity is 45.60458169743865
At time: 475.7466678619385 and batch: 650, loss is 3.860184950828552 and perplexity is 47.47413093678587
At time: 477.1020448207855 and batch: 700, loss is 3.899150252342224 and perplexity is 49.36048732110332
At time: 478.4535768032074 and batch: 750, loss is 3.8483984375 and perplexity is 46.91786114024663
At time: 479.8069312572479 and batch: 800, loss is 3.829941010475159 and perplexity is 46.05982110711286
At time: 481.1611680984497 and batch: 850, loss is 3.8288731718063356 and perplexity is 46.01066290024387
At time: 482.5397071838379 and batch: 900, loss is 3.778596868515015 and perplexity is 43.75460517972986
At time: 483.8982594013214 and batch: 950, loss is 3.8928960800170898 and perplexity is 49.05274167760141
At time: 485.2517490386963 and batch: 1000, loss is 3.850202383995056 and perplexity is 47.00257483792199
At time: 486.6046862602234 and batch: 1050, loss is 3.7993351316452024 and perplexity is 44.671473968197695
At time: 487.95798444747925 and batch: 1100, loss is 3.813748769760132 and perplexity is 45.32001511876931
At time: 489.31217551231384 and batch: 1150, loss is 3.7794377613067627 and perplexity is 43.79141358562392
At time: 490.67036294937134 and batch: 1200, loss is 3.8149714422225953 and perplexity is 45.37546054214238
At time: 492.0277519226074 and batch: 1250, loss is 3.8017713975906373 and perplexity is 44.78043823803326
At time: 493.3815715312958 and batch: 1300, loss is 3.793491415977478 and perplexity is 44.41118783565394
At time: 494.7402226924896 and batch: 1350, loss is 3.668031153678894 and perplexity is 39.1747009171287
At time: 496.0973792076111 and batch: 1400, loss is 3.6900201654434204 and perplexity is 40.04565448752439
At time: 497.454847574234 and batch: 1450, loss is 3.6218296337127684 and perplexity is 37.4059444278907
At time: 498.8129391670227 and batch: 1500, loss is 3.61074285030365 and perplexity is 36.993523260331884
At time: 500.1688277721405 and batch: 1550, loss is 3.630772113800049 and perplexity is 37.741946447655465
At time: 501.52272725105286 and batch: 1600, loss is 3.7091329431533815 and perplexity is 40.81839930658527
At time: 502.8751485347748 and batch: 1650, loss is 3.6686634254455566 and perplexity is 39.19947780652445
At time: 504.22910380363464 and batch: 1700, loss is 3.6600199794769286 and perplexity is 38.86211930839215
At time: 505.58513283729553 and batch: 1750, loss is 3.6284699630737305 and perplexity is 37.65515873575582
At time: 506.94722414016724 and batch: 1800, loss is 3.5931280946731565 and perplexity is 36.34759700614439
At time: 508.30346941947937 and batch: 1850, loss is 3.613475551605225 and perplexity is 37.09475376286204
At time: 509.6565091609955 and batch: 1900, loss is 3.710359506607056 and perplexity is 40.86849638075163
At time: 511.01184844970703 and batch: 1950, loss is 3.650247974395752 and perplexity is 38.484207964123804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338904376362645 and perplexity of 76.62354276774973
finished 9 epochs...
Completing Train Step...
At time: 515.334721326828 and batch: 50, loss is 3.9034316873550416 and perplexity is 49.57227409190121
At time: 516.7075755596161 and batch: 100, loss is 3.874902172088623 and perplexity is 48.17798490891442
At time: 518.0604994297028 and batch: 150, loss is 3.824981894493103 and perplexity is 45.83197054776248
At time: 519.412784576416 and batch: 200, loss is 3.82454270362854 and perplexity is 45.811845984578625
At time: 520.7705588340759 and batch: 250, loss is 3.8228529024124147 and perplexity is 45.734498440912645
At time: 522.1309938430786 and batch: 300, loss is 3.831177821159363 and perplexity is 46.116823629368554
At time: 523.4865355491638 and batch: 350, loss is 3.8469484424591065 and perplexity is 46.8498797724978
At time: 524.8408343791962 and batch: 400, loss is 3.8056560277938845 and perplexity is 44.95473199514447
At time: 526.1942763328552 and batch: 450, loss is 3.8423769998550417 and perplexity is 46.63619702744267
At time: 527.5470209121704 and batch: 500, loss is 3.8365262937545777 and perplexity is 46.36413898687298
At time: 528.9034245014191 and batch: 550, loss is 3.8203768920898438 and perplexity is 45.62139942562066
At time: 530.2608964443207 and batch: 600, loss is 3.7732771682739257 and perplexity is 43.522461810032276
At time: 531.6152501106262 and batch: 650, loss is 3.8144080781936647 and perplexity is 45.34990483913458
At time: 532.967716217041 and batch: 700, loss is 3.856432991027832 and perplexity is 47.2963436398947
At time: 534.3201332092285 and batch: 750, loss is 3.8081038904190065 and perplexity is 45.06490979846547
At time: 535.6753168106079 and batch: 800, loss is 3.790160927772522 and perplexity is 44.26352293300092
At time: 537.0351529121399 and batch: 850, loss is 3.7905058526992796 and perplexity is 44.27879315879598
At time: 538.3928439617157 and batch: 900, loss is 3.7410484600067138 and perplexity is 42.14215137063149
At time: 539.7466979026794 and batch: 950, loss is 3.857459964752197 and perplexity is 47.34494069174791
At time: 541.1011006832123 and batch: 1000, loss is 3.815648703575134 and perplexity is 45.40620199674573
At time: 542.4547226428986 and batch: 1050, loss is 3.767488079071045 and perplexity is 43.2712342871819
At time: 543.8093917369843 and batch: 1100, loss is 3.782399492263794 and perplexity is 43.92130422651027
At time: 545.1688115596771 and batch: 1150, loss is 3.750451378822327 and perplexity is 42.54027944831488
At time: 546.525404214859 and batch: 1200, loss is 3.7893646717071534 and perplexity is 44.22829186272907
At time: 547.879200220108 and batch: 1250, loss is 3.7786094999313353 and perplexity is 43.755157865854414
At time: 549.233097076416 and batch: 1300, loss is 3.770914525985718 and perplexity is 43.419755178564756
At time: 550.5904409885406 and batch: 1350, loss is 3.6468033027648925 and perplexity is 38.351870565012895
At time: 551.9475793838501 and batch: 1400, loss is 3.671558909416199 and perplexity is 39.31314374571029
At time: 553.3057715892792 and batch: 1450, loss is 3.605945086479187 and perplexity is 36.81646216100309
At time: 554.6605250835419 and batch: 1500, loss is 3.5964731931686402 and perplexity is 36.46938688420719
At time: 556.0144200325012 and batch: 1550, loss is 3.619389009475708 and perplexity is 37.314761889728025
At time: 557.3694462776184 and batch: 1600, loss is 3.700577111244202 and perplexity is 40.47065369114394
At time: 558.7233624458313 and batch: 1650, loss is 3.661627016067505 and perplexity is 38.92462236500606
At time: 560.0801815986633 and batch: 1700, loss is 3.654690718650818 and perplexity is 38.655563821240676
At time: 561.4383738040924 and batch: 1750, loss is 3.62551682472229 and perplexity is 37.54412187666346
At time: 562.7931866645813 and batch: 1800, loss is 3.592763719558716 and perplexity is 36.334355258953714
At time: 564.1487882137299 and batch: 1850, loss is 3.6154449939727784 and perplexity is 37.16788172955771
At time: 565.5018329620361 and batch: 1900, loss is 3.713429079055786 and perplexity is 40.994137925522715
At time: 566.8579320907593 and batch: 1950, loss is 3.653426003456116 and perplexity is 38.606706444162064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3393216865007265 and perplexity of 76.65552522179941
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 571.1652393341064 and batch: 50, loss is 3.8982586669921875 and perplexity is 49.31649784683659
At time: 572.5373497009277 and batch: 100, loss is 3.8858756256103515 and perplexity is 48.70957514309631
At time: 573.8907375335693 and batch: 150, loss is 3.8450057220458986 and perplexity is 46.758951907015685
At time: 575.2482678890228 and batch: 200, loss is 3.8542383527755737 and perplexity is 47.19265909160439
At time: 576.6066787242889 and batch: 250, loss is 3.8626520442962646 and perplexity is 47.591398650831344
At time: 577.9609589576721 and batch: 300, loss is 3.870356707572937 and perplexity is 47.959490543463254
At time: 579.3164432048798 and batch: 350, loss is 3.8871014976501463 and perplexity is 48.76932346375008
At time: 580.6702470779419 and batch: 400, loss is 3.844732794761658 and perplexity is 46.746191854620186
At time: 582.0261266231537 and batch: 450, loss is 3.888447027206421 and perplexity is 48.83498819692282
At time: 583.3836810588837 and batch: 500, loss is 3.8758184146881103 and perplexity is 48.22214785994438
At time: 584.7615103721619 and batch: 550, loss is 3.860409474372864 and perplexity is 47.484791193621454
At time: 586.1142780780792 and batch: 600, loss is 3.8126552867889405 and perplexity is 45.27048553879417
At time: 587.4681527614594 and batch: 650, loss is 3.8446796989440917 and perplexity is 46.743709893237025
At time: 588.8218860626221 and batch: 700, loss is 3.8836986875534056 and perplexity is 48.60365275030465
At time: 590.1779038906097 and batch: 750, loss is 3.833462162017822 and perplexity is 46.22229058922787
At time: 591.5338804721832 and batch: 800, loss is 3.809290542602539 and perplexity is 45.1184179135604
At time: 592.8896143436432 and batch: 850, loss is 3.806829085350037 and perplexity is 45.00749742558891
At time: 594.2394545078278 and batch: 900, loss is 3.757190217971802 and perplexity is 42.82791964086162
At time: 595.592700958252 and batch: 950, loss is 3.868266267776489 and perplexity is 47.85933883284602
At time: 596.9479415416718 and batch: 1000, loss is 3.822971529960632 and perplexity is 45.73992413414362
At time: 598.3029141426086 and batch: 1050, loss is 3.778458471298218 and perplexity is 43.74855008316485
At time: 599.6606087684631 and batch: 1100, loss is 3.7948934841156006 and perplexity is 44.47349901914941
At time: 601.0182535648346 and batch: 1150, loss is 3.7706741380691526 and perplexity is 43.40931884851368
At time: 602.3704054355621 and batch: 1200, loss is 3.8093232822418215 and perplexity is 45.119895098469
At time: 603.7232918739319 and batch: 1250, loss is 3.7939053535461427 and perplexity is 44.42957510009535
At time: 605.0759170055389 and batch: 1300, loss is 3.7829325675964354 and perplexity is 43.94472383202327
At time: 606.4317371845245 and batch: 1350, loss is 3.6553844213485718 and perplexity is 38.682388593279306
At time: 607.7901685237885 and batch: 1400, loss is 3.677647385597229 and perplexity is 39.553231026191746
At time: 609.1462218761444 and batch: 1450, loss is 3.6076084852218626 and perplexity is 36.877753579773675
At time: 610.49968957901 and batch: 1500, loss is 3.6008681058883667 and perplexity is 36.63001938085181
At time: 611.8534498214722 and batch: 1550, loss is 3.621069474220276 and perplexity is 37.377520748791625
At time: 613.2080264091492 and batch: 1600, loss is 3.699088144302368 and perplexity is 40.41043906560161
At time: 614.5642642974854 and batch: 1650, loss is 3.65067289352417 and perplexity is 38.500564115004366
At time: 615.9214448928833 and batch: 1700, loss is 3.642726516723633 and perplexity is 38.195836469358376
At time: 617.2753472328186 and batch: 1750, loss is 3.618803234100342 and perplexity is 37.292910221784695
At time: 618.6288659572601 and batch: 1800, loss is 3.590319104194641 and perplexity is 36.24564021710224
At time: 619.9813210964203 and batch: 1850, loss is 3.603673467636108 and perplexity is 36.732924111049954
At time: 621.3360984325409 and batch: 1900, loss is 3.705313811302185 and perplexity is 40.66280576292874
At time: 622.6934614181519 and batch: 1950, loss is 3.652219982147217 and perplexity is 38.560173998724444
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324843011900436 and perplexity of 75.55365090458741
finished 11 epochs...
Completing Train Step...
At time: 626.9842350482941 and batch: 50, loss is 3.904977707862854 and perplexity is 49.64897311812287
At time: 628.3375055789948 and batch: 100, loss is 3.877108016014099 and perplexity is 48.284375321450966
At time: 629.6937534809113 and batch: 150, loss is 3.8262628507614136 and perplexity is 45.89071691545581
At time: 631.0528631210327 and batch: 200, loss is 3.8273150634765627 and perplexity is 45.939029124204325
At time: 632.4101126194 and batch: 250, loss is 3.8344909143447876 and perplexity is 46.26986634586847
At time: 633.7638018131256 and batch: 300, loss is 3.8409046363830566 and perplexity is 46.5675821199045
At time: 635.1192352771759 and batch: 350, loss is 3.855232973098755 and perplexity is 47.23962122031416
At time: 636.4740571975708 and batch: 400, loss is 3.813513479232788 and perplexity is 45.309353002909404
At time: 637.8338768482208 and batch: 450, loss is 3.8597426319122317 and perplexity is 47.45313687401448
At time: 639.1909852027893 and batch: 500, loss is 3.8498481369018553 and perplexity is 46.98592726126462
At time: 640.5448267459869 and batch: 550, loss is 3.835327115058899 and perplexity is 46.308573422335776
At time: 641.8998990058899 and batch: 600, loss is 3.789282031059265 and perplexity is 44.22463695905842
At time: 643.2539505958557 and batch: 650, loss is 3.822839031219482 and perplexity is 45.733864053260966
At time: 644.6087124347687 and batch: 700, loss is 3.862353844642639 and perplexity is 47.57720902801356
At time: 645.967470407486 and batch: 750, loss is 3.815042424201965 and perplexity is 45.37868149645998
At time: 647.3254234790802 and batch: 800, loss is 3.7903672361373903 and perplexity is 44.27265581010261
At time: 648.6792721748352 and batch: 850, loss is 3.7889651584625246 and perplexity is 44.21062560352985
At time: 650.0321967601776 and batch: 900, loss is 3.740182433128357 and perplexity is 42.10567093363227
At time: 651.4331274032593 and batch: 950, loss is 3.8524233293533325 and perplexity is 47.107080996612105
At time: 652.7934303283691 and batch: 1000, loss is 3.8074222135543825 and perplexity is 45.03420056012731
At time: 654.1529197692871 and batch: 1050, loss is 3.7635748052597044 and perplexity is 43.10223298910812
At time: 655.509863615036 and batch: 1100, loss is 3.780796012878418 and perplexity is 43.85093375448258
At time: 656.8630805015564 and batch: 1150, loss is 3.7577823972702027 and perplexity is 42.85328895911769
At time: 658.2182807922363 and batch: 1200, loss is 3.7966841793060304 and perplexity is 44.55320884664722
At time: 659.5739231109619 and batch: 1250, loss is 3.78358199596405 and perplexity is 43.97327205129513
At time: 660.9370675086975 and batch: 1300, loss is 3.7736235809326173 and perplexity is 43.53754115342762
At time: 662.2990782260895 and batch: 1350, loss is 3.6471491956710818 and perplexity is 38.36513849949035
At time: 663.6548824310303 and batch: 1400, loss is 3.6707701539993285 and perplexity is 39.28214751645551
At time: 665.0085065364838 and batch: 1450, loss is 3.602709774971008 and perplexity is 36.69754191303711
At time: 666.363847732544 and batch: 1500, loss is 3.598024582862854 and perplexity is 36.526009025320185
At time: 667.7216312885284 and batch: 1550, loss is 3.620130615234375 and perplexity is 37.342444995735384
At time: 669.0822765827179 and batch: 1600, loss is 3.6997502040863037 and perplexity is 40.43720205052857
At time: 670.4411206245422 and batch: 1650, loss is 3.6528427696228025 and perplexity is 38.58419627175619
At time: 671.7967753410339 and batch: 1700, loss is 3.6460666942596434 and perplexity is 38.32363065311903
At time: 673.1529774665833 and batch: 1750, loss is 3.6240320110321047 and perplexity is 37.488417216270385
At time: 674.5061161518097 and batch: 1800, loss is 3.5966893243789673 and perplexity is 36.4772699087875
At time: 675.8626585006714 and batch: 1850, loss is 3.610546040534973 and perplexity is 36.986243289984614
At time: 677.2215268611908 and batch: 1900, loss is 3.7126386404037475 and perplexity is 40.96174737745641
At time: 678.5783805847168 and batch: 1950, loss is 3.6582283544540406 and perplexity is 38.79255529791562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323305777616279 and perplexity of 75.43759646640821
finished 12 epochs...
Completing Train Step...
At time: 682.8929107189178 and batch: 50, loss is 3.899689016342163 and perplexity is 49.387088139829686
At time: 684.2499492168427 and batch: 100, loss is 3.86927077293396 and perplexity is 47.90743793939261
At time: 685.6258778572083 and batch: 150, loss is 3.8173189687728883 and perplexity is 45.482105767770385
At time: 686.9805228710175 and batch: 200, loss is 3.816830596923828 and perplexity is 45.459899010696304
At time: 688.3347270488739 and batch: 250, loss is 3.8235189723968506 and perplexity is 45.76497096486755
At time: 689.6878905296326 and batch: 300, loss is 3.829282855987549 and perplexity is 46.029516602769384
At time: 691.0452790260315 and batch: 350, loss is 3.843531398773193 and perplexity is 46.690064889356414
At time: 692.4017179012299 and batch: 400, loss is 3.8014149904251098 and perplexity is 44.764481012773395
At time: 693.7576858997345 and batch: 450, loss is 3.8477495765686034 and perplexity is 46.88742784772304
At time: 695.109840631485 and batch: 500, loss is 3.8379665279388426 and perplexity is 46.43096231383496
At time: 696.4644074440002 and batch: 550, loss is 3.8235754489898683 and perplexity is 45.76755568749468
At time: 697.81698179245 and batch: 600, loss is 3.7782265615463255 and perplexity is 43.73840554412365
At time: 699.1748304367065 and batch: 650, loss is 3.8123802375793456 and perplexity is 45.258035639774675
At time: 700.539553642273 and batch: 700, loss is 3.8523201990127562 and perplexity is 47.102223077809086
At time: 701.8938438892365 and batch: 750, loss is 3.8058340835571287 and perplexity is 44.962737156922756
At time: 703.2453927993774 and batch: 800, loss is 3.7812917709350584 and perplexity is 43.87267859782785
At time: 704.5978605747223 and batch: 850, loss is 3.7801307439804077 and perplexity is 43.82177079378796
At time: 705.9489414691925 and batch: 900, loss is 3.7316038990020752 and perplexity is 41.74601088228026
At time: 707.2977476119995 and batch: 950, loss is 3.844533476829529 and perplexity is 46.73687542882103
At time: 708.6454062461853 and batch: 1000, loss is 3.799520525932312 and perplexity is 44.67975657201816
At time: 710.0014944076538 and batch: 1050, loss is 3.7562438154220583 and perplexity is 42.78740636247218
At time: 711.3622171878815 and batch: 1100, loss is 3.7737753868103026 and perplexity is 43.54415090976191
At time: 712.7146434783936 and batch: 1150, loss is 3.7513869285583494 and perplexity is 42.58009661809024
At time: 714.0670223236084 and batch: 1200, loss is 3.790559620857239 and perplexity is 44.28117401194726
At time: 715.4187963008881 and batch: 1250, loss is 3.7784493923187257 and perplexity is 43.748152892778876
At time: 716.7704739570618 and batch: 1300, loss is 3.7690170431137084 and perplexity is 43.337445052529816
At time: 718.126763343811 and batch: 1350, loss is 3.642625570297241 and perplexity is 38.19198093076845
At time: 719.4805102348328 and batch: 1400, loss is 3.6667686033248903 and perplexity is 39.125272094372555
At time: 720.8335480690002 and batch: 1450, loss is 3.599364814758301 and perplexity is 36.574995166691345
At time: 722.1866972446442 and batch: 1500, loss is 3.5954837465286253 and perplexity is 36.433320217854586
At time: 723.5386235713959 and batch: 1550, loss is 3.618151140213013 and perplexity is 37.26859967023085
At time: 724.8949584960938 and batch: 1600, loss is 3.698448896408081 and perplexity is 40.38461503238053
At time: 726.2499825954437 and batch: 1650, loss is 3.6520327806472777 and perplexity is 38.552956151930914
At time: 727.6051959991455 and batch: 1700, loss is 3.645780782699585 and perplexity is 38.31267505033327
At time: 728.9568471908569 and batch: 1750, loss is 3.6243967056274413 and perplexity is 37.502091532739975
At time: 730.3119275569916 and batch: 1800, loss is 3.5975358390808108 and perplexity is 36.50816152730831
At time: 731.6646311283112 and batch: 1850, loss is 3.6116743183135984 and perplexity is 37.027997597202564
At time: 733.0192396640778 and batch: 1900, loss is 3.7138205671310427 and perplexity is 41.01018978352647
At time: 734.3747355937958 and batch: 1950, loss is 3.658791251182556 and perplexity is 38.81439764730034
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323163551507994 and perplexity of 75.4268680335941
finished 13 epochs...
Completing Train Step...
At time: 738.6866574287415 and batch: 50, loss is 3.8938302421569824 and perplexity is 49.09858630155667
At time: 740.0388185977936 and batch: 100, loss is 3.8623844242095946 and perplexity is 47.57866394070778
At time: 741.4061214923859 and batch: 150, loss is 3.8100733661651613 and perplexity is 45.15375150238991
At time: 742.76788854599 and batch: 200, loss is 3.8088839864730835 and perplexity is 45.100078472465
At time: 744.122385263443 and batch: 250, loss is 3.8152586364746095 and perplexity is 45.38849398506794
At time: 745.474879026413 and batch: 300, loss is 3.8207058238983156 and perplexity is 45.636408223338904
At time: 746.827342748642 and batch: 350, loss is 3.8350328969955445 and perplexity is 46.2949506076841
At time: 748.1809544563293 and batch: 400, loss is 3.792734260559082 and perplexity is 44.377574391053464
At time: 749.5375487804413 and batch: 450, loss is 3.839094090461731 and perplexity is 46.48334565403729
At time: 750.8944380283356 and batch: 500, loss is 3.8293486404418946 and perplexity is 46.03254472900362
At time: 752.2641718387604 and batch: 550, loss is 3.8150335502624513 and perplexity is 45.37827881057187
At time: 753.615104675293 and batch: 600, loss is 3.770141530036926 and perplexity is 43.386204852517835
At time: 754.9682681560516 and batch: 650, loss is 3.804695611000061 and perplexity is 44.9115774420704
At time: 756.3248794078827 and batch: 700, loss is 3.8449508142471314 and perplexity is 46.75638454637851
At time: 757.6812510490417 and batch: 750, loss is 3.7988701009750367 and perplexity is 44.65070519215417
At time: 759.0356845855713 and batch: 800, loss is 3.7744724464416506 and perplexity is 43.574514360881004
At time: 760.3894131183624 and batch: 850, loss is 3.773434348106384 and perplexity is 43.52930320093801
At time: 761.7428874969482 and batch: 900, loss is 3.725023651123047 and perplexity is 41.472213597658396
At time: 763.0953271389008 and batch: 950, loss is 3.838379898071289 and perplexity is 46.45015945436515
At time: 764.4513788223267 and batch: 1000, loss is 3.7933800172805787 and perplexity is 44.40624076275514
At time: 765.8079328536987 and batch: 1050, loss is 3.75061089515686 and perplexity is 42.54706585901979
At time: 767.1601002216339 and batch: 1100, loss is 3.7683594322204588 and perplexity is 43.30895524520819
At time: 768.5118386745453 and batch: 1150, loss is 3.746445770263672 and perplexity is 42.370220562913985
At time: 769.8651070594788 and batch: 1200, loss is 3.785797047615051 and perplexity is 44.07078307626125
At time: 771.2186856269836 and batch: 1250, loss is 3.774233660697937 and perplexity is 43.5641106302431
At time: 772.573043346405 and batch: 1300, loss is 3.765116586685181 and perplexity is 43.168738466608104
At time: 773.9275920391083 and batch: 1350, loss is 3.6385914707183837 and perplexity is 38.03822102648594
At time: 775.2785820960999 and batch: 1400, loss is 3.6630308723449705 and perplexity is 38.97930531498163
At time: 776.6312663555145 and batch: 1450, loss is 3.595995864868164 and perplexity is 36.451983167719995
At time: 777.9843282699585 and batch: 1500, loss is 3.592601456642151 and perplexity is 36.32846001880025
At time: 779.3388087749481 and batch: 1550, loss is 3.615494017601013 and perplexity is 37.169703878637705
At time: 780.6956288814545 and batch: 1600, loss is 3.696212077140808 and perplexity is 40.29438290148114
At time: 782.051730632782 and batch: 1650, loss is 3.650112133026123 and perplexity is 38.47898057166099
At time: 783.4026436805725 and batch: 1700, loss is 3.6442464208602905 and perplexity is 38.25393461983646
At time: 784.7538471221924 and batch: 1750, loss is 3.6232066106796266 and perplexity is 37.45748703013552
At time: 786.1039719581604 and batch: 1800, loss is 3.5966659116744997 and perplexity is 36.476415887244855
At time: 787.4601762294769 and batch: 1850, loss is 3.611054196357727 and perplexity is 37.00504284102035
At time: 788.8174569606781 and batch: 1900, loss is 3.7132661390304564 and perplexity is 40.98745888380716
At time: 790.1661219596863 and batch: 1950, loss is 3.6578822040557863 and perplexity is 38.779129563245704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.32349115416061 and perplexity of 75.45158212362014
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 794.485846042633 and batch: 50, loss is 3.8935826349258424 and perplexity is 49.08643064152643
At time: 795.854001045227 and batch: 100, loss is 3.8704198884963987 and perplexity is 47.96252076408961
At time: 797.2044169902802 and batch: 150, loss is 3.821514949798584 and perplexity is 45.67334876598717
At time: 798.5556724071503 and batch: 200, loss is 3.82150230884552 and perplexity is 45.67277141497829
At time: 799.9053137302399 and batch: 250, loss is 3.829783573150635 and perplexity is 46.05257014291089
At time: 801.255047082901 and batch: 300, loss is 3.836338300704956 and perplexity is 46.355423670226905
At time: 802.6069493293762 and batch: 350, loss is 3.8542467308044435 and perplexity is 47.19305447472097
At time: 803.958890914917 and batch: 400, loss is 3.813024559020996 and perplexity is 45.287205759001836
At time: 805.3111374378204 and batch: 450, loss is 3.8632865381240844 and perplexity is 47.621604681289185
At time: 806.6630957126617 and batch: 500, loss is 3.852836217880249 and perplexity is 47.12653498578022
At time: 808.0146687030792 and batch: 550, loss is 3.839291744232178 and perplexity is 46.492534170611364
At time: 809.3669471740723 and batch: 600, loss is 3.7943346738815307 and perplexity is 44.44865371530417
At time: 810.7260897159576 and batch: 650, loss is 3.8250660419464113 and perplexity is 45.835827353632105
At time: 812.0860049724579 and batch: 700, loss is 3.8685207080841066 and perplexity is 47.87151772707611
At time: 813.4448256492615 and batch: 750, loss is 3.8212276601791384 and perplexity is 45.660229171653256
At time: 814.802788734436 and batch: 800, loss is 3.7972940015792847 and perplexity is 44.580386671726146
At time: 816.1548871994019 and batch: 850, loss is 3.796570544242859 and perplexity is 44.54814632759072
At time: 817.5058686733246 and batch: 900, loss is 3.746901202201843 and perplexity is 42.38952170943136
At time: 818.8566796779633 and batch: 950, loss is 3.855087356567383 and perplexity is 47.232742851343005
At time: 820.2433104515076 and batch: 1000, loss is 3.8061005544662474 and perplexity is 44.974720014840045
At time: 821.5954403877258 and batch: 1050, loss is 3.7594444513320924 and perplexity is 42.924572664373805
At time: 822.94642329216 and batch: 1100, loss is 3.7724631643295288 and perplexity is 43.487048769581754
At time: 824.2993731498718 and batch: 1150, loss is 3.7506281566619872 and perplexity is 42.547800291753944
At time: 825.6509068012238 and batch: 1200, loss is 3.7946238994598387 and perplexity is 44.46151126215607
At time: 827.007737159729 and batch: 1250, loss is 3.780360989570618 and perplexity is 43.83186172492005
At time: 828.3662014007568 and batch: 1300, loss is 3.7710629749298095 and perplexity is 43.4262012738199
At time: 829.7210340499878 and batch: 1350, loss is 3.6403208065032957 and perplexity is 38.104058794697835
At time: 831.0749938488007 and batch: 1400, loss is 3.666535983085632 and perplexity is 39.11617182271164
At time: 832.4280743598938 and batch: 1450, loss is 3.5948378467559814 and perplexity is 36.409795542718214
At time: 833.779529094696 and batch: 1500, loss is 3.5906583881378173 and perplexity is 36.257939867256965
At time: 835.1335279941559 and batch: 1550, loss is 3.6151794004440307 and perplexity is 37.15801149148678
At time: 836.4901843070984 and batch: 1600, loss is 3.69802161693573 and perplexity is 40.367363201317495
At time: 837.8436162471771 and batch: 1650, loss is 3.648789119720459 and perplexity is 38.42810602964506
At time: 839.1957948207855 and batch: 1700, loss is 3.6376564788818357 and perplexity is 38.00267222186019
At time: 840.5473544597626 and batch: 1750, loss is 3.6137522888183593 and perplexity is 37.10502068219408
At time: 841.9002356529236 and batch: 1800, loss is 3.5858906745910644 and perplexity is 36.08548383333511
At time: 843.2525465488434 and batch: 1850, loss is 3.6017730951309206 and perplexity is 36.66318415896623
At time: 844.6037056446075 and batch: 1900, loss is 3.704507784843445 and perplexity is 40.63004367092745
At time: 845.9613618850708 and batch: 1950, loss is 3.652753300666809 and perplexity is 38.580744338420644
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317473087754361 and perplexity of 74.99887307482027
finished 15 epochs...
Completing Train Step...
At time: 850.2504549026489 and batch: 50, loss is 3.8929739809036255 and perplexity is 49.056563078508425
At time: 851.6324491500854 and batch: 100, loss is 3.8648393869400026 and perplexity is 47.69561127938851
At time: 852.9848484992981 and batch: 150, loss is 3.8139714765548707 and perplexity is 45.33010931805559
At time: 854.3665325641632 and batch: 200, loss is 3.810633430480957 and perplexity is 45.179047590387576
At time: 855.7204341888428 and batch: 250, loss is 3.8182138061523436 and perplexity is 45.52282307107324
At time: 857.0727279186249 and batch: 300, loss is 3.823528265953064 and perplexity is 45.76539628617419
At time: 858.4252309799194 and batch: 350, loss is 3.8406648874282836 and perplexity is 46.556418929000095
At time: 859.7778599262238 and batch: 400, loss is 3.800508222579956 and perplexity is 44.723908418527934
At time: 861.1298336982727 and batch: 450, loss is 3.849516201019287 and perplexity is 46.97033353423281
At time: 862.4814021587372 and batch: 500, loss is 3.8408282995224 and perplexity is 46.56402743255566
At time: 863.8349885940552 and batch: 550, loss is 3.8280015420913696 and perplexity is 45.97057611221051
At time: 865.1879005432129 and batch: 600, loss is 3.783562331199646 and perplexity is 43.9724073357624
At time: 866.5403664112091 and batch: 650, loss is 3.815494966506958 and perplexity is 45.399221916936
At time: 867.8921091556549 and batch: 700, loss is 3.8588913679122925 and perplexity is 47.41275891549901
At time: 869.2447023391724 and batch: 750, loss is 3.8125128698349 and perplexity is 45.26403871321533
At time: 870.5951180458069 and batch: 800, loss is 3.7883649969100954 and perplexity is 44.184100046439724
At time: 871.9481360912323 and batch: 850, loss is 3.787176375389099 and perplexity is 44.13161307399074
At time: 873.2999956607819 and batch: 900, loss is 3.738176283836365 and perplexity is 42.02128534504607
At time: 874.6515488624573 and batch: 950, loss is 3.8471420431137084 and perplexity is 46.85895081794162
At time: 876.0029344558716 and batch: 1000, loss is 3.7984441804885862 and perplexity is 44.63169159150682
At time: 877.353670835495 and batch: 1050, loss is 3.752392134666443 and perplexity is 42.62291991080579
At time: 878.7054991722107 and batch: 1100, loss is 3.7663522481918337 and perplexity is 43.2221133848967
At time: 880.057763338089 and batch: 1150, loss is 3.7449015951156617 and perplexity is 42.304844010719336
At time: 881.4097537994385 and batch: 1200, loss is 3.7886196994781494 and perplexity is 44.19535528349675
At time: 882.7654297351837 and batch: 1250, loss is 3.775039277076721 and perplexity is 43.5992207320316
At time: 884.1236312389374 and batch: 1300, loss is 3.7668370962142945 and perplexity is 43.24307462219455
At time: 885.4828753471375 and batch: 1350, loss is 3.6373757410049437 and perplexity is 37.99200492977093
At time: 886.8403573036194 and batch: 1400, loss is 3.6643565988540647 and perplexity is 39.031015482540134
At time: 888.1911244392395 and batch: 1450, loss is 3.5945855474472044 and perplexity is 36.40061053520432
At time: 889.5419204235077 and batch: 1500, loss is 3.592700319290161 and perplexity is 36.33205172409567
At time: 890.8945739269257 and batch: 1550, loss is 3.618299264907837 and perplexity is 37.27412047905749
At time: 892.2477345466614 and batch: 1600, loss is 3.701530976295471 and perplexity is 40.509275650442156
At time: 893.6012587547302 and batch: 1650, loss is 3.6528833627700807 and perplexity is 38.58576255750808
At time: 894.9547142982483 and batch: 1700, loss is 3.6424487018585205 and perplexity is 38.18522657206363
At time: 896.3079025745392 and batch: 1750, loss is 3.6196321487426757 and perplexity is 37.3238356766332
At time: 897.6594798564911 and batch: 1800, loss is 3.5921567821502687 and perplexity is 36.31230927047956
At time: 899.0104401111603 and batch: 1850, loss is 3.607506818771362 and perplexity is 36.8740045400438
At time: 900.3613412380219 and batch: 1900, loss is 3.7102536821365355 and perplexity is 40.86417172259254
At time: 901.714120388031 and batch: 1950, loss is 3.657071886062622 and perplexity is 38.74771886484714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.316192201126453 and perplexity of 74.90286951915179
finished 16 epochs...
Completing Train Step...
At time: 906.0699214935303 and batch: 50, loss is 3.8921802711486815 and perplexity is 49.01764185397007
At time: 907.4386940002441 and batch: 100, loss is 3.8622931337356565 and perplexity is 47.574320660180376
At time: 908.789351940155 and batch: 150, loss is 3.810671081542969 and perplexity is 45.18074866153342
At time: 910.1415503025055 and batch: 200, loss is 3.8058995246887206 and perplexity is 44.96567966560127
At time: 911.4934091567993 and batch: 250, loss is 3.813180432319641 and perplexity is 45.29426537533845
At time: 912.8451235294342 and batch: 300, loss is 3.8182691049575808 and perplexity is 45.525340498404816
At time: 914.1969528198242 and batch: 350, loss is 3.8350007724761963 and perplexity is 46.29346342853516
At time: 915.5486688613892 and batch: 400, loss is 3.7949737024307253 and perplexity is 44.477066751405246
At time: 916.8997812271118 and batch: 450, loss is 3.8435351037979126 and perplexity is 46.69023787752145
At time: 918.2543489933014 and batch: 500, loss is 3.8352522087097167 and perplexity is 46.30510474607944
At time: 919.6076560020447 and batch: 550, loss is 3.822637825012207 and perplexity is 45.72466304161213
At time: 920.9598667621613 and batch: 600, loss is 3.77849196434021 and perplexity is 43.750015379728374
At time: 922.327951669693 and batch: 650, loss is 3.810764722824097 and perplexity is 45.18497964281457
At time: 923.6815292835236 and batch: 700, loss is 3.854126896858215 and perplexity is 47.18739948360541
At time: 925.0434637069702 and batch: 750, loss is 3.808191390037537 and perplexity is 45.06885313339957
At time: 926.402890920639 and batch: 800, loss is 3.784080619812012 and perplexity is 43.99520364076519
At time: 927.7598683834076 and batch: 850, loss is 3.7830000591278075 and perplexity is 43.94768982881912
At time: 929.1126420497894 and batch: 900, loss is 3.7341846132278445 and perplexity is 41.85388454210688
At time: 930.464586019516 and batch: 950, loss is 3.843641004562378 and perplexity is 46.69518267122984
At time: 931.8184616565704 and batch: 1000, loss is 3.795116081237793 and perplexity is 44.483399793946006
At time: 933.1687352657318 and batch: 1050, loss is 3.7492890787124633 and perplexity is 42.490863600424355
At time: 934.5218026638031 and batch: 1100, loss is 3.7637119674682618 and perplexity is 43.10814539204851
At time: 935.8734200000763 and batch: 1150, loss is 3.7425887632369994 and perplexity is 42.20711308004063
At time: 937.2267034053802 and batch: 1200, loss is 3.7860265445709227 and perplexity is 44.08089834748771
At time: 938.5769002437592 and batch: 1250, loss is 3.7728782749176024 and perplexity is 43.50510445126312
At time: 939.9300918579102 and batch: 1300, loss is 3.765245270729065 and perplexity is 43.17429395188686
At time: 941.2823748588562 and batch: 1350, loss is 3.636181716918945 and perplexity is 37.94666863251116
At time: 942.6352050304413 and batch: 1400, loss is 3.663408441543579 and perplexity is 38.99402547881708
At time: 943.9860656261444 and batch: 1450, loss is 3.5944479084014893 and perplexity is 36.3956007346868
At time: 945.3375022411346 and batch: 1500, loss is 3.5934466743469238 and perplexity is 36.3591784564502
At time: 946.6888601779938 and batch: 1550, loss is 3.619662766456604 and perplexity is 37.324978464651345
At time: 948.0406491756439 and batch: 1600, loss is 3.7030516147613524 and perplexity is 40.57092247260671
At time: 949.390707731247 and batch: 1650, loss is 3.654628691673279 and perplexity is 38.653166207810905
At time: 950.7416291236877 and batch: 1700, loss is 3.6443055725097655 and perplexity is 38.256197470093134
At time: 952.0930473804474 and batch: 1750, loss is 3.621984992027283 and perplexity is 37.411756203812004
At time: 953.4443879127502 and batch: 1800, loss is 3.594638819694519 and perplexity is 36.40254972918331
At time: 954.7961070537567 and batch: 1850, loss is 3.609740204811096 and perplexity is 36.95645045952531
At time: 956.1475515365601 and batch: 1900, loss is 3.7123866271972656 and perplexity is 40.95142577680119
At time: 957.4984266757965 and batch: 1950, loss is 3.6584660482406615 and perplexity is 38.80177714322133
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315688022347384 and perplexity of 74.86511460026307
finished 17 epochs...
Completing Train Step...
At time: 961.7994129657745 and batch: 50, loss is 3.890720524787903 and perplexity is 48.946140729109764
At time: 963.1517655849457 and batch: 100, loss is 3.85995804309845 and perplexity is 47.463359911557085
At time: 964.509771823883 and batch: 150, loss is 3.8079681158065797 and perplexity is 45.0587915431648
At time: 965.858802318573 and batch: 200, loss is 3.802595520019531 and perplexity is 44.81735801267851
At time: 967.211398601532 and batch: 250, loss is 3.8097246313095092 and perplexity is 45.13800756076773
At time: 968.5623691082001 and batch: 300, loss is 3.814718041419983 and perplexity is 45.36396382072284
At time: 969.9137251377106 and batch: 350, loss is 3.8312910270690916 and perplexity is 46.12204462185934
At time: 971.2698538303375 and batch: 400, loss is 3.7912314748764038 and perplexity is 44.310934492910434
At time: 972.6209778785706 and batch: 450, loss is 3.8396334648132324 and perplexity is 46.508424341247384
At time: 973.9710619449615 and batch: 500, loss is 3.8314635610580443 and perplexity is 46.130002928716074
At time: 975.3221776485443 and batch: 550, loss is 3.818981046676636 and perplexity is 45.55776342782838
At time: 976.6737160682678 and batch: 600, loss is 3.775071635246277 and perplexity is 43.6006315458341
At time: 978.0249845981598 and batch: 650, loss is 3.8075538158416746 and perplexity is 45.04012755392181
At time: 979.3777892589569 and batch: 700, loss is 3.850940899848938 and perplexity is 47.03729980550435
At time: 980.7294602394104 and batch: 750, loss is 3.8053112125396726 and perplexity is 44.939233590000356
At time: 982.0807766914368 and batch: 800, loss is 3.7812842082977296 and perplexity is 43.87234680592558
At time: 983.4343733787537 and batch: 850, loss is 3.7803358316421507 and perplexity is 43.83075901994914
At time: 984.7846302986145 and batch: 900, loss is 3.731657943725586 and perplexity is 41.74826709486371
At time: 986.1368291378021 and batch: 950, loss is 3.8414328050613404 and perplexity is 46.59218415464381
At time: 987.4898047447205 and batch: 1000, loss is 3.792999839782715 and perplexity is 44.38936171797223
At time: 988.8602313995361 and batch: 1050, loss is 3.7472691488265992 and perplexity is 42.405121660668065
At time: 990.2112476825714 and batch: 1100, loss is 3.7619553709030153 and perplexity is 43.032488240918774
At time: 991.5641767978668 and batch: 1150, loss is 3.7410687732696535 and perplexity is 42.14300742392771
At time: 992.9163856506348 and batch: 1200, loss is 3.7843374824523925 and perplexity is 44.00650581642764
At time: 994.2733426094055 and batch: 1250, loss is 3.771463384628296 and perplexity is 43.44359302765946
At time: 995.6328921318054 and batch: 1300, loss is 3.7641527318954466 and perplexity is 43.12715011705493
At time: 996.9915978908539 and batch: 1350, loss is 3.6352184772491456 and perplexity is 37.910134494337974
At time: 998.349127292633 and batch: 1400, loss is 3.662556071281433 and perplexity is 38.96080229233714
At time: 999.7091233730316 and batch: 1450, loss is 3.5939930391311647 and perplexity is 36.3790492590018
At time: 1001.0671796798706 and batch: 1500, loss is 3.59347008228302 and perplexity is 36.36002955973727
At time: 1002.420170545578 and batch: 1550, loss is 3.6200486183166505 and perplexity is 37.33938315587786
At time: 1003.7785301208496 and batch: 1600, loss is 3.7035210227966306 and perplexity is 40.58997126009118
At time: 1005.1278913021088 and batch: 1650, loss is 3.6552103900909425 and perplexity is 38.67565723429474
At time: 1006.4799914360046 and batch: 1700, loss is 3.644918375015259 and perplexity is 38.27964814833678
At time: 1007.8319180011749 and batch: 1750, loss is 3.62288275718689 and perplexity is 37.445358256210575
At time: 1009.181628704071 and batch: 1800, loss is 3.5956162118911745 and perplexity is 36.438146690489276
At time: 1010.5346195697784 and batch: 1850, loss is 3.6106136226654053 and perplexity is 36.988742983569196
At time: 1011.8880138397217 and batch: 1900, loss is 3.713153533935547 and perplexity is 40.98284374695829
At time: 1013.241132736206 and batch: 1950, loss is 3.658774981498718 and perplexity is 38.813766154459366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315471986282703 and perplexity of 74.84894278243377
finished 18 epochs...
Completing Train Step...
At time: 1017.5479984283447 and batch: 50, loss is 3.889060206413269 and perplexity is 48.86494197883143
At time: 1018.9006900787354 and batch: 100, loss is 3.857773756980896 and perplexity is 47.35979949737213
At time: 1020.2520914077759 and batch: 150, loss is 3.8055776834487913 and perplexity is 44.95121018406627
At time: 1021.6045608520508 and batch: 200, loss is 3.799911036491394 and perplexity is 44.69720789597811
At time: 1022.9737401008606 and batch: 250, loss is 3.8069467115402222 and perplexity is 45.01279179741315
At time: 1024.32568192482 and batch: 300, loss is 3.811881628036499 and perplexity is 45.235475176212795
At time: 1025.6773042678833 and batch: 350, loss is 3.8284049701690672 and perplexity is 45.98912567481772
At time: 1027.030279636383 and batch: 400, loss is 3.788293118476868 and perplexity is 44.18092427669086
At time: 1028.3826804161072 and batch: 450, loss is 3.836634397506714 and perplexity is 46.36915139518722
At time: 1029.7338383197784 and batch: 500, loss is 3.8284955549240114 and perplexity is 45.993291777186904
At time: 1031.0862247943878 and batch: 550, loss is 3.816122570037842 and perplexity is 45.42772357184453
At time: 1032.4364206790924 and batch: 600, loss is 3.7723967313766478 and perplexity is 43.48415989247929
At time: 1033.7869119644165 and batch: 650, loss is 3.8050305080413818 and perplexity is 44.92662071531005
At time: 1035.1389615535736 and batch: 700, loss is 3.8484622383117677 and perplexity is 46.920854633366396
At time: 1036.4913260936737 and batch: 750, loss is 3.803062205314636 and perplexity is 44.838278495889725
At time: 1037.8430669307709 and batch: 800, loss is 3.779121117591858 and perplexity is 43.7775495048481
At time: 1039.193526506424 and batch: 850, loss is 3.778268928527832 and perplexity is 43.740258647597386
At time: 1040.5451188087463 and batch: 900, loss is 3.7297052001953124 and perplexity is 41.666822982006586
At time: 1041.8977658748627 and batch: 950, loss is 3.839708743095398 and perplexity is 46.51192554731876
At time: 1043.2492156028748 and batch: 1000, loss is 3.7913258361816404 and perplexity is 44.31511592780517
At time: 1044.5997471809387 and batch: 1050, loss is 3.7456498622894285 and perplexity is 42.33651118305911
At time: 1045.950940132141 and batch: 1100, loss is 3.7605003690719605 and perplexity is 42.96992142019074
At time: 1047.3023669719696 and batch: 1150, loss is 3.7397925329208372 and perplexity is 42.089257123879335
At time: 1048.655509710312 and batch: 1200, loss is 3.7829602003097533 and perplexity is 43.94593816075628
At time: 1050.0058073997498 and batch: 1250, loss is 3.770276961326599 and perplexity is 43.392081100099944
At time: 1051.3578929901123 and batch: 1300, loss is 3.763162775039673 and perplexity is 43.084477224772705
At time: 1052.7091238498688 and batch: 1350, loss is 3.6342670488357545 and perplexity is 37.87408286821484
At time: 1054.0601015090942 and batch: 1400, loss is 3.6616769361495973 and perplexity is 38.926565533851104
At time: 1055.411898136139 and batch: 1450, loss is 3.5933421897888183 and perplexity is 36.35537968221618
At time: 1056.7632389068604 and batch: 1500, loss is 3.5931408262252806 and perplexity is 36.34805977041611
At time: 1058.1139149665833 and batch: 1550, loss is 3.619941539764404 and perplexity is 37.33538512284338
At time: 1059.464023590088 and batch: 1600, loss is 3.7034721851348875 and perplexity is 40.58798898920975
At time: 1060.814771413803 and batch: 1650, loss is 3.655232005119324 and perplexity is 38.67649321875841
At time: 1062.1642730236053 and batch: 1700, loss is 3.644970121383667 and perplexity is 38.28162903236373
At time: 1063.5128781795502 and batch: 1750, loss is 3.62313196182251 and perplexity is 37.45469097590068
At time: 1064.8767697811127 and batch: 1800, loss is 3.5959327936172487 and perplexity is 36.44968416804441
At time: 1066.2295336723328 and batch: 1850, loss is 3.6108916139602663 and perplexity is 36.99902696148842
At time: 1067.5820665359497 and batch: 1900, loss is 3.7133373117446897 and perplexity is 40.99037617632003
At time: 1068.9340903759003 and batch: 1950, loss is 3.658640241622925 and perplexity is 38.80853674474157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315390795330669 and perplexity of 74.84286597220483
finished 19 epochs...
Completing Train Step...
At time: 1073.2577242851257 and batch: 50, loss is 3.8873763990402224 and perplexity is 48.78273206149997
At time: 1074.611650943756 and batch: 100, loss is 3.8557352781295777 and perplexity is 47.26335588022779
At time: 1075.9638242721558 and batch: 150, loss is 3.8034120273590086 and perplexity is 44.853966658011785
At time: 1077.3168728351593 and batch: 200, loss is 3.797575387954712 and perplexity is 44.59293275021185
At time: 1078.672336101532 and batch: 250, loss is 3.804545907974243 and perplexity is 44.904854546264545
At time: 1080.0283942222595 and batch: 300, loss is 3.8094320487976074 and perplexity is 45.12480290095383
At time: 1081.38760304451 and batch: 350, loss is 3.825951490402222 and perplexity is 45.876430589566645
At time: 1082.740388393402 and batch: 400, loss is 3.785795979499817 and perplexity is 44.07073600361161
At time: 1084.0929265022278 and batch: 450, loss is 3.8341139793395995 and perplexity is 46.25242890015565
At time: 1085.4471082687378 and batch: 500, loss is 3.8259798669815064 and perplexity is 45.87773242420728
At time: 1086.8027427196503 and batch: 550, loss is 3.8137040185928344 and perplexity is 45.31798704057058
At time: 1088.1582312583923 and batch: 600, loss is 3.7701202917098997 and perplexity is 43.385283411895706
At time: 1089.5104076862335 and batch: 650, loss is 3.802870750427246 and perplexity is 44.82969481005006
At time: 1090.8961956501007 and batch: 700, loss is 3.846353178024292 and perplexity is 46.82200000403444
At time: 1092.248376607895 and batch: 750, loss is 3.8011319732666013 and perplexity is 44.751813689174575
At time: 1093.6052503585815 and batch: 800, loss is 3.7772692441940308 and perplexity is 43.696554045313825
At time: 1094.961373090744 and batch: 850, loss is 3.7764837169647216 and perplexity is 43.662242690300396
At time: 1096.3156764507294 and batch: 900, loss is 3.72801540851593 and perplexity is 41.59647418537037
At time: 1097.6676959991455 and batch: 950, loss is 3.838196997642517 and perplexity is 46.44166447717558
At time: 1099.0189244747162 and batch: 1000, loss is 3.789845361709595 and perplexity is 44.2495570710296
At time: 1100.3705425262451 and batch: 1050, loss is 3.7442135047912597 and perplexity is 42.275744469584716
At time: 1101.725867509842 and batch: 1100, loss is 3.7591761636734007 and perplexity is 42.913058075953394
At time: 1103.08043384552 and batch: 1150, loss is 3.7386090993881225 and perplexity is 42.039476747325175
At time: 1104.4351646900177 and batch: 1200, loss is 3.7817136955261232 and perplexity is 43.89119346546847
At time: 1105.787005662918 and batch: 1250, loss is 3.769174222946167 and perplexity is 43.34425736024701
At time: 1107.1397898197174 and batch: 1300, loss is 3.762188935279846 and perplexity is 43.04254027107062
At time: 1108.4923326969147 and batch: 1350, loss is 3.633297157287598 and perplexity is 37.837366923467215
At time: 1109.8498749732971 and batch: 1400, loss is 3.6607684087753296 and perplexity is 38.89121574403478
At time: 1111.2060067653656 and batch: 1450, loss is 3.592581105232239 and perplexity is 36.327720690942144
At time: 1112.5588645935059 and batch: 1500, loss is 3.592625856399536 and perplexity is 36.32934643522502
At time: 1113.9110205173492 and batch: 1550, loss is 3.6195718669891357 and perplexity is 37.32158579818377
At time: 1115.265156030655 and batch: 1600, loss is 3.7031506586074827 and perplexity is 40.57494097180997
At time: 1116.6191339492798 and batch: 1650, loss is 3.654963722229004 and perplexity is 38.6661183691298
At time: 1117.9760925769806 and batch: 1700, loss is 3.6447406721115114 and perplexity is 38.27284634807412
At time: 1119.3313992023468 and batch: 1750, loss is 3.6230562686920167 and perplexity is 37.451856020383744
At time: 1120.6835706233978 and batch: 1800, loss is 3.5959203386306764 and perplexity is 36.44923019054468
At time: 1122.0358710289001 and batch: 1850, loss is 3.610871767997742 and perplexity is 36.99829268747211
At time: 1123.3875992298126 and batch: 1900, loss is 3.71324059009552 and perplexity is 40.98641171126405
At time: 1124.743679523468 and batch: 1950, loss is 3.6583045291900635 and perplexity is 38.79551042312661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31538454987282 and perplexity of 74.84239854569978
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa20428cb38>
ELAPSED
3504.7759535312653


RESULTS SO FAR:
[{'best_accuracy': -74.4178468006303, 'params': {'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}}, {'best_accuracy': -77.53052041197337, 'params': {'dropout': 0.9649993788704626, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.2039606990300309, 'data': 'wikitext'}}, {'best_accuracy': -74.84239854569978, 'params': {'dropout': 0.18248612094762118, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.031083902810406072, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'dropout': 0.6426102732804025, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.040188596927537734, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.169343948364258 and batch: 50, loss is 7.69259108543396 and perplexity is 2192.046991210071
At time: 3.771141290664673 and batch: 100, loss is 7.038888359069825 and perplexity is 1140.1194984193273
At time: 5.377561807632446 and batch: 150, loss is 6.731493654251099 and perplexity is 838.3986088308892
At time: 6.988251447677612 and batch: 200, loss is 6.453876428604126 and perplexity is 635.1596779398086
At time: 8.597838401794434 and batch: 250, loss is 6.35238715171814 and perplexity is 573.8609684392834
At time: 10.210433721542358 and batch: 300, loss is 6.2655760765075685 and perplexity is 526.1445982144405
At time: 11.822634935379028 and batch: 350, loss is 6.185297174453735 and perplexity is 485.5572373774008
At time: 13.429357051849365 and batch: 400, loss is 6.1154592323303225 and perplexity is 452.80394184100066
At time: 15.040593385696411 and batch: 450, loss is 6.011125001907349 and perplexity is 407.94199774456075
At time: 16.650878190994263 and batch: 500, loss is 5.983724126815796 and perplexity is 396.91578384676365
At time: 18.25713086128235 and batch: 550, loss is 5.920482187271118 and perplexity is 372.59132936489976
At time: 19.86387038230896 and batch: 600, loss is 5.9433712387084965 and perplexity is 381.2179423353669
At time: 21.47159242630005 and batch: 650, loss is 6.003944463729859 and perplexity is 405.0232462995676
At time: 23.082253217697144 and batch: 700, loss is 5.903862133026123 and perplexity is 366.45001709645527
At time: 24.689516067504883 and batch: 750, loss is 5.824254293441772 and perplexity is 338.40868538762163
At time: 26.295108795166016 and batch: 800, loss is 5.828803586959839 and perplexity is 339.9517130080724
At time: 27.899388313293457 and batch: 850, loss is 5.849269027709961 and perplexity is 346.98065451307843
At time: 29.51067352294922 and batch: 900, loss is 5.82499888420105 and perplexity is 338.66075520040135
At time: 31.12359881401062 and batch: 950, loss is 5.831798868179321 and perplexity is 340.97149048731336
At time: 32.728774547576904 and batch: 1000, loss is 5.810863828659057 and perplexity is 333.90743994567185
At time: 34.33445119857788 and batch: 1050, loss is 5.706987428665161 and perplexity is 300.96302860955876
At time: 35.93807291984558 and batch: 1100, loss is 5.769397621154785 and perplexity is 320.3447056416457
At time: 37.55202555656433 and batch: 1150, loss is 5.674915323257446 and perplexity is 291.46365730729764
At time: 39.17163395881653 and batch: 1200, loss is 5.745013437271118 and perplexity is 312.6278286667233
At time: 40.78691053390503 and batch: 1250, loss is 5.6812121772766115 and perplexity is 293.3047518777906
At time: 42.40181565284729 and batch: 1300, loss is 5.689175052642822 and perplexity is 295.64962463589774
At time: 44.018861293792725 and batch: 1350, loss is 5.654455623626709 and perplexity is 285.5609877515921
At time: 45.64189577102661 and batch: 1400, loss is 5.6576274871826175 and perplexity is 286.468186235947
At time: 47.261518239974976 and batch: 1450, loss is 5.622765254974365 and perplexity is 276.6533435098119
At time: 48.87901067733765 and batch: 1500, loss is 5.581129302978516 and perplexity is 265.37112103005813
At time: 50.496118783950806 and batch: 1550, loss is 5.55994665145874 and perplexity is 259.80897552337706
At time: 52.115745544433594 and batch: 1600, loss is 5.581083106994629 and perplexity is 265.35886223318266
At time: 53.737762451171875 and batch: 1650, loss is 5.570613832473755 and perplexity is 262.5952392640432
At time: 55.35604429244995 and batch: 1700, loss is 5.581125974655151 and perplexity is 265.3702377906256
At time: 56.97216463088989 and batch: 1750, loss is 5.570897798538208 and perplexity is 262.6698179890937
At time: 58.58854627609253 and batch: 1800, loss is 5.5680673217773435 and perplexity is 261.9273883840374
At time: 60.20767164230347 and batch: 1850, loss is 5.536051845550537 and perplexity is 253.67447372268475
At time: 61.82930827140808 and batch: 1900, loss is 5.549118309020996 and perplexity is 257.01085182942745
At time: 63.44709253311157 and batch: 1950, loss is 5.480736894607544 and perplexity is 240.0235142555745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.996274300508721 and perplexity of 147.86124504259416
finished 1 epochs...
Completing Train Step...
At time: 67.8523383140564 and batch: 50, loss is 5.289631929397583 and perplexity is 198.27043445904084
At time: 69.2069365978241 and batch: 100, loss is 5.2144261169433594 and perplexity is 183.90625000895787
At time: 70.5581443309784 and batch: 150, loss is 5.122666063308716 and perplexity is 167.78209154015588
At time: 71.90821290016174 and batch: 200, loss is 5.079363746643066 and perplexity is 160.67179543105703
At time: 73.25932908058167 and batch: 250, loss is 5.093268518447876 and perplexity is 162.92150468192418
At time: 74.61082029342651 and batch: 300, loss is 5.10035325050354 and perplexity is 164.07985835626428
At time: 75.98625135421753 and batch: 350, loss is 5.089112243652344 and perplexity is 162.24576339436965
At time: 77.341717004776 and batch: 400, loss is 5.041461124420166 and perplexity is 154.695879905191
At time: 78.69207549095154 and batch: 450, loss is 4.990971221923828 and perplexity is 147.07920069455238
At time: 80.04372191429138 and batch: 500, loss is 4.9780189990997314 and perplexity is 145.18648203144542
At time: 81.39688920974731 and batch: 550, loss is 4.940668001174926 and perplexity is 139.86364744240333
At time: 82.74994921684265 and batch: 600, loss is 4.918281288146972 and perplexity is 136.76734740624622
At time: 84.1055760383606 and batch: 650, loss is 4.989338054656982 and perplexity is 146.83919179902685
At time: 85.4586660861969 and batch: 700, loss is 4.985052576065064 and perplexity is 146.2112620369049
At time: 86.80977702140808 and batch: 750, loss is 4.927462205886841 and perplexity is 138.0287788610801
At time: 88.16194319725037 and batch: 800, loss is 4.930152225494385 and perplexity is 138.40057883302728
At time: 89.5139844417572 and batch: 850, loss is 4.918851737976074 and perplexity is 136.84538857336972
At time: 90.8684024810791 and batch: 900, loss is 4.90606011390686 and perplexity is 135.10606192988467
At time: 92.2239363193512 and batch: 950, loss is 4.955417737960816 and perplexity is 141.9418885049563
At time: 93.57684969902039 and batch: 1000, loss is 4.917669048309326 and perplexity is 136.683638615218
At time: 94.92646908760071 and batch: 1050, loss is 4.833250522613525 and perplexity is 125.61862391421258
At time: 96.27788925170898 and batch: 1100, loss is 4.89571626663208 and perplexity is 133.71574845091118
At time: 97.62946724891663 and batch: 1150, loss is 4.817834892272949 and perplexity is 123.6969833493604
At time: 98.98552012443542 and batch: 1200, loss is 4.898785552978516 and perplexity is 134.1267908526647
At time: 100.34113693237305 and batch: 1250, loss is 4.864916477203369 and perplexity is 129.66010858465782
At time: 101.69307851791382 and batch: 1300, loss is 4.871937465667725 and perplexity is 130.57365395435866
At time: 103.04376602172852 and batch: 1350, loss is 4.767455768585205 and perplexity is 117.61960944971877
At time: 104.3938250541687 and batch: 1400, loss is 4.775424432754517 and perplexity is 118.56062495591823
At time: 105.7464656829834 and batch: 1450, loss is 4.725504703521729 and perplexity is 112.78740821369502
At time: 107.10194730758667 and batch: 1500, loss is 4.698473882675171 and perplexity is 109.7795081376772
At time: 108.4542589187622 and batch: 1550, loss is 4.704481763839722 and perplexity is 110.44103557619187
At time: 109.80599975585938 and batch: 1600, loss is 4.760939388275147 and perplexity is 116.85564718032455
At time: 111.15756940841675 and batch: 1650, loss is 4.733567247390747 and perplexity is 113.70043736315615
At time: 112.51021695137024 and batch: 1700, loss is 4.747969179153443 and perplexity is 115.34979173964798
At time: 113.85935115814209 and batch: 1750, loss is 4.735787487030029 and perplexity is 113.95316002981907
At time: 115.20615363121033 and batch: 1800, loss is 4.701438369750977 and perplexity is 110.10543092900188
At time: 116.55625605583191 and batch: 1850, loss is 4.713509912490845 and perplexity is 111.4426281226596
At time: 117.91153192520142 and batch: 1900, loss is 4.810745353698731 and perplexity is 122.82313008271076
At time: 119.26805830001831 and batch: 1950, loss is 4.72112732887268 and perplexity is 112.29477448008632
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5774714980014535 and perplexity of 97.26814032433008
finished 2 epochs...
Completing Train Step...
At time: 123.56252145767212 and batch: 50, loss is 4.693670558929443 and perplexity is 109.25346600617564
At time: 124.93356370925903 and batch: 100, loss is 4.627503213882446 and perplexity is 102.25842768590822
At time: 126.28672623634338 and batch: 150, loss is 4.567167921066284 and perplexity is 96.27107604241348
At time: 127.6405246257782 and batch: 200, loss is 4.553724193572998 and perplexity is 94.98549479486977
At time: 129.001220703125 and batch: 250, loss is 4.566051912307739 and perplexity is 96.16369660769531
At time: 130.36163759231567 and batch: 300, loss is 4.58823016166687 and perplexity is 98.32026511129925
At time: 131.720947265625 and batch: 350, loss is 4.5926691341400145 and perplexity is 98.75767617126176
At time: 133.0827512741089 and batch: 400, loss is 4.540488500595092 and perplexity is 93.73657931175798
At time: 134.43773126602173 and batch: 450, loss is 4.538675804138183 and perplexity is 93.56681725657938
At time: 135.79052710533142 and batch: 500, loss is 4.535603637695313 and perplexity is 93.27980552008994
At time: 137.14309072494507 and batch: 550, loss is 4.51370322227478 and perplexity is 91.25914642872614
At time: 138.49335289001465 and batch: 600, loss is 4.48231595993042 and perplexity is 88.43925745567472
At time: 139.85212016105652 and batch: 650, loss is 4.546617641448974 and perplexity is 94.31286828357206
At time: 141.2203311920166 and batch: 700, loss is 4.581286153793335 and perplexity is 97.63989340340191
At time: 142.58375120162964 and batch: 750, loss is 4.527902126312256 and perplexity is 92.5641693134872
At time: 143.98014402389526 and batch: 800, loss is 4.522533016204834 and perplexity is 92.06851390138434
At time: 145.33871817588806 and batch: 850, loss is 4.518464269638062 and perplexity is 91.69467150226644
At time: 146.69686150550842 and batch: 900, loss is 4.49363263130188 and perplexity is 89.4457799690512
At time: 148.058495759964 and batch: 950, loss is 4.55348690032959 and perplexity is 94.9629580527472
At time: 149.42278599739075 and batch: 1000, loss is 4.528497343063354 and perplexity is 92.61928145782275
At time: 150.78750371932983 and batch: 1050, loss is 4.466733293533325 and perplexity is 87.0718198423401
At time: 152.1470606327057 and batch: 1100, loss is 4.507746887207031 and perplexity is 90.71719200794472
At time: 153.50510001182556 and batch: 1150, loss is 4.461329374313355 and perplexity is 86.6025598251464
At time: 154.8637306690216 and batch: 1200, loss is 4.534006509780884 and perplexity is 93.13094464541355
At time: 156.22550559043884 and batch: 1250, loss is 4.530381155014038 and perplexity is 92.79392321156152
At time: 157.5896987915039 and batch: 1300, loss is 4.519363307952881 and perplexity is 91.77714559334056
At time: 158.95003652572632 and batch: 1350, loss is 4.396989212036133 and perplexity is 81.2060061694423
At time: 160.30931949615479 and batch: 1400, loss is 4.407713623046875 and perplexity is 82.08157936772676
At time: 161.66016507148743 and batch: 1450, loss is 4.361062655448913 and perplexity is 78.34033899446106
At time: 163.01254844665527 and batch: 1500, loss is 4.347906441688537 and perplexity is 77.31642692034022
At time: 164.3671805858612 and batch: 1550, loss is 4.364237289428711 and perplexity is 78.58943608345702
At time: 165.72500824928284 and batch: 1600, loss is 4.43212345123291 and perplexity is 84.10983054026856
At time: 167.07553672790527 and batch: 1650, loss is 4.402122173309326 and perplexity is 81.62390506614558
At time: 168.4266939163208 and batch: 1700, loss is 4.414934749603272 and perplexity is 82.67644605919672
At time: 169.78061366081238 and batch: 1750, loss is 4.409150009155273 and perplexity is 82.19956492420744
At time: 171.1317584514618 and batch: 1800, loss is 4.367600727081299 and perplexity is 78.85421178053934
At time: 172.48720335960388 and batch: 1850, loss is 4.401285724639893 and perplexity is 81.5556594053341
At time: 173.84300351142883 and batch: 1900, loss is 4.507879228591919 and perplexity is 90.72919844122461
At time: 175.19548273086548 and batch: 1950, loss is 4.418397922515869 and perplexity is 82.96326525326522
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.462156499818314 and perplexity of 86.67422064333229
finished 3 epochs...
Completing Train Step...
At time: 179.48920464515686 and batch: 50, loss is 4.401847462654114 and perplexity is 81.6014851893344
At time: 180.8705117702484 and batch: 100, loss is 4.345677366256714 and perplexity is 77.1442747140247
At time: 182.22296786308289 and batch: 150, loss is 4.295759916305542 and perplexity is 73.38796196954603
At time: 183.57620072364807 and batch: 200, loss is 4.292252902984619 and perplexity is 73.13104018670728
At time: 184.92821764945984 and batch: 250, loss is 4.294071202278137 and perplexity is 73.26413527209283
At time: 186.28698825836182 and batch: 300, loss is 4.315936250686645 and perplexity is 74.88370055001317
At time: 187.6498577594757 and batch: 350, loss is 4.326202230453491 and perplexity is 75.65641465202295
At time: 189.00573682785034 and batch: 400, loss is 4.269764366149903 and perplexity is 71.50478468625609
At time: 190.35851168632507 and batch: 450, loss is 4.287099046707153 and perplexity is 72.75510291165006
At time: 191.7098343372345 and batch: 500, loss is 4.287413883209228 and perplexity is 72.7780124799538
At time: 193.0594403743744 and batch: 550, loss is 4.266801404953003 and perplexity is 71.29323234929139
At time: 194.41287064552307 and batch: 600, loss is 4.2443983840942385 and perplexity is 69.71380659031009
At time: 195.76755285263062 and batch: 650, loss is 4.29978310585022 and perplexity is 73.68381037890939
At time: 197.1229748725891 and batch: 700, loss is 4.345776376724243 and perplexity is 77.15191318286925
At time: 198.47663712501526 and batch: 750, loss is 4.292394142150879 and perplexity is 73.1413698833127
At time: 199.8293206691742 and batch: 800, loss is 4.284824938774109 and perplexity is 72.58983794136242
At time: 201.18211197853088 and batch: 850, loss is 4.286064338684082 and perplexity is 72.67986155607807
At time: 202.53652906417847 and batch: 900, loss is 4.250571284294129 and perplexity is 70.14547390987629
At time: 203.89618682861328 and batch: 950, loss is 4.324678649902344 and perplexity is 75.5412337760416
At time: 205.25052976608276 and batch: 1000, loss is 4.299704570770263 and perplexity is 73.6780238421958
At time: 206.60323023796082 and batch: 1050, loss is 4.251625413894653 and perplexity is 70.21945531641218
At time: 207.9559588432312 and batch: 1100, loss is 4.282944135665893 and perplexity is 72.45343905846725
At time: 209.31156992912292 and batch: 1150, loss is 4.248360886573791 and perplexity is 69.99059574848074
At time: 210.67798137664795 and batch: 1200, loss is 4.318155226707458 and perplexity is 75.05005018054722
At time: 212.05875897407532 and batch: 1250, loss is 4.319305295944214 and perplexity is 75.13641258633089
At time: 213.41179776191711 and batch: 1300, loss is 4.297544355392456 and perplexity is 73.5190352287364
At time: 214.76386952400208 and batch: 1350, loss is 4.171381034851074 and perplexity is 64.8048881450941
At time: 216.11582326889038 and batch: 1400, loss is 4.195690426826477 and perplexity is 66.39955979230673
At time: 217.46882963180542 and batch: 1450, loss is 4.146181612014771 and perplexity is 63.1922465221193
At time: 218.82392144203186 and batch: 1500, loss is 4.138631772994995 and perplexity is 62.71695169096146
At time: 220.1813931465149 and batch: 1550, loss is 4.156681933403015 and perplexity is 63.859281331035895
At time: 221.53300285339355 and batch: 1600, loss is 4.23044451713562 and perplexity is 68.74778495117356
At time: 222.88395595550537 and batch: 1650, loss is 4.197246260643006 and perplexity is 66.50294687854162
At time: 224.23536562919617 and batch: 1700, loss is 4.208481211662292 and perplexity is 67.25431712994177
At time: 225.58944034576416 and batch: 1750, loss is 4.2024247932434085 and perplexity is 66.84822780963201
At time: 226.94671750068665 and batch: 1800, loss is 4.16158477306366 and perplexity is 64.173141923616
At time: 228.30430793762207 and batch: 1850, loss is 4.2019921875 and perplexity is 66.81931513669
At time: 229.65672397613525 and batch: 1900, loss is 4.308555536270141 and perplexity is 74.3330399757867
At time: 231.00929856300354 and batch: 1950, loss is 4.218973169326782 and perplexity is 67.96366127528671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.427184490824855 and perplexity of 83.69543958991481
finished 4 epochs...
Completing Train Step...
At time: 235.31107020378113 and batch: 50, loss is 4.2128588533401485 and perplexity is 67.54937779535328
At time: 236.68084049224854 and batch: 100, loss is 4.1607501745224 and perplexity is 64.11960545681465
At time: 238.03188967704773 and batch: 150, loss is 4.1169593620300295 and perplexity is 61.372347179137584
At time: 239.3834855556488 and batch: 200, loss is 4.11733904838562 and perplexity is 61.395653846303844
At time: 240.73794865608215 and batch: 250, loss is 4.111995582580566 and perplexity is 61.06846321388751
At time: 242.09311771392822 and batch: 300, loss is 4.129579882621766 and perplexity is 62.151806395183584
At time: 243.4472210407257 and batch: 350, loss is 4.1429832172393795 and perplexity is 62.99045564646106
At time: 244.8337664604187 and batch: 400, loss is 4.085604615211487 and perplexity is 59.47788811798267
At time: 246.18733620643616 and batch: 450, loss is 4.115042181015014 and perplexity is 61.25479799781335
At time: 247.53820967674255 and batch: 500, loss is 4.119332542419434 and perplexity is 61.5181677907845
At time: 248.8933277130127 and batch: 550, loss is 4.096897268295288 and perplexity is 60.153358020088554
At time: 250.2479190826416 and batch: 600, loss is 4.079141821861267 and perplexity is 59.094734273846875
At time: 251.6048641204834 and batch: 650, loss is 4.130258860588074 and perplexity is 62.19402043187082
At time: 252.95837950706482 and batch: 700, loss is 4.183740620613098 and perplexity is 65.61081995011017
At time: 254.31570434570312 and batch: 750, loss is 4.124128723144532 and perplexity is 61.81392873590061
At time: 255.6687548160553 and batch: 800, loss is 4.11862557888031 and perplexity is 61.474692058852106
At time: 257.0270013809204 and batch: 850, loss is 4.121011338233948 and perplexity is 61.62153097195001
At time: 258.3814971446991 and batch: 900, loss is 4.086174125671387 and perplexity is 59.51177104482343
At time: 259.73392963409424 and batch: 950, loss is 4.163671326637268 and perplexity is 64.30718241492842
At time: 261.0862669944763 and batch: 1000, loss is 4.1374404954910275 and perplexity is 62.64228288176138
At time: 262.43837571144104 and batch: 1050, loss is 4.09964961051941 and perplexity is 60.31914869897214
At time: 263.7939043045044 and batch: 1100, loss is 4.122558631896973 and perplexity is 61.71695137898707
At time: 265.1562671661377 and batch: 1150, loss is 4.093090786933899 and perplexity is 59.9248206215795
At time: 266.51051807403564 and batch: 1200, loss is 4.165222225189209 and perplexity is 64.40699370960506
At time: 267.86374950408936 and batch: 1250, loss is 4.161961283683777 and perplexity is 64.19730834224767
At time: 269.21562910079956 and batch: 1300, loss is 4.137930569648742 and perplexity is 62.672989769493476
At time: 270.5677218437195 and batch: 1350, loss is 4.013480181694031 and perplexity is 55.33912604083388
At time: 271.92104268074036 and batch: 1400, loss is 4.042799553871155 and perplexity is 56.98565410969266
At time: 273.27673387527466 and batch: 1450, loss is 3.9925438356399536 and perplexity is 54.19257116309133
At time: 274.63203525543213 and batch: 1500, loss is 3.9901459503173826 and perplexity is 54.06277926733824
At time: 275.99256110191345 and batch: 1550, loss is 4.00856050491333 and perplexity is 55.067544023023096
At time: 277.346066236496 and batch: 1600, loss is 4.08137535572052 and perplexity is 59.2268718757224
At time: 278.70097732543945 and batch: 1650, loss is 4.050193462371826 and perplexity is 57.40856236781937
At time: 280.05633211135864 and batch: 1700, loss is 4.059774327278137 and perplexity is 57.96122933453193
At time: 281.41104650497437 and batch: 1750, loss is 4.051467165946961 and perplexity is 57.48173044628032
At time: 282.76369976997375 and batch: 1800, loss is 4.0099925565719605 and perplexity is 55.14646008322887
At time: 284.1149125099182 and batch: 1850, loss is 4.053470048904419 and perplexity is 57.5969749967037
At time: 285.4666247367859 and batch: 1900, loss is 4.1591594028472905 and perplexity is 64.01768689071135
At time: 286.820392370224 and batch: 1950, loss is 4.075612425804138 and perplexity is 58.88653317988747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425301201398983 and perplexity of 83.53796518502611
finished 5 epochs...
Completing Train Step...
At time: 291.11740469932556 and batch: 50, loss is 4.071343092918396 and perplexity is 58.63566287273666
At time: 292.4843719005585 and batch: 100, loss is 4.021641592979432 and perplexity is 55.792619464588995
At time: 293.8365399837494 and batch: 150, loss is 3.9832270336151123 and perplexity is 53.690014452310194
At time: 295.1880648136139 and batch: 200, loss is 3.9816723346710203 and perplexity is 53.60660749668599
At time: 296.540824174881 and batch: 250, loss is 3.975885992050171 and perplexity is 53.297316992347916
At time: 297.8926694393158 and batch: 300, loss is 3.9903009700775147 and perplexity is 54.07116071604064
At time: 299.243940114975 and batch: 350, loss is 4.009625687599182 and perplexity is 55.12623226877138
At time: 300.59748458862305 and batch: 400, loss is 3.9508767414093016 and perplexity is 51.980920688099545
At time: 301.9490087032318 and batch: 450, loss is 3.987251091003418 and perplexity is 53.90650143753968
At time: 303.30155301094055 and batch: 500, loss is 3.9944970273971556 and perplexity is 54.29852308491534
At time: 304.6536581516266 and batch: 550, loss is 3.972692022323608 and perplexity is 53.12735854092674
At time: 306.00439381599426 and batch: 600, loss is 3.9567705821990966 and perplexity is 52.28819257504862
At time: 307.35682487487793 and batch: 650, loss is 3.999144129753113 and perplexity is 54.55144109224343
At time: 308.71443939208984 and batch: 700, loss is 4.054407014846801 and perplexity is 57.65096669089921
At time: 310.07421827316284 and batch: 750, loss is 3.9955846309661864 and perplexity is 54.35761047842117
At time: 311.4260528087616 and batch: 800, loss is 3.99289942741394 and perplexity is 54.211845022217894
At time: 312.81121706962585 and batch: 850, loss is 3.992244534492493 and perplexity is 54.17635369143337
At time: 314.1635673046112 and batch: 900, loss is 3.959374575614929 and perplexity is 52.42452811562637
At time: 315.5144782066345 and batch: 950, loss is 4.0413466787338255 and perplexity is 56.9029211845103
At time: 316.8669354915619 and batch: 1000, loss is 4.012646932601928 and perplexity is 55.29303397005749
At time: 318.2172191143036 and batch: 1050, loss is 3.9797821712493895 and perplexity is 53.505377948371454
At time: 319.5672187805176 and batch: 1100, loss is 4.000842108726501 and perplexity is 54.64414697623334
At time: 320.9186842441559 and batch: 1150, loss is 3.9748944425582886 and perplexity is 53.24449625628012
At time: 322.2684359550476 and batch: 1200, loss is 4.045411601066589 and perplexity is 57.13469789765284
At time: 323.61958146095276 and batch: 1250, loss is 4.0423985195159915 and perplexity is 56.962805486490886
At time: 324.971474647522 and batch: 1300, loss is 4.014875903129577 and perplexity is 55.41641797172855
At time: 326.3229274749756 and batch: 1350, loss is 3.889249334335327 and perplexity is 48.87418457775859
At time: 327.67537355422974 and batch: 1400, loss is 3.9274714899063112 and perplexity is 50.778421458655856
At time: 329.02653455734253 and batch: 1450, loss is 3.8727528047561646 and perplexity is 48.07454392816283
At time: 330.37755584716797 and batch: 1500, loss is 3.8705011558532716 and perplexity is 47.96641870976679
At time: 331.72809982299805 and batch: 1550, loss is 3.8918170309066773 and perplexity is 48.99983990726801
At time: 333.0785222053528 and batch: 1600, loss is 3.9658326530456542 and perplexity is 52.76418536336966
At time: 334.429443359375 and batch: 1650, loss is 3.9353889560699464 and perplexity is 51.18205365601593
At time: 335.7814600467682 and batch: 1700, loss is 3.941626853942871 and perplexity is 51.50231993532062
At time: 337.1383173465729 and batch: 1750, loss is 3.936542615890503 and perplexity is 51.24113440784451
At time: 338.4902834892273 and batch: 1800, loss is 3.8927288341522215 and perplexity is 49.04453849538865
At time: 339.8409421443939 and batch: 1850, loss is 3.93970440864563 and perplexity is 51.4034046526382
At time: 341.1937065124512 and batch: 1900, loss is 4.039501395225525 and perplexity is 56.79801598216178
At time: 342.54430389404297 and batch: 1950, loss is 3.9618386888504027 and perplexity is 52.55386737706846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4239328783611915 and perplexity of 83.42373643147337
finished 6 epochs...
Completing Train Step...
At time: 346.83264899253845 and batch: 50, loss is 3.9570380020141602 and perplexity is 52.30217734365582
At time: 348.1829307079315 and batch: 100, loss is 3.912023229598999 and perplexity is 50.0000112085439
At time: 349.53481459617615 and batch: 150, loss is 3.874506187438965 and perplexity is 48.15891094318709
At time: 350.88630628585815 and batch: 200, loss is 3.873331208229065 and perplexity is 48.10235845456287
At time: 352.23804116249084 and batch: 250, loss is 3.86880455493927 and perplexity is 47.88510783549836
At time: 353.58840107917786 and batch: 300, loss is 3.881618847846985 and perplexity is 48.50266999381283
At time: 354.9397211074829 and batch: 350, loss is 3.901489939689636 and perplexity is 49.47611063721066
At time: 356.2920129299164 and batch: 400, loss is 3.8466753244400023 and perplexity is 46.83708597332714
At time: 357.64428067207336 and batch: 450, loss is 3.8806788110733033 and perplexity is 48.45709712383967
At time: 358.9956946372986 and batch: 500, loss is 3.888786964416504 and perplexity is 48.85159184850453
At time: 360.3483865261078 and batch: 550, loss is 3.867413296699524 and perplexity is 47.818533606371936
At time: 361.6998963356018 and batch: 600, loss is 3.8520626258850097 and perplexity is 47.09009237322594
At time: 363.0509738922119 and batch: 650, loss is 3.898464674949646 and perplexity is 49.32665848437719
At time: 364.4022922515869 and batch: 700, loss is 3.9503840160369874 and perplexity is 51.955314678483624
At time: 365.75134015083313 and batch: 750, loss is 3.8981499767303465 and perplexity is 49.31113791506401
At time: 367.1029374599457 and batch: 800, loss is 3.891013569831848 and perplexity is 48.96048625491063
At time: 368.4544577598572 and batch: 850, loss is 3.8938961362838747 and perplexity is 49.10182171662891
At time: 369.8050627708435 and batch: 900, loss is 3.858773183822632 and perplexity is 47.40715581285361
At time: 371.15727043151855 and batch: 950, loss is 3.9458169603347777 and perplexity is 51.71857288030733
At time: 372.5084533691406 and batch: 1000, loss is 3.9140724086761476 and perplexity is 50.102575235508695
At time: 373.85959935188293 and batch: 1050, loss is 3.8806086587905884 and perplexity is 48.4536978670969
At time: 375.21171045303345 and batch: 1100, loss is 3.898882293701172 and perplexity is 49.34726252392755
At time: 376.563791513443 and batch: 1150, loss is 3.8765043687820433 and perplexity is 48.25523738733806
At time: 377.91539311408997 and batch: 1200, loss is 3.9464869785308836 and perplexity is 51.75323687667113
At time: 379.2648229598999 and batch: 1250, loss is 3.945180654525757 and perplexity is 51.685674519768284
At time: 380.6158833503723 and batch: 1300, loss is 3.9150995683670042 and perplexity is 50.154065020787634
At time: 381.9688057899475 and batch: 1350, loss is 3.793355760574341 and perplexity is 44.40516362668177
At time: 383.32130551338196 and batch: 1400, loss is 3.8342730665206908 and perplexity is 46.25978765401418
At time: 384.67377614974976 and batch: 1450, loss is 3.7745547819137575 and perplexity is 43.57810223679544
At time: 386.02651023864746 and batch: 1500, loss is 3.7743048572540285 and perplexity is 43.56721235530392
At time: 387.3783781528473 and batch: 1550, loss is 3.8004232835769653 and perplexity is 44.720109775665776
At time: 388.7296359539032 and batch: 1600, loss is 3.8742415428161623 and perplexity is 48.146167632664614
At time: 390.08079743385315 and batch: 1650, loss is 3.8430280303955078 and perplexity is 46.66656850130453
At time: 391.4379255771637 and batch: 1700, loss is 3.848846445083618 and perplexity is 46.93888540700841
At time: 392.7977046966553 and batch: 1750, loss is 3.8426303625106812 and perplexity is 46.64801439514709
At time: 394.15616154670715 and batch: 1800, loss is 3.7994595336914063 and perplexity is 44.67703153664556
At time: 395.5135352611542 and batch: 1850, loss is 3.8504018592834472 and perplexity is 47.0119516252805
At time: 396.8652489185333 and batch: 1900, loss is 3.9405095767974854 and perplexity is 51.44480970373878
At time: 398.21789956092834 and batch: 1950, loss is 3.8706846237182617 and perplexity is 47.97521981353387
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.433642010356104 and perplexity of 84.23765331944601
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 402.5259199142456 and batch: 50, loss is 3.9178803968429565 and perplexity is 50.29372897372905
At time: 403.8758010864258 and batch: 100, loss is 3.905006227493286 and perplexity is 49.650389108679214
At time: 405.23092126846313 and batch: 150, loss is 3.8765922880172727 and perplexity is 48.25948013741191
At time: 406.5809328556061 and batch: 200, loss is 3.879854998588562 and perplexity is 48.417194000856924
At time: 407.933443069458 and batch: 250, loss is 3.874896249771118 and perplexity is 48.177699584435935
At time: 409.2852029800415 and batch: 300, loss is 3.8881381797790526 and perplexity is 48.81990796531788
At time: 410.63598132133484 and batch: 350, loss is 3.906092338562012 and perplexity is 49.70434424118604
At time: 411.9893116950989 and batch: 400, loss is 3.8430791330337524 and perplexity is 46.668953347008205
At time: 413.35553097724915 and batch: 450, loss is 3.8700460052490233 and perplexity is 47.94459173296507
At time: 414.714825630188 and batch: 500, loss is 3.874031310081482 and perplexity is 48.13604679608167
At time: 416.07053112983704 and batch: 550, loss is 3.8481935024261475 and perplexity is 46.908247010078725
At time: 417.42391562461853 and batch: 600, loss is 3.8153760766983034 and perplexity is 45.39382473297066
At time: 418.77786803245544 and batch: 650, loss is 3.850976619720459 and perplexity is 47.03898000181812
At time: 420.12896704673767 and batch: 700, loss is 3.898226776123047 and perplexity is 49.31492512593513
At time: 421.4806730747223 and batch: 750, loss is 3.8400768041610718 and perplexity is 46.52904792704961
At time: 422.8331151008606 and batch: 800, loss is 3.8276600885391234 and perplexity is 45.95488197526008
At time: 424.18773221969604 and batch: 850, loss is 3.8294172620773317 and perplexity is 46.03570366589072
At time: 425.54306745529175 and batch: 900, loss is 3.788829460144043 and perplexity is 44.204626703006
At time: 426.9017696380615 and batch: 950, loss is 3.881772584915161 and perplexity is 48.51012722530815
At time: 428.2604022026062 and batch: 1000, loss is 3.8334181785583494 and perplexity is 46.220257617691885
At time: 429.61875796318054 and batch: 1050, loss is 3.788606243133545 and perplexity is 44.19476057956742
At time: 430.9768023490906 and batch: 1100, loss is 3.7999400234222414 and perplexity is 44.69850354963087
At time: 432.32528805732727 and batch: 1150, loss is 3.771754641532898 and perplexity is 43.45624811694108
At time: 433.67687225341797 and batch: 1200, loss is 3.82189603805542 and perplexity is 45.69075765980408
At time: 435.0280818939209 and batch: 1250, loss is 3.8138403415679933 and perplexity is 45.32416534450498
At time: 436.38024973869324 and batch: 1300, loss is 3.7910331869125367 and perplexity is 44.30214903898646
At time: 437.73223423957825 and batch: 1350, loss is 3.6605289220809936 and perplexity is 38.8819029305295
At time: 439.0851950645447 and batch: 1400, loss is 3.692537145614624 and perplexity is 40.146575560702885
At time: 440.43604469299316 and batch: 1450, loss is 3.619490361213684 and perplexity is 37.31854399735606
At time: 441.78742504119873 and batch: 1500, loss is 3.611539421081543 and perplexity is 37.02300295970711
At time: 443.13932728767395 and batch: 1550, loss is 3.6277164697647093 and perplexity is 37.626796512312985
At time: 444.49836254119873 and batch: 1600, loss is 3.699293308258057 and perplexity is 40.41873068167272
At time: 445.8614544868469 and batch: 1650, loss is 3.660628876686096 and perplexity is 38.88578955002208
At time: 447.2234308719635 and batch: 1700, loss is 3.6508175563812255 and perplexity is 38.506134119484166
At time: 448.5826141834259 and batch: 1750, loss is 3.6382505989074705 and perplexity is 38.025257078848405
At time: 449.9383840560913 and batch: 1800, loss is 3.5846323728561402 and perplexity is 36.04010596193652
At time: 451.290488243103 and batch: 1850, loss is 3.616877808570862 and perplexity is 37.22117458335178
At time: 452.6419982910156 and batch: 1900, loss is 3.700990290641785 and perplexity is 40.4873787864503
At time: 453.9950604438782 and batch: 1950, loss is 3.630817894935608 and perplexity is 37.743674356374555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371476710119913 and perplexity of 79.16044245699648
finished 8 epochs...
Completing Train Step...
At time: 458.37135100364685 and batch: 50, loss is 3.8497684955596925 and perplexity is 46.98218538796065
At time: 459.74160742759705 and batch: 100, loss is 3.80601776599884 and perplexity is 44.970996780820485
At time: 461.0924291610718 and batch: 150, loss is 3.765970940589905 and perplexity is 43.205635606242396
At time: 462.44397830963135 and batch: 200, loss is 3.7633246278762815 and perplexity is 43.091451133983604
At time: 463.79366278648376 and batch: 250, loss is 3.7611624717712404 and perplexity is 42.99838134180666
At time: 465.1466042995453 and batch: 300, loss is 3.768992695808411 and perplexity is 43.336389915369224
At time: 466.49799704551697 and batch: 350, loss is 3.788275055885315 and perplexity is 44.180126261908356
At time: 467.8491415977478 and batch: 400, loss is 3.7313542699813844 and perplexity is 41.73559116705173
At time: 469.2003483772278 and batch: 450, loss is 3.760881543159485 and perplexity is 42.986303562804856
At time: 470.55282378196716 and batch: 500, loss is 3.7685481262207032 and perplexity is 43.31712815628521
At time: 471.9043004512787 and batch: 550, loss is 3.745605549812317 and perplexity is 42.334635188941604
At time: 473.25591349601746 and batch: 600, loss is 3.714102954864502 and perplexity is 41.02177219335645
At time: 474.6060428619385 and batch: 650, loss is 3.752160930633545 and perplexity is 42.61306645895132
At time: 475.96311044692993 and batch: 700, loss is 3.8008951568603515 and perplexity is 44.74121698027032
At time: 477.3212151527405 and batch: 750, loss is 3.748616199493408 and perplexity is 42.462281998369356
At time: 478.67898178100586 and batch: 800, loss is 3.7350155830383303 and perplexity is 41.88867831089654
At time: 480.0316174030304 and batch: 850, loss is 3.7411445236206053 and perplexity is 42.146199892444024
At time: 481.41301107406616 and batch: 900, loss is 3.7001168584823607 and perplexity is 40.45203124685352
At time: 482.7659146785736 and batch: 950, loss is 3.7935818958282472 and perplexity is 44.415206335095654
At time: 484.12115693092346 and batch: 1000, loss is 3.7501735925674438 and perplexity is 42.52846398456794
At time: 485.4809265136719 and batch: 1050, loss is 3.7109846687316894 and perplexity is 40.89405380471395
At time: 486.8383643627167 and batch: 1100, loss is 3.7229291152954103 and perplexity is 41.38543946791229
At time: 488.19632935523987 and batch: 1150, loss is 3.697919125556946 and perplexity is 40.36322610661701
At time: 489.55235838890076 and batch: 1200, loss is 3.75072687625885 and perplexity is 42.55200080077902
At time: 490.910275220871 and batch: 1250, loss is 3.7475142240524293 and perplexity is 42.41551537900482
At time: 492.2669939994812 and batch: 1300, loss is 3.7273073053359984 and perplexity is 41.56703001571115
At time: 493.6212570667267 and batch: 1350, loss is 3.59703941822052 and perplexity is 36.49004261203114
At time: 494.9744303226471 and batch: 1400, loss is 3.6323337364196777 and perplexity is 37.800931168887395
At time: 496.32952213287354 and batch: 1450, loss is 3.563285002708435 and perplexity is 35.278898278186716
At time: 497.6814408302307 and batch: 1500, loss is 3.5577123069763186 and perplexity is 35.08284648816927
At time: 499.032488822937 and batch: 1550, loss is 3.577765016555786 and perplexity is 35.79345360734898
At time: 500.38854813575745 and batch: 1600, loss is 3.6557958793640135 and perplexity is 38.698308046991265
At time: 501.74138498306274 and batch: 1650, loss is 3.6184229946136472 and perplexity is 37.27873268034597
At time: 503.0922155380249 and batch: 1700, loss is 3.6136991500854494 and perplexity is 37.10304902079669
At time: 504.4432625770569 and batch: 1750, loss is 3.6051239442825316 and perplexity is 36.786243019195354
At time: 505.7955939769745 and batch: 1800, loss is 3.552872591018677 and perplexity is 34.9134656842857
At time: 507.1483998298645 and batch: 1850, loss is 3.5902195501327516 and perplexity is 36.24203199600236
At time: 508.49806094169617 and batch: 1900, loss is 3.678321237564087 and perplexity is 39.579893030827584
At time: 509.8506245613098 and batch: 1950, loss is 3.6118195390701295 and perplexity is 37.03337522148834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379807867005814 and perplexity of 79.82269535819611
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 514.1265246868134 and batch: 50, loss is 3.8252305507659914 and perplexity is 45.84336837174951
At time: 515.4952390193939 and batch: 100, loss is 3.8157296419143676 and perplexity is 45.40987724805861
At time: 516.8485336303711 and batch: 150, loss is 3.7911870813369752 and perplexity is 44.30896741735596
At time: 518.1995213031769 and batch: 200, loss is 3.8033765506744386 and perplexity is 44.8523754162111
At time: 519.5511560440063 and batch: 250, loss is 3.807531270980835 and perplexity is 45.03911214196012
At time: 520.9021816253662 and batch: 300, loss is 3.817137975692749 and perplexity is 45.473874566273984
At time: 522.2542350292206 and batch: 350, loss is 3.8392292213439942 and perplexity is 46.489627413966396
At time: 523.6060531139374 and batch: 400, loss is 3.7814089679718017 and perplexity is 43.87782064706409
At time: 524.9577209949493 and batch: 450, loss is 3.8199097108840943 and perplexity is 45.600090943077866
At time: 526.3096075057983 and batch: 500, loss is 3.821767029762268 and perplexity is 45.68486355334806
At time: 527.6613800525665 and batch: 550, loss is 3.8046292591094972 and perplexity is 44.90859757285999
At time: 529.0135793685913 and batch: 600, loss is 3.7687378454208376 and perplexity is 43.325347026805254
At time: 530.3662483692169 and batch: 650, loss is 3.796345648765564 and perplexity is 44.53812877745286
At time: 531.7178471088409 and batch: 700, loss is 3.838621668815613 and perplexity is 46.46139110167755
At time: 533.0680179595947 and batch: 750, loss is 3.775777430534363 and perplexity is 43.63141552845375
At time: 534.4208054542542 and batch: 800, loss is 3.755296721458435 and perplexity is 42.746901852003546
At time: 535.769594669342 and batch: 850, loss is 3.758350510597229 and perplexity is 42.877641400500536
At time: 537.1222214698792 and batch: 900, loss is 3.7149036026000974 and perplexity is 41.05462933411562
At time: 538.4780466556549 and batch: 950, loss is 3.8205391788482665 and perplexity is 45.62880377544587
At time: 539.8330595493317 and batch: 1000, loss is 3.7700307846069334 and perplexity is 43.38140029465202
At time: 541.1836950778961 and batch: 1050, loss is 3.731571817398071 and perplexity is 41.74467162477327
At time: 542.533444404602 and batch: 1100, loss is 3.74669828414917 and perplexity is 42.380920982883175
At time: 543.8823473453522 and batch: 1150, loss is 3.716645402908325 and perplexity is 41.12620061348737
At time: 545.2303690910339 and batch: 1200, loss is 3.750472807884216 and perplexity is 42.54119105636339
At time: 546.5784130096436 and batch: 1250, loss is 3.741741614341736 and perplexity is 42.17137251175155
At time: 547.9329459667206 and batch: 1300, loss is 3.7250950574874877 and perplexity is 41.47517508338993
At time: 549.2918696403503 and batch: 1350, loss is 3.590369267463684 and perplexity is 36.24745846250827
At time: 550.6419186592102 and batch: 1400, loss is 3.625354347229004 and perplexity is 37.5380222973889
At time: 551.9934558868408 and batch: 1450, loss is 3.5480302953720093 and perplexity is 34.74481302395879
At time: 553.3447823524475 and batch: 1500, loss is 3.5440517377853396 and perplexity is 34.60685340662526
At time: 554.7015302181244 and batch: 1550, loss is 3.5550960206985476 and perplexity is 34.991179683906104
At time: 556.0569334030151 and batch: 1600, loss is 3.62198028087616 and perplexity is 37.411579951789925
At time: 557.4171266555786 and batch: 1650, loss is 3.5836047649383547 and perplexity is 36.00308988595593
At time: 558.7769289016724 and batch: 1700, loss is 3.574977788925171 and perplexity is 35.69382800856653
At time: 560.1323795318604 and batch: 1750, loss is 3.560886068344116 and perplexity is 35.19436794866656
At time: 561.4839351177216 and batch: 1800, loss is 3.5111275625228884 and perplexity is 33.48600406816539
At time: 562.8374137878418 and batch: 1850, loss is 3.534640407562256 and perplexity is 34.282684703307496
At time: 564.192848443985 and batch: 1900, loss is 3.620975522994995 and perplexity is 37.374009249876714
At time: 565.5459725856781 and batch: 1950, loss is 3.567803978919983 and perplexity is 35.43868354126044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348480082667151 and perplexity of 77.36079151459977
finished 10 epochs...
Completing Train Step...
At time: 569.817305803299 and batch: 50, loss is 3.8266788578033446 and perplexity is 45.909811748369
At time: 571.1918108463287 and batch: 100, loss is 3.7942285203933714 and perplexity is 44.44393558609568
At time: 572.5460684299469 and batch: 150, loss is 3.749305567741394 and perplexity is 42.49156423927997
At time: 573.8977723121643 and batch: 200, loss is 3.752854461669922 and perplexity is 42.64263019359459
At time: 575.2506940364838 and batch: 250, loss is 3.7545209741592407 and perplexity is 42.71375391721569
At time: 576.6030263900757 and batch: 300, loss is 3.7594789409637452 and perplexity is 42.92605314260429
At time: 577.9564244747162 and batch: 350, loss is 3.781374006271362 and perplexity is 43.87628663065875
At time: 579.3134837150574 and batch: 400, loss is 3.723123412132263 and perplexity is 41.39348130911953
At time: 580.6674783229828 and batch: 450, loss is 3.7650958585739134 and perplexity is 43.16784366946766
At time: 582.019199848175 and batch: 500, loss is 3.767071986198425 and perplexity is 43.25323318033139
At time: 583.3868653774261 and batch: 550, loss is 3.7487032556533815 and perplexity is 42.46597876249455
At time: 584.7391285896301 and batch: 600, loss is 3.7177090072631835 and perplexity is 41.169965889902144
At time: 586.0934855937958 and batch: 650, loss is 3.7452638387680053 and perplexity is 42.32017144789141
At time: 587.4491775035858 and batch: 700, loss is 3.7896428155899047 and perplexity is 44.240595402553076
At time: 588.8025255203247 and batch: 750, loss is 3.7323745775222776 and perplexity is 41.77819603678197
At time: 590.1557331085205 and batch: 800, loss is 3.7107188510894775 and perplexity is 40.88318488838995
At time: 591.5081148147583 and batch: 850, loss is 3.7152559852600096 and perplexity is 41.06909882285081
At time: 592.8618695735931 and batch: 900, loss is 3.6733893728256226 and perplexity is 39.38517091828701
At time: 594.217396736145 and batch: 950, loss is 3.777982778549194 and perplexity is 43.72774416411474
At time: 595.5733196735382 and batch: 1000, loss is 3.7314658975601196 and perplexity is 41.74025027007815
At time: 596.927332162857 and batch: 1050, loss is 3.6956332397460936 and perplexity is 40.27106575493005
At time: 598.2789740562439 and batch: 1100, loss is 3.711869339942932 and perplexity is 40.93024760427167
At time: 599.6304597854614 and batch: 1150, loss is 3.684216456413269 and perplexity is 39.81391428777759
At time: 600.9848744869232 and batch: 1200, loss is 3.7203063106536867 and perplexity is 41.27703576818285
At time: 602.3418710231781 and batch: 1250, loss is 3.71528480052948 and perplexity is 41.070282257050714
At time: 603.6953563690186 and batch: 1300, loss is 3.7012657356262206 and perplexity is 40.49853236789849
At time: 605.0469937324524 and batch: 1350, loss is 3.567293186187744 and perplexity is 35.42058634161995
At time: 606.3993248939514 and batch: 1400, loss is 3.6045046043395996 and perplexity is 36.76346688335654
At time: 607.7503769397736 and batch: 1450, loss is 3.529816722869873 and perplexity is 34.11771404498705
At time: 609.1073944568634 and batch: 1500, loss is 3.5280078744888304 and perplexity is 34.05605605496135
At time: 610.4650676250458 and batch: 1550, loss is 3.5426072168350218 and perplexity is 34.55689917051151
At time: 611.8166105747223 and batch: 1600, loss is 3.613568892478943 and perplexity is 37.098216381188024
At time: 613.1669147014618 and batch: 1650, loss is 3.5761728525161742 and perplexity is 35.73650990155147
At time: 614.5172929763794 and batch: 1700, loss is 3.571705780029297 and perplexity is 35.577228347385734
At time: 615.8706023693085 and batch: 1750, loss is 3.560228400230408 and perplexity is 35.17122934467963
At time: 617.2287182807922 and batch: 1800, loss is 3.5123606014251707 and perplexity is 33.52731908013737
At time: 618.5853250026703 and batch: 1850, loss is 3.537469186782837 and perplexity is 34.37980014373214
At time: 619.9363071918488 and batch: 1900, loss is 3.62497136592865 and perplexity is 37.52364868938396
At time: 621.2887132167816 and batch: 1950, loss is 3.572301774024963 and perplexity is 35.59843848179177
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348729049327762 and perplexity of 77.38005417030543
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 625.5940055847168 and batch: 50, loss is 3.8220818185806276 and perplexity is 45.69924690130271
At time: 626.9448661804199 and batch: 100, loss is 3.811649284362793 and perplexity is 45.22496622062047
At time: 628.2947595119476 and batch: 150, loss is 3.77609534740448 and perplexity is 43.64528889668939
At time: 629.6473186016083 and batch: 200, loss is 3.7884305810928343 and perplexity is 44.186997919557605
At time: 630.9979975223541 and batch: 250, loss is 3.7966513299942015 and perplexity is 44.55174532843476
At time: 632.3532907962799 and batch: 300, loss is 3.7980053424835205 and perplexity is 44.61210980593621
At time: 633.7093136310577 and batch: 350, loss is 3.833779926300049 and perplexity is 46.23698071609503
At time: 635.0611650943756 and batch: 400, loss is 3.775478959083557 and perplexity is 43.618394739823756
At time: 636.4144556522369 and batch: 450, loss is 3.8284242296218873 and perplexity is 45.990011408743236
At time: 637.7675046920776 and batch: 500, loss is 3.824516386985779 and perplexity is 45.810640386457344
At time: 639.1202571392059 and batch: 550, loss is 3.8064893102645874 and perplexity is 44.99220759700377
At time: 640.4771001338959 and batch: 600, loss is 3.770729870796204 and perplexity is 43.411738235651434
At time: 641.8319132328033 and batch: 650, loss is 3.790251030921936 and perplexity is 44.26751139550517
At time: 643.1856672763824 and batch: 700, loss is 3.831700391769409 and perplexity is 46.140929223914995
At time: 644.5365617275238 and batch: 750, loss is 3.772053389549255 and perplexity is 43.46923252430075
At time: 645.8951659202576 and batch: 800, loss is 3.744699196815491 and perplexity is 42.2962824486546
At time: 647.2571563720703 and batch: 850, loss is 3.7473398733139036 and perplexity is 42.40812084721331
At time: 648.6197047233582 and batch: 900, loss is 3.700007510185242 and perplexity is 40.44760812795634
At time: 649.9908127784729 and batch: 950, loss is 3.806200833320618 and perplexity is 44.97923025437581
At time: 651.3415143489838 and batch: 1000, loss is 3.754791283607483 and perplexity is 42.72530140909717
At time: 652.6929240226746 and batch: 1050, loss is 3.721824493408203 and perplexity is 41.33974944540966
At time: 654.0435922145844 and batch: 1100, loss is 3.73244010925293 and perplexity is 41.78093392398005
At time: 655.3993396759033 and batch: 1150, loss is 3.711305456161499 and perplexity is 40.90717420744608
At time: 656.7552120685577 and batch: 1200, loss is 3.744271283149719 and perplexity is 42.27818716326956
At time: 658.1085486412048 and batch: 1250, loss is 3.730588574409485 and perplexity is 41.703646641156254
At time: 659.4584031105042 and batch: 1300, loss is 3.7149191665649415 and perplexity is 41.05526831189576
At time: 660.8105733394623 and batch: 1350, loss is 3.572932162284851 and perplexity is 35.62088639418787
At time: 662.1613230705261 and batch: 1400, loss is 3.6098942804336547 and perplexity is 36.962144986320034
At time: 663.509418964386 and batch: 1450, loss is 3.526381335258484 and perplexity is 34.000707569201424
At time: 664.8590965270996 and batch: 1500, loss is 3.5289314126968385 and perplexity is 34.08752265200795
At time: 666.2098386287689 and batch: 1550, loss is 3.549570960998535 and perplexity is 34.79838442029267
At time: 667.5671286582947 and batch: 1600, loss is 3.6170146560668943 and perplexity is 37.22626855643367
At time: 668.923344373703 and batch: 1650, loss is 3.5692149209976196 and perplexity is 35.488720762554344
At time: 670.2746205329895 and batch: 1700, loss is 3.557857046127319 and perplexity is 35.08792471708505
At time: 671.6265735626221 and batch: 1750, loss is 3.541278028488159 and perplexity is 34.5109970558664
At time: 672.9778463840485 and batch: 1800, loss is 3.4961595916748047 and perplexity is 32.9885189945121
At time: 674.3294730186462 and batch: 1850, loss is 3.5201003122329713 and perplexity is 33.78781762529275
At time: 675.6858484745026 and batch: 1900, loss is 3.6101288414001464 and perplexity is 36.97081587965844
At time: 677.0418660640717 and batch: 1950, loss is 3.567217082977295 and perplexity is 35.41789082385345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330170955214389 and perplexity of 75.95727075080455
finished 12 epochs...
Completing Train Step...
At time: 681.3159401416779 and batch: 50, loss is 3.828961811065674 and perplexity is 46.014741432081365
At time: 682.6698565483093 and batch: 100, loss is 3.8058490991592406 and perplexity is 44.96341230456263
At time: 684.0426857471466 and batch: 150, loss is 3.760062608718872 and perplexity is 42.95111500886862
At time: 685.3947329521179 and batch: 200, loss is 3.7641749382019043 and perplexity is 43.12810782240058
At time: 686.7464847564697 and batch: 250, loss is 3.770155153274536 and perplexity is 43.38679591712164
At time: 688.0961368083954 and batch: 300, loss is 3.7669050025939943 and perplexity is 43.246011202544366
At time: 689.4486174583435 and batch: 350, loss is 3.8023087644577025 and perplexity is 44.804508228463504
At time: 690.8020930290222 and batch: 400, loss is 3.7436198711395265 and perplexity is 42.250655612547185
At time: 692.1573805809021 and batch: 450, loss is 3.794396119117737 and perplexity is 44.4513849572408
At time: 693.5080935955048 and batch: 500, loss is 3.7908062601089476 and perplexity is 44.292096834513366
At time: 694.8594636917114 and batch: 550, loss is 3.7737015008926393 and perplexity is 43.540933729066715
At time: 696.2109186649323 and batch: 600, loss is 3.740182466506958 and perplexity is 42.105672339060675
At time: 697.5657076835632 and batch: 650, loss is 3.760660057067871 and perplexity is 42.976783748727925
At time: 698.921804189682 and batch: 700, loss is 3.8047093296051027 and perplexity is 44.91219357048933
At time: 700.2749516963959 and batch: 750, loss is 3.7483611345291137 and perplexity is 42.45145273906861
At time: 701.6264975070953 and batch: 800, loss is 3.7223859786987306 and perplexity is 41.36296762436034
At time: 702.9775474071503 and batch: 850, loss is 3.7244519424438476 and perplexity is 41.44851034952097
At time: 704.328485250473 and batch: 900, loss is 3.6783036899566652 and perplexity is 39.57919850449654
At time: 705.6827805042267 and batch: 950, loss is 3.7851448965072634 and perplexity is 44.04205163589562
At time: 707.0392808914185 and batch: 1000, loss is 3.734484577178955 and perplexity is 41.86644108184394
At time: 708.3914778232574 and batch: 1050, loss is 3.702422947883606 and perplexity is 40.54542489303021
At time: 709.7425243854523 and batch: 1100, loss is 3.7154344940185546 and perplexity is 41.07643067107634
At time: 711.0940251350403 and batch: 1150, loss is 3.6960470867156983 and perplexity is 40.28773526253016
At time: 712.4455232620239 and batch: 1200, loss is 3.730151662826538 and perplexity is 41.685429814748616
At time: 713.7987830638885 and batch: 1250, loss is 3.7178539514541624 and perplexity is 41.175933669787746
At time: 715.1519269943237 and batch: 1300, loss is 3.70436505317688 and perplexity is 40.6242448909263
At time: 716.5026648044586 and batch: 1350, loss is 3.5644109582901002 and perplexity is 35.31864312188338
At time: 717.8556249141693 and batch: 1400, loss is 3.6035534811019896 and perplexity is 36.72851691920496
At time: 719.2056949138641 and batch: 1450, loss is 3.523464641571045 and perplexity is 33.90168240330543
At time: 720.5591161251068 and batch: 1500, loss is 3.5284265422821046 and perplexity is 34.07031721393317
At time: 721.9128036499023 and batch: 1550, loss is 3.5504977607727053 and perplexity is 34.83065050490525
At time: 723.2656214237213 and batch: 1600, loss is 3.6196275901794435 and perplexity is 37.32366553395601
At time: 724.6156578063965 and batch: 1650, loss is 3.571936163902283 and perplexity is 35.58542571127648
At time: 725.9670534133911 and batch: 1700, loss is 3.5629510498046875 and perplexity is 35.26711875467822
At time: 727.3196313381195 and batch: 1750, loss is 3.54860876083374 and perplexity is 34.764917512582976
At time: 728.6749167442322 and batch: 1800, loss is 3.5048654508590698 and perplexity is 33.27696616396582
At time: 730.0321009159088 and batch: 1850, loss is 3.5290227842330935 and perplexity is 34.090637423618354
At time: 731.3850002288818 and batch: 1900, loss is 3.619155993461609 and perplexity is 37.30606796559653
At time: 732.7362914085388 and batch: 1950, loss is 3.5749342393875123 and perplexity is 35.692273592706776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328300156704215 and perplexity of 75.81530283993112
finished 13 epochs...
Completing Train Step...
At time: 737.0426526069641 and batch: 50, loss is 3.823941082954407 and perplexity is 45.78429291999181
At time: 738.3958051204681 and batch: 100, loss is 3.79853657245636 and perplexity is 44.63581539181811
At time: 739.7458736896515 and batch: 150, loss is 3.751206736564636 and perplexity is 42.57242471681648
At time: 741.0971417427063 and batch: 200, loss is 3.753713641166687 and perplexity is 42.679283610822594
At time: 742.447591304779 and batch: 250, loss is 3.75851900100708 and perplexity is 42.884866480534804
At time: 743.8044261932373 and batch: 300, loss is 3.7540391063690186 and perplexity is 42.693176493200596
At time: 745.1624479293823 and batch: 350, loss is 3.789229712486267 and perplexity is 44.22232324968689
At time: 746.5161454677582 and batch: 400, loss is 3.7298672151565553 and perplexity is 41.67357417759971
At time: 747.8690721988678 and batch: 450, loss is 3.7802022600173952 and perplexity is 43.82490486523576
At time: 749.2206284999847 and batch: 500, loss is 3.776607160568237 and perplexity is 43.667632847559034
At time: 750.6019542217255 and batch: 550, loss is 3.759566044807434 and perplexity is 42.92979232967382
At time: 751.9596898555756 and batch: 600, loss is 3.727326807975769 and perplexity is 41.56784069042901
At time: 753.3153851032257 and batch: 650, loss is 3.7480376815795897 and perplexity is 42.4377239119031
At time: 754.6684880256653 and batch: 700, loss is 3.7927585458755493 and perplexity is 44.37865212757813
At time: 756.0207390785217 and batch: 750, loss is 3.737644853591919 and perplexity is 41.998959895838105
At time: 757.3729827404022 and batch: 800, loss is 3.7118407011032106 and perplexity is 40.92907542625576
At time: 758.7284610271454 and batch: 850, loss is 3.7138900804519652 and perplexity is 41.01304063709499
At time: 760.0854532718658 and batch: 900, loss is 3.6680784749984743 and perplexity is 39.17655475953305
At time: 761.4383635520935 and batch: 950, loss is 3.775200366973877 and perplexity is 43.60624469174468
At time: 762.7960188388824 and batch: 1000, loss is 3.725060820579529 and perplexity is 41.47375512594563
At time: 764.1543824672699 and batch: 1050, loss is 3.693550696372986 and perplexity is 40.18728678076689
At time: 765.5096163749695 and batch: 1100, loss is 3.7072153377532957 and perplexity is 40.74020072462635
At time: 766.8661158084869 and batch: 1150, loss is 3.6885796213150024 and perplexity is 39.9880084858571
At time: 768.2209224700928 and batch: 1200, loss is 3.7232285070419313 and perplexity is 41.39783178190083
At time: 769.5721566677094 and batch: 1250, loss is 3.7118279361724853 and perplexity is 40.92855297277784
At time: 770.9234328269958 and batch: 1300, loss is 3.6993441009521484 and perplexity is 40.42078371003478
At time: 772.2754888534546 and batch: 1350, loss is 3.5597097492218017 and perplexity is 35.15299248079882
At time: 773.6274838447571 and batch: 1400, loss is 3.5994931745529173 and perplexity is 36.57969022688108
At time: 774.9828701019287 and batch: 1450, loss is 3.5206382369995115 and perplexity is 33.80599781855046
At time: 776.3383417129517 and batch: 1500, loss is 3.5265177869796753 and perplexity is 34.00534734081618
At time: 777.6906242370605 and batch: 1550, loss is 3.549214730262756 and perplexity is 34.78599037390791
At time: 779.0421450138092 and batch: 1600, loss is 3.6193779420852663 and perplexity is 37.314348914974225
At time: 780.3943243026733 and batch: 1650, loss is 3.5714986181259154 and perplexity is 35.56985886440867
At time: 781.747932434082 and batch: 1700, loss is 3.563368330001831 and perplexity is 35.28183809577605
At time: 783.1040272712708 and batch: 1750, loss is 3.549814963340759 and perplexity is 34.80687634357929
At time: 784.4567847251892 and batch: 1800, loss is 3.50648166179657 and perplexity is 33.3307922460814
At time: 785.8076407909393 and batch: 1850, loss is 3.5308519124984743 and perplexity is 34.153050635598454
At time: 787.1584708690643 and batch: 1900, loss is 3.6209338331222534 and perplexity is 37.372451164665655
At time: 788.5088675022125 and batch: 1950, loss is 3.576135458946228 and perplexity is 35.73517361085333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.32807134583939 and perplexity of 75.79795745940272
finished 14 epochs...
Completing Train Step...
At time: 792.7954456806183 and batch: 50, loss is 3.8178985643386842 and perplexity is 45.50847463549767
At time: 794.1639337539673 and batch: 100, loss is 3.7914257574081422 and perplexity is 44.31954416977525
At time: 795.5167977809906 and batch: 150, loss is 3.7434915685653687 and perplexity is 42.24523509241302
At time: 796.8698761463165 and batch: 200, loss is 3.7454620885848997 and perplexity is 42.32856224584149
At time: 798.2269766330719 and batch: 250, loss is 3.7497858667373656 and perplexity is 42.51197779683452
At time: 799.5813810825348 and batch: 300, loss is 3.7446882009506224 and perplexity is 42.295817367005355
At time: 800.9330761432648 and batch: 350, loss is 3.779627003669739 and perplexity is 43.79970156040216
At time: 802.284318447113 and batch: 400, loss is 3.7196643590927123 and perplexity is 41.250546413989895
At time: 803.6350231170654 and batch: 450, loss is 3.7702837705612184 and perplexity is 43.39237656796673
At time: 804.9870276451111 and batch: 500, loss is 3.7667219257354736 and perplexity is 43.23809458336685
At time: 806.3421323299408 and batch: 550, loss is 3.7498455476760864 and perplexity is 42.51451502728771
At time: 807.6955916881561 and batch: 600, loss is 3.7184206151962282 and perplexity is 41.1992731906497
At time: 809.0456483364105 and batch: 650, loss is 3.739203381538391 and perplexity is 42.0644674830013
At time: 810.3959310054779 and batch: 700, loss is 3.7843623542785645 and perplexity is 44.00760035220224
At time: 811.7476875782013 and batch: 750, loss is 3.72984402179718 and perplexity is 41.67260763862604
At time: 813.1016273498535 and batch: 800, loss is 3.70413206577301 and perplexity is 40.61478105609496
At time: 814.4584813117981 and batch: 850, loss is 3.7062602472305297 and perplexity is 40.701308720667306
At time: 815.8107235431671 and batch: 900, loss is 3.6607049894332886 and perplexity is 38.88874936692995
At time: 817.1630966663361 and batch: 950, loss is 3.767882213592529 and perplexity is 43.2882923357638
At time: 818.5310776233673 and batch: 1000, loss is 3.7181015396118164 and perplexity is 41.18612960548912
At time: 819.8839826583862 and batch: 1050, loss is 3.6870393180847167 and perplexity is 39.9264622393232
At time: 821.2406628131866 and batch: 1100, loss is 3.7009552764892577 and perplexity is 40.48596118001233
At time: 822.5957765579224 and batch: 1150, loss is 3.682778387069702 and perplexity is 39.75670026691773
At time: 823.9471251964569 and batch: 1200, loss is 3.717834391593933 and perplexity is 41.17512828215702
At time: 825.2998025417328 and batch: 1250, loss is 3.7070260667800903 and perplexity is 40.73249051686889
At time: 826.6520326137543 and batch: 1300, loss is 3.695153932571411 and perplexity is 40.25176816928667
At time: 828.0055491924286 and batch: 1350, loss is 3.5555892896652224 and perplexity is 35.008444004578266
At time: 829.3606464862823 and batch: 1400, loss is 3.5957089710235595 and perplexity is 36.44152681812843
At time: 830.714174747467 and batch: 1450, loss is 3.517492480278015 and perplexity is 33.69981946687742
At time: 832.0656275749207 and batch: 1500, loss is 3.5238145542144776 and perplexity is 33.913547106295724
At time: 833.4159932136536 and batch: 1550, loss is 3.5468916749954222 and perplexity is 34.705274385890164
At time: 834.7683987617493 and batch: 1600, loss is 3.6177905225753784 and perplexity is 37.25516237886758
At time: 836.1252174377441 and batch: 1650, loss is 3.569715962409973 and perplexity is 35.50650653666043
At time: 837.48042345047 and batch: 1700, loss is 3.5620722818374633 and perplexity is 35.236140753651334
At time: 838.8335869312286 and batch: 1750, loss is 3.548959856033325 and perplexity is 34.777125451184524
At time: 840.1847474575043 and batch: 1800, loss is 3.5058920431137084 and perplexity is 33.31114558084815
At time: 841.5358102321625 and batch: 1850, loss is 3.5305147886276247 and perplexity is 34.14153876753865
At time: 842.8889892101288 and batch: 1900, loss is 3.6206245851516723 and perplexity is 37.360895596847385
At time: 844.2436854839325 and batch: 1950, loss is 3.575523533821106 and perplexity is 35.713313049465775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328398096838662 and perplexity of 75.8227285645167
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 848.5054669380188 and batch: 50, loss is 3.8175154066085817 and perplexity is 45.491041051775376
At time: 849.8753864765167 and batch: 100, loss is 3.7999508666992186 and perplexity is 44.69898823051309
At time: 851.2301001548767 and batch: 150, loss is 3.7569259786605835 and perplexity is 42.81660431591748
At time: 852.6040728092194 and batch: 200, loss is 3.7629923152923586 and perplexity is 43.07713368157884
At time: 853.9546432495117 and batch: 250, loss is 3.7708670806884768 and perplexity is 43.41769516424355
At time: 855.3070821762085 and batch: 300, loss is 3.763495292663574 and perplexity is 43.09880595491214
At time: 856.6589615345001 and batch: 350, loss is 3.8052411317825316 and perplexity is 44.93608432483777
At time: 858.0098781585693 and batch: 400, loss is 3.7495874691009523 and perplexity is 42.503544357535255
At time: 859.3655593395233 and batch: 450, loss is 3.8033001899719237 and perplexity is 44.84895058807766
At time: 860.7204744815826 and batch: 500, loss is 3.8004080152511595 and perplexity is 44.719426979672235
At time: 862.0707716941833 and batch: 550, loss is 3.7863067150115968 and perplexity is 44.09325024244016
At time: 863.4216356277466 and batch: 600, loss is 3.7493485403060913 and perplexity is 42.49339025000723
At time: 864.7721631526947 and batch: 650, loss is 3.763732018470764 and perplexity is 43.10900976224535
At time: 866.1261446475983 and batch: 700, loss is 3.8084674978256228 and perplexity is 45.08129871283144
At time: 867.4799609184265 and batch: 750, loss is 3.7516786813735963 and perplexity is 42.592521293530936
At time: 868.8326594829559 and batch: 800, loss is 3.726547288894653 and perplexity is 41.53545039151822
At time: 870.1833386421204 and batch: 850, loss is 3.7276183795928954 and perplexity is 41.579962460055675
At time: 871.5342824459076 and batch: 900, loss is 3.6775388526916504 and perplexity is 39.54893843205152
At time: 872.8849020004272 and batch: 950, loss is 3.780772066116333 and perplexity is 43.849883679177765
At time: 874.2385013103485 and batch: 1000, loss is 3.7264433526992797 and perplexity is 41.53113357917181
At time: 875.5952248573303 and batch: 1050, loss is 3.696779365539551 and perplexity is 40.317247922353005
At time: 876.9480526447296 and batch: 1100, loss is 3.704239807128906 and perplexity is 40.61915718341608
At time: 878.2995047569275 and batch: 1150, loss is 3.6882432556152343 and perplexity is 39.974560153306115
At time: 879.6492161750793 and batch: 1200, loss is 3.7220102548599243 and perplexity is 41.34742949058652
At time: 881.0014095306396 and batch: 1250, loss is 3.7125233125686647 and perplexity is 40.957023620205746
At time: 882.3562853336334 and batch: 1300, loss is 3.6993727779388426 and perplexity is 40.42194287293197
At time: 883.7125599384308 and batch: 1350, loss is 3.5514688014984133 and perplexity is 34.86448891162502
At time: 885.064651966095 and batch: 1400, loss is 3.588382158279419 and perplexity is 36.17550232092325
At time: 886.4149854183197 and batch: 1450, loss is 3.50491464138031 and perplexity is 33.278603115537635
At time: 887.7655599117279 and batch: 1500, loss is 3.5107459878921508 and perplexity is 33.47322909598585
At time: 889.1207511425018 and batch: 1550, loss is 3.538055715560913 and perplexity is 34.399970800658075
At time: 890.4746346473694 and batch: 1600, loss is 3.6114309072494506 and perplexity is 37.01898566975009
At time: 891.8299074172974 and batch: 1650, loss is 3.5636507987976076 and perplexity is 35.29180552177289
At time: 893.1794626712799 and batch: 1700, loss is 3.555548071861267 and perplexity is 35.00700106313415
At time: 894.5297060012817 and batch: 1750, loss is 3.5402416801452636 and perplexity is 34.475250167569506
At time: 895.8790516853333 and batch: 1800, loss is 3.4909289026260377 and perplexity is 32.81641680837696
At time: 897.2316472530365 and batch: 1850, loss is 3.519315185546875 and perplexity is 33.76130031909471
At time: 898.5856313705444 and batch: 1900, loss is 3.612430830001831 and perplexity is 37.056020308594576
At time: 899.9380722045898 and batch: 1950, loss is 3.5700938749313353 and perplexity is 35.519927425871785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.322006438499273 and perplexity of 75.33964109882827
finished 16 epochs...
Completing Train Step...
At time: 904.2032017707825 and batch: 50, loss is 3.8195017623901366 and perplexity is 45.581492248565944
At time: 905.5766093730927 and batch: 100, loss is 3.795669131278992 and perplexity is 44.50800814423204
At time: 906.9290466308594 and batch: 150, loss is 3.7488761806488036 and perplexity is 42.47332282664548
At time: 908.2778780460358 and batch: 200, loss is 3.751898317337036 and perplexity is 42.601877170386466
At time: 909.6284182071686 and batch: 250, loss is 3.7588157987594606 and perplexity is 42.89759650154473
At time: 910.9795191287994 and batch: 300, loss is 3.7500362539291383 and perplexity is 42.52262358430057
At time: 912.3321511745453 and batch: 350, loss is 3.7885015201568604 and perplexity is 44.190132615017006
At time: 913.6887257099152 and batch: 400, loss is 3.7321053075790407 and perplexity is 41.76694793876192
At time: 915.0416724681854 and batch: 450, loss is 3.785736322402954 and perplexity is 44.06810694986665
At time: 916.3933942317963 and batch: 500, loss is 3.7849193143844606 and perplexity is 44.032117656901164
At time: 917.7436826229095 and batch: 550, loss is 3.771202664375305 and perplexity is 43.432267879506355
At time: 919.094254732132 and batch: 600, loss is 3.7353137922286987 and perplexity is 41.90117176247969
At time: 920.4697229862213 and batch: 650, loss is 3.7504601812362672 and perplexity is 42.540653907111796
At time: 921.8265016078949 and batch: 700, loss is 3.796418776512146 and perplexity is 44.5413858695378
At time: 923.1828680038452 and batch: 750, loss is 3.7412278032302857 and perplexity is 42.149709957676976
At time: 924.5379865169525 and batch: 800, loss is 3.716467514038086 and perplexity is 41.11888537079243
At time: 925.8888683319092 and batch: 850, loss is 3.717911162376404 and perplexity is 41.17828945031469
At time: 927.2435235977173 and batch: 900, loss is 3.6693557786941526 and perplexity is 39.22662708968976
At time: 928.5995628833771 and batch: 950, loss is 3.7738380289077758 and perplexity is 43.5468786921437
At time: 929.9533824920654 and batch: 1000, loss is 3.7202644109725953 and perplexity is 41.27530630977989
At time: 931.303683757782 and batch: 1050, loss is 3.6901869201660156 and perplexity is 40.05233284633806
At time: 932.656660079956 and batch: 1100, loss is 3.698543834686279 and perplexity is 40.38844926020201
At time: 934.0078032016754 and batch: 1150, loss is 3.6826869440078736 and perplexity is 39.75306495873152
At time: 935.3623735904694 and batch: 1200, loss is 3.7175653982162475 and perplexity is 41.164053934853584
At time: 936.7160727977753 and batch: 1250, loss is 3.7076398134231567 and perplexity is 40.757497619415
At time: 938.0666444301605 and batch: 1300, loss is 3.694881281852722 and perplexity is 40.240794991757156
At time: 939.4258592128754 and batch: 1350, loss is 3.5490556573867797 and perplexity is 34.78045730646759
At time: 940.7813909053802 and batch: 1400, loss is 3.587857193946838 and perplexity is 36.15651645637845
At time: 942.1326403617859 and batch: 1450, loss is 3.506126365661621 and perplexity is 33.31895204793445
At time: 943.4842369556427 and batch: 1500, loss is 3.5137774467468263 and perplexity is 33.57485577344218
At time: 944.8355665206909 and batch: 1550, loss is 3.542164530754089 and perplexity is 34.541604697823395
At time: 946.1852736473083 and batch: 1600, loss is 3.615964775085449 and perplexity is 37.18720591421675
At time: 947.5361368656158 and batch: 1650, loss is 3.5682036018371583 and perplexity is 35.45284848148691
At time: 948.8904225826263 and batch: 1700, loss is 3.5604279804229737 and perplexity is 35.178249525926276
At time: 950.2431073188782 and batch: 1750, loss is 3.5457437372207643 and perplexity is 34.66545774832629
At time: 951.5934584140778 and batch: 1800, loss is 3.4964835119247435 and perplexity is 32.99920637466589
At time: 952.947065114975 and batch: 1850, loss is 3.5248692989349366 and perplexity is 33.94933611187257
At time: 954.3035087585449 and batch: 1900, loss is 3.6183259534835814 and perplexity is 37.27511528552013
At time: 955.6591439247131 and batch: 1950, loss is 3.5749002933502196 and perplexity is 35.69106200202081
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320731797329215 and perplexity of 75.24367126708921
finished 17 epochs...
Completing Train Step...
At time: 959.9618260860443 and batch: 50, loss is 3.819132881164551 and perplexity is 45.56468119267335
At time: 961.3121619224548 and batch: 100, loss is 3.79367928981781 and perplexity is 44.41953231989694
At time: 962.6628708839417 and batch: 150, loss is 3.745981464385986 and perplexity is 42.35055238684599
At time: 964.0139834880829 and batch: 200, loss is 3.747769651412964 and perplexity is 42.426350845922244
At time: 965.3657121658325 and batch: 250, loss is 3.753982081413269 and perplexity is 42.69074198611476
At time: 966.7176477909088 and batch: 300, loss is 3.7445089626312256 and perplexity is 42.288237015148034
At time: 968.0684807300568 and batch: 350, loss is 3.7819837856292726 and perplexity is 43.903049643485005
At time: 969.4204359054565 and batch: 400, loss is 3.7251778745651247 and perplexity is 41.47861007842098
At time: 970.7718744277954 and batch: 450, loss is 3.7783636379241945 and perplexity is 43.74440145726904
At time: 972.1225256919861 and batch: 500, loss is 3.777842469215393 and perplexity is 43.72160918387
At time: 973.4740555286407 and batch: 550, loss is 3.7641484260559084 and perplexity is 43.12696441886658
At time: 974.8261051177979 and batch: 600, loss is 3.7289311265945435 and perplexity is 41.634582274258534
At time: 976.1778259277344 and batch: 650, loss is 3.7443547677993774 and perplexity is 42.281716890250024
At time: 977.5329396724701 and batch: 700, loss is 3.790776529312134 and perplexity is 44.290780014757075
At time: 978.8851706981659 and batch: 750, loss is 3.7360582685470582 and perplexity is 41.9323778072077
At time: 980.2366745471954 and batch: 800, loss is 3.7115780210494993 and perplexity is 40.918325586470495
At time: 981.5880253314972 and batch: 850, loss is 3.7131521844863893 and perplexity is 40.98278844273163
At time: 982.9393720626831 and batch: 900, loss is 3.664951944351196 and perplexity is 39.0542593402326
At time: 984.290111541748 and batch: 950, loss is 3.770034546852112 and perplexity is 43.381563506423134
At time: 985.639445066452 and batch: 1000, loss is 3.716949782371521 and perplexity is 41.138720489653316
At time: 987.0093469619751 and batch: 1050, loss is 3.6869357347488405 and perplexity is 39.92232673736296
At time: 988.3606369495392 and batch: 1100, loss is 3.695747675895691 and perplexity is 40.27567448433281
At time: 989.7118043899536 and batch: 1150, loss is 3.680134949684143 and perplexity is 39.651744701954854
At time: 991.0624389648438 and batch: 1200, loss is 3.715328993797302 and perplexity is 41.07209732714067
At time: 992.4129536151886 and batch: 1250, loss is 3.705556721687317 and perplexity is 40.672684380498
At time: 993.761378288269 and batch: 1300, loss is 3.693223724365234 and perplexity is 40.174148810913316
At time: 995.1122851371765 and batch: 1350, loss is 3.5480603647232054 and perplexity is 34.745857793651545
At time: 996.4636127948761 and batch: 1400, loss is 3.58759090423584 and perplexity is 36.14688962987989
At time: 997.8154671192169 and batch: 1450, loss is 3.5068245458602907 and perplexity is 33.342222803139705
At time: 999.1675555706024 and batch: 1500, loss is 3.515187954902649 and perplexity is 33.62224679619607
At time: 1000.5168826580048 and batch: 1550, loss is 3.5439443731307985 and perplexity is 34.603138053216895
At time: 1001.8675293922424 and batch: 1600, loss is 3.6180090045928956 and perplexity is 37.26330285114807
At time: 1003.218517780304 and batch: 1650, loss is 3.5702177047729493 and perplexity is 35.52432612519857
At time: 1004.5701494216919 and batch: 1700, loss is 3.5625264024734498 and perplexity is 35.25214584614643
At time: 1005.922521352768 and batch: 1750, loss is 3.548112645149231 and perplexity is 34.74767436938489
At time: 1007.2733211517334 and batch: 1800, loss is 3.499008660316467 and perplexity is 33.08263956382932
At time: 1008.6231038570404 and batch: 1850, loss is 3.5274055290222166 and perplexity is 34.03554872085581
At time: 1009.9735972881317 and batch: 1900, loss is 3.6208534908294676 and perplexity is 37.36944869686625
At time: 1011.3262448310852 and batch: 1950, loss is 3.5768038606643677 and perplexity is 35.75906704661004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320266510719477 and perplexity of 75.20866953793046
finished 18 epochs...
Completing Train Step...
At time: 1015.599940776825 and batch: 50, loss is 3.817897038459778 and perplexity is 45.50840519512914
At time: 1016.9511845111847 and batch: 100, loss is 3.79164927482605 and perplexity is 44.32945146703642
At time: 1018.3066585063934 and batch: 150, loss is 3.7435653257369994 and perplexity is 42.248351096380716
At time: 1019.6658685207367 and batch: 200, loss is 3.7447758102416993 and perplexity is 42.29952303590353
At time: 1021.0395603179932 and batch: 250, loss is 3.750551280975342 and perplexity is 42.544529526114054
At time: 1022.3981664180756 and batch: 300, loss is 3.7407813930511473 and perplexity is 42.13089809731952
At time: 1023.7549409866333 and batch: 350, loss is 3.777907385826111 and perplexity is 43.72444753468042
At time: 1025.1112747192383 and batch: 400, loss is 3.720854926109314 and perplexity is 41.29968720086264
At time: 1026.468983888626 and batch: 450, loss is 3.7738057231903075 and perplexity is 43.545471901707856
At time: 1027.8265755176544 and batch: 500, loss is 3.773365578651428 and perplexity is 43.52630981741013
At time: 1029.184201002121 and batch: 550, loss is 3.759632830619812 and perplexity is 42.93265952647273
At time: 1030.5428318977356 and batch: 600, loss is 3.7248363590240476 and perplexity is 41.46444690706614
At time: 1031.899535894394 and batch: 650, loss is 3.740410876274109 and perplexity is 42.115290784306985
At time: 1033.2604806423187 and batch: 700, loss is 3.7870956230163575 and perplexity is 44.128049485408155
At time: 1034.6171491146088 and batch: 750, loss is 3.7326419019699095 and perplexity is 41.78936586287784
At time: 1035.9747326374054 and batch: 800, loss is 3.7083279609680178 and perplexity is 40.78555444384671
At time: 1037.3341345787048 and batch: 850, loss is 3.7099652814865114 and perplexity is 40.8523881681791
At time: 1038.6864285469055 and batch: 900, loss is 3.661915683746338 and perplexity is 38.93586026732516
At time: 1040.0383973121643 and batch: 950, loss is 3.76732129573822 and perplexity is 43.264017968309616
At time: 1041.3888409137726 and batch: 1000, loss is 3.7145299434661867 and perplexity is 41.03929176256591
At time: 1042.73979139328 and batch: 1050, loss is 3.6846209955215454 and perplexity is 39.830023831411076
At time: 1044.0935175418854 and batch: 1100, loss is 3.693740630149841 and perplexity is 40.194920428847574
At time: 1045.4472873210907 and batch: 1150, loss is 3.6783411598205564 and perplexity is 39.580681559462185
At time: 1046.793972492218 and batch: 1200, loss is 3.7136791133880616 and perplexity is 41.00438914895163
At time: 1048.1428105831146 and batch: 1250, loss is 3.7041142892837526 and perplexity is 40.61405907429299
At time: 1049.494333267212 and batch: 1300, loss is 3.692076678276062 and perplexity is 40.12809362939149
At time: 1050.8434507846832 and batch: 1350, loss is 3.5472185134887697 and perplexity is 34.71661925935134
At time: 1052.1981227397919 and batch: 1400, loss is 3.5870724058151247 and perplexity is 36.128152382729326
At time: 1053.5496752262115 and batch: 1450, loss is 3.5069016361236574 and perplexity is 33.34479326295427
At time: 1054.9014086723328 and batch: 1500, loss is 3.515654287338257 and perplexity is 33.637929596850256
At time: 1056.251408815384 and batch: 1550, loss is 3.544603314399719 and perplexity is 34.625947002968154
At time: 1057.6026546955109 and batch: 1600, loss is 3.618849835395813 and perplexity is 37.29464816020769
At time: 1058.954402923584 and batch: 1650, loss is 3.5710129022598265 and perplexity is 35.55258621474326
At time: 1060.3056137561798 and batch: 1700, loss is 3.5634074783325196 and perplexity is 35.28321934787781
At time: 1061.6555378437042 and batch: 1750, loss is 3.54916533946991 and perplexity is 34.78427230869205
At time: 1063.0057637691498 and batch: 1800, loss is 3.5001923704147337 and perplexity is 33.12182300470044
At time: 1064.3572642803192 and batch: 1850, loss is 3.5286260652542114 and perplexity is 34.07711570308914
At time: 1065.7072677612305 and batch: 1900, loss is 3.6220032501220705 and perplexity is 37.412439277438736
At time: 1067.0584526062012 and batch: 1950, loss is 3.577541308403015 and perplexity is 35.78544721554215
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320079146984011 and perplexity of 75.19457948069056
finished 19 epochs...
Completing Train Step...
At time: 1071.3351974487305 and batch: 50, loss is 3.816377558708191 and perplexity is 45.43930860363826
At time: 1072.6848900318146 and batch: 100, loss is 3.7896270513534547 and perplexity is 44.23989798884357
At time: 1074.0334641933441 and batch: 150, loss is 3.7413329887390137 and perplexity is 42.1541437295418
At time: 1075.3840169906616 and batch: 200, loss is 3.7422520303726197 and perplexity is 42.192902950599056
At time: 1076.734771490097 and batch: 250, loss is 3.7477415943145753 and perplexity is 42.42516050232116
At time: 1078.0841929912567 and batch: 300, loss is 3.7377984809875486 and perplexity is 42.00541258230808
At time: 1079.4342212677002 and batch: 350, loss is 3.7747800159454346 and perplexity is 43.58791861390467
At time: 1080.7852203845978 and batch: 400, loss is 3.7175197076797484 and perplexity is 41.16217317011172
At time: 1082.1360955238342 and batch: 450, loss is 3.770404477119446 and perplexity is 43.39761462852332
At time: 1083.4882690906525 and batch: 500, loss is 3.769995994567871 and perplexity is 43.37989108029414
At time: 1084.8396439552307 and batch: 550, loss is 3.7562308263778688 and perplexity is 42.786850598569615
At time: 1086.1904385089874 and batch: 600, loss is 3.721731948852539 and perplexity is 41.33592385368754
At time: 1087.54501080513 and batch: 650, loss is 3.737394814491272 and perplexity is 41.9884598264463
At time: 1088.9126517772675 and batch: 700, loss is 3.78427143573761 and perplexity is 44.00359942726919
At time: 1090.2638561725616 and batch: 750, loss is 3.7300108766555784 and perplexity is 41.67956149579897
At time: 1091.614382982254 and batch: 800, loss is 3.7058010625839235 and perplexity is 40.682623594895745
At time: 1092.9680581092834 and batch: 850, loss is 3.7074750900268554 and perplexity is 40.75078445890486
At time: 1094.3213670253754 and batch: 900, loss is 3.6595054960250852 and perplexity is 38.84213053349229
At time: 1095.6717429161072 and batch: 950, loss is 3.7650989484786987 and perplexity is 43.167977054200456
At time: 1097.0253014564514 and batch: 1000, loss is 3.7125082349777223 and perplexity is 40.95640609161281
At time: 1098.37615609169 and batch: 1050, loss is 3.6827031803131103 and perplexity is 39.753710406868116
At time: 1099.7257778644562 and batch: 1100, loss is 3.6920422506332398 and perplexity is 40.12671213749777
At time: 1101.0758910179138 and batch: 1150, loss is 3.676815233230591 and perplexity is 39.520330402449645
At time: 1102.4266588687897 and batch: 1200, loss is 3.7122431993484497 and perplexity is 40.94555262309304
At time: 1103.7772414684296 and batch: 1250, loss is 3.7028723621368407 and perplexity is 40.56365068003806
At time: 1105.1270637512207 and batch: 1300, loss is 3.691053938865662 and perplexity is 40.087074026330335
At time: 1106.476422071457 and batch: 1350, loss is 3.546357970237732 and perplexity is 34.68675695769277
At time: 1107.825555562973 and batch: 1400, loss is 3.5863788080215455 and perplexity is 36.103102664169576
At time: 1109.1763854026794 and batch: 1450, loss is 3.5066102170944213 and perplexity is 33.335077371438096
At time: 1110.5268087387085 and batch: 1500, loss is 3.5156175184249876 and perplexity is 33.63669278947253
At time: 1111.8783688545227 and batch: 1550, loss is 3.544696316719055 and perplexity is 34.62916744610065
At time: 1113.2297880649567 and batch: 1600, loss is 3.6190860748291014 and perplexity is 37.303459667525516
At time: 1114.5820877552032 and batch: 1650, loss is 3.571204080581665 and perplexity is 35.55938374826264
At time: 1115.933776140213 and batch: 1700, loss is 3.563698410987854 and perplexity is 35.29348588193403
At time: 1117.2862493991852 and batch: 1750, loss is 3.5495786476135254 and perplexity is 34.79865190310401
At time: 1118.6356327533722 and batch: 1800, loss is 3.5007042121887206 and perplexity is 33.138780476745914
At time: 1119.987591266632 and batch: 1850, loss is 3.5291882371902465 and perplexity is 34.096278287027225
At time: 1121.339805841446 and batch: 1900, loss is 3.6224928379058836 and perplexity is 37.43076043521318
At time: 1122.6920261383057 and batch: 1950, loss is 3.5777356672286986 and perplexity is 35.79240310898726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320024073401163 and perplexity of 75.19043835982198
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa20428cb38>
ELAPSED
4667.7418076992035


RESULTS SO FAR:
[{'best_accuracy': -74.4178468006303, 'params': {'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}}, {'best_accuracy': -77.53052041197337, 'params': {'dropout': 0.9649993788704626, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.2039606990300309, 'data': 'wikitext'}}, {'best_accuracy': -74.84239854569978, 'params': {'dropout': 0.18248612094762118, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.031083902810406072, 'data': 'wikitext'}}, {'best_accuracy': -75.19043835982198, 'params': {'dropout': 0.6426102732804025, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.040188596927537734, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'dropout': 0.28425270504382827, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.42033359040349494, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.2088494300842285 and batch: 50, loss is 7.678365297317505 and perplexity is 2161.084152730225
At time: 3.842244863510132 and batch: 100, loss is 7.026775875091553 and perplexity is 1126.393117365337
At time: 5.44918417930603 and batch: 150, loss is 6.672195873260498 and perplexity is 790.1287234475797
At time: 7.060664415359497 and batch: 200, loss is 6.3586521911621094 and perplexity is 577.4675158261039
At time: 8.676050424575806 and batch: 250, loss is 6.227965936660767 and perplexity is 506.72372636692955
At time: 10.289344787597656 and batch: 300, loss is 6.12679913520813 and perplexity is 457.9679187246691
At time: 11.899195671081543 and batch: 350, loss is 6.033050212860108 and perplexity is 416.9849845429116
At time: 13.50411605834961 and batch: 400, loss is 5.948602113723755 and perplexity is 383.2172703038483
At time: 15.11920714378357 and batch: 450, loss is 5.829153518676758 and perplexity is 340.0706937110217
At time: 16.731262683868408 and batch: 500, loss is 5.7933538627624515 and perplexity is 328.11162242501746
At time: 18.341136693954468 and batch: 550, loss is 5.726246204376221 and perplexity is 306.8153817677194
At time: 19.950071811676025 and batch: 600, loss is 5.73794056892395 and perplexity is 310.4244544661169
At time: 21.56607413291931 and batch: 650, loss is 5.79114821434021 and perplexity is 327.3887210688838
At time: 23.1847403049469 and batch: 700, loss is 5.704600133895874 and perplexity is 300.2453980842353
At time: 24.79712224006653 and batch: 750, loss is 5.622154207229614 and perplexity is 276.48434674598633
At time: 26.41003942489624 and batch: 800, loss is 5.622231683731079 and perplexity is 276.5057686157171
At time: 28.0206458568573 and batch: 850, loss is 5.630239782333374 and perplexity is 278.72894389738747
At time: 29.634167909622192 and batch: 900, loss is 5.609878320693969 and perplexity is 273.11100402541484
At time: 31.24457859992981 and batch: 950, loss is 5.613352699279785 and perplexity is 274.06154536339676
At time: 32.851181507110596 and batch: 1000, loss is 5.571623783111573 and perplexity is 262.8605814621329
At time: 34.45847153663635 and batch: 1050, loss is 5.478577690124512 and perplexity is 239.50581351956956
At time: 36.06571102142334 and batch: 1100, loss is 5.549204969406128 and perplexity is 257.0331254539366
At time: 37.68077516555786 and batch: 1150, loss is 5.446665267944336 and perplexity is 231.98327253956546
At time: 39.30084252357483 and batch: 1200, loss is 5.5029794788360595 and perplexity is 245.42207387835938
At time: 40.91739082336426 and batch: 1250, loss is 5.46428219795227 and perplexity is 236.1063166710329
At time: 42.53547644615173 and batch: 1300, loss is 5.473445148468017 and perplexity is 238.27968921339308
At time: 44.15996026992798 and batch: 1350, loss is 5.409768552780151 and perplexity is 223.5798347605727
At time: 45.781126737594604 and batch: 1400, loss is 5.41029543876648 and perplexity is 223.69766688165444
At time: 47.398820877075195 and batch: 1450, loss is 5.386853494644165 and perplexity is 218.51474490119983
At time: 49.014622926712036 and batch: 1500, loss is 5.336992511749267 and perplexity is 207.88655281536148
At time: 50.63027501106262 and batch: 1550, loss is 5.324145278930664 and perplexity is 205.2328686202484
At time: 52.24872612953186 and batch: 1600, loss is 5.346810541152954 and perplexity is 209.9376414518293
At time: 53.872042417526245 and batch: 1650, loss is 5.339243564605713 and perplexity is 208.35504353474968
At time: 55.487417221069336 and batch: 1700, loss is 5.350692014694214 and perplexity is 210.75409234366361
At time: 57.105294942855835 and batch: 1750, loss is 5.338935737609863 and perplexity is 208.29091609821265
At time: 58.7211697101593 and batch: 1800, loss is 5.3217659854888915 and perplexity is 204.74513985691559
At time: 60.34196758270264 and batch: 1850, loss is 5.308069267272949 and perplexity is 201.95992109065546
At time: 61.96110820770264 and batch: 1900, loss is 5.340934591293335 and perplexity is 208.70767554490627
At time: 63.57626390457153 and batch: 1950, loss is 5.271387920379639 and perplexity is 194.68598366242725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.9072998046875 and perplexity of 135.2736555299245
finished 1 epochs...
Completing Train Step...
At time: 68.083984375 and batch: 50, loss is 5.163810949325562 and perplexity is 174.8294538522141
At time: 69.44767093658447 and batch: 100, loss is 5.1016226005554195 and perplexity is 164.28826537572874
At time: 70.80587363243103 and batch: 150, loss is 5.027041816711426 and perplexity is 152.4812773006577
At time: 72.16280627250671 and batch: 200, loss is 4.992128210067749 and perplexity is 147.2494680656446
At time: 73.51919865608215 and batch: 250, loss is 5.010632934570313 and perplexity is 149.99964607152612
At time: 74.86947417259216 and batch: 300, loss is 5.017176465988159 and perplexity is 150.98439181188803
At time: 76.2224817276001 and batch: 350, loss is 5.013561601638794 and perplexity is 150.4395890039963
At time: 77.5747320652008 and batch: 400, loss is 4.96067759513855 and perplexity is 142.69044950218463
At time: 78.92530536651611 and batch: 450, loss is 4.920069408416748 and perplexity is 137.01212265095526
At time: 80.30890965461731 and batch: 500, loss is 4.917334041595459 and perplexity is 136.63785634771776
At time: 81.65928387641907 and batch: 550, loss is 4.874195022583008 and perplexity is 130.86876439877196
At time: 83.01432919502258 and batch: 600, loss is 4.850771341323853 and perplexity is 127.83895929790077
At time: 84.36767172813416 and batch: 650, loss is 4.916065473556518 and perplexity is 136.46463182702126
At time: 85.7205228805542 and batch: 700, loss is 4.926695909500122 and perplexity is 137.92304842217607
At time: 87.07023334503174 and batch: 750, loss is 4.864758377075195 and perplexity is 129.63961092525548
At time: 88.41976237297058 and batch: 800, loss is 4.86792402267456 and perplexity is 130.05065425457167
At time: 89.77042555809021 and batch: 850, loss is 4.865351877212524 and perplexity is 129.71657488894527
At time: 91.1240746974945 and batch: 900, loss is 4.847448272705078 and perplexity is 127.41484673186254
At time: 92.47775721549988 and batch: 950, loss is 4.891887512207031 and perplexity is 133.2047625313584
At time: 93.82780694961548 and batch: 1000, loss is 4.856779317855835 and perplexity is 128.60932461636935
At time: 95.1791512966156 and batch: 1050, loss is 4.79100811958313 and perplexity is 120.42270798083683
At time: 96.5299379825592 and batch: 1100, loss is 4.843003225326538 and perplexity is 126.84973859809557
At time: 97.88123750686646 and batch: 1150, loss is 4.775141611099243 and perplexity is 118.5270981849898
At time: 99.23695063591003 and batch: 1200, loss is 4.8447222328186035 and perplexity is 127.06798177619919
At time: 100.59005689620972 and batch: 1250, loss is 4.8194349670410155 and perplexity is 123.89506620272982
At time: 101.94040179252625 and batch: 1300, loss is 4.83034652709961 and perplexity is 125.2543571643993
At time: 103.28931903839111 and batch: 1350, loss is 4.722777967453003 and perplexity is 112.48028563102275
At time: 104.63976836204529 and batch: 1400, loss is 4.725563945770264 and perplexity is 112.79409019128978
At time: 105.99353575706482 and batch: 1450, loss is 4.680539989471436 and perplexity is 107.82828299101733
At time: 107.34774661064148 and batch: 1500, loss is 4.655459880828857 and perplexity is 105.15756883061158
At time: 108.70739126205444 and batch: 1550, loss is 4.663138179779053 and perplexity is 105.96810787933926
At time: 110.06371712684631 and batch: 1600, loss is 4.720332822799683 and perplexity is 112.20559103288254
At time: 111.42089223861694 and batch: 1650, loss is 4.696787414550781 and perplexity is 109.5945245248189
At time: 112.779465675354 and batch: 1700, loss is 4.7127790451049805 and perplexity is 111.3612080976145
At time: 114.14899110794067 and batch: 1750, loss is 4.690741348266601 and perplexity is 108.9339078436778
At time: 115.51105618476868 and batch: 1800, loss is 4.650984258651733 and perplexity is 104.68797492977617
At time: 116.87031817436218 and batch: 1850, loss is 4.67547176361084 and perplexity is 107.28316744986078
At time: 118.22893857955933 and batch: 1900, loss is 4.77538818359375 and perplexity is 118.55632731065712
At time: 119.58557367324829 and batch: 1950, loss is 4.69286994934082 and perplexity is 109.16603163876754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.578826478470203 and perplexity of 97.40002608583842
finished 2 epochs...
Completing Train Step...
At time: 124.00459051132202 and batch: 50, loss is 4.67651107788086 and perplexity is 107.39472633905513
At time: 125.37908792495728 and batch: 100, loss is 4.61015775680542 and perplexity is 100.50000294528216
At time: 126.73594284057617 and batch: 150, loss is 4.554953699111938 and perplexity is 95.10235181029196
At time: 128.09182858467102 and batch: 200, loss is 4.549288921356201 and perplexity is 94.56514114931687
At time: 129.45236349105835 and batch: 250, loss is 4.557252826690674 and perplexity is 95.32125579781207
At time: 130.81608295440674 and batch: 300, loss is 4.5769407081604 and perplexity is 97.21652508322241
At time: 132.17968821525574 and batch: 350, loss is 4.5849441814422605 and perplexity is 97.99771689822055
At time: 133.53628492355347 and batch: 400, loss is 4.532257509231568 and perplexity is 92.96820093297772
At time: 134.89033246040344 and batch: 450, loss is 4.529805631637573 and perplexity is 92.74053350454524
At time: 136.23979926109314 and batch: 500, loss is 4.532943143844604 and perplexity is 93.03196500637908
At time: 137.5933198928833 and batch: 550, loss is 4.501254720687866 and perplexity is 90.13014854513725
At time: 138.94661211967468 and batch: 600, loss is 4.474973344802857 and perplexity is 87.7922602585615
At time: 140.2969617843628 and batch: 650, loss is 4.540463228225708 and perplexity is 93.73421039623493
At time: 141.6509130001068 and batch: 700, loss is 4.571200132369995 and perplexity is 96.660045039033
At time: 143.00360536575317 and batch: 750, loss is 4.517603406906128 and perplexity is 91.61576894386197
At time: 144.36017060279846 and batch: 800, loss is 4.514417600631714 and perplexity is 91.32436327978697
At time: 145.71557450294495 and batch: 850, loss is 4.511013288497924 and perplexity is 91.01399523635777
At time: 147.10592794418335 and batch: 900, loss is 4.488940753936768 and perplexity is 89.02709431754383
At time: 148.45858502388 and batch: 950, loss is 4.557274179458618 and perplexity is 95.32329119219783
At time: 149.80941009521484 and batch: 1000, loss is 4.522684402465821 and perplexity is 92.08245286451559
At time: 151.16032767295837 and batch: 1050, loss is 4.464723405838012 and perplexity is 86.89699101503878
At time: 152.51614141464233 and batch: 1100, loss is 4.506649217605591 and perplexity is 90.61766913555812
At time: 153.8726451396942 and batch: 1150, loss is 4.461170291900634 and perplexity is 86.58878397675832
At time: 155.22594475746155 and batch: 1200, loss is 4.532002182006836 and perplexity is 92.94446665037839
At time: 156.57458639144897 and batch: 1250, loss is 4.513056383132935 and perplexity is 91.20013552810231
At time: 157.92510986328125 and batch: 1300, loss is 4.512480020523071 and perplexity is 91.14758632512202
At time: 159.27634239196777 and batch: 1350, loss is 4.399799318313598 and perplexity is 81.43452460731693
At time: 160.63909244537354 and batch: 1400, loss is 4.4082392311096195 and perplexity is 82.12473344771796
At time: 162.00399136543274 and batch: 1450, loss is 4.362099132537842 and perplexity is 78.42157905542574
At time: 163.35889315605164 and batch: 1500, loss is 4.357224144935608 and perplexity is 78.04020518153136
At time: 164.71755075454712 and batch: 1550, loss is 4.365421886444092 and perplexity is 78.68258805776418
At time: 166.07311630249023 and batch: 1600, loss is 4.4366639137268065 and perplexity is 84.49259638059047
At time: 167.42991614341736 and batch: 1650, loss is 4.405695858001709 and perplexity is 81.91612500617582
At time: 168.78539872169495 and batch: 1700, loss is 4.416573820114135 and perplexity is 82.81206970186868
At time: 170.14078617095947 and batch: 1750, loss is 4.406350641250611 and perplexity is 81.96977987688304
At time: 171.5032081604004 and batch: 1800, loss is 4.362027349472046 and perplexity is 78.41594991609747
At time: 172.85503244400024 and batch: 1850, loss is 4.403163537979126 and perplexity is 81.70894959058865
At time: 174.20795035362244 and batch: 1900, loss is 4.504216117858887 and perplexity is 90.39745531746831
At time: 175.5606713294983 and batch: 1950, loss is 4.424077320098877 and perplexity is 83.43578717122166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465615915697675 and perplexity of 86.97458205652889
finished 3 epochs...
Completing Train Step...
At time: 179.90038585662842 and batch: 50, loss is 4.416979112625122 and perplexity is 82.84563961589602
At time: 181.28576803207397 and batch: 100, loss is 4.350028009414673 and perplexity is 77.4806330820494
At time: 182.634770154953 and batch: 150, loss is 4.300983858108521 and perplexity is 73.77233952076875
At time: 183.98543906211853 and batch: 200, loss is 4.30818962097168 and perplexity is 74.30584535504573
At time: 185.33909821510315 and batch: 250, loss is 4.304960241317749 and perplexity is 74.0662706169886
At time: 186.69661355018616 and batch: 300, loss is 4.329601135253906 and perplexity is 75.91400111090995
At time: 188.04630637168884 and batch: 350, loss is 4.337197551727295 and perplexity is 76.49287136561324
At time: 189.39726638793945 and batch: 400, loss is 4.283693780899048 and perplexity is 72.50777379702745
At time: 190.74886798858643 and batch: 450, loss is 4.3015043163299564 and perplexity is 73.81074493472669
At time: 192.10117268562317 and batch: 500, loss is 4.310460615158081 and perplexity is 74.47478525602138
At time: 193.45550155639648 and batch: 550, loss is 4.274005270004272 and perplexity is 71.80867352946112
At time: 194.80978298187256 and batch: 600, loss is 4.253651056289673 and perplexity is 70.36183898256552
At time: 196.1603057384491 and batch: 650, loss is 4.310921974182129 and perplexity is 74.50915279754142
At time: 197.5101170539856 and batch: 700, loss is 4.352883005142212 and perplexity is 77.70215603153343
At time: 198.86441445350647 and batch: 750, loss is 4.301442489624024 and perplexity is 73.80618160057435
At time: 200.22423648834229 and batch: 800, loss is 4.293691787719727 and perplexity is 73.23634306527859
At time: 201.59260654449463 and batch: 850, loss is 4.292864418029785 and perplexity is 73.17577459453776
At time: 202.95155787467957 and batch: 900, loss is 4.262430553436279 and perplexity is 70.98230023061927
At time: 204.30761790275574 and batch: 950, loss is 4.346609382629395 and perplexity is 77.21620795738994
At time: 205.66012358665466 and batch: 1000, loss is 4.316756839752197 and perplexity is 74.94517451485473
At time: 207.01148509979248 and batch: 1050, loss is 4.268023090362549 and perplexity is 71.38038347584224
At time: 208.36519074440002 and batch: 1100, loss is 4.2971227788925175 and perplexity is 73.48804786341725
At time: 209.71957445144653 and batch: 1150, loss is 4.2597341728210445 and perplexity is 70.79116273777285
At time: 211.07034492492676 and batch: 1200, loss is 4.32884877204895 and perplexity is 75.85690768992085
At time: 212.42284893989563 and batch: 1250, loss is 4.314409217834473 and perplexity is 74.76943794276197
At time: 213.77247619628906 and batch: 1300, loss is 4.310145502090454 and perplexity is 74.45132097512344
At time: 215.1251561641693 and batch: 1350, loss is 4.198246841430664 and perplexity is 66.56952175072561
At time: 216.47863793373108 and batch: 1400, loss is 4.211847167015076 and perplexity is 67.48107357062146
At time: 217.83279848098755 and batch: 1450, loss is 4.164305429458619 and perplexity is 64.34797271198528
At time: 219.18316888809204 and batch: 1500, loss is 4.16082603931427 and perplexity is 64.12447006186122
At time: 220.532728433609 and batch: 1550, loss is 4.171990442276001 and perplexity is 64.8443927610818
At time: 221.88231492042542 and batch: 1600, loss is 4.248050494194031 and perplexity is 69.96887457212372
At time: 223.23503065109253 and batch: 1650, loss is 4.212989616394043 and perplexity is 67.55821133582023
At time: 224.58905482292175 and batch: 1700, loss is 4.225016679763794 and perplexity is 68.37564402863828
At time: 225.94200253486633 and batch: 1750, loss is 4.2173897695541385 and perplexity is 67.856132782237
At time: 227.29227137565613 and batch: 1800, loss is 4.175756425857544 and perplexity is 65.08905608944988
At time: 228.64272451400757 and batch: 1850, loss is 4.2189292192459105 and perplexity is 67.960674332516
At time: 229.9935541152954 and batch: 1900, loss is 4.320073261260986 and perplexity is 75.19413690752516
At time: 231.3476414680481 and batch: 1950, loss is 4.2386133050918575 and perplexity is 69.31167102615917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425555277979651 and perplexity of 83.55919292219752
finished 4 epochs...
Completing Train Step...
At time: 235.66436409950256 and batch: 50, loss is 4.236916441917419 and perplexity is 69.19415833371289
At time: 237.05094981193542 and batch: 100, loss is 4.1725540494918825 and perplexity is 64.88094982969754
At time: 238.40430569648743 and batch: 150, loss is 4.127072782516479 and perplexity is 61.99618076086464
At time: 239.75919365882874 and batch: 200, loss is 4.135491390228271 and perplexity is 62.52030539062657
At time: 241.11186361312866 and batch: 250, loss is 4.134902858734131 and perplexity is 62.48352104731495
At time: 242.46111130714417 and batch: 300, loss is 4.159581580162048 and perplexity is 64.04471941171693
At time: 243.8113293647766 and batch: 350, loss is 4.165939288139343 and perplexity is 64.45319414085294
At time: 245.16222739219666 and batch: 400, loss is 4.112030682563781 and perplexity is 61.07060675354017
At time: 246.52183508872986 and batch: 450, loss is 4.140089550018311 and perplexity is 62.8084456948343
At time: 247.88561177253723 and batch: 500, loss is 4.149643154144287 and perplexity is 63.41136817633523
At time: 249.26451063156128 and batch: 550, loss is 4.118985934257507 and perplexity is 61.496848786605305
At time: 250.6216802597046 and batch: 600, loss is 4.097343974113464 and perplexity is 60.18023487767633
At time: 251.9774477481842 and batch: 650, loss is 4.150329260826111 and perplexity is 63.45489006836779
At time: 253.3325788974762 and batch: 700, loss is 4.19498544216156 and perplexity is 66.35276561742181
At time: 254.69615268707275 and batch: 750, loss is 4.149403781890869 and perplexity is 63.39619107080399
At time: 256.05862164497375 and batch: 800, loss is 4.136501617431641 and perplexity is 62.58349701747117
At time: 257.4079132080078 and batch: 850, loss is 4.13492666721344 and perplexity is 62.4850087026423
At time: 258.76133155822754 and batch: 900, loss is 4.1013722372055055 and perplexity is 60.42314562242431
At time: 260.11255288124084 and batch: 950, loss is 4.196046414375306 and perplexity is 66.42320141665276
At time: 261.4673044681549 and batch: 1000, loss is 4.161203174591065 and perplexity is 64.14865822244492
At time: 262.82173371315 and batch: 1050, loss is 4.12009705543518 and perplexity is 61.56521721342181
At time: 264.1749572753906 and batch: 1100, loss is 4.14859028339386 and perplexity is 63.344639336124125
At time: 265.52656388282776 and batch: 1150, loss is 4.112919826507568 and perplexity is 61.12493146134194
At time: 266.87708711624146 and batch: 1200, loss is 4.17856885433197 and perplexity is 65.27237206487192
At time: 268.2326760292053 and batch: 1250, loss is 4.170550775527954 and perplexity is 64.751105612342
At time: 269.59517431259155 and batch: 1300, loss is 4.1604786348342895 and perplexity is 64.10219680282434
At time: 270.95073914527893 and batch: 1350, loss is 4.04625394821167 and perplexity is 57.18284542293031
At time: 272.30248522758484 and batch: 1400, loss is 4.068991556167602 and perplexity is 58.49794094913032
At time: 273.6537697315216 and batch: 1450, loss is 4.015592627525329 and perplexity is 55.45615050735201
At time: 275.004540681839 and batch: 1500, loss is 4.016541166305542 and perplexity is 55.50877777226453
At time: 276.3566782474518 and batch: 1550, loss is 4.028980894088745 and perplexity is 56.203604625621445
At time: 277.7141375541687 and batch: 1600, loss is 4.109083795547486 and perplexity is 60.89090348807814
At time: 279.0698997974396 and batch: 1650, loss is 4.072659320831299 and perplexity is 58.7128915830438
At time: 280.4204857349396 and batch: 1700, loss is 4.083484129905701 and perplexity is 59.35189975565324
At time: 281.7714536190033 and batch: 1750, loss is 4.073183274269104 and perplexity is 58.74366246498291
At time: 283.1201832294464 and batch: 1800, loss is 4.033977766036987 and perplexity is 56.485149677432794
At time: 284.4726846218109 and batch: 1850, loss is 4.079478840827942 and perplexity is 59.11465367654752
At time: 285.8354802131653 and batch: 1900, loss is 4.179185757637024 and perplexity is 65.31265122982501
At time: 287.1903953552246 and batch: 1950, loss is 4.100665016174316 and perplexity is 60.38042821017616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4197137876998545 and perplexity of 83.0725055825723
finished 5 epochs...
Completing Train Step...
At time: 291.49630093574524 and batch: 50, loss is 4.101157212257386 and perplexity is 60.41015453542556
At time: 292.84949684143066 and batch: 100, loss is 4.04276746749878 and perplexity is 56.98382567610892
At time: 294.2061104774475 and batch: 150, loss is 3.997661838531494 and perplexity is 54.470639870251375
At time: 295.5582706928253 and batch: 200, loss is 4.002229228019714 and perplexity is 54.719997521480586
At time: 296.9096336364746 and batch: 250, loss is 3.9995349836349487 and perplexity is 54.57276690212037
At time: 298.2593722343445 and batch: 300, loss is 4.024245476722717 and perplexity is 55.938086266537255
At time: 299.6093280315399 and batch: 350, loss is 4.033157515525818 and perplexity is 56.43883670125426
At time: 300.9654061794281 and batch: 400, loss is 3.9825593185424806 and perplexity is 53.65417678641691
At time: 302.32131695747375 and batch: 450, loss is 4.013484110832215 and perplexity is 55.33934347633423
At time: 303.67238664627075 and batch: 500, loss is 4.029579224586487 and perplexity is 56.237243018786714
At time: 305.0240595340729 and batch: 550, loss is 3.998872313499451 and perplexity is 54.53661513895269
At time: 306.37436413764954 and batch: 600, loss is 3.978434805870056 and perplexity is 53.43333519936742
At time: 307.72579979896545 and batch: 650, loss is 4.0248504114151 and perplexity is 55.971935392768536
At time: 309.0800943374634 and batch: 700, loss is 4.072056531906128 and perplexity is 58.67751076688615
At time: 310.43438148498535 and batch: 750, loss is 4.02524121761322 and perplexity is 55.99381384688009
At time: 311.7836368083954 and batch: 800, loss is 4.014103059768677 and perplexity is 55.373606306500726
At time: 313.1406202316284 and batch: 850, loss is 4.013297090530395 and perplexity is 55.32899486334533
At time: 314.5053253173828 and batch: 900, loss is 3.9779534339904785 and perplexity is 53.40762008413363
At time: 315.8880515098572 and batch: 950, loss is 4.074200596809387 and perplexity is 58.80345412545255
At time: 317.2359793186188 and batch: 1000, loss is 4.046546096801758 and perplexity is 57.19955375113625
At time: 318.5835123062134 and batch: 1050, loss is 4.007402257919312 and perplexity is 55.00379912898275
At time: 319.9308125972748 and batch: 1100, loss is 4.032617716789246 and perplexity is 56.408379309679646
At time: 321.2827138900757 and batch: 1150, loss is 3.997665696144104 and perplexity is 54.47084999728392
At time: 322.6374912261963 and batch: 1200, loss is 4.063216023445129 and perplexity is 58.16105795280953
At time: 323.99398398399353 and batch: 1250, loss is 4.0589586448669435 and perplexity is 57.913970655889315
At time: 325.34823846817017 and batch: 1300, loss is 4.043149380683899 and perplexity is 57.005592706766606
At time: 326.70106267929077 and batch: 1350, loss is 3.9306225395202636 and perplexity is 50.93867914134348
At time: 328.0517268180847 and batch: 1400, loss is 3.9579817819595338 and perplexity is 52.351562390374795
At time: 329.40889859199524 and batch: 1450, loss is 3.904114465713501 and perplexity is 49.60613252541824
At time: 330.76345038414 and batch: 1500, loss is 3.897561860084534 and perplexity is 49.28214574025815
At time: 332.1153917312622 and batch: 1550, loss is 3.9133119630813598 and perplexity is 50.06448943580798
At time: 333.46610617637634 and batch: 1600, loss is 4.002619400024414 and perplexity is 54.7413518982798
At time: 334.8172070980072 and batch: 1650, loss is 3.960313582420349 and perplexity is 52.47377822377244
At time: 336.1735291481018 and batch: 1700, loss is 3.972728910446167 and perplexity is 53.129318345586356
At time: 337.528927564621 and batch: 1750, loss is 3.9612116956710817 and perplexity is 52.5209267885174
At time: 338.88303875923157 and batch: 1800, loss is 3.9217085218429566 and perplexity is 50.486628641405495
At time: 340.2347228527069 and batch: 1850, loss is 3.9696393394470215 and perplexity is 52.96542485507881
At time: 341.5868065357208 and batch: 1900, loss is 4.068376541137695 and perplexity is 58.46197489719291
At time: 342.9379906654358 and batch: 1950, loss is 3.9901088523864745 and perplexity is 54.060773687289945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.426174429960029 and perplexity of 83.61094478145391
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 347.28877305984497 and batch: 50, loss is 4.030894389152527 and perplexity is 56.3112529050191
At time: 348.63955569267273 and batch: 100, loss is 4.007007322311401 and perplexity is 54.982080459156705
At time: 350.00718545913696 and batch: 150, loss is 3.965728211402893 and perplexity is 52.75867487293869
At time: 351.3585696220398 and batch: 200, loss is 3.9680343437194825 and perplexity is 52.880483757762356
At time: 352.7123746871948 and batch: 250, loss is 3.959558615684509 and perplexity is 52.43417721731191
At time: 354.06859159469604 and batch: 300, loss is 3.9890398454666136 and perplexity is 54.00301322479285
At time: 355.42034459114075 and batch: 350, loss is 4.0090764713287355 and perplexity is 55.09596435765643
At time: 356.77229046821594 and batch: 400, loss is 3.9496329498291014 and perplexity is 51.91630744764867
At time: 358.12384271621704 and batch: 450, loss is 3.9657601594924925 and perplexity is 52.76036043873585
At time: 359.47697496414185 and batch: 500, loss is 3.9689937829971313 and perplexity is 52.93124371755639
At time: 360.8349812030792 and batch: 550, loss is 3.9407039213180544 and perplexity is 51.454808692209255
At time: 362.19026017189026 and batch: 600, loss is 3.9134424543380737 and perplexity is 50.071022840218
At time: 363.5430529117584 and batch: 650, loss is 3.9569351291656494 and perplexity is 52.29679714643201
At time: 364.893856048584 and batch: 700, loss is 4.001476039886475 and perplexity is 54.67879858591886
At time: 366.2439012527466 and batch: 750, loss is 3.9388119888305666 and perplexity is 51.35755169884989
At time: 367.5969605445862 and batch: 800, loss is 3.926026477813721 and perplexity is 50.705099014273316
At time: 368.9512219429016 and batch: 850, loss is 3.918601622581482 and perplexity is 50.33001518925473
At time: 370.3045771121979 and batch: 900, loss is 3.8792287254333497 and perplexity is 48.3868811050707
At time: 371.65581917762756 and batch: 950, loss is 3.9786756658554077 and perplexity is 53.44620670175354
At time: 373.00546288490295 and batch: 1000, loss is 3.9347407531738283 and perplexity is 51.14888805078876
At time: 374.3581590652466 and batch: 1050, loss is 3.8921608829498293 and perplexity is 49.0166914993954
At time: 375.71520137786865 and batch: 1100, loss is 3.909299864768982 and perplexity is 49.864028186253904
At time: 377.07045340538025 and batch: 1150, loss is 3.8743399953842164 and perplexity is 48.150907979855866
At time: 378.42214608192444 and batch: 1200, loss is 3.919034242630005 and perplexity is 50.35179367343282
At time: 379.77276730537415 and batch: 1250, loss is 3.8954736375808716 and perplexity is 49.179341031405976
At time: 381.12375140190125 and batch: 1300, loss is 3.8872177696228025 and perplexity is 48.77499429886752
At time: 382.4753804206848 and batch: 1350, loss is 3.7772519159317017 and perplexity is 43.69579686652277
At time: 383.8307168483734 and batch: 1400, loss is 3.78783136844635 and perplexity is 44.16052844280864
At time: 385.18644404411316 and batch: 1450, loss is 3.728583993911743 and perplexity is 41.62013205823263
At time: 386.5384147167206 and batch: 1500, loss is 3.72013943195343 and perplexity is 41.27014808482321
At time: 387.8904528617859 and batch: 1550, loss is 3.7345270586013792 and perplexity is 41.868219665591056
At time: 389.24107241630554 and batch: 1600, loss is 3.8124845123291013 and perplexity is 45.26275515617437
At time: 390.5934658050537 and batch: 1650, loss is 3.759896445274353 and perplexity is 42.94397869656633
At time: 391.94699478149414 and batch: 1700, loss is 3.7631653928756714 and perplexity is 43.08459001301579
At time: 393.29908514022827 and batch: 1750, loss is 3.7364916515350344 and perplexity is 41.95055452485033
At time: 394.65181279182434 and batch: 1800, loss is 3.6957400941848757 and perplexity is 40.27536912697355
At time: 396.00170397758484 and batch: 1850, loss is 3.7296445178985596 and perplexity is 41.66429462020382
At time: 397.3524925708771 and batch: 1900, loss is 3.8220885515213014 and perplexity is 45.69955459265677
At time: 398.7060651779175 and batch: 1950, loss is 3.741527781486511 and perplexity is 42.162355850822145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3598635651344475 and perplexity of 78.24645814979523
finished 7 epochs...
Completing Train Step...
At time: 403.04225635528564 and batch: 50, loss is 3.947221989631653 and perplexity is 51.791290063320375
At time: 404.3959882259369 and batch: 100, loss is 3.905520725250244 and perplexity is 49.67594069506101
At time: 405.7480843067169 and batch: 150, loss is 3.859244050979614 and perplexity is 47.42948354181641
At time: 407.0990171432495 and batch: 200, loss is 3.8550105571746824 and perplexity is 47.2291155446657
At time: 408.4501085281372 and batch: 250, loss is 3.8466717338562013 and perplexity is 46.836917801146875
At time: 409.8013792037964 and batch: 300, loss is 3.872595829963684 and perplexity is 48.06699802887959
At time: 411.1539146900177 and batch: 350, loss is 3.8939454555511475 and perplexity is 49.10424344221611
At time: 412.50323939323425 and batch: 400, loss is 3.8361921739578246 and perplexity is 46.34865039784426
At time: 413.8537311553955 and batch: 450, loss is 3.8602241468429566 and perplexity is 47.47599176997429
At time: 415.20669436454773 and batch: 500, loss is 3.8675029039382935 and perplexity is 47.82281868511458
At time: 416.5734841823578 and batch: 550, loss is 3.840999836921692 and perplexity is 46.57201558983628
At time: 417.9253842830658 and batch: 600, loss is 3.8168573331832887 and perplexity is 45.461114454599446
At time: 419.2837553024292 and batch: 650, loss is 3.8603139114379883 and perplexity is 47.48025362442821
At time: 420.6415436267853 and batch: 700, loss is 3.907025375366211 and perplexity is 49.75074186567131
At time: 421.99981665611267 and batch: 750, loss is 3.8517625904083252 and perplexity is 47.07596579425703
At time: 423.3563163280487 and batch: 800, loss is 3.836555299758911 and perplexity is 46.36548384479374
At time: 424.71236205101013 and batch: 850, loss is 3.832423086166382 and perplexity is 46.17428706724762
At time: 426.0650794506073 and batch: 900, loss is 3.7936830711364746 and perplexity is 44.41970028462112
At time: 427.41559648513794 and batch: 950, loss is 3.89647705078125 and perplexity is 49.22871299748157
At time: 428.7661154270172 and batch: 1000, loss is 3.855042839050293 and perplexity is 47.23064021370836
At time: 430.1160202026367 and batch: 1050, loss is 3.8170981407165527 and perplexity is 45.472063151642146
At time: 431.4673008918762 and batch: 1100, loss is 3.833666296005249 and perplexity is 46.23172709283664
At time: 432.81623816490173 and batch: 1150, loss is 3.802066640853882 and perplexity is 44.793661312663986
At time: 434.1679587364197 and batch: 1200, loss is 3.8511315870285032 and perplexity is 47.04627007076873
At time: 435.51832938194275 and batch: 1250, loss is 3.8311832094192506 and perplexity is 46.11707211946892
At time: 436.86926436424255 and batch: 1300, loss is 3.824714322090149 and perplexity is 45.819708817794336
At time: 438.2197563648224 and batch: 1350, loss is 3.717244381904602 and perplexity is 41.150841722868286
At time: 439.5718402862549 and batch: 1400, loss is 3.731064133644104 and perplexity is 41.72348391195855
At time: 440.9231925010681 and batch: 1450, loss is 3.6725451135635376 and perplexity is 39.3519336553582
At time: 442.2736053466797 and batch: 1500, loss is 3.668254976272583 and perplexity is 39.183470081626915
At time: 443.62407422065735 and batch: 1550, loss is 3.6863733291625977 and perplexity is 39.89988051032344
At time: 444.9769320487976 and batch: 1600, loss is 3.76795551776886 and perplexity is 43.291465664685944
At time: 446.3275394439697 and batch: 1650, loss is 3.7159382009506228 and perplexity is 41.09712636579485
At time: 447.6785306930542 and batch: 1700, loss is 3.725296573638916 and perplexity is 41.48353384323682
At time: 449.0332336425781 and batch: 1750, loss is 3.7040635347366333 and perplexity is 40.61199777842851
At time: 450.38981461524963 and batch: 1800, loss is 3.663695845603943 and perplexity is 39.005234130698504
At time: 451.74787735939026 and batch: 1850, loss is 3.7021478176116944 and perplexity is 40.53427115369064
At time: 453.09930515289307 and batch: 1900, loss is 3.7972496604919432 and perplexity is 44.57840997273184
At time: 454.44944643974304 and batch: 1950, loss is 3.7203295612335205 and perplexity is 41.27799549435533
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364727073492006 and perplexity of 78.62793736468129
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 458.73895478248596 and batch: 50, loss is 3.9140312099456787 and perplexity is 50.100511115535625
At time: 460.1094036102295 and batch: 100, loss is 3.9088134765625 and perplexity is 49.83978080831378
At time: 461.45918893814087 and batch: 150, loss is 3.882399845123291 and perplexity is 48.54056524308859
At time: 462.81073904037476 and batch: 200, loss is 3.880839705467224 and perplexity is 48.46489422635079
At time: 464.16249775886536 and batch: 250, loss is 3.8743592166900633 and perplexity is 48.1518335120799
At time: 465.513925075531 and batch: 300, loss is 3.8849792289733887 and perplexity is 48.66593160763175
At time: 466.86534547805786 and batch: 350, loss is 3.909129900932312 and perplexity is 49.855553824899424
At time: 468.22098112106323 and batch: 400, loss is 3.866418008804321 and perplexity is 47.770964075323235
At time: 469.5719199180603 and batch: 450, loss is 3.9003188180923463 and perplexity is 49.41820201113345
At time: 470.92326617240906 and batch: 500, loss is 3.896608691215515 and perplexity is 49.2351939132048
At time: 472.27442169189453 and batch: 550, loss is 3.8655072116851805 and perplexity is 47.72747422708552
At time: 473.6240653991699 and batch: 600, loss is 3.8280645847320556 and perplexity is 45.97347431007654
At time: 474.9758405685425 and batch: 650, loss is 3.869247107505798 and perplexity is 47.90630420277686
At time: 476.3273026943207 and batch: 700, loss is 3.9254450511932375 and perplexity is 50.67562628885603
At time: 477.676438331604 and batch: 750, loss is 3.8675305700302123 and perplexity is 47.8241417739144
At time: 479.0242202281952 and batch: 800, loss is 3.8515414094924925 and perplexity is 47.065554640445654
At time: 480.3753972053528 and batch: 850, loss is 3.8385685968399046 and perplexity is 46.45892536928885
At time: 481.72611927986145 and batch: 900, loss is 3.79135347366333 and perplexity is 44.31634070293496
At time: 483.07691073417664 and batch: 950, loss is 3.9018014526367186 and perplexity is 49.49152548708344
At time: 484.445627450943 and batch: 1000, loss is 3.859840588569641 and perplexity is 47.45778545236214
At time: 485.7956380844116 and batch: 1050, loss is 3.809269094467163 and perplexity is 45.1174502180027
At time: 487.146347284317 and batch: 1100, loss is 3.830622797012329 and perplexity is 46.091234780541136
At time: 488.49620389938354 and batch: 1150, loss is 3.8013956928253174 and perplexity is 44.76361717406893
At time: 489.8473610877991 and batch: 1200, loss is 3.8374605989456176 and perplexity is 46.40747748514586
At time: 491.1994116306305 and batch: 1250, loss is 3.8147242069244385 and perplexity is 45.36424351330611
At time: 492.5493845939636 and batch: 1300, loss is 3.8011338329315185 and perplexity is 44.75189691262985
At time: 493.90020060539246 and batch: 1350, loss is 3.6855282163619996 and perplexity is 39.866174855108255
At time: 495.2509698867798 and batch: 1400, loss is 3.6992494916915892 and perplexity is 40.41695971047249
At time: 496.60264706611633 and batch: 1450, loss is 3.63583297252655 and perplexity is 37.93343725193449
At time: 497.95365953445435 and batch: 1500, loss is 3.6261043882369997 and perplexity is 37.56618791483464
At time: 499.30534386634827 and batch: 1550, loss is 3.6501563739776612 and perplexity is 38.48068295603298
At time: 500.6608417034149 and batch: 1600, loss is 3.727784523963928 and perplexity is 41.586871310683584
At time: 502.01892042160034 and batch: 1650, loss is 3.6790033340454102 and perplexity is 39.60689954607249
At time: 503.3748297691345 and batch: 1700, loss is 3.679524097442627 and perplexity is 39.6275307411527
At time: 504.72748613357544 and batch: 1750, loss is 3.6527876091003417 and perplexity is 38.58206800602977
At time: 506.07843494415283 and batch: 1800, loss is 3.612271771430969 and perplexity is 37.050126699689386
At time: 507.4298212528229 and batch: 1850, loss is 3.6404310703277587 and perplexity is 38.10826052559331
At time: 508.7790434360504 and batch: 1900, loss is 3.7369309663772583 and perplexity is 41.96898807486221
At time: 510.12731885910034 and batch: 1950, loss is 3.6724402856826783 and perplexity is 39.347808691754764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337409440861192 and perplexity of 76.50908109114792
finished 9 epochs...
Completing Train Step...
At time: 514.4027259349823 and batch: 50, loss is 3.910512022972107 and perplexity is 49.92450792516117
At time: 515.7884545326233 and batch: 100, loss is 3.880981001853943 and perplexity is 48.47174262460326
At time: 517.1407949924469 and batch: 150, loss is 3.8447546672821047 and perplexity is 46.74721432283928
At time: 518.5081105232239 and batch: 200, loss is 3.8354829692840577 and perplexity is 46.315791371624066
At time: 519.8585479259491 and batch: 250, loss is 3.8263536500930786 and perplexity is 45.89488395106052
At time: 521.2068412303925 and batch: 300, loss is 3.833405809402466 and perplexity is 46.21968591565618
At time: 522.5585157871246 and batch: 350, loss is 3.857926812171936 and perplexity is 47.36704871528287
At time: 523.913482427597 and batch: 400, loss is 3.812259430885315 and perplexity is 45.25256849635113
At time: 525.265650510788 and batch: 450, loss is 3.8483096837997435 and perplexity is 46.91369719124797
At time: 526.6170341968536 and batch: 500, loss is 3.8459546041488646 and perplexity is 46.80334169664153
At time: 527.9690256118774 and batch: 550, loss is 3.8152663326263427 and perplexity is 45.38884330314879
At time: 529.3196995258331 and batch: 600, loss is 3.7820464849472044 and perplexity is 43.90580242105051
At time: 530.6706049442291 and batch: 650, loss is 3.82513557434082 and perplexity is 45.839014539262756
At time: 532.0231359004974 and batch: 700, loss is 3.883316631317139 and perplexity is 48.585086968478244
At time: 533.3744719028473 and batch: 750, loss is 3.8279536867141726 and perplexity is 45.96837622558932
At time: 534.7253725528717 and batch: 800, loss is 3.8120531845092773 and perplexity is 45.243236280493285
At time: 536.0787899494171 and batch: 850, loss is 3.800265140533447 and perplexity is 44.71303816057748
At time: 537.4356446266174 and batch: 900, loss is 3.754337286949158 and perplexity is 42.70590866748455
At time: 538.7894387245178 and batch: 950, loss is 3.8640661096572875 and perplexity is 47.658743603006364
At time: 540.1388139724731 and batch: 1000, loss is 3.823526496887207 and perplexity is 45.765315324245805
At time: 541.4891810417175 and batch: 1050, loss is 3.777194199562073 and perplexity is 43.69327497653746
At time: 542.840803861618 and batch: 1100, loss is 3.7993043994903566 and perplexity is 44.67010113863763
At time: 544.1961557865143 and batch: 1150, loss is 3.7712820196151733 and perplexity is 43.43571459429758
At time: 545.553563117981 and batch: 1200, loss is 3.8102033281326295 and perplexity is 45.15962015411623
At time: 546.904679775238 and batch: 1250, loss is 3.7891852045059204 and perplexity is 44.22035504719349
At time: 548.2554531097412 and batch: 1300, loss is 3.778710207939148 and perplexity is 43.759564582526714
At time: 549.6068735122681 and batch: 1350, loss is 3.6644208812713623 and perplexity is 39.03352457120921
At time: 550.9574751853943 and batch: 1400, loss is 3.681671438217163 and perplexity is 39.712715981844774
At time: 552.308269739151 and batch: 1450, loss is 3.62049072265625 and perplexity is 37.35589470885473
At time: 553.659752368927 and batch: 1500, loss is 3.6141040420532224 and perplexity is 37.11807478902626
At time: 555.0126240253448 and batch: 1550, loss is 3.641571669578552 and perplexity is 38.15175157721325
At time: 556.362318277359 and batch: 1600, loss is 3.720651216506958 and perplexity is 41.29127491486634
At time: 557.7128279209137 and batch: 1650, loss is 3.6731478214263915 and perplexity is 39.37565852405506
At time: 559.0634682178497 and batch: 1700, loss is 3.6762285947799684 and perplexity is 39.49715305608024
At time: 560.413645029068 and batch: 1750, loss is 3.6514660787582396 and perplexity is 38.53111430834317
At time: 561.7647974491119 and batch: 1800, loss is 3.6130449295043947 and perplexity is 37.0787833809134
At time: 563.1170721054077 and batch: 1850, loss is 3.642324457168579 and perplexity is 38.180482555143385
At time: 564.4677097797394 and batch: 1900, loss is 3.7394501399993896 and perplexity is 42.07484852701268
At time: 565.8181502819061 and batch: 1950, loss is 3.6741715383529665 and perplexity is 39.4159886919968
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338084801962209 and perplexity of 76.56076980069867
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 570.08678150177 and batch: 50, loss is 3.903374342918396 and perplexity is 49.56943147927494
At time: 571.454763174057 and batch: 100, loss is 3.889227018356323 and perplexity is 48.87309391465138
At time: 572.806711435318 and batch: 150, loss is 3.8691196393966676 and perplexity is 47.90019806594182
At time: 574.1586537361145 and batch: 200, loss is 3.8684463834762575 and perplexity is 47.867959827515286
At time: 575.5093581676483 and batch: 250, loss is 3.8656174612045286 and perplexity is 47.732736448252105
At time: 576.8607614040375 and batch: 300, loss is 3.874653263092041 and perplexity is 48.16599446735969
At time: 578.2110540866852 and batch: 350, loss is 3.9018164825439454 and perplexity is 49.49226934571008
At time: 579.5626621246338 and batch: 400, loss is 3.8466600656509398 and perplexity is 46.8363713015645
At time: 580.913872718811 and batch: 450, loss is 3.8932924318313598 and perplexity is 49.072187674233696
At time: 582.2639026641846 and batch: 500, loss is 3.8901340913772584 and perplexity is 48.91744549160947
At time: 583.6152868270874 and batch: 550, loss is 3.8588640546798705 and perplexity is 47.411463937480086
At time: 584.965794801712 and batch: 600, loss is 3.818986301422119 and perplexity is 45.55800282290895
At time: 586.3501794338226 and batch: 650, loss is 3.8463579273223876 and perplexity is 46.822222376197956
At time: 587.7010941505432 and batch: 700, loss is 3.9040074014663695 and perplexity is 49.60082176648758
At time: 589.0590195655823 and batch: 750, loss is 3.848186869621277 and perplexity is 46.90793587786133
At time: 590.4092121124268 and batch: 800, loss is 3.8364299297332765 and perplexity is 46.35967136725839
At time: 591.7595241069794 and batch: 850, loss is 3.830032033920288 and perplexity is 46.06401382152683
At time: 593.1101543903351 and batch: 900, loss is 3.776419372558594 and perplexity is 43.65943335960762
At time: 594.4626252651215 and batch: 950, loss is 3.8895523071289064 and perplexity is 48.88899436936272
At time: 595.8123295307159 and batch: 1000, loss is 3.85000901222229 and perplexity is 46.9934867454196
At time: 597.1636443138123 and batch: 1050, loss is 3.7999686765670777 and perplexity is 44.699784320676024
At time: 598.51411485672 and batch: 1100, loss is 3.8177906894683837 and perplexity is 45.503565679480054
At time: 599.8654742240906 and batch: 1150, loss is 3.793825330734253 and perplexity is 44.426019862816716
At time: 601.2159547805786 and batch: 1200, loss is 3.8272318172454836 and perplexity is 45.93520503234312
At time: 602.5657663345337 and batch: 1250, loss is 3.804785523414612 and perplexity is 44.91561573198299
At time: 603.9166052341461 and batch: 1300, loss is 3.7892892169952392 and perplexity is 44.22495475560993
At time: 605.2695128917694 and batch: 1350, loss is 3.6640763330459594 and perplexity is 39.020077956223666
At time: 606.621025800705 and batch: 1400, loss is 3.6820128536224366 and perplexity is 39.726276829675676
At time: 607.9721298217773 and batch: 1450, loss is 3.6163837814331057 and perplexity is 37.20279085441283
At time: 609.3217768669128 and batch: 1500, loss is 3.6089037036895752 and perplexity is 36.92554927350875
At time: 610.6728234291077 and batch: 1550, loss is 3.63331250667572 and perplexity is 37.83794770835499
At time: 612.0221643447876 and batch: 1600, loss is 3.709978313446045 and perplexity is 40.85292055831759
At time: 613.374189376831 and batch: 1650, loss is 3.662513756752014 and perplexity is 38.9591537192019
At time: 614.725528717041 and batch: 1700, loss is 3.6620446109771727 and perplexity is 38.94088048358394
At time: 616.0761933326721 and batch: 1750, loss is 3.639612593650818 and perplexity is 38.077082564112
At time: 617.4285817146301 and batch: 1800, loss is 3.602409157752991 and perplexity is 36.68651165810448
At time: 618.7804601192474 and batch: 1850, loss is 3.6283715677261354 and perplexity is 37.65145382559922
At time: 620.1313638687134 and batch: 1900, loss is 3.7252570152282716 and perplexity is 41.48189285302776
At time: 621.4825556278229 and batch: 1950, loss is 3.667715549468994 and perplexity is 39.162339167410416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.321935751271802 and perplexity of 75.33431573670006
finished 11 epochs...
Completing Train Step...
At time: 625.7865676879883 and batch: 50, loss is 3.908402876853943 and perplexity is 49.81932080956155
At time: 627.142077922821 and batch: 100, loss is 3.877447681427002 and perplexity is 48.30077863939346
At time: 628.4995210170746 and batch: 150, loss is 3.8486011695861815 and perplexity is 46.927373860348965
At time: 629.8530960083008 and batch: 200, loss is 3.8443718481063844 and perplexity is 46.72932201776224
At time: 631.2040963172913 and batch: 250, loss is 3.839341235160828 and perplexity is 46.494835186241986
At time: 632.5555694103241 and batch: 300, loss is 3.8468263864517214 and perplexity is 46.8441618121891
At time: 633.9074881076813 and batch: 350, loss is 3.8745054531097414 and perplexity is 48.15887557870439
At time: 635.2595906257629 and batch: 400, loss is 3.819721975326538 and perplexity is 45.591530988109156
At time: 636.6129415035248 and batch: 450, loss is 3.8669966363906862 and perplexity is 47.7986136716026
At time: 637.9642360210419 and batch: 500, loss is 3.8651209926605223 and perplexity is 47.709044527719485
At time: 639.3138747215271 and batch: 550, loss is 3.8344693422317504 and perplexity is 46.26886821784735
At time: 640.6628000736237 and batch: 600, loss is 3.7943492221832273 and perplexity is 44.449300372432305
At time: 642.0143780708313 and batch: 650, loss is 3.823759088516235 and perplexity is 45.77596119151186
At time: 643.3638255596161 and batch: 700, loss is 3.8837674283981323 and perplexity is 48.606993921287646
At time: 644.7148418426514 and batch: 750, loss is 3.8288984203338625 and perplexity is 46.01182461639839
At time: 646.0642557144165 and batch: 800, loss is 3.817901711463928 and perplexity is 45.50861785659238
At time: 647.4208362102509 and batch: 850, loss is 3.8115650367736817 and perplexity is 45.22115628673988
At time: 648.8018887042999 and batch: 900, loss is 3.7598526000976564 and perplexity is 42.94209585150948
At time: 650.1539082527161 and batch: 950, loss is 3.8720586919784545 and perplexity is 48.04118635123918
At time: 651.5039858818054 and batch: 1000, loss is 3.8318054151535033 and perplexity is 46.14577535492143
At time: 652.9104027748108 and batch: 1050, loss is 3.7828686332702635 and perplexity is 43.94191434552853
At time: 654.2682685852051 and batch: 1100, loss is 3.800990414619446 and perplexity is 44.745479131337284
At time: 655.6225256919861 and batch: 1150, loss is 3.777841272354126 and perplexity is 43.72155685520075
At time: 656.9781856536865 and batch: 1200, loss is 3.8125642013549803 and perplexity is 45.26636224476214
At time: 658.3281109333038 and batch: 1250, loss is 3.7919409561157225 and perplexity is 44.34238342452414
At time: 659.6793839931488 and batch: 1300, loss is 3.778522024154663 and perplexity is 43.75133051683928
At time: 661.0295634269714 and batch: 1350, loss is 3.6553766441345217 and perplexity is 38.6820877532331
At time: 662.3848283290863 and batch: 1400, loss is 3.6757695198059084 and perplexity is 39.47902506293794
At time: 663.738569021225 and batch: 1450, loss is 3.612181444168091 and perplexity is 37.04678021429702
At time: 665.0906436443329 and batch: 1500, loss is 3.6072430276870726 and perplexity is 36.864278789243656
At time: 666.441596031189 and batch: 1550, loss is 3.6342746210098267 and perplexity is 37.87436965844896
At time: 667.7935824394226 and batch: 1600, loss is 3.7123909282684324 and perplexity is 40.95160191217662
At time: 669.1462044715881 and batch: 1650, loss is 3.6662356996536256 and perplexity is 39.10442764776859
At time: 670.5005657672882 and batch: 1700, loss is 3.6667564344406127 and perplexity is 39.124795986360965
At time: 671.8539547920227 and batch: 1750, loss is 3.6453713941574097 and perplexity is 38.2969934902921
At time: 673.2056660652161 and batch: 1800, loss is 3.6089461278915405 and perplexity is 36.927115843698815
At time: 674.5565173625946 and batch: 1850, loss is 3.63551146030426 and perplexity is 37.9212431486062
At time: 675.9079196453094 and batch: 1900, loss is 3.732116947174072 and perplexity is 41.76743409195094
At time: 677.2622075080872 and batch: 1950, loss is 3.6732580184936525 and perplexity is 39.37999784523172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3206883630087205 and perplexity of 75.24040318033026
finished 12 epochs...
Completing Train Step...
At time: 681.5713031291962 and batch: 50, loss is 3.902949357032776 and perplexity is 49.548369646345904
At time: 682.9229307174683 and batch: 100, loss is 3.8704532194137573 and perplexity is 47.964119425547786
At time: 684.2782618999481 and batch: 150, loss is 3.8403826904296876 and perplexity is 46.5432827009022
At time: 685.6447982788086 and batch: 200, loss is 3.8349504470825195 and perplexity is 46.29113375038494
At time: 687.0291125774384 and batch: 250, loss is 3.8290172672271727 and perplexity is 46.0172933037714
At time: 688.3862454891205 and batch: 300, loss is 3.8359329319000244 and perplexity is 46.33663643566828
At time: 689.7435030937195 and batch: 350, loss is 3.863804650306702 and perplexity is 47.646284407711725
At time: 691.0948901176453 and batch: 400, loss is 3.8085012578964235 and perplexity is 45.082820686358595
At time: 692.4465670585632 and batch: 450, loss is 3.855728521347046 and perplexity is 47.26303653308927
At time: 693.7997007369995 and batch: 500, loss is 3.853803071975708 and perplexity is 47.172121503340406
At time: 695.165610074997 and batch: 550, loss is 3.823047842979431 and perplexity is 45.743414819024586
At time: 696.529146194458 and batch: 600, loss is 3.783153619766235 and perplexity is 43.95443898231556
At time: 697.8883218765259 and batch: 650, loss is 3.8130760765075684 and perplexity is 45.28953890211474
At time: 699.2459795475006 and batch: 700, loss is 3.8735595035552977 and perplexity is 48.11334125179175
At time: 700.6045136451721 and batch: 750, loss is 3.819468994140625 and perplexity is 45.57999864732632
At time: 701.9766254425049 and batch: 800, loss is 3.8085027647018435 and perplexity is 45.08288861744833
At time: 703.3356099128723 and batch: 850, loss is 3.8022396469116213 and perplexity is 44.801411557819755
At time: 704.6890788078308 and batch: 900, loss is 3.75092098236084 and perplexity is 42.56026120545787
At time: 706.0426881313324 and batch: 950, loss is 3.8632674074172972 and perplexity is 47.6206936550476
At time: 707.3948721885681 and batch: 1000, loss is 3.8229761028289797 and perplexity is 45.740133297273154
At time: 708.7484884262085 and batch: 1050, loss is 3.7750147008895873 and perplexity is 43.598149242590615
At time: 710.1052374839783 and batch: 1100, loss is 3.7933985233306884 and perplexity is 44.407062554475914
At time: 711.4636507034302 and batch: 1150, loss is 3.77056529045105 and perplexity is 43.40459410469677
At time: 712.8199779987335 and batch: 1200, loss is 3.805933356285095 and perplexity is 44.96720095206006
At time: 714.173360824585 and batch: 1250, loss is 3.7860226106643675 and perplexity is 44.08072493769383
At time: 715.5257616043091 and batch: 1300, loss is 3.77353244304657 and perplexity is 43.5335734147716
At time: 716.8810198307037 and batch: 1350, loss is 3.6511127805709838 and perplexity is 38.517503739941226
At time: 718.238778591156 and batch: 1400, loss is 3.672262363433838 and perplexity is 39.340808463912
At time: 719.5928945541382 and batch: 1450, loss is 3.609396481513977 and perplexity is 36.94374984939638
At time: 720.9445576667786 and batch: 1500, loss is 3.605461206436157 and perplexity is 36.79865171911461
At time: 722.2957854270935 and batch: 1550, loss is 3.633399395942688 and perplexity is 37.841235562732486
At time: 723.6489551067352 and batch: 1600, loss is 3.71207407951355 and perplexity is 40.93862850351302
At time: 725.0043740272522 and batch: 1650, loss is 3.66612238407135 and perplexity is 39.0999967578293
At time: 726.3624484539032 and batch: 1700, loss is 3.666812653541565 and perplexity is 39.12699560904609
At time: 727.7143709659576 and batch: 1750, loss is 3.645826382637024 and perplexity is 38.314422145752104
At time: 729.0661702156067 and batch: 1800, loss is 3.6098392009735107 and perplexity is 36.96010918739429
At time: 730.4175341129303 and batch: 1850, loss is 3.6366614961624144 and perplexity is 37.9648790246146
At time: 731.7717168331146 and batch: 1900, loss is 3.733100800514221 and perplexity is 41.808547342880026
At time: 733.1293551921844 and batch: 1950, loss is 3.6736748790740967 and perplexity is 39.396417236052
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320721577489099 and perplexity of 75.2429022927285
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 737.464521408081 and batch: 50, loss is 3.9012852907180786 and perplexity is 49.4659864380409
At time: 738.8178968429565 and batch: 100, loss is 3.8739366865158082 and perplexity is 48.13149220718552
At time: 740.1742980480194 and batch: 150, loss is 3.849284291267395 and perplexity is 46.959441918821334
At time: 741.5316662788391 and batch: 200, loss is 3.847307734489441 and perplexity is 46.86671558522775
At time: 742.8867728710175 and batch: 250, loss is 3.8448537397384643 and perplexity is 46.75184591361796
At time: 744.2379519939423 and batch: 300, loss is 3.8544828939437865 and perplexity is 47.204201050774294
At time: 745.5916528701782 and batch: 350, loss is 3.8928293704986574 and perplexity is 49.04946950197015
At time: 746.9453184604645 and batch: 400, loss is 3.839815812110901 and perplexity is 46.516905800006874
At time: 748.3010492324829 and batch: 450, loss is 3.8956084966659548 and perplexity is 49.18597375957424
At time: 749.6576833724976 and batch: 500, loss is 3.8942545461654663 and perplexity is 49.11942344886526
At time: 751.0089509487152 and batch: 550, loss is 3.866636567115784 and perplexity is 47.78140595760699
At time: 752.3614075183868 and batch: 600, loss is 3.8186028099060056 and perplexity is 45.54053506491787
At time: 753.7133693695068 and batch: 650, loss is 3.839160385131836 and perplexity is 46.48642735425182
At time: 755.0857918262482 and batch: 700, loss is 3.8927944898605347 and perplexity is 49.04775865501223
At time: 756.4410359859467 and batch: 750, loss is 3.8293539333343505 and perplexity is 46.032788374957136
At time: 757.7975018024445 and batch: 800, loss is 3.813755178451538 and perplexity is 45.320305561691406
At time: 759.1499571800232 and batch: 850, loss is 3.809968843460083 and perplexity is 45.149032156782134
At time: 760.5023880004883 and batch: 900, loss is 3.753461980819702 and perplexity is 42.668544278888696
At time: 761.8538815975189 and batch: 950, loss is 3.866965594291687 and perplexity is 47.797129925334396
At time: 763.2089173793793 and batch: 1000, loss is 3.828096981048584 and perplexity is 45.97496370542754
At time: 764.5644910335541 and batch: 1050, loss is 3.7809052085876464 and perplexity is 43.8557223497365
At time: 765.9204142093658 and batch: 1100, loss is 3.793997735977173 and perplexity is 44.43367980185099
At time: 767.2743356227875 and batch: 1150, loss is 3.7751224040985107 and perplexity is 43.6028451560451
At time: 768.6283121109009 and batch: 1200, loss is 3.8132889890670776 and perplexity is 45.299182640361444
At time: 769.9798212051392 and batch: 1250, loss is 3.7928836345672607 and perplexity is 44.38420374232756
At time: 771.3373548984528 and batch: 1300, loss is 3.778729410171509 and perplexity is 43.76040487192154
At time: 772.6941049098969 and batch: 1350, loss is 3.6505083417892457 and perplexity is 38.49422930160024
At time: 774.0540487766266 and batch: 1400, loss is 3.6714378213882446 and perplexity is 39.308383682860566
At time: 775.4116122722626 and batch: 1450, loss is 3.6051335525512695 and perplexity is 36.786596473002184
At time: 776.7678701877594 and batch: 1500, loss is 3.601503086090088 and perplexity is 36.653286104119886
At time: 778.1208820343018 and batch: 1550, loss is 3.6263945150375365 and perplexity is 37.577088453935545
At time: 779.4790925979614 and batch: 1600, loss is 3.7040468215942384 and perplexity is 40.61131902999872
At time: 780.8343324661255 and batch: 1650, loss is 3.6559390163421632 and perplexity is 38.70384760231276
At time: 782.1867773532867 and batch: 1700, loss is 3.6521374082565305 and perplexity is 38.55699006658847
At time: 783.5417649745941 and batch: 1750, loss is 3.6310702991485595 and perplexity is 37.75320222118041
At time: 784.8931646347046 and batch: 1800, loss is 3.5960499382019044 and perplexity is 36.45395430126372
At time: 786.2466571331024 and batch: 1850, loss is 3.625375394821167 and perplexity is 37.53881239068757
At time: 787.6022069454193 and batch: 1900, loss is 3.7233817863464354 and perplexity is 41.40417769910079
At time: 788.9552791118622 and batch: 1950, loss is 3.6722034072875975 and perplexity is 39.33848914982456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315724643441134 and perplexity of 74.86785629284499
finished 14 epochs...
Completing Train Step...
At time: 793.2617049217224 and batch: 50, loss is 3.905470333099365 and perplexity is 49.67343748063416
At time: 794.6391453742981 and batch: 100, loss is 3.871027503013611 and perplexity is 47.99167234355252
At time: 795.994879245758 and batch: 150, loss is 3.8424159193038943 and perplexity is 46.63801211784849
At time: 797.3490793704987 and batch: 200, loss is 3.8376615953445437 and perplexity is 46.416806158487084
At time: 798.7018420696259 and batch: 250, loss is 3.8350757789611816 and perplexity is 46.29693586873087
At time: 800.0530695915222 and batch: 300, loss is 3.842115640640259 and perplexity is 46.62400982029594
At time: 801.4064521789551 and batch: 350, loss is 3.8772223377227784 and perplexity is 48.289895589277435
At time: 802.76154088974 and batch: 400, loss is 3.8227908039093017 and perplexity is 45.73165848519825
At time: 804.1169836521149 and batch: 450, loss is 3.8783575439453126 and perplexity is 48.34474570644266
At time: 805.4711470603943 and batch: 500, loss is 3.8779955768585204 and perplexity is 48.32724966636394
At time: 806.823324918747 and batch: 550, loss is 3.8502858448028565 and perplexity is 47.006497874494286
At time: 808.1766285896301 and batch: 600, loss is 3.804568133354187 and perplexity is 44.90585258480902
At time: 809.5300719738007 and batch: 650, loss is 3.8269575119018553 and perplexity is 45.922606488145085
At time: 810.8876430988312 and batch: 700, loss is 3.8823162364959716 and perplexity is 48.53650700271363
At time: 812.2414968013763 and batch: 750, loss is 3.8210728216171264 and perplexity is 45.653159754750476
At time: 813.5919003486633 and batch: 800, loss is 3.8067880773544314 and perplexity is 45.00565179617531
At time: 814.947993516922 and batch: 850, loss is 3.8035302782058715 and perplexity is 44.85927099116902
At time: 816.3062269687653 and batch: 900, loss is 3.7492445039749147 and perplexity is 42.48896962354323
At time: 817.6702611446381 and batch: 950, loss is 3.864120125770569 and perplexity is 47.66131801262885
At time: 819.0261232852936 and batch: 1000, loss is 3.824689755439758 and perplexity is 45.81858319485325
At time: 820.3810122013092 and batch: 1050, loss is 3.7782029151916503 and perplexity is 43.737371302501295
At time: 821.7503407001495 and batch: 1100, loss is 3.791905598640442 and perplexity is 44.34081561751534
At time: 823.1049246788025 and batch: 1150, loss is 3.7730449867248534 and perplexity is 43.51235787044935
At time: 824.4584448337555 and batch: 1200, loss is 3.810736002922058 and perplexity is 45.18368195326045
At time: 825.8143045902252 and batch: 1250, loss is 3.7907789087295534 and perplexity is 44.290885401135945
At time: 827.1691389083862 and batch: 1300, loss is 3.7767511796951294 and perplexity is 43.673922274803225
At time: 828.5219609737396 and batch: 1350, loss is 3.648271894454956 and perplexity is 38.40823518159642
At time: 829.8746132850647 and batch: 1400, loss is 3.669779686927795 and perplexity is 39.24325910486613
At time: 831.2273044586182 and batch: 1450, loss is 3.6042033195495606 and perplexity is 36.75239227834428
At time: 832.5905578136444 and batch: 1500, loss is 3.601289248466492 and perplexity is 36.64544909047643
At time: 833.947803735733 and batch: 1550, loss is 3.6272178220748903 and perplexity is 37.6080386743218
At time: 835.3009958267212 and batch: 1600, loss is 3.7056410026550295 and perplexity is 40.67611245815587
At time: 836.6500153541565 and batch: 1650, loss is 3.6586009073257446 and perplexity is 38.80701026824576
At time: 837.9998073577881 and batch: 1700, loss is 3.6560830879211426 and perplexity is 38.70942412844922
At time: 839.3528790473938 and batch: 1750, loss is 3.635845003128052 and perplexity is 37.93389361674683
At time: 840.706515789032 and batch: 1800, loss is 3.6006901931762694 and perplexity is 36.62350301444899
At time: 842.0686502456665 and batch: 1850, loss is 3.6305972862243654 and perplexity is 37.73534869140812
At time: 843.431857585907 and batch: 1900, loss is 3.7285584831237792 and perplexity is 41.61907030941175
At time: 844.7880339622498 and batch: 1950, loss is 3.6770829010009765 and perplexity is 39.53091013703719
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314482648982558 and perplexity of 74.77492855002015
finished 15 epochs...
Completing Train Step...
At time: 849.176034450531 and batch: 50, loss is 3.9052271699905394 and perplexity is 49.66136020158418
At time: 850.5629634857178 and batch: 100, loss is 3.868667516708374 and perplexity is 47.878546194642425
At time: 851.9140496253967 and batch: 150, loss is 3.8388664817810056 and perplexity is 46.47276684501733
At time: 853.2646446228027 and batch: 200, loss is 3.833351345062256 and perplexity is 46.21716865950905
At time: 854.6160352230072 and batch: 250, loss is 3.830436520576477 and perplexity is 46.08264986921037
At time: 855.9883222579956 and batch: 300, loss is 3.8368959283828734 and perplexity is 46.381279945904495
At time: 857.3438136577606 and batch: 350, loss is 3.8714471101760863 and perplexity is 48.01181421854902
At time: 858.697459936142 and batch: 400, loss is 3.8165694999694826 and perplexity is 45.44803111892238
At time: 860.0492014884949 and batch: 450, loss is 3.8719526052474977 and perplexity is 48.036090089155564
At time: 861.3996961116791 and batch: 500, loss is 3.8718886375427246 and perplexity is 48.03301742900285
At time: 862.7616913318634 and batch: 550, loss is 3.8443107080459593 and perplexity is 46.726465071528274
At time: 864.1215877532959 and batch: 600, loss is 3.799165472984314 and perplexity is 44.66389570862119
At time: 865.4776735305786 and batch: 650, loss is 3.821956658363342 and perplexity is 45.69352753155701
At time: 866.8316075801849 and batch: 700, loss is 3.877820134162903 and perplexity is 48.31877174712694
At time: 868.190500497818 and batch: 750, loss is 3.817265110015869 and perplexity is 45.479656224052405
At time: 869.5555913448334 and batch: 800, loss is 3.803380560874939 and perplexity is 44.8525552835901
At time: 870.9170138835907 and batch: 850, loss is 3.7999891567230226 and perplexity is 44.70069978860404
At time: 872.2689356803894 and batch: 900, loss is 3.7465136098861693 and perplexity is 42.373095040182726
At time: 873.6197187900543 and batch: 950, loss is 3.861519856452942 and perplexity is 47.5375467388247
At time: 874.971474647522 and batch: 1000, loss is 3.822032585144043 and perplexity is 45.69699702571344
At time: 876.324214220047 and batch: 1050, loss is 3.7758612537384035 and perplexity is 43.6350730067888
At time: 877.6785454750061 and batch: 1100, loss is 3.7896943426132204 and perplexity is 44.24287504747504
At time: 879.0317850112915 and batch: 1150, loss is 3.77104877948761 and perplexity is 43.425584824065176
At time: 880.3844623565674 and batch: 1200, loss is 3.8085914039611817 and perplexity is 45.08688490841573
At time: 881.7366874217987 and batch: 1250, loss is 3.7890838861465452 and perplexity is 44.215874940331496
At time: 883.0883612632751 and batch: 1300, loss is 3.775295948982239 and perplexity is 43.61041286338737
At time: 884.4417707920074 and batch: 1350, loss is 3.6471109867095945 and perplexity is 38.363672635395716
At time: 885.8014392852783 and batch: 1400, loss is 3.6689490509033202 and perplexity is 39.21067577445326
At time: 887.1531383991241 and batch: 1450, loss is 3.603944616317749 and perplexity is 36.742885545449354
At time: 888.5042707920074 and batch: 1500, loss is 3.601482925415039 and perplexity is 36.65254715657812
At time: 889.8550004959106 and batch: 1550, loss is 3.6280222940444946 and perplexity is 37.638305460025116
At time: 891.2073380947113 and batch: 1600, loss is 3.706813430786133 and perplexity is 40.723830244036975
At time: 892.5620315074921 and batch: 1650, loss is 3.660170831680298 and perplexity is 38.86798218692038
At time: 893.917986869812 and batch: 1700, loss is 3.6580063009262087 and perplexity is 38.7839422304745
At time: 895.271080493927 and batch: 1750, loss is 3.638035840988159 and perplexity is 38.017091730574855
At time: 896.62229180336 and batch: 1800, loss is 3.6027653646469116 and perplexity is 36.69958197420115
At time: 897.9732058048248 and batch: 1850, loss is 3.632825050354004 and perplexity is 37.81950785622016
At time: 899.3259932994843 and batch: 1900, loss is 3.7304966402053834 and perplexity is 41.69981282582625
At time: 900.6848602294922 and batch: 1950, loss is 3.678517608642578 and perplexity is 39.587666140290565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3139651276344475 and perplexity of 74.73624093988761
finished 16 epochs...
Completing Train Step...
At time: 904.9690597057343 and batch: 50, loss is 3.903675746917725 and perplexity is 49.58437415594539
At time: 906.3503887653351 and batch: 100, loss is 3.86627402305603 and perplexity is 47.76408623248182
At time: 907.7051842212677 and batch: 150, loss is 3.83599684715271 and perplexity is 46.339598148142954
At time: 909.0609655380249 and batch: 200, loss is 3.830167088508606 and perplexity is 46.070235398066544
At time: 910.4129211902618 and batch: 250, loss is 3.827042784690857 and perplexity is 45.92652260384523
At time: 911.763528585434 and batch: 300, loss is 3.833335757255554 and perplexity is 46.21644824083256
At time: 913.1147663593292 and batch: 350, loss is 3.8678386116027834 and perplexity is 47.83887586699339
At time: 914.4671392440796 and batch: 400, loss is 3.8128473234176634 and perplexity is 45.27917996501512
At time: 915.821888923645 and batch: 450, loss is 3.8681512117385863 and perplexity is 47.85383264370949
At time: 917.1776006221771 and batch: 500, loss is 3.868210110664368 and perplexity is 47.85665126605283
At time: 918.5291006565094 and batch: 550, loss is 3.840765733718872 and perplexity is 46.561114207898925
At time: 919.8791828155518 and batch: 600, loss is 3.7958603620529177 and perplexity is 44.51652025893856
At time: 921.2303867340088 and batch: 650, loss is 3.818733377456665 and perplexity is 45.546481569238814
At time: 922.5837836265564 and batch: 700, loss is 3.874839153289795 and perplexity is 48.17494888583976
At time: 923.9580430984497 and batch: 750, loss is 3.814604616165161 and perplexity is 45.35881869336595
At time: 925.3110706806183 and batch: 800, loss is 3.8008249521255495 and perplexity is 44.73807604525305
At time: 926.6636154651642 and batch: 850, loss is 3.797272081375122 and perplexity is 44.57940947125892
At time: 928.0138330459595 and batch: 900, loss is 3.7441844606399535 and perplexity is 42.27451662429671
At time: 929.3643498420715 and batch: 950, loss is 3.8591768407821654 and perplexity is 47.42629590398476
At time: 930.719108581543 and batch: 1000, loss is 3.8197063112258913 and perplexity is 45.590816843372345
At time: 932.0732553005219 and batch: 1050, loss is 3.773767075538635 and perplexity is 43.54378900399813
At time: 933.4254801273346 and batch: 1100, loss is 3.7876656675338745 and perplexity is 44.153211609170015
At time: 934.7757320404053 and batch: 1150, loss is 3.769199752807617 and perplexity is 43.34536394725753
At time: 936.1250112056732 and batch: 1200, loss is 3.8067685174942016 and perplexity is 45.004771500525884
At time: 937.4774296283722 and batch: 1250, loss is 3.7875941801071167 and perplexity is 44.15005532250773
At time: 938.8316793441772 and batch: 1300, loss is 3.77404203414917 and perplexity is 43.55576338987489
At time: 940.1862072944641 and batch: 1350, loss is 3.646168737411499 and perplexity is 38.32754151671645
At time: 941.536949634552 and batch: 1400, loss is 3.6682284927368163 and perplexity is 39.18243237853663
At time: 942.8865814208984 and batch: 1450, loss is 3.60360830783844 and perplexity is 36.730530679125735
At time: 944.2368907928467 and batch: 1500, loss is 3.6014624071121215 and perplexity is 36.651795116228186
At time: 945.5896689891815 and batch: 1550, loss is 3.6283852672576904 and perplexity is 37.65196963641217
At time: 946.9507129192352 and batch: 1600, loss is 3.707400712966919 and perplexity is 40.7477536480795
At time: 948.3087494373322 and batch: 1650, loss is 3.660927095413208 and perplexity is 38.89738774999869
At time: 949.6600728034973 and batch: 1700, loss is 3.658888854980469 and perplexity is 38.818186264813136
At time: 951.0100059509277 and batch: 1750, loss is 3.639050841331482 and perplexity is 38.05569868145324
At time: 952.3616456985474 and batch: 1800, loss is 3.6037198972702025 and perplexity is 36.73462964686904
At time: 953.718517780304 and batch: 1850, loss is 3.633834581375122 and perplexity is 37.857707101021504
At time: 955.076224565506 and batch: 1900, loss is 3.731261620521545 and perplexity is 41.731724566196036
At time: 956.4278883934021 and batch: 1950, loss is 3.678878664970398 and perplexity is 39.6019620983219
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313719567587209 and perplexity of 74.71789095813538
finished 17 epochs...
Completing Train Step...
At time: 960.7995324134827 and batch: 50, loss is 3.9018719482421873 and perplexity is 49.49501454511841
At time: 962.1614496707916 and batch: 100, loss is 3.86405864238739 and perplexity is 47.65838772363362
At time: 963.5159273147583 and batch: 150, loss is 3.8335470390319824 and perplexity is 46.22621396574061
At time: 964.8662252426147 and batch: 200, loss is 3.8275292682647706 and perplexity is 45.94887053820972
At time: 966.2181758880615 and batch: 250, loss is 3.824251608848572 and perplexity is 45.79851233612369
At time: 967.5690052509308 and batch: 300, loss is 3.8304497623443603 and perplexity is 46.083260089003566
At time: 968.9238150119781 and batch: 350, loss is 3.865005431175232 and perplexity is 47.703531518224
At time: 970.2859587669373 and batch: 400, loss is 3.809990439414978 and perplexity is 45.15000720377264
At time: 971.6485116481781 and batch: 450, loss is 3.8652564430236818 and perplexity is 47.715507172800685
At time: 973.0066030025482 and batch: 500, loss is 3.8653743648529053 and perplexity is 47.72113420445724
At time: 974.3576397895813 and batch: 550, loss is 3.8380348443984986 and perplexity is 46.434134421151
At time: 975.7087152004242 and batch: 600, loss is 3.7933054828643797 and perplexity is 44.40293109286799
At time: 977.0701770782471 and batch: 650, loss is 3.8161728763580323 and perplexity is 45.430008930935585
At time: 978.4396967887878 and batch: 700, loss is 3.8724431467056273 and perplexity is 48.05965956326021
At time: 979.7967247962952 and batch: 750, loss is 3.81240159034729 and perplexity is 45.25900203442488
At time: 981.1486430168152 and batch: 800, loss is 3.7986495208740236 and perplexity is 44.64085722126572
At time: 982.4995212554932 and batch: 850, loss is 3.794974913597107 and perplexity is 44.47712062056588
At time: 983.8525586128235 and batch: 900, loss is 3.74210901260376 and perplexity is 42.186869047245324
At time: 985.2074587345123 and batch: 950, loss is 3.8571100091934203 and perplexity is 47.32837496537595
At time: 986.5624401569366 and batch: 1000, loss is 3.8176554918289183 and perplexity is 45.49741412066041
At time: 987.9133992195129 and batch: 1050, loss is 3.7719220781326293 and perplexity is 43.463524892545145
At time: 989.2648606300354 and batch: 1100, loss is 3.7858788633346556 and perplexity is 44.07438890659696
At time: 990.6521275043488 and batch: 1150, loss is 3.767541904449463 and perplexity is 43.273563440425235
At time: 992.005722284317 and batch: 1200, loss is 3.8051990938186644 and perplexity is 44.93419534305334
At time: 993.3615121841431 and batch: 1250, loss is 3.7862665271759033 and perplexity is 44.09147826575042
At time: 994.7161355018616 and batch: 1300, loss is 3.772921643257141 and perplexity is 43.5069912363177
At time: 996.0663499832153 and batch: 1350, loss is 3.6452890968322755 and perplexity is 38.2938418798535
At time: 997.4168519973755 and batch: 1400, loss is 3.6675021648406982 and perplexity is 39.153983417749956
At time: 998.767539024353 and batch: 1450, loss is 3.603134651184082 and perplexity is 36.71313713845979
At time: 1000.1212539672852 and batch: 1500, loss is 3.601220736503601 and perplexity is 36.642938524831095
At time: 1001.4759521484375 and batch: 1550, loss is 3.628401584625244 and perplexity is 37.65258402245241
At time: 1002.8291954994202 and batch: 1600, loss is 3.7075828981399535 and perplexity is 40.755177960907965
At time: 1004.1804111003876 and batch: 1650, loss is 3.6611883068084716 and perplexity is 38.907549518052
At time: 1005.5311505794525 and batch: 1700, loss is 3.6592169046401977 and perplexity is 38.830922646577235
At time: 1006.8823375701904 and batch: 1750, loss is 3.639472665786743 and perplexity is 38.07175489203218
At time: 1008.237562417984 and batch: 1800, loss is 3.604115700721741 and perplexity is 36.7491722178843
At time: 1009.5931115150452 and batch: 1850, loss is 3.634264659881592 and perplexity is 37.873992388875
At time: 1010.9444842338562 and batch: 1900, loss is 3.731508870124817 and perplexity is 41.74204399422355
At time: 1012.2985637187958 and batch: 1950, loss is 3.678837194442749 and perplexity is 39.600319818111096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313611407612646 and perplexity of 74.70980990998079
finished 18 epochs...
Completing Train Step...
At time: 1016.6316237449646 and batch: 50, loss is 3.9000723600387572 and perplexity is 49.40602399800027
At time: 1017.9840714931488 and batch: 100, loss is 3.8620178794860838 and perplexity is 47.561227428314645
At time: 1019.3360629081726 and batch: 150, loss is 3.8313736724853515 and perplexity is 46.125856554953096
At time: 1020.6938581466675 and batch: 200, loss is 3.8252117252349853 and perplexity is 45.84250535412021
At time: 1022.050060749054 and batch: 250, loss is 3.8218147945404053 and perplexity is 45.68704573283515
At time: 1023.4072556495667 and batch: 300, loss is 3.8279202222824096 and perplexity is 45.96683794573884
At time: 1024.7803497314453 and batch: 350, loss is 3.8625390195846556 and perplexity is 47.5860199506925
At time: 1026.1309292316437 and batch: 400, loss is 3.8075222158432007 and perplexity is 45.03870430844724
At time: 1027.4813883304596 and batch: 450, loss is 3.862772307395935 and perplexity is 47.59712248412681
At time: 1028.831967830658 and batch: 500, loss is 3.862923150062561 and perplexity is 47.60430270253406
At time: 1030.1833727359772 and batch: 550, loss is 3.835663356781006 and perplexity is 46.32414691489388
At time: 1031.5379230976105 and batch: 600, loss is 3.7911026096343994 and perplexity is 44.30522472151701
At time: 1032.891191482544 and batch: 650, loss is 3.813945074081421 and perplexity is 45.3289125068473
At time: 1034.2472496032715 and batch: 700, loss is 3.8703494548797606 and perplexity is 47.95914270925482
At time: 1035.602267742157 and batch: 750, loss is 3.810445351600647 and perplexity is 45.17055116472747
At time: 1036.9583899974823 and batch: 800, loss is 3.79670063495636 and perplexity is 44.55394200470534
At time: 1038.311604499817 and batch: 850, loss is 3.79294068813324 and perplexity is 44.386736091663295
At time: 1039.6655132770538 and batch: 900, loss is 3.740221757888794 and perplexity is 42.10732676161207
At time: 1041.0153541564941 and batch: 950, loss is 3.8552613162994387 and perplexity is 47.240960161353485
At time: 1042.3727111816406 and batch: 1000, loss is 3.8158077573776246 and perplexity is 45.413424600206014
At time: 1043.7359483242035 and batch: 1050, loss is 3.7702635431289675 and perplexity is 43.39149886048641
At time: 1045.0881667137146 and batch: 1100, loss is 3.78427348613739 and perplexity is 44.00368965233228
At time: 1046.4454329013824 and batch: 1150, loss is 3.7660315465927123 and perplexity is 43.20825420646589
At time: 1047.796819448471 and batch: 1200, loss is 3.8037929725646973 and perplexity is 44.87105681656658
At time: 1049.1483616828918 and batch: 1250, loss is 3.7850406694412233 and perplexity is 44.03746150128351
At time: 1050.5003588199615 and batch: 1300, loss is 3.771875433921814 and perplexity is 43.46149761800797
At time: 1051.8525290489197 and batch: 1350, loss is 3.644420371055603 and perplexity is 38.2605894780252
At time: 1053.2044296264648 and batch: 1400, loss is 3.666745076179504 and perplexity is 39.12435159923607
At time: 1054.5571599006653 and batch: 1450, loss is 3.602549753189087 and perplexity is 36.69166997681943
At time: 1055.9085445404053 and batch: 1500, loss is 3.600815119743347 and perplexity is 36.628078548751894
At time: 1057.2576985359192 and batch: 1550, loss is 3.6281831407547 and perplexity is 37.644359944544966
At time: 1058.6078906059265 and batch: 1600, loss is 3.7075018787384035 and perplexity is 40.75187613453732
At time: 1059.9588558673859 and batch: 1650, loss is 3.661146807670593 and perplexity is 38.90593492179244
At time: 1061.309674501419 and batch: 1700, loss is 3.6592271947860717 and perplexity is 38.831322224491544
At time: 1062.6611890792847 and batch: 1750, loss is 3.6395631551742555 and perplexity is 38.07520013769062
At time: 1064.0119090080261 and batch: 1800, loss is 3.604199266433716 and perplexity is 36.75224331694269
At time: 1065.363958120346 and batch: 1850, loss is 3.6343798637390137 and perplexity is 37.87835587023427
At time: 1066.7150313854218 and batch: 1900, loss is 3.7314876747131347 and perplexity is 41.74115926379278
At time: 1068.0652952194214 and batch: 1950, loss is 3.6786113119125368 and perplexity is 39.59137580785923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313581031976744 and perplexity of 74.70754058646293
finished 19 epochs...
Completing Train Step...
At time: 1072.3730773925781 and batch: 50, loss is 3.898330373764038 and perplexity is 49.32003430048848
At time: 1073.7231905460358 and batch: 100, loss is 3.8601128911972045 and perplexity is 47.470710091665914
At time: 1075.0741307735443 and batch: 150, loss is 3.8293855237960814 and perplexity is 46.03424259496628
At time: 1076.4256377220154 and batch: 200, loss is 3.823101077079773 and perplexity is 45.745849993375636
At time: 1077.7763538360596 and batch: 250, loss is 3.8196094846725464 and perplexity is 45.58640265542197
At time: 1079.1233236789703 and batch: 300, loss is 3.8256149530410766 and perplexity is 45.86099405430838
At time: 1080.4743084907532 and batch: 350, loss is 3.8602915954589845 and perplexity is 47.4791940679078
At time: 1081.8267126083374 and batch: 400, loss is 3.8052741956710814 and perplexity is 44.93757011108455
At time: 1083.1773438453674 and batch: 450, loss is 3.8605230951309206 and perplexity is 47.4901867581113
At time: 1084.5281155109406 and batch: 500, loss is 3.8606947803497316 and perplexity is 47.49834082116226
At time: 1085.8763265609741 and batch: 550, loss is 3.8334962797164915 and perplexity is 46.22386761431208
At time: 1087.2250237464905 and batch: 600, loss is 3.789106125831604 and perplexity is 44.216858298399515
At time: 1088.5764918327332 and batch: 650, loss is 3.811924362182617 and perplexity is 45.23740831692397
At time: 1089.9266262054443 and batch: 700, loss is 3.8684447765350343 and perplexity is 47.86788290657917
At time: 1091.2802612781525 and batch: 750, loss is 3.8086495351791383 and perplexity is 45.08950594013047
At time: 1092.649269580841 and batch: 800, loss is 3.794905743598938 and perplexity is 44.47404424461167
At time: 1094.007083415985 and batch: 850, loss is 3.7910859060287474 and perplexity is 44.30448467069571
At time: 1095.3633613586426 and batch: 900, loss is 3.73847589969635 and perplexity is 42.033877474899114
At time: 1096.7129964828491 and batch: 950, loss is 3.8535711574554443 and perplexity is 47.1611828718749
At time: 1098.0688183307648 and batch: 1000, loss is 3.8141047763824463 and perplexity is 45.33615221656139
At time: 1099.4279816150665 and batch: 1050, loss is 3.768735022544861 and perplexity is 43.32522472489658
At time: 1100.7856209278107 and batch: 1100, loss is 3.7827911281585695 and perplexity is 43.9385087545262
At time: 1102.1425335407257 and batch: 1150, loss is 3.764623689651489 and perplexity is 43.14746596647648
At time: 1103.5010182857513 and batch: 1200, loss is 3.802486639022827 and perplexity is 44.8124785197153
At time: 1104.8587787151337 and batch: 1250, loss is 3.7838742780685424 and perplexity is 43.98612653026726
At time: 1106.2110075950623 and batch: 1300, loss is 3.7708670473098755 and perplexity is 43.41769371502164
At time: 1107.5626225471497 and batch: 1350, loss is 3.6435457563400266 and perplexity is 38.227140832911935
At time: 1108.9135870933533 and batch: 1400, loss is 3.6659571647644045 and perplexity is 39.09353721709852
At time: 1110.2632057666779 and batch: 1450, loss is 3.601885256767273 and perplexity is 36.6672965923197
At time: 1111.612027645111 and batch: 1500, loss is 3.600295934677124 and perplexity is 36.60906673311737
At time: 1112.960899591446 and batch: 1550, loss is 3.6278092002868654 and perplexity is 37.6302858265811
At time: 1114.312978029251 and batch: 1600, loss is 3.7072489786148073 and perplexity is 40.741571283130135
At time: 1115.664835691452 and batch: 1650, loss is 3.660914673805237 and perplexity is 38.89690458489781
At time: 1117.0158832073212 and batch: 1700, loss is 3.659043674468994 and perplexity is 38.82419654179813
At time: 1118.3680424690247 and batch: 1750, loss is 3.639453420639038 and perplexity is 38.07102220253627
At time: 1119.720443725586 and batch: 1800, loss is 3.6040939903259277 and perplexity is 36.748374387470285
At time: 1121.069904088974 and batch: 1850, loss is 3.6343068933486937 and perplexity is 37.87559197266432
At time: 1122.4205627441406 and batch: 1900, loss is 3.7313102149963377 and perplexity is 41.73375254670744
At time: 1123.771299123764 and batch: 1950, loss is 3.6782847929000853 and perplexity is 39.5784505812098
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313606581577035 and perplexity of 74.70944935864767
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa20428cb38>
ELAPSED
5830.9825694561005


RESULTS SO FAR:
[{'best_accuracy': -74.4178468006303, 'params': {'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}}, {'best_accuracy': -77.53052041197337, 'params': {'dropout': 0.9649993788704626, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.2039606990300309, 'data': 'wikitext'}}, {'best_accuracy': -74.84239854569978, 'params': {'dropout': 0.18248612094762118, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.031083902810406072, 'data': 'wikitext'}}, {'best_accuracy': -75.19043835982198, 'params': {'dropout': 0.6426102732804025, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.040188596927537734, 'data': 'wikitext'}}, {'best_accuracy': -74.70754058646293, 'params': {'dropout': 0.28425270504382827, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.42033359040349494, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'dropout': 0.3924988781453342, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.6338794062420806, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.2481799125671387 and batch: 50, loss is 7.705435037612915 and perplexity is 2220.383122352802
At time: 3.8550305366516113 and batch: 100, loss is 7.029077196121216 and perplexity is 1128.988294556566
At time: 5.465610980987549 and batch: 150, loss is 6.64571478843689 and perplexity is 769.4798664174443
At time: 7.0750038623809814 and batch: 200, loss is 6.414076347351074 and perplexity is 610.3767242930412
At time: 8.68137240409851 and batch: 250, loss is 6.280127325057983 and perplexity is 533.8566328251203
At time: 10.289095163345337 and batch: 300, loss is 6.18600058555603 and perplexity is 485.89890388089
At time: 11.89659070968628 and batch: 350, loss is 6.110208511352539 and perplexity is 450.43262569258616
At time: 13.502599239349365 and batch: 400, loss is 6.048215665817261 and perplexity is 423.3569454223336
At time: 15.10632848739624 and batch: 450, loss is 5.9401500797271725 and perplexity is 379.99195434773713
At time: 16.712885856628418 and batch: 500, loss is 5.905041761398316 and perplexity is 366.88254699572707
At time: 18.32563281059265 and batch: 550, loss is 5.8464937496185305 and perplexity is 346.01902172088955
At time: 19.933422088623047 and batch: 600, loss is 5.856927146911621 and perplexity is 349.64807439944667
At time: 21.545806646347046 and batch: 650, loss is 5.920448942184448 and perplexity is 372.5789427397608
At time: 23.153367042541504 and batch: 700, loss is 5.828851099014282 and perplexity is 339.9678651960778
At time: 24.766273260116577 and batch: 750, loss is 5.754767217636108 and perplexity is 315.6920514282464
At time: 26.37780499458313 and batch: 800, loss is 5.754981021881104 and perplexity is 315.75955494496515
At time: 27.98402452468872 and batch: 850, loss is 5.776705722808838 and perplexity is 322.69439273313935
At time: 29.59002685546875 and batch: 900, loss is 5.757178192138672 and perplexity is 316.4540951797954
At time: 31.19902801513672 and batch: 950, loss is 5.769488954544068 and perplexity is 320.3739651455152
At time: 32.81209588050842 and batch: 1000, loss is 5.739711484909058 and perplexity is 310.97467714997435
At time: 34.42222547531128 and batch: 1050, loss is 5.642090253829956 and perplexity is 282.05166230718044
At time: 36.029568910598755 and batch: 1100, loss is 5.7107346248626705 and perplexity is 302.09291175075833
At time: 37.643171310424805 and batch: 1150, loss is 5.614414911270142 and perplexity is 274.3528114887767
At time: 39.2612829208374 and batch: 1200, loss is 5.678933391571045 and perplexity is 292.63713416958575
At time: 40.88329339027405 and batch: 1250, loss is 5.626421012878418 and perplexity is 277.6665720877753
At time: 42.50351643562317 and batch: 1300, loss is 5.6368435287475585 and perplexity is 280.5756901719268
At time: 44.119877338409424 and batch: 1350, loss is 5.588136672973633 and perplexity is 267.2372051963412
At time: 45.73616981506348 and batch: 1400, loss is 5.592073564529419 and perplexity is 268.29136278337984
At time: 47.35609483718872 and batch: 1450, loss is 5.565295639038086 and perplexity is 261.20241392642794
At time: 48.97892498970032 and batch: 1500, loss is 5.522854490280151 and perplexity is 250.3486359727918
At time: 50.599589109420776 and batch: 1550, loss is 5.503894538879394 and perplexity is 245.64675259349764
At time: 52.21759629249573 and batch: 1600, loss is 5.523572845458984 and perplexity is 250.528539821651
At time: 53.83378791809082 and batch: 1650, loss is 5.5116636848449705 and perplexity is 247.5626508801891
At time: 55.45401120185852 and batch: 1700, loss is 5.522742586135864 and perplexity is 250.32062249035147
At time: 57.076929569244385 and batch: 1750, loss is 5.519236879348755 and perplexity is 249.44460820692612
At time: 58.693504095077515 and batch: 1800, loss is 5.513214054107666 and perplexity is 247.94676208486894
At time: 60.30928158760071 and batch: 1850, loss is 5.488389797210694 and perplexity is 241.86743751579743
At time: 61.92543268203735 and batch: 1900, loss is 5.504713077545166 and perplexity is 245.84790627341778
At time: 63.54473686218262 and batch: 1950, loss is 5.43280442237854 and perplexity is 228.78997028515744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.038606013808139 and perplexity of 154.25483597104846
finished 1 epochs...
Completing Train Step...
At time: 68.03834009170532 and batch: 50, loss is 5.306575326919556 and perplexity is 201.65843027549118
At time: 69.39357447624207 and batch: 100, loss is 5.231993141174317 and perplexity is 187.16547922219874
At time: 70.74766397476196 and batch: 150, loss is 5.1414814376831055 and perplexity is 170.96886051748518
At time: 72.1000497341156 and batch: 200, loss is 5.10173526763916 and perplexity is 164.3067762982477
At time: 73.44927644729614 and batch: 250, loss is 5.120181846618652 and perplexity is 167.36580175915742
At time: 74.79864287376404 and batch: 300, loss is 5.125946474075318 and perplexity is 168.33338946713405
At time: 76.16733241081238 and batch: 350, loss is 5.111620149612427 and perplexity is 165.93898318523648
At time: 77.51813316345215 and batch: 400, loss is 5.059865589141846 and perplexity is 157.5693358703043
At time: 78.87176632881165 and batch: 450, loss is 5.014872322082519 and perplexity is 150.63690253203845
At time: 80.22585773468018 and batch: 500, loss is 5.007734718322754 and perplexity is 149.565544024815
At time: 81.57681226730347 and batch: 550, loss is 4.962880725860596 and perplexity is 143.0051617640564
At time: 82.92724537849426 and batch: 600, loss is 4.949757289886475 and perplexity is 141.1407034878016
At time: 84.27707719802856 and batch: 650, loss is 5.010637807846069 and perplexity is 150.00037706294594
At time: 85.63541865348816 and batch: 700, loss is 5.008115797042847 and perplexity is 149.62255113230987
At time: 86.99851131439209 and batch: 750, loss is 4.948829269409179 and perplexity is 141.00978278272862
At time: 88.36195421218872 and batch: 800, loss is 4.949195184707642 and perplexity is 141.06138986081555
At time: 89.72034740447998 and batch: 850, loss is 4.946562299728393 and perplexity is 140.6904799421407
At time: 91.07735538482666 and batch: 900, loss is 4.9378378963470455 and perplexity is 139.46837824898333
At time: 92.43536424636841 and batch: 950, loss is 4.986906309127807 and perplexity is 146.48255005758872
At time: 93.79653120040894 and batch: 1000, loss is 4.94370512008667 and perplexity is 140.2890756821767
At time: 95.16004920005798 and batch: 1050, loss is 4.865062055587768 and perplexity is 129.67898566780084
At time: 96.51985597610474 and batch: 1100, loss is 4.93319863319397 and perplexity is 138.82284629486026
At time: 97.87673306465149 and batch: 1150, loss is 4.847485704421997 and perplexity is 127.41961617760039
At time: 99.23294067382812 and batch: 1200, loss is 4.92908465385437 and perplexity is 138.25290514025218
At time: 100.58995294570923 and batch: 1250, loss is 4.887956943511963 and perplexity is 132.6822196797521
At time: 101.95512557029724 and batch: 1300, loss is 4.908631057739258 and perplexity is 135.4538589182129
At time: 103.31935048103333 and batch: 1350, loss is 4.805161247253418 and perplexity is 122.13918404137804
At time: 104.67713379859924 and batch: 1400, loss is 4.8144411373138425 and perplexity is 123.27789763803494
At time: 106.026451587677 and batch: 1450, loss is 4.769089126586914 and perplexity is 117.81188136165812
At time: 107.37566709518433 and batch: 1500, loss is 4.73230694770813 and perplexity is 113.55723099845719
At time: 108.72896599769592 and batch: 1550, loss is 4.73338981628418 and perplexity is 113.68026515837886
At time: 110.08369946479797 and batch: 1600, loss is 4.787305459976197 and perplexity is 119.97764814524582
At time: 111.43692183494568 and batch: 1650, loss is 4.761844491958618 and perplexity is 116.96146153627983
At time: 112.78866338729858 and batch: 1700, loss is 4.775913791656494 and perplexity is 118.61865785146334
At time: 114.14072608947754 and batch: 1750, loss is 4.770252113342285 and perplexity is 117.94897472273661
At time: 115.49521470069885 and batch: 1800, loss is 4.724791259765625 and perplexity is 112.70696943922044
At time: 116.84800791740417 and batch: 1850, loss is 4.745219869613647 and perplexity is 115.03309500496641
At time: 118.2032482624054 and batch: 1900, loss is 4.832418298721313 and perplexity is 125.51412458353552
At time: 119.55967164039612 and batch: 1950, loss is 4.751189432144165 and perplexity is 115.72184598435618
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.611761616551599 and perplexity of 100.66132018502994
finished 2 epochs...
Completing Train Step...
At time: 123.94231390953064 and batch: 50, loss is 4.7281640529632565 and perplexity is 113.08774852265188
At time: 125.3181266784668 and batch: 100, loss is 4.663808717727661 and perplexity is 106.03918734509087
At time: 126.67382216453552 and batch: 150, loss is 4.602546005249024 and perplexity is 99.73792594133562
At time: 128.02617835998535 and batch: 200, loss is 4.5978462028503415 and perplexity is 99.27027718691653
At time: 129.38074779510498 and batch: 250, loss is 4.616369276046753 and perplexity is 101.12620346222234
At time: 130.74893617630005 and batch: 300, loss is 4.633637437820434 and perplexity is 102.88763164687025
At time: 132.0975422859192 and batch: 350, loss is 4.636344509124756 and perplexity is 103.16653313485725
At time: 133.4448368549347 and batch: 400, loss is 4.579986724853516 and perplexity is 97.513099697779
At time: 134.79102039337158 and batch: 450, loss is 4.573981695175171 and perplexity is 96.92928530582134
At time: 136.1394386291504 and batch: 500, loss is 4.579619131088257 and perplexity is 97.47726107772922
At time: 137.49813032150269 and batch: 550, loss is 4.5472462940216065 and perplexity is 94.37217695117084
At time: 138.85536098480225 and batch: 600, loss is 4.530067090988159 and perplexity is 92.76478455440207
At time: 140.20722818374634 and batch: 650, loss is 4.582853517532349 and perplexity is 97.79305062698866
At time: 141.5579776763916 and batch: 700, loss is 4.615169458389282 and perplexity is 101.00494321731364
At time: 142.9092869758606 and batch: 750, loss is 4.559128112792969 and perplexity is 95.5001781369163
At time: 144.28056621551514 and batch: 800, loss is 4.56358832359314 and perplexity is 95.92708039217152
At time: 145.6365180015564 and batch: 850, loss is 4.556675119400024 and perplexity is 95.26620391685138
At time: 146.99135494232178 and batch: 900, loss is 4.532948598861695 and perplexity is 93.03247249872234
At time: 148.34169483184814 and batch: 950, loss is 4.601466636657715 and perplexity is 99.63033003497932
At time: 149.69292044639587 and batch: 1000, loss is 4.573201923370362 and perplexity is 96.8537320430599
At time: 151.04377555847168 and batch: 1050, loss is 4.512802572250366 and perplexity is 91.17699087851973
At time: 152.40230655670166 and batch: 1100, loss is 4.555866832733154 and perplexity is 95.18923262604675
At time: 153.76572155952454 and batch: 1150, loss is 4.50560564994812 and perplexity is 90.52315279252986
At time: 155.1260268688202 and batch: 1200, loss is 4.571989488601685 and perplexity is 96.73637436949299
At time: 156.48061060905457 and batch: 1250, loss is 4.559701452255249 and perplexity is 95.55494785701757
At time: 157.83229851722717 and batch: 1300, loss is 4.563760309219361 and perplexity is 95.94357988996184
At time: 159.1842634677887 and batch: 1350, loss is 4.447767705917358 and perplexity is 85.43601266851935
At time: 160.5407521724701 and batch: 1400, loss is 4.461502351760864 and perplexity is 86.61754141059362
At time: 161.89953327178955 and batch: 1450, loss is 4.417097463607788 and perplexity is 82.85544505898459
At time: 163.25054168701172 and batch: 1500, loss is 4.393359107971191 and perplexity is 80.91175432189192
At time: 164.60155129432678 and batch: 1550, loss is 4.406312370300293 and perplexity is 81.96664287553824
At time: 165.95382857322693 and batch: 1600, loss is 4.475286645889282 and perplexity is 87.81976997826776
At time: 167.30455374717712 and batch: 1650, loss is 4.4407639312744145 and perplexity is 84.83972864630577
At time: 168.65992140769958 and batch: 1700, loss is 4.4542872333526615 and perplexity is 85.99483474564886
At time: 170.01534247398376 and batch: 1750, loss is 4.455094995498658 and perplexity is 86.06432618040434
At time: 171.36692118644714 and batch: 1800, loss is 4.406314163208008 and perplexity is 81.96678983429635
At time: 172.71749019622803 and batch: 1850, loss is 4.435336723327636 and perplexity is 84.3805329990446
At time: 174.0674924850464 and batch: 1900, loss is 4.540656366348267 and perplexity is 93.7523157940154
At time: 175.41949892044067 and batch: 1950, loss is 4.461291074752808 and perplexity is 86.5992430486788
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.498898528343023 and perplexity of 89.91803456789208
finished 3 epochs...
Completing Train Step...
At time: 179.7296690940857 and batch: 50, loss is 4.444527492523194 and perplexity is 85.15962976752724
At time: 181.09905433654785 and batch: 100, loss is 4.389144878387452 and perplexity is 80.57149109042628
At time: 182.4560558795929 and batch: 150, loss is 4.333619556427002 and perplexity is 76.21966928071126
At time: 183.8099660873413 and batch: 200, loss is 4.344383506774903 and perplexity is 77.0445254074272
At time: 185.16678643226624 and batch: 250, loss is 4.346928510665894 and perplexity is 77.24085374659326
At time: 186.5205204486847 and batch: 300, loss is 4.369726753234863 and perplexity is 79.02203623347785
At time: 187.87312078475952 and batch: 350, loss is 4.375452299118042 and perplexity is 79.47577824853582
At time: 189.22808241844177 and batch: 400, loss is 4.319251708984375 and perplexity is 75.13238636228468
At time: 190.57927775382996 and batch: 450, loss is 4.330679206848145 and perplexity is 75.99588597005214
At time: 191.93413090705872 and batch: 500, loss is 4.337015161514282 and perplexity is 76.47892108674675
At time: 193.28788471221924 and batch: 550, loss is 4.305583896636963 and perplexity is 74.11247684751632
At time: 194.64078068733215 and batch: 600, loss is 4.292456603050232 and perplexity is 73.145938501734
At time: 195.9923870563507 and batch: 650, loss is 4.34233003616333 and perplexity is 76.88647906601585
At time: 197.34340119361877 and batch: 700, loss is 4.381603002548218 and perplexity is 79.96611660750042
At time: 198.69796228408813 and batch: 750, loss is 4.329598636627197 and perplexity is 75.91381143039615
At time: 200.05420565605164 and batch: 800, loss is 4.332725830078125 and perplexity is 76.15158018501403
At time: 201.4111430644989 and batch: 850, loss is 4.325858287811279 and perplexity is 75.6303976593003
At time: 202.76523566246033 and batch: 900, loss is 4.304555325508118 and perplexity is 74.03628608407075
At time: 204.1197624206543 and batch: 950, loss is 4.377627601623535 and perplexity is 79.64885028185256
At time: 205.4709804058075 and batch: 1000, loss is 4.351147222518921 and perplexity is 77.56739896762114
At time: 206.82913041114807 and batch: 1050, loss is 4.300631456375122 and perplexity is 73.7463466006888
At time: 208.185528755188 and batch: 1100, loss is 4.329191627502442 and perplexity is 75.88292010340146
At time: 209.53799057006836 and batch: 1150, loss is 4.294190063476562 and perplexity is 73.27284405257063
At time: 210.88982462882996 and batch: 1200, loss is 4.362221188545227 and perplexity is 78.43115146443124
At time: 212.28153777122498 and batch: 1250, loss is 4.352196912765503 and perplexity is 77.64886345853088
At time: 213.63957333564758 and batch: 1300, loss is 4.34907374382019 and perplexity is 77.40673124625816
At time: 214.99504923820496 and batch: 1350, loss is 4.229609971046448 and perplexity is 68.69043568973271
At time: 216.3481593132019 and batch: 1400, loss is 4.246845607757568 and perplexity is 69.88462079248833
At time: 217.69868421554565 and batch: 1450, loss is 4.202649993896484 and perplexity is 66.86328376943406
At time: 219.0476315021515 and batch: 1500, loss is 4.1897979164123536 and perplexity is 66.0094501859674
At time: 220.39877271652222 and batch: 1550, loss is 4.2061748123168945 and perplexity is 67.09938055842348
At time: 221.75382733345032 and batch: 1600, loss is 4.277694230079651 and perplexity is 72.07406206206787
At time: 223.109050989151 and batch: 1650, loss is 4.237021884918213 and perplexity is 69.20145475807668
At time: 224.461181640625 and batch: 1700, loss is 4.253461627960205 and perplexity is 70.34851171926923
At time: 225.81144738197327 and batch: 1750, loss is 4.253764934539795 and perplexity is 70.36985212191671
At time: 227.16330790519714 and batch: 1800, loss is 4.201587958335876 and perplexity is 66.79231027922816
At time: 228.514817237854 and batch: 1850, loss is 4.235607056617737 and perplexity is 69.10361581042754
At time: 229.87000465393066 and batch: 1900, loss is 4.345010976791382 and perplexity is 77.0928837071592
At time: 231.2265887260437 and batch: 1950, loss is 4.267783670425415 and perplexity is 71.36329563458445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.449938397074854 and perplexity of 85.62166929444913
finished 4 epochs...
Completing Train Step...
At time: 235.52586460113525 and batch: 50, loss is 4.258377451896667 and perplexity is 70.69518400892264
At time: 236.90112829208374 and batch: 100, loss is 4.206790423393249 and perplexity is 67.14070039748214
At time: 238.25786209106445 and batch: 150, loss is 4.156877617835999 and perplexity is 63.87177882103615
At time: 239.61078238487244 and batch: 200, loss is 4.1662662935256956 and perplexity is 64.47427412895158
At time: 240.96231842041016 and batch: 250, loss is 4.161477317810059 and perplexity is 64.16624655285477
At time: 242.31331968307495 and batch: 300, loss is 4.187538828849792 and perplexity is 65.86049737011571
At time: 243.66444635391235 and batch: 350, loss is 4.191523566246032 and perplexity is 66.12345772295404
At time: 245.04132843017578 and batch: 400, loss is 4.14039448261261 and perplexity is 62.82760095750748
At time: 246.39654970169067 and batch: 450, loss is 4.164757151603698 and perplexity is 64.37704668243403
At time: 247.74934816360474 and batch: 500, loss is 4.168331580162048 and perplexity is 64.60756958498071
At time: 249.09973049163818 and batch: 550, loss is 4.14186276435852 and perplexity is 62.919917333772744
At time: 250.45091843605042 and batch: 600, loss is 4.130124015808105 and perplexity is 62.1856344582854
At time: 251.8056092262268 and batch: 650, loss is 4.17323977470398 and perplexity is 64.92545559039773
At time: 253.16174936294556 and batch: 700, loss is 4.219371881484985 and perplexity is 67.9907646162099
At time: 254.51640486717224 and batch: 750, loss is 4.170849504470826 and perplexity is 64.77045153112039
At time: 255.8674030303955 and batch: 800, loss is 4.173375153541565 and perplexity is 64.93424571809048
At time: 257.2179238796234 and batch: 850, loss is 4.162009878158569 and perplexity is 64.20042805252939
At time: 258.57408475875854 and batch: 900, loss is 4.1413323068618775 and perplexity is 62.886549842735214
At time: 259.9427180290222 and batch: 950, loss is 4.217372269630432 and perplexity is 67.8549453154806
At time: 261.29710364341736 and batch: 1000, loss is 4.190769538879395 and perplexity is 66.07361761901682
At time: 262.64968705177307 and batch: 1050, loss is 4.144863209724426 and perplexity is 63.10898861533981
At time: 264.0012288093567 and batch: 1100, loss is 4.169480304718018 and perplexity is 64.68182853003552
At time: 265.35142159461975 and batch: 1150, loss is 4.133806943893433 and perplexity is 62.41508193786774
At time: 266.70264983177185 and batch: 1200, loss is 4.207427892684937 and perplexity is 67.18351417699293
At time: 268.05738735198975 and batch: 1250, loss is 4.200800867080688 and perplexity is 66.73975931980688
At time: 269.412273645401 and batch: 1300, loss is 4.191656618118286 and perplexity is 66.13225615811515
At time: 270.76660537719727 and batch: 1350, loss is 4.07130334854126 and perplexity is 58.63333248114811
At time: 272.1179254055023 and batch: 1400, loss is 4.097812433242797 and perplexity is 60.20843346253677
At time: 273.4685113430023 and batch: 1450, loss is 4.049831795692444 and perplexity is 57.387803357847055
At time: 274.8209195137024 and batch: 1500, loss is 4.042639465332031 and perplexity is 56.976532089760134
At time: 276.17648577690125 and batch: 1550, loss is 4.056556234359741 and perplexity is 57.77500451796454
At time: 277.53055715560913 and batch: 1600, loss is 4.1300364112854 and perplexity is 62.180186954076035
At time: 278.8818428516388 and batch: 1650, loss is 4.09285578250885 and perplexity is 59.91073967816998
At time: 280.23386693000793 and batch: 1700, loss is 4.103369498252869 and perplexity is 60.5439470133345
At time: 281.58626103401184 and batch: 1750, loss is 4.105333452224731 and perplexity is 60.66296937750908
At time: 282.93930220603943 and batch: 1800, loss is 4.0578984451293945 and perplexity is 57.85260281623151
At time: 284.2943775653839 and batch: 1850, loss is 4.09283932685852 and perplexity is 59.90975381609838
At time: 285.64840269088745 and batch: 1900, loss is 4.197330584526062 and perplexity is 66.50855490169894
At time: 286.9993715286255 and batch: 1950, loss is 4.124499168395996 and perplexity is 61.83683165415192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4253795535065406 and perplexity of 83.54451081708811
finished 5 epochs...
Completing Train Step...
At time: 291.3481137752533 and batch: 50, loss is 4.11645432472229 and perplexity is 61.34135967972886
At time: 292.70232915878296 and batch: 100, loss is 4.072235832214355 and perplexity is 58.688032605908965
At time: 294.05229783058167 and batch: 150, loss is 4.024849963188172 and perplexity is 55.971910304645476
At time: 295.401643037796 and batch: 200, loss is 4.03005741596222 and perplexity is 56.26414161421887
At time: 296.75339221954346 and batch: 250, loss is 4.024080395698547 and perplexity is 55.92885271212956
At time: 298.1067705154419 and batch: 300, loss is 4.0550913953781125 and perplexity is 57.69043539437933
At time: 299.4623591899872 and batch: 350, loss is 4.0563156700134275 and perplexity is 57.76110758338992
At time: 300.8179678916931 and batch: 400, loss is 4.0062677907943725 and perplexity is 54.941434509118345
At time: 302.1720292568207 and batch: 450, loss is 4.036918530464172 and perplexity is 56.651503680348384
At time: 303.52608704566956 and batch: 500, loss is 4.044176049232483 and perplexity is 57.06414860950047
At time: 304.87735533714294 and batch: 550, loss is 4.018861889839172 and perplexity is 55.63774789327769
At time: 306.2329761981964 and batch: 600, loss is 4.005968961715698 and perplexity is 54.925018863721206
At time: 307.5874366760254 and batch: 650, loss is 4.046825714111328 and perplexity is 57.21554997277078
At time: 308.94225430488586 and batch: 700, loss is 4.090948820114136 and perplexity is 59.79660101422299
At time: 310.3013708591461 and batch: 750, loss is 4.047549390792847 and perplexity is 57.25697051783995
At time: 311.66029500961304 and batch: 800, loss is 4.046017603874207 and perplexity is 57.16933217816689
At time: 313.03605604171753 and batch: 850, loss is 4.038583168983459 and perplexity is 56.74588649038607
At time: 314.4028766155243 and batch: 900, loss is 4.0229602670669555 and perplexity is 55.866240276412185
At time: 315.7672462463379 and batch: 950, loss is 4.093811373710633 and perplexity is 59.96801721649599
At time: 317.1212282180786 and batch: 1000, loss is 4.067822370529175 and perplexity is 58.42958596431505
At time: 318.47122049331665 and batch: 1050, loss is 4.021460995674134 and perplexity is 55.782544377652336
At time: 319.82231307029724 and batch: 1100, loss is 4.041715950965881 and perplexity is 56.92393773340173
At time: 321.173953294754 and batch: 1150, loss is 4.014047269821167 and perplexity is 55.370517102085536
At time: 322.52828764915466 and batch: 1200, loss is 4.0838672542572025 and perplexity is 59.37464327027647
At time: 323.8826689720154 and batch: 1250, loss is 4.081365118026733 and perplexity is 59.22626553224797
At time: 325.24029564857483 and batch: 1300, loss is 4.072047290802002 and perplexity is 58.67696852440474
At time: 326.5903317928314 and batch: 1350, loss is 3.9508821153640747 and perplexity is 51.98120003196698
At time: 327.94494104385376 and batch: 1400, loss is 3.9839521503448485 and perplexity is 53.728960098372646
At time: 329.3065257072449 and batch: 1450, loss is 3.933960781097412 and perplexity is 51.10900890070288
At time: 330.6635527610779 and batch: 1500, loss is 3.9223336362838745 and perplexity is 50.51819842837933
At time: 332.01703333854675 and batch: 1550, loss is 3.9407682275772093 and perplexity is 51.458117664864474
At time: 333.3690347671509 and batch: 1600, loss is 4.0180824804306035 and perplexity is 55.59440020409088
At time: 334.7198386192322 and batch: 1650, loss is 3.9806716632843018 and perplexity is 53.5529917287814
At time: 336.0715434551239 and batch: 1700, loss is 3.9889154052734375 and perplexity is 53.99629349750582
At time: 337.4272940158844 and batch: 1750, loss is 3.993586010932922 and perplexity is 54.24907876211718
At time: 338.7828755378723 and batch: 1800, loss is 3.945732398033142 and perplexity is 51.714199623656185
At time: 340.13642168045044 and batch: 1850, loss is 3.9761596155166625 and perplexity is 53.31190238433983
At time: 341.4874358177185 and batch: 1900, loss is 4.080177268981934 and perplexity is 59.1559554364657
At time: 342.83853459358215 and batch: 1950, loss is 4.0130021238327025 and perplexity is 55.312677059166546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425862157067587 and perplexity of 83.58483942609674
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 347.18911385536194 and batch: 50, loss is 4.046674070358276 and perplexity is 57.20687424986617
At time: 348.539457321167 and batch: 100, loss is 4.029700617790223 and perplexity is 56.2440702522675
At time: 349.8897659778595 and batch: 150, loss is 3.9979190683364867 and perplexity is 54.484653144561676
At time: 351.2394573688507 and batch: 200, loss is 4.001487655639648 and perplexity is 54.679433725035864
At time: 352.594181060791 and batch: 250, loss is 3.9885597038269043 and perplexity is 53.97709035329688
At time: 353.9498338699341 and batch: 300, loss is 4.007453789710999 and perplexity is 55.00663364633472
At time: 355.3021900653839 and batch: 350, loss is 4.0174178123474125 and perplexity is 55.55746065829956
At time: 356.6551265716553 and batch: 400, loss is 3.9621967697143554 and perplexity is 52.57268928098358
At time: 358.0071134567261 and batch: 450, loss is 3.9888777923583985 and perplexity is 53.994262577700724
At time: 359.36054515838623 and batch: 500, loss is 3.9889187574386598 and perplexity is 53.99647450230639
At time: 360.7166700363159 and batch: 550, loss is 3.951797103881836 and perplexity is 52.02878399920772
At time: 362.07238006591797 and batch: 600, loss is 3.9288943672180174 and perplexity is 50.85072434934642
At time: 363.42356133461 and batch: 650, loss is 3.9686408758163454 and perplexity is 52.912567197293434
At time: 364.77330327033997 and batch: 700, loss is 4.012121334075927 and perplexity is 55.26397966902248
At time: 366.12493443489075 and batch: 750, loss is 3.956989412307739 and perplexity is 52.299636057954174
At time: 367.4792196750641 and batch: 800, loss is 3.947682819366455 and perplexity is 51.81516252993407
At time: 368.8352313041687 and batch: 850, loss is 3.936780548095703 and perplexity is 51.25332777449092
At time: 370.18901538848877 and batch: 900, loss is 3.90673565864563 and perplexity is 49.7363303316235
At time: 371.53919434547424 and batch: 950, loss is 3.9878684282302856 and perplexity is 53.93979020178678
At time: 372.88632702827454 and batch: 1000, loss is 3.9545453119277956 and perplexity is 52.17196657965837
At time: 374.2372376918793 and batch: 1050, loss is 3.904399485588074 and perplexity is 49.620273274190176
At time: 375.5888252258301 and batch: 1100, loss is 3.9050512313842773 and perplexity is 49.6526236196588
At time: 376.94396114349365 and batch: 1150, loss is 3.8790939474105834 and perplexity is 48.380360056364424
At time: 378.2992024421692 and batch: 1200, loss is 3.9353918504714964 and perplexity is 51.18220179764575
At time: 379.6506493091583 and batch: 1250, loss is 3.924090013504028 and perplexity is 50.60700540775015
At time: 381.0049002170563 and batch: 1300, loss is 3.910085668563843 and perplexity is 49.90322692807269
At time: 382.3573863506317 and batch: 1350, loss is 3.7908929920196535 and perplexity is 44.29593853929779
At time: 383.7113015651703 and batch: 1400, loss is 3.817783570289612 and perplexity is 45.50324173261434
At time: 385.0661108493805 and batch: 1450, loss is 3.754106683731079 and perplexity is 42.69606168293165
At time: 386.4205026626587 and batch: 1500, loss is 3.74295081615448 and perplexity is 42.22239705510662
At time: 387.7710304260254 and batch: 1550, loss is 3.758633613586426 and perplexity is 42.88978190737653
At time: 389.1232135295868 and batch: 1600, loss is 3.83411096572876 and perplexity is 46.25228951354459
At time: 390.4756667613983 and batch: 1650, loss is 3.7809868621826173 and perplexity is 43.85930347333022
At time: 391.82986879348755 and batch: 1700, loss is 3.76776575088501 and perplexity is 43.28325115759482
At time: 393.1879951953888 and batch: 1750, loss is 3.7626245260238647 and perplexity is 43.061293287235365
At time: 394.54213094711304 and batch: 1800, loss is 3.7179613637924196 and perplexity is 41.18035671064347
At time: 395.8935503959656 and batch: 1850, loss is 3.7356234693527224 and perplexity is 41.91414960621126
At time: 397.2434265613556 and batch: 1900, loss is 3.8328968238830567 and perplexity is 46.1961667507784
At time: 398.5952134132385 and batch: 1950, loss is 3.757440600395203 and perplexity is 42.83864434175279
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3535582076671515 and perplexity of 77.75463843961248
finished 7 epochs...
Completing Train Step...
At time: 402.93739557266235 and batch: 50, loss is 3.9581240797042847 and perplexity is 52.35901242968646
At time: 404.28677010536194 and batch: 100, loss is 3.9286235570907593 and perplexity is 50.83695532269429
At time: 405.6374077796936 and batch: 150, loss is 3.884544196128845 and perplexity is 48.64476493340519
At time: 406.98950934410095 and batch: 200, loss is 3.8877830410003664 and perplexity is 48.802573201133185
At time: 408.34456491470337 and batch: 250, loss is 3.874860200881958 and perplexity is 48.17596286318725
At time: 409.69436502456665 and batch: 300, loss is 3.8911051416397093 and perplexity is 48.964969860433555
At time: 411.0524973869324 and batch: 350, loss is 3.9047300910949705 and perplexity is 49.63668072183516
At time: 412.41795659065247 and batch: 400, loss is 3.8529866981506347 and perplexity is 47.133627133107964
At time: 413.7872543334961 and batch: 450, loss is 3.8869175481796265 and perplexity is 48.760353197584465
At time: 415.1394739151001 and batch: 500, loss is 3.888329701423645 and perplexity is 48.829258929807715
At time: 416.491571187973 and batch: 550, loss is 3.8533254146575926 and perplexity is 47.149594774749986
At time: 417.8426687717438 and batch: 600, loss is 3.834069266319275 and perplexity is 46.25036086059667
At time: 419.1925730705261 and batch: 650, loss is 3.8738794136047363 and perplexity is 48.128735655451194
At time: 420.54395961761475 and batch: 700, loss is 3.92036584854126 and perplexity is 50.41888708060543
At time: 421.8959491252899 and batch: 750, loss is 3.868958616256714 and perplexity is 47.89248564660049
At time: 423.24716424942017 and batch: 800, loss is 3.8591521406173706 and perplexity is 47.42512448112755
At time: 424.5999073982239 and batch: 850, loss is 3.8507953453063966 and perplexity is 47.03045381109365
At time: 425.9506423473358 and batch: 900, loss is 3.8247198152542112 and perplexity is 45.81996051366346
At time: 427.3028028011322 and batch: 950, loss is 3.9092212820053103 and perplexity is 49.860109887068624
At time: 428.65366220474243 and batch: 1000, loss is 3.8770802497863768 and perplexity is 48.28303466510293
At time: 430.0064506530762 and batch: 1050, loss is 3.832671194076538 and perplexity is 46.18574469442
At time: 431.35784339904785 and batch: 1100, loss is 3.8319278717041017 and perplexity is 46.15142655340215
At time: 432.70857286453247 and batch: 1150, loss is 3.809755482673645 and perplexity is 45.13940015135691
At time: 434.06083846092224 and batch: 1200, loss is 3.8696388816833496 and perplexity is 47.925076332683204
At time: 435.41219544410706 and batch: 1250, loss is 3.8602125215530396 and perplexity is 47.47543985101399
At time: 436.76307463645935 and batch: 1300, loss is 3.8493187189102174 and perplexity is 46.9610586495448
At time: 438.11436915397644 and batch: 1350, loss is 3.729916491508484 and perplexity is 41.675627749902866
At time: 439.4642560482025 and batch: 1400, loss is 3.761313180923462 and perplexity is 43.00486207974658
At time: 440.81683111190796 and batch: 1450, loss is 3.6997884368896483 and perplexity is 40.438748107677235
At time: 442.1677072048187 and batch: 1500, loss is 3.692134518623352 and perplexity is 40.13041471938878
At time: 443.5196008682251 and batch: 1550, loss is 3.7092016553878784 and perplexity is 40.82120412637183
At time: 444.87104392051697 and batch: 1600, loss is 3.787800211906433 and perplexity is 44.15915257497522
At time: 446.2222294807434 and batch: 1650, loss is 3.7381044960021974 and perplexity is 42.018268836257825
At time: 447.57417941093445 and batch: 1700, loss is 3.7303640985488893 and perplexity is 41.69428622981901
At time: 448.9262294769287 and batch: 1750, loss is 3.7285587978363037 and perplexity is 41.61908340745649
At time: 450.27907395362854 and batch: 1800, loss is 3.686758027076721 and perplexity is 39.915232863949406
At time: 451.6305932998657 and batch: 1850, loss is 3.7104983043670656 and perplexity is 40.874169230184535
At time: 452.9821650981903 and batch: 1900, loss is 3.8092214250564576 and perplexity is 45.115299546999296
At time: 454.3339464664459 and batch: 1950, loss is 3.735669345855713 and perplexity is 41.91607252492908
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358444142896076 and perplexity of 78.13547217363912
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 458.6352348327637 and batch: 50, loss is 3.925205669403076 and perplexity is 50.663496918550564
At time: 460.0060405731201 and batch: 100, loss is 3.9317348527908327 and perplexity is 50.9953704335309
At time: 461.3571698665619 and batch: 150, loss is 3.8975318813323976 and perplexity is 49.2806683451716
At time: 462.70785450935364 and batch: 200, loss is 3.9110851430892946 and perplexity is 49.95312886582878
At time: 464.0589337348938 and batch: 250, loss is 3.910388035774231 and perplexity is 49.91831830904269
At time: 465.4116630554199 and batch: 300, loss is 3.915412817001343 and perplexity is 50.16977817409535
At time: 466.7621717453003 and batch: 350, loss is 3.933681221008301 and perplexity is 51.09472285861687
At time: 468.11335158348083 and batch: 400, loss is 3.888425464630127 and perplexity is 48.83393520011672
At time: 469.46390986442566 and batch: 450, loss is 3.9292622232437133 and perplexity is 50.86943353564181
At time: 470.81567645072937 and batch: 500, loss is 3.927164087295532 and perplexity is 50.762814438270524
At time: 472.1737365722656 and batch: 550, loss is 3.888858046531677 and perplexity is 48.85506444640104
At time: 473.53235626220703 and batch: 600, loss is 3.854010558128357 and perplexity is 47.181910080805444
At time: 474.8914189338684 and batch: 650, loss is 3.8841488265991213 and perplexity is 48.625536077072375
At time: 476.2504367828369 and batch: 700, loss is 3.927305521965027 and perplexity is 50.76999456790089
At time: 477.6053001880646 and batch: 750, loss is 3.8723029851913453 and perplexity is 48.05292392064991
At time: 478.9572169780731 and batch: 800, loss is 3.8626659965515135 and perplexity is 47.5920626628052
At time: 480.3087651729584 and batch: 850, loss is 3.854328727722168 and perplexity is 47.196924318381356
At time: 481.67835307121277 and batch: 900, loss is 3.8146008110046385 and perplexity is 45.35864609610808
At time: 483.0304317474365 and batch: 950, loss is 3.904256377220154 and perplexity is 49.613172705953644
At time: 484.3808419704437 and batch: 1000, loss is 3.86827552318573 and perplexity is 47.859781792662794
At time: 485.73306679725647 and batch: 1050, loss is 3.825125608444214 and perplexity is 45.838557714659665
At time: 487.0843722820282 and batch: 1100, loss is 3.8231009578704835 and perplexity is 45.74584454004568
At time: 488.4363248348236 and batch: 1150, loss is 3.802757353782654 and perplexity is 44.82461156129763
At time: 489.78942799568176 and batch: 1200, loss is 3.8562399911880494 and perplexity is 47.28721633396252
At time: 491.1401777267456 and batch: 1250, loss is 3.8331918287277222 and perplexity is 46.20979685414927
At time: 492.49018144607544 and batch: 1300, loss is 3.822015657424927 and perplexity is 45.69622348633048
At time: 493.8428404331207 and batch: 1350, loss is 3.701800618171692 and perplexity is 40.52020012031398
At time: 495.20328760147095 and batch: 1400, loss is 3.727224168777466 and perplexity is 41.5635744195324
At time: 496.5589349269867 and batch: 1450, loss is 3.6526087379455565 and perplexity is 38.57516740414925
At time: 497.9160943031311 and batch: 1500, loss is 3.6486358499526976 and perplexity is 38.422216614104585
At time: 499.2734034061432 and batch: 1550, loss is 3.6703457021713257 and perplexity is 39.265477675156845
At time: 500.6321187019348 and batch: 1600, loss is 3.756642527580261 and perplexity is 42.80446962304554
At time: 501.9881534576416 and batch: 1650, loss is 3.70537136554718 and perplexity is 40.6651461473627
At time: 503.3498888015747 and batch: 1700, loss is 3.6858338212966917 and perplexity is 39.8783600166992
At time: 504.7026424407959 and batch: 1750, loss is 3.6815321159362795 and perplexity is 39.70718350108197
At time: 506.0534117221832 and batch: 1800, loss is 3.631976046562195 and perplexity is 37.787412577080595
At time: 507.4044735431671 and batch: 1850, loss is 3.6445115566253663 and perplexity is 38.26407845074581
At time: 508.75494408607483 and batch: 1900, loss is 3.749930863380432 and perplexity is 42.51814233781325
At time: 510.10771679878235 and batch: 1950, loss is 3.6839672756195068 and perplexity is 39.80399466095415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332547351925872 and perplexity of 76.1379900045027
finished 9 epochs...
Completing Train Step...
At time: 514.4102625846863 and batch: 50, loss is 3.9164097833633424 and perplexity is 50.219820696534725
At time: 515.7797422409058 and batch: 100, loss is 3.903268632888794 and perplexity is 49.56419177015571
At time: 517.1297821998596 and batch: 150, loss is 3.8576251602172853 and perplexity is 47.35276250729149
At time: 518.4809904098511 and batch: 200, loss is 3.8632432222366333 and perplexity is 47.61954195389532
At time: 519.8313562870026 and batch: 250, loss is 3.8588077783584596 and perplexity is 47.4087958697722
At time: 521.1823728084564 and batch: 300, loss is 3.8624106740951536 and perplexity is 47.57991289158361
At time: 522.5337965488434 and batch: 350, loss is 3.8819179773330688 and perplexity is 48.51718074275001
At time: 523.8840088844299 and batch: 400, loss is 3.835120038986206 and perplexity is 46.298985017618335
At time: 525.233983039856 and batch: 450, loss is 3.8793800401687624 and perplexity is 48.394203307147116
At time: 526.5848581790924 and batch: 500, loss is 3.878245358467102 and perplexity is 48.339322432238596
At time: 527.9364495277405 and batch: 550, loss is 3.842032561302185 and perplexity is 46.62013648932083
At time: 529.2881813049316 and batch: 600, loss is 3.809572286605835 and perplexity is 45.13113154815679
At time: 530.6385154724121 and batch: 650, loss is 3.8418686962127686 and perplexity is 46.612497702368756
At time: 531.9895451068878 and batch: 700, loss is 3.887177848815918 and perplexity is 48.77304720060444
At time: 533.340571641922 and batch: 750, loss is 3.8339447212219238 and perplexity is 46.244600963591665
At time: 534.6912505626678 and batch: 800, loss is 3.825628023147583 and perplexity is 45.86159346630234
At time: 536.0438995361328 and batch: 850, loss is 3.8176904010772703 and perplexity is 45.49900242891249
At time: 537.394255399704 and batch: 900, loss is 3.7799039697647094 and perplexity is 43.811834272801654
At time: 538.7461111545563 and batch: 950, loss is 3.870432152748108 and perplexity is 47.963108992123956
At time: 540.0971102714539 and batch: 1000, loss is 3.8354669618606567 and perplexity is 46.31504998107532
At time: 541.4469702243805 and batch: 1050, loss is 3.7953148460388184 and perplexity is 44.492242406825966
At time: 542.7984397411346 and batch: 1100, loss is 3.7932090902328492 and perplexity is 44.39865118377144
At time: 544.1493170261383 and batch: 1150, loss is 3.7744767570495608 and perplexity is 43.57470219393213
At time: 545.5001528263092 and batch: 1200, loss is 3.831106767654419 and perplexity is 46.113546983822744
At time: 546.850177526474 and batch: 1250, loss is 3.8107857370376585 and perplexity is 45.18592917960341
At time: 548.201229095459 and batch: 1300, loss is 3.802332630157471 and perplexity is 44.805577532164946
At time: 549.5518629550934 and batch: 1350, loss is 3.6836173486709596 and perplexity is 39.79006860725529
At time: 550.9030921459198 and batch: 1400, loss is 3.7095152235031126 and perplexity is 40.8340063614928
At time: 552.2543902397156 and batch: 1450, loss is 3.637882719039917 and perplexity is 38.011270925080474
At time: 553.6044826507568 and batch: 1500, loss is 3.636162004470825 and perplexity is 37.945920618147035
At time: 554.9580953121185 and batch: 1550, loss is 3.6597459888458252 and perplexity is 38.85147291037009
At time: 556.313529253006 and batch: 1600, loss is 3.7472825193405153 and perplexity is 42.40568864272775
At time: 557.6616566181183 and batch: 1650, loss is 3.6975455045700074 and perplexity is 40.3481483750969
At time: 559.0123047828674 and batch: 1700, loss is 3.681081256866455 and perplexity is 39.689285192373916
At time: 560.3690166473389 and batch: 1750, loss is 3.678793830871582 and perplexity is 39.59860264405609
At time: 561.7195777893066 and batch: 1800, loss is 3.6311105823516847 and perplexity is 37.754723071726275
At time: 563.0696008205414 and batch: 1850, loss is 3.6459192752838137 and perplexity is 38.31798143914897
At time: 564.4198658466339 and batch: 1900, loss is 3.7522893953323364 and perplexity is 42.618541085339146
At time: 565.7693829536438 and batch: 1950, loss is 3.6850784015655518 and perplexity is 39.84824649230438
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3327029206031975 and perplexity of 76.14983561228077
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 570.0535213947296 and batch: 50, loss is 3.9080356979370117 and perplexity is 49.80103156322276
At time: 571.4228994846344 and batch: 100, loss is 3.9108496427536013 and perplexity is 49.94136627231367
At time: 572.7730221748352 and batch: 150, loss is 3.8716419982910155 and perplexity is 48.02117206235305
At time: 574.1239502429962 and batch: 200, loss is 3.8846460676193235 and perplexity is 48.64972070053434
At time: 575.4738357067108 and batch: 250, loss is 3.8908099937438965 and perplexity is 48.950520085125994
At time: 576.8230104446411 and batch: 300, loss is 3.8935657119750977 and perplexity is 49.085599961307246
At time: 578.1749424934387 and batch: 350, loss is 3.9122218608856203 and perplexity is 50.00994376152657
At time: 579.5265851020813 and batch: 400, loss is 3.875947256088257 and perplexity is 48.22836126925631
At time: 580.8769409656525 and batch: 450, loss is 3.9276407623291014 and perplexity is 50.78701757260362
At time: 582.2269678115845 and batch: 500, loss is 3.932912530899048 and perplexity is 51.05546194219271
At time: 583.612833738327 and batch: 550, loss is 3.897829599380493 and perplexity is 49.29534227379847
At time: 584.9642932415009 and batch: 600, loss is 3.859623045921326 and perplexity is 47.44746248291542
At time: 586.3172514438629 and batch: 650, loss is 3.873172416687012 and perplexity is 48.09472081329994
At time: 587.6701080799103 and batch: 700, loss is 3.913695664405823 and perplexity is 50.08370293259942
At time: 589.0198833942413 and batch: 750, loss is 3.8554666233062744 and perplexity is 47.25066005717848
At time: 590.3666779994965 and batch: 800, loss is 3.845120348930359 and perplexity is 46.76431204719563
At time: 591.7141771316528 and batch: 850, loss is 3.8382997703552246 and perplexity is 46.446437658288744
At time: 593.061190366745 and batch: 900, loss is 3.7938222789764406 and perplexity is 44.425884285570405
At time: 594.4315195083618 and batch: 950, loss is 3.886292452812195 and perplexity is 48.72988285111471
At time: 595.8032641410828 and batch: 1000, loss is 3.8481441593170165 and perplexity is 46.905932468431175
At time: 597.1534214019775 and batch: 1050, loss is 3.8087058544158934 and perplexity is 45.09204541820075
At time: 598.5187005996704 and batch: 1100, loss is 3.803350257873535 and perplexity is 44.85119613713758
At time: 599.8783233165741 and batch: 1150, loss is 3.787883162498474 and perplexity is 44.1628157547547
At time: 601.2362899780273 and batch: 1200, loss is 3.8422130727767945 and perplexity is 46.628552718495136
At time: 602.5922706127167 and batch: 1250, loss is 3.8175742483139037 and perplexity is 45.493717900962146
At time: 603.9460186958313 and batch: 1300, loss is 3.8062050914764405 and perplexity is 44.979421783354795
At time: 605.296569108963 and batch: 1350, loss is 3.682305722236633 and perplexity is 39.73791311318591
At time: 606.6460661888123 and batch: 1400, loss is 3.7080177640914918 and perplexity is 40.772904854283865
At time: 607.997312784195 and batch: 1450, loss is 3.629252038002014 and perplexity is 37.68461941004935
At time: 609.3516843318939 and batch: 1500, loss is 3.619680166244507 and perplexity is 37.32562791701026
At time: 610.7091736793518 and batch: 1550, loss is 3.6450714540481566 and perplexity is 38.28550840838502
At time: 612.0615932941437 and batch: 1600, loss is 3.7317394161224366 and perplexity is 41.751668564809364
At time: 613.4134757518768 and batch: 1650, loss is 3.6824731159210207 and perplexity is 39.74456554564386
At time: 614.7658741474152 and batch: 1700, loss is 3.668664355278015 and perplexity is 39.19951425548822
At time: 616.1157367229462 and batch: 1750, loss is 3.6674595737457274 and perplexity is 39.15231584223591
At time: 617.4644994735718 and batch: 1800, loss is 3.6203075504302977 and perplexity is 37.34905277311389
At time: 618.8144896030426 and batch: 1850, loss is 3.6283632040023805 and perplexity is 37.651138920557344
At time: 620.1645631790161 and batch: 1900, loss is 3.740655083656311 and perplexity is 42.125576905142296
At time: 621.5168204307556 and batch: 1950, loss is 3.679876518249512 and perplexity is 39.64149876867854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315323798601018 and perplexity of 74.83785191291165
finished 11 epochs...
Completing Train Step...
At time: 625.8302221298218 and batch: 50, loss is 3.9157337760925293 and perplexity is 50.185883204892896
At time: 627.1814196109772 and batch: 100, loss is 3.902325963973999 and perplexity is 49.517491162350964
At time: 628.5333433151245 and batch: 150, loss is 3.8567682933807372 and perplexity is 47.312204874206955
At time: 629.8874752521515 and batch: 200, loss is 3.8603257608413695 and perplexity is 47.480816240439374
At time: 631.2424123287201 and batch: 250, loss is 3.861832938194275 and perplexity is 47.55243220679892
At time: 632.5971734523773 and batch: 300, loss is 3.8640184879302977 and perplexity is 47.656474065369906
At time: 633.9566020965576 and batch: 350, loss is 3.881789402961731 and perplexity is 48.51094307774745
At time: 635.3132658004761 and batch: 400, loss is 3.8431181144714355 and perplexity is 46.670772605363254
At time: 636.6654052734375 and batch: 450, loss is 3.895700397491455 and perplexity is 49.190494198878646
At time: 638.0233895778656 and batch: 500, loss is 3.9009273624420167 and perplexity is 49.44828433102274
At time: 639.378071308136 and batch: 550, loss is 3.8655851888656616 and perplexity is 47.731196026063046
At time: 640.730518579483 and batch: 600, loss is 3.830861520767212 and perplexity is 46.102239166627065
At time: 642.0823600292206 and batch: 650, loss is 3.84776291847229 and perplexity is 46.88805341944265
At time: 643.433135509491 and batch: 700, loss is 3.89061842918396 and perplexity is 48.94114379839801
At time: 644.7865114212036 and batch: 750, loss is 3.8348087310791015 and perplexity is 46.28457402073646
At time: 646.140772819519 and batch: 800, loss is 3.826638970375061 and perplexity is 45.90798056056631
At time: 647.4940812587738 and batch: 850, loss is 3.8205813503265382 and perplexity is 45.63072805012732
At time: 648.8452820777893 and batch: 900, loss is 3.7787911033630373 and perplexity is 43.763104674239514
At time: 650.2315104007721 and batch: 950, loss is 3.871066675186157 and perplexity is 47.99355231844345
At time: 651.5821964740753 and batch: 1000, loss is 3.832373538017273 and perplexity is 46.17199927346545
At time: 652.9378271102905 and batch: 1050, loss is 3.7939333486557008 and perplexity is 44.43081892832837
At time: 654.2932622432709 and batch: 1100, loss is 3.7896081495285032 and perplexity is 44.239061781938865
At time: 655.6473846435547 and batch: 1150, loss is 3.774864687919617 and perplexity is 43.59160944527699
At time: 656.9989731311798 and batch: 1200, loss is 3.8305831432342528 and perplexity is 46.089407125182845
At time: 658.3518249988556 and batch: 1250, loss is 3.806766142845154 and perplexity is 45.004664630114995
At time: 659.7021453380585 and batch: 1300, loss is 3.7967845582962036 and perplexity is 44.557681277225505
At time: 661.0575790405273 and batch: 1350, loss is 3.6744983530044557 and perplexity is 39.42887251980145
At time: 662.4130754470825 and batch: 1400, loss is 3.7020228147506713 and perplexity is 40.52920457050224
At time: 663.7650775909424 and batch: 1450, loss is 3.6258398914337158 and perplexity is 37.556253092141944
At time: 665.1149218082428 and batch: 1500, loss is 3.618578405380249 and perplexity is 37.28452664698051
At time: 666.4685966968536 and batch: 1550, loss is 3.6463444995880128 and perplexity is 38.33427864088232
At time: 667.8195202350616 and batch: 1600, loss is 3.735019311904907 and perplexity is 41.88883450848026
At time: 669.1757817268372 and batch: 1650, loss is 3.6864089441299437 and perplexity is 39.90130156857025
At time: 670.5313262939453 and batch: 1700, loss is 3.6737312650680543 and perplexity is 39.398638704825494
At time: 671.8839280605316 and batch: 1750, loss is 3.6743281745910643 and perplexity is 39.42216314774556
At time: 673.2351381778717 and batch: 1800, loss is 3.6272007036209106 and perplexity is 37.607394888352815
At time: 674.5863420963287 and batch: 1850, loss is 3.635289120674133 and perplexity is 37.91281269067776
At time: 675.9382801055908 and batch: 1900, loss is 3.7483842039108275 and perplexity is 42.45243207913249
At time: 677.2937552928925 and batch: 1950, loss is 3.6861329460144043 and perplexity is 39.89029040412996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.313969385901163 and perplexity of 74.73655918741241
finished 12 epochs...
Completing Train Step...
At time: 681.6111395359039 and batch: 50, loss is 3.911032590866089 and perplexity is 49.950503786828286
At time: 682.9621307849884 and batch: 100, loss is 3.894615902900696 and perplexity is 49.13717629072042
At time: 684.3336584568024 and batch: 150, loss is 3.8476496744155884 and perplexity is 46.88274392670251
At time: 685.6869118213654 and batch: 200, loss is 3.8501422452926635 and perplexity is 46.99974824905667
At time: 687.0412857532501 and batch: 250, loss is 3.8503365468978883 and perplexity is 47.00888126283751
At time: 688.3936190605164 and batch: 300, loss is 3.8520783138275148 and perplexity is 47.09083112568239
At time: 689.7452566623688 and batch: 350, loss is 3.869950671195984 and perplexity is 47.94002119858109
At time: 691.0974342823029 and batch: 400, loss is 3.8307202100753783 and perplexity is 46.09572488759482
At time: 692.459707736969 and batch: 450, loss is 3.8833400535583498 and perplexity is 48.586224953431504
At time: 693.8149170875549 and batch: 500, loss is 3.8885455656051637 and perplexity is 48.839800555559535
At time: 695.1690409183502 and batch: 550, loss is 3.8532412338256834 and perplexity is 47.145625849693715
At time: 696.5197205543518 and batch: 600, loss is 3.8192630672454833 and perplexity is 45.57061346608809
At time: 697.8712141513824 and batch: 650, loss is 3.837049989700317 and perplexity is 46.38842605745323
At time: 699.2228925228119 and batch: 700, loss is 3.88047664642334 and perplexity is 48.44730180192867
At time: 700.5770537853241 and batch: 750, loss is 3.8255737161636354 and perplexity is 45.85910292910955
At time: 701.9333066940308 and batch: 800, loss is 3.818047184944153 and perplexity is 45.51523863517437
At time: 703.2855434417725 and batch: 850, loss is 3.8121159934997557 and perplexity is 45.2460780517335
At time: 704.6363472938538 and batch: 900, loss is 3.771238560676575 and perplexity is 43.43382696526152
At time: 705.9876363277435 and batch: 950, loss is 3.8635786533355714 and perplexity is 47.6355177084165
At time: 707.3390755653381 and batch: 1000, loss is 3.8248512315750123 and perplexity is 45.82598239997182
At time: 708.6937229633331 and batch: 1050, loss is 3.7868039274215697 and perplexity is 44.115179404930835
At time: 710.0495901107788 and batch: 1100, loss is 3.7828735303878784 and perplexity is 43.94212953477821
At time: 711.4025681018829 and batch: 1150, loss is 3.7684165716171263 and perplexity is 43.31142996348248
At time: 712.7534472942352 and batch: 1200, loss is 3.824763765335083 and perplexity is 45.82197434888737
At time: 714.1034033298492 and batch: 1250, loss is 3.8014472627639773 and perplexity is 44.765925690585306
At time: 715.4544367790222 and batch: 1300, loss is 3.7923915243148802 and perplexity is 44.36236719405753
At time: 716.8084495067596 and batch: 1350, loss is 3.670664896965027 and perplexity is 39.27801301170361
At time: 718.164564371109 and batch: 1400, loss is 3.6986168670654296 and perplexity is 40.391399032454814
At time: 719.5145795345306 and batch: 1450, loss is 3.6233313846588135 and perplexity is 37.462161041434044
At time: 720.86390209198 and batch: 1500, loss is 3.6168540620803835 and perplexity is 37.22029072157829
At time: 722.2145526409149 and batch: 1550, loss is 3.645561122894287 and perplexity is 38.304260219825125
At time: 723.5694439411163 and batch: 1600, loss is 3.73479519367218 and perplexity is 41.8794475088574
At time: 724.9257035255432 and batch: 1650, loss is 3.686293811798096 and perplexity is 39.89670790312167
At time: 726.2795820236206 and batch: 1700, loss is 3.674211015701294 and perplexity is 39.41754476142662
At time: 727.6299433708191 and batch: 1750, loss is 3.675175623893738 and perplexity is 39.455585592328426
At time: 728.9803745746613 and batch: 1800, loss is 3.6280854177474975 and perplexity is 37.640681404228914
At time: 730.3299815654755 and batch: 1850, loss is 3.636302628517151 and perplexity is 37.951257102256115
At time: 731.6856336593628 and batch: 1900, loss is 3.7497875928878783 and perplexity is 42.512051178970125
At time: 733.0390939712524 and batch: 1950, loss is 3.6867523908615114 and perplexity is 39.91500789374083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31394412018532 and perplexity of 74.73467093859898
finished 13 epochs...
Completing Train Step...
At time: 737.3564414978027 and batch: 50, loss is 3.9052801513671875 and perplexity is 49.663991398515485
At time: 738.710709810257 and batch: 100, loss is 3.887743034362793 and perplexity is 48.800620813328976
At time: 740.0652480125427 and batch: 150, loss is 3.8401413440704344 and perplexity is 46.53205100449368
At time: 741.4182937145233 and batch: 200, loss is 3.8423935317993165 and perplexity is 46.63696802082611
At time: 742.7737085819244 and batch: 250, loss is 3.8420737171173096 and perplexity is 46.62205521852243
At time: 744.131199836731 and batch: 300, loss is 3.8435716104507445 and perplexity is 46.69194241293953
At time: 745.489009141922 and batch: 350, loss is 3.8615344524383546 and perplexity is 47.53824060122725
At time: 746.8430685997009 and batch: 400, loss is 3.822003903388977 and perplexity is 45.69568637443347
At time: 748.1967146396637 and batch: 450, loss is 3.8747452974319456 and perplexity is 48.170427596863284
At time: 749.5474200248718 and batch: 500, loss is 3.8799921607971193 and perplexity is 48.4238354655868
At time: 750.9160070419312 and batch: 550, loss is 3.844705095291138 and perplexity is 46.74489702779008
At time: 752.2679302692413 and batch: 600, loss is 3.8111823558807374 and perplexity is 45.20385432504831
At time: 753.6208212375641 and batch: 650, loss is 3.8294505882263183 and perplexity is 46.037237884174445
At time: 754.9756164550781 and batch: 700, loss is 3.8731612396240234 and perplexity is 48.094183258580145
At time: 756.328245639801 and batch: 750, loss is 3.818693747520447 and perplexity is 45.5446766008449
At time: 757.6778066158295 and batch: 800, loss is 3.8114897632598876 and perplexity is 45.21775245951896
At time: 759.0272552967072 and batch: 850, loss is 3.805707974433899 and perplexity is 44.95706730307955
At time: 760.3767676353455 and batch: 900, loss is 3.765348024368286 and perplexity is 43.17873049564282
At time: 761.7305319309235 and batch: 950, loss is 3.8578065252304077 and perplexity is 47.361351420525644
At time: 763.0838828086853 and batch: 1000, loss is 3.819106273651123 and perplexity is 45.563468845935525
At time: 764.4371881484985 and batch: 1050, loss is 3.781365170478821 and perplexity is 43.87589895060534
At time: 765.788693189621 and batch: 1100, loss is 3.777621636390686 and perplexity is 43.71195508342356
At time: 767.1396372318268 and batch: 1150, loss is 3.7632912731170656 and perplexity is 43.09001385297698
At time: 768.4904463291168 and batch: 1200, loss is 3.8200619411468506 and perplexity is 45.60703318530011
At time: 769.8439917564392 and batch: 1250, loss is 3.7971441841125486 and perplexity is 44.57370825141337
At time: 771.1995770931244 and batch: 1300, loss is 3.7887471389770506 and perplexity is 44.20098787632762
At time: 772.5521230697632 and batch: 1350, loss is 3.667249975204468 and perplexity is 39.14411043389929
At time: 773.9025657176971 and batch: 1400, loss is 3.6953280925750733 and perplexity is 40.258779027866304
At time: 775.2537775039673 and batch: 1450, loss is 3.6205802297592165 and perplexity is 37.35923847641207
At time: 776.6054575443268 and batch: 1500, loss is 3.614454526901245 and perplexity is 37.131086391879215
At time: 777.9596338272095 and batch: 1550, loss is 3.643685612678528 and perplexity is 38.232487514735155
At time: 779.3160796165466 and batch: 1600, loss is 3.7332350492477415 and perplexity is 41.81416046417992
At time: 780.6691176891327 and batch: 1650, loss is 3.684752049446106 and perplexity is 39.835244054407404
At time: 782.0206315517426 and batch: 1700, loss is 3.673072657585144 and perplexity is 39.37269900953437
At time: 783.3718638420105 and batch: 1750, loss is 3.6742049980163576 and perplexity is 39.417307559774976
At time: 784.7248928546906 and batch: 1800, loss is 3.6271880626678468 and perplexity is 37.60691949804387
At time: 786.0795197486877 and batch: 1850, loss is 3.6355399084091187 and perplexity is 37.92232195145253
At time: 787.4342350959778 and batch: 1900, loss is 3.749347791671753 and perplexity is 42.49335843800804
At time: 788.785135269165 and batch: 1950, loss is 3.6858122682571413 and perplexity is 39.877500526090905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3143407067587205 and perplexity of 74.7643155836063
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 793.0940272808075 and batch: 50, loss is 3.90358962059021 and perplexity is 49.580103819794054
At time: 794.4845886230469 and batch: 100, loss is 3.8914580297470094 and perplexity is 48.98225206513452
At time: 795.8366129398346 and batch: 150, loss is 3.847296004295349 and perplexity is 46.86616583278184
At time: 797.1877107620239 and batch: 200, loss is 3.8505324125289917 and perplexity is 47.018089588801374
At time: 798.5379178524017 and batch: 250, loss is 3.852282862663269 and perplexity is 47.10046448557654
At time: 799.890246629715 and batch: 300, loss is 3.8550469160079954 and perplexity is 47.2308327714233
At time: 801.2447066307068 and batch: 350, loss is 3.872706580162048 and perplexity is 48.072321753242385
At time: 802.6000092029572 and batch: 400, loss is 3.8383049631118773 and perplexity is 46.44667884396309
At time: 803.9516224861145 and batch: 450, loss is 3.893325061798096 and perplexity is 49.0737889242094
At time: 805.3028807640076 and batch: 500, loss is 3.901091766357422 and perplexity is 49.456414490873584
At time: 806.6531670093536 and batch: 550, loss is 3.8673339653015137 and perplexity is 47.814740245718426
At time: 808.0052077770233 and batch: 600, loss is 3.831448221206665 and perplexity is 46.129295306754436
At time: 809.3590495586395 and batch: 650, loss is 3.844987998008728 and perplexity is 46.75812315695843
At time: 810.7128388881683 and batch: 700, loss is 3.887925968170166 and perplexity is 48.809548913297284
At time: 812.064154624939 and batch: 750, loss is 3.834091553688049 and perplexity is 46.25139167093209
At time: 813.4151363372803 and batch: 800, loss is 3.8268660926818847 and perplexity is 45.918408471173564
At time: 814.7661328315735 and batch: 850, loss is 3.820401816368103 and perplexity is 45.622536520245085
At time: 816.1198265552521 and batch: 900, loss is 3.77803777217865 and perplexity is 43.73014897759834
At time: 817.475399017334 and batch: 950, loss is 3.8712063074111938 and perplexity is 48.00025423283181
At time: 818.8431220054626 and batch: 1000, loss is 3.8306332874298095 and perplexity is 46.091718299372324
At time: 820.1942899227142 and batch: 1050, loss is 3.79211510181427 and perplexity is 44.35010613227951
At time: 821.5452926158905 and batch: 1100, loss is 3.7830910444259644 and perplexity is 43.951688604393645
At time: 822.8964879512787 and batch: 1150, loss is 3.7718042230606077 and perplexity is 43.45840279752699
At time: 824.2502133846283 and batch: 1200, loss is 3.8255823612213136 and perplexity is 45.85949938541313
At time: 825.6054394245148 and batch: 1250, loss is 3.802107672691345 and perplexity is 44.79549931660243
At time: 826.9552390575409 and batch: 1300, loss is 3.7904967784881594 and perplexity is 44.27839136550168
At time: 828.3059074878693 and batch: 1350, loss is 3.6675897312164305 and perplexity is 39.15741214029154
At time: 829.6591367721558 and batch: 1400, loss is 3.694602165222168 and perplexity is 40.22956468400398
At time: 831.0222499370575 and batch: 1450, loss is 3.6158824634552 and perplexity is 37.184145100645544
At time: 832.3868782520294 and batch: 1500, loss is 3.605053491592407 and perplexity is 36.78365142070869
At time: 833.7452325820923 and batch: 1550, loss is 3.633165593147278 and perplexity is 37.83238921026742
At time: 835.0967779159546 and batch: 1600, loss is 3.719884419441223 and perplexity is 41.259625022494255
At time: 836.4482977390289 and batch: 1650, loss is 3.6690046691894533 and perplexity is 39.21285666568611
At time: 837.798928976059 and batch: 1700, loss is 3.6590734243392946 and perplexity is 38.82535157379072
At time: 839.153591632843 and batch: 1750, loss is 3.660817928314209 and perplexity is 38.89314166678989
At time: 840.50790143013 and batch: 1800, loss is 3.613908667564392 and perplexity is 37.110823572512416
At time: 841.8581755161285 and batch: 1850, loss is 3.6239099979400633 and perplexity is 37.483843417607424
At time: 843.2080054283142 and batch: 1900, loss is 3.7386817121505738 and perplexity is 42.04252946069544
At time: 844.5603320598602 and batch: 1950, loss is 3.6817332315444946 and perplexity is 39.71517003852404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.311163755904796 and perplexity of 74.52716992687778
finished 15 epochs...
Completing Train Step...
At time: 848.8847494125366 and batch: 50, loss is 3.9072924852371216 and perplexity is 49.764032554866866
At time: 850.2525858879089 and batch: 100, loss is 3.8898994874954225 and perplexity is 48.90597061508556
At time: 851.6049149036407 and batch: 150, loss is 3.84450119972229 and perplexity is 46.735366922026046
At time: 852.974990606308 and batch: 200, loss is 3.845309844017029 and perplexity is 46.77317449422864
At time: 854.3312714099884 and batch: 250, loss is 3.8462488079071044 and perplexity is 46.817113441417064
At time: 855.685574054718 and batch: 300, loss is 3.8481012058258055 and perplexity is 46.903917738143306
At time: 857.0381627082825 and batch: 350, loss is 3.8641502332687376 and perplexity is 47.662752997275426
At time: 858.3890931606293 and batch: 400, loss is 3.8271797609329226 and perplexity is 45.932813877190306
At time: 859.7395634651184 and batch: 450, loss is 3.8827965688705444 and perplexity is 48.559826258424096
At time: 861.0911254882812 and batch: 500, loss is 3.890003480911255 and perplexity is 48.91105677848359
At time: 862.445404291153 and batch: 550, loss is 3.8563478899002077 and perplexity is 47.29231883897841
At time: 863.8003325462341 and batch: 600, loss is 3.82139723777771 and perplexity is 45.66797278021914
At time: 865.1497182846069 and batch: 650, loss is 3.8362082719802855 and perplexity is 46.34939652546497
At time: 866.5004155635834 and batch: 700, loss is 3.8797823762893677 and perplexity is 48.413677960581055
At time: 867.8533444404602 and batch: 750, loss is 3.8254457235336305 and perplexity is 45.853233677534476
At time: 869.2062146663666 and batch: 800, loss is 3.8187067794799803 and perplexity is 45.54527014109481
At time: 870.5626001358032 and batch: 850, loss is 3.812783808708191 and perplexity is 45.27630416238335
At time: 871.916330575943 and batch: 900, loss is 3.7707019805908204 and perplexity is 43.410527490240035
At time: 873.2669861316681 and batch: 950, loss is 3.8641061878204344 and perplexity is 47.66065371618452
At time: 874.6139612197876 and batch: 1000, loss is 3.8236470317840574 and perplexity is 45.770831974275474
At time: 875.9661872386932 and batch: 1050, loss is 3.7853975820541383 and perplexity is 44.05318183195934
At time: 877.318470954895 and batch: 1100, loss is 3.7775826930999754 and perplexity is 43.71025282919513
At time: 878.672201871872 and batch: 1150, loss is 3.7663752460479736 and perplexity is 43.2231074122726
At time: 880.0257971286774 and batch: 1200, loss is 3.821087832450867 and perplexity is 45.65384505188471
At time: 881.3762855529785 and batch: 1250, loss is 3.79802273273468 and perplexity is 44.61288562847635
At time: 882.7282123565674 and batch: 1300, loss is 3.787312183380127 and perplexity is 44.137606906699126
At time: 884.0782842636108 and batch: 1350, loss is 3.664964656829834 and perplexity is 39.054755819825914
At time: 885.4291052818298 and batch: 1400, loss is 3.6927504253387453 and perplexity is 40.155138924426346
At time: 886.7850439548492 and batch: 1450, loss is 3.6152642965316772 and perplexity is 37.161166195196245
At time: 888.1382899284363 and batch: 1500, loss is 3.605662603378296 and perplexity is 36.80606360138583
At time: 889.4898505210876 and batch: 1550, loss is 3.6349014139175413 and perplexity is 37.898116486129176
At time: 890.8398158550262 and batch: 1600, loss is 3.7228736209869386 and perplexity is 41.38314287529272
At time: 892.1906163692474 and batch: 1650, loss is 3.672559280395508 and perplexity is 39.35249115153896
At time: 893.5436496734619 and batch: 1700, loss is 3.6626037693023683 and perplexity is 38.96266068982113
At time: 894.8972389698029 and batch: 1750, loss is 3.6654873180389402 and perplexity is 39.07517356103991
At time: 896.2506201267242 and batch: 1800, loss is 3.6188363552093508 and perplexity is 37.29414542478494
At time: 897.5995724201202 and batch: 1850, loss is 3.6286393117904665 and perplexity is 37.66153612855261
At time: 898.9485976696014 and batch: 1900, loss is 3.7438027667999267 and perplexity is 42.25838378081046
At time: 900.29993724823 and batch: 1950, loss is 3.686353998184204 and perplexity is 39.89910921405037
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310514512172965 and perplexity of 74.47879933280322
finished 16 epochs...
Completing Train Step...
At time: 904.6076724529266 and batch: 50, loss is 3.907884955406189 and perplexity is 49.79352499548106
At time: 905.9755029678345 and batch: 100, loss is 3.888574275970459 and perplexity is 48.84120278420359
At time: 907.3248703479767 and batch: 150, loss is 3.8425002336502074 and perplexity is 46.641944537130904
At time: 908.6746151447296 and batch: 200, loss is 3.842298302650452 and perplexity is 46.63252703351493
At time: 910.0209786891937 and batch: 250, loss is 3.8427221250534056 and perplexity is 46.652295131963676
At time: 911.3677067756653 and batch: 300, loss is 3.844178943634033 and perplexity is 46.72030859194809
At time: 912.7146673202515 and batch: 350, loss is 3.8598898315429686 and perplexity is 47.46012247236578
At time: 914.0636625289917 and batch: 400, loss is 3.8221002435684204 and perplexity is 45.700088917126045
At time: 915.4180812835693 and batch: 450, loss is 3.877716426849365 and perplexity is 48.31376099694582
At time: 916.7732620239258 and batch: 500, loss is 3.884746747016907 and perplexity is 48.65461897168042
At time: 918.1242492198944 and batch: 550, loss is 3.850861306190491 and perplexity is 47.03355608371958
At time: 919.4749803543091 and batch: 600, loss is 3.8162633657455443 and perplexity is 45.43412005062196
At time: 920.8738787174225 and batch: 650, loss is 3.831582818031311 and perplexity is 46.13550458129084
At time: 922.2274277210236 and batch: 700, loss is 3.875499701499939 and perplexity is 48.20678127435629
At time: 923.5823376178741 and batch: 750, loss is 3.821260886192322 and perplexity is 45.66174630423367
At time: 924.9347865581512 and batch: 800, loss is 3.814878697395325 and perplexity is 45.371252398036894
At time: 926.285825252533 and batch: 850, loss is 3.809222378730774 and perplexity is 45.11534257232227
At time: 927.6369016170502 and batch: 900, loss is 3.7674527072906496 and perplexity is 43.269703733654616
At time: 928.9916470050812 and batch: 950, loss is 3.8608922147750855 and perplexity is 47.50771955459951
At time: 930.3529767990112 and batch: 1000, loss is 3.820485820770264 and perplexity is 45.626369175128225
At time: 931.705958366394 and batch: 1050, loss is 3.7825652885437013 and perplexity is 43.9285868190564
At time: 933.0580153465271 and batch: 1100, loss is 3.775237703323364 and perplexity is 43.60787282013031
At time: 934.4080872535706 and batch: 1150, loss is 3.764057321548462 and perplexity is 43.12303553698767
At time: 935.760073184967 and batch: 1200, loss is 3.819009246826172 and perplexity is 45.55904818168461
At time: 937.1119046211243 and batch: 1250, loss is 3.7960582113265993 and perplexity is 44.52532869148089
At time: 938.4658408164978 and batch: 1300, loss is 3.7858291482925415 and perplexity is 44.072197800962215
At time: 939.8189055919647 and batch: 1350, loss is 3.6638038206100463 and perplexity is 39.00944594847326
At time: 941.1691415309906 and batch: 1400, loss is 3.6918587779998777 and perplexity is 40.11935065928929
At time: 942.5214130878448 and batch: 1450, loss is 3.61507119178772 and perplexity is 37.15399089052794
At time: 943.8708896636963 and batch: 1500, loss is 3.606000599861145 and perplexity is 36.81850602405972
At time: 945.2240891456604 and batch: 1550, loss is 3.6357591915130616 and perplexity is 37.93063858773435
At time: 946.5782780647278 and batch: 1600, loss is 3.724322786331177 and perplexity is 41.443157366740905
At time: 947.9312632083893 and batch: 1650, loss is 3.674181094169617 and perplexity is 39.41636534575745
At time: 949.2813692092896 and batch: 1700, loss is 3.664271502494812 and perplexity is 39.02769422654003
At time: 950.6318509578705 and batch: 1750, loss is 3.667639102935791 and perplexity is 39.159345456779796
At time: 951.983598947525 and batch: 1800, loss is 3.6209956550598146 and perplexity is 37.37476167342739
At time: 953.3403072357178 and batch: 1850, loss is 3.630683603286743 and perplexity is 37.738606036435165
At time: 954.6959822177887 and batch: 1900, loss is 3.7458810377120972 and perplexity is 42.34629947528888
At time: 956.0506691932678 and batch: 1950, loss is 3.6880373191833495 and perplexity is 39.96632878262063
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31024652525436 and perplexity of 74.4588426630513
finished 17 epochs...
Completing Train Step...
At time: 960.3798487186432 and batch: 50, loss is 3.9071328926086424 and perplexity is 49.75609121581415
At time: 961.7360122203827 and batch: 100, loss is 3.88683002948761 and perplexity is 48.75608594198538
At time: 963.0898847579956 and batch: 150, loss is 3.8403884506225587 and perplexity is 46.54355079995957
At time: 964.4406337738037 and batch: 200, loss is 3.839709897041321 and perplexity is 46.511979219596576
At time: 965.7925145626068 and batch: 250, loss is 3.839777150154114 and perplexity is 46.51510740017002
At time: 967.1455407142639 and batch: 300, loss is 3.841036992073059 and perplexity is 46.57374601227185
At time: 968.5012636184692 and batch: 350, loss is 3.8566712760925292 and perplexity is 47.30761499504334
At time: 969.8576588630676 and batch: 400, loss is 3.8185245418548583 and perplexity is 45.5369708354746
At time: 971.2096025943756 and batch: 450, loss is 3.8741231775283813 and perplexity is 48.14046913493604
At time: 972.5599892139435 and batch: 500, loss is 3.8811524295806885 and perplexity is 48.480052737524325
At time: 973.9098217487335 and batch: 550, loss is 3.847150454521179 and perplexity is 46.85934496932827
At time: 975.2615714073181 and batch: 600, loss is 3.8127870035171507 and perplexity is 45.27644881175661
At time: 976.6162476539612 and batch: 650, loss is 3.8283835887908935 and perplexity is 45.988142374441985
At time: 977.9686887264252 and batch: 700, loss is 3.872512493133545 and perplexity is 48.06299244453824
At time: 979.3185610771179 and batch: 750, loss is 3.8184417915344238 and perplexity is 45.53320279245188
At time: 980.6692926883698 and batch: 800, loss is 3.8123376178741455 and perplexity is 45.25610679674143
At time: 982.0191044807434 and batch: 850, loss is 3.8068140745162964 and perplexity is 45.00682183059862
At time: 983.3722186088562 and batch: 900, loss is 3.7652995443344115 and perplexity is 43.17663724006669
At time: 984.72780418396 and batch: 950, loss is 3.8587595224380493 and perplexity is 47.40650816988994
At time: 986.0827004909515 and batch: 1000, loss is 3.818405337333679 and perplexity is 45.5315429461911
At time: 987.4507856369019 and batch: 1050, loss is 3.780706706047058 and perplexity is 43.84701774140276
At time: 988.8014900684357 and batch: 1100, loss is 3.7736498594284056 and perplexity is 43.53868526955221
At time: 990.152272939682 and batch: 1150, loss is 3.7625190782547 and perplexity is 43.05675280931671
At time: 991.5059385299683 and batch: 1200, loss is 3.817572526931763 and perplexity is 45.493639588956036
At time: 992.859837770462 and batch: 1250, loss is 3.7946848678588867 and perplexity is 44.46422209195362
At time: 994.2163722515106 and batch: 1300, loss is 3.784732837677002 and perplexity is 44.02390745810728
At time: 995.5727932453156 and batch: 1350, loss is 3.662919869422913 and perplexity is 38.97497873832766
At time: 996.9394845962524 and batch: 1400, loss is 3.6911140155792235 and perplexity is 40.089482398336955
At time: 998.290668964386 and batch: 1450, loss is 3.6147408294677734 and perplexity is 37.14171863915841
At time: 999.6429557800293 and batch: 1500, loss is 3.6059789562225344 and perplexity is 36.81770914624485
At time: 1000.9930202960968 and batch: 1550, loss is 3.636060347557068 and perplexity is 37.94206334902968
At time: 1002.3429455757141 and batch: 1600, loss is 3.7249346351623536 and perplexity is 41.468522073027664
At time: 1003.6950013637543 and batch: 1650, loss is 3.6748630475997923 and perplexity is 39.443254638890785
At time: 1005.045841217041 and batch: 1700, loss is 3.6650345516204834 and perplexity is 39.057485639206774
At time: 1006.3979449272156 and batch: 1750, loss is 3.668628249168396 and perplexity is 39.19809893908043
At time: 1007.7479107379913 and batch: 1800, loss is 3.6219636583328247 and perplexity is 37.41095808134949
At time: 1009.0993885993958 and batch: 1850, loss is 3.6315884685516355 and perplexity is 37.77276984467363
At time: 1010.4531767368317 and batch: 1900, loss is 3.7467630672454835 and perplexity is 42.38366663910417
At time: 1011.8043327331543 and batch: 1950, loss is 3.688628468513489 and perplexity is 39.98996183575214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310143475199855 and perplexity of 74.45117007059378
finished 18 epochs...
Completing Train Step...
At time: 1016.1323366165161 and batch: 50, loss is 3.90590048789978 and perplexity is 49.69480934449494
At time: 1017.4825670719147 and batch: 100, loss is 3.8849923515319826 and perplexity is 48.66657023336099
At time: 1018.8334300518036 and batch: 150, loss is 3.8383482789993284 and perplexity is 46.44869076665017
At time: 1020.1850588321686 and batch: 200, loss is 3.8374110507965087 and perplexity is 46.405178137496335
At time: 1021.5554678440094 and batch: 250, loss is 3.837226004600525 and perplexity is 46.3965918302643
At time: 1022.9057960510254 and batch: 300, loss is 3.838356909751892 and perplexity is 46.44909165553707
At time: 1024.25687789917 and batch: 350, loss is 3.8539910316467285 and perplexity is 47.180988793099836
At time: 1025.6109080314636 and batch: 400, loss is 3.8156574821472167 and perplexity is 45.40660060011254
At time: 1026.9674215316772 and batch: 450, loss is 3.8712488651275634 and perplexity is 48.002297057505785
At time: 1028.3238079547882 and batch: 500, loss is 3.8783252239227295 and perplexity is 48.34318322841945
At time: 1029.6796011924744 and batch: 550, loss is 3.844274435043335 and perplexity is 46.72477019307746
At time: 1031.0335190296173 and batch: 600, loss is 3.8101036405563353 and perplexity is 45.15511852541866
At time: 1032.3842902183533 and batch: 650, loss is 3.8258741760253905 and perplexity is 45.87288381903431
At time: 1033.7346985340118 and batch: 700, loss is 3.870152683258057 and perplexity is 47.949706639374234
At time: 1035.086009979248 and batch: 750, loss is 3.8162272691726686 and perplexity is 45.43248006419563
At time: 1036.4368295669556 and batch: 800, loss is 3.8103329515457154 and perplexity is 45.165474277621804
At time: 1037.787608385086 and batch: 850, loss is 3.804881887435913 and perplexity is 44.919944189884596
At time: 1039.1387960910797 and batch: 900, loss is 3.763568139076233 and perplexity is 43.10194566267267
At time: 1040.4910800457 and batch: 950, loss is 3.857049279212952 and perplexity is 47.32550080136354
At time: 1041.8396878242493 and batch: 1000, loss is 3.816740894317627 and perplexity is 45.455821322169776
At time: 1043.192165851593 and batch: 1050, loss is 3.7791900491714476 and perplexity is 43.78056726449431
At time: 1044.5417969226837 and batch: 1100, loss is 3.772303957939148 and perplexity is 43.480125904615626
At time: 1045.8905427455902 and batch: 1150, loss is 3.7612315225601196 and perplexity is 43.00135051646959
At time: 1047.2398657798767 and batch: 1200, loss is 3.816347432136536 and perplexity is 45.43793969367204
At time: 1048.5914554595947 and batch: 1250, loss is 3.7935159969329835 and perplexity is 44.41227951850331
At time: 1049.9403200149536 and batch: 1300, loss is 3.783761377334595 and perplexity is 43.981160744624184
At time: 1051.292277097702 and batch: 1350, loss is 3.662097234725952 and perplexity is 38.9429297526154
At time: 1052.6417920589447 and batch: 1400, loss is 3.6903768396377563 and perplexity is 40.05994028661188
At time: 1053.9912021160126 and batch: 1450, loss is 3.614275631904602 and perplexity is 37.124444420429235
At time: 1055.3410382270813 and batch: 1500, loss is 3.60572124004364 and perplexity is 36.808221849495474
At time: 1056.6897840499878 and batch: 1550, loss is 3.63603168964386 and perplexity is 37.94097602425159
At time: 1058.039421081543 and batch: 1600, loss is 3.7250904417037964 and perplexity is 41.47498364339501
At time: 1059.3914303779602 and batch: 1650, loss is 3.675052342414856 and perplexity is 39.4507217492035
At time: 1060.7432610988617 and batch: 1700, loss is 3.6653185892105102 and perplexity is 39.068581008976686
At time: 1062.0944118499756 and batch: 1750, loss is 3.669025058746338 and perplexity is 39.21365620660882
At time: 1063.445954799652 and batch: 1800, loss is 3.622347979545593 and perplexity is 37.425338669335645
At time: 1064.7990341186523 and batch: 1850, loss is 3.6319408893585203 and perplexity is 37.786084100673186
At time: 1066.152025938034 and batch: 1900, loss is 3.7470959568023683 and perplexity is 42.39777806775412
At time: 1067.509390592575 and batch: 1950, loss is 3.6887415075302123 and perplexity is 39.99448251721874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.310132971475291 and perplexity of 74.45038806011691
finished 19 epochs...
Completing Train Step...
At time: 1071.8577280044556 and batch: 50, loss is 3.904498038291931 and perplexity is 49.625163727267214
At time: 1073.2146422863007 and batch: 100, loss is 3.883183755874634 and perplexity is 48.57863163243548
At time: 1074.5641322135925 and batch: 150, loss is 3.836416401863098 and perplexity is 46.359044223884595
At time: 1075.91428399086 and batch: 200, loss is 3.835324935913086 and perplexity is 46.30847250931186
At time: 1077.2656924724579 and batch: 250, loss is 3.8349567890167235 and perplexity is 46.29142732664033
At time: 1078.6163721084595 and batch: 300, loss is 3.8359887075424193 and perplexity is 46.339220963408074
At time: 1079.9669737815857 and batch: 350, loss is 3.8516486406326296 and perplexity is 47.07060180413266
At time: 1081.316597700119 and batch: 400, loss is 3.8132014751434324 and perplexity is 45.29521850461174
At time: 1082.6675219535828 and batch: 450, loss is 3.8687944841384887 and perplexity is 47.88462559654523
At time: 1084.0186476707458 and batch: 500, loss is 3.87592764377594 and perplexity is 48.227415408847854
At time: 1085.3694994449615 and batch: 550, loss is 3.8418575954437255 and perplexity is 46.61198027066919
At time: 1086.7202095985413 and batch: 600, loss is 3.807854914665222 and perplexity is 45.05369112522593
At time: 1088.0723135471344 and batch: 650, loss is 3.8237453269958497 and perplexity is 45.77533124902325
At time: 1089.440134048462 and batch: 700, loss is 3.868140697479248 and perplexity is 47.85332949874785
At time: 1090.7904069423676 and batch: 750, loss is 3.8143271923065187 and perplexity is 45.34623682019716
At time: 1092.1393418312073 and batch: 800, loss is 3.8085933828353884 and perplexity is 45.086974129777616
At time: 1093.4879705905914 and batch: 850, loss is 3.8031876468658448 and perplexity is 44.843903431890745
At time: 1094.8414330482483 and batch: 900, loss is 3.7620353841781617 and perplexity is 43.03593154899397
At time: 1096.1953628063202 and batch: 950, loss is 3.8555378246307375 and perplexity is 47.25402448653079
At time: 1097.5445806980133 and batch: 1000, loss is 3.815270004272461 and perplexity is 45.38900995522506
At time: 1098.8947732448578 and batch: 1050, loss is 3.777826542854309 and perplexity is 43.72091286327992
At time: 1100.244217157364 and batch: 1100, loss is 3.7710565233230593 and perplexity is 43.425921105950394
At time: 1101.5954549312592 and batch: 1150, loss is 3.7600423669815064 and perplexity is 42.95024561247812
At time: 1102.9449980258942 and batch: 1200, loss is 3.815206542015076 and perplexity is 45.38612955759206
At time: 1104.2951912879944 and batch: 1250, loss is 3.7924318218231203 and perplexity is 44.364154922935356
At time: 1105.6447343826294 and batch: 1300, loss is 3.7828384971618654 and perplexity is 43.94059012718809
At time: 1106.9953496456146 and batch: 1350, loss is 3.6612842988967897 and perplexity is 38.911284514243754
At time: 1108.3439009189606 and batch: 1400, loss is 3.6896202087402346 and perplexity is 40.02964116211053
At time: 1109.6936357021332 and batch: 1450, loss is 3.6137149333953857 and perplexity is 37.103634634340416
At time: 1111.0458414554596 and batch: 1500, loss is 3.6053117895126343 and perplexity is 36.79315378853712
At time: 1112.396411895752 and batch: 1550, loss is 3.6357974767684937 and perplexity is 37.93209079972036
At time: 1113.7486395835876 and batch: 1600, loss is 3.7249793004989624 and perplexity is 41.470374319890034
At time: 1115.0989682674408 and batch: 1650, loss is 3.674959325790405 and perplexity is 39.447052346894594
At time: 1116.4588038921356 and batch: 1700, loss is 3.665321741104126 and perplexity is 39.06870414918181
At time: 1117.813913822174 and batch: 1750, loss is 3.6690884017944336 and perplexity is 39.21614019779088
At time: 1119.1648375988007 and batch: 1800, loss is 3.622411637306213 and perplexity is 37.42772115841694
At time: 1120.5180096626282 and batch: 1850, loss is 3.6319928646087645 and perplexity is 37.78804809288911
At time: 1121.8714158535004 and batch: 1900, loss is 3.7471422243118284 and perplexity is 42.39973975273274
At time: 1123.21896982193 and batch: 1950, loss is 3.6886155366897584 and perplexity is 39.989444695958476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3101803801780525 and perplexity of 74.45391774010307
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fa20428cb38>
ELAPSED
6994.8307247161865


RESULTS SO FAR:
[{'best_accuracy': -74.4178468006303, 'params': {'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}}, {'best_accuracy': -77.53052041197337, 'params': {'dropout': 0.9649993788704626, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.2039606990300309, 'data': 'wikitext'}}, {'best_accuracy': -74.84239854569978, 'params': {'dropout': 0.18248612094762118, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.031083902810406072, 'data': 'wikitext'}}, {'best_accuracy': -75.19043835982198, 'params': {'dropout': 0.6426102732804025, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.040188596927537734, 'data': 'wikitext'}}, {'best_accuracy': -74.70754058646293, 'params': {'dropout': 0.28425270504382827, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.42033359040349494, 'data': 'wikitext'}}, {'best_accuracy': -74.45038806011691, 'params': {'dropout': 0.3924988781453342, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.6338794062420806, 'data': 'wikitext'}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -74.4178468006303, 'params': {'dropout': 0.5292933473333308, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.5499624419708893, 'data': 'wikitext'}}, {'best_accuracy': -77.53052041197337, 'params': {'dropout': 0.9649993788704626, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.2039606990300309, 'data': 'wikitext'}}, {'best_accuracy': -74.84239854569978, 'params': {'dropout': 0.18248612094762118, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.031083902810406072, 'data': 'wikitext'}}, {'best_accuracy': -75.19043835982198, 'params': {'dropout': 0.6426102732804025, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.040188596927537734, 'data': 'wikitext'}}, {'best_accuracy': -74.70754058646293, 'params': {'dropout': 0.28425270504382827, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.42033359040349494, 'data': 'wikitext'}}, {'best_accuracy': -74.45038806011691, 'params': {'dropout': 0.3924988781453342, 'seq_len': 35, 'wordvec_source': 'gigavec', 'tie_weights': 'FALSE', 'tune_wordvecs': 'TRUE', 'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'rnn_dropout': 0.6338794062420806, 'data': 'wikitext'}}]
