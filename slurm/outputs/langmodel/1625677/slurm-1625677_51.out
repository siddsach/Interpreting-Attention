FALSE
TRUE
Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'domain': [0, 1], 'type': 'continuous'}, {'name': 'rnn_dropout', 'domain': [0, 1], 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.3272247314453125 and batch: 50, loss is 7.609661874771118 and perplexity is 2017.5957823335978
At time: 3.853403091430664 and batch: 100, loss is 6.671726188659668 and perplexity is 789.7576992924896
At time: 5.386689186096191 and batch: 150, loss is 6.446861257553101 and perplexity is 630.7195166092788
At time: 6.917869806289673 and batch: 200, loss is 6.26370602607727 and perplexity is 525.1616006960855
At time: 8.451156854629517 and batch: 250, loss is 6.14517237663269 and perplexity is 466.46004894588003
At time: 9.991337060928345 and batch: 300, loss is 6.057204875946045 and perplexity is 427.1797462019229
At time: 11.525903940200806 and batch: 350, loss is 5.987490968704224 and perplexity is 398.41372232503977
At time: 13.058441162109375 and batch: 400, loss is 5.924014234542847 and perplexity is 373.9096663970514
At time: 14.592355251312256 and batch: 450, loss is 5.8606696128845215 and perplexity is 350.95907207230925
At time: 16.126681327819824 and batch: 500, loss is 5.821561250686646 and perplexity is 337.4985623793075
At time: 17.659929990768433 and batch: 550, loss is 5.770132131576538 and perplexity is 320.58008860152904
At time: 19.195290327072144 and batch: 600, loss is 5.803323755264282 and perplexity is 331.39922130099586
At time: 20.728460550308228 and batch: 650, loss is 5.882586660385132 and perplexity is 358.7359707497499
At time: 22.262355089187622 and batch: 700, loss is 5.782655239105225 and perplexity is 324.61999078997894
At time: 23.799463510513306 and batch: 750, loss is 5.724359149932861 and perplexity is 306.2369503756762
At time: 25.33538508415222 and batch: 800, loss is 5.720755367279053 and perplexity is 305.13532516712246
At time: 26.870054721832275 and batch: 850, loss is 5.734667081832885 and perplexity is 309.4099454187391
At time: 28.407283782958984 and batch: 900, loss is 5.726079063415527 and perplexity is 306.76410463542925
At time: 29.942723751068115 and batch: 950, loss is 5.752994060516357 and perplexity is 315.13277580791583
At time: 31.478074073791504 and batch: 1000, loss is 5.72371955871582 and perplexity is 306.0411465357655
At time: 33.011735916137695 and batch: 1050, loss is 5.626424026489258 and perplexity is 277.66740886802774
At time: 34.5498526096344 and batch: 1100, loss is 5.713838815689087 and perplexity is 303.0321227870956
At time: 36.088135719299316 and batch: 1150, loss is 5.6185549545288085 and perplexity is 275.4909984423833
At time: 37.623005628585815 and batch: 1200, loss is 5.688103456497192 and perplexity is 295.33297732699975
At time: 39.163536071777344 and batch: 1250, loss is 5.623487787246704 and perplexity is 276.8533067099816
At time: 40.70310878753662 and batch: 1300, loss is 5.638073682785034 and perplexity is 280.92105387173154
At time: 42.24369716644287 and batch: 1350, loss is 5.606497011184692 and perplexity is 272.18909070592474
At time: 43.78532838821411 and batch: 1400, loss is 5.626215476989746 and perplexity is 277.6095075067372
At time: 45.32619571685791 and batch: 1450, loss is 5.591092805862427 and perplexity is 268.0283626949405
At time: 46.86542248725891 and batch: 1500, loss is 5.560151634216308 and perplexity is 259.8622373423115
At time: 48.4050178527832 and batch: 1550, loss is 5.540797252655029 and perplexity is 254.8811231294844
At time: 49.9454071521759 and batch: 1600, loss is 5.5658941650390625 and perplexity is 261.3587971577272
At time: 51.486719608306885 and batch: 1650, loss is 5.547308292388916 and perplexity is 256.5460786634606
At time: 53.02713370323181 and batch: 1700, loss is 5.552828531265259 and perplexity is 257.96619037214566
At time: 54.565584897994995 and batch: 1750, loss is 5.573327989578247 and perplexity is 263.3089320974076
At time: 56.10552477836609 and batch: 1800, loss is 5.574866380691528 and perplexity is 263.7143159581082
At time: 57.6452419757843 and batch: 1850, loss is 5.544575777053833 and perplexity is 255.84601946619404
At time: 59.18571186065674 and batch: 1900, loss is 5.537840690612793 and perplexity is 254.12866416947685
At time: 60.724724531173706 and batch: 1950, loss is 5.472825336456299 and perplexity is 238.13204636000364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.0748024164244185 and perplexity of 159.9405872240947
finished 1 epochs...
Completing Train Step...
At time: 64.77687954902649 and batch: 50, loss is 5.332226943969727 and perplexity is 206.89821222997554
At time: 66.09342575073242 and batch: 100, loss is 5.269146299362182 and perplexity is 194.25006023973648
At time: 67.4097146987915 and batch: 150, loss is 5.177873744964599 and perplexity is 177.3054133857507
At time: 68.72476959228516 and batch: 200, loss is 5.153691987991333 and perplexity is 173.06928194347904
At time: 70.04227495193481 and batch: 250, loss is 5.149081516265869 and perplexity is 172.27318750815257
At time: 71.35710382461548 and batch: 300, loss is 5.164948396682739 and perplexity is 175.0284262913402
At time: 72.68553972244263 and batch: 350, loss is 5.12999135017395 and perplexity is 169.01565608253946
At time: 74.00137639045715 and batch: 400, loss is 5.084796304702759 and perplexity is 161.54702951574032
At time: 75.31713128089905 and batch: 450, loss is 5.045709171295166 and perplexity is 155.35443304635584
At time: 76.6320629119873 and batch: 500, loss is 5.031722459793091 and perplexity is 153.19666065734194
At time: 77.94771385192871 and batch: 550, loss is 4.976587343215942 and perplexity is 144.97877366912522
At time: 79.26334619522095 and batch: 600, loss is 4.973163013458252 and perplexity is 144.4831675838406
At time: 80.57627654075623 and batch: 650, loss is 5.047668828964233 and perplexity is 155.659173048016
At time: 81.88941621780396 and batch: 700, loss is 5.024790267944336 and perplexity is 152.13834447860748
At time: 83.20207858085632 and batch: 750, loss is 4.979083766937256 and perplexity is 145.3411542583491
At time: 84.51436305046082 and batch: 800, loss is 4.971368646621704 and perplexity is 144.22414424043666
At time: 85.82808685302734 and batch: 850, loss is 4.960652809143067 and perplexity is 142.6869128211781
At time: 87.14171004295349 and batch: 900, loss is 4.9605388164520265 and perplexity is 142.67064848303482
At time: 88.46492862701416 and batch: 950, loss is 5.018988618850708 and perplexity is 151.25824666819838
At time: 89.77873134613037 and batch: 1000, loss is 4.976019010543824 and perplexity is 144.89640090506913
At time: 91.09354662895203 and batch: 1050, loss is 4.896470394134521 and perplexity is 133.8166252065146
At time: 92.41015386581421 and batch: 1100, loss is 4.97104250907898 and perplexity is 144.1771150018496
At time: 93.72674250602722 and batch: 1150, loss is 4.876577768325806 and perplexity is 131.18096318746726
At time: 95.04356336593628 and batch: 1200, loss is 4.956917715072632 and perplexity is 142.15495784854173
At time: 96.35951805114746 and batch: 1250, loss is 4.906206045150757 and perplexity is 135.12577956423456
At time: 97.67474746704102 and batch: 1300, loss is 4.933865222930908 and perplexity is 138.91541502870925
At time: 98.99114298820496 and batch: 1350, loss is 4.843359327316284 and perplexity is 126.89491808618443
At time: 100.30862164497375 and batch: 1400, loss is 4.859283351898194 and perplexity is 128.93177028235283
At time: 101.62414121627808 and batch: 1450, loss is 4.799799356460571 and perplexity is 121.48603968419576
At time: 102.94172883033752 and batch: 1500, loss is 4.777266273498535 and perplexity is 118.77919597030858
At time: 104.25642943382263 and batch: 1550, loss is 4.770183801651001 and perplexity is 117.9409177039855
At time: 105.57059264183044 and batch: 1600, loss is 4.84384446144104 and perplexity is 126.9564940763055
At time: 106.88788866996765 and batch: 1650, loss is 4.78746259689331 and perplexity is 119.99650254432021
At time: 108.20583319664001 and batch: 1700, loss is 4.812820262908936 and perplexity is 123.0782415015354
At time: 109.52496862411499 and batch: 1750, loss is 4.825972318649292 and perplexity is 124.70766504119082
At time: 110.84652328491211 and batch: 1800, loss is 4.79676682472229 and perplexity is 121.11818745677769
At time: 112.17888808250427 and batch: 1850, loss is 4.797520217895507 and perplexity is 121.20947145441264
At time: 113.50712299346924 and batch: 1900, loss is 4.851724672317505 and perplexity is 127.96089025103939
At time: 114.82746648788452 and batch: 1950, loss is 4.768303728103637 and perplexity is 117.71938841538903
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.647796205032703 and perplexity of 104.35475549537237
finished 2 epochs...
Completing Train Step...
At time: 118.80372405052185 and batch: 50, loss is 4.732625970840454 and perplexity is 113.59346416128957
At time: 120.12085127830505 and batch: 100, loss is 4.679069023132325 and perplexity is 107.66978781544603
At time: 121.43609046936035 and batch: 150, loss is 4.624289474487305 and perplexity is 101.93032325183337
At time: 122.74965310096741 and batch: 200, loss is 4.612994461059571 and perplexity is 100.78549647008276
At time: 124.06618332862854 and batch: 250, loss is 4.623996562957764 and perplexity is 101.90047105718253
At time: 125.37885546684265 and batch: 300, loss is 4.647226581573486 and perplexity is 104.29532950538717
At time: 126.69177007675171 and batch: 350, loss is 4.652363901138306 and perplexity is 104.83250658590396
At time: 128.00660467147827 and batch: 400, loss is 4.615610160827637 and perplexity is 101.04946615203775
At time: 129.3225290775299 and batch: 450, loss is 4.603081274032593 and perplexity is 99.79132683026934
At time: 130.6430697441101 and batch: 500, loss is 4.61237117767334 and perplexity is 100.72269811717794
At time: 131.9575755596161 and batch: 550, loss is 4.568276348114014 and perplexity is 96.37784466869816
At time: 133.2730734348297 and batch: 600, loss is 4.549962844848633 and perplexity is 94.62889229878834
At time: 134.59066605567932 and batch: 650, loss is 4.612945785522461 and perplexity is 100.78059080130323
At time: 135.9081745147705 and batch: 700, loss is 4.632226314544678 and perplexity is 102.74254690536894
At time: 137.2254695892334 and batch: 750, loss is 4.592137584686279 and perplexity is 98.70519553170406
At time: 138.56656050682068 and batch: 800, loss is 4.571275510787964 and perplexity is 96.66733139492237
At time: 139.87988829612732 and batch: 850, loss is 4.569205989837647 and perplexity is 96.4674831937367
At time: 141.19590830802917 and batch: 900, loss is 4.556614112854004 and perplexity is 95.26039223207516
At time: 142.51229643821716 and batch: 950, loss is 4.6366408252716065 and perplexity is 103.197107574066
At time: 143.82959699630737 and batch: 1000, loss is 4.597777500152588 and perplexity is 99.26345728534251
At time: 145.14653754234314 and batch: 1050, loss is 4.540432615280151 and perplexity is 93.73134095987648
At time: 146.46244072914124 and batch: 1100, loss is 4.593573055267334 and perplexity is 98.8469856795326
At time: 147.77906775474548 and batch: 1150, loss is 4.522647829055786 and perplexity is 92.07908515679462
At time: 149.0963921546936 and batch: 1200, loss is 4.612619066238404 and perplexity is 100.7476692171808
At time: 150.4143521785736 and batch: 1250, loss is 4.568669080734253 and perplexity is 96.41570282574787
At time: 151.732191324234 and batch: 1300, loss is 4.589379653930664 and perplexity is 98.43334847719427
At time: 153.04814457893372 and batch: 1350, loss is 4.470560474395752 and perplexity is 87.40569794330189
At time: 154.36529111862183 and batch: 1400, loss is 4.497830400466919 and perplexity is 89.82204188396288
At time: 155.69180560112 and batch: 1450, loss is 4.434094133377076 and perplexity is 84.2757477127715
At time: 157.00844550132751 and batch: 1500, loss is 4.425764284133911 and perplexity is 83.57665913297247
At time: 158.32524609565735 and batch: 1550, loss is 4.434548873901367 and perplexity is 84.31408002543887
At time: 159.64229679107666 and batch: 1600, loss is 4.513941202163696 and perplexity is 91.28086685466559
At time: 160.9572458267212 and batch: 1650, loss is 4.461932783126831 and perplexity is 86.65483234227723
At time: 162.27195167541504 and batch: 1700, loss is 4.491718940734863 and perplexity is 89.27477210392306
At time: 163.58721661567688 and batch: 1750, loss is 4.49894567489624 and perplexity is 89.92227399323036
At time: 164.90370512008667 and batch: 1800, loss is 4.452098197937012 and perplexity is 85.8067948948628
At time: 166.2196762561798 and batch: 1850, loss is 4.482701387405395 and perplexity is 88.47335094522627
At time: 167.5356466770172 and batch: 1900, loss is 4.549922046661377 and perplexity is 94.62503169027394
At time: 168.8548891544342 and batch: 1950, loss is 4.477424945831299 and perplexity is 88.00775590083612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.528190293422965 and perplexity of 92.59084710636013
finished 3 epochs...
Completing Train Step...
At time: 172.82680892944336 and batch: 50, loss is 4.452928051948548 and perplexity is 85.87803156175208
At time: 174.15346312522888 and batch: 100, loss is 4.390325927734375 and perplexity is 80.66670621317078
At time: 175.46954464912415 and batch: 150, loss is 4.344837703704834 and perplexity is 77.07952674248303
At time: 176.785813331604 and batch: 200, loss is 4.350149564743042 and perplexity is 77.49005183828434
At time: 178.10313415527344 and batch: 250, loss is 4.354618244171142 and perplexity is 77.83710489571784
At time: 179.42172527313232 and batch: 300, loss is 4.38019401550293 and perplexity is 79.85352472401797
At time: 180.7392692565918 and batch: 350, loss is 4.386126136779785 and perplexity is 80.32863332472706
At time: 182.05663466453552 and batch: 400, loss is 4.344731225967407 and perplexity is 77.07131992580292
At time: 183.37195801734924 and batch: 450, loss is 4.355888204574585 and perplexity is 77.9360177312524
At time: 184.68969678878784 and batch: 500, loss is 4.3690544128417965 and perplexity is 78.9689243831976
At time: 186.0062916278839 and batch: 550, loss is 4.330075988769531 and perplexity is 75.95005770134446
At time: 187.32344317436218 and batch: 600, loss is 4.311251010894775 and perplexity is 74.53367307805499
At time: 188.63889265060425 and batch: 650, loss is 4.367817783355713 and perplexity is 78.87132943965078
At time: 189.96266531944275 and batch: 700, loss is 4.399864683151245 and perplexity is 81.43984773576753
At time: 191.27957201004028 and batch: 750, loss is 4.360593595504761 and perplexity is 78.30360129619235
At time: 192.59713053703308 and batch: 800, loss is 4.336499271392822 and perplexity is 76.43947654225842
At time: 193.913311958313 and batch: 850, loss is 4.336250352859497 and perplexity is 76.42045170778457
At time: 195.22907257080078 and batch: 900, loss is 4.310483684539795 and perplexity is 74.4765033630883
At time: 196.54458737373352 and batch: 950, loss is 4.395825338363648 and perplexity is 81.11154761638832
At time: 197.86185503005981 and batch: 1000, loss is 4.371637554168701 and perplexity is 79.17317596709235
At time: 199.19377398490906 and batch: 1050, loss is 4.321523160934448 and perplexity is 75.30323993718406
At time: 200.5210566520691 and batch: 1100, loss is 4.361423425674438 and perplexity is 78.36860695504043
At time: 201.83703804016113 and batch: 1150, loss is 4.299201393127442 and perplexity is 73.64096003345311
At time: 203.18379592895508 and batch: 1200, loss is 4.391904673576355 and perplexity is 80.79415902151428
At time: 204.49868607521057 and batch: 1250, loss is 4.354200925827026 and perplexity is 77.80462882089418
At time: 205.81797170639038 and batch: 1300, loss is 4.367956600189209 and perplexity is 78.88227886782208
At time: 207.1360559463501 and batch: 1350, loss is 4.238169593811035 and perplexity is 69.2809234778537
At time: 208.45371532440186 and batch: 1400, loss is 4.275314283370972 and perplexity is 71.90273359246491
At time: 209.77327418327332 and batch: 1450, loss is 4.209709415435791 and perplexity is 67.33696988284632
At time: 211.09884190559387 and batch: 1500, loss is 4.2066303777694705 and perplexity is 67.12995568205136
At time: 212.42537236213684 and batch: 1550, loss is 4.2200167274475096 and perplexity is 68.03462232547521
At time: 213.75128960609436 and batch: 1600, loss is 4.306282482147217 and perplexity is 74.1642688384319
At time: 215.07821989059448 and batch: 1650, loss is 4.249546041488648 and perplexity is 70.07359462057141
At time: 216.40132784843445 and batch: 1700, loss is 4.284732608795166 and perplexity is 72.58313603255218
At time: 217.72478580474854 and batch: 1750, loss is 4.287458548545837 and perplexity is 72.78126320697582
At time: 219.04981136322021 and batch: 1800, loss is 4.2440293455123905 and perplexity is 69.68808425255021
At time: 220.37675380706787 and batch: 1850, loss is 4.27559760093689 and perplexity is 71.92310778597636
At time: 221.70259428024292 and batch: 1900, loss is 4.34977276802063 and perplexity is 77.4608593408962
At time: 223.02730250358582 and batch: 1950, loss is 4.288480243682861 and perplexity is 72.85566146936051
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.471404603470203 and perplexity of 87.47951078360786
finished 4 epochs...
Completing Train Step...
At time: 226.98617792129517 and batch: 50, loss is 4.2641218519210815 and perplexity is 71.10245406680608
At time: 228.3188292980194 and batch: 100, loss is 4.2001289367675785 and perplexity is 66.69492991523484
At time: 229.6385154724121 and batch: 150, loss is 4.157158818244934 and perplexity is 63.88974211688473
At time: 230.95537066459656 and batch: 200, loss is 4.165837988853455 and perplexity is 64.44666540899676
At time: 232.28141593933105 and batch: 250, loss is 4.16841151714325 and perplexity is 64.61273432548022
At time: 233.59931182861328 and batch: 300, loss is 4.190222945213318 and perplexity is 66.03751206656352
At time: 234.91840648651123 and batch: 350, loss is 4.194270062446594 and perplexity is 66.30531516943483
At time: 236.24879002571106 and batch: 400, loss is 4.158330569267273 and perplexity is 63.964648864985904
At time: 237.56583976745605 and batch: 450, loss is 4.178993511199951 and perplexity is 65.30009631218806
At time: 238.88520503044128 and batch: 500, loss is 4.191158366203308 and perplexity is 66.09931384231002
At time: 240.21066975593567 and batch: 550, loss is 4.15923164844513 and perplexity is 64.02231205384487
At time: 241.53084707260132 and batch: 600, loss is 4.138424301147461 and perplexity is 62.70394103884112
At time: 242.85052967071533 and batch: 650, loss is 4.192585363388061 and perplexity is 66.19370470880997
At time: 244.16970419883728 and batch: 700, loss is 4.224918389320374 and perplexity is 68.36892368654568
At time: 245.48565578460693 and batch: 750, loss is 4.191800379753113 and perplexity is 66.14176412279912
At time: 246.80405259132385 and batch: 800, loss is 4.163717851638794 and perplexity is 64.31017437628837
At time: 248.12404036521912 and batch: 850, loss is 4.165116190910339 and perplexity is 64.4001647225327
At time: 249.45049500465393 and batch: 900, loss is 4.137438859939575 and perplexity is 62.64218042716841
At time: 250.7731475830078 and batch: 950, loss is 4.227954025268555 and perplexity is 68.57678218076614
At time: 252.10122179985046 and batch: 1000, loss is 4.206925659179688 and perplexity is 67.14978083688878
At time: 253.42021298408508 and batch: 1050, loss is 4.159659023284912 and perplexity is 64.04967942684817
At time: 254.73821902275085 and batch: 1100, loss is 4.196320929527283 and perplexity is 66.44143809489218
At time: 256.05900144577026 and batch: 1150, loss is 4.1412187099456785 and perplexity is 62.8794065303395
At time: 257.37827920913696 and batch: 1200, loss is 4.230603923797608 and perplexity is 68.75874467959532
At time: 258.69430780410767 and batch: 1250, loss is 4.197019457817078 and perplexity is 66.48786553256761
At time: 260.01260781288147 and batch: 1300, loss is 4.203640928268433 and perplexity is 66.92957373462059
At time: 261.33221459388733 and batch: 1350, loss is 4.075550746917725 and perplexity is 58.882901236104466
At time: 262.650808095932 and batch: 1400, loss is 4.112006244659423 and perplexity is 61.069114334129125
At time: 263.9692997932434 and batch: 1450, loss is 4.047988982200622 and perplexity is 57.2821457231114
At time: 265.2877445220947 and batch: 1500, loss is 4.043499994277954 and perplexity is 57.02558314676197
At time: 266.6068706512451 and batch: 1550, loss is 4.060468873977661 and perplexity is 58.00150009841079
At time: 267.92479038238525 and batch: 1600, loss is 4.149517192840576 and perplexity is 63.40338130075883
At time: 269.2437891960144 and batch: 1650, loss is 4.095559616088867 and perplexity is 60.072947540626906
At time: 270.5637822151184 and batch: 1700, loss is 4.132562036514282 and perplexity is 62.337429287000866
At time: 271.8826789855957 and batch: 1750, loss is 4.133750376701355 and perplexity is 62.41155139179668
At time: 273.20013427734375 and batch: 1800, loss is 4.092975306510925 and perplexity is 59.91790087750268
At time: 274.51967310905457 and batch: 1850, loss is 4.118775591850281 and perplexity is 61.48391475173041
At time: 275.8403503894806 and batch: 1900, loss is 4.198524713516235 and perplexity is 66.58802213282083
At time: 277.1593658924103 and batch: 1950, loss is 4.140480451583862 and perplexity is 62.83300241390353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.457963242641715 and perplexity of 86.31153429559704
finished 5 epochs...
Completing Train Step...
At time: 281.1221718788147 and batch: 50, loss is 4.115993599891663 and perplexity is 61.313104701564804
At time: 282.4510180950165 and batch: 100, loss is 4.0576122808456425 and perplexity is 57.836049836132226
At time: 283.7706105709076 and batch: 150, loss is 4.014438457489014 and perplexity is 55.39218160270465
At time: 285.09129571914673 and batch: 200, loss is 4.0242800664901734 and perplexity is 55.94002118539718
At time: 286.4087073802948 and batch: 250, loss is 4.019054365158081 and perplexity is 55.64845781721177
At time: 287.7268645763397 and batch: 300, loss is 4.0425298261642455 and perplexity is 56.970285572636236
At time: 289.0456790924072 and batch: 350, loss is 4.052353296279907 and perplexity is 57.53268932598902
At time: 290.3663971424103 and batch: 400, loss is 4.01584222316742 and perplexity is 55.46999384839268
At time: 291.6873970031738 and batch: 450, loss is 4.045558071136474 and perplexity is 57.143067033745794
At time: 293.0068151950836 and batch: 500, loss is 4.054732789993286 and perplexity is 57.66975100258275
At time: 294.32442140579224 and batch: 550, loss is 4.025449910163879 and perplexity is 56.00550055813531
At time: 295.64403796195984 and batch: 600, loss is 4.00258955001831 and perplexity is 54.739717892979186
At time: 296.9631624221802 and batch: 650, loss is 4.057427806854248 and perplexity is 57.82538157321123
At time: 298.2832088470459 and batch: 700, loss is 4.092539238929748 and perplexity is 59.89177831941215
At time: 299.6021695137024 and batch: 750, loss is 4.055798668861389 and perplexity is 57.73125274238486
At time: 300.9185881614685 and batch: 800, loss is 4.029042525291443 and perplexity is 56.20706862811469
At time: 302.26359462738037 and batch: 850, loss is 4.032180247306823 and perplexity is 56.3837077620968
At time: 303.58154582977295 and batch: 900, loss is 4.008336682319641 and perplexity is 55.05522004173594
At time: 304.8991153240204 and batch: 950, loss is 4.096550259590149 and perplexity is 60.132487902477884
At time: 306.21671509742737 and batch: 1000, loss is 4.074990620613098 and perplexity is 58.84992860950923
At time: 307.5328505039215 and batch: 1050, loss is 4.030163469314576 and perplexity is 56.2701089314759
At time: 308.84973883628845 and batch: 1100, loss is 4.067151799201965 and perplexity is 58.39041789326704
At time: 310.18018412590027 and batch: 1150, loss is 4.0145986366271975 and perplexity is 55.40105498526229
At time: 311.51020407676697 and batch: 1200, loss is 4.107698721885681 and perplexity is 60.80662348189547
At time: 312.8324615955353 and batch: 1250, loss is 4.069817900657654 and perplexity is 58.5463003783351
At time: 314.1493453979492 and batch: 1300, loss is 4.078396139144897 and perplexity is 59.0506847773856
At time: 315.46518301963806 and batch: 1350, loss is 3.9473521852493287 and perplexity is 51.7980335012939
At time: 316.783518075943 and batch: 1400, loss is 3.986853551864624 and perplexity is 53.8850757524392
At time: 318.1024568080902 and batch: 1450, loss is 3.9213205432891844 and perplexity is 50.467044711558415
At time: 319.4324405193329 and batch: 1500, loss is 3.9185287666320803 and perplexity is 50.32634848178705
At time: 320.7731583118439 and batch: 1550, loss is 3.936011333465576 and perplexity is 51.2139181241071
At time: 322.09324502944946 and batch: 1600, loss is 4.03111834526062 and perplexity is 56.323865566350115
At time: 323.4107186794281 and batch: 1650, loss is 3.9697875022888183 and perplexity is 52.97327294432555
At time: 324.73122334480286 and batch: 1700, loss is 4.0038827419281 and perplexity is 54.81055264489494
At time: 326.0516314506531 and batch: 1750, loss is 4.010119223594666 and perplexity is 55.15344576355867
At time: 327.37518334388733 and batch: 1800, loss is 3.966724133491516 and perplexity is 52.811244575930196
At time: 328.7023651599884 and batch: 1850, loss is 3.99608811378479 and perplexity is 54.38498549220366
At time: 330.0315856933594 and batch: 1900, loss is 4.0813287830352785 and perplexity is 59.22411358549168
At time: 331.37238454818726 and batch: 1950, loss is 4.019563946723938 and perplexity is 55.67682247192257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.455141999000727 and perplexity of 86.06837160021175
finished 6 epochs...
Completing Train Step...
At time: 335.4999170303345 and batch: 50, loss is 4.000069541931152 and perplexity is 54.60194702595846
At time: 336.8229262828827 and batch: 100, loss is 3.9408817052841187 and perplexity is 51.46395734538947
At time: 338.1601233482361 and batch: 150, loss is 3.901762490272522 and perplexity is 49.48959721780797
At time: 339.49114179611206 and batch: 200, loss is 3.9060227155685423 and perplexity is 49.70088379641619
At time: 340.81444025039673 and batch: 250, loss is 3.9021233987808226 and perplexity is 49.50746165803658
At time: 342.13246178627014 and batch: 300, loss is 3.9293922758102418 and perplexity is 50.87604966624403
At time: 343.4532961845398 and batch: 350, loss is 3.936431407928467 and perplexity is 51.23543630255781
At time: 344.77296328544617 and batch: 400, loss is 3.9022620153427123 and perplexity is 49.514324687813314
At time: 346.0939955711365 and batch: 450, loss is 3.933291444778442 and perplexity is 51.07481123096702
At time: 347.416139125824 and batch: 500, loss is 3.9440126609802246 and perplexity is 51.625341226840014
At time: 348.7374107837677 and batch: 550, loss is 3.9189452362060546 and perplexity is 50.34731223977962
At time: 350.0557608604431 and batch: 600, loss is 3.894397716522217 and perplexity is 49.1264563976867
At time: 351.3745627403259 and batch: 650, loss is 3.943566198348999 and perplexity is 51.60229758560308
At time: 352.69412565231323 and batch: 700, loss is 3.98320415019989 and perplexity is 53.68878585547349
At time: 354.01290917396545 and batch: 750, loss is 3.94581974029541 and perplexity is 51.718716656103744
At time: 355.33427715301514 and batch: 800, loss is 3.918121814727783 and perplexity is 50.30587224514041
At time: 356.6519179344177 and batch: 850, loss is 3.9251607418060304 and perplexity is 50.661220780507165
At time: 357.969571352005 and batch: 900, loss is 3.8964919567108156 and perplexity is 49.229446802679135
At time: 359.2887713909149 and batch: 950, loss is 3.9895447874069214 and perplexity is 54.03028849670789
At time: 360.6087124347687 and batch: 1000, loss is 3.9651112508773805 and perplexity is 52.72613489213774
At time: 361.92711877822876 and batch: 1050, loss is 3.9233954191207885 and perplexity is 50.57186627117756
At time: 363.2440176010132 and batch: 1100, loss is 3.953201904296875 and perplexity is 52.101925419083784
At time: 364.5616364479065 and batch: 1150, loss is 3.9095636653900145 and perplexity is 49.8771840830472
At time: 365.88031125068665 and batch: 1200, loss is 4.000117506980896 and perplexity is 54.60456607387454
At time: 367.2007546424866 and batch: 1250, loss is 3.967279706001282 and perplexity is 52.84059320351354
At time: 368.5203413963318 and batch: 1300, loss is 3.973962116241455 and perplexity is 53.19487814492348
At time: 369.8438515663147 and batch: 1350, loss is 3.838509383201599 and perplexity is 46.456174448732774
At time: 371.1620440483093 and batch: 1400, loss is 3.8846572113037108 and perplexity is 48.650262840688065
At time: 372.4813783168793 and batch: 1450, loss is 3.8199665927886963 and perplexity is 45.60268483687284
At time: 373.80069160461426 and batch: 1500, loss is 3.815554308891296 and perplexity is 45.40191609495032
At time: 375.1218466758728 and batch: 1550, loss is 3.837171783447266 and perplexity is 46.39407622174818
At time: 376.442342042923 and batch: 1600, loss is 3.9286537313461305 and perplexity is 50.83848931310988
At time: 377.7598760128021 and batch: 1650, loss is 3.870999836921692 and perplexity is 47.990344619900654
At time: 379.07763409614563 and batch: 1700, loss is 3.904476828575134 and perplexity is 49.62411120276046
At time: 380.39726543426514 and batch: 1750, loss is 3.90718900680542 and perplexity is 49.75888331724506
At time: 381.7168483734131 and batch: 1800, loss is 3.863279256820679 and perplexity is 47.621257935199225
At time: 383.0352849960327 and batch: 1850, loss is 3.892272515296936 and perplexity is 49.022163653143885
At time: 384.35324454307556 and batch: 1900, loss is 3.9804204082489014 and perplexity is 53.53953796018312
At time: 385.6709740161896 and batch: 1950, loss is 3.9160944700241087 and perplexity is 50.203988213402916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.457159849654796 and perplexity of 86.2422200612668
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 389.6529104709625 and batch: 50, loss is 3.9362554025650023 and perplexity is 51.22641938450536
At time: 390.97113370895386 and batch: 100, loss is 3.9051907682418823 and perplexity is 49.65955247413457
At time: 392.289302110672 and batch: 150, loss is 3.8679709005355836 and perplexity is 47.845204839445465
At time: 393.607364654541 and batch: 200, loss is 3.8714298009872437 and perplexity is 48.01098318018236
At time: 394.93104434013367 and batch: 250, loss is 3.8687486362457277 and perplexity is 47.88243023769265
At time: 396.2493026256561 and batch: 300, loss is 3.885381326675415 and perplexity is 48.68550400164177
At time: 397.56844115257263 and batch: 350, loss is 3.8931260442733766 and perplexity is 49.06402335200134
At time: 398.8847749233246 and batch: 400, loss is 3.856528329849243 and perplexity is 47.30085303251104
At time: 400.22857570648193 and batch: 450, loss is 3.873691716194153 and perplexity is 48.1197028641363
At time: 401.5467607975006 and batch: 500, loss is 3.8842056655883788 and perplexity is 48.62829998194313
At time: 402.8650860786438 and batch: 550, loss is 3.8500013637542723 and perplexity is 46.99312731861373
At time: 404.18326592445374 and batch: 600, loss is 3.822732129096985 and perplexity is 45.72897526743911
At time: 405.4994418621063 and batch: 650, loss is 3.8721679210662843 and perplexity is 48.04643413280257
At time: 406.815771818161 and batch: 700, loss is 3.901364860534668 and perplexity is 49.46992259410672
At time: 408.1337938308716 and batch: 750, loss is 3.84854350566864 and perplexity is 46.9246679221505
At time: 409.45356035232544 and batch: 800, loss is 3.8155534839630127 and perplexity is 45.40187864164106
At time: 410.7722783088684 and batch: 850, loss is 3.8129220247268676 and perplexity is 45.28256250537672
At time: 412.0916254520416 and batch: 900, loss is 3.7783015632629393 and perplexity is 43.74168612264438
At time: 413.4084858894348 and batch: 950, loss is 3.8758763217926027 and perplexity is 48.22494034575095
At time: 414.72556161880493 and batch: 1000, loss is 3.8392533540725706 and perplexity is 46.49074934906402
At time: 416.04475831985474 and batch: 1050, loss is 3.7879909658432007 and perplexity is 44.16757691063526
At time: 417.3640503883362 and batch: 1100, loss is 3.8070085430145264 and perplexity is 45.01557509073921
At time: 418.682825088501 and batch: 1150, loss is 3.7667571973800658 and perplexity is 43.23961968896817
At time: 420.00129985809326 and batch: 1200, loss is 3.840019268989563 and perplexity is 46.52637094730797
At time: 421.321177482605 and batch: 1250, loss is 3.797430467605591 and perplexity is 44.586470795075066
At time: 422.63926911354065 and batch: 1300, loss is 3.8036029148101806 and perplexity is 44.86252953462893
At time: 423.96013617515564 and batch: 1350, loss is 3.658917999267578 and perplexity is 38.81931760966474
At time: 425.28030037879944 and batch: 1400, loss is 3.695108470916748 and perplexity is 40.24993829889736
At time: 426.59765625 and batch: 1450, loss is 3.6286858701705933 and perplexity is 37.66328962948761
At time: 427.91519474983215 and batch: 1500, loss is 3.614709711074829 and perplexity is 37.14056286654616
At time: 429.2362332344055 and batch: 1550, loss is 3.6238045358657835 and perplexity is 37.47989050217362
At time: 430.5659132003784 and batch: 1600, loss is 3.708203663825989 and perplexity is 40.780485231044146
At time: 431.8841519355774 and batch: 1650, loss is 3.6340993356704714 and perplexity is 37.86773141852058
At time: 433.20219683647156 and batch: 1700, loss is 3.654248752593994 and perplexity is 38.638483148941035
At time: 434.5196101665497 and batch: 1750, loss is 3.6526624011993407 and perplexity is 38.57723752869174
At time: 435.8388011455536 and batch: 1800, loss is 3.6000261020660402 and perplexity is 36.59918974567802
At time: 437.1577661037445 and batch: 1850, loss is 3.619333529472351 and perplexity is 37.312691724040036
At time: 438.47706413269043 and batch: 1900, loss is 3.698105802536011 and perplexity is 40.37076169507047
At time: 439.79746174812317 and batch: 1950, loss is 3.621496596336365 and perplexity is 37.393488924485744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.412749534429506 and perplexity of 82.49597748789927
finished 8 epochs...
Completing Train Step...
At time: 443.7778351306915 and batch: 50, loss is 3.8315496492385863 and perplexity is 46.133974347680265
At time: 445.09711956977844 and batch: 100, loss is 3.7875629568099978 and perplexity is 44.14867683373318
At time: 446.4159231185913 and batch: 150, loss is 3.7449031686782837 and perplexity is 42.30491058009297
At time: 447.7339723110199 and batch: 200, loss is 3.7510050630569456 and perplexity is 42.563839852291906
At time: 449.0514259338379 and batch: 250, loss is 3.7447467947006228 and perplexity is 42.29829571016122
At time: 450.3690915107727 and batch: 300, loss is 3.7586826992034914 and perplexity is 42.891887230457385
At time: 451.6872091293335 and batch: 350, loss is 3.7710680198669433 and perplexity is 43.42642035682792
At time: 453.00829339027405 and batch: 400, loss is 3.736826810836792 and perplexity is 41.96461699986625
At time: 454.33162546157837 and batch: 450, loss is 3.7584109258651734 and perplexity is 42.880231942947944
At time: 455.65368366241455 and batch: 500, loss is 3.770952501296997 and perplexity is 43.42140408859206
At time: 456.971394777298 and batch: 550, loss is 3.7397487783432006 and perplexity is 42.087415566499416
At time: 458.29279947280884 and batch: 600, loss is 3.7157385969161987 and perplexity is 41.08892403220567
At time: 459.6112439632416 and batch: 650, loss is 3.7628588247299195 and perplexity is 43.0713836745698
At time: 460.9308032989502 and batch: 700, loss is 3.7949876165390015 and perplexity is 44.477685614433284
At time: 462.24736857414246 and batch: 750, loss is 3.7454429960250852 and perplexity is 42.32775409294983
At time: 463.5657663345337 and batch: 800, loss is 3.7131181859970095 and perplexity is 40.98139511351968
At time: 464.88517785072327 and batch: 850, loss is 3.715099086761475 and perplexity is 41.06265564838475
At time: 466.2173993587494 and batch: 900, loss is 3.6877352380752564 and perplexity is 39.95425753307558
At time: 467.53490114212036 and batch: 950, loss is 3.780816731452942 and perplexity is 43.851842292733295
At time: 468.85246872901917 and batch: 1000, loss is 3.746728010177612 and perplexity is 42.38218081807058
At time: 470.170042514801 and batch: 1050, loss is 3.700645933151245 and perplexity is 40.47343905455615
At time: 471.48928904533386 and batch: 1100, loss is 3.7201219844818114 and perplexity is 41.26942803136738
At time: 472.80897760391235 and batch: 1150, loss is 3.684661936759949 and perplexity is 39.83165455529407
At time: 474.1292984485626 and batch: 1200, loss is 3.760632176399231 and perplexity is 42.97558554396446
At time: 475.4478368759155 and batch: 1250, loss is 3.720502028465271 and perplexity is 41.28511520991161
At time: 476.7661108970642 and batch: 1300, loss is 3.7293035221099853 and perplexity is 41.65008969325219
At time: 478.0842571258545 and batch: 1350, loss is 3.586112308502197 and perplexity is 36.09348248660587
At time: 479.40304732322693 and batch: 1400, loss is 3.626502504348755 and perplexity is 37.581146596949374
At time: 480.7233099937439 and batch: 1450, loss is 3.565056924819946 and perplexity is 35.341465153560414
At time: 482.0415298938751 and batch: 1500, loss is 3.550629906654358 and perplexity is 34.83525353605387
At time: 483.3594374656677 and batch: 1550, loss is 3.563986144065857 and perplexity is 35.303642446379996
At time: 484.6776328086853 and batch: 1600, loss is 3.6537014389038087 and perplexity is 38.617341564212744
At time: 485.99608850479126 and batch: 1650, loss is 3.582554612159729 and perplexity is 35.96530098660478
At time: 487.3162269592285 and batch: 1700, loss is 3.607128381729126 and perplexity is 36.86005269094502
At time: 488.63599395751953 and batch: 1750, loss is 3.6065969944000242 and perplexity is 36.84047092920584
At time: 489.95746517181396 and batch: 1800, loss is 3.5598566150665283 and perplexity is 35.15815563387032
At time: 491.2796354293823 and batch: 1850, loss is 3.583738808631897 and perplexity is 36.0079161965642
At time: 492.5981628894806 and batch: 1900, loss is 3.667422556877136 and perplexity is 39.1508665729292
At time: 493.9177989959717 and batch: 1950, loss is 3.591712532043457 and perplexity is 36.29618110594224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.420403059138808 and perplexity of 83.12978482623826
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 497.8835697174072 and batch: 50, loss is 3.792324113845825 and perplexity is 44.35937680686942
At time: 499.2133255004883 and batch: 100, loss is 3.784056234359741 and perplexity is 43.994130810907436
At time: 500.53266763687134 and batch: 150, loss is 3.7591719579696656 and perplexity is 42.91287759672428
At time: 501.85124158859253 and batch: 200, loss is 3.7725097370147704 and perplexity is 43.48907412537895
At time: 503.1695177555084 and batch: 250, loss is 3.7688090896606443 and perplexity is 43.32843381817529
At time: 504.4875957965851 and batch: 300, loss is 3.7810629272460936 and perplexity is 43.8626397609188
At time: 505.8051414489746 and batch: 350, loss is 3.8029451751708985 and perplexity is 44.83303137275418
At time: 507.1248404979706 and batch: 400, loss is 3.767075152397156 and perplexity is 43.253370128880185
At time: 508.44426941871643 and batch: 450, loss is 3.7911547422409058 and perplexity is 44.307534528571196
At time: 509.7705011367798 and batch: 500, loss is 3.8051089811325074 and perplexity is 44.93014638444468
At time: 511.08774733543396 and batch: 550, loss is 3.7654275417327883 and perplexity is 43.1821640910078
At time: 512.4055950641632 and batch: 600, loss is 3.727344789505005 and perplexity is 41.56858815049187
At time: 513.7243275642395 and batch: 650, loss is 3.782636046409607 and perplexity is 43.93169522208265
At time: 515.0558314323425 and batch: 700, loss is 3.820298867225647 and perplexity is 45.61783996099119
At time: 516.3753650188446 and batch: 750, loss is 3.7541885995864868 and perplexity is 42.69955931060057
At time: 517.6929347515106 and batch: 800, loss is 3.7228233671188353 and perplexity is 41.38106326454365
At time: 519.0101137161255 and batch: 850, loss is 3.715391912460327 and perplexity is 41.07468160989108
At time: 520.327632188797 and batch: 900, loss is 3.6833203172683717 and perplexity is 39.77825146248624
At time: 521.6477563381195 and batch: 950, loss is 3.795577311515808 and perplexity is 44.50392161707931
At time: 522.9675974845886 and batch: 1000, loss is 3.751150116920471 and perplexity is 42.570014349515475
At time: 524.2857065200806 and batch: 1050, loss is 3.6843764686584475 and perplexity is 39.82028551131542
At time: 525.6023333072662 and batch: 1100, loss is 3.694422235488892 and perplexity is 40.22232684033174
At time: 526.9207656383514 and batch: 1150, loss is 3.668642339706421 and perplexity is 39.19865126527531
At time: 528.2402784824371 and batch: 1200, loss is 3.7353592777252196 and perplexity is 41.903077701428074
At time: 529.5591759681702 and batch: 1250, loss is 3.690673246383667 and perplexity is 40.07181608309976
At time: 530.8786680698395 and batch: 1300, loss is 3.698936700820923 and perplexity is 40.40431963140869
At time: 532.1960604190826 and batch: 1350, loss is 3.5560481643676756 and perplexity is 35.02451218026194
At time: 533.5138666629791 and batch: 1400, loss is 3.585982851982117 and perplexity is 36.08881025239769
At time: 534.8331537246704 and batch: 1450, loss is 3.520474648475647 and perplexity is 33.800467997589514
At time: 536.1544415950775 and batch: 1500, loss is 3.5079359579086304 and perplexity is 33.379300351682
At time: 537.4757497310638 and batch: 1550, loss is 3.527670006752014 and perplexity is 34.04455155598613
At time: 538.793694972992 and batch: 1600, loss is 3.6119413948059083 and perplexity is 37.037888225636465
At time: 540.1170153617859 and batch: 1650, loss is 3.5403021955490113 and perplexity is 34.47733651438012
At time: 541.4389197826385 and batch: 1700, loss is 3.5418951892852784 and perplexity is 34.53230246407389
At time: 542.7587702274323 and batch: 1750, loss is 3.5357339668273924 and perplexity is 34.3201953571219
At time: 544.0786733627319 and batch: 1800, loss is 3.481485300064087 and perplexity is 32.50797032583761
At time: 545.3980474472046 and batch: 1850, loss is 3.502985191345215 and perplexity is 33.21445561818453
At time: 546.7151832580566 and batch: 1900, loss is 3.608890719413757 and perplexity is 36.9250698251049
At time: 548.0341248512268 and batch: 1950, loss is 3.532999863624573 and perplexity is 34.22648856147367
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.396600767623546 and perplexity of 81.17446827583314
finished 10 epochs...
Completing Train Step...
At time: 552.0106673240662 and batch: 50, loss is 3.7872006940841674 and perplexity is 44.13268631028176
At time: 553.3368656635284 and batch: 100, loss is 3.7535455989837647 and perplexity is 42.67211229339785
At time: 554.6547255516052 and batch: 150, loss is 3.717623052597046 and perplexity is 41.16642729131089
At time: 555.9747214317322 and batch: 200, loss is 3.7245323848724365 and perplexity is 41.451844702464804
At time: 557.2946434020996 and batch: 250, loss is 3.717143898010254 and perplexity is 41.14670693377959
At time: 558.6127541065216 and batch: 300, loss is 3.7274066638946532 and perplexity is 41.57116026108529
At time: 559.9310190677643 and batch: 350, loss is 3.7482776975631715 and perplexity is 42.44791086641583
At time: 561.2549130916595 and batch: 400, loss is 3.7161066246032717 and perplexity is 41.10404867685484
At time: 562.5839307308197 and batch: 450, loss is 3.7405662870407106 and perplexity is 42.12183646255468
At time: 563.9198002815247 and batch: 500, loss is 3.7550052547454835 and perplexity is 42.73444436859094
At time: 565.23921251297 and batch: 550, loss is 3.7161371231079103 and perplexity is 41.10530230799092
At time: 566.5577440261841 and batch: 600, loss is 3.6811522674560546 and perplexity is 39.69210365198527
At time: 567.8754243850708 and batch: 650, loss is 3.739817657470703 and perplexity is 42.09031461080315
At time: 569.1939294338226 and batch: 700, loss is 3.779525580406189 and perplexity is 43.7952594769965
At time: 570.513325214386 and batch: 750, loss is 3.714383373260498 and perplexity is 41.033277065929376
At time: 571.8396270275116 and batch: 800, loss is 3.6785341453552247 and perplexity is 39.588320795562794
At time: 573.1591155529022 and batch: 850, loss is 3.6712931108474733 and perplexity is 39.302695756962315
At time: 574.4771130084991 and batch: 900, loss is 3.6413124990463257 and perplexity is 38.14186504865539
At time: 575.7944276332855 and batch: 950, loss is 3.7549234867095946 and perplexity is 42.73095019986772
At time: 577.1148390769958 and batch: 1000, loss is 3.7139287424087524 and perplexity is 41.01462631215226
At time: 578.4350452423096 and batch: 1050, loss is 3.6506522941589354 and perplexity is 38.49977103599092
At time: 579.7543320655823 and batch: 1100, loss is 3.6587070417404175 and perplexity is 38.811129246144574
At time: 581.0714299678802 and batch: 1150, loss is 3.636254267692566 and perplexity is 37.94942179254752
At time: 582.3887436389923 and batch: 1200, loss is 3.7050833082199097 and perplexity is 40.65343394102484
At time: 583.7074418067932 and batch: 1250, loss is 3.664493188858032 and perplexity is 39.03634709321382
At time: 585.026871919632 and batch: 1300, loss is 3.673023610115051 and perplexity is 39.370767925615006
At time: 586.3456127643585 and batch: 1350, loss is 3.5310369396209715 and perplexity is 34.15937046093358
At time: 587.6765871047974 and batch: 1400, loss is 3.5628151321411132 and perplexity is 35.26232565603686
At time: 588.9960305690765 and batch: 1450, loss is 3.500758867263794 and perplexity is 33.140591728777316
At time: 590.315358877182 and batch: 1500, loss is 3.4894682598114013 and perplexity is 32.76851873446822
At time: 591.6360795497894 and batch: 1550, loss is 3.510927829742432 and perplexity is 33.479316483353664
At time: 592.9598932266235 and batch: 1600, loss is 3.6000158739089967 and perplexity is 36.59881540533204
At time: 594.2783093452454 and batch: 1650, loss is 3.5296722221374512 and perplexity is 34.11278436649865
At time: 595.5958313941956 and batch: 1700, loss is 3.535854287147522 and perplexity is 34.324325022450516
At time: 596.9138972759247 and batch: 1750, loss is 3.5308968591690064 and perplexity is 34.154585736011605
At time: 598.2323920726776 and batch: 1800, loss is 3.4789547538757324 and perplexity is 32.42581140275641
At time: 599.5524728298187 and batch: 1850, loss is 3.5027645301818846 and perplexity is 33.20712728633728
At time: 600.8726665973663 and batch: 1900, loss is 3.6112705993652345 and perplexity is 37.01305171012451
At time: 602.1900761127472 and batch: 1950, loss is 3.5376439809799196 and perplexity is 34.38581005852794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39742062590843 and perplexity of 81.24104712505134
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 606.1410765647888 and batch: 50, loss is 3.7804654455184936 and perplexity is 43.836440462717725
At time: 607.4859139919281 and batch: 100, loss is 3.7716359853744508 and perplexity is 43.45109207138333
At time: 608.804037809372 and batch: 150, loss is 3.7476110887527465 and perplexity is 42.41962414418475
At time: 610.1309614181519 and batch: 200, loss is 3.7673542881011963 and perplexity is 43.26544537404086
At time: 611.4505167007446 and batch: 250, loss is 3.7686683416366575 and perplexity is 43.32233585588108
At time: 612.7707657814026 and batch: 300, loss is 3.780825724601746 and perplexity is 43.85223666064966
At time: 614.090169429779 and batch: 350, loss is 3.807556109428406 and perplexity is 45.04023085747921
At time: 615.4096758365631 and batch: 400, loss is 3.7787164783477785 and perplexity is 43.75983897373842
At time: 616.7253928184509 and batch: 450, loss is 3.807550868988037 and perplexity is 45.039994827453654
At time: 618.044086933136 and batch: 500, loss is 3.816044988632202 and perplexity is 45.42419936190316
At time: 619.366402387619 and batch: 550, loss is 3.7818745231628417 and perplexity is 43.898252950051166
At time: 620.6903927326202 and batch: 600, loss is 3.7255837869644166 and perplexity is 41.49545017812862
At time: 622.008748292923 and batch: 650, loss is 3.764637818336487 and perplexity is 43.14807558773815
At time: 623.3257937431335 and batch: 700, loss is 3.8063753986358644 and perplexity is 44.98708275325174
At time: 624.643536567688 and batch: 750, loss is 3.7532694339752197 and perplexity is 42.66032937623131
At time: 625.9635219573975 and batch: 800, loss is 3.7326080131530763 and perplexity is 41.78794969470881
At time: 627.2841913700104 and batch: 850, loss is 3.7342479753494264 and perplexity is 41.856536577046306
At time: 628.6047773361206 and batch: 900, loss is 3.6918709516525268 and perplexity is 40.11983906130153
At time: 629.9345700740814 and batch: 950, loss is 3.8093160438537597 and perplexity is 45.119568504340975
At time: 631.2519061565399 and batch: 1000, loss is 3.765490517616272 and perplexity is 43.18488361157337
At time: 632.5713195800781 and batch: 1050, loss is 3.7101529932022093 and perplexity is 40.860057359828545
At time: 633.890748500824 and batch: 1100, loss is 3.7148761463165285 and perplexity is 41.053502142045126
At time: 635.216183423996 and batch: 1150, loss is 3.6827745246887207 and perplexity is 39.756546711691286
At time: 636.5348443984985 and batch: 1200, loss is 3.7433968496322634 and perplexity is 42.24123385831559
At time: 637.8524279594421 and batch: 1250, loss is 3.6920310163497927 and perplexity is 40.12626134517199
At time: 639.170960187912 and batch: 1300, loss is 3.6942369556427 and perplexity is 40.21487514414717
At time: 640.4904742240906 and batch: 1350, loss is 3.549309244155884 and perplexity is 34.78927828865882
At time: 641.8105466365814 and batch: 1400, loss is 3.5786900520324707 and perplexity is 35.82657914055345
At time: 643.1296048164368 and batch: 1450, loss is 3.511099729537964 and perplexity is 33.48507206568925
At time: 644.4470009803772 and batch: 1500, loss is 3.486815824508667 and perplexity is 32.681717526742645
At time: 645.7652409076691 and batch: 1550, loss is 3.5076030254364015 and perplexity is 33.36818914843746
At time: 647.084802865982 and batch: 1600, loss is 3.593707633018494 and perplexity is 36.36866793748691
At time: 648.4032967090607 and batch: 1650, loss is 3.522819747924805 and perplexity is 33.87982647185982
At time: 649.722615480423 and batch: 1700, loss is 3.5226967191696166 and perplexity is 33.87565853537627
At time: 651.0400850772858 and batch: 1750, loss is 3.5240968465805054 and perplexity is 33.9231219931439
At time: 652.3576099872589 and batch: 1800, loss is 3.4758564758300783 and perplexity is 32.32550269554872
At time: 653.6762413978577 and batch: 1850, loss is 3.4988418674468993 and perplexity is 33.07712207559523
At time: 654.9952125549316 and batch: 1900, loss is 3.611663136482239 and perplexity is 37.02758355869271
At time: 656.3132214546204 and batch: 1950, loss is 3.553948245048523 and perplexity is 34.95104069958024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373256381722384 and perplexity of 79.30144748257989
finished 12 epochs...
Completing Train Step...
At time: 660.3206324577332 and batch: 50, loss is 3.8157341623306276 and perplexity is 45.41008252007004
At time: 661.6383650302887 and batch: 100, loss is 3.7803539514541624 and perplexity is 43.83155323225838
At time: 662.9669675827026 and batch: 150, loss is 3.735914134979248 and perplexity is 41.926334379528434
At time: 664.2871582508087 and batch: 200, loss is 3.7426891231536867 and perplexity is 42.21134919495747
At time: 665.6061663627625 and batch: 250, loss is 3.7418681621551513 and perplexity is 42.176709544419424
At time: 666.9225525856018 and batch: 300, loss is 3.7459750604629516 and perplexity is 42.35028117803643
At time: 668.2399110794067 and batch: 350, loss is 3.7699876499176024 and perplexity is 43.37952909178473
At time: 669.5611336231232 and batch: 400, loss is 3.7425400972366334 and perplexity is 42.205059078640446
At time: 670.8808286190033 and batch: 450, loss is 3.7725348234176637 and perplexity is 43.490165123498464
At time: 672.2019531726837 and batch: 500, loss is 3.7809456062316893 and perplexity is 43.85749405338332
At time: 673.5180788040161 and batch: 550, loss is 3.7473668813705445 and perplexity is 42.40926622361032
At time: 674.8344895839691 and batch: 600, loss is 3.697015013694763 and perplexity is 40.32674972694653
At time: 676.1514704227448 and batch: 650, loss is 3.7398670148849487 and perplexity is 42.092392131167216
At time: 677.4688291549683 and batch: 700, loss is 3.7836363744735717 and perplexity is 43.97566331730422
At time: 678.7858748435974 and batch: 750, loss is 3.7317775774002073 and perplexity is 41.753261892232366
At time: 680.1003952026367 and batch: 800, loss is 3.710629463195801 and perplexity is 40.87953058993343
At time: 681.4182529449463 and batch: 850, loss is 3.712096781730652 and perplexity is 40.939557911694955
At time: 682.738046169281 and batch: 900, loss is 3.672072238922119 and perplexity is 39.333329522899696
At time: 684.0582556724548 and batch: 950, loss is 3.788148546218872 and perplexity is 44.17453740240138
At time: 685.3891599178314 and batch: 1000, loss is 3.7450966453552246 and perplexity is 42.31309638546597
At time: 686.7080693244934 and batch: 1050, loss is 3.6895699977874754 and perplexity is 40.027631286148484
At time: 688.0351567268372 and batch: 1100, loss is 3.693942861557007 and perplexity is 40.20304992615895
At time: 689.3610556125641 and batch: 1150, loss is 3.66235372543335 and perplexity is 38.95291953330397
At time: 690.6829192638397 and batch: 1200, loss is 3.72116069316864 and perplexity is 41.312317215591975
At time: 692.0043544769287 and batch: 1250, loss is 3.6728669595718384 and perplexity is 39.3646009564749
At time: 693.3231937885284 and batch: 1300, loss is 3.6763204288482667 and perplexity is 39.50078040688623
At time: 694.6469721794128 and batch: 1350, loss is 3.533194408416748 and perplexity is 34.233147794316274
At time: 695.9669744968414 and batch: 1400, loss is 3.5653462409973145 and perplexity is 35.35169149041225
At time: 697.2881619930267 and batch: 1450, loss is 3.5004612588882447 and perplexity is 33.130730278606045
At time: 698.6091597080231 and batch: 1500, loss is 3.4798788356781007 and perplexity is 32.45578935390704
At time: 699.9290812015533 and batch: 1550, loss is 3.5034423637390137 and perplexity is 33.229643821917406
At time: 701.2506234645844 and batch: 1600, loss is 3.592264404296875 and perplexity is 36.31621748945317
At time: 702.5710797309875 and batch: 1650, loss is 3.522413492202759 and perplexity is 33.86606539394129
At time: 703.8931579589844 and batch: 1700, loss is 3.5236950397491453 and perplexity is 33.90949418904174
At time: 705.213965177536 and batch: 1750, loss is 3.5269180965423583 and perplexity is 34.0189627315428
At time: 706.5342061519623 and batch: 1800, loss is 3.479005208015442 and perplexity is 32.42744746044772
At time: 707.8542988300323 and batch: 1850, loss is 3.502336735725403 and perplexity is 33.192924499521844
At time: 709.1742911338806 and batch: 1900, loss is 3.614883608818054 and perplexity is 37.14702208821651
At time: 710.4958157539368 and batch: 1950, loss is 3.556920471191406 and perplexity is 35.05507763052188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372145825763082 and perplexity of 79.21342767200589
finished 13 epochs...
Completing Train Step...
At time: 714.5006515979767 and batch: 50, loss is 3.8087892150878906 and perplexity is 45.09580447808524
At time: 715.8206973075867 and batch: 100, loss is 3.7712891244888307 and perplexity is 43.4360232006583
At time: 717.1425259113312 and batch: 150, loss is 3.7252280616760256 and perplexity is 41.48069182226291
At time: 718.4703795909882 and batch: 200, loss is 3.7309591007232665 and perplexity is 41.71910180271265
At time: 719.7940971851349 and batch: 250, loss is 3.72935986995697 and perplexity is 41.65243665225555
At time: 721.1144461631775 and batch: 300, loss is 3.7324283266067506 and perplexity is 41.780441636918816
At time: 722.4333972930908 and batch: 350, loss is 3.756617474555969 and perplexity is 42.803397255061356
At time: 723.7541327476501 and batch: 400, loss is 3.7289741706848143 and perplexity is 41.63637443554703
At time: 725.07559466362 and batch: 450, loss is 3.758950114250183 and perplexity is 42.90335870023726
At time: 726.3987317085266 and batch: 500, loss is 3.766853938102722 and perplexity is 43.24380292336556
At time: 727.7462859153748 and batch: 550, loss is 3.7333199834823607 and perplexity is 41.81771206871946
At time: 729.065269947052 and batch: 600, loss is 3.683841037750244 and perplexity is 39.79897020662488
At time: 730.3938035964966 and batch: 650, loss is 3.7265807723999025 and perplexity is 41.53684116727332
At time: 731.7257444858551 and batch: 700, loss is 3.7712394618988037 and perplexity is 43.433866108809504
At time: 733.0478060245514 and batch: 750, loss is 3.7195551013946533 and perplexity is 41.24603972044499
At time: 734.3685472011566 and batch: 800, loss is 3.6978790950775147 and perplexity is 40.36161037966395
At time: 735.6894891262054 and batch: 850, loss is 3.700054430961609 and perplexity is 40.449506005656495
At time: 737.008996963501 and batch: 900, loss is 3.6612522983551026 and perplexity is 38.910039351984594
At time: 738.3300166130066 and batch: 950, loss is 3.776881413459778 and perplexity is 43.67961046450718
At time: 739.6521353721619 and batch: 1000, loss is 3.7340828466415403 and perplexity is 41.84962543187469
At time: 740.9715557098389 and batch: 1050, loss is 3.679387888908386 and perplexity is 39.6221335008583
At time: 742.2908413410187 and batch: 1100, loss is 3.6836869430541994 and perplexity is 39.7928378689005
At time: 743.6087913513184 and batch: 1150, loss is 3.652020826339722 and perplexity is 38.55249528079059
At time: 744.9285864830017 and batch: 1200, loss is 3.7102477407455443 and perplexity is 40.86392893329206
At time: 746.2492280006409 and batch: 1250, loss is 3.6635582065582275 and perplexity is 38.99986585694536
At time: 747.5684368610382 and batch: 1300, loss is 3.667443356513977 and perplexity is 39.151680905204806
At time: 748.887565612793 and batch: 1350, loss is 3.5248675537109375 and perplexity is 33.949276862728134
At time: 750.2052216529846 and batch: 1400, loss is 3.5582876682281492 and perplexity is 35.10303760667909
At time: 751.5240206718445 and batch: 1450, loss is 3.4942898845672605 and perplexity is 32.92689775087063
At time: 752.8463597297668 and batch: 1500, loss is 3.4754201889038088 and perplexity is 32.31140257740982
At time: 754.168389081955 and batch: 1550, loss is 3.5000070905685425 and perplexity is 33.115686766906705
At time: 755.4910163879395 and batch: 1600, loss is 3.5899494457244874 and perplexity is 36.2322441853207
At time: 756.8114774227142 and batch: 1650, loss is 3.520809211730957 and perplexity is 33.81177828409143
At time: 758.1306102275848 and batch: 1700, loss is 3.522549228668213 and perplexity is 33.870662565951584
At time: 759.4494302272797 and batch: 1750, loss is 3.526580801010132 and perplexity is 34.0074902223243
At time: 760.7717714309692 and batch: 1800, loss is 3.4790939807891847 and perplexity is 32.430326262681916
At time: 762.0920035839081 and batch: 1850, loss is 3.5024200820922853 and perplexity is 33.19569112447755
At time: 763.4113237857819 and batch: 1900, loss is 3.6145417356491087 and perplexity is 37.13432468863212
At time: 764.7280468940735 and batch: 1950, loss is 3.556340184211731 and perplexity is 35.03474152636026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3724708734556685 and perplexity of 79.23917999903307
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 768.7335715293884 and batch: 50, loss is 3.8078132486343383 and perplexity is 45.05181395584745
At time: 770.0543401241302 and batch: 100, loss is 3.7823382425308227 and perplexity is 43.91861414073901
At time: 771.3741655349731 and batch: 150, loss is 3.743154401779175 and perplexity is 42.23099380324467
At time: 772.6953222751617 and batch: 200, loss is 3.753681755065918 and perplexity is 42.677922756580905
At time: 774.0163474082947 and batch: 250, loss is 3.7620896434783937 and perplexity is 43.038266711876226
At time: 775.3366112709045 and batch: 300, loss is 3.7638311910629274 and perplexity is 43.11328520648901
At time: 776.6570944786072 and batch: 350, loss is 3.7904872035980226 and perplexity is 44.27796740679861
At time: 777.9769184589386 and batch: 400, loss is 3.7646620941162108 and perplexity is 43.14912305363059
At time: 779.2961914539337 and batch: 450, loss is 3.7976346445083617 and perplexity is 44.59557525201576
At time: 780.6166968345642 and batch: 500, loss is 3.811209659576416 and perplexity is 45.20508857418001
At time: 781.934351682663 and batch: 550, loss is 3.7871554040908815 and perplexity is 44.13068758647652
At time: 783.2550802230835 and batch: 600, loss is 3.734601306915283 and perplexity is 41.87132842571605
At time: 784.5801758766174 and batch: 650, loss is 3.767928066253662 and perplexity is 43.29027726467008
At time: 785.9034554958344 and batch: 700, loss is 3.7949115228652954 and perplexity is 44.47430127270207
At time: 787.223753452301 and batch: 750, loss is 3.741406183242798 and perplexity is 42.15722929409633
At time: 788.544685125351 and batch: 800, loss is 3.711323699951172 and perplexity is 40.90792051613616
At time: 789.8661839962006 and batch: 850, loss is 3.7164015674591067 and perplexity is 41.11617381038083
At time: 791.1867311000824 and batch: 900, loss is 3.667878336906433 and perplexity is 39.16871482317184
At time: 792.5029859542847 and batch: 950, loss is 3.7907027053833007 and perplexity is 44.2875104160541
At time: 793.8508973121643 and batch: 1000, loss is 3.7563284111022948 and perplexity is 42.79102614532581
At time: 795.1756539344788 and batch: 1050, loss is 3.7047608709335327 and perplexity is 40.64032787115934
At time: 796.4980432987213 and batch: 1100, loss is 3.7148674583435057 and perplexity is 41.053145471875396
At time: 797.8161208629608 and batch: 1150, loss is 3.6854843997955324 and perplexity is 39.864428094476736
At time: 799.1324374675751 and batch: 1200, loss is 3.749147162437439 and perplexity is 42.48483388320724
At time: 800.4500033855438 and batch: 1250, loss is 3.7026700735092164 and perplexity is 40.555445944700864
At time: 801.7681357860565 and batch: 1300, loss is 3.7076738691329956 and perplexity is 40.758885668563046
At time: 803.087482213974 and batch: 1350, loss is 3.555980052947998 and perplexity is 35.02212669225423
At time: 804.4048035144806 and batch: 1400, loss is 3.588348789215088 and perplexity is 36.17429519839947
At time: 805.7222759723663 and batch: 1450, loss is 3.5176986122131346 and perplexity is 33.706766791885485
At time: 807.0402317047119 and batch: 1500, loss is 3.4876961421966555 and perplexity is 32.710500487971416
At time: 808.3591601848602 and batch: 1550, loss is 3.509932198524475 and perplexity is 33.446000018915186
At time: 809.6856391429901 and batch: 1600, loss is 3.596433720588684 and perplexity is 36.467947371828274
At time: 811.0034561157227 and batch: 1650, loss is 3.5244943714141845 and perplexity is 33.936609957294834
At time: 812.3224172592163 and batch: 1700, loss is 3.5199257278442384 and perplexity is 33.78191931469748
At time: 813.6395773887634 and batch: 1750, loss is 3.5238075160980227 and perplexity is 33.913308419641744
At time: 814.9657816886902 and batch: 1800, loss is 3.475553512573242 and perplexity is 32.31571073934958
At time: 816.284485578537 and batch: 1850, loss is 3.4978351259231566 and perplexity is 33.043838719995016
At time: 817.6017138957977 and batch: 1900, loss is 3.6135463380813597 and perplexity is 37.097379662702004
At time: 818.9196562767029 and batch: 1950, loss is 3.561860613822937 and perplexity is 35.228683178991304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364997047601745 and perplexity of 78.64916773776852
finished 15 epochs...
Completing Train Step...
At time: 822.8820407390594 and batch: 50, loss is 3.815220055580139 and perplexity is 45.386742890150956
At time: 824.2135615348816 and batch: 100, loss is 3.7821062183380127 and perplexity is 43.9084251418365
At time: 825.5328743457794 and batch: 150, loss is 3.739161491394043 and perplexity is 42.06270543329303
At time: 826.8588404655457 and batch: 200, loss is 3.745099148750305 and perplexity is 42.313202311995894
At time: 828.1757113933563 and batch: 250, loss is 3.752035813331604 and perplexity is 42.60773516057434
At time: 829.4956157207489 and batch: 300, loss is 3.7536994552612306 and perplexity is 42.6786781708347
At time: 830.8147690296173 and batch: 350, loss is 3.780125617980957 and perplexity is 43.821546163990675
At time: 832.1362462043762 and batch: 400, loss is 3.7536185455322264 and perplexity is 42.675225190241385
At time: 833.4536972045898 and batch: 450, loss is 3.7852855253219606 and perplexity is 44.04824565293244
At time: 834.7712450027466 and batch: 500, loss is 3.799249486923218 and perplexity is 44.66764825605741
At time: 836.0892593860626 and batch: 550, loss is 3.774953303337097 and perplexity is 43.59547250510742
At time: 837.4078578948975 and batch: 600, loss is 3.720755362510681 and perplexity is 41.29557546007577
At time: 838.7245321273804 and batch: 650, loss is 3.7502245903015137 and perplexity is 42.53063289516892
At time: 840.0434319972992 and batch: 700, loss is 3.7805901956558228 and perplexity is 43.841909405804074
At time: 841.3604414463043 and batch: 750, loss is 3.7263013982772826 and perplexity is 41.52523846953803
At time: 842.6778919696808 and batch: 800, loss is 3.698411993980408 and perplexity is 40.38312476954252
At time: 843.9976568222046 and batch: 850, loss is 3.7032891845703126 and perplexity is 40.580562043898084
At time: 845.3166875839233 and batch: 900, loss is 3.657767734527588 and perplexity is 38.77469078863771
At time: 846.6350033283234 and batch: 950, loss is 3.7800242280960084 and perplexity is 43.81710332769997
At time: 847.9510052204132 and batch: 1000, loss is 3.7433664846420287 and perplexity is 42.239951223135684
At time: 849.2738425731659 and batch: 1050, loss is 3.691649327278137 and perplexity is 40.11094851228653
At time: 850.5977144241333 and batch: 1100, loss is 3.7011842775344848 and perplexity is 40.495233569092456
At time: 851.9166271686554 and batch: 1150, loss is 3.6725100898742675 and perplexity is 39.350555429597094
At time: 853.2371098995209 and batch: 1200, loss is 3.7350891828536987 and perplexity is 41.891761423343105
At time: 854.5547521114349 and batch: 1250, loss is 3.6905558633804323 and perplexity is 40.067112609042205
At time: 855.8723058700562 and batch: 1300, loss is 3.6959558629989626 and perplexity is 40.284060233208116
At time: 857.1924078464508 and batch: 1350, loss is 3.545333323478699 and perplexity is 34.651233487207165
At time: 858.5144052505493 and batch: 1400, loss is 3.5790088510513307 and perplexity is 35.83800243960408
At time: 859.8355340957642 and batch: 1450, loss is 3.5102134323120118 and perplexity is 33.455407486965385
At time: 861.1556470394135 and batch: 1500, loss is 3.4833805894851686 and perplexity is 32.569640761298324
At time: 862.4751164913177 and batch: 1550, loss is 3.5087900590896606 and perplexity is 33.40782182991461
At time: 863.7963597774506 and batch: 1600, loss is 3.5961851501464843 and perplexity is 36.45888364455796
At time: 865.1186165809631 and batch: 1650, loss is 3.5268629026412963 and perplexity is 34.01708514409573
At time: 866.438559293747 and batch: 1700, loss is 3.5243723392486572 and perplexity is 33.932468851970256
At time: 867.7606399059296 and batch: 1750, loss is 3.5310429668426515 and perplexity is 34.159576347652255
At time: 869.0769937038422 and batch: 1800, loss is 3.483803868293762 and perplexity is 32.58342971811682
At time: 870.3958179950714 and batch: 1850, loss is 3.5059821367263795 and perplexity is 33.31414683749074
At time: 871.7152426242828 and batch: 1900, loss is 3.6216726016998293 and perplexity is 37.40007095831474
At time: 873.0349323749542 and batch: 1950, loss is 3.569478611946106 and perplexity is 35.49808005091837
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3627197265625 and perplexity of 78.4702621234399
finished 16 epochs...
Completing Train Step...
At time: 877.0015144348145 and batch: 50, loss is 3.814406008720398 and perplexity is 45.34981098881599
At time: 878.3307733535767 and batch: 100, loss is 3.778386912345886 and perplexity is 43.74541959476344
At time: 879.6499283313751 and batch: 150, loss is 3.734434652328491 and perplexity is 41.86435095820846
At time: 880.9722571372986 and batch: 200, loss is 3.7394651889801027 and perplexity is 42.07548171536108
At time: 882.2907078266144 and batch: 250, loss is 3.745352783203125 and perplexity is 42.3239357590398
At time: 883.6089155673981 and batch: 300, loss is 3.7464776468276977 and perplexity is 42.37157120148928
At time: 884.9303743839264 and batch: 350, loss is 3.7724283075332643 and perplexity is 43.48553297680064
At time: 886.2498836517334 and batch: 400, loss is 3.746170859336853 and perplexity is 42.35857412724907
At time: 887.5692157745361 and batch: 450, loss is 3.7779734706878663 and perplexity is 43.72733715423008
At time: 888.8915727138519 and batch: 500, loss is 3.7919577407836913 and perplexity is 44.34312770295308
At time: 890.210462808609 and batch: 550, loss is 3.7672154092788697 and perplexity is 43.25943713715796
At time: 891.5599665641785 and batch: 600, loss is 3.7132216930389403 and perplexity is 40.985637196041004
At time: 892.8854537010193 and batch: 650, loss is 3.7426893854141237 and perplexity is 42.2113602653258
At time: 894.204746723175 and batch: 700, loss is 3.7739980697631834 and perplexity is 43.553848529574424
At time: 895.5240969657898 and batch: 750, loss is 3.7200075340270997 and perplexity is 41.26470499684538
At time: 896.8407526016235 and batch: 800, loss is 3.6926100778579714 and perplexity is 40.1495036472959
At time: 898.1595005989075 and batch: 850, loss is 3.6971507263183594 and perplexity is 40.332222947337236
At time: 899.4788928031921 and batch: 900, loss is 3.652836127281189 and perplexity is 38.583939983194846
At time: 900.8030421733856 and batch: 950, loss is 3.7742947483062745 and perplexity is 43.56677193885651
At time: 902.1246140003204 and batch: 1000, loss is 3.737074317932129 and perplexity is 41.975004825804085
At time: 903.4446957111359 and batch: 1050, loss is 3.6858004474639894 and perplexity is 39.87702914519183
At time: 904.7639513015747 and batch: 1100, loss is 3.695394334793091 and perplexity is 40.26144594701413
At time: 906.0851144790649 and batch: 1150, loss is 3.6672745370864868 and perplexity is 39.14507189872915
At time: 907.4061508178711 and batch: 1200, loss is 3.729371914863586 and perplexity is 41.65293835498684
At time: 908.7278892993927 and batch: 1250, loss is 3.6859904289245606 and perplexity is 39.88460576111756
At time: 910.0517666339874 and batch: 1300, loss is 3.6919000053405764 and perplexity is 40.1210047075233
At time: 911.3698570728302 and batch: 1350, loss is 3.542211527824402 and perplexity is 34.543228090195136
At time: 912.6876728534698 and batch: 1400, loss is 3.5761213302612305 and perplexity is 35.73466872340875
At time: 914.0093712806702 and batch: 1450, loss is 3.5084064960479737 and perplexity is 33.39501028133274
At time: 915.3302879333496 and batch: 1500, loss is 3.4826440143585207 and perplexity is 32.54565960707478
At time: 916.6488358974457 and batch: 1550, loss is 3.50918869972229 and perplexity is 33.42114219998763
At time: 917.9650504589081 and batch: 1600, loss is 3.5973996210098265 and perplexity is 36.50318879466559
At time: 919.2877209186554 and batch: 1650, loss is 3.5286810779571534 and perplexity is 34.078990428898834
At time: 920.6077344417572 and batch: 1700, loss is 3.526500773429871 and perplexity is 34.00476879406716
At time: 921.9275622367859 and batch: 1750, loss is 3.5338445568084715 and perplexity is 34.25541165692139
At time: 923.2468461990356 and batch: 1800, loss is 3.486362295150757 and perplexity is 32.66689876900219
At time: 924.5644543170929 and batch: 1850, loss is 3.5083856058120726 and perplexity is 33.394312658976816
At time: 925.881724357605 and batch: 1900, loss is 3.623611216545105 and perplexity is 37.47264561551347
At time: 927.2019536495209 and batch: 1950, loss is 3.5710278606414794 and perplexity is 35.55311802787413
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361750828942587 and perplexity of 78.39426929381537
finished 17 epochs...
Completing Train Step...
At time: 931.1681740283966 and batch: 50, loss is 3.8118290662765504 and perplexity is 45.233097582511235
At time: 932.4978847503662 and batch: 100, loss is 3.774720287322998 and perplexity is 43.58531524531957
At time: 933.8175601959229 and batch: 150, loss is 3.7303147649765016 and perplexity is 41.692229352468104
At time: 935.1453723907471 and batch: 200, loss is 3.7350288105010985 and perplexity is 41.88923239549386
At time: 936.4645187854767 and batch: 250, loss is 3.7403977060317994 and perplexity is 42.11473611937496
At time: 937.7827925682068 and batch: 300, loss is 3.7412824726104734 and perplexity is 42.15201431918389
At time: 939.0986938476562 and batch: 350, loss is 3.7670277404785155 and perplexity is 43.25131945222835
At time: 940.4170367717743 and batch: 400, loss is 3.741003255844116 and perplexity is 42.140246413025054
At time: 941.7349672317505 and batch: 450, loss is 3.7731066703796388 and perplexity is 43.51504195449233
At time: 943.0540010929108 and batch: 500, loss is 3.786947684288025 and perplexity is 44.121521720749996
At time: 944.372437953949 and batch: 550, loss is 3.7619768619537353 and perplexity is 43.03341306424384
At time: 945.6903624534607 and batch: 600, loss is 3.7086068296432497 and perplexity is 40.79692984343066
At time: 947.0078239440918 and batch: 650, loss is 3.7380690717697145 and perplexity is 42.016780397697595
At time: 948.3310425281525 and batch: 700, loss is 3.769841365814209 and perplexity is 43.3731838203834
At time: 949.6532394886017 and batch: 750, loss is 3.7162136697769164 and perplexity is 41.10844890239021
At time: 950.9725320339203 and batch: 800, loss is 3.6888706922531127 and perplexity is 39.999649527102456
At time: 952.2910797595978 and batch: 850, loss is 3.6932453727722168 and perplexity is 40.1750185266509
At time: 953.6083779335022 and batch: 900, loss is 3.649333395957947 and perplexity is 38.44902722754762
At time: 954.940806388855 and batch: 950, loss is 3.7703572130203247 and perplexity is 43.395563527835996
At time: 956.266964673996 and batch: 1000, loss is 3.7330171203613283 and perplexity is 41.80504894362148
At time: 957.5969443321228 and batch: 1050, loss is 3.6821318912506102 and perplexity is 39.73100603291664
At time: 958.9154777526855 and batch: 1100, loss is 3.691851830482483 and perplexity is 40.11907193037096
At time: 960.2305099964142 and batch: 1150, loss is 3.6640267896652223 and perplexity is 39.0181448175326
At time: 961.548376083374 and batch: 1200, loss is 3.7259011268615723 and perplexity is 41.508620429633176
At time: 962.8670337200165 and batch: 1250, loss is 3.6831579494476316 and perplexity is 39.77179327879822
At time: 964.1858265399933 and batch: 1300, loss is 3.689424505233765 and perplexity is 40.02180798748725
At time: 965.5030183792114 and batch: 1350, loss is 3.540226559638977 and perplexity is 34.474728888273624
At time: 966.8187446594238 and batch: 1400, loss is 3.574184455871582 and perplexity is 35.665522144471595
At time: 968.1359376907349 and batch: 1450, loss is 3.507036118507385 and perplexity is 33.34927785177951
At time: 969.4584255218506 and batch: 1500, loss is 3.481882014274597 and perplexity is 32.520869258046396
At time: 970.7802531719208 and batch: 1550, loss is 3.508940715789795 and perplexity is 33.41285532126526
At time: 972.0976309776306 and batch: 1600, loss is 3.597707829475403 and perplexity is 36.51444112041459
At time: 973.4125728607178 and batch: 1650, loss is 3.5292625522613523 and perplexity is 34.09881224852717
At time: 974.7287521362305 and batch: 1700, loss is 3.5271467399597167 and perplexity is 34.026741832722976
At time: 976.0561227798462 and batch: 1750, loss is 3.534756956100464 and perplexity is 34.28668053294504
At time: 977.3748393058777 and batch: 1800, loss is 3.487064814567566 and perplexity is 32.68985596266732
At time: 978.6929287910461 and batch: 1850, loss is 3.5090852069854734 and perplexity is 33.41768353349034
At time: 980.0101144313812 and batch: 1900, loss is 3.623953590393066 and perplexity is 37.4854774659058
At time: 981.327659368515 and batch: 1950, loss is 3.571045370101929 and perplexity is 35.553740549238086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361304278706395 and perplexity of 78.35927012937029
finished 18 epochs...
Completing Train Step...
At time: 985.2919490337372 and batch: 50, loss is 3.809210844039917 and perplexity is 45.11482218379405
At time: 986.6090397834778 and batch: 100, loss is 3.771587543487549 and perplexity is 43.44898726947615
At time: 987.9264857769012 and batch: 150, loss is 3.726905565261841 and perplexity is 41.5503342278982
At time: 989.2440989017487 and batch: 200, loss is 3.7314508819580077 and perplexity is 41.73962351979357
At time: 990.5726165771484 and batch: 250, loss is 3.736525130271912 and perplexity is 41.95195899993703
At time: 991.9001483917236 and batch: 300, loss is 3.737290554046631 and perplexity is 41.984082319159405
At time: 993.2192022800446 and batch: 350, loss is 3.763013710975647 and perplexity is 43.07805535614797
At time: 994.5369861125946 and batch: 400, loss is 3.7371142864227296 and perplexity is 41.9766825369175
At time: 995.8542773723602 and batch: 450, loss is 3.7694145917892454 and perplexity is 43.354677221497624
At time: 997.1735723018646 and batch: 500, loss is 3.7830728673934937 and perplexity is 43.95088970038361
At time: 998.4927649497986 and batch: 550, loss is 3.757988843917847 and perplexity is 42.862136790234935
At time: 999.811628818512 and batch: 600, loss is 3.7051316356658934 and perplexity is 40.655398665132346
At time: 1001.1300327777863 and batch: 650, loss is 3.734528579711914 and perplexity is 41.8682833518295
At time: 1002.4474856853485 and batch: 700, loss is 3.7666376399993897 and perplexity is 43.23445038231727
At time: 1003.7649939060211 and batch: 750, loss is 3.713252739906311 and perplexity is 40.98690969143653
At time: 1005.084404706955 and batch: 800, loss is 3.6858736991882326 and perplexity is 39.8799503133234
At time: 1006.4028851985931 and batch: 850, loss is 3.6902022123336793 and perplexity is 40.05294533801042
At time: 1007.7209851741791 and batch: 900, loss is 3.6464235496521 and perplexity is 38.33730908784255
At time: 1009.0373282432556 and batch: 950, loss is 3.7672274017333987 and perplexity is 43.25995592710155
At time: 1010.3546874523163 and batch: 1000, loss is 3.729806661605835 and perplexity is 41.67105077111343
At time: 1011.6764633655548 and batch: 1050, loss is 3.6792687702178957 and perplexity is 39.617414045294495
At time: 1012.9951057434082 and batch: 1100, loss is 3.689076714515686 and perplexity is 40.00789119435449
At time: 1014.3131947517395 and batch: 1150, loss is 3.661463236808777 and perplexity is 38.91824784123049
At time: 1015.6326539516449 and batch: 1200, loss is 3.7232288551330566 and perplexity is 41.397846192121186
At time: 1016.9497554302216 and batch: 1250, loss is 3.6808891773223875 and perplexity is 39.68166242468211
At time: 1018.2685458660126 and batch: 1300, loss is 3.6874377489089967 and perplexity is 39.94237334211021
At time: 1019.587094783783 and batch: 1350, loss is 3.53853835105896 and perplexity is 34.4165774548563
At time: 1020.9063301086426 and batch: 1400, loss is 3.57249463558197 and perplexity is 35.60530471415923
At time: 1022.2234244346619 and batch: 1450, loss is 3.505730586051941 and perplexity is 33.30576769531904
At time: 1023.5402064323425 and batch: 1500, loss is 3.481003608703613 and perplexity is 32.49231528813601
At time: 1024.8575744628906 and batch: 1550, loss is 3.5083748292922974 and perplexity is 33.393952786445155
At time: 1026.1772344112396 and batch: 1600, loss is 3.5975392055511475 and perplexity is 36.50828443115801
At time: 1027.4957814216614 and batch: 1650, loss is 3.5292946195602415 and perplexity is 34.099905722863596
At time: 1028.8141281604767 and batch: 1700, loss is 3.527212390899658 and perplexity is 34.02897579363745
At time: 1030.1363461017609 and batch: 1750, loss is 3.5349832820892333 and perplexity is 34.29444137802562
At time: 1031.4531457424164 and batch: 1800, loss is 3.4871499490737916 and perplexity is 32.6926391158828
At time: 1032.7727572917938 and batch: 1850, loss is 3.509212112426758 and perplexity is 33.42192468847299
At time: 1034.0924320220947 and batch: 1900, loss is 3.6238157653808596 and perplexity is 37.48031138553221
At time: 1035.4110538959503 and batch: 1950, loss is 3.570625190734863 and perplexity is 35.53880473911666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3611013013263085 and perplexity of 78.34336658409849
finished 19 epochs...
Completing Train Step...
At time: 1039.3880186080933 and batch: 50, loss is 3.806749310493469 and perplexity is 45.003907102147984
At time: 1040.707010269165 and batch: 100, loss is 3.768838057518005 and perplexity is 43.32968896824522
At time: 1042.0267896652222 and batch: 150, loss is 3.7239750909805296 and perplexity is 41.4287502783923
At time: 1043.3464164733887 and batch: 200, loss is 3.7283934450149534 and perplexity is 41.612202143526936
At time: 1044.6622684001923 and batch: 250, loss is 3.733260374069214 and perplexity is 41.81521941373749
At time: 1045.9794652462006 and batch: 300, loss is 3.7339596939086914 and perplexity is 41.8444718534792
At time: 1047.298044204712 and batch: 350, loss is 3.759727635383606 and perplexity is 42.93672994006244
At time: 1048.6175813674927 and batch: 400, loss is 3.7338770723342893 and perplexity is 41.84101474015268
At time: 1049.937159538269 and batch: 450, loss is 3.76631721496582 and perplexity is 43.22059920135323
At time: 1051.2541010379791 and batch: 500, loss is 3.779779148101807 and perplexity is 43.8063659480827
At time: 1052.5710582733154 and batch: 550, loss is 3.754634895324707 and perplexity is 42.718620195024144
At time: 1053.8897759914398 and batch: 600, loss is 3.702168426513672 and perplexity is 40.53510652911963
At time: 1055.219609260559 and batch: 650, loss is 3.731519422531128 and perplexity is 41.74248447555609
At time: 1056.5371594429016 and batch: 700, loss is 3.7638702297210695 and perplexity is 43.114968324144684
At time: 1057.8542943000793 and batch: 750, loss is 3.710674138069153 and perplexity is 40.88135691858044
At time: 1059.1710562705994 and batch: 800, loss is 3.6832327175140382 and perplexity is 39.77476705004938
At time: 1060.4882805347443 and batch: 850, loss is 3.6875796556472777 and perplexity is 39.94804183621964
At time: 1061.805512189865 and batch: 900, loss is 3.6438472127914427 and perplexity is 38.23866638827443
At time: 1063.1234233379364 and batch: 950, loss is 3.764518370628357 and perplexity is 43.1429219567998
At time: 1064.441725730896 and batch: 1000, loss is 3.7270426177978515 and perplexity is 41.55602919682227
At time: 1065.7581827640533 and batch: 1050, loss is 3.6767893505096434 and perplexity is 39.51930752200361
At time: 1067.0776867866516 and batch: 1100, loss is 3.6866621589660644 and perplexity is 39.91140644940681
At time: 1068.3965458869934 and batch: 1150, loss is 3.659203553199768 and perplexity is 38.83040420128769
At time: 1069.715535402298 and batch: 1200, loss is 3.7209383916854857 and perplexity is 41.30313444691177
At time: 1071.0340402126312 and batch: 1250, loss is 3.6788982057571413 and perplexity is 39.60273595937878
At time: 1072.3525705337524 and batch: 1300, loss is 3.6857118892669676 and perplexity is 39.873497863752405
At time: 1073.6696825027466 and batch: 1350, loss is 3.5370074701309204 and perplexity is 34.36393008153414
At time: 1074.988065958023 and batch: 1400, loss is 3.5709467220306395 and perplexity is 35.550233414294674
At time: 1076.3082921504974 and batch: 1450, loss is 3.5044805431365966 and perplexity is 33.26416006744966
At time: 1077.6274869441986 and batch: 1500, loss is 3.480089054107666 and perplexity is 32.46261287616526
At time: 1078.9447481632233 and batch: 1550, loss is 3.507684898376465 and perplexity is 33.37092121202715
At time: 1080.261386871338 and batch: 1600, loss is 3.597157106399536 and perplexity is 36.49433731141108
At time: 1081.5798161029816 and batch: 1650, loss is 3.52907630443573 and perplexity is 34.092462010266956
At time: 1082.8994970321655 and batch: 1700, loss is 3.5270291996002197 and perplexity is 34.02274255229848
At time: 1084.2179625034332 and batch: 1750, loss is 3.5349178600311277 and perplexity is 34.29219783847837
At time: 1085.5364427566528 and batch: 1800, loss is 3.48699245929718 and perplexity is 32.68749076486856
At time: 1086.8535027503967 and batch: 1850, loss is 3.509095368385315 and perplexity is 33.41802310565976
At time: 1088.1718904972076 and batch: 1900, loss is 3.623495407104492 and perplexity is 37.46830618066507
At time: 1089.4920761585236 and batch: 1950, loss is 3.570055079460144 and perplexity is 35.518549440280594
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361046511627907 and perplexity of 78.33907429225935
Finished Training.
Improved accuracyfrom -10000000 to -78.33907429225935
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f00fbd17b38>
ELAPSED
1120.9746465682983


RESULTS SO FAR:
[{'params': {'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}, 'best_accuracy': -78.33907429225935}]
SETTINGS FOR THIS RUN
{'dropout': 0.16802636512990798, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.23001756521426064}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9427235126495361 and batch: 50, loss is 7.629502515792847 and perplexity is 2058.025929726187
At time: 3.4753451347351074 and batch: 100, loss is 6.667903985977173 and perplexity is 786.744846830069
At time: 5.010623216629028 and batch: 150, loss is 6.344685497283936 and perplexity is 569.4582653782123
At time: 6.546144962310791 and batch: 200, loss is 6.122641878128052 and perplexity is 456.06798035457433
At time: 8.083297491073608 and batch: 250, loss is 5.992799854278564 and perplexity is 400.53447963606135
At time: 9.619022846221924 and batch: 300, loss is 5.924746789932251 and perplexity is 374.18367628977893
At time: 11.156238794326782 and batch: 350, loss is 5.818510332107544 and perplexity is 336.4704508846352
At time: 12.695475578308105 and batch: 400, loss is 5.748674468994141 and perplexity is 313.7744667234085
At time: 14.2311851978302 and batch: 450, loss is 5.66132043838501 and perplexity is 287.5280550861958
At time: 15.76844072341919 and batch: 500, loss is 5.626179933547974 and perplexity is 277.5996404847268
At time: 17.3036367893219 and batch: 550, loss is 5.5578824901580814 and perplexity is 259.27324100199087
At time: 18.840769290924072 and batch: 600, loss is 5.5723238277435305 and perplexity is 263.0446600252263
At time: 20.375190496444702 and batch: 650, loss is 5.6387544441223145 and perplexity is 281.1123591732738
At time: 21.909453868865967 and batch: 700, loss is 5.550213232040405 and perplexity is 257.29241304313115
At time: 23.447603702545166 and batch: 750, loss is 5.486571216583252 and perplexity is 241.42798179346923
At time: 24.987860918045044 and batch: 800, loss is 5.4739457130432125 and perplexity is 238.39899344204596
At time: 26.524470329284668 and batch: 850, loss is 5.47994722366333 and perplexity is 239.83404947769927
At time: 28.061678886413574 and batch: 900, loss is 5.47154167175293 and perplexity is 237.8265607698332
At time: 29.599177598953247 and batch: 950, loss is 5.505375671386719 and perplexity is 246.01085756137147
At time: 31.136157989501953 and batch: 1000, loss is 5.465521430969238 and perplexity is 236.39908878313267
At time: 32.67454934120178 and batch: 1050, loss is 5.3713927078247075 and perplexity is 215.1623173759748
At time: 34.21325373649597 and batch: 1100, loss is 5.4523137664794925 and perplexity is 233.29733746777
At time: 35.751306772232056 and batch: 1150, loss is 5.356100378036499 and perplexity is 211.89701493534548
At time: 37.28941583633423 and batch: 1200, loss is 5.414874458312989 and perplexity is 224.72433163592746
At time: 38.82617497444153 and batch: 1250, loss is 5.3547326183319095 and perplexity is 211.6073888513896
At time: 40.36515283584595 and batch: 1300, loss is 5.3690291786193844 and perplexity is 214.65437545920753
At time: 41.89985394477844 and batch: 1350, loss is 5.310832605361939 and perplexity is 202.5187764305581
At time: 43.43863892555237 and batch: 1400, loss is 5.319806108474731 and perplexity is 204.34425753189578
At time: 44.97746300697327 and batch: 1450, loss is 5.265875253677368 and perplexity is 193.61569749879388
At time: 46.514495849609375 and batch: 1500, loss is 5.234890060424805 and perplexity is 187.70846862046776
At time: 48.04987335205078 and batch: 1550, loss is 5.212592754364014 and perplexity is 183.5693920578192
At time: 49.58802318572998 and batch: 1600, loss is 5.25575608253479 and perplexity is 191.66634666133083
At time: 51.12590527534485 and batch: 1650, loss is 5.228366470336914 and perplexity is 186.48792101986703
At time: 52.663564682006836 and batch: 1700, loss is 5.237387075424194 and perplexity is 188.1777651585309
At time: 54.19976854324341 and batch: 1750, loss is 5.25167326927185 and perplexity is 190.88540406533468
At time: 55.74032115936279 and batch: 1800, loss is 5.225047397613525 and perplexity is 185.869980110659
At time: 57.277957916259766 and batch: 1850, loss is 5.212226600646972 and perplexity is 183.50218974652103
At time: 58.81574630737305 and batch: 1900, loss is 5.245114078521729 and perplexity is 189.6374475552859
At time: 60.362329721450806 and batch: 1950, loss is 5.167562141418457 and perplexity is 175.48650430787615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.913311909520349 and perplexity of 136.08938459535148
finished 1 epochs...
Completing Train Step...
At time: 64.41760444641113 and batch: 50, loss is 5.089172601699829 and perplexity is 162.25555652740513
At time: 65.73419046401978 and batch: 100, loss is 5.026271362304687 and perplexity is 152.3638426734383
At time: 67.05059933662415 and batch: 150, loss is 4.950195560455322 and perplexity is 141.2025748614174
At time: 68.36646151542664 and batch: 200, loss is 4.927438020706177 and perplexity is 138.02544065049423
At time: 69.68192648887634 and batch: 250, loss is 4.939139766693115 and perplexity is 139.65006623628014
At time: 70.99857068061829 and batch: 300, loss is 4.955437688827515 and perplexity is 141.94472039690214
At time: 72.34580707550049 and batch: 350, loss is 4.93905556678772 and perplexity is 139.63830820893392
At time: 73.66261053085327 and batch: 400, loss is 4.906420526504516 and perplexity is 135.15476463263053
At time: 74.97903299331665 and batch: 450, loss is 4.877517757415771 and perplexity is 131.30432983424194
At time: 76.29410433769226 and batch: 500, loss is 4.868777770996093 and perplexity is 130.16173219191012
At time: 77.60834240913391 and batch: 550, loss is 4.822888059616089 and perplexity is 124.32362683985878
At time: 78.92323970794678 and batch: 600, loss is 4.808790788650513 and perplexity is 122.58329874486643
At time: 80.24009108543396 and batch: 650, loss is 4.873200492858887 and perplexity is 130.73867622162027
At time: 81.55661010742188 and batch: 700, loss is 4.870401945114136 and perplexity is 130.37330928100116
At time: 82.87031483650208 and batch: 750, loss is 4.826795034408569 and perplexity is 124.81030621899063
At time: 84.18469476699829 and batch: 800, loss is 4.811822681427002 and perplexity is 122.95552214843879
At time: 85.49997115135193 and batch: 850, loss is 4.813662528991699 and perplexity is 123.18194979873793
At time: 86.81781935691833 and batch: 900, loss is 4.800644207000732 and perplexity is 121.58872059935071
At time: 88.13300919532776 and batch: 950, loss is 4.873780107498169 and perplexity is 130.814476237556
At time: 89.44661092758179 and batch: 1000, loss is 4.840440492630005 and perplexity is 126.52507281893695
At time: 90.75912356376648 and batch: 1050, loss is 4.75738904953003 and perplexity is 116.44150565492411
At time: 92.07402896881104 and batch: 1100, loss is 4.8226315307617185 and perplexity is 124.29173833263037
At time: 93.39449882507324 and batch: 1150, loss is 4.73929759979248 and perplexity is 114.35385129551811
At time: 94.7107834815979 and batch: 1200, loss is 4.818637027740478 and perplexity is 123.79624489221104
At time: 96.02714395523071 and batch: 1250, loss is 4.772960233688354 and perplexity is 118.26882764560418
At time: 97.34151220321655 and batch: 1300, loss is 4.799295082092285 and perplexity is 121.42479283218506
At time: 98.655770778656 and batch: 1350, loss is 4.688987245559693 and perplexity is 108.74299407118912
At time: 99.97057271003723 and batch: 1400, loss is 4.712518367767334 and perplexity is 111.33218253768773
At time: 101.30498552322388 and batch: 1450, loss is 4.654323406219483 and perplexity is 105.03812780735272
At time: 102.63414430618286 and batch: 1500, loss is 4.632516965866089 and perplexity is 102.77241350256489
At time: 103.95959329605103 and batch: 1550, loss is 4.629344329833985 and perplexity is 102.44687072781466
At time: 105.27374339103699 and batch: 1600, loss is 4.705847816467285 and perplexity is 110.5920069369663
At time: 106.58756256103516 and batch: 1650, loss is 4.656405954360962 and perplexity is 105.25710269893787
At time: 107.90466117858887 and batch: 1700, loss is 4.688335886001587 and perplexity is 108.67218634577166
At time: 109.22074556350708 and batch: 1750, loss is 4.693894653320313 and perplexity is 109.27795183855706
At time: 110.53671526908875 and batch: 1800, loss is 4.649640159606934 and perplexity is 104.5473584450823
At time: 111.85137248039246 and batch: 1850, loss is 4.664622182846069 and perplexity is 106.12548161911282
At time: 113.1662175655365 and batch: 1900, loss is 4.737114276885986 and perplexity is 114.10445227091209
At time: 114.48160886764526 and batch: 1950, loss is 4.664219570159912 and perplexity is 106.08276275404398
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.604165436500727 and perplexity of 99.89957551043918
finished 2 epochs...
Completing Train Step...
At time: 118.4547975063324 and batch: 50, loss is 4.639500284194947 and perplexity is 103.49261776245075
At time: 119.79217553138733 and batch: 100, loss is 4.57504864692688 and perplexity is 97.03275936766997
At time: 121.10756778717041 and batch: 150, loss is 4.5213847255706785 and perplexity is 91.96285316539762
At time: 122.42481970787048 and batch: 200, loss is 4.520155515670776 and perplexity is 91.84988096336271
At time: 123.74096965789795 and batch: 250, loss is 4.52822265625 and perplexity is 92.59384365641814
At time: 125.05583548545837 and batch: 300, loss is 4.553855190277099 and perplexity is 94.99793839664291
At time: 126.37111806869507 and batch: 350, loss is 4.553064517974853 and perplexity is 94.92285584474085
At time: 127.68570685386658 and batch: 400, loss is 4.517839679718017 and perplexity is 91.63741781662308
At time: 129.00135922431946 and batch: 450, loss is 4.513232221603394 and perplexity is 91.21617343043799
At time: 130.31759405136108 and batch: 500, loss is 4.5276006317138675 and perplexity is 92.536265923007
At time: 131.63334393501282 and batch: 550, loss is 4.475963668823242 and perplexity is 87.87924610767817
At time: 132.947655916214 and batch: 600, loss is 4.4563231277465825 and perplexity is 86.17008948715261
At time: 134.26365208625793 and batch: 650, loss is 4.514256610870361 and perplexity is 91.3096621757322
At time: 135.58003425598145 and batch: 700, loss is 4.543025255203247 and perplexity is 93.9746678697256
At time: 136.89452743530273 and batch: 750, loss is 4.504341506958008 and perplexity is 90.40879088361682
At time: 138.22150301933289 and batch: 800, loss is 4.486359853744506 and perplexity is 88.79762052455938
At time: 139.535418510437 and batch: 850, loss is 4.476457414627075 and perplexity is 87.92264683026843
At time: 140.85034489631653 and batch: 900, loss is 4.46913631439209 and perplexity is 87.28130684163928
At time: 142.16563987731934 and batch: 950, loss is 4.54686505317688 and perplexity is 94.33620528008214
At time: 143.48183917999268 and batch: 1000, loss is 4.524021768569947 and perplexity is 92.2056831994309
At time: 144.79865622520447 and batch: 1050, loss is 4.4532499027252195 and perplexity is 85.90567592134994
At time: 146.11319708824158 and batch: 1100, loss is 4.4936776542663575 and perplexity is 89.44980717388307
At time: 147.42763543128967 and batch: 1150, loss is 4.432285928726197 and perplexity is 84.12349760496062
At time: 148.7450668811798 and batch: 1200, loss is 4.514354982376099 and perplexity is 91.31864488650298
At time: 150.0620355606079 and batch: 1250, loss is 4.484252939224243 and perplexity is 88.61072848042795
At time: 151.37862968444824 and batch: 1300, loss is 4.498099136352539 and perplexity is 89.84618353365529
At time: 152.69373893737793 and batch: 1350, loss is 4.377160501480103 and perplexity is 79.61165498010334
At time: 154.01616048812866 and batch: 1400, loss is 4.418201503753662 and perplexity is 82.94697131166583
At time: 155.33141613006592 and batch: 1450, loss is 4.347082319259644 and perplexity is 77.25273496738161
At time: 156.64843916893005 and batch: 1500, loss is 4.342368016242981 and perplexity is 76.88939927606943
At time: 157.96578121185303 and batch: 1550, loss is 4.3357017040252686 and perplexity is 76.37853521581258
At time: 159.28128933906555 and batch: 1600, loss is 4.429014387130738 and perplexity is 83.84873377909915
At time: 160.59549069404602 and batch: 1650, loss is 4.378055362701416 and perplexity is 79.68292824799524
At time: 161.91154265403748 and batch: 1700, loss is 4.414778366088867 and perplexity is 82.66351783691026
At time: 163.22791528701782 and batch: 1750, loss is 4.419426584243775 and perplexity is 83.0486502976879
At time: 164.54328775405884 and batch: 1800, loss is 4.368692979812622 and perplexity is 78.9403875630325
At time: 165.86003041267395 and batch: 1850, loss is 4.393121366500854 and perplexity is 80.89252052887761
At time: 167.1744740009308 and batch: 1900, loss is 4.47602746963501 and perplexity is 87.88485305377935
At time: 168.49015474319458 and batch: 1950, loss is 4.416141443252563 and perplexity is 82.77627141880305
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.528265522801599 and perplexity of 92.59781292026871
finished 3 epochs...
Completing Train Step...
At time: 172.45883870124817 and batch: 50, loss is 4.393083095550537 and perplexity is 80.8894247544829
At time: 173.78576803207397 and batch: 100, loss is 4.326058893203736 and perplexity is 75.6455710467852
At time: 175.0999653339386 and batch: 150, loss is 4.278402051925659 and perplexity is 72.12509571696316
At time: 176.4143190383911 and batch: 200, loss is 4.280751523971557 and perplexity is 72.29475083509503
At time: 177.7360315322876 and batch: 250, loss is 4.281365776062012 and perplexity is 72.33917167832561
At time: 179.05595636367798 and batch: 300, loss is 4.310763168334961 and perplexity is 74.49732124789409
At time: 180.37313842773438 and batch: 350, loss is 4.311101503372193 and perplexity is 74.52253056620953
At time: 181.68815279006958 and batch: 400, loss is 4.277644147872925 and perplexity is 72.07045252437968
At time: 183.0018653869629 and batch: 450, loss is 4.292310600280762 and perplexity is 73.13525977171831
At time: 184.31791877746582 and batch: 500, loss is 4.311150455474854 and perplexity is 74.52617869006731
At time: 185.63179898262024 and batch: 550, loss is 4.2666555023193355 and perplexity is 71.2828312377222
At time: 186.94831466674805 and batch: 600, loss is 4.240793771743775 and perplexity is 69.46296770215447
At time: 188.26312828063965 and batch: 650, loss is 4.295662899017334 and perplexity is 73.38084241385418
At time: 189.5771210193634 and batch: 700, loss is 4.332124223709107 and perplexity is 76.10578068737998
At time: 190.89212918281555 and batch: 750, loss is 4.295317049026489 and perplexity is 73.3554680382939
At time: 192.20818996429443 and batch: 800, loss is 4.273254795074463 and perplexity is 71.75480313695229
At time: 193.52452683448792 and batch: 850, loss is 4.261845979690552 and perplexity is 70.94081796739542
At time: 194.8393669128418 and batch: 900, loss is 4.249454398155212 and perplexity is 70.06717313702214
At time: 196.15345239639282 and batch: 950, loss is 4.338600492477417 and perplexity is 76.60026164543157
At time: 197.46776056289673 and batch: 1000, loss is 4.3161558914184575 and perplexity is 74.90014986720668
At time: 198.78460836410522 and batch: 1050, loss is 4.255319061279297 and perplexity is 70.47930081729686
At time: 200.10075187683105 and batch: 1100, loss is 4.2899309206008915 and perplexity is 72.96142819392642
At time: 201.41596674919128 and batch: 1150, loss is 4.233047437667847 and perplexity is 68.92696306419886
At time: 202.72940587997437 and batch: 1200, loss is 4.315964531898499 and perplexity is 74.88581838176007
At time: 204.08314728736877 and batch: 1250, loss is 4.286744647026062 and perplexity is 72.72932309482964
At time: 205.40252327919006 and batch: 1300, loss is 4.302336349487304 and perplexity is 73.87218347778902
At time: 206.7224748134613 and batch: 1350, loss is 4.17415418624878 and perplexity is 64.98485132847665
At time: 208.03851795196533 and batch: 1400, loss is 4.217324991226196 and perplexity is 67.85173731778167
At time: 209.35344982147217 and batch: 1450, loss is 4.148147535324097 and perplexity is 63.316599827005525
At time: 210.6686475276947 and batch: 1500, loss is 4.149083695411682 and perplexity is 63.375902054503406
At time: 211.9855432510376 and batch: 1550, loss is 4.1434859991073605 and perplexity is 63.02213406841672
At time: 213.30332231521606 and batch: 1600, loss is 4.2412848377227785 and perplexity is 69.49708697911608
At time: 214.62642359733582 and batch: 1650, loss is 4.188279294967652 and perplexity is 65.90928289670934
At time: 215.94329476356506 and batch: 1700, loss is 4.229614028930664 and perplexity is 68.69071442813303
At time: 217.25786542892456 and batch: 1750, loss is 4.229486174583435 and perplexity is 68.68193258308966
At time: 218.5790605545044 and batch: 1800, loss is 4.172041664123535 and perplexity is 64.8477142957481
At time: 219.90556263923645 and batch: 1850, loss is 4.207929801940918 and perplexity is 67.21724266822065
At time: 221.23156476020813 and batch: 1900, loss is 4.2907912635803225 and perplexity is 73.02422705684916
At time: 222.55699467658997 and batch: 1950, loss is 4.232700080871582 and perplexity is 68.90302497290264
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482791208666424 and perplexity of 88.48129809008157
finished 4 epochs...
Completing Train Step...
At time: 226.542133808136 and batch: 50, loss is 4.208880076408386 and perplexity is 67.28114785662731
At time: 227.88943219184875 and batch: 100, loss is 4.153085265159607 and perplexity is 63.63001322962686
At time: 229.22756910324097 and batch: 150, loss is 4.10569209098816 and perplexity is 60.68472937158796
At time: 230.55649971961975 and batch: 200, loss is 4.1079590702056885 and perplexity is 60.82245644511757
At time: 231.89069294929504 and batch: 250, loss is 4.105276079177856 and perplexity is 60.659489057962624
At time: 233.2183814048767 and batch: 300, loss is 4.1359293222427365 and perplexity is 62.54769102999771
At time: 234.53609013557434 and batch: 350, loss is 4.137560405731201 and perplexity is 62.64979478331472
At time: 235.88454174995422 and batch: 400, loss is 4.105596017837525 and perplexity is 60.67889947849439
At time: 237.19874095916748 and batch: 450, loss is 4.129177107810974 and perplexity is 62.12677825381321
At time: 238.52342176437378 and batch: 500, loss is 4.152746434211731 and perplexity is 63.60845706408514
At time: 239.84350109100342 and batch: 550, loss is 4.106411304473877 and perplexity is 60.72839034622796
At time: 241.16069507598877 and batch: 600, loss is 4.081055717468262 and perplexity is 59.20794372715064
At time: 242.47825622558594 and batch: 650, loss is 4.1380300617218015 and perplexity is 62.67922554537046
At time: 243.79321599006653 and batch: 700, loss is 4.179048795700073 and perplexity is 65.30370649516325
At time: 245.1093785762787 and batch: 750, loss is 4.140413479804993 and perplexity is 62.82879451686692
At time: 246.42459416389465 and batch: 800, loss is 4.114656758308411 and perplexity is 61.23119355691253
At time: 247.7422137260437 and batch: 850, loss is 4.101578245162964 and perplexity is 60.43559455348258
At time: 249.05919408798218 and batch: 900, loss is 4.087118020057678 and perplexity is 59.5679703903818
At time: 250.37768268585205 and batch: 950, loss is 4.186983141899109 and perplexity is 65.8239097177436
At time: 251.69308924674988 and batch: 1000, loss is 4.1670154237747195 and perplexity is 64.52259185386045
At time: 253.0099413394928 and batch: 1050, loss is 4.106106939315796 and perplexity is 60.709909552697745
At time: 254.32601809501648 and batch: 1100, loss is 4.13518846988678 and perplexity is 62.501369586532405
At time: 255.64510297775269 and batch: 1150, loss is 4.086811437606811 and perplexity is 59.5497106952204
At time: 256.9626085758209 and batch: 1200, loss is 4.164156064987183 and perplexity is 64.3383621288109
At time: 258.2782323360443 and batch: 1250, loss is 4.144799399375915 and perplexity is 63.10496173726171
At time: 259.59405541419983 and batch: 1300, loss is 4.145662651062012 and perplexity is 63.159460721668154
At time: 260.9106113910675 and batch: 1350, loss is 4.016999754905701 and perplexity is 55.53423930269722
At time: 262.2267827987671 and batch: 1400, loss is 4.066801996231079 and perplexity is 58.3699963235878
At time: 263.54410219192505 and batch: 1450, loss is 3.9972980546951296 and perplexity is 54.45082793575941
At time: 264.86074924468994 and batch: 1500, loss is 4.004184303283691 and perplexity is 54.82708388191706
At time: 266.1744077205658 and batch: 1550, loss is 4.000826926231384 and perplexity is 54.64331734803662
At time: 267.48943185806274 and batch: 1600, loss is 4.102136249542236 and perplexity is 60.4693272905396
At time: 268.8039743900299 and batch: 1650, loss is 4.048835892677307 and perplexity is 57.330679121272034
At time: 270.12112832069397 and batch: 1700, loss is 4.082956566810608 and perplexity is 59.32059614176025
At time: 271.43719363212585 and batch: 1750, loss is 4.086987524032593 and perplexity is 59.5601975141992
At time: 272.751088142395 and batch: 1800, loss is 4.026593680381775 and perplexity is 56.06959462916946
At time: 274.07049345970154 and batch: 1850, loss is 4.069580144882202 and perplexity is 58.53238231190473
At time: 275.38939237594604 and batch: 1900, loss is 4.150605669021607 and perplexity is 63.472431944274405
At time: 276.7113130092621 and batch: 1950, loss is 4.089610772132874 and perplexity is 59.716643798174765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4424952307412795 and perplexity of 84.98673884589951
finished 5 epochs...
Completing Train Step...
At time: 280.72998332977295 and batch: 50, loss is 4.0734072160720824 and perplexity is 58.75681909977418
At time: 282.0507972240448 and batch: 100, loss is 4.0154251909255985 and perplexity is 55.44686589539051
At time: 283.3712360858917 and batch: 150, loss is 3.9696623039245607 and perplexity is 52.96664119235446
At time: 284.6909191608429 and batch: 200, loss is 3.979126205444336 and perplexity is 53.47029175897921
At time: 286.01032161712646 and batch: 250, loss is 3.968803973197937 and perplexity is 52.92119780225202
At time: 287.32878589630127 and batch: 300, loss is 3.9976945734024047 and perplexity is 54.47242298880088
At time: 288.64783787727356 and batch: 350, loss is 4.001477808952331 and perplexity is 54.67889531640007
At time: 289.96898889541626 and batch: 400, loss is 3.9734622764587404 and perplexity is 53.16829587258206
At time: 291.29029512405396 and batch: 450, loss is 4.0002923631668095 and perplexity is 54.614114854839066
At time: 292.6109414100647 and batch: 500, loss is 4.0256630182266235 and perplexity is 56.01743705369881
At time: 293.9296898841858 and batch: 550, loss is 3.979271802902222 and perplexity is 53.47807746430742
At time: 295.24949383735657 and batch: 600, loss is 3.9575574588775635 and perplexity is 52.32935312636026
At time: 296.5689663887024 and batch: 650, loss is 4.021478471755981 and perplexity is 55.78351924648196
At time: 297.89699840545654 and batch: 700, loss is 4.052789835929871 and perplexity is 57.55781010875877
At time: 299.23200964927673 and batch: 750, loss is 4.018491377830506 and perplexity is 55.617137258027775
At time: 300.5534691810608 and batch: 800, loss is 3.993169174194336 and perplexity is 54.22647046536636
At time: 301.90342926979065 and batch: 850, loss is 3.973515815734863 and perplexity is 53.17114254085935
At time: 303.22322630882263 and batch: 900, loss is 3.965081715583801 and perplexity is 52.72457763326157
At time: 304.54440808296204 and batch: 950, loss is 4.060626330375672 and perplexity is 58.01063352473483
At time: 305.8668797016144 and batch: 1000, loss is 4.045690741539001 and perplexity is 57.15064873037304
At time: 307.18711614608765 and batch: 1050, loss is 3.99163209438324 and perplexity is 54.14318407769738
At time: 308.5062024593353 and batch: 1100, loss is 4.010642952919007 and perplexity is 55.18233880584982
At time: 309.8221187591553 and batch: 1150, loss is 3.969647469520569 and perplexity is 52.9658554696288
At time: 311.14361906051636 and batch: 1200, loss is 4.046919927597046 and perplexity is 57.22094070310674
At time: 312.4623215198517 and batch: 1250, loss is 4.028891263008117 and perplexity is 56.19856726155924
At time: 313.7777874469757 and batch: 1300, loss is 4.025218992233277 and perplexity is 55.99256937692231
At time: 315.09316420555115 and batch: 1350, loss is 3.897647910118103 and perplexity is 49.286386653016194
At time: 316.4101736545563 and batch: 1400, loss is 3.9476261854171755 and perplexity is 51.81222811574195
At time: 317.7293291091919 and batch: 1450, loss is 3.878349814414978 and perplexity is 48.344372025708395
At time: 319.05055356025696 and batch: 1500, loss is 3.8871608448028563 and perplexity is 48.77221787012378
At time: 320.3764193058014 and batch: 1550, loss is 3.88726936340332 and perplexity is 48.777510850136764
At time: 321.69587874412537 and batch: 1600, loss is 3.9897729206085204 and perplexity is 54.04261600550952
At time: 323.01314306259155 and batch: 1650, loss is 3.937542128562927 and perplexity is 51.29237617516646
At time: 324.3327069282532 and batch: 1700, loss is 3.973252830505371 and perplexity is 53.15716115426556
At time: 325.6532940864563 and batch: 1750, loss is 3.9758041429519655 and perplexity is 53.292954833537145
At time: 326.97329568862915 and batch: 1800, loss is 3.9120415258407593 and perplexity is 50.00092602920586
At time: 328.2921874523163 and batch: 1850, loss is 3.96056293964386 and perplexity is 52.48686457093724
At time: 329.61147832870483 and batch: 1900, loss is 4.038233213424682 and perplexity is 56.72603142636868
At time: 330.93956112861633 and batch: 1950, loss is 3.9772853565216066 and perplexity is 53.3719515724805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.45094476744186 and perplexity of 85.70787977776247
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 335.02244567871094 and batch: 50, loss is 3.9968004846572875 and perplexity is 54.42374157448262
At time: 336.3407998085022 and batch: 100, loss is 3.9770796966552733 and perplexity is 53.3609762326863
At time: 337.6601827144623 and batch: 150, loss is 3.9295136594772337 and perplexity is 50.88222556253347
At time: 338.9807639122009 and batch: 200, loss is 3.931308178901672 and perplexity is 50.97361668170782
At time: 340.3006091117859 and batch: 250, loss is 3.9241717147827146 and perplexity is 50.61114023371044
At time: 341.618656873703 and batch: 300, loss is 3.9434186935424806 and perplexity is 51.594686560027036
At time: 342.9340567588806 and batch: 350, loss is 3.948694124221802 and perplexity is 51.86758996097067
At time: 344.2523989677429 and batch: 400, loss is 3.914955620765686 and perplexity is 50.14684598302558
At time: 345.5704610347748 and batch: 450, loss is 3.936215057373047 and perplexity is 51.22435268647306
At time: 346.8889582157135 and batch: 500, loss is 3.9492835187911988 and perplexity is 51.89816944762781
At time: 348.2071440219879 and batch: 550, loss is 3.8994385814666748 and perplexity is 49.37472143915186
At time: 349.5248863697052 and batch: 600, loss is 3.871043462753296 and perplexity is 47.99243828426226
At time: 350.8403284549713 and batch: 650, loss is 3.9305173349380493 and perplexity is 50.933320440770736
At time: 352.1583878993988 and batch: 700, loss is 3.959133734703064 and perplexity is 52.41190366477407
At time: 353.4776179790497 and batch: 750, loss is 3.9086222076416015 and perplexity is 49.830248918826925
At time: 354.7972722053528 and batch: 800, loss is 3.877571244239807 and perplexity is 48.30674718820057
At time: 356.1151793003082 and batch: 850, loss is 3.8636143684387205 and perplexity is 47.63721904622657
At time: 357.4306700229645 and batch: 900, loss is 3.8412266778945923 and perplexity is 46.582581229477285
At time: 358.7481458187103 and batch: 950, loss is 3.9318052673339845 and perplexity is 50.99896137566863
At time: 360.0657637119293 and batch: 1000, loss is 3.906932053565979 and perplexity is 49.74609925350936
At time: 361.383496761322 and batch: 1050, loss is 3.8455706310272215 and perplexity is 46.78537392121911
At time: 362.7012038230896 and batch: 1100, loss is 3.856972408294678 and perplexity is 47.321862986482046
At time: 364.0168240070343 and batch: 1150, loss is 3.818473415374756 and perplexity is 45.534642749955175
At time: 365.3346438407898 and batch: 1200, loss is 3.8674341297149657 and perplexity is 47.81952982099799
At time: 366.65291118621826 and batch: 1250, loss is 3.84453471660614 and perplexity is 46.73693337214198
At time: 367.97031831741333 and batch: 1300, loss is 3.845394730567932 and perplexity is 46.77714507620837
At time: 369.28815269470215 and batch: 1350, loss is 3.716291460990906 and perplexity is 41.11164690292211
At time: 370.6064531803131 and batch: 1400, loss is 3.7511257219314573 and perplexity is 42.56897586715004
At time: 371.92298460006714 and batch: 1450, loss is 3.6740337133407595 and perplexity is 39.410556557224794
At time: 373.23912358283997 and batch: 1500, loss is 3.6747309017181395 and perplexity is 39.4380427196057
At time: 374.55512022972107 and batch: 1550, loss is 3.666676502227783 and perplexity is 39.12166877982521
At time: 375.8735611438751 and batch: 1600, loss is 3.756804986000061 and perplexity is 42.81142413443504
At time: 377.19098353385925 and batch: 1650, loss is 3.6928146839141847 and perplexity is 40.157719319355564
At time: 378.50727939605713 and batch: 1700, loss is 3.7215882682800294 and perplexity is 41.329985111134214
At time: 379.8240416049957 and batch: 1750, loss is 3.705878200531006 and perplexity is 40.68576189000104
At time: 381.14290618896484 and batch: 1800, loss is 3.6387318658828733 and perplexity is 38.043561783683316
At time: 382.4611644744873 and batch: 1850, loss is 3.6661927843093873 and perplexity is 39.10274950380416
At time: 383.78046560287476 and batch: 1900, loss is 3.738235363960266 and perplexity is 42.02376804112901
At time: 385.0967209339142 and batch: 1950, loss is 3.6700201797485352 and perplexity is 39.25269796188647
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399804403615552 and perplexity of 81.43493872751698
finished 7 epochs...
Completing Train Step...
At time: 389.0737450122833 and batch: 50, loss is 3.8958391904830934 and perplexity is 49.197321968541004
At time: 390.3911671638489 and batch: 100, loss is 3.861191067695618 and perplexity is 47.52191949707769
At time: 391.70656633377075 and batch: 150, loss is 3.8068836164474487 and perplexity is 45.00995180073456
At time: 393.02547955513 and batch: 200, loss is 3.8036032056808473 and perplexity is 44.862542583824705
At time: 394.3438296318054 and batch: 250, loss is 3.7933549737930297 and perplexity is 44.40512868954265
At time: 395.66352915763855 and batch: 300, loss is 3.812422275543213 and perplexity is 45.259938235431946
At time: 396.9810736179352 and batch: 350, loss is 3.8200360202789305 and perplexity is 45.605851026738044
At time: 398.29664301872253 and batch: 400, loss is 3.787545771598816 and perplexity is 44.14791813591761
At time: 399.6223337650299 and batch: 450, loss is 3.8150633239746092 and perplexity is 45.37962991049693
At time: 400.9387173652649 and batch: 500, loss is 3.8366131258010863 and perplexity is 46.368165054739144
At time: 402.2566692829132 and batch: 550, loss is 3.7880280685424803 and perplexity is 44.169215677360434
At time: 403.5748999118805 and batch: 600, loss is 3.762678151130676 and perplexity is 43.06360251560309
At time: 404.8906075954437 and batch: 650, loss is 3.819932851791382 and perplexity is 45.601146182764246
At time: 406.2067995071411 and batch: 700, loss is 3.8521956968307496 and perplexity is 47.096359113304295
At time: 407.5223140716553 and batch: 750, loss is 3.8029230785369874 and perplexity is 44.83204072461785
At time: 408.84158396720886 and batch: 800, loss is 3.773385343551636 and perplexity is 43.52717011908194
At time: 410.1591579914093 and batch: 850, loss is 3.761835217475891 and perplexity is 43.02731805059321
At time: 411.47669434547424 and batch: 900, loss is 3.7383530521392823 and perplexity is 42.028714032901846
At time: 412.7920889854431 and batch: 950, loss is 3.8359070014953613 and perplexity is 46.33543492351269
At time: 414.1078350543976 and batch: 1000, loss is 3.8131940746307373 and perplexity is 45.29488329801252
At time: 415.42504692077637 and batch: 1050, loss is 3.757931351661682 and perplexity is 42.85967262012285
At time: 416.7443220615387 and batch: 1100, loss is 3.769216146469116 and perplexity is 43.34607454230625
At time: 418.0634021759033 and batch: 1150, loss is 3.736386470794678 and perplexity is 41.946142366508155
At time: 419.38184332847595 and batch: 1200, loss is 3.786832766532898 and perplexity is 44.116451665846306
At time: 420.6973638534546 and batch: 1250, loss is 3.7684432220458985 and perplexity is 43.31258424704276
At time: 422.0135176181793 and batch: 1300, loss is 3.7702811002731322 and perplexity is 43.392260697975246
At time: 423.3309648036957 and batch: 1350, loss is 3.643155255317688 and perplexity is 38.21221600960464
At time: 424.64959955215454 and batch: 1400, loss is 3.6812686824798586 and perplexity is 39.69672467814996
At time: 425.967490196228 and batch: 1450, loss is 3.606189475059509 and perplexity is 36.82546078345859
At time: 427.28262853622437 and batch: 1500, loss is 3.606635947227478 and perplexity is 36.841905997663076
At time: 428.59916591644287 and batch: 1550, loss is 3.6064820957183836 and perplexity is 36.8362382508343
At time: 429.9165258407593 and batch: 1600, loss is 3.6981490993499757 and perplexity is 40.37250965826954
At time: 431.2344398498535 and batch: 1650, loss is 3.63601532459259 and perplexity is 37.94035512331428
At time: 432.5522835254669 and batch: 1700, loss is 3.6701854181289675 and perplexity is 39.259184550027186
At time: 433.8674941062927 and batch: 1750, loss is 3.6580008363723753 and perplexity is 38.78373029411338
At time: 435.18513107299805 and batch: 1800, loss is 3.5961124658584596 and perplexity is 36.45623375286199
At time: 436.50275897979736 and batch: 1850, loss is 3.6269450902938845 and perplexity is 37.597783165519175
At time: 437.82241463661194 and batch: 1900, loss is 3.702971658706665 and perplexity is 40.56767871139167
At time: 439.14104866981506 and batch: 1950, loss is 3.64037850856781 and perplexity is 38.10625754099216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4117681458938955 and perplexity of 82.41505659527158
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 443.1054790019989 and batch: 50, loss is 3.851288905143738 and perplexity is 47.05367188350944
At time: 444.4345724582672 and batch: 100, loss is 3.8538402128219604 and perplexity is 47.17387354838858
At time: 445.75313091278076 and batch: 150, loss is 3.816997652053833 and perplexity is 45.467493954405036
At time: 447.0719544887543 and batch: 200, loss is 3.8309008646011353 and perplexity is 46.10405304115048
At time: 448.38713455200195 and batch: 250, loss is 3.813162317276001 and perplexity is 45.29344487517626
At time: 449.70331144332886 and batch: 300, loss is 3.830746331214905 and perplexity is 46.0969289761822
At time: 451.0202453136444 and batch: 350, loss is 3.84154155254364 and perplexity is 46.59725121287539
At time: 452.33846855163574 and batch: 400, loss is 3.8123579931259157 and perplexity is 45.25702891070567
At time: 453.663006067276 and batch: 450, loss is 3.8332572555541993 and perplexity is 46.212820313416174
At time: 454.9811556339264 and batch: 500, loss is 3.852261347770691 and perplexity is 47.09945113504385
At time: 456.29870867729187 and batch: 550, loss is 3.8180652236938477 and perplexity is 45.5160596805767
At time: 457.6168940067291 and batch: 600, loss is 3.778555302619934 and perplexity is 43.75278651819906
At time: 458.93510460853577 and batch: 650, loss is 3.8109824895858764 and perplexity is 45.194820500979475
At time: 460.2520258426666 and batch: 700, loss is 3.845067982673645 and perplexity is 46.76186323934392
At time: 461.56798005104065 and batch: 750, loss is 3.7973063707351686 and perplexity is 44.58093809688858
At time: 462.88191509246826 and batch: 800, loss is 3.7556807565689088 and perplexity is 42.76332131580218
At time: 464.1973783969879 and batch: 850, loss is 3.7408344745635986 and perplexity is 42.13313452846751
At time: 465.5479066371918 and batch: 900, loss is 3.720508508682251 and perplexity is 41.28538274728308
At time: 466.8674614429474 and batch: 950, loss is 3.828962960243225 and perplexity is 46.01479431121963
At time: 468.1839408874512 and batch: 1000, loss is 3.8063519191741944 and perplexity is 44.98602649316685
At time: 469.49861693382263 and batch: 1050, loss is 3.741802191734314 and perplexity is 42.17392722091778
At time: 470.8134307861328 and batch: 1100, loss is 3.749021677970886 and perplexity is 42.479503030967386
At time: 472.13004446029663 and batch: 1150, loss is 3.721539545059204 and perplexity is 41.32797143019984
At time: 473.4483587741852 and batch: 1200, loss is 3.760488524436951 and perplexity is 42.96941246016935
At time: 474.7617087364197 and batch: 1250, loss is 3.7220706367492675 and perplexity is 41.34992620187596
At time: 476.07554173469543 and batch: 1300, loss is 3.7238420391082765 and perplexity is 41.423238472288844
At time: 477.3908038139343 and batch: 1350, loss is 3.6053647089004515 and perplexity is 36.79510091123129
At time: 478.70775961875916 and batch: 1400, loss is 3.6411277770996096 and perplexity is 38.13482005979428
At time: 480.02445101737976 and batch: 1450, loss is 3.56130184173584 and perplexity is 35.20900387280122
At time: 481.34188747406006 and batch: 1500, loss is 3.5624209785461427 and perplexity is 35.248429622378225
At time: 482.6582577228546 and batch: 1550, loss is 3.5625961589813233 and perplexity is 35.25460499850565
At time: 483.9744620323181 and batch: 1600, loss is 3.649472088813782 and perplexity is 38.45436020275212
At time: 485.2909321784973 and batch: 1650, loss is 3.579634470939636 and perplexity is 35.86043042165173
At time: 486.6085922718048 and batch: 1700, loss is 3.599186496734619 and perplexity is 36.56847376729586
At time: 487.92530632019043 and batch: 1750, loss is 3.588340663909912 and perplexity is 36.17400127240559
At time: 489.24246549606323 and batch: 1800, loss is 3.521930661201477 and perplexity is 33.849717754568786
At time: 490.5591735839844 and batch: 1850, loss is 3.5451069927215575 and perplexity is 34.64339173474449
At time: 491.87711000442505 and batch: 1900, loss is 3.615850553512573 and perplexity is 37.18295857563982
At time: 493.1945834159851 and batch: 1950, loss is 3.556529235839844 and perplexity is 35.0413655274057
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.397694290515989 and perplexity of 81.26328296677312
finished 9 epochs...
Completing Train Step...
At time: 497.1626470088959 and batch: 50, loss is 3.83550190448761 and perplexity is 46.3166683788645
At time: 498.49031591415405 and batch: 100, loss is 3.818039045333862 and perplexity is 45.514868160377354
At time: 499.80795788764954 and batch: 150, loss is 3.773852477073669 and perplexity is 43.5475078692164
At time: 501.1260554790497 and batch: 200, loss is 3.783111972808838 and perplexity is 43.95260845178611
At time: 502.44457268714905 and batch: 250, loss is 3.763129320144653 and perplexity is 43.083035862220626
At time: 503.76138973236084 and batch: 300, loss is 3.7790378284454347 and perplexity is 43.773903461957346
At time: 505.0778720378876 and batch: 350, loss is 3.7883666706085206 and perplexity is 44.184173997360276
At time: 506.3953788280487 and batch: 400, loss is 3.7549985885620116 and perplexity is 42.73415949389372
At time: 507.71282720565796 and batch: 450, loss is 3.7794451332092285 and perplexity is 43.79173641284364
At time: 509.0309660434723 and batch: 500, loss is 3.8007729864120483 and perplexity is 44.73575125961578
At time: 510.3475227355957 and batch: 550, loss is 3.765749144554138 and perplexity is 43.19605383018139
At time: 511.6628563404083 and batch: 600, loss is 3.731591420173645 and perplexity is 41.74548994422317
At time: 512.9791343212128 and batch: 650, loss is 3.7670809030532837 and perplexity is 43.253618864853365
At time: 514.3019874095917 and batch: 700, loss is 3.804590940475464 and perplexity is 44.90687676971427
At time: 515.6178929805756 and batch: 750, loss is 3.757733631134033 and perplexity is 42.85119922074764
At time: 516.9312558174133 and batch: 800, loss is 3.7153658485412597 and perplexity is 41.07361105666535
At time: 518.2461607456207 and batch: 850, loss is 3.6990673875808717 and perplexity is 40.40960028607757
At time: 519.5605578422546 and batch: 900, loss is 3.678452730178833 and perplexity is 39.58509783664284
At time: 520.8776814937592 and batch: 950, loss is 3.786966128349304 and perplexity is 44.1223355083051
At time: 522.1939587593079 and batch: 1000, loss is 3.771014757156372 and perplexity is 43.424107409566766
At time: 523.5099048614502 and batch: 1050, loss is 3.710092191696167 and perplexity is 40.857573082328756
At time: 524.82532787323 and batch: 1100, loss is 3.7175827407836914 and perplexity is 41.16476783142559
At time: 526.1431481838226 and batch: 1150, loss is 3.690819787979126 and perplexity is 40.07768870124241
At time: 527.4622690677643 and batch: 1200, loss is 3.7319429063797 and perplexity is 41.76016548707791
At time: 528.781848192215 and batch: 1250, loss is 3.6965121173858644 and perplexity is 40.30647465191647
At time: 530.103031873703 and batch: 1300, loss is 3.6995037412643432 and perplexity is 40.42723701165525
At time: 531.4219198226929 and batch: 1350, loss is 3.581153392791748 and perplexity is 35.91494100122033
At time: 532.7401876449585 and batch: 1400, loss is 3.618781957626343 and perplexity is 37.29211676859099
At time: 534.0590975284576 and batch: 1450, loss is 3.5420037317276 and perplexity is 34.53605088795019
At time: 535.3780465126038 and batch: 1500, loss is 3.544034690856934 and perplexity is 34.6062634711012
At time: 536.6984066963196 and batch: 1550, loss is 3.54776554107666 and perplexity is 34.73561540307813
At time: 538.0175981521606 and batch: 1600, loss is 3.637135457992554 and perplexity is 37.98287719304363
At time: 539.3393585681915 and batch: 1650, loss is 3.5685876274108885 and perplexity is 35.46646589651584
At time: 540.6687359809875 and batch: 1700, loss is 3.592288465499878 and perplexity is 36.31709131184706
At time: 541.9960372447968 and batch: 1750, loss is 3.5832335805892943 and perplexity is 35.98972858237924
At time: 543.3222029209137 and batch: 1800, loss is 3.5183312129974365 and perplexity is 33.72809646486692
At time: 544.6492085456848 and batch: 1850, loss is 3.543457579612732 and perplexity is 34.586297569159626
At time: 545.9698872566223 and batch: 1900, loss is 3.615891137123108 and perplexity is 37.18446762497032
At time: 547.2889959812164 and batch: 1950, loss is 3.5572717142105104 and perplexity is 35.06739264447848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399171341297238 and perplexity of 81.38340165122611
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 551.2774386405945 and batch: 50, loss is 3.8234652614593507 and perplexity is 45.76251295138407
At time: 552.6085739135742 and batch: 100, loss is 3.822482328414917 and perplexity is 45.71755356486098
At time: 553.9276072978973 and batch: 150, loss is 3.7936070919036866 and perplexity is 44.416325438083575
At time: 555.2481479644775 and batch: 200, loss is 3.8324376010894774 and perplexity is 46.174957288337474
At time: 556.5685567855835 and batch: 250, loss is 3.81561408996582 and perplexity is 45.40463035140971
At time: 557.8854231834412 and batch: 300, loss is 3.830729103088379 and perplexity is 46.096134819298285
At time: 559.20689868927 and batch: 350, loss is 3.85050274848938 and perplexity is 47.01669486301604
At time: 560.526132106781 and batch: 400, loss is 3.8240943813323973 and perplexity is 45.79131211583581
At time: 561.8462600708008 and batch: 450, loss is 3.8453634548187257 and perplexity is 46.77568210882819
At time: 563.1669068336487 and batch: 500, loss is 3.8580699872970583 and perplexity is 47.37383098392386
At time: 564.50040102005 and batch: 550, loss is 3.8234442472457886 and perplexity is 45.761551298267996
At time: 565.8214740753174 and batch: 600, loss is 3.7788157510757445 and perplexity is 43.764183347964064
At time: 567.1394970417023 and batch: 650, loss is 3.7994575023651125 and perplexity is 44.67694078310884
At time: 568.4585020542145 and batch: 700, loss is 3.8417567682266234 and perplexity is 46.607280751338585
At time: 569.7778248786926 and batch: 750, loss is 3.802386064529419 and perplexity is 44.807971754026454
At time: 571.1010670661926 and batch: 800, loss is 3.752451415061951 and perplexity is 42.62544668924928
At time: 572.432035446167 and batch: 850, loss is 3.7355234384536744 and perplexity is 41.909957105836604
At time: 573.7567656040192 and batch: 900, loss is 3.703900842666626 and perplexity is 40.60539106588724
At time: 575.0881536006927 and batch: 950, loss is 3.812119221687317 and perplexity is 45.24622411479562
At time: 576.4159610271454 and batch: 1000, loss is 3.7905757093429564 and perplexity is 44.28188643471379
At time: 577.7379631996155 and batch: 1050, loss is 3.7258097982406615 and perplexity is 41.50482967767814
At time: 579.0588381290436 and batch: 1100, loss is 3.734909863471985 and perplexity is 41.88425009206954
At time: 580.3784325122833 and batch: 1150, loss is 3.717024040222168 and perplexity is 41.14177547604221
At time: 581.6955897808075 and batch: 1200, loss is 3.7643531799316405 and perplexity is 43.13579573607226
At time: 583.0107231140137 and batch: 1250, loss is 3.723830780982971 and perplexity is 41.42277212690466
At time: 584.3271384239197 and batch: 1300, loss is 3.7176101207733154 and perplexity is 41.165894937771704
At time: 585.643566608429 and batch: 1350, loss is 3.583552222251892 and perplexity is 36.001198236588976
At time: 586.9597582817078 and batch: 1400, loss is 3.623127746582031 and perplexity is 37.45453309570391
At time: 588.2758786678314 and batch: 1450, loss is 3.5395112085342406 and perplexity is 34.45007617160325
At time: 589.5922558307648 and batch: 1500, loss is 3.5359647369384763 and perplexity is 34.32811634634551
At time: 590.9081125259399 and batch: 1550, loss is 3.538228139877319 and perplexity is 34.405902703495215
At time: 592.2272067070007 and batch: 1600, loss is 3.630823040008545 and perplexity is 37.74386855083161
At time: 593.5476293563843 and batch: 1650, loss is 3.5607160663604738 and perplexity is 35.188385344843915
At time: 594.8678357601166 and batch: 1700, loss is 3.5829815530776976 and perplexity is 35.98065932354096
At time: 596.1861915588379 and batch: 1750, loss is 3.581735544204712 and perplexity is 35.93585502184339
At time: 597.5052471160889 and batch: 1800, loss is 3.5164154672622683 and perplexity is 33.66354386083972
At time: 598.8321468830109 and batch: 1850, loss is 3.544266366958618 and perplexity is 34.61428184411288
At time: 600.1477401256561 and batch: 1900, loss is 3.619283757209778 and perplexity is 37.31083463316643
At time: 601.4638667106628 and batch: 1950, loss is 3.563209834098816 and perplexity is 35.27624651212029
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365374613917151 and perplexity of 78.67886862091471
finished 11 epochs...
Completing Train Step...
At time: 605.4348728656769 and batch: 50, loss is 3.8285386466979983 and perplexity is 45.99527375242418
At time: 606.7498776912689 and batch: 100, loss is 3.8040633058547972 and perplexity is 44.8831885967242
At time: 608.0651571750641 and batch: 150, loss is 3.764872899055481 and perplexity is 43.15822006070881
At time: 609.3797426223755 and batch: 200, loss is 3.7859662675857546 and perplexity is 44.0782413639101
At time: 610.6912937164307 and batch: 250, loss is 3.778237805366516 and perplexity is 43.73889733365579
At time: 612.0053713321686 and batch: 300, loss is 3.7911679935455322 and perplexity is 44.30812166509864
At time: 613.320240020752 and batch: 350, loss is 3.810616807937622 and perplexity is 45.178296605952845
At time: 614.6372187137604 and batch: 400, loss is 3.7850139427185057 and perplexity is 44.036284539989005
At time: 615.9548859596252 and batch: 450, loss is 3.80999370098114 and perplexity is 45.1501544637485
At time: 617.2685208320618 and batch: 500, loss is 3.82485716342926 and perplexity is 45.82625423382642
At time: 618.5842399597168 and batch: 550, loss is 3.791157808303833 and perplexity is 44.307670378468465
At time: 619.9004395008087 and batch: 600, loss is 3.751498193740845 and perplexity is 42.58483456389044
At time: 621.2148103713989 and batch: 650, loss is 3.7736186504364015 and perplexity is 43.537326492274914
At time: 622.5344893932343 and batch: 700, loss is 3.816873006820679 and perplexity is 45.46182700120684
At time: 623.8545083999634 and batch: 750, loss is 3.7812547874450684 and perplexity is 43.87105606306178
At time: 625.1721994876862 and batch: 800, loss is 3.7340662050247193 and perplexity is 41.84892899223911
At time: 626.4895832538605 and batch: 850, loss is 3.718724250793457 and perplexity is 41.21178465593732
At time: 627.8068671226501 and batch: 900, loss is 3.6877176475524904 and perplexity is 39.95355472298026
At time: 629.1423180103302 and batch: 950, loss is 3.7957671022415163 and perplexity is 44.51236885023778
At time: 630.4595067501068 and batch: 1000, loss is 3.773097949028015 and perplexity is 43.51466244616545
At time: 631.7776222229004 and batch: 1050, loss is 3.7093588972091673 and perplexity is 40.827623431534256
At time: 633.098979473114 and batch: 1100, loss is 3.718253927230835 and perplexity is 41.192406339952456
At time: 634.4272632598877 and batch: 1150, loss is 3.6993678331375124 and perplexity is 40.42174299494927
At time: 635.7466623783112 and batch: 1200, loss is 3.749078426361084 and perplexity is 42.48191374278217
At time: 637.0650179386139 and batch: 1250, loss is 3.710053896903992 and perplexity is 40.856008480017046
At time: 638.3820159435272 and batch: 1300, loss is 3.7053928089141848 and perplexity is 40.66601815436518
At time: 639.6958763599396 and batch: 1350, loss is 3.574046263694763 and perplexity is 35.660593788867004
At time: 641.010755777359 and batch: 1400, loss is 3.615229482650757 and perplexity is 37.15987249330099
At time: 642.3268280029297 and batch: 1450, loss is 3.5345613384246826 and perplexity is 34.27997410815793
At time: 643.6438374519348 and batch: 1500, loss is 3.5325755977630617 and perplexity is 34.21197051079205
At time: 644.9606673717499 and batch: 1550, loss is 3.536791892051697 and perplexity is 34.356522769948285
At time: 646.2776503562927 and batch: 1600, loss is 3.6313873863220216 and perplexity is 37.76517517549667
At time: 647.5930609703064 and batch: 1650, loss is 3.56207537651062 and perplexity is 35.23624979815901
At time: 648.911497592926 and batch: 1700, loss is 3.585146622657776 and perplexity is 36.05864434554988
At time: 650.2292821407318 and batch: 1750, loss is 3.584633913040161 and perplexity is 36.04016147037458
At time: 651.5477192401886 and batch: 1800, loss is 3.520388650894165 and perplexity is 33.79756136407227
At time: 652.8642823696136 and batch: 1850, loss is 3.5486307191848754 and perplexity is 34.765680901230255
At time: 654.1798996925354 and batch: 1900, loss is 3.625103635787964 and perplexity is 37.52861226537556
At time: 655.4951391220093 and batch: 1950, loss is 3.5681388092041018 and perplexity is 35.450551472499875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363408714117006 and perplexity of 78.52434578678776
finished 12 epochs...
Completing Train Step...
At time: 659.4837398529053 and batch: 50, loss is 3.821886215209961 and perplexity is 45.69030884875699
At time: 660.7977588176727 and batch: 100, loss is 3.793939428329468 and perplexity is 44.4310890540338
At time: 662.124165058136 and batch: 150, loss is 3.7528508949279784 and perplexity is 42.64247809860814
At time: 663.4492886066437 and batch: 200, loss is 3.772119889259338 and perplexity is 43.47212331177834
At time: 664.7652869224548 and batch: 250, loss is 3.7629195070266723 and perplexity is 43.073997424358865
At time: 666.0821530818939 and batch: 300, loss is 3.7768553400039675 and perplexity is 43.67847160096104
At time: 667.396276473999 and batch: 350, loss is 3.7964560270309446 and perplexity is 44.54304509017266
At time: 668.714212179184 and batch: 400, loss is 3.7706887912750244 and perplexity is 43.40995493885989
At time: 670.0328891277313 and batch: 450, loss is 3.79602087020874 and perplexity is 44.523666096976264
At time: 671.3545274734497 and batch: 500, loss is 3.810647716522217 and perplexity is 45.17969302473589
At time: 672.676038980484 and batch: 550, loss is 3.7766312742233277 and perplexity is 43.66868584649191
At time: 673.9970581531525 and batch: 600, loss is 3.7387472438812255 and perplexity is 42.04528467068783
At time: 675.3143286705017 and batch: 650, loss is 3.761360692977905 and perplexity is 43.00690537763529
At time: 676.6353793144226 and batch: 700, loss is 3.805447220802307 and perplexity is 44.94534611275244
At time: 677.9631145000458 and batch: 750, loss is 3.7708823776245115 and perplexity is 43.418359327029066
At time: 679.2824788093567 and batch: 800, loss is 3.724494891166687 and perplexity is 41.45029054833244
At time: 680.6103329658508 and batch: 850, loss is 3.7099795818328856 and perplexity is 40.85297237565729
At time: 681.9376981258392 and batch: 900, loss is 3.6793280363082888 and perplexity is 39.6197620841153
At time: 683.2708821296692 and batch: 950, loss is 3.787061219215393 and perplexity is 44.126531338891866
At time: 684.5919995307922 and batch: 1000, loss is 3.7640230560302737 and perplexity is 43.12155792914479
At time: 685.9126029014587 and batch: 1050, loss is 3.699995255470276 and perplexity is 40.44711245708484
At time: 687.2335059642792 and batch: 1100, loss is 3.7083426094055176 and perplexity is 40.78615189286772
At time: 688.5515475273132 and batch: 1150, loss is 3.6886827754974365 and perplexity is 39.99213362893885
At time: 689.8787989616394 and batch: 1200, loss is 3.739482684135437 and perplexity is 42.07621783888873
At time: 691.1978542804718 and batch: 1250, loss is 3.701609897613525 and perplexity is 40.512472822030745
At time: 692.5208342075348 and batch: 1300, loss is 3.697914752960205 and perplexity is 40.363049614891956
At time: 693.8465585708618 and batch: 1350, loss is 3.5676109838485717 and perplexity is 35.431844709951264
At time: 695.1662676334381 and batch: 1400, loss is 3.609495134353638 and perplexity is 36.94739463500802
At time: 696.4858829975128 and batch: 1450, loss is 3.530505504608154 and perplexity is 34.141221798299355
At time: 697.8054506778717 and batch: 1500, loss is 3.5291904067993163 and perplexity is 34.09635226270209
At time: 699.1238522529602 and batch: 1550, loss is 3.5345178937911985 and perplexity is 34.27848485959712
At time: 700.441844701767 and batch: 1600, loss is 3.6300417089462282 and perplexity is 37.714389611825894
At time: 701.7578775882721 and batch: 1650, loss is 3.5613036060333254 and perplexity is 35.20906599201302
At time: 703.072646856308 and batch: 1700, loss is 3.584655752182007 and perplexity is 36.04094856516779
At time: 704.3950979709625 and batch: 1750, loss is 3.584314613342285 and perplexity is 36.028655694698784
At time: 705.7099299430847 and batch: 1800, loss is 3.5202438163757326 and perplexity is 33.79266666501717
At time: 707.0262632369995 and batch: 1850, loss is 3.5484664154052736 and perplexity is 34.759969237694555
At time: 708.3429725170135 and batch: 1900, loss is 3.62581787109375 and perplexity is 37.55542609978638
At time: 709.6571266651154 and batch: 1950, loss is 3.5683480405807497 and perplexity is 35.45796961621454
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363310490098111 and perplexity of 78.51663318875084
finished 13 epochs...
Completing Train Step...
At time: 713.6074323654175 and batch: 50, loss is 3.815107169151306 and perplexity is 45.381619632008324
At time: 714.9245188236237 and batch: 100, loss is 3.7853988075256346 and perplexity is 44.05323581791108
At time: 716.2412090301514 and batch: 150, loss is 3.743659248352051 and perplexity is 42.25231935834916
At time: 717.5578436851501 and batch: 200, loss is 3.761678705215454 and perplexity is 43.02058427475754
At time: 718.8787276744843 and batch: 250, loss is 3.751144824028015 and perplexity is 42.56978903160397
At time: 720.1960833072662 and batch: 300, loss is 3.7666321659088133 and perplexity is 43.23421371366763
At time: 721.51331615448 and batch: 350, loss is 3.786276788711548 and perplexity is 44.091930714347676
At time: 722.828696012497 and batch: 400, loss is 3.7603400325775147 and perplexity is 42.963032325924985
At time: 724.1435332298279 and batch: 450, loss is 3.7858554697036744 and perplexity is 44.07335785866718
At time: 725.4601480960846 and batch: 500, loss is 3.8002824115753175 and perplexity is 44.71381040800045
At time: 726.7776303291321 and batch: 550, loss is 3.7660811138153076 and perplexity is 43.210395972700354
At time: 728.1254990100861 and batch: 600, loss is 3.7291717386245726 and perplexity is 41.64460126091498
At time: 729.4424705505371 and batch: 650, loss is 3.7520963668823244 and perplexity is 42.61031528834363
At time: 730.7574973106384 and batch: 700, loss is 3.7969892168045045 and perplexity is 44.56680131902429
At time: 732.0729324817657 and batch: 750, loss is 3.762975459098816 and perplexity is 43.076407571195986
At time: 733.4027442932129 and batch: 800, loss is 3.717186107635498 and perplexity is 41.148443757514386
At time: 734.722395658493 and batch: 850, loss is 3.7033241415023803 and perplexity is 40.58198064064347
At time: 736.0454404354095 and batch: 900, loss is 3.6729776668548584 and perplexity is 39.368959145731154
At time: 737.3615734577179 and batch: 950, loss is 3.7804783964157105 and perplexity is 43.837008187628776
At time: 738.6782276630402 and batch: 1000, loss is 3.7571963024139405 and perplexity is 42.82818022565335
At time: 739.9979329109192 and batch: 1050, loss is 3.6926060009002684 and perplexity is 40.14933995980141
At time: 741.3193299770355 and batch: 1100, loss is 3.7002939319610597 and perplexity is 40.45919486297134
At time: 742.6405081748962 and batch: 1150, loss is 3.679984936714172 and perplexity is 39.64579687210455
At time: 743.9609632492065 and batch: 1200, loss is 3.731715803146362 and perplexity is 41.75068269529818
At time: 745.2796437740326 and batch: 1250, loss is 3.6946954917907715 and perplexity is 40.233319346434506
At time: 746.5954196453094 and batch: 1300, loss is 3.691717200279236 and perplexity is 40.11367105513151
At time: 747.9151618480682 and batch: 1350, loss is 3.562092175483704 and perplexity is 35.236841735942896
At time: 749.2359964847565 and batch: 1400, loss is 3.60437548160553 and perplexity is 36.758720190458256
At time: 750.5561032295227 and batch: 1450, loss is 3.526548900604248 and perplexity is 34.00640538688655
At time: 751.8782050609589 and batch: 1500, loss is 3.525645070075989 and perplexity is 33.97568324543762
At time: 753.2028188705444 and batch: 1550, loss is 3.531649699211121 and perplexity is 34.18030835707017
At time: 754.5249338150024 and batch: 1600, loss is 3.6277751779556273 and perplexity is 37.62900557831077
At time: 755.8444955348969 and batch: 1650, loss is 3.5594481325149534 and perplexity is 35.14379707355866
At time: 757.1647281646729 and batch: 1700, loss is 3.583025221824646 and perplexity is 35.982230588155325
At time: 758.4856679439545 and batch: 1750, loss is 3.582766351699829 and perplexity is 35.9729170691797
At time: 759.8038609027863 and batch: 1800, loss is 3.5187924528121948 and perplexity is 33.74365679407835
At time: 761.1203582286835 and batch: 1850, loss is 3.5470779132843018 and perplexity is 34.71173843871527
At time: 762.4381060600281 and batch: 1900, loss is 3.625103178024292 and perplexity is 37.528595086144136
At time: 763.7546494007111 and batch: 1950, loss is 3.5672876834869385 and perplexity is 35.42039143326722
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363750510992006 and perplexity of 78.55118975011912
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 767.7006673812866 and batch: 50, loss is 3.8132684659957885 and perplexity is 45.298252971546646
At time: 769.0303249359131 and batch: 100, loss is 3.7892308044433594 and perplexity is 44.22237153859277
At time: 770.3467724323273 and batch: 150, loss is 3.750198345184326 and perplexity is 42.529516688372084
At time: 771.6635541915894 and batch: 200, loss is 3.769281964302063 and perplexity is 43.348927580888756
At time: 772.9778001308441 and batch: 250, loss is 3.763484625816345 and perplexity is 43.09834622898518
At time: 774.293863773346 and batch: 300, loss is 3.779917573928833 and perplexity is 43.81243030023988
At time: 775.6104388237 and batch: 350, loss is 3.803649969100952 and perplexity is 44.864640558804375
At time: 776.9278950691223 and batch: 400, loss is 3.7875723838806152 and perplexity is 44.149093028389096
At time: 778.2456362247467 and batch: 450, loss is 3.81793683052063 and perplexity is 45.510216104387624
At time: 779.5644047260284 and batch: 500, loss is 3.834501123428345 and perplexity is 46.27033872121144
At time: 780.890602350235 and batch: 550, loss is 3.8031968688964843 and perplexity is 44.844316985649094
At time: 782.2061593532562 and batch: 600, loss is 3.7620933198928834 and perplexity is 43.03842493867443
At time: 783.5226290225983 and batch: 650, loss is 3.7792333126068116 and perplexity is 43.78246140320953
At time: 784.8389291763306 and batch: 700, loss is 3.8236363410949705 and perplexity is 45.77034265515717
At time: 786.154803276062 and batch: 750, loss is 3.7868865537643432 and perplexity is 44.11882463145965
At time: 787.4675981998444 and batch: 800, loss is 3.7397396326065064 and perplexity is 42.087030647838695
At time: 788.7828731536865 and batch: 850, loss is 3.733265676498413 and perplexity is 41.81544113656572
At time: 790.1004695892334 and batch: 900, loss is 3.705723876953125 and perplexity is 40.67948360211376
At time: 791.4172878265381 and batch: 950, loss is 3.82114616394043 and perplexity is 45.656508186342414
At time: 792.7637882232666 and batch: 1000, loss is 3.800463943481445 and perplexity is 44.721928128024345
At time: 794.0788140296936 and batch: 1050, loss is 3.7296763181686403 and perplexity is 41.66561957709235
At time: 795.3946778774261 and batch: 1100, loss is 3.7338802003860474 and perplexity is 41.8411456212171
At time: 796.732298374176 and batch: 1150, loss is 3.716867699623108 and perplexity is 41.1353438489932
At time: 798.0539169311523 and batch: 1200, loss is 3.755574817657471 and perplexity is 42.75879125605155
At time: 799.3822042942047 and batch: 1250, loss is 3.719606556892395 and perplexity is 41.248162110552535
At time: 800.7021050453186 and batch: 1300, loss is 3.7162984657287597 and perplexity is 41.11193488024
At time: 802.026449918747 and batch: 1350, loss is 3.5764771604537966 and perplexity is 35.74738646000503
At time: 803.34814620018 and batch: 1400, loss is 3.616131443977356 and perplexity is 37.19340438115104
At time: 804.6672699451447 and batch: 1450, loss is 3.528147873878479 and perplexity is 34.0608242157849
At time: 805.9845657348633 and batch: 1500, loss is 3.521920232772827 and perplexity is 33.84936475704297
At time: 807.2998430728912 and batch: 1550, loss is 3.523448905944824 and perplexity is 33.90114894330006
At time: 808.6159541606903 and batch: 1600, loss is 3.614611096382141 and perplexity is 37.13690044194021
At time: 809.9323408603668 and batch: 1650, loss is 3.547743921279907 and perplexity is 34.73486443425096
At time: 811.2488322257996 and batch: 1700, loss is 3.5679526996612547 and perplexity is 35.44395440047972
At time: 812.5658142566681 and batch: 1750, loss is 3.5692225551605223 and perplexity is 35.488991690264
At time: 813.8942747116089 and batch: 1800, loss is 3.508057060241699 and perplexity is 33.38334290760733
At time: 815.2234280109406 and batch: 1850, loss is 3.5439486837387086 and perplexity is 34.60328721409899
At time: 816.545823097229 and batch: 1900, loss is 3.6270969533920288 and perplexity is 37.60349331492356
At time: 817.8626461029053 and batch: 1950, loss is 3.578845291137695 and perplexity is 35.83214125836041
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354244072492732 and perplexity of 77.80798590362724
finished 15 epochs...
Completing Train Step...
At time: 821.8036160469055 and batch: 50, loss is 3.8287692260742188 and perplexity is 46.005880536760976
At time: 823.136981010437 and batch: 100, loss is 3.7947950744628907 and perplexity is 44.46912261289998
At time: 824.4647898674011 and batch: 150, loss is 3.7494863939285277 and perplexity is 42.49924852156549
At time: 825.7964317798615 and batch: 200, loss is 3.760513129234314 and perplexity is 42.97046972686261
At time: 827.1180193424225 and batch: 250, loss is 3.7518891382217405 and perplexity is 42.60148612463885
At time: 828.4358506202698 and batch: 300, loss is 3.7672189140319823 and perplexity is 43.2595887510706
At time: 829.7509000301361 and batch: 350, loss is 3.789000573158264 and perplexity is 44.21219133710888
At time: 831.0718512535095 and batch: 400, loss is 3.7730141162872313 and perplexity is 43.51101464565299
At time: 832.3923180103302 and batch: 450, loss is 3.8029143810272217 and perplexity is 44.83165079920152
At time: 833.7131018638611 and batch: 500, loss is 3.819883093833923 and perplexity is 45.59887721932237
At time: 835.0331721305847 and batch: 550, loss is 3.788885726928711 and perplexity is 44.20711402519418
At time: 836.3515975475311 and batch: 600, loss is 3.748172154426575 and perplexity is 42.44343101717385
At time: 837.6718482971191 and batch: 650, loss is 3.7642005777359007 and perplexity is 43.129213621163316
At time: 838.9938225746155 and batch: 700, loss is 3.8082583570480346 and perplexity is 45.07187136082018
At time: 840.3099834918976 and batch: 750, loss is 3.772522211074829 and perplexity is 43.489616614084994
At time: 841.6269135475159 and batch: 800, loss is 3.7275854778289794 and perplexity is 41.578594428452625
At time: 842.9416909217834 and batch: 850, loss is 3.7204031419754027 and perplexity is 41.28103287163208
At time: 844.258926153183 and batch: 900, loss is 3.693337936401367 and perplexity is 40.17873744428252
At time: 845.577064037323 and batch: 950, loss is 3.8077938604354857 and perplexity is 45.05094049078729
At time: 846.8968029022217 and batch: 1000, loss is 3.7860716247558592 and perplexity is 44.082885567329164
At time: 848.2140560150146 and batch: 1050, loss is 3.7167884731292724 and perplexity is 41.13208496902385
At time: 849.5321176052094 and batch: 1100, loss is 3.718522186279297 and perplexity is 41.20345805797647
At time: 850.8487541675568 and batch: 1150, loss is 3.6995880603790283 and perplexity is 40.430645944206304
At time: 852.164689540863 and batch: 1200, loss is 3.7417241382598876 and perplexity is 42.170635527833696
At time: 853.4813508987427 and batch: 1250, loss is 3.7069119739532472 and perplexity is 40.727843496982324
At time: 854.7966930866241 and batch: 1300, loss is 3.703918390274048 and perplexity is 40.6061035996005
At time: 856.1167187690735 and batch: 1350, loss is 3.5668483543395997 and perplexity is 35.40483364064655
At time: 857.4328887462616 and batch: 1400, loss is 3.6086776494979858 and perplexity is 36.91720304170461
At time: 858.7496445178986 and batch: 1450, loss is 3.524395394325256 and perplexity is 33.93325117665707
At time: 860.0671746730804 and batch: 1500, loss is 3.5218416833877564 and perplexity is 33.84670601467893
At time: 861.3847680091858 and batch: 1550, loss is 3.524510912895203 and perplexity is 33.93717132372717
At time: 862.7017517089844 and batch: 1600, loss is 3.617394108772278 and perplexity is 37.24039684508791
At time: 864.0237536430359 and batch: 1650, loss is 3.552216691970825 and perplexity is 34.890573483693146
At time: 865.3402230739594 and batch: 1700, loss is 3.573837676048279 and perplexity is 35.65315620525735
At time: 866.6603126525879 and batch: 1750, loss is 3.576925587654114 and perplexity is 35.76342015513779
At time: 867.9786562919617 and batch: 1800, loss is 3.5165192699432373 and perplexity is 33.66703840831195
At time: 869.29474568367 and batch: 1850, loss is 3.553094606399536 and perplexity is 34.92121787118723
At time: 870.6084051132202 and batch: 1900, loss is 3.635847625732422 and perplexity is 37.933993102472456
At time: 871.9261856079102 and batch: 1950, loss is 3.587325735092163 and perplexity is 36.13730586082622
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3529149255087205 and perplexity of 77.7046363524186
finished 16 epochs...
Completing Train Step...
At time: 875.9052066802979 and batch: 50, loss is 3.83000364780426 and perplexity is 46.06270626164414
At time: 877.2328352928162 and batch: 100, loss is 3.793101053237915 and perplexity is 44.39385474601944
At time: 878.5505197048187 and batch: 150, loss is 3.746762409210205 and perplexity is 42.38363874916548
At time: 879.8708202838898 and batch: 200, loss is 3.7602587652206423 and perplexity is 42.959540975712954
At time: 881.1885719299316 and batch: 250, loss is 3.747059426307678 and perplexity is 42.396229284236625
At time: 882.5050501823425 and batch: 300, loss is 3.761131820678711 and perplexity is 42.9970634146396
At time: 883.8218829631805 and batch: 350, loss is 3.782332501411438 and perplexity is 43.9183619994558
At time: 885.1361620426178 and batch: 400, loss is 3.7656040620803832 and perplexity is 43.18978729442851
At time: 886.4521970748901 and batch: 450, loss is 3.7955135774612425 and perplexity is 44.50108529209679
At time: 887.7679476737976 and batch: 500, loss is 3.8124320936203 and perplexity is 45.26038260317593
At time: 889.0848500728607 and batch: 550, loss is 3.7809172677993774 and perplexity is 43.8562512183668
At time: 890.4015865325928 and batch: 600, loss is 3.7411478614807128 and perplexity is 42.1463405707981
At time: 891.7275223731995 and batch: 650, loss is 3.757184834480286 and perplexity is 42.8276890777402
At time: 893.0435569286346 and batch: 700, loss is 3.801439685821533 and perplexity is 44.7655865030279
At time: 894.3631637096405 and batch: 750, loss is 3.7661956262588503 and perplexity is 43.21534438405157
At time: 895.6838800907135 and batch: 800, loss is 3.722057414054871 and perplexity is 41.34937944805325
At time: 897.0031938552856 and batch: 850, loss is 3.714912109375 and perplexity is 41.05497857809154
At time: 898.3232350349426 and batch: 900, loss is 3.6884003400802614 and perplexity is 39.98084002892503
At time: 899.6395149230957 and batch: 950, loss is 3.8027694702148436 and perplexity is 44.825154678954355
At time: 900.9549374580383 and batch: 1000, loss is 3.780903515815735 and perplexity is 43.85564811206439
At time: 902.2795007228851 and batch: 1050, loss is 3.712272939682007 and perplexity is 40.94677037559383
At time: 903.5971591472626 and batch: 1100, loss is 3.713776035308838 and perplexity is 41.008363565709146
At time: 904.9140310287476 and batch: 1150, loss is 3.694384732246399 and perplexity is 40.22081840094048
At time: 906.2306733131409 and batch: 1200, loss is 3.737552366256714 and perplexity is 41.995075703578024
At time: 907.5455574989319 and batch: 1250, loss is 3.703509192466736 and perplexity is 40.58949107018116
At time: 908.8611223697662 and batch: 1300, loss is 3.7012713146209717 and perplexity is 40.498758309628265
At time: 910.1778993606567 and batch: 1350, loss is 3.5652569484710694 and perplexity is 35.3485349895001
At time: 911.4937529563904 and batch: 1400, loss is 3.6076881313323974 and perplexity is 36.880690866381734
At time: 912.8084709644318 and batch: 1450, loss is 3.524227862358093 and perplexity is 33.92756674851022
At time: 914.1241154670715 and batch: 1500, loss is 3.522759189605713 and perplexity is 33.87777482864023
At time: 915.4389479160309 and batch: 1550, loss is 3.5257944011688234 and perplexity is 33.98075725019037
At time: 916.75559258461 and batch: 1600, loss is 3.619125566482544 and perplexity is 37.304932871916364
At time: 918.0721266269684 and batch: 1650, loss is 3.554161715507507 and perplexity is 34.958502510690145
At time: 919.3895390033722 and batch: 1700, loss is 3.575957202911377 and perplexity is 35.7288041682134
At time: 920.7042169570923 and batch: 1750, loss is 3.5792289113998415 and perplexity is 35.84588983073006
At time: 922.0212399959564 and batch: 1800, loss is 3.519128270149231 and perplexity is 33.75499040194929
At time: 923.3381495475769 and batch: 1850, loss is 3.555724039077759 and perplexity is 35.013161689687216
At time: 924.6707394123077 and batch: 1900, loss is 3.6383963298797606 and perplexity is 38.03079894033471
At time: 926.0003910064697 and batch: 1950, loss is 3.589730315208435 and perplexity is 36.22430546479437
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352389171511628 and perplexity of 77.66379356683336
finished 17 epochs...
Completing Train Step...
At time: 929.9889435768127 and batch: 50, loss is 3.828713493347168 and perplexity is 46.00331657502724
At time: 931.3095052242279 and batch: 100, loss is 3.790672736167908 and perplexity is 44.28618317400352
At time: 932.6304075717926 and batch: 150, loss is 3.743926544189453 and perplexity is 42.26361473697083
At time: 933.9530069828033 and batch: 200, loss is 3.7566261005401613 and perplexity is 42.803766478081904
At time: 935.2684595584869 and batch: 250, loss is 3.7430867385864257 and perplexity is 42.228136416042034
At time: 936.5848090648651 and batch: 300, loss is 3.7567926979064943 and perplexity is 42.81089806688175
At time: 937.9027922153473 and batch: 350, loss is 3.7777836179733275 and perplexity is 43.719036188577164
At time: 939.2199409008026 and batch: 400, loss is 3.760730471611023 and perplexity is 42.97981004586814
At time: 940.5374372005463 and batch: 450, loss is 3.790829038619995 and perplexity is 44.293105754021234
At time: 941.8525900840759 and batch: 500, loss is 3.8077007007598875 and perplexity is 45.04674375527207
At time: 943.1678030490875 and batch: 550, loss is 3.775952763557434 and perplexity is 43.63906622712968
At time: 944.4837825298309 and batch: 600, loss is 3.7367789506912232 and perplexity is 41.96260861524907
At time: 945.8018686771393 and batch: 650, loss is 3.7528878688812255 and perplexity is 42.64405478874775
At time: 947.1210057735443 and batch: 700, loss is 3.7972419929504393 and perplexity is 44.578068167233596
At time: 948.43980717659 and batch: 750, loss is 3.7622057056427 and perplexity is 43.04326211614191
At time: 949.7557377815247 and batch: 800, loss is 3.7184907817840576 and perplexity is 41.20216410449213
At time: 951.0709519386292 and batch: 850, loss is 3.711441469192505 and perplexity is 40.91273849459913
At time: 952.3867042064667 and batch: 900, loss is 3.6851334285736086 and perplexity is 39.85043928241595
At time: 953.7005319595337 and batch: 950, loss is 3.799558334350586 and perplexity is 44.681445874877745
At time: 955.0173244476318 and batch: 1000, loss is 3.7777010679244993 and perplexity is 43.71542732896289
At time: 956.3412599563599 and batch: 1050, loss is 3.7094539403915405 and perplexity is 40.83150400320194
At time: 957.6569249629974 and batch: 1100, loss is 3.710989751815796 and perplexity is 40.8942616731572
At time: 958.9754891395569 and batch: 1150, loss is 3.6913050746917726 and perplexity is 40.09714259101804
At time: 960.2932147979736 and batch: 1200, loss is 3.734994430541992 and perplexity is 41.88779227015298
At time: 961.6092607975006 and batch: 1250, loss is 3.701391406059265 and perplexity is 40.503622155810056
At time: 962.925000667572 and batch: 1300, loss is 3.699595084190369 and perplexity is 40.4309299224331
At time: 964.2408125400543 and batch: 1350, loss is 3.564168381690979 and perplexity is 35.31007668459991
At time: 965.5565762519836 and batch: 1400, loss is 3.606811909675598 and perplexity is 36.84838936003325
At time: 966.8727405071259 and batch: 1450, loss is 3.523721556663513 and perplexity is 33.910393376117185
At time: 968.1926074028015 and batch: 1500, loss is 3.5227835416793822 and perplexity is 33.878599832753835
At time: 969.5109126567841 and batch: 1550, loss is 3.526040372848511 and perplexity is 33.98911658216557
At time: 970.8255627155304 and batch: 1600, loss is 3.619639654159546 and perplexity is 37.32411580863041
At time: 972.1427342891693 and batch: 1650, loss is 3.5547277784347533 and perplexity is 34.97829682483864
At time: 973.4591619968414 and batch: 1700, loss is 3.576594018936157 and perplexity is 35.75156408942607
At time: 974.7745099067688 and batch: 1750, loss is 3.5798426818847657 and perplexity is 35.867897733123584
At time: 976.0917599201202 and batch: 1800, loss is 3.5198844289779663 and perplexity is 33.78052418853805
At time: 977.4060735702515 and batch: 1850, loss is 3.5564816617965698 and perplexity is 35.03969850761946
At time: 978.7212173938751 and batch: 1900, loss is 3.6391922664642333 and perplexity is 38.06108109428646
At time: 980.0376763343811 and batch: 1950, loss is 3.5903646469116213 and perplexity is 36.247290979626236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352182787518169 and perplexity of 77.64776665687562
finished 18 epochs...
Completing Train Step...
At time: 984.0003957748413 and batch: 50, loss is 3.8269038295745847 and perplexity is 45.920141321923
At time: 985.3186490535736 and batch: 100, loss is 3.7883192777633665 and perplexity is 44.18208003326361
At time: 986.6344048976898 and batch: 150, loss is 3.7413437175750732 and perplexity is 42.154595996865254
At time: 987.9542734622955 and batch: 200, loss is 3.752930636405945 and perplexity is 42.64587860841492
At time: 989.3050227165222 and batch: 250, loss is 3.739792814254761 and perplexity is 42.089268965016856
At time: 990.620721578598 and batch: 300, loss is 3.753383755683899 and perplexity is 42.665206656762635
At time: 991.936511516571 and batch: 350, loss is 3.7742739057540895 and perplexity is 43.565863905601745
At time: 993.256742477417 and batch: 400, loss is 3.757101130485535 and perplexity is 42.82410437910733
At time: 994.5810797214508 and batch: 450, loss is 3.7874117374420164 and perplexity is 44.14200120348018
At time: 995.9016103744507 and batch: 500, loss is 3.8042073678970336 and perplexity is 44.88965502630787
At time: 997.2229297161102 and batch: 550, loss is 3.772316083908081 and perplexity is 43.4806531464682
At time: 998.5412359237671 and batch: 600, loss is 3.7335491800308227 and perplexity is 41.82729764243843
At time: 999.8616635799408 and batch: 650, loss is 3.749713730812073 and perplexity is 42.50891126658495
At time: 1001.1822590827942 and batch: 700, loss is 3.794129648208618 and perplexity is 44.43954153431358
At time: 1002.5027284622192 and batch: 750, loss is 3.759169268608093 and perplexity is 42.91276218863549
At time: 1003.8227760791779 and batch: 800, loss is 3.715729064941406 and perplexity is 41.08853237548417
At time: 1005.1415476799011 and batch: 850, loss is 3.7087624216079713 and perplexity is 40.80327801174879
At time: 1006.4677467346191 and batch: 900, loss is 3.6824993896484375 and perplexity is 39.74560979724344
At time: 1007.7896020412445 and batch: 950, loss is 3.79698760509491 and perplexity is 44.56672949034088
At time: 1009.1115827560425 and batch: 1000, loss is 3.775178995132446 and perplexity is 43.605312755956355
At time: 1010.4306495189667 and batch: 1050, loss is 3.7071942138671874 and perplexity is 40.739340142355665
At time: 1011.7498404979706 and batch: 1100, loss is 3.708815722465515 and perplexity is 40.80545291941911
At time: 1013.0687980651855 and batch: 1150, loss is 3.6889086627960204 and perplexity is 40.00116836434647
At time: 1014.3884170055389 and batch: 1200, loss is 3.7329190254211424 and perplexity is 41.80094828097631
At time: 1015.705249786377 and batch: 1250, loss is 3.699609661102295 and perplexity is 40.43151928483319
At time: 1017.0222764015198 and batch: 1300, loss is 3.698087286949158 and perplexity is 40.37001421364604
At time: 1018.3394756317139 and batch: 1350, loss is 3.5630354404449465 and perplexity is 35.27009509499589
At time: 1019.6610658168793 and batch: 1400, loss is 3.605762996673584 and perplexity is 36.809758868884295
At time: 1020.9913778305054 and batch: 1450, loss is 3.522915472984314 and perplexity is 33.883069775495244
At time: 1022.3109421730042 and batch: 1500, loss is 3.5223079109191895 and perplexity is 33.86248996004033
At time: 1023.6273653507233 and batch: 1550, loss is 3.5257294464111326 and perplexity is 33.97855011001994
At time: 1024.9427795410156 and batch: 1600, loss is 3.6195468950271605 and perplexity is 37.32065381659912
At time: 1026.25763463974 and batch: 1650, loss is 3.554658923149109 and perplexity is 34.975888467134446
At time: 1027.57261800766 and batch: 1700, loss is 3.576590690612793 and perplexity is 35.751445096858035
At time: 1028.8897306919098 and batch: 1750, loss is 3.5797805404663086 and perplexity is 35.86566892033288
At time: 1030.2072575092316 and batch: 1800, loss is 3.5198939752578737 and perplexity is 33.780846668416615
At time: 1031.525143623352 and batch: 1850, loss is 3.556499819755554 and perplexity is 35.04033476280432
At time: 1032.8420400619507 and batch: 1900, loss is 3.6392765474319457 and perplexity is 38.06428905421635
At time: 1034.158080816269 and batch: 1950, loss is 3.5903056955337522 and perplexity is 36.2451542148622
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352150140806686 and perplexity of 77.64523175401864
finished 19 epochs...
Completing Train Step...
At time: 1038.1074290275574 and batch: 50, loss is 3.8249790859222412 and perplexity is 45.83184182560623
At time: 1039.4219012260437 and batch: 100, loss is 3.786098198890686 and perplexity is 44.08405704743925
At time: 1040.736610174179 and batch: 150, loss is 3.738973088264465 and perplexity is 42.054781434427426
At time: 1042.0527501106262 and batch: 200, loss is 3.7465872812271117 and perplexity is 42.37621683790631
At time: 1043.3698353767395 and batch: 250, loss is 3.7369498872756957 and perplexity is 41.9697821733356
At time: 1044.6878337860107 and batch: 300, loss is 3.7505156230926513 and perplexity is 42.543012505318124
At time: 1046.0050556659698 and batch: 350, loss is 3.7713313579559324 and perplexity is 43.43785769325339
At time: 1047.3200361728668 and batch: 400, loss is 3.7541065502166746 and perplexity is 42.69605598239278
At time: 1048.6357917785645 and batch: 450, loss is 3.7846050167083742 and perplexity is 44.01828063923359
At time: 1049.953202009201 and batch: 500, loss is 3.8013114166259765 and perplexity is 44.75984482550658
At time: 1051.27108335495 and batch: 550, loss is 3.7693064498901365 and perplexity is 43.34998901786783
At time: 1052.5868873596191 and batch: 600, loss is 3.730843858718872 and perplexity is 41.71429428681858
At time: 1053.9093141555786 and batch: 650, loss is 3.747063798904419 and perplexity is 42.396414666255914
At time: 1055.25568151474 and batch: 700, loss is 3.791525545120239 and perplexity is 44.32396693635434
At time: 1056.5718805789948 and batch: 750, loss is 3.7565932273864746 and perplexity is 42.80235940641567
At time: 1057.8902530670166 and batch: 800, loss is 3.71335253238678 and perplexity is 40.991000080913054
At time: 1059.207615852356 and batch: 850, loss is 3.706457943916321 and perplexity is 40.709356029945724
At time: 1060.5255000591278 and batch: 900, loss is 3.680190477371216 and perplexity is 39.653946532757274
At time: 1061.842759847641 and batch: 950, loss is 3.794738450050354 and perplexity is 44.46660464624587
At time: 1063.1591489315033 and batch: 1000, loss is 3.7729893255233766 and perplexity is 43.509935987734266
At time: 1064.475924730301 and batch: 1050, loss is 3.7052092933654786 and perplexity is 40.6585559924622
At time: 1065.79296541214 and batch: 1100, loss is 3.7069210815429687 and perplexity is 40.728214431160296
At time: 1067.109160900116 and batch: 1150, loss is 3.6868414974212644 and perplexity is 39.91856474124363
At time: 1068.42471408844 and batch: 1200, loss is 3.731077890396118 and perplexity is 41.724057895527956
At time: 1069.7533831596375 and batch: 1250, loss is 3.697980914115906 and perplexity is 40.36572016924459
At time: 1071.0767517089844 and batch: 1300, loss is 3.6966511631011962 and perplexity is 40.312079484171875
At time: 1072.404049396515 and batch: 1350, loss is 3.561861038208008 and perplexity is 35.228698129521675
At time: 1073.722404241562 and batch: 1400, loss is 3.6046265602111816 and perplexity is 36.76795067740962
At time: 1075.0450060367584 and batch: 1450, loss is 3.5219634675979616 and perplexity is 33.85082826004608
At time: 1076.360051393509 and batch: 1500, loss is 3.521587371826172 and perplexity is 33.83809950043227
At time: 1077.673121213913 and batch: 1550, loss is 3.5251442527770998 and perplexity is 33.958671895671415
At time: 1078.993150472641 and batch: 1600, loss is 3.6191518688201905 and perplexity is 37.30591409176077
At time: 1080.3086395263672 and batch: 1650, loss is 3.5542816162109374 and perplexity is 34.96269431102693
At time: 1081.624275445938 and batch: 1700, loss is 3.5762765550613405 and perplexity is 35.74021606074937
At time: 1082.9389081001282 and batch: 1750, loss is 3.5794073152542114 and perplexity is 35.85228544612344
At time: 1084.257073879242 and batch: 1800, loss is 3.5195641708374024 and perplexity is 33.76970743284364
At time: 1085.5765891075134 and batch: 1850, loss is 3.556179847717285 and perplexity is 35.029124629028956
At time: 1086.8925144672394 and batch: 1900, loss is 3.6390337705612184 and perplexity is 38.05504904690872
At time: 1088.2088425159454 and batch: 1950, loss is 3.5899415016174316 and perplexity is 36.23195635363731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352221111918604 and perplexity of 77.65074251800156
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f00fbd17b38>
ELAPSED
2235.7840309143066


RESULTS SO FAR:
[{'params': {'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}, 'best_accuracy': -78.33907429225935}, {'params': {'dropout': 0.16802636512990798, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.23001756521426064}, 'best_accuracy': -77.64523175401864}]
SETTINGS FOR THIS RUN
{'dropout': 0.7990403138855218, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.10718988942097152}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.947021722793579 and batch: 50, loss is 7.67092188835144 and perplexity is 2145.0580380272613
At time: 3.4686310291290283 and batch: 100, loss is 6.766320352554321 and perplexity is 868.11166487398
At time: 4.996333837509155 and batch: 150, loss is 6.534013509750366 and perplexity is 688.1545915756464
At time: 6.5286359786987305 and batch: 200, loss is 6.4513109683990475 and perplexity is 633.5322894549481
At time: 8.063146829605103 and batch: 250, loss is 6.388008728027343 and perplexity is 594.6712477319817
At time: 9.594930171966553 and batch: 300, loss is 6.31356954574585 and perplexity is 552.011867834328
At time: 11.12864637374878 and batch: 350, loss is 6.259598417282104 and perplexity is 523.0088666077445
At time: 12.663222074508667 and batch: 400, loss is 6.229235010147095 and perplexity is 507.3672042369444
At time: 14.196423053741455 and batch: 450, loss is 6.152349128723144 and perplexity is 469.81975855840125
At time: 15.728805541992188 and batch: 500, loss is 6.122817668914795 and perplexity is 456.1481599508599
At time: 17.26100993156433 and batch: 550, loss is 6.077312450408936 and perplexity is 435.8562339859284
At time: 18.79185199737549 and batch: 600, loss is 6.127359113693237 and perplexity is 458.224442723281
At time: 20.323764085769653 and batch: 650, loss is 6.210337724685669 and perplexity is 497.86936567204594
At time: 21.8561794757843 and batch: 700, loss is 6.108334789276123 and perplexity is 449.5894303414532
At time: 23.387295246124268 and batch: 750, loss is 6.0370669937133785 and perplexity is 418.66329028154814
At time: 24.92007565498352 and batch: 800, loss is 6.040121688842773 and perplexity is 419.94413429322935
At time: 26.454599142074585 and batch: 850, loss is 6.092045888900757 and perplexity is 442.325434762204
At time: 27.99349808692932 and batch: 900, loss is 6.077601842880249 and perplexity is 435.9823857514238
At time: 29.5268337726593 and batch: 950, loss is 6.088268995285034 and perplexity is 440.65796955311845
At time: 31.05996060371399 and batch: 1000, loss is 6.074987268447876 and perplexity is 434.84396624246335
At time: 32.59199261665344 and batch: 1050, loss is 5.9644902896881105 and perplexity is 389.35451947064286
At time: 34.12732458114624 and batch: 1100, loss is 6.041792335510254 and perplexity is 420.646298932907
At time: 35.66917157173157 and batch: 1150, loss is 5.950501127243042 and perplexity is 383.94569650767653
At time: 37.20743799209595 and batch: 1200, loss is 6.03350567817688 and perplexity is 417.17494999904005
At time: 38.74743700027466 and batch: 1250, loss is 5.955780410766602 and perplexity is 385.9780145686203
At time: 40.287672996520996 and batch: 1300, loss is 5.9722745227813725 and perplexity is 392.3971728035654
At time: 41.822524070739746 and batch: 1350, loss is 5.968858270645142 and perplexity is 391.0589323087245
At time: 43.35655879974365 and batch: 1400, loss is 5.988864297866821 and perplexity is 398.96125139145016
At time: 44.885873794555664 and batch: 1450, loss is 5.961944217681885 and perplexity is 388.36445574972254
At time: 46.419092655181885 and batch: 1500, loss is 5.946868314743042 and perplexity is 382.5534242453102
At time: 47.95311188697815 and batch: 1550, loss is 5.92763469696045 and perplexity is 375.2658458087448
At time: 49.49053716659546 and batch: 1600, loss is 5.917727365493774 and perplexity is 371.56631916516295
At time: 51.025954246520996 and batch: 1650, loss is 5.907788562774658 and perplexity is 367.8916857982077
At time: 52.55886268615723 and batch: 1700, loss is 5.926447114944458 and perplexity is 374.82045136261047
At time: 54.093501806259155 and batch: 1750, loss is 5.930229082107544 and perplexity is 376.24069396431537
At time: 55.6282422542572 and batch: 1800, loss is 5.944188823699951 and perplexity is 381.52974784987936
At time: 57.162877798080444 and batch: 1850, loss is 5.894725294113159 and perplexity is 363.1170717993988
At time: 58.70013618469238 and batch: 1900, loss is 5.856040344238282 and perplexity is 349.3381429966508
At time: 60.23576617240906 and batch: 1950, loss is 5.792882108688355 and perplexity is 327.9568709355728
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.2970765579578485 and perplexity of 199.75199217889931
finished 1 epochs...
Completing Train Step...
At time: 64.31876111030579 and batch: 50, loss is 5.577271366119385 and perplexity is 264.3493083127206
At time: 65.63786888122559 and batch: 100, loss is 5.495227584838867 and perplexity is 243.52694289448482
At time: 66.95495271682739 and batch: 150, loss is 5.3813889122009275 and perplexity is 217.32390973445493
At time: 68.2731864452362 and batch: 200, loss is 5.335425453186035 and perplexity is 207.56103752996233
At time: 69.59150910377502 and batch: 250, loss is 5.323597183227539 and perplexity is 205.12041218807656
At time: 70.91017723083496 and batch: 300, loss is 5.312271156311035 and perplexity is 202.81031965821822
At time: 72.25842332839966 and batch: 350, loss is 5.265336513519287 and perplexity is 193.51141703987406
At time: 73.57475996017456 and batch: 400, loss is 5.2240576171875 and perplexity is 185.68610065771315
At time: 74.89443874359131 and batch: 450, loss is 5.165678672790527 and perplexity is 175.156292052217
At time: 76.2141580581665 and batch: 500, loss is 5.143501834869385 and perplexity is 171.31463470519307
At time: 77.53269553184509 and batch: 550, loss is 5.082963733673096 and perplexity is 161.25125420692837
At time: 78.85008263587952 and batch: 600, loss is 5.07990608215332 and perplexity is 160.75895708450903
At time: 80.16656994819641 and batch: 650, loss is 5.143712396621704 and perplexity is 171.3507108128655
At time: 81.48425245285034 and batch: 700, loss is 5.102995567321777 and perplexity is 164.51398261987242
At time: 82.80200386047363 and batch: 750, loss is 5.054154653549194 and perplexity is 156.67203220227884
At time: 84.11836194992065 and batch: 800, loss is 5.0365941524505615 and perplexity is 153.94480859795655
At time: 85.43022561073303 and batch: 850, loss is 5.03147027015686 and perplexity is 153.1580309184336
At time: 86.74086999893188 and batch: 900, loss is 5.03785623550415 and perplexity is 154.1392223894457
At time: 88.062087059021 and batch: 950, loss is 5.087255802154541 and perplexity is 161.94484303330822
At time: 89.37699174880981 and batch: 1000, loss is 5.041147470474243 and perplexity is 154.6473665406426
At time: 90.69378566741943 and batch: 1050, loss is 4.945730428695679 and perplexity is 140.573492273371
At time: 92.00903487205505 and batch: 1100, loss is 5.026348991394043 and perplexity is 152.37567099890094
At time: 93.32236862182617 and batch: 1150, loss is 4.9313748264312744 and perplexity is 138.56989098988547
At time: 94.64299583435059 and batch: 1200, loss is 5.015370674133301 and perplexity is 150.71199145014282
At time: 95.96888566017151 and batch: 1250, loss is 4.954350461959839 and perplexity is 141.79047814651491
At time: 97.28566646575928 and batch: 1300, loss is 4.992054967880249 and perplexity is 147.2386835874395
At time: 98.59944748878479 and batch: 1350, loss is 4.892449779510498 and perplexity is 133.27968027392066
At time: 99.9133472442627 and batch: 1400, loss is 4.909036340713501 and perplexity is 135.50876718696972
At time: 101.22705507278442 and batch: 1450, loss is 4.853215885162354 and perplexity is 128.1518495192903
At time: 102.54089522361755 and batch: 1500, loss is 4.833867664337158 and perplexity is 125.69617233501715
At time: 103.85582852363586 and batch: 1550, loss is 4.818741369247436 and perplexity is 123.80916265287644
At time: 105.17093849182129 and batch: 1600, loss is 4.877182722091675 and perplexity is 131.26034561408585
At time: 106.48703384399414 and batch: 1650, loss is 4.838690748214722 and perplexity is 126.30387985139231
At time: 107.80032157897949 and batch: 1700, loss is 4.861866807937622 and perplexity is 129.2652904748411
At time: 109.11604237556458 and batch: 1750, loss is 4.87865686416626 and perplexity is 131.4539847029779
At time: 110.43031215667725 and batch: 1800, loss is 4.835200681686401 and perplexity is 125.86383924009203
At time: 111.74558019638062 and batch: 1850, loss is 4.835165405273438 and perplexity is 125.85939929363502
At time: 113.06755685806274 and batch: 1900, loss is 4.8939837551116945 and perplexity is 133.48428494075858
At time: 114.39651775360107 and batch: 1950, loss is 4.8071808242797855 and perplexity is 122.38610278327114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6587433571039245 and perplexity of 105.503418697203
finished 2 epochs...
Completing Train Step...
At time: 118.35590386390686 and batch: 50, loss is 4.759972372055054 and perplexity is 116.74270049353234
At time: 119.70967292785645 and batch: 100, loss is 4.699928941726685 and perplexity is 109.93936007346353
At time: 121.0289659500122 and batch: 150, loss is 4.648594770431519 and perplexity is 104.43812287503489
At time: 122.34516525268555 and batch: 200, loss is 4.6370934391021725 and perplexity is 103.24382658426595
At time: 123.66151404380798 and batch: 250, loss is 4.644584112167358 and perplexity is 104.02009609605373
At time: 124.98069953918457 and batch: 300, loss is 4.669042587280273 and perplexity is 106.59563754273941
At time: 126.29904127120972 and batch: 350, loss is 4.673143911361694 and perplexity is 107.03371853996488
At time: 127.61394047737122 and batch: 400, loss is 4.637425270080566 and perplexity is 103.278091769065
At time: 128.9313530921936 and batch: 450, loss is 4.6235981464385985 and perplexity is 101.85988031275109
At time: 130.24792408943176 and batch: 500, loss is 4.632215461730957 and perplexity is 102.74143186569687
At time: 131.5667314529419 and batch: 550, loss is 4.590450220108032 and perplexity is 98.53878431875181
At time: 132.8859977722168 and batch: 600, loss is 4.565910186767578 and perplexity is 96.15006872158224
At time: 134.20549774169922 and batch: 650, loss is 4.627388887405395 and perplexity is 102.24673750838328
At time: 135.52287101745605 and batch: 700, loss is 4.637963962554932 and perplexity is 103.33374188767212
At time: 136.83969020843506 and batch: 750, loss is 4.602942695617676 and perplexity is 99.7774988645257
At time: 138.18849802017212 and batch: 800, loss is 4.578572063446045 and perplexity is 97.37524920778745
At time: 139.5049889087677 and batch: 850, loss is 4.578107089996338 and perplexity is 97.32998282689537
At time: 140.82338666915894 and batch: 900, loss is 4.5643173122406 and perplexity is 95.99703563995418
At time: 142.136714220047 and batch: 950, loss is 4.631043291091919 and perplexity is 102.62107193082306
At time: 143.45209550857544 and batch: 1000, loss is 4.603996286392212 and perplexity is 99.88267891547166
At time: 144.76579523086548 and batch: 1050, loss is 4.5359664726257325 and perplexity is 93.31365683268335
At time: 146.07952046394348 and batch: 1100, loss is 4.600437030792237 and perplexity is 99.52780285314695
At time: 147.39416432380676 and batch: 1150, loss is 4.523978786468506 and perplexity is 92.20172009057418
At time: 148.7089147567749 and batch: 1200, loss is 4.621541757583618 and perplexity is 101.65063201178125
At time: 150.02172541618347 and batch: 1250, loss is 4.579179840087891 and perplexity is 97.43444959823474
At time: 151.33557844161987 and batch: 1300, loss is 4.596534395217896 and perplexity is 99.14013905638642
At time: 152.65051889419556 and batch: 1350, loss is 4.479435110092163 and perplexity is 88.18484387475415
At time: 153.96628737449646 and batch: 1400, loss is 4.505773859024048 and perplexity is 90.53838088912727
At time: 155.28218150138855 and batch: 1450, loss is 4.433872375488281 and perplexity is 84.25706097292473
At time: 156.59666347503662 and batch: 1500, loss is 4.446714811325073 and perplexity is 85.34610489280557
At time: 157.91380095481873 and batch: 1550, loss is 4.438352785110474 and perplexity is 84.6354140751617
At time: 159.23194241523743 and batch: 1600, loss is 4.524678211212159 and perplexity is 92.26623081258062
At time: 160.55124950408936 and batch: 1650, loss is 4.477592172622681 and perplexity is 88.0224743861004
At time: 161.87823390960693 and batch: 1700, loss is 4.498977289199829 and perplexity is 89.92511686823734
At time: 163.19708108901978 and batch: 1750, loss is 4.506215534210205 and perplexity is 90.57837827763763
At time: 164.51428818702698 and batch: 1800, loss is 4.462468786239624 and perplexity is 86.70129205231353
At time: 165.83470344543457 and batch: 1850, loss is 4.491680221557617 and perplexity is 89.27131552511676
At time: 167.15499877929688 and batch: 1900, loss is 4.565276708602905 and perplexity is 96.0891790406932
At time: 168.4696660041809 and batch: 1950, loss is 4.484929141998291 and perplexity is 88.67066756404017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509379258266715 and perplexity of 90.86539705670108
finished 3 epochs...
Completing Train Step...
At time: 172.4195761680603 and batch: 50, loss is 4.451809272766114 and perplexity is 85.78200673311792
At time: 173.75294828414917 and batch: 100, loss is 4.392196073532104 and perplexity is 80.81770586648611
At time: 175.07212138175964 and batch: 150, loss is 4.347286539077759 and perplexity is 77.2685131179162
At time: 176.3912422657013 and batch: 200, loss is 4.345957508087158 and perplexity is 77.16588907975402
At time: 177.70955419540405 and batch: 250, loss is 4.346672077178955 and perplexity is 77.221049144523
At time: 179.0270733833313 and batch: 300, loss is 4.37562445640564 and perplexity is 79.48946176077321
At time: 180.34230613708496 and batch: 350, loss is 4.383791484832764 and perplexity is 80.14131267387921
At time: 181.65864872932434 and batch: 400, loss is 4.350708742141723 and perplexity is 77.53339464092342
At time: 182.9740595817566 and batch: 450, loss is 4.354969568252564 and perplexity is 77.86445574932128
At time: 184.28952741622925 and batch: 500, loss is 4.3740173435211185 and perplexity is 79.36181582078501
At time: 185.60628485679626 and batch: 550, loss is 4.333885898590088 and perplexity is 76.23997249597831
At time: 186.92429065704346 and batch: 600, loss is 4.307430448532105 and perplexity is 74.24945581255444
At time: 188.24313712120056 and batch: 650, loss is 4.36563588142395 and perplexity is 78.69942753832866
At time: 189.5617003440857 and batch: 700, loss is 4.38342622756958 and perplexity is 80.11204582263439
At time: 190.88867211341858 and batch: 750, loss is 4.360201816558838 and perplexity is 78.27292960246884
At time: 192.21158719062805 and batch: 800, loss is 4.336345543861389 and perplexity is 76.42772659339404
At time: 193.52988028526306 and batch: 850, loss is 4.331704082489014 and perplexity is 76.07381222792992
At time: 194.8481810092926 and batch: 900, loss is 4.3081842708587645 and perplexity is 74.30544781144627
At time: 196.176451921463 and batch: 950, loss is 4.385421600341797 and perplexity is 80.27205880728069
At time: 197.4948058128357 and batch: 1000, loss is 4.369224119186401 and perplexity is 78.98232704791849
At time: 198.81359243392944 and batch: 1050, loss is 4.309966268539429 and perplexity is 74.43797799627703
At time: 200.13067936897278 and batch: 1100, loss is 4.358910913467407 and perplexity is 78.17195202582525
At time: 201.44956851005554 and batch: 1150, loss is 4.297968893051148 and perplexity is 73.55025345400892
At time: 202.76886296272278 and batch: 1200, loss is 4.389876236915589 and perplexity is 80.63043929106706
At time: 204.12261152267456 and batch: 1250, loss is 4.353055057525634 and perplexity is 77.71552602281214
At time: 205.4363875389099 and batch: 1300, loss is 4.366097803115845 and perplexity is 78.7357889084546
At time: 206.75036668777466 and batch: 1350, loss is 4.237486205101013 and perplexity is 69.23359385103734
At time: 208.06545281410217 and batch: 1400, loss is 4.271077151298523 and perplexity is 71.59871674846538
At time: 209.37954807281494 and batch: 1450, loss is 4.205569877624511 and perplexity is 67.05880209018534
At time: 210.69298672676086 and batch: 1500, loss is 4.214674029350281 and perplexity is 67.67210315579489
At time: 212.00727319717407 and batch: 1550, loss is 4.209527883529663 and perplexity is 67.32474718378913
At time: 213.3267855644226 and batch: 1600, loss is 4.303295783996582 and perplexity is 73.94309301098043
At time: 214.65091252326965 and batch: 1650, loss is 4.263018589019776 and perplexity is 71.02405262369662
At time: 215.969242811203 and batch: 1700, loss is 4.281539845466614 and perplexity is 72.35176481087677
At time: 217.28829216957092 and batch: 1750, loss is 4.285566973686218 and perplexity is 72.6437221248795
At time: 218.6074402332306 and batch: 1800, loss is 4.236953310966491 and perplexity is 69.19670950356134
At time: 219.92653560638428 and batch: 1850, loss is 4.273039617538452 and perplexity is 71.73936477627012
At time: 221.24718976020813 and batch: 1900, loss is 4.351654405593872 and perplexity is 77.60674981774459
At time: 222.5636510848999 and batch: 1950, loss is 4.278154888153076 and perplexity is 72.1072712090849
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.458516533430233 and perplexity of 86.35930288620759
finished 4 epochs...
Completing Train Step...
At time: 226.50969338417053 and batch: 50, loss is 4.253104319572449 and perplexity is 70.32338009610301
At time: 227.83697938919067 and batch: 100, loss is 4.195431423187256 and perplexity is 66.3823642916226
At time: 229.15367603302002 and batch: 150, loss is 4.152786674499512 and perplexity is 63.611016738203375
At time: 230.4704246520996 and batch: 200, loss is 4.164832129478454 and perplexity is 64.3818737175355
At time: 231.7868127822876 and batch: 250, loss is 4.150265502929687 and perplexity is 63.450844447030754
At time: 233.10191226005554 and batch: 300, loss is 4.178064842224121 and perplexity is 65.23948228816226
At time: 234.41680932044983 and batch: 350, loss is 4.188946676254273 and perplexity is 65.95328419991921
At time: 235.76491284370422 and batch: 400, loss is 4.157580337524414 and perplexity is 63.916678551662464
At time: 237.08176064491272 and batch: 450, loss is 4.177786650657654 and perplexity is 65.22133573861461
At time: 238.40156817436218 and batch: 500, loss is 4.196948118209839 and perplexity is 66.48312248354003
At time: 239.71686458587646 and batch: 550, loss is 4.157423810958862 and perplexity is 63.90667467644384
At time: 241.02974605560303 and batch: 600, loss is 4.13043966293335 and perplexity is 62.20526627323364
At time: 242.34418869018555 and batch: 650, loss is 4.182704958915711 and perplexity is 65.54290451173324
At time: 243.65921998023987 and batch: 700, loss is 4.21376953125 and perplexity is 67.61092154054695
At time: 244.97531270980835 and batch: 750, loss is 4.191054315567016 and perplexity is 66.09243652444712
At time: 246.2894868850708 and batch: 800, loss is 4.160517086982727 and perplexity is 64.10466171740131
At time: 247.60237336158752 and batch: 850, loss is 4.160064296722412 and perplexity is 64.07564232128064
At time: 248.9162061214447 and batch: 900, loss is 4.130792942047119 and perplexity is 62.22724597683092
At time: 250.22993636131287 and batch: 950, loss is 4.212491755485535 and perplexity is 67.52458511463247
At time: 251.54598140716553 and batch: 1000, loss is 4.197650680541992 and perplexity is 66.5298474327936
At time: 252.87018871307373 and batch: 1050, loss is 4.144608402252198 and perplexity is 63.09291002203568
At time: 254.1929633617401 and batch: 1100, loss is 4.18664092540741 and perplexity is 65.80138754423949
At time: 255.5139570236206 and batch: 1150, loss is 4.131511068344116 and perplexity is 62.27194904786087
At time: 256.83659076690674 and batch: 1200, loss is 4.220518097877503 and perplexity is 68.06874142576423
At time: 258.16112661361694 and batch: 1250, loss is 4.19032054901123 and perplexity is 66.04395789310936
At time: 259.4849305152893 and batch: 1300, loss is 4.200735912322998 and perplexity is 66.73542439570048
At time: 260.80985021591187 and batch: 1350, loss is 4.071579132080078 and perplexity is 58.64950481900224
At time: 262.13152170181274 and batch: 1400, loss is 4.109889693260193 and perplexity is 60.93999510667848
At time: 263.4538173675537 and batch: 1450, loss is 4.039264745712281 and perplexity is 56.78457634963033
At time: 264.777321100235 and batch: 1500, loss is 4.048847155570984 and perplexity is 57.33132483425172
At time: 266.1007182598114 and batch: 1550, loss is 4.048491020202636 and perplexity is 57.31091075706722
At time: 267.42465329170227 and batch: 1600, loss is 4.1447369003295895 and perplexity is 63.10101786058026
At time: 268.74648785591125 and batch: 1650, loss is 4.100430417060852 and perplexity is 60.36626467668861
At time: 270.070232629776 and batch: 1700, loss is 4.124038600921631 and perplexity is 61.808358178256015
At time: 271.39342188835144 and batch: 1750, loss is 4.12785496711731 and perplexity is 62.0446921887387
At time: 272.7159323692322 and batch: 1800, loss is 4.075456953048706 and perplexity is 58.87737863997535
At time: 274.0397412776947 and batch: 1850, loss is 4.114056277275085 and perplexity is 61.194436423618896
At time: 275.3715476989746 and batch: 1900, loss is 4.193576922416687 and perplexity is 66.25937222558147
At time: 276.69722294807434 and batch: 1950, loss is 4.123910236358642 and perplexity is 61.800424684570025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4366281908611915 and perplexity of 84.48957811683535
finished 5 epochs...
Completing Train Step...
At time: 280.7003619670868 and batch: 50, loss is 4.105238733291626 and perplexity is 60.65722371788629
At time: 282.01913833618164 and batch: 100, loss is 4.047039909362793 and perplexity is 57.227806584492036
At time: 283.33453011512756 and batch: 150, loss is 4.0062093877792355 and perplexity is 54.93822585738545
At time: 284.6505591869354 and batch: 200, loss is 4.028344287872314 and perplexity is 56.16783644786108
At time: 285.9662847518921 and batch: 250, loss is 4.001938042640686 and perplexity is 54.70406617786159
At time: 287.28738236427307 and batch: 300, loss is 4.031595187187195 and perplexity is 56.350729551347065
At time: 288.6039848327637 and batch: 350, loss is 4.036110615730285 and perplexity is 56.60575257981087
At time: 289.9224708080292 and batch: 400, loss is 4.011223406791687 and perplexity is 55.21437890611376
At time: 291.23866868019104 and batch: 450, loss is 4.041591029167176 and perplexity is 56.91682713685418
At time: 292.55473279953003 and batch: 500, loss is 4.056708936691284 and perplexity is 57.783827569492466
At time: 293.8744864463806 and batch: 550, loss is 4.019325246810913 and perplexity is 55.66353400528203
At time: 295.1921091079712 and batch: 600, loss is 3.9972148180007934 and perplexity is 54.44629581746006
At time: 296.5081377029419 and batch: 650, loss is 4.047370648384094 and perplexity is 57.24673718360434
At time: 297.82305693626404 and batch: 700, loss is 4.077833113670349 and perplexity is 59.0174470952753
At time: 299.1522436141968 and batch: 750, loss is 4.056434841156006 and perplexity is 57.767991450748234
At time: 300.4749083518982 and batch: 800, loss is 4.022904806137085 and perplexity is 55.863141968696375
At time: 301.805632352829 and batch: 850, loss is 4.0249048566818235 and perplexity is 55.974982882679974
At time: 303.12752413749695 and batch: 900, loss is 3.9945698833465575 and perplexity is 54.3024791994773
At time: 304.446950674057 and batch: 950, loss is 4.082267251014709 and perplexity is 59.27971960785644
At time: 305.7628948688507 and batch: 1000, loss is 4.066812801361084 and perplexity is 58.37062702239385
At time: 307.08242082595825 and batch: 1050, loss is 4.017908234596252 and perplexity is 55.584713955360805
At time: 308.4010491371155 and batch: 1100, loss is 4.054166951179504 and perplexity is 57.63712844950812
At time: 309.71814942359924 and batch: 1150, loss is 4.006652622222901 and perplexity is 54.96258176864994
At time: 311.0324695110321 and batch: 1200, loss is 4.091145191192627 and perplexity is 59.80834449025606
At time: 312.3480715751648 and batch: 1250, loss is 4.06605098247528 and perplexity is 58.326176110274
At time: 313.66413283348083 and batch: 1300, loss is 4.072836999893188 and perplexity is 58.72332456137453
At time: 314.98330426216125 and batch: 1350, loss is 3.9396533298492433 and perplexity is 51.40077909565408
At time: 316.30067443847656 and batch: 1400, loss is 3.9810350275039674 and perplexity is 53.572454505655905
At time: 317.6236310005188 and batch: 1450, loss is 3.916181831359863 and perplexity is 50.208374292457506
At time: 318.9569182395935 and batch: 1500, loss is 3.9196011781692506 and perplexity is 50.38034798819416
At time: 320.2774832248688 and batch: 1550, loss is 3.9230396795272826 and perplexity is 50.55387905559949
At time: 321.59415650367737 and batch: 1600, loss is 4.0200430250167845 and perplexity is 55.70350241936507
At time: 322.91105222702026 and batch: 1650, loss is 3.9768644094467165 and perplexity is 53.349489533581355
At time: 324.2376208305359 and batch: 1700, loss is 4.003332405090332 and perplexity is 54.78039667740704
At time: 325.552449464798 and batch: 1750, loss is 4.002222752571106 and perplexity is 54.71964318609602
At time: 326.86975932121277 and batch: 1800, loss is 3.9535315084457396 and perplexity is 52.11910126032452
At time: 328.1891973018646 and batch: 1850, loss is 3.988587727546692 and perplexity is 53.97860301334699
At time: 329.507520198822 and batch: 1900, loss is 4.066488976478577 and perplexity is 58.35172822107267
At time: 330.8247947692871 and batch: 1950, loss is 4.001060786247254 and perplexity is 54.656097729450664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.439833246275436 and perplexity of 84.76080631514878
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 334.7926564216614 and batch: 50, loss is 4.02856369972229 and perplexity is 56.18016168886776
At time: 336.1074411869049 and batch: 100, loss is 4.00011598110199 and perplexity is 54.604482753982566
At time: 337.4237277507782 and batch: 150, loss is 3.9628547382354737 and perplexity is 52.607291838049306
At time: 338.7376265525818 and batch: 200, loss is 3.9773229503631593 and perplexity is 53.373958066886956
At time: 340.0513849258423 and batch: 250, loss is 3.959243712425232 and perplexity is 52.41766812352881
At time: 341.3655574321747 and batch: 300, loss is 3.9793463850021364 and perplexity is 53.48206612036343
At time: 342.68120551109314 and batch: 350, loss is 3.9783990955352784 and perplexity is 53.431427111148594
At time: 343.9961977005005 and batch: 400, loss is 3.956253423690796 and perplexity is 52.26115828248451
At time: 345.31152749061584 and batch: 450, loss is 3.973306941986084 and perplexity is 53.160037644790975
At time: 346.62451672554016 and batch: 500, loss is 3.9886616039276124 and perplexity is 53.98259090448842
At time: 347.9409108161926 and batch: 550, loss is 3.949333529472351 and perplexity is 51.900764975333956
At time: 349.2572503089905 and batch: 600, loss is 3.9115522956848143 and perplexity is 49.976470051155964
At time: 350.57366728782654 and batch: 650, loss is 3.947164635658264 and perplexity is 51.78831971222984
At time: 351.8899018764496 and batch: 700, loss is 3.982814612388611 and perplexity is 53.66787611617256
At time: 353.20666217803955 and batch: 750, loss is 3.9443590593338014 and perplexity is 51.643227257710805
At time: 354.5235719680786 and batch: 800, loss is 3.902765793800354 and perplexity is 49.53927522217887
At time: 355.8391773700714 and batch: 850, loss is 3.901452136039734 and perplexity is 49.47424029499872
At time: 357.1617133617401 and batch: 900, loss is 3.8601040744781496 and perplexity is 47.47029155759675
At time: 358.48548769950867 and batch: 950, loss is 3.9513739061355593 and perplexity is 52.00677019350277
At time: 359.8059456348419 and batch: 1000, loss is 3.921140217781067 and perplexity is 50.45794503655403
At time: 361.1225833892822 and batch: 1050, loss is 3.86534604549408 and perplexity is 47.71978279166981
At time: 362.4408121109009 and batch: 1100, loss is 3.8899549198150636 and perplexity is 48.90868166162016
At time: 363.75919795036316 and batch: 1150, loss is 3.851132092475891 and perplexity is 47.04629385018906
At time: 365.0777385234833 and batch: 1200, loss is 3.9343868684768677 and perplexity is 51.130790444462875
At time: 366.3946750164032 and batch: 1250, loss is 3.895415802001953 and perplexity is 49.176496797996336
At time: 367.71073150634766 and batch: 1300, loss is 3.8931376266479494 and perplexity is 49.06459163318887
At time: 369.0276126861572 and batch: 1350, loss is 3.7560095453262328 and perplexity is 42.77738372673128
At time: 370.3462369441986 and batch: 1400, loss is 3.783097019195557 and perplexity is 43.951951206390746
At time: 371.66480684280396 and batch: 1450, loss is 3.7028123998641966 and perplexity is 40.561218464277864
At time: 372.98404359817505 and batch: 1500, loss is 3.6947900915145873 and perplexity is 40.2371255873647
At time: 374.30054998397827 and batch: 1550, loss is 3.6975882482528686 and perplexity is 40.34987304041409
At time: 375.61813855171204 and batch: 1600, loss is 3.7824143981933593 and perplexity is 43.92195891925688
At time: 376.93653893470764 and batch: 1650, loss is 3.7328604316711425 and perplexity is 41.79849907841765
At time: 378.2548131942749 and batch: 1700, loss is 3.7428258895874023 and perplexity is 42.217122685450036
At time: 379.57586145401 and batch: 1750, loss is 3.734067883491516 and perplexity is 41.84899923433585
At time: 380.8945827484131 and batch: 1800, loss is 3.67953565120697 and perplexity is 39.627988590949315
At time: 382.2142822742462 and batch: 1850, loss is 3.6961132764816282 and perplexity is 40.29040198655098
At time: 383.5345823764801 and batch: 1900, loss is 3.7655744695663453 and perplexity is 43.18850921895253
At time: 384.85249495506287 and batch: 1950, loss is 3.6913495445251465 and perplexity is 40.09892574391579
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.395985306140989 and perplexity of 81.12452388824221
finished 7 epochs...
Completing Train Step...
At time: 388.8177833557129 and batch: 50, loss is 3.9138315153121948 and perplexity is 50.09050731121731
At time: 390.1333980560303 and batch: 100, loss is 3.8789384508132936 and perplexity is 48.372837659868686
At time: 391.44997477531433 and batch: 150, loss is 3.831237783432007 and perplexity is 46.11958898182807
At time: 392.7693531513214 and batch: 200, loss is 3.8488279151916505 and perplexity is 46.93801564259108
At time: 394.0858533382416 and batch: 250, loss is 3.8225832986831665 and perplexity is 45.722169911561096
At time: 395.4001667499542 and batch: 300, loss is 3.845766711235046 and perplexity is 46.79454850650864
At time: 396.7163496017456 and batch: 350, loss is 3.8480396842956544 and perplexity is 46.90103222611544
At time: 398.03431129455566 and batch: 400, loss is 3.827447748184204 and perplexity is 45.94512493525451
At time: 399.366224527359 and batch: 450, loss is 3.8517795515060427 and perplexity is 47.07676426108443
At time: 400.6827812194824 and batch: 500, loss is 3.8700916719436647 and perplexity is 47.94678125398916
At time: 401.9994943141937 and batch: 550, loss is 3.8330472612380984 and perplexity is 46.20311690268557
At time: 403.3142457008362 and batch: 600, loss is 3.798106369972229 and perplexity is 44.6166170830315
At time: 404.6317090988159 and batch: 650, loss is 3.832507514953613 and perplexity is 46.17818567088084
At time: 405.95149302482605 and batch: 700, loss is 3.8721767616271974 and perplexity is 48.04685889210773
At time: 407.26864886283875 and batch: 750, loss is 3.8394847774505614 and perplexity is 46.50150964036715
At time: 408.5860459804535 and batch: 800, loss is 3.8001696062088013 and perplexity is 44.70876673471109
At time: 409.90242648124695 and batch: 850, loss is 3.800728645324707 and perplexity is 44.73376767173944
At time: 411.22025084495544 and batch: 900, loss is 3.75852108001709 and perplexity is 42.88495563869417
At time: 412.5375807285309 and batch: 950, loss is 3.855017371177673 and perplexity is 47.229437365096715
At time: 413.8565466403961 and batch: 1000, loss is 3.8282703256607054 and perplexity is 45.982933908454264
At time: 415.17497968673706 and batch: 1050, loss is 3.7787378215789795 and perplexity is 43.76077296006606
At time: 416.49057936668396 and batch: 1100, loss is 3.800157012939453 and perplexity is 44.70820370871455
At time: 417.8079478740692 and batch: 1150, loss is 3.764975862503052 and perplexity is 43.162664008615444
At time: 419.131947517395 and batch: 1200, loss is 3.8488899087905883 and perplexity is 46.94092558930588
At time: 420.46839570999146 and batch: 1250, loss is 3.812702679634094 and perplexity is 45.27263108674675
At time: 421.7905366420746 and batch: 1300, loss is 3.815100474357605 and perplexity is 45.381315812444065
At time: 423.1085596084595 and batch: 1350, loss is 3.6796709156036376 and perplexity is 39.63334920945945
At time: 424.4265387058258 and batch: 1400, loss is 3.7114419746398926 and perplexity is 40.912759173841145
At time: 425.74487805366516 and batch: 1450, loss is 3.6340796327590943 and perplexity is 37.86698532131455
At time: 427.0635929107666 and batch: 1500, loss is 3.631261706352234 and perplexity is 37.76042914766815
At time: 428.38193583488464 and batch: 1550, loss is 3.6367079257965087 and perplexity is 37.96664176097743
At time: 429.69852232933044 and batch: 1600, loss is 3.725281529426575 and perplexity is 41.48290976083944
At time: 431.01427721977234 and batch: 1650, loss is 3.6779359006881713 and perplexity is 39.564644376621075
At time: 432.3309943675995 and batch: 1700, loss is 3.691746482849121 and perplexity is 40.114845703705804
At time: 433.6506233215332 and batch: 1750, loss is 3.686618709564209 and perplexity is 39.90967236034221
At time: 434.969690322876 and batch: 1800, loss is 3.6369752883911133 and perplexity is 37.976793977928125
At time: 436.28769516944885 and batch: 1850, loss is 3.659457802772522 and perplexity is 38.84027807012601
At time: 437.604243516922 and batch: 1900, loss is 3.732410497665405 and perplexity is 41.779696742515846
At time: 438.92209100723267 and batch: 1950, loss is 3.6606988859176637 and perplexity is 38.88851200956491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.404520575944767 and perplexity of 81.81990700700122
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 442.8854269981384 and batch: 50, loss is 3.8692952823638915 and perplexity is 47.90861213777538
At time: 444.21432161331177 and batch: 100, loss is 3.870933771133423 and perplexity is 47.987174204683186
At time: 445.5309262275696 and batch: 150, loss is 3.8411120796203613 and perplexity is 46.57724325192651
At time: 446.8490905761719 and batch: 200, loss is 3.8806105279922485 and perplexity is 48.45378843691404
At time: 448.167688369751 and batch: 250, loss is 3.850362038612366 and perplexity is 47.01007961509053
At time: 449.4869918823242 and batch: 300, loss is 3.8737025117874144 and perplexity is 48.120222347680354
At time: 450.8044538497925 and batch: 350, loss is 3.8805243730545045 and perplexity is 48.44961408361095
At time: 452.1193754673004 and batch: 400, loss is 3.8515131092071533 and perplexity is 47.06422269066705
At time: 453.4365620613098 and batch: 450, loss is 3.871657485961914 and perplexity is 48.02191580422152
At time: 454.7547414302826 and batch: 500, loss is 3.8817286586761472 and perplexity is 48.50799640466488
At time: 456.0728735923767 and batch: 550, loss is 3.8479297971725464 and perplexity is 46.89587868977214
At time: 457.390745639801 and batch: 600, loss is 3.808698229789734 and perplexity is 45.09170160952238
At time: 458.7062637805939 and batch: 650, loss is 3.8322876644134523 and perplexity is 46.168034487729884
At time: 460.0223169326782 and batch: 700, loss is 3.871529669761658 and perplexity is 48.015778217664256
At time: 461.3405373096466 and batch: 750, loss is 3.8397060680389403 and perplexity is 46.51180112545838
At time: 462.6593294143677 and batch: 800, loss is 3.7999175071716307 and perplexity is 44.6974971182536
At time: 463.9768741130829 and batch: 850, loss is 3.7997876310348513 and perplexity is 44.69169235696232
At time: 465.30330443382263 and batch: 900, loss is 3.749534468650818 and perplexity is 42.50129171024818
At time: 466.61963176727295 and batch: 950, loss is 3.852974033355713 and perplexity is 47.13303019916644
At time: 467.9363293647766 and batch: 1000, loss is 3.8138385105133055 and perplexity is 45.32408235355553
At time: 469.25690269470215 and batch: 1050, loss is 3.7585209369659425 and perplexity is 42.8849495039525
At time: 470.5748724937439 and batch: 1100, loss is 3.7707630968093873 and perplexity is 43.41318065860122
At time: 471.8925869464874 and batch: 1150, loss is 3.739105715751648 and perplexity is 42.06035942430231
At time: 473.21127939224243 and batch: 1200, loss is 3.809790644645691 and perplexity is 45.140987369587904
At time: 474.53165555000305 and batch: 1250, loss is 3.7724259090423584 and perplexity is 43.48542867727034
At time: 475.8526146411896 and batch: 1300, loss is 3.773016209602356 and perplexity is 43.511105728013376
At time: 477.1743223667145 and batch: 1350, loss is 3.641089367866516 and perplexity is 38.13335535873082
At time: 478.49474334716797 and batch: 1400, loss is 3.6735937881469725 and perplexity is 39.39322267357972
At time: 479.817982673645 and batch: 1450, loss is 3.5923694133758546 and perplexity is 36.32003122223854
At time: 481.1351342201233 and batch: 1500, loss is 3.582966995239258 and perplexity is 35.98013552672826
At time: 482.4547905921936 and batch: 1550, loss is 3.583522553443909 and perplexity is 36.000130139795985
At time: 483.77620697021484 and batch: 1600, loss is 3.6659687900543214 and perplexity is 39.09399169344425
At time: 485.1045606136322 and batch: 1650, loss is 3.6113234472274782 and perplexity is 37.015007822470224
At time: 486.42442750930786 and batch: 1700, loss is 3.612768669128418 and perplexity is 37.068541397068124
At time: 487.74475359916687 and batch: 1750, loss is 3.611035051345825 and perplexity is 37.004334385816435
At time: 489.06507325172424 and batch: 1800, loss is 3.5578191328048705 and perplexity is 35.08659444249893
At time: 490.3864805698395 and batch: 1850, loss is 3.584783606529236 and perplexity is 36.045556851708554
At time: 491.7076814174652 and batch: 1900, loss is 3.6599722146987914 and perplexity is 38.8602631122162
At time: 493.0285460948944 and batch: 1950, loss is 3.5875966262817385 and perplexity is 36.147096464633194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384130007721657 and perplexity of 80.16844693509039
finished 9 epochs...
Completing Train Step...
At time: 497.0168342590332 and batch: 50, loss is 3.85954008102417 and perplexity is 47.44352617236028
At time: 498.34955763816833 and batch: 100, loss is 3.839824562072754 and perplexity is 46.51731282293885
At time: 499.66997838020325 and batch: 150, loss is 3.801046438217163 and perplexity is 44.74798600428115
At time: 500.98808336257935 and batch: 200, loss is 3.8204414224624634 and perplexity is 45.624343486514675
At time: 502.3075988292694 and batch: 250, loss is 3.798694067001343 and perplexity is 44.6428458428675
At time: 503.6359164714813 and batch: 300, loss is 3.8162996053695677 and perplexity is 45.43576659588533
At time: 504.95523285865784 and batch: 350, loss is 3.8230413436889648 and perplexity is 45.74311752025088
At time: 506.27181005477905 and batch: 400, loss is 3.797948889732361 and perplexity is 44.60959140068876
At time: 507.5877914428711 and batch: 450, loss is 3.81893217086792 and perplexity is 45.55553680971188
At time: 508.90475487709045 and batch: 500, loss is 3.831933856010437 and perplexity is 46.151702738502856
At time: 510.2225480079651 and batch: 550, loss is 3.7979403638839724 and perplexity is 44.60921106769713
At time: 511.5412755012512 and batch: 600, loss is 3.7595964288711547 and perplexity is 42.931096731035886
At time: 512.8582651615143 and batch: 650, loss is 3.785582070350647 and perplexity is 44.06130987817295
At time: 514.175240278244 and batch: 700, loss is 3.8256736898422243 and perplexity is 45.86368786150862
At time: 515.4921069145203 and batch: 750, loss is 3.7966118621826173 and perplexity is 44.54998700324324
At time: 516.8099186420441 and batch: 800, loss is 3.7575822734832762 and perplexity is 42.84471385471874
At time: 518.1279995441437 and batch: 850, loss is 3.7578283309936524 and perplexity is 42.855257415450566
At time: 519.4461472034454 and batch: 900, loss is 3.709514470100403 and perplexity is 40.83397559705335
At time: 520.7628014087677 and batch: 950, loss is 3.8139411783218384 and perplexity is 45.32873591664602
At time: 522.0768036842346 and batch: 1000, loss is 3.7759440326690674 and perplexity is 43.638685220977294
At time: 523.3948442935944 and batch: 1050, loss is 3.7241810131073 and perplexity is 41.43728225319011
At time: 524.7131662368774 and batch: 1100, loss is 3.737944235801697 and perplexity is 42.0115355196252
At time: 526.0318388938904 and batch: 1150, loss is 3.7081115865707397 and perplexity is 40.77673044876401
At time: 527.349356174469 and batch: 1200, loss is 3.7807212495803832 and perplexity is 43.84765543660365
At time: 528.6699812412262 and batch: 1250, loss is 3.746090726852417 and perplexity is 42.35517996546021
At time: 530.0040903091431 and batch: 1300, loss is 3.7491030931472777 and perplexity is 42.48296164798973
At time: 531.3385632038116 and batch: 1350, loss is 3.6170388793945314 and perplexity is 37.22717031145533
At time: 532.6571354866028 and batch: 1400, loss is 3.6513081073760985 and perplexity is 38.52502797570629
At time: 533.9757902622223 and batch: 1450, loss is 3.572908263206482 and perplexity is 35.62003509800499
At time: 535.2920982837677 and batch: 1500, loss is 3.566015863418579 and perplexity is 35.375371703179724
At time: 536.6084847450256 and batch: 1550, loss is 3.5688862943649293 and perplexity is 35.477060139852185
At time: 537.9286966323853 and batch: 1600, loss is 3.6540861988067626 and perplexity is 38.632202827631126
At time: 539.2492699623108 and batch: 1650, loss is 3.601434817314148 and perplexity is 36.65078391455506
At time: 540.567595243454 and batch: 1700, loss is 3.6061529111862183 and perplexity is 36.824114326592614
At time: 541.8835346698761 and batch: 1750, loss is 3.6066187763214113 and perplexity is 36.84127339418707
At time: 543.199376821518 and batch: 1800, loss is 3.555403504371643 and perplexity is 35.00194055467251
At time: 544.5167055130005 and batch: 1850, loss is 3.5848985290527344 and perplexity is 36.049699536102175
At time: 545.8349184989929 and batch: 1900, loss is 3.6614863538742064 and perplexity is 38.919147527311246
At time: 547.1531562805176 and batch: 1950, loss is 3.5889811182022093 and perplexity is 36.197176487330836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3863346543422965 and perplexity of 80.34538500199659
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 551.1176631450653 and batch: 50, loss is 3.8485431098937988 and perplexity is 46.92464935055117
At time: 552.4459223747253 and batch: 100, loss is 3.8476815176010133 and perplexity is 46.88423684638013
At time: 553.7631914615631 and batch: 150, loss is 3.822903804779053 and perplexity is 45.736826494371506
At time: 555.0809946060181 and batch: 200, loss is 3.8559285688400267 and perplexity is 47.27249233083115
At time: 556.3967900276184 and batch: 250, loss is 3.8394581937789916 and perplexity is 46.50027347593834
At time: 557.7135281562805 and batch: 300, loss is 3.8569497585296633 and perplexity is 47.32079116954359
At time: 559.0296928882599 and batch: 350, loss is 3.876718282699585 and perplexity is 48.26556095834788
At time: 560.3491938114166 and batch: 400, loss is 3.857680859565735 and perplexity is 47.35540009876581
At time: 561.667275428772 and batch: 450, loss is 3.8789404582977296 and perplexity is 48.37293476768489
At time: 562.983952999115 and batch: 500, loss is 3.8843679094314574 and perplexity is 48.63619026427214
At time: 564.3179788589478 and batch: 550, loss is 3.853157248497009 and perplexity is 47.141666475078196
At time: 565.6345603466034 and batch: 600, loss is 3.7946512651443483 and perplexity is 44.46272799849443
At time: 566.9526221752167 and batch: 650, loss is 3.804893274307251 and perplexity is 44.92045569042178
At time: 568.2707192897797 and batch: 700, loss is 3.847077226638794 and perplexity is 46.85591368436062
At time: 569.587815284729 and batch: 750, loss is 3.8173761892318727 and perplexity is 45.48470834919773
At time: 570.9033899307251 and batch: 800, loss is 3.7784633588790895 and perplexity is 43.74876390826394
At time: 572.2201993465424 and batch: 850, loss is 3.7842319011688232 and perplexity is 44.00185979832874
At time: 573.5376105308533 and batch: 900, loss is 3.7324927282333373 and perplexity is 41.78313245196525
At time: 574.8536553382874 and batch: 950, loss is 3.856549034118652 and perplexity is 47.301832372253735
At time: 576.1716332435608 and batch: 1000, loss is 3.818189034461975 and perplexity is 45.521695407762536
At time: 577.4877417087555 and batch: 1050, loss is 3.7573179054260253 and perplexity is 42.83338857804015
At time: 578.8045513629913 and batch: 1100, loss is 3.769754033088684 and perplexity is 43.3693960874246
At time: 580.1226150989532 and batch: 1150, loss is 3.7355472660064697 and perplexity is 41.910955729449526
At time: 581.4430024623871 and batch: 1200, loss is 3.8010814905166628 and perplexity is 44.749554551579024
At time: 582.7607035636902 and batch: 1250, loss is 3.759145727157593 and perplexity is 42.91175197185964
At time: 584.078382730484 and batch: 1300, loss is 3.751050548553467 and perplexity is 42.56577593371292
At time: 585.3942656517029 and batch: 1350, loss is 3.614757628440857 and perplexity is 37.14234258713094
At time: 586.7110877037048 and batch: 1400, loss is 3.6548746728897097 and perplexity is 38.66267533013839
At time: 588.030308008194 and batch: 1450, loss is 3.5681756067276003 and perplexity is 35.451855989002055
At time: 589.3495717048645 and batch: 1500, loss is 3.5595624351501467 and perplexity is 35.14781433176209
At time: 590.6675140857697 and batch: 1550, loss is 3.5669112825393676 and perplexity is 35.40706167319294
At time: 591.9832201004028 and batch: 1600, loss is 3.651701560020447 and perplexity is 38.54018873216121
At time: 593.2995488643646 and batch: 1650, loss is 3.593115973472595 and perplexity is 36.3471564323013
At time: 594.6178605556488 and batch: 1700, loss is 3.595767388343811 and perplexity is 36.4436556966521
At time: 595.937117099762 and batch: 1750, loss is 3.591198663711548 and perplexity is 36.27753443927872
At time: 597.2549667358398 and batch: 1800, loss is 3.535815896987915 and perplexity is 34.32300733142785
At time: 598.5778620243073 and batch: 1850, loss is 3.5649103546142578 and perplexity is 35.33628552734224
At time: 599.8939738273621 and batch: 1900, loss is 3.6479388093948364 and perplexity is 38.39544410264877
At time: 601.2106537818909 and batch: 1950, loss is 3.585796241760254 and perplexity is 36.08207633983772
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367191190497819 and perplexity of 78.82192470787376
finished 11 epochs...
Completing Train Step...
At time: 605.1689660549164 and batch: 50, loss is 3.8599727153778076 and perplexity is 47.464056312341846
At time: 606.4845054149628 and batch: 100, loss is 3.8393813037872313 and perplexity is 46.49669820774686
At time: 607.8096745014191 and batch: 150, loss is 3.804096231460571 and perplexity is 44.88466642722691
At time: 609.1281173229218 and batch: 200, loss is 3.8260839939117433 and perplexity is 45.882509780372246
At time: 610.4457223415375 and batch: 250, loss is 3.8091437149047853 and perplexity is 45.111793766447896
At time: 611.7634842395782 and batch: 300, loss is 3.824587526321411 and perplexity is 45.81389944090142
At time: 613.0802965164185 and batch: 350, loss is 3.840187530517578 and perplexity is 46.53420020423946
At time: 614.3962736129761 and batch: 400, loss is 3.822522177696228 and perplexity is 45.71937541281327
At time: 615.7136373519897 and batch: 450, loss is 3.8482596492767334 and perplexity is 46.91134994550852
At time: 617.0318896770477 and batch: 500, loss is 3.854301381111145 and perplexity is 47.195633660098174
At time: 618.3493971824646 and batch: 550, loss is 3.823318433761597 and perplexity is 45.7557942402225
At time: 619.6662323474884 and batch: 600, loss is 3.76843111038208 and perplexity is 43.31205966276004
At time: 620.982852935791 and batch: 650, loss is 3.782074017524719 and perplexity is 43.90701127760041
At time: 622.3011167049408 and batch: 700, loss is 3.8236986780166626 and perplexity is 45.77319592635424
At time: 623.6265180110931 and batch: 750, loss is 3.7971273851394653 and perplexity is 44.572959465177675
At time: 624.9475722312927 and batch: 800, loss is 3.758708109855652 and perplexity is 42.8929771551321
At time: 626.2663097381592 and batch: 850, loss is 3.763370680809021 and perplexity is 43.09343566738076
At time: 627.5816009044647 and batch: 900, loss is 3.7148458194732665 and perplexity is 41.052257137798925
At time: 628.9288280010223 and batch: 950, loss is 3.838717336654663 and perplexity is 46.46583617518541
At time: 630.2490906715393 and batch: 1000, loss is 3.8002775621414187 and perplexity is 44.713593571858276
At time: 631.5666923522949 and batch: 1050, loss is 3.7406312656402587 and perplexity is 42.124573569424136
At time: 632.8831284046173 and batch: 1100, loss is 3.752581696510315 and perplexity is 42.631000355943144
At time: 634.2031726837158 and batch: 1150, loss is 3.719888029098511 and perplexity is 41.25977395586921
At time: 635.5245559215546 and batch: 1200, loss is 3.785425329208374 and perplexity is 44.05440419934874
At time: 636.8419661521912 and batch: 1250, loss is 3.745377197265625 and perplexity is 42.32496907086629
At time: 638.1605272293091 and batch: 1300, loss is 3.7392216539382934 and perplexity is 42.06523610879513
At time: 639.4782793521881 and batch: 1350, loss is 3.603785924911499 and perplexity is 36.73705522789535
At time: 640.7954223155975 and batch: 1400, loss is 3.6452908611297605 and perplexity is 38.29390944164202
At time: 642.1124262809753 and batch: 1450, loss is 3.562100920677185 and perplexity is 35.23714989028898
At time: 643.4301335811615 and batch: 1500, loss is 3.556263427734375 and perplexity is 35.032052486217566
At time: 644.7475311756134 and batch: 1550, loss is 3.564532604217529 and perplexity is 35.32293975230998
At time: 646.0662317276001 and batch: 1600, loss is 3.651044292449951 and perplexity is 38.51486583881669
At time: 647.383410692215 and batch: 1650, loss is 3.593566379547119 and perplexity is 36.36353109969809
At time: 648.6988952159882 and batch: 1700, loss is 3.5979541397094725 and perplexity is 36.52343610868724
At time: 650.0170729160309 and batch: 1750, loss is 3.596057891845703 and perplexity is 36.45424424418434
At time: 651.3363394737244 and batch: 1800, loss is 3.5410091733932494 and perplexity is 34.50171984564601
At time: 652.6532428264618 and batch: 1850, loss is 3.571897039413452 and perplexity is 35.5840334769211
At time: 653.9698050022125 and batch: 1900, loss is 3.655681643486023 and perplexity is 38.693887564288445
At time: 655.288542509079 and batch: 1950, loss is 3.5930572319030762 and perplexity is 36.34502140599293
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366139398619186 and perplexity of 78.73906403133994
finished 12 epochs...
Completing Train Step...
At time: 659.260835647583 and batch: 50, loss is 3.8547146558761596 and perplexity is 47.21514245547752
At time: 660.5791854858398 and batch: 100, loss is 3.8309680318832395 and perplexity is 46.10714982908749
At time: 661.9082894325256 and batch: 150, loss is 3.7940957498550416 and perplexity is 44.438035132554276
At time: 663.2339019775391 and batch: 200, loss is 3.813434715270996 and perplexity is 45.305784399301196
At time: 664.5558462142944 and batch: 250, loss is 3.796677894592285 and perplexity is 44.552928843363055
At time: 665.8775691986084 and batch: 300, loss is 3.811310601234436 and perplexity is 45.20965188108165
At time: 667.195794582367 and batch: 350, loss is 3.8267472553253175 and perplexity is 45.9129519731174
At time: 668.5109970569611 and batch: 400, loss is 3.808764672279358 and perplexity is 45.09469771397192
At time: 669.8281972408295 and batch: 450, loss is 3.835333938598633 and perplexity is 46.308889411804635
At time: 671.1463029384613 and batch: 500, loss is 3.841412973403931 and perplexity is 46.59126016357186
At time: 672.4649958610535 and batch: 550, loss is 3.809479789733887 and perplexity is 45.12695725271872
At time: 673.7835824489594 and batch: 600, loss is 3.756162052154541 and perplexity is 42.783908067337364
At time: 675.1008927822113 and batch: 650, loss is 3.770759091377258 and perplexity is 43.41300677040083
At time: 676.416996717453 and batch: 700, loss is 3.8123374652862547 and perplexity is 45.25609989120807
At time: 677.7415618896484 and batch: 750, loss is 3.786908965110779 and perplexity is 44.11981340480263
At time: 679.0596168041229 and batch: 800, loss is 3.7483878564834594 and perplexity is 42.45258714000725
At time: 680.3783388137817 and batch: 850, loss is 3.7527990627288816 and perplexity is 42.64026790247351
At time: 681.696647644043 and batch: 900, loss is 3.705203676223755 and perplexity is 40.65832760823234
At time: 683.011093378067 and batch: 950, loss is 3.8291890382766725 and perplexity is 46.02519842145307
At time: 684.3282132148743 and batch: 1000, loss is 3.7908478307724 and perplexity is 44.29393812463604
At time: 685.6455173492432 and batch: 1050, loss is 3.7319522380828856 and perplexity is 41.760555182365486
At time: 686.9615685939789 and batch: 1100, loss is 3.7438270616531373 and perplexity is 42.259410454512725
At time: 688.2818367481232 and batch: 1150, loss is 3.7120383882522585 and perplexity is 40.937167378301055
At time: 689.5998203754425 and batch: 1200, loss is 3.777629337310791 and perplexity is 43.71229170699345
At time: 690.9155504703522 and batch: 1250, loss is 3.738228693008423 and perplexity is 42.02348770353121
At time: 692.2341148853302 and batch: 1300, loss is 3.733075165748596 and perplexity is 41.80747560430471
At time: 693.5513098239899 and batch: 1350, loss is 3.597966237068176 and perplexity is 36.52387794846748
At time: 694.87051653862 and batch: 1400, loss is 3.6397410821914673 and perplexity is 38.081975347209394
At time: 696.1867821216583 and batch: 1450, loss is 3.55781662940979 and perplexity is 35.08650660700095
At time: 697.5018799304962 and batch: 1500, loss is 3.5530642604827882 and perplexity is 34.920158170895846
At time: 698.818247795105 and batch: 1550, loss is 3.5619234228134156 and perplexity is 35.23089592650715
At time: 700.1367518901825 and batch: 1600, loss is 3.6493362617492675 and perplexity is 38.44913741459402
At time: 701.454044342041 and batch: 1650, loss is 3.5922856092453004 and perplexity is 36.316987581136885
At time: 702.7712960243225 and batch: 1700, loss is 3.5972326040267943 and perplexity is 36.49709265129596
At time: 704.0882234573364 and batch: 1750, loss is 3.596296944618225 and perplexity is 36.46295977403539
At time: 705.4061644077301 and batch: 1800, loss is 3.5414279985427854 and perplexity is 34.51617306009319
At time: 706.7242438793182 and batch: 1850, loss is 3.5727523279190065 and perplexity is 35.614481110634664
At time: 708.0426664352417 and batch: 1900, loss is 3.6568645906448363 and perplexity is 38.73968747274095
At time: 709.3612906932831 and batch: 1950, loss is 3.5940152311325075 and perplexity is 36.379856591869945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366493970294331 and perplexity of 78.76698762333774
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 713.3435747623444 and batch: 50, loss is 3.8527566385269165 and perplexity is 47.12278483582049
At time: 714.6621451377869 and batch: 100, loss is 3.8354059839248658 and perplexity is 46.312225871036496
At time: 715.9803845882416 and batch: 150, loss is 3.802786707878113 and perplexity is 44.82592736653635
At time: 717.2979071140289 and batch: 200, loss is 3.826039237976074 and perplexity is 45.88045631166897
At time: 718.6164226531982 and batch: 250, loss is 3.8119458818435668 and perplexity is 45.23838182108789
At time: 719.9370410442352 and batch: 300, loss is 3.8273541069030763 and perplexity is 45.940822776326975
At time: 721.2569391727448 and batch: 350, loss is 3.85059410572052 and perplexity is 47.02099037428611
At time: 722.5750784873962 and batch: 400, loss is 3.8387562608718873 and perplexity is 46.46764485668672
At time: 723.8929824829102 and batch: 450, loss is 3.8691467809677125 and perplexity is 47.901498170214055
At time: 725.2093312740326 and batch: 500, loss is 3.878949294090271 and perplexity is 48.37336218278938
At time: 726.5259501934052 and batch: 550, loss is 3.854864602088928 and perplexity is 47.22222271809006
At time: 727.8527524471283 and batch: 600, loss is 3.7963899755477906 and perplexity is 44.54010305314428
At time: 729.1706509590149 and batch: 650, loss is 3.8024974966049196 and perplexity is 44.812965077521014
At time: 730.4888353347778 and batch: 700, loss is 3.835436773300171 and perplexity is 46.31365181749195
At time: 731.8041911125183 and batch: 750, loss is 3.8043159198760987 and perplexity is 44.89452815168945
At time: 733.1202478408813 and batch: 800, loss is 3.7543546104431154 and perplexity is 42.70664848944343
At time: 734.4373462200165 and batch: 850, loss is 3.759699273109436 and perplexity is 42.935512174025305
At time: 735.7553322315216 and batch: 900, loss is 3.705216989517212 and perplexity is 40.65886890808249
At time: 737.073667049408 and batch: 950, loss is 3.834371166229248 and perplexity is 46.2643259483
At time: 738.4009799957275 and batch: 1000, loss is 3.805036072731018 and perplexity is 44.92687071870633
At time: 739.7161388397217 and batch: 1050, loss is 3.749449682235718 and perplexity is 42.49768833084792
At time: 741.0330891609192 and batch: 1100, loss is 3.761495099067688 and perplexity is 43.01268615609797
At time: 742.3515930175781 and batch: 1150, loss is 3.7315253162384034 and perplexity is 41.74273049426552
At time: 743.6692023277283 and batch: 1200, loss is 3.798549518585205 and perplexity is 44.63639325657582
At time: 744.9843633174896 and batch: 1250, loss is 3.7571789407730103 and perplexity is 42.82743666462132
At time: 746.2998652458191 and batch: 1300, loss is 3.743660707473755 and perplexity is 42.25238100967036
At time: 747.6155261993408 and batch: 1350, loss is 3.6049316930770874 and perplexity is 36.779171499407035
At time: 748.9330153465271 and batch: 1400, loss is 3.6396069860458375 and perplexity is 38.07686904347285
At time: 750.2517900466919 and batch: 1450, loss is 3.552536492347717 and perplexity is 34.901733286602685
At time: 751.5683908462524 and batch: 1500, loss is 3.5426367235183718 and perplexity is 34.557918845036426
At time: 752.8854856491089 and batch: 1550, loss is 3.5573695516586303 and perplexity is 35.07082371652797
At time: 754.2039034366608 and batch: 1600, loss is 3.645714831352234 and perplexity is 38.31014836111328
At time: 755.5208942890167 and batch: 1650, loss is 3.5854615545272828 and perplexity is 36.07000215019896
At time: 756.8477249145508 and batch: 1700, loss is 3.5908575439453125 and perplexity is 36.265161565647055
At time: 758.1667652130127 and batch: 1750, loss is 3.586889362335205 and perplexity is 36.12153996519255
At time: 759.4835872650146 and batch: 1800, loss is 3.5354817962646483 and perplexity is 34.31154190526397
At time: 760.8013670444489 and batch: 1850, loss is 3.561342692375183 and perplexity is 35.210442212498414
At time: 762.1190407276154 and batch: 1900, loss is 3.644292778968811 and perplexity is 38.255708040994804
At time: 763.4369993209839 and batch: 1950, loss is 3.5881395149230957 and perplexity is 36.16672564046808
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357809093386628 and perplexity of 78.08586803257455
finished 14 epochs...
Completing Train Step...
At time: 767.4061169624329 and batch: 50, loss is 3.8550271511077883 and perplexity is 47.229899267952206
At time: 768.7324404716492 and batch: 100, loss is 3.8328284502029417 and perplexity is 46.1930082568306
At time: 770.0519924163818 and batch: 150, loss is 3.7974090242385863 and perplexity is 44.58551472126912
At time: 771.3715670108795 and batch: 200, loss is 3.8168503284454345 and perplexity is 45.460796012525435
At time: 772.6892967224121 and batch: 250, loss is 3.8021862077713013 and perplexity is 44.799017472870474
At time: 774.0048711299896 and batch: 300, loss is 3.815764193534851 and perplexity is 45.41144626000928
At time: 775.322457075119 and batch: 350, loss is 3.835547456741333 and perplexity is 46.318778255548544
At time: 776.6414668560028 and batch: 400, loss is 3.8227901077270507 and perplexity is 45.73162664764039
At time: 777.960611820221 and batch: 450, loss is 3.8536968278884887 and perplexity is 47.16711001057453
At time: 779.2846419811249 and batch: 500, loss is 3.862731099128723 and perplexity is 47.59516112959726
At time: 780.6025912761688 and batch: 550, loss is 3.8389565086364748 and perplexity is 46.47695083041404
At time: 781.9177162647247 and batch: 600, loss is 3.7813080406188964 and perplexity is 43.8733923982444
At time: 783.2326884269714 and batch: 650, loss is 3.7880285358428956 and perplexity is 44.16923631765808
At time: 784.5497059822083 and batch: 700, loss is 3.823242635726929 and perplexity is 45.752326172382446
At time: 785.8665492534637 and batch: 750, loss is 3.7939264440536498 and perplexity is 44.43051215226396
At time: 787.1844754219055 and batch: 800, loss is 3.745192036628723 and perplexity is 42.31713287813587
At time: 788.4992079734802 and batch: 850, loss is 3.750369095802307 and perplexity is 42.53677924965482
At time: 789.8146300315857 and batch: 900, loss is 3.6976039886474608 and perplexity is 40.350508168336056
At time: 791.1305799484253 and batch: 950, loss is 3.8255042886734008 and perplexity is 45.85591915721069
At time: 792.4782860279083 and batch: 1000, loss is 3.7958952713012697 and perplexity is 44.51807432432552
At time: 793.7959532737732 and batch: 1050, loss is 3.740176000595093 and perplexity is 42.10540008837449
At time: 795.1112713813782 and batch: 1100, loss is 3.7536191177368163 and perplexity is 42.6752496092081
At time: 796.4270174503326 and batch: 1150, loss is 3.724476490020752 and perplexity is 41.44952782250455
At time: 797.7424604892731 and batch: 1200, loss is 3.7912156438827513 and perplexity is 44.310233012340326
At time: 799.0598833560944 and batch: 1250, loss is 3.7500103187561034 and perplexity is 42.52152076700095
At time: 800.3780374526978 and batch: 1300, loss is 3.7380030584335326 and perplexity is 42.01400682139544
At time: 801.6944446563721 and batch: 1350, loss is 3.599982500076294 and perplexity is 36.59759398297147
At time: 803.010678768158 and batch: 1400, loss is 3.636924066543579 and perplexity is 37.974848786195736
At time: 804.3295102119446 and batch: 1450, loss is 3.551590313911438 and perplexity is 34.86872563720371
At time: 805.648092508316 and batch: 1500, loss is 3.5433325719833375 and perplexity is 34.58197428831814
At time: 806.9713132381439 and batch: 1550, loss is 3.558923168182373 and perplexity is 35.125352675332785
At time: 808.2906014919281 and batch: 1600, loss is 3.648388271331787 and perplexity is 38.41270527215398
At time: 809.6062850952148 and batch: 1650, loss is 3.5887389278411863 and perplexity is 36.18841094159754
At time: 810.920690536499 and batch: 1700, loss is 3.595290379524231 and perplexity is 36.42627589695548
At time: 812.2376034259796 and batch: 1750, loss is 3.592454137802124 and perplexity is 36.32310854640635
At time: 813.555995464325 and batch: 1800, loss is 3.5415176486968996 and perplexity is 34.51926757903743
At time: 814.8735580444336 and batch: 1850, loss is 3.5677028036117555 and perplexity is 35.43509820290689
At time: 816.188894033432 and batch: 1900, loss is 3.650159878730774 and perplexity is 38.48081782156268
At time: 817.5052690505981 and batch: 1950, loss is 3.593400726318359 and perplexity is 36.35750786226045
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35606320403343 and perplexity of 77.94965768563742
finished 15 epochs...
Completing Train Step...
At time: 821.4892065525055 and batch: 50, loss is 3.854692807197571 and perplexity is 47.21411087827484
At time: 822.8153190612793 and batch: 100, loss is 3.830523190498352 and perplexity is 46.08664402195828
At time: 824.13094830513 and batch: 150, loss is 3.7939794778823854 and perplexity is 44.43286853491952
At time: 825.4577872753143 and batch: 200, loss is 3.811671199798584 and perplexity is 45.22595735632438
At time: 826.7754988670349 and batch: 250, loss is 3.796793065071106 and perplexity is 44.558060321002515
At time: 828.091813325882 and batch: 300, loss is 3.8097433376312257 and perplexity is 45.13885193475635
At time: 829.4163072109222 and batch: 350, loss is 3.8286282444000244 and perplexity is 45.99939500788121
At time: 830.7353620529175 and batch: 400, loss is 3.8152486276626587 and perplexity is 45.38803970244033
At time: 832.0557925701141 and batch: 450, loss is 3.8464978075027467 and perplexity is 46.8287723352028
At time: 833.3745405673981 and batch: 500, loss is 3.8553707122802736 and perplexity is 47.24612841521387
At time: 834.6925709247589 and batch: 550, loss is 3.831239728927612 and perplexity is 46.119678707373026
At time: 836.011221408844 and batch: 600, loss is 3.774492664337158 and perplexity is 43.575395354765035
At time: 837.3268146514893 and batch: 650, loss is 3.781786675453186 and perplexity is 43.894396758452906
At time: 838.6417849063873 and batch: 700, loss is 3.817478666305542 and perplexity is 45.48936972784419
At time: 839.9787044525146 and batch: 750, loss is 3.7889869022369385 and perplexity is 44.21158691985095
At time: 841.300537109375 and batch: 800, loss is 3.7408622550964354 and perplexity is 42.13430502565324
At time: 842.6249554157257 and batch: 850, loss is 3.7459112882614134 and perplexity is 42.34758049348517
At time: 843.9439761638641 and batch: 900, loss is 3.693788800239563 and perplexity is 40.19685666840504
At time: 845.2605917453766 and batch: 950, loss is 3.8213660430908205 and perplexity is 45.66654820432709
At time: 846.5777220726013 and batch: 1000, loss is 3.7916504526138306 and perplexity is 44.32950367775343
At time: 847.8956978321075 and batch: 1050, loss is 3.7361968183517456 and perplexity is 41.93818793244952
At time: 849.2144434452057 and batch: 1100, loss is 3.7499843883514403 and perplexity is 42.52041818105589
At time: 850.5317265987396 and batch: 1150, loss is 3.7212407398223877 and perplexity is 41.31562426070082
At time: 851.8477516174316 and batch: 1200, loss is 3.787895193099976 and perplexity is 44.16334706318821
At time: 853.1669960021973 and batch: 1250, loss is 3.7469294357299803 and perplexity is 42.39071853208044
At time: 854.4858727455139 and batch: 1300, loss is 3.7354975509643555 and perplexity is 41.90887217631279
At time: 855.804135799408 and batch: 1350, loss is 3.5978054666519164 and perplexity is 36.51800646139964
At time: 857.1222405433655 and batch: 1400, loss is 3.635702061653137 and perplexity is 37.92847167756321
At time: 858.4382770061493 and batch: 1450, loss is 3.5509925794601442 and perplexity is 34.847889626438736
At time: 859.7540628910065 and batch: 1500, loss is 3.5435067892074583 and perplexity is 34.58799958872359
At time: 861.0722277164459 and batch: 1550, loss is 3.5594272804260254 and perplexity is 35.14306425961719
At time: 862.3898112773895 and batch: 1600, loss is 3.6493574476242063 and perplexity is 38.449952001839634
At time: 863.7081003189087 and batch: 1650, loss is 3.589955325126648 and perplexity is 36.23245720988167
At time: 865.023761510849 and batch: 1700, loss is 3.596844973564148 and perplexity is 36.48294800801071
At time: 866.3398435115814 and batch: 1750, loss is 3.59454035282135 and perplexity is 36.39896546040487
At time: 867.656396150589 and batch: 1800, loss is 3.5436637878417967 and perplexity is 34.59343028371821
At time: 868.9741566181183 and batch: 1850, loss is 3.5702283668518064 and perplexity is 35.52470489038427
At time: 870.2922194004059 and batch: 1900, loss is 3.652464566230774 and perplexity is 38.56960635699905
At time: 871.6074163913727 and batch: 1950, loss is 3.59538938999176 and perplexity is 36.429882658112994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355473859920058 and perplexity of 77.90373204807234
finished 16 epochs...
Completing Train Step...
At time: 875.563467502594 and batch: 50, loss is 3.8532487630844114 and perplexity is 47.14598082264497
At time: 876.8930494785309 and batch: 100, loss is 3.8279667901992798 and perplexity is 45.96897857546902
At time: 878.2081925868988 and batch: 150, loss is 3.7909138107299807 and perplexity is 44.296860733210316
At time: 879.5238852500916 and batch: 200, loss is 3.807732729911804 and perplexity is 45.04818658737737
At time: 880.8399150371552 and batch: 250, loss is 3.7926637268066408 and perplexity is 44.37444438459426
At time: 882.1578326225281 and batch: 300, loss is 3.805285682678223 and perplexity is 44.938086312238134
At time: 883.4769058227539 and batch: 350, loss is 3.8239113664627076 and perplexity is 45.782932391646455
At time: 884.7943186759949 and batch: 400, loss is 3.8102355766296387 and perplexity is 45.161076507474185
At time: 886.1098749637604 and batch: 450, loss is 3.8417410326004027 and perplexity is 46.606547362359706
At time: 887.4255020618439 and batch: 500, loss is 3.8506172132492065 and perplexity is 47.02207692572376
At time: 888.7416138648987 and batch: 550, loss is 3.826159462928772 and perplexity is 45.88597261895104
At time: 890.060959815979 and batch: 600, loss is 3.770177974700928 and perplexity is 43.38778607698942
At time: 891.4077634811401 and batch: 650, loss is 3.777851257324219 and perplexity is 43.72199341581789
At time: 892.7233731746674 and batch: 700, loss is 3.813702163696289 and perplexity is 45.31790298047094
At time: 894.0405893325806 and batch: 750, loss is 3.785660185813904 and perplexity is 44.06475188224091
At time: 895.3558988571167 and batch: 800, loss is 3.7378205680847167 and perplexity is 42.0063403701834
At time: 896.6736109256744 and batch: 850, loss is 3.7427879333496095 and perplexity is 42.21552031271267
At time: 897.9922263622284 and batch: 900, loss is 3.6909979295730593 and perplexity is 40.084828840547836
At time: 899.3144464492798 and batch: 950, loss is 3.8185003709793093 and perplexity is 45.53587018032161
At time: 900.6290509700775 and batch: 1000, loss is 3.7888008975982665 and perplexity is 44.203364124363574
At time: 901.9445514678955 and batch: 1050, loss is 3.733588361740112 and perplexity is 41.82893653956221
At time: 903.2632446289062 and batch: 1100, loss is 3.7474633502960204 and perplexity is 42.41335759729517
At time: 904.5810322761536 and batch: 1150, loss is 3.7189551115036013 and perplexity is 41.221299936119216
At time: 905.899796962738 and batch: 1200, loss is 3.785535888671875 and perplexity is 44.05927509989899
At time: 907.2156965732574 and batch: 1250, loss is 3.7448018646240233 and perplexity is 42.30062513820607
At time: 908.5307621955872 and batch: 1300, loss is 3.733690090179443 and perplexity is 41.833191948439634
At time: 909.8549835681915 and batch: 1350, loss is 3.596194319725037 and perplexity is 36.45921795868823
At time: 911.1762185096741 and batch: 1400, loss is 3.6345494604110717 and perplexity is 37.88478045811186
At time: 912.49427485466 and batch: 1450, loss is 3.5501429271697997 and perplexity is 34.81829361214509
At time: 913.8105719089508 and batch: 1500, loss is 3.543123512268066 and perplexity is 34.57474534628652
At time: 915.1265759468079 and batch: 1550, loss is 3.55925639629364 and perplexity is 35.13705938065571
At time: 916.4435482025146 and batch: 1600, loss is 3.6494557762146 and perplexity is 38.45373291730367
At time: 917.7606492042542 and batch: 1650, loss is 3.5902217292785643 and perplexity is 36.24211097276068
At time: 919.0779137611389 and batch: 1700, loss is 3.5972337532043457 and perplexity is 36.497134592959625
At time: 920.3956007957458 and batch: 1750, loss is 3.5952575063705443 and perplexity is 36.42507847007139
At time: 921.7107765674591 and batch: 1800, loss is 3.5443409872055054 and perplexity is 34.61686486674161
At time: 923.0267374515533 and batch: 1850, loss is 3.571263575553894 and perplexity is 35.56149941574638
At time: 924.3454160690308 and batch: 1900, loss is 3.653385806083679 and perplexity is 38.60515458719506
At time: 925.662871837616 and batch: 1950, loss is 3.5961018943786622 and perplexity is 36.45584835856048
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355273721384448 and perplexity of 77.88814206935149
finished 17 epochs...
Completing Train Step...
At time: 929.6324799060822 and batch: 50, loss is 3.851476078033447 and perplexity is 47.06247987953062
At time: 930.9492211341858 and batch: 100, loss is 3.8254866409301758 and perplexity is 45.85510991086477
At time: 932.266518831253 and batch: 150, loss is 3.7881639575958252 and perplexity is 44.17521819809501
At time: 933.5833053588867 and batch: 200, loss is 3.804462947845459 and perplexity is 44.90112938827029
At time: 934.9006910324097 and batch: 250, loss is 3.789265546798706 and perplexity is 44.22390795462824
At time: 936.2174737453461 and batch: 300, loss is 3.8016660451889037 and perplexity is 44.775720759817396
At time: 937.5339004993439 and batch: 350, loss is 3.8202179479599 and perplexity is 45.6141487482237
At time: 938.8493251800537 and batch: 400, loss is 3.806379141807556 and perplexity is 44.98725114794156
At time: 940.165468454361 and batch: 450, loss is 3.838089623451233 and perplexity is 46.43667810871889
At time: 941.4818186759949 and batch: 500, loss is 3.846974186897278 and perplexity is 46.85108591185657
At time: 942.7958793640137 and batch: 550, loss is 3.8222587871551514 and perplexity is 45.70733494752754
At time: 944.1110084056854 and batch: 600, loss is 3.766884059906006 and perplexity is 43.24510552430872
At time: 945.4272971153259 and batch: 650, loss is 3.7748199605941775 and perplexity is 43.58965975277749
At time: 946.7428591251373 and batch: 700, loss is 3.8107415342330935 and perplexity is 45.18393187895026
At time: 948.0586066246033 and batch: 750, loss is 3.7829660320281984 and perplexity is 43.94619444184171
At time: 949.373556137085 and batch: 800, loss is 3.73527937412262 and perplexity is 41.899729628323044
At time: 950.6890435218811 and batch: 850, loss is 3.740198402404785 and perplexity is 42.106343336099464
At time: 952.0052063465118 and batch: 900, loss is 3.6886093997955323 and perplexity is 39.989199285719245
At time: 953.3214166164398 and batch: 950, loss is 3.8160952043533327 and perplexity is 45.42648042810312
At time: 954.6381134986877 and batch: 1000, loss is 3.7864466381072996 and perplexity is 44.09942033817307
At time: 955.9813487529755 and batch: 1050, loss is 3.731446738243103 and perplexity is 41.73945056305182
At time: 957.2960708141327 and batch: 1100, loss is 3.7453352546691896 and perplexity is 42.32319388899753
At time: 958.6175918579102 and batch: 1150, loss is 3.716992611885071 and perplexity is 41.140482478772256
At time: 959.9356851577759 and batch: 1200, loss is 3.7835171890258787 and perplexity is 43.97042237051265
At time: 961.2613179683685 and batch: 1250, loss is 3.742969012260437 and perplexity is 42.223165345307116
At time: 962.5778079032898 and batch: 1300, loss is 3.7321038103103636 and perplexity is 41.76688540246586
At time: 963.8920619487762 and batch: 1350, loss is 3.5947408437728883 and perplexity is 36.40626385523164
At time: 965.2096843719482 and batch: 1400, loss is 3.633354620933533 and perplexity is 37.83954125899525
At time: 966.528115272522 and batch: 1450, loss is 3.5491496467590333 and perplexity is 34.78372645344665
At time: 967.844309091568 and batch: 1500, loss is 3.542456560134888 and perplexity is 34.55169333427252
At time: 969.1618587970734 and batch: 1550, loss is 3.558756194114685 and perplexity is 35.119488141943734
At time: 970.4780645370483 and batch: 1600, loss is 3.649160137176514 and perplexity is 38.442366173002654
At time: 971.7942726612091 and batch: 1650, loss is 3.590050754547119 and perplexity is 36.235915017261114
At time: 973.1119639873505 and batch: 1700, loss is 3.597120137214661 and perplexity is 36.492988170446594
At time: 974.4302423000336 and batch: 1750, loss is 3.5953856611251833 and perplexity is 36.42974681619442
At time: 975.746913433075 and batch: 1800, loss is 3.5444100999832155 and perplexity is 34.61925741710512
At time: 977.0631363391876 and batch: 1850, loss is 3.571636095046997 and perplexity is 35.574749235237526
At time: 978.380184173584 and batch: 1900, loss is 3.653694438934326 and perplexity is 38.61707124494641
At time: 979.6952884197235 and batch: 1950, loss is 3.596246433258057 and perplexity is 36.461118026856404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355247036246366 and perplexity of 77.88606364125715
finished 18 epochs...
Completing Train Step...
At time: 983.6621232032776 and batch: 50, loss is 3.8496218013763426 and perplexity is 46.97529388012759
At time: 984.9770023822784 and batch: 100, loss is 3.823144669532776 and perplexity is 45.74784421065765
At time: 986.29287981987 and batch: 150, loss is 3.7856599473953247 and perplexity is 44.064741376386635
At time: 987.610185623169 and batch: 200, loss is 3.80159460067749 and perplexity is 44.772521894596565
At time: 988.9372935295105 and batch: 250, loss is 3.786324143409729 and perplexity is 44.09401872385701
At time: 990.253648519516 and batch: 300, loss is 3.7985484743118287 and perplexity is 44.636346644003076
At time: 991.5685827732086 and batch: 350, loss is 3.8170852184295656 and perplexity is 45.471475552388775
At time: 992.8835227489471 and batch: 400, loss is 3.803142056465149 and perplexity is 44.84185902696749
At time: 994.2013068199158 and batch: 450, loss is 3.8350193023681642 and perplexity is 46.29432124935896
At time: 995.5193226337433 and batch: 500, loss is 3.843898720741272 and perplexity is 46.7072183261055
At time: 996.8368742465973 and batch: 550, loss is 3.8189760398864747 and perplexity is 45.557535330237705
At time: 998.1524040699005 and batch: 600, loss is 3.7640903186798096 and perplexity is 43.12445849693207
At time: 999.4683711528778 and batch: 650, loss is 3.772222304344177 and perplexity is 43.476575740969515
At time: 1000.7856407165527 and batch: 700, loss is 3.8081915473937986 and perplexity is 45.068860225266384
At time: 1002.1042671203613 and batch: 750, loss is 3.780589156150818 and perplexity is 43.84186383194352
At time: 1003.4224088191986 and batch: 800, loss is 3.7329960441589356 and perplexity is 41.80416786123388
At time: 1004.7379169464111 and batch: 850, loss is 3.737890944480896 and perplexity is 42.00929672906305
At time: 1006.0539884567261 and batch: 900, loss is 3.6864348220825196 and perplexity is 39.90233414592039
At time: 1007.3696939945221 and batch: 950, loss is 3.8139165258407592 and perplexity is 45.327618464615526
At time: 1008.6880972385406 and batch: 1000, loss is 3.7843303155899046 and perplexity is 44.00619042898205
At time: 1010.0077407360077 and batch: 1050, loss is 3.729520206451416 and perplexity is 41.659115593358194
At time: 1011.3247270584106 and batch: 1100, loss is 3.7434002017974852 and perplexity is 42.241375458147985
At time: 1012.6397089958191 and batch: 1150, loss is 3.715188798904419 and perplexity is 41.066339632464526
At time: 1013.9543800354004 and batch: 1200, loss is 3.781673927307129 and perplexity is 43.88944802558156
At time: 1015.2708704471588 and batch: 1250, loss is 3.7412713241577147 and perplexity is 42.15154439206305
At time: 1016.5853044986725 and batch: 1300, loss is 3.7306219387054442 and perplexity is 41.705038077177385
At time: 1017.9012861251831 and batch: 1350, loss is 3.593354434967041 and perplexity is 36.355824863045406
At time: 1019.2243139743805 and batch: 1400, loss is 3.6321401262283324 and perplexity is 37.793613231807214
At time: 1020.5393433570862 and batch: 1450, loss is 3.548092427253723 and perplexity is 34.74697185163708
At time: 1021.854964017868 and batch: 1500, loss is 3.541650986671448 and perplexity is 34.523870615132246
At time: 1023.1709976196289 and batch: 1550, loss is 3.5580874919891357 and perplexity is 35.09601151588471
At time: 1024.4886693954468 and batch: 1600, loss is 3.6486661005020142 and perplexity is 38.4233789248433
At time: 1025.8113083839417 and batch: 1650, loss is 3.589653196334839 and perplexity is 36.221511994876124
At time: 1027.1271390914917 and batch: 1700, loss is 3.596756114959717 and perplexity is 36.4797063281929
At time: 1028.4415600299835 and batch: 1750, loss is 3.5952204132080077 and perplexity is 36.423727373773666
At time: 1029.7677268981934 and batch: 1800, loss is 3.544184002876282 and perplexity is 34.611430987958755
At time: 1031.0830612182617 and batch: 1850, loss is 3.571667819023132 and perplexity is 35.57587782563486
At time: 1032.3991045951843 and batch: 1900, loss is 3.6536895418167115 and perplexity is 38.616882133069645
At time: 1033.713139295578 and batch: 1950, loss is 3.596103162765503 and perplexity is 36.455894598708134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3553194267805235 and perplexity of 77.89170205908913
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 1037.6779124736786 and batch: 50, loss is 3.849052109718323 and perplexity is 46.948540068506276
At time: 1038.9942660331726 and batch: 100, loss is 3.8243161153793337 and perplexity is 45.80146673455652
At time: 1040.3099117279053 and batch: 150, loss is 3.7881522750854493 and perplexity is 44.17470212366458
At time: 1041.6250340938568 and batch: 200, loss is 3.8048971033096315 and perplexity is 44.92062769128285
At time: 1042.9423151016235 and batch: 250, loss is 3.790402364730835 and perplexity is 44.27421107354624
At time: 1044.268725156784 and batch: 300, loss is 3.8026606893539427 and perplexity is 44.82027882524295
At time: 1045.5867998600006 and batch: 350, loss is 3.822999982833862 and perplexity is 45.74122558492148
At time: 1046.9029958248138 and batch: 400, loss is 3.8112389039993286 and perplexity is 45.20641059023878
At time: 1048.218890428543 and batch: 450, loss is 3.8444801902770998 and perplexity is 46.7343850482106
At time: 1049.5335268974304 and batch: 500, loss is 3.8552948141098025 and perplexity is 47.24254265658329
At time: 1050.8527081012726 and batch: 550, loss is 3.833525881767273 and perplexity is 46.22523595584126
At time: 1052.1702954769135 and batch: 600, loss is 3.7783679580688476 and perplexity is 43.74459043981931
At time: 1053.4957344532013 and batch: 650, loss is 3.7862076234817503 and perplexity is 44.088881191289296
At time: 1054.8431253433228 and batch: 700, loss is 3.8193592643737793 and perplexity is 45.57499743909764
At time: 1056.160682439804 and batch: 750, loss is 3.7884146070480345 and perplexity is 44.18629208011084
At time: 1057.4758009910583 and batch: 800, loss is 3.7367712450027466 and perplexity is 41.962285265705226
At time: 1058.7954518795013 and batch: 850, loss is 3.7414130353927613 and perplexity is 42.15751816274319
At time: 1060.1150481700897 and batch: 900, loss is 3.686964440345764 and perplexity is 39.92347274803091
At time: 1061.4375743865967 and batch: 950, loss is 3.812776494026184 and perplexity is 45.27597298182718
At time: 1062.766474723816 and batch: 1000, loss is 3.785320291519165 and perplexity is 44.049777069547915
At time: 1064.0923821926117 and batch: 1050, loss is 3.731180634498596 and perplexity is 41.7283450166426
At time: 1065.4159002304077 and batch: 1100, loss is 3.7431422090530395 and perplexity is 42.23047889544188
At time: 1066.7429068088531 and batch: 1150, loss is 3.7159326601028444 and perplexity is 41.09689865350438
At time: 1068.072695016861 and batch: 1200, loss is 3.783106961250305 and perplexity is 43.95238818126815
At time: 1069.388240814209 and batch: 1250, loss is 3.744239640235901 and perplexity is 42.27684937940256
At time: 1070.7037253379822 and batch: 1300, loss is 3.7314134073257446 and perplexity is 41.738059372059475
At time: 1072.0299954414368 and batch: 1350, loss is 3.5921558427810667 and perplexity is 36.3122751598306
At time: 1073.347490310669 and batch: 1400, loss is 3.629720754623413 and perplexity is 37.702286957751106
At time: 1074.6648650169373 and batch: 1450, loss is 3.5425962734222414 and perplexity is 34.55652100216871
At time: 1075.9797894954681 and batch: 1500, loss is 3.5344436168670654 and perplexity is 34.27593885373372
At time: 1077.2955901622772 and batch: 1550, loss is 3.5513151359558104 and perplexity is 34.859131852627065
At time: 1078.617742061615 and batch: 1600, loss is 3.642082681655884 and perplexity is 38.17125256523641
At time: 1079.9358539581299 and batch: 1650, loss is 3.5829527091979982 and perplexity is 35.97962151669919
At time: 1081.2539498806 and batch: 1700, loss is 3.5902438354492188 and perplexity is 36.24291215590623
At time: 1082.5691816806793 and batch: 1750, loss is 3.5885676383972167 and perplexity is 36.18221277966422
At time: 1083.8848628997803 and batch: 1800, loss is 3.538197331428528 and perplexity is 34.404842727331854
At time: 1085.2030518054962 and batch: 1850, loss is 3.5653347158432007 and perplexity is 35.3512840590675
At time: 1086.5323402881622 and batch: 1900, loss is 3.6472581005096436 and perplexity is 38.36931687622363
At time: 1087.8528997898102 and batch: 1950, loss is 3.5917044925689696 and perplexity is 36.29588930489321
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354042514534884 and perplexity of 77.79230466527649
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f00fbd17b38>
ELAPSED
3350.3885555267334


RESULTS SO FAR:
[{'params': {'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}, 'best_accuracy': -78.33907429225935}, {'params': {'dropout': 0.16802636512990798, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.23001756521426064}, 'best_accuracy': -77.64523175401864}, {'params': {'dropout': 0.7990403138855218, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.10718988942097152}, 'best_accuracy': -77.79230466527649}]
SETTINGS FOR THIS RUN
{'dropout': 0.7943354117872055, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.9645103263983709}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9602718353271484 and batch: 50, loss is 7.952593297958374 and perplexity is 2842.937984348262
At time: 3.501011848449707 and batch: 100, loss is 7.1425856018066405 and perplexity is 1264.6941607933018
At time: 5.020411729812622 and batch: 150, loss is 6.993207912445069 and perplexity is 1089.2099680178515
At time: 6.540618658065796 and batch: 200, loss is 6.956308479309082 and perplexity is 1049.7512174427882
At time: 8.066908121109009 and batch: 250, loss is 6.915516939163208 and perplexity is 1007.7918599483345
At time: 9.595727682113647 and batch: 300, loss is 6.868161687850952 and perplexity is 961.1799918581245
At time: 11.126730680465698 and batch: 350, loss is 6.849107236862182 and perplexity is 943.0386206285211
At time: 12.655902624130249 and batch: 400, loss is 6.839022912979126 and perplexity is 933.5765034572113
At time: 14.18887448310852 and batch: 450, loss is 6.7831268215179445 and perplexity is 882.8248486408061
At time: 15.720888376235962 and batch: 500, loss is 6.755815744400024 and perplexity is 859.0402213967698
At time: 17.252758502960205 and batch: 550, loss is 6.71798412322998 and perplexity is 827.1484004398153
At time: 18.78226399421692 and batch: 600, loss is 6.739039440155029 and perplexity is 844.7489141257897
At time: 20.313427209854126 and batch: 650, loss is 6.791487035751342 and perplexity is 890.2363913805873
At time: 21.845795392990112 and batch: 700, loss is 6.699775352478027 and perplexity is 812.2233407101909
At time: 23.37670397758484 and batch: 750, loss is 6.633747425079346 and perplexity is 760.3261037101238
At time: 24.90748119354248 and batch: 800, loss is 6.628120450973511 and perplexity is 756.0597829078768
At time: 26.436569452285767 and batch: 850, loss is 6.674610137939453 and perplexity is 792.0386078720061
At time: 27.969170331954956 and batch: 900, loss is 6.661177072525025 and perplexity is 781.4702431280548
At time: 29.50136113166809 and batch: 950, loss is 6.663023147583008 and perplexity is 782.9142282948591
At time: 31.03394865989685 and batch: 1000, loss is 6.657123928070068 and perplexity is 778.3092416705763
At time: 32.56633996963501 and batch: 1050, loss is 6.566561460494995 and perplexity is 710.921105199369
At time: 34.099247455596924 and batch: 1100, loss is 6.627860441207885 and perplexity is 755.8632255354495
At time: 35.63185954093933 and batch: 1150, loss is 6.537479486465454 and perplexity is 690.5438575446829
At time: 37.163151264190674 and batch: 1200, loss is 6.6199767112731935 and perplexity is 749.9276320487662
At time: 38.695366621017456 and batch: 1250, loss is 6.548834028244019 and perplexity is 698.4293499817821
At time: 40.22682547569275 and batch: 1300, loss is 6.562600622177124 and perplexity is 708.1108308401155
At time: 41.7587034702301 and batch: 1350, loss is 6.572150430679321 and perplexity is 714.9055461488808
At time: 43.29117012023926 and batch: 1400, loss is 6.591687784194947 and perplexity is 729.0102441157802
At time: 44.82106304168701 and batch: 1450, loss is 6.592364244461059 and perplexity is 729.5035574141245
At time: 46.35303616523743 and batch: 1500, loss is 6.569847192764282 and perplexity is 713.2608433872813
At time: 47.8876838684082 and batch: 1550, loss is 6.545517292022705 and perplexity is 696.1166814345263
At time: 49.42604446411133 and batch: 1600, loss is 6.5215185928344725 and perplexity is 679.6096524522852
At time: 50.96032643318176 and batch: 1650, loss is 6.513203172683716 and perplexity is 673.9818438784777
At time: 52.49317145347595 and batch: 1700, loss is 6.546107711791993 and perplexity is 696.5278038404311
At time: 54.02670741081238 and batch: 1750, loss is 6.559315404891968 and perplexity is 705.7883499148837
At time: 55.5608184337616 and batch: 1800, loss is 6.565540542602539 and perplexity is 710.1956834839582
At time: 57.09553265571594 and batch: 1850, loss is 6.5075125312805175 and perplexity is 670.1573471333058
At time: 58.627665996551514 and batch: 1900, loss is 6.4550690269470214 and perplexity is 635.9176201896948
At time: 60.15850877761841 and batch: 1950, loss is 6.407202234268189 and perplexity is 606.1953138766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.957625136264535 and perplexity of 386.69069520169944
finished 1 epochs...
Completing Train Step...
At time: 64.18934035301208 and batch: 50, loss is 6.364240875244141 and perplexity is 580.7038342970242
At time: 65.5010998249054 and batch: 100, loss is 6.268865652084351 and perplexity is 527.8782405449612
At time: 66.81204414367676 and batch: 150, loss is 6.087861995697022 and perplexity is 440.4786584333072
At time: 68.12242817878723 and batch: 200, loss is 6.012423725128174 and perplexity is 408.47214567297794
At time: 69.43312311172485 and batch: 250, loss is 5.931641979217529 and perplexity is 376.7726590709616
At time: 70.74430418014526 and batch: 300, loss is 5.857789058685302 and perplexity is 349.94957010410036
At time: 72.05598711967468 and batch: 350, loss is 5.772662773132324 and perplexity is 321.3923892831241
At time: 73.36774015426636 and batch: 400, loss is 5.6997417545318605 and perplexity is 298.7902297801694
At time: 74.67773485183716 and batch: 450, loss is 5.596801853179931 and perplexity is 269.562925578028
At time: 75.99865579605103 and batch: 500, loss is 5.563977317810059 and perplexity is 260.8582921207169
At time: 77.30998539924622 and batch: 550, loss is 5.495809516906738 and perplexity is 243.66870027452796
At time: 78.62015223503113 and batch: 600, loss is 5.50451171875 and perplexity is 245.7984076188785
At time: 79.92981719970703 and batch: 650, loss is 5.565293779373169 and perplexity is 261.20192817791417
At time: 81.23907709121704 and batch: 700, loss is 5.484768371582032 and perplexity is 240.99311667832265
At time: 82.54959011077881 and batch: 750, loss is 5.405848617553711 and perplexity is 222.7051317998962
At time: 83.88169765472412 and batch: 800, loss is 5.388243036270142 and perplexity is 218.81859128984263
At time: 85.20568776130676 and batch: 850, loss is 5.39332347869873 and perplexity is 219.93311528545553
At time: 86.51676869392395 and batch: 900, loss is 5.392651262283326 and perplexity is 219.78532231506532
At time: 87.83056020736694 and batch: 950, loss is 5.418068714141846 and perplexity is 225.44330632536355
At time: 89.14466857910156 and batch: 1000, loss is 5.37906849861145 and perplexity is 216.82021299936858
At time: 90.45571208000183 and batch: 1050, loss is 5.2740387344360355 and perplexity is 195.20274462051015
At time: 91.77283501625061 and batch: 1100, loss is 5.351651296615601 and perplexity is 210.95636193557746
At time: 93.09358596801758 and batch: 1150, loss is 5.248270139694214 and perplexity is 190.23690039770284
At time: 94.4116837978363 and batch: 1200, loss is 5.307566528320312 and perplexity is 201.85841348950223
At time: 95.72612690925598 and batch: 1250, loss is 5.241722936630249 and perplexity is 188.99544923163256
At time: 97.04134154319763 and batch: 1300, loss is 5.268337888717651 and perplexity is 194.09308988014138
At time: 98.35621094703674 and batch: 1350, loss is 5.201928329467774 and perplexity is 181.62213172388053
At time: 99.66998386383057 and batch: 1400, loss is 5.210933942794799 and perplexity is 183.26513744682134
At time: 100.98270153999329 and batch: 1450, loss is 5.146513986587524 and perplexity is 171.83143833117867
At time: 102.29652500152588 and batch: 1500, loss is 5.123384246826172 and perplexity is 167.90263315314286
At time: 103.61030554771423 and batch: 1550, loss is 5.113368330001831 and perplexity is 166.22932817524293
At time: 104.92634606361389 and batch: 1600, loss is 5.14454532623291 and perplexity is 171.49349334944912
At time: 106.24258136749268 and batch: 1650, loss is 5.119026737213135 and perplexity is 167.17258756063592
At time: 107.55519986152649 and batch: 1700, loss is 5.12072566986084 and perplexity is 167.45684392528065
At time: 108.86844182014465 and batch: 1750, loss is 5.151172246932983 and perplexity is 172.63374112331127
At time: 110.18361711502075 and batch: 1800, loss is 5.107632026672364 and perplexity is 165.27851600729727
At time: 111.50066328048706 and batch: 1850, loss is 5.090360698699951 and perplexity is 162.4484464306362
At time: 112.81592345237732 and batch: 1900, loss is 5.121873226165771 and perplexity is 167.6491203852625
At time: 114.13149952888489 and batch: 1950, loss is 5.0426582336425785 and perplexity is 154.88117865898943
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.863434547601744 and perplexity of 129.46810373556977
finished 2 epochs...
Completing Train Step...
At time: 118.07946610450745 and batch: 50, loss is 5.051433267593384 and perplexity is 156.24624676021497
At time: 119.40660381317139 and batch: 100, loss is 5.017072610855102 and perplexity is 150.9687121220091
At time: 120.72039341926575 and batch: 150, loss is 4.949589633941651 and perplexity is 141.11704239332224
At time: 122.03456568717957 and batch: 200, loss is 4.933283138275146 and perplexity is 138.834578026444
At time: 123.34887742996216 and batch: 250, loss is 4.938070125579834 and perplexity is 139.50077064454737
At time: 124.66379618644714 and batch: 300, loss is 4.965305776596069 and perplexity is 143.3523773743435
At time: 125.9814202785492 and batch: 350, loss is 4.962134342193604 and perplexity is 142.89846487038284
At time: 127.29622554779053 and batch: 400, loss is 4.921105298995972 and perplexity is 137.15412575518948
At time: 128.60950660705566 and batch: 450, loss is 4.892661237716675 and perplexity is 133.3078663360133
At time: 129.92191362380981 and batch: 500, loss is 4.891388635635376 and perplexity is 133.13832636919895
At time: 131.23438024520874 and batch: 550, loss is 4.842910490036011 and perplexity is 126.83797569615983
At time: 132.54969191551208 and batch: 600, loss is 4.8320127296447755 and perplexity is 125.46323025721583
At time: 133.86223983764648 and batch: 650, loss is 4.896598033905029 and perplexity is 133.83370661995673
At time: 135.17538738250732 and batch: 700, loss is 4.897120313644409 and perplexity is 133.9036235098687
At time: 136.4874517917633 and batch: 750, loss is 4.8513338756561275 and perplexity is 127.91089333229318
At time: 137.80108428001404 and batch: 800, loss is 4.842058019638062 and perplexity is 126.72989615039492
At time: 139.1163535118103 and batch: 850, loss is 4.8455431842803955 and perplexity is 127.17234125275657
At time: 140.4527349472046 and batch: 900, loss is 4.84281623840332 and perplexity is 126.82602157321996
At time: 141.767564535141 and batch: 950, loss is 4.898086919784546 and perplexity is 134.03311814961427
At time: 143.0812041759491 and batch: 1000, loss is 4.868203582763672 and perplexity is 130.087016309517
At time: 144.3971221446991 and batch: 1050, loss is 4.785808925628662 and perplexity is 119.7982317587378
At time: 145.71195244789124 and batch: 1100, loss is 4.867420606613159 and perplexity is 129.9852011428803
At time: 147.02732181549072 and batch: 1150, loss is 4.773452491760254 and perplexity is 118.32706076235176
At time: 148.3429491519928 and batch: 1200, loss is 4.853418245315551 and perplexity is 128.17778497125408
At time: 149.656268119812 and batch: 1250, loss is 4.800100078582764 and perplexity is 121.52257871763882
At time: 150.96799635887146 and batch: 1300, loss is 4.832380094528198 and perplexity is 125.50932950927785
At time: 152.28049206733704 and batch: 1350, loss is 4.733924026489258 and perplexity is 113.74101054009925
At time: 153.5950014591217 and batch: 1400, loss is 4.745012216567993 and perplexity is 115.0092105123672
At time: 154.90882468223572 and batch: 1450, loss is 4.680004148483277 and perplexity is 107.77051965467163
At time: 156.2219958305359 and batch: 1500, loss is 4.662920885086059 and perplexity is 105.9450840734365
At time: 157.5335111618042 and batch: 1550, loss is 4.662611446380615 and perplexity is 105.91230563549291
At time: 158.84703183174133 and batch: 1600, loss is 4.7430455684661865 and perplexity is 114.78325013192844
At time: 160.1611704826355 and batch: 1650, loss is 4.7011470699310305 and perplexity is 110.07336190787396
At time: 161.47571110725403 and batch: 1700, loss is 4.725747060775757 and perplexity is 112.81474637290543
At time: 162.78983736038208 and batch: 1750, loss is 4.737290096282959 and perplexity is 114.12451581063033
At time: 164.10362482070923 and batch: 1800, loss is 4.68970290184021 and perplexity is 108.82084453162123
At time: 165.41778326034546 and batch: 1850, loss is 4.706811618804932 and perplexity is 110.69864715356724
At time: 166.7339322566986 and batch: 1900, loss is 4.761768531799317 and perplexity is 116.95257746245153
At time: 168.05018830299377 and batch: 1950, loss is 4.690260505676269 and perplexity is 108.88154037251947
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.683514546239099 and perplexity of 108.14950184494667
finished 3 epochs...
Completing Train Step...
At time: 171.999995470047 and batch: 50, loss is 4.699647045135498 and perplexity is 109.90837291041454
At time: 173.32583451271057 and batch: 100, loss is 4.636315565109253 and perplexity is 103.16354712433662
At time: 174.64114451408386 and batch: 150, loss is 4.589523658752442 and perplexity is 98.44752437467297
At time: 175.95608735084534 and batch: 200, loss is 4.587530651092529 and perplexity is 98.2515130953664
At time: 177.2714560031891 and batch: 250, loss is 4.59769422531128 and perplexity is 99.25519148086094
At time: 178.5858085155487 and batch: 300, loss is 4.622748155593872 and perplexity is 101.77333713270615
At time: 179.90056920051575 and batch: 350, loss is 4.6276044750213625 and perplexity is 102.26878301504688
At time: 181.2155954837799 and batch: 400, loss is 4.584157314300537 and perplexity is 97.92063604500186
At time: 182.5317714214325 and batch: 450, loss is 4.584056787490844 and perplexity is 97.91079289061594
At time: 183.84707593917847 and batch: 500, loss is 4.593981599807739 and perplexity is 98.887377326199
At time: 185.16056203842163 and batch: 550, loss is 4.555074186325073 and perplexity is 95.1138111179603
At time: 186.4741666316986 and batch: 600, loss is 4.530567150115967 and perplexity is 92.8111840319319
At time: 187.78762364387512 and batch: 650, loss is 4.58163143157959 and perplexity is 97.67361211047167
At time: 189.10390615463257 and batch: 700, loss is 4.61332368850708 and perplexity is 100.81868328453693
At time: 190.41971492767334 and batch: 750, loss is 4.569825620651245 and perplexity is 96.52727594163524
At time: 191.7344627380371 and batch: 800, loss is 4.562555561065674 and perplexity is 95.82806163840354
At time: 193.0470552444458 and batch: 850, loss is 4.561209106445313 and perplexity is 95.69912032834188
At time: 194.35968112945557 and batch: 900, loss is 4.5582998180389405 and perplexity is 95.42110859132224
At time: 195.68285870552063 and batch: 950, loss is 4.622512893676758 and perplexity is 101.74939655856434
At time: 196.9995892047882 and batch: 1000, loss is 4.5952731800079345 and perplexity is 99.01518082126807
At time: 198.31496143341064 and batch: 1050, loss is 4.5213127708435055 and perplexity is 91.95623624145038
At time: 199.62926268577576 and batch: 1100, loss is 4.584440631866455 and perplexity is 97.94838261161854
At time: 200.94303798675537 and batch: 1150, loss is 4.514178819656372 and perplexity is 91.30255936253448
At time: 202.2582688331604 and batch: 1200, loss is 4.601592473983764 and perplexity is 99.64286803816216
At time: 203.5766477584839 and batch: 1250, loss is 4.562950448989868 and perplexity is 95.86591045527204
At time: 204.8944754600525 and batch: 1300, loss is 4.583259010314942 and perplexity is 97.83271304407415
At time: 206.22185683250427 and batch: 1350, loss is 4.46705379486084 and perplexity is 87.09973094872312
At time: 207.5362560749054 and batch: 1400, loss is 4.492835683822632 and perplexity is 89.37452477726954
At time: 208.85167837142944 and batch: 1450, loss is 4.427357835769653 and perplexity is 83.709949028803
At time: 210.1678819656372 and batch: 1500, loss is 4.409099397659301 and perplexity is 82.19540478653467
At time: 211.48234462738037 and batch: 1550, loss is 4.415067481994629 and perplexity is 82.68742062991547
At time: 212.79619908332825 and batch: 1600, loss is 4.510825939178467 and perplexity is 90.99694542347444
At time: 214.10961747169495 and batch: 1650, loss is 4.4656828498840335 and perplexity is 86.98040382424821
At time: 215.4242103099823 and batch: 1700, loss is 4.488975591659546 and perplexity is 89.03019587280069
At time: 216.74027943611145 and batch: 1750, loss is 4.495178165435791 and perplexity is 89.58412835866784
At time: 218.05663800239563 and batch: 1800, loss is 4.454540958404541 and perplexity is 86.01665655780923
At time: 219.37194275856018 and batch: 1850, loss is 4.4809004497528075 and perplexity is 88.3141593463571
At time: 220.68652987480164 and batch: 1900, loss is 4.544616069793701 and perplexity is 94.1242831160117
At time: 222.00169348716736 and batch: 1950, loss is 4.478368711471558 and perplexity is 88.09085380323627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.593412177507267 and perplexity of 98.83108467698027
finished 4 epochs...
Completing Train Step...
At time: 225.95399689674377 and batch: 50, loss is 4.473641767501831 and perplexity is 87.67543587520574
At time: 227.27972841262817 and batch: 100, loss is 4.414057035446167 and perplexity is 82.60391160894497
At time: 228.60145449638367 and batch: 150, loss is 4.372104234695435 and perplexity is 79.21013316948846
At time: 229.92708683013916 and batch: 200, loss is 4.373853712081909 and perplexity is 79.34883079505221
At time: 231.24045205116272 and batch: 250, loss is 4.380706300735474 and perplexity is 79.89444298551635
At time: 232.55523872375488 and batch: 300, loss is 4.403894529342652 and perplexity is 81.76869996290453
At time: 233.87029218673706 and batch: 350, loss is 4.414109115600586 and perplexity is 82.6082137454442
At time: 235.18420505523682 and batch: 400, loss is 4.3725992202758786 and perplexity is 79.24935074849971
At time: 236.49742889404297 and batch: 450, loss is 4.38339129447937 and perplexity is 80.10924731019139
At time: 237.84217524528503 and batch: 500, loss is 4.397499446868896 and perplexity is 81.24745087478654
At time: 239.15864610671997 and batch: 550, loss is 4.360124139785767 and perplexity is 78.2668498500093
At time: 240.47376227378845 and batch: 600, loss is 4.338074412345886 and perplexity is 76.55997436780719
At time: 241.78868770599365 and batch: 650, loss is 4.385447416305542 and perplexity is 80.27413113459006
At time: 243.11631560325623 and batch: 700, loss is 4.425338430404663 and perplexity is 83.54107527829896
At time: 244.44175148010254 and batch: 750, loss is 4.383611192703247 and perplexity is 80.1268651283835
At time: 245.7685751914978 and batch: 800, loss is 4.371571245193482 and perplexity is 79.16792624898277
At time: 247.08663296699524 and batch: 850, loss is 4.366574630737305 and perplexity is 78.77334125969126
At time: 248.40174055099487 and batch: 900, loss is 4.361258878707885 and perplexity is 78.35571269937743
At time: 249.71478843688965 and batch: 950, loss is 4.433508720397949 and perplexity is 84.22642603441876
At time: 251.02793622016907 and batch: 1000, loss is 4.410749139785767 and perplexity is 82.33111792347218
At time: 252.34324193000793 and batch: 1050, loss is 4.340500459671021 and perplexity is 76.74593797588098
At time: 253.65836596488953 and batch: 1100, loss is 4.392851238250732 and perplexity is 80.8706721249276
At time: 254.97386837005615 and batch: 1150, loss is 4.338408088684082 and perplexity is 76.58552488227058
At time: 256.2889482975006 and batch: 1200, loss is 4.430142707824707 and perplexity is 83.94339543489497
At time: 257.6017506122589 and batch: 1250, loss is 4.395473909378052 and perplexity is 81.08304767563534
At time: 258.9154243469238 and batch: 1300, loss is 4.406341667175293 and perplexity is 81.96904427720533
At time: 260.2293953895569 and batch: 1350, loss is 4.2833943176269536 and perplexity is 72.48606363269457
At time: 261.5435893535614 and batch: 1400, loss is 4.31130934715271 and perplexity is 74.53802122045842
At time: 262.85664415359497 and batch: 1450, loss is 4.252252535820007 and perplexity is 70.26350528733514
At time: 264.17783522605896 and batch: 1500, loss is 4.237607989311218 and perplexity is 69.24202592302035
At time: 265.4908127784729 and batch: 1550, loss is 4.244653038978576 and perplexity is 69.73156181229514
At time: 266.80491065979004 and batch: 1600, loss is 4.34120807647705 and perplexity is 76.8002639100924
At time: 268.1175878047943 and batch: 1650, loss is 4.292980074882507 and perplexity is 73.18423836375992
At time: 269.4308478832245 and batch: 1700, loss is 4.320108766555786 and perplexity is 75.19680674491971
At time: 270.74294114112854 and batch: 1750, loss is 4.328028621673584 and perplexity is 75.79471912407861
At time: 272.05610060691833 and batch: 1800, loss is 4.283553791046143 and perplexity is 72.49762415487915
At time: 273.3709008693695 and batch: 1850, loss is 4.319034900665283 and perplexity is 75.11609880159125
At time: 274.68470215797424 and batch: 1900, loss is 4.3822778129577635 and perplexity is 80.02009678654308
At time: 275.99888014793396 and batch: 1950, loss is 4.322865772247314 and perplexity is 75.40441082040779
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.561325286155523 and perplexity of 95.71023927029424
finished 5 epochs...
Completing Train Step...
At time: 279.9857494831085 and batch: 50, loss is 4.324717049598694 and perplexity is 75.54413459217535
At time: 281.3017168045044 and batch: 100, loss is 4.251910443305969 and perplexity is 70.23947277907122
At time: 282.61726808547974 and batch: 150, loss is 4.216382374763489 and perplexity is 67.78780928770294
At time: 283.9315490722656 and batch: 200, loss is 4.222224578857422 and perplexity is 68.18499860545482
At time: 285.2441210746765 and batch: 250, loss is 4.223750066757202 and perplexity is 68.28909337324163
At time: 286.5573947429657 and batch: 300, loss is 4.24096941947937 and perplexity is 69.47516978674199
At time: 287.87250995635986 and batch: 350, loss is 4.2518187999725345 and perplexity is 70.23303609459116
At time: 289.1898338794708 and batch: 400, loss is 4.210525703430176 and perplexity is 67.39195868323539
At time: 290.5045518875122 and batch: 450, loss is 4.234266262054444 and perplexity is 69.01102414511698
At time: 291.8176317214966 and batch: 500, loss is 4.254254913330078 and perplexity is 70.40434030548101
At time: 293.1316623687744 and batch: 550, loss is 4.217498135566712 and perplexity is 67.86348647921346
At time: 294.4476671218872 and batch: 600, loss is 4.195645570755005 and perplexity is 66.39658143570614
At time: 295.763484954834 and batch: 650, loss is 4.2420046472549435 and perplexity is 69.54712965321755
At time: 297.0796928405762 and batch: 700, loss is 4.287099223136902 and perplexity is 72.75511574781574
At time: 298.3931939601898 and batch: 750, loss is 4.245709562301636 and perplexity is 69.80527376604567
At time: 299.7059326171875 and batch: 800, loss is 4.228680438995362 and perplexity is 68.62661539425633
At time: 301.021027803421 and batch: 850, loss is 4.22417697429657 and perplexity is 68.31825272579007
At time: 302.33625888824463 and batch: 900, loss is 4.2133048629760745 and perplexity is 67.57951218836611
At time: 303.68021416664124 and batch: 950, loss is 4.289015436172486 and perplexity is 72.89466370812721
At time: 304.99376821517944 and batch: 1000, loss is 4.278611707687378 and perplexity is 72.14021874410422
At time: 306.30703496932983 and batch: 1050, loss is 4.20658275604248 and perplexity is 67.12675891374742
At time: 307.62130069732666 and batch: 1100, loss is 4.2572155809402465 and perplexity is 70.61309302666275
At time: 308.93622851371765 and batch: 1150, loss is 4.2047431802749635 and perplexity is 67.00338766486877
At time: 310.2507200241089 and batch: 1200, loss is 4.2981201267242435 and perplexity is 73.56137757014517
At time: 311.5654203891754 and batch: 1250, loss is 4.266199779510498 and perplexity is 71.25035342665042
At time: 312.87880086898804 and batch: 1300, loss is 4.265149917602539 and perplexity is 71.17558964734825
At time: 314.1928277015686 and batch: 1350, loss is 4.139884424209595 and perplexity is 62.795563382909464
At time: 315.5088939666748 and batch: 1400, loss is 4.181480536460876 and perplexity is 65.46270141894799
At time: 316.8250889778137 and batch: 1450, loss is 4.113093471527099 and perplexity is 61.13554642285032
At time: 318.1402094364166 and batch: 1500, loss is 4.103904824256897 and perplexity is 60.576366439263914
At time: 319.4528431892395 and batch: 1550, loss is 4.108927445411682 and perplexity is 60.881383931259975
At time: 320.7653160095215 and batch: 1600, loss is 4.216813468933106 and perplexity is 67.81703851688043
At time: 322.07951641082764 and batch: 1650, loss is 4.1596959400177 and perplexity is 64.05204397539416
At time: 323.3953366279602 and batch: 1700, loss is 4.187422552108765 and perplexity is 65.852839771328
At time: 324.7128086090088 and batch: 1750, loss is 4.200318946838379 and perplexity is 66.70760382763741
At time: 326.02581095695496 and batch: 1800, loss is 4.1517050123214725 and perplexity is 63.54224830610192
At time: 327.3383038043976 and batch: 1850, loss is 4.193115701675415 and perplexity is 66.22881907522232
At time: 328.65167593955994 and batch: 1900, loss is 4.253669271469116 and perplexity is 70.36312064776136
At time: 329.9750440120697 and batch: 1950, loss is 4.1964498710632325 and perplexity is 66.4500057083196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.541947617641715 and perplexity of 93.8734517847194
finished 6 epochs...
Completing Train Step...
At time: 333.9385042190552 and batch: 50, loss is 4.196364779472351 and perplexity is 66.4443516121812
At time: 335.2522144317627 and batch: 100, loss is 4.131032285690307 and perplexity is 62.2421414550865
At time: 336.5795078277588 and batch: 150, loss is 4.093973560333252 and perplexity is 59.97774401543051
At time: 337.8942127227783 and batch: 200, loss is 4.097380509376526 and perplexity is 60.18243361855426
At time: 339.210932970047 and batch: 250, loss is 4.099763188362122 and perplexity is 60.32600000682662
At time: 340.5235469341278 and batch: 300, loss is 4.113844332695007 and perplexity is 61.18146796883336
At time: 341.8456618785858 and batch: 350, loss is 4.126841049194336 and perplexity is 61.98181584441594
At time: 343.16284108161926 and batch: 400, loss is 4.092860746383667 and perplexity is 59.91103706832004
At time: 344.47885847091675 and batch: 450, loss is 4.120367379188537 and perplexity is 61.581862003654905
At time: 345.79463815689087 and batch: 500, loss is 4.137915077209473 and perplexity is 62.67201881952686
At time: 347.10857677459717 and batch: 550, loss is 4.100639276504516 and perplexity is 60.37887405789342
At time: 348.4226231575012 and batch: 600, loss is 4.076805472373962 and perplexity is 58.95682948134917
At time: 349.73671793937683 and batch: 650, loss is 4.121449704170227 and perplexity is 61.64854967367607
At time: 351.0538430213928 and batch: 700, loss is 4.170834336280823 and perplexity is 64.76946908805596
At time: 352.36831998825073 and batch: 750, loss is 4.136351318359375 and perplexity is 62.574091482769546
At time: 353.6832399368286 and batch: 800, loss is 4.114160146713257 and perplexity is 61.200792985469974
At time: 354.99659037590027 and batch: 850, loss is 4.103681507110596 and perplexity is 60.56284020835325
At time: 356.3107054233551 and batch: 900, loss is 4.099328908920288 and perplexity is 60.29980735309279
At time: 357.6258807182312 and batch: 950, loss is 4.174298977851867 and perplexity is 64.99426127050077
At time: 358.9408209323883 and batch: 1000, loss is 4.166958804130554 and perplexity is 64.51893871108986
At time: 360.2553038597107 and batch: 1050, loss is 4.1000762987136845 and perplexity is 60.34489165932877
At time: 361.56941175460815 and batch: 1100, loss is 4.143533244132995 and perplexity is 63.02511162109306
At time: 362.8830301761627 and batch: 1150, loss is 4.099771018028259 and perplexity is 60.3264723411152
At time: 364.198308467865 and batch: 1200, loss is 4.188131785392761 and perplexity is 65.89956136343514
At time: 365.514253616333 and batch: 1250, loss is 4.156912508010865 and perplexity is 63.87400735744499
At time: 366.8298707008362 and batch: 1300, loss is 4.160961246490478 and perplexity is 64.13314073653962
At time: 368.14423060417175 and batch: 1350, loss is 4.034431343078613 and perplexity is 56.51077585580305
At time: 369.45658779144287 and batch: 1400, loss is 4.067813010215759 and perplexity is 58.429039047637325
At time: 370.77291989326477 and batch: 1450, loss is 4.004215016365051 and perplexity is 54.82876781646433
At time: 372.0972316265106 and batch: 1500, loss is 4.001745457649231 and perplexity is 54.69353201013806
At time: 373.4120464324951 and batch: 1550, loss is 4.008223943710327 and perplexity is 55.04901354265559
At time: 374.74046874046326 and batch: 1600, loss is 4.1119910955429075 and perplexity is 61.06818919800807
At time: 376.053275346756 and batch: 1650, loss is 4.0560763072967525 and perplexity is 57.74728338232577
At time: 377.3670926094055 and batch: 1700, loss is 4.083154582977295 and perplexity is 59.33234374188285
At time: 378.6815800666809 and batch: 1750, loss is 4.09857976436615 and perplexity is 60.25465099722955
At time: 379.99612498283386 and batch: 1800, loss is 4.043544282913208 and perplexity is 57.02810878794231
At time: 381.308137178421 and batch: 1850, loss is 4.091477570533752 and perplexity is 59.82822685245169
At time: 382.6186490058899 and batch: 1900, loss is 4.153499073982239 and perplexity is 63.6563493391669
At time: 383.93970370292664 and batch: 1950, loss is 4.095639472007751 and perplexity is 60.0777449125996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.543530557321947 and perplexity of 94.02216546781216
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 387.8925096988678 and batch: 50, loss is 4.131359796524048 and perplexity is 62.26252976924292
At time: 389.2056710720062 and batch: 100, loss is 4.067859816551208 and perplexity is 58.4317739608441
At time: 390.51822662353516 and batch: 150, loss is 4.028788361549378 and perplexity is 56.19278464453391
At time: 391.8313784599304 and batch: 200, loss is 4.0338249778747555 and perplexity is 56.47652007448759
At time: 393.14555072784424 and batch: 250, loss is 4.028139572143555 and perplexity is 56.156339185165244
At time: 394.4588210582733 and batch: 300, loss is 4.051147217750549 and perplexity is 57.46334221209547
At time: 395.7726740837097 and batch: 350, loss is 4.0545978832244876 and perplexity is 57.66197148758397
At time: 397.0847249031067 and batch: 400, loss is 4.016216006278992 and perplexity is 55.490731470737266
At time: 398.39761328697205 and batch: 450, loss is 4.032979679107666 and perplexity is 56.428800713099214
At time: 399.7120563983917 and batch: 500, loss is 4.047107973098755 and perplexity is 57.23170185537093
At time: 401.026908159256 and batch: 550, loss is 4.004269165992737 and perplexity is 54.83173685421348
At time: 402.35221552848816 and batch: 600, loss is 3.970770044326782 and perplexity is 53.02534699016214
At time: 403.665176153183 and batch: 650, loss is 4.010638470649719 and perplexity is 55.18209146430171
At time: 404.97736072540283 and batch: 700, loss is 4.051604099273682 and perplexity is 57.48960214979299
At time: 406.2917175292969 and batch: 750, loss is 4.012151141166687 and perplexity is 55.26562695203042
At time: 407.60633087158203 and batch: 800, loss is 3.987797665596008 and perplexity is 53.93597341518425
At time: 408.9230446815491 and batch: 850, loss is 3.996861047744751 and perplexity is 54.42703774411577
At time: 410.23681831359863 and batch: 900, loss is 3.964012484550476 and perplexity is 52.668233006716775
At time: 411.54997730255127 and batch: 950, loss is 4.051812872886658 and perplexity is 57.50160571471257
At time: 412.8652653694153 and batch: 1000, loss is 4.017235741615296 and perplexity is 55.54734619156508
At time: 414.18167757987976 and batch: 1050, loss is 3.947877550125122 and perplexity is 51.825253518325
At time: 415.49735617637634 and batch: 1100, loss is 3.9911981534957888 and perplexity is 54.11969423331983
At time: 416.81219124794006 and batch: 1150, loss is 3.9410920763015747 and perplexity is 51.47478500933193
At time: 418.12535858154297 and batch: 1200, loss is 4.015255002975464 and perplexity is 55.43743030987665
At time: 419.4393436908722 and batch: 1250, loss is 3.984842529296875 and perplexity is 53.7768205373604
At time: 420.75521326065063 and batch: 1300, loss is 3.985527753829956 and perplexity is 53.81368236197464
At time: 422.06942486763 and batch: 1350, loss is 3.8542516040802 and perplexity is 47.19328446004961
At time: 423.3836090564728 and batch: 1400, loss is 3.8763245916366578 and perplexity is 48.24656297826428
At time: 424.69685649871826 and batch: 1450, loss is 3.8082165193557738 and perplexity is 45.06998569718275
At time: 426.0100519657135 and batch: 1500, loss is 3.793499255180359 and perplexity is 44.411535985330154
At time: 427.32436299324036 and batch: 1550, loss is 3.801799736022949 and perplexity is 44.78170726343218
At time: 428.64039039611816 and batch: 1600, loss is 3.901076807975769 and perplexity is 49.455674708483436
At time: 429.95473861694336 and batch: 1650, loss is 3.8349456548690797 and perplexity is 46.290911913923175
At time: 431.26845693588257 and batch: 1700, loss is 3.8500643396377563 and perplexity is 46.99608684551273
At time: 432.58154010772705 and batch: 1750, loss is 3.852194209098816 and perplexity is 47.096289046599004
At time: 433.8957943916321 and batch: 1800, loss is 3.7941936588287355 and perplexity is 44.442386227969244
At time: 435.2122538089752 and batch: 1850, loss is 3.8269945764541626 and perplexity is 45.92430862053955
At time: 436.5262358188629 and batch: 1900, loss is 3.8878074169158934 and perplexity is 48.80376282303404
At time: 437.84055042266846 and batch: 1950, loss is 3.822197961807251 and perplexity is 45.70455486752827
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486574252816133 and perplexity of 88.81666069298682
finished 8 epochs...
Completing Train Step...
At time: 441.76978039741516 and batch: 50, loss is 4.023152284622192 and perplexity is 55.876968605271095
At time: 443.09518027305603 and batch: 100, loss is 3.9605802869796753 and perplexity is 52.487775086100335
At time: 444.4139859676361 and batch: 150, loss is 3.921368284225464 and perplexity is 50.46945411303729
At time: 445.72725558280945 and batch: 200, loss is 3.921614170074463 and perplexity is 50.481865363423275
At time: 447.0407176017761 and batch: 250, loss is 3.9188643312454223 and perplexity is 50.343239057237476
At time: 448.3544464111328 and batch: 300, loss is 3.9406498956680296 and perplexity is 51.4520288878138
At time: 449.66941499710083 and batch: 350, loss is 3.9407532167434693 and perplexity is 51.45734524141301
At time: 450.9853632450104 and batch: 400, loss is 3.9036576318740845 and perplexity is 49.58347594097931
At time: 452.3002128601074 and batch: 450, loss is 3.930817370414734 and perplexity is 50.948604536619136
At time: 453.6143960952759 and batch: 500, loss is 3.948257508277893 and perplexity is 51.84494868735179
At time: 454.92965745925903 and batch: 550, loss is 3.9057582569122316 and perplexity is 49.687741705316405
At time: 456.2452754974365 and batch: 600, loss is 3.8759588384628296 and perplexity is 48.228919871436524
At time: 457.5605812072754 and batch: 650, loss is 3.91239465713501 and perplexity is 50.0185860388958
At time: 458.8756031990051 and batch: 700, loss is 3.95815646648407 and perplexity is 52.360708196951855
At time: 460.1890540122986 and batch: 750, loss is 3.918758358955383 and perplexity is 50.33790435157707
At time: 461.5030906200409 and batch: 800, loss is 3.896513833999634 and perplexity is 49.23052382128628
At time: 462.81893372535706 and batch: 850, loss is 3.904957423210144 and perplexity is 49.647966016160154
At time: 464.13413858413696 and batch: 900, loss is 3.873266854286194 and perplexity is 48.09926297773906
At time: 465.4511675834656 and batch: 950, loss is 3.962012166976929 and perplexity is 52.562985114363855
At time: 466.79588556289673 and batch: 1000, loss is 3.9353781223297117 and perplexity is 51.181499165945546
At time: 468.10983204841614 and batch: 1050, loss is 3.872515559196472 and perplexity is 48.06313980892345
At time: 469.4264032840729 and batch: 1100, loss is 3.913904709815979 and perplexity is 50.094173795225856
At time: 470.7425916194916 and batch: 1150, loss is 3.865433359146118 and perplexity is 47.723949562085146
At time: 472.05785393714905 and batch: 1200, loss is 3.9419867610931396 and perplexity is 51.52085932455002
At time: 473.3712682723999 and batch: 1250, loss is 3.915064015388489 and perplexity is 50.15228192608884
At time: 474.68407678604126 and batch: 1300, loss is 3.9148549175262453 and perplexity is 50.141796287451974
At time: 475.9971914291382 and batch: 1350, loss is 3.7820501565933227 and perplexity is 43.90596362791548
At time: 477.3130292892456 and batch: 1400, loss is 3.8118589782714842 and perplexity is 45.23445061493281
At time: 478.62830901145935 and batch: 1450, loss is 3.7455492782592774 and perplexity is 42.33225302029695
At time: 479.9419493675232 and batch: 1500, loss is 3.731323199272156 and perplexity is 41.73429443277943
At time: 481.25409746170044 and batch: 1550, loss is 3.7410358667373655 and perplexity is 42.14162066651002
At time: 482.567307472229 and batch: 1600, loss is 3.8442884635925294 and perplexity is 46.72542567841245
At time: 483.88633823394775 and batch: 1650, loss is 3.780391845703125 and perplexity is 43.83321422751987
At time: 485.20936918258667 and batch: 1700, loss is 3.8012504291534426 and perplexity is 44.75711511893946
At time: 486.53303050994873 and batch: 1750, loss is 3.805678606033325 and perplexity is 44.95574700530598
At time: 487.85603737831116 and batch: 1800, loss is 3.753571033477783 and perplexity is 42.67319765078544
At time: 489.17581820487976 and batch: 1850, loss is 3.7880924129486084 and perplexity is 44.17205781074905
At time: 490.49730706214905 and batch: 1900, loss is 3.850641965866089 and perplexity is 47.02324085958406
At time: 491.8205337524414 and batch: 1950, loss is 3.7916886949539186 and perplexity is 44.33119897412485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4897211119186045 and perplexity of 89.09659443515314
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 495.76315093040466 and batch: 50, loss is 3.9877253484725954 and perplexity is 53.93207306177127
At time: 497.08798241615295 and batch: 100, loss is 3.9546860885620116 and perplexity is 52.179311690511746
At time: 498.4033582210541 and batch: 150, loss is 3.915616593360901 and perplexity is 50.18000263056737
At time: 499.73243832588196 and batch: 200, loss is 3.911635370254517 and perplexity is 49.980621997358895
At time: 501.04849672317505 and batch: 250, loss is 3.9059790658950804 and perplexity is 49.69871441641442
At time: 502.3624701499939 and batch: 300, loss is 3.944542188644409 and perplexity is 51.65268551233146
At time: 503.682580947876 and batch: 350, loss is 3.9541875600814818 and perplexity is 52.153305300541234
At time: 504.9989938735962 and batch: 400, loss is 3.8994710540771482 and perplexity is 49.376324791280766
At time: 506.312050819397 and batch: 450, loss is 3.919859251976013 and perplexity is 50.39335151424806
At time: 507.64138293266296 and batch: 500, loss is 3.9289603662490844 and perplexity is 50.85408055863459
At time: 508.9661271572113 and batch: 550, loss is 3.8928581285476684 and perplexity is 49.05088008930083
At time: 510.2903256416321 and batch: 600, loss is 3.8661732149124144 and perplexity is 47.759271466305115
At time: 511.6063370704651 and batch: 650, loss is 3.9031675958633425 and perplexity is 49.55918420462936
At time: 512.9236090183258 and batch: 700, loss is 3.9382060527801515 and perplexity is 51.326441733091244
At time: 514.2389538288116 and batch: 750, loss is 3.8843950843811035 and perplexity is 48.637511968252085
At time: 515.5550274848938 and batch: 800, loss is 3.866811547279358 and perplexity is 47.78976748736685
At time: 516.8688857555389 and batch: 850, loss is 3.8724646759033203 and perplexity is 48.060694260310065
At time: 518.1831865310669 and batch: 900, loss is 3.8501487827301024 and perplexity is 47.000055507974835
At time: 519.4991314411163 and batch: 950, loss is 3.9408516836166383 and perplexity is 51.46241233476683
At time: 520.8168983459473 and batch: 1000, loss is 3.8974866485595703 and perplexity is 49.278439294309024
At time: 522.132922410965 and batch: 1050, loss is 3.8332134246826173 and perplexity is 46.2107948096137
At time: 523.4475815296173 and batch: 1100, loss is 3.88282630443573 and perplexity is 48.561270233771815
At time: 524.7629306316376 and batch: 1150, loss is 3.847686505317688 and perplexity is 46.88447069225321
At time: 526.0788321495056 and batch: 1200, loss is 3.9011270236968993 and perplexity is 49.45815822320812
At time: 527.3952679634094 and batch: 1250, loss is 3.8672564744949343 and perplexity is 47.811035186486265
At time: 528.7151663303375 and batch: 1300, loss is 3.8786512136459352 and perplexity is 48.358945178316226
At time: 530.0339181423187 and batch: 1350, loss is 3.740159983634949 and perplexity is 42.10472569326032
At time: 531.3488602638245 and batch: 1400, loss is 3.76290367603302 and perplexity is 43.07331552557663
At time: 532.6645245552063 and batch: 1450, loss is 3.6945449113845825 and perplexity is 40.227261452976464
At time: 533.9806663990021 and batch: 1500, loss is 3.6739289712905885 and perplexity is 39.40642883090965
At time: 535.2974376678467 and batch: 1550, loss is 3.6870636510849 and perplexity is 39.92743378175641
At time: 536.6136012077332 and batch: 1600, loss is 3.790665807723999 and perplexity is 44.285876340730404
At time: 537.9279770851135 and batch: 1650, loss is 3.723487448692322 and perplexity is 41.40855279278325
At time: 539.2427804470062 and batch: 1700, loss is 3.7357671070098877 and perplexity is 41.92017048886516
At time: 540.5584390163422 and batch: 1750, loss is 3.737080855369568 and perplexity is 41.9752792356691
At time: 541.8725271224976 and batch: 1800, loss is 3.6892132425308226 and perplexity is 40.013353765217545
At time: 543.1888437271118 and batch: 1850, loss is 3.714501476287842 and perplexity is 41.03812350635672
At time: 544.5123109817505 and batch: 1900, loss is 3.7814962434768677 and perplexity is 43.8816502731361
At time: 545.8265314102173 and batch: 1950, loss is 3.714584832191467 and perplexity is 41.04154441879932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.466560967023983 and perplexity of 87.05681635235125
finished 10 epochs...
Completing Train Step...
At time: 549.7743017673492 and batch: 50, loss is 3.9693366956710814 and perplexity is 52.94939762429954
At time: 551.1026830673218 and batch: 100, loss is 3.914110107421875 and perplexity is 50.104464075356006
At time: 552.416702747345 and batch: 150, loss is 3.8758304595947264 and perplexity is 48.22272869471022
At time: 553.7303736209869 and batch: 200, loss is 3.870337529182434 and perplexity is 47.95857076644524
At time: 555.0470943450928 and batch: 250, loss is 3.86545937538147 and perplexity is 47.72519117573986
At time: 556.3629369735718 and batch: 300, loss is 3.9021426105499266 and perplexity is 49.508412793095346
At time: 557.6780109405518 and batch: 350, loss is 3.9059328413009644 and perplexity is 49.69641716660756
At time: 558.993250131607 and batch: 400, loss is 3.8569081449508666 and perplexity is 47.31882202304344
At time: 560.3093390464783 and batch: 450, loss is 3.883509860038757 and perplexity is 48.59447590980023
At time: 561.6270759105682 and batch: 500, loss is 3.894587268829346 and perplexity is 49.13576931345241
At time: 562.9450166225433 and batch: 550, loss is 3.8557475090026854 and perplexity is 47.26393395587138
At time: 564.2687606811523 and batch: 600, loss is 3.8280510902404785 and perplexity is 45.972853925600596
At time: 565.5960595607758 and batch: 650, loss is 3.860008568763733 and perplexity is 47.46575808997746
At time: 566.9108998775482 and batch: 700, loss is 3.9004592943191527 and perplexity is 49.425144581309155
At time: 568.2261290550232 and batch: 750, loss is 3.851443748474121 and perplexity is 47.06095839488992
At time: 569.5421752929688 and batch: 800, loss is 3.8357649135589598 and perplexity is 46.32885168489261
At time: 570.8585183620453 and batch: 850, loss is 3.8385524225234984 and perplexity is 46.45817393400702
At time: 572.1750988960266 and batch: 900, loss is 3.813068766593933 and perplexity is 45.2892078407068
At time: 573.489232301712 and batch: 950, loss is 3.906718902587891 and perplexity is 49.73549695378282
At time: 574.8050303459167 and batch: 1000, loss is 3.866556529998779 and perplexity is 47.77758182466605
At time: 576.1219577789307 and batch: 1050, loss is 3.8043815422058107 and perplexity is 44.897474331884624
At time: 577.4387879371643 and batch: 1100, loss is 3.8545563888549803 and perplexity is 47.20767044682841
At time: 578.7551157474518 and batch: 1150, loss is 3.8200149488449098 and perplexity is 45.60489005618172
At time: 580.0694780349731 and batch: 1200, loss is 3.874926791191101 and perplexity is 48.17917102226253
At time: 581.3837583065033 and batch: 1250, loss is 3.844881491661072 and perplexity is 46.7531433852311
At time: 582.6993033885956 and batch: 1300, loss is 3.853844175338745 and perplexity is 47.17406047602465
At time: 584.0164015293121 and batch: 1350, loss is 3.7163216876983642 and perplexity is 41.11288959142727
At time: 585.3314702510834 and batch: 1400, loss is 3.745236883163452 and perplexity is 42.31903069746011
At time: 586.6472809314728 and batch: 1450, loss is 3.677164692878723 and perplexity is 39.53414357663908
At time: 587.9595561027527 and batch: 1500, loss is 3.6570509672164917 and perplexity is 38.7469083157562
At time: 589.2736105918884 and batch: 1550, loss is 3.6721640062332153 and perplexity is 39.33693920240923
At time: 590.5895237922668 and batch: 1600, loss is 3.7754298496246337 and perplexity is 43.616252716656206
At time: 591.90460729599 and batch: 1650, loss is 3.7086752605438233 and perplexity is 40.79972170960435
At time: 593.2195105552673 and batch: 1700, loss is 3.725600018501282 and perplexity is 41.49612371852421
At time: 594.5340447425842 and batch: 1750, loss is 3.7303607130050658 and perplexity is 41.69414507222473
At time: 595.8497288227081 and batch: 1800, loss is 3.6802366304397585 and perplexity is 39.655776726303785
At time: 597.1661765575409 and batch: 1850, loss is 3.7070671415328977 and perplexity is 40.73416362820919
At time: 598.4826002120972 and batch: 1900, loss is 3.7779865217208863 and perplexity is 43.727907844875205
At time: 599.798965215683 and batch: 1950, loss is 3.7163926124572755 and perplexity is 41.115805616617656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465894690225291 and perplexity of 86.99883173449551
finished 11 epochs...
Completing Train Step...
At time: 603.7640006542206 and batch: 50, loss is 3.9441046619415285 and perplexity is 51.630091026350236
At time: 605.0811767578125 and batch: 100, loss is 3.8892605447769166 and perplexity is 48.874732482021166
At time: 606.3982102870941 and batch: 150, loss is 3.8510173749923706 and perplexity is 47.04089712730475
At time: 607.7129175662994 and batch: 200, loss is 3.8434198904037475 and perplexity is 46.684858846615356
At time: 609.0282266139984 and batch: 250, loss is 3.8386027574539185 and perplexity is 46.460512461813764
At time: 610.3445224761963 and batch: 300, loss is 3.873917751312256 and perplexity is 48.13058083621183
At time: 611.6601219177246 and batch: 350, loss is 3.8755438995361327 and perplexity is 48.20891196650569
At time: 612.9759352207184 and batch: 400, loss is 3.829616832733154 and perplexity is 46.044891958288844
At time: 614.2936425209045 and batch: 450, loss is 3.85937237739563 and perplexity is 47.43557038799603
At time: 615.6169033050537 and batch: 500, loss is 3.8722735261917114 and perplexity is 48.051508350432464
At time: 616.9333097934723 and batch: 550, loss is 3.8354246854782104 and perplexity is 46.31309198969799
At time: 618.2513463497162 and batch: 600, loss is 3.8066944599151613 and perplexity is 45.00143867951515
At time: 619.5680239200592 and batch: 650, loss is 3.838520030975342 and perplexity is 46.456669106200756
At time: 620.8843476772308 and batch: 700, loss is 3.879121961593628 and perplexity is 48.381715411611296
At time: 622.1990480422974 and batch: 750, loss is 3.8314869737625123 and perplexity is 46.13108296948504
At time: 623.5130803585052 and batch: 800, loss is 3.8154516506195066 and perplexity is 45.39725545193895
At time: 624.8372359275818 and batch: 850, loss is 3.819299898147583 and perplexity is 45.572291903800284
At time: 626.1548297405243 and batch: 900, loss is 3.7927410650253295 and perplexity is 44.377876357787905
At time: 627.4717266559601 and batch: 950, loss is 3.885497360229492 and perplexity is 48.69115348146138
At time: 628.7875220775604 and batch: 1000, loss is 3.8476427793502808 and perplexity is 46.88242066823578
At time: 630.1134302616119 and batch: 1050, loss is 3.786317253112793 and perplexity is 44.0937149040216
At time: 631.4312150478363 and batch: 1100, loss is 3.8354977989196777 and perplexity is 46.31647822302642
At time: 632.748678445816 and batch: 1150, loss is 3.799965100288391 and perplexity is 44.69962446207591
At time: 634.0646197795868 and batch: 1200, loss is 3.8570217227935792 and perplexity is 47.32419669798473
At time: 635.380209684372 and batch: 1250, loss is 3.8289098501205445 and perplexity is 46.012350524744114
At time: 636.6953160762787 and batch: 1300, loss is 3.837282199859619 and perplexity is 46.39919917202272
At time: 638.0105967521667 and batch: 1350, loss is 3.7003265762329103 and perplexity is 40.460515645485174
At time: 639.3268404006958 and batch: 1400, loss is 3.730024566650391 and perplexity is 41.680132092685355
At time: 640.6437690258026 and batch: 1450, loss is 3.662329888343811 and perplexity is 38.951991020139836
At time: 641.9602990150452 and batch: 1500, loss is 3.644405150413513 and perplexity is 38.26000713171847
At time: 643.2748160362244 and batch: 1550, loss is 3.661867060661316 and perplexity is 38.93396713170641
At time: 644.5906918048859 and batch: 1600, loss is 3.7642332696914673 and perplexity is 43.13062362254637
At time: 645.9081275463104 and batch: 1650, loss is 3.696190505027771 and perplexity is 40.29351367587398
At time: 647.2250747680664 and batch: 1700, loss is 3.7129365682601927 and perplexity is 40.97395284113236
At time: 648.5440993309021 and batch: 1750, loss is 3.7213838291168213 and perplexity is 41.321536507204875
At time: 649.8603181838989 and batch: 1800, loss is 3.6722938299179075 and perplexity is 39.34204640031146
At time: 651.1752309799194 and batch: 1850, loss is 3.702323899269104 and perplexity is 40.54140912375162
At time: 652.492479801178 and batch: 1900, loss is 3.7697749090194703 and perplexity is 43.370301473385915
At time: 653.8101696968079 and batch: 1950, loss is 3.710138454437256 and perplexity is 40.859463309377
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.466679062954215 and perplexity of 87.06709801516075
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 657.7669064998627 and batch: 50, loss is 3.949084882736206 and perplexity is 51.88786162377401
At time: 659.0821988582611 and batch: 100, loss is 3.9189292860031126 and perplexity is 50.34650919633618
At time: 660.3985486030579 and batch: 150, loss is 3.8811807584762574 and perplexity is 48.481426143328946
At time: 661.7152483463287 and batch: 200, loss is 3.8688624334335326 and perplexity is 47.88787943364467
At time: 663.0401754379272 and batch: 250, loss is 3.853303461074829 and perplexity is 47.14855968358084
At time: 664.3551678657532 and batch: 300, loss is 3.895259690284729 and perplexity is 49.16882036983992
At time: 665.6699676513672 and batch: 350, loss is 3.9242002391815185 and perplexity is 50.61258390664823
At time: 666.9859502315521 and batch: 400, loss is 3.8529869413375852 and perplexity is 47.13363859539241
At time: 668.3023521900177 and batch: 450, loss is 3.870946698188782 and perplexity is 47.987794541550215
At time: 669.6182806491852 and batch: 500, loss is 3.875380764007568 and perplexity is 48.20104802163235
At time: 670.9311990737915 and batch: 550, loss is 3.8429085636138915 and perplexity is 46.66099372956325
At time: 672.244663476944 and batch: 600, loss is 3.8284919834136963 and perplexity is 45.99312751196423
At time: 673.5596165657043 and batch: 650, loss is 3.874381256103516 and perplexity is 48.15289476194178
At time: 674.875919342041 and batch: 700, loss is 3.9114223098754883 and perplexity is 49.96997424143979
At time: 676.1936464309692 and batch: 750, loss is 3.8365716218948362 and perplexity is 46.36624063469948
At time: 677.5093114376068 and batch: 800, loss is 3.816887640953064 and perplexity is 45.46249230046967
At time: 678.8229782581329 and batch: 850, loss is 3.8224835062026976 and perplexity is 45.71760741046864
At time: 680.1384196281433 and batch: 900, loss is 3.811535987854004 and perplexity is 45.21984268008269
At time: 681.4549753665924 and batch: 950, loss is 3.91776132106781 and perplexity is 50.28774056551076
At time: 682.7704522609711 and batch: 1000, loss is 3.863901834487915 and perplexity is 47.65091509786101
At time: 684.0902895927429 and batch: 1050, loss is 3.7874823331832888 and perplexity is 44.14511755077551
At time: 685.4090354442596 and batch: 1100, loss is 3.833480019569397 and perplexity is 46.22311601353598
At time: 686.7238318920135 and batch: 1150, loss is 3.813192648887634 and perplexity is 45.294818719191085
At time: 688.0400025844574 and batch: 1200, loss is 3.8722524404525758 and perplexity is 48.05049515954429
At time: 689.3571326732635 and batch: 1250, loss is 3.8375613069534302 and perplexity is 46.4121513250936
At time: 690.673259973526 and batch: 1300, loss is 3.8461496162414552 and perplexity is 46.81246980426278
At time: 691.9881196022034 and batch: 1350, loss is 3.705979766845703 and perplexity is 40.68989440275535
At time: 693.3036379814148 and batch: 1400, loss is 3.7286058855056763 and perplexity is 41.62104319923622
At time: 694.6192383766174 and batch: 1450, loss is 3.655596923828125 and perplexity is 38.69060957022848
At time: 695.9359533786774 and batch: 1500, loss is 3.6389963912963865 and perplexity is 38.053626603737314
At time: 697.2520558834076 and batch: 1550, loss is 3.6594911575317384 and perplexity is 38.84157359985486
At time: 698.5668277740479 and batch: 1600, loss is 3.763409433364868 and perplexity is 43.095105680511544
At time: 699.881379365921 and batch: 1650, loss is 3.6995468187332152 and perplexity is 40.428978552209514
At time: 701.1973962783813 and batch: 1700, loss is 3.7083094120025635 and perplexity is 40.78479792102268
At time: 702.5145182609558 and batch: 1750, loss is 3.7108530139923097 and perplexity is 40.88867026311027
At time: 703.8315596580505 and batch: 1800, loss is 3.6662789821624755 and perplexity is 39.10612022213349
At time: 705.1485152244568 and batch: 1850, loss is 3.6976275300979613 and perplexity is 40.351458089007984
At time: 706.4636707305908 and batch: 1900, loss is 3.7672962236404417 and perplexity is 43.262933262218816
At time: 707.7792534828186 and batch: 1950, loss is 3.711461458206177 and perplexity is 40.91355630806187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.449439044331395 and perplexity of 85.57892455222778
finished 13 epochs...
Completing Train Step...
At time: 711.7380714416504 and batch: 50, loss is 3.975590386390686 and perplexity is 53.28156433221208
At time: 713.0509171485901 and batch: 100, loss is 3.92354154586792 and perplexity is 50.57925671344963
At time: 714.3663375377655 and batch: 150, loss is 3.87774450302124 and perplexity is 48.315117481445846
At time: 715.6844024658203 and batch: 200, loss is 3.8521170663833617 and perplexity is 47.0926560511055
At time: 717.0011835098267 and batch: 250, loss is 3.83597354888916 and perplexity is 46.33851852854918
At time: 718.3175570964813 and batch: 300, loss is 3.8878356075286864 and perplexity is 48.805138650407244
At time: 719.6328699588776 and batch: 350, loss is 3.919002356529236 and perplexity is 50.3501881766625
At time: 720.9474165439606 and batch: 400, loss is 3.841258945465088 and perplexity is 46.58408436045204
At time: 722.2637739181519 and batch: 450, loss is 3.857104654312134 and perplexity is 47.3281215282251
At time: 723.5812821388245 and batch: 500, loss is 3.8646990203857423 and perplexity is 47.68891688062572
At time: 724.8988769054413 and batch: 550, loss is 3.8325486850738524 and perplexity is 46.1800868714734
At time: 726.2171206474304 and batch: 600, loss is 3.8140517187118532 and perplexity is 45.333746849743264
At time: 727.5321760177612 and batch: 650, loss is 3.857956581115723 and perplexity is 47.36845880328174
At time: 728.8583698272705 and batch: 700, loss is 3.9007510900497437 and perplexity is 49.439568731832246
At time: 730.1755819320679 and batch: 750, loss is 3.8257266235351564 and perplexity is 45.86611566013422
At time: 731.4933862686157 and batch: 800, loss is 3.8046939516067506 and perplexity is 44.91150291616107
At time: 732.8090376853943 and batch: 850, loss is 3.8097408056259154 and perplexity is 45.13873764308824
At time: 734.124103307724 and batch: 900, loss is 3.7994106245040893 and perplexity is 44.67484647277665
At time: 735.4381215572357 and batch: 950, loss is 3.903963041305542 and perplexity is 49.59862151485897
At time: 736.755859375 and batch: 1000, loss is 3.8493171405792235 and perplexity is 46.96098452950893
At time: 738.0743560791016 and batch: 1050, loss is 3.7760256481170655 and perplexity is 43.64224695716603
At time: 739.3903238773346 and batch: 1100, loss is 3.8257795572280884 and perplexity is 45.86854358727557
At time: 740.7055494785309 and batch: 1150, loss is 3.8042038774490354 and perplexity is 44.8894983415748
At time: 742.0201098918915 and batch: 1200, loss is 3.8630878210067747 and perplexity is 47.61214239347567
At time: 743.3385529518127 and batch: 1250, loss is 3.8319361925125124 and perplexity is 46.15181057217806
At time: 744.6591753959656 and batch: 1300, loss is 3.846213974952698 and perplexity is 46.8154826914412
At time: 745.9760868549347 and batch: 1350, loss is 3.7095552349090575 and perplexity is 40.835640220183954
At time: 747.2919549942017 and batch: 1400, loss is 3.7289920902252196 and perplexity is 41.63712054692603
At time: 748.6059744358063 and batch: 1450, loss is 3.6524455165863037 and perplexity is 38.56887162670879
At time: 749.9208490848541 and batch: 1500, loss is 3.634003143310547 and perplexity is 37.86408900725932
At time: 751.2379243373871 and batch: 1550, loss is 3.654663815498352 and perplexity is 38.65452387870248
At time: 752.5554909706116 and batch: 1600, loss is 3.7582075548172 and perplexity is 42.87151223193879
At time: 753.8691778182983 and batch: 1650, loss is 3.6937461519241332 and perplexity is 40.195142376738644
At time: 755.1821575164795 and batch: 1700, loss is 3.7058717393875122 and perplexity is 40.68549901430457
At time: 756.4964139461517 and batch: 1750, loss is 3.710014328956604 and perplexity is 40.85439192360515
At time: 757.8124604225159 and batch: 1800, loss is 3.6670228576660158 and perplexity is 39.135221129389336
At time: 759.1310927867889 and batch: 1850, loss is 3.699364032745361 and perplexity is 40.421589376766356
At time: 760.4511671066284 and batch: 1900, loss is 3.770105686187744 and perplexity is 43.384649751805085
At time: 761.7671985626221 and batch: 1950, loss is 3.7112066745758057 and perplexity is 40.903133531487114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.454358194040697 and perplexity of 86.00093721480508
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 765.7026925086975 and batch: 50, loss is 3.9852217197418214 and perplexity is 53.797216060517115
At time: 767.0294198989868 and batch: 100, loss is 3.9836968326568605 and perplexity is 53.71524389557143
At time: 768.3460547924042 and batch: 150, loss is 3.9775857496261597 and perplexity is 53.387986546986724
At time: 769.6703503131866 and batch: 200, loss is 3.9715155124664308 and perplexity is 53.06489043429472
At time: 770.9851703643799 and batch: 250, loss is 3.9581996965408326 and perplexity is 52.36297180226689
At time: 772.3018119335175 and batch: 300, loss is 3.9635992288589477 and perplexity is 52.646472056391985
At time: 773.6200048923492 and batch: 350, loss is 3.9975471687316895 and perplexity is 54.464394090990204
At time: 774.9358325004578 and batch: 400, loss is 3.9481654071807863 and perplexity is 51.840173930581784
At time: 776.2508547306061 and batch: 450, loss is 3.9519890356063843 and perplexity is 52.03877093182078
At time: 777.564938545227 and batch: 500, loss is 3.943683180809021 and perplexity is 51.60833450241724
At time: 778.8794710636139 and batch: 550, loss is 3.8943786430358887 and perplexity is 49.12551939382824
At time: 780.1951098442078 and batch: 600, loss is 3.8538019275665283 and perplexity is 47.17206751916242
At time: 781.5099937915802 and batch: 650, loss is 3.8979354190826414 and perplexity is 49.30055896824484
At time: 782.8247005939484 and batch: 700, loss is 3.9653464221954344 and perplexity is 52.73853602491443
At time: 784.147029876709 and batch: 750, loss is 3.889062237739563 and perplexity is 48.865041239573756
At time: 785.475982427597 and batch: 800, loss is 3.8536314296722414 and perplexity is 47.164025466577236
At time: 786.7984669208527 and batch: 850, loss is 3.8472886276245117 and perplexity is 46.8658201177782
At time: 788.1140570640564 and batch: 900, loss is 3.832567820549011 and perplexity is 46.180970557833405
At time: 789.4323980808258 and batch: 950, loss is 3.960239763259888 and perplexity is 52.46990479648607
At time: 790.7521302700043 and batch: 1000, loss is 3.90922758102417 and perplexity is 49.86042395783033
At time: 792.0663876533508 and batch: 1050, loss is 3.8211809825897216 and perplexity is 45.65809791196473
At time: 793.3953983783722 and batch: 1100, loss is 3.8297226524353025 and perplexity is 46.04976467285138
At time: 794.7112646102905 and batch: 1150, loss is 3.808957743644714 and perplexity is 45.103405049371396
At time: 796.0243182182312 and batch: 1200, loss is 3.8713916444778445 and perplexity is 48.009151283600985
At time: 797.3386068344116 and batch: 1250, loss is 3.8497627639770506 and perplexity is 46.98191610645411
At time: 798.6538121700287 and batch: 1300, loss is 3.8855113983154297 and perplexity is 48.69183701685611
At time: 799.9706387519836 and batch: 1350, loss is 3.7741721534729002 and perplexity is 43.56143120508989
At time: 801.2879509925842 and batch: 1400, loss is 3.808586292266846 and perplexity is 45.086654438630575
At time: 802.6055798530579 and batch: 1450, loss is 3.7370372676849364 and perplexity is 41.97344967030901
At time: 803.9264779090881 and batch: 1500, loss is 3.7276597023010254 and perplexity is 41.581680692209225
At time: 805.2432341575623 and batch: 1550, loss is 3.7293896484375 and perplexity is 41.65367701699742
At time: 806.5594873428345 and batch: 1600, loss is 3.806892657279968 and perplexity is 45.01035873000999
At time: 807.8771512508392 and batch: 1650, loss is 3.7232594680786133 and perplexity is 41.39911352153107
At time: 809.195250749588 and batch: 1700, loss is 3.718985438346863 and perplexity is 41.22255006697758
At time: 810.5126850605011 and batch: 1750, loss is 3.72373863697052 and perplexity is 41.41895544231905
At time: 811.8272271156311 and batch: 1800, loss is 3.67881516456604 and perplexity is 39.59944743755712
At time: 813.1430904865265 and batch: 1850, loss is 3.722268891334534 and perplexity is 41.358124827026565
At time: 814.4611685276031 and batch: 1900, loss is 3.8130036115646364 and perplexity is 45.2862571171714
At time: 815.7783551216125 and batch: 1950, loss is 3.772018299102783 and perplexity is 43.46770719628605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425878054596657 and perplexity of 83.58616822907365
finished 15 epochs...
Completing Train Step...
At time: 819.7014508247375 and batch: 50, loss is 4.019468092918396 and perplexity is 55.67148589237798
At time: 821.0284793376923 and batch: 100, loss is 3.983481402397156 and perplexity is 53.70367325300693
At time: 822.3455591201782 and batch: 150, loss is 3.953045606613159 and perplexity is 52.09378264518857
At time: 823.6626009941101 and batch: 200, loss is 3.9421613121032717 and perplexity is 51.529853127503856
At time: 824.9779870510101 and batch: 250, loss is 3.927779312133789 and perplexity is 50.79405459144651
At time: 826.3042690753937 and batch: 300, loss is 3.9314176082611083 and perplexity is 50.979194997139615
At time: 827.619622707367 and batch: 350, loss is 3.9620503759384156 and perplexity is 52.56499352980721
At time: 828.9448022842407 and batch: 400, loss is 3.920551176071167 and perplexity is 50.42823195431318
At time: 830.2692468166351 and batch: 450, loss is 3.9253100681304933 and perplexity is 50.66878639925809
At time: 831.5858409404755 and batch: 500, loss is 3.927327523231506 and perplexity is 50.77111158436838
At time: 832.8997721672058 and batch: 550, loss is 3.8848602104187013 and perplexity is 48.660139803462215
At time: 834.214839220047 and batch: 600, loss is 3.849024248123169 and perplexity is 46.947232025511994
At time: 835.5313613414764 and batch: 650, loss is 3.895457968711853 and perplexity is 49.17857045278999
At time: 836.8482217788696 and batch: 700, loss is 3.9647728538513185 and perplexity is 52.70829554345601
At time: 838.1663208007812 and batch: 750, loss is 3.890290322303772 and perplexity is 48.9250885064634
At time: 839.4825041294098 and batch: 800, loss is 3.8507601261138915 and perplexity is 47.02879746565502
At time: 840.7977776527405 and batch: 850, loss is 3.8417591428756714 and perplexity is 46.60739142740486
At time: 842.1139986515045 and batch: 900, loss is 3.830349907875061 and perplexity is 46.07865869926228
At time: 843.4327616691589 and batch: 950, loss is 3.9619735622406007 and perplexity is 52.560955973350374
At time: 844.7508118152618 and batch: 1000, loss is 3.9131567525863646 and perplexity is 50.056719504624
At time: 846.0673048496246 and batch: 1050, loss is 3.8229744052886963 and perplexity is 45.74005565162021
At time: 847.3833303451538 and batch: 1100, loss is 3.8243959951400757 and perplexity is 45.80512549088925
At time: 848.6995046138763 and batch: 1150, loss is 3.797907147407532 and perplexity is 44.607729331497836
At time: 850.017439365387 and batch: 1200, loss is 3.8633712911605835 and perplexity is 47.62564092792854
At time: 851.3342568874359 and batch: 1250, loss is 3.8440350914001464 and perplexity is 46.71358825456863
At time: 852.6494052410126 and batch: 1300, loss is 3.8794363164901733 and perplexity is 48.3969268315211
At time: 853.9632782936096 and batch: 1350, loss is 3.7683322858810424 and perplexity is 43.30777958156689
At time: 855.2802264690399 and batch: 1400, loss is 3.803468008041382 and perplexity is 44.856477683956264
At time: 856.598922252655 and batch: 1450, loss is 3.7306590461730957 and perplexity is 41.70658567424226
At time: 857.9155843257904 and batch: 1500, loss is 3.722078700065613 and perplexity is 41.350259620756006
At time: 859.2330651283264 and batch: 1550, loss is 3.725338411331177 and perplexity is 41.48526945486638
At time: 860.5480878353119 and batch: 1600, loss is 3.805206089019775 and perplexity is 44.9345096678859
At time: 861.863687992096 and batch: 1650, loss is 3.723986406326294 and perplexity is 41.4292190616785
At time: 863.1808838844299 and batch: 1700, loss is 3.715589542388916 and perplexity is 41.08279999847631
At time: 864.5039703845978 and batch: 1750, loss is 3.7180377769470216 and perplexity is 41.18350355183587
At time: 865.8238298892975 and batch: 1800, loss is 3.6736310815811155 and perplexity is 39.394691809529576
At time: 867.1395757198334 and batch: 1850, loss is 3.7198222732543944 and perplexity is 41.25706097380288
At time: 868.454521894455 and batch: 1900, loss is 3.8121684122085573 and perplexity is 45.24844985488619
At time: 869.7721300125122 and batch: 1950, loss is 3.7728288269042967 and perplexity is 43.50295326346577
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.42198117278343 and perplexity of 83.2610766434032
finished 16 epochs...
Completing Train Step...
At time: 873.70183801651 and batch: 50, loss is 4.011421709060669 and perplexity is 55.22532912842238
At time: 875.035213470459 and batch: 100, loss is 3.967866311073303 and perplexity is 52.87159885664292
At time: 876.3526878356934 and batch: 150, loss is 3.9396815395355222 and perplexity is 51.402229115959074
At time: 877.6671049594879 and batch: 200, loss is 3.933523063659668 and perplexity is 51.086642491721946
At time: 878.9821100234985 and batch: 250, loss is 3.9216160488128664 and perplexity is 50.481960205731504
At time: 880.2976994514465 and batch: 300, loss is 3.9271239948272707 and perplexity is 50.760779272541484
At time: 881.6117858886719 and batch: 350, loss is 3.9600332832336425 and perplexity is 52.459071927590614
At time: 882.9255464076996 and batch: 400, loss is 3.9093440914154054 and perplexity is 49.86623355376539
At time: 884.2552192211151 and batch: 450, loss is 3.917050766944885 and perplexity is 50.252021095930395
At time: 885.5754699707031 and batch: 500, loss is 3.92331916809082 and perplexity is 50.5680102613012
At time: 886.8996934890747 and batch: 550, loss is 3.880152406692505 and perplexity is 48.4315958082239
At time: 888.2152509689331 and batch: 600, loss is 3.846767072677612 and perplexity is 46.84138339055719
At time: 889.5350620746613 and batch: 650, loss is 3.8910832738876344 and perplexity is 48.963899118319695
At time: 890.8494260311127 and batch: 700, loss is 3.9575491046905515 and perplexity is 52.32891595898412
At time: 892.1756510734558 and batch: 750, loss is 3.8840358734130858 and perplexity is 48.620043978030665
At time: 893.4921703338623 and batch: 800, loss is 3.8448769521713255 and perplexity is 46.75293115029781
At time: 894.8087050914764 and batch: 850, loss is 3.8398114919662474 and perplexity is 46.51670484067907
At time: 896.1230564117432 and batch: 900, loss is 3.8318217992782593 and perplexity is 46.14653141925552
At time: 897.4381387233734 and batch: 950, loss is 3.9669281101226805 and perplexity is 52.82201793440572
At time: 898.7542541027069 and batch: 1000, loss is 3.9191970729827883 and perplexity is 50.35999314130295
At time: 900.0792067050934 and batch: 1050, loss is 3.8280273246765137 and perplexity is 45.97176136778266
At time: 901.4055116176605 and batch: 1100, loss is 3.824766445159912 and perplexity is 45.822097143916466
At time: 902.7201383113861 and batch: 1150, loss is 3.793246283531189 and perplexity is 44.400302546760436
At time: 904.0378329753876 and batch: 1200, loss is 3.858142809867859 and perplexity is 47.37728099370255
At time: 905.3553919792175 and batch: 1250, loss is 3.839552364349365 and perplexity is 46.50465263940503
At time: 906.672749042511 and batch: 1300, loss is 3.8753570127487182 and perplexity is 48.19990319965949
At time: 907.9902827739716 and batch: 1350, loss is 3.764706358909607 and perplexity is 43.151033082920996
At time: 909.305388212204 and batch: 1400, loss is 3.8000885391235353 and perplexity is 44.70514247221225
At time: 910.6213014125824 and batch: 1450, loss is 3.726484670639038 and perplexity is 41.53284959549802
At time: 911.9372565746307 and batch: 1500, loss is 3.7174103546142576 and perplexity is 41.157672206394885
At time: 913.2545695304871 and batch: 1550, loss is 3.7232323265075684 and perplexity is 41.39798989979873
At time: 914.5717778205872 and batch: 1600, loss is 3.805857138633728 and perplexity is 44.963773788221786
At time: 915.8882572650909 and batch: 1650, loss is 3.7247524881362915 and perplexity is 41.46096939292686
At time: 917.2032670974731 and batch: 1700, loss is 3.712623481750488 and perplexity is 40.96112645723719
At time: 918.5171196460724 and batch: 1750, loss is 3.7131957101821897 and perplexity is 40.98457228593567
At time: 919.8306727409363 and batch: 1800, loss is 3.6697571802139284 and perplexity is 39.24237587800155
At time: 921.1558825969696 and batch: 1850, loss is 3.7185883951187133 and perplexity is 41.206186181426375
At time: 922.4898562431335 and batch: 1900, loss is 3.8136817598342896 and perplexity is 45.31697832966567
At time: 923.8183572292328 and batch: 1950, loss is 3.7755712127685546 and perplexity is 43.62241888309035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.417266987645349 and perplexity of 82.86949223919865
finished 17 epochs...
Completing Train Step...
At time: 927.7663888931274 and batch: 50, loss is 4.009670248031616 and perplexity is 55.12868877225079
At time: 929.0797986984253 and batch: 100, loss is 3.9594232177734376 and perplexity is 52.42707821985349
At time: 930.3923914432526 and batch: 150, loss is 3.926421809196472 and perplexity is 50.72514829397277
At time: 931.7042088508606 and batch: 200, loss is 3.9213954114913943 and perplexity is 50.470823229910486
At time: 933.0161528587341 and batch: 250, loss is 3.910030927658081 and perplexity is 49.90049525499801
At time: 934.3291308879852 and batch: 300, loss is 3.91642071723938 and perplexity is 50.22036979683073
At time: 935.6430556774139 and batch: 350, loss is 3.9586640214920044 and perplexity is 52.387290882133044
At time: 936.9557735919952 and batch: 400, loss is 3.9111335468292237 and perplexity is 49.95554684260614
At time: 938.2672038078308 and batch: 450, loss is 3.9205097007751464 and perplexity is 50.426140471837805
At time: 939.5803921222687 and batch: 500, loss is 3.924165062904358 and perplexity is 50.61080357568182
At time: 940.8934235572815 and batch: 550, loss is 3.8788624238967895 and perplexity is 48.36916016197504
At time: 942.2076277732849 and batch: 600, loss is 3.84111620426178 and perplexity is 46.5774353667494
At time: 943.5208961963654 and batch: 650, loss is 3.8779431581497192 and perplexity is 48.32471648073026
At time: 944.8320293426514 and batch: 700, loss is 3.938664183616638 and perplexity is 51.34996134589488
At time: 946.1437835693359 and batch: 750, loss is 3.8624977397918703 and perplexity is 47.5840556501927
At time: 947.4561052322388 and batch: 800, loss is 3.8273578882217407 and perplexity is 45.94099649354604
At time: 948.7766625881195 and batch: 850, loss is 3.8286657190322875 and perplexity is 46.00111885059344
At time: 950.0915975570679 and batch: 900, loss is 3.8290336894989014 and perplexity is 46.018049018471515
At time: 951.4037275314331 and batch: 950, loss is 3.9674994373321533 and perplexity is 52.852205213096624
At time: 952.7157564163208 and batch: 1000, loss is 3.921480107307434 and perplexity is 50.475098078498476
At time: 954.0409791469574 and batch: 1050, loss is 3.829006772041321 and perplexity is 46.016810346260144
At time: 955.3566362857819 and batch: 1100, loss is 3.8248249959945677 and perplexity is 45.824780144495115
At time: 956.6832513809204 and batch: 1150, loss is 3.7909076833724975 and perplexity is 44.296589311340774
At time: 957.9997339248657 and batch: 1200, loss is 3.854952473640442 and perplexity is 47.22637239038263
At time: 959.3136682510376 and batch: 1250, loss is 3.8362063360214234 and perplexity is 46.34930679502686
At time: 960.6285245418549 and batch: 1300, loss is 3.8719542837142944 and perplexity is 48.03617071620549
At time: 961.9456412792206 and batch: 1350, loss is 3.7629576921463013 and perplexity is 43.075642241506976
At time: 963.2618734836578 and batch: 1400, loss is 3.7991166639328005 and perplexity is 44.66171575943582
At time: 964.5786566734314 and batch: 1450, loss is 3.725585994720459 and perplexity is 41.495541790060614
At time: 965.9006009101868 and batch: 1500, loss is 3.7178311109542848 and perplexity is 41.174993201620225
At time: 967.2180111408234 and batch: 1550, loss is 3.7242313861846923 and perplexity is 41.439369629189315
At time: 968.5437242984772 and batch: 1600, loss is 3.8079312801361085 and perplexity is 45.057131802936695
At time: 969.8739051818848 and batch: 1650, loss is 3.7258755111694337 and perplexity is 41.507557171209264
At time: 971.2006306648254 and batch: 1700, loss is 3.712026071548462 and perplexity is 40.936663170441285
At time: 972.5279965400696 and batch: 1750, loss is 3.710574736595154 and perplexity is 40.87729345340421
At time: 973.8462612628937 and batch: 1800, loss is 3.6674156379699707 and perplexity is 39.15059569265504
At time: 975.1625139713287 and batch: 1850, loss is 3.716511902809143 and perplexity is 41.12071062809144
At time: 976.4795091152191 and batch: 1900, loss is 3.8152908945083617 and perplexity is 45.38995815225432
At time: 977.7963361740112 and batch: 1950, loss is 3.779941511154175 and perplexity is 43.81347906080891
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.414229424055232 and perplexity of 82.61815280984578
finished 18 epochs...
Completing Train Step...
At time: 981.7256541252136 and batch: 50, loss is 4.011946482658386 and perplexity is 55.254317528582476
At time: 983.0410866737366 and batch: 100, loss is 3.9527109146118162 and perplexity is 52.07635019023188
At time: 984.3634667396545 and batch: 150, loss is 3.9117804670333864 and perplexity is 49.98787455076496
At time: 985.6799347400665 and batch: 200, loss is 3.9104924535751344 and perplexity is 49.92353094220643
At time: 986.9943778514862 and batch: 250, loss is 3.899511694908142 and perplexity is 49.37833152692913
At time: 988.3090815544128 and batch: 300, loss is 3.9079643535614013 and perplexity is 49.79747866646223
At time: 989.6385364532471 and batch: 350, loss is 3.953882293701172 and perplexity is 52.137387079583405
At time: 990.9569282531738 and batch: 400, loss is 3.9075022077560426 and perplexity is 49.77447028760149
At time: 992.2726447582245 and batch: 450, loss is 3.932499189376831 and perplexity is 51.034362960679005
At time: 993.5883281230927 and batch: 500, loss is 3.9373625707626343 and perplexity is 51.28316705573801
At time: 994.9025602340698 and batch: 550, loss is 3.8958267688751222 and perplexity is 49.19671086248975
At time: 996.2182941436768 and batch: 600, loss is 3.8480426406860353 and perplexity is 46.90117088408093
At time: 997.5356886386871 and batch: 650, loss is 3.866228504180908 and perplexity is 47.761912114487366
At time: 998.8515291213989 and batch: 700, loss is 3.9181133270263673 and perplexity is 50.30544526572936
At time: 1000.1672201156616 and batch: 750, loss is 3.8437509965896606 and perplexity is 46.70031905151144
At time: 1001.4812424182892 and batch: 800, loss is 3.8166933107376098 and perplexity is 45.4536584229183
At time: 1002.7968378067017 and batch: 850, loss is 3.8248890113830565 and perplexity is 45.82771372949477
At time: 1004.1132273674011 and batch: 900, loss is 3.8279850482940674 and perplexity is 45.969817889099254
At time: 1005.4302306175232 and batch: 950, loss is 3.9669617080688475 and perplexity is 52.82379267553438
At time: 1006.7453298568726 and batch: 1000, loss is 3.920609502792358 and perplexity is 50.431173353518794
At time: 1008.0577044487 and batch: 1050, loss is 3.8282178163528444 and perplexity is 45.98051943981291
At time: 1009.3813548088074 and batch: 1100, loss is 3.823330807685852 and perplexity is 45.7563604224576
At time: 1010.6973440647125 and batch: 1150, loss is 3.7894067049026487 and perplexity is 44.23015095823895
At time: 1012.0142724514008 and batch: 1200, loss is 3.8530955600738523 and perplexity is 47.13875846970442
At time: 1013.3298985958099 and batch: 1250, loss is 3.8338270235061644 and perplexity is 46.239158399986984
At time: 1014.64528465271 and batch: 1300, loss is 3.8668551635742188 and perplexity is 47.79185194541474
At time: 1015.9594566822052 and batch: 1350, loss is 3.7594333362579344 and perplexity is 42.92409555721699
At time: 1017.2787880897522 and batch: 1400, loss is 3.79960645198822 and perplexity is 44.683595892225775
At time: 1018.5978178977966 and batch: 1450, loss is 3.726651029586792 and perplexity is 41.539759531402844
At time: 1019.9143254756927 and batch: 1500, loss is 3.7184716129302977 and perplexity is 41.201374313803534
At time: 1021.2292263507843 and batch: 1550, loss is 3.7230422782897947 and perplexity is 41.39012303316453
At time: 1022.5439178943634 and batch: 1600, loss is 3.8058753299713133 and perplexity is 44.964591746849734
At time: 1023.859379529953 and batch: 1650, loss is 3.723346161842346 and perplexity is 41.40270272207586
At time: 1025.1759634017944 and batch: 1700, loss is 3.7125803661346435 and perplexity is 40.95936043111622
At time: 1026.4943182468414 and batch: 1750, loss is 3.7100789833068846 and perplexity is 40.85703342316238
At time: 1027.8100852966309 and batch: 1800, loss is 3.6661611795425415 and perplexity is 39.10151369005197
At time: 1029.1247437000275 and batch: 1850, loss is 3.7134892177581786 and perplexity is 40.99660333391575
At time: 1030.4396097660065 and batch: 1900, loss is 3.8138323402404786 and perplexity is 45.323802692464575
At time: 1031.755867242813 and batch: 1950, loss is 3.779360466003418 and perplexity is 43.78802884584086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.412440384265988 and perplexity of 82.47047778479111
finished 19 epochs...
Completing Train Step...
At time: 1035.6899244785309 and batch: 50, loss is 4.01844829082489 and perplexity is 55.61474093374799
At time: 1037.004412651062 and batch: 100, loss is 3.9576474714279173 and perplexity is 52.33406363689288
At time: 1038.3193652629852 and batch: 150, loss is 3.905134439468384 and perplexity is 49.6567552912329
At time: 1039.6365926265717 and batch: 200, loss is 3.903247480392456 and perplexity is 49.56314337485892
At time: 1040.9531800746918 and batch: 250, loss is 3.887865252494812 and perplexity is 48.80658549853506
At time: 1042.2688782215118 and batch: 300, loss is 3.896975569725037 and perplexity is 49.25326056169358
At time: 1043.5891571044922 and batch: 350, loss is 3.944405369758606 and perplexity is 51.64561893288271
At time: 1044.9042270183563 and batch: 400, loss is 3.9089983224868776 and perplexity is 49.848994340183744
At time: 1046.2207870483398 and batch: 450, loss is 3.9384816312789916 and perplexity is 51.340588145988946
At time: 1047.5386290550232 and batch: 500, loss is 3.955574803352356 and perplexity is 52.22570482864162
At time: 1048.8583645820618 and batch: 550, loss is 3.915306887626648 and perplexity is 50.1644640023332
At time: 1050.1746661663055 and batch: 600, loss is 3.8606546783447264 and perplexity is 47.496436080653126
At time: 1051.4899215698242 and batch: 650, loss is 3.8634043598175047 and perplexity is 47.62721586994951
At time: 1052.8080022335052 and batch: 700, loss is 3.905580201148987 and perplexity is 49.67889530414289
At time: 1054.1220512390137 and batch: 750, loss is 3.8326893997192384 and perplexity is 46.186585543239836
At time: 1055.4479775428772 and batch: 800, loss is 3.810656771659851 and perplexity is 45.18010213492676
At time: 1056.7624053955078 and batch: 850, loss is 3.821415891647339 and perplexity is 45.66882467257512
At time: 1058.0770328044891 and batch: 900, loss is 3.824236478805542 and perplexity is 45.79781940790337
At time: 1059.392709493637 and batch: 950, loss is 3.9632866477966306 and perplexity is 52.63001833792373
At time: 1060.7091987133026 and batch: 1000, loss is 3.916259837150574 and perplexity is 50.21229098915502
At time: 1062.024477481842 and batch: 1050, loss is 3.82448317527771 and perplexity is 45.809118962107064
At time: 1063.348560810089 and batch: 1100, loss is 3.8205420207977294 and perplexity is 45.628933450384515
At time: 1064.6635155677795 and batch: 1150, loss is 3.7878145027160643 and perplexity is 44.15978364952741
At time: 1065.979364156723 and batch: 1200, loss is 3.8516545820236208 and perplexity is 47.07088146981297
At time: 1067.2953081130981 and batch: 1250, loss is 3.8322185707092284 and perplexity is 46.16484467740957
At time: 1068.6128714084625 and batch: 1300, loss is 3.863899002075195 and perplexity is 47.650780130994114
At time: 1069.9335629940033 and batch: 1350, loss is 3.7540816831588746 and perplexity is 42.69499427030171
At time: 1071.2487213611603 and batch: 1400, loss is 3.795738296508789 and perplexity is 44.511086657304965
At time: 1072.5642139911652 and batch: 1450, loss is 3.7245124435424803 and perplexity is 41.45101810579405
At time: 1073.8806881904602 and batch: 1500, loss is 3.720725865364075 and perplexity is 41.29435737639732
At time: 1075.1960809230804 and batch: 1550, loss is 3.7257119369506837 and perplexity is 41.500768160241485
At time: 1076.5124008655548 and batch: 1600, loss is 3.80435480594635 and perplexity is 44.896273957408596
At time: 1077.8273296356201 and batch: 1650, loss is 3.7206954908370973 and perplexity is 41.29310309887431
At time: 1079.14226770401 and batch: 1700, loss is 3.7112350988388063 and perplexity is 40.90429618943593
At time: 1080.4583902359009 and batch: 1750, loss is 3.7082984590530397 and perplexity is 40.78435120963612
At time: 1081.7743062973022 and batch: 1800, loss is 3.6643234300613403 and perplexity is 39.02972089234788
At time: 1083.0906691551208 and batch: 1850, loss is 3.710289325714111 and perplexity is 40.86562829382595
At time: 1084.40598320961 and batch: 1900, loss is 3.810731201171875 and perplexity is 45.183464993028245
At time: 1085.724173784256 and batch: 1950, loss is 3.7767438554763793 and perplexity is 43.673602398614236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411048214934593 and perplexity of 82.35574479727755
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f00fbd17b38>
ELAPSED
4463.089378833771


RESULTS SO FAR:
[{'params': {'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}, 'best_accuracy': -78.33907429225935}, {'params': {'dropout': 0.16802636512990798, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.23001756521426064}, 'best_accuracy': -77.64523175401864}, {'params': {'dropout': 0.7990403138855218, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.10718988942097152}, 'best_accuracy': -77.79230466527649}, {'params': {'dropout': 0.7943354117872055, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.9645103263983709}, 'best_accuracy': -82.35574479727755}]
SETTINGS FOR THIS RUN
{'dropout': 0.37534925793438456, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.7617994495357929}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9442713260650635 and batch: 50, loss is 7.6970712852478025 and perplexity is 2201.8898322153022
At time: 3.482954502105713 and batch: 100, loss is 6.7275651168823245 and perplexity is 835.1113897753656
At time: 5.017086982727051 and batch: 150, loss is 6.452117280960083 and perplexity is 634.043320495444
At time: 6.550415992736816 and batch: 200, loss is 6.277516756057739 and perplexity is 532.4647808022283
At time: 8.081559658050537 and batch: 250, loss is 6.198077840805054 and perplexity is 491.8028086891127
At time: 9.613966941833496 and batch: 300, loss is 6.109742012023926 and perplexity is 450.22254817943417
At time: 11.148207902908325 and batch: 350, loss is 6.065363330841064 and perplexity is 430.6791282587156
At time: 12.68222713470459 and batch: 400, loss is 6.004639835357666 and perplexity is 405.30498591916285
At time: 14.216735601425171 and batch: 450, loss is 5.933703937530518 and perplexity is 377.55035009513523
At time: 15.747110843658447 and batch: 500, loss is 5.9089333438873295 and perplexity is 368.313082409038
At time: 17.281737565994263 and batch: 550, loss is 5.853835382461548 and perplexity is 348.56871433631864
At time: 18.816994190216064 and batch: 600, loss is 5.894253568649292 and perplexity is 362.94582062521164
At time: 20.351760625839233 and batch: 650, loss is 5.976840219497681 and perplexity is 394.1928353930151
At time: 21.884847402572632 and batch: 700, loss is 5.877572374343872 and perplexity is 356.9416683114768
At time: 23.41789484024048 and batch: 750, loss is 5.821718435287476 and perplexity is 337.5516161256227
At time: 24.95420479774475 and batch: 800, loss is 5.816985464096069 and perplexity is 335.95776884283913
At time: 26.49205255508423 and batch: 850, loss is 5.849964399337768 and perplexity is 347.2220189248809
At time: 28.026047229766846 and batch: 900, loss is 5.836228618621826 and perplexity is 342.485259432157
At time: 29.55936050415039 and batch: 950, loss is 5.862885246276855 and perplexity is 351.73753078283545
At time: 31.095471143722534 and batch: 1000, loss is 5.83337592124939 and perplexity is 341.50964486065874
At time: 32.63097882270813 and batch: 1050, loss is 5.729041719436646 and perplexity is 307.67428877259874
At time: 34.17228102684021 and batch: 1100, loss is 5.817051067352295 and perplexity is 335.9798094893907
At time: 35.70519733428955 and batch: 1150, loss is 5.729461450576782 and perplexity is 307.8034563585485
At time: 37.23816680908203 and batch: 1200, loss is 5.805869798660279 and perplexity is 332.24405313270694
At time: 38.767457008361816 and batch: 1250, loss is 5.740625028610229 and perplexity is 311.2588959108715
At time: 40.30025029182434 and batch: 1300, loss is 5.744924154281616 and perplexity is 312.59991756559026
At time: 41.834224700927734 and batch: 1350, loss is 5.721337261199952 and perplexity is 305.3129332274024
At time: 43.37340998649597 and batch: 1400, loss is 5.737931480407715 and perplexity is 310.4216331812435
At time: 44.91297912597656 and batch: 1450, loss is 5.709019613265991 and perplexity is 301.5752629175857
At time: 46.45053505897522 and batch: 1500, loss is 5.691647281646729 and perplexity is 296.38144245079644
At time: 47.98816895484924 and batch: 1550, loss is 5.672458829879761 and perplexity is 290.7485574419257
At time: 49.524500370025635 and batch: 1600, loss is 5.685311155319214 and perplexity is 294.5094689832438
At time: 51.06237483024597 and batch: 1650, loss is 5.671368522644043 and perplexity is 290.4317249397437
At time: 52.60606503486633 and batch: 1700, loss is 5.684261646270752 and perplexity is 294.20054077052157
At time: 54.14573955535889 and batch: 1750, loss is 5.698196363449097 and perplexity is 298.3288386301605
At time: 55.68501949310303 and batch: 1800, loss is 5.696802167892456 and perplexity is 297.91319969722724
At time: 57.22200965881348 and batch: 1850, loss is 5.662493686676026 and perplexity is 287.8655948557047
At time: 58.76207995414734 and batch: 1900, loss is 5.648088979721069 and perplexity is 283.7486978530862
At time: 60.31127953529358 and batch: 1950, loss is 5.582259664535522 and perplexity is 265.67125594213616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.1698435228924415 and perplexity of 175.88731299265174
finished 1 epochs...
Completing Train Step...
At time: 64.37340903282166 and batch: 50, loss is 5.445960531234741 and perplexity is 231.81984300555476
At time: 65.69070053100586 and batch: 100, loss is 5.380028743743896 and perplexity is 217.0285135473051
At time: 67.00807666778564 and batch: 150, loss is 5.291069450378418 and perplexity is 198.55565732626604
At time: 68.32612991333008 and batch: 200, loss is 5.252085886001587 and perplexity is 190.9641828281146
At time: 69.64417457580566 and batch: 250, loss is 5.246996440887451 and perplexity is 189.99475013065398
At time: 70.96065616607666 and batch: 300, loss is 5.252227115631103 and perplexity is 190.9911545334635
At time: 72.27637100219727 and batch: 350, loss is 5.211692266464233 and perplexity is 183.4041644453988
At time: 73.59310936927795 and batch: 400, loss is 5.173558378219605 and perplexity is 176.54192405418678
At time: 74.909175157547 and batch: 450, loss is 5.1235324668884275 and perplexity is 167.92752153631503
At time: 76.22445940971375 and batch: 500, loss is 5.10698356628418 and perplexity is 165.17137417901898
At time: 77.53842544555664 and batch: 550, loss is 5.058372497558594 and perplexity is 157.33424597018757
At time: 78.87081789970398 and batch: 600, loss is 5.054985160827637 and perplexity is 156.8022035119793
At time: 80.18484902381897 and batch: 650, loss is 5.1198036479949955 and perplexity is 167.3025162112928
At time: 81.49895930290222 and batch: 700, loss is 5.090636472702027 and perplexity is 162.4932516666151
At time: 82.81284642219543 and batch: 750, loss is 5.044876184463501 and perplexity is 155.22507873208716
At time: 84.1279649734497 and batch: 800, loss is 5.0231369113922115 and perplexity is 151.88701337714897
At time: 85.43896579742432 and batch: 850, loss is 5.0177977085113525 and perplexity is 151.07821887808407
At time: 86.74964547157288 and batch: 900, loss is 5.0188780117034915 and perplexity is 151.24151735024958
At time: 88.06365394592285 and batch: 950, loss is 5.079086084365844 and perplexity is 160.6271891274828
At time: 89.3771538734436 and batch: 1000, loss is 5.048416843414307 and perplexity is 155.77565191725003
At time: 90.69041466712952 and batch: 1050, loss is 4.950644264221191 and perplexity is 141.26594720514953
At time: 92.00262951850891 and batch: 1100, loss is 5.029944105148315 and perplexity is 152.92446476644724
At time: 93.31544089317322 and batch: 1150, loss is 4.935628242492676 and perplexity is 139.16054164084946
At time: 94.62895774841309 and batch: 1200, loss is 5.015122241973877 and perplexity is 150.67455439513256
At time: 95.94319653511047 and batch: 1250, loss is 4.955036840438843 and perplexity is 141.88783348672536
At time: 97.25766634941101 and batch: 1300, loss is 4.977092323303222 and perplexity is 145.05200355116637
At time: 98.57134890556335 and batch: 1350, loss is 4.898666973114014 and perplexity is 134.1108870589328
At time: 99.88216757774353 and batch: 1400, loss is 4.907167844772339 and perplexity is 135.25580600755387
At time: 101.19384670257568 and batch: 1450, loss is 4.848857355117798 and perplexity is 127.59451130287822
At time: 102.50860929489136 and batch: 1500, loss is 4.820793914794922 and perplexity is 124.06354757743051
At time: 103.82235264778137 and batch: 1550, loss is 4.810261096954346 and perplexity is 122.76366655257154
At time: 105.13694286346436 and batch: 1600, loss is 4.8817539882659915 and perplexity is 131.86174512337726
At time: 106.44898390769958 and batch: 1650, loss is 4.848943099975586 and perplexity is 127.6054523451668
At time: 107.76223468780518 and batch: 1700, loss is 4.865377140045166 and perplexity is 129.71985193846118
At time: 109.07585573196411 and batch: 1750, loss is 4.878605012893677 and perplexity is 131.4471688232925
At time: 110.3891212940216 and batch: 1800, loss is 4.829601268768311 and perplexity is 125.16104508631173
At time: 111.707754611969 and batch: 1850, loss is 4.8360612678527835 and perplexity is 125.97220254028049
At time: 113.02446603775024 and batch: 1900, loss is 4.887556524276733 and perplexity is 132.62910180223906
At time: 114.33770155906677 and batch: 1950, loss is 4.80194619178772 and perplexity is 121.74713036501531
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.668671931776889 and perplexity of 106.55613460449044
finished 2 epochs...
Completing Train Step...
At time: 118.26528644561768 and batch: 50, loss is 4.774365663528442 and perplexity is 118.43516304411654
At time: 119.596848487854 and batch: 100, loss is 4.719171819686889 and perplexity is 112.07539558570478
At time: 120.90964269638062 and batch: 150, loss is 4.668704824447632 and perplexity is 106.55963957798525
At time: 122.2224395275116 and batch: 200, loss is 4.654510326385498 and perplexity is 105.05776338672615
At time: 123.53753137588501 and batch: 250, loss is 4.659779405593872 and perplexity is 105.61278199788725
At time: 124.86570525169373 and batch: 300, loss is 4.686283206939697 and perplexity is 108.44934601233781
At time: 126.19108057022095 and batch: 350, loss is 4.690417795181275 and perplexity is 108.89866764304354
At time: 127.50972127914429 and batch: 400, loss is 4.649066705703735 and perplexity is 104.48742254119435
At time: 128.82798051834106 and batch: 450, loss is 4.6380225276947025 and perplexity is 103.33979381992319
At time: 130.14278984069824 and batch: 500, loss is 4.6504809761047365 and perplexity is 104.63530055527212
At time: 131.46620774269104 and batch: 550, loss is 4.605894651412964 and perplexity is 100.07247279133324
At time: 132.78155136108398 and batch: 600, loss is 4.5869236755371094 and perplexity is 98.19189492385127
At time: 134.093736410141 and batch: 650, loss is 4.64680965423584 and perplexity is 104.25185499481329
At time: 135.40597486495972 and batch: 700, loss is 4.660451784133911 and perplexity is 105.68381764480252
At time: 136.72681713104248 and batch: 750, loss is 4.626006441116333 and perplexity is 102.10548454535977
At time: 138.04271125793457 and batch: 800, loss is 4.6026687335968015 and perplexity is 99.75016736336656
At time: 139.35647058486938 and batch: 850, loss is 4.594409217834473 and perplexity is 98.92967239378231
At time: 140.67132210731506 and batch: 900, loss is 4.582823343276978 and perplexity is 97.79009983902469
At time: 141.98511695861816 and batch: 950, loss is 4.666076869964599 and perplexity is 106.27997333148036
At time: 143.3256766796112 and batch: 1000, loss is 4.637196025848389 and perplexity is 103.2544185757918
At time: 144.64026021957397 and batch: 1050, loss is 4.564582576751709 and perplexity is 96.02250362440797
At time: 145.95484948158264 and batch: 1100, loss is 4.623826208114624 and perplexity is 101.88311329695098
At time: 147.2696659564972 and batch: 1150, loss is 4.549561128616333 and perplexity is 94.5908859710979
At time: 148.58648991584778 and batch: 1200, loss is 4.637264785766601 and perplexity is 103.2615185852634
At time: 149.8987205028534 and batch: 1250, loss is 4.598751411437989 and perplexity is 99.36017817775995
At time: 151.21300983428955 and batch: 1300, loss is 4.620285196304321 and perplexity is 101.52298198041863
At time: 152.53337597846985 and batch: 1350, loss is 4.511890697479248 and perplexity is 91.09388677685651
At time: 153.88077545166016 and batch: 1400, loss is 4.5242566394805905 and perplexity is 92.22734217564265
At time: 155.2071568965912 and batch: 1450, loss is 4.457525386810302 and perplexity is 86.27375055950579
At time: 156.53131413459778 and batch: 1500, loss is 4.4523474216461185 and perplexity is 85.82818264760986
At time: 157.85984230041504 and batch: 1550, loss is 4.452135286331177 and perplexity is 85.80997739011032
At time: 159.18676161766052 and batch: 1600, loss is 4.542229490280151 and perplexity is 93.89991587182891
At time: 160.5151720046997 and batch: 1650, loss is 4.486825151443481 and perplexity is 88.83894746698391
At time: 161.8428053855896 and batch: 1700, loss is 4.518502740859986 and perplexity is 91.69819917617956
At time: 163.16878151893616 and batch: 1750, loss is 4.535654582977295 and perplexity is 93.28455780713769
At time: 164.48616290092468 and batch: 1800, loss is 4.481294555664062 and perplexity is 88.34897133795826
At time: 165.80655694007874 and batch: 1850, loss is 4.504663820266724 and perplexity is 90.43793553674597
At time: 167.12492299079895 and batch: 1900, loss is 4.576295280456543 and perplexity is 97.15379908938561
At time: 168.44355726242065 and batch: 1950, loss is 4.5002945709228515 and perplexity is 90.0436516358295
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5373807685319765 and perplexity of 93.44572332407388
finished 3 epochs...
Completing Train Step...
At time: 172.43101143836975 and batch: 50, loss is 4.477385053634643 and perplexity is 88.0042451481568
At time: 173.7803452014923 and batch: 100, loss is 4.418731441497803 and perplexity is 82.99093969174918
At time: 175.09634375572205 and batch: 150, loss is 4.3740721035003665 and perplexity is 79.36616179116398
At time: 176.43018198013306 and batch: 200, loss is 4.3685244274139405 and perplexity is 78.92708309263757
At time: 177.74641919136047 and batch: 250, loss is 4.370015459060669 and perplexity is 79.04485364930747
At time: 179.0623071193695 and batch: 300, loss is 4.402687749862671 and perplexity is 81.67008269030323
At time: 180.37708687782288 and batch: 350, loss is 4.413654861450195 and perplexity is 82.57069714317521
At time: 181.6896903514862 and batch: 400, loss is 4.373156995773315 and perplexity is 79.293566424599
At time: 183.00254130363464 and batch: 450, loss is 4.381417989730835 and perplexity is 79.9513232194971
At time: 184.31717467308044 and batch: 500, loss is 4.3988722229003905 and perplexity is 81.35906201899152
At time: 185.63073682785034 and batch: 550, loss is 4.351665906906128 and perplexity is 77.6076424023403
At time: 186.94647359848022 and batch: 600, loss is 4.329756693840027 and perplexity is 75.92581110413865
At time: 188.26372385025024 and batch: 650, loss is 4.380451135635376 and perplexity is 79.87405931268621
At time: 189.57965421676636 and batch: 700, loss is 4.414277563095093 and perplexity is 82.62213006412689
At time: 190.89346289634705 and batch: 750, loss is 4.383528175354004 and perplexity is 80.12021348454213
At time: 192.2077922821045 and batch: 800, loss is 4.352083787918091 and perplexity is 77.6400799395269
At time: 193.523832321167 and batch: 850, loss is 4.341970891952514 and perplexity is 76.85887069016026
At time: 194.83956742286682 and batch: 900, loss is 4.326954145431518 and perplexity is 75.71332323591068
At time: 196.15310502052307 and batch: 950, loss is 4.417722053527832 and perplexity is 82.90721189962976
At time: 197.4935176372528 and batch: 1000, loss is 4.396009159088135 and perplexity is 81.1264589703014
At time: 198.81012296676636 and batch: 1050, loss is 4.336378183364868 and perplexity is 76.43022119715314
At time: 200.12424063682556 and batch: 1100, loss is 4.382540607452393 and perplexity is 80.04112839081216
At time: 201.4416651725769 and batch: 1150, loss is 4.326957354545593 and perplexity is 75.7135662089918
At time: 202.75880765914917 and batch: 1200, loss is 4.415490398406982 and perplexity is 82.72239789290299
At time: 204.08194231987 and batch: 1250, loss is 4.377927017211914 and perplexity is 79.67270195982731
At time: 205.40346240997314 and batch: 1300, loss is 4.382817096710205 and perplexity is 80.06326196270183
At time: 206.72167801856995 and batch: 1350, loss is 4.2701074457168575 and perplexity is 71.52932072548764
At time: 208.03693413734436 and batch: 1400, loss is 4.296350584030152 and perplexity is 73.43132267468017
At time: 209.35397028923035 and batch: 1450, loss is 4.226504545211792 and perplexity is 68.4774535074944
At time: 210.66891050338745 and batch: 1500, loss is 4.227070517539978 and perplexity is 68.51622082086273
At time: 211.98875427246094 and batch: 1550, loss is 4.2319889259338375 and perplexity is 68.85404166589237
At time: 213.30604600906372 and batch: 1600, loss is 4.3268092918395995 and perplexity is 75.7023566833753
At time: 214.6314799785614 and batch: 1650, loss is 4.274081072807312 and perplexity is 71.81411703451109
At time: 215.95515155792236 and batch: 1700, loss is 4.301988744735718 and perplexity is 73.8465096182384
At time: 217.27045106887817 and batch: 1750, loss is 4.317474489212036 and perplexity is 74.99897818264022
At time: 218.5874559879303 and batch: 1800, loss is 4.264420638084411 and perplexity is 71.12370167034693
At time: 219.90381121635437 and batch: 1850, loss is 4.29311990737915 and perplexity is 73.19447261404895
At time: 221.22412657737732 and batch: 1900, loss is 4.373938798904419 and perplexity is 79.3555826221761
At time: 222.54606080055237 and batch: 1950, loss is 4.300389194488526 and perplexity is 73.72848283557383
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.471822197492733 and perplexity of 87.51604933301384
finished 4 epochs...
Completing Train Step...
At time: 226.5221884250641 and batch: 50, loss is 4.275674686431885 and perplexity is 71.92865222803691
At time: 227.8525276184082 and batch: 100, loss is 4.2210719108581545 and perplexity is 68.10644921891132
At time: 229.1667561531067 and batch: 150, loss is 4.176955027580261 and perplexity is 65.1671187178635
At time: 230.48011255264282 and batch: 200, loss is 4.1759323883056645 and perplexity is 65.10051032683351
At time: 231.7947599887848 and batch: 250, loss is 4.172360391616821 and perplexity is 64.86838633937025
At time: 233.13522386550903 and batch: 300, loss is 4.202724647521973 and perplexity is 66.86827554230418
At time: 234.45614528656006 and batch: 350, loss is 4.213897767066956 and perplexity is 67.619592238241
At time: 235.775048494339 and batch: 400, loss is 4.182171554565429 and perplexity is 65.50795296381916
At time: 237.0980634689331 and batch: 450, loss is 4.200961265563965 and perplexity is 66.7504651345513
At time: 238.4195806980133 and batch: 500, loss is 4.2163090944290165 and perplexity is 67.78284195637124
At time: 239.73466658592224 and batch: 550, loss is 4.17328471660614 and perplexity is 64.92837352943899
At time: 241.04885530471802 and batch: 600, loss is 4.153983120918274 and perplexity is 63.687169458614115
At time: 242.3769564628601 and batch: 650, loss is 4.196983218193054 and perplexity is 66.48545608097767
At time: 243.69431686401367 and batch: 700, loss is 4.236798243522644 and perplexity is 69.18598017860197
At time: 245.01028561592102 and batch: 750, loss is 4.206926093101502 and perplexity is 67.14980997464981
At time: 246.32572650909424 and batch: 800, loss is 4.178792119026184 and perplexity is 65.28694670800269
At time: 247.6394112110138 and batch: 850, loss is 4.162975859642029 and perplexity is 64.26247444026443
At time: 248.9531764984131 and batch: 900, loss is 4.153654055595398 and perplexity is 63.66621566740528
At time: 250.27681708335876 and batch: 950, loss is 4.245539140701294 and perplexity is 69.79337845321606
At time: 251.60306978225708 and batch: 1000, loss is 4.2257105207443235 and perplexity is 68.42310231488345
At time: 252.93059253692627 and batch: 1050, loss is 4.172979307174683 and perplexity is 64.9085468195801
At time: 254.2514021396637 and batch: 1100, loss is 4.2123418092727665 and perplexity is 67.51446081789474
At time: 255.57015204429626 and batch: 1150, loss is 4.1608259391784665 and perplexity is 64.1244636407062
At time: 256.8939218521118 and batch: 1200, loss is 4.252354140281677 and perplexity is 70.27064473565866
At time: 258.2267804145813 and batch: 1250, loss is 4.213059096336365 and perplexity is 67.56290543951837
At time: 259.54292917251587 and batch: 1300, loss is 4.213053464889526 and perplexity is 67.56252496367945
At time: 260.85841727256775 and batch: 1350, loss is 4.100277137756348 and perplexity is 60.3570124867262
At time: 262.17241287231445 and batch: 1400, loss is 4.13556884765625 and perplexity is 62.52514824023351
At time: 263.48731565475464 and batch: 1450, loss is 4.060899472236633 and perplexity is 58.02648082131283
At time: 264.80443501472473 and batch: 1500, loss is 4.067599210739136 and perplexity is 58.41654828497619
At time: 266.1209681034088 and batch: 1550, loss is 4.073696694374084 and perplexity is 58.77383038607856
At time: 267.43742775917053 and batch: 1600, loss is 4.170336899757385 and perplexity is 64.73725840057827
At time: 268.74981784820557 and batch: 1650, loss is 4.109227080345153 and perplexity is 60.89962885395545
At time: 270.0621132850647 and batch: 1700, loss is 4.144572768211365 and perplexity is 63.09066180676044
At time: 271.3773875236511 and batch: 1750, loss is 4.161249828338623 and perplexity is 64.15165106756503
At time: 272.69272017478943 and batch: 1800, loss is 4.103193516731262 and perplexity is 60.533293334867786
At time: 274.0087568759918 and batch: 1850, loss is 4.140426425933838 and perplexity is 62.829607911801084
At time: 275.3237364292145 and batch: 1900, loss is 4.219681167602539 and perplexity is 68.01179646808984
At time: 276.63731694221497 and batch: 1950, loss is 4.149927573204041 and perplexity is 63.42940614309882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.441707451398982 and perplexity of 84.91981441297146
finished 5 epochs...
Completing Train Step...
At time: 280.61682081222534 and batch: 50, loss is 4.127606205940246 and perplexity is 62.02925979764875
At time: 281.93082189559937 and batch: 100, loss is 4.071545524597168 and perplexity is 58.64753378989219
At time: 283.24986028671265 and batch: 150, loss is 4.032445554733276 and perplexity is 56.398668763041606
At time: 284.5633637905121 and batch: 200, loss is 4.030816307067871 and perplexity is 56.30685617665779
At time: 285.8796877861023 and batch: 250, loss is 4.023243088722229 and perplexity is 55.882042693488586
At time: 287.19635009765625 and batch: 300, loss is 4.052130260467529 and perplexity is 57.519858906761584
At time: 288.51227045059204 and batch: 350, loss is 4.065311522483825 and perplexity is 58.28306217906406
At time: 289.82689595222473 and batch: 400, loss is 4.032643136978149 and perplexity is 56.40981323956273
At time: 291.1437795162201 and batch: 450, loss is 4.067738642692566 and perplexity is 58.42469398628854
At time: 292.4689404964447 and batch: 500, loss is 4.075899395942688 and perplexity is 58.90343428141257
At time: 293.79987120628357 and batch: 550, loss is 4.034718403816223 and perplexity is 56.52700020937915
At time: 295.12953901290894 and batch: 600, loss is 4.018574814796448 and perplexity is 55.62177797681605
At time: 296.4611871242523 and batch: 650, loss is 4.052630748748779 and perplexity is 57.54865412731771
At time: 297.7828390598297 and batch: 700, loss is 4.101769328117371 and perplexity is 60.44714386884471
At time: 299.1047794818878 and batch: 750, loss is 4.07292338848114 and perplexity is 58.728397805595264
At time: 300.4326775074005 and batch: 800, loss is 4.044050521850586 and perplexity is 57.056985945889956
At time: 301.7495882511139 and batch: 850, loss is 4.028776960372925 and perplexity is 56.19214398433295
At time: 303.0649001598358 and batch: 900, loss is 4.01966543674469 and perplexity is 55.68247340054222
At time: 304.37882566452026 and batch: 950, loss is 4.112279896736145 and perplexity is 61.08582831089312
At time: 305.69285678863525 and batch: 1000, loss is 4.091323752403259 and perplexity is 59.819024894178675
At time: 307.03493213653564 and batch: 1050, loss is 4.046435027122498 and perplexity is 57.19320096785462
At time: 308.3517928123474 and batch: 1100, loss is 4.077875137329102 and perplexity is 59.01992727644527
At time: 309.66788935661316 and batch: 1150, loss is 4.031234846115113 and perplexity is 56.33042772705815
At time: 310.98248839378357 and batch: 1200, loss is 4.119766511917114 and perplexity is 61.54487059284061
At time: 312.2965679168701 and batch: 1250, loss is 4.087290153503418 and perplexity is 59.578224912928654
At time: 313.6110966205597 and batch: 1300, loss is 4.08422281742096 and perplexity is 59.395758459953974
At time: 314.92739510536194 and batch: 1350, loss is 3.962848219871521 and perplexity is 52.60694892569216
At time: 316.24248576164246 and batch: 1400, loss is 4.005509719848633 and perplexity is 54.899800786551275
At time: 317.5570089817047 and batch: 1450, loss is 3.931144480705261 and perplexity is 50.96527307552775
At time: 318.8703634738922 and batch: 1500, loss is 3.9432069396972658 and perplexity is 51.583762343418556
At time: 320.18490862846375 and batch: 1550, loss is 3.9465392637252807 and perplexity is 51.75594287546313
At time: 321.50184535980225 and batch: 1600, loss is 4.047046103477478 and perplexity is 57.22816106118703
At time: 322.81685757637024 and batch: 1650, loss is 3.9838551616668703 and perplexity is 53.723749250264284
At time: 324.13189935684204 and batch: 1700, loss is 4.013750014305114 and perplexity is 55.35406035650064
At time: 325.4496076107025 and batch: 1750, loss is 4.035020217895508 and perplexity is 56.54406342873249
At time: 326.7692015171051 and batch: 1800, loss is 3.9744612121582032 and perplexity is 53.22143411783511
At time: 328.09044766426086 and batch: 1850, loss is 4.015830025672913 and perplexity is 55.469317257573785
At time: 329.4176723957062 and batch: 1900, loss is 4.098459281921387 and perplexity is 60.24739180688033
At time: 330.7394058704376 and batch: 1950, loss is 4.02752959728241 and perplexity is 56.1220956748703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.437287370548692 and perplexity of 84.54529029068478
finished 6 epochs...
Completing Train Step...
At time: 334.7581729888916 and batch: 50, loss is 4.005119791030884 and perplexity is 54.87839794519941
At time: 336.078497171402 and batch: 100, loss is 3.95328727722168 and perplexity is 52.10637370272356
At time: 337.40042877197266 and batch: 150, loss is 3.911467752456665 and perplexity is 49.97224505764614
At time: 338.71959257125854 and batch: 200, loss is 3.9169619274139404 and perplexity is 50.24755692824743
At time: 340.08223366737366 and batch: 250, loss is 3.9085660696029665 and perplexity is 49.82745162490596
At time: 341.40008020401 and batch: 300, loss is 3.9326553916931153 and perplexity is 51.04233526901386
At time: 342.73010206222534 and batch: 350, loss is 3.942479815483093 and perplexity is 51.54626817387177
At time: 344.05199098587036 and batch: 400, loss is 3.9171128845214844 and perplexity is 50.255142726653155
At time: 345.3669340610504 and batch: 450, loss is 3.9558554315567016 and perplexity is 52.240362891045024
At time: 346.68210458755493 and batch: 500, loss is 3.9645962142944335 and perplexity is 52.69898599572845
At time: 347.99751901626587 and batch: 550, loss is 3.92070565700531 and perplexity is 50.43602275644237
At time: 349.3137118816376 and batch: 600, loss is 3.9093214464187622 and perplexity is 49.86510434585946
At time: 350.6309199333191 and batch: 650, loss is 3.9394815969467163 and perplexity is 51.39195264858521
At time: 351.9536290168762 and batch: 700, loss is 3.9884949111938477 and perplexity is 53.97359314878593
At time: 353.2777135372162 and batch: 750, loss is 3.964355368614197 and perplexity is 52.68629520092142
At time: 354.5929009914398 and batch: 800, loss is 3.938705115318298 and perplexity is 51.35206323020951
At time: 355.9095437526703 and batch: 850, loss is 3.9164719200134277 and perplexity is 50.22294128491114
At time: 357.2238986492157 and batch: 900, loss is 3.908917818069458 and perplexity is 49.844981437465805
At time: 358.5382180213928 and batch: 950, loss is 4.003142471313477 and perplexity is 54.76999301780291
At time: 359.85137605667114 and batch: 1000, loss is 3.986748342514038 and perplexity is 53.879406836829695
At time: 361.1642954349518 and batch: 1050, loss is 3.9374244737625124 and perplexity is 51.28634173588211
At time: 362.4783329963684 and batch: 1100, loss is 3.969532356262207 and perplexity is 52.95975874833723
At time: 363.79337072372437 and batch: 1150, loss is 3.9282727670669555 and perplexity is 50.81912535339704
At time: 365.10807371139526 and batch: 1200, loss is 4.010859961509705 and perplexity is 55.19431514686294
At time: 366.420401096344 and batch: 1250, loss is 3.9804696226119995 and perplexity is 53.542172939283276
At time: 367.7329685688019 and batch: 1300, loss is 3.9753826904296874 and perplexity is 53.27049911564476
At time: 369.04786372184753 and batch: 1350, loss is 3.85548593044281 and perplexity is 47.251572340930366
At time: 370.3641312122345 and batch: 1400, loss is 3.898461952209473 and perplexity is 49.32652418088535
At time: 371.6814167499542 and batch: 1450, loss is 3.82750274181366 and perplexity is 45.94765169390767
At time: 372.99598026275635 and batch: 1500, loss is 3.839245204925537 and perplexity is 46.49037049065556
At time: 374.3074254989624 and batch: 1550, loss is 3.846634516716003 and perplexity is 46.83517469744749
At time: 375.6218988895416 and batch: 1600, loss is 3.946890478134155 and perplexity is 51.77412350080778
At time: 376.93885111808777 and batch: 1650, loss is 3.8823800706863403 and perplexity is 48.53960539023195
At time: 378.25657391548157 and batch: 1700, loss is 3.915651993751526 and perplexity is 50.181779053704915
At time: 379.57105684280396 and batch: 1750, loss is 3.9338686323165892 and perplexity is 51.10429948483042
At time: 380.89075565338135 and batch: 1800, loss is 3.872493600845337 and perplexity is 48.06208443321007
At time: 382.21274518966675 and batch: 1850, loss is 3.9174683189392088 and perplexity is 50.273008308879184
At time: 383.529066324234 and batch: 1900, loss is 3.9960562133789064 and perplexity is 54.38325061676425
At time: 384.84686517715454 and batch: 1950, loss is 3.926292910575867 and perplexity is 50.718610313705064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.447162574945494 and perplexity of 85.38432833061506
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 388.8348207473755 and batch: 50, loss is 3.9412538480758665 and perplexity is 51.48311285022082
At time: 390.15717244148254 and batch: 100, loss is 3.9138837099075316 and perplexity is 50.093121833208
At time: 391.4722013473511 and batch: 150, loss is 3.8783277559280394 and perplexity is 48.343305633771045
At time: 392.7862706184387 and batch: 200, loss is 3.893168082237244 and perplexity is 49.06608594699554
At time: 394.1003305912018 and batch: 250, loss is 3.8828608798980713 and perplexity is 48.56294929116895
At time: 395.4130308628082 and batch: 300, loss is 3.8962266206741334 and perplexity is 49.21638618917879
At time: 396.7268662452698 and batch: 350, loss is 3.902495474815369 and perplexity is 49.525885625396555
At time: 398.041930437088 and batch: 400, loss is 3.8690238857269286 and perplexity is 47.895611665781615
At time: 399.35745906829834 and batch: 450, loss is 3.9010761880874636 and perplexity is 49.45564405149854
At time: 400.67421650886536 and batch: 500, loss is 3.911912760734558 and perplexity is 49.994488069156745
At time: 401.99109840393066 and batch: 550, loss is 3.860736484527588 and perplexity is 47.5003217417218
At time: 403.3072986602783 and batch: 600, loss is 3.824977593421936 and perplexity is 45.83177342161937
At time: 404.62159180641174 and batch: 650, loss is 3.85227867603302 and perplexity is 47.100267293759956
At time: 405.94935631752014 and batch: 700, loss is 3.8911512184143064 and perplexity is 48.96722606029178
At time: 407.26345109939575 and batch: 750, loss is 3.85108594417572 and perplexity is 47.044122793794195
At time: 408.5762391090393 and batch: 800, loss is 3.8240179014205933 and perplexity is 45.78781013424113
At time: 409.8885443210602 and batch: 850, loss is 3.8125407218933107 and perplexity is 45.265299427422136
At time: 411.2023811340332 and batch: 900, loss is 3.7946540975570677 and perplexity is 44.462853935469106
At time: 412.53008222579956 and batch: 950, loss is 3.882660217285156 and perplexity is 48.55320550051326
At time: 413.857310295105 and batch: 1000, loss is 3.847998218536377 and perplexity is 46.89908747952377
At time: 415.18541860580444 and batch: 1050, loss is 3.7947689390182493 and perplexity is 44.46796040779512
At time: 416.52396750450134 and batch: 1100, loss is 3.8161015701293945 and perplexity is 45.426769603825214
At time: 417.8408634662628 and batch: 1150, loss is 3.779950909614563 and perplexity is 43.81389084199138
At time: 419.1554560661316 and batch: 1200, loss is 3.8403618001937865 and perplexity is 46.54231041090269
At time: 420.46932005882263 and batch: 1250, loss is 3.808405113220215 and perplexity is 45.078486421522726
At time: 421.7816197872162 and batch: 1300, loss is 3.8051795959472656 and perplexity is 44.933319230432325
At time: 423.09210443496704 and batch: 1350, loss is 3.681921434402466 and perplexity is 39.72264525043617
At time: 424.4059114456177 and batch: 1400, loss is 3.7128132724761964 and perplexity is 40.96890123692054
At time: 425.71990489959717 and batch: 1450, loss is 3.6305924320220946 and perplexity is 37.7351655168374
At time: 427.0349099636078 and batch: 1500, loss is 3.6271398639678956 and perplexity is 37.60510693709679
At time: 428.34841895103455 and batch: 1550, loss is 3.632813892364502 and perplexity is 37.819085868902796
At time: 429.6613919734955 and batch: 1600, loss is 3.7137725448608396 and perplexity is 41.00822042839844
At time: 430.9735324382782 and batch: 1650, loss is 3.6498341798782348 and perplexity is 38.468286704149484
At time: 432.2872862815857 and batch: 1700, loss is 3.6717941761016846 and perplexity is 39.32239390682007
At time: 433.60213470458984 and batch: 1750, loss is 3.677633385658264 and perplexity is 39.552677287247676
At time: 434.9169406890869 and batch: 1800, loss is 3.609630656242371 and perplexity is 36.95240215501933
At time: 436.2309076786041 and batch: 1850, loss is 3.64174430847168 and perplexity is 38.15833862195012
At time: 437.54473209381104 and batch: 1900, loss is 3.717309823036194 and perplexity is 41.153534768633605
At time: 438.8594708442688 and batch: 1950, loss is 3.6347394514083864 and perplexity is 37.89197890913294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.397251998546512 and perplexity of 81.22734881658242
finished 8 epochs...
Completing Train Step...
At time: 442.81942868232727 and batch: 50, loss is 3.8383589601516723 and perplexity is 46.44918689484203
At time: 444.1435444355011 and batch: 100, loss is 3.7922637701034545 and perplexity is 44.356700076826435
At time: 445.45687079429626 and batch: 150, loss is 3.7543302726745607 and perplexity is 42.7056091175648
At time: 446.77155566215515 and batch: 200, loss is 3.7634657430648804 and perplexity is 43.09753242130829
At time: 448.0855197906494 and batch: 250, loss is 3.7568131113052368 and perplexity is 42.81177199173437
At time: 449.3997712135315 and batch: 300, loss is 3.772703757286072 and perplexity is 43.49751270594078
At time: 450.71274757385254 and batch: 350, loss is 3.7783358192443846 and perplexity is 43.7431845626977
At time: 452.0271165370941 and batch: 400, loss is 3.7480076265335085 and perplexity is 42.43644846332227
At time: 453.34354853630066 and batch: 450, loss is 3.7849238443374635 and perplexity is 44.03231712077655
At time: 454.6626522541046 and batch: 500, loss is 3.801133642196655 and perplexity is 44.75188837688372
At time: 455.98025846481323 and batch: 550, loss is 3.7528163766860962 and perplexity is 42.64100618063883
At time: 457.2967917919159 and batch: 600, loss is 3.7220766878128053 and perplexity is 41.35017641366371
At time: 458.610319852829 and batch: 650, loss is 3.752598605155945 and perplexity is 42.631721194515194
At time: 459.9256536960602 and batch: 700, loss is 3.7917058801651002 and perplexity is 44.331960821687396
At time: 461.2439308166504 and batch: 750, loss is 3.750536336898804 and perplexity is 42.543893742159156
At time: 462.567752122879 and batch: 800, loss is 3.723286819458008 and perplexity is 41.40024585987704
At time: 463.891877412796 and batch: 850, loss is 3.7163529443740844 and perplexity is 41.11417466376859
At time: 465.21479511260986 and batch: 900, loss is 3.6951544952392577 and perplexity is 40.251790817668756
At time: 466.536883354187 and batch: 950, loss is 3.7881139516830444 and perplexity is 44.17300923121788
At time: 467.86296701431274 and batch: 1000, loss is 3.7574875783920287 and perplexity is 42.84065686272244
At time: 469.1861412525177 and batch: 1050, loss is 3.708549542427063 and perplexity is 40.794592767833876
At time: 470.5392129421234 and batch: 1100, loss is 3.7295919036865235 and perplexity is 41.66210254384003
At time: 471.86795592308044 and batch: 1150, loss is 3.6986163377761843 and perplexity is 40.39137765372736
At time: 473.19497513771057 and batch: 1200, loss is 3.7593359565734863 and perplexity is 42.91991582585017
At time: 474.53312945365906 and batch: 1250, loss is 3.734192090034485 and perplexity is 41.85419747667863
At time: 475.8647491931915 and batch: 1300, loss is 3.7301316452026367 and perplexity is 41.68459537984416
At time: 477.189861536026 and batch: 1350, loss is 3.608922600746155 and perplexity is 36.92624706429568
At time: 478.51246523857117 and batch: 1400, loss is 3.6479690217971803 and perplexity is 38.396604138777825
At time: 479.8327786922455 and batch: 1450, loss is 3.567007918357849 and perplexity is 35.41048342890718
At time: 481.15481972694397 and batch: 1500, loss is 3.563695578575134 and perplexity is 35.29338591635726
At time: 482.47921419143677 and batch: 1550, loss is 3.5737405824661255 and perplexity is 35.64969468065494
At time: 483.80190205574036 and batch: 1600, loss is 3.6587401485443114 and perplexity is 38.81241417985933
At time: 485.1247305870056 and batch: 1650, loss is 3.597633228302002 and perplexity is 36.51171720186595
At time: 486.44687151908875 and batch: 1700, loss is 3.624599585533142 and perplexity is 37.50970072538376
At time: 487.77087664604187 and batch: 1750, loss is 3.631739926338196 and perplexity is 37.77849125805193
At time: 489.09924268722534 and batch: 1800, loss is 3.568531131744385 and perplexity is 35.46446225148565
At time: 490.4263913631439 and batch: 1850, loss is 3.6038517427444456 and perplexity is 36.73947326083325
At time: 491.7527611255646 and batch: 1900, loss is 3.683053798675537 and perplexity is 39.7676512315231
At time: 493.0761196613312 and batch: 1950, loss is 3.606593132019043 and perplexity is 36.84032863754638
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.406728913063227 and perplexity of 82.00079259934641
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 497.05077600479126 and batch: 50, loss is 3.7984065628051757 and perplexity is 44.630012682240995
At time: 498.3816976547241 and batch: 100, loss is 3.785339856147766 and perplexity is 44.05063889550687
At time: 499.69814920425415 and batch: 150, loss is 3.766377553939819 and perplexity is 43.22320716664485
At time: 501.0145299434662 and batch: 200, loss is 3.771745829582214 and perplexity is 43.45586518431297
At time: 502.33350229263306 and batch: 250, loss is 3.7755532026290894 and perplexity is 43.62163324431721
At time: 503.6642162799835 and batch: 300, loss is 3.8012447929382325 and perplexity is 44.756862858917366
At time: 504.98240184783936 and batch: 350, loss is 3.823307967185974 and perplexity is 45.75531533624816
At time: 506.2998125553131 and batch: 400, loss is 3.787703876495361 and perplexity is 44.1548986897625
At time: 507.61614751815796 and batch: 450, loss is 3.8118879556655885 and perplexity is 45.235761410426996
At time: 508.9315049648285 and batch: 500, loss is 3.815298981666565 and perplexity is 45.390325229511035
At time: 510.2479522228241 and batch: 550, loss is 3.779277091026306 and perplexity is 43.784378172127596
At time: 511.56734228134155 and batch: 600, loss is 3.753939347267151 and perplexity is 42.68891767268935
At time: 512.8853125572205 and batch: 650, loss is 3.7703022146224976 and perplexity is 43.393176906999926
At time: 514.2022912502289 and batch: 700, loss is 3.8069732332229616 and perplexity is 45.013985628227545
At time: 515.5196666717529 and batch: 750, loss is 3.75996591091156 and perplexity is 42.946961931025655
At time: 516.8369905948639 and batch: 800, loss is 3.7263662004470826 and perplexity is 41.52792948228311
At time: 518.1523458957672 and batch: 850, loss is 3.7129849672317503 and perplexity is 40.97593598630123
At time: 519.4709436893463 and batch: 900, loss is 3.686251516342163 and perplexity is 39.895020489355915
At time: 520.7889487743378 and batch: 950, loss is 3.7847212839126585 and perplexity is 44.02339881919339
At time: 522.1148591041565 and batch: 1000, loss is 3.742177948951721 and perplexity is 42.18977735617231
At time: 523.4311068058014 and batch: 1050, loss is 3.6875089168548585 and perplexity is 39.94521605992781
At time: 524.7490015029907 and batch: 1100, loss is 3.701800627708435 and perplexity is 40.520200506744715
At time: 526.0670793056488 and batch: 1150, loss is 3.6740400838851928 and perplexity is 39.4108076247262
At time: 527.385237455368 and batch: 1200, loss is 3.7242875576019285 and perplexity is 41.44169740268732
At time: 528.7029547691345 and batch: 1250, loss is 3.6946547174453737 and perplexity is 40.23167889261941
At time: 530.0204348564148 and batch: 1300, loss is 3.7041497230529785 and perplexity is 40.61549820898639
At time: 531.3378484249115 and batch: 1350, loss is 3.5754975128173827 and perplexity is 35.71238376530445
At time: 532.6607506275177 and batch: 1400, loss is 3.604669132232666 and perplexity is 36.76951599671497
At time: 533.9789943695068 and batch: 1450, loss is 3.525478711128235 and perplexity is 33.97003155664123
At time: 535.2929031848907 and batch: 1500, loss is 3.5210452699661254 and perplexity is 33.81976077493036
At time: 536.6064791679382 and batch: 1550, loss is 3.5266620302200318 and perplexity is 34.01025273608261
At time: 537.922712802887 and batch: 1600, loss is 3.609614887237549 and perplexity is 36.95181945700586
At time: 539.2383286952972 and batch: 1650, loss is 3.5359246730804443 and perplexity is 34.32674105711558
At time: 540.5536770820618 and batch: 1700, loss is 3.5606180524826048 and perplexity is 35.18493656375728
At time: 541.868842124939 and batch: 1750, loss is 3.5595446634292602 and perplexity is 35.14718970016643
At time: 543.1831986904144 and batch: 1800, loss is 3.4914465665817263 and perplexity is 32.83340908227791
At time: 544.499059677124 and batch: 1850, loss is 3.5190245580673216 and perplexity is 33.75148978315125
At time: 545.8147912025452 and batch: 1900, loss is 3.6087722969055176 and perplexity is 36.920697324625635
At time: 547.1316661834717 and batch: 1950, loss is 3.540351309776306 and perplexity is 34.47902988370613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385352414153343 and perplexity of 80.26650528160832
finished 10 epochs...
Completing Train Step...
At time: 551.0915336608887 and batch: 50, loss is 3.7969108772277833 and perplexity is 44.56331011142479
At time: 552.418069601059 and batch: 100, loss is 3.7631297588348387 and perplexity is 43.083054762329766
At time: 553.7337574958801 and batch: 150, loss is 3.728993353843689 and perplexity is 41.63717316039381
At time: 555.0491609573364 and batch: 200, loss is 3.7243069791793824 and perplexity is 41.44250227363915
At time: 556.3638622760773 and batch: 250, loss is 3.721048049926758 and perplexity is 41.30766392433698
At time: 557.6805412769318 and batch: 300, loss is 3.743451461791992 and perplexity is 42.24354080631933
At time: 558.9994258880615 and batch: 350, loss is 3.7655934286117554 and perplexity is 43.18932803962201
At time: 560.3178777694702 and batch: 400, loss is 3.732948832511902 and perplexity is 41.80219426420503
At time: 561.6357185840607 and batch: 450, loss is 3.761588101387024 and perplexity is 43.01668662169476
At time: 562.9538662433624 and batch: 500, loss is 3.7633416128158568 and perplexity is 43.09218304589305
At time: 564.2725033760071 and batch: 550, loss is 3.7202441024780275 and perplexity is 41.27446807895755
At time: 565.5892350673676 and batch: 600, loss is 3.6941461420059203 and perplexity is 40.211223250906045
At time: 566.9041867256165 and batch: 650, loss is 3.7188868856430055 and perplexity is 41.21848767339181
At time: 568.2220394611359 and batch: 700, loss is 3.7623920154571535 and perplexity is 43.051282245411436
At time: 569.5513246059418 and batch: 750, loss is 3.719044451713562 and perplexity is 41.22498282022273
At time: 570.8688044548035 and batch: 800, loss is 3.6832935571670533 and perplexity is 39.777187006689374
At time: 572.1867425441742 and batch: 850, loss is 3.6711185932159425 and perplexity is 39.2958373420606
At time: 573.5057497024536 and batch: 900, loss is 3.6446986103057863 and perplexity is 38.27123655690208
At time: 574.8248589038849 and batch: 950, loss is 3.7477664279937746 and perplexity is 42.4262140882292
At time: 576.1434977054596 and batch: 1000, loss is 3.7036475276947023 and perplexity is 40.59510641507245
At time: 577.4606788158417 and batch: 1050, loss is 3.6512582540512084 and perplexity is 38.52310742284359
At time: 578.7773582935333 and batch: 1100, loss is 3.6682300090789797 and perplexity is 39.18249179255596
At time: 580.0959963798523 and batch: 1150, loss is 3.6423753976821898 and perplexity is 38.18242753807345
At time: 581.4159469604492 and batch: 1200, loss is 3.6961101150512694 and perplexity is 40.29027461145232
At time: 582.7414643764496 and batch: 1250, loss is 3.66992742061615 and perplexity is 39.24905708454466
At time: 584.0585813522339 and batch: 1300, loss is 3.6800999546051028 and perplexity is 39.6503571102945
At time: 585.3747162818909 and batch: 1350, loss is 3.5498299264907835 and perplexity is 34.807397167988476
At time: 586.6915137767792 and batch: 1400, loss is 3.580754265785217 and perplexity is 35.900609238615786
At time: 588.0104334354401 and batch: 1450, loss is 3.5040816259384155 and perplexity is 33.2508930683087
At time: 589.3326258659363 and batch: 1500, loss is 3.501996440887451 and perplexity is 33.18163104032005
At time: 590.6546695232391 and batch: 1550, loss is 3.510816903114319 and perplexity is 33.47560294163378
At time: 591.9805591106415 and batch: 1600, loss is 3.5973145246505736 and perplexity is 36.500082638361214
At time: 593.2992751598358 and batch: 1650, loss is 3.525168890953064 and perplexity is 33.95950858571231
At time: 594.6174626350403 and batch: 1700, loss is 3.5536919403076173 and perplexity is 34.942083730055266
At time: 595.9369556903839 and batch: 1750, loss is 3.5552072095870972 and perplexity is 34.99507053058964
At time: 597.2558023929596 and batch: 1800, loss is 3.4890145015716554 and perplexity is 32.75365312204032
At time: 598.5707123279572 and batch: 1850, loss is 3.518229203224182 and perplexity is 33.72465604487546
At time: 599.8873240947723 and batch: 1900, loss is 3.6086928129196165 and perplexity is 36.91776283706396
At time: 601.2056541442871 and batch: 1950, loss is 3.5409778928756714 and perplexity is 34.500640630871196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386517475926599 and perplexity of 80.36007521537718
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 605.1800553798676 and batch: 50, loss is 3.788222885131836 and perplexity is 44.17782141155589
At time: 606.494556427002 and batch: 100, loss is 3.780206460952759 and perplexity is 43.82508897121512
At time: 607.8122375011444 and batch: 150, loss is 3.7647698068618776 and perplexity is 43.15377101446563
At time: 609.1288962364197 and batch: 200, loss is 3.7810728693008424 and perplexity is 43.86307584785253
At time: 610.4455938339233 and batch: 250, loss is 3.780524091720581 and perplexity is 43.839011378850394
At time: 611.7610793113708 and batch: 300, loss is 3.797590789794922 and perplexity is 44.59361956872568
At time: 613.0753650665283 and batch: 350, loss is 3.8210326719284056 and perplexity is 45.6513268313931
At time: 614.3903863430023 and batch: 400, loss is 3.7938902807235717 and perplexity is 44.42890542603992
At time: 615.7086653709412 and batch: 450, loss is 3.8288197708129883 and perplexity is 46.00820595074279
At time: 617.0267357826233 and batch: 500, loss is 3.8284238147735596 and perplexity is 45.989992329867874
At time: 618.3448302745819 and batch: 550, loss is 3.7875766372680664 and perplexity is 44.14928081198672
At time: 619.660727262497 and batch: 600, loss is 3.735800485610962 and perplexity is 41.921569748865416
At time: 620.9763617515564 and batch: 650, loss is 3.7456955099105835 and perplexity is 42.3384437881917
At time: 622.2943515777588 and batch: 700, loss is 3.802254009246826 and perplexity is 44.80205501533095
At time: 623.6123011112213 and batch: 750, loss is 3.766383194923401 and perplexity is 43.22345098873451
At time: 624.9293301105499 and batch: 800, loss is 3.7389810276031494 and perplexity is 42.05511532290595
At time: 626.2445375919342 and batch: 850, loss is 3.730957474708557 and perplexity is 41.7190339668946
At time: 627.5598747730255 and batch: 900, loss is 3.6849486112594603 and perplexity is 39.8430749118127
At time: 628.8759908676147 and batch: 950, loss is 3.7889587259292603 and perplexity is 44.21034121812468
At time: 630.1938405036926 and batch: 1000, loss is 3.73719172000885 and perplexity is 41.97993306782828
At time: 631.5109794139862 and batch: 1050, loss is 3.6859045314788816 and perplexity is 39.88117992249827
At time: 632.8267722129822 and batch: 1100, loss is 3.6949293661117553 and perplexity is 40.242729987088275
At time: 634.1654210090637 and batch: 1150, loss is 3.652927198410034 and perplexity is 38.58745402617592
At time: 635.4858646392822 and batch: 1200, loss is 3.695749673843384 and perplexity is 40.27575495310412
At time: 636.8077628612518 and batch: 1250, loss is 3.662103090286255 and perplexity is 38.943157785956565
At time: 638.1277210712433 and batch: 1300, loss is 3.6831546449661254 and perplexity is 39.77166185386
At time: 639.4483051300049 and batch: 1350, loss is 3.5733464574813842 and perplexity is 35.63564701373299
At time: 640.764937877655 and batch: 1400, loss is 3.6174890279769896 and perplexity is 37.24393184170647
At time: 642.0833168029785 and batch: 1450, loss is 3.5304661226272582 and perplexity is 34.13987727582988
At time: 643.4021756649017 and batch: 1500, loss is 3.524541964530945 and perplexity is 33.938225144770584
At time: 644.7230739593506 and batch: 1550, loss is 3.5220587491989135 and perplexity is 33.85405377481991
At time: 646.0405697822571 and batch: 1600, loss is 3.606756930351257 and perplexity is 36.84636351617347
At time: 647.3584749698639 and batch: 1650, loss is 3.5309459352493286 and perplexity is 34.156261950335235
At time: 648.6768448352814 and batch: 1700, loss is 3.5531492757797243 and perplexity is 34.92312704470985
At time: 649.9950850009918 and batch: 1750, loss is 3.5586448192596434 and perplexity is 35.11557693185206
At time: 651.3184232711792 and batch: 1800, loss is 3.4872070789337157 and perplexity is 32.69450689512851
At time: 652.6362833976746 and batch: 1850, loss is 3.5062431859970093 and perplexity is 33.32284460644805
At time: 653.9519951343536 and batch: 1900, loss is 3.593493275642395 and perplexity is 36.360872880749426
At time: 655.2666668891907 and batch: 1950, loss is 3.5309133672714235 and perplexity is 34.155149568064836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365938124545785 and perplexity of 78.72321749398863
finished 12 epochs...
Completing Train Step...
At time: 659.2348096370697 and batch: 50, loss is 3.7912610578536987 and perplexity is 44.31224536166906
At time: 660.5496883392334 and batch: 100, loss is 3.7676827907562256 and perplexity is 43.27966052244641
At time: 661.8623416423798 and batch: 150, loss is 3.7437293577194213 and perplexity is 42.25528174557363
At time: 663.1754846572876 and batch: 200, loss is 3.755603790283203 and perplexity is 42.7600301084537
At time: 664.4917478561401 and batch: 250, loss is 3.7524810361862184 and perplexity is 42.62670932160283
At time: 665.8075759410858 and batch: 300, loss is 3.7673020267486574 and perplexity is 43.26318432243073
At time: 667.134861946106 and batch: 350, loss is 3.791346344947815 and perplexity is 44.31602478547548
At time: 668.4492847919464 and batch: 400, loss is 3.765110559463501 and perplexity is 43.168478279835824
At time: 669.7668061256409 and batch: 450, loss is 3.800294337272644 and perplexity is 44.71434365454935
At time: 671.085052728653 and batch: 500, loss is 3.7980418014526367 and perplexity is 44.61373634712066
At time: 672.4049320220947 and batch: 550, loss is 3.7556570959091187 and perplexity is 42.762309519374966
At time: 673.7232732772827 and batch: 600, loss is 3.707058854103088 and perplexity is 40.73382604808611
At time: 675.0414769649506 and batch: 650, loss is 3.719705171585083 and perplexity is 41.25222998595585
At time: 676.3604702949524 and batch: 700, loss is 3.7744731807708742 and perplexity is 43.57454635893206
At time: 677.6859660148621 and batch: 750, loss is 3.7430416345596313 and perplexity is 42.2262317999989
At time: 679.0153777599335 and batch: 800, loss is 3.716188292503357 and perplexity is 41.107405695273734
At time: 680.3455898761749 and batch: 850, loss is 3.7083456993103026 and perplexity is 40.786277918388315
At time: 681.6645951271057 and batch: 900, loss is 3.6641701316833495 and perplexity is 39.023738158025104
At time: 682.9821648597717 and batch: 950, loss is 3.7688811731338503 and perplexity is 43.33155719474404
At time: 684.300192117691 and batch: 1000, loss is 3.716576323509216 and perplexity is 41.12335973838545
At time: 685.6193919181824 and batch: 1050, loss is 3.665863494873047 and perplexity is 39.08987550121355
At time: 686.9376459121704 and batch: 1100, loss is 3.676123466491699 and perplexity is 39.49300100624072
At time: 688.2559685707092 and batch: 1150, loss is 3.636973419189453 and perplexity is 37.97672299170812
At time: 689.5713939666748 and batch: 1200, loss is 3.6841826152801516 and perplexity is 39.812566962601885
At time: 690.8881800174713 and batch: 1250, loss is 3.6537125730514526 and perplexity is 38.617771537789025
At time: 692.2065622806549 and batch: 1300, loss is 3.675257196426392 and perplexity is 39.45880421564638
At time: 693.5231065750122 and batch: 1350, loss is 3.565473418235779 and perplexity is 35.356187706813174
At time: 694.8484103679657 and batch: 1400, loss is 3.6085072326660157 and perplexity is 36.9109122649594
At time: 696.1651883125305 and batch: 1450, loss is 3.5190808629989623 and perplexity is 33.75339021197752
At time: 697.4808373451233 and batch: 1500, loss is 3.5115956449508667 and perplexity is 33.50168194723651
At time: 698.7981357574463 and batch: 1550, loss is 3.5118928384780883 and perplexity is 33.511639909909995
At time: 700.1179320812225 and batch: 1600, loss is 3.5999492597579956 and perplexity is 36.59637748751698
At time: 701.4362087249756 and batch: 1650, loss is 3.526003189086914 and perplexity is 33.98785276245462
At time: 702.755077123642 and batch: 1700, loss is 3.5508190488815305 and perplexity is 34.84184297664289
At time: 704.0728697776794 and batch: 1750, loss is 3.5591846084594727 and perplexity is 35.13453705780089
At time: 705.3890843391418 and batch: 1800, loss is 3.490292353630066 and perplexity is 32.795534198313554
At time: 706.7067015171051 and batch: 1850, loss is 3.511118030548096 and perplexity is 33.48568488193995
At time: 708.024087190628 and batch: 1900, loss is 3.5994495725631714 and perplexity is 36.578095314373826
At time: 709.3395962715149 and batch: 1950, loss is 3.5363555431365965 and perplexity is 34.34153460878274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364281374909157 and perplexity of 78.5929008128763
finished 13 epochs...
Completing Train Step...
At time: 713.3227708339691 and batch: 50, loss is 3.785816354751587 and perplexity is 44.07163396510143
At time: 714.6414477825165 and batch: 100, loss is 3.7594964027404787 and perplexity is 42.92680271430472
At time: 715.959105014801 and batch: 150, loss is 3.73325767993927 and perplexity is 41.8151067582545
At time: 717.2760217189789 and batch: 200, loss is 3.744014120101929 and perplexity is 42.26731617367192
At time: 718.593400478363 and batch: 250, loss is 3.7399868297576906 and perplexity is 42.09743572791673
At time: 719.9127600193024 and batch: 300, loss is 3.7544464302062988 and perplexity is 42.71056998382668
At time: 721.2319860458374 and batch: 350, loss is 3.778992648124695 and perplexity is 43.77192578763522
At time: 722.5582602024078 and batch: 400, loss is 3.7529072380065918 and perplexity is 42.644880774790366
At time: 723.8824028968811 and batch: 450, loss is 3.787923731803894 and perplexity is 44.16460744585885
At time: 725.2056450843811 and batch: 500, loss is 3.7832682514190674 and perplexity is 43.95947784110625
At time: 726.5328452587128 and batch: 550, loss is 3.737856192588806 and perplexity is 42.007836851883255
At time: 727.8613038063049 and batch: 600, loss is 3.6906139135360716 and perplexity is 40.06943857867598
At time: 729.1867656707764 and batch: 650, loss is 3.7055571413040163 and perplexity is 40.672701447439145
At time: 730.5069887638092 and batch: 700, loss is 3.7603292083740234 and perplexity is 42.962567287837324
At time: 731.8221158981323 and batch: 750, loss is 3.7307341289520264 and perplexity is 41.70971723815618
At time: 733.1523706912994 and batch: 800, loss is 3.705918483734131 and perplexity is 40.68740087582314
At time: 734.4693837165833 and batch: 850, loss is 3.6994738721847535 and perplexity is 40.426029505329
At time: 735.7879545688629 and batch: 900, loss is 3.655780019760132 and perplexity is 38.697694312021554
At time: 737.1064484119415 and batch: 950, loss is 3.760965356826782 and perplexity is 42.98990655353782
At time: 738.4250707626343 and batch: 1000, loss is 3.708072748184204 and perplexity is 40.775146777099
At time: 739.7399952411652 and batch: 1050, loss is 3.656927237510681 and perplexity is 38.74211446876597
At time: 741.0565569400787 and batch: 1100, loss is 3.666917815208435 and perplexity is 39.131110485483795
At time: 742.3747305870056 and batch: 1150, loss is 3.62888072013855 and perplexity is 37.670629035283326
At time: 743.6925029754639 and batch: 1200, loss is 3.677195372581482 and perplexity is 39.53535649101866
At time: 745.0099513530731 and batch: 1250, loss is 3.6475706624984743 and perplexity is 38.38131154065697
At time: 746.3275411128998 and batch: 1300, loss is 3.6690586948394777 and perplexity is 39.214975222984485
At time: 747.6439354419708 and batch: 1350, loss is 3.5596546173095702 and perplexity is 35.151054482525964
At time: 748.962851524353 and batch: 1400, loss is 3.603229732513428 and perplexity is 36.71662803830045
At time: 750.2811839580536 and batch: 1450, loss is 3.5130790948867796 and perplexity is 33.55141689570651
At time: 751.5981206893921 and batch: 1500, loss is 3.50402144908905 and perplexity is 33.24889219452901
At time: 752.9143240451813 and batch: 1550, loss is 3.505909719467163 and perplexity is 33.31173440563554
At time: 754.2308523654938 and batch: 1600, loss is 3.5950217962265016 and perplexity is 36.41649372137437
At time: 755.546959400177 and batch: 1650, loss is 3.5216421937942504 and perplexity is 33.839954622493174
At time: 756.8650114536285 and batch: 1700, loss is 3.5479341983795165 and perplexity is 34.741474312345105
At time: 758.1802575588226 and batch: 1750, loss is 3.5577254247665406 and perplexity is 35.083306700608375
At time: 759.4988443851471 and batch: 1800, loss is 3.4898197412490846 and perplexity is 32.78003828487924
At time: 760.8147926330566 and batch: 1850, loss is 3.511522889137268 and perplexity is 33.4992445937764
At time: 762.1321218013763 and batch: 1900, loss is 3.600028247833252 and perplexity is 36.59926827910361
At time: 763.4492404460907 and batch: 1950, loss is 3.5368081951141357 and perplexity is 34.35708289105001
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364211539335029 and perplexity of 78.58741242417025
finished 14 epochs...
Completing Train Step...
At time: 767.4264523983002 and batch: 50, loss is 3.779883975982666 and perplexity is 43.81095831729315
At time: 768.751677274704 and batch: 100, loss is 3.7522005939483645 and perplexity is 42.61475666794114
At time: 770.0691211223602 and batch: 150, loss is 3.724965043067932 and perplexity is 41.46978306310327
At time: 771.3858346939087 and batch: 200, loss is 3.734785308837891 and perplexity is 41.87903353950466
At time: 772.7193789482117 and batch: 250, loss is 3.7301424837112425 and perplexity is 41.68504718113833
At time: 774.040299654007 and batch: 300, loss is 3.744487314224243 and perplexity is 42.28732155209175
At time: 775.3563823699951 and batch: 350, loss is 3.769194345474243 and perplexity is 43.345129565058144
At time: 776.679770231247 and batch: 400, loss is 3.7434978914260864 and perplexity is 42.245502203994945
At time: 778.0076203346252 and batch: 450, loss is 3.778502388000488 and perplexity is 43.750471417402636
At time: 779.3252625465393 and batch: 500, loss is 3.77219895362854 and perplexity is 43.47556054366535
At time: 780.6422367095947 and batch: 550, loss is 3.724340629577637 and perplexity is 41.44389685380928
At time: 781.9570159912109 and batch: 600, loss is 3.6784754037857055 and perplexity is 39.58599538376447
At time: 783.273033618927 and batch: 650, loss is 3.6950314807891846 and perplexity is 40.246839570300594
At time: 784.5901894569397 and batch: 700, loss is 3.749486737251282 and perplexity is 42.49926311252705
At time: 785.9083898067474 and batch: 750, loss is 3.7212161445617675 and perplexity is 41.31460810465081
At time: 787.2262027263641 and batch: 800, loss is 3.697999258041382 and perplexity is 40.366460641798724
At time: 788.5420694351196 and batch: 850, loss is 3.692818078994751 and perplexity is 40.15785565827946
At time: 789.8580741882324 and batch: 900, loss is 3.6497293281555176 and perplexity is 38.464253449469126
At time: 791.1758322715759 and batch: 950, loss is 3.7554973220825194 and perplexity is 42.75547776733095
At time: 792.4947760105133 and batch: 1000, loss is 3.702173070907593 and perplexity is 40.535294790559156
At time: 793.8114261627197 and batch: 1050, loss is 3.650909605026245 and perplexity is 38.50967872009014
At time: 795.1287467479706 and batch: 1100, loss is 3.6606061840057373 and perplexity is 38.88490713724152
At time: 796.4449338912964 and batch: 1150, loss is 3.6229853725433347 and perplexity is 37.44920092215014
At time: 797.7942986488342 and batch: 1200, loss is 3.671615414619446 and perplexity is 39.31536520564936
At time: 799.1117033958435 and batch: 1250, loss is 3.641935362815857 and perplexity is 38.16562963477809
At time: 800.435271024704 and batch: 1300, loss is 3.6633726358413696 and perplexity is 38.99262929534866
At time: 801.7711427211761 and batch: 1350, loss is 3.5544342374801636 and perplexity is 34.968030769026385
At time: 803.0946073532104 and batch: 1400, loss is 3.59851580619812 and perplexity is 36.54395586088889
At time: 804.4256269931793 and batch: 1450, loss is 3.508433690071106 and perplexity is 33.395918438363005
At time: 805.7420964241028 and batch: 1500, loss is 3.4984621477127074 and perplexity is 33.06456442393781
At time: 807.0564630031586 and batch: 1550, loss is 3.5010691022872926 and perplexity is 33.15087469601687
At time: 808.3706068992615 and batch: 1600, loss is 3.590449767112732 and perplexity is 36.25037648764181
At time: 809.6839842796326 and batch: 1650, loss is 3.5172697734832763 and perplexity is 33.692315123765795
At time: 810.9969878196716 and batch: 1700, loss is 3.544542360305786 and perplexity is 34.62383647406535
At time: 812.3122508525848 and batch: 1750, loss is 3.5554016828536987 and perplexity is 35.00187679806776
At time: 813.6281571388245 and batch: 1800, loss is 3.488053059577942 and perplexity is 32.72217751788966
At time: 814.9458663463593 and batch: 1850, loss is 3.510433955192566 and perplexity is 33.46278598332826
At time: 816.2609786987305 and batch: 1900, loss is 3.599014983177185 and perplexity is 36.562202316104916
At time: 817.5750434398651 and batch: 1950, loss is 3.53573881149292 and perplexity is 34.320361627391996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364781295421512 and perplexity of 78.63220083874415
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 821.5309362411499 and batch: 50, loss is 3.7788361883163453 and perplexity is 43.76507777624864
At time: 822.858720779419 and batch: 100, loss is 3.7601350498199464 and perplexity is 42.954226547632516
At time: 824.1708796024323 and batch: 150, loss is 3.740055356025696 and perplexity is 42.10032060692363
At time: 825.4855358600616 and batch: 200, loss is 3.7571314573287964 and perplexity is 42.82540311870189
At time: 826.8010053634644 and batch: 250, loss is 3.758047409057617 and perplexity is 42.86464709077424
At time: 828.1164855957031 and batch: 300, loss is 3.774866943359375 and perplexity is 43.591707763636926
At time: 829.4450116157532 and batch: 350, loss is 3.8004917097091675 and perplexity is 44.72316990450457
At time: 830.7702980041504 and batch: 400, loss is 3.780732045173645 and perplexity is 43.848128800612336
At time: 832.0912218093872 and batch: 450, loss is 3.8257680177688598 and perplexity is 45.86801429214086
At time: 833.410453081131 and batch: 500, loss is 3.8268039655685424 and perplexity is 45.91555578162158
At time: 834.7302074432373 and batch: 550, loss is 3.7969200944900514 and perplexity is 44.56372086503463
At time: 836.0505936145782 and batch: 600, loss is 3.74001944065094 and perplexity is 42.09880858528426
At time: 837.3694298267365 and batch: 650, loss is 3.737738318443298 and perplexity is 42.00288550583328
At time: 838.6876780986786 and batch: 700, loss is 3.776708359718323 and perplexity is 43.67205219850297
At time: 840.0072658061981 and batch: 750, loss is 3.735173201560974 and perplexity is 41.895281262847504
At time: 841.3275299072266 and batch: 800, loss is 3.7053490257263184 and perplexity is 40.664237705429706
At time: 842.6479825973511 and batch: 850, loss is 3.70012387752533 and perplexity is 40.4523151823955
At time: 843.9665153026581 and batch: 900, loss is 3.661292243003845 and perplexity is 38.91159363088142
At time: 845.2842137813568 and batch: 950, loss is 3.7815777349472044 and perplexity is 43.88522639904756
At time: 846.602655172348 and batch: 1000, loss is 3.744321141242981 and perplexity is 42.280295125617144
At time: 847.9221289157867 and batch: 1050, loss is 3.6995712518692017 and perplexity is 40.42996637100798
At time: 849.2428615093231 and batch: 1100, loss is 3.7183376789093017 and perplexity is 41.19585641759638
At time: 850.5637226104736 and batch: 1150, loss is 3.685762391090393 and perplexity is 39.875511598949096
At time: 851.8815314769745 and batch: 1200, loss is 3.7407394647598267 and perplexity is 42.12913165778265
At time: 853.2002375125885 and batch: 1250, loss is 3.696943130493164 and perplexity is 40.323851015251655
At time: 854.5191071033478 and batch: 1300, loss is 3.697818441390991 and perplexity is 40.35916237344145
At time: 855.8391578197479 and batch: 1350, loss is 3.565270872116089 and perplexity is 35.349027173379746
At time: 857.1599168777466 and batch: 1400, loss is 3.595604076385498 and perplexity is 36.4377044978364
At time: 858.4798994064331 and batch: 1450, loss is 3.4987711334228515 and perplexity is 33.074782480392365
At time: 859.7985641956329 and batch: 1500, loss is 3.493470621109009 and perplexity is 32.899932993878
At time: 861.1184899806976 and batch: 1550, loss is 3.4999156332015993 and perplexity is 33.112658231883515
At time: 862.4458696842194 and batch: 1600, loss is 3.5859104347229005 and perplexity is 36.08619689429809
At time: 863.7651109695435 and batch: 1650, loss is 3.5123394298553468 and perplexity is 33.526609261674466
At time: 865.0847446918488 and batch: 1700, loss is 3.536964564323425 and perplexity is 34.36245570099525
At time: 866.4043526649475 and batch: 1750, loss is 3.546524748802185 and perplexity is 34.692542447658155
At time: 867.7220075130463 and batch: 1800, loss is 3.481162781715393 and perplexity is 32.4974875994554
At time: 869.0499806404114 and batch: 1850, loss is 3.5058183002471925 and perplexity is 33.30868921205705
At time: 870.3719356060028 and batch: 1900, loss is 3.599046859741211 and perplexity is 36.56336781206389
At time: 871.6915533542633 and batch: 1950, loss is 3.5484346389770507 and perplexity is 34.758864707576144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358054937318314 and perplexity of 78.10506732929937
finished 16 epochs...
Completing Train Step...
At time: 875.6690006256104 and batch: 50, loss is 3.7976352882385256 and perplexity is 44.59560395954197
At time: 877.0010464191437 and batch: 100, loss is 3.770691056251526 and perplexity is 43.4100532614991
At time: 878.3213410377502 and batch: 150, loss is 3.7428934955596924 and perplexity is 42.219976911556756
At time: 879.6381950378418 and batch: 200, loss is 3.750389270782471 and perplexity is 42.53763743698934
At time: 880.958046913147 and batch: 250, loss is 3.7481194162368774 and perplexity is 42.441192686480726
At time: 882.286985874176 and batch: 300, loss is 3.7610959577560426 and perplexity is 42.99552144192938
At time: 883.6174919605255 and batch: 350, loss is 3.782304072380066 and perplexity is 43.917113460712166
At time: 884.9397172927856 and batch: 400, loss is 3.7624253129959104 and perplexity is 43.05271577101684
At time: 886.2587201595306 and batch: 450, loss is 3.8068594455718996 and perplexity is 45.00886388393912
At time: 887.5763509273529 and batch: 500, loss is 3.812589840888977 and perplexity is 45.267522868074686
At time: 888.8947818279266 and batch: 550, loss is 3.7830268573760986 and perplexity is 43.94886756570355
At time: 890.2135345935822 and batch: 600, loss is 3.7283155632019045 and perplexity is 41.60896143597677
At time: 891.5387535095215 and batch: 650, loss is 3.727327237129211 and perplexity is 41.56785852941475
At time: 892.8580176830292 and batch: 700, loss is 3.7683943939208984 and perplexity is 43.31046942639684
At time: 894.1744132041931 and batch: 750, loss is 3.7253554916381835 and perplexity is 41.485978042056345
At time: 895.4911608695984 and batch: 800, loss is 3.696070351600647 and perplexity is 40.28867256295894
At time: 896.8237583637238 and batch: 850, loss is 3.6904794120788575 and perplexity is 40.06404954322208
At time: 898.140557050705 and batch: 900, loss is 3.651388716697693 and perplexity is 38.528133577244354
At time: 899.4578576087952 and batch: 950, loss is 3.7693032026290894 and perplexity is 43.34984824936565
At time: 900.7740962505341 and batch: 1000, loss is 3.7295352172851564 and perplexity is 41.659740936109586
At time: 902.0898687839508 and batch: 1050, loss is 3.683790712356567 and perplexity is 39.79696735817879
At time: 903.4069468975067 and batch: 1100, loss is 3.70223210811615 and perplexity is 40.53768795185371
At time: 904.7252871990204 and batch: 1150, loss is 3.668691568374634 and perplexity is 39.200581010171845
At time: 906.0428998470306 and batch: 1200, loss is 3.721194934844971 and perplexity is 41.313731842806014
At time: 907.3610332012177 and batch: 1250, loss is 3.678871808052063 and perplexity is 39.601690551832874
At time: 908.67618227005 and batch: 1300, loss is 3.6832132720947266 and perplexity is 39.773993620545916
At time: 909.9921398162842 and batch: 1350, loss is 3.5568769931793214 and perplexity is 35.05355353856551
At time: 911.3101694583893 and batch: 1400, loss is 3.591146683692932 and perplexity is 36.27564878137193
At time: 912.6287596225739 and batch: 1450, loss is 3.4989219760894774 and perplexity is 33.0797719450824
At time: 913.9466235637665 and batch: 1500, loss is 3.498359513282776 and perplexity is 33.06117103535946
At time: 915.2621235847473 and batch: 1550, loss is 3.506175408363342 and perplexity is 33.3205861394312
At time: 916.5811469554901 and batch: 1600, loss is 3.592020468711853 and perplexity is 36.307359752096694
At time: 917.9116435050964 and batch: 1650, loss is 3.5188172912597655 and perplexity is 33.74449494453761
At time: 919.2325007915497 and batch: 1700, loss is 3.5434264087677003 and perplexity is 34.5852195018401
At time: 920.5513944625854 and batch: 1750, loss is 3.55496346950531 and perplexity is 34.986541868666976
At time: 921.8658969402313 and batch: 1800, loss is 3.489341254234314 and perplexity is 32.7643572141098
At time: 923.1801061630249 and batch: 1850, loss is 3.5131393098831176 and perplexity is 33.55343725497938
At time: 924.4946444034576 and batch: 1900, loss is 3.605812110900879 and perplexity is 36.811566796145165
At time: 925.8108928203583 and batch: 1950, loss is 3.553695011138916 and perplexity is 34.942191031464375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355629428597384 and perplexity of 77.91585237137272
finished 17 epochs...
Completing Train Step...
At time: 929.7600131034851 and batch: 50, loss is 3.7971180152893065 and perplexity is 44.57254182518297
At time: 931.0763783454895 and batch: 100, loss is 3.767830352783203 and perplexity is 43.28604742810079
At time: 932.3945717811584 and batch: 150, loss is 3.7380169296264647 and perplexity is 42.01458960983189
At time: 933.7129848003387 and batch: 200, loss is 3.7437770128250123 and perplexity is 42.25729547346883
At time: 935.0308260917664 and batch: 250, loss is 3.7404776334762575 and perplexity is 42.118102377133404
At time: 936.3456449508667 and batch: 300, loss is 3.7525061988830566 and perplexity is 42.6277819380616
At time: 937.6615221500397 and batch: 350, loss is 3.774089984893799 and perplexity is 43.55785197123644
At time: 938.9794080257416 and batch: 400, loss is 3.7533998250961305 and perplexity is 42.665892267065004
At time: 940.2986688613892 and batch: 450, loss is 3.797623567581177 and perplexity is 44.59508127281182
At time: 941.6173641681671 and batch: 500, loss is 3.803561429977417 and perplexity is 44.86066845869731
At time: 942.9350299835205 and batch: 550, loss is 3.7737038564682006 and perplexity is 43.541036293146924
At time: 944.251645565033 and batch: 600, loss is 3.7207854175567627 and perplexity is 41.29681661915065
At time: 945.5699949264526 and batch: 650, loss is 3.7208360242843628 and perplexity is 41.29890656878235
At time: 946.8972315788269 and batch: 700, loss is 3.7621746969223024 and perplexity is 43.04192742035566
At time: 948.2250430583954 and batch: 750, loss is 3.720098738670349 and perplexity is 41.268468701174456
At time: 949.5405106544495 and batch: 800, loss is 3.6912648820877076 and perplexity is 40.09553101482868
At time: 950.8570489883423 and batch: 850, loss is 3.6867572689056396 and perplexity is 39.91520260138561
At time: 952.1813032627106 and batch: 900, loss is 3.647992706298828 and perplexity is 38.3975135539813
At time: 953.5000514984131 and batch: 950, loss is 3.765645718574524 and perplexity is 43.191586467023235
At time: 954.817901134491 and batch: 1000, loss is 3.7254299211502073 and perplexity is 41.489065938071725
At time: 956.1351540088654 and batch: 1050, loss is 3.679860095977783 and perplexity is 39.640847770559475
At time: 957.4513483047485 and batch: 1100, loss is 3.698141641616821 and perplexity is 40.372208571988445
At time: 958.7700846195221 and batch: 1150, loss is 3.6647259759902955 and perplexity is 39.04543531027664
At time: 960.0893220901489 and batch: 1200, loss is 3.717164616584778 and perplexity is 41.14755944372498
At time: 961.4073944091797 and batch: 1250, loss is 3.675360107421875 and perplexity is 39.4628651694236
At time: 962.7241387367249 and batch: 1300, loss is 3.6799978113174436 and perplexity is 39.646307299296424
At time: 964.0405652523041 and batch: 1350, loss is 3.5544575595855714 and perplexity is 34.96884630663587
At time: 965.3606605529785 and batch: 1400, loss is 3.5891053533554076 and perplexity is 36.201673728449016
At time: 966.681009054184 and batch: 1450, loss is 3.497653298377991 and perplexity is 33.037830986120014
At time: 967.9984667301178 and batch: 1500, loss is 3.497355465888977 and perplexity is 33.02799271183738
At time: 969.3171348571777 and batch: 1550, loss is 3.50575888633728 and perplexity is 33.30671027138578
At time: 970.6344447135925 and batch: 1600, loss is 3.5918934869766237 and perplexity is 36.30274967325787
At time: 971.9486496448517 and batch: 1650, loss is 3.519187502861023 and perplexity is 33.75698986078342
At time: 973.2657203674316 and batch: 1700, loss is 3.5441968727111814 and perplexity is 34.61187643422761
At time: 974.5909395217896 and batch: 1750, loss is 3.556789903640747 and perplexity is 35.05050087369195
At time: 975.9075739383698 and batch: 1800, loss is 3.4910474729537966 and perplexity is 32.82030809236465
At time: 977.2242956161499 and batch: 1850, loss is 3.5151136112213135 and perplexity is 33.61974728750696
At time: 978.5388503074646 and batch: 1900, loss is 3.6074792766571044 and perplexity is 36.87298896598321
At time: 979.8547039031982 and batch: 1950, loss is 3.554696364402771 and perplexity is 34.97719803276233
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3547184434047965 and perplexity of 77.84490450472916
finished 18 epochs...
Completing Train Step...
At time: 983.8484201431274 and batch: 50, loss is 3.795169725418091 and perplexity is 44.48578613347086
At time: 985.1778614521027 and batch: 100, loss is 3.7648396635055543 and perplexity is 43.15678569736728
At time: 986.4951951503754 and batch: 150, loss is 3.7344601821899412 and perplexity is 41.86541976293129
At time: 987.8119370937347 and batch: 200, loss is 3.739217019081116 and perplexity is 42.06504114288545
At time: 989.1294553279877 and batch: 250, loss is 3.7355997133255006 and perplexity is 41.91315390435924
At time: 990.4464769363403 and batch: 300, loss is 3.747146000862122 and perplexity is 42.399899877784705
At time: 991.7624111175537 and batch: 350, loss is 3.7689272499084474 and perplexity is 43.3335538191365
At time: 993.0783879756927 and batch: 400, loss is 3.7479474401474 and perplexity is 42.43389444370935
At time: 994.4080510139465 and batch: 450, loss is 3.7925172948837282 and perplexity is 44.36794702509688
At time: 995.7272741794586 and batch: 500, loss is 3.798655796051025 and perplexity is 44.641137351425215
At time: 997.0444006919861 and batch: 550, loss is 3.768823652267456 and perplexity is 43.329064797715084
At time: 998.3600325584412 and batch: 600, loss is 3.7167215824127195 and perplexity is 41.12933370640495
At time: 999.675586938858 and batch: 650, loss is 3.717157831192017 and perplexity is 41.14728024232025
At time: 1000.9918913841248 and batch: 700, loss is 3.7585804796218873 and perplexity is 42.887503063768136
At time: 1002.3098020553589 and batch: 750, loss is 3.7170560503005983 and perplexity is 41.14309244858004
At time: 1003.6290011405945 and batch: 800, loss is 3.6883209276199342 and perplexity is 39.977665178115416
At time: 1004.9461197853088 and batch: 850, loss is 3.6840878391265868 and perplexity is 39.808793859444556
At time: 1006.2604932785034 and batch: 900, loss is 3.6455104303359986 and perplexity is 38.302318528096315
At time: 1007.5771179199219 and batch: 950, loss is 3.7630574989318846 and perplexity is 43.07994169744991
At time: 1008.8939471244812 and batch: 1000, loss is 3.7225716495513916 and perplexity is 41.37064823483843
At time: 1010.2126705646515 and batch: 1050, loss is 3.677214388847351 and perplexity is 39.53610831301733
At time: 1011.5335042476654 and batch: 1100, loss is 3.695435447692871 and perplexity is 40.263101245833184
At time: 1012.8504242897034 and batch: 1150, loss is 3.6621616649627686 and perplexity is 38.94543893563444
At time: 1014.1661534309387 and batch: 1200, loss is 3.714802680015564 and perplexity is 41.050486203887374
At time: 1015.4828805923462 and batch: 1250, loss is 3.6733646965026856 and perplexity is 39.38419904908162
At time: 1016.8000264167786 and batch: 1300, loss is 3.6781052637100218 and perplexity is 39.571345731816
At time: 1018.1171653270721 and batch: 1350, loss is 3.5527080631256105 and perplexity is 34.907721917854865
At time: 1019.4360611438751 and batch: 1400, loss is 3.5873458099365236 and perplexity is 36.13803131889869
At time: 1020.757346868515 and batch: 1450, loss is 3.496200590133667 and perplexity is 32.98987150067616
At time: 1022.0720958709717 and batch: 1500, loss is 3.4955894565582275 and perplexity is 32.96971644189654
At time: 1023.389194726944 and batch: 1550, loss is 3.5044732999801638 and perplexity is 33.26391913080725
At time: 1024.7043762207031 and batch: 1600, loss is 3.59098069190979 and perplexity is 36.26962782147483
At time: 1026.020188331604 and batch: 1650, loss is 3.518619966506958 and perplexity is 33.73783697732654
At time: 1027.336014032364 and batch: 1700, loss is 3.543986339569092 and perplexity is 34.6045902541464
At time: 1028.6508247852325 and batch: 1750, loss is 3.557276339530945 and perplexity is 35.067554842781384
At time: 1029.9672441482544 and batch: 1800, loss is 3.4914745092391968 and perplexity is 32.834326547799634
At time: 1031.2834186553955 and batch: 1850, loss is 3.515864453315735 and perplexity is 33.644999888145634
At time: 1032.602200269699 and batch: 1900, loss is 3.607959246635437 and perplexity is 36.89069114161486
At time: 1033.9185771942139 and batch: 1950, loss is 3.554797286987305 and perplexity is 34.98072820012136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35436273619186 and perplexity of 77.81721943488793
finished 19 epochs...
Completing Train Step...
At time: 1037.9130368232727 and batch: 50, loss is 3.7931724166870118 and perplexity is 44.39702295765873
At time: 1039.2312512397766 and batch: 100, loss is 3.7622467708587646 and perplexity is 43.04502973329437
At time: 1040.547759771347 and batch: 150, loss is 3.7316094064712524 and perplexity is 41.74624079778159
At time: 1041.8626244068146 and batch: 200, loss is 3.735702772140503 and perplexity is 41.91747364692359
At time: 1043.1784749031067 and batch: 250, loss is 3.732033920288086 and perplexity is 41.763966415919825
At time: 1044.4968280792236 and batch: 300, loss is 3.743327331542969 and perplexity is 42.23829743051692
At time: 1045.8144946098328 and batch: 350, loss is 3.7652892017364503 and perplexity is 43.17619068377568
At time: 1047.1326823234558 and batch: 400, loss is 3.7441509675979616 and perplexity is 42.273100745847394
At time: 1048.4482645988464 and batch: 450, loss is 3.7890103387832643 and perplexity is 44.21262309889812
At time: 1049.7643032073975 and batch: 500, loss is 3.7952560901641847 and perplexity is 44.48962830300667
At time: 1051.0805258750916 and batch: 550, loss is 3.765362424850464 and perplexity is 43.17935229465887
At time: 1052.3978564739227 and batch: 600, loss is 3.71366548538208 and perplexity is 41.00383034469875
At time: 1053.7160437107086 and batch: 650, loss is 3.7142697191238403 and perplexity is 41.028613729258986
At time: 1055.0334839820862 and batch: 700, loss is 3.755595178604126 and perplexity is 42.75966187438264
At time: 1056.3498220443726 and batch: 750, loss is 3.714327130317688 and perplexity is 41.03096929857248
At time: 1057.666758298874 and batch: 800, loss is 3.6856769132614136 and perplexity is 39.872103272458425
At time: 1058.984069108963 and batch: 850, loss is 3.6815351486206054 and perplexity is 39.7073039206176
At time: 1060.3125658035278 and batch: 900, loss is 3.643164372444153 and perplexity is 38.21256439679864
At time: 1061.6305029392242 and batch: 950, loss is 3.7606809616088865 and perplexity is 42.97768216805701
At time: 1062.9472830295563 and batch: 1000, loss is 3.7200672674179076 and perplexity is 41.26716995121484
At time: 1064.2629277706146 and batch: 1050, loss is 3.6749785470962526 and perplexity is 39.44781057803961
At time: 1065.5805208683014 and batch: 1100, loss is 3.693238115310669 and perplexity is 40.17472695905679
At time: 1066.8983132839203 and batch: 1150, loss is 3.6600628089904785 and perplexity is 38.86378378970186
At time: 1068.2156269550323 and batch: 1200, loss is 3.712893595695496 and perplexity is 40.972192123124564
At time: 1069.5322704315186 and batch: 1250, loss is 3.671877927780151 and perplexity is 39.325687361225334
At time: 1070.8495490550995 and batch: 1300, loss is 3.6766842222213745 and perplexity is 39.51515314322544
At time: 1072.173398733139 and batch: 1350, loss is 3.55131254196167 and perplexity is 34.859041428360584
At time: 1073.4917895793915 and batch: 1400, loss is 3.5858786344528197 and perplexity is 36.08504936173669
At time: 1074.8106272220612 and batch: 1450, loss is 3.4948787975311277 and perplexity is 32.94629453876537
At time: 1076.1279046535492 and batch: 1500, loss is 3.493960237503052 and perplexity is 32.91604528453366
At time: 1077.4459702968597 and batch: 1550, loss is 3.503209319114685 and perplexity is 33.221900734333865
At time: 1078.7650277614594 and batch: 1600, loss is 3.5899798250198365 and perplexity is 36.23334491208753
At time: 1080.084867477417 and batch: 1650, loss is 3.517835488319397 and perplexity is 33.711380758642356
At time: 1081.4050493240356 and batch: 1700, loss is 3.5434551143646242 and perplexity is 34.58621230546009
At time: 1082.7233729362488 and batch: 1750, loss is 3.557220425605774 and perplexity is 35.065594132959966
At time: 1084.0436787605286 and batch: 1800, loss is 3.4913740444183348 and perplexity is 32.831028018760726
At time: 1085.3734204769135 and batch: 1850, loss is 3.5160592889785764 and perplexity is 33.651555772639455
At time: 1086.702359676361 and batch: 1900, loss is 3.607905774116516 and perplexity is 36.8887185561748
At time: 1088.0202617645264 and batch: 1950, loss is 3.5545012617111205 and perplexity is 34.97037455294103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354267067132994 and perplexity of 77.8097750908434
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f00fbd17b38>
ELAPSED
5577.421622037888


RESULTS SO FAR:
[{'params': {'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}, 'best_accuracy': -78.33907429225935}, {'params': {'dropout': 0.16802636512990798, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.23001756521426064}, 'best_accuracy': -77.64523175401864}, {'params': {'dropout': 0.7990403138855218, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.10718988942097152}, 'best_accuracy': -77.79230466527649}, {'params': {'dropout': 0.7943354117872055, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.9645103263983709}, 'best_accuracy': -82.35574479727755}, {'params': {'dropout': 0.37534925793438456, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.7617994495357929}, 'best_accuracy': -77.8097750908434}]
SETTINGS FOR THIS RUN
{'dropout': 0.3942674357276707, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.1655256110608432}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9667184352874756 and batch: 50, loss is 7.627289552688598 and perplexity is 2053.476629849076
At time: 3.5171682834625244 and batch: 100, loss is 6.677194480895996 and perplexity is 794.088154494545
At time: 5.045369863510132 and batch: 150, loss is 6.411002807617187 and perplexity is 608.5035872334486
At time: 6.580776691436768 and batch: 200, loss is 6.192376070022583 and perplexity is 489.0066409329242
At time: 8.114807605743408 and batch: 250, loss is 6.074591970443725 and perplexity is 434.67210726048506
At time: 9.649453163146973 and batch: 300, loss is 5.98522310256958 and perplexity is 397.5111971265916
At time: 11.188258647918701 and batch: 350, loss is 5.910906991958618 and perplexity is 369.0407206284525
At time: 12.725772380828857 and batch: 400, loss is 5.8489261245727535 and perplexity is 346.8616941552012
At time: 14.262749671936035 and batch: 450, loss is 5.774754018783569 and perplexity is 322.0652029837167
At time: 15.800868272781372 and batch: 500, loss is 5.734418697357178 and perplexity is 309.3331023353772
At time: 17.340060472488403 and batch: 550, loss is 5.6768659973144535 and perplexity is 292.03276279135923
At time: 18.876953125 and batch: 600, loss is 5.707364692687988 and perplexity is 301.0765925529023
At time: 20.41434597969055 and batch: 650, loss is 5.775671043395996 and perplexity is 322.3606801608746
At time: 21.949707508087158 and batch: 700, loss is 5.681029586791992 and perplexity is 293.2512021099919
At time: 23.484180450439453 and batch: 750, loss is 5.621369962692261 and perplexity is 276.2676004095612
At time: 25.014492511749268 and batch: 800, loss is 5.623338899612427 and perplexity is 276.812089744528
At time: 26.549148559570312 and batch: 850, loss is 5.631276426315307 and perplexity is 279.0180363967803
At time: 28.082005977630615 and batch: 900, loss is 5.621986131668091 and perplexity is 276.43788038919365
At time: 29.61655068397522 and batch: 950, loss is 5.656276397705078 and perplexity is 286.0814034317996
At time: 31.14965319633484 and batch: 1000, loss is 5.616664085388184 and perplexity is 274.9705731979861
At time: 32.68872952461243 and batch: 1050, loss is 5.522872705459594 and perplexity is 250.35319615965153
At time: 34.224395513534546 and batch: 1100, loss is 5.5986857509613035 and perplexity is 270.0712332249538
At time: 35.75856280326843 and batch: 1150, loss is 5.505528469085693 and perplexity is 246.04845032630038
At time: 37.29354500770569 and batch: 1200, loss is 5.581731595993042 and perplexity is 265.53100034477563
At time: 38.82506561279297 and batch: 1250, loss is 5.511609649658203 and perplexity is 247.54927414752245
At time: 40.36149287223816 and batch: 1300, loss is 5.524971494674682 and perplexity is 250.8791865260898
At time: 41.902183294296265 and batch: 1350, loss is 5.475836324691772 and perplexity is 238.850139692849
At time: 43.439635038375854 and batch: 1400, loss is 5.491480779647827 and perplexity is 242.61620213025762
At time: 44.973164081573486 and batch: 1450, loss is 5.4525791263580325 and perplexity is 233.35925343554769
At time: 46.507577657699585 and batch: 1500, loss is 5.427504720687867 and perplexity is 227.58065901778832
At time: 48.05299162864685 and batch: 1550, loss is 5.408636875152588 and perplexity is 223.326957578313
At time: 49.603249311447144 and batch: 1600, loss is 5.442042360305786 and perplexity is 230.9133103706056
At time: 51.149723052978516 and batch: 1650, loss is 5.412032661437988 and perplexity is 224.0866172890385
At time: 52.682854652404785 and batch: 1700, loss is 5.421289558410645 and perplexity is 226.17059471907706
At time: 54.217540979385376 and batch: 1750, loss is 5.432444505691528 and perplexity is 228.70763977398198
At time: 55.75560474395752 and batch: 1800, loss is 5.421038570404053 and perplexity is 226.11383573556893
At time: 57.293171405792236 and batch: 1850, loss is 5.39152943611145 and perplexity is 219.53889963584712
At time: 58.83217787742615 and batch: 1900, loss is 5.407900066375732 and perplexity is 223.16246892164529
At time: 60.36951971054077 and batch: 1950, loss is 5.3359811496734615 and perplexity is 207.67641052265876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.945714480377907 and perplexity of 140.57125038052314
finished 1 epochs...
Completing Train Step...
At time: 64.41113328933716 and batch: 50, loss is 5.197230815887451 and perplexity is 180.77096005406676
At time: 65.7269344329834 and batch: 100, loss is 5.129587545394897 and perplexity is 168.9474205307268
At time: 67.04033827781677 and batch: 150, loss is 5.053201570510864 and perplexity is 156.5227818810788
At time: 68.35361671447754 and batch: 200, loss is 5.0221078491210935 and perplexity is 151.73079257646182
At time: 69.66906476020813 and batch: 250, loss is 5.022042369842529 and perplexity is 151.7208576788964
At time: 70.9844880104065 and batch: 300, loss is 5.033762874603272 and perplexity is 153.50956451088672
At time: 72.30012631416321 and batch: 350, loss is 5.01950517654419 and perplexity is 151.33640046295156
At time: 73.6137056350708 and batch: 400, loss is 4.983476629257202 and perplexity is 145.9810223356377
At time: 74.92699766159058 and batch: 450, loss is 4.953389463424682 and perplexity is 141.65428315679128
At time: 76.25932669639587 and batch: 500, loss is 4.939888429641724 and perplexity is 139.75465621307703
At time: 77.58181810379028 and batch: 550, loss is 4.897629060745239 and perplexity is 133.9717639217688
At time: 78.89716172218323 and batch: 600, loss is 4.885451059341431 and perplexity is 132.35014964403686
At time: 80.2128369808197 and batch: 650, loss is 4.945518579483032 and perplexity is 140.5437150439665
At time: 81.52650046348572 and batch: 700, loss is 4.934893999099732 and perplexity is 139.05840143506546
At time: 82.84228873252869 and batch: 750, loss is 4.885293970108032 and perplexity is 132.32936049340765
At time: 84.15890121459961 and batch: 800, loss is 4.867977781295776 and perplexity is 130.0576457863585
At time: 85.47281575202942 and batch: 850, loss is 4.87118444442749 and perplexity is 130.47536623053222
At time: 86.78717136383057 and batch: 900, loss is 4.867916984558105 and perplexity is 130.049738946143
At time: 88.10062646865845 and batch: 950, loss is 4.934851903915405 and perplexity is 139.05254786922922
At time: 89.41494417190552 and batch: 1000, loss is 4.89356915473938 and perplexity is 133.428953777477
At time: 90.73166394233704 and batch: 1050, loss is 4.808016014099121 and perplexity is 122.48836110695522
At time: 92.04758906364441 and batch: 1100, loss is 4.878434448242188 and perplexity is 131.42475049469448
At time: 93.36298203468323 and batch: 1150, loss is 4.799080724716187 and perplexity is 121.39876732168001
At time: 94.67683863639832 and batch: 1200, loss is 4.877463121414184 and perplexity is 131.29715608664299
At time: 95.99107432365417 and batch: 1250, loss is 4.82598349571228 and perplexity is 124.70905891440776
At time: 97.30763411521912 and batch: 1300, loss is 4.860684518814087 and perplexity is 129.11255183626926
At time: 98.62314653396606 and batch: 1350, loss is 4.7554139804840085 and perplexity is 116.21175260518828
At time: 99.93813133239746 and batch: 1400, loss is 4.773942918777466 and perplexity is 118.38510578207644
At time: 101.25227975845337 and batch: 1450, loss is 4.715043411254883 and perplexity is 111.61365635742409
At time: 102.56802248954773 and batch: 1500, loss is 4.696054449081421 and perplexity is 109.51422495471235
At time: 103.88301181793213 and batch: 1550, loss is 4.687589960098267 and perplexity is 108.59115517238868
At time: 105.19863176345825 and batch: 1600, loss is 4.759434175491333 and perplexity is 116.67988687783952
At time: 106.51412177085876 and batch: 1650, loss is 4.717411136627197 and perplexity is 111.87823995051416
At time: 107.83087110519409 and batch: 1700, loss is 4.743000764846801 and perplexity is 114.77810754208191
At time: 109.14553952217102 and batch: 1750, loss is 4.744122400283813 and perplexity is 114.90691896111596
At time: 110.46142745018005 and batch: 1800, loss is 4.707651252746582 and perplexity is 110.7916325263869
At time: 111.77757048606873 and batch: 1850, loss is 4.710997276306152 and perplexity is 111.16296483590237
At time: 113.09483861923218 and batch: 1900, loss is 4.781574773788452 and perplexity is 119.29206021509096
At time: 114.41045236587524 and batch: 1950, loss is 4.7057765865325925 and perplexity is 110.58412975608351
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.60724359556686 and perplexity of 100.20755605787873
finished 2 epochs...
Completing Train Step...
At time: 118.38466048240662 and batch: 50, loss is 4.665513372421264 and perplexity is 106.22010169794581
At time: 119.71362972259521 and batch: 100, loss is 4.6034422206878665 and perplexity is 99.82735267722742
At time: 121.03105735778809 and batch: 150, loss is 4.548679828643799 and perplexity is 94.50755974898141
At time: 122.34638857841492 and batch: 200, loss is 4.546910648345947 and perplexity is 94.3405066533712
At time: 123.65892052650452 and batch: 250, loss is 4.5391597557067875 and perplexity is 93.61211002342881
At time: 124.97500824928284 and batch: 300, loss is 4.572925262451172 and perplexity is 96.82694010683764
At time: 126.29200077056885 and batch: 350, loss is 4.579808778762818 and perplexity is 97.4957491666713
At time: 127.60915946960449 and batch: 400, loss is 4.537262964248657 and perplexity is 93.4347156659958
At time: 128.92528176307678 and batch: 450, loss is 4.53302848815918 and perplexity is 93.03990509448202
At time: 130.2390296459198 and batch: 500, loss is 4.5464757061004635 and perplexity is 94.29948290369494
At time: 131.55324578285217 and batch: 550, loss is 4.506593008041381 and perplexity is 90.6125756990176
At time: 132.8696916103363 and batch: 600, loss is 4.486869707107544 and perplexity is 88.84290583346606
At time: 134.18613958358765 and batch: 650, loss is 4.537407150268555 and perplexity is 93.44818861705022
At time: 135.50180006027222 and batch: 700, loss is 4.56811785697937 and perplexity is 96.36257084515685
At time: 136.82369017601013 and batch: 750, loss is 4.522331047058105 and perplexity is 92.04992077987274
At time: 138.13976001739502 and batch: 800, loss is 4.505026445388794 and perplexity is 90.47073655103625
At time: 139.45419311523438 and batch: 850, loss is 4.503463459014893 and perplexity is 90.32944247169476
At time: 140.785906791687 and batch: 900, loss is 4.487925672531128 and perplexity is 88.936770420314
At time: 142.10473728179932 and batch: 950, loss is 4.566731853485107 and perplexity is 96.22910449902618
At time: 143.4267282485962 and batch: 1000, loss is 4.536098423004151 and perplexity is 93.32597041738723
At time: 144.73982453346252 and batch: 1050, loss is 4.466732120513916 and perplexity is 87.0717177054653
At time: 146.05370497703552 and batch: 1100, loss is 4.524553365707398 and perplexity is 92.2547125074417
At time: 147.3686079978943 and batch: 1150, loss is 4.461026277542114 and perplexity is 86.57631484646731
At time: 148.68158316612244 and batch: 1200, loss is 4.5440943145751955 and perplexity is 94.07518608953652
At time: 149.99362230300903 and batch: 1250, loss is 4.506287031173706 and perplexity is 90.5848545881588
At time: 151.30532789230347 and batch: 1300, loss is 4.52475435256958 and perplexity is 92.27325635610268
At time: 152.61769938468933 and batch: 1350, loss is 4.409575672149658 and perplexity is 82.23456168503478
At time: 153.93217658996582 and batch: 1400, loss is 4.436799688339233 and perplexity is 84.50406910895198
At time: 155.2471408843994 and batch: 1450, loss is 4.3725873517990115 and perplexity is 79.24841018499517
At time: 156.564218044281 and batch: 1500, loss is 4.36919680595398 and perplexity is 78.98016981472327
At time: 157.87734818458557 and batch: 1550, loss is 4.363264827728272 and perplexity is 78.51304801506205
At time: 159.19023823738098 and batch: 1600, loss is 4.447034339904786 and perplexity is 85.37337976980527
At time: 160.50496864318848 and batch: 1650, loss is 4.403044347763061 and perplexity is 81.69921126360069
At time: 161.82180261611938 and batch: 1700, loss is 4.4375013160705565 and perplexity is 84.56338031200775
At time: 163.13874912261963 and batch: 1750, loss is 4.438592319488525 and perplexity is 84.65568959467838
At time: 164.45229148864746 and batch: 1800, loss is 4.388993291854859 and perplexity is 80.55927846312434
At time: 165.76532292366028 and batch: 1850, loss is 4.4157711696624755 and perplexity is 82.74562722532862
At time: 167.0809621810913 and batch: 1900, loss is 4.49937780380249 and perplexity is 89.9611404041836
At time: 168.39790558815002 and batch: 1950, loss is 4.42710322380066 and perplexity is 83.68863818696924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.506284633902617 and perplexity of 90.58463743196607
finished 3 epochs...
Completing Train Step...
At time: 172.35954976081848 and batch: 50, loss is 4.3959035348892215 and perplexity is 81.11789050558856
At time: 173.68588876724243 and batch: 100, loss is 4.334678773880005 and perplexity is 76.30044525678515
At time: 175.00297594070435 and batch: 150, loss is 4.289959516525268 and perplexity is 72.96351462324104
At time: 176.31895470619202 and batch: 200, loss is 4.288493242263794 and perplexity is 72.8566084957275
At time: 177.64097619056702 and batch: 250, loss is 4.287086868286133 and perplexity is 72.7542168747707
At time: 178.95965695381165 and batch: 300, loss is 4.313612298965454 and perplexity is 74.70987650280935
At time: 180.2845163345337 and batch: 350, loss is 4.327687673568725 and perplexity is 75.76888146313598
At time: 181.61264419555664 and batch: 400, loss is 4.284981083869934 and perplexity is 72.60117337352678
At time: 182.92844605445862 and batch: 450, loss is 4.298888940811157 and perplexity is 73.6179543391956
At time: 184.24478387832642 and batch: 500, loss is 4.315451049804688 and perplexity is 74.84737572559312
At time: 185.558758020401 and batch: 550, loss is 4.273499488830566 and perplexity is 71.77236323758622
At time: 186.87395596504211 and batch: 600, loss is 4.252168493270874 and perplexity is 70.25760041137363
At time: 188.18989753723145 and batch: 650, loss is 4.298120479583741 and perplexity is 73.56140352698044
At time: 189.5068929195404 and batch: 700, loss is 4.344273643493652 and perplexity is 77.03606150800798
At time: 190.83941531181335 and batch: 750, loss is 4.304620237350464 and perplexity is 74.04109207178197
At time: 192.1562705039978 and batch: 800, loss is 4.283278465270996 and perplexity is 72.47766643787544
At time: 193.46997547149658 and batch: 850, loss is 4.279850463867188 and perplexity is 72.22963825894
At time: 194.78589820861816 and batch: 900, loss is 4.256899571418762 and perplexity is 70.59078214233645
At time: 196.10087513923645 and batch: 950, loss is 4.337411890029907 and perplexity is 76.50926847502521
At time: 197.41693210601807 and batch: 1000, loss is 4.317181959152221 and perplexity is 74.97704193572865
At time: 198.7324242591858 and batch: 1050, loss is 4.256705045700073 and perplexity is 70.57705175520744
At time: 200.04691815376282 and batch: 1100, loss is 4.30781439781189 and perplexity is 74.27796931115643
At time: 201.36163568496704 and batch: 1150, loss is 4.251070041656494 and perplexity is 70.1804682075318
At time: 202.67717099189758 and batch: 1200, loss is 4.33467622756958 and perplexity is 76.30025097241334
At time: 203.9931514263153 and batch: 1250, loss is 4.299728126525879 and perplexity is 73.67975940416082
At time: 205.3085334300995 and batch: 1300, loss is 4.309331340789795 and perplexity is 74.3907302594574
At time: 206.6224114894867 and batch: 1350, loss is 4.19270281791687 and perplexity is 66.20147991581435
At time: 207.93555974960327 and batch: 1400, loss is 4.222328586578369 and perplexity is 68.19209074057456
At time: 209.25022768974304 and batch: 1450, loss is 4.160731391906738 and perplexity is 64.11840113421917
At time: 210.56709384918213 and batch: 1500, loss is 4.163603572845459 and perplexity is 64.30282550707943
At time: 211.8847906589508 and batch: 1550, loss is 4.162254657745361 and perplexity is 64.21614493028689
At time: 213.1992106437683 and batch: 1600, loss is 4.25014093875885 and perplexity is 70.11529361280301
At time: 214.51283431053162 and batch: 1650, loss is 4.20528181552887 and perplexity is 67.03948777311889
At time: 215.83529567718506 and batch: 1700, loss is 4.241240739822388 and perplexity is 69.4940223710689
At time: 217.15214681625366 and batch: 1750, loss is 4.242905144691467 and perplexity is 69.60978487138563
At time: 218.46992683410645 and batch: 1800, loss is 4.187886953353882 and perplexity is 65.88342901440383
At time: 219.78675389289856 and batch: 1850, loss is 4.220844640731811 and perplexity is 68.09097241636661
At time: 221.10104703903198 and batch: 1900, loss is 4.307422657012939 and perplexity is 74.24887729875017
At time: 222.41653752326965 and batch: 1950, loss is 4.2341423511505125 and perplexity is 69.00247345650665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.453134368186773 and perplexity of 85.89575142205469
finished 4 epochs...
Completing Train Step...
At time: 226.39127779006958 and batch: 50, loss is 4.209819521903992 and perplexity is 67.3443845269721
At time: 227.71896290779114 and batch: 100, loss is 4.152260274887085 and perplexity is 63.57754073529676
At time: 229.0339195728302 and batch: 150, loss is 4.105181574821472 and perplexity is 60.65375674285926
At time: 230.34980750083923 and batch: 200, loss is 4.11276072025299 and perplexity is 61.115206876077494
At time: 231.6664171218872 and batch: 250, loss is 4.112574853897095 and perplexity is 61.10384867087244
At time: 232.98182201385498 and batch: 300, loss is 4.13536750793457 and perplexity is 62.51256071151612
At time: 234.29675674438477 and batch: 350, loss is 4.14709969997406 and perplexity is 63.250289202837884
At time: 235.61207127571106 and batch: 400, loss is 4.1101103687286376 and perplexity is 60.95344455257245
At time: 236.92755389213562 and batch: 450, loss is 4.130680150985718 and perplexity is 62.22022769551628
At time: 238.27610087394714 and batch: 500, loss is 4.1474635887146 and perplexity is 63.273309459066695
At time: 239.59316420555115 and batch: 550, loss is 4.1052629756927494 and perplexity is 60.658694212458805
At time: 240.9087154865265 and batch: 600, loss is 4.088199920654297 and perplexity is 59.63245188808226
At time: 242.23037314414978 and batch: 650, loss is 4.132023944854736 and perplexity is 62.303895059277224
At time: 243.5447142124176 and batch: 700, loss is 4.183302865028382 and perplexity is 65.58210473284112
At time: 244.85972833633423 and batch: 750, loss is 4.145435266494751 and perplexity is 63.14510086768996
At time: 246.17551970481873 and batch: 800, loss is 4.1189781761169435 and perplexity is 61.4963716872589
At time: 247.49091815948486 and batch: 850, loss is 4.115357604026794 and perplexity is 61.274122218175464
At time: 248.8072690963745 and batch: 900, loss is 4.092772226333619 and perplexity is 59.905733975038814
At time: 250.1221058368683 and batch: 950, loss is 4.178302979469299 and perplexity is 65.25502008874231
At time: 251.4382290840149 and batch: 1000, loss is 4.160264945030212 and perplexity is 64.08850028040432
At time: 252.75557494163513 and batch: 1050, loss is 4.105372614860535 and perplexity is 60.66534514580595
At time: 254.0719132423401 and batch: 1100, loss is 4.144222087860108 and perplexity is 63.068541030204536
At time: 255.38779067993164 and batch: 1150, loss is 4.093732566833496 and perplexity is 59.963291510542575
At time: 256.70626044273376 and batch: 1200, loss is 4.1817703485488895 and perplexity is 65.48167605053919
At time: 258.0240316390991 and batch: 1250, loss is 4.150818781852722 and perplexity is 63.48596017541246
At time: 259.3408386707306 and batch: 1300, loss is 4.145597944259643 and perplexity is 63.155374007146065
At time: 260.6567003726959 and batch: 1350, loss is 4.029122648239135 and perplexity is 56.21157228455504
At time: 261.9739706516266 and batch: 1400, loss is 4.068797163963318 and perplexity is 58.486570510641215
At time: 263.2892782688141 and batch: 1450, loss is 4.004372673034668 and perplexity is 54.83741261883495
At time: 264.6025035381317 and batch: 1500, loss is 4.014169688224793 and perplexity is 55.37729588731267
At time: 265.9176936149597 and batch: 1550, loss is 4.011107354164124 and perplexity is 55.20797150416755
At time: 267.2325646877289 and batch: 1600, loss is 4.11014262676239 and perplexity is 60.955410822558
At time: 268.54897260665894 and batch: 1650, loss is 4.052869081497192 and perplexity is 57.562371490806896
At time: 269.8710820674896 and batch: 1700, loss is 4.091105260848999 and perplexity is 59.80595637018829
At time: 271.1941993236542 and batch: 1750, loss is 4.0925390625 and perplexity is 59.89176775272171
At time: 272.5178062915802 and batch: 1800, loss is 4.036758570671082 and perplexity is 56.64244244227762
At time: 273.8429214954376 and batch: 1850, loss is 4.074830474853516 and perplexity is 58.840504797602584
At time: 275.16749000549316 and batch: 1900, loss is 4.16212333202362 and perplexity is 64.20771225243239
At time: 276.4901919364929 and batch: 1950, loss is 4.091408905982971 and perplexity is 59.824118915167276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.441442587209302 and perplexity of 84.89732517356774
finished 5 epochs...
Completing Train Step...
At time: 280.48628401756287 and batch: 50, loss is 4.075383257865906 and perplexity is 58.873039820670705
At time: 281.80557680130005 and batch: 100, loss is 4.010508885383606 and perplexity is 55.17494114159287
At time: 283.12331080436707 and batch: 150, loss is 3.9718138647079466 and perplexity is 53.080724825297146
At time: 284.43936371803284 and batch: 200, loss is 3.974509291648865 and perplexity is 53.22399303879509
At time: 285.75766229629517 and batch: 250, loss is 3.973407173156738 and perplexity is 53.165366204635575
At time: 287.07466101646423 and batch: 300, loss is 3.9983164501190185 and perplexity is 54.50630865561671
At time: 288.39214158058167 and batch: 350, loss is 4.0103933620452885 and perplexity is 55.16856751635903
At time: 289.70918583869934 and batch: 400, loss is 3.97949857711792 and perplexity is 53.49020628858177
At time: 291.02338337898254 and batch: 450, loss is 4.003505153656006 and perplexity is 54.78986072978729
At time: 292.3379201889038 and batch: 500, loss is 4.015984878540039 and perplexity is 55.47790750548376
At time: 293.65445017814636 and batch: 550, loss is 3.9818819427490233 and perplexity is 53.61784505235171
At time: 294.972140789032 and batch: 600, loss is 3.963331084251404 and perplexity is 52.63235708131566
At time: 296.2884781360626 and batch: 650, loss is 4.0011130762100215 and perplexity is 54.65895576948871
At time: 297.6046063899994 and batch: 700, loss is 4.054029078483581 and perplexity is 57.62918241100698
At time: 298.92147517204285 and batch: 750, loss is 4.0214161825180055 and perplexity is 55.78004464179286
At time: 300.24359607696533 and batch: 800, loss is 3.994202527999878 and perplexity is 54.28253455701524
At time: 301.56138706207275 and batch: 850, loss is 3.9919301080703735 and perplexity is 54.15932189214288
At time: 302.87879514694214 and batch: 900, loss is 3.9627152395248415 and perplexity is 52.599953700510305
At time: 304.2072021961212 and batch: 950, loss is 4.056334991455078 and perplexity is 57.762223622041446
At time: 305.5222783088684 and batch: 1000, loss is 4.039316611289978 and perplexity is 56.78752159086467
At time: 306.83881759643555 and batch: 1050, loss is 3.9828079605102538 and perplexity is 53.667519125176284
At time: 308.1654808521271 and batch: 1100, loss is 4.024640598297119 and perplexity is 55.960192978383716
At time: 309.4832773208618 and batch: 1150, loss is 3.9777477407455444 and perplexity is 53.396635627207345
At time: 310.8007769584656 and batch: 1200, loss is 4.063894414901734 and perplexity is 58.20052730395341
At time: 312.11661171913147 and batch: 1250, loss is 4.031854271888733 and perplexity is 56.365331054725715
At time: 313.43151092529297 and batch: 1300, loss is 4.026216263771057 and perplexity is 56.04843702566684
At time: 314.7473475933075 and batch: 1350, loss is 3.9113710212707518 and perplexity is 49.96741141690463
At time: 316.0663924217224 and batch: 1400, loss is 3.9493290615081786 and perplexity is 51.900533085093564
At time: 317.38745975494385 and batch: 1450, loss is 3.8847066450119017 and perplexity is 48.65266786302884
At time: 318.70340037345886 and batch: 1500, loss is 3.8959188747406004 and perplexity is 49.20124237680874
At time: 320.0196647644043 and batch: 1550, loss is 3.891839904785156 and perplexity is 49.00096073647034
At time: 321.3379399776459 and batch: 1600, loss is 3.9920129919052125 and perplexity is 54.16381101046868
At time: 322.6557581424713 and batch: 1650, loss is 3.940038628578186 and perplexity is 51.42058756635053
At time: 323.9744737148285 and batch: 1700, loss is 3.975628261566162 and perplexity is 53.28358241902825
At time: 325.2918395996094 and batch: 1750, loss is 3.9745995473861693 and perplexity is 53.22879702631955
At time: 326.6077034473419 and batch: 1800, loss is 3.9186715030670167 and perplexity is 50.333532398043815
At time: 327.92470049858093 and batch: 1850, loss is 3.957925624847412 and perplexity is 52.34862256036284
At time: 329.24252367019653 and batch: 1900, loss is 4.044148111343384 and perplexity is 57.0625543799149
At time: 330.56001496315 and batch: 1950, loss is 3.975508995056152 and perplexity is 53.277227851063415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.446046341297238 and perplexity of 85.28907264399052
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 334.5423312187195 and batch: 50, loss is 3.9986451721191405 and perplexity is 54.52422902366549
At time: 335.8580117225647 and batch: 100, loss is 3.968259344100952 and perplexity is 52.89238322542232
At time: 337.1857888698578 and batch: 150, loss is 3.9312434911727907 and perplexity is 50.970319420859106
At time: 338.5022909641266 and batch: 200, loss is 3.9416314601898192 and perplexity is 51.50255716827103
At time: 339.8180208206177 and batch: 250, loss is 3.9348346042633056 and perplexity is 51.15368865492532
At time: 341.13271617889404 and batch: 300, loss is 3.9532628536224363 and perplexity is 52.105101093075135
At time: 342.4501600265503 and batch: 350, loss is 3.9686314058303833 and perplexity is 52.91206611839746
At time: 343.768089056015 and batch: 400, loss is 3.9252864027023318 and perplexity is 50.667587314922
At time: 345.08537316322327 and batch: 450, loss is 3.944023585319519 and perplexity is 51.62590520266429
At time: 346.40263962745667 and batch: 500, loss is 3.9560238885879517 and perplexity is 52.24916388876324
At time: 347.7182376384735 and batch: 550, loss is 3.913173208236694 and perplexity is 50.05754322727424
At time: 349.03589510917664 and batch: 600, loss is 3.8778070640563964 and perplexity is 48.31814021976102
At time: 350.35281348228455 and batch: 650, loss is 3.9120304679870603 and perplexity is 50.00037312933796
At time: 351.67562103271484 and batch: 700, loss is 3.9499187660217285 and perplexity is 51.9311480897255
At time: 352.9933364391327 and batch: 750, loss is 3.9072378969192503 and perplexity is 49.76131609418339
At time: 354.3082091808319 and batch: 800, loss is 3.878468451499939 and perplexity is 48.35010780131091
At time: 355.62448358535767 and batch: 850, loss is 3.883587851524353 and perplexity is 48.59826601296416
At time: 356.94224882125854 and batch: 900, loss is 3.8387913370132445 and perplexity is 46.469274790951985
At time: 358.26093220710754 and batch: 950, loss is 3.924768304824829 and perplexity is 50.641343344535684
At time: 359.59138560295105 and batch: 1000, loss is 3.890292177200317 and perplexity is 48.925179257525215
At time: 360.9231162071228 and batch: 1050, loss is 3.8315607023239138 and perplexity is 46.13448427325334
At time: 362.2419457435608 and batch: 1100, loss is 3.858498044013977 and perplexity is 47.39411401131604
At time: 363.55902075767517 and batch: 1150, loss is 3.8268791913986204 and perplexity is 45.91900994733836
At time: 364.876900434494 and batch: 1200, loss is 3.890127320289612 and perplexity is 48.91711426841997
At time: 366.19188046455383 and batch: 1250, loss is 3.8539562225341797 and perplexity is 47.179346493334435
At time: 367.5082800388336 and batch: 1300, loss is 3.8514374256134034 and perplexity is 47.06066083594546
At time: 368.8241696357727 and batch: 1350, loss is 3.7197127676010133 and perplexity is 41.25254333974211
At time: 370.14023518562317 and batch: 1400, loss is 3.7476971340179444 and perplexity is 42.42327430903128
At time: 371.4585511684418 and batch: 1450, loss is 3.680516438484192 and perplexity is 39.66687428416064
At time: 372.77728843688965 and batch: 1500, loss is 3.6747289896011353 and perplexity is 39.43796730952569
At time: 374.09885263442993 and batch: 1550, loss is 3.667859501838684 and perplexity is 39.1679770847222
At time: 375.41281366348267 and batch: 1600, loss is 3.7586510229110717 and perplexity is 42.890528596013404
At time: 376.73247718811035 and batch: 1650, loss is 3.6939431476593017 and perplexity is 40.203061428345436
At time: 378.06035017967224 and batch: 1700, loss is 3.715574851036072 and perplexity is 41.08219644099926
At time: 379.38522124290466 and batch: 1750, loss is 3.7090763521194456 and perplexity is 40.81608941652506
At time: 380.7038516998291 and batch: 1800, loss is 3.6501907682418824 and perplexity is 38.4820064935709
At time: 382.02043104171753 and batch: 1850, loss is 3.6806503772735595 and perplexity is 39.672187573100054
At time: 383.3360004425049 and batch: 1900, loss is 3.7459124088287354 and perplexity is 42.34762794682662
At time: 384.6534061431885 and batch: 1950, loss is 3.6649344539642335 and perplexity is 39.05357627209778
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.393141919513082 and perplexity of 80.8941831309268
finished 7 epochs...
Completing Train Step...
At time: 388.63252902030945 and batch: 50, loss is 3.888031849861145 and perplexity is 48.814717224482074
At time: 389.94839239120483 and batch: 100, loss is 3.8405898284912108 and perplexity is 46.55292458482389
At time: 391.26408791542053 and batch: 150, loss is 3.7973221063613893 and perplexity is 44.581639611386414
At time: 392.5823128223419 and batch: 200, loss is 3.8059580373764037 and perplexity is 44.968310805348786
At time: 393.89987564086914 and batch: 250, loss is 3.7990643692016604 and perplexity is 44.659380248085924
At time: 395.2211513519287 and batch: 300, loss is 3.8168031311035158 and perplexity is 45.45865043442532
At time: 396.54076623916626 and batch: 350, loss is 3.8369495487213134 and perplexity is 46.38376699251002
At time: 397.8587734699249 and batch: 400, loss is 3.799195718765259 and perplexity is 44.66524662345659
At time: 399.175493478775 and batch: 450, loss is 3.8231678009033203 and perplexity is 45.74890243323271
At time: 400.49266266822815 and batch: 500, loss is 3.836085624694824 and perplexity is 46.34371224638617
At time: 401.8116433620453 and batch: 550, loss is 3.800313777923584 and perplexity is 44.71521293894604
At time: 403.1714732646942 and batch: 600, loss is 3.769512610435486 and perplexity is 43.358926996542266
At time: 404.4876663684845 and batch: 650, loss is 3.799355511665344 and perplexity is 44.67238438301403
At time: 405.8056888580322 and batch: 700, loss is 3.8434875440597533 and perplexity is 46.688017354837555
At time: 407.12291955947876 and batch: 750, loss is 3.803986268043518 and perplexity is 44.87973102729499
At time: 408.4399380683899 and batch: 800, loss is 3.776295790672302 and perplexity is 43.65403817785884
At time: 409.75679302215576 and batch: 850, loss is 3.7859616231918336 and perplexity is 44.07803664766926
At time: 411.0719654560089 and batch: 900, loss is 3.7405840444564817 and perplexity is 42.12258444415888
At time: 412.3882803916931 and batch: 950, loss is 3.828558259010315 and perplexity is 45.99617583494405
At time: 413.7070903778076 and batch: 1000, loss is 3.7987239503860475 and perplexity is 44.64417994213773
At time: 415.0255618095398 and batch: 1050, loss is 3.7435135078430175 and perplexity is 42.246161932522114
At time: 416.3421494960785 and batch: 1100, loss is 3.769736714363098 and perplexity is 43.368644991258954
At time: 417.657044172287 and batch: 1150, loss is 3.7423300552368164 and perplexity is 42.196195174557836
At time: 418.977041721344 and batch: 1200, loss is 3.808117847442627 and perplexity is 45.06553877486529
At time: 420.301766872406 and batch: 1250, loss is 3.7757775449752806 and perplexity is 43.63142052167326
At time: 421.6279058456421 and batch: 1300, loss is 3.7786569023132324 and perplexity is 43.75723201371692
At time: 422.9568336009979 and batch: 1350, loss is 3.6454491806030274 and perplexity is 38.29997259315896
At time: 424.27506947517395 and batch: 1400, loss is 3.677345690727234 and perplexity is 39.54129981918188
At time: 425.59041380882263 and batch: 1450, loss is 3.614068431854248 and perplexity is 37.116753030531655
At time: 426.907687664032 and batch: 1500, loss is 3.6089748525619507 and perplexity is 36.92817657816518
At time: 428.2265405654907 and batch: 1550, loss is 3.6059831619262694 and perplexity is 36.81786399094734
At time: 429.5437316894531 and batch: 1600, loss is 3.7022940492630005 and perplexity is 40.54019898050333
At time: 430.8603308200836 and batch: 1650, loss is 3.6408710575103758 and perplexity is 38.12503136098215
At time: 432.17901587486267 and batch: 1700, loss is 3.666733283996582 and perplexity is 39.12389024044552
At time: 433.49619030952454 and batch: 1750, loss is 3.6650725746154786 and perplexity is 39.05897075002176
At time: 434.8143901824951 and batch: 1800, loss is 3.6075749683380125 and perplexity is 36.876517573103946
At time: 436.1358504295349 and batch: 1850, loss is 3.644909119606018 and perplexity is 38.27929385616714
At time: 437.4574365615845 and batch: 1900, loss is 3.711562795639038 and perplexity is 40.91770259291073
At time: 438.77270698547363 and batch: 1950, loss is 3.6337939977645872 and perplexity is 37.85617072975673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4046017668968025 and perplexity of 81.82655031283107
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 442.723539352417 and batch: 50, loss is 3.845531997680664 and perplexity is 46.78356648056856
At time: 444.05802178382874 and batch: 100, loss is 3.826045861244202 and perplexity is 45.88076019123928
At time: 445.3814103603363 and batch: 150, loss is 3.7974228858947754 and perplexity is 44.58613275462867
At time: 446.6976385116577 and batch: 200, loss is 3.816714963912964 and perplexity is 45.4546426496104
At time: 448.0143094062805 and batch: 250, loss is 3.8235879516601563 and perplexity is 45.76812790773046
At time: 449.3313274383545 and batch: 300, loss is 3.8428726148605348 and perplexity is 46.659316355158225
At time: 450.64964962005615 and batch: 350, loss is 3.8803479719161986 and perplexity is 48.44106827030388
At time: 451.96567940711975 and batch: 400, loss is 3.845456142425537 and perplexity is 46.78001783579081
At time: 453.2810468673706 and batch: 450, loss is 3.8582212638854982 and perplexity is 47.380998077549506
At time: 454.59691190719604 and batch: 500, loss is 3.8545484018325804 and perplexity is 47.207293399612844
At time: 455.91369795799255 and batch: 550, loss is 3.819468870162964 and perplexity is 45.57999299642505
At time: 457.23089480400085 and batch: 600, loss is 3.7857751750946047 and perplexity is 44.069819147699135
At time: 458.553959608078 and batch: 650, loss is 3.8092665910720824 and perplexity is 45.11733727134116
At time: 459.87041091918945 and batch: 700, loss is 3.8534860038757324 and perplexity is 47.15716709931104
At time: 461.186767578125 and batch: 750, loss is 3.8025195503234865 and perplexity is 44.81395338093882
At time: 462.52056789398193 and batch: 800, loss is 3.7645701789855956 and perplexity is 43.14515717861394
At time: 463.83694434165955 and batch: 850, loss is 3.7792151021957396 and perplexity is 43.781664113849146
At time: 465.1734836101532 and batch: 900, loss is 3.7297869157791137 and perplexity is 41.67022794988928
At time: 466.50160002708435 and batch: 950, loss is 3.823397326469421 and perplexity is 45.7594041811259
At time: 467.85529255867004 and batch: 1000, loss is 3.7829332637786863 and perplexity is 43.94475442557067
At time: 469.17582154273987 and batch: 1050, loss is 3.7229428052902223 and perplexity is 41.38600603824206
At time: 470.4957447052002 and batch: 1100, loss is 3.7472628688812257 and perplexity is 42.404855359656665
At time: 471.81419038772583 and batch: 1150, loss is 3.718159294128418 and perplexity is 41.1885083591864
At time: 473.131098985672 and batch: 1200, loss is 3.7723027944564818 and perplexity is 43.48007531627224
At time: 474.4474287033081 and batch: 1250, loss is 3.742410225868225 and perplexity is 42.199578205776085
At time: 475.76399517059326 and batch: 1300, loss is 3.7542242336273195 and perplexity is 42.70108089555053
At time: 477.08170890808105 and batch: 1350, loss is 3.6135773229599 and perplexity is 37.098529138313104
At time: 478.39952087402344 and batch: 1400, loss is 3.6366802787780763 and perplexity is 37.96559211104277
At time: 479.7201118469238 and batch: 1450, loss is 3.5620498275756836 and perplexity is 35.235349561005606
At time: 481.04359698295593 and batch: 1500, loss is 3.5486290311813353 and perplexity is 34.76562221668735
At time: 482.3603324890137 and batch: 1550, loss is 3.5443519115448 and perplexity is 34.617243035184345
At time: 483.67701148986816 and batch: 1600, loss is 3.6348018980026247 and perplexity is 37.894345208047646
At time: 484.99169993400574 and batch: 1650, loss is 3.5761391305923462 and perplexity is 35.73530481800567
At time: 486.30923771858215 and batch: 1700, loss is 3.5905072116851806 and perplexity is 36.25245893483231
At time: 487.63528966903687 and batch: 1750, loss is 3.590124478340149 and perplexity is 36.2385865648372
At time: 488.9522466659546 and batch: 1800, loss is 3.531671471595764 and perplexity is 34.18105255199236
At time: 490.26880860328674 and batch: 1850, loss is 3.5654385709762573 and perplexity is 35.35495566203128
At time: 491.587233543396 and batch: 1900, loss is 3.6479882860183714 and perplexity is 38.397343826577675
At time: 492.9032895565033 and batch: 1950, loss is 3.567955050468445 and perplexity is 35.444037722480516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377045387445494 and perplexity of 79.6024910887531
finished 9 epochs...
Completing Train Step...
At time: 496.8713219165802 and batch: 50, loss is 3.837912139892578 and perplexity is 46.428437093180065
At time: 498.22036242485046 and batch: 100, loss is 3.7932098293304444 and perplexity is 44.39868399871988
At time: 499.54081535339355 and batch: 150, loss is 3.755455436706543 and perplexity is 42.75368697557387
At time: 500.8698465824127 and batch: 200, loss is 3.76492326259613 and perplexity is 43.16039371621521
At time: 502.1843912601471 and batch: 250, loss is 3.7666563034057616 and perplexity is 43.23525729196384
At time: 503.5012619495392 and batch: 300, loss is 3.7858065223693846 and perplexity is 44.07120063808233
At time: 504.8192849159241 and batch: 350, loss is 3.819883327484131 and perplexity is 45.59888787351075
At time: 506.1379017829895 and batch: 400, loss is 3.788267369270325 and perplexity is 44.17978666759273
At time: 507.4552216529846 and batch: 450, loss is 3.8054811763763428 and perplexity is 44.94687228369079
At time: 508.7879412174225 and batch: 500, loss is 3.8019238710403442 and perplexity is 44.7872665864885
At time: 510.1191883087158 and batch: 550, loss is 3.767927041053772 and perplexity is 43.29023288350535
At time: 511.45092940330505 and batch: 600, loss is 3.7366432905197144 and perplexity is 41.95691634668316
At time: 512.7680518627167 and batch: 650, loss is 3.759470205307007 and perplexity is 42.92567815697677
At time: 514.0835709571838 and batch: 700, loss is 3.8063439178466796 and perplexity is 44.98566654667531
At time: 515.3975386619568 and batch: 750, loss is 3.7593350982666016 and perplexity is 42.91987898740673
At time: 516.7116770744324 and batch: 800, loss is 3.7220275592803955 and perplexity is 41.34814499008246
At time: 518.0261166095734 and batch: 850, loss is 3.7376523351669313 and perplexity is 41.99927411538244
At time: 519.3414816856384 and batch: 900, loss is 3.689684581756592 and perplexity is 40.032218073796734
At time: 520.6563854217529 and batch: 950, loss is 3.784874234199524 and perplexity is 44.030132725634914
At time: 521.9723989963531 and batch: 1000, loss is 3.7456388759613035 and perplexity is 42.336046062810574
At time: 523.286502122879 and batch: 1050, loss is 3.688059139251709 and perplexity is 39.96720086016109
At time: 524.6012246608734 and batch: 1100, loss is 3.7134340810775757 and perplexity is 40.994342979606714
At time: 525.918318271637 and batch: 1150, loss is 3.6864363622665404 and perplexity is 39.90239560290516
At time: 527.2358825206757 and batch: 1200, loss is 3.7430570793151854 and perplexity is 42.22688397886338
At time: 528.5544531345367 and batch: 1250, loss is 3.715043110847473 and perplexity is 41.06035719303316
At time: 529.869880437851 and batch: 1300, loss is 3.7279642963409425 and perplexity is 41.594348153436464
At time: 531.1861591339111 and batch: 1350, loss is 3.5891683769226073 and perplexity is 36.203955358963476
At time: 532.5021011829376 and batch: 1400, loss is 3.6147663688659666 and perplexity is 37.142667228413465
At time: 533.8177602291107 and batch: 1450, loss is 3.5415144062042234 and perplexity is 34.51915565074659
At time: 535.1328663825989 and batch: 1500, loss is 3.5309514808654785 and perplexity is 34.15645136837835
At time: 536.4463183879852 and batch: 1550, loss is 3.529576106071472 and perplexity is 34.109505737432734
At time: 537.7604377269745 and batch: 1600, loss is 3.622245750427246 and perplexity is 37.4215129055152
At time: 539.0767316818237 and batch: 1650, loss is 3.565716891288757 and perplexity is 35.36479703380286
At time: 540.395054101944 and batch: 1700, loss is 3.58279634475708 and perplexity is 35.973996023121316
At time: 541.7118883132935 and batch: 1750, loss is 3.5838478899002073 and perplexity is 36.01184419996404
At time: 543.0290729999542 and batch: 1800, loss is 3.528630747795105 and perplexity is 34.07727527095055
At time: 544.343480348587 and batch: 1850, loss is 3.564235234260559 and perplexity is 35.31243733286517
At time: 545.6589713096619 and batch: 1900, loss is 3.6490645933151247 and perplexity is 38.438693416355015
At time: 546.9761433601379 and batch: 1950, loss is 3.5699184560775756 and perplexity is 35.51369710739075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380121275436046 and perplexity of 79.84771638454072
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 550.9308605194092 and batch: 50, loss is 3.82931836605072 and perplexity is 46.03115114283283
At time: 552.2724390029907 and batch: 100, loss is 3.802226586341858 and perplexity is 44.80082642967966
At time: 553.5879437923431 and batch: 150, loss is 3.779856324195862 and perplexity is 43.80974688276331
At time: 554.9042360782623 and batch: 200, loss is 3.7980719375610352 and perplexity is 44.615080851774245
At time: 556.2228529453278 and batch: 250, loss is 3.8018550300598144 and perplexity is 44.78418349326423
At time: 557.5457274913788 and batch: 300, loss is 3.8156926441192627 and perplexity is 45.40819721380342
At time: 558.8726630210876 and batch: 350, loss is 3.8477615404129026 and perplexity is 46.887988804965
At time: 560.2060832977295 and batch: 400, loss is 3.8290102434158326 and perplexity is 46.01697008811996
At time: 561.530403137207 and batch: 450, loss is 3.8658385992050173 and perplexity is 47.74329313734766
At time: 562.8472344875336 and batch: 500, loss is 3.868717246055603 and perplexity is 47.880927222693956
At time: 564.1621367931366 and batch: 550, loss is 3.8450559473037718 and perplexity is 46.761300446410594
At time: 565.483006477356 and batch: 600, loss is 3.7917870330810546 and perplexity is 44.33555863556261
At time: 566.8122062683105 and batch: 650, loss is 3.794001889228821 and perplexity is 44.43386434648808
At time: 568.1313691139221 and batch: 700, loss is 3.842790379524231 and perplexity is 46.65547946835206
At time: 569.451905965805 and batch: 750, loss is 3.794704818725586 and perplexity is 44.46510920057072
At time: 570.7680418491364 and batch: 800, loss is 3.7486333417892457 and perplexity is 42.463009905608295
At time: 572.0817108154297 and batch: 850, loss is 3.7548627758026125 and perplexity is 42.72835604387246
At time: 573.3966155052185 and batch: 900, loss is 3.708752875328064 and perplexity is 40.80288849409497
At time: 574.7132749557495 and batch: 950, loss is 3.815131273269653 and perplexity is 45.38271352912237
At time: 576.0295786857605 and batch: 1000, loss is 3.7738617849349976 and perplexity is 43.54791320526725
At time: 577.3447558879852 and batch: 1050, loss is 3.710624485015869 and perplexity is 40.879327084781174
At time: 578.6587955951691 and batch: 1100, loss is 3.729171814918518 and perplexity is 41.64460443814603
At time: 579.9725501537323 and batch: 1150, loss is 3.6983056402206422 and perplexity is 40.37883010077332
At time: 581.2865002155304 and batch: 1200, loss is 3.745235495567322 and perplexity is 42.31897197577763
At time: 582.6041321754456 and batch: 1250, loss is 3.714828653335571 and perplexity is 41.05155243514872
At time: 583.9199821949005 and batch: 1300, loss is 3.728149118423462 and perplexity is 41.60203641794186
At time: 585.2342736721039 and batch: 1350, loss is 3.5911931467056273 and perplexity is 36.27733429645853
At time: 586.5513544082642 and batch: 1400, loss is 3.6280730676651003 and perplexity is 37.64021654158264
At time: 587.872930765152 and batch: 1450, loss is 3.554834270477295 and perplexity is 34.98202193345583
At time: 589.1904277801514 and batch: 1500, loss is 3.5367377042770385 and perplexity is 34.354661116874254
At time: 590.5089693069458 and batch: 1550, loss is 3.537153968811035 and perplexity is 34.36896472070963
At time: 591.8266355991364 and batch: 1600, loss is 3.626521682739258 and perplexity is 37.58186734976577
At time: 593.1425414085388 and batch: 1650, loss is 3.5687593030929565 and perplexity is 35.47255514891249
At time: 594.461275100708 and batch: 1700, loss is 3.572101397514343 and perplexity is 35.59130610550947
At time: 595.7805097103119 and batch: 1750, loss is 3.5634075355529786 and perplexity is 35.28322136679988
At time: 597.0995461940765 and batch: 1800, loss is 3.505369291305542 and perplexity is 33.293736669929935
At time: 598.4160284996033 and batch: 1850, loss is 3.5347210693359377 and perplexity is 34.28545011699232
At time: 599.730553150177 and batch: 1900, loss is 3.6305989170074464 and perplexity is 37.7354102296265
At time: 601.044949054718 and batch: 1950, loss is 3.5666603422164918 and perplexity is 35.39817772842119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369302439135175 and perplexity of 78.98851318197258
finished 11 epochs...
Completing Train Step...
At time: 605.011842250824 and batch: 50, loss is 3.845379409790039 and perplexity is 46.77642841944807
At time: 606.3257539272308 and batch: 100, loss is 3.802571940422058 and perplexity is 44.81630124987583
At time: 607.6487905979156 and batch: 150, loss is 3.7710674095153807 and perplexity is 43.42639385145248
At time: 608.9643335342407 and batch: 200, loss is 3.784837441444397 and perplexity is 44.02851276554491
At time: 610.2798948287964 and batch: 250, loss is 3.7843072414398193 and perplexity is 44.00517503525413
At time: 611.5961217880249 and batch: 300, loss is 3.7928267669677735 and perplexity is 44.38167979097179
At time: 612.9126451015472 and batch: 350, loss is 3.821686372756958 and perplexity is 45.68117889766448
At time: 614.2299480438232 and batch: 400, loss is 3.8015539264678955 and perplexity is 44.77070084469208
At time: 615.5542094707489 and batch: 450, loss is 3.8384207773208616 and perplexity is 46.45205834083843
At time: 616.8783390522003 and batch: 500, loss is 3.8395265626907347 and perplexity is 46.50345275771243
At time: 618.2000143527985 and batch: 550, loss is 3.814277939796448 and perplexity is 45.34400345921127
At time: 619.5174601078033 and batch: 600, loss is 3.763135437965393 and perplexity is 43.08329943731721
At time: 620.8329455852509 and batch: 650, loss is 3.7659490060806275 and perplexity is 43.204687922220884
At time: 622.1490914821625 and batch: 700, loss is 3.815968313217163 and perplexity is 45.42071657608801
At time: 623.4668889045715 and batch: 750, loss is 3.7696862602233887 and perplexity is 43.366456918784685
At time: 624.7851586341858 and batch: 800, loss is 3.72656934261322 and perplexity is 41.5363664127525
At time: 626.101823091507 and batch: 850, loss is 3.7344690799713134 and perplexity is 41.86579227394065
At time: 627.4170076847076 and batch: 900, loss is 3.6884505987167358 and perplexity is 39.98284946192524
At time: 628.7308766841888 and batch: 950, loss is 3.7966597270965576 and perplexity is 44.55211943557113
At time: 630.0473430156708 and batch: 1000, loss is 3.757783226966858 and perplexity is 42.85332451436296
At time: 631.3972244262695 and batch: 1050, loss is 3.6953131484985353 and perplexity is 40.25817740208657
At time: 632.7151031494141 and batch: 1100, loss is 3.715363278388977 and perplexity is 41.0735054913658
At time: 634.030978679657 and batch: 1150, loss is 3.6861805391311644 and perplexity is 39.892188952557326
At time: 635.3442885875702 and batch: 1200, loss is 3.733726797103882 and perplexity is 41.83472754443885
At time: 636.6595215797424 and batch: 1250, loss is 3.703464913368225 and perplexity is 40.58769384389763
At time: 637.9736483097076 and batch: 1300, loss is 3.7173790025711058 and perplexity is 41.1563818495076
At time: 639.2892467975616 and batch: 1350, loss is 3.5811640357971193 and perplexity is 35.91532324616443
At time: 640.6044237613678 and batch: 1400, loss is 3.6185252475738525 and perplexity is 37.2825447360089
At time: 641.9189474582672 and batch: 1450, loss is 3.5475942945480345 and perplexity is 34.72966755880906
At time: 643.2320606708527 and batch: 1500, loss is 3.5313510608673098 and perplexity is 34.170102330422765
At time: 644.5474941730499 and batch: 1550, loss is 3.5335355854034423 and perplexity is 34.24482934915133
At time: 645.8633337020874 and batch: 1600, loss is 3.6252826929092405 and perplexity is 37.53533263230013
At time: 647.1781091690063 and batch: 1650, loss is 3.5692707681655884 and perplexity is 35.49070276244779
At time: 648.4919238090515 and batch: 1700, loss is 3.57426992893219 and perplexity is 35.66857071609098
At time: 649.8047044277191 and batch: 1750, loss is 3.566799759864807 and perplexity is 35.403113203152884
At time: 651.120364189148 and batch: 1800, loss is 3.509935793876648 and perplexity is 33.4461202692802
At time: 652.4362490177155 and batch: 1850, loss is 3.53898353099823 and perplexity is 34.43190243565144
At time: 653.7509524822235 and batch: 1900, loss is 3.6345853996276856 and perplexity is 37.88614203190991
At time: 655.0658524036407 and batch: 1950, loss is 3.5695665502548217 and perplexity is 35.50120182930065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368688113190407 and perplexity of 78.9400033909235
finished 12 epochs...
Completing Train Step...
At time: 659.0499658584595 and batch: 50, loss is 3.8368682956695555 and perplexity is 46.37999832299987
At time: 660.3665008544922 and batch: 100, loss is 3.7934158420562745 and perplexity is 44.407831634866106
At time: 661.6819448471069 and batch: 150, loss is 3.760688347816467 and perplexity is 42.97799961131118
At time: 662.9958050251007 and batch: 200, loss is 3.7742650747299193 and perplexity is 43.56547917610338
At time: 664.3199164867401 and batch: 250, loss is 3.773119125366211 and perplexity is 43.51558393713076
At time: 665.6370420455933 and batch: 300, loss is 3.7815420722961424 and perplexity is 43.883661363438534
At time: 666.9604275226593 and batch: 350, loss is 3.8097994327545166 and perplexity is 45.14138407524054
At time: 668.2779252529144 and batch: 400, loss is 3.7886731958389284 and perplexity is 44.19771963740936
At time: 669.5913155078888 and batch: 450, loss is 3.825748291015625 and perplexity is 45.86710947406613
At time: 670.906388759613 and batch: 500, loss is 3.8264075708389282 and perplexity is 45.89735870415352
At time: 672.2210230827332 and batch: 550, loss is 3.8005302429199217 and perplexity is 44.72489326503919
At time: 673.5365681648254 and batch: 600, loss is 3.750079536437988 and perplexity is 42.524464109963176
At time: 674.8525905609131 and batch: 650, loss is 3.7534539318084716 and perplexity is 42.66820084067878
At time: 676.1668074131012 and batch: 700, loss is 3.803789882659912 and perplexity is 44.8709181694876
At time: 677.4870712757111 and batch: 750, loss is 3.7589187908172605 and perplexity is 42.90201484080612
At time: 678.8029720783234 and batch: 800, loss is 3.7166154336929322 and perplexity is 41.124968111991535
At time: 680.125173330307 and batch: 850, loss is 3.7245947551727294 and perplexity is 41.454430147093234
At time: 681.455629825592 and batch: 900, loss is 3.6788086223602297 and perplexity is 39.59918837066944
At time: 682.7739288806915 and batch: 950, loss is 3.787700433731079 and perplexity is 44.15474667511608
At time: 684.0886585712433 and batch: 1000, loss is 3.74943895816803 and perplexity is 42.4972325852054
At time: 685.40038895607 and batch: 1050, loss is 3.687070379257202 and perplexity is 39.927702421314194
At time: 686.7131605148315 and batch: 1100, loss is 3.70692485332489 and perplexity is 40.728368049392884
At time: 688.0282399654388 and batch: 1150, loss is 3.6784289598464968 and perplexity is 39.58415689689497
At time: 689.3411550521851 and batch: 1200, loss is 3.726521248817444 and perplexity is 41.534368819265275
At time: 690.6525962352753 and batch: 1250, loss is 3.6964371395111084 and perplexity is 40.303452671400414
At time: 691.9636585712433 and batch: 1300, loss is 3.710510673522949 and perplexity is 40.87467481228216
At time: 693.276223897934 and batch: 1350, loss is 3.57460636138916 and perplexity is 35.68057279980566
At time: 694.5928797721863 and batch: 1400, loss is 3.6122530460357667 and perplexity is 37.049432927920236
At time: 695.9074387550354 and batch: 1450, loss is 3.542085452079773 and perplexity is 34.53887330151415
At time: 697.2213668823242 and batch: 1500, loss is 3.5272303199768067 and perplexity is 34.02958590723912
At time: 698.5345101356506 and batch: 1550, loss is 3.5306848669052124 and perplexity is 34.14734599547409
At time: 699.8494448661804 and batch: 1600, loss is 3.623787875175476 and perplexity is 37.47926606652698
At time: 701.1648180484772 and batch: 1650, loss is 3.5688614559173586 and perplexity is 35.476178955697605
At time: 702.4827404022217 and batch: 1700, loss is 3.5748753643035887 and perplexity is 35.690172268961994
At time: 703.8005969524384 and batch: 1750, loss is 3.5678136110305787 and perplexity is 35.439024892223635
At time: 705.1186144351959 and batch: 1800, loss is 3.510666446685791 and perplexity is 33.47056670084927
At time: 706.4354820251465 and batch: 1850, loss is 3.538879566192627 and perplexity is 34.42832291568345
At time: 707.7527539730072 and batch: 1900, loss is 3.6335511589050293 and perplexity is 37.846978896541806
At time: 709.0709400177002 and batch: 1950, loss is 3.5676403522491453 and perplexity is 35.43288530183996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369285122183866 and perplexity of 78.98714535357922
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 713.0538363456726 and batch: 50, loss is 3.83368257522583 and perplexity is 46.23247971544586
At time: 714.3709268569946 and batch: 100, loss is 3.7998955917358397 and perplexity is 44.69651756385921
At time: 715.6903247833252 and batch: 150, loss is 3.775921859741211 and perplexity is 43.637717634285295
At time: 717.010427236557 and batch: 200, loss is 3.795951795578003 and perplexity is 44.520590747397094
At time: 718.328530550003 and batch: 250, loss is 3.800761170387268 and perplexity is 44.735222663993284
At time: 719.644570350647 and batch: 300, loss is 3.8117034101486205 and perplexity is 45.22741412370293
At time: 720.9599611759186 and batch: 350, loss is 3.8413291072845457 and perplexity is 46.58735289923052
At time: 722.2764921188354 and batch: 400, loss is 3.8207531499862672 and perplexity is 45.63856806711636
At time: 723.5920121669769 and batch: 450, loss is 3.864207592010498 and perplexity is 47.66548695122351
At time: 724.9083142280579 and batch: 500, loss is 3.867250533103943 and perplexity is 47.8107511232764
At time: 726.2229874134064 and batch: 550, loss is 3.8454464292526245 and perplexity is 46.77956345559545
At time: 727.5392558574677 and batch: 600, loss is 3.7860778522491456 and perplexity is 44.08316009405789
At time: 728.8567757606506 and batch: 650, loss is 3.7803207635879517 and perplexity is 43.83009858067242
At time: 730.1834740638733 and batch: 700, loss is 3.822982892990112 and perplexity is 45.74044388120292
At time: 731.4994385242462 and batch: 750, loss is 3.7806354570388794 and perplexity is 43.843893796167414
At time: 732.8134508132935 and batch: 800, loss is 3.738577489852905 and perplexity is 42.03814792000633
At time: 734.1289701461792 and batch: 850, loss is 3.749956822395325 and perplexity is 42.5192460812294
At time: 735.4451313018799 and batch: 900, loss is 3.6954222965240477 and perplexity is 40.262571742473156
At time: 736.7684710025787 and batch: 950, loss is 3.814199423789978 and perplexity is 45.34044336890617
At time: 738.0870108604431 and batch: 1000, loss is 3.7808586740493775 and perplexity is 43.85368159142975
At time: 739.404226064682 and batch: 1050, loss is 3.7263301610946655 and perplexity is 41.52643286956599
At time: 740.719884634018 and batch: 1100, loss is 3.7407896614074705 and perplexity is 42.13124645203737
At time: 742.0433266162872 and batch: 1150, loss is 3.7112302780151367 and perplexity is 40.90409899751199
At time: 743.3642911911011 and batch: 1200, loss is 3.7558029890060425 and perplexity is 42.76854870025801
At time: 744.6826424598694 and batch: 1250, loss is 3.7114929294586183 and perplexity is 40.91484392918213
At time: 746.0033984184265 and batch: 1300, loss is 3.7113415145874025 and perplexity is 40.90864928235044
At time: 747.3272368907928 and batch: 1350, loss is 3.568823914527893 and perplexity is 35.47484715564565
At time: 748.6449384689331 and batch: 1400, loss is 3.605073790550232 and perplexity is 36.78439809807589
At time: 749.9634518623352 and batch: 1450, loss is 3.5260679435729982 and perplexity is 33.99005369965287
At time: 751.2988958358765 and batch: 1500, loss is 3.515019664764404 and perplexity is 33.61658897972535
At time: 752.6156141757965 and batch: 1550, loss is 3.522118263244629 and perplexity is 33.85606862647931
At time: 753.9314353466034 and batch: 1600, loss is 3.6196951484680175 and perplexity is 37.3261871420996
At time: 755.2471015453339 and batch: 1650, loss is 3.568327932357788 and perplexity is 35.45725662662423
At time: 756.5660266876221 and batch: 1700, loss is 3.5843404960632324 and perplexity is 36.029588226408414
At time: 757.8836436271667 and batch: 1750, loss is 3.580824308395386 and perplexity is 35.903123899059175
At time: 759.2014274597168 and batch: 1800, loss is 3.52802197933197 and perplexity is 34.05653641367765
At time: 760.5175371170044 and batch: 1850, loss is 3.5474986124038694 and perplexity is 34.72634470872214
At time: 761.8374202251434 and batch: 1900, loss is 3.6379220199584963 and perplexity is 38.01276483229998
At time: 763.1558830738068 and batch: 1950, loss is 3.580349316596985 and perplexity is 35.886074259210254
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3559226812318315 and perplexity of 77.93870475094235
finished 14 epochs...
Completing Train Step...
At time: 767.1268649101257 and batch: 50, loss is 3.841011528968811 and perplexity is 46.572560115220284
At time: 768.4559655189514 and batch: 100, loss is 3.796866044998169 and perplexity is 44.561312283657365
At time: 769.7739038467407 and batch: 150, loss is 3.763885555267334 and perplexity is 43.11562908964971
At time: 771.0898542404175 and batch: 200, loss is 3.7776147413253782 and perplexity is 43.71165368767761
At time: 772.406480550766 and batch: 250, loss is 3.7777895593643187 and perplexity is 43.71929594123656
At time: 773.7214531898499 and batch: 300, loss is 3.788992657661438 and perplexity is 44.211841377033736
At time: 775.0358860492706 and batch: 350, loss is 3.821322717666626 and perplexity is 45.66456972461419
At time: 776.3502962589264 and batch: 400, loss is 3.8015107822418215 and perplexity is 44.76876928912138
At time: 777.6655323505402 and batch: 450, loss is 3.8435214042663572 and perplexity is 46.68959824751564
At time: 778.9907412528992 and batch: 500, loss is 3.844995141029358 and perplexity is 46.75845715238964
At time: 780.3055613040924 and batch: 550, loss is 3.826342921257019 and perplexity is 45.894391555016064
At time: 781.6209371089935 and batch: 600, loss is 3.770348687171936 and perplexity is 43.395193545417825
At time: 782.9351804256439 and batch: 650, loss is 3.766475057601929 and perplexity is 43.22742179309913
At time: 784.2512543201447 and batch: 700, loss is 3.8120562267303466 and perplexity is 45.24337392062931
At time: 785.5669016838074 and batch: 750, loss is 3.7681747102737426 and perplexity is 43.30095586953792
At time: 786.8833115100861 and batch: 800, loss is 3.725977578163147 and perplexity is 41.51179393899951
At time: 788.2003829479218 and batch: 850, loss is 3.7354617977142333 and perplexity is 41.907373824709154
At time: 789.5136425495148 and batch: 900, loss is 3.6819143676757813 and perplexity is 39.72236454235084
At time: 790.827264547348 and batch: 950, loss is 3.798531484603882 and perplexity is 44.63558829195189
At time: 792.146479845047 and batch: 1000, loss is 3.765216226577759 and perplexity is 43.17304000937072
At time: 793.4696753025055 and batch: 1050, loss is 3.7105341243743895 and perplexity is 40.875633369448295
At time: 794.8183298110962 and batch: 1100, loss is 3.7280281925201417 and perplexity is 41.597005958270636
At time: 796.1349637508392 and batch: 1150, loss is 3.7001071310043336 and perplexity is 40.451637752522274
At time: 797.4576580524445 and batch: 1200, loss is 3.74634361743927 and perplexity is 42.36589254627627
At time: 798.77525639534 and batch: 1250, loss is 3.704675302505493 and perplexity is 40.63685049096749
At time: 800.0914976596832 and batch: 1300, loss is 3.707663826942444 and perplexity is 40.75847636212166
At time: 801.4077048301697 and batch: 1350, loss is 3.567339038848877 and perplexity is 35.422210506998475
At time: 802.7243008613586 and batch: 1400, loss is 3.6054925775527953 and perplexity is 36.79980615201765
At time: 804.0413780212402 and batch: 1450, loss is 3.5298120737075807 and perplexity is 34.117555426566135
At time: 805.3580327033997 and batch: 1500, loss is 3.518227849006653 and perplexity is 33.724610374386
At time: 806.6766426563263 and batch: 1550, loss is 3.5260625791549685 and perplexity is 33.98987136328504
At time: 807.9945604801178 and batch: 1600, loss is 3.624841294288635 and perplexity is 37.51876824427023
At time: 809.3108961582184 and batch: 1650, loss is 3.574171757698059 and perplexity is 35.66506926035803
At time: 810.6281840801239 and batch: 1700, loss is 3.589709372520447 and perplexity is 36.223546838411295
At time: 811.9456510543823 and batch: 1750, loss is 3.586909809112549 and perplexity is 36.12227854182826
At time: 813.2636561393738 and batch: 1800, loss is 3.534927101135254 and perplexity is 34.29251473771357
At time: 814.5820326805115 and batch: 1850, loss is 3.5537603807449343 and perplexity is 34.944475263384376
At time: 815.899498462677 and batch: 1900, loss is 3.643352675437927 and perplexity is 38.21976061458776
At time: 817.2148084640503 and batch: 1950, loss is 3.585059862136841 and perplexity is 36.05551601449202
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354196947674419 and perplexity of 77.80431930282283
finished 15 epochs...
Completing Train Step...
At time: 821.1805083751678 and batch: 50, loss is 3.8393803071975707 and perplexity is 46.49665186964127
At time: 822.5118825435638 and batch: 100, loss is 3.7941725969314577 and perplexity is 44.44145019685306
At time: 823.8290190696716 and batch: 150, loss is 3.7595528078079226 and perplexity is 42.92922407179474
At time: 825.1441798210144 and batch: 200, loss is 3.7713076305389404 and perplexity is 43.43682703731811
At time: 826.4615256786346 and batch: 250, loss is 3.7704900217056276 and perplexity is 43.40132721830172
At time: 827.7916934490204 and batch: 300, loss is 3.7819278764724733 and perplexity is 43.900595129614054
At time: 829.1095473766327 and batch: 350, loss is 3.8149356508255003 and perplexity is 45.37383652007893
At time: 830.4276268482208 and batch: 400, loss is 3.794648427963257 and perplexity is 44.46260184986223
At time: 831.7446043491364 and batch: 450, loss is 3.8365827798843384 and perplexity is 46.36675799161206
At time: 833.0609893798828 and batch: 500, loss is 3.8374091482162473 and perplexity is 46.40508984800438
At time: 834.3790593147278 and batch: 550, loss is 3.8186759901046754 and perplexity is 45.543867852266985
At time: 835.6963376998901 and batch: 600, loss is 3.763128972053528 and perplexity is 43.0830208654008
At time: 837.0147616863251 and batch: 650, loss is 3.759633526802063 and perplexity is 42.93268941543869
At time: 838.3317120075226 and batch: 700, loss is 3.8056903791427614 and perplexity is 44.956276277350845
At time: 839.6476442813873 and batch: 750, loss is 3.7620311403274536 and perplexity is 43.03574891131293
At time: 840.9648590087891 and batch: 800, loss is 3.7200973796844483 and perplexity is 41.26841261794545
At time: 842.282954454422 and batch: 850, loss is 3.7288180780410767 and perplexity is 41.62987581099268
At time: 843.6000452041626 and batch: 900, loss is 3.6759658432006836 and perplexity is 39.48677648002808
At time: 844.9169120788574 and batch: 950, loss is 3.792411513328552 and perplexity is 44.363253962884684
At time: 846.2325344085693 and batch: 1000, loss is 3.760133843421936 and perplexity is 42.95417472777032
At time: 847.5492124557495 and batch: 1050, loss is 3.7059000158309936 and perplexity is 40.6866494717833
At time: 848.8665935993195 and batch: 1100, loss is 3.7249716615676878 and perplexity is 41.47005753176064
At time: 850.1842911243439 and batch: 1150, loss is 3.6978259897232055 and perplexity is 40.35946701895672
At time: 851.5014505386353 and batch: 1200, loss is 3.7444608402252197 and perplexity is 42.286202052401165
At time: 852.8167462348938 and batch: 1250, loss is 3.703528470993042 and perplexity is 40.59027358329533
At time: 854.1327874660492 and batch: 1300, loss is 3.707494955062866 and perplexity is 40.751593982746186
At time: 855.4496207237244 and batch: 1350, loss is 3.567700686454773 and perplexity is 35.435023181320716
At time: 856.7721016407013 and batch: 1400, loss is 3.606168351173401 and perplexity is 36.824682894835156
At time: 858.0892887115479 and batch: 1450, loss is 3.531153721809387 and perplexity is 34.16335989991408
At time: 859.4047706127167 and batch: 1500, loss is 3.519193296432495 and perplexity is 33.75718543488339
At time: 860.7217392921448 and batch: 1550, loss is 3.527091736793518 and perplexity is 34.02487030565719
At time: 862.0399086475372 and batch: 1600, loss is 3.6260973978042603 and perplexity is 37.565925311842605
At time: 863.3596754074097 and batch: 1650, loss is 3.575565996170044 and perplexity is 35.71482955282313
At time: 864.6775224208832 and batch: 1700, loss is 3.590845575332642 and perplexity is 36.26472752457228
At time: 865.9945409297943 and batch: 1750, loss is 3.5885852813720702 and perplexity is 36.18285114716577
At time: 867.3107995986938 and batch: 1800, loss is 3.536951112747192 and perplexity is 34.36199347491168
At time: 868.6284666061401 and batch: 1850, loss is 3.555646014213562 and perplexity is 35.010429899076456
At time: 869.947015285492 and batch: 1900, loss is 3.644937891960144 and perplexity is 38.28039525741054
At time: 871.2659990787506 and batch: 1950, loss is 3.5862662982940674 and perplexity is 36.0990409424236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.353463958030523 and perplexity of 77.74731043852951
finished 16 epochs...
Completing Train Step...
At time: 875.2370007038116 and batch: 50, loss is 3.8370067167282103 and perplexity is 46.38641873581806
At time: 876.5673384666443 and batch: 100, loss is 3.7913069343566894 and perplexity is 44.3142782991576
At time: 877.885107755661 and batch: 150, loss is 3.7560664892196653 and perplexity is 42.779819706867976
At time: 879.2031760215759 and batch: 200, loss is 3.7670608949661255 and perplexity is 43.25275345133487
At time: 880.5194985866547 and batch: 250, loss is 3.7659308195114134 and perplexity is 43.20390218431857
At time: 881.8440434932709 and batch: 300, loss is 3.777280178070068 and perplexity is 43.69703182063098
At time: 883.1720335483551 and batch: 350, loss is 3.8104310274124145 and perplexity is 45.1699041378841
At time: 884.5004284381866 and batch: 400, loss is 3.790005841255188 and perplexity is 44.256658789666105
At time: 885.8230671882629 and batch: 450, loss is 3.8319594764709475 and perplexity is 46.15288518152766
At time: 887.1399838924408 and batch: 500, loss is 3.8325733232498167 and perplexity is 46.18122467859648
At time: 888.4553344249725 and batch: 550, loss is 3.813647594451904 and perplexity is 45.315430084220836
At time: 889.7728879451752 and batch: 600, loss is 3.7584995555877687 and perplexity is 42.884032574431835
At time: 891.0900266170502 and batch: 650, loss is 3.7552636241912842 and perplexity is 42.745487069785916
At time: 892.4070644378662 and batch: 700, loss is 3.8015158557891846 and perplexity is 44.76899642616895
At time: 893.7565398216248 and batch: 750, loss is 3.7581795406341554 and perplexity is 42.870311238370235
At time: 895.0709233283997 and batch: 800, loss is 3.7164618015289306 and perplexity is 41.118650479454196
At time: 896.3847765922546 and batch: 850, loss is 3.724868125915527 and perplexity is 41.46576412457314
At time: 897.7024710178375 and batch: 900, loss is 3.672364172935486 and perplexity is 39.34481393591023
At time: 899.0218045711517 and batch: 950, loss is 3.788986439704895 and perplexity is 44.211566470580046
At time: 900.3400704860687 and batch: 1000, loss is 3.7572882556915284 and perplexity is 42.83211859826858
At time: 901.6563048362732 and batch: 1050, loss is 3.70330849647522 and perplexity is 40.58134573942066
At time: 902.9737973213196 and batch: 1100, loss is 3.723104491233826 and perplexity is 41.3926981146731
At time: 904.2922451496124 and batch: 1150, loss is 3.6963210773468016 and perplexity is 40.29877523689618
At time: 905.6100013256073 and batch: 1200, loss is 3.743131732940674 and perplexity is 42.230036486517086
At time: 906.9283339977264 and batch: 1250, loss is 3.702498893737793 and perplexity is 40.548504266888436
At time: 908.2456603050232 and batch: 1300, loss is 3.7068987035751344 and perplexity is 40.72730302668553
At time: 909.5622174739838 and batch: 1350, loss is 3.567229833602905 and perplexity is 35.41834242699834
At time: 910.8864734172821 and batch: 1400, loss is 3.605784087181091 and perplexity is 36.81053521356677
At time: 912.2051267623901 and batch: 1450, loss is 3.531000838279724 and perplexity is 34.15813728410357
At time: 913.5216035842896 and batch: 1500, loss is 3.518906388282776 and perplexity is 33.74750161252076
At time: 914.8379445075989 and batch: 1550, loss is 3.526947045326233 and perplexity is 34.01994755339718
At time: 916.154803276062 and batch: 1600, loss is 3.6260846567153933 and perplexity is 37.56544668409896
At time: 917.4753477573395 and batch: 1650, loss is 3.5757707929611207 and perplexity is 35.722144584331325
At time: 918.7927157878876 and batch: 1700, loss is 3.5909781360626223 and perplexity is 36.26953512196775
At time: 920.1102240085602 and batch: 1750, loss is 3.5891158771514893 and perplexity is 36.20205470948583
At time: 921.4379367828369 and batch: 1800, loss is 3.5377012348175048 and perplexity is 34.38777883447172
At time: 922.7550015449524 and batch: 1850, loss is 3.556386399269104 and perplexity is 35.036360696364675
At time: 924.0715427398682 and batch: 1900, loss is 3.6456300687789915 and perplexity is 38.30690123197634
At time: 925.3895885944366 and batch: 1950, loss is 3.5867334747314454 and perplexity is 36.11590950375424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3530886627906975 and perplexity of 77.71813771754677
finished 17 epochs...
Completing Train Step...
At time: 929.3568167686462 and batch: 50, loss is 3.8347483253479004 and perplexity is 46.281778251640496
At time: 930.680246591568 and batch: 100, loss is 3.7886689949035643 and perplexity is 44.19753396603592
At time: 931.9986155033112 and batch: 150, loss is 3.7530240297317503 and perplexity is 42.649861634841194
At time: 933.3166146278381 and batch: 200, loss is 3.763656506538391 and perplexity is 43.105754640517326
At time: 934.6344363689423 and batch: 250, loss is 3.762407784461975 and perplexity is 43.051961126641366
At time: 935.9502944946289 and batch: 300, loss is 3.7735976552963257 and perplexity is 43.53641242960215
At time: 937.2659285068512 and batch: 350, loss is 3.8067594003677367 and perplexity is 45.00436118820303
At time: 938.5836281776428 and batch: 400, loss is 3.7863396549224855 and perplexity is 44.09470269409562
At time: 939.9017667770386 and batch: 450, loss is 3.8283133935928344 and perplexity is 45.98491434097719
At time: 941.2185394763947 and batch: 500, loss is 3.828824005126953 and perplexity is 46.008400764344195
At time: 942.5374898910522 and batch: 550, loss is 3.8097254705429076 and perplexity is 45.13804544210711
At time: 943.8520872592926 and batch: 600, loss is 3.754952573776245 and perplexity is 42.73219313594081
At time: 945.1677935123444 and batch: 650, loss is 3.751969566345215 and perplexity is 42.604912620016535
At time: 946.484913110733 and batch: 700, loss is 3.7983221101760862 and perplexity is 44.62624371948533
At time: 947.8034269809723 and batch: 750, loss is 3.755254855155945 and perplexity is 42.745112234742685
At time: 949.1212244033813 and batch: 800, loss is 3.713705720901489 and perplexity is 41.00548018830136
At time: 950.4377455711365 and batch: 850, loss is 3.7219109535217285 and perplexity is 41.34332383935885
At time: 951.7535848617554 and batch: 900, loss is 3.669600234031677 and perplexity is 39.23621742021089
At time: 953.0713083744049 and batch: 950, loss is 3.786386179924011 and perplexity is 44.09675424792964
At time: 954.3892467021942 and batch: 1000, loss is 3.755052285194397 and perplexity is 42.736454235955776
At time: 955.7057871818542 and batch: 1050, loss is 3.7012302446365357 and perplexity is 40.497095060409855
At time: 957.0223157405853 and batch: 1100, loss is 3.7214338874816892 and perplexity is 41.323605047529696
At time: 958.3701803684235 and batch: 1150, loss is 3.694862184524536 and perplexity is 40.24002650742676
At time: 959.6874520778656 and batch: 1200, loss is 3.741812105178833 and perplexity is 42.174345311877794
At time: 961.0054903030396 and batch: 1250, loss is 3.701349630355835 and perplexity is 40.50193012384619
At time: 962.3233499526978 and batch: 1300, loss is 3.7060242652893067 and perplexity is 40.69170508001253
At time: 963.63991522789 and batch: 1350, loss is 3.5663828897476195 and perplexity is 35.38835777896447
At time: 964.9551513195038 and batch: 1400, loss is 3.6049807548522947 and perplexity is 36.78097599511697
At time: 966.2713911533356 and batch: 1450, loss is 3.5302869844436646 and perplexity is 34.13376206797655
At time: 967.5890827178955 and batch: 1500, loss is 3.5181381607055666 and perplexity is 33.72158580701291
At time: 968.9068124294281 and batch: 1550, loss is 3.526337456703186 and perplexity is 33.99921570000496
At time: 970.2242243289948 and batch: 1600, loss is 3.6255981588363646 and perplexity is 37.54717561874002
At time: 971.5403270721436 and batch: 1650, loss is 3.57549795627594 and perplexity is 35.712399602270146
At time: 972.8566129207611 and batch: 1700, loss is 3.590715012550354 and perplexity is 36.259993009930184
At time: 974.1755001544952 and batch: 1750, loss is 3.5891571187973024 and perplexity is 36.20354777259185
At time: 975.4937920570374 and batch: 1800, loss is 3.5379138708114626 and perplexity is 34.39509169146494
At time: 976.8128736019135 and batch: 1850, loss is 3.556635928153992 and perplexity is 35.04510437123413
At time: 978.1315870285034 and batch: 1900, loss is 3.6459286832809448 and perplexity is 38.3183419363042
At time: 979.4473910331726 and batch: 1950, loss is 3.5868852758407592 and perplexity is 36.121392355021705
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352900731286337 and perplexity of 77.70353340335778
finished 18 epochs...
Completing Train Step...
At time: 983.415931224823 and batch: 50, loss is 3.8326230955123903 and perplexity is 46.18352327983997
At time: 984.7330513000488 and batch: 100, loss is 3.786236968040466 and perplexity is 44.09017497903485
At time: 986.0484488010406 and batch: 150, loss is 3.75028374671936 and perplexity is 42.5331489294788
At time: 987.3655958175659 and batch: 200, loss is 3.7607030200958254 and perplexity is 42.97863020115382
At time: 988.6828727722168 and batch: 250, loss is 3.759395604133606 and perplexity is 42.92247597046215
At time: 989.9997410774231 and batch: 300, loss is 3.7704258489608766 and perplexity is 43.398542125372764
At time: 991.3302335739136 and batch: 350, loss is 3.8035585641860963 and perplexity is 44.86053989756722
At time: 992.6445620059967 and batch: 400, loss is 3.7831910181045534 and perplexity is 43.95608283603371
At time: 993.9607083797455 and batch: 450, loss is 3.825189642906189 and perplexity is 45.841493056021136
At time: 995.2788326740265 and batch: 500, loss is 3.825634069442749 and perplexity is 45.861870759871515
At time: 996.5967066287994 and batch: 550, loss is 3.80637996673584 and perplexity is 44.987288259212754
At time: 997.9138400554657 and batch: 600, loss is 3.751950922012329 and perplexity is 42.60411828724799
At time: 999.2302641868591 and batch: 650, loss is 3.7492118215560915 and perplexity is 42.48758100393447
At time: 1000.5460007190704 and batch: 700, loss is 3.7956278944015502 and perplexity is 44.506172810797004
At time: 1001.8685078620911 and batch: 750, loss is 3.7527747440338133 and perplexity is 42.63923095940936
At time: 1003.1893255710602 and batch: 800, loss is 3.7113612604141237 and perplexity is 40.90945706542572
At time: 1004.5092422962189 and batch: 850, loss is 3.719408755302429 and perplexity is 41.24000396537754
At time: 1005.8381199836731 and batch: 900, loss is 3.6672250175476075 and perplexity is 39.14313350081401
At time: 1007.1686928272247 and batch: 950, loss is 3.784128341674805 and perplexity is 43.997303223934495
At time: 1008.4864621162415 and batch: 1000, loss is 3.7530683612823488 and perplexity is 42.65175241125049
At time: 1009.8048055171967 and batch: 1050, loss is 3.6993618297576902 and perplexity is 40.421500328601404
At time: 1011.1233084201813 and batch: 1100, loss is 3.7198370265960694 and perplexity is 41.257669657809984
At time: 1012.4410328865051 and batch: 1150, loss is 3.693416061401367 and perplexity is 40.18187653076432
At time: 1013.757994890213 and batch: 1200, loss is 3.7404986953735353 and perplexity is 42.11898947362114
At time: 1015.0732929706573 and batch: 1250, loss is 3.700149531364441 and perplexity is 40.45335295289221
At time: 1016.3895452022552 and batch: 1300, loss is 3.7050339555740357 and perplexity is 40.65142763600463
At time: 1017.7077066898346 and batch: 1350, loss is 3.5653921699523927 and perplexity is 35.35331519394987
At time: 1019.0257875919342 and batch: 1400, loss is 3.6040217781066897 and perplexity is 36.74572080161419
At time: 1020.3432967662811 and batch: 1450, loss is 3.529351143836975 and perplexity is 34.10183324984678
At time: 1021.6591846942902 and batch: 1500, loss is 3.5171747255325316 and perplexity is 33.68911289044271
At time: 1022.9745202064514 and batch: 1550, loss is 3.5255178689956663 and perplexity is 33.97136177667768
At time: 1024.2918252944946 and batch: 1600, loss is 3.624902467727661 and perplexity is 37.521063466554345
At time: 1025.6098651885986 and batch: 1650, loss is 3.574986710548401 and perplexity is 35.69414645687219
At time: 1026.926679611206 and batch: 1700, loss is 3.5902540397644045 and perplexity is 36.243281991892076
At time: 1028.2461910247803 and batch: 1750, loss is 3.5889408874511717 and perplexity is 36.19572027702772
At time: 1029.5655517578125 and batch: 1800, loss is 3.5378468799591065 and perplexity is 34.39278761213264
At time: 1030.8829429149628 and batch: 1850, loss is 3.5566293001174927 and perplexity is 35.044872091773016
At time: 1032.2022366523743 and batch: 1900, loss is 3.646006350517273 and perplexity is 38.321318131598
At time: 1033.520103931427 and batch: 1950, loss is 3.586857409477234 and perplexity is 36.12038579719592
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352834870094477 and perplexity of 77.69841592455955
finished 19 epochs...
Completing Train Step...
At time: 1037.5098991394043 and batch: 50, loss is 3.830603175163269 and perplexity is 46.09033039416219
At time: 1038.8280856609344 and batch: 100, loss is 3.783963232040405 and perplexity is 43.99003944496106
At time: 1040.142652273178 and batch: 150, loss is 3.747761664390564 and perplexity is 42.426011987060924
At time: 1041.4599313735962 and batch: 200, loss is 3.7580338811874388 and perplexity is 42.864067227315324
At time: 1042.7774713039398 and batch: 250, loss is 3.756687569618225 and perplexity is 42.80639766701251
At time: 1044.0930063724518 and batch: 300, loss is 3.7675699901580813 and perplexity is 43.274778826186306
At time: 1045.4105379581451 and batch: 350, loss is 3.80065749168396 and perplexity is 44.73058481454255
At time: 1046.7270095348358 and batch: 400, loss is 3.780353832244873 and perplexity is 43.83154800713037
At time: 1048.0467295646667 and batch: 450, loss is 3.8223838567733766 and perplexity is 45.713051903960846
At time: 1049.3641080856323 and batch: 500, loss is 3.822778778076172 and perplexity is 45.73110852721142
At time: 1050.6792187690735 and batch: 550, loss is 3.8033815002441407 and perplexity is 44.852597416718936
At time: 1052.0059349536896 and batch: 600, loss is 3.7492676830291747 and perplexity is 42.48995448908966
At time: 1053.3301060199738 and batch: 650, loss is 3.7467598915100098 and perplexity is 42.38353204000424
At time: 1054.6544251441956 and batch: 700, loss is 3.7932248306274414 and perplexity is 44.39935004156057
At time: 1055.9722611904144 and batch: 750, loss is 3.7505456399917603 and perplexity is 42.544289533798406
At time: 1057.3300347328186 and batch: 800, loss is 3.709247598648071 and perplexity is 40.8230796286574
At time: 1058.6464173793793 and batch: 850, loss is 3.71716392993927 and perplexity is 41.14753118994783
At time: 1059.9631435871124 and batch: 900, loss is 3.665076665878296 and perplexity is 39.059130550863365
At time: 1061.2814824581146 and batch: 950, loss is 3.7820619916915894 and perplexity is 43.90648326238448
At time: 1062.6033084392548 and batch: 1000, loss is 3.7512319803237917 and perplexity is 42.57349941841739
At time: 1063.9209270477295 and batch: 1050, loss is 3.6976209545135497 and perplexity is 40.35119275546155
At time: 1065.2376952171326 and batch: 1100, loss is 3.7182953214645384 and perplexity is 41.194111503339016
At time: 1066.55464553833 and batch: 1150, loss is 3.691995086669922 and perplexity is 40.124819647347465
At time: 1067.8723068237305 and batch: 1200, loss is 3.7392062520980835 and perplexity is 42.06458823173946
At time: 1069.193820476532 and batch: 1250, loss is 3.698938889503479 and perplexity is 40.40440806373503
At time: 1070.512725353241 and batch: 1300, loss is 3.703997254371643 and perplexity is 40.609306089596814
At time: 1071.82754945755 and batch: 1350, loss is 3.5643446540832517 and perplexity is 35.31630142489726
At time: 1073.1428530216217 and batch: 1400, loss is 3.6030012273788454 and perplexity is 36.70823905876809
At time: 1074.4599618911743 and batch: 1450, loss is 3.528317618370056 and perplexity is 34.066606343802405
At time: 1075.7783422470093 and batch: 1500, loss is 3.5161241817474367 and perplexity is 33.653739586126086
At time: 1077.0960097312927 and batch: 1550, loss is 3.524590311050415 and perplexity is 33.939865979497334
At time: 1078.4121873378754 and batch: 1600, loss is 3.624099087715149 and perplexity is 37.49093189928719
At time: 1079.7291226387024 and batch: 1650, loss is 3.5743407726287844 and perplexity is 35.6710976990021
At time: 1081.0462174415588 and batch: 1700, loss is 3.5896810245513917 and perplexity is 36.22251998898107
At time: 1082.365893125534 and batch: 1750, loss is 3.5885767412185667 and perplexity is 36.182542141382264
At time: 1083.6851570606232 and batch: 1800, loss is 3.5376161766052245 and perplexity is 34.3848539958723
At time: 1085.003223657608 and batch: 1850, loss is 3.5564723920822146 and perplexity is 35.03937370112864
At time: 1086.320255279541 and batch: 1900, loss is 3.645944890975952 and perplexity is 38.318962993336434
At time: 1087.6362102031708 and batch: 1950, loss is 3.5867138290405274 and perplexity is 36.11519998872838
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352850767623546 and perplexity of 77.69965114720381
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f00fbd17b38>
ELAPSED
6691.92954158783


RESULTS SO FAR:
[{'params': {'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}, 'best_accuracy': -78.33907429225935}, {'params': {'dropout': 0.16802636512990798, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.23001756521426064}, 'best_accuracy': -77.64523175401864}, {'params': {'dropout': 0.7990403138855218, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.10718988942097152}, 'best_accuracy': -77.79230466527649}, {'params': {'dropout': 0.7943354117872055, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.9645103263983709}, 'best_accuracy': -82.35574479727755}, {'params': {'dropout': 0.37534925793438456, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.7617994495357929}, 'best_accuracy': -77.8097750908434}, {'params': {'dropout': 0.3942674357276707, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.1655256110608432}, 'best_accuracy': -77.69841592455955}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'dropout': 0.3100826111212067, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.6821294103613286}, 'best_accuracy': -78.33907429225935}, {'params': {'dropout': 0.16802636512990798, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.23001756521426064}, 'best_accuracy': -77.64523175401864}, {'params': {'dropout': 0.7990403138855218, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.10718988942097152}, 'best_accuracy': -77.79230466527649}, {'params': {'dropout': 0.7943354117872055, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.9645103263983709}, 'best_accuracy': -82.35574479727755}, {'params': {'dropout': 0.37534925793438456, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.7617994495357929}, 'best_accuracy': -77.8097750908434}, {'params': {'dropout': 0.3942674357276707, 'wordvec_source': 'None', 'num_layers': 3, 'batch_size': 32, 'seq_len': 35, 'data': 'wikitext', 'tune_wordvecs': 'FALSE', 'tie_weights': 'TRUE', 'wordvec_dim': 300, 'rnn_dropout': 0.1655256110608432}, 'best_accuracy': -77.69841592455955}]
