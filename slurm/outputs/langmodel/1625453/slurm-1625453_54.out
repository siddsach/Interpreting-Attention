Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'type': 'continuous', 'name': 'dropout', 'domain': [0, 1]}, {'type': 'continuous', 'name': 'rnn_dropout', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9368586540222168 and batch: 50, loss is 7.659351139068604 and perplexity is 2120.3811496322724
At time: 3.0826053619384766 and batch: 100, loss is 6.854499950408935 and perplexity is 948.1378948779445
At time: 4.236145973205566 and batch: 150, loss is 6.549293098449707 and perplexity is 698.7500516938048
At time: 5.3896753787994385 and batch: 200, loss is 6.4467857074737545 and perplexity is 630.6718674997232
At time: 6.543567180633545 and batch: 250, loss is 6.375943851470947 and perplexity is 587.5397195460359
At time: 7.692962884902954 and batch: 300, loss is 6.306604633331299 and perplexity is 548.1805115418192
At time: 8.840151071548462 and batch: 350, loss is 6.2497147178649906 and perplexity is 517.8650659412231
At time: 9.98738694190979 and batch: 400, loss is 6.208690490722656 and perplexity is 497.04993342736515
At time: 11.136493444442749 and batch: 450, loss is 6.122695531845093 and perplexity is 456.0924507534017
At time: 12.290218591690063 and batch: 500, loss is 6.104834718704224 and perplexity is 448.01858624311325
At time: 13.443042993545532 and batch: 550, loss is 6.0446333408355715 and perplexity is 421.8430565006117
At time: 14.595530271530151 and batch: 600, loss is 6.09485013961792 and perplexity is 443.5675669909598
At time: 15.748879194259644 and batch: 650, loss is 6.161897649765015 and perplexity is 474.32732847416855
At time: 16.902559995651245 and batch: 700, loss is 6.070352048873901 and perplexity is 432.83303313720785
At time: 18.055952310562134 and batch: 750, loss is 6.002294855117798 and perplexity is 404.3556672378569
At time: 19.2092125415802 and batch: 800, loss is 6.004645338058472 and perplexity is 405.3072161973719
At time: 20.363219261169434 and batch: 850, loss is 6.040770683288574 and perplexity is 420.21676416199864
At time: 21.516136646270752 and batch: 900, loss is 6.012904462814331 and perplexity is 408.668560835451
At time: 22.672022819519043 and batch: 950, loss is 6.028214206695557 and perplexity is 414.9733107411658
At time: 23.825211763381958 and batch: 1000, loss is 6.0136801052093505 and perplexity is 408.9856644603562
At time: 24.97880220413208 and batch: 1050, loss is 5.913361520767212 and perplexity is 369.94765430085795
At time: 26.135682582855225 and batch: 1100, loss is 5.996841382980347 and perplexity is 402.15652679877627
At time: 27.293233394622803 and batch: 1150, loss is 5.895781555175781 and perplexity is 363.5008208574292
At time: 28.448930740356445 and batch: 1200, loss is 5.973326940536499 and perplexity is 392.8103559377822
At time: 29.60384750366211 and batch: 1250, loss is 5.915191631317139 and perplexity is 370.625319317721
At time: 30.770230054855347 and batch: 1300, loss is 5.936424074172973 and perplexity is 378.578736678717
At time: 31.930087089538574 and batch: 1350, loss is 5.911746463775635 and perplexity is 369.3506499830299
At time: 33.088624477386475 and batch: 1400, loss is 5.92622540473938 and perplexity is 374.7373590550182
At time: 34.249407052993774 and batch: 1450, loss is 5.908532037734985 and perplexity is 368.1653057569014
At time: 35.41218376159668 and batch: 1500, loss is 5.8873712348937985 and perplexity is 360.45648240666515
At time: 36.576171875 and batch: 1550, loss is 5.855509576797485 and perplexity is 349.1527748825513
At time: 37.738630533218384 and batch: 1600, loss is 5.866235523223877 and perplexity is 352.9179251435301
At time: 38.91356086730957 and batch: 1650, loss is 5.864010591506958 and perplexity is 352.13357973945557
At time: 40.14360785484314 and batch: 1700, loss is 5.883239707946777 and perplexity is 358.970318912642
At time: 41.40081763267517 and batch: 1750, loss is 5.89177059173584 and perplexity is 362.0457524184773
At time: 42.664982080459595 and batch: 1800, loss is 5.898496417999268 and perplexity is 364.4890165231632
At time: 43.93176317214966 and batch: 1850, loss is 5.857940444946289 and perplexity is 350.00255167129177
At time: 45.19789218902588 and batch: 1900, loss is 5.840295705795288 and perplexity is 343.88101324014553
At time: 46.46474742889404 and batch: 1950, loss is 5.774295139312744 and perplexity is 321.91744777730855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.290698809956395 and perplexity of 198.4820782101792
finished 1 epochs...
Completing Train Step...
At time: 49.95670986175537 and batch: 50, loss is 5.57750171661377 and perplexity is 264.4102083204849
At time: 50.9984347820282 and batch: 100, loss is 5.494505910873413 and perplexity is 243.35125924069575
At time: 52.04003095626831 and batch: 150, loss is 5.390127658843994 and perplexity is 219.23137059098468
At time: 53.08233976364136 and batch: 200, loss is 5.332734632492065 and perplexity is 207.00327874589243
At time: 54.14525532722473 and batch: 250, loss is 5.323143081665039 and perplexity is 205.0272878339589
At time: 55.22001051902771 and batch: 300, loss is 5.312720556259155 and perplexity is 202.90148308823683
At time: 56.33186626434326 and batch: 350, loss is 5.276373176574707 and perplexity is 195.65896643766763
At time: 57.38954043388367 and batch: 400, loss is 5.221558771133423 and perplexity is 185.2226789287097
At time: 58.44615435600281 and batch: 450, loss is 5.160155572891235 and perplexity is 174.1915529807736
At time: 59.5064218044281 and batch: 500, loss is 5.14188141822815 and perplexity is 171.0372584135025
At time: 60.567957639694214 and batch: 550, loss is 5.077854232788086 and perplexity is 160.42944209362912
At time: 61.62965965270996 and batch: 600, loss is 5.0715693092346195 and perplexity is 159.42431718949356
At time: 62.691105365753174 and batch: 650, loss is 5.142312250137329 and perplexity is 171.11096259800283
At time: 63.76284337043762 and batch: 700, loss is 5.115005016326904 and perplexity is 166.50161620776075
At time: 64.82477498054504 and batch: 750, loss is 5.056757211685181 and perplexity is 157.08031132899993
At time: 65.88657259941101 and batch: 800, loss is 5.0376330089569095 and perplexity is 154.1048182631374
At time: 66.94740176200867 and batch: 850, loss is 5.0270441627502445 and perplexity is 152.48163502807293
At time: 68.01006555557251 and batch: 900, loss is 5.031422853469849 and perplexity is 153.1507688441914
At time: 69.07224631309509 and batch: 950, loss is 5.080046243667603 and perplexity is 160.78149088251726
At time: 70.13307070732117 and batch: 1000, loss is 5.04108998298645 and perplexity is 154.63847650758163
At time: 71.19538235664368 and batch: 1050, loss is 4.951452684402466 and perplexity is 141.3801956219378
At time: 72.25601625442505 and batch: 1100, loss is 5.026048431396484 and perplexity is 152.3298798494361
At time: 73.34526443481445 and batch: 1150, loss is 4.927215642929077 and perplexity is 137.99475027237474
At time: 74.40762782096863 and batch: 1200, loss is 5.003411664962768 and perplexity is 148.92035978493752
At time: 75.46838688850403 and batch: 1250, loss is 4.9513568019866945 and perplexity is 141.36664039710354
At time: 76.52965235710144 and batch: 1300, loss is 4.97480224609375 and perplexity is 144.720203332714
At time: 77.5906674861908 and batch: 1350, loss is 4.887853670120239 and perplexity is 132.66851784443404
At time: 78.65277624130249 and batch: 1400, loss is 4.899509372711182 and perplexity is 134.22390961456105
At time: 79.7133800983429 and batch: 1450, loss is 4.846170396804809 and perplexity is 127.25213035769656
At time: 80.7805163860321 and batch: 1500, loss is 4.818205308914185 and perplexity is 123.74281125764955
At time: 81.8483235836029 and batch: 1550, loss is 4.813011932373047 and perplexity is 123.10183410304613
At time: 82.91120171546936 and batch: 1600, loss is 4.8692710590362545 and perplexity is 130.2259552566196
At time: 83.99971175193787 and batch: 1650, loss is 4.831073360443115 and perplexity is 125.34542930072907
At time: 85.06892013549805 and batch: 1700, loss is 4.856930379867554 and perplexity is 128.62875406716066
At time: 86.13558840751648 and batch: 1750, loss is 4.852573671340942 and perplexity is 128.06957505201737
At time: 87.2109694480896 and batch: 1800, loss is 4.81985071182251 and perplexity is 123.94658563868278
At time: 88.28729772567749 and batch: 1850, loss is 4.816423244476319 and perplexity is 123.52248996594233
At time: 89.3530170917511 and batch: 1900, loss is 4.886955804824829 and perplexity is 132.5494528466316
At time: 90.41711711883545 and batch: 1950, loss is 4.807263040542603 and perplexity is 122.39616532490938
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.631667594022529 and perplexity of 102.68515856942852
finished 2 epochs...
Completing Train Step...
At time: 93.80832409858704 and batch: 50, loss is 4.779926929473877 and perplexity is 119.09564734525183
At time: 94.83037114143372 and batch: 100, loss is 4.735717258453369 and perplexity is 113.94515754258923
At time: 95.85513067245483 and batch: 150, loss is 4.676745262145996 and perplexity is 107.41987943923755
At time: 96.88790035247803 and batch: 200, loss is 4.665287923812866 and perplexity is 106.19615722305981
At time: 97.91862916946411 and batch: 250, loss is 4.66911054611206 and perplexity is 106.60288190389677
At time: 98.94889330863953 and batch: 300, loss is 4.690712738037109 and perplexity is 108.93079126415816
At time: 99.98136162757874 and batch: 350, loss is 4.699512767791748 and perplexity is 109.89361569684615
At time: 101.02183699607849 and batch: 400, loss is 4.660484790802002 and perplexity is 105.68730597306286
At time: 102.06759667396545 and batch: 450, loss is 4.643504047393799 and perplexity is 103.90780830447794
At time: 103.11209797859192 and batch: 500, loss is 4.647167854309082 and perplexity is 104.28920470584329
At time: 104.15747570991516 and batch: 550, loss is 4.608101167678833 and perplexity is 100.29352812171624
At time: 105.20242142677307 and batch: 600, loss is 4.589780550003052 and perplexity is 98.47281793103664
At time: 106.24906301498413 and batch: 650, loss is 4.660840806961059 and perplexity is 105.7249390603926
At time: 107.2954204082489 and batch: 700, loss is 4.6739469909667966 and perplexity is 107.11970966061864
At time: 108.34843277931213 and batch: 750, loss is 4.62895281791687 and perplexity is 102.40676940763822
At time: 109.45770907402039 and batch: 800, loss is 4.609097814559936 and perplexity is 100.39353518129745
At time: 110.5087251663208 and batch: 850, loss is 4.603452529907226 and perplexity is 99.82838182460914
At time: 111.56101298332214 and batch: 900, loss is 4.595723686218261 and perplexity is 99.0597978245086
At time: 112.61283707618713 and batch: 950, loss is 4.661490240097046 and perplexity is 105.79362263940064
At time: 113.6704933643341 and batch: 1000, loss is 4.638740367889405 and perplexity is 103.41400190922741
At time: 114.73193788528442 and batch: 1050, loss is 4.563502445220947 and perplexity is 95.91884268438373
At time: 115.79298400878906 and batch: 1100, loss is 4.625773830413818 and perplexity is 102.08173647900334
At time: 116.85515928268433 and batch: 1150, loss is 4.559473600387573 and perplexity is 95.53317796393227
At time: 117.94445371627808 and batch: 1200, loss is 4.640280466079712 and perplexity is 103.57339233336731
At time: 119.0340645313263 and batch: 1250, loss is 4.605428419113159 and perplexity is 100.02582664701114
At time: 120.11452007293701 and batch: 1300, loss is 4.626147403717041 and perplexity is 102.11987861449667
At time: 121.1991605758667 and batch: 1350, loss is 4.507140760421753 and perplexity is 90.66222254889712
At time: 122.26395463943481 and batch: 1400, loss is 4.5282565879821775 and perplexity is 92.59698557922755
At time: 123.3373351097107 and batch: 1450, loss is 4.474511632919311 and perplexity is 87.75173488496003
At time: 124.41275930404663 and batch: 1500, loss is 4.463126239776611 and perplexity is 86.75831286564845
At time: 125.4793336391449 and batch: 1550, loss is 4.468347978591919 and perplexity is 87.21252697714715
At time: 126.54642248153687 and batch: 1600, loss is 4.537058010101318 and perplexity is 93.41556779579933
At time: 127.61284399032593 and batch: 1650, loss is 4.494946508407593 and perplexity is 89.5633779692981
At time: 128.69844913482666 and batch: 1700, loss is 4.522497997283936 and perplexity is 92.0652898178311
At time: 129.76553106307983 and batch: 1750, loss is 4.520206727981567 and perplexity is 91.85458492846217
At time: 130.8299310207367 and batch: 1800, loss is 4.484983997344971 and perplexity is 88.67553175766206
At time: 131.8907494544983 and batch: 1850, loss is 4.51188666343689 and perplexity is 91.09351930099992
At time: 132.95204973220825 and batch: 1900, loss is 4.597116346359253 and perplexity is 99.19785056447485
At time: 134.0121614933014 and batch: 1950, loss is 4.52796441078186 and perplexity is 92.5699348032256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488404171965843 and perplexity of 88.97933679786715
finished 3 epochs...
Completing Train Step...
At time: 137.36610579490662 and batch: 50, loss is 4.501441850662231 and perplexity is 90.14701617569443
At time: 138.42088842391968 and batch: 100, loss is 4.458937959671021 and perplexity is 86.39570463236676
At time: 139.46191883087158 and batch: 150, loss is 4.411523790359497 and perplexity is 82.39492048036048
At time: 140.5040946006775 and batch: 200, loss is 4.411850500106811 and perplexity is 82.42184410187593
At time: 141.5447690486908 and batch: 250, loss is 4.402999668121338 and perplexity is 81.695561053658
At time: 142.58500695228577 and batch: 300, loss is 4.429614200592041 and perplexity is 83.89904246473817
At time: 143.62784266471863 and batch: 350, loss is 4.445161933898926 and perplexity is 85.21367570286971
At time: 144.67744660377502 and batch: 400, loss is 4.402366981506348 and perplexity is 81.6438897132816
At time: 145.7279019355774 and batch: 450, loss is 4.4107685470581055 and perplexity is 82.33271576140444
At time: 146.78830981254578 and batch: 500, loss is 4.419253463745117 and perplexity is 83.0342741183771
At time: 147.8508858680725 and batch: 550, loss is 4.380063076019287 and perplexity is 79.8430694292439
At time: 148.92716717720032 and batch: 600, loss is 4.3633748722076415 and perplexity is 78.5216884179602
At time: 150.00264859199524 and batch: 650, loss is 4.430526142120361 and perplexity is 83.97558838314414
At time: 151.07702827453613 and batch: 700, loss is 4.452408246994018 and perplexity is 85.83340333545249
At time: 152.15203046798706 and batch: 750, loss is 4.41235273361206 and perplexity is 82.46324951026966
At time: 153.22815775871277 and batch: 800, loss is 4.3923767471313475 and perplexity is 80.83230881143119
At time: 154.3045129776001 and batch: 850, loss is 4.384250478744507 and perplexity is 80.17810549166936
At time: 155.3804726600647 and batch: 900, loss is 4.366487483978272 and perplexity is 78.76647671741792
At time: 156.46386981010437 and batch: 950, loss is 4.454856662750244 and perplexity is 86.04381667714566
At time: 157.55671215057373 and batch: 1000, loss is 4.428335514068603 and perplexity is 83.7918304496966
At time: 158.6327781677246 and batch: 1050, loss is 4.361049861907959 and perplexity is 78.33933675053687
At time: 159.70823526382446 and batch: 1100, loss is 4.412481632232666 and perplexity is 82.47387959446907
At time: 160.78362655639648 and batch: 1150, loss is 4.3631155395507815 and perplexity is 78.50132782007972
At time: 161.99949979782104 and batch: 1200, loss is 4.442833671569824 and perplexity is 85.01550669604273
At time: 163.06776309013367 and batch: 1250, loss is 4.412845420837402 and perplexity is 82.503888110101
At time: 164.13210558891296 and batch: 1300, loss is 4.423617401123047 and perplexity is 83.39742229248245
At time: 165.19594168663025 and batch: 1350, loss is 4.305587944984436 and perplexity is 74.11277688118196
At time: 166.2630558013916 and batch: 1400, loss is 4.332654495239257 and perplexity is 76.1461481180621
At time: 167.33048343658447 and batch: 1450, loss is 4.271277227401733 and perplexity is 71.61304337386717
At time: 168.39787220954895 and batch: 1500, loss is 4.265622344017029 and perplexity is 71.20922281993856
At time: 169.4645025730133 and batch: 1550, loss is 4.2745715999603275 and perplexity is 71.8493524501439
At time: 170.5296757221222 and batch: 1600, loss is 4.352424144744873 and perplexity is 77.66650976829739
At time: 171.59495878219604 and batch: 1650, loss is 4.309853234291077 and perplexity is 74.42956443090482
At time: 172.66079926490784 and batch: 1700, loss is 4.3385526561737064 and perplexity is 76.59659745969248
At time: 173.72846627235413 and batch: 1750, loss is 4.336334924697876 and perplexity is 76.42691499917765
At time: 174.7952585220337 and batch: 1800, loss is 4.29700478553772 and perplexity is 73.47937727365834
At time: 175.86140084266663 and batch: 1850, loss is 4.324622383117676 and perplexity is 75.53698343328485
At time: 176.92763090133667 and batch: 1900, loss is 4.419041481018066 and perplexity is 83.01667415202112
At time: 177.99298906326294 and batch: 1950, loss is 4.355132884979248 and perplexity is 77.87717335583
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.424130745821221 and perplexity of 83.44024490749845
finished 4 epochs...
Completing Train Step...
At time: 181.39019227027893 and batch: 50, loss is 4.327141313552857 and perplexity is 75.72749568265479
At time: 182.45407819747925 and batch: 100, loss is 4.28603874206543 and perplexity is 72.67800122118736
At time: 183.5138909816742 and batch: 150, loss is 4.2479015064239505 and perplexity is 69.95845084204963
At time: 184.58045864105225 and batch: 200, loss is 4.252307920455933 and perplexity is 70.26739691376149
At time: 185.64422750473022 and batch: 250, loss is 4.236922001838684 and perplexity is 69.1945430488547
At time: 186.70919036865234 and batch: 300, loss is 4.2658913040161135 and perplexity is 71.22837782829309
At time: 187.77353143692017 and batch: 350, loss is 4.276941986083984 and perplexity is 72.01986516883784
At time: 188.8729691505432 and batch: 400, loss is 4.238286600112915 and perplexity is 69.28903025676355
At time: 189.94636392593384 and batch: 450, loss is 4.257770156860351 and perplexity is 70.6522642083926
At time: 191.0183765888214 and batch: 500, loss is 4.269960355758667 and perplexity is 71.51880025443953
At time: 192.09760928153992 and batch: 550, loss is 4.229739289283753 and perplexity is 68.69931919018276
At time: 193.1770215034485 and batch: 600, loss is 4.216309270858765 and perplexity is 67.78285391528203
At time: 194.27860188484192 and batch: 650, loss is 4.281889600753784 and perplexity is 72.37707464902233
At time: 195.36014819145203 and batch: 700, loss is 4.3067255783081055 and perplexity is 74.19713802279625
At time: 196.43941521644592 and batch: 750, loss is 4.269941997528076 and perplexity is 71.51748730786461
At time: 197.5160734653473 and batch: 800, loss is 4.245262923240662 and perplexity is 69.77410296568645
At time: 198.59203696250916 and batch: 850, loss is 4.237215166091919 and perplexity is 69.21483138915832
At time: 199.66804480552673 and batch: 900, loss is 4.2195055103302 and perplexity is 67.99985075064214
At time: 200.74488592147827 and batch: 950, loss is 4.31432936668396 and perplexity is 74.76346775548542
At time: 201.82161951065063 and batch: 1000, loss is 4.289502239227295 and perplexity is 72.93015769168846
At time: 202.89823532104492 and batch: 1050, loss is 4.225406265258789 and perplexity is 68.40228737735688
At time: 203.97507190704346 and batch: 1100, loss is 4.270519347190857 and perplexity is 71.55878982689512
At time: 205.05195784568787 and batch: 1150, loss is 4.223884887695313 and perplexity is 68.29830079353549
At time: 206.12375664710999 and batch: 1200, loss is 4.302366633415222 and perplexity is 73.8744206515436
At time: 207.2010145187378 and batch: 1250, loss is 4.277208471298218 and perplexity is 72.03905995548628
At time: 208.27650833129883 and batch: 1300, loss is 4.290951290130615 and perplexity is 73.03591380706308
At time: 209.35267543792725 and batch: 1350, loss is 4.167887225151062 and perplexity is 64.57886726517003
At time: 210.42861437797546 and batch: 1400, loss is 4.2019709205627445 and perplexity is 66.81789410961801
At time: 211.50209641456604 and batch: 1450, loss is 4.13675847530365 and perplexity is 62.59957414601809
At time: 212.57654452323914 and batch: 1500, loss is 4.130498919487 and perplexity is 62.20895245214591
At time: 213.65289568901062 and batch: 1550, loss is 4.1415113258361815 and perplexity is 62.897808736133285
At time: 214.72860765457153 and batch: 1600, loss is 4.226522536277771 and perplexity is 68.47868550096088
At time: 215.8053801059723 and batch: 1650, loss is 4.1736502981185915 and perplexity is 64.95211448179708
At time: 216.8819944858551 and batch: 1700, loss is 4.214061865806579 and perplexity is 67.63068943859453
At time: 217.95883297920227 and batch: 1750, loss is 4.206829876899719 and perplexity is 67.14334938579526
At time: 219.03498816490173 and batch: 1800, loss is 4.161772546768188 and perplexity is 64.1851930836163
At time: 220.11165046691895 and batch: 1850, loss is 4.194904780387878 and perplexity is 66.34741370150883
At time: 221.18809247016907 and batch: 1900, loss is 4.290869970321655 and perplexity is 73.0299747819885
At time: 222.26386547088623 and batch: 1950, loss is 4.229397883415222 and perplexity is 68.67586884271809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380991949037064 and perplexity of 79.91726795726365
finished 5 epochs...
Completing Train Step...
At time: 225.73939323425293 and batch: 50, loss is 4.207558541297913 and perplexity is 67.19229218333972
At time: 226.81572008132935 and batch: 100, loss is 4.165087113380432 and perplexity is 64.39829215204192
At time: 227.85882329940796 and batch: 150, loss is 4.136040558815003 and perplexity is 62.55464900773467
At time: 228.93121910095215 and batch: 200, loss is 4.140631351470947 and perplexity is 62.84248462228712
At time: 229.9888801574707 and batch: 250, loss is 4.119291863441467 and perplexity is 61.5156653454912
At time: 231.08799529075623 and batch: 300, loss is 4.144452776908874 and perplexity is 63.08309193024401
At time: 232.13179850578308 and batch: 350, loss is 4.154717121124268 and perplexity is 63.73393301424612
At time: 233.174813747406 and batch: 400, loss is 4.120277609825134 and perplexity is 61.57633408722813
At time: 234.21862626075745 and batch: 450, loss is 4.145309038162232 and perplexity is 63.13713066994366
At time: 235.27243566513062 and batch: 500, loss is 4.163302726745606 and perplexity is 64.28348316249642
At time: 236.33627915382385 and batch: 550, loss is 4.120751509666443 and perplexity is 61.60552201771199
At time: 237.4008390903473 and batch: 600, loss is 4.110955929756164 and perplexity is 61.00500620596983
At time: 238.46702075004578 and batch: 650, loss is 4.169779601097107 and perplexity is 64.70119046444132
At time: 239.53040838241577 and batch: 700, loss is 4.199244379997253 and perplexity is 66.63596054815342
At time: 240.59488487243652 and batch: 750, loss is 4.163969402313232 and perplexity is 64.32635367889789
At time: 241.65957045555115 and batch: 800, loss is 4.135516982078553 and perplexity is 62.52190542139547
At time: 242.78078866004944 and batch: 850, loss is 4.132068548202515 and perplexity is 62.306674083552956
At time: 243.84913063049316 and batch: 900, loss is 4.1112424087524415 and perplexity is 61.02248536250167
At time: 244.91242480278015 and batch: 950, loss is 4.213244614601135 and perplexity is 67.57544075522739
At time: 245.97489380836487 and batch: 1000, loss is 4.185265331268311 and perplexity is 65.71093376929387
At time: 247.0355761051178 and batch: 1050, loss is 4.123396463394165 and perplexity is 61.768681452279424
At time: 248.09810495376587 and batch: 1100, loss is 4.166507430076599 and perplexity is 64.48982310767528
At time: 249.16428780555725 and batch: 1150, loss is 4.120357303619385 and perplexity is 61.58124153447155
At time: 250.22889471054077 and batch: 1200, loss is 4.20069085597992 and perplexity is 66.7324176092613
At time: 251.29215598106384 and batch: 1250, loss is 4.178350133895874 and perplexity is 65.25809722434545
At time: 252.35563230514526 and batch: 1300, loss is 4.189328498840332 and perplexity is 65.97847146167827
At time: 253.41975212097168 and batch: 1350, loss is 4.069964838027954 and perplexity is 58.55490364980907
At time: 254.48422837257385 and batch: 1400, loss is 4.1019466638565065 and perplexity is 60.457864258307346
At time: 255.54798650741577 and batch: 1450, loss is 4.035323729515076 and perplexity is 56.56122781366406
At time: 256.6141812801361 and batch: 1500, loss is 4.032568945884704 and perplexity is 56.405628289082415
At time: 257.679221868515 and batch: 1550, loss is 4.04298617362976 and perplexity is 56.99628975108614
At time: 258.74341583251953 and batch: 1600, loss is 4.133922786712646 and perplexity is 62.42231269572848
At time: 259.80814385414124 and batch: 1650, loss is 4.077311148643494 and perplexity is 58.98665009009634
At time: 260.8721766471863 and batch: 1700, loss is 4.116861414909363 and perplexity is 61.36633622882528
At time: 261.9365372657776 and batch: 1750, loss is 4.109596700668335 and perplexity is 60.92214275499544
At time: 263.00198006629944 and batch: 1800, loss is 4.0613609790802006 and perplexity is 58.053266619759235
At time: 264.06549525260925 and batch: 1850, loss is 4.098469076156616 and perplexity is 60.247981886897314
At time: 265.12900400161743 and batch: 1900, loss is 4.189834327697754 and perplexity is 66.0118537186548
At time: 266.1934087276459 and batch: 1950, loss is 4.128905844688416 and perplexity is 62.109927835501466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369391011082849 and perplexity of 78.99550965827018
finished 6 epochs...
Completing Train Step...
At time: 269.58728408813477 and batch: 50, loss is 4.112572884559631 and perplexity is 61.10372833689256
At time: 270.62214612960815 and batch: 100, loss is 4.0724572706222535 and perplexity is 58.70102982940103
At time: 271.65743374824524 and batch: 150, loss is 4.0459932565689085 and perplexity is 57.167940275927265
At time: 272.69988489151 and batch: 200, loss is 4.049335465431214 and perplexity is 57.359327121808455
At time: 273.74118208885193 and batch: 250, loss is 4.027883901596069 and perplexity is 56.1419834984223
At time: 274.7841475009918 and batch: 300, loss is 4.053200507164002 and perplexity is 57.58145229992165
At time: 275.82921504974365 and batch: 350, loss is 4.05838065624237 and perplexity is 57.88050671146756
At time: 276.8731806278229 and batch: 400, loss is 4.0295525074005125 and perplexity is 56.23574053797739
At time: 277.918479681015 and batch: 450, loss is 4.060977725982666 and perplexity is 58.03102178847775
At time: 278.97281646728516 and batch: 500, loss is 4.078953104019165 and perplexity is 59.0835830953614
At time: 280.0301492214203 and batch: 550, loss is 4.038476700782776 and perplexity is 56.73984517956471
At time: 281.090660572052 and batch: 600, loss is 4.025795545578003 and perplexity is 56.02486138821542
At time: 282.152316570282 and batch: 650, loss is 4.087527756690979 and perplexity is 59.592382570962904
At time: 283.2179214954376 and batch: 700, loss is 4.109266219139099 and perplexity is 60.90201243862552
At time: 284.3116593360901 and batch: 750, loss is 4.079417061805725 and perplexity is 59.111001743852256
At time: 285.37591552734375 and batch: 800, loss is 4.052659001350403 and perplexity is 57.5502800494849
At time: 286.44197845458984 and batch: 850, loss is 4.0493248462677 and perplexity is 57.3587180169688
At time: 287.5073916912079 and batch: 900, loss is 4.02466392993927 and perplexity is 55.96149863681249
At time: 288.568861246109 and batch: 950, loss is 4.12859676361084 and perplexity is 62.09073379848756
At time: 289.6331057548523 and batch: 1000, loss is 4.102448129653931 and perplexity is 60.48818941229651
At time: 290.6988580226898 and batch: 1050, loss is 4.047743911743164 and perplexity is 57.26810928148369
At time: 291.76347184181213 and batch: 1100, loss is 4.0834650135040285 and perplexity is 59.35076517174211
At time: 292.8287777900696 and batch: 1150, loss is 4.036472287178039 and perplexity is 56.62622896693671
At time: 293.8919196128845 and batch: 1200, loss is 4.119857544898987 and perplexity is 61.550473460948666
At time: 294.95345163345337 and batch: 1250, loss is 4.100556764602661 and perplexity is 60.37389228769353
At time: 296.0144000053406 and batch: 1300, loss is 4.1086906147003175 and perplexity is 60.86696705704134
At time: 297.07668590545654 and batch: 1350, loss is 3.9874111127853396 and perplexity is 53.91512834218481
At time: 298.13898253440857 and batch: 1400, loss is 4.0261484718322755 and perplexity is 56.0446375222445
At time: 299.2007830142975 and batch: 1450, loss is 3.957885727882385 and perplexity is 52.34653405086222
At time: 300.2628903388977 and batch: 1500, loss is 3.9546645641326905 and perplexity is 52.17818857269251
At time: 301.32406973838806 and batch: 1550, loss is 3.964399046897888 and perplexity is 52.688596498127836
At time: 302.38515639305115 and batch: 1600, loss is 4.056235566139221 and perplexity is 57.756480880204926
At time: 303.44997358322144 and batch: 1650, loss is 4.00163724899292 and perplexity is 54.68761401672518
At time: 304.51890897750854 and batch: 1700, loss is 4.043528394699097 and perplexity is 57.02720272033743
At time: 305.58387517929077 and batch: 1750, loss is 4.032036094665528 and perplexity is 56.375580487494965
At time: 306.6483714580536 and batch: 1800, loss is 3.984463691711426 and perplexity is 53.756451714996224
At time: 307.7137613296509 and batch: 1850, loss is 4.023824572563171 and perplexity is 55.914546647659925
At time: 308.77727603912354 and batch: 1900, loss is 4.113449740409851 and perplexity is 61.15733099602315
At time: 309.8417522907257 and batch: 1950, loss is 4.050594973564148 and perplexity is 57.431617176217216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.366479776071948 and perplexity of 78.76586959513374
finished 7 epochs...
Completing Train Step...
At time: 313.30402851104736 and batch: 50, loss is 4.033128433227539 and perplexity is 56.43719535403799
At time: 314.3318862915039 and batch: 100, loss is 3.9969733572006225 and perplexity is 54.43315075837775
At time: 315.3628249168396 and batch: 150, loss is 3.9729995679855348 and perplexity is 53.14370014234113
At time: 316.4242286682129 and batch: 200, loss is 3.9783022832870483 and perplexity is 53.426254544951746
At time: 317.4542968273163 and batch: 250, loss is 3.949291272163391 and perplexity is 51.898571835011566
At time: 318.48866748809814 and batch: 300, loss is 3.981828761100769 and perplexity is 53.614993642798
At time: 319.52605867385864 and batch: 350, loss is 3.982370963096619 and perplexity is 53.64407168173159
At time: 320.5672998428345 and batch: 400, loss is 3.9562691164016726 and perplexity is 52.26197840816649
At time: 321.6373407840729 and batch: 450, loss is 3.9956267976760866 and perplexity is 54.35990260833854
At time: 322.6888449192047 and batch: 500, loss is 4.011985397338867 and perplexity is 55.25646777453207
At time: 323.74197936058044 and batch: 550, loss is 3.971477484703064 and perplexity is 53.06287253356657
At time: 324.79973316192627 and batch: 600, loss is 3.9606752729415895 and perplexity is 52.49276092469421
At time: 325.86110830307007 and batch: 650, loss is 4.015974369049072 and perplexity is 55.47732446397969
At time: 326.92573261260986 and batch: 700, loss is 4.037811307907105 and perplexity is 56.702103448747444
At time: 327.9904775619507 and batch: 750, loss is 4.013258457183838 and perplexity is 55.32685736040181
At time: 329.052987575531 and batch: 800, loss is 3.980123963356018 and perplexity is 53.52366878987094
At time: 330.1151270866394 and batch: 850, loss is 3.9814734983444215 and perplexity is 53.59594961539202
At time: 331.1801199913025 and batch: 900, loss is 3.9590957164764404 and perplexity is 52.409911095019986
At time: 332.2458963394165 and batch: 950, loss is 4.060601582527161 and perplexity is 58.009197904128676
At time: 333.3098740577698 and batch: 1000, loss is 4.035432691574097 and perplexity is 56.56739117728768
At time: 334.3741648197174 and batch: 1050, loss is 3.981864123344421 and perplexity is 53.61688962278945
At time: 335.4389991760254 and batch: 1100, loss is 4.022412691116333 and perplexity is 55.8356576407072
At time: 336.5044493675232 and batch: 1150, loss is 3.9732527494430543 and perplexity is 53.15715684522309
At time: 337.5680809020996 and batch: 1200, loss is 4.052563009262085 and perplexity is 57.54475594305915
At time: 338.6319999694824 and batch: 1250, loss is 4.03580011844635 and perplexity is 56.588179375736956
At time: 339.6961839199066 and batch: 1300, loss is 4.039886517524719 and perplexity is 56.819894377325014
At time: 340.7610909938812 and batch: 1350, loss is 3.9234868478775025 and perplexity is 50.5764902054125
At time: 341.82501125335693 and batch: 1400, loss is 3.962249436378479 and perplexity is 52.57545818206577
At time: 342.8900363445282 and batch: 1450, loss is 3.8915073251724244 and perplexity is 48.98466672560322
At time: 343.95442485809326 and batch: 1500, loss is 3.8911609983444215 and perplexity is 48.96770495868237
At time: 345.018506526947 and batch: 1550, loss is 3.900881643295288 and perplexity is 49.446023649334556
At time: 346.08362674713135 and batch: 1600, loss is 3.9939559936523437 and perplexity is 54.26915369726425
At time: 347.14657068252563 and batch: 1650, loss is 3.938128786087036 and perplexity is 51.32247606187828
At time: 348.2119903564453 and batch: 1700, loss is 3.9803517866134643 and perplexity is 53.535864115581795
At time: 349.2770619392395 and batch: 1750, loss is 3.9701206064224244 and perplexity is 52.990921499754144
At time: 350.34075236320496 and batch: 1800, loss is 3.9215976572036744 and perplexity is 50.48103176978589
At time: 351.40572476387024 and batch: 1850, loss is 3.9615800857543944 and perplexity is 52.54027854139075
At time: 352.46980595588684 and batch: 1900, loss is 4.050615940093994 and perplexity is 57.4328213305563
At time: 353.53479051589966 and batch: 1950, loss is 3.9897837162017824 and perplexity is 54.043199430759934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362904819222384 and perplexity of 78.48478773722886
finished 8 epochs...
Completing Train Step...
At time: 356.91812205314636 and batch: 50, loss is 3.971551942825317 and perplexity is 53.06682364251103
At time: 357.94787979125977 and batch: 100, loss is 3.93484158039093 and perplexity is 51.15404551083057
At time: 358.97955536842346 and batch: 150, loss is 3.913687448501587 and perplexity is 50.08329145138269
At time: 360.009094953537 and batch: 200, loss is 3.9175017070770264 and perplexity is 50.27468685903078
At time: 361.0382900238037 and batch: 250, loss is 3.8896995210647582 and perplexity is 48.89619204042941
At time: 362.0674238204956 and batch: 300, loss is 3.9161926984786986 and perplexity is 50.20891991579215
At time: 363.1031217575073 and batch: 350, loss is 3.921380777359009 and perplexity is 50.470084638606075
At time: 364.14279556274414 and batch: 400, loss is 3.900131468772888 and perplexity is 49.408944411847365
At time: 365.1749587059021 and batch: 450, loss is 3.9334097623825075 and perplexity is 51.08085463777362
At time: 366.2156352996826 and batch: 500, loss is 3.9532453632354736 and perplexity is 52.10418976266406
At time: 367.2587127685547 and batch: 550, loss is 3.91461462020874 and perplexity is 50.12974879585714
At time: 368.30170011520386 and batch: 600, loss is 3.904296803474426 and perplexity is 49.61517842123021
At time: 369.3464095592499 and batch: 650, loss is 3.9594615745544433 and perplexity is 52.429089192378505
At time: 370.3830142021179 and batch: 700, loss is 3.9848170948028563 and perplexity is 53.775452768534414
At time: 371.42160153388977 and batch: 750, loss is 3.9573856019973754 and perplexity is 52.32036073971359
At time: 372.46922969818115 and batch: 800, loss is 3.924883451461792 and perplexity is 50.64717486064637
At time: 373.5177433490753 and batch: 850, loss is 3.92487154006958 and perplexity is 50.64657158587512
At time: 374.58165645599365 and batch: 900, loss is 3.8970830917358397 and perplexity is 49.25855665602602
At time: 375.6276626586914 and batch: 950, loss is 4.001797013282776 and perplexity is 54.69635184252012
At time: 376.67664098739624 and batch: 1000, loss is 3.9778072690963744 and perplexity is 53.39981433547679
At time: 377.7280218601227 and batch: 1050, loss is 3.9227317142486573 and perplexity is 50.538312613235455
At time: 378.7857315540314 and batch: 1100, loss is 3.963223614692688 and perplexity is 52.6267010090592
At time: 379.8428897857666 and batch: 1150, loss is 3.9191311740875245 and perplexity is 50.35667458273532
At time: 380.8993513584137 and batch: 1200, loss is 3.9974986600875853 and perplexity is 54.46175216115963
At time: 381.95517587661743 and batch: 1250, loss is 3.9802738332748415 and perplexity is 53.531690978895014
At time: 383.01253390312195 and batch: 1300, loss is 3.983558187484741 and perplexity is 53.707797052582436
At time: 384.0703799724579 and batch: 1350, loss is 3.867800030708313 and perplexity is 47.83703023597526
At time: 385.1282150745392 and batch: 1400, loss is 3.9081874322891235 and perplexity is 49.80858866380288
At time: 386.18511843681335 and batch: 1450, loss is 3.8373691987991334 and perplexity is 46.40323602874358
At time: 387.2452311515808 and batch: 1500, loss is 3.842546334266663 and perplexity is 46.644094809090795
At time: 388.3024203777313 and batch: 1550, loss is 3.847533025741577 and perplexity is 46.877275435741765
At time: 389.3604621887207 and batch: 1600, loss is 3.942714114189148 and perplexity is 51.55834681275634
At time: 390.4184968471527 and batch: 1650, loss is 3.887217788696289 and perplexity is 48.77499522917672
At time: 391.4758448600769 and batch: 1700, loss is 3.9279824781417845 and perplexity is 50.80437526511729
At time: 392.5325028896332 and batch: 1750, loss is 3.916863865852356 and perplexity is 50.24262981593334
At time: 393.5909764766693 and batch: 1800, loss is 3.867496509552002 and perplexity is 47.822512888516044
At time: 394.6469786167145 and batch: 1850, loss is 3.9107128763198853 and perplexity is 49.934536436810475
At time: 395.70366883277893 and batch: 1900, loss is 3.9961238431930544 and perplexity is 54.386928670267864
At time: 396.7604205608368 and batch: 1950, loss is 3.9348369026184082 and perplexity is 51.15380622440177
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363233557412791 and perplexity of 78.51059292566715
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 400.09749841690063 and batch: 50, loss is 3.947770562171936 and perplexity is 51.81970913712401
At time: 401.14353251457214 and batch: 100, loss is 3.929940071105957 and perplexity is 50.90392696174431
At time: 402.1762478351593 and batch: 150, loss is 3.9119688367843626 and perplexity is 49.99729164116555
At time: 403.20887541770935 and batch: 200, loss is 3.9154650926589967 and perplexity is 50.17240090079552
At time: 404.24384236335754 and batch: 250, loss is 3.895425281524658 and perplexity is 49.17696296992382
At time: 405.2844669818878 and batch: 300, loss is 3.911054368019104 and perplexity is 49.95159157843689
At time: 406.32472681999207 and batch: 350, loss is 3.9148266649246217 and perplexity is 50.14037967126842
At time: 407.36672854423523 and batch: 400, loss is 3.8969070720672607 and perplexity is 49.24988694425103
At time: 408.4427282810211 and batch: 450, loss is 3.9215658617019655 and perplexity is 50.479426725570725
At time: 409.49050736427307 and batch: 500, loss is 3.9323851966857912 and perplexity is 51.02854574787579
At time: 410.53698229789734 and batch: 550, loss is 3.8918421840667725 and perplexity is 49.00107242358661
At time: 411.5785918235779 and batch: 600, loss is 3.862191319465637 and perplexity is 47.569477162023496
At time: 412.6226387023926 and batch: 650, loss is 3.9091000032424925 and perplexity is 49.854063281297414
At time: 413.70547699928284 and batch: 700, loss is 3.924763388633728 and perplexity is 50.64109438262615
At time: 414.7885112762451 and batch: 750, loss is 3.8904591846466063 and perplexity is 48.93335080910824
At time: 415.83897137641907 and batch: 800, loss is 3.8531259155273436 and perplexity is 47.14018940981309
At time: 416.8865716457367 and batch: 850, loss is 3.8472125911712647 and perplexity is 46.862256742512855
At time: 417.93280005455017 and batch: 900, loss is 3.812596125602722 and perplexity is 45.267807362391835
At time: 418.9802312850952 and batch: 950, loss is 3.9213022136688234 and perplexity is 50.46611967826589
At time: 420.02782797813416 and batch: 1000, loss is 3.8818653631210327 and perplexity is 48.51462811666781
At time: 421.0858974456787 and batch: 1050, loss is 3.8314836025238037 and perplexity is 46.13092745085461
At time: 422.1608188152313 and batch: 1100, loss is 3.8595836639404295 and perplexity is 47.445593944647946
At time: 423.22607612609863 and batch: 1150, loss is 3.8190877866744994 and perplexity is 45.562626522938096
At time: 424.2868478298187 and batch: 1200, loss is 3.882189350128174 and perplexity is 48.530348772340474
At time: 425.35330724716187 and batch: 1250, loss is 3.8549090909957884 and perplexity is 47.22432362989159
At time: 426.4304039478302 and batch: 1300, loss is 3.852331666946411 and perplexity is 47.10276324607563
At time: 427.4784481525421 and batch: 1350, loss is 3.732444791793823 and perplexity is 41.78112956536976
At time: 428.52644538879395 and batch: 1400, loss is 3.7632808589935305 and perplexity is 43.08956511058622
At time: 429.57576298713684 and batch: 1450, loss is 3.6840895509719847 and perplexity is 39.808862006003444
At time: 430.6254868507385 and batch: 1500, loss is 3.6878257513046266 and perplexity is 39.95787408562244
At time: 431.67583894729614 and batch: 1550, loss is 3.6932008600234987 and perplexity is 40.17323026594698
At time: 432.7259647846222 and batch: 1600, loss is 3.7822775936126707 and perplexity is 43.91595060507573
At time: 433.7770321369171 and batch: 1650, loss is 3.710970335006714 and perplexity is 40.89346764479452
At time: 434.8264193534851 and batch: 1700, loss is 3.7398350858688354 and perplexity is 42.09104818395618
At time: 435.9080665111542 and batch: 1750, loss is 3.7215822982788085 and perplexity is 41.32973837180916
At time: 436.9618697166443 and batch: 1800, loss is 3.6690372705459593 and perplexity is 39.21413507884477
At time: 438.01227712631226 and batch: 1850, loss is 3.7010307836532594 and perplexity is 40.489018275537774
At time: 439.06252002716064 and batch: 1900, loss is 3.7841400051116945 and perplexity is 43.99781638669658
At time: 440.1131386756897 and batch: 1950, loss is 3.716482515335083 and perplexity is 41.11950221203076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3003812568132265 and perplexity of 73.72789760513946
finished 10 epochs...
Completing Train Step...
At time: 443.43000745773315 and batch: 50, loss is 3.8648980808258058 and perplexity is 47.69841080230689
At time: 444.48968029022217 and batch: 100, loss is 3.834683518409729 and perplexity is 46.2787789684871
At time: 445.51494884490967 and batch: 150, loss is 3.8123829650878904 and perplexity is 45.25815908162195
At time: 446.54322481155396 and batch: 200, loss is 3.8124044227600096 and perplexity is 45.25913022677946
At time: 447.5767548084259 and batch: 250, loss is 3.7929183721542357 and perplexity is 44.38574556924489
At time: 448.61551690101624 and batch: 300, loss is 3.810117077827454 and perplexity is 45.155725291065295
At time: 449.65304350852966 and batch: 350, loss is 3.8169217824935915 and perplexity is 45.4640444864899
At time: 450.69578647613525 and batch: 400, loss is 3.8003175354003904 and perplexity is 44.71538095563722
At time: 451.743460893631 and batch: 450, loss is 3.8327140522003176 and perplexity is 46.187724171201
At time: 452.8857743740082 and batch: 500, loss is 3.84860152721405 and perplexity is 46.92739064288866
At time: 453.95925998687744 and batch: 550, loss is 3.8065118741989137 and perplexity is 44.993222809674734
At time: 455.01670503616333 and batch: 600, loss is 3.780831937789917 and perplexity is 43.85250912369419
At time: 456.0730860233307 and batch: 650, loss is 3.8270355224609376 and perplexity is 45.92618907608977
At time: 457.16014409065247 and batch: 700, loss is 3.849077730178833 and perplexity is 46.949742927131936
At time: 458.2071828842163 and batch: 750, loss is 3.815975852012634 and perplexity is 45.42105899487113
At time: 459.2512891292572 and batch: 800, loss is 3.781234860420227 and perplexity is 43.87018185214803
At time: 460.2992298603058 and batch: 850, loss is 3.782509546279907 and perplexity is 43.926138208428014
At time: 461.37668657302856 and batch: 900, loss is 3.7460861444473266 and perplexity is 42.35498587731262
At time: 462.43299436569214 and batch: 950, loss is 3.8575866842269897 and perplexity is 47.3509405979109
At time: 463.5061728954315 and batch: 1000, loss is 3.8197274827957153 and perplexity is 45.59178208275226
At time: 464.5533516407013 and batch: 1050, loss is 3.7741078472137453 and perplexity is 43.5586300224734
At time: 465.60096764564514 and batch: 1100, loss is 3.8007253551483156 and perplexity is 44.73362048999528
At time: 466.64839029312134 and batch: 1150, loss is 3.761745252609253 and perplexity is 43.02344727778238
At time: 467.69646978378296 and batch: 1200, loss is 3.829355978965759 and perplexity is 46.032882541171176
At time: 468.7467658519745 and batch: 1250, loss is 3.8055744791030883 and perplexity is 44.95106614507985
At time: 469.79408144950867 and batch: 1300, loss is 3.8058441734313964 and perplexity is 44.963190827576135
At time: 470.8679473400116 and batch: 1350, loss is 3.687441825866699 and perplexity is 39.94253618580882
At time: 471.91545844078064 and batch: 1400, loss is 3.7226278018951415 and perplexity is 41.37297135892309
At time: 472.96280574798584 and batch: 1450, loss is 3.6448655700683594 and perplexity is 38.2776268469168
At time: 474.0097997188568 and batch: 1500, loss is 3.6509742975234984 and perplexity is 38.512170087960506
At time: 475.057701587677 and batch: 1550, loss is 3.6577557706832886 and perplexity is 38.77422689704934
At time: 476.104647397995 and batch: 1600, loss is 3.750100131034851 and perplexity is 42.52533989317651
At time: 477.1521213054657 and batch: 1650, loss is 3.6821303367614746 and perplexity is 39.730944271547415
At time: 478.1984894275665 and batch: 1700, loss is 3.7148779582977296 and perplexity is 41.05357653028664
At time: 479.2464921474457 and batch: 1750, loss is 3.700149459838867 and perplexity is 40.453350059443025
At time: 480.293710231781 and batch: 1800, loss is 3.6516563177108763 and perplexity is 38.53844512445439
At time: 481.34156560897827 and batch: 1850, loss is 3.685773549079895 and perplexity is 39.875956531971184
At time: 482.38944911956787 and batch: 1900, loss is 3.7722911500930785 and perplexity is 43.4795690214222
At time: 483.45010924339294 and batch: 1950, loss is 3.7069507789611817 and perplexity is 40.72942397193736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.302145882539971 and perplexity of 73.85811460837901
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 486.82518458366394 and batch: 50, loss is 3.8435848140716553 and perplexity is 46.692558919716795
At time: 487.86782717704773 and batch: 100, loss is 3.8412097311019897 and perplexity is 46.581791810823375
At time: 488.8894658088684 and batch: 150, loss is 3.828300242424011 and perplexity is 45.98430958958197
At time: 489.924028635025 and batch: 200, loss is 3.830869002342224 and perplexity is 46.102584085277876
At time: 490.95927810668945 and batch: 250, loss is 3.8200068950653074 and perplexity is 45.60452276592746
At time: 492.00034737586975 and batch: 300, loss is 3.8341676425933837 and perplexity is 46.254911022584636
At time: 493.03995871543884 and batch: 350, loss is 3.8489610528945923 and perplexity is 46.94426527819622
At time: 494.0816810131073 and batch: 400, loss is 3.834010944366455 and perplexity is 46.24766352789027
At time: 495.12443232536316 and batch: 450, loss is 3.8710272455215455 and perplexity is 47.99165998607928
At time: 496.17153215408325 and batch: 500, loss is 3.8925384426116945 and perplexity is 49.0352017189999
At time: 497.22146821022034 and batch: 550, loss is 3.854350562095642 and perplexity is 47.19795484490417
At time: 498.2708067893982 and batch: 600, loss is 3.818198018074036 and perplexity is 45.52210435885136
At time: 499.32018280029297 and batch: 650, loss is 3.8509135675430297 and perplexity is 47.036014185206525
At time: 500.3746919631958 and batch: 700, loss is 3.8675840711593628 and perplexity is 47.82670048794639
At time: 501.4307744503021 and batch: 750, loss is 3.824612364768982 and perplexity is 45.81503740117322
At time: 502.48694944381714 and batch: 800, loss is 3.7860684633255004 and perplexity is 44.08274620257672
At time: 503.54325342178345 and batch: 850, loss is 3.7855353927612305 and perplexity is 44.0592532504409
At time: 504.5950560569763 and batch: 900, loss is 3.744354968070984 and perplexity is 42.28172535807824
At time: 505.67370080947876 and batch: 950, loss is 3.8598495531082153 and perplexity is 47.4582108914174
At time: 506.7339012622833 and batch: 1000, loss is 3.8166324615478517 and perplexity is 45.45089268877893
At time: 507.79150795936584 and batch: 1050, loss is 3.771375546455383 and perplexity is 43.43977718941372
At time: 508.8484613895416 and batch: 1100, loss is 3.7903427600860597 and perplexity is 44.27157220356772
At time: 509.9057581424713 and batch: 1150, loss is 3.761731495857239 and perplexity is 43.02285541895843
At time: 510.96211433410645 and batch: 1200, loss is 3.8205252504348755 and perplexity is 45.62816824303033
At time: 512.0180809497833 and batch: 1250, loss is 3.7961440896987915 and perplexity is 44.52915261842419
At time: 513.074212551117 and batch: 1300, loss is 3.7952253341674806 and perplexity is 44.488260001187065
At time: 514.1538090705872 and batch: 1350, loss is 3.666315083503723 and perplexity is 39.10753203100844
At time: 515.2165720462799 and batch: 1400, loss is 3.696070671081543 and perplexity is 40.288685434422206
At time: 516.2665116786957 and batch: 1450, loss is 3.614239854812622 and perplexity is 37.123116239525864
At time: 517.3153638839722 and batch: 1500, loss is 3.6197484493255616 and perplexity is 37.32817671290557
At time: 518.3659608364105 and batch: 1550, loss is 3.630706443786621 and perplexity is 37.73946801490571
At time: 519.4168560504913 and batch: 1600, loss is 3.724123306274414 and perplexity is 41.43489110786125
At time: 520.4661946296692 and batch: 1650, loss is 3.644958424568176 and perplexity is 38.281181261831
At time: 521.5164666175842 and batch: 1700, loss is 3.6659018278121946 and perplexity is 39.09137395975241
At time: 522.567624092102 and batch: 1750, loss is 3.654944071769714 and perplexity is 38.66535856961011
At time: 523.6185793876648 and batch: 1800, loss is 3.6055780172348024 and perplexity is 36.8029504500752
At time: 524.6694602966309 and batch: 1850, loss is 3.634789023399353 and perplexity is 37.89385733652744
At time: 525.7206859588623 and batch: 1900, loss is 3.7237636613845826 and perplexity is 41.41999194037891
At time: 526.7717909812927 and batch: 1950, loss is 3.670353832244873 and perplexity is 39.265796907675906
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.272791378997093 and perplexity of 71.7215585111921
finished 12 epochs...
Completing Train Step...
At time: 530.2064831256866 and batch: 50, loss is 3.846922745704651 and perplexity is 46.84867589810892
At time: 531.2199594974518 and batch: 100, loss is 3.821423816680908 and perplexity is 45.66918660097785
At time: 532.2632601261139 and batch: 150, loss is 3.793935179710388 and perplexity is 44.43090028366212
At time: 533.2770671844482 and batch: 200, loss is 3.7892880249023437 and perplexity is 44.22490203538698
At time: 534.3080017566681 and batch: 250, loss is 3.774150166511536 and perplexity is 43.5604734321143
At time: 535.3376486301422 and batch: 300, loss is 3.7856106615066527 and perplexity is 44.06256965996672
At time: 536.368595123291 and batch: 350, loss is 3.8020088386535646 and perplexity is 44.79107221530833
At time: 537.403731584549 and batch: 400, loss is 3.7853761672973634 and perplexity is 44.052238453886396
At time: 538.4461183547974 and batch: 450, loss is 3.8239528560638427 and perplexity is 45.7848319466558
At time: 539.4902968406677 and batch: 500, loss is 3.846782102584839 and perplexity is 46.84208741749464
At time: 540.5345764160156 and batch: 550, loss is 3.811002278327942 and perplexity is 45.19571485847413
At time: 541.5788848400116 and batch: 600, loss is 3.776459584236145 and perplexity is 43.66118901396259
At time: 542.621255159378 and batch: 650, loss is 3.8111014127731324 and perplexity is 45.20019553268253
At time: 543.6994571685791 and batch: 700, loss is 3.83131133556366 and perplexity is 46.122981300663255
At time: 544.7920823097229 and batch: 750, loss is 3.791874494552612 and perplexity is 44.33943645834078
At time: 545.8365185260773 and batch: 800, loss is 3.754069519042969 and perplexity is 42.69447492660151
At time: 546.8800394535065 and batch: 850, loss is 3.755889644622803 and perplexity is 42.772254995806925
At time: 547.9225678443909 and batch: 900, loss is 3.7154765701293946 and perplexity is 41.07815904388751
At time: 548.9658122062683 and batch: 950, loss is 3.8325033044815062 and perplexity is 46.17799123932745
At time: 550.0090754032135 and batch: 1000, loss is 3.790039234161377 and perplexity is 44.25813667279658
At time: 551.0503001213074 and batch: 1050, loss is 3.746948866844177 and perplexity is 42.391542238975866
At time: 552.0913071632385 and batch: 1100, loss is 3.7666996145248413 and perplexity is 43.23712989989293
At time: 553.1351706981659 and batch: 1150, loss is 3.739357256889343 and perplexity is 42.070940665716726
At time: 554.1812798976898 and batch: 1200, loss is 3.7993509006500243 and perplexity is 44.67217839844017
At time: 555.2315592765808 and batch: 1250, loss is 3.7777564573287963 and perplexity is 43.71784876750163
At time: 556.284426689148 and batch: 1300, loss is 3.7784786367416383 and perplexity is 43.74943230097141
At time: 557.3346688747406 and batch: 1350, loss is 3.651021132469177 and perplexity is 38.513973845593654
At time: 558.3857421875 and batch: 1400, loss is 3.6833590507507323 and perplexity is 39.77979224252729
At time: 559.4349689483643 and batch: 1450, loss is 3.6037741994857786 and perplexity is 36.73662447280848
At time: 560.485565662384 and batch: 1500, loss is 3.610978670120239 and perplexity is 37.002248094906136
At time: 561.536101102829 and batch: 1550, loss is 3.6242111349105834 and perplexity is 37.49513288841086
At time: 562.5864343643188 and batch: 1600, loss is 3.719731683731079 and perplexity is 41.25332368559801
At time: 563.6368968486786 and batch: 1650, loss is 3.642132339477539 and perplexity is 38.17314811355266
At time: 564.6878671646118 and batch: 1700, loss is 3.664780864715576 and perplexity is 39.04757852326742
At time: 565.7384462356567 and batch: 1750, loss is 3.65540461063385 and perplexity is 38.68316957094152
At time: 566.7884840965271 and batch: 1800, loss is 3.60816921710968 and perplexity is 36.89843791079696
At time: 567.8394732475281 and batch: 1850, loss is 3.637698893547058 and perplexity is 38.00428412666399
At time: 568.8898086547852 and batch: 1900, loss is 3.728383951187134 and perplexity is 41.6118070863199
At time: 569.939671754837 and batch: 1950, loss is 3.674965271949768 and perplexity is 39.4472869060516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2723215502361915 and perplexity of 71.68786957486218
finished 13 epochs...
Completing Train Step...
At time: 573.2898678779602 and batch: 50, loss is 3.8307912063598635 and perplexity is 46.09899762896735
At time: 574.3016633987427 and batch: 100, loss is 3.8031849098205566 and perplexity is 44.843780692264126
At time: 575.3176610469818 and batch: 150, loss is 3.7748024129867552 and perplexity is 43.588894865251476
At time: 576.3384428024292 and batch: 200, loss is 3.7687591075897218 and perplexity is 43.32626822744403
At time: 577.3644337654114 and batch: 250, loss is 3.753320264816284 and perplexity is 42.662497891766854
At time: 578.3998672962189 and batch: 300, loss is 3.764741644859314 and perplexity is 43.15255573496812
At time: 579.4348237514496 and batch: 350, loss is 3.781647968292236 and perplexity is 43.8883087135344
At time: 580.470226764679 and batch: 400, loss is 3.765017261505127 and perplexity is 43.16445093682058
At time: 581.5061867237091 and batch: 450, loss is 3.804178171157837 and perplexity is 44.888344413890344
At time: 582.5517861843109 and batch: 500, loss is 3.827421159744263 and perplexity is 45.94390334229977
At time: 583.6495249271393 and batch: 550, loss is 3.7922422313690185 and perplexity is 44.35574469993186
At time: 584.6864466667175 and batch: 600, loss is 3.7580408096313476 and perplexity is 42.86436420962963
At time: 585.7782340049744 and batch: 650, loss is 3.7921945905685424 and perplexity is 44.35363160708376
At time: 586.8532693386078 and batch: 700, loss is 3.8133599185943603 and perplexity is 45.30239580392516
At time: 587.8979380130768 and batch: 750, loss is 3.774969806671143 and perplexity is 43.59619198168991
At time: 588.9739983081818 and batch: 800, loss is 3.737399582862854 and perplexity is 41.988660043502264
At time: 590.0177240371704 and batch: 850, loss is 3.740637059211731 and perplexity is 42.124817621858824
At time: 591.0616564750671 and batch: 900, loss is 3.7006401014328003 and perplexity is 40.473203025543334
At time: 592.1141498088837 and batch: 950, loss is 3.8183481550216674 and perplexity is 45.528939421734464
At time: 593.1647999286652 and batch: 1000, loss is 3.77593364238739 and perplexity is 43.63823180510139
At time: 594.2166728973389 and batch: 1050, loss is 3.733715500831604 and perplexity is 41.834254970634994
At time: 595.2666206359863 and batch: 1100, loss is 3.7538463735580443 and perplexity is 42.68494891017371
At time: 596.3160314559937 and batch: 1150, loss is 3.7269030523300173 and perplexity is 41.550229814872225
At time: 597.3637406826019 and batch: 1200, loss is 3.7872984504699705 and perplexity is 44.137000773070945
At time: 598.4134883880615 and batch: 1250, loss is 3.766865029335022 and perplexity is 43.244282553089164
At time: 599.46968126297 and batch: 1300, loss is 3.768133668899536 and perplexity is 43.29917877527202
At time: 600.5209002494812 and batch: 1350, loss is 3.6414404678344727 and perplexity is 38.14674632922245
At time: 601.571783542633 and batch: 1400, loss is 3.6748450565338135 and perplexity is 39.442545019077585
At time: 602.6230654716492 and batch: 1450, loss is 3.5959692335128786 and perplexity is 36.45101241493168
At time: 603.6888911724091 and batch: 1500, loss is 3.6037119483947753 and perplexity is 36.73433764903464
At time: 604.7524499893188 and batch: 1550, loss is 3.617754325866699 and perplexity is 37.25381388901375
At time: 605.8034210205078 and batch: 1600, loss is 3.7142197561264036 and perplexity is 41.026563867945434
At time: 606.8552408218384 and batch: 1650, loss is 3.6373692035675047 and perplexity is 37.991756560227365
At time: 607.9053661823273 and batch: 1700, loss is 3.660365204811096 and perplexity is 38.87553781258738
At time: 608.957896232605 and batch: 1750, loss is 3.651822805404663 and perplexity is 38.54486183544218
At time: 610.0058553218842 and batch: 1800, loss is 3.6054407119750977 and perplexity is 36.797897558308
At time: 611.0534298419952 and batch: 1850, loss is 3.6348975801467898 and perplexity is 37.89797119371716
At time: 612.1008296012878 and batch: 1900, loss is 3.7265299797058105 and perplexity is 41.53473145278586
At time: 613.1472115516663 and batch: 1950, loss is 3.673423490524292 and perplexity is 39.38651467260321
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.27337163880814 and perplexity of 71.76318772589386
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 616.5028698444366 and batch: 50, loss is 3.830232524871826 and perplexity is 46.073250165360314
At time: 617.5132710933685 and batch: 100, loss is 3.8197966766357423 and perplexity is 45.594936862372634
At time: 618.5240876674652 and batch: 150, loss is 3.7968363189697265 and perplexity is 44.559987672508804
At time: 619.5353865623474 and batch: 200, loss is 3.7923178339004515 and perplexity is 44.35909823328098
At time: 620.5581510066986 and batch: 250, loss is 3.7806971168518064 and perplexity is 43.84659728580436
At time: 621.5836081504822 and batch: 300, loss is 3.7893424367904665 and perplexity is 44.22730846127727
At time: 622.6156778335571 and batch: 350, loss is 3.8110332679748535 and perplexity is 45.19711547942179
At time: 623.65540599823 and batch: 400, loss is 3.7967366695404055 and perplexity is 44.55554751639987
At time: 624.7444863319397 and batch: 450, loss is 3.8391956615448 and perplexity is 46.48806725758518
At time: 625.7921853065491 and batch: 500, loss is 3.860849461555481 and perplexity is 47.50568849005006
At time: 626.8334469795227 and batch: 550, loss is 3.8351764059066773 and perplexity is 46.30159482237736
At time: 627.8747107982635 and batch: 600, loss is 3.797961268424988 and perplexity is 44.61014361252674
At time: 628.9154880046844 and batch: 650, loss is 3.8286815023422243 and perplexity is 46.00184490623947
At time: 629.9560234546661 and batch: 700, loss is 3.852912354469299 and perplexity is 47.13012317600234
At time: 630.9960670471191 and batch: 750, loss is 3.8115957403182983 and perplexity is 45.22254475784492
At time: 632.0365467071533 and batch: 800, loss is 3.7680257463455202 and perplexity is 43.29450606946151
At time: 633.0778846740723 and batch: 850, loss is 3.7693436908721925 and perplexity is 43.35160344409219
At time: 634.1182723045349 and batch: 900, loss is 3.7256550550460816 and perplexity is 41.49840758464373
At time: 635.157692193985 and batch: 950, loss is 3.8472178030014037 and perplexity is 46.86250098127139
At time: 636.2316300868988 and batch: 1000, loss is 3.8031576013565065 and perplexity is 44.84255609421224
At time: 637.2637984752655 and batch: 1050, loss is 3.756287851333618 and perplexity is 42.789290586401094
At time: 638.2953634262085 and batch: 1100, loss is 3.766238808631897 and perplexity is 43.21721056546688
At time: 639.3279371261597 and batch: 1150, loss is 3.7404385805130005 and perplexity is 42.116457572546274
At time: 640.3792669773102 and batch: 1200, loss is 3.797922959327698 and perplexity is 44.608434670929185
At time: 641.4213371276855 and batch: 1250, loss is 3.7760408782958983 and perplexity is 43.642911641453466
At time: 642.5118706226349 and batch: 1300, loss is 3.7732891130447386 and perplexity is 43.52298167896866
At time: 643.5865068435669 and batch: 1350, loss is 3.6448836851119997 and perplexity is 38.27832025407812
At time: 644.6490576267242 and batch: 1400, loss is 3.6788088607788088 and perplexity is 39.59919781185279
At time: 645.7070908546448 and batch: 1450, loss is 3.594273543357849 and perplexity is 36.38925516741502
At time: 646.7649188041687 and batch: 1500, loss is 3.597242546081543 and perplexity is 36.497455509193045
At time: 647.8214678764343 and batch: 1550, loss is 3.6092863416671754 and perplexity is 36.93968109451782
At time: 648.8912816047668 and batch: 1600, loss is 3.7077627992630005 and perplexity is 40.762510522741394
At time: 649.938129901886 and batch: 1650, loss is 3.6330135536193846 and perplexity is 37.82663762891775
At time: 650.9851052761078 and batch: 1700, loss is 3.6524418020248413 and perplexity is 38.568728360530685
At time: 652.0334918498993 and batch: 1750, loss is 3.6406600427627565 and perplexity is 38.116987265852735
At time: 653.080011844635 and batch: 1800, loss is 3.593693952560425 and perplexity is 36.36817040085344
At time: 654.1286425590515 and batch: 1850, loss is 3.618330798149109 and perplexity is 37.27529587142362
At time: 655.2059519290924 and batch: 1900, loss is 3.7127938508987426 and perplexity is 40.9681055639586
At time: 656.2520637512207 and batch: 1950, loss is 3.6679037189483643 and perplexity is 39.169709017751174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2610223814498545 and perplexity of 70.8824152879971
finished 15 epochs...
Completing Train Step...
At time: 659.658900976181 and batch: 50, loss is 3.841535449028015 and perplexity is 46.59696680669247
At time: 660.7313556671143 and batch: 100, loss is 3.819742498397827 and perplexity is 45.592466675951364
At time: 661.74436378479 and batch: 150, loss is 3.78701566696167 and perplexity is 44.12452132172116
At time: 662.7916579246521 and batch: 200, loss is 3.780282344818115 and perplexity is 43.828414714549375
At time: 663.836902141571 and batch: 250, loss is 3.7651151704788206 and perplexity is 43.168677330809416
At time: 664.8581087589264 and batch: 300, loss is 3.771209216117859 and perplexity is 43.432552437476204
At time: 665.8867518901825 and batch: 350, loss is 3.7884973287582397 and perplexity is 44.189947396944284
At time: 666.9180982112885 and batch: 400, loss is 3.7726996994018553 and perplexity is 43.497336198428634
At time: 667.94899559021 and batch: 450, loss is 3.813877067565918 and perplexity is 45.325829950274326
At time: 669.0100328922272 and batch: 500, loss is 3.8361634588241578 and perplexity is 46.34731950926122
At time: 670.0559515953064 and batch: 550, loss is 3.8100027084350585 and perplexity is 45.15056115351585
At time: 671.0924844741821 and batch: 600, loss is 3.7759143781661986 and perplexity is 43.63739115664873
At time: 672.125129699707 and batch: 650, loss is 3.8071072626113893 and perplexity is 45.0200192295229
At time: 673.1697599887848 and batch: 700, loss is 3.8315577411651613 and perplexity is 46.13434766192371
At time: 674.2181875705719 and batch: 750, loss is 3.7915285539627077 and perplexity is 44.32410030038906
At time: 675.2561192512512 and batch: 800, loss is 3.749311480522156 and perplexity is 42.49181548332631
At time: 676.3026196956635 and batch: 850, loss is 3.751680679321289 and perplexity is 42.59260639124559
At time: 677.3491680622101 and batch: 900, loss is 3.7086740589141844 and perplexity is 40.79967268347894
At time: 678.3954455852509 and batch: 950, loss is 3.831382541656494 and perplexity is 46.126265654883156
At time: 679.4728541374207 and batch: 1000, loss is 3.788278398513794 and perplexity is 44.18027393990342
At time: 680.5205085277557 and batch: 1050, loss is 3.742804865837097 and perplexity is 42.216235132533974
At time: 681.5702612400055 and batch: 1100, loss is 3.7542839574813844 and perplexity is 42.70363124483194
At time: 682.6181378364563 and batch: 1150, loss is 3.7295405960083006 and perplexity is 41.659965012924964
At time: 683.6661241054535 and batch: 1200, loss is 3.7877423191070556 and perplexity is 44.156596152014465
At time: 684.7134249210358 and batch: 1250, loss is 3.7673839378356933 and perplexity is 43.26672820202675
At time: 685.7606582641602 and batch: 1300, loss is 3.7659291648864746 and perplexity is 43.2038306981237
At time: 686.8072500228882 and batch: 1350, loss is 3.638162531852722 and perplexity is 38.02190845390536
At time: 687.855349779129 and batch: 1400, loss is 3.6737658834457396 and perplexity is 39.40000264538904
At time: 688.9004547595978 and batch: 1450, loss is 3.5920703172683717 and perplexity is 36.309169666681775
At time: 689.944732427597 and batch: 1500, loss is 3.5970383787155153 and perplexity is 36.490004680468935
At time: 690.9897062778473 and batch: 1550, loss is 3.609992713928223 and perplexity is 36.965783478489584
At time: 692.0364506244659 and batch: 1600, loss is 3.7104085302352905 and perplexity is 40.87049995183547
At time: 693.0836431980133 and batch: 1650, loss is 3.6366372776031493 and perplexity is 37.96395958107579
At time: 694.1299998760223 and batch: 1700, loss is 3.656659893989563 and perplexity is 38.73175839984399
At time: 695.1733334064484 and batch: 1750, loss is 3.646186490058899 and perplexity is 38.32822193808634
At time: 696.2208783626556 and batch: 1800, loss is 3.599941191673279 and perplexity is 36.596082226034184
At time: 697.2691719532013 and batch: 1850, loss is 3.6250654458999634 and perplexity is 37.52717907924311
At time: 698.3170955181122 and batch: 1900, loss is 3.7192366313934326 and perplexity is 41.23290618555431
At time: 699.3643736839294 and batch: 1950, loss is 3.674397974014282 and perplexity is 39.42491488802909
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260009765625 and perplexity of 70.81067496139774
finished 16 epochs...
Completing Train Step...
At time: 702.6748702526093 and batch: 50, loss is 3.838668985366821 and perplexity is 46.463589546479824
At time: 703.7012276649475 and batch: 100, loss is 3.8150718593597412 and perplexity is 45.38001724476838
At time: 704.7126111984253 and batch: 150, loss is 3.781109504699707 and perplexity is 43.86468281856748
At time: 705.7321190834045 and batch: 200, loss is 3.773409104347229 and perplexity is 43.52820437156117
At time: 706.7586526870728 and batch: 250, loss is 3.7574761486053467 and perplexity is 42.84016720595152
At time: 707.7843840122223 and batch: 300, loss is 3.762451672554016 and perplexity is 43.05385063653703
At time: 708.8141508102417 and batch: 350, loss is 3.7791321992874147 and perplexity is 43.77803463701197
At time: 709.8464148044586 and batch: 400, loss is 3.763103733062744 and perplexity is 43.0819335071562
At time: 710.8771417140961 and batch: 450, loss is 3.804220561981201 and perplexity is 44.890247308101834
At time: 711.912115573883 and batch: 500, loss is 3.8267097759246824 and perplexity is 45.91123121544275
At time: 712.9507987499237 and batch: 550, loss is 3.800608673095703 and perplexity is 44.72840118384133
At time: 714.0312459468842 and batch: 600, loss is 3.7673242235183717 and perplexity is 43.264144636028135
At time: 715.071204662323 and batch: 650, loss is 3.7984450387954714 and perplexity is 44.63172989921145
At time: 716.1131618022919 and batch: 700, loss is 3.8234470558166502 and perplexity is 45.76167982300804
At time: 717.1535902023315 and batch: 750, loss is 3.7839885330200196 and perplexity is 43.9911524501323
At time: 718.1934134960175 and batch: 800, loss is 3.741973695755005 and perplexity is 42.18116083928408
At time: 719.2338809967041 and batch: 850, loss is 3.744787015914917 and perplexity is 42.299997033191666
At time: 720.2746200561523 and batch: 900, loss is 3.701962461471558 and perplexity is 40.526758573919246
At time: 721.3144555091858 and batch: 950, loss is 3.8251833009719847 and perplexity is 45.84120233321021
At time: 722.3547880649567 and batch: 1000, loss is 3.782424654960632 and perplexity is 43.92240941887802
At time: 723.3948290348053 and batch: 1050, loss is 3.7373971796035765 and perplexity is 41.988559133986726
At time: 724.4458844661713 and batch: 1100, loss is 3.7492453336715696 and perplexity is 42.48900487651382
At time: 725.4872133731842 and batch: 1150, loss is 3.7249893951416015 and perplexity is 41.470792950611866
At time: 726.5284833908081 and batch: 1200, loss is 3.7834446668624877 and perplexity is 43.967233655984764
At time: 727.5685050487518 and batch: 1250, loss is 3.7637302112579345 and perplexity is 43.108931855160236
At time: 728.6103491783142 and batch: 1300, loss is 3.762825584411621 and perplexity is 43.069951991861835
At time: 729.6506519317627 and batch: 1350, loss is 3.6354182624816893 and perplexity is 37.91770913599927
At time: 730.69029545784 and batch: 1400, loss is 3.671347794532776 and perplexity is 39.30484503197324
At time: 731.730429649353 and batch: 1450, loss is 3.590516571998596 and perplexity is 36.252798270798166
At time: 732.770096540451 and batch: 1500, loss is 3.5960082626342773 and perplexity is 36.4524350936831
At time: 733.8106594085693 and batch: 1550, loss is 3.6093587684631347 and perplexity is 36.94235661415175
At time: 734.8462376594543 and batch: 1600, loss is 3.710406289100647 and perplexity is 40.87040835564476
At time: 735.8824188709259 and batch: 1650, loss is 3.6369434070587157 and perplexity is 37.97558324643589
At time: 736.9227888584137 and batch: 1700, loss is 3.657257661819458 and perplexity is 38.7549179203292
At time: 737.9631080627441 and batch: 1750, loss is 3.647171936035156 and perplexity is 38.36601094662743
At time: 739.0028231143951 and batch: 1800, loss is 3.6012466382980346 and perplexity is 36.64388765498425
At time: 740.0441327095032 and batch: 1850, loss is 3.6266258144378662 and perplexity is 37.58578101721466
At time: 741.0849375724792 and batch: 1900, loss is 3.7205793190002443 and perplexity is 41.288306281870874
At time: 742.1253952980042 and batch: 1950, loss is 3.6757581853866577 and perplexity is 39.478577593652176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.259883720930232 and perplexity of 70.80175021395628
finished 17 epochs...
Completing Train Step...
At time: 745.4351234436035 and batch: 50, loss is 3.83452645778656 and perplexity is 46.2715109653963
At time: 746.4680469036102 and batch: 100, loss is 3.8101939249038694 and perplexity is 45.15919550987372
At time: 747.4938716888428 and batch: 150, loss is 3.7758163976669312 and perplexity is 43.633115752733005
At time: 748.5206823348999 and batch: 200, loss is 3.767473464012146 and perplexity is 43.2706018801655
At time: 749.5528998374939 and batch: 250, loss is 3.7514874839782717 and perplexity is 42.584378492865255
At time: 750.583420753479 and batch: 300, loss is 3.755928702354431 and perplexity is 42.773925615688775
At time: 751.6152889728546 and batch: 350, loss is 3.7725007200241087 and perplexity is 43.488681986571635
At time: 752.6766211986542 and batch: 400, loss is 3.7563882303237914 and perplexity is 42.7935859477588
At time: 753.7361397743225 and batch: 450, loss is 3.7976486349105834 and perplexity is 44.59619916641524
At time: 754.8053376674652 and batch: 500, loss is 3.8201442670822146 and perplexity is 45.610787981522705
At time: 755.844375371933 and batch: 550, loss is 3.794311246871948 and perplexity is 44.44761242846482
At time: 756.8852758407593 and batch: 600, loss is 3.761457476615906 and perplexity is 43.0110679438278
At time: 757.9257214069366 and batch: 650, loss is 3.7924593448638917 and perplexity is 44.36537597618356
At time: 758.9671294689178 and batch: 700, loss is 3.8178434276580813 and perplexity is 45.505965518439794
At time: 760.0075316429138 and batch: 750, loss is 3.7787800312042235 and perplexity is 43.76262012487688
At time: 761.0486867427826 and batch: 800, loss is 3.737052812576294 and perplexity is 41.974102148095376
At time: 762.1440711021423 and batch: 850, loss is 3.7396930122375487 and perplexity is 42.08506858067806
At time: 763.2241084575653 and batch: 900, loss is 3.697133798599243 and perplexity is 40.33154022057437
At time: 764.2735869884491 and batch: 950, loss is 3.820754818916321 and perplexity is 45.63864423475777
At time: 765.3197116851807 and batch: 1000, loss is 3.7781883239746095 and perplexity is 43.73673312567972
At time: 766.3815279006958 and batch: 1050, loss is 3.733496541976929 and perplexity is 41.82509599283668
At time: 767.4287173748016 and batch: 1100, loss is 3.7455473518371583 and perplexity is 42.332171470586935
At time: 768.4774830341339 and batch: 1150, loss is 3.7216097640991213 and perplexity is 41.33087354256598
At time: 769.5249497890472 and batch: 1200, loss is 3.7801417922973632 and perplexity is 43.82225495327582
At time: 770.5721604824066 and batch: 1250, loss is 3.760921640396118 and perplexity is 42.9880272293477
At time: 771.619699716568 and batch: 1300, loss is 3.7602845001220704 and perplexity is 42.960646549491216
At time: 772.6670641899109 and batch: 1350, loss is 3.6330877590179442 and perplexity is 37.82944467378683
At time: 773.713653087616 and batch: 1400, loss is 3.6691341686248777 and perplexity is 39.21793503730173
At time: 774.7569465637207 and batch: 1450, loss is 3.588769335746765 and perplexity is 36.18951137211131
At time: 775.8002104759216 and batch: 1500, loss is 3.594454674720764 and perplexity is 36.39584699977472
At time: 776.8487844467163 and batch: 1550, loss is 3.6080583810806273 and perplexity is 36.89434846109404
At time: 777.8956594467163 and batch: 1600, loss is 3.7094599533081056 and perplexity is 40.831749520366884
At time: 778.9421622753143 and batch: 1650, loss is 3.6361887407302858 and perplexity is 37.94693516368867
At time: 779.987184047699 and batch: 1700, loss is 3.656710171699524 and perplexity is 38.7337057929139
At time: 781.0342497825623 and batch: 1750, loss is 3.646865038871765 and perplexity is 38.3542383332805
At time: 782.0794913768768 and batch: 1800, loss is 3.601156072616577 and perplexity is 36.64056912660219
At time: 783.1292190551758 and batch: 1850, loss is 3.6266866445541384 and perplexity is 37.588067434184914
At time: 784.1771862506866 and batch: 1900, loss is 3.720542049407959 and perplexity is 41.286767512204435
At time: 785.224858045578 and batch: 1950, loss is 3.675775685310364 and perplexity is 39.47926847179323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.260046954487645 and perplexity of 70.81330837882929
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 788.5374381542206 and batch: 50, loss is 3.8353307342529295 and perplexity is 46.30874102235156
At time: 789.5470304489136 and batch: 100, loss is 3.817992854118347 and perplexity is 45.51276582184817
At time: 790.5568175315857 and batch: 150, loss is 3.786778631210327 and perplexity is 44.114063472148096
At time: 791.5741455554962 and batch: 200, loss is 3.7802419233322144 and perplexity is 43.826643140707006
At time: 792.630345582962 and batch: 250, loss is 3.765937237739563 and perplexity is 43.2041794777096
At time: 793.6544165611267 and batch: 300, loss is 3.7702969980239867 and perplexity is 43.392950542808315
At time: 794.6802718639374 and batch: 350, loss is 3.788972592353821 and perplexity is 44.21095426173633
At time: 795.7080543041229 and batch: 400, loss is 3.774022741317749 and perplexity is 43.55492308398037
At time: 796.7426946163177 and batch: 450, loss is 3.815727686882019 and perplexity is 45.409788470366436
At time: 797.7823240756989 and batch: 500, loss is 3.8339921379089357 and perplexity is 46.24679378134921
At time: 798.8309073448181 and batch: 550, loss is 3.805472321510315 and perplexity is 44.94647428692044
At time: 799.9095230102539 and batch: 600, loss is 3.7702421808242796 and perplexity is 43.39057192796763
At time: 800.9654657840729 and batch: 650, loss is 3.799621024131775 and perplexity is 44.68424703274391
At time: 802.0061497688293 and batch: 700, loss is 3.82592378616333 and perplexity is 45.87515963557957
At time: 803.0464289188385 and batch: 750, loss is 3.789838933944702 and perplexity is 44.24927264619424
At time: 804.0871772766113 and batch: 800, loss is 3.747199420928955 and perplexity is 42.40216494376934
At time: 805.1268720626831 and batch: 850, loss is 3.7509602737426757 and perplexity is 42.561933489784884
At time: 806.1668891906738 and batch: 900, loss is 3.7055271816253663 and perplexity is 40.67148292462732
At time: 807.2076954841614 and batch: 950, loss is 3.8289191627502444 and perplexity is 46.01277902272139
At time: 808.2483108043671 and batch: 1000, loss is 3.7891403245925903 and perplexity is 44.21837048602535
At time: 809.2890992164612 and batch: 1050, loss is 3.74217559337616 and perplexity is 42.189677975080876
At time: 810.3297717571259 and batch: 1100, loss is 3.7501396989822386 and perplexity is 42.52702256687778
At time: 811.3698496818542 and batch: 1150, loss is 3.727776498794556 and perplexity is 41.58653757033682
At time: 812.410712480545 and batch: 1200, loss is 3.7845669317245485 and perplexity is 44.01660423565051
At time: 813.4509074687958 and batch: 1250, loss is 3.764708971977234 and perplexity is 43.151145839635944
At time: 814.4912734031677 and batch: 1300, loss is 3.763763666152954 and perplexity is 43.11037408407453
At time: 815.5273818969727 and batch: 1350, loss is 3.6359441614151002 and perplexity is 37.937655263155065
At time: 816.5658049583435 and batch: 1400, loss is 3.669419360160828 and perplexity is 39.229121255463355
At time: 817.6034159660339 and batch: 1450, loss is 3.584196605682373 and perplexity is 36.02440428820468
At time: 818.6379749774933 and batch: 1500, loss is 3.5872553968429566 and perplexity is 36.13476411539293
At time: 819.6728475093842 and batch: 1550, loss is 3.6003921461105346 and perplexity is 36.6125891133475
At time: 820.7078144550323 and batch: 1600, loss is 3.6988340187072755 and perplexity is 40.40017104346499
At time: 821.7426443099976 and batch: 1650, loss is 3.6242444276809693 and perplexity is 37.49638122604089
At time: 822.7792439460754 and batch: 1700, loss is 3.644813046455383 and perplexity is 38.275616420456544
At time: 823.8143513202667 and batch: 1750, loss is 3.634484043121338 and perplexity is 37.88230221951285
At time: 824.8497140407562 and batch: 1800, loss is 3.5883760166168215 and perplexity is 36.175280143875966
At time: 825.884293794632 and batch: 1850, loss is 3.6153676891326905 and perplexity is 37.16500858345968
At time: 826.9207282066345 and batch: 1900, loss is 3.709022531509399 and perplexity is 40.81389272880702
At time: 827.9545114040375 and batch: 1950, loss is 3.6671850442886353 and perplexity is 39.141568853473835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.257555868459303 and perplexity of 70.63712586970804
finished 19 epochs...
Completing Train Step...
At time: 831.2091660499573 and batch: 50, loss is 3.834117708206177 and perplexity is 46.25260136961345
At time: 832.2144260406494 and batch: 100, loss is 3.815019211769104 and perplexity is 45.37762815908773
At time: 833.2319412231445 and batch: 150, loss is 3.7818881273269653 and perplexity is 43.89885015315126
At time: 834.2538254261017 and batch: 200, loss is 3.7751139259338378 and perplexity is 43.602475485510716
At time: 835.2800333499908 and batch: 250, loss is 3.7603065586090088 and perplexity is 42.9615942068039
At time: 836.3067083358765 and batch: 300, loss is 3.763905854225159 and perplexity is 43.1165043008691
At time: 837.3406915664673 and batch: 350, loss is 3.781382236480713 and perplexity is 43.87664774316927
At time: 838.3756036758423 and batch: 400, loss is 3.7654725170135497 and perplexity is 43.184106264636256
At time: 839.4196727275848 and batch: 450, loss is 3.807565245628357 and perplexity is 45.04064235591394
At time: 840.457067489624 and batch: 500, loss is 3.8262616205215454 and perplexity is 45.89066045890101
At time: 841.5002145767212 and batch: 550, loss is 3.798525586128235 and perplexity is 44.63532501079784
At time: 842.5487976074219 and batch: 600, loss is 3.7644411182403563 and perplexity is 43.139589191786996
At time: 843.6229696273804 and batch: 650, loss is 3.793723168373108 and perplexity is 44.42148142756383
At time: 844.6773247718811 and batch: 700, loss is 3.820229935646057 and perplexity is 45.61469555960071
At time: 845.7172555923462 and batch: 750, loss is 3.7835718822479247 and perplexity is 43.972827320353446
At time: 846.7576327323914 and batch: 800, loss is 3.7411564111709597 and perplexity is 42.14670091049542
At time: 847.7973337173462 and batch: 850, loss is 3.7447917318344115 and perplexity is 42.30019651704267
At time: 848.8381881713867 and batch: 900, loss is 3.6996112155914305 and perplexity is 40.43158213523951
At time: 849.8789370059967 and batch: 950, loss is 3.823038311004639 and perplexity is 45.74297879602571
At time: 850.9192345142365 and batch: 1000, loss is 3.782893671989441 and perplexity is 43.94301460855648
At time: 851.9601936340332 and batch: 1050, loss is 3.7370985078811647 and perplexity is 41.976020211312616
At time: 853.0005125999451 and batch: 1100, loss is 3.7461997127532958 and perplexity is 42.359796334460626
At time: 854.0417215824127 and batch: 1150, loss is 3.7240800571441652 and perplexity is 41.43309912361005
At time: 855.0819480419159 and batch: 1200, loss is 3.781392469406128 and perplexity is 43.87709673193032
At time: 856.1236619949341 and batch: 1250, loss is 3.762011179924011 and perplexity is 43.03488990897525
At time: 857.1633212566376 and batch: 1300, loss is 3.7611090755462646 and perplexity is 42.996085451859415
At time: 858.2041163444519 and batch: 1350, loss is 3.633779010772705 and perplexity is 37.85560338388473
At time: 859.2435474395752 and batch: 1400, loss is 3.668518753051758 and perplexity is 39.19380713443927
At time: 860.2839093208313 and batch: 1450, loss is 3.5846808481216432 and perplexity is 36.04185305798691
At time: 861.3243148326874 and batch: 1500, loss is 3.5887451171875 and perplexity is 36.18863492489856
At time: 862.3640327453613 and batch: 1550, loss is 3.6024054527282714 and perplexity is 36.68637573392372
At time: 863.4051465988159 and batch: 1600, loss is 3.7011514949798583 and perplexity is 40.49390605364566
At time: 864.4492452144623 and batch: 1650, loss is 3.627033805847168 and perplexity is 37.60111882161504
At time: 865.4883835315704 and batch: 1700, loss is 3.648037858009338 and perplexity is 38.39924730653825
At time: 866.5580615997314 and batch: 1750, loss is 3.638304328918457 and perplexity is 38.02730023121783
At time: 867.5978400707245 and batch: 1800, loss is 3.592105565071106 and perplexity is 36.31044950768729
At time: 868.637449502945 and batch: 1850, loss is 3.6191012716293334 and perplexity is 37.30402656505755
At time: 869.6772696971893 and batch: 1900, loss is 3.712572612762451 and perplexity is 40.95904285918117
At time: 870.7177639007568 and batch: 1950, loss is 3.670126829147339 and perplexity is 39.25688446176541
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.256827988735465 and perplexity of 70.58572924558682
Finished Training.
Improved accuracyfrom -10000000 to -70.58572924558682
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd78797ab38>
ELAPSED
903.3998177051544


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.58572924558682}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.5545691141662139, 'dropout': 0.7795352401135597, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6263389587402344 and batch: 50, loss is 7.634161462783814 and perplexity is 2067.63653370225
At time: 2.7729504108428955 and batch: 100, loss is 6.885252447128296 and perplexity is 977.7484683486599
At time: 3.920755624771118 and batch: 150, loss is 6.595525436401367 and perplexity is 731.8133070377254
At time: 5.06646203994751 and batch: 200, loss is 6.517466087341308 and perplexity is 676.8611036187094
At time: 6.214439153671265 and batch: 250, loss is 6.483258924484253 and perplexity is 654.0991362726961
At time: 7.361424207687378 and batch: 300, loss is 6.421662759780884 and perplexity is 615.024903068419
At time: 8.509618282318115 and batch: 350, loss is 6.3752570056915285 and perplexity is 587.1363089257251
At time: 9.658295631408691 and batch: 400, loss is 6.3323995399475095 and perplexity is 562.5047283211484
At time: 10.809746742248535 and batch: 450, loss is 6.250823440551758 and perplexity is 518.4395531031415
At time: 11.96109676361084 and batch: 500, loss is 6.234679584503174 and perplexity is 510.137136414588
At time: 13.114238977432251 and batch: 550, loss is 6.188015651702881 and perplexity is 486.87900947004624
At time: 14.269089221954346 and batch: 600, loss is 6.230724306106567 and perplexity is 508.12338711446733
At time: 15.42499566078186 and batch: 650, loss is 6.305262069702149 and perplexity is 547.4450381452035
At time: 16.587260961532593 and batch: 700, loss is 6.206090755462647 and perplexity is 495.7594134214751
At time: 17.749745845794678 and batch: 750, loss is 6.137971220016479 and perplexity is 463.11306262816265
At time: 18.909596920013428 and batch: 800, loss is 6.142205381393433 and perplexity is 465.0781153103831
At time: 20.06449294090271 and batch: 850, loss is 6.181192874908447 and perplexity is 483.5684491120144
At time: 21.21608877182007 and batch: 900, loss is 6.167616844177246 and perplexity is 477.04787092076964
At time: 22.366088151931763 and batch: 950, loss is 6.175595035552979 and perplexity is 480.86907300234657
At time: 23.514246463775635 and batch: 1000, loss is 6.157694454193115 and perplexity is 472.33782201888226
At time: 24.66633439064026 and batch: 1050, loss is 6.059096269607544 and perplexity is 427.98847583817
At time: 25.817056894302368 and batch: 1100, loss is 6.134472141265869 and perplexity is 461.4954253222207
At time: 26.965989351272583 and batch: 1150, loss is 6.036024904251098 and perplexity is 418.2272329233525
At time: 28.120131254196167 and batch: 1200, loss is 6.1274850463867185 and perplexity is 458.2821517952253
At time: 29.27328610420227 and batch: 1250, loss is 6.060259523391724 and perplexity is 428.4866247328949
At time: 30.426071166992188 and batch: 1300, loss is 6.071211824417114 and perplexity is 433.20533241736774
At time: 31.57874608039856 and batch: 1350, loss is 6.048243618011474 and perplexity is 423.3687793432849
At time: 32.73238015174866 and batch: 1400, loss is 6.067876091003418 and perplexity is 431.76268240067543
At time: 33.88651394844055 and batch: 1450, loss is 6.054611806869507 and perplexity is 426.07347455120856
At time: 35.06594967842102 and batch: 1500, loss is 6.043009853363037 and perplexity is 421.1587552105948
At time: 36.30533480644226 and batch: 1550, loss is 6.004171457290649 and perplexity is 405.11519440386706
At time: 37.581504821777344 and batch: 1600, loss is 6.005971670150757 and perplexity is 405.8451448225902
At time: 38.85789895057678 and batch: 1650, loss is 6.006203098297119 and perplexity is 405.93907968133243
At time: 40.13314652442932 and batch: 1700, loss is 6.0231272411346435 and perplexity is 412.8677158855614
At time: 41.40945887565613 and batch: 1750, loss is 6.037104215621948 and perplexity is 418.6788740182869
At time: 42.68505620956421 and batch: 1800, loss is 6.045399713516235 and perplexity is 422.16646940622
At time: 43.96119022369385 and batch: 1850, loss is 5.993648672103882 and perplexity is 400.87460477374935
At time: 45.23809313774109 and batch: 1900, loss is 5.971279039382934 and perplexity is 392.00674229823113
At time: 46.51347279548645 and batch: 1950, loss is 5.911810007095337 and perplexity is 369.37412049515314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.355095725835755 and perplexity of 211.68423903374537
finished 1 epochs...
Completing Train Step...
At time: 50.02311158180237 and batch: 50, loss is 5.638443765640258 and perplexity is 281.0250371774735
At time: 51.121222257614136 and batch: 100, loss is 5.523579006195068 and perplexity is 250.53008326662072
At time: 52.19840145111084 and batch: 150, loss is 5.397412919998169 and perplexity is 220.8343603886916
At time: 53.27751970291138 and batch: 200, loss is 5.322613248825073 and perplexity is 204.91868641661452
At time: 54.35630488395691 and batch: 250, loss is 5.312058830261231 and perplexity is 202.76726231544515
At time: 55.43536591529846 and batch: 300, loss is 5.280680065155029 and perplexity is 196.5034650812339
At time: 56.528522968292236 and batch: 350, loss is 5.249203157424927 and perplexity is 190.41447762727955
At time: 57.608343839645386 and batch: 400, loss is 5.198993787765503 and perplexity is 181.08993526255531
At time: 58.68709993362427 and batch: 450, loss is 5.128321342468261 and perplexity is 168.73363418941184
At time: 59.765568017959595 and batch: 500, loss is 5.117007303237915 and perplexity is 166.83533420264834
At time: 60.87499499320984 and batch: 550, loss is 5.049749794006348 and perplexity is 155.9834316139691
At time: 61.95426392555237 and batch: 600, loss is 5.043933439254761 and perplexity is 155.07880999074695
At time: 63.03353977203369 and batch: 650, loss is 5.114076128005982 and perplexity is 166.3470266104018
At time: 64.11237263679504 and batch: 700, loss is 5.079497060775757 and perplexity is 160.69321667995862
At time: 65.19111037254333 and batch: 750, loss is 5.021863164901734 and perplexity is 151.69367098764613
At time: 66.29110980033875 and batch: 800, loss is 5.005096092224121 and perplexity is 149.17141668291103
At time: 67.37360429763794 and batch: 850, loss is 4.992994241714477 and perplexity is 147.377046000244
At time: 68.4503378868103 and batch: 900, loss is 4.998330669403076 and perplexity is 148.16561514893368
At time: 69.52724003791809 and batch: 950, loss is 5.05515947341919 and perplexity is 156.82953849278113
At time: 70.60627722740173 and batch: 1000, loss is 5.00802393913269 and perplexity is 149.60880774867945
At time: 71.68594622612 and batch: 1050, loss is 4.915748462677002 and perplexity is 136.42137791040628
At time: 72.7647852897644 and batch: 1100, loss is 4.991443729400634 and perplexity is 147.1487131378446
At time: 73.86200141906738 and batch: 1150, loss is 4.89186800956726 and perplexity is 133.20216471219123
At time: 74.9523446559906 and batch: 1200, loss is 4.980393533706665 and perplexity is 145.53164199244463
At time: 76.03051733970642 and batch: 1250, loss is 4.922336883544922 and perplexity is 137.32314671773307
At time: 77.11061263084412 and batch: 1300, loss is 4.951525106430053 and perplexity is 141.39043503314042
At time: 78.18932318687439 and batch: 1350, loss is 4.8611179542541505 and perplexity is 129.16852592169204
At time: 79.26827263832092 and batch: 1400, loss is 4.873434038162231 and perplexity is 130.7692131911614
At time: 80.3470892906189 and batch: 1450, loss is 4.816746711730957 and perplexity is 123.56245190949936
At time: 81.42515659332275 and batch: 1500, loss is 4.793655052185058 and perplexity is 120.74188100098965
At time: 82.50375866889954 and batch: 1550, loss is 4.781467008590698 and perplexity is 119.27920537529602
At time: 83.58271098136902 and batch: 1600, loss is 4.837310523986816 and perplexity is 126.12967242665279
At time: 84.66199278831482 and batch: 1650, loss is 4.8010564708709715 and perplexity is 121.63885757000311
At time: 85.73913860321045 and batch: 1700, loss is 4.8279323387146 and perplexity is 124.9523342669368
At time: 86.81724572181702 and batch: 1750, loss is 4.83731255531311 and perplexity is 126.12992863743304
At time: 87.89607810974121 and batch: 1800, loss is 4.789710626602173 and perplexity is 120.26656168375202
At time: 88.9746572971344 and batch: 1850, loss is 4.785353679656982 and perplexity is 119.74370650845721
At time: 90.05394244194031 and batch: 1900, loss is 4.8615279865264895 and perplexity is 129.2215000456984
At time: 91.13388657569885 and batch: 1950, loss is 4.7791564083099365 and perplexity is 119.00391697307407
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.595554653433866 and perplexity of 99.0430548861533
finished 2 epochs...
Completing Train Step...
At time: 94.56142830848694 and batch: 50, loss is 4.741363592147827 and perplexity is 114.59034969592182
At time: 95.63344311714172 and batch: 100, loss is 4.687697772979736 and perplexity is 108.60286332886362
At time: 96.69250917434692 and batch: 150, loss is 4.640024480819702 and perplexity is 103.54688246481324
At time: 97.76240873336792 and batch: 200, loss is 4.626251697540283 and perplexity is 102.130529642475
At time: 98.83439064025879 and batch: 250, loss is 4.63149694442749 and perplexity is 102.66763688377894
At time: 99.91093564033508 and batch: 300, loss is 4.651999340057373 and perplexity is 104.7942956995104
At time: 100.98245477676392 and batch: 350, loss is 4.655640659332275 and perplexity is 105.17658077695164
At time: 102.0597414970398 and batch: 400, loss is 4.615111618041992 and perplexity is 100.99910122527305
At time: 103.13803172111511 and batch: 450, loss is 4.602204790115357 and perplexity is 99.70389965707557
At time: 104.21648693084717 and batch: 500, loss is 4.611214733123779 and perplexity is 100.60628522742309
At time: 105.33383893966675 and batch: 550, loss is 4.574138145446778 and perplexity is 96.9444511051499
At time: 106.42655920982361 and batch: 600, loss is 4.550545749664306 and perplexity is 94.68406801534431
At time: 107.53471684455872 and batch: 650, loss is 4.618175992965698 and perplexity is 101.30907503380287
At time: 108.61137819290161 and batch: 700, loss is 4.630234994888306 and perplexity is 102.53815722230706
At time: 109.69087815284729 and batch: 750, loss is 4.594942798614502 and perplexity is 98.98247345110816
At time: 110.80576539039612 and batch: 800, loss is 4.570758800506592 and perplexity is 96.61739529327745
At time: 111.8872377872467 and batch: 850, loss is 4.5602023315429685 and perplexity is 95.60282133965535
At time: 112.96703243255615 and batch: 900, loss is 4.550232973098755 and perplexity is 94.65445768868757
At time: 114.0464494228363 and batch: 950, loss is 4.630321140289307 and perplexity is 102.54699079345919
At time: 115.12348484992981 and batch: 1000, loss is 4.599047956466674 and perplexity is 99.38964731389486
At time: 116.20075225830078 and batch: 1050, loss is 4.5228018379211425 and perplexity is 92.09326724427827
At time: 117.27730202674866 and batch: 1100, loss is 4.583940925598145 and perplexity is 97.89944941798672
At time: 118.35423350334167 and batch: 1150, loss is 4.520786037445069 and perplexity is 91.90781257492827
At time: 119.42757225036621 and batch: 1200, loss is 4.60620982170105 and perplexity is 100.10401763214956
At time: 120.50568699836731 and batch: 1250, loss is 4.566871004104614 and perplexity is 96.24249577021206
At time: 121.58735227584839 and batch: 1300, loss is 4.588987770080567 and perplexity is 98.39478159497774
At time: 122.6709418296814 and batch: 1350, loss is 4.481597986221313 and perplexity is 88.37578318312472
At time: 123.75576090812683 and batch: 1400, loss is 4.497146043777466 and perplexity is 89.7605925977526
At time: 124.86253595352173 and batch: 1450, loss is 4.442367963790893 and perplexity is 84.975923531054
At time: 125.95896530151367 and batch: 1500, loss is 4.441732721328735 and perplexity is 84.92196035783016
At time: 127.05186057090759 and batch: 1550, loss is 4.435789585113525 and perplexity is 84.41875437175915
At time: 128.12765216827393 and batch: 1600, loss is 4.50555908203125 and perplexity is 90.5189374160272
At time: 129.20384001731873 and batch: 1650, loss is 4.460961980819702 and perplexity is 86.57074845213654
At time: 130.2791543006897 and batch: 1700, loss is 4.493885688781738 and perplexity is 89.46841775692407
At time: 131.351788520813 and batch: 1750, loss is 4.496311941146851 and perplexity is 89.68575426710439
At time: 132.42241668701172 and batch: 1800, loss is 4.447786722183228 and perplexity is 85.4376373578988
At time: 133.4944794178009 and batch: 1850, loss is 4.473020105361939 and perplexity is 87.62094831430522
At time: 134.5652186870575 and batch: 1900, loss is 4.559109058380127 and perplexity is 95.49835845443212
At time: 135.6369390487671 and batch: 1950, loss is 4.490545797348022 and perplexity is 89.17010140429171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.454536473473837 and perplexity of 86.01627077993025
finished 3 epochs...
Completing Train Step...
At time: 139.0093171596527 and batch: 50, loss is 4.459994382858277 and perplexity is 86.48702328509793
At time: 140.05503916740417 and batch: 100, loss is 4.410790071487427 and perplexity is 82.33448794519825
At time: 141.0888934135437 and batch: 150, loss is 4.376668434143067 and perplexity is 79.5724903216551
At time: 142.12447452545166 and batch: 200, loss is 4.370531177520752 and perplexity is 79.08562905291939
At time: 143.16333150863647 and batch: 250, loss is 4.363479146957397 and perplexity is 78.52987667427715
At time: 144.21097016334534 and batch: 300, loss is 4.389308567047119 and perplexity is 80.58468080928455
At time: 145.2626347541809 and batch: 350, loss is 4.399467868804932 and perplexity is 81.40753764680179
At time: 146.31437134742737 and batch: 400, loss is 4.366076164245605 and perplexity is 78.73408517336871
At time: 147.3660056591034 and batch: 450, loss is 4.368972568511963 and perplexity is 78.96246148898302
At time: 148.4460084438324 and batch: 500, loss is 4.381137933731079 and perplexity is 79.928935506794
At time: 149.49302554130554 and batch: 550, loss is 4.3468091011047365 and perplexity is 77.23163100079695
At time: 150.5453805923462 and batch: 600, loss is 4.324584417343139 and perplexity is 75.53411566764146
At time: 151.60180044174194 and batch: 650, loss is 4.38792085647583 and perplexity is 80.47293015255894
At time: 152.65898442268372 and batch: 700, loss is 4.4109904575347905 and perplexity is 82.3509882809626
At time: 153.74276733398438 and batch: 750, loss is 4.379576597213745 and perplexity is 79.80423691456072
At time: 154.79903984069824 and batch: 800, loss is 4.355952472686767 and perplexity is 77.94102669293953
At time: 155.85740303993225 and batch: 850, loss is 4.344257125854492 and perplexity is 77.03478906465055
At time: 156.95985436439514 and batch: 900, loss is 4.329131803512573 and perplexity is 75.87838062014436
At time: 158.01981353759766 and batch: 950, loss is 4.425351896286011 and perplexity is 83.5422002400806
At time: 159.08034324645996 and batch: 1000, loss is 4.391575956344605 and perplexity is 80.76760495384806
At time: 160.14127326011658 and batch: 1050, loss is 4.3195870494842525 and perplexity is 75.15758551919721
At time: 161.20164346694946 and batch: 1100, loss is 4.370439891815185 and perplexity is 79.07840999497455
At time: 162.26246285438538 and batch: 1150, loss is 4.322442193031311 and perplexity is 75.37247784273954
At time: 163.32468724250793 and batch: 1200, loss is 4.4046289825439455 and perplexity is 81.8287773056557
At time: 164.40471076965332 and batch: 1250, loss is 4.376660242080688 and perplexity is 79.5718384615208
At time: 165.46556854248047 and batch: 1300, loss is 4.391560888290405 and perplexity is 80.76638795236796
At time: 166.5268292427063 and batch: 1350, loss is 4.279218463897705 and perplexity is 72.18400355185031
At time: 167.5892562866211 and batch: 1400, loss is 4.303192911148071 and perplexity is 73.93548666562461
At time: 168.65046405792236 and batch: 1450, loss is 4.2455474424362185 and perplexity is 69.79395786174851
At time: 169.71193981170654 and batch: 1500, loss is 4.250048117637634 and perplexity is 70.10878573467444
At time: 170.77415132522583 and batch: 1550, loss is 4.246805801391601 and perplexity is 69.8818389950646
At time: 171.83556413650513 and batch: 1600, loss is 4.324568552970886 and perplexity is 75.53291737581779
At time: 172.8964352607727 and batch: 1650, loss is 4.275592761039734 and perplexity is 71.92275968637392
At time: 173.95717787742615 and batch: 1700, loss is 4.3026818799972535 and perplexity is 73.89771298137435
At time: 175.0169641971588 and batch: 1750, loss is 4.311417770385742 and perplexity is 74.54610331183831
At time: 176.07870888710022 and batch: 1800, loss is 4.261599540710449 and perplexity is 70.92333753858587
At time: 177.1414806842804 and batch: 1850, loss is 4.299330930709839 and perplexity is 73.65049992325507
At time: 178.20212078094482 and batch: 1900, loss is 4.3822597408294675 and perplexity is 80.01865066615495
At time: 179.2630000114441 and batch: 1950, loss is 4.315002040863037 and perplexity is 74.81377612845752
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.393070664516715 and perplexity of 80.88841922155787
finished 4 epochs...
Completing Train Step...
At time: 182.63190531730652 and batch: 50, loss is 4.28644323348999 and perplexity is 72.70740479578149
At time: 183.68117952346802 and batch: 100, loss is 4.2446365690231325 and perplexity is 69.73041334603667
At time: 184.71341061592102 and batch: 150, loss is 4.218622236251831 and perplexity is 67.93981476316011
At time: 185.74540281295776 and batch: 200, loss is 4.217807450294495 and perplexity is 67.88448090183486
At time: 186.78331065177917 and batch: 250, loss is 4.201727685928344 and perplexity is 66.80164365998908
At time: 187.82587695121765 and batch: 300, loss is 4.227084717750549 and perplexity is 68.51719377253396
At time: 188.8804054260254 and batch: 350, loss is 4.2342379188537596 and perplexity is 69.00906817952949
At time: 189.9491937160492 and batch: 400, loss is 4.208857893943787 and perplexity is 67.27965541149989
At time: 191.00505542755127 and batch: 450, loss is 4.221054248809814 and perplexity is 68.10524633013571
At time: 192.0620493888855 and batch: 500, loss is 4.2314786529541015 and perplexity is 68.81891627141667
At time: 193.1276843547821 and batch: 550, loss is 4.196035327911377 and perplexity is 66.42246502230826
At time: 194.19252705574036 and batch: 600, loss is 4.180464835166931 and perplexity is 65.39624462425114
At time: 195.25780153274536 and batch: 650, loss is 4.2428353404998775 and perplexity is 69.6049259862132
At time: 196.3236916065216 and batch: 700, loss is 4.2659687805175786 and perplexity is 71.2338965675958
At time: 197.3893654346466 and batch: 750, loss is 4.237039937973022 and perplexity is 69.2027040670092
At time: 198.4578776359558 and batch: 800, loss is 4.215435419082642 and perplexity is 67.72364762052798
At time: 199.5256803035736 and batch: 850, loss is 4.2010633087158205 and perplexity is 66.75727690994304
At time: 200.59142661094666 and batch: 900, loss is 4.183463554382325 and perplexity is 65.59264392562622
At time: 201.65909075737 and batch: 950, loss is 4.2878865718841555 and perplexity is 72.81242195408046
At time: 202.72626113891602 and batch: 1000, loss is 4.252881917953491 and perplexity is 70.30774180157454
At time: 203.79146575927734 and batch: 1050, loss is 4.187212419509888 and perplexity is 65.83900339675102
At time: 204.85709524154663 and batch: 1100, loss is 4.2292094326019285 and perplexity is 68.66292803877182
At time: 205.92379307746887 and batch: 1150, loss is 4.1852771234512325 and perplexity is 65.71170864921359
At time: 206.98970127105713 and batch: 1200, loss is 4.270112648010254 and perplexity is 71.5296928429684
At time: 208.05542063713074 and batch: 1250, loss is 4.246597385406494 and perplexity is 69.86727602038039
At time: 209.1214108467102 and batch: 1300, loss is 4.259532461166382 and perplexity is 70.77688477526564
At time: 210.18637418746948 and batch: 1350, loss is 4.143489537239074 and perplexity is 63.0223570494224
At time: 211.2521960735321 and batch: 1400, loss is 4.167864255905151 and perplexity is 64.57738395432253
At time: 212.31717801094055 and batch: 1450, loss is 4.1161503410339355 and perplexity is 61.32271574083496
At time: 213.3821737766266 and batch: 1500, loss is 4.12169732093811 and perplexity is 61.66381677840849
At time: 214.44746041297913 and batch: 1550, loss is 4.118117818832397 and perplexity is 61.44348558963652
At time: 215.5139880180359 and batch: 1600, loss is 4.2007938623428345 and perplexity is 66.73929182692575
At time: 216.57874870300293 and batch: 1650, loss is 4.151621880531311 and perplexity is 63.53696614481018
At time: 217.64310383796692 and batch: 1700, loss is 4.177709441184998 and perplexity is 65.21630022807337
At time: 218.7089102268219 and batch: 1750, loss is 4.186904635429382 and perplexity is 65.81874231780786
At time: 219.77465748786926 and batch: 1800, loss is 4.135092668533325 and perplexity is 62.49538215753972
At time: 220.83985376358032 and batch: 1850, loss is 4.173527345657349 and perplexity is 64.94412895038907
At time: 221.90130352973938 and batch: 1900, loss is 4.2582325887680055 and perplexity is 70.68494362513073
At time: 222.96864938735962 and batch: 1950, loss is 4.186310958862305 and perplexity is 65.77967886949355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368296068768169 and perplexity of 78.90906146860297
finished 5 epochs...
Completing Train Step...
At time: 226.5357313156128 and batch: 50, loss is 4.167170262336731 and perplexity is 64.53258321270418
At time: 227.56251454353333 and batch: 100, loss is 4.129578337669373 and perplexity is 62.151710373675755
At time: 228.58904314041138 and batch: 150, loss is 4.10821786403656 and perplexity is 60.83819895856885
At time: 229.62144947052002 and batch: 200, loss is 4.105338978767395 and perplexity is 60.66330463492385
At time: 230.67089462280273 and batch: 250, loss is 4.084318585395813 and perplexity is 59.40144694383952
At time: 231.71332120895386 and batch: 300, loss is 4.11103925704956 and perplexity is 61.010089799818694
At time: 232.752135515213 and batch: 350, loss is 4.116866855621338 and perplexity is 61.36667010629394
At time: 233.79705810546875 and batch: 400, loss is 4.092282786369323 and perplexity is 59.8764208888241
At time: 234.8428599834442 and batch: 450, loss is 4.107767963409424 and perplexity is 60.81083397092769
At time: 235.9260492324829 and batch: 500, loss is 4.122043313980103 and perplexity is 61.68515572130655
At time: 236.97865772247314 and batch: 550, loss is 4.089527387619018 and perplexity is 59.71166456246104
At time: 238.02594232559204 and batch: 600, loss is 4.0762264966964725 and perplexity is 58.92270479069374
At time: 239.0734419822693 and batch: 650, loss is 4.133919525146484 and perplexity is 62.42210910155765
At time: 240.1274425983429 and batch: 700, loss is 4.156860814094544 and perplexity is 63.87070554519611
At time: 241.20591402053833 and batch: 750, loss is 4.135900073051452 and perplexity is 62.54586158737338
At time: 242.2631015777588 and batch: 800, loss is 4.11242184638977 and perplexity is 61.09450003852307
At time: 243.36928343772888 and batch: 850, loss is 4.09868522644043 and perplexity is 60.261005912804116
At time: 244.4265058040619 and batch: 900, loss is 4.075339827537537 and perplexity is 58.870483000741366
At time: 245.48972272872925 and batch: 950, loss is 4.182601585388183 and perplexity is 65.53612946067597
At time: 246.5668032169342 and batch: 1000, loss is 4.149951419830322 and perplexity is 63.43091873847745
At time: 247.62311553955078 and batch: 1050, loss is 4.088580865859985 and perplexity is 59.65517291219026
At time: 248.69665098190308 and batch: 1100, loss is 4.125365324020386 and perplexity is 61.89041517616814
At time: 249.78616166114807 and batch: 1150, loss is 4.084018182754517 and perplexity is 59.383605272257554
At time: 250.84633135795593 and batch: 1200, loss is 4.172919092178344 and perplexity is 64.90463846934284
At time: 251.90288615226746 and batch: 1250, loss is 4.147567677497864 and perplexity is 63.27989584363979
At time: 252.96005058288574 and batch: 1300, loss is 4.157818760871887 and perplexity is 63.93191959696043
At time: 254.01684021949768 and batch: 1350, loss is 4.040219101905823 and perplexity is 56.838794929570895
At time: 255.07294917106628 and batch: 1400, loss is 4.071063857078553 and perplexity is 58.61929197994598
At time: 256.1294279098511 and batch: 1450, loss is 4.012248015403747 and perplexity is 55.27098102680885
At time: 257.18590092658997 and batch: 1500, loss is 4.030482869148255 and perplexity is 56.288084465448186
At time: 258.2444143295288 and batch: 1550, loss is 4.024502477645874 and perplexity is 55.95246425384626
At time: 259.30221581459045 and batch: 1600, loss is 4.108870072364807 and perplexity is 60.87789108096455
At time: 260.35921263694763 and batch: 1650, loss is 4.055188012123108 and perplexity is 57.696009525737395
At time: 261.417578458786 and batch: 1700, loss is 4.082095794677734 and perplexity is 59.26955659555689
At time: 262.47406673431396 and batch: 1750, loss is 4.0897607278823855 and perplexity is 59.72559932370335
At time: 263.53020310401917 and batch: 1800, loss is 4.043133907318115 and perplexity is 57.004710645203154
At time: 264.58618998527527 and batch: 1850, loss is 4.0795235919952395 and perplexity is 59.117299185498275
At time: 265.6435081958771 and batch: 1900, loss is 4.164941387176514 and perplexity is 64.38890831713971
At time: 266.70098853111267 and batch: 1950, loss is 4.093779048919678 and perplexity is 59.96607879420519
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357246434411337 and perplexity of 78.0419446761768
finished 6 epochs...
Completing Train Step...
At time: 270.0520088672638 and batch: 50, loss is 4.075238814353943 and perplexity is 58.864536606170944
At time: 271.06902980804443 and batch: 100, loss is 4.040686802864075 and perplexity is 56.86538470597259
At time: 272.098295211792 and batch: 150, loss is 4.021423726081848 and perplexity is 55.780465423707874
At time: 273.12585377693176 and batch: 200, loss is 4.019032874107361 and perplexity is 55.64726188623326
At time: 274.16346764564514 and batch: 250, loss is 3.998612699508667 and perplexity is 54.52245850836182
At time: 275.2057888507843 and batch: 300, loss is 4.02521577835083 and perplexity is 55.99238942367564
At time: 276.24752593040466 and batch: 350, loss is 4.028609371185302 and perplexity is 56.18272757763786
At time: 277.2885160446167 and batch: 400, loss is 4.003908338546753 and perplexity is 54.81195562766489
At time: 278.3276832103729 and batch: 450, loss is 4.026214113235474 and perplexity is 56.04831649163823
At time: 279.36749148368835 and batch: 500, loss is 4.039284586906433 and perplexity is 56.785703034611906
At time: 280.4073152542114 and batch: 550, loss is 4.0067668056488035 and perplexity is 54.96885794284347
At time: 281.4447400569916 and batch: 600, loss is 3.99424298286438 and perplexity is 54.28473059401545
At time: 282.485657453537 and batch: 650, loss is 4.0465112400054934 and perplexity is 57.19755999269295
At time: 283.5326716899872 and batch: 700, loss is 4.0726879644393925 and perplexity is 58.71457335618624
At time: 284.57940697669983 and batch: 750, loss is 4.054377770423889 and perplexity is 57.649280746300334
At time: 285.62738966941833 and batch: 800, loss is 4.032087779045105 and perplexity is 56.378494299694395
At time: 286.6808340549469 and batch: 850, loss is 4.018143591880798 and perplexity is 55.59779776232384
At time: 287.7366907596588 and batch: 900, loss is 3.992034559249878 and perplexity is 54.16497919264638
At time: 288.79211139678955 and batch: 950, loss is 4.105926823616028 and perplexity is 60.69897572956195
At time: 289.8480637073517 and batch: 1000, loss is 4.068869419097901 and perplexity is 58.49079661834191
At time: 290.9053564071655 and batch: 1050, loss is 4.0138576698303225 and perplexity is 55.36001984772105
At time: 291.9629373550415 and batch: 1100, loss is 4.043353729248047 and perplexity is 57.01724290809502
At time: 293.0192677974701 and batch: 1150, loss is 4.002626185417175 and perplexity is 54.741723341112916
At time: 294.07567143440247 and batch: 1200, loss is 4.092910351753235 and perplexity is 59.91400905116759
At time: 295.13180351257324 and batch: 1250, loss is 4.070890936851502 and perplexity is 58.60915639501631
At time: 296.189106464386 and batch: 1300, loss is 4.075805945396423 and perplexity is 58.897929980496066
At time: 297.24511075019836 and batch: 1350, loss is 3.964221992492676 and perplexity is 52.67926857581263
At time: 298.3020987510681 and batch: 1400, loss is 3.9946287298202514 and perplexity is 54.3056748029151
At time: 299.3589107990265 and batch: 1450, loss is 3.9345376300811767 and perplexity is 51.13849958556651
At time: 300.41611981391907 and batch: 1500, loss is 3.9504299688339235 and perplexity is 51.95770222536561
At time: 301.4731149673462 and batch: 1550, loss is 3.9490749931335447 and perplexity is 51.88734847597703
At time: 302.52930641174316 and batch: 1600, loss is 4.033454675674438 and perplexity is 56.455610566495075
At time: 303.5862982273102 and batch: 1650, loss is 3.9816322231292727 and perplexity is 53.60445729613566
At time: 304.64371609687805 and batch: 1700, loss is 4.007506537437439 and perplexity is 55.00953519772313
At time: 305.7077302932739 and batch: 1750, loss is 4.017887029647827 and perplexity is 55.583535296864916
At time: 306.764773607254 and batch: 1800, loss is 3.966074628829956 and perplexity is 52.776954563362295
At time: 307.8223910331726 and batch: 1850, loss is 4.007281842231751 and perplexity is 54.99717620745201
At time: 308.87804913520813 and batch: 1900, loss is 4.09207405090332 and perplexity is 59.86392386053914
At time: 309.9349398612976 and batch: 1950, loss is 4.0193177318573 and perplexity is 55.66311569797782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35441042877907 and perplexity of 77.82093082791448
finished 7 epochs...
Completing Train Step...
At time: 313.37080121040344 and batch: 50, loss is 4.00218436717987 and perplexity is 54.717542791496555
At time: 314.3962528705597 and batch: 100, loss is 3.971013379096985 and perplexity is 53.03825147077765
At time: 315.4225561618805 and batch: 150, loss is 3.9518620443344115 and perplexity is 52.03216288169947
At time: 316.4489505290985 and batch: 200, loss is 3.9495103883743288 and perplexity is 51.909944899391014
At time: 317.47601532936096 and batch: 250, loss is 3.9319892263412477 and perplexity is 51.00834395695346
At time: 318.52721333503723 and batch: 300, loss is 3.9531547117233274 and perplexity is 52.09946665315467
At time: 319.59838581085205 and batch: 350, loss is 3.958679986000061 and perplexity is 52.3881272261363
At time: 320.6442959308624 and batch: 400, loss is 3.931068124771118 and perplexity is 50.96138172305903
At time: 321.70440101623535 and batch: 450, loss is 3.960063557624817 and perplexity is 52.460660118095426
At time: 322.74916529655457 and batch: 500, loss is 3.9738741159439086 and perplexity is 53.19019718578471
At time: 323.7939028739929 and batch: 550, loss is 3.943823504447937 and perplexity is 51.615576879839494
At time: 324.8398382663727 and batch: 600, loss is 3.9294951820373534 and perplexity is 50.8812853979556
At time: 325.88645696640015 and batch: 650, loss is 3.9805180263519286 and perplexity is 53.54476464342105
At time: 326.93262791633606 and batch: 700, loss is 4.006550960540771 and perplexity is 54.95699446414537
At time: 327.97780203819275 and batch: 750, loss is 3.9886575412750243 and perplexity is 53.98237159242126
At time: 329.02280497550964 and batch: 800, loss is 3.9662054061889647 and perplexity is 52.78385704543096
At time: 330.0700349807739 and batch: 850, loss is 3.9487211656570436 and perplexity is 51.868992554009715
At time: 331.1170356273651 and batch: 900, loss is 3.9181019115447997 and perplexity is 50.304871008123904
At time: 332.164119720459 and batch: 950, loss is 4.0407823467254635 and perplexity is 56.870818103966535
At time: 333.21076822280884 and batch: 1000, loss is 4.003589768409729 and perplexity is 54.794496956503274
At time: 334.25862073898315 and batch: 1050, loss is 3.9502020931243895 and perplexity is 51.94586367601539
At time: 335.3053481578827 and batch: 1100, loss is 3.9785910129547117 and perplexity is 53.44168251682043
At time: 336.35337710380554 and batch: 1150, loss is 3.9379899168014525 and perplexity is 51.315349441139
At time: 337.40134716033936 and batch: 1200, loss is 4.030461363792419 and perplexity is 56.286873983178424
At time: 338.44765424728394 and batch: 1250, loss is 4.008339238166809 and perplexity is 55.05536075464402
At time: 339.51842737197876 and batch: 1300, loss is 4.011242847442627 and perplexity is 55.215452320014876
At time: 340.5700240135193 and batch: 1350, loss is 3.90104856967926 and perplexity is 49.454278184194784
At time: 341.61535596847534 and batch: 1400, loss is 3.9305959224700926 and perplexity is 50.93732332200916
At time: 342.661306142807 and batch: 1450, loss is 3.872262964248657 and perplexity is 48.05100083581777
At time: 343.70804738998413 and batch: 1500, loss is 3.8812290906906126 and perplexity is 48.48376941463684
At time: 344.7547814846039 and batch: 1550, loss is 3.884808130264282 and perplexity is 48.65760564185752
At time: 345.80106925964355 and batch: 1600, loss is 3.9753117609024047 and perplexity is 53.266720798323085
At time: 346.8470160961151 and batch: 1650, loss is 3.921176233291626 and perplexity is 50.45976233793161
At time: 347.8934473991394 and batch: 1700, loss is 3.947905921936035 and perplexity is 51.82672391547716
At time: 348.94074726104736 and batch: 1750, loss is 3.9549599266052247 and perplexity is 52.193602327692034
At time: 349.98748445510864 and batch: 1800, loss is 3.9105977630615234 and perplexity is 49.92878864044658
At time: 351.036404132843 and batch: 1850, loss is 3.94680287361145 and perplexity is 51.769588052095834
At time: 352.0843462944031 and batch: 1900, loss is 4.027957220077514 and perplexity is 56.14609989429983
At time: 353.1309263706207 and batch: 1950, loss is 3.9549222564697266 and perplexity is 52.191636224652136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360748716842297 and perplexity of 78.31574879770328
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 356.4404754638672 and batch: 50, loss is 3.9769465494155884 and perplexity is 53.35387183896973
At time: 357.47431921958923 and batch: 100, loss is 3.9652960681915284 and perplexity is 52.73588049532427
At time: 358.5110733509064 and batch: 150, loss is 3.9440436458587644 and perplexity is 51.62694085654954
At time: 359.5647029876709 and batch: 200, loss is 3.946701021194458 and perplexity is 51.76431546294358
At time: 360.5895736217499 and batch: 250, loss is 3.924161128997803 and perplexity is 50.61060447790149
At time: 361.62021684646606 and batch: 300, loss is 3.9439401388168336 and perplexity is 51.62159738116598
At time: 362.66447281837463 and batch: 350, loss is 3.9541878747940062 and perplexity is 52.15332171384219
At time: 363.71224188804626 and batch: 400, loss is 3.9174494552612305 and perplexity is 50.272059983983915
At time: 364.75838351249695 and batch: 450, loss is 3.9316096782684324 and perplexity is 50.98898751189018
At time: 365.8111982345581 and batch: 500, loss is 3.9335386466979982 and perplexity is 51.087438583032814
At time: 366.86483573913574 and batch: 550, loss is 3.9085946464538575 and perplexity is 49.82887555690697
At time: 367.91148138046265 and batch: 600, loss is 3.8825377130508425 and perplexity is 48.547257891561024
At time: 368.96019649505615 and batch: 650, loss is 3.9210786485671996 and perplexity is 50.454838476179994
At time: 370.0351827144623 and batch: 700, loss is 3.9421534729003906 and perplexity is 51.529449176114085
At time: 371.0838315486908 and batch: 750, loss is 3.9084851932525635 and perplexity is 49.82342192542455
At time: 372.1319124698639 and batch: 800, loss is 3.8844342613220215 and perplexity is 48.63941747451057
At time: 373.17782974243164 and batch: 850, loss is 3.87271812915802 and perplexity is 48.07287694349861
At time: 374.2601125240326 and batch: 900, loss is 3.835102276802063 and perplexity is 46.29816265382433
At time: 375.305783033371 and batch: 950, loss is 3.94056423664093 and perplexity is 51.44762174583542
At time: 376.35396361351013 and batch: 1000, loss is 3.9007190370559695 and perplexity is 49.43798407104018
At time: 377.40144538879395 and batch: 1050, loss is 3.84852915763855 and perplexity is 46.92399465043325
At time: 378.45157289505005 and batch: 1100, loss is 3.8672555685043335 and perplexity is 47.810991870157395
At time: 379.4983801841736 and batch: 1150, loss is 3.8262009382247926 and perplexity is 45.88787579271568
At time: 380.54568576812744 and batch: 1200, loss is 3.9063880014419556 and perplexity is 49.7190421434551
At time: 381.592253446579 and batch: 1250, loss is 3.881294765472412 and perplexity is 48.48695368017579
At time: 382.6394429206848 and batch: 1300, loss is 3.879237484931946 and perplexity is 48.38730495174415
At time: 383.6867105960846 and batch: 1350, loss is 3.7614660978317263 and perplexity is 43.01143875312562
At time: 384.7335274219513 and batch: 1400, loss is 3.786816291809082 and perplexity is 44.11572486547632
At time: 385.7824184894562 and batch: 1450, loss is 3.7172104501724244 and perplexity is 41.14944542721755
At time: 386.8293778896332 and batch: 1500, loss is 3.717457013130188 and perplexity is 41.15959260710036
At time: 387.87573170661926 and batch: 1550, loss is 3.716247320175171 and perplexity is 41.10983224134222
At time: 388.9227759838104 and batch: 1600, loss is 3.7974731492996217 and perplexity is 44.58837386179221
At time: 389.9699971675873 and batch: 1650, loss is 3.7382776403427123 and perplexity is 42.025544691573465
At time: 391.015367269516 and batch: 1700, loss is 3.7527325344085694 and perplexity is 42.63743121143349
At time: 392.06161236763 and batch: 1750, loss is 3.7517178201675416 and perplexity is 42.59418834606846
At time: 393.10823130607605 and batch: 1800, loss is 3.7010395622253416 and perplexity is 40.489373712863355
At time: 394.15263843536377 and batch: 1850, loss is 3.7261784744262694 and perplexity is 41.52013434102711
At time: 395.19638562202454 and batch: 1900, loss is 3.8042310905456542 and perplexity is 44.890719940452
At time: 396.2449531555176 and batch: 1950, loss is 3.72683265209198 and perplexity is 41.54730477176582
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.29593505859375 and perplexity of 73.40081643077934
finished 9 epochs...
Completing Train Step...
At time: 399.581511259079 and batch: 50, loss is 3.895626106262207 and perplexity is 49.1868399123397
At time: 400.61366081237793 and batch: 100, loss is 3.869015374183655 and perplexity is 47.895204001945224
At time: 401.6296730041504 and batch: 150, loss is 3.8454023122787477 and perplexity is 46.77749972833955
At time: 402.6532483100891 and batch: 200, loss is 3.8434642791748046 and perplexity is 46.68693117612027
At time: 403.67834520339966 and batch: 250, loss is 3.819328236579895 and perplexity is 45.57358336940866
At time: 404.7097473144531 and batch: 300, loss is 3.840092725753784 and perplexity is 46.52978874949751
At time: 405.7441635131836 and batch: 350, loss is 3.8537683486938477 and perplexity is 47.17048356090702
At time: 406.78500175476074 and batch: 400, loss is 3.8196794986724854 and perplexity is 45.589594453548685
At time: 407.82503056526184 and batch: 450, loss is 3.839410452842712 and perplexity is 46.49805356233615
At time: 408.86533761024475 and batch: 500, loss is 3.845150966644287 and perplexity is 46.765743885443634
At time: 409.9055211544037 and batch: 550, loss is 3.8211985301971434 and perplexity is 45.658899109372044
At time: 410.9467751979828 and batch: 600, loss is 3.798332004547119 and perplexity is 44.62668527028292
At time: 411.98580718040466 and batch: 650, loss is 3.8411126232147215 and perplexity is 46.57726857106014
At time: 413.02501606941223 and batch: 700, loss is 3.863103609085083 and perplexity is 47.61289410364222
At time: 414.0658118724823 and batch: 750, loss is 3.8318893909454346 and perplexity is 46.149650645664174
At time: 415.1056227684021 and batch: 800, loss is 3.81156268119812 and perplexity is 45.22104976501471
At time: 416.1691892147064 and batch: 850, loss is 3.803250298500061 and perplexity is 44.84671306373848
At time: 417.24305629730225 and batch: 900, loss is 3.766394634246826 and perplexity is 43.223945438598015
At time: 418.2905113697052 and batch: 950, loss is 3.8754523468017577 and perplexity is 48.20449851082896
At time: 419.33079385757446 and batch: 1000, loss is 3.8340672302246093 and perplexity is 46.2502666905795
At time: 420.40011262893677 and batch: 1050, loss is 3.7872531366348268 and perplexity is 44.13500080160771
At time: 421.43987703323364 and batch: 1100, loss is 3.805335030555725 and perplexity is 44.94030396613445
At time: 422.49043703079224 and batch: 1150, loss is 3.767319769859314 and perplexity is 43.263951952707586
At time: 423.54009461402893 and batch: 1200, loss is 3.8500110340118407 and perplexity is 46.99358175645611
At time: 424.5881927013397 and batch: 1250, loss is 3.8306131410598754 and perplexity is 46.09078972791827
At time: 425.6331934928894 and batch: 1300, loss is 3.828361315727234 and perplexity is 45.98711808902632
At time: 426.6819748878479 and batch: 1350, loss is 3.7113735675811768 and perplexity is 40.90996054804609
At time: 427.72551465034485 and batch: 1400, loss is 3.7415776109695433 and perplexity is 42.16445683156257
At time: 428.7680516242981 and batch: 1450, loss is 3.6743611764907835 and perplexity is 39.42346417548855
At time: 429.81178975105286 and batch: 1500, loss is 3.6750404024124146 and perplexity is 39.45025071030161
At time: 430.8633668422699 and batch: 1550, loss is 3.6791705751419066 and perplexity is 39.61352400130654
At time: 431.91361451148987 and batch: 1600, loss is 3.7650569438934327 and perplexity is 43.166163839309455
At time: 432.98280930519104 and batch: 1650, loss is 3.7087136793136595 and perplexity is 40.80128921483271
At time: 434.07108521461487 and batch: 1700, loss is 3.7258514261245725 and perplexity is 41.506557471871666
At time: 435.1414575576782 and batch: 1750, loss is 3.7277546310424805 and perplexity is 41.5856281761868
At time: 436.1889138221741 and batch: 1800, loss is 3.680345435142517 and perplexity is 39.660091696043395
At time: 437.26806139945984 and batch: 1850, loss is 3.709515609741211 and perplexity is 40.834022133144806
At time: 438.3161189556122 and batch: 1900, loss is 3.7923767518997193 and perplexity is 44.361711859592276
At time: 439.3648660182953 and batch: 1950, loss is 3.7162619924545286 and perplexity is 41.11043542071021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.297801598837209 and perplexity of 73.53794995135344
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 442.7852098941803 and batch: 50, loss is 3.8761189460754393 and perplexity is 48.23664230684973
At time: 443.8186638355255 and batch: 100, loss is 3.8801550483703613 and perplexity is 48.431723749067096
At time: 444.8363902568817 and batch: 150, loss is 3.863274235725403 and perplexity is 47.62101882492627
At time: 445.88407158851624 and batch: 200, loss is 3.865342240333557 and perplexity is 47.71960121058165
At time: 446.93027997016907 and batch: 250, loss is 3.847809567451477 and perplexity is 46.89024075028871
At time: 447.9578595161438 and batch: 300, loss is 3.866320447921753 and perplexity is 47.76630372524454
At time: 448.9967200756073 and batch: 350, loss is 3.8874637413024904 and perplexity is 48.78699304175696
At time: 450.0386347770691 and batch: 400, loss is 3.8570005083084107 and perplexity is 47.32319275016493
At time: 451.08028984069824 and batch: 450, loss is 3.878234052658081 and perplexity is 48.33877592018036
At time: 452.1205167770386 and batch: 500, loss is 3.8768825149536132 and perplexity is 48.273488371166636
At time: 453.1987040042877 and batch: 550, loss is 3.8468538999557493 and perplexity is 46.84545067695432
At time: 454.2409989833832 and batch: 600, loss is 3.815405931472778 and perplexity is 45.39517997560074
At time: 455.2812280654907 and batch: 650, loss is 3.8513357925415037 and perplexity is 47.055878159462246
At time: 456.32131481170654 and batch: 700, loss is 3.8665585470199586 and perplexity is 47.777678193157676
At time: 457.3627371788025 and batch: 750, loss is 3.832558579444885 and perplexity is 46.18054379664772
At time: 458.4050211906433 and batch: 800, loss is 3.808214292526245 and perplexity is 45.06988533411949
At time: 459.4428074359894 and batch: 850, loss is 3.7985131978988647 and perplexity is 44.63477206157862
At time: 460.481547832489 and batch: 900, loss is 3.770933122634888 and perplexity is 43.420562648026944
At time: 461.51882886886597 and batch: 950, loss is 3.879882016181946 and perplexity is 48.41850213458846
At time: 462.5574791431427 and batch: 1000, loss is 3.830820665359497 and perplexity is 46.10035567932491
At time: 463.59648633003235 and batch: 1050, loss is 3.7814121198654176 and perplexity is 43.877958945504815
At time: 464.635306596756 and batch: 1100, loss is 3.797165107727051 and perplexity is 44.57464090425897
At time: 465.67287158966064 and batch: 1150, loss is 3.761865954399109 and perplexity is 43.02864059828981
At time: 466.7103509902954 and batch: 1200, loss is 3.831850233078003 and perplexity is 46.147843559143226
At time: 467.75077509880066 and batch: 1250, loss is 3.8055168533325197 and perplexity is 44.94847587988909
At time: 468.7893559932709 and batch: 1300, loss is 3.806076211929321 and perplexity is 44.97362522938232
At time: 469.8278298377991 and batch: 1350, loss is 3.6912184858322146 and perplexity is 40.09367077548199
At time: 470.866849899292 and batch: 1400, loss is 3.7189828300476075 and perplexity is 41.22244254637116
At time: 471.9051263332367 and batch: 1450, loss is 3.639660887718201 and perplexity is 38.07892150570772
At time: 472.94392919540405 and batch: 1500, loss is 3.6384643745422363 and perplexity is 38.03338682125703
At time: 473.98166155815125 and batch: 1550, loss is 3.641079754829407 and perplexity is 38.13298878313262
At time: 475.01957392692566 and batch: 1600, loss is 3.725520362854004 and perplexity is 41.492818449573306
At time: 476.05701756477356 and batch: 1650, loss is 3.665029511451721 and perplexity is 39.05728878338381
At time: 477.0971145629883 and batch: 1700, loss is 3.67432737827301 and perplexity is 39.42213175517781
At time: 478.136088848114 and batch: 1750, loss is 3.6677907514572143 and perplexity is 39.16528436392009
At time: 479.1735324859619 and batch: 1800, loss is 3.620838289260864 and perplexity is 37.368880626946
At time: 480.2120854854584 and batch: 1850, loss is 3.652118988037109 and perplexity is 38.55627984491245
At time: 481.2500150203705 and batch: 1900, loss is 3.7344125175476073 and perplexity is 41.86342431022877
At time: 482.316162109375 and batch: 1950, loss is 3.673820390701294 and perplexity is 39.40215028993265
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268117221566134 and perplexity of 71.38710291350057
finished 11 epochs...
Completing Train Step...
At time: 485.6862576007843 and batch: 50, loss is 3.872456364631653 and perplexity is 48.0602948164835
At time: 486.70039319992065 and batch: 100, loss is 3.858957877159119 and perplexity is 47.41591240725146
At time: 487.716285943985 and batch: 150, loss is 3.8292954635620116 and perplexity is 46.030096926985664
At time: 488.76673698425293 and batch: 200, loss is 3.825901598930359 and perplexity is 45.87414180401664
At time: 489.8068046569824 and batch: 250, loss is 3.8044943523406984 and perplexity is 44.90253950771634
At time: 490.8512740135193 and batch: 300, loss is 3.818488712310791 and perplexity is 45.5353392958002
At time: 491.88972997665405 and batch: 350, loss is 3.838119559288025 and perplexity is 46.43806825034334
At time: 492.93774461746216 and batch: 400, loss is 3.8077162456512452 and perplexity is 45.04744400745242
At time: 493.97408151626587 and batch: 450, loss is 3.832673931121826 and perplexity is 46.185871107067896
At time: 495.0266942977905 and batch: 500, loss is 3.8331472969055174 and perplexity is 46.20773909350989
At time: 496.1024935245514 and batch: 550, loss is 3.8041171169281007 and perplexity is 44.88560387425964
At time: 497.143860578537 and batch: 600, loss is 3.776650915145874 and perplexity is 43.669543548191314
At time: 498.1845667362213 and batch: 650, loss is 3.8149584531784058 and perplexity is 45.37487116210802
At time: 499.2580306529999 and batch: 700, loss is 3.832913522720337 and perplexity is 46.1969381794909
At time: 500.29770040512085 and batch: 750, loss is 3.8004309368133544 and perplexity is 44.72045203054691
At time: 501.339058637619 and batch: 800, loss is 3.7774249792098997 and perplexity is 43.7033596587739
At time: 502.37974739074707 and batch: 850, loss is 3.7685496759414674 and perplexity is 43.31719528579017
At time: 503.4200584888458 and batch: 900, loss is 3.7406468868255613 and perplexity is 42.12523161033334
At time: 504.5039520263672 and batch: 950, loss is 3.8517634963989256 and perplexity is 47.07600844465886
At time: 505.5440893173218 and batch: 1000, loss is 3.803895573616028 and perplexity is 44.87566087035661
At time: 506.584835767746 and batch: 1050, loss is 3.7563850688934326 and perplexity is 42.793450659030874
At time: 507.6242883205414 and batch: 1100, loss is 3.7727164363861085 and perplexity is 43.498064218752056
At time: 508.66576290130615 and batch: 1150, loss is 3.7388047218322753 and perplexity is 42.04770141695615
At time: 509.7057023048401 and batch: 1200, loss is 3.810611147880554 and perplexity is 45.17804089493949
At time: 510.7461905479431 and batch: 1250, loss is 3.7880153322219847 and perplexity is 44.16865312765594
At time: 511.7838282585144 and batch: 1300, loss is 3.7895068740844726 and perplexity is 44.23458167817948
At time: 512.8213212490082 and batch: 1350, loss is 3.675354170799255 and perplexity is 39.462630893981
At time: 513.8608891963959 and batch: 1400, loss is 3.7050897550582884 and perplexity is 40.65369602798781
At time: 514.901673078537 and batch: 1450, loss is 3.628250684738159 and perplexity is 37.64690268044268
At time: 515.9373233318329 and batch: 1500, loss is 3.6283489894866943 and perplexity is 37.65060373165628
At time: 516.9744491577148 and batch: 1550, loss is 3.6323755168914795 and perplexity is 37.80251054261944
At time: 518.0144119262695 and batch: 1600, loss is 3.7192155218124388 and perplexity is 41.2320357853685
At time: 519.0549397468567 and batch: 1650, loss is 3.661261878013611 and perplexity is 38.91041209865952
At time: 520.0969753265381 and batch: 1700, loss is 3.673463921546936 and perplexity is 39.38810714186217
At time: 521.1598856449127 and batch: 1750, loss is 3.667936477661133 and perplexity is 39.170992188015504
At time: 522.2054193019867 and batch: 1800, loss is 3.6229429197311402 and perplexity is 37.44761113200233
At time: 523.2442715167999 and batch: 1850, loss is 3.6553391504287718 and perplexity is 38.68063744560596
At time: 524.2841913700104 and batch: 1900, loss is 3.7383350944519043 and perplexity is 42.02795930117099
At time: 525.3258912563324 and batch: 1950, loss is 3.677385768890381 and perplexity is 39.54288459360429
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.26743277616279 and perplexity of 71.33825905643697
finished 12 epochs...
Completing Train Step...
At time: 528.7957105636597 and batch: 50, loss is 3.8567045164108276 and perplexity is 47.30918754135953
At time: 529.8112008571625 and batch: 100, loss is 3.8407935523986816 and perplexity is 46.56240949464315
At time: 530.880761384964 and batch: 150, loss is 3.8095752096176145 and perplexity is 45.131263467178734
At time: 531.9157571792603 and batch: 200, loss is 3.805374889373779 and perplexity is 44.94209526923291
At time: 532.9430420398712 and batch: 250, loss is 3.783610167503357 and perplexity is 43.974510863506715
At time: 533.9823143482208 and batch: 300, loss is 3.7972109842300417 and perplexity is 44.576685879813525
At time: 535.0346496105194 and batch: 350, loss is 3.816916375160217 and perplexity is 45.46379864790948
At time: 536.0797469615936 and batch: 400, loss is 3.786557021141052 and perplexity is 44.10428843464941
At time: 537.1334629058838 and batch: 450, loss is 3.8124445915222167 and perplexity is 45.2609482665332
At time: 538.1944136619568 and batch: 500, loss is 3.8133020639419555 and perplexity is 45.29977492537856
At time: 539.2571566104889 and batch: 550, loss is 3.784480166435242 and perplexity is 44.01278528792816
At time: 540.3129513263702 and batch: 600, loss is 3.758063850402832 and perplexity is 42.86535184902815
At time: 541.3702466487885 and batch: 650, loss is 3.796997375488281 and perplexity is 44.56716492694647
At time: 542.4285881519318 and batch: 700, loss is 3.815277042388916 and perplexity is 45.38932940948708
At time: 543.4843745231628 and batch: 750, loss is 3.7834987306594847 and perplexity is 43.9696107558366
At time: 544.5408456325531 and batch: 800, loss is 3.761142621040344 and perplexity is 42.9975278009814
At time: 545.5988488197327 and batch: 850, loss is 3.753019552230835 and perplexity is 42.64967067047421
At time: 546.6572494506836 and batch: 900, loss is 3.7249661016464235 and perplexity is 41.46982696214691
At time: 547.7134957313538 and batch: 950, loss is 3.8375036239624025 and perplexity is 46.40947421059787
At time: 548.7705473899841 and batch: 1000, loss is 3.7896451807022093 and perplexity is 44.240700036653365
At time: 549.8273332118988 and batch: 1050, loss is 3.7429505348205567 and perplexity is 42.22238517651567
At time: 550.8819081783295 and batch: 1100, loss is 3.7591802072525025 and perplexity is 42.91323159864905
At time: 551.9347450733185 and batch: 1150, loss is 3.7258697175979614 and perplexity is 41.507316694906756
At time: 552.9903461933136 and batch: 1200, loss is 3.7981550025939943 and perplexity is 44.61878695885749
At time: 554.0463426113129 and batch: 1250, loss is 3.777286911010742 and perplexity is 43.69732603114431
At time: 555.1033849716187 and batch: 1300, loss is 3.7787342834472657 and perplexity is 43.76061812896133
At time: 556.1591279506683 and batch: 1350, loss is 3.6652870035171508 and perplexity is 39.06734702024524
At time: 557.2152585983276 and batch: 1400, loss is 3.695797953605652 and perplexity is 40.27769950391927
At time: 558.2688405513763 and batch: 1450, loss is 3.619533672332764 and perplexity is 37.320160340261566
At time: 559.3220038414001 and batch: 1500, loss is 3.62009192943573 and perplexity is 37.34100040137019
At time: 560.3778080940247 and batch: 1550, loss is 3.624470853805542 and perplexity is 37.504872347596994
At time: 561.4344823360443 and batch: 1600, loss is 3.712727971076965 and perplexity is 40.96540668136742
At time: 562.4911170005798 and batch: 1650, loss is 3.655634670257568 and perplexity is 38.69207003015613
At time: 563.5465919971466 and batch: 1700, loss is 3.6690774869918825 and perplexity is 39.215712163699756
At time: 564.6023926734924 and batch: 1750, loss is 3.6638551139831543 and perplexity is 39.01144692585704
At time: 565.6570937633514 and batch: 1800, loss is 3.6197425365447997 and perplexity is 37.32795600023294
At time: 566.7125992774963 and batch: 1850, loss is 3.6526814460754395 and perplexity is 38.577972234396874
At time: 567.7680277824402 and batch: 1900, loss is 3.7360699510574342 and perplexity is 41.93286768550802
At time: 568.8234543800354 and batch: 1950, loss is 3.674919800758362 and perplexity is 39.44549323169881
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268387195675872 and perplexity of 71.40637818485146
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 572.2824807167053 and batch: 50, loss is 3.853550853729248 and perplexity is 47.1602253338516
At time: 573.2928130626678 and batch: 100, loss is 3.8576112604141235 and perplexity is 47.352104317787834
At time: 574.3076038360596 and batch: 150, loss is 3.8345969915390015 and perplexity is 46.27477478379915
At time: 575.3261649608612 and batch: 200, loss is 3.8383396530151366 and perplexity is 46.44829010270595
At time: 576.3501002788544 and batch: 250, loss is 3.8240324687957763 and perplexity is 45.78847714730846
At time: 577.3755812644958 and batch: 300, loss is 3.8303988695144655 and perplexity is 46.08091484116551
At time: 578.4042053222656 and batch: 350, loss is 3.845193738937378 and perplexity is 46.76774420632657
At time: 579.4391317367554 and batch: 400, loss is 3.824439024925232 and perplexity is 45.80709651800432
At time: 580.4732174873352 and batch: 450, loss is 3.8540520000457765 and perplexity is 47.18386543014314
At time: 581.5084991455078 and batch: 500, loss is 3.8578009271621703 and perplexity is 47.36108628919069
At time: 582.6028490066528 and batch: 550, loss is 3.8307769441604616 and perplexity is 46.098340160559424
At time: 583.6596648693085 and batch: 600, loss is 3.7996077346801758 and perplexity is 44.68365320755154
At time: 584.7024366855621 and batch: 650, loss is 3.8263151979446413 and perplexity is 45.89311922809924
At time: 585.7565915584564 and batch: 700, loss is 3.8390468978881835 and perplexity is 46.48115203709041
At time: 586.8166782855988 and batch: 750, loss is 3.806488094329834 and perplexity is 44.99215288944818
At time: 587.882556438446 and batch: 800, loss is 3.780533962249756 and perplexity is 43.839444095226774
At time: 588.9228837490082 and batch: 850, loss is 3.7654210472106935 and perplexity is 43.1818836443997
At time: 589.9621789455414 and batch: 900, loss is 3.7355557012557985 and perplexity is 41.91130926030177
At time: 591.0031967163086 and batch: 950, loss is 3.8563900279998777 and perplexity is 47.29431168941045
At time: 592.0429697036743 and batch: 1000, loss is 3.8045066499710085 and perplexity is 44.90309170594254
At time: 593.0827777385712 and batch: 1050, loss is 3.7588241338729858 and perplexity is 42.89795405937167
At time: 594.1237819194794 and batch: 1100, loss is 3.7714988374710083 and perplexity is 43.445133253832466
At time: 595.1626718044281 and batch: 1150, loss is 3.740224199295044 and perplexity is 42.107429562828294
At time: 596.2014117240906 and batch: 1200, loss is 3.806406297683716 and perplexity is 44.98847283275039
At time: 597.23881483078 and batch: 1250, loss is 3.7781715774536133 and perplexity is 43.73600069369299
At time: 598.2813947200775 and batch: 1300, loss is 3.77636399269104 and perplexity is 43.65701557291965
At time: 599.3218874931335 and batch: 1350, loss is 3.6627238416671752 and perplexity is 38.967339309510166
At time: 600.361252784729 and batch: 1400, loss is 3.693700084686279 and perplexity is 40.19329074020441
At time: 601.4008710384369 and batch: 1450, loss is 3.615054306983948 and perplexity is 37.153363557978615
At time: 602.4400277137756 and batch: 1500, loss is 3.615837507247925 and perplexity is 37.182473480086195
At time: 603.5115234851837 and batch: 1550, loss is 3.6206096982955933 and perplexity is 37.36033941471156
At time: 604.5492322444916 and batch: 1600, loss is 3.7054929876327516 and perplexity is 40.67009222801743
At time: 605.5960419178009 and batch: 1650, loss is 3.644177346229553 and perplexity is 38.25129233468682
At time: 606.6442368030548 and batch: 1700, loss is 3.656469130516052 and perplexity is 38.72437049976959
At time: 607.6833996772766 and batch: 1750, loss is 3.6488747358322144 and perplexity is 38.43139623551074
At time: 608.7264783382416 and batch: 1800, loss is 3.6039734077453613 and perplexity is 36.74394344080788
At time: 609.7674305438995 and batch: 1850, loss is 3.6353606176376343 and perplexity is 37.9155234385669
At time: 610.8084719181061 and batch: 1900, loss is 3.7180677223205567 and perplexity is 41.18473682569854
At time: 611.8511731624603 and batch: 1950, loss is 3.6624309539794924 and perplexity is 38.95592792681297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253755791242733 and perplexity of 70.36920871239596
finished 14 epochs...
Completing Train Step...
At time: 615.1844902038574 and batch: 50, loss is 3.8575070762634276 and perplexity is 47.34717123599475
At time: 616.2184293270111 and batch: 100, loss is 3.849019446372986 and perplexity is 46.94700659717324
At time: 617.2703666687012 and batch: 150, loss is 3.8216194248199464 and perplexity is 45.678120739346866
At time: 618.309867143631 and batch: 200, loss is 3.8203120040893555 and perplexity is 45.618439240273744
At time: 619.3650424480438 and batch: 250, loss is 3.8027611923217775 and perplexity is 44.82478362265304
At time: 620.4048991203308 and batch: 300, loss is 3.805655837059021 and perplexity is 44.95472342071062
At time: 621.4439775943756 and batch: 350, loss is 3.817797646522522 and perplexity is 45.503882251351165
At time: 622.4932651519775 and batch: 400, loss is 3.796558780670166 and perplexity is 44.54762228531538
At time: 623.5432295799255 and batch: 450, loss is 3.8283818769454956 and perplexity is 45.98806364991948
At time: 624.5914206504822 and batch: 500, loss is 3.8326317405700685 and perplexity is 46.183922540788316
At time: 625.6592907905579 and batch: 550, loss is 3.8060108280181884 and perplexity is 44.970684773997284
At time: 626.7163980007172 and batch: 600, loss is 3.777578420639038 and perplexity is 43.71006607924629
At time: 627.7659561634064 and batch: 650, loss is 3.8069312810897826 and perplexity is 45.01209723511889
At time: 628.815701007843 and batch: 700, loss is 3.82248797416687 and perplexity is 45.71781167555692
At time: 629.8645095825195 and batch: 750, loss is 3.7914610958099364 and perplexity is 44.32111037930796
At time: 630.9134147167206 and batch: 800, loss is 3.7659946727752684 and perplexity is 43.20666098256251
At time: 631.963196516037 and batch: 850, loss is 3.751662893295288 and perplexity is 42.59184884477776
At time: 633.0411896705627 and batch: 900, loss is 3.72262864112854 and perplexity is 41.37300608051701
At time: 634.095174074173 and batch: 950, loss is 3.84337112903595 and perplexity is 46.682582484542266
At time: 635.1785278320312 and batch: 1000, loss is 3.7924475336074828 and perplexity is 44.36485196844683
At time: 636.2274758815765 and batch: 1050, loss is 3.7484754753112792 and perplexity is 42.45630694889064
At time: 637.298036813736 and batch: 1100, loss is 3.7624909591674807 and perplexity is 43.05554210975106
At time: 638.3397071361542 and batch: 1150, loss is 3.7321460342407224 and perplexity is 41.76864900175918
At time: 639.380078792572 and batch: 1200, loss is 3.798824501037598 and perplexity is 44.64866916921242
At time: 640.4222912788391 and batch: 1250, loss is 3.7722616243362426 and perplexity is 43.47828527319186
At time: 641.4634394645691 and batch: 1300, loss is 3.771267614364624 and perplexity is 43.43508889645274
At time: 642.5039026737213 and batch: 1350, loss is 3.6589130973815918 and perplexity is 38.81912732226213
At time: 643.5438046455383 and batch: 1400, loss is 3.690715751647949 and perplexity is 40.07351938243197
At time: 644.584059715271 and batch: 1450, loss is 3.613871636390686 and perplexity is 37.10944934060319
At time: 645.6236646175385 and batch: 1500, loss is 3.615703682899475 and perplexity is 37.17749789273376
At time: 646.6620571613312 and batch: 1550, loss is 3.6208772802352907 and perplexity is 37.370337704421125
At time: 647.7008912563324 and batch: 1600, loss is 3.706818780899048 and perplexity is 40.72404812170994
At time: 648.7425146102905 and batch: 1650, loss is 3.6465957880020143 and perplexity is 38.3439128113909
At time: 649.7830693721771 and batch: 1700, loss is 3.660046911239624 and perplexity is 38.86316594786107
At time: 650.8210680484772 and batch: 1750, loss is 3.653155255317688 and perplexity is 38.59625516515748
At time: 651.857666015625 and batch: 1800, loss is 3.6085774993896482 and perplexity is 36.91350596495488
At time: 652.8953359127045 and batch: 1850, loss is 3.6406693840026856 and perplexity is 38.11734332743919
At time: 653.933694601059 and batch: 1900, loss is 3.722851610183716 and perplexity is 41.382232009102644
At time: 654.974310874939 and batch: 1950, loss is 3.6666968297958373 and perplexity is 39.122464036292506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252434309138808 and perplexity of 70.27627847875931
finished 15 epochs...
Completing Train Step...
At time: 658.3268835544586 and batch: 50, loss is 3.853372073173523 and perplexity is 47.15179475619243
At time: 659.3590636253357 and batch: 100, loss is 3.842883768081665 and perplexity is 46.65983675973341
At time: 660.3747427463531 and batch: 150, loss is 3.8147404956817628 and perplexity is 45.36498244647803
At time: 661.4117834568024 and batch: 200, loss is 3.8128107738494874 and perplexity is 45.27752506078323
At time: 662.4373469352722 and batch: 250, loss is 3.79451060295105 and perplexity is 44.456474213499995
At time: 663.4717960357666 and batch: 300, loss is 3.796889591217041 and perplexity is 44.56236154642266
At time: 664.50546002388 and batch: 350, loss is 3.8086085605621336 and perplexity is 45.08765845274395
At time: 665.5429966449738 and batch: 400, loss is 3.787330527305603 and perplexity is 44.138416571097096
At time: 666.5951545238495 and batch: 450, loss is 3.819414720535278 and perplexity is 45.577524923597586
At time: 667.6665575504303 and batch: 500, loss is 3.8233458900451662 and perplexity is 45.7570505415307
At time: 668.7048978805542 and batch: 550, loss is 3.7971806287765504 and perplexity is 44.57533275483597
At time: 669.7681148052216 and batch: 600, loss is 3.7693706130981446 and perplexity is 43.352770581466395
At time: 670.8149619102478 and batch: 650, loss is 3.7992818403244017 and perplexity is 44.669093429779394
At time: 671.8534953594208 and batch: 700, loss is 3.8154472732543945 and perplexity is 45.397056732011684
At time: 672.8929142951965 and batch: 750, loss is 3.784718379974365 and perplexity is 44.02327097814537
At time: 673.932450056076 and batch: 800, loss is 3.7595040893554685 and perplexity is 42.927132677378076
At time: 674.9727597236633 and batch: 850, loss is 3.7454164934158327 and perplexity is 42.3266323118877
At time: 676.0130774974823 and batch: 900, loss is 3.7165480136871336 and perplexity is 41.122195559866746
At time: 677.0510461330414 and batch: 950, loss is 3.8375774955749513 and perplexity is 46.412902679927065
At time: 678.0870923995972 and batch: 1000, loss is 3.786887035369873 and perplexity is 44.11884587933468
At time: 679.1312146186829 and batch: 1050, loss is 3.7435741519927976 and perplexity is 42.248723992780185
At time: 680.1758277416229 and batch: 1100, loss is 3.7578667259216307 and perplexity is 42.856902871560905
At time: 681.2219865322113 and batch: 1150, loss is 3.7279506158828735 and perplexity is 41.59377912759292
At time: 682.2681035995483 and batch: 1200, loss is 3.7948974132537843 and perplexity is 44.473673762015856
At time: 683.3173990249634 and batch: 1250, loss is 3.769015030860901 and perplexity is 43.33735784672208
At time: 684.3638393878937 and batch: 1300, loss is 3.7684281492233276 and perplexity is 43.31193140906538
At time: 685.409346818924 and batch: 1350, loss is 3.6564068937301637 and perplexity is 38.7219604944104
At time: 686.4566445350647 and batch: 1400, loss is 3.6885093021392823 and perplexity is 39.98519666092545
At time: 687.5026381015778 and batch: 1450, loss is 3.6125190353393553 and perplexity is 37.05928899152872
At time: 688.5492427349091 and batch: 1500, loss is 3.614773864746094 and perplexity is 37.14294564643811
At time: 689.595121383667 and batch: 1550, loss is 3.6201043701171876 and perplexity is 37.34146495175114
At time: 690.642195224762 and batch: 1600, loss is 3.7064325857162475 and perplexity is 40.70832372703938
At time: 691.6884846687317 and batch: 1650, loss is 3.646570153236389 and perplexity is 38.342929886771394
At time: 692.7352578639984 and batch: 1700, loss is 3.6604596996307373 and perplexity is 38.879211523092
At time: 693.7816662788391 and batch: 1750, loss is 3.6539340734481813 and perplexity is 38.62632633691615
At time: 694.8304560184479 and batch: 1800, loss is 3.609537973403931 and perplexity is 36.9489774602081
At time: 695.8771252632141 and batch: 1850, loss is 3.6418570375442503 and perplexity is 38.16264041853802
At time: 696.9227230548859 and batch: 1900, loss is 3.7237254667282103 and perplexity is 41.41840994823182
At time: 697.967992067337 and batch: 1950, loss is 3.6671942329406737 and perplexity is 39.14192851338266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252203227198401 and perplexity of 70.26004077615603
finished 16 epochs...
Completing Train Step...
At time: 701.2955701351166 and batch: 50, loss is 3.848860945701599 and perplexity is 46.93956605478904
At time: 702.3180065155029 and batch: 100, loss is 3.8375169897079466 and perplexity is 46.41009451196639
At time: 703.3257257938385 and batch: 150, loss is 3.8090880727767944 and perplexity is 45.10928372007805
At time: 704.3412747383118 and batch: 200, loss is 3.80696515083313 and perplexity is 45.013621809118085
At time: 705.3574650287628 and batch: 250, loss is 3.78835702419281 and perplexity is 44.183747780505804
At time: 706.3758959770203 and batch: 300, loss is 3.790437912940979 and perplexity is 44.27578497047988
At time: 707.4015531539917 and batch: 350, loss is 3.802075080871582 and perplexity is 44.794039373553744
At time: 708.4253706932068 and batch: 400, loss is 3.780833501815796 and perplexity is 43.85257771020695
At time: 709.4501023292542 and batch: 450, loss is 3.8131538009643555 and perplexity is 45.29305914372671
At time: 710.4792749881744 and batch: 500, loss is 3.8169485569000243 and perplexity is 45.46526177559108
At time: 711.510662317276 and batch: 550, loss is 3.79107355594635 and perplexity is 44.30393751003821
At time: 712.5415177345276 and batch: 600, loss is 3.7636714124679567 and perplexity is 43.10639717664866
At time: 713.5863838195801 and batch: 650, loss is 3.7938279151916503 and perplexity is 44.426134680120754
At time: 714.6231472492218 and batch: 700, loss is 3.810364933013916 and perplexity is 45.166918758899385
At time: 715.6623520851135 and batch: 750, loss is 3.7798516750335693 and perplexity is 43.809543204613526
At time: 716.7029993534088 and batch: 800, loss is 3.7548089456558227 and perplexity is 42.72605603210007
At time: 717.7377805709839 and batch: 850, loss is 3.7408602619171143 and perplexity is 42.13422104451144
At time: 718.783997297287 and batch: 900, loss is 3.712036190032959 and perplexity is 40.93707738952856
At time: 719.8268818855286 and batch: 950, loss is 3.833353404998779 and perplexity is 46.217263864040824
At time: 720.8861615657806 and batch: 1000, loss is 3.782701449394226 and perplexity is 43.93456858003162
At time: 721.9469127655029 and batch: 1050, loss is 3.7398057556152344 and perplexity is 42.08981366094314
At time: 722.993889093399 and batch: 1100, loss is 3.7541693687438964 and perplexity is 42.69873816999243
At time: 724.0404891967773 and batch: 1150, loss is 3.7245127677917482 and perplexity is 41.4510315462585
At time: 725.0868511199951 and batch: 1200, loss is 3.791651654243469 and perplexity is 44.32955694543091
At time: 726.1562445163727 and batch: 1250, loss is 3.7661905431747438 and perplexity is 43.215124717379666
At time: 727.2023994922638 and batch: 1300, loss is 3.7658456420898436 and perplexity is 43.20022234405064
At time: 728.2710354328156 and batch: 1350, loss is 3.653993148803711 and perplexity is 38.62860826827959
At time: 729.3583798408508 and batch: 1400, loss is 3.686303987503052 and perplexity is 39.89711388231557
At time: 730.4054021835327 and batch: 1450, loss is 3.610806393623352 and perplexity is 36.99587402629427
At time: 731.4522261619568 and batch: 1500, loss is 3.6133491134643556 and perplexity is 37.09006386765732
At time: 732.4990158081055 and batch: 1550, loss is 3.618711724281311 and perplexity is 37.2894977104607
At time: 733.5448994636536 and batch: 1600, loss is 3.705329723358154 and perplexity is 40.66345279691772
At time: 734.5914433002472 and batch: 1650, loss is 3.6456587314605713 and perplexity is 38.30799922622432
At time: 735.6696693897247 and batch: 1700, loss is 3.6598137331008913 and perplexity is 38.85410496361286
At time: 736.7155287265778 and batch: 1750, loss is 3.6535208511352537 and perplexity is 38.610368374327486
At time: 737.7622277736664 and batch: 1800, loss is 3.609323363304138 and perplexity is 36.94104868729593
At time: 738.8103902339935 and batch: 1850, loss is 3.641791639328003 and perplexity is 38.160144731534984
At time: 739.8566753864288 and batch: 1900, loss is 3.7235142374038697 and perplexity is 41.40966208941787
At time: 740.9035482406616 and batch: 1950, loss is 3.6666766166687013 and perplexity is 39.12167325694515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252333814044332 and perplexity of 70.26921641237159
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 744.2407050132751 and batch: 50, loss is 3.848246068954468 and perplexity is 46.91071287858415
At time: 745.2492628097534 and batch: 100, loss is 3.8441068983078 and perplexity is 46.71694273332253
At time: 746.2603113651276 and batch: 150, loss is 3.8211790180206298 and perplexity is 45.658008213564884
At time: 747.2773435115814 and batch: 200, loss is 3.8224858236312866 and perplexity is 45.717713357881834
At time: 748.2928767204285 and batch: 250, loss is 3.808608264923096 and perplexity is 45.08764512307396
At time: 749.3078033924103 and batch: 300, loss is 3.8073214626312257 and perplexity is 45.029663551405
At time: 750.3332233428955 and batch: 350, loss is 3.8131916904449463 and perplexity is 45.29477530672409
At time: 751.3606655597687 and batch: 400, loss is 3.7928358459472657 and perplexity is 44.38208273316159
At time: 752.390743970871 and batch: 450, loss is 3.8249597930908203 and perplexity is 45.83095760813774
At time: 753.4284825325012 and batch: 500, loss is 3.8317061710357665 and perplexity is 46.141195885405516
At time: 754.4685747623444 and batch: 550, loss is 3.80995512008667 and perplexity is 45.14841256400606
At time: 755.5071020126343 and batch: 600, loss is 3.7840184354782105 and perplexity is 43.99246791339691
At time: 756.5449590682983 and batch: 650, loss is 3.8140412521362306 and perplexity is 45.333272363136736
At time: 757.5832829475403 and batch: 700, loss is 3.8279189968109133 and perplexity is 45.96678161472367
At time: 758.6191484928131 and batch: 750, loss is 3.7971465015411376 and perplexity is 44.573811547918886
At time: 759.655238866806 and batch: 800, loss is 3.7712213468551634 and perplexity is 43.43307930955595
At time: 760.6932303905487 and batch: 850, loss is 3.755861873626709 and perplexity is 42.771067184173944
At time: 761.7274191379547 and batch: 900, loss is 3.721328549385071 and perplexity is 41.319252326886264
At time: 762.7620005607605 and batch: 950, loss is 3.8437566471099855 and perplexity is 46.70058293335896
At time: 763.7974586486816 and batch: 1000, loss is 3.790561079978943 and perplexity is 44.281238623616474
At time: 764.8681571483612 and batch: 1050, loss is 3.745754141807556 and perplexity is 42.34092624424071
At time: 765.9036285877228 and batch: 1100, loss is 3.755011601448059 and perplexity is 42.73471559225976
At time: 766.9394690990448 and batch: 1150, loss is 3.72564085483551 and perplexity is 41.497818302701624
At time: 767.9741296768188 and batch: 1200, loss is 3.794368472099304 and perplexity is 44.45015602596974
At time: 769.0093977451324 and batch: 1250, loss is 3.7663577222824096 and perplexity is 43.222349987307844
At time: 770.0439281463623 and batch: 1300, loss is 3.7628608989715575 and perplexity is 43.07147301511988
At time: 771.0805592536926 and batch: 1350, loss is 3.648042902946472 and perplexity is 38.39944102881555
At time: 772.1162395477295 and batch: 1400, loss is 3.67871208190918 and perplexity is 39.59536563169037
At time: 773.1556711196899 and batch: 1450, loss is 3.602911114692688 and perplexity is 36.70493132977881
At time: 774.1906447410583 and batch: 1500, loss is 3.6061057806015016 and perplexity is 36.82237882545064
At time: 775.2263948917389 and batch: 1550, loss is 3.611252613067627 and perplexity is 37.01238598834803
At time: 776.2633345127106 and batch: 1600, loss is 3.6985272407531737 and perplexity is 40.387779062537376
At time: 777.2993800640106 and batch: 1650, loss is 3.636407494544983 and perplexity is 37.95523710851974
At time: 778.338428735733 and batch: 1700, loss is 3.649157705307007 and perplexity is 38.442272686298246
At time: 779.3726770877838 and batch: 1750, loss is 3.645977463722229 and perplexity is 38.320211167523716
At time: 780.4081618785858 and batch: 1800, loss is 3.601956958770752 and perplexity is 36.669925805206326
At time: 781.4425668716431 and batch: 1850, loss is 3.63475594997406 and perplexity is 37.89260407759265
At time: 782.4877734184265 and batch: 1900, loss is 3.716277828216553 and perplexity is 41.11108644093694
At time: 783.5278797149658 and batch: 1950, loss is 3.6606182193756105 and perplexity is 38.885375134297654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249906602016715 and perplexity of 70.09886494831896
finished 18 epochs...
Completing Train Step...
At time: 786.8656640052795 and batch: 50, loss is 3.8489623832702637 and perplexity is 46.944327731746206
At time: 787.8828420639038 and batch: 100, loss is 3.839838171005249 and perplexity is 46.51794587821651
At time: 788.897064447403 and batch: 150, loss is 3.8152966117858886 and perplexity is 45.390217659983854
At time: 789.9106776714325 and batch: 200, loss is 3.8143392038345336 and perplexity is 45.34678150106232
At time: 790.941623210907 and batch: 250, loss is 3.7991446924209593 and perplexity is 44.66296757735034
At time: 791.9577231407166 and batch: 300, loss is 3.797542700767517 and perplexity is 44.591475156493914
At time: 792.9815232753754 and batch: 350, loss is 3.8037560176849365 and perplexity is 44.86939864269618
At time: 794.0060484409332 and batch: 400, loss is 3.7821989011764527 and perplexity is 43.91249488790498
At time: 795.037225484848 and batch: 450, loss is 3.8154125118255617 and perplexity is 45.395478692882484
At time: 796.0683867931366 and batch: 500, loss is 3.8221992206573487 and perplexity is 45.704612402747856
At time: 797.09956407547 and batch: 550, loss is 3.799614429473877 and perplexity is 44.68395235639295
At time: 798.1307382583618 and batch: 600, loss is 3.774047508239746 and perplexity is 43.5560018187214
At time: 799.1661705970764 and batch: 650, loss is 3.803972053527832 and perplexity is 44.87909308818831
At time: 800.1981725692749 and batch: 700, loss is 3.819904851913452 and perplexity is 45.599869374112984
At time: 801.2304060459137 and batch: 750, loss is 3.7905225801467894 and perplexity is 44.27953383617914
At time: 802.2620990276337 and batch: 800, loss is 3.764703369140625 and perplexity is 43.15090407149361
At time: 803.2933688163757 and batch: 850, loss is 3.7487947607040404 and perplexity is 42.46986479182544
At time: 804.3252022266388 and batch: 900, loss is 3.715061845779419 and perplexity is 41.06112646323694
At time: 805.3613822460175 and batch: 950, loss is 3.8373218059539793 and perplexity is 46.40103689947573
At time: 806.4025716781616 and batch: 1000, loss is 3.784867353439331 and perplexity is 44.02982976589265
At time: 807.4447364807129 and batch: 1050, loss is 3.7408877420425415 and perplexity is 42.135378914099654
At time: 808.4845218658447 and batch: 1100, loss is 3.7513472986221315 and perplexity is 42.578409205013365
At time: 809.5242249965668 and batch: 1150, loss is 3.7223793601989748 and perplexity is 41.362693864475155
At time: 810.5635671615601 and batch: 1200, loss is 3.791100091934204 and perplexity is 44.30511317438449
At time: 811.6029803752899 and batch: 1250, loss is 3.7640721893310545 and perplexity is 43.123676685670986
At time: 812.6421418190002 and batch: 1300, loss is 3.76134343624115 and perplexity is 43.00616322519412
At time: 813.6824820041656 and batch: 1350, loss is 3.6474953651428224 and perplexity is 38.37842163819388
At time: 814.7228562831879 and batch: 1400, loss is 3.6791547918319703 and perplexity is 39.612898773713646
At time: 815.7621142864227 and batch: 1450, loss is 3.603729066848755 and perplexity is 36.73496648948554
At time: 816.8011264801025 and batch: 1500, loss is 3.6078622055053713 and perplexity is 36.88711140095142
At time: 817.8408441543579 and batch: 1550, loss is 3.614022722244263 and perplexity is 37.11505647700142
At time: 818.8809566497803 and batch: 1600, loss is 3.701580090522766 and perplexity is 40.51126528107319
At time: 819.9205179214478 and batch: 1650, loss is 3.639964990615845 and perplexity is 38.09050317699741
At time: 820.9610488414764 and batch: 1700, loss is 3.652691750526428 and perplexity is 38.578369761269144
At time: 821.9999485015869 and batch: 1750, loss is 3.650216693878174 and perplexity is 38.48300417700775
At time: 823.038735628128 and batch: 1800, loss is 3.606528196334839 and perplexity is 36.83793646326958
At time: 824.078138589859 and batch: 1850, loss is 3.639463357925415 and perplexity is 38.07140052706633
At time: 825.1265518665314 and batch: 1900, loss is 3.720807070732117 and perplexity is 41.29771083604375
At time: 826.179446220398 and batch: 1950, loss is 3.664204730987549 and perplexity is 39.025088375570796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249106899527616 and perplexity of 70.04282912051865
finished 19 epochs...
Completing Train Step...
At time: 829.5139524936676 and batch: 50, loss is 3.8485761785507204 and perplexity is 46.9262011113389
At time: 830.5251290798187 and batch: 100, loss is 3.837333426475525 and perplexity is 46.401576106857675
At time: 831.5350542068481 and batch: 150, loss is 3.8121585273742675 and perplexity is 45.24800258366811
At time: 832.5431845188141 and batch: 200, loss is 3.810366139411926 and perplexity is 45.16697324821316
At time: 833.5573239326477 and batch: 250, loss is 3.794787120819092 and perplexity is 44.46876892274524
At time: 834.5722427368164 and batch: 300, loss is 3.792970881462097 and perplexity is 44.388076295215505
At time: 835.59525847435 and batch: 350, loss is 3.79943021774292 and perplexity is 44.675721806288585
At time: 836.6211955547333 and batch: 400, loss is 3.777478051185608 and perplexity is 43.70567914396537
At time: 837.6520526409149 and batch: 450, loss is 3.810926609039307 and perplexity is 45.19229506026993
At time: 838.6817724704742 and batch: 500, loss is 3.817639317512512 and perplexity is 45.49667823703998
At time: 839.7119815349579 and batch: 550, loss is 3.794873375892639 and perplexity is 44.472604745106416
At time: 840.7424259185791 and batch: 600, loss is 3.7695014238357545 and perplexity is 43.35844196029413
At time: 841.7734680175781 and batch: 650, loss is 3.799460530281067 and perplexity is 44.67707606133544
At time: 842.8434503078461 and batch: 700, loss is 3.816141676902771 and perplexity is 45.42859156151512
At time: 843.8748037815094 and batch: 750, loss is 3.7872371578216555 and perplexity is 44.13429558230988
At time: 844.9129779338837 and batch: 800, loss is 3.7615670108795167 and perplexity is 43.01577938750968
At time: 845.9523441791534 and batch: 850, loss is 3.745469102859497 and perplexity is 42.32885915104167
At time: 847.007572889328 and batch: 900, loss is 3.7121706008911133 and perplexity is 40.94258014703771
At time: 848.0462846755981 and batch: 950, loss is 3.834483141899109 and perplexity is 46.269506717243345
At time: 849.0864470005035 and batch: 1000, loss is 3.7823734140396117 and perplexity is 43.92015885182701
At time: 850.1249811649323 and batch: 1050, loss is 3.7389012432098387 and perplexity is 42.0517601148927
At time: 851.1637349128723 and batch: 1100, loss is 3.749847025871277 and perplexity is 42.5145778720858
At time: 852.2019481658936 and batch: 1150, loss is 3.721136622428894 and perplexity is 41.31132280952407
At time: 853.2404327392578 and batch: 1200, loss is 3.7899143409729006 and perplexity is 44.252609478153154
At time: 854.2794518470764 and batch: 1250, loss is 3.7632081508636475 and perplexity is 43.08643226278269
At time: 855.3174896240234 and batch: 1300, loss is 3.7608383655548097 and perplexity is 42.984447557252395
At time: 856.3566386699677 and batch: 1350, loss is 3.6473331022262574 and perplexity is 38.37219474877598
At time: 857.3961505889893 and batch: 1400, loss is 3.679354019165039 and perplexity is 39.62079153209195
At time: 858.4354510307312 and batch: 1450, loss is 3.604135570526123 and perplexity is 36.74990242400198
At time: 859.5095834732056 and batch: 1500, loss is 3.608740234375 and perplexity is 36.91951357261808
At time: 860.5490810871124 and batch: 1550, loss is 3.615223274230957 and perplexity is 37.15964178992898
At time: 861.5884897708893 and batch: 1600, loss is 3.7029593229293822 and perplexity is 40.567178280628816
At time: 862.6289687156677 and batch: 1650, loss is 3.641566572189331 and perplexity is 38.151557103381656
At time: 863.6686272621155 and batch: 1700, loss is 3.654351453781128 and perplexity is 38.642451570806806
At time: 864.7071270942688 and batch: 1750, loss is 3.652147903442383 and perplexity is 38.557394731488635
At time: 865.745637178421 and batch: 1800, loss is 3.60854193687439 and perplexity is 36.9121932511776
At time: 866.8116326332092 and batch: 1850, loss is 3.6414870691299437 and perplexity is 38.14852405844131
At time: 867.8517055511475 and batch: 1900, loss is 3.722650032043457 and perplexity is 41.37389109643556
At time: 868.8909940719604 and batch: 1950, loss is 3.6655433177948 and perplexity is 39.077361822489976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.248740404705669 and perplexity of 70.01716348977908
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd78797ab38>
ELAPSED
1798.9119131565094


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.58572924558682}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.5545691141662139, 'dropout': 0.7795352401135597, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.01716348977908}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.30559750332649016, 'dropout': 0.7036453025474743, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6054985523223877 and batch: 50, loss is 7.661554613113403 and perplexity is 2125.058505784513
At time: 2.7533295154571533 and batch: 100, loss is 6.7981585597991945 and perplexity is 896.1954808755314
At time: 3.9019932746887207 and batch: 150, loss is 6.526511116027832 and perplexity is 683.0111032504092
At time: 5.05061674118042 and batch: 200, loss is 6.433076639175415 and perplexity is 622.0849376821752
At time: 6.198371648788452 and batch: 250, loss is 6.3764465808868405 and perplexity is 587.8351673049743
At time: 7.352035760879517 and batch: 300, loss is 6.307517728805542 and perplexity is 548.6812812764728
At time: 8.501020193099976 and batch: 350, loss is 6.242706527709961 and perplexity is 514.2484568290334
At time: 9.64949083328247 and batch: 400, loss is 6.181998090744019 and perplexity is 483.9579828931597
At time: 10.803949356079102 and batch: 450, loss is 6.086099548339844 and perplexity is 439.7030216960917
At time: 11.953678607940674 and batch: 500, loss is 6.065222063064575 and perplexity is 430.6182914731261
At time: 13.103249073028564 and batch: 550, loss is 6.0105439567565915 and perplexity is 407.70503387500156
At time: 14.255598068237305 and batch: 600, loss is 6.039696245193482 and perplexity is 419.7655097282748
At time: 15.409016132354736 and batch: 650, loss is 6.107218971252442 and perplexity is 449.0880501283811
At time: 16.562204599380493 and batch: 700, loss is 6.010110654830933 and perplexity is 407.5284127666193
At time: 17.716585636138916 and batch: 750, loss is 5.943111629486084 and perplexity is 381.11898748713884
At time: 18.86997127532959 and batch: 800, loss is 5.942595405578613 and perplexity is 380.9222955271211
At time: 20.022764444351196 and batch: 850, loss is 5.968264617919922 and perplexity is 390.82684800339393
At time: 21.176088333129883 and batch: 900, loss is 5.946834192276001 and perplexity is 382.5403708014093
At time: 22.329010009765625 and batch: 950, loss is 5.972329893112183 and perplexity is 392.4189005663637
At time: 23.499574184417725 and batch: 1000, loss is 5.946752243041992 and perplexity is 382.5090231955182
At time: 24.658775568008423 and batch: 1050, loss is 5.837853946685791 and perplexity is 343.04236295115714
At time: 25.811991691589355 and batch: 1100, loss is 5.9091856575012205 and perplexity is 368.4060245386932
At time: 26.96492314338684 and batch: 1150, loss is 5.814021034240723 and perplexity is 334.96332031744976
At time: 28.124812841415405 and batch: 1200, loss is 5.894407882690429 and perplexity is 363.00183258311085
At time: 29.278120517730713 and batch: 1250, loss is 5.81871506690979 and perplexity is 336.5393451481447
At time: 30.432339191436768 and batch: 1300, loss is 5.834040679931641 and perplexity is 341.7367418361324
At time: 31.58617115020752 and batch: 1350, loss is 5.802417316436768 and perplexity is 331.098964282269
At time: 32.73643088340759 and batch: 1400, loss is 5.816683349609375 and perplexity is 335.8562864643744
At time: 33.893349170684814 and batch: 1450, loss is 5.785877027511597 and perplexity is 325.6675342884139
At time: 35.10377907752991 and batch: 1500, loss is 5.75624002456665 and perplexity is 316.15734743098716
At time: 36.369587659835815 and batch: 1550, loss is 5.732373571395874 and perplexity is 308.70112363539647
At time: 37.64506125450134 and batch: 1600, loss is 5.744987154006958 and perplexity is 312.619611894901
At time: 38.92115807533264 and batch: 1650, loss is 5.738264255523681 and perplexity is 310.52495096606435
At time: 40.19725966453552 and batch: 1700, loss is 5.7457052516937255 and perplexity is 312.84418393772273
At time: 41.473938941955566 and batch: 1750, loss is 5.750397357940674 and perplexity is 314.3155312470353
At time: 42.750375747680664 and batch: 1800, loss is 5.754685859680176 and perplexity is 315.6663684130111
At time: 44.025296449661255 and batch: 1850, loss is 5.717773170471191 and perplexity is 304.22670708681187
At time: 45.301917552948 and batch: 1900, loss is 5.7096089744567875 and perplexity is 301.7530520595175
At time: 46.5775203704834 and batch: 1950, loss is 5.641184015274048 and perplexity is 281.79617200110823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.096867051235465 and perplexity of 163.508839195774
finished 1 epochs...
Completing Train Step...
At time: 50.05611062049866 and batch: 50, loss is 5.354450387954712 and perplexity is 211.54767524510945
At time: 51.11626386642456 and batch: 100, loss is 5.258177919387817 and perplexity is 192.13109382691022
At time: 52.178014039993286 and batch: 150, loss is 5.155330715179443 and perplexity is 173.35312779065933
At time: 53.2513153553009 and batch: 200, loss is 5.116284284591675 and perplexity is 166.71475274174335
At time: 54.330317974090576 and batch: 250, loss is 5.1221286487579345 and perplexity is 167.69194722740386
At time: 55.41134810447693 and batch: 300, loss is 5.1085707950592045 and perplexity is 165.43374710477212
At time: 56.50569677352905 and batch: 350, loss is 5.0999000549316404 and perplexity is 164.0055149383457
At time: 57.584333181381226 and batch: 400, loss is 5.0519564247131346 and perplexity is 156.32800948215208
At time: 58.662240982055664 and batch: 450, loss is 4.997013959884644 and perplexity is 147.9706524559471
At time: 59.74060940742493 and batch: 500, loss is 4.978720350265503 and perplexity is 145.2883444563622
At time: 60.81940412521362 and batch: 550, loss is 4.92485671043396 and perplexity is 137.6696136102906
At time: 61.89797830581665 and batch: 600, loss is 4.912410373687744 and perplexity is 135.96675042655644
At time: 62.97805833816528 and batch: 650, loss is 4.985377607345581 and perplexity is 146.25879299473635
At time: 64.05440473556519 and batch: 700, loss is 4.970770435333252 and perplexity is 144.13789352993118
At time: 65.13187503814697 and batch: 750, loss is 4.9249294090271 and perplexity is 137.67962236132487
At time: 66.20992636680603 and batch: 800, loss is 4.8999075603485105 and perplexity is 134.2773665582442
At time: 67.28866457939148 and batch: 850, loss is 4.890699691772461 and perplexity is 133.04663312570358
At time: 68.3665862083435 and batch: 900, loss is 4.885125141143799 and perplexity is 132.3070213503382
At time: 69.44506669044495 and batch: 950, loss is 4.946399745941162 and perplexity is 140.66761203048188
At time: 70.56876516342163 and batch: 1000, loss is 4.9096080493927 and perplexity is 135.58626087507432
At time: 71.67968678474426 and batch: 1050, loss is 4.820480442047119 and perplexity is 124.02466313119476
At time: 72.75883173942566 and batch: 1100, loss is 4.8929158973693845 and perplexity is 133.34181879393492
At time: 73.83651757240295 and batch: 1150, loss is 4.803965005874634 and perplexity is 121.99316345080604
At time: 74.91508603096008 and batch: 1200, loss is 4.89365629196167 and perplexity is 133.44058091245304
At time: 75.99386668205261 and batch: 1250, loss is 4.837448606491089 and perplexity is 126.1470899301831
At time: 77.07234025001526 and batch: 1300, loss is 4.860317687988282 and perplexity is 129.06519805820113
At time: 78.14933133125305 and batch: 1350, loss is 4.764261522293091 and perplexity is 117.24450285871366
At time: 79.22635793685913 and batch: 1400, loss is 4.776939754486084 and perplexity is 118.74041863565364
At time: 80.30375552177429 and batch: 1450, loss is 4.719099426269532 and perplexity is 112.06728235849229
At time: 81.38177037239075 and batch: 1500, loss is 4.699229965209961 and perplexity is 109.86254189268828
At time: 82.45941495895386 and batch: 1550, loss is 4.691365308761597 and perplexity is 109.00189950858828
At time: 83.5393295288086 and batch: 1600, loss is 4.757487134933472 and perplexity is 116.45292742712908
At time: 84.61729288101196 and batch: 1650, loss is 4.71672758102417 and perplexity is 111.80179108424133
At time: 85.69565343856812 and batch: 1700, loss is 4.739153814315796 and perplexity is 114.33741005453308
At time: 86.77435660362244 and batch: 1750, loss is 4.745096874237061 and perplexity is 115.0189473361931
At time: 87.85350108146667 and batch: 1800, loss is 4.704279108047485 and perplexity is 110.41865632835047
At time: 88.93297624588013 and batch: 1850, loss is 4.711358957290649 and perplexity is 111.20317763812842
At time: 90.01180791854858 and batch: 1900, loss is 4.786158599853516 and perplexity is 119.84012943740912
At time: 91.09104800224304 and batch: 1950, loss is 4.7007448196411135 and perplexity is 110.02909377016688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.541288721838662 and perplexity of 93.8116193341285
finished 2 epochs...
Completing Train Step...
At time: 94.53666043281555 and batch: 50, loss is 4.665271043777466 and perplexity is 106.19436464329594
At time: 95.63562893867493 and batch: 100, loss is 4.60137167930603 and perplexity is 99.62086985185579
At time: 96.68237328529358 and batch: 150, loss is 4.55648796081543 and perplexity is 95.24837569737079
At time: 97.72703814506531 and batch: 200, loss is 4.553325634002686 and perplexity is 94.94764496008638
At time: 98.79183578491211 and batch: 250, loss is 4.5511894702911375 and perplexity is 94.74503772458245
At time: 99.85927629470825 and batch: 300, loss is 4.571391792297363 and perplexity is 96.6785726716902
At time: 100.93190121650696 and batch: 350, loss is 4.584150428771973 and perplexity is 97.91996181198658
At time: 102.01741576194763 and batch: 400, loss is 4.542058877944946 and perplexity is 93.88389675447479
At time: 103.09611129760742 and batch: 450, loss is 4.532889394760132 and perplexity is 93.02696475781394
At time: 104.18836951255798 and batch: 500, loss is 4.540290966033935 and perplexity is 93.71806492637496
At time: 105.26837277412415 and batch: 550, loss is 4.496873836517334 and perplexity is 89.73616243795807
At time: 106.34137916564941 and batch: 600, loss is 4.484462080001831 and perplexity is 88.6292625351307
At time: 107.4119861125946 and batch: 650, loss is 4.548092555999756 and perplexity is 94.4520743386121
At time: 108.48360562324524 and batch: 700, loss is 4.562505502700805 and perplexity is 95.8232647623923
At time: 109.55544018745422 and batch: 750, loss is 4.52993631362915 and perplexity is 92.75265381409942
At time: 110.66145515441895 and batch: 800, loss is 4.501824731826782 and perplexity is 90.18153837875751
At time: 111.73120713233948 and batch: 850, loss is 4.497098426818848 and perplexity is 89.7563185730882
At time: 112.80081462860107 and batch: 900, loss is 4.469904623031616 and perplexity is 87.34839159135124
At time: 113.8702495098114 and batch: 950, loss is 4.555903902053833 and perplexity is 95.19276129163835
At time: 114.94140434265137 and batch: 1000, loss is 4.538538055419922 and perplexity is 93.55392943509133
At time: 116.01087546348572 and batch: 1050, loss is 4.465471811294556 and perplexity is 86.96204953931228
At time: 117.08109712600708 and batch: 1100, loss is 4.522556247711182 and perplexity is 92.0706528164945
At time: 118.15132594108582 and batch: 1150, loss is 4.464308557510376 and perplexity is 86.86094942005413
At time: 119.22756791114807 and batch: 1200, loss is 4.544310560226441 and perplexity is 94.09553163915749
At time: 120.30392932891846 and batch: 1250, loss is 4.515257043838501 and perplexity is 91.40105708169821
At time: 121.38122057914734 and batch: 1300, loss is 4.519346351623535 and perplexity is 91.77558940302713
At time: 122.4587333202362 and batch: 1350, loss is 4.408465261459351 and perplexity is 82.14329822796358
At time: 123.53664565086365 and batch: 1400, loss is 4.431828842163086 and perplexity is 84.08505467110712
At time: 124.61147475242615 and batch: 1450, loss is 4.3712574481964115 and perplexity is 79.14308748882954
At time: 125.68593907356262 and batch: 1500, loss is 4.3713919019699095 and perplexity is 79.1537292909879
At time: 126.76322484016418 and batch: 1550, loss is 4.373526525497437 and perplexity is 79.32287316884756
At time: 127.83994197845459 and batch: 1600, loss is 4.446997756958008 and perplexity is 85.37025661712433
At time: 128.91729998588562 and batch: 1650, loss is 4.404183511734009 and perplexity is 81.79233309197258
At time: 130.00536370277405 and batch: 1700, loss is 4.431173057556152 and perplexity is 84.02993106316288
At time: 131.08718514442444 and batch: 1750, loss is 4.4332770824432375 and perplexity is 84.20691825681756
At time: 132.16401505470276 and batch: 1800, loss is 4.392321014404297 and perplexity is 80.82780393196313
At time: 133.239022731781 and batch: 1850, loss is 4.421228704452514 and perplexity is 83.19844888568828
At time: 134.31537199020386 and batch: 1900, loss is 4.49962968826294 and perplexity is 89.98380307156276
At time: 135.3947310447693 and batch: 1950, loss is 4.43015869140625 and perplexity is 83.94473716172365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.415129053869912 and perplexity of 82.69251200620721
finished 3 epochs...
Completing Train Step...
At time: 138.78327059745789 and batch: 50, loss is 4.4002788591384885 and perplexity is 81.47358515123585
At time: 139.84823489189148 and batch: 100, loss is 4.347311382293701 and perplexity is 77.27043274011783
At time: 140.9006016254425 and batch: 150, loss is 4.311660375595093 and perplexity is 74.56419077880666
At time: 141.9524347782135 and batch: 200, loss is 4.316497840881348 and perplexity is 74.92576631273946
At time: 143.00673270225525 and batch: 250, loss is 4.306286296844482 and perplexity is 74.16455175320505
At time: 144.06019139289856 and batch: 300, loss is 4.32693489074707 and perplexity is 75.71186541379828
At time: 145.113707780838 and batch: 350, loss is 4.342591705322266 and perplexity is 76.90660051879364
At time: 146.1678967475891 and batch: 400, loss is 4.304723920822144 and perplexity is 74.04876930724932
At time: 147.22120237350464 and batch: 450, loss is 4.315888938903808 and perplexity is 74.88015775244341
At time: 148.2741560935974 and batch: 500, loss is 4.322673568725586 and perplexity is 75.38991921980718
At time: 149.32628750801086 and batch: 550, loss is 4.284076356887818 and perplexity is 72.53551883723603
At time: 150.37916779518127 and batch: 600, loss is 4.277904677391052 and perplexity is 72.08923145077314
At time: 151.4326832294464 and batch: 650, loss is 4.335556421279907 and perplexity is 76.36743953855449
At time: 152.48566246032715 and batch: 700, loss is 4.353007717132568 and perplexity is 77.71184702634615
At time: 153.53874254226685 and batch: 750, loss is 4.323521518707276 and perplexity is 75.45387321149026
At time: 154.59094715118408 and batch: 800, loss is 4.297769966125489 and perplexity is 73.53562378337382
At time: 155.6439232826233 and batch: 850, loss is 4.294066982269287 and perplexity is 73.26382609744596
At time: 156.69762325286865 and batch: 900, loss is 4.261290926933288 and perplexity is 70.9014529966085
At time: 157.75097179412842 and batch: 950, loss is 4.353247051239014 and perplexity is 77.73044834769092
At time: 158.80582547187805 and batch: 1000, loss is 4.337553834915161 and perplexity is 76.520129345164
At time: 159.86211371421814 and batch: 1050, loss is 4.276943731307983 and perplexity is 72.01999085974461
At time: 160.9202916622162 and batch: 1100, loss is 4.323416776657105 and perplexity is 75.44597043200064
At time: 161.97718238830566 and batch: 1150, loss is 4.277936391830444 and perplexity is 72.09151775658907
At time: 163.03526735305786 and batch: 1200, loss is 4.357258877754211 and perplexity is 78.04291578489489
At time: 164.12949085235596 and batch: 1250, loss is 4.333275985717774 and perplexity is 76.19348693288079
At time: 165.1859369277954 and batch: 1300, loss is 4.332914419174195 and perplexity is 76.16594289696823
At time: 166.24146461486816 and batch: 1350, loss is 4.219883141517639 and perplexity is 68.02553446420717
At time: 167.29864645004272 and batch: 1400, loss is 4.245052042007447 and perplexity is 69.75939046815589
At time: 168.35523176193237 and batch: 1450, loss is 4.180251717567444 and perplexity is 65.3823090185955
At time: 169.4120271205902 and batch: 1500, loss is 4.188400802612304 and perplexity is 65.91729186500045
At time: 170.4678430557251 and batch: 1550, loss is 4.194794311523437 and perplexity is 66.34008478287475
At time: 171.52408719062805 and batch: 1600, loss is 4.27287091255188 and perplexity is 71.7272630085418
At time: 172.58020687103271 and batch: 1650, loss is 4.223179278373718 and perplexity is 68.25012587418135
At time: 173.63434624671936 and batch: 1700, loss is 4.2510595703125 and perplexity is 70.17973332755517
At time: 174.68966460227966 and batch: 1750, loss is 4.251103758811951 and perplexity is 70.18283453318107
At time: 175.74571824073792 and batch: 1800, loss is 4.217596912384034 and perplexity is 67.87019014949841
At time: 176.79943871498108 and batch: 1850, loss is 4.249740571975708 and perplexity is 70.08722739701534
At time: 177.85587096214294 and batch: 1900, loss is 4.327997741699218 and perplexity is 75.7923786212325
At time: 178.91121912002563 and batch: 1950, loss is 4.2624212265014645 and perplexity is 70.98163818641945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375930005450582 and perplexity of 79.5137534008519
finished 4 epochs...
Completing Train Step...
At time: 182.24966716766357 and batch: 50, loss is 4.234771914482117 and perplexity is 69.04592856101978
At time: 183.29884123802185 and batch: 100, loss is 4.187589058876037 and perplexity is 65.86380562771336
At time: 184.33466124534607 and batch: 150, loss is 4.161570944786072 and perplexity is 64.1722545257314
At time: 185.36864519119263 and batch: 200, loss is 4.167692337036133 and perplexity is 64.566282837782
At time: 186.40516066551208 and batch: 250, loss is 4.1481944894790646 and perplexity is 63.31957287424375
At time: 187.44661378860474 and batch: 300, loss is 4.172422375679016 and perplexity is 64.87240727007911
At time: 188.48833775520325 and batch: 350, loss is 4.1837953758239745 and perplexity is 65.61441258274911
At time: 189.55562329292297 and batch: 400, loss is 4.151626281738281 and perplexity is 63.537245784763776
At time: 190.6116771697998 and batch: 450, loss is 4.174629402160645 and perplexity is 65.0157405027904
At time: 191.66671681404114 and batch: 500, loss is 4.182952399253845 and perplexity is 65.55912447684202
At time: 192.7211332321167 and batch: 550, loss is 4.1463211107254025 and perplexity is 63.20106237391674
At time: 193.77672624588013 and batch: 600, loss is 4.136495213508606 and perplexity is 62.583096238856314
At time: 194.83233499526978 and batch: 650, loss is 4.196204319000244 and perplexity is 66.43369077549698
At time: 195.92166996002197 and batch: 700, loss is 4.214492435455322 and perplexity is 67.65981543072448
At time: 197.00423550605774 and batch: 750, loss is 4.194131183624267 and perplexity is 66.29610740474666
At time: 198.08807253837585 and batch: 800, loss is 4.162782764434814 and perplexity is 64.2500668624067
At time: 199.15149545669556 and batch: 850, loss is 4.158595566749573 and perplexity is 63.98160158200578
At time: 200.2124342918396 and batch: 900, loss is 4.122648072242737 and perplexity is 61.72247161131999
At time: 201.27612686157227 and batch: 950, loss is 4.219558324813843 and perplexity is 68.00344222248734
At time: 202.33948493003845 and batch: 1000, loss is 4.201194324493408 and perplexity is 66.76602373946088
At time: 203.3994333744049 and batch: 1050, loss is 4.145857882499695 and perplexity is 63.17179263773781
At time: 204.45667958259583 and batch: 1100, loss is 4.188119807243347 and perplexity is 65.89877201337032
At time: 205.51373553276062 and batch: 1150, loss is 4.15157148361206 and perplexity is 63.533764158143725
At time: 206.57226657867432 and batch: 1200, loss is 4.2264327669143675 and perplexity is 68.47253848886758
At time: 207.62987279891968 and batch: 1250, loss is 4.206077508926391 and perplexity is 67.09285187883096
At time: 208.68752121925354 and batch: 1300, loss is 4.204863057136536 and perplexity is 67.01142030215081
At time: 209.7455232143402 and batch: 1350, loss is 4.096671228408813 and perplexity is 60.13976249849357
At time: 210.80307269096375 and batch: 1400, loss is 4.121893773078918 and perplexity is 61.675931957212455
At time: 211.86176013946533 and batch: 1450, loss is 4.05573727607727 and perplexity is 57.72770856884281
At time: 212.91923332214355 and batch: 1500, loss is 4.068303213119507 and perplexity is 58.45768815360546
At time: 213.97651362419128 and batch: 1550, loss is 4.076936058998108 and perplexity is 58.96452895739479
At time: 215.03442978858948 and batch: 1600, loss is 4.153100442886353 and perplexity is 63.63097899590954
At time: 216.0916085243225 and batch: 1650, loss is 4.10382483959198 and perplexity is 60.57152145265727
At time: 217.1492681503296 and batch: 1700, loss is 4.1283448743820195 and perplexity is 62.07509578104091
At time: 218.2082371711731 and batch: 1750, loss is 4.1312667083740235 and perplexity is 62.256734135287445
At time: 219.26560711860657 and batch: 1800, loss is 4.095371537208557 and perplexity is 60.06165015035011
At time: 220.32358598709106 and batch: 1850, loss is 4.128221197128296 and perplexity is 62.06741897840279
At time: 221.37874221801758 and batch: 1900, loss is 4.206320180892944 and perplexity is 67.10913540883624
At time: 222.43251776695251 and batch: 1950, loss is 4.143650732040405 and perplexity is 63.03251674456941
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359876056050146 and perplexity of 78.24743552581181
finished 5 epochs...
Completing Train Step...
At time: 225.73626375198364 and batch: 50, loss is 4.117692031860352 and perplexity is 61.41732932284937
At time: 226.75118851661682 and batch: 100, loss is 4.0762758684158324 and perplexity is 58.92561397775379
At time: 227.76369738578796 and batch: 150, loss is 4.051495604515075 and perplexity is 57.48336516763141
At time: 228.7749309539795 and batch: 200, loss is 4.059002556800842 and perplexity is 57.916513826177926
At time: 229.78728723526 and batch: 250, loss is 4.035307807922363 and perplexity is 56.5603272760005
At time: 230.80338191986084 and batch: 300, loss is 4.064907011985778 and perplexity is 58.25949083630351
At time: 231.83126425743103 and batch: 350, loss is 4.07253945350647 and perplexity is 58.70585424757845
At time: 232.8608546257019 and batch: 400, loss is 4.039608936309815 and perplexity is 56.80412443083473
At time: 233.9007749557495 and batch: 450, loss is 4.066038126945496 and perplexity is 58.32542630119939
At time: 234.94347715377808 and batch: 500, loss is 4.0773291635513305 and perplexity is 58.98771273873304
At time: 235.9880485534668 and batch: 550, loss is 4.044662303924561 and perplexity is 57.09190306683195
At time: 237.03107285499573 and batch: 600, loss is 4.037614326477051 and perplexity is 56.690935287319384
At time: 238.07422518730164 and batch: 650, loss is 4.093313055038452 and perplexity is 59.93814147822071
At time: 239.11731219291687 and batch: 700, loss is 4.111389269828797 and perplexity is 61.03144784848793
At time: 240.1615114212036 and batch: 750, loss is 4.09615469455719 and perplexity is 60.10870629681473
At time: 241.2050337791443 and batch: 800, loss is 4.061657967567444 and perplexity is 58.07051033205746
At time: 242.28511929512024 and batch: 850, loss is 4.061602354049683 and perplexity is 58.067280916500096
At time: 243.32726573944092 and batch: 900, loss is 4.026414241790771 and perplexity is 56.059534482727294
At time: 244.36860132217407 and batch: 950, loss is 4.125129852294922 and perplexity is 61.87584344899912
At time: 245.408029794693 and batch: 1000, loss is 4.101663098335266 and perplexity is 60.44072292297658
At time: 246.44804334640503 and batch: 1050, loss is 4.05342740058899 and perplexity is 57.59451863512647
At time: 247.5232274532318 and batch: 1100, loss is 4.090911779403687 and perplexity is 59.79438614665938
At time: 248.56498622894287 and batch: 1150, loss is 4.0530570697784425 and perplexity is 57.57319355926728
At time: 249.6058588027954 and batch: 1200, loss is 4.130532183647156 and perplexity is 62.21102181512104
At time: 250.65322828292847 and batch: 1250, loss is 4.110573205947876 and perplexity is 60.981662605030905
At time: 251.69608402252197 and batch: 1300, loss is 4.11132779121399 and perplexity is 61.027695834950016
At time: 252.7389497756958 and batch: 1350, loss is 4.000662961006165 and perplexity is 54.6343584786925
At time: 253.78197121620178 and batch: 1400, loss is 4.028446445465088 and perplexity is 56.17357471192252
At time: 254.82641077041626 and batch: 1450, loss is 3.9594771480560302 and perplexity is 52.4299057032402
At time: 255.87058782577515 and batch: 1500, loss is 3.9754587268829344 and perplexity is 53.27454976945693
At time: 256.9144797325134 and batch: 1550, loss is 3.983330512046814 and perplexity is 53.69557049826426
At time: 257.9569444656372 and batch: 1600, loss is 4.064906005859375 and perplexity is 58.25943221992102
At time: 259.001122713089 and batch: 1650, loss is 4.015039973258972 and perplexity is 55.42551089651403
At time: 260.0435411930084 and batch: 1700, loss is 4.036234841346741 and perplexity is 56.61278490110822
At time: 261.08770775794983 and batch: 1750, loss is 4.0369998598098755 and perplexity is 56.65611129744052
At time: 262.12997794151306 and batch: 1800, loss is 4.003898696899414 and perplexity is 54.81142715266644
At time: 263.18932271003723 and batch: 1850, loss is 4.03245641708374 and perplexity is 56.399281388474655
At time: 264.24783635139465 and batch: 1900, loss is 4.114401898384094 and perplexity is 61.21559016798052
At time: 265.31831407546997 and batch: 1950, loss is 4.054214224815369 and perplexity is 57.639853230535365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35726318359375 and perplexity of 78.04325182589082
finished 6 epochs...
Completing Train Step...
At time: 268.6260552406311 and batch: 50, loss is 4.028985714912414 and perplexity is 56.20387557394201
At time: 269.6482412815094 and batch: 100, loss is 3.9899571180343627 and perplexity is 54.052571433117436
At time: 270.6748113632202 and batch: 150, loss is 3.9740907526016236 and perplexity is 53.20172138056269
At time: 271.70739221572876 and batch: 200, loss is 3.9789812994003295 and perplexity is 53.46254415187964
At time: 272.74181032180786 and batch: 250, loss is 3.953938293457031 and perplexity is 52.14030684228323
At time: 273.776415348053 and batch: 300, loss is 3.9738346004486083 and perplexity is 53.188095390324804
At time: 274.8138175010681 and batch: 350, loss is 3.9868358039855956 and perplexity is 53.884119415119805
At time: 275.85527777671814 and batch: 400, loss is 3.952161169052124 and perplexity is 52.04772931576996
At time: 276.89680910110474 and batch: 450, loss is 3.9852567529678344 and perplexity is 53.799100783560014
At time: 277.9392297267914 and batch: 500, loss is 3.997363018989563 and perplexity is 54.45436541028109
At time: 278.9805955886841 and batch: 550, loss is 3.9648672008514403 and perplexity is 52.713268647617106
At time: 280.0227518081665 and batch: 600, loss is 3.9573007345199587 and perplexity is 52.31592063109315
At time: 281.090548992157 and batch: 650, loss is 4.016020355224609 and perplexity is 55.47987571262144
At time: 282.13256311416626 and batch: 700, loss is 4.033166117668152 and perplexity is 56.43932219824891
At time: 283.17386054992676 and batch: 750, loss is 4.021818294525146 and perplexity is 55.802478977757815
At time: 284.2150447368622 and batch: 800, loss is 3.985689992904663 and perplexity is 53.82241375227483
At time: 285.2572269439697 and batch: 850, loss is 3.986304531097412 and perplexity is 53.85549984644451
At time: 286.2996997833252 and batch: 900, loss is 3.9489303970336915 and perplexity is 51.87984631016071
At time: 287.3417592048645 and batch: 950, loss is 4.05140706539154 and perplexity is 57.4782758661661
At time: 288.3840527534485 and batch: 1000, loss is 4.02740026473999 and perplexity is 56.114837730905045
At time: 289.4597818851471 and batch: 1050, loss is 3.9732213973999024 and perplexity is 53.15549028587301
At time: 290.5134217739105 and batch: 1100, loss is 4.011606483459473 and perplexity is 55.23553429820884
At time: 291.5636930465698 and batch: 1150, loss is 3.9740037965774535 and perplexity is 53.19709537152502
At time: 292.61433362960815 and batch: 1200, loss is 4.052385106086731 and perplexity is 57.53451945883044
At time: 293.6665790081024 and batch: 1250, loss is 4.0360372400283815 and perplexity is 56.60159924536231
At time: 294.7208342552185 and batch: 1300, loss is 4.036885952949524 and perplexity is 56.64965814521901
At time: 295.774160861969 and batch: 1350, loss is 3.9273748064041136 and perplexity is 50.773512260356235
At time: 296.8278388977051 and batch: 1400, loss is 3.9619777679443358 and perplexity is 52.56117702962408
At time: 297.88259625434875 and batch: 1450, loss is 3.8877367210388183 and perplexity is 48.800312720172165
At time: 298.93599224090576 and batch: 1500, loss is 3.903471813201904 and perplexity is 49.57426326128833
At time: 299.9924898147583 and batch: 1550, loss is 3.91077036857605 and perplexity is 49.93740736849814
At time: 301.04607629776 and batch: 1600, loss is 3.993472294807434 and perplexity is 54.24291011781287
At time: 302.09760069847107 and batch: 1650, loss is 3.9436432695388794 and perplexity is 51.60627478934051
At time: 303.1496751308441 and batch: 1700, loss is 3.968584098815918 and perplexity is 52.90956306572665
At time: 304.20272278785706 and batch: 1750, loss is 3.9643779754638673 and perplexity is 52.687486285540004
At time: 305.2557291984558 and batch: 1800, loss is 3.9274113368988037 and perplexity is 50.775367075754716
At time: 306.3075406551361 and batch: 1850, loss is 3.9637450885772707 and perplexity is 52.65415161603242
At time: 307.36142563819885 and batch: 1900, loss is 4.0396535158157345 and perplexity is 56.80665678708123
At time: 308.4135568141937 and batch: 1950, loss is 3.980662064552307 and perplexity is 53.55247769043335
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357060773982558 and perplexity of 78.02745672022711
finished 7 epochs...
Completing Train Step...
At time: 311.7785995006561 and batch: 50, loss is 3.9583912801742556 and perplexity is 52.37300465169578
At time: 312.80534958839417 and batch: 100, loss is 3.9231963968276977 and perplexity is 50.56180234389256
At time: 313.83352875709534 and batch: 150, loss is 3.909399266242981 and perplexity is 49.86898499050789
At time: 314.86214995384216 and batch: 200, loss is 3.912707977294922 and perplexity is 50.03426032567888
At time: 315.8893029689789 and batch: 250, loss is 3.882634468078613 and perplexity is 48.551955310092275
At time: 316.91578578948975 and batch: 300, loss is 3.907967166900635 and perplexity is 49.79761876385977
At time: 317.94426560401917 and batch: 350, loss is 3.9176622152328493 and perplexity is 50.282757003947815
At time: 318.97998809814453 and batch: 400, loss is 3.8841615867614747 and perplexity is 48.6261565507659
At time: 320.0301306247711 and batch: 450, loss is 3.9227750396728513 and perplexity is 50.5405022545007
At time: 321.06693148612976 and batch: 500, loss is 3.9333192491531372 and perplexity is 51.07623135389869
At time: 322.1032865047455 and batch: 550, loss is 3.901200432777405 and perplexity is 49.4617890343924
At time: 323.13964462280273 and batch: 600, loss is 3.8935004901885986 and perplexity is 49.08239861518628
At time: 324.1761312484741 and batch: 650, loss is 3.9531554126739503 and perplexity is 52.09950317232107
At time: 325.21472668647766 and batch: 700, loss is 3.968426685333252 and perplexity is 52.901235042626894
At time: 326.26206612586975 and batch: 750, loss is 3.9608437204360962 and perplexity is 52.50160394352299
At time: 327.30908966064453 and batch: 800, loss is 3.925884847640991 and perplexity is 50.69791815086711
At time: 328.35015416145325 and batch: 850, loss is 3.922987494468689 and perplexity is 50.55124096729384
At time: 329.3923909664154 and batch: 900, loss is 3.8854846477508547 and perplexity is 48.69053450014732
At time: 330.43484568595886 and batch: 950, loss is 3.988804898262024 and perplexity is 53.99032685816781
At time: 331.47747802734375 and batch: 1000, loss is 3.9660096883773805 and perplexity is 52.77352731533212
At time: 332.52044892311096 and batch: 1050, loss is 3.9130796337127687 and perplexity is 50.052859335647746
At time: 333.5631904602051 and batch: 1100, loss is 3.945397663116455 and perplexity is 51.69689197225286
At time: 334.6051342487335 and batch: 1150, loss is 3.9120209646224975 and perplexity is 49.999897959821695
At time: 335.6475784778595 and batch: 1200, loss is 3.9926920557022094 and perplexity is 54.2006041846757
At time: 336.6895625591278 and batch: 1250, loss is 3.9752057123184206 and perplexity is 53.26107223752518
At time: 337.73118019104004 and batch: 1300, loss is 3.9756952285766602 and perplexity is 53.28715078073141
At time: 338.77071714401245 and batch: 1350, loss is 3.866369743347168 and perplexity is 47.76865844354512
At time: 339.8150782585144 and batch: 1400, loss is 3.8998242378234864 and perplexity is 49.39376678658427
At time: 340.85708141326904 and batch: 1450, loss is 3.828316607475281 and perplexity is 45.98506213132368
At time: 341.899028301239 and batch: 1500, loss is 3.842990517616272 and perplexity is 46.66481794145704
At time: 342.94203186035156 and batch: 1550, loss is 3.8498001718521118 and perplexity is 46.983673632974416
At time: 343.9844708442688 and batch: 1600, loss is 3.9332468414306643 and perplexity is 51.072533174203855
At time: 345.02719163894653 and batch: 1650, loss is 3.8891655445098876 and perplexity is 48.87008958992588
At time: 346.0682804584503 and batch: 1700, loss is 3.912760214805603 and perplexity is 50.03687405915393
At time: 347.11027336120605 and batch: 1750, loss is 3.9036788654327395 and perplexity is 49.5845287858018
At time: 348.15305352211 and batch: 1800, loss is 3.869524984359741 and perplexity is 47.9196181055998
At time: 349.20106267929077 and batch: 1850, loss is 3.905176963806152 and perplexity is 49.65886695676566
At time: 350.27014780044556 and batch: 1900, loss is 3.980173363685608 and perplexity is 53.526312942060486
At time: 351.31303215026855 and batch: 1950, loss is 3.9225857257843018 and perplexity is 50.53093514111194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359520064952761 and perplexity of 78.21958509291866
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 354.65871238708496 and batch: 50, loss is 3.932788782119751 and perplexity is 51.04914428201036
At time: 355.73383355140686 and batch: 100, loss is 3.9284564638137818 and perplexity is 50.82846151888638
At time: 356.7531418800354 and batch: 150, loss is 3.9100044918060304 and perplexity is 49.89917611032463
At time: 357.7747504711151 and batch: 200, loss is 3.914773874282837 and perplexity is 50.13773279831192
At time: 358.79782915115356 and batch: 250, loss is 3.891739873886108 and perplexity is 48.99605937146172
At time: 359.8253524303436 and batch: 300, loss is 3.9097782373428345 and perplexity is 49.887887476119964
At time: 360.85207414627075 and batch: 350, loss is 3.9192398595809936 and perplexity is 50.36214792019261
At time: 361.8845708370209 and batch: 400, loss is 3.870860662460327 and perplexity is 47.983666054291135
At time: 362.92039227485657 and batch: 450, loss is 3.902486915588379 and perplexity is 49.52546172391376
At time: 363.957994222641 and batch: 500, loss is 3.9108367776870727 and perplexity is 49.940723777446934
At time: 364.9957654476166 and batch: 550, loss is 3.868088641166687 and perplexity is 47.85083849570715
At time: 366.0376160144806 and batch: 600, loss is 3.8484243822097777 and perplexity is 46.91907842632829
At time: 367.07879161834717 and batch: 650, loss is 3.9003963756561277 and perplexity is 49.42203491512132
At time: 368.1210527420044 and batch: 700, loss is 3.9155414962768553 and perplexity is 50.17623440018575
At time: 369.16294288635254 and batch: 750, loss is 3.888528847694397 and perplexity is 48.83898406295702
At time: 370.20369696617126 and batch: 800, loss is 3.8527155923843384 and perplexity is 47.120850666970796
At time: 371.28907203674316 and batch: 850, loss is 3.846484670639038 and perplexity is 46.82815715604375
At time: 372.38630294799805 and batch: 900, loss is 3.8021640825271605 and perplexity is 44.798026294636685
At time: 373.42918944358826 and batch: 950, loss is 3.9092559671401976 and perplexity is 49.86183932169822
At time: 374.4726071357727 and batch: 1000, loss is 3.8721405458450318 and perplexity is 48.045118869040685
At time: 375.5166389942169 and batch: 1050, loss is 3.8118989276885986 and perplexity is 45.236257740964945
At time: 376.5593030452728 and batch: 1100, loss is 3.8358653354644776 and perplexity is 46.33350435007011
At time: 377.6014823913574 and batch: 1150, loss is 3.7948184251785277 and perplexity is 44.470161010860366
At time: 378.6443305015564 and batch: 1200, loss is 3.859240326881409 and perplexity is 47.42930691009077
At time: 379.6870958805084 and batch: 1250, loss is 3.8436806058883666 and perplexity is 46.6970318989966
At time: 380.7324299812317 and batch: 1300, loss is 3.8419987869262697 and perplexity is 46.618561949895515
At time: 381.7768290042877 and batch: 1350, loss is 3.7280967330932615 and perplexity is 41.59985713860873
At time: 382.84616446495056 and batch: 1400, loss is 3.755415120124817 and perplexity is 42.75196332780486
At time: 383.9056832790375 and batch: 1450, loss is 3.6752019214630125 and perplexity is 39.456623191966926
At time: 384.94426918029785 and batch: 1500, loss is 3.6879997777938844 and perplexity is 39.96482841926935
At time: 385.9865553379059 and batch: 1550, loss is 3.687418818473816 and perplexity is 39.94161722275755
At time: 387.0302426815033 and batch: 1600, loss is 3.7583240699768066 and perplexity is 42.87650770404754
At time: 388.0732970237732 and batch: 1650, loss is 3.7108962678909303 and perplexity is 40.890438895758415
At time: 389.11604261398315 and batch: 1700, loss is 3.717696256637573 and perplexity is 41.169440950427344
At time: 390.15908312797546 and batch: 1750, loss is 3.69852162361145 and perplexity is 40.38755219929564
At time: 391.20208859443665 and batch: 1800, loss is 3.6612448263168336 and perplexity is 38.909748615767704
At time: 392.24577951431274 and batch: 1850, loss is 3.6877012252807617 and perplexity is 39.9528986002356
At time: 393.2887237071991 and batch: 1900, loss is 3.75666154384613 and perplexity is 42.805283611959766
At time: 394.33002400398254 and batch: 1950, loss is 3.693869500160217 and perplexity is 40.200100682442795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.285008346202762 and perplexity of 72.60315267785907
finished 9 epochs...
Completing Train Step...
At time: 397.60268473625183 and batch: 50, loss is 3.8475348806381224 and perplexity is 46.877362388318666
At time: 398.6286373138428 and batch: 100, loss is 3.8272998189926146 and perplexity is 45.93832881275021
At time: 399.64011549949646 and batch: 150, loss is 3.8061633825302126 and perplexity is 44.977545778193644
At time: 400.65947341918945 and batch: 200, loss is 3.807520618438721 and perplexity is 45.03863236347667
At time: 401.6809084415436 and batch: 250, loss is 3.785253186225891 and perplexity is 44.04682119551753
At time: 402.7086589336395 and batch: 300, loss is 3.804220447540283 and perplexity is 44.89024217082102
At time: 403.7355408668518 and batch: 350, loss is 3.8158316469192504 and perplexity is 45.41450951906242
At time: 404.7702283859253 and batch: 400, loss is 3.77053774356842 and perplexity is 43.4033984599056
At time: 405.8047983646393 and batch: 450, loss is 3.810112614631653 and perplexity is 45.15552375267154
At time: 406.84019136428833 and batch: 500, loss is 3.816921715736389 and perplexity is 45.46404145143757
At time: 407.8757197856903 and batch: 550, loss is 3.7788978242874145 and perplexity is 43.76777536244961
At time: 408.9092450141907 and batch: 600, loss is 3.7653133153915403 and perplexity is 43.177231832098826
At time: 409.9779005050659 and batch: 650, loss is 3.8170170164108277 and perplexity is 45.46837441171434
At time: 411.0113422870636 and batch: 700, loss is 3.833207688331604 and perplexity is 46.21052972903437
At time: 412.0479850769043 and batch: 750, loss is 3.8106132698059083 and perplexity is 45.17813675947162
At time: 413.08607840538025 and batch: 800, loss is 3.775105562210083 and perplexity is 43.60211080797576
At time: 414.12912011146545 and batch: 850, loss is 3.7725795841217042 and perplexity is 43.4921118174756
At time: 415.2009437084198 and batch: 900, loss is 3.7286896991729734 and perplexity is 41.62453175769588
At time: 416.2461361885071 and batch: 950, loss is 3.840454115867615 and perplexity is 46.54660719397696
At time: 417.28802609443665 and batch: 1000, loss is 3.8053206825256347 and perplexity is 44.9396591659267
At time: 418.3297612667084 and batch: 1050, loss is 3.749292702674866 and perplexity is 42.491017585995515
At time: 419.37308502197266 and batch: 1100, loss is 3.7751211738586425 and perplexity is 43.602791514119616
At time: 420.4176754951477 and batch: 1150, loss is 3.7371314430236815 and perplexity is 41.977402720287
At time: 421.46098256111145 and batch: 1200, loss is 3.803340482711792 and perplexity is 44.8507577115838
At time: 422.50378227233887 and batch: 1250, loss is 3.790836772918701 and perplexity is 44.293448331456545
At time: 423.54571652412415 and batch: 1300, loss is 3.791321210861206 and perplexity is 44.31491095666795
At time: 424.5879991054535 and batch: 1350, loss is 3.6777624034881593 and perplexity is 39.55778061704101
At time: 425.6555869579315 and batch: 1400, loss is 3.709649434089661 and perplexity is 40.83948708521503
At time: 426.70281434059143 and batch: 1450, loss is 3.6330382299423216 and perplexity is 37.82757106276031
At time: 427.7456295490265 and batch: 1500, loss is 3.646037425994873 and perplexity is 38.322509003364566
At time: 428.78904128074646 and batch: 1550, loss is 3.649509620666504 and perplexity is 38.45580349322029
At time: 429.8289325237274 and batch: 1600, loss is 3.7253799343109133 and perplexity is 41.486992082633385
At time: 430.88185834884644 and batch: 1650, loss is 3.6796254110336304 and perplexity is 39.63154575197882
At time: 431.92450976371765 and batch: 1700, loss is 3.6914174938201905 and perplexity is 40.10165053022472
At time: 432.9665973186493 and batch: 1750, loss is 3.6753653621673585 and perplexity is 39.46307253728095
At time: 434.0090160369873 and batch: 1800, loss is 3.641909637451172 and perplexity is 38.16464782266609
At time: 435.05404472351074 and batch: 1850, loss is 3.672532625198364 and perplexity is 39.35144221710907
At time: 436.0978329181671 and batch: 1900, loss is 3.7439314270019532 and perplexity is 42.26382110278099
At time: 437.1436460018158 and batch: 1950, loss is 3.6830499362945557 and perplexity is 39.76749763399994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.28737679414971 and perplexity of 72.77531326197332
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 440.4480884075165 and batch: 50, loss is 3.827071957588196 and perplexity is 45.927862433117554
At time: 441.47491908073425 and batch: 100, loss is 3.8365840196609495 and perplexity is 46.36681547606979
At time: 442.4924442768097 and batch: 150, loss is 3.824561553001404 and perplexity is 45.81270951728367
At time: 443.51605319976807 and batch: 200, loss is 3.8301632595062256 and perplexity is 46.07005899536326
At time: 444.5428409576416 and batch: 250, loss is 3.820776414871216 and perplexity is 45.63962985550281
At time: 445.56776213645935 and batch: 300, loss is 3.8358277463912964 and perplexity is 46.331762749317136
At time: 446.5950982570648 and batch: 350, loss is 3.8542112207412718 and perplexity is 47.19137867612933
At time: 447.6218726634979 and batch: 400, loss is 3.8148079442977907 and perplexity is 45.368042354952316
At time: 448.65593218803406 and batch: 450, loss is 3.849772434234619 and perplexity is 46.98237043588066
At time: 449.6914486885071 and batch: 500, loss is 3.8525788307189943 and perplexity is 47.11440678160944
At time: 450.7430188655853 and batch: 550, loss is 3.817915678024292 and perplexity is 45.50925345988933
At time: 451.7794761657715 and batch: 600, loss is 3.7877148723602296 and perplexity is 44.15538421373114
At time: 452.81571555137634 and batch: 650, loss is 3.82997013092041 and perplexity is 46.061162409141254
At time: 453.8514246940613 and batch: 700, loss is 3.852532320022583 and perplexity is 47.11221550869824
At time: 454.8885178565979 and batch: 750, loss is 3.8195457792282106 and perplexity is 45.58349864588673
At time: 455.923465013504 and batch: 800, loss is 3.7784838771820066 and perplexity is 43.74966156786326
At time: 456.95882868766785 and batch: 850, loss is 3.7779821252822874 and perplexity is 43.7277155982359
At time: 457.9948992729187 and batch: 900, loss is 3.7292257928848267 and perplexity is 41.64685238987072
At time: 459.0328359603882 and batch: 950, loss is 3.84279354095459 and perplexity is 46.655626966634415
At time: 460.0689880847931 and batch: 1000, loss is 3.804122943878174 and perplexity is 44.885865421194424
At time: 461.10679483413696 and batch: 1050, loss is 3.7476804208755494 and perplexity is 42.42256528873189
At time: 462.1421377658844 and batch: 1100, loss is 3.7653123044967653 and perplexity is 43.17718818448283
At time: 463.1791887283325 and batch: 1150, loss is 3.7270384216308594 and perplexity is 41.55585482115009
At time: 464.2143626213074 and batch: 1200, loss is 3.786448292732239 and perplexity is 44.09949330623413
At time: 465.2516167163849 and batch: 1250, loss is 3.773531856536865 and perplexity is 43.533547881915794
At time: 466.2877929210663 and batch: 1300, loss is 3.7752894258499143 and perplexity is 43.61012838782137
At time: 467.3236241340637 and batch: 1350, loss is 3.6611202573776245 and perplexity is 38.904901971534684
At time: 468.3592584133148 and batch: 1400, loss is 3.679996995925903 and perplexity is 39.64627497204602
At time: 469.40292835235596 and batch: 1450, loss is 3.5990530490875243 and perplexity is 36.56359411610999
At time: 470.44476342201233 and batch: 1500, loss is 3.610992126464844 and perplexity is 37.00274601325773
At time: 471.4885575771332 and batch: 1550, loss is 3.6121756649017334 and perplexity is 37.046566111705154
At time: 472.5313801765442 and batch: 1600, loss is 3.6899093103408815 and perplexity is 40.041215468438445
At time: 473.5731065273285 and batch: 1650, loss is 3.643071789741516 and perplexity is 38.20902673807763
At time: 474.61558628082275 and batch: 1700, loss is 3.651756544113159 and perplexity is 38.54230788773099
At time: 475.65862822532654 and batch: 1750, loss is 3.627973265647888 and perplexity is 37.63646015949385
At time: 476.6984989643097 and batch: 1800, loss is 3.5909591913223267 and perplexity is 36.268848011552805
At time: 477.7383794784546 and batch: 1850, loss is 3.617413783073425 and perplexity is 37.2411295310778
At time: 478.7808201313019 and batch: 1900, loss is 3.6939828157424928 and perplexity is 40.204656238362034
At time: 479.82327151298523 and batch: 1950, loss is 3.636565704345703 and perplexity is 37.961242474060285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.255639932321948 and perplexity of 70.50191921263539
finished 11 epochs...
Completing Train Step...
At time: 483.1462254524231 and batch: 50, loss is 3.8258231401443483 and perplexity is 45.8705427157333
At time: 484.16855025291443 and batch: 100, loss is 3.8135891437530516 and perplexity is 45.31278144307183
At time: 485.1909646987915 and batch: 150, loss is 3.786559782028198 and perplexity is 44.104410201780524
At time: 486.21360540390015 and batch: 200, loss is 3.786036343574524 and perplexity is 44.08133029848571
At time: 487.23727583885193 and batch: 250, loss is 3.770827040672302 and perplexity is 43.41595675383013
At time: 488.26394057273865 and batch: 300, loss is 3.783555278778076 and perplexity is 43.972097224901944
At time: 489.29738759994507 and batch: 350, loss is 3.8023764181137083 and perplexity is 44.80753951978852
At time: 490.34811305999756 and batch: 400, loss is 3.76372435092926 and perplexity is 43.10867922339102
At time: 491.3841931819916 and batch: 450, loss is 3.8021906137466432 and perplexity is 44.79921485667163
At time: 492.41989731788635 and batch: 500, loss is 3.8065293550491335 and perplexity is 44.99400933633813
At time: 493.4556486606598 and batch: 550, loss is 3.7734721279144288 and perplexity is 43.53094776072264
At time: 494.4923634529114 and batch: 600, loss is 3.747112760543823 and perplexity is 42.3984905150409
At time: 495.52890062332153 and batch: 650, loss is 3.7906405878067018 and perplexity is 44.284759468675425
At time: 496.56474590301514 and batch: 700, loss is 3.815381908416748 and perplexity is 45.394089457747526
At time: 497.5988712310791 and batch: 750, loss is 3.7857818365097047 and perplexity is 44.07011271603565
At time: 498.63400053977966 and batch: 800, loss is 3.7451406860351564 and perplexity is 42.31495992403626
At time: 499.669899225235 and batch: 850, loss is 3.745673108100891 and perplexity is 42.337495341054776
At time: 500.7049307823181 and batch: 900, loss is 3.6967902612686157 and perplexity is 40.31768721055618
At time: 501.7825255393982 and batch: 950, loss is 3.8122479724884033 and perplexity is 45.25204997743072
At time: 502.819397687912 and batch: 1000, loss is 3.775879864692688 and perplexity is 43.635885104694665
At time: 503.85660696029663 and batch: 1050, loss is 3.72118803024292 and perplexity is 41.31344658891318
At time: 504.8922243118286 and batch: 1100, loss is 3.7400934743881225 and perplexity is 42.101925432789265
At time: 505.9289984703064 and batch: 1150, loss is 3.7037807083129883 and perplexity is 40.600513256479445
At time: 506.96423387527466 and batch: 1200, loss is 3.764706792831421 and perplexity is 43.15105180709961
At time: 508.000324010849 and batch: 1250, loss is 3.753651189804077 and perplexity is 42.67661831463242
At time: 509.0346381664276 and batch: 1300, loss is 3.7566189193725585 and perplexity is 42.803459098164474
At time: 510.07045912742615 and batch: 1350, loss is 3.6439989471435545 and perplexity is 38.24446894775715
At time: 511.10674023628235 and batch: 1400, loss is 3.6655525875091555 and perplexity is 39.077724060150764
At time: 512.1426427364349 and batch: 1450, loss is 3.5873602628707886 and perplexity is 36.13855362326421
At time: 513.1779873371124 and batch: 1500, loss is 3.600800247192383 and perplexity is 36.62753379983787
At time: 514.214035987854 and batch: 1550, loss is 3.605497884750366 and perplexity is 36.80000145637772
At time: 515.2503066062927 and batch: 1600, loss is 3.6857438039779664 and perplexity is 39.87477043522001
At time: 516.2860949039459 and batch: 1650, loss is 3.6395826625823973 and perplexity is 38.07594289340438
At time: 517.3223686218262 and batch: 1700, loss is 3.65051992893219 and perplexity is 38.494675342321855
At time: 518.3587074279785 and batch: 1750, loss is 3.6287344169616698 and perplexity is 37.66511810572347
At time: 519.3950159549713 and batch: 1800, loss is 3.593277440071106 and perplexity is 36.353025757853224
At time: 520.4304049015045 and batch: 1850, loss is 3.6212331676483154 and perplexity is 37.38363970409734
At time: 521.4677319526672 and batch: 1900, loss is 3.6986799907684325 and perplexity is 40.39394876760472
At time: 522.5024261474609 and batch: 1950, loss is 3.64205406665802 and perplexity is 38.17016031055329
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25473746366279 and perplexity of 70.43832214163359
finished 12 epochs...
Completing Train Step...
At time: 525.7933049201965 and batch: 50, loss is 3.809636106491089 and perplexity is 45.13401190370459
At time: 526.8094880580902 and batch: 100, loss is 3.7957035446166993 and perplexity is 44.50953983970223
At time: 527.8455185890198 and batch: 150, loss is 3.767152485847473 and perplexity is 43.256715190571015
At time: 528.8667929172516 and batch: 200, loss is 3.765474348068237 and perplexity is 43.18418533716885
At time: 529.893474817276 and batch: 250, loss is 3.74912278175354 and perplexity is 42.4837980865286
At time: 530.9186971187592 and batch: 300, loss is 3.761699481010437 and perplexity is 43.021478070881116
At time: 531.9533214569092 and batch: 350, loss is 3.780493588447571 and perplexity is 43.8376741659126
At time: 532.9891219139099 and batch: 400, loss is 3.741474814414978 and perplexity is 42.16012269344621
At time: 534.0251002311707 and batch: 450, loss is 3.7813780069351197 and perplexity is 43.87646216527962
At time: 535.062059879303 and batch: 500, loss is 3.7856572818756105 and perplexity is 44.06462392110633
At time: 536.0988504886627 and batch: 550, loss is 3.753120250701904 and perplexity is 42.6539656433473
At time: 537.13587641716 and batch: 600, loss is 3.7278521347045896 and perplexity is 41.58968312490805
At time: 538.1726326942444 and batch: 650, loss is 3.7716598892211914 and perplexity is 43.45213073204286
At time: 539.2090337276459 and batch: 700, loss is 3.7972389221191407 and perplexity is 44.57793127571682
At time: 540.2447307109833 and batch: 750, loss is 3.768673663139343 and perplexity is 43.322566396421095
At time: 541.2863237857819 and batch: 800, loss is 3.72793749332428 and perplexity is 41.59323331437043
At time: 542.3273787498474 and batch: 850, loss is 3.729346947669983 and perplexity is 41.651898410993084
At time: 543.3698148727417 and batch: 900, loss is 3.6804773712158205 and perplexity is 39.66532463800794
At time: 544.4141685962677 and batch: 950, loss is 3.7963495206832887 and perplexity is 44.53830122575695
At time: 545.4562699794769 and batch: 1000, loss is 3.761088180541992 and perplexity is 42.9951870578562
At time: 546.4988431930542 and batch: 1050, loss is 3.707195544242859 and perplexity is 40.73939434101871
At time: 547.542236328125 and batch: 1100, loss is 3.7264276790618895 and perplexity is 41.53048264034499
At time: 548.5868618488312 and batch: 1150, loss is 3.69057165145874 and perplexity is 40.0677451967473
At time: 549.6306467056274 and batch: 1200, loss is 3.752362904548645 and perplexity is 42.62167405604424
At time: 550.6880970001221 and batch: 1250, loss is 3.741932363510132 and perplexity is 42.179417433244936
At time: 551.7335834503174 and batch: 1300, loss is 3.745612540245056 and perplexity is 42.334931127395805
At time: 552.7750539779663 and batch: 1350, loss is 3.6335445547103884 and perplexity is 37.846728948551956
At time: 553.8144295215607 and batch: 1400, loss is 3.6557556056976317 and perplexity is 38.69674955562673
At time: 554.8581523895264 and batch: 1450, loss is 3.5785465955734255 and perplexity is 35.82143995500373
At time: 555.8989059925079 and batch: 1500, loss is 3.5922448348999025 and perplexity is 36.31550680993038
At time: 556.9389860630035 and batch: 1550, loss is 3.5984978675842285 and perplexity is 36.543300318854406
At time: 557.9808943271637 and batch: 1600, loss is 3.680097556114197 and perplexity is 39.65026200938761
At time: 559.0239436626434 and batch: 1650, loss is 3.6337128639221192 and perplexity is 37.85309943775884
At time: 560.0650007724762 and batch: 1700, loss is 3.6457505512237547 and perplexity is 38.3115168191311
At time: 561.1082723140717 and batch: 1750, loss is 3.6247799301147463 and perplexity is 37.51646600668976
At time: 562.1499106884003 and batch: 1800, loss is 3.5902622509002686 and perplexity is 36.24357959162649
At time: 563.1923744678497 and batch: 1850, loss is 3.618654041290283 and perplexity is 37.28734680273481
At time: 564.2349801063538 and batch: 1900, loss is 3.69665114402771 and perplexity is 40.31207871527999
At time: 565.277131319046 and batch: 1950, loss is 3.640188899040222 and perplexity is 38.09903291645213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.255677121184593 and perplexity of 70.50454114757831
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 568.5874881744385 and batch: 50, loss is 3.8063734769821167 and perplexity is 44.986996303738636
At time: 569.5971007347107 and batch: 100, loss is 3.809604911804199 and perplexity is 45.13260398429508
At time: 570.6066844463348 and batch: 150, loss is 3.7883918571472166 and perplexity is 44.185286857782906
At time: 571.6188380718231 and batch: 200, loss is 3.7925747728347776 and perplexity is 44.37049727707508
At time: 572.6391310691833 and batch: 250, loss is 3.779522109031677 and perplexity is 43.79510744751289
At time: 573.6605513095856 and batch: 300, loss is 3.788107361793518 and perplexity is 44.172718136926136
At time: 574.6814353466034 and batch: 350, loss is 3.8095013332366943 and perplexity is 45.12792945592128
At time: 575.7064418792725 and batch: 400, loss is 3.7776197004318237 and perplexity is 43.71187045895865
At time: 576.7348899841309 and batch: 450, loss is 3.820047240257263 and perplexity is 45.606362726269026
At time: 577.7698454856873 and batch: 500, loss is 3.8248575592041014 and perplexity is 45.82627237070851
At time: 578.8197634220123 and batch: 550, loss is 3.7971626329421997 and perplexity is 44.57453059174941
At time: 579.8551726341248 and batch: 600, loss is 3.7651186752319337 and perplexity is 43.168828626630805
At time: 580.8906629085541 and batch: 650, loss is 3.7964273071289063 and perplexity is 44.54176583665129
At time: 581.9266495704651 and batch: 700, loss is 3.8177325201034544 and perplexity is 45.5009188429456
At time: 582.9640135765076 and batch: 750, loss is 3.7884251976013186 and perplexity is 44.18676003986951
At time: 583.9981551170349 and batch: 800, loss is 3.745334267616272 and perplexity is 42.323152113786136
At time: 585.0337038040161 and batch: 850, loss is 3.744923391342163 and perplexity is 42.30576610673057
At time: 586.0683495998383 and batch: 900, loss is 3.6944511699676514 and perplexity is 40.22349066923067
At time: 587.1025450229645 and batch: 950, loss is 3.81721640586853 and perplexity is 45.47744123011486
At time: 588.1369323730469 and batch: 1000, loss is 3.783155484199524 and perplexity is 43.95452093251117
At time: 589.1731293201447 and batch: 1050, loss is 3.73120689868927 and perplexity is 41.72944099224502
At time: 590.2094686031342 and batch: 1100, loss is 3.7469658756256106 and perplexity is 42.39226327358438
At time: 591.2463784217834 and batch: 1150, loss is 3.7101032400131224 and perplexity is 40.85802449223986
At time: 592.2830572128296 and batch: 1200, loss is 3.764707326889038 and perplexity is 43.15107485225367
At time: 593.3186266422272 and batch: 1250, loss is 3.7501383352279665 and perplexity is 42.526964570508625
At time: 594.3535807132721 and batch: 1300, loss is 3.754196047782898 and perplexity is 42.69987734648938
At time: 595.3920903205872 and batch: 1350, loss is 3.641135540008545 and perplexity is 38.13511609807872
At time: 596.4281854629517 and batch: 1400, loss is 3.6609179401397705 and perplexity is 38.897031635408
At time: 597.4629995822906 and batch: 1450, loss is 3.5759070825576784 and perplexity is 35.72701347278679
At time: 598.4989967346191 and batch: 1500, loss is 3.5858847093582153 and perplexity is 36.085268575663605
At time: 599.534095287323 and batch: 1550, loss is 3.5891834020614626 and perplexity is 36.20449933250649
At time: 600.5770308971405 and batch: 1600, loss is 3.6727660369873045 and perplexity is 39.36062837967196
At time: 601.6342248916626 and batch: 1650, loss is 3.619959897994995 and perplexity is 37.33607054074417
At time: 602.6827526092529 and batch: 1700, loss is 3.628817982673645 and perplexity is 37.668265749650324
At time: 603.7255868911743 and batch: 1750, loss is 3.6104415464401245 and perplexity is 36.98237864788984
At time: 604.7688362598419 and batch: 1800, loss is 3.5765259885787963 and perplexity is 35.74913198047442
At time: 605.8129436969757 and batch: 1850, loss is 3.601696462631226 and perplexity is 36.66037467516762
At time: 606.8570582866669 and batch: 1900, loss is 3.6810090351104736 and perplexity is 39.686418866010484
At time: 607.9336812496185 and batch: 1950, loss is 3.6291484451293945 and perplexity is 37.68071575427003
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.241392339662064 and perplexity of 69.50455845233276
finished 14 epochs...
Completing Train Step...
At time: 611.2370476722717 and batch: 50, loss is 3.814608826637268 and perplexity is 45.35900967580892
At time: 612.3080098628998 and batch: 100, loss is 3.8037354850769045 and perplexity is 44.86847736637936
At time: 613.3240723609924 and batch: 150, loss is 3.775449390411377 and perplexity is 43.61710502087641
At time: 614.3544895648956 and batch: 200, loss is 3.7753786516189574 and perplexity is 43.6140197086653
At time: 615.3736083507538 and batch: 250, loss is 3.758896803855896 and perplexity is 42.90107156623327
At time: 616.3919177055359 and batch: 300, loss is 3.764797911643982 and perplexity is 43.154983858840254
At time: 617.4167196750641 and batch: 350, loss is 3.7843282985687257 and perplexity is 44.00610166765347
At time: 618.445469379425 and batch: 400, loss is 3.750238676071167 and perplexity is 42.531231976086346
At time: 619.4811179637909 and batch: 450, loss is 3.7942085123062133 and perplexity is 44.44304635685474
At time: 620.517021894455 and batch: 500, loss is 3.8007091093063354 and perplexity is 44.732893760568786
At time: 621.5527465343475 and batch: 550, loss is 3.772569189071655 and perplexity is 43.49165971714632
At time: 622.5906414985657 and batch: 600, loss is 3.7433337593078613 and perplexity is 42.23856892923482
At time: 623.6295609474182 and batch: 650, loss is 3.775495858192444 and perplexity is 43.61913185805424
At time: 624.6662366390228 and batch: 700, loss is 3.799403386116028 and perplexity is 44.674523100071646
At time: 625.7014768123627 and batch: 750, loss is 3.772151303291321 and perplexity is 43.47348896790069
At time: 626.7352032661438 and batch: 800, loss is 3.729756445884705 and perplexity is 41.66895828178708
At time: 627.7707555294037 and batch: 850, loss is 3.730052127838135 and perplexity is 41.68128086246182
At time: 628.8057408332825 and batch: 900, loss is 3.6803808879852293 and perplexity is 39.66149778396101
At time: 629.840900182724 and batch: 950, loss is 3.803130249977112 and perplexity is 44.84132960522064
At time: 630.9192733764648 and batch: 1000, loss is 3.7682045793533323 and perplexity is 43.30224924855102
At time: 631.9558448791504 and batch: 1050, loss is 3.7178536891937255 and perplexity is 41.17592287097081
At time: 632.991238117218 and batch: 1100, loss is 3.734529585838318 and perplexity is 41.86832547663606
At time: 634.0257472991943 and batch: 1150, loss is 3.6991826343536376 and perplexity is 40.414257630466096
At time: 635.0604400634766 and batch: 1200, loss is 3.75421489238739 and perplexity is 42.70068201637165
At time: 636.0958874225616 and batch: 1250, loss is 3.741093783378601 and perplexity is 42.14406143831521
At time: 637.1309111118317 and batch: 1300, loss is 3.7461045217514037 and perplexity is 42.35576425491949
At time: 638.1647429466248 and batch: 1350, loss is 3.6342768144607542 and perplexity is 37.87445273411133
At time: 639.2002086639404 and batch: 1400, loss is 3.655406608581543 and perplexity is 38.683246857968136
At time: 640.2349786758423 and batch: 1450, loss is 3.5730232334136964 and perplexity is 35.624130576245676
At time: 641.2731177806854 and batch: 1500, loss is 3.585823221206665 and perplexity is 36.083049827414754
At time: 642.3056042194366 and batch: 1550, loss is 3.59014347076416 and perplexity is 36.23927482997468
At time: 643.3410437107086 and batch: 1600, loss is 3.67475736618042 and perplexity is 39.43908644001034
At time: 644.3762803077698 and batch: 1650, loss is 3.6235901308059693 and perplexity is 37.47185548541357
At time: 645.4107127189636 and batch: 1700, loss is 3.633517279624939 and perplexity is 37.84569668986344
At time: 646.4443080425262 and batch: 1750, loss is 3.6164717149734495 and perplexity is 37.20606237135926
At time: 647.4788298606873 and batch: 1800, loss is 3.582847352027893 and perplexity is 35.97583100527702
At time: 648.5123724937439 and batch: 1850, loss is 3.6082570552825928 and perplexity is 36.90167914451631
At time: 649.5453565120697 and batch: 1900, loss is 3.6880062294006346 and perplexity is 39.965086257457884
At time: 650.5780506134033 and batch: 1950, loss is 3.6353125381469726 and perplexity is 37.91370052333457
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2401636877725295 and perplexity of 69.4192139853156
finished 15 epochs...
Completing Train Step...
At time: 653.82856965065 and batch: 50, loss is 3.811558971405029 and perplexity is 45.22088200458791
At time: 654.8604187965393 and batch: 100, loss is 3.7983373403549194 and perplexity is 44.62692339033357
At time: 655.87637758255 and batch: 150, loss is 3.7690469217300415 and perplexity is 43.33873993476794
At time: 656.9159786701202 and batch: 200, loss is 3.767686085700989 and perplexity is 43.279803126772144
At time: 657.9342937469482 and batch: 250, loss is 3.7500456809997558 and perplexity is 42.52302444996543
At time: 658.9581201076508 and batch: 300, loss is 3.755219807624817 and perplexity is 42.743614150343305
At time: 659.9842982292175 and batch: 350, loss is 3.774460024833679 and perplexity is 43.57397309870775
At time: 661.009083032608 and batch: 400, loss is 3.739914083480835 and perplexity is 42.094373407589906
At time: 662.04816198349 and batch: 450, loss is 3.784337978363037 and perplexity is 44.006527639727715
At time: 663.0893306732178 and batch: 500, loss is 3.7911496543884278 and perplexity is 44.30730909894533
At time: 664.1292219161987 and batch: 550, loss is 3.7631064224243165 and perplexity is 43.082049370208445
At time: 665.1730327606201 and batch: 600, loss is 3.7345703125 and perplexity is 41.87003066848608
At time: 666.2160184383392 and batch: 650, loss is 3.767144436836243 and perplexity is 43.256367018185884
At time: 667.2579889297485 and batch: 700, loss is 3.7915810537338257 and perplexity is 44.32642736659453
At time: 668.2966115474701 and batch: 750, loss is 3.7648716592788696 and perplexity is 43.158166554190146
At time: 669.3375413417816 and batch: 800, loss is 3.7226933288574218 and perplexity is 41.37568249288196
At time: 670.3892903327942 and batch: 850, loss is 3.723199210166931 and perplexity is 41.39661897256368
At time: 671.4312105178833 and batch: 900, loss is 3.6735702991485595 and perplexity is 39.39229737710205
At time: 672.4736371040344 and batch: 950, loss is 3.79672354221344 and perplexity is 44.55496262499854
At time: 673.5162019729614 and batch: 1000, loss is 3.761982560157776 and perplexity is 43.033658278110686
At time: 674.5576939582825 and batch: 1050, loss is 3.712176899909973 and perplexity is 40.94283804593449
At time: 675.6009137630463 and batch: 1100, loss is 3.729151792526245 and perplexity is 41.64377062188744
At time: 676.6431775093079 and batch: 1150, loss is 3.694588007926941 and perplexity is 40.22899514621145
At time: 677.6858267784119 and batch: 1200, loss is 3.749737067222595 and perplexity is 42.509903283564135
At time: 678.7280204296112 and batch: 1250, loss is 3.737186059951782 and perplexity is 41.979695459683846
At time: 679.7689638137817 and batch: 1300, loss is 3.7426680517196655 and perplexity is 42.210459750668925
At time: 680.8112237453461 and batch: 1350, loss is 3.6312632608413695 and perplexity is 37.76048784589064
At time: 681.8530883789062 and batch: 1400, loss is 3.6527608251571655 and perplexity is 38.581034639951554
At time: 682.898767709732 and batch: 1450, loss is 3.571090998649597 and perplexity is 35.5553628517949
At time: 683.9413809776306 and batch: 1500, loss is 3.5849268722534178 and perplexity is 36.05072131445087
At time: 684.9839053153992 and batch: 1550, loss is 3.589769787788391 and perplexity is 36.22573535980881
At time: 686.0259428024292 and batch: 1600, loss is 3.674825391769409 and perplexity is 39.441769398348505
At time: 687.0679500102997 and batch: 1650, loss is 3.624012198448181 and perplexity is 37.4876744812159
At time: 688.1086437702179 and batch: 1700, loss is 3.6343640422821046 and perplexity is 37.87775658419989
At time: 689.1506707668304 and batch: 1750, loss is 3.617799258232117 and perplexity is 37.255487828599364
At time: 690.192440032959 and batch: 1800, loss is 3.5843108081817627 and perplexity is 36.0285186001413
At time: 691.2350444793701 and batch: 1850, loss is 3.6096611833572387 and perplexity is 36.9535302224628
At time: 692.2765548229218 and batch: 1900, loss is 3.689487838745117 and perplexity is 40.02434278938587
At time: 693.3183469772339 and batch: 1950, loss is 3.63639591217041 and perplexity is 37.95479749929241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240032533157703 and perplexity of 69.41010993207614
finished 16 epochs...
Completing Train Step...
At time: 696.5935282707214 and batch: 50, loss is 3.80716187953949 and perplexity is 45.022478151825034
At time: 697.6119334697723 and batch: 100, loss is 3.7930033159255983 and perplexity is 44.38951602200425
At time: 698.6167788505554 and batch: 150, loss is 3.7633142375946047 and perplexity is 43.091003403994485
At time: 699.6253008842468 and batch: 200, loss is 3.7614623069763184 and perplexity is 43.01127570328947
At time: 700.6453247070312 and batch: 250, loss is 3.74346116065979 and perplexity is 42.24395052282381
At time: 701.6671509742737 and batch: 300, loss is 3.7483302640914915 and perplexity is 42.450142264372424
At time: 702.6871423721313 and batch: 350, loss is 3.767496075630188 and perplexity is 43.271580309549556
At time: 703.7085518836975 and batch: 400, loss is 3.7328500080108644 and perplexity is 41.798063387333876
At time: 704.7336022853851 and batch: 450, loss is 3.7776778602600096 and perplexity is 43.714412807764795
At time: 705.7591164112091 and batch: 500, loss is 3.784639663696289 and perplexity is 44.0198057664913
At time: 706.7838697433472 and batch: 550, loss is 3.7567381381988527 and perplexity is 42.80856238051711
At time: 707.8113403320312 and batch: 600, loss is 3.72857075214386 and perplexity is 41.61958093775356
At time: 708.8563363552094 and batch: 650, loss is 3.7613223123550417 and perplexity is 43.0052547774952
At time: 709.8893892765045 and batch: 700, loss is 3.786038188934326 and perplexity is 44.081411644475715
At time: 710.9233899116516 and batch: 750, loss is 3.759607181549072 and perplexity is 42.93155835777353
At time: 711.9572172164917 and batch: 800, loss is 3.7175711250305175 and perplexity is 41.16428967442008
At time: 712.9910845756531 and batch: 850, loss is 3.7182323694229127 and perplexity is 41.19151833154051
At time: 714.0247421264648 and batch: 900, loss is 3.668598928451538 and perplexity is 39.19694963956929
At time: 715.060421705246 and batch: 950, loss is 3.7920575618743895 and perplexity is 44.34755430325572
At time: 716.09459400177 and batch: 1000, loss is 3.757558526992798 and perplexity is 42.84369645520902
At time: 717.1280226707458 and batch: 1050, loss is 3.708076319694519 and perplexity is 40.77529240621637
At time: 718.1639955043793 and batch: 1100, loss is 3.725237741470337 and perplexity is 41.48109334877099
At time: 719.1974816322327 and batch: 1150, loss is 3.691095218658447 and perplexity is 40.08872884659459
At time: 720.2320897579193 and batch: 1200, loss is 3.746327142715454 and perplexity is 42.36519458564673
At time: 721.2657415866852 and batch: 1250, loss is 3.734072027206421 and perplexity is 41.84917264501701
At time: 722.3035237789154 and batch: 1300, loss is 3.7398536348342897 and perplexity is 42.09182893659594
At time: 723.3373341560364 and batch: 1350, loss is 3.6286447525024412 and perplexity is 37.66174103468063
At time: 724.3719244003296 and batch: 1400, loss is 3.6503249740600587 and perplexity is 38.48717134930653
At time: 725.4057404994965 and batch: 1450, loss is 3.5689782381057737 and perplexity is 35.480322183435554
At time: 726.4476082324982 and batch: 1500, loss is 3.5834071254730224 and perplexity is 35.995974957639035
At time: 727.4826147556305 and batch: 1550, loss is 3.588556604385376 and perplexity is 36.18181354690256
At time: 728.5146317481995 and batch: 1600, loss is 3.673940005302429 and perplexity is 39.406863644310825
At time: 729.5452156066895 and batch: 1650, loss is 3.6232271146774293 and perplexity is 37.45825506624116
At time: 730.595737695694 and batch: 1700, loss is 3.6338950204849243 and perplexity is 37.85999525628418
At time: 731.6897835731506 and batch: 1750, loss is 3.6175953197479247 and perplexity is 37.24789077557583
At time: 732.7245895862579 and batch: 1800, loss is 3.584275279045105 and perplexity is 36.027238560719866
At time: 733.7594020366669 and batch: 1850, loss is 3.609546365737915 and perplexity is 36.949287549668504
At time: 734.7935342788696 and batch: 1900, loss is 3.689484701156616 and perplexity is 40.02421720966518
At time: 735.8282163143158 and batch: 1950, loss is 3.6361492538452147 and perplexity is 37.945436787004375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.240253679142442 and perplexity of 69.4254613965827
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 739.0890867710114 and batch: 50, loss is 3.8067675971984865 and perplexity is 45.00473008284657
At time: 740.0934746265411 and batch: 100, loss is 3.7979776096343993 and perplexity is 44.61087260218166
At time: 741.0982460975647 and batch: 150, loss is 3.771735601425171 and perplexity is 43.45542071317249
At time: 742.1102805137634 and batch: 200, loss is 3.7731615114212036 and perplexity is 43.51742843015466
At time: 743.1261940002441 and batch: 250, loss is 3.756990728378296 and perplexity is 42.81937676871714
At time: 744.1460683345795 and batch: 300, loss is 3.759266276359558 and perplexity is 42.91692526112645
At time: 745.1656894683838 and batch: 350, loss is 3.7782338666915893 and perplexity is 43.738725060696815
At time: 746.1862499713898 and batch: 400, loss is 3.745199432373047 and perplexity is 42.31744584598848
At time: 747.2118859291077 and batch: 450, loss is 3.7925390577316285 and perplexity is 44.36891260848652
At time: 748.2463309764862 and batch: 500, loss is 3.8005005359649657 and perplexity is 44.7235646443843
At time: 749.2815420627594 and batch: 550, loss is 3.7739189863204956 and perplexity is 43.55040427748385
At time: 750.316285610199 and batch: 600, loss is 3.7459519338607787 and perplexity is 42.34930177125694
At time: 751.3514218330383 and batch: 650, loss is 3.7749978637695314 and perplexity is 43.597415181497354
At time: 752.3856151103973 and batch: 700, loss is 3.7982633686065674 and perplexity is 44.62362238087905
At time: 753.419762134552 and batch: 750, loss is 3.7700282859802248 and perplexity is 43.381291900862
At time: 754.4509534835815 and batch: 800, loss is 3.7258429622650144 and perplexity is 41.50620616768518
At time: 755.4833128452301 and batch: 850, loss is 3.7247857427597046 and perplexity is 41.46234818477585
At time: 756.5163686275482 and batch: 900, loss is 3.672386021614075 and perplexity is 39.34567357749504
At time: 757.5506384372711 and batch: 950, loss is 3.7979658746719362 and perplexity is 44.61034909833788
At time: 758.5859315395355 and batch: 1000, loss is 3.764488444328308 and perplexity is 43.14163086809118
At time: 759.6568179130554 and batch: 1050, loss is 3.7157436180114747 and perplexity is 41.08913034412598
At time: 760.6917498111725 and batch: 1100, loss is 3.731592502593994 and perplexity is 41.74553513041542
At time: 761.7263646125793 and batch: 1150, loss is 3.700551085472107 and perplexity is 40.46960042484054
At time: 762.760368347168 and batch: 1200, loss is 3.7564359092712403 and perplexity is 42.795626349536064
At time: 763.7952120304108 and batch: 1250, loss is 3.740515699386597 and perplexity is 42.1197056715574
At time: 764.831132888794 and batch: 1300, loss is 3.7421770000457766 and perplexity is 42.18973732206077
At time: 765.8651087284088 and batch: 1350, loss is 3.6281509399414062 and perplexity is 37.6431477850552
At time: 766.9006052017212 and batch: 1400, loss is 3.6498885631561278 and perplexity is 38.47037879256218
At time: 767.9350297451019 and batch: 1450, loss is 3.563927903175354 and perplexity is 35.301586390679766
At time: 768.9704263210297 and batch: 1500, loss is 3.576128067970276 and perplexity is 35.73490949402056
At time: 770.005087852478 and batch: 1550, loss is 3.582244973182678 and perplexity is 35.95416645152995
At time: 771.0401940345764 and batch: 1600, loss is 3.6671905422210695 and perplexity is 39.14178405176633
At time: 772.0749306678772 and batch: 1650, loss is 3.613257718086243 and perplexity is 37.08667416214998
At time: 773.1106381416321 and batch: 1700, loss is 3.621035265922546 and perplexity is 37.37624214930294
At time: 774.1450846195221 and batch: 1750, loss is 3.606179599761963 and perplexity is 36.8250971228717
At time: 775.1803419589996 and batch: 1800, loss is 3.572672095298767 and perplexity is 35.611623782123694
At time: 776.214248418808 and batch: 1850, loss is 3.596394419670105 and perplexity is 36.466514176161006
At time: 777.24760389328 and batch: 1900, loss is 3.677431755065918 and perplexity is 39.54470306144833
At time: 778.2825887203217 and batch: 1950, loss is 3.6263017320632933 and perplexity is 37.57360210164496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.23816400572311 and perplexity of 69.28053633104349
finished 18 epochs...
Completing Train Step...
At time: 781.552116394043 and batch: 50, loss is 3.8058075094223023 and perplexity is 44.96154232695924
At time: 782.5557255744934 and batch: 100, loss is 3.794262309074402 and perplexity is 44.44543731342948
At time: 783.5606751441956 and batch: 150, loss is 3.7663530015945437 and perplexity is 43.22214594856632
At time: 784.5763244628906 and batch: 200, loss is 3.7672935247421266 and perplexity is 43.262816500118696
At time: 785.6146349906921 and batch: 250, loss is 3.7500800466537476 and perplexity is 42.52448580662046
At time: 786.6343750953674 and batch: 300, loss is 3.752256178855896 and perplexity is 42.61712547108424
At time: 787.6526415348053 and batch: 350, loss is 3.770819845199585 and perplexity is 43.41564435662174
At time: 788.671383857727 and batch: 400, loss is 3.7369619369506837 and perplexity is 41.970287898617016
At time: 789.6940414905548 and batch: 450, loss is 3.7844286966323852 and perplexity is 44.010520016843245
At time: 790.7423763275146 and batch: 500, loss is 3.7921366405487063 and perplexity is 44.351061387725174
At time: 791.7980971336365 and batch: 550, loss is 3.7651187324523927 and perplexity is 43.168831096771065
At time: 792.8327925205231 and batch: 600, loss is 3.737929801940918 and perplexity is 42.010929135346636
At time: 793.8670742511749 and batch: 650, loss is 3.7669220876693728 and perplexity is 43.24675007021737
At time: 794.9153804779053 and batch: 700, loss is 3.791742358207703 and perplexity is 44.33357799433837
At time: 795.9687325954437 and batch: 750, loss is 3.763844680786133 and perplexity is 43.11386679669566
At time: 797.0029637813568 and batch: 800, loss is 3.7203991556167604 and perplexity is 41.28086831095793
At time: 798.0373520851135 and batch: 850, loss is 3.719191508293152 and perplexity is 41.23104567097005
At time: 799.0706059932709 and batch: 900, loss is 3.667281699180603 and perplexity is 39.14535226042227
At time: 800.104326248169 and batch: 950, loss is 3.7928874111175537 and perplexity is 44.384371361821714
At time: 801.136340379715 and batch: 1000, loss is 3.7592719125747682 and perplexity is 42.91716715083505
At time: 802.1698331832886 and batch: 1050, loss is 3.711135621070862 and perplexity is 40.90022732373586
At time: 803.2346169948578 and batch: 1100, loss is 3.7279556703567507 and perplexity is 41.59398936279429
At time: 804.2684342861176 and batch: 1150, loss is 3.6967401838302614 and perplexity is 40.3156682546128
At time: 805.3029985427856 and batch: 1200, loss is 3.7526967906951905 and perplexity is 42.6359072185498
At time: 806.3367836475372 and batch: 1250, loss is 3.737599687576294 and perplexity is 41.99706301299687
At time: 807.3709645271301 and batch: 1300, loss is 3.7400488662719726 and perplexity is 42.10004738709778
At time: 808.4026732444763 and batch: 1350, loss is 3.626475329399109 and perplexity is 37.58012534505926
At time: 809.4347248077393 and batch: 1400, loss is 3.648818359375 and perplexity is 38.429229670617374
At time: 810.4695482254028 and batch: 1450, loss is 3.5641202831268313 and perplexity is 35.308378361455226
At time: 811.5052781105042 and batch: 1500, loss is 3.5776963567733766 and perplexity is 35.790996120978825
At time: 812.539258480072 and batch: 1550, loss is 3.584249563217163 and perplexity is 36.02631210236418
At time: 813.5724647045135 and batch: 1600, loss is 3.669775490760803 and perplexity is 39.2430944339431
At time: 814.6066720485687 and batch: 1650, loss is 3.616362690925598 and perplexity is 37.202006236947035
At time: 815.6398646831512 and batch: 1700, loss is 3.624655661582947 and perplexity is 37.51180418020597
At time: 816.6739027500153 and batch: 1750, loss is 3.6099644756317137 and perplexity is 36.96473964247317
At time: 817.7073404788971 and batch: 1800, loss is 3.576715211868286 and perplexity is 35.75589718887147
At time: 818.7411024570465 and batch: 1850, loss is 3.599898476600647 and perplexity is 36.59451905510958
At time: 819.7753305435181 and batch: 1900, loss is 3.6811296129226685 and perplexity is 39.69120445608339
At time: 820.8091280460358 and batch: 1950, loss is 3.629104290008545 and perplexity is 37.67905199444424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.237422499545785 and perplexity of 69.22918342698635
finished 19 epochs...
Completing Train Step...
At time: 824.1139719486237 and batch: 50, loss is 3.8050614404678345 and perplexity is 44.928010426194554
At time: 825.1127927303314 and batch: 100, loss is 3.7921470499038694 and perplexity is 44.35152305607786
At time: 826.1195962429047 and batch: 150, loss is 3.7637740755081177 and perplexity is 43.11082283760522
At time: 827.1347131729126 and batch: 200, loss is 3.764094800949097 and perplexity is 43.124651792801124
At time: 828.1565024852753 and batch: 250, loss is 3.746453866958618 and perplexity is 42.3705636230535
At time: 829.1807398796082 and batch: 300, loss is 3.7483672285079956 and perplexity is 42.451711438113364
At time: 830.2032308578491 and batch: 350, loss is 3.766724410057068 and perplexity is 43.238202000832345
At time: 831.227326631546 and batch: 400, loss is 3.732503128051758 and perplexity is 41.78356699121536
At time: 832.2541601657867 and batch: 450, loss is 3.7800314950942995 and perplexity is 43.81742174767195
At time: 833.2877309322357 and batch: 500, loss is 3.7877324056625366 and perplexity is 44.156158410218126
At time: 834.3222219944 and batch: 550, loss is 3.760560622215271 and perplexity is 42.97251057102557
At time: 835.3603360652924 and batch: 600, loss is 3.7337755155563355 and perplexity is 41.83676571727154
At time: 836.4031457901001 and batch: 650, loss is 3.7630002641677858 and perplexity is 43.077476097709145
At time: 837.4710257053375 and batch: 700, loss is 3.7883535623550415 and perplexity is 44.183594823803745
At time: 838.5109975337982 and batch: 750, loss is 3.760680704116821 and perplexity is 42.97767110164628
At time: 839.5529885292053 and batch: 800, loss is 3.7175105381011964 and perplexity is 41.16179573206194
At time: 840.5948166847229 and batch: 850, loss is 3.7162973213195802 and perplexity is 41.111887831391265
At time: 841.6357672214508 and batch: 900, loss is 3.664730930328369 and perplexity is 39.045628755042586
At time: 842.6779363155365 and batch: 950, loss is 3.7904630136489867 and perplexity is 44.27689633797823
At time: 843.7206723690033 and batch: 1000, loss is 3.7568480730056764 and perplexity is 42.813268790247186
At time: 844.7619745731354 and batch: 1050, loss is 3.708974599838257 and perplexity is 40.81193649760579
At time: 845.8040084838867 and batch: 1100, loss is 3.7262583923339845 and perplexity is 41.523452675887114
At time: 846.8436548709869 and batch: 1150, loss is 3.6951034307479858 and perplexity is 40.249735432926904
At time: 847.8828022480011 and batch: 1200, loss is 3.7510219860076903 and perplexity is 42.56456016415212
At time: 848.923463344574 and batch: 1250, loss is 3.7363362646102907 and perplexity is 41.944036463615284
At time: 849.9786803722382 and batch: 1300, loss is 3.7392376041412354 and perplexity is 42.065907063198786
At time: 851.024795293808 and batch: 1350, loss is 3.625829982757568 and perplexity is 37.555880961236404
At time: 852.0656111240387 and batch: 1400, loss is 3.6483474493026735 and perplexity is 38.41113721958679
At time: 853.1086883544922 and batch: 1450, loss is 3.564219708442688 and perplexity is 35.311889082650595
At time: 854.1503057479858 and batch: 1500, loss is 3.5785063123703003 and perplexity is 35.81999698172578
At time: 855.1928753852844 and batch: 1550, loss is 3.585209746360779 and perplexity is 36.06092057254742
At time: 856.2344946861267 and batch: 1600, loss is 3.670927333831787 and perplexity is 39.28832236308872
At time: 857.2756125926971 and batch: 1650, loss is 3.617809200286865 and perplexity is 37.25585822654028
At time: 858.3162560462952 and batch: 1700, loss is 3.62632071018219 and perplexity is 37.57431518469949
At time: 859.3570492267609 and batch: 1750, loss is 3.611717767715454 and perplexity is 37.02960647650224
At time: 860.3980898857117 and batch: 1800, loss is 3.5785933923721314 and perplexity is 35.82311632294269
At time: 861.4414587020874 and batch: 1850, loss is 3.601513829231262 and perplexity is 36.65367987766217
At time: 862.4830923080444 and batch: 1900, loss is 3.6827933979034424 and perplexity is 39.75729705261462
At time: 863.5269315242767 and batch: 1950, loss is 3.630369687080383 and perplexity is 37.726761135645326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.237106536155523 and perplexity of 69.20731299479563
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd78797ab38>
ELAPSED
2689.312070131302


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.58572924558682}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.5545691141662139, 'dropout': 0.7795352401135597, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.01716348977908}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.30559750332649016, 'dropout': 0.7036453025474743, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -69.20731299479563}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.2784456490206031, 'dropout': 0.9440744352266794, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5752456188201904 and batch: 50, loss is 7.979969615936279 and perplexity is 2921.842285290577
At time: 2.716856002807617 and batch: 100, loss is 7.264892148971557 and perplexity is 1429.231475364222
At time: 3.8566980361938477 and batch: 150, loss is 6.9884622764587405 and perplexity is 1084.053219700103
At time: 4.996419906616211 and batch: 200, loss is 6.867408866882324 and perplexity is 960.456667706584
At time: 6.141613960266113 and batch: 250, loss is 6.7855851936340335 and perplexity is 884.9978305367611
At time: 7.282407283782959 and batch: 300, loss is 6.691361894607544 and perplexity is 805.4184005317695
At time: 8.424763679504395 and batch: 350, loss is 6.65681004524231 and perplexity is 778.0649821013775
At time: 9.567260503768921 and batch: 400, loss is 6.630126085281372 and perplexity is 757.5776840157179
At time: 10.710097789764404 and batch: 450, loss is 6.537423963546753 and perplexity is 690.5055175986037
At time: 11.855594396591187 and batch: 500, loss is 6.530530242919922 and perplexity is 685.7617354102546
At time: 13.002935647964478 and batch: 550, loss is 6.4868497562408445 and perplexity is 656.4521182761407
At time: 14.15160059928894 and batch: 600, loss is 6.535998592376709 and perplexity is 689.5219920520593
At time: 15.298591613769531 and batch: 650, loss is 6.619644136428833 and perplexity is 749.6782664519166
At time: 16.44660234451294 and batch: 700, loss is 6.500085430145264 and perplexity is 665.1984586179677
At time: 17.594276189804077 and batch: 750, loss is 6.440477514266968 and perplexity is 626.7059894232938
At time: 18.74288034439087 and batch: 800, loss is 6.433988180160522 and perplexity is 622.6522521249916
At time: 19.891419887542725 and batch: 850, loss is 6.488566217422485 and perplexity is 657.5798604407084
At time: 21.048641443252563 and batch: 900, loss is 6.473856134414673 and perplexity is 647.9776042514565
At time: 22.206647634506226 and batch: 950, loss is 6.484953451156616 and perplexity is 655.2084643330276
At time: 23.355475425720215 and batch: 1000, loss is 6.482873859405518 and perplexity is 653.8473140243754
At time: 24.50495195388794 and batch: 1050, loss is 6.3757513236999515 and perplexity is 587.4266127219119
At time: 25.652109622955322 and batch: 1100, loss is 6.45693962097168 and perplexity is 637.1082771609167
At time: 26.800943851470947 and batch: 1150, loss is 6.358765487670898 and perplexity is 577.532944585941
At time: 27.95277714729309 and batch: 1200, loss is 6.452702760696411 and perplexity is 634.4146487035117
At time: 29.101941347122192 and batch: 1250, loss is 6.378710336685181 and perplexity is 589.1673899178372
At time: 30.253414392471313 and batch: 1300, loss is 6.395065660476685 and perplexity is 598.8826448519007
At time: 31.406235933303833 and batch: 1350, loss is 6.4033299255371094 and perplexity is 603.852477490358
At time: 32.56280159950256 and batch: 1400, loss is 6.424224081039429 and perplexity is 616.6021985450975
At time: 33.71414303779602 and batch: 1450, loss is 6.426410303115845 and perplexity is 617.9517025040934
At time: 34.879865884780884 and batch: 1500, loss is 6.411272926330566 and perplexity is 608.6679776409818
At time: 36.10020399093628 and batch: 1550, loss is 6.385297870635986 and perplexity is 593.0613618560396
At time: 37.37228035926819 and batch: 1600, loss is 6.3711785793304445 and perplexity is 584.7465931781591
At time: 38.651692390441895 and batch: 1650, loss is 6.366341819763184 and perplexity is 581.9251433369096
At time: 39.92492604255676 and batch: 1700, loss is 6.399245882034302 and perplexity is 601.3913468062493
At time: 41.19723558425903 and batch: 1750, loss is 6.414806261062622 and perplexity is 610.8224092693125
At time: 42.46875190734863 and batch: 1800, loss is 6.421914215087891 and perplexity is 615.1795737898087
At time: 43.741236209869385 and batch: 1850, loss is 6.367205228805542 and perplexity is 582.4277997354556
At time: 45.01327610015869 and batch: 1900, loss is 6.323646154403686 and perplexity is 557.6023948733737
At time: 46.2863712310791 and batch: 1950, loss is 6.274593000411987 and perplexity is 530.9102575236833
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.817768895348837 and perplexity of 336.2210717849705
finished 1 epochs...
Completing Train Step...
At time: 49.817251682281494 and batch: 50, loss is 6.048383655548096 and perplexity is 423.4280710156597
At time: 50.89398455619812 and batch: 100, loss is 5.903703317642212 and perplexity is 366.3918238174224
At time: 51.96887755393982 and batch: 150, loss is 5.740126791000367 and perplexity is 311.1038536496745
At time: 53.043397665023804 and batch: 200, loss is 5.645191650390625 and perplexity is 282.9277742456156
At time: 54.119455099105835 and batch: 250, loss is 5.59857931137085 and perplexity is 270.04248848331247
At time: 55.19361352920532 and batch: 300, loss is 5.557158622741699 and perplexity is 259.0856294620222
At time: 56.281609535217285 and batch: 350, loss is 5.494568901062012 and perplexity is 243.36658846520132
At time: 57.35567045211792 and batch: 400, loss is 5.428854084014892 and perplexity is 227.88795529354314
At time: 58.430976152420044 and batch: 450, loss is 5.336877565383912 and perplexity is 207.86265838502428
At time: 59.505326986312866 and batch: 500, loss is 5.314551753997803 and perplexity is 203.273376226251
At time: 60.58047080039978 and batch: 550, loss is 5.2546003055572506 and perplexity is 191.44495107709548
At time: 61.655242919921875 and batch: 600, loss is 5.258012485504151 and perplexity is 192.09931146289773
At time: 62.73198699951172 and batch: 650, loss is 5.322832231521606 and perplexity is 204.9635649767708
At time: 63.80843210220337 and batch: 700, loss is 5.270197229385376 and perplexity is 194.45431076775694
At time: 64.88374900817871 and batch: 750, loss is 5.1978389930725095 and perplexity is 180.88093426620637
At time: 65.9590654373169 and batch: 800, loss is 5.177325382232666 and perplexity is 177.20821235802615
At time: 67.033531665802 and batch: 850, loss is 5.169064121246338 and perplexity is 175.75027954036264
At time: 68.13430595397949 and batch: 900, loss is 5.182845735549927 and perplexity is 178.18916942459722
At time: 69.20997309684753 and batch: 950, loss is 5.216570396423339 and perplexity is 184.30101950389545
At time: 70.28584790229797 and batch: 1000, loss is 5.172517919540406 and perplexity is 176.35833500203555
At time: 71.3596658706665 and batch: 1050, loss is 5.073044519424439 and perplexity is 159.659675125246
At time: 72.43521165847778 and batch: 1100, loss is 5.1542276096343995 and perplexity is 173.16200642704118
At time: 73.51146292686462 and batch: 1150, loss is 5.042914247512817 and perplexity is 154.92083546509463
At time: 74.58808326721191 and batch: 1200, loss is 5.124654922485352 and perplexity is 168.116118548826
At time: 75.66335582733154 and batch: 1250, loss is 5.058068027496338 and perplexity is 157.28634969438312
At time: 76.73863005638123 and batch: 1300, loss is 5.092790002822876 and perplexity is 162.84356284596583
At time: 77.81451940536499 and batch: 1350, loss is 5.01745641708374 and perplexity is 151.02666597486441
At time: 78.88975429534912 and batch: 1400, loss is 5.028474559783936 and perplexity is 152.6999003723451
At time: 79.96496868133545 and batch: 1450, loss is 4.966672744750976 and perplexity is 143.5484695044583
At time: 81.06120824813843 and batch: 1500, loss is 4.927875251770019 and perplexity is 138.08580285590122
At time: 82.13601040840149 and batch: 1550, loss is 4.919622745513916 and perplexity is 136.95093808398414
At time: 83.21299171447754 and batch: 1600, loss is 4.969492616653443 and perplexity is 143.95382906266292
At time: 84.28869295120239 and batch: 1650, loss is 4.931658668518066 and perplexity is 138.60922853947253
At time: 85.36486005783081 and batch: 1700, loss is 4.96822075843811 and perplexity is 143.77085658473064
At time: 86.43797135353088 and batch: 1750, loss is 4.969386701583862 and perplexity is 143.93858299025
At time: 87.5127477645874 and batch: 1800, loss is 4.92466570854187 and perplexity is 137.6433209646602
At time: 88.58723497390747 and batch: 1850, loss is 4.912905073165893 and perplexity is 136.03402974718838
At time: 89.66174530982971 and batch: 1900, loss is 4.97874903678894 and perplexity is 145.29251233364133
At time: 90.7361855506897 and batch: 1950, loss is 4.8922035598754885 and perplexity is 133.24686823933877
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6959313680959305 and perplexity of 109.50074666545726
finished 2 epochs...
Completing Train Step...
At time: 94.11945676803589 and batch: 50, loss is 4.886296644210815 and perplexity is 132.46211025746578
At time: 95.1874451637268 and batch: 100, loss is 4.838803901672363 and perplexity is 126.31817238072028
At time: 96.24874973297119 and batch: 150, loss is 4.78033486366272 and perplexity is 119.14424044226527
At time: 97.31440305709839 and batch: 200, loss is 4.761055021286011 and perplexity is 116.86916033191265
At time: 98.38392305374146 and batch: 250, loss is 4.778529462814331 and perplexity is 118.92933138636022
At time: 99.45344758033752 and batch: 300, loss is 4.798243131637573 and perplexity is 121.29712712692323
At time: 100.5283613204956 and batch: 350, loss is 4.806212244033813 and perplexity is 122.2676194113234
At time: 101.60360836982727 and batch: 400, loss is 4.7612861633300785 and perplexity is 116.89617683072431
At time: 102.6783037185669 and batch: 450, loss is 4.742124090194702 and perplexity is 114.67752857853951
At time: 103.75327754020691 and batch: 500, loss is 4.74566421508789 and perplexity is 115.0842207980362
At time: 104.82725262641907 and batch: 550, loss is 4.694782314300537 and perplexity is 109.37499667748924
At time: 105.90086340904236 and batch: 600, loss is 4.682950868606567 and perplexity is 108.08855756786377
At time: 106.9749801158905 and batch: 650, loss is 4.748122835159302 and perplexity is 115.36751728970717
At time: 108.0488691329956 and batch: 700, loss is 4.748454179763794 and perplexity is 115.40575002785066
At time: 109.1223874092102 and batch: 750, loss is 4.714032688140869 and perplexity is 111.50090284599285
At time: 110.21589541435242 and batch: 800, loss is 4.689718475341797 and perplexity is 108.82253926641269
At time: 111.29121851921082 and batch: 850, loss is 4.689565935134888 and perplexity is 108.80594071976164
At time: 112.36770749092102 and batch: 900, loss is 4.682524633407593 and perplexity is 108.04249623719959
At time: 113.44427633285522 and batch: 950, loss is 4.746678104400635 and perplexity is 115.20096263121678
At time: 114.52004981040955 and batch: 1000, loss is 4.721150121688843 and perplexity is 112.29733402340655
At time: 115.59497475624084 and batch: 1050, loss is 4.640258407592773 and perplexity is 103.57110768624328
At time: 116.66992831230164 and batch: 1100, loss is 4.7159342861175535 and perplexity is 111.71313446289614
At time: 117.74331855773926 and batch: 1150, loss is 4.640688562393189 and perplexity is 103.61566887881725
At time: 118.81860947608948 and batch: 1200, loss is 4.724471273422242 and perplexity is 112.6709105176847
At time: 119.89218831062317 and batch: 1250, loss is 4.683293418884277 and perplexity is 108.12558967559323
At time: 120.96753287315369 and batch: 1300, loss is 4.703260803222657 and perplexity is 110.30627370745397
At time: 122.04364466667175 and batch: 1350, loss is 4.60122971534729 and perplexity is 99.60672828261877
At time: 123.12022018432617 and batch: 1400, loss is 4.6142467021942135 and perplexity is 100.91178326879745
At time: 124.19509267807007 and batch: 1450, loss is 4.551341876983643 and perplexity is 94.75947860282864
At time: 125.27048063278198 and batch: 1500, loss is 4.542578353881836 and perplexity is 93.93267984942511
At time: 126.34615707397461 and batch: 1550, loss is 4.537751741409302 and perplexity is 93.48039558376553
At time: 127.42137861251831 and batch: 1600, loss is 4.613445568084717 and perplexity is 100.83097177191613
At time: 128.49746131896973 and batch: 1650, loss is 4.572176446914673 and perplexity is 96.7544617295882
At time: 129.5741481781006 and batch: 1700, loss is 4.609705114364624 and perplexity is 100.45452267257636
At time: 130.65005111694336 and batch: 1750, loss is 4.6067615985870365 and perplexity is 100.15926795679762
At time: 131.72694039344788 and batch: 1800, loss is 4.567083711624146 and perplexity is 96.26296945013648
At time: 132.80341339111328 and batch: 1850, loss is 4.580878772735596 and perplexity is 97.60012486137505
At time: 133.87744092941284 and batch: 1900, loss is 4.664333896636963 and perplexity is 106.09489151589155
At time: 134.9523732662201 and batch: 1950, loss is 4.589941492080689 and perplexity is 98.48866762635242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5146839230559594 and perplexity of 91.34868824460634
finished 3 epochs...
Completing Train Step...
At time: 138.3012752532959 and batch: 50, loss is 4.579443607330322 and perplexity is 97.46015300403232
At time: 139.35261964797974 and batch: 100, loss is 4.532327957153321 and perplexity is 92.97475058022438
At time: 140.38695693016052 and batch: 150, loss is 4.484870414733887 and perplexity is 88.66546033120608
At time: 141.45981216430664 and batch: 200, loss is 4.482756538391113 and perplexity is 88.47823047229478
At time: 142.49555087089539 and batch: 250, loss is 4.489437313079834 and perplexity is 89.0713125127738
At time: 143.53522562980652 and batch: 300, loss is 4.510067367553711 and perplexity is 90.92794389734543
At time: 144.575293302536 and batch: 350, loss is 4.528191909790039 and perplexity is 92.5909967672777
At time: 145.62361121177673 and batch: 400, loss is 4.487322273254395 and perplexity is 88.88312222463637
At time: 146.67970418930054 and batch: 450, loss is 4.483983592987061 and perplexity is 88.58686472808799
At time: 147.73527240753174 and batch: 500, loss is 4.48897349357605 and perplexity is 89.03000908021201
At time: 148.79204773902893 and batch: 550, loss is 4.451284265518188 and perplexity is 85.73698237793204
At time: 149.84912514686584 and batch: 600, loss is 4.430331354141235 and perplexity is 83.95923254099951
At time: 150.90597534179688 and batch: 650, loss is 4.4996740341186525 and perplexity is 89.98779356879062
At time: 151.97145009040833 and batch: 700, loss is 4.512590293884277 and perplexity is 91.15763803003935
At time: 153.04896759986877 and batch: 750, loss is 4.478829536437988 and perplexity is 88.13145762289135
At time: 154.14509201049805 and batch: 800, loss is 4.4608667373657225 and perplexity is 86.56250354768319
At time: 155.21621179580688 and batch: 850, loss is 4.455076637268067 and perplexity is 86.06274620616148
At time: 156.2856364250183 and batch: 900, loss is 4.438313055038452 and perplexity is 84.63205157086162
At time: 157.35408568382263 and batch: 950, loss is 4.515851945877075 and perplexity is 91.45544793389425
At time: 158.4224636554718 and batch: 1000, loss is 4.497897958755493 and perplexity is 89.8281103123728
At time: 159.49246072769165 and batch: 1050, loss is 4.426710691452026 and perplexity is 83.65579413586576
At time: 160.561705827713 and batch: 1100, loss is 4.489469566345215 and perplexity is 89.07418539978387
At time: 161.63064861297607 and batch: 1150, loss is 4.430874013900757 and perplexity is 84.00480620231752
At time: 162.69997215270996 and batch: 1200, loss is 4.512972593307495 and perplexity is 91.19249420480337
At time: 163.78114318847656 and batch: 1250, loss is 4.4821892261505125 and perplexity is 88.42804992448653
At time: 164.8484823703766 and batch: 1300, loss is 4.489565992355347 and perplexity is 89.08277488220585
At time: 165.91778469085693 and batch: 1350, loss is 4.382078342437744 and perplexity is 80.00413672805854
At time: 166.98811507225037 and batch: 1400, loss is 4.399894418716431 and perplexity is 81.4422694316737
At time: 168.05967235565186 and batch: 1450, loss is 4.334781646728516 and perplexity is 76.30829490468226
At time: 169.12786889076233 and batch: 1500, loss is 4.3381370210647585 and perplexity is 76.56476783977426
At time: 170.19835925102234 and batch: 1550, loss is 4.336188440322876 and perplexity is 76.41572047023259
At time: 171.26809668540955 and batch: 1600, loss is 4.4179493427276615 and perplexity is 82.9260579551538
At time: 172.33841013908386 and batch: 1650, loss is 4.380087013244629 and perplexity is 79.8449806736637
At time: 173.40794324874878 and batch: 1700, loss is 4.407378168106079 and perplexity is 82.05404931418393
At time: 174.4785499572754 and batch: 1750, loss is 4.406206197738648 and perplexity is 81.95794072906743
At time: 175.5483856201172 and batch: 1800, loss is 4.365615482330322 and perplexity is 78.69782215771208
At time: 176.61790895462036 and batch: 1850, loss is 4.38652099609375 and perplexity is 80.36035809677207
At time: 177.68715000152588 and batch: 1900, loss is 4.474105033874512 and perplexity is 87.71606236607381
At time: 178.75472950935364 and batch: 1950, loss is 4.407985486984253 and perplexity is 82.10389742267958
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.438132494549419 and perplexity of 84.61677174574996
finished 4 epochs...
Completing Train Step...
At time: 182.1167435646057 and batch: 50, loss is 4.3939288187026975 and perplexity is 80.95786374990493
At time: 183.16679883003235 and batch: 100, loss is 4.343808479309082 and perplexity is 77.00023542442558
At time: 184.202401638031 and batch: 150, loss is 4.303846426010132 and perplexity is 73.98382039667992
At time: 185.24010825157166 and batch: 200, loss is 4.307485656738281 and perplexity is 74.25355510497567
At time: 186.27607083320618 and batch: 250, loss is 4.311939706802368 and perplexity is 74.58502179347724
At time: 187.31520915031433 and batch: 300, loss is 4.329292211532593 and perplexity is 75.8905530971973
At time: 188.35777139663696 and batch: 350, loss is 4.347878313064575 and perplexity is 77.3142521462281
At time: 189.43378710746765 and batch: 400, loss is 4.308341627120972 and perplexity is 74.31714115896209
At time: 190.47676134109497 and batch: 450, loss is 4.32137435913086 and perplexity is 75.29203551290531
At time: 191.51802158355713 and batch: 500, loss is 4.32172887802124 and perplexity is 75.31873269383769
At time: 192.56343507766724 and batch: 550, loss is 4.290355834960938 and perplexity is 72.9924371401022
At time: 193.6207242012024 and batch: 600, loss is 4.273316264152527 and perplexity is 71.75921397411145
At time: 194.6785283088684 and batch: 650, loss is 4.3376061153411865 and perplexity is 76.52412995470158
At time: 195.7447144985199 and batch: 700, loss is 4.3592519950866695 and perplexity is 78.19861958945246
At time: 196.81483602523804 and batch: 750, loss is 4.327372016906739 and perplexity is 75.74496828530637
At time: 197.8842751979828 and batch: 800, loss is 4.306786570549011 and perplexity is 74.20166361052452
At time: 198.95343279838562 and batch: 850, loss is 4.300088167190552 and perplexity is 73.70629188980992
At time: 200.02345824241638 and batch: 900, loss is 4.2798295497894285 and perplexity is 72.22812765846538
At time: 201.1087305545807 and batch: 950, loss is 4.367589893341065 and perplexity is 78.85335749912011
At time: 202.18182849884033 and batch: 1000, loss is 4.346617021560669 and perplexity is 77.2167978089487
At time: 203.25146555900574 and batch: 1050, loss is 4.279441795349121 and perplexity is 72.20012631042508
At time: 204.32105779647827 and batch: 1100, loss is 4.33474753856659 and perplexity is 76.30569221339012
At time: 205.39012694358826 and batch: 1150, loss is 4.288406677246094 and perplexity is 72.85030193509122
At time: 206.45927453041077 and batch: 1200, loss is 4.368718900680542 and perplexity is 78.94243379291196
At time: 207.5290560722351 and batch: 1250, loss is 4.342810382843018 and perplexity is 76.92342010248994
At time: 208.59943437576294 and batch: 1300, loss is 4.347748432159424 and perplexity is 77.30421115325903
At time: 209.66899037361145 and batch: 1350, loss is 4.23435754776001 and perplexity is 69.01732415269385
At time: 210.7390787601471 and batch: 1400, loss is 4.2560523319244385 and perplexity is 70.53100017216941
At time: 211.80838680267334 and batch: 1450, loss is 4.187402296066284 and perplexity is 65.85150586691798
At time: 212.87824416160583 and batch: 1500, loss is 4.198029084205627 and perplexity is 66.55502733458636
At time: 213.94843935966492 and batch: 1550, loss is 4.194430122375488 and perplexity is 66.3159288428554
At time: 215.01754093170166 and batch: 1600, loss is 4.28008005619049 and perplexity is 72.24622353325213
At time: 216.0867087841034 and batch: 1650, loss is 4.237184195518494 and perplexity is 69.21268779933496
At time: 217.15580010414124 and batch: 1700, loss is 4.268253474235535 and perplexity is 71.39683025950674
At time: 218.22599935531616 and batch: 1750, loss is 4.2692955875396725 and perplexity is 71.47127262814777
At time: 219.29574632644653 and batch: 1800, loss is 4.2292101860046385 and perplexity is 68.66297976962737
At time: 220.36540985107422 and batch: 1850, loss is 4.254803771972656 and perplexity is 70.44299294257935
At time: 221.4347026348114 and batch: 1900, loss is 4.337033386230469 and perplexity is 76.48031490607877
At time: 222.5057122707367 and batch: 1950, loss is 4.275649185180664 and perplexity is 71.92681798079437
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.404663653706395 and perplexity of 81.83161445367004
finished 5 epochs...
Completing Train Step...
At time: 225.8396294116974 and batch: 50, loss is 4.2634778356552125 and perplexity is 71.0566776717975
At time: 226.86595344543457 and batch: 100, loss is 4.209680128097534 and perplexity is 67.33499779111098
At time: 227.89249110221863 and batch: 150, loss is 4.17806713104248 and perplexity is 65.23963160965799
At time: 228.91758584976196 and batch: 200, loss is 4.180648980140686 and perplexity is 65.40828812284195
At time: 229.94442057609558 and batch: 250, loss is 4.184828586578369 and perplexity is 65.68224113403318
At time: 230.9715337753296 and batch: 300, loss is 4.1993385887146 and perplexity is 66.64223853224156
At time: 231.99879264831543 and batch: 350, loss is 4.21737042427063 and perplexity is 67.8548200988077
At time: 233.03203344345093 and batch: 400, loss is 4.177880277633667 and perplexity is 65.22744250092573
At time: 234.07452821731567 and batch: 450, loss is 4.198034634590149 and perplexity is 66.5553967416051
At time: 235.12186002731323 and batch: 500, loss is 4.20673713684082 and perplexity is 67.13712279635014
At time: 236.17281866073608 and batch: 550, loss is 4.17323579788208 and perplexity is 64.92519739393751
At time: 237.2224154472351 and batch: 600, loss is 4.156813082695007 and perplexity is 63.86765697978776
At time: 238.2730429172516 and batch: 650, loss is 4.222828197479248 and perplexity is 68.22616876462955
At time: 239.3227469921112 and batch: 700, loss is 4.249884700775146 and perplexity is 70.09732971295588
At time: 240.37468767166138 and batch: 750, loss is 4.2180848932266235 and perplexity is 67.90331758419367
At time: 241.42467284202576 and batch: 800, loss is 4.192843356132507 and perplexity is 66.21078440747729
At time: 242.49043369293213 and batch: 850, loss is 4.186386442184448 and perplexity is 65.78464432558633
At time: 243.5445098876953 and batch: 900, loss is 4.1668644666671755 and perplexity is 64.51285244515792
At time: 244.59866380691528 and batch: 950, loss is 4.2560540342330935 and perplexity is 70.53112023780363
At time: 245.65410614013672 and batch: 1000, loss is 4.234479351043701 and perplexity is 69.02573120139989
At time: 246.70625281333923 and batch: 1050, loss is 4.174975509643555 and perplexity is 65.03824683166509
At time: 247.76030611991882 and batch: 1100, loss is 4.218441100120544 and perplexity is 67.92750952244904
At time: 248.81481409072876 and batch: 1150, loss is 4.181320910453796 and perplexity is 65.45225270327339
At time: 249.86981439590454 and batch: 1200, loss is 4.2598678016662594 and perplexity is 70.80062311117624
At time: 250.92345714569092 and batch: 1250, loss is 4.2380467224121094 and perplexity is 69.27241135682594
At time: 251.97746515274048 and batch: 1300, loss is 4.2380567646026615 and perplexity is 69.2731070070737
At time: 253.03219270706177 and batch: 1350, loss is 4.127147078514099 and perplexity is 62.00078700007334
At time: 254.08637261390686 and batch: 1400, loss is 4.151489815711975 and perplexity is 63.528575700908505
At time: 255.14075016975403 and batch: 1450, loss is 4.079918918609619 and perplexity is 59.140674447363665
At time: 256.19448137283325 and batch: 1500, loss is 4.092686944007873 and perplexity is 59.9006252925632
At time: 257.24951100349426 and batch: 1550, loss is 4.088513646125794 and perplexity is 59.65116304209667
At time: 258.30378341674805 and batch: 1600, loss is 4.177929873466492 and perplexity is 65.2306775904824
At time: 259.35831785202026 and batch: 1650, loss is 4.135333075523376 and perplexity is 62.51040829037763
At time: 260.4124083518982 and batch: 1700, loss is 4.16594024181366 and perplexity is 64.45325560823811
At time: 261.4854612350464 and batch: 1750, loss is 4.1661233234405515 and perplexity is 64.4650568953998
At time: 262.54579162597656 and batch: 1800, loss is 4.12247878074646 and perplexity is 61.71202340616806
At time: 263.602974653244 and batch: 1850, loss is 4.156184844970703 and perplexity is 63.82754550939885
At time: 264.65923595428467 and batch: 1900, loss is 4.231535038948059 and perplexity is 68.82279680381652
At time: 265.7478551864624 and batch: 1950, loss is 4.173781008720398 and perplexity is 64.9606049666557
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385552836573401 and perplexity of 80.2825941010727
finished 6 epochs...
Completing Train Step...
At time: 269.0658371448517 and batch: 50, loss is 4.160512585639953 and perplexity is 64.10437316099495
At time: 270.07670068740845 and batch: 100, loss is 4.112028880119324 and perplexity is 61.0704966772627
At time: 271.0881586074829 and batch: 150, loss is 4.080384426116943 and perplexity is 59.16821128411199
At time: 272.10047125816345 and batch: 200, loss is 4.087890229225159 and perplexity is 59.613987088176714
At time: 273.1143584251404 and batch: 250, loss is 4.084169816970825 and perplexity is 59.39261054144081
At time: 274.1340730190277 and batch: 300, loss is 4.100116591453553 and perplexity is 60.34732316933654
At time: 275.15401101112366 and batch: 350, loss is 4.116358890533447 and perplexity is 61.33550589615528
At time: 276.1860511302948 and batch: 400, loss is 4.0716144323349 and perplexity is 58.651575198009745
At time: 277.22540402412415 and batch: 450, loss is 4.106377897262573 and perplexity is 60.72636161394684
At time: 278.2603635787964 and batch: 500, loss is 4.114395403862 and perplexity is 61.215192603268655
At time: 279.295015335083 and batch: 550, loss is 4.0735875415802 and perplexity is 58.767415408397376
At time: 280.32891607284546 and batch: 600, loss is 4.069087753295898 and perplexity is 58.503568553736216
At time: 281.36295104026794 and batch: 650, loss is 4.130489072799683 and perplexity is 62.20833990305858
At time: 282.39805150032043 and batch: 700, loss is 4.15921049118042 and perplexity is 64.02095753117045
At time: 283.4373412132263 and batch: 750, loss is 4.128114624023437 and perplexity is 62.060804613314694
At time: 284.4790463447571 and batch: 800, loss is 4.104439105987549 and perplexity is 60.60873993267459
At time: 285.5212631225586 and batch: 850, loss is 4.098634166717529 and perplexity is 60.257929081092264
At time: 286.56372117996216 and batch: 900, loss is 4.0734043264389035 and perplexity is 58.756649314365525
At time: 287.6075313091278 and batch: 950, loss is 4.1672419786453245 and perplexity is 64.53721141731312
At time: 288.6482672691345 and batch: 1000, loss is 4.146440162658691 and perplexity is 63.208587030481816
At time: 289.69230461120605 and batch: 1050, loss is 4.0880319690704345 and perplexity is 59.62243736433914
At time: 290.7340292930603 and batch: 1100, loss is 4.129177379608154 and perplexity is 62.12679513969865
At time: 291.77604818344116 and batch: 1150, loss is 4.093297543525696 and perplexity is 59.93721175418533
At time: 292.81837010383606 and batch: 1200, loss is 4.171532378196717 and perplexity is 64.81469667588917
At time: 293.85926151275635 and batch: 1250, loss is 4.153774285316468 and perplexity is 63.67387069892846
At time: 294.89954352378845 and batch: 1300, loss is 4.154207229614258 and perplexity is 63.70144390656661
At time: 295.93970131874084 and batch: 1350, loss is 4.039871139526367 and perplexity is 56.81902060780135
At time: 296.98254227638245 and batch: 1400, loss is 4.0682054090499875 and perplexity is 58.451971033392695
At time: 298.02467250823975 and batch: 1450, loss is 3.996742787361145 and perplexity is 54.420601562333786
At time: 299.0668771266937 and batch: 1500, loss is 4.008218355178833 and perplexity is 55.04870590036934
At time: 300.1091332435608 and batch: 1550, loss is 4.003726434707642 and perplexity is 54.80198602928861
At time: 301.1514766216278 and batch: 1600, loss is 4.097103157043457 and perplexity is 60.16574419471269
At time: 302.1942307949066 and batch: 1650, loss is 4.0520146417617795 and perplexity is 57.513208919558735
At time: 303.2365517616272 and batch: 1700, loss is 4.0835243463516235 and perplexity is 59.35428672611759
At time: 304.27863669395447 and batch: 1750, loss is 4.086061296463012 and perplexity is 59.50505675759845
At time: 305.32217717170715 and batch: 1800, loss is 4.036087174415588 and perplexity is 56.60442568210314
At time: 306.36535477638245 and batch: 1850, loss is 4.071125316619873 and perplexity is 58.62289480545645
At time: 307.40734696388245 and batch: 1900, loss is 4.147630672454834 and perplexity is 63.283882283517066
At time: 308.4489486217499 and batch: 1950, loss is 4.091180095672607 and perplexity is 59.81043210585232
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371814532612645 and perplexity of 79.18718915255643
finished 7 epochs...
Completing Train Step...
At time: 311.75159764289856 and batch: 50, loss is 4.0800825786590575 and perplexity is 59.15035420514077
At time: 312.77659273147583 and batch: 100, loss is 4.031153726577759 and perplexity is 56.32585841415476
At time: 313.8041751384735 and batch: 150, loss is 3.999741406440735 and perplexity is 54.58403312854686
At time: 314.83716893196106 and batch: 200, loss is 4.012543492317199 and perplexity is 55.28731473868467
At time: 315.8731129169464 and batch: 250, loss is 4.009010138511658 and perplexity is 55.0923098083406
At time: 316.9093384742737 and batch: 300, loss is 4.020842852592469 and perplexity is 55.74807343885141
At time: 317.9443416595459 and batch: 350, loss is 4.034872260093689 and perplexity is 56.53569791228862
At time: 318.9790372848511 and batch: 400, loss is 3.9899604082107545 and perplexity is 54.05274927590445
At time: 320.02936148643494 and batch: 450, loss is 4.030183005332947 and perplexity is 56.27120823609571
At time: 321.08176612854004 and batch: 500, loss is 4.038532285690308 and perplexity is 56.742999146268055
At time: 322.1180591583252 and batch: 550, loss is 4.003949303627014 and perplexity is 54.81420104981804
At time: 323.15892791748047 and batch: 600, loss is 3.9958858585357664 and perplexity is 54.37398695571316
At time: 324.2012553215027 and batch: 650, loss is 4.059500880241394 and perplexity is 57.9453821749026
At time: 325.24285221099854 and batch: 700, loss is 4.085791239738464 and perplexity is 59.488989186551905
At time: 326.28398418426514 and batch: 750, loss is 4.058053598403931 and perplexity is 57.86157953336443
At time: 327.32615637779236 and batch: 800, loss is 4.033199071884155 and perplexity is 56.44118214251004
At time: 328.3692388534546 and batch: 850, loss is 4.024101657867432 and perplexity is 55.930041893483676
At time: 329.40963864326477 and batch: 900, loss is 4.0001714277267455 and perplexity is 54.6075104721854
At time: 330.4546661376953 and batch: 950, loss is 4.101952223777771 and perplexity is 60.45820040020692
At time: 331.4973990917206 and batch: 1000, loss is 4.072959747314453 and perplexity is 58.73053314044072
At time: 332.539968252182 and batch: 1050, loss is 4.020263881683349 and perplexity is 55.71580626786888
At time: 333.58642745018005 and batch: 1100, loss is 4.055985054969788 and perplexity is 57.74201404876436
At time: 334.6291699409485 and batch: 1150, loss is 4.021715211868286 and perplexity is 55.796727006434736
At time: 335.67057490348816 and batch: 1200, loss is 4.0998336219787594 and perplexity is 60.330249134823354
At time: 336.7119472026825 and batch: 1250, loss is 4.083017501831055 and perplexity is 59.32421095363229
At time: 337.75462007522583 and batch: 1300, loss is 4.083314204216004 and perplexity is 59.34181519998924
At time: 338.7972102165222 and batch: 1350, loss is 3.9672559547424315 and perplexity is 52.83933818781072
At time: 339.8384506702423 and batch: 1400, loss is 3.996833853721619 and perplexity is 54.42555767411697
At time: 340.8805921077728 and batch: 1450, loss is 3.9247161293029786 and perplexity is 50.63870117494836
At time: 341.9224765300751 and batch: 1500, loss is 3.9403928899765015 and perplexity is 51.43880712265619
At time: 342.96576499938965 and batch: 1550, loss is 3.933685426712036 and perplexity is 51.09493774833552
At time: 344.0073480606079 and batch: 1600, loss is 4.027411766052246 and perplexity is 56.115483128887455
At time: 345.0493688583374 and batch: 1650, loss is 3.983257737159729 and perplexity is 53.69166295137165
At time: 346.09101700782776 and batch: 1700, loss is 4.020336084365844 and perplexity is 55.71982924377187
At time: 347.1337556838989 and batch: 1750, loss is 4.019297671318054 and perplexity is 55.66199907706087
At time: 348.17444586753845 and batch: 1800, loss is 3.9717683172225953 and perplexity is 53.07830718681983
At time: 349.21625781059265 and batch: 1850, loss is 4.002732133865356 and perplexity is 54.74752344900244
At time: 350.2589554786682 and batch: 1900, loss is 4.081906695365905 and perplexity is 59.258349822822176
At time: 351.3008108139038 and batch: 1950, loss is 4.023806757926941 and perplexity is 55.91355055922392
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.367407510446948 and perplexity of 78.83897730695898
finished 8 epochs...
Completing Train Step...
At time: 354.5820050239563 and batch: 50, loss is 4.008975338935852 and perplexity is 55.090392652687406
At time: 355.6154074668884 and batch: 100, loss is 3.966570038795471 and perplexity is 52.803107270223435
At time: 356.6344966888428 and batch: 150, loss is 3.940874080657959 and perplexity is 51.463564953449925
At time: 357.65604400634766 and batch: 200, loss is 3.9442385387420655 and perplexity is 51.63700356045192
At time: 358.6775691509247 and batch: 250, loss is 3.9421673583984376 and perplexity is 51.530164693147626
At time: 359.7038447856903 and batch: 300, loss is 3.953420419692993 and perplexity is 52.11331173595271
At time: 360.7325828075409 and batch: 350, loss is 3.9672097301483156 and perplexity is 52.836895767300014
At time: 361.7673852443695 and batch: 400, loss is 3.9216870784759523 and perplexity is 50.485546049705974
At time: 362.8054542541504 and batch: 450, loss is 3.962422041893005 and perplexity is 52.58453377930327
At time: 363.8403203487396 and batch: 500, loss is 3.972352538108826 and perplexity is 53.10932570243421
At time: 364.87492394447327 and batch: 550, loss is 3.9482033824920655 and perplexity is 51.842142614704024
At time: 365.91239047050476 and batch: 600, loss is 3.9336831855773924 and perplexity is 51.09482323782873
At time: 366.9477393627167 and batch: 650, loss is 3.9962836694717407 and perplexity is 54.395621825365225
At time: 367.9825007915497 and batch: 700, loss is 4.021220264434814 and perplexity is 55.7691173928241
At time: 369.0180275440216 and batch: 750, loss is 3.9991040325164793 and perplexity is 54.54925377405425
At time: 370.05360102653503 and batch: 800, loss is 3.9704292726516726 and perplexity is 53.00728053228842
At time: 371.0893759727478 and batch: 850, loss is 3.9650030374526977 and perplexity is 52.72042952521499
At time: 372.1420612335205 and batch: 900, loss is 3.937796993255615 and perplexity is 51.30545045687321
At time: 373.1775097846985 and batch: 950, loss is 4.037033381462098 and perplexity is 56.65801053573231
At time: 374.2143404483795 and batch: 1000, loss is 4.010126452445984 and perplexity is 55.15384446105886
At time: 375.2490220069885 and batch: 1050, loss is 3.9606225204467775 and perplexity is 52.489991873633684
At time: 376.2836513519287 and batch: 1100, loss is 3.9965351963043214 and perplexity is 54.40930550466333
At time: 377.31831884384155 and batch: 1150, loss is 3.9600183391571044 and perplexity is 52.45828798106231
At time: 378.3542249202728 and batch: 1200, loss is 4.040998392105102 and perplexity is 56.88310610878971
At time: 379.38827681541443 and batch: 1250, loss is 4.029640622138977 and perplexity is 56.240695953866656
At time: 380.4273545742035 and batch: 1300, loss is 4.026263689994812 and perplexity is 56.05109525441669
At time: 381.4616003036499 and batch: 1350, loss is 3.9085416698455813 and perplexity is 49.82623586200741
At time: 382.4982843399048 and batch: 1400, loss is 3.938970890045166 and perplexity is 51.36571312460674
At time: 383.53447222709656 and batch: 1450, loss is 3.865859909057617 and perplexity is 47.74431055072748
At time: 384.57103991508484 and batch: 1500, loss is 3.879629526138306 and perplexity is 48.406278488110964
At time: 385.60779905319214 and batch: 1550, loss is 3.872105736732483 and perplexity is 48.04344649019773
At time: 386.64926505088806 and batch: 1600, loss is 3.9683441162109374 and perplexity is 52.89686721440642
At time: 387.69796538352966 and batch: 1650, loss is 3.9307892322540283 and perplexity is 50.94717095676621
At time: 388.7399010658264 and batch: 1700, loss is 3.9624656724929808 and perplexity is 52.586828124112955
At time: 389.78267216682434 and batch: 1750, loss is 3.9580494737625123 and perplexity is 52.35510628196659
At time: 390.82565903663635 and batch: 1800, loss is 3.915064477920532 and perplexity is 50.15230512313164
At time: 391.8685128688812 and batch: 1850, loss is 3.944397177696228 and perplexity is 51.645195850483816
At time: 392.9113736152649 and batch: 1900, loss is 4.020023031234741 and perplexity is 55.70238870681235
At time: 393.9563817977905 and batch: 1950, loss is 3.96589328289032 and perplexity is 52.76738454471411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365878792696221 and perplexity of 78.71854683845176
finished 9 epochs...
Completing Train Step...
At time: 397.26124835014343 and batch: 50, loss is 3.9539236640930175 and perplexity is 52.13954406833412
At time: 398.2984211444855 and batch: 100, loss is 3.9128795719146727 and perplexity is 50.04284667221834
At time: 399.32134675979614 and batch: 150, loss is 3.888580470085144 and perplexity is 48.84150531315193
At time: 400.3444905281067 and batch: 200, loss is 3.893057131767273 and perplexity is 49.06064234369084
At time: 401.3651602268219 and batch: 250, loss is 3.8852744722366332 and perplexity is 48.68030201736737
At time: 402.38584303855896 and batch: 300, loss is 3.897130222320557 and perplexity is 49.260878295313226
At time: 403.40810203552246 and batch: 350, loss is 3.9117419862747194 and perplexity is 49.98595101643785
At time: 404.4311158657074 and batch: 400, loss is 3.8630627155303956 and perplexity is 47.61094708296393
At time: 405.4622447490692 and batch: 450, loss is 3.9090921974182127 and perplexity is 49.85367413075863
At time: 406.49674344062805 and batch: 500, loss is 3.915396881103516 and perplexity is 50.1689786800067
At time: 407.53079628944397 and batch: 550, loss is 3.89745454788208 and perplexity is 49.276857448411306
At time: 408.56863474845886 and batch: 600, loss is 3.882440767288208 and perplexity is 48.54255166874878
At time: 409.61108922958374 and batch: 650, loss is 3.9420268678665162 and perplexity is 51.522925701416696
At time: 410.653600692749 and batch: 700, loss is 3.9667748737335207 and perplexity is 52.81392429924487
At time: 411.69712114334106 and batch: 750, loss is 3.9426448154449463 and perplexity is 51.55477400786597
At time: 412.7411971092224 and batch: 800, loss is 3.9200161600112917 and perplexity is 50.40125925640318
At time: 413.7829177379608 and batch: 850, loss is 3.9135465908050535 and perplexity is 50.07623733113927
At time: 414.8249509334564 and batch: 900, loss is 3.884698414802551 and perplexity is 48.65226744303464
At time: 415.86569023132324 and batch: 950, loss is 3.9807952785491945 and perplexity is 53.55961210522111
At time: 416.9058909416199 and batch: 1000, loss is 3.957187705039978 and perplexity is 52.31000772396222
At time: 417.947767496109 and batch: 1050, loss is 3.9114707994461058 and perplexity is 49.972397322781134
At time: 418.9882757663727 and batch: 1100, loss is 3.9442657136917116 and perplexity is 51.638406812490125
At time: 420.0317053794861 and batch: 1150, loss is 3.90760853767395 and perplexity is 49.779763084327385
At time: 421.07295632362366 and batch: 1200, loss is 3.9871817874908446 and perplexity is 53.90276565709238
At time: 422.1152329444885 and batch: 1250, loss is 3.9775906467437743 and perplexity is 53.38824799487622
At time: 423.15856766700745 and batch: 1300, loss is 3.979445414543152 and perplexity is 53.48736268707785
At time: 424.2000126838684 and batch: 1350, loss is 3.8601921367645264 and perplexity is 47.47447208407695
At time: 425.2440416812897 and batch: 1400, loss is 3.8915513801574706 and perplexity is 48.98682479189975
At time: 426.28520941734314 and batch: 1450, loss is 3.8154128313064577 and perplexity is 45.39549319587301
At time: 427.3282151222229 and batch: 1500, loss is 3.8278746747970582 and perplexity is 45.96474431954092
At time: 428.3697657585144 and batch: 1550, loss is 3.818572540283203 and perplexity is 45.53915659096228
At time: 429.4119882583618 and batch: 1600, loss is 3.921996669769287 and perplexity is 50.50117835489015
At time: 430.4542624950409 and batch: 1650, loss is 3.8782687425613402 and perplexity is 48.34045281672623
At time: 431.4958109855652 and batch: 1700, loss is 3.914665846824646 and perplexity is 50.13231683901967
At time: 432.5402641296387 and batch: 1750, loss is 3.9092689466476442 and perplexity is 49.86248650801307
At time: 433.58178186416626 and batch: 1800, loss is 3.868394193649292 and perplexity is 47.865461672164415
At time: 434.6226897239685 and batch: 1850, loss is 3.891665334701538 and perplexity is 48.9924073812589
At time: 435.66482758522034 and batch: 1900, loss is 3.968222575187683 and perplexity is 52.8904384657245
At time: 436.70724725723267 and batch: 1950, loss is 3.9128429651260377 and perplexity is 50.041014797837235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3716615188953485 and perplexity of 79.1750733533473
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 439.9929873943329 and batch: 50, loss is 3.936713500022888 and perplexity is 51.249891452838945
At time: 441.05572152137756 and batch: 100, loss is 3.9243662309646608 and perplexity is 50.620985877010064
At time: 442.0874502658844 and batch: 150, loss is 3.8951926755905153 and perplexity is 49.16552544678334
At time: 443.1098189353943 and batch: 200, loss is 3.894204368591309 and perplexity is 49.11695881718772
At time: 444.12952613830566 and batch: 250, loss is 3.889248127937317 and perplexity is 48.87412561607515
At time: 445.15074467658997 and batch: 300, loss is 3.898332223892212 and perplexity is 49.32012554895788
At time: 446.17697620391846 and batch: 350, loss is 3.9091440439224243 and perplexity is 49.8562589364904
At time: 447.2017512321472 and batch: 400, loss is 3.853304262161255 and perplexity is 47.14859745366714
At time: 448.22542810440063 and batch: 450, loss is 3.885635938644409 and perplexity is 48.69790149188482
At time: 449.2575087547302 and batch: 500, loss is 3.8904506158828736 and perplexity is 48.93293151258293
At time: 450.3051996231079 and batch: 550, loss is 3.8685940313339233 and perplexity is 47.87502795101846
At time: 451.34014916419983 and batch: 600, loss is 3.8436167526245115 and perplexity is 46.69405023629296
At time: 452.3752748966217 and batch: 650, loss is 3.890102391242981 and perplexity is 48.915894826597146
At time: 453.43889713287354 and batch: 700, loss is 3.914817690849304 and perplexity is 50.1399297097438
At time: 454.4957664012909 and batch: 750, loss is 3.8759886169433595 and perplexity is 48.23035607677179
At time: 455.53161215782166 and batch: 800, loss is 3.8525957250595093 and perplexity is 47.115202755164475
At time: 456.5667335987091 and batch: 850, loss is 3.848300676345825 and perplexity is 46.91327462018553
At time: 457.61266708374023 and batch: 900, loss is 3.809780993461609 and perplexity is 45.14055170771148
At time: 458.6670994758606 and batch: 950, loss is 3.9061671113967895 and perplexity is 49.70806091485711
At time: 459.7023630142212 and batch: 1000, loss is 3.872662181854248 and perplexity is 48.070187470884136
At time: 460.73763132095337 and batch: 1050, loss is 3.8126237964630127 and perplexity is 45.269059978895434
At time: 461.7736189365387 and batch: 1100, loss is 3.8355638647079466 and perplexity is 46.31953825875079
At time: 462.8275008201599 and batch: 1150, loss is 3.80354718208313 and perplexity is 44.86002929318886
At time: 463.8659734725952 and batch: 1200, loss is 3.8656907224655153 and perplexity is 47.73623353681364
At time: 464.91239738464355 and batch: 1250, loss is 3.8488885021209716 and perplexity is 46.9408595589785
At time: 465.9515902996063 and batch: 1300, loss is 3.8517637062072754 and perplexity is 47.07601832159955
At time: 466.9873435497284 and batch: 1350, loss is 3.734467077255249 and perplexity is 41.86570842872987
At time: 468.0229072570801 and batch: 1400, loss is 3.7483159065246583 and perplexity is 42.44953278799309
At time: 469.0589666366577 and batch: 1450, loss is 3.670763306617737 and perplexity is 39.28187853752263
At time: 470.0942373275757 and batch: 1500, loss is 3.682239360809326 and perplexity is 39.73527613605127
At time: 471.12991738319397 and batch: 1550, loss is 3.6660275411605836 and perplexity is 39.096288576175986
At time: 472.1653172969818 and batch: 1600, loss is 3.759234561920166 and perplexity is 42.91556419648418
At time: 473.20058131217957 and batch: 1650, loss is 3.701759853363037 and perplexity is 40.51854835577658
At time: 474.2356414794922 and batch: 1700, loss is 3.7316534423828127 and perplexity is 41.74807917202628
At time: 475.30269479751587 and batch: 1750, loss is 3.7187306880950928 and perplexity is 41.21204994947999
At time: 476.3370785713196 and batch: 1800, loss is 3.6755587005615236 and perplexity is 39.470703001961255
At time: 477.371333360672 and batch: 1850, loss is 3.682334270477295 and perplexity is 39.73904757688626
At time: 478.4055526256561 and batch: 1900, loss is 3.754328894615173 and perplexity is 42.705550266739806
At time: 479.44076776504517 and batch: 1950, loss is 3.6906090688705446 and perplexity is 40.06924445611844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.321478981195495 and perplexity of 75.2999131331905
finished 11 epochs...
Completing Train Step...
At time: 482.76681900024414 and batch: 50, loss is 3.86025372505188 and perplexity is 47.47739604554559
At time: 483.7811357975006 and batch: 100, loss is 3.8337946557998657 and perplexity is 46.237661768709785
At time: 484.80111289024353 and batch: 150, loss is 3.795976047515869 and perplexity is 44.521670471090296
At time: 485.82224702835083 and batch: 200, loss is 3.79552218914032 and perplexity is 44.50146852281205
At time: 486.84483766555786 and batch: 250, loss is 3.7903980445861816 and perplexity is 44.27401980296314
At time: 487.8736381530762 and batch: 300, loss is 3.7998322582244874 and perplexity is 44.693686866096634
At time: 488.90844798088074 and batch: 350, loss is 3.8113511276245116 and perplexity is 45.21148410219535
At time: 489.9511888027191 and batch: 400, loss is 3.761067728996277 and perplexity is 42.9943077488142
At time: 490.99273800849915 and batch: 450, loss is 3.7995565843582155 and perplexity is 44.68136768275678
At time: 492.0375053882599 and batch: 500, loss is 3.8050954008102416 and perplexity is 44.92953622272044
At time: 493.0792541503906 and batch: 550, loss is 3.7862066650390624 and perplexity is 44.088838934643746
At time: 494.1191303730011 and batch: 600, loss is 3.7657016563415526 and perplexity is 43.19400257549985
At time: 495.15907859802246 and batch: 650, loss is 3.8155179166793824 and perplexity is 45.40026384886313
At time: 496.20003294944763 and batch: 700, loss is 3.841083817481995 and perplexity is 46.575926898034574
At time: 497.2415246963501 and batch: 750, loss is 3.805639843940735 and perplexity is 44.95400446025066
At time: 498.2834596633911 and batch: 800, loss is 3.7827797746658325 and perplexity is 43.938009901818035
At time: 499.3246793746948 and batch: 850, loss is 3.780811414718628 and perplexity is 43.851609144758434
At time: 500.36580753326416 and batch: 900, loss is 3.742490062713623 and perplexity is 42.20294742146913
At time: 501.4495120048523 and batch: 950, loss is 3.841360297203064 and perplexity is 46.588805977632
At time: 502.4903974533081 and batch: 1000, loss is 3.8096234035491943 and perplexity is 45.1334385726154
At time: 503.53151845932007 and batch: 1050, loss is 3.7557603931427 and perplexity is 42.76672697580146
At time: 504.57255482673645 and batch: 1100, loss is 3.7793372821807862 and perplexity is 43.78701368371442
At time: 505.61349081993103 and batch: 1150, loss is 3.7493495988845824 and perplexity is 42.493435232619966
At time: 506.65530610084534 and batch: 1200, loss is 3.816386308670044 and perplexity is 45.439706197594624
At time: 507.6968147754669 and batch: 1250, loss is 3.8027517890930174 and perplexity is 44.82436212694022
At time: 508.7382698059082 and batch: 1300, loss is 3.807235598564148 and perplexity is 45.025797287342286
At time: 509.7802939414978 and batch: 1350, loss is 3.690064969062805 and perplexity is 40.04744871797977
At time: 510.82191944122314 and batch: 1400, loss is 3.7087474250793457 and perplexity is 40.80266610881029
At time: 511.8646697998047 and batch: 1450, loss is 3.631029748916626 and perplexity is 37.75167135111288
At time: 512.9066400527954 and batch: 1500, loss is 3.645087399482727 and perplexity is 38.28611889232155
At time: 513.9525246620178 and batch: 1550, loss is 3.6320651292800905 and perplexity is 37.790778932435025
At time: 514.9934313297272 and batch: 1600, loss is 3.7281707620620725 and perplexity is 41.60293684712781
At time: 516.0350530147552 and batch: 1650, loss is 3.6737024927139283 and perplexity is 39.39750512954849
At time: 517.0761871337891 and batch: 1700, loss is 3.708304748535156 and perplexity is 40.78460772289035
At time: 518.1175248622894 and batch: 1750, loss is 3.697413234710693 and perplexity is 40.34281188412397
At time: 519.1590025424957 and batch: 1800, loss is 3.657856388092041 and perplexity is 38.77812845556516
At time: 520.2007656097412 and batch: 1850, loss is 3.6673458003997803 and perplexity is 39.147861605652466
At time: 521.2428550720215 and batch: 1900, loss is 3.7435289478302 and perplexity is 42.246814217756494
At time: 522.2849881649017 and batch: 1950, loss is 3.6818608236312866 and perplexity is 39.72023770323665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324282624000727 and perplexity of 75.51132341385616
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 525.5871896743774 and batch: 50, loss is 3.8428833198547365 and perplexity is 46.65981584554278
At time: 526.5977501869202 and batch: 100, loss is 3.855509419441223 and perplexity is 47.25268224607333
At time: 527.6265323162079 and batch: 150, loss is 3.833470640182495 and perplexity is 46.22268247108026
At time: 528.6462969779968 and batch: 200, loss is 3.8354762172698975 and perplexity is 46.31547864780064
At time: 529.6660776138306 and batch: 250, loss is 3.8308651208877564 and perplexity is 46.10240514054419
At time: 530.6914258003235 and batch: 300, loss is 3.8385181188583375 and perplexity is 46.45658027569872
At time: 531.7206346988678 and batch: 350, loss is 3.8522928857803347 and perplexity is 47.10093658141186
At time: 532.7583270072937 and batch: 400, loss is 3.8087183809280396 and perplexity is 45.09261026779317
At time: 533.7930953502655 and batch: 450, loss is 3.837698950767517 and perplexity is 46.41854011030026
At time: 534.8282098770142 and batch: 500, loss is 3.8372191524505617 and perplexity is 46.39627391494849
At time: 535.8613169193268 and batch: 550, loss is 3.8181443309783933 and perplexity is 45.5196604748839
At time: 536.8955175876617 and batch: 600, loss is 3.7899289989471434 and perplexity is 44.253258136517054
At time: 537.9299533367157 and batch: 650, loss is 3.828636245727539 and perplexity is 45.99976306557863
At time: 538.9643747806549 and batch: 700, loss is 3.8491799640655517 and perplexity is 46.95454302719409
At time: 539.9985003471375 and batch: 750, loss is 3.806920385360718 and perplexity is 45.01160679817462
At time: 541.0309274196625 and batch: 800, loss is 3.784103455543518 and perplexity is 43.996208314894275
At time: 542.0639736652374 and batch: 850, loss is 3.787044816017151 and perplexity is 44.125807528587
At time: 543.1056659221649 and batch: 900, loss is 3.7605603170394897 and perplexity is 42.97249745685808
At time: 544.1482915878296 and batch: 950, loss is 3.8620508432388307 and perplexity is 47.56279525069645
At time: 545.1914355754852 and batch: 1000, loss is 3.818598260879517 and perplexity is 45.540327900288744
At time: 546.2344813346863 and batch: 1050, loss is 3.753375406265259 and perplexity is 42.66485042857804
At time: 547.2773382663727 and batch: 1100, loss is 3.76964063167572 and perplexity is 43.36447821548097
At time: 548.3198223114014 and batch: 1150, loss is 3.741665496826172 and perplexity is 42.16816265381279
At time: 549.3620274066925 and batch: 1200, loss is 3.8003500747680663 and perplexity is 44.71683598953172
At time: 550.4044766426086 and batch: 1250, loss is 3.780163297653198 and perplexity is 43.82319737659561
At time: 551.4459774494171 and batch: 1300, loss is 3.7894640302658082 and perplexity is 44.232686540381124
At time: 552.4860908985138 and batch: 1350, loss is 3.670227837562561 and perplexity is 39.260849937721304
At time: 553.5269434452057 and batch: 1400, loss is 3.6847134971618654 and perplexity is 39.83370834435858
At time: 554.5680429935455 and batch: 1450, loss is 3.603501033782959 and perplexity is 36.72659065747465
At time: 555.6105546951294 and batch: 1500, loss is 3.620840458869934 and perplexity is 37.368961702896286
At time: 556.6513624191284 and batch: 1550, loss is 3.6080892515182494 and perplexity is 36.89548742335686
At time: 557.6930990219116 and batch: 1600, loss is 3.7058362579345703 and perplexity is 40.684055459295735
At time: 558.7349648475647 and batch: 1650, loss is 3.6387226676940916 and perplexity is 38.04321185342946
At time: 559.7769215106964 and batch: 1700, loss is 3.659771218299866 and perplexity is 38.852453124185374
At time: 560.8202579021454 and batch: 1750, loss is 3.6480977153778076 and perplexity is 38.40154585322501
At time: 561.9209887981415 and batch: 1800, loss is 3.612467951774597 and perplexity is 37.057395919292475
At time: 562.967756986618 and batch: 1850, loss is 3.620035796165466 and perplexity is 37.33890438773133
At time: 564.0088346004486 and batch: 1900, loss is 3.699208059310913 and perplexity is 40.41528517430225
At time: 565.0500078201294 and batch: 1950, loss is 3.6401661109924315 and perplexity is 38.0981647237615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.29477652616279 and perplexity of 73.31582844466031
finished 13 epochs...
Completing Train Step...
At time: 568.3729910850525 and batch: 50, loss is 3.8357460641860963 and perplexity is 46.32797842332311
At time: 569.3930242061615 and batch: 100, loss is 3.826849060058594 and perplexity is 45.91762636688062
At time: 570.4182183742523 and batch: 150, loss is 3.796817812919617 and perplexity is 44.55916305077432
At time: 571.4506905078888 and batch: 200, loss is 3.7913141536712645 and perplexity is 44.3145982190276
At time: 572.4857182502747 and batch: 250, loss is 3.783851456642151 and perplexity is 43.9851227155727
At time: 573.5224106311798 and batch: 300, loss is 3.7891159200668336 and perplexity is 44.2172913708316
At time: 574.5555236339569 and batch: 350, loss is 3.803447952270508 and perplexity is 44.85557806173897
At time: 575.590470790863 and batch: 400, loss is 3.757876377105713 and perplexity is 42.85731649341568
At time: 576.6253836154938 and batch: 450, loss is 3.790129780769348 and perplexity is 44.26214427838223
At time: 577.6643843650818 and batch: 500, loss is 3.792141809463501 and perplexity is 44.35129063517503
At time: 578.719019651413 and batch: 550, loss is 3.7746325540542602 and perplexity is 43.581491530880065
At time: 579.7620325088501 and batch: 600, loss is 3.7512484121322633 and perplexity is 42.57419898375335
At time: 580.8035972118378 and batch: 650, loss is 3.792164001464844 and perplexity is 44.35227488999762
At time: 581.8452007770538 and batch: 700, loss is 3.812804388999939 and perplexity is 45.27723597152068
At time: 582.8865518569946 and batch: 750, loss is 3.774699716567993 and perplexity is 43.58441867169947
At time: 583.927928686142 and batch: 800, loss is 3.7539153575897215 and perplexity is 42.6878935916083
At time: 584.9698855876923 and batch: 850, loss is 3.7576647090911863 and perplexity is 42.84824593033348
At time: 586.0086052417755 and batch: 900, loss is 3.7315075540542604 and perplexity is 41.741989058784625
At time: 587.0463898181915 and batch: 950, loss is 3.833276295661926 and perplexity is 46.21370021887003
At time: 588.0869643688202 and batch: 1000, loss is 3.79039445400238 and perplexity is 44.273860833670206
At time: 589.1285061836243 and batch: 1050, loss is 3.727539291381836 and perplexity is 41.57667410524556
At time: 590.1717622280121 and batch: 1100, loss is 3.746178159713745 and perplexity is 42.358883361933565
At time: 591.2244260311127 and batch: 1150, loss is 3.719062647819519 and perplexity is 41.22573296120301
At time: 592.2765533924103 and batch: 1200, loss is 3.780017251968384 and perplexity is 43.81679765506123
At time: 593.3293015956879 and batch: 1250, loss is 3.7625201463699343 and perplexity is 43.0567987989149
At time: 594.3813166618347 and batch: 1300, loss is 3.7740346002578735 and perplexity is 43.555439602268024
At time: 595.433317899704 and batch: 1350, loss is 3.6555801391601563 and perplexity is 38.68996016664336
At time: 596.4868547916412 and batch: 1400, loss is 3.6725386333465577 and perplexity is 39.35167864711579
At time: 597.5436742305756 and batch: 1450, loss is 3.5929417610168457 and perplexity is 36.34082485645542
At time: 598.5996906757355 and batch: 1500, loss is 3.612085952758789 and perplexity is 37.04324273394645
At time: 599.6604776382446 and batch: 1550, loss is 3.6014879369735717 and perplexity is 36.652730843423846
At time: 600.7446782588959 and batch: 1600, loss is 3.701174192428589 and perplexity is 40.494825172433
At time: 601.802050113678 and batch: 1650, loss is 3.635080699920654 and perplexity is 37.90491169708438
At time: 602.858740568161 and batch: 1700, loss is 3.6590723991394043 and perplexity is 38.82531177006494
At time: 603.9149806499481 and batch: 1750, loss is 3.649174451828003 and perplexity is 38.44291646601545
At time: 604.9730315208435 and batch: 1800, loss is 3.6154553842544557 and perplexity is 37.168267916324524
At time: 606.0310599803925 and batch: 1850, loss is 3.6243734788894653 and perplexity is 37.501220491602155
At time: 607.0879311561584 and batch: 1900, loss is 3.7044275426864623 and perplexity is 40.62678355938594
At time: 608.1462469100952 and batch: 1950, loss is 3.6448340797424317 and perplexity is 38.276421490950284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.293933389353198 and perplexity of 73.25403922301683
finished 14 epochs...
Completing Train Step...
At time: 611.4931037425995 and batch: 50, loss is 3.820082116127014 and perplexity is 45.60795331557171
At time: 612.5528016090393 and batch: 100, loss is 3.809279565811157 and perplexity is 45.11792266081763
At time: 613.5878670215607 and batch: 150, loss is 3.7783617687225344 and perplexity is 43.74431969023763
At time: 614.6498825550079 and batch: 200, loss is 3.771516451835632 and perplexity is 43.44589851899053
At time: 615.7261247634888 and batch: 250, loss is 3.763540906906128 and perplexity is 43.10077191913839
At time: 616.7630200386047 and batch: 300, loss is 3.768676509857178 and perplexity is 43.32268972371904
At time: 617.7863736152649 and batch: 350, loss is 3.7832731580734253 and perplexity is 43.959693535598944
At time: 618.8143291473389 and batch: 400, loss is 3.7369975996017457 and perplexity is 41.971784697039055
At time: 619.8466742038727 and batch: 450, loss is 3.7699582862854 and perplexity is 43.3782553299486
At time: 620.882532119751 and batch: 500, loss is 3.7725512075424192 and perplexity is 43.490877677626756
At time: 621.9559826850891 and batch: 550, loss is 3.7550958967208863 and perplexity is 42.73831807860396
At time: 623.0052745342255 and batch: 600, loss is 3.7330977392196654 and perplexity is 41.80841935479757
At time: 624.0458550453186 and batch: 650, loss is 3.775131573677063 and perplexity is 43.60324497759196
At time: 625.0871117115021 and batch: 700, loss is 3.795704207420349 and perplexity is 44.509569340797455
At time: 626.135187625885 and batch: 750, loss is 3.7586352491378783 and perplexity is 42.889852055879
At time: 627.1878135204315 and batch: 800, loss is 3.7384192609786986 and perplexity is 42.03149679740091
At time: 628.2413868904114 and batch: 850, loss is 3.7424142026901244 and perplexity is 42.19974602631653
At time: 629.2944791316986 and batch: 900, loss is 3.7165571737289427 and perplexity is 41.12257224262257
At time: 630.3468995094299 and batch: 950, loss is 3.8189305162429807 and perplexity is 45.55546143244692
At time: 631.4342079162598 and batch: 1000, loss is 3.775940146446228 and perplexity is 43.638515631651636
At time: 632.485303401947 and batch: 1050, loss is 3.7142955255508423 and perplexity is 41.02967254484625
At time: 633.5360989570618 and batch: 1100, loss is 3.7334346055984495 and perplexity is 41.82250557808261
At time: 634.5869553089142 and batch: 1150, loss is 3.706780195236206 and perplexity is 40.722476787635244
At time: 635.638833284378 and batch: 1200, loss is 3.7687252044677733 and perplexity is 43.324799356588535
At time: 636.6910562515259 and batch: 1250, loss is 3.752306489944458 and perplexity is 42.619269638995334
At time: 637.7439262866974 and batch: 1300, loss is 3.7645896911621093 and perplexity is 43.14599904274979
At time: 638.7963693141937 and batch: 1350, loss is 3.6464058351516724 and perplexity is 38.336629967579476
At time: 639.8491613864899 and batch: 1400, loss is 3.6643588829040525 and perplexity is 39.03110463143238
At time: 640.9008085727692 and batch: 1450, loss is 3.5851825857162476 and perplexity is 36.05994114800324
At time: 641.9530882835388 and batch: 1500, loss is 3.604749059677124 and perplexity is 36.7724550076148
At time: 643.005980014801 and batch: 1550, loss is 3.595124225616455 and perplexity is 36.42022403165394
At time: 644.0593409538269 and batch: 1600, loss is 3.695708394050598 and perplexity is 40.27409241260027
At time: 645.1153450012207 and batch: 1650, loss is 3.629853410720825 and perplexity is 37.70728872775275
At time: 646.1722621917725 and batch: 1700, loss is 3.6550102758407594 and perplexity is 38.667918458492444
At time: 647.2282474040985 and batch: 1750, loss is 3.645910177230835 and perplexity is 38.31763282170968
At time: 648.2837553024292 and batch: 1800, loss is 3.6131438875198363 and perplexity is 37.08245280528825
At time: 649.340101480484 and batch: 1850, loss is 3.6226612234115603 and perplexity is 37.43706376341658
At time: 650.3953385353088 and batch: 1900, loss is 3.703146905899048 and perplexity is 40.574788706172455
At time: 651.4519791603088 and batch: 1950, loss is 3.6432757329940797 and perplexity is 38.21682000593307
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.29496218659157 and perplexity of 73.32944155647465
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 654.7888133525848 and batch: 50, loss is 3.8180095243453978 and perplexity is 45.51352453631208
At time: 655.8430187702179 and batch: 100, loss is 3.8242543172836303 and perplexity is 45.79863637858811
At time: 656.8770716190338 and batch: 150, loss is 3.808151135444641 and perplexity is 45.06703894157942
At time: 657.9506223201752 and batch: 200, loss is 3.811287908554077 and perplexity is 45.2086259645428
At time: 658.9851474761963 and batch: 250, loss is 3.8077721309661867 and perplexity is 45.04996156839478
At time: 660.0203869342804 and batch: 300, loss is 3.810042796134949 and perplexity is 45.15237117194075
At time: 661.0536332130432 and batch: 350, loss is 3.830160641670227 and perplexity is 46.06993839166223
At time: 662.0875775814056 and batch: 400, loss is 3.792626142501831 and perplexity is 44.37277663329158
At time: 663.1223375797272 and batch: 450, loss is 3.82772768497467 and perplexity is 45.95798846647026
At time: 664.1629302501678 and batch: 500, loss is 3.825337166786194 and perplexity is 45.848256269797474
At time: 665.2046411037445 and batch: 550, loss is 3.8063757944107057 and perplexity is 44.9871005580108
At time: 666.2458145618439 and batch: 600, loss is 3.770825366973877 and perplexity is 43.41588408867249
At time: 667.2870717048645 and batch: 650, loss is 3.8052226877212525 and perplexity is 44.935255528588044
At time: 668.329653263092 and batch: 700, loss is 3.823232398033142 and perplexity is 45.7518577764747
At time: 669.3786180019379 and batch: 750, loss is 3.7778689861297607 and perplexity is 43.722768561408245
At time: 670.4361515045166 and batch: 800, loss is 3.7509196281433104 and perplexity is 42.560203569645104
At time: 671.4923975467682 and batch: 850, loss is 3.753177547454834 and perplexity is 42.656409647094314
At time: 672.5477983951569 and batch: 900, loss is 3.7310855484008787 and perplexity is 41.724377419785405
At time: 673.6058580875397 and batch: 950, loss is 3.8406111145019532 and perplexity is 46.5539155214232
At time: 674.6608195304871 and batch: 1000, loss is 3.8009757804870605 and perplexity is 44.744824324863295
At time: 675.7172470092773 and batch: 1050, loss is 3.7429065704345703 and perplexity is 42.22052893608104
At time: 676.772866487503 and batch: 1100, loss is 3.7580814361572266 and perplexity is 42.86610567520608
At time: 677.8380522727966 and batch: 1150, loss is 3.7314796447753906 and perplexity is 41.74082408622825
At time: 678.8929760456085 and batch: 1200, loss is 3.7851433324813843 and perplexity is 44.04198275304096
At time: 679.9474756717682 and batch: 1250, loss is 3.757547082901001 and perplexity is 42.84320615081941
At time: 681.0189912319183 and batch: 1300, loss is 3.7645989274978637 and perplexity is 43.14639755552381
At time: 682.0765891075134 and batch: 1350, loss is 3.6416673135757445 and perplexity is 38.15540073774135
At time: 683.133118391037 and batch: 1400, loss is 3.661752042770386 and perplexity is 38.92948928644247
At time: 684.1899209022522 and batch: 1450, loss is 3.5734466075897218 and perplexity is 35.63921610636162
At time: 685.246420621872 and batch: 1500, loss is 3.5916014671325684 and perplexity is 36.29215009767804
At time: 686.3024616241455 and batch: 1550, loss is 3.5878364706039427 and perplexity is 36.15576718025379
At time: 687.3575282096863 and batch: 1600, loss is 3.690308060646057 and perplexity is 40.057185099062025
At time: 688.4120812416077 and batch: 1650, loss is 3.6258186626434328 and perplexity is 37.555455826783756
At time: 689.4675211906433 and batch: 1700, loss is 3.6455428123474123 and perplexity is 38.303558854294074
At time: 690.523824930191 and batch: 1750, loss is 3.631479721069336 and perplexity is 37.768662374396115
At time: 691.5808138847351 and batch: 1800, loss is 3.598831000328064 and perplexity is 36.5554761167243
At time: 692.6372652053833 and batch: 1850, loss is 3.6097711372375487 and perplexity is 36.95759362989153
At time: 693.6966142654419 and batch: 1900, loss is 3.696758666038513 and perplexity is 40.31641338407509
At time: 694.7547709941864 and batch: 1950, loss is 3.642648539543152 and perplexity is 38.192858181845125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.277295773528343 and perplexity of 72.0453494006138
finished 16 epochs...
Completing Train Step...
At time: 698.059095621109 and batch: 50, loss is 3.824907088279724 and perplexity is 45.82854215982807
At time: 699.1194932460785 and batch: 100, loss is 3.815099892616272 and perplexity is 45.38128941226459
At time: 700.1446394920349 and batch: 150, loss is 3.789394745826721 and perplexity is 44.22962200966822
At time: 701.1699607372284 and batch: 200, loss is 3.7872290325164797 and perplexity is 44.13393697914644
At time: 702.1952478885651 and batch: 250, loss is 3.780502076148987 and perplexity is 43.83804624858075
At time: 703.2214252948761 and batch: 300, loss is 3.779194293022156 and perplexity is 43.78075306307995
At time: 704.2463173866272 and batch: 350, loss is 3.7993925857543944 and perplexity is 44.67404060167194
At time: 705.2722463607788 and batch: 400, loss is 3.7609462451934816 and perplexity is 42.98908495405924
At time: 706.3020906448364 and batch: 450, loss is 3.798616714477539 and perplexity is 44.63939273962661
At time: 707.3369989395142 and batch: 500, loss is 3.797871775627136 and perplexity is 44.6061515045974
At time: 708.3712038993835 and batch: 550, loss is 3.7805566120147707 and perplexity is 43.84043705957907
At time: 709.4061915874481 and batch: 600, loss is 3.749228415489197 and perplexity is 42.48828604586115
At time: 710.4624314308167 and batch: 650, loss is 3.783502278327942 and perplexity is 43.96976674571446
At time: 711.5079398155212 and batch: 700, loss is 3.803414101600647 and perplexity is 44.85405969607357
At time: 712.560852766037 and batch: 750, loss is 3.7610936260223387 and perplexity is 42.9954211879398
At time: 713.6136364936829 and batch: 800, loss is 3.7360984563827513 and perplexity is 41.93406301257939
At time: 714.6668848991394 and batch: 850, loss is 3.7392402267456055 and perplexity is 42.06601738557515
At time: 715.7217857837677 and batch: 900, loss is 3.7174913120269775 and perplexity is 41.16100435992973
At time: 716.7773969173431 and batch: 950, loss is 3.8270618391036986 and perplexity is 45.92739771510465
At time: 717.8329410552979 and batch: 1000, loss is 3.787949275970459 and perplexity is 44.16573560835665
At time: 718.8890719413757 and batch: 1050, loss is 3.7304270124435424 and perplexity is 41.69690946226852
At time: 719.9467535018921 and batch: 1100, loss is 3.7466670227050782 and perplexity is 42.37959611480007
At time: 721.0016241073608 and batch: 1150, loss is 3.720829071998596 and perplexity is 41.29861944798011
At time: 722.0590579509735 and batch: 1200, loss is 3.7754812383651735 and perplexity is 43.618494158542326
At time: 723.1155245304108 and batch: 1250, loss is 3.750268969535828 and perplexity is 42.532520413974716
At time: 724.170797586441 and batch: 1300, loss is 3.7581444072723387 and perplexity is 42.868805086672545
At time: 725.2256853580475 and batch: 1350, loss is 3.6368297338485718 and perplexity is 37.97126668532451
At time: 726.2809383869171 and batch: 1400, loss is 3.6584722089767454 and perplexity is 38.80201619146625
At time: 727.3373861312866 and batch: 1450, loss is 3.5724053716659547 and perplexity is 35.60212658707767
At time: 728.4246754646301 and batch: 1500, loss is 3.5922251462936403 and perplexity is 36.31479181525424
At time: 729.4811882972717 and batch: 1550, loss is 3.5892454624176025 and perplexity is 36.20674626635096
At time: 730.5376315116882 and batch: 1600, loss is 3.693267149925232 and perplexity is 40.1758934337032
At time: 731.5944349765778 and batch: 1650, loss is 3.6290449619293215 and perplexity is 37.676816634972894
At time: 732.6504776477814 and batch: 1700, loss is 3.6497603273391723 and perplexity is 38.46544582840724
At time: 733.707581281662 and batch: 1750, loss is 3.6366317796707155 and perplexity is 37.96375085836487
At time: 734.763706445694 and batch: 1800, loss is 3.604892973899841 and perplexity is 36.77774746771563
At time: 735.8200416564941 and batch: 1850, loss is 3.6165138053894044 and perplexity is 37.20762842295816
At time: 736.8770887851715 and batch: 1900, loss is 3.703764281272888 and perplexity is 40.599846315698045
At time: 737.9337685108185 and batch: 1950, loss is 3.648871159553528 and perplexity is 38.43125879437326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.275976278615552 and perplexity of 71.95034861889708
finished 17 epochs...
Completing Train Step...
At time: 741.3231210708618 and batch: 50, loss is 3.8217269802093505 and perplexity is 45.68303393162565
At time: 742.3410091400146 and batch: 100, loss is 3.8095671415328978 and perplexity is 45.13089934579059
At time: 743.3612632751465 and batch: 150, loss is 3.782650089263916 and perplexity is 43.932312152809935
At time: 744.3838551044464 and batch: 200, loss is 3.7795447874069215 and perplexity is 43.79610066065564
At time: 745.4170694351196 and batch: 250, loss is 3.7721305322647094 and perplexity is 43.47258598828238
At time: 746.4861416816711 and batch: 300, loss is 3.7701783037185668 and perplexity is 43.3878003523387
At time: 747.5503928661346 and batch: 350, loss is 3.7903882932662962 and perplexity is 44.27358807493839
At time: 748.6137092113495 and batch: 400, loss is 3.7514259147644045 and perplexity is 42.58175668687052
At time: 749.6554501056671 and batch: 450, loss is 3.7893356847763062 and perplexity is 44.22700983887242
At time: 750.6966338157654 and batch: 500, loss is 3.788732190132141 and perplexity is 44.20032712755374
At time: 751.7382736206055 and batch: 550, loss is 3.771623945236206 and perplexity is 43.45056891737734
At time: 752.7816333770752 and batch: 600, loss is 3.7412527275085448 and perplexity is 42.150760521868726
At time: 753.826093673706 and batch: 650, loss is 3.7757053709030153 and perplexity is 43.62827157801291
At time: 754.8751134872437 and batch: 700, loss is 3.795828423500061 and perplexity is 44.51509848840805
At time: 755.9263851642609 and batch: 750, loss is 3.7545101165771486 and perplexity is 42.71329015164377
At time: 756.9798746109009 and batch: 800, loss is 3.72986074924469 and perplexity is 41.6733047208131
At time: 758.0355010032654 and batch: 850, loss is 3.7331076002120973 and perplexity is 41.808831629337135
At time: 759.0909910202026 and batch: 900, loss is 3.7115018224716185 and perplexity is 40.915207787038995
At time: 760.1478397846222 and batch: 950, loss is 3.8211697816848753 and perplexity is 45.65758650281868
At time: 761.2052094936371 and batch: 1000, loss is 3.782187232971191 and perplexity is 43.91198251089034
At time: 762.2884321212769 and batch: 1050, loss is 3.7249804878234865 and perplexity is 41.470423558711715
At time: 763.3480606079102 and batch: 1100, loss is 3.7416277503967286 and perplexity is 42.16657098627649
At time: 764.4048252105713 and batch: 1150, loss is 3.716203627586365 and perplexity is 41.108036085585844
At time: 765.4631361961365 and batch: 1200, loss is 3.771139392852783 and perplexity is 43.42951994072508
At time: 766.5197193622589 and batch: 1250, loss is 3.7469171571731565 and perplexity is 42.39019803842961
At time: 767.5768232345581 and batch: 1300, loss is 3.7551351833343505 and perplexity is 42.739997155368826
At time: 768.633044719696 and batch: 1350, loss is 3.6343589544296266 and perplexity is 37.87756386825245
At time: 769.6891620159149 and batch: 1400, loss is 3.6566173887252806 and perplexity is 38.73011213120487
At time: 770.7447018623352 and batch: 1450, loss is 3.57122266292572 and perplexity is 35.56004453110526
At time: 771.7981927394867 and batch: 1500, loss is 3.5915335607528687 and perplexity is 36.28968571282806
At time: 772.8529486656189 and batch: 1550, loss is 3.588979878425598 and perplexity is 36.19713161094585
At time: 773.909255027771 and batch: 1600, loss is 3.693480062484741 and perplexity is 40.18444829669131
At time: 774.9662387371063 and batch: 1650, loss is 3.6293976354599 and perplexity is 37.69010659428719
At time: 776.0233328342438 and batch: 1700, loss is 3.6505527973175047 and perplexity is 38.49594062093729
At time: 777.0796904563904 and batch: 1750, loss is 3.637678837776184 and perplexity is 38.00352192909258
At time: 778.1372480392456 and batch: 1800, loss is 3.6063108539581297 and perplexity is 36.82993088861241
At time: 779.1946680545807 and batch: 1850, loss is 3.618101944923401 and perplexity is 37.2667662757742
At time: 780.2522640228271 and batch: 1900, loss is 3.7053874635696413 and perplexity is 40.66580078106791
At time: 781.3086018562317 and batch: 1950, loss is 3.6500088787078857 and perplexity is 38.47500765586948
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.275790902071221 and perplexity of 71.93701194809786
finished 18 epochs...
Completing Train Step...
At time: 784.6488382816315 and batch: 50, loss is 3.817470045089722 and perplexity is 45.488977555860764
At time: 785.6766340732574 and batch: 100, loss is 3.804497690200806 and perplexity is 44.90268938636182
At time: 786.7035212516785 and batch: 150, loss is 3.777215657234192 and perplexity is 43.69421254256467
At time: 787.7296583652496 and batch: 200, loss is 3.773675560951233 and perplexity is 43.5398042944458
At time: 788.7698788642883 and batch: 250, loss is 3.7659992218017577 and perplexity is 43.20685753125489
At time: 789.8017287254333 and batch: 300, loss is 3.7638145685195923 and perplexity is 43.112568559993605
At time: 790.8375706672668 and batch: 350, loss is 3.78405818939209 and perplexity is 43.99421682094041
At time: 791.8774635791779 and batch: 400, loss is 3.7448834133148194 and perplexity is 42.304074839463354
At time: 792.918210029602 and batch: 450, loss is 3.782995352745056 and perplexity is 43.94748299465646
At time: 793.9620840549469 and batch: 500, loss is 3.782495265007019 and perplexity is 43.925510891740785
At time: 795.0071494579315 and batch: 550, loss is 3.7654573106765747 and perplexity is 43.18344959755719
At time: 796.05015873909 and batch: 600, loss is 3.735622410774231 and perplexity is 41.914105236817484
At time: 797.102032661438 and batch: 650, loss is 3.770320429801941 and perplexity is 43.39396732870272
At time: 798.1597714424133 and batch: 700, loss is 3.7905619859695436 and perplexity is 44.28127874202063
At time: 799.2187294960022 and batch: 750, loss is 3.7498361539840697 and perplexity is 42.514115660903066
At time: 800.2779445648193 and batch: 800, loss is 3.725318627357483 and perplexity is 41.48444871950553
At time: 801.344489812851 and batch: 850, loss is 3.7286152839660645 and perplexity is 41.621434374800266
At time: 802.3991558551788 and batch: 900, loss is 3.7071312189102175 and perplexity is 40.73677385020899
At time: 803.4531245231628 and batch: 950, loss is 3.816924967765808 and perplexity is 45.464189302078296
At time: 804.5067653656006 and batch: 1000, loss is 3.7780144119262697 and perplexity is 43.72912744221331
At time: 805.5608701705933 and batch: 1050, loss is 3.7210556745529173 and perplexity is 41.307978881032625
At time: 806.6181480884552 and batch: 1100, loss is 3.7379622983932497 and perplexity is 42.012294363685115
At time: 807.6770222187042 and batch: 1150, loss is 3.71278489112854 and perplexity is 40.96773850079151
At time: 808.7354736328125 and batch: 1200, loss is 3.767879638671875 and perplexity is 43.28818087198929
At time: 809.793030500412 and batch: 1250, loss is 3.744225249290466 and perplexity is 42.27624097994772
At time: 810.8500714302063 and batch: 1300, loss is 3.7526269435882567 and perplexity is 42.63292932777882
At time: 811.9069137573242 and batch: 1350, loss is 3.6321176862716675 and perplexity is 37.79276515427953
At time: 812.9634318351746 and batch: 1400, loss is 3.654776120185852 and perplexity is 38.6588652066983
At time: 814.0497028827667 and batch: 1450, loss is 3.5697008848190306 and perplexity is 35.50597118811497
At time: 815.1078777313232 and batch: 1500, loss is 3.5902185249328613 and perplexity is 36.241994840694176
At time: 816.1718013286591 and batch: 1550, loss is 3.5879686164855955 and perplexity is 36.160545331684226
At time: 817.2365539073944 and batch: 1600, loss is 3.6927175235748293 and perplexity is 40.153817771259696
At time: 818.2904839515686 and batch: 1650, loss is 3.628741364479065 and perplexity is 37.66537978569571
At time: 819.3444976806641 and batch: 1700, loss is 3.65020067691803 and perplexity is 38.48238780119988
At time: 820.3993186950684 and batch: 1750, loss is 3.6374649095535276 and perplexity is 37.995392772750584
At time: 821.4540629386902 and batch: 1800, loss is 3.6063545083999635 and perplexity is 36.83153871378223
At time: 822.519445180893 and batch: 1850, loss is 3.6182353830337526 and perplexity is 37.27173941444069
At time: 823.6084277629852 and batch: 1900, loss is 3.70558575630188 and perplexity is 40.6738653133561
At time: 824.6664249897003 and batch: 1950, loss is 3.649859232902527 and perplexity is 38.46925046314325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.275945902979651 and perplexity of 71.9481631144977
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 827.9997608661652 and batch: 50, loss is 3.8174196815490724 and perplexity is 45.48668662758064
At time: 829.0282645225525 and batch: 100, loss is 3.8104113960266113 and perplexity is 45.16901739877326
At time: 830.0587360858917 and batch: 150, loss is 3.7881142568588255 and perplexity is 44.17302271175254
At time: 831.0882923603058 and batch: 200, loss is 3.7877477312088015 and perplexity is 44.15683513265228
At time: 832.1171579360962 and batch: 250, loss is 3.7814261674880982 and perplexity is 43.87857533084544
At time: 833.1510083675385 and batch: 300, loss is 3.776670117378235 and perplexity is 43.67038210896472
At time: 834.1956212520599 and batch: 350, loss is 3.799255356788635 and perplexity is 44.6679104499107
At time: 835.2392945289612 and batch: 400, loss is 3.762978405952454 and perplexity is 43.07653451125138
At time: 836.2843420505524 and batch: 450, loss is 3.8054447555541993 and perplexity is 44.945235311459555
At time: 837.3285167217255 and batch: 500, loss is 3.807542657852173 and perplexity is 45.039624999455164
At time: 838.3731873035431 and batch: 550, loss is 3.79251344203949 and perplexity is 44.36777608263713
At time: 839.4199030399323 and batch: 600, loss is 3.7591418552398683 and perplexity is 42.91158582140824
At time: 840.4746849536896 and batch: 650, loss is 3.7898651218414305 and perplexity is 44.25043145674995
At time: 841.5432291030884 and batch: 700, loss is 3.814438672065735 and perplexity is 45.35129228954526
At time: 842.597583770752 and batch: 750, loss is 3.770365915298462 and perplexity is 43.395941169742905
At time: 843.6562511920929 and batch: 800, loss is 3.740980362892151 and perplexity is 42.13928170943061
At time: 844.7152090072632 and batch: 850, loss is 3.737965865135193 and perplexity is 42.01244421096478
At time: 845.798930644989 and batch: 900, loss is 3.710599603652954 and perplexity is 40.878309964061984
At time: 846.8596694469452 and batch: 950, loss is 3.820712456703186 and perplexity is 45.636710921733496
At time: 847.9189863204956 and batch: 1000, loss is 3.7826397132873537 and perplexity is 43.93185631453359
At time: 848.9767069816589 and batch: 1050, loss is 3.7293649387359618 and perplexity is 41.652647779786484
At time: 850.035108089447 and batch: 1100, loss is 3.7454098653793335 and perplexity is 42.32635177035357
At time: 851.0937900543213 and batch: 1150, loss is 3.720118312835693 and perplexity is 41.26927650491032
At time: 852.1538529396057 and batch: 1200, loss is 3.773373966217041 and perplexity is 43.52667489872067
At time: 853.2132041454315 and batch: 1250, loss is 3.7474024391174314 and perplexity is 42.41077422837482
At time: 854.2724478244781 and batch: 1300, loss is 3.7543794298171997 and perplexity is 42.70770845488197
At time: 855.3323254585266 and batch: 1350, loss is 3.629870491027832 and perplexity is 37.70793278532095
At time: 856.3910555839539 and batch: 1400, loss is 3.6532106399536133 and perplexity is 38.59839286389517
At time: 857.4503099918365 and batch: 1450, loss is 3.563671827316284 and perplexity is 35.29254766396748
At time: 858.5096487998962 and batch: 1500, loss is 3.5807844591140747 and perplexity is 35.901693213881046
At time: 859.5694856643677 and batch: 1550, loss is 3.5796121168136597 and perplexity is 35.85962880203229
At time: 860.6276824474335 and batch: 1600, loss is 3.682342071533203 and perplexity is 39.73935758462734
At time: 861.7022330760956 and batch: 1650, loss is 3.621712245941162 and perplexity is 37.40155368514428
At time: 862.7608821392059 and batch: 1700, loss is 3.641763381958008 and perplexity is 38.159066441441134
At time: 863.8182573318481 and batch: 1750, loss is 3.628823652267456 and perplexity is 37.668479314022115
At time: 864.9017932415009 and batch: 1800, loss is 3.596155562400818 and perplexity is 36.45780492433993
At time: 865.9625000953674 and batch: 1850, loss is 3.6055997085571287 and perplexity is 36.80374876339418
At time: 867.0317676067352 and batch: 1900, loss is 3.6959082221984865 and perplexity is 40.28214111404673
At time: 868.107100725174 and batch: 1950, loss is 3.6455527210235594 and perplexity is 38.30393839373441
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.271897710755814 and perplexity of 71.65749186356365
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd78797ab38>
ELAPSED
3583.453716993332


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.58572924558682}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.5545691141662139, 'dropout': 0.7795352401135597, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.01716348977908}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.30559750332649016, 'dropout': 0.7036453025474743, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -69.20731299479563}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.2784456490206031, 'dropout': 0.9440744352266794, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -71.65749186356365}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.7972956216277209, 'dropout': 0.16004583408284256, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.596698522567749 and batch: 50, loss is 7.661144599914551 and perplexity is 2124.1873823470655
At time: 2.761528730392456 and batch: 100, loss is 6.915326881408691 and perplexity is 1007.600339490963
At time: 3.912702798843384 and batch: 150, loss is 6.484669637680054 and perplexity is 655.0225337269462
At time: 5.06349778175354 and batch: 200, loss is 6.38764817237854 and perplexity is 594.4568743035287
At time: 6.2218544483184814 and batch: 250, loss is 6.267800960540772 and perplexity is 527.3165121330217
At time: 7.386216640472412 and batch: 300, loss is 6.201246490478516 and perplexity is 493.36363104196045
At time: 8.538162469863892 and batch: 350, loss is 6.104556789398194 and perplexity is 447.8940860502777
At time: 9.690185546875 and batch: 400, loss is 6.0390410900115965 and perplexity is 419.49058824734976
At time: 10.842602968215942 and batch: 450, loss is 5.946491174697876 and perplexity is 382.40917523236135
At time: 11.9959876537323 and batch: 500, loss is 5.90745177268982 and perplexity is 367.76780438832265
At time: 13.14931035041809 and batch: 550, loss is 5.841949663162231 and perplexity is 344.45024839091604
At time: 14.302389144897461 and batch: 600, loss is 5.865126390457153 and perplexity is 352.52670930404764
At time: 15.451047420501709 and batch: 650, loss is 5.921593942642212 and perplexity is 373.0057901233418
At time: 16.599594593048096 and batch: 700, loss is 5.838333301544189 and perplexity is 343.2068413930948
At time: 17.758400201797485 and batch: 750, loss is 5.772162771224975 and perplexity is 321.23173264313544
At time: 18.913742065429688 and batch: 800, loss is 5.771611919403076 and perplexity is 321.0548302859234
At time: 20.066373109817505 and batch: 850, loss is 5.793248834609986 and perplexity is 328.0771632771336
At time: 21.220232248306274 and batch: 900, loss is 5.780703868865967 and perplexity is 323.98715465049946
At time: 22.37220072746277 and batch: 950, loss is 5.7994293594360355 and perplexity is 330.11113135010754
At time: 23.524117946624756 and batch: 1000, loss is 5.780340013504028 and perplexity is 323.8692916309268
At time: 24.67784547805786 and batch: 1050, loss is 5.675026903152466 and perplexity is 291.49618060602137
At time: 25.831622838974 and batch: 1100, loss is 5.751399440765381 and perplexity is 314.63065930827526
At time: 26.991966485977173 and batch: 1150, loss is 5.651117267608643 and perplexity is 284.6092729748578
At time: 28.156750202178955 and batch: 1200, loss is 5.714580383300781 and perplexity is 303.2569249373523
At time: 29.320823431015015 and batch: 1250, loss is 5.667940368652344 and perplexity is 289.4377849257071
At time: 30.48573350906372 and batch: 1300, loss is 5.672273225784302 and perplexity is 290.69459832658697
At time: 31.681301593780518 and batch: 1350, loss is 5.628714771270752 and perplexity is 278.30420312397695
At time: 32.93039798736572 and batch: 1400, loss is 5.646957311630249 and perplexity is 283.4277701319951
At time: 34.205273389816284 and batch: 1450, loss is 5.607485713958741 and perplexity is 272.45833789575994
At time: 35.48482537269592 and batch: 1500, loss is 5.571328945159912 and perplexity is 262.7830916107583
At time: 36.76551866531372 and batch: 1550, loss is 5.5551560115814205 and perplexity is 258.5673008675353
At time: 38.04240345954895 and batch: 1600, loss is 5.577618703842163 and perplexity is 264.4411427473464
At time: 39.319244146347046 and batch: 1650, loss is 5.574822797775268 and perplexity is 263.7028227696144
At time: 40.596587896347046 and batch: 1700, loss is 5.592787246704102 and perplexity is 268.4829058889398
At time: 41.87414002418518 and batch: 1750, loss is 5.598700618743896 and perplexity is 270.0752486151838
At time: 43.1507785320282 and batch: 1800, loss is 5.5934234237670895 and perplexity is 268.653762897363
At time: 44.426228046417236 and batch: 1850, loss is 5.567057361602783 and perplexity is 261.6629856937113
At time: 45.70239615440369 and batch: 1900, loss is 5.5730122947692875 and perplexity is 263.2258199541182
At time: 46.97876024246216 and batch: 1950, loss is 5.49502968788147 and perplexity is 243.47875442177508
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.112883244004361 and perplexity of 166.14871221019501
finished 1 epochs...
Completing Train Step...
At time: 50.479246616363525 and batch: 50, loss is 5.347288379669189 and perplexity is 210.0379817142344
At time: 51.55650186538696 and batch: 100, loss is 5.284455766677857 and perplexity is 197.24680594711776
At time: 52.634039878845215 and batch: 150, loss is 5.193091478347778 and perplexity is 180.02423457364512
At time: 53.71151041984558 and batch: 200, loss is 5.152512426376343 and perplexity is 172.8652564157612
At time: 54.789812326431274 and batch: 250, loss is 5.16438060760498 and perplexity is 174.929075270476
At time: 55.866963386535645 and batch: 300, loss is 5.165617656707764 and perplexity is 175.14560502744817
At time: 56.99136185646057 and batch: 350, loss is 5.1450941944122315 and perplexity is 171.58764650738183
At time: 58.08617830276489 and batch: 400, loss is 5.098790807723999 and perplexity is 163.8236931401667
At time: 59.16428589820862 and batch: 450, loss is 5.047456636428833 and perplexity is 155.6261468375102
At time: 60.25696063041687 and batch: 500, loss is 5.038683910369873 and perplexity is 154.26685236041297
At time: 61.333112716674805 and batch: 550, loss is 4.985471830368042 and perplexity is 146.27257458953548
At time: 62.409228563308716 and batch: 600, loss is 4.967979412078858 and perplexity is 143.7361621987776
At time: 63.51349711418152 and batch: 650, loss is 5.036660270690918 and perplexity is 153.9549874943147
At time: 64.59000134468079 and batch: 700, loss is 5.015696382522583 and perplexity is 150.7610876052042
At time: 65.6669659614563 and batch: 750, loss is 4.97597601890564 and perplexity is 144.89017170533
At time: 66.74369311332703 and batch: 800, loss is 4.955919675827026 and perplexity is 142.0131523971251
At time: 67.82268118858337 and batch: 850, loss is 4.94820164680481 and perplexity is 140.9213096223988
At time: 68.90235018730164 and batch: 900, loss is 4.945075063705445 and perplexity is 140.48139550977362
At time: 69.9801230430603 and batch: 950, loss is 4.999077081680298 and perplexity is 148.2762490672639
At time: 71.05865740776062 and batch: 1000, loss is 4.964909811019897 and perplexity is 143.29562600417682
At time: 72.14120078086853 and batch: 1050, loss is 4.873193740844727 and perplexity is 130.7377934752073
At time: 73.22599220275879 and batch: 1100, loss is 4.941600208282471 and perplexity is 139.99409011898499
At time: 74.30990743637085 and batch: 1150, loss is 4.854900569915771 and perplexity is 128.36792694636594
At time: 75.39454054832458 and batch: 1200, loss is 4.939483137130737 and perplexity is 139.69802617417884
At time: 76.48066639900208 and batch: 1250, loss is 4.883340826034546 and perplexity is 132.0711544261199
At time: 77.60703563690186 and batch: 1300, loss is 4.915424308776855 and perplexity is 136.3771635552082
At time: 78.72221970558167 and batch: 1350, loss is 4.822227563858032 and perplexity is 124.24153872411523
At time: 79.81341338157654 and batch: 1400, loss is 4.83281533241272 and perplexity is 125.56396781380867
At time: 80.89928245544434 and batch: 1450, loss is 4.781911134719849 and perplexity is 119.3321921526027
At time: 81.98366832733154 and batch: 1500, loss is 4.755094575881958 and perplexity is 116.17463996388354
At time: 83.07180047035217 and batch: 1550, loss is 4.753157453536987 and perplexity is 115.94981330157036
At time: 84.15750789642334 and batch: 1600, loss is 4.803319625854492 and perplexity is 121.91445690107017
At time: 85.24474048614502 and batch: 1650, loss is 4.777088432312012 and perplexity is 118.7580740153954
At time: 86.33161354064941 and batch: 1700, loss is 4.806782283782959 and perplexity is 122.33733668334156
At time: 87.43725204467773 and batch: 1750, loss is 4.803921594619751 and perplexity is 121.98786768944211
At time: 88.52309560775757 and batch: 1800, loss is 4.763441514968872 and perplexity is 117.14840091517894
At time: 89.61042141914368 and batch: 1850, loss is 4.764378595352173 and perplexity is 117.25822983483772
At time: 90.71891522407532 and batch: 1900, loss is 4.836367216110229 and perplexity is 126.01074941250782
At time: 91.82347226142883 and batch: 1950, loss is 4.754762239456177 and perplexity is 116.13603731416019
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607957281068314 and perplexity of 100.27909826405437
finished 2 epochs...
Completing Train Step...
At time: 95.26547837257385 and batch: 50, loss is 4.731457166671753 and perplexity is 113.46077320681681
At time: 96.36615228652954 and batch: 100, loss is 4.681634578704834 and perplexity is 107.94637528812281
At time: 97.45190834999084 and batch: 150, loss is 4.632308387756348 and perplexity is 102.75097966221564
At time: 98.53676128387451 and batch: 200, loss is 4.6259660720825195 and perplexity is 102.10136272879905
At time: 99.62169075012207 and batch: 250, loss is 4.634010381698609 and perplexity is 102.9260101152954
At time: 100.72653150558472 and batch: 300, loss is 4.652707090377808 and perplexity is 104.86849014834684
At time: 101.85032153129578 and batch: 350, loss is 4.658174266815186 and perplexity is 105.44339480732006
At time: 102.9404227733612 and batch: 400, loss is 4.618738851547241 and perplexity is 101.36611376693818
At time: 104.01783204078674 and batch: 450, loss is 4.61164101600647 and perplexity is 100.64918110694664
At time: 105.09501147270203 and batch: 500, loss is 4.614415969848633 and perplexity is 100.92886581537512
At time: 106.17286252975464 and batch: 550, loss is 4.572401151657105 and perplexity is 96.77620535884708
At time: 107.2493224143982 and batch: 600, loss is 4.5555799770355225 and perplexity is 95.16193096832001
At time: 108.32435894012451 and batch: 650, loss is 4.619426307678222 and perplexity is 101.43582248141723
At time: 109.400634765625 and batch: 700, loss is 4.630238313674926 and perplexity is 102.53849752513605
At time: 110.47723245620728 and batch: 750, loss is 4.595700311660766 and perplexity is 99.05748237263036
At time: 111.55478978157043 and batch: 800, loss is 4.573194818496704 and perplexity is 96.85304391197504
At time: 112.63390827178955 and batch: 850, loss is 4.564176177978515 and perplexity is 95.9834881251985
At time: 113.75078749656677 and batch: 900, loss is 4.559797601699829 and perplexity is 95.56413585388425
At time: 114.82570505142212 and batch: 950, loss is 4.631905374526977 and perplexity is 102.70957800134984
At time: 115.90407252311707 and batch: 1000, loss is 4.609233617782593 and perplexity is 100.40716987270552
At time: 116.99014401435852 and batch: 1050, loss is 4.53113865852356 and perplexity is 92.86424156389342
At time: 118.07424783706665 and batch: 1100, loss is 4.587752151489258 and perplexity is 98.27327825490293
At time: 119.16549968719482 and batch: 1150, loss is 4.532705631256103 and perplexity is 93.00987136741965
At time: 120.25083875656128 and batch: 1200, loss is 4.606106147766114 and perplexity is 100.09363999269334
At time: 121.33603429794312 and batch: 1250, loss is 4.57425332069397 and perplexity is 96.95561734929494
At time: 122.4215681552887 and batch: 1300, loss is 4.594791402816773 and perplexity is 98.96748905489471
At time: 123.50737595558167 and batch: 1350, loss is 4.488402938842773 and perplexity is 88.97922707546181
At time: 124.59158968925476 and batch: 1400, loss is 4.505068244934082 and perplexity is 90.4745182657224
At time: 125.67822623252869 and batch: 1450, loss is 4.447988576889038 and perplexity is 85.454885087762
At time: 126.76290392875671 and batch: 1500, loss is 4.443007488250732 and perplexity is 85.03028509357115
At time: 127.85015749931335 and batch: 1550, loss is 4.447232570648193 and perplexity is 85.39030507584683
At time: 128.93673086166382 and batch: 1600, loss is 4.514702911376953 and perplexity is 91.35042281928936
At time: 130.0209300518036 and batch: 1650, loss is 4.475545291900635 and perplexity is 87.84248714921672
At time: 131.1125407218933 and batch: 1700, loss is 4.503920373916626 and perplexity is 90.37072477055585
At time: 132.1993806362152 and batch: 1750, loss is 4.501163320541382 and perplexity is 90.12191101281914
At time: 133.28822565078735 and batch: 1800, loss is 4.456601362228394 and perplexity is 86.19406831306212
At time: 134.38051843643188 and batch: 1850, loss is 4.482631683349609 and perplexity is 88.46718420876218
At time: 135.46830534934998 and batch: 1900, loss is 4.566291007995606 and perplexity is 96.18669168178548
At time: 136.55931162834167 and batch: 1950, loss is 4.48962327003479 and perplexity is 89.08787748296061
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4748625999273255 and perplexity of 87.78253825396759
finished 3 epochs...
Completing Train Step...
At time: 140.09969115257263 and batch: 50, loss is 4.479873418807983 and perplexity is 88.22350453246035
At time: 141.21304941177368 and batch: 100, loss is 4.430455923080444 and perplexity is 83.96969190497636
At time: 142.27116632461548 and batch: 150, loss is 4.386154003143311 and perplexity is 80.3308718228141
At time: 143.35178184509277 and batch: 200, loss is 4.385411987304687 and perplexity is 80.27128715270949
At time: 144.4478464126587 and batch: 250, loss is 4.385779037475586 and perplexity is 80.30075615034657
At time: 145.51829767227173 and batch: 300, loss is 4.410124940872192 and perplexity is 82.27974296487571
At time: 146.59104657173157 and batch: 350, loss is 4.417896070480347 and perplexity is 82.92164041535275
At time: 147.6733956336975 and batch: 400, loss is 4.376888999938965 and perplexity is 79.59004322702857
At time: 148.74210166931152 and batch: 450, loss is 4.387885189056396 and perplexity is 80.47005994199293
At time: 149.8017077445984 and batch: 500, loss is 4.399300899505615 and perplexity is 81.39394622198874
At time: 150.88475823402405 and batch: 550, loss is 4.357520418167114 and perplexity is 78.06332983074604
At time: 151.96469807624817 and batch: 600, loss is 4.345466961860657 and perplexity is 77.12804492696338
At time: 153.03220057487488 and batch: 650, loss is 4.398309440612793 and perplexity is 81.31328746171485
At time: 154.09900069236755 and batch: 700, loss is 4.421067266464234 and perplexity is 83.18501857958208
At time: 155.16371846199036 and batch: 750, loss is 4.390724954605102 and perplexity is 80.69890081935216
At time: 156.23407077789307 and batch: 800, loss is 4.365750055313111 and perplexity is 78.70841347101513
At time: 157.30177664756775 and batch: 850, loss is 4.363474197387696 and perplexity is 78.52948798614081
At time: 158.384996175766 and batch: 900, loss is 4.348978033065796 and perplexity is 77.39932294414817
At time: 159.4691607952118 and batch: 950, loss is 4.429196062088013 and perplexity is 83.86396837805673
At time: 160.55528473854065 and batch: 1000, loss is 4.407108030319214 and perplexity is 82.03188640855281
At time: 161.65318894386292 and batch: 1050, loss is 4.339390335083007 and perplexity is 76.6607876955585
At time: 162.7405834197998 and batch: 1100, loss is 4.392013893127442 and perplexity is 80.80298380520372
At time: 163.83314776420593 and batch: 1150, loss is 4.34530104637146 and perplexity is 77.11524925118825
At time: 164.91899061203003 and batch: 1200, loss is 4.421133422851563 and perplexity is 83.19052198193181
At time: 166.005220413208 and batch: 1250, loss is 4.394068489074707 and perplexity is 80.96917195454415
At time: 167.09077715873718 and batch: 1300, loss is 4.405607118606567 and perplexity is 81.90885614131247
At time: 168.1755940914154 and batch: 1350, loss is 4.291776657104492 and perplexity is 73.09622012222323
At time: 169.2606384754181 and batch: 1400, loss is 4.317033863067627 and perplexity is 74.96593895155802
At time: 170.34819841384888 and batch: 1450, loss is 4.260437369346619 and perplexity is 70.84096034415128
At time: 171.43530011177063 and batch: 1500, loss is 4.26469211101532 and perplexity is 71.14301245115496
At time: 172.5189757347107 and batch: 1550, loss is 4.263016529083252 and perplexity is 71.02390631880725
At time: 173.60500359535217 and batch: 1600, loss is 4.337243404388428 and perplexity is 76.49637884773612
At time: 174.69127583503723 and batch: 1650, loss is 4.299698395729065 and perplexity is 73.67756887876787
At time: 175.77600288391113 and batch: 1700, loss is 4.331573333740234 and perplexity is 76.06386632238772
At time: 176.86262559890747 and batch: 1750, loss is 4.32519495010376 and perplexity is 75.58024580034677
At time: 177.94832849502563 and batch: 1800, loss is 4.280015144348145 and perplexity is 72.24153404998322
At time: 179.03163194656372 and batch: 1850, loss is 4.312318363189697 and perplexity is 74.61326923607818
At time: 180.12011170387268 and batch: 1900, loss is 4.393329772949219 and perplexity is 80.90938080861477
At time: 181.21791648864746 and batch: 1950, loss is 4.321322584152222 and perplexity is 75.28813737028905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.411207757994186 and perplexity of 82.36888513297437
finished 4 epochs...
Completing Train Step...
At time: 184.76906871795654 and batch: 50, loss is 4.315792984962464 and perplexity is 74.87297305088428
At time: 185.84902262687683 and batch: 100, loss is 4.273382997512817 and perplexity is 71.7640028673794
At time: 186.89417386054993 and batch: 150, loss is 4.230880146026611 and perplexity is 68.77773999665784
At time: 187.9399869441986 and batch: 200, loss is 4.233947553634644 and perplexity is 68.98903325518992
At time: 188.9841251373291 and batch: 250, loss is 4.225789771080017 and perplexity is 68.42852508358641
At time: 190.02967166900635 and batch: 300, loss is 4.250013279914856 and perplexity is 70.10634334677654
At time: 191.09527111053467 and batch: 350, loss is 4.254535808563232 and perplexity is 70.42411932685255
At time: 192.16885471343994 and batch: 400, loss is 4.219172968864441 and perplexity is 67.97724174002721
At time: 193.21672987937927 and batch: 450, loss is 4.240713629722595 and perplexity is 69.45740102259116
At time: 194.27694296836853 and batch: 500, loss is 4.253796896934509 and perplexity is 70.37210134685131
At time: 195.4659218788147 and batch: 550, loss is 4.216837854385376 and perplexity is 67.81869228620015
At time: 196.5267732143402 and batch: 600, loss is 4.203311185836792 and perplexity is 66.90750785245744
At time: 197.60356259346008 and batch: 650, loss is 4.251737003326416 and perplexity is 70.22729150273928
At time: 198.68001794815063 and batch: 700, loss is 4.280896258354187 and perplexity is 72.30521512847778
At time: 199.77565550804138 and batch: 750, loss is 4.251895928382874 and perplexity is 70.23845326592466
At time: 200.84857273101807 and batch: 800, loss is 4.2228222703933715 and perplexity is 68.22576438346668
At time: 201.94843244552612 and batch: 850, loss is 4.220392451286316 and perplexity is 68.06018935771807
At time: 203.02553486824036 and batch: 900, loss is 4.206222591400146 and perplexity is 67.10258658190314
At time: 204.1253879070282 and batch: 950, loss is 4.294463911056519 and perplexity is 73.29291239129854
At time: 205.21016097068787 and batch: 1000, loss is 4.265272245407105 and perplexity is 71.18429693352923
At time: 206.29047679901123 and batch: 1050, loss is 4.210679836273194 and perplexity is 67.40234679797803
At time: 207.4058277606964 and batch: 1100, loss is 4.2569472599029545 and perplexity is 70.59414859000455
At time: 208.51152658462524 and batch: 1150, loss is 4.211849803924561 and perplexity is 67.48125151233899
At time: 209.61969590187073 and batch: 1200, loss is 4.287945384979248 and perplexity is 72.81670440390761
At time: 210.69647240638733 and batch: 1250, loss is 4.266441297531128 and perplexity is 71.26756374919707
At time: 211.77166533470154 and batch: 1300, loss is 4.274953947067261 and perplexity is 71.87682909466129
At time: 212.8487560749054 and batch: 1350, loss is 4.160686368942261 and perplexity is 64.11551439870773
At time: 213.9458246231079 and batch: 1400, loss is 4.190503945350647 and perplexity is 66.0560712239639
At time: 215.02290105819702 and batch: 1450, loss is 4.131285929679871 and perplexity is 62.25793080251604
At time: 216.0993993282318 and batch: 1500, loss is 4.136115097999573 and perplexity is 62.55931195404675
At time: 217.17650270462036 and batch: 1550, loss is 4.13685311794281 and perplexity is 62.605499015293745
At time: 218.27578949928284 and batch: 1600, loss is 4.212180924415589 and perplexity is 67.50359963723179
At time: 219.39308643341064 and batch: 1650, loss is 4.173237504959107 and perplexity is 64.92530822634502
At time: 220.4692153930664 and batch: 1700, loss is 4.203756084442139 and perplexity is 66.93728153203136
At time: 221.54566311836243 and batch: 1750, loss is 4.197464551925659 and perplexity is 66.51746547670002
At time: 222.62423157691956 and batch: 1800, loss is 4.15712682723999 and perplexity is 63.88769825252162
At time: 223.70989084243774 and batch: 1850, loss is 4.189510917663574 and perplexity is 65.99050827463883
At time: 224.7877595424652 and batch: 1900, loss is 4.267502918243408 and perplexity is 71.34326304584788
At time: 225.8963234424591 and batch: 1950, loss is 4.199642062187195 and perplexity is 66.66246575284767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3848170080850295 and perplexity of 80.22354161012977
finished 5 epochs...
Completing Train Step...
At time: 229.38101243972778 and batch: 50, loss is 4.198272194862366 and perplexity is 66.57120953794424
At time: 230.412118434906 and batch: 100, loss is 4.162018957138062 and perplexity is 64.20101092954505
At time: 231.44770884513855 and batch: 150, loss is 4.118352966308594 and perplexity is 61.457935569073165
At time: 232.50380396842957 and batch: 200, loss is 4.119229736328125 and perplexity is 61.511843673493935
At time: 233.55935645103455 and batch: 250, loss is 4.114660778045654 and perplexity is 61.231439690716435
At time: 234.61017227172852 and batch: 300, loss is 4.129408092498779 and perplexity is 62.14113024577389
At time: 235.66223001480103 and batch: 350, loss is 4.133113403320312 and perplexity is 62.371809553480816
At time: 236.7127504348755 and batch: 400, loss is 4.103732991218567 and perplexity is 60.565958312423255
At time: 237.76789140701294 and batch: 450, loss is 4.129871044158936 and perplexity is 62.169905245388165
At time: 238.82842016220093 and batch: 500, loss is 4.145967206954956 and perplexity is 63.178699237079016
At time: 239.8902018070221 and batch: 550, loss is 4.114503479003906 and perplexity is 61.22180880141289
At time: 240.9663417339325 and batch: 600, loss is 4.106298723220825 and perplexity is 60.721553852784695
At time: 242.06363892555237 and batch: 650, loss is 4.142593340873718 and perplexity is 62.96590194330758
At time: 243.17441749572754 and batch: 700, loss is 4.173008246421814 and perplexity is 64.9104252512375
At time: 244.2544982433319 and batch: 750, loss is 4.148973870277405 and perplexity is 63.368942169742446
At time: 245.3346028327942 and batch: 800, loss is 4.119018840789795 and perplexity is 61.49887246794147
At time: 246.41368675231934 and batch: 850, loss is 4.1172205305099485 and perplexity is 61.38837779501409
At time: 247.48871445655823 and batch: 900, loss is 4.099669213294983 and perplexity is 60.32033113329633
At time: 248.6254734992981 and batch: 950, loss is 4.189707770347595 and perplexity is 66.0034999619949
At time: 249.70609951019287 and batch: 1000, loss is 4.166184344291687 and perplexity is 64.46899072806174
At time: 250.7870454788208 and batch: 1050, loss is 4.106941080093383 and perplexity is 60.76057129043243
At time: 251.87100672721863 and batch: 1100, loss is 4.153291320800781 and perplexity is 63.64312590372463
At time: 252.96650505065918 and batch: 1150, loss is 4.116680645942688 and perplexity is 61.355244102222926
At time: 254.05674839019775 and batch: 1200, loss is 4.182171487808228 and perplexity is 65.5079485906917
At time: 255.12839674949646 and batch: 1250, loss is 4.168688011169434 and perplexity is 64.63060183055201
At time: 256.20015382766724 and batch: 1300, loss is 4.176712522506714 and perplexity is 65.15131727698817
At time: 257.27180337905884 and batch: 1350, loss is 4.0589038228988645 and perplexity is 57.91079578506582
At time: 258.3445394039154 and batch: 1400, loss is 4.0939721632003785 and perplexity is 59.97766021861121
At time: 259.41691541671753 and batch: 1450, loss is 4.033547778129577 and perplexity is 56.460866967133306
At time: 260.4879288673401 and batch: 1500, loss is 4.041963038444519 and perplexity is 56.93800466345997
At time: 261.55974817276 and batch: 1550, loss is 4.040912051200866 and perplexity is 56.878194981991136
At time: 262.63146710395813 and batch: 1600, loss is 4.118271942138672 and perplexity is 61.452956192586214
At time: 263.70295691490173 and batch: 1650, loss is 4.07564444065094 and perplexity is 58.88841845340414
At time: 264.77492809295654 and batch: 1700, loss is 4.113034782409668 and perplexity is 61.131958536873015
At time: 265.848105430603 and batch: 1750, loss is 4.103549704551697 and perplexity is 60.55485839706273
At time: 266.9426417350769 and batch: 1800, loss is 4.060745120048523 and perplexity is 58.01752499822296
At time: 268.01437306404114 and batch: 1850, loss is 4.096629137992859 and perplexity is 60.13723124414575
At time: 269.0855658054352 and batch: 1900, loss is 4.172855896949768 and perplexity is 64.90053693547917
At time: 270.1590299606323 and batch: 1950, loss is 4.105914235115051 and perplexity is 60.69821162525617
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3724280069040695 and perplexity of 79.23578336143657
finished 6 epochs...
Completing Train Step...
At time: 273.6149387359619 and batch: 50, loss is 4.105810408592224 and perplexity is 60.69190986815171
At time: 274.65365839004517 and batch: 100, loss is 4.07294385433197 and perplexity is 58.72959974452355
At time: 275.7209885120392 and batch: 150, loss is 4.033001751899719 and perplexity is 56.430046268029535
At time: 276.75596356391907 and batch: 200, loss is 4.035445332527161 and perplexity is 56.56810624754408
At time: 277.78975915908813 and batch: 250, loss is 4.026353235244751 and perplexity is 56.05611458847603
At time: 278.8553624153137 and batch: 300, loss is 4.0386777591705325 and perplexity is 56.75125434827417
At time: 279.9297614097595 and batch: 350, loss is 4.044685969352722 and perplexity is 57.09325418714992
At time: 280.9845507144928 and batch: 400, loss is 4.013369030952454 and perplexity is 55.33297539776682
At time: 282.06715631484985 and batch: 450, loss is 4.045732307434082 and perplexity is 57.1530242976129
At time: 283.1397399902344 and batch: 500, loss is 4.0593595743179325 and perplexity is 57.93719472764505
At time: 284.2023320198059 and batch: 550, loss is 4.035200843811035 and perplexity is 56.554277674407885
At time: 285.27545857429504 and batch: 600, loss is 4.026144313812256 and perplexity is 56.044404488004155
At time: 286.34515738487244 and batch: 650, loss is 4.063843789100647 and perplexity is 58.19758093021689
At time: 287.3987629413605 and batch: 700, loss is 4.089754457473755 and perplexity is 59.72522482096403
At time: 288.48214316368103 and batch: 750, loss is 4.066161680221557 and perplexity is 58.33263304389577
At time: 289.5565791130066 and batch: 800, loss is 4.032620978355408 and perplexity is 56.408563289640895
At time: 290.6372003555298 and batch: 850, loss is 4.035344395637512 and perplexity is 56.56239672700163
At time: 291.7146546840668 and batch: 900, loss is 4.017726678848266 and perplexity is 55.5746231470919
At time: 292.8102581501007 and batch: 950, loss is 4.108825063705444 and perplexity is 60.87515111036381
At time: 293.88344860076904 and batch: 1000, loss is 4.085802636146545 and perplexity is 59.48966715121219
At time: 294.95670652389526 and batch: 1050, loss is 4.028467545509338 and perplexity is 56.17475998933931
At time: 296.02861070632935 and batch: 1100, loss is 4.069451355934143 and perplexity is 58.524844473364965
At time: 297.10153126716614 and batch: 1150, loss is 4.037016701698303 and perplexity is 56.65706550138103
At time: 298.1761405467987 and batch: 1200, loss is 4.103201293945313 and perplexity is 60.53376411707792
At time: 299.2486369609833 and batch: 1250, loss is 4.091990795135498 and perplexity is 59.85894005106161
At time: 300.32221841812134 and batch: 1300, loss is 4.093523387908935 and perplexity is 59.950749765491395
At time: 301.4040253162384 and batch: 1350, loss is 3.9790445375442505 and perplexity is 53.46592513084339
At time: 302.49042439460754 and batch: 1400, loss is 4.014083838462829 and perplexity is 55.3725419637071
At time: 303.5627443790436 and batch: 1450, loss is 3.951313076019287 and perplexity is 52.00360671184341
At time: 304.63495802879333 and batch: 1500, loss is 3.968892936706543 and perplexity is 52.92590606711689
At time: 305.7304615974426 and batch: 1550, loss is 3.968813033103943 and perplexity is 52.92167726550176
At time: 306.8038923740387 and batch: 1600, loss is 4.0420663547515865 and perplexity is 56.943887591729585
At time: 307.885347366333 and batch: 1650, loss is 3.999181475639343 and perplexity is 54.55347840219849
At time: 308.99168825149536 and batch: 1700, loss is 4.038186864852905 and perplexity is 56.7234023167577
At time: 310.0719060897827 and batch: 1750, loss is 4.027492094039917 and perplexity is 56.11999095377418
At time: 311.13779878616333 and batch: 1800, loss is 3.984591236114502 and perplexity is 53.76330848680386
At time: 312.2009286880493 and batch: 1850, loss is 4.019548802375794 and perplexity is 55.67597928912422
At time: 313.26438069343567 and batch: 1900, loss is 4.100463671684265 and perplexity is 60.36827216746628
At time: 314.32850885391235 and batch: 1950, loss is 4.034959135055542 and perplexity is 56.54060966223903
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370380348382994 and perplexity of 79.07370153521157
finished 7 epochs...
Completing Train Step...
At time: 317.7261757850647 and batch: 50, loss is 4.029394636154175 and perplexity is 56.226863232284025
At time: 318.7551472187042 and batch: 100, loss is 4.003114099502564 and perplexity is 54.76843911596091
At time: 319.7838592529297 and batch: 150, loss is 3.962363739013672 and perplexity is 52.58146803894715
At time: 320.8121569156647 and batch: 200, loss is 3.9675787782669065 and perplexity is 52.85639872281829
At time: 321.8444676399231 and batch: 250, loss is 3.9573635816574098 and perplexity is 52.31920864026783
At time: 322.8834321498871 and batch: 300, loss is 3.9634374284744265 and perplexity is 52.637954526058
At time: 323.92878341674805 and batch: 350, loss is 3.9711234092712404 and perplexity is 53.04408759989845
At time: 324.97292017936707 and batch: 400, loss is 3.9420716047286986 and perplexity is 51.52523072700245
At time: 326.0179977416992 and batch: 450, loss is 3.9768981981277465 and perplexity is 53.35129217292055
At time: 327.07837867736816 and batch: 500, loss is 3.9912288045883177 and perplexity is 54.12135308649811
At time: 328.15883564949036 and batch: 550, loss is 3.965760140419006 and perplexity is 52.760359432411846
At time: 329.20437812805176 and batch: 600, loss is 3.9578603744506835 and perplexity is 52.345206903410286
At time: 330.2472538948059 and batch: 650, loss is 3.9978963422775267 and perplexity is 54.48341493719173
At time: 331.30470967292786 and batch: 700, loss is 4.022366018295288 and perplexity is 55.83305169386411
At time: 332.3663740158081 and batch: 750, loss is 4.000504755973816 and perplexity is 54.62571573192309
At time: 333.4503381252289 and batch: 800, loss is 3.96768262386322 and perplexity is 52.861887912071786
At time: 334.54341411590576 and batch: 850, loss is 3.9718604135513305 and perplexity is 53.08319572915215
At time: 335.6275100708008 and batch: 900, loss is 3.949246129989624 and perplexity is 51.8962290735426
At time: 336.6875698566437 and batch: 950, loss is 4.046343383789062 and perplexity is 57.1879598324293
At time: 337.77975034713745 and batch: 1000, loss is 4.0195783472061155 and perplexity is 55.67762425078526
At time: 338.8412170410156 and batch: 1050, loss is 3.964428505897522 and perplexity is 52.690148674335454
At time: 339.900084733963 and batch: 1100, loss is 4.00103485584259 and perplexity is 54.65468049309405
At time: 340.9933342933655 and batch: 1150, loss is 3.9690556001663206 and perplexity is 52.9345158783415
At time: 342.0567481517792 and batch: 1200, loss is 4.0361154794692995 and perplexity is 56.60602789608765
At time: 343.1157386302948 and batch: 1250, loss is 4.028649244308472 and perplexity is 56.18496780311666
At time: 344.1765732765198 and batch: 1300, loss is 4.028768100738525 and perplexity is 56.19164614468647
At time: 345.23615193367004 and batch: 1350, loss is 3.9130881690979002 and perplexity is 50.05328655790237
At time: 346.29640340805054 and batch: 1400, loss is 3.9480034923553466 and perplexity is 51.83178091736402
At time: 347.3719947338104 and batch: 1450, loss is 3.8883917236328127 and perplexity is 48.832287522237586
At time: 348.4647879600525 and batch: 1500, loss is 3.905840835571289 and perplexity is 49.69184502181888
At time: 349.52658224105835 and batch: 1550, loss is 3.905787453651428 and perplexity is 49.6891924465306
At time: 350.586199760437 and batch: 1600, loss is 3.9805885887145998 and perplexity is 53.54854302182704
At time: 351.64517402648926 and batch: 1650, loss is 3.9391246747970583 and perplexity is 51.37361299547966
At time: 352.7040503025055 and batch: 1700, loss is 3.9739893102645873 and perplexity is 53.196324747339666
At time: 353.76283955574036 and batch: 1750, loss is 3.965043387413025 and perplexity is 52.72255683537292
At time: 354.82141876220703 and batch: 1800, loss is 3.9209130954742433 and perplexity is 50.446486213006224
At time: 355.8793339729309 and batch: 1850, loss is 3.9628254652023314 and perplexity is 52.605751885591445
At time: 356.938285112381 and batch: 1900, loss is 4.0355110931396485 and perplexity is 56.57182632317408
At time: 357.99790239334106 and batch: 1950, loss is 3.9733046102523804 and perplexity is 53.159913689884036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3720353947129365 and perplexity of 79.20468053298923
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 361.36278653144836 and batch: 50, loss is 3.9964554929733276 and perplexity is 54.4049690745938
At time: 362.42750787734985 and batch: 100, loss is 3.9934761476516725 and perplexity is 54.24311910769919
At time: 363.456241607666 and batch: 150, loss is 3.9563202095031738 and perplexity is 52.2646487029502
At time: 364.49757719039917 and batch: 200, loss is 3.96649356842041 and perplexity is 52.799069551191
At time: 365.56860423088074 and batch: 250, loss is 3.954582290649414 and perplexity is 52.173895867957896
At time: 366.61180305480957 and batch: 300, loss is 3.9558128833770754 and perplexity is 52.23814020598693
At time: 367.65337324142456 and batch: 350, loss is 3.9478293561935427 and perplexity is 51.82275591578799
At time: 368.692898273468 and batch: 400, loss is 3.9116901540756226 and perplexity is 49.98336020181712
At time: 369.7329351902008 and batch: 450, loss is 3.9330721950531005 and perplexity is 51.06361432013742
At time: 370.7757956981659 and batch: 500, loss is 3.9370049333572386 and perplexity is 51.26482955621505
At time: 371.8182246685028 and batch: 550, loss is 3.9121584558486937 and perplexity is 50.006772979718505
At time: 372.86098074913025 and batch: 600, loss is 3.9020219659805297 and perplexity is 49.50244023223816
At time: 373.9035134315491 and batch: 650, loss is 3.949691233634949 and perplexity is 51.919333415813874
At time: 374.95709133148193 and batch: 700, loss is 3.9649650859832763 and perplexity is 52.718428745412496
At time: 376.02373003959656 and batch: 750, loss is 3.9195295572280884 and perplexity is 50.37673982946657
At time: 377.07446455955505 and batch: 800, loss is 3.8773553705215456 and perplexity is 48.296320156569465
At time: 378.1247868537903 and batch: 850, loss is 3.887887201309204 and perplexity is 48.807656756977664
At time: 379.1792221069336 and batch: 900, loss is 3.854821195602417 and perplexity is 47.22017301180223
At time: 380.25765013694763 and batch: 950, loss is 3.949652509689331 and perplexity is 51.917322933297335
At time: 381.39346194267273 and batch: 1000, loss is 3.9236991596221924 and perplexity is 50.58722932826892
At time: 382.46396112442017 and batch: 1050, loss is 3.860622625350952 and perplexity is 47.49491370208166
At time: 383.55257868766785 and batch: 1100, loss is 3.8837349224090576 and perplexity is 48.60541392855404
At time: 384.6122989654541 and batch: 1150, loss is 3.8534695625305178 and perplexity is 47.15639177842109
At time: 385.6724090576172 and batch: 1200, loss is 3.905273790359497 and perplexity is 49.66367548648902
At time: 386.7702603340149 and batch: 1250, loss is 3.8945565605163575 and perplexity is 49.13426046003669
At time: 387.8567600250244 and batch: 1300, loss is 3.8940000247955324 and perplexity is 49.10692309678955
At time: 388.9185981750488 and batch: 1350, loss is 3.7693578815460205 and perplexity is 43.35221863692158
At time: 389.97908759117126 and batch: 1400, loss is 3.7885214042663575 and perplexity is 44.191011305188574
At time: 391.03979420661926 and batch: 1450, loss is 3.7283930253982542 and perplexity is 41.61218468235569
At time: 392.1011712551117 and batch: 1500, loss is 3.741632242202759 and perplexity is 42.166760390759706
At time: 393.184041261673 and batch: 1550, loss is 3.7424913311004637 and perplexity is 42.20300095116624
At time: 394.24597811698914 and batch: 1600, loss is 3.8080109405517577 and perplexity is 45.06072121574924
At time: 395.30632162094116 and batch: 1650, loss is 3.7552834939956665 and perplexity is 42.74633642269043
At time: 396.4090909957886 and batch: 1700, loss is 3.7795792770385743 and perplexity is 43.79761119808405
At time: 397.49568605422974 and batch: 1750, loss is 3.7702719736099244 and perplexity is 43.39186467323323
At time: 398.555627822876 and batch: 1800, loss is 3.7156162738800047 and perplexity is 41.08389821765682
At time: 399.63554072380066 and batch: 1850, loss is 3.746431770324707 and perplexity is 42.369627386564396
At time: 400.7092022895813 and batch: 1900, loss is 3.816367120742798 and perplexity is 45.438834312182905
At time: 401.7707643508911 and batch: 1950, loss is 3.7468755578994752 and perplexity is 42.388434673657606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.305799191497093 and perplexity of 74.12843460060256
finished 9 epochs...
Completing Train Step...
At time: 405.14535665512085 and batch: 50, loss is 3.9092759466171265 and perplexity is 49.86283554511856
At time: 406.19559621810913 and batch: 100, loss is 3.893502426147461 and perplexity is 49.08249363678285
At time: 407.2256119251251 and batch: 150, loss is 3.8483175325393675 and perplexity is 46.91406540608703
At time: 408.27553153038025 and batch: 200, loss is 3.861179566383362 and perplexity is 47.52137293578564
At time: 409.32339000701904 and batch: 250, loss is 3.8476440954208373 and perplexity is 46.88248236884984
At time: 410.36499404907227 and batch: 300, loss is 3.8545821619033815 and perplexity is 47.20888714808273
At time: 411.4104528427124 and batch: 350, loss is 3.8518427419662475 and perplexity is 47.079739157474584
At time: 412.4544138908386 and batch: 400, loss is 3.8188955116271974 and perplexity is 45.5538668089324
At time: 413.49883103370667 and batch: 450, loss is 3.84635461807251 and perplexity is 46.82206743002067
At time: 414.54046511650085 and batch: 500, loss is 3.8557591819763184 and perplexity is 47.26448566974631
At time: 415.5795555114746 and batch: 550, loss is 3.831634964942932 and perplexity is 46.13791046810006
At time: 416.623886346817 and batch: 600, loss is 3.8206116008758544 and perplexity is 45.63210842559498
At time: 417.6669292449951 and batch: 650, loss is 3.868770565986633 and perplexity is 47.88348029849543
At time: 418.7146499156952 and batch: 700, loss is 3.889681534767151 and perplexity is 48.89531258687659
At time: 419.8086133003235 and batch: 750, loss is 3.8480581998825074 and perplexity is 46.90190063429064
At time: 420.87119722366333 and batch: 800, loss is 3.807378821372986 and perplexity is 45.032246470323976
At time: 421.93525409698486 and batch: 850, loss is 3.816440715789795 and perplexity is 45.44217850838623
At time: 422.99587202072144 and batch: 900, loss is 3.7841554737091063 and perplexity is 43.998496976469134
At time: 424.09880781173706 and batch: 950, loss is 3.8860961484909056 and perplexity is 48.72031790338612
At time: 425.15295362472534 and batch: 1000, loss is 3.8611084175109864 and perplexity is 47.51799196396512
At time: 426.20305943489075 and batch: 1050, loss is 3.800351767539978 and perplexity is 44.71691168499972
At time: 427.2531702518463 and batch: 1100, loss is 3.8253045320510863 and perplexity is 45.846760048513495
At time: 428.30294394493103 and batch: 1150, loss is 3.79855544090271 and perplexity is 44.636657608251745
At time: 429.3636918067932 and batch: 1200, loss is 3.852421760559082 and perplexity is 47.107007095352245
At time: 430.4533922672272 and batch: 1250, loss is 3.845896391868591 and perplexity is 46.80061724669594
At time: 431.52818727493286 and batch: 1300, loss is 3.8478385066986083 and perplexity is 46.891597738188835
At time: 432.60080456733704 and batch: 1350, loss is 3.725108041763306 and perplexity is 41.475713611999005
At time: 433.65268993377686 and batch: 1400, loss is 3.748914346694946 and perplexity is 42.474943896379024
At time: 434.74197363853455 and batch: 1450, loss is 3.688364210128784 and perplexity is 39.979395549209414
At time: 435.81805992126465 and batch: 1500, loss is 3.7028681468963622 and perplexity is 40.56347969485613
At time: 436.90267062187195 and batch: 1550, loss is 3.7068224716186524 and perplexity is 40.72419842303008
At time: 437.9677891731262 and batch: 1600, loss is 3.7744874143600464 and perplexity is 43.57516658553731
At time: 439.0276584625244 and batch: 1650, loss is 3.724993748664856 and perplexity is 41.47097349506635
At time: 440.07987785339355 and batch: 1700, loss is 3.7513018083572387 and perplexity is 42.57647234595437
At time: 441.15355491638184 and batch: 1750, loss is 3.7479637813568116 and perplexity is 42.434587870530315
At time: 442.2342219352722 and batch: 1800, loss is 3.6960069608688353 and perplexity is 40.28611871546744
At time: 443.31229996681213 and batch: 1850, loss is 3.731117353439331 and perplexity is 41.72570448631723
At time: 444.363046169281 and batch: 1900, loss is 3.80101291179657 and perplexity is 44.746485789630235
At time: 445.4300305843353 and batch: 1950, loss is 3.735306391716003 and perplexity is 41.900861673473514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.308031091024709 and perplexity of 74.2940665869904
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 448.8046040534973 and batch: 50, loss is 3.8853698539733887 and perplexity is 48.68494545056541
At time: 449.85440397262573 and batch: 100, loss is 3.893153648376465 and perplexity is 49.06537773905311
At time: 450.8965790271759 and batch: 150, loss is 3.86652108669281 and perplexity is 47.775888459224376
At time: 451.9407048225403 and batch: 200, loss is 3.8874432706832884 and perplexity is 48.78599435202232
At time: 452.9911346435547 and batch: 250, loss is 3.8805442667007446 and perplexity is 48.450577932681206
At time: 454.07499527931213 and batch: 300, loss is 3.8959494686126708 and perplexity is 49.20274765634977
At time: 455.14250659942627 and batch: 350, loss is 3.892003126144409 and perplexity is 49.00895939264445
At time: 456.20350408554077 and batch: 400, loss is 3.851197028160095 and perplexity is 47.049348932660344
At time: 457.2647635936737 and batch: 450, loss is 3.86751531124115 and perplexity is 47.823412040990405
At time: 458.3242244720459 and batch: 500, loss is 3.8686549139022826 and perplexity is 47.87794279441106
At time: 459.3848865032196 and batch: 550, loss is 3.8442106103897093 and perplexity is 46.721788095970815
At time: 460.4701569080353 and batch: 600, loss is 3.824774465560913 and perplexity is 45.822464656984074
At time: 461.5341227054596 and batch: 650, loss is 3.8748896408081053 and perplexity is 48.177381180853494
At time: 462.5946743488312 and batch: 700, loss is 3.9044757795333864 and perplexity is 49.62405914502342
At time: 463.663880109787 and batch: 750, loss is 3.859934401512146 and perplexity is 47.462237815701585
At time: 464.7353115081787 and batch: 800, loss is 3.815427875518799 and perplexity is 45.39617614044915
At time: 465.78456568717957 and batch: 850, loss is 3.8167815923690798 and perplexity is 45.457671323170246
At time: 466.8355300426483 and batch: 900, loss is 3.7749064493179323 and perplexity is 43.59342992985497
At time: 467.92008423805237 and batch: 950, loss is 3.875988688468933 and perplexity is 48.230359526475794
At time: 468.9981405735016 and batch: 1000, loss is 3.8469091033935547 and perplexity is 46.848036778257416
At time: 470.0731530189514 and batch: 1050, loss is 3.7856476593017576 and perplexity is 44.0641999080484
At time: 471.146666765213 and batch: 1100, loss is 3.8120460987091063 and perplexity is 45.24291569709771
At time: 472.2002582550049 and batch: 1150, loss is 3.794743227958679 and perplexity is 44.46681710411394
At time: 473.25016236305237 and batch: 1200, loss is 3.842775597572327 and perplexity is 46.65478981439572
At time: 474.30099964141846 and batch: 1250, loss is 3.82241201877594 and perplexity is 45.71433929317338
At time: 475.3531827926636 and batch: 1300, loss is 3.825482039451599 and perplexity is 45.854898910044334
At time: 476.4049024581909 and batch: 1350, loss is 3.696003293991089 and perplexity is 40.28597099146608
At time: 477.4567070007324 and batch: 1400, loss is 3.715280685424805 and perplexity is 41.07011324888793
At time: 478.50800824165344 and batch: 1450, loss is 3.6527434301376345 and perplexity is 38.580363527937486
At time: 479.570925951004 and batch: 1500, loss is 3.6665338182449343 and perplexity is 39.116087142522595
At time: 480.65494871139526 and batch: 1550, loss is 3.6723188877105715 and perplexity is 39.34303223750454
At time: 481.7226617336273 and batch: 1600, loss is 3.738995943069458 and perplexity is 42.05574259923971
At time: 482.81049275398254 and batch: 1650, loss is 3.692590107917786 and perplexity is 40.14870187211532
At time: 483.8772192001343 and batch: 1700, loss is 3.7069198226928712 and perplexity is 40.72816316047586
At time: 484.9509837627411 and batch: 1750, loss is 3.6986010837554932 and perplexity is 40.390761527516105
At time: 486.0379207134247 and batch: 1800, loss is 3.65036922454834 and perplexity is 38.48887446311283
At time: 487.0877637863159 and batch: 1850, loss is 3.682246699333191 and perplexity is 39.73556773539343
At time: 488.13802671432495 and batch: 1900, loss is 3.7572062015533447 and perplexity is 42.82860418987827
At time: 489.2101535797119 and batch: 1950, loss is 3.693025188446045 and perplexity is 40.1661735910615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2741449400436045 and perplexity of 71.81870375016173
finished 11 epochs...
Completing Train Step...
At time: 492.60095024108887 and batch: 50, loss is 3.877257981300354 and perplexity is 48.29161684459266
At time: 493.64353346824646 and batch: 100, loss is 3.8628593158721922 and perplexity is 47.60126401740002
At time: 494.6812617778778 and batch: 150, loss is 3.8232926082611085 and perplexity is 45.75461258919444
At time: 495.7317032814026 and batch: 200, loss is 3.83678683757782 and perplexity is 46.37622045071301
At time: 496.798791885376 and batch: 250, loss is 3.830056209564209 and perplexity is 46.06512746218399
At time: 497.8775496482849 and batch: 300, loss is 3.8435664796829223 and perplexity is 46.69170284803842
At time: 498.92198967933655 and batch: 350, loss is 3.844871611595154 and perplexity is 46.75268146337449
At time: 499.98262119293213 and batch: 400, loss is 3.8056664180755617 and perplexity is 44.955199089899246
At time: 501.0355772972107 and batch: 450, loss is 3.824825658798218 and perplexity is 45.82481051733673
At time: 502.08135652542114 and batch: 500, loss is 3.8301462936401367 and perplexity is 46.069277383542016
At time: 503.1257412433624 and batch: 550, loss is 3.806791729927063 and perplexity is 45.005816182887536
At time: 504.1689131259918 and batch: 600, loss is 3.788660473823547 and perplexity is 44.197157356916996
At time: 505.2165250778198 and batch: 650, loss is 3.8404398107528688 and perplexity is 46.54594134418255
At time: 506.2698085308075 and batch: 700, loss is 3.8725760316848756 and perplexity is 48.06604639447153
At time: 507.3187038898468 and batch: 750, loss is 3.829227066040039 and perplexity is 46.02694869008674
At time: 508.36715483665466 and batch: 800, loss is 3.7845196866989137 and perplexity is 44.01452471917884
At time: 509.41802310943604 and batch: 850, loss is 3.7865426540374756 and perplexity is 44.10365478832114
At time: 510.48661494255066 and batch: 900, loss is 3.7457189893722536 and perplexity is 42.339437883730156
At time: 511.5567317008972 and batch: 950, loss is 3.8481032848358154 and perplexity is 46.90401525195915
At time: 512.6258993148804 and batch: 1000, loss is 3.820561718940735 and perplexity is 45.62983226449327
At time: 513.6923723220825 and batch: 1050, loss is 3.7609518480300905 and perplexity is 42.98932581555295
At time: 514.7436966896057 and batch: 1100, loss is 3.7882459449768064 and perplexity is 44.17884015701478
At time: 515.7955536842346 and batch: 1150, loss is 3.772110729217529 and perplexity is 43.471725107135065
At time: 516.8780310153961 and batch: 1200, loss is 3.822521104812622 and perplexity is 45.71932636127123
At time: 517.9429814815521 and batch: 1250, loss is 3.806726722717285 and perplexity is 45.00289057544753
At time: 518.9946944713593 and batch: 1300, loss is 3.810972981452942 and perplexity is 45.19439078466111
At time: 520.0463457107544 and batch: 1350, loss is 3.6828744554519655 and perplexity is 39.760519812262345
At time: 521.0995559692383 and batch: 1400, loss is 3.7043928050994874 and perplexity is 40.62537230747042
At time: 522.1698670387268 and batch: 1450, loss is 3.6429434204101563 and perplexity is 38.204122185667146
At time: 523.2202658653259 and batch: 1500, loss is 3.6576750612258913 and perplexity is 38.771097576520056
At time: 524.2897009849548 and batch: 1550, loss is 3.6650897455215454 and perplexity is 39.05964143369768
At time: 525.3406465053558 and batch: 1600, loss is 3.7334311771392823 and perplexity is 41.82236219157577
At time: 526.40904545784 and batch: 1650, loss is 3.6879991626739503 and perplexity is 39.964803836114285
At time: 527.4603796005249 and batch: 1700, loss is 3.7049084520339965 and perplexity is 40.646326058068404
At time: 528.5102381706238 and batch: 1750, loss is 3.6991512060165403 and perplexity is 40.41298749751294
At time: 529.5617518424988 and batch: 1800, loss is 3.6523133182525633 and perplexity is 38.56377322315315
At time: 530.6121821403503 and batch: 1850, loss is 3.6858813619613646 and perplexity is 39.88025590550601
At time: 531.6632359027863 and batch: 1900, loss is 3.7616290521621703 and perplexity is 43.018448224425406
At time: 532.7137775421143 and batch: 1950, loss is 3.6973050928115843 and perplexity is 40.33844937172086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273024164244186 and perplexity of 71.73825617532154
finished 12 epochs...
Completing Train Step...
At time: 536.0872678756714 and batch: 50, loss is 3.861161241531372 and perplexity is 47.520502121639026
At time: 537.133837223053 and batch: 100, loss is 3.845117726325989 and perplexity is 46.76418940306731
At time: 538.1698346138 and batch: 150, loss is 3.8041711902618407 and perplexity is 44.88803105412031
At time: 539.2106750011444 and batch: 200, loss is 3.8161048030853273 and perplexity is 45.42691646680691
At time: 540.2756969928741 and batch: 250, loss is 3.8092229652404783 and perplexity is 45.11536903291626
At time: 541.3207733631134 and batch: 300, loss is 3.8221716547012328 and perplexity is 45.70335252877296
At time: 542.3640058040619 and batch: 350, loss is 3.825095491409302 and perplexity is 45.837177214005045
At time: 543.4083037376404 and batch: 400, loss is 3.785288329124451 and perplexity is 44.04836915568642
At time: 544.4510350227356 and batch: 450, loss is 3.805836601257324 and perplexity is 44.96285035975739
At time: 545.501054763794 and batch: 500, loss is 3.8120128774642943 and perplexity is 45.24141269608525
At time: 546.5758111476898 and batch: 550, loss is 3.788474926948547 and perplexity is 44.18895747324045
At time: 547.6398823261261 and batch: 600, loss is 3.7709345197677613 and perplexity is 43.420623312364775
At time: 548.7092955112457 and batch: 650, loss is 3.822941770553589 and perplexity is 45.73856296137714
At time: 549.7616503238678 and batch: 700, loss is 3.856113233566284 and perplexity is 47.281222698757624
At time: 550.8109946250916 and batch: 750, loss is 3.8133732175827024 and perplexity is 45.302998283965
At time: 551.8601486682892 and batch: 800, loss is 3.7683620071411132 and perplexity is 43.30906676247515
At time: 552.9087920188904 and batch: 850, loss is 3.770868148803711 and perplexity is 43.41774153936995
At time: 553.9551646709442 and batch: 900, loss is 3.730508050918579 and perplexity is 41.70028865314548
At time: 555.0023195743561 and batch: 950, loss is 3.833130030632019 and perplexity is 46.20694126493674
At time: 556.0505061149597 and batch: 1000, loss is 3.806347632408142 and perplexity is 44.98583364900899
At time: 557.1063017845154 and batch: 1050, loss is 3.7470658349990846 and perplexity is 42.39650098945754
At time: 558.1652545928955 and batch: 1100, loss is 3.774662389755249 and perplexity is 43.58279183462767
At time: 559.2252604961395 and batch: 1150, loss is 3.758994483947754 and perplexity is 42.90526235151947
At time: 560.2841410636902 and batch: 1200, loss is 3.810991759300232 and perplexity is 45.19523944599762
At time: 561.3439462184906 and batch: 1250, loss is 3.7971590757369995 and perplexity is 44.57437203127941
At time: 562.4036591053009 and batch: 1300, loss is 3.801797351837158 and perplexity is 44.7816004956493
At time: 563.460452079773 and batch: 1350, loss is 3.6746016931533814 and perplexity is 39.43294731590101
At time: 564.5177335739136 and batch: 1400, loss is 3.6966000509262087 and perplexity is 40.31001909876701
At time: 565.5771493911743 and batch: 1450, loss is 3.635370764732361 and perplexity is 37.915908172926805
At time: 566.6497995853424 and batch: 1500, loss is 3.650479164123535 and perplexity is 38.4931061462315
At time: 567.7394318580627 and batch: 1550, loss is 3.658183870315552 and perplexity is 38.790829682894945
At time: 568.8331241607666 and batch: 1600, loss is 3.726858739852905 and perplexity is 41.548388662057874
At time: 569.9352617263794 and batch: 1650, loss is 3.6820367336273194 and perplexity is 39.72722550468749
At time: 571.0371479988098 and batch: 1700, loss is 3.7003369903564454 and perplexity is 40.460937008487456
At time: 572.1001818180084 and batch: 1750, loss is 3.6953899908065795 and perplexity is 40.261271052215875
At time: 573.1600198745728 and batch: 1800, loss is 3.6491954469680787 and perplexity is 38.443723588904376
At time: 574.2202589511871 and batch: 1850, loss is 3.683675808906555 and perplexity is 39.79239481203501
At time: 575.2867782115936 and batch: 1900, loss is 3.759722924232483 and perplexity is 42.936527659115455
At time: 576.3459236621857 and batch: 1950, loss is 3.6953839635849 and perplexity is 40.26102838934144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.273450842569041 and perplexity of 71.76887186535564
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 579.928658246994 and batch: 50, loss is 3.8569131565093993 and perplexity is 47.31905916468393
At time: 580.9623289108276 and batch: 100, loss is 3.8550808906555174 and perplexity is 47.232437449577915
At time: 581.98064661026 and batch: 150, loss is 3.823622407913208 and perplexity is 45.769704933096385
At time: 582.9973394870758 and batch: 200, loss is 3.8367081594467165 and perplexity is 46.3725717998967
At time: 584.0204155445099 and batch: 250, loss is 3.8342226552963257 and perplexity is 46.25745570025849
At time: 585.0472729206085 and batch: 300, loss is 3.8473689126968384 and perplexity is 46.869582894581384
At time: 586.0796582698822 and batch: 350, loss is 3.861609444618225 and perplexity is 47.541805731193904
At time: 587.111403465271 and batch: 400, loss is 3.8354542112350463 and perplexity is 46.31445943897778
At time: 588.1502976417542 and batch: 450, loss is 3.8647090101242068 and perplexity is 47.689393282812574
At time: 589.193873167038 and batch: 500, loss is 3.8647163581848143 and perplexity is 47.68974370865222
At time: 590.2380392551422 and batch: 550, loss is 3.8398496866226197 and perplexity is 46.518481564166485
At time: 591.2808012962341 and batch: 600, loss is 3.802982220649719 and perplexity is 44.83469226463244
At time: 592.3410181999207 and batch: 650, loss is 3.8381811141967774 and perplexity is 46.44092682937601
At time: 593.4755594730377 and batch: 700, loss is 3.8735135221481323 and perplexity is 48.111128983519556
At time: 594.5082919597626 and batch: 750, loss is 3.8351239204406737 and perplexity is 46.299164725369344
At time: 595.5414083003998 and batch: 800, loss is 3.799697451591492 and perplexity is 44.68766226674116
At time: 596.5827074050903 and batch: 850, loss is 3.806692361831665 and perplexity is 45.00134426283839
At time: 597.6260223388672 and batch: 900, loss is 3.7573132801055906 and perplexity is 42.833190460350856
At time: 598.6710622310638 and batch: 950, loss is 3.861238169670105 and perplexity is 47.524157926034206
At time: 599.7279601097107 and batch: 1000, loss is 3.8291251277923584 and perplexity is 46.02225702272541
At time: 600.7836418151855 and batch: 1050, loss is 3.766113591194153 and perplexity is 43.211799355889404
At time: 601.8369009494781 and batch: 1100, loss is 3.785232038497925 and perplexity is 44.045889715174496
At time: 602.889990568161 and batch: 1150, loss is 3.767845296859741 and perplexity is 43.28669430294004
At time: 603.9498836994171 and batch: 1200, loss is 3.8231829452514647 and perplexity is 45.74959527578469
At time: 605.0232691764832 and batch: 1250, loss is 3.8105348348617554 and perplexity is 45.17459335380319
At time: 606.0860342979431 and batch: 1300, loss is 3.815931143760681 and perplexity is 45.419028344115375
At time: 607.1448125839233 and batch: 1350, loss is 3.6902644491195677 and perplexity is 40.05543818216612
At time: 608.1947948932648 and batch: 1400, loss is 3.7066601085662843 and perplexity is 40.717586854620606
At time: 609.2606406211853 and batch: 1450, loss is 3.6378206396102906 and perplexity is 38.00891128030554
At time: 610.3381960391998 and batch: 1500, loss is 3.6457454633712767 and perplexity is 38.311321896281186
At time: 611.3986072540283 and batch: 1550, loss is 3.650379328727722 and perplexity is 38.48926336356937
At time: 612.4584584236145 and batch: 1600, loss is 3.719239339828491 and perplexity is 41.233017862354224
At time: 613.5202217102051 and batch: 1650, loss is 3.676612720489502 and perplexity is 39.51232784234864
At time: 614.5814986228943 and batch: 1700, loss is 3.6920136833190917 and perplexity is 40.12556584147979
At time: 615.6427927017212 and batch: 1750, loss is 3.6792901372909546 and perplexity is 39.61826056251857
At time: 616.7070453166962 and batch: 1800, loss is 3.6331122875213624 and perplexity is 37.83037258482991
At time: 617.7675805091858 and batch: 1850, loss is 3.66286096572876 and perplexity is 38.97268303571378
At time: 618.8283672332764 and batch: 1900, loss is 3.750879349708557 and perplexity is 42.558489345785894
At time: 619.8901643753052 and batch: 1950, loss is 3.6961293697357176 and perplexity is 40.291050395445005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.257500510992005 and perplexity of 70.63321568555268
finished 14 epochs...
Completing Train Step...
At time: 623.24720454216 and batch: 50, loss is 3.8743759059906004 and perplexity is 48.15263713920676
At time: 624.2921195030212 and batch: 100, loss is 3.8578794384002686 and perplexity is 47.364804812683964
At time: 625.3075127601624 and batch: 150, loss is 3.8150189208984373 and perplexity is 45.37761496006869
At time: 626.3283972740173 and batch: 200, loss is 3.8211161279678345 and perplexity is 45.65513686930825
At time: 627.3558871746063 and batch: 250, loss is 3.8140690898895264 and perplexity is 45.33453435715433
At time: 628.3877789974213 and batch: 300, loss is 3.8210332345962525 and perplexity is 45.65135251793411
At time: 629.433679819107 and batch: 350, loss is 3.8320173692703245 and perplexity is 46.155557178594094
At time: 630.4994807243347 and batch: 400, loss is 3.8052327680587767 and perplexity is 44.93570849341353
At time: 631.5391185283661 and batch: 450, loss is 3.8363125467300416 and perplexity is 46.354229849181436
At time: 632.6351017951965 and batch: 500, loss is 3.8377310180664064 and perplexity is 46.4200286513666
At time: 633.7109341621399 and batch: 550, loss is 3.8139901971817016 and perplexity is 45.330957934059626
At time: 634.75257563591 and batch: 600, loss is 3.7817519903182983 and perplexity is 43.892874301783976
At time: 635.793536901474 and batch: 650, loss is 3.819816164970398 and perplexity is 45.59582544041925
At time: 636.8502209186554 and batch: 700, loss is 3.857033271789551 and perplexity is 47.3247432480978
At time: 637.8979086875916 and batch: 750, loss is 3.821248846054077 and perplexity is 45.66119653380534
At time: 638.9487020969391 and batch: 800, loss is 3.786055703163147 and perplexity is 44.08218370316699
At time: 639.9957814216614 and batch: 850, loss is 3.7939983224868774 and perplexity is 44.43370586264304
At time: 641.0419406890869 and batch: 900, loss is 3.7461273288726806 and perplexity is 42.356730278987705
At time: 642.0885908603668 and batch: 950, loss is 3.8501985454559327 and perplexity is 47.00239441704585
At time: 643.1376068592072 and batch: 1000, loss is 3.8174885845184328 and perplexity is 45.48982090333485
At time: 644.1876890659332 and batch: 1050, loss is 3.7546879196166993 and perplexity is 42.72088537966924
At time: 645.3112931251526 and batch: 1100, loss is 3.773949227333069 and perplexity is 43.55172130572121
At time: 646.3584959506989 and batch: 1150, loss is 3.7572300815582276 and perplexity is 42.82962694936715
At time: 647.3947982788086 and batch: 1200, loss is 3.812318205833435 and perplexity is 45.255228291880705
At time: 648.4335241317749 and batch: 1250, loss is 3.801050510406494 and perplexity is 44.74816822692337
At time: 649.4743473529816 and batch: 1300, loss is 3.808316078186035 and perplexity is 45.07447303561203
At time: 650.5164799690247 and batch: 1350, loss is 3.6844435262680055 and perplexity is 39.822955854006125
At time: 651.5592811107635 and batch: 1400, loss is 3.70262957572937 and perplexity is 40.55380357243586
At time: 652.6026713848114 and batch: 1450, loss is 3.6353757905960085 and perplexity is 37.91609873359022
At time: 653.644602060318 and batch: 1500, loss is 3.6451369667053224 and perplexity is 38.28801667593254
At time: 654.6883804798126 and batch: 1550, loss is 3.650606279373169 and perplexity is 38.49799951803296
At time: 655.73109126091 and batch: 1600, loss is 3.7201857948303223 and perplexity is 41.27206153197431
At time: 656.773463010788 and batch: 1650, loss is 3.6790508031845093 and perplexity is 39.60877969612052
At time: 657.814227104187 and batch: 1700, loss is 3.695263247489929 and perplexity is 40.25616852855238
At time: 658.8565828800201 and batch: 1750, loss is 3.684418144226074 and perplexity is 39.82194507889863
At time: 659.8985981941223 and batch: 1800, loss is 3.639014620780945 and perplexity is 38.05432030805879
At time: 660.962525844574 and batch: 1850, loss is 3.6692097902297975 and perplexity is 39.22090087263009
At time: 662.0041329860687 and batch: 1900, loss is 3.757817406654358 and perplexity is 42.85478925263519
At time: 663.0466623306274 and batch: 1950, loss is 3.7024944829940796 and perplexity is 40.54832541822258
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25579351380814 and perplexity of 70.512747833684
finished 15 epochs...
Completing Train Step...
At time: 666.3793585300446 and batch: 50, loss is 3.871879334449768 and perplexity is 48.03257057545529
At time: 667.4419703483582 and batch: 100, loss is 3.8529177045822145 and perplexity is 47.13037532815757
At time: 668.4704835414886 and batch: 150, loss is 3.80884681224823 and perplexity is 45.09840194316899
At time: 669.50150847435 and batch: 200, loss is 3.813679132461548 and perplexity is 45.316859265228494
At time: 670.5355298519135 and batch: 250, loss is 3.805973243713379 and perplexity is 44.9689946138352
At time: 671.6000213623047 and batch: 300, loss is 3.8117399263381957 and perplexity is 45.229065686685274
At time: 672.6388013362885 and batch: 350, loss is 3.8229504013061524 and perplexity is 45.738957721300196
At time: 673.6803154945374 and batch: 400, loss is 3.7960576963424684 and perplexity is 44.525305761649086
At time: 674.7212314605713 and batch: 450, loss is 3.8275336027145386 and perplexity is 45.949069701712595
At time: 675.7631123065948 and batch: 500, loss is 3.82918568611145 and perplexity is 46.02504413764217
At time: 676.8047633171082 and batch: 550, loss is 3.805169115066528 and perplexity is 44.93284829214026
At time: 677.8446102142334 and batch: 600, loss is 3.7735901641845704 and perplexity is 43.53608629469277
At time: 678.8876724243164 and batch: 650, loss is 3.811894555091858 and perplexity is 45.23605994148423
At time: 679.9306004047394 and batch: 700, loss is 3.849752178192139 and perplexity is 46.981418768627826
At time: 680.9725420475006 and batch: 750, loss is 3.814777135848999 and perplexity is 45.3666446574732
At time: 682.0157589912415 and batch: 800, loss is 3.7794656991958617 and perplexity is 43.79263704237049
At time: 683.0635917186737 and batch: 850, loss is 3.788033356666565 and perplexity is 44.16944925027124
At time: 684.1133103370667 and batch: 900, loss is 3.740773305892944 and perplexity is 42.13055737945909
At time: 685.1619820594788 and batch: 950, loss is 3.8450409078598025 and perplexity is 46.76059718774092
At time: 686.2152376174927 and batch: 1000, loss is 3.8123885202407837 and perplexity is 45.258410498313644
At time: 687.2628169059753 and batch: 1050, loss is 3.7498955488204957 and perplexity is 42.516640854839544
At time: 688.3117315769196 and batch: 1100, loss is 3.7691679859161376 and perplexity is 43.343987021655316
At time: 689.3599457740784 and batch: 1150, loss is 3.7523978042602537 and perplexity is 42.62316156613377
At time: 690.407407283783 and batch: 1200, loss is 3.8073416996002196 and perplexity is 45.03057482453077
At time: 691.4569742679596 and batch: 1250, loss is 3.79676335811615 and perplexity is 44.556736656372756
At time: 692.5059580802917 and batch: 1300, loss is 3.804584684371948 and perplexity is 44.906595828523436
At time: 693.5526630878448 and batch: 1350, loss is 3.6814928340911863 and perplexity is 39.70562376028554
At time: 694.5987575054169 and batch: 1400, loss is 3.700508990287781 and perplexity is 40.4678968854067
At time: 695.6478621959686 and batch: 1450, loss is 3.6338500356674195 and perplexity is 37.85829216961365
At time: 696.6968269348145 and batch: 1500, loss is 3.6442685413360594 and perplexity is 38.25478082442947
At time: 697.7446007728577 and batch: 1550, loss is 3.6501073598861695 and perplexity is 38.478796906539785
At time: 698.7970073223114 and batch: 1600, loss is 3.7200586938858033 and perplexity is 41.26681614732509
At time: 699.8461413383484 and batch: 1650, loss is 3.6792627429962157 and perplexity is 39.61717526307726
At time: 700.8918805122375 and batch: 1700, loss is 3.6957020139694214 and perplexity is 40.27383546144104
At time: 701.9409394264221 and batch: 1750, loss is 3.685587706565857 and perplexity is 39.86854657252368
At time: 702.9894711971283 and batch: 1800, loss is 3.640267448425293 and perplexity is 38.10202568959822
At time: 704.0377395153046 and batch: 1850, loss is 3.6706463098526 and perplexity is 39.27728295364471
At time: 705.0861914157867 and batch: 1900, loss is 3.759282431602478 and perplexity is 42.91761860007993
At time: 706.1350848674774 and batch: 1950, loss is 3.7035747575759888 and perplexity is 40.59215241184233
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25547613099564 and perplexity of 70.49037185052352
finished 16 epochs...
Completing Train Step...
At time: 709.4755916595459 and batch: 50, loss is 3.8678373670578003 and perplexity is 47.83881632939748
At time: 710.5339441299438 and batch: 100, loss is 3.84797070980072 and perplexity is 46.89779736266857
At time: 711.588951587677 and batch: 150, loss is 3.803584566116333 and perplexity is 44.86170637336127
At time: 712.6146852970123 and batch: 200, loss is 3.807962760925293 and perplexity is 45.058550259331184
At time: 713.6437692642212 and batch: 250, loss is 3.8000374031066895 and perplexity is 44.70285648774227
At time: 714.6781482696533 and batch: 300, loss is 3.8052316999435423 and perplexity is 44.93566049692434
At time: 715.7126607894897 and batch: 350, loss is 3.8166297101974487 and perplexity is 45.45076763761904
At time: 716.7468686103821 and batch: 400, loss is 3.7896816062927248 and perplexity is 44.242311559627176
At time: 717.7804608345032 and batch: 450, loss is 3.8214568519592285 and perplexity is 45.67069532018822
At time: 718.8139626979828 and batch: 500, loss is 3.82318341255188 and perplexity is 45.749616654594554
At time: 719.8469409942627 and batch: 550, loss is 3.799085178375244 and perplexity is 44.660309582550966
At time: 720.8879396915436 and batch: 600, loss is 3.767775659561157 and perplexity is 43.283680039437954
At time: 721.9316916465759 and batch: 650, loss is 3.806212568283081 and perplexity is 44.97975808705151
At time: 722.9797782897949 and batch: 700, loss is 3.8445417499542236 and perplexity is 46.73726209041874
At time: 724.0647304058075 and batch: 750, loss is 3.8099361991882326 and perplexity is 45.147558323558854
At time: 725.1145038604736 and batch: 800, loss is 3.7745945167541506 and perplexity is 43.57983384013472
At time: 726.163740158081 and batch: 850, loss is 3.7835653400421143 and perplexity is 43.97253964200808
At time: 727.2119052410126 and batch: 900, loss is 3.7366182804107666 and perplexity is 41.955867012756244
At time: 728.261262178421 and batch: 950, loss is 3.8410889673233033 and perplexity is 46.57616675728451
At time: 729.3109874725342 and batch: 1000, loss is 3.8085712814331054 and perplexity is 45.08597765543644
At time: 730.368771314621 and batch: 1050, loss is 3.746363806724548 and perplexity is 42.366747892001335
At time: 731.4280848503113 and batch: 1100, loss is 3.765654864311218 and perplexity is 43.19198148770684
At time: 732.487667798996 and batch: 1150, loss is 3.7487658071517944 and perplexity is 42.468635156177555
At time: 733.5467677116394 and batch: 1200, loss is 3.8036285066604614 and perplexity is 44.86367766445932
At time: 734.6044158935547 and batch: 1250, loss is 3.793479266166687 and perplexity is 44.41064825140265
At time: 735.6630628108978 and batch: 1300, loss is 3.801569228172302 and perplexity is 44.77138591796386
At time: 736.72070145607 and batch: 1350, loss is 3.6789168453216554 and perplexity is 39.60347414401033
At time: 737.7785289287567 and batch: 1400, loss is 3.698487358093262 and perplexity is 40.38616832260094
At time: 738.8377332687378 and batch: 1450, loss is 3.632146635055542 and perplexity is 37.793859224705926
At time: 739.8938148021698 and batch: 1500, loss is 3.6429308891296386 and perplexity is 38.20364344209475
At time: 740.9489850997925 and batch: 1550, loss is 3.6489923000335693 and perplexity is 38.43591465751325
At time: 742.0077404975891 and batch: 1600, loss is 3.719224557876587 and perplexity is 41.23240836237213
At time: 743.0662667751312 and batch: 1650, loss is 3.6785874509811403 and perplexity is 39.590431132027646
At time: 744.1247413158417 and batch: 1700, loss is 3.69515221118927 and perplexity is 40.25169888067143
At time: 745.2057988643646 and batch: 1750, loss is 3.6854564571380615 and perplexity is 39.86331419197999
At time: 746.285802602768 and batch: 1800, loss is 3.6401211500167845 and perplexity is 38.0964518316121
At time: 747.3605709075928 and batch: 1850, loss is 3.6706270933151246 and perplexity is 39.27652818751691
At time: 748.4189565181732 and batch: 1900, loss is 3.7592732095718384 and perplexity is 42.9172228143112
At time: 749.4766690731049 and batch: 1950, loss is 3.703321475982666 and perplexity is 40.581872468718196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25557747774346 and perplexity of 70.49751618248446
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 752.8549439907074 and batch: 50, loss is 3.8682615089416506 and perplexity is 47.85911107869895
At time: 753.8612146377563 and batch: 100, loss is 3.856095304489136 and perplexity is 47.280374997667465
At time: 754.8682928085327 and batch: 150, loss is 3.8157750082015993 and perplexity is 45.41193737232275
At time: 755.8891253471375 and batch: 200, loss is 3.8209441471099854 and perplexity is 45.64728573484602
At time: 756.9197373390198 and batch: 250, loss is 3.8143347263336183 and perplexity is 45.346578461261196
At time: 757.9516911506653 and batch: 300, loss is 3.815241837501526 and perplexity is 45.38773151138358
At time: 759.0122210979462 and batch: 350, loss is 3.8238875818252565 and perplexity is 45.78184347414788
At time: 760.0513002872467 and batch: 400, loss is 3.799469518661499 and perplexity is 44.67747763769642
At time: 761.0904803276062 and batch: 450, loss is 3.8395742416381835 and perplexity is 46.505670046251225
At time: 762.1342430114746 and batch: 500, loss is 3.8461757850646974 and perplexity is 46.81369484753952
At time: 763.1731526851654 and batch: 550, loss is 3.830424437522888 and perplexity is 46.08209305344649
At time: 764.2113192081451 and batch: 600, loss is 3.795383276939392 and perplexity is 44.49528715521865
At time: 765.2496831417084 and batch: 650, loss is 3.819680943489075 and perplexity is 45.58966032219864
At time: 766.2880733013153 and batch: 700, loss is 3.853263144493103 and perplexity is 47.14665885313885
At time: 767.3266913890839 and batch: 750, loss is 3.8176157760620115 and perplexity is 45.49560719184836
At time: 768.3654556274414 and batch: 800, loss is 3.7836413526535035 and perplexity is 43.97588223661374
At time: 769.407888174057 and batch: 850, loss is 3.7955857038497927 and perplexity is 44.50429511042038
At time: 770.453989982605 and batch: 900, loss is 3.746603636741638 and perplexity is 42.37690992840429
At time: 771.500462770462 and batch: 950, loss is 3.8566282987594604 and perplexity is 47.305581883606166
At time: 772.5465800762177 and batch: 1000, loss is 3.8259905624389647 and perplexity is 45.87822311016676
At time: 773.5925633907318 and batch: 1050, loss is 3.7652225399017336 and perplexity is 43.173312575619676
At time: 774.6356897354126 and batch: 1100, loss is 3.780413188934326 and perplexity is 43.834149779929234
At time: 775.7079834938049 and batch: 1150, loss is 3.7611253595352174 and perplexity is 42.99678560534056
At time: 776.7546038627625 and batch: 1200, loss is 3.8134551286697387 and perplexity is 45.30670925378316
At time: 777.7997465133667 and batch: 1250, loss is 3.799173979759216 and perplexity is 44.66427565594431
At time: 778.8639261722565 and batch: 1300, loss is 3.8017004203796385 and perplexity is 44.777259960213804
At time: 779.9128844738007 and batch: 1350, loss is 3.676388158798218 and perplexity is 39.50345588337014
At time: 780.9596292972565 and batch: 1400, loss is 3.696862373352051 and perplexity is 40.32059470781181
At time: 782.0054655075073 and batch: 1450, loss is 3.6276835918426515 and perplexity is 37.625559441766235
At time: 783.0509238243103 and batch: 1500, loss is 3.6368394565582274 and perplexity is 37.97163587072048
At time: 784.0967741012573 and batch: 1550, loss is 3.64262442111969 and perplexity is 38.19193704142654
At time: 785.143664598465 and batch: 1600, loss is 3.714289231300354 and perplexity is 41.02941429462254
At time: 786.1862511634827 and batch: 1650, loss is 3.6736836338043215 and perplexity is 39.39676214256651
At time: 787.2294661998749 and batch: 1700, loss is 3.689428105354309 and perplexity is 40.02195207107977
At time: 788.2737927436829 and batch: 1750, loss is 3.679282937049866 and perplexity is 39.617975302517976
At time: 789.3218331336975 and batch: 1800, loss is 3.63174120426178 and perplexity is 37.77853953610772
At time: 790.3706796169281 and batch: 1850, loss is 3.658744716644287 and perplexity is 38.81259147925256
At time: 791.4494948387146 and batch: 1900, loss is 3.7446770000457765 and perplexity is 42.29534361823286
At time: 792.4981226921082 and batch: 1950, loss is 3.6926217746734618 and perplexity is 40.14997327137864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252556947220204 and perplexity of 70.28489755522227
finished 18 epochs...
Completing Train Step...
At time: 795.80490899086 and batch: 50, loss is 3.868661184310913 and perplexity is 47.878243009618004
At time: 796.8236904144287 and batch: 100, loss is 3.8532701301574708 and perplexity is 47.14698820502404
At time: 797.8494112491608 and batch: 150, loss is 3.810925188064575 and perplexity is 45.192230843206204
At time: 798.8756506443024 and batch: 200, loss is 3.8159014129638673 and perplexity is 45.4176780202854
At time: 799.9022221565247 and batch: 250, loss is 3.8086852169036867 and perplexity is 45.091114840165446
At time: 800.9289627075195 and batch: 300, loss is 3.8093626165390013 and perplexity is 45.12166989273644
At time: 801.9962468147278 and batch: 350, loss is 3.8175752544403077 and perplexity is 45.49376367341597
At time: 803.0399765968323 and batch: 400, loss is 3.7925883293151856 and perplexity is 44.371098788929295
At time: 804.0807156562805 and batch: 450, loss is 3.832219276428223 and perplexity is 46.164877256828824
At time: 805.1206378936768 and batch: 500, loss is 3.8384764575958252 and perplexity is 46.45464487622831
At time: 806.1638069152832 and batch: 550, loss is 3.8224692344665527 and perplexity is 45.716954945494415
At time: 807.2179679870605 and batch: 600, loss is 3.787825412750244 and perplexity is 44.160265436904545
At time: 808.2670230865479 and batch: 650, loss is 3.812341685295105 and perplexity is 45.25629087275312
At time: 809.3168387413025 and batch: 700, loss is 3.846280379295349 and perplexity is 46.8185915460148
At time: 810.3644938468933 and batch: 750, loss is 3.811259889602661 and perplexity is 45.20735928399393
At time: 811.4127779006958 and batch: 800, loss is 3.777776074409485 and perplexity is 43.71870639248046
At time: 812.4592170715332 and batch: 850, loss is 3.7901590871810913 and perplexity is 44.26344146201489
At time: 813.5082490444183 and batch: 900, loss is 3.7424111366271973 and perplexity is 42.19961663943806
At time: 814.556604385376 and batch: 950, loss is 3.852477707862854 and perplexity is 47.109642679114216
At time: 815.6059560775757 and batch: 1000, loss is 3.822148871421814 and perplexity is 45.70231126838364
At time: 816.655885219574 and batch: 1050, loss is 3.761409487724304 and perplexity is 43.00900393987558
At time: 817.7046909332275 and batch: 1100, loss is 3.7775572967529296 and perplexity is 43.7091427625407
At time: 818.7564759254456 and batch: 1150, loss is 3.7584179830551148 and perplexity is 42.8805345579573
At time: 819.8054039478302 and batch: 1200, loss is 3.810773391723633 and perplexity is 45.18537134856145
At time: 820.8865733146667 and batch: 1250, loss is 3.7966834545135497 and perplexity is 44.55317655482816
At time: 821.9747636318207 and batch: 1300, loss is 3.798983373641968 and perplexity is 44.65576318307229
At time: 823.0330183506012 and batch: 1350, loss is 3.674412112236023 and perplexity is 39.425472290158226
At time: 824.0815577507019 and batch: 1400, loss is 3.695765247344971 and perplexity is 40.27638219252194
At time: 825.1290996074677 and batch: 1450, loss is 3.627329249382019 and perplexity is 37.61222947027789
At time: 826.1774563789368 and batch: 1500, loss is 3.6376764297485353 and perplexity is 38.003430415671204
At time: 827.2248108386993 and batch: 1550, loss is 3.6437458419799804 and perplexity is 38.234790300097835
At time: 828.2729256153107 and batch: 1600, loss is 3.7158490133285524 and perplexity is 41.093461174267645
At time: 829.3230202198029 and batch: 1650, loss is 3.67621741771698 and perplexity is 39.49671159637979
At time: 830.3718855381012 and batch: 1700, loss is 3.692193841934204 and perplexity is 40.13279545907179
At time: 831.4209055900574 and batch: 1750, loss is 3.6824906778335573 and perplexity is 39.74526354235684
At time: 832.4682860374451 and batch: 1800, loss is 3.6352476930618285 and perplexity is 37.911242085905656
At time: 833.5160431861877 and batch: 1850, loss is 3.6619768381118774 and perplexity is 38.938241437965296
At time: 834.5597007274628 and batch: 1900, loss is 3.7481297397613527 and perplexity is 42.44163083143378
At time: 835.6033327579498 and batch: 1950, loss is 3.6953219032287596 and perplexity is 40.258529853111845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251785633175872 and perplexity of 70.23070672839302
finished 19 epochs...
Completing Train Step...
At time: 839.0181584358215 and batch: 50, loss is 3.8681587839126585 and perplexity is 47.85419500263221
At time: 840.0559780597687 and batch: 100, loss is 3.8514803743362425 and perplexity is 47.062682074628825
At time: 841.0797019004822 and batch: 150, loss is 3.8083209466934203 and perplexity is 45.074692481551075
At time: 842.1072409152985 and batch: 200, loss is 3.8130149698257445 and perplexity is 45.286771493225544
At time: 843.1356046199799 and batch: 250, loss is 3.805487775802612 and perplexity is 44.94716890823924
At time: 844.1632008552551 and batch: 300, loss is 3.8059199476242065 and perplexity is 44.96659800615374
At time: 845.1989579200745 and batch: 350, loss is 3.8141975927352907 and perplexity is 45.34036034815082
At time: 846.2322335243225 and batch: 400, loss is 3.7889921855926514 and perplexity is 44.211820506008344
At time: 847.2679417133331 and batch: 450, loss is 3.828496732711792 and perplexity is 45.993345947555845
At time: 848.3096804618835 and batch: 500, loss is 3.8347007131576536 and perplexity is 46.27957472726714
At time: 849.3570799827576 and batch: 550, loss is 3.818554749488831 and perplexity is 45.53834642039829
At time: 850.4050755500793 and batch: 600, loss is 3.7841610670089723 and perplexity is 43.99874307394462
At time: 851.4541847705841 and batch: 650, loss is 3.808732647895813 and perplexity is 45.09325360719992
At time: 852.5041840076447 and batch: 700, loss is 3.8428962516784666 and perplexity is 46.6604192459581
At time: 853.5527083873749 and batch: 750, loss is 3.8082804822921754 and perplexity is 45.07286859800995
At time: 854.639241695404 and batch: 800, loss is 3.7749640369415283 and perplexity is 43.59594044417561
At time: 855.6872596740723 and batch: 850, loss is 3.7873669719696044 and perplexity is 44.14002521017156
At time: 856.7352323532104 and batch: 900, loss is 3.740125322341919 and perplexity is 42.103266314317246
At time: 857.7851960659027 and batch: 950, loss is 3.8502028656005858 and perplexity is 47.00259747462739
At time: 858.8337805271149 and batch: 1000, loss is 3.820069546699524 and perplexity is 45.60738005331234
At time: 859.8816895484924 and batch: 1050, loss is 3.7594118165969848 and perplexity is 42.92317185517294
At time: 860.9300720691681 and batch: 1100, loss is 3.7759716653823854 and perplexity is 43.63989109291626
At time: 861.9784750938416 and batch: 1150, loss is 3.756945781707764 and perplexity is 42.8174522235484
At time: 863.02991938591 and batch: 1200, loss is 3.8092340803146363 and perplexity is 45.11587049637562
At time: 864.078284740448 and batch: 1250, loss is 3.795308790206909 and perplexity is 44.49197297010051
At time: 865.1264741420746 and batch: 1300, loss is 3.797641649246216 and perplexity is 44.595887633423935
At time: 866.1911301612854 and batch: 1350, loss is 3.6734167337417603 and perplexity is 39.386248547387964
At time: 867.2390127182007 and batch: 1400, loss is 3.6951598930358887 and perplexity is 40.252008089236014
At time: 868.2870190143585 and batch: 1450, loss is 3.627109394073486 and perplexity is 37.60396113091555
At time: 869.3357772827148 and batch: 1500, loss is 3.6380697202682497 and perplexity is 38.018379744092194
At time: 870.3849542140961 and batch: 1550, loss is 3.6443150281906127 and perplexity is 38.25655921019708
At time: 871.4358170032501 and batch: 1600, loss is 3.716601734161377 and perplexity is 41.12440472305226
At time: 872.4840438365936 and batch: 1650, loss is 3.677375946044922 and perplexity is 39.54249617186763
At time: 873.5320203304291 and batch: 1700, loss is 3.6934886598587036 and perplexity is 40.18479377890591
At time: 874.6040551662445 and batch: 1750, loss is 3.684005255699158 and perplexity is 39.80550644855053
At time: 875.6579937934875 and batch: 1800, loss is 3.636873931884766 and perplexity is 37.97294497783214
At time: 876.7047083377838 and batch: 1850, loss is 3.6635254573822023 and perplexity is 38.998588664387064
At time: 877.7532505989075 and batch: 1900, loss is 3.7497203016281127 and perplexity is 42.509190585738615
At time: 878.8030886650085 and batch: 1950, loss is 3.6965352487564087 and perplexity is 40.30740700670026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251395859829215 and perplexity of 70.20333800493943
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd78797ab38>
ELAPSED
4488.811988353729


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.58572924558682}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.5545691141662139, 'dropout': 0.7795352401135597, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.01716348977908}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.30559750332649016, 'dropout': 0.7036453025474743, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -69.20731299479563}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.2784456490206031, 'dropout': 0.9440744352266794, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -71.65749186356365}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.7972956216277209, 'dropout': 0.16004583408284256, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.20333800493943}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.31612970171994975, 'dropout': 0.6964694918509416, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 3 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6212828159332275 and batch: 50, loss is 7.607822008132935 and perplexity is 2013.887087962061
At time: 2.7696242332458496 and batch: 100, loss is 6.828898477554321 and perplexity is 924.1722551174639
At time: 3.917618989944458 and batch: 150, loss is 6.528458337783814 and perplexity is 684.3423730483474
At time: 5.0656421184539795 and batch: 200, loss is 6.432814903259278 and perplexity is 621.9221370174159
At time: 6.213940143585205 and batch: 250, loss is 6.381347904205322 and perplexity is 590.7234098411443
At time: 7.361071825027466 and batch: 300, loss is 6.306431818008423 and perplexity is 548.085785734994
At time: 8.50750470161438 and batch: 350, loss is 6.2412275791168215 and perplexity is 513.4884719251097
At time: 9.653209686279297 and batch: 400, loss is 6.180209102630616 and perplexity is 483.0929618013096
At time: 10.804328441619873 and batch: 450, loss is 6.082836751937866 and perplexity is 438.27069821959617
At time: 11.959259748458862 and batch: 500, loss is 6.063460474014282 and perplexity is 429.8603867603266
At time: 13.112977504730225 and batch: 550, loss is 6.006958551406861 and perplexity is 406.24586348724307
At time: 14.267269134521484 and batch: 600, loss is 6.03500846862793 and perplexity is 417.80234783597984
At time: 15.419636487960815 and batch: 650, loss is 6.1017602443695065 and perplexity is 446.6432798536588
At time: 16.57270121574402 and batch: 700, loss is 6.0035986232757566 and perplexity is 404.8831970948816
At time: 17.72645902633667 and batch: 750, loss is 5.931228160858154 and perplexity is 376.61677588321453
At time: 18.880547285079956 and batch: 800, loss is 5.934281549453735 and perplexity is 377.76849067319966
At time: 20.03621554374695 and batch: 850, loss is 5.962837152481079 and perplexity is 388.7113947609375
At time: 21.18550133705139 and batch: 900, loss is 5.936449337005615 and perplexity is 378.588300770791
At time: 22.33875060081482 and batch: 950, loss is 5.962060384750366 and perplexity is 388.40957353059866
At time: 23.49215793609619 and batch: 1000, loss is 5.937703123092652 and perplexity is 379.06326720594654
At time: 24.646302461624146 and batch: 1050, loss is 5.829094152450562 and perplexity is 340.05050559654813
At time: 25.800426959991455 and batch: 1100, loss is 5.899237899780274 and perplexity is 364.7593787102228
At time: 26.958423137664795 and batch: 1150, loss is 5.808104600906372 and perplexity is 332.9873831773554
At time: 28.12370800971985 and batch: 1200, loss is 5.8781867027282715 and perplexity is 357.16101507846946
At time: 29.287901639938354 and batch: 1250, loss is 5.809440441131592 and perplexity is 333.4324983534819
At time: 30.452291250228882 and batch: 1300, loss is 5.819926786422729 and perplexity is 336.9473836036862
At time: 31.618141889572144 and batch: 1350, loss is 5.78596866607666 and perplexity is 325.69737936140274
At time: 32.78366684913635 and batch: 1400, loss is 5.809619932174683 and perplexity is 333.49235187183626
At time: 33.95094156265259 and batch: 1450, loss is 5.779923601150513 and perplexity is 323.7344565324161
At time: 35.14115071296692 and batch: 1500, loss is 5.74941611289978 and perplexity is 314.00726195931276
At time: 36.39169788360596 and batch: 1550, loss is 5.720832033157349 and perplexity is 305.1587195315887
At time: 37.669360637664795 and batch: 1600, loss is 5.731601305007935 and perplexity is 308.4628161639628
At time: 38.94660711288452 and batch: 1650, loss is 5.732538900375366 and perplexity is 308.7521650963354
At time: 40.225059032440186 and batch: 1700, loss is 5.750721998214722 and perplexity is 314.4175872920918
At time: 41.50076866149902 and batch: 1750, loss is 5.74997989654541 and perplexity is 314.18434403151207
At time: 42.77626657485962 and batch: 1800, loss is 5.744937686920166 and perplexity is 312.6041478959092
At time: 44.052186012268066 and batch: 1850, loss is 5.705245027542114 and perplexity is 300.4390868813972
At time: 45.33061909675598 and batch: 1900, loss is 5.70117693901062 and perplexity is 299.21935674487634
At time: 46.608238697052 and batch: 1950, loss is 5.637892379760742 and perplexity is 280.8701266518462
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.100379837390989 and perplexity of 164.0842207869825
finished 1 epochs...
Completing Train Step...
At time: 50.13135647773743 and batch: 50, loss is 5.35754732131958 and perplexity is 212.20383982338475
At time: 51.21166682243347 and batch: 100, loss is 5.261399755477905 and perplexity is 192.75110697307204
At time: 52.291905879974365 and batch: 150, loss is 5.1555008125305175 and perplexity is 173.38261720646165
At time: 53.37323522567749 and batch: 200, loss is 5.112529535293579 and perplexity is 166.08995435559615
At time: 54.4542760848999 and batch: 250, loss is 5.1146741771698 and perplexity is 166.44654006457276
At time: 55.53430962562561 and batch: 300, loss is 5.104366340637207 and perplexity is 164.73964863039967
At time: 56.65855097770691 and batch: 350, loss is 5.086236476898193 and perplexity is 161.7798526683779
At time: 57.74463415145874 and batch: 400, loss is 5.04940788269043 and perplexity is 155.93010823005815
At time: 58.825804710388184 and batch: 450, loss is 5.000394477844238 and perplexity is 148.47171635464585
At time: 59.90609622001648 and batch: 500, loss is 4.983415899276733 and perplexity is 145.97215718019544
At time: 60.9852511882782 and batch: 550, loss is 4.927691049575806 and perplexity is 138.06036949053822
At time: 62.0654559135437 and batch: 600, loss is 4.909709444046021 and perplexity is 135.6000092939871
At time: 63.14533042907715 and batch: 650, loss is 4.9869217205047605 and perplexity is 146.4848075727804
At time: 64.22562074661255 and batch: 700, loss is 4.966122455596924 and perplexity is 143.46949806916416
At time: 65.30674839019775 and batch: 750, loss is 4.921961889266968 and perplexity is 137.2716609775156
At time: 66.3854730129242 and batch: 800, loss is 4.901037302017212 and perplexity is 134.42915101687856
At time: 67.46297979354858 and batch: 850, loss is 4.892700433731079 and perplexity is 133.31309157546596
At time: 68.54425072669983 and batch: 900, loss is 4.885950527191162 and perplexity is 132.41627080001234
At time: 69.62489485740662 and batch: 950, loss is 4.947649765014648 and perplexity is 140.84355917427413
At time: 70.70657849311829 and batch: 1000, loss is 4.90843207359314 and perplexity is 135.42690842920666
At time: 71.78717160224915 and batch: 1050, loss is 4.817029266357422 and perplexity is 123.59736998484331
At time: 72.86732268333435 and batch: 1100, loss is 4.890940361022949 and perplexity is 133.07865721262976
At time: 73.94742679595947 and batch: 1150, loss is 4.806992702484131 and perplexity is 122.363081455327
At time: 75.02759528160095 and batch: 1200, loss is 4.884900808334351 and perplexity is 132.27734387346925
At time: 76.10681700706482 and batch: 1250, loss is 4.837935962677002 and perplexity is 126.20858347820891
At time: 77.1877760887146 and batch: 1300, loss is 4.865982265472412 and perplexity is 129.79837247427804
At time: 78.26716375350952 and batch: 1350, loss is 4.766221046447754 and perplexity is 117.47447153506994
At time: 79.34981226921082 and batch: 1400, loss is 4.783332853317261 and perplexity is 119.50196960874207
At time: 80.43769955635071 and batch: 1450, loss is 4.724984655380249 and perplexity is 112.7287685807088
At time: 81.51819181442261 and batch: 1500, loss is 4.694968910217285 and perplexity is 109.39540750949332
At time: 82.60001516342163 and batch: 1550, loss is 4.700220346450806 and perplexity is 109.97140159065376
At time: 83.67997288703918 and batch: 1600, loss is 4.764305238723755 and perplexity is 117.24962848192976
At time: 84.75915265083313 and batch: 1650, loss is 4.723673286437989 and perplexity is 112.58103646152037
At time: 85.83937668800354 and batch: 1700, loss is 4.750092678070068 and perplexity is 115.59499715201287
At time: 86.92044019699097 and batch: 1750, loss is 4.7525450801849365 and perplexity is 115.87883046194713
At time: 87.99702882766724 and batch: 1800, loss is 4.706598215103149 and perplexity is 110.67502617297431
At time: 89.07717180252075 and batch: 1850, loss is 4.715158967971802 and perplexity is 111.62655481035316
At time: 90.15751481056213 and batch: 1900, loss is 4.795971117019653 and perplexity is 121.02185111495646
At time: 91.23821115493774 and batch: 1950, loss is 4.70759467124939 and perplexity is 110.78536394728664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5621522415515985 and perplexity of 95.789420104115
finished 2 epochs...
Completing Train Step...
At time: 94.67946887016296 and batch: 50, loss is 4.661643552780151 and perplexity is 105.8098433869343
At time: 95.7792317867279 and batch: 100, loss is 4.603739261627197 and perplexity is 99.85700989232302
At time: 96.84453654289246 and batch: 150, loss is 4.558434114456177 and perplexity is 95.43392416485834
At time: 97.91324949264526 and batch: 200, loss is 4.551750764846802 and perplexity is 94.79823252601311
At time: 98.98891353607178 and batch: 250, loss is 4.552432680130005 and perplexity is 94.86289893559388
At time: 100.064120054245 and batch: 300, loss is 4.5658391571044925 and perplexity is 96.14323945713835
At time: 101.13928437232971 and batch: 350, loss is 4.575345058441162 and perplexity is 97.061525257869
At time: 102.21464657783508 and batch: 400, loss is 4.541652545928955 and perplexity is 93.84575647077143
At time: 103.28847002983093 and batch: 450, loss is 4.539944896697998 and perplexity is 93.6856375892577
At time: 104.36373496055603 and batch: 500, loss is 4.536377449035644 and perplexity is 93.35201442585725
At time: 105.43833327293396 and batch: 550, loss is 4.499237489700318 and perplexity is 89.94851847307552
At time: 106.51727104187012 and batch: 600, loss is 4.47901180267334 and perplexity is 88.14752247588399
At time: 107.59797167778015 and batch: 650, loss is 4.54347674369812 and perplexity is 94.0171059305055
At time: 108.67805933952332 and batch: 700, loss is 4.559443492889404 and perplexity is 95.53030174224976
At time: 109.75801062583923 and batch: 750, loss is 4.5312892436981205 and perplexity is 92.87822659486251
At time: 110.90647792816162 and batch: 800, loss is 4.507849140167236 and perplexity is 90.72646858363957
At time: 111.98706722259521 and batch: 850, loss is 4.497697458267212 and perplexity is 89.81010153783822
At time: 113.06730437278748 and batch: 900, loss is 4.4787225341796875 and perplexity is 88.12202786241018
At time: 114.14506697654724 and batch: 950, loss is 4.555461091995239 and perplexity is 95.1506183107896
At time: 115.22502779960632 and batch: 1000, loss is 4.543540420532227 and perplexity is 94.02309283277451
At time: 116.30587267875671 and batch: 1050, loss is 4.461334648132325 and perplexity is 86.6030165525736
At time: 117.38599038124084 and batch: 1100, loss is 4.519672212600708 and perplexity is 91.80550035941263
At time: 118.46437573432922 and batch: 1150, loss is 4.462368154525757 and perplexity is 86.69256759168591
At time: 119.54439949989319 and batch: 1200, loss is 4.546343936920166 and perplexity is 94.28705795676072
At time: 120.62453198432922 and batch: 1250, loss is 4.50929476737976 and perplexity is 90.85772008303204
At time: 121.70528316497803 and batch: 1300, loss is 4.5243596267700195 and perplexity is 92.23684090874055
At time: 122.78652667999268 and batch: 1350, loss is 4.410561561584473 and perplexity is 82.31567584880511
At time: 123.86931824684143 and batch: 1400, loss is 4.434388036727905 and perplexity is 84.30052027760956
At time: 124.9742386341095 and batch: 1450, loss is 4.373267431259155 and perplexity is 79.3023237316809
At time: 126.0647382736206 and batch: 1500, loss is 4.36698395729065 and perplexity is 78.80559188003187
At time: 127.14501929283142 and batch: 1550, loss is 4.379451150894165 and perplexity is 79.79422639465746
At time: 128.22835159301758 and batch: 1600, loss is 4.4503767204284665 and perplexity is 85.65920749801079
At time: 129.30958819389343 and batch: 1650, loss is 4.40828691482544 and perplexity is 82.128649553536
At time: 130.39096117019653 and batch: 1700, loss is 4.4367896175384525 and perplexity is 84.50321808959205
At time: 131.47206664085388 and batch: 1750, loss is 4.42832106590271 and perplexity is 83.7906198201755
At time: 132.55440139770508 and batch: 1800, loss is 4.3954635429382325 and perplexity is 81.08220713745794
At time: 133.63520884513855 and batch: 1850, loss is 4.420452337265015 and perplexity is 83.13388140720159
At time: 134.7165596485138 and batch: 1900, loss is 4.510763931274414 and perplexity is 90.9913030685506
At time: 135.7980830669403 and batch: 1950, loss is 4.4299805545806885 and perplexity is 83.92978484454176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4319895189861915 and perplexity of 84.0985662760341
finished 3 epochs...
Completing Train Step...
At time: 139.20441460609436 and batch: 50, loss is 4.399027662277222 and perplexity is 81.37170940381667
At time: 140.2959361076355 and batch: 100, loss is 4.348919534683228 and perplexity is 77.39479534137406
At time: 141.3404884338379 and batch: 150, loss is 4.309886150360107 and perplexity is 74.43201439990699
At time: 142.37924194335938 and batch: 200, loss is 4.312007160186767 and perplexity is 74.5900529753059
At time: 143.42314171791077 and batch: 250, loss is 4.302428741455078 and perplexity is 73.87900898949063
At time: 144.47094774246216 and batch: 300, loss is 4.324718408584594 and perplexity is 75.5442372556589
At time: 145.53220772743225 and batch: 350, loss is 4.337120485305786 and perplexity is 76.48697656089486
At time: 146.58718991279602 and batch: 400, loss is 4.294464178085327 and perplexity is 73.29293196262024
At time: 147.6466724872589 and batch: 450, loss is 4.315945310592651 and perplexity is 74.88437899237483
At time: 148.71111631393433 and batch: 500, loss is 4.31772536277771 and perplexity is 75.01779580404202
At time: 149.78598523139954 and batch: 550, loss is 4.283142080307007 and perplexity is 72.46778224799105
At time: 150.85522079467773 and batch: 600, loss is 4.26723614692688 and perplexity is 71.3242332480547
At time: 151.9195261001587 and batch: 650, loss is 4.331455364227295 and perplexity is 76.05489363438758
At time: 152.98657727241516 and batch: 700, loss is 4.350200414657593 and perplexity is 77.49399230098412
At time: 154.05180096626282 and batch: 750, loss is 4.327511987686157 and perplexity is 75.75557110957978
At time: 155.11733388900757 and batch: 800, loss is 4.301065950393677 and perplexity is 73.77839590928933
At time: 156.1810245513916 and batch: 850, loss is 4.294306735992432 and perplexity is 73.281393478363
At time: 157.2435426712036 and batch: 900, loss is 4.2675878524780275 and perplexity is 71.34932278862611
At time: 158.30604100227356 and batch: 950, loss is 4.351856279373169 and perplexity is 77.62241816709046
At time: 159.36704969406128 and batch: 1000, loss is 4.341779661178589 and perplexity is 76.84417431407962
At time: 160.4285032749176 and batch: 1050, loss is 4.26964846611023 and perplexity is 71.49649775911101
At time: 161.49253940582275 and batch: 1100, loss is 4.3172095584869385 and perplexity is 74.97911128076129
At time: 162.55814170837402 and batch: 1150, loss is 4.271616649627686 and perplexity is 71.63735455810108
At time: 163.62306571006775 and batch: 1200, loss is 4.356674342155457 and perplexity is 77.99731025271508
At time: 164.75383138656616 and batch: 1250, loss is 4.328635683059693 and perplexity is 75.84074514022487
At time: 165.82001328468323 and batch: 1300, loss is 4.336396913528443 and perplexity is 76.43165276110489
At time: 166.8796741962433 and batch: 1350, loss is 4.21696382522583 and perplexity is 67.82723600198416
At time: 167.94350719451904 and batch: 1400, loss is 4.245005035400391 and perplexity is 69.7561113929694
At time: 169.007559299469 and batch: 1450, loss is 4.183038582801819 and perplexity is 65.56477483827209
At time: 170.07150173187256 and batch: 1500, loss is 4.189188618659973 and perplexity is 65.96924302664299
At time: 171.1363296508789 and batch: 1550, loss is 4.192244749069214 and perplexity is 66.1711620245671
At time: 172.1998074054718 and batch: 1600, loss is 4.275584740638733 and perplexity is 71.92218283931341
At time: 173.26388549804688 and batch: 1650, loss is 4.227614693641662 and perplexity is 68.55351585742461
At time: 174.32829666137695 and batch: 1700, loss is 4.261014132499695 and perplexity is 70.88183058489783
At time: 175.39263439178467 and batch: 1750, loss is 4.249247560501098 and perplexity is 70.0526821059972
At time: 176.45795941352844 and batch: 1800, loss is 4.212299079895019 and perplexity is 67.51157602862813
At time: 177.52864336967468 and batch: 1850, loss is 4.244577035903931 and perplexity is 69.72626220059352
At time: 178.5993583202362 and batch: 1900, loss is 4.336102323532105 and perplexity is 76.40914007696645
At time: 179.6814911365509 and batch: 1950, loss is 4.258617010116577 and perplexity is 70.7121216500546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37813351653343 and perplexity of 79.68915601754277
finished 4 epochs...
Completing Train Step...
At time: 183.13038158416748 and batch: 50, loss is 4.232235174179078 and perplexity is 68.87099894059416
At time: 184.24769377708435 and batch: 100, loss is 4.1917806816101075 and perplexity is 66.14046126570277
At time: 185.3113729953766 and batch: 150, loss is 4.1604436588287355 and perplexity is 64.09995480324126
At time: 186.36485767364502 and batch: 200, loss is 4.16584499835968 and perplexity is 64.44711714988237
At time: 187.4211139678955 and batch: 250, loss is 4.1449344444274905 and perplexity is 63.1134843255279
At time: 188.47915506362915 and batch: 300, loss is 4.170728917121887 and perplexity is 64.76264150498535
At time: 189.53941202163696 and batch: 350, loss is 4.180727214813232 and perplexity is 65.41340551902137
At time: 190.62463879585266 and batch: 400, loss is 4.139893531799316 and perplexity is 62.79613530174149
At time: 191.6855444908142 and batch: 450, loss is 4.1713514280319215 and perplexity is 64.80296950689309
At time: 192.74613308906555 and batch: 500, loss is 4.172376132011413 and perplexity is 64.86940740140372
At time: 193.805561542511 and batch: 550, loss is 4.14422191619873 and perplexity is 63.06853020377283
At time: 194.8654544353485 and batch: 600, loss is 4.127510714530945 and perplexity is 62.02333681901402
At time: 195.93514251708984 and batch: 650, loss is 4.186219253540039 and perplexity is 65.77364679943499
At time: 196.99428868293762 and batch: 700, loss is 4.210439314842224 and perplexity is 67.3861370385509
At time: 198.05579781532288 and batch: 750, loss is 4.190127744674682 and perplexity is 66.03122555908884
At time: 199.1173267364502 and batch: 800, loss is 4.1687511491775515 and perplexity is 64.63468260683972
At time: 200.17780947685242 and batch: 850, loss is 4.1613995885849 and perplexity is 64.16125915406472
At time: 201.27253103256226 and batch: 900, loss is 4.131875476837158 and perplexity is 62.29464561013108
At time: 202.33770275115967 and batch: 950, loss is 4.219002833366394 and perplexity is 67.96567738192977
At time: 203.3986735343933 and batch: 1000, loss is 4.208876900672912 and perplexity is 67.28093418983862
At time: 204.45912170410156 and batch: 1050, loss is 4.145292892456054 and perplexity is 63.136111284612355
At time: 205.51938772201538 and batch: 1100, loss is 4.181683731079102 and perplexity is 65.4760044390761
At time: 206.5771563053131 and batch: 1150, loss is 4.142330913543701 and perplexity is 62.94938013775997
At time: 207.64146780967712 and batch: 1200, loss is 4.23020094871521 and perplexity is 68.73104220087173
At time: 208.70297026634216 and batch: 1250, loss is 4.202363843917847 and perplexity is 66.84415357939407
At time: 209.76782965660095 and batch: 1300, loss is 4.2060973262786865 and perplexity is 67.09418149468782
At time: 210.82872200012207 and batch: 1350, loss is 4.087534370422364 and perplexity is 59.592776700277135
At time: 211.88879990577698 and batch: 1400, loss is 4.117838201522827 and perplexity is 61.426307329286715
At time: 212.94934511184692 and batch: 1450, loss is 4.056155519485474 and perplexity is 57.75185785220968
At time: 214.00771236419678 and batch: 1500, loss is 4.061770086288452 and perplexity is 58.0770214884086
At time: 215.06722974777222 and batch: 1550, loss is 4.07004144191742 and perplexity is 58.559389354984965
At time: 216.12714457511902 and batch: 1600, loss is 4.152252035140991 and perplexity is 63.57701687466209
At time: 217.18615984916687 and batch: 1650, loss is 4.105069732666015 and perplexity is 60.646973475303284
At time: 218.2464954853058 and batch: 1700, loss is 4.137147703170776 and perplexity is 62.62394438722679
At time: 219.30641651153564 and batch: 1750, loss is 4.123900685310364 and perplexity is 61.79983442854902
At time: 220.37331247329712 and batch: 1800, loss is 4.090618271827697 and perplexity is 59.776838616616175
At time: 221.4329833984375 and batch: 1850, loss is 4.119595561027527 and perplexity is 61.534350341712
At time: 222.4917459487915 and batch: 1900, loss is 4.211584696769714 and perplexity is 67.46336412088756
At time: 223.5523717403412 and batch: 1950, loss is 4.13684814453125 and perplexity is 62.60518765315549
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.353575240734012 and perplexity of 77.75596285084707
finished 5 epochs...
Completing Train Step...
At time: 226.95305252075195 and batch: 50, loss is 4.115104632377625 and perplexity is 61.25862356286936
At time: 227.99342274665833 and batch: 100, loss is 4.078670563697815 and perplexity is 59.066891958877704
At time: 229.0319685935974 and batch: 150, loss is 4.061095838546753 and perplexity is 58.03787638605683
At time: 230.07143473625183 and batch: 200, loss is 4.058088154792785 and perplexity is 57.863579055154446
At time: 231.11467123031616 and batch: 250, loss is 4.034248461723328 and perplexity is 56.50044203348683
At time: 232.1547155380249 and batch: 300, loss is 4.0589040088653565 and perplexity is 57.91080655453436
At time: 233.20047998428345 and batch: 350, loss is 4.068574357032776 and perplexity is 58.47354074900232
At time: 234.24795937538147 and batch: 400, loss is 4.029446220397949 and perplexity is 56.229763727312935
At time: 235.2982017993927 and batch: 450, loss is 4.067170281410217 and perplexity is 58.39149708710337
At time: 236.35009360313416 and batch: 500, loss is 4.072926368713379 and perplexity is 58.72857283012054
At time: 237.40136218070984 and batch: 550, loss is 4.042275590896606 and perplexity is 56.95580355783366
At time: 238.45222878456116 and batch: 600, loss is 4.029677858352661 and perplexity is 56.24279018342928
At time: 239.50442361831665 and batch: 650, loss is 4.083254814147949 and perplexity is 59.3382909901986
At time: 240.5547912120819 and batch: 700, loss is 4.108974418640137 and perplexity is 60.88424379358396
At time: 241.60600304603577 and batch: 750, loss is 4.088124189376831 and perplexity is 59.627936017320835
At time: 242.66677451133728 and batch: 800, loss is 4.069056096076966 and perplexity is 58.50171652277341
At time: 243.7720067501068 and batch: 850, loss is 4.062530541419983 and perplexity is 58.12120325441969
At time: 244.83803462982178 and batch: 900, loss is 4.029031991958618 and perplexity is 56.20647658347184
At time: 245.91097807884216 and batch: 950, loss is 4.12436589717865 and perplexity is 61.828591133444846
At time: 247.01963663101196 and batch: 1000, loss is 4.110939421653748 and perplexity is 61.00399913739187
At time: 248.10838770866394 and batch: 1050, loss is 4.049624400138855 and perplexity is 57.37590261672347
At time: 249.18933963775635 and batch: 1100, loss is 4.079438462257385 and perplexity is 59.112266759523536
At time: 250.25805068016052 and batch: 1150, loss is 4.046552972793579 and perplexity is 57.199947056152205
At time: 251.32661724090576 and batch: 1200, loss is 4.134334855079651 and perplexity is 62.44804025657859
At time: 252.3955979347229 and batch: 1250, loss is 4.107390780448913 and perplexity is 60.7879014856826
At time: 253.4649519920349 and batch: 1300, loss is 4.114139404296875 and perplexity is 61.19952354630463
At time: 254.55807900428772 and batch: 1350, loss is 3.9913108253479006 and perplexity is 54.12579234304103
At time: 255.63015413284302 and batch: 1400, loss is 4.023193526268005 and perplexity is 55.879273110939906
At time: 256.70003747940063 and batch: 1450, loss is 3.959402618408203 and perplexity is 52.42599826644428
At time: 257.78610253334045 and batch: 1500, loss is 3.969539079666138 and perplexity is 52.96011481938438
At time: 258.86499547958374 and batch: 1550, loss is 3.9798022413253786 and perplexity is 53.506451816148974
At time: 259.93496775627136 and batch: 1600, loss is 4.059372215270996 and perplexity is 57.93792711363327
At time: 261.03337693214417 and batch: 1650, loss is 4.011810650825501 and perplexity is 55.24681274306366
At time: 262.0985565185547 and batch: 1700, loss is 4.0455346775054934 and perplexity is 57.141730265558486
At time: 263.1920509338379 and batch: 1750, loss is 4.033660879135132 and perplexity is 56.467253109094514
At time: 264.28121614456177 and batch: 1800, loss is 3.9975671100616457 and perplexity is 54.46548019427278
At time: 265.3490972518921 and batch: 1850, loss is 4.02875020980835 and perplexity is 56.19064083286186
At time: 266.4145874977112 and batch: 1900, loss is 4.12044843673706 and perplexity is 61.58685388073433
At time: 267.51092886924744 and batch: 1950, loss is 4.047424955368042 and perplexity is 57.2498461656606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350688135901163 and perplexity of 77.5317969856029
finished 6 epochs...
Completing Train Step...
At time: 270.9769916534424 and batch: 50, loss is 4.027880787849426 and perplexity is 56.14180868678183
At time: 272.02178406715393 and batch: 100, loss is 3.997227931022644 and perplexity is 54.447009777607875
At time: 273.0851163864136 and batch: 150, loss is 3.978229422569275 and perplexity is 53.42236201150577
At time: 274.12999987602234 and batch: 200, loss is 3.973237781524658 and perplexity is 53.15636119919185
At time: 275.19300651550293 and batch: 250, loss is 3.951193594932556 and perplexity is 51.997393635579485
At time: 276.23481488227844 and batch: 300, loss is 3.9755224132537843 and perplexity is 53.27794274023226
At time: 277.3062300682068 and batch: 350, loss is 3.9860880899429323 and perplexity is 53.84384456126986
At time: 278.3570132255554 and batch: 400, loss is 3.9471984052658082 and perplexity is 51.79006861299157
At time: 279.42601013183594 and batch: 450, loss is 3.985570888519287 and perplexity is 53.81600364850871
At time: 280.4978108406067 and batch: 500, loss is 3.997305884361267 and perplexity is 54.45125426923209
At time: 281.5963797569275 and batch: 550, loss is 3.965688304901123 and perplexity is 52.756569500795806
At time: 282.6625249385834 and batch: 600, loss is 3.9512011098861692 and perplexity is 51.99778439504893
At time: 283.740460395813 and batch: 650, loss is 4.003428173065186 and perplexity is 54.785643136275866
At time: 284.78593826293945 and batch: 700, loss is 4.031957626342773 and perplexity is 56.37115696380533
At time: 285.8275887966156 and batch: 750, loss is 4.008836522102356 and perplexity is 55.082745709597766
At time: 286.8736979961395 and batch: 800, loss is 3.9921098804473876 and perplexity is 54.169059117392734
At time: 287.9225330352783 and batch: 850, loss is 3.986234436035156 and perplexity is 53.85172497413146
At time: 288.9784858226776 and batch: 900, loss is 3.9528444957733155 and perplexity is 52.08330707422091
At time: 290.0355567932129 and batch: 950, loss is 4.051331133842468 and perplexity is 57.47391161733576
At time: 291.0914270877838 and batch: 1000, loss is 4.030606160163879 and perplexity is 56.29502470837549
At time: 292.14725852012634 and batch: 1050, loss is 3.9796362113952637 and perplexity is 53.497568881130185
At time: 293.20338678359985 and batch: 1100, loss is 4.003383226394654 and perplexity is 54.78318075936217
At time: 294.26440811157227 and batch: 1150, loss is 3.9680469131469724 and perplexity is 52.88114843934591
At time: 295.3236608505249 and batch: 1200, loss is 4.056914467811584 and perplexity is 57.79570516487397
At time: 296.3836612701416 and batch: 1250, loss is 4.031411247253418 and perplexity is 56.340365355109114
At time: 297.4437348842621 and batch: 1300, loss is 4.038560805320739 and perplexity is 56.74461745871
At time: 298.50160670280457 and batch: 1350, loss is 3.918300976753235 and perplexity is 50.314885954537075
At time: 299.56082701683044 and batch: 1400, loss is 3.951166243553162 and perplexity is 51.995971454588044
At time: 300.6184129714966 and batch: 1450, loss is 3.881224126815796 and perplexity is 48.48352874787215
At time: 301.6780540943146 and batch: 1500, loss is 3.89558434009552 and perplexity is 49.184785609485594
At time: 302.73844027519226 and batch: 1550, loss is 3.903933901786804 and perplexity is 49.597176255955134
At time: 303.7986671924591 and batch: 1600, loss is 3.9908162784576415 and perplexity is 54.09903121861583
At time: 304.85949301719666 and batch: 1650, loss is 3.9414592742919923 and perplexity is 51.493689917654294
At time: 305.9187686443329 and batch: 1700, loss is 3.9748921060562132 and perplexity is 53.244371850549456
At time: 306.97839879989624 and batch: 1750, loss is 3.9617382287979126 and perplexity is 52.548588077976966
At time: 308.03946828842163 and batch: 1800, loss is 3.925626049041748 and perplexity is 50.68479929830867
At time: 309.09972763061523 and batch: 1850, loss is 3.956061716079712 and perplexity is 52.25114038096236
At time: 310.1593973636627 and batch: 1900, loss is 4.045958995819092 and perplexity is 57.165981692979386
At time: 311.22076535224915 and batch: 1950, loss is 3.9738805389404295 and perplexity is 53.190538827333356
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348555028161337 and perplexity of 77.36658957461702
finished 7 epochs...
Completing Train Step...
At time: 314.5992650985718 and batch: 50, loss is 3.960494861602783 and perplexity is 52.48329148964055
At time: 315.6288352012634 and batch: 100, loss is 3.9289661502838134 and perplexity is 50.85437470125332
At time: 316.6572847366333 and batch: 150, loss is 3.9106568050384523 and perplexity is 49.93173662186004
At time: 317.68609070777893 and batch: 200, loss is 3.9066519021987913 and perplexity is 49.732164767764985
At time: 318.7178053855896 and batch: 250, loss is 3.8833430004119873 and perplexity is 48.5863681301362
At time: 319.77467799186707 and batch: 300, loss is 3.9066131019592287 and perplexity is 49.7302351852924
At time: 320.8465476036072 and batch: 350, loss is 3.919308967590332 and perplexity is 50.36562846824686
At time: 321.9100351333618 and batch: 400, loss is 3.8814190244674682 and perplexity is 48.492978994655424
At time: 322.97305488586426 and batch: 450, loss is 3.918509383201599 and perplexity is 50.325372993964066
At time: 324.0124771595001 and batch: 500, loss is 3.9324938106536864 and perplexity is 51.03408846170801
At time: 325.04855942726135 and batch: 550, loss is 3.9052143907546997 and perplexity is 49.660725571405095
At time: 326.08659267425537 and batch: 600, loss is 3.8911970615386964 and perplexity is 48.96947092238244
At time: 327.1293933391571 and batch: 650, loss is 3.9359295320510865 and perplexity is 51.20972892450656
At time: 328.1752541065216 and batch: 700, loss is 3.968466625213623 and perplexity is 52.9033479538204
At time: 329.2215805053711 and batch: 750, loss is 3.946517744064331 and perplexity is 51.75482911710421
At time: 330.26756024360657 and batch: 800, loss is 3.9250549507141113 and perplexity is 50.65586155812684
At time: 331.3136067390442 and batch: 850, loss is 3.9218075275421143 and perplexity is 50.491627352818625
At time: 332.3601903915405 and batch: 900, loss is 3.887658967971802 and perplexity is 48.796518493695096
At time: 333.40601778030396 and batch: 950, loss is 3.9869069814682008 and perplexity is 53.88795488759019
At time: 334.4671936035156 and batch: 1000, loss is 3.9706361865997315 and perplexity is 53.01824961276797
At time: 335.5382225513458 and batch: 1050, loss is 3.9174202251434327 and perplexity is 50.27059054722466
At time: 336.59290623664856 and batch: 1100, loss is 3.940673785209656 and perplexity is 51.45325806788189
At time: 337.65013885498047 and batch: 1150, loss is 3.90397469997406 and perplexity is 49.59919977211699
At time: 338.709614276886 and batch: 1200, loss is 3.9918807983398437 and perplexity is 54.15665137641644
At time: 339.7727975845337 and batch: 1250, loss is 3.971243739128113 and perplexity is 53.05047077140263
At time: 340.8369691371918 and batch: 1300, loss is 3.976702561378479 and perplexity is 53.34085572046073
At time: 341.9017746448517 and batch: 1350, loss is 3.8559800291061403 and perplexity is 47.27492504845996
At time: 342.96699261665344 and batch: 1400, loss is 3.8959960985183715 and perplexity is 49.20504202932598
At time: 344.03151988983154 and batch: 1450, loss is 3.821037783622742 and perplexity is 45.65156018761833
At time: 345.0948176383972 and batch: 1500, loss is 3.83095992565155 and perplexity is 46.10677607536331
At time: 346.1568386554718 and batch: 1550, loss is 3.8442287731170652 and perplexity is 46.72263669877603
At time: 347.2203178405762 and batch: 1600, loss is 3.9307228231430056 and perplexity is 50.9437877127742
At time: 348.2832553386688 and batch: 1650, loss is 3.8789182472229005 and perplexity is 48.37186036474292
At time: 349.34638714790344 and batch: 1700, loss is 3.9154938793182374 and perplexity is 50.17384521739197
At time: 350.40964913368225 and batch: 1750, loss is 3.900130672454834 and perplexity is 49.408905066628556
At time: 351.47305607795715 and batch: 1800, loss is 3.8635648679733277 and perplexity is 47.63486104007544
At time: 352.5352454185486 and batch: 1850, loss is 3.898771061897278 and perplexity is 49.34177384416333
At time: 353.59664583206177 and batch: 1900, loss is 3.9871044683456422 and perplexity is 53.89859810244569
At time: 354.658509016037 and batch: 1950, loss is 3.9113653087615967 and perplexity is 49.96712597842475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3469505132630815 and perplexity of 77.24255326468153
finished 8 epochs...
Completing Train Step...
At time: 358.0560030937195 and batch: 50, loss is 3.904250135421753 and perplexity is 49.61286303149805
At time: 359.10360741615295 and batch: 100, loss is 3.866681261062622 and perplexity is 47.78354154494827
At time: 360.1257107257843 and batch: 150, loss is 3.855686984062195 and perplexity is 47.261073395649845
At time: 361.1482195854187 and batch: 200, loss is 3.8514497232437135 and perplexity is 47.06123957411312
At time: 362.171199798584 and batch: 250, loss is 3.8279867935180665 and perplexity is 45.969898116798674
At time: 363.19437885284424 and batch: 300, loss is 3.8502858591079714 and perplexity is 47.006498546927645
At time: 364.212455034256 and batch: 350, loss is 3.8614816188812258 and perplexity is 47.53572905322424
At time: 365.23668122291565 and batch: 400, loss is 3.825402455329895 and perplexity is 45.851249733398944
At time: 366.2580211162567 and batch: 450, loss is 3.8667216634750368 and perplexity is 47.785472154300784
At time: 367.30601048469543 and batch: 500, loss is 3.8846542692184447 and perplexity is 48.65011970767713
At time: 368.33290243148804 and batch: 550, loss is 3.8528272819519045 and perplexity is 47.12611386832201
At time: 369.36150336265564 and batch: 600, loss is 3.8395256900787356 and perplexity is 46.50341217825926
At time: 370.3967034816742 and batch: 650, loss is 3.8824636793136595 and perplexity is 48.543663889669666
At time: 371.43279504776 and batch: 700, loss is 3.9119721126556395 and perplexity is 49.99745542612543
At time: 372.4688878059387 and batch: 750, loss is 3.889482355117798 and perplexity is 48.885574605496586
At time: 373.5071806907654 and batch: 800, loss is 3.869910635948181 and perplexity is 47.938101946371866
At time: 374.5444247722626 and batch: 850, loss is 3.8739613008499147 and perplexity is 48.13267694639647
At time: 375.60237646102905 and batch: 900, loss is 3.8333622217178345 and perplexity is 46.21767135046816
At time: 376.63933539390564 and batch: 950, loss is 3.9366931390762328 and perplexity is 51.248847967156195
At time: 377.67763924598694 and batch: 1000, loss is 3.917394366264343 and perplexity is 50.2692906229093
At time: 378.7195973396301 and batch: 1050, loss is 3.865920057296753 and perplexity is 47.747182373302536
At time: 379.76761651039124 and batch: 1100, loss is 3.886886968612671 and perplexity is 48.75886214989699
At time: 380.81499791145325 and batch: 1150, loss is 3.851297001838684 and perplexity is 47.054052864279114
At time: 381.86502838134766 and batch: 1200, loss is 3.941431474685669 and perplexity is 51.4922584332439
At time: 382.9242699146271 and batch: 1250, loss is 3.9212172174453737 and perplexity is 50.46183043096857
At time: 384.01336908340454 and batch: 1300, loss is 3.9234734344482423 and perplexity is 50.575811805788746
At time: 385.0726330280304 and batch: 1350, loss is 3.8074788188934328 and perplexity is 45.03674980846873
At time: 386.1329355239868 and batch: 1400, loss is 3.8434229612350466 and perplexity is 46.685002208161215
At time: 387.19298243522644 and batch: 1450, loss is 3.7705133533477784 and perplexity is 43.40233985435042
At time: 388.2524652481079 and batch: 1500, loss is 3.784549078941345 and perplexity is 44.01581842377223
At time: 389.3119044303894 and batch: 1550, loss is 3.789508371353149 and perplexity is 44.23464790928263
At time: 390.37225008010864 and batch: 1600, loss is 3.8792991924285887 and perplexity is 48.39029090332886
At time: 391.43198466300964 and batch: 1650, loss is 3.829488043785095 and perplexity is 46.038962266937595
At time: 392.4926311969757 and batch: 1700, loss is 3.865249752998352 and perplexity is 47.71518795591687
At time: 393.5548806190491 and batch: 1750, loss is 3.8460046529769896 and perplexity is 46.80568420766526
At time: 394.61400628089905 and batch: 1800, loss is 3.814403939247131 and perplexity is 45.349717138691595
At time: 395.67199969291687 and batch: 1850, loss is 3.849971876144409 and perplexity is 46.99174162403962
At time: 396.73091888427734 and batch: 1900, loss is 3.9359455251693727 and perplexity is 51.21054793430789
At time: 397.80913972854614 and batch: 1950, loss is 3.864886898994446 and perplexity is 47.69787744970309
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350060751271802 and perplexity of 77.48316998339928
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 401.1489429473877 and batch: 50, loss is 3.8877122592926026 and perplexity is 48.79911899390753
At time: 402.1890432834625 and batch: 100, loss is 3.881465754508972 and perplexity is 48.4952451265243
At time: 403.18909788131714 and batch: 150, loss is 3.88250497341156 and perplexity is 48.54566849786774
At time: 404.19257402420044 and batch: 200, loss is 3.8730462121963503 and perplexity is 48.088651426556176
At time: 405.2105379104614 and batch: 250, loss is 3.850788297653198 and perplexity is 47.03012235793341
At time: 406.23414754867554 and batch: 300, loss is 3.8624085855484007 and perplexity is 47.57981351881481
At time: 407.25864839553833 and batch: 350, loss is 3.870342435836792 and perplexity is 47.9588060831528
At time: 408.28367733955383 and batch: 400, loss is 3.8284992837905882 and perplexity is 45.99346328035512
At time: 409.3084077835083 and batch: 450, loss is 3.860442500114441 and perplexity is 47.48635943996037
At time: 410.33544063568115 and batch: 500, loss is 3.877560315132141 and perplexity is 48.30621924144455
At time: 411.41465282440186 and batch: 550, loss is 3.8402534675598146 and perplexity is 46.53726863292421
At time: 412.473685503006 and batch: 600, loss is 3.8097309732437132 and perplexity is 45.13829382394952
At time: 413.54188418388367 and batch: 650, loss is 3.8396969270706176 and perplexity is 46.51137596450086
At time: 414.60012197494507 and batch: 700, loss is 3.870151605606079 and perplexity is 47.94965496630588
At time: 415.6571500301361 and batch: 750, loss is 3.8270825147628784 and perplexity is 45.92834730414348
At time: 416.7214980125427 and batch: 800, loss is 3.811118941307068 and perplexity is 45.200987832787725
At time: 417.78709053993225 and batch: 850, loss is 3.8069299459457397 and perplexity is 45.012037137525525
At time: 418.85107469558716 and batch: 900, loss is 3.7635594606399536 and perplexity is 43.10157160680683
At time: 419.9148073196411 and batch: 950, loss is 3.863671269416809 and perplexity is 47.63992972770319
At time: 420.9748709201813 and batch: 1000, loss is 3.830220627784729 and perplexity is 46.07270203115085
At time: 422.0343632698059 and batch: 1050, loss is 3.7694941997528075 and perplexity is 43.358128736444336
At time: 423.09584879875183 and batch: 1100, loss is 3.7808799171447753 and perplexity is 43.85461318926632
At time: 424.15608382225037 and batch: 1150, loss is 3.7496365213394167 and perplexity is 42.505629302663856
At time: 425.2151973247528 and batch: 1200, loss is 3.827888541221619 and perplexity is 45.965381690619495
At time: 426.2805280685425 and batch: 1250, loss is 3.794486656188965 and perplexity is 44.4554096376355
At time: 427.36963391304016 and batch: 1300, loss is 3.80418671131134 and perplexity is 44.88872776887909
At time: 428.4415862560272 and batch: 1350, loss is 3.6828178119659425 and perplexity is 39.75826770159839
At time: 429.50758481025696 and batch: 1400, loss is 3.711449670791626 and perplexity is 40.913074045855225
At time: 430.5738751888275 and batch: 1450, loss is 3.6259925508499147 and perplexity is 37.56198684545819
At time: 431.64135694503784 and batch: 1500, loss is 3.632197461128235 and perplexity is 37.79578018695929
At time: 432.70753240585327 and batch: 1550, loss is 3.6288752698898317 and perplexity is 37.67042372154522
At time: 433.78065037727356 and batch: 1600, loss is 3.710302457809448 and perplexity is 40.8661649486764
At time: 434.8196849822998 and batch: 1650, loss is 3.6576629400253298 and perplexity is 38.77062762711852
At time: 435.8578567504883 and batch: 1700, loss is 3.6811211681365967 and perplexity is 39.6908692737681
At time: 436.8962426185608 and batch: 1750, loss is 3.6531557989120484 and perplexity is 38.59627614586983
At time: 437.93473720550537 and batch: 1800, loss is 3.6151091384887697 and perplexity is 37.1554007886634
At time: 438.97290539741516 and batch: 1850, loss is 3.639097933769226 and perplexity is 38.057490859272875
At time: 440.0194163322449 and batch: 1900, loss is 3.7151563501358034 and perplexity is 41.065007101931506
At time: 441.06414103507996 and batch: 1950, loss is 3.635574107170105 and perplexity is 37.92361887005337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.290892703034157 and perplexity of 73.03163497027946
finished 10 epochs...
Completing Train Step...
At time: 444.4317002296448 and batch: 50, loss is 3.8013299465179444 and perplexity is 44.760674228280045
At time: 445.4670991897583 and batch: 100, loss is 3.7798945903778076 and perplexity is 43.811423346584256
At time: 446.4911324977875 and batch: 150, loss is 3.7755055475234984 and perplexity is 43.61955450031068
At time: 447.52189350128174 and batch: 200, loss is 3.7660466051101684 and perplexity is 43.208904863615054
At time: 448.54613876342773 and batch: 250, loss is 3.743479776382446 and perplexity is 42.24473693181041
At time: 449.5729591846466 and batch: 300, loss is 3.754981293678284 and perplexity is 42.733420417965206
At time: 450.61202216148376 and batch: 350, loss is 3.7655587577819825 and perplexity is 43.18783065573947
At time: 451.65236353874207 and batch: 400, loss is 3.7284442567825318 and perplexity is 41.61431658678952
At time: 452.6929738521576 and batch: 450, loss is 3.7651908874511717 and perplexity is 43.17194605610474
At time: 453.7314085960388 and batch: 500, loss is 3.7827759265899656 and perplexity is 43.937840825347806
At time: 454.7846965789795 and batch: 550, loss is 3.750410737991333 and perplexity is 42.53855061113832
At time: 455.8227581977844 and batch: 600, loss is 3.724506721496582 and perplexity is 41.4507809218445
At time: 456.86092495918274 and batch: 650, loss is 3.7564721393585203 and perplexity is 42.79717686690143
At time: 457.8988661766052 and batch: 700, loss is 3.7909023904800416 and perplexity is 44.29635485487786
At time: 458.93794775009155 and batch: 750, loss is 3.7490403938293455 and perplexity is 42.48029807877352
At time: 459.98225259780884 and batch: 800, loss is 3.737620234489441 and perplexity is 41.997925931868146
At time: 461.04549050331116 and batch: 850, loss is 3.732997851371765 and perplexity is 41.804243410330635
At time: 462.0966246128082 and batch: 900, loss is 3.6924646377563475 and perplexity is 40.14366472402238
At time: 463.136150598526 and batch: 950, loss is 3.7957058715820313 and perplexity is 44.50964341197888
At time: 464.1744041442871 and batch: 1000, loss is 3.7635551404953005 and perplexity is 43.10138540218493
At time: 465.21398162841797 and batch: 1050, loss is 3.7087327575683595 and perplexity is 40.80206763964591
At time: 466.25079011917114 and batch: 1100, loss is 3.7220970439910888 and perplexity is 41.351018153794115
At time: 467.29203152656555 and batch: 1150, loss is 3.692479496002197 and perplexity is 40.14426119289339
At time: 468.33681058883667 and batch: 1200, loss is 3.7725419855117797 and perplexity is 43.49047660526963
At time: 469.38280868530273 and batch: 1250, loss is 3.741848659515381 and perplexity is 42.17588699526745
At time: 470.4293215274811 and batch: 1300, loss is 3.753371319770813 and perplexity is 42.66467607925997
At time: 471.47528982162476 and batch: 1350, loss is 3.633086013793945 and perplexity is 37.829378652989725
At time: 472.52163195610046 and batch: 1400, loss is 3.665328335762024 and perplexity is 39.068961794769734
At time: 473.5690882205963 and batch: 1450, loss is 3.584013648033142 and perplexity is 36.01781395077587
At time: 474.6151955127716 and batch: 1500, loss is 3.5913946437835693 and perplexity is 36.2846448098136
At time: 475.66077613830566 and batch: 1550, loss is 3.591436562538147 and perplexity is 36.28616584881413
At time: 476.7062633037567 and batch: 1600, loss is 3.6786305713653564 and perplexity is 39.59213832343646
At time: 477.752347946167 and batch: 1650, loss is 3.6264520025253297 and perplexity is 37.579248728443126
At time: 478.79817819595337 and batch: 1700, loss is 3.6533656120300293 and perplexity is 38.6043750005037
At time: 479.8443031311035 and batch: 1750, loss is 3.6296153926849364 and perplexity is 37.69831478097404
At time: 480.8902745246887 and batch: 1800, loss is 3.595193281173706 and perplexity is 36.42273913735966
At time: 481.9335675239563 and batch: 1850, loss is 3.6235146856307985 and perplexity is 37.46902852135424
At time: 482.97818064689636 and batch: 1900, loss is 3.7009632205963134 and perplexity is 40.486282806099716
At time: 484.0245714187622 and batch: 1950, loss is 3.6255114221572877 and perplexity is 37.543919042652476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.294605911609739 and perplexity of 73.30332076438509
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 487.3672676086426 and batch: 50, loss is 3.7802110147476196 and perplexity is 43.82528854213445
At time: 488.3914587497711 and batch: 100, loss is 3.792784957885742 and perplexity is 44.37982427246974
At time: 489.41605591773987 and batch: 150, loss is 3.8051462507247926 and perplexity is 44.93182094388662
At time: 490.4403636455536 and batch: 200, loss is 3.8023378610610963 and perplexity is 44.80581190643589
At time: 491.46626353263855 and batch: 250, loss is 3.793320574760437 and perplexity is 44.40360122234543
At time: 492.4910080432892 and batch: 300, loss is 3.8052195072174073 and perplexity is 44.935112612062326
At time: 493.53257608413696 and batch: 350, loss is 3.8270070123672486 and perplexity is 45.924879734801245
At time: 494.5711326599121 and batch: 400, loss is 3.7823473453521728 and perplexity is 43.91901392585706
At time: 495.60021233558655 and batch: 450, loss is 3.8207888174057008 and perplexity is 45.64019590609619
At time: 496.6299593448639 and batch: 500, loss is 3.8336886310577394 and perplexity is 46.23275969241951
At time: 497.66211581230164 and batch: 550, loss is 3.8046165561676024 and perplexity is 44.908027105177766
At time: 498.7002248764038 and batch: 600, loss is 3.767114477157593 and perplexity is 43.255071090743336
At time: 499.7376928329468 and batch: 650, loss is 3.784485592842102 and perplexity is 44.01302411985618
At time: 500.78428053855896 and batch: 700, loss is 3.8185089445114135 and perplexity is 45.536260585240065
At time: 501.8350658416748 and batch: 750, loss is 3.7670703601837157 and perplexity is 43.25316284999518
At time: 502.8977792263031 and batch: 800, loss is 3.749987964630127 and perplexity is 42.52057024619309
At time: 503.9429724216461 and batch: 850, loss is 3.7433126544952393 and perplexity is 42.23767750155889
At time: 504.9885952472687 and batch: 900, loss is 3.694643077850342 and perplexity is 40.23121061489494
At time: 506.07590079307556 and batch: 950, loss is 3.808598279953003 and perplexity is 45.08719492653345
At time: 507.12165927886963 and batch: 1000, loss is 3.773439784049988 and perplexity is 43.52953982441846
At time: 508.16768527030945 and batch: 1050, loss is 3.7136971044540403 and perplexity is 41.00512686825839
At time: 509.213107585907 and batch: 1100, loss is 3.724503130912781 and perplexity is 41.45063208960918
At time: 510.25782108306885 and batch: 1150, loss is 3.691942071914673 and perplexity is 40.122692496240155
At time: 511.30164432525635 and batch: 1200, loss is 3.7598495292663574 and perplexity is 42.941963983779964
At time: 512.3455700874329 and batch: 1250, loss is 3.729041748046875 and perplexity is 41.63918820696972
At time: 513.3919606208801 and batch: 1300, loss is 3.742229027748108 and perplexity is 42.1919324142579
At time: 514.4355983734131 and batch: 1350, loss is 3.6247638273239136 and perplexity is 37.515861891748855
At time: 515.4806883335114 and batch: 1400, loss is 3.6489145231246947 and perplexity is 38.43292534713259
At time: 516.5259602069855 and batch: 1450, loss is 3.5671102237701415 and perplexity is 35.41410629833026
At time: 517.5714519023895 and batch: 1500, loss is 3.5666168928146362 and perplexity is 35.396639732184866
At time: 518.6163516044617 and batch: 1550, loss is 3.5634271478652955 and perplexity is 35.28391335914263
At time: 519.6623330116272 and batch: 1600, loss is 3.651113338470459 and perplexity is 38.51752522884234
At time: 520.707991361618 and batch: 1650, loss is 3.5918746471405028 and perplexity is 36.30206574184589
At time: 521.7493894100189 and batch: 1700, loss is 3.6124718236923217 and perplexity is 37.057539402758344
At time: 522.7984209060669 and batch: 1750, loss is 3.5857139587402345 and perplexity is 36.07910751977133
At time: 523.8653953075409 and batch: 1800, loss is 3.551250810623169 and perplexity is 34.856889599492675
At time: 524.9160122871399 and batch: 1850, loss is 3.577501964569092 and perplexity is 35.78403930654648
At time: 525.9563601016998 and batch: 1900, loss is 3.66131751537323 and perplexity is 38.912577031475394
At time: 526.9919919967651 and batch: 1950, loss is 3.5917264652252197 and perplexity is 36.29668683075404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.262865927053053 and perplexity of 71.0132107797281
finished 12 epochs...
Completing Train Step...
At time: 530.2524526119232 and batch: 50, loss is 3.7792176246643066 and perplexity is 43.78177455185997
At time: 531.2910072803497 and batch: 100, loss is 3.7637036657333374 and perplexity is 43.10778752113786
At time: 532.3143072128296 and batch: 150, loss is 3.7618940258026123 and perplexity is 43.02984848957578
At time: 533.3332939147949 and batch: 200, loss is 3.754586362838745 and perplexity is 42.71654700449816
At time: 534.3607122898102 and batch: 250, loss is 3.741194133758545 and perplexity is 42.148290823099565
At time: 535.3942239284515 and batch: 300, loss is 3.751890468597412 and perplexity is 42.601542800657256
At time: 536.4282240867615 and batch: 350, loss is 3.7710754537582396 and perplexity is 43.42674318531618
At time: 537.4599153995514 and batch: 400, loss is 3.729631071090698 and perplexity is 41.663734372206164
At time: 538.4959425926208 and batch: 450, loss is 3.7707979774475096 and perplexity is 43.41469496445533
At time: 539.5321807861328 and batch: 500, loss is 3.7834943294525147 and perplexity is 43.96941723690513
At time: 540.5655286312103 and batch: 550, loss is 3.7551855278015136 and perplexity is 42.74214893191674
At time: 541.6016068458557 and batch: 600, loss is 3.7215904140472413 and perplexity is 41.330073795756284
At time: 542.6399350166321 and batch: 650, loss is 3.7414406728744507 and perplexity is 42.15868330648023
At time: 543.680956363678 and batch: 700, loss is 3.7777872943878172 and perplexity is 43.71919691817074
At time: 544.7375588417053 and batch: 750, loss is 3.7306446743011477 and perplexity is 41.705986276840804
At time: 545.7948043346405 and batch: 800, loss is 3.714089822769165 and perplexity is 41.02123349507024
At time: 546.8348083496094 and batch: 850, loss is 3.7089391136169434 and perplexity is 40.810488261891365
At time: 547.8778638839722 and batch: 900, loss is 3.662953004837036 and perplexity is 38.97627021178523
At time: 548.9170892238617 and batch: 950, loss is 3.7780015754699705 and perplexity is 43.72856611878261
At time: 549.9508829116821 and batch: 1000, loss is 3.7431742906570435 and perplexity is 42.231833738675356
At time: 550.9849915504456 and batch: 1050, loss is 3.685289669036865 and perplexity is 39.856666019931914
At time: 552.0206201076508 and batch: 1100, loss is 3.698974356651306 and perplexity is 40.405841118261726
At time: 553.0541174411774 and batch: 1150, loss is 3.6681608819961546 and perplexity is 39.179783314816184
At time: 554.0915653705597 and batch: 1200, loss is 3.7379076051712037 and perplexity is 42.00999663877638
At time: 555.1352305412292 and batch: 1250, loss is 3.7088709020614625 and perplexity is 40.80770460994678
At time: 556.2127096652985 and batch: 1300, loss is 3.723489146232605 and perplexity is 41.408623085529335
At time: 557.2877373695374 and batch: 1350, loss is 3.60711003780365 and perplexity is 36.85937653908708
At time: 558.3571319580078 and batch: 1400, loss is 3.6347300672531127 and perplexity is 37.89162332658765
At time: 559.4094114303589 and batch: 1450, loss is 3.5545399045944213 and perplexity is 34.97172593515435
At time: 560.4843308925629 and batch: 1500, loss is 3.556358256340027 and perplexity is 35.035374684425186
At time: 561.5815377235413 and batch: 1550, loss is 3.5558441877365112 and perplexity is 35.01736872683278
At time: 562.6529154777527 and batch: 1600, loss is 3.645977063179016 and perplexity is 38.320195818626296
At time: 563.7202117443085 and batch: 1650, loss is 3.588129076957703 and perplexity is 36.16634813540767
At time: 564.7787680625916 and batch: 1700, loss is 3.611623167991638 and perplexity is 37.026103651642295
At time: 565.837925195694 and batch: 1750, loss is 3.5867523336410523 and perplexity is 36.11659061684944
At time: 566.8963551521301 and batch: 1800, loss is 3.5544152879714965 and perplexity is 34.96736814830244
At time: 567.9575049877167 and batch: 1850, loss is 3.5818071126937867 and perplexity is 35.9384269887257
At time: 569.0192515850067 and batch: 1900, loss is 3.6666196155548096 and perplexity is 39.11944334154664
At time: 570.0790503025055 and batch: 1950, loss is 3.596439199447632 and perplexity is 36.46814717511539
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.262836119186047 and perplexity of 71.01109405893314
finished 13 epochs...
Completing Train Step...
At time: 573.4348101615906 and batch: 50, loss is 3.7617534685134886 and perplexity is 43.023800755757165
At time: 574.4219295978546 and batch: 100, loss is 3.744226450920105 and perplexity is 42.27629178036243
At time: 575.4156546592712 and batch: 150, loss is 3.741877303123474 and perplexity is 42.17709508214742
At time: 576.4357845783234 and batch: 200, loss is 3.734052314758301 and perplexity is 41.84834770350322
At time: 577.4632520675659 and batch: 250, loss is 3.7191815853118895 and perplexity is 41.23063653810634
At time: 578.5182580947876 and batch: 300, loss is 3.7292664575576784 and perplexity is 41.64854597993287
At time: 579.5583665370941 and batch: 350, loss is 3.7483163690567016 and perplexity is 42.44955242226678
At time: 580.5888941287994 and batch: 400, loss is 3.7070240926742555 and perplexity is 40.73241010670107
At time: 581.6220331192017 and batch: 450, loss is 3.749002070426941 and perplexity is 42.47867012041064
At time: 582.6626641750336 and batch: 500, loss is 3.7612852382659914 and perplexity is 43.00366042640469
At time: 583.71986079216 and batch: 550, loss is 3.733373031616211 and perplexity is 41.81993047914733
At time: 584.7661170959473 and batch: 600, loss is 3.701329469680786 and perplexity is 40.501113585825124
At time: 585.8100941181183 and batch: 650, loss is 3.7218360614776613 and perplexity is 41.34022766926869
At time: 586.851713180542 and batch: 700, loss is 3.758622636795044 and perplexity is 42.88931111777202
At time: 587.9038259983063 and batch: 750, loss is 3.712678327560425 and perplexity is 40.963373065001605
At time: 588.9592654705048 and batch: 800, loss is 3.6961117792129516 and perplexity is 40.290341661039285
At time: 590.0148684978485 and batch: 850, loss is 3.6920218324661254 and perplexity is 40.12589283194798
At time: 591.074544429779 and batch: 900, loss is 3.6466017723083497 and perplexity is 38.34414227379784
At time: 592.1300013065338 and batch: 950, loss is 3.762280321121216 and perplexity is 43.04647392956559
At time: 593.1819405555725 and batch: 1000, loss is 3.7277461767196653 and perplexity is 41.58527659934791
At time: 594.2388205528259 and batch: 1050, loss is 3.6704735136032105 and perplexity is 39.27049657281157
At time: 595.306688785553 and batch: 1100, loss is 3.685552921295166 and perplexity is 39.867159758459586
At time: 596.3642332553864 and batch: 1150, loss is 3.654979190826416 and perplexity is 38.66671648437432
At time: 597.4381392002106 and batch: 1200, loss is 3.725246253013611 and perplexity is 41.481446418394654
At time: 598.5120820999146 and batch: 1250, loss is 3.697167782783508 and perplexity is 40.33291087835912
At time: 599.6020348072052 and batch: 1300, loss is 3.7123441028594972 and perplexity is 40.949684381565454
At time: 600.6593978404999 and batch: 1350, loss is 3.5962947845458983 and perplexity is 36.46288101149009
At time: 601.7170114517212 and batch: 1400, loss is 3.625277018547058 and perplexity is 37.535119643832424
At time: 602.778356552124 and batch: 1450, loss is 3.545919895172119 and perplexity is 34.671564882240325
At time: 603.8503048419952 and batch: 1500, loss is 3.548496055603027 and perplexity is 34.76099954532585
At time: 604.9273228645325 and batch: 1550, loss is 3.54880898475647 and perplexity is 34.77187897764338
At time: 605.9853596687317 and batch: 1600, loss is 3.6400843143463133 and perplexity is 38.095048549111894
At time: 607.0431597232819 and batch: 1650, loss is 3.582327446937561 and perplexity is 35.957131848922934
At time: 608.1007409095764 and batch: 1700, loss is 3.6069814205169677 and perplexity is 36.854636090946144
At time: 609.1612229347229 and batch: 1750, loss is 3.582936305999756 and perplexity is 35.979031340675164
At time: 610.221816778183 and batch: 1800, loss is 3.5515382385253904 and perplexity is 34.86690988213364
At time: 611.2810971736908 and batch: 1850, loss is 3.579492225646973 and perplexity is 35.85532980700918
At time: 612.3485386371613 and batch: 1900, loss is 3.664714021682739 and perplexity is 39.04496855192416
At time: 613.440746307373 and batch: 1950, loss is 3.594411725997925 and perplexity is 36.39428387819671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.264332757994186 and perplexity of 71.11745158765991
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 616.8585383892059 and batch: 50, loss is 3.7595165157318116 and perplexity is 42.92766610939836
At time: 617.8855335712433 and batch: 100, loss is 3.7592315673828125 and perplexity is 42.91543568441656
At time: 618.90545129776 and batch: 150, loss is 3.761068916320801 and perplexity is 42.99435879704049
At time: 619.9587047100067 and batch: 200, loss is 3.7612114906311036 and perplexity is 43.00048912509615
At time: 620.9920053482056 and batch: 250, loss is 3.7552641677856444 and perplexity is 42.745510305997925
At time: 622.0358972549438 and batch: 300, loss is 3.765257706642151 and perplexity is 43.17483086699251
At time: 623.0805609226227 and batch: 350, loss is 3.791532826423645 and perplexity is 44.32428967378073
At time: 624.1281056404114 and batch: 400, loss is 3.7538811922073365 and perplexity is 42.686435168314475
At time: 625.1676878929138 and batch: 450, loss is 3.79920925617218 and perplexity is 44.66585127916809
At time: 626.2024052143097 and batch: 500, loss is 3.8112371826171874 and perplexity is 45.20633277279789
At time: 627.256382226944 and batch: 550, loss is 3.7837962198257444 and perplexity is 43.98269318452504
At time: 628.2929565906525 and batch: 600, loss is 3.744405059814453 and perplexity is 42.283843376465484
At time: 629.3245785236359 and batch: 650, loss is 3.759143867492676 and perplexity is 42.91167217045416
At time: 630.356725692749 and batch: 700, loss is 3.798491497039795 and perplexity is 44.6338034591903
At time: 631.4020600318909 and batch: 750, loss is 3.748205027580261 and perplexity is 42.44482628953803
At time: 632.4550182819366 and batch: 800, loss is 3.7239341020584105 and perplexity is 41.42705219337522
At time: 633.5366342067719 and batch: 850, loss is 3.720098090171814 and perplexity is 41.268441938641644
At time: 634.5887603759766 and batch: 900, loss is 3.6635100173950197 and perplexity is 38.997986531326426
At time: 635.6847107410431 and batch: 950, loss is 3.7842617893218993 and perplexity is 44.00317495230368
At time: 636.7830667495728 and batch: 1000, loss is 3.744592242240906 and perplexity is 42.29175890966969
At time: 637.8363034725189 and batch: 1050, loss is 3.687718162536621 and perplexity is 39.95357529843219
At time: 638.8851408958435 and batch: 1100, loss is 3.7006928539276123 and perplexity is 40.47533814429188
At time: 639.9581365585327 and batch: 1150, loss is 3.668851194381714 and perplexity is 39.206838941844744
At time: 641.0103254318237 and batch: 1200, loss is 3.734240355491638 and perplexity is 41.85621763740522
At time: 642.0793135166168 and batch: 1250, loss is 3.702914652824402 and perplexity is 40.56536618098991
At time: 643.1281797885895 and batch: 1300, loss is 3.7155109357833864 and perplexity is 41.07957074594473
At time: 644.1794695854187 and batch: 1350, loss is 3.597524676322937 and perplexity is 36.50775399781535
At time: 645.225932598114 and batch: 1400, loss is 3.6228041553497317 and perplexity is 37.44241509792893
At time: 646.2796862125397 and batch: 1450, loss is 3.541837272644043 and perplexity is 34.53030252701642
At time: 647.345461845398 and batch: 1500, loss is 3.547004613876343 and perplexity is 34.70919418208588
At time: 648.430496931076 and batch: 1550, loss is 3.550309805870056 and perplexity is 34.824104528573834
At time: 649.5008218288422 and batch: 1600, loss is 3.645008535385132 and perplexity is 38.2830996111627
At time: 650.5815374851227 and batch: 1650, loss is 3.5793212842941284 and perplexity is 35.849201172258766
At time: 651.6374757289886 and batch: 1700, loss is 3.5965976190567015 and perplexity is 36.473924902374925
At time: 652.6929638385773 and batch: 1750, loss is 3.5716481018066406 and perplexity is 35.575176375265244
At time: 653.7560770511627 and batch: 1800, loss is 3.536197552680969 and perplexity is 34.33610940265963
At time: 654.8168604373932 and batch: 1850, loss is 3.558172745704651 and perplexity is 35.09900370881217
At time: 655.8770728111267 and batch: 1900, loss is 3.649505515098572 and perplexity is 38.455645610630754
At time: 656.9196729660034 and batch: 1950, loss is 3.5921043968200683 and perplexity is 36.310407087991756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.248984261446221 and perplexity of 70.03423972904383
finished 15 epochs...
Completing Train Step...
At time: 660.1993939876556 and batch: 50, loss is 3.7743798303604126 and perplexity is 43.57047884699868
At time: 661.2179656028748 and batch: 100, loss is 3.754446954727173 and perplexity is 42.710592386418064
At time: 662.2283909320831 and batch: 150, loss is 3.746194348335266 and perplexity is 42.35956909941493
At time: 663.2547194957733 and batch: 200, loss is 3.7393807554244995 and perplexity is 42.0719292828105
At time: 664.3067908287048 and batch: 250, loss is 3.728591589927673 and perplexity is 41.620448206619486
At time: 665.3668856620789 and batch: 300, loss is 3.7338856172561647 and perplexity is 41.841372269882356
At time: 666.4353041648865 and batch: 350, loss is 3.7567155838012694 and perplexity is 42.807596870069496
At time: 667.4893593788147 and batch: 400, loss is 3.721054458618164 and perplexity is 41.30792865325605
At time: 668.5146837234497 and batch: 450, loss is 3.7678064584732054 and perplexity is 43.285013150221694
At time: 669.5511045455933 and batch: 500, loss is 3.7803272008895874 and perplexity is 43.830380729145844
At time: 670.5895204544067 and batch: 550, loss is 3.7532327699661256 and perplexity is 42.65876530619982
At time: 671.6292698383331 and batch: 600, loss is 3.7174317979812623 and perplexity is 41.15855477492765
At time: 672.6706314086914 and batch: 650, loss is 3.73457631111145 and perplexity is 41.87028183128478
At time: 673.7170062065125 and batch: 700, loss is 3.774894437789917 and perplexity is 43.59290630929483
At time: 674.7618856430054 and batch: 750, loss is 3.726485252380371 and perplexity is 41.532873756880335
At time: 675.806343793869 and batch: 800, loss is 3.704757881164551 and perplexity is 40.6402063661493
At time: 676.8534207344055 and batch: 850, loss is 3.7021107625961305 and perplexity is 40.5327691834701
At time: 677.8970031738281 and batch: 900, loss is 3.6478311347961427 and perplexity is 38.39131011118028
At time: 678.9431204795837 and batch: 950, loss is 3.7682049036026 and perplexity is 43.30226328927591
At time: 680.0085473060608 and batch: 1000, loss is 3.7290402603149415 and perplexity is 41.63912625906581
At time: 681.0694191455841 and batch: 1050, loss is 3.674028306007385 and perplexity is 39.410343451783184
At time: 682.1226670742035 and batch: 1100, loss is 3.688527750968933 and perplexity is 39.985934347811906
At time: 683.1711752414703 and batch: 1150, loss is 3.6581089687347412 and perplexity is 38.78792429724109
At time: 684.2239458560944 and batch: 1200, loss is 3.725312705039978 and perplexity is 41.48420303615621
At time: 685.2747569084167 and batch: 1250, loss is 3.6957234239578245 and perplexity is 40.274697733021796
At time: 686.3252935409546 and batch: 1300, loss is 3.7088347911834716 and perplexity is 40.80623103451073
At time: 687.3765802383423 and batch: 1350, loss is 3.59154212474823 and perplexity is 36.28999649885895
At time: 688.429013967514 and batch: 1400, loss is 3.6190904569625855 and perplexity is 37.30362313662337
At time: 689.4817609786987 and batch: 1450, loss is 3.539937210083008 and perplexity is 34.46475508380519
At time: 690.5299355983734 and batch: 1500, loss is 3.5465062141418455 and perplexity is 34.691899439126566
At time: 691.5779182910919 and batch: 1550, loss is 3.551209988594055 and perplexity is 34.85546669957365
At time: 692.6835331916809 and batch: 1600, loss is 3.6476724672317506 and perplexity is 38.38521913874378
At time: 693.7700855731964 and batch: 1650, loss is 3.583299226760864 and perplexity is 35.992091247825634
At time: 694.8233749866486 and batch: 1700, loss is 3.6019859313964844 and perplexity is 36.670988244633065
At time: 695.8775553703308 and batch: 1750, loss is 3.578040404319763 and perplexity is 35.803312043887026
At time: 696.9285905361176 and batch: 1800, loss is 3.5439104557037355 and perplexity is 34.601964423709184
At time: 697.9823563098907 and batch: 1850, loss is 3.5657256698608397 and perplexity is 35.365107487585476
At time: 699.033796787262 and batch: 1900, loss is 3.6574849939346312 and perplexity is 38.76372915929424
At time: 700.0823469161987 and batch: 1950, loss is 3.599396367073059 and perplexity is 36.57614921065741
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.24781494140625 and perplexity of 69.95239514962351
finished 16 epochs...
Completing Train Step...
At time: 703.5240414142609 and batch: 50, loss is 3.7716962480545044 and perplexity is 43.453710629542684
At time: 704.5444209575653 and batch: 100, loss is 3.748773627281189 and perplexity is 42.46896726769827
At time: 705.5666131973267 and batch: 150, loss is 3.7388659048080446 and perplexity is 42.05027409915447
At time: 706.5812723636627 and batch: 200, loss is 3.7312344026565554 and perplexity is 41.73058873320855
At time: 707.5991523265839 and batch: 250, loss is 3.718882427215576 and perplexity is 41.21830390416543
At time: 708.6285336017609 and batch: 300, loss is 3.723416738510132 and perplexity is 41.40562488998854
At time: 709.6740803718567 and batch: 350, loss is 3.745593400001526 and perplexity is 42.334120834258826
At time: 710.7221384048462 and batch: 400, loss is 3.7100765895843506 and perplexity is 40.856935622877856
At time: 711.7678217887878 and batch: 450, loss is 3.756664776802063 and perplexity is 42.80542199977908
At time: 712.8146135807037 and batch: 500, loss is 3.769374494552612 and perplexity is 43.352938853598026
At time: 713.860579252243 and batch: 550, loss is 3.7423094797134397 and perplexity is 42.19532697468948
At time: 714.911833524704 and batch: 600, loss is 3.707318549156189 and perplexity is 40.74440579489915
At time: 716.0086796283722 and batch: 650, loss is 3.7250159406661987 and perplexity is 41.47189382917784
At time: 717.0619924068451 and batch: 700, loss is 3.7658443880081176 and perplexity is 43.200168167475205
At time: 718.1137297153473 and batch: 750, loss is 3.717957782745361 and perplexity is 41.180209242112255
At time: 719.2007217407227 and batch: 800, loss is 3.6966072940826415 and perplexity is 40.310311071598555
At time: 720.2519006729126 and batch: 850, loss is 3.694505605697632 and perplexity is 40.225680323904804
At time: 721.304536819458 and batch: 900, loss is 3.6410438919067385 and perplexity is 38.13162124722684
At time: 722.3561406135559 and batch: 950, loss is 3.761625895500183 and perplexity is 43.01831242993946
At time: 723.4077761173248 and batch: 1000, loss is 3.722827115058899 and perplexity is 41.381218358579176
At time: 724.460321187973 and batch: 1050, loss is 3.668591175079346 and perplexity is 39.19664573220809
At time: 725.5203289985657 and batch: 1100, loss is 3.6838306427001952 and perplexity is 39.79855649648797
At time: 726.5743482112885 and batch: 1150, loss is 3.653853554725647 and perplexity is 38.623216319672295
At time: 727.6274034976959 and batch: 1200, loss is 3.7213528108596803 and perplexity is 41.32025480503822
At time: 728.6788642406464 and batch: 1250, loss is 3.692393364906311 and perplexity is 40.14080367258545
At time: 729.7317814826965 and batch: 1300, loss is 3.705689353942871 and perplexity is 40.678079248125634
At time: 730.7873642444611 and batch: 1350, loss is 3.5883503580093383 and perplexity is 36.17435194847031
At time: 731.8387234210968 and batch: 1400, loss is 3.6167968797683714 and perplexity is 37.21816244015167
At time: 732.8926148414612 and batch: 1450, loss is 3.5381800985336302 and perplexity is 34.40424983740178
At time: 733.9455988407135 and batch: 1500, loss is 3.5452524280548094 and perplexity is 34.64843047436291
At time: 734.9995918273926 and batch: 1550, loss is 3.5505453395843505 and perplexity is 34.832307745289555
At time: 736.0498435497284 and batch: 1600, loss is 3.6476599311828615 and perplexity is 38.38473794277619
At time: 737.1028215885162 and batch: 1650, loss is 3.583703064918518 and perplexity is 36.00662916293012
At time: 738.1630322933197 and batch: 1700, loss is 3.6030267477035522 and perplexity is 36.70917587690219
At time: 739.2190041542053 and batch: 1750, loss is 3.579366765022278 and perplexity is 35.85083165710919
At time: 740.2756507396698 and batch: 1800, loss is 3.5457565450668334 and perplexity is 34.665901741016334
At time: 741.3286218643188 and batch: 1850, loss is 3.56738872051239 and perplexity is 35.42397038505824
At time: 742.3786771297455 and batch: 1900, loss is 3.659203777313232 and perplexity is 38.83041290370507
At time: 743.4308996200562 and batch: 1950, loss is 3.6005856657028197 and perplexity is 36.6196750522771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.247716433502907 and perplexity of 69.94550462523465
finished 17 epochs...
Completing Train Step...
At time: 746.897451877594 and batch: 50, loss is 3.7671618700027465 and perplexity is 43.25712112020763
At time: 747.9130039215088 and batch: 100, loss is 3.743132348060608 and perplexity is 42.23006246306233
At time: 748.9381859302521 and batch: 150, loss is 3.732776985168457 and perplexity is 41.79501128537614
At time: 749.9916977882385 and batch: 200, loss is 3.724924726486206 and perplexity is 41.46811117690785
At time: 751.0215151309967 and batch: 250, loss is 3.7119366359710693 and perplexity is 40.93300214004972
At time: 752.0500359535217 and batch: 300, loss is 3.7163014078140257 and perplexity is 41.1120558352358
At time: 753.0754249095917 and batch: 350, loss is 3.738259162902832 and perplexity is 42.02476817427203
At time: 754.1057624816895 and batch: 400, loss is 3.7028531217575074 and perplexity is 40.56287022751995
At time: 755.147278547287 and batch: 450, loss is 3.7493427896499636 and perplexity is 42.49314588583483
At time: 756.1973915100098 and batch: 500, loss is 3.7621794080734254 and perplexity is 43.04213019785802
At time: 757.2455155849457 and batch: 550, loss is 3.735116648674011 and perplexity is 41.89291203073604
At time: 758.2998127937317 and batch: 600, loss is 3.7006433963775636 and perplexity is 40.4733363827314
At time: 759.3510444164276 and batch: 650, loss is 3.718661675453186 and perplexity is 41.209205895173554
At time: 760.4011559486389 and batch: 700, loss is 3.759785842895508 and perplexity is 42.93922925302015
At time: 761.4760961532593 and batch: 750, loss is 3.712209215164185 and perplexity is 40.94416114553212
At time: 762.5315239429474 and batch: 800, loss is 3.6909966325759886 and perplexity is 40.084776850675965
At time: 763.5849449634552 and batch: 850, loss is 3.689244713783264 and perplexity is 40.014613055390534
At time: 764.6597621440887 and batch: 900, loss is 3.6361950397491456 and perplexity is 37.94717419290176
At time: 765.737683057785 and batch: 950, loss is 3.7570185470581055 and perplexity is 42.82056796381777
At time: 766.7876305580139 and batch: 1000, loss is 3.718408145904541 and perplexity is 41.19875946809787
At time: 767.8829720020294 and batch: 1050, loss is 3.664601969718933 and perplexity is 39.04059373162934
At time: 768.9318509101868 and batch: 1100, loss is 3.680304970741272 and perplexity is 39.65848690664822
At time: 769.9776740074158 and batch: 1150, loss is 3.6505302143096925 and perplexity is 38.49507127662575
At time: 771.0256597995758 and batch: 1200, loss is 3.718164348602295 and perplexity is 41.18871654595206
At time: 772.0728623867035 and batch: 1250, loss is 3.689533038139343 and perplexity is 40.026151906319434
At time: 773.1204609870911 and batch: 1300, loss is 3.702967395782471 and perplexity is 40.56750577482121
At time: 774.1698455810547 and batch: 1350, loss is 3.58552047252655 and perplexity is 36.0721273851659
At time: 775.2156126499176 and batch: 1400, loss is 3.6145213079452514 and perplexity is 37.13356612739229
At time: 776.2593510150909 and batch: 1450, loss is 3.5361683845520018 and perplexity is 34.33510789719843
At time: 777.3020858764648 and batch: 1500, loss is 3.5435374641418456 and perplexity is 34.58906058961454
At time: 778.345344543457 and batch: 1550, loss is 3.549130048751831 and perplexity is 34.78304476840494
At time: 779.3915677070618 and batch: 1600, loss is 3.646648941040039 and perplexity is 38.345950961013024
At time: 780.4346761703491 and batch: 1650, loss is 3.5828777313232423 and perplexity is 35.97692394227381
At time: 781.4795875549316 and batch: 1700, loss is 3.6026330041885375 and perplexity is 36.69472472217005
At time: 782.5090584754944 and batch: 1750, loss is 3.5791291904449465 and perplexity is 35.84231542259174
At time: 783.541995048523 and batch: 1800, loss is 3.5458542108535767 and perplexity is 34.66928757892061
At time: 784.5771286487579 and batch: 1850, loss is 3.567354326248169 and perplexity is 35.42275202461348
At time: 785.6044251918793 and batch: 1900, loss is 3.6592574453353883 and perplexity is 38.83249691108689
At time: 786.62957072258 and batch: 1950, loss is 3.60025324344635 and perplexity is 36.60750388036134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2479497865188955 and perplexity of 69.96182852423524
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 789.9835646152496 and batch: 50, loss is 3.7676032114028932 and perplexity is 43.27621649208827
At time: 791.0045523643494 and batch: 100, loss is 3.749718050956726 and perplexity is 42.50909491162736
At time: 792.0357813835144 and batch: 150, loss is 3.740641574859619 and perplexity is 42.12500784313204
At time: 793.0674612522125 and batch: 200, loss is 3.734110617637634 and perplexity is 41.85078765379705
At time: 794.1118121147156 and batch: 250, loss is 3.723581566810608 and perplexity is 41.41245027126185
At time: 795.1422982215881 and batch: 300, loss is 3.724790244102478 and perplexity is 41.462534821437266
At time: 796.1810591220856 and batch: 350, loss is 3.747933235168457 and perplexity is 42.43329167541348
At time: 797.2239153385162 and batch: 400, loss is 3.714716854095459 and perplexity is 41.0469631593246
At time: 798.2655258178711 and batch: 450, loss is 3.7640060138702394 and perplexity is 43.12082305091561
At time: 799.3120005130768 and batch: 500, loss is 3.7781386756896973 and perplexity is 43.734561725795956
At time: 800.3832840919495 and batch: 550, loss is 3.751640019416809 and perplexity is 42.59087461514534
At time: 801.4328107833862 and batch: 600, loss is 3.7147795867919924 and perplexity is 41.04953822677771
At time: 802.4793381690979 and batch: 650, loss is 3.7319863080978393 and perplexity is 41.76197798934241
At time: 803.5257375240326 and batch: 700, loss is 3.7728768396377563 and perplexity is 43.50504200930831
At time: 804.5713167190552 and batch: 750, loss is 3.724233798980713 and perplexity is 41.43946961405608
At time: 805.6159722805023 and batch: 800, loss is 3.7009460592269896 and perplexity is 40.48558801200976
At time: 806.6625046730042 and batch: 850, loss is 3.7011455297470093 and perplexity is 40.493664498787545
At time: 807.7108116149902 and batch: 900, loss is 3.646932077407837 and perplexity is 38.356809631457594
At time: 808.7561869621277 and batch: 950, loss is 3.7702038383483885 and perplexity is 43.3889082579044
At time: 809.8084571361542 and batch: 1000, loss is 3.7286947059631346 and perplexity is 41.624740163513664
At time: 810.8711524009705 and batch: 1050, loss is 3.675403051376343 and perplexity is 39.46455989729751
At time: 811.9330718517303 and batch: 1100, loss is 3.688454089164734 and perplexity is 39.982989020225666
At time: 812.9852294921875 and batch: 1150, loss is 3.6582950925827027 and perplexity is 38.79514432685474
At time: 814.0340054035187 and batch: 1200, loss is 3.724311194419861 and perplexity is 41.442676964120444
At time: 815.0826964378357 and batch: 1250, loss is 3.693881311416626 and perplexity is 40.20057549894371
At time: 816.1353154182434 and batch: 1300, loss is 3.7040205430984496 and perplexity is 40.610251839644754
At time: 817.2012414932251 and batch: 1350, loss is 3.5811758279800414 and perplexity is 35.915746768722975
At time: 818.2634122371674 and batch: 1400, loss is 3.607513871192932 and perplexity is 36.87426459198578
At time: 819.3137769699097 and batch: 1450, loss is 3.525893979072571 and perplexity is 33.98414115124319
At time: 820.363201379776 and batch: 1500, loss is 3.5332594299316407 and perplexity is 34.23537375781238
At time: 821.4422748088837 and batch: 1550, loss is 3.539722065925598 and perplexity is 34.45734099069035
At time: 822.5184609889984 and batch: 1600, loss is 3.6358703422546386 and perplexity is 37.934854840657344
At time: 823.5811495780945 and batch: 1650, loss is 3.569858374595642 and perplexity is 35.51156345593671
At time: 824.6321437358856 and batch: 1700, loss is 3.5896287393569946 and perplexity is 36.22062613699253
At time: 825.6836967468262 and batch: 1750, loss is 3.5686949157714842 and perplexity is 35.470271239628865
At time: 826.7363650798798 and batch: 1800, loss is 3.533180150985718 and perplexity is 34.232659721052
At time: 827.7880017757416 and batch: 1850, loss is 3.5538475799560545 and perplexity is 34.94752252691791
At time: 828.8426887989044 and batch: 1900, loss is 3.646231746673584 and perplexity is 38.32995658290993
At time: 829.8933987617493 and batch: 1950, loss is 3.591955690383911 and perplexity is 36.30500789821536
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.245120310228924 and perplexity of 69.76415298023677
finished 19 epochs...
Completing Train Step...
At time: 833.2874989509583 and batch: 50, loss is 3.767985215187073 and perplexity is 43.2927513285372
At time: 834.3021168708801 and batch: 100, loss is 3.7463518524169923 and perplexity is 42.366241429894096
At time: 835.3383202552795 and batch: 150, loss is 3.7359105730056763 and perplexity is 41.92618503929939
At time: 836.3807837963104 and batch: 200, loss is 3.7276848363876343 and perplexity is 41.58272582290723
At time: 837.4124944210052 and batch: 250, loss is 3.716831827163696 and perplexity is 41.13386824950744
At time: 838.4459939002991 and batch: 300, loss is 3.7173653268814086 and perplexity is 41.15581901144898
At time: 839.5105431079865 and batch: 350, loss is 3.73930878162384 and perplexity is 42.06890131512743
At time: 840.5567579269409 and batch: 400, loss is 3.7056998682022093 and perplexity is 40.67850695024872
At time: 841.6016137599945 and batch: 450, loss is 3.7553839015960695 and perplexity is 42.75062869524144
At time: 842.6683876514435 and batch: 500, loss is 3.76875253200531 and perplexity is 43.32598333284673
At time: 843.7144801616669 and batch: 550, loss is 3.7424071550369264 and perplexity is 42.199448618189514
At time: 844.7663979530334 and batch: 600, loss is 3.7065358400344848 and perplexity is 40.712527254264835
At time: 845.833212852478 and batch: 650, loss is 3.7242761754989626 and perplexity is 41.441225711704824
At time: 846.8970634937286 and batch: 700, loss is 3.765690975189209 and perplexity is 43.19354121624195
At time: 847.9416100978851 and batch: 750, loss is 3.717589030265808 and perplexity is 41.16502673731089
At time: 848.9846856594086 and batch: 800, loss is 3.695137128829956 and perplexity is 40.25109179466407
At time: 850.0308735370636 and batch: 850, loss is 3.6949485826492308 and perplexity is 40.24350332044756
At time: 851.0640277862549 and batch: 900, loss is 3.6410304498672486 and perplexity is 38.131108683913176
At time: 852.08247590065 and batch: 950, loss is 3.7637453651428223 and perplexity is 43.109585127901006
At time: 853.1038801670074 and batch: 1000, loss is 3.722451171875 and perplexity is 41.36566429550102
At time: 854.1275706291199 and batch: 1050, loss is 3.6695342302322387 and perplexity is 39.23362776625001
At time: 855.1515634059906 and batch: 1100, loss is 3.6830520677566527 and perplexity is 39.76758239700417
At time: 856.1735289096832 and batch: 1150, loss is 3.65363965511322 and perplexity is 38.61495571217271
At time: 857.2054541110992 and batch: 1200, loss is 3.720525689125061 and perplexity is 41.286092054533334
At time: 858.2536578178406 and batch: 1250, loss is 3.690815658569336 and perplexity is 40.07752320438404
At time: 859.3055324554443 and batch: 1300, loss is 3.7017949295043944 and perplexity is 40.519969615032295
At time: 860.3745324611664 and batch: 1350, loss is 3.5799327087402344 and perplexity is 35.87112695252482
At time: 861.4431402683258 and batch: 1400, loss is 3.6073032093048094 and perplexity is 36.86649740793725
At time: 862.4950077533722 and batch: 1450, loss is 3.5265847396850587 and perplexity is 34.007624167037136
At time: 863.5465877056122 and batch: 1500, loss is 3.534693007469177 and perplexity is 34.284488016758544
At time: 864.5986750125885 and batch: 1550, loss is 3.542000579833984 and perplexity is 34.535942034163426
At time: 865.6485862731934 and batch: 1600, loss is 3.639135856628418 and perplexity is 38.05893413550634
At time: 866.6994919776917 and batch: 1650, loss is 3.573492226600647 and perplexity is 35.64084196923539
At time: 867.7499933242798 and batch: 1700, loss is 3.5937181425094606 and perplexity is 36.36905015568253
At time: 868.7980406284332 and batch: 1750, loss is 3.573243441581726 and perplexity is 35.63197616457713
At time: 869.8490166664124 and batch: 1800, loss is 3.537556071281433 and perplexity is 34.38278734519834
At time: 870.9006831645966 and batch: 1850, loss is 3.5578768396377565 and perplexity is 35.08861923716264
At time: 871.9532499313354 and batch: 1900, loss is 3.6503571224212648 and perplexity is 38.48840866868165
At time: 873.0062620639801 and batch: 1950, loss is 3.5960046100616454 and perplexity is 36.45230194875948
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.244433309865553 and perplexity of 69.71624144129576
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fd78797ab38>
ELAPSED
5389.179709434509


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.58572924558682}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.5545691141662139, 'dropout': 0.7795352401135597, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.01716348977908}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.30559750332649016, 'dropout': 0.7036453025474743, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -69.20731299479563}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.2784456490206031, 'dropout': 0.9440744352266794, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -71.65749186356365}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.7972956216277209, 'dropout': 0.16004583408284256, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.20333800493943}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.31612970171994975, 'dropout': 0.6964694918509416, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -69.71624144129576}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.8293866707113604, 'dropout': 0.48240368287173163, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.58572924558682}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.5545691141662139, 'dropout': 0.7795352401135597, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.01716348977908}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.30559750332649016, 'dropout': 0.7036453025474743, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -69.20731299479563}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.2784456490206031, 'dropout': 0.9440744352266794, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -71.65749186356365}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.7972956216277209, 'dropout': 0.16004583408284256, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -70.20333800493943}, {'params': {'wordvec_dim': 300, 'batch_size': 32, 'num_layers': 3, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'rnn_dropout': 0.31612970171994975, 'dropout': 0.6964694918509416, 'data': 'wikitext', 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -69.71624144129576}]
