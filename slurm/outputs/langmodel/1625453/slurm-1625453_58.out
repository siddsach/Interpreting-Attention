Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6629469394683838 and batch: 50, loss is 8.827834396362304 and perplexity is 6821.49814700373
At time: 2.650967597961426 and batch: 100, loss is 7.815189552307129 and perplexity is 2477.9566108923764
At time: 3.642216920852661 and batch: 150, loss is 7.509512414932251 and perplexity is 1825.3233254086056
At time: 4.638186693191528 and batch: 200, loss is 7.400094814300537 and perplexity is 1636.1395520691258
At time: 5.64233660697937 and batch: 250, loss is 7.305035247802734 and perplexity is 1487.7724016336597
At time: 6.64544415473938 and batch: 300, loss is 7.175412168502808 and perplexity is 1306.8986524558663
At time: 7.644841909408569 and batch: 350, loss is 7.130973739624023 and perplexity is 1250.093640166813
At time: 8.65062952041626 and batch: 400, loss is 7.082939615249634 and perplexity is 1191.4658267340315
At time: 9.643121004104614 and batch: 450, loss is 6.997592926025391 and perplexity is 1093.9966556946615
At time: 10.626524448394775 and batch: 500, loss is 6.977880992889404 and perplexity is 1072.6430189235657
At time: 11.610976934432983 and batch: 550, loss is 6.937263069152832 and perplexity is 1029.947458907151
At time: 12.595294713973999 and batch: 600, loss is 6.973783073425293 and perplexity is 1068.2564083453838
At time: 13.580006837844849 and batch: 650, loss is 7.039268913269043 and perplexity is 1140.5534582494427
At time: 14.566442489624023 and batch: 700, loss is 6.913702764511108 and perplexity is 1005.9652069362149
At time: 15.557940244674683 and batch: 750, loss is 6.873809604644776 and perplexity is 966.6240157013199
At time: 16.54327082633972 and batch: 800, loss is 6.865115222930908 and perplexity is 958.2562465361202
At time: 17.53425645828247 and batch: 850, loss is 6.891049909591675 and perplexity is 983.433391534141
At time: 18.521397590637207 and batch: 900, loss is 6.876791000366211 and perplexity is 969.5102047038632
At time: 19.509817838668823 and batch: 950, loss is 6.884198589324951 and perplexity is 976.7186032565797
At time: 20.498661994934082 and batch: 1000, loss is 6.8750636100769045 and perplexity is 967.8369278080759
At time: 21.489288806915283 and batch: 1050, loss is 6.787687110900879 and perplexity is 886.8599791134205
At time: 22.480592489242554 and batch: 1100, loss is 6.837415618896484 and perplexity is 932.077176719787
At time: 23.468068599700928 and batch: 1150, loss is 6.753851699829101 and perplexity is 857.3546838909506
At time: 24.45679473876953 and batch: 1200, loss is 6.840065174102783 and perplexity is 934.5500412048675
At time: 25.44373846054077 and batch: 1250, loss is 6.761063661575317 and perplexity is 863.5602433055244
At time: 26.43827724456787 and batch: 1300, loss is 6.7826713180541995 and perplexity is 882.4228104362187
At time: 27.425148487091064 and batch: 1350, loss is 6.8005170726776125 and perplexity is 898.3116640003793
At time: 28.420002460479736 and batch: 1400, loss is 6.824227142333984 and perplexity is 919.865204383514
At time: 29.40730047225952 and batch: 1450, loss is 6.821274147033692 and perplexity is 917.1528535087755
At time: 30.405582427978516 and batch: 1500, loss is 6.792766284942627 and perplexity is 891.3759543013797
At time: 31.392051935195923 and batch: 1550, loss is 6.761696033477783 and perplexity is 864.1065072422558
At time: 32.382283449172974 and batch: 1600, loss is 6.74512167930603 and perplexity is 849.9025359366354
At time: 33.38266134262085 and batch: 1650, loss is 6.74073203086853 and perplexity is 846.1799390211629
At time: 34.38178038597107 and batch: 1700, loss is 6.762349281311035 and perplexity is 864.6711673572295
At time: 35.372764348983765 and batch: 1750, loss is 6.787235889434815 and perplexity is 886.4598991225795
At time: 36.37066459655762 and batch: 1800, loss is 6.787069902420044 and perplexity is 886.3127705012686
At time: 37.361236333847046 and batch: 1850, loss is 6.72517424583435 and perplexity is 833.1171310893711
At time: 38.351019859313965 and batch: 1900, loss is 6.6668017482757564 and perplexity is 785.878144742105
At time: 39.343459367752075 and batch: 1950, loss is 6.6252428150177005 and perplexity is 753.8872454769455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.130337595385174 and perplexity of 459.5912903916259
finished 1 epochs...
Completing Train Step...
At time: 42.56458306312561 and batch: 50, loss is 6.305305480957031 and perplexity is 547.4688039371363
At time: 43.5826690196991 and batch: 100, loss is 6.013039464950562 and perplexity is 408.7237356884519
At time: 44.56865572929382 and batch: 150, loss is 5.811735897064209 and perplexity is 334.1987570800658
At time: 45.56177020072937 and batch: 200, loss is 5.719042100906372 and perplexity is 304.6129946488184
At time: 46.55717921257019 and batch: 250, loss is 5.689492063522339 and perplexity is 295.74336364078954
At time: 47.54751396179199 and batch: 300, loss is 5.659367408752441 and perplexity is 286.96705228029015
At time: 48.53325319290161 and batch: 350, loss is 5.61104097366333 and perplexity is 273.4287220072978
At time: 49.556349754333496 and batch: 400, loss is 5.544711399078369 and perplexity is 255.8807201743605
At time: 50.552562952041626 and batch: 450, loss is 5.445294151306152 and perplexity is 231.66541437491185
At time: 51.541258096694946 and batch: 500, loss is 5.438513860702515 and perplexity is 230.09996862844307
At time: 52.53235197067261 and batch: 550, loss is 5.396597032546997 and perplexity is 220.65425788693912
At time: 53.51627993583679 and batch: 600, loss is 5.38348310470581 and perplexity is 217.77950472265104
At time: 54.50436544418335 and batch: 650, loss is 5.444265565872192 and perplexity is 231.4272492117404
At time: 55.48796987533569 and batch: 700, loss is 5.393184413909912 and perplexity is 219.9025324597707
At time: 56.47566819190979 and batch: 750, loss is 5.313882064819336 and perplexity is 203.13729181813562
At time: 57.46103024482727 and batch: 800, loss is 5.309162464141846 and perplexity is 202.18082376709174
At time: 58.44822311401367 and batch: 850, loss is 5.313298501968384 and perplexity is 203.01878302301583
At time: 59.43843412399292 and batch: 900, loss is 5.327104997634888 and perplexity is 205.84119998100013
At time: 60.425190448760986 and batch: 950, loss is 5.336666393280029 and perplexity is 207.81876822448638
At time: 61.4088819026947 and batch: 1000, loss is 5.311783638000488 and perplexity is 202.71147001128122
At time: 62.395262002944946 and batch: 1050, loss is 5.208694763183594 and perplexity is 182.855232983733
At time: 63.382256507873535 and batch: 1100, loss is 5.282749128341675 and perplexity is 196.9104640750017
At time: 64.37187337875366 and batch: 1150, loss is 5.184086961746216 and perplexity is 178.4104798092921
At time: 65.37336540222168 and batch: 1200, loss is 5.245519819259644 and perplexity is 189.71440680488888
At time: 66.37866401672363 and batch: 1250, loss is 5.209028949737549 and perplexity is 182.9163509557499
At time: 67.37475347518921 and batch: 1300, loss is 5.221028509140015 and perplexity is 185.12448841740553
At time: 68.36013889312744 and batch: 1350, loss is 5.1713065338134765 and perplexity is 176.1448263789479
At time: 69.34934663772583 and batch: 1400, loss is 5.149547052383423 and perplexity is 172.3534055697775
At time: 70.33760476112366 and batch: 1450, loss is 5.105719070434571 and perplexity is 164.96264765661792
At time: 71.33040642738342 and batch: 1500, loss is 5.068829717636109 and perplexity is 158.98815739217582
At time: 72.31799530982971 and batch: 1550, loss is 5.0645800304412845 and perplexity is 158.3139410744898
At time: 73.30393314361572 and batch: 1600, loss is 5.112917156219482 and perplexity is 166.1543467766054
At time: 74.29083800315857 and batch: 1650, loss is 5.100096168518067 and perplexity is 164.03768180215036
At time: 75.27753758430481 and batch: 1700, loss is 5.1016881561279295 and perplexity is 164.29903574004695
At time: 76.26846837997437 and batch: 1750, loss is 5.097703189849853 and perplexity is 163.64561242273908
At time: 77.26154661178589 and batch: 1800, loss is 5.064466600418091 and perplexity is 158.29598453890623
At time: 78.25167393684387 and batch: 1850, loss is 5.0468528270721436 and perplexity is 155.53220667773206
At time: 79.25540971755981 and batch: 1900, loss is 5.127155036926269 and perplexity is 168.53695393366723
At time: 80.2411150932312 and batch: 1950, loss is 5.050909252166748 and perplexity is 156.16439276480978
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.811210596838663 and perplexity of 122.88028599607411
finished 2 epochs...
Completing Train Step...
At time: 83.46722435951233 and batch: 50, loss is 5.060114965438843 and perplexity is 157.60863482771452
At time: 84.4842483997345 and batch: 100, loss is 5.004584312438965 and perplexity is 149.09509329937794
At time: 85.47419786453247 and batch: 150, loss is 4.93042387008667 and perplexity is 138.43817970864242
At time: 86.473717212677 and batch: 200, loss is 4.9094004058837895 and perplexity is 135.55811019086073
At time: 87.4636869430542 and batch: 250, loss is 4.920904350280762 and perplexity is 137.12656757881604
At time: 88.4550268650055 and batch: 300, loss is 4.9513888263702395 and perplexity is 141.37116764910692
At time: 89.44760346412659 and batch: 350, loss is 4.955973949432373 and perplexity is 142.02086017207486
At time: 90.43823528289795 and batch: 400, loss is 4.901428546905517 and perplexity is 134.48175602510244
At time: 91.43377375602722 and batch: 450, loss is 4.874822053909302 and perplexity is 130.95084894578517
At time: 92.42861700057983 and batch: 500, loss is 4.888118257522583 and perplexity is 132.70362490718182
At time: 93.4229691028595 and batch: 550, loss is 4.850056228637695 and perplexity is 127.74757271606812
At time: 94.43430089950562 and batch: 600, loss is 4.811086263656616 and perplexity is 122.86500884885324
At time: 95.43678617477417 and batch: 650, loss is 4.887386226654053 and perplexity is 132.60651730460165
At time: 96.42733192443848 and batch: 700, loss is 4.90872220993042 and perplexity is 135.46620639699597
At time: 97.42604660987854 and batch: 750, loss is 4.848861598968506 and perplexity is 127.59505279608439
At time: 98.41946935653687 and batch: 800, loss is 4.841706047058105 and perplexity is 126.68529855091576
At time: 99.47091126441956 and batch: 850, loss is 4.857848310470581 and perplexity is 128.74688054460816
At time: 100.46823811531067 and batch: 900, loss is 4.846319875717163 and perplexity is 127.27115328946527
At time: 101.46260976791382 and batch: 950, loss is 4.89791485786438 and perplexity is 134.01005813787145
At time: 102.4584002494812 and batch: 1000, loss is 4.878658571243286 and perplexity is 131.45420910524675
At time: 103.4482741355896 and batch: 1050, loss is 4.8007226657867434 and perplexity is 121.59826067700814
At time: 104.43887233734131 and batch: 1100, loss is 4.858389558792115 and perplexity is 128.8165834391913
At time: 105.43404960632324 and batch: 1150, loss is 4.795088596343994 and perplexity is 120.91509394377535
At time: 106.43251132965088 and batch: 1200, loss is 4.856881074905395 and perplexity is 128.62241218765323
At time: 107.42404794692993 and batch: 1250, loss is 4.83659369468689 and perplexity is 126.03929137962875
At time: 108.41560697555542 and batch: 1300, loss is 4.8399866008758545 and perplexity is 126.46765716292325
At time: 109.40687155723572 and batch: 1350, loss is 4.754463701248169 and perplexity is 116.10137144449605
At time: 110.39808249473572 and batch: 1400, loss is 4.742820434570312 and perplexity is 114.75741144033691
At time: 111.39061212539673 and batch: 1450, loss is 4.694840669631958 and perplexity is 109.38137947790295
At time: 112.39146280288696 and batch: 1500, loss is 4.685690803527832 and perplexity is 108.38511927569286
At time: 113.39797878265381 and batch: 1550, loss is 4.694504880905152 and perplexity is 109.3446566096594
At time: 114.39529800415039 and batch: 1600, loss is 4.759901056289673 and perplexity is 116.73437519536003
At time: 115.38699340820312 and batch: 1650, loss is 4.739382009506226 and perplexity is 114.36350427876874
At time: 116.37683582305908 and batch: 1700, loss is 4.736411714553833 and perplexity is 114.02431493484875
At time: 117.36719298362732 and batch: 1750, loss is 4.728747987747193 and perplexity is 113.15380367672539
At time: 118.35845351219177 and batch: 1800, loss is 4.700244808197022 and perplexity is 109.97409171607295
At time: 119.348956823349 and batch: 1850, loss is 4.712283782958984 and perplexity is 111.30606876205121
At time: 120.33984136581421 and batch: 1900, loss is 4.81286190032959 and perplexity is 123.08336626874052
At time: 121.33044409751892 and batch: 1950, loss is 4.746130027770996 and perplexity is 115.13784097521904
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.632084620276163 and perplexity of 102.72798990668582
finished 3 epochs...
Completing Train Step...
At time: 124.56557393074036 and batch: 50, loss is 4.758944263458252 and perplexity is 116.6227379973447
At time: 125.56492710113525 and batch: 100, loss is 4.703678035736084 and perplexity is 110.3523066738371
At time: 126.54969477653503 and batch: 150, loss is 4.64396222114563 and perplexity is 103.9554270428483
At time: 127.53580141067505 and batch: 200, loss is 4.6350461292266845 and perplexity is 103.03267070303185
At time: 128.5184986591339 and batch: 250, loss is 4.640338315963745 and perplexity is 103.57938421541581
At time: 129.50237226486206 and batch: 300, loss is 4.6813898849487305 and perplexity is 107.91996471547868
At time: 130.48878049850464 and batch: 350, loss is 4.689779424667359 and perplexity is 108.82917212891907
At time: 131.47312664985657 and batch: 400, loss is 4.628901071548462 and perplexity is 102.40147036632524
At time: 132.4587140083313 and batch: 450, loss is 4.625099334716797 and perplexity is 102.01290600254339
At time: 133.4426817893982 and batch: 500, loss is 4.647790956497192 and perplexity is 104.35420778716974
At time: 134.42900228500366 and batch: 550, loss is 4.606604928970337 and perplexity is 100.14357727183682
At time: 135.4204957485199 and batch: 600, loss is 4.574579486846924 and perplexity is 96.9872461478544
At time: 136.4074580669403 and batch: 650, loss is 4.647414464950561 and perplexity is 104.31492670504416
At time: 137.39408946037292 and batch: 700, loss is 4.674109573364258 and perplexity is 107.13712685565693
At time: 138.37931418418884 and batch: 750, loss is 4.622028408050537 and perplexity is 101.70011237815757
At time: 139.36948132514954 and batch: 800, loss is 4.617272663116455 and perplexity is 101.21760084422884
At time: 140.35615396499634 and batch: 850, loss is 4.635531425476074 and perplexity is 103.08268420638987
At time: 141.34299778938293 and batch: 900, loss is 4.608385000228882 and perplexity is 100.32199872980793
At time: 142.34015607833862 and batch: 950, loss is 4.673319301605225 and perplexity is 107.05249285629341
At time: 143.34467577934265 and batch: 1000, loss is 4.65280029296875 and perplexity is 104.87826461883273
At time: 144.33135724067688 and batch: 1050, loss is 4.596715898513794 and perplexity is 99.15813495148866
At time: 145.31993412971497 and batch: 1100, loss is 4.640483484268189 and perplexity is 103.59442175045804
At time: 146.31822109222412 and batch: 1150, loss is 4.584676456451416 and perplexity is 97.97148397212285
At time: 147.30777788162231 and batch: 1200, loss is 4.644767799377441 and perplexity is 104.03920501227624
At time: 148.2947804927826 and batch: 1250, loss is 4.6352652740478515 and perplexity is 103.05525225345197
At time: 149.29134941101074 and batch: 1300, loss is 4.628861293792725 and perplexity is 102.39739714666217
At time: 150.28399777412415 and batch: 1350, loss is 4.529597396850586 and perplexity is 92.72122370986114
At time: 151.27089428901672 and batch: 1400, loss is 4.5317839336395265 and perplexity is 92.92418388570216
At time: 152.25726461410522 and batch: 1450, loss is 4.483543777465821 and perplexity is 88.54791141676597
At time: 153.24474024772644 and batch: 1500, loss is 4.483088779449463 and perplexity is 88.50763145706449
At time: 154.23155164718628 and batch: 1550, loss is 4.491318998336792 and perplexity is 89.23907447645374
At time: 155.21774077415466 and batch: 1600, loss is 4.565558986663818 and perplexity is 96.11630673642411
At time: 156.20377254486084 and batch: 1650, loss is 4.534975996017456 and perplexity is 93.22127759564688
At time: 157.18960618972778 and batch: 1700, loss is 4.53126314163208 and perplexity is 92.87580231289776
At time: 158.17887210845947 and batch: 1750, loss is 4.533158044815064 and perplexity is 93.05195981431758
At time: 159.1712200641632 and batch: 1800, loss is 4.502849283218384 and perplexity is 90.27398134759996
At time: 160.16213417053223 and batch: 1850, loss is 4.525141086578369 and perplexity is 92.30894846366833
At time: 161.15648412704468 and batch: 1900, loss is 4.6303791904449465 and perplexity is 102.55294383502097
At time: 162.14936089515686 and batch: 1950, loss is 4.564007263183594 and perplexity is 95.96727646321935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.565674395893895 and perplexity of 96.12740008550749
finished 4 epochs...
Completing Train Step...
At time: 165.38613104820251 and batch: 50, loss is 4.574131517410279 and perplexity is 96.943808555919
At time: 166.39751386642456 and batch: 100, loss is 4.520569334030151 and perplexity is 91.88789799594225
At time: 167.3839840888977 and batch: 150, loss is 4.471294708251953 and perplexity is 87.4698977319018
At time: 168.36952996253967 and batch: 200, loss is 4.463560228347778 and perplexity is 86.79597315336203
At time: 169.36475729942322 and batch: 250, loss is 4.464084920883178 and perplexity is 86.8415263022319
At time: 170.35090017318726 and batch: 300, loss is 4.502601413726807 and perplexity is 90.25160795469598
At time: 171.33902740478516 and batch: 350, loss is 4.512915897369385 and perplexity is 91.18732410735893
At time: 172.32584738731384 and batch: 400, loss is 4.451297807693481 and perplexity is 85.73814345103821
At time: 173.3121783733368 and batch: 450, loss is 4.4586385726928714 and perplexity is 86.36984275497963
At time: 174.32828187942505 and batch: 500, loss is 4.486537733078003 and perplexity is 88.81341719102296
At time: 175.31746006011963 and batch: 550, loss is 4.450120573043823 and perplexity is 85.63726892591342
At time: 176.3051953315735 and batch: 600, loss is 4.418987550735474 and perplexity is 83.01219716004802
At time: 177.29375982284546 and batch: 650, loss is 4.486503019332885 and perplexity is 88.810334198207
At time: 178.2817497253418 and batch: 700, loss is 4.5132886409759525 and perplexity is 91.22131993489006
At time: 179.26995611190796 and batch: 750, loss is 4.467013025283814 and perplexity is 87.09618000191902
At time: 180.25981187820435 and batch: 800, loss is 4.4633762168884275 and perplexity is 86.78000316905143
At time: 181.24830555915833 and batch: 850, loss is 4.479012613296509 and perplexity is 88.14759393033692
At time: 182.23751020431519 and batch: 900, loss is 4.448452243804931 and perplexity is 85.49451687804358
At time: 183.22730135917664 and batch: 950, loss is 4.521517162322998 and perplexity is 91.9750332335314
At time: 184.21596789360046 and batch: 1000, loss is 4.498369035720825 and perplexity is 89.87043623458102
At time: 185.21373987197876 and batch: 1050, loss is 4.452175016403198 and perplexity is 85.81338669441772
At time: 186.20219445228577 and batch: 1100, loss is 4.485692873001098 and perplexity is 88.73841396862029
At time: 187.18784022331238 and batch: 1150, loss is 4.439562816619873 and perplexity is 84.73788757858442
At time: 188.17537665367126 and batch: 1200, loss is 4.496910429000854 and perplexity is 89.73944616708273
At time: 189.1637668609619 and batch: 1250, loss is 4.493817615509033 and perplexity is 89.46232755621593
At time: 190.15173482894897 and batch: 1300, loss is 4.4804948043823245 and perplexity is 88.27834238145428
At time: 191.14072012901306 and batch: 1350, loss is 4.380550975799561 and perplexity is 79.88203434999001
At time: 192.1292884349823 and batch: 1400, loss is 4.387831621170044 and perplexity is 80.46574944642028
At time: 193.11780381202698 and batch: 1450, loss is 4.335549087524414 and perplexity is 76.36687948047891
At time: 194.1060276031494 and batch: 1500, loss is 4.340093684196472 and perplexity is 76.71472595911303
At time: 195.09378290176392 and batch: 1550, loss is 4.350199241638183 and perplexity is 77.49390139908034
At time: 196.0855634212494 and batch: 1600, loss is 4.4224263954162595 and perplexity is 83.29815461252163
At time: 197.0864384174347 and batch: 1650, loss is 4.391696882247925 and perplexity is 80.77737243999525
At time: 198.07892537117004 and batch: 1700, loss is 4.390520849227905 and perplexity is 80.68243142056467
At time: 199.06834197044373 and batch: 1750, loss is 4.39636302947998 and perplexity is 81.15517230222562
At time: 200.0561122894287 and batch: 1800, loss is 4.363117628097534 and perplexity is 78.50149177394421
At time: 201.04525804519653 and batch: 1850, loss is 4.391487550735474 and perplexity is 80.76046496014645
At time: 202.03975081443787 and batch: 1900, loss is 4.499263467788697 and perplexity is 89.95085519398963
At time: 203.03552389144897 and batch: 1950, loss is 4.430089378356934 and perplexity is 83.93891889766007
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.526527298328489 and perplexity of 92.43699694331876
finished 5 epochs...
Completing Train Step...
At time: 206.2676384449005 and batch: 50, loss is 4.436296253204346 and perplexity is 84.46153749837343
At time: 207.28751802444458 and batch: 100, loss is 4.385258092880249 and perplexity is 80.25893479967769
At time: 208.2812831401825 and batch: 150, loss is 4.342971639633179 and perplexity is 76.93582552650642
At time: 209.27611351013184 and batch: 200, loss is 4.337087488174438 and perplexity is 76.48445275172232
At time: 210.2693178653717 and batch: 250, loss is 4.331416091918945 and perplexity is 76.0519068418028
At time: 211.26318979263306 and batch: 300, loss is 4.370021209716797 and perplexity is 79.04530821038652
At time: 212.25969171524048 and batch: 350, loss is 4.38047534942627 and perplexity is 79.87599338987185
At time: 213.26180028915405 and batch: 400, loss is 4.3144573211669925 and perplexity is 74.77303468840469
At time: 214.2664303779602 and batch: 450, loss is 4.333829298019409 and perplexity is 76.23565739214628
At time: 215.27101492881775 and batch: 500, loss is 4.365134830474854 and perplexity is 78.66000499264398
At time: 216.2763216495514 and batch: 550, loss is 4.333795776367188 and perplexity is 76.2331018897849
At time: 217.28058052062988 and batch: 600, loss is 4.299664492607117 and perplexity is 73.67507102150816
At time: 218.28471660614014 and batch: 650, loss is 4.366346998214722 and perplexity is 78.75541192603514
At time: 219.29148769378662 and batch: 700, loss is 4.389584264755249 and perplexity is 80.60690088396512
At time: 220.29064345359802 and batch: 750, loss is 4.349027700424195 and perplexity is 77.40316725952833
At time: 221.29731941223145 and batch: 800, loss is 4.343988590240478 and perplexity is 77.01410525756236
At time: 222.30331444740295 and batch: 850, loss is 4.362134742736816 and perplexity is 78.42437171318305
At time: 223.31562972068787 and batch: 900, loss is 4.329944000244141 and perplexity is 75.94003382675794
At time: 224.36630821228027 and batch: 950, loss is 4.406133689880371 and perplexity is 81.95199834975361
At time: 225.3812336921692 and batch: 1000, loss is 4.3824296474456785 and perplexity is 80.03224751938838
At time: 226.3747158050537 and batch: 1050, loss is 4.340728807449341 and perplexity is 76.76346474133567
At time: 227.37138485908508 and batch: 1100, loss is 4.366956186294556 and perplexity is 78.80340340063586
At time: 228.3714940547943 and batch: 1150, loss is 4.3247589492797855 and perplexity is 75.54729993363605
At time: 229.37177300453186 and batch: 1200, loss is 4.381538000106811 and perplexity is 79.9609187836286
At time: 230.3704228401184 and batch: 1250, loss is 4.385271625518799 and perplexity is 80.2600209221818
At time: 231.37258338928223 and batch: 1300, loss is 4.36776593208313 and perplexity is 78.8672399668721
At time: 232.3810155391693 and batch: 1350, loss is 4.267428164482117 and perplexity is 71.33793006792497
At time: 233.3852562904358 and batch: 1400, loss is 4.280194902420044 and perplexity is 72.25452121609412
At time: 234.39493536949158 and batch: 1450, loss is 4.223093762397766 and perplexity is 68.24428964760723
At time: 235.39496326446533 and batch: 1500, loss is 4.229207892417907 and perplexity is 68.66282228530865
At time: 236.39986157417297 and batch: 1550, loss is 4.240782117843628 and perplexity is 69.46215819238193
At time: 237.4127266407013 and batch: 1600, loss is 4.317237882614136 and perplexity is 74.98123502872286
At time: 238.41716480255127 and batch: 1650, loss is 4.277092356681823 and perplexity is 72.03069565329237
At time: 239.41927194595337 and batch: 1700, loss is 4.2826433801651005 and perplexity is 72.4316515646376
At time: 240.42502355575562 and batch: 1750, loss is 4.286742939949035 and perplexity is 72.729198940379
At time: 241.43616843223572 and batch: 1800, loss is 4.256153216362 and perplexity is 70.53811601138509
At time: 242.43762731552124 and batch: 1850, loss is 4.285842599868775 and perplexity is 72.66374739631328
At time: 243.437805891037 and batch: 1900, loss is 4.392759056091308 and perplexity is 80.8632176353278
At time: 244.4376082420349 and batch: 1950, loss is 4.323025884628296 and perplexity is 75.41648496674516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.501090967932413 and perplexity of 90.115390693316
finished 6 epochs...
Completing Train Step...
At time: 247.7144501209259 and batch: 50, loss is 4.329675607681274 and perplexity is 75.91965482136406
At time: 248.7026345729828 and batch: 100, loss is 4.278980264663696 and perplexity is 72.16681142515354
At time: 249.71443438529968 and batch: 150, loss is 4.241117668151856 and perplexity is 69.48547015192244
At time: 250.7000608444214 and batch: 200, loss is 4.234814786911011 and perplexity is 69.04888879113811
At time: 251.68867301940918 and batch: 250, loss is 4.222724986076355 and perplexity is 68.2191274094177
At time: 252.67707705497742 and batch: 300, loss is 4.26501350402832 and perplexity is 71.1658809929785
At time: 253.6670799255371 and batch: 350, loss is 4.272872633934021 and perplexity is 71.72738647867769
At time: 254.6554217338562 and batch: 400, loss is 4.203808851242066 and perplexity is 66.94081369136316
At time: 255.6419186592102 and batch: 450, loss is 4.23318386554718 and perplexity is 68.93636726508159
At time: 256.6277656555176 and batch: 500, loss is 4.266923961639404 and perplexity is 71.30197034705003
At time: 257.61397409439087 and batch: 550, loss is 4.235965719223023 and perplexity is 69.12840513854553
At time: 258.60356044769287 and batch: 600, loss is 4.207108688354492 and perplexity is 67.16207233068033
At time: 259.5934565067291 and batch: 650, loss is 4.266057605743408 and perplexity is 71.24022421556838
At time: 260.5804843902588 and batch: 700, loss is 4.290559301376343 and perplexity is 73.00729016063295
At time: 261.5676918029785 and batch: 750, loss is 4.25137526512146 and perplexity is 70.20189220259776
At time: 262.5556252002716 and batch: 800, loss is 4.247263903617859 and perplexity is 69.91385935482229
At time: 263.54374146461487 and batch: 850, loss is 4.269979066848755 and perplexity is 71.5201384616737
At time: 264.53116369247437 and batch: 900, loss is 4.233520035743713 and perplexity is 68.95954551291317
At time: 265.51842880249023 and batch: 950, loss is 4.313104171752929 and perplexity is 74.67192402467394
At time: 266.5072991847992 and batch: 1000, loss is 4.287014322280884 and perplexity is 72.7489390384167
At time: 267.4940404891968 and batch: 1050, loss is 4.253392677307129 and perplexity is 70.3436613106646
At time: 268.4803321361542 and batch: 1100, loss is 4.267336478233338 and perplexity is 71.33138966055867
At time: 269.4674623012543 and batch: 1150, loss is 4.231107478141785 and perplexity is 68.79337716311584
At time: 270.45486187934875 and batch: 1200, loss is 4.2867147159576415 and perplexity is 72.72714626106158
At time: 271.44173669815063 and batch: 1250, loss is 4.29538553237915 and perplexity is 73.36049183870256
At time: 272.4297385215759 and batch: 1300, loss is 4.274828052520752 and perplexity is 71.86778076343761
At time: 273.416925907135 and batch: 1350, loss is 4.173869996070862 and perplexity is 64.96638589598722
At time: 274.40739846229553 and batch: 1400, loss is 4.1906468963623045 and perplexity is 66.06551468113126
At time: 275.40495204925537 and batch: 1450, loss is 4.132266263961792 and perplexity is 62.31899431283906
At time: 276.3941698074341 and batch: 1500, loss is 4.135763993263245 and perplexity is 62.53735093885207
At time: 277.38985681533813 and batch: 1550, loss is 4.151463489532471 and perplexity is 63.526903258235585
At time: 278.37898445129395 and batch: 1600, loss is 4.230694208145142 and perplexity is 68.76495279823973
At time: 279.3751335144043 and batch: 1650, loss is 4.187300982475281 and perplexity is 65.84483455233878
At time: 280.36233711242676 and batch: 1700, loss is 4.194671392440796 and perplexity is 66.33193082165988
At time: 281.3575737476349 and batch: 1750, loss is 4.197786169052124 and perplexity is 66.53886207337791
At time: 282.3589994907379 and batch: 1800, loss is 4.164404821395874 and perplexity is 64.35436869950112
At time: 283.35383582115173 and batch: 1850, loss is 4.197870678901673 and perplexity is 66.54448550021499
At time: 284.34254026412964 and batch: 1900, loss is 4.304676542282104 and perplexity is 74.04526106777608
At time: 285.34089183807373 and batch: 1950, loss is 4.233403687477112 and perplexity is 68.9515226560589
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489092307867006 and perplexity of 89.04058774605059
finished 7 epochs...
Completing Train Step...
At time: 288.58006739616394 and batch: 50, loss is 4.241339573860168 and perplexity is 69.50089108532724
At time: 289.5944962501526 and batch: 100, loss is 4.194064388275146 and perplexity is 66.29167928099788
At time: 290.58350467681885 and batch: 150, loss is 4.15495274066925 and perplexity is 63.74895174382651
At time: 291.5722658634186 and batch: 200, loss is 4.150711340904236 and perplexity is 63.47913955004943
At time: 292.5608251094818 and batch: 250, loss is 4.136336627006531 and perplexity is 62.57317219146554
At time: 293.5484969615936 and batch: 300, loss is 4.1775202512741085 and perplexity is 65.2039631291088
At time: 294.53523206710815 and batch: 350, loss is 4.184460897445678 and perplexity is 65.65809492717835
At time: 295.53418588638306 and batch: 400, loss is 4.113616714477539 and perplexity is 61.16754353693951
At time: 296.52078008651733 and batch: 450, loss is 4.143528218269348 and perplexity is 63.0247948662717
At time: 297.5106484889984 and batch: 500, loss is 4.180083842277527 and perplexity is 65.37133386576781
At time: 298.507027387619 and batch: 550, loss is 4.154576406478882 and perplexity is 63.724965347418824
At time: 299.53225898742676 and batch: 600, loss is 4.1281691789627075 and perplexity is 62.064190429097074
At time: 300.5342319011688 and batch: 650, loss is 4.1811521530151365 and perplexity is 65.44120808070998
At time: 301.52249336242676 and batch: 700, loss is 4.2068179416656495 and perplexity is 67.14254801898639
At time: 302.51435899734497 and batch: 750, loss is 4.171943359375 and perplexity is 64.84133977082935
At time: 303.50239086151123 and batch: 800, loss is 4.165319919586182 and perplexity is 64.41328621938284
At time: 304.48964190483093 and batch: 850, loss is 4.189731850624084 and perplexity is 66.00508936365979
At time: 305.48701572418213 and batch: 900, loss is 4.153967409133911 and perplexity is 63.686168827401794
At time: 306.480033159256 and batch: 950, loss is 4.236017470359802 and perplexity is 69.13198270466596
At time: 307.4769685268402 and batch: 1000, loss is 4.206222491264343 and perplexity is 67.1025798625321
At time: 308.4653685092926 and batch: 1050, loss is 4.174945750236511 and perplexity is 65.03631136080361
At time: 309.46365761756897 and batch: 1100, loss is 4.1836948442459105 and perplexity is 65.60781659386656
At time: 310.45158195495605 and batch: 1150, loss is 4.154344134330749 and perplexity is 63.71016553168691
At time: 311.44555163383484 and batch: 1200, loss is 4.208308811187744 and perplexity is 67.24272345315958
At time: 312.4519233703613 and batch: 1250, loss is 4.217881860733033 and perplexity is 67.8895324037686
At time: 313.44837498664856 and batch: 1300, loss is 4.196299881935119 and perplexity is 66.44003967731713
At time: 314.43655371665955 and batch: 1350, loss is 4.096985411643982 and perplexity is 60.15866037217972
At time: 315.42941975593567 and batch: 1400, loss is 4.1149165105819705 and perplexity is 61.247100564502965
At time: 316.4174325466156 and batch: 1450, loss is 4.054291100502014 and perplexity is 57.644284504157
At time: 317.4144163131714 and batch: 1500, loss is 4.060019035339355 and perplexity is 57.97541465014795
At time: 318.411084651947 and batch: 1550, loss is 4.077716856002808 and perplexity is 59.01058626335168
At time: 319.3989977836609 and batch: 1600, loss is 4.156349730491638 and perplexity is 63.83807061518514
At time: 320.3907961845398 and batch: 1650, loss is 4.1097363042831425 and perplexity is 60.93064830003448
At time: 321.39118003845215 and batch: 1700, loss is 4.118364248275757 and perplexity is 61.45862893939545
At time: 322.39500522613525 and batch: 1750, loss is 4.1202869749069215 and perplexity is 61.57691075733331
At time: 323.39375281333923 and batch: 1800, loss is 4.087598080635071 and perplexity is 59.59657348970237
At time: 324.3947982788086 and batch: 1850, loss is 4.123999752998352 and perplexity is 61.80595709853828
At time: 325.3858919143677 and batch: 1900, loss is 4.229511671066284 and perplexity is 68.68368375313003
At time: 326.3779265880585 and batch: 1950, loss is 4.155603346824646 and perplexity is 63.790440699252464
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.490741676507994 and perplexity of 89.1875696796291
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 329.62671971321106 and batch: 50, loss is 4.194245038032531 and perplexity is 66.3036559385342
At time: 330.64314818382263 and batch: 100, loss is 4.16887354850769 and perplexity is 64.64259433287965
At time: 331.6365246772766 and batch: 150, loss is 4.128095750808716 and perplexity is 62.05963333747633
At time: 332.6303653717041 and batch: 200, loss is 4.130283923149109 and perplexity is 62.19557919283706
At time: 333.62190771102905 and batch: 250, loss is 4.117209162712097 and perplexity is 61.38767994831138
At time: 334.6245319843292 and batch: 300, loss is 4.140682873725891 and perplexity is 62.84572249221156
At time: 335.62482929229736 and batch: 350, loss is 4.139710121154785 and perplexity is 62.78461887824132
At time: 336.61389803886414 and batch: 400, loss is 4.0710777759552 and perplexity is 58.62010790031856
At time: 337.6028654575348 and batch: 450, loss is 4.085974369049072 and perplexity is 59.49988436171293
At time: 338.593688249588 and batch: 500, loss is 4.114274044036865 and perplexity is 61.20776398897549
At time: 339.5821838378906 and batch: 550, loss is 4.08264967918396 and perplexity is 59.30239417792056
At time: 340.56968235969543 and batch: 600, loss is 4.05157853603363 and perplexity is 57.48813254807671
At time: 341.56080412864685 and batch: 650, loss is 4.09494122505188 and perplexity is 60.03581045210719
At time: 342.55820631980896 and batch: 700, loss is 4.120194549560547 and perplexity is 61.57121975302846
At time: 343.54834032058716 and batch: 750, loss is 4.071468191146851 and perplexity is 58.64299854911678
At time: 344.53846979141235 and batch: 800, loss is 4.0631863880157475 and perplexity is 58.159334350423784
At time: 345.5441677570343 and batch: 850, loss is 4.085493063926696 and perplexity is 59.47125365319489
At time: 346.5344624519348 and batch: 900, loss is 4.040521159172058 and perplexity is 56.85596609379031
At time: 347.5369622707367 and batch: 950, loss is 4.131030840873718 and perplexity is 62.242051526672945
At time: 348.53344917297363 and batch: 1000, loss is 4.089970860481262 and perplexity is 59.738150937814176
At time: 349.5688359737396 and batch: 1050, loss is 4.052217130661011 and perplexity is 57.52485588507492
At time: 350.55763697624207 and batch: 1100, loss is 4.05010525226593 and perplexity is 57.403498575795666
At time: 351.56001591682434 and batch: 1150, loss is 4.017947692871093 and perplexity is 55.58690727555306
At time: 352.5590350627899 and batch: 1200, loss is 4.0669919204711915 and perplexity is 58.381083253589985
At time: 353.5569121837616 and batch: 1250, loss is 4.0721968126296995 and perplexity is 58.68574266792892
At time: 354.54646921157837 and batch: 1300, loss is 4.049300742149353 and perplexity is 57.357335452304326
At time: 355.5452926158905 and batch: 1350, loss is 3.9490789365768433 and perplexity is 51.8875530911971
At time: 356.54780077934265 and batch: 1400, loss is 3.9548605251312257 and perplexity is 52.18841446453224
At time: 357.5394380092621 and batch: 1450, loss is 3.889271926879883 and perplexity is 48.875288782424654
At time: 358.53060030937195 and batch: 1500, loss is 3.892373032569885 and perplexity is 49.027091475009826
At time: 359.5203478336334 and batch: 1550, loss is 3.9069494819641113 and perplexity is 49.746966255887884
At time: 360.5178165435791 and batch: 1600, loss is 3.9742298030853274 and perplexity is 53.209119620006994
At time: 361.51028752326965 and batch: 1650, loss is 3.9228318786621093 and perplexity is 50.54337500720684
At time: 362.50061321258545 and batch: 1700, loss is 3.918691759109497 and perplexity is 50.334551966540424
At time: 363.49264454841614 and batch: 1750, loss is 3.9149558973312377 and perplexity is 50.146859851917625
At time: 364.4883043766022 and batch: 1800, loss is 3.8724018144607544 and perplexity is 48.057673190693535
At time: 365.477952003479 and batch: 1850, loss is 3.9023188972473144 and perplexity is 49.517141237011224
At time: 366.4788906574249 and batch: 1900, loss is 4.007093605995178 and perplexity is 54.98682472027363
At time: 367.46860122680664 and batch: 1950, loss is 3.9191659021377565 and perplexity is 50.358423402226116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.393596986282703 and perplexity of 80.93100376281295
finished 9 epochs...
Completing Train Step...
At time: 370.77042293548584 and batch: 50, loss is 4.101845922470093 and perplexity is 60.451773956020276
At time: 371.76248693466187 and batch: 100, loss is 4.068819332122803 and perplexity is 58.487867064635076
At time: 372.75473046302795 and batch: 150, loss is 4.025938611030579 and perplexity is 56.03287718374349
At time: 373.74601793289185 and batch: 200, loss is 4.029643807411194 and perplexity is 56.240875096078234
At time: 374.762677192688 and batch: 250, loss is 4.017797045707702 and perplexity is 55.57853389637907
At time: 375.7598628997803 and batch: 300, loss is 4.0441839361190794 and perplexity is 57.06459866974405
At time: 376.7498826980591 and batch: 350, loss is 4.049739418029785 and perplexity is 57.3825022515634
At time: 377.741197347641 and batch: 400, loss is 3.9823796558380127 and perplexity is 53.64453799780081
At time: 378.7364354133606 and batch: 450, loss is 4.005472893714905 and perplexity is 54.89777907637197
At time: 379.738064289093 and batch: 500, loss is 4.037662363052368 and perplexity is 56.693658591110655
At time: 380.74104166030884 and batch: 550, loss is 4.007771034240722 and perplexity is 55.0240869682966
At time: 381.741583108902 and batch: 600, loss is 3.981716318130493 and perplexity is 53.60896535258724
At time: 382.7407476902008 and batch: 650, loss is 4.023295078277588 and perplexity is 55.88494805156428
At time: 383.7378661632538 and batch: 700, loss is 4.051137461662292 and perplexity is 57.462781597391995
At time: 384.732839345932 and batch: 750, loss is 4.007056946754456 and perplexity is 54.98480898197761
At time: 385.7236316204071 and batch: 800, loss is 4.001194105148316 and perplexity is 54.66338490608468
At time: 386.7193603515625 and batch: 850, loss is 4.027639479637146 and perplexity is 56.12826284172098
At time: 387.71283078193665 and batch: 900, loss is 3.9800380849838257 and perplexity is 53.519072461686925
At time: 388.7107424736023 and batch: 950, loss is 4.073497672080993 and perplexity is 58.76213424751614
At time: 389.71090054512024 and batch: 1000, loss is 4.0342947864532475 and perplexity is 56.50305946182973
At time: 390.7029616832733 and batch: 1050, loss is 4.000834631919861 and perplexity is 54.64373841403973
At time: 391.6984033584595 and batch: 1100, loss is 3.9982705545425414 and perplexity is 54.503807114564594
At time: 392.6901731491089 and batch: 1150, loss is 3.9702204847335816 and perplexity is 52.99621440781917
At time: 393.6897647380829 and batch: 1200, loss is 4.021194682121277 and perplexity is 55.76769070802631
At time: 394.70243096351624 and batch: 1250, loss is 4.0305334568023685 and perplexity is 56.29093201962078
At time: 395.70531129837036 and batch: 1300, loss is 4.00987630367279 and perplexity is 55.14004951999571
At time: 396.7040994167328 and batch: 1350, loss is 3.9102575302124025 and perplexity is 49.911804115944705
At time: 397.7020847797394 and batch: 1400, loss is 3.920495934486389 and perplexity is 50.42544629580527
At time: 398.6986081600189 and batch: 1450, loss is 3.855187749862671 and perplexity is 47.23748494007632
At time: 399.6959447860718 and batch: 1500, loss is 3.8612020874023436 and perplexity is 47.52244317757899
At time: 400.69200921058655 and batch: 1550, loss is 3.8797575855255126 and perplexity is 48.41247776340034
At time: 401.68820786476135 and batch: 1600, loss is 3.951037106513977 and perplexity is 51.989257282318356
At time: 402.6835696697235 and batch: 1650, loss is 3.9020512533187866 and perplexity is 49.5038900481803
At time: 403.68006014823914 and batch: 1700, loss is 3.9005808448791504 and perplexity is 49.43115260044262
At time: 404.67587447166443 and batch: 1750, loss is 3.898721914291382 and perplexity is 49.33934887369945
At time: 405.67757415771484 and batch: 1800, loss is 3.8581203413009644 and perplexity is 47.37621650605406
At time: 406.67334032058716 and batch: 1850, loss is 3.895752034187317 and perplexity is 49.19303429904751
At time: 407.6692113876343 and batch: 1900, loss is 4.001481094360352 and perplexity is 54.67907495917639
At time: 408.6657795906067 and batch: 1950, loss is 3.9147147226333616 and perplexity is 50.13476715642811
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.390888160882994 and perplexity of 80.71207246140298
finished 10 epochs...
Completing Train Step...
At time: 411.97254037857056 and batch: 50, loss is 4.059300484657288 and perplexity is 57.93377133961431
At time: 413.0004117488861 and batch: 100, loss is 4.027059707641602 and perplexity is 56.09573067829674
At time: 413.9941987991333 and batch: 150, loss is 3.9834626054763795 and perplexity is 53.70266379880274
At time: 414.9891984462738 and batch: 200, loss is 3.9863441801071167 and perplexity is 53.857635206012745
At time: 415.9940085411072 and batch: 250, loss is 3.9743811082839966 and perplexity is 53.21717104551802
At time: 416.98895740509033 and batch: 300, loss is 4.0016344165802 and perplexity is 54.687459119050956
At time: 417.9833972454071 and batch: 350, loss is 4.0068168497085574 and perplexity is 54.97160887648834
At time: 418.97801446914673 and batch: 400, loss is 3.940689249038696 and perplexity is 51.454053738420264
At time: 419.9719977378845 and batch: 450, loss is 3.9664408063888548 and perplexity is 52.796283838507826
At time: 420.9657039642334 and batch: 500, loss is 3.999570074081421 and perplexity is 54.57468191847538
At time: 421.9598431587219 and batch: 550, loss is 3.9691681241989136 and perplexity is 52.94047261866342
At time: 422.9627933502197 and batch: 600, loss is 3.945524129867554 and perplexity is 51.703430323655816
At time: 423.9559519290924 and batch: 650, loss is 3.9863889694213865 and perplexity is 53.86004750658406
At time: 425.0157699584961 and batch: 700, loss is 4.014530463218689 and perplexity is 55.3972782352474
At time: 426.0095021724701 and batch: 750, loss is 3.972228903770447 and perplexity is 53.10275997197247
At time: 427.0144593715668 and batch: 800, loss is 3.966562819480896 and perplexity is 52.80272606935752
At time: 428.0131757259369 and batch: 850, loss is 3.99446252822876 and perplexity is 54.29664986333626
At time: 429.00689029693604 and batch: 900, loss is 3.9461974239349367 and perplexity is 51.7382536584129
At time: 430.000461101532 and batch: 950, loss is 4.041175727844238 and perplexity is 56.89319441093768
At time: 430.99798607826233 and batch: 1000, loss is 4.003447575569153 and perplexity is 54.78670612524645
At time: 431.9927294254303 and batch: 1050, loss is 3.9710631942749024 and perplexity is 53.04089364652078
At time: 432.9863169193268 and batch: 1100, loss is 3.9677621650695802 and perplexity is 52.866092777634606
At time: 433.9806582927704 and batch: 1150, loss is 3.940881061553955 and perplexity is 51.463924216498434
At time: 434.9749710559845 and batch: 1200, loss is 3.9923830699920653 and perplexity is 54.183859559559615
At time: 435.9714946746826 and batch: 1250, loss is 4.003700513839721 and perplexity is 54.80056553265729
At time: 436.97409677505493 and batch: 1300, loss is 3.983945369720459 and perplexity is 53.728595783710524
At time: 437.96790194511414 and batch: 1350, loss is 3.8851423692703246 and perplexity is 48.67387162981606
At time: 438.9628403186798 and batch: 1400, loss is 3.8979101610183715 and perplexity is 49.29931374728388
At time: 439.9556691646576 and batch: 1450, loss is 3.8311024045944215 and perplexity is 46.11334578808948
At time: 440.960791349411 and batch: 1500, loss is 3.837905149459839 and perplexity is 46.42811253944776
At time: 441.9554388523102 and batch: 1550, loss is 3.8586499643325807 and perplexity is 47.40131468716722
At time: 442.94824290275574 and batch: 1600, loss is 3.9314988803863526 and perplexity is 50.98333835302766
At time: 443.94190788269043 and batch: 1650, loss is 3.8845448112487793 and perplexity is 48.644794855779
At time: 444.93666982650757 and batch: 1700, loss is 3.883278532028198 and perplexity is 48.58323594647316
At time: 445.9353804588318 and batch: 1750, loss is 3.87979754447937 and perplexity is 48.41441231401646
At time: 446.9323468208313 and batch: 1800, loss is 3.8405371284484864 and perplexity is 46.55047130835378
At time: 447.926949262619 and batch: 1850, loss is 3.882844982147217 and perplexity is 48.562177255637195
At time: 448.9210135936737 and batch: 1900, loss is 3.988233833312988 and perplexity is 53.959503676769046
At time: 449.9143602848053 and batch: 1950, loss is 3.901495599746704 and perplexity is 49.47639067561288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.391499931867733 and perplexity of 80.76146487233443
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 453.1548902988434 and batch: 50, loss is 4.0507420063018795 and perplexity is 57.440062124949755
At time: 454.1776502132416 and batch: 100, loss is 4.046361241340637 and perplexity is 57.18898107848994
At time: 455.17086958885193 and batch: 150, loss is 4.004617295265198 and perplexity is 54.850828709896405
At time: 456.1651313304901 and batch: 200, loss is 4.006523270606994 and perplexity is 54.95547272967653
At time: 457.15885615348816 and batch: 250, loss is 4.002554140090942 and perplexity is 54.737779597862094
At time: 458.15311765670776 and batch: 300, loss is 4.0264602518081665 and perplexity is 56.06211384222174
At time: 459.1460871696472 and batch: 350, loss is 4.0295885562896725 and perplexity is 56.23776781049512
At time: 460.14267230033875 and batch: 400, loss is 3.9716778945922853 and perplexity is 53.07350792365586
At time: 461.1379466056824 and batch: 450, loss is 3.9950750732421874 and perplexity is 54.329919193896885
At time: 462.13142442703247 and batch: 500, loss is 4.018877377510071 and perplexity is 55.638609599079494
At time: 463.1248116493225 and batch: 550, loss is 3.9805680179595946 and perplexity is 53.54744149919727
At time: 464.1187324523926 and batch: 600, loss is 3.9490019559860228 and perplexity is 51.88355891044308
At time: 465.11457109451294 and batch: 650, loss is 3.9858963298797607 and perplexity is 53.833520452142935
At time: 466.1153974533081 and batch: 700, loss is 4.015423092842102 and perplexity is 55.446749563358296
At time: 467.1158399581909 and batch: 750, loss is 3.9665769433975218 and perplexity is 52.803471855924826
At time: 468.1112127304077 and batch: 800, loss is 3.954829750061035 and perplexity is 52.18680838712766
At time: 469.10316348075867 and batch: 850, loss is 3.985723476409912 and perplexity is 53.82421594551991
At time: 470.1040017604828 and batch: 900, loss is 3.929784460067749 and perplexity is 50.896006365103055
At time: 471.11506700515747 and batch: 950, loss is 4.0267762231826785 and perplexity is 56.07983066424742
At time: 472.12054109573364 and batch: 1000, loss is 3.988969631195068 and perplexity is 53.999221575673516
At time: 473.1308991909027 and batch: 1050, loss is 3.9559419345855713 and perplexity is 52.2448820361214
At time: 474.1305830478668 and batch: 1100, loss is 3.9541862916946413 and perplexity is 52.15323915001706
At time: 475.15676403045654 and batch: 1150, loss is 3.9304033613204954 and perplexity is 50.927515716785045
At time: 476.15183448791504 and batch: 1200, loss is 3.9682917308807375 and perplexity is 52.89409626712998
At time: 477.15048360824585 and batch: 1250, loss is 3.9770238494873045 and perplexity is 53.35799625649604
At time: 478.14475655555725 and batch: 1300, loss is 3.9531035566329957 and perplexity is 52.0968015683987
At time: 479.13972520828247 and batch: 1350, loss is 3.858886094093323 and perplexity is 47.412508869850996
At time: 480.1426057815552 and batch: 1400, loss is 3.8774392557144166 and perplexity is 48.30037167262949
At time: 481.13732266426086 and batch: 1450, loss is 3.806605563163757 and perplexity is 44.99743837561767
At time: 482.13283491134644 and batch: 1500, loss is 3.808270583152771 and perplexity is 45.07242241760873
At time: 483.1256093978882 and batch: 1550, loss is 3.8299268245697022 and perplexity is 46.05916771147981
At time: 484.122287273407 and batch: 1600, loss is 3.9005234146118166 and perplexity is 49.4283138376504
At time: 485.1208322048187 and batch: 1650, loss is 3.856020154953003 and perplexity is 47.27682203292169
At time: 486.11555433273315 and batch: 1700, loss is 3.843080396652222 and perplexity is 46.66901231879686
At time: 487.11077904701233 and batch: 1750, loss is 3.8361542940139772 and perplexity is 46.346894746821974
At time: 488.1076157093048 and batch: 1800, loss is 3.79212908744812 and perplexity is 44.3507264009625
At time: 489.102326631546 and batch: 1850, loss is 3.828229670524597 and perplexity is 45.98106450401826
At time: 490.098486661911 and batch: 1900, loss is 3.93486572265625 and perplexity is 51.15528050027714
At time: 491.1056125164032 and batch: 1950, loss is 3.8582086515426637 and perplexity is 47.38040049592637
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3667330009992735 and perplexity of 78.78581760229744
finished 12 epochs...
Completing Train Step...
At time: 494.42831325531006 and batch: 50, loss is 4.035695667266846 and perplexity is 56.58226898233434
At time: 495.4265410900116 and batch: 100, loss is 4.0203221321105955 and perplexity is 55.71905183191517
At time: 496.4303607940674 and batch: 150, loss is 3.9737950468063357 and perplexity is 53.18599164903217
At time: 497.4444947242737 and batch: 200, loss is 3.9681201124191285 and perplexity is 52.88501944259803
At time: 498.4519553184509 and batch: 250, loss is 3.965475835800171 and perplexity is 52.74536155061836
At time: 499.4609286785126 and batch: 300, loss is 3.9895465326309205 and perplexity is 54.030382791746334
At time: 500.5036506652832 and batch: 350, loss is 3.993611578941345 and perplexity is 54.25046582075199
At time: 501.50321435928345 and batch: 400, loss is 3.936473665237427 and perplexity is 51.237601419965046
At time: 502.5019955635071 and batch: 450, loss is 3.9626488208770754 and perplexity is 52.59646019873107
At time: 503.50150299072266 and batch: 500, loss is 3.988252329826355 and perplexity is 53.96050174868046
At time: 504.49989676475525 and batch: 550, loss is 3.952186231613159 and perplexity is 52.04903378150923
At time: 505.49686765670776 and batch: 600, loss is 3.9227540636062623 and perplexity is 50.53944212467868
At time: 506.4981849193573 and batch: 650, loss is 3.9614483451843263 and perplexity is 52.5333573110576
At time: 507.5048174858093 and batch: 700, loss is 3.9937695503234862 and perplexity is 54.259036518764184
At time: 508.5115125179291 and batch: 750, loss is 3.9458416891098023 and perplexity is 51.71985183307408
At time: 509.50606083869934 and batch: 800, loss is 3.934250526428223 and perplexity is 51.12381964296232
At time: 510.50376534461975 and batch: 850, loss is 3.967231230735779 and perplexity is 52.83803180381143
At time: 511.51460313796997 and batch: 900, loss is 3.9121416330337526 and perplexity is 50.00593173210696
At time: 512.51407289505 and batch: 950, loss is 4.010499925613403 and perplexity is 55.17444678901391
At time: 513.5110569000244 and batch: 1000, loss is 3.9729704904556273 and perplexity is 53.14215487727721
At time: 514.5117461681366 and batch: 1050, loss is 3.9417696714401247 and perplexity is 51.509675893023775
At time: 515.519172668457 and batch: 1100, loss is 3.940273108482361 and perplexity is 51.43264607447937
At time: 516.5171735286713 and batch: 1150, loss is 3.9165051126480104 and perplexity is 50.22460834431577
At time: 517.5141322612762 and batch: 1200, loss is 3.956200370788574 and perplexity is 52.25838574991024
At time: 518.513347864151 and batch: 1250, loss is 3.9667193698883056 and perplexity is 52.81099300471517
At time: 519.5103752613068 and batch: 1300, loss is 3.9423595380783083 and perplexity is 51.540068695345546
At time: 520.5049657821655 and batch: 1350, loss is 3.8488130712509157 and perplexity is 46.93731890263987
At time: 521.5055885314941 and batch: 1400, loss is 3.869115881919861 and perplexity is 47.900018082396706
At time: 522.503422498703 and batch: 1450, loss is 3.7993625926971437 and perplexity is 44.67270071070837
At time: 523.5019643306732 and batch: 1500, loss is 3.803347086906433 and perplexity is 44.85105391569564
At time: 524.5002162456512 and batch: 1550, loss is 3.825914430618286 and perplexity is 45.87473045046483
At time: 525.4994888305664 and batch: 1600, loss is 3.8970424127578736 and perplexity is 49.256552909040636
At time: 526.5120480060577 and batch: 1650, loss is 3.852973127365112 and perplexity is 47.132987497103436
At time: 527.5096681118011 and batch: 1700, loss is 3.842478747367859 and perplexity is 46.640942385907586
At time: 528.5073111057281 and batch: 1750, loss is 3.8364859294891356 and perplexity is 46.362267570229356
At time: 529.5057044029236 and batch: 1800, loss is 3.793468794822693 and perplexity is 44.410183214662595
At time: 530.5041687488556 and batch: 1850, loss is 3.8308807373046876 and perplexity is 46.10312510054598
At time: 531.5023760795593 and batch: 1900, loss is 3.937665090560913 and perplexity is 51.29868357599976
At time: 532.5023055076599 and batch: 1950, loss is 3.861096029281616 and perplexity is 47.51740330382769
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365549770621366 and perplexity of 78.69265095923299
finished 13 epochs...
Completing Train Step...
At time: 535.7380659580231 and batch: 50, loss is 4.02343258857727 and perplexity is 55.89263333590934
At time: 536.7533919811249 and batch: 100, loss is 4.007194924354553 and perplexity is 54.992396177382226
At time: 537.7423548698425 and batch: 150, loss is 3.960255389213562 and perplexity is 52.47072469519354
At time: 538.7272567749023 and batch: 200, loss is 3.9528972196578978 and perplexity is 52.086053180883816
At time: 539.7149910926819 and batch: 250, loss is 3.9498131036758424 and perplexity is 51.92566121267703
At time: 540.7001581192017 and batch: 300, loss is 3.9734095764160156 and perplexity is 53.165493974948674
At time: 541.6850395202637 and batch: 350, loss is 3.9780060148239134 and perplexity is 53.41042837513992
At time: 542.6728200912476 and batch: 400, loss is 3.921188220977783 and perplexity is 50.46036723735174
At time: 543.6620395183563 and batch: 450, loss is 3.94821074962616 and perplexity is 51.842524544127265
At time: 544.6476349830627 and batch: 500, loss is 3.9736933135986328 and perplexity is 53.180581142715596
At time: 545.6434769630432 and batch: 550, loss is 3.9384726333618163 and perplexity is 51.3401261897074
At time: 546.6293663978577 and batch: 600, loss is 3.9097503280639647 and perplexity is 49.886495160585525
At time: 547.6172075271606 and batch: 650, loss is 3.949270362854004 and perplexity is 51.89748668306125
At time: 548.6038999557495 and batch: 700, loss is 3.9819803714752195 and perplexity is 53.62312284828071
At time: 549.5905299186707 and batch: 750, loss is 3.934462924003601 and perplexity is 51.13467937154775
At time: 550.6234424114227 and batch: 800, loss is 3.9226791524887084 and perplexity is 50.5356563003905
At time: 551.6118083000183 and batch: 850, loss is 3.9568130922317506 and perplexity is 52.29041539506814
At time: 552.6041057109833 and batch: 900, loss is 3.9018457078933717 and perplexity is 49.493715795712006
At time: 553.5903875827789 and batch: 950, loss is 4.000358219146729 and perplexity is 54.61771163932383
At time: 554.5789713859558 and batch: 1000, loss is 3.963061900138855 and perplexity is 52.618191193684865
At time: 555.5727562904358 and batch: 1050, loss is 3.9329879570007322 and perplexity is 51.05931300189009
At time: 556.5623142719269 and batch: 1100, loss is 3.9317295217514037 and perplexity is 50.99509857592506
At time: 557.5479588508606 and batch: 1150, loss is 3.9077723312377928 and perplexity is 49.78791735692067
At time: 558.5378971099854 and batch: 1200, loss is 3.948204174041748 and perplexity is 51.8421836503518
At time: 559.5288202762604 and batch: 1250, loss is 3.959502830505371 and perplexity is 52.431252248928594
At time: 560.5217273235321 and batch: 1300, loss is 3.9348596334457397 and perplexity is 51.15496900595385
At time: 561.5084726810455 and batch: 1350, loss is 3.8414070081710814 and perplexity is 46.590982236685186
At time: 562.4964971542358 and batch: 1400, loss is 3.8628945541381836 and perplexity is 47.60294143295742
At time: 563.4827041625977 and batch: 1450, loss is 3.793547101020813 and perplexity is 44.413660943430024
At time: 564.4674129486084 and batch: 1500, loss is 3.7990770053863527 and perplexity is 44.659944575828455
At time: 565.4535627365112 and batch: 1550, loss is 3.8219076013565063 and perplexity is 45.69128599884643
At time: 566.4407396316528 and batch: 1600, loss is 3.8924831771850585 and perplexity is 49.032491842538654
At time: 567.4287848472595 and batch: 1650, loss is 3.848911075592041 and perplexity is 46.941919189073445
At time: 568.426153421402 and batch: 1700, loss is 3.8398978471755982 and perplexity is 46.52072197391159
At time: 569.4128694534302 and batch: 1750, loss is 3.834662747383118 and perplexity is 46.277817720720705
At time: 570.4002916812897 and batch: 1800, loss is 3.791648087501526 and perplexity is 44.329398833622804
At time: 571.3850002288818 and batch: 1850, loss is 3.8292030000686648 and perplexity is 46.025841020185744
At time: 572.3702538013458 and batch: 1900, loss is 3.9359713125228883 and perplexity is 51.21186853583854
At time: 573.3594770431519 and batch: 1950, loss is 3.8594269800186156 and perplexity is 47.43816056527663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36568972565407 and perplexity of 78.70366516250013
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 576.5663275718689 and batch: 50, loss is 4.024639821052551 and perplexity is 55.96014948364459
At time: 577.5850837230682 and batch: 100, loss is 4.0284508609771725 and perplexity is 56.17382274756811
At time: 578.5717661380768 and batch: 150, loss is 3.9959046602249146 and perplexity is 54.37500928812441
At time: 579.5593459606171 and batch: 200, loss is 3.9877798080444338 and perplexity is 53.93501025935711
At time: 580.5485169887543 and batch: 250, loss is 3.9873828315734863 and perplexity is 53.91360357857925
At time: 581.5363817214966 and batch: 300, loss is 4.0003551197052 and perplexity is 54.617542355182536
At time: 582.5273480415344 and batch: 350, loss is 4.003656792640686 and perplexity is 54.79816963860044
At time: 583.5184593200684 and batch: 400, loss is 3.949326615333557 and perplexity is 51.90040612748197
At time: 584.5075933933258 and batch: 450, loss is 3.979987840652466 and perplexity is 53.516383499229214
At time: 585.504469871521 and batch: 500, loss is 4.0041947841644285 and perplexity is 54.82765852105577
At time: 586.4935328960419 and batch: 550, loss is 3.971927218437195 and perplexity is 53.08674206443911
At time: 587.484870672226 and batch: 600, loss is 3.934220781326294 and perplexity is 51.12229898235227
At time: 588.4747107028961 and batch: 650, loss is 3.964469289779663 and perplexity is 52.69229762697001
At time: 589.4705190658569 and batch: 700, loss is 3.9994116592407227 and perplexity is 54.566037163679916
At time: 590.4735696315765 and batch: 750, loss is 3.955605173110962 and perplexity is 52.227290934774985
At time: 591.4674415588379 and batch: 800, loss is 3.9410947275161745 and perplexity is 51.47492148021438
At time: 592.4621577262878 and batch: 850, loss is 3.970191168785095 and perplexity is 52.994660796300515
At time: 593.455721616745 and batch: 900, loss is 3.9149668645858764 and perplexity is 50.147409828314814
At time: 594.4552419185638 and batch: 950, loss is 4.01323281288147 and perplexity is 55.32543855993475
At time: 595.4463002681732 and batch: 1000, loss is 3.970562205314636 and perplexity is 53.01432739961508
At time: 596.4376707077026 and batch: 1050, loss is 3.936122555732727 and perplexity is 51.219614568970435
At time: 597.4258391857147 and batch: 1100, loss is 3.9350575733184816 and perplexity is 51.16509561620591
At time: 598.4187846183777 and batch: 1150, loss is 3.9213811588287353 and perplexity is 50.47010389141913
At time: 599.4111530780792 and batch: 1200, loss is 3.955358319282532 and perplexity is 52.2144000192106
At time: 600.4424178600311 and batch: 1250, loss is 3.963141984939575 and perplexity is 52.62240527978072
At time: 601.4313228130341 and batch: 1300, loss is 3.933197326660156 and perplexity is 51.07000439205101
At time: 602.42817902565 and batch: 1350, loss is 3.836828279495239 and perplexity is 46.3781424100357
At time: 603.4224359989166 and batch: 1400, loss is 3.857048583030701 and perplexity is 47.325467854201335
At time: 604.428551197052 and batch: 1450, loss is 3.7904802131652833 and perplexity is 44.277657885727464
At time: 605.4346928596497 and batch: 1500, loss is 3.801029381752014 and perplexity is 44.747222768326466
At time: 606.4372098445892 and batch: 1550, loss is 3.830553021430969 and perplexity is 46.08801885003674
At time: 607.4390742778778 and batch: 1600, loss is 3.9011945390701293 and perplexity is 49.46149752194555
At time: 608.4268159866333 and batch: 1650, loss is 3.852397389411926 and perplexity is 47.10585905753981
At time: 609.4185783863068 and batch: 1700, loss is 3.83541672706604 and perplexity is 46.3127234124897
At time: 610.4137210845947 and batch: 1750, loss is 3.833719801902771 and perplexity is 46.23420082906789
At time: 611.4042100906372 and batch: 1800, loss is 3.791882972717285 and perplexity is 44.33981237697813
At time: 612.3903501033783 and batch: 1850, loss is 3.822811260223389 and perplexity is 45.73259399593646
At time: 613.3810234069824 and batch: 1900, loss is 3.926658272743225 and perplexity is 50.73714436070829
At time: 614.3703982830048 and batch: 1950, loss is 3.855735569000244 and perplexity is 47.263369627753605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3495122865188955 and perplexity of 77.44068484758469
finished 15 epochs...
Completing Train Step...
At time: 617.6204979419708 and batch: 50, loss is 4.025881876945496 and perplexity is 56.02969829989827
At time: 618.6197528839111 and batch: 100, loss is 4.020012574195862 and perplexity is 55.701806227813485
At time: 619.6086087226868 and batch: 150, loss is 3.98062997341156 and perplexity is 53.55075915790942
At time: 620.5987236499786 and batch: 200, loss is 3.9684756994247437 and perplexity is 52.9038280121468
At time: 621.5875689983368 and batch: 250, loss is 3.9653145027160646 and perplexity is 52.736852665167916
At time: 622.5910205841064 and batch: 300, loss is 3.9791718673706056 and perplexity is 53.47273337124305
At time: 623.582049369812 and batch: 350, loss is 3.9846057796478274 and perplexity is 53.764090400958395
At time: 624.5746955871582 and batch: 400, loss is 3.93026207447052 and perplexity is 50.92032083679528
At time: 625.6001491546631 and batch: 450, loss is 3.9618978261947633 and perplexity is 52.556975365119186
At time: 626.5897138118744 and batch: 500, loss is 3.9871545219421387 and perplexity is 53.90129598864572
At time: 627.5847971439362 and batch: 550, loss is 3.9547425746917724 and perplexity is 52.1822591811281
At time: 628.5723505020142 and batch: 600, loss is 3.920083842277527 and perplexity is 50.40467064329465
At time: 629.5624659061432 and batch: 650, loss is 3.9522934103012086 and perplexity is 52.054612627625545
At time: 630.5555613040924 and batch: 700, loss is 3.9882737970352173 and perplexity is 53.96166014247552
At time: 631.5504906177521 and batch: 750, loss is 3.9451734733581545 and perplexity is 51.68530335760961
At time: 632.5418751239777 and batch: 800, loss is 3.9314222049713137 and perplexity is 50.979429334264104
At time: 633.5381157398224 and batch: 850, loss is 3.9611591053009034 and perplexity is 52.51816476616401
At time: 634.5268199443817 and batch: 900, loss is 3.9067293643951415 and perplexity is 49.73601727968724
At time: 635.5194220542908 and batch: 950, loss is 4.006004934310913 and perplexity is 54.92699469472962
At time: 636.5084810256958 and batch: 1000, loss is 3.9635735607147216 and perplexity is 52.64512073649726
At time: 637.5075526237488 and batch: 1050, loss is 3.930469765663147 and perplexity is 50.93089763727496
At time: 638.5021810531616 and batch: 1100, loss is 3.9310592365264894 and perplexity is 50.96092876784464
At time: 639.4892373085022 and batch: 1150, loss is 3.9173490524291994 and perplexity is 50.26701278017051
At time: 640.4785580635071 and batch: 1200, loss is 3.9515052700042723 and perplexity is 52.01360245278083
At time: 641.4673655033112 and batch: 1250, loss is 3.9603370141983034 and perplexity is 52.47500779209764
At time: 642.4592041969299 and batch: 1300, loss is 3.931374444961548 and perplexity is 50.97699461436284
At time: 643.4481914043427 and batch: 1350, loss is 3.8352554750442507 and perplexity is 46.30525599428918
At time: 644.440333366394 and batch: 1400, loss is 3.8558335399627683 and perplexity is 47.26800029239981
At time: 645.4454505443573 and batch: 1450, loss is 3.7895156812667845 and perplexity is 44.23497126192037
At time: 646.4474384784698 and batch: 1500, loss is 3.8012594032287597 and perplexity is 44.75751677446375
At time: 647.4416284561157 and batch: 1550, loss is 3.8311276054382324 and perplexity is 46.114507897957296
At time: 648.429664850235 and batch: 1600, loss is 3.9019717884063723 and perplexity is 49.49995638218974
At time: 649.418815612793 and batch: 1650, loss is 3.852969422340393 and perplexity is 47.13281286854318
At time: 650.4117112159729 and batch: 1700, loss is 3.837133541107178 and perplexity is 46.39230203763193
At time: 651.4036979675293 and batch: 1750, loss is 3.8366803455352785 and perplexity is 46.37128201522856
At time: 652.3949892520905 and batch: 1800, loss is 3.7955383396148683 and perplexity is 44.50218724845066
At time: 653.3825528621674 and batch: 1850, loss is 3.826477499008179 and perplexity is 45.90056833464162
At time: 654.3718545436859 and batch: 1900, loss is 3.9303608560562133 and perplexity is 50.92535107527493
At time: 655.3603811264038 and batch: 1950, loss is 3.859341330528259 and perplexity is 47.434097684995066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3485198264898255 and perplexity of 77.36386618927895
finished 16 epochs...
Completing Train Step...
At time: 658.559079170227 and batch: 50, loss is 4.022780466079712 and perplexity is 55.85619637423571
At time: 659.5763413906097 and batch: 100, loss is 4.015605955123902 and perplexity is 55.45688960958955
At time: 660.5669717788696 and batch: 150, loss is 3.9757464694976807 and perplexity is 53.289881333373394
At time: 661.5647103786469 and batch: 200, loss is 3.9626917695999144 and perplexity is 52.59871919803268
At time: 662.5597326755524 and batch: 250, loss is 3.959427514076233 and perplexity is 52.42730346294006
At time: 663.5548713207245 and batch: 300, loss is 3.9726230239868165 and perplexity is 53.123692968009955
At time: 664.5506947040558 and batch: 350, loss is 3.977856869697571 and perplexity is 53.402463064060335
At time: 665.5493228435516 and batch: 400, loss is 3.9233858442306517 and perplexity is 50.571382053432174
At time: 666.5434966087341 and batch: 450, loss is 3.9551054716110228 and perplexity is 52.2011993986899
At time: 667.5396506786346 and batch: 500, loss is 3.9803276443481446 and perplexity is 53.53457165414773
At time: 668.5288956165314 and batch: 550, loss is 3.9482539796829226 and perplexity is 51.844765747849365
At time: 669.5239605903625 and batch: 600, loss is 3.9146392917633057 and perplexity is 50.13098558994667
At time: 670.5179028511047 and batch: 650, loss is 3.9474577569961546 and perplexity is 51.80350219883768
At time: 671.5110623836517 and batch: 700, loss is 3.9836521768569946 and perplexity is 53.71284525194736
At time: 672.5030195713043 and batch: 750, loss is 3.940970892906189 and perplexity is 51.468547498056786
At time: 673.4955887794495 and batch: 800, loss is 3.9272845697402956 and perplexity is 50.76893083470893
At time: 674.4946863651276 and batch: 850, loss is 3.9572291564941406 and perplexity is 52.31217609479038
At time: 675.5152173042297 and batch: 900, loss is 3.9030715084075926 and perplexity is 49.55442241748777
At time: 676.5091156959534 and batch: 950, loss is 4.002703328132629 and perplexity is 54.745946429188216
At time: 677.5018091201782 and batch: 1000, loss is 3.9604231405258177 and perplexity is 52.47952746643374
At time: 678.4952759742737 and batch: 1050, loss is 3.927459864616394 and perplexity is 50.77783114821612
At time: 679.4882211685181 and batch: 1100, loss is 3.928464937210083 and perplexity is 50.8288922104089
At time: 680.4819605350494 and batch: 1150, loss is 3.914634680747986 and perplexity is 50.130754435737046
At time: 681.4777355194092 and batch: 1200, loss is 3.9490290880203247 and perplexity is 51.88496663604029
At time: 682.4812784194946 and batch: 1250, loss is 3.958444929122925 and perplexity is 52.37581448370559
At time: 683.4740171432495 and batch: 1300, loss is 3.9299459075927734 and perplexity is 50.90422406270994
At time: 684.4676492214203 and batch: 1350, loss is 3.833722686767578 and perplexity is 46.23433420867913
At time: 685.4610517024994 and batch: 1400, loss is 3.8544371795654295 and perplexity is 47.20204318939044
At time: 686.457617521286 and batch: 1450, loss is 3.7882711601257326 and perplexity is 44.179954147093376
At time: 687.4516620635986 and batch: 1500, loss is 3.8006125116348266 and perplexity is 44.72857287588872
At time: 688.4453024864197 and batch: 1550, loss is 3.830985655784607 and perplexity is 46.10796242410895
At time: 689.4395837783813 and batch: 1600, loss is 3.901845278739929 and perplexity is 49.493694555318044
At time: 690.435516834259 and batch: 1650, loss is 3.852569999694824 and perplexity is 47.11399071498154
At time: 691.4275875091553 and batch: 1700, loss is 3.8371399068832397 and perplexity is 46.39259736157768
At time: 692.4197766780853 and batch: 1750, loss is 3.8372686767578124 and perplexity is 46.39857171517115
At time: 693.4112164974213 and batch: 1800, loss is 3.7965063142776487 and perplexity is 44.545285093591396
At time: 694.4018294811249 and batch: 1850, loss is 3.8275211095809936 and perplexity is 45.94849565743436
At time: 695.4040069580078 and batch: 1900, loss is 3.9311900997161864 and perplexity is 50.96759811390956
At time: 696.3976509571075 and batch: 1950, loss is 3.8601398038864136 and perplexity is 47.47198767332465
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348297828851744 and perplexity of 77.34669349993086
finished 17 epochs...
Completing Train Step...
At time: 699.6519136428833 and batch: 50, loss is 4.0194223546981815 and perplexity is 55.66893963592761
At time: 700.6663329601288 and batch: 100, loss is 4.011810126304627 and perplexity is 55.24678376496476
At time: 701.6574387550354 and batch: 150, loss is 3.971754622459412 and perplexity is 53.077580296950025
At time: 702.6477229595184 and batch: 200, loss is 3.9583122158050537 and perplexity is 52.368863976811866
At time: 703.6392967700958 and batch: 250, loss is 3.955058469772339 and perplexity is 52.1987459039965
At time: 704.63125872612 and batch: 300, loss is 3.967847476005554 and perplexity is 52.87060302587476
At time: 705.6265144348145 and batch: 350, loss is 3.9730321550369263 and perplexity is 53.14543196704618
At time: 706.6160204410553 and batch: 400, loss is 3.918583869934082 and perplexity is 50.3291217061723
At time: 707.6146364212036 and batch: 450, loss is 3.950337233543396 and perplexity is 51.952884136161494
At time: 708.6140122413635 and batch: 500, loss is 3.97552237033844 and perplexity is 53.27794045379106
At time: 709.6127622127533 and batch: 550, loss is 3.9437255811691285 and perplexity is 51.61052276077583
At time: 710.603476524353 and batch: 600, loss is 3.91073383808136 and perplexity is 49.935583163623185
At time: 711.5962762832642 and batch: 650, loss is 3.9439342784881593 and perplexity is 51.621294862525055
At time: 712.59654712677 and batch: 700, loss is 3.9802847003936765 and perplexity is 53.53227271730322
At time: 713.5866079330444 and batch: 750, loss is 3.9379113626480104 and perplexity is 51.31131856562815
At time: 714.5819463729858 and batch: 800, loss is 3.924187808036804 and perplexity is 50.61195473820397
At time: 715.5751700401306 and batch: 850, loss is 3.9542670917510985 and perplexity is 52.157453304934485
At time: 716.5644423961639 and batch: 900, loss is 3.900319833755493 and perplexity is 49.418252203405515
At time: 717.5562505722046 and batch: 950, loss is 4.000224041938782 and perplexity is 54.61038367890524
At time: 718.5472180843353 and batch: 1000, loss is 3.9579735136032106 and perplexity is 52.35112953079239
At time: 719.53751039505 and batch: 1050, loss is 3.9250007009506227 and perplexity is 50.653113564157685
At time: 720.5289602279663 and batch: 1100, loss is 3.9261479234695433 and perplexity is 50.71125730221774
At time: 721.5218341350555 and batch: 1150, loss is 3.9122206497192384 and perplexity is 50.00988319120061
At time: 722.5151951313019 and batch: 1200, loss is 3.94672972202301 and perplexity is 51.765801163007104
At time: 723.5036115646362 and batch: 1250, loss is 3.9565680027008057 and perplexity is 52.27760113207105
At time: 724.4965436458588 and batch: 1300, loss is 3.928428010940552 and perplexity is 50.827015323688606
At time: 725.4916021823883 and batch: 1350, loss is 3.83207603931427 and perplexity is 46.15826520660137
At time: 726.480039358139 and batch: 1400, loss is 3.8528433418273926 and perplexity is 47.126870713920376
At time: 727.4724252223969 and batch: 1450, loss is 3.7867881298065185 and perplexity is 44.11448249581344
At time: 728.461375951767 and batch: 1500, loss is 3.7995728635787964 and perplexity is 44.682095066517746
At time: 729.4513008594513 and batch: 1550, loss is 3.8304042768478395 and perplexity is 46.08116401670792
At time: 730.4427623748779 and batch: 1600, loss is 3.9012125825881956 and perplexity is 49.46238998942128
At time: 731.4337997436523 and batch: 1650, loss is 3.851698760986328 and perplexity is 47.07296105846672
At time: 732.4228069782257 and batch: 1700, loss is 3.836481308937073 and perplexity is 46.362053351453206
At time: 733.414547920227 and batch: 1750, loss is 3.8370472955703736 and perplexity is 46.38830108117391
At time: 734.4054996967316 and batch: 1800, loss is 3.7966379499435425 and perplexity is 44.551149227813255
At time: 735.3983602523804 and batch: 1850, loss is 3.8277563190460206 and perplexity is 45.95930444963202
At time: 736.3967413902283 and batch: 1900, loss is 3.9312367248535156 and perplexity is 50.96997454057114
At time: 737.3956985473633 and batch: 1950, loss is 3.8602101945877076 and perplexity is 47.47532937743986
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34824956849564 and perplexity of 77.34296081103024
finished 18 epochs...
Completing Train Step...
At time: 740.6994166374207 and batch: 50, loss is 4.016199684143066 and perplexity is 55.489825750867254
At time: 741.6930272579193 and batch: 100, loss is 4.008404350280761 and perplexity is 55.058945642275695
At time: 742.6850829124451 and batch: 150, loss is 3.96820677280426 and perplexity is 52.889602677340186
At time: 743.6745882034302 and batch: 200, loss is 3.9545348644256593 and perplexity is 52.17142151577335
At time: 744.6645488739014 and batch: 250, loss is 3.951289930343628 and perplexity is 52.00240306715899
At time: 745.6554472446442 and batch: 300, loss is 3.9638116645812986 and perplexity is 52.65765723573628
At time: 746.6553926467896 and batch: 350, loss is 3.9690060806274414 and perplexity is 52.931894650425946
At time: 747.64368724823 and batch: 400, loss is 3.9146043920516966 and perplexity is 50.12923606353606
At time: 748.6353199481964 and batch: 450, loss is 3.9463825702667235 and perplexity is 51.747833693117585
At time: 749.6399056911469 and batch: 500, loss is 3.971529779434204 and perplexity is 53.06564751477705
At time: 750.6550393104553 and batch: 550, loss is 3.9399649620056154 and perplexity is 51.41679972742522
At time: 751.6457483768463 and batch: 600, loss is 3.9074174213409423 and perplexity is 49.77025026760499
At time: 752.639767408371 and batch: 650, loss is 3.940953073501587 and perplexity is 51.46763036735602
At time: 753.6370642185211 and batch: 700, loss is 3.977420392036438 and perplexity is 53.37915916806838
At time: 754.629857301712 and batch: 750, loss is 3.935316023826599 and perplexity is 51.178320970141904
At time: 755.6174783706665 and batch: 800, loss is 3.9215297937393188 and perplexity is 50.477606068327056
At time: 756.6093909740448 and batch: 850, loss is 3.9517084169387817 and perplexity is 52.02416993001086
At time: 757.5994355678558 and batch: 900, loss is 3.8979444885253907 and perplexity is 49.30100609886952
At time: 758.6022491455078 and batch: 950, loss is 3.9981041622161864 and perplexity is 54.49473885376902
At time: 759.598788022995 and batch: 1000, loss is 3.9558292198181153 and perplexity is 52.23899359825512
At time: 760.5889475345612 and batch: 1050, loss is 3.922801570892334 and perplexity is 50.54184317344681
At time: 761.5770602226257 and batch: 1100, loss is 3.9239554023742675 and perplexity is 50.60019360006126
At time: 762.5771260261536 and batch: 1150, loss is 3.9099339771270754 and perplexity is 49.89565760999551
At time: 763.5705680847168 and batch: 1200, loss is 3.944493851661682 and perplexity is 51.650188837705386
At time: 764.5624425411224 and batch: 1250, loss is 3.9546833086013793 and perplexity is 52.179166634281046
At time: 765.5659086704254 and batch: 1300, loss is 3.9268641471862793 and perplexity is 50.74759091734833
At time: 766.558479309082 and batch: 1350, loss is 3.8303661060333254 and perplexity is 46.07940509471361
At time: 767.5506730079651 and batch: 1400, loss is 3.851138849258423 and perplexity is 47.04661173283946
At time: 768.5498399734497 and batch: 1450, loss is 3.785165557861328 and perplexity is 44.04296161371885
At time: 769.5395107269287 and batch: 1500, loss is 3.798329463005066 and perplexity is 44.62657184982976
At time: 770.5350387096405 and batch: 1550, loss is 3.829601035118103 and perplexity is 46.04416456455617
At time: 771.5251388549805 and batch: 1600, loss is 3.900375509262085 and perplexity is 49.421003666225644
At time: 772.5266304016113 and batch: 1650, loss is 3.8506493043899535 and perplexity is 47.02358594202549
At time: 773.5197424888611 and batch: 1700, loss is 3.835543713569641 and perplexity is 46.318604876733474
At time: 774.518581867218 and batch: 1750, loss is 3.836472063064575 and perplexity is 46.36162469580083
At time: 775.5154988765717 and batch: 1800, loss is 3.796383056640625 and perplexity is 44.53979488537221
At time: 776.5143644809723 and batch: 1850, loss is 3.8276177215576173 and perplexity is 45.95293504686835
At time: 777.5137891769409 and batch: 1900, loss is 3.930944423675537 and perplexity is 50.95507813419602
At time: 778.503321647644 and batch: 1950, loss is 3.859973783493042 and perplexity is 47.46410700945056
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348271711482558 and perplexity of 77.3446734341609
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 781.8165082931519 and batch: 50, loss is 4.0174732542037965 and perplexity is 55.56054095244227
At time: 782.8413009643555 and batch: 100, loss is 4.017657790184021 and perplexity is 55.57079481740315
At time: 783.8371798992157 and batch: 150, loss is 3.9838272523880005 and perplexity is 53.722249880087794
At time: 784.845575094223 and batch: 200, loss is 3.9734584951400755 and perplexity is 53.1680948266926
At time: 785.8496856689453 and batch: 250, loss is 3.9725773620605467 and perplexity is 53.121267293239384
At time: 786.8539891242981 and batch: 300, loss is 3.9794500827789308 and perplexity is 53.48761237928087
At time: 787.8541300296783 and batch: 350, loss is 3.981351375579834 and perplexity is 53.58940472950221
At time: 788.8600027561188 and batch: 400, loss is 3.9289165925979614 and perplexity is 50.85185453857491
At time: 789.8666052818298 and batch: 450, loss is 3.9617919921875 and perplexity is 52.55141334413734
At time: 790.8694839477539 and batch: 500, loss is 3.9861977338790893 and perplexity is 53.84974853598698
At time: 791.8695330619812 and batch: 550, loss is 3.957311997413635 and perplexity is 52.316509863063025
At time: 792.866800069809 and batch: 600, loss is 3.924092621803284 and perplexity is 50.60713740613683
At time: 793.8629305362701 and batch: 650, loss is 3.95354238986969 and perplexity is 52.119668393446844
At time: 794.8560707569122 and batch: 700, loss is 3.9861262464523315 and perplexity is 53.845899093627594
At time: 795.859680891037 and batch: 750, loss is 3.9476149225234987 and perplexity is 51.811644563411775
At time: 796.8699066638947 and batch: 800, loss is 3.934880089759827 and perplexity is 51.1560154587702
At time: 797.8775227069855 and batch: 850, loss is 3.9666021490097045 and perplexity is 52.8048028165321
At time: 798.8794131278992 and batch: 900, loss is 3.910760006904602 and perplexity is 49.936889936170765
At time: 799.8799872398376 and batch: 950, loss is 4.014526233673096 and perplexity is 55.397043930428886
At time: 800.9038305282593 and batch: 1000, loss is 3.974730038642883 and perplexity is 53.23574337214573
At time: 801.9090876579285 and batch: 1050, loss is 3.93684157371521 and perplexity is 51.25645563600901
At time: 802.909716129303 and batch: 1100, loss is 3.930451216697693 and perplexity is 50.92995293057582
At time: 803.902934551239 and batch: 1150, loss is 3.9222958993911745 and perplexity is 50.516292064516186
At time: 804.8978755474091 and batch: 1200, loss is 3.957476053237915 and perplexity is 52.325093395282046
At time: 805.8960762023926 and batch: 1250, loss is 3.965533890724182 and perplexity is 52.74842376746265
At time: 806.8896181583405 and batch: 1300, loss is 3.9364823579788206 and perplexity is 51.23804681711969
At time: 807.8828513622284 and batch: 1350, loss is 3.837005558013916 and perplexity is 46.38636498724275
At time: 808.8760299682617 and batch: 1400, loss is 3.8556316661834718 and perplexity is 47.25845908563313
At time: 809.8698508739471 and batch: 1450, loss is 3.7831210803985598 and perplexity is 43.953008755934
At time: 810.866580247879 and batch: 1500, loss is 3.7915983819961547 and perplexity is 44.327195473211006
At time: 811.8665118217468 and batch: 1550, loss is 3.8255623531341554 and perplexity is 45.858581833731655
At time: 812.8705766201019 and batch: 1600, loss is 3.901770176887512 and perplexity is 49.489977626749834
At time: 813.8716297149658 and batch: 1650, loss is 3.854376611709595 and perplexity is 47.199184349421216
At time: 814.8689334392548 and batch: 1700, loss is 3.8387142753601076 and perplexity is 46.46569392979183
At time: 815.8773267269135 and batch: 1750, loss is 3.8367580461502073 and perplexity is 46.37488523234046
At time: 816.8767404556274 and batch: 1800, loss is 3.7922261810302733 and perplexity is 44.35503278091742
At time: 817.8780739307404 and batch: 1850, loss is 3.8237546348571776 and perplexity is 45.77575732144167
At time: 818.8724522590637 and batch: 1900, loss is 3.9291646909713744 and perplexity is 50.86447236613749
At time: 819.8677651882172 and batch: 1950, loss is 3.862828936576843 and perplexity is 47.59981794650686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3409673646438955 and perplexity of 76.78177940258892
Finished Training.
Improved accuracyfrom -10000000 to -76.78177940258892
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f4a57130b38>
ELAPSED
851.0951027870178


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.78177940258892}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.6888560527046866, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6228089196258255, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4834001064300537 and batch: 50, loss is 7.5396714019775395 and perplexity is 1881.2117611235483
At time: 2.4838755130767822 and batch: 100, loss is 6.7001981449127195 and perplexity is 812.5668151980148
At time: 3.47912335395813 and batch: 150, loss is 6.4745500373840335 and perplexity is 648.4273938722546
At time: 4.472648620605469 and batch: 200, loss is 6.342040214538574 and perplexity is 567.9538778969754
At time: 5.492619276046753 and batch: 250, loss is 6.286808834075928 and perplexity is 537.4355436799034
At time: 6.4858033657073975 and batch: 300, loss is 6.214126920700073 and perplexity is 499.75946901265775
At time: 7.481287956237793 and batch: 350, loss is 6.167362804412842 and perplexity is 476.9266971841568
At time: 8.470441341400146 and batch: 400, loss is 6.111692695617676 and perplexity is 451.10164706082713
At time: 9.462146520614624 and batch: 450, loss is 6.025573778152466 and perplexity is 413.87904866302983
At time: 10.455931425094604 and batch: 500, loss is 6.01762619972229 and perplexity is 410.6027490326424
At time: 11.450182914733887 and batch: 550, loss is 5.966186122894287 and perplexity is 390.0153599729969
At time: 12.445169925689697 and batch: 600, loss is 6.007576122283935 and perplexity is 406.4968265872394
At time: 13.439334869384766 and batch: 650, loss is 6.074622716903686 and perplexity is 434.6854720944868
At time: 14.43318247795105 and batch: 700, loss is 5.982312288284302 and perplexity is 396.3557982470117
At time: 15.42505431175232 and batch: 750, loss is 5.9174181079864505 and perplexity is 371.4514272580006
At time: 16.417253494262695 and batch: 800, loss is 5.925363674163818 and perplexity is 374.4145755111139
At time: 17.410874605178833 and batch: 850, loss is 5.954031391143799 and perplexity is 385.30352146994517
At time: 18.405372619628906 and batch: 900, loss is 5.9300893211364745 and perplexity is 376.18811387397903
At time: 19.400567770004272 and batch: 950, loss is 5.952556591033936 and perplexity is 384.73569461262684
At time: 20.393768310546875 and batch: 1000, loss is 5.930947217941284 and perplexity is 376.5109829292421
At time: 21.38878583908081 and batch: 1050, loss is 5.833391714096069 and perplexity is 341.5150383127084
At time: 22.383707761764526 and batch: 1100, loss is 5.902066469192505 and perplexity is 365.79258649275766
At time: 23.378502368927002 and batch: 1150, loss is 5.805136976242065 and perplexity is 332.0006664327603
At time: 24.372721672058105 and batch: 1200, loss is 5.891880044937134 and perplexity is 362.08538165382805
At time: 25.367439031600952 and batch: 1250, loss is 5.830666017532349 and perplexity is 340.58543942410057
At time: 26.365458965301514 and batch: 1300, loss is 5.8462193775177 and perplexity is 345.92409677794626
At time: 27.365558385849 and batch: 1350, loss is 5.813127517700195 and perplexity is 334.66415872309614
At time: 28.362503051757812 and batch: 1400, loss is 5.824806232452392 and perplexity is 338.59551789795216
At time: 29.35751700401306 and batch: 1450, loss is 5.807144756317139 and perplexity is 332.6679203811747
At time: 30.359923601150513 and batch: 1500, loss is 5.777431373596191 and perplexity is 322.92864115429717
At time: 31.37143301963806 and batch: 1550, loss is 5.7558972358703615 and perplexity is 316.04899083880775
At time: 32.36587476730347 and batch: 1600, loss is 5.766552057266235 and perplexity is 319.43444003906694
At time: 33.36115765571594 and batch: 1650, loss is 5.769495191574097 and perplexity is 320.3759633337878
At time: 34.35714602470398 and batch: 1700, loss is 5.783191604614258 and perplexity is 324.79415245956227
At time: 35.35230779647827 and batch: 1750, loss is 5.77792031288147 and perplexity is 323.0865722595138
At time: 36.347362995147705 and batch: 1800, loss is 5.78449743270874 and perplexity is 325.21855482672754
At time: 37.34939670562744 and batch: 1850, loss is 5.750069789886474 and perplexity is 314.2125883813776
At time: 38.344590187072754 and batch: 1900, loss is 5.753011684417725 and perplexity is 315.1383297258151
At time: 39.343034505844116 and batch: 1950, loss is 5.690942506790162 and perplexity is 296.17263385237203
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.117633766351744 and perplexity of 166.93988313021384
finished 1 epochs...
Completing Train Step...
At time: 42.60001063346863 and batch: 50, loss is 5.400662441253662 and perplexity is 221.55313353854828
At time: 43.61352872848511 and batch: 100, loss is 5.298398895263672 and perplexity is 200.01630640783824
At time: 44.59913873672485 and batch: 150, loss is 5.198086519241333 and perplexity is 180.9257125725511
At time: 45.58803749084473 and batch: 200, loss is 5.154448347091675 and perplexity is 173.20023398700855
At time: 46.577691316604614 and batch: 250, loss is 5.163918619155884 and perplexity is 174.84827872326275
At time: 47.57726693153381 and batch: 300, loss is 5.172759504318237 and perplexity is 176.400945638049
At time: 48.5665078163147 and batch: 350, loss is 5.155000448226929 and perplexity is 173.29588443474975
At time: 49.55500555038452 and batch: 400, loss is 5.098883819580078 and perplexity is 163.83893139459363
At time: 50.544068574905396 and batch: 450, loss is 5.058390693664551 and perplexity is 157.33710886684463
At time: 51.53315806388855 and batch: 500, loss is 5.0490207862854 and perplexity is 155.8697599267856
At time: 52.520355224609375 and batch: 550, loss is 5.009474248886108 and perplexity is 149.82594428130975
At time: 53.51208734512329 and batch: 600, loss is 4.988247051239013 and perplexity is 146.6790770976075
At time: 54.497992753982544 and batch: 650, loss is 5.0591372299194335 and perplexity is 157.45461057703835
At time: 55.48791241645813 and batch: 700, loss is 5.056851224899292 and perplexity is 157.0950796481393
At time: 56.47801995277405 and batch: 750, loss is 4.997632989883423 and perplexity is 148.0622790856465
At time: 57.47283887863159 and batch: 800, loss is 4.9946441745758055 and perplexity is 147.62040894249463
At time: 58.49147009849548 and batch: 850, loss is 4.986991481781006 and perplexity is 146.49502689635963
At time: 59.4799120426178 and batch: 900, loss is 4.981636543273925 and perplexity is 145.71265169086772
At time: 60.46804881095886 and batch: 950, loss is 5.0165098190307615 and perplexity is 150.88377206912122
At time: 61.45494866371155 and batch: 1000, loss is 4.991332988739014 and perplexity is 147.13241869424053
At time: 62.444514989852905 and batch: 1050, loss is 4.900592575073242 and perplexity is 134.36938004323272
At time: 63.436460971832275 and batch: 1100, loss is 4.974021224975586 and perplexity is 144.6072179254241
At time: 64.42928385734558 and batch: 1150, loss is 4.904183940887451 and perplexity is 134.8528172214635
At time: 65.42183566093445 and batch: 1200, loss is 4.976008434295654 and perplexity is 144.8948684528781
At time: 66.40802550315857 and batch: 1250, loss is 4.9473463153839115 and perplexity is 140.80082673215082
At time: 67.41024804115295 and batch: 1300, loss is 4.950611734390259 and perplexity is 141.26135192251277
At time: 68.40857696533203 and batch: 1350, loss is 4.858479166030884 and perplexity is 128.82812685472007
At time: 69.40096879005432 and batch: 1400, loss is 4.860643377304077 and perplexity is 129.10724006019353
At time: 70.39116954803467 and batch: 1450, loss is 4.810489273071289 and perplexity is 122.79168148535494
At time: 71.38245463371277 and batch: 1500, loss is 4.791671152114868 and perplexity is 120.50257862928129
At time: 72.37384128570557 and batch: 1550, loss is 4.792532119750977 and perplexity is 120.60637212455731
At time: 73.36630988121033 and batch: 1600, loss is 4.84803973197937 and perplexity is 127.49022971542945
At time: 74.35720229148865 and batch: 1650, loss is 4.818768606185913 and perplexity is 123.81253488134689
At time: 75.35846018791199 and batch: 1700, loss is 4.828547954559326 and perplexity is 125.02928058600355
At time: 76.35994935035706 and batch: 1750, loss is 4.8281347370147705 and perplexity is 124.97762696650813
At time: 77.35687565803528 and batch: 1800, loss is 4.776737318038941 and perplexity is 118.71638368003035
At time: 78.34884142875671 and batch: 1850, loss is 4.800260028839111 and perplexity is 121.54201783986156
At time: 79.33913564682007 and batch: 1900, loss is 4.894362821578979 and perplexity is 133.53489394857198
At time: 80.33157181739807 and batch: 1950, loss is 4.814749059677124 and perplexity is 123.31586350458566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.629644633448401 and perplexity of 102.47764051328753
finished 2 epochs...
Completing Train Step...
At time: 83.75596880912781 and batch: 50, loss is 4.7647905349731445 and perplexity is 117.30654309598175
At time: 84.74612402915955 and batch: 100, loss is 4.708105421066284 and perplexity is 110.84196200413048
At time: 85.73541259765625 and batch: 150, loss is 4.646996278762817 and perplexity is 104.27131276353013
At time: 86.72389721870422 and batch: 200, loss is 4.632625646591187 and perplexity is 102.78358348995455
At time: 87.71475267410278 and batch: 250, loss is 4.644173069000244 and perplexity is 103.97734813254193
At time: 88.7006483078003 and batch: 300, loss is 4.668220844268799 and perplexity is 106.50807930264799
At time: 89.68833065032959 and batch: 350, loss is 4.672903099060059 and perplexity is 107.00794660707444
At time: 90.67687654495239 and batch: 400, loss is 4.613929224014282 and perplexity is 100.87975106454367
At time: 91.67596244812012 and batch: 450, loss is 4.612296724319458 and perplexity is 100.71519925365239
At time: 92.6688871383667 and batch: 500, loss is 4.630749397277832 and perplexity is 102.59091666402787
At time: 93.65732312202454 and batch: 550, loss is 4.5923389720916745 and perplexity is 98.72507551665335
At time: 94.64619874954224 and batch: 600, loss is 4.5588007831573485 and perplexity is 95.46892321401538
At time: 95.63534665107727 and batch: 650, loss is 4.62873538017273 and perplexity is 102.3845047313917
At time: 96.62287712097168 and batch: 700, loss is 4.655718278884888 and perplexity is 105.18474485293876
At time: 97.61636281013489 and batch: 750, loss is 4.6065644359588624 and perplexity is 100.13952223891405
At time: 98.60852265357971 and batch: 800, loss is 4.603087501525879 and perplexity is 99.79194828202226
At time: 99.60393762588501 and batch: 850, loss is 4.598952646255493 and perplexity is 99.38017491703539
At time: 100.59296011924744 and batch: 900, loss is 4.577318286895752 and perplexity is 97.25323890656192
At time: 101.58213329315186 and batch: 950, loss is 4.637651576995849 and perplexity is 103.30146696031352
At time: 102.57140946388245 and batch: 1000, loss is 4.615496845245361 and perplexity is 101.03801632167644
At time: 103.56969499588013 and batch: 1050, loss is 4.547339553833008 and perplexity is 94.38097849300352
At time: 104.56652021408081 and batch: 1100, loss is 4.603367662429809 and perplexity is 99.81991000116527
At time: 105.55635380744934 and batch: 1150, loss is 4.559621543884277 and perplexity is 95.54731252186369
At time: 106.54757452011108 and batch: 1200, loss is 4.622375698089599 and perplexity is 101.73543794791226
At time: 107.53773641586304 and batch: 1250, loss is 4.619190874099732 and perplexity is 101.41194389376429
At time: 108.52610492706299 and batch: 1300, loss is 4.609899244308472 and perplexity is 100.47402579643092
At time: 109.51501178741455 and batch: 1350, loss is 4.498593664169311 and perplexity is 89.8906259587455
At time: 110.51058864593506 and batch: 1400, loss is 4.509210996627807 and perplexity is 90.85010918228983
At time: 111.50789189338684 and batch: 1450, loss is 4.460518255233764 and perplexity is 86.53234331735516
At time: 112.50050592422485 and batch: 1500, loss is 4.458147478103638 and perplexity is 86.32743740590071
At time: 113.48982691764832 and batch: 1550, loss is 4.463426036834717 and perplexity is 86.78432665184525
At time: 114.49627923965454 and batch: 1600, loss is 4.530425214767456 and perplexity is 92.7980117790069
At time: 115.49936485290527 and batch: 1650, loss is 4.5020739936828615 and perplexity is 90.20401999818657
At time: 116.49084138870239 and batch: 1700, loss is 4.5088959980010985 and perplexity is 90.82149602944959
At time: 117.48948335647583 and batch: 1750, loss is 4.511126728057861 and perplexity is 91.02432040955594
At time: 118.47956895828247 and batch: 1800, loss is 4.462450695037842 and perplexity is 86.69972353593246
At time: 119.46619915962219 and batch: 1850, loss is 4.506310033798218 and perplexity is 90.5869383015207
At time: 120.45772051811218 and batch: 1900, loss is 4.603748483657837 and perplexity is 99.85793078097406
At time: 121.44845271110535 and batch: 1950, loss is 4.522133636474609 and perplexity is 92.0317509448187
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.522246320857558 and perplexity of 92.04212207020659
finished 3 epochs...
Completing Train Step...
At time: 124.6700325012207 and batch: 50, loss is 4.49017216682434 and perplexity is 89.13679095589491
At time: 125.68883919715881 and batch: 100, loss is 4.443559093475342 and perplexity is 85.07720118146884
At time: 126.6938579082489 and batch: 150, loss is 4.393601684570313 and perplexity is 80.9313840008384
At time: 127.68765306472778 and batch: 200, loss is 4.388960828781128 and perplexity is 80.5566633037762
At time: 128.6798849105835 and batch: 250, loss is 4.394675645828247 and perplexity is 81.01834786135622
At time: 129.66915154457092 and batch: 300, loss is 4.413937187194824 and perplexity is 82.5940122678058
At time: 130.6620581150055 and batch: 350, loss is 4.425985946655273 and perplexity is 83.59518699935381
At time: 131.65528464317322 and batch: 400, loss is 4.362412691116333 and perplexity is 78.44617266984528
At time: 132.65103816986084 and batch: 450, loss is 4.387116355895996 and perplexity is 80.40821566850063
At time: 133.71708369255066 and batch: 500, loss is 4.407747468948364 and perplexity is 82.08435753979074
At time: 134.71859097480774 and batch: 550, loss is 4.369967031478882 and perplexity is 79.04102579088021
At time: 135.72135996818542 and batch: 600, loss is 4.341510610580444 and perplexity is 76.82350212407373
At time: 136.71215438842773 and batch: 650, loss is 4.408412246704102 and perplexity is 82.13894353654516
At time: 137.70586466789246 and batch: 700, loss is 4.437998065948486 and perplexity is 84.6053975960314
At time: 138.710599899292 and batch: 750, loss is 4.390348567962646 and perplexity is 80.66853254648753
At time: 139.70718002319336 and batch: 800, loss is 4.3904531288146975 and perplexity is 80.67696775797309
At time: 140.69879603385925 and batch: 850, loss is 4.3919640636444095 and perplexity is 80.79895753460757
At time: 141.69302439689636 and batch: 900, loss is 4.3609469127655025 and perplexity is 78.33127219812431
At time: 142.6917061805725 and batch: 950, loss is 4.435848379135132 and perplexity is 84.42371783573728
At time: 143.69225311279297 and batch: 1000, loss is 4.409217481613159 and perplexity is 82.20511131800232
At time: 144.6922676563263 and batch: 1050, loss is 4.354270753860473 and perplexity is 77.81006195480815
At time: 145.6912703514099 and batch: 1100, loss is 4.397232284545899 and perplexity is 81.2257475163621
At time: 146.69092988967896 and batch: 1150, loss is 4.35894455909729 and perplexity is 78.17458221463728
At time: 147.68933534622192 and batch: 1200, loss is 4.421560134887695 and perplexity is 83.22602795382767
At time: 148.6948652267456 and batch: 1250, loss is 4.422421541213989 and perplexity is 83.29775026741179
At time: 149.69669938087463 and batch: 1300, loss is 4.40948410987854 and perplexity is 82.22703244650486
At time: 150.70445036888123 and batch: 1350, loss is 4.29363187789917 and perplexity is 73.23195562053414
At time: 151.70390844345093 and batch: 1400, loss is 4.316004762649536 and perplexity is 74.88883115507826
At time: 152.7028045654297 and batch: 1450, loss is 4.266702561378479 and perplexity is 71.28618581962448
At time: 153.70235300064087 and batch: 1500, loss is 4.2657713079452515 and perplexity is 71.21983121561004
At time: 154.70241570472717 and batch: 1550, loss is 4.275628328323364 and perplexity is 71.92531782905998
At time: 155.69995856285095 and batch: 1600, loss is 4.344001770019531 and perplexity is 77.01512029314259
At time: 156.699387550354 and batch: 1650, loss is 4.3167538356781 and perplexity is 74.94494937433544
At time: 157.7089068889618 and batch: 1700, loss is 4.321788034439087 and perplexity is 75.32318841205148
At time: 158.70824694633484 and batch: 1750, loss is 4.320385799407959 and perplexity is 75.21764161660528
At time: 159.70983934402466 and batch: 1800, loss is 4.277035360336304 and perplexity is 72.02659028387153
At time: 160.71145272254944 and batch: 1850, loss is 4.3248164844512935 and perplexity is 75.55164668553907
At time: 161.7108190059662 and batch: 1900, loss is 4.421113815307617 and perplexity is 83.18889083610762
At time: 162.713139295578 and batch: 1950, loss is 4.341407537460327 and perplexity is 76.8155840940865
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483061182776162 and perplexity of 88.50518897457694
finished 4 epochs...
Completing Train Step...
At time: 165.94976711273193 and batch: 50, loss is 4.317202005386353 and perplexity is 74.9785449581307
At time: 166.9808542728424 and batch: 100, loss is 4.277746229171753 and perplexity is 72.07780994530164
At time: 167.97533440589905 and batch: 150, loss is 4.23365737915039 and perplexity is 68.96901730224582
At time: 168.97281122207642 and batch: 200, loss is 4.2330774974823 and perplexity is 68.9290350270606
At time: 169.96298718452454 and batch: 250, loss is 4.232049551010132 and perplexity is 68.85821607395715
At time: 170.95321702957153 and batch: 300, loss is 4.249676437377929 and perplexity is 70.08273252501678
At time: 171.95355939865112 and batch: 350, loss is 4.263731079101563 and perplexity is 71.07467458844171
At time: 172.95667004585266 and batch: 400, loss is 4.205752315521241 and perplexity is 67.07103727304242
At time: 173.94640564918518 and batch: 450, loss is 4.23538535118103 and perplexity is 69.08829686131615
At time: 174.9358685016632 and batch: 500, loss is 4.256722288131714 and perplexity is 70.57826868568911
At time: 175.94084930419922 and batch: 550, loss is 4.220875682830811 and perplexity is 68.09308613588031
At time: 176.94192361831665 and batch: 600, loss is 4.199155073165894 and perplexity is 66.63000976738891
At time: 177.94029092788696 and batch: 650, loss is 4.261236228942871 and perplexity is 70.89757493567397
At time: 178.93006086349487 and batch: 700, loss is 4.291664605140686 and perplexity is 73.08803000607959
At time: 179.92076301574707 and batch: 750, loss is 4.246965713500977 and perplexity is 69.89301484089808
At time: 180.9131133556366 and batch: 800, loss is 4.248901309967041 and perplexity is 70.02843052620939
At time: 181.91165971755981 and batch: 850, loss is 4.2497368335723875 and perplexity is 70.0869653831815
At time: 182.90221047401428 and batch: 900, loss is 4.219195036888123 and perplexity is 67.97874187996028
At time: 183.9221773147583 and batch: 950, loss is 4.293844165802002 and perplexity is 73.2475035290712
At time: 184.91568279266357 and batch: 1000, loss is 4.268992490768433 and perplexity is 71.44961319879516
At time: 185.91344141960144 and batch: 1050, loss is 4.219249410629272 and perplexity is 67.98243823896645
At time: 186.90281748771667 and batch: 1100, loss is 4.255003461837768 and perplexity is 70.45706109892551
At time: 187.8936357498169 and batch: 1150, loss is 4.221546287536621 and perplexity is 68.13876499439306
At time: 188.8839225769043 and batch: 1200, loss is 4.281900715827942 and perplexity is 72.37787913004533
At time: 189.87565755844116 and batch: 1250, loss is 4.288280839920044 and perplexity is 72.84113522466303
At time: 190.86583137512207 and batch: 1300, loss is 4.270578660964966 and perplexity is 71.56303437466927
At time: 191.855078458786 and batch: 1350, loss is 4.157760033607483 and perplexity is 63.92816516045935
At time: 192.8432207107544 and batch: 1400, loss is 4.181651721000671 and perplexity is 65.47390858058316
At time: 193.8330316543579 and batch: 1450, loss is 4.130767178535462 and perplexity is 62.225642805105544
At time: 194.82484340667725 and batch: 1500, loss is 4.129822931289673 and perplexity is 62.1669141448208
At time: 195.81504440307617 and batch: 1550, loss is 4.140931878089905 and perplexity is 62.86137329985058
At time: 196.80582332611084 and batch: 1600, loss is 4.211571226119995 and perplexity is 67.46245535166148
At time: 197.7986147403717 and batch: 1650, loss is 4.185350165367127 and perplexity is 65.71650853360426
At time: 198.79656720161438 and batch: 1700, loss is 4.192330412864685 and perplexity is 66.1768307402552
At time: 199.79056072235107 and batch: 1750, loss is 4.188213424682617 and perplexity is 65.90494157644208
At time: 200.78711867332458 and batch: 1800, loss is 4.148767614364624 and perplexity is 63.35587329854562
At time: 201.787446975708 and batch: 1850, loss is 4.199195890426636 and perplexity is 66.632729477376
At time: 202.77876019477844 and batch: 1900, loss is 4.293388032913208 and perplexity is 73.21410055236682
At time: 203.7693133354187 and batch: 1950, loss is 4.216495037078857 and perplexity is 67.79544684947567
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4671628020530525 and perplexity of 87.10922596333933
finished 5 epochs...
Completing Train Step...
At time: 207.0647566318512 and batch: 50, loss is 4.196282391548157 and perplexity is 66.43887762547574
At time: 208.05574440956116 and batch: 100, loss is 4.156957812309265 and perplexity is 63.87690119008539
At time: 209.0718686580658 and batch: 150, loss is 4.120016937255859 and perplexity is 61.56028491789507
At time: 210.06886410713196 and batch: 200, loss is 4.118593835830689 and perplexity is 61.47274069562293
At time: 211.062579870224 and batch: 250, loss is 4.11580427646637 and perplexity is 61.301497793331805
At time: 212.0515992641449 and batch: 300, loss is 4.130281534194946 and perplexity is 62.19543061062674
At time: 213.05190777778625 and batch: 350, loss is 4.146615757942199 and perplexity is 63.219687134776045
At time: 214.04826664924622 and batch: 400, loss is 4.0919517993927 and perplexity is 59.85660585274344
At time: 215.03978323936462 and batch: 450, loss is 4.124421167373657 and perplexity is 61.832008506172386
At time: 216.02977395057678 and batch: 500, loss is 4.147563199996949 and perplexity is 63.27961250848257
At time: 217.02581691741943 and batch: 550, loss is 4.112244734764099 and perplexity is 61.08368045046737
At time: 218.0224964618683 and batch: 600, loss is 4.093938269615173 and perplexity is 59.97562739512422
At time: 219.01684761047363 and batch: 650, loss is 4.155088000297546 and perplexity is 63.75757498651879
At time: 220.00520730018616 and batch: 700, loss is 4.181862783432007 and perplexity is 65.48772912136441
At time: 220.99568271636963 and batch: 750, loss is 4.138037691116333 and perplexity is 62.67970375173527
At time: 221.98532629013062 and batch: 800, loss is 4.144329099655152 and perplexity is 63.075290469119324
At time: 222.97286343574524 and batch: 850, loss is 4.142524223327637 and perplexity is 62.961550045076464
At time: 223.96177411079407 and batch: 900, loss is 4.112993688583374 and perplexity is 61.129446442404046
At time: 224.96151399612427 and batch: 950, loss is 4.186453008651734 and perplexity is 65.78902352271297
At time: 225.94898891448975 and batch: 1000, loss is 4.161908531188965 and perplexity is 64.19392186339581
At time: 226.9368462562561 and batch: 1050, loss is 4.117353143692017 and perplexity is 61.396519242955236
At time: 227.92464685440063 and batch: 1100, loss is 4.150693125724793 and perplexity is 63.477983276662535
At time: 228.9160671234131 and batch: 1150, loss is 4.119533281326294 and perplexity is 61.53051812009322
At time: 229.9034149646759 and batch: 1200, loss is 4.176581878662109 and perplexity is 65.14280621438913
At time: 230.89021730422974 and batch: 1250, loss is 4.187299857139587 and perplexity is 65.84476045483788
At time: 231.87831735610962 and batch: 1300, loss is 4.168293452262878 and perplexity is 64.60510628104252
At time: 232.88316583633423 and batch: 1350, loss is 4.055833287239075 and perplexity is 57.73325133929049
At time: 233.89120650291443 and batch: 1400, loss is 4.080014872550964 and perplexity is 59.14634950043821
At time: 234.89055585861206 and batch: 1450, loss is 4.027730460166931 and perplexity is 56.133369653116944
At time: 235.88709545135498 and batch: 1500, loss is 4.03019775390625 and perplexity is 56.27203816225533
At time: 236.89006304740906 and batch: 1550, loss is 4.03851966381073 and perplexity is 56.74228294748583
At time: 237.88293361663818 and batch: 1600, loss is 4.1137295341491695 and perplexity is 61.17444482840921
At time: 238.8730103969574 and batch: 1650, loss is 4.086966485977173 and perplexity is 59.55894449664362
At time: 239.87631177902222 and batch: 1700, loss is 4.093110823631287 and perplexity is 59.92602132910541
At time: 240.87043619155884 and batch: 1750, loss is 4.0883952379226685 and perplexity is 59.64410027321967
At time: 241.86236834526062 and batch: 1800, loss is 4.051868543624878 and perplexity is 57.50480696065859
At time: 242.85212779045105 and batch: 1850, loss is 4.102813448905945 and perplexity is 60.51029094922093
At time: 243.84318923950195 and batch: 1900, loss is 4.195894117355347 and perplexity is 66.41308613130434
At time: 244.83408737182617 and batch: 1950, loss is 4.116318078041076 and perplexity is 61.33300269237019
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.470932219749273 and perplexity of 87.43819664563014
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 248.08449792861938 and batch: 50, loss is 4.135457029342652 and perplexity is 62.51815717447166
At time: 249.10627150535583 and batch: 100, loss is 4.121970419883728 and perplexity is 61.68065940150007
At time: 250.10703897476196 and batch: 150, loss is 4.0857217979431155 and perplexity is 59.484858307768796
At time: 251.10497045516968 and batch: 200, loss is 4.094389653205871 and perplexity is 60.002705520023056
At time: 252.09743857383728 and batch: 250, loss is 4.086049780845642 and perplexity is 59.504371524078714
At time: 253.09358096122742 and batch: 300, loss is 4.093308386802673 and perplexity is 59.93786167349722
At time: 254.09250378608704 and batch: 350, loss is 4.103115611076355 and perplexity is 60.52857763269914
At time: 255.0925989151001 and batch: 400, loss is 4.042747220993042 and perplexity is 56.982671964434765
At time: 256.0977785587311 and batch: 450, loss is 4.0652583837509155 and perplexity is 58.27996517327596
At time: 257.10481309890747 and batch: 500, loss is 4.084226961135864 and perplexity is 59.3960045795535
At time: 258.10514187812805 and batch: 550, loss is 4.056493034362793 and perplexity is 57.77135325323652
At time: 259.1454849243164 and batch: 600, loss is 4.024225730895996 and perplexity is 55.93698173368371
At time: 260.1375722885132 and batch: 650, loss is 4.074839124679565 and perplexity is 58.841013759934945
At time: 261.13288378715515 and batch: 700, loss is 4.100027661323548 and perplexity is 60.34195671266503
At time: 262.1294057369232 and batch: 750, loss is 4.038635287284851 and perplexity is 56.748844066672184
At time: 263.13416171073914 and batch: 800, loss is 4.036973586082459 and perplexity is 56.65462274977073
At time: 264.13046526908875 and batch: 850, loss is 4.04807909488678 and perplexity is 57.287307803712345
At time: 265.12499141693115 and batch: 900, loss is 4.006236543655396 and perplexity is 54.93971777330034
At time: 266.1328639984131 and batch: 950, loss is 4.08302041053772 and perplexity is 59.324383510611035
At time: 267.12470412254333 and batch: 1000, loss is 4.045176510810852 and perplexity is 57.121267665632814
At time: 268.1189007759094 and batch: 1050, loss is 3.991746287345886 and perplexity is 54.14936720132219
At time: 269.1144003868103 and batch: 1100, loss is 4.015469489097595 and perplexity is 55.44932214459588
At time: 270.1099591255188 and batch: 1150, loss is 3.9844007682800293 and perplexity is 53.75306928101291
At time: 271.1063177585602 and batch: 1200, loss is 4.035704789161682 and perplexity is 56.58278512219566
At time: 272.106436252594 and batch: 1250, loss is 4.031273641586304 and perplexity is 56.33261313493591
At time: 273.1164128780365 and batch: 1300, loss is 4.016589345932007 and perplexity is 55.511452228869786
At time: 274.13055896759033 and batch: 1350, loss is 3.894859051704407 and perplexity is 49.14912538899884
At time: 275.1240231990814 and batch: 1400, loss is 3.9141515111923217 and perplexity is 50.10653863203188
At time: 276.12607860565186 and batch: 1450, loss is 3.8540401697158813 and perplexity is 47.183307232751204
At time: 277.1332836151123 and batch: 1500, loss is 3.8503018188476563 and perplexity is 47.007248764394575
At time: 278.13668727874756 and batch: 1550, loss is 3.85943208694458 and perplexity is 47.43840282906914
At time: 279.13689947128296 and batch: 1600, loss is 3.9250419473648073 and perplexity is 50.655202866547306
At time: 280.13033866882324 and batch: 1650, loss is 3.8919589853286745 and perplexity is 49.00679614494267
At time: 281.12558674812317 and batch: 1700, loss is 3.8843533325195314 and perplexity is 48.63548130397748
At time: 282.12521171569824 and batch: 1750, loss is 3.8694377994537352 and perplexity is 47.91544042031763
At time: 283.1213164329529 and batch: 1800, loss is 3.8239063930511477 and perplexity is 45.78270469484747
At time: 284.11746311187744 and batch: 1850, loss is 3.8656734085083007 and perplexity is 47.73540704086358
At time: 285.12387895584106 and batch: 1900, loss is 3.952366003990173 and perplexity is 52.05839160114696
At time: 286.1320400238037 and batch: 1950, loss is 3.872081618309021 and perplexity is 48.04228777198399
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38526128724564 and perplexity of 80.2591911764508
finished 7 epochs...
Completing Train Step...
At time: 289.3959319591522 and batch: 50, loss is 4.045090160369873 and perplexity is 57.116335431933955
At time: 290.4099895954132 and batch: 100, loss is 4.021541790962219 and perplexity is 55.787051526471224
At time: 291.39886689186096 and batch: 150, loss is 3.981846284866333 and perplexity is 53.615933187609464
At time: 292.39241552352905 and batch: 200, loss is 3.986386332511902 and perplexity is 53.8599054827012
At time: 293.3827793598175 and batch: 250, loss is 3.9778982830047607 and perplexity is 53.4046746824628
At time: 294.3752191066742 and batch: 300, loss is 3.985299587249756 and perplexity is 53.801405278765436
At time: 295.3668141365051 and batch: 350, loss is 4.001013016700744 and perplexity is 54.653486894807834
At time: 296.35924553871155 and batch: 400, loss is 3.9446410608291624 and perplexity is 51.65779277867557
At time: 297.35886311531067 and batch: 450, loss is 3.973993263244629 and perplexity is 53.19653503176529
At time: 298.3589541912079 and batch: 500, loss is 3.9973177480697633 and perplexity is 54.45190026687194
At time: 299.3547739982605 and batch: 550, loss is 3.9713553380966187 and perplexity is 53.056391479585784
At time: 300.3467969894409 and batch: 600, loss is 3.942512044906616 and perplexity is 51.54792950715154
At time: 301.33896946907043 and batch: 650, loss is 3.991394591331482 and perplexity is 54.13032643317238
At time: 302.3292033672333 and batch: 700, loss is 4.0206583929061885 and perplexity is 55.73779111508042
At time: 303.32112550735474 and batch: 750, loss is 3.962827181816101 and perplexity is 52.605842189427015
At time: 304.3098351955414 and batch: 800, loss is 3.9636036491394044 and perplexity is 52.646704769077864
At time: 305.299519777298 and batch: 850, loss is 3.977181468009949 and perplexity is 53.3664071278744
At time: 306.29928827285767 and batch: 900, loss is 3.934111671447754 and perplexity is 51.11672133881315
At time: 307.2996292114258 and batch: 950, loss is 4.015160121917725 and perplexity is 55.43217059737798
At time: 308.29918098449707 and batch: 1000, loss is 3.9794655323028563 and perplexity is 53.48843874381149
At time: 309.33253383636475 and batch: 1050, loss is 3.9311248874664306 and perplexity is 50.96427451054291
At time: 310.32776165008545 and batch: 1100, loss is 3.9550075244903566 and perplexity is 52.19608669190502
At time: 311.32357597351074 and batch: 1150, loss is 3.9273003053665163 and perplexity is 50.76972972191365
At time: 312.3141222000122 and batch: 1200, loss is 3.980349540710449 and perplexity is 53.535743879358186
At time: 313.30289816856384 and batch: 1250, loss is 3.979820342063904 and perplexity is 53.50742033120811
At time: 314.3084201812744 and batch: 1300, loss is 3.968901481628418 and perplexity is 52.92635831678161
At time: 315.30953788757324 and batch: 1350, loss is 3.8485914993286134 and perplexity is 46.926920062750916
At time: 316.3011157512665 and batch: 1400, loss is 3.87152645111084 and perplexity is 48.01562367188914
At time: 317.2953326702118 and batch: 1450, loss is 3.8130592060089112 and perplexity is 45.288774851454484
At time: 318.28482270240784 and batch: 1500, loss is 3.8125726175308228 and perplexity is 45.2667432160297
At time: 319.2773880958557 and batch: 1550, loss is 3.824491229057312 and perplexity is 45.80948790014061
At time: 320.26614356040955 and batch: 1600, loss is 3.8929833984375 and perplexity is 49.057025072528404
At time: 321.2575466632843 and batch: 1650, loss is 3.861606388092041 and perplexity is 47.54166041864192
At time: 322.24957609176636 and batch: 1700, loss is 3.8604472160339354 and perplexity is 47.48658338233661
At time: 323.24043321609497 and batch: 1750, loss is 3.847870445251465 and perplexity is 46.89309541187836
At time: 324.2324640750885 and batch: 1800, loss is 3.806129126548767 and perplexity is 44.976005054609644
At time: 325.2334659099579 and batch: 1850, loss is 3.8508291101455687 and perplexity is 47.03204181361195
At time: 326.2277970314026 and batch: 1900, loss is 3.940318169593811 and perplexity is 51.43496373889418
At time: 327.2173388004303 and batch: 1950, loss is 3.8633235454559327 and perplexity is 47.62336706242708
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3841121230014535 and perplexity of 80.1670131576692
finished 8 epochs...
Completing Train Step...
At time: 330.5186834335327 and batch: 50, loss is 3.9973998165130613 and perplexity is 54.4563692329395
At time: 331.5109555721283 and batch: 100, loss is 3.97302631855011 and perplexity is 53.14512178533833
At time: 332.5149233341217 and batch: 150, loss is 3.932608323097229 and perplexity is 51.039932834502046
At time: 333.51577401161194 and batch: 200, loss is 3.9365153408050535 and perplexity is 51.23973682058476
At time: 334.53208804130554 and batch: 250, loss is 3.9272106504440307 and perplexity is 50.76517816976839
At time: 335.52208399772644 and batch: 300, loss is 3.9353142547607423 and perplexity is 51.17823043240175
At time: 336.5136878490448 and batch: 350, loss is 3.952533082962036 and perplexity is 52.067090190347955
At time: 337.51406502723694 and batch: 400, loss is 3.896395220756531 and perplexity is 49.2246847754971
At time: 338.5057141780853 and batch: 450, loss is 3.928309874534607 and perplexity is 50.821011157435656
At time: 339.5140976905823 and batch: 500, loss is 3.9533856391906737 and perplexity is 52.111499240312945
At time: 340.51127433776855 and batch: 550, loss is 3.9290757465362547 and perplexity is 50.85994845556654
At time: 341.51201272010803 and batch: 600, loss is 3.901354041099548 and perplexity is 49.4693873603843
At time: 342.5023229122162 and batch: 650, loss is 3.9489545440673828 and perplexity is 51.88109906968261
At time: 343.49539160728455 and batch: 700, loss is 3.9793930149078367 and perplexity is 53.48456004220849
At time: 344.4858753681183 and batch: 750, loss is 3.921359543800354 and perplexity is 50.469012990481076
At time: 345.477427482605 and batch: 800, loss is 3.9225858640670777 and perplexity is 50.530942128670404
At time: 346.4639539718628 and batch: 850, loss is 3.93808856010437 and perplexity is 51.32041160636848
At time: 347.45589995384216 and batch: 900, loss is 3.8949633407592774 and perplexity is 49.1542513721207
At time: 348.446950674057 and batch: 950, loss is 3.977156105041504 and perplexity is 53.36505361453902
At time: 349.4381537437439 and batch: 1000, loss is 3.941932110786438 and perplexity is 51.518043770722535
At time: 350.4348294734955 and batch: 1050, loss is 3.8960666418075562 and perplexity is 49.208513237268974
At time: 351.4291307926178 and batch: 1100, loss is 3.919761452674866 and perplexity is 50.38842332067837
At time: 352.42015409469604 and batch: 1150, loss is 3.8929576778411867 and perplexity is 49.055763312816865
At time: 353.41361021995544 and batch: 1200, loss is 3.946428894996643 and perplexity is 51.750230953063124
At time: 354.402752161026 and batch: 1250, loss is 3.947756390571594 and perplexity is 51.81897477411986
At time: 355.40496587753296 and batch: 1300, loss is 3.9385647869110105 and perplexity is 51.34485758255583
At time: 356.39779472351074 and batch: 1350, loss is 3.8188177347183228 and perplexity is 45.550323907764444
At time: 357.3979434967041 and batch: 1400, loss is 3.8431877660751343 and perplexity is 46.67402341273174
At time: 358.39336109161377 and batch: 1450, loss is 3.7843138122558595 and perplexity is 44.00546418611408
At time: 359.3850131034851 and batch: 1500, loss is 3.78496346950531 and perplexity is 44.03406194330235
At time: 360.3745610713959 and batch: 1550, loss is 3.7989989852905275 and perplexity is 44.65646033859513
At time: 361.36527729034424 and batch: 1600, loss is 3.868266296386719 and perplexity is 47.85934020211272
At time: 362.35487627983093 and batch: 1650, loss is 3.837924027442932 and perplexity is 46.42898901684436
At time: 363.36154794692993 and batch: 1700, loss is 3.838766736984253 and perplexity is 46.4681316595055
At time: 364.3535854816437 and batch: 1750, loss is 3.82712366104126 and perplexity is 45.9302371235865
At time: 365.3452823162079 and batch: 1800, loss is 3.7870130252838137 and perplexity is 44.124404759104216
At time: 366.33662366867065 and batch: 1850, loss is 3.8326526069641114 and perplexity is 46.18488624276896
At time: 367.32937502861023 and batch: 1900, loss is 3.9233776998519896 and perplexity is 50.570970182624485
At time: 368.3200054168701 and batch: 1950, loss is 3.8474112272262575 and perplexity is 46.87156620088668
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386377237009448 and perplexity of 80.34880639562881
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 371.6106958389282 and batch: 50, loss is 3.987323899269104 and perplexity is 53.91042641930239
At time: 372.6292533874512 and batch: 100, loss is 3.992151288986206 and perplexity is 54.17130222542154
At time: 373.61960196495056 and batch: 150, loss is 3.96350679397583 and perplexity is 52.64160591080517
At time: 374.61119413375854 and batch: 200, loss is 3.975203514099121 and perplexity is 53.26095515813696
At time: 375.598934173584 and batch: 250, loss is 3.968652539253235 and perplexity is 52.91318434328062
At time: 376.59114241600037 and batch: 300, loss is 3.9700186538696287 and perplexity is 52.98551921542527
At time: 377.58119773864746 and batch: 350, loss is 3.9916895151138307 and perplexity is 54.14629310814417
At time: 378.5763030052185 and batch: 400, loss is 3.930304527282715 and perplexity is 50.922482593498664
At time: 379.5701835155487 and batch: 450, loss is 3.9611953353881835 and perplexity is 52.52006753832587
At time: 380.56138730049133 and batch: 500, loss is 3.9781729412078857 and perplexity is 53.41934472898165
At time: 381.5553300380707 and batch: 550, loss is 3.963523435592651 and perplexity is 52.64248195952899
At time: 382.54927277565 and batch: 600, loss is 3.934667263031006 and perplexity is 51.14512924981981
At time: 383.5397803783417 and batch: 650, loss is 3.970324311256409 and perplexity is 53.00171710614221
At time: 384.5632610321045 and batch: 700, loss is 4.000841960906983 and perplexity is 54.64413889876244
At time: 385.55435729026794 and batch: 750, loss is 3.9301122713088987 and perplexity is 50.912693383065765
At time: 386.5442717075348 and batch: 800, loss is 3.9225501680374144 and perplexity is 50.529138406854315
At time: 387.5340313911438 and batch: 850, loss is 3.9409386110305786 and perplexity is 51.46688602362651
At time: 388.52494764328003 and batch: 900, loss is 3.89589994430542 and perplexity is 49.200310984694994
At time: 389.51391530036926 and batch: 950, loss is 3.984129366874695 and perplexity is 53.73848260198114
At time: 390.5026488304138 and batch: 1000, loss is 3.9440408754348755 and perplexity is 51.6267978282374
At time: 391.4922614097595 and batch: 1050, loss is 3.897317762374878 and perplexity is 49.270117549442666
At time: 392.483362197876 and batch: 1100, loss is 3.9177653980255127 and perplexity is 50.28794558691993
At time: 393.47327280044556 and batch: 1150, loss is 3.8938245487213137 and perplexity is 49.09830676270991
At time: 394.4755346775055 and batch: 1200, loss is 3.9303339910507202 and perplexity is 50.92398298381553
At time: 395.46441864967346 and batch: 1250, loss is 3.9335431241989136 and perplexity is 51.087667327597934
At time: 396.4547815322876 and batch: 1300, loss is 3.929984245300293 and perplexity is 50.90617565137306
At time: 397.46218085289 and batch: 1350, loss is 3.8052458572387695 and perplexity is 44.93629666883946
At time: 398.46388697624207 and batch: 1400, loss is 3.8185133266448976 and perplexity is 45.536460131649534
At time: 399.4543149471283 and batch: 1450, loss is 3.753540072441101 and perplexity is 42.671876464800384
At time: 400.45593333244324 and batch: 1500, loss is 3.75298535823822 and perplexity is 42.64821233288362
At time: 401.4490501880646 and batch: 1550, loss is 3.769935474395752 and perplexity is 43.37726580126143
At time: 402.4503152370453 and batch: 1600, loss is 3.8362606525421143 and perplexity is 46.35182439648147
At time: 403.44847345352173 and batch: 1650, loss is 3.802386522293091 and perplexity is 44.80799226549282
At time: 404.4421923160553 and batch: 1700, loss is 3.7972727680206297 and perplexity is 44.57944008152067
At time: 405.4365108013153 and batch: 1750, loss is 3.7876047134399413 and perplexity is 44.15052037218393
At time: 406.4282579421997 and batch: 1800, loss is 3.7464693069458006 and perplexity is 42.37121782906321
At time: 407.4183633327484 and batch: 1850, loss is 3.779318618774414 and perplexity is 43.78619647651016
At time: 408.4098811149597 and batch: 1900, loss is 3.8734973096847534 and perplexity is 48.110348989925626
At time: 409.40656447410583 and batch: 1950, loss is 3.7984613466262815 and perplexity is 44.632457751846246
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.35743777252907 and perplexity of 78.056878503635
finished 10 epochs...
Completing Train Step...
At time: 412.7513258457184 and batch: 50, loss is 3.976935610771179 and perplexity is 53.35328822312981
At time: 413.7720696926117 and batch: 100, loss is 3.967202248573303 and perplexity is 52.83650046557965
At time: 414.76673316955566 and batch: 150, loss is 3.930094265937805 and perplexity is 50.91177668938076
At time: 415.7640380859375 and batch: 200, loss is 3.9346340703964233 and perplexity is 51.14343163640822
At time: 416.7561285495758 and batch: 250, loss is 3.925055465698242 and perplexity is 50.65588764509839
At time: 417.76074266433716 and batch: 300, loss is 3.924181733131409 and perplexity is 50.61164727630097
At time: 418.76238536834717 and batch: 350, loss is 3.9467859268188477 and perplexity is 51.76871073105791
At time: 419.75789427757263 and batch: 400, loss is 3.886769943237305 and perplexity is 48.75315645961326
At time: 420.76087737083435 and batch: 450, loss is 3.921300144195557 and perplexity is 50.46601524008842
At time: 421.7616469860077 and batch: 500, loss is 3.94169228553772 and perplexity is 51.505689924503095
At time: 422.7606439590454 and batch: 550, loss is 3.9279494667053223 and perplexity is 50.802698167393075
At time: 423.7631239891052 and batch: 600, loss is 3.9006841564178467 and perplexity is 49.43625967268251
At time: 424.7637505531311 and batch: 650, loss is 3.937731623649597 and perplexity is 51.30209674940673
At time: 425.7598488330841 and batch: 700, loss is 3.969286313056946 and perplexity is 52.94672996243279
At time: 426.7541973590851 and batch: 750, loss is 3.901810622215271 and perplexity is 49.49197930559474
At time: 427.75055623054504 and batch: 800, loss is 3.8946802616119385 and perplexity is 49.140338797826935
At time: 428.7439835071564 and batch: 850, loss is 3.9137439489364625 and perplexity is 50.086121259071625
At time: 429.73660945892334 and batch: 900, loss is 3.8687195110321047 and perplexity is 47.881035671991796
At time: 430.7309558391571 and batch: 950, loss is 3.9591337490081786 and perplexity is 52.41190441453235
At time: 431.72556376457214 and batch: 1000, loss is 3.920360984802246 and perplexity is 50.41864185689366
At time: 432.720112323761 and batch: 1050, loss is 3.876022753715515 and perplexity is 48.23200253355037
At time: 433.7156937122345 and batch: 1100, loss is 3.8970630979537964 and perplexity is 49.257571801025996
At time: 434.7799355983734 and batch: 1150, loss is 3.873789987564087 and perplexity is 48.12443188561748
At time: 435.7801003456116 and batch: 1200, loss is 3.912727394104004 and perplexity is 50.035231840791006
At time: 436.77567410469055 and batch: 1250, loss is 3.9182043790817263 and perplexity is 50.31002588845095
At time: 437.7704322338104 and batch: 1300, loss is 3.915407781600952 and perplexity is 50.16952554981075
At time: 438.7639992237091 and batch: 1350, loss is 3.7913713121414183 and perplexity is 44.31713124605857
At time: 439.7583336830139 and batch: 1400, loss is 3.8068708419799804 and perplexity is 45.00937682624204
At time: 440.75319814682007 and batch: 1450, loss is 3.7438988971710203 and perplexity is 42.26244629018726
At time: 441.7538523674011 and batch: 1500, loss is 3.7447576236724855 and perplexity is 42.29875375969541
At time: 442.7517023086548 and batch: 1550, loss is 3.7642750549316406 and perplexity is 43.132425883666954
At time: 443.74425768852234 and batch: 1600, loss is 3.832040858268738 and perplexity is 46.15664133913631
At time: 444.73429703712463 and batch: 1650, loss is 3.798805513381958 and perplexity is 44.647821403706025
At time: 445.73412251472473 and batch: 1700, loss is 3.797319059371948 and perplexity is 44.5815037718082
At time: 446.73613929748535 and batch: 1750, loss is 3.789349174499512 and perplexity is 44.22760645301743
At time: 447.731746673584 and batch: 1800, loss is 3.7492255687713625 and perplexity is 42.48816509387167
At time: 448.7279529571533 and batch: 1850, loss is 3.7828343725204467 and perplexity is 43.940408888383864
At time: 449.7227065563202 and batch: 1900, loss is 3.8772079944610596 and perplexity is 48.289202959633926
At time: 450.7167627811432 and batch: 1950, loss is 3.802362155914307 and perplexity is 44.806900470282336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3560791015625 and perplexity of 77.9508969024367
finished 11 epochs...
Completing Train Step...
At time: 453.99127745628357 and batch: 50, loss is 3.963150768280029 and perplexity is 52.62286748231165
At time: 454.9828510284424 and batch: 100, loss is 3.9512367248535156 and perplexity is 51.999636327420305
At time: 455.972971200943 and batch: 150, loss is 3.9133651876449584 and perplexity is 50.06715416732395
At time: 456.97359681129456 and batch: 200, loss is 3.9166029930114745 and perplexity is 50.22952458783328
At time: 457.9709758758545 and batch: 250, loss is 3.906722822189331 and perplexity is 49.73569189749036
At time: 458.9606056213379 and batch: 300, loss is 3.9054439067840576 and perplexity is 49.67212481205747
At time: 459.99620723724365 and batch: 350, loss is 3.9279723739624024 and perplexity is 50.80386193118962
At time: 460.99554800987244 and batch: 400, loss is 3.8687017869949343 and perplexity is 47.88018703425646
At time: 461.99037766456604 and batch: 450, loss is 3.9040373945236206 and perplexity is 49.60230946908479
At time: 462.9844048023224 and batch: 500, loss is 3.9252070379257202 and perplexity is 50.66356625274077
At time: 463.97686409950256 and batch: 550, loss is 3.9118813848495484 and perplexity is 49.99291947245615
At time: 464.96858859062195 and batch: 600, loss is 3.8850955963134766 and perplexity is 48.67159506216001
At time: 465.9744837284088 and batch: 650, loss is 3.922113699913025 and perplexity is 50.50708886089888
At time: 466.97156405448914 and batch: 700, loss is 3.9541648054122924 and perplexity is 52.15211858283372
At time: 467.96969866752625 and batch: 750, loss is 3.8875601863861085 and perplexity is 48.791698534287505
At time: 468.9643211364746 and batch: 800, loss is 3.8803284788131713 and perplexity is 48.44012401277262
At time: 469.9575045108795 and batch: 850, loss is 3.899516625404358 and perplexity is 49.37857498720605
At time: 470.9497628211975 and batch: 900, loss is 3.854594488143921 and perplexity is 47.2094690597677
At time: 471.94462418556213 and batch: 950, loss is 3.9463561582565307 and perplexity is 51.74646694685597
At time: 472.9360556602478 and batch: 1000, loss is 3.9078927755355837 and perplexity is 49.79391438881209
At time: 473.92955780029297 and batch: 1050, loss is 3.8646878242492675 and perplexity is 47.68838295199296
At time: 474.9215805530548 and batch: 1100, loss is 3.8859080266952515 and perplexity is 48.71115341174463
At time: 475.9121732711792 and batch: 1150, loss is 3.8625141286849978 and perplexity is 47.5848355065858
At time: 476.91288709640503 and batch: 1200, loss is 3.902351121902466 and perplexity is 49.51873693552194
At time: 477.908979177475 and batch: 1250, loss is 3.909107036590576 and perplexity is 49.85441392351094
At time: 478.8995041847229 and batch: 1300, loss is 3.9067014932632445 and perplexity is 49.73463109990689
At time: 479.8988084793091 and batch: 1350, loss is 3.783003134727478 and perplexity is 43.94782499452734
At time: 480.891624212265 and batch: 1400, loss is 3.7991232824325563 and perplexity is 44.662011353968865
At time: 481.8874659538269 and batch: 1450, loss is 3.7368065309524536 and perplexity is 41.9637659709166
At time: 482.8824887275696 and batch: 1500, loss is 3.7377670335769655 and perplexity is 42.00409164162208
At time: 483.88267254829407 and batch: 1550, loss is 3.7582135677337645 and perplexity is 42.87177001553986
At time: 484.87692856788635 and batch: 1600, loss is 3.8264453172683717 and perplexity is 45.89909119826301
At time: 485.88375210762024 and batch: 1650, loss is 3.793649835586548 and perplexity is 44.41822399598735
At time: 486.89260697364807 and batch: 1700, loss is 3.794056944847107 and perplexity is 44.43631074770597
At time: 487.8980886936188 and batch: 1750, loss is 3.7868874740600584 and perplexity is 44.11886523384361
At time: 488.9014239311218 and batch: 1800, loss is 3.7471542167663574 and perplexity is 42.40024823273272
At time: 489.90926122665405 and batch: 1850, loss is 3.7809598350524904 and perplexity is 43.85811809824669
At time: 490.9183359146118 and batch: 1900, loss is 3.875330743789673 and perplexity is 48.19863705500657
At time: 491.92092871665955 and batch: 1950, loss is 3.800715613365173 and perplexity is 44.73318470688795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.356207701217296 and perplexity of 77.96092200546798
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 495.22427463531494 and batch: 50, loss is 3.9631869077682493 and perplexity is 52.62476928017593
At time: 496.26132345199585 and batch: 100, loss is 3.9711490154266356 and perplexity is 53.04544587243832
At time: 497.25606083869934 and batch: 150, loss is 3.945642204284668 and perplexity is 51.709535536481724
At time: 498.24891448020935 and batch: 200, loss is 3.9528630113601686 and perplexity is 52.08427143614447
At time: 499.24323081970215 and batch: 250, loss is 3.9490155792236328 and perplexity is 51.884265737308795
At time: 500.2370240688324 and batch: 300, loss is 3.948566880226135 and perplexity is 51.860990541455585
At time: 501.2326440811157 and batch: 350, loss is 3.9715082025527955 and perplexity is 53.06450253594633
At time: 502.22816276550293 and batch: 400, loss is 3.9150340366363525 and perplexity is 50.15077844579625
At time: 503.2218246459961 and batch: 450, loss is 3.9455570936203004 and perplexity is 51.70513469084017
At time: 504.2176742553711 and batch: 500, loss is 3.963233623504639 and perplexity is 52.62722774244917
At time: 505.2128903865814 and batch: 550, loss is 3.950581979751587 and perplexity is 51.965600963692594
At time: 506.2063841819763 and batch: 600, loss is 3.9191065788269044 and perplexity is 50.355436062430925
At time: 507.20628023147583 and batch: 650, loss is 3.9459825134277344 and perplexity is 51.727135758796926
At time: 508.205527305603 and batch: 700, loss is 3.982313060760498 and perplexity is 53.64096565458616
At time: 509.19933700561523 and batch: 750, loss is 3.91613196849823 and perplexity is 50.20587082165297
At time: 510.2374608516693 and batch: 800, loss is 3.90859338760376 and perplexity is 49.8288128298616
At time: 511.23203802108765 and batch: 850, loss is 3.9139922142028807 and perplexity is 50.09855744698274
At time: 512.2260031700134 and batch: 900, loss is 3.8652388286590575 and perplexity is 47.71466670186132
At time: 513.2230894565582 and batch: 950, loss is 3.9626570034027098 and perplexity is 52.59689057237569
At time: 514.223438501358 and batch: 1000, loss is 3.9246932220458985 and perplexity is 50.63754119448838
At time: 515.2179639339447 and batch: 1050, loss is 3.880666527748108 and perplexity is 48.45650191321327
At time: 516.213648557663 and batch: 1100, loss is 3.900117030143738 and perplexity is 49.40823101957252
At time: 517.2222256660461 and batch: 1150, loss is 3.883278727531433 and perplexity is 48.58324544465388
At time: 518.2236976623535 and batch: 1200, loss is 3.916508526802063 and perplexity is 50.22477981915862
At time: 519.2186143398285 and batch: 1250, loss is 3.91753258228302 and perplexity is 50.276239124306954
At time: 520.2128541469574 and batch: 1300, loss is 3.9148110818862913 and perplexity is 50.13959833789789
At time: 521.2062373161316 and batch: 1350, loss is 3.796698293685913 and perplexity is 44.553837691999746
At time: 522.2007868289948 and batch: 1400, loss is 3.8124745893478393 and perplexity is 45.26230601693149
At time: 523.1973769664764 and batch: 1450, loss is 3.7422011423110964 and perplexity is 42.19075589018819
At time: 524.1918570995331 and batch: 1500, loss is 3.7381977701187132 and perplexity is 42.02218823594748
At time: 525.1852488517761 and batch: 1550, loss is 3.760728187561035 and perplexity is 42.97971187794564
At time: 526.1801788806915 and batch: 1600, loss is 3.824590969085693 and perplexity is 45.81405716762955
At time: 527.1739659309387 and batch: 1650, loss is 3.7853802156448366 and perplexity is 44.05241679301562
At time: 528.1666283607483 and batch: 1700, loss is 3.778594241142273 and perplexity is 43.75449022022389
At time: 529.1592018604279 and batch: 1750, loss is 3.7760616397857665 and perplexity is 43.6438177427273
At time: 530.1523311138153 and batch: 1800, loss is 3.7384309864044187 and perplexity is 42.031989637483896
At time: 531.145013332367 and batch: 1850, loss is 3.7717221403121948 and perplexity is 43.45483575878191
At time: 532.1374175548553 and batch: 1900, loss is 3.864787764549255 and perplexity is 47.69314918145635
At time: 533.1309278011322 and batch: 1950, loss is 3.7972707605361937 and perplexity is 44.579350589078366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33912353515625 and perplexity of 76.6403373312153
finished 13 epochs...
Completing Train Step...
At time: 536.364673614502 and batch: 50, loss is 3.9705435752868654 and perplexity is 53.01333975042337
At time: 537.3925044536591 and batch: 100, loss is 3.9629453563690187 and perplexity is 52.61205922864928
At time: 538.3910307884216 and batch: 150, loss is 3.927289381027222 and perplexity is 50.769175099189724
At time: 539.3891286849976 and batch: 200, loss is 3.9307037925720216 and perplexity is 50.942818232630856
At time: 540.3875911235809 and batch: 250, loss is 3.9249010276794434 and perplexity is 50.64806505423825
At time: 541.388265132904 and batch: 300, loss is 3.9247228622436525 and perplexity is 50.639042123466965
At time: 542.3871808052063 and batch: 350, loss is 3.9470472526550293 and perplexity is 51.78224100050523
At time: 543.385871887207 and batch: 400, loss is 3.8897990226745605 and perplexity is 48.901057532308755
At time: 544.385290145874 and batch: 450, loss is 3.9213554668426513 and perplexity is 50.46880723086926
At time: 545.3868806362152 and batch: 500, loss is 3.9405808210372926 and perplexity is 51.44847498066153
At time: 546.3884954452515 and batch: 550, loss is 3.9297936582565307 and perplexity is 50.89647451833091
At time: 547.3904826641083 and batch: 600, loss is 3.9005444288253783 and perplexity is 49.429352545707154
At time: 548.398434638977 and batch: 650, loss is 3.930332465171814 and perplexity is 50.92390528004335
At time: 549.4050576686859 and batch: 700, loss is 3.9670625162124633 and perplexity is 52.829118012426896
At time: 550.4086694717407 and batch: 750, loss is 3.903137230873108 and perplexity is 49.55767936333231
At time: 551.4058771133423 and batch: 800, loss is 3.89591215133667 and perplexity is 49.200911578094406
At time: 552.406623840332 and batch: 850, loss is 3.902958993911743 and perplexity is 49.54884714028798
At time: 553.4054851531982 and batch: 900, loss is 3.854600777626038 and perplexity is 47.209765983812844
At time: 554.4040670394897 and batch: 950, loss is 3.9520880699157717 and perplexity is 52.04392481076259
At time: 555.4030237197876 and batch: 1000, loss is 3.9146650218963623 and perplexity is 50.13227548347065
At time: 556.4115054607391 and batch: 1050, loss is 3.8706805419921877 and perplexity is 47.9750239922279
At time: 557.4094352722168 and batch: 1100, loss is 3.8908770799636843 and perplexity is 48.953804100630016
At time: 558.4069240093231 and batch: 1150, loss is 3.873795161247253 and perplexity is 48.1246808668247
At time: 559.4056768417358 and batch: 1200, loss is 3.9081157350540163 and perplexity is 49.8050176537284
At time: 560.4479084014893 and batch: 1250, loss is 3.909849457740784 and perplexity is 49.891440637846166
At time: 561.445990562439 and batch: 1300, loss is 3.9081102275848387 and perplexity is 49.80474335488413
At time: 562.4456517696381 and batch: 1350, loss is 3.7903566122055055 and perplexity is 44.2721854629214
At time: 563.4508173465729 and batch: 1400, loss is 3.8076016426086428 and perplexity is 45.04228172911976
At time: 564.4613997936249 and batch: 1450, loss is 3.738889331817627 and perplexity is 42.05125922286795
At time: 565.4762914180756 and batch: 1500, loss is 3.736576280593872 and perplexity is 41.95410491102829
At time: 566.4756338596344 and batch: 1550, loss is 3.760690565109253 and perplexity is 42.978094906225316
At time: 567.4745881557465 and batch: 1600, loss is 3.826226119995117 and perplexity is 45.889031345213944
At time: 568.4751687049866 and batch: 1650, loss is 3.787178049087524 and perplexity is 44.131686937063854
At time: 569.4735820293427 and batch: 1700, loss is 3.78222541809082 and perplexity is 43.913659327210176
At time: 570.4745762348175 and batch: 1750, loss is 3.780425887107849 and perplexity is 43.834706397103375
At time: 571.4894757270813 and batch: 1800, loss is 3.7433613109588624 and perplexity is 42.23973268757641
At time: 572.4880633354187 and batch: 1850, loss is 3.7770370769500734 and perplexity is 43.68641031435728
At time: 573.4876964092255 and batch: 1900, loss is 3.8702793645858766 and perplexity is 47.95578135664838
At time: 574.486784696579 and batch: 1950, loss is 3.8017427206039427 and perplexity is 44.77915408841459
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337747263353925 and perplexity of 76.53493194589306
finished 14 epochs...
Completing Train Step...
At time: 577.7795262336731 and batch: 50, loss is 3.9672767686843873 and perplexity is 52.84043799417435
At time: 578.7790150642395 and batch: 100, loss is 3.9579432010650635 and perplexity is 52.349542659232625
At time: 579.7738854885101 and batch: 150, loss is 3.921116147041321 and perplexity is 50.4567304911085
At time: 580.7618379592896 and batch: 200, loss is 3.9234621477127076 and perplexity is 50.575240973197864
At time: 581.7489483356476 and batch: 250, loss is 3.9173692226409913 and perplexity is 50.26802668668975
At time: 582.7405281066895 and batch: 300, loss is 3.916562547683716 and perplexity is 50.22749307933096
At time: 583.7268753051758 and batch: 350, loss is 3.938910193443298 and perplexity is 51.36259549498329
At time: 584.7250797748566 and batch: 400, loss is 3.8809354448318483 and perplexity is 48.46953444665293
At time: 585.7382016181946 and batch: 450, loss is 3.912622456550598 and perplexity is 50.02998154145914
At time: 586.7258832454681 and batch: 500, loss is 3.932013945579529 and perplexity is 51.00960485994627
At time: 587.7230548858643 and batch: 550, loss is 3.9215981435775755 and perplexity is 50.481056322448225
At time: 588.7114660739899 and batch: 600, loss is 3.8930279302597044 and perplexity is 49.059209719889616
At time: 589.7016055583954 and batch: 650, loss is 3.923400821685791 and perplexity is 50.57213948971043
At time: 590.6908421516418 and batch: 700, loss is 3.9604658699035644 and perplexity is 52.48176993189606
At time: 591.6805522441864 and batch: 750, loss is 3.897379369735718 and perplexity is 49.273153044856635
At time: 592.6665487289429 and batch: 800, loss is 3.890321035385132 and perplexity is 48.92659116976283
At time: 593.6567711830139 and batch: 850, loss is 3.897419571876526 and perplexity is 49.27513397091186
At time: 594.6447079181671 and batch: 900, loss is 3.8491582536697386 and perplexity is 46.95352363654548
At time: 595.6326813697815 and batch: 950, loss is 3.946836733818054 and perplexity is 51.77134101072068
At time: 596.6216447353363 and batch: 1000, loss is 3.90966607093811 and perplexity is 49.88229204495804
At time: 597.6184537410736 and batch: 1050, loss is 3.8659488010406493 and perplexity is 47.74855482580905
At time: 598.6099009513855 and batch: 1100, loss is 3.8865919303894043 and perplexity is 48.744478543800916
At time: 599.5980823040009 and batch: 1150, loss is 3.8696072483062744 and perplexity is 47.92356032465057
At time: 600.5868346691132 and batch: 1200, loss is 3.9044267416000364 and perplexity is 49.62162574338349
At time: 601.5765106678009 and batch: 1250, loss is 3.9065303802490234 and perplexity is 49.726121585333324
At time: 602.5667386054993 and batch: 1300, loss is 3.9050845670700074 and perplexity is 49.65427885150444
At time: 603.5578465461731 and batch: 1350, loss is 3.7875479316711425 and perplexity is 44.14801349871683
At time: 604.5555322170258 and batch: 1400, loss is 3.8053116035461425 and perplexity is 44.93925116153488
At time: 605.542268037796 and batch: 1450, loss is 3.737080888748169 and perplexity is 41.97528063674523
At time: 606.5299780368805 and batch: 1500, loss is 3.7353190660476683 and perplexity is 41.90139274225688
At time: 607.5183093547821 and batch: 1550, loss is 3.760188226699829 and perplexity is 42.95651078011173
At time: 608.5063393115997 and batch: 1600, loss is 3.8262309551239015 and perplexity is 45.8892532251267
At time: 609.4939143657684 and batch: 1650, loss is 3.7871104145050047 and perplexity is 44.12870220977852
At time: 610.4808762073517 and batch: 1700, loss is 3.782888898849487 and perplexity is 43.94280486289833
At time: 611.471214056015 and batch: 1750, loss is 3.781372389793396 and perplexity is 43.8762157056655
At time: 612.4589288234711 and batch: 1800, loss is 3.7446002769470215 and perplexity is 42.292098712888745
At time: 613.4491813182831 and batch: 1850, loss is 3.7781847286224366 and perplexity is 43.73657587700393
At time: 614.4371893405914 and batch: 1900, loss is 3.871452350616455 and perplexity is 48.01206582225769
At time: 615.4240789413452 and batch: 1950, loss is 3.8023996543884278 and perplexity is 44.80858069218274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337416821856832 and perplexity of 76.50964580642592
finished 15 epochs...
Completing Train Step...
At time: 618.6303071975708 and batch: 50, loss is 3.963476104736328 and perplexity is 52.63999040474305
At time: 619.6441042423248 and batch: 100, loss is 3.953445773124695 and perplexity is 52.11463300399183
At time: 620.6335844993591 and batch: 150, loss is 3.9161697101593016 and perplexity is 50.20776571037123
At time: 621.6204693317413 and batch: 200, loss is 3.918021392822266 and perplexity is 50.30082068723862
At time: 622.6090869903564 and batch: 250, loss is 3.9118674182891846 and perplexity is 49.99222124820449
At time: 623.596150636673 and batch: 300, loss is 3.9106422758102415 and perplexity is 49.93101115753393
At time: 624.5823338031769 and batch: 350, loss is 3.9331025171279905 and perplexity is 51.065162698349894
At time: 625.5692369937897 and batch: 400, loss is 3.874750909805298 and perplexity is 48.170697948046154
At time: 626.571019411087 and batch: 450, loss is 3.9065226030349733 and perplexity is 49.72573485614571
At time: 627.5708799362183 and batch: 500, loss is 3.9260698795318603 and perplexity is 50.70729975044648
At time: 628.5591430664062 and batch: 550, loss is 3.9158321046829223 and perplexity is 50.190818154665415
At time: 629.5499975681305 and batch: 600, loss is 3.887712459564209 and perplexity is 48.799128766986456
At time: 630.5395588874817 and batch: 650, loss is 3.9184049654006956 and perplexity is 50.32011840352755
At time: 631.5270648002625 and batch: 700, loss is 3.955706362724304 and perplexity is 52.23257606154604
At time: 632.5173363685608 and batch: 750, loss is 3.893199143409729 and perplexity is 49.06761002082395
At time: 633.5091886520386 and batch: 800, loss is 3.8862389755249023 and perplexity is 48.727276978847854
At time: 634.5020534992218 and batch: 850, loss is 3.8932947158813476 and perplexity is 49.072299757691354
At time: 635.5201439857483 and batch: 900, loss is 3.845073070526123 and perplexity is 46.762101157410925
At time: 636.5113153457642 and batch: 950, loss is 3.9429604148864748 and perplexity is 51.57104723352638
At time: 637.5152020454407 and batch: 1000, loss is 3.9059277820587157 and perplexity is 49.696165741030235
At time: 638.5188784599304 and batch: 1050, loss is 3.8624378633499146 and perplexity is 47.58120657154374
At time: 639.5135793685913 and batch: 1100, loss is 3.883341283798218 and perplexity is 48.58628472617925
At time: 640.5040454864502 and batch: 1150, loss is 3.866402130126953 and perplexity is 47.77020554161939
At time: 641.4966194629669 and batch: 1200, loss is 3.9015512084960937 and perplexity is 49.47914207232283
At time: 642.488165140152 and batch: 1250, loss is 3.9039096546173098 and perplexity is 49.595973679395605
At time: 643.4773414134979 and batch: 1300, loss is 3.902668385505676 and perplexity is 49.53444992087591
At time: 644.4699041843414 and batch: 1350, loss is 3.7852585411071775 and perplexity is 44.04705706164759
At time: 645.4587008953094 and batch: 1400, loss is 3.8033517837524413 and perplexity is 44.851264574683896
At time: 646.4515645503998 and batch: 1450, loss is 3.735346207618713 and perplexity is 41.902530027318655
At time: 647.4375486373901 and batch: 1500, loss is 3.7338560819625854 and perplexity is 41.84013649091824
At time: 648.4285509586334 and batch: 1550, loss is 3.7591913890838624 and perplexity is 42.913711449850695
At time: 649.417896270752 and batch: 1600, loss is 3.825519151687622 and perplexity is 45.85660071945428
At time: 650.4126172065735 and batch: 1650, loss is 3.786258454322815 and perplexity is 44.091122323160675
At time: 651.4021995067596 and batch: 1700, loss is 3.7824670457839966 and perplexity is 43.924271365441875
At time: 652.3940131664276 and batch: 1750, loss is 3.7811905908584595 and perplexity is 43.8682397814104
At time: 653.3823044300079 and batch: 1800, loss is 3.7445886278152467 and perplexity is 42.29160604952737
At time: 654.3737392425537 and batch: 1850, loss is 3.7780846118927003 and perplexity is 43.732197333243654
At time: 655.3625979423523 and batch: 1900, loss is 3.8713679122924805 and perplexity is 48.00801193504322
At time: 656.3518719673157 and batch: 1950, loss is 3.8020159721374513 and perplexity is 44.791391732839884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337403479287791 and perplexity of 76.50862497800472
finished 16 epochs...
Completing Train Step...
At time: 659.560714006424 and batch: 50, loss is 3.959780387878418 and perplexity is 52.44580694935714
At time: 660.5768232345581 and batch: 100, loss is 3.94936363697052 and perplexity is 51.902327601043666
At time: 661.5654537677765 and batch: 150, loss is 3.911807041168213 and perplexity is 49.98920295293345
At time: 662.5566322803497 and batch: 200, loss is 3.9133595514297483 and perplexity is 50.06687197886334
At time: 663.5448365211487 and batch: 250, loss is 3.9072347497940063 and perplexity is 49.76115948933577
At time: 664.5332925319672 and batch: 300, loss is 3.9058397245407104 and perplexity is 49.691789812690224
At time: 665.5208919048309 and batch: 350, loss is 3.92836012840271 and perplexity is 50.82356517400129
At time: 666.5140838623047 and batch: 400, loss is 3.869709973335266 and perplexity is 47.928483526638004
At time: 667.5136368274689 and batch: 450, loss is 3.901542592048645 and perplexity is 49.47871573973208
At time: 668.5098156929016 and batch: 500, loss is 3.92120343208313 and perplexity is 50.46113480115136
At time: 669.5081975460052 and batch: 550, loss is 3.9110635137557983 and perplexity is 49.952048424630014
At time: 670.4979822635651 and batch: 600, loss is 3.8833203125 and perplexity is 48.585265819396895
At time: 671.4902102947235 and batch: 650, loss is 3.914228377342224 and perplexity is 50.11039027677012
At time: 672.4796319007874 and batch: 700, loss is 3.9517300224304197 and perplexity is 52.02529394992172
At time: 673.4717540740967 and batch: 750, loss is 3.889677367210388 and perplexity is 48.89510881331057
At time: 674.4735639095306 and batch: 800, loss is 3.882792797088623 and perplexity is 48.55964310169472
At time: 675.4615323543549 and batch: 850, loss is 3.8898004627227785 and perplexity is 48.901127952240216
At time: 676.4518752098083 and batch: 900, loss is 3.8415871047973633 and perplexity is 46.59937387103101
At time: 677.4377145767212 and batch: 950, loss is 3.9396606159210203 and perplexity is 51.40115360678432
At time: 678.4284205436707 and batch: 1000, loss is 3.9027038192749024 and perplexity is 49.536205144240064
At time: 679.4166858196259 and batch: 1050, loss is 3.8594053983688354 and perplexity is 47.4371367825566
At time: 680.406210899353 and batch: 1100, loss is 3.8804900741577146 and perplexity is 48.447952343796075
At time: 681.3943700790405 and batch: 1150, loss is 3.863558082580566 and perplexity is 47.634537819930735
At time: 682.3854503631592 and batch: 1200, loss is 3.8989391326904297 and perplexity is 49.350067452165945
At time: 683.3755362033844 and batch: 1250, loss is 3.9015023708343506 and perplexity is 49.47672568572477
At time: 684.3648781776428 and batch: 1300, loss is 3.900435838699341 and perplexity is 49.42398529750463
At time: 685.3548047542572 and batch: 1350, loss is 3.7831102275848387 and perplexity is 43.95253174470596
At time: 686.344402551651 and batch: 1400, loss is 3.801476788520813 and perplexity is 44.76724745793477
At time: 687.3369569778442 and batch: 1450, loss is 3.7335979986190795 and perplexity is 41.829339641903296
At time: 688.3233644962311 and batch: 1500, loss is 3.732269215583801 and perplexity is 41.773794436946105
At time: 689.3157620429993 and batch: 1550, loss is 3.757931933403015 and perplexity is 42.85969755337318
At time: 690.3012177944183 and batch: 1600, loss is 3.8244641494750975 and perplexity is 45.80824741514281
At time: 691.2914426326752 and batch: 1650, loss is 3.785043520927429 and perplexity is 44.037587073676555
At time: 692.2798788547516 and batch: 1700, loss is 3.78154324054718 and perplexity is 43.88371263060141
At time: 693.2702884674072 and batch: 1750, loss is 3.7804903411865234 and perplexity is 43.83753181377199
At time: 694.2572393417358 and batch: 1800, loss is 3.744017415046692 and perplexity is 42.267455442373446
At time: 695.2508912086487 and batch: 1850, loss is 3.777449507713318 and perplexity is 43.704431649927784
At time: 696.2375793457031 and batch: 1900, loss is 3.8707447624206544 and perplexity is 47.97810506775731
At time: 697.2381074428558 and batch: 1950, loss is 3.8012123584747313 and perplexity is 44.75541121762427
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337543434320494 and perplexity of 76.51933349445352
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 700.4583983421326 and batch: 50, loss is 3.9612112283706664 and perplexity is 52.520902245472236
At time: 701.4514319896698 and batch: 100, loss is 3.959347810745239 and perplexity is 52.42312499874001
At time: 702.442370891571 and batch: 150, loss is 3.925667543411255 and perplexity is 50.68690247573385
At time: 703.4330358505249 and batch: 200, loss is 3.9286276960372923 and perplexity is 50.83716573456971
At time: 704.4341697692871 and batch: 250, loss is 3.926117043495178 and perplexity is 50.70969136407041
At time: 705.4266955852509 and batch: 300, loss is 3.9268289613723755 and perplexity is 50.74580535347169
At time: 706.4208817481995 and batch: 350, loss is 3.9528652477264403 and perplexity is 52.08438791578264
At time: 707.4105515480042 and batch: 400, loss is 3.8973718881607056 and perplexity is 49.27278440544503
At time: 708.4043440818787 and batch: 450, loss is 3.9269431257247924 and perplexity is 50.75159904618804
At time: 709.394609451294 and batch: 500, loss is 3.9456278181076048 and perplexity is 51.70879163929856
At time: 710.4325804710388 and batch: 550, loss is 3.9352900314331056 and perplexity is 51.176990740372915
At time: 711.4234471321106 and batch: 600, loss is 3.903624119758606 and perplexity is 49.581814321650086
At time: 712.4152159690857 and batch: 650, loss is 3.9251833248138426 and perplexity is 50.662364876170344
At time: 713.4048340320587 and batch: 700, loss is 3.961599111557007 and perplexity is 52.54127817186884
At time: 714.3998832702637 and batch: 750, loss is 3.900940432548523 and perplexity is 49.44893062958909
At time: 715.39519739151 and batch: 800, loss is 3.8993497610092165 and perplexity is 49.3703361485614
At time: 716.3897535800934 and batch: 850, loss is 3.9023058080673216 and perplexity is 49.51649310247863
At time: 717.38587474823 and batch: 900, loss is 3.8499131631851196 and perplexity is 46.98898268082036
At time: 718.3884110450745 and batch: 950, loss is 3.9446088790893556 and perplexity is 51.65613036777915
At time: 719.3848488330841 and batch: 1000, loss is 3.908264412879944 and perplexity is 49.812423105973075
At time: 720.378326177597 and batch: 1050, loss is 3.8644951581954956 and perplexity is 47.67919590448335
At time: 721.3724501132965 and batch: 1100, loss is 3.8859410381317137 and perplexity is 48.712761463432386
At time: 722.3668215274811 and batch: 1150, loss is 3.8736965370178225 and perplexity is 48.119934841298004
At time: 723.3599572181702 and batch: 1200, loss is 3.9096225118637085 and perplexity is 49.880119265809995
At time: 724.3558263778687 and batch: 1250, loss is 3.9041696071624754 and perplexity is 49.608867954860784
At time: 725.3481407165527 and batch: 1300, loss is 3.897579717636108 and perplexity is 49.283025806575296
At time: 726.3416051864624 and batch: 1350, loss is 3.7810262632369995 and perplexity is 43.861031610176525
At time: 727.3426740169525 and batch: 1400, loss is 3.803558421134949 and perplexity is 44.86053348021597
At time: 728.3447363376617 and batch: 1450, loss is 3.7324752807617188 and perplexity is 41.78240344830731
At time: 729.3437402248383 and batch: 1500, loss is 3.7295974349975585 and perplexity is 41.66233299052491
At time: 730.3370566368103 and batch: 1550, loss is 3.7580996561050415 and perplexity is 42.86688670052961
At time: 731.3326482772827 and batch: 1600, loss is 3.8244497919082643 and perplexity is 45.807589724890455
At time: 732.3256647586823 and batch: 1650, loss is 3.7833585214614867 and perplexity is 43.96344624414696
At time: 733.3183977603912 and batch: 1700, loss is 3.7704905319213866 and perplexity is 43.40134936234847
At time: 734.3131544589996 and batch: 1750, loss is 3.7692895460128786 and perplexity is 43.34925624116774
At time: 735.3083739280701 and batch: 1800, loss is 3.7318659591674805 and perplexity is 41.756952282387026
At time: 736.3023765087128 and batch: 1850, loss is 3.7669590282440186 and perplexity is 43.24834765952428
At time: 737.3038206100464 and batch: 1900, loss is 3.8628259038925172 and perplexity is 47.59967359150395
At time: 738.2973017692566 and batch: 1950, loss is 3.7975824642181397 and perplexity is 44.59324830266747
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332555868459302 and perplexity of 76.13863843900103
finished 18 epochs...
Completing Train Step...
At time: 741.5168914794922 and batch: 50, loss is 3.9631588745117186 and perplexity is 52.623294057196574
At time: 742.5335111618042 and batch: 100, loss is 3.955635766983032 and perplexity is 52.22888879427465
At time: 743.5255424976349 and batch: 150, loss is 3.917534828186035 and perplexity is 50.27635203999079
At time: 744.5169765949249 and batch: 200, loss is 3.919244899749756 and perplexity is 50.36240175455705
At time: 745.5098190307617 and batch: 250, loss is 3.9157554292678833 and perplexity is 50.18696990038739
At time: 746.5016539096832 and batch: 300, loss is 3.916484637260437 and perplexity is 50.223579986522246
At time: 747.493077993393 and batch: 350, loss is 3.9434541606903077 and perplexity is 51.596516508853696
At time: 748.4854714870453 and batch: 400, loss is 3.8870440673828126 and perplexity is 48.76652270889069
At time: 749.475412607193 and batch: 450, loss is 3.917362833023071 and perplexity is 50.26770549423178
At time: 750.4634902477264 and batch: 500, loss is 3.9359384393692016 and perplexity is 51.21018506788418
At time: 751.4533016681671 and batch: 550, loss is 3.924959592819214 and perplexity is 50.651031352107246
At time: 752.4492964744568 and batch: 600, loss is 3.8935868310928345 and perplexity is 49.086636616818595
At time: 753.4384913444519 and batch: 650, loss is 3.9172956466674806 and perplexity is 50.26432830374755
At time: 754.4319844245911 and batch: 700, loss is 3.954610595703125 and perplexity is 52.175372673783166
At time: 755.4407961368561 and batch: 750, loss is 3.8946845531463623 and perplexity is 49.140549685735
At time: 756.440128326416 and batch: 800, loss is 3.892465419769287 and perplexity is 49.031621159925244
At time: 757.438440322876 and batch: 850, loss is 3.896666684150696 and perplexity is 49.23804928940904
At time: 758.4280881881714 and batch: 900, loss is 3.8451519632339477 and perplexity is 46.765790491723685
At time: 759.4168701171875 and batch: 950, loss is 3.9411325359344485 and perplexity is 51.47686770236788
At time: 760.4350848197937 and batch: 1000, loss is 3.9050785303115845 and perplexity is 49.65397910152311
At time: 761.4246535301208 and batch: 1050, loss is 3.861200098991394 and perplexity is 47.522348683526566
At time: 762.4139947891235 and batch: 1100, loss is 3.8830685663223266 and perplexity is 48.57303620387968
At time: 763.4069881439209 and batch: 1150, loss is 3.8706458473205565 and perplexity is 47.973359543397905
At time: 764.3986709117889 and batch: 1200, loss is 3.9065736627578733 and perplexity is 49.728273903209434
At time: 765.3900167942047 and batch: 1250, loss is 3.901722860336304 and perplexity is 49.48763598708876
At time: 766.3847014904022 and batch: 1300, loss is 3.895988984107971 and perplexity is 49.20469196570847
At time: 767.372284412384 and batch: 1350, loss is 3.779688391685486 and perplexity is 43.8023904197023
At time: 768.3653526306152 and batch: 1400, loss is 3.8030982494354246 and perplexity is 44.8398946813426
At time: 769.3550136089325 and batch: 1450, loss is 3.733108868598938 and perplexity is 41.808884659142635
At time: 770.3475518226624 and batch: 1500, loss is 3.7311148834228516 and perplexity is 41.725601423266816
At time: 771.3387994766235 and batch: 1550, loss is 3.7599953413009644 and perplexity is 42.9482258954384
At time: 772.3383295536041 and batch: 1600, loss is 3.826878423690796 and perplexity is 45.91897469496867
At time: 773.3391315937042 and batch: 1650, loss is 3.786033887863159 and perplexity is 44.081222047594835
At time: 774.3380241394043 and batch: 1700, loss is 3.7733997821807863 and perplexity is 43.52779859628642
At time: 775.3298091888428 and batch: 1750, loss is 3.7724721145629885 and perplexity is 43.48743799056252
At time: 776.3213558197021 and batch: 1800, loss is 3.734941830635071 and perplexity is 41.885589034123946
At time: 777.317435503006 and batch: 1850, loss is 3.770744285583496 and perplexity is 43.41236401113429
At time: 778.309953212738 and batch: 1900, loss is 3.8668705892562865 and perplexity is 47.792589173014385
At time: 779.3083410263062 and batch: 1950, loss is 3.801052837371826 and perplexity is 44.748272354480655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3316922919694765 and perplexity of 76.07291528344827
finished 19 epochs...
Completing Train Step...
At time: 782.5468616485596 and batch: 50, loss is 3.9629420375823976 and perplexity is 52.611884620740746
At time: 783.5645806789398 and batch: 100, loss is 3.9536934328079223 and perplexity is 52.12754129585887
At time: 784.5545890331268 and batch: 150, loss is 3.914301037788391 and perplexity is 50.114031452368344
At time: 785.5732827186584 and batch: 200, loss is 3.915717887878418 and perplexity is 50.185085847169475
At time: 786.564080953598 and batch: 250, loss is 3.9120644426345823 and perplexity is 50.002071903248456
At time: 787.5547227859497 and batch: 300, loss is 3.9128479528427125 and perplexity is 50.04126438886361
At time: 788.5475268363953 and batch: 350, loss is 3.9401586627960206 and perplexity is 51.42676016681388
At time: 789.5370225906372 and batch: 400, loss is 3.883323197364807 and perplexity is 48.58540598152257
At time: 790.5379116535187 and batch: 450, loss is 3.9134521484375 and perplexity is 50.07150823604453
At time: 791.5421676635742 and batch: 500, loss is 3.9318706798553467 and perplexity is 51.00229745542857
At time: 792.5372133255005 and batch: 550, loss is 3.920703067779541 and perplexity is 50.435892166361626
At time: 793.5372400283813 and batch: 600, loss is 3.8896418142318727 and perplexity is 48.89337047745911
At time: 794.530782699585 and batch: 650, loss is 3.9138755226135253 and perplexity is 50.092711707770775
At time: 795.525387763977 and batch: 700, loss is 3.9515122747421265 and perplexity is 52.01396679570693
At time: 796.5156078338623 and batch: 750, loss is 3.8918731784820557 and perplexity is 49.00259120671141
At time: 797.5209472179413 and batch: 800, loss is 3.8897117662429808 and perplexity is 48.89679078668122
At time: 798.5191502571106 and batch: 850, loss is 3.894296631813049 and perplexity is 49.12149071511082
At time: 799.5211853981018 and batch: 900, loss is 3.8431220960617067 and perplexity is 46.670958429627355
At time: 800.5100862979889 and batch: 950, loss is 3.939568033218384 and perplexity is 51.39639496935194
At time: 801.5074052810669 and batch: 1000, loss is 3.9036297941207887 and perplexity is 49.58209566762046
At time: 802.5074143409729 and batch: 1050, loss is 3.85963454246521 and perplexity is 47.44800796788563
At time: 803.5024404525757 and batch: 1100, loss is 3.8816620206832884 and perplexity is 48.50476403684731
At time: 804.4984266757965 and batch: 1150, loss is 3.869202184677124 and perplexity is 47.904152164418925
At time: 805.5004515647888 and batch: 1200, loss is 3.905128011703491 and perplexity is 49.65643611031036
At time: 806.498583316803 and batch: 1250, loss is 3.900511646270752 and perplexity is 49.427732151817644
At time: 807.4893691539764 and batch: 1300, loss is 3.895125737190247 and perplexity is 49.16223449530832
At time: 808.4832165241241 and batch: 1350, loss is 3.7789413213729857 and perplexity is 43.769679174524654
At time: 809.4750595092773 and batch: 1400, loss is 3.8026334285736083 and perplexity is 44.81905700612132
At time: 810.467690706253 and batch: 1450, loss is 3.733168783187866 and perplexity is 41.811389696323914
At time: 811.4575743675232 and batch: 1500, loss is 3.731673083305359 and perplexity is 41.7488991508683
At time: 812.450493812561 and batch: 1550, loss is 3.7608436822891234 and perplexity is 42.984676094747215
At time: 813.4386196136475 and batch: 1600, loss is 3.8279754018783567 and perplexity is 45.96937444726457
At time: 814.4394447803497 and batch: 1650, loss is 3.7871033334732056 and perplexity is 44.128389734141244
At time: 815.4375464916229 and batch: 1700, loss is 3.7746161794662476 and perplexity is 43.58077790775393
At time: 816.4287152290344 and batch: 1750, loss is 3.7738296222686767 and perplexity is 43.54651261078941
At time: 817.4233469963074 and batch: 1800, loss is 3.7363289976119995 and perplexity is 41.94373165748149
At time: 818.4215657711029 and batch: 1850, loss is 3.7723429298400877 and perplexity is 43.48182044079466
At time: 819.4193871021271 and batch: 1900, loss is 3.8683757305145265 and perplexity is 47.86457793385326
At time: 820.409731388092 and batch: 1950, loss is 3.8021810817718507 and perplexity is 44.79878783372008
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331309331849564 and perplexity of 76.04378796834526
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f4a57130b38>
ELAPSED
1699.5496175289154


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.78177940258892}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.6888560527046866, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6228089196258255, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.04378796834526}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.14308718722040714, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.37386466100496807, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4657328128814697 and batch: 50, loss is 7.530598793029785 and perplexity is 1864.221452223596
At time: 2.4685070514678955 and batch: 100, loss is 6.630123958587647 and perplexity is 757.5760728817241
At time: 3.474559783935547 and batch: 150, loss is 6.313887939453125 and perplexity is 552.1876529223358
At time: 4.485499382019043 and batch: 200, loss is 6.109106636047363 and perplexity is 449.93657844698373
At time: 5.48621129989624 and batch: 250, loss is 5.999878902435302 and perplexity is 403.37994220625984
At time: 6.488666534423828 and batch: 300, loss is 5.866575098037719 and perplexity is 353.0377875322347
At time: 7.4907166957855225 and batch: 350, loss is 5.776931982040406 and perplexity is 322.76741357897896
At time: 8.491515398025513 and batch: 400, loss is 5.695806608200074 and perplexity is 297.61675691150884
At time: 9.48989748954773 and batch: 450, loss is 5.595851068496704 and perplexity is 269.3067510799153
At time: 10.515090942382812 and batch: 500, loss is 5.5620413017272945 and perplexity is 260.3537548255981
At time: 11.523413181304932 and batch: 550, loss is 5.514414844512939 and perplexity is 248.2446730062905
At time: 12.523273944854736 and batch: 600, loss is 5.5071357727050785 and perplexity is 246.44424288525195
At time: 13.524653196334839 and batch: 650, loss is 5.556661109924317 and perplexity is 258.95676309955684
At time: 14.525008916854858 and batch: 700, loss is 5.492979984283448 and perplexity is 242.98020625532536
At time: 15.531669616699219 and batch: 750, loss is 5.416415615081787 and perplexity is 225.0709340764874
At time: 16.53623127937317 and batch: 800, loss is 5.404948301315308 and perplexity is 222.50471698525456
At time: 17.54103112220764 and batch: 850, loss is 5.407253198623657 and perplexity is 223.01815899677678
At time: 18.540537118911743 and batch: 900, loss is 5.406974802017212 and perplexity is 222.95608013980893
At time: 19.545451164245605 and batch: 950, loss is 5.420612878799439 and perplexity is 226.0176014585243
At time: 20.559765338897705 and batch: 1000, loss is 5.383291854858398 and perplexity is 217.73785840815592
At time: 21.568952322006226 and batch: 1050, loss is 5.281741428375244 and perplexity is 196.71213735066286
At time: 22.59168291091919 and batch: 1100, loss is 5.353939867019653 and perplexity is 211.43970329145023
At time: 23.60867166519165 and batch: 1150, loss is 5.257691392898559 and perplexity is 192.0376396961518
At time: 24.62609362602234 and batch: 1200, loss is 5.329813461303711 and perplexity is 206.39946907719994
At time: 25.63879704475403 and batch: 1250, loss is 5.282688598632813 and perplexity is 196.89854550265684
At time: 26.660693168640137 and batch: 1300, loss is 5.289074106216431 and perplexity is 198.15986545640598
At time: 27.677086353302002 and batch: 1350, loss is 5.226142778396606 and perplexity is 186.0736900646397
At time: 28.687509059906006 and batch: 1400, loss is 5.221185617446899 and perplexity is 185.15357529717895
At time: 29.701781272888184 and batch: 1450, loss is 5.181955728530884 and perplexity is 178.0306503650934
At time: 30.71852135658264 and batch: 1500, loss is 5.143957662582397 and perplexity is 171.39274246382436
At time: 31.72670340538025 and batch: 1550, loss is 5.129055919647217 and perplexity is 168.85762760219973
At time: 32.73315477371216 and batch: 1600, loss is 5.174905042648316 and perplexity is 176.77982693520727
At time: 33.73429775238037 and batch: 1650, loss is 5.152105751037598 and perplexity is 172.79497067175916
At time: 34.74222016334534 and batch: 1700, loss is 5.164488620758057 and perplexity is 174.94797093193242
At time: 35.74626636505127 and batch: 1750, loss is 5.147691211700439 and perplexity is 172.03384172937692
At time: 36.7483184337616 and batch: 1800, loss is 5.113537359237671 and perplexity is 166.2574281663517
At time: 37.75003170967102 and batch: 1850, loss is 5.1124165248870845 and perplexity is 166.07118552289649
At time: 38.760396242141724 and batch: 1900, loss is 5.191381912231446 and perplexity is 179.71673416313277
At time: 39.77208065986633 and batch: 1950, loss is 5.115412435531616 and perplexity is 166.56946598453186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.808946902252907 and perplexity of 122.60243715907131
finished 1 epochs...
Completing Train Step...
At time: 43.01379370689392 and batch: 50, loss is 5.055066108703613 and perplexity is 156.81489683104368
At time: 44.05909252166748 and batch: 100, loss is 5.007005405426026 and perplexity is 149.45650371173795
At time: 45.05014252662659 and batch: 150, loss is 4.941868410110474 and perplexity is 140.0316418253576
At time: 46.03625154495239 and batch: 200, loss is 4.905619411468506 and perplexity is 135.04653347708637
At time: 47.03209185600281 and batch: 250, loss is 4.925581159591675 and perplexity is 137.76938438097545
At time: 48.02103018760681 and batch: 300, loss is 4.933870038986206 and perplexity is 138.91608405464075
At time: 49.00866651535034 and batch: 350, loss is 4.932013397216797 and perplexity is 138.658405932545
At time: 50.003981828689575 and batch: 400, loss is 4.870316896438599 and perplexity is 130.36222167522124
At time: 50.98990035057068 and batch: 450, loss is 4.847886724472046 and perplexity is 127.47072424545217
At time: 51.97929120063782 and batch: 500, loss is 4.849810009002685 and perplexity is 127.71612262731419
At time: 52.967350006103516 and batch: 550, loss is 4.819757642745972 and perplexity is 123.93505058120425
At time: 53.95579433441162 and batch: 600, loss is 4.78507734298706 and perplexity is 119.71062150286726
At time: 54.94658136367798 and batch: 650, loss is 4.852734088897705 and perplexity is 128.0901213082889
At time: 55.933178663253784 and batch: 700, loss is 4.874852800369263 and perplexity is 130.95487528271664
At time: 56.929179668426514 and batch: 750, loss is 4.807343111038208 and perplexity is 122.40596603889593
At time: 57.93233609199524 and batch: 800, loss is 4.804831447601319 and perplexity is 122.0989092226492
At time: 58.92143511772156 and batch: 850, loss is 4.812768516540527 and perplexity is 123.07187281428719
At time: 59.909907817840576 and batch: 900, loss is 4.793468561172485 and perplexity is 120.71936582484605
At time: 60.89779710769653 and batch: 950, loss is 4.84172945022583 and perplexity is 126.68826342289955
At time: 61.88839268684387 and batch: 1000, loss is 4.811424303054809 and perplexity is 122.90654908322587
At time: 62.87666058540344 and batch: 1050, loss is 4.735107173919678 and perplexity is 113.8756625653444
At time: 63.86402606964111 and batch: 1100, loss is 4.795936040878296 and perplexity is 121.01760620984727
At time: 64.8529212474823 and batch: 1150, loss is 4.7394389820098874 and perplexity is 114.37002003954284
At time: 65.85035419464111 and batch: 1200, loss is 4.800839891433716 and perplexity is 121.61251594731206
At time: 66.84598422050476 and batch: 1250, loss is 4.786468601226806 and perplexity is 119.87728580107436
At time: 67.84006857872009 and batch: 1300, loss is 4.777350282669067 and perplexity is 118.78917493119475
At time: 68.83831453323364 and batch: 1350, loss is 4.672650518417359 and perplexity is 106.98092188425105
At time: 69.8342752456665 and batch: 1400, loss is 4.680505027770996 and perplexity is 107.82451319678808
At time: 70.82862162590027 and batch: 1450, loss is 4.628980312347412 and perplexity is 102.40958506215397
At time: 71.82318496704102 and batch: 1500, loss is 4.614706373214721 and perplexity is 100.95818015402871
At time: 72.82046484947205 and batch: 1550, loss is 4.628838787078857 and perplexity is 102.39509254367842
At time: 73.81465649604797 and batch: 1600, loss is 4.685999898910523 and perplexity is 108.4186257937016
At time: 74.81063079833984 and batch: 1650, loss is 4.657466554641724 and perplexity is 105.36879763298153
At time: 75.81357455253601 and batch: 1700, loss is 4.668733978271485 and perplexity is 106.56274624423271
At time: 76.80883860588074 and batch: 1750, loss is 4.650814743041992 and perplexity is 104.67023018792125
At time: 77.80352330207825 and batch: 1800, loss is 4.6088498592376705 and perplexity is 100.36864515586285
At time: 78.79868674278259 and batch: 1850, loss is 4.643863954544067 and perplexity is 103.94521219821607
At time: 79.79164505004883 and batch: 1900, loss is 4.7519393634796145 and perplexity is 115.80866197180185
At time: 80.7954273223877 and batch: 1950, loss is 4.680224981307983 and perplexity is 107.79432155097034
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.595731797329215 and perplexity of 99.06060131277839
finished 2 epochs...
Completing Train Step...
At time: 84.08305335044861 and batch: 50, loss is 4.671610260009766 and perplexity is 106.86969194477929
At time: 85.07975101470947 and batch: 100, loss is 4.619961538314819 and perplexity is 101.49012857310329
At time: 86.06964015960693 and batch: 150, loss is 4.567338151931763 and perplexity is 96.28746574598587
At time: 87.06102657318115 and batch: 200, loss is 4.557419271469116 and perplexity is 95.33712284357095
At time: 88.06244802474976 and batch: 250, loss is 4.568733882904053 and perplexity is 96.4219509749384
At time: 89.05422234535217 and batch: 300, loss is 4.581050434112549 and perplexity is 97.61688047130393
At time: 90.04997777938843 and batch: 350, loss is 4.590091915130615 and perplexity is 98.503483706432
At time: 91.04339814186096 and batch: 400, loss is 4.5335038471221925 and perplexity is 93.08414296088668
At time: 92.0341567993164 and batch: 450, loss is 4.532649431228638 and perplexity is 93.00464435697468
At time: 93.02544569969177 and batch: 500, loss is 4.546111459732056 and perplexity is 94.26514091435668
At time: 94.04304957389832 and batch: 550, loss is 4.515698003768921 and perplexity is 91.441370173045
At time: 95.03070974349976 and batch: 600, loss is 4.4885962867736815 and perplexity is 88.99643268819189
At time: 96.02003216743469 and batch: 650, loss is 4.554162368774414 and perplexity is 95.02712420300418
At time: 97.0115077495575 and batch: 700, loss is 4.581038904190064 and perplexity is 97.61575496272738
At time: 98.01120138168335 and batch: 750, loss is 4.52862509727478 and perplexity is 92.63111471694646
At time: 99.004723072052 and batch: 800, loss is 4.52959527015686 and perplexity is 92.72102652042608
At time: 99.99499773979187 and batch: 850, loss is 4.537385663986206 and perplexity is 93.44618078445511
At time: 100.99051976203918 and batch: 900, loss is 4.511445360183716 and perplexity is 91.05332830345056
At time: 101.9782783985138 and batch: 950, loss is 4.56592041015625 and perplexity is 96.1510517061303
At time: 102.96662473678589 and batch: 1000, loss is 4.541222476959229 and perplexity is 93.80540500055241
At time: 103.95659518241882 and batch: 1050, loss is 4.48227144241333 and perplexity is 88.43532044715305
At time: 104.9466335773468 and batch: 1100, loss is 4.528759641647339 and perplexity is 92.643578550606
At time: 105.93622612953186 and batch: 1150, loss is 4.49276029586792 and perplexity is 89.36778726860994
At time: 106.92643809318542 and batch: 1200, loss is 4.545203857421875 and perplexity is 94.17962446802568
At time: 107.91650247573853 and batch: 1250, loss is 4.544060335159302 and perplexity is 94.07198952397215
At time: 108.90622973442078 and batch: 1300, loss is 4.524037456512451 and perplexity is 92.20712972823398
At time: 109.89851593971252 and batch: 1350, loss is 4.414374465942383 and perplexity is 82.63013677170942
At time: 110.89189457893372 and batch: 1400, loss is 4.431927680969238 and perplexity is 84.09336594825763
At time: 111.88161897659302 and batch: 1450, loss is 4.376563596725464 and perplexity is 79.56414858452825
At time: 112.87221050262451 and batch: 1500, loss is 4.368756093978882 and perplexity is 78.94536997700654
At time: 113.86268186569214 and batch: 1550, loss is 4.391240653991699 and perplexity is 80.74052792561777
At time: 114.86448740959167 and batch: 1600, loss is 4.456882333755493 and perplexity is 86.21828979467689
At time: 115.85265278816223 and batch: 1650, loss is 4.423322877883911 and perplexity is 83.37286343028865
At time: 116.84487676620483 and batch: 1700, loss is 4.428829088211059 and perplexity is 83.83319813872662
At time: 117.83341646194458 and batch: 1750, loss is 4.42147198677063 and perplexity is 83.21869205950011
At time: 118.8263897895813 and batch: 1800, loss is 4.3792798137664795 and perplexity is 79.78055585227027
At time: 119.82005381584167 and batch: 1850, loss is 4.420601224899292 and perplexity is 83.14625993561458
At time: 120.81704664230347 and batch: 1900, loss is 4.532730712890625 and perplexity is 93.01220423627612
At time: 121.81405997276306 and batch: 1950, loss is 4.46417649269104 and perplexity is 86.84947890190428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.519337073037791 and perplexity of 91.77473785930219
finished 3 epochs...
Completing Train Step...
At time: 125.06467962265015 and batch: 50, loss is 4.458466377258301 and perplexity is 86.3549715427868
At time: 126.08102345466614 and batch: 100, loss is 4.40660982131958 and perplexity is 81.99102756345442
At time: 127.07812190055847 and batch: 150, loss is 4.362576684951782 and perplexity is 78.45903841350021
At time: 128.07249927520752 and batch: 200, loss is 4.354818620681763 and perplexity is 77.85270318590693
At time: 129.06224751472473 and batch: 250, loss is 4.367686357498169 and perplexity is 78.86096438867628
At time: 130.05867099761963 and batch: 300, loss is 4.374067764282227 and perplexity is 79.36581740482227
At time: 131.06091165542603 and batch: 350, loss is 4.387297792434692 and perplexity is 80.42280598040209
At time: 132.06264209747314 and batch: 400, loss is 4.3332648181915285 and perplexity is 76.19263604486693
At time: 133.05455017089844 and batch: 450, loss is 4.344376745223999 and perplexity is 77.04400446870802
At time: 134.04292511940002 and batch: 500, loss is 4.364541368484497 and perplexity is 78.61333711869396
At time: 135.03194165229797 and batch: 550, loss is 4.330181455612182 and perplexity is 75.95806833655018
At time: 136.02091002464294 and batch: 600, loss is 4.311489796638488 and perplexity is 74.55147278168576
At time: 137.01030158996582 and batch: 650, loss is 4.374322843551636 and perplexity is 79.38606456174713
At time: 137.99996876716614 and batch: 700, loss is 4.401109609603882 and perplexity is 81.54129749215261
At time: 138.98864579200745 and batch: 750, loss is 4.352666873931884 and perplexity is 77.68536398521326
At time: 139.9850389957428 and batch: 800, loss is 4.356589918136597 and perplexity is 77.99072568427503
At time: 140.97537541389465 and batch: 850, loss is 4.361553897857666 and perplexity is 78.37883254534944
At time: 141.97017884254456 and batch: 900, loss is 4.3361421394348145 and perplexity is 76.41218243642065
At time: 142.96085023880005 and batch: 950, loss is 4.395206003189087 and perplexity is 81.06132793489931
At time: 143.99783158302307 and batch: 1000, loss is 4.372548198699951 and perplexity is 79.24530742488253
At time: 144.98678731918335 and batch: 1050, loss is 4.319944458007813 and perplexity is 75.18445228179094
At time: 145.97510623931885 and batch: 1100, loss is 4.356694488525391 and perplexity is 77.99888163121003
At time: 146.97332429885864 and batch: 1150, loss is 4.328962841033936 and perplexity is 75.86556110391888
At time: 147.96284365653992 and batch: 1200, loss is 4.379253425598145 and perplexity is 79.77845061730936
At time: 148.954181432724 and batch: 1250, loss is 4.384754619598389 and perplexity is 80.21853674090048
At time: 149.9585542678833 and batch: 1300, loss is 4.35907395362854 and perplexity is 78.18469823252316
At time: 150.9614770412445 and batch: 1350, loss is 4.251645283699036 and perplexity is 70.22085057711489
At time: 151.9563763141632 and batch: 1400, loss is 4.276129560470581 and perplexity is 71.96137814709506
At time: 152.94686317443848 and batch: 1450, loss is 4.216620573997497 and perplexity is 67.8039582152051
At time: 153.93407797813416 and batch: 1500, loss is 4.208839168548584 and perplexity is 67.27839558515863
At time: 154.93184995651245 and batch: 1550, loss is 4.236064872741699 and perplexity is 69.13525980298195
At time: 155.9237072467804 and batch: 1600, loss is 4.3058239936828615 and perplexity is 74.13027317060842
At time: 156.91552090644836 and batch: 1650, loss is 4.270656332969666 and perplexity is 71.56859303488491
At time: 157.90568709373474 and batch: 1700, loss is 4.273622155189514 and perplexity is 71.78116783206038
At time: 158.90332627296448 and batch: 1750, loss is 4.2704249858856205 and perplexity is 71.55203776465765
At time: 159.89220476150513 and batch: 1800, loss is 4.226922979354859 and perplexity is 68.50611280766886
At time: 160.88220381736755 and batch: 1850, loss is 4.27573637008667 and perplexity is 71.9330891870326
At time: 161.87044382095337 and batch: 1900, loss is 4.383499965667725 and perplexity is 80.11795335033409
At time: 162.85813975334167 and batch: 1950, loss is 4.309822397232056 and perplexity is 74.42726927742163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488566269985465 and perplexity of 88.99376134121268
finished 4 epochs...
Completing Train Step...
At time: 166.06453275680542 and batch: 50, loss is 4.310084528923035 and perplexity is 74.44678158065707
At time: 167.08107805252075 and batch: 100, loss is 4.26015076637268 and perplexity is 70.8206600234451
At time: 168.0717420578003 and batch: 150, loss is 4.223873949050903 and perplexity is 68.29755370679538
At time: 169.09187602996826 and batch: 200, loss is 4.216149988174439 and perplexity is 67.77205814017199
At time: 170.08872079849243 and batch: 250, loss is 4.225909004211426 and perplexity is 68.43668451733753
At time: 171.08748173713684 and batch: 300, loss is 4.232180142402649 and perplexity is 68.86720895146395
At time: 172.0786714553833 and batch: 350, loss is 4.24693006515503 and perplexity is 69.89052331493538
At time: 173.07949709892273 and batch: 400, loss is 4.193222093582153 and perplexity is 66.2358656604079
At time: 174.07488250732422 and batch: 450, loss is 4.2114905166625975 and perplexity is 67.45701071321521
At time: 175.06445360183716 and batch: 500, loss is 4.239740643501282 and perplexity is 69.38985279550405
At time: 176.07330679893494 and batch: 550, loss is 4.202599730491638 and perplexity is 66.85992307759322
At time: 177.08344078063965 and batch: 600, loss is 4.1877730321884155 and perplexity is 65.87592392488797
At time: 178.0810031890869 and batch: 650, loss is 4.245859355926513 and perplexity is 69.81573093422766
At time: 179.07534074783325 and batch: 700, loss is 4.267700791358948 and perplexity is 71.35738135635052
At time: 180.06901335716248 and batch: 750, loss is 4.227135801315308 and perplexity is 68.5206939644395
At time: 181.0633888244629 and batch: 800, loss is 4.230511903762817 and perplexity is 68.7524177886226
At time: 182.05632495880127 and batch: 850, loss is 4.234245910644531 and perplexity is 69.00961968776748
At time: 183.04962849617004 and batch: 900, loss is 4.210152759552002 and perplexity is 67.36682995090099
At time: 184.04336404800415 and batch: 950, loss is 4.275987334251404 and perplexity is 71.951144080148
At time: 185.0407111644745 and batch: 1000, loss is 4.250388135910034 and perplexity is 70.13262805606277
At time: 186.03311347961426 and batch: 1050, loss is 4.203845129013062 and perplexity is 66.9432421989227
At time: 187.03821897506714 and batch: 1100, loss is 4.2321651792526245 and perplexity is 68.86617848879412
At time: 188.03708410263062 and batch: 1150, loss is 4.208877682685852 and perplexity is 67.28098680442032
At time: 189.0364453792572 and batch: 1200, loss is 4.26137677192688 and perplexity is 70.90753979264339
At time: 190.036527633667 and batch: 1250, loss is 4.2687087059021 and perplexity is 71.42933975664806
At time: 191.03346014022827 and batch: 1300, loss is 4.237784314155578 and perplexity is 69.25423608891057
At time: 192.0318524837494 and batch: 1350, loss is 4.131098408699035 and perplexity is 62.24625722882135
At time: 193.02973294258118 and batch: 1400, loss is 4.161325159072876 and perplexity is 64.15648384056938
At time: 194.02908778190613 and batch: 1450, loss is 4.101002292633057 and perplexity is 60.40079654186643
At time: 195.02948570251465 and batch: 1500, loss is 4.097065892219543 and perplexity is 60.16350217062421
At time: 196.0291087627411 and batch: 1550, loss is 4.1233783531188966 and perplexity is 61.767562814584785
At time: 197.02880311012268 and batch: 1600, loss is 4.197048201560974 and perplexity is 66.48977667021317
At time: 198.04135537147522 and batch: 1650, loss is 4.15961763381958 and perplexity is 64.04702849972259
At time: 199.04088044166565 and batch: 1700, loss is 4.16035632610321 and perplexity is 64.09435702392048
At time: 200.03974652290344 and batch: 1750, loss is 4.1589635181427 and perplexity is 64.00514803315151
At time: 201.03940844535828 and batch: 1800, loss is 4.114153966903687 and perplexity is 61.200414777392425
At time: 202.03772234916687 and batch: 1850, loss is 4.16895628452301 and perplexity is 64.64794282480808
At time: 203.03654050827026 and batch: 1900, loss is 4.271709203720093 and perplexity is 71.64398519527622
At time: 204.0354723930359 and batch: 1950, loss is 4.196588439941406 and perplexity is 66.45921424905907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4771901685138085 and perplexity of 87.98709610130844
finished 5 epochs...
Completing Train Step...
At time: 207.32299709320068 and batch: 50, loss is 4.200360670089721 and perplexity is 66.71038714382249
At time: 208.31811785697937 and batch: 100, loss is 4.155104665756226 and perplexity is 63.758637544604234
At time: 209.30977249145508 and batch: 150, loss is 4.117661137580871 and perplexity is 61.41543190802211
At time: 210.30147290229797 and batch: 200, loss is 4.110440087318421 and perplexity is 60.973545349973925
At time: 211.29206323623657 and batch: 250, loss is 4.121619243621826 and perplexity is 61.65900242103108
At time: 212.27999258041382 and batch: 300, loss is 4.12583137512207 and perplexity is 61.91926599480037
At time: 213.2797577381134 and batch: 350, loss is 4.140552353858948 and perplexity is 62.83752041215279
At time: 214.2690327167511 and batch: 400, loss is 4.089735589027405 and perplexity is 59.72409790939531
At time: 215.26740550994873 and batch: 450, loss is 4.114546160697937 and perplexity is 61.22442190768972
At time: 216.25709223747253 and batch: 500, loss is 4.143812384605408 and perplexity is 63.04270693619284
At time: 217.24683713912964 and batch: 550, loss is 4.1067047119140625 and perplexity is 60.7462111220323
At time: 218.23693108558655 and batch: 600, loss is 4.093589272499084 and perplexity is 59.95469972618816
At time: 219.2517602443695 and batch: 650, loss is 4.148324151039123 and perplexity is 63.327783521136006
At time: 220.2416615486145 and batch: 700, loss is 4.164359731674194 and perplexity is 64.35146704434547
At time: 221.2329409122467 and batch: 750, loss is 4.1301419639587404 and perplexity is 62.18675058543617
At time: 222.22238945960999 and batch: 800, loss is 4.1357754039764405 and perplexity is 62.53806453869898
At time: 223.21122288703918 and batch: 850, loss is 4.137513527870178 and perplexity is 62.64685796377818
At time: 224.21182584762573 and batch: 900, loss is 4.113438625335693 and perplexity is 61.15665123153165
At time: 225.1993327140808 and batch: 950, loss is 4.181985564231873 and perplexity is 65.49577025076537
At time: 226.18949580192566 and batch: 1000, loss is 4.157267346382141 and perplexity is 63.896676327855
At time: 227.17926502227783 and batch: 1050, loss is 4.111329736709595 and perplexity is 61.02781456417957
At time: 228.17163467407227 and batch: 1100, loss is 4.135878567695618 and perplexity is 62.54451653082696
At time: 229.16309642791748 and batch: 1150, loss is 4.1145563888549805 and perplexity is 61.225048123894375
At time: 230.1571750640869 and batch: 1200, loss is 4.16934579372406 and perplexity is 64.67312869811353
At time: 231.16065526008606 and batch: 1250, loss is 4.180655512809754 and perplexity is 65.40871541493824
At time: 232.1524305343628 and batch: 1300, loss is 4.147642693519592 and perplexity is 63.28464302773659
At time: 233.14479613304138 and batch: 1350, loss is 4.039330339431762 and perplexity is 56.788301183363814
At time: 234.13433980941772 and batch: 1400, loss is 4.072387719154358 and perplexity is 58.69694722858652
At time: 235.12413907051086 and batch: 1450, loss is 4.011476788520813 and perplexity is 55.22837099350842
At time: 236.11238431930542 and batch: 1500, loss is 4.010267858505249 and perplexity is 55.16164410030252
At time: 237.10109305381775 and batch: 1550, loss is 4.038223433494568 and perplexity is 56.72547665245848
At time: 238.09301257133484 and batch: 1600, loss is 4.1123315048217775 and perplexity is 61.08898091490075
At time: 239.08855533599854 and batch: 1650, loss is 4.071916375160217 and perplexity is 58.669287294219984
At time: 240.07932782173157 and batch: 1700, loss is 4.071216869354248 and perplexity is 58.62826213746608
At time: 241.06941175460815 and batch: 1750, loss is 4.069434990882874 and perplexity is 58.52388671912148
At time: 242.06865882873535 and batch: 1800, loss is 4.028400864601135 and perplexity is 56.17101433020849
At time: 243.06232857704163 and batch: 1850, loss is 4.084037947654724 and perplexity is 59.38477899488892
At time: 244.05261206626892 and batch: 1900, loss is 4.184022617340088 and perplexity is 65.62932459559335
At time: 245.0401382446289 and batch: 1950, loss is 4.1036898708343506 and perplexity is 60.56334674133679
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.478616403978925 and perplexity of 88.11267595017046
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 248.27438068389893 and batch: 50, loss is 4.150160493850708 and perplexity is 63.44418188211596
At time: 249.3111674785614 and batch: 100, loss is 4.128840012550354 and perplexity is 62.10583914074243
At time: 250.30016684532166 and batch: 150, loss is 4.092124233245849 and perplexity is 59.86692804784941
At time: 251.2974500656128 and batch: 200, loss is 4.078134188652038 and perplexity is 59.03521844719936
At time: 252.30161261558533 and batch: 250, loss is 4.078713212013245 and perplexity is 59.06941111603593
At time: 253.30758357048035 and batch: 300, loss is 4.095674152374268 and perplexity is 60.07982846694164
At time: 254.31495308876038 and batch: 350, loss is 4.097820363044739 and perplexity is 60.20891090538233
At time: 255.31892013549805 and batch: 400, loss is 4.0411343669891355 and perplexity is 56.89084130843082
At time: 256.3298943042755 and batch: 450, loss is 4.053747024536133 and perplexity is 57.612930164732575
At time: 257.33904480934143 and batch: 500, loss is 4.0806057834625244 and perplexity is 59.181310052005394
At time: 258.3422462940216 and batch: 550, loss is 4.0462282848358155 and perplexity is 57.18137793690619
At time: 259.356742143631 and batch: 600, loss is 4.019581770896911 and perplexity is 55.67781487408125
At time: 260.3622524738312 and batch: 650, loss is 4.064147963523864 and perplexity is 58.21528583838258
At time: 261.3653552532196 and batch: 700, loss is 4.083223161697387 and perplexity is 59.33641281760114
At time: 262.3711063861847 and batch: 750, loss is 4.029774441719055 and perplexity is 56.24822256377513
At time: 263.3679850101471 and batch: 800, loss is 4.038000559806823 and perplexity is 56.712835445036475
At time: 264.3673429489136 and batch: 850, loss is 4.039686179161071 and perplexity is 56.80851231283298
At time: 265.3669533729553 and batch: 900, loss is 4.0048028135299685 and perplexity is 54.86100548441949
At time: 266.368262052536 and batch: 950, loss is 4.07747817993164 and perplexity is 58.99650352913774
At time: 267.3655228614807 and batch: 1000, loss is 4.041366953849792 and perplexity is 56.90407490953207
At time: 268.3591208457947 and batch: 1050, loss is 3.9924809074401857 and perplexity is 54.18916102944515
At time: 269.4155204296112 and batch: 1100, loss is 4.011525731086731 and perplexity is 55.23107407784373
At time: 270.41143679618835 and batch: 1150, loss is 3.9786330175399782 and perplexity is 53.443927359677005
At time: 271.40724062919617 and batch: 1200, loss is 4.022870969772339 and perplexity is 55.86125179502737
At time: 272.4045057296753 and batch: 1250, loss is 4.024969210624695 and perplexity is 55.97858520944136
At time: 273.3951244354248 and batch: 1300, loss is 3.9954622745513917 and perplexity is 54.35095988296603
At time: 274.3899064064026 and batch: 1350, loss is 3.8896993303298952 and perplexity is 48.89618271422181
At time: 275.38523626327515 and batch: 1400, loss is 3.909331121444702 and perplexity is 49.865586794371346
At time: 276.38261008262634 and batch: 1450, loss is 3.8430708265304565 and perplexity is 46.66856569280344
At time: 277.38099908828735 and batch: 1500, loss is 3.8398136377334593 and perplexity is 46.51680465480621
At time: 278.37848114967346 and batch: 1550, loss is 3.8601624727249146 and perplexity is 47.473063820343995
At time: 279.37345933914185 and batch: 1600, loss is 3.9263827991485596 and perplexity is 50.723169542103314
At time: 280.37148666381836 and batch: 1650, loss is 3.879311933517456 and perplexity is 48.39090745225333
At time: 281.36949396133423 and batch: 1700, loss is 3.8689850044250487 and perplexity is 47.89374945824847
At time: 282.36888313293457 and batch: 1750, loss is 3.8565682935714722 and perplexity is 47.302743388435424
At time: 283.3723919391632 and batch: 1800, loss is 3.807036576271057 and perplexity is 45.01683704159182
At time: 284.36118483543396 and batch: 1850, loss is 3.8484973096847535 and perplexity is 46.92250024101675
At time: 285.3517608642578 and batch: 1900, loss is 3.950900831222534 and perplexity is 51.98217291385346
At time: 286.3436393737793 and batch: 1950, loss is 3.867637667655945 and perplexity is 47.829263900229975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399676939498547 and perplexity of 81.42455935647143
finished 7 epochs...
Completing Train Step...
At time: 289.5967056751251 and batch: 50, loss is 4.0549253606796265 and perplexity is 57.68085757548024
At time: 290.63903403282166 and batch: 100, loss is 4.025672369003296 and perplexity is 56.01796086269145
At time: 291.6439595222473 and batch: 150, loss is 3.988636403083801 and perplexity is 53.98123051478806
At time: 292.6501307487488 and batch: 200, loss is 3.9725727367401125 and perplexity is 53.12102159092451
At time: 293.65592408180237 and batch: 250, loss is 3.978299436569214 and perplexity is 53.426102455696586
At time: 294.70633697509766 and batch: 300, loss is 3.988620047569275 and perplexity is 53.980347631208254
At time: 295.7098207473755 and batch: 350, loss is 3.9971611642837526 and perplexity is 54.443374649676805
At time: 296.712753534317 and batch: 400, loss is 3.94216938495636 and perplexity is 51.53026912211694
At time: 297.7193465232849 and batch: 450, loss is 3.9637182569503784 and perplexity is 52.652738838435575
At time: 298.71458101272583 and batch: 500, loss is 3.9956374645233153 and perplexity is 54.360482460207606
At time: 299.7104346752167 and batch: 550, loss is 3.961621241569519 and perplexity is 52.542440923878004
At time: 300.7082622051239 and batch: 600, loss is 3.9382341384887694 and perplexity is 51.327883292821674
At time: 301.70741057395935 and batch: 650, loss is 3.9857802772521973 and perplexity is 53.8272732931501
At time: 302.7017469406128 and batch: 700, loss is 4.0050240325927735 and perplexity is 54.87314312712677
At time: 303.70119047164917 and batch: 750, loss is 3.9553404951095583 and perplexity is 52.213469349007184
At time: 304.69722747802734 and batch: 800, loss is 3.965377702713013 and perplexity is 52.740185739419445
At time: 305.693621635437 and batch: 850, loss is 3.96981810092926 and perplexity is 52.97489387925648
At time: 306.69090843200684 and batch: 900, loss is 3.932785711288452 and perplexity is 51.04898751894101
At time: 307.6880497932434 and batch: 950, loss is 4.01011748790741 and perplexity is 55.153350034508804
At time: 308.68332600593567 and batch: 1000, loss is 3.976987528800964 and perplexity is 53.35605829264456
At time: 309.6791033744812 and batch: 1050, loss is 3.9325740909576417 and perplexity is 51.038185658301686
At time: 310.6719057559967 and batch: 1100, loss is 3.9534434938430785 and perplexity is 52.11451422020225
At time: 311.6665828227997 and batch: 1150, loss is 3.9257102680206297 and perplexity is 50.68906810010495
At time: 312.6623032093048 and batch: 1200, loss is 3.9699484968185423 and perplexity is 52.981802038041465
At time: 313.6594774723053 and batch: 1250, loss is 3.976160478591919 and perplexity is 53.311948396543514
At time: 314.65527176856995 and batch: 1300, loss is 3.9465246486663816 and perplexity is 51.75518646483713
At time: 315.6555745601654 and batch: 1350, loss is 3.8417425537109375 and perplexity is 46.60661825612381
At time: 316.6608943939209 and batch: 1400, loss is 3.8661375141143797 and perplexity is 47.75756645263557
At time: 317.65723395347595 and batch: 1450, loss is 3.802299027442932 and perplexity is 44.80407196842904
At time: 318.6614284515381 and batch: 1500, loss is 3.802945065498352 and perplexity is 44.83302645580172
At time: 319.6724474430084 and batch: 1550, loss is 3.8269782733917235 and perplexity is 45.923559919771705
At time: 320.6708493232727 and batch: 1600, loss is 3.895390930175781 and perplexity is 49.175273703926585
At time: 321.6679656505585 and batch: 1650, loss is 3.8508044385910036 and perplexity is 47.03088147433978
At time: 322.66481757164 and batch: 1700, loss is 3.8454591989517213 and perplexity is 46.78016082035873
At time: 323.6596941947937 and batch: 1750, loss is 3.8366391134262083 and perplexity is 46.36937006888785
At time: 324.66359210014343 and batch: 1800, loss is 3.7897056913375855 and perplexity is 44.243377150518185
At time: 325.6616516113281 and batch: 1850, loss is 3.8365769481658933 and perplexity is 46.36648759452269
At time: 326.6565811634064 and batch: 1900, loss is 3.9414756011962893 and perplexity is 51.49453065706479
At time: 327.6612799167633 and batch: 1950, loss is 3.85899094581604 and perplexity is 47.41748041371726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.398111884538517 and perplexity of 81.29722511451685
finished 8 epochs...
Completing Train Step...
At time: 330.96063470840454 and batch: 50, loss is 4.00666877746582 and perplexity is 54.96346970968233
At time: 331.9557635784149 and batch: 100, loss is 3.9776781034469604 and perplexity is 53.39291735921536
At time: 332.9456353187561 and batch: 150, loss is 3.942369089126587 and perplexity is 51.54056095938074
At time: 333.9388380050659 and batch: 200, loss is 3.926131887435913 and perplexity is 50.71044410131048
At time: 334.92903661727905 and batch: 250, loss is 3.9318884658813475 and perplexity is 51.003204591684366
At time: 335.91892409324646 and batch: 300, loss is 3.9405376291275025 and perplexity is 51.44625287076026
At time: 336.91160559654236 and batch: 350, loss is 3.949454274177551 and perplexity is 51.90703209625378
At time: 337.90177273750305 and batch: 400, loss is 3.8961511182785036 and perplexity is 49.21267037439549
At time: 338.89163517951965 and batch: 450, loss is 3.919537315368652 and perplexity is 50.37713066081137
At time: 339.88267827033997 and batch: 500, loss is 3.9537295722961425 and perplexity is 52.12942519256481
At time: 340.8740653991699 and batch: 550, loss is 3.918900518417358 and perplexity is 50.34506086964797
At time: 341.86456394195557 and batch: 600, loss is 3.8977325916290284 and perplexity is 49.29056047542632
At time: 342.8554630279541 and batch: 650, loss is 3.945556015968323 and perplexity is 51.705078970729545
At time: 343.8477108478546 and batch: 700, loss is 3.9642942428588865 and perplexity is 52.68307480975819
At time: 344.8703701496124 and batch: 750, loss is 3.916246705055237 and perplexity is 50.211631600892254
At time: 345.86712169647217 and batch: 800, loss is 3.926538462638855 and perplexity is 50.73106590228464
At time: 346.8675572872162 and batch: 850, loss is 3.9320179510116575 and perplexity is 51.009809175865634
At time: 347.8692102432251 and batch: 900, loss is 3.8926353454589844 and perplexity is 49.03995359989558
At time: 348.86372804641724 and batch: 950, loss is 3.9728706741333006 and perplexity is 53.1368506875436
At time: 349.8617789745331 and batch: 1000, loss is 3.940913634300232 and perplexity is 51.465600565145856
At time: 350.8595383167267 and batch: 1050, loss is 3.8987767934799193 and perplexity is 49.34205665142825
At time: 351.8538119792938 and batch: 1100, loss is 3.92004695892334 and perplexity is 50.40281158425902
At time: 352.8560094833374 and batch: 1150, loss is 3.8938858032226564 and perplexity is 49.101314347120535
At time: 353.857328414917 and batch: 1200, loss is 3.937001657485962 and perplexity is 51.264661619507486
At time: 354.8492362499237 and batch: 1250, loss is 3.944812602996826 and perplexity is 51.66665502852858
At time: 355.8402154445648 and batch: 1300, loss is 3.9152297306060793 and perplexity is 50.1605936110682
At time: 356.8275034427643 and batch: 1350, loss is 3.8112964391708375 and perplexity is 45.20901162365012
At time: 357.817134141922 and batch: 1400, loss is 3.837621726989746 and perplexity is 46.414955633679526
At time: 358.80303835868835 and batch: 1450, loss is 3.7749809217453003 and perplexity is 43.59667655928983
At time: 359.7945454120636 and batch: 1500, loss is 3.7775156784057615 and perplexity is 43.70732369811628
At time: 360.78493762016296 and batch: 1550, loss is 3.8028852224349974 and perplexity is 44.8303435904354
At time: 361.7766811847687 and batch: 1600, loss is 3.871685619354248 and perplexity is 48.02326684262403
At time: 362.76368260383606 and batch: 1650, loss is 3.8286310625076294 and perplexity is 45.999524639308774
At time: 363.75510811805725 and batch: 1700, loss is 3.824055528640747 and perplexity is 45.78953303466718
At time: 364.7435450553894 and batch: 1750, loss is 3.816798219680786 and perplexity is 45.45842716832459
At time: 365.73415327072144 and batch: 1800, loss is 3.7709913730621336 and perplexity is 43.423091988019294
At time: 366.7252073287964 and batch: 1850, loss is 3.819769868850708 and perplexity is 45.59371457948999
At time: 367.71518182754517 and batch: 1900, loss is 3.926430163383484 and perplexity is 50.72557206311795
At time: 368.7025451660156 and batch: 1950, loss is 3.8439524173736572 and perplexity is 46.70972641377503
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.400770178506541 and perplexity of 81.5136245368627
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 371.9110789299011 and batch: 50, loss is 3.9944122648239135 and perplexity is 54.29392079742903
At time: 372.9232659339905 and batch: 100, loss is 4.000538992881775 and perplexity is 54.627585979540335
At time: 373.9133131504059 and batch: 150, loss is 3.981188178062439 and perplexity is 53.58065978528768
At time: 374.9034209251404 and batch: 200, loss is 3.969734025001526 and perplexity is 52.970440153135165
At time: 375.89556312561035 and batch: 250, loss is 3.9720133924484253 and perplexity is 53.09131695906163
At time: 376.88303327560425 and batch: 300, loss is 3.983771858215332 and perplexity is 53.71927406292403
At time: 377.8716266155243 and batch: 350, loss is 3.986787419319153 and perplexity is 53.88151231304773
At time: 378.8604700565338 and batch: 400, loss is 3.9355936670303344 and perplexity is 51.19253225588001
At time: 379.8479070663452 and batch: 450, loss is 3.95016535282135 and perplexity is 51.94395520430142
At time: 380.8380994796753 and batch: 500, loss is 3.972893781661987 and perplexity is 53.1380785630317
At time: 381.8245632648468 and batch: 550, loss is 3.9357042026519777 and perplexity is 51.19819116700627
At time: 382.8139216899872 and batch: 600, loss is 3.9119451236724854 and perplexity is 49.996106063852224
At time: 383.80260396003723 and batch: 650, loss is 3.9650401067733765 and perplexity is 52.72238387194631
At time: 384.78958320617676 and batch: 700, loss is 3.9871299982070925 and perplexity is 53.8999741437526
At time: 385.78665804862976 and batch: 750, loss is 3.928430643081665 and perplexity is 50.82714910774136
At time: 386.7860987186432 and batch: 800, loss is 3.927015027999878 and perplexity is 50.75524833281812
At time: 387.7873237133026 and batch: 850, loss is 3.937989435195923 and perplexity is 51.3153247273889
At time: 388.7886941432953 and batch: 900, loss is 3.890940160751343 and perplexity is 48.95689224255176
At time: 389.7949900627136 and batch: 950, loss is 3.9804634428024293 and perplexity is 53.54184205987291
At time: 390.79381704330444 and batch: 1000, loss is 3.9376676654815674 and perplexity is 51.298815666209705
At time: 391.78144693374634 and batch: 1050, loss is 3.8927733802795412 and perplexity is 49.046723288306474
At time: 392.77246165275574 and batch: 1100, loss is 3.9183657455444334 and perplexity is 50.318144894417294
At time: 393.76202869415283 and batch: 1150, loss is 3.8936350107192994 and perplexity is 49.08900164960795
At time: 394.7507152557373 and batch: 1200, loss is 3.929060730934143 and perplexity is 50.85918476855074
At time: 395.78420400619507 and batch: 1250, loss is 3.933904643058777 and perplexity is 51.1061398217196
At time: 396.77737307548523 and batch: 1300, loss is 3.9042734861373902 and perplexity is 49.6140215408806
At time: 397.77121138572693 and batch: 1350, loss is 3.7921445560455322 and perplexity is 44.351412449800236
At time: 398.7665219306946 and batch: 1400, loss is 3.8162372159957885 and perplexity is 45.43293197528626
At time: 399.76068139076233 and batch: 1450, loss is 3.7498905801773073 and perplexity is 42.516429605346374
At time: 400.7557249069214 and batch: 1500, loss is 3.7513880729675293 and perplexity is 42.58014534717157
At time: 401.744754076004 and batch: 1550, loss is 3.7807572650909425 and perplexity is 43.849234660739135
At time: 402.744197845459 and batch: 1600, loss is 3.845224151611328 and perplexity is 46.76916656011117
At time: 403.7345416545868 and batch: 1650, loss is 3.7951614665985107 and perplexity is 44.48541873490644
At time: 404.7234101295471 and batch: 1700, loss is 3.7817314767837527 and perplexity is 43.89197391302579
At time: 405.71341943740845 and batch: 1750, loss is 3.772666654586792 and perplexity is 43.495898860746614
At time: 406.70999813079834 and batch: 1800, loss is 3.726088719367981 and perplexity is 41.516407866186675
At time: 407.71010541915894 and batch: 1850, loss is 3.7669079875946045 and perplexity is 43.246140292106865
At time: 408.70321679115295 and batch: 1900, loss is 3.8801696825027467 and perplexity is 48.43243251051013
At time: 409.69514298439026 and batch: 1950, loss is 3.805806031227112 and perplexity is 44.96147586507275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365386537063953 and perplexity of 78.6798067262081
finished 10 epochs...
Completing Train Step...
At time: 412.92687129974365 and batch: 50, loss is 3.9877133178710937 and perplexity is 53.931424230395024
At time: 413.94391679763794 and batch: 100, loss is 3.969968614578247 and perplexity is 52.98286792392517
At time: 414.93178510665894 and batch: 150, loss is 3.9431429958343505 and perplexity is 51.58046398384666
At time: 415.92234206199646 and batch: 200, loss is 3.9301611471176146 and perplexity is 50.91518184294101
At time: 416.92267394065857 and batch: 250, loss is 3.9326083564758303 and perplexity is 51.03993453814364
At time: 417.9128634929657 and batch: 300, loss is 3.9407671880722046 and perplexity is 51.45806417392143
At time: 418.91434478759766 and batch: 350, loss is 3.9460227155685423 and perplexity is 51.72921534219386
At time: 419.9178855419159 and batch: 400, loss is 3.893997564315796 and perplexity is 49.10680227034899
At time: 420.9405903816223 and batch: 450, loss is 3.911911435127258 and perplexity is 49.99442179614233
At time: 421.9336128234863 and batch: 500, loss is 3.93611611366272 and perplexity is 51.21928460969045
At time: 422.92274045944214 and batch: 550, loss is 3.9011897897720336 and perplexity is 49.46126261510739
At time: 423.9136130809784 and batch: 600, loss is 3.8792017841339113 and perplexity is 48.385577517178206
At time: 424.9009220600128 and batch: 650, loss is 3.933302297592163 and perplexity is 51.07536553938705
At time: 425.8962333202362 and batch: 700, loss is 3.9586414337158202 and perplexity is 52.3861075830958
At time: 426.88911390304565 and batch: 750, loss is 3.9025323677062986 and perplexity is 49.52771281219803
At time: 427.8794012069702 and batch: 800, loss is 3.901386423110962 and perplexity is 49.47098930458738
At time: 428.88232374191284 and batch: 850, loss is 3.9121544408798217 and perplexity is 50.006572204484655
At time: 429.8861634731293 and batch: 900, loss is 3.8653198289871216 and perplexity is 47.71853176205109
At time: 430.8830771446228 and batch: 950, loss is 3.956595091819763 and perplexity is 52.279017305408274
At time: 431.87571907043457 and batch: 1000, loss is 3.9151226472854614 and perplexity is 50.15522253572159
At time: 432.88552689552307 and batch: 1050, loss is 3.8716485929489135 and perplexity is 48.02148874659888
At time: 433.8856272697449 and batch: 1100, loss is 3.896854934692383 and perplexity is 49.247319251369696
At time: 434.8771297931671 and batch: 1150, loss is 3.874125237464905 and perplexity is 48.140568301348814
At time: 435.88364362716675 and batch: 1200, loss is 3.9124760913848875 and perplexity is 50.02265943078437
At time: 436.8770110607147 and batch: 1250, loss is 3.9191393566131594 and perplexity is 50.35708662920177
At time: 437.87035632133484 and batch: 1300, loss is 3.890324091911316 and perplexity is 48.92674071539839
At time: 438.86895990371704 and batch: 1350, loss is 3.7789765930175783 and perplexity is 43.77122303031943
At time: 439.85907769203186 and batch: 1400, loss is 3.8038983297348024 and perplexity is 44.8757845531785
At time: 440.8493809700012 and batch: 1450, loss is 3.7399038076400757 and perplexity is 42.093940854734335
At time: 441.83927369117737 and batch: 1500, loss is 3.743717169761658 and perplexity is 42.25476674312286
At time: 442.8340756893158 and batch: 1550, loss is 3.774580044746399 and perplexity is 43.5792031570052
At time: 443.8366243839264 and batch: 1600, loss is 3.840301365852356 and perplexity is 46.53949774201611
At time: 444.8266279697418 and batch: 1650, loss is 3.7915755891799927 and perplexity is 44.326185143107786
At time: 445.8191862106323 and batch: 1700, loss is 3.781068592071533 and perplexity is 43.862888235820144
At time: 446.81867241859436 and batch: 1750, loss is 3.7733620023727417 and perplexity is 43.52615415547437
At time: 447.81031584739685 and batch: 1800, loss is 3.7280988788604734 and perplexity is 41.59994640231397
At time: 448.8029396533966 and batch: 1850, loss is 3.7705033349990846 and perplexity is 43.40190503675372
At time: 449.8012344837189 and batch: 1900, loss is 3.884638662338257 and perplexity is 48.64936043701267
At time: 450.7968454360962 and batch: 1950, loss is 3.8097136640548706 and perplexity is 45.13751252345954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36446902252907 and perplexity of 78.60764996743445
finished 11 epochs...
Completing Train Step...
At time: 454.0737204551697 and batch: 50, loss is 3.9735368394851687 and perplexity is 53.17226040943444
At time: 455.06690216064453 and batch: 100, loss is 3.954203281402588 and perplexity is 52.15412522584575
At time: 456.0592133998871 and batch: 150, loss is 3.9267607498168946 and perplexity is 50.742344021207174
At time: 457.05229091644287 and batch: 200, loss is 3.9131752347946165 and perplexity is 50.05764467188783
At time: 458.04545998573303 and batch: 250, loss is 3.9146833181381226 and perplexity is 50.133192724093895
At time: 459.0380234718323 and batch: 300, loss is 3.9229979801177977 and perplexity is 50.55177103264766
At time: 460.0292761325836 and batch: 350, loss is 3.9287900495529176 and perplexity is 50.845419997187285
At time: 461.0207395553589 and batch: 400, loss is 3.8764331245422365 and perplexity is 48.25179960209636
At time: 462.01285910606384 and batch: 450, loss is 3.8950095176696777 and perplexity is 49.15652121598889
At time: 463.0060143470764 and batch: 500, loss is 3.9194451904296876 and perplexity is 50.372489884492936
At time: 463.9988548755646 and batch: 550, loss is 3.8845836353302 and perplexity is 48.64668348191703
At time: 464.9942235946655 and batch: 600, loss is 3.8638697910308837 and perplexity is 47.649388222273885
At time: 465.9942293167114 and batch: 650, loss is 3.9185107374191284 and perplexity is 50.325441145512485
At time: 466.98966789245605 and batch: 700, loss is 3.9445232057571413 and perplexity is 51.65170500453176
At time: 467.9827256202698 and batch: 750, loss is 3.8892664432525637 and perplexity is 48.87502076929069
At time: 468.9817068576813 and batch: 800, loss is 3.8879241228103636 and perplexity is 48.809458842200854
At time: 470.00726294517517 and batch: 850, loss is 3.8990075826644897 and perplexity is 49.353445578617915
At time: 471.0089228153229 and batch: 900, loss is 3.852026786804199 and perplexity is 47.088404737841834
At time: 472.0131666660309 and batch: 950, loss is 3.9438734102249144 and perplexity is 51.61815285958543
At time: 473.00643396377563 and batch: 1000, loss is 3.9027763271331786 and perplexity is 49.53979703860091
At time: 474.0050776004791 and batch: 1050, loss is 3.8601141023635863 and perplexity is 47.47076758662892
At time: 474.9979820251465 and batch: 1100, loss is 3.8848388671875 and perplexity is 48.659101249931176
At time: 475.9912259578705 and batch: 1150, loss is 3.8632645177841187 and perplexity is 47.62055604891005
At time: 476.9930419921875 and batch: 1200, loss is 3.9029587364196776 and perplexity is 49.54883438185464
At time: 477.98553013801575 and batch: 1250, loss is 3.910425543785095 and perplexity is 49.92019068098241
At time: 478.98615980148315 and batch: 1300, loss is 3.8818265438079833 and perplexity is 48.512744848685294
At time: 479.9805541038513 and batch: 1350, loss is 3.770496106147766 and perplexity is 43.40159129196928
At time: 480.9785854816437 and batch: 1400, loss is 3.7955449771881105 and perplexity is 44.50248263595828
At time: 481.97111082077026 and batch: 1450, loss is 3.7323877000808716 and perplexity is 41.77874427720457
At time: 482.96715474128723 and batch: 1500, loss is 3.737021441459656 and perplexity is 41.97278539429524
At time: 483.9663016796112 and batch: 1550, loss is 3.7686564111709595 and perplexity is 43.32181900332234
At time: 484.9572322368622 and batch: 1600, loss is 3.834720559120178 and perplexity is 46.28049319908678
At time: 485.95198941230774 and batch: 1650, loss is 3.7866522073745728 and perplexity is 44.10848675555562
At time: 486.95966362953186 and batch: 1700, loss is 3.7774683618545533 and perplexity is 43.70525566722277
At time: 487.95988368988037 and batch: 1750, loss is 3.7701184701919557 and perplexity is 43.38520438489544
At time: 488.95625591278076 and batch: 1800, loss is 3.725392680168152 and perplexity is 41.48752087328167
At time: 489.9527144432068 and batch: 1850, loss is 3.7687188673019407 and perplexity is 43.3245248010203
At time: 490.9472904205322 and batch: 1900, loss is 3.883408579826355 and perplexity is 48.58955450018343
At time: 491.95045018196106 and batch: 1950, loss is 3.808142414093018 and perplexity is 45.066645897800136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.36506830259811 and perplexity of 78.65477208359627
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 495.19925928115845 and batch: 50, loss is 3.973779196739197 and perplexity is 53.18514865417447
At time: 496.2149283885956 and batch: 100, loss is 3.972450065612793 and perplexity is 53.11450557499325
At time: 497.20487213134766 and batch: 150, loss is 3.9576968288421632 and perplexity is 52.336646774698956
At time: 498.20180320739746 and batch: 200, loss is 3.9513257551193237 and perplexity is 52.004266074955225
At time: 499.1944410800934 and batch: 250, loss is 3.9602715253829954 and perplexity is 52.471571378528616
At time: 500.18700790405273 and batch: 300, loss is 3.9661917686462402 and perplexity is 52.78313720823376
At time: 501.177453994751 and batch: 350, loss is 3.9752129888534546 and perplexity is 53.2614597949933
At time: 502.17078137397766 and batch: 400, loss is 3.9232519912719725 and perplexity is 50.56461337733359
At time: 503.16078758239746 and batch: 450, loss is 3.9448645639419557 and perplexity is 51.669339746505194
At time: 504.15283370018005 and batch: 500, loss is 3.961502833366394 and perplexity is 52.53621983618158
At time: 505.1427810192108 and batch: 550, loss is 3.9219100666046143 and perplexity is 50.496804982401585
At time: 506.13316535949707 and batch: 600, loss is 3.891076211929321 and perplexity is 48.96355333852621
At time: 507.1329584121704 and batch: 650, loss is 3.9351877069473264 and perplexity is 51.171754349021775
At time: 508.12177205085754 and batch: 700, loss is 3.9660677194595335 and perplexity is 52.77658990909321
At time: 509.1162190437317 and batch: 750, loss is 3.911444807052612 and perplexity is 49.97109843744675
At time: 510.11456274986267 and batch: 800, loss is 3.907659397125244 and perplexity is 49.78229492014675
At time: 511.11105704307556 and batch: 850, loss is 3.920002088546753 and perplexity is 50.40055004186069
At time: 512.1147634983063 and batch: 900, loss is 3.869212884902954 and perplexity is 47.90466475240769
At time: 513.1220178604126 and batch: 950, loss is 3.960838360786438 and perplexity is 52.501322554073425
At time: 514.1214685440063 and batch: 1000, loss is 3.9255312728881835 and perplexity is 50.6799958156184
At time: 515.1204297542572 and batch: 1050, loss is 3.8751661252975462 and perplexity is 48.190703321089586
At time: 516.1175343990326 and batch: 1100, loss is 3.895026693344116 and perplexity is 49.157365519644536
At time: 517.1120483875275 and batch: 1150, loss is 3.877580933570862 and perplexity is 48.30721525053386
At time: 518.1039729118347 and batch: 1200, loss is 3.916106219291687 and perplexity is 50.204578076959166
At time: 519.104451417923 and batch: 1250, loss is 3.9262750053405764 and perplexity is 50.71770219318387
At time: 520.098718881607 and batch: 1300, loss is 3.898207688331604 and perplexity is 49.31398382191304
At time: 521.0951981544495 and batch: 1350, loss is 3.7857923221588137 and perplexity is 44.07057482219652
At time: 522.0931205749512 and batch: 1400, loss is 3.804990391731262 and perplexity is 44.92481846121095
At time: 523.0880017280579 and batch: 1450, loss is 3.733755340576172 and perplexity is 41.835921669867446
At time: 524.0877573490143 and batch: 1500, loss is 3.734276280403137 and perplexity is 41.85772134532965
At time: 525.084005355835 and batch: 1550, loss is 3.769598526954651 and perplexity is 43.36265240465929
At time: 526.077116727829 and batch: 1600, loss is 3.8362305545806885 and perplexity is 46.350429322053316
At time: 527.0695216655731 and batch: 1650, loss is 3.786121892929077 and perplexity is 44.08510158915402
At time: 528.0582647323608 and batch: 1700, loss is 3.7687495470047 and perplexity is 43.32585400495307
At time: 529.0504348278046 and batch: 1750, loss is 3.7611102533340453 and perplexity is 42.9961360921533
At time: 530.0416963100433 and batch: 1800, loss is 3.7142049837112427 and perplexity is 41.025957810987826
At time: 531.0299820899963 and batch: 1850, loss is 3.751248016357422 and perplexity is 42.57418213395983
At time: 532.0206687450409 and batch: 1900, loss is 3.8681947708129885 and perplexity is 47.85591715776547
At time: 533.016086101532 and batch: 1950, loss is 3.8025903606414797 and perplexity is 44.817126783581756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346553926689681 and perplexity of 77.21192597874817
finished 13 epochs...
Completing Train Step...
At time: 536.2795283794403 and batch: 50, loss is 3.9852185535430906 and perplexity is 53.797045728109566
At time: 537.2988951206207 and batch: 100, loss is 3.9638029813766478 and perplexity is 52.6572000005072
At time: 538.2970325946808 and batch: 150, loss is 3.9375080394744875 and perplexity is 51.290627694620966
At time: 539.2999503612518 and batch: 200, loss is 3.9256919860839843 and perplexity is 50.68814141424416
At time: 540.2927885055542 and batch: 250, loss is 3.9331771755218505 and perplexity is 51.06897528369813
At time: 541.28382396698 and batch: 300, loss is 3.9373163890838625 and perplexity is 51.28079876767682
At time: 542.2734105587006 and batch: 350, loss is 3.947768893241882 and perplexity is 51.81962265372622
At time: 543.2606897354126 and batch: 400, loss is 3.8966321992874144 and perplexity is 49.23635135128781
At time: 544.2519826889038 and batch: 450, loss is 3.9227325439453127 and perplexity is 50.53835454472179
At time: 545.2429728507996 and batch: 500, loss is 3.9439452838897706 and perplexity is 51.621862978732885
At time: 546.2584953308105 and batch: 550, loss is 3.9059388494491576 and perplexity is 49.69671575094354
At time: 547.2503221035004 and batch: 600, loss is 3.875848569869995 and perplexity is 48.22360202950924
At time: 548.2502510547638 and batch: 650, loss is 3.920206780433655 and perplexity is 50.4108676814822
At time: 549.2398781776428 and batch: 700, loss is 3.949976878166199 and perplexity is 51.93416600779379
At time: 550.230890750885 and batch: 750, loss is 3.8995028829574583 and perplexity is 49.37789640942398
At time: 551.2361266613007 and batch: 800, loss is 3.895595507621765 and perplexity is 49.185334884936765
At time: 552.2309193611145 and batch: 850, loss is 3.907585926055908 and perplexity is 49.778637496064036
At time: 553.2228605747223 and batch: 900, loss is 3.8588312101364135 and perplexity is 47.40990675516504
At time: 554.2214260101318 and batch: 950, loss is 3.951788372993469 and perplexity is 52.02832974368578
At time: 555.21919298172 and batch: 1000, loss is 3.916142110824585 and perplexity is 50.20638002856204
At time: 556.2149837017059 and batch: 1050, loss is 3.8667450380325317 and perplexity is 47.786589131621454
At time: 557.2096073627472 and batch: 1100, loss is 3.887032890319824 and perplexity is 48.765977645440756
At time: 558.198682308197 and batch: 1150, loss is 3.8692671489715575 and perplexity is 47.907264324953296
At time: 559.1900928020477 and batch: 1200, loss is 3.90708580493927 and perplexity is 49.753748372601656
At time: 560.1803679466248 and batch: 1250, loss is 3.919172477722168 and perplexity is 50.358754539378744
At time: 561.1727132797241 and batch: 1300, loss is 3.8923449897766114 and perplexity is 49.02571663769601
At time: 562.1611626148224 and batch: 1350, loss is 3.7804534339904787 and perplexity is 43.83591392324731
At time: 563.1543004512787 and batch: 1400, loss is 3.8008393335342405 and perplexity is 44.738719446435205
At time: 564.1447212696075 and batch: 1450, loss is 3.7309847593307497 and perplexity is 41.72017227050365
At time: 565.1332399845123 and batch: 1500, loss is 3.7332160758972166 and perplexity is 41.81336711698278
At time: 566.1345109939575 and batch: 1550, loss is 3.770324821472168 and perplexity is 43.394157901115534
At time: 567.131706237793 and batch: 1600, loss is 3.837644953727722 and perplexity is 46.4160337142123
At time: 568.1291358470917 and batch: 1650, loss is 3.788350963592529 and perplexity is 44.18348000128305
At time: 569.118320941925 and batch: 1700, loss is 3.7721249294281005 and perplexity is 43.47234241916846
At time: 570.1103067398071 and batch: 1750, loss is 3.7654727697372437 and perplexity is 43.18411717828449
At time: 571.1020400524139 and batch: 1800, loss is 3.719224758148193 and perplexity is 41.23241662005361
At time: 572.0919783115387 and batch: 1850, loss is 3.7565041637420653 and perplexity is 42.79854744205386
At time: 573.081600189209 and batch: 1900, loss is 3.8734792613983156 and perplexity is 48.10948068840213
At time: 574.071914434433 and batch: 1950, loss is 3.807335352897644 and perplexity is 45.030289029772476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344772835664971 and perplexity of 77.07452690683618
finished 14 epochs...
Completing Train Step...
At time: 577.3894667625427 and batch: 50, loss is 3.9816256856918333 and perplexity is 53.60410686149508
At time: 578.397768497467 and batch: 100, loss is 3.9581965351104738 and perplexity is 52.36280626063983
At time: 579.3917648792267 and batch: 150, loss is 3.930701150894165 and perplexity is 50.94268365829373
At time: 580.3858621120453 and batch: 200, loss is 3.9178641653060913 and perplexity is 50.292912635838356
At time: 581.3790647983551 and batch: 250, loss is 3.924780707359314 and perplexity is 50.64197142943779
At time: 582.374712228775 and batch: 300, loss is 3.9283744287490845 and perplexity is 50.824291973784
At time: 583.370411157608 and batch: 350, loss is 3.939507956504822 and perplexity is 51.39330733560161
At time: 584.3654499053955 and batch: 400, loss is 3.8878294944763185 and perplexity is 48.80484030295076
At time: 585.3616621494293 and batch: 450, loss is 3.9146997833251955 and perplexity is 50.13401818328631
At time: 586.3575460910797 and batch: 500, loss is 3.936235661506653 and perplexity is 51.22540813075291
At time: 587.3517317771912 and batch: 550, loss is 3.8986697578430176 and perplexity is 49.33677557560522
At time: 588.3457245826721 and batch: 600, loss is 3.868825273513794 and perplexity is 47.88609995695128
At time: 589.3414800167084 and batch: 650, loss is 3.9132990646362305 and perplexity is 50.063843685902654
At time: 590.3450574874878 and batch: 700, loss is 3.943358135223389 and perplexity is 51.59156216713984
At time: 591.3550720214844 and batch: 750, loss is 3.893898105621338 and perplexity is 49.10191841478115
At time: 592.3638138771057 and batch: 800, loss is 3.890149922370911 and perplexity is 48.91821990950843
At time: 593.3740487098694 and batch: 850, loss is 3.901886987686157 and perplexity is 49.49575892821398
At time: 594.3819842338562 and batch: 900, loss is 3.8538521575927733 and perplexity is 47.17443703286181
At time: 595.3863816261292 and batch: 950, loss is 3.9474008560180662 and perplexity is 51.80055461275522
At time: 596.4356861114502 and batch: 1000, loss is 3.9117033433914186 and perplexity is 49.98401945248689
At time: 597.4402639865875 and batch: 1050, loss is 3.8624224615097047 and perplexity is 47.58047373904663
At time: 598.4494595527649 and batch: 1100, loss is 3.8827722787857057 and perplexity is 48.55864675044976
At time: 599.4592523574829 and batch: 1150, loss is 3.865083441734314 and perplexity is 47.70725304254512
At time: 600.4691777229309 and batch: 1200, loss is 3.9029142665863037 and perplexity is 49.546631002438126
At time: 601.4790079593658 and batch: 1250, loss is 3.9158488750457763 and perplexity is 50.19165987995581
At time: 602.4897556304932 and batch: 1300, loss is 3.889496965408325 and perplexity is 48.88628884316176
At time: 603.4945704936981 and batch: 1350, loss is 3.7779046201705935 and perplexity is 43.72432660808807
At time: 604.5005056858063 and batch: 1400, loss is 3.798766031265259 and perplexity is 44.64605864800989
At time: 605.5058562755585 and batch: 1450, loss is 3.729367175102234 and perplexity is 41.65274093046729
At time: 606.510776758194 and batch: 1500, loss is 3.732249321937561 and perplexity is 41.77296341212355
At time: 607.5162925720215 and batch: 1550, loss is 3.7698609113693236 and perplexity is 43.37403158162321
At time: 608.5124590396881 and batch: 1600, loss is 3.8374877977371216 and perplexity is 46.40873972961589
At time: 609.5076720714569 and batch: 1650, loss is 3.7885641479492187 and perplexity is 44.192900232130675
At time: 610.5037994384766 and batch: 1700, loss is 3.772807011604309 and perplexity is 43.50200424384158
At time: 611.5015823841095 and batch: 1750, loss is 3.7665451669692995 and perplexity is 43.23045254653498
At time: 612.497236251831 and batch: 1800, loss is 3.7206501245498655 and perplexity is 41.29122982659046
At time: 613.5023844242096 and batch: 1850, loss is 3.757821822166443 and perplexity is 42.854978478892804
At time: 614.5030901432037 and batch: 1900, loss is 3.8745837450027465 and perplexity is 48.16264617584011
At time: 615.4964201450348 and batch: 1950, loss is 3.808035316467285 and perplexity is 45.06181962547051
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344186614280523 and perplexity of 77.02935741192267
finished 15 epochs...
Completing Train Step...
At time: 618.761549949646 and batch: 50, loss is 3.977594532966614 and perplexity is 53.388455473908095
At time: 619.7747020721436 and batch: 100, loss is 3.9534690237045287 and perplexity is 52.11584471351342
At time: 620.7678933143616 and batch: 150, loss is 3.925441288948059 and perplexity is 50.675435635084
At time: 621.7819039821625 and batch: 200, loss is 3.912200717926025 and perplexity is 50.008886414484024
At time: 622.7696158885956 and batch: 250, loss is 3.918851041793823 and perplexity is 50.34257002764421
At time: 623.7614102363586 and batch: 300, loss is 3.9221453046798707 and perplexity is 50.508685150891445
At time: 624.7513642311096 and batch: 350, loss is 3.9337643814086913 and perplexity is 51.098972092909186
At time: 625.7540407180786 and batch: 400, loss is 3.881736731529236 and perplexity is 48.50838800417414
At time: 626.7530300617218 and batch: 450, loss is 3.9089439058303834 and perplexity is 49.84628179838655
At time: 627.7525157928467 and batch: 500, loss is 3.930592031478882 and perplexity is 50.937125125717415
At time: 628.7558932304382 and batch: 550, loss is 3.89332893371582 and perplexity is 49.073978934250384
At time: 629.761910200119 and batch: 600, loss is 3.863790168762207 and perplexity is 47.64559442092012
At time: 630.7566919326782 and batch: 650, loss is 3.908330225944519 and perplexity is 49.815701522071706
At time: 631.7478997707367 and batch: 700, loss is 3.9387064456939695 and perplexity is 51.35213154779055
At time: 632.7417306900024 and batch: 750, loss is 3.8897483777999877 and perplexity is 48.89858100709574
At time: 633.7323195934296 and batch: 800, loss is 3.8860755872726442 and perplexity is 48.71931616459446
At time: 634.7275149822235 and batch: 850, loss is 3.8977729272842407 and perplexity is 49.292548682576424
At time: 635.7171261310577 and batch: 900, loss is 3.85012393951416 and perplexity is 46.99888788995031
At time: 636.7095148563385 and batch: 950, loss is 3.94401752948761 and perplexity is 51.62559256580686
At time: 637.7063586711884 and batch: 1000, loss is 3.90835250377655 and perplexity is 49.816811320264634
At time: 638.7129859924316 and batch: 1050, loss is 3.8591157484054563 and perplexity is 47.42339860735174
At time: 639.711503982544 and batch: 1100, loss is 3.8794126653671266 and perplexity is 48.39578220338545
At time: 640.7064838409424 and batch: 1150, loss is 3.861740870475769 and perplexity is 47.54805436438831
At time: 641.6984798908234 and batch: 1200, loss is 3.8997234582901 and perplexity is 49.388789156641145
At time: 642.688948392868 and batch: 1250, loss is 3.91319109916687 and perplexity is 50.05843881129629
At time: 643.680074930191 and batch: 1300, loss is 3.8871249961853027 and perplexity is 48.7704694848769
At time: 644.672370672226 and batch: 1350, loss is 3.775708589553833 and perplexity is 43.62841200241089
At time: 645.666118144989 and batch: 1400, loss is 3.7968869686126707 and perplexity is 44.56224467713177
At time: 646.6549742221832 and batch: 1450, loss is 3.7277647495269775 and perplexity is 41.58604896184965
At time: 647.6473205089569 and batch: 1500, loss is 3.7309766149520875 and perplexity is 41.7198324870065
At time: 648.6425077915192 and batch: 1550, loss is 3.768829870223999 and perplexity is 43.32933421679466
At time: 649.6355662345886 and batch: 1600, loss is 3.8366083669662476 and perplexity is 46.36794439682492
At time: 650.6294724941254 and batch: 1650, loss is 3.7879026079177858 and perplexity is 44.16367452757461
At time: 651.6215693950653 and batch: 1700, loss is 3.772434883117676 and perplexity is 43.48581892053354
At time: 652.6094398498535 and batch: 1750, loss is 3.7664386796951295 and perplexity is 43.22584929858017
At time: 653.5987854003906 and batch: 1800, loss is 3.7208443593978884 and perplexity is 41.29925080129169
At time: 654.5912537574768 and batch: 1850, loss is 3.757898840904236 and perplexity is 42.85827924235208
At time: 655.5965909957886 and batch: 1900, loss is 3.8745202732086184 and perplexity is 48.15958930329099
At time: 656.5990843772888 and batch: 1950, loss is 3.8076279592514037 and perplexity is 45.04346710635467
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344010889807413 and perplexity of 77.01582265790601
finished 16 epochs...
Completing Train Step...
At time: 660.0209827423096 and batch: 50, loss is 3.973715510368347 and perplexity is 53.18176159292954
At time: 661.0816552639008 and batch: 100, loss is 3.9492168617248535 and perplexity is 51.89471018319723
At time: 662.10502576828 and batch: 150, loss is 3.9208777141571045 and perplexity is 50.444701381454024
At time: 663.1092865467072 and batch: 200, loss is 3.907439670562744 and perplexity is 49.77135762926125
At time: 664.1053884029388 and batch: 250, loss is 3.9139168787002565 and perplexity is 50.09478338913878
At time: 665.1040620803833 and batch: 300, loss is 3.917028422355652 and perplexity is 50.25089824770571
At time: 666.0962619781494 and batch: 350, loss is 3.9290305376052856 and perplexity is 50.857649183641925
At time: 667.0862972736359 and batch: 400, loss is 3.876768274307251 and perplexity is 48.2679738916478
At time: 668.0795872211456 and batch: 450, loss is 3.904210786819458 and perplexity is 49.61091087308951
At time: 669.0687248706818 and batch: 500, loss is 3.9259287023544314 and perplexity is 50.70014154229238
At time: 670.0608284473419 and batch: 550, loss is 3.8888982582092284 and perplexity is 48.85702902999864
At time: 671.0495615005493 and batch: 600, loss is 3.859629902839661 and perplexity is 47.447787827406295
At time: 672.085958480835 and batch: 650, loss is 3.9041962099075316 and perplexity is 49.610187704481916
At time: 673.0749289989471 and batch: 700, loss is 3.934797511100769 and perplexity is 51.15179123802851
At time: 674.0703420639038 and batch: 750, loss is 3.8861702489852905 and perplexity is 48.72392823679144
At time: 675.0694260597229 and batch: 800, loss is 3.8825349473953246 and perplexity is 48.547123626755024
At time: 676.0692596435547 and batch: 850, loss is 3.894294958114624 and perplexity is 49.121408500617974
At time: 677.0692863464355 and batch: 900, loss is 3.8469075345993042 and perplexity is 46.84796328338432
At time: 678.0757157802582 and batch: 950, loss is 3.94106107711792 and perplexity is 51.473189357749916
At time: 679.0811650753021 and batch: 1000, loss is 3.905432634353638 and perplexity is 49.67156488964257
At time: 680.0833246707916 and batch: 1050, loss is 3.856231732368469 and perplexity is 47.286825798987046
At time: 681.0865125656128 and batch: 1100, loss is 3.8764149856567385 and perplexity is 48.25092437616614
At time: 682.087584733963 and batch: 1150, loss is 3.8587572622299193 and perplexity is 47.40640102143585
At time: 683.098664522171 and batch: 1200, loss is 3.896871581077576 and perplexity is 49.24813904803898
At time: 684.1073958873749 and batch: 1250, loss is 3.9107674169540405 and perplexity is 49.93725997236499
At time: 685.1154203414917 and batch: 1300, loss is 3.8849125337600707 and perplexity is 48.66268593117861
At time: 686.1209976673126 and batch: 1350, loss is 3.7736561584472654 and perplexity is 43.53895952141561
At time: 687.1268033981323 and batch: 1400, loss is 3.7950795555114745 and perplexity is 44.48177503513234
At time: 688.1249821186066 and batch: 1450, loss is 3.7261266040802004 and perplexity is 41.51798073314468
At time: 689.1237161159515 and batch: 1500, loss is 3.729529676437378 and perplexity is 41.65951010646607
At time: 690.1267402172089 and batch: 1550, loss is 3.7675189352035523 and perplexity is 43.27256949072032
At time: 691.1271622180939 and batch: 1600, loss is 3.8353816509246825 and perplexity is 46.311098969346396
At time: 692.1268882751465 and batch: 1650, loss is 3.7868402004241943 and perplexity is 44.116779623971375
At time: 693.12486743927 and batch: 1700, loss is 3.771596131324768 and perplexity is 43.449360403908365
At time: 694.1223669052124 and batch: 1750, loss is 3.765809416770935 and perplexity is 43.19865743056422
At time: 695.1218192577362 and batch: 1800, loss is 3.720491523742676 and perplexity is 41.28468152350692
At time: 696.1224150657654 and batch: 1850, loss is 3.7574374580383303 and perplexity is 42.83850972765584
At time: 697.1227235794067 and batch: 1900, loss is 3.873960747718811 and perplexity is 48.132650322723116
At time: 698.1217181682587 and batch: 1950, loss is 3.8068215799331666 and perplexity is 45.00715962682611
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344010322038518 and perplexity of 77.01577893072991
finished 17 epochs...
Completing Train Step...
At time: 701.5742557048798 and batch: 50, loss is 3.9700685262680055 and perplexity is 52.98816179624316
At time: 702.5879256725311 and batch: 100, loss is 3.9453198194503782 and perplexity is 51.69286785328509
At time: 703.5901505947113 and batch: 150, loss is 3.9167415285110474 and perplexity is 50.23648364214227
At time: 704.5908939838409 and batch: 200, loss is 3.9031950759887697 and perplexity is 49.560546115940035
At time: 705.5896396636963 and batch: 250, loss is 3.9095473098754883 and perplexity is 49.8763683227095
At time: 706.5849893093109 and batch: 300, loss is 3.912525706291199 and perplexity is 50.02514136191535
At time: 707.5827732086182 and batch: 350, loss is 3.9248434019088747 and perplexity is 50.64514650455433
At time: 708.5789995193481 and batch: 400, loss is 3.8724198865890505 and perplexity is 48.05854170297696
At time: 709.5739846229553 and batch: 450, loss is 3.900065016746521 and perplexity is 49.40566119645991
At time: 710.5744330883026 and batch: 500, loss is 3.9218365573883056 and perplexity is 50.49309313827029
At time: 711.5696585178375 and batch: 550, loss is 3.8849812889099122 and perplexity is 48.666031856464976
At time: 712.5654559135437 and batch: 600, loss is 3.855956630706787 and perplexity is 47.273818903825344
At time: 713.5636887550354 and batch: 650, loss is 3.9005154275894167 and perplexity is 49.42791905417716
At time: 714.5546610355377 and batch: 700, loss is 3.9312947940826417 and perplexity is 50.97293441363923
At time: 715.5452029705048 and batch: 750, loss is 3.882977313995361 and perplexity is 48.56860400352568
At time: 716.5387828350067 and batch: 800, loss is 3.8793378591537477 and perplexity is 48.39216203358259
At time: 717.532628774643 and batch: 850, loss is 3.8911873054504396 and perplexity is 48.968993174232715
At time: 718.5328118801117 and batch: 900, loss is 3.8440027809143067 and perplexity is 46.71207894022028
At time: 719.5297560691833 and batch: 950, loss is 3.9383538818359374 and perplexity is 51.33402983336653
At time: 720.5265500545502 and batch: 1000, loss is 3.9027715969085692 and perplexity is 49.53956270478804
At time: 721.5238330364227 and batch: 1050, loss is 3.853591351509094 and perplexity is 47.16213525694822
At time: 722.6616237163544 and batch: 1100, loss is 3.873641891479492 and perplexity is 48.11730537339918
At time: 723.6591420173645 and batch: 1150, loss is 3.8559656953811645 and perplexity is 47.27424742754249
At time: 724.6559989452362 and batch: 1200, loss is 3.8942100191116333 and perplexity is 49.11723635434591
At time: 725.65065741539 and batch: 1250, loss is 3.9084564781188966 and perplexity is 49.82199125974519
At time: 726.6465792655945 and batch: 1300, loss is 3.882773127555847 and perplexity is 48.55868796559672
At time: 727.6365518569946 and batch: 1350, loss is 3.7716536569595336 and perplexity is 43.45185992783841
At time: 728.6269836425781 and batch: 1400, loss is 3.7932920694351195 and perplexity is 44.4023355012873
At time: 729.6248531341553 and batch: 1450, loss is 3.7244569492340087 and perplexity is 41.448717874034294
At time: 730.6287569999695 and batch: 1500, loss is 3.7279859972000122 and perplexity is 41.59525079631787
At time: 731.6294469833374 and batch: 1550, loss is 3.766062922477722 and perplexity is 43.20960992494966
At time: 732.6260871887207 and batch: 1600, loss is 3.83397723197937 and perplexity is 46.24610443503615
At time: 733.622540473938 and batch: 1650, loss is 3.785573472976685 and perplexity is 44.06093106824306
At time: 734.6228659152985 and batch: 1700, loss is 3.77050874710083 and perplexity is 43.40213993291536
At time: 735.6254830360413 and batch: 1750, loss is 3.7648989009857177 and perplexity is 43.15934227232573
At time: 736.6175947189331 and batch: 1800, loss is 3.7198339033126833 and perplexity is 41.25754079861702
At time: 737.6112585067749 and batch: 1850, loss is 3.7566976594924926 and perplexity is 42.8068295803618
At time: 738.6084032058716 and batch: 1900, loss is 3.8731553173065185 and perplexity is 48.09389843040017
At time: 739.6124622821808 and batch: 1950, loss is 3.8058074569702147 and perplexity is 44.96153996863254
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3441162109375 and perplexity of 77.02393447854853
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 742.9791924953461 and batch: 50, loss is 3.9720168352127074 and perplexity is 53.09149974026598
At time: 744.009206533432 and batch: 100, loss is 3.9542834091186525 and perplexity is 52.15830438421441
At time: 745.009302854538 and batch: 150, loss is 3.9287976312637327 and perplexity is 50.84580549391934
At time: 746.0118718147278 and batch: 200, loss is 3.917583179473877 and perplexity is 50.278783025130075
At time: 747.0157811641693 and batch: 250, loss is 3.9274630165100097 and perplexity is 50.777991194790175
At time: 748.0638418197632 and batch: 300, loss is 3.9278442239761353 and perplexity is 50.797351834124164
At time: 749.0568962097168 and batch: 350, loss is 3.943252444267273 and perplexity is 51.58610969375052
At time: 750.0577237606049 and batch: 400, loss is 3.8921399974822997 and perplexity is 49.015667773567216
At time: 751.0630609989166 and batch: 450, loss is 3.9238383865356443 and perplexity is 50.59427292238593
At time: 752.0721175670624 and batch: 500, loss is 3.9478936338424684 and perplexity is 51.826087067757264
At time: 753.0825026035309 and batch: 550, loss is 3.9138598966598512 and perplexity is 50.091928967493764
At time: 754.0883400440216 and batch: 600, loss is 3.877908773422241 and perplexity is 48.32305487709067
At time: 755.08953332901 and batch: 650, loss is 3.9134781789779662 and perplexity is 50.07281164142997
At time: 756.0931906700134 and batch: 700, loss is 3.9431895542144777 and perplexity is 51.582865542601866
At time: 757.0962691307068 and batch: 750, loss is 3.894852681159973 and perplexity is 49.148812283309
At time: 758.100771188736 and batch: 800, loss is 3.8897072744369505 and perplexity is 48.89657115227478
At time: 759.1063876152039 and batch: 850, loss is 3.901161985397339 and perplexity is 49.459887394747426
At time: 760.1089625358582 and batch: 900, loss is 3.8534370279312133 and perplexity is 47.15485758906719
At time: 761.1101562976837 and batch: 950, loss is 3.9481191730499265 and perplexity is 51.837777200602275
At time: 762.1112651824951 and batch: 1000, loss is 3.9143252611160277 and perplexity is 50.11524539567422
At time: 763.1144297122955 and batch: 1050, loss is 3.864221005439758 and perplexity is 47.66612631314889
At time: 764.1142363548279 and batch: 1100, loss is 3.882868528366089 and perplexity is 48.56332072475389
At time: 765.110032081604 and batch: 1150, loss is 3.8721379470825195 and perplexity is 48.04499401134911
At time: 766.1054131984711 and batch: 1200, loss is 3.9054039669036866 and perplexity is 49.67014095295251
At time: 767.1001443862915 and batch: 1250, loss is 3.9185869121551513 and perplexity is 50.329274818719654
At time: 768.0982904434204 and batch: 1300, loss is 3.8874248266220093 and perplexity is 48.78509454845097
At time: 769.1013517379761 and batch: 1350, loss is 3.775250072479248 and perplexity is 43.60841221604292
At time: 770.1019320487976 and batch: 1400, loss is 3.797326240539551 and perplexity is 44.581823920208286
At time: 771.0988609790802 and batch: 1450, loss is 3.724089512825012 and perplexity is 41.43349090362412
At time: 772.0964941978455 and batch: 1500, loss is 3.727224278450012 and perplexity is 41.56357897791569
At time: 773.0940222740173 and batch: 1550, loss is 3.7633288860321046 and perplexity is 43.09163462448784
At time: 774.0991570949554 and batch: 1600, loss is 3.8299093294143676 and perplexity is 46.05836190623497
At time: 775.1086893081665 and batch: 1650, loss is 3.781249928474426 and perplexity is 43.870842895406206
At time: 776.1142873764038 and batch: 1700, loss is 3.762815823554993 and perplexity is 43.06953159428718
At time: 777.1153440475464 and batch: 1750, loss is 3.7579169273376465 and perplexity is 42.85905440277561
At time: 778.1201980113983 and batch: 1800, loss is 3.713369941711426 and perplexity is 40.991713712752926
At time: 779.1224138736725 and batch: 1850, loss is 3.7489353466033934 and perplexity is 42.47583587567786
At time: 780.1242401599884 and batch: 1900, loss is 3.863888759613037 and perplexity is 47.65029207218129
At time: 781.1300525665283 and batch: 1950, loss is 3.7990050745010375 and perplexity is 44.656732262010664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.339043763626454 and perplexity of 76.63422385810611
finished 19 epochs...
Completing Train Step...
At time: 784.4685125350952 and batch: 50, loss is 3.9752904844284056 and perplexity is 53.26558748237953
At time: 785.498681306839 and batch: 100, loss is 3.9536894226074217 and perplexity is 52.12733225438582
At time: 786.4988083839417 and batch: 150, loss is 3.9244989585876464 and perplexity is 50.62770512604382
At time: 787.5005519390106 and batch: 200, loss is 3.909752411842346 and perplexity is 49.88659911309397
At time: 788.5028319358826 and batch: 250, loss is 3.9170218563079833 and perplexity is 50.25056829899565
At time: 789.4977920055389 and batch: 300, loss is 3.9160688877105714 and perplexity is 50.202703895663596
At time: 790.5005350112915 and batch: 350, loss is 3.930382924079895 and perplexity is 50.926474909528814
At time: 791.4992361068726 and batch: 400, loss is 3.8789170455932616 and perplexity is 48.37180223971674
At time: 792.4996445178986 and batch: 450, loss is 3.912083373069763 and perplexity is 50.00301847318899
At time: 793.4925246238708 and batch: 500, loss is 3.9376247453689577 and perplexity is 51.29661396251359
At time: 794.4880065917969 and batch: 550, loss is 3.903267488479614 and perplexity is 49.56413504847211
At time: 795.4809548854828 and batch: 600, loss is 3.870143322944641 and perplexity is 47.949257817192446
At time: 796.4743688106537 and batch: 650, loss is 3.9062968254089356 and perplexity is 49.714509165079534
At time: 797.4746618270874 and batch: 700, loss is 3.9367191410064697 and perplexity is 51.25018055345059
At time: 798.5256369113922 and batch: 750, loss is 3.8893494319915773 and perplexity is 48.87907701394259
At time: 799.5252957344055 and batch: 800, loss is 3.8837616872787475 and perplexity is 48.60671486353366
At time: 800.5264117717743 and batch: 850, loss is 3.895159511566162 and perplexity is 49.163894947137194
At time: 801.5253014564514 and batch: 900, loss is 3.84809730052948 and perplexity is 46.903734564803386
At time: 802.5235795974731 and batch: 950, loss is 3.9426303243637086 and perplexity is 51.554026928860644
At time: 803.5209567546844 and batch: 1000, loss is 3.9089789962768555 and perplexity is 49.848030957359036
At time: 804.519323348999 and batch: 1050, loss is 3.85949462890625 and perplexity is 47.44136981262008
At time: 805.515186548233 and batch: 1100, loss is 3.8793396663665773 and perplexity is 48.3922494885977
At time: 806.5129835605621 and batch: 1150, loss is 3.868013691902161 and perplexity is 47.84725224495004
At time: 807.5099279880524 and batch: 1200, loss is 3.901830205917358 and perplexity is 49.49294855126384
At time: 808.5102398395538 and batch: 1250, loss is 3.9153040933609007 and perplexity is 50.16432382968554
At time: 809.5107679367065 and batch: 1300, loss is 3.885073380470276 and perplexity is 48.67051379364648
At time: 810.517637014389 and batch: 1350, loss is 3.7738146066665648 and perplexity is 43.54585873859183
At time: 811.5117475986481 and batch: 1400, loss is 3.7962401485443116 and perplexity is 44.53343024286525
At time: 812.5019376277924 and batch: 1450, loss is 3.724166464805603 and perplexity is 41.43667941549154
At time: 813.492927312851 and batch: 1500, loss is 3.7284966135025024 and perplexity is 41.61649543294794
At time: 814.4859340190887 and batch: 1550, loss is 3.765703558921814 and perplexity is 43.194084755634734
At time: 815.4792337417603 and batch: 1600, loss is 3.832048087120056 and perplexity is 46.156974999839875
At time: 816.4756679534912 and batch: 1650, loss is 3.783930253982544 and perplexity is 43.98858876281541
At time: 817.4681708812714 and batch: 1700, loss is 3.765273652076721 and perplexity is 43.175519313921946
At time: 818.4651968479156 and batch: 1750, loss is 3.761093034744263 and perplexity is 42.99539576569741
At time: 819.4596302509308 and batch: 1800, loss is 3.7166511821746826 and perplexity is 41.126438293441794
At time: 820.4537827968597 and batch: 1850, loss is 3.7522458744049074 and perplexity is 42.61668632726613
At time: 821.4473714828491 and batch: 1900, loss is 3.86748601436615 and perplexity is 47.82201098498916
At time: 822.4420053958893 and batch: 1950, loss is 3.802133250236511 and perplexity is 44.79664509016241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337890057231105 and perplexity of 76.54586144587961
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f4a57130b38>
ELAPSED
2548.9922132492065


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.78177940258892}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.6888560527046866, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6228089196258255, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.04378796834526}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.14308718722040714, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.37386466100496807, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.54586144587961}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.31025574538464784, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6931579404631784, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5449583530426025 and batch: 50, loss is 7.454704532623291 and perplexity is 1727.9733600774039
At time: 2.5380120277404785 and batch: 100, loss is 6.648116979598999 and perplexity is 771.330526081178
At time: 3.567863941192627 and batch: 150, loss is 6.36367919921875 and perplexity is 580.3777584585102
At time: 4.562904357910156 and batch: 200, loss is 6.183304700851441 and perplexity is 484.5907405789474
At time: 5.559574365615845 and batch: 250, loss is 6.051293220520019 and perplexity is 424.66185651836554
At time: 6.554795980453491 and batch: 300, loss is 5.950710239410401 and perplexity is 384.0259926195758
At time: 7.549995422363281 and batch: 350, loss is 5.864940118789673 and perplexity is 352.4610496815279
At time: 8.54603624343872 and batch: 400, loss is 5.792168054580689 and perplexity is 327.7227755730681
At time: 9.541070938110352 and batch: 450, loss is 5.69206241607666 and perplexity is 296.50450613416916
At time: 10.536507368087769 and batch: 500, loss is 5.661568517684937 and perplexity is 287.5993936932608
At time: 11.529706716537476 and batch: 550, loss is 5.613397951126099 and perplexity is 274.0739474349342
At time: 12.527808666229248 and batch: 600, loss is 5.611620244979858 and perplexity is 273.58715730715346
At time: 13.520612716674805 and batch: 650, loss is 5.662873306274414 and perplexity is 287.97489502214364
At time: 14.515119075775146 and batch: 700, loss is 5.595849056243896 and perplexity is 269.3062091671945
At time: 15.5097975730896 and batch: 750, loss is 5.515936183929443 and perplexity is 248.62262483588347
At time: 16.504786729812622 and batch: 800, loss is 5.515199432373047 and perplexity is 248.43951919004755
At time: 17.506008863449097 and batch: 850, loss is 5.5277656555175785 and perplexity is 251.58116358707272
At time: 18.516833543777466 and batch: 900, loss is 5.525290794372559 and perplexity is 250.95930496476703
At time: 19.51445174217224 and batch: 950, loss is 5.5401376247406 and perplexity is 254.7130518641505
At time: 20.510762691497803 and batch: 1000, loss is 5.506829776763916 and perplexity is 246.36884348374997
At time: 21.50764298439026 and batch: 1050, loss is 5.40187931060791 and perplexity is 221.82289885837594
At time: 22.50234031677246 and batch: 1100, loss is 5.481129331588745 and perplexity is 240.11772684396902
At time: 23.497865676879883 and batch: 1150, loss is 5.377135992050171 and perplexity is 216.401611120843
At time: 24.494744539260864 and batch: 1200, loss is 5.452765483856201 and perplexity is 233.4027457346245
At time: 25.496051788330078 and batch: 1250, loss is 5.405464162826538 and perplexity is 222.61952821561582
At time: 26.501736402511597 and batch: 1300, loss is 5.421338491439819 and perplexity is 226.18166220216736
At time: 27.49540424346924 and batch: 1350, loss is 5.359211702346801 and perplexity is 212.55732195116346
At time: 28.49461579322815 and batch: 1400, loss is 5.363345355987549 and perplexity is 213.43777879703399
At time: 29.49527597427368 and batch: 1450, loss is 5.319002246856689 and perplexity is 204.18005903167662
At time: 30.493524074554443 and batch: 1500, loss is 5.285495710372925 and perplexity is 197.4520382158405
At time: 31.497051000595093 and batch: 1550, loss is 5.274620504379272 and perplexity is 195.31634075037073
At time: 32.498302698135376 and batch: 1600, loss is 5.29740273475647 and perplexity is 199.81715727131933
At time: 33.508312463760376 and batch: 1650, loss is 5.287998638153076 and perplexity is 197.94686540757422
At time: 34.51656889915466 and batch: 1700, loss is 5.300537805557251 and perplexity is 200.44458120190296
At time: 35.51472353935242 and batch: 1750, loss is 5.2918934154510495 and perplexity is 198.71932767294086
At time: 36.51238465309143 and batch: 1800, loss is 5.26575288772583 and perplexity is 193.59200697922267
At time: 37.50943064689636 and batch: 1850, loss is 5.24593939781189 and perplexity is 189.79402360261864
At time: 38.5198028087616 and batch: 1900, loss is 5.312865829467773 and perplexity is 202.93096137886954
At time: 39.530537128448486 and batch: 1950, loss is 5.242720623016357 and perplexity is 189.18410151062417
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.872803869912791 and perplexity of 130.68683254456417
finished 1 epochs...
Completing Train Step...
At time: 42.91132378578186 and batch: 50, loss is 5.11623969078064 and perplexity is 166.70731846132554
At time: 43.91242742538452 and batch: 100, loss is 5.0578532314300535 and perplexity is 157.25256883331642
At time: 44.904284954071045 and batch: 150, loss is 4.981895208358765 and perplexity is 145.75034734134363
At time: 45.9006028175354 and batch: 200, loss is 4.943064641952515 and perplexity is 140.19925236474737
At time: 46.909515380859375 and batch: 250, loss is 4.963191881179809 and perplexity is 143.04966550424294
At time: 47.906123638153076 and batch: 300, loss is 4.977194356918335 and perplexity is 145.06680448655163
At time: 48.90064549446106 and batch: 350, loss is 4.979567642211914 and perplexity is 145.41149826677568
At time: 49.91126799583435 and batch: 400, loss is 4.921117429733276 and perplexity is 137.15578954595074
At time: 50.91742181777954 and batch: 450, loss is 4.891230554580688 and perplexity is 133.11728138559752
At time: 51.924479246139526 and batch: 500, loss is 4.8852171707153325 and perplexity is 132.31919806912444
At time: 52.91970419883728 and batch: 550, loss is 4.857063703536987 and perplexity is 128.6459044678993
At time: 53.91426181793213 and batch: 600, loss is 4.8223145484924315 and perplexity is 124.25234629897801
At time: 54.90723490715027 and batch: 650, loss is 4.893331823348999 and perplexity is 133.39729065583487
At time: 55.941633224487305 and batch: 700, loss is 4.9107421875 and perplexity is 135.74012165355296
At time: 56.939430713653564 and batch: 750, loss is 4.853267259597779 and perplexity is 128.15843341732858
At time: 57.94727659225464 and batch: 800, loss is 4.852278728485107 and perplexity is 128.03180741572692
At time: 58.94636869430542 and batch: 850, loss is 4.847891693115234 and perplexity is 127.47135760357139
At time: 59.950536489486694 and batch: 900, loss is 4.829965381622315 and perplexity is 125.20662612946647
At time: 60.944112062454224 and batch: 950, loss is 4.881533193588257 and perplexity is 131.8326339657698
At time: 61.93804359436035 and batch: 1000, loss is 4.858267307281494 and perplexity is 128.8008363798434
At time: 62.941579818725586 and batch: 1050, loss is 4.772452745437622 and perplexity is 118.20882283230286
At time: 63.9343376159668 and batch: 1100, loss is 4.832400531768799 and perplexity is 125.5118945998542
At time: 64.93706846237183 and batch: 1150, loss is 4.772469253540039 and perplexity is 118.2107742517638
At time: 65.93363904953003 and batch: 1200, loss is 4.841890048980713 and perplexity is 126.70861103412037
At time: 66.93515849113464 and batch: 1250, loss is 4.82520076751709 and perplexity is 124.61148381017414
At time: 67.92928457260132 and batch: 1300, loss is 4.821975059509278 and perplexity is 124.21017115568182
At time: 68.92252254486084 and batch: 1350, loss is 4.713004512786865 and perplexity is 111.38631928183001
At time: 69.91637539863586 and batch: 1400, loss is 4.7140984630584715 and perplexity is 111.50823704989081
At time: 70.92087531089783 and batch: 1450, loss is 4.6723926067352295 and perplexity is 106.95333381252806
At time: 71.92405533790588 and batch: 1500, loss is 4.6584852600097655 and perplexity is 105.47619208511928
At time: 72.92147850990295 and batch: 1550, loss is 4.6618027496337895 and perplexity is 105.8266893219598
At time: 73.92290663719177 and batch: 1600, loss is 4.71660192489624 and perplexity is 111.78774338668623
At time: 74.91639280319214 and batch: 1650, loss is 4.688609828948975 and perplexity is 108.70196040280857
At time: 75.91003561019897 and batch: 1700, loss is 4.7006353092193605 and perplexity is 110.01704509744268
At time: 76.90380048751831 and batch: 1750, loss is 4.692956581115722 and perplexity is 109.17548929550831
At time: 77.90011096000671 and batch: 1800, loss is 4.655273141860962 and perplexity is 105.13793364812571
At time: 78.89346385002136 and batch: 1850, loss is 4.687134695053101 and perplexity is 108.54172866715827
At time: 79.88667011260986 and batch: 1900, loss is 4.7895814800262455 and perplexity is 120.25103067202204
At time: 80.8807282447815 and batch: 1950, loss is 4.711343908309937 and perplexity is 111.20150415624514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.606690020893895 and perplexity of 100.15209904402072
finished 2 epochs...
Completing Train Step...
At time: 84.2941665649414 and batch: 50, loss is 4.69005841255188 and perplexity is 108.85953838513738
At time: 85.31332731246948 and batch: 100, loss is 4.635803623199463 and perplexity is 103.11074689747869
At time: 86.30105209350586 and batch: 150, loss is 4.5798679637908934 and perplexity is 97.50151962608372
At time: 87.2869279384613 and batch: 200, loss is 4.571777563095093 and perplexity is 96.71587563652781
At time: 88.27483344078064 and batch: 250, loss is 4.575158271789551 and perplexity is 97.0433971536625
At time: 89.26335334777832 and batch: 300, loss is 4.596621551513672 and perplexity is 99.14878012022538
At time: 90.25222992897034 and batch: 350, loss is 4.607862014770507 and perplexity is 100.26954550065078
At time: 91.25436162948608 and batch: 400, loss is 4.548491353988648 and perplexity is 94.48974914772472
At time: 92.24891948699951 and batch: 450, loss is 4.551003770828247 and perplexity is 94.72744525547205
At time: 93.2372498512268 and batch: 500, loss is 4.558593473434448 and perplexity is 95.44913362935583
At time: 94.22565937042236 and batch: 550, loss is 4.532722082138061 and perplexity is 93.01140147442021
At time: 95.21609950065613 and batch: 600, loss is 4.50741436958313 and perplexity is 90.68703195746329
At time: 96.20855784416199 and batch: 650, loss is 4.5750496959686275 and perplexity is 97.03286115913882
At time: 97.20465183258057 and batch: 700, loss is 4.6030998802185055 and perplexity is 99.79318358352234
At time: 98.20848846435547 and batch: 750, loss is 4.5523241424560545 and perplexity is 94.85260329594169
At time: 99.21104001998901 and batch: 800, loss is 4.548345880508423 and perplexity is 94.4760043948434
At time: 100.21538949012756 and batch: 850, loss is 4.545505666732788 and perplexity is 94.20805304537737
At time: 101.21142816543579 and batch: 900, loss is 4.52225209236145 and perplexity is 92.04265329320529
At time: 102.20278096199036 and batch: 950, loss is 4.589116897583008 and perplexity is 98.40748788772659
At time: 103.19274425506592 and batch: 1000, loss is 4.564543132781982 and perplexity is 96.01871619037813
At time: 104.18181133270264 and batch: 1050, loss is 4.498363494873047 and perplexity is 89.86993827755367
At time: 105.16947269439697 and batch: 1100, loss is 4.546097211837768 and perplexity is 94.26379784416193
At time: 106.20894479751587 and batch: 1150, loss is 4.500221214294434 and perplexity is 90.03704657940035
At time: 107.19772219657898 and batch: 1200, loss is 4.562039136886597 and perplexity is 95.77858648652129
At time: 108.18420004844666 and batch: 1250, loss is 4.568885498046875 and perplexity is 96.43657111109563
At time: 109.17274832725525 and batch: 1300, loss is 4.552935562133789 and perplexity is 94.91061577726023
At time: 110.16635775566101 and batch: 1350, loss is 4.436163272857666 and perplexity is 84.45030652060198
At time: 111.16882824897766 and batch: 1400, loss is 4.450595636367797 and perplexity is 85.67796171660633
At time: 112.16603565216064 and batch: 1450, loss is 4.402498846054077 and perplexity is 81.65465635772723
At time: 113.156081199646 and batch: 1500, loss is 4.391562004089355 and perplexity is 80.76647807146912
At time: 114.15045046806335 and batch: 1550, loss is 4.400571241378784 and perplexity is 81.49741006340814
At time: 115.13895511627197 and batch: 1600, loss is 4.4696265316009525 and perplexity is 87.32410412939147
At time: 116.13285875320435 and batch: 1650, loss is 4.431721992492676 and perplexity is 84.07607069070531
At time: 117.12211155891418 and batch: 1700, loss is 4.449759159088135 and perplexity is 85.60632401409491
At time: 118.11042857170105 and batch: 1750, loss is 4.439818544387817 and perplexity is 84.75956018046018
At time: 119.10324287414551 and batch: 1800, loss is 4.398705406188965 and perplexity is 81.34549109978036
At time: 120.09159469604492 and batch: 1850, loss is 4.443112964630127 and perplexity is 85.03925425319068
At time: 121.08225679397583 and batch: 1900, loss is 4.547831716537476 and perplexity is 94.42744072317956
At time: 122.07578802108765 and batch: 1950, loss is 4.471079587936401 and perplexity is 87.45108320366658
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.511503565588662 and perplexity of 91.05862825353756
finished 3 epochs...
Completing Train Step...
At time: 125.45334768295288 and batch: 50, loss is 4.4608855819702145 and perplexity is 86.56413479919647
At time: 126.44059324264526 and batch: 100, loss is 4.410321884155273 and perplexity is 82.29594900336909
At time: 127.42868161201477 and batch: 150, loss is 4.366587314605713 and perplexity is 78.77434041672242
At time: 128.415620803833 and batch: 200, loss is 4.36026104927063 and perplexity is 78.2775660576626
At time: 129.40146279335022 and batch: 250, loss is 4.359491882324218 and perplexity is 78.21738069047029
At time: 130.3896300792694 and batch: 300, loss is 4.377937335968017 and perplexity is 79.67352408724855
At time: 131.37759971618652 and batch: 350, loss is 4.3888638401031494 and perplexity is 80.5488505983781
At time: 132.39252352714539 and batch: 400, loss is 4.333898859024048 and perplexity is 76.24096060551008
At time: 133.3807077407837 and batch: 450, loss is 4.3521554660797115 and perplexity is 77.64564523717779
At time: 134.36852741241455 and batch: 500, loss is 4.3679054164886475 and perplexity is 78.8782414842059
At time: 135.3576729297638 and batch: 550, loss is 4.343047256469727 and perplexity is 76.94164339021138
At time: 136.34451937675476 and batch: 600, loss is 4.320396900177002 and perplexity is 75.21847659490724
At time: 137.33316922187805 and batch: 650, loss is 4.385242280960083 and perplexity is 80.25766576184101
At time: 138.3228681087494 and batch: 700, loss is 4.416830387115478 and perplexity is 82.8333192721198
At time: 139.31205368041992 and batch: 750, loss is 4.368234186172486 and perplexity is 78.90417852214262
At time: 140.30034112930298 and batch: 800, loss is 4.367605972290039 and perplexity is 78.8546253884249
At time: 141.2860028743744 and batch: 850, loss is 4.361819534301758 and perplexity is 78.39965558527555
At time: 142.27475786209106 and batch: 900, loss is 4.335433349609375 and perplexity is 76.35804144852742
At time: 143.2629075050354 and batch: 950, loss is 4.4114368724823 and perplexity is 82.38775920000667
At time: 144.25212907791138 and batch: 1000, loss is 4.381713609695435 and perplexity is 79.97496192070084
At time: 145.24204015731812 and batch: 1050, loss is 4.328745908737183 and perplexity is 75.84910519847739
At time: 146.23125648498535 and batch: 1100, loss is 4.367890224456787 and perplexity is 78.87704317255063
At time: 147.22068905830383 and batch: 1150, loss is 4.331451892852783 and perplexity is 76.05462961982661
At time: 148.2068293094635 and batch: 1200, loss is 4.390247550010681 and perplexity is 80.66038398812391
At time: 149.19587874412537 and batch: 1250, loss is 4.401937513351441 and perplexity is 81.60883379084696
At time: 150.18481040000916 and batch: 1300, loss is 4.383359708786011 and perplexity is 80.1067170440309
At time: 151.17346286773682 and batch: 1350, loss is 4.268104238510132 and perplexity is 71.3861760967621
At time: 152.1614077091217 and batch: 1400, loss is 4.286631364822387 and perplexity is 72.72108462348261
At time: 153.1580708026886 and batch: 1450, loss is 4.231956219673156 and perplexity is 68.85178974448287
At time: 154.1553852558136 and batch: 1500, loss is 4.226361794471741 and perplexity is 68.46767899800517
At time: 155.14960312843323 and batch: 1550, loss is 4.236671810150146 and perplexity is 69.17723331475783
At time: 156.1416790485382 and batch: 1600, loss is 4.309855670928955 and perplexity is 74.42974578902172
At time: 157.13578963279724 and batch: 1650, loss is 4.272028365135193 and perplexity is 71.66685484033457
At time: 158.13445401191711 and batch: 1700, loss is 4.294570555686951 and perplexity is 73.3007291036516
At time: 159.13201355934143 and batch: 1750, loss is 4.276831150054932 and perplexity is 72.01188321532182
At time: 160.13437151908875 and batch: 1800, loss is 4.233985414505005 and perplexity is 68.991645289481
At time: 161.1282434463501 and batch: 1850, loss is 4.282015981674195 and perplexity is 72.38622230836575
At time: 162.12215781211853 and batch: 1900, loss is 4.38815544128418 and perplexity is 80.49181009384327
At time: 163.11462807655334 and batch: 1950, loss is 4.313373584747314 and perplexity is 74.69204432153492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.489611248637354 and perplexity of 89.08680652861588
finished 4 epochs...
Completing Train Step...
At time: 166.33064532279968 and batch: 50, loss is 4.30715211391449 and perplexity is 74.22879249445448
At time: 167.342102766037 and batch: 100, loss is 4.261028652191162 and perplexity is 70.88285977468027
At time: 168.33805465698242 and batch: 150, loss is 4.223261165618896 and perplexity is 68.25571491780484
At time: 169.32501316070557 and batch: 200, loss is 4.217772417068481 and perplexity is 67.88210273113036
At time: 170.32042860984802 and batch: 250, loss is 4.212998342514038 and perplexity is 67.55880085945115
At time: 171.30960321426392 and batch: 300, loss is 4.231066002845764 and perplexity is 68.7905239966021
At time: 172.29798436164856 and batch: 350, loss is 4.240590333938599 and perplexity is 69.44883774579651
At time: 173.2862298488617 and batch: 400, loss is 4.188219327926635 and perplexity is 65.90533063054255
At time: 174.27404069900513 and batch: 450, loss is 4.215349531173706 and perplexity is 67.71783122783081
At time: 175.26200151443481 and batch: 500, loss is 4.234238252639771 and perplexity is 69.00909121379495
At time: 176.24969458580017 and batch: 550, loss is 4.208802070617676 and perplexity is 67.27589974218317
At time: 177.23772287368774 and batch: 600, loss is 4.190359463691712 and perplexity is 66.04652802263607
At time: 178.22575879096985 and batch: 650, loss is 4.251205096244812 and perplexity is 70.18994704183916
At time: 179.21100902557373 and batch: 700, loss is 4.284333667755127 and perplexity is 72.55418541595255
At time: 180.19869875907898 and batch: 750, loss is 4.2382479000091555 and perplexity is 69.28634881598956
At time: 181.1865382194519 and batch: 800, loss is 4.241130962371826 and perplexity is 69.48639391318771
At time: 182.19941401481628 and batch: 850, loss is 4.235906372070312 and perplexity is 69.12430268626478
At time: 183.1869330406189 and batch: 900, loss is 4.2059358215332034 and perplexity is 67.08334634097005
At time: 184.17495369911194 and batch: 950, loss is 4.28556921005249 and perplexity is 72.64388458303118
At time: 185.1623854637146 and batch: 1000, loss is 4.255094051361084 and perplexity is 70.463444059615
At time: 186.1516056060791 and batch: 1050, loss is 4.204481735229492 and perplexity is 66.98587225089285
At time: 187.13907766342163 and batch: 1100, loss is 4.239105734825134 and perplexity is 69.34581055880618
At time: 188.12528610229492 and batch: 1150, loss is 4.208004298210144 and perplexity is 67.2222502885493
At time: 189.11243891716003 and batch: 1200, loss is 4.266269636154175 and perplexity is 71.25533091105474
At time: 190.10045886039734 and batch: 1250, loss is 4.27877516746521 and perplexity is 72.15201173204625
At time: 191.0871980190277 and batch: 1300, loss is 4.259665231704712 and perplexity is 70.78628248421425
At time: 192.0759129524231 and batch: 1350, loss is 4.146392283439636 and perplexity is 63.205560725146356
At time: 193.0618040561676 and batch: 1400, loss is 4.171194586753845 and perplexity is 64.792806523341
At time: 194.0499246120453 and batch: 1450, loss is 4.109149098396301 and perplexity is 60.89487996737917
At time: 195.0388913154602 and batch: 1500, loss is 4.11105073928833 and perplexity is 61.01079033625898
At time: 196.027352809906 and batch: 1550, loss is 4.119813923835754 and perplexity is 61.547788622412014
At time: 197.01531505584717 and batch: 1600, loss is 4.190875840187073 and perplexity is 66.08064170430085
At time: 198.0065257549286 and batch: 1650, loss is 4.155194897651672 and perplexity is 63.76439086688363
At time: 199.01089119911194 and batch: 1700, loss is 4.178406925201416 and perplexity is 65.2618034221229
At time: 200.0149793624878 and batch: 1750, loss is 4.1619141483306885 and perplexity is 64.19428245076544
At time: 201.01953220367432 and batch: 1800, loss is 4.117124338150024 and perplexity is 61.382472986085354
At time: 202.0233016014099 and batch: 1850, loss is 4.165345478057861 and perplexity is 64.41493254557317
At time: 203.02247309684753 and batch: 1900, loss is 4.270392169952393 and perplexity is 71.54968975629032
At time: 204.02084493637085 and batch: 1950, loss is 4.193628702163696 and perplexity is 66.26280320793923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47733267850654 and perplexity of 87.99963603524606
finished 5 epochs...
Completing Train Step...
At time: 207.49301409721375 and batch: 50, loss is 4.19353551864624 and perplexity is 66.2566288945364
At time: 208.49989938735962 and batch: 100, loss is 4.149832730293274 and perplexity is 63.42339059886237
At time: 209.50595474243164 and batch: 150, loss is 4.116283955574036 and perplexity is 61.330909894713244
At time: 210.51160430908203 and batch: 200, loss is 4.110186305046081 and perplexity is 60.95807330843041
At time: 211.50300931930542 and batch: 250, loss is 4.10299168586731 and perplexity is 60.52107708082615
At time: 212.49867868423462 and batch: 300, loss is 4.121115050315857 and perplexity is 61.62792220063563
At time: 213.4933693408966 and batch: 350, loss is 4.13309919834137 and perplexity is 62.370923569532216
At time: 214.49248719215393 and batch: 400, loss is 4.081683254241943 and perplexity is 59.24511054968773
At time: 215.48626899719238 and batch: 450, loss is 4.114491686820984 and perplexity is 61.22108686690131
At time: 216.48541164398193 and batch: 500, loss is 4.134936151504516 and perplexity is 62.485601331463045
At time: 217.48917269706726 and batch: 550, loss is 4.108520722389221 and perplexity is 60.856627105702565
At time: 218.4899730682373 and batch: 600, loss is 4.093077635765075 and perplexity is 59.92403254532887
At time: 219.48604702949524 and batch: 650, loss is 4.149364676475525 and perplexity is 63.39371198489408
At time: 220.4800615310669 and batch: 700, loss is 4.182706718444824 and perplexity is 65.54301983648337
At time: 221.4743459224701 and batch: 750, loss is 4.135370292663574 and perplexity is 62.512734792299426
At time: 222.46727347373962 and batch: 800, loss is 4.144596018791199 and perplexity is 63.09212871828276
At time: 223.4582643508911 and batch: 850, loss is 4.138180780410766 and perplexity is 62.68867318802026
At time: 224.4505717754364 and batch: 900, loss is 4.108327312469482 and perplexity is 60.84485796850912
At time: 225.44400310516357 and batch: 950, loss is 4.188712787628174 and perplexity is 65.93786028070095
At time: 226.43958616256714 and batch: 1000, loss is 4.160077333450317 and perplexity is 64.07647766343997
At time: 227.4297080039978 and batch: 1050, loss is 4.115452566146851 and perplexity is 61.27994121501366
At time: 228.42356491088867 and batch: 1100, loss is 4.141466674804687 and perplexity is 62.89500034679369
At time: 229.41667246818542 and batch: 1150, loss is 4.111102156639099 and perplexity is 61.01392743011623
At time: 230.40882539749146 and batch: 1200, loss is 4.1706164360046385 and perplexity is 64.75535734038606
At time: 231.40280032157898 and batch: 1250, loss is 4.186153440475464 and perplexity is 65.76931817661237
At time: 232.40343189239502 and batch: 1300, loss is 4.161440453529358 and perplexity is 64.16388115392996
At time: 233.39821314811707 and batch: 1350, loss is 4.05342821598053 and perplexity is 57.594565597228865
At time: 234.39038062095642 and batch: 1400, loss is 4.0788091373443605 and perplexity is 59.075077640633324
At time: 235.38372898101807 and batch: 1450, loss is 4.014391312599182 and perplexity is 55.389570205962926
At time: 236.38064694404602 and batch: 1500, loss is 4.019821882247925 and perplexity is 55.691185354569974
At time: 237.37495803833008 and batch: 1550, loss is 4.02991584777832 and perplexity is 56.25617696565562
At time: 238.37585997581482 and batch: 1600, loss is 4.1031026268005375 and perplexity is 60.52779171805461
At time: 239.37895941734314 and batch: 1650, loss is 4.0662084531784055 and perplexity is 58.33536149743239
At time: 240.3838882446289 and batch: 1700, loss is 4.091112008094788 and perplexity is 59.8063598970369
At time: 241.37866759300232 and batch: 1750, loss is 4.0725935935974125 and perplexity is 58.70903267390566
At time: 242.38474917411804 and batch: 1800, loss is 4.02548457622528 and perplexity is 56.00744208190875
At time: 243.37828707695007 and batch: 1850, loss is 4.0794477891922 and perplexity is 59.1128180983535
At time: 244.3719081878662 and batch: 1900, loss is 4.179008092880249 and perplexity is 65.30104850425818
At time: 245.3706157207489 and batch: 1950, loss is 4.099007024765014 and perplexity is 60.28040092401833
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474527048510175 and perplexity of 87.7530876402293
finished 6 epochs...
Completing Train Step...
At time: 248.59923911094666 and batch: 50, loss is 4.106061496734619 and perplexity is 60.70715080038753
At time: 249.61848616600037 and batch: 100, loss is 4.065067677497864 and perplexity is 58.268851879210814
At time: 250.62632608413696 and batch: 150, loss is 4.033460297584534 and perplexity is 56.45592795575424
At time: 251.6256320476532 and batch: 200, loss is 4.029069910049438 and perplexity is 56.20860786616244
At time: 252.62647318840027 and batch: 250, loss is 4.020695209503174 and perplexity is 55.73984322864844
At time: 253.62608289718628 and batch: 300, loss is 4.0384084558486935 and perplexity is 56.73597310469683
At time: 254.63223958015442 and batch: 350, loss is 4.046315875053406 and perplexity is 57.18638668559728
At time: 255.6368579864502 and batch: 400, loss is 3.9994734477996827 and perplexity is 54.56940882464838
At time: 256.63919377326965 and batch: 450, loss is 4.029731149673462 and perplexity is 56.24578751586886
At time: 257.6391727924347 and batch: 500, loss is 4.053917317390442 and perplexity is 57.62274207048046
At time: 258.6930160522461 and batch: 550, loss is 4.031082973480225 and perplexity is 56.321873326181034
At time: 259.6822018623352 and batch: 600, loss is 4.017786240577697 and perplexity is 55.577933366339245
At time: 260.67094802856445 and batch: 650, loss is 4.071861505508423 and perplexity is 58.66606821917068
At time: 261.66090416908264 and batch: 700, loss is 4.102281379699707 and perplexity is 60.47810385038776
At time: 262.6520845890045 and batch: 750, loss is 4.058771977424621 and perplexity is 57.90316101204793
At time: 263.6429274082184 and batch: 800, loss is 4.063641252517701 and perplexity is 58.185794984622376
At time: 264.6489586830139 and batch: 850, loss is 4.060816087722778 and perplexity is 58.02164251314164
At time: 265.64524936676025 and batch: 900, loss is 4.029528207778931 and perplexity is 56.234374047365634
At time: 266.6449942588806 and batch: 950, loss is 4.1106920289993285 and perplexity is 60.98890906277886
At time: 267.6466453075409 and batch: 1000, loss is 4.0842536306381225 and perplexity is 59.397588662555016
At time: 268.6487674713135 and batch: 1050, loss is 4.042067375183105 and perplexity is 56.943945699096936
At time: 269.6503276824951 and batch: 1100, loss is 4.0616977453231815 and perplexity is 58.0728202925752
At time: 270.6539044380188 and batch: 1150, loss is 4.03437343120575 and perplexity is 56.50750330569694
At time: 271.65181183815 and batch: 1200, loss is 4.096908626556396 and perplexity is 60.15404126151566
At time: 272.65706181526184 and batch: 1250, loss is 4.111035385131836 and perplexity is 61.00985357422796
At time: 273.67499804496765 and batch: 1300, loss is 4.085134444236755 and perplexity is 59.44992991443418
At time: 274.6761939525604 and batch: 1350, loss is 3.978085465431213 and perplexity is 53.414672034688905
At time: 275.67012906074524 and batch: 1400, loss is 4.007060284614563 and perplexity is 54.98499251388433
At time: 276.6594729423523 and batch: 1450, loss is 3.9413041067123413 and perplexity is 51.48570038629662
At time: 277.65773725509644 and batch: 1500, loss is 3.9435764598846434 and perplexity is 51.60282710713594
At time: 278.6482355594635 and batch: 1550, loss is 3.956730298995972 and perplexity is 52.2860862815905
At time: 279.63567781448364 and batch: 1600, loss is 4.029459433555603 and perplexity is 56.23050670495446
At time: 280.62856364250183 and batch: 1650, loss is 3.993573727607727 and perplexity is 54.24841240713374
At time: 281.624018907547 and batch: 1700, loss is 4.020211691856384 and perplexity is 55.71289854545797
At time: 282.61807107925415 and batch: 1750, loss is 4.003344359397889 and perplexity is 54.781051543031204
At time: 283.60525465011597 and batch: 1800, loss is 3.953258023262024 and perplexity is 52.10484940726539
At time: 284.59343671798706 and batch: 1850, loss is 4.00573646068573 and perplexity is 54.91225022468276
At time: 285.58666014671326 and batch: 1900, loss is 4.106366453170776 and perplexity is 60.72566665986661
At time: 286.57374906539917 and batch: 1950, loss is 4.029601669311523 and perplexity is 56.238505262408346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.477657442314681 and perplexity of 88.02821977339042
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 289.80830001831055 and batch: 50, loss is 4.074585752487183 and perplexity is 58.826106971839124
At time: 290.797527551651 and batch: 100, loss is 4.061703662872315 and perplexity is 58.07316394235938
At time: 291.7852609157562 and batch: 150, loss is 4.023623790740967 and perplexity is 55.903321150071896
At time: 292.7731499671936 and batch: 200, loss is 4.02336476802826 and perplexity is 55.88884279537057
At time: 293.7613036632538 and batch: 250, loss is 4.007456612586975 and perplexity is 55.00678892345855
At time: 294.74921441078186 and batch: 300, loss is 4.024004597663879 and perplexity is 55.92461357567386
At time: 295.7362132072449 and batch: 350, loss is 4.030041756629944 and perplexity is 56.26326056222851
At time: 296.72667956352234 and batch: 400, loss is 3.9787094449996947 and perplexity is 53.44801209937353
At time: 297.7258110046387 and batch: 450, loss is 4.0062677907943725 and perplexity is 54.941434509118345
At time: 298.7302145957947 and batch: 500, loss is 4.016446099281311 and perplexity is 55.503500968772016
At time: 299.7301902770996 and batch: 550, loss is 3.9887103843688965 and perplexity is 53.985224263322074
At time: 300.73021602630615 and batch: 600, loss is 3.9672201824188233 and perplexity is 52.83744803571359
At time: 301.72894406318665 and batch: 650, loss is 4.0121257114410405 and perplexity is 55.26422158016856
At time: 302.7339446544647 and batch: 700, loss is 4.041870412826538 and perplexity is 56.93273098983382
At time: 303.7370412349701 and batch: 750, loss is 3.983787522315979 and perplexity is 53.72011553363004
At time: 304.7387766838074 and batch: 800, loss is 3.9792626905441284 and perplexity is 53.47759015513569
At time: 305.7370276451111 and batch: 850, loss is 3.977364854812622 and perplexity is 53.37619472007793
At time: 306.7368335723877 and batch: 900, loss is 3.9404681444168093 and perplexity is 51.44267826695488
At time: 307.73462319374084 and batch: 950, loss is 4.032283554077148 and perplexity is 56.38953288172661
At time: 308.7990517616272 and batch: 1000, loss is 3.993409733772278 and perplexity is 54.239516731354
At time: 309.79786825180054 and batch: 1050, loss is 3.9367191648483275 and perplexity is 51.25018177535012
At time: 310.8085539340973 and batch: 1100, loss is 3.950524926185608 and perplexity is 51.96263622542462
At time: 311.82174491882324 and batch: 1150, loss is 3.914446325302124 and perplexity is 50.12131292434188
At time: 312.812349319458 and batch: 1200, loss is 3.9655173206329346 and perplexity is 52.74754972850913
At time: 313.803151845932 and batch: 1250, loss is 3.9716395473480226 and perplexity is 53.07147273990573
At time: 314.796484708786 and batch: 1300, loss is 3.949670214653015 and perplexity is 51.91824213575164
At time: 315.79622650146484 and batch: 1350, loss is 3.840930976867676 and perplexity is 46.56880874874002
At time: 316.79836988449097 and batch: 1400, loss is 3.8531045293807984 and perplexity is 47.13918127359431
At time: 317.8091514110565 and batch: 1450, loss is 3.7873326683044435 and perplexity is 44.13851107149696
At time: 318.8100588321686 and batch: 1500, loss is 3.786193642616272 and perplexity is 44.08826479488116
At time: 319.80343222618103 and batch: 1550, loss is 3.7996393966674806 and perplexity is 44.685068003209636
At time: 320.79358100891113 and batch: 1600, loss is 3.8583441019058227 and perplexity is 47.38681862303917
At time: 321.7864508628845 and batch: 1650, loss is 3.821518621444702 and perplexity is 45.673516462668736
At time: 322.77589225769043 and batch: 1700, loss is 3.8198039960861205 and perplexity is 45.59527059347187
At time: 323.78646636009216 and batch: 1750, loss is 3.794080739021301 and perplexity is 44.43736808560363
At time: 324.78291416168213 and batch: 1800, loss is 3.7516951751708985 and perplexity is 42.593223811737325
At time: 325.7843940258026 and batch: 1850, loss is 3.786680932044983 and perplexity is 44.10975377549724
At time: 326.7877390384674 and batch: 1900, loss is 3.892831997871399 and perplexity is 49.04959837337861
At time: 327.78572964668274 and batch: 1950, loss is 3.805167546272278 and perplexity is 44.932777801801514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.389913869458575 and perplexity of 80.63347367663519
finished 8 epochs...
Completing Train Step...
At time: 331.08712792396545 and batch: 50, loss is 3.991801357269287 and perplexity is 54.15234928493698
At time: 332.11503863334656 and batch: 100, loss is 3.960902829170227 and perplexity is 52.5047073385899
At time: 333.1215159893036 and batch: 150, loss is 3.9207782793045043 and perplexity is 50.439685669380125
At time: 334.1424193382263 and batch: 200, loss is 3.9204609107971193 and perplexity is 50.423680241569976
At time: 335.1383454799652 and batch: 250, loss is 3.903836727142334 and perplexity is 49.59235690214902
At time: 336.1355838775635 and batch: 300, loss is 3.9200679016113282 and perplexity is 50.40386716566908
At time: 337.13042068481445 and batch: 350, loss is 3.929905138015747 and perplexity is 50.90214876133092
At time: 338.1353294849396 and batch: 400, loss is 3.878604083061218 and perplexity is 48.35666604666249
At time: 339.1383957862854 and batch: 450, loss is 3.9134385633468627 and perplexity is 50.07082801468724
At time: 340.1321415901184 and batch: 500, loss is 3.9281446504592896 and perplexity is 50.81261499650354
At time: 341.1253991127014 and batch: 550, loss is 3.9065488624572753 and perplexity is 49.727040642361096
At time: 342.1206285953522 and batch: 600, loss is 3.8878619384765627 and perplexity is 48.80642375288805
At time: 343.11598324775696 and batch: 650, loss is 3.933084135055542 and perplexity is 51.064224023456994
At time: 344.11045932769775 and batch: 700, loss is 3.96554780960083 and perplexity is 52.749157971376064
At time: 345.1065742969513 and batch: 750, loss is 3.9106641530990602 and perplexity is 49.932103524635004
At time: 346.1010284423828 and batch: 800, loss is 3.9091615724563598 and perplexity is 49.85713285127626
At time: 347.1020493507385 and batch: 850, loss is 3.907141799926758 and perplexity is 49.75653441112064
At time: 348.10226821899414 and batch: 900, loss is 3.8694282150268555 and perplexity is 47.91498118048329
At time: 349.09810400009155 and batch: 950, loss is 3.9668670177459715 and perplexity is 52.81879101035877
At time: 350.1024708747864 and batch: 1000, loss is 3.931692109107971 and perplexity is 50.99319075017386
At time: 351.10357666015625 and batch: 1050, loss is 3.879760980606079 and perplexity is 48.41264212794179
At time: 352.0992076396942 and batch: 1100, loss is 3.892356400489807 and perplexity is 49.02627605927946
At time: 353.09421968460083 and batch: 1150, loss is 3.861019811630249 and perplexity is 47.513781776962695
At time: 354.08850717544556 and batch: 1200, loss is 3.913494973182678 and perplexity is 50.073652581540614
At time: 355.0902695655823 and batch: 1250, loss is 3.9256315183639527 and perplexity is 50.685076510565004
At time: 356.08513283729553 and batch: 1300, loss is 3.9053091764450074 and perplexity is 49.665432920650716
At time: 357.0790922641754 and batch: 1350, loss is 3.7955409240722657 and perplexity is 44.50230226260632
At time: 358.0750241279602 and batch: 1400, loss is 3.8125853729248047 and perplexity is 45.26732061485617
At time: 359.06991052627563 and batch: 1450, loss is 3.7500177383422852 and perplexity is 42.521836260259285
At time: 360.06752038002014 and batch: 1500, loss is 3.750374131202698 and perplexity is 42.53699343990895
At time: 361.062402009964 and batch: 1550, loss is 3.7669781064987182 and perplexity is 43.24917277038708
At time: 362.0668201446533 and batch: 1600, loss is 3.829496645927429 and perplexity is 46.0393583023473
At time: 363.062344789505 and batch: 1650, loss is 3.793040223121643 and perplexity is 44.39115434480716
At time: 364.0607843399048 and batch: 1700, loss is 3.7967778921127318 and perplexity is 44.557384248537055
At time: 365.05786871910095 and batch: 1750, loss is 3.775009298324585 and perplexity is 43.597913701391604
At time: 366.05969166755676 and batch: 1800, loss is 3.735372095108032 and perplexity is 41.90361479265803
At time: 367.05564546585083 and batch: 1850, loss is 3.773660912513733 and perplexity is 43.539166509015125
At time: 368.05844378471375 and batch: 1900, loss is 3.884108934402466 and perplexity is 48.62359633631523
At time: 369.052716255188 and batch: 1950, loss is 3.796960349082947 and perplexity is 44.565514795582686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39043451353561 and perplexity of 80.67546594768072
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 372.3035180568695 and batch: 50, loss is 3.976521792411804 and perplexity is 53.33121422055883
At time: 373.29214668273926 and batch: 100, loss is 3.978748950958252 and perplexity is 53.45012365603377
At time: 374.28155732154846 and batch: 150, loss is 3.9524664163589476 and perplexity is 52.06361917001411
At time: 375.27245140075684 and batch: 200, loss is 3.957263526916504 and perplexity is 52.31397411727672
At time: 376.26449751853943 and batch: 250, loss is 3.9390948534011843 and perplexity is 51.37208098547249
At time: 377.25320315361023 and batch: 300, loss is 3.9545716857910156 and perplexity is 52.173342574113924
At time: 378.2533378601074 and batch: 350, loss is 3.968858118057251 and perplexity is 52.924063290636774
At time: 379.25403928756714 and batch: 400, loss is 3.912260251045227 and perplexity is 50.01186368810241
At time: 380.2545623779297 and batch: 450, loss is 3.946648931503296 and perplexity is 51.761619145963664
At time: 381.2472925186157 and batch: 500, loss is 3.9608101940155027 and perplexity is 52.499843782173464
At time: 382.2386009693146 and batch: 550, loss is 3.942758355140686 and perplexity is 51.56062785353641
At time: 383.2292523384094 and batch: 600, loss is 3.911921167373657 and perplexity is 49.99490835654149
At time: 384.2216386795044 and batch: 650, loss is 3.9479356098175047 and perplexity is 51.82826256395322
At time: 385.24021887779236 and batch: 700, loss is 3.9799424409866333 and perplexity is 53.51395392845305
At time: 386.2283718585968 and batch: 750, loss is 3.915713005065918 and perplexity is 50.184840803403254
At time: 387.2202322483063 and batch: 800, loss is 3.9214306020736696 and perplexity is 50.47259935881918
At time: 388.2173709869385 and batch: 850, loss is 3.925064692497253 and perplexity is 50.65635503894869
At time: 389.20855474472046 and batch: 900, loss is 3.886788845062256 and perplexity is 48.75407799195176
At time: 390.202924489975 and batch: 950, loss is 3.9762314701080324 and perplexity is 53.315733226930966
At time: 391.1930205821991 and batch: 1000, loss is 3.935108251571655 and perplexity is 51.16768863957959
At time: 392.19199538230896 and batch: 1050, loss is 3.879091215133667 and perplexity is 48.38022786800403
At time: 393.1847040653229 and batch: 1100, loss is 3.894988527297974 and perplexity is 49.155489413165895
At time: 394.1745014190674 and batch: 1150, loss is 3.867312297821045 and perplexity is 47.81370423199197
At time: 395.1670706272125 and batch: 1200, loss is 3.901197352409363 and perplexity is 49.461636674112825
At time: 396.1739637851715 and batch: 1250, loss is 3.9075425338745116 and perplexity is 49.7764775392591
At time: 397.16780853271484 and batch: 1300, loss is 3.887507743835449 and perplexity is 48.789139840258166
At time: 398.1660351753235 and batch: 1350, loss is 3.7725376749038695 and perplexity is 43.49028913528121
At time: 399.155321598053 and batch: 1400, loss is 3.7883762645721437 and perplexity is 44.18459790075178
At time: 400.1474356651306 and batch: 1450, loss is 3.7239604997634888 and perplexity is 41.4281457869154
At time: 401.1385021209717 and batch: 1500, loss is 3.7353064966201783 and perplexity is 41.90086606904907
At time: 402.128212928772 and batch: 1550, loss is 3.7482200622558595 and perplexity is 42.445464438529285
At time: 403.1200134754181 and batch: 1600, loss is 3.8057988834381105 and perplexity is 44.961154491078624
At time: 404.11031794548035 and batch: 1650, loss is 3.767790265083313 and perplexity is 43.28431222480244
At time: 405.1035852432251 and batch: 1700, loss is 3.7566721773147584 and perplexity is 42.8057387830202
At time: 406.0942656993866 and batch: 1750, loss is 3.7332053995132446 and perplexity is 41.81292070380332
At time: 407.08388924598694 and batch: 1800, loss is 3.6988113498687745 and perplexity is 40.39925522889246
At time: 408.08398175239563 and batch: 1850, loss is 3.731639361381531 and perplexity is 41.74749132140872
At time: 409.0768814086914 and batch: 1900, loss is 3.843190269470215 and perplexity is 46.6741402563986
At time: 410.07327675819397 and batch: 1950, loss is 3.7639488410949706 and perplexity is 43.11835778426366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3628190861191865 and perplexity of 78.4780592812522
finished 10 epochs...
Completing Train Step...
At time: 413.48320388793945 and batch: 50, loss is 3.970539312362671 and perplexity is 53.01311375905641
At time: 414.5084750652313 and batch: 100, loss is 3.9503859233856202 and perplexity is 51.95541377547655
At time: 415.5049271583557 and batch: 150, loss is 3.916676468849182 and perplexity is 50.23321537982037
At time: 416.49468183517456 and batch: 200, loss is 3.914487318992615 and perplexity is 50.12336762404545
At time: 417.48441910743713 and batch: 250, loss is 3.8926909589767456 and perplexity is 49.042680960064466
At time: 418.4739816188812 and batch: 300, loss is 3.906832275390625 and perplexity is 49.74113592611486
At time: 419.46440744400024 and batch: 350, loss is 3.9247775268554688 and perplexity is 50.641810362709066
At time: 420.45079255104065 and batch: 400, loss is 3.8687312269210814 and perplexity is 47.88159664417596
At time: 421.43942952156067 and batch: 450, loss is 3.9057190465927123 and perplexity is 49.68579347128364
At time: 422.4261758327484 and batch: 500, loss is 3.9200923824310303 and perplexity is 50.40510110875736
At time: 423.41805243492126 and batch: 550, loss is 3.9039589595794677 and perplexity is 49.59841906728544
At time: 424.4063150882721 and batch: 600, loss is 3.876409549713135 and perplexity is 48.25066208757529
At time: 425.3970501422882 and batch: 650, loss is 3.9124886322021486 and perplexity is 50.02328675974881
At time: 426.3872101306915 and batch: 700, loss is 3.9465995740890505 and perplexity is 51.759064389334064
At time: 427.38829040527344 and batch: 750, loss is 3.8854732084274293 and perplexity is 48.689977516561186
At time: 428.3764190673828 and batch: 800, loss is 3.8920288562774656 and perplexity is 49.01022041591367
At time: 429.3644106388092 and batch: 850, loss is 3.895058469772339 and perplexity is 49.15892758995997
At time: 430.36533188819885 and batch: 900, loss is 3.8542103004455566 and perplexity is 47.19133524612573
At time: 431.3545501232147 and batch: 950, loss is 3.947489342689514 and perplexity is 51.80513847421439
At time: 432.3504145145416 and batch: 1000, loss is 3.9084841632843017 and perplexity is 49.823370608907695
At time: 433.3442714214325 and batch: 1050, loss is 3.8556224155426024 and perplexity is 47.25802191662214
At time: 434.33379888534546 and batch: 1100, loss is 3.8729485702514648 and perplexity is 48.08395618633389
At time: 435.35230112075806 and batch: 1150, loss is 3.8463179016113282 and perplexity is 46.82034832095942
At time: 436.34184885025024 and batch: 1200, loss is 3.881078782081604 and perplexity is 48.47648243435828
At time: 437.33027720451355 and batch: 1250, loss is 3.8908852243423464 and perplexity is 48.95420280057114
At time: 438.3308570384979 and batch: 1300, loss is 3.872037353515625 and perplexity is 48.04016123710716
At time: 439.3239505290985 and batch: 1350, loss is 3.757786593437195 and perplexity is 42.853468779051596
At time: 440.31513953208923 and batch: 1400, loss is 3.7758814001083376 and perplexity is 43.63595210396698
At time: 441.3127751350403 and batch: 1450, loss is 3.713069043159485 and perplexity is 40.979381220962686
At time: 442.30452966690063 and batch: 1500, loss is 3.7262463760375977 and perplexity is 41.52295372077056
At time: 443.2957921028137 and batch: 1550, loss is 3.7422821378707884 and perplexity is 42.19417329247069
At time: 444.2879021167755 and batch: 1600, loss is 3.8026019525527954 and perplexity is 44.81764630275196
At time: 445.28731989860535 and batch: 1650, loss is 3.7645058393478394 and perplexity is 43.14238132412983
At time: 446.28606700897217 and batch: 1700, loss is 3.7550536584854126 and perplexity is 42.73651292558471
At time: 447.276038646698 and batch: 1750, loss is 3.7338573265075685 and perplexity is 41.8401885628826
At time: 448.2677962779999 and batch: 1800, loss is 3.700613031387329 and perplexity is 40.472107428926044
At time: 449.2733337879181 and batch: 1850, loss is 3.7356215381622313 and perplexity is 41.91406866208226
At time: 450.27538657188416 and batch: 1900, loss is 3.848857479095459 and perplexity is 46.939403334083195
At time: 451.2678496837616 and batch: 1950, loss is 3.7685460901260375 and perplexity is 43.31703995860142
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361405909338663 and perplexity of 78.36723423622928
finished 11 epochs...
Completing Train Step...
At time: 454.71348881721497 and batch: 50, loss is 3.9554097509384154 and perplexity is 52.2170855613249
At time: 455.7173249721527 and batch: 100, loss is 3.9332680177688597 and perplexity is 51.07361471489034
At time: 456.72193670272827 and batch: 150, loss is 3.8988412618637085 and perplexity is 49.345237756612654
At time: 457.7230603694916 and batch: 200, loss is 3.8959655570983887 and perplexity is 49.203539260420555
At time: 458.73051714897156 and batch: 250, loss is 3.8729487085342407 and perplexity is 48.08396283551728
At time: 459.72951674461365 and batch: 300, loss is 3.8868029356002807 and perplexity is 48.754764967981494
At time: 460.7269763946533 and batch: 350, loss is 3.9048038959503173 and perplexity is 49.640344285068444
At time: 461.75999546051025 and batch: 400, loss is 3.848767294883728 and perplexity is 46.93517033187224
At time: 462.76413655281067 and batch: 450, loss is 3.8869918727874757 and perplexity is 48.76397742639748
At time: 463.76909351348877 and batch: 500, loss is 3.901786918640137 and perplexity is 49.490806182648384
At time: 464.77451252937317 and batch: 550, loss is 3.8857482957839964 and perplexity is 48.70337335619611
At time: 465.7788438796997 and batch: 600, loss is 3.8592780113220213 and perplexity is 47.43109429066832
At time: 466.78227162361145 and batch: 650, loss is 3.8952018880844115 and perplexity is 49.16597838597277
At time: 467.7813892364502 and batch: 700, loss is 3.929989619255066 and perplexity is 50.90644921959373
At time: 468.77994084358215 and batch: 750, loss is 3.8696295547485353 and perplexity is 47.92462934070482
At time: 469.78048181533813 and batch: 800, loss is 3.8770109605789185 and perplexity is 48.279689287797915
At time: 470.78127431869507 and batch: 850, loss is 3.879681735038757 and perplexity is 48.40880579265909
At time: 471.7814869880676 and batch: 900, loss is 3.8383241081237793 and perplexity is 46.44756807469451
At time: 472.7808470726013 and batch: 950, loss is 3.932961311340332 and perplexity is 51.05795251090124
At time: 473.7800328731537 and batch: 1000, loss is 3.8948625898361207 and perplexity is 49.14929928538572
At time: 474.77839183807373 and batch: 1050, loss is 3.8425697088241577 and perplexity is 46.64518510690927
At time: 475.77870059013367 and batch: 1100, loss is 3.8609259366989135 and perplexity is 47.50932163331201
At time: 476.7822308540344 and batch: 1150, loss is 3.83445481300354 and perplexity is 46.268195971785595
At time: 477.78647089004517 and batch: 1200, loss is 3.869460411071777 and perplexity is 47.916523878204046
At time: 478.7882807254791 and batch: 1250, loss is 3.8808465719223024 and perplexity is 48.4652270095124
At time: 479.789071559906 and batch: 1300, loss is 3.8625134515762327 and perplexity is 47.5848032864875
At time: 480.78922295570374 and batch: 1350, loss is 3.747865343093872 and perplexity is 42.43041088900256
At time: 481.7911550998688 and batch: 1400, loss is 3.767391963005066 and perplexity is 43.26707542624203
At time: 482.79653692245483 and batch: 1450, loss is 3.7052220344543456 and perplexity is 40.65907403003748
At time: 483.7999601364136 and batch: 1500, loss is 3.719113202095032 and perplexity is 41.22781715094726
At time: 484.7968554496765 and batch: 1550, loss is 3.73615083694458 and perplexity is 41.93625959988849
At time: 485.78597497940063 and batch: 1600, loss is 3.7982095098495483 and perplexity is 44.62121907276409
At time: 486.77854084968567 and batch: 1650, loss is 3.759831175804138 and perplexity is 42.94117585729881
At time: 487.7675507068634 and batch: 1700, loss is 3.7507489109039307 and perplexity is 42.55293842934425
At time: 488.7592992782593 and batch: 1750, loss is 3.730862760543823 and perplexity is 41.71508277055901
At time: 489.74684500694275 and batch: 1800, loss is 3.6975934743881225 and perplexity is 40.3500839148591
At time: 490.7424957752228 and batch: 1850, loss is 3.7337955713272093 and perplexity is 41.837604794273005
At time: 491.7311222553253 and batch: 1900, loss is 3.84792254447937 and perplexity is 46.89553856958617
At time: 492.72241473197937 and batch: 1950, loss is 3.7667665386199953 and perplexity is 43.24002360251667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.361836845930233 and perplexity of 78.40101282273356
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 495.9981927871704 and batch: 50, loss is 3.956495566368103 and perplexity is 52.2738144715101
At time: 497.0205075740814 and batch: 100, loss is 3.953899230957031 and perplexity is 52.13827015132659
At time: 498.0195825099945 and batch: 150, loss is 3.9348812913894653 and perplexity is 51.15607692939149
At time: 499.01740074157715 and batch: 200, loss is 3.93712354183197 and perplexity is 51.270910360066395
At time: 500.0157141685486 and batch: 250, loss is 3.9140289402008057 and perplexity is 50.10039740028644
At time: 501.0173156261444 and batch: 300, loss is 3.9172222423553467 and perplexity is 50.260638820717176
At time: 502.01126766204834 and batch: 350, loss is 3.9382006168365478 and perplexity is 51.32616272620694
At time: 503.02187180519104 and batch: 400, loss is 3.888226180076599 and perplexity is 48.82420432078252
At time: 504.02191519737244 and batch: 450, loss is 3.9310854864120484 and perplexity is 50.96226650395041
At time: 505.0169892311096 and batch: 500, loss is 3.9418125629425047 and perplexity is 51.5118852677913
At time: 506.02032470703125 and batch: 550, loss is 3.9290246677398684 and perplexity is 50.857350656961934
At time: 507.014799118042 and batch: 600, loss is 3.89735152721405 and perplexity is 49.271781175123586
At time: 508.00841426849365 and batch: 650, loss is 3.9237600469589236 and perplexity is 50.590309543707434
At time: 509.00232768058777 and batch: 700, loss is 3.9554940128326415 and perplexity is 52.221485657242866
At time: 510.0016791820526 and batch: 750, loss is 3.8869923400878905 and perplexity is 48.76400021382969
At time: 511.00174713134766 and batch: 800, loss is 3.891010217666626 and perplexity is 48.96032213154644
At time: 512.0306179523468 and batch: 850, loss is 3.9043322658538817 and perplexity is 49.61693792471205
At time: 513.0258672237396 and batch: 900, loss is 3.8568677568435668 and perplexity is 47.31691094397496
At time: 514.0266785621643 and batch: 950, loss is 3.9516604948043823 and perplexity is 52.021676880484065
At time: 515.0229570865631 and batch: 1000, loss is 3.9093748188018798 and perplexity is 49.86776583633721
At time: 516.0164465904236 and batch: 1050, loss is 3.8576410007476807 and perplexity is 47.35351260610626
At time: 517.0177381038666 and batch: 1100, loss is 3.874589762687683 and perplexity is 48.162936004342555
At time: 518.0128345489502 and batch: 1150, loss is 3.856573100090027 and perplexity is 47.30297075049562
At time: 519.0096850395203 and batch: 1200, loss is 3.888356132507324 and perplexity is 48.83054955709274
At time: 520.0110125541687 and batch: 1250, loss is 3.894427990913391 and perplexity is 49.12794369375808
At time: 521.005509853363 and batch: 1300, loss is 3.8719024515151976 and perplexity is 48.0336809603664
At time: 521.999359369278 and batch: 1350, loss is 3.7557762670516968 and perplexity is 42.76740585632179
At time: 522.9978189468384 and batch: 1400, loss is 3.7679680585861206 and perplexity is 43.29200857845008
At time: 523.9911336898804 and batch: 1450, loss is 3.704493646621704 and perplexity is 40.62946923842142
At time: 524.9856977462769 and batch: 1500, loss is 3.7240278005599974 and perplexity is 41.43093402794911
At time: 525.9788160324097 and batch: 1550, loss is 3.740217294692993 and perplexity is 42.10713882878748
At time: 526.9903869628906 and batch: 1600, loss is 3.8035712099075316 and perplexity is 44.861107195045136
At time: 527.9945621490479 and batch: 1650, loss is 3.760743007659912 and perplexity is 42.98034884624533
At time: 529.0067167282104 and batch: 1700, loss is 3.750450325012207 and perplexity is 42.54023461896153
At time: 530.0105748176575 and batch: 1750, loss is 3.7299429988861084 and perplexity is 41.676732476147
At time: 531.0107982158661 and batch: 1800, loss is 3.6930346584320066 and perplexity is 40.166553965962606
At time: 532.0086710453033 and batch: 1850, loss is 3.7252120304107668 and perplexity is 41.48002683961946
At time: 533.0108258724213 and batch: 1900, loss is 3.8393529558181765 and perplexity is 46.49538013946729
At time: 534.0060949325562 and batch: 1950, loss is 3.7597322511672973 and perplexity is 42.93692812717765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3446905091751455 and perplexity of 77.06818189276595
finished 13 epochs...
Completing Train Step...
At time: 537.2651710510254 and batch: 50, loss is 3.9620831966400147 and perplexity is 52.56671877808619
At time: 538.2595489025116 and batch: 100, loss is 3.940810551643372 and perplexity is 51.460295627730915
At time: 539.2559990882874 and batch: 150, loss is 3.9114147090911864 and perplexity is 49.96959443188744
At time: 540.2468521595001 and batch: 200, loss is 3.9106142377853392 and perplexity is 49.92961121022567
At time: 541.2376899719238 and batch: 250, loss is 3.8893148279190064 and perplexity is 48.87738562807898
At time: 542.2322318553925 and batch: 300, loss is 3.891811308860779 and perplexity is 48.999559528737215
At time: 543.2237694263458 and batch: 350, loss is 3.914872479438782 and perplexity is 50.14267688102524
At time: 544.2138652801514 and batch: 400, loss is 3.8635002183914184 and perplexity is 47.63178156576933
At time: 545.2030563354492 and batch: 450, loss is 3.9071229600906374 and perplexity is 49.75559701499663
At time: 546.1937510967255 and batch: 500, loss is 3.918397932052612 and perplexity is 50.31976448586383
At time: 547.1841626167297 and batch: 550, loss is 3.9065374517440796 and perplexity is 49.72647322459958
At time: 548.174813747406 and batch: 600, loss is 3.878008441925049 and perplexity is 48.327871403645375
At time: 549.1643307209015 and batch: 650, loss is 3.906434636116028 and perplexity is 49.72136082884579
At time: 550.1643528938293 and batch: 700, loss is 3.9401788759231566 and perplexity is 51.42779967296113
At time: 551.1568598747253 and batch: 750, loss is 3.87326789855957 and perplexity is 48.09931320654503
At time: 552.1465640068054 and batch: 800, loss is 3.87827278137207 and perplexity is 48.340648055060015
At time: 553.1409940719604 and batch: 850, loss is 3.8911882400512696 and perplexity is 48.96903894071577
At time: 554.144166469574 and batch: 900, loss is 3.8441066122055054 and perplexity is 46.71692936749992
At time: 555.1363761425018 and batch: 950, loss is 3.940327315330505 and perplexity is 51.43543415168055
At time: 556.1267504692078 and batch: 1000, loss is 3.8994177532196046 and perplexity is 49.3736930609644
At time: 557.1272451877594 and batch: 1050, loss is 3.847444396018982 and perplexity is 46.87312089993427
At time: 558.1248052120209 and batch: 1100, loss is 3.8658539199829103 and perplexity is 47.74402460734103
At time: 559.1182382106781 and batch: 1150, loss is 3.8485208988189696 and perplexity is 46.92360711522774
At time: 560.1259636878967 and batch: 1200, loss is 3.880369920730591 and perplexity is 48.44213150598864
At time: 561.1200611591339 and batch: 1250, loss is 3.8887965631484986 and perplexity is 48.85206076409269
At time: 562.1123943328857 and batch: 1300, loss is 3.866548843383789 and perplexity is 47.77721457820084
At time: 563.1019206047058 and batch: 1350, loss is 3.7505600166320803 and perplexity is 42.54490118214342
At time: 564.0942938327789 and batch: 1400, loss is 3.764217691421509 and perplexity is 43.1299517272816
At time: 565.1004576683044 and batch: 1450, loss is 3.7017781829833982 and perplexity is 40.51929105219217
At time: 566.0958805084229 and batch: 1500, loss is 3.7232520532608033 and perplexity is 41.398806555784866
At time: 567.0846557617188 and batch: 1550, loss is 3.7407419061660767 and perplexity is 42.129234512233545
At time: 568.0755190849304 and batch: 1600, loss is 3.805144033432007 and perplexity is 44.93172131699464
At time: 569.0672636032104 and batch: 1650, loss is 3.763069763183594 and perplexity is 43.08047004393839
At time: 570.0578966140747 and batch: 1700, loss is 3.7536470031738283 and perplexity is 42.67643964378529
At time: 571.0492565631866 and batch: 1750, loss is 3.733696846961975 and perplexity is 41.83347460717517
At time: 572.0382952690125 and batch: 1800, loss is 3.6978660917282102 and perplexity is 40.361085546957995
At time: 573.0313413143158 and batch: 1850, loss is 3.7303818750381468 and perplexity is 41.69502741443808
At time: 574.0192360877991 and batch: 1900, loss is 3.8448908281326295 and perplexity is 46.75357989666228
At time: 575.0130593776703 and batch: 1950, loss is 3.7650976514816286 and perplexity is 43.167921065497
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34308599427689 and perplexity of 76.94462399848658
finished 14 epochs...
Completing Train Step...
At time: 578.254100561142 and batch: 50, loss is 3.958480019569397 and perplexity is 52.37765240666674
At time: 579.2701606750488 and batch: 100, loss is 3.9350347900390625 and perplexity is 51.163929920815214
At time: 580.2625012397766 and batch: 150, loss is 3.9044238328933716 and perplexity is 49.621481408839884
At time: 581.2557582855225 and batch: 200, loss is 3.9023016405105593 and perplexity is 49.51628674011296
At time: 582.245551109314 and batch: 250, loss is 3.8808197021484374 and perplexity is 48.46392477731775
At time: 583.2375299930573 and batch: 300, loss is 3.882881588935852 and perplexity is 48.56395499353409
At time: 584.2296767234802 and batch: 350, loss is 3.906185007095337 and perplexity is 49.708950483290316
At time: 585.2188069820404 and batch: 400, loss is 3.854423413276672 and perplexity is 47.20139339690658
At time: 586.2122550010681 and batch: 450, loss is 3.8984744691848756 and perplexity is 49.327141603639355
At time: 587.204662322998 and batch: 500, loss is 3.909714412689209 and perplexity is 49.88470350059085
At time: 588.2260568141937 and batch: 550, loss is 3.8979408740997314 and perplexity is 49.30082790437009
At time: 589.2256026268005 and batch: 600, loss is 3.8704523229599 and perplexity is 47.964076427947184
At time: 590.2236030101776 and batch: 650, loss is 3.89894193649292 and perplexity is 49.350205820201936
At time: 591.2138392925262 and batch: 700, loss is 3.933309783935547 and perplexity is 51.07574790854321
At time: 592.2055404186249 and batch: 750, loss is 3.8669775533676147 and perplexity is 47.79770153825828
At time: 593.1955347061157 and batch: 800, loss is 3.872294659614563 and perplexity is 48.052523854007596
At time: 594.1876437664032 and batch: 850, loss is 3.88498685836792 and perplexity is 48.66630290064059
At time: 595.1823568344116 and batch: 900, loss is 3.837745485305786 and perplexity is 46.42070022589102
At time: 596.1753225326538 and batch: 950, loss is 3.9345081615448 and perplexity is 51.13699263103519
At time: 597.1682767868042 and batch: 1000, loss is 3.8942646837234496 and perplexity is 49.1199214023926
At time: 598.1580910682678 and batch: 1050, loss is 3.8423922538757322 and perplexity is 46.63690842238286
At time: 599.1514954566956 and batch: 1100, loss is 3.8615822649002074 and perplexity is 47.54051357588037
At time: 600.1405339241028 and batch: 1150, loss is 3.8446407651901247 and perplexity is 46.74189002056401
At time: 601.1309442520142 and batch: 1200, loss is 3.8765591192245483 and perplexity is 48.25787945526474
At time: 602.1211786270142 and batch: 1250, loss is 3.8858011865615847 and perplexity is 48.70594938360754
At time: 603.1120712757111 and batch: 1300, loss is 3.8638546514511107 and perplexity is 47.64866683602052
At time: 604.1003129482269 and batch: 1350, loss is 3.7477592420578003 and perplexity is 42.42590921726653
At time: 605.0903265476227 and batch: 1400, loss is 3.7619187736511233 and perplexity is 43.030913398924696
At time: 606.0779252052307 and batch: 1450, loss is 3.699896378517151 and perplexity is 40.443113367554524
At time: 607.0751204490662 and batch: 1500, loss is 3.722033953666687 and perplexity is 41.348409386939295
At time: 608.0804789066315 and batch: 1550, loss is 3.7400670051574707 and perplexity is 42.1008110419627
At time: 609.083838224411 and batch: 1600, loss is 3.8051584434509276 and perplexity is 44.93236878861399
At time: 610.0873627662659 and batch: 1650, loss is 3.763234534263611 and perplexity is 43.08756904435409
At time: 611.0920679569244 and batch: 1700, loss is 3.7542836618423463 and perplexity is 42.70361861997334
At time: 612.0927474498749 and batch: 1750, loss is 3.7346223974227906 and perplexity is 41.87221152259501
At time: 613.0926249027252 and batch: 1800, loss is 3.6990367364883423 and perplexity is 40.40836170666213
At time: 614.0919396877289 and batch: 1850, loss is 3.7316121816635133 and perplexity is 41.74635665178673
At time: 615.090301990509 and batch: 1900, loss is 3.846279673576355 and perplexity is 46.81855850525714
At time: 616.0890855789185 and batch: 1950, loss is 3.766354212760925 and perplexity is 43.222198297808134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342607081213663 and perplexity of 76.90778303542199
finished 15 epochs...
Completing Train Step...
At time: 619.4622886180878 and batch: 50, loss is 3.9543992948532103 and perplexity is 52.16434913787486
At time: 620.4568276405334 and batch: 100, loss is 3.930100026130676 and perplexity is 50.91206995187852
At time: 621.4514775276184 and batch: 150, loss is 3.898972272872925 and perplexity is 49.35170294950764
At time: 622.4471733570099 and batch: 200, loss is 3.8964295387268066 and perplexity is 49.226374095752924
At time: 623.4422392845154 and batch: 250, loss is 3.8747216176986696 and perplexity is 48.169286947491194
At time: 624.4372274875641 and batch: 300, loss is 3.876639485359192 and perplexity is 48.26175791034879
At time: 625.4341106414795 and batch: 350, loss is 3.900086760520935 and perplexity is 49.406735473691114
At time: 626.429988861084 and batch: 400, loss is 3.8480948495864866 and perplexity is 46.90361960656467
At time: 627.4262959957123 and batch: 450, loss is 3.8924422121047972 and perplexity is 49.030483263715986
At time: 628.4282298088074 and batch: 500, loss is 3.903717269897461 and perplexity is 49.586433089654946
At time: 629.4234647750854 and batch: 550, loss is 3.892063331604004 and perplexity is 49.01191008839207
At time: 630.420547246933 and batch: 600, loss is 3.865131516456604 and perplexity is 47.70954661061725
At time: 631.4213879108429 and batch: 650, loss is 3.8935707235336303 and perplexity is 49.085845957280966
At time: 632.4197056293488 and batch: 700, loss is 3.9282636928558348 and perplexity is 50.81866421201686
At time: 633.4257824420929 and batch: 750, loss is 3.8623095178604125 and perplexity is 47.5751001301707
At time: 634.4327871799469 and batch: 800, loss is 3.8678406953811644 and perplexity is 47.838975552712554
At time: 635.427921295166 and batch: 850, loss is 3.8803660583496096 and perplexity is 48.441944404382554
At time: 636.4223239421844 and batch: 900, loss is 3.832935767173767 and perplexity is 46.197965816560426
At time: 637.4169323444366 and batch: 950, loss is 3.930105113983154 and perplexity is 50.91232898563875
At time: 638.4465749263763 and batch: 1000, loss is 3.8903280448913575 and perplexity is 48.9269341222102
At time: 639.4488534927368 and batch: 1050, loss is 3.8385946369171142 and perplexity is 46.460135179044244
At time: 640.4437983036041 and batch: 1100, loss is 3.858314347267151 and perplexity is 47.385408666349726
At time: 641.4543154239655 and batch: 1150, loss is 3.8416269302368162 and perplexity is 46.60122974852898
At time: 642.4593863487244 and batch: 1200, loss is 3.873518633842468 and perplexity is 48.11137491353363
At time: 643.4636499881744 and batch: 1250, loss is 3.883257293701172 and perplexity is 48.58220413077719
At time: 644.4698259830475 and batch: 1300, loss is 3.8615474557876586 and perplexity is 47.538858761594156
At time: 645.4705865383148 and batch: 1350, loss is 3.7452706050872804 and perplexity is 42.32045780065198
At time: 646.4782328605652 and batch: 1400, loss is 3.7597335147857667 and perplexity is 42.936982383107335
At time: 647.4794239997864 and batch: 1450, loss is 3.697970356941223 and perplexity is 40.365294023535014
At time: 648.4816238880157 and batch: 1500, loss is 3.720448808670044 and perplexity is 41.28291808300007
At time: 649.4901397228241 and batch: 1550, loss is 3.7388029050827027 and perplexity is 42.04762502688197
At time: 650.4920890331268 and batch: 1600, loss is 3.8044184637069702 and perplexity is 44.89913204463767
At time: 651.51207280159 and batch: 1650, loss is 3.7625225400924682 and perplexity is 43.05690186506778
At time: 652.5216982364655 and batch: 1700, loss is 3.7539222335815428 and perplexity is 42.68818711422463
At time: 653.5313119888306 and batch: 1750, loss is 3.7344784355163574 and perplexity is 41.866183953078256
At time: 654.5313189029694 and batch: 1800, loss is 3.6989525365829468 and perplexity is 40.404959469665265
At time: 655.5319590568542 and batch: 1850, loss is 3.7315993881225586 and perplexity is 41.74582257147959
At time: 656.5325841903687 and batch: 1900, loss is 3.8464216947555543 and perplexity is 46.825208204332334
At time: 657.5339722633362 and batch: 1950, loss is 3.7663902378082277 and perplexity is 43.22375540759364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342522483648255 and perplexity of 76.90127709941339
finished 16 epochs...
Completing Train Step...
At time: 660.7769544124603 and batch: 50, loss is 3.950483913421631 and perplexity is 51.960505137790676
At time: 661.7986359596252 and batch: 100, loss is 3.9256963872909547 and perplexity is 50.6883645037364
At time: 662.7927317619324 and batch: 150, loss is 3.8942574310302733 and perplexity is 49.11956515196571
At time: 663.8148145675659 and batch: 200, loss is 3.8915269136428834 and perplexity is 48.98562626969829
At time: 664.810396194458 and batch: 250, loss is 3.8696457815170286 and perplexity is 47.92540700887976
At time: 665.8058257102966 and batch: 300, loss is 3.871506304740906 and perplexity is 48.014656341116165
At time: 666.8004131317139 and batch: 350, loss is 3.895038504600525 and perplexity is 49.15794613332196
At time: 667.7944157123566 and batch: 400, loss is 3.842867727279663 and perplexity is 46.65908830453344
At time: 668.7881000041962 and batch: 450, loss is 3.88748095035553 and perplexity is 48.78783262693206
At time: 669.7855203151703 and batch: 500, loss is 3.898805031776428 and perplexity is 49.34345000672722
At time: 670.7829377651215 and batch: 550, loss is 3.8872788763046264 and perplexity is 48.77797486799052
At time: 671.7988033294678 and batch: 600, loss is 3.86072612285614 and perplexity is 47.499829561544146
At time: 672.8002076148987 and batch: 650, loss is 3.889115252494812 and perplexity is 48.867631876445685
At time: 673.8045766353607 and batch: 700, loss is 3.9240163803100585 and perplexity is 50.603279189493094
At time: 674.8002572059631 and batch: 750, loss is 3.8583469009399414 and perplexity is 47.3869512605469
At time: 675.7964193820953 and batch: 800, loss is 3.8640553188323974 and perplexity is 47.65822932862439
At time: 676.7925298213959 and batch: 850, loss is 3.876448211669922 and perplexity is 48.252527588649606
At time: 677.7885992527008 and batch: 900, loss is 3.828840136528015 and perplexity is 46.009142950295384
At time: 678.7875790596008 and batch: 950, loss is 3.9263509130477905 and perplexity is 50.721552203793415
At time: 679.7871477603912 and batch: 1000, loss is 3.8869264698028565 and perplexity is 48.760788221024804
At time: 680.7836663722992 and batch: 1050, loss is 3.8353254890441892 and perplexity is 46.30849812397543
At time: 681.7784461975098 and batch: 1100, loss is 3.8554627227783205 and perplexity is 47.25047575501752
At time: 682.7835841178894 and batch: 1150, loss is 3.8389635372161863 and perplexity is 46.477277498515704
At time: 683.7870571613312 and batch: 1200, loss is 3.8707865333557128 and perplexity is 47.980109199925266
At time: 684.7837405204773 and batch: 1250, loss is 3.8808846282958984 and perplexity is 48.46707145539412
At time: 685.7799718379974 and batch: 1300, loss is 3.8593586826324464 and perplexity is 47.434920773541265
At time: 686.7776188850403 and batch: 1350, loss is 3.7428811836242675 and perplexity is 42.2194571051273
At time: 687.7697412967682 and batch: 1400, loss is 3.7575777435302733 and perplexity is 42.84451977061815
At time: 688.7625448703766 and batch: 1450, loss is 3.695998511314392 and perplexity is 40.28577831715216
At time: 689.7553091049194 and batch: 1500, loss is 3.7186761331558227 and perplexity is 41.209801689925186
At time: 690.7484986782074 and batch: 1550, loss is 3.7372399520874025 and perplexity is 41.981957896088076
At time: 691.7405726909637 and batch: 1600, loss is 3.803296127319336 and perplexity is 44.84876838274262
At time: 692.7335739135742 and batch: 1650, loss is 3.761417932510376 and perplexity is 43.00936714324661
At time: 693.729376077652 and batch: 1700, loss is 3.7531049346923826 and perplexity is 42.653312359806236
At time: 694.7377083301544 and batch: 1750, loss is 3.7338416147232056 and perplexity is 41.83953118402651
At time: 695.7414457798004 and batch: 1800, loss is 3.6983056974411013 and perplexity is 40.37883241126858
At time: 696.7450103759766 and batch: 1850, loss is 3.7310657405853274 and perplexity is 41.7235509591987
At time: 697.7493319511414 and batch: 1900, loss is 3.8460389280319216 and perplexity is 46.8072885025561
At time: 698.7539041042328 and batch: 1950, loss is 3.7659188652038575 and perplexity is 43.20338571467127
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.342613326671511 and perplexity of 76.9082633612391
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 702.1939799785614 and batch: 50, loss is 3.952681474685669 and perplexity is 52.07481708889557
At time: 703.2059462070465 and batch: 100, loss is 3.9353786516189575 and perplexity is 51.1815262557698
At time: 704.214136838913 and batch: 150, loss is 3.9079317903518676 and perplexity is 49.79585712713157
At time: 705.2166175842285 and batch: 200, loss is 3.9051413917541504 and perplexity is 49.657100520385995
At time: 706.221134185791 and batch: 250, loss is 3.8867852544784545 and perplexity is 48.75390293666335
At time: 707.2253499031067 and batch: 300, loss is 3.8853477907180785 and perplexity is 48.68387131403369
At time: 708.2283906936646 and batch: 350, loss is 3.9096495008468626 and perplexity is 49.88146549767522
At time: 709.2315647602081 and batch: 400, loss is 3.859423818588257 and perplexity is 47.43801059307272
At time: 710.240558385849 and batch: 450, loss is 3.905540361404419 and perplexity is 49.67691614906834
At time: 711.2501859664917 and batch: 500, loss is 3.9156274509429934 and perplexity is 50.18054746702313
At time: 712.2641952037811 and batch: 550, loss is 3.904950680732727 and perplexity is 49.64763126699902
At time: 713.2711932659149 and batch: 600, loss is 3.8793520021438597 and perplexity is 48.39284644829156
At time: 714.2753953933716 and batch: 650, loss is 3.9071689319610594 and perplexity is 49.75788442543324
At time: 715.3200724124908 and batch: 700, loss is 3.9400648307800292 and perplexity is 51.42193491661654
At time: 716.3234457969666 and batch: 750, loss is 3.87402214050293 and perplexity is 48.135605410843056
At time: 717.3304107189178 and batch: 800, loss is 3.8761702966690064 and perplexity is 48.239119350662165
At time: 718.339025259018 and batch: 850, loss is 3.88929949760437 and perplexity is 48.87663632812222
At time: 719.3483879566193 and batch: 900, loss is 3.8354419040679932 and perplexity is 46.31388944269602
At time: 720.3556473255157 and batch: 950, loss is 3.9320661067962646 and perplexity is 51.012265652395456
At time: 721.358610868454 and batch: 1000, loss is 3.8945759916305542 and perplexity is 49.13521520273849
At time: 722.3618378639221 and batch: 1050, loss is 3.8441345739364623 and perplexity is 46.71823567197321
At time: 723.3649482727051 and batch: 1100, loss is 3.8603461027145385 and perplexity is 47.481782099004946
At time: 724.3735506534576 and batch: 1150, loss is 3.8446704053878786 and perplexity is 46.743275479960154
At time: 725.3858425617218 and batch: 1200, loss is 3.8803877305984495 and perplexity is 48.44299426163232
At time: 726.392404794693 and batch: 1250, loss is 3.888682279586792 and perplexity is 48.84647809560156
At time: 727.3876242637634 and batch: 1300, loss is 3.8688995838165283 and perplexity is 47.88965851975315
At time: 728.3809084892273 and batch: 1350, loss is 3.7525257062911987 and perplexity is 42.628613503712884
At time: 729.3753454685211 and batch: 1400, loss is 3.764269723892212 and perplexity is 43.13219594361683
At time: 730.3664162158966 and batch: 1450, loss is 3.6970682954788208 and perplexity is 40.32889846536103
At time: 731.360589504242 and batch: 1500, loss is 3.7147873067855834 and perplexity is 41.049855130172986
At time: 732.3539726734161 and batch: 1550, loss is 3.7354507350921633 and perplexity is 41.90691022183492
At time: 733.3487100601196 and batch: 1600, loss is 3.7994075345993044 and perplexity is 44.67470843196803
At time: 734.3439705371857 and batch: 1650, loss is 3.7544256019592286 and perplexity is 42.709680406786745
At time: 735.3402879238129 and batch: 1700, loss is 3.7451592588424685 and perplexity is 42.31574583893165
At time: 736.3364119529724 and batch: 1750, loss is 3.7261448192596434 and perplexity is 41.51873699750157
At time: 737.3359282016754 and batch: 1800, loss is 3.6904807615280153 and perplexity is 40.06410360765647
At time: 738.3359949588776 and batch: 1850, loss is 3.7222674083709717 and perplexity is 41.35806349447992
At time: 739.3445250988007 and batch: 1900, loss is 3.836701683998108 and perplexity is 46.3722715176634
At time: 740.3438284397125 and batch: 1950, loss is 3.7607050371170043 and perplexity is 42.9787168900486
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336169149709303 and perplexity of 76.4142463783162
finished 18 epochs...
Completing Train Step...
At time: 743.5920386314392 and batch: 50, loss is 3.954728198051453 and perplexity is 52.18150898094949
At time: 744.6157009601593 and batch: 100, loss is 3.9310803031921386 and perplexity is 50.962002356000596
At time: 745.6127355098724 and batch: 150, loss is 3.9002996492385864 and perplexity is 49.417254729925205
At time: 746.613287448883 and batch: 200, loss is 3.8958570528030396 and perplexity is 49.198200754695065
At time: 747.6081149578094 and batch: 250, loss is 3.8771934652328492 and perplexity is 48.28850135988089
At time: 748.6037185192108 and batch: 300, loss is 3.8774327993392945 and perplexity is 48.300059828318126
At time: 749.6057977676392 and batch: 350, loss is 3.902963786125183 and perplexity is 49.54908458950813
At time: 750.6016299724579 and batch: 400, loss is 3.8516018104553225 and perplexity is 47.06839753111787
At time: 751.5991642475128 and batch: 450, loss is 3.8978515386581423 and perplexity is 49.296423789863226
At time: 752.5989606380463 and batch: 500, loss is 3.908083086013794 and perplexity is 49.80339159424853
At time: 753.5930342674255 and batch: 550, loss is 3.896839208602905 and perplexity is 49.24654478971025
At time: 754.5878469944 and batch: 600, loss is 3.8705868530273437 and perplexity is 47.97052947243844
At time: 755.5835087299347 and batch: 650, loss is 3.8983731031417848 and perplexity is 49.32214175988948
At time: 756.578551530838 and batch: 700, loss is 3.9321489095687867 and perplexity is 51.016489784306614
At time: 757.5747129917145 and batch: 750, loss is 3.866660442352295 and perplexity is 47.78254676359351
At time: 758.5881984233856 and batch: 800, loss is 3.8695921325683593 and perplexity is 47.922835930147635
At time: 759.5894513130188 and batch: 850, loss is 3.8826760959625246 and perplexity is 48.55397646731956
At time: 760.5938985347748 and batch: 900, loss is 3.8311204862594606 and perplexity is 46.1141796017002
At time: 761.5882370471954 and batch: 950, loss is 3.9283753633499146 and perplexity is 50.824339474231664
At time: 762.5829808712006 and batch: 1000, loss is 3.8900626277923585 and perplexity is 48.91394980049929
At time: 763.5768926143646 and batch: 1050, loss is 3.839683589935303 and perplexity is 46.510755640122625
At time: 764.5727074146271 and batch: 1100, loss is 3.8561198234558107 and perplexity is 47.28153427781852
At time: 765.5971512794495 and batch: 1150, loss is 3.8406178951263428 and perplexity is 46.55423118710842
At time: 766.5976071357727 and batch: 1200, loss is 3.876044363975525 and perplexity is 48.23304485092826
At time: 767.6018912792206 and batch: 1250, loss is 3.8849977159500124 and perplexity is 48.666831301888045
At time: 768.6102261543274 and batch: 1300, loss is 3.864996943473816 and perplexity is 47.703126626610285
At time: 769.6203155517578 and batch: 1350, loss is 3.7491689586639403 and perplexity is 42.48575990236125
At time: 770.6282782554626 and batch: 1400, loss is 3.7624150371551512 and perplexity is 43.05227337043836
At time: 771.6385762691498 and batch: 1450, loss is 3.696658420562744 and perplexity is 40.312372048600274
At time: 772.6508820056915 and batch: 1500, loss is 3.715980062484741 and perplexity is 41.09884679056193
At time: 773.6567623615265 and batch: 1550, loss is 3.73742112159729 and perplexity is 41.98956443583996
At time: 774.6662983894348 and batch: 1600, loss is 3.801484808921814 and perplexity is 44.76760651065096
At time: 775.6729135513306 and batch: 1650, loss is 3.757031626701355 and perplexity is 42.821128045233294
At time: 776.6850302219391 and batch: 1700, loss is 3.7486098289489744 and perplexity is 42.46201149137677
At time: 777.6947700977325 and batch: 1750, loss is 3.730342321395874 and perplexity is 41.69337825685449
At time: 778.7011413574219 and batch: 1800, loss is 3.694543409347534 and perplexity is 40.22720103018478
At time: 779.705894947052 and batch: 1850, loss is 3.7268900537490843 and perplexity is 41.54968972435741
At time: 780.7114458084106 and batch: 1900, loss is 3.8410607385635376 and perplexity is 46.574851988419546
At time: 781.7163331508636 and batch: 1950, loss is 3.76429847240448 and perplexity is 43.13343594790512
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334942201126453 and perplexity of 76.32054752060768
finished 19 epochs...
Completing Train Step...
At time: 785.0134286880493 and batch: 50, loss is 3.954227089881897 and perplexity is 52.15536695103881
At time: 786.0272822380066 and batch: 100, loss is 3.928933801651001 and perplexity is 50.85272965836679
At time: 787.0312376022339 and batch: 150, loss is 3.8973420238494874 and perplexity is 49.271312929649376
At time: 788.0317058563232 and batch: 200, loss is 3.8921503591537476 and perplexity is 49.016175660443764
At time: 789.0290291309357 and batch: 250, loss is 3.873371024131775 and perplexity is 48.1042737315162
At time: 790.0283794403076 and batch: 300, loss is 3.8736114406585695 and perplexity is 48.1158401842582
At time: 791.028069972992 and batch: 350, loss is 3.89923171043396 and perplexity is 49.3645082959759
At time: 792.0606606006622 and batch: 400, loss is 3.8475257349014282 and perplexity is 46.87693366226585
At time: 793.0586230754852 and batch: 450, loss is 3.8939009857177735 and perplexity is 49.10205983324501
At time: 794.056485414505 and batch: 500, loss is 3.9043766927719115 and perplexity is 49.61914230131258
At time: 795.0549457073212 and batch: 550, loss is 3.8928860425949097 and perplexity is 49.05224931699512
At time: 796.0539455413818 and batch: 600, loss is 3.8668690967559813 and perplexity is 47.79251784261369
At time: 797.0527188777924 and batch: 650, loss is 3.8947577476501465 and perplexity is 49.1441466355218
At time: 798.0533485412598 and batch: 700, loss is 3.929059133529663 and perplexity is 50.85910352592602
At time: 799.053573846817 and batch: 750, loss is 3.863807687759399 and perplexity is 47.646429131266615
At time: 800.0523810386658 and batch: 800, loss is 3.867093358039856 and perplexity is 47.80323705593203
At time: 801.0499501228333 and batch: 850, loss is 3.8800184297561646 and perplexity is 48.42510752604524
At time: 802.0492510795593 and batch: 900, loss is 3.8291879796981814 and perplexity is 46.025149700193765
At time: 803.047384262085 and batch: 950, loss is 3.9265791749954224 and perplexity is 50.733131325572536
At time: 804.0453922748566 and batch: 1000, loss is 3.888247947692871 and perplexity is 48.82526711889422
At time: 805.0444958209991 and batch: 1050, loss is 3.8376930236816404 and perplexity is 46.418264984442104
At time: 806.0559718608856 and batch: 1100, loss is 3.8543950510025025 and perplexity is 47.20005467703053
At time: 807.0588579177856 and batch: 1150, loss is 3.839050016403198 and perplexity is 46.48129698948696
At time: 808.0584337711334 and batch: 1200, loss is 3.87422833442688 and perplexity is 48.14553170353988
At time: 809.0580863952637 and batch: 1250, loss is 3.8837205839157103 and perplexity is 48.60471700514621
At time: 810.0608417987823 and batch: 1300, loss is 3.8637573385238646 and perplexity is 47.64403023037582
At time: 811.0659868717194 and batch: 1350, loss is 3.7481107616424563 and perplexity is 42.440825376760735
At time: 812.0649781227112 and batch: 1400, loss is 3.7619556856155394 and perplexity is 43.03250178378389
At time: 813.0613739490509 and batch: 1450, loss is 3.696640787124634 and perplexity is 40.311661209149975
At time: 814.0599308013916 and batch: 1500, loss is 3.7165978240966795 and perplexity is 41.12424392428352
At time: 815.0589730739594 and batch: 1550, loss is 3.738313274383545 and perplexity is 42.02704225823104
At time: 816.057585477829 and batch: 1600, loss is 3.802487998008728 and perplexity is 44.81253941928316
At time: 817.0572581291199 and batch: 1650, loss is 3.758186001777649 and perplexity is 42.8705882304976
At time: 818.056421995163 and batch: 1700, loss is 3.74992458820343 and perplexity is 42.51787552978142
At time: 819.0610973834991 and batch: 1750, loss is 3.7319731950759887 and perplexity is 41.76143036720301
At time: 820.0601811408997 and batch: 1800, loss is 3.6961653089523314 and perplexity is 40.29249845025359
At time: 821.0685353279114 and batch: 1850, loss is 3.7286975526809694 and perplexity is 41.62485865757252
At time: 822.0679368972778 and batch: 1900, loss is 3.842578158378601 and perplexity is 46.64557923960547
At time: 823.066602230072 and batch: 1950, loss is 3.76545437335968 and perplexity is 43.183322754267415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334440009538517 and perplexity of 76.28222960592869
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f4a57130b38>
ELAPSED
3401.2754287719727


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.78177940258892}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.6888560527046866, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6228089196258255, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.04378796834526}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.14308718722040714, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.37386466100496807, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.54586144587961}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.31025574538464784, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6931579404631784, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.28222960592869}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.7280101718420305, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.21880679215341725, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.55792236328125 and batch: 50, loss is 7.546835670471191 and perplexity is 1894.7376610095373
At time: 2.5603103637695312 and batch: 100, loss is 6.7120905780792235 and perplexity is 822.2879008509949
At time: 3.562098503112793 and batch: 150, loss is 6.471381998062133 and perplexity is 646.3764009196259
At time: 4.564934253692627 and batch: 200, loss is 6.380390510559082 and perplexity is 590.1581256448047
At time: 5.574748754501343 and batch: 250, loss is 6.330840225219727 and perplexity is 561.6282899130741
At time: 6.5791237354278564 and batch: 300, loss is 6.26277153968811 and perplexity is 524.6710735592886
At time: 7.573009014129639 and batch: 350, loss is 6.214505968093872 and perplexity is 499.9489374434022
At time: 8.571778059005737 and batch: 400, loss is 6.169778575897217 and perplexity is 478.0802358812972
At time: 9.575006008148193 and batch: 450, loss is 6.080675630569458 and perplexity is 437.3245647713717
At time: 10.577481269836426 and batch: 500, loss is 6.072736082077026 and perplexity is 433.8661524656862
At time: 11.628180980682373 and batch: 550, loss is 6.031380949020385 and perplexity is 416.2895072155762
At time: 12.63264799118042 and batch: 600, loss is 6.065390253067017 and perplexity is 430.69072325560046
At time: 13.638154745101929 and batch: 650, loss is 6.141865797042847 and perplexity is 464.9202088734185
At time: 14.64683747291565 and batch: 700, loss is 6.041938514709472 and perplexity is 420.70779316651846
At time: 15.642327785491943 and batch: 750, loss is 5.974028491973877 and perplexity is 393.0860292958213
At time: 16.633764505386353 and batch: 800, loss is 5.989828443527221 and perplexity is 399.3460936428286
At time: 17.627131462097168 and batch: 850, loss is 6.023457002639771 and perplexity is 413.00388621560273
At time: 18.620410680770874 and batch: 900, loss is 6.00340573310852 and perplexity is 404.8051066389655
At time: 19.6147882938385 and batch: 950, loss is 6.0210158729553225 and perplexity is 411.99691973710264
At time: 20.610179662704468 and batch: 1000, loss is 6.000140075683594 and perplexity is 403.48530801482775
At time: 21.603891849517822 and batch: 1050, loss is 5.905212049484253 and perplexity is 366.94502804215665
At time: 22.597877979278564 and batch: 1100, loss is 5.984360008239746 and perplexity is 397.1682554830893
At time: 23.5925612449646 and batch: 1150, loss is 5.889675054550171 and perplexity is 361.28786644782843
At time: 24.5910062789917 and batch: 1200, loss is 5.972914247512818 and perplexity is 392.64827929050824
At time: 25.599310636520386 and batch: 1250, loss is 5.903685569763184 and perplexity is 366.3853211973602
At time: 26.605802536010742 and batch: 1300, loss is 5.92395173072815 and perplexity is 373.8862963469156
At time: 27.609988927841187 and batch: 1350, loss is 5.895661201477051 and perplexity is 363.45707482169877
At time: 28.612380981445312 and batch: 1400, loss is 5.913680057525635 and perplexity is 370.06551499793096
At time: 29.61294412612915 and batch: 1450, loss is 5.892300786972046 and perplexity is 362.2377582474884
At time: 30.614293098449707 and batch: 1500, loss is 5.861187763214112 and perplexity is 351.1409687520188
At time: 31.61484384536743 and batch: 1550, loss is 5.8403763103485105 and perplexity is 343.90873273272297
At time: 32.61799693107605 and batch: 1600, loss is 5.849168748855591 and perplexity is 346.9458614350893
At time: 33.62276268005371 and batch: 1650, loss is 5.843094158172607 and perplexity is 344.84469565993163
At time: 34.62817406654358 and batch: 1700, loss is 5.86818528175354 and perplexity is 353.6067011335786
At time: 35.630439043045044 and batch: 1750, loss is 5.862474994659424 and perplexity is 351.59325948771004
At time: 36.63277292251587 and batch: 1800, loss is 5.878488168716431 and perplexity is 357.2687032081508
At time: 37.64241123199463 and batch: 1850, loss is 5.830387535095215 and perplexity is 340.49060556627234
At time: 38.647735357284546 and batch: 1900, loss is 5.826624593734741 and perplexity is 339.2117669900203
At time: 39.64839696884155 and batch: 1950, loss is 5.765163812637329 and perplexity is 318.9912945617295
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.188343136809593 and perplexity of 179.17144429479455
finished 1 epochs...
Completing Train Step...
At time: 42.99789643287659 and batch: 50, loss is 5.458358869552613 and perplexity is 234.71191524591177
At time: 44.023887634277344 and batch: 100, loss is 5.355799474716187 and perplexity is 211.8332640119005
At time: 45.01525259017944 and batch: 150, loss is 5.248674764633178 and perplexity is 190.31389056693587
At time: 46.044602394104004 and batch: 200, loss is 5.193936214447022 and perplexity is 180.1763717921816
At time: 47.03975439071655 and batch: 250, loss is 5.209545822143554 and perplexity is 183.01091980807584
At time: 48.02999687194824 and batch: 300, loss is 5.210098438262939 and perplexity is 183.11208254188946
At time: 49.021424293518066 and batch: 350, loss is 5.187072477340698 and perplexity is 178.94392298421224
At time: 50.011799573898315 and batch: 400, loss is 5.131954975128174 and perplexity is 169.3478655030868
At time: 51.001338958740234 and batch: 450, loss is 5.0873451423645015 and perplexity is 161.95931186590153
At time: 51.99386692047119 and batch: 500, loss is 5.078413009643555 and perplexity is 160.51911140304105
At time: 52.98648524284363 and batch: 550, loss is 5.044138412475586 and perplexity is 155.1106002518774
At time: 53.97795248031616 and batch: 600, loss is 5.019515542984009 and perplexity is 151.337969290771
At time: 54.96376848220825 and batch: 650, loss is 5.087320137023926 and perplexity is 161.95526206878236
At time: 55.95046544075012 and batch: 700, loss is 5.080125198364258 and perplexity is 160.79418583751425
At time: 56.94065761566162 and batch: 750, loss is 5.015158395767212 and perplexity is 150.68000195030731
At time: 57.92956733703613 and batch: 800, loss is 5.015355777740479 and perplexity is 150.70974640183672
At time: 58.91789507865906 and batch: 850, loss is 5.018394975662232 and perplexity is 151.1684798877181
At time: 59.911017417907715 and batch: 900, loss is 5.015357627868652 and perplexity is 150.7100252344425
At time: 60.90712356567383 and batch: 950, loss is 5.056109094619751 and perplexity is 156.97853788270086
At time: 61.90165734291077 and batch: 1000, loss is 5.024697742462158 and perplexity is 152.12426845613223
At time: 62.89723825454712 and batch: 1050, loss is 4.937489995956421 and perplexity is 139.41986558498738
At time: 63.892213106155396 and batch: 1100, loss is 5.002080869674683 and perplexity is 148.7223090835351
At time: 64.88740754127502 and batch: 1150, loss is 4.924608316421509 and perplexity is 137.6354215493008
At time: 65.8852915763855 and batch: 1200, loss is 4.99703577041626 and perplexity is 147.9738798097358
At time: 66.87988924980164 and batch: 1250, loss is 4.961732950210571 and perplexity is 142.84111808223665
At time: 67.8762104511261 and batch: 1300, loss is 4.970927391052246 and perplexity is 144.1605185721629
At time: 68.88753485679626 and batch: 1350, loss is 4.882262258529663 and perplexity is 131.92878356271873
At time: 69.89072275161743 and batch: 1400, loss is 4.880388059616089 and perplexity is 131.68175434315376
At time: 70.88734745979309 and batch: 1450, loss is 4.838820142745972 and perplexity is 126.32022394011575
At time: 71.8892834186554 and batch: 1500, loss is 4.814966535568237 and perplexity is 123.34268464826009
At time: 72.88338994979858 and batch: 1550, loss is 4.81142894744873 and perplexity is 122.90711991098085
At time: 73.87850999832153 and batch: 1600, loss is 4.864056015014649 and perplexity is 129.54858894993052
At time: 74.87358212471008 and batch: 1650, loss is 4.839968500137329 and perplexity is 126.46536802564655
At time: 75.86900782585144 and batch: 1700, loss is 4.848158826828003 and perplexity is 127.50541404920958
At time: 76.8639235496521 and batch: 1750, loss is 4.847342433929444 and perplexity is 127.4013620141024
At time: 77.8600492477417 and batch: 1800, loss is 4.8000289154052735 and perplexity is 121.51393109250036
At time: 78.85587644577026 and batch: 1850, loss is 4.811382808685303 and perplexity is 122.90144925927115
At time: 79.853933095932 and batch: 1900, loss is 4.914643850326538 and perplexity is 136.2707683693927
At time: 80.84871220588684 and batch: 1950, loss is 4.826240968704224 and perplexity is 124.7411722629115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.643605786700581 and perplexity of 103.91838035065128
finished 2 epochs...
Completing Train Step...
At time: 84.23907899856567 and batch: 50, loss is 4.783335008621216 and perplexity is 119.50222717208734
At time: 85.23401832580566 and batch: 100, loss is 4.730424489974975 and perplexity is 113.34366538799274
At time: 86.23337197303772 and batch: 150, loss is 4.663654985427857 and perplexity is 106.02288694993167
At time: 87.22746157646179 and batch: 200, loss is 4.647363386154175 and perplexity is 104.30959856022172
At time: 88.22206091880798 and batch: 250, loss is 4.65469274520874 and perplexity is 105.07692964838584
At time: 89.21737337112427 and batch: 300, loss is 4.678715534210205 and perplexity is 107.63173446432161
At time: 90.21379208564758 and batch: 350, loss is 4.68397274017334 and perplexity is 108.19906664496145
At time: 91.20920395851135 and batch: 400, loss is 4.626151714324951 and perplexity is 102.12031881420202
At time: 92.2043228149414 and batch: 450, loss is 4.623932886123657 and perplexity is 101.89398256437714
At time: 93.19940710067749 and batch: 500, loss is 4.637407503128052 and perplexity is 103.27625684841327
At time: 94.19513845443726 and batch: 550, loss is 4.6025682544708255 and perplexity is 99.74014505725864
At time: 95.18991541862488 and batch: 600, loss is 4.579979639053345 and perplexity is 97.51240874188852
At time: 96.2110481262207 and batch: 650, loss is 4.643273134231567 and perplexity is 103.88381739389685
At time: 97.20293426513672 and batch: 700, loss is 4.66558874130249 and perplexity is 106.22810768987202
At time: 98.2004382610321 and batch: 750, loss is 4.611188173294067 and perplexity is 100.6036131771043
At time: 99.19341254234314 and batch: 800, loss is 4.617391872406006 and perplexity is 101.22966764173842
At time: 100.19091582298279 and batch: 850, loss is 4.618516473770142 and perplexity is 101.34357470207196
At time: 101.18763184547424 and batch: 900, loss is 4.590881643295288 and perplexity is 98.58130540678304
At time: 102.18651556968689 and batch: 950, loss is 4.653431606292725 and perplexity is 104.94449656903853
At time: 103.18407797813416 and batch: 1000, loss is 4.628408212661743 and perplexity is 102.3510133267636
At time: 104.18098711967468 and batch: 1050, loss is 4.561453142166138 and perplexity is 95.7224771819909
At time: 105.17589616775513 and batch: 1100, loss is 4.609116735458374 and perplexity is 100.39543473515104
At time: 106.17128825187683 and batch: 1150, loss is 4.564011850357056 and perplexity is 95.96771668277279
At time: 107.16603541374207 and batch: 1200, loss is 4.633336715698242 and perplexity is 102.85669571172721
At time: 108.15989947319031 and batch: 1250, loss is 4.622996244430542 and perplexity is 101.79858909375477
At time: 109.15521383285522 and batch: 1300, loss is 4.615090398788452 and perplexity is 100.99695812247442
At time: 110.15046048164368 and batch: 1350, loss is 4.509170703887939 and perplexity is 90.84644865622036
At time: 111.14686632156372 and batch: 1400, loss is 4.512807970046997 and perplexity is 91.17748303470219
At time: 112.14236187934875 and batch: 1450, loss is 4.472796478271484 and perplexity is 87.60135608732885
At time: 113.13777804374695 and batch: 1500, loss is 4.463252286911011 and perplexity is 86.76924919160236
At time: 114.13371324539185 and batch: 1550, loss is 4.466560974121093 and perplexity is 87.05681697020309
At time: 115.14508438110352 and batch: 1600, loss is 4.536414031982422 and perplexity is 93.3554295801004
At time: 116.1497392654419 and batch: 1650, loss is 4.507569408416748 and perplexity is 90.70109305910245
At time: 117.14501547813416 and batch: 1700, loss is 4.507433929443359 and perplexity is 90.68880580048099
At time: 118.13740086555481 and batch: 1750, loss is 4.509989547729492 and perplexity is 90.92086817605399
At time: 119.13219666481018 and batch: 1800, loss is 4.465969514846802 and perplexity is 87.00534163269926
At time: 120.13087630271912 and batch: 1850, loss is 4.496179885864258 and perplexity is 89.67391157144259
At time: 121.13234043121338 and batch: 1900, loss is 4.611039657592773 and perplexity is 100.58867307038821
At time: 122.13295650482178 and batch: 1950, loss is 4.529148597717285 and perplexity is 92.67961984160985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.515766374454942 and perplexity of 91.44762229598298
finished 3 epochs...
Completing Train Step...
At time: 125.40032863616943 and batch: 50, loss is 4.502671747207642 and perplexity is 90.25795588766788
At time: 126.42217993736267 and batch: 100, loss is 4.459427480697632 and perplexity is 86.43800749961993
At time: 127.41855692863464 and batch: 150, loss is 4.399657154083252 and perplexity is 81.42294835368662
At time: 128.41394305229187 and batch: 200, loss is 4.397552852630615 and perplexity is 81.25179007265628
At time: 129.40868282318115 and batch: 250, loss is 4.391776552200318 and perplexity is 80.78380822577792
At time: 130.403475522995 and batch: 300, loss is 4.417265996932984 and perplexity is 82.86941013940864
At time: 131.39954566955566 and batch: 350, loss is 4.4259303760528566 and perplexity is 83.59054169352555
At time: 132.39581656455994 and batch: 400, loss is 4.369187316894531 and perplexity is 78.97942037075242
At time: 133.38998365402222 and batch: 450, loss is 4.3869397258758545 and perplexity is 80.39401441796805
At time: 134.38436675071716 and batch: 500, loss is 4.406972723007202 and perplexity is 82.02078764539246
At time: 135.37823867797852 and batch: 550, loss is 4.364515266418457 and perplexity is 78.61128517495696
At time: 136.37444806098938 and batch: 600, loss is 4.3508640384674075 and perplexity is 77.54543622721184
At time: 137.3692810535431 and batch: 650, loss is 4.4120730209350585 and perplexity is 82.4401867196227
At time: 138.3652982711792 and batch: 700, loss is 4.433250494003296 and perplexity is 84.20467935599342
At time: 139.35904145240784 and batch: 750, loss is 4.38992980003357 and perplexity is 80.63475822446641
At time: 140.35396766662598 and batch: 800, loss is 4.39765193939209 and perplexity is 81.25984144828439
At time: 141.34808373451233 and batch: 850, loss is 4.39265477180481 and perplexity is 80.85478531205976
At time: 142.3404884338379 and batch: 900, loss is 4.360746908187866 and perplexity is 78.31560715170532
At time: 143.33518481254578 and batch: 950, loss is 4.4316424369812015 and perplexity is 84.06938224195375
At time: 144.3295862674713 and batch: 1000, loss is 4.410045251846314 and perplexity is 82.27318643355457
At time: 145.32355618476868 and batch: 1050, loss is 4.353828964233398 and perplexity is 77.77569386884537
At time: 146.35025596618652 and batch: 1100, loss is 4.3936066055297855 and perplexity is 80.93178226187906
At time: 147.3456482887268 and batch: 1150, loss is 4.362066717147827 and perplexity is 78.41903703055566
At time: 148.3443672657013 and batch: 1200, loss is 4.424284524917603 and perplexity is 83.4530772596107
At time: 149.34684443473816 and batch: 1250, loss is 4.424618091583252 and perplexity is 83.48091906762171
At time: 150.3407392501831 and batch: 1300, loss is 4.4078232860565185 and perplexity is 82.09058117433013
At time: 151.33848309516907 and batch: 1350, loss is 4.299357767105103 and perplexity is 73.65247646370385
At time: 152.34111833572388 and batch: 1400, loss is 4.312155771255493 and perplexity is 74.60113870650564
At time: 153.33460545539856 and batch: 1450, loss is 4.266735677719116 and perplexity is 71.28854659632671
At time: 154.32905101776123 and batch: 1500, loss is 4.259601893424988 and perplexity is 70.78179914483863
At time: 155.32517528533936 and batch: 1550, loss is 4.274546175003052 and perplexity is 71.8475257066501
At time: 156.3189413547516 and batch: 1600, loss is 4.3462803840637205 and perplexity is 77.19080811421024
At time: 157.314222574234 and batch: 1650, loss is 4.3155490493774415 and perplexity is 74.85471109586167
At time: 158.30869817733765 and batch: 1700, loss is 4.315610513687134 and perplexity is 74.85931213040467
At time: 159.3034393787384 and batch: 1750, loss is 4.317060298919678 and perplexity is 74.9679207662244
At time: 160.29739141464233 and batch: 1800, loss is 4.269965791702271 and perplexity is 71.51918902766099
At time: 161.29139161109924 and batch: 1850, loss is 4.313870105743408 and perplexity is 74.72913969833638
At time: 162.28583025932312 and batch: 1900, loss is 4.420629301071167 and perplexity is 83.14859439707054
At time: 163.28019309043884 and batch: 1950, loss is 4.345297145843506 and perplexity is 77.11494846158949
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.463267907430959 and perplexity of 86.77060458297615
finished 4 epochs...
Completing Train Step...
At time: 166.55803656578064 and batch: 50, loss is 4.327200331687927 and perplexity is 75.73196511011088
At time: 167.57985138893127 and batch: 100, loss is 4.287238388061524 and perplexity is 72.76524141256694
At time: 168.57356595993042 and batch: 150, loss is 4.232384853363037 and perplexity is 68.8813082670406
At time: 169.56896543502808 and batch: 200, loss is 4.2334936904907225 and perplexity is 68.95772878017175
At time: 170.56373620033264 and batch: 250, loss is 4.225499744415283 and perplexity is 68.40868186435418
At time: 171.58644676208496 and batch: 300, loss is 4.251383743286133 and perplexity is 70.20248738832322
At time: 172.58229970932007 and batch: 350, loss is 4.259677314758301 and perplexity is 70.78713780382628
At time: 173.58118343353271 and batch: 400, loss is 4.206184368133545 and perplexity is 67.10002175086504
At time: 174.57751941680908 and batch: 450, loss is 4.234825201034546 and perplexity is 69.04960787854027
At time: 175.57294297218323 and batch: 500, loss is 4.258649654388428 and perplexity is 70.71443003345445
At time: 176.56706929206848 and batch: 550, loss is 4.211429195404053 and perplexity is 67.45287429124721
At time: 177.56092309951782 and batch: 600, loss is 4.203396549224854 and perplexity is 66.91321954779583
At time: 178.55629897117615 and batch: 650, loss is 4.259446835517883 and perplexity is 70.7708247180599
At time: 179.55169415473938 and batch: 700, loss is 4.281800527572631 and perplexity is 72.3706280798533
At time: 180.54647064208984 and batch: 750, loss is 4.241597466468811 and perplexity is 69.5188171628343
At time: 181.53856897354126 and batch: 800, loss is 4.248261594772339 and perplexity is 69.98364660114657
At time: 182.53369069099426 and batch: 850, loss is 4.243815507888794 and perplexity is 69.6731839114042
At time: 183.52858996391296 and batch: 900, loss is 4.211646027565003 and perplexity is 67.46750182954513
At time: 184.5226321220398 and batch: 950, loss is 4.289013061523438 and perplexity is 72.89449060908895
At time: 185.51648378372192 and batch: 1000, loss is 4.263865699768067 and perplexity is 71.08424335256862
At time: 186.51316475868225 and batch: 1050, loss is 4.216150550842285 and perplexity is 67.77209627334074
At time: 187.50909066200256 and batch: 1100, loss is 4.247899832725525 and perplexity is 69.95833375279861
At time: 188.50593781471252 and batch: 1150, loss is 4.220298895835876 and perplexity is 68.05382225388897
At time: 189.50223970413208 and batch: 1200, loss is 4.27909658908844 and perplexity is 72.1752066762551
At time: 190.49699997901917 and batch: 1250, loss is 4.288669557571411 and perplexity is 72.8694553635828
At time: 191.49102878570557 and batch: 1300, loss is 4.268636407852173 and perplexity is 71.4241757413525
At time: 192.48771214485168 and batch: 1350, loss is 4.159738693237305 and perplexity is 64.05478246503557
At time: 193.48527121543884 and batch: 1400, loss is 4.178693509101867 and perplexity is 65.28050908454094
At time: 194.48307180404663 and batch: 1450, loss is 4.128181066513061 and perplexity is 62.06492822467125
At time: 195.4806203842163 and batch: 1500, loss is 4.120019340515137 and perplexity is 61.56043286339872
At time: 196.47725987434387 and batch: 1550, loss is 4.1408076572418215 and perplexity is 62.85356509172875
At time: 197.47316908836365 and batch: 1600, loss is 4.21260241985321 and perplexity is 67.53205809363537
At time: 198.46888375282288 and batch: 1650, loss is 4.18390558719635 and perplexity is 65.62164443571639
At time: 199.4643383026123 and batch: 1700, loss is 4.182047820091247 and perplexity is 65.49984787315435
At time: 200.45961999893188 and batch: 1750, loss is 4.1821078681945805 and perplexity is 65.50378113287896
At time: 201.4548819065094 and batch: 1800, loss is 4.135570349693299 and perplexity is 62.525242155393165
At time: 202.44773602485657 and batch: 1850, loss is 4.188693027496338 and perplexity is 65.9365573527619
At time: 203.44374895095825 and batch: 1900, loss is 4.285411376953125 and perplexity is 72.63241987835625
At time: 204.4403293132782 and batch: 1950, loss is 4.215212264060974 and perplexity is 67.70853643460704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.446124977289244 and perplexity of 85.29577969852964
finished 5 epochs...
Completing Train Step...
At time: 207.70302486419678 and batch: 50, loss is 4.200880331993103 and perplexity is 66.74506299966124
At time: 208.69561457633972 and batch: 100, loss is 4.161697659492493 and perplexity is 64.18038660934042
At time: 209.68965911865234 and batch: 150, loss is 4.1117092752456665 and perplexity is 61.05098136764814
At time: 210.68324875831604 and batch: 200, loss is 4.120395956039428 and perplexity is 61.583621844488206
At time: 211.67752242088318 and batch: 250, loss is 4.1059380674362185 and perplexity is 60.699658221767706
At time: 212.66821265220642 and batch: 300, loss is 4.128678302764893 and perplexity is 62.09579683081089
At time: 213.6619758605957 and batch: 350, loss is 4.1401522731781 and perplexity is 62.812385362562665
At time: 214.65533661842346 and batch: 400, loss is 4.085649366378784 and perplexity is 59.48054988246241
At time: 215.64858484268188 and batch: 450, loss is 4.120572919845581 and perplexity is 61.59452088094553
At time: 216.64059948921204 and batch: 500, loss is 4.144407496452332 and perplexity is 63.08023556371057
At time: 217.6347472667694 and batch: 550, loss is 4.103794836997986 and perplexity is 60.56970417715315
At time: 218.64770579338074 and batch: 600, loss is 4.096264019012451 and perplexity is 60.11527800760488
At time: 219.65893173217773 and batch: 650, loss is 4.149512848854065 and perplexity is 63.40310587792393
At time: 220.66639614105225 and batch: 700, loss is 4.16874445438385 and perplexity is 64.63424989242216
At time: 221.7148196697235 and batch: 750, loss is 4.130034065246582 and perplexity is 62.18004107711483
At time: 222.71692824363708 and batch: 800, loss is 4.1373011302948 and perplexity is 62.633553336026964
At time: 223.72093510627747 and batch: 850, loss is 4.134850873947143 and perplexity is 62.48027293920988
At time: 224.72704553604126 and batch: 900, loss is 4.101457586288452 and perplexity is 60.428302902573385
At time: 225.73846125602722 and batch: 950, loss is 4.1823869323730465 and perplexity is 65.52206344259744
At time: 226.7498743534088 and batch: 1000, loss is 4.15849657535553 and perplexity is 63.975268267549076
At time: 227.75871443748474 and batch: 1050, loss is 4.112183303833008 and perplexity is 61.07992813835801
At time: 228.7612006664276 and batch: 1100, loss is 4.140034852027893 and perplexity is 62.80501029302916
At time: 229.7690999507904 and batch: 1150, loss is 4.114019131660461 and perplexity is 61.192163360883775
At time: 230.7732334136963 and batch: 1200, loss is 4.170520706176758 and perplexity is 64.74915861787956
At time: 231.78096222877502 and batch: 1250, loss is 4.184601593017578 and perplexity is 65.66733338028345
At time: 232.7925045490265 and batch: 1300, loss is 4.165364761352539 and perplexity is 64.41617468967534
At time: 233.80310225486755 and batch: 1350, loss is 4.053304085731506 and perplexity is 57.58741681315823
At time: 234.80491971969604 and batch: 1400, loss is 4.078007645606995 and perplexity is 59.02774842354199
At time: 235.80035161972046 and batch: 1450, loss is 4.024237852096558 and perplexity is 55.9376597611674
At time: 236.79526042938232 and batch: 1500, loss is 4.017630209922791 and perplexity is 55.56926218150065
At time: 237.7911822795868 and batch: 1550, loss is 4.0431437492370605 and perplexity is 57.005271683705686
At time: 238.78471279144287 and batch: 1600, loss is 4.113363046646118 and perplexity is 61.152029266635985
At time: 239.78063654899597 and batch: 1650, loss is 4.084746055603027 and perplexity is 59.426844720683114
At time: 240.77677130699158 and batch: 1700, loss is 4.0802246809005736 and perplexity is 59.158760200301025
At time: 241.77372813224792 and batch: 1750, loss is 4.082744679450989 and perplexity is 59.30802818881496
At time: 242.77050495147705 and batch: 1800, loss is 4.035297832489014 and perplexity is 56.559763065039654
At time: 243.76717925071716 and batch: 1850, loss is 4.090680894851684 and perplexity is 59.78058214022888
At time: 244.76436758041382 and batch: 1900, loss is 4.18710693359375 and perplexity is 65.83205867545168
At time: 245.76098132133484 and batch: 1950, loss is 4.116561169624329 and perplexity is 61.34791404143859
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4477635583212205 and perplexity of 85.43565831517805
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 249.24028539657593 and batch: 50, loss is 4.142480120658875 and perplexity is 62.958773333920696
At time: 250.29764127731323 and batch: 100, loss is 4.126993746757507 and perplexity is 61.99128103929399
At time: 251.31401085853577 and batch: 150, loss is 4.077339124679566 and perplexity is 58.98830032583043
At time: 252.32481050491333 and batch: 200, loss is 4.082395896911621 and perplexity is 59.2873461911079
At time: 253.32479619979858 and batch: 250, loss is 4.066733121871948 and perplexity is 58.365976265939594
At time: 254.32550168037415 and batch: 300, loss is 4.079766402244568 and perplexity is 59.13165521447807
At time: 255.32533621788025 and batch: 350, loss is 4.091840972900391 and perplexity is 59.849972522656365
At time: 256.3254780769348 and batch: 400, loss is 4.0345168828964235 and perplexity is 56.51560998402635
At time: 257.32417273521423 and batch: 450, loss is 4.053178396224975 and perplexity is 57.5801791340163
At time: 258.323472738266 and batch: 500, loss is 4.0803933477401735 and perplexity is 59.16873916295505
At time: 259.3239514827728 and batch: 550, loss is 4.041189675331116 and perplexity is 56.89398793355395
At time: 260.333975315094 and batch: 600, loss is 4.004804158210755 and perplexity is 54.86107925500908
At time: 261.3331768512726 and batch: 650, loss is 4.055547227859497 and perplexity is 57.71673856316122
At time: 262.3320822715759 and batch: 700, loss is 4.086068820953369 and perplexity is 59.50550450450876
At time: 263.3324251174927 and batch: 750, loss is 4.0293444681167605 and perplexity is 56.22404251166131
At time: 264.336626291275 and batch: 800, loss is 4.037382817268371 and perplexity is 56.6778123328527
At time: 265.34593772888184 and batch: 850, loss is 4.034258971214294 and perplexity is 56.50103582749221
At time: 266.358012676239 and batch: 900, loss is 3.9922968673706056 and perplexity is 54.179188970136195
At time: 267.36586022377014 and batch: 950, loss is 4.077852745056152 and perplexity is 59.01860570092083
At time: 268.36835265159607 and batch: 1000, loss is 4.039375748634338 and perplexity is 56.79087995338569
At time: 269.3679859638214 and batch: 1050, loss is 3.987577271461487 and perplexity is 53.92408755283914
At time: 270.373991727829 and batch: 1100, loss is 4.0018103885650635 and perplexity is 54.6970834265587
At time: 271.3814539909363 and batch: 1150, loss is 3.9727536153793337 and perplexity is 53.13063091805872
At time: 272.3795940876007 and batch: 1200, loss is 4.016507868766785 and perplexity is 55.50692949735696
At time: 273.4439663887024 and batch: 1250, loss is 4.032606897354126 and perplexity is 56.40776900618104
At time: 274.4526011943817 and batch: 1300, loss is 4.010454216003418 and perplexity is 55.171924844209045
At time: 275.4516398906708 and batch: 1350, loss is 3.9001212549209594 and perplexity is 49.40843975878242
At time: 276.456661939621 and batch: 1400, loss is 3.90959023475647 and perplexity is 49.87850930583395
At time: 277.45863342285156 and batch: 1450, loss is 3.844038138389587 and perplexity is 46.71373059059563
At time: 278.45667147636414 and batch: 1500, loss is 3.8369760084152222 and perplexity is 46.384994309024115
At time: 279.45588970184326 and batch: 1550, loss is 3.8609679698944093 and perplexity is 47.51131864388617
At time: 280.45465540885925 and batch: 1600, loss is 3.9238871145248413 and perplexity is 50.59673833963725
At time: 281.4637269973755 and batch: 1650, loss is 3.8846519804000854 and perplexity is 48.65000835651739
At time: 282.47098422050476 and batch: 1700, loss is 3.869121446609497 and perplexity is 47.90028463187253
At time: 283.48229908943176 and batch: 1750, loss is 3.8591067171096802 and perplexity is 47.422970314546234
At time: 284.4809422492981 and batch: 1800, loss is 3.8099674654006956 and perplexity is 45.1489699387774
At time: 285.48146963119507 and batch: 1850, loss is 3.8505584812164306 and perplexity is 47.01931530465917
At time: 286.48291659355164 and batch: 1900, loss is 3.9464536619186403 and perplexity is 51.751512662868414
At time: 287.48380756378174 and batch: 1950, loss is 3.869008016586304 and perplexity is 47.89485160961552
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380232842023982 and perplexity of 79.8566252187671
finished 7 epochs...
Completing Train Step...
At time: 290.74727058410645 and batch: 50, loss is 4.049853434562683 and perplexity is 57.389045178513
At time: 291.77171754837036 and batch: 100, loss is 4.022469549179077 and perplexity is 55.838832438288264
At time: 292.77321791648865 and batch: 150, loss is 3.969877381324768 and perplexity is 52.97803434500074
At time: 293.7711544036865 and batch: 200, loss is 3.9789885330200194 and perplexity is 53.46293088099041
At time: 294.76669931411743 and batch: 250, loss is 3.960085792541504 and perplexity is 52.46182658947065
At time: 295.765123128891 and batch: 300, loss is 3.974717526435852 and perplexity is 53.23507727967034
At time: 296.7668704986572 and batch: 350, loss is 3.993425416946411 and perplexity is 54.24036738581026
At time: 297.7656352519989 and batch: 400, loss is 3.9366635704040527 and perplexity is 51.24733262917442
At time: 298.7888090610504 and batch: 450, loss is 3.9631239557266236 and perplexity is 52.62145654778239
At time: 299.7972230911255 and batch: 500, loss is 3.991593389511108 and perplexity is 54.14108851323538
At time: 300.79491424560547 and batch: 550, loss is 3.9547113180160522 and perplexity is 52.180628162664775
At time: 301.795117855072 and batch: 600, loss is 3.9250480937957763 and perplexity is 50.6555142162118
At time: 302.7946903705597 and batch: 650, loss is 3.9738760137557985 and perplexity is 53.19029813086914
At time: 303.7902669906616 and batch: 700, loss is 4.005831160545349 and perplexity is 54.91745065330644
At time: 304.7945635318756 and batch: 750, loss is 3.9541461944580076 and perplexity is 52.151147991170774
At time: 305.7910244464874 and batch: 800, loss is 3.963186378479004 and perplexity is 52.62474142645888
At time: 306.79691195487976 and batch: 850, loss is 3.96230562210083 and perplexity is 52.57841225514926
At time: 307.80254459381104 and batch: 900, loss is 3.919184603691101 and perplexity is 50.35936519177416
At time: 308.7984471321106 and batch: 950, loss is 4.011499228477478 and perplexity is 55.229610329665476
At time: 309.7932357788086 and batch: 1000, loss is 3.9736186933517454 and perplexity is 53.176612942677
At time: 310.7888009548187 and batch: 1050, loss is 3.9267279052734376 and perplexity is 50.740677439453066
At time: 311.7840166091919 and batch: 1100, loss is 3.9402877426147462 and perplexity is 51.43339875213834
At time: 312.779159784317 and batch: 1150, loss is 3.9167786836624146 and perplexity is 50.23835022097244
At time: 313.77363204956055 and batch: 1200, loss is 3.9628993892669677 and perplexity is 52.60964086033672
At time: 314.77061700820923 and batch: 1250, loss is 3.9836967992782593 and perplexity is 53.715242102631755
At time: 315.7776608467102 and batch: 1300, loss is 3.9640625286102296 and perplexity is 52.670868804868945
At time: 316.7762944698334 and batch: 1350, loss is 3.8516505050659178 and perplexity is 47.07068956421137
At time: 317.77065563201904 and batch: 1400, loss is 3.86632185459137 and perplexity is 47.766370916699955
At time: 318.7677171230316 and batch: 1450, loss is 3.8020527839660643 and perplexity is 44.7930406162247
At time: 319.76454997062683 and batch: 1500, loss is 3.7986010456085206 and perplexity is 44.638693296308475
At time: 320.768657207489 and batch: 1550, loss is 3.826229419708252 and perplexity is 45.88918276610324
At time: 321.7645568847656 and batch: 1600, loss is 3.893627381324768 and perplexity is 49.0886271316759
At time: 322.7695281505585 and batch: 1650, loss is 3.8543969202041626 and perplexity is 47.200142903533546
At time: 323.7721869945526 and batch: 1700, loss is 3.845643091201782 and perplexity is 46.78876412040605
At time: 324.7665784358978 and batch: 1750, loss is 3.8385349178314208 and perplexity is 46.4573607050955
At time: 325.7659752368927 and batch: 1800, loss is 3.792212381362915 and perplexity is 44.354420700442645
At time: 326.7622559070587 and batch: 1850, loss is 3.83707745552063 and perplexity is 46.38970017112513
At time: 327.7582573890686 and batch: 1900, loss is 3.9374438762664794 and perplexity is 51.287336828984714
At time: 328.7664165496826 and batch: 1950, loss is 3.860322051048279 and perplexity is 47.48064009676208
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379401060592296 and perplexity of 79.79022957787167
finished 8 epochs...
Completing Train Step...
At time: 332.2497594356537 and batch: 50, loss is 4.000545320510864 and perplexity is 54.62793164373606
At time: 333.2469952106476 and batch: 100, loss is 3.9729504776000977 and perplexity is 53.141091361651135
At time: 334.2443211078644 and batch: 150, loss is 3.920510449409485 and perplexity is 50.426178222592256
At time: 335.24224162101746 and batch: 200, loss is 3.9303014135360717 and perplexity is 50.922324034036286
At time: 336.23674750328064 and batch: 250, loss is 3.9094058227539064 and perplexity is 49.8693119581247
At time: 337.23130989074707 and batch: 300, loss is 3.9247419929504392 and perplexity is 50.64001089340039
At time: 338.2270493507385 and batch: 350, loss is 3.9450781297683717 and perplexity is 51.68037573016106
At time: 339.2233018875122 and batch: 400, loss is 3.889449610710144 and perplexity is 48.88397390252049
At time: 340.22887134552 and batch: 450, loss is 3.9180979681015016 and perplexity is 50.304672634108606
At time: 341.23341131210327 and batch: 500, loss is 3.946630349159241 and perplexity is 51.76065730268452
At time: 342.2289779186249 and batch: 550, loss is 3.9103774785995484 and perplexity is 49.917791315418235
At time: 343.22560119628906 and batch: 600, loss is 3.883408660888672 and perplexity is 48.589558438965454
At time: 344.2233488559723 and batch: 650, loss is 3.9310449600219726 and perplexity is 50.96020122910828
At time: 345.2330641746521 and batch: 700, loss is 3.9633775424957274 and perplexity is 52.63480234502116
At time: 346.23842215538025 and batch: 750, loss is 3.912973461151123 and perplexity is 50.047545377457666
At time: 347.24130725860596 and batch: 800, loss is 3.9222853422164916 and perplexity is 50.515758758011636
At time: 348.2662227153778 and batch: 850, loss is 3.9226106119155886 and perplexity is 50.53219267624544
At time: 349.2621281147003 and batch: 900, loss is 3.8794572067260744 and perplexity is 48.39793786529983
At time: 350.26407265663147 and batch: 950, loss is 3.974965968132019 and perplexity is 53.24830473562305
At time: 351.2685556411743 and batch: 1000, loss is 3.9365435075759887 and perplexity is 51.241180098840715
At time: 352.26944971084595 and batch: 1050, loss is 3.891572093963623 and perplexity is 48.98783950600178
At time: 353.28066849708557 and batch: 1100, loss is 3.9045631647109986 and perplexity is 49.62839574172003
At time: 354.28815364837646 and batch: 1150, loss is 3.882947392463684 and perplexity is 48.56715077824394
At time: 355.2847182750702 and batch: 1200, loss is 3.929501800537109 and perplexity is 50.881622156845
At time: 356.2788996696472 and batch: 1250, loss is 3.9522210502624513 and perplexity is 52.05084609011335
At time: 357.27461647987366 and batch: 1300, loss is 3.9331755113601683 and perplexity is 51.068890296737024
At time: 358.28364992141724 and batch: 1350, loss is 3.821225600242615 and perplexity is 45.66013511457639
At time: 359.2852017879486 and batch: 1400, loss is 3.838859143257141 and perplexity is 46.47242580476016
At time: 360.29516863822937 and batch: 1450, loss is 3.7732975387573244 and perplexity is 43.52334839264808
At time: 361.30350732803345 and batch: 1500, loss is 3.7716462564468385 and perplexity is 43.451538362987264
At time: 362.3140251636505 and batch: 1550, loss is 3.80026397228241 and perplexity is 44.712985924554786
At time: 363.3241262435913 and batch: 1600, loss is 3.869734082221985 and perplexity is 47.92963904294701
At time: 364.332804441452 and batch: 1650, loss is 3.830678691864014 and perplexity is 46.09381111527442
At time: 365.3375747203827 and batch: 1700, loss is 3.8235889863967896 and perplexity is 45.768175265713545
At time: 366.3469235897064 and batch: 1750, loss is 3.8174906301498415 and perplexity is 45.489913958836446
At time: 367.3421206474304 and batch: 1800, loss is 3.7728787422180177 and perplexity is 43.50512478122125
At time: 368.3347134590149 and batch: 1850, loss is 3.8192750310897825 and perplexity is 45.571158669073576
At time: 369.3294277191162 and batch: 1900, loss is 3.9214883613586426 and perplexity is 50.47551470426221
At time: 370.3230791091919 and batch: 1950, loss is 3.8444970655441284 and perplexity is 46.735173710092134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3825340093568315 and perplexity of 80.04060027354048
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 373.7780005931854 and batch: 50, loss is 3.988219265937805 and perplexity is 53.9587176341596
At time: 374.8081750869751 and batch: 100, loss is 3.996634602546692 and perplexity is 54.41471439810797
At time: 375.80935406684875 and batch: 150, loss is 3.9509977436065675 and perplexity is 51.98721087427421
At time: 376.81084060668945 and batch: 200, loss is 3.961861319541931 and perplexity is 52.55505672088747
At time: 377.8113272190094 and batch: 250, loss is 3.940784287452698 and perplexity is 51.45894408246311
At time: 378.8129196166992 and batch: 300, loss is 3.955383162498474 and perplexity is 52.215697208938685
At time: 379.82042360305786 and batch: 350, loss is 3.9709814262390135 and perplexity is 53.0365567741367
At time: 380.83046770095825 and batch: 400, loss is 3.921363124847412 and perplexity is 50.46919372271517
At time: 381.8307750225067 and batch: 450, loss is 3.9484467840194704 and perplexity is 51.854762607200804
At time: 382.83602595329285 and batch: 500, loss is 3.9707764863967894 and perplexity is 53.02568858425989
At time: 383.8383729457855 and batch: 550, loss is 3.936815824508667 and perplexity is 51.2551358399381
At time: 384.8386039733887 and batch: 600, loss is 3.90068540096283 and perplexity is 49.436321198369754
At time: 385.84788703918457 and batch: 650, loss is 3.941534399986267 and perplexity is 51.49755856217561
At time: 386.85003995895386 and batch: 700, loss is 3.972619824409485 and perplexity is 53.12352299491809
At time: 387.85760736465454 and batch: 750, loss is 3.9176835441589355 and perplexity is 50.28382949259284
At time: 388.8601245880127 and batch: 800, loss is 3.92028995513916 and perplexity is 50.4150607649327
At time: 389.87807512283325 and batch: 850, loss is 3.923998947143555 and perplexity is 50.60239702179086
At time: 390.8850197792053 and batch: 900, loss is 3.8867818975448607 and perplexity is 48.75373927332346
At time: 391.8864371776581 and batch: 950, loss is 3.9797061347961424 and perplexity is 53.5013097438705
At time: 392.8859965801239 and batch: 1000, loss is 3.9325261735916137 and perplexity is 51.035740101470886
At time: 393.8985571861267 and batch: 1050, loss is 3.885262894630432 and perplexity is 48.679738419263415
At time: 394.8993790149689 and batch: 1100, loss is 3.9009438133239747 and perplexity is 49.44909780560246
At time: 395.91324400901794 and batch: 1150, loss is 3.8800085258483885 and perplexity is 48.42462793062119
At time: 396.9137854576111 and batch: 1200, loss is 3.9071586513519287 and perplexity is 49.75737288670176
At time: 397.9175374507904 and batch: 1250, loss is 3.9285735511779785 and perplexity is 50.83441323790054
At time: 398.92109394073486 and batch: 1300, loss is 3.9137426137924196 and perplexity is 50.08605438692984
At time: 399.92076659202576 and batch: 1350, loss is 3.802062840461731 and perplexity is 44.793491079508605
At time: 400.9192180633545 and batch: 1400, loss is 3.816081714630127 and perplexity is 45.42586764158911
At time: 401.9213795661926 and batch: 1450, loss is 3.743701972961426 and perplexity is 42.254124610753
At time: 402.9334924221039 and batch: 1500, loss is 3.7425046873092653 and perplexity is 42.203564627023276
At time: 403.9406850337982 and batch: 1550, loss is 3.769365382194519 and perplexity is 43.35254380789471
At time: 404.94213700294495 and batch: 1600, loss is 3.834661116600037 and perplexity is 46.277742251700076
At time: 405.945698261261 and batch: 1650, loss is 3.797665753364563 and perplexity is 44.59696259093264
At time: 406.95288157463074 and batch: 1700, loss is 3.776339178085327 and perplexity is 43.65593225473272
At time: 407.95432114601135 and batch: 1750, loss is 3.7677362251281736 and perplexity is 43.2819732057124
At time: 408.95255947113037 and batch: 1800, loss is 3.729473519325256 and perplexity is 41.65717069437401
At time: 409.9540226459503 and batch: 1850, loss is 3.7654881286621094 and perplexity is 43.184780444989144
At time: 410.95539832115173 and batch: 1900, loss is 3.867294526100159 and perplexity is 47.81285450773639
At time: 411.9647798538208 and batch: 1950, loss is 3.7969294214248657 and perplexity is 44.56413650989256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352131972202035 and perplexity of 77.64382106131507
finished 10 epochs...
Completing Train Step...
At time: 415.23397040367126 and batch: 50, loss is 3.9786718893051147 and perplexity is 53.44600485984709
At time: 416.26089572906494 and batch: 100, loss is 3.9674722719192506 and perplexity is 52.85076948062041
At time: 417.25901913642883 and batch: 150, loss is 3.9155805778503416 and perplexity is 50.17819540469705
At time: 418.2543795108795 and batch: 200, loss is 3.921684880256653 and perplexity is 50.48543507152628
At time: 419.25163888931274 and batch: 250, loss is 3.8998559808731077 and perplexity is 49.395334720259726
At time: 420.2519197463989 and batch: 300, loss is 3.9127933597564697 and perplexity is 50.03853255637139
At time: 421.2473301887512 and batch: 350, loss is 3.930956473350525 and perplexity is 50.955692130025746
At time: 422.2417299747467 and batch: 400, loss is 3.8797891998291014 and perplexity is 48.414008314363365
At time: 423.2426996231079 and batch: 450, loss is 3.911272201538086 and perplexity is 49.96247389463275
At time: 424.24644589424133 and batch: 500, loss is 3.9342670583724977 and perplexity is 51.12466482608602
At time: 425.3043041229248 and batch: 550, loss is 3.902268714904785 and perplexity is 49.51465641321625
At time: 426.30613470077515 and batch: 600, loss is 3.869094796180725 and perplexity is 47.89900808575911
At time: 427.300981760025 and batch: 650, loss is 3.9102914905548096 and perplexity is 49.91349916668472
At time: 428.2944095134735 and batch: 700, loss is 3.9436436748504637 and perplexity is 51.60629570596574
At time: 429.287127494812 and batch: 750, loss is 3.8904277229309083 and perplexity is 48.93181130615476
At time: 430.27862334251404 and batch: 800, loss is 3.8923498678207396 and perplexity is 49.02595578788847
At time: 431.27234077453613 and batch: 850, loss is 3.8979460859298705 and perplexity is 49.30108485258042
At time: 432.264803647995 and batch: 900, loss is 3.860654296875 and perplexity is 47.496417962204106
At time: 433.25784158706665 and batch: 950, loss is 3.9550572443008423 and perplexity is 52.19868193596042
At time: 434.24966311454773 and batch: 1000, loss is 3.9098737907409666 and perplexity is 49.89265466105068
At time: 435.2572457790375 and batch: 1050, loss is 3.86527379989624 and perplexity is 47.716335371965194
At time: 436.26601004600525 and batch: 1100, loss is 3.881072793006897 and perplexity is 48.476192105952855
At time: 437.27635979652405 and batch: 1150, loss is 3.86128315448761 and perplexity is 47.52629583969207
At time: 438.28700852394104 and batch: 1200, loss is 3.891032114028931 and perplexity is 48.9613941962355
At time: 439.29262113571167 and batch: 1250, loss is 3.9140892887115477 and perplexity is 50.10342097589035
At time: 440.2975914478302 and batch: 1300, loss is 3.900974841117859 and perplexity is 49.450632125820114
At time: 441.3018751144409 and batch: 1350, loss is 3.789539408683777 and perplexity is 44.23602085598119
At time: 442.3059401512146 and batch: 1400, loss is 3.8059616231918336 and perplexity is 44.96847205370063
At time: 443.3165695667267 and batch: 1450, loss is 3.7341870880126953 and perplexity is 41.85398812159446
At time: 444.3268656730652 and batch: 1500, loss is 3.7342613554000854 and perplexity is 41.85709662337283
At time: 445.33666491508484 and batch: 1550, loss is 3.763152723312378 and perplexity is 43.084044153533554
At time: 446.34747791290283 and batch: 1600, loss is 3.8308756494522096 and perplexity is 46.10289053524341
At time: 447.35611057281494 and batch: 1650, loss is 3.793953619003296 and perplexity is 44.43171956560007
At time: 448.3668563365936 and batch: 1700, loss is 3.77492693901062 and perplexity is 43.594323154988366
At time: 449.3697485923767 and batch: 1750, loss is 3.7682170629501344 and perplexity is 43.30278981974539
At time: 450.3698925971985 and batch: 1800, loss is 3.7310705947875977 and perplexity is 41.72375349424606
At time: 451.36583709716797 and batch: 1850, loss is 3.76884192943573 and perplexity is 43.32985673756073
At time: 452.3631012439728 and batch: 1900, loss is 3.8708235359191896 and perplexity is 47.9818846198089
At time: 453.35860085487366 and batch: 1950, loss is 3.800608515739441 and perplexity is 44.72839414554785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351324037063954 and perplexity of 77.58111522456012
finished 11 epochs...
Completing Train Step...
At time: 456.6382110118866 and batch: 50, loss is 3.9645496654510497 and perplexity is 52.696532975975906
At time: 457.6343791484833 and batch: 100, loss is 3.952272181510925 and perplexity is 52.05350758290021
At time: 458.62865471839905 and batch: 150, loss is 3.8990329360961913 and perplexity is 49.35469687369188
At time: 459.6274950504303 and batch: 200, loss is 3.904699053764343 and perplexity is 49.635140155672005
At time: 460.62146282196045 and batch: 250, loss is 3.882039647102356 and perplexity is 48.52308417606484
At time: 461.61741614341736 and batch: 300, loss is 3.8947571229934694 and perplexity is 49.14411593731206
At time: 462.6137840747833 and batch: 350, loss is 3.9128996419906614 and perplexity is 50.043851046032636
At time: 463.61154985427856 and batch: 400, loss is 3.8619537925720215 and perplexity is 47.5581794736878
At time: 464.60921335220337 and batch: 450, loss is 3.8946349573135377 and perplexity is 49.13811257968353
At time: 465.60668420791626 and batch: 500, loss is 3.917417345046997 and perplexity is 50.270445763284506
At time: 466.60581707954407 and batch: 550, loss is 3.8859651851654053 and perplexity is 48.71393774632647
At time: 467.6012945175171 and batch: 600, loss is 3.853822784423828 and perplexity is 47.1730513905034
At time: 468.59601879119873 and batch: 650, loss is 3.8950064992904663 and perplexity is 49.156372843191065
At time: 469.5923023223877 and batch: 700, loss is 3.9289376497268678 and perplexity is 50.852925343905056
At time: 470.5883598327637 and batch: 750, loss is 3.8764545822143557 and perplexity is 48.25283498449979
At time: 471.58688831329346 and batch: 800, loss is 3.8778602647781373 and perplexity is 48.32071084807292
At time: 472.5830981731415 and batch: 850, loss is 3.8842033624649046 and perplexity is 48.62818798509291
At time: 473.5791280269623 and batch: 900, loss is 3.8469672775268555 and perplexity is 46.85076220146763
At time: 474.5732705593109 and batch: 950, loss is 3.941985511779785 and perplexity is 51.52079495889264
At time: 475.61428213119507 and batch: 1000, loss is 3.897698540687561 and perplexity is 49.28888211401173
At time: 476.6114249229431 and batch: 1050, loss is 3.853972306251526 and perplexity is 47.180105318710375
At time: 477.60879468917847 and batch: 1100, loss is 3.869887571334839 and perplexity is 47.936996285336974
At time: 478.6049485206604 and batch: 1150, loss is 3.8507102489471436 and perplexity is 47.02645186097842
At time: 479.60151076316833 and batch: 1200, loss is 3.8811615562438964 and perplexity is 48.48049520065706
At time: 480.5964255332947 and batch: 1250, loss is 3.905200023651123 and perplexity is 49.660012095742424
At time: 481.5930542945862 and batch: 1300, loss is 3.8927775955200197 and perplexity is 49.04693003247555
At time: 482.58848762512207 and batch: 1350, loss is 3.781226553916931 and perplexity is 43.86981744585136
At time: 483.5847964286804 and batch: 1400, loss is 3.7990194034576414 and perplexity is 44.65737215097378
At time: 484.57940459251404 and batch: 1450, loss is 3.7271088361740112 and perplexity is 41.55878106070631
At time: 485.57531452178955 and batch: 1500, loss is 3.727541751861572 and perplexity is 41.57677640393553
At time: 486.5726053714752 and batch: 1550, loss is 3.7569581508636474 and perplexity is 42.81798184256495
At time: 487.56901931762695 and batch: 1600, loss is 3.8258181762695314 and perplexity is 45.8703150206666
At time: 488.5641715526581 and batch: 1650, loss is 3.7888635540008546 and perplexity is 44.20613383491104
At time: 489.5588071346283 and batch: 1700, loss is 3.7707565069198608 and perplexity is 43.41289457147933
At time: 490.5532319545746 and batch: 1750, loss is 3.7649466705322268 and perplexity is 43.161404023777784
At time: 491.54651403427124 and batch: 1800, loss is 3.728119750022888 and perplexity is 41.60081465061242
At time: 492.5411295890808 and batch: 1850, loss is 3.76679506778717 and perplexity is 43.24125722197566
At time: 493.53644371032715 and batch: 1900, loss is 3.868902769088745 and perplexity is 47.889811061594834
At time: 494.53274488449097 and batch: 1950, loss is 3.798575987815857 and perplexity is 44.63757476320113
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351991733284883 and perplexity of 77.63293313939893
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 497.80316257476807 and batch: 50, loss is 3.965035047531128 and perplexity is 52.72211713730912
At time: 498.83354353904724 and batch: 100, loss is 3.9740365505218507 and perplexity is 53.1988378147647
At time: 499.8301405906677 and batch: 150, loss is 3.931860113143921 and perplexity is 51.001758531716625
At time: 500.852422952652 and batch: 200, loss is 3.942049651145935 and perplexity is 51.524099576001724
At time: 501.84948539733887 and batch: 250, loss is 3.9238325214385985 and perplexity is 50.593976182935485
At time: 502.8443031311035 and batch: 300, loss is 3.9319104385375976 and perplexity is 51.00432527987871
At time: 503.8485050201416 and batch: 350, loss is 3.948196625709534 and perplexity is 51.8417923298038
At time: 504.8519775867462 and batch: 400, loss is 3.8900005531311037 and perplexity is 48.910913577872016
At time: 505.8489739894867 and batch: 450, loss is 3.925232419967651 and perplexity is 50.664852213823856
At time: 506.85160660743713 and batch: 500, loss is 3.94698326587677 and perplexity is 51.77892772773651
At time: 507.85392212867737 and batch: 550, loss is 3.9174606132507326 and perplexity is 50.272620922230935
At time: 508.86026334762573 and batch: 600, loss is 3.8876686763763426 and perplexity is 48.79699223233643
At time: 509.8558189868927 and batch: 650, loss is 3.9194970178604125 and perplexity is 50.37510062887637
At time: 510.85976791381836 and batch: 700, loss is 3.9548141050338743 and perplexity is 52.185991929479776
At time: 511.85487818717957 and batch: 750, loss is 3.901535782814026 and perplexity is 49.47837882869503
At time: 512.8494138717651 and batch: 800, loss is 3.897395257949829 and perplexity is 49.27393591348131
At time: 513.8436126708984 and batch: 850, loss is 3.8987262535095213 and perplexity is 49.33956296836158
At time: 514.8388946056366 and batch: 900, loss is 3.857049069404602 and perplexity is 47.32549087207936
At time: 515.8341109752655 and batch: 950, loss is 3.959364695549011 and perplexity is 52.424010160391596
At time: 516.8373265266418 and batch: 1000, loss is 3.911716341972351 and perplexity is 49.98466917803182
At time: 517.8475432395935 and batch: 1050, loss is 3.8665662670135497 and perplexity is 47.77804703795086
At time: 518.8508095741272 and batch: 1100, loss is 3.881150035858154 and perplexity is 48.47993668986851
At time: 519.848509311676 and batch: 1150, loss is 3.8721225309371947 and perplexity is 48.0442533484484
At time: 520.8428730964661 and batch: 1200, loss is 3.8940257358551027 and perplexity is 49.108185704046015
At time: 521.8383731842041 and batch: 1250, loss is 3.911367039680481 and perplexity is 49.96721246754155
At time: 522.8330841064453 and batch: 1300, loss is 3.8952569484710695 and perplexity is 49.16868555828141
At time: 523.8284337520599 and batch: 1350, loss is 3.781581287384033 and perplexity is 43.88538229881897
At time: 524.8218975067139 and batch: 1400, loss is 3.799726710319519 and perplexity is 44.68896979002572
At time: 525.8165366649628 and batch: 1450, loss is 3.723039426803589 and perplexity is 41.390005009967915
At time: 526.8119888305664 and batch: 1500, loss is 3.724424786567688 and perplexity is 41.4473847941897
At time: 527.8072023391724 and batch: 1550, loss is 3.749429397583008 and perplexity is 42.4968262887423
At time: 528.8013260364532 and batch: 1600, loss is 3.817158718109131 and perplexity is 45.474817814097314
At time: 529.7965562343597 and batch: 1650, loss is 3.7804632711410524 and perplexity is 43.836345145854104
At time: 530.7960917949677 and batch: 1700, loss is 3.7608539962768557 and perplexity is 42.98511944045546
At time: 531.797153711319 and batch: 1750, loss is 3.754721975326538 and perplexity is 42.72234029451973
At time: 532.7931230068207 and batch: 1800, loss is 3.716695098876953 and perplexity is 41.12824447064815
At time: 533.7872545719147 and batch: 1850, loss is 3.7518917322158813 and perplexity is 42.601596632787576
At time: 534.7833385467529 and batch: 1900, loss is 3.854533896446228 and perplexity is 47.20660864454976
At time: 535.7807323932648 and batch: 1950, loss is 3.7922595357894897 and perplexity is 44.356512257029515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338232705759448 and perplexity of 76.57209426671685
finished 13 epochs...
Completing Train Step...
At time: 539.046549320221 and batch: 50, loss is 3.9702326345443724 and perplexity is 52.99685830570846
At time: 540.0803029537201 and batch: 100, loss is 3.963535928726196 and perplexity is 52.64313963319445
At time: 541.0792446136475 and batch: 150, loss is 3.9112133407592773 and perplexity is 49.95953315105618
At time: 542.0806226730347 and batch: 200, loss is 3.9161040449142455 and perplexity is 50.204468913375806
At time: 543.0841779708862 and batch: 250, loss is 3.900241594314575 and perplexity is 49.41438589823272
At time: 544.0840167999268 and batch: 300, loss is 3.9087868690490724 and perplexity is 49.83845471331882
At time: 545.082973241806 and batch: 350, loss is 3.9237225961685183 and perplexity is 50.58841493210574
At time: 546.0903675556183 and batch: 400, loss is 3.8674593448638914 and perplexity is 47.820735612766036
At time: 547.1007652282715 and batch: 450, loss is 3.906067681312561 and perplexity is 49.70311868388081
At time: 548.0988657474518 and batch: 500, loss is 3.9299756336212157 and perplexity is 50.90573726561291
At time: 549.0968372821808 and batch: 550, loss is 3.9015469789505004 and perplexity is 49.47893279847808
At time: 550.0938792228699 and batch: 600, loss is 3.8728392839431764 and perplexity is 48.078701555409225
At time: 551.120402097702 and batch: 650, loss is 3.906274800300598 and perplexity is 49.71341420968753
At time: 552.1189393997192 and batch: 700, loss is 3.9398328113555907 and perplexity is 51.41000541286549
At time: 553.1311767101288 and batch: 750, loss is 3.8884646987915037 and perplexity is 48.83585119619702
At time: 554.1410353183746 and batch: 800, loss is 3.8856100368499757 and perplexity is 48.696640145186684
At time: 555.1444416046143 and batch: 850, loss is 3.8870360755920412 and perplexity is 48.766132978601874
At time: 556.1479289531708 and batch: 900, loss is 3.8463999223709107 and perplexity is 46.82418871898665
At time: 557.1502492427826 and batch: 950, loss is 3.9483731603622436 and perplexity is 51.85094501046748
At time: 558.1566059589386 and batch: 1000, loss is 3.9006719064712523 and perplexity is 49.43565408485091
At time: 559.1555805206299 and batch: 1050, loss is 3.856466236114502 and perplexity is 47.29791603707527
At time: 560.1624360084534 and batch: 1100, loss is 3.871970615386963 and perplexity is 48.03695523362809
At time: 561.1633501052856 and batch: 1150, loss is 3.863042407035828 and perplexity is 47.609980186121874
At time: 562.1630477905273 and batch: 1200, loss is 3.886820664405823 and perplexity is 48.755629339390985
At time: 563.1603722572327 and batch: 1250, loss is 3.905502438545227 and perplexity is 49.67503229409294
At time: 564.1592464447021 and batch: 1300, loss is 3.8903351545333864 and perplexity is 48.92728197643394
At time: 565.1571800708771 and batch: 1350, loss is 3.7772342205047607 and perplexity is 43.69502365758284
At time: 566.1569395065308 and batch: 1400, loss is 3.797067232131958 and perplexity is 44.57027834825177
At time: 567.1690151691437 and batch: 1450, loss is 3.7215316247940065 and perplexity is 41.3276441030023
At time: 568.1787188053131 and batch: 1500, loss is 3.7238171672821045 and perplexity is 41.422208213514345
At time: 569.1824555397034 and batch: 1550, loss is 3.7504650211334227 and perplexity is 42.54085979999988
At time: 570.1902732849121 and batch: 1600, loss is 3.819392590522766 and perplexity is 45.57651630356117
At time: 571.1887965202332 and batch: 1650, loss is 3.7832551860809325 and perplexity is 43.95890349941602
At time: 572.1878867149353 and batch: 1700, loss is 3.763952736854553 and perplexity is 43.118525763346376
At time: 573.1874582767487 and batch: 1750, loss is 3.7589096307754515 and perplexity is 42.90162185835636
At time: 574.1931216716766 and batch: 1800, loss is 3.7210449266433714 and perplexity is 41.30753490899798
At time: 575.1971542835236 and batch: 1850, loss is 3.756675319671631 and perplexity is 42.80587329413899
At time: 576.2011330127716 and batch: 1900, loss is 3.859678635597229 and perplexity is 47.45010014528998
At time: 577.1996958255768 and batch: 1950, loss is 3.797040491104126 and perplexity is 44.56908650913355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336732092569041 and perplexity of 76.45727534298501
finished 14 epochs...
Completing Train Step...
At time: 580.5126633644104 and batch: 50, loss is 3.9665834951400756 and perplexity is 52.80381781181168
At time: 581.5078282356262 and batch: 100, loss is 3.9576553773880003 and perplexity is 52.33447738954653
At time: 582.501656293869 and batch: 150, loss is 3.9045150756835936 and perplexity is 49.626009217820396
At time: 583.4977803230286 and batch: 200, loss is 3.908717384338379 and perplexity is 49.83499182302202
At time: 584.4929587841034 and batch: 250, loss is 3.892631998062134 and perplexity is 49.03978944398411
At time: 585.4890239238739 and batch: 300, loss is 3.900946607589722 and perplexity is 49.449235979715745
At time: 586.4841134548187 and batch: 350, loss is 3.9158307552337646 and perplexity is 50.19075042475383
At time: 587.4809160232544 and batch: 400, loss is 3.859353051185608 and perplexity is 47.43465364705879
At time: 588.4914922714233 and batch: 450, loss is 3.8984115362167358 and perplexity is 49.32403739788785
At time: 589.4863159656525 and batch: 500, loss is 3.922467818260193 and perplexity is 50.52497751488994
At time: 590.4881052970886 and batch: 550, loss is 3.894201970100403 and perplexity is 49.11684101074995
At time: 591.4927809238434 and batch: 600, loss is 3.8661373901367186 and perplexity is 47.757560531764554
At time: 592.487694978714 and batch: 650, loss is 3.8997210693359374 and perplexity is 49.388671169228644
At time: 593.4844191074371 and batch: 700, loss is 3.933153624534607 and perplexity is 51.06777257307525
At time: 594.4774415493011 and batch: 750, loss is 3.8823922872543335 and perplexity is 48.54019838124371
At time: 595.4721846580505 and batch: 800, loss is 3.8799056243896484 and perplexity is 48.419645222136566
At time: 596.4674789905548 and batch: 850, loss is 3.881389718055725 and perplexity is 48.49155786027063
At time: 597.4631035327911 and batch: 900, loss is 3.8411591958999636 and perplexity is 46.57943785004292
At time: 598.4575569629669 and batch: 950, loss is 3.9432633256912233 and perplexity is 51.586671027134095
At time: 599.4528756141663 and batch: 1000, loss is 3.8958478498458864 and perplexity is 49.197747987844906
At time: 600.448561668396 and batch: 1050, loss is 3.852060089111328 and perplexity is 47.08997291647046
At time: 601.4697947502136 and batch: 1100, loss is 3.8677483129501344 and perplexity is 47.834556275987914
At time: 602.4637770652771 and batch: 1150, loss is 3.8590935277938843 and perplexity is 47.42234484213956
At time: 603.4587495326996 and batch: 1200, loss is 3.883471302986145 and perplexity is 48.59260228615686
At time: 604.4540014266968 and batch: 1250, loss is 3.9024805784225465 and perplexity is 49.52514787384434
At time: 605.4571368694305 and batch: 1300, loss is 3.887758731842041 and perplexity is 48.80138686607402
At time: 606.4716076850891 and batch: 1350, loss is 3.77481342792511 and perplexity is 43.589374996885674
At time: 607.4691541194916 and batch: 1400, loss is 3.795435447692871 and perplexity is 44.497608568430216
At time: 608.464239358902 and batch: 1450, loss is 3.7203576278686525 and perplexity is 41.27915404505209
At time: 609.4658508300781 and batch: 1500, loss is 3.722960557937622 and perplexity is 41.38674075593611
At time: 610.4604637622833 and batch: 1550, loss is 3.750174322128296 and perplexity is 42.52849501168169
At time: 611.4632270336151 and batch: 1600, loss is 3.8195792722702024 and perplexity is 45.585025401488714
At time: 612.459130525589 and batch: 1650, loss is 3.7835333490371705 and perplexity is 43.971132938776044
At time: 613.4603686332703 and batch: 1700, loss is 3.76444935798645 and perplexity is 43.13994465251298
At time: 614.4565327167511 and batch: 1750, loss is 3.7598886728286742 and perplexity is 42.943644918121834
At time: 615.4595410823822 and batch: 1800, loss is 3.722018713951111 and perplexity is 41.347779253742246
At time: 616.4558494091034 and batch: 1850, loss is 3.7577527379989624 and perplexity is 42.85201798064515
At time: 617.4527788162231 and batch: 1900, loss is 3.8608173894882203 and perplexity is 47.50416490884588
At time: 618.4495069980621 and batch: 1950, loss is 3.797917995452881 and perplexity is 44.60821324079327
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336375533702761 and perplexity of 76.43001868316053
finished 15 epochs...
Completing Train Step...
At time: 621.6812038421631 and batch: 50, loss is 3.9625601816177367 and perplexity is 52.59179829407216
At time: 622.7109501361847 and batch: 100, loss is 3.952771258354187 and perplexity is 52.07949276690784
At time: 623.707004070282 and batch: 150, loss is 3.899364881515503 and perplexity is 49.3710826586833
At time: 624.7046518325806 and batch: 200, loss is 3.9033254957199097 and perplexity is 49.56701021055321
At time: 625.7060070037842 and batch: 250, loss is 3.8871631956100465 and perplexity is 48.772332524339
At time: 626.7531318664551 and batch: 300, loss is 3.8953694438934328 and perplexity is 49.17421712146227
At time: 627.7494175434113 and batch: 350, loss is 3.910273561477661 and perplexity is 49.91260427172975
At time: 628.7470078468323 and batch: 400, loss is 3.8536350679397584 and perplexity is 47.16419706223122
At time: 629.7421538829803 and batch: 450, loss is 3.893030323982239 and perplexity is 49.059327154166
At time: 630.7362637519836 and batch: 500, loss is 3.917128963470459 and perplexity is 50.2559507830251
At time: 631.7314856052399 and batch: 550, loss is 3.888996138572693 and perplexity is 48.86181140780452
At time: 632.7319917678833 and batch: 600, loss is 3.8613081979751587 and perplexity is 47.52748607879397
At time: 633.7333054542542 and batch: 650, loss is 3.8948612785339356 and perplexity is 49.14923483584443
At time: 634.7311825752258 and batch: 700, loss is 3.9283915042877195 and perplexity is 50.82515983335476
At time: 635.7310252189636 and batch: 750, loss is 3.8779388236999512 and perplexity is 48.32450702012807
At time: 636.7409732341766 and batch: 800, loss is 3.8756555795669554 and perplexity is 48.21429623993235
At time: 637.7446413040161 and batch: 850, loss is 3.877228307723999 and perplexity is 48.29018388087359
At time: 638.7423193454742 and batch: 900, loss is 3.8371971225738526 and perplexity is 46.39525182201271
At time: 639.7458386421204 and batch: 950, loss is 3.9394345760345457 and perplexity is 51.3895362089055
At time: 640.7456631660461 and batch: 1000, loss is 3.8922607135772704 and perplexity is 49.021585110724956
At time: 641.7472803592682 and batch: 1050, loss is 3.8487433290481565 and perplexity is 46.93404550477631
At time: 642.7497553825378 and batch: 1100, loss is 3.864498505592346 and perplexity is 47.67935550594068
At time: 643.7487819194794 and batch: 1150, loss is 3.8560638761520387 and perplexity is 47.27888907745408
At time: 644.7518091201782 and batch: 1200, loss is 3.880759844779968 and perplexity is 48.46102394113396
At time: 645.754597902298 and batch: 1250, loss is 3.899917960166931 and perplexity is 49.398396303100256
At time: 646.7610502243042 and batch: 1300, loss is 3.8854805183410646 and perplexity is 48.69033343739261
At time: 647.7690210342407 and batch: 1350, loss is 3.772558193206787 and perplexity is 43.49118149136245
At time: 648.7760281562805 and batch: 1400, loss is 3.7937404489517212 and perplexity is 44.422249063098334
At time: 649.7846908569336 and batch: 1450, loss is 3.7189369058609008 and perplexity is 41.22054948269219
At time: 650.7931456565857 and batch: 1500, loss is 3.7216750383377075 and perplexity is 41.33357147191826
At time: 651.7953941822052 and batch: 1550, loss is 3.749195113182068 and perplexity is 42.48687111147029
At time: 652.7978982925415 and batch: 1600, loss is 3.8189348649978636 and perplexity is 45.555659542413025
At time: 653.8029255867004 and batch: 1650, loss is 3.7828937768936157 and perplexity is 43.9430192183624
At time: 654.8074667453766 and batch: 1700, loss is 3.763972578048706 and perplexity is 43.119381294875
At time: 655.8045771121979 and batch: 1750, loss is 3.7597397994995116 and perplexity is 42.93725223059864
At time: 656.800194978714 and batch: 1800, loss is 3.7218530321121217 and perplexity is 41.34092924511405
At time: 657.7959187030792 and batch: 1850, loss is 3.7576481819152834 and perplexity is 42.847537775687776
At time: 658.8040518760681 and batch: 1900, loss is 3.8608008289337157 and perplexity is 47.50337822004773
At time: 659.8128325939178 and batch: 1950, loss is 3.797692742347717 and perplexity is 44.59816623384721
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336375817587209 and perplexity of 76.43004038045724
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 663.128271818161 and batch: 50, loss is 3.9636524724960327 and perplexity is 52.649275220668635
At time: 664.1586382389069 and batch: 100, loss is 3.9617739629745485 and perplexity is 52.55046589205619
At time: 665.1656200885773 and batch: 150, loss is 3.9106095886230468 and perplexity is 49.92937907989956
At time: 666.1663284301758 and batch: 200, loss is 3.916140608787537 and perplexity is 50.206304616775824
At time: 667.1644823551178 and batch: 250, loss is 3.9031700229644777 and perplexity is 49.55930448992758
At time: 668.1602318286896 and batch: 300, loss is 3.912718529701233 and perplexity is 50.034788310309054
At time: 669.1640810966492 and batch: 350, loss is 3.929675874710083 and perplexity is 50.89048010408908
At time: 670.1650471687317 and batch: 400, loss is 3.8702320861816406 and perplexity is 47.95351413742762
At time: 671.1718499660492 and batch: 450, loss is 3.909493474960327 and perplexity is 49.8736833049268
At time: 672.172331571579 and batch: 500, loss is 3.9361775159835815 and perplexity is 51.22242968919495
At time: 673.1730754375458 and batch: 550, loss is 3.9099109411239623 and perplexity is 49.89450822671013
At time: 674.1703538894653 and batch: 600, loss is 3.8806057214736938 and perplexity is 48.45355554344057
At time: 675.169686794281 and batch: 650, loss is 3.9097608041763308 and perplexity is 49.88701777985188
At time: 676.1676661968231 and batch: 700, loss is 3.9449167537689207 and perplexity is 51.67203643077509
At time: 677.1916308403015 and batch: 750, loss is 3.890083179473877 and perplexity is 48.9149550747474
At time: 678.2006163597107 and batch: 800, loss is 3.8878599643707275 and perplexity is 48.806327403937225
At time: 679.2034730911255 and batch: 850, loss is 3.887512879371643 and perplexity is 48.78939039929507
At time: 680.2015655040741 and batch: 900, loss is 3.842292351722717 and perplexity is 46.632249527542186
At time: 681.20379114151 and batch: 950, loss is 3.9505927085876467 and perplexity is 51.96615849709691
At time: 682.2110917568207 and batch: 1000, loss is 3.9013817262649537 and perplexity is 49.47075694751442
At time: 683.212197303772 and batch: 1050, loss is 3.8580640840530394 and perplexity is 47.373551325464895
At time: 684.2254674434662 and batch: 1100, loss is 3.867308802604675 and perplexity is 47.8135371130423
At time: 685.2411162853241 and batch: 1150, loss is 3.8642160367965697 and perplexity is 47.665889477763436
At time: 686.2590689659119 and batch: 1200, loss is 3.8912644672393797 and perplexity is 48.97277185513165
At time: 687.275586605072 and batch: 1250, loss is 3.905985126495361 and perplexity is 49.6990156213697
At time: 688.2885661125183 and batch: 1300, loss is 3.886350736618042 and perplexity is 48.73272309691511
At time: 689.2912104129791 and batch: 1350, loss is 3.7705266094207763 and perplexity is 43.402915202749234
At time: 690.2967324256897 and batch: 1400, loss is 3.789712738990784 and perplexity is 44.24368896359544
At time: 691.3113927841187 and batch: 1450, loss is 3.7126527547836305 and perplexity is 40.9623255311997
At time: 692.3223836421967 and batch: 1500, loss is 3.7146646785736084 and perplexity is 41.04482156847118
At time: 693.3233959674835 and batch: 1550, loss is 3.743581085205078 and perplexity is 42.24901691316764
At time: 694.3229022026062 and batch: 1600, loss is 3.8148669528961183 and perplexity is 45.3707195385282
At time: 695.3245661258698 and batch: 1650, loss is 3.7760893392562864 and perplexity is 43.64502667011349
At time: 696.3262078762054 and batch: 1700, loss is 3.757070331573486 and perplexity is 42.82278546359368
At time: 697.3279194831848 and batch: 1750, loss is 3.7524957609176637 and perplexity is 42.62733699307112
At time: 698.3293423652649 and batch: 1800, loss is 3.7138809728622437 and perplexity is 41.01266710884861
At time: 699.3297185897827 and batch: 1850, loss is 3.7509979581832886 and perplexity is 42.5635374426617
At time: 700.330803155899 and batch: 1900, loss is 3.853883743286133 and perplexity is 47.17592709369651
At time: 701.3293917179108 and batch: 1950, loss is 3.7950758934020996 and perplexity is 44.481612138305245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331391658339389 and perplexity of 76.0500486441879
finished 17 epochs...
Completing Train Step...
At time: 704.6080853939056 and batch: 50, loss is 3.9659927701950073 and perplexity is 52.772634490725025
At time: 705.5996732711792 and batch: 100, loss is 3.9563325786590577 and perplexity is 52.26529517653538
At time: 706.5938675403595 and batch: 150, loss is 3.9025656366348267 and perplexity is 49.52936057354521
At time: 707.5871770381927 and batch: 200, loss is 3.9061968612670896 and perplexity is 49.70953974521959
At time: 708.5793161392212 and batch: 250, loss is 3.8931212997436524 and perplexity is 49.06379056683639
At time: 709.5716245174408 and batch: 300, loss is 3.9026614379882814 and perplexity is 49.5341057806189
At time: 710.5694561004639 and batch: 350, loss is 3.91821572303772 and perplexity is 50.31059660640776
At time: 711.5782585144043 and batch: 400, loss is 3.860033640861511 and perplexity is 47.46694817102425
At time: 712.5737574100494 and batch: 450, loss is 3.8999507427215576 and perplexity is 49.40001573526994
At time: 713.5666172504425 and batch: 500, loss is 3.9266691255569457 and perplexity is 50.73769500447277
At time: 714.5612623691559 and batch: 550, loss is 3.9000089597702026 and perplexity is 49.402891742104565
At time: 715.5579087734222 and batch: 600, loss is 3.872247543334961 and perplexity is 48.050259851194205
At time: 716.5542051792145 and batch: 650, loss is 3.902232189178467 and perplexity is 49.512847887456424
At time: 717.5501530170441 and batch: 700, loss is 3.937418646812439 and perplexity is 51.28604289380003
At time: 718.5446381568909 and batch: 750, loss is 3.884502091407776 and perplexity is 48.642716802264495
At time: 719.5413451194763 and batch: 800, loss is 3.8824730682373048 and perplexity is 48.544119664563
At time: 720.53995013237 and batch: 850, loss is 3.8819939994812014 and perplexity is 48.520869263254255
At time: 721.5371613502502 and batch: 900, loss is 3.8375594663619994 and perplexity is 46.4120658993642
At time: 722.5348279476166 and batch: 950, loss is 3.9448638486862184 and perplexity is 51.669302789726714
At time: 723.5332865715027 and batch: 1000, loss is 3.896126136779785 and perplexity is 49.21144098348967
At time: 724.530597448349 and batch: 1050, loss is 3.8527025032043456 and perplexity is 47.120233897711515
At time: 725.5295715332031 and batch: 1100, loss is 3.863533406257629 and perplexity is 47.63336238919525
At time: 726.5366747379303 and batch: 1150, loss is 3.860429015159607 and perplexity is 47.485719092865615
At time: 727.5659880638123 and batch: 1200, loss is 3.887603678703308 and perplexity is 48.793820644464276
At time: 728.5635201931 and batch: 1250, loss is 3.902954239845276 and perplexity is 49.54861158233524
At time: 729.559609413147 and batch: 1300, loss is 3.8839424896240233 and perplexity is 48.61550386608934
At time: 730.5594317913055 and batch: 1350, loss is 3.7684493350982664 and perplexity is 43.31284901994773
At time: 731.5633788108826 and batch: 1400, loss is 3.789052577018738 and perplexity is 44.21449060152321
At time: 732.5608797073364 and batch: 1450, loss is 3.7126207971572875 and perplexity is 40.961016493423216
At time: 733.5650098323822 and batch: 1500, loss is 3.7161955070495605 and perplexity is 41.10770226762125
At time: 734.5583083629608 and batch: 1550, loss is 3.745632696151733 and perplexity is 42.33578443491635
At time: 735.5519154071808 and batch: 1600, loss is 3.8167713260650635 and perplexity is 45.457204643292116
At time: 736.5444104671478 and batch: 1650, loss is 3.778832445144653 and perplexity is 43.764913956355
At time: 737.5370042324066 and batch: 1700, loss is 3.759996657371521 and perplexity is 42.94828241837115
At time: 738.5350210666656 and batch: 1750, loss is 3.7562344741821287 and perplexity is 42.787006676910174
At time: 739.5391118526459 and batch: 1800, loss is 3.717797703742981 and perplexity is 41.17361768289815
At time: 740.5421266555786 and batch: 1850, loss is 3.7548411464691163 and perplexity is 42.72743186800453
At time: 741.5320653915405 and batch: 1900, loss is 3.8581042861938477 and perplexity is 47.37545588192924
At time: 742.5251767635345 and batch: 1950, loss is 3.7986808967590333 and perplexity is 44.64225788964212
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330423896257267 and perplexity of 75.97648589212892
finished 18 epochs...
Completing Train Step...
At time: 745.7965564727783 and batch: 50, loss is 3.9657241773605345 and perplexity is 52.75846204263877
At time: 746.8188643455505 and batch: 100, loss is 3.9540467929840086 and perplexity is 52.14596434782487
At time: 747.8142020702362 and batch: 150, loss is 3.8995597124099732 and perplexity is 49.380702607979885
At time: 748.8087215423584 and batch: 200, loss is 3.902561011314392 and perplexity is 49.52913148491144
At time: 749.8046119213104 and batch: 250, loss is 3.8891571807861327 and perplexity is 48.86968085570595
At time: 750.8005940914154 and batch: 300, loss is 3.8987725353240967 and perplexity is 49.34184654570976
At time: 751.7950248718262 and batch: 350, loss is 3.9142101430892944 and perplexity is 50.1094765595699
At time: 752.814305305481 and batch: 400, loss is 3.8563119077682497 and perplexity is 47.29061719113599
At time: 753.807151556015 and batch: 450, loss is 3.8963684368133547 and perplexity is 49.22336636199345
At time: 754.8013353347778 and batch: 500, loss is 3.923035407066345 and perplexity is 50.55366306658739
At time: 755.7945141792297 and batch: 550, loss is 3.896161284446716 and perplexity is 49.21317068122381
At time: 756.7872033119202 and batch: 600, loss is 3.8688556814193724 and perplexity is 47.88755609509623
At time: 757.7797870635986 and batch: 650, loss is 3.8991231060028078 and perplexity is 49.35914738274804
At time: 758.7744731903076 and batch: 700, loss is 3.9342992210388186 and perplexity is 51.126309158064494
At time: 759.7678110599518 and batch: 750, loss is 3.881893572807312 and perplexity is 48.51599671841076
At time: 760.7626359462738 and batch: 800, loss is 3.8801341962814333 and perplexity is 48.43071385698576
At time: 761.7576308250427 and batch: 850, loss is 3.879542899131775 and perplexity is 48.402085378729126
At time: 762.7561731338501 and batch: 900, loss is 3.8355019235610963 and perplexity is 46.31666926228485
At time: 763.7526032924652 and batch: 950, loss is 3.942623338699341 and perplexity is 51.55366679098961
At time: 764.7482898235321 and batch: 1000, loss is 3.8940278053283692 and perplexity is 49.108287332228656
At time: 765.740868806839 and batch: 1050, loss is 3.85066517829895 and perplexity is 47.02433239607399
At time: 766.7335665225983 and batch: 1100, loss is 3.8618544292449952 and perplexity is 47.55345416951284
At time: 767.7252085208893 and batch: 1150, loss is 3.858858861923218 and perplexity is 47.411217741924524
At time: 768.7248859405518 and batch: 1200, loss is 3.8860974597930906 and perplexity is 48.72038179048732
At time: 769.7253367900848 and batch: 1250, loss is 3.9017279863357546 and perplexity is 49.48788966133381
At time: 770.7223274707794 and batch: 1300, loss is 3.8832037115097044 and perplexity is 48.579601059553305
At time: 771.7198288440704 and batch: 1350, loss is 3.7678591585159302 and perplexity is 43.287294332372724
At time: 772.7237937450409 and batch: 1400, loss is 3.788948621749878 and perplexity is 44.209894511163256
At time: 773.7288839817047 and batch: 1450, loss is 3.7127861881256106 and perplexity is 40.9677916358628
At time: 774.7330226898193 and batch: 1500, loss is 3.7168173933029176 and perplexity is 41.13327453326466
At time: 775.7283239364624 and batch: 1550, loss is 3.746525568962097 and perplexity is 42.3736017862737
At time: 776.7217829227448 and batch: 1600, loss is 3.8176649522781374 and perplexity is 45.49784454867232
At time: 777.7154867649078 and batch: 1650, loss is 3.780000076293945 and perplexity is 43.81604507847278
At time: 778.7099316120148 and batch: 1700, loss is 3.76121395111084 and perplexity is 43.00059492705846
At time: 779.7065193653107 and batch: 1750, loss is 3.75779016494751 and perplexity is 42.85362183093069
At time: 780.7022590637207 and batch: 1800, loss is 3.71928062915802 and perplexity is 41.234720381163896
At time: 781.7000463008881 and batch: 1850, loss is 3.7563355064392088 and perplexity is 42.79132976315034
At time: 782.6961522102356 and batch: 1900, loss is 3.8595718240737913 and perplexity is 47.44503219846858
At time: 783.6973984241486 and batch: 1950, loss is 3.7998483896255495 and perplexity is 44.69440784369959
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330048884901889 and perplexity of 75.9479991889301
finished 19 epochs...
Completing Train Step...
At time: 786.9392242431641 and batch: 50, loss is 3.964723834991455 and perplexity is 52.7057119062271
At time: 787.9585161209106 and batch: 100, loss is 3.9522048139572146 and perplexity is 52.050000983549126
At time: 788.9503047466278 and batch: 150, loss is 3.8974201488494873 and perplexity is 49.27516240134003
At time: 789.9427781105042 and batch: 200, loss is 3.9002069282531737 and perplexity is 49.412672925788236
At time: 790.9535217285156 and batch: 250, loss is 3.8866528701782226 and perplexity is 48.747449112541425
At time: 791.9564578533173 and batch: 300, loss is 3.8963317251205445 and perplexity is 49.22155932205843
At time: 792.9596271514893 and batch: 350, loss is 3.9117243337631225 and perplexity is 49.9850686466459
At time: 793.9598770141602 and batch: 400, loss is 3.8539352226257324 and perplexity is 47.17835574178036
At time: 794.9538609981537 and batch: 450, loss is 3.894045395851135 and perplexity is 49.10915118027272
At time: 795.9480259418488 and batch: 500, loss is 3.920721001625061 and perplexity is 50.4367966839711
At time: 796.9395959377289 and batch: 550, loss is 3.89377112865448 and perplexity is 49.095683997935986
At time: 797.9321024417877 and batch: 600, loss is 3.8667211723327637 and perplexity is 47.785448684841136
At time: 798.9310848712921 and batch: 650, loss is 3.8971054220199584 and perplexity is 49.2596566258727
At time: 799.9296572208405 and batch: 700, loss is 3.9322766399383546 and perplexity is 51.02300655558677
At time: 800.9235327243805 and batch: 750, loss is 3.8800995206832884 and perplexity is 48.42903452213032
At time: 801.9164264202118 and batch: 800, loss is 3.878536195755005 and perplexity is 48.35338335429497
At time: 802.9374384880066 and batch: 850, loss is 3.877902264595032 and perplexity is 48.32274035169985
At time: 803.9384460449219 and batch: 900, loss is 3.834070143699646 and perplexity is 46.25040143977324
At time: 804.9464409351349 and batch: 950, loss is 3.941174144744873 and perplexity is 51.47900963815876
At time: 805.9519262313843 and batch: 1000, loss is 3.892672562599182 and perplexity is 49.04177876068742
At time: 806.9618625640869 and batch: 1050, loss is 3.8493777084350587 and perplexity is 46.96382894178889
At time: 807.9670479297638 and batch: 1100, loss is 3.8606595277786253 and perplexity is 47.49666641203882
At time: 808.9599900245667 and batch: 1150, loss is 3.8577650117874147 and perplexity is 47.35938532857328
At time: 809.9672029018402 and batch: 1200, loss is 3.885105834007263 and perplexity is 48.672093349597006
At time: 810.9708676338196 and batch: 1250, loss is 3.900900459289551 and perplexity is 49.446954034184884
At time: 811.9671504497528 and batch: 1300, loss is 3.882673115730286 and perplexity is 48.55383176540919
At time: 812.9638268947601 and batch: 1350, loss is 3.7674168872833254 and perplexity is 43.26815384030872
At time: 813.9606230258942 and batch: 1400, loss is 3.7887711238861086 and perplexity is 44.20204804571609
At time: 814.9560751914978 and batch: 1450, loss is 3.7127472352981568 and perplexity is 40.96619585562432
At time: 815.9504406452179 and batch: 1500, loss is 3.716991276741028 and perplexity is 41.14042755033882
At time: 816.9456224441528 and batch: 1550, loss is 3.74686580657959 and perplexity is 42.38802133248698
At time: 817.9405972957611 and batch: 1600, loss is 3.818033413887024 and perplexity is 45.51461184653867
At time: 818.9361219406128 and batch: 1650, loss is 3.7804680967330935 and perplexity is 43.83655668268275
At time: 819.9315547943115 and batch: 1700, loss is 3.761726517677307 and perplexity is 43.022641243976075
At time: 820.9230351448059 and batch: 1750, loss is 3.758481011390686 and perplexity is 42.883237331853664
At time: 821.924234867096 and batch: 1800, loss is 3.7199053812026976 and perplexity is 41.26048990597722
At time: 822.9247891902924 and batch: 1850, loss is 3.7569894075393675 and perplexity is 42.81932021125476
At time: 823.9208407402039 and batch: 1900, loss is 3.860160150527954 and perplexity is 47.472953578667486
At time: 824.9147245883942 and batch: 1950, loss is 3.8002857160568237 and perplexity is 44.71395816420414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3298689021620635 and perplexity of 75.93433108999963
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f4a57130b38>
ELAPSED
4255.073131799698


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.78177940258892}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.6888560527046866, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6228089196258255, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.04378796834526}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.14308718722040714, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.37386466100496807, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.54586144587961}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.31025574538464784, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6931579404631784, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.28222960592869}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.7280101718420305, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.21880679215341725, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -75.93433108999963}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.7229570152146902, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.23532633160778885, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4864084720611572 and batch: 50, loss is 7.587277364730835 and perplexity is 1972.9346133148233
At time: 2.51054310798645 and batch: 100, loss is 6.748555641174317 and perplexity is 852.8260856430106
At time: 3.5249974727630615 and batch: 150, loss is 6.502597131729126 and perplexity is 666.871338648305
At time: 4.532463073730469 and batch: 200, loss is 6.388778524398804 and perplexity is 595.129199742981
At time: 5.529986143112183 and batch: 250, loss is 6.328003578186035 and perplexity is 560.0374061450781
At time: 6.527591228485107 and batch: 300, loss is 6.260502042770386 and perplexity is 523.4816843431142
At time: 7.525742530822754 and batch: 350, loss is 6.210297212600708 and perplexity is 497.84919635455793
At time: 8.525212526321411 and batch: 400, loss is 6.167332391738892 and perplexity is 476.9121927885772
At time: 9.522840023040771 and batch: 450, loss is 6.075226926803589 and perplexity is 434.94819272127944
At time: 10.521520853042603 and batch: 500, loss is 6.068403177261352 and perplexity is 431.9903185639342
At time: 11.5239999294281 and batch: 550, loss is 6.017040681838989 and perplexity is 410.3624041501313
At time: 12.520290613174438 and batch: 600, loss is 6.063316316604614 and perplexity is 429.7984236667791
At time: 13.517983675003052 and batch: 650, loss is 6.131025657653809 and perplexity is 459.90762663457383
At time: 14.522220849990845 and batch: 700, loss is 6.03821629524231 and perplexity is 419.1447372520508
At time: 15.52100920677185 and batch: 750, loss is 5.972174425125122 and perplexity is 392.3578967320025
At time: 16.51806116104126 and batch: 800, loss is 5.98631552696228 and perplexity is 397.9456853342529
At time: 17.514998197555542 and batch: 850, loss is 6.0222545337677005 and perplexity is 412.5075603663809
At time: 18.513695001602173 and batch: 900, loss is 6.002828512191773 and perplexity is 404.57151208852326
At time: 19.519646406173706 and batch: 950, loss is 6.0219011306762695 and perplexity is 412.3618046760816
At time: 20.535054922103882 and batch: 1000, loss is 6.003095703125 and perplexity is 404.67962437106314
At time: 21.541680335998535 and batch: 1050, loss is 5.897775812149048 and perplexity is 364.2264582174028
At time: 22.55237340927124 and batch: 1100, loss is 5.974976377487183 and perplexity is 393.45880649561593
At time: 23.551366567611694 and batch: 1150, loss is 5.889170846939087 and perplexity is 361.1057482723164
At time: 24.55074644088745 and batch: 1200, loss is 5.9689439868927 and perplexity is 391.092453849626
At time: 25.556057691574097 and batch: 1250, loss is 5.905616722106934 and perplexity is 367.0935506985337
At time: 26.56603693962097 and batch: 1300, loss is 5.919029664993286 and perplexity is 372.05052501873394
At time: 27.568349599838257 and batch: 1350, loss is 5.889460735321045 and perplexity is 361.21044380767523
At time: 28.573410034179688 and batch: 1400, loss is 5.905002775192261 and perplexity is 366.8682439159653
At time: 29.57621717453003 and batch: 1450, loss is 5.880869560241699 and perplexity is 358.1205137148218
At time: 30.578003644943237 and batch: 1500, loss is 5.85397777557373 and perplexity is 348.61835165428454
At time: 31.575698137283325 and batch: 1550, loss is 5.834321165084839 and perplexity is 341.8326073623198
At time: 32.57248616218567 and batch: 1600, loss is 5.844763898849488 and perplexity is 345.42097786250775
At time: 33.570822954177856 and batch: 1650, loss is 5.83820951461792 and perplexity is 343.1643595025297
At time: 34.56753706932068 and batch: 1700, loss is 5.855616035461426 and perplexity is 349.1899471990991
At time: 35.5656476020813 and batch: 1750, loss is 5.850384330749511 and perplexity is 347.36785897674264
At time: 36.56382131576538 and batch: 1800, loss is 5.857653732299805 and perplexity is 349.9022158978808
At time: 37.56253457069397 and batch: 1850, loss is 5.826922092437744 and perplexity is 339.31269706328175
At time: 38.560951471328735 and batch: 1900, loss is 5.823872756958008 and perplexity is 338.27959475568247
At time: 39.558332204818726 and batch: 1950, loss is 5.765568513870239 and perplexity is 319.12041685814
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.190644871911338 and perplexity of 179.58432448548604
finished 1 epochs...
Completing Train Step...
At time: 42.81675338745117 and batch: 50, loss is 5.450843553543091 and perplexity is 232.95459271981574
At time: 43.80698871612549 and batch: 100, loss is 5.3509012222290036 and perplexity is 210.79818830021193
At time: 44.79567575454712 and batch: 150, loss is 5.244236946105957 and perplexity is 189.4711833313209
At time: 45.78313708305359 and batch: 200, loss is 5.193394708633423 and perplexity is 180.07883165104317
At time: 46.77069878578186 and batch: 250, loss is 5.209916934967041 and perplexity is 183.07885011137844
At time: 47.75648021697998 and batch: 300, loss is 5.210261068344116 and perplexity is 183.14186449639294
At time: 48.747270584106445 and batch: 350, loss is 5.189585771560669 and perplexity is 179.39422734819044
At time: 49.73425054550171 and batch: 400, loss is 5.138602838516236 and perplexity is 170.4774173713095
At time: 50.72866606712341 and batch: 450, loss is 5.09495641708374 and perplexity is 163.19673187989216
At time: 51.73534393310547 and batch: 500, loss is 5.082233686447143 and perplexity is 161.13357613661415
At time: 52.78205585479736 and batch: 550, loss is 5.042905712127686 and perplexity is 154.9195131617423
At time: 53.7721688747406 and batch: 600, loss is 5.0178937816619875 and perplexity is 151.0927341358161
At time: 54.767778396606445 and batch: 650, loss is 5.085458717346191 and perplexity is 161.65407576107944
At time: 55.76226186752319 and batch: 700, loss is 5.078912954330445 and perplexity is 160.59938214372454
At time: 56.7561194896698 and batch: 750, loss is 5.012282609939575 and perplexity is 150.24730101201146
At time: 57.75088095664978 and batch: 800, loss is 5.017955884933472 and perplexity is 151.10211778027798
At time: 58.74825954437256 and batch: 850, loss is 5.013998432159424 and perplexity is 150.50531996358364
At time: 59.737114667892456 and batch: 900, loss is 5.010239906311035 and perplexity is 149.94070355553438
At time: 60.728580713272095 and batch: 950, loss is 5.050566987991333 and perplexity is 156.11095243356814
At time: 61.7330424785614 and batch: 1000, loss is 5.0128082752227785 and perplexity is 150.32630156415314
At time: 62.724815368652344 and batch: 1050, loss is 4.932296829223633 and perplexity is 138.69771173280097
At time: 63.71985983848572 and batch: 1100, loss is 4.998143901824951 and perplexity is 148.13794519983605
At time: 64.7291510105133 and batch: 1150, loss is 4.923772420883179 and perplexity is 137.52042078552034
At time: 65.72424912452698 and batch: 1200, loss is 4.993585109710693 and perplexity is 147.46415211167493
At time: 66.72029781341553 and batch: 1250, loss is 4.963053779602051 and perplexity is 143.02991148380107
At time: 67.71765518188477 and batch: 1300, loss is 4.965737762451172 and perplexity is 143.41431695121196
At time: 68.713463306427 and batch: 1350, loss is 4.875011606216431 and perplexity is 130.975673334009
At time: 69.7090802192688 and batch: 1400, loss is 4.877156352996826 and perplexity is 131.25688444321662
At time: 70.70740246772766 and batch: 1450, loss is 4.827353372573852 and perplexity is 124.88001203427103
At time: 71.70877623558044 and batch: 1500, loss is 4.804171228408814 and perplexity is 122.01832378435019
At time: 72.70574569702148 and batch: 1550, loss is 4.802203950881958 and perplexity is 121.77851583983625
At time: 73.70479106903076 and batch: 1600, loss is 4.864212608337402 and perplexity is 129.56887698237594
At time: 74.71033930778503 and batch: 1650, loss is 4.837320690155029 and perplexity is 126.13095468863716
At time: 75.7125654220581 and batch: 1700, loss is 4.842098236083984 and perplexity is 126.73499287889572
At time: 76.7174015045166 and batch: 1750, loss is 4.83966495513916 and perplexity is 126.42698592138336
At time: 77.71372389793396 and batch: 1800, loss is 4.7911507034301755 and perplexity is 120.43987953797665
At time: 78.70862746238708 and batch: 1850, loss is 4.804176731109619 and perplexity is 122.01899521652608
At time: 79.71252417564392 and batch: 1900, loss is 4.903778057098389 and perplexity is 134.7980937554791
At time: 80.71596026420593 and batch: 1950, loss is 4.820727920532226 and perplexity is 124.05536036523824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.638729503542878 and perplexity of 103.41287838977816
finished 2 epochs...
Completing Train Step...
At time: 83.9382221698761 and batch: 50, loss is 4.77582278251648 and perplexity is 118.60786296064693
At time: 84.95245862007141 and batch: 100, loss is 4.720835857391357 and perplexity is 112.2620485253967
At time: 85.9415328502655 and batch: 150, loss is 4.658223094940186 and perplexity is 105.44854353628253
At time: 86.9305260181427 and batch: 200, loss is 4.640191431045532 and perplexity is 103.56417108335401
At time: 87.91885757446289 and batch: 250, loss is 4.652922067642212 and perplexity is 104.89103691291517
At time: 88.90734076499939 and batch: 300, loss is 4.678368444442749 and perplexity is 107.5943830731533
At time: 89.89326930046082 and batch: 350, loss is 4.685355443954467 and perplexity is 108.34877738247499
At time: 90.8798177242279 and batch: 400, loss is 4.6318839645385745 and perplexity is 102.70737901401623
At time: 91.86643886566162 and batch: 450, loss is 4.628432016372681 and perplexity is 102.3534496896962
At time: 92.86152696609497 and batch: 500, loss is 4.628703546524048 and perplexity is 102.38124551091437
At time: 93.86692595481873 and batch: 550, loss is 4.602210597991943 and perplexity is 99.70447872670158
At time: 94.87229943275452 and batch: 600, loss is 4.568012580871582 and perplexity is 96.35242670273914
At time: 95.87595415115356 and batch: 650, loss is 4.636948566436768 and perplexity is 103.22887045931512
At time: 96.87527251243591 and batch: 700, loss is 4.659660768508911 and perplexity is 105.60025314850425
At time: 97.8671703338623 and batch: 750, loss is 4.607024946212769 and perplexity is 100.18564813563538
At time: 98.8597469329834 and batch: 800, loss is 4.615560226440429 and perplexity is 101.04442043484626
At time: 99.84831070899963 and batch: 850, loss is 4.612643404006958 and perplexity is 100.75012122047461
At time: 100.84491872787476 and batch: 900, loss is 4.58423192024231 and perplexity is 97.92794177879519
At time: 101.83518195152283 and batch: 950, loss is 4.650765142440796 and perplexity is 104.66503861033034
At time: 102.8310055732727 and batch: 1000, loss is 4.6209914588928225 and perplexity is 101.59470919060556
At time: 103.88251852989197 and batch: 1050, loss is 4.5613681602478025 and perplexity is 95.71434284789272
At time: 104.87942862510681 and batch: 1100, loss is 4.60597752571106 and perplexity is 100.0807665709404
At time: 105.88167786598206 and batch: 1150, loss is 4.566117258071899 and perplexity is 96.16998070325185
At time: 106.8871717453003 and batch: 1200, loss is 4.629062767028809 and perplexity is 102.41802956000161
At time: 107.89056849479675 and batch: 1250, loss is 4.624089002609253 and perplexity is 101.90989113660133
At time: 108.89334225654602 and batch: 1300, loss is 4.610158882141113 and perplexity is 100.50011604158627
At time: 109.8952865600586 and batch: 1350, loss is 4.505295915603638 and perplexity is 90.4951190048767
At time: 110.8994562625885 and batch: 1400, loss is 4.510815143585205 and perplexity is 90.99596306276615
At time: 111.89048075675964 and batch: 1450, loss is 4.459194135665894 and perplexity is 86.41783997310412
At time: 112.89134311676025 and batch: 1500, loss is 4.45331916809082 and perplexity is 85.91162641547898
At time: 113.88091731071472 and batch: 1550, loss is 4.461675834655762 and perplexity is 86.63256937593621
At time: 114.88413572311401 and batch: 1600, loss is 4.538586845397949 and perplexity is 93.55849404060545
At time: 115.87807941436768 and batch: 1650, loss is 4.506914186477661 and perplexity is 90.64168317848502
At time: 116.86765432357788 and batch: 1700, loss is 4.510875673294067 and perplexity is 91.00147118861891
At time: 117.86330533027649 and batch: 1750, loss is 4.503388319015503 and perplexity is 90.32265537243708
At time: 118.86363673210144 and batch: 1800, loss is 4.460854024887085 and perplexity is 86.56140313070053
At time: 119.86715531349182 and batch: 1850, loss is 4.496705369949341 and perplexity is 89.72104616797606
At time: 120.87206625938416 and batch: 1900, loss is 4.607735061645508 and perplexity is 100.25681677649996
At time: 121.8723361492157 and batch: 1950, loss is 4.523917045593262 and perplexity is 92.19602765140665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.512291912699855 and perplexity of 91.13044236357413
finished 3 epochs...
Completing Train Step...
At time: 125.12569761276245 and batch: 50, loss is 4.499140949249267 and perplexity is 89.93983522168008
At time: 126.12429976463318 and batch: 100, loss is 4.446782941818237 and perplexity is 85.35191976310432
At time: 127.13144707679749 and batch: 150, loss is 4.3998252964019775 and perplexity is 81.43664014807302
At time: 128.12716341018677 and batch: 200, loss is 4.394782600402832 and perplexity is 81.0270136076976
At time: 129.14967012405396 and batch: 250, loss is 4.402566890716553 and perplexity is 81.66021271029662
At time: 130.16094660758972 and batch: 300, loss is 4.424211959838868 and perplexity is 83.44702170020238
At time: 131.16322016716003 and batch: 350, loss is 4.431219615936279 and perplexity is 84.03384345171192
At time: 132.15984988212585 and batch: 400, loss is 4.376740016937256 and perplexity is 79.57818654672633
At time: 133.15565991401672 and batch: 450, loss is 4.395971822738647 and perplexity is 81.12343006102115
At time: 134.1570703983307 and batch: 500, loss is 4.405223731994629 and perplexity is 81.87745940139816
At time: 135.16449999809265 and batch: 550, loss is 4.371823558807373 and perplexity is 79.18790391477144
At time: 136.1711609363556 and batch: 600, loss is 4.344755029678344 and perplexity is 77.07315453105912
At time: 137.17197227478027 and batch: 650, loss is 4.415075693130493 and perplexity is 82.68809959034807
At time: 138.17145466804504 and batch: 700, loss is 4.441153020858764 and perplexity is 84.87274532386726
At time: 139.17236828804016 and batch: 750, loss is 4.3911397171020505 and perplexity is 80.73237863914913
At time: 140.16710710525513 and batch: 800, loss is 4.399784641265869 and perplexity is 81.43332939768356
At time: 141.16265487670898 and batch: 850, loss is 4.394844369888306 and perplexity is 81.03201875921887
At time: 142.15493297576904 and batch: 900, loss is 4.3613217830657955 and perplexity is 78.36064177020178
At time: 143.15471124649048 and batch: 950, loss is 4.431898441314697 and perplexity is 84.09090712323587
At time: 144.1521716117859 and batch: 1000, loss is 4.411282653808594 and perplexity is 82.37505444873337
At time: 145.15933918952942 and batch: 1050, loss is 4.35905463218689 and perplexity is 78.18318760603212
At time: 146.1557059288025 and batch: 1100, loss is 4.395358285903931 and perplexity is 81.07367311394088
At time: 147.15126514434814 and batch: 1150, loss is 4.36520471572876 and perplexity is 78.66550235915537
At time: 148.15155243873596 and batch: 1200, loss is 4.428394193649292 and perplexity is 83.79674746343527
At time: 149.1523642539978 and batch: 1250, loss is 4.426994886398315 and perplexity is 83.67957206841108
At time: 150.152037858963 and batch: 1300, loss is 4.407666006088257 and perplexity is 82.07767098561209
At time: 151.15831923484802 and batch: 1350, loss is 4.30126651763916 and perplexity is 73.79319492298211
At time: 152.1708652973175 and batch: 1400, loss is 4.31664963722229 and perplexity is 74.9371406331763
At time: 153.17225909233093 and batch: 1450, loss is 4.258275985717773 and perplexity is 70.68801120263984
At time: 154.17730069160461 and batch: 1500, loss is 4.254038910865784 and perplexity is 70.38913443678973
At time: 155.18307256698608 and batch: 1550, loss is 4.269950799942016 and perplexity is 71.51811683716252
At time: 156.182861328125 and batch: 1600, loss is 4.350394029617309 and perplexity is 77.50899774977455
At time: 157.18317222595215 and batch: 1650, loss is 4.315867013931275 and perplexity is 74.87851602503886
At time: 158.18264317512512 and batch: 1700, loss is 4.3232023143768314 and perplexity is 75.42979185205394
At time: 159.18599891662598 and batch: 1750, loss is 4.31254638671875 and perplexity is 74.63028475693936
At time: 160.18906378746033 and batch: 1800, loss is 4.272167682647705 and perplexity is 71.67683998381702
At time: 161.1954083442688 and batch: 1850, loss is 4.313332138061523 and perplexity is 74.68894864799599
At time: 162.19500708580017 and batch: 1900, loss is 4.423111276626587 and perplexity is 83.35522349394226
At time: 163.19641518592834 and batch: 1950, loss is 4.341406345367432 and perplexity is 76.81549252282902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.466093125454215 and perplexity of 87.01609708055668
finished 4 epochs...
Completing Train Step...
At time: 166.45055532455444 and batch: 50, loss is 4.325011081695557 and perplexity is 75.56635025837461
At time: 167.4699001312256 and batch: 100, loss is 4.274383773803711 and perplexity is 71.83585852971308
At time: 168.46727323532104 and batch: 150, loss is 4.238319730758667 and perplexity is 69.29132588510706
At time: 169.4628391265869 and batch: 200, loss is 4.235712385177612 and perplexity is 69.11089477809786
At time: 170.45895266532898 and batch: 250, loss is 4.238832168579101 and perplexity is 69.32684248036477
At time: 171.45507621765137 and batch: 300, loss is 4.26126868724823 and perplexity is 70.89987618815762
At time: 172.45034766197205 and batch: 350, loss is 4.266685819625854 and perplexity is 71.28499237392612
At time: 173.44605708122253 and batch: 400, loss is 4.211895518302917 and perplexity is 67.48433644631498
At time: 174.45072507858276 and batch: 450, loss is 4.244217157363892 and perplexity is 69.70117372982226
At time: 175.45374703407288 and batch: 500, loss is 4.252408037185669 and perplexity is 70.27443220791699
At time: 176.45590496063232 and batch: 550, loss is 4.216858115196228 and perplexity is 67.8200663618167
At time: 177.45005106925964 and batch: 600, loss is 4.201217999458313 and perplexity is 66.76760444144121
At time: 178.44706964492798 and batch: 650, loss is 4.266150536537171 and perplexity is 71.24684493378207
At time: 179.44176840782166 and batch: 700, loss is 4.294231381416321 and perplexity is 73.27587159807268
At time: 180.4830813407898 and batch: 750, loss is 4.242528438568115 and perplexity is 69.58356737763462
At time: 181.48605465888977 and batch: 800, loss is 4.250268774032593 and perplexity is 70.12425739348703
At time: 182.48215985298157 and batch: 850, loss is 4.2447665309906 and perplexity is 69.73947623665025
At time: 183.47746515274048 and batch: 900, loss is 4.212812008857727 and perplexity is 67.5462135538268
At time: 184.48386120796204 and batch: 950, loss is 4.287626085281372 and perplexity is 72.79345776371117
At time: 185.48455810546875 and batch: 1000, loss is 4.267818269729614 and perplexity is 71.36576479767413
At time: 186.48540616035461 and batch: 1050, loss is 4.2212651824951175 and perplexity is 68.11961353594317
At time: 187.48613786697388 and batch: 1100, loss is 4.251461219787598 and perplexity is 70.20792664214467
At time: 188.48173022270203 and batch: 1150, loss is 4.224762945175171 and perplexity is 68.35829696359713
At time: 189.47664499282837 and batch: 1200, loss is 4.289330987930298 and perplexity is 72.91766937694418
At time: 190.4721872806549 and batch: 1250, loss is 4.291686754226685 and perplexity is 73.08964885706966
At time: 191.47157406806946 and batch: 1300, loss is 4.270037002563477 and perplexity is 71.52428215204515
At time: 192.47377920150757 and batch: 1350, loss is 4.16258131980896 and perplexity is 64.23712533527082
At time: 193.46934127807617 and batch: 1400, loss is 4.184329900741577 and perplexity is 65.64949449647168
At time: 194.47365736961365 and batch: 1450, loss is 4.122807788848877 and perplexity is 61.73233050230165
At time: 195.46850323677063 and batch: 1500, loss is 4.120722312927246 and perplexity is 61.60372336361009
At time: 196.46349835395813 and batch: 1550, loss is 4.1382984447479245 and perplexity is 62.69604984317436
At time: 197.4589159488678 and batch: 1600, loss is 4.2198998069763185 and perplexity is 68.02666815038762
At time: 198.45909523963928 and batch: 1650, loss is 4.182802848815918 and perplexity is 65.54932081415565
At time: 199.4545476436615 and batch: 1700, loss is 4.192143774032592 and perplexity is 66.16448072638619
At time: 200.45003008842468 and batch: 1750, loss is 4.183020477294922 and perplexity is 65.56358776553535
At time: 201.44502568244934 and batch: 1800, loss is 4.138954544067383 and perplexity is 62.73719817602972
At time: 202.4399130344391 and batch: 1850, loss is 4.1842723560333255 and perplexity is 65.64571682415757
At time: 203.43375086784363 and batch: 1900, loss is 4.290267896652222 and perplexity is 72.98601859085338
At time: 204.42799615859985 and batch: 1950, loss is 4.211849722862244 and perplexity is 67.48124604215262
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.451823673691861 and perplexity of 85.78324208232239
finished 5 epochs...
Completing Train Step...
At time: 207.68514752388 and batch: 50, loss is 4.1968285179138185 and perplexity is 66.47517155788664
At time: 208.69314074516296 and batch: 100, loss is 4.151179404258728 and perplexity is 63.50885876374234
At time: 209.69524264335632 and batch: 150, loss is 4.119860291481018 and perplexity is 61.550642514605244
At time: 210.6950933933258 and batch: 200, loss is 4.118194041252136 and perplexity is 61.44816913927882
At time: 211.69170951843262 and batch: 250, loss is 4.118399810791016 and perplexity is 61.46081460168849
At time: 212.6887605190277 and batch: 300, loss is 4.143079533576965 and perplexity is 62.99652294863724
At time: 213.69307947158813 and batch: 350, loss is 4.148905177116394 and perplexity is 63.36458930630257
At time: 214.6961145401001 and batch: 400, loss is 4.09176872253418 and perplexity is 59.84564849643203
At time: 215.70142459869385 and batch: 450, loss is 4.1302135181427 and perplexity is 62.19120046682931
At time: 216.69687485694885 and batch: 500, loss is 4.140742135047913 and perplexity is 62.84944692316614
At time: 217.69804692268372 and batch: 550, loss is 4.105625071525574 and perplexity is 60.68066244992129
At time: 218.70108938217163 and batch: 600, loss is 4.096438708305359 and perplexity is 60.12578042031584
At time: 219.69491291046143 and batch: 650, loss is 4.155215573310852 and perplexity is 63.76570925132622
At time: 220.68919610977173 and batch: 700, loss is 4.185168743133545 and perplexity is 65.70458717927495
At time: 221.6858389377594 and batch: 750, loss is 4.132855792045593 and perplexity is 62.355743941545434
At time: 222.67961859703064 and batch: 800, loss is 4.141003174781799 and perplexity is 62.865855267587634
At time: 223.6736831665039 and batch: 850, loss is 4.138762130737304 and perplexity is 62.72512786409056
At time: 224.66916704177856 and batch: 900, loss is 4.105040349960327 and perplexity is 60.64519152931011
At time: 225.66764330863953 and batch: 950, loss is 4.184841246604919 and perplexity is 65.68307267821345
At time: 226.67473649978638 and batch: 1000, loss is 4.160278406143188 and perplexity is 64.08936298875356
At time: 227.67178750038147 and batch: 1050, loss is 4.118191885948181 and perplexity is 61.44803669993958
At time: 228.6682152748108 and batch: 1100, loss is 4.143229179382324 and perplexity is 63.00595081945177
At time: 229.66447687149048 and batch: 1150, loss is 4.118618307113647 and perplexity is 61.47424503086114
At time: 230.6986906528473 and batch: 1200, loss is 4.1843487691879275 and perplexity is 65.65073321212279
At time: 231.6897737979889 and batch: 1250, loss is 4.190534358024597 and perplexity is 66.05808019626939
At time: 232.6846103668213 and batch: 1300, loss is 4.165519227981568 and perplexity is 64.42612560755718
At time: 233.6757447719574 and batch: 1350, loss is 4.0605350732803345 and perplexity is 58.00533988436548
At time: 234.67874097824097 and batch: 1400, loss is 4.087720150947571 and perplexity is 59.60384890609933
At time: 235.67178750038147 and batch: 1450, loss is 4.024314851760864 and perplexity is 55.941967108021075
At time: 236.66910457611084 and batch: 1500, loss is 4.022394008636475 and perplexity is 55.834614501902195
At time: 237.68111634254456 and batch: 1550, loss is 4.038493976593018 and perplexity is 56.74082541483035
At time: 238.6886019706726 and batch: 1600, loss is 4.119835991859436 and perplexity is 61.54914687545579
At time: 239.69314122200012 and batch: 1650, loss is 4.082567911148072 and perplexity is 59.29754533586803
At time: 240.6973135471344 and batch: 1700, loss is 4.094272232055664 and perplexity is 59.99566034695959
At time: 241.7065613269806 and batch: 1750, loss is 4.082987246513366 and perplexity is 59.32241610793522
At time: 242.71832370758057 and batch: 1800, loss is 4.04069146156311 and perplexity is 56.86564962530256
At time: 243.73268151283264 and batch: 1850, loss is 4.086274538040161 and perplexity is 59.51774706275204
At time: 244.74090671539307 and batch: 1900, loss is 4.186119508743286 and perplexity is 65.76708654758421
At time: 245.74340987205505 and batch: 1950, loss is 4.1120619249343875 and perplexity is 61.07251477387489
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.453603913063227 and perplexity of 85.93609280234712
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 248.99855780601501 and batch: 50, loss is 4.1381076097488405 and perplexity is 62.684086384119624
At time: 250.01913571357727 and batch: 100, loss is 4.123722176551819 and perplexity is 61.78880360140584
At time: 251.0212013721466 and batch: 150, loss is 4.085156683921814 and perplexity is 59.45125207685443
At time: 252.01708436012268 and batch: 200, loss is 4.084974980354309 and perplexity is 59.440450553626796
At time: 253.0104262828827 and batch: 250, loss is 4.076139912605286 and perplexity is 58.91760324270882
At time: 254.00465536117554 and batch: 300, loss is 4.101068873405456 and perplexity is 60.404818207435035
At time: 255.01763916015625 and batch: 350, loss is 4.11185625076294 and perplexity is 61.05995502665262
At time: 256.02462697029114 and batch: 400, loss is 4.045354905128479 and perplexity is 57.13145868418291
At time: 257.0810432434082 and batch: 450, loss is 4.0714838457107545 and perplexity is 58.6439165868708
At time: 258.0920898914337 and batch: 500, loss is 4.079119029045105 and perplexity is 59.09338735378256
At time: 259.10067319869995 and batch: 550, loss is 4.03844961643219 and perplexity is 56.73830843851657
At time: 260.1074194908142 and batch: 600, loss is 4.0088357257843015 and perplexity is 55.08270184623035
At time: 261.11474442481995 and batch: 650, loss is 4.0683073139190675 and perplexity is 58.45792787735887
At time: 262.12930965423584 and batch: 700, loss is 4.097539000511169 and perplexity is 60.191972756658494
At time: 263.1307473182678 and batch: 750, loss is 4.035921354293823 and perplexity is 56.595040307507574
At time: 264.1257920265198 and batch: 800, loss is 4.038885517120361 and perplexity is 56.76304609740018
At time: 265.12509393692017 and batch: 850, loss is 4.045601019859314 and perplexity is 57.14552130819762
At time: 266.11953711509705 and batch: 900, loss is 4.001647062301636 and perplexity is 54.6881506857977
At time: 267.1246302127838 and batch: 950, loss is 4.0786620616912845 and perplexity is 59.06638977391131
At time: 268.1374771595001 and batch: 1000, loss is 4.04159348487854 and perplexity is 56.91696690832501
At time: 269.1387848854065 and batch: 1050, loss is 3.9911425161361693 and perplexity is 54.116683240191904
At time: 270.1376404762268 and batch: 1100, loss is 4.002842540740967 and perplexity is 54.7535682857035
At time: 271.1337947845459 and batch: 1150, loss is 3.9887085866928103 and perplexity is 53.98512721546264
At time: 272.1299910545349 and batch: 1200, loss is 4.029288702011108 and perplexity is 56.220907203189185
At time: 273.13723278045654 and batch: 1250, loss is 4.041419777870178 and perplexity is 56.90708089093847
At time: 274.1353566646576 and batch: 1300, loss is 4.0204572057723995 and perplexity is 55.72657851659534
At time: 275.1291399002075 and batch: 1350, loss is 3.9027290773391723 and perplexity is 49.53745634869472
At time: 276.12233424186707 and batch: 1400, loss is 3.9179559326171876 and perplexity is 50.29752809296895
At time: 277.118061542511 and batch: 1450, loss is 3.85271906375885 and perplexity is 47.12101424137469
At time: 278.11426281929016 and batch: 1500, loss is 3.8489863109588622 and perplexity is 46.94545101444036
At time: 279.10952043533325 and batch: 1550, loss is 3.8613815689086914 and perplexity is 47.53097334274638
At time: 280.1024281978607 and batch: 1600, loss is 3.933341774940491 and perplexity is 51.077381899183415
At time: 281.1090679168701 and batch: 1650, loss is 3.890957889556885 and perplexity is 48.95776019746814
At time: 282.0995683670044 and batch: 1700, loss is 3.878503646850586 and perplexity is 48.35180953025509
At time: 283.09694480895996 and batch: 1750, loss is 3.862736339569092 and perplexity is 47.595410549854535
At time: 284.1061964035034 and batch: 1800, loss is 3.8161543083190916 and perplexity is 45.42916539259213
At time: 285.116756439209 and batch: 1850, loss is 3.84829638004303 and perplexity is 46.91307306698561
At time: 286.1274333000183 and batch: 1900, loss is 3.942554821968079 and perplexity is 51.5501346232642
At time: 287.1385827064514 and batch: 1950, loss is 3.863684992790222 and perplexity is 47.64058351273428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379513478833576 and perplexity of 79.79919995935991
finished 7 epochs...
Completing Train Step...
At time: 290.6302990913391 and batch: 50, loss is 4.047053442001343 and perplexity is 57.22858103295371
At time: 291.6404128074646 and batch: 100, loss is 4.021482257843018 and perplexity is 55.78373044814086
At time: 292.65516448020935 and batch: 150, loss is 3.979638419151306 and perplexity is 53.497686990841515
At time: 293.66985869407654 and batch: 200, loss is 3.975655755996704 and perplexity is 53.28504744092398
At time: 294.68705797195435 and batch: 250, loss is 3.968676609992981 and perplexity is 52.914458018099154
At time: 295.69578409194946 and batch: 300, loss is 3.9964041757583617 and perplexity is 54.40217723473592
At time: 296.6945261955261 and batch: 350, loss is 4.009273090362549 and perplexity is 55.10679833798392
At time: 297.697057723999 and batch: 400, loss is 3.946376390457153 and perplexity is 51.747513902347805
At time: 298.6962583065033 and batch: 450, loss is 3.9788733434677126 and perplexity is 53.45677286459361
At time: 299.69564723968506 and batch: 500, loss is 3.9889608669281005 and perplexity is 53.998748314153474
At time: 300.6935324668884 and batch: 550, loss is 3.9500972843170166 and perplexity is 51.94041957729528
At time: 301.70016717910767 and batch: 600, loss is 3.9278833961486814 and perplexity is 50.799341715728836
At time: 302.69894647598267 and batch: 650, loss is 3.9863005590438845 and perplexity is 53.85528592994122
At time: 303.6984214782715 and batch: 700, loss is 4.018490266799927 and perplexity is 55.61707546572191
At time: 304.70824003219604 and batch: 750, loss is 3.9612670516967774 and perplexity is 52.523834218761415
At time: 305.7086806297302 and batch: 800, loss is 3.965885543823242 and perplexity is 52.766976175965794
At time: 306.7083568572998 and batch: 850, loss is 3.972692999839783 and perplexity is 53.12741047380442
At time: 307.7428631782532 and batch: 900, loss is 3.9297248840332033 and perplexity is 50.89297427319051
At time: 308.7484128475189 and batch: 950, loss is 4.011573286056518 and perplexity is 55.23370065235564
At time: 309.746798992157 and batch: 1000, loss is 3.97615611076355 and perplexity is 53.31171553961143
At time: 310.7458703517914 and batch: 1050, loss is 3.9309595346450807 and perplexity is 50.95584812064741
At time: 311.75342059135437 and batch: 1100, loss is 3.9416130685806277 and perplexity is 51.50160996207757
At time: 312.7531862258911 and batch: 1150, loss is 3.932141661643982 and perplexity is 51.016120021964866
At time: 313.7539577484131 and batch: 1200, loss is 3.9748834562301636 and perplexity is 53.24391129798668
At time: 314.7600209712982 and batch: 1250, loss is 3.9920876932144167 and perplexity is 54.16785726919118
At time: 315.7597827911377 and batch: 1300, loss is 3.9716805934906008 and perplexity is 53.073651163850286
At time: 316.7574462890625 and batch: 1350, loss is 3.853799648284912 and perplexity is 47.17196000085865
At time: 317.7556085586548 and batch: 1400, loss is 3.8754685735702514 and perplexity is 48.205280720413
At time: 318.7545163631439 and batch: 1450, loss is 3.8112940216064453 and perplexity is 45.20890232808553
At time: 319.7585656642914 and batch: 1500, loss is 3.810933203697205 and perplexity is 45.19259308897817
At time: 320.75805592536926 and batch: 1550, loss is 3.827509994506836 and perplexity is 45.94798493933604
At time: 321.7559895515442 and batch: 1600, loss is 3.9015830755233765 and perplexity is 49.480718850616654
At time: 322.75408005714417 and batch: 1650, loss is 3.8600260400772095 and perplexity is 47.46658738636087
At time: 323.75241446495056 and batch: 1700, loss is 3.854470295906067 and perplexity is 47.203606374214814
At time: 324.76322078704834 and batch: 1750, loss is 3.8424490213394167 and perplexity is 46.63955595653427
At time: 325.7736175060272 and batch: 1800, loss is 3.7981956386566162 and perplexity is 44.62060012751824
At time: 326.78097701072693 and batch: 1850, loss is 3.8334662818908694 and perplexity is 46.22248101958932
At time: 327.78012228012085 and batch: 1900, loss is 3.9308813524246218 and perplexity is 50.95186443502469
At time: 328.77972769737244 and batch: 1950, loss is 3.854082899093628 and perplexity is 47.185323389183544
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379324127906977 and perplexity of 79.78409133736669
finished 8 epochs...
Completing Train Step...
At time: 332.0380790233612 and batch: 50, loss is 3.9992411231994627 and perplexity is 54.55673248112919
At time: 333.0604865550995 and batch: 100, loss is 3.972808165550232 and perplexity is 53.13352928210764
At time: 334.061726808548 and batch: 150, loss is 3.931283779144287 and perplexity is 50.972372953001134
At time: 335.06787872314453 and batch: 200, loss is 3.9266890048980714 and perplexity is 50.738703646445224
At time: 336.06414580345154 and batch: 250, loss is 3.9185706758499146 and perplexity is 50.32845766388516
At time: 337.06181621551514 and batch: 300, loss is 3.94776243686676 and perplexity is 51.81928808788373
At time: 338.0677981376648 and batch: 350, loss is 3.9601740789413453 and perplexity is 52.4664584597319
At time: 339.07023906707764 and batch: 400, loss is 3.8993857717514038 and perplexity is 49.3721140430196
At time: 340.0658574104309 and batch: 450, loss is 3.9338907623291015 and perplexity is 51.105430436131385
At time: 341.06121611595154 and batch: 500, loss is 3.9442961168289186 and perplexity is 51.63997680592383
At time: 342.0573480129242 and batch: 550, loss is 3.9064513206481934 and perplexity is 49.72219041341045
At time: 343.0525403022766 and batch: 600, loss is 3.8868198108673098 and perplexity is 48.75558772460137
At time: 344.04872465133667 and batch: 650, loss is 3.9442302417755126 and perplexity is 51.63657513173782
At time: 345.0434741973877 and batch: 700, loss is 3.976981348991394 and perplexity is 53.35572856338373
At time: 346.0387616157532 and batch: 750, loss is 3.920942621231079 and perplexity is 50.44797570568047
At time: 347.0442957878113 and batch: 800, loss is 3.9258557987213134 and perplexity is 50.69644545250517
At time: 348.04013442993164 and batch: 850, loss is 3.932573981285095 and perplexity is 51.0381800608142
At time: 349.0349702835083 and batch: 900, loss is 3.8912855625152587 and perplexity is 48.973804960161274
At time: 350.03864431381226 and batch: 950, loss is 3.9750014543533325 and perplexity is 53.250194350276914
At time: 351.0345187187195 and batch: 1000, loss is 3.9388825273513794 and perplexity is 51.361174512351745
At time: 352.03029894828796 and batch: 1050, loss is 3.896497106552124 and perplexity is 49.22970032717068
At time: 353.0284969806671 and batch: 1100, loss is 3.905122480392456 and perplexity is 49.656161445876975
At time: 354.0272114276886 and batch: 1150, loss is 3.898032088279724 and perplexity is 49.305325044058684
At time: 355.03753185272217 and batch: 1200, loss is 3.940913324356079 and perplexity is 51.46558461368635
At time: 356.0427873134613 and batch: 1250, loss is 3.9609550857543945 and perplexity is 52.50745112693801
At time: 357.04318261146545 and batch: 1300, loss is 3.9404630851745606 and perplexity is 51.442418006641965
At time: 358.0380685329437 and batch: 1350, loss is 3.822696342468262 and perplexity is 45.72733881086114
At time: 359.0365753173828 and batch: 1400, loss is 3.8468503379821777 and perplexity is 46.84528381499423
At time: 360.0334985256195 and batch: 1450, loss is 3.782768726348877 and perplexity is 43.93752446343989
At time: 361.02935886383057 and batch: 1500, loss is 3.7837993049621583 and perplexity is 43.982828877342676
At time: 362.02508783340454 and batch: 1550, loss is 3.802414307594299 and perplexity is 44.80923728635102
At time: 363.02119541168213 and batch: 1600, loss is 3.876746654510498 and perplexity is 48.26693035914311
At time: 364.0173647403717 and batch: 1650, loss is 3.8360500144958496 and perplexity is 46.34206196695542
At time: 365.0133283138275 and batch: 1700, loss is 3.832816743850708 and perplexity is 46.19246750837031
At time: 366.009724855423 and batch: 1750, loss is 3.821923923492432 and perplexity is 45.6920317843135
At time: 367.01180148124695 and batch: 1800, loss is 3.778613796234131 and perplexity is 43.755345851665304
At time: 368.0149073600769 and batch: 1850, loss is 3.8151595067977904 and perplexity is 45.38399486132992
At time: 369.01451778411865 and batch: 1900, loss is 3.914210247993469 and perplexity is 50.10948181626346
At time: 370.01030564308167 and batch: 1950, loss is 3.837416367530823 and perplexity is 46.40542486215518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382491994458576 and perplexity of 80.03723744650857
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 373.26807403564453 and batch: 50, loss is 3.9905944728851317 and perplexity is 54.08703308270005
At time: 374.2639591693878 and batch: 100, loss is 4.000774202346801 and perplexity is 54.64043641602718
At time: 375.26203966140747 and batch: 150, loss is 3.965531792640686 and perplexity is 52.748313096981384
At time: 376.2567410469055 and batch: 200, loss is 3.964364776611328 and perplexity is 52.68679087576717
At time: 377.2562277317047 and batch: 250, loss is 3.949418878555298 and perplexity is 51.9051948470689
At time: 378.2498333454132 and batch: 300, loss is 3.9755242586135866 and perplexity is 53.27804105729686
At time: 379.244286775589 and batch: 350, loss is 3.9883412313461304 and perplexity is 53.965299132537965
At time: 380.24021673202515 and batch: 400, loss is 3.9382468843460083 and perplexity is 51.328537514863804
At time: 381.2341568470001 and batch: 450, loss is 3.9672149562835695 and perplexity is 52.83717190078524
At time: 382.2301700115204 and batch: 500, loss is 3.968490300178528 and perplexity is 52.90460045355295
At time: 383.23374700546265 and batch: 550, loss is 3.937839455604553 and perplexity is 51.307629053066755
At time: 384.2564239501953 and batch: 600, loss is 3.909574418067932 and perplexity is 49.87772039922648
At time: 385.2640564441681 and batch: 650, loss is 3.9553083181381226 and perplexity is 52.21178930472489
At time: 386.2664065361023 and batch: 700, loss is 3.988161954879761 and perplexity is 53.95562529157483
At time: 387.26348304748535 and batch: 750, loss is 3.9275898218154905 and perplexity is 50.784430521737114
At time: 388.2593107223511 and batch: 800, loss is 3.929488487243652 and perplexity is 50.880944759386864
At time: 389.2543544769287 and batch: 850, loss is 3.9316486120224 and perplexity is 50.99097274323102
At time: 390.249347448349 and batch: 900, loss is 3.897147331237793 and perplexity is 49.26172110281271
At time: 391.25038385391235 and batch: 950, loss is 3.989308085441589 and perplexity is 54.01750093471348
At time: 392.2461767196655 and batch: 1000, loss is 3.9411970520019532 and perplexity is 51.48018889457348
At time: 393.24335074424744 and batch: 1050, loss is 3.8901489067077635 and perplexity is 48.91817022510046
At time: 394.25231289863586 and batch: 1100, loss is 3.899739456176758 and perplexity is 49.38957927921238
At time: 395.2565088272095 and batch: 1150, loss is 3.8889851236343382 and perplexity is 48.861273200928125
At time: 396.2514081001282 and batch: 1200, loss is 3.9234758615493774 and perplexity is 50.57593455854796
At time: 397.2457275390625 and batch: 1250, loss is 3.9337530279159547 and perplexity is 51.098391944394045
At time: 398.2412164211273 and batch: 1300, loss is 3.923921575546265 and perplexity is 50.59848198496486
At time: 399.2454788684845 and batch: 1350, loss is 3.813530592918396 and perplexity is 45.31012841956689
At time: 400.2518467903137 and batch: 1400, loss is 3.8262223196029663 and perplexity is 45.8888569492308
At time: 401.25239658355713 and batch: 1450, loss is 3.758624401092529 and perplexity is 42.88938678734251
At time: 402.2513978481293 and batch: 1500, loss is 3.7573782873153685 and perplexity is 42.835975017055716
At time: 403.24826741218567 and batch: 1550, loss is 3.7707379150390623 and perplexity is 43.4120874516213
At time: 404.24477458000183 and batch: 1600, loss is 3.8426801538467408 and perplexity is 46.65033711993365
At time: 405.24174427986145 and batch: 1650, loss is 3.8042878770828246 and perplexity is 44.89326920136967
At time: 406.24490785598755 and batch: 1700, loss is 3.7850584745407105 and perplexity is 44.038245599647155
At time: 407.24636030197144 and batch: 1750, loss is 3.770115714073181 and perplexity is 43.38508481028388
At time: 408.26037192344666 and batch: 1800, loss is 3.73267548084259 and perplexity is 41.79076912623342
At time: 409.2662332057953 and batch: 1850, loss is 3.757815718650818 and perplexity is 42.85471691366028
At time: 410.2718029022217 and batch: 1900, loss is 3.8644421195983885 and perplexity is 47.6766671338832
At time: 411.2816834449768 and batch: 1950, loss is 3.788872117996216 and perplexity is 44.20651241765723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.352820675872093 and perplexity of 77.69731306379217
finished 10 epochs...
Completing Train Step...
At time: 414.71809244155884 and batch: 50, loss is 3.980720157623291 and perplexity is 53.55558880868752
At time: 415.7672498226166 and batch: 100, loss is 3.972021698951721 and perplexity is 53.09175796409254
At time: 416.76776003837585 and batch: 150, loss is 3.9285781717300416 and perplexity is 50.83464812149615
At time: 417.76824426651 and batch: 200, loss is 3.9257036685943603 and perplexity is 50.68873358244117
At time: 418.76885652542114 and batch: 250, loss is 3.906989879608154 and perplexity is 49.748975956716215
At time: 419.7664005756378 and batch: 300, loss is 3.9318981313705446 and perplexity is 51.003697564989764
At time: 420.7659227848053 and batch: 350, loss is 3.9477054262161255 and perplexity is 51.81633392076471
At time: 421.7684180736542 and batch: 400, loss is 3.898476119041443 and perplexity is 49.327222986415016
At time: 422.7773554325104 and batch: 450, loss is 3.9295534181594847 and perplexity is 50.88424861298847
At time: 423.78624153137207 and batch: 500, loss is 3.9318798828125 and perplexity is 51.00276682954657
At time: 424.79886269569397 and batch: 550, loss is 3.903065252304077 and perplexity is 49.55411240086122
At time: 425.7990252971649 and batch: 600, loss is 3.8773196744918823 and perplexity is 48.2945962004619
At time: 426.80084133148193 and batch: 650, loss is 3.9243234157562257 and perplexity is 50.61881857534562
At time: 427.80922412872314 and batch: 700, loss is 3.9593719387054445 and perplexity is 52.42438987707322
At time: 428.81605672836304 and batch: 750, loss is 3.900194525718689 and perplexity is 49.41206008720867
At time: 429.8220920562744 and batch: 800, loss is 3.9016369676589964 and perplexity is 49.48338554408378
At time: 430.82334089279175 and batch: 850, loss is 3.905905566215515 and perplexity is 49.695061711067986
At time: 431.82937836647034 and batch: 900, loss is 3.870656714439392 and perplexity is 47.973880878429696
At time: 432.8298149108887 and batch: 950, loss is 3.9655935955047608 and perplexity is 52.751573194546545
At time: 433.83559226989746 and batch: 1000, loss is 3.9184740591049194 and perplexity is 50.32359532702041
At time: 434.8660399913788 and batch: 1050, loss is 3.870093469619751 and perplexity is 47.9468674468487
At time: 435.8679778575897 and batch: 1100, loss is 3.879121766090393 and perplexity is 48.381705952830345
At time: 436.87449169158936 and batch: 1150, loss is 3.8707157707214357 and perplexity is 47.976714121129156
At time: 437.8758451938629 and batch: 1200, loss is 3.9069333267211914 and perplexity is 49.746162588055235
At time: 438.8786425590515 and batch: 1250, loss is 3.91839506149292 and perplexity is 50.3196200401835
At time: 439.87907576560974 and batch: 1300, loss is 3.909620723724365 and perplexity is 49.880030073286036
At time: 440.8801543712616 and batch: 1350, loss is 3.799148006439209 and perplexity is 44.66311559148523
At time: 441.8819558620453 and batch: 1400, loss is 3.8142406272888185 and perplexity is 45.34231159230035
At time: 442.8825571537018 and batch: 1450, loss is 3.7482159471511842 and perplexity is 42.44528977135952
At time: 443.88902378082275 and batch: 1500, loss is 3.749301209449768 and perplexity is 42.49137904905493
At time: 444.8922595977783 and batch: 1550, loss is 3.7644491243362426 and perplexity is 43.139934572857136
At time: 445.9031777381897 and batch: 1600, loss is 3.8380849599838256 and perplexity is 46.43646155328897
At time: 446.908358335495 and batch: 1650, loss is 3.800969748497009 and perplexity is 44.74455442534213
At time: 447.9091398715973 and batch: 1700, loss is 3.783475008010864 and perplexity is 43.968567692582816
At time: 448.9089586734772 and batch: 1750, loss is 3.7703215360641478 and perplexity is 43.39401533383533
At time: 449.90932393074036 and batch: 1800, loss is 3.7348712491989136 and perplexity is 41.882632793424705
At time: 450.9226551055908 and batch: 1850, loss is 3.76152446269989 and perplexity is 43.01394918333773
At time: 451.9286425113678 and batch: 1900, loss is 3.869655156135559 and perplexity is 47.92585629339431
At time: 452.92736196517944 and batch: 1950, loss is 3.79361909866333 and perplexity is 44.416858737428946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351399834211483 and perplexity of 77.58699587466171
finished 11 epochs...
Completing Train Step...
At time: 456.20584750175476 and batch: 50, loss is 3.9674124193191527 and perplexity is 52.847606319312476
At time: 457.2020785808563 and batch: 100, loss is 3.9561052322387695 and perplexity is 52.253414199371676
At time: 458.1984691619873 and batch: 150, loss is 3.912095475196838 and perplexity is 50.00362361973446
At time: 459.19348764419556 and batch: 200, loss is 3.9084511947631837 and perplexity is 49.8217280331384
At time: 460.1973497867584 and batch: 250, loss is 3.889361801147461 and perplexity is 48.879681610604784
At time: 461.2248148918152 and batch: 300, loss is 3.9135751056671144 and perplexity is 50.07766526849792
At time: 462.2208080291748 and batch: 350, loss is 3.929732851982117 and perplexity is 50.89337978742513
At time: 463.21768140792847 and batch: 400, loss is 3.8810685157775877 and perplexity is 48.4759847626066
At time: 464.22088384628296 and batch: 450, loss is 3.9125438833236696 and perplexity is 50.02605067879856
At time: 465.21881651878357 and batch: 500, loss is 3.915248908996582 and perplexity is 50.16155561974519
At time: 466.21412420272827 and batch: 550, loss is 3.8869424152374266 and perplexity is 48.76156573918188
At time: 467.20970034599304 and batch: 600, loss is 3.8622357082366943 and perplexity is 47.571588759519805
At time: 468.2060122489929 and batch: 650, loss is 3.909327201843262 and perplexity is 49.86539134152858
At time: 469.2017731666565 and batch: 700, loss is 3.9451272439956666 and perplexity is 51.68291403421427
At time: 470.19733786582947 and batch: 750, loss is 3.886500720977783 and perplexity is 48.74003279134347
At time: 471.19903206825256 and batch: 800, loss is 3.8873835754394532 and perplexity is 48.78308214711699
At time: 472.2057523727417 and batch: 850, loss is 3.8922437906265257 and perplexity is 49.020755527874215
At time: 473.19872522354126 and batch: 900, loss is 3.856923246383667 and perplexity is 47.319536610450044
At time: 474.1970212459564 and batch: 950, loss is 3.9528351497650145 and perplexity is 52.08282030547532
At time: 475.1923260688782 and batch: 1000, loss is 3.9059013175964354 and perplexity is 49.69485057612915
At time: 476.19777393341064 and batch: 1050, loss is 3.8591834926605224 and perplexity is 47.426611378985285
At time: 477.19240069389343 and batch: 1100, loss is 3.8679343128204344 and perplexity is 47.84345432474341
At time: 478.18705320358276 and batch: 1150, loss is 3.860356068611145 and perplexity is 47.48225529989398
At time: 479.18278980255127 and batch: 1200, loss is 3.896892590522766 and perplexity is 49.24917373498609
At time: 480.17778992652893 and batch: 1250, loss is 3.9090189599990843 and perplexity is 49.85002311002852
At time: 481.17358112335205 and batch: 1300, loss is 3.900434913635254 and perplexity is 49.423939577171936
At time: 482.1816279888153 and batch: 1350, loss is 3.7901634979248047 and perplexity is 44.26363669714162
At time: 483.17953515052795 and batch: 1400, loss is 3.8060789203643797 and perplexity is 44.97374703769055
At time: 484.1765937805176 and batch: 1450, loss is 3.7407167196273803 and perplexity is 42.12817343600073
At time: 485.1849286556244 and batch: 1500, loss is 3.7425412464141847 and perplexity is 42.20510757977476
At time: 486.1830198764801 and batch: 1550, loss is 3.7583942461013793 and perplexity is 42.87951671677261
At time: 487.18027210235596 and batch: 1600, loss is 3.8327670669555665 and perplexity is 46.19017286700137
At time: 488.1764771938324 and batch: 1650, loss is 3.7958638286590576 and perplexity is 44.51667458044851
At time: 489.1737127304077 and batch: 1700, loss is 3.7793131065368653 and perplexity is 43.78595511725905
At time: 490.17607593536377 and batch: 1750, loss is 3.7670527935028075 and perplexity is 43.2524030421588
At time: 491.17114901542664 and batch: 1800, loss is 3.7324885368347167 and perplexity is 41.78295732256854
At time: 492.16873002052307 and batch: 1850, loss is 3.7597163009643553 and perplexity is 42.93624327992206
At time: 493.1704754829407 and batch: 1900, loss is 3.868830919265747 and perplexity is 47.88637031075681
At time: 494.1705286502838 and batch: 1950, loss is 3.792354927062988 and perplexity is 44.36074368303901
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.351581236373547 and perplexity of 77.60107160010635
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 497.41153025627136 and batch: 50, loss is 3.967365388870239 and perplexity is 52.8451209311082
At time: 498.4329833984375 and batch: 100, loss is 3.9764288854599 and perplexity is 53.32625961016668
At time: 499.42844009399414 and batch: 150, loss is 3.942451629638672 and perplexity is 51.5448153192516
At time: 500.43152499198914 and batch: 200, loss is 3.9499631404876707 and perplexity is 51.933452557817134
At time: 501.4285800457001 and batch: 250, loss is 3.934024758338928 and perplexity is 51.11227881870802
At time: 502.42373847961426 and batch: 300, loss is 3.948917565345764 and perplexity is 51.87918060843419
At time: 503.41887974739075 and batch: 350, loss is 3.96088191986084 and perplexity is 52.50360951289731
At time: 504.4143581390381 and batch: 400, loss is 3.911324667930603 and perplexity is 49.96509531416683
At time: 505.41942739486694 and batch: 450, loss is 3.9470070791244507 and perplexity is 51.78016076684842
At time: 506.41416573524475 and batch: 500, loss is 3.9484128522872926 and perplexity is 51.85300311513535
At time: 507.41048884391785 and batch: 550, loss is 3.9240591096878052 and perplexity is 50.60544148232119
At time: 508.40511775016785 and batch: 600, loss is 3.8989666366577147 and perplexity is 49.35142479347271
At time: 509.40099811553955 and batch: 650, loss is 3.931108856201172 and perplexity is 50.96345749528842
At time: 510.39525961875916 and batch: 700, loss is 3.9702833700180054 and perplexity is 52.99954719462611
At time: 511.4283664226532 and batch: 750, loss is 3.9121993160247803 and perplexity is 50.00881630701305
At time: 512.4359560012817 and batch: 800, loss is 3.914024872779846 and perplexity is 50.100193621294395
At time: 513.4450972080231 and batch: 850, loss is 3.911896381378174 and perplexity is 49.993669198325726
At time: 514.4562449455261 and batch: 900, loss is 3.8711533069610597 and perplexity is 47.997710265167235
At time: 515.4680037498474 and batch: 950, loss is 3.968906717300415 and perplexity is 52.92663542255919
At time: 516.4752554893494 and batch: 1000, loss is 3.919546546936035 and perplexity is 50.37759572283425
At time: 517.4889602661133 and batch: 1050, loss is 3.8708616733551025 and perplexity is 47.98371456075297
At time: 518.4937062263489 and batch: 1100, loss is 3.8855045938491823 and perplexity is 48.69150569602184
At time: 519.4880604743958 and batch: 1150, loss is 3.8800535726547243 and perplexity is 48.42680935459019
At time: 520.4834957122803 and batch: 1200, loss is 3.9165087127685547 and perplexity is 50.22478915928558
At time: 521.4825389385223 and batch: 1250, loss is 3.9209528732299805 and perplexity is 50.44849290092312
At time: 522.4813888072968 and batch: 1300, loss is 3.903531584739685 and perplexity is 49.577226479795
At time: 523.4763181209564 and batch: 1350, loss is 3.7911667680740355 and perplexity is 44.30806736679173
At time: 524.4715151786804 and batch: 1400, loss is 3.8119407653808595 and perplexity is 45.2381503611865
At time: 525.4674842357635 and batch: 1450, loss is 3.7447631645202635 and perplexity is 42.29898813130049
At time: 526.4635577201843 and batch: 1500, loss is 3.743909087181091 and perplexity is 42.26287694713478
At time: 527.4603774547577 and batch: 1550, loss is 3.7580094003677367 and perplexity is 42.86301789265817
At time: 528.4590644836426 and batch: 1600, loss is 3.8307775497436523 and perplexity is 46.0983680769478
At time: 529.4550449848175 and batch: 1650, loss is 3.7935673284530638 and perplexity is 44.41455932683374
At time: 530.4585757255554 and batch: 1700, loss is 3.773581414222717 and perplexity is 43.53570535726505
At time: 531.4616222381592 and batch: 1750, loss is 3.755250210762024 and perplexity is 42.74491371006428
At time: 532.4577670097351 and batch: 1800, loss is 3.718065733909607 and perplexity is 41.184654933598296
At time: 533.4574453830719 and batch: 1850, loss is 3.745878520011902 and perplexity is 42.346192860136625
At time: 534.4636244773865 and batch: 1900, loss is 3.8563000059127805 and perplexity is 47.29005434839458
At time: 535.4731876850128 and batch: 1950, loss is 3.7899099349975587 and perplexity is 44.2524145026765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338593522892442 and perplexity of 76.59972777525937
finished 13 epochs...
Completing Train Step...
At time: 538.9549705982208 and batch: 50, loss is 3.9728266954422 and perplexity is 53.13451384978705
At time: 539.9671258926392 and batch: 100, loss is 3.967589268684387 and perplexity is 52.85695321141581
At time: 540.977130651474 and batch: 150, loss is 3.926499605178833 and perplexity is 50.72909466021844
At time: 541.9869930744171 and batch: 200, loss is 3.925449404716492 and perplexity is 50.675846906853735
At time: 542.994015455246 and batch: 250, loss is 3.9117421960830687 and perplexity is 49.98596150390883
At time: 543.988865852356 and batch: 300, loss is 3.9287284421920776 and perplexity is 50.842287641539535
At time: 544.9906723499298 and batch: 350, loss is 3.940790390968323 and perplexity is 51.45925816389086
At time: 545.9962310791016 and batch: 400, loss is 3.8915497922897337 and perplexity is 48.98674700736289
At time: 546.9998013973236 and batch: 450, loss is 3.927808737754822 and perplexity is 50.7955492600383
At time: 547.9969272613525 and batch: 500, loss is 3.92954119682312 and perplexity is 50.883626743270554
At time: 548.9911909103394 and batch: 550, loss is 3.9072896528244017 and perplexity is 49.76389160278768
At time: 549.9861767292023 and batch: 600, loss is 3.8823539066314696 and perplexity is 48.53833541394706
At time: 550.9806225299835 and batch: 650, loss is 3.915630564689636 and perplexity is 50.1807037167776
At time: 551.9812054634094 and batch: 700, loss is 3.955373167991638 and perplexity is 52.2151753414039
At time: 552.9843006134033 and batch: 750, loss is 3.898682703971863 and perplexity is 49.337414299993135
At time: 553.9816386699677 and batch: 800, loss is 3.8997876977920534 and perplexity is 49.39196196976753
At time: 554.991461277008 and batch: 850, loss is 3.898782353401184 and perplexity is 49.34233099014092
At time: 555.999443769455 and batch: 900, loss is 3.859102602005005 and perplexity is 47.422775164460916
At time: 557.006112575531 and batch: 950, loss is 3.95809877872467 and perplexity is 52.357687712138734
At time: 558.0163938999176 and batch: 1000, loss is 3.909492464065552 and perplexity is 49.87363288790642
At time: 559.0124440193176 and batch: 1050, loss is 3.8616571855545043 and perplexity is 47.54407547569135
At time: 560.0067403316498 and batch: 1100, loss is 3.8763110733032224 and perplexity is 48.24591076954723
At time: 561.0000355243683 and batch: 1150, loss is 3.871999568939209 and perplexity is 48.03834609425627
At time: 562.02951836586 and batch: 1200, loss is 3.908576512336731 and perplexity is 49.827971962434304
At time: 563.020473241806 and batch: 1250, loss is 3.914444031715393 and perplexity is 50.12119796689544
At time: 564.0144305229187 and batch: 1300, loss is 3.898479266166687 and perplexity is 49.32737822560797
At time: 565.0094294548035 and batch: 1350, loss is 3.786896653175354 and perplexity is 44.11927020785294
At time: 566.0078158378601 and batch: 1400, loss is 3.808472766876221 and perplexity is 45.081536249101184
At time: 567.0027487277985 and batch: 1450, loss is 3.7428286361694334 and perplexity is 42.21723863839985
At time: 567.9974946975708 and batch: 1500, loss is 3.7434779262542723 and perplexity is 42.24465877370472
At time: 568.9903140068054 and batch: 1550, loss is 3.758747658729553 and perplexity is 42.894673557622035
At time: 569.9865987300873 and batch: 1600, loss is 3.832135252952576 and perplexity is 46.160998486345065
At time: 570.9831786155701 and batch: 1650, loss is 3.795047016143799 and perplexity is 44.48032764984824
At time: 571.9770090579987 and batch: 1700, loss is 3.7758617877960203 and perplexity is 43.63509631043812
At time: 572.9729428291321 and batch: 1750, loss is 3.7587618160247804 and perplexity is 42.89528083447796
At time: 573.96812915802 and batch: 1800, loss is 3.7227471256256104 and perplexity is 41.37790843075527
At time: 574.9643068313599 and batch: 1850, loss is 3.7510136699676515 and perplexity is 42.564206197037365
At time: 575.9604830741882 and batch: 1900, loss is 3.861993408203125 and perplexity is 47.560063558301145
At time: 576.9534168243408 and batch: 1950, loss is 3.7948750591278078 and perplexity is 44.47267960302177
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33737423918968 and perplexity of 76.50638789101052
finished 14 epochs...
Completing Train Step...
At time: 580.2500803470612 and batch: 50, loss is 3.9693012475967406 and perplexity is 52.94752070338307
At time: 581.2770147323608 and batch: 100, loss is 3.961986389160156 and perplexity is 52.561630172828345
At time: 582.2829806804657 and batch: 150, loss is 3.920179409980774 and perplexity is 50.4094879320859
At time: 583.287867307663 and batch: 200, loss is 3.9180208253860473 and perplexity is 50.30079214473924
At time: 584.2853672504425 and batch: 250, loss is 3.9041470813751222 and perplexity is 49.607750488636356
At time: 585.2850847244263 and batch: 300, loss is 3.921025528907776 and perplexity is 50.452158403526774
At time: 586.2819437980652 and batch: 350, loss is 3.932976713180542 and perplexity is 51.0587389033832
At time: 587.2808001041412 and batch: 400, loss is 3.883546018600464 and perplexity is 48.59623304792362
At time: 588.312609910965 and batch: 450, loss is 3.9199282121658325 and perplexity is 50.39682676915986
At time: 589.3200099468231 and batch: 500, loss is 3.9216364288330077 and perplexity is 50.482989039581064
At time: 590.3276546001434 and batch: 550, loss is 3.8995622301101687 and perplexity is 49.380826933940995
At time: 591.3288655281067 and batch: 600, loss is 3.8752094507217407 and perplexity is 48.19279124898306
At time: 592.330025434494 and batch: 650, loss is 3.908736672401428 and perplexity is 49.83595305275645
At time: 593.3386552333832 and batch: 700, loss is 3.948847827911377 and perplexity is 51.87556281362978
At time: 594.3398578166962 and batch: 750, loss is 3.892966933250427 and perplexity is 49.05621734608305
At time: 595.3373551368713 and batch: 800, loss is 3.893635573387146 and perplexity is 49.08902927041857
At time: 596.3452792167664 and batch: 850, loss is 3.8930660247802735 and perplexity is 49.06107864256103
At time: 597.362587928772 and batch: 900, loss is 3.85337938785553 and perplexity is 47.152139657838546
At time: 598.3749067783356 and batch: 950, loss is 3.953062505722046 and perplexity is 52.09466299113233
At time: 599.3928232192993 and batch: 1000, loss is 3.9046443367004393 and perplexity is 49.632424340837616
At time: 600.3856918811798 and batch: 1050, loss is 3.857236156463623 and perplexity is 47.33434568726817
At time: 601.3786725997925 and batch: 1100, loss is 3.872044630050659 and perplexity is 48.04051080429526
At time: 602.3766856193542 and batch: 1150, loss is 3.8682861614227293 and perplexity is 47.86029093907245
At time: 603.372138261795 and batch: 1200, loss is 3.904935350418091 and perplexity is 49.64687015902479
At time: 604.3631701469421 and batch: 1250, loss is 3.9114917135238647 and perplexity is 49.97344246031355
At time: 605.3548941612244 and batch: 1300, loss is 3.895928421020508 and perplexity is 49.20171206788216
At time: 606.3464362621307 and batch: 1350, loss is 3.784525465965271 and perplexity is 44.014779091575825
At time: 607.3377854824066 and batch: 1400, loss is 3.8063541936874388 and perplexity is 44.986128814596285
At time: 608.3289976119995 and batch: 1450, loss is 3.741213631629944 and perplexity is 42.14911263306547
At time: 609.3203465938568 and batch: 1500, loss is 3.7424029541015624 and perplexity is 42.19927134140583
At time: 610.3120892047882 and batch: 1550, loss is 3.7582129192352296 and perplexity is 42.87174221326883
At time: 611.3037617206573 and batch: 1600, loss is 3.831885657310486 and perplexity is 46.14947834003731
At time: 612.2955141067505 and batch: 1650, loss is 3.794853687286377 and perplexity is 44.47172915012179
At time: 613.3016855716705 and batch: 1700, loss is 3.776134419441223 and perplexity is 43.64699424033622
At time: 614.3068006038666 and batch: 1750, loss is 3.7594334268569947 and perplexity is 42.92409944609989
At time: 615.2981238365173 and batch: 1800, loss is 3.7238256549835205 and perplexity is 41.4225597943417
At time: 616.290164232254 and batch: 1850, loss is 3.752243881225586 and perplexity is 42.61660138465284
At time: 617.2824048995972 and batch: 1900, loss is 3.863391065597534 and perplexity is 47.62658270747386
At time: 618.2744379043579 and batch: 1950, loss is 3.795873990058899 and perplexity is 44.517126934476806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337092058048692 and perplexity of 76.48480227685242
finished 15 epochs...
Completing Train Step...
At time: 621.4863014221191 and batch: 50, loss is 3.9654954528808593 and perplexity is 52.74639627078089
At time: 622.4782199859619 and batch: 100, loss is 3.957200675010681 and perplexity is 52.310686187629685
At time: 623.4669463634491 and batch: 150, loss is 3.9150749683380126 and perplexity is 50.1528312445096
At time: 624.4582235813141 and batch: 200, loss is 3.9126551818847655 and perplexity is 50.03161881611351
At time: 625.4503185749054 and batch: 250, loss is 3.898603343963623 and perplexity is 49.33349903774742
At time: 626.4384605884552 and batch: 300, loss is 3.915384693145752 and perplexity is 50.16836722633968
At time: 627.4285268783569 and batch: 350, loss is 3.927300577163696 and perplexity is 50.76974352098488
At time: 628.4185798168182 and batch: 400, loss is 3.877885398864746 and perplexity is 48.321925360267144
At time: 629.4080076217651 and batch: 450, loss is 3.9143000650405884 and perplexity is 50.113982704078076
At time: 630.3966042995453 and batch: 500, loss is 3.9160651540756226 and perplexity is 50.20251645744372
At time: 631.3852128982544 and batch: 550, loss is 3.89411235332489 and perplexity is 49.112439515062064
At time: 632.374226808548 and batch: 600, loss is 3.870237350463867 and perplexity is 47.95376657892426
At time: 633.3641154766083 and batch: 650, loss is 3.9038869762420654 and perplexity is 49.59484893604762
At time: 634.3531258106232 and batch: 700, loss is 3.944284830093384 and perplexity is 51.63939396245181
At time: 635.3413734436035 and batch: 750, loss is 3.8888314247131346 and perplexity is 48.85376385305262
At time: 636.3298687934875 and batch: 800, loss is 3.88923369884491 and perplexity is 48.873420411888056
At time: 637.3187870979309 and batch: 850, loss is 3.888921928405762 and perplexity is 48.8581854991647
At time: 638.3507187366486 and batch: 900, loss is 3.849212474822998 and perplexity is 46.956069579768
At time: 639.33913397789 and batch: 950, loss is 3.9493223524093626 and perplexity is 51.900184880456564
At time: 640.3277449607849 and batch: 1000, loss is 3.900960259437561 and perplexity is 49.44991105776913
At time: 641.3165283203125 and batch: 1050, loss is 3.8538654327392576 and perplexity is 47.17506328458052
At time: 642.3055469989777 and batch: 1100, loss is 3.8687867593765257 and perplexity is 47.88425570063949
At time: 643.2947359085083 and batch: 1150, loss is 3.86538188457489 and perplexity is 47.72149305546848
At time: 644.2842621803284 and batch: 1200, loss is 3.902051010131836 and perplexity is 49.5038780094817
At time: 645.2724797725677 and batch: 1250, loss is 3.9090545272827146 and perplexity is 49.85179617147075
At time: 646.2609944343567 and batch: 1300, loss is 3.893661994934082 and perplexity is 49.09032629564412
At time: 647.2504591941833 and batch: 1350, loss is 3.7823201990127564 and perplexity is 43.91782170158053
At time: 648.2397074699402 and batch: 1400, loss is 3.8043161916732786 and perplexity is 44.89454035389725
At time: 649.2283227443695 and batch: 1450, loss is 3.7394531106948854 and perplexity is 42.07497351876135
At time: 650.2174737453461 and batch: 1500, loss is 3.740947151184082 and perplexity is 42.13788221514817
At time: 651.2065970897675 and batch: 1550, loss is 3.757076964378357 and perplexity is 42.82306949971566
At time: 652.1945824623108 and batch: 1600, loss is 3.830954432487488 and perplexity is 46.106522803973576
At time: 653.1823859214783 and batch: 1650, loss is 3.7939186191558836 and perplexity is 44.43016448940888
At time: 654.1719608306885 and batch: 1700, loss is 3.775564851760864 and perplexity is 43.622141401430895
At time: 655.1600193977356 and batch: 1750, loss is 3.7590693378448488 and perplexity is 42.90847409781672
At time: 656.1473090648651 and batch: 1800, loss is 3.723708667755127 and perplexity is 41.41771416732217
At time: 657.1353161334991 and batch: 1850, loss is 3.7522281646728515 and perplexity is 42.615931603853156
At time: 658.123687505722 and batch: 1900, loss is 3.863526668548584 and perplexity is 47.633041450539814
At time: 659.1123666763306 and batch: 1950, loss is 3.7957698106765747 and perplexity is 44.51248940926136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337129246911338 and perplexity of 76.4876467125491
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 662.2982876300812 and batch: 50, loss is 3.966170926094055 and perplexity is 52.78203708440674
At time: 663.312614440918 and batch: 100, loss is 3.9653496742248535 and perplexity is 52.73870753246398
At time: 664.3015780448914 and batch: 150, loss is 3.92768373966217 and perplexity is 50.789200310077184
At time: 665.2905130386353 and batch: 200, loss is 3.9280150270462038 and perplexity is 50.80602891878403
At time: 666.2811074256897 and batch: 250, loss is 3.919899792671204 and perplexity is 50.39539453716394
At time: 667.2716817855835 and batch: 300, loss is 3.934229016304016 and perplexity is 51.122719975078915
At time: 668.2606320381165 and batch: 350, loss is 3.9471663141250612 and perplexity is 51.78840663727791
At time: 669.2496342658997 and batch: 400, loss is 3.8969800806045534 and perplexity is 49.253482737718876
At time: 670.2501447200775 and batch: 450, loss is 3.9360052442550657 and perplexity is 51.21360627272804
At time: 671.239330291748 and batch: 500, loss is 3.9392407512664795 and perplexity is 51.379576609208506
At time: 672.2280988693237 and batch: 550, loss is 3.9201337718963623 and perplexity is 50.40718739211703
At time: 673.2174458503723 and batch: 600, loss is 3.892788643836975 and perplexity is 49.047471921497724
At time: 674.2067708969116 and batch: 650, loss is 3.9184048175811768 and perplexity is 50.32011096523241
At time: 675.2061054706573 and batch: 700, loss is 3.959251046180725 and perplexity is 52.418052543299964
At time: 676.1951217651367 and batch: 750, loss is 3.904641408920288 and perplexity is 49.6322790282235
At time: 677.1834826469421 and batch: 800, loss is 3.9024204206466675 and perplexity is 49.52216864071109
At time: 678.177031993866 and batch: 850, loss is 3.901460394859314 and perplexity is 49.47464889551044
At time: 679.1726791858673 and batch: 900, loss is 3.856945662498474 and perplexity is 47.320597342504016
At time: 680.1619589328766 and batch: 950, loss is 3.9570291328430174 and perplexity is 52.30171346875091
At time: 681.1514005661011 and batch: 1000, loss is 3.908253884315491 and perplexity is 49.811898655426695
At time: 682.1404602527618 and batch: 1050, loss is 3.8597118616104127 and perplexity is 47.45167674913497
At time: 683.12939286232 and batch: 1100, loss is 3.8725192451477053 and perplexity is 48.063316967639395
At time: 684.1180684566498 and batch: 1150, loss is 3.872112193107605 and perplexity is 48.04375667771178
At time: 685.1077184677124 and batch: 1200, loss is 3.9135597705841065 and perplexity is 50.0768973292324
At time: 686.0987777709961 and batch: 1250, loss is 3.9165484046936037 and perplexity is 50.226782717416306
At time: 687.088184595108 and batch: 1300, loss is 3.8976352548599245 and perplexity is 49.28576292501513
At time: 688.0769257545471 and batch: 1350, loss is 3.7797202491760253 and perplexity is 43.80378587616845
At time: 689.0679128170013 and batch: 1400, loss is 3.8023668050765993 and perplexity is 44.80710878531869
At time: 690.059662103653 and batch: 1450, loss is 3.732713027000427 and perplexity is 41.79233823850405
At time: 691.0596928596497 and batch: 1500, loss is 3.7355443096160887 and perplexity is 41.91083182448631
At time: 692.0611135959625 and batch: 1550, loss is 3.7543876504898073 and perplexity is 42.70805954241408
At time: 693.0648427009583 and batch: 1600, loss is 3.827154517173767 and perplexity is 45.93165437493462
At time: 694.0671887397766 and batch: 1650, loss is 3.7903750371932983 and perplexity is 44.27300118491292
At time: 695.0589287281036 and batch: 1700, loss is 3.773833384513855 and perplexity is 43.546676443754706
At time: 696.0490310192108 and batch: 1750, loss is 3.7553798389434814 and perplexity is 42.75045501464193
At time: 697.0401568412781 and batch: 1800, loss is 3.7153900861740112 and perplexity is 41.07460659583062
At time: 698.0319304466248 and batch: 1850, loss is 3.7440854263305665 and perplexity is 42.270330204041194
At time: 699.0240998268127 and batch: 1900, loss is 3.8528545475006104 and perplexity is 47.12739880519218
At time: 700.0155851840973 and batch: 1950, loss is 3.7893894386291502 and perplexity is 44.22938727494863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333119095203489 and perplexity of 76.18153383521906
finished 17 epochs...
Completing Train Step...
At time: 703.3257532119751 and batch: 50, loss is 3.96636944770813 and perplexity is 52.7925164997637
At time: 704.3257439136505 and batch: 100, loss is 3.960633411407471 and perplexity is 52.490563543184976
At time: 705.3279318809509 and batch: 150, loss is 3.9204467725753784 and perplexity is 50.42296734543728
At time: 706.3320648670197 and batch: 200, loss is 3.916668343544006 and perplexity is 50.23280722127366
At time: 707.330614566803 and batch: 250, loss is 3.9069904851913453 and perplexity is 49.749006083868956
At time: 708.329580783844 and batch: 300, loss is 3.9235996198654175 and perplexity is 50.58219413837062
At time: 709.3354852199554 and batch: 350, loss is 3.936009964942932 and perplexity is 51.213848036748416
At time: 710.337611913681 and batch: 400, loss is 3.88607572555542 and perplexity is 48.719322901637206
At time: 711.3352918624878 and batch: 450, loss is 3.9239868402481077 and perplexity is 50.6017843875693
At time: 712.3336129188538 and batch: 500, loss is 3.9276446390151976 and perplexity is 50.78721445831014
At time: 713.3312933444977 and batch: 550, loss is 3.9085340452194215 and perplexity is 49.82585595703433
At time: 714.3636245727539 and batch: 600, loss is 3.8834878110885622 and perplexity is 48.59340446443331
At time: 715.3629529476166 and batch: 650, loss is 3.9106939697265624 and perplexity is 49.93359235376202
At time: 716.3619165420532 and batch: 700, loss is 3.952175669670105 and perplexity is 52.048484045481565
At time: 717.36048579216 and batch: 750, loss is 3.8972963953018187 and perplexity is 49.269064802488444
At time: 718.3603830337524 and batch: 800, loss is 3.896402521133423 and perplexity is 49.22504413556008
At time: 719.3664646148682 and batch: 850, loss is 3.895805149078369 and perplexity is 49.19564725109755
At time: 720.373387336731 and batch: 900, loss is 3.8521110439300537 and perplexity is 47.092372438637305
At time: 721.3743095397949 and batch: 950, loss is 3.952209506034851 and perplexity is 52.050245206767684
At time: 722.3745896816254 and batch: 1000, loss is 3.903435678482056 and perplexity is 49.57247194153831
At time: 723.3803899288177 and batch: 1050, loss is 3.855626745223999 and perplexity is 47.25822652924342
At time: 724.3874487876892 and batch: 1100, loss is 3.868673253059387 and perplexity is 47.878820843577124
At time: 725.3879687786102 and batch: 1150, loss is 3.8677937841415404 and perplexity is 47.836731419704975
At time: 726.3831067085266 and batch: 1200, loss is 3.909077706336975 and perplexity is 49.8529517023512
At time: 727.3792021274567 and batch: 1250, loss is 3.913310112953186 and perplexity is 50.06439681017125
At time: 728.3770666122437 and batch: 1300, loss is 3.895374069213867 and perplexity is 49.17444456849957
At time: 729.3796074390411 and batch: 1350, loss is 3.7785986614227296 and perplexity is 43.75468362776937
At time: 730.385262966156 and batch: 1400, loss is 3.8021650457382203 and perplexity is 44.798069444611855
At time: 731.3873586654663 and batch: 1450, loss is 3.7338091564178466 and perplexity is 41.83817316578687
At time: 732.3921661376953 and batch: 1500, loss is 3.7378252124786377 and perplexity is 42.006535464628314
At time: 733.395295381546 and batch: 1550, loss is 3.756987361907959 and perplexity is 42.81923261879803
At time: 734.4033353328705 and batch: 1600, loss is 3.8300344705581666 and perplexity is 46.06412606298449
At time: 735.4050803184509 and batch: 1650, loss is 3.793739333152771 and perplexity is 44.422199496827126
At time: 736.4032025337219 and batch: 1700, loss is 3.777316327095032 and perplexity is 43.69861145427604
At time: 737.402087688446 and batch: 1750, loss is 3.7593069791793825 and perplexity is 42.91867213655391
At time: 738.3983917236328 and batch: 1800, loss is 3.7197276163101196 and perplexity is 41.253155891305845
At time: 739.397561788559 and batch: 1850, loss is 3.748070592880249 and perplexity is 42.4391206155776
At time: 740.3965380191803 and batch: 1900, loss is 3.856885299682617 and perplexity is 47.31774102420897
At time: 741.3962202072144 and batch: 1950, loss is 3.7928260231018065 and perplexity is 44.38164677696291
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332351755541424 and perplexity of 76.12309914528525
finished 18 epochs...
Completing Train Step...
At time: 744.6672053337097 and batch: 50, loss is 3.966018085479736 and perplexity is 52.773970461903225
At time: 745.6877830028534 and batch: 100, loss is 3.9586511945724485 and perplexity is 52.38661891887676
At time: 746.6817805767059 and batch: 150, loss is 3.9176844692230226 and perplexity is 50.283876008379174
At time: 747.681764125824 and batch: 200, loss is 3.9126836347579954 and perplexity is 50.03304237967331
At time: 748.6812705993652 and batch: 250, loss is 3.90263379573822 and perplexity is 49.532736565404534
At time: 749.6866862773895 and batch: 300, loss is 3.9194598627090453 and perplexity is 50.37322896915848
At time: 750.6893661022186 and batch: 350, loss is 3.9317823314666747 and perplexity is 50.99779168367157
At time: 751.6857671737671 and batch: 400, loss is 3.8817729806900023 and perplexity is 48.510146424399856
At time: 752.6812286376953 and batch: 450, loss is 3.9193918561935424 and perplexity is 50.36980337786424
At time: 753.6904039382935 and batch: 500, loss is 3.923166608810425 and perplexity is 50.56029623048317
At time: 754.6931805610657 and batch: 550, loss is 3.9041744565963743 and perplexity is 49.60910853037006
At time: 755.6886098384857 and batch: 600, loss is 3.8797793197631836 and perplexity is 48.41352998313285
At time: 756.680184841156 and batch: 650, loss is 3.907484893798828 and perplexity is 49.773608502013026
At time: 757.6745233535767 and batch: 700, loss is 3.9489908361434938 and perplexity is 51.882981976645866
At time: 758.6705508232117 and batch: 750, loss is 3.89447359085083 and perplexity is 49.13018397599499
At time: 759.667418718338 and batch: 800, loss is 3.8936319303512574 and perplexity is 49.08885043764895
At time: 760.6625308990479 and batch: 850, loss is 3.8932949686050415 and perplexity is 49.07231215942579
At time: 761.6546361446381 and batch: 900, loss is 3.849899034500122 and perplexity is 46.98831879297565
At time: 762.6475772857666 and batch: 950, loss is 3.9501975774765015 and perplexity is 51.945629107315405
At time: 763.6400458812714 and batch: 1000, loss is 3.901624836921692 and perplexity is 49.48278527777366
At time: 764.6581115722656 and batch: 1050, loss is 3.854105968475342 and perplexity is 47.186411937976125
At time: 765.6482264995575 and batch: 1100, loss is 3.8671346426010134 and perplexity is 47.805210632334614
At time: 766.6398558616638 and batch: 1150, loss is 3.8662321758270264 and perplexity is 47.76208747964852
At time: 767.6320192813873 and batch: 1200, loss is 3.9073353099822996 and perplexity is 49.766163732513306
At time: 768.6245110034943 and batch: 1250, loss is 3.912101345062256 and perplexity is 50.00391713513696
At time: 769.6170592308044 and batch: 1300, loss is 3.8945680809020997 and perplexity is 49.1348265089309
At time: 770.6097621917725 and batch: 1350, loss is 3.7781343555450437 and perplexity is 43.734372786571065
At time: 771.6020183563232 and batch: 1400, loss is 3.8020166683197023 and perplexity is 44.79142291582266
At time: 772.5958683490753 and batch: 1450, loss is 3.734202766418457 and perplexity is 41.85464433054712
At time: 773.5882663726807 and batch: 1500, loss is 3.7386729097366334 and perplexity is 42.0421593865768
At time: 774.5813980102539 and batch: 1550, loss is 3.7579822874069215 and perplexity is 42.86185576508806
At time: 775.5730104446411 and batch: 1600, loss is 3.831182951927185 and perplexity is 46.1170602446903
At time: 776.5651202201843 and batch: 1650, loss is 3.7950642013549807 and perplexity is 44.48109206024059
At time: 777.557567358017 and batch: 1700, loss is 3.778574366569519 and perplexity is 43.75362062706613
At time: 778.5498239994049 and batch: 1750, loss is 3.7608366441726684 and perplexity is 42.984373564655705
At time: 779.5422723293304 and batch: 1800, loss is 3.7214791774749756 and perplexity is 41.32547663570666
At time: 780.5325105190277 and batch: 1850, loss is 3.749639325141907 and perplexity is 42.50574848022021
At time: 781.5229339599609 and batch: 1900, loss is 3.858503317832947 and perplexity is 47.39436395995267
At time: 782.5157542228699 and batch: 1950, loss is 3.794112892150879 and perplexity is 44.43879690902824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331963401617005 and perplexity of 76.09354218064634
finished 19 epochs...
Completing Train Step...
At time: 785.7560555934906 and batch: 50, loss is 3.9651263618469237 and perplexity is 52.72693164117604
At time: 786.7480690479279 and batch: 100, loss is 3.9569957876205444 and perplexity is 52.299969485556495
At time: 787.7404613494873 and batch: 150, loss is 3.9157183504104616 and perplexity is 50.18510905938517
At time: 788.7327566146851 and batch: 200, loss is 3.9102847146987916 and perplexity is 49.91316096114683
At time: 789.7248749732971 and batch: 250, loss is 3.900077896118164 and perplexity is 49.406297514429404
At time: 790.7435290813446 and batch: 300, loss is 3.9168789482116697 and perplexity is 50.24338759904367
At time: 791.7360692024231 and batch: 350, loss is 3.929245262145996 and perplexity is 50.86857074152577
At time: 792.7288625240326 and batch: 400, loss is 3.879142374992371 and perplexity is 48.38270305694042
At time: 793.7226366996765 and batch: 450, loss is 3.9166855716705324 and perplexity is 50.23367264588704
At time: 794.7407670021057 and batch: 500, loss is 3.920506157875061 and perplexity is 50.4259618173769
At time: 795.7356677055359 and batch: 550, loss is 3.9015818357467653 and perplexity is 49.48065750561675
At time: 796.7309167385101 and batch: 600, loss is 3.877472677230835 and perplexity is 48.30198597127036
At time: 797.726286649704 and batch: 650, loss is 3.905367488861084 and perplexity is 49.66832911648108
At time: 798.7348477840424 and batch: 700, loss is 3.946905479431152 and perplexity is 51.7749001856368
At time: 799.7257483005524 and batch: 750, loss is 3.892651734352112 and perplexity is 49.04075731704011
At time: 800.7153775691986 and batch: 800, loss is 3.891757597923279 and perplexity is 48.996927787135135
At time: 801.704790353775 and batch: 850, loss is 3.8916079330444338 and perplexity is 48.98959521660191
At time: 802.6950302124023 and batch: 900, loss is 3.8483265256881714 and perplexity is 46.91448731315536
At time: 803.6844823360443 and batch: 950, loss is 3.948832082748413 and perplexity is 51.87474603086962
At time: 804.6756889820099 and batch: 1000, loss is 3.90040030002594 and perplexity is 49.42222886584377
At time: 805.6717901229858 and batch: 1050, loss is 3.853038640022278 and perplexity is 47.13607540550197
At time: 806.6617994308472 and batch: 1100, loss is 3.8660734367370604 and perplexity is 47.75450637107218
At time: 807.6520545482635 and batch: 1150, loss is 3.865246605873108 and perplexity is 47.71503779048062
At time: 808.6431696414948 and batch: 1200, loss is 3.9062502908706667 and perplexity is 49.71219577717691
At time: 809.6345283985138 and batch: 1250, loss is 3.9113116693496703 and perplexity is 49.9644458430527
At time: 810.6254553794861 and batch: 1300, loss is 3.894014983177185 and perplexity is 49.10765766238095
At time: 811.6152894496918 and batch: 1350, loss is 3.777706093788147 and perplexity is 43.71564703729205
At time: 812.6058719158173 and batch: 1400, loss is 3.8017433500289917 and perplexity is 44.77918227354472
At time: 813.5953164100647 and batch: 1450, loss is 3.734180474281311 and perplexity is 41.85371131147504
At time: 814.5839700698853 and batch: 1500, loss is 3.7389151000976564 and perplexity is 42.05234282545241
At time: 815.5738983154297 and batch: 1550, loss is 3.758314681053162 and perplexity is 42.87610514168037
At time: 816.565890789032 and batch: 1600, loss is 3.8315929889678957 and perplexity is 46.135973824968545
At time: 817.5575902462006 and batch: 1650, loss is 3.7955312967300414 and perplexity is 44.50187382577502
At time: 818.5477747917175 and batch: 1700, loss is 3.7790279006958007 and perplexity is 43.77346888776045
At time: 819.5394108295441 and batch: 1750, loss is 3.7614644718170167 and perplexity is 43.011368815950384
At time: 820.5289175510406 and batch: 1800, loss is 3.722237677574158 and perplexity is 41.35683390457599
At time: 821.5172350406647 and batch: 1850, loss is 3.7503132677078246 and perplexity is 42.534404568611464
At time: 822.5045869350433 and batch: 1900, loss is 3.8592288637161256 and perplexity is 47.42876322322258
At time: 823.4937205314636 and batch: 1950, loss is 3.794617519378662 and perplexity is 44.461227595009895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331734022983285 and perplexity of 76.07608994956695
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f4a57130b38>
ELAPSED
5105.541294813156


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.78177940258892}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.6888560527046866, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6228089196258255, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.04378796834526}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.14308718722040714, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.37386466100496807, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.54586144587961}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.31025574538464784, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6931579404631784, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.28222960592869}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.7280101718420305, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.21880679215341725, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -75.93433108999963}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.7229570152146902, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.23532633160778885, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.07608994956695}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.9652382328942114, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.5707789545302457, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.78177940258892}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.6888560527046866, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6228089196258255, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.04378796834526}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.14308718722040714, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.37386466100496807, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.54586144587961}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.31025574538464784, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.6931579404631784, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.28222960592869}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.7280101718420305, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.21880679215341725, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -75.93433108999963}, {'params': {'wordvec_dim': 300, 'data': 'wikitext', 'num_layers': 1, 'dropout': 0.7229570152146902, 'wordvec_source': 'gigavec', 'batch_size': 32, 'rnn_dropout': 0.23532633160778885, 'tune_wordvecs': True, 'seq_len': 35, 'tie_weights': True}, 'best_accuracy': -76.07608994956695}]
