Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'type': 'continuous', 'domain': [0, 1], 'name': 'dropout'}, {'type': 'continuous', 'domain': [0, 1], 'name': 'rnn_dropout'}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.7133996486663818 and batch: 50, loss is 7.428437032699585 and perplexity is 1683.174769284009
At time: 2.52750301361084 and batch: 100, loss is 6.718074865341187 and perplexity is 827.2234610374793
At time: 3.3387086391448975 and batch: 150, loss is 6.47473032951355 and perplexity is 648.5443107672139
At time: 4.150146722793579 and batch: 200, loss is 6.373303775787353 and perplexity is 585.9906159943966
At time: 4.961588382720947 and batch: 250, loss is 6.293776073455811 and perplexity is 541.1930603230402
At time: 5.773138761520386 and batch: 300, loss is 6.221423025131226 and perplexity is 503.4191005816261
At time: 6.584484577178955 and batch: 350, loss is 6.17703872680664 and perplexity is 481.5638008427846
At time: 7.396054029464722 and batch: 400, loss is 6.130488519668579 and perplexity is 459.66065911236797
At time: 8.209941625595093 and batch: 450, loss is 6.042311782836914 and perplexity is 420.8648592887389
At time: 9.022658586502075 and batch: 500, loss is 6.025305624008179 and perplexity is 413.7680801598943
At time: 9.834529399871826 and batch: 550, loss is 5.985263786315918 and perplexity is 397.52736970028025
At time: 10.646647214889526 and batch: 600, loss is 6.019837560653687 and perplexity is 411.5117445983932
At time: 11.458369016647339 and batch: 650, loss is 6.089091682434082 and perplexity is 441.0206423644709
At time: 12.270661354064941 and batch: 700, loss is 5.99553219795227 and perplexity is 401.6303739857913
At time: 13.096105813980103 and batch: 750, loss is 5.931091289520264 and perplexity is 376.5652313687913
At time: 13.908864259719849 and batch: 800, loss is 5.93480619430542 and perplexity is 377.96673696686133
At time: 14.720822095870972 and batch: 850, loss is 5.959942216873169 and perplexity is 387.58772755989486
At time: 15.532904386520386 and batch: 900, loss is 5.948906784057617 and perplexity is 383.3340430252222
At time: 16.345080137252808 and batch: 950, loss is 5.977337617874145 and perplexity is 394.38895504010713
At time: 17.157207489013672 and batch: 1000, loss is 5.951517066955566 and perplexity is 384.3359603969363
At time: 17.96947741508484 and batch: 1050, loss is 5.855174770355225 and perplexity is 349.03589585120574
At time: 18.781800985336304 and batch: 1100, loss is 5.933167390823364 and perplexity is 377.3478310333333
At time: 19.59423065185547 and batch: 1150, loss is 5.840526542663574 and perplexity is 343.9604028189732
At time: 20.406527042388916 and batch: 1200, loss is 5.925040159225464 and perplexity is 374.29346639415917
At time: 21.219141960144043 and batch: 1250, loss is 5.864789047241211 and perplexity is 352.4078068668185
At time: 22.03219199180603 and batch: 1300, loss is 5.875835323333741 and perplexity is 356.3221806226036
At time: 22.88869047164917 and batch: 1350, loss is 5.844673957824707 and perplexity is 345.3899117428583
At time: 23.70830249786377 and batch: 1400, loss is 5.8588197135925295 and perplexity is 350.3104332765661
At time: 24.524415016174316 and batch: 1450, loss is 5.845029382705689 and perplexity is 345.5126937297258
At time: 25.35496473312378 and batch: 1500, loss is 5.822828388214111 and perplexity is 337.92649053782014
At time: 26.181068420410156 and batch: 1550, loss is 5.795578022003173 and perplexity is 328.8422070891618
At time: 27.003626823425293 and batch: 1600, loss is 5.811433877944946 and perplexity is 334.0978379063207
At time: 27.82190752029419 and batch: 1650, loss is 5.808283052444458 and perplexity is 333.0468105903456
At time: 28.640755653381348 and batch: 1700, loss is 5.824567041397095 and perplexity is 338.51453856385945
At time: 29.460552215576172 and batch: 1750, loss is 5.834768648147583 and perplexity is 341.98560589398073
At time: 30.2763729095459 and batch: 1800, loss is 5.828624887466431 and perplexity is 339.8909692367768
At time: 31.091785430908203 and batch: 1850, loss is 5.787578105926514 and perplexity is 326.2219917555445
At time: 31.90695548057556 and batch: 1900, loss is 5.787185697555542 and perplexity is 326.094004628437
At time: 32.72310400009155 and batch: 1950, loss is 5.725672702789307 and perplexity is 306.63947310615583
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.119944017986919 and perplexity of 167.32600211246145
finished 1 epochs...
Completing Train Step...
At time: 35.45963454246521 and batch: 50, loss is 5.364789075851441 and perplexity is 213.74614570213996
At time: 36.30723190307617 and batch: 100, loss is 5.26290337562561 and perplexity is 193.04114942319933
At time: 37.117409229278564 and batch: 150, loss is 5.176934185028077 and perplexity is 177.13890255850527
At time: 37.927462577819824 and batch: 200, loss is 5.130733375549316 and perplexity is 169.14111652984812
At time: 38.73825120925903 and batch: 250, loss is 5.136153612136841 and perplexity is 170.06039048868215
At time: 39.55111503601074 and batch: 300, loss is 5.133849639892578 and perplexity is 169.669027087477
At time: 40.362186431884766 and batch: 350, loss is 5.120064764022827 and perplexity is 167.34620728374358
At time: 41.21418881416321 and batch: 400, loss is 5.075315227508545 and perplexity is 160.02262756382484
At time: 42.02460312843323 and batch: 450, loss is 5.033763008117676 and perplexity is 153.5095850066261
At time: 42.83576965332031 and batch: 500, loss is 5.017824192047119 and perplexity is 151.08222001647914
At time: 43.64615488052368 and batch: 550, loss is 4.970623645782471 and perplexity is 144.1167371460954
At time: 44.45712637901306 and batch: 600, loss is 4.956660070419312 and perplexity is 142.11833710148147
At time: 45.26766872406006 and batch: 650, loss is 5.03688461303711 and perplexity is 153.9895299919447
At time: 46.07869601249695 and batch: 700, loss is 5.022269582748413 and perplexity is 151.75533453249753
At time: 46.892399072647095 and batch: 750, loss is 4.975805044174194 and perplexity is 144.86540126475364
At time: 47.7033326625824 and batch: 800, loss is 4.952519874572754 and perplexity is 141.53115571421495
At time: 48.51450181007385 and batch: 850, loss is 4.951280336380005 and perplexity is 141.35583112445403
At time: 49.32519292831421 and batch: 900, loss is 4.944323482513428 and perplexity is 140.37585200230606
At time: 50.13628363609314 and batch: 950, loss is 5.00528226852417 and perplexity is 149.19919145076372
At time: 50.956971645355225 and batch: 1000, loss is 4.973784551620484 and perplexity is 144.57299729970052
At time: 51.768275022506714 and batch: 1050, loss is 4.876411790847778 and perplexity is 131.15919190885313
At time: 52.58895492553711 and batch: 1100, loss is 4.952239198684692 and perplexity is 141.4914369057131
At time: 53.39993977546692 and batch: 1150, loss is 4.873102188110352 and perplexity is 130.72582462062752
At time: 54.20965361595154 and batch: 1200, loss is 4.950417108535767 and perplexity is 141.2338614864497
At time: 55.01855659484863 and batch: 1250, loss is 4.916310710906982 and perplexity is 136.4981021556822
At time: 55.83041453361511 and batch: 1300, loss is 4.93458197593689 and perplexity is 139.01501876138153
At time: 56.64281177520752 and batch: 1350, loss is 4.844122390747071 and perplexity is 126.99178391041264
At time: 57.45523500442505 and batch: 1400, loss is 4.843741683959961 and perplexity is 126.94344647814889
At time: 58.26766324043274 and batch: 1450, loss is 4.793121919631958 and perplexity is 120.67752672990821
At time: 59.08017659187317 and batch: 1500, loss is 4.787309398651123 and perplexity is 119.97812069913094
At time: 59.890563011169434 and batch: 1550, loss is 4.778860321044922 and perplexity is 118.96868664465468
At time: 60.70244598388672 and batch: 1600, loss is 4.84145001411438 and perplexity is 126.65286709293903
At time: 61.5132839679718 and batch: 1650, loss is 4.8048116493225095 and perplexity is 122.0964918983316
At time: 62.323777198791504 and batch: 1700, loss is 4.82695858001709 and perplexity is 124.83072006572286
At time: 63.13456201553345 and batch: 1750, loss is 4.825698823928833 and perplexity is 124.67356281680298
At time: 63.94570302963257 and batch: 1800, loss is 4.780103149414063 and perplexity is 119.11663622237843
At time: 64.75684833526611 and batch: 1850, loss is 4.797686586380005 and perplexity is 121.22963856802477
At time: 65.56743049621582 and batch: 1900, loss is 4.874067869186401 and perplexity is 130.8521250487663
At time: 66.37768840789795 and batch: 1950, loss is 4.790944023132324 and perplexity is 120.4149895600232
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6448543105014535 and perplexity of 104.04820595017819
finished 2 epochs...
Completing Train Step...
At time: 69.1252110004425 and batch: 50, loss is 4.726590852737427 and perplexity is 112.90997872154755
At time: 69.97866439819336 and batch: 100, loss is 4.690315132141113 and perplexity is 108.88748834861376
At time: 70.79787540435791 and batch: 150, loss is 4.64414047241211 and perplexity is 103.97395888098886
At time: 71.6100561618805 and batch: 200, loss is 4.637436494827271 and perplexity is 103.27925104599151
At time: 72.42232275009155 and batch: 250, loss is 4.63639006614685 and perplexity is 103.17123320194638
At time: 73.23440384864807 and batch: 300, loss is 4.662669858932495 and perplexity is 105.91849242423186
At time: 74.05124473571777 and batch: 350, loss is 4.664445419311523 and perplexity is 106.10672416174245
At time: 74.8802752494812 and batch: 400, loss is 4.624788227081299 and perplexity is 101.98117394486535
At time: 75.69311308860779 and batch: 450, loss is 4.625096492767334 and perplexity is 102.0126160874319
At time: 76.50842690467834 and batch: 500, loss is 4.6240192317962645 and perplexity is 101.90278104868636
At time: 77.3265163898468 and batch: 550, loss is 4.5866794013977055 and perplexity is 98.16791211253184
At time: 78.14398193359375 and batch: 600, loss is 4.571183738708496 and perplexity is 96.65846043996284
At time: 78.96840739250183 and batch: 650, loss is 4.64723617553711 and perplexity is 104.29633011578444
At time: 79.78659987449646 and batch: 700, loss is 4.655957250595093 and perplexity is 105.20988403496078
At time: 80.6052258014679 and batch: 750, loss is 4.620225219726563 and perplexity is 101.51689316199068
At time: 81.43447995185852 and batch: 800, loss is 4.595506734848023 and perplexity is 99.03830899673461
At time: 82.27927470207214 and batch: 850, loss is 4.596835765838623 and perplexity is 99.17002148424959
At time: 83.09627056121826 and batch: 900, loss is 4.579267482757569 and perplexity is 97.44298938773565
At time: 83.9142599105835 and batch: 950, loss is 4.660050716400146 and perplexity is 105.64143977433044
At time: 84.73124361038208 and batch: 1000, loss is 4.628555030822754 and perplexity is 102.36604141748917
At time: 85.54868412017822 and batch: 1050, loss is 4.5552011013031 and perplexity is 95.1258832512595
At time: 86.36645722389221 and batch: 1100, loss is 4.617181243896485 and perplexity is 101.20834803306126
At time: 87.18397665023804 and batch: 1150, loss is 4.564659013748169 and perplexity is 96.02984357669592
At time: 88.00134611129761 and batch: 1200, loss is 4.636564035415649 and perplexity is 103.18918338729263
At time: 88.82659864425659 and batch: 1250, loss is 4.621389665603638 and perplexity is 101.63517294152247
At time: 89.64762353897095 and batch: 1300, loss is 4.632502565383911 and perplexity is 102.77093354091193
At time: 90.46533370018005 and batch: 1350, loss is 4.523800020217895 and perplexity is 92.18523900794831
At time: 91.28214073181152 and batch: 1400, loss is 4.530205202102661 and perplexity is 92.77759728695347
At time: 92.09921479225159 and batch: 1450, loss is 4.47691309928894 and perplexity is 87.9627209617497
At time: 92.91638159751892 and batch: 1500, loss is 4.4876916885375975 and perplexity is 88.91596307398726
At time: 93.73394107818604 and batch: 1550, loss is 4.482208118438721 and perplexity is 88.42972054847232
At time: 94.56147003173828 and batch: 1600, loss is 4.556251535415649 and perplexity is 95.22585922390611
At time: 95.38039112091064 and batch: 1650, loss is 4.518780488967895 and perplexity is 91.7236717148104
At time: 96.19742822647095 and batch: 1700, loss is 4.542312107086182 and perplexity is 93.90767390343223
At time: 97.01458191871643 and batch: 1750, loss is 4.538587379455566 and perplexity is 93.55854400624516
At time: 97.83233284950256 and batch: 1800, loss is 4.493027429580689 and perplexity is 89.39166360637033
At time: 98.64969420433044 and batch: 1850, loss is 4.534550399780273 and perplexity is 93.18161141216473
At time: 99.46718740463257 and batch: 1900, loss is 4.612629280090332 and perplexity is 100.7486982442115
At time: 100.28491973876953 and batch: 1950, loss is 4.53668363571167 and perplexity is 93.38060194519004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5428040970203485 and perplexity of 93.95388690096638
finished 3 epochs...
Completing Train Step...
At time: 103.0423493385315 and batch: 50, loss is 4.492947807312012 and perplexity is 89.38454632266408
At time: 103.85369896888733 and batch: 100, loss is 4.467360048294068 and perplexity is 87.12640962536899
At time: 104.66478371620178 and batch: 150, loss is 4.425976057052612 and perplexity is 83.59436028025797
At time: 105.47646951675415 and batch: 200, loss is 4.422706670761109 and perplexity is 83.32150430354946
At time: 106.28965473175049 and batch: 250, loss is 4.41888319015503 and perplexity is 83.00353441100107
At time: 107.11129975318909 and batch: 300, loss is 4.446855735778809 and perplexity is 85.35813309352996
At time: 107.92363023757935 and batch: 350, loss is 4.4487591743469235 and perplexity is 85.52076178392187
At time: 108.73592162132263 and batch: 400, loss is 4.410454187393189 and perplexity is 82.30683774418151
At time: 109.56590461730957 and batch: 450, loss is 4.434098062515258 and perplexity is 84.27607884448025
At time: 110.37921380996704 and batch: 500, loss is 4.434003200531006 and perplexity is 84.26808462759567
At time: 111.19606947898865 and batch: 550, loss is 4.396680946350098 and perplexity is 81.18097700225519
At time: 112.0126383304596 and batch: 600, loss is 4.385058155059815 and perplexity is 80.24288960725734
At time: 112.83423113822937 and batch: 650, loss is 4.457680683135987 and perplexity is 86.28714959635434
At time: 113.65295696258545 and batch: 700, loss is 4.4709470844268795 and perplexity is 87.43949639589391
At time: 114.46956181526184 and batch: 750, loss is 4.4383808040618895 and perplexity is 84.63778550393906
At time: 115.28394341468811 and batch: 800, loss is 4.4128599452972415 and perplexity is 82.50508644321299
At time: 116.09635782241821 and batch: 850, loss is 4.417500915527344 and perplexity is 82.88887999157967
At time: 116.90774011611938 and batch: 900, loss is 4.391602420806885 and perplexity is 80.76974245336659
At time: 117.71924686431885 and batch: 950, loss is 4.483297548294067 and perplexity is 88.52611102193406
At time: 118.53125953674316 and batch: 1000, loss is 4.452679586410523 and perplexity is 85.85669648106146
At time: 119.34552431106567 and batch: 1050, loss is 4.387491941452026 and perplexity is 80.43842150497476
At time: 120.16035628318787 and batch: 1100, loss is 4.443158969879151 and perplexity is 85.04316659525283
At time: 120.97371244430542 and batch: 1150, loss is 4.395632200241089 and perplexity is 81.09588339709148
At time: 121.78670310974121 and batch: 1200, loss is 4.470428323745727 and perplexity is 87.39414798668678
At time: 122.5993914604187 and batch: 1250, loss is 4.4603313636779784 and perplexity is 86.51617266421312
At time: 123.41420531272888 and batch: 1300, loss is 4.462275714874267 and perplexity is 86.68455413133744
At time: 124.22704863548279 and batch: 1350, loss is 4.355413360595703 and perplexity is 77.89901906748624
At time: 125.04053735733032 and batch: 1400, loss is 4.3616704082489015 and perplexity is 78.38796502579797
At time: 125.85400247573853 and batch: 1450, loss is 4.3052831602096555 and perplexity is 74.09019187712941
At time: 126.66743850708008 and batch: 1500, loss is 4.324746980667114 and perplexity is 75.54639574267573
At time: 127.47991466522217 and batch: 1550, loss is 4.318464202880859 and perplexity is 75.07324244060894
At time: 128.2931945323944 and batch: 1600, loss is 4.3988175964355465 and perplexity is 81.35461778243797
At time: 129.10585379600525 and batch: 1650, loss is 4.3615938091278075 and perplexity is 78.38196080653454
At time: 129.91844367980957 and batch: 1700, loss is 4.388727865219116 and perplexity is 80.53789872236588
At time: 130.73120379447937 and batch: 1750, loss is 4.37951470375061 and perplexity is 79.79929770681913
At time: 131.5441176891327 and batch: 1800, loss is 4.338875694274902 and perplexity is 76.62134507609021
At time: 132.35622477531433 and batch: 1850, loss is 4.383290719985962 and perplexity is 80.10119076837395
At time: 133.16887760162354 and batch: 1900, loss is 4.458372688293457 and perplexity is 86.34688141387764
At time: 133.98556876182556 and batch: 1950, loss is 4.386748905181885 and perplexity is 80.37867503992774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494317485010901 and perplexity of 89.50705822414437
finished 4 epochs...
Completing Train Step...
At time: 136.76548218727112 and batch: 50, loss is 4.349537925720215 and perplexity is 77.44267039034756
At time: 137.6096441745758 and batch: 100, loss is 4.3290119457244876 and perplexity is 75.86928655028814
At time: 138.42653465270996 and batch: 150, loss is 4.292870655059814 and perplexity is 73.1762309954646
At time: 139.24454379081726 and batch: 200, loss is 4.287810297012329 and perplexity is 72.80686840772924
At time: 140.06172132492065 and batch: 250, loss is 4.278498001098633 and perplexity is 72.1320163922591
At time: 140.8793876171112 and batch: 300, loss is 4.308740262985229 and perplexity is 74.34677254243086
At time: 141.6966507434845 and batch: 350, loss is 4.316008739471435 and perplexity is 74.8891289752142
At time: 142.51385951042175 and batch: 400, loss is 4.275850830078125 and perplexity is 71.94132311902517
At time: 143.33073163032532 and batch: 450, loss is 4.307243804931641 and perplexity is 74.2355989199795
At time: 144.1834921836853 and batch: 500, loss is 4.3115968418121335 and perplexity is 74.55945358418074
At time: 145.00401544570923 and batch: 550, loss is 4.274667043685913 and perplexity is 71.85621034728904
At time: 145.8212389945984 and batch: 600, loss is 4.265892629623413 and perplexity is 71.22847224921325
At time: 146.63853240013123 and batch: 650, loss is 4.331550493240356 and perplexity is 76.06212900549893
At time: 147.4558129310608 and batch: 700, loss is 4.350158538818359 and perplexity is 77.4907472429662
At time: 148.28320264816284 and batch: 750, loss is 4.323219594955444 and perplexity is 75.43109533376419
At time: 149.10408186912537 and batch: 800, loss is 4.296130318641662 and perplexity is 73.41515007706107
At time: 149.92047691345215 and batch: 850, loss is 4.2979144096374515 and perplexity is 73.5462462942854
At time: 150.73754358291626 and batch: 900, loss is 4.273652348518372 and perplexity is 71.78333517718603
At time: 151.55456805229187 and batch: 950, loss is 4.366398334503174 and perplexity is 78.7594550403573
At time: 152.37151956558228 and batch: 1000, loss is 4.334483480453491 and perplexity is 76.28554573632297
At time: 153.1882083415985 and batch: 1050, loss is 4.27573444366455 and perplexity is 71.93295061367195
At time: 154.00518369674683 and batch: 1100, loss is 4.321410150527954 and perplexity is 75.29473036827241
At time: 154.8222737312317 and batch: 1150, loss is 4.2818236780166625 and perplexity is 72.37230351142158
At time: 155.64017462730408 and batch: 1200, loss is 4.3561496877670285 and perplexity is 77.95639935458495
At time: 156.45764875411987 and batch: 1250, loss is 4.348044166564941 and perplexity is 77.32707604898995
At time: 157.27492475509644 and batch: 1300, loss is 4.346103086471557 and perplexity is 77.17712358294753
At time: 158.09326839447021 and batch: 1350, loss is 4.242443861961365 and perplexity is 69.5776824844859
At time: 158.91063237190247 and batch: 1400, loss is 4.2535484027862545 and perplexity is 70.35461646400174
At time: 159.73536896705627 and batch: 1450, loss is 4.192763938903808 and perplexity is 66.20552633926302
At time: 160.5514063835144 and batch: 1500, loss is 4.21446816444397 and perplexity is 67.65817327850446
At time: 161.36823797225952 and batch: 1550, loss is 4.20592209815979 and perplexity is 67.08242573747529
At time: 162.1929476261139 and batch: 1600, loss is 4.292348594665527 and perplexity is 73.13803855370672
At time: 163.016681432724 and batch: 1650, loss is 4.253329405784607 and perplexity is 70.33921070091358
At time: 163.8348207473755 and batch: 1700, loss is 4.282943234443665 and perplexity is 72.45337376184688
At time: 164.65308666229248 and batch: 1750, loss is 4.268833904266358 and perplexity is 71.43828315298325
At time: 165.47130870819092 and batch: 1800, loss is 4.230915932655335 and perplexity is 68.7802013641453
At time: 166.28897380828857 and batch: 1850, loss is 4.27831771850586 and perplexity is 72.11901341746214
At time: 167.1068069934845 and batch: 1900, loss is 4.351076641082764 and perplexity is 77.56192434240877
At time: 167.92537593841553 and batch: 1950, loss is 4.282099189758301 and perplexity is 72.39224567783276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4826475631359015 and perplexity of 88.46858905989562
finished 5 epochs...
Completing Train Step...
At time: 170.68050336837769 and batch: 50, loss is 4.249610414505005 and perplexity is 70.07810561441573
At time: 171.52833032608032 and batch: 100, loss is 4.22819272518158 and perplexity is 68.59315340653556
At time: 172.34932208061218 and batch: 150, loss is 4.194401679039001 and perplexity is 66.31404262340219
At time: 173.17016458511353 and batch: 200, loss is 4.1901966571807865 and perplexity is 66.0357760931158
At time: 173.9905300140381 and batch: 250, loss is 4.18463321685791 and perplexity is 65.66941006638554
At time: 174.81121444702148 and batch: 300, loss is 4.207166490554809 and perplexity is 67.16595455843846
At time: 175.63162064552307 and batch: 350, loss is 4.218957104682922 and perplexity is 67.96256947204267
At time: 176.45702743530273 and batch: 400, loss is 4.17436646938324 and perplexity is 64.99864798075558
At time: 177.28255105018616 and batch: 450, loss is 4.214278244972229 and perplexity is 67.64532489409432
At time: 178.1030158996582 and batch: 500, loss is 4.223555932044983 and perplexity is 68.27583737651806
At time: 178.92367553710938 and batch: 550, loss is 4.184706225395202 and perplexity is 65.67420466898066
At time: 179.7441005706787 and batch: 600, loss is 4.1806490516662596 and perplexity is 65.40829280120747
At time: 180.57607316970825 and batch: 650, loss is 4.240901088714599 and perplexity is 69.4704226574472
At time: 181.39621829986572 and batch: 700, loss is 4.260249814987183 and perplexity is 70.8276750591076
At time: 182.2167625427246 and batch: 750, loss is 4.237985873222351 and perplexity is 69.26819631496453
At time: 183.03782320022583 and batch: 800, loss is 4.2114959144592286 and perplexity is 67.4573748334231
At time: 183.85821628570557 and batch: 850, loss is 4.2138402462005615 and perplexity is 67.61570281257285
At time: 184.67811608314514 and batch: 900, loss is 4.185578532218933 and perplexity is 65.73151771950484
At time: 185.52554607391357 and batch: 950, loss is 4.281045866012573 and perplexity is 72.3160333516266
At time: 186.3457853794098 and batch: 1000, loss is 4.250135488510132 and perplexity is 70.11491146805528
At time: 187.16739416122437 and batch: 1050, loss is 4.195056781768799 and perplexity is 66.3574993665101
At time: 187.98939871788025 and batch: 1100, loss is 4.236095752716064 and perplexity is 69.13739473099548
At time: 188.81877517700195 and batch: 1150, loss is 4.198213911056518 and perplexity is 66.56732962756158
At time: 189.64832735061646 and batch: 1200, loss is 4.274333829879761 and perplexity is 71.8322708546498
At time: 190.46885776519775 and batch: 1250, loss is 4.265996837615967 and perplexity is 71.23589521207835
At time: 191.28927421569824 and batch: 1300, loss is 4.25904158115387 and perplexity is 70.74215034309833
At time: 192.10956954956055 and batch: 1350, loss is 4.159224591255188 and perplexity is 64.02186023782248
At time: 192.92971515655518 and batch: 1400, loss is 4.171177663803101 and perplexity is 64.79171004714543
At time: 193.76190876960754 and batch: 1450, loss is 4.106678881645203 and perplexity is 60.74464205133165
At time: 194.58303093910217 and batch: 1500, loss is 4.1320549631118775 and perplexity is 62.30582764748769
At time: 195.4034595489502 and batch: 1550, loss is 4.1232073736190795 and perplexity is 61.75700273039451
At time: 196.22405910491943 and batch: 1600, loss is 4.214486098289489 and perplexity is 67.65938666061247
At time: 197.04469323158264 and batch: 1650, loss is 4.171856393814087 and perplexity is 64.83570105253655
At time: 197.8655297756195 and batch: 1700, loss is 4.203975868225098 and perplexity is 66.95199487780563
At time: 198.68632102012634 and batch: 1750, loss is 4.187531304359436 and perplexity is 65.86000180530284
At time: 199.5076379776001 and batch: 1800, loss is 4.15342616558075 and perplexity is 63.65170842567478
At time: 200.32771515846252 and batch: 1850, loss is 4.197555446624756 and perplexity is 66.5235118364961
At time: 201.15248560905457 and batch: 1900, loss is 4.27022780418396 and perplexity is 71.53793040299641
At time: 201.97722554206848 and batch: 1950, loss is 4.2022837018966674 and perplexity is 66.83879676847789
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.468580804869186 and perplexity of 87.23283470912934
finished 6 epochs...
Completing Train Step...
At time: 204.77063727378845 and batch: 50, loss is 4.172432985305786 and perplexity is 64.87309554575909
At time: 205.58910179138184 and batch: 100, loss is 4.156692042350769 and perplexity is 63.85992688443738
At time: 206.4329218864441 and batch: 150, loss is 4.124990243911743 and perplexity is 61.867205665504876
At time: 207.25056099891663 and batch: 200, loss is 4.116495304107666 and perplexity is 61.343873462452926
At time: 208.07020950317383 and batch: 250, loss is 4.108942818641663 and perplexity is 60.88231988197096
At time: 208.89170670509338 and batch: 300, loss is 4.132899098396301 and perplexity is 62.3584443997343
At time: 209.71633744239807 and batch: 350, loss is 4.146133890151978 and perplexity is 63.189230942356296
At time: 210.53542399406433 and batch: 400, loss is 4.101549248695374 and perplexity is 60.43384216013058
At time: 211.3549451828003 and batch: 450, loss is 4.1407296752929685 and perplexity is 62.848663839337625
At time: 212.17352175712585 and batch: 500, loss is 4.155062112808228 and perplexity is 63.75592448434113
At time: 212.99262070655823 and batch: 550, loss is 4.113178148269653 and perplexity is 61.14072340095738
At time: 213.81326532363892 and batch: 600, loss is 4.11200632572174 and perplexity is 61.06911928453322
At time: 214.63468194007874 and batch: 650, loss is 4.1719425630569456 and perplexity is 64.84128813652039
At time: 215.45538854599 and batch: 700, loss is 4.189673948287964 and perplexity is 66.00126762543465
At time: 216.27724385261536 and batch: 750, loss is 4.169937262535095 and perplexity is 64.71139215135464
At time: 217.0985026359558 and batch: 800, loss is 4.144798650741577 and perplexity is 63.104914494738104
At time: 217.91964387893677 and batch: 850, loss is 4.145024447441101 and perplexity is 63.11916498495108
At time: 218.74034023284912 and batch: 900, loss is 4.117545437812805 and perplexity is 61.40832656784572
At time: 219.5608491897583 and batch: 950, loss is 4.216221327781677 and perplexity is 67.77689314464307
At time: 220.38000392913818 and batch: 1000, loss is 4.184427590370178 and perplexity is 65.65590808447227
At time: 221.19958877563477 and batch: 1050, loss is 4.130230665206909 and perplexity is 62.19226687247981
At time: 222.0193407535553 and batch: 1100, loss is 4.167081260681153 and perplexity is 64.52683996154276
At time: 222.83779788017273 and batch: 1150, loss is 4.1309754133224486 and perplexity is 62.238601697779494
At time: 223.65725135803223 and batch: 1200, loss is 4.206844410896301 and perplexity is 67.14432525409737
At time: 224.47560095787048 and batch: 1250, loss is 4.198965911865234 and perplexity is 66.6174071400806
At time: 225.29539251327515 and batch: 1300, loss is 4.19227514743805 and perplexity is 66.17317355052998
At time: 226.11486196517944 and batch: 1350, loss is 4.09358856678009 and perplexity is 59.95465741503269
At time: 226.93326902389526 and batch: 1400, loss is 4.105770845413208 and perplexity is 60.68950875075498
At time: 227.75230813026428 and batch: 1450, loss is 4.039705142974854 and perplexity is 56.80958962909671
At time: 228.5718071460724 and batch: 1500, loss is 4.068838758468628 and perplexity is 58.48900328120349
At time: 229.39038848876953 and batch: 1550, loss is 4.055679006576538 and perplexity is 57.724344902086635
At time: 230.2091851234436 and batch: 1600, loss is 4.1505464792251585 and perplexity is 63.468675135131036
At time: 231.02742171287537 and batch: 1650, loss is 4.111089835166931 and perplexity is 61.01317565333906
At time: 231.8459918498993 and batch: 1700, loss is 4.142400832176208 and perplexity is 62.95378162620758
At time: 232.66479563713074 and batch: 1750, loss is 4.1247827386856075 and perplexity is 61.8543692288628
At time: 233.48406171798706 and batch: 1800, loss is 4.086936435699463 and perplexity is 59.557154760712564
At time: 234.3027937412262 and batch: 1850, loss is 4.134978590011596 and perplexity is 62.488253183367476
At time: 235.12214136123657 and batch: 1900, loss is 4.207151341438293 and perplexity is 67.16493706127406
At time: 235.94114184379578 and batch: 1950, loss is 4.136844453811645 and perplexity is 62.60495659538846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473939123819041 and perplexity of 87.7015105964768
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 238.68916630744934 and batch: 50, loss is 4.133588109016419 and perplexity is 62.401424835467715
At time: 239.53571224212646 and batch: 100, loss is 4.134835705757141 and perplexity is 62.47932523374609
At time: 240.3543198108673 and batch: 150, loss is 4.105668063163757 and perplexity is 60.68327126708434
At time: 241.17271208763123 and batch: 200, loss is 4.095129551887513 and perplexity is 60.04711787102608
At time: 241.99067783355713 and batch: 250, loss is 4.086538977622986 and perplexity is 59.53348799212666
At time: 242.80957674980164 and batch: 300, loss is 4.095463824272156 and perplexity is 60.067193319454866
At time: 243.6283824443817 and batch: 350, loss is 4.107016396522522 and perplexity is 60.765147732032915
At time: 244.447185754776 and batch: 400, loss is 4.046870708465576 and perplexity is 57.218124407411814
At time: 245.26567006111145 and batch: 450, loss is 4.079712057113648 and perplexity is 59.12844178425187
At time: 246.08443689346313 and batch: 500, loss is 4.091529717445374 and perplexity is 59.831346791056724
At time: 246.902494430542 and batch: 550, loss is 4.050839424133301 and perplexity is 57.44565808380733
At time: 247.7484347820282 and batch: 600, loss is 4.0359225082397465 and perplexity is 56.595105615161316
At time: 248.56722235679626 and batch: 650, loss is 4.08795120716095 and perplexity is 59.6176223368875
At time: 249.38392996788025 and batch: 700, loss is 4.105022768974305 and perplexity is 60.644125336417886
At time: 250.20116901397705 and batch: 750, loss is 4.0654365968704225 and perplexity is 58.290352353212626
At time: 251.01990151405334 and batch: 800, loss is 4.045390596389771 and perplexity is 57.133497814392115
At time: 251.83886122703552 and batch: 850, loss is 4.051493301391601 and perplexity is 57.48323277649618
At time: 252.66639256477356 and batch: 900, loss is 4.012420058250427 and perplexity is 55.280490821746135
At time: 253.48443722724915 and batch: 950, loss is 4.10526927947998 and perplexity is 60.65907659316604
At time: 254.3048632144928 and batch: 1000, loss is 4.061735563278198 and perplexity is 58.07501652940904
At time: 255.12553763389587 and batch: 1050, loss is 4.004500679969787 and perplexity is 54.844432637250094
At time: 255.9468502998352 and batch: 1100, loss is 4.0328121089935305 and perplexity is 56.41934572473205
At time: 256.76518416404724 and batch: 1150, loss is 3.99476900100708 and perplexity is 54.3132928586556
At time: 257.5839819908142 and batch: 1200, loss is 4.062620363235474 and perplexity is 58.12642404088123
At time: 258.4030570983887 and batch: 1250, loss is 4.04755247592926 and perplexity is 57.25714716367708
At time: 259.2218518257141 and batch: 1300, loss is 4.0344425344467165 and perplexity is 56.51140829223636
At time: 260.0410666465759 and batch: 1350, loss is 3.939271664619446 and perplexity is 51.38116494874581
At time: 260.86563301086426 and batch: 1400, loss is 3.9402087926864624 and perplexity is 51.42933824928578
At time: 261.68986654281616 and batch: 1450, loss is 3.8654249715805054 and perplexity is 47.72354927600561
At time: 262.50905323028564 and batch: 1500, loss is 3.8856047439575194 and perplexity is 48.69638239978952
At time: 263.32855343818665 and batch: 1550, loss is 3.879847011566162 and perplexity is 48.41680729318822
At time: 264.1583857536316 and batch: 1600, loss is 3.9682086658477784 and perplexity is 52.889702799754495
At time: 264.9796757698059 and batch: 1650, loss is 3.914588451385498 and perplexity is 50.12843697648619
At time: 265.7981834411621 and batch: 1700, loss is 3.934917411804199 and perplexity is 51.157924741478006
At time: 266.61716175079346 and batch: 1750, loss is 3.913717188835144 and perplexity is 50.08478096732534
At time: 267.43611311912537 and batch: 1800, loss is 3.8718553495407106 and perplexity is 48.03141853243412
At time: 268.2559721469879 and batch: 1850, loss is 3.9059967184066773 and perplexity is 49.69959173129039
At time: 269.0781376361847 and batch: 1900, loss is 3.9758318567276003 and perplexity is 53.29443180299643
At time: 269.8980576992035 and batch: 1950, loss is 3.9043449211120604 and perplexity is 49.61756584384475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369831883630087 and perplexity of 79.03034428808536
finished 8 epochs...
Completing Train Step...
At time: 272.6706573963165 and batch: 50, loss is 4.044215421676636 and perplexity is 57.06639540873544
At time: 273.5164921283722 and batch: 100, loss is 4.035917868614197 and perplexity is 56.59484303567246
At time: 274.33482241630554 and batch: 150, loss is 4.004138903617859 and perplexity is 54.824594807132286
At time: 275.1532766819 and batch: 200, loss is 3.995478811264038 and perplexity is 54.35185867660319
At time: 275.971275806427 and batch: 250, loss is 3.9889918899536134 and perplexity is 54.00042354468532
At time: 276.79055166244507 and batch: 300, loss is 4.0025242328643795 and perplexity is 54.736142567165764
At time: 277.60943055152893 and batch: 350, loss is 4.01906807422638 and perplexity is 55.64922071094995
At time: 278.4281733036041 and batch: 400, loss is 3.9640950679779055 and perplexity is 52.67258270951933
At time: 279.2471077442169 and batch: 450, loss is 4.0030813837051396 and perplexity is 54.76664735211121
At time: 280.06568455696106 and batch: 500, loss is 4.0194859170913695 and perplexity is 55.67247819941569
At time: 280.88479447364807 and batch: 550, loss is 3.979786949157715 and perplexity is 53.50563359277293
At time: 281.711053609848 and batch: 600, loss is 3.969751601219177 and perplexity is 52.971371181302324
At time: 282.53266644477844 and batch: 650, loss is 4.020720210075378 and perplexity is 55.74123677404339
At time: 283.35093665122986 and batch: 700, loss is 4.043158531188965 and perplexity is 57.006114339118035
At time: 284.1696434020996 and batch: 750, loss is 4.006062607765198 and perplexity is 54.93016261559876
At time: 284.98774003982544 and batch: 800, loss is 3.9868025016784667 and perplexity is 53.88232497950526
At time: 285.80644130706787 and batch: 850, loss is 3.994606695175171 and perplexity is 54.304478209828254
At time: 286.62438797950745 and batch: 900, loss is 3.9536908721923827 and perplexity is 52.12740781743748
At time: 287.4433841705322 and batch: 950, loss is 4.051665029525757 and perplexity is 57.493105112460775
At time: 288.2623589038849 and batch: 1000, loss is 4.012006878852844 and perplexity is 55.2576547798662
At time: 289.109397649765 and batch: 1050, loss is 3.958947949409485 and perplexity is 52.40216720833788
At time: 289.9280045032501 and batch: 1100, loss is 3.9870941257476806 and perplexity is 53.89804065379756
At time: 290.7462191581726 and batch: 1150, loss is 3.950732822418213 and perplexity is 51.97344018474442
At time: 291.56493186950684 and batch: 1200, loss is 4.021205940246582 and perplexity is 55.76831855121043
At time: 292.3828547000885 and batch: 1250, loss is 4.011131234169007 and perplexity is 55.20928988653807
At time: 293.2001848220825 and batch: 1300, loss is 4.001703810691834 and perplexity is 54.691254238371975
At time: 294.0175504684448 and batch: 1350, loss is 3.9062559318542482 and perplexity is 49.71247620364803
At time: 294.83709955215454 and batch: 1400, loss is 3.910879683494568 and perplexity is 49.94286657049631
At time: 295.66147017478943 and batch: 1450, loss is 3.8380944776535033 and perplexity is 46.436903522294294
At time: 296.4832236766815 and batch: 1500, loss is 3.861471676826477 and perplexity is 47.535256452752776
At time: 297.3071653842926 and batch: 1550, loss is 3.857652897834778 and perplexity is 47.35407597832133
At time: 298.13015842437744 and batch: 1600, loss is 3.9489041996002197 and perplexity is 51.87848720914103
At time: 298.94740295410156 and batch: 1650, loss is 3.8967885684967043 and perplexity is 49.24405100259543
At time: 299.7649552822113 and batch: 1700, loss is 3.9229637289047243 and perplexity is 50.55003960281874
At time: 300.5829703807831 and batch: 1750, loss is 3.9055902004241942 and perplexity is 49.67939205957263
At time: 301.4019718170166 and batch: 1800, loss is 3.8673771905899046 and perplexity is 47.816807096324666
At time: 302.2209618091583 and batch: 1850, loss is 3.9041916799545286 and perplexity is 49.60996297317216
At time: 303.0399589538574 and batch: 1900, loss is 3.9750752210617066 and perplexity is 53.25412258671917
At time: 303.8582239151001 and batch: 1950, loss is 3.904405646324158 and perplexity is 49.62057897253989
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364898823582849 and perplexity of 78.64144287982005
finished 9 epochs...
Completing Train Step...
At time: 306.63342809677124 and batch: 50, loss is 4.007064852714539 and perplexity is 54.98524369140099
At time: 307.4542760848999 and batch: 100, loss is 3.9958134698867798 and perplexity is 54.370051038716994
At time: 308.27422761917114 and batch: 150, loss is 3.9633563899993898 and perplexity is 52.633688999332385
At time: 309.0949170589447 and batch: 200, loss is 3.9558851671218873 and perplexity is 52.24191631085689
At time: 309.9460389614105 and batch: 250, loss is 3.948985466957092 and perplexity is 51.8827034079924
At time: 310.77226090431213 and batch: 300, loss is 3.963466854095459 and perplexity is 52.63950345334879
At time: 311.5928318500519 and batch: 350, loss is 3.980355157852173 and perplexity is 53.53604459806343
At time: 312.4229784011841 and batch: 400, loss is 3.9268738842010498 and perplexity is 50.748085049796344
At time: 313.24325609207153 and batch: 450, loss is 3.9683112716674804 and perplexity is 52.89512986948377
At time: 314.0718114376068 and batch: 500, loss is 3.985270185470581 and perplexity is 53.799823444982614
At time: 314.9011175632477 and batch: 550, loss is 3.9463790225982667 and perplexity is 51.74765010928593
At time: 315.723201751709 and batch: 600, loss is 3.9382389879226682 and perplexity is 51.32813220460241
At time: 316.54421496391296 and batch: 650, loss is 3.9887917375564577 and perplexity is 53.98961631204826
At time: 317.3644025325775 and batch: 700, loss is 4.012207198143005 and perplexity is 55.268725062806254
At time: 318.1850597858429 and batch: 750, loss is 3.975622143745422 and perplexity is 53.28325644061977
At time: 319.0071589946747 and batch: 800, loss is 3.9560024690628053 and perplexity is 52.24804474846921
At time: 319.8366856575012 and batch: 850, loss is 3.9653843069076538 and perplexity is 52.74053404702161
At time: 320.6559147834778 and batch: 900, loss is 3.9242707204818728 and perplexity is 50.6161512730911
At time: 321.4753267765045 and batch: 950, loss is 4.024837055206299 and perplexity is 55.971187824904774
At time: 322.29472756385803 and batch: 1000, loss is 3.9867836141586306 and perplexity is 53.88130728563428
At time: 323.1142723560333 and batch: 1050, loss is 3.9341767692565917 and perplexity is 51.12004903367892
At time: 323.9328875541687 and batch: 1100, loss is 3.961949191093445 and perplexity is 52.55967501816693
At time: 324.7523527145386 and batch: 1150, loss is 3.9257088899612427 and perplexity is 50.68899824760696
At time: 325.5714762210846 and batch: 1200, loss is 3.997901372909546 and perplexity is 54.48368902389286
At time: 326.39053082466125 and batch: 1250, loss is 3.989623384475708 and perplexity is 54.034535285899835
At time: 327.2096598148346 and batch: 1300, loss is 3.9810558700561525 and perplexity is 53.57357110397096
At time: 328.0322527885437 and batch: 1350, loss is 3.8864427614212036 and perplexity is 48.73720792252007
At time: 328.85586404800415 and batch: 1400, loss is 3.892077956199646 and perplexity is 49.01262687300009
At time: 329.67841029167175 and batch: 1450, loss is 3.8200583696365356 and perplexity is 45.606870299601525
At time: 330.49937200546265 and batch: 1500, loss is 3.844013752937317 and perplexity is 46.712591469036994
At time: 331.319251537323 and batch: 1550, loss is 3.8414114046096803 and perplexity is 46.591187071528125
At time: 332.1393678188324 and batch: 1600, loss is 3.933848485946655 and perplexity is 51.103269929078714
At time: 332.9594156742096 and batch: 1650, loss is 3.881931800842285 and perplexity is 48.517851425080735
At time: 333.7819790840149 and batch: 1700, loss is 3.9106411933898926 and perplexity is 49.930957111220664
At time: 334.60173439979553 and batch: 1750, loss is 3.8951389932632448 and perplexity is 49.16288619779703
At time: 335.42214369773865 and batch: 1800, loss is 3.8580814266204833 and perplexity is 47.374372911598
At time: 336.2406516075134 and batch: 1850, loss is 3.8953938102722168 and perplexity is 49.17541533366105
At time: 337.0642583370209 and batch: 1900, loss is 3.966903109550476 and perplexity is 52.82069737023987
At time: 337.8836553096771 and batch: 1950, loss is 3.895509467124939 and perplexity is 49.18110313634018
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364352913789971 and perplexity of 78.59852346215698
finished 10 epochs...
Completing Train Step...
At time: 340.6526231765747 and batch: 50, loss is 3.9790967416763308 and perplexity is 53.46871634591656
At time: 341.4985098838806 and batch: 100, loss is 3.967025694847107 and perplexity is 52.82717280798387
At time: 342.3165638446808 and batch: 150, loss is 3.9346698570251464 and perplexity is 51.145261920157466
At time: 343.1347641944885 and batch: 200, loss is 3.927364926338196 and perplexity is 50.77301061718636
At time: 343.95333647727966 and batch: 250, loss is 3.9201445817947387 and perplexity is 50.40773229163533
At time: 344.76971077919006 and batch: 300, loss is 3.9351081466674804 and perplexity is 51.167683271875724
At time: 345.5865669250488 and batch: 350, loss is 3.952044577598572 and perplexity is 52.041661349098355
At time: 346.40479731559753 and batch: 400, loss is 3.8995231580734253 and perplexity is 49.378897562149106
At time: 347.2215316295624 and batch: 450, loss is 3.942354164123535 and perplexity is 51.539791722091586
At time: 348.04036355018616 and batch: 500, loss is 3.9606707811355593 and perplexity is 52.4925251379237
At time: 348.8590943813324 and batch: 550, loss is 3.9218524169921873 and perplexity is 50.493893945076444
At time: 349.6875705718994 and batch: 600, loss is 3.9146621561050416 and perplexity is 50.132131815036544
At time: 350.5065953731537 and batch: 650, loss is 3.965146942138672 and perplexity is 52.728016787978476
At time: 351.3525199890137 and batch: 700, loss is 3.988550090789795 and perplexity is 53.97657147201827
At time: 352.1707122325897 and batch: 750, loss is 3.9526961755752565 and perplexity is 52.075582640659015
At time: 352.98941373825073 and batch: 800, loss is 3.933029546737671 and perplexity is 51.06143658944553
At time: 353.80780577659607 and batch: 850, loss is 3.9434630060195923 and perplexity is 51.59697289905061
At time: 354.62554907798767 and batch: 900, loss is 3.9016997385025025 and perplexity is 49.486491755422655
At time: 355.44363260269165 and batch: 950, loss is 4.004378848075866 and perplexity is 54.83775124316259
At time: 356.26137113571167 and batch: 1000, loss is 3.9675077867507933 and perplexity is 52.852646500126234
At time: 357.0790784358978 and batch: 1050, loss is 3.914474220275879 and perplexity is 50.12271107655108
At time: 357.89819145202637 and batch: 1100, loss is 3.94249596118927 and perplexity is 51.5471004314909
At time: 358.71594643592834 and batch: 1150, loss is 3.9061585807800294 and perplexity is 49.70763687624821
At time: 359.5414102077484 and batch: 1200, loss is 3.979433937072754 and perplexity is 53.48674879097893
At time: 360.3630299568176 and batch: 1250, loss is 3.970864782333374 and perplexity is 53.030370743801264
At time: 361.1811490058899 and batch: 1300, loss is 3.9641488933563234 and perplexity is 52.67541790751804
At time: 361.9995503425598 and batch: 1350, loss is 3.8695072317123413 and perplexity is 47.918767413067094
At time: 362.82024931907654 and batch: 1400, loss is 3.875934910774231 and perplexity is 48.227765878666645
At time: 363.63917541503906 and batch: 1450, loss is 3.8040720796585084 and perplexity is 44.88358239473843
At time: 364.4578733444214 and batch: 1500, loss is 3.8284666776657104 and perplexity is 45.991963636196765
At time: 365.2815978527069 and batch: 1550, loss is 3.8266199827194214 and perplexity is 45.90710888391588
At time: 366.10721492767334 and batch: 1600, loss is 3.920303864479065 and perplexity is 50.41576201002611
At time: 366.927218914032 and batch: 1650, loss is 3.86783899307251 and perplexity is 47.838894116079764
At time: 367.74509358406067 and batch: 1700, loss is 3.897883596420288 and perplexity is 49.29800414822296
At time: 368.56322264671326 and batch: 1750, loss is 3.8832834434509276 and perplexity is 48.58347455986842
At time: 369.38085865974426 and batch: 1800, loss is 3.8474786138534545 and perplexity is 46.874724824067684
At time: 370.2095251083374 and batch: 1850, loss is 3.885011763572693 and perplexity is 48.66751495997311
At time: 371.0308859348297 and batch: 1900, loss is 3.956623101234436 and perplexity is 52.280481630590025
At time: 371.84939455986023 and batch: 1950, loss is 3.884501175880432 and perplexity is 48.64267226854757
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364604435410611 and perplexity of 78.61829517656065
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 374.61243772506714 and batch: 50, loss is 3.977284245491028 and perplexity is 53.3718922746432
At time: 375.4592294692993 and batch: 100, loss is 3.983825445175171 and perplexity is 53.7221527926363
At time: 376.2774143218994 and batch: 150, loss is 3.9549758052825927 and perplexity is 52.19443109964396
At time: 377.0964243412018 and batch: 200, loss is 3.947575922012329 and perplexity is 51.80962392219255
At time: 377.9148762226105 and batch: 250, loss is 3.9418709754943846 and perplexity is 51.5148942963436
At time: 378.73359298706055 and batch: 300, loss is 3.95273886680603 and perplexity is 52.077805858830814
At time: 379.56028962135315 and batch: 350, loss is 3.9673919582366945 and perplexity is 52.84652501114427
At time: 380.37760305404663 and batch: 400, loss is 3.9115871715545656 and perplexity is 49.97821305441029
At time: 381.2038645744324 and batch: 450, loss is 3.9566712522506715 and perplexity is 52.28299904951748
At time: 382.02192282676697 and batch: 500, loss is 3.971155004501343 and perplexity is 53.04576356652788
At time: 382.8409757614136 and batch: 550, loss is 3.9305300283432008 and perplexity is 50.933966962146066
At time: 383.6592044830322 and batch: 600, loss is 3.9140527963638307 and perplexity is 50.101592617791034
At time: 384.4772672653198 and batch: 650, loss is 3.9631820058822633 and perplexity is 52.62451132018912
At time: 385.3032627105713 and batch: 700, loss is 3.984925723075867 and perplexity is 53.78129462038841
At time: 386.1242015361786 and batch: 750, loss is 3.943452911376953 and perplexity is 51.59645204867684
At time: 386.9426574707031 and batch: 800, loss is 3.921798667907715 and perplexity is 50.491180017441664
At time: 387.76715421676636 and batch: 850, loss is 3.93760142326355 and perplexity is 51.295417631426226
At time: 388.58839178085327 and batch: 900, loss is 3.8885563230514526 and perplexity is 48.84032594991672
At time: 389.4086854457855 and batch: 950, loss is 3.9902635049819946 and perplexity is 54.06913497278709
At time: 390.231422662735 and batch: 1000, loss is 3.948772740364075 and perplexity is 51.87166775109036
At time: 391.0481901168823 and batch: 1050, loss is 3.895319414138794 and perplexity is 49.17175700898506
At time: 391.8648912906647 and batch: 1100, loss is 3.9178184700012206 and perplexity is 50.290614538369155
At time: 392.71380829811096 and batch: 1150, loss is 3.8837369585037234 and perplexity is 48.605512893878824
At time: 393.53283500671387 and batch: 1200, loss is 3.953966946601868 and perplexity is 52.14180084745089
At time: 394.35649704933167 and batch: 1250, loss is 3.942306580543518 and perplexity is 51.53733933263531
At time: 395.1738438606262 and batch: 1300, loss is 3.9287380981445312 and perplexity is 50.842778574621846
At time: 395.9912266731262 and batch: 1350, loss is 3.8331526374816893 and perplexity is 46.20798587011922
At time: 396.8075523376465 and batch: 1400, loss is 3.837742986679077 and perplexity is 46.420584238034486
At time: 397.6247742176056 and batch: 1450, loss is 3.761417784690857 and perplexity is 43.009360785623116
At time: 398.44208097457886 and batch: 1500, loss is 3.7846299171447755 and perplexity is 44.01937672727762
At time: 399.2611210346222 and batch: 1550, loss is 3.787627558708191 and perplexity is 44.151529014186494
At time: 400.0786786079407 and batch: 1600, loss is 3.8776339435577394 and perplexity is 48.309776083254626
At time: 400.907279253006 and batch: 1650, loss is 3.8181985998153687 and perplexity is 45.522130840948726
At time: 401.72527718544006 and batch: 1700, loss is 3.8397693634033203 and perplexity is 46.51474520003074
At time: 402.54310274124146 and batch: 1750, loss is 3.821307692527771 and perplexity is 45.6638836132678
At time: 403.3605201244354 and batch: 1800, loss is 3.79212037563324 and perplexity is 44.350340027327306
At time: 404.1772699356079 and batch: 1850, loss is 3.821993179321289 and perplexity is 45.69519633342736
At time: 404.99491572380066 and batch: 1900, loss is 3.894165930747986 and perplexity is 49.115070903504105
At time: 405.8120448589325 and batch: 1950, loss is 3.8257313632965086 and perplexity is 45.86633305509181
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3365481354469475 and perplexity of 76.4432117762361
finished 12 epochs...
Completing Train Step...
At time: 408.5908582210541 and batch: 50, loss is 3.9599948644638063 and perplexity is 52.45705655329476
At time: 409.41052746772766 and batch: 100, loss is 3.955166025161743 and perplexity is 52.204360462371206
At time: 410.2302362918854 and batch: 150, loss is 3.92348201751709 and perplexity is 50.57624590332644
At time: 411.04963064193726 and batch: 200, loss is 3.9157274341583252 and perplexity is 50.18556493033288
At time: 411.87724685668945 and batch: 250, loss is 3.9094254779815674 and perplexity is 49.87029216043755
At time: 412.7010838985443 and batch: 300, loss is 3.9197192859649657 and perplexity is 50.386298651445344
At time: 413.54774022102356 and batch: 350, loss is 3.9378770542144776 and perplexity is 51.30955818486378
At time: 414.36710691452026 and batch: 400, loss is 3.8827644872665403 and perplexity is 48.558268406296904
At time: 415.187237739563 and batch: 450, loss is 3.9287890625 and perplexity is 50.845369810091896
At time: 416.0064437389374 and batch: 500, loss is 3.945446701049805 and perplexity is 51.699427143155056
At time: 416.8270375728607 and batch: 550, loss is 3.906524968147278 and perplexity is 49.72585246323216
At time: 417.64998841285706 and batch: 600, loss is 3.891910810470581 and perplexity is 49.00443530635977
At time: 418.47664642333984 and batch: 650, loss is 3.9415139102935792 and perplexity is 51.49650340383647
At time: 419.2962682247162 and batch: 700, loss is 3.965563111305237 and perplexity is 52.7499651295745
At time: 420.12486505508423 and batch: 750, loss is 3.925235619544983 and perplexity is 50.665014320195866
At time: 420.9443635940552 and batch: 800, loss is 3.904259123802185 and perplexity is 49.61330897278944
At time: 421.76440238952637 and batch: 850, loss is 3.9200498914718627 and perplexity is 50.4029593931664
At time: 422.5834903717041 and batch: 900, loss is 3.871590881347656 and perplexity is 48.01871742955789
At time: 423.40284633636475 and batch: 950, loss is 3.974501814842224 and perplexity is 53.22359509477816
At time: 424.2221338748932 and batch: 1000, loss is 3.9343153429031372 and perplexity is 51.127133416128125
At time: 425.04110765457153 and batch: 1050, loss is 3.882076802253723 and perplexity is 48.52488709209581
At time: 425.85994958877563 and batch: 1100, loss is 3.9059106159210204 and perplexity is 49.6953126571283
At time: 426.67945289611816 and batch: 1150, loss is 3.872844891548157 and perplexity is 48.07897116253144
At time: 427.5046706199646 and batch: 1200, loss is 3.944294419288635 and perplexity is 51.639889145057374
At time: 428.32891869544983 and batch: 1250, loss is 3.933772144317627 and perplexity is 51.099368771115934
At time: 429.14866757392883 and batch: 1300, loss is 3.9213008165359495 and perplexity is 50.46604917044033
At time: 429.96806478500366 and batch: 1350, loss is 3.826233220100403 and perplexity is 45.88935716332463
At time: 430.7880115509033 and batch: 1400, loss is 3.8323843002319338 and perplexity is 46.1724961891069
At time: 431.6122999191284 and batch: 1450, loss is 3.7576970863342285 and perplexity is 42.84963326086475
At time: 432.431538105011 and batch: 1500, loss is 3.781676106452942 and perplexity is 43.889543667192676
At time: 433.2508041858673 and batch: 1550, loss is 3.7857581901550295 and perplexity is 44.06907063084059
At time: 434.07126665115356 and batch: 1600, loss is 3.876966643333435 and perplexity is 48.27754971236627
At time: 434.89069986343384 and batch: 1650, loss is 3.8183442306518556 and perplexity is 45.52876074968962
At time: 435.7216191291809 and batch: 1700, loss is 3.841574501991272 and perplexity is 46.59878659185883
At time: 436.5410931110382 and batch: 1750, loss is 3.824703130722046 and perplexity is 45.81919603543596
At time: 437.3589458465576 and batch: 1800, loss is 3.7961164903640747 and perplexity is 44.527923660395714
At time: 438.1770849227905 and batch: 1850, loss is 3.8269643449783324 and perplexity is 45.92292028189934
At time: 438.99662470817566 and batch: 1900, loss is 3.8993626165390016 and perplexity is 49.37097083446786
At time: 439.8172152042389 and batch: 1950, loss is 3.8309035158157347 and perplexity is 46.10417527305103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3345762740734015 and perplexity of 76.29262487670316
finished 13 epochs...
Completing Train Step...
At time: 442.5492742061615 and batch: 50, loss is 3.9495442152023315 and perplexity is 51.91170087786818
At time: 443.39785504341125 and batch: 100, loss is 3.9426928853988645 and perplexity is 51.55725230304209
At time: 444.22138237953186 and batch: 150, loss is 3.910622639656067 and perplexity is 49.93003071412684
At time: 445.0395851135254 and batch: 200, loss is 3.9024271678924563 and perplexity is 49.52250278008216
At time: 445.8577377796173 and batch: 250, loss is 3.8956857681274415 and perplexity is 49.18977457849682
At time: 446.67599749565125 and batch: 300, loss is 3.90583101272583 and perplexity is 49.691356908902
At time: 447.4940528869629 and batch: 350, loss is 3.924561095237732 and perplexity is 50.630851059779765
At time: 448.3112761974335 and batch: 400, loss is 3.869835147857666 and perplexity is 47.934483327176046
At time: 449.1335508823395 and batch: 450, loss is 3.9160583353042604 and perplexity is 50.20217413912929
At time: 449.952424287796 and batch: 500, loss is 3.9334221029281617 and perplexity is 51.08148500728188
At time: 450.7711057662964 and batch: 550, loss is 3.894991645812988 and perplexity is 49.155642705536685
At time: 451.58850049972534 and batch: 600, loss is 3.8810870313644408 and perplexity is 48.476882332222246
At time: 452.4071023464203 and batch: 650, loss is 3.930796880722046 and perplexity is 50.947560626064046
At time: 453.2252700328827 and batch: 700, loss is 3.9553978729248045 and perplexity is 52.216465329755444
At time: 454.0498502254486 and batch: 750, loss is 3.9156172180175783 and perplexity is 50.18003397585088
At time: 454.8970310688019 and batch: 800, loss is 3.8948965215682985 and perplexity is 49.15096703454045
At time: 455.715852022171 and batch: 850, loss is 3.9109133100509643 and perplexity is 49.94454600535228
At time: 456.5354013442993 and batch: 900, loss is 3.862679696083069 and perplexity is 47.59271465623542
At time: 457.35381865501404 and batch: 950, loss is 3.9660095262527464 and perplexity is 52.773518759444
At time: 458.17328786849976 and batch: 1000, loss is 3.9265486001968384 and perplexity is 50.7315801940136
At time: 458.99242329597473 and batch: 1050, loss is 3.8749655628204347 and perplexity is 48.181039043435895
At time: 459.8117928504944 and batch: 1100, loss is 3.8991789054870605 and perplexity is 49.36190167455847
At time: 460.6308879852295 and batch: 1150, loss is 3.8664107084274293 and perplexity is 47.77061533055398
At time: 461.4500939846039 and batch: 1200, loss is 3.9382906103134157 and perplexity is 51.33078195389202
At time: 462.2696554660797 and batch: 1250, loss is 3.928404173851013 and perplexity is 50.825803770013366
At time: 463.097207069397 and batch: 1300, loss is 3.9161569118499755 and perplexity is 50.20712313996701
At time: 463.9234757423401 and batch: 1350, loss is 3.821738591194153 and perplexity is 45.68356435971776
At time: 464.75141429901123 and batch: 1400, loss is 3.828478260040283 and perplexity is 45.99249633543189
At time: 465.57014894485474 and batch: 1450, loss is 3.7545023107528688 and perplexity is 42.71295674050771
At time: 466.3881833553314 and batch: 1500, loss is 3.7787686920166017 and perplexity is 43.762123895129896
At time: 467.2059328556061 and batch: 1550, loss is 3.7833365058898925 and perplexity is 43.962478374402785
At time: 468.02338099479675 and batch: 1600, loss is 3.87488667011261 and perplexity is 48.177238060736826
At time: 468.8471875190735 and batch: 1650, loss is 3.816551537513733 and perplexity is 45.44721476800636
At time: 469.67795968055725 and batch: 1700, loss is 3.8408278942108156 and perplexity is 46.56400855961976
At time: 470.5091814994812 and batch: 1750, loss is 3.8245559215545653 and perplexity is 45.81245152617192
At time: 471.33261609077454 and batch: 1800, loss is 3.7965346002578735 and perplexity is 44.54654511846509
At time: 472.1608474254608 and batch: 1850, loss is 3.8275271224975587 and perplexity is 45.948771942735675
At time: 472.9872713088989 and batch: 1900, loss is 3.899936304092407 and perplexity is 49.399302471911994
At time: 473.81089329719543 and batch: 1950, loss is 3.8314592838287354 and perplexity is 46.12980562053749
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3338625885719475 and perplexity of 76.23819536154899
finished 14 epochs...
Completing Train Step...
At time: 476.6215035915375 and batch: 50, loss is 3.940714592933655 and perplexity is 51.45535780107835
At time: 477.469553232193 and batch: 100, loss is 3.9328953886032103 and perplexity is 51.05458674186146
At time: 478.2960033416748 and batch: 150, loss is 3.9007432889938354 and perplexity is 49.439183052496844
At time: 479.12219429016113 and batch: 200, loss is 3.8925959348678587 and perplexity is 49.03802094441924
At time: 479.9451732635498 and batch: 250, loss is 3.8855184221267702 and perplexity is 48.69217902033422
At time: 480.76537346839905 and batch: 300, loss is 3.8956181955337525 and perplexity is 49.186450810144656
At time: 481.58615350723267 and batch: 350, loss is 3.9146466207504274 and perplexity is 50.13135300064082
At time: 482.41334652900696 and batch: 400, loss is 3.8602445936203003 and perplexity is 47.47696251093141
At time: 483.23582911491394 and batch: 450, loss is 3.906570234298706 and perplexity is 49.72810341214516
At time: 484.05566477775574 and batch: 500, loss is 3.924619646072388 and perplexity is 50.633815625156686
At time: 484.8766005039215 and batch: 550, loss is 3.8863618993759155 and perplexity is 48.7332670915398
At time: 485.6978089809418 and batch: 600, loss is 3.872941269874573 and perplexity is 48.0836051566126
At time: 486.5226421356201 and batch: 650, loss is 3.922752704620361 and perplexity is 50.53937344233605
At time: 487.34423208236694 and batch: 700, loss is 3.9476262283325196 and perplexity is 51.812230339281605
At time: 488.1633987426758 and batch: 750, loss is 3.908295316696167 and perplexity is 49.81396252372918
At time: 488.98098945617676 and batch: 800, loss is 3.88781569480896 and perplexity is 48.80416681703604
At time: 489.79880809783936 and batch: 850, loss is 3.9038690328598022 and perplexity is 49.59395904469873
At time: 490.616498708725 and batch: 900, loss is 3.855772728919983 and perplexity is 47.26512596340801
At time: 491.43462085723877 and batch: 950, loss is 3.959405918121338 and perplexity is 52.426171257484775
At time: 492.2520360946655 and batch: 1000, loss is 3.920383987426758 and perplexity is 50.419801631319565
At time: 493.0739047527313 and batch: 1050, loss is 3.869347014427185 and perplexity is 47.91109061323857
At time: 493.8922872543335 and batch: 1100, loss is 3.893821859359741 and perplexity is 49.09817471978798
At time: 494.71027851104736 and batch: 1150, loss is 3.8610892486572266 and perplexity is 47.51708110725627
At time: 495.53043484687805 and batch: 1200, loss is 3.933213539123535 and perplexity is 51.07083236933874
At time: 496.37958002090454 and batch: 1250, loss is 3.9235507106781005 and perplexity is 50.57972026486066
At time: 497.1975402832031 and batch: 1300, loss is 3.9115736055374146 and perplexity is 49.977535053713716
At time: 498.0152099132538 and batch: 1350, loss is 3.817660927772522 and perplexity is 45.4976614427099
At time: 498.83455991744995 and batch: 1400, loss is 3.8248096656799317 and perplexity is 45.824077641582186
At time: 499.65728735923767 and batch: 1450, loss is 3.7512250661849977 and perplexity is 42.573205060351086
At time: 500.47525811195374 and batch: 1500, loss is 3.775515570640564 and perplexity is 43.619991706402864
At time: 501.29282879829407 and batch: 1550, loss is 3.78048481464386 and perplexity is 43.837289544451615
At time: 502.1098737716675 and batch: 1600, loss is 3.872192897796631 and perplexity is 48.047634190618716
At time: 502.9330790042877 and batch: 1650, loss is 3.813987545967102 and perplexity is 45.33083775212146
At time: 503.7513117790222 and batch: 1700, loss is 3.8389878034591676 and perplexity is 46.47840534110879
At time: 504.5688889026642 and batch: 1750, loss is 3.8230458211898806 and perplexity is 45.743322335559995
At time: 505.38746213912964 and batch: 1800, loss is 3.795522232055664 and perplexity is 44.50147043260793
At time: 506.20509099960327 and batch: 1850, loss is 3.826462368965149 and perplexity is 45.89987386232133
At time: 507.0323781967163 and batch: 1900, loss is 3.8989548778533933 and perplexity is 49.350844483137465
At time: 507.84984731674194 and batch: 1950, loss is 3.830378589630127 and perplexity is 46.07998033501819
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333594317768895 and perplexity of 76.21774562281266
finished 15 epochs...
Completing Train Step...
At time: 510.60689759254456 and batch: 50, loss is 3.932936849594116 and perplexity is 51.05670355950045
At time: 511.42585277557373 and batch: 100, loss is 3.924519248008728 and perplexity is 50.6287323432923
At time: 512.2452471256256 and batch: 150, loss is 3.892340831756592 and perplexity is 49.025512788208566
At time: 513.064471244812 and batch: 200, loss is 3.884333815574646 and perplexity is 48.634532097232224
At time: 513.884046792984 and batch: 250, loss is 3.877022156715393 and perplexity is 48.280229836814144
At time: 514.7032837867737 and batch: 300, loss is 3.8870251417160033 and perplexity is 48.76559977866402
At time: 515.5223121643066 and batch: 350, loss is 3.906295256614685 and perplexity is 49.71443117330457
At time: 516.3468654155731 and batch: 400, loss is 3.852155499458313 and perplexity is 47.09446600146593
At time: 517.1937212944031 and batch: 450, loss is 3.8987194681167603 and perplexity is 49.33922818118401
At time: 518.0129764080048 and batch: 500, loss is 3.9172449207305906 and perplexity is 50.26177866326919
At time: 518.8406665325165 and batch: 550, loss is 3.8790891456604 and perplexity is 48.380127746519406
At time: 519.6598584651947 and batch: 600, loss is 3.86606303691864 and perplexity is 47.75400973545964
At time: 520.4787402153015 and batch: 650, loss is 3.9159333086013794 and perplexity is 50.19589791917494
At time: 521.2974946498871 and batch: 700, loss is 3.9409076833724974 and perplexity is 51.46529429798736
At time: 522.1238725185394 and batch: 750, loss is 3.9020014905929568 and perplexity is 49.501426660965265
At time: 522.9467570781708 and batch: 800, loss is 3.8815783262252808 and perplexity is 48.50070462678789
At time: 523.7663621902466 and batch: 850, loss is 3.897779092788696 and perplexity is 49.292852596941835
At time: 524.5870881080627 and batch: 900, loss is 3.8497127389907835 and perplexity is 46.9795658955312
At time: 525.4078986644745 and batch: 950, loss is 3.953644218444824 and perplexity is 52.12497593524094
At time: 526.2270402908325 and batch: 1000, loss is 3.914948363304138 and perplexity is 50.14648204553975
At time: 527.0463624000549 and batch: 1050, loss is 3.8643501567840577 and perplexity is 47.67228285499406
At time: 527.8738486766815 and batch: 1100, loss is 3.8889205265045166 and perplexity is 48.85811700486161
At time: 528.6929614543915 and batch: 1150, loss is 3.8561727571487427 and perplexity is 47.28403713027737
At time: 529.5180323123932 and batch: 1200, loss is 3.928467526435852 and perplexity is 50.829023818056825
At time: 530.3357577323914 and batch: 1250, loss is 3.919036831855774 and perplexity is 50.3519240457633
At time: 531.1542148590088 and batch: 1300, loss is 3.9072126054763796 and perplexity is 49.76005757461518
At time: 531.9816303253174 and batch: 1350, loss is 3.813710446357727 and perplexity is 45.31827833487287
At time: 532.8010501861572 and batch: 1400, loss is 3.821139512062073 and perplexity is 45.65620448581384
At time: 533.6209139823914 and batch: 1450, loss is 3.7478338432312013 and perplexity is 42.42907435793688
At time: 534.4408612251282 and batch: 1500, loss is 3.7721077585220337 and perplexity is 43.47159596606893
At time: 535.2598958015442 and batch: 1550, loss is 3.777461977005005 and perplexity is 43.70497661663172
At time: 536.0795655250549 and batch: 1600, loss is 3.8691958570480347 and perplexity is 47.903849045671215
At time: 536.9050390720367 and batch: 1650, loss is 3.8110937690734863 and perplexity is 45.199850037284364
At time: 537.7269802093506 and batch: 1700, loss is 3.83662727355957 and perplexity is 46.36882106498021
At time: 538.5456352233887 and batch: 1750, loss is 3.820869216918945 and perplexity is 45.643865503146344
At time: 539.3649485111237 and batch: 1800, loss is 3.7938709926605223 and perplexity is 44.42804848677522
At time: 540.1862165927887 and batch: 1850, loss is 3.82467764377594 and perplexity is 45.818028258937574
At time: 541.0105595588684 and batch: 1900, loss is 3.8972289419174193 and perplexity is 49.26574154940492
At time: 541.837728023529 and batch: 1950, loss is 3.828636283874512 and perplexity is 45.99976482033036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333540379723837 and perplexity of 76.21363469748367
finished 16 epochs...
Completing Train Step...
At time: 544.6049132347107 and batch: 50, loss is 3.9258914184570313 and perplexity is 50.69825127865536
At time: 545.4646048545837 and batch: 100, loss is 3.9170786476135255 and perplexity is 50.253422175410506
At time: 546.2880988121033 and batch: 150, loss is 3.884872484207153 and perplexity is 48.66073705138944
At time: 547.1077167987823 and batch: 200, loss is 3.877027893066406 and perplexity is 48.28050678995384
At time: 547.9360976219177 and batch: 250, loss is 3.8695376253128053 and perplexity is 47.920223859071776
At time: 548.7663824558258 and batch: 300, loss is 3.8794313621520997 and perplexity is 48.39668705737782
At time: 549.5876033306122 and batch: 350, loss is 3.8989144563674927 and perplexity is 49.348849688989546
At time: 550.4158294200897 and batch: 400, loss is 3.84497576713562 and perplexity is 46.757551267784706
At time: 551.2360773086548 and batch: 450, loss is 3.891706595420837 and perplexity is 48.99442888493171
At time: 552.0564279556274 and batch: 500, loss is 3.9107237339019774 and perplexity is 49.93507860808239
At time: 552.8757116794586 and batch: 550, loss is 3.8726620960235594 and perplexity is 48.07018334498701
At time: 553.6953115463257 and batch: 600, loss is 3.8599388122558596 and perplexity is 47.462447159930335
At time: 554.5139031410217 and batch: 650, loss is 3.9097889184951784 and perplexity is 49.88842033909201
At time: 555.3426339626312 and batch: 700, loss is 3.934828062057495 and perplexity is 51.15335399806087
At time: 556.1704285144806 and batch: 750, loss is 3.8963110303878783 and perplexity is 49.220540705586885
At time: 556.9915633201599 and batch: 800, loss is 3.876108293533325 and perplexity is 48.23612846672297
At time: 557.8111970424652 and batch: 850, loss is 3.8922606754302977 and perplexity is 49.021583240699925
At time: 558.6679406166077 and batch: 900, loss is 3.844314007759094 and perplexity is 46.72661925571319
At time: 559.4992835521698 and batch: 950, loss is 3.9485467576980593 and perplexity is 51.85994697771698
At time: 560.3198239803314 and batch: 1000, loss is 3.909919471740723 and perplexity is 49.89493385945372
At time: 561.1397631168365 and batch: 1050, loss is 3.859690103530884 and perplexity is 47.450644303010556
At time: 561.9712145328522 and batch: 1100, loss is 3.884349002838135 and perplexity is 48.63527072829473
At time: 562.797171831131 and batch: 1150, loss is 3.851492123603821 and perplexity is 47.063235029921884
At time: 563.6219034194946 and batch: 1200, loss is 3.9239725923538207 and perplexity is 50.60106342383073
At time: 564.4420177936554 and batch: 1250, loss is 3.914722776412964 and perplexity is 50.135170932419165
At time: 565.2606587409973 and batch: 1300, loss is 3.903001456260681 and perplexity is 49.55095114539491
At time: 566.0806088447571 and batch: 1350, loss is 3.809867401123047 and perplexity is 45.1444523657415
At time: 566.900050163269 and batch: 1400, loss is 3.817513041496277 and perplexity is 45.49093346048166
At time: 567.7207856178284 and batch: 1450, loss is 3.744417457580566 and perplexity is 42.28436760491566
At time: 568.5468513965607 and batch: 1500, loss is 3.768603959083557 and perplexity is 43.31954674307847
At time: 569.3719561100006 and batch: 1550, loss is 3.774297399520874 and perplexity is 43.566887443871444
At time: 570.1922297477722 and batch: 1600, loss is 3.866061973571777 and perplexity is 47.75395895641019
At time: 571.0119936466217 and batch: 1650, loss is 3.8080310153961183 and perplexity is 45.06162581179421
At time: 571.8318176269531 and batch: 1700, loss is 3.834016971588135 and perplexity is 46.24794227365056
At time: 572.652069568634 and batch: 1750, loss is 3.818343343734741 and perplexity is 45.52872036947042
At time: 573.4714074134827 and batch: 1800, loss is 3.7918858194351195 and perplexity is 44.33993860009245
At time: 574.3030457496643 and batch: 1850, loss is 3.8224811506271363 and perplexity is 45.71749971931674
At time: 575.1229498386383 and batch: 1900, loss is 3.895131130218506 and perplexity is 49.162499629343166
At time: 575.9425706863403 and batch: 1950, loss is 3.826486139297485 and perplexity is 45.9009649305447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333615325218023 and perplexity of 76.21934678004452
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 578.6834111213684 and batch: 50, loss is 3.9286224842071533 and perplexity is 50.8369007805876
At time: 579.530131816864 and batch: 100, loss is 3.9306634187698366 and perplexity is 50.94076151888374
At time: 580.3486590385437 and batch: 150, loss is 3.9041594648361206 and perplexity is 49.608364808083444
At time: 581.1672441959381 and batch: 200, loss is 3.8960716104507447 and perplexity is 49.208757737420505
At time: 581.9939005374908 and batch: 250, loss is 3.8908649396896364 and perplexity is 48.95320979164009
At time: 582.812527179718 and batch: 300, loss is 3.8989652252197264 and perplexity is 49.35135513704614
At time: 583.6308689117432 and batch: 350, loss is 3.91815438747406 and perplexity is 50.30751087224042
At time: 584.4493033885956 and batch: 400, loss is 3.8661589670181273 and perplexity is 47.758591002101646
At time: 585.2723271846771 and batch: 450, loss is 3.9127938413619994 and perplexity is 50.03855665521117
At time: 586.0911240577698 and batch: 500, loss is 3.930263876914978 and perplexity is 50.920412617928086
At time: 586.9095935821533 and batch: 550, loss is 3.889237742424011 and perplexity is 48.873618035829
At time: 587.7277939319611 and batch: 600, loss is 3.872393741607666 and perplexity is 48.05728522972408
At time: 588.5565466880798 and batch: 650, loss is 3.916011004447937 and perplexity is 50.19979808346879
At time: 589.3751604557037 and batch: 700, loss is 3.938993525505066 and perplexity is 51.366875824305495
At time: 590.1929807662964 and batch: 750, loss is 3.8987706089019776 and perplexity is 49.341751492576726
At time: 591.0116004943848 and batch: 800, loss is 3.8807668924331664 and perplexity is 48.46136547882785
At time: 591.8298778533936 and batch: 850, loss is 3.8951657676696776 and perplexity is 49.164202522515325
At time: 592.647604227066 and batch: 900, loss is 3.8454465007781984 and perplexity is 46.77956680153069
At time: 593.4662456512451 and batch: 950, loss is 3.954061813354492 and perplexity is 52.14674760541099
At time: 594.291552066803 and batch: 1000, loss is 3.9089988470077515 and perplexity is 49.849020487028675
At time: 595.1103899478912 and batch: 1050, loss is 3.8622009992599486 and perplexity is 47.569937627006524
At time: 595.9279656410217 and batch: 1100, loss is 3.883638925552368 and perplexity is 48.60074818555072
At time: 596.7496523857117 and batch: 1150, loss is 3.8534199953079225 and perplexity is 47.15405442498156
At time: 597.570234298706 and batch: 1200, loss is 3.9225299549102783 and perplexity is 50.52811706527791
At time: 598.3882532119751 and batch: 1250, loss is 3.910188527107239 and perplexity is 49.9083601652994
At time: 599.2062828540802 and batch: 1300, loss is 3.899524869918823 and perplexity is 49.37898209126
At time: 600.0252115726471 and batch: 1350, loss is 3.804826946258545 and perplexity is 44.91747630305842
At time: 600.8461258411407 and batch: 1400, loss is 3.8102917003631593 and perplexity is 45.16361118682477
At time: 601.6692171096802 and batch: 1450, loss is 3.7333782148361205 and perplexity is 41.820147241605376
At time: 602.4969153404236 and batch: 1500, loss is 3.7585714435577393 and perplexity is 42.88711553129019
At time: 603.3150362968445 and batch: 1550, loss is 3.7661803150177002 and perplexity is 43.214682708557866
At time: 604.1332893371582 and batch: 1600, loss is 3.856859302520752 and perplexity is 47.316510913226246
At time: 604.9600667953491 and batch: 1650, loss is 3.7986999702453614 and perplexity is 44.64310938125806
At time: 605.7823832035065 and batch: 1700, loss is 3.82077796459198 and perplexity is 45.63970058423967
At time: 606.6055312156677 and batch: 1750, loss is 3.8026770067214968 and perplexity is 44.821010180173296
At time: 607.4239675998688 and batch: 1800, loss is 3.7786477994918823 and perplexity is 43.75683370126402
At time: 608.2492532730103 and batch: 1850, loss is 3.8035625076293944 and perplexity is 44.86071680291143
At time: 609.0712237358093 and batch: 1900, loss is 3.8765807294845582 and perplexity is 48.25892233185567
At time: 609.8955407142639 and batch: 1950, loss is 3.815237922668457 and perplexity is 45.38755382633914
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323877804778343 and perplexity of 75.48076116514085
finished 18 epochs...
Completing Train Step...
At time: 612.711407661438 and batch: 50, loss is 3.9281629371643065 and perplexity is 50.81354420030113
At time: 613.5298438072205 and batch: 100, loss is 3.9239198541641236 and perplexity is 50.598394885716566
At time: 614.3556797504425 and batch: 150, loss is 3.892084798812866 and perplexity is 49.0129622485961
At time: 615.1775336265564 and batch: 200, loss is 3.8817320442199708 and perplexity is 48.508160630890494
At time: 615.9991776943207 and batch: 250, loss is 3.877666039466858 and perplexity is 48.31132665432069
At time: 616.8185751438141 and batch: 300, loss is 3.885904550552368 and perplexity is 48.710984085109665
At time: 617.6373791694641 and batch: 350, loss is 3.9051795291900633 and perplexity is 49.6589943509874
At time: 618.4566829204559 and batch: 400, loss is 3.8534767913818357 and perplexity is 47.15673266619806
At time: 619.2757687568665 and batch: 450, loss is 3.9012942123413086 and perplexity is 49.46642775690324
At time: 620.0946564674377 and batch: 500, loss is 3.9197423887252807 and perplexity is 50.38746272747289
At time: 620.940836429596 and batch: 550, loss is 3.8798065042495726 and perplexity is 48.41484609796859
At time: 621.7593050003052 and batch: 600, loss is 3.8638927602767943 and perplexity is 47.65048270535913
At time: 622.5766890048981 and batch: 650, loss is 3.907899746894836 and perplexity is 49.79426152128788
At time: 623.394522190094 and batch: 700, loss is 3.9329077672958372 and perplexity is 51.05521873480955
At time: 624.213992357254 and batch: 750, loss is 3.8930986738204956 and perplexity is 49.06268046583982
At time: 625.0326793193817 and batch: 800, loss is 3.874999599456787 and perplexity is 48.182678991849905
At time: 625.8514442443848 and batch: 850, loss is 3.889778079986572 and perplexity is 48.900033423442395
At time: 626.6699187755585 and batch: 900, loss is 3.8408145189285277 and perplexity is 46.5633857570259
At time: 627.4878582954407 and batch: 950, loss is 3.9496428060531614 and perplexity is 51.916819148928965
At time: 628.3066585063934 and batch: 1000, loss is 3.905007171630859 and perplexity is 49.650435985499215
At time: 629.1268720626831 and batch: 1050, loss is 3.8583261442184447 and perplexity is 47.38596767300507
At time: 629.9451179504395 and batch: 1100, loss is 3.880458106994629 and perplexity is 48.446403624956545
At time: 630.7644362449646 and batch: 1150, loss is 3.850039587020874 and perplexity is 46.994923583777016
At time: 631.5842311382294 and batch: 1200, loss is 3.9195725870132447 and perplexity is 50.37890757639682
At time: 632.4029264450073 and batch: 1250, loss is 3.9079230546951296 and perplexity is 49.79542212951673
At time: 633.2262108325958 and batch: 1300, loss is 3.8971744632720946 and perplexity is 49.263057691651525
At time: 634.0566425323486 and batch: 1350, loss is 3.8031439685821535 and perplexity is 44.841944769930635
At time: 634.8771011829376 and batch: 1400, loss is 3.809276328086853 and perplexity is 45.11777658165935
At time: 635.6942076683044 and batch: 1450, loss is 3.7329932498931884 and perplexity is 41.804051049442734
At time: 636.5115385055542 and batch: 1500, loss is 3.758655152320862 and perplexity is 42.89070570894778
At time: 637.3289518356323 and batch: 1550, loss is 3.7666079139709474 and perplexity is 43.2331652129171
At time: 638.146448135376 and batch: 1600, loss is 3.8575340938568115 and perplexity is 47.34845045989578
At time: 638.964271068573 and batch: 1650, loss is 3.799892683029175 and perplexity is 44.696387554989755
At time: 639.7860527038574 and batch: 1700, loss is 3.8224072647094727 and perplexity is 45.71412196468248
At time: 640.6094822883606 and batch: 1750, loss is 3.8048015785217286 and perplexity is 44.91633686279368
At time: 641.4270787239075 and batch: 1800, loss is 3.781307077407837 and perplexity is 43.87335013892798
At time: 642.2443664073944 and batch: 1850, loss is 3.8062550020217896 and perplexity is 44.98166678684969
At time: 643.0621113777161 and batch: 1900, loss is 3.8793202781677247 and perplexity is 48.391311259137005
At time: 643.8794143199921 and batch: 1950, loss is 3.817904915809631 and perplexity is 45.5087636821701
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323254962300146 and perplexity of 75.4337631784911
finished 19 epochs...
Completing Train Step...
At time: 646.6146667003632 and batch: 50, loss is 3.925528311729431 and perplexity is 50.67984574432741
At time: 647.4609725475311 and batch: 100, loss is 3.9205200242996217 and perplexity is 50.42666105002026
At time: 648.2800993919373 and batch: 150, loss is 3.88816309928894 and perplexity is 48.8211245486554
At time: 649.0999202728271 and batch: 200, loss is 3.877408604621887 and perplexity is 48.298891236156756
At time: 649.9187326431274 and batch: 250, loss is 3.8732732009887694 and perplexity is 48.099568250424014
At time: 650.7378234863281 and batch: 300, loss is 3.8814294576644897 and perplexity is 48.49348493409871
At time: 651.557386636734 and batch: 350, loss is 3.9007383489608767 and perplexity is 49.43893882190636
At time: 652.3766014575958 and batch: 400, loss is 3.8489564514160155 and perplexity is 46.94404926566223
At time: 653.1950917243958 and batch: 450, loss is 3.896976184844971 and perplexity is 49.25329085836528
At time: 654.0261352062225 and batch: 500, loss is 3.915590124130249 and perplexity is 50.17867442208205
At time: 654.8458375930786 and batch: 550, loss is 3.8759065866470337 and perplexity is 48.22639988863678
At time: 655.6657128334045 and batch: 600, loss is 3.860311436653137 and perplexity is 47.4801361211612
At time: 656.4853539466858 and batch: 650, loss is 3.9044702196121217 and perplexity is 49.62378323992875
At time: 657.3049039840698 and batch: 700, loss is 3.9297785425186156 and perplexity is 50.895705186375814
At time: 658.1243929862976 and batch: 750, loss is 3.8901084518432616 and perplexity is 48.91619128718143
At time: 658.945564031601 and batch: 800, loss is 3.8721505212783813 and perplexity is 48.045598142312215
At time: 659.7647240161896 and batch: 850, loss is 3.887007622718811 and perplexity is 48.76474546174181
At time: 660.5845665931702 and batch: 900, loss is 3.8382541513442994 and perplexity is 46.44431886607074
At time: 661.4040355682373 and batch: 950, loss is 3.9473861980438234 and perplexity is 51.79979532712475
At time: 662.2520136833191 and batch: 1000, loss is 3.902857789993286 and perplexity is 49.54383285653922
At time: 663.0717339515686 and batch: 1050, loss is 3.856245994567871 and perplexity is 47.28750021793501
At time: 663.8917310237885 and batch: 1100, loss is 3.878742299079895 and perplexity is 48.36335017443607
At time: 664.7106468677521 and batch: 1150, loss is 3.8483318853378297 and perplexity is 46.914738759045086
At time: 665.5297482013702 and batch: 1200, loss is 3.9181059837341308 and perplexity is 50.30507585950002
At time: 666.3578510284424 and batch: 1250, loss is 3.906675629615784 and perplexity is 49.733344797575846
At time: 667.1772680282593 and batch: 1300, loss is 3.8960270500183105 and perplexity is 49.206565022750695
At time: 667.9962384700775 and batch: 1350, loss is 3.8022058248519897 and perplexity is 44.79989630743105
At time: 668.8136487007141 and batch: 1400, loss is 3.8085532569885254 and perplexity is 45.085165013054585
At time: 669.6362891197205 and batch: 1450, loss is 3.732582211494446 and perplexity is 41.786871510205444
At time: 670.45760846138 and batch: 1500, loss is 3.7583343982696533 and perplexity is 42.87695054746226
At time: 671.2791004180908 and batch: 1550, loss is 3.766603932380676 and perplexity is 43.232993076509786
At time: 672.1001462936401 and batch: 1600, loss is 3.857651405334473 and perplexity is 47.35400530240123
At time: 672.9254102706909 and batch: 1650, loss is 3.800141987800598 and perplexity is 44.707531966792395
At time: 673.7545442581177 and batch: 1700, loss is 3.822900819778442 and perplexity is 45.73668997012025
At time: 674.5833623409271 and batch: 1750, loss is 3.805469846725464 and perplexity is 44.94636305420442
At time: 675.4026365280151 and batch: 1800, loss is 3.7822437381744383 and perplexity is 43.91446383649035
At time: 676.2282705307007 and batch: 1850, loss is 3.807193260192871 and perplexity is 45.02389100877434
At time: 677.0513632297516 and batch: 1900, loss is 3.8801299285888673 and perplexity is 48.4305071700293
At time: 677.8706040382385 and batch: 1950, loss is 3.8186769676208496 and perplexity is 45.54391237215621
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.323007982830669 and perplexity of 75.41513488817796
Finished Training.
Improved accuracyfrom -10000000 to -75.41513488817796
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdf90580b38>
ELAPSED
710.2189033031464


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}, 'best_accuracy': -75.41513488817796}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.6309802267622319, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.016023383857180606, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3059594631195068 and batch: 50, loss is 7.394167518615722 and perplexity is 1626.4703535705053
At time: 2.123143196105957 and batch: 100, loss is 6.678641910552979 and perplexity is 795.238373469333
At time: 2.9396603107452393 and batch: 150, loss is 6.454211091995239 and perplexity is 635.3722782043047
At time: 3.7572600841522217 and batch: 200, loss is 6.323690195083618 and perplexity is 557.6269526027409
At time: 4.601236343383789 and batch: 250, loss is 6.262723989486695 and perplexity is 524.646125937201
At time: 5.418389558792114 and batch: 300, loss is 6.188275384902954 and perplexity is 487.0054845374002
At time: 6.235928773880005 and batch: 350, loss is 6.143525333404541 and perplexity is 465.69240142892016
At time: 7.053117275238037 and batch: 400, loss is 6.095852603912354 and perplexity is 444.01245059174295
At time: 7.870281219482422 and batch: 450, loss is 6.006799440383912 and perplexity is 406.18123043438675
At time: 8.687832355499268 and batch: 500, loss is 5.9908147811889645 and perplexity is 399.7401780532573
At time: 9.504469156265259 and batch: 550, loss is 5.941785640716553 and perplexity is 380.61396289234295
At time: 10.322224855422974 and batch: 600, loss is 5.974520683288574 and perplexity is 393.2795504461773
At time: 11.138259649276733 and batch: 650, loss is 6.033873243331909 and perplexity is 417.328317158696
At time: 11.954859495162964 and batch: 700, loss is 5.956919651031495 and perplexity is 386.4179868336546
At time: 12.77230978012085 and batch: 750, loss is 5.8881425952911375 and perplexity is 360.73463152497345
At time: 13.590103149414062 and batch: 800, loss is 5.889759330749512 and perplexity is 361.31831569913624
At time: 14.407114505767822 and batch: 850, loss is 5.920761957168579 and perplexity is 372.69558378585515
At time: 15.223744630813599 and batch: 900, loss is 5.9132310581207275 and perplexity is 369.89939309902775
At time: 16.0503671169281 and batch: 950, loss is 5.934778938293457 and perplexity is 377.95643524134954
At time: 16.86968231201172 and batch: 1000, loss is 5.906595592498779 and perplexity is 367.45306363592823
At time: 17.68663763999939 and batch: 1050, loss is 5.807572698593139 and perplexity is 332.8103135140226
At time: 18.50471329689026 and batch: 1100, loss is 5.88535514831543 and perplexity is 359.73050299497476
At time: 19.322893142700195 and batch: 1150, loss is 5.796040964126587 and perplexity is 328.9944772421942
At time: 20.14084506034851 and batch: 1200, loss is 5.877294006347657 and perplexity is 356.8423210027003
At time: 20.958314418792725 and batch: 1250, loss is 5.813232545852661 and perplexity is 334.69930972727354
At time: 21.776092767715454 and batch: 1300, loss is 5.8280902671813966 and perplexity is 339.7093051948908
At time: 22.593629598617554 and batch: 1350, loss is 5.794154424667358 and perplexity is 328.3744012618165
At time: 23.41149616241455 and batch: 1400, loss is 5.811966896057129 and perplexity is 334.27596557358504
At time: 24.229419708251953 and batch: 1450, loss is 5.792509593963623 and perplexity is 327.8347249240788
At time: 25.047958850860596 and batch: 1500, loss is 5.7648263263702395 and perplexity is 318.8836575445229
At time: 25.86580204963684 and batch: 1550, loss is 5.743271093368531 and perplexity is 312.08359773207167
At time: 26.68356466293335 and batch: 1600, loss is 5.764274053573608 and perplexity is 318.70759539681313
At time: 27.501296043395996 and batch: 1650, loss is 5.758675813674927 and perplexity is 316.9283787079394
At time: 28.319517612457275 and batch: 1700, loss is 5.7750070190429685 and perplexity is 322.14669587204133
At time: 29.136826038360596 and batch: 1750, loss is 5.778408441543579 and perplexity is 323.24431857289255
At time: 29.955605506896973 and batch: 1800, loss is 5.776168308258057 and perplexity is 322.5210186620759
At time: 30.7729914188385 and batch: 1850, loss is 5.733762111663818 and perplexity is 309.1300653087988
At time: 31.590959548950195 and batch: 1900, loss is 5.741048898696899 and perplexity is 311.39085721130624
At time: 32.409679889678955 and batch: 1950, loss is 5.676778583526612 and perplexity is 292.00723621709324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.093580237100291 and perplexity of 162.97229827005617
finished 1 epochs...
Completing Train Step...
At time: 35.1654908657074 and batch: 50, loss is 5.334367885589599 and perplexity is 207.34164373472078
At time: 36.006651639938354 and batch: 100, loss is 5.245956268310547 and perplexity is 189.79722554944803
At time: 36.819315910339355 and batch: 150, loss is 5.161685094833374 and perplexity is 174.45818664222975
At time: 37.63185358047485 and batch: 200, loss is 5.109533329010009 and perplexity is 165.59305936239784
At time: 38.44413876533508 and batch: 250, loss is 5.122874021530151 and perplexity is 167.81698683375708
At time: 39.25672173500061 and batch: 300, loss is 5.122652044296265 and perplexity is 167.7797394174127
At time: 40.06890320777893 and batch: 350, loss is 5.115550479888916 and perplexity is 166.59246154657674
At time: 40.88912868499756 and batch: 400, loss is 5.064781980514526 and perplexity is 158.34591581502696
At time: 41.70771765708923 and batch: 450, loss is 5.026998615264892 and perplexity is 152.47469003119977
At time: 42.52718949317932 and batch: 500, loss is 5.0134236526489255 and perplexity is 150.4188374460181
At time: 43.3398060798645 and batch: 550, loss is 4.968608865737915 and perplexity is 143.82666593297753
At time: 44.15277028083801 and batch: 600, loss is 4.956832733154297 and perplexity is 142.14287776082466
At time: 44.9650137424469 and batch: 650, loss is 5.029023609161377 and perplexity is 152.7837631778837
At time: 45.781391620635986 and batch: 700, loss is 5.018467359542846 and perplexity is 151.1794224449466
At time: 46.59720516204834 and batch: 750, loss is 4.970510530471802 and perplexity is 144.10043625855783
At time: 47.41469359397888 and batch: 800, loss is 4.9431445503234865 and perplexity is 140.21045590623768
At time: 48.25894808769226 and batch: 850, loss is 4.939453449249267 and perplexity is 139.69387889729848
At time: 49.07563233375549 and batch: 900, loss is 4.954012098312378 and perplexity is 141.74250951903161
At time: 49.90302634239197 and batch: 950, loss is 5.0034926223754885 and perplexity is 148.93241647999992
At time: 50.7206597328186 and batch: 1000, loss is 4.975432653427124 and perplexity is 144.81146477310048
At time: 51.538891315460205 and batch: 1050, loss is 4.881270294189453 and perplexity is 131.7979798010366
At time: 52.35676574707031 and batch: 1100, loss is 4.9562929916381835 and perplexity is 142.06617804934862
At time: 53.17419362068176 and batch: 1150, loss is 4.87572793006897 and perplexity is 131.06952794405524
At time: 53.99188208580017 and batch: 1200, loss is 4.956672897338867 and perplexity is 142.1201600536503
At time: 54.809916734695435 and batch: 1250, loss is 4.913139038085937 and perplexity is 136.06586066159494
At time: 55.62723731994629 and batch: 1300, loss is 4.932044477462768 and perplexity is 138.66271553687884
At time: 56.44482159614563 and batch: 1350, loss is 4.840608940124512 and perplexity is 126.54638744559291
At time: 57.26039218902588 and batch: 1400, loss is 4.848888969421386 and perplexity is 127.5985451782585
At time: 58.07680153846741 and batch: 1450, loss is 4.793549470901489 and perplexity is 120.72913359116878
At time: 58.894105434417725 and batch: 1500, loss is 4.781018257141113 and perplexity is 119.22569066727799
At time: 59.71200680732727 and batch: 1550, loss is 4.776408681869507 and perplexity is 118.67737559253398
At time: 60.530365228652954 and batch: 1600, loss is 4.839512777328491 and perplexity is 126.4077480032857
At time: 61.347893953323364 and batch: 1650, loss is 4.813645114898682 and perplexity is 123.17980471548347
At time: 62.16551899909973 and batch: 1700, loss is 4.826681079864502 and perplexity is 124.79608432779057
At time: 62.98280668258667 and batch: 1750, loss is 4.830049781799317 and perplexity is 125.21719403683396
At time: 63.80082106590271 and batch: 1800, loss is 4.788904752731323 and perplexity is 120.16968104618442
At time: 64.6182587146759 and batch: 1850, loss is 4.80475962638855 and perplexity is 122.0901402458141
At time: 65.43648386001587 and batch: 1900, loss is 4.8812486743927 and perplexity is 131.79513038630287
At time: 66.25456237792969 and batch: 1950, loss is 4.7971791076660155 and perplexity is 121.16813271472255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.64622320130814 and perplexity of 104.19073411324516
finished 2 epochs...
Completing Train Step...
At time: 69.01763153076172 and batch: 50, loss is 4.743671607971192 and perplexity is 114.85513147895769
At time: 69.83432269096375 and batch: 100, loss is 4.696409578323364 and perplexity is 109.5531235650107
At time: 70.6520037651062 and batch: 150, loss is 4.654830980300903 and perplexity is 105.0914559714407
At time: 71.46934819221497 and batch: 200, loss is 4.63630256652832 and perplexity is 103.16220615333533
At time: 72.28655076026917 and batch: 250, loss is 4.6397362804412845 and perplexity is 103.51704451396384
At time: 73.10451912879944 and batch: 300, loss is 4.6645303440094 and perplexity is 106.1157356258771
At time: 73.92199945449829 and batch: 350, loss is 4.676433134078979 and perplexity is 107.38635591199807
At time: 74.73916244506836 and batch: 400, loss is 4.629591932296753 and perplexity is 102.47223996592308
At time: 75.55778813362122 and batch: 450, loss is 4.627567024230957 and perplexity is 102.26495304000737
At time: 76.37551474571228 and batch: 500, loss is 4.633941793441773 and perplexity is 102.91895084177293
At time: 77.19328951835632 and batch: 550, loss is 4.5906577396392825 and perplexity is 98.55923516298505
At time: 78.01111054420471 and batch: 600, loss is 4.579483108520508 and perplexity is 97.46400287210832
At time: 78.8298351764679 and batch: 650, loss is 4.657866191864014 and perplexity is 105.41091534192515
At time: 79.64794087409973 and batch: 700, loss is 4.663271350860596 and perplexity is 105.98222070656395
At time: 80.46605563163757 and batch: 750, loss is 4.628988962173462 and perplexity is 102.41047089108174
At time: 81.2839047908783 and batch: 800, loss is 4.595671434402465 and perplexity is 99.05462190542666
At time: 82.1021978855133 and batch: 850, loss is 4.5930172729492185 and perplexity is 98.79206353648465
At time: 82.91940021514893 and batch: 900, loss is 4.607384796142578 and perplexity is 100.22170642148163
At time: 83.737220287323 and batch: 950, loss is 4.667162055969238 and perplexity is 106.39536947292746
At time: 84.5543372631073 and batch: 1000, loss is 4.641874084472656 and perplexity is 103.7385803848083
At time: 85.37166953086853 and batch: 1050, loss is 4.565218687057495 and perplexity is 96.08360395976705
At time: 86.18925929069519 and batch: 1100, loss is 4.633719263076782 and perplexity is 102.89605079814964
At time: 87.00733733177185 and batch: 1150, loss is 4.574724855422974 and perplexity is 97.00134607053998
At time: 87.82474446296692 and batch: 1200, loss is 4.656696081161499 and perplexity is 105.28764503573868
At time: 88.64233994483948 and batch: 1250, loss is 4.627559909820556 and perplexity is 102.26422548774993
At time: 89.47133302688599 and batch: 1300, loss is 4.635602111816406 and perplexity is 103.08997100162345
At time: 90.29170346260071 and batch: 1350, loss is 4.533168087005615 and perplexity is 93.05289426452116
At time: 91.10899090766907 and batch: 1400, loss is 4.539911680221557 and perplexity is 93.68252573416662
At time: 91.92709517478943 and batch: 1450, loss is 4.484121227264405 and perplexity is 88.5990581562946
At time: 92.74482369422913 and batch: 1500, loss is 4.4861008834838865 and perplexity is 88.77462755900535
At time: 93.56280207633972 and batch: 1550, loss is 4.4868753623962405 and perplexity is 88.84340826716792
At time: 94.38070726394653 and batch: 1600, loss is 4.56352858543396 and perplexity is 95.92135005613493
At time: 95.19854855537415 and batch: 1650, loss is 4.5376208209991455 and perplexity is 93.46815789313332
At time: 96.01639294624329 and batch: 1700, loss is 4.55221001625061 and perplexity is 94.84177874594516
At time: 96.83338689804077 and batch: 1750, loss is 4.55520959854126 and perplexity is 95.1266915619788
At time: 97.65046262741089 and batch: 1800, loss is 4.514838562011719 and perplexity is 91.36281540264282
At time: 98.46747374534607 and batch: 1850, loss is 4.546350154876709 and perplexity is 94.28764423141241
At time: 99.2857358455658 and batch: 1900, loss is 4.626358585357666 and perplexity is 102.14144673531835
At time: 100.10273718833923 and batch: 1950, loss is 4.554514408111572 and perplexity is 95.06058337794796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.548021041515262 and perplexity of 94.44531988872976
finished 3 epochs...
Completing Train Step...
At time: 102.84140992164612 and batch: 50, loss is 4.514801187515259 and perplexity is 91.35940082723137
At time: 103.68563532829285 and batch: 100, loss is 4.479395895004273 and perplexity is 88.18138576615642
At time: 104.50398588180542 and batch: 150, loss is 4.438635778427124 and perplexity is 84.6593687210394
At time: 105.3268301486969 and batch: 200, loss is 4.4242887210845945 and perplexity is 83.45342744339356
At time: 106.14614367485046 and batch: 250, loss is 4.427550668716431 and perplexity is 83.72609262140706
At time: 106.96681475639343 and batch: 300, loss is 4.455188140869141 and perplexity is 86.07234304731303
At time: 107.7863781452179 and batch: 350, loss is 4.465906686782837 and perplexity is 86.99987542724723
At time: 108.60579347610474 and batch: 400, loss is 4.421010932922363 and perplexity is 83.18033260484495
At time: 109.42577719688416 and batch: 450, loss is 4.437286205291748 and perplexity is 84.54519177375563
At time: 110.28978395462036 and batch: 500, loss is 4.4482745265960695 and perplexity is 85.47932438115508
At time: 111.10930037498474 and batch: 550, loss is 4.404819097518921 and perplexity is 81.84433566049668
At time: 111.92937016487122 and batch: 600, loss is 4.396366300582886 and perplexity is 81.15543776957975
At time: 112.74935150146484 and batch: 650, loss is 4.473108072280883 and perplexity is 87.62865639818666
At time: 113.56939482688904 and batch: 700, loss is 4.480913372039795 and perplexity is 88.31530057464283
At time: 114.38880944252014 and batch: 750, loss is 4.45394850730896 and perplexity is 85.9657109882627
At time: 115.20880222320557 and batch: 800, loss is 4.415657615661621 and perplexity is 82.73623166176596
At time: 116.02829313278198 and batch: 850, loss is 4.417883777618409 and perplexity is 82.92062107734075
At time: 116.84790468215942 and batch: 900, loss is 4.425367259979248 and perplexity is 83.54348376667733
At time: 117.66714477539062 and batch: 950, loss is 4.495182361602783 and perplexity is 89.58450426941893
At time: 118.48679852485657 and batch: 1000, loss is 4.469624252319336 and perplexity is 87.32390509339307
At time: 119.30700206756592 and batch: 1050, loss is 4.401966562271118 and perplexity is 81.61120447373746
At time: 120.12677145004272 and batch: 1100, loss is 4.4649788284301755 and perplexity is 86.91918930458667
At time: 120.94649362564087 and batch: 1150, loss is 4.411659593582153 and perplexity is 82.40611073591144
At time: 121.76578211784363 and batch: 1200, loss is 4.490761823654175 and perplexity is 89.18936657273402
At time: 122.58555626869202 and batch: 1250, loss is 4.470942831039428 and perplexity is 87.43912448262815
At time: 123.40534472465515 and batch: 1300, loss is 4.469648342132569 and perplexity is 87.32600873529562
At time: 124.22552061080933 and batch: 1350, loss is 4.369058599472046 and perplexity is 78.96925499757728
At time: 125.0448591709137 and batch: 1400, loss is 4.373455781936645 and perplexity is 79.31726178483437
At time: 125.86470317840576 and batch: 1450, loss is 4.315438370704651 and perplexity is 74.84642673424501
At time: 126.68411636352539 and batch: 1500, loss is 4.323333616256714 and perplexity is 75.43969657576345
At time: 127.50404119491577 and batch: 1550, loss is 4.322643136978149 and perplexity is 75.38762500773484
At time: 128.3236858844757 and batch: 1600, loss is 4.407414398193359 and perplexity is 82.05702219340581
At time: 129.14365911483765 and batch: 1650, loss is 4.383719596862793 and perplexity is 80.13555168467569
At time: 129.96325087547302 and batch: 1700, loss is 4.400275630950928 and perplexity is 81.47332213964626
At time: 130.7839117050171 and batch: 1750, loss is 4.402851343154907 and perplexity is 81.68344446092598
At time: 131.6038839817047 and batch: 1800, loss is 4.35901478767395 and perplexity is 78.1800724970623
At time: 132.42335867881775 and batch: 1850, loss is 4.3989488220214845 and perplexity is 81.36529429032542
At time: 133.24349784851074 and batch: 1900, loss is 4.472710399627686 and perplexity is 87.5938158059352
At time: 134.0629711151123 and batch: 1950, loss is 4.4103779602050786 and perplexity is 82.30056396449737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509790890715843 and perplexity of 90.90280790186323
finished 4 epochs...
Completing Train Step...
At time: 136.80273604393005 and batch: 50, loss is 4.373472833633423 and perplexity is 79.31861429026281
At time: 137.64639711380005 and batch: 100, loss is 4.343898420333862 and perplexity is 77.00716121595967
At time: 138.46271204948425 and batch: 150, loss is 4.3047764873504635 and perplexity is 74.05266189628718
At time: 139.2799370288849 and batch: 200, loss is 4.291717357635498 and perplexity is 73.09188568370075
At time: 140.09640836715698 and batch: 250, loss is 4.29209997177124 and perplexity is 73.11985702314503
At time: 140.9133162498474 and batch: 300, loss is 4.323057584762573 and perplexity is 75.41887571733864
At time: 141.72931671142578 and batch: 350, loss is 4.33674765586853 and perplexity is 76.45846527971895
At time: 142.55757880210876 and batch: 400, loss is 4.287557497024536 and perplexity is 72.78846515855311
At time: 143.37445068359375 and batch: 450, loss is 4.312305955886841 and perplexity is 74.61234349239268
At time: 144.1902449131012 and batch: 500, loss is 4.329322967529297 and perplexity is 75.89288722269222
At time: 145.0069456100464 and batch: 550, loss is 4.283932189941407 and perplexity is 72.52506236673574
At time: 145.82335925102234 and batch: 600, loss is 4.279314699172974 and perplexity is 72.19095053356911
At time: 146.64049220085144 and batch: 650, loss is 4.354702396392822 and perplexity is 77.84365533663717
At time: 147.4572892189026 and batch: 700, loss is 4.362480344772339 and perplexity is 78.45148001975488
At time: 148.2740569114685 and batch: 750, loss is 4.340006980895996 and perplexity is 76.70807482751894
At time: 149.09083080291748 and batch: 800, loss is 4.295160036087037 and perplexity is 73.34395118480346
At time: 149.9149558544159 and batch: 850, loss is 4.3006230735778805 and perplexity is 73.74572840260907
At time: 150.7309820652008 and batch: 900, loss is 4.3069100761413575 and perplexity is 74.21082849688752
At time: 151.5737600326538 and batch: 950, loss is 4.380795364379883 and perplexity is 79.90155899266071
At time: 152.38947939872742 and batch: 1000, loss is 4.35502742767334 and perplexity is 77.86896107196642
At time: 153.2069547176361 and batch: 1050, loss is 4.2923557090759275 and perplexity is 73.13855888957981
At time: 154.02328372001648 and batch: 1100, loss is 4.350679121017456 and perplexity is 77.5310980486199
At time: 154.83969163894653 and batch: 1150, loss is 4.296382722854614 and perplexity is 73.4336827089938
At time: 155.6563220024109 and batch: 1200, loss is 4.377019472122193 and perplexity is 79.60042819119136
At time: 156.48123860359192 and batch: 1250, loss is 4.360131826400757 and perplexity is 78.26745145946273
At time: 157.3024706840515 and batch: 1300, loss is 4.353762931823731 and perplexity is 77.77055832192379
At time: 158.11964058876038 and batch: 1350, loss is 4.259154915809631 and perplexity is 70.75016833470488
At time: 158.9359142780304 and batch: 1400, loss is 4.266127090454102 and perplexity is 71.24517449392008
At time: 159.76565980911255 and batch: 1450, loss is 4.203887891769409 and perplexity is 66.94610493768683
At time: 160.58736968040466 and batch: 1500, loss is 4.215482773780823 and perplexity is 67.72685472935603
At time: 161.40483212471008 and batch: 1550, loss is 4.213902926445007 and perplexity is 67.619941114181
At time: 162.22319889068604 and batch: 1600, loss is 4.300664978027344 and perplexity is 73.74881874150708
At time: 163.0443286895752 and batch: 1650, loss is 4.278297400474548 and perplexity is 72.11754811597544
At time: 163.86994862556458 and batch: 1700, loss is 4.2940777397155765 and perplexity is 73.26461423335931
At time: 164.6931185722351 and batch: 1750, loss is 4.29665602684021 and perplexity is 73.453755169972
At time: 165.51767301559448 and batch: 1800, loss is 4.256294565200806 and perplexity is 70.548087196866
At time: 166.33435535430908 and batch: 1850, loss is 4.297164258956909 and perplexity is 73.4910962155971
At time: 167.163747549057 and batch: 1900, loss is 4.367423973083496 and perplexity is 78.84027521507167
At time: 167.98105883598328 and batch: 1950, loss is 4.30549373626709 and perplexity is 74.10579514040866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.491301212754361 and perplexity of 89.23748732165286
finished 5 epochs...
Completing Train Step...
At time: 170.77460932731628 and batch: 50, loss is 4.272550873756408 and perplexity is 71.70431117462064
At time: 171.5929992198944 and batch: 100, loss is 4.24752836227417 and perplexity is 69.93235112517137
At time: 172.43768310546875 and batch: 150, loss is 4.208996424674988 and perplexity is 67.28897635696278
At time: 173.2557156085968 and batch: 200, loss is 4.199527111053467 and perplexity is 66.6548032672464
At time: 174.07433104515076 and batch: 250, loss is 4.197336120605469 and perplexity is 66.50892309935928
At time: 174.89210319519043 and batch: 300, loss is 4.228025665283203 and perplexity is 68.58169519842835
At time: 175.70967745780945 and batch: 350, loss is 4.23581524848938 and perplexity is 69.1180041192529
At time: 176.52705812454224 and batch: 400, loss is 4.188652443885803 and perplexity is 65.93388146349724
At time: 177.34514617919922 and batch: 450, loss is 4.220105257034302 and perplexity is 68.04064566909537
At time: 178.16709852218628 and batch: 500, loss is 4.2423629426956175 and perplexity is 69.5720525372955
At time: 178.99213075637817 and batch: 550, loss is 4.193888864517212 and perplexity is 66.28004453744752
At time: 179.81035447120667 and batch: 600, loss is 4.194388470649719 and perplexity is 66.31316672749696
At time: 180.63755679130554 and batch: 650, loss is 4.262100601196289 and perplexity is 70.95888332510121
At time: 181.45721411705017 and batch: 700, loss is 4.275435209274292 and perplexity is 71.91142902121646
At time: 182.27465653419495 and batch: 750, loss is 4.2536364269256595 and perplexity is 70.3608096411397
At time: 183.09239602088928 and batch: 800, loss is 4.208644313812256 and perplexity is 67.26528734826879
At time: 183.9103500843048 and batch: 850, loss is 4.215625886917114 and perplexity is 67.73654802554994
At time: 184.72837018966675 and batch: 900, loss is 4.220494413375855 and perplexity is 68.06712927063738
At time: 185.5464346408844 and batch: 950, loss is 4.2959937000274655 and perplexity is 73.4051208860992
At time: 186.3649401664734 and batch: 1000, loss is 4.269745559692383 and perplexity is 71.50343994720532
At time: 187.18316197395325 and batch: 1050, loss is 4.211955251693726 and perplexity is 67.48836763495449
At time: 188.0006308555603 and batch: 1100, loss is 4.267904357910156 and perplexity is 71.37190881097825
At time: 188.81810903549194 and batch: 1150, loss is 4.21190948009491 and perplexity is 67.48527865516066
At time: 189.63616180419922 and batch: 1200, loss is 4.291129546165466 and perplexity is 73.0489340598949
At time: 190.45435905456543 and batch: 1250, loss is 4.278414106369018 and perplexity is 72.12596515008451
At time: 191.27281522750854 and batch: 1300, loss is 4.268250885009766 and perplexity is 71.39664539723334
At time: 192.09072971343994 and batch: 1350, loss is 4.176243319511413 and perplexity is 65.12075525423104
At time: 192.90896463394165 and batch: 1400, loss is 4.186656475067139 and perplexity is 65.80241074138064
At time: 193.72710752487183 and batch: 1450, loss is 4.1204539489746095 and perplexity is 61.58719336303847
At time: 194.54545092582703 and batch: 1500, loss is 4.136594862937927 and perplexity is 62.5893329194173
At time: 195.36273884773254 and batch: 1550, loss is 4.136867246627808 and perplexity is 62.606383554917144
At time: 196.17905378341675 and batch: 1600, loss is 4.221398530006408 and perplexity is 68.12869772254166
At time: 196.9957184791565 and batch: 1650, loss is 4.1952878189086915 and perplexity is 66.37283218453115
At time: 197.81442594528198 and batch: 1700, loss is 4.216770606040955 and perplexity is 67.81413174476926
At time: 198.6319239139557 and batch: 1750, loss is 4.218330559730529 and perplexity is 67.92000120404757
At time: 199.44996070861816 and batch: 1800, loss is 4.182580499649048 and perplexity is 65.53474759751509
At time: 200.26704931259155 and batch: 1850, loss is 4.219027738571167 and perplexity is 67.9673701021212
At time: 201.08461928367615 and batch: 1900, loss is 4.287115135192871 and perplexity is 72.75627344050014
At time: 201.901704788208 and batch: 1950, loss is 4.226908435821533 and perplexity is 68.50511649397924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482818745457849 and perplexity of 88.48373461467895
finished 6 epochs...
Completing Train Step...
At time: 204.63194799423218 and batch: 50, loss is 4.197833867073059 and perplexity is 66.54203592110659
At time: 205.47725582122803 and batch: 100, loss is 4.173935475349427 and perplexity is 64.97063998734252
At time: 206.29705286026 and batch: 150, loss is 4.136025447845459 and perplexity is 62.55370375348055
At time: 207.11730670928955 and batch: 200, loss is 4.127094831466675 and perplexity is 61.99754772663657
At time: 207.93693709373474 and batch: 250, loss is 4.128465628623962 and perplexity is 62.08259206477038
At time: 208.75669479370117 and batch: 300, loss is 4.1520548343658445 and perplexity is 63.56448067376778
At time: 209.57582426071167 and batch: 350, loss is 4.161029896736145 and perplexity is 64.13754364353517
At time: 210.39479184150696 and batch: 400, loss is 4.117600378990173 and perplexity is 61.41170050629076
At time: 211.2142744064331 and batch: 450, loss is 4.150112810134888 and perplexity is 63.44115669990318
At time: 212.03359603881836 and batch: 500, loss is 4.174070339202881 and perplexity is 64.97940276909061
At time: 212.86333441734314 and batch: 550, loss is 4.121977767944336 and perplexity is 61.68111263638889
At time: 213.71345210075378 and batch: 600, loss is 4.129089059829712 and perplexity is 62.12130835721589
At time: 214.5325825214386 and batch: 650, loss is 4.192334270477295 and perplexity is 66.17708602532433
At time: 215.35232877731323 and batch: 700, loss is 4.206585803031921 and perplexity is 67.12696344858466
At time: 216.1714415550232 and batch: 750, loss is 4.1858826971054075 and perplexity is 65.75151398005575
At time: 216.99143028259277 and batch: 800, loss is 4.139223113059997 and perplexity is 62.75404970494107
At time: 217.810560464859 and batch: 850, loss is 4.148287215232849 and perplexity is 63.32544450158916
At time: 218.63038754463196 and batch: 900, loss is 4.152157263755798 and perplexity is 63.57099187820959
At time: 219.45012497901917 and batch: 950, loss is 4.230188097953796 and perplexity is 68.73015896032183
At time: 220.26934361457825 and batch: 1000, loss is 4.20544557094574 and perplexity is 67.05046675129498
At time: 221.08971428871155 and batch: 1050, loss is 4.1477323198318485 and perplexity is 63.29031525110006
At time: 221.91655945777893 and batch: 1100, loss is 4.198908123970032 and perplexity is 66.61355757156845
At time: 222.73793244361877 and batch: 1150, loss is 4.145060648918152 and perplexity is 63.12145003331455
At time: 223.55755376815796 and batch: 1200, loss is 4.222605257034302 and perplexity is 68.21096008758582
At time: 224.3812050819397 and batch: 1250, loss is 4.212721824645996 and perplexity is 67.54012222647691
At time: 225.21014499664307 and batch: 1300, loss is 4.199820652008056 and perplexity is 66.67437205380507
At time: 226.0325961112976 and batch: 1350, loss is 4.114227976799011 and perplexity is 61.20494438129959
At time: 226.8523280620575 and batch: 1400, loss is 4.12363422870636 and perplexity is 61.783369648211306
At time: 227.6722927093506 and batch: 1450, loss is 4.055492639541626 and perplexity is 57.71358798948308
At time: 228.49251413345337 and batch: 1500, loss is 4.069517645835877 and perplexity is 58.52872420814625
At time: 229.31246757507324 and batch: 1550, loss is 4.071981620788574 and perplexity is 58.67311533361481
At time: 230.1319761276245 and batch: 1600, loss is 4.16012553691864 and perplexity is 64.07956644634568
At time: 230.95205426216125 and batch: 1650, loss is 4.133848390579224 and perplexity is 62.41766888976736
At time: 231.7755308151245 and batch: 1700, loss is 4.15582498550415 and perplexity is 63.8045806952212
At time: 232.6101348400116 and batch: 1750, loss is 4.154402866363525 and perplexity is 63.7139074691018
At time: 233.43168354034424 and batch: 1800, loss is 4.120759987831116 and perplexity is 61.60604432168653
At time: 234.25244212150574 and batch: 1850, loss is 4.155851850509643 and perplexity is 63.80629482865706
At time: 235.07338523864746 and batch: 1900, loss is 4.222630553245544 and perplexity is 68.21268558826546
At time: 235.89441204071045 and batch: 1950, loss is 4.161457877159119 and perplexity is 64.16499913137882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.476060876180959 and perplexity of 87.8877890322013
finished 7 epochs...
Completing Train Step...
At time: 238.6693639755249 and batch: 50, loss is 4.133915686607361 and perplexity is 62.4218694923096
At time: 239.51557207107544 and batch: 100, loss is 4.113966269493103 and perplexity is 61.188928695999635
At time: 240.34337306022644 and batch: 150, loss is 4.077851877212525 and perplexity is 59.01855448202221
At time: 241.16470408439636 and batch: 200, loss is 4.068600597381592 and perplexity is 58.47507513523943
At time: 241.98142170906067 and batch: 250, loss is 4.070439825057983 and perplexity is 58.5827230759976
At time: 242.79910469055176 and batch: 300, loss is 4.095876908302307 and perplexity is 60.09201124334222
At time: 243.61793851852417 and batch: 350, loss is 4.101055731773377 and perplexity is 60.40402439475434
At time: 244.43611645698547 and batch: 400, loss is 4.057081236839294 and perplexity is 57.80534450217925
At time: 245.25381422042847 and batch: 450, loss is 4.092763857841492 and perplexity is 59.90523265647334
At time: 246.0706810951233 and batch: 500, loss is 4.116757416725159 and perplexity is 61.35995457313229
At time: 246.88829493522644 and batch: 550, loss is 4.068202176094055 and perplexity is 58.45178206105166
At time: 247.7065830230713 and batch: 600, loss is 4.0752905654907225 and perplexity is 58.86758299168259
At time: 248.53473901748657 and batch: 650, loss is 4.13384090423584 and perplexity is 62.417201611413965
At time: 249.35541224479675 and batch: 700, loss is 4.15012643814087 and perplexity is 63.442021282257414
At time: 250.1774868965149 and batch: 750, loss is 4.132807922363281 and perplexity is 62.35275906333582
At time: 250.99974727630615 and batch: 800, loss is 4.083466401100159 and perplexity is 59.350847526691346
At time: 251.81841492652893 and batch: 850, loss is 4.095756707191467 and perplexity is 60.08478855093469
At time: 252.6362428665161 and batch: 900, loss is 4.0942380285263065 and perplexity is 59.993608318723105
At time: 253.45456671714783 and batch: 950, loss is 4.173729381561279 and perplexity is 64.95725132173698
At time: 254.2724711894989 and batch: 1000, loss is 4.150200700759887 and perplexity is 63.4467328278573
At time: 255.11676359176636 and batch: 1050, loss is 4.095010280609131 and perplexity is 60.03995640160176
At time: 255.93469762802124 and batch: 1100, loss is 4.145299301147461 and perplexity is 63.13651590576275
At time: 256.75334334373474 and batch: 1150, loss is 4.088577241897583 and perplexity is 59.654956724478254
At time: 257.571834564209 and batch: 1200, loss is 4.166096787452698 and perplexity is 64.46334627412968
At time: 258.3907024860382 and batch: 1250, loss is 4.157802724838257 and perplexity is 63.93089439076789
At time: 259.2092411518097 and batch: 1300, loss is 4.14670961856842 and perplexity is 63.22562125268565
At time: 260.0278196334839 and batch: 1350, loss is 4.062184805870056 and perplexity is 58.10111216155275
At time: 260.84619545936584 and batch: 1400, loss is 4.072842268943787 and perplexity is 58.72363397835812
At time: 261.6643602848053 and batch: 1450, loss is 3.9999084186553957 and perplexity is 54.593150090105546
At time: 262.4825873374939 and batch: 1500, loss is 4.017366304397583 and perplexity is 55.554599081100925
At time: 263.3006429672241 and batch: 1550, loss is 4.015671200752259 and perplexity is 55.46050804724119
At time: 264.11911153793335 and batch: 1600, loss is 4.109687404632568 and perplexity is 60.92766888547011
At time: 264.9503848552704 and batch: 1650, loss is 4.07945674419403 and perplexity is 59.113347456117985
At time: 265.7701859474182 and batch: 1700, loss is 4.1062544822692875 and perplexity is 60.718867532886506
At time: 266.58856987953186 and batch: 1750, loss is 4.10286431312561 and perplexity is 60.51336883622829
At time: 267.40643668174744 and batch: 1800, loss is 4.072925105094909 and perplexity is 58.72849861965812
At time: 268.2245190143585 and batch: 1850, loss is 4.106341228485108 and perplexity is 60.72413489333237
At time: 269.0432834625244 and batch: 1900, loss is 4.1697537183761595 and perplexity is 64.69951584325551
At time: 269.8620591163635 and batch: 1950, loss is 4.110117893218995 and perplexity is 60.95390319790375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.483087016260901 and perplexity of 88.5074754015587
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 272.62466382980347 and batch: 50, loss is 4.108834738731384 and perplexity is 60.87574008187908
At time: 273.4429314136505 and batch: 100, loss is 4.101591806411744 and perplexity is 60.43641414117279
At time: 274.2608163356781 and batch: 150, loss is 4.065455632209778 and perplexity is 58.29146194041147
At time: 275.07901215553284 and batch: 200, loss is 4.054200959205628 and perplexity is 57.63908860780847
At time: 275.92367362976074 and batch: 250, loss is 4.059757261276245 and perplexity is 57.96024017652297
At time: 276.7410113811493 and batch: 300, loss is 4.071846656799316 and perplexity is 58.6651971102567
At time: 277.5589647293091 and batch: 350, loss is 4.074568405151367 and perplexity is 58.825086504457964
At time: 278.37645506858826 and batch: 400, loss is 4.02048164844513 and perplexity is 55.7279406397633
At time: 279.1949710845947 and batch: 450, loss is 4.049164524078369 and perplexity is 57.349522878831166
At time: 280.013117313385 and batch: 500, loss is 4.069629034996033 and perplexity is 58.53524403669318
At time: 280.8305141925812 and batch: 550, loss is 4.015602645874023 and perplexity is 55.456706089188
At time: 281.6475033760071 and batch: 600, loss is 4.015048332214356 and perplexity is 55.425974197823095
At time: 282.46559286117554 and batch: 650, loss is 4.060540599822998 and perplexity is 58.00566045423689
At time: 283.28347635269165 and batch: 700, loss is 4.072003269195557 and perplexity is 58.67438552684327
At time: 284.10194659233093 and batch: 750, loss is 4.0464396476745605 and perplexity is 57.19346523262786
At time: 284.9204840660095 and batch: 800, loss is 3.9980953693389893 and perplexity is 54.49425969032901
At time: 285.74607038497925 and batch: 850, loss is 4.010624465942382 and perplexity is 55.18131866067197
At time: 286.5655663013458 and batch: 900, loss is 3.9999676513671876 and perplexity is 54.59638388620295
At time: 287.38497710227966 and batch: 950, loss is 4.075539565086364 and perplexity is 58.882242821113984
At time: 288.20112562179565 and batch: 1000, loss is 4.03921914100647 and perplexity is 56.78198676478039
At time: 289.0177478790283 and batch: 1050, loss is 3.9844540882110597 and perplexity is 53.7559354673714
At time: 289.8358676433563 and batch: 1100, loss is 4.016308784484863 and perplexity is 55.49588004007945
At time: 290.65412425994873 and batch: 1150, loss is 3.9638949537277224 and perplexity is 52.662043229710434
At time: 291.4728305339813 and batch: 1200, loss is 4.029197788238525 and perplexity is 56.21579618075199
At time: 292.2903790473938 and batch: 1250, loss is 4.018940515518189 and perplexity is 55.64212262096545
At time: 293.1134057044983 and batch: 1300, loss is 4.005033559799195 and perplexity is 54.87366591737868
At time: 293.93739080429077 and batch: 1350, loss is 3.9147872972488402 and perplexity is 50.138405799911574
At time: 294.75481247901917 and batch: 1400, loss is 3.922661247253418 and perplexity is 50.53475145567464
At time: 295.5719413757324 and batch: 1450, loss is 3.8355560207366945 and perplexity is 46.31917493104925
At time: 296.39069294929504 and batch: 1500, loss is 3.8510253381729127 and perplexity is 47.041271723952924
At time: 297.20881152153015 and batch: 1550, loss is 3.849979419708252 and perplexity is 46.992096110579695
At time: 298.0271108150482 and batch: 1600, loss is 3.931355175971985 and perplexity is 50.97601234864932
At time: 298.8439927101135 and batch: 1650, loss is 3.8965642976760866 and perplexity is 49.23300823719785
At time: 299.66188883781433 and batch: 1700, loss is 3.908195848464966 and perplexity is 49.809007863407565
At time: 300.4796209335327 and batch: 1750, loss is 3.9017066621780394 and perplexity is 49.486834385021155
At time: 301.2972369194031 and batch: 1800, loss is 3.8641232538223265 and perplexity is 47.6614670999316
At time: 302.1221385002136 and batch: 1850, loss is 3.8844209241867067 and perplexity is 48.638768768344036
At time: 302.9484248161316 and batch: 1900, loss is 3.9491078281402587 and perplexity is 51.88905222538377
At time: 303.76657700538635 and batch: 1950, loss is 3.8876478385925295 and perplexity is 48.795975421755635
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375459892805233 and perplexity of 79.47638176502656
finished 9 epochs...
Completing Train Step...
At time: 306.5179970264435 and batch: 50, loss is 4.017495350837708 and perplexity is 55.56176866693972
At time: 307.36179542541504 and batch: 100, loss is 4.0096682357788085 and perplexity is 55.12857783950362
At time: 308.17957758903503 and batch: 150, loss is 3.9724813175201414 and perplexity is 53.11616553053861
At time: 308.997802734375 and batch: 200, loss is 3.9605832052230836 and perplexity is 52.48792825842749
At time: 309.81564831733704 and batch: 250, loss is 3.9663936138153075 and perplexity is 52.79379230479117
At time: 310.63396668434143 and batch: 300, loss is 3.9835969972610474 and perplexity is 53.70988148061979
At time: 311.4521062374115 and batch: 350, loss is 3.987533378601074 and perplexity is 53.921720722335145
At time: 312.2718393802643 and batch: 400, loss is 3.937342782020569 and perplexity is 51.28215223641388
At time: 313.0934603214264 and batch: 450, loss is 3.9747310209274294 and perplexity is 53.23579566481943
At time: 313.91155219078064 and batch: 500, loss is 3.9971569967269898 and perplexity is 54.443147754295396
At time: 314.7285659313202 and batch: 550, loss is 3.9434700870513915 and perplexity is 51.59733826015002
At time: 315.5465934276581 and batch: 600, loss is 3.950757794380188 and perplexity is 51.97473807972185
At time: 316.3645489215851 and batch: 650, loss is 3.9970791435241697 and perplexity is 54.4389093458601
At time: 317.20918917655945 and batch: 700, loss is 4.009907913208008 and perplexity is 55.14179249888015
At time: 318.0270164012909 and batch: 750, loss is 3.9893752670288087 and perplexity is 54.02113003806701
At time: 318.846923828125 and batch: 800, loss is 3.9403065061569214 and perplexity is 51.43436383393918
At time: 319.66549825668335 and batch: 850, loss is 3.9578069257736206 and perplexity is 52.342409196118254
At time: 320.48374366760254 and batch: 900, loss is 3.9450882339477538 and perplexity is 51.68089792058612
At time: 321.30136585235596 and batch: 950, loss is 4.023777189254761 and perplexity is 55.91189729421956
At time: 322.1195456981659 and batch: 1000, loss is 3.991962718963623 and perplexity is 54.16108810480629
At time: 322.9374167919159 and batch: 1050, loss is 3.94041259765625 and perplexity is 51.439820872182906
At time: 323.75561451911926 and batch: 1100, loss is 3.9729125404357912 and perplexity is 53.13907537757733
At time: 324.57347655296326 and batch: 1150, loss is 3.9236127710342408 and perplexity is 50.58285935771938
At time: 325.3909752368927 and batch: 1200, loss is 3.9900916910171507 and perplexity is 54.05984593834751
At time: 326.208713054657 and batch: 1250, loss is 3.984012475013733 and perplexity is 53.73220137786367
At time: 327.02634739875793 and batch: 1300, loss is 3.97329656124115 and perplexity is 53.159485806863756
At time: 327.8438718318939 and batch: 1350, loss is 3.88382493019104 and perplexity is 48.60978899094596
At time: 328.66121768951416 and batch: 1400, loss is 3.895506281852722 and perplexity is 49.18094648138827
At time: 329.47874903678894 and batch: 1450, loss is 3.810324239730835 and perplexity is 45.16508080608483
At time: 330.29725670814514 and batch: 1500, loss is 3.829151120185852 and perplexity is 46.023453266885966
At time: 331.1151964664459 and batch: 1550, loss is 3.8300314140319824 and perplexity is 46.063985266992205
At time: 331.93250346183777 and batch: 1600, loss is 3.9151451206207275 and perplexity is 50.15634970351854
At time: 332.75042748451233 and batch: 1650, loss is 3.882486343383789 and perplexity is 48.54476409913997
At time: 333.5690920352936 and batch: 1700, loss is 3.8970440435409546 and perplexity is 49.25663323585925
At time: 334.38549876213074 and batch: 1750, loss is 3.8946633625030516 and perplexity is 49.13950837690756
At time: 335.2018301486969 and batch: 1800, loss is 3.859265003204346 and perplexity is 47.43047730542523
At time: 336.0200433731079 and batch: 1850, loss is 3.8828496026992796 and perplexity is 48.562401640223875
At time: 336.84327483177185 and batch: 1900, loss is 3.9515085077285765 and perplexity is 52.01377085875827
At time: 337.6608440876007 and batch: 1950, loss is 3.889659972190857 and perplexity is 48.894258289335255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371907362827035 and perplexity of 79.19454045750874
finished 10 epochs...
Completing Train Step...
At time: 340.40760707855225 and batch: 50, loss is 3.982515587806702 and perplexity is 53.651830501091204
At time: 341.25381565093994 and batch: 100, loss is 3.9732004404067993 and perplexity is 53.15437631830244
At time: 342.07566571235657 and batch: 150, loss is 3.935251612663269 and perplexity is 51.17502462111292
At time: 342.9025762081146 and batch: 200, loss is 3.9223891210556032 and perplexity is 50.52100149685035
At time: 343.7220447063446 and batch: 250, loss is 3.927254905700684 and perplexity is 50.76742484547057
At time: 344.5396046638489 and batch: 300, loss is 3.947289476394653 and perplexity is 51.79478540778177
At time: 345.3575704097748 and batch: 350, loss is 3.950929503440857 and perplexity is 51.98366337943151
At time: 346.1760878562927 and batch: 400, loss is 3.902057161331177 and perplexity is 49.504182518640036
At time: 346.99401807785034 and batch: 450, loss is 3.94147310256958 and perplexity is 51.49440199161587
At time: 347.8107669353485 and batch: 500, loss is 3.9641590023040774 and perplexity is 52.67595040325707
At time: 348.6309070587158 and batch: 550, loss is 3.9118046665191653 and perplexity is 49.98908424626121
At time: 349.4479160308838 and batch: 600, loss is 3.9208842754364013 and perplexity is 50.44503236431466
At time: 350.2654712200165 and batch: 650, loss is 3.966910705566406 and perplexity is 52.82109859862239
At time: 351.0832989215851 and batch: 700, loss is 3.980115828514099 and perplexity is 53.5232333850574
At time: 351.900506734848 and batch: 750, loss is 3.961303834915161 and perplexity is 52.52576624995877
At time: 352.7185299396515 and batch: 800, loss is 3.9117975568771364 and perplexity is 49.98872884303026
At time: 353.5362882614136 and batch: 850, loss is 3.9311925983428955 and perplexity is 50.9677254630706
At time: 354.35375237464905 and batch: 900, loss is 3.917897968292236 and perplexity is 50.29461271520108
At time: 355.1754970550537 and batch: 950, loss is 3.9979032135009764 and perplexity is 54.48378930619626
At time: 355.99287390708923 and batch: 1000, loss is 3.967347116470337 and perplexity is 52.8441553327476
At time: 356.81068301200867 and batch: 1050, loss is 3.9169400787353514 and perplexity is 50.24645909751934
At time: 357.6277709007263 and batch: 1100, loss is 3.949830927848816 and perplexity is 51.926586752892725
At time: 358.4753532409668 and batch: 1150, loss is 3.901534776687622 and perplexity is 49.478329047216704
At time: 359.29393696784973 and batch: 1200, loss is 3.9681927251815794 and perplexity is 52.888859709376526
At time: 360.11322498321533 and batch: 1250, loss is 3.9641342782974243 and perplexity is 52.67464805880849
At time: 360.9299874305725 and batch: 1300, loss is 3.9545780658721923 and perplexity is 52.17367544533668
At time: 361.7474672794342 and batch: 1350, loss is 3.864628915786743 and perplexity is 47.685573785415635
At time: 362.56474900245667 and batch: 1400, loss is 3.87833589553833 and perplexity is 48.34369913104052
At time: 363.3821849822998 and batch: 1450, loss is 3.794143490791321 and perplexity is 44.44015669660025
At time: 364.19914960861206 and batch: 1500, loss is 3.814117202758789 and perplexity is 45.33671558415105
At time: 365.0168106555939 and batch: 1550, loss is 3.8157057857513426 and perplexity is 45.40879395554569
At time: 365.8343770503998 and batch: 1600, loss is 3.902426061630249 and perplexity is 49.52244799523923
At time: 366.6518702507019 and batch: 1650, loss is 3.8707048749923705 and perplexity is 47.97619138269847
At time: 367.4782905578613 and batch: 1700, loss is 3.8861318969726564 and perplexity is 48.72205961191311
At time: 368.2975287437439 and batch: 1750, loss is 3.8845533657073976 and perplexity is 48.64521098744348
At time: 369.12644052505493 and batch: 1800, loss is 3.8510634326934814 and perplexity is 47.0430637727796
At time: 369.9452533721924 and batch: 1850, loss is 3.875005865097046 and perplexity is 48.18298088812895
At time: 370.7726185321808 and batch: 1900, loss is 3.9449774169921876 and perplexity is 51.6751711181369
At time: 371.594712972641 and batch: 1950, loss is 3.8825357961654663 and perplexity is 48.54716483212151
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371662086664244 and perplexity of 79.17511830650403
finished 11 epochs...
Completing Train Step...
At time: 374.34932565689087 and batch: 50, loss is 3.9567054224014284 and perplexity is 52.28478559800016
At time: 375.1661636829376 and batch: 100, loss is 3.9460463666915895 and perplexity is 51.7304388106992
At time: 375.9836091995239 and batch: 150, loss is 3.9088164377212524 and perplexity is 49.839928392035446
At time: 376.8003351688385 and batch: 200, loss is 3.8948691940307616 and perplexity is 49.149623877996504
At time: 377.6176085472107 and batch: 250, loss is 3.899695339202881 and perplexity is 49.38740040849646
At time: 378.43540692329407 and batch: 300, loss is 3.9210476779937746 and perplexity is 50.45327588509762
At time: 379.27852272987366 and batch: 350, loss is 3.9254003524780274 and perplexity is 50.67336120409202
At time: 380.0955557823181 and batch: 400, loss is 3.8766680717468263 and perplexity is 48.26313755938783
At time: 380.9133596420288 and batch: 450, loss is 3.9180054378509523 and perplexity is 50.300018145489794
At time: 381.730673789978 and batch: 500, loss is 3.940324821472168 and perplexity is 51.435305879154214
At time: 382.5497097969055 and batch: 550, loss is 3.888642973899841 and perplexity is 48.84455818895675
At time: 383.3671452999115 and batch: 600, loss is 3.8994400787353514 and perplexity is 49.37479536643103
At time: 384.184072971344 and batch: 650, loss is 3.943865327835083 and perplexity is 51.6177356632376
At time: 385.00214433670044 and batch: 700, loss is 3.9580968189239503 and perplexity is 52.35758510160521
At time: 385.8198664188385 and batch: 750, loss is 3.9402511310577393 and perplexity is 51.431515729798264
At time: 386.6369960308075 and batch: 800, loss is 3.8906630754470823 and perplexity is 48.9433288863592
At time: 387.4547882080078 and batch: 850, loss is 3.911469144821167 and perplexity is 49.97231463727468
At time: 388.2718629837036 and batch: 900, loss is 3.897761845588684 and perplexity is 49.29200244058536
At time: 389.08917117118835 and batch: 950, loss is 3.9783467769622805 and perplexity is 53.42863172825476
At time: 389.9072608947754 and batch: 1000, loss is 3.9484464645385744 and perplexity is 51.85474604059743
At time: 390.7241928577423 and batch: 1050, loss is 3.8985707807540892 and perplexity is 49.33189260683664
At time: 391.54138827323914 and batch: 1100, loss is 3.9321330118179323 and perplexity is 51.01567874330944
At time: 392.3585150241852 and batch: 1150, loss is 3.8841784954071046 and perplexity is 48.626978760166566
At time: 393.17619013786316 and batch: 1200, loss is 3.950783472061157 and perplexity is 51.97607268759946
At time: 393.9934513568878 and batch: 1250, loss is 3.9479918384552004 and perplexity is 51.83117687848452
At time: 394.8113350868225 and batch: 1300, loss is 3.9388499641418457 and perplexity is 51.35950205489464
At time: 395.62919449806213 and batch: 1350, loss is 3.8492711782455444 and perplexity is 46.95882614267071
At time: 396.4465482234955 and batch: 1400, loss is 3.8640203714370727 and perplexity is 47.65656382674621
At time: 397.26658821105957 and batch: 1450, loss is 3.7803579568862915 and perplexity is 43.83172879692157
At time: 398.0845196247101 and batch: 1500, loss is 3.8008904600143434 and perplexity is 44.74100683815745
At time: 398.90947794914246 and batch: 1550, loss is 3.8025242853164674 and perplexity is 44.814165575195894
At time: 399.7315855026245 and batch: 1600, loss is 3.890266194343567 and perplexity is 48.923908058115856
At time: 400.5493338108063 and batch: 1650, loss is 3.858659658432007 and perplexity is 47.401774202452025
At time: 401.36698055267334 and batch: 1700, loss is 3.875048141479492 and perplexity is 48.18501793331553
At time: 402.1848666667938 and batch: 1750, loss is 3.8733518934249878 and perplexity is 48.103353471562876
At time: 403.0040376186371 and batch: 1800, loss is 3.840655632019043 and perplexity is 46.55598803228419
At time: 403.82691979408264 and batch: 1850, loss is 3.865302491188049 and perplexity is 47.717704434907404
At time: 404.65029191970825 and batch: 1900, loss is 3.9360393381118772 and perplexity is 51.21535237185257
At time: 405.4677891731262 and batch: 1950, loss is 3.873145227432251 and perplexity is 48.09341317146008
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373256949491279 and perplexity of 79.30149250748788
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 408.23389649391174 and batch: 50, loss is 3.9574810552597044 and perplexity is 52.32535512719392
At time: 409.07806491851807 and batch: 100, loss is 3.9690454530715944 and perplexity is 52.933978749519746
At time: 409.89684414863586 and batch: 150, loss is 3.9359599113464356 and perplexity is 51.21128466361731
At time: 410.71710753440857 and batch: 200, loss is 3.9205265474319457 and perplexity is 50.42698999087581
At time: 411.53732562065125 and batch: 250, loss is 3.924717969894409 and perplexity is 50.638794380193566
At time: 412.3580379486084 and batch: 300, loss is 3.942251205444336 and perplexity is 51.53448552637382
At time: 413.17859649658203 and batch: 350, loss is 3.946337571144104 and perplexity is 51.7455051383958
At time: 413.99885272979736 and batch: 400, loss is 3.8971358585357665 and perplexity is 49.26115594100715
At time: 414.8276369571686 and batch: 450, loss is 3.9368062019348145 and perplexity is 51.254642635981114
At time: 415.6476755142212 and batch: 500, loss is 3.955894417762756 and perplexity is 52.242399584298276
At time: 416.4680223464966 and batch: 550, loss is 3.906322703361511 and perplexity is 49.715795691436284
At time: 417.2889084815979 and batch: 600, loss is 3.9126940107345582 and perplexity is 50.03356152404172
At time: 418.10959696769714 and batch: 650, loss is 3.949216561317444 and perplexity is 51.89469459364412
At time: 418.92938804626465 and batch: 700, loss is 3.960054650306702 and perplexity is 52.460192836388345
At time: 419.753511428833 and batch: 750, loss is 3.938927984237671 and perplexity is 51.36350928448669
At time: 420.59981966018677 and batch: 800, loss is 3.8878589487075805 and perplexity is 48.80627783317432
At time: 421.41950249671936 and batch: 850, loss is 3.9063932275772095 and perplexity is 49.71930198257301
At time: 422.23979115486145 and batch: 900, loss is 3.8916655826568602 and perplexity is 48.99241952918856
At time: 423.0595302581787 and batch: 950, loss is 3.9716468906402587 and perplexity is 53.071862460670374
At time: 423.87973618507385 and batch: 1000, loss is 3.9354247999191285 and perplexity is 51.18388825070728
At time: 424.70003271102905 and batch: 1050, loss is 3.8827149295806884 and perplexity is 48.55586203051341
At time: 425.5205111503601 and batch: 1100, loss is 3.909099636077881 and perplexity is 49.85404497665299
At time: 426.340514421463 and batch: 1150, loss is 3.8668885612487793 and perplexity is 47.793448108786585
At time: 427.16052436828613 and batch: 1200, loss is 3.928511743545532 and perplexity is 50.8312713802679
At time: 427.98136615753174 and batch: 1250, loss is 3.920216293334961 and perplexity is 50.4113472373722
At time: 428.801616191864 and batch: 1300, loss is 3.916249966621399 and perplexity is 50.21179536971789
At time: 429.6219415664673 and batch: 1350, loss is 3.821564140319824 and perplexity is 45.67559551707874
At time: 430.450599193573 and batch: 1400, loss is 3.8336439323425293 and perplexity is 46.23069319364591
At time: 431.2720546722412 and batch: 1450, loss is 3.744212727546692 and perplexity is 42.275711611004745
At time: 432.1015787124634 and batch: 1500, loss is 3.76176064491272 and perplexity is 43.02410951283572
At time: 432.9287145137787 and batch: 1550, loss is 3.764033246040344 and perplexity is 43.121997340493145
At time: 433.753436088562 and batch: 1600, loss is 3.852646827697754 and perplexity is 47.11761052784794
At time: 434.5736606121063 and batch: 1650, loss is 3.815934500694275 and perplexity is 45.419180813033336
At time: 435.39373111724854 and batch: 1700, loss is 3.8249534463882444 and perplexity is 45.830666733604076
At time: 436.2139937877655 and batch: 1750, loss is 3.8179656410217286 and perplexity is 45.51152729540664
At time: 437.03439712524414 and batch: 1800, loss is 3.782696371078491 and perplexity is 43.93434546698722
At time: 437.85456371307373 and batch: 1850, loss is 3.8083244800567626 and perplexity is 45.074851747098535
At time: 438.6755449771881 and batch: 1900, loss is 3.8780127000808715 and perplexity is 48.328077191690525
At time: 439.4965977668762 and batch: 1950, loss is 3.8189782094955445 and perplexity is 45.55763417238678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.346518725018169 and perplexity of 77.20920803773139
finished 13 epochs...
Completing Train Step...
At time: 442.26642966270447 and batch: 50, loss is 3.94298490524292 and perplexity is 51.57231024232107
At time: 443.12280201911926 and batch: 100, loss is 3.9420279979705812 and perplexity is 51.52298392771737
At time: 443.9432442188263 and batch: 150, loss is 3.9027552509307863 and perplexity is 49.53875293881492
At time: 444.7627155780792 and batch: 200, loss is 3.8880257558822633 and perplexity is 48.814419749532604
At time: 445.582213640213 and batch: 250, loss is 3.892065477371216 and perplexity is 49.012015256654564
At time: 446.4022045135498 and batch: 300, loss is 3.911053490638733 and perplexity is 49.95154775191016
At time: 447.2224223613739 and batch: 350, loss is 3.918295741081238 and perplexity is 50.31462252298726
At time: 448.0421094894409 and batch: 400, loss is 3.8683730125427247 and perplexity is 47.86444783945693
At time: 448.86172008514404 and batch: 450, loss is 3.910590229034424 and perplexity is 49.92841247701693
At time: 449.68165016174316 and batch: 500, loss is 3.9301326847076417 and perplexity is 50.91373269478478
At time: 450.5017409324646 and batch: 550, loss is 3.8806330442428587 and perplexity is 48.45487944684018
At time: 451.32054233551025 and batch: 600, loss is 3.889364094734192 and perplexity is 48.87979372052252
At time: 452.14081835746765 and batch: 650, loss is 3.9275705766677858 and perplexity is 50.78345317727522
At time: 452.9613378047943 and batch: 700, loss is 3.940036153793335 and perplexity is 51.420460311616864
At time: 453.78222823143005 and batch: 750, loss is 3.9205058813095093 and perplexity is 50.42594787129488
At time: 454.60021710395813 and batch: 800, loss is 3.8696834802627564 and perplexity is 47.9272137706686
At time: 455.4183850288391 and batch: 850, loss is 3.8889983892440796 and perplexity is 48.861921379809104
At time: 456.23798847198486 and batch: 900, loss is 3.874752640724182 and perplexity is 48.17078132768906
At time: 457.0581247806549 and batch: 950, loss is 3.9553267478942873 and perplexity is 52.212751564137776
At time: 457.87836146354675 and batch: 1000, loss is 3.9201667737960815 and perplexity is 50.40885095251065
At time: 458.7081274986267 and batch: 1050, loss is 3.8691511440277098 and perplexity is 47.901707167780465
At time: 459.52854442596436 and batch: 1100, loss is 3.897012457847595 and perplexity is 49.255077455516265
At time: 460.3484959602356 and batch: 1150, loss is 3.855542054176331 and perplexity is 47.25422435000449
At time: 461.16899609565735 and batch: 1200, loss is 3.9190404748916627 and perplexity is 50.3521074799638
At time: 462.0165345668793 and batch: 1250, loss is 3.912808728218079 and perplexity is 50.03930157754728
At time: 462.84094977378845 and batch: 1300, loss is 3.909165439605713 and perplexity is 49.85732565662813
At time: 463.6612219810486 and batch: 1350, loss is 3.815247640609741 and perplexity is 45.38799490206543
At time: 464.48070788383484 and batch: 1400, loss is 3.8281812953948973 and perplexity is 45.97884021785964
At time: 465.30921745300293 and batch: 1450, loss is 3.7402521085739138 and perplexity is 42.10860476722193
At time: 466.1288547515869 and batch: 1500, loss is 3.7600846004486086 and perplexity is 42.952059588568204
At time: 466.94804191589355 and batch: 1550, loss is 3.762980341911316 and perplexity is 43.07661790573084
At time: 467.7682490348816 and batch: 1600, loss is 3.8528209924697876 and perplexity is 47.12581747040369
At time: 468.5880124568939 and batch: 1650, loss is 3.8157607746124267 and perplexity is 45.411291002062754
At time: 469.40776228904724 and batch: 1700, loss is 3.826859378814697 and perplexity is 45.91810018211253
At time: 470.22813391685486 and batch: 1750, loss is 3.820448389053345 and perplexity is 45.62466133375714
At time: 471.048526763916 and batch: 1800, loss is 3.786459288597107 and perplexity is 44.0999782209693
At time: 471.86855149269104 and batch: 1850, loss is 3.8134528827667236 and perplexity is 45.306607499422505
At time: 472.68829917907715 and batch: 1900, loss is 3.883257646560669 and perplexity is 48.582221273472335
At time: 473.5084583759308 and batch: 1950, loss is 3.8244299936294555 and perplexity is 45.80668282243511
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3449281204578485 and perplexity of 77.08649633809432
finished 14 epochs...
Completing Train Step...
At time: 476.2743275165558 and batch: 50, loss is 3.932811141014099 and perplexity is 51.05028569719426
At time: 477.09233713150024 and batch: 100, loss is 3.930212349891663 and perplexity is 50.91778890823646
At time: 477.9115128517151 and batch: 150, loss is 3.8899643087387084 and perplexity is 48.90914086365355
At time: 478.7303819656372 and batch: 200, loss is 3.8745730543136596 and perplexity is 48.16213128671651
At time: 479.5488820075989 and batch: 250, loss is 3.8781152820587157 and perplexity is 48.33303503572263
At time: 480.36704301834106 and batch: 300, loss is 3.897516841888428 and perplexity is 49.27992719689448
At time: 481.18538904190063 and batch: 350, loss is 3.9054202222824097 and perplexity is 49.670948366467314
At time: 482.00374817848206 and batch: 400, loss is 3.8549323749542235 and perplexity is 47.22542321188138
At time: 482.8485412597656 and batch: 450, loss is 3.8981500482559204 and perplexity is 49.31114144207157
At time: 483.6673710346222 and batch: 500, loss is 3.917968363761902 and perplexity is 50.298153352705796
At time: 484.4862537384033 and batch: 550, loss is 3.868743686676025 and perplexity is 47.882193240853184
At time: 485.30466890335083 and batch: 600, loss is 3.878259973526001 and perplexity is 48.34002891944575
At time: 486.1233584880829 and batch: 650, loss is 3.917160224914551 and perplexity is 50.257521881178064
At time: 486.9411976337433 and batch: 700, loss is 3.930081257820129 and perplexity is 50.91111442730589
At time: 487.758691072464 and batch: 750, loss is 3.9107295751571653 and perplexity is 49.935370292471276
At time: 488.57674860954285 and batch: 800, loss is 3.8603640604019165 and perplexity is 47.48263476966001
At time: 489.4061517715454 and batch: 850, loss is 3.8801736354827883 and perplexity is 48.432623963327615
At time: 490.224693775177 and batch: 900, loss is 3.865934343338013 and perplexity is 47.74786449639237
At time: 491.04322934150696 and batch: 950, loss is 3.94695023059845 and perplexity is 51.777217224701545
At time: 491.8611526489258 and batch: 1000, loss is 3.9120325088500976 and perplexity is 50.00047517335546
At time: 492.6793637275696 and batch: 1050, loss is 3.8618694305419923 and perplexity is 47.55416753835279
At time: 493.4976444244385 and batch: 1100, loss is 3.8905398654937744 and perplexity is 48.93729895257393
At time: 494.3155722618103 and batch: 1150, loss is 3.8492363405227663 and perplexity is 46.95719023259942
At time: 495.13470220565796 and batch: 1200, loss is 3.9145631074905394 and perplexity is 50.12716654274395
At time: 495.9526951313019 and batch: 1250, loss is 3.9066574668884275 and perplexity is 49.73244151259685
At time: 496.7709617614746 and batch: 1300, loss is 3.904087243080139 and perplexity is 49.604782134240686
At time: 497.58880615234375 and batch: 1350, loss is 3.8107623863220215 and perplexity is 45.184874068139194
At time: 498.40738248825073 and batch: 1400, loss is 3.8242812299728395 and perplexity is 45.79986895964113
At time: 499.225462436676 and batch: 1450, loss is 3.7371821498870847 and perplexity is 41.97953131667953
At time: 500.0442018508911 and batch: 1500, loss is 3.7582018184661865 and perplexity is 42.87126630660151
At time: 500.8607368469238 and batch: 1550, loss is 3.7608455181121827 and perplexity is 42.98475500707922
At time: 501.67805790901184 and batch: 1600, loss is 3.851080536842346 and perplexity is 47.043868411226725
At time: 502.49566435813904 and batch: 1650, loss is 3.814118595123291 and perplexity is 45.33677870942844
At time: 503.31372261047363 and batch: 1700, loss is 3.8262765264511107 and perplexity is 45.89134450695169
At time: 504.1347472667694 and batch: 1750, loss is 3.8201250410079957 and perplexity is 45.60991107355756
At time: 504.95418643951416 and batch: 1800, loss is 3.786528158187866 and perplexity is 44.103015473007815
At time: 505.77208614349365 and batch: 1850, loss is 3.814301919937134 and perplexity is 45.34509082783107
At time: 506.60032391548157 and batch: 1900, loss is 3.884115228652954 and perplexity is 48.62390238637337
At time: 507.426429271698 and batch: 1950, loss is 3.8253742694854735 and perplexity is 45.84995739542033
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344383062318314 and perplexity of 77.04449116448785
finished 15 epochs...
Completing Train Step...
At time: 510.18927025794983 and batch: 50, loss is 3.9241371822357176 and perplexity is 50.609392532308206
At time: 511.0324056148529 and batch: 100, loss is 3.9207718992233276 and perplexity is 50.439363861117606
At time: 511.85040259361267 and batch: 150, loss is 3.880148935317993 and perplexity is 48.43142768430846
At time: 512.6682887077332 and batch: 200, loss is 3.8644914627075195 and perplexity is 47.67901970691375
At time: 513.4865367412567 and batch: 250, loss is 3.8678949308395385 and perplexity is 47.841570191839885
At time: 514.304767370224 and batch: 300, loss is 3.8876681089401246 and perplexity is 48.79696454316356
At time: 515.1223266124725 and batch: 350, loss is 3.89591269493103 and perplexity is 49.20093832343973
At time: 515.9405570030212 and batch: 400, loss is 3.845293493270874 and perplexity is 46.77240972417793
At time: 516.7583360671997 and batch: 450, loss is 3.8890242052078245 and perplexity is 48.86318281368245
At time: 517.5764317512512 and batch: 500, loss is 3.909177374839783 and perplexity is 49.857920719031036
At time: 518.3945269584656 and batch: 550, loss is 3.860154252052307 and perplexity is 47.47267356143275
At time: 519.2129890918732 and batch: 600, loss is 3.870230865478516 and perplexity is 47.953455600458796
At time: 520.0312020778656 and batch: 650, loss is 3.9094878482818602 and perplexity is 49.87340268253638
At time: 520.8495604991913 and batch: 700, loss is 3.922846236228943 and perplexity is 50.54410069230103
At time: 521.6677026748657 and batch: 750, loss is 3.903459930419922 and perplexity is 49.573674184626
At time: 522.4861483573914 and batch: 800, loss is 3.853262085914612 and perplexity is 47.146608944726275
At time: 523.3042237758636 and batch: 850, loss is 3.8734579563140867 and perplexity is 48.10845572278239
At time: 524.1578681468964 and batch: 900, loss is 3.859248328208923 and perplexity is 47.42968640902738
At time: 524.9817373752594 and batch: 950, loss is 3.940581817626953 and perplexity is 51.4485262537053
At time: 525.8037405014038 and batch: 1000, loss is 3.9057383918762207 and perplexity is 49.68675466634195
At time: 526.6212062835693 and batch: 1050, loss is 3.856098575592041 and perplexity is 47.280529656892426
At time: 527.4392468929291 and batch: 1100, loss is 3.8852253007888793 and perplexity is 48.67790839528949
At time: 528.2569825649261 and batch: 1150, loss is 3.8439995527267454 and perplexity is 46.71192814511148
At time: 529.0750176906586 and batch: 1200, loss is 3.909551100730896 and perplexity is 49.87655739716846
At time: 529.8949964046478 and batch: 1250, loss is 3.902105655670166 and perplexity is 49.50658324945892
At time: 530.7133386135101 and batch: 1300, loss is 3.9000129079818726 and perplexity is 49.403086795563325
At time: 531.5388240814209 and batch: 1350, loss is 3.806718654632568 and perplexity is 45.00252748977857
At time: 532.3609094619751 and batch: 1400, loss is 3.820688066482544 and perplexity is 45.63559784585889
At time: 533.1789221763611 and batch: 1450, loss is 3.7339741563796998 and perplexity is 41.84507703231642
At time: 533.9972257614136 and batch: 1500, loss is 3.7556450748443604 and perplexity is 42.76179547397271
At time: 534.8156175613403 and batch: 1550, loss is 3.7583470058441164 and perplexity is 42.877491125216714
At time: 535.6341409683228 and batch: 1600, loss is 3.848872518539429 and perplexity is 46.94010928191813
At time: 536.4524700641632 and batch: 1650, loss is 3.8119772052764893 and perplexity is 45.23979886469961
At time: 537.2700095176697 and batch: 1700, loss is 3.8245196676254274 and perplexity is 45.81079067490703
At time: 538.0886104106903 and batch: 1750, loss is 3.818446397781372 and perplexity is 45.53341253011134
At time: 538.9073367118835 and batch: 1800, loss is 3.7854051303863527 and perplexity is 44.05351436126593
At time: 539.7253963947296 and batch: 1850, loss is 3.8137613916397095 and perplexity is 45.32058714615262
At time: 540.5504148006439 and batch: 1900, loss is 3.8836061191558837 and perplexity is 48.599153796289535
At time: 541.3740937709808 and batch: 1950, loss is 3.8247304821014403 and perplexity is 45.82044927078905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344326853197674 and perplexity of 77.04016068309677
finished 16 epochs...
Completing Train Step...
At time: 544.1042919158936 and batch: 50, loss is 3.916599864959717 and perplexity is 50.22936746752635
At time: 544.9476397037506 and batch: 100, loss is 3.9128854417800905 and perplexity is 50.04314041785555
At time: 545.7708070278168 and batch: 150, loss is 3.8718895149230956 and perplexity is 48.033059572247986
At time: 546.5894110202789 and batch: 200, loss is 3.8561004543304445 and perplexity is 47.28061848472267
At time: 547.4056158065796 and batch: 250, loss is 3.85948570728302 and perplexity is 47.440946560481144
At time: 548.2245163917542 and batch: 300, loss is 3.8795105171203614 and perplexity is 48.40051804722476
At time: 549.0428032875061 and batch: 350, loss is 3.8880265378952026 and perplexity is 48.8144579230554
At time: 549.8613548278809 and batch: 400, loss is 3.8373031711578367 and perplexity is 46.400172233668755
At time: 550.6794717311859 and batch: 450, loss is 3.88152054309845 and perplexity is 48.497902185388746
At time: 551.4975402355194 and batch: 500, loss is 3.901817545890808 and perplexity is 49.49232197318739
At time: 552.3158464431763 and batch: 550, loss is 3.8530567836761476 and perplexity is 47.13693063389736
At time: 553.1344838142395 and batch: 600, loss is 3.863510694503784 and perplexity is 47.632280564278965
At time: 553.9528646469116 and batch: 650, loss is 3.903032865524292 and perplexity is 49.55250752872391
At time: 554.7708671092987 and batch: 700, loss is 3.916774091720581 and perplexity is 50.23811952992008
At time: 555.5885462760925 and batch: 750, loss is 3.897039828300476 and perplexity is 49.2564256077426
At time: 556.4062387943268 and batch: 800, loss is 3.8472047519683836 and perplexity is 46.861889381214695
At time: 557.2237086296082 and batch: 850, loss is 3.8677465438842775 and perplexity is 47.83447165358248
At time: 558.053364276886 and batch: 900, loss is 3.8534954309463503 and perplexity is 47.15761165535085
At time: 558.8722922801971 and batch: 950, loss is 3.9350722503662108 and perplexity is 51.16584657426725
At time: 559.6899528503418 and batch: 1000, loss is 3.9002185583114626 and perplexity is 49.41324760139632
At time: 560.5168952941895 and batch: 1050, loss is 3.850960063934326 and perplexity is 47.0382012409718
At time: 561.3368942737579 and batch: 1100, loss is 3.8804359817504883 and perplexity is 48.44533174830641
At time: 562.1554527282715 and batch: 1150, loss is 3.8392998027801513 and perplexity is 46.492908834438005
At time: 562.9726934432983 and batch: 1200, loss is 3.905092658996582 and perplexity is 49.65468065190869
At time: 563.7904224395752 and batch: 1250, loss is 3.8978972578048707 and perplexity is 49.298677631817135
At time: 564.6185762882233 and batch: 1300, loss is 3.896148443222046 and perplexity is 49.21253872789989
At time: 565.4425160884857 and batch: 1350, loss is 3.802889347076416 and perplexity is 44.83052849990872
At time: 566.2608604431152 and batch: 1400, loss is 3.8173157930374146 and perplexity is 45.48196132886303
At time: 567.0790181159973 and batch: 1450, loss is 3.7307188272476197 and perplexity is 41.709079013275094
At time: 567.8966255187988 and batch: 1500, loss is 3.7528494453430175 and perplexity is 42.64241628475799
At time: 568.7148847579956 and batch: 1550, loss is 3.7555471658706665 and perplexity is 42.75760891541872
At time: 569.5430641174316 and batch: 1600, loss is 3.846110382080078 and perplexity is 46.810633192297225
At time: 570.3667781352997 and batch: 1650, loss is 3.809357042312622 and perplexity is 45.121418375034864
At time: 571.1846888065338 and batch: 1700, loss is 3.8221779346466063 and perplexity is 45.70363954423145
At time: 572.001790523529 and batch: 1750, loss is 3.816205744743347 and perplexity is 45.431502166513965
At time: 572.8198485374451 and batch: 1800, loss is 3.7836222743988035 and perplexity is 43.97504326153489
At time: 573.6375172138214 and batch: 1850, loss is 3.8124399614334106 and perplexity is 45.26073870480842
At time: 574.4590301513672 and batch: 1900, loss is 3.88234956741333 and perplexity is 48.538124795978526
At time: 575.2764000892639 and batch: 1950, loss is 3.823342761993408 and perplexity is 45.75690741133217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344406340843023 and perplexity of 77.04628466745415
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 578.0329813957214 and batch: 50, loss is 3.920124878883362 and perplexity is 50.406739122337484
At time: 578.8577604293823 and batch: 100, loss is 3.9323761749267576 and perplexity is 51.028085382708866
At time: 579.683274269104 and batch: 150, loss is 3.894134545326233 and perplexity is 49.11352943047939
At time: 580.5028207302094 and batch: 200, loss is 3.880743770599365 and perplexity is 48.46024497614356
At time: 581.3228604793549 and batch: 250, loss is 3.8794978284835815 and perplexity is 48.399903914527556
At time: 582.1517744064331 and batch: 300, loss is 3.894492030143738 and perplexity is 49.131089910200295
At time: 582.9717712402344 and batch: 350, loss is 3.9076385641098024 and perplexity is 49.781257815630994
At time: 583.7916626930237 and batch: 400, loss is 3.860064525604248 and perplexity is 47.468414198145844
At time: 584.6120054721832 and batch: 450, loss is 3.90611921787262 and perplexity is 49.70568027764926
At time: 585.4459571838379 and batch: 500, loss is 3.923963828086853 and perplexity is 50.60061994454542
At time: 586.306604385376 and batch: 550, loss is 3.87821533203125 and perplexity is 48.33787099646529
At time: 587.1267535686493 and batch: 600, loss is 3.8820954847335813 and perplexity is 48.525793665790026
At time: 587.9467594623566 and batch: 650, loss is 3.9161870956420897 and perplexity is 50.208638604205625
At time: 588.7672581672668 and batch: 700, loss is 3.927753596305847 and perplexity is 50.792748397073154
At time: 589.5992224216461 and batch: 750, loss is 3.903577055931091 and perplexity is 49.57948086660408
At time: 590.4183881282806 and batch: 800, loss is 3.8572929763793944 and perplexity is 47.3370352972142
At time: 591.237729549408 and batch: 850, loss is 3.8762385559082033 and perplexity is 48.24241222863196
At time: 592.0579464435577 and batch: 900, loss is 3.855186491012573 and perplexity is 47.237425475201206
At time: 592.875501871109 and batch: 950, loss is 3.941959009170532 and perplexity is 51.51942954148908
At time: 593.6965403556824 and batch: 1000, loss is 3.9068597173690796 and perplexity is 49.7425009400245
At time: 594.5250287055969 and batch: 1050, loss is 3.855754404067993 and perplexity is 47.26425984490621
At time: 595.3448147773743 and batch: 1100, loss is 3.880564956665039 and perplexity is 48.451580383778975
At time: 596.1641466617584 and batch: 1150, loss is 3.839585962295532 and perplexity is 46.50621512646895
At time: 596.9848141670227 and batch: 1200, loss is 3.902795820236206 and perplexity is 49.540762732380685
At time: 597.807471036911 and batch: 1250, loss is 3.8930114793777464 and perplexity is 49.05840265926001
At time: 598.6359746456146 and batch: 1300, loss is 3.8928436851501464 and perplexity is 49.05017163305717
At time: 599.4554817676544 and batch: 1350, loss is 3.7982217979431154 and perplexity is 44.621767385847996
At time: 600.275208234787 and batch: 1400, loss is 3.814031105041504 and perplexity is 45.332812364461624
At time: 601.1029453277588 and batch: 1450, loss is 3.7272045469284056 and perplexity is 41.56275887335003
At time: 601.9256784915924 and batch: 1500, loss is 3.7497587823867797 and perplexity is 42.51082640311622
At time: 602.7455594539642 and batch: 1550, loss is 3.748935270309448 and perplexity is 42.47583263502888
At time: 603.5650973320007 and batch: 1600, loss is 3.83848379611969 and perplexity is 46.454985785999234
At time: 604.3853216171265 and batch: 1650, loss is 3.803821244239807 and perplexity is 44.872325414439345
At time: 605.2053081989288 and batch: 1700, loss is 3.808279962539673 and perplexity is 45.07284517127979
At time: 606.0248906612396 and batch: 1750, loss is 3.8005412578582765 and perplexity is 44.72538590969465
At time: 606.8447654247284 and batch: 1800, loss is 3.7691566705703736 and perplexity is 43.34349657223019
At time: 607.6635482311249 and batch: 1850, loss is 3.7966674089431764 and perplexity is 44.55246167943371
At time: 608.4833755493164 and batch: 1900, loss is 3.8688745164871214 and perplexity is 47.88845806895396
At time: 609.3029775619507 and batch: 1950, loss is 3.8125996923446657 and perplexity is 45.26796882126699
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333766067859738 and perplexity of 76.23083715175066
finished 18 epochs...
Completing Train Step...
At time: 612.027063369751 and batch: 50, loss is 3.9200360012054443 and perplexity is 50.402259287494495
At time: 612.8703639507294 and batch: 100, loss is 3.922180185317993 and perplexity is 50.5104469567865
At time: 613.6880257129669 and batch: 150, loss is 3.8793249702453614 and perplexity is 48.39153831545906
At time: 614.5050120353699 and batch: 200, loss is 3.863860764503479 and perplexity is 47.64895811570647
At time: 615.3259358406067 and batch: 250, loss is 3.865420880317688 and perplexity is 47.72335402682235
At time: 616.1429736614227 and batch: 300, loss is 3.881183023452759 and perplexity is 48.481535952744274
At time: 616.959680557251 and batch: 350, loss is 3.8942977571487427 and perplexity is 49.12154599330875
At time: 617.7766444683075 and batch: 400, loss is 3.8473973178863528 and perplexity is 46.87091425287462
At time: 618.5933587551117 and batch: 450, loss is 3.893862261772156 and perplexity is 49.10015844456518
At time: 619.4103302955627 and batch: 500, loss is 3.913258466720581 and perplexity is 50.06181123945644
At time: 620.2278678417206 and batch: 550, loss is 3.867248501777649 and perplexity is 47.81065400413913
At time: 621.0452773571014 and batch: 600, loss is 3.872459878921509 and perplexity is 48.060463714586824
At time: 621.8633651733398 and batch: 650, loss is 3.907788643836975 and perplexity is 49.78872953388497
At time: 622.6815497875214 and batch: 700, loss is 3.9206485414505003 and perplexity is 50.43314215728453
At time: 623.4987697601318 and batch: 750, loss is 3.8973009967803955 and perplexity is 49.26929151355624
At time: 624.3195369243622 and batch: 800, loss is 3.850786232948303 and perplexity is 47.030025254709805
At time: 625.1438181400299 and batch: 850, loss is 3.870308728218079 and perplexity is 47.957189533248595
At time: 625.9683973789215 and batch: 900, loss is 3.849967441558838 and perplexity is 46.991533235602304
At time: 626.7886836528778 and batch: 950, loss is 3.93668954372406 and perplexity is 51.24866370983053
At time: 627.6314492225647 and batch: 1000, loss is 3.90145339012146 and perplexity is 49.47430233977829
At time: 628.4485197067261 and batch: 1050, loss is 3.8514917707443237 and perplexity is 47.06321842321537
At time: 629.2659480571747 and batch: 1100, loss is 3.876523151397705 and perplexity is 48.25614375542754
At time: 630.0878348350525 and batch: 1150, loss is 3.8366110706329346 and perplexity is 46.368069760461
At time: 630.9060478210449 and batch: 1200, loss is 3.900058193206787 and perplexity is 49.40532407611783
At time: 631.7238328456879 and batch: 1250, loss is 3.890886812210083 and perplexity is 48.95428053343205
At time: 632.5413451194763 and batch: 1300, loss is 3.891017189025879 and perplexity is 48.9606634527309
At time: 633.3587214946747 and batch: 1350, loss is 3.797019290924072 and perplexity is 44.56814164649039
At time: 634.1754922866821 and batch: 1400, loss is 3.8132676219940187 and perplexity is 45.2982147397571
At time: 634.9930438995361 and batch: 1450, loss is 3.7267057847976686 and perplexity is 41.542034111967745
At time: 635.8101856708527 and batch: 1500, loss is 3.7500566244125366 and perplexity is 42.52348979952093
At time: 636.6274819374084 and batch: 1550, loss is 3.749623260498047 and perplexity is 42.50506564599363
At time: 637.4444441795349 and batch: 1600, loss is 3.8397302865982055 and perplexity is 46.51292758791106
At time: 638.2626442909241 and batch: 1650, loss is 3.8050195837020873 and perplexity is 44.92612992434279
At time: 639.0783500671387 and batch: 1700, loss is 3.810074653625488 and perplexity is 45.153809636091
At time: 639.8938963413239 and batch: 1750, loss is 3.802831826210022 and perplexity is 44.827949883231355
At time: 640.7121503353119 and batch: 1800, loss is 3.7716868114471436 and perplexity is 43.453300575871864
At time: 641.5318133831024 and batch: 1850, loss is 3.7996851778030396 and perplexity is 44.68711378319406
At time: 642.351188659668 and batch: 1900, loss is 3.8717928409576414 and perplexity is 48.02841625035403
At time: 643.1706125736237 and batch: 1950, loss is 3.8153305768966677 and perplexity is 45.391759369936985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333067712118459 and perplexity of 76.17761949355466
finished 19 epochs...
Completing Train Step...
At time: 645.9303910732269 and batch: 50, loss is 3.917475452423096 and perplexity is 50.273366931853026
At time: 646.7751934528351 and batch: 100, loss is 3.918604121208191 and perplexity is 50.33014094533203
At time: 647.5945379734039 and batch: 150, loss is 3.875254716873169 and perplexity is 48.19497280054433
At time: 648.4403500556946 and batch: 200, loss is 3.859298210144043 and perplexity is 47.43205235257602
At time: 649.259982585907 and batch: 250, loss is 3.860795660018921 and perplexity is 47.50313267976783
At time: 650.0795314311981 and batch: 300, loss is 3.876453456878662 and perplexity is 48.25278068389282
At time: 650.8989367485046 and batch: 350, loss is 3.8898052167892456 and perplexity is 48.90136043200543
At time: 651.7184722423553 and batch: 400, loss is 3.8426538610458376 and perplexity is 46.649110568032505
At time: 652.5370063781738 and batch: 450, loss is 3.8893099069595336 and perplexity is 48.87714510503697
At time: 653.3554124832153 and batch: 500, loss is 3.909021701812744 and perplexity is 49.850159789690196
At time: 654.1730527877808 and batch: 550, loss is 3.863019518852234 and perplexity is 47.60889049262508
At time: 654.9909090995789 and batch: 600, loss is 3.8684514713287355 and perplexity is 47.86820337325287
At time: 655.8085453510284 and batch: 650, loss is 3.904043459892273 and perplexity is 49.60261032629012
At time: 656.6266293525696 and batch: 700, loss is 3.9173154067993163 and perplexity is 50.265321543314705
At time: 657.445075750351 and batch: 750, loss is 3.894096474647522 and perplexity is 49.11165968067163
At time: 658.263400554657 and batch: 800, loss is 3.847609796524048 and perplexity is 46.88087437900214
At time: 659.0816965103149 and batch: 850, loss is 3.8673088359832763 and perplexity is 47.81353870899132
At time: 659.899836063385 and batch: 900, loss is 3.847162141799927 and perplexity is 46.8598926307552
At time: 660.7180321216583 and batch: 950, loss is 3.934042224884033 and perplexity is 51.11317158142814
At time: 661.5350291728973 and batch: 1000, loss is 3.898809242248535 and perplexity is 49.34365776638452
At time: 662.3523886203766 and batch: 1050, loss is 3.849223756790161 and perplexity is 46.95659933959147
At time: 663.1707503795624 and batch: 1100, loss is 3.8744201946258543 and perplexity is 48.15476980101552
At time: 663.9893333911896 and batch: 1150, loss is 3.834950017929077 and perplexity is 46.291113884389794
At time: 664.8073441982269 and batch: 1200, loss is 3.898562731742859 and perplexity is 49.331495535477046
At time: 665.6264228820801 and batch: 1250, loss is 3.8896308755874633 and perplexity is 48.892835653190616
At time: 666.4454100131989 and batch: 1300, loss is 3.8898856687545775 and perplexity is 48.90529480082132
At time: 667.2640027999878 and batch: 1350, loss is 3.796218032836914 and perplexity is 44.532445365443266
At time: 668.0819981098175 and batch: 1400, loss is 3.8126570558547974 and perplexity is 45.2705656253353
At time: 668.9006114006042 and batch: 1450, loss is 3.7262694311141966 and perplexity is 41.52391104668478
At time: 669.7194533348083 and batch: 1500, loss is 3.7500719451904296 and perplexity is 42.5241412974541
At time: 670.5378499031067 and batch: 1550, loss is 3.749739923477173 and perplexity is 42.510024702843396
At time: 671.356112241745 and batch: 1600, loss is 3.8401190567016603 and perplexity is 46.53101393906991
At time: 672.1748628616333 and batch: 1650, loss is 3.805327892303467 and perplexity is 44.93998317205314
At time: 672.9933214187622 and batch: 1700, loss is 3.810618977546692 and perplexity is 45.178394625301245
At time: 673.8120007514954 and batch: 1750, loss is 3.803573989868164 and perplexity is 44.86123190733041
At time: 674.6305527687073 and batch: 1800, loss is 3.7725482177734375 and perplexity is 43.490747650144066
At time: 675.4487149715424 and batch: 1850, loss is 3.8007724475860596 and perplexity is 44.73572715483687
At time: 676.2672493457794 and batch: 1900, loss is 3.8727601909637452 and perplexity is 48.07489901803501
At time: 677.0854744911194 and batch: 1950, loss is 3.8160384368896483 and perplexity is 45.423901755218154
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332794047510901 and perplexity of 76.15677522751027
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdf90580b38>
ELAPSED
1413.1600999832153


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}, 'best_accuracy': -75.41513488817796}, {'params': {'wordvec_dim': 300, 'dropout': 0.6309802267622319, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.016023383857180606, 'tune_wordvecs': True}, 'best_accuracy': -76.15677522751027}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.32978472608712295, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8376966109346161, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.2789039611816406 and batch: 50, loss is 7.373009843826294 and perplexity is 1592.4195113192227
At time: 2.0976710319519043 and batch: 100, loss is 6.645047206878662 and perplexity is 768.9663472762218
At time: 2.9213387966156006 and batch: 150, loss is 6.330589895248413 and perplexity is 561.4877151151479
At time: 3.7456791400909424 and batch: 200, loss is 6.136515302658081 and perplexity is 462.43929887256945
At time: 4.567077875137329 and batch: 250, loss is 6.024814558029175 and perplexity is 413.5649426135812
At time: 5.38742208480835 and batch: 300, loss is 5.919754896163941 and perplexity is 372.32044552208646
At time: 6.2082624435424805 and batch: 350, loss is 5.8499009323120115 and perplexity is 347.19998247536387
At time: 7.030113220214844 and batch: 400, loss is 5.775326423645019 and perplexity is 322.24960744357816
At time: 7.859460115432739 and batch: 450, loss is 5.6737996768951415 and perplexity is 291.13866825841245
At time: 8.72925329208374 and batch: 500, loss is 5.641251077651978 and perplexity is 281.81507055617817
At time: 9.55154800415039 and batch: 550, loss is 5.58169753074646 and perplexity is 265.52195511983854
At time: 10.374923467636108 and batch: 600, loss is 5.59477746963501 and perplexity is 269.01777880641737
At time: 11.196688652038574 and batch: 650, loss is 5.658113107681275 and perplexity is 286.60733484336976
At time: 12.025277614593506 and batch: 700, loss is 5.59896803855896 and perplexity is 270.14748174607655
At time: 12.854031324386597 and batch: 750, loss is 5.535410528182983 and perplexity is 253.51184003246058
At time: 13.673628568649292 and batch: 800, loss is 5.523239679336548 and perplexity is 250.44508610222704
At time: 14.499478340148926 and batch: 850, loss is 5.537348413467408 and perplexity is 254.00359322342885
At time: 15.319464921951294 and batch: 900, loss is 5.538819961547851 and perplexity is 254.37764687492935
At time: 16.138938426971436 and batch: 950, loss is 5.5596926879882815 and perplexity is 259.74300191209505
At time: 16.959182262420654 and batch: 1000, loss is 5.52849684715271 and perplexity is 251.7651848986674
At time: 17.779070377349854 and batch: 1050, loss is 5.424119997024536 and perplexity is 226.81166352866586
At time: 18.598512649536133 and batch: 1100, loss is 5.506425743103027 and perplexity is 246.26932228429942
At time: 19.4185733795166 and batch: 1150, loss is 5.399647855758667 and perplexity is 221.32846293592948
At time: 20.237902402877808 and batch: 1200, loss is 5.47911431312561 and perplexity is 239.63437233872554
At time: 21.06833243370056 and batch: 1250, loss is 5.428206539154052 and perplexity is 227.74043538727886
At time: 21.88752245903015 and batch: 1300, loss is 5.455506534576416 and perplexity is 234.04339211992132
At time: 22.70741295814514 and batch: 1350, loss is 5.393471727371216 and perplexity is 219.96572249476023
At time: 23.529353857040405 and batch: 1400, loss is 5.397841892242432 and perplexity is 220.9291125214423
At time: 24.35391592979431 and batch: 1450, loss is 5.3602450466156 and perplexity is 212.77708036508685
At time: 25.173513174057007 and batch: 1500, loss is 5.3236167526245115 and perplexity is 205.1244263101266
At time: 25.99319314956665 and batch: 1550, loss is 5.313083963394165 and perplexity is 202.97523233458477
At time: 26.813387632369995 and batch: 1600, loss is 5.352802371978759 and perplexity is 211.19932841604088
At time: 27.633609533309937 and batch: 1650, loss is 5.33689510345459 and perplexity is 207.86630392698623
At time: 28.451976537704468 and batch: 1700, loss is 5.3597947692871095 and perplexity is 212.68129323678053
At time: 29.271267414093018 and batch: 1750, loss is 5.3558863830566406 and perplexity is 211.85167488934653
At time: 30.095720767974854 and batch: 1800, loss is 5.324901685714722 and perplexity is 205.38816688130905
At time: 30.9256854057312 and batch: 1850, loss is 5.310727453231811 and perplexity is 202.4974822694084
At time: 31.755056381225586 and batch: 1900, loss is 5.358862028121949 and perplexity is 212.48300912777006
At time: 32.57432317733765 and batch: 1950, loss is 5.283519840240478 and perplexity is 197.06228380978615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.850400844840117 and perplexity of 127.79160418598933
finished 1 epochs...
Completing Train Step...
At time: 35.35092854499817 and batch: 50, loss is 5.076909351348877 and perplexity is 160.27792688471925
At time: 36.19079566001892 and batch: 100, loss is 5.024584245681763 and perplexity is 152.10700382120123
At time: 37.01434063911438 and batch: 150, loss is 4.962284679412842 and perplexity is 142.91994944314982
At time: 37.82740259170532 and batch: 200, loss is 4.929679107666016 and perplexity is 138.33511453910822
At time: 38.64576768875122 and batch: 250, loss is 4.9356076049804685 and perplexity is 139.15766974310705
At time: 39.46247410774231 and batch: 300, loss is 4.944247817993164 and perplexity is 140.36523093263176
At time: 40.27541518211365 and batch: 350, loss is 4.941993017196655 and perplexity is 140.0490918473942
At time: 41.0885214805603 and batch: 400, loss is 4.892668409347534 and perplexity is 133.30882237424942
At time: 41.90122866630554 and batch: 450, loss is 4.867579040527343 and perplexity is 130.0057968385687
At time: 42.72225475311279 and batch: 500, loss is 4.866159219741821 and perplexity is 129.82134288274568
At time: 43.54055070877075 and batch: 550, loss is 4.823102922439575 and perplexity is 124.3503422353175
At time: 44.36086630821228 and batch: 600, loss is 4.800741157531738 and perplexity is 121.60050926182646
At time: 45.18229866027832 and batch: 650, loss is 4.883339443206787 and perplexity is 132.07097179458768
At time: 46.00140905380249 and batch: 700, loss is 4.879681711196899 and perplexity is 131.58877398626728
At time: 46.821218967437744 and batch: 750, loss is 4.842079048156738 and perplexity is 126.73256112040309
At time: 47.64712166786194 and batch: 800, loss is 4.82208514213562 and perplexity is 124.22384529016959
At time: 48.47324562072754 and batch: 850, loss is 4.809354476928711 and perplexity is 122.65241699221446
At time: 49.29341530799866 and batch: 900, loss is 4.810605134963989 and perplexity is 122.80590918618796
At time: 50.114471197128296 and batch: 950, loss is 4.875407285690308 and perplexity is 131.02750797379974
At time: 50.94121074676514 and batch: 1000, loss is 4.84207124710083 and perplexity is 126.73157247646468
At time: 51.77075743675232 and batch: 1050, loss is 4.756148624420166 and perplexity is 116.29715823207172
At time: 52.59056997299194 and batch: 1100, loss is 4.824910488128662 and perplexity is 124.57531691436881
At time: 53.41102457046509 and batch: 1150, loss is 4.755977888107299 and perplexity is 116.27730377906461
At time: 54.23751950263977 and batch: 1200, loss is 4.835925598144531 and perplexity is 125.95511308760065
At time: 55.05721116065979 and batch: 1250, loss is 4.800246839523315 and perplexity is 121.54041479437736
At time: 55.88689565658569 and batch: 1300, loss is 4.812762613296509 and perplexity is 123.07114629313463
At time: 56.7145140171051 and batch: 1350, loss is 4.712032842636108 and perplexity is 111.27814108545466
At time: 57.54145789146423 and batch: 1400, loss is 4.721207065582275 and perplexity is 112.30372885289945
At time: 58.368953466415405 and batch: 1450, loss is 4.66901125907898 and perplexity is 106.59229814545839
At time: 59.18805503845215 and batch: 1500, loss is 4.662902698516846 and perplexity is 105.94315731335283
At time: 60.00749588012695 and batch: 1550, loss is 4.666756572723389 and perplexity is 106.35223667857395
At time: 60.83499455451965 and batch: 1600, loss is 4.735701112747193 and perplexity is 113.94331783240706
At time: 61.65664744377136 and batch: 1650, loss is 4.6967435073852535 and perplexity is 109.58971264552845
At time: 62.47679090499878 and batch: 1700, loss is 4.7239985752105715 and perplexity is 112.61766376558947
At time: 63.298946142196655 and batch: 1750, loss is 4.7095368957519534 and perplexity is 111.00074308528501
At time: 64.11832666397095 and batch: 1800, loss is 4.67152398109436 and perplexity is 106.86047174142882
At time: 64.9388906955719 and batch: 1850, loss is 4.695782394409179 and perplexity is 109.48443515054792
At time: 65.75868940353394 and batch: 1900, loss is 4.774866962432862 and perplexity is 118.49454934549553
At time: 66.57875919342041 and batch: 1950, loss is 4.697992572784424 and perplexity is 109.72668288828643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.600107592205669 and perplexity of 99.49501995472318
finished 2 epochs...
Completing Train Step...
At time: 69.41725659370422 and batch: 50, loss is 4.653419904708862 and perplexity is 104.94326855939585
At time: 70.23749494552612 and batch: 100, loss is 4.618226070404052 and perplexity is 101.31414845979363
At time: 71.05775284767151 and batch: 150, loss is 4.573217105865479 and perplexity is 96.85520253553656
At time: 71.87791657447815 and batch: 200, loss is 4.567500705718994 and perplexity is 96.30311891041192
At time: 72.69691324234009 and batch: 250, loss is 4.572531747817993 and perplexity is 96.78884478504457
At time: 73.516193151474 and batch: 300, loss is 4.586388969421387 and perplexity is 98.13940515167282
At time: 74.33578395843506 and batch: 350, loss is 4.589600019454956 and perplexity is 98.45504218382393
At time: 75.1542456150055 and batch: 400, loss is 4.548092155456543 and perplexity is 94.45203650648237
At time: 75.97324895858765 and batch: 450, loss is 4.556058464050293 and perplexity is 95.20747561198013
At time: 76.79454827308655 and batch: 500, loss is 4.5605054950714115 and perplexity is 95.63180902208381
At time: 77.66140365600586 and batch: 550, loss is 4.526995668411255 and perplexity is 92.48030180778755
At time: 78.48197841644287 and batch: 600, loss is 4.507082824707031 and perplexity is 90.65697012038856
At time: 79.30146813392639 and batch: 650, loss is 4.5853271484375 and perplexity is 98.03525397667369
At time: 80.1207582950592 and batch: 700, loss is 4.594127635955811 and perplexity is 98.90181951239163
At time: 80.94113278388977 and batch: 750, loss is 4.563243427276611 and perplexity is 95.89400120026254
At time: 81.7611494064331 and batch: 800, loss is 4.538391876220703 and perplexity is 93.54025479610097
At time: 82.58033633232117 and batch: 850, loss is 4.531374673843384 and perplexity is 92.88616153418903
At time: 83.39993190765381 and batch: 900, loss is 4.525596504211426 and perplexity is 92.35099716061987
At time: 84.21997427940369 and batch: 950, loss is 4.606482515335083 and perplexity is 100.13131908279566
At time: 85.0399956703186 and batch: 1000, loss is 4.575883226394653 and perplexity is 97.11377471851141
At time: 85.86063027381897 and batch: 1050, loss is 4.503703022003174 and perplexity is 90.35108465509263
At time: 86.68049716949463 and batch: 1100, loss is 4.55648286819458 and perplexity is 95.24789063474196
At time: 87.50114035606384 and batch: 1150, loss is 4.507665824890137 and perplexity is 90.70983856022616
At time: 88.3211760520935 and batch: 1200, loss is 4.584305095672607 and perplexity is 97.93510796026399
At time: 89.14852547645569 and batch: 1250, loss is 4.560540857315064 and perplexity is 95.63519083720931
At time: 89.96988487243652 and batch: 1300, loss is 4.563723669052124 and perplexity is 95.94006456555086
At time: 90.78888440132141 and batch: 1350, loss is 4.4567109489440915 and perplexity is 86.20351455550305
At time: 91.60870027542114 and batch: 1400, loss is 4.475083322525024 and perplexity is 87.80191598231619
At time: 92.42841148376465 and batch: 1450, loss is 4.410323123931885 and perplexity is 82.29605103202518
At time: 93.25602674484253 and batch: 1500, loss is 4.419044437408448 and perplexity is 83.01691958208087
At time: 94.0785002708435 and batch: 1550, loss is 4.422990770339966 and perplexity is 83.34517927069668
At time: 94.89872074127197 and batch: 1600, loss is 4.502607355117798 and perplexity is 90.25214417637933
At time: 95.71895742416382 and batch: 1650, loss is 4.465169382095337 and perplexity is 86.93575365283004
At time: 96.53939318656921 and batch: 1700, loss is 4.488375768661499 and perplexity is 88.97680952657534
At time: 97.3595597743988 and batch: 1750, loss is 4.479956846237183 and perplexity is 88.23086509967081
At time: 98.17980122566223 and batch: 1800, loss is 4.437140092849732 and perplexity is 84.53283957175198
At time: 98.99990630149841 and batch: 1850, loss is 4.4749619579315185 and perplexity is 87.79126058508103
At time: 99.82032799720764 and batch: 1900, loss is 4.557124118804932 and perplexity is 95.30898799001079
At time: 100.64051485061646 and batch: 1950, loss is 4.481184339523315 and perplexity is 88.33923439189256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525510992005814 and perplexity of 92.34310036080342
finished 3 epochs...
Completing Train Step...
At time: 103.41149115562439 and batch: 50, loss is 4.453520431518554 and perplexity is 85.92891902402006
At time: 104.2566306591034 and batch: 100, loss is 4.422996969223022 and perplexity is 83.34569591931763
At time: 105.07488012313843 and batch: 150, loss is 4.384189939498901 and perplexity is 80.17325171657221
At time: 105.89317917823792 and batch: 200, loss is 4.382442655563355 and perplexity is 80.03328859505321
At time: 106.71125292778015 and batch: 250, loss is 4.380165376663208 and perplexity is 79.85123784446911
At time: 107.53830409049988 and batch: 300, loss is 4.396571922302246 and perplexity is 81.1721268059847
At time: 108.36464500427246 and batch: 350, loss is 4.401642007827759 and perplexity is 81.58472149251466
At time: 109.1852638721466 and batch: 400, loss is 4.360811939239502 and perplexity is 78.32070026360134
At time: 110.00316286087036 and batch: 450, loss is 4.3887050914764405 and perplexity is 80.53606459386981
At time: 110.82068824768066 and batch: 500, loss is 4.400535945892334 and perplexity is 81.49453362343851
At time: 111.64829564094543 and batch: 550, loss is 4.360488681793213 and perplexity is 78.2953866056772
At time: 112.46987104415894 and batch: 600, loss is 4.3465613269805905 and perplexity is 77.21249737157636
At time: 113.29366374015808 and batch: 650, loss is 4.417417831420899 and perplexity is 82.88199352913307
At time: 114.11107754707336 and batch: 700, loss is 4.4315211296081545 and perplexity is 84.05918462457588
At time: 114.92866849899292 and batch: 750, loss is 4.40398211479187 and perplexity is 81.77586202486444
At time: 115.7475335597992 and batch: 800, loss is 4.3800637149810795 and perplexity is 79.84312044593098
At time: 116.57080936431885 and batch: 850, loss is 4.373098230361938 and perplexity is 79.28890684246099
At time: 117.39326119422913 and batch: 900, loss is 4.360980272293091 and perplexity is 78.33388533594652
At time: 118.21054768562317 and batch: 950, loss is 4.448836107254028 and perplexity is 85.52734139783486
At time: 119.05560731887817 and batch: 1000, loss is 4.419535799026489 and perplexity is 83.05772093329962
At time: 119.87392258644104 and batch: 1050, loss is 4.357849798202515 and perplexity is 78.08904656814659
At time: 120.6919846534729 and batch: 1100, loss is 4.3994519329071045 and perplexity is 81.40624035493627
At time: 121.5085232257843 and batch: 1150, loss is 4.3605255699157714 and perplexity is 78.29827482876429
At time: 122.33724045753479 and batch: 1200, loss is 4.430348787307739 and perplexity is 83.96069622903828
At time: 123.1552665233612 and batch: 1250, loss is 4.412293157577515 and perplexity is 82.45833682320875
At time: 123.9729413986206 and batch: 1300, loss is 4.412984981536865 and perplexity is 82.51540321394332
At time: 124.79206871986389 and batch: 1350, loss is 4.303747363090515 and perplexity is 73.97649170643373
At time: 125.61014986038208 and batch: 1400, loss is 4.328279685974121 and perplexity is 75.8137508612148
At time: 126.42819666862488 and batch: 1450, loss is 4.262008714675903 and perplexity is 70.95236345977042
At time: 127.24643063545227 and batch: 1500, loss is 4.275106225013733 and perplexity is 71.88777518399759
At time: 128.06458139419556 and batch: 1550, loss is 4.274757423400879 and perplexity is 71.86270498458609
At time: 128.88870525360107 and batch: 1600, loss is 4.362489833831787 and perplexity is 78.45222445404453
At time: 129.71215271949768 and batch: 1650, loss is 4.323869218826294 and perplexity is 75.48011309372703
At time: 130.53031253814697 and batch: 1700, loss is 4.349558358192444 and perplexity is 77.44425275172536
At time: 131.34808564186096 and batch: 1750, loss is 4.339190063476562 and perplexity is 76.64543625373562
At time: 132.16587924957275 and batch: 1800, loss is 4.297375020980835 and perplexity is 73.50658698015113
At time: 132.98379945755005 and batch: 1850, loss is 4.339152917861939 and perplexity is 76.64258926477481
At time: 133.80129981040955 and batch: 1900, loss is 4.421998109817505 and perplexity is 83.26248685103774
At time: 134.62029552459717 and batch: 1950, loss is 4.348456287384034 and perplexity is 77.35895071456477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486312511355378 and perplexity of 88.79341673256442
finished 4 epochs...
Completing Train Step...
At time: 137.44127774238586 and batch: 50, loss is 4.322571005821228 and perplexity is 75.38218740723806
At time: 138.290452003479 and batch: 100, loss is 4.297158489227295 and perplexity is 73.49067219306615
At time: 139.11270189285278 and batch: 150, loss is 4.260430879592896 and perplexity is 70.84050060525696
At time: 139.96214866638184 and batch: 200, loss is 4.2617878913879395 and perplexity is 70.9366972553775
At time: 140.7842288017273 and batch: 250, loss is 4.257031621932984 and perplexity is 70.60010430690244
At time: 141.606107711792 and batch: 300, loss is 4.2700418281555175 and perplexity is 71.52462729988457
At time: 142.42721843719482 and batch: 350, loss is 4.278872108459472 and perplexity is 72.15900655883883
At time: 143.24900341033936 and batch: 400, loss is 4.236395063400269 and perplexity is 69.15809138912748
At time: 144.07087206840515 and batch: 450, loss is 4.273684110641479 and perplexity is 71.78561520452406
At time: 144.89325261116028 and batch: 500, loss is 4.290149698257446 and perplexity is 72.97739227043351
At time: 145.71585369110107 and batch: 550, loss is 4.249061508178711 and perplexity is 70.03964985417986
At time: 146.5377163887024 and batch: 600, loss is 4.237841091156006 and perplexity is 69.25816824832964
At time: 147.359628200531 and batch: 650, loss is 4.302211675643921 and perplexity is 73.8629741228505
At time: 148.18181705474854 and batch: 700, loss is 4.320139646530151 and perplexity is 75.19912885623752
At time: 149.00333714485168 and batch: 750, loss is 4.293315515518189 and perplexity is 73.20879144901956
At time: 149.82313871383667 and batch: 800, loss is 4.272262215614319 and perplexity is 71.68361612841767
At time: 150.64291310310364 and batch: 850, loss is 4.267538900375366 and perplexity is 71.34583017473824
At time: 151.46258974075317 and batch: 900, loss is 4.248657274246216 and perplexity is 70.01134317273474
At time: 152.28288650512695 and batch: 950, loss is 4.344117250442505 and perplexity is 77.02401454535551
At time: 153.10239601135254 and batch: 1000, loss is 4.313816776275635 and perplexity is 74.72515453935326
At time: 153.92216563224792 and batch: 1050, loss is 4.254941263198853 and perplexity is 70.45267890190792
At time: 154.74190878868103 and batch: 1100, loss is 4.292729368209839 and perplexity is 73.16589288663083
At time: 155.56181120872498 and batch: 1150, loss is 4.256317644119263 and perplexity is 70.54971538920613
At time: 156.38183617591858 and batch: 1200, loss is 4.321186666488647 and perplexity is 75.27790507795316
At time: 157.20151782035828 and batch: 1250, loss is 4.309432029724121 and perplexity is 74.39822095991997
At time: 158.02170753479004 and batch: 1300, loss is 4.306799573898315 and perplexity is 74.20262848694868
At time: 158.84190106391907 and batch: 1350, loss is 4.203161783218384 and perplexity is 66.89751244228192
At time: 159.66172218322754 and batch: 1400, loss is 4.227873907089234 and perplexity is 68.57128815392277
At time: 160.48170852661133 and batch: 1450, loss is 4.156950840950012 and perplexity is 63.876455882811406
At time: 161.3018021583557 and batch: 1500, loss is 4.1754874420166015 and perplexity is 65.0715505396002
At time: 162.12210202217102 and batch: 1550, loss is 4.173459582328796 and perplexity is 64.93972826914552
At time: 162.9420783519745 and batch: 1600, loss is 4.265099444389343 and perplexity is 71.17199727729765
At time: 163.7620575428009 and batch: 1650, loss is 4.226853442192078 and perplexity is 68.50134925257504
At time: 164.58165836334229 and batch: 1700, loss is 4.252033557891846 and perplexity is 70.24812081501334
At time: 165.40065932273865 and batch: 1750, loss is 4.239387626647949 and perplexity is 69.36536133122115
At time: 166.22067308425903 and batch: 1800, loss is 4.197101316452026 and perplexity is 66.49330836124899
At time: 167.04775857925415 and batch: 1850, loss is 4.245786514282226 and perplexity is 69.81064562680262
At time: 167.8706338405609 and batch: 1900, loss is 4.325141706466675 and perplexity is 75.57622174029733
At time: 168.69049263000488 and batch: 1950, loss is 4.249787511825562 and perplexity is 70.09051735816058
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.47083257630814 and perplexity of 87.42948443689428
finished 5 epochs...
Completing Train Step...
At time: 171.470223903656 and batch: 50, loss is 4.2316046142578125 and perplexity is 68.82758533780218
At time: 172.28775787353516 and batch: 100, loss is 4.206393237113953 and perplexity is 67.11403832775656
At time: 173.1052601337433 and batch: 150, loss is 4.17477979183197 and perplexity is 65.02551893390465
At time: 173.92248106002808 and batch: 200, loss is 4.172513885498047 and perplexity is 64.87834400395907
At time: 174.74081659317017 and batch: 250, loss is 4.16926646232605 and perplexity is 64.66799829190408
At time: 175.5581021308899 and batch: 300, loss is 4.177918462753296 and perplexity is 65.22993326617551
At time: 176.37599778175354 and batch: 350, loss is 4.187397494316101 and perplexity is 65.85118966519677
At time: 177.1934151649475 and batch: 400, loss is 4.149397449493408 and perplexity is 63.39578962219571
At time: 178.0123782157898 and batch: 450, loss is 4.190729441642762 and perplexity is 66.07096830265142
At time: 178.83204793930054 and batch: 500, loss is 4.210201959609986 and perplexity is 67.37014448437773
At time: 179.65161442756653 and batch: 550, loss is 4.16595751285553 and perplexity is 64.45436879272731
At time: 180.47124910354614 and batch: 600, loss is 4.157815766334534 and perplexity is 63.93172815072578
At time: 181.31927490234375 and batch: 650, loss is 4.215985288619995 and perplexity is 67.76089703153264
At time: 182.143372297287 and batch: 700, loss is 4.238606867790222 and perplexity is 69.311224847462
At time: 182.9615819454193 and batch: 750, loss is 4.214975552558899 and perplexity is 67.69251094202833
At time: 183.7788634300232 and batch: 800, loss is 4.192306265830994 and perplexity is 66.17523278538677
At time: 184.59617161750793 and batch: 850, loss is 4.188075590133667 and perplexity is 65.89585822456053
At time: 185.41567969322205 and batch: 900, loss is 4.169730005264282 and perplexity is 64.6979816345884
At time: 186.23312520980835 and batch: 950, loss is 4.263910222053528 and perplexity is 71.08740825599679
At time: 187.05100440979004 and batch: 1000, loss is 4.233105802536011 and perplexity is 68.93098609471174
At time: 187.86847972869873 and batch: 1050, loss is 4.1775213766098025 and perplexity is 65.20403650549719
At time: 188.68621444702148 and batch: 1100, loss is 4.214597778320313 and perplexity is 67.66694328495436
At time: 189.50398921966553 and batch: 1150, loss is 4.17478883266449 and perplexity is 65.02610682138835
At time: 190.3232388496399 and batch: 1200, loss is 4.246028141975403 and perplexity is 69.8275158501391
At time: 191.14064240455627 and batch: 1250, loss is 4.233371624946594 and perplexity is 68.9493119312004
At time: 191.95808792114258 and batch: 1300, loss is 4.227850937843323 and perplexity is 68.56971314123125
At time: 192.77568888664246 and batch: 1350, loss is 4.128190312385559 and perplexity is 62.06550207173706
At time: 193.59255933761597 and batch: 1400, loss is 4.1520994710922245 and perplexity is 63.56731804742417
At time: 194.40860223770142 and batch: 1450, loss is 4.078759002685547 and perplexity is 59.0721160060123
At time: 195.2262237071991 and batch: 1500, loss is 4.103672437667846 and perplexity is 60.56229093963201
At time: 196.04362273216248 and batch: 1550, loss is 4.098248167037964 and perplexity is 60.234674028285895
At time: 196.8612198829651 and batch: 1600, loss is 4.190800185203552 and perplexity is 66.07564256354902
At time: 197.67879557609558 and batch: 1650, loss is 4.1539560985565185 and perplexity is 63.68544850413406
At time: 198.49614429473877 and batch: 1700, loss is 4.179747943878174 and perplexity is 65.34937942679561
At time: 199.313068151474 and batch: 1750, loss is 4.165091195106506 and perplexity is 64.3985550087666
At time: 200.13563299179077 and batch: 1800, loss is 4.12226526260376 and perplexity is 61.6988481761735
At time: 200.9541506767273 and batch: 1850, loss is 4.176263041496277 and perplexity is 65.12203957744515
At time: 201.7718722820282 and batch: 1900, loss is 4.249945311546326 and perplexity is 70.1015784949271
At time: 202.58925604820251 and batch: 1950, loss is 4.175159573554993 and perplexity is 65.05021912756999
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465424861464389 and perplexity of 86.95796678169859
finished 6 epochs...
Completing Train Step...
At time: 205.3661150932312 and batch: 50, loss is 4.159540090560913 and perplexity is 64.04206227697584
At time: 206.21122121810913 and batch: 100, loss is 4.13720136642456 and perplexity is 62.62730508201948
At time: 207.02958726882935 and batch: 150, loss is 4.107325644493103 and perplexity is 60.78394213656702
At time: 207.84791588783264 and batch: 200, loss is 4.103689846992492 and perplexity is 60.56334529739407
At time: 208.66692447662354 and batch: 250, loss is 4.098075594902038 and perplexity is 60.22428009880917
At time: 209.49405360221863 and batch: 300, loss is 4.105334277153015 and perplexity is 60.66301942012895
At time: 210.31265139579773 and batch: 350, loss is 4.117813515663147 and perplexity is 61.424790986799515
At time: 211.13057017326355 and batch: 400, loss is 4.078906002044678 and perplexity is 59.08080020747811
At time: 211.94833707809448 and batch: 450, loss is 4.126137285232544 and perplexity is 61.93821062183005
At time: 212.76649975776672 and batch: 500, loss is 4.147792530059815 and perplexity is 63.294126090133965
At time: 213.58295035362244 and batch: 550, loss is 4.09930645942688 and perplexity is 60.29845366815992
At time: 214.39992094039917 and batch: 600, loss is 4.093162603378296 and perplexity is 59.92912436366558
At time: 215.21757912635803 and batch: 650, loss is 4.1551330327987674 and perplexity is 63.76044621424104
At time: 216.0368013381958 and batch: 700, loss is 4.1716190576553345 and perplexity is 64.8203150222016
At time: 216.85454058647156 and batch: 750, loss is 4.149434752464295 and perplexity is 63.39815451759884
At time: 217.6728663444519 and batch: 800, loss is 4.131072931289673 and perplexity is 62.24467137564644
At time: 218.49145126342773 and batch: 850, loss is 4.125129585266113 and perplexity is 61.87582692636855
At time: 219.30950832366943 and batch: 900, loss is 4.110224080085755 and perplexity is 60.96037604556075
At time: 220.12666940689087 and batch: 950, loss is 4.203449187278747 and perplexity is 66.91674182215459
At time: 220.94525289535522 and batch: 1000, loss is 4.170928287506103 and perplexity is 64.77555454490114
At time: 221.7639400959015 and batch: 1050, loss is 4.113678517341614 and perplexity is 61.17132398313854
At time: 222.6193175315857 and batch: 1100, loss is 4.1480781888961795 and perplexity is 63.31220919921859
At time: 223.43722796440125 and batch: 1150, loss is 4.111961627006531 and perplexity is 61.066389634368626
At time: 224.25552678108215 and batch: 1200, loss is 4.18673303604126 and perplexity is 65.80744883090459
At time: 225.07392191886902 and batch: 1250, loss is 4.171782341003418 and perplexity is 64.83089996441113
At time: 225.89231395721436 and batch: 1300, loss is 4.166954407691955 and perplexity is 64.51865505816087
At time: 226.71095728874207 and batch: 1350, loss is 4.068614783287049 and perplexity is 58.47590466301065
At time: 227.54052305221558 and batch: 1400, loss is 4.0916005945205685 and perplexity is 59.835587612208954
At time: 228.35916781425476 and batch: 1450, loss is 4.014078984260559 and perplexity is 55.37227317484056
At time: 229.17716312408447 and batch: 1500, loss is 4.042971286773682 and perplexity is 56.99544126183929
At time: 229.9956295490265 and batch: 1550, loss is 4.037775354385376 and perplexity is 56.70006484508675
At time: 230.8140890598297 and batch: 1600, loss is 4.130749254226685 and perplexity is 62.22452746346597
At time: 231.63265204429626 and batch: 1650, loss is 4.096258311271668 and perplexity is 60.114934886160135
At time: 232.45069646835327 and batch: 1700, loss is 4.120172023773193 and perplexity is 61.56983282844604
At time: 233.2689619064331 and batch: 1750, loss is 4.103817739486694 and perplexity is 60.571091390004376
At time: 234.08637690544128 and batch: 1800, loss is 4.062687773704528 and perplexity is 58.13034250246149
At time: 234.91201663017273 and batch: 1850, loss is 4.1161944818496705 and perplexity is 61.325422635272666
At time: 235.7362196445465 and batch: 1900, loss is 4.187425622940063 and perplexity is 65.85304199459996
At time: 236.56366276741028 and batch: 1950, loss is 4.113795561790466 and perplexity is 61.17848416606136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.465261627906977 and perplexity of 86.94377348187841
finished 7 epochs...
Completing Train Step...
At time: 239.4113986492157 and batch: 50, loss is 4.100641193389893 and perplexity is 60.37898979738509
At time: 240.27088403701782 and batch: 100, loss is 4.082467112541199 and perplexity is 59.29156852713925
At time: 241.09086108207703 and batch: 150, loss is 4.051059799194336 and perplexity is 57.458319069245235
At time: 241.91152334213257 and batch: 200, loss is 4.050761995315551 and perplexity is 57.44121030661235
At time: 242.7334508895874 and batch: 250, loss is 4.042359490394592 and perplexity is 56.960582321624656
At time: 243.59863567352295 and batch: 300, loss is 4.049286556243897 and perplexity is 57.356521792337624
At time: 244.41850399971008 and batch: 350, loss is 4.065848631858826 and perplexity is 58.31437496660725
At time: 245.23810601234436 and batch: 400, loss is 4.022531657218933 and perplexity is 55.84230058641768
At time: 246.0579490661621 and batch: 450, loss is 4.0720461559295655 and perplexity is 58.67690193356832
At time: 246.8809769153595 and batch: 500, loss is 4.092055172920227 and perplexity is 59.86279376106364
At time: 247.7095959186554 and batch: 550, loss is 4.047099604606628 and perplexity is 57.231222914328555
At time: 248.52922749519348 and batch: 600, loss is 4.042870216369629 and perplexity is 56.989681000662635
At time: 249.3496072292328 and batch: 650, loss is 4.101712317466736 and perplexity is 60.44369783607494
At time: 250.1810119152069 and batch: 700, loss is 4.115746307373047 and perplexity is 61.29794430408266
At time: 251.0011203289032 and batch: 750, loss is 4.097491464614868 and perplexity is 60.18911154528904
At time: 251.8207926750183 and batch: 800, loss is 4.0797928428649906 and perplexity is 59.13321871279842
At time: 252.65018272399902 and batch: 850, loss is 4.074051771163941 and perplexity is 58.794703314626524
At time: 253.4695222377777 and batch: 900, loss is 4.056389350891113 and perplexity is 57.76536362928542
At time: 254.28933334350586 and batch: 950, loss is 4.1494851350784305 and perplexity is 63.401348762821364
At time: 255.10965847969055 and batch: 1000, loss is 4.120289473533631 and perplexity is 61.5770646152394
At time: 255.92933344841003 and batch: 1050, loss is 4.063658137321472 and perplexity is 58.1867774486473
At time: 256.74870705604553 and batch: 1100, loss is 4.098069748878479 and perplexity is 60.223928027277964
At time: 257.56919598579407 and batch: 1150, loss is 4.0603000354766845 and perplexity is 57.99170803874137
At time: 258.38848066329956 and batch: 1200, loss is 4.13470018863678 and perplexity is 62.470858789195304
At time: 259.2078335285187 and batch: 1250, loss is 4.125495471954346 and perplexity is 61.89847061002289
At time: 260.0257017612457 and batch: 1300, loss is 4.120070447921753 and perplexity is 61.56357913787081
At time: 260.8446295261383 and batch: 1350, loss is 4.019676022529602 and perplexity is 55.68306284634887
At time: 261.6636161804199 and batch: 1400, loss is 4.042083039283752 and perplexity is 56.94483768177963
At time: 262.4837338924408 and batch: 1450, loss is 3.9623004007339477 and perplexity is 52.5781377246855
At time: 263.302752494812 and batch: 1500, loss is 3.9914693689346312 and perplexity is 54.134374320584506
At time: 264.12248277664185 and batch: 1550, loss is 3.9893875169754027 and perplexity is 54.021791798078176
At time: 264.94195890426636 and batch: 1600, loss is 4.082798290252685 and perplexity is 59.31120782498387
At time: 265.76198267936707 and batch: 1650, loss is 4.049538812637329 and perplexity is 57.37099216671028
At time: 266.5824398994446 and batch: 1700, loss is 4.068032741546631 and perplexity is 58.44187914878342
At time: 267.40469908714294 and batch: 1750, loss is 4.052800769805908 and perplexity is 57.55843944216001
At time: 268.22670698165894 and batch: 1800, loss is 4.01172294139862 and perplexity is 55.24196728928008
At time: 269.04746890068054 and batch: 1850, loss is 4.0675550031661984 and perplexity is 58.41396588823829
At time: 269.8671543598175 and batch: 1900, loss is 4.134542689323426 and perplexity is 62.461020446617816
At time: 270.6869466304779 and batch: 1950, loss is 4.063394689559937 and perplexity is 58.1714502914188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.469271779614826 and perplexity of 87.29313122418951
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 273.50067830085754 and batch: 50, loss is 4.0802347946166995 and perplexity is 59.15935851823365
At time: 274.3194718360901 and batch: 100, loss is 4.070722842216492 and perplexity is 58.59930533824197
At time: 275.1376428604126 and batch: 150, loss is 4.043936510086059 and perplexity is 57.05048114906239
At time: 275.95538306236267 and batch: 200, loss is 4.041096892356872 and perplexity is 56.88870938502042
At time: 276.77325892448425 and batch: 250, loss is 4.025167527198792 and perplexity is 55.989687791559525
At time: 277.59486532211304 and batch: 300, loss is 4.023401427268982 and perplexity is 55.89089167546726
At time: 278.4137167930603 and batch: 350, loss is 4.034864263534546 and perplexity is 56.535245823044164
At time: 279.23190450668335 and batch: 400, loss is 3.9952440309524535 and perplexity is 54.33909942815667
At time: 280.04964208602905 and batch: 450, loss is 4.027151436805725 and perplexity is 56.10087652879141
At time: 280.8674957752228 and batch: 500, loss is 4.042112889289856 and perplexity is 56.94653751090186
At time: 281.69295048713684 and batch: 550, loss is 3.997686357498169 and perplexity is 54.47197545042859
At time: 282.5123164653778 and batch: 600, loss is 3.9803460216522217 and perplexity is 53.53555548428971
At time: 283.32982659339905 and batch: 650, loss is 4.025545339584351 and perplexity is 56.01084538561963
At time: 284.1476013660431 and batch: 700, loss is 4.038588523864746 and perplexity is 56.74619035868533
At time: 284.9914734363556 and batch: 750, loss is 4.009357089996338 and perplexity is 55.11142748328413
At time: 285.8090958595276 and batch: 800, loss is 3.9913135719299317 and perplexity is 54.12594100417385
At time: 286.6264808177948 and batch: 850, loss is 3.9877927780151365 and perplexity is 53.93570979939652
At time: 287.4441485404968 and batch: 900, loss is 3.955002875328064 and perplexity is 52.195844024391064
At time: 288.26146626472473 and batch: 950, loss is 4.052642874717712 and perplexity is 57.54935196474076
At time: 289.0796353816986 and batch: 1000, loss is 4.009710111618042 and perplexity is 55.130886443303424
At time: 289.89766669273376 and batch: 1050, loss is 3.9510959434509276 and perplexity is 51.99231626096077
At time: 290.71525287628174 and batch: 1100, loss is 3.9734004735946655 and perplexity is 53.16501002115771
At time: 291.53236413002014 and batch: 1150, loss is 3.9356248331069947 and perplexity is 51.19412775112726
At time: 292.34945344924927 and batch: 1200, loss is 3.9961613750457765 and perplexity is 54.388969950771006
At time: 293.1667945384979 and batch: 1250, loss is 3.9822149896621704 and perplexity is 53.63570528411844
At time: 293.9842474460602 and batch: 1300, loss is 3.970476942062378 and perplexity is 53.0098074183416
At time: 294.8082549571991 and batch: 1350, loss is 3.8743984270095826 and perplexity is 48.15372159787332
At time: 295.6391968727112 and batch: 1400, loss is 3.8885371589660647 and perplexity is 48.83938997870838
At time: 296.45705938339233 and batch: 1450, loss is 3.8021697473526 and perplexity is 44.798280068354465
At time: 297.2748177051544 and batch: 1500, loss is 3.8243850660324097 and perplexity is 45.80462488447671
At time: 298.09179878234863 and batch: 1550, loss is 3.81917121887207 and perplexity is 45.56642807157957
At time: 298.9092266559601 and batch: 1600, loss is 3.904171028137207 and perplexity is 49.6089384478587
At time: 299.7266368865967 and batch: 1650, loss is 3.862180209159851 and perplexity is 47.56894865352209
At time: 300.5517544746399 and batch: 1700, loss is 3.8730255222320555 and perplexity is 48.087656484367876
At time: 301.3691236972809 and batch: 1750, loss is 3.844540810585022 and perplexity is 46.737218186894786
At time: 302.1878516674042 and batch: 1800, loss is 3.80518958568573 and perplexity is 44.93376810478184
At time: 303.008531332016 and batch: 1850, loss is 3.850126633644104 and perplexity is 46.999014511232055
At time: 303.82744002342224 and batch: 1900, loss is 3.912546167373657 and perplexity is 50.026164940929476
At time: 304.6455714702606 and batch: 1950, loss is 3.839317560195923 and perplexity is 46.49373443568086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3750794876453485 and perplexity of 79.44615428902266
finished 9 epochs...
Completing Train Step...
At time: 307.4206511974335 and batch: 50, loss is 3.990512056350708 and perplexity is 54.08257560056375
At time: 308.26575756073 and batch: 100, loss is 3.977649760246277 and perplexity is 53.391404054489634
At time: 309.0847225189209 and batch: 150, loss is 3.949393286705017 and perplexity is 51.9038665140909
At time: 309.90257024765015 and batch: 200, loss is 3.9461025619506835 and perplexity is 51.7333458977927
At time: 310.7207524776459 and batch: 250, loss is 3.9328486919403076 and perplexity is 51.05220271869814
At time: 311.5436761379242 and batch: 300, loss is 3.934068307876587 and perplexity is 51.11450478328877
At time: 312.3686680793762 and batch: 350, loss is 3.9507955217361452 and perplexity is 51.97669898615584
At time: 313.1872012615204 and batch: 400, loss is 3.908125710487366 and perplexity is 49.80551448284052
At time: 314.0049216747284 and batch: 450, loss is 3.9508350896835327 and perplexity is 51.978755638135176
At time: 314.8228425979614 and batch: 500, loss is 3.9712338256835937 and perplexity is 53.04994486111072
At time: 315.64976954460144 and batch: 550, loss is 3.929431495666504 and perplexity is 50.87804505672833
At time: 316.47016191482544 and batch: 600, loss is 3.9148896741867065 and perplexity is 50.14353907912709
At time: 317.2885208129883 and batch: 650, loss is 3.9606689453125 and perplexity is 52.492428771024066
At time: 318.107040643692 and batch: 700, loss is 3.978135404586792 and perplexity is 53.41733958491289
At time: 318.92478585243225 and batch: 750, loss is 3.950007119178772 and perplexity is 51.93573657330864
At time: 319.74300837516785 and batch: 800, loss is 3.9344840002059938 and perplexity is 51.13575710775672
At time: 320.5615680217743 and batch: 850, loss is 3.934435973167419 and perplexity is 51.1333012677514
At time: 321.37995862960815 and batch: 900, loss is 3.9005967378616333 and perplexity is 49.43193821512788
At time: 322.1973009109497 and batch: 950, loss is 4.001506390571595 and perplexity is 54.6804581501018
At time: 323.01474165916443 and batch: 1000, loss is 3.962271237373352 and perplexity is 52.576604391854254
At time: 323.83226776123047 and batch: 1050, loss is 3.9076742696762086 and perplexity is 49.783035315370846
At time: 324.6573808193207 and batch: 1100, loss is 3.9293109512329103 and perplexity is 50.8719123612432
At time: 325.47960138320923 and batch: 1150, loss is 3.8956529474258423 and perplexity is 49.188160162076926
At time: 326.2981848716736 and batch: 1200, loss is 3.957565450668335 and perplexity is 52.32977133327275
At time: 327.16197967529297 and batch: 1250, loss is 3.947220106124878 and perplexity is 51.79119251416652
At time: 327.98015904426575 and batch: 1300, loss is 3.938800563812256 and perplexity is 51.35696494123321
At time: 328.7981493473053 and batch: 1350, loss is 3.842409782409668 and perplexity is 46.63772590617943
At time: 329.6164515018463 and batch: 1400, loss is 3.8609485912322996 and perplexity is 47.51039794701675
At time: 330.4341468811035 and batch: 1450, loss is 3.777495894432068 and perplexity is 43.70645900212761
At time: 331.2566864490509 and batch: 1500, loss is 3.8026951789855956 and perplexity is 44.821824686808164
At time: 332.08172607421875 and batch: 1550, loss is 3.79847629070282 and perplexity is 44.633124747694794
At time: 332.8991584777832 and batch: 1600, loss is 3.887901210784912 and perplexity is 48.80834053144902
At time: 333.7178113460541 and batch: 1650, loss is 3.847157130241394 and perplexity is 46.85965779024889
At time: 334.5358774662018 and batch: 1700, loss is 3.8635959243774414 and perplexity is 47.636340430541956
At time: 335.35444235801697 and batch: 1750, loss is 3.8372618341445923 and perplexity is 46.39825422877716
At time: 336.17294335365295 and batch: 1800, loss is 3.802833905220032 and perplexity is 44.828043081084765
At time: 336.99087476730347 and batch: 1850, loss is 3.8498371171951296 and perplexity is 46.985409492978796
At time: 337.8089096546173 and batch: 1900, loss is 3.9151621675491333 and perplexity is 50.15720472250874
At time: 338.63288259506226 and batch: 1950, loss is 3.8420580625534058 and perplexity is 46.62132537629238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372708484738372 and perplexity of 79.25801035929747
finished 10 epochs...
Completing Train Step...
At time: 341.4019594192505 and batch: 50, loss is 3.9548529148101808 and perplexity is 52.188017295454635
At time: 342.25137162208557 and batch: 100, loss is 3.9405559587478636 and perplexity is 51.447195869686766
At time: 343.075475692749 and batch: 150, loss is 3.9118696594238282 and perplexity is 49.99233328762899
At time: 343.8967535495758 and batch: 200, loss is 3.907874150276184 and perplexity is 49.79298697287678
At time: 344.7139792442322 and batch: 250, loss is 3.895400285720825 and perplexity is 49.17573376756684
At time: 345.53176259994507 and batch: 300, loss is 3.898073115348816 and perplexity is 49.307347938532295
At time: 346.349472284317 and batch: 350, loss is 3.9152148580551147 and perplexity is 50.15984760063086
At time: 347.16860270500183 and batch: 400, loss is 3.8728294658660887 and perplexity is 48.07822951732833
At time: 348.0142755508423 and batch: 450, loss is 3.916735200881958 and perplexity is 50.23616576531272
At time: 348.83233404159546 and batch: 500, loss is 3.9399464654922487 and perplexity is 51.41584870469712
At time: 349.6618528366089 and batch: 550, loss is 3.8982167530059812 and perplexity is 49.31443083914466
At time: 350.47935938835144 and batch: 600, loss is 3.885344305038452 and perplexity is 48.68370161795107
At time: 351.2976772785187 and batch: 650, loss is 3.9300568437576295 and perplexity is 50.90987149534891
At time: 352.11353850364685 and batch: 700, loss is 3.947997612953186 and perplexity is 51.83147617837515
At time: 352.9422860145569 and batch: 750, loss is 3.9208065032958985 and perplexity is 50.44110929872454
At time: 353.75991559028625 and batch: 800, loss is 3.906385145187378 and perplexity is 49.718900133416184
At time: 354.5875747203827 and batch: 850, loss is 3.908127336502075 and perplexity is 49.8055954674055
At time: 355.4067986011505 and batch: 900, loss is 3.8736291217803953 and perplexity is 48.11669093381133
At time: 356.2256474494934 and batch: 950, loss is 3.976146450042725 and perplexity is 53.311200512498665
At time: 357.0440938472748 and batch: 1000, loss is 3.9380054664611817 and perplexity is 51.31614738356554
At time: 357.86187195777893 and batch: 1050, loss is 3.8846067714691164 and perplexity is 48.6478089913638
At time: 358.67967200279236 and batch: 1100, loss is 3.906425428390503 and perplexity is 49.720903010310295
At time: 359.4981861114502 and batch: 1150, loss is 3.875230617523193 and perplexity is 48.19381134702294
At time: 360.3150568008423 and batch: 1200, loss is 3.9360983991622924 and perplexity is 51.21837729368769
At time: 361.13317370414734 and batch: 1250, loss is 3.926918511390686 and perplexity is 50.75034984474687
At time: 361.9515073299408 and batch: 1300, loss is 3.919909257888794 and perplexity is 50.39587154279625
At time: 362.77612566947937 and batch: 1350, loss is 3.8236088800430297 and perplexity is 45.76908577065794
At time: 363.59563398361206 and batch: 1400, loss is 3.8443655157089234 and perplexity is 46.72902611005904
At time: 364.41374826431274 and batch: 1450, loss is 3.7609498786926268 and perplexity is 42.989241155146445
At time: 365.2391777038574 and batch: 1500, loss is 3.788311104774475 and perplexity is 44.181718935089926
At time: 366.0598666667938 and batch: 1550, loss is 3.7844508600234987 and perplexity is 44.0114954500209
At time: 366.87780380249023 and batch: 1600, loss is 3.8754898500442505 and perplexity is 48.20630636972593
At time: 367.6961431503296 and batch: 1650, loss is 3.834311728477478 and perplexity is 46.261576182499226
At time: 368.513827085495 and batch: 1700, loss is 3.853346753120422 and perplexity is 47.15060088535991
At time: 369.33179473876953 and batch: 1750, loss is 3.827721481323242 and perplexity is 45.95770336001383
At time: 370.15009570121765 and batch: 1800, loss is 3.795621728897095 and perplexity is 44.505898408636156
At time: 370.96824526786804 and batch: 1850, loss is 3.843199691772461 and perplexity is 46.674580036327036
At time: 371.7865855693817 and batch: 1900, loss is 3.910154128074646 and perplexity is 49.90664339551918
At time: 372.60488772392273 and batch: 1950, loss is 3.836682844161987 and perplexity is 46.37139787989707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373398323946221 and perplexity of 79.31270450529358
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 375.3938753604889 and batch: 50, loss is 3.951717576980591 and perplexity is 52.024646475765095
At time: 376.21321511268616 and batch: 100, loss is 3.962834553718567 and perplexity is 52.6062299959942
At time: 377.0337288379669 and batch: 150, loss is 3.9352378034591675 and perplexity is 51.17431793963239
At time: 377.8530261516571 and batch: 200, loss is 3.932886214256287 and perplexity is 51.05411835151925
At time: 378.67284989356995 and batch: 250, loss is 3.9213637781143187 and perplexity is 50.46922669258001
At time: 379.4925284385681 and batch: 300, loss is 3.913921036720276 and perplexity is 50.09499168468403
At time: 380.31286358833313 and batch: 350, loss is 3.932352595329285 and perplexity is 51.02688217518137
At time: 381.13245248794556 and batch: 400, loss is 3.8909832096099852 and perplexity is 48.95899982624969
At time: 381.95209765434265 and batch: 450, loss is 3.9299401235580445 and perplexity is 50.90392963176162
At time: 382.7709288597107 and batch: 500, loss is 3.9510073137283324 and perplexity is 51.987708400593185
At time: 383.58994007110596 and batch: 550, loss is 3.9182665061950686 and perplexity is 50.313151602226355
At time: 384.40970277786255 and batch: 600, loss is 3.895812120437622 and perplexity is 49.19599021282367
At time: 385.23798418045044 and batch: 650, loss is 3.9350094985961914 and perplexity is 51.16263592756811
At time: 386.058123588562 and batch: 700, loss is 3.94932550907135 and perplexity is 51.900348712055894
At time: 386.87781167030334 and batch: 750, loss is 3.9142182159423826 and perplexity is 50.10988108764534
At time: 387.69770407676697 and batch: 800, loss is 3.894940457344055 and perplexity is 49.15312656784634
At time: 388.5616331100464 and batch: 850, loss is 3.9016201734542846 and perplexity is 49.48255451695536
At time: 389.38085174560547 and batch: 900, loss is 3.8641140937805174 and perplexity is 47.66103052089983
At time: 390.19976258277893 and batch: 950, loss is 3.9673638248443606 and perplexity is 52.845038280036135
At time: 391.019540309906 and batch: 1000, loss is 3.9248487424850462 and perplexity is 50.645416979539206
At time: 391.83806347846985 and batch: 1050, loss is 3.8674014902114866 and perplexity is 47.81796904075971
At time: 392.65740418434143 and batch: 1100, loss is 3.885869245529175 and perplexity is 48.70926437304418
At time: 393.4759123325348 and batch: 1150, loss is 3.8541144323349 and perplexity is 47.18681131882997
At time: 394.29525661468506 and batch: 1200, loss is 3.9128878355026244 and perplexity is 50.0432602073918
At time: 395.1146500110626 and batch: 1250, loss is 3.8948569869995118 and perplexity is 49.14902391066383
At time: 395.93366503715515 and batch: 1300, loss is 3.8862603950500487 and perplexity is 48.72832070516044
At time: 396.7524013519287 and batch: 1350, loss is 3.792126941680908 and perplexity is 44.350631234730066
At time: 397.5717341899872 and batch: 1400, loss is 3.8095431518554688 and perplexity is 45.12981668305962
At time: 398.3893258571625 and batch: 1450, loss is 3.7232177591323854 and perplexity is 41.39738684414052
At time: 399.2073881626129 and batch: 1500, loss is 3.751801176071167 and perplexity is 42.59773897110795
At time: 400.02752709388733 and batch: 1550, loss is 3.7457839918136595 and perplexity is 42.34219014001108
At time: 400.8460023403168 and batch: 1600, loss is 3.8302482318878175 and perplexity is 46.07397384432084
At time: 401.6649398803711 and batch: 1650, loss is 3.7849171924591065 and perplexity is 44.032024224133444
At time: 402.4842462539673 and batch: 1700, loss is 3.8013475131988526 and perplexity is 44.7614605316678
At time: 403.3033480644226 and batch: 1750, loss is 3.7738949775695803 and perplexity is 43.54935869922685
At time: 404.12275099754333 and batch: 1800, loss is 3.7441103219985963 and perplexity is 42.27138256524903
At time: 404.9416811466217 and batch: 1850, loss is 3.7864126110076906 and perplexity is 44.09791978833434
At time: 405.7609112262726 and batch: 1900, loss is 3.8537637424468993 and perplexity is 47.17026628251149
At time: 406.57987880706787 and batch: 1950, loss is 3.7832078981399535 and perplexity is 43.95682482253039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.344081577034884 and perplexity of 77.02126688529754
finished 12 epochs...
Completing Train Step...
At time: 409.3722357749939 and batch: 50, loss is 3.9300790548324587 and perplexity is 50.91100227087205
At time: 410.22313165664673 and batch: 100, loss is 3.930615439414978 and perplexity is 50.93831747264242
At time: 411.049259185791 and batch: 150, loss is 3.899772572517395 and perplexity is 49.391214908426576
At time: 411.87341952323914 and batch: 200, loss is 3.897604193687439 and perplexity is 49.28423207520695
At time: 412.7002010345459 and batch: 250, loss is 3.886524453163147 and perplexity is 48.74118951256202
At time: 413.51914167404175 and batch: 300, loss is 3.8801007890701293 and perplexity is 48.42909594891938
At time: 414.33647751808167 and batch: 350, loss is 3.9010830450057985 and perplexity is 49.45598316597364
At time: 415.15449929237366 and batch: 400, loss is 3.8586726665496824 and perplexity is 47.40239081431935
At time: 415.9719398021698 and batch: 450, loss is 3.900395646095276 and perplexity is 49.421998858752595
At time: 416.78899216651917 and batch: 500, loss is 3.922592568397522 and perplexity is 50.531280905939724
At time: 417.6063015460968 and batch: 550, loss is 3.8903345012664796 and perplexity is 48.92725001387022
At time: 418.4309284687042 and batch: 600, loss is 3.8701160621643065 and perplexity is 47.94795070082448
At time: 419.2529184818268 and batch: 650, loss is 3.9112967252731323 and perplexity is 49.963699176128976
At time: 420.07176065444946 and batch: 700, loss is 3.9269133043289184 and perplexity is 50.75008558522852
At time: 420.89446115493774 and batch: 750, loss is 3.894102463722229 and perplexity is 49.11195381495123
At time: 421.71711325645447 and batch: 800, loss is 3.87640567779541 and perplexity is 48.25047526534321
At time: 422.53586435317993 and batch: 850, loss is 3.8834676790237426 and perplexity is 48.59242618871222
At time: 423.3666818141937 and batch: 900, loss is 3.8468023252487185 and perplexity is 46.84303469886214
At time: 424.1850664615631 and batch: 950, loss is 3.95027437210083 and perplexity is 51.94961840556458
At time: 425.0022919178009 and batch: 1000, loss is 3.9087300729751586 and perplexity is 49.83562416514395
At time: 425.8276777267456 and batch: 1050, loss is 3.8528129196166994 and perplexity is 47.1254370321382
At time: 426.6468813419342 and batch: 1100, loss is 3.8723502922058106 and perplexity is 48.05519721478788
At time: 427.46501445770264 and batch: 1150, loss is 3.841855010986328 and perplexity is 46.61185980414764
At time: 428.2828688621521 and batch: 1200, loss is 3.902190046310425 and perplexity is 49.51076131800884
At time: 429.1008098125458 and batch: 1250, loss is 3.885688614845276 and perplexity is 48.70046677988983
At time: 429.9186441898346 and batch: 1300, loss is 3.8784141063690187 and perplexity is 48.347480279769584
At time: 430.73668003082275 and batch: 1350, loss is 3.785712628364563 and perplexity is 44.06706281081874
At time: 431.55509519577026 and batch: 1400, loss is 3.8040569496154784 and perplexity is 44.88290330934277
At time: 432.3733868598938 and batch: 1450, loss is 3.720266261100769 and perplexity is 41.275382674457624
At time: 433.1911475658417 and batch: 1500, loss is 3.749041533470154 and perplexity is 42.48034649108235
At time: 434.00905680656433 and batch: 1550, loss is 3.744278545379639 and perplexity is 42.2784941983002
At time: 434.8274862766266 and batch: 1600, loss is 3.8299193477630613 and perplexity is 46.0588233372762
At time: 435.64518761634827 and batch: 1650, loss is 3.7854217720031738 and perplexity is 44.054247489071756
At time: 436.4624936580658 and batch: 1700, loss is 3.804119234085083 and perplexity is 44.88569890422987
At time: 437.2808644771576 and batch: 1750, loss is 3.7772804403305056 and perplexity is 43.697043280635164
At time: 438.0988733768463 and batch: 1800, loss is 3.7488650465011597 and perplexity is 42.472849925030886
At time: 438.91711807250977 and batch: 1850, loss is 3.7916337490081786 and perplexity is 44.328763221389416
At time: 439.7345836162567 and batch: 1900, loss is 3.8598074102401734 and perplexity is 47.4562109084411
At time: 440.5527768135071 and batch: 1950, loss is 3.789242691993713 and perplexity is 44.22289723738582
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341904467205668 and perplexity of 76.8537655286882
finished 13 epochs...
Completing Train Step...
At time: 443.31341314315796 and batch: 50, loss is 3.9185481023788453 and perplexity is 50.32732158872475
At time: 444.17575454711914 and batch: 100, loss is 3.917900342941284 and perplexity is 50.2947321473971
At time: 444.99232363700867 and batch: 150, loss is 3.8860936546325684 and perplexity is 48.720196401966625
At time: 445.8131694793701 and batch: 200, loss is 3.883371338844299 and perplexity is 48.58774501114997
At time: 446.6355700492859 and batch: 250, loss is 3.871926188468933 and perplexity is 48.034821147161324
At time: 447.4542989730835 and batch: 300, loss is 3.865966057777405 and perplexity is 47.74937881715982
At time: 448.2790849208832 and batch: 350, loss is 3.886867742538452 and perplexity is 48.75792471740608
At time: 449.1014189720154 and batch: 400, loss is 3.844144892692566 and perplexity is 46.71871774853992
At time: 449.9199035167694 and batch: 450, loss is 3.8867908334732055 and perplexity is 48.75417493519067
At time: 450.73792457580566 and batch: 500, loss is 3.909611678123474 and perplexity is 49.87957888048222
At time: 451.58359265327454 and batch: 550, loss is 3.8773245716094973 and perplexity is 48.294832705358765
At time: 452.4022283554077 and batch: 600, loss is 3.857947368621826 and perplexity is 47.368022423654196
At time: 453.2206332683563 and batch: 650, loss is 3.899726037979126 and perplexity is 49.38891656452287
At time: 454.03897881507874 and batch: 700, loss is 3.9158677864074707 and perplexity is 50.19260908156516
At time: 454.8575518131256 and batch: 750, loss is 3.883582673072815 and perplexity is 48.59801434985039
At time: 455.68278527259827 and batch: 800, loss is 3.866540541648865 and perplexity is 47.77681794607638
At time: 456.5014591217041 and batch: 850, loss is 3.87426043510437 and perplexity is 48.147077232531814
At time: 457.3194377422333 and batch: 900, loss is 3.837567753791809 and perplexity is 46.412450537696486
At time: 458.14824318885803 and batch: 950, loss is 3.94120641708374 and perplexity is 51.48067101301042
At time: 458.9668800830841 and batch: 1000, loss is 3.900180449485779 and perplexity is 49.41136455643756
At time: 459.7850852012634 and batch: 1050, loss is 3.8450930166244506 and perplexity is 46.76303388818076
At time: 460.6107888221741 and batch: 1100, loss is 3.8649841260910036 and perplexity is 47.70251520129341
At time: 461.4294581413269 and batch: 1150, loss is 3.8350044870376587 and perplexity is 46.29363538876976
At time: 462.2472069263458 and batch: 1200, loss is 3.895861053466797 and perplexity is 49.19839758054746
At time: 463.06593918800354 and batch: 1250, loss is 3.8801539611816405 and perplexity is 48.43167109467193
At time: 463.8842468261719 and batch: 1300, loss is 3.8735671615600586 and perplexity is 48.11370970539893
At time: 464.7026000022888 and batch: 1350, loss is 3.7812035417556764 and perplexity is 43.86880791815383
At time: 465.52016043663025 and batch: 1400, loss is 3.8001880073547363 and perplexity is 44.70958943482164
At time: 466.33818531036377 and batch: 1450, loss is 3.7172964572906495 and perplexity is 41.152984724635516
At time: 467.16174244880676 and batch: 1500, loss is 3.7464444828033447 and perplexity is 42.37016601297107
At time: 467.98058009147644 and batch: 1550, loss is 3.742030005455017 and perplexity is 42.183536114672
At time: 468.8046324253082 and batch: 1600, loss is 3.828028326034546 and perplexity is 45.9718074019982
At time: 469.62413144111633 and batch: 1650, loss is 3.7838642454147338 and perplexity is 43.98568523490109
At time: 470.44218349456787 and batch: 1700, loss is 3.803839797973633 and perplexity is 44.873157971344725
At time: 471.2605814933777 and batch: 1750, loss is 3.777235026359558 and perplexity is 43.69505886944147
At time: 472.0793764591217 and batch: 1800, loss is 3.7493089246749878 and perplexity is 42.49170688087883
At time: 472.8976356983185 and batch: 1850, loss is 3.7926454305648805 and perplexity is 44.373632506459
At time: 473.7169268131256 and batch: 1900, loss is 3.8611970806121825 and perplexity is 47.522205243273696
At time: 474.5350937843323 and batch: 1950, loss is 3.7903972482681274 and perplexity is 44.27398454677587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341256359011628 and perplexity of 76.80397211101015
finished 14 epochs...
Completing Train Step...
At time: 477.3245339393616 and batch: 50, loss is 3.908942666053772 and perplexity is 49.84622000017051
At time: 478.14474391937256 and batch: 100, loss is 3.9077526998519896 and perplexity is 49.78693996070055
At time: 478.96480798721313 and batch: 150, loss is 3.8755792951583863 and perplexity is 48.21061838114254
At time: 479.785564661026 and batch: 200, loss is 3.8729544401168825 and perplexity is 48.08423843351383
At time: 480.6056475639343 and batch: 250, loss is 3.8610696315765383 and perplexity is 47.51614896998505
At time: 481.4258463382721 and batch: 300, loss is 3.855633997917175 and perplexity is 47.258569279903426
At time: 482.25890922546387 and batch: 350, loss is 3.8764668560028075 and perplexity is 48.25342723322315
At time: 483.0803918838501 and batch: 400, loss is 3.8335869407653806 and perplexity is 46.22805850860627
At time: 483.90112471580505 and batch: 450, loss is 3.8769135093688964 and perplexity is 48.27498460289967
At time: 484.72434520721436 and batch: 500, loss is 3.9002064037323 and perplexity is 49.41264700781665
At time: 485.54860186576843 and batch: 550, loss is 3.8679297161102295 and perplexity is 47.84323440275414
At time: 486.3684341907501 and batch: 600, loss is 3.8490748977661133 and perplexity is 46.94960994627122
At time: 487.18947553634644 and batch: 650, loss is 3.8913200521469116 and perplexity is 48.975494077783345
At time: 488.0094301700592 and batch: 700, loss is 3.90758939743042 and perplexity is 49.778810296657404
At time: 488.83456563949585 and batch: 750, loss is 3.875510869026184 and perplexity is 48.207319627857395
At time: 489.6609938144684 and batch: 800, loss is 3.8590333366394045 and perplexity is 47.419490522358636
At time: 490.4792296886444 and batch: 850, loss is 3.867200345993042 and perplexity is 47.808351700018086
At time: 491.2983949184418 and batch: 900, loss is 3.8305402851104735 and perplexity is 46.087431861995704
At time: 492.11826395988464 and batch: 950, loss is 3.9342675590515137 and perplexity is 51.124690423139306
At time: 492.9659640789032 and batch: 1000, loss is 3.893568253517151 and perplexity is 49.08572471458229
At time: 493.7859983444214 and batch: 1050, loss is 3.839025387763977 and perplexity is 46.48015223248982
At time: 494.6061820983887 and batch: 1100, loss is 3.859024043083191 and perplexity is 47.41904982870566
At time: 495.4376404285431 and batch: 1150, loss is 3.8293483591079713 and perplexity is 46.03253177848903
At time: 496.2574026584625 and batch: 1200, loss is 3.890650792121887 and perplexity is 48.942727703226616
At time: 497.0873291492462 and batch: 1250, loss is 3.875404477119446 and perplexity is 48.20219103202882
At time: 497.9076335430145 and batch: 1300, loss is 3.869321904182434 and perplexity is 47.90988756913141
At time: 498.7276723384857 and batch: 1350, loss is 3.7770377922058107 and perplexity is 43.68644156132408
At time: 499.54805064201355 and batch: 1400, loss is 3.796558713912964 and perplexity is 44.547619311440855
At time: 500.3687176704407 and batch: 1450, loss is 3.714148144721985 and perplexity is 41.02362600328194
At time: 501.18952107429504 and batch: 1500, loss is 3.743495907783508 and perplexity is 42.24541840410115
At time: 502.0100212097168 and batch: 1550, loss is 3.7392794704437256 and perplexity is 42.06766824405523
At time: 502.83176589012146 and batch: 1600, loss is 3.8254660081863405 and perplexity is 45.854163803888866
At time: 503.6525158882141 and batch: 1650, loss is 3.7815164852142336 and perplexity is 43.88253852296594
At time: 504.47634053230286 and batch: 1700, loss is 3.802366404533386 and perplexity is 44.807090838138954
At time: 505.3054418563843 and batch: 1750, loss is 3.775959024429321 and perplexity is 43.6393394465879
At time: 506.12699031829834 and batch: 1800, loss is 3.74829843044281 and perplexity is 42.448790942965964
At time: 506.946186542511 and batch: 1850, loss is 3.7919791555404663 and perplexity is 44.34407731041525
At time: 507.7661876678467 and batch: 1900, loss is 3.8609355878829956 and perplexity is 47.509780156733356
At time: 508.5859031677246 and batch: 1950, loss is 3.7899389266967773 and perplexity is 44.25369747396513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341076092387355 and perplexity of 76.79012816606503
finished 15 epochs...
Completing Train Step...
At time: 511.4022934436798 and batch: 50, loss is 3.9005362367630005 and perplexity is 49.4289476190264
At time: 512.2598915100098 and batch: 100, loss is 3.8990907573699953 and perplexity is 49.35755070763869
At time: 513.082658290863 and batch: 150, loss is 3.8667036056518556 and perplexity is 47.784609260485006
At time: 513.9456202983856 and batch: 200, loss is 3.8640538024902344 and perplexity is 47.658157062496635
At time: 514.7655375003815 and batch: 250, loss is 3.852284803390503 and perplexity is 47.1005558948194
At time: 515.5922281742096 and batch: 300, loss is 3.846919393539429 and perplexity is 46.84851885387008
At time: 516.414882183075 and batch: 350, loss is 3.8677399444580076 and perplexity is 47.834155974555294
At time: 517.2347869873047 and batch: 400, loss is 3.8247974586486815 and perplexity is 45.82351826904855
At time: 518.0546650886536 and batch: 450, loss is 3.868691725730896 and perplexity is 47.87970530147592
At time: 518.874517917633 and batch: 500, loss is 3.89245512008667 and perplexity is 49.031116152389814
At time: 519.6936795711517 and batch: 550, loss is 3.8600941038131715 and perplexity is 47.46981824958282
At time: 520.5135014057159 and batch: 600, loss is 3.8416437530517578 and perplexity is 46.60201371898736
At time: 521.3328325748444 and batch: 650, loss is 3.884066162109375 and perplexity is 48.62151663807865
At time: 522.152745962143 and batch: 700, loss is 3.900620765686035 and perplexity is 49.433125971328685
At time: 522.9723217487335 and batch: 750, loss is 3.868762722015381 and perplexity is 47.88310470332559
At time: 523.7990536689758 and batch: 800, loss is 3.8525730895996095 and perplexity is 47.11413629295182
At time: 524.6289784908295 and batch: 850, loss is 3.8611545181274414 and perplexity is 47.52018262318234
At time: 525.4532220363617 and batch: 900, loss is 3.8243569135665894 and perplexity is 45.80333538949155
At time: 526.2785890102386 and batch: 950, loss is 3.928256769180298 and perplexity is 50.81831236129269
At time: 527.1055612564087 and batch: 1000, loss is 3.8877356815338135 and perplexity is 48.80026199202922
At time: 527.9242286682129 and batch: 1050, loss is 3.8336659479141235 and perplexity is 46.231710999985516
At time: 528.743536233902 and batch: 1100, loss is 3.85375768661499 and perplexity is 47.16998062817271
At time: 529.563309431076 and batch: 1150, loss is 3.8242248249053956 and perplexity is 45.79728568779904
At time: 530.3826522827148 and batch: 1200, loss is 3.885864510536194 and perplexity is 48.709033735565306
At time: 531.2021470069885 and batch: 1250, loss is 3.8709282636642457 and perplexity is 47.98690991752813
At time: 532.0216081142426 and batch: 1300, loss is 3.8654062032699583 and perplexity is 47.722653594017636
At time: 532.8458359241486 and batch: 1350, loss is 3.773091311454773 and perplexity is 43.514373615364924
At time: 533.6664726734161 and batch: 1400, loss is 3.7930378198623655 and perplexity is 44.39104766148185
At time: 534.4876577854156 and batch: 1450, loss is 3.710975184440613 and perplexity is 40.89366595544361
At time: 535.3074104785919 and batch: 1500, loss is 3.7404313468933106 and perplexity is 42.11615291921138
At time: 536.1302442550659 and batch: 1550, loss is 3.7363721799850462 and perplexity is 41.94554292645606
At time: 536.9512259960175 and batch: 1600, loss is 3.8226397609710694 and perplexity is 45.72475156276447
At time: 537.7694616317749 and batch: 1650, loss is 3.778828296661377 and perplexity is 43.764732398717975
At time: 538.588211774826 and batch: 1700, loss is 3.800377597808838 and perplexity is 44.718066749768894
At time: 539.408723115921 and batch: 1750, loss is 3.774105076789856 and perplexity is 43.55850934677136
At time: 540.228803396225 and batch: 1800, loss is 3.7466408157348634 and perplexity is 42.378485488540115
At time: 541.0488741397858 and batch: 1850, loss is 3.7906719636917114 and perplexity is 44.28614896399441
At time: 541.8687355518341 and batch: 1900, loss is 3.8599072742462157 and perplexity is 47.46095031241801
At time: 542.6899499893188 and batch: 1950, loss is 3.788760757446289 and perplexity is 44.201589830220165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341156147801599 and perplexity of 76.79627587766076
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 545.472588300705 and batch: 50, loss is 3.901817588806152 and perplexity is 49.49232409716746
At time: 546.3223376274109 and batch: 100, loss is 3.91486677646637 and perplexity is 50.14239091953773
At time: 547.1478164196014 and batch: 150, loss is 3.886783938407898 and perplexity is 48.7538387731294
At time: 547.96794962883 and batch: 200, loss is 3.888008131980896 and perplexity is 48.813559456594525
At time: 548.7970669269562 and batch: 250, loss is 3.876416664123535 and perplexity is 48.25100536380858
At time: 549.6196205615997 and batch: 300, loss is 3.8653053665161132 and perplexity is 47.717841639159374
At time: 550.4406657218933 and batch: 350, loss is 3.8870810747146605 and perplexity is 48.768327461173975
At time: 551.2610900402069 and batch: 400, loss is 3.8408590602874755 and perplexity is 46.56545979969473
At time: 552.0818855762482 and batch: 450, loss is 3.8870764064788816 and perplexity is 48.76809979965423
At time: 552.9028358459473 and batch: 500, loss is 3.908810658454895 and perplexity is 49.839640354646356
At time: 553.725049495697 and batch: 550, loss is 3.880561046600342 and perplexity is 48.45139093533538
At time: 554.5530955791473 and batch: 600, loss is 3.855703854560852 and perplexity is 47.26187072025071
At time: 555.4098973274231 and batch: 650, loss is 3.896460633277893 and perplexity is 49.22790479155506
At time: 556.2287700176239 and batch: 700, loss is 3.9100260400772093 and perplexity is 49.90025136288794
At time: 557.0516412258148 and batch: 750, loss is 3.8780902576446534 and perplexity is 48.33182554497447
At time: 557.8767786026001 and batch: 800, loss is 3.859789342880249 and perplexity is 47.45535350774349
At time: 558.6963329315186 and batch: 850, loss is 3.8633006763458253 and perplexity is 47.62227797085537
At time: 559.5208191871643 and batch: 900, loss is 3.825919523239136 and perplexity is 45.87496407366849
At time: 560.3424558639526 and batch: 950, loss is 3.9317546558380125 and perplexity is 50.99638030725681
At time: 561.1680808067322 and batch: 1000, loss is 3.891653633117676 and perplexity is 48.9918340958495
At time: 561.9965281486511 and batch: 1050, loss is 3.836017255783081 and perplexity is 46.34054388552367
At time: 562.8194403648376 and batch: 1100, loss is 3.853032102584839 and perplexity is 47.135767257365146
At time: 563.638167142868 and batch: 1150, loss is 3.8250722217559816 and perplexity is 45.836110611191884
At time: 564.457257270813 and batch: 1200, loss is 3.886044030189514 and perplexity is 48.71777874934251
At time: 565.2866015434265 and batch: 1250, loss is 3.868840956687927 and perplexity is 47.886850968884566
At time: 566.1112372875214 and batch: 1300, loss is 3.8609601783752443 and perplexity is 47.51094845997855
At time: 566.944842338562 and batch: 1350, loss is 3.7640582942962646 and perplexity is 43.12307748484614
At time: 567.7980570793152 and batch: 1400, loss is 3.785186414718628 and perplexity is 44.04388022106389
At time: 568.6570725440979 and batch: 1450, loss is 3.7028534698486326 and perplexity is 40.56288434709755
At time: 569.5134353637695 and batch: 1500, loss is 3.7336845636367797 and perplexity is 41.83296075615843
At time: 570.3629994392395 and batch: 1550, loss is 3.730647201538086 and perplexity is 41.70609167788306
At time: 571.1930458545685 and batch: 1600, loss is 3.816745500564575 and perplexity is 45.456030703390255
At time: 572.0180368423462 and batch: 1650, loss is 3.768058433532715 and perplexity is 43.29592126821522
At time: 572.8379278182983 and batch: 1700, loss is 3.78372549533844 and perplexity is 43.979582641096385
At time: 573.6618618965149 and batch: 1750, loss is 3.759890055656433 and perplexity is 42.943704301827154
At time: 574.4852252006531 and batch: 1800, loss is 3.7352997303009032 and perplexity is 41.90058255537052
At time: 575.3045501708984 and batch: 1850, loss is 3.772827343940735 and perplexity is 43.502888750219086
At time: 576.123937368393 and batch: 1900, loss is 3.8415457439422607 and perplexity is 46.59744652093916
At time: 576.942643404007 and batch: 1950, loss is 3.7761986684799194 and perplexity is 43.649798607846144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.329238962572674 and perplexity of 75.8865121117673
finished 17 epochs...
Completing Train Step...
At time: 579.8130476474762 and batch: 50, loss is 3.9019616556167604 and perplexity is 49.49945481208708
At time: 580.6345977783203 and batch: 100, loss is 3.905787591934204 and perplexity is 49.68919931769053
At time: 581.4654095172882 and batch: 150, loss is 3.8713701581954956 and perplexity is 48.008119756503056
At time: 582.2881813049316 and batch: 200, loss is 3.8717377758026124 and perplexity is 48.025771630981254
At time: 583.1055951118469 and batch: 250, loss is 3.861639223098755 and perplexity is 47.54322147500947
At time: 583.9235248565674 and batch: 300, loss is 3.8506045579910277 and perplexity is 47.02148185296557
At time: 584.7401077747345 and batch: 350, loss is 3.8738773679733276 and perplexity is 48.12863720189858
At time: 585.5592226982117 and batch: 400, loss is 3.828144083023071 and perplexity is 45.97712926799577
At time: 586.3766725063324 and batch: 450, loss is 3.875466365814209 and perplexity is 48.205174295030695
At time: 587.2084450721741 and batch: 500, loss is 3.898335189819336 and perplexity is 49.32027182907295
At time: 588.0353291034698 and batch: 550, loss is 3.870414443016052 and perplexity is 47.962259585836534
At time: 588.8537242412567 and batch: 600, loss is 3.846602649688721 and perplexity is 46.83368222343812
At time: 589.6694822311401 and batch: 650, loss is 3.887353286743164 and perplexity is 48.78160459353448
At time: 590.4855482578278 and batch: 700, loss is 3.902427487373352 and perplexity is 49.52251860157824
At time: 591.3022365570068 and batch: 750, loss is 3.8709371662139893 and perplexity is 47.98733712528233
At time: 592.1191694736481 and batch: 800, loss is 3.8527441453933715 and perplexity is 47.12219612825393
At time: 592.9460685253143 and batch: 850, loss is 3.8571820497512816 and perplexity is 47.33178465072747
At time: 593.76331782341 and batch: 900, loss is 3.8206076192855836 and perplexity is 45.63192673759774
At time: 594.5802025794983 and batch: 950, loss is 3.9263739156723023 and perplexity is 50.72271894603243
At time: 595.3975248336792 and batch: 1000, loss is 3.8863155221939087 and perplexity is 48.73100703235011
At time: 596.214905500412 and batch: 1050, loss is 3.831093430519104 and perplexity is 46.11293196530808
At time: 597.0577280521393 and batch: 1100, loss is 3.8481814289093017 and perplexity is 46.90768066598713
At time: 597.874787569046 and batch: 1150, loss is 3.820692090988159 and perplexity is 45.635781506948234
At time: 598.6946716308594 and batch: 1200, loss is 3.8824054527282716 and perplexity is 48.5408374401672
At time: 599.5110795497894 and batch: 1250, loss is 3.865977029800415 and perplexity is 47.7499027273171
At time: 600.3277168273926 and batch: 1300, loss is 3.858332862854004 and perplexity is 47.386286043122
At time: 601.1486072540283 and batch: 1350, loss is 3.7622875022888183 and perplexity is 43.04678305461951
At time: 601.9731476306915 and batch: 1400, loss is 3.7841516876220704 and perplexity is 43.99833039464548
At time: 602.7983281612396 and batch: 1450, loss is 3.7024255084991453 and perplexity is 40.54552871440816
At time: 603.6154170036316 and batch: 1500, loss is 3.7339610958099367 and perplexity is 41.84453051533752
At time: 604.4351074695587 and batch: 1550, loss is 3.731485753059387 and perplexity is 41.741079051814715
At time: 605.2517862319946 and batch: 1600, loss is 3.8178631496429443 and perplexity is 45.50686299525291
At time: 606.069242477417 and batch: 1650, loss is 3.769566521644592 and perplexity is 43.361264591732926
At time: 606.8864569664001 and batch: 1700, loss is 3.785583691596985 and perplexity is 44.06138131246815
At time: 607.7069432735443 and batch: 1750, loss is 3.7625368642807007 and perplexity is 43.057518624652076
At time: 608.5353724956512 and batch: 1800, loss is 3.738512535095215 and perplexity is 42.035417430974526
At time: 609.351226568222 and batch: 1850, loss is 3.7759062576293947 and perplexity is 43.637036799046605
At time: 610.1681339740753 and batch: 1900, loss is 3.844849910736084 and perplexity is 46.751666901031385
At time: 610.9896245002747 and batch: 1950, loss is 3.779297742843628 and perplexity is 43.78528240844419
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328481842750727 and perplexity of 75.8290786739697
finished 18 epochs...
Completing Train Step...
At time: 613.8080749511719 and batch: 50, loss is 3.8989231061935423 and perplexity is 49.34927654980124
At time: 614.6757667064667 and batch: 100, loss is 3.9018855142593383 and perplexity is 49.49568599988908
At time: 615.4976615905762 and batch: 150, loss is 3.8669301986694338 and perplexity is 47.79543814611974
At time: 616.319249868393 and batch: 200, loss is 3.867058687210083 and perplexity is 47.801579706768464
At time: 617.1399691104889 and batch: 250, loss is 3.856775412559509 and perplexity is 47.312541699450506
At time: 618.0133883953094 and batch: 300, loss is 3.845729398727417 and perplexity is 46.7928025171343
At time: 618.8338854312897 and batch: 350, loss is 3.8689943742752075 and perplexity is 47.89419821760684
At time: 619.6552088260651 and batch: 400, loss is 3.823071689605713 and perplexity is 45.74450565814901
At time: 620.4761984348297 and batch: 450, loss is 3.8707113885879516 and perplexity is 47.976503881224396
At time: 621.2967443466187 and batch: 500, loss is 3.893835301399231 and perplexity is 49.0988347038272
At time: 622.1173236370087 and batch: 550, loss is 3.865927467346191 and perplexity is 47.74753618359532
At time: 622.9389495849609 and batch: 600, loss is 3.842560739517212 and perplexity is 46.644766733802776
At time: 623.7609524726868 and batch: 650, loss is 3.8834552335739136 and perplexity is 48.59182143787323
At time: 624.58225274086 and batch: 700, loss is 3.898871650695801 and perplexity is 49.346737323542335
At time: 625.4065763950348 and batch: 750, loss is 3.867767038345337 and perplexity is 47.83545200534493
At time: 626.2279562950134 and batch: 800, loss is 3.8494776821136476 and perplexity is 46.968524323232195
At time: 627.0489385128021 and batch: 850, loss is 3.854168667793274 and perplexity is 47.189370586571954
At time: 627.8697724342346 and batch: 900, loss is 3.8178328323364257 and perplexity is 45.505483370652136
At time: 628.6896424293518 and batch: 950, loss is 3.923611669540405 and perplexity is 50.58280364104229
At time: 629.5092554092407 and batch: 1000, loss is 3.8837502431869506 and perplexity is 48.60615860700975
At time: 630.3288877010345 and batch: 1050, loss is 3.828790211677551 and perplexity is 46.00684600805134
At time: 631.1595540046692 and batch: 1100, loss is 3.846073422431946 and perplexity is 46.808903119737224
At time: 631.9798760414124 and batch: 1150, loss is 3.8186323976516725 and perplexity is 45.54188252662098
At time: 632.8069334030151 and batch: 1200, loss is 3.880668783187866 and perplexity is 48.456611204057474
At time: 633.627249956131 and batch: 1250, loss is 3.864627799987793 and perplexity is 47.68552057793215
At time: 634.4514622688293 and batch: 1300, loss is 3.8570608854293824 and perplexity is 47.326050074556015
At time: 635.2737393379211 and batch: 1350, loss is 3.7613021087646485 and perplexity is 43.004385925719916
At time: 636.093766450882 and batch: 1400, loss is 3.7834949398040774 and perplexity is 43.96944407371584
At time: 636.9150326251984 and batch: 1450, loss is 3.702090620994568 and perplexity is 40.531952796804674
At time: 637.7352514266968 and batch: 1500, loss is 3.733977098464966 and perplexity is 41.84520014428212
At time: 638.5562283992767 and batch: 1550, loss is 3.731753692626953 and perplexity is 41.7522646369491
At time: 639.3768844604492 and batch: 1600, loss is 3.8181528282165527 and perplexity is 45.520047267923225
At time: 640.1971893310547 and batch: 1650, loss is 3.7699104833602903 and perplexity is 43.37618177201913
At time: 641.016988992691 and batch: 1700, loss is 3.7862558555603028 and perplexity is 44.09100774095374
At time: 641.837883234024 and batch: 1750, loss is 3.7635068321228027 and perplexity is 43.099303294695765
At time: 642.658118724823 and batch: 1800, loss is 3.739745683670044 and perplexity is 42.08728531990576
At time: 643.4798605442047 and batch: 1850, loss is 3.777017521858215 and perplexity is 43.68555603094345
At time: 644.3001174926758 and batch: 1900, loss is 3.845995349884033 and perplexity is 46.805248772059635
At time: 645.1218192577362 and batch: 1950, loss is 3.780303816795349 and perplexity is 43.829355807375855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328144588026889 and perplexity of 75.803509270926
finished 19 epochs...
Completing Train Step...
At time: 647.9308195114136 and batch: 50, loss is 3.8960512399673464 and perplexity is 49.207755341447644
At time: 648.7774798870087 and batch: 100, loss is 3.8987153816223143 and perplexity is 49.339026557114046
At time: 649.5952620506287 and batch: 150, loss is 3.8635079288482665 and perplexity is 47.63214882998158
At time: 650.414300441742 and batch: 200, loss is 3.8634807538986204 and perplexity is 47.63085444632307
At time: 651.2319242954254 and batch: 250, loss is 3.8530784034729004 and perplexity is 47.13794973577357
At time: 652.0506100654602 and batch: 300, loss is 3.8421875286102294 and perplexity is 46.627361646190344
At time: 652.8693151473999 and batch: 350, loss is 3.8653912591934203 and perplexity is 47.72194042835854
At time: 653.6877524852753 and batch: 400, loss is 3.819410872459412 and perplexity is 45.57734953816132
At time: 654.5060710906982 and batch: 450, loss is 3.867312412261963 and perplexity is 47.813709703836494
At time: 655.330245256424 and batch: 500, loss is 3.890545654296875 and perplexity is 48.93758224178178
At time: 656.1560990810394 and batch: 550, loss is 3.8626453924179076 and perplexity is 47.59108207968958
At time: 656.9777870178223 and batch: 600, loss is 3.839532833099365 and perplexity is 46.50374435427817
At time: 657.7945339679718 and batch: 650, loss is 3.8805309629440305 and perplexity is 48.449933362267345
At time: 658.6120898723602 and batch: 700, loss is 3.896153573989868 and perplexity is 49.2127912266578
At time: 659.4585785865784 and batch: 750, loss is 3.8652505445480347 and perplexity is 47.7152257248737
At time: 660.2787554264069 and batch: 800, loss is 3.8470387983322145 and perplexity is 46.85411312554093
At time: 661.0995767116547 and batch: 850, loss is 3.851925802230835 and perplexity is 47.083649775471955
At time: 661.9262185096741 and batch: 900, loss is 3.8157019662857055 and perplexity is 45.40862051854877
At time: 662.7555704116821 and batch: 950, loss is 3.921471886634827 and perplexity is 50.474683140947896
At time: 663.5741698741913 and batch: 1000, loss is 3.8817913484573365 and perplexity is 48.51103745566583
At time: 664.3928968906403 and batch: 1050, loss is 3.8270272970199586 and perplexity is 45.92581131448576
At time: 665.2116439342499 and batch: 1100, loss is 3.844397702217102 and perplexity is 46.73053017844534
At time: 666.0310924053192 and batch: 1150, loss is 3.8169627523422243 and perplexity is 45.46590717966761
At time: 666.8493657112122 and batch: 1200, loss is 3.879215130805969 and perplexity is 48.386223307923224
At time: 667.6692440509796 and batch: 1250, loss is 3.8634194803237913 and perplexity is 47.62793602301101
At time: 668.4877822399139 and batch: 1300, loss is 3.855950560569763 and perplexity is 47.27353194613788
At time: 669.3057219982147 and batch: 1350, loss is 3.7603441047668458 and perplexity is 42.96320727988308
At time: 670.1224892139435 and batch: 1400, loss is 3.782774639129639 and perplexity is 43.93778425715731
At time: 670.9390022754669 and batch: 1450, loss is 3.701611361503601 and perplexity is 40.512532127881066
At time: 671.7571499347687 and batch: 1500, loss is 3.7337101125717163 and perplexity is 41.8340295574043
At time: 672.5754764080048 and batch: 1550, loss is 3.7316196298599245 and perplexity is 41.74666758800848
At time: 673.3938426971436 and batch: 1600, loss is 3.8180164432525636 and perplexity is 45.513839441252536
At time: 674.2128496170044 and batch: 1650, loss is 3.7697536325454712 and perplexity is 43.36937871611083
At time: 675.0307743549347 and batch: 1700, loss is 3.7863889598846434 and perplexity is 44.09687683534086
At time: 675.8532390594482 and batch: 1750, loss is 3.763797287940979 and perplexity is 43.11182355630044
At time: 676.6828768253326 and batch: 1800, loss is 3.7402261877059937 and perplexity is 42.10751328978554
At time: 677.5030314922333 and batch: 1850, loss is 3.7774352121353147 and perplexity is 43.70380687428183
At time: 678.3209025859833 and batch: 1900, loss is 3.846448655128479 and perplexity is 46.82647064642568
At time: 679.1394820213318 and batch: 1950, loss is 3.7806544351577758 and perplexity is 43.844725878692415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327953533793605 and perplexity of 75.7890280729731
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdf90580b38>
ELAPSED
2118.180438041687


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}, 'best_accuracy': -75.41513488817796}, {'params': {'wordvec_dim': 300, 'dropout': 0.6309802267622319, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.016023383857180606, 'tune_wordvecs': True}, 'best_accuracy': -76.15677522751027}, {'params': {'wordvec_dim': 300, 'dropout': 0.32978472608712295, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8376966109346161, 'tune_wordvecs': True}, 'best_accuracy': -75.7890280729731}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.29541444939753103, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8777067374849862, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3057520389556885 and batch: 50, loss is 7.353662481307984 and perplexity is 1561.9065185162651
At time: 2.1421473026275635 and batch: 100, loss is 6.605088624954224 and perplexity is 738.8453464451995
At time: 3.0014073848724365 and batch: 150, loss is 6.31787540435791 and perplexity is 554.3938775075477
At time: 3.820176601409912 and batch: 200, loss is 6.131226396560669 and perplexity is 459.9999572556648
At time: 4.637503623962402 and batch: 250, loss is 6.021630182266235 and perplexity is 412.2500910357457
At time: 5.454090356826782 and batch: 300, loss is 5.921154651641846 and perplexity is 372.841968022078
At time: 6.271027565002441 and batch: 350, loss is 5.828503484725952 and perplexity is 339.8497080463091
At time: 7.089551687240601 and batch: 400, loss is 5.755867443084717 and perplexity is 316.0395749992332
At time: 7.911900758743286 and batch: 450, loss is 5.6613095760345455 and perplexity is 287.5249318726558
At time: 8.739680290222168 and batch: 500, loss is 5.6160095596313475 and perplexity is 274.7906567618498
At time: 9.558520317077637 and batch: 550, loss is 5.559879922866822 and perplexity is 259.791639414686
At time: 10.376936912536621 and batch: 600, loss is 5.572733039855957 and perplexity is 263.1523231132352
At time: 11.203081846237183 and batch: 650, loss is 5.628313722610474 and perplexity is 278.1926119744007
At time: 12.021828174591064 and batch: 700, loss is 5.565452318191529 and perplexity is 261.2433421057316
At time: 12.849157333374023 and batch: 750, loss is 5.5030614852905275 and perplexity is 245.44220089774782
At time: 13.676070928573608 and batch: 800, loss is 5.485045900344849 and perplexity is 241.0600084816122
At time: 14.501521110534668 and batch: 850, loss is 5.496356306076049 and perplexity is 243.80197211321675
At time: 15.322052001953125 and batch: 900, loss is 5.497401447296142 and perplexity is 244.0569128051187
At time: 16.146857261657715 and batch: 950, loss is 5.531492385864258 and perplexity is 252.5204879612391
At time: 16.975982427597046 and batch: 1000, loss is 5.494261999130249 and perplexity is 243.29191024910526
At time: 17.80008840560913 and batch: 1050, loss is 5.384058303833008 and perplexity is 217.9048073372116
At time: 18.62577176094055 and batch: 1100, loss is 5.4704752540588375 and perplexity is 237.57307350297955
At time: 19.451308488845825 and batch: 1150, loss is 5.366602401733399 and perplexity is 214.1340887475917
At time: 20.273919105529785 and batch: 1200, loss is 5.4449351978302 and perplexity is 231.58227219214461
At time: 21.092172145843506 and batch: 1250, loss is 5.396088647842407 and perplexity is 220.54210914699425
At time: 21.910987615585327 and batch: 1300, loss is 5.409160223007202 and perplexity is 223.4438658516177
At time: 22.729639053344727 and batch: 1350, loss is 5.353522233963012 and perplexity is 211.35141751868122
At time: 23.54828715324402 and batch: 1400, loss is 5.357166681289673 and perplexity is 212.12308191826872
At time: 24.37328577041626 and batch: 1450, loss is 5.315505952835083 and perplexity is 203.46743201467604
At time: 25.19250249862671 and batch: 1500, loss is 5.284777307510376 and perplexity is 197.31023904693316
At time: 26.021617889404297 and batch: 1550, loss is 5.269325571060181 and perplexity is 194.28488689949592
At time: 26.851842403411865 and batch: 1600, loss is 5.317218255996704 and perplexity is 203.81612839356015
At time: 27.670747756958008 and batch: 1650, loss is 5.2959737300872805 and perplexity is 199.531821542195
At time: 28.490084886550903 and batch: 1700, loss is 5.3149081993103025 and perplexity is 203.34584498316994
At time: 29.318300008773804 and batch: 1750, loss is 5.320634450912475 and perplexity is 204.5135946772081
At time: 30.155405044555664 and batch: 1800, loss is 5.287262229919434 and perplexity is 197.80114936589592
At time: 30.98013949394226 and batch: 1850, loss is 5.273588056564331 and perplexity is 195.11479088390382
At time: 31.811720371246338 and batch: 1900, loss is 5.318126564025879 and perplexity is 204.0013403214622
At time: 32.63329863548279 and batch: 1950, loss is 5.240032262802124 and perplexity is 188.67618953003995
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.856686614280523 and perplexity of 128.5974026247731
finished 1 epochs...
Completing Train Step...
At time: 35.41040229797363 and batch: 50, loss is 5.058509483337402 and perplexity is 157.35580000066912
At time: 36.2244234085083 and batch: 100, loss is 5.0130923557281495 and perplexity is 150.36901240224304
At time: 37.0400173664093 and batch: 150, loss is 4.954699192047119 and perplexity is 141.83993337509636
At time: 37.86113095283508 and batch: 200, loss is 4.918680953979492 and perplexity is 136.82201956657832
At time: 38.68583154678345 and batch: 250, loss is 4.923832025527954 and perplexity is 137.5286178856408
At time: 39.50199294090271 and batch: 300, loss is 4.930709943771363 and perplexity is 138.47778889411657
At time: 40.31718063354492 and batch: 350, loss is 4.92804967880249 and perplexity is 138.10989085345764
At time: 41.132277488708496 and batch: 400, loss is 4.875987529754639 and perplexity is 131.1035579692111
At time: 41.956305503845215 and batch: 450, loss is 4.858582086563111 and perplexity is 128.84138659643983
At time: 42.779648780822754 and batch: 500, loss is 4.853613986968994 and perplexity is 128.20287715853195
At time: 43.60740089416504 and batch: 550, loss is 4.808981075286865 and perplexity is 122.60662692790785
At time: 44.42611503601074 and batch: 600, loss is 4.802457695007324 and perplexity is 121.80942034357876
At time: 45.242937326431274 and batch: 650, loss is 4.870457372665405 and perplexity is 130.38053575455652
At time: 46.095569133758545 and batch: 700, loss is 4.875172529220581 and perplexity is 130.9967520288105
At time: 46.92060971260071 and batch: 750, loss is 4.832586803436279 and perplexity is 125.53527608733671
At time: 47.74251985549927 and batch: 800, loss is 4.811059484481811 and perplexity is 122.86171866935823
At time: 48.56644654273987 and batch: 850, loss is 4.805573253631592 and perplexity is 122.18951653216973
At time: 49.38724946975708 and batch: 900, loss is 4.801903142929077 and perplexity is 121.74188940281955
At time: 50.20724678039551 and batch: 950, loss is 4.8664717102050785 and perplexity is 129.86191715353002
At time: 51.02759265899658 and batch: 1000, loss is 4.834311504364013 and perplexity is 125.75197371004774
At time: 51.84770059585571 and batch: 1050, loss is 4.74345700263977 and perplexity is 114.83048560006432
At time: 52.682775259017944 and batch: 1100, loss is 4.816597032546997 and perplexity is 123.54395856659819
At time: 53.506985664367676 and batch: 1150, loss is 4.748439979553223 and perplexity is 115.40411125353467
At time: 54.328025579452515 and batch: 1200, loss is 4.8287864017486575 and perplexity is 125.0590970212247
At time: 55.156373500823975 and batch: 1250, loss is 4.8014867305755615 and perplexity is 121.69120512964305
At time: 55.976797580718994 and batch: 1300, loss is 4.813415899276733 and perplexity is 123.1515732156081
At time: 56.80535078048706 and batch: 1350, loss is 4.710805854797363 and perplexity is 111.14168788994957
At time: 57.626062631607056 and batch: 1400, loss is 4.718211030960083 and perplexity is 111.96776652174881
At time: 58.44646644592285 and batch: 1450, loss is 4.6570658874511714 and perplexity is 105.32658826938025
At time: 59.26586437225342 and batch: 1500, loss is 4.661575860977173 and perplexity is 105.80268117027703
At time: 60.085171699523926 and batch: 1550, loss is 4.663359289169311 and perplexity is 105.99154101360685
At time: 60.90979337692261 and batch: 1600, loss is 4.726376543045044 and perplexity is 112.88578361145662
At time: 61.737608671188354 and batch: 1650, loss is 4.6896779918670655 and perplexity is 108.81813384106813
At time: 62.56145620346069 and batch: 1700, loss is 4.711863050460815 and perplexity is 111.25924853176649
At time: 63.39128255844116 and batch: 1750, loss is 4.717808961868286 and perplexity is 111.92275679266973
At time: 64.22357249259949 and batch: 1800, loss is 4.6672124099731445 and perplexity is 106.40072704066384
At time: 65.04443359375 and batch: 1850, loss is 4.686943731307983 and perplexity is 108.52100311112835
At time: 65.87417984008789 and batch: 1900, loss is 4.773952169418335 and perplexity is 118.38620092523968
At time: 66.69425392150879 and batch: 1950, loss is 4.697908487319946 and perplexity is 109.7174568570832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.599925338390261 and perplexity of 99.47688826005783
finished 2 epochs...
Completing Train Step...
At time: 69.46741461753845 and batch: 50, loss is 4.652480211257934 and perplexity is 104.84470037640283
At time: 70.3136043548584 and batch: 100, loss is 4.622967863082886 and perplexity is 101.79569995360585
At time: 71.13271498680115 and batch: 150, loss is 4.574585599899292 and perplexity is 96.98783903778134
At time: 71.9510087966919 and batch: 200, loss is 4.567975111007691 and perplexity is 96.34881645806307
At time: 72.77909994125366 and batch: 250, loss is 4.565959901809692 and perplexity is 96.15484894512154
At time: 73.60574698448181 and batch: 300, loss is 4.585840978622437 and perplexity is 98.08564039327712
At time: 74.42977356910706 and batch: 350, loss is 4.591672630310058 and perplexity is 98.65931278660402
At time: 75.24840688705444 and batch: 400, loss is 4.551737718582153 and perplexity is 94.79699577125085
At time: 76.0722815990448 and batch: 450, loss is 4.5627037715911865 and perplexity is 95.84226541832668
At time: 76.89676427841187 and batch: 500, loss is 4.568304500579834 and perplexity is 96.38055798086901
At time: 77.71796035766602 and batch: 550, loss is 4.523132047653198 and perplexity is 92.12368235878617
At time: 78.53642845153809 and batch: 600, loss is 4.511933736801147 and perplexity is 91.09780748034417
At time: 79.35508155822754 and batch: 650, loss is 4.584014301300049 and perplexity is 97.9066331223552
At time: 80.17846131324768 and batch: 700, loss is 4.594470233917236 and perplexity is 98.9357088790203
At time: 81.00888514518738 and batch: 750, loss is 4.562241163253784 and perplexity is 95.79793824112002
At time: 81.83507084846497 and batch: 800, loss is 4.542368726730347 and perplexity is 93.91299107303972
At time: 82.6593120098114 and batch: 850, loss is 4.537970914840698 and perplexity is 93.50088624825646
At time: 83.47807192802429 and batch: 900, loss is 4.527847681045532 and perplexity is 92.55912976979079
At time: 84.29648065567017 and batch: 950, loss is 4.607465829849243 and perplexity is 100.22982808690112
At time: 85.1145510673523 and batch: 1000, loss is 4.577811632156372 and perplexity is 97.30123016821383
At time: 85.93211388587952 and batch: 1050, loss is 4.49796085357666 and perplexity is 89.83376021297956
At time: 86.74949169158936 and batch: 1100, loss is 4.563416442871094 and perplexity is 95.91059379323477
At time: 87.59549403190613 and batch: 1150, loss is 4.512013750076294 and perplexity is 91.10509680589688
At time: 88.41456246376038 and batch: 1200, loss is 4.588945255279541 and perplexity is 98.39059844933972
At time: 89.23400139808655 and batch: 1250, loss is 4.572605895996094 and perplexity is 96.79602176762265
At time: 90.05318069458008 and batch: 1300, loss is 4.579487247467041 and perplexity is 97.46440627123994
At time: 90.87810945510864 and batch: 1350, loss is 4.465265970230103 and perplexity is 86.94415102065635
At time: 91.69945025444031 and batch: 1400, loss is 4.476482629776001 and perplexity is 87.92486384085325
At time: 92.51847839355469 and batch: 1450, loss is 4.413636589050293 and perplexity is 82.56918839216115
At time: 93.33754777908325 and batch: 1500, loss is 4.428295822143554 and perplexity is 83.78850465664668
At time: 94.1565535068512 and batch: 1550, loss is 4.435066404342652 and perplexity is 84.35772642167613
At time: 94.97581696510315 and batch: 1600, loss is 4.507685108184814 and perplexity is 90.7115877616384
At time: 95.79448127746582 and batch: 1650, loss is 4.46493239402771 and perplexity is 86.91515335767265
At time: 96.61401057243347 and batch: 1700, loss is 4.487502317428589 and perplexity is 88.89912655367698
At time: 97.43341493606567 and batch: 1750, loss is 4.494201574325562 and perplexity is 89.49668400093614
At time: 98.25224542617798 and batch: 1800, loss is 4.447366857528687 and perplexity is 85.40177264349458
At time: 99.07126498222351 and batch: 1850, loss is 4.477125339508056 and perplexity is 87.98139217024126
At time: 99.89012384414673 and batch: 1900, loss is 4.567418823242187 and perplexity is 96.29523369534618
At time: 100.70797848701477 and batch: 1950, loss is 4.496081409454345 and perplexity is 89.66508124136493
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.537241949037064 and perplexity of 93.432752136308
finished 3 epochs...
Completing Train Step...
At time: 103.48397374153137 and batch: 50, loss is 4.458697938919068 and perplexity is 86.3749703588029
At time: 104.30256366729736 and batch: 100, loss is 4.431334781646728 and perplexity is 84.04352182629253
At time: 105.13107538223267 and batch: 150, loss is 4.3895516777038575 and perplexity is 80.60427418554191
At time: 105.9494526386261 and batch: 200, loss is 4.390153112411499 and perplexity is 80.6527669747829
At time: 106.76797437667847 and batch: 250, loss is 4.385072851181031 and perplexity is 80.24406887515504
At time: 107.58657789230347 and batch: 300, loss is 4.399756116867065 and perplexity is 81.43100659404834
At time: 108.40574145317078 and batch: 350, loss is 4.411939325332642 and perplexity is 82.4291655659522
At time: 109.2700982093811 and batch: 400, loss is 4.369497900009155 and perplexity is 79.00395385476808
At time: 110.09064865112305 and batch: 450, loss is 4.39884162902832 and perplexity is 81.35657296833139
At time: 110.9191381931305 and batch: 500, loss is 4.407436075210572 and perplexity is 82.05880096416745
At time: 111.73826837539673 and batch: 550, loss is 4.365025491714477 and perplexity is 78.65140487537853
At time: 112.56806254386902 and batch: 600, loss is 4.354558992385864 and perplexity is 77.83249304492344
At time: 113.40253782272339 and batch: 650, loss is 4.425242052078247 and perplexity is 83.53302411726162
At time: 114.22717261314392 and batch: 700, loss is 4.438610010147094 and perplexity is 84.65718722282591
At time: 115.0487813949585 and batch: 750, loss is 4.407083005905151 and perplexity is 82.0298336343458
At time: 115.87393474578857 and batch: 800, loss is 4.38849910736084 and perplexity is 80.51947715226386
At time: 116.7047917842865 and batch: 850, loss is 4.3816652011871335 and perplexity is 79.97109054579728
At time: 117.53448867797852 and batch: 900, loss is 4.3708773040771485 and perplexity is 79.11300742728183
At time: 118.35584163665771 and batch: 950, loss is 4.458764057159424 and perplexity is 86.38068150865737
At time: 119.17503118515015 and batch: 1000, loss is 4.422684564590454 and perplexity is 83.31966240451484
At time: 119.99378538131714 and batch: 1050, loss is 4.359081172943116 and perplexity is 78.18526267449214
At time: 120.81243348121643 and batch: 1100, loss is 4.4138530731201175 and perplexity is 82.58706524106306
At time: 121.63369989395142 and batch: 1150, loss is 4.370709505081177 and perplexity is 79.09973345777775
At time: 122.45476412773132 and batch: 1200, loss is 4.442419099807739 and perplexity is 84.98026897241449
At time: 123.28097939491272 and batch: 1250, loss is 4.4315508937835695 and perplexity is 84.06168661412693
At time: 124.11239862442017 and batch: 1300, loss is 4.434040336608887 and perplexity is 84.27121407185659
At time: 124.94100952148438 and batch: 1350, loss is 4.321963639259338 and perplexity is 75.3364166884539
At time: 125.76773309707642 and batch: 1400, loss is 4.332684297561645 and perplexity is 76.14841748393292
At time: 126.58582472801208 and batch: 1450, loss is 4.265885348320007 and perplexity is 71.22795361498386
At time: 127.40376734733582 and batch: 1500, loss is 4.2855269765853885 and perplexity is 72.64081664470682
At time: 128.22322463989258 and batch: 1550, loss is 4.295657291412353 and perplexity is 73.38043092423054
At time: 129.0479154586792 and batch: 1600, loss is 4.373047780990601 and perplexity is 79.28490686785571
At time: 129.87124228477478 and batch: 1650, loss is 4.328519258499146 and perplexity is 75.83191592877887
At time: 130.7006814479828 and batch: 1700, loss is 4.352575712203979 and perplexity is 77.6782823759902
At time: 131.52268815040588 and batch: 1750, loss is 4.358239965438843 and perplexity is 78.11952030017291
At time: 132.3490071296692 and batch: 1800, loss is 4.318747577667236 and perplexity is 75.09451931917123
At time: 133.17430233955383 and batch: 1850, loss is 4.346689710617065 and perplexity is 77.22241082911947
At time: 133.99807333946228 and batch: 1900, loss is 4.434666576385498 and perplexity is 84.3240045861664
At time: 134.81750679016113 and batch: 1950, loss is 4.363079814910889 and perplexity is 78.49852343850532
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.501567609920058 and perplexity of 90.15835371042903
finished 4 epochs...
Completing Train Step...
At time: 137.5649173259735 and batch: 50, loss is 4.330441913604736 and perplexity is 75.97785479920672
At time: 138.4123785495758 and batch: 100, loss is 4.308230381011963 and perplexity is 74.30887412602169
At time: 139.2379596233368 and batch: 150, loss is 4.270297231674195 and perplexity is 71.54289727437762
At time: 140.05683422088623 and batch: 200, loss is 4.271420879364014 and perplexity is 71.62333146700738
At time: 140.87549328804016 and batch: 250, loss is 4.266499104499817 and perplexity is 71.27168363010104
At time: 141.69453811645508 and batch: 300, loss is 4.278923592567444 and perplexity is 72.16272169655807
At time: 142.51361227035522 and batch: 350, loss is 4.293627805709839 and perplexity is 73.23165740675299
At time: 143.3320746421814 and batch: 400, loss is 4.249564228057861 and perplexity is 70.07486903043855
At time: 144.1507225036621 and batch: 450, loss is 4.289043951034546 and perplexity is 72.89674231904327
At time: 144.96848249435425 and batch: 500, loss is 4.301197776794433 and perplexity is 73.78812249077166
At time: 145.78633093833923 and batch: 550, loss is 4.2583336353302 and perplexity is 70.69208645655618
At time: 146.60482096672058 and batch: 600, loss is 4.25085832118988 and perplexity is 70.16561113888399
At time: 147.42867350578308 and batch: 650, loss is 4.3144269371032715 and perplexity is 74.77076281426866
At time: 148.26302003860474 and batch: 700, loss is 4.332173891067505 and perplexity is 76.10956075433778
At time: 149.09696197509766 and batch: 750, loss is 4.298060340881348 and perplexity is 73.55697977264688
At time: 149.92252111434937 and batch: 800, loss is 4.283215675354004 and perplexity is 72.4731157140873
At time: 150.78199672698975 and batch: 850, loss is 4.2769106578826905 and perplexity is 72.01760895134649
At time: 151.61105108261108 and batch: 900, loss is 4.2648776292800905 and perplexity is 71.15621200371666
At time: 152.44127488136292 and batch: 950, loss is 4.3571876049041744 and perplexity is 78.03735364207894
At time: 153.26194047927856 and batch: 1000, loss is 4.317696046829224 and perplexity is 75.01559661844043
At time: 154.08365631103516 and batch: 1050, loss is 4.260773658752441 and perplexity is 70.86478741478449
At time: 154.90441274642944 and batch: 1100, loss is 4.310200462341308 and perplexity is 74.45541295084764
At time: 155.73163747787476 and batch: 1150, loss is 4.269614782333374 and perplexity is 71.49408952759391
At time: 156.5535273551941 and batch: 1200, loss is 4.342496604919433 and perplexity is 76.89928701786776
At time: 157.3726179599762 and batch: 1250, loss is 4.331792593002319 and perplexity is 76.08054585809343
At time: 158.19228839874268 and batch: 1300, loss is 4.333929691314697 and perplexity is 76.24331132520572
At time: 159.0111312866211 and batch: 1350, loss is 4.224329700469971 and perplexity is 68.32868750791424
At time: 159.83013606071472 and batch: 1400, loss is 4.232668552398682 and perplexity is 68.90085259999303
At time: 160.64851808547974 and batch: 1450, loss is 4.1663044691085815 and perplexity is 64.4767355189298
At time: 161.4704074859619 and batch: 1500, loss is 4.184212760925293 and perplexity is 65.64180477714216
At time: 162.29795622825623 and batch: 1550, loss is 4.194658308029175 and perplexity is 66.33106291305145
At time: 163.1165952682495 and batch: 1600, loss is 4.281307535171509 and perplexity is 72.33495870323371
At time: 163.9384641647339 and batch: 1650, loss is 4.23424943447113 and perplexity is 69.00986286612941
At time: 164.75687623023987 and batch: 1700, loss is 4.255126042366028 and perplexity is 70.46569829205966
At time: 165.5755579471588 and batch: 1750, loss is 4.26356752872467 and perplexity is 71.06305124915195
At time: 166.39347791671753 and batch: 1800, loss is 4.22048189163208 and perplexity is 68.06627695682138
At time: 167.2108597755432 and batch: 1850, loss is 4.253581733703613 and perplexity is 70.35696148698956
At time: 168.0291714668274 and batch: 1900, loss is 4.337527294158935 and perplexity is 76.51809847001529
At time: 168.84731888771057 and batch: 1950, loss is 4.265085477828979 and perplexity is 71.17100325624297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486869208757267 and perplexity of 88.84286155859039
finished 5 epochs...
Completing Train Step...
At time: 171.64125204086304 and batch: 50, loss is 4.2422790575027465 and perplexity is 69.56621671702285
At time: 172.46601843833923 and batch: 100, loss is 4.220218195915222 and perplexity is 68.04833053742637
At time: 173.29896783828735 and batch: 150, loss is 4.182425394058227 and perplexity is 65.52458358003803
At time: 174.1221170425415 and batch: 200, loss is 4.186496877670288 and perplexity is 65.79190968591269
At time: 174.95280075073242 and batch: 250, loss is 4.17646445274353 and perplexity is 65.13515720963508
At time: 175.77301049232483 and batch: 300, loss is 4.192668843269348 and perplexity is 66.19923078207576
At time: 176.6039581298828 and batch: 350, loss is 4.207955479621887 and perplexity is 67.2189686732933
At time: 177.42465496063232 and batch: 400, loss is 4.1579923343658445 and perplexity is 63.94301744673869
At time: 178.2456295490265 and batch: 450, loss is 4.2030907201766965 and perplexity is 66.89275867047718
At time: 179.07216215133667 and batch: 500, loss is 4.217055249214172 and perplexity is 67.8334373218881
At time: 179.89729285240173 and batch: 550, loss is 4.176500110626221 and perplexity is 65.13747983283959
At time: 180.72061824798584 and batch: 600, loss is 4.171968302726746 and perplexity is 64.84295715134628
At time: 181.54898405075073 and batch: 650, loss is 4.228010907173156 and perplexity is 68.58068306969197
At time: 182.38171792030334 and batch: 700, loss is 4.250800876617432 and perplexity is 70.16158062111835
At time: 183.20897126197815 and batch: 750, loss is 4.219799761772156 and perplexity is 68.01986274891357
At time: 184.03094363212585 and batch: 800, loss is 4.205301871299744 and perplexity is 67.04083231520806
At time: 184.85154724121094 and batch: 850, loss is 4.200140285491943 and perplexity is 66.69568682190592
At time: 185.67263388633728 and batch: 900, loss is 4.1829558372497555 and perplexity is 65.5593498692313
At time: 186.4989755153656 and batch: 950, loss is 4.2765418148040775 and perplexity is 71.99105065296989
At time: 187.32000875473022 and batch: 1000, loss is 4.240838174819946 and perplexity is 69.46605214007921
At time: 188.14511585235596 and batch: 1050, loss is 4.183126015663147 and perplexity is 65.57050760475094
At time: 188.96519231796265 and batch: 1100, loss is 4.228447508811951 and perplexity is 68.61063204572011
At time: 189.79502296447754 and batch: 1150, loss is 4.192541127204895 and perplexity is 66.1907766167283
At time: 190.62389373779297 and batch: 1200, loss is 4.264755668640137 and perplexity is 71.1475342757454
At time: 191.44783329963684 and batch: 1250, loss is 4.255328903198242 and perplexity is 70.47999447227622
At time: 192.2693645954132 and batch: 1300, loss is 4.254619903564453 and perplexity is 70.43004189227894
At time: 193.09163522720337 and batch: 1350, loss is 4.150933394432068 and perplexity is 63.49323688205348
At time: 193.91141653060913 and batch: 1400, loss is 4.15770465373993 and perplexity is 63.92462492516964
At time: 194.73199701309204 and batch: 1450, loss is 4.089393501281738 and perplexity is 59.70367052155825
At time: 195.55298376083374 and batch: 1500, loss is 4.107628827095032 and perplexity is 60.80237356420239
At time: 196.38286232948303 and batch: 1550, loss is 4.119024171829223 and perplexity is 61.499200321729305
At time: 197.20697498321533 and batch: 1600, loss is 4.207200965881348 and perplexity is 67.16827016656957
At time: 198.03797316551208 and batch: 1650, loss is 4.162647128105164 and perplexity is 64.24135281014208
At time: 198.85869455337524 and batch: 1700, loss is 4.184928932189941 and perplexity is 65.68883238938542
At time: 199.67955923080444 and batch: 1750, loss is 4.190234866142273 and perplexity is 66.0382992997455
At time: 200.50028681755066 and batch: 1800, loss is 4.144987654685974 and perplexity is 63.11684269969186
At time: 201.3312394618988 and batch: 1850, loss is 4.179540376663208 and perplexity is 65.33581644577207
At time: 202.15637516975403 and batch: 1900, loss is 4.261837296485901 and perplexity is 70.94020197642926
At time: 202.98146200180054 and batch: 1950, loss is 4.190970449447632 and perplexity is 66.0868938407001
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.478673464752907 and perplexity of 88.117703871105
finished 6 epochs...
Completing Train Step...
At time: 205.73165464401245 and batch: 50, loss is 4.173476343154907 and perplexity is 64.94081672176038
At time: 206.5760748386383 and batch: 100, loss is 4.154331293106079 and perplexity is 63.70934742039033
At time: 207.39254784584045 and batch: 150, loss is 4.1130708360672 and perplexity is 61.13416260730255
At time: 208.20985078811646 and batch: 200, loss is 4.119814453125 and perplexity is 61.547821199003224
At time: 209.02825498580933 and batch: 250, loss is 4.111938991546631 and perplexity is 61.0650073841988
At time: 209.85612177848816 and batch: 300, loss is 4.125671048164367 and perplexity is 61.90933946302681
At time: 210.6871690750122 and batch: 350, loss is 4.138175454139709 and perplexity is 62.688339292043864
At time: 211.51447248458862 and batch: 400, loss is 4.089931330680847 and perplexity is 59.73578954730338
At time: 212.3333239555359 and batch: 450, loss is 4.138353776931763 and perplexity is 62.69951904850869
At time: 213.15144801139832 and batch: 500, loss is 4.15583767414093 and perplexity is 63.805390293506846
At time: 213.9967794418335 and batch: 550, loss is 4.111366138458252 and perplexity is 61.03003612378052
At time: 214.82166194915771 and batch: 600, loss is 4.108964147567749 and perplexity is 60.88361845032019
At time: 215.64553689956665 and batch: 650, loss is 4.1637372875213625 and perplexity is 64.31142431343227
At time: 216.47292256355286 and batch: 700, loss is 4.186103210449219 and perplexity is 65.76601466500267
At time: 217.29932761192322 and batch: 750, loss is 4.154536399841309 and perplexity is 63.722415976822
At time: 218.11978268623352 and batch: 800, loss is 4.140973944664001 and perplexity is 62.8640177180887
At time: 218.9385085105896 and batch: 850, loss is 4.135925464630127 and perplexity is 62.54744974570146
At time: 219.7561914920807 and batch: 900, loss is 4.1181444787979125 and perplexity is 61.44512369267927
At time: 220.57405424118042 and batch: 950, loss is 4.213783922195435 and perplexity is 67.6118945326308
At time: 221.39256310462952 and batch: 1000, loss is 4.178918776512146 and perplexity is 65.29521631223142
At time: 222.21082544326782 and batch: 1050, loss is 4.125584144592285 and perplexity is 61.90395955405225
At time: 223.02927374839783 and batch: 1100, loss is 4.165785303115845 and perplexity is 64.44327007833672
At time: 223.85775446891785 and batch: 1150, loss is 4.128766956329346 and perplexity is 62.101302088564246
At time: 224.67642331123352 and batch: 1200, loss is 4.202317566871643 and perplexity is 66.84106030098486
At time: 225.49515867233276 and batch: 1250, loss is 4.192381992340088 and perplexity is 66.18024419449993
At time: 226.31399512290955 and batch: 1300, loss is 4.191143851280213 and perplexity is 66.0983544228159
At time: 227.14002513885498 and batch: 1350, loss is 4.0911936378479 and perplexity is 59.811242074692615
At time: 227.96328258514404 and batch: 1400, loss is 4.096407794952393 and perplexity is 60.1239217595722
At time: 228.78737115859985 and batch: 1450, loss is 4.029525566101074 and perplexity is 56.23422549446113
At time: 229.60469245910645 and batch: 1500, loss is 4.0473525333404545 and perplexity is 57.245700165854885
At time: 230.42177176475525 and batch: 1550, loss is 4.060938549041748 and perplexity is 58.028748355099104
At time: 231.23992133140564 and batch: 1600, loss is 4.1509589672088625 and perplexity is 63.49486060118966
At time: 232.05833458900452 and batch: 1650, loss is 4.106015782356263 and perplexity is 60.70437567415896
At time: 232.8778965473175 and batch: 1700, loss is 4.125647020339966 and perplexity is 61.90785193416051
At time: 233.70959162712097 and batch: 1750, loss is 4.130583295822143 and perplexity is 62.214201637017325
At time: 234.52883982658386 and batch: 1800, loss is 4.08892472743988 and perplexity is 59.67568956143833
At time: 235.34697461128235 and batch: 1850, loss is 4.124654316902161 and perplexity is 61.84642629048655
At time: 236.16739988327026 and batch: 1900, loss is 4.199350075721741 and perplexity is 66.64300405650826
At time: 236.99778008460999 and batch: 1950, loss is 4.131917996406555 and perplexity is 62.29729440795062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487305255268895 and perplexity of 88.88160962582188
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 239.83673310279846 and batch: 50, loss is 4.139486632347107 and perplexity is 62.77058878647034
At time: 240.65597224235535 and batch: 100, loss is 4.132803792953491 and perplexity is 62.352501583773716
At time: 241.47979140281677 and batch: 150, loss is 4.095843915939331 and perplexity is 60.09002869859993
At time: 242.300847530365 and batch: 200, loss is 4.092296891212463 and perplexity is 59.87726544230463
At time: 243.11997318267822 and batch: 250, loss is 4.088962435722351 and perplexity is 59.677939871624346
At time: 243.94593620300293 and batch: 300, loss is 4.103322315216064 and perplexity is 60.54109043344585
At time: 244.7654378414154 and batch: 350, loss is 4.103650603294373 and perplexity is 60.56096861438933
At time: 245.5839695930481 and batch: 400, loss is 4.05050410747528 and perplexity is 57.426398826876174
At time: 246.4034345149994 and batch: 450, loss is 4.087819538116455 and perplexity is 59.60977305828419
At time: 247.23409461975098 and batch: 500, loss is 4.102154912948609 and perplexity is 60.470455864699375
At time: 248.05397987365723 and batch: 550, loss is 4.056310524940491 and perplexity is 57.76081039904303
At time: 248.8800826072693 and batch: 600, loss is 4.042103748321534 and perplexity is 56.94601696678553
At time: 249.7048819065094 and batch: 650, loss is 4.08375307559967 and perplexity is 59.367864340228344
At time: 250.52624201774597 and batch: 700, loss is 4.0996052932739255 and perplexity is 60.31647557968494
At time: 251.3520758152008 and batch: 750, loss is 4.05972770690918 and perplexity is 57.958527223622326
At time: 252.1780285835266 and batch: 800, loss is 4.044307465553284 and perplexity is 57.07164826273798
At time: 252.99703645706177 and batch: 850, loss is 4.045158629417419 and perplexity is 57.12024626690436
At time: 253.81598091125488 and batch: 900, loss is 4.0111678647995 and perplexity is 55.21131227467615
At time: 254.63403058052063 and batch: 950, loss is 4.102854599952698 and perplexity is 60.51278106226786
At time: 255.47927832603455 and batch: 1000, loss is 4.061688623428345 and perplexity is 58.0722905608317
At time: 256.29747891426086 and batch: 1050, loss is 4.010147919654846 and perplexity is 55.15502847286612
At time: 257.1219403743744 and batch: 1100, loss is 4.0306683540344235 and perplexity is 56.29852602273351
At time: 257.94128799438477 and batch: 1150, loss is 3.996448321342468 and perplexity is 54.40457890363776
At time: 258.76085448265076 and batch: 1200, loss is 4.060974407196045 and perplexity is 58.0308291962186
At time: 259.5863411426544 and batch: 1250, loss is 4.047094297409058 and perplexity is 57.23091917772736
At time: 260.4166193008423 and batch: 1300, loss is 4.044310178756714 and perplexity is 57.071803109939864
At time: 261.2350699901581 and batch: 1350, loss is 3.9375303173065186 and perplexity is 51.291770351337426
At time: 262.0652234554291 and batch: 1400, loss is 3.939859976768494 and perplexity is 51.41140200585931
At time: 262.89478373527527 and batch: 1450, loss is 3.856418085098267 and perplexity is 47.29563864918199
At time: 263.71937322616577 and batch: 1500, loss is 3.8755115842819214 and perplexity is 48.207354108431666
At time: 264.54820251464844 and batch: 1550, loss is 3.882023983001709 and perplexity is 48.5223241115435
At time: 265.37256932258606 and batch: 1600, loss is 3.9701366662979125 and perplexity is 52.99177253418917
At time: 266.20085096359253 and batch: 1650, loss is 3.915594177246094 and perplexity is 50.178877802474574
At time: 267.02693486213684 and batch: 1700, loss is 3.922835922241211 and perplexity is 50.54357938375496
At time: 267.85095405578613 and batch: 1750, loss is 3.9206677675247192 and perplexity is 50.4341117979399
At time: 268.6802604198456 and batch: 1800, loss is 3.8735488080978393 and perplexity is 48.112826660349114
At time: 269.50611758232117 and batch: 1850, loss is 3.9019646501541136 and perplexity is 49.49960304027541
At time: 270.33468413352966 and batch: 1900, loss is 3.967524542808533 and perplexity is 52.85353210954232
At time: 271.15419936180115 and batch: 1950, loss is 3.9002024126052857 and perplexity is 49.41244979605988
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37470703125 and perplexity of 79.41656957062264
finished 8 epochs...
Completing Train Step...
At time: 273.90162992477417 and batch: 50, loss is 4.044031944274902 and perplexity is 57.05592597526111
At time: 274.7568473815918 and batch: 100, loss is 4.035213737487793 and perplexity is 56.55500687168452
At time: 275.57624912261963 and batch: 150, loss is 3.9965071868896485 and perplexity is 54.40778155320597
At time: 276.42219614982605 and batch: 200, loss is 3.997943596839905 and perplexity is 54.48598958795298
At time: 277.24350905418396 and batch: 250, loss is 3.992738528251648 and perplexity is 54.203123083462636
At time: 278.0688965320587 and batch: 300, loss is 4.005808429718018 and perplexity is 54.916202348405704
At time: 278.8968462944031 and batch: 350, loss is 4.013554263114929 and perplexity is 55.34322579377814
At time: 279.7209777832031 and batch: 400, loss is 3.9650162839889527 and perplexity is 52.721127892921544
At time: 280.54485273361206 and batch: 450, loss is 4.008040480613708 and perplexity is 55.038915006547924
At time: 281.3728196620941 and batch: 500, loss is 4.027218823432922 and perplexity is 56.10465710502221
At time: 282.19420337677 and batch: 550, loss is 3.98326687335968 and perplexity is 53.69215349138092
At time: 283.0148012638092 and batch: 600, loss is 3.9744810962677004 and perplexity is 53.22249238918006
At time: 283.8457634449005 and batch: 650, loss is 4.017420301437378 and perplexity is 55.55759894598949
At time: 284.6669771671295 and batch: 700, loss is 4.035595207214356 and perplexity is 56.57658501013322
At time: 285.48827481269836 and batch: 750, loss is 3.9990574598312376 and perplexity is 54.54671332798622
At time: 286.3181266784668 and batch: 800, loss is 3.984679479598999 and perplexity is 53.768052957814064
At time: 287.1506690979004 and batch: 850, loss is 3.9889467334747315 and perplexity is 53.99798513075542
At time: 287.97072553634644 and batch: 900, loss is 3.954771389961243 and perplexity is 52.18376284865218
At time: 288.79042649269104 and batch: 950, loss is 4.052403798103333 and perplexity is 57.535594905074454
At time: 289.619912147522 and batch: 1000, loss is 4.0120868968963626 and perplexity is 55.262076566200086
At time: 290.4520878791809 and batch: 1050, loss is 3.9635839366912844 and perplexity is 52.64566698387009
At time: 291.28464698791504 and batch: 1100, loss is 3.985422315597534 and perplexity is 53.808008641545065
At time: 292.10585021972656 and batch: 1150, loss is 3.9547577142715453 and perplexity is 52.18304920458401
At time: 292.9414041042328 and batch: 1200, loss is 4.01961760520935 and perplexity is 55.67981008604369
At time: 293.7768085002899 and batch: 1250, loss is 4.009723339080811 and perplexity is 55.13161568987429
At time: 294.61289644241333 and batch: 1300, loss is 4.008338346481323 and perplexity is 55.05531166259978
At time: 295.4431173801422 and batch: 1350, loss is 3.904019684791565 and perplexity is 49.601431033253206
At time: 296.27696990966797 and batch: 1400, loss is 3.9108051586151125 and perplexity is 49.93914472307232
At time: 297.1005630493164 and batch: 1450, loss is 3.829451570510864 and perplexity is 46.037283105863956
At time: 297.92248606681824 and batch: 1500, loss is 3.852327656745911 and perplexity is 47.10257435492965
At time: 298.75168633461 and batch: 1550, loss is 3.861173543930054 and perplexity is 47.5210867413978
At time: 299.57328271865845 and batch: 1600, loss is 3.9521929454803466 and perplexity is 52.049383232982365
At time: 300.3938822746277 and batch: 1650, loss is 3.899306035041809 and perplexity is 49.368177430048455
At time: 301.21766424179077 and batch: 1700, loss is 3.9121884632110597 and perplexity is 50.00827357359038
At time: 302.0391585826874 and batch: 1750, loss is 3.910526041984558 and perplexity is 49.9252078223653
At time: 302.85968041419983 and batch: 1800, loss is 3.8690149116516115 and perplexity is 47.89518184888377
At time: 303.69052934646606 and batch: 1850, loss is 3.898820595741272 and perplexity is 49.344217992424845
At time: 304.5117919445038 and batch: 1900, loss is 3.9673661041259765 and perplexity is 52.84515872889765
At time: 305.3318600654602 and batch: 1950, loss is 3.9003208255767823 and perplexity is 49.41830121750443
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371367414607558 and perplexity of 79.15179104866861
finished 9 epochs...
Completing Train Step...
At time: 308.12520480155945 and batch: 50, loss is 4.007350187301636 and perplexity is 55.00093512175357
At time: 308.94414138793945 and batch: 100, loss is 3.995792202949524 and perplexity is 54.368894766548195
At time: 309.7645571231842 and batch: 150, loss is 3.957317423820496 and perplexity is 52.316793754501326
At time: 310.58552265167236 and batch: 200, loss is 3.9581706809997557 and perplexity is 52.36145248434967
At time: 311.4045307636261 and batch: 250, loss is 3.953733115196228 and perplexity is 52.12960988223694
At time: 312.2239019870758 and batch: 300, loss is 3.9664162969589234 and perplexity is 52.794989847546006
At time: 313.0431778430939 and batch: 350, loss is 3.975533699989319 and perplexity is 53.27854407767536
At time: 313.86283469200134 and batch: 400, loss is 3.927903289794922 and perplexity is 50.800352309914345
At time: 314.6875014305115 and batch: 450, loss is 3.9718810749053954 and perplexity is 53.08429251118448
At time: 315.50758171081543 and batch: 500, loss is 3.992941370010376 and perplexity is 54.21411885544061
At time: 316.3258728981018 and batch: 550, loss is 3.9494175720214844 and perplexity is 51.905127031221035
At time: 317.15623712539673 and batch: 600, loss is 3.942478952407837 and perplexity is 51.54622368558236
At time: 317.97833585739136 and batch: 650, loss is 3.984772138595581 and perplexity is 53.773035282474346
At time: 318.8367054462433 and batch: 700, loss is 4.004357471466064 and perplexity is 54.83657901048106
At time: 319.6639940738678 and batch: 750, loss is 3.9691855335235595 and perplexity is 52.941394284560914
At time: 320.4833679199219 and batch: 800, loss is 3.955113744735718 and perplexity is 52.20163126750821
At time: 321.30925726890564 and batch: 850, loss is 3.9611587524414062 and perplexity is 52.51814623463407
At time: 322.1273880004883 and batch: 900, loss is 3.9261909103393555 and perplexity is 50.713437267288
At time: 322.95037961006165 and batch: 950, loss is 4.0260180616378785 and perplexity is 56.03732920672009
At time: 323.77597737312317 and batch: 1000, loss is 3.98578191280365 and perplexity is 53.82736133049711
At time: 324.60391998291016 and batch: 1050, loss is 3.9388804817199707 and perplexity is 51.36106944642744
At time: 325.4234607219696 and batch: 1100, loss is 3.9609976243972778 and perplexity is 52.509684770157946
At time: 326.2423973083496 and batch: 1150, loss is 3.9312219762802125 and perplexity is 50.96922281170885
At time: 327.066370010376 and batch: 1200, loss is 3.9962841939926146 and perplexity is 54.3956503570118
At time: 327.8902597427368 and batch: 1250, loss is 3.9880876970291137 and perplexity is 53.951618811568494
At time: 328.70713543891907 and batch: 1300, loss is 3.987057294845581 and perplexity is 53.89605557689518
At time: 329.5289514064789 and batch: 1350, loss is 3.8834726428985595 and perplexity is 48.59266739603153
At time: 330.35681653022766 and batch: 1400, loss is 3.8923598384857176 and perplexity is 49.02644461170581
At time: 331.17563104629517 and batch: 1450, loss is 3.8117352437973024 and perplexity is 45.228853900231485
At time: 332.00352811813354 and batch: 1500, loss is 3.836280598640442 and perplexity is 46.35274894374907
At time: 332.82626724243164 and batch: 1550, loss is 3.8455733013153077 and perplexity is 46.7854988518125
At time: 333.6561441421509 and batch: 1600, loss is 3.9381302213668823 and perplexity is 51.32254972404669
At time: 334.48382234573364 and batch: 1650, loss is 3.8857426404953004 and perplexity is 48.703097925338135
At time: 335.30382204055786 and batch: 1700, loss is 3.9004190015792846 and perplexity is 49.42315314693604
At time: 336.1302809715271 and batch: 1750, loss is 3.9005520486831666 and perplexity is 49.42972919177912
At time: 336.94942808151245 and batch: 1800, loss is 3.859632787704468 and perplexity is 47.44792470805701
At time: 337.7734339237213 and batch: 1850, loss is 3.889776835441589 and perplexity is 48.899972565188996
At time: 338.5921244621277 and batch: 1900, loss is 3.9598355531692504 and perplexity is 52.44870021735368
At time: 339.4146876335144 and batch: 1950, loss is 3.8916282272338867 and perplexity is 48.99058943081681
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371629723837209 and perplexity of 79.17255601730649
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 342.18239068984985 and batch: 50, loss is 4.001185140609741 and perplexity is 54.66289487625853
At time: 343.0283772945404 and batch: 100, loss is 4.007605895996094 and perplexity is 55.01500113739212
At time: 343.84686517715454 and batch: 150, loss is 3.975716314315796 and perplexity is 53.288274391538096
At time: 344.673465013504 and batch: 200, loss is 3.973040385246277 and perplexity is 53.145869366877236
At time: 345.4936456680298 and batch: 250, loss is 3.9732435035705564 and perplexity is 53.156665363200645
At time: 346.31234788894653 and batch: 300, loss is 3.9837135791778566 and perplexity is 53.7161434465633
At time: 347.13884592056274 and batch: 350, loss is 3.990701961517334 and perplexity is 54.09284713637272
At time: 347.96560430526733 and batch: 400, loss is 3.941420111656189 and perplexity is 51.491673328517614
At time: 348.79645562171936 and batch: 450, loss is 3.9840139865875246 and perplexity is 53.73228259811242
At time: 349.62402272224426 and batch: 500, loss is 4.002362694740295 and perplexity is 54.72730130749533
At time: 350.44329047203064 and batch: 550, loss is 3.959146776199341 and perplexity is 52.41258719887771
At time: 351.2618465423584 and batch: 600, loss is 3.9433546829223634 and perplexity is 51.59138405784431
At time: 352.08624053001404 and batch: 650, loss is 3.985732650756836 and perplexity is 53.82470974981507
At time: 352.91441822052 and batch: 700, loss is 4.000778708457947 and perplexity is 54.64068263246145
At time: 353.734450340271 and batch: 750, loss is 3.9594778490066527 and perplexity is 52.429942454028115
At time: 354.55999279022217 and batch: 800, loss is 3.9448375415802004 and perplexity is 51.667943537779415
At time: 355.3840448856354 and batch: 850, loss is 3.951848478317261 and perplexity is 52.03145701727333
At time: 356.21599555015564 and batch: 900, loss is 3.908876996040344 and perplexity is 49.84294670571361
At time: 357.04448771476746 and batch: 950, loss is 4.011574301719666 and perplexity is 55.23375675121837
At time: 357.86994314193726 and batch: 1000, loss is 3.964970798492432 and perplexity is 52.71872990077954
At time: 358.6890082359314 and batch: 1050, loss is 3.9174118137359617 and perplexity is 50.27016770258212
At time: 359.5098280906677 and batch: 1100, loss is 3.9342923021316527 and perplexity is 51.12595542110143
At time: 360.3672924041748 and batch: 1150, loss is 3.9077688598632814 and perplexity is 49.78774452471336
At time: 361.19087648391724 and batch: 1200, loss is 3.9678356409072877 and perplexity is 52.86997730079531
At time: 362.0140006542206 and batch: 1250, loss is 3.9564420223236083 and perplexity is 52.27101559499439
At time: 362.83577823638916 and batch: 1300, loss is 3.961710205078125 and perplexity is 52.54711549170322
At time: 363.65376830101013 and batch: 1350, loss is 3.8553021812438963 and perplexity is 47.24289070001201
At time: 364.47902154922485 and batch: 1400, loss is 3.858270649909973 and perplexity is 47.38333809446179
At time: 365.3098783493042 and batch: 1450, loss is 3.769740147590637 and perplexity is 43.36879388594087
At time: 366.1394760608673 and batch: 1500, loss is 3.793971290588379 and perplexity is 44.43250475145049
At time: 366.95814418792725 and batch: 1550, loss is 3.8025828313827517 and perplexity is 44.816789345109086
At time: 367.7913475036621 and batch: 1600, loss is 3.893579349517822 and perplexity is 49.08626937283842
At time: 368.6100733280182 and batch: 1650, loss is 3.836191997528076 and perplexity is 46.348642220564244
At time: 369.4261553287506 and batch: 1700, loss is 3.844761347770691 and perplexity is 46.747526618114144
At time: 370.24699544906616 and batch: 1750, loss is 3.846288814544678 and perplexity is 46.81898647417337
At time: 371.07787585258484 and batch: 1800, loss is 3.8032697534561155 and perplexity is 44.84758556305752
At time: 371.89812707901 and batch: 1850, loss is 3.8270623779296873 and perplexity is 45.9274224619868
At time: 372.71734738349915 and batch: 1900, loss is 3.899955973625183 and perplexity is 49.40027414266719
At time: 373.5363085269928 and batch: 1950, loss is 3.8342824459075926 and perplexity is 46.260221544495394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.340845578215843 and perplexity of 76.77242899332398
finished 11 epochs...
Completing Train Step...
At time: 376.3194148540497 and batch: 50, loss is 3.9830800437927247 and perplexity is 53.682123146606884
At time: 377.14799189567566 and batch: 100, loss is 3.97734739780426 and perplexity is 53.37526293953345
At time: 377.96622943878174 and batch: 150, loss is 3.9435596323013304 and perplexity is 51.601958763569684
At time: 378.7844603061676 and batch: 200, loss is 3.940511984825134 and perplexity is 51.44493358441209
At time: 379.6027874946594 and batch: 250, loss is 3.9393391847610473 and perplexity is 51.384634329404015
At time: 380.42154479026794 and batch: 300, loss is 3.947030363082886 and perplexity is 51.7813664279957
At time: 381.2491261959076 and batch: 350, loss is 3.9572594690322878 and perplexity is 52.31376183365758
At time: 382.10399866104126 and batch: 400, loss is 3.9095216035842895 and perplexity is 49.87508620274081
At time: 382.92255187034607 and batch: 450, loss is 3.9544644069671633 and perplexity is 52.167745779500265
At time: 383.7414493560791 and batch: 500, loss is 3.973971390724182 and perplexity is 53.19537150218982
At time: 384.5602271556854 and batch: 550, loss is 3.9324280977249146 and perplexity is 51.030734972473
At time: 385.3793704509735 and batch: 600, loss is 3.9194698667526247 and perplexity is 50.37373290765703
At time: 386.19976329803467 and batch: 650, loss is 3.9626478338241578 and perplexity is 52.596408283267195
At time: 387.0262145996094 and batch: 700, loss is 3.979784731864929 and perplexity is 53.50551495524909
At time: 387.8510112762451 and batch: 750, loss is 3.939599385261536 and perplexity is 51.39800637660519
At time: 388.66973209381104 and batch: 800, loss is 3.9257385873794557 and perplexity is 50.690503602339184
At time: 389.4930684566498 and batch: 850, loss is 3.9333644819259646 and perplexity is 51.078541725720264
At time: 390.31231927871704 and batch: 900, loss is 3.8912113237380983 and perplexity is 48.970169339721814
At time: 391.1302270889282 and batch: 950, loss is 3.994689974784851 and perplexity is 54.30900085389687
At time: 391.9487249851227 and batch: 1000, loss is 3.949702863693237 and perplexity is 51.91993724419907
At time: 392.7667942047119 and batch: 1050, loss is 3.9033638620376587 and perplexity is 49.56891195069797
At time: 393.5870337486267 and batch: 1100, loss is 3.9212895822525025 and perplexity is 50.465482223724116
At time: 394.4156537055969 and batch: 1150, loss is 3.895812530517578 and perplexity is 49.19601038711732
At time: 395.2472245693207 and batch: 1200, loss is 3.9570995664596555 and perplexity is 52.30539739732158
At time: 396.06632232666016 and batch: 1250, loss is 3.946268696784973 and perplexity is 51.741941322620654
At time: 396.88480854034424 and batch: 1300, loss is 3.952422480583191 and perplexity is 52.061331764767004
At time: 397.7046387195587 and batch: 1350, loss is 3.846613883972168 and perplexity is 46.83420836925452
At time: 398.5293142795563 and batch: 1400, loss is 3.8520328998565674 and perplexity is 47.08869259260577
At time: 399.3484528064728 and batch: 1450, loss is 3.7655337333679197 and perplexity is 43.186749919105125
At time: 400.1741452217102 and batch: 1500, loss is 3.790874276161194 and perplexity is 44.29510951053977
At time: 400.99932527542114 and batch: 1550, loss is 3.8012969064712525 and perplexity is 44.75919535794469
At time: 401.8227872848511 and batch: 1600, loss is 3.893073568344116 and perplexity is 49.06144873933587
At time: 402.6437964439392 and batch: 1650, loss is 3.8366266679763794 and perplexity is 46.3687929848101
At time: 403.477965593338 and batch: 1700, loss is 3.847101163864136 and perplexity is 46.85703529834919
At time: 404.3074085712433 and batch: 1750, loss is 3.8486912059783935 and perplexity is 46.931599222002646
At time: 405.127968788147 and batch: 1800, loss is 3.808046989440918 and perplexity is 45.062345633972896
At time: 405.9594030380249 and batch: 1850, loss is 3.8325533199310304 and perplexity is 46.18030091007654
At time: 406.7822871208191 and batch: 1900, loss is 3.905636305809021 and perplexity is 49.68168259986421
At time: 407.6008815765381 and batch: 1950, loss is 3.8396254348754884 and perplexity is 46.50805088299477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33883425690407 and perplexity of 76.61817015478127
finished 12 epochs...
Completing Train Step...
At time: 410.3843820095062 and batch: 50, loss is 3.971481432914734 and perplexity is 53.063082037432736
At time: 411.23983335494995 and batch: 100, loss is 3.9641736364364624 and perplexity is 52.676721275729285
At time: 412.06118535995483 and batch: 150, loss is 3.929774913787842 and perplexity is 50.89552049989925
At time: 412.8794116973877 and batch: 200, loss is 3.926442275047302 and perplexity is 50.72618643791431
At time: 413.69779920578003 and batch: 250, loss is 3.924778323173523 and perplexity is 50.64185068971301
At time: 414.5276188850403 and batch: 300, loss is 3.932040696144104 and perplexity is 51.01096941392624
At time: 415.34467673301697 and batch: 350, loss is 3.9427835893630983 and perplexity is 51.56192896230353
At time: 416.1644310951233 and batch: 400, loss is 3.89501100063324 and perplexity is 49.15659411337275
At time: 416.9836177825928 and batch: 450, loss is 3.9408618211746216 and perplexity is 51.46293404060024
At time: 417.8020877838135 and batch: 500, loss is 3.9604119062423706 and perplexity is 52.4789378998587
At time: 418.6209421157837 and batch: 550, loss is 3.9196312475204467 and perplexity is 50.38186291534752
At time: 419.43957328796387 and batch: 600, loss is 3.907876615524292 and perplexity is 49.793109725095015
At time: 420.2586257457733 and batch: 650, loss is 3.9510804986953736 and perplexity is 51.99151325854653
At time: 421.07753348350525 and batch: 700, loss is 3.9687461948394773 and perplexity is 52.91814019064801
At time: 421.8968584537506 and batch: 750, loss is 3.9290355587005616 and perplexity is 50.85790454538508
At time: 422.7156045436859 and batch: 800, loss is 3.915527219772339 and perplexity is 50.17551806406212
At time: 423.56071853637695 and batch: 850, loss is 3.923595361709595 and perplexity is 50.5819787519647
At time: 424.3795266151428 and batch: 900, loss is 3.8817297410964966 and perplexity is 48.50804891073571
At time: 425.20835304260254 and batch: 950, loss is 3.9858699083328246 and perplexity is 53.83209810604595
At time: 426.0278434753418 and batch: 1000, loss is 3.941337399482727 and perplexity is 51.487414516431656
At time: 426.8464870452881 and batch: 1050, loss is 3.895827293395996 and perplexity is 49.196736667198294
At time: 427.6696038246155 and batch: 1100, loss is 3.913864870071411 and perplexity is 50.09217809589186
At time: 428.49305176734924 and batch: 1150, loss is 3.888754014968872 and perplexity is 48.84998224205515
At time: 429.3190062046051 and batch: 1200, loss is 3.9506667470932006 and perplexity is 51.97000613624638
At time: 430.14048767089844 and batch: 1250, loss is 3.9400128602981566 and perplexity is 51.41926256332245
At time: 430.95916628837585 and batch: 1300, loss is 3.9466160106658936 and perplexity is 51.75991513816491
At time: 431.7776701450348 and batch: 1350, loss is 3.841092338562012 and perplexity is 46.57632377692546
At time: 432.5956349372864 and batch: 1400, loss is 3.8476458549499513 and perplexity is 46.88256486001507
At time: 433.4197220802307 and batch: 1450, loss is 3.762205424308777 and perplexity is 43.04325000661381
At time: 434.25337314605713 and batch: 1500, loss is 3.7877414798736573 and perplexity is 44.15655909433977
At time: 435.0809109210968 and batch: 1550, loss is 3.7989683723449708 and perplexity is 44.65509329373077
At time: 435.9436094760895 and batch: 1600, loss is 3.8909469652175903 and perplexity is 48.95722536920597
At time: 436.80015802383423 and batch: 1650, loss is 3.8349383449554444 and perplexity is 46.29057353259176
At time: 437.63140177726746 and batch: 1700, loss is 3.8463879442214965 and perplexity is 46.82362785521703
At time: 438.45978593826294 and batch: 1750, loss is 3.8480571556091308 and perplexity is 46.901851655910065
At time: 439.2856078147888 and batch: 1800, loss is 3.8085527849197387 and perplexity is 45.08514372976046
At time: 440.10785031318665 and batch: 1850, loss is 3.8333306550979613 and perplexity is 46.21621243783181
At time: 440.93434166908264 and batch: 1900, loss is 3.906537108421326 and perplexity is 49.72645615237279
At time: 441.76283740997314 and batch: 1950, loss is 3.8402071714401247 and perplexity is 46.53511418783715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3380464775617735 and perplexity of 76.55783571132315
finished 13 epochs...
Completing Train Step...
At time: 444.54184460639954 and batch: 50, loss is 3.961818618774414 and perplexity is 52.552812627541186
At time: 445.36777234077454 and batch: 100, loss is 3.95362425327301 and perplexity is 52.12393526152924
At time: 446.18599677085876 and batch: 150, loss is 3.919091668128967 and perplexity is 50.354685233332006
At time: 447.00458002090454 and batch: 200, loss is 3.9156586265563966 and perplexity is 50.18211190075729
At time: 447.82325196266174 and batch: 250, loss is 3.913979158401489 and perplexity is 50.09790337443644
At time: 448.64218378067017 and batch: 300, loss is 3.9210728883743284 and perplexity is 50.45454784741613
At time: 449.46422958374023 and batch: 350, loss is 3.932015309333801 and perplexity is 51.00967442456026
At time: 450.28868532180786 and batch: 400, loss is 3.88423659324646 and perplexity is 48.62980396463526
At time: 451.10650539398193 and batch: 450, loss is 3.9308227252960206 and perplexity is 50.94887736107863
At time: 451.92568707466125 and batch: 500, loss is 3.950417127609253 and perplexity is 51.957035029121776
At time: 452.7431983947754 and batch: 550, loss is 3.910178418159485 and perplexity is 49.90785564684408
At time: 453.5619432926178 and batch: 600, loss is 3.8990223455429076 and perplexity is 49.35417418291264
At time: 454.3887107372284 and batch: 650, loss is 3.942275547981262 and perplexity is 51.53574002175946
At time: 455.209130525589 and batch: 700, loss is 3.960181379318237 and perplexity is 52.46684148605096
At time: 456.0277900695801 and batch: 750, loss is 3.921083760261536 and perplexity is 50.45509638655125
At time: 456.84676361083984 and batch: 800, loss is 3.9077282428741453 and perplexity is 49.785722337502754
At time: 457.6776201725006 and batch: 850, loss is 3.9159978580474855 and perplexity is 50.199138141158556
At time: 458.5002222061157 and batch: 900, loss is 3.8743653869628907 and perplexity is 48.15213062294643
At time: 459.3181231021881 and batch: 950, loss is 3.9790875625610354 and perplexity is 53.46822555265705
At time: 460.1363773345947 and batch: 1000, loss is 3.9347487020492555 and perplexity is 51.149294628544034
At time: 460.9613847732544 and batch: 1050, loss is 3.8897298860549925 and perplexity is 48.897676795365385
At time: 461.7775821685791 and batch: 1100, loss is 3.9077837800979616 and perplexity is 49.788487375087605
At time: 462.59536361694336 and batch: 1150, loss is 3.8829271745681764 and perplexity is 48.56616886259057
At time: 463.42389249801636 and batch: 1200, loss is 3.945236177444458 and perplexity is 51.6885443389423
At time: 464.24218487739563 and batch: 1250, loss is 3.934672517776489 and perplexity is 51.14539800516284
At time: 465.0605208873749 and batch: 1300, loss is 3.9414351987838745 and perplexity is 51.49245019582819
At time: 465.8794672489166 and batch: 1350, loss is 3.8361152029037475 and perplexity is 46.345083030661854
At time: 466.69768381118774 and batch: 1400, loss is 3.8435073280334473 and perplexity is 46.688941038481765
At time: 467.5161292552948 and batch: 1450, loss is 3.7588000297546387 and perplexity is 42.89692005447211
At time: 468.3347611427307 and batch: 1500, loss is 3.784357466697693 and perplexity is 44.00738526202219
At time: 469.1531364917755 and batch: 1550, loss is 3.7960355472564697 and perplexity is 44.52431957774424
At time: 469.9708762168884 and batch: 1600, loss is 3.8881841135025024 and perplexity is 48.822150496972725
At time: 470.7883970737457 and batch: 1650, loss is 3.832391104698181 and perplexity is 46.17281036936769
At time: 471.61909103393555 and batch: 1700, loss is 3.84450213432312 and perplexity is 46.73541060095918
At time: 472.4387800693512 and batch: 1750, loss is 3.8468185234069825 and perplexity is 46.843793475897144
At time: 473.25706005096436 and batch: 1800, loss is 3.807651686668396 and perplexity is 45.044535884161085
At time: 474.0755136013031 and batch: 1850, loss is 3.8322931814193724 and perplexity is 46.16828919775209
At time: 474.89392614364624 and batch: 1900, loss is 3.9057763147354128 and perplexity is 49.688638965871654
At time: 475.71097683906555 and batch: 1950, loss is 3.8391505098342895 and perplexity is 46.48596828921654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337683673237645 and perplexity of 76.53006523541018
finished 14 epochs...
Completing Train Step...
At time: 478.4907763004303 and batch: 50, loss is 3.9532767581939696 and perplexity is 52.105825597217475
At time: 479.3368592262268 and batch: 100, loss is 3.944466066360474 and perplexity is 51.64875374158845
At time: 480.1555247306824 and batch: 150, loss is 3.9099749660491945 and perplexity is 49.89770282113459
At time: 480.9746220111847 and batch: 200, loss is 3.906439518928528 and perplexity is 49.72160360952069
At time: 481.80600905418396 and batch: 250, loss is 3.904975209236145 and perplexity is 49.648849064027566
At time: 482.63026762008667 and batch: 300, loss is 3.9118714904785157 and perplexity is 49.99242482640899
At time: 483.44934153556824 and batch: 350, loss is 3.9229741525650024 and perplexity is 50.550566522004814
At time: 484.28065752983093 and batch: 400, loss is 3.8751758432388304 and perplexity is 48.19117163779044
At time: 485.0985019207001 and batch: 450, loss is 3.9223765420913694 and perplexity is 50.52036599897643
At time: 485.917240858078 and batch: 500, loss is 3.9420520210266115 and perplexity is 51.52422168211437
At time: 486.76985573768616 and batch: 550, loss is 3.9021915292739866 and perplexity is 49.51083474071823
At time: 487.5986330509186 and batch: 600, loss is 3.89156662940979 and perplexity is 48.98757181004706
At time: 488.4250292778015 and batch: 650, loss is 3.934822688102722 and perplexity is 51.15307910298863
At time: 489.24407839775085 and batch: 700, loss is 3.9529080247879027 and perplexity is 52.08661598050044
At time: 490.06383204460144 and batch: 750, loss is 3.9140923690795897 and perplexity is 50.10357531310483
At time: 490.8834707736969 and batch: 800, loss is 3.900952458381653 and perplexity is 49.44952529775297
At time: 491.70733618736267 and batch: 850, loss is 3.9093427896499633 and perplexity is 49.86616863966807
At time: 492.5256164073944 and batch: 900, loss is 3.8679147434234618 and perplexity is 47.84251806635422
At time: 493.3457646369934 and batch: 950, loss is 3.97308162689209 and perplexity is 53.14806123519591
At time: 494.17871594429016 and batch: 1000, loss is 3.928874635696411 and perplexity is 50.84972099707909
At time: 495.0091254711151 and batch: 1050, loss is 3.884261474609375 and perplexity is 48.63101395548923
At time: 495.8357403278351 and batch: 1100, loss is 3.90230278968811 and perplexity is 49.51634364315078
At time: 496.6656849384308 and batch: 1150, loss is 3.8776013040542603 and perplexity is 48.3081993018829
At time: 497.4909234046936 and batch: 1200, loss is 3.9402648401260376 and perplexity is 51.43222081279309
At time: 498.3099732398987 and batch: 1250, loss is 3.9297419023513793 and perplexity is 50.89384039338955
At time: 499.12897634506226 and batch: 1300, loss is 3.9365649223327637 and perplexity is 51.24227742799887
At time: 499.94809079170227 and batch: 1350, loss is 3.831489987373352 and perplexity is 46.13122199082619
At time: 500.76763796806335 and batch: 1400, loss is 3.839530463218689 and perplexity is 46.50363414608364
At time: 501.5871067047119 and batch: 1450, loss is 3.7553642654418944 and perplexity is 42.749789245547106
At time: 502.40655851364136 and batch: 1500, loss is 3.7808208990097047 and perplexity is 43.85202504815603
At time: 503.23095631599426 and batch: 1550, loss is 3.792842135429382 and perplexity is 44.382361874355055
At time: 504.0502736568451 and batch: 1600, loss is 3.8850827169418336 and perplexity is 48.67096820663551
At time: 504.86911058425903 and batch: 1650, loss is 3.8294855403900145 and perplexity is 46.0388470133702
At time: 505.6983277797699 and batch: 1700, loss is 3.8420595121383667 and perplexity is 46.62139295791349
At time: 506.5265095233917 and batch: 1750, loss is 3.844483952522278 and perplexity is 46.73456087475615
At time: 507.3440101146698 and batch: 1800, loss is 3.805786380767822 and perplexity is 44.96059236010231
At time: 508.1613736152649 and batch: 1850, loss is 3.8307093143463136 and perplexity is 46.09522264380156
At time: 508.98593950271606 and batch: 1900, loss is 3.904420943260193 and perplexity is 49.62133802116801
At time: 509.8084251880646 and batch: 1950, loss is 3.8375788354873657 and perplexity is 46.41296486919322
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337580907067587 and perplexity of 76.52220093781042
finished 15 epochs...
Completing Train Step...
At time: 512.5973253250122 and batch: 50, loss is 3.9456667566299437 and perplexity is 51.71080514243809
At time: 513.4179437160492 and batch: 100, loss is 3.9364431715011596 and perplexity is 51.23603901788224
At time: 514.2391760349274 and batch: 150, loss is 3.9019612455368042 and perplexity is 49.49943451335698
At time: 515.0731666088104 and batch: 200, loss is 3.898295044898987 and perplexity is 49.31829191043087
At time: 515.9032900333405 and batch: 250, loss is 3.897082180976868 and perplexity is 49.25851179337404
At time: 516.726012468338 and batch: 300, loss is 3.9038283109664915 and perplexity is 49.59193952590925
At time: 517.5449652671814 and batch: 350, loss is 3.9149516820907593 and perplexity is 50.14664847128962
At time: 518.3640079498291 and batch: 400, loss is 3.8672425842285154 and perplexity is 47.81037108308206
At time: 519.1927134990692 and batch: 450, loss is 3.9149171209335325 and perplexity is 50.14491537503649
At time: 520.0282826423645 and batch: 500, loss is 3.934719753265381 and perplexity is 51.14781394010067
At time: 520.8531546592712 and batch: 550, loss is 3.8952031421661375 and perplexity is 49.166040044166465
At time: 521.6877341270447 and batch: 600, loss is 3.884895529747009 and perplexity is 48.66185847726646
At time: 522.5129277706146 and batch: 650, loss is 3.928205943107605 and perplexity is 50.81572953169259
At time: 523.3396799564362 and batch: 700, loss is 3.9463171339035035 and perplexity is 51.744447613863755
At time: 524.1678082942963 and batch: 750, loss is 3.907891254425049 and perplexity is 49.793838646821946
At time: 524.9991886615753 and batch: 800, loss is 3.8949198579788207 and perplexity is 49.15211405506835
At time: 525.8239412307739 and batch: 850, loss is 3.90338095664978 and perplexity is 49.56975931926374
At time: 526.6520946025848 and batch: 900, loss is 3.8621024179458616 and perplexity is 47.5652483511855
At time: 527.4798786640167 and batch: 950, loss is 3.9676352024078367 and perplexity is 52.8593811838495
At time: 528.3509333133698 and batch: 1000, loss is 3.923524136543274 and perplexity is 50.57837617041401
At time: 529.1713206768036 and batch: 1050, loss is 3.8791771602630614 and perplexity is 48.38438609163524
At time: 530.0006721019745 and batch: 1100, loss is 3.8972186613082886 and perplexity is 49.26523507017598
At time: 530.8354892730713 and batch: 1150, loss is 3.872653307914734 and perplexity is 48.069760900840755
At time: 531.6769886016846 and batch: 1200, loss is 3.935585765838623 and perplexity is 51.192127775466396
At time: 532.5288710594177 and batch: 1250, loss is 3.9250507497787477 and perplexity is 50.655648756573626
At time: 533.3610117435455 and batch: 1300, loss is 3.931900420188904 and perplexity is 51.00381430332274
At time: 534.1836700439453 and batch: 1350, loss is 3.827101216316223 and perplexity is 45.92920624361234
At time: 535.0244576931 and batch: 1400, loss is 3.8356462383270262 and perplexity is 46.32335392390418
At time: 535.8758881092072 and batch: 1450, loss is 3.751944074630737 and perplexity is 42.60382656159147
At time: 536.7240402698517 and batch: 1500, loss is 3.7772420692443847 and perplexity is 43.69536660979226
At time: 537.5549972057343 and batch: 1550, loss is 3.7895320749282835 and perplexity is 44.235696441009814
At time: 538.3759441375732 and batch: 1600, loss is 3.8818798542022703 and perplexity is 48.51533115117891
At time: 539.1963047981262 and batch: 1650, loss is 3.826395721435547 and perplexity is 45.896814851058274
At time: 540.0174820423126 and batch: 1700, loss is 3.839314751625061 and perplexity is 46.493603854916444
At time: 540.8431296348572 and batch: 1750, loss is 3.84157817363739 and perplexity is 46.59895768642682
At time: 541.6649408340454 and batch: 1800, loss is 3.803619875907898 and perplexity is 44.86329045882926
At time: 542.486718416214 and batch: 1850, loss is 3.828632106781006 and perplexity is 45.99957267541277
At time: 543.3074359893799 and batch: 1900, loss is 3.9025610208511354 and perplexity is 49.52913195725806
At time: 544.1323697566986 and batch: 1950, loss is 3.8353772830963133 and perplexity is 46.31089669085627
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3376127021257265 and perplexity of 76.52463400431773
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 546.899197101593 and batch: 50, loss is 3.9476338958740236 and perplexity is 51.81262761323119
At time: 547.7552180290222 and batch: 100, loss is 3.951472897529602 and perplexity is 52.01191867100716
At time: 548.5766198635101 and batch: 150, loss is 3.921578440666199 and perplexity is 50.48006170846773
At time: 549.4235808849335 and batch: 200, loss is 3.9158161544799803 and perplexity is 50.19001760731449
At time: 550.2432548999786 and batch: 250, loss is 3.9166624879837038 and perplexity is 50.232513080903
At time: 551.0687918663025 and batch: 300, loss is 3.921251902580261 and perplexity is 50.46358073671835
At time: 551.8891112804413 and batch: 350, loss is 3.933461780548096 and perplexity is 51.08351183923933
At time: 552.7136042118073 and batch: 400, loss is 3.88852578163147 and perplexity is 48.83883431978815
At time: 553.5358078479767 and batch: 450, loss is 3.934653835296631 and perplexity is 51.14444249122048
At time: 554.353280544281 and batch: 500, loss is 3.9554267930984497 and perplexity is 52.21797546083644
At time: 555.1721172332764 and batch: 550, loss is 3.913274841308594 and perplexity is 50.06263098770216
At time: 555.9912075996399 and batch: 600, loss is 3.897584547996521 and perplexity is 49.283263861927125
At time: 556.8166697025299 and batch: 650, loss is 3.9360185718536376 and perplexity is 51.214288831662294
At time: 557.6443619728088 and batch: 700, loss is 3.9555665683746337 and perplexity is 52.225274752896645
At time: 558.4793763160706 and batch: 750, loss is 3.9174461126327516 and perplexity is 50.27189194344537
At time: 559.3004193305969 and batch: 800, loss is 3.9024807739257814 and perplexity is 49.525157556171905
At time: 560.1180713176727 and batch: 850, loss is 3.9077647495269776 and perplexity is 49.787539880760136
At time: 560.9451229572296 and batch: 900, loss is 3.862478265762329 and perplexity is 47.583129005910045
At time: 561.7728383541107 and batch: 950, loss is 3.9715687465667724 and perplexity is 53.06771537118753
At time: 562.5916385650635 and batch: 1000, loss is 3.9244875478744508 and perplexity is 50.62712743111684
At time: 563.4166357517242 and batch: 1050, loss is 3.8798419046401977 and perplexity is 48.41656003276931
At time: 564.2404255867004 and batch: 1100, loss is 3.896431303024292 and perplexity is 49.22646094579757
At time: 565.0594801902771 and batch: 1150, loss is 3.872645764350891 and perplexity is 48.0693982848982
At time: 565.8786492347717 and batch: 1200, loss is 3.9317286348342897 and perplexity is 50.995053347519466
At time: 566.7090857028961 and batch: 1250, loss is 3.9201951742172243 and perplexity is 50.4102826054367
At time: 567.5285804271698 and batch: 1300, loss is 3.9258113288879395 and perplexity is 50.694191040150294
At time: 568.3476364612579 and batch: 1350, loss is 3.8226770782470703 and perplexity is 45.72645791777667
At time: 569.1664493083954 and batch: 1400, loss is 3.829015989303589 and perplexity is 46.0172344972246
At time: 569.991516828537 and batch: 1450, loss is 3.743557085990906 and perplexity is 42.24800298212901
At time: 570.8111310005188 and batch: 1500, loss is 3.766502103805542 and perplexity is 43.228590946561134
At time: 571.6301724910736 and batch: 1550, loss is 3.7782026720046997 and perplexity is 43.73736066614463
At time: 572.4496397972107 and batch: 1600, loss is 3.86795747756958 and perplexity is 47.84456261919773
At time: 573.2686469554901 and batch: 1650, loss is 3.8104786539077757 and perplexity is 45.17205547334387
At time: 574.0883438587189 and batch: 1700, loss is 3.8236377477645873 and perplexity is 45.77040703895282
At time: 574.9079964160919 and batch: 1750, loss is 3.8290197229385377 and perplexity is 46.01740630910031
At time: 575.7272787094116 and batch: 1800, loss is 3.7910480070114136 and perplexity is 44.30280560608086
At time: 576.5467436313629 and batch: 1850, loss is 3.8110716724395752 and perplexity is 45.198851283779845
At time: 577.365442276001 and batch: 1900, loss is 3.887034306526184 and perplexity is 48.766046708177335
At time: 578.1844308376312 and batch: 1950, loss is 3.8255037307739257 and perplexity is 45.8558935742246
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3257568359375 and perplexity of 75.62272520294222
finished 17 epochs...
Completing Train Step...
At time: 580.9701714515686 and batch: 50, loss is 3.9476100158691407 and perplexity is 51.81139034220388
At time: 581.7966070175171 and batch: 100, loss is 3.943522267341614 and perplexity is 51.60003069448053
At time: 582.6237914562225 and batch: 150, loss is 3.9084954500198363 and perplexity is 49.823932955288726
At time: 583.4468243122101 and batch: 200, loss is 3.9041768884658814 and perplexity is 49.609229173395065
At time: 584.2697849273682 and batch: 250, loss is 3.904254002571106 and perplexity is 49.61305489222019
At time: 585.0890808105469 and batch: 300, loss is 3.906947112083435 and perplexity is 49.746848361653555
At time: 585.9143469333649 and batch: 350, loss is 3.9199971342086792 and perplexity is 50.40030034111524
At time: 586.7327606678009 and batch: 400, loss is 3.87524468421936 and perplexity is 48.19448927949241
At time: 587.5512847900391 and batch: 450, loss is 3.9224428701400758 and perplexity is 50.52371702740543
At time: 588.3819251060486 and batch: 500, loss is 3.9434420251846314 and perplexity is 51.595890362834034
At time: 589.2090079784393 and batch: 550, loss is 3.9020014667510985 and perplexity is 49.50142548075928
At time: 590.0368609428406 and batch: 600, loss is 3.8876380825042727 and perplexity is 48.79549936623507
At time: 590.8555500507355 and batch: 650, loss is 3.927105178833008 and perplexity is 50.759824166995585
At time: 591.7150106430054 and batch: 700, loss is 3.9477677726745606 and perplexity is 51.819564586382995
At time: 592.5365741252899 and batch: 750, loss is 3.9113015270233156 and perplexity is 49.96393908990666
At time: 593.3550977706909 and batch: 800, loss is 3.8964018058776855 and perplexity is 49.22500892707744
At time: 594.1819951534271 and batch: 850, loss is 3.9017131233215334 and perplexity is 49.487154127592135
At time: 595.0109620094299 and batch: 900, loss is 3.857215371131897 and perplexity is 47.333361837415886
At time: 595.8294978141785 and batch: 950, loss is 3.9665553903579713 and perplexity is 52.80233379287192
At time: 596.6544528007507 and batch: 1000, loss is 3.9198814105987547 and perplexity is 50.39446817388472
At time: 597.4875600337982 and batch: 1050, loss is 3.875463395118713 and perplexity is 48.205031092349245
At time: 598.3083322048187 and batch: 1100, loss is 3.8927705001831057 and perplexity is 49.04658202921698
At time: 599.1353931427002 and batch: 1150, loss is 3.8692536878585817 and perplexity is 47.90661944419627
At time: 599.9519436359406 and batch: 1200, loss is 3.928667216300964 and perplexity is 50.83917487246443
At time: 600.7670774459839 and batch: 1250, loss is 3.9175247383117675 and perplexity is 50.275844760479266
At time: 601.5885143280029 and batch: 1300, loss is 3.923607449531555 and perplexity is 50.58259018161367
At time: 602.419064283371 and batch: 1350, loss is 3.8208376121520997 and perplexity is 45.6424229622149
At time: 603.2424747943878 and batch: 1400, loss is 3.8281675243377684 and perplexity is 45.978207044984025
At time: 604.0634474754333 and batch: 1450, loss is 3.7433222007751463 and perplexity is 42.238080716175546
At time: 604.8811073303223 and batch: 1500, loss is 3.7667354583740233 and perplexity is 43.23867971283159
At time: 605.7009398937225 and batch: 1550, loss is 3.778862614631653 and perplexity is 43.76623434127522
At time: 606.5244216918945 and batch: 1600, loss is 3.869088764190674 and perplexity is 47.89871916029028
At time: 607.3427951335907 and batch: 1650, loss is 3.8119536209106446 and perplexity is 45.238731925314035
At time: 608.1624708175659 and batch: 1700, loss is 3.825694513320923 and perplexity is 45.86464291297956
At time: 608.991096496582 and batch: 1750, loss is 3.831529288291931 and perplexity is 46.133035025852344
At time: 609.8091959953308 and batch: 1800, loss is 3.7938173103332518 and perplexity is 44.42566354975142
At time: 610.6317856311798 and batch: 1850, loss is 3.8138948583602907 and perplexity is 45.326636339967884
At time: 611.4503660202026 and batch: 1900, loss is 3.8900881385803223 and perplexity is 48.91519764981787
At time: 612.2804584503174 and batch: 1950, loss is 3.8283125829696654 and perplexity is 45.984877064555306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3250547896984015 and perplexity of 75.56965318480829
finished 18 epochs...
Completing Train Step...
At time: 615.0558786392212 and batch: 50, loss is 3.9447183561325074 and perplexity is 51.6617858377589
At time: 615.9076192378998 and batch: 100, loss is 3.9399209880828856 and perplexity is 51.414538778758754
At time: 616.7353827953339 and batch: 150, loss is 3.9043437910079954 and perplexity is 49.617509770863585
At time: 617.5599036216736 and batch: 200, loss is 3.8999439764022825 and perplexity is 49.39968148012212
At time: 618.3785893917084 and batch: 250, loss is 3.8998782634735107 and perplexity is 49.39643538902791
At time: 619.1975519657135 and batch: 300, loss is 3.902232036590576 and perplexity is 49.512840332395974
At time: 620.016116142273 and batch: 350, loss is 3.9154998683929443 and perplexity is 50.17414571319915
At time: 620.8350174427032 and batch: 400, loss is 3.8705395793914796 and perplexity is 47.9682617846973
At time: 621.6703250408173 and batch: 450, loss is 3.917933120727539 and perplexity is 50.296380724395384
At time: 622.4937164783478 and batch: 500, loss is 3.9390301513671875 and perplexity is 51.368757214870605
At time: 623.3139102458954 and batch: 550, loss is 3.8977607774734495 and perplexity is 49.29194979107473
At time: 624.1452157497406 and batch: 600, loss is 3.883757538795471 and perplexity is 48.606513219808186
At time: 624.9687926769257 and batch: 650, loss is 3.9233333349227903 and perplexity is 50.56872665488014
At time: 625.7912201881409 and batch: 700, loss is 3.9443167734146116 and perplexity is 51.641043522547236
At time: 626.6103162765503 and batch: 750, loss is 3.9082554006576538 and perplexity is 49.81197418736611
At time: 627.4294192790985 and batch: 800, loss is 3.893317461013794 and perplexity is 49.07341592634245
At time: 628.2571427822113 and batch: 850, loss is 3.8986348295211792 and perplexity is 49.33505235492423
At time: 629.0893189907074 and batch: 900, loss is 3.854494962692261 and perplexity is 47.20477074984148
At time: 629.9121625423431 and batch: 950, loss is 3.9639668083190918 and perplexity is 52.665827375259866
At time: 630.7304227352142 and batch: 1000, loss is 3.9175124025344847 and perplexity is 50.275224572680855
At time: 631.5492234230042 and batch: 1050, loss is 3.8733194637298585 and perplexity is 48.101793519769615
At time: 632.3708686828613 and batch: 1100, loss is 3.89089551448822 and perplexity is 48.954706549050904
At time: 633.2367877960205 and batch: 1150, loss is 3.8674688291549684 and perplexity is 47.82118916069289
At time: 634.0555636882782 and batch: 1200, loss is 3.927078766822815 and perplexity is 50.758483515707006
At time: 634.8749108314514 and batch: 1250, loss is 3.916101140975952 and perplexity is 50.20432312290772
At time: 635.6934344768524 and batch: 1300, loss is 3.922327356338501 and perplexity is 50.517881177848984
At time: 636.5119392871857 and batch: 1350, loss is 3.8195665073394776 and perplexity is 45.584443515511246
At time: 637.3298516273499 and batch: 1400, loss is 3.8273448181152343 and perplexity is 45.940396043752834
At time: 638.152001619339 and batch: 1450, loss is 3.742930212020874 and perplexity is 42.22152710815881
At time: 638.9763433933258 and batch: 1500, loss is 3.7665244817733763 and perplexity is 43.229558325402806
At time: 639.7945096492767 and batch: 1550, loss is 3.778928179740906 and perplexity is 43.76910397328424
At time: 640.6152369976044 and batch: 1600, loss is 3.8692535734176636 and perplexity is 47.906613961719074
At time: 641.4321229457855 and batch: 1650, loss is 3.812333869934082 and perplexity is 45.255937179883496
At time: 642.2499103546143 and batch: 1700, loss is 3.826303324699402 and perplexity is 45.89257433107469
At time: 643.0678429603577 and batch: 1750, loss is 3.8322687101364137 and perplexity is 46.16715941430709
At time: 643.8862683773041 and batch: 1800, loss is 3.7947177410125734 and perplexity is 44.46568379518528
At time: 644.7049424648285 and batch: 1850, loss is 3.81484516620636 and perplexity is 45.36973107150524
At time: 645.5237348079681 and batch: 1900, loss is 3.8910590553283693 and perplexity is 48.96271329758654
At time: 646.341644525528 and batch: 1950, loss is 3.8290109539031985 and perplexity is 46.017002782607435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324789925508721 and perplexity of 75.54964014033948
finished 19 epochs...
Completing Train Step...
At time: 649.1149616241455 and batch: 50, loss is 3.94192617893219 and perplexity is 51.51773817410213
At time: 649.9417321681976 and batch: 100, loss is 3.936921796798706 and perplexity is 51.26056775187032
At time: 650.7689175605774 and batch: 150, loss is 3.9010901737213133 and perplexity is 49.45633572486478
At time: 651.5919859409332 and batch: 200, loss is 3.896606001853943 and perplexity is 49.23506150214435
At time: 652.4193136692047 and batch: 250, loss is 3.8965582275390624 and perplexity is 49.23270938699877
At time: 653.2453937530518 and batch: 300, loss is 3.8987583923339844 and perplexity is 49.34114870939669
At time: 654.0641794204712 and batch: 350, loss is 3.9121484756469727 and perplexity is 50.006273904527184
At time: 654.915148973465 and batch: 400, loss is 3.8670335388183594 and perplexity is 47.80037758903271
At time: 655.7455058097839 and batch: 450, loss is 3.9146249437332155 and perplexity is 50.130266314217074
At time: 656.5763113498688 and batch: 500, loss is 3.935792407989502 and perplexity is 51.20270731991025
At time: 657.400238275528 and batch: 550, loss is 3.8946785593032835 and perplexity is 49.14025514587409
At time: 658.2266936302185 and batch: 600, loss is 3.88088650226593 and perplexity is 48.46716228131865
At time: 659.0467982292175 and batch: 650, loss is 3.9204888772964477 and perplexity is 50.42509043510858
At time: 659.8671717643738 and batch: 700, loss is 3.941691436767578 and perplexity is 51.50564620802991
At time: 660.6883718967438 and batch: 750, loss is 3.905924096107483 and perplexity is 49.695982563724456
At time: 661.5232810974121 and batch: 800, loss is 3.8909636116027833 and perplexity is 48.95804033682056
At time: 662.3591876029968 and batch: 850, loss is 3.8962940835952757 and perplexity is 49.219706582359635
At time: 663.1931326389313 and batch: 900, loss is 3.8523520326614378 and perplexity is 47.103722537297166
At time: 664.0172457695007 and batch: 950, loss is 3.9619585371017454 and perplexity is 52.560166243621424
At time: 664.8379731178284 and batch: 1000, loss is 3.9156520175933838 and perplexity is 50.18178025013177
At time: 665.658896446228 and batch: 1050, loss is 3.8716309881210327 and perplexity is 48.02064334399652
At time: 666.4864702224731 and batch: 1100, loss is 3.8893788194656373 and perplexity is 48.88051346765718
At time: 667.3132276535034 and batch: 1150, loss is 3.865995030403137 and perplexity is 47.75076226208216
At time: 668.1437225341797 and batch: 1200, loss is 3.9257440900802614 and perplexity is 50.690782537781644
At time: 668.9642624855042 and batch: 1250, loss is 3.9148622131347657 and perplexity is 50.142162103702624
At time: 669.7840442657471 and batch: 1300, loss is 3.921155071258545 and perplexity is 50.458694518070416
At time: 670.604944229126 and batch: 1350, loss is 3.8183821964263918 and perplexity is 45.53048931716815
At time: 671.4257190227509 and batch: 1400, loss is 3.826449503898621 and perplexity is 45.899283361188886
At time: 672.2554137706757 and batch: 1450, loss is 3.742347297668457 and perplexity is 42.19692274584116
At time: 673.0783185958862 and batch: 1500, loss is 3.7660255002975465 and perplexity is 43.207992957397146
At time: 673.9016065597534 and batch: 1550, loss is 3.778641662597656 and perplexity is 43.756565171027894
At time: 674.7236318588257 and batch: 1600, loss is 3.8690135860443116 and perplexity is 47.89511835872317
At time: 675.5548145771027 and batch: 1650, loss is 3.8122528409957885 and perplexity is 45.252270287906526
At time: 676.3893849849701 and batch: 1700, loss is 3.8263841342926024 and perplexity is 45.89628304118497
At time: 677.2194514274597 and batch: 1750, loss is 3.8324354124069213 and perplexity is 46.174856226124525
At time: 678.0389466285706 and batch: 1800, loss is 3.795025610923767 and perplexity is 44.47937554883781
At time: 678.8594861030579 and batch: 1850, loss is 3.8151523160934446 and perplexity is 45.383668519614154
At time: 679.6804513931274 and batch: 1900, loss is 3.8913930225372315 and perplexity is 48.97906796909485
At time: 680.5011785030365 and batch: 1950, loss is 3.8291935682296754 and perplexity is 46.025406913911105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324650254360465 and perplexity of 75.53908877222875
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdf90580b38>
ELAPSED
2824.905003786087


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}, 'best_accuracy': -75.41513488817796}, {'params': {'wordvec_dim': 300, 'dropout': 0.6309802267622319, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.016023383857180606, 'tune_wordvecs': True}, 'best_accuracy': -76.15677522751027}, {'params': {'wordvec_dim': 300, 'dropout': 0.32978472608712295, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8376966109346161, 'tune_wordvecs': True}, 'best_accuracy': -75.7890280729731}, {'params': {'wordvec_dim': 300, 'dropout': 0.29541444939753103, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8777067374849862, 'tune_wordvecs': True}, 'best_accuracy': -75.53908877222875}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.18877573745735154, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.7802425779340171, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.2849886417388916 and batch: 50, loss is 7.461725378036499 and perplexity is 1740.147881624421
At time: 2.103339195251465 and batch: 100, loss is 6.633407030105591 and perplexity is 760.0673365700219
At time: 2.9196887016296387 and batch: 150, loss is 6.310716419219971 and perplexity is 550.4391527760035
At time: 3.7366249561309814 and batch: 200, loss is 6.123171758651734 and perplexity is 456.309705932021
At time: 4.553699016571045 and batch: 250, loss is 5.988373079299927 and perplexity is 398.7653223432281
At time: 5.376675128936768 and batch: 300, loss is 5.849472398757935 and perplexity is 347.05122750842213
At time: 6.2042670249938965 and batch: 350, loss is 5.772064619064331 and perplexity is 321.20020460180694
At time: 7.03262186050415 and batch: 400, loss is 5.685587100982666 and perplexity is 294.59074880794697
At time: 7.8508827686309814 and batch: 450, loss is 5.584728574752807 and perplexity is 266.3279847890589
At time: 8.677694320678711 and batch: 500, loss is 5.540756139755249 and perplexity is 254.87064444281953
At time: 9.540038585662842 and batch: 550, loss is 5.479784889221191 and perplexity is 239.79511931101044
At time: 10.35798454284668 and batch: 600, loss is 5.482879495620727 and perplexity is 240.53834021676673
At time: 11.175799369812012 and batch: 650, loss is 5.538126955032348 and perplexity is 254.20142257759264
At time: 11.993670463562012 and batch: 700, loss is 5.483031263351441 and perplexity is 240.57484894516435
At time: 12.814991474151611 and batch: 750, loss is 5.41538987159729 and perplexity is 224.84018739599242
At time: 13.632798194885254 and batch: 800, loss is 5.396830129623413 and perplexity is 220.7056977443586
At time: 14.45170545578003 and batch: 850, loss is 5.401251411437988 and perplexity is 221.68366016281834
At time: 15.273298501968384 and batch: 900, loss is 5.397860174179077 and perplexity is 220.93315157040126
At time: 16.089701175689697 and batch: 950, loss is 5.4357947254180905 and perplexity is 229.4751455590071
At time: 16.908890962600708 and batch: 1000, loss is 5.387080783843994 and perplexity is 218.56441658742438
At time: 17.726683378219604 and batch: 1050, loss is 5.281283645629883 and perplexity is 196.6221065372294
At time: 18.54386854171753 and batch: 1100, loss is 5.366873540878296 and perplexity is 214.192156753207
At time: 19.36086630821228 and batch: 1150, loss is 5.255986270904541 and perplexity is 191.71047110347664
At time: 20.178602695465088 and batch: 1200, loss is 5.344231472015381 and perplexity is 209.39689537044634
At time: 20.996680974960327 and batch: 1250, loss is 5.292159185409546 and perplexity is 198.77214831916856
At time: 21.814353466033936 and batch: 1300, loss is 5.306774730682373 and perplexity is 201.69864573471563
At time: 22.632657527923584 and batch: 1350, loss is 5.243923816680908 and perplexity is 189.41186361647988
At time: 23.451565980911255 and batch: 1400, loss is 5.246482229232788 and perplexity is 189.89707773010744
At time: 24.269201278686523 and batch: 1450, loss is 5.198559923171997 and perplexity is 181.01138379298746
At time: 25.0876784324646 and batch: 1500, loss is 5.173802967071533 and perplexity is 176.58510952183514
At time: 25.91560697555542 and batch: 1550, loss is 5.166268167495727 and perplexity is 175.25957619870204
At time: 26.733586311340332 and batch: 1600, loss is 5.206404466629028 and perplexity is 182.4369194874794
At time: 27.55176019668579 and batch: 1650, loss is 5.18052004814148 and perplexity is 177.77523864032435
At time: 28.369970560073853 and batch: 1700, loss is 5.1934007549285885 and perplexity is 180.07992046410408
At time: 29.188199996948242 and batch: 1750, loss is 5.195653600692749 and perplexity is 180.48607007456872
At time: 30.00745177268982 and batch: 1800, loss is 5.1636097240448 and perplexity is 174.79427728560321
At time: 30.831881284713745 and batch: 1850, loss is 5.14845905303955 and perplexity is 172.16598715164926
At time: 31.650089025497437 and batch: 1900, loss is 5.214852437973023 and perplexity is 183.98466982564398
At time: 32.46666669845581 and batch: 1950, loss is 5.140240745544434 and perplexity is 170.7568723295157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.801044694767442 and perplexity of 121.63742514665734
finished 1 epochs...
Completing Train Step...
At time: 35.241520404815674 and batch: 50, loss is 5.011346664428711 and perplexity is 150.10674351245078
At time: 36.081756591796875 and batch: 100, loss is 4.970077743530274 and perplexity is 144.03808496486272
At time: 36.89492583274841 and batch: 150, loss is 4.913998613357544 and perplexity is 136.18286979260273
At time: 37.735389947891235 and batch: 200, loss is 4.882209300994873 and perplexity is 131.9217971245673
At time: 38.55650353431702 and batch: 250, loss is 4.886607465744018 and perplexity is 132.50328873291426
At time: 39.370702505111694 and batch: 300, loss is 4.890895986557007 and perplexity is 133.07275204930792
At time: 40.189258098602295 and batch: 350, loss is 4.890272712707519 and perplexity is 132.9898371249124
At time: 41.006765842437744 and batch: 400, loss is 4.837424354553223 and perplexity is 126.14403065589296
At time: 41.82689666748047 and batch: 450, loss is 4.823116512298584 and perplexity is 124.352032150419
At time: 42.643476247787476 and batch: 500, loss is 4.816953372955322 and perplexity is 123.58799011588417
At time: 43.464295387268066 and batch: 550, loss is 4.775514917373657 and perplexity is 118.57135335428264
At time: 44.278815031051636 and batch: 600, loss is 4.761627445220947 and perplexity is 116.93607818740635
At time: 45.09386396408081 and batch: 650, loss is 4.838962545394898 and perplexity is 126.3382135554718
At time: 45.91039276123047 and batch: 700, loss is 4.84447862625122 and perplexity is 127.03703095139954
At time: 46.734190940856934 and batch: 750, loss is 4.79578803062439 and perplexity is 120.9996956887282
At time: 47.55785655975342 and batch: 800, loss is 4.766049013137818 and perplexity is 117.45426375115457
At time: 48.37571144104004 and batch: 850, loss is 4.76746973991394 and perplexity is 117.62125276342765
At time: 49.193376541137695 and batch: 900, loss is 4.762928247451782 and perplexity is 117.08828787466535
At time: 50.0107045173645 and batch: 950, loss is 4.82360993385315 and perplexity is 124.41340526359937
At time: 50.82912063598633 and batch: 1000, loss is 4.793684072494507 and perplexity is 120.74538501858332
At time: 51.64761304855347 and batch: 1050, loss is 4.705759439468384 and perplexity is 110.58223357916712
At time: 52.469992876052856 and batch: 1100, loss is 4.778795003890991 and perplexity is 118.9609162024105
At time: 53.29608964920044 and batch: 1150, loss is 4.718953094482422 and perplexity is 112.05088455257761
At time: 54.124391317367554 and batch: 1200, loss is 4.80031678199768 and perplexity is 121.54891592901517
At time: 54.94269371032715 and batch: 1250, loss is 4.770917177200317 and perplexity is 118.02744441370206
At time: 55.76065969467163 and batch: 1300, loss is 4.773022127151489 and perplexity is 118.27614793946492
At time: 56.57748103141785 and batch: 1350, loss is 4.679842977523804 and perplexity is 107.75315157626855
At time: 57.40361762046814 and batch: 1400, loss is 4.685846366882324 and perplexity is 108.40198133995007
At time: 58.220677614212036 and batch: 1450, loss is 4.626606540679932 and perplexity is 102.16677639084196
At time: 59.03853702545166 and batch: 1500, loss is 4.627057609558105 and perplexity is 102.21287103920429
At time: 59.85656714439392 and batch: 1550, loss is 4.625340309143066 and perplexity is 102.03749146615444
At time: 60.67509841918945 and batch: 1600, loss is 4.692181692123413 and perplexity is 109.09092317953098
At time: 61.49361705780029 and batch: 1650, loss is 4.662797470092773 and perplexity is 105.93200966840227
At time: 62.31133317947388 and batch: 1700, loss is 4.681100435256958 and perplexity is 107.88873183534754
At time: 63.129472494125366 and batch: 1750, loss is 4.679933691024781 and perplexity is 107.76292668524977
At time: 63.94842505455017 and batch: 1800, loss is 4.639729394912719 and perplexity is 103.51633174685075
At time: 64.76708912849426 and batch: 1850, loss is 4.661045894622803 and perplexity is 105.74662416453016
At time: 65.58525061607361 and batch: 1900, loss is 4.740932178497315 and perplexity is 114.54092451696098
At time: 66.40350866317749 and batch: 1950, loss is 4.6723952293396 and perplexity is 106.95361430917653
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.603810013172239 and perplexity of 99.86407517999318
finished 2 epochs...
Completing Train Step...
At time: 69.18206787109375 and batch: 50, loss is 4.637673320770264 and perplexity is 103.30371314852803
At time: 70.00384283065796 and batch: 100, loss is 4.6134507369995115 and perplexity is 100.83149295996489
At time: 70.82283306121826 and batch: 150, loss is 4.572747249603271 and perplexity is 96.80970520153852
At time: 71.64242005348206 and batch: 200, loss is 4.557048788070679 and perplexity is 95.30180856438368
At time: 72.46189022064209 and batch: 250, loss is 4.55763916015625 and perplexity is 95.35808870334138
At time: 73.28176069259644 and batch: 300, loss is 4.565813884735108 and perplexity is 96.14080972037968
At time: 74.1016755104065 and batch: 350, loss is 4.582741641998291 and perplexity is 97.78211058919538
At time: 74.92265510559082 and batch: 400, loss is 4.533910274505615 and perplexity is 93.1219825945592
At time: 75.74285578727722 and batch: 450, loss is 4.549479894638061 and perplexity is 94.58320228921444
At time: 76.56270384788513 and batch: 500, loss is 4.548453378677368 and perplexity is 94.48616093822022
At time: 77.38291454315186 and batch: 550, loss is 4.511598320007324 and perplexity is 91.06725686971514
At time: 78.20055055618286 and batch: 600, loss is 4.504769287109375 and perplexity is 90.4474742432627
At time: 79.04694271087646 and batch: 650, loss is 4.575882301330567 and perplexity is 97.11368488208764
At time: 79.86607074737549 and batch: 700, loss is 4.5920492362976075 and perplexity is 98.69647547193262
At time: 80.68643450737 and batch: 750, loss is 4.547956752777099 and perplexity is 94.43924831345781
At time: 81.50583362579346 and batch: 800, loss is 4.516941890716553 and perplexity is 91.55518367076414
At time: 82.3260281085968 and batch: 850, loss is 4.525521259307862 and perplexity is 92.34404848017415
At time: 83.1455614566803 and batch: 900, loss is 4.511705446243286 and perplexity is 91.07701308472694
At time: 83.96537947654724 and batch: 950, loss is 4.585450105667114 and perplexity is 98.04730886100957
At time: 84.78492712974548 and batch: 1000, loss is 4.5609805870056155 and perplexity is 95.67725371755289
At time: 85.60459637641907 and batch: 1050, loss is 4.482014780044556 and perplexity is 88.41262534093822
At time: 86.4254584312439 and batch: 1100, loss is 4.545016660690307 and perplexity is 94.16199600019227
At time: 87.2519006729126 and batch: 1150, loss is 4.498495569229126 and perplexity is 89.8818085756463
At time: 88.07200932502747 and batch: 1200, loss is 4.575495624542237 and perplexity is 97.0761405335464
At time: 88.90145134925842 and batch: 1250, loss is 4.561860780715943 and perplexity is 95.761505307917
At time: 89.7215645313263 and batch: 1300, loss is 4.556290187835693 and perplexity is 95.22954000495099
At time: 90.54538536071777 and batch: 1350, loss is 4.4559550380706785 and perplexity is 86.1383770037176
At time: 91.36473560333252 and batch: 1400, loss is 4.467391996383667 and perplexity is 87.12919319217478
At time: 92.18442988395691 and batch: 1450, loss is 4.406826438903809 and perplexity is 82.00879018555237
At time: 93.00400280952454 and batch: 1500, loss is 4.412924480438233 and perplexity is 82.51041109241073
At time: 93.82373380661011 and batch: 1550, loss is 4.415522680282593 and perplexity is 82.72506837016579
At time: 94.64503169059753 and batch: 1600, loss is 4.492629909515381 and perplexity is 89.35613568841354
At time: 95.46493816375732 and batch: 1650, loss is 4.458522005081177 and perplexity is 86.3597754154615
At time: 96.28483366966248 and batch: 1700, loss is 4.475454568862915 and perplexity is 87.834518173432
At time: 97.10348153114319 and batch: 1750, loss is 4.47867280960083 and perplexity is 88.11764614062723
At time: 97.9217882156372 and batch: 1800, loss is 4.436349220275879 and perplexity is 84.46601129715289
At time: 98.74170970916748 and batch: 1850, loss is 4.470483617782593 and perplexity is 87.39898049553062
At time: 99.56187272071838 and batch: 1900, loss is 4.548458480834961 and perplexity is 94.48664302273355
At time: 100.38146328926086 and batch: 1950, loss is 4.4856532955169675 and perplexity is 88.73490199494765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.530221202761628 and perplexity of 92.77908180152397
finished 3 epochs...
Completing Train Step...
At time: 103.16287231445312 and batch: 50, loss is 4.454148054122925 and perplexity is 85.98286688364585
At time: 104.00898933410645 and batch: 100, loss is 4.4355151653289795 and perplexity is 84.39559137371064
At time: 104.82750511169434 and batch: 150, loss is 4.396995487213135 and perplexity is 81.2065157531035
At time: 105.64600086212158 and batch: 200, loss is 4.386617612838745 and perplexity is 80.3681226280839
At time: 106.4647810459137 and batch: 250, loss is 4.383463277816772 and perplexity is 80.11501404872159
At time: 107.28356432914734 and batch: 300, loss is 4.391996231079101 and perplexity is 80.8015566716008
At time: 108.1015875339508 and batch: 350, loss is 4.411478023529053 and perplexity is 82.39114961229645
At time: 108.91945934295654 and batch: 400, loss is 4.3674600887298585 and perplexity is 78.84312263398833
At time: 109.73766946792603 and batch: 450, loss is 4.3958336544036865 and perplexity is 81.11222214607061
At time: 110.55646252632141 and batch: 500, loss is 4.398724136352539 and perplexity is 81.34701472840352
At time: 111.37482690811157 and batch: 550, loss is 4.357689456939697 and perplexity is 78.07652667556216
At time: 112.19329762458801 and batch: 600, loss is 4.358315086364746 and perplexity is 78.12538893129468
At time: 113.01144552230835 and batch: 650, loss is 4.424009561538696 and perplexity is 83.43013387394723
At time: 113.84077191352844 and batch: 700, loss is 4.438924388885498 and perplexity is 84.6838058264841
At time: 114.65957427024841 and batch: 750, loss is 4.4042920398712155 and perplexity is 81.80121034322791
At time: 115.48629522323608 and batch: 800, loss is 4.377984867095948 and perplexity is 79.67731114971558
At time: 116.30485963821411 and batch: 850, loss is 4.384044761657715 and perplexity is 80.16161318181625
At time: 117.12374544143677 and batch: 900, loss is 4.367904090881348 and perplexity is 78.87813692270252
At time: 117.94538378715515 and batch: 950, loss is 4.44405385017395 and perplexity is 85.11930411114662
At time: 118.77176213264465 and batch: 1000, loss is 4.4177533149719235 and perplexity is 82.90980373931143
At time: 119.5899486541748 and batch: 1050, loss is 4.3484883308410645 and perplexity is 77.3614296024938
At time: 120.4351441860199 and batch: 1100, loss is 4.403068590164184 and perplexity is 81.70119187265884
At time: 121.25335049629211 and batch: 1150, loss is 4.363643140792846 and perplexity is 78.54275614599844
At time: 122.07185769081116 and batch: 1200, loss is 4.437622528076172 and perplexity is 84.57363103017953
At time: 122.88997220993042 and batch: 1250, loss is 4.4275880050659175 and perplexity is 83.72921870642027
At time: 123.70884203910828 and batch: 1300, loss is 4.420849456787109 and perplexity is 83.16690205059294
At time: 124.52573990821838 and batch: 1350, loss is 4.321937198638916 and perplexity is 75.33442477319014
At time: 125.34337401390076 and batch: 1400, loss is 4.334501600265503 and perplexity is 76.28692802859432
At time: 126.16030550003052 and batch: 1450, loss is 4.272620429992676 and perplexity is 71.70929883008938
At time: 126.97903370857239 and batch: 1500, loss is 4.282596278190613 and perplexity is 72.42823997118052
At time: 127.79604959487915 and batch: 1550, loss is 4.2816086769104 and perplexity is 72.35674505870607
At time: 128.61235523223877 and batch: 1600, loss is 4.367910737991333 and perplexity is 78.87866123609665
At time: 129.429025888443 and batch: 1650, loss is 4.331443433761597 and perplexity is 76.05398626950057
At time: 130.24510264396667 and batch: 1700, loss is 4.353642897605896 and perplexity is 77.76122375403004
At time: 131.06176161766052 and batch: 1750, loss is 4.353473882675171 and perplexity is 77.74808205678698
At time: 131.8779752254486 and batch: 1800, loss is 4.311289510726929 and perplexity is 74.53654266719727
At time: 132.69506168365479 and batch: 1850, loss is 4.347942972183228 and perplexity is 77.31925137925245
At time: 133.51166081428528 and batch: 1900, loss is 4.421670637130737 and perplexity is 83.2352251247407
At time: 134.32833003997803 and batch: 1950, loss is 4.35912841796875 and perplexity is 78.18895662649119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499614768804506 and perplexity of 89.98246057196782
finished 4 epochs...
Completing Train Step...
At time: 137.09151911735535 and batch: 50, loss is 4.338097825050354 and perplexity is 76.56176686484463
At time: 137.9498565196991 and batch: 100, loss is 4.3124502086639405 and perplexity is 74.62310730648372
At time: 138.76534962654114 and batch: 150, loss is 4.2805029487609865 and perplexity is 72.27678238553112
At time: 139.5872564315796 and batch: 200, loss is 4.272022562026978 and perplexity is 71.6664389510272
At time: 140.41118955612183 and batch: 250, loss is 4.270852251052856 and perplexity is 71.58261599007935
At time: 141.26291823387146 and batch: 300, loss is 4.278068313598633 and perplexity is 72.10102882442756
At time: 142.08407402038574 and batch: 350, loss is 4.2965663814544675 and perplexity is 73.44717067489478
At time: 142.90025758743286 and batch: 400, loss is 4.251559009552002 and perplexity is 70.21479259445478
At time: 143.71731209754944 and batch: 450, loss is 4.283948774337769 and perplexity is 72.52626516109
At time: 144.53358054161072 and batch: 500, loss is 4.297804489135742 and perplexity is 73.53816249828945
At time: 145.35344886779785 and batch: 550, loss is 4.2552159833908085 and perplexity is 70.47203633419667
At time: 146.17012000083923 and batch: 600, loss is 4.257912211418152 and perplexity is 70.66230139743965
At time: 146.9873354434967 and batch: 650, loss is 4.317118721008301 and perplexity is 74.97230067667579
At time: 147.80382871627808 and batch: 700, loss is 4.331458253860474 and perplexity is 76.05511340544919
At time: 148.62340998649597 and batch: 750, loss is 4.305024366378785 and perplexity is 74.07102027339695
At time: 149.4420177936554 and batch: 800, loss is 4.280119342803955 and perplexity is 72.24906189846487
At time: 150.25967121124268 and batch: 850, loss is 4.285718841552734 and perplexity is 72.65475520973874
At time: 151.08201479911804 and batch: 900, loss is 4.263565578460693 and perplexity is 71.06291265757815
At time: 151.9012565612793 and batch: 950, loss is 4.347694902420044 and perplexity is 77.30007318973608
At time: 152.72019481658936 and batch: 1000, loss is 4.320428247451782 and perplexity is 75.2208345261188
At time: 153.53845310211182 and batch: 1050, loss is 4.254655256271362 and perplexity is 70.43253182892025
At time: 154.35667371749878 and batch: 1100, loss is 4.300550909042358 and perplexity is 73.74040676839108
At time: 155.17538285255432 and batch: 1150, loss is 4.266486330032349 and perplexity is 71.27077317811234
At time: 155.9933261871338 and batch: 1200, loss is 4.3389505100250245 and perplexity is 76.62707777394283
At time: 156.81185340881348 and batch: 1250, loss is 4.330964756011963 and perplexity is 76.01758963032806
At time: 157.6297528743744 and batch: 1300, loss is 4.328959617614746 and perplexity is 75.86531655780755
At time: 158.44871592521667 and batch: 1350, loss is 4.229210786819458 and perplexity is 68.66302102337553
At time: 159.26768326759338 and batch: 1400, loss is 4.240990495681762 and perplexity is 69.47663407491241
At time: 160.08614993095398 and batch: 1450, loss is 4.1761905431747435 and perplexity is 65.11731851001774
At time: 160.9046700000763 and batch: 1500, loss is 4.189763479232788 and perplexity is 66.00717704581879
At time: 161.7223997116089 and batch: 1550, loss is 4.188210563659668 and perplexity is 65.9047530211615
At time: 162.54082345962524 and batch: 1600, loss is 4.275044221878051 and perplexity is 71.88331805469842
At time: 163.3590705394745 and batch: 1650, loss is 4.240533142089844 and perplexity is 69.44486595195018
At time: 164.18732976913452 and batch: 1700, loss is 4.263680634498596 and perplexity is 71.07108934512995
At time: 165.0056540966034 and batch: 1750, loss is 4.260848779678344 and perplexity is 70.87011104318445
At time: 165.8248574733734 and batch: 1800, loss is 4.222277183532714 and perplexity is 68.18858554951045
At time: 166.64346551895142 and batch: 1850, loss is 4.259085350036621 and perplexity is 70.74524671574414
At time: 167.46280980110168 and batch: 1900, loss is 4.330704946517944 and perplexity is 75.99784210423812
At time: 168.2819962501526 and batch: 1950, loss is 4.2688915824890135 and perplexity is 71.442403705017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495438828579215 and perplexity of 89.60748268284023
finished 5 epochs...
Completing Train Step...
At time: 171.06406903266907 and batch: 50, loss is 4.244864430427551 and perplexity is 69.74630402632
At time: 171.88253831863403 and batch: 100, loss is 4.222176036834717 and perplexity is 68.18168884803616
At time: 172.70035862922668 and batch: 150, loss is 4.19632719039917 and perplexity is 66.44185407752633
At time: 173.51821303367615 and batch: 200, loss is 4.1876533460617065 and perplexity is 65.8680399625199
At time: 174.33768773078918 and batch: 250, loss is 4.182828426361084 and perplexity is 65.55099742631111
At time: 175.15675282478333 and batch: 300, loss is 4.190809421539306 and perplexity is 66.07625286318736
At time: 175.97519659996033 and batch: 350, loss is 4.214683923721314 and perplexity is 67.67277273200459
At time: 176.79388308525085 and batch: 400, loss is 4.167106385231018 and perplexity is 64.52846118971726
At time: 177.61124920845032 and batch: 450, loss is 4.203391323089599 and perplexity is 66.91286985117395
At time: 178.42859172821045 and batch: 500, loss is 4.222135791778564 and perplexity is 68.17894492735489
At time: 179.2560520172119 and batch: 550, loss is 4.179406781196594 and perplexity is 65.32708845991
At time: 180.0799536705017 and batch: 600, loss is 4.182920799255371 and perplexity is 65.5570528413406
At time: 180.89795470237732 and batch: 650, loss is 4.241744165420532 and perplexity is 69.5290162485163
At time: 181.71633195877075 and batch: 700, loss is 4.252025675773621 and perplexity is 70.24756711320218
At time: 182.56147742271423 and batch: 750, loss is 4.229722418785095 and perplexity is 68.6981602081869
At time: 183.3797950744629 and batch: 800, loss is 4.205324883460999 and perplexity is 67.04237508740314
At time: 184.19800114631653 and batch: 850, loss is 4.2090102434158325 and perplexity is 67.28990621231348
At time: 185.02685451507568 and batch: 900, loss is 4.184493589401245 and perplexity is 65.6602414537872
At time: 185.84584093093872 and batch: 950, loss is 4.276689996719361 and perplexity is 72.00171921516335
At time: 186.66443061828613 and batch: 1000, loss is 4.246215238571167 and perplexity is 69.84058156288236
At time: 187.48353385925293 and batch: 1050, loss is 4.186225137710571 and perplexity is 65.77403382392794
At time: 188.3034589290619 and batch: 1100, loss is 4.226289615631104 and perplexity is 68.46273725866065
At time: 189.12167096138 and batch: 1150, loss is 4.193027300834656 and perplexity is 66.22296465070539
At time: 189.94998860359192 and batch: 1200, loss is 4.265747685432434 and perplexity is 71.21814884410527
At time: 190.76912188529968 and batch: 1250, loss is 4.256932797431946 and perplexity is 70.59312763156002
At time: 191.58780908584595 and batch: 1300, loss is 4.254602880477905 and perplexity is 70.42884296578494
At time: 192.40613675117493 and batch: 1350, loss is 4.1564142036437985 and perplexity is 63.84218658950901
At time: 193.22488451004028 and batch: 1400, loss is 4.170375409126282 and perplexity is 64.73975143954578
At time: 194.05127620697021 and batch: 1450, loss is 4.104891705513 and perplexity is 60.63617762828197
At time: 194.87022924423218 and batch: 1500, loss is 4.116072425842285 and perplexity is 61.31793795581891
At time: 195.68824982643127 and batch: 1550, loss is 4.1162242555618285 and perplexity is 61.32724854793614
At time: 196.5068953037262 and batch: 1600, loss is 4.203794112205506 and perplexity is 66.93982705553384
At time: 197.3257555961609 and batch: 1650, loss is 4.167133293151855 and perplexity is 64.53019753980338
At time: 198.1436061859131 and batch: 1700, loss is 4.192897825241089 and perplexity is 66.2143909481041
At time: 198.96043419837952 and batch: 1750, loss is 4.188211364746094 and perplexity is 65.90480581658568
At time: 199.7786159515381 and batch: 1800, loss is 4.1521403598785405 and perplexity is 63.569917291048085
At time: 200.59681868553162 and batch: 1850, loss is 4.190859174728393 and perplexity is 66.07954044927348
At time: 201.41572189331055 and batch: 1900, loss is 4.262175483703613 and perplexity is 70.96419710315352
At time: 202.24355697631836 and batch: 1950, loss is 4.197539048194885 and perplexity is 66.5224209642968
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.490296261809593 and perplexity of 89.1478530710164
finished 6 epochs...
Completing Train Step...
At time: 205.025053024292 and batch: 50, loss is 4.173605542182923 and perplexity is 64.9492075541914
At time: 205.88037252426147 and batch: 100, loss is 4.153589024543762 and perplexity is 63.66207552106723
At time: 206.69929480552673 and batch: 150, loss is 4.130727438926697 and perplexity is 62.2231700315392
At time: 207.5194547176361 and batch: 200, loss is 4.122747464179993 and perplexity is 61.728606632226395
At time: 208.33879160881042 and batch: 250, loss is 4.114813799858093 and perplexity is 61.24081015352048
At time: 209.15936183929443 and batch: 300, loss is 4.1260499048233035 and perplexity is 61.93279867209091
At time: 209.98254704475403 and batch: 350, loss is 4.144389281272888 and perplexity is 63.07908655636514
At time: 210.80409836769104 and batch: 400, loss is 4.100932631492615 and perplexity is 60.39658910004502
At time: 211.62455368041992 and batch: 450, loss is 4.137688927650451 and perplexity is 62.65784717262408
At time: 212.44511079788208 and batch: 500, loss is 4.160745706558227 and perplexity is 64.1193189733547
At time: 213.26515126228333 and batch: 550, loss is 4.115994892120361 and perplexity is 61.31318393216947
At time: 214.0855848789215 and batch: 600, loss is 4.122946109771728 and perplexity is 61.740869965806134
At time: 214.9132297039032 and batch: 650, loss is 4.1778483581542964 and perplexity is 65.22536050814865
At time: 215.73625683784485 and batch: 700, loss is 4.1884147691726685 and perplexity is 65.91821250926543
At time: 216.5560269355774 and batch: 750, loss is 4.168205409049988 and perplexity is 64.59941849030581
At time: 217.37576842308044 and batch: 800, loss is 4.144549894332886 and perplexity is 63.08921869513394
At time: 218.2047634124756 and batch: 850, loss is 4.146851916313171 and perplexity is 63.23461875614742
At time: 219.02303266525269 and batch: 900, loss is 4.123173580169678 and perplexity is 61.75491578351032
At time: 219.84265613555908 and batch: 950, loss is 4.216564297676086 and perplexity is 67.80014256522603
At time: 220.662743806839 and batch: 1000, loss is 4.187568974494934 and perplexity is 65.8624828072243
At time: 221.48219799995422 and batch: 1050, loss is 4.131814360618591 and perplexity is 62.29083851329329
At time: 222.30289363861084 and batch: 1100, loss is 4.1622527933120725 and perplexity is 64.21602520368023
At time: 223.1230845451355 and batch: 1150, loss is 4.132470183372497 and perplexity is 62.33170366123243
At time: 223.94551038742065 and batch: 1200, loss is 4.204332056045533 and perplexity is 66.9758466105311
At time: 224.79335641860962 and batch: 1250, loss is 4.196827807426453 and perplexity is 66.47512432813389
At time: 225.6135597229004 and batch: 1300, loss is 4.1931169939041135 and perplexity is 66.22890465805827
At time: 226.43448209762573 and batch: 1350, loss is 4.099625272750854 and perplexity is 60.317680683355846
At time: 227.25486969947815 and batch: 1400, loss is 4.112931213378906 and perplexity is 61.12562748703482
At time: 228.0752980709076 and batch: 1450, loss is 4.044004564285278 and perplexity is 57.054363805986114
At time: 228.9070529937744 and batch: 1500, loss is 4.05846640586853 and perplexity is 57.88547015608372
At time: 229.73374366760254 and batch: 1550, loss is 4.057171273231506 and perplexity is 57.81054932115685
At time: 230.5533983707428 and batch: 1600, loss is 4.1490340375900265 and perplexity is 63.37275502339992
At time: 231.37446451187134 and batch: 1650, loss is 4.108874559402466 and perplexity is 60.878164242967266
At time: 232.19513201713562 and batch: 1700, loss is 4.136479349136352 and perplexity is 62.58210340519613
At time: 233.02054691314697 and batch: 1750, loss is 4.131360206604004 and perplexity is 62.26255530186361
At time: 233.84683990478516 and batch: 1800, loss is 4.0986718702316285 and perplexity is 60.260201059601485
At time: 234.66807746887207 and batch: 1850, loss is 4.134559240341186 and perplexity is 62.462054248631794
At time: 235.48865222930908 and batch: 1900, loss is 4.2032195615768435 and perplexity is 66.90137778240128
At time: 236.30896162986755 and batch: 1950, loss is 4.141000475883484 and perplexity is 62.8656855992657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495664800599564 and perplexity of 89.6277337547421
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 239.06397080421448 and batch: 50, loss is 4.144104743003846 and perplexity is 63.06114069552678
At time: 239.9096167087555 and batch: 100, loss is 4.135674481391907 and perplexity is 62.531753354069885
At time: 240.72781229019165 and batch: 150, loss is 4.114854202270508 and perplexity is 61.24328447997296
At time: 241.55105900764465 and batch: 200, loss is 4.102995104789734 and perplexity is 60.52128399804744
At time: 242.37466669082642 and batch: 250, loss is 4.094708371162414 and perplexity is 60.02183250760874
At time: 243.19250679016113 and batch: 300, loss is 4.096610670089722 and perplexity is 60.136120645839426
At time: 244.01014590263367 and batch: 350, loss is 4.10605945110321 and perplexity is 60.707026616060105
At time: 244.82667422294617 and batch: 400, loss is 4.053473114967346 and perplexity is 57.59715159292418
At time: 245.67059516906738 and batch: 450, loss is 4.082518362998963 and perplexity is 59.29460732503703
At time: 246.48866295814514 and batch: 500, loss is 4.106182913780213 and perplexity is 60.714522130777645
At time: 247.30732440948486 and batch: 550, loss is 4.055407018661499 and perplexity is 57.70864671282537
At time: 248.12574982643127 and batch: 600, loss is 4.045343708992005 and perplexity is 57.13081903615528
At time: 248.9442629814148 and batch: 650, loss is 4.100825915336609 and perplexity is 60.39014415211653
At time: 249.76287746429443 and batch: 700, loss is 4.1073641157150265 and perplexity is 60.78628061407611
At time: 250.5804204940796 and batch: 750, loss is 4.075176429748535 and perplexity is 58.86086447982553
At time: 251.39883065223694 and batch: 800, loss is 4.04857684135437 and perplexity is 57.3158294564965
At time: 252.21693181991577 and batch: 850, loss is 4.053127946853638 and perplexity is 57.57727432345104
At time: 253.03534197807312 and batch: 900, loss is 4.0198756170272825 and perplexity is 55.69417798853071
At time: 253.86199116706848 and batch: 950, loss is 4.103732252120972 and perplexity is 60.56591354828569
At time: 254.68793654441833 and batch: 1000, loss is 4.069304466247559 and perplexity is 58.51624840865493
At time: 255.51275181770325 and batch: 1050, loss is 4.007715620994568 and perplexity is 55.021037989498694
At time: 256.34085845947266 and batch: 1100, loss is 4.031668787002563 and perplexity is 56.35487710726572
At time: 257.1591799259186 and batch: 1150, loss is 3.9984404039382935 and perplexity is 54.51306533949889
At time: 257.97697925567627 and batch: 1200, loss is 4.060637559890747 and perplexity is 58.01128495967616
At time: 258.7931592464447 and batch: 1250, loss is 4.048550853729248 and perplexity is 57.31433997356117
At time: 259.60947370529175 and batch: 1300, loss is 4.043385076522827 and perplexity is 57.01903027129002
At time: 260.4281802177429 and batch: 1350, loss is 3.9480499696731566 and perplexity is 51.834189975501225
At time: 261.24533867836 and batch: 1400, loss is 3.957715620994568 and perplexity is 52.337630302182774
At time: 262.06364488601685 and batch: 1450, loss is 3.8723247861862182 and perplexity is 48.05397153361739
At time: 262.8889162540436 and batch: 1500, loss is 3.886807951927185 and perplexity is 48.75500953843415
At time: 263.7144742012024 and batch: 1550, loss is 3.8788912010192873 and perplexity is 48.37055210725013
At time: 264.5424110889435 and batch: 1600, loss is 3.961118669509888 and perplexity is 52.516041195563425
At time: 265.36775636672974 and batch: 1650, loss is 3.9183442306518557 and perplexity is 50.317062316580994
At time: 266.1896650791168 and batch: 1700, loss is 3.9348625421524046 and perplexity is 51.155117800969535
At time: 267.0072269439697 and batch: 1750, loss is 3.9240077781677245 and perplexity is 50.602843894755175
At time: 267.82591462135315 and batch: 1800, loss is 3.8891808366775513 and perplexity is 48.87083692524381
At time: 268.64402770996094 and batch: 1850, loss is 3.913040852546692 and perplexity is 50.050918265035975
At time: 269.4728147983551 and batch: 1900, loss is 3.9734936475753786 and perplexity is 53.16996384755631
At time: 270.29269099235535 and batch: 1950, loss is 3.9107908821105957 and perplexity is 49.93843177173635
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3847477402797965 and perplexity of 80.21798489392741
finished 8 epochs...
Completing Train Step...
At time: 273.09283685684204 and batch: 50, loss is 4.051525135040283 and perplexity is 57.48506270665999
At time: 273.91142988204956 and batch: 100, loss is 4.037086858749389 and perplexity is 56.661040533456415
At time: 274.73005080223083 and batch: 150, loss is 4.01421694278717 and perplexity is 55.37991277902504
At time: 275.5487401485443 and batch: 200, loss is 4.0060419082641605 and perplexity is 54.929025600408565
At time: 276.36743330955505 and batch: 250, loss is 3.998653745651245 and perplexity is 54.52469649089743
At time: 277.1866309642792 and batch: 300, loss is 4.003450403213501 and perplexity is 54.78686104278539
At time: 278.00511837005615 and batch: 350, loss is 4.019508099555969 and perplexity is 55.673713165889765
At time: 278.82305574417114 and batch: 400, loss is 3.96923171043396 and perplexity is 52.94383901102579
At time: 279.6418459415436 and batch: 450, loss is 4.0042226600646975 and perplexity is 54.82918691269923
At time: 280.46036076545715 and batch: 500, loss is 4.030928959846497 and perplexity is 56.313199657760435
At time: 281.27936148643494 and batch: 550, loss is 3.9847311067581175 and perplexity is 53.77082892129654
At time: 282.0975878238678 and batch: 600, loss is 3.981020698547363 and perplexity is 53.571686873779804
At time: 282.91602969169617 and batch: 650, loss is 4.034223275184631 and perplexity is 56.4990190008379
At time: 283.7347981929779 and batch: 700, loss is 4.045969309806824 and perplexity is 57.166571305253896
At time: 284.55333852767944 and batch: 750, loss is 4.015176677703858 and perplexity is 55.433088328136144
At time: 285.3714692592621 and batch: 800, loss is 3.9907588386535644 and perplexity is 54.095923870105466
At time: 286.21617817878723 and batch: 850, loss is 3.9978847312927246 and perplexity is 54.48278233476151
At time: 287.0348756313324 and batch: 900, loss is 3.9643649530410765 and perplexity is 52.686800171285256
At time: 287.8531632423401 and batch: 950, loss is 4.052015991210937 and perplexity is 57.513286530762436
At time: 288.67151641845703 and batch: 1000, loss is 4.020973987579346 and perplexity is 55.75538444108386
At time: 289.4895701408386 and batch: 1050, loss is 3.9626408290863036 and perplexity is 52.596039860505456
At time: 290.308057308197 and batch: 1100, loss is 3.987177920341492 and perplexity is 53.90255720745011
At time: 291.1250174045563 and batch: 1150, loss is 3.9592575216293335 and perplexity is 52.41839197480435
At time: 291.94419169425964 and batch: 1200, loss is 4.021614909172058 and perplexity is 55.791130724941056
At time: 292.7665412425995 and batch: 1250, loss is 4.012422432899475 and perplexity is 55.280622093666906
At time: 293.5899267196655 and batch: 1300, loss is 4.010144839286804 and perplexity is 55.154858575340704
At time: 294.415549993515 and batch: 1350, loss is 3.9160325717926026 and perplexity is 50.200880771491526
At time: 295.2371745109558 and batch: 1400, loss is 3.930308599472046 and perplexity is 50.92268995991122
At time: 296.062105178833 and batch: 1450, loss is 3.8473325824737548 and perplexity is 46.86788014310984
At time: 296.88056683540344 and batch: 1500, loss is 3.86341507434845 and perplexity is 47.62772617596162
At time: 297.6992464065552 and batch: 1550, loss is 3.858097858428955 and perplexity is 47.375151364615824
At time: 298.5174605846405 and batch: 1600, loss is 3.943950276374817 and perplexity is 51.622120700755204
At time: 299.3451178073883 and batch: 1650, loss is 3.9030630207061767 and perplexity is 49.554001816131425
At time: 300.16549587249756 and batch: 1700, loss is 3.923127222061157 and perplexity is 50.55830486398961
At time: 300.9914445877075 and batch: 1750, loss is 3.9150079870224 and perplexity is 50.14947205439389
At time: 301.8098473548889 and batch: 1800, loss is 3.8850608348846434 and perplexity is 48.66990319737805
At time: 302.63847970962524 and batch: 1850, loss is 3.911563696861267 and perplexity is 49.97703984495765
At time: 303.45740509033203 and batch: 1900, loss is 3.974411826133728 and perplexity is 53.218805787689085
At time: 304.27599835395813 and batch: 1950, loss is 3.9125180292129516 and perplexity is 50.024757316464964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381868584211483 and perplexity of 79.98735696215338
finished 9 epochs...
Completing Train Step...
At time: 307.03433060646057 and batch: 50, loss is 4.014754042625428 and perplexity is 55.409665310546046
At time: 307.8976137638092 and batch: 100, loss is 3.998627791404724 and perplexity is 54.52328136184759
At time: 308.7192986011505 and batch: 150, loss is 3.974122929573059 and perplexity is 53.20343327837355
At time: 309.53922033309937 and batch: 200, loss is 3.967125720977783 and perplexity is 52.83245716995714
At time: 310.358939409256 and batch: 250, loss is 3.959119215011597 and perplexity is 52.41114266562839
At time: 311.1788339614868 and batch: 300, loss is 3.965550718307495 and perplexity is 52.74931140342659
At time: 312.0100827217102 and batch: 350, loss is 3.981557536125183 and perplexity is 53.60045388931744
At time: 312.83753776550293 and batch: 400, loss is 3.933144063949585 and perplexity is 51.0672843376276
At time: 313.66032314300537 and batch: 450, loss is 3.968638095855713 and perplexity is 52.91242010264413
At time: 314.481320142746 and batch: 500, loss is 3.9984933376312255 and perplexity is 54.515950993733846
At time: 315.3110291957855 and batch: 550, loss is 3.951940393447876 and perplexity is 52.036239715238956
At time: 316.13425970077515 and batch: 600, loss is 3.950158505439758 and perplexity is 51.943599525436476
At time: 316.9558310508728 and batch: 650, loss is 4.002877674102783 and perplexity is 54.75549199642183
At time: 317.78202652931213 and batch: 700, loss is 4.016425824165344 and perplexity is 55.5023756402614
At time: 318.60363364219666 and batch: 750, loss is 3.9854774618148805 and perplexity is 53.810976031504
At time: 319.4301087856293 and batch: 800, loss is 3.961121530532837 and perplexity is 52.51619144537742
At time: 320.250292301178 and batch: 850, loss is 3.969763355255127 and perplexity is 52.97199381236271
At time: 321.07068824768066 and batch: 900, loss is 3.9358633184432983 and perplexity is 51.206338255856046
At time: 321.8902499675751 and batch: 950, loss is 4.025924048423767 and perplexity is 56.03206120492592
At time: 322.7119927406311 and batch: 1000, loss is 3.9954233312606813 and perplexity is 54.34884331894817
At time: 323.5350296497345 and batch: 1050, loss is 3.9385120677948 and perplexity is 51.342150798392375
At time: 324.35974621772766 and batch: 1100, loss is 3.963440022468567 and perplexity is 52.6380910687807
At time: 325.1806945800781 and batch: 1150, loss is 3.937213535308838 and perplexity is 51.27552461517519
At time: 326.000390291214 and batch: 1200, loss is 3.9994735383987425 and perplexity is 54.56941376858574
At time: 326.81981325149536 and batch: 1250, loss is 3.9917081880569456 and perplexity is 54.147304188235154
At time: 327.638619184494 and batch: 1300, loss is 3.9894349241256712 and perplexity is 54.02435287798599
At time: 328.461954832077 and batch: 1350, loss is 3.8969267320632937 and perplexity is 49.25085520635096
At time: 329.28191661834717 and batch: 1400, loss is 3.9133694219589232 and perplexity is 50.067366167822854
At time: 330.10699582099915 and batch: 1450, loss is 3.8307794618606565 and perplexity is 46.09845622250554
At time: 330.92884373664856 and batch: 1500, loss is 3.8475815868377685 and perplexity is 46.87955190289681
At time: 331.7493977546692 and batch: 1550, loss is 3.842880268096924 and perplexity is 46.65967345130252
At time: 332.5692777633667 and batch: 1600, loss is 3.930054030418396 and perplexity is 50.90972826881153
At time: 333.39032649993896 and batch: 1650, loss is 3.88995566368103 and perplexity is 48.90871804313745
At time: 334.2104604244232 and batch: 1700, loss is 3.9116250467300415 and perplexity is 49.98010602384775
At time: 335.03043270111084 and batch: 1750, loss is 3.9040388917922972 and perplexity is 49.60238373712464
At time: 335.86026430130005 and batch: 1800, loss is 3.876393394470215 and perplexity is 48.24988259270471
At time: 336.6804618835449 and batch: 1850, loss is 3.903476595878601 and perplexity is 49.574500359528976
At time: 337.49975323677063 and batch: 1900, loss is 3.9664610481262206 and perplexity is 52.79735253783531
At time: 338.3209960460663 and batch: 1950, loss is 3.905316462516785 and perplexity is 49.66579478787813
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382322799327762 and perplexity of 80.02369668119688
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 341.0952961444855 and batch: 50, loss is 4.0082643032073975 and perplexity is 55.051235337991365
At time: 341.9422655105591 and batch: 100, loss is 4.011600985527038 and perplexity is 55.235230617808085
At time: 342.7692346572876 and batch: 150, loss is 3.9903024005889893 and perplexity is 54.071238065511814
At time: 343.5877492427826 and batch: 200, loss is 3.9910799837112427 and perplexity is 54.11329929856405
At time: 344.4069242477417 and batch: 250, loss is 3.9860442543029784 and perplexity is 53.84148433361736
At time: 345.2258517742157 and batch: 300, loss is 3.9827291345596314 and perplexity is 53.6632888986917
At time: 346.0447368621826 and batch: 350, loss is 3.9926358699798583 and perplexity is 54.197558970127304
At time: 346.86834931373596 and batch: 400, loss is 3.945110363960266 and perplexity is 51.68204163215888
At time: 347.6869204044342 and batch: 450, loss is 3.9781846237182616 and perplexity is 53.419968804676095
At time: 348.5123736858368 and batch: 500, loss is 4.006323876380921 and perplexity is 54.94451601811191
At time: 349.36615347862244 and batch: 550, loss is 3.961228413581848 and perplexity is 52.52180483602436
At time: 350.1860234737396 and batch: 600, loss is 3.9530111026763914 and perplexity is 52.09198523561522
At time: 351.0055878162384 and batch: 650, loss is 3.9981542110443113 and perplexity is 54.4974663198403
At time: 351.82413721084595 and batch: 700, loss is 4.019391012191773 and perplexity is 55.66719485917327
At time: 352.64248037338257 and batch: 750, loss is 3.9804471588134764 and perplexity is 53.54097019220706
At time: 353.462144613266 and batch: 800, loss is 3.9500843286514282 and perplexity is 51.93974665894778
At time: 354.28112292289734 and batch: 850, loss is 3.959208960533142 and perplexity is 52.41584654203447
At time: 355.1077802181244 and batch: 900, loss is 3.9230239391326904 and perplexity is 50.55308332385757
At time: 355.93098425865173 and batch: 950, loss is 4.013294610977173 and perplexity is 55.32885767232791
At time: 356.7496325969696 and batch: 1000, loss is 3.9752044010162355 and perplexity is 53.261002396210564
At time: 357.5682771205902 and batch: 1050, loss is 3.918808755874634 and perplexity is 50.34044129080435
At time: 358.3870506286621 and batch: 1100, loss is 3.9394435119628906 and perplexity is 51.389995424170486
At time: 359.20632338523865 and batch: 1150, loss is 3.917041687965393 and perplexity is 50.2515648609325
At time: 360.02519130706787 and batch: 1200, loss is 3.9690140676498413 and perplexity is 52.93231742034252
At time: 360.8440659046173 and batch: 1250, loss is 3.960405554771423 and perplexity is 52.4786045824678
At time: 361.66232776641846 and batch: 1300, loss is 3.9556962347030638 and perplexity is 52.23204705158517
At time: 362.4871530532837 and batch: 1350, loss is 3.865584626197815 and perplexity is 47.73116916926132
At time: 363.3057050704956 and batch: 1400, loss is 3.8754349040985105 and perplexity is 48.20365770139927
At time: 364.1243026256561 and batch: 1450, loss is 3.7868043279647825 and perplexity is 44.11519707497006
At time: 364.9429974555969 and batch: 1500, loss is 3.806668372154236 and perplexity is 45.000264708054786
At time: 365.76216769218445 and batch: 1550, loss is 3.798949737548828 and perplexity is 44.65426116292383
At time: 366.58247470855713 and batch: 1600, loss is 3.885483283996582 and perplexity is 48.69046809826814
At time: 367.4018759727478 and batch: 1650, loss is 3.841007237434387 and perplexity is 46.572360247904214
At time: 368.22430896759033 and batch: 1700, loss is 3.8581284379959104 and perplexity is 47.37660009837972
At time: 369.043452501297 and batch: 1750, loss is 3.848592643737793 and perplexity is 46.92697376637973
At time: 369.8617992401123 and batch: 1800, loss is 3.821924729347229 and perplexity is 45.69206860547134
At time: 370.68007802963257 and batch: 1850, loss is 3.841343960762024 and perplexity is 46.588044888566785
At time: 371.4987361431122 and batch: 1900, loss is 3.905751371383667 and perplexity is 49.68739958012944
At time: 372.31742119789124 and batch: 1950, loss is 3.8447992277145384 and perplexity is 46.74929744533665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350074093840843 and perplexity of 77.48420381484125
finished 11 epochs...
Completing Train Step...
At time: 375.10975217819214 and batch: 50, loss is 3.989354286193848 and perplexity is 54.019996641543116
At time: 375.92831087112427 and batch: 100, loss is 3.9810382652282716 and perplexity is 53.572627958774696
At time: 376.7472610473633 and batch: 150, loss is 3.9568165159225464 and perplexity is 52.2905944215885
At time: 377.5671718120575 and batch: 200, loss is 3.955961236953735 and perplexity is 52.24589049580194
At time: 378.38571524620056 and batch: 250, loss is 3.951352400779724 and perplexity is 52.00565178142988
At time: 379.20346212387085 and batch: 300, loss is 3.949218773841858 and perplexity is 51.894809412049874
At time: 380.0199658870697 and batch: 350, loss is 3.9620301151275634 and perplexity is 52.56392853120476
At time: 380.8365948200226 and batch: 400, loss is 3.914976229667664 and perplexity is 50.14787946510837
At time: 381.6553010940552 and batch: 450, loss is 3.950155916213989 and perplexity is 51.94346503190417
At time: 382.4740128517151 and batch: 500, loss is 3.9780876731872556 and perplexity is 53.414789961384024
At time: 383.29096126556396 and batch: 550, loss is 3.9346671056747438 and perplexity is 51.14512120181407
At time: 384.10941338539124 and batch: 600, loss is 3.9288151979446413 and perplexity is 50.846698693805244
At time: 384.92982244491577 and batch: 650, loss is 3.975678105354309 and perplexity is 53.28623834081211
At time: 385.75395464897156 and batch: 700, loss is 3.998698410987854 and perplexity is 54.52713190920868
At time: 386.5799195766449 and batch: 750, loss is 3.961279511451721 and perplexity is 52.52448865694155
At time: 387.4002766609192 and batch: 800, loss is 3.930781536102295 and perplexity is 50.94677886111696
At time: 388.2188923358917 and batch: 850, loss is 3.9419920110702513 and perplexity is 51.52112980859226
At time: 389.0375316143036 and batch: 900, loss is 3.905220742225647 and perplexity is 49.66104099106248
At time: 389.8561460971832 and batch: 950, loss is 3.9970296096801756 and perplexity is 54.43621284420195
At time: 390.72930216789246 and batch: 1000, loss is 3.9599532413482668 and perplexity is 52.45487317260885
At time: 391.5483727455139 and batch: 1050, loss is 3.9047110176086424 and perplexity is 49.63573398631284
At time: 392.36690497398376 and batch: 1100, loss is 3.92653395652771 and perplexity is 50.73083730297822
At time: 393.1858286857605 and batch: 1150, loss is 3.905106029510498 and perplexity is 49.655344564945764
At time: 394.0036709308624 and batch: 1200, loss is 3.9585049247741697 and perplexity is 52.3789568990697
At time: 394.8259115219116 and batch: 1250, loss is 3.9515183353424073 and perplexity is 52.01428203252396
At time: 395.64502024650574 and batch: 1300, loss is 3.9482322788238524 and perplexity is 51.843640684101814
At time: 396.4694607257843 and batch: 1350, loss is 3.857873463630676 and perplexity is 47.36452181973383
At time: 397.2908947467804 and batch: 1400, loss is 3.870097999572754 and perplexity is 47.94708464439682
At time: 398.1096305847168 and batch: 1450, loss is 3.783532428741455 and perplexity is 43.97109247234941
At time: 398.9276022911072 and batch: 1500, loss is 3.8040575885772707 and perplexity is 44.88293198781228
At time: 399.7457523345947 and batch: 1550, loss is 3.797200846672058 and perplexity is 44.576233983366265
At time: 400.5643935203552 and batch: 1600, loss is 3.884831199645996 and perplexity is 48.65872815568316
At time: 401.3829174041748 and batch: 1650, loss is 3.841108865737915 and perplexity is 46.57709355838257
At time: 402.20230865478516 and batch: 1700, loss is 3.8599225854873658 and perplexity is 47.46167700403671
At time: 403.0212981700897 and batch: 1750, loss is 3.8516024208068846 and perplexity is 47.068426259396595
At time: 403.84034395217896 and batch: 1800, loss is 3.8263274908065794 and perplexity is 45.89368338934539
At time: 404.6590898036957 and batch: 1850, loss is 3.8464226484298707 and perplexity is 46.82525286035205
At time: 405.47786927223206 and batch: 1900, loss is 3.911662373542786 and perplexity is 49.98197165672509
At time: 406.2973017692566 and batch: 1950, loss is 3.8504147815704344 and perplexity is 47.0125591311364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.348277673055959 and perplexity of 77.3451345314832
finished 12 epochs...
Completing Train Step...
At time: 409.053585767746 and batch: 50, loss is 3.9776838493347166 and perplexity is 53.393224149806876
At time: 409.89916133880615 and batch: 100, loss is 3.967732138633728 and perplexity is 52.8645054211225
At time: 410.71732926368713 and batch: 150, loss is 3.9426461601257325 and perplexity is 51.55484333262663
At time: 411.56289982795715 and batch: 200, loss is 3.941697287559509 and perplexity is 51.50594755773071
At time: 412.3804020881653 and batch: 250, loss is 3.9368876886367796 and perplexity is 51.258819377942075
At time: 413.19830775260925 and batch: 300, loss is 3.934817967414856 and perplexity is 51.15283762583877
At time: 414.01644921302795 and batch: 350, loss is 3.947666759490967 and perplexity is 51.814330391557476
At time: 414.8351180553436 and batch: 400, loss is 3.901383428573608 and perplexity is 49.470841162083794
At time: 415.65768218040466 and batch: 450, loss is 3.9368361616134644 and perplexity is 51.25617823160667
At time: 416.47877764701843 and batch: 500, loss is 3.964851765632629 and perplexity is 52.71245501306061
At time: 417.2971842288971 and batch: 550, loss is 3.9221005868911742 and perplexity is 50.5064265646814
At time: 418.1149742603302 and batch: 600, loss is 3.9170809412002563 and perplexity is 50.253537436124965
At time: 418.93318486213684 and batch: 650, loss is 3.96434730052948 and perplexity is 52.685870125143104
At time: 419.75635957717896 and batch: 700, loss is 3.987915692329407 and perplexity is 53.94233967762631
At time: 420.574116230011 and batch: 750, loss is 3.9507621145248413 and perplexity is 51.974962618593686
At time: 421.39170479774475 and batch: 800, loss is 3.9203470754623413 and perplexity is 50.41794057174375
At time: 422.21089363098145 and batch: 850, loss is 3.9326978302001954 and perplexity is 51.04450147548552
At time: 423.02981758117676 and batch: 900, loss is 3.895228180885315 and perplexity is 49.16727111424835
At time: 423.8480966091156 and batch: 950, loss is 3.9884498167037963 and perplexity is 53.97115929200382
At time: 424.666996717453 and batch: 1000, loss is 3.9518004417419434 and perplexity is 52.0289576643001
At time: 425.4854910373688 and batch: 1050, loss is 3.8969776153564455 and perplexity is 49.253361315813414
At time: 426.3045153617859 and batch: 1100, loss is 3.919300956726074 and perplexity is 50.365224997650024
At time: 427.12296891212463 and batch: 1150, loss is 3.898398199081421 and perplexity is 49.323379560913644
At time: 427.9423100948334 and batch: 1200, loss is 3.952211046218872 and perplexity is 52.05032537378537
At time: 428.76133012771606 and batch: 1250, loss is 3.9459287118911743 and perplexity is 51.724352834274725
At time: 429.5781533718109 and batch: 1300, loss is 3.9432395982742308 and perplexity is 51.585447023200665
At time: 430.3959457874298 and batch: 1350, loss is 3.8530647373199463 and perplexity is 47.13730554574434
At time: 431.21401476860046 and batch: 1400, loss is 3.8661409187316895 and perplexity is 47.75772904914978
At time: 432.0382807254791 and batch: 1450, loss is 3.7805944204330446 and perplexity is 43.84209462849556
At time: 432.86362385749817 and batch: 1500, loss is 3.801348476409912 and perplexity is 44.761503646422376
At time: 433.6815917491913 and batch: 1550, loss is 3.7947438240051268 and perplexity is 44.46684360841022
At time: 434.50111961364746 and batch: 1600, loss is 3.8829262161254885 and perplexity is 48.56612231472345
At time: 435.330598115921 and batch: 1650, loss is 3.839214758872986 and perplexity is 46.48895506393967
At time: 436.14970088005066 and batch: 1700, loss is 3.858681364059448 and perplexity is 47.40280309886929
At time: 436.9684691429138 and batch: 1750, loss is 3.851241698265076 and perplexity is 47.05145067895871
At time: 437.7873811721802 and batch: 1800, loss is 3.8268010997772217 and perplexity is 45.91542419740888
At time: 438.60589575767517 and batch: 1850, loss is 3.8471174335479734 and perplexity is 46.85779765370068
At time: 439.4251072406769 and batch: 1900, loss is 3.9128152036666872 and perplexity is 50.03962560552216
At time: 440.2438955307007 and batch: 1950, loss is 3.851283540725708 and perplexity is 47.053419468620646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3477087686228195 and perplexity of 77.30114505565682
finished 13 epochs...
Completing Train Step...
At time: 443.01478815078735 and batch: 50, loss is 3.967853937149048 and perplexity is 52.8709446315311
At time: 443.8744230270386 and batch: 100, loss is 3.957331714630127 and perplexity is 52.317541409183676
At time: 444.6976647377014 and batch: 150, loss is 3.9319498634338377 and perplexity is 51.00633615974977
At time: 445.5184073448181 and batch: 200, loss is 3.9309489583969115 and perplexity is 50.95530920180189
At time: 446.33861231803894 and batch: 250, loss is 3.9260681104660033 and perplexity is 50.70721004597315
At time: 447.1592803001404 and batch: 300, loss is 3.92403039932251 and perplexity is 50.60398860246675
At time: 447.9795455932617 and batch: 350, loss is 3.9368701457977293 and perplexity is 51.257920160611256
At time: 448.79946875572205 and batch: 400, loss is 3.8911370754241945 and perplexity is 48.96653352219509
At time: 449.6198842525482 and batch: 450, loss is 3.9269355821609495 and perplexity is 50.75121619970452
At time: 450.441942691803 and batch: 500, loss is 3.955333185195923 and perplexity is 52.21308767445065
At time: 451.26180958747864 and batch: 550, loss is 3.9127779102325437 and perplexity is 50.0377594908372
At time: 452.0823059082031 and batch: 600, loss is 3.908330364227295 and perplexity is 49.81570841072567
At time: 452.9310803413391 and batch: 650, loss is 3.9558995819091796 and perplexity is 52.242669372395845
At time: 453.7515995502472 and batch: 700, loss is 3.9796246767044066 and perplexity is 53.496951806770426
At time: 454.57213282585144 and batch: 750, loss is 3.942550277709961 and perplexity is 51.54990036667873
At time: 455.39190649986267 and batch: 800, loss is 3.9122594451904296 and perplexity is 50.01182338581836
At time: 456.2117383480072 and batch: 850, loss is 3.9252132606506347 and perplexity is 50.663881519157655
At time: 457.0321967601776 and batch: 900, loss is 3.887746591567993 and perplexity is 48.80079440745986
At time: 457.8533458709717 and batch: 950, loss is 3.9818588733673095 and perplexity is 53.61660813608503
At time: 458.673095703125 and batch: 1000, loss is 3.9453160858154295 and perplexity is 51.69267485134736
At time: 459.49381136894226 and batch: 1050, loss is 3.890697546005249 and perplexity is 48.94501601930248
At time: 460.3160390853882 and batch: 1100, loss is 3.9135704231262207 and perplexity is 50.07743077833144
At time: 461.146767616272 and batch: 1150, loss is 3.892897357940674 and perplexity is 49.05280436329693
At time: 461.9653708934784 and batch: 1200, loss is 3.947195219993591 and perplexity is 51.789903647787625
At time: 462.7893979549408 and batch: 1250, loss is 3.9411629390716554 and perplexity is 51.4784327844312
At time: 463.62260150909424 and batch: 1300, loss is 3.938680577278137 and perplexity is 51.35080316667942
At time: 464.45026540756226 and batch: 1350, loss is 3.8486316299438474 and perplexity is 46.92880330671169
At time: 465.2803280353546 and batch: 1400, loss is 3.8622290229797365 and perplexity is 47.571270732288106
At time: 466.1001513004303 and batch: 1450, loss is 3.7774503374099733 and perplexity is 43.704467911363594
At time: 466.9337441921234 and batch: 1500, loss is 3.7982852458953857 and perplexity is 44.624598635432854
At time: 467.7591829299927 and batch: 1550, loss is 3.791829614639282 and perplexity is 44.33744655292915
At time: 468.57940101623535 and batch: 1600, loss is 3.880325813293457 and perplexity is 48.43999489483918
At time: 469.40497732162476 and batch: 1650, loss is 3.8365687131881714 and perplexity is 46.36610576910246
At time: 470.2257544994354 and batch: 1700, loss is 3.856779708862305 and perplexity is 47.31274496889233
At time: 471.05570697784424 and batch: 1750, loss is 3.849859580993652 and perplexity is 46.98646497560618
At time: 471.87571597099304 and batch: 1800, loss is 3.8258500576019285 and perplexity is 45.871777450738925
At time: 472.7043921947479 and batch: 1850, loss is 3.8462404012680054 and perplexity is 46.81671986849502
At time: 473.52492690086365 and batch: 1900, loss is 3.9122199487686156 and perplexity is 50.009848136754115
At time: 474.346107006073 and batch: 1950, loss is 3.850478687286377 and perplexity is 47.015563598386265
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347431981286337 and perplexity of 77.27975203840451
finished 14 epochs...
Completing Train Step...
At time: 477.11952781677246 and batch: 50, loss is 3.9593197107315063 and perplexity is 52.42165192890437
At time: 477.9476990699768 and batch: 100, loss is 3.9481974458694458 and perplexity is 51.84183484838107
At time: 478.766893863678 and batch: 150, loss is 3.92272451877594 and perplexity is 50.537948967494174
At time: 479.58575344085693 and batch: 200, loss is 3.921948719024658 and perplexity is 50.498756843840475
At time: 480.40432810783386 and batch: 250, loss is 3.9170644283294678 and perplexity is 50.25270761280602
At time: 481.222758769989 and batch: 300, loss is 3.9150060510635374 and perplexity is 50.14937496717299
At time: 482.05603075027466 and batch: 350, loss is 3.927817077636719 and perplexity is 50.79597289068654
At time: 482.880074262619 and batch: 400, loss is 3.882502222061157 and perplexity is 48.54553493190689
At time: 483.69899821281433 and batch: 450, loss is 3.9186198234558107 and perplexity is 50.330931247872655
At time: 484.51708936691284 and batch: 500, loss is 3.9473199892044066 and perplexity is 51.79636583632667
At time: 485.33718705177307 and batch: 550, loss is 3.9050308752059935 and perplexity is 49.65161289228744
At time: 486.16334652900696 and batch: 600, loss is 3.900940489768982 and perplexity is 49.44893345907968
At time: 486.9817614555359 and batch: 650, loss is 3.9485178804397583 and perplexity is 51.85844942625532
At time: 487.8064475059509 and batch: 700, loss is 3.972591371536255 and perplexity is 53.12201149955608
At time: 488.6288809776306 and batch: 750, loss is 3.9355131673812864 and perplexity is 51.18841144086384
At time: 489.4586868286133 and batch: 800, loss is 3.905289692878723 and perplexity is 49.664465270323035
At time: 490.28379559516907 and batch: 850, loss is 3.9188777208328247 and perplexity is 50.343913136949766
At time: 491.1110374927521 and batch: 900, loss is 3.8815001344680784 and perplexity is 48.49691241972917
At time: 491.9350960254669 and batch: 950, loss is 3.976129159927368 and perplexity is 53.31027876366059
At time: 492.7594301700592 and batch: 1000, loss is 3.9397365856170654 and perplexity is 51.405058685132126
At time: 493.5776813030243 and batch: 1050, loss is 3.8851530265808107 and perplexity is 48.67439036514274
At time: 494.42371225357056 and batch: 1100, loss is 3.908359627723694 and perplexity is 49.817166213859466
At time: 495.2558083534241 and batch: 1150, loss is 3.8879126930236816 and perplexity is 48.80890096368645
At time: 496.0744025707245 and batch: 1200, loss is 3.9422963523864745 and perplexity is 51.5368122033308
At time: 496.8936893939972 and batch: 1250, loss is 3.93661479473114 and perplexity is 51.24483306699987
At time: 497.71187686920166 and batch: 1300, loss is 3.9343001556396486 and perplexity is 51.1263569407778
At time: 498.53008699417114 and batch: 1350, loss is 3.8442736673355102 and perplexity is 46.72473432211954
At time: 499.34805250167847 and batch: 1400, loss is 3.8583798360824586 and perplexity is 47.388511982241276
At time: 500.16962361335754 and batch: 1450, loss is 3.7742445564270017 and perplexity is 43.56458529557538
At time: 500.9942009449005 and batch: 1500, loss is 3.795131506919861 and perplexity is 44.48408598602099
At time: 501.82533073425293 and batch: 1550, loss is 3.788704695701599 and perplexity is 44.199111881435925
At time: 502.6443486213684 and batch: 1600, loss is 3.877379536628723 and perplexity is 48.29748730472131
At time: 503.4782290458679 and batch: 1650, loss is 3.833629069328308 and perplexity is 46.23000607130189
At time: 504.3013150691986 and batch: 1700, loss is 3.854305067062378 and perplexity is 47.19580762122287
At time: 505.12021231651306 and batch: 1750, loss is 3.847793011665344 and perplexity is 46.889464451917256
At time: 505.9382448196411 and batch: 1800, loss is 3.8241978740692137 and perplexity is 45.79605142928712
At time: 506.75624537467957 and batch: 1850, loss is 3.844616355895996 and perplexity is 46.74074909794698
At time: 507.5753402709961 and batch: 1900, loss is 3.9107895421981813 and perplexity is 49.93836485865649
At time: 508.3927683830261 and batch: 1950, loss is 3.8489290571212766 and perplexity is 46.942763284154765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347459234193314 and perplexity of 77.28185816499695
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 511.1963517665863 and batch: 50, loss is 3.9608667612075807 and perplexity is 52.50281363491808
At time: 512.0464055538177 and batch: 100, loss is 3.9610374546051026 and perplexity is 52.51177628346758
At time: 512.8671102523804 and batch: 150, loss is 3.9379446840286256 and perplexity is 51.3130283580901
At time: 513.6884548664093 and batch: 200, loss is 3.93965238571167 and perplexity is 51.40073056627014
At time: 514.50843334198 and batch: 250, loss is 3.9398880338668825 and perplexity is 51.41284448085942
At time: 515.3548460006714 and batch: 300, loss is 3.932622985839844 and perplexity is 51.04068122538699
At time: 516.1736054420471 and batch: 350, loss is 3.94655038356781 and perplexity is 51.75651839659771
At time: 516.9926328659058 and batch: 400, loss is 3.9022563886642456 and perplexity is 49.514046087412595
At time: 517.8117544651031 and batch: 450, loss is 3.936980490684509 and perplexity is 51.26357652207749
At time: 518.6309766769409 and batch: 500, loss is 3.9621938562393186 and perplexity is 52.572536111988875
At time: 519.4498915672302 and batch: 550, loss is 3.920801739692688 and perplexity is 50.44086901786664
At time: 520.2686927318573 and batch: 600, loss is 3.9135385036468504 and perplexity is 50.0758323583233
At time: 521.0896265506744 and batch: 650, loss is 3.9568575954437257 and perplexity is 52.29274253829102
At time: 521.9067225456238 and batch: 700, loss is 3.9822634506225585 and perplexity is 53.6383045848894
At time: 522.7247667312622 and batch: 750, loss is 3.9463077116012575 and perplexity is 51.74396006433571
At time: 523.5443046092987 and batch: 800, loss is 3.912410545349121 and perplexity is 50.019380751213575
At time: 524.363142490387 and batch: 850, loss is 3.92561327457428 and perplexity is 50.68415183112445
At time: 525.1823825836182 and batch: 900, loss is 3.8887543439865113 and perplexity is 48.84999831456363
At time: 526.0002331733704 and batch: 950, loss is 3.984480423927307 and perplexity is 53.757351187076395
At time: 526.8189392089844 and batch: 1000, loss is 3.940002918243408 and perplexity is 51.418751352740166
At time: 527.6375668048859 and batch: 1050, loss is 3.8839896154403686 and perplexity is 48.617794965380604
At time: 528.4564669132233 and batch: 1100, loss is 3.9047338151931763 and perplexity is 49.63686557405298
At time: 529.2748718261719 and batch: 1150, loss is 3.885798578262329 and perplexity is 48.70582234408169
At time: 530.0937478542328 and batch: 1200, loss is 3.93579137802124 and perplexity is 51.20265458277396
At time: 530.9124903678894 and batch: 1250, loss is 3.9309750843048095 and perplexity is 50.95664047290726
At time: 531.731109380722 and batch: 1300, loss is 3.9284461069107057 and perplexity is 50.82793509616298
At time: 532.5497584342957 and batch: 1350, loss is 3.838694524765015 and perplexity is 46.464776213748074
At time: 533.3680379390717 and batch: 1400, loss is 3.8506229162216186 and perplexity is 47.0223450920959
At time: 534.1871664524078 and batch: 1450, loss is 3.7625126457214355 and perplexity is 43.0564758462128
At time: 535.0057384967804 and batch: 1500, loss is 3.786717290878296 and perplexity is 44.11135758383836
At time: 535.824718952179 and batch: 1550, loss is 3.7807641935348513 and perplexity is 43.84953846875438
At time: 536.6429195404053 and batch: 1600, loss is 3.8702362108230592 and perplexity is 47.95371192888611
At time: 537.4614019393921 and batch: 1650, loss is 3.8220951175689697 and perplexity is 45.69985465909576
At time: 538.2804663181305 and batch: 1700, loss is 3.8401192665100097 and perplexity is 46.53102370166616
At time: 539.0999410152435 and batch: 1750, loss is 3.833228096961975 and perplexity is 46.211472832278545
At time: 539.9281384944916 and batch: 1800, loss is 3.809140453338623 and perplexity is 45.11164663158776
At time: 540.7478587627411 and batch: 1850, loss is 3.8279547452926637 and perplexity is 45.96842488674942
At time: 541.5668773651123 and batch: 1900, loss is 3.8946653175354005 and perplexity is 49.139604446329955
At time: 542.3848733901978 and batch: 1950, loss is 3.8363430595397947 and perplexity is 46.35564426855692
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.334227947856105 and perplexity of 76.26605478307098
finished 16 epochs...
Completing Train Step...
At time: 545.1170697212219 and batch: 50, loss is 3.9609086751937865 and perplexity is 52.50501428324319
At time: 545.962366104126 and batch: 100, loss is 3.953415036201477 and perplexity is 52.11303118513628
At time: 546.7804458141327 and batch: 150, loss is 3.9251323080062868 and perplexity is 50.65978030997985
At time: 547.5990347862244 and batch: 200, loss is 3.9234029769897463 and perplexity is 50.57224848816016
At time: 548.41756772995 and batch: 250, loss is 3.9234151315689085 and perplexity is 50.57286317629345
At time: 549.2432820796967 and batch: 300, loss is 3.917064695358276 and perplexity is 50.25272103172844
At time: 550.0651223659515 and batch: 350, loss is 3.93214280128479 and perplexity is 51.01617816205023
At time: 550.8836557865143 and batch: 400, loss is 3.888950409889221 and perplexity is 48.85957707258378
At time: 551.7023963928223 and batch: 450, loss is 3.92531436920166 and perplexity is 50.66900432978299
At time: 552.5209121704102 and batch: 500, loss is 3.951889123916626 and perplexity is 52.033571910009876
At time: 553.340083360672 and batch: 550, loss is 3.9114278745651245 and perplexity is 49.970252309611254
At time: 554.1587479114532 and batch: 600, loss is 3.90546190738678 and perplexity is 49.67301894829004
At time: 554.9778919219971 and batch: 650, loss is 3.9485784101486208 and perplexity is 51.86158849810375
At time: 555.7959804534912 and batch: 700, loss is 3.97444917678833 and perplexity is 53.22079358204488
At time: 556.6435420513153 and batch: 750, loss is 3.9398004245758056 and perplexity is 51.4083404353032
At time: 557.4623379707336 and batch: 800, loss is 3.905731840133667 and perplexity is 49.68642913258345
At time: 558.281042098999 and batch: 850, loss is 3.919852809906006 and perplexity is 50.39302687779537
At time: 559.1107683181763 and batch: 900, loss is 3.8825974464416504 and perplexity is 48.55015787050124
At time: 559.9292984008789 and batch: 950, loss is 3.9792759895324705 and perplexity is 53.47830135771286
At time: 560.7478668689728 and batch: 1000, loss is 3.9351208782196045 and perplexity is 51.16833472004933
At time: 561.5663394927979 and batch: 1050, loss is 3.880088896751404 and perplexity is 48.42852001809936
At time: 562.3847937583923 and batch: 1100, loss is 3.900834074020386 and perplexity is 49.443671593785986
At time: 563.2032082080841 and batch: 1150, loss is 3.8822243881225584 and perplexity is 48.532049208218
At time: 564.0218615531921 and batch: 1200, loss is 3.933352828025818 and perplexity is 51.077946464963915
At time: 564.8407642841339 and batch: 1250, loss is 3.928792715072632 and perplexity is 50.845555526837295
At time: 565.6594443321228 and batch: 1300, loss is 3.9264456033706665 and perplexity is 50.72635527134678
At time: 566.4779946804047 and batch: 1350, loss is 3.8366911363601686 and perplexity is 46.371782402312505
At time: 567.2978069782257 and batch: 1400, loss is 3.8493865442276003 and perplexity is 46.96424390627165
At time: 568.125634431839 and batch: 1450, loss is 3.7622055339813234 and perplexity is 43.04325472727691
At time: 568.948967218399 and batch: 1500, loss is 3.7868122053146362 and perplexity is 44.115544587180025
At time: 569.7766191959381 and batch: 1550, loss is 3.781441287994385 and perplexity is 43.879238802135575
At time: 570.5988450050354 and batch: 1600, loss is 3.871375460624695 and perplexity is 48.00837431683395
At time: 571.426616191864 and batch: 1650, loss is 3.8235475397109986 and perplexity is 45.76627836584446
At time: 572.2499053478241 and batch: 1700, loss is 3.8419261312484743 and perplexity is 46.61517496972236
At time: 573.0728595256805 and batch: 1750, loss is 3.835774383544922 and perplexity is 46.329290420545114
At time: 573.8956191539764 and batch: 1800, loss is 3.811961441040039 and perplexity is 45.239085699434604
At time: 574.7176637649536 and batch: 1850, loss is 3.8309128093719482 and perplexity is 46.10460374678662
At time: 575.5403208732605 and batch: 1900, loss is 3.8977578020095827 and perplexity is 49.2918031248774
At time: 576.3700375556946 and batch: 1950, loss is 3.8392451286315916 and perplexity is 46.49036694372191
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333374875090843 and perplexity of 76.20102203160003
finished 17 epochs...
Completing Train Step...
At time: 579.2731115818024 and batch: 50, loss is 3.957985920906067 and perplexity is 52.35177907114086
At time: 580.0967445373535 and batch: 100, loss is 3.949448676109314 and perplexity is 51.90674151795947
At time: 580.9216587543488 and batch: 150, loss is 3.9205652189254763 and perplexity is 50.42894011559988
At time: 581.7402992248535 and batch: 200, loss is 3.9186310338974 and perplexity is 50.3314954830002
At time: 582.5599768161774 and batch: 250, loss is 3.918505516052246 and perplexity is 50.32517837860675
At time: 583.3787121772766 and batch: 300, loss is 3.912202377319336 and perplexity is 50.008969398964474
At time: 584.198148727417 and batch: 350, loss is 3.927423882484436 and perplexity is 50.776004086466195
At time: 585.02308344841 and batch: 400, loss is 3.8841659450531005 and perplexity is 48.626368478198614
At time: 585.8465261459351 and batch: 450, loss is 3.920817427635193 and perplexity is 50.44166033752677
At time: 586.6658229827881 and batch: 500, loss is 3.9474011278152465 and perplexity is 51.80056869200182
At time: 587.4848625659943 and batch: 550, loss is 3.907149839401245 and perplexity is 49.756934429117564
At time: 588.3033635616302 and batch: 600, loss is 3.9016034269332884 and perplexity is 49.481725863255754
At time: 589.1213593482971 and batch: 650, loss is 3.944745879173279 and perplexity is 51.66320774676437
At time: 589.939309835434 and batch: 700, loss is 3.970888113975525 and perplexity is 53.031608043868665
At time: 590.7584927082062 and batch: 750, loss is 3.936523871421814 and perplexity is 51.240173929006886
At time: 591.5773227214813 and batch: 800, loss is 3.902484431266785 and perplexity is 49.52533868689256
At time: 592.3957281112671 and batch: 850, loss is 3.9168346548080444 and perplexity is 50.241162197682904
At time: 593.214430809021 and batch: 900, loss is 3.8796917629241943 and perplexity is 48.4092912330517
At time: 594.0335466861725 and batch: 950, loss is 3.976561598777771 and perplexity is 53.333337184643014
At time: 594.8524634838104 and batch: 1000, loss is 3.9324944591522217 and perplexity is 51.03412155725036
At time: 595.670994758606 and batch: 1050, loss is 3.8778483057022095 and perplexity is 48.32013298047839
At time: 596.4896771907806 and batch: 1100, loss is 3.898673267364502 and perplexity is 49.33694872438292
At time: 597.307368516922 and batch: 1150, loss is 3.8803324556350707 and perplexity is 48.44031665090164
At time: 598.1530861854553 and batch: 1200, loss is 3.9319622802734373 and perplexity is 51.00696950117647
At time: 598.9716658592224 and batch: 1250, loss is 3.9275115013122557 and perplexity is 50.78045321533651
At time: 599.790390253067 and batch: 1300, loss is 3.925376057624817 and perplexity is 50.672130117174476
At time: 600.6093597412109 and batch: 1350, loss is 3.8356216192245483 and perplexity is 46.32221349854498
At time: 601.4287536144257 and batch: 1400, loss is 3.84870352268219 and perplexity is 46.93217726816876
At time: 602.2485167980194 and batch: 1450, loss is 3.761938910484314 and perplexity is 43.03177991397426
At time: 603.0678911209106 and batch: 1500, loss is 3.786675796508789 and perplexity is 44.109527248841886
At time: 603.8966970443726 and batch: 1550, loss is 3.7816230058670044 and perplexity is 43.88721316858338
At time: 604.7194635868073 and batch: 1600, loss is 3.8716807317733766 and perplexity is 48.02303212559722
At time: 605.5439066886902 and batch: 1650, loss is 3.823892283439636 and perplexity is 45.78205872322749
At time: 606.3630137443542 and batch: 1700, loss is 3.8424578523635864 and perplexity is 46.63996783339883
At time: 607.1915543079376 and batch: 1750, loss is 3.8366707706451417 and perplexity is 46.37083801742338
At time: 608.0108625888824 and batch: 1800, loss is 3.8129181146621702 and perplexity is 45.282385447973816
At time: 608.8401010036469 and batch: 1850, loss is 3.8318924474716187 and perplexity is 46.14979170349533
At time: 609.6705605983734 and batch: 1900, loss is 3.89878803730011 and perplexity is 49.34261144776008
At time: 610.4883043766022 and batch: 1950, loss is 3.8401432847976684 and perplexity is 46.532141310599954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333048975744913 and perplexity of 76.17619221459104
finished 18 epochs...
Completing Train Step...
At time: 613.2703318595886 and batch: 50, loss is 3.955228590965271 and perplexity is 52.20762677230977
At time: 614.1265406608582 and batch: 100, loss is 3.946167664527893 and perplexity is 51.736713981572606
At time: 614.9440984725952 and batch: 150, loss is 3.917004714012146 and perplexity is 50.2497068962711
At time: 615.7721400260925 and batch: 200, loss is 3.915094504356384 and perplexity is 50.1538110407128
At time: 616.5928666591644 and batch: 250, loss is 3.914874725341797 and perplexity is 50.14278949674089
At time: 617.4117066860199 and batch: 300, loss is 3.908603882789612 and perplexity is 49.829335795257336
At time: 618.2316896915436 and batch: 350, loss is 3.9239221811294556 and perplexity is 50.59851262656431
At time: 619.0845222473145 and batch: 400, loss is 3.880610771179199 and perplexity is 48.453800220244524
At time: 619.9058556556702 and batch: 450, loss is 3.9174732303619386 and perplexity is 50.273255221481236
At time: 620.7251152992249 and batch: 500, loss is 3.944079751968384 and perplexity is 51.62880493818759
At time: 621.5433430671692 and batch: 550, loss is 3.904017028808594 and perplexity is 49.60129929287198
At time: 622.3623163700104 and batch: 600, loss is 3.8987261486053466 and perplexity is 49.33955779243571
At time: 623.1812815666199 and batch: 650, loss is 3.9418964910507204 and perplexity is 51.51620874430051
At time: 624.0003387928009 and batch: 700, loss is 3.9681740903854372 and perplexity is 52.88787414544057
At time: 624.8191843032837 and batch: 750, loss is 3.933979787826538 and perplexity is 51.10998032502273
At time: 625.638019323349 and batch: 800, loss is 3.899958372116089 and perplexity is 49.400392628917565
At time: 626.4566617012024 and batch: 850, loss is 3.9144882440567015 and perplexity is 50.12341399139419
At time: 627.275515794754 and batch: 900, loss is 3.8774205303192137 and perplexity is 48.29946723754945
At time: 628.1033136844635 and batch: 950, loss is 3.9744506216049196 and perplexity is 53.2208704763859
At time: 628.9211637973785 and batch: 1000, loss is 3.9304369688034058 and perplexity is 50.929227291159854
At time: 629.7425546646118 and batch: 1050, loss is 3.8760243368148806 and perplexity is 48.23207888966341
At time: 630.5620303153992 and batch: 1100, loss is 3.8969586181640623 and perplexity is 49.25242564912053
At time: 631.3904039859772 and batch: 1150, loss is 3.8788027000427245 and perplexity is 48.36627145557548
At time: 632.2090535163879 and batch: 1200, loss is 3.930752744674683 and perplexity is 50.945312051737176
At time: 633.0304505825043 and batch: 1250, loss is 3.9263904905319214 and perplexity is 50.72355967494592
At time: 633.8565530776978 and batch: 1300, loss is 3.92439058303833 and perplexity is 50.622218617997184
At time: 634.6804800033569 and batch: 1350, loss is 3.8346262550354004 and perplexity is 46.27612896531835
At time: 635.5106327533722 and batch: 1400, loss is 3.8479826068878173 and perplexity is 46.89835531316744
At time: 636.3330500125885 and batch: 1450, loss is 3.761485152244568 and perplexity is 43.01225831864468
At time: 637.1523525714874 and batch: 1500, loss is 3.786305546760559 and perplexity is 44.0931987304849
At time: 637.9708158969879 and batch: 1550, loss is 3.7814268493652343 and perplexity is 43.878605250652924
At time: 638.7894718647003 and batch: 1600, loss is 3.8715139627456665 and perplexity is 48.015024038990916
At time: 639.6080210208893 and batch: 1650, loss is 3.8237133550643922 and perplexity is 45.77386774666574
At time: 640.4270451068878 and batch: 1700, loss is 3.8424100923538207 and perplexity is 46.6377403612721
At time: 641.2463862895966 and batch: 1750, loss is 3.8369229936599734 and perplexity is 46.382535285086455
At time: 642.0654683113098 and batch: 1800, loss is 3.8132193374633787 and perplexity is 45.29602758952275
At time: 642.884566783905 and batch: 1850, loss is 3.8322138023376464 and perplexity is 46.16462454680095
At time: 643.7035291194916 and batch: 1900, loss is 3.89916672706604 and perplexity is 49.361300528198015
At time: 644.5228090286255 and batch: 1950, loss is 3.840422306060791 and perplexity is 46.545126578942984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332867573582849 and perplexity of 76.16237494190497
finished 19 epochs...
Completing Train Step...
At time: 647.2777261734009 and batch: 50, loss is 3.9526622676849366 and perplexity is 52.07381689745097
At time: 648.1236305236816 and batch: 100, loss is 3.9432911348342894 and perplexity is 51.588105628196416
At time: 648.9414212703705 and batch: 150, loss is 3.9140004205703733 and perplexity is 50.09896857584294
At time: 649.7604722976685 and batch: 200, loss is 3.9120336246490477 and perplexity is 50.000530963864286
At time: 650.578813791275 and batch: 250, loss is 3.911804404258728 and perplexity is 49.989071136103824
At time: 651.3960218429565 and batch: 300, loss is 3.905541892051697 and perplexity is 49.676992186963005
At time: 652.2137742042542 and batch: 350, loss is 3.920929675102234 and perplexity is 50.44732260391457
At time: 653.0321745872498 and batch: 400, loss is 3.877634882926941 and perplexity is 48.309821463991724
At time: 653.8508417606354 and batch: 450, loss is 3.914653806686401 and perplexity is 50.1317132426281
At time: 654.6702523231506 and batch: 500, loss is 3.941286201477051 and perplexity is 51.484778530970154
At time: 655.4896807670593 and batch: 550, loss is 3.9013989925384522 and perplexity is 49.47161113050831
At time: 656.308679819107 and batch: 600, loss is 3.896301851272583 and perplexity is 49.2200889066424
At time: 657.1273860931396 and batch: 650, loss is 3.939480366706848 and perplexity is 51.39188942419505
At time: 657.94571185112 and batch: 700, loss is 3.965857353210449 and perplexity is 52.7654886635392
At time: 658.7649924755096 and batch: 750, loss is 3.9317830276489256 and perplexity is 50.997827187441345
At time: 659.5896241664886 and batch: 800, loss is 3.8977424001693723 and perplexity is 49.29104394624838
At time: 660.4416720867157 and batch: 850, loss is 3.912442531585693 and perplexity is 50.020980708547654
At time: 661.258980512619 and batch: 900, loss is 3.8754547214508057 and perplexity is 48.20461297973137
At time: 662.0775663852692 and batch: 950, loss is 3.972612681388855 and perplexity is 53.12314353385265
At time: 662.8966732025146 and batch: 1000, loss is 3.928615379333496 and perplexity is 50.836539592113525
At time: 663.7157499790192 and batch: 1050, loss is 3.8744116973876954 and perplexity is 48.15436062020649
At time: 664.5339961051941 and batch: 1100, loss is 3.8954034757614138 and perplexity is 49.17589064040374
At time: 665.3525500297546 and batch: 1150, loss is 3.877418599128723 and perplexity is 48.299373962167685
At time: 666.171144247055 and batch: 1200, loss is 3.929597215652466 and perplexity is 50.886477264314266
At time: 666.9904434680939 and batch: 1250, loss is 3.9252932500839233 and perplexity is 50.66793425641449
At time: 667.80974817276 and batch: 1300, loss is 3.923384027481079 and perplexity is 50.5712901779789
At time: 668.6280837059021 and batch: 1350, loss is 3.8336186933517458 and perplexity is 46.22952639233098
At time: 669.4470770359039 and batch: 1400, loss is 3.847174587249756 and perplexity is 46.860475826826985
At time: 670.2661378383636 and batch: 1450, loss is 3.7608951425552366 and perplexity is 42.98688815453394
At time: 671.0850319862366 and batch: 1500, loss is 3.7857780408859254 and perplexity is 44.069945442785325
At time: 671.9039580821991 and batch: 1550, loss is 3.7810204792022706 and perplexity is 43.86077791718013
At time: 672.7217571735382 and batch: 1600, loss is 3.8711155128479002 and perplexity is 47.99589626855349
At time: 673.5403752326965 and batch: 1650, loss is 3.8232797288894655 and perplexity is 45.75402330232935
At time: 674.3621792793274 and batch: 1700, loss is 3.8420876359939573 and perplexity is 46.62270414967427
At time: 675.1833953857422 and batch: 1750, loss is 3.8368663787841797 and perplexity is 46.37990941794457
At time: 676.0023427009583 and batch: 1800, loss is 3.8132027053833006 and perplexity is 45.29527422862966
At time: 676.8313994407654 and batch: 1850, loss is 3.8322110414505004 and perplexity is 46.16449709165839
At time: 677.6603150367737 and batch: 1900, loss is 3.8992231702804565 and perplexity is 49.3640867172976
At time: 678.4799535274506 and batch: 1950, loss is 3.8404132890701295 and perplexity is 46.54470688386347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332757994186046 and perplexity of 76.15402957204842
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdf90580b38>
ELAPSED
3529.872751712799


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}, 'best_accuracy': -75.41513488817796}, {'params': {'wordvec_dim': 300, 'dropout': 0.6309802267622319, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.016023383857180606, 'tune_wordvecs': True}, 'best_accuracy': -76.15677522751027}, {'params': {'wordvec_dim': 300, 'dropout': 0.32978472608712295, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8376966109346161, 'tune_wordvecs': True}, 'best_accuracy': -75.7890280729731}, {'params': {'wordvec_dim': 300, 'dropout': 0.29541444939753103, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8777067374849862, 'tune_wordvecs': True}, 'best_accuracy': -75.53908877222875}, {'params': {'wordvec_dim': 300, 'dropout': 0.18877573745735154, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.7802425779340171, 'tune_wordvecs': True}, 'best_accuracy': -76.15402957204842}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 300, 'dropout': 0.658038160820733, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.0626355800263455, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.3532757759094238 and batch: 50, loss is 7.417068300247192 and perplexity is 1664.1475681760799
At time: 2.2168898582458496 and batch: 100, loss is 6.703214797973633 and perplexity is 815.0217483473809
At time: 3.0369269847869873 and batch: 150, loss is 6.47601583480835 and perplexity is 649.3785540097864
At time: 3.856797456741333 and batch: 200, loss is 6.346978073120117 and perplexity is 570.7652892903852
At time: 4.677467107772827 and batch: 250, loss is 6.3002085113525395 and perplexity is 544.6854713904594
At time: 5.497128486633301 and batch: 300, loss is 6.216848459243774 and perplexity is 501.1214361525404
At time: 6.325051784515381 and batch: 350, loss is 6.175683193206787 and perplexity is 480.9114671602686
At time: 7.144165277481079 and batch: 400, loss is 6.131799440383912 and perplexity is 460.2636329315054
At time: 7.962049722671509 and batch: 450, loss is 6.041329612731934 and perplexity is 420.4517013346173
At time: 8.78098177909851 and batch: 500, loss is 6.031414918899536 and perplexity is 416.3036487600198
At time: 9.603173017501831 and batch: 550, loss is 5.979313383102417 and perplexity is 395.1689453089817
At time: 10.421483278274536 and batch: 600, loss is 6.014771461486816 and perplexity is 409.43225718421843
At time: 11.239873170852661 and batch: 650, loss is 6.089693269729614 and perplexity is 441.28603460027944
At time: 12.057999849319458 and batch: 700, loss is 5.998001003265381 and perplexity is 402.62314616336204
At time: 12.876472473144531 and batch: 750, loss is 5.9379761695861815 and perplexity is 379.16678323358417
At time: 13.694843292236328 and batch: 800, loss is 5.943787517547608 and perplexity is 381.37666833269554
At time: 14.51334834098816 and batch: 850, loss is 5.971359786987304 and perplexity is 392.0383971815794
At time: 15.342787742614746 and batch: 900, loss is 5.957488679885865 and perplexity is 386.6379323897597
At time: 16.176932334899902 and batch: 950, loss is 5.982213182449341 and perplexity is 396.31651902111724
At time: 16.996716499328613 and batch: 1000, loss is 5.961357460021973 and perplexity is 388.13664677134136
At time: 17.815399885177612 and batch: 1050, loss is 5.856412487030029 and perplexity is 349.4681708614152
At time: 18.634405612945557 and batch: 1100, loss is 5.943061723709106 and perplexity is 381.09996792254435
At time: 19.45342230796814 and batch: 1150, loss is 5.850509548187256 and perplexity is 347.41135821337326
At time: 20.273232460021973 and batch: 1200, loss is 5.931480855941772 and perplexity is 376.7119571162966
At time: 21.092398405075073 and batch: 1250, loss is 5.873495483398438 and perplexity is 355.489418399639
At time: 21.911668062210083 and batch: 1300, loss is 5.882144975662231 and perplexity is 358.57755753883765
At time: 22.736873388290405 and batch: 1350, loss is 5.857482414245606 and perplexity is 349.84227646559333
At time: 23.557887077331543 and batch: 1400, loss is 5.874474821090698 and perplexity is 355.83773311730414
At time: 24.378154516220093 and batch: 1450, loss is 5.851382064819336 and perplexity is 347.714612679632
At time: 25.20524525642395 and batch: 1500, loss is 5.828752136230468 and perplexity is 339.93422269443596
At time: 26.025020122528076 and batch: 1550, loss is 5.802647886276245 and perplexity is 331.17531451900726
At time: 26.844614028930664 and batch: 1600, loss is 5.816742191314697 and perplexity is 335.87604940245
At time: 27.664191722869873 and batch: 1650, loss is 5.814442548751831 and perplexity is 335.1045419790516
At time: 28.48347043991089 and batch: 1700, loss is 5.837016744613647 and perplexity is 342.7552873609687
At time: 29.302679300308228 and batch: 1750, loss is 5.8369732761383055 and perplexity is 342.74038863502653
At time: 30.122533798217773 and batch: 1800, loss is 5.839175653457642 and perplexity is 343.4960641292132
At time: 30.95012593269348 and batch: 1850, loss is 5.803375701904297 and perplexity is 331.4164368241865
At time: 31.771175861358643 and batch: 1900, loss is 5.805210189819336 and perplexity is 332.0249742790275
At time: 32.589876890182495 and batch: 1950, loss is 5.735492820739746 and perplexity is 309.6655427626536
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.127164902797965 and perplexity of 168.53861670583305
finished 1 epochs...
Completing Train Step...
At time: 35.37487292289734 and batch: 50, loss is 5.37646369934082 and perplexity is 216.25617478876538
At time: 36.18682551383972 and batch: 100, loss is 5.279553909301757 and perplexity is 196.28229611258317
At time: 36.99868655204773 and batch: 150, loss is 5.192894620895386 and perplexity is 179.98879894945583
At time: 37.81081223487854 and batch: 200, loss is 5.137246732711792 and perplexity is 170.24638864119225
At time: 38.62325167655945 and batch: 250, loss is 5.1462713241577145 and perplexity is 171.78974635557816
At time: 39.435649394989014 and batch: 300, loss is 5.145425825119019 and perplexity is 171.64455967642468
At time: 40.24799299240112 and batch: 350, loss is 5.128611783981324 and perplexity is 168.7826485589896
At time: 41.06035137176514 and batch: 400, loss is 5.077772960662842 and perplexity is 160.41640418173506
At time: 41.880016803741455 and batch: 450, loss is 5.040291318893432 and perplexity is 154.51502161505326
At time: 42.697001934051514 and batch: 500, loss is 5.0260987472534175 and perplexity is 152.33754465070618
At time: 43.538562059402466 and batch: 550, loss is 4.981873550415039 and perplexity is 145.74719072270597
At time: 44.35006022453308 and batch: 600, loss is 4.975324106216431 and perplexity is 144.7957467456125
At time: 45.16631245613098 and batch: 650, loss is 5.045759563446045 and perplexity is 155.36226188764002
At time: 45.978752851486206 and batch: 700, loss is 5.035737056732177 and perplexity is 153.81291969042266
At time: 46.793973445892334 and batch: 750, loss is 4.985989875793457 and perplexity is 146.3483700587182
At time: 47.620330572128296 and batch: 800, loss is 4.968353891372681 and perplexity is 143.7899984949546
At time: 48.43718481063843 and batch: 850, loss is 4.9551968765258785 and perplexity is 141.9105424774751
At time: 49.25314116477966 and batch: 900, loss is 4.965296812057495 and perplexity is 143.351092292187
At time: 50.071266651153564 and batch: 950, loss is 5.017883367538452 and perplexity is 151.09116064561084
At time: 50.888445138931274 and batch: 1000, loss is 4.987612495422363 and perplexity is 146.5860305607871
At time: 51.71464252471924 and batch: 1050, loss is 4.894943513870239 and perplexity is 133.61245915068002
At time: 52.53381323814392 and batch: 1100, loss is 4.970186862945557 and perplexity is 144.0538031740379
At time: 53.35040616989136 and batch: 1150, loss is 4.892845373153687 and perplexity is 133.33241529833575
At time: 54.1678307056427 and batch: 1200, loss is 4.969385433197021 and perplexity is 143.93840042056124
At time: 54.98379635810852 and batch: 1250, loss is 4.927020502090454 and perplexity is 137.96782448832647
At time: 55.79950785636902 and batch: 1300, loss is 4.944696340560913 and perplexity is 140.4282020273553
At time: 56.62016320228577 and batch: 1350, loss is 4.857960739135742 and perplexity is 128.76135619825536
At time: 57.44296836853027 and batch: 1400, loss is 4.864023504257202 and perplexity is 129.54437729563998
At time: 58.25919842720032 and batch: 1450, loss is 4.804915790557861 and perplexity is 122.10920783994546
At time: 59.0756254196167 and batch: 1500, loss is 4.794539241790772 and perplexity is 120.84868692853216
At time: 59.89183235168457 and batch: 1550, loss is 4.793895044326782 and perplexity is 120.7708615810235
At time: 60.70824909210205 and batch: 1600, loss is 4.857390594482422 and perplexity is 128.68796452338827
At time: 61.534061431884766 and batch: 1650, loss is 4.82555645942688 and perplexity is 124.65581499048614
At time: 62.350791692733765 and batch: 1700, loss is 4.8431110668182376 and perplexity is 126.86341900077191
At time: 63.17122197151184 and batch: 1750, loss is 4.850313367843628 and perplexity is 127.78042584920951
At time: 63.99550008773804 and batch: 1800, loss is 4.802022438049317 and perplexity is 121.75641348246279
At time: 64.8120756149292 and batch: 1850, loss is 4.815051927566528 and perplexity is 123.35321757628427
At time: 65.62852191925049 and batch: 1900, loss is 4.893062810897828 and perplexity is 133.36140995009066
At time: 66.44477558135986 and batch: 1950, loss is 4.8127619171142575 and perplexity is 123.07106061321674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.652618550145349 and perplexity of 104.85920547889097
finished 2 epochs...
Completing Train Step...
At time: 69.19227838516235 and batch: 50, loss is 4.7518426704406735 and perplexity is 115.79746462170175
At time: 70.03507494926453 and batch: 100, loss is 4.707834711074829 and perplexity is 110.81196003864267
At time: 70.85248923301697 and batch: 150, loss is 4.670279207229615 and perplexity is 106.72753737280935
At time: 71.6725172996521 and batch: 200, loss is 4.650859689712524 and perplexity is 104.67493487200117
At time: 72.49819421768188 and batch: 250, loss is 4.656224632263184 and perplexity is 105.23801899047174
At time: 73.3149664402008 and batch: 300, loss is 4.681109380722046 and perplexity is 107.88969695454826
At time: 74.13148760795593 and batch: 350, loss is 4.680944852828979 and perplexity is 107.87194755020079
At time: 74.94842076301575 and batch: 400, loss is 4.636335887908936 and perplexity is 103.16564371774359
At time: 75.76458239555359 and batch: 450, loss is 4.635451669692993 and perplexity is 103.07446309403389
At time: 76.58092498779297 and batch: 500, loss is 4.639331817626953 and perplexity is 103.47518418485237
At time: 77.39808940887451 and batch: 550, loss is 4.597152557373047 and perplexity is 99.2014426842467
At time: 78.2154541015625 and batch: 600, loss is 4.587609090805054 and perplexity is 98.25922021807699
At time: 79.03287506103516 and batch: 650, loss is 4.656964063644409 and perplexity is 105.3158640612085
At time: 79.85009407997131 and batch: 700, loss is 4.673481912612915 and perplexity is 107.06990218546844
At time: 80.66798639297485 and batch: 750, loss is 4.6417882537841795 and perplexity is 103.7296768131376
At time: 81.49454402923584 and batch: 800, loss is 4.612615985870361 and perplexity is 100.74735887775817
At time: 82.3120973110199 and batch: 850, loss is 4.604927644729615 and perplexity is 99.97574881522765
At time: 83.12958931922913 and batch: 900, loss is 4.608078546524048 and perplexity is 100.2912593919534
At time: 83.94724369049072 and batch: 950, loss is 4.671116609573364 and perplexity is 106.81694869414802
At time: 84.76486229896545 and batch: 1000, loss is 4.649537734985351 and perplexity is 104.53665076983027
At time: 85.62731313705444 and batch: 1050, loss is 4.576812620162964 and perplexity is 97.20407361066592
At time: 86.44433832168579 and batch: 1100, loss is 4.641413831710816 and perplexity is 103.69084540259816
At time: 87.26185655593872 and batch: 1150, loss is 4.584494876861572 and perplexity is 97.95369596526515
At time: 88.07911849021912 and batch: 1200, loss is 4.661567831039429 and perplexity is 105.80183158474514
At time: 88.89637088775635 and batch: 1250, loss is 4.634711589813232 and perplexity is 102.99820797869965
At time: 89.72236609458923 and batch: 1300, loss is 4.637606220245361 and perplexity is 103.29678164770765
At time: 90.54224634170532 and batch: 1350, loss is 4.540858182907105 and perplexity is 93.77123847316281
At time: 91.35967350006104 and batch: 1400, loss is 4.553068523406982 and perplexity is 94.92323605255888
At time: 92.17742657661438 and batch: 1450, loss is 4.491061697006225 and perplexity is 89.21611609758982
At time: 92.99505829811096 and batch: 1500, loss is 4.494871006011963 and perplexity is 89.55661597497732
At time: 93.81340861320496 and batch: 1550, loss is 4.504575853347778 and perplexity is 90.4299803401032
At time: 94.63409900665283 and batch: 1600, loss is 4.581481027603149 and perplexity is 97.65892271551635
At time: 95.45824098587036 and batch: 1650, loss is 4.5422567367553714 and perplexity is 93.90247434841444
At time: 96.2761721611023 and batch: 1700, loss is 4.567766342163086 and perplexity is 96.32870392648015
At time: 97.09323954582214 and batch: 1750, loss is 4.5603179931640625 and perplexity is 95.61387955644597
At time: 97.91184043884277 and batch: 1800, loss is 4.516866474151612 and perplexity is 91.54827915366985
At time: 98.72944593429565 and batch: 1850, loss is 4.557107181549072 and perplexity is 95.30737373096603
At time: 99.54672574996948 and batch: 1900, loss is 4.635326700210571 and perplexity is 103.06158273657267
At time: 100.36399722099304 and batch: 1950, loss is 4.559063034057617 and perplexity is 95.49396330832607
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.559922896984012 and perplexity of 95.57611033960136
finished 3 epochs...
Completing Train Step...
At time: 103.13242387771606 and batch: 50, loss is 4.518795537948608 and perplexity is 91.72505207296344
At time: 103.95126700401306 and batch: 100, loss is 4.480756626129151 and perplexity is 88.30145859729548
At time: 104.7699339389801 and batch: 150, loss is 4.452151746749878 and perplexity is 85.81138986989185
At time: 105.59114408493042 and batch: 200, loss is 4.44262812614441 and perplexity is 84.99803394333578
At time: 106.43646168708801 and batch: 250, loss is 4.438596467971802 and perplexity is 84.65604078811941
At time: 107.2556540966034 and batch: 300, loss is 4.460176687240601 and perplexity is 86.50279168573759
At time: 108.07918405532837 and batch: 350, loss is 4.469242401123047 and perplexity is 87.29056672132228
At time: 108.90331602096558 and batch: 400, loss is 4.4259876537322995 and perplexity is 83.59532970289887
At time: 109.72910475730896 and batch: 450, loss is 4.442790203094482 and perplexity is 85.01181128190383
At time: 110.55251574516296 and batch: 500, loss is 4.454815549850464 and perplexity is 86.04027923905153
At time: 111.37535667419434 and batch: 550, loss is 4.406711444854737 and perplexity is 81.99936020491562
At time: 112.19827699661255 and batch: 600, loss is 4.402835540771484 and perplexity is 81.68215367801604
At time: 113.0167019367218 and batch: 650, loss is 4.471383752822876 and perplexity is 87.47768679819589
At time: 113.83590030670166 and batch: 700, loss is 4.496153869628906 and perplexity is 89.67157862420162
At time: 114.65554332733154 and batch: 750, loss is 4.462985410690307 and perplexity is 86.74609563200946
At time: 115.47498750686646 and batch: 800, loss is 4.432952499389648 and perplexity is 84.17959055345104
At time: 116.29393792152405 and batch: 850, loss is 4.425568389892578 and perplexity is 83.56028855024225
At time: 117.11327052116394 and batch: 900, loss is 4.422574729919433 and perplexity is 83.31051151935654
At time: 117.93300437927246 and batch: 950, loss is 4.493218841552735 and perplexity is 89.40877587868033
At time: 118.75266551971436 and batch: 1000, loss is 4.468720216751098 and perplexity is 87.2449968505345
At time: 119.57159161567688 and batch: 1050, loss is 4.4070352268218995 and perplexity is 82.02591441772452
At time: 120.3910059928894 and batch: 1100, loss is 4.4651277637481686 and perplexity is 86.93213560574225
At time: 121.21092939376831 and batch: 1150, loss is 4.413534021377563 and perplexity is 82.5607198969729
At time: 122.03087210655212 and batch: 1200, loss is 4.492823343276978 and perplexity is 89.3734218536716
At time: 122.8499665260315 and batch: 1250, loss is 4.470190067291259 and perplexity is 87.37332824716337
At time: 123.66911244392395 and batch: 1300, loss is 4.4656394100189205 and perplexity is 86.97662548930438
At time: 124.48802590370178 and batch: 1350, loss is 4.371775817871094 and perplexity is 79.18412350033756
At time: 125.30723428726196 and batch: 1400, loss is 4.386099157333374 and perplexity is 80.32646613190396
At time: 126.12636590003967 and batch: 1450, loss is 4.320083847045899 and perplexity is 75.19493290069826
At time: 126.9456958770752 and batch: 1500, loss is 4.33287618637085 and perplexity is 76.16303091511887
At time: 127.76493549346924 and batch: 1550, loss is 4.342344532012939 and perplexity is 76.88759360893151
At time: 128.5835518836975 and batch: 1600, loss is 4.425975685119629 and perplexity is 83.59432918876396
At time: 129.40323328971863 and batch: 1650, loss is 4.388033437728882 and perplexity is 80.48199040587002
At time: 130.22321248054504 and batch: 1700, loss is 4.412503328323364 and perplexity is 82.4756689746522
At time: 131.04272747039795 and batch: 1750, loss is 4.4046273612976075 and perplexity is 81.8286446411577
At time: 131.86901593208313 and batch: 1800, loss is 4.358176107406616 and perplexity is 78.11453190060443
At time: 132.68863368034363 and batch: 1850, loss is 4.404729051589966 and perplexity is 81.83696624306043
At time: 133.50815987586975 and batch: 1900, loss is 4.483502340316773 and perplexity is 88.54424231978169
At time: 134.32791447639465 and batch: 1950, loss is 4.407754259109497 and perplexity is 82.08491490769724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.523591933139535 and perplexity of 92.1660584465779
finished 4 epochs...
Completing Train Step...
At time: 137.13815236091614 and batch: 50, loss is 4.376031203269958 and perplexity is 79.52180042647038
At time: 137.98310494422913 and batch: 100, loss is 4.342648983001709 and perplexity is 76.9110056765626
At time: 138.80135321617126 and batch: 150, loss is 4.31716212272644 and perplexity is 74.97555467395205
At time: 139.62040972709656 and batch: 200, loss is 4.317364196777344 and perplexity is 74.99070681887986
At time: 140.43759942054749 and batch: 250, loss is 4.303453140258789 and perplexity is 73.9547293352129
At time: 141.25389623641968 and batch: 300, loss is 4.324630403518677 and perplexity is 75.53758927261192
At time: 142.07308650016785 and batch: 350, loss is 4.338439445495606 and perplexity is 76.58792639779152
At time: 142.89104843139648 and batch: 400, loss is 4.292016620635986 and perplexity is 73.1137626540424
At time: 143.70913457870483 and batch: 450, loss is 4.318840036392212 and perplexity is 75.10146278366713
At time: 144.5391674041748 and batch: 500, loss is 4.33227201461792 and perplexity is 76.11702926107169
At time: 145.357506275177 and batch: 550, loss is 4.283987073898316 and perplexity is 72.52904293836725
At time: 146.17600870132446 and batch: 600, loss is 4.282013802528382 and perplexity is 72.38606456840434
At time: 146.9952688217163 and batch: 650, loss is 4.348507499694824 and perplexity is 77.3629125466376
At time: 147.81454038619995 and batch: 700, loss is 4.373458967208863 and perplexity is 79.31751443230708
At time: 148.6613097190857 and batch: 750, loss is 4.342925310134888 and perplexity is 76.93226121087628
At time: 149.48095059394836 and batch: 800, loss is 4.314705476760865 and perplexity is 74.79159233773042
At time: 150.30074548721313 and batch: 850, loss is 4.3082510852813725 and perplexity is 74.31041265289807
At time: 151.12035989761353 and batch: 900, loss is 4.302422370910644 and perplexity is 73.87853834148031
At time: 151.94021320343018 and batch: 950, loss is 4.379922800064087 and perplexity is 79.83187015192662
At time: 152.75939416885376 and batch: 1000, loss is 4.351468286514282 and perplexity is 77.59230706497615
At time: 153.57888650894165 and batch: 1050, loss is 4.29575834274292 and perplexity is 73.387846489083
At time: 154.39851832389832 and batch: 1100, loss is 4.3441926383972165 and perplexity is 77.02982144715824
At time: 155.21797394752502 and batch: 1150, loss is 4.297735934257507 and perplexity is 73.5331212713161
At time: 156.03922319412231 and batch: 1200, loss is 4.377628264427185 and perplexity is 79.6489030734187
At time: 156.86120700836182 and batch: 1250, loss is 4.358072566986084 and perplexity is 78.10644430782536
At time: 157.6864755153656 and batch: 1300, loss is 4.3493188381195065 and perplexity is 77.42570551996351
At time: 158.51255083084106 and batch: 1350, loss is 4.25866732597351 and perplexity is 70.71567968056293
At time: 159.33232975006104 and batch: 1400, loss is 4.274887790679932 and perplexity is 71.87207414060273
At time: 160.1587462425232 and batch: 1450, loss is 4.2057828521728515 and perplexity is 67.07308542921257
At time: 160.98160338401794 and batch: 1500, loss is 4.225065665245056 and perplexity is 68.3789935245053
At time: 161.80189681053162 and batch: 1550, loss is 4.230896396636963 and perplexity is 68.77885768599293
At time: 162.62598133087158 and batch: 1600, loss is 4.320522203445434 and perplexity is 75.22790230639498
At time: 163.4509720802307 and batch: 1650, loss is 4.279906115531921 and perplexity is 72.23365807040577
At time: 164.27169156074524 and batch: 1700, loss is 4.306995625495911 and perplexity is 74.21717745693714
At time: 165.09694504737854 and batch: 1750, loss is 4.298666849136352 and perplexity is 73.60160621987852
At time: 165.9204399585724 and batch: 1800, loss is 4.250642838478089 and perplexity is 70.15049329159716
At time: 166.73995065689087 and batch: 1850, loss is 4.298742942810058 and perplexity is 73.60720704957761
At time: 167.56012392044067 and batch: 1900, loss is 4.3729164409637455 and perplexity is 79.27449426986888
At time: 168.3798909187317 and batch: 1950, loss is 4.300819063186646 and perplexity is 73.7601832155171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.501523891715117 and perplexity of 90.15441223520207
finished 5 epochs...
Completing Train Step...
At time: 171.15919399261475 and batch: 50, loss is 4.275476250648499 and perplexity is 71.91438042564909
At time: 171.98755717277527 and batch: 100, loss is 4.2455722618103025 and perplexity is 69.79569012559425
At time: 172.80472207069397 and batch: 150, loss is 4.221315946578979 and perplexity is 68.1230716534907
At time: 173.6277632713318 and batch: 200, loss is 4.2217209434509275 and perplexity is 68.15066687202926
At time: 174.45079970359802 and batch: 250, loss is 4.207743721008301 and perplexity is 67.20473598468074
At time: 175.27072024345398 and batch: 300, loss is 4.224987797737121 and perplexity is 68.37366922998191
At time: 176.09081053733826 and batch: 350, loss is 4.241869964599609 and perplexity is 69.53776349186889
At time: 176.91893196105957 and batch: 400, loss is 4.193462061882019 and perplexity is 66.25176207572216
At time: 177.73885321617126 and batch: 450, loss is 4.225641541481018 and perplexity is 68.41838270247224
At time: 178.55845522880554 and batch: 500, loss is 4.242465209960938 and perplexity is 69.57916784467652
At time: 179.37750339508057 and batch: 550, loss is 4.194346218109131 and perplexity is 66.31036488692115
At time: 180.19597172737122 and batch: 600, loss is 4.196909785270691 and perplexity is 66.48057403889649
At time: 181.0138087272644 and batch: 650, loss is 4.258142433166504 and perplexity is 70.67857126877722
At time: 181.831645488739 and batch: 700, loss is 4.284542474746704 and perplexity is 72.56933681893997
At time: 182.64920353889465 and batch: 750, loss is 4.255092716217041 and perplexity is 70.4633499808302
At time: 183.47818970680237 and batch: 800, loss is 4.225997223854065 and perplexity is 68.44272224350814
At time: 184.2959439754486 and batch: 850, loss is 4.22400333404541 and perplexity is 68.30639095709802
At time: 185.1136782169342 and batch: 900, loss is 4.211049041748047 and perplexity is 67.42723670789655
At time: 185.9428162574768 and batch: 950, loss is 4.295735197067261 and perplexity is 73.38614789744847
At time: 186.758469581604 and batch: 1000, loss is 4.262632794380188 and perplexity is 70.99665720975432
At time: 187.57449507713318 and batch: 1050, loss is 4.210905351638794 and perplexity is 67.41754877693398
At time: 188.39361572265625 and batch: 1100, loss is 4.2566552114486695 and perplexity is 70.57353468830286
At time: 189.21079635620117 and batch: 1150, loss is 4.212786254882812 and perplexity is 67.54447399273771
At time: 190.07331538200378 and batch: 1200, loss is 4.292764029502869 and perplexity is 73.1684289550354
At time: 190.89108514785767 and batch: 1250, loss is 4.276510457992554 and perplexity is 71.9887932785554
At time: 191.7092592716217 and batch: 1300, loss is 4.26408483505249 and perplexity is 71.09982212532074
At time: 192.52718544006348 and batch: 1350, loss is 4.175322098731995 and perplexity is 65.0607922851266
At time: 193.34677577018738 and batch: 1400, loss is 4.193104701042175 and perplexity is 66.22809052028104
At time: 194.16388320922852 and batch: 1450, loss is 4.12256730556488 and perplexity is 61.71748669364916
At time: 194.9811496734619 and batch: 1500, loss is 4.14176378250122 and perplexity is 62.91368971170978
At time: 195.79925560951233 and batch: 1550, loss is 4.146322445869446 and perplexity is 63.201146756495035
At time: 196.61628651618958 and batch: 1600, loss is 4.2411651611328125 and perplexity is 69.48877030239952
At time: 197.4340739250183 and batch: 1650, loss is 4.201973638534546 and perplexity is 66.81807571901683
At time: 198.25803232192993 and batch: 1700, loss is 4.225908913612366 and perplexity is 68.43667831703853
At time: 199.08084774017334 and batch: 1750, loss is 4.218741188049316 and perplexity is 67.94789680692426
At time: 199.90517950057983 and batch: 1800, loss is 4.174133281707764 and perplexity is 64.98349286418575
At time: 200.72455263137817 and batch: 1850, loss is 4.219368586540222 and perplexity is 67.99054059076515
At time: 201.54437017440796 and batch: 1900, loss is 4.289809322357177 and perplexity is 72.95255675178599
At time: 202.36457753181458 and batch: 1950, loss is 4.219492206573486 and perplexity is 67.99894610318879
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49026730559593 and perplexity of 89.14527172410844
finished 6 epochs...
Completing Train Step...
At time: 205.16066336631775 and batch: 50, loss is 4.198081583976745 and perplexity is 66.55852155001013
At time: 206.0096263885498 and batch: 100, loss is 4.172574601173401 and perplexity is 64.88228325601709
At time: 206.8300404548645 and batch: 150, loss is 4.150760760307312 and perplexity is 63.48227672875191
At time: 207.65074801445007 and batch: 200, loss is 4.147246298789978 and perplexity is 63.2595623000374
At time: 208.47009778022766 and batch: 250, loss is 4.133598017692566 and perplexity is 62.40204315404088
At time: 209.28966212272644 and batch: 300, loss is 4.148862748146057 and perplexity is 63.36190086905674
At time: 210.10996890068054 and batch: 350, loss is 4.167255964279175 and perplexity is 64.53811401743341
At time: 210.9295952320099 and batch: 400, loss is 4.1151671838760375 and perplexity is 61.26245550140943
At time: 211.7759611606598 and batch: 450, loss is 4.153498225212097 and perplexity is 63.656295309581154
At time: 212.5960488319397 and batch: 500, loss is 4.174937410354614 and perplexity is 65.03576896790959
At time: 213.41586470603943 and batch: 550, loss is 4.126620173454285 and perplexity is 61.96812707678555
At time: 214.23477244377136 and batch: 600, loss is 4.131240592002869 and perplexity is 62.25510823654328
At time: 215.0540270805359 and batch: 650, loss is 4.190631022453308 and perplexity is 66.06446597148701
At time: 215.8746302127838 and batch: 700, loss is 4.216010775566101 and perplexity is 67.76262407187174
At time: 216.69408011436462 and batch: 750, loss is 4.189401473999023 and perplexity is 65.98328642678766
At time: 217.51388096809387 and batch: 800, loss is 4.1577569150924685 and perplexity is 63.92796579982732
At time: 218.33360266685486 and batch: 850, loss is 4.158822393417358 and perplexity is 63.996115961554146
At time: 219.15116024017334 and batch: 900, loss is 4.142467370033264 and perplexity is 62.95797057529087
At time: 219.9685845375061 and batch: 950, loss is 4.230279026031494 and perplexity is 68.73640874569212
At time: 220.7862343788147 and batch: 1000, loss is 4.191109256744385 and perplexity is 66.09606782047786
At time: 221.6108522415161 and batch: 1050, loss is 4.141482887268066 and perplexity is 62.896020037949356
At time: 222.42782473564148 and batch: 1100, loss is 4.18813307762146 and perplexity is 65.89964652079462
At time: 223.24554347991943 and batch: 1150, loss is 4.1466779708862305 and perplexity is 63.22362033998029
At time: 224.0630395412445 and batch: 1200, loss is 4.225528135299682 and perplexity is 68.41062407490328
At time: 224.88721251487732 and batch: 1250, loss is 4.211825037002564 and perplexity is 67.47958023014289
At time: 225.70466923713684 and batch: 1300, loss is 4.191800312995911 and perplexity is 66.14175970736014
At time: 226.5217125415802 and batch: 1350, loss is 4.108632950782776 and perplexity is 60.86345733046524
At time: 227.33923411369324 and batch: 1400, loss is 4.127111740112305 and perplexity is 61.998596030063695
At time: 228.15651035308838 and batch: 1450, loss is 4.057275323867798 and perplexity is 57.81656485855292
At time: 228.97435545921326 and batch: 1500, loss is 4.077350907325744 and perplexity is 58.98899536819657
At time: 229.8005394935608 and batch: 1550, loss is 4.082492895126343 and perplexity is 59.29309723676009
At time: 230.62356209754944 and batch: 1600, loss is 4.173927264213562 and perplexity is 64.97010650678062
At time: 231.44318079948425 and batch: 1650, loss is 4.135850539207459 and perplexity is 62.54276352715311
At time: 232.2630090713501 and batch: 1700, loss is 4.1633412599563595 and perplexity is 64.28596025922604
At time: 233.08085298538208 and batch: 1750, loss is 4.152482366561889 and perplexity is 63.59166234588664
At time: 233.89997458457947 and batch: 1800, loss is 4.113024301528931 and perplexity is 61.13131782346402
At time: 234.72091460227966 and batch: 1850, loss is 4.1583274269104 and perplexity is 63.964447865547754
At time: 235.54123258590698 and batch: 1900, loss is 4.2267261362075805 and perplexity is 68.4926291759398
At time: 236.3611581325531 and batch: 1950, loss is 4.155308713912964 and perplexity is 63.771648704477805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488395655432413 and perplexity of 88.97857900559757
finished 7 epochs...
Completing Train Step...
At time: 239.18186497688293 and batch: 50, loss is 4.136488089561462 and perplexity is 62.58265040177465
At time: 240.00275945663452 and batch: 100, loss is 4.1123953485488896 and perplexity is 61.09288118763049
At time: 240.8244514465332 and batch: 150, loss is 4.091181421279908 and perplexity is 59.81051139105031
At time: 241.64579796791077 and batch: 200, loss is 4.086945476531983 and perplexity is 59.55769320940813
At time: 242.4675328731537 and batch: 250, loss is 4.074331035614014 and perplexity is 58.811124877987616
At time: 243.2891652584076 and batch: 300, loss is 4.085546641349793 and perplexity is 59.474440055072776
At time: 244.1111171245575 and batch: 350, loss is 4.109604535102844 and perplexity is 60.92262004740267
At time: 244.93296766281128 and batch: 400, loss is 4.059515471458435 and perplexity is 57.94622767471885
At time: 245.76140427589417 and batch: 450, loss is 4.095786776542663 and perplexity is 60.086595288706775
At time: 246.58524775505066 and batch: 500, loss is 4.121019434928894 and perplexity is 61.62202990470828
At time: 247.40833401679993 and batch: 550, loss is 4.071606631278992 and perplexity is 58.651117655577195
At time: 248.2290437221527 and batch: 600, loss is 4.076311917304992 and perplexity is 58.9277382189688
At time: 249.05008101463318 and batch: 650, loss is 4.135091471672058 and perplexity is 62.495307359282215
At time: 249.87181282043457 and batch: 700, loss is 4.15836895942688 and perplexity is 63.967104525201314
At time: 250.7011206150055 and batch: 750, loss is 4.134106531143188 and perplexity is 62.43378350184396
At time: 251.5305471420288 and batch: 800, loss is 4.101105756759644 and perplexity is 60.40704618082694
At time: 252.35198140144348 and batch: 850, loss is 4.103201470375061 and perplexity is 60.53377479703562
At time: 253.20558500289917 and batch: 900, loss is 4.088536787033081 and perplexity is 59.65254344010198
At time: 254.031245470047 and batch: 950, loss is 4.179323968887329 and perplexity is 65.3216787968535
At time: 254.85282635688782 and batch: 1000, loss is 4.136882858276367 and perplexity is 62.60736095140416
At time: 255.67385911941528 and batch: 1050, loss is 4.086632957458496 and perplexity is 59.53908320244986
At time: 256.49481320381165 and batch: 1100, loss is 4.131185789108276 and perplexity is 62.25169656989417
At time: 257.3270106315613 and batch: 1150, loss is 4.095012097358704 and perplexity is 60.040065479266005
At time: 258.152468919754 and batch: 1200, loss is 4.170327272415161 and perplexity is 64.7366351558371
At time: 258.9812059402466 and batch: 1250, loss is 4.156990056037903 and perplexity is 63.878960852758986
At time: 259.80329394340515 and batch: 1300, loss is 4.1375782012939455 and perplexity is 62.65090968158879
At time: 260.6275670528412 and batch: 1350, loss is 4.06021487236023 and perplexity is 57.98676949445015
At time: 261.4536895751953 and batch: 1400, loss is 4.078284826278686 and perplexity is 59.0441120422331
At time: 262.2811155319214 and batch: 1450, loss is 4.005604777336121 and perplexity is 54.905019671720744
At time: 263.1089599132538 and batch: 1500, loss is 4.027321491241455 and perplexity is 56.11041754291639
At time: 263.93075489997864 and batch: 1550, loss is 4.029510226249695 and perplexity is 56.233362876415846
At time: 264.75360584259033 and batch: 1600, loss is 4.11968816280365 and perplexity is 61.5400487956856
At time: 265.57589387893677 and batch: 1650, loss is 4.08257378578186 and perplexity is 59.29789368825464
At time: 266.3983054161072 and batch: 1700, loss is 4.109024386405945 and perplexity is 60.887286119227745
At time: 267.2242000102997 and batch: 1750, loss is 4.100828771591186 and perplexity is 60.390316641988555
At time: 268.05154156684875 and batch: 1800, loss is 4.059619140625 and perplexity is 57.95223522324087
At time: 268.8838005065918 and batch: 1850, loss is 4.106351737976074 and perplexity is 60.72477307643295
At time: 269.7062199115753 and batch: 1900, loss is 4.172575645446777 and perplexity is 64.88235101089346
At time: 270.52868032455444 and batch: 1950, loss is 4.103098721504211 and perplexity is 60.52755533955354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.490158861736918 and perplexity of 89.13560499098843
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 273.320588350296 and batch: 50, loss is 4.111513323783875 and perplexity is 61.03901951061529
At time: 274.1813094615936 and batch: 100, loss is 4.108985991477966 and perplexity is 60.884948401140896
At time: 275.0034065246582 and batch: 150, loss is 4.0821876001358035 and perplexity is 59.27499811412645
At time: 275.8238127231598 and batch: 200, loss is 4.074057855606079 and perplexity is 58.795061048685206
At time: 276.6490206718445 and batch: 250, loss is 4.061375226974487 and perplexity is 58.054093762457526
At time: 277.469758272171 and batch: 300, loss is 4.067431845664978 and perplexity is 58.406772213149736
At time: 278.29166316986084 and batch: 350, loss is 4.078245091438293 and perplexity is 59.04176598047546
At time: 279.1195809841156 and batch: 400, loss is 4.024260740280152 and perplexity is 55.93894008724593
At time: 279.9388506412506 and batch: 450, loss is 4.051037263870239 and perplexity is 57.4570242419927
At time: 280.758492231369 and batch: 500, loss is 4.071426582336426 and perplexity is 58.64055853447082
At time: 281.585813999176 and batch: 550, loss is 4.0239438676834105 and perplexity is 55.921217378110256
At time: 282.41785311698914 and batch: 600, loss is 4.013700776100158 and perplexity is 55.351334889030774
At time: 283.2469642162323 and batch: 650, loss is 4.06591908454895 and perplexity is 58.31848351592405
At time: 284.06648802757263 and batch: 700, loss is 4.0884361743927 and perplexity is 59.64654194211938
At time: 284.88943457603455 and batch: 750, loss is 4.046524395942688 and perplexity is 57.19831248514976
At time: 285.7102208137512 and batch: 800, loss is 4.01523024559021 and perplexity is 55.43605784104643
At time: 286.53342175483704 and batch: 850, loss is 4.0196724081039426 and perplexity is 55.68286158442145
At time: 287.3537027835846 and batch: 900, loss is 3.98792845249176 and perplexity is 53.94302799502983
At time: 288.17381262779236 and batch: 950, loss is 4.07998095035553 and perplexity is 59.144343160441174
At time: 288.9951272010803 and batch: 1000, loss is 4.034295048713684 and perplexity is 56.50307428034871
At time: 289.8197274208069 and batch: 1050, loss is 3.986026196479797 and perplexity is 53.84051208239185
At time: 290.6447203159332 and batch: 1100, loss is 4.0111284875869755 and perplexity is 55.20913824990276
At time: 291.46493005752563 and batch: 1150, loss is 3.97319833278656 and perplexity is 53.154264289181164
At time: 292.2951834201813 and batch: 1200, loss is 4.038243594169617 and perplexity is 56.72662028788849
At time: 293.11859154701233 and batch: 1250, loss is 4.017468018531799 and perplexity is 55.560250056435365
At time: 293.93947649002075 and batch: 1300, loss is 3.999126410484314 and perplexity is 54.55047448915913
At time: 294.7595851421356 and batch: 1350, loss is 3.9118634462356567 and perplexity is 49.99202267682008
At time: 295.5798397064209 and batch: 1400, loss is 3.924228515625 and perplexity is 50.61401507075054
At time: 296.3999705314636 and batch: 1450, loss is 3.841585092544556 and perplexity is 46.59928010140445
At time: 297.23238015174866 and batch: 1500, loss is 3.8595988941192627 and perplexity is 47.4463165550313
At time: 298.06582045555115 and batch: 1550, loss is 3.8581441116333006 and perplexity is 47.37734266784981
At time: 298.8968679904938 and batch: 1600, loss is 3.944055886268616 and perplexity is 51.62757279533259
At time: 299.7185823917389 and batch: 1650, loss is 3.90213014125824 and perplexity is 49.50779546210413
At time: 300.53926825523376 and batch: 1700, loss is 3.91676598072052 and perplexity is 50.23771205018205
At time: 301.3598265647888 and batch: 1750, loss is 3.8963708686828613 and perplexity is 49.22348606694267
At time: 302.18045115470886 and batch: 1800, loss is 3.8526543188095093 and perplexity is 47.1179634924561
At time: 302.9999589920044 and batch: 1850, loss is 3.8891485834121706 and perplexity is 48.86926070659032
At time: 303.82035970687866 and batch: 1900, loss is 3.948635835647583 and perplexity is 51.86456676121353
At time: 304.6434986591339 and batch: 1950, loss is 3.88223340511322 and perplexity is 48.53248682322548
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384172022619913 and perplexity of 80.1718152749914
finished 9 epochs...
Completing Train Step...
At time: 307.4657406806946 and batch: 50, loss is 4.022434282302856 and perplexity is 55.83686321182077
At time: 308.28648376464844 and batch: 100, loss is 4.011788311004639 and perplexity is 55.245578552949645
At time: 309.1109130382538 and batch: 150, loss is 3.984030160903931 and perplexity is 53.73315168808084
At time: 309.93961572647095 and batch: 200, loss is 3.979033799171448 and perplexity is 53.46535099688974
At time: 310.7707133293152 and batch: 250, loss is 3.9656171417236328 and perplexity is 52.752815309258324
At time: 311.5960705280304 and batch: 300, loss is 3.9750507068634033 and perplexity is 53.2528171205989
At time: 312.41697788238525 and batch: 350, loss is 3.99246102809906 and perplexity is 54.18808379533512
At time: 313.2383394241333 and batch: 400, loss is 3.940517249107361 and perplexity is 51.44520440577445
At time: 314.059743642807 and batch: 450, loss is 3.973874740600586 and perplexity is 53.19023041140694
At time: 314.8803298473358 and batch: 500, loss is 3.999983425140381 and perplexity is 54.59724508397171
At time: 315.70166754722595 and batch: 550, loss is 3.9529605293273926 and perplexity is 52.08935083608162
At time: 316.5598211288452 and batch: 600, loss is 3.948806266784668 and perplexity is 51.87340685159299
At time: 317.3939616680145 and batch: 650, loss is 3.9979527950286866 and perplexity is 54.48649076267611
At time: 318.2304120063782 and batch: 700, loss is 4.024216833114624 and perplexity is 55.936484020863944
At time: 319.0509157180786 and batch: 750, loss is 3.9884963130950926 and perplexity is 53.97366881448639
At time: 319.87704372406006 and batch: 800, loss is 3.9576308822631834 and perplexity is 52.33319546569115
At time: 320.69859528541565 and batch: 850, loss is 3.9642246389389038 and perplexity is 52.679407988848716
At time: 321.5179455280304 and batch: 900, loss is 3.9329180192947386 and perplexity is 51.05574215553898
At time: 322.3440182209015 and batch: 950, loss is 4.029424395561218 and perplexity is 56.228536535291866
At time: 323.1645510196686 and batch: 1000, loss is 3.983849205970764 and perplexity is 53.723429288892866
At time: 323.9845745563507 and batch: 1050, loss is 3.9407968425750735 and perplexity is 51.45959015985916
At time: 324.8043646812439 and batch: 1100, loss is 3.9658955335617065 and perplexity is 52.7675033068903
At time: 325.62363934516907 and batch: 1150, loss is 3.933056058883667 and perplexity is 51.062790355652695
At time: 326.44309759140015 and batch: 1200, loss is 3.998368844985962 and perplexity is 54.50916458122356
At time: 327.26290583610535 and batch: 1250, loss is 3.980745859146118 and perplexity is 53.5569652865645
At time: 328.0829086303711 and batch: 1300, loss is 3.965360951423645 and perplexity is 52.73930228070638
At time: 328.9034411907196 and batch: 1350, loss is 3.879866509437561 and perplexity is 48.41775132707365
At time: 329.72279596328735 and batch: 1400, loss is 3.896928997039795 and perplexity is 49.25096675850701
At time: 330.5406754016876 and batch: 1450, loss is 3.8173172426223756 and perplexity is 45.482027258877956
At time: 331.35886430740356 and batch: 1500, loss is 3.837697010040283 and perplexity is 46.418450024662725
At time: 332.1762146949768 and batch: 1550, loss is 3.837028560638428 and perplexity is 46.387432007651114
At time: 332.9940285682678 and batch: 1600, loss is 3.92752893447876 and perplexity is 50.78133848714909
At time: 333.81220054626465 and batch: 1650, loss is 3.887558255195618 and perplexity is 48.791604308314255
At time: 334.62959337234497 and batch: 1700, loss is 3.9059223318099976 and perplexity is 49.695894885304725
At time: 335.44729018211365 and batch: 1750, loss is 3.889649052619934 and perplexity is 48.893724387929126
At time: 336.26446890830994 and batch: 1800, loss is 3.848016867637634 and perplexity is 46.89996211351058
At time: 337.08414006233215 and batch: 1850, loss is 3.887741274833679 and perplexity is 48.80053494729142
At time: 337.9015073776245 and batch: 1900, loss is 3.950128173828125 and perplexity is 51.94202401624283
At time: 338.7193834781647 and batch: 1950, loss is 3.885593156814575 and perplexity is 48.69581815111481
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380720555505087 and perplexity of 79.89558187051176
finished 10 epochs...
Completing Train Step...
At time: 341.4807732105255 and batch: 50, loss is 3.9865984106063843 and perplexity is 53.87132920014227
At time: 342.3261675834656 and batch: 100, loss is 3.973144335746765 and perplexity is 53.15139419374609
At time: 343.1454613208771 and batch: 150, loss is 3.9462850522994994 and perplexity is 51.74278759561417
At time: 343.9658582210541 and batch: 200, loss is 3.9413606214523313 and perplexity is 51.488610169489206
At time: 344.7891960144043 and batch: 250, loss is 3.927313175201416 and perplexity is 50.77038312415765
At time: 345.6108286380768 and batch: 300, loss is 3.9388160037994386 and perplexity is 51.35775789823525
At time: 346.4306392669678 and batch: 350, loss is 3.956158003807068 and perplexity is 52.256171766747855
At time: 347.25018882751465 and batch: 400, loss is 3.9039807605743406 and perplexity is 49.59950037395197
At time: 348.069748878479 and batch: 450, loss is 3.9394915199279783 and perplexity is 51.39246261249854
At time: 348.88958191871643 and batch: 500, loss is 3.9683027124404906 and perplexity is 52.89467712999811
At time: 349.70929288864136 and batch: 550, loss is 3.9205847787857055 and perplexity is 50.429926508266874
At time: 350.5354895591736 and batch: 600, loss is 3.919118185043335 and perplexity is 50.35602050191188
At time: 351.3551664352417 and batch: 650, loss is 3.9657588720321657 and perplexity is 52.76029251190869
At time: 352.17449593544006 and batch: 700, loss is 3.993861379623413 and perplexity is 54.26401931688233
At time: 352.9952483177185 and batch: 750, loss is 3.9602370262145996 and perplexity is 52.46976118417691
At time: 353.82770109176636 and batch: 800, loss is 3.9289060258865356 and perplexity is 50.85131720454146
At time: 354.6514415740967 and batch: 850, loss is 3.9369657897949217 and perplexity is 51.262822907438604
At time: 355.4797999858856 and batch: 900, loss is 3.9055215072631837 and perplexity is 49.67597954230462
At time: 356.3138098716736 and batch: 950, loss is 4.004369206428528 and perplexity is 54.83722251945317
At time: 357.1391661167145 and batch: 1000, loss is 3.9584399461746216 and perplexity is 52.37555349837991
At time: 358.0088469982147 and batch: 1050, loss is 3.9174469709396362 and perplexity is 50.27193509217485
At time: 358.83057975769043 and batch: 1100, loss is 3.9423582410812377 and perplexity is 51.54000184807077
At time: 359.6541087627411 and batch: 1150, loss is 3.9107295083999634 and perplexity is 49.93536695892579
At time: 360.4757134914398 and batch: 1200, loss is 3.9759452390670775 and perplexity is 53.30047479293305
At time: 361.2973108291626 and batch: 1250, loss is 3.9604691743850706 and perplexity is 52.48194335722075
At time: 362.11858344078064 and batch: 1300, loss is 3.945610556602478 and perplexity is 51.707899075430106
At time: 362.94099974632263 and batch: 1350, loss is 3.8606973028182985 and perplexity is 47.498460634385076
At time: 363.762757062912 and batch: 1400, loss is 3.8801150274276734 and perplexity is 48.4297855046121
At time: 364.58508014678955 and batch: 1450, loss is 3.801326928138733 and perplexity is 44.76053912379536
At time: 365.40800642967224 and batch: 1500, loss is 3.822355465888977 and perplexity is 45.711754088411844
At time: 366.2308955192566 and batch: 1550, loss is 3.821297254562378 and perplexity is 45.66340697771847
At time: 367.0551619529724 and batch: 1600, loss is 3.9145333766937256 and perplexity is 50.12567624429461
At time: 367.8820171356201 and batch: 1650, loss is 3.875027985572815 and perplexity is 48.184046730378604
At time: 368.7039761543274 and batch: 1700, loss is 3.8946143865585325 and perplexity is 49.137101782004706
At time: 369.5266606807709 and batch: 1750, loss is 3.87997661113739 and perplexity is 48.423082497276745
At time: 370.3493187427521 and batch: 1800, loss is 3.8396261978149413 and perplexity is 46.50808636583521
At time: 371.1726334095001 and batch: 1850, loss is 3.8799990892410277 and perplexity is 48.4241709685769
At time: 372.00313210487366 and batch: 1900, loss is 3.9430296754837038 and perplexity is 51.57461919875429
At time: 372.8294107913971 and batch: 1950, loss is 3.879675507545471 and perplexity is 48.408504328084724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380288199491279 and perplexity of 79.86104600164659
finished 11 epochs...
Completing Train Step...
At time: 375.6497735977173 and batch: 50, loss is 3.959892387390137 and perplexity is 52.45168118307667
At time: 376.47944688796997 and batch: 100, loss is 3.945616755485535 and perplexity is 51.70821960764305
At time: 377.3031885623932 and batch: 150, loss is 3.9194304513931275 and perplexity is 50.371747447994316
At time: 378.1221077442169 and batch: 200, loss is 3.9141621828079223 and perplexity is 50.107073352604395
At time: 378.9411144256592 and batch: 250, loss is 3.9003645086288454 and perplexity is 49.42046000688029
At time: 379.7873525619507 and batch: 300, loss is 3.9131440353393554 and perplexity is 50.05608292500536
At time: 380.6059968471527 and batch: 350, loss is 3.9300814390182497 and perplexity is 50.91112365230497
At time: 381.4252676963806 and batch: 400, loss is 3.8778733301162718 and perplexity is 48.32134217862332
At time: 382.24426007270813 and batch: 450, loss is 3.9148075723648073 and perplexity is 50.1394223722091
At time: 383.06319284439087 and batch: 500, loss is 3.944446868896484 and perplexity is 51.64776222601571
At time: 383.8817000389099 and batch: 550, loss is 3.897348895072937 and perplexity is 49.27165148501332
At time: 384.7005410194397 and batch: 600, loss is 3.8976695013046263 and perplexity is 49.2874508160717
At time: 385.5198082923889 and batch: 650, loss is 3.9427401781082154 and perplexity is 51.559690642847585
At time: 386.33868527412415 and batch: 700, loss is 3.97158043384552 and perplexity is 53.06833559199391
At time: 387.1555104255676 and batch: 750, loss is 3.938921914100647 and perplexity is 51.36319750189357
At time: 387.97272419929504 and batch: 800, loss is 3.907556276321411 and perplexity is 49.77716159455881
At time: 388.78929924964905 and batch: 850, loss is 3.916842279434204 and perplexity is 50.24154526922288
At time: 389.6096637248993 and batch: 900, loss is 3.8846569776535036 and perplexity is 48.6502514735454
At time: 390.4290826320648 and batch: 950, loss is 3.985398602485657 and perplexity is 53.80673270134457
At time: 391.25498032569885 and batch: 1000, loss is 3.9390262508392335 and perplexity is 51.36855684998789
At time: 392.07465505599976 and batch: 1050, loss is 3.8994590187072755 and perplexity is 49.37573053252501
At time: 392.8943827152252 and batch: 1100, loss is 3.9241042137145996 and perplexity is 50.6077240429857
At time: 393.717378616333 and batch: 1150, loss is 3.8934803342819215 and perplexity is 49.08140932491036
At time: 394.5358507633209 and batch: 1200, loss is 3.9580679512023926 and perplexity is 52.35607367923283
At time: 395.35582304000854 and batch: 1250, loss is 3.9441688680648803 and perplexity is 51.63340610076624
At time: 396.1747844219208 and batch: 1300, loss is 3.929633994102478 and perplexity is 50.88834882449096
At time: 396.9945659637451 and batch: 1350, loss is 3.8448031091690065 and perplexity is 46.74947890095825
At time: 397.8173522949219 and batch: 1400, loss is 3.86574547290802 and perplexity is 47.73884718827192
At time: 398.63898372650146 and batch: 1450, loss is 3.7871166467666626 and perplexity is 44.128977232254314
At time: 399.46389508247375 and batch: 1500, loss is 3.808515648841858 and perplexity is 45.08346947543946
At time: 400.28888869285583 and batch: 1550, loss is 3.8073470401763916 and perplexity is 45.03081531438786
At time: 401.1091375350952 and batch: 1600, loss is 3.902382798194885 and perplexity is 49.52030553035685
At time: 401.9306161403656 and batch: 1650, loss is 3.8626346349716187 and perplexity is 47.590570123933944
At time: 402.75242161750793 and batch: 1700, loss is 3.8830615854263306 and perplexity is 48.572697121749286
At time: 403.5816330909729 and batch: 1750, loss is 3.8693698263168335 and perplexity is 47.91218356821671
At time: 404.40251207351685 and batch: 1800, loss is 3.8299760818481445 and perplexity is 46.06143651660572
At time: 405.2253201007843 and batch: 1850, loss is 3.870521459579468 and perplexity is 47.967392616685835
At time: 406.0459702014923 and batch: 1900, loss is 3.9334561014175415 and perplexity is 51.083221730130205
At time: 406.8683500289917 and batch: 1950, loss is 3.871078596115112 and perplexity is 47.9941244495811
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.381538710483285 and perplexity of 79.96097558600425
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 409.72283267974854 and batch: 50, loss is 3.9600949573516844 and perplexity is 52.4623073943563
At time: 410.5798828601837 and batch: 100, loss is 3.967457218170166 and perplexity is 52.84997388438609
At time: 411.4114625453949 and batch: 150, loss is 3.946504831314087 and perplexity is 51.75416082423665
At time: 412.2474145889282 and batch: 200, loss is 3.9420036125183104 and perplexity is 51.52172753177091
At time: 413.0769500732422 and batch: 250, loss is 3.9251634216308595 and perplexity is 50.6613565438864
At time: 413.91284823417664 and batch: 300, loss is 3.9354487752914427 and perplexity is 51.18511541819541
At time: 414.7551438808441 and batch: 350, loss is 3.9466206789016725 and perplexity is 51.76015676621665
At time: 415.58752036094666 and batch: 400, loss is 3.89607515335083 and perplexity is 49.208932079441325
At time: 416.406635761261 and batch: 450, loss is 3.933146343231201 and perplexity is 51.06740073448262
At time: 417.2253863811493 and batch: 500, loss is 3.9569985389709474 and perplexity is 52.30011338129657
At time: 418.04447507858276 and batch: 550, loss is 3.9094566249847413 and perplexity is 49.87184549477649
At time: 418.8734815120697 and batch: 600, loss is 3.9061488676071168 and perplexity is 49.707154059721
At time: 419.69825768470764 and batch: 650, loss is 3.946444935798645 and perplexity is 51.75106107492928
At time: 420.5177776813507 and batch: 700, loss is 3.9776586627960206 and perplexity is 53.39187937623589
At time: 421.3838403224945 and batch: 750, loss is 3.9371159172058103 and perplexity is 51.27051944003234
At time: 422.20340967178345 and batch: 800, loss is 3.9028852224349975 and perplexity is 49.545191983488216
At time: 423.0237965583801 and batch: 850, loss is 3.9201862239837646 and perplexity is 50.40983142365771
At time: 423.8523368835449 and batch: 900, loss is 3.87779314994812 and perplexity is 48.31746792060353
At time: 424.6819167137146 and batch: 950, loss is 3.9756086111068725 and perplexity is 53.28253538244853
At time: 425.50832295417786 and batch: 1000, loss is 3.924311399459839 and perplexity is 50.618210328273314
At time: 426.3289842605591 and batch: 1050, loss is 3.884428482055664 and perplexity is 48.63913637517379
At time: 427.15128564834595 and batch: 1100, loss is 3.9048839092254637 and perplexity is 49.64431633050015
At time: 427.9765305519104 and batch: 1150, loss is 3.877725224494934 and perplexity is 48.314186046160884
At time: 428.7947835922241 and batch: 1200, loss is 3.9332600975036622 and perplexity is 51.073210199919146
At time: 429.6135296821594 and batch: 1250, loss is 3.9183682870864867 and perplexity is 50.3182727802611
At time: 430.43494844436646 and batch: 1300, loss is 3.9042924785614015 and perplexity is 49.61496384036286
At time: 431.25779819488525 and batch: 1350, loss is 3.8139515829086306 and perplexity is 45.32920754586659
At time: 432.0765073299408 and batch: 1400, loss is 3.834042162895203 and perplexity is 46.249107334440275
At time: 432.89545035362244 and batch: 1450, loss is 3.7449636936187742 and perplexity is 42.30747115977698
At time: 433.7139503955841 and batch: 1500, loss is 3.7671040153503417 and perplexity is 43.25461856689406
At time: 434.5441040992737 and batch: 1550, loss is 3.7674173879623414 and perplexity is 43.268175503770834
At time: 435.36642575263977 and batch: 1600, loss is 3.862012448310852 and perplexity is 47.560969115655716
At time: 436.1857032775879 and batch: 1650, loss is 3.815881094932556 and perplexity is 45.41675523185596
At time: 437.01035356521606 and batch: 1700, loss is 3.8321188497543335 and perplexity is 46.16024130454594
At time: 437.8341529369354 and batch: 1750, loss is 3.814093437194824 and perplexity is 45.33563814433992
At time: 438.65324115753174 and batch: 1800, loss is 3.7750877857208254 and perplexity is 43.601335722410546
At time: 439.48065853118896 and batch: 1850, loss is 3.8095714807510377 and perplexity is 45.131095179032584
At time: 440.3064794540405 and batch: 1900, loss is 3.8735177183151244 and perplexity is 48.11133086627452
At time: 441.1321108341217 and batch: 1950, loss is 3.8137748575210573 and perplexity is 45.32119743191075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357122376907704 and perplexity of 78.0322635878598
finished 13 epochs...
Completing Train Step...
At time: 443.9653511047363 and batch: 50, loss is 3.9439702367782594 and perplexity is 51.623151109394605
At time: 444.7834782600403 and batch: 100, loss is 3.9384791660308838 and perplexity is 51.34046157885717
At time: 445.60204553604126 and batch: 150, loss is 3.914285411834717 and perplexity is 50.1132483789526
At time: 446.42212176322937 and batch: 200, loss is 3.908767399787903 and perplexity is 49.837484404873344
At time: 447.24016547203064 and batch: 250, loss is 3.892371301651001 and perplexity is 49.027006613164794
At time: 448.0578496456146 and batch: 300, loss is 3.9038265419006346 and perplexity is 49.59185179457986
At time: 448.8769552707672 and batch: 350, loss is 3.9173305225372315 and perplexity is 50.26608134648385
At time: 449.69623589515686 and batch: 400, loss is 3.867579321861267 and perplexity is 47.82647334522822
At time: 450.5144553184509 and batch: 450, loss is 3.9066416120529173 and perplexity is 49.73165301916788
At time: 451.3331489562988 and batch: 500, loss is 3.9313665294647215 and perplexity is 50.97659110772073
At time: 452.1525909900665 and batch: 550, loss is 3.884558300971985 and perplexity is 48.645451065023025
At time: 452.97707509994507 and batch: 600, loss is 3.8833597803115847 and perplexity is 48.587183411355376
At time: 453.8096640110016 and batch: 650, loss is 3.925077142715454 and perplexity is 50.65698572554827
At time: 454.6383590698242 and batch: 700, loss is 3.9573160648345946 and perplexity is 52.31672265676453
At time: 455.46150398254395 and batch: 750, loss is 3.9188446760177613 and perplexity is 50.34224955913705
At time: 456.284481048584 and batch: 800, loss is 3.8848291778564454 and perplexity is 48.658629778074484
At time: 457.1182231903076 and batch: 850, loss is 3.9025768184661866 and perplexity is 49.52991440559894
At time: 457.9431598186493 and batch: 900, loss is 3.861097536087036 and perplexity is 47.517474903362476
At time: 458.7645220756531 and batch: 950, loss is 3.9603748083114625 and perplexity is 52.47699107595815
At time: 459.5850875377655 and batch: 1000, loss is 3.9092093229293825 and perplexity is 49.85951360979419
At time: 460.4070534706116 and batch: 1050, loss is 3.8705828619003295 and perplexity is 47.97033801634444
At time: 461.22848653793335 and batch: 1100, loss is 3.8918509912490844 and perplexity is 49.00150398686535
At time: 462.04924988746643 and batch: 1150, loss is 3.8664995193481446 and perplexity is 47.774858071282694
At time: 462.92706274986267 and batch: 1200, loss is 3.9226768589019776 and perplexity is 50.5355403926127
At time: 463.77329778671265 and batch: 1250, loss is 3.909260754585266 and perplexity is 49.86207803308639
At time: 464.59430503845215 and batch: 1300, loss is 3.8966923713684083 and perplexity is 49.23931409414546
At time: 465.4199962615967 and batch: 1350, loss is 3.806639814376831 and perplexity is 44.99897961886182
At time: 466.243860244751 and batch: 1400, loss is 3.8283354473114013 and perplexity is 45.98592849051923
At time: 467.06391739845276 and batch: 1450, loss is 3.741704406738281 and perplexity is 42.169803445236774
At time: 467.8847270011902 and batch: 1500, loss is 3.7645589780807494 and perplexity is 43.1446739165203
At time: 468.70560598373413 and batch: 1550, loss is 3.765806322097778 and perplexity is 43.19852374504551
At time: 469.5264410972595 and batch: 1600, loss is 3.861375594139099 and perplexity is 47.53068935698053
At time: 470.3480386734009 and batch: 1650, loss is 3.8164661026000974 and perplexity is 45.44333215499539
At time: 471.16860008239746 and batch: 1700, loss is 3.8343069171905517 and perplexity is 46.26135360531799
At time: 471.98936915397644 and batch: 1750, loss is 3.8177695846557618 and perplexity is 45.50260534538663
At time: 472.8101558685303 and batch: 1800, loss is 3.7796947813034056 and perplexity is 43.802670301135215
At time: 473.6305491924286 and batch: 1850, loss is 3.8144811820983886 and perplexity is 45.35322021543918
At time: 474.4562728404999 and batch: 1900, loss is 3.87881130695343 and perplexity is 48.36668774154652
At time: 475.2748222351074 and batch: 1950, loss is 3.8191193675994874 and perplexity is 45.564065455549866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.355318007358285 and perplexity of 77.8915914979535
finished 14 epochs...
Completing Train Step...
At time: 478.08659982681274 and batch: 50, loss is 3.9336594009399413 and perplexity is 51.093607980434676
At time: 478.93630051612854 and batch: 100, loss is 3.9263434743881227 and perplexity is 50.72117490483205
At time: 479.7586889266968 and batch: 150, loss is 3.901723613739014 and perplexity is 49.487673271221865
At time: 480.5812578201294 and batch: 200, loss is 3.8957078361511233 and perplexity is 49.190860111584854
At time: 481.4039669036865 and batch: 250, loss is 3.8787660789489746 and perplexity is 48.36450026224589
At time: 482.22588181495667 and batch: 300, loss is 3.890596966743469 and perplexity is 48.94009341328365
At time: 483.04851174354553 and batch: 350, loss is 3.9042501926422117 and perplexity is 49.61286587036891
At time: 483.87107038497925 and batch: 400, loss is 3.855052390098572 and perplexity is 47.23109131798754
At time: 484.7211289405823 and batch: 450, loss is 3.8940722227096556 and perplexity is 49.110468642195094
At time: 485.54309248924255 and batch: 500, loss is 3.9192430353164673 and perplexity is 50.362307857306256
At time: 486.3666031360626 and batch: 550, loss is 3.872964391708374 and perplexity is 48.08471695059289
At time: 487.19069647789 and batch: 600, loss is 3.8725986433029176 and perplexity is 48.067133257841206
At time: 488.0226192474365 and batch: 650, loss is 3.914541916847229 and perplexity is 50.12610432709214
At time: 488.85140657424927 and batch: 700, loss is 3.946788120269775 and perplexity is 51.76882428330901
At time: 489.67433309555054 and batch: 750, loss is 3.909308366775513 and perplexity is 49.86445213234939
At time: 490.4969894886017 and batch: 800, loss is 3.8753179597854612 and perplexity is 48.19802088736602
At time: 491.3191556930542 and batch: 850, loss is 3.8932420015335083 and perplexity is 49.069713011592576
At time: 492.14251351356506 and batch: 900, loss is 3.852252688407898 and perplexity is 47.09904328557498
At time: 492.9653568267822 and batch: 950, loss is 3.9521868085861205 and perplexity is 52.049063812403055
At time: 493.78902196884155 and batch: 1000, loss is 3.900966553688049 and perplexity is 49.450222308875475
At time: 494.6114478111267 and batch: 1050, loss is 3.8632917261123656 and perplexity is 47.62185174225707
At time: 495.4336168766022 and batch: 1100, loss is 3.8848334074020388 and perplexity is 48.658835582402865
At time: 496.26435136795044 and batch: 1150, loss is 3.8603199100494385 and perplexity is 47.48053844087551
At time: 497.09000396728516 and batch: 1200, loss is 3.9164324951171876 and perplexity is 50.220961289692916
At time: 497.91982674598694 and batch: 1250, loss is 3.9039463090896604 and perplexity is 49.59779162695929
At time: 498.7550902366638 and batch: 1300, loss is 3.8920406198501585 and perplexity is 49.01079695459529
At time: 499.5794439315796 and batch: 1350, loss is 3.802193350791931 and perplexity is 44.79933747431936
At time: 500.40208768844604 and batch: 1400, loss is 3.824507532119751 and perplexity is 45.810234741170035
At time: 501.2340567111969 and batch: 1450, loss is 3.7387775802612304 and perplexity is 42.04656019176826
At time: 502.060179233551 and batch: 1500, loss is 3.762011475563049 and perplexity is 43.03490263177059
At time: 502.8920555114746 and batch: 1550, loss is 3.763624129295349 and perplexity is 43.10435901761616
At time: 503.72337532043457 and batch: 1600, loss is 3.8597072696685792 and perplexity is 47.45145885429572
At time: 504.5521674156189 and batch: 1650, loss is 3.8152143478393556 and perplexity is 45.38648383512684
At time: 505.37445425987244 and batch: 1700, loss is 3.833766894340515 and perplexity is 46.23637816155962
At time: 506.197824716568 and batch: 1750, loss is 3.81792236328125 and perplexity is 45.509557701959636
At time: 507.0205957889557 and batch: 1800, loss is 3.780302267074585 and perplexity is 43.829287884165716
At time: 507.85223722457886 and batch: 1850, loss is 3.815063614845276 and perplexity is 45.37964311010205
At time: 508.6745171546936 and batch: 1900, loss is 3.879666385650635 and perplexity is 48.40806275281306
At time: 509.50584053993225 and batch: 1950, loss is 3.8197903442382812 and perplexity is 45.594648138024375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354705668604651 and perplexity of 77.84391005798369
finished 15 epochs...
Completing Train Step...
At time: 512.369019985199 and batch: 50, loss is 3.9249959087371824 and perplexity is 50.652870824207696
At time: 513.1954810619354 and batch: 100, loss is 3.9167912578582764 and perplexity is 50.238981931799515
At time: 514.0255582332611 and batch: 150, loss is 3.8921143627166748 and perplexity is 49.01441128451686
At time: 514.8463842868805 and batch: 200, loss is 3.8859376525878906 and perplexity is 48.712596544522874
At time: 515.6760799884796 and batch: 250, loss is 3.868673424720764 and perplexity is 47.87882906252215
At time: 516.5002129077911 and batch: 300, loss is 3.8808769845962523 and perplexity is 48.466700989073054
At time: 517.329576253891 and batch: 350, loss is 3.894586958885193 and perplexity is 49.13575408411037
At time: 518.1513783931732 and batch: 400, loss is 3.8458867359161375 and perplexity is 46.80016534434279
At time: 518.9803194999695 and batch: 450, loss is 3.8847754049301146 and perplexity is 48.656013331507694
At time: 519.8108546733856 and batch: 500, loss is 3.910365719795227 and perplexity is 49.91720434532904
At time: 520.6384501457214 and batch: 550, loss is 3.8644391870498658 and perplexity is 47.676527319948434
At time: 521.4664323329926 and batch: 600, loss is 3.864768886566162 and perplexity is 47.69224883949079
At time: 522.2911338806152 and batch: 650, loss is 3.9067453050613405 and perplexity is 49.73681011125588
At time: 523.1118335723877 and batch: 700, loss is 3.938840045928955 and perplexity is 51.35899266294545
At time: 523.9328603744507 and batch: 750, loss is 3.9020731353759768 and perplexity is 49.50497330698539
At time: 524.7583820819855 and batch: 800, loss is 3.8680660057067873 and perplexity is 47.849755382229645
At time: 525.5839219093323 and batch: 850, loss is 3.8861462688446045 and perplexity is 48.72275984414671
At time: 526.4321756362915 and batch: 900, loss is 3.8454851961135863 and perplexity is 46.78137698758003
At time: 527.2579355239868 and batch: 950, loss is 3.945811543464661 and perplexity is 51.71829272827418
At time: 528.0787329673767 and batch: 1000, loss is 3.894516096115112 and perplexity is 49.132272311831436
At time: 528.8986079692841 and batch: 1050, loss is 3.857604422569275 and perplexity is 47.351780532552254
At time: 529.7187285423279 and batch: 1100, loss is 3.879268970489502 and perplexity is 48.38882847700358
At time: 530.5387904644012 and batch: 1150, loss is 3.855320520401001 and perplexity is 47.243757102751154
At time: 531.3592531681061 and batch: 1200, loss is 3.9112193632125853 and perplexity is 49.95983403091789
At time: 532.1791381835938 and batch: 1250, loss is 3.8994039916992187 and perplexity is 49.37301360855597
At time: 532.9995121955872 and batch: 1300, loss is 3.8879239654541013 and perplexity is 48.80945116172745
At time: 533.826961517334 and batch: 1350, loss is 3.7981409502029417 and perplexity is 44.61815996262027
At time: 534.647075176239 and batch: 1400, loss is 3.8209134340286255 and perplexity is 45.645883787574554
At time: 535.4775586128235 and batch: 1450, loss is 3.7358231687545778 and perplexity is 41.92252067263756
At time: 536.2976589202881 and batch: 1500, loss is 3.7592153644561765 and perplexity is 42.91474033439398
At time: 537.1181757450104 and batch: 1550, loss is 3.761092505455017 and perplexity is 42.995373008702835
At time: 537.9485487937927 and batch: 1600, loss is 3.8575310134887695 and perplexity is 47.34830460946678
At time: 538.7754168510437 and batch: 1650, loss is 3.8132715368270875 and perplexity is 45.29839207505324
At time: 539.5968134403229 and batch: 1700, loss is 3.8321513509750367 and perplexity is 46.16174159311677
At time: 540.4153625965118 and batch: 1750, loss is 3.816770091056824 and perplexity is 45.457148503304495
At time: 541.2355949878693 and batch: 1800, loss is 3.779467935562134 and perplexity is 43.79273497885645
At time: 542.065393447876 and batch: 1850, loss is 3.8140864181518555 and perplexity is 45.33531993266455
At time: 542.8859624862671 and batch: 1900, loss is 3.878976140022278 and perplexity is 48.37466082821309
At time: 543.7066552639008 and batch: 1950, loss is 3.8189741373062134 and perplexity is 45.55744865345268
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3544825354287795 and perplexity of 77.8265424368285
finished 16 epochs...
Completing Train Step...
At time: 546.530157327652 and batch: 50, loss is 3.9174465799331664 and perplexity is 50.27191543552682
At time: 547.3911714553833 and batch: 100, loss is 3.908643741607666 and perplexity is 49.831321973269645
At time: 548.2130045890808 and batch: 150, loss is 3.883990316390991 and perplexity is 48.61782904406619
At time: 549.0407192707062 and batch: 200, loss is 3.8777322483062746 and perplexity is 48.31452539708051
At time: 549.8668642044067 and batch: 250, loss is 3.8602868270874025 and perplexity is 47.47896767000784
At time: 550.693127155304 and batch: 300, loss is 3.8728272581100462 and perplexity is 48.07812337244378
At time: 551.5197746753693 and batch: 350, loss is 3.886500825881958 and perplexity is 48.74003790437667
At time: 552.3457291126251 and batch: 400, loss is 3.8382719373703003 and perplexity is 46.44514493327989
At time: 553.174480676651 and batch: 450, loss is 3.8769718647003173 and perplexity is 48.27780178782359
At time: 553.9949927330017 and batch: 500, loss is 3.902960877418518 and perplexity is 49.54894046596515
At time: 554.815375328064 and batch: 550, loss is 3.8573277473449705 and perplexity is 47.338681280255045
At time: 555.635498046875 and batch: 600, loss is 3.8582530546188356 and perplexity is 47.38250437816772
At time: 556.4641499519348 and batch: 650, loss is 3.9001937437057497 and perplexity is 49.412021446353435
At time: 557.2882144451141 and batch: 700, loss is 3.9321141481399535 and perplexity is 51.014716409050365
At time: 558.121265411377 and batch: 750, loss is 3.895927996635437 and perplexity is 49.20169118741454
At time: 558.9436202049255 and batch: 800, loss is 3.861828827857971 and perplexity is 47.55223675071218
At time: 559.7638204097748 and batch: 850, loss is 3.8800492668151856 and perplexity is 48.42660083696866
At time: 560.5877482891083 and batch: 900, loss is 3.8396915912628176 and perplexity is 46.5111277894003
At time: 561.4131996631622 and batch: 950, loss is 3.9402518224716188 and perplexity is 51.43155129027437
At time: 562.2350435256958 and batch: 1000, loss is 3.8888796091079714 and perplexity is 48.85611789881306
At time: 563.0536544322968 and batch: 1050, loss is 3.852618222236633 and perplexity is 47.11626272614922
At time: 563.8724491596222 and batch: 1100, loss is 3.8742936134338377 and perplexity is 48.14867469862362
At time: 564.6914646625519 and batch: 1150, loss is 3.8508162307739258 and perplexity is 47.03143607436708
At time: 565.5154447555542 and batch: 1200, loss is 3.9064731788635254 and perplexity is 49.72327726363354
At time: 566.3353998661041 and batch: 1250, loss is 3.895261511802673 and perplexity is 49.16890993181008
At time: 567.1635851860046 and batch: 1300, loss is 3.883985342979431 and perplexity is 48.61758724819448
At time: 567.9928414821625 and batch: 1350, loss is 3.7942575645446777 and perplexity is 44.44522644123129
At time: 568.8253507614136 and batch: 1400, loss is 3.817465524673462 and perplexity is 45.48877192721173
At time: 569.6526966094971 and batch: 1450, loss is 3.7326922750473024 and perplexity is 41.79147097485869
At time: 570.4767818450928 and batch: 1500, loss is 3.756271867752075 and perplexity is 42.788606665751594
At time: 571.2980983257294 and batch: 1550, loss is 3.7583135557174683 and perplexity is 42.876056891696
At time: 572.1191790103912 and batch: 1600, loss is 3.8549294090270996 and perplexity is 47.22528314492545
At time: 572.9405725002289 and batch: 1650, loss is 3.810765852928162 and perplexity is 45.18503070657259
At time: 573.7622764110565 and batch: 1700, loss is 3.829851951599121 and perplexity is 46.05571925387049
At time: 574.5853476524353 and batch: 1750, loss is 3.814969706535339 and perplexity is 45.37538178460212
At time: 575.4164199829102 and batch: 1800, loss is 3.777897810935974 and perplexity is 43.72402887990327
At time: 576.2503788471222 and batch: 1850, loss is 3.8124155616760254 and perplexity is 45.25963436723779
At time: 577.0751724243164 and batch: 1900, loss is 3.8775895071029662 and perplexity is 48.3076294157701
At time: 577.8966627120972 and batch: 1950, loss is 3.81743344783783 and perplexity is 45.487312814753494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3544660701308135 and perplexity of 77.8252610101672
finished 17 epochs...
Completing Train Step...
At time: 580.7330543994904 and batch: 50, loss is 3.910635347366333 and perplexity is 49.930665214522264
At time: 581.561872959137 and batch: 100, loss is 3.9014017724990846 and perplexity is 49.47174865983084
At time: 582.3968729972839 and batch: 150, loss is 3.876860327720642 and perplexity is 48.27241732791559
At time: 583.2266638278961 and batch: 200, loss is 3.8705246925354 and perplexity is 47.96754769340303
At time: 584.058096408844 and batch: 250, loss is 3.852926435470581 and perplexity is 47.13078681999957
At time: 584.8877460956573 and batch: 300, loss is 3.865713539123535 and perplexity is 47.73732273055524
At time: 585.7113382816315 and batch: 350, loss is 3.879376907348633 and perplexity is 48.39405169705033
At time: 586.5354490280151 and batch: 400, loss is 3.8315028810501097 and perplexity is 46.13181679572559
At time: 587.3573017120361 and batch: 450, loss is 3.8700775384902952 and perplexity is 47.94610360518086
At time: 588.1807811260223 and batch: 500, loss is 3.896411123275757 and perplexity is 49.22546757821739
At time: 589.0135324001312 and batch: 550, loss is 3.851015830039978 and perplexity is 47.040824451414316
At time: 589.8701090812683 and batch: 600, loss is 3.8525030422210693 and perplexity is 47.11083618679555
At time: 590.7055442333221 and batch: 650, loss is 3.8943134260177614 and perplexity is 49.122315678408945
At time: 591.532534122467 and batch: 700, loss is 3.926091694831848 and perplexity is 50.70840595746819
At time: 592.3555791378021 and batch: 750, loss is 3.8903928565979005 and perplexity is 48.93010526306899
At time: 593.1855239868164 and batch: 800, loss is 3.856197004318237 and perplexity is 47.2851836482399
At time: 594.0097374916077 and batch: 850, loss is 3.8746033191680906 and perplexity is 48.16358892866654
At time: 594.8346557617188 and batch: 900, loss is 3.834395503997803 and perplexity is 46.26545193245918
At time: 595.657074213028 and batch: 950, loss is 3.9351837253570556 and perplexity is 51.17155060446813
At time: 596.4793062210083 and batch: 1000, loss is 3.8837289714813235 and perplexity is 48.60512468210891
At time: 597.3024327754974 and batch: 1050, loss is 3.8480491971969606 and perplexity is 46.901478393128336
At time: 598.1324465274811 and batch: 1100, loss is 3.8697122621536253 and perplexity is 47.928593226356575
At time: 598.9617593288422 and batch: 1150, loss is 3.846589460372925 and perplexity is 46.833064523286914
At time: 599.7880442142487 and batch: 1200, loss is 3.9019968557357787 and perplexity is 49.50119722945427
At time: 600.6200659275055 and batch: 1250, loss is 3.8912485456466674 and perplexity is 48.97199213681138
At time: 601.4517157077789 and batch: 1300, loss is 3.8801907014846804 and perplexity is 48.433450521632814
At time: 602.2751786708832 and batch: 1350, loss is 3.790441083908081 and perplexity is 44.275925367760024
At time: 603.1009905338287 and batch: 1400, loss is 3.8140199518203737 and perplexity is 45.33230676040043
At time: 603.9236090183258 and batch: 1450, loss is 3.7293472194671633 and perplexity is 41.651909731863164
At time: 604.7459309101105 and batch: 1500, loss is 3.7533302164077758 and perplexity is 42.66292245363042
At time: 605.5688059329987 and batch: 1550, loss is 3.755399522781372 and perplexity is 42.75129651595015
At time: 606.3918225765228 and batch: 1600, loss is 3.8522798013687134 and perplexity is 47.100320297401744
At time: 607.2145743370056 and batch: 1650, loss is 3.8082408142089843 and perplexity is 45.07108067917063
At time: 608.0376498699188 and batch: 1700, loss is 3.8273936176300047 and perplexity is 45.942637967490086
At time: 608.8612785339355 and batch: 1750, loss is 3.8128867530822754 and perplexity is 45.28096534309324
At time: 609.6839537620544 and batch: 1800, loss is 3.776018261909485 and perplexity is 43.64192460766119
At time: 610.5069677829742 and batch: 1850, loss is 3.810379672050476 and perplexity is 45.167584480672296
At time: 611.3302013874054 and batch: 1900, loss is 3.8758384656906126 and perplexity is 48.223114772045534
At time: 612.1537537574768 and batch: 1950, loss is 3.8155548334121705 and perplexity is 45.4019399092093
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354611135083576 and perplexity of 77.83655154689012
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 614.9618780612946 and batch: 50, loss is 3.9147960138320923 and perplexity is 50.13884283740459
At time: 615.8135724067688 and batch: 100, loss is 3.9197152709960936 and perplexity is 50.3860963524308
At time: 616.6405944824219 and batch: 150, loss is 3.900267128944397 and perplexity is 49.41564769239416
At time: 617.4620034694672 and batch: 200, loss is 3.8932561254501343 and perplexity is 49.07040607302237
At time: 618.2831156253815 and batch: 250, loss is 3.8771907186508177 and perplexity is 48.28836873173286
At time: 619.1049225330353 and batch: 300, loss is 3.88907940864563 and perplexity is 48.86588030381056
At time: 619.9317185878754 and batch: 350, loss is 3.902692742347717 and perplexity is 49.53565643834164
At time: 620.7571172714233 and batch: 400, loss is 3.8525236463546753 and perplexity is 47.11180687475869
At time: 621.5788915157318 and batch: 450, loss is 3.8918107986450194 and perplexity is 48.99953452839612
At time: 622.4001042842865 and batch: 500, loss is 3.917900309562683 and perplexity is 50.29473046862932
At time: 623.2243649959564 and batch: 550, loss is 3.8727878665924074 and perplexity is 48.07622953949963
At time: 624.0565853118896 and batch: 600, loss is 3.8688737297058107 and perplexity is 47.88842039122497
At time: 624.8762283325195 and batch: 650, loss is 3.9070245599746705 and perplexity is 49.75070129935379
At time: 625.6958365440369 and batch: 700, loss is 3.940855073928833 and perplexity is 51.46258680870669
At time: 626.5158064365387 and batch: 750, loss is 3.9017227554321288 and perplexity is 49.48763079562939
At time: 627.3377561569214 and batch: 800, loss is 3.8638442087173464 and perplexity is 47.648169256276574
At time: 628.1599869728088 and batch: 850, loss is 3.879207978248596 and perplexity is 48.38587722392264
At time: 628.9781494140625 and batch: 900, loss is 3.8385354804992677 and perplexity is 46.45738684516598
At time: 629.79682970047 and batch: 950, loss is 3.9410548543930055 and perplexity is 51.47286905524865
At time: 630.6159212589264 and batch: 1000, loss is 3.8865103912353516 and perplexity is 48.740504122293395
At time: 631.4617311954498 and batch: 1050, loss is 3.851279911994934 and perplexity is 47.05324872473919
At time: 632.2809474468231 and batch: 1100, loss is 3.8713600969314577 and perplexity is 48.00763673656412
At time: 633.0984098911285 and batch: 1150, loss is 3.8475664615631104 and perplexity is 46.878842842160815
At time: 633.9168932437897 and batch: 1200, loss is 3.9013060092926026 and perplexity is 49.46701131338426
At time: 634.7364585399628 and batch: 1250, loss is 3.88964759349823 and perplexity is 48.89365304608673
At time: 635.5562884807587 and batch: 1300, loss is 3.878825068473816 and perplexity is 48.36735334528572
At time: 636.3755724430084 and batch: 1350, loss is 3.787241759300232 and perplexity is 44.134498665792734
At time: 637.1945793628693 and batch: 1400, loss is 3.809790754318237 and perplexity is 45.14099232031519
At time: 638.0145485401154 and batch: 1450, loss is 3.7205140495300295 and perplexity is 41.28561150393811
At time: 638.8379375934601 and batch: 1500, loss is 3.7443305253982544 and perplexity is 42.28069189233326
At time: 639.6625854969025 and batch: 1550, loss is 3.746839747428894 and perplexity is 42.38691675104366
At time: 640.4818389415741 and batch: 1600, loss is 3.843822646141052 and perplexity is 46.703665228295925
At time: 641.3010296821594 and batch: 1650, loss is 3.796894211769104 and perplexity is 44.56256744960993
At time: 642.1192927360535 and batch: 1700, loss is 3.814741263389587 and perplexity is 45.36501727354338
At time: 642.9381394386292 and batch: 1750, loss is 3.798178162574768 and perplexity is 44.61982034107211
At time: 643.7567837238312 and batch: 1800, loss is 3.7628308153152465 and perplexity is 43.0701772872191
At time: 644.5796403884888 and batch: 1850, loss is 3.7920418787002563 and perplexity is 44.34685879829308
At time: 645.4094753265381 and batch: 1900, loss is 3.8598504161834715 and perplexity is 47.4582518514426
At time: 646.2300319671631 and batch: 1950, loss is 3.8058474588394167 and perplexity is 44.96333855024656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341978561046512 and perplexity of 76.85946013032434
finished 19 epochs...
Completing Train Step...
At time: 649.0467963218689 and batch: 50, loss is 3.914113006591797 and perplexity is 50.104609336921776
At time: 649.8669209480286 and batch: 100, loss is 3.9095492267608645 and perplexity is 49.876463930082195
At time: 650.6858916282654 and batch: 150, loss is 3.885335578918457 and perplexity is 48.68327679998246
At time: 651.515159368515 and batch: 200, loss is 3.8784893798828124 and perplexity is 48.351119701467624
At time: 652.3334813117981 and batch: 250, loss is 3.861663088798523 and perplexity is 47.54435614079894
At time: 653.1796159744263 and batch: 300, loss is 3.874187068939209 and perplexity is 48.143544995686476
At time: 653.9987061023712 and batch: 350, loss is 3.889229826927185 and perplexity is 48.87323117839165
At time: 654.8176147937775 and batch: 400, loss is 3.8399191665649415 and perplexity is 46.52171377786817
At time: 655.635488986969 and batch: 450, loss is 3.8799771213531495 and perplexity is 48.42310720350286
At time: 656.4535760879517 and batch: 500, loss is 3.9072345542907714 and perplexity is 49.76114976086906
At time: 657.2716920375824 and batch: 550, loss is 3.8622729778289795 and perplexity is 47.57336176627665
At time: 658.0993738174438 and batch: 600, loss is 3.8599619483947754 and perplexity is 47.46354527040408
At time: 658.9217760562897 and batch: 650, loss is 3.8992324352264403 and perplexity is 49.36454407501327
At time: 659.7405848503113 and batch: 700, loss is 3.9337295150756835 and perplexity is 51.097190490191
At time: 660.5644087791443 and batch: 750, loss is 3.8951818561553955 and perplexity is 49.16499350644829
At time: 661.3835575580597 and batch: 800, loss is 3.857478895187378 and perplexity is 47.34583696056216
At time: 662.2021667957306 and batch: 850, loss is 3.873145499229431 and perplexity is 48.09342624311594
At time: 663.0208549499512 and batch: 900, loss is 3.833447413444519 and perplexity is 46.221608881414
At time: 663.8400111198425 and batch: 950, loss is 3.936298999786377 and perplexity is 51.2286527627357
At time: 664.6580328941345 and batch: 1000, loss is 3.8817285251617433 and perplexity is 48.50798992814908
At time: 665.4767825603485 and batch: 1050, loss is 3.8466148853302 and perplexity is 46.83425526708872
At time: 666.3070559501648 and batch: 1100, loss is 3.866956796646118 and perplexity is 47.79670942497581
At time: 667.1333117485046 and batch: 1150, loss is 3.8439481830596924 and perplexity is 46.70952863054692
At time: 667.9540028572083 and batch: 1200, loss is 3.8980279541015626 and perplexity is 49.30512120748199
At time: 668.7746531963348 and batch: 1250, loss is 3.8869860124588014 and perplexity is 48.763691654299656
At time: 669.5982568264008 and batch: 1300, loss is 3.876756944656372 and perplexity is 48.267427035452826
At time: 670.4259951114655 and batch: 1350, loss is 3.785301809310913 and perplexity is 44.04896293991815
At time: 671.2454924583435 and batch: 1400, loss is 3.8086124944686888 and perplexity is 45.08783582372797
At time: 672.0653169155121 and batch: 1450, loss is 3.7199712944030763 and perplexity is 41.263209606547214
At time: 672.8839490413666 and batch: 1500, loss is 3.744702820777893 and perplexity is 42.29643572906969
At time: 673.7035262584686 and batch: 1550, loss is 3.7476590490341186 and perplexity is 42.42165865008175
At time: 674.5225903987885 and batch: 1600, loss is 3.844896378517151 and perplexity is 46.75383939772862
At time: 675.3421006202698 and batch: 1650, loss is 3.7982619428634643 and perplexity is 44.62355875910255
At time: 676.161318063736 and batch: 1700, loss is 3.816565113067627 and perplexity is 45.44783174330765
At time: 676.9801394939423 and batch: 1750, loss is 3.8005779075622557 and perplexity is 44.727025111886554
At time: 677.7999937534332 and batch: 1800, loss is 3.7653146457672118 and perplexity is 43.177289274075825
At time: 678.6193137168884 and batch: 1850, loss is 3.794616641998291 and perplexity is 44.46118858561864
At time: 679.4364852905273 and batch: 1900, loss is 3.862814173698425 and perplexity is 47.599115241368786
At time: 680.2543103694916 and batch: 1950, loss is 3.808623833656311 and perplexity is 45.0883470860565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.341224847837936 and perplexity of 76.80155196583576
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fdf90580b38>
ELAPSED
4236.74690246582


RESULTS SO FAR:
[{'params': {'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}, 'best_accuracy': -75.41513488817796}, {'params': {'wordvec_dim': 300, 'dropout': 0.6309802267622319, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.016023383857180606, 'tune_wordvecs': True}, 'best_accuracy': -76.15677522751027}, {'params': {'wordvec_dim': 300, 'dropout': 0.32978472608712295, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8376966109346161, 'tune_wordvecs': True}, 'best_accuracy': -75.7890280729731}, {'params': {'wordvec_dim': 300, 'dropout': 0.29541444939753103, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8777067374849862, 'tune_wordvecs': True}, 'best_accuracy': -75.53908877222875}, {'params': {'wordvec_dim': 300, 'dropout': 0.18877573745735154, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.7802425779340171, 'tune_wordvecs': True}, 'best_accuracy': -76.15402957204842}, {'params': {'wordvec_dim': 300, 'dropout': 0.658038160820733, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.0626355800263455, 'tune_wordvecs': True}, 'best_accuracy': -76.80155196583576}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'params': {'wordvec_dim': 300, 'dropout': 0.65500155180996, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.06300743885376481, 'tune_wordvecs': True}, 'best_accuracy': -75.41513488817796}, {'params': {'wordvec_dim': 300, 'dropout': 0.6309802267622319, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.016023383857180606, 'tune_wordvecs': True}, 'best_accuracy': -76.15677522751027}, {'params': {'wordvec_dim': 300, 'dropout': 0.32978472608712295, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8376966109346161, 'tune_wordvecs': True}, 'best_accuracy': -75.7890280729731}, {'params': {'wordvec_dim': 300, 'dropout': 0.29541444939753103, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.8777067374849862, 'tune_wordvecs': True}, 'best_accuracy': -75.53908877222875}, {'params': {'wordvec_dim': 300, 'dropout': 0.18877573745735154, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.7802425779340171, 'tune_wordvecs': True}, 'best_accuracy': -76.15402957204842}, {'params': {'wordvec_dim': 300, 'dropout': 0.658038160820733, 'num_layers': 1, 'tie_weights': True, 'wordvec_source': 'glove', 'data': 'wikitext', 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.0626355800263455, 'tune_wordvecs': True}, 'best_accuracy': -76.80155196583576}]
