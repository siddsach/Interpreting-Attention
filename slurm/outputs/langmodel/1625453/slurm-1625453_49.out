Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.7970774173736572 and batch: 50, loss is 10.698407955169678 and perplexity is 44285.29480294891
At time: 2.849091053009033 and batch: 100, loss is 9.954270515441895 and perplexity is 21041.890499266905
At time: 3.9018678665161133 and batch: 150, loss is 9.196308860778808 and perplexity is 9860.664716380847
At time: 4.946840763092041 and batch: 200, loss is 8.764705314636231 and perplexity is 6404.174450663736
At time: 5.9904866218566895 and batch: 250, loss is 8.47284963607788 and perplexity is 4783.126236503475
At time: 7.032546520233154 and batch: 300, loss is 8.238794021606445 and perplexity is 3784.9729590531747
At time: 8.078581094741821 and batch: 350, loss is 8.093501739501953 and perplexity is 3273.1291714963877
At time: 9.12783408164978 and batch: 400, loss is 7.9727582931518555 and perplexity is 2900.847727693835
At time: 10.176429986953735 and batch: 450, loss is 7.843934440612793 and perplexity is 2550.2188056607174
At time: 11.223213911056519 and batch: 500, loss is 7.768685188293457 and perplexity is 2365.3592409053435
At time: 12.26816987991333 and batch: 550, loss is 7.689453830718994 and perplexity is 2185.18075764495
At time: 13.311823844909668 and batch: 600, loss is 7.718837308883667 and perplexity is 2250.341606721334
At time: 14.356662511825562 and batch: 650, loss is 7.7557557106018065 and perplexity is 2334.973242218034
At time: 15.406505584716797 and batch: 700, loss is 7.591821146011353 and perplexity is 1981.9195941136527
At time: 16.46091628074646 and batch: 750, loss is 7.527201862335205 and perplexity is 1857.899564736961
At time: 17.50993585586548 and batch: 800, loss is 7.523395881652832 and perplexity is 1850.8418741203648
At time: 18.555979251861572 and batch: 850, loss is 7.526703567504883 and perplexity is 1856.9740136064174
At time: 19.601532220840454 and batch: 900, loss is 7.486343040466308 and perplexity is 1783.5178987025529
At time: 20.645578622817993 and batch: 950, loss is 7.477403774261474 and perplexity is 1767.645606444586
At time: 21.692307233810425 and batch: 1000, loss is 7.467293615341187 and perplexity is 1749.8644649901148
At time: 22.74524164199829 and batch: 1050, loss is 7.358440294265747 and perplexity is 1569.386871352797
At time: 23.79397225379944 and batch: 1100, loss is 7.4039785671234135 and perplexity is 1642.506269047898
At time: 24.83949327468872 and batch: 1150, loss is 7.306483669281006 and perplexity is 1489.9288845060091
At time: 25.881888151168823 and batch: 1200, loss is 7.381805620193481 and perplexity is 1606.487857536642
At time: 26.925864219665527 and batch: 1250, loss is 7.29062933921814 and perplexity is 1466.4933286143046
At time: 27.970701932907104 and batch: 1300, loss is 7.300244226455688 and perplexity is 1480.6615001402092
At time: 29.018661737442017 and batch: 1350, loss is 7.315960159301758 and perplexity is 1504.11529322596
At time: 30.06788682937622 and batch: 1400, loss is 7.330850191116333 and perplexity is 1526.6791894703777
At time: 31.12019968032837 and batch: 1450, loss is 7.320180501937866 and perplexity is 1510.476589109798
At time: 32.180814266204834 and batch: 1500, loss is 7.2815987014770505 and perplexity is 1453.309577053186
At time: 33.2358341217041 and batch: 1550, loss is 7.252063550949097 and perplexity is 1411.0135443898619
At time: 34.286293506622314 and batch: 1600, loss is 7.220821628570556 and perplexity is 1367.6122685285081
At time: 35.334317445755005 and batch: 1650, loss is 7.193251476287842 and perplexity is 1330.4220161856647
At time: 36.387616872787476 and batch: 1700, loss is 7.218611278533936 and perplexity is 1364.5927050761536
At time: 37.437538385391235 and batch: 1750, loss is 7.2446192932128906 and perplexity is 1400.548596110176
At time: 38.481823682785034 and batch: 1800, loss is 7.240734720230103 and perplexity is 1395.1186162772792
At time: 39.524338722229004 and batch: 1850, loss is 7.1654187679290775 and perplexity is 1293.9033325824093
At time: 40.57090425491333 and batch: 1900, loss is 7.109108085632324 and perplexity is 1223.0561980740601
At time: 41.6249303817749 and batch: 1950, loss is 7.045361547470093 and perplexity is 1147.5236450954724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 6.233594885537791 and perplexity of 509.5840911885327
finished 1 epochs...
Completing Train Step...
At time: 45.022160053253174 and batch: 50, loss is 6.254409646987915 and perplexity is 520.3021221475968
At time: 46.06303095817566 and batch: 100, loss is 5.936225662231445 and perplexity is 378.50362958786957
At time: 47.09827470779419 and batch: 150, loss is 5.750216436386109 and perplexity is 314.2586699363715
At time: 48.136401653289795 and batch: 200, loss is 5.681803455352783 and perplexity is 293.478227828422
At time: 49.176512718200684 and batch: 250, loss is 5.648072891235351 and perplexity is 283.7441328029358
At time: 50.2179536819458 and batch: 300, loss is 5.627587432861328 and perplexity is 277.99063688713176
At time: 51.25527906417847 and batch: 350, loss is 5.572526760101319 and perplexity is 263.0980457149475
At time: 52.319475173950195 and batch: 400, loss is 5.525542049407959 and perplexity is 251.02236767590009
At time: 53.35606932640076 and batch: 450, loss is 5.449636220932007 and perplexity is 232.67350875818343
At time: 54.39904046058655 and batch: 500, loss is 5.428444948196411 and perplexity is 227.79473723915493
At time: 55.44182085990906 and batch: 550, loss is 5.3815756511688235 and perplexity is 217.3644963664928
At time: 56.4812273979187 and batch: 600, loss is 5.3990510559082034 and perplexity is 221.1964135497922
At time: 57.517866373062134 and batch: 650, loss is 5.476166639328003 and perplexity is 238.92904842149187
At time: 58.553263902664185 and batch: 700, loss is 5.408940486907959 and perplexity is 223.3947725621171
At time: 59.58230781555176 and batch: 750, loss is 5.344764890670777 and perplexity is 209.50862137653766
At time: 60.617926836013794 and batch: 800, loss is 5.3256739902496335 and perplexity is 205.54685036210728
At time: 61.656585931777954 and batch: 850, loss is 5.335628404617309 and perplexity is 207.60316661454016
At time: 62.69202494621277 and batch: 900, loss is 5.364365787506103 and perplexity is 213.6556885958735
At time: 63.722811222076416 and batch: 950, loss is 5.381067314147949 and perplexity is 217.25403002541017
At time: 64.75403547286987 and batch: 1000, loss is 5.354497509002686 and perplexity is 211.5576438281266
At time: 65.79096007347107 and batch: 1050, loss is 5.257876424789429 and perplexity is 192.0731760713229
At time: 66.83797955513 and batch: 1100, loss is 5.351427173614502 and perplexity is 210.9090870605308
At time: 67.87712073326111 and batch: 1150, loss is 5.247153692245483 and perplexity is 190.0246294123482
At time: 68.91469192504883 and batch: 1200, loss is 5.323619966506958 and perplexity is 205.12508555697903
At time: 69.9520812034607 and batch: 1250, loss is 5.25636770248413 and perplexity is 191.78360947904986
At time: 70.98817086219788 and batch: 1300, loss is 5.291593055725098 and perplexity is 198.65964935307034
At time: 72.03116464614868 and batch: 1350, loss is 5.2385741806030275 and perplexity is 188.4012846023876
At time: 73.07218956947327 and batch: 1400, loss is 5.242826452255249 and perplexity is 189.2041237795496
At time: 74.11042785644531 and batch: 1450, loss is 5.185097942352295 and perplexity is 178.5909405500846
At time: 75.15229797363281 and batch: 1500, loss is 5.161765613555908 and perplexity is 174.47223435809823
At time: 76.1945059299469 and batch: 1550, loss is 5.150107688903809 and perplexity is 172.4500602748999
At time: 77.23454475402832 and batch: 1600, loss is 5.19380295753479 and perplexity is 180.15236364488078
At time: 78.27597093582153 and batch: 1650, loss is 5.1677682495117185 and perplexity is 175.5226772243096
At time: 79.31871509552002 and batch: 1700, loss is 5.182331771850586 and perplexity is 178.0976101909739
At time: 80.35852932929993 and batch: 1750, loss is 5.202354755401611 and perplexity is 181.6995966263543
At time: 81.40696120262146 and batch: 1800, loss is 5.160403604507446 and perplexity is 174.23476335173726
At time: 82.45946550369263 and batch: 1850, loss is 5.148628225326538 and perplexity is 172.19511532920797
At time: 83.51533460617065 and batch: 1900, loss is 5.193526000976562 and perplexity is 180.10247617493897
At time: 84.57245302200317 and batch: 1950, loss is 5.120685424804687 and perplexity is 167.4501047508039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.920735487827035 and perplexity of 137.10341400508324
finished 2 epochs...
Completing Train Step...
At time: 87.93728590011597 and batch: 50, loss is 5.090110330581665 and perplexity is 162.4077796098351
At time: 89.0050880908966 and batch: 100, loss is 5.044989795684814 and perplexity is 155.2427150446829
At time: 90.04611563682556 and batch: 150, loss is 5.005821704864502 and perplexity is 149.27969662833738
At time: 91.08778595924377 and batch: 200, loss is 4.97117015838623 and perplexity is 144.19552028538683
At time: 92.12868690490723 and batch: 250, loss is 4.991645774841309 and perplexity is 147.17844686811634
At time: 93.17532134056091 and batch: 300, loss is 5.009905414581299 and perplexity is 149.89055801734563
At time: 94.22049570083618 and batch: 350, loss is 4.996591348648071 and perplexity is 147.90813160747325
At time: 95.27216076850891 and batch: 400, loss is 4.962697620391846 and perplexity is 142.97897913404245
At time: 96.31661891937256 and batch: 450, loss is 4.936093082427979 and perplexity is 139.2252440549904
At time: 97.36054992675781 and batch: 500, loss is 4.9442935562133785 and perplexity is 140.37165113529784
At time: 98.40170550346375 and batch: 550, loss is 4.9070550727844235 and perplexity is 135.2405538014603
At time: 99.44625067710876 and batch: 600, loss is 4.899894914627075 and perplexity is 134.27566853480803
At time: 100.50174379348755 and batch: 650, loss is 4.968761043548584 and perplexity is 143.8485548255747
At time: 101.54749274253845 and batch: 700, loss is 4.963452968597412 and perplexity is 143.08701884803025
At time: 102.5895779132843 and batch: 750, loss is 4.910671062469483 and perplexity is 135.73046747658876
At time: 103.63095617294312 and batch: 800, loss is 4.890171136856079 and perplexity is 132.97632925502185
At time: 104.70849084854126 and batch: 850, loss is 4.892469272613526 and perplexity is 133.28227833378176
At time: 105.7524983882904 and batch: 900, loss is 4.918436555862427 and perplexity is 136.78858460851004
At time: 106.79812049865723 and batch: 950, loss is 4.964671316146851 and perplexity is 143.26145480703454
At time: 107.84477806091309 and batch: 1000, loss is 4.94133056640625 and perplexity is 139.95634693866512
At time: 108.89188647270203 and batch: 1050, loss is 4.868163175582886 and perplexity is 130.08175996612874
At time: 109.9340672492981 and batch: 1100, loss is 4.950310468673706 and perplexity is 141.2188011299739
At time: 110.97631859779358 and batch: 1150, loss is 4.867019186019897 and perplexity is 129.9330328777308
At time: 112.01802086830139 and batch: 1200, loss is 4.9397685337066655 and perplexity is 139.7379012023405
At time: 113.06041550636292 and batch: 1250, loss is 4.899987545013428 and perplexity is 134.2881071179486
At time: 114.10209679603577 and batch: 1300, loss is 4.921059608459473 and perplexity is 137.1478592527617
At time: 115.1468653678894 and batch: 1350, loss is 4.834692659378052 and perplexity is 125.79991384108287
At time: 116.20220685005188 and batch: 1400, loss is 4.835126876831055 and perplexity is 125.85455022043519
At time: 117.24994254112244 and batch: 1450, loss is 4.779024963378906 and perplexity is 118.9882755394313
At time: 118.2934799194336 and batch: 1500, loss is 4.775404920578003 and perplexity is 118.55831160264587
At time: 119.34883713722229 and batch: 1550, loss is 4.785049886703491 and perplexity is 119.70733473921837
At time: 120.40673327445984 and batch: 1600, loss is 4.847243690490723 and perplexity is 127.38878258659761
At time: 121.46962261199951 and batch: 1650, loss is 4.811495056152344 and perplexity is 122.91524540992319
At time: 122.53835391998291 and batch: 1700, loss is 4.8319721508026126 and perplexity is 125.45813920789311
At time: 123.60206484794617 and batch: 1750, loss is 4.841386852264404 and perplexity is 126.64486771617905
At time: 124.65703248977661 and batch: 1800, loss is 4.803915538787842 and perplexity is 121.9871289536573
At time: 125.71159958839417 and batch: 1850, loss is 4.821577281951904 and perplexity is 124.1607729625962
At time: 126.76729083061218 and batch: 1900, loss is 4.885730533599854 and perplexity is 132.3871432731035
At time: 127.82594347000122 and batch: 1950, loss is 4.815714511871338 and perplexity is 123.43497656531845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.778586596111919 and perplexity of 118.93612640535133
finished 3 epochs...
Completing Train Step...
At time: 131.2211310863495 and batch: 50, loss is 4.784858064651489 and perplexity is 119.68437443484581
At time: 132.272723197937 and batch: 100, loss is 4.747208290100097 and perplexity is 115.26205672834534
At time: 133.32270741462708 and batch: 150, loss is 4.710382537841797 and perplexity is 111.09464968573262
At time: 134.37088799476624 and batch: 200, loss is 4.686075353622437 and perplexity is 108.42680679852079
At time: 135.42484760284424 and batch: 250, loss is 4.698846101760864 and perplexity is 109.82037777158106
At time: 136.47354936599731 and batch: 300, loss is 4.726496410369873 and perplexity is 112.89931573936319
At time: 137.5152566432953 and batch: 350, loss is 4.733636293411255 and perplexity is 113.70828819691741
At time: 138.55786728858948 and batch: 400, loss is 4.6885578823089595 and perplexity is 108.69631384786362
At time: 139.60555624961853 and batch: 450, loss is 4.688141794204712 and perplexity is 108.65109601264997
At time: 140.65689826011658 and batch: 500, loss is 4.693764162063599 and perplexity is 109.26369295164079
At time: 141.7089719772339 and batch: 550, loss is 4.6620261764526365 and perplexity is 105.85033648411087
At time: 142.75954508781433 and batch: 600, loss is 4.643489532470703 and perplexity is 103.90630010157705
At time: 143.80686569213867 and batch: 650, loss is 4.7036668491363525 and perplexity is 110.35107221365757
At time: 144.8547694683075 and batch: 700, loss is 4.720302991867065 and perplexity is 112.20224388538165
At time: 145.90321397781372 and batch: 750, loss is 4.670179204940796 and perplexity is 106.7168649084364
At time: 146.9509813785553 and batch: 800, loss is 4.6484923171997075 and perplexity is 104.42742339992931
At time: 148.00087785720825 and batch: 850, loss is 4.648718290328979 and perplexity is 104.45102385801103
At time: 149.052396774292 and batch: 900, loss is 4.674917964935303 and perplexity is 107.22377062227989
At time: 150.10318207740784 and batch: 950, loss is 4.734484338760376 and perplexity is 113.80475888185553
At time: 151.15105605125427 and batch: 1000, loss is 4.704062290191651 and perplexity is 110.3947181872432
At time: 152.19922471046448 and batch: 1050, loss is 4.640112733840942 and perplexity is 103.55602119328503
At time: 153.24705839157104 and batch: 1100, loss is 4.71276777267456 and perplexity is 111.35995279321988
At time: 154.29767656326294 and batch: 1150, loss is 4.6376814365386965 and perplexity is 103.30455154094426
At time: 155.35644578933716 and batch: 1200, loss is 4.707593269348145 and perplexity is 110.78520863725588
At time: 156.40769624710083 and batch: 1250, loss is 4.680890922546387 and perplexity is 107.86613014245422
At time: 157.45879101753235 and batch: 1300, loss is 4.701322221755982 and perplexity is 110.09264314661343
At time: 158.5084354877472 and batch: 1350, loss is 4.608576021194458 and perplexity is 100.34116416531553
At time: 159.55581212043762 and batch: 1400, loss is 4.610080518722534 and perplexity is 100.49224081749443
At time: 160.60739469528198 and batch: 1450, loss is 4.54263934135437 and perplexity is 93.93840874085105
At time: 161.6627025604248 and batch: 1500, loss is 4.543433027267456 and perplexity is 94.01299592805083
At time: 162.7136151790619 and batch: 1550, loss is 4.555117473602295 and perplexity is 95.11792842498268
At time: 163.76661658287048 and batch: 1600, loss is 4.633391609191895 and perplexity is 102.86234203007207
At time: 164.8236334323883 and batch: 1650, loss is 4.589339094161987 and perplexity is 98.42935612431494
At time: 165.87737226486206 and batch: 1700, loss is 4.619763603210449 and perplexity is 101.47004210188612
At time: 166.9271354675293 and batch: 1750, loss is 4.6147405052185055 and perplexity is 100.96162611782427
At time: 167.98852586746216 and batch: 1800, loss is 4.584383535385132 and perplexity is 97.94279026327332
At time: 169.0429539680481 and batch: 1850, loss is 4.608110942840576 and perplexity is 100.29450851196714
At time: 170.0975730419159 and batch: 1900, loss is 4.680057945251465 and perplexity is 107.77631751628677
At time: 171.14866590499878 and batch: 1950, loss is 4.616093769073486 and perplexity is 101.09834632558237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.71236458711846 and perplexity of 111.31506311876788
finished 4 epochs...
Completing Train Step...
At time: 174.57309985160828 and batch: 50, loss is 4.581295919418335 and perplexity is 97.6408469226418
At time: 175.6642210483551 and batch: 100, loss is 4.550889520645142 and perplexity is 94.71662324572658
At time: 176.72486448287964 and batch: 150, loss is 4.521010503768921 and perplexity is 91.92844509931712
At time: 177.77707314491272 and batch: 200, loss is 4.49552282333374 and perplexity is 89.61500955745635
At time: 178.8355371952057 and batch: 250, loss is 4.505003490447998 and perplexity is 90.46865982447059
At time: 179.90012288093567 and batch: 300, loss is 4.5361405372619625 and perplexity is 93.32990085412905
At time: 180.96425127983093 and batch: 350, loss is 4.544191064834595 and perplexity is 94.08428832850863
At time: 182.02398896217346 and batch: 400, loss is 4.49404278755188 and perplexity is 89.48247423941939
At time: 183.09061932563782 and batch: 450, loss is 4.502963857650757 and perplexity is 90.28432503032035
At time: 184.1742765903473 and batch: 500, loss is 4.517107915878296 and perplexity is 91.57038539684109
At time: 185.23011755943298 and batch: 550, loss is 4.48906644821167 and perplexity is 89.03828521691197
At time: 186.29293608665466 and batch: 600, loss is 4.469670372009277 and perplexity is 87.32793253769199
At time: 187.35658168792725 and batch: 650, loss is 4.52959794998169 and perplexity is 92.72127499686812
At time: 188.4219732284546 and batch: 700, loss is 4.548793478012085 and perplexity is 94.51830108380653
At time: 189.4827995300293 and batch: 750, loss is 4.502356042861939 and perplexity is 90.22946555625721
At time: 190.53761172294617 and batch: 800, loss is 4.472401294708252 and perplexity is 87.56674431073932
At time: 191.5998284816742 and batch: 850, loss is 4.479046115875244 and perplexity is 88.1505471515129
At time: 192.66258716583252 and batch: 900, loss is 4.498342666625977 and perplexity is 89.86806646376841
At time: 193.72491073608398 and batch: 950, loss is 4.563419389724731 and perplexity is 95.9108764281334
At time: 194.79374861717224 and batch: 1000, loss is 4.530776300430298 and perplexity is 92.83059755034655
At time: 195.85845351219177 and batch: 1050, loss is 4.47495867729187 and perplexity is 87.79097257406316
At time: 196.9218771457672 and batch: 1100, loss is 4.533010654449463 and perplexity is 93.03824586261764
At time: 197.98323678970337 and batch: 1150, loss is 4.470397987365723 and perplexity is 87.39149680481711
At time: 199.04522347450256 and batch: 1200, loss is 4.531809720993042 and perplexity is 92.92658018537915
At time: 200.1081576347351 and batch: 1250, loss is 4.514849033355713 and perplexity is 91.36377209912007
At time: 201.16973090171814 and batch: 1300, loss is 4.530020055770874 and perplexity is 92.76042144521482
At time: 202.23171520233154 and batch: 1350, loss is 4.432945766448975 and perplexity is 84.17902377916997
At time: 203.29470133781433 and batch: 1400, loss is 4.440848741531372 and perplexity is 84.84692423061784
At time: 204.35205268859863 and batch: 1450, loss is 4.367153606414795 and perplexity is 78.81896231378119
At time: 205.41901063919067 and batch: 1500, loss is 4.377098531723022 and perplexity is 79.60672161804465
At time: 206.48278045654297 and batch: 1550, loss is 4.383819227218628 and perplexity is 80.14353601593933
At time: 207.54548501968384 and batch: 1600, loss is 4.478136472702026 and perplexity is 88.07039806714144
At time: 208.61024641990662 and batch: 1650, loss is 4.42550630569458 and perplexity is 83.55510093777919
At time: 209.67141032218933 and batch: 1700, loss is 4.459187278747558 and perplexity is 86.41724741506428
At time: 210.73327708244324 and batch: 1750, loss is 4.457351541519165 and perplexity is 86.25875357783731
At time: 211.795423746109 and batch: 1800, loss is 4.42478500366211 and perplexity is 83.49485420430722
At time: 212.8598244190216 and batch: 1850, loss is 4.452854843139648 and perplexity is 85.87174476347812
At time: 213.92181015014648 and batch: 1900, loss is 4.530379800796509 and perplexity is 92.7937975484892
At time: 214.983877658844 and batch: 1950, loss is 4.460818662643432 and perplexity is 86.5583421793935
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.68448486328125 and perplexity of 108.25449207835588
finished 5 epochs...
Completing Train Step...
At time: 218.3879692554474 and batch: 50, loss is 4.423182945251465 and perplexity is 83.36119766226415
At time: 219.48296666145325 and batch: 100, loss is 4.39144907951355 and perplexity is 80.7573580661397
At time: 220.54788398742676 and batch: 150, loss is 4.368596324920654 and perplexity is 78.93275795712596
At time: 221.60811972618103 and batch: 200, loss is 4.344019422531128 and perplexity is 77.01647981544612
At time: 222.6696856021881 and batch: 250, loss is 4.3497848796844485 and perplexity is 77.46179752646513
At time: 223.73480343818665 and batch: 300, loss is 4.383125410079956 and perplexity is 80.08795034247402
At time: 224.80217790603638 and batch: 350, loss is 4.3905832481384275 and perplexity is 80.68746607346039
At time: 225.8757619857788 and batch: 400, loss is 4.347660913467407 and perplexity is 77.29744588585947
At time: 226.94476103782654 and batch: 450, loss is 4.3584021377563475 and perplexity is 78.13219015114412
At time: 228.01845240592957 and batch: 500, loss is 4.377635612487793 and perplexity is 79.64948834053612
At time: 229.09075927734375 and batch: 550, loss is 4.3480354690551755 and perplexity is 77.32640349891561
At time: 230.1632206439972 and batch: 600, loss is 4.3367793750762935 and perplexity is 76.46089052012758
At time: 231.23249316215515 and batch: 650, loss is 4.384713392257691 and perplexity is 80.21522961212851
At time: 232.30233025550842 and batch: 700, loss is 4.403723535537719 and perplexity is 81.75471921711804
At time: 233.3739137649536 and batch: 750, loss is 4.361225471496582 and perplexity is 78.35309509725013
At time: 234.44415855407715 and batch: 800, loss is 4.335737781524658 and perplexity is 76.38129081207742
At time: 235.50966358184814 and batch: 850, loss is 4.345451402664184 and perplexity is 77.12684488589468
At time: 236.59029054641724 and batch: 900, loss is 4.359771242141724 and perplexity is 78.23923453606677
At time: 237.70030283927917 and batch: 950, loss is 4.425084037780762 and perplexity is 83.51982574793186
At time: 238.77130126953125 and batch: 1000, loss is 4.394344530105591 and perplexity is 80.991525853395
At time: 239.84391355514526 and batch: 1050, loss is 4.3442529201507565 and perplexity is 77.0344650798317
At time: 240.90334343910217 and batch: 1100, loss is 4.396279592514038 and perplexity is 81.14840124336041
At time: 241.96529340744019 and batch: 1150, loss is 4.34105842590332 and perplexity is 76.78877156647496
At time: 243.03219270706177 and batch: 1200, loss is 4.396861400604248 and perplexity is 81.19562777676884
At time: 244.088960647583 and batch: 1250, loss is 4.388430252075195 and perplexity is 80.51393315153365
At time: 245.1498053073883 and batch: 1300, loss is 4.397180213928222 and perplexity is 81.22151815163149
At time: 246.2092742919922 and batch: 1350, loss is 4.301157097816468 and perplexity is 73.78512092641343
At time: 247.2657012939453 and batch: 1400, loss is 4.30866587638855 and perplexity is 74.34124234473614
At time: 248.3221800327301 and batch: 1450, loss is 4.23036159992218 and perplexity is 68.74208481273828
At time: 249.38243198394775 and batch: 1500, loss is 4.250348272323609 and perplexity is 70.12983237370634
At time: 250.44394540786743 and batch: 1550, loss is 4.255466966629029 and perplexity is 70.4897258538734
At time: 251.50532507896423 and batch: 1600, loss is 4.347520208358764 and perplexity is 77.28657050546704
At time: 252.56816291809082 and batch: 1650, loss is 4.296687788963318 and perplexity is 73.45608825423815
At time: 253.62889695167542 and batch: 1700, loss is 4.329199047088623 and perplexity is 75.88348312535553
At time: 254.69180059432983 and batch: 1750, loss is 4.329922609329223 and perplexity is 75.93840941732938
At time: 255.75631737709045 and batch: 1800, loss is 4.294211282730102 and perplexity is 73.2743988641221
At time: 256.8234770298004 and batch: 1850, loss is 4.3219217014312745 and perplexity is 75.3332573090131
At time: 257.8876323699951 and batch: 1900, loss is 4.404727907180786 and perplexity is 81.83687258813859
At time: 258.9474310874939 and batch: 1950, loss is 4.335476541519165 and perplexity is 76.36133956939096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.676848655523256 and perplexity of 107.43098651754688
finished 6 epochs...
Completing Train Step...
At time: 262.35088896751404 and batch: 50, loss is 4.296294965744019 and perplexity is 73.42723866393841
At time: 263.40860962867737 and batch: 100, loss is 4.266182708740234 and perplexity is 71.24913713861736
At time: 264.4935314655304 and batch: 150, loss is 4.241839618682861 and perplexity is 69.53565333670456
At time: 265.5503888130188 and batch: 200, loss is 4.227085428237915 and perplexity is 68.51724245315177
At time: 266.60369658470154 and batch: 250, loss is 4.230170035362244 and perplexity is 68.728917526745
At time: 267.6579964160919 and batch: 300, loss is 4.256969652175903 and perplexity is 70.59572937114694
At time: 268.7132308483124 and batch: 350, loss is 4.26692006111145 and perplexity is 71.30169223226392
At time: 269.77496814727783 and batch: 400, loss is 4.221420273780823 and perplexity is 68.13017911368158
At time: 270.8345191478729 and batch: 450, loss is 4.238981156349182 and perplexity is 69.33717210150719
At time: 271.8954417705536 and batch: 500, loss is 4.265520877838135 and perplexity is 71.20199785874784
At time: 272.9539613723755 and batch: 550, loss is 4.236228160858154 and perplexity is 69.14654969106299
At time: 274.00858902931213 and batch: 600, loss is 4.226876602172852 and perplexity is 68.50293576087842
At time: 275.06306076049805 and batch: 650, loss is 4.268413667678833 and perplexity is 71.40826847972605
At time: 276.11436557769775 and batch: 700, loss is 4.2954401016235355 and perplexity is 73.36449517453845
At time: 277.1618437767029 and batch: 750, loss is 4.2449852466583256 and perplexity is 69.75473102093152
At time: 278.2175235748291 and batch: 800, loss is 4.21722297668457 and perplexity is 67.84481580695407
At time: 279.2715849876404 and batch: 850, loss is 4.226544132232666 and perplexity is 68.48016437953311
At time: 280.33229327201843 and batch: 900, loss is 4.2439648103713985 and perplexity is 69.68358706732232
At time: 281.38322830200195 and batch: 950, loss is 4.311887102127075 and perplexity is 74.58109837582003
At time: 282.43583846092224 and batch: 1000, loss is 4.275095596313476 and perplexity is 71.88701111444358
At time: 283.4904065132141 and batch: 1050, loss is 4.235013942718506 and perplexity is 69.06264164777713
At time: 284.54463505744934 and batch: 1100, loss is 4.284940133094787 and perplexity is 72.59820036007457
At time: 285.59488892555237 and batch: 1150, loss is 4.227251844406128 and perplexity is 68.52864577891991
At time: 286.6447036266327 and batch: 1200, loss is 4.286462550163269 and perplexity is 72.70880927452976
At time: 287.6946792602539 and batch: 1250, loss is 4.275251235961914 and perplexity is 71.89820045431054
At time: 288.7578287124634 and batch: 1300, loss is 4.288636965751648 and perplexity is 72.86708045412888
At time: 289.80902075767517 and batch: 1350, loss is 4.189604415893554 and perplexity is 65.99667855880885
At time: 290.85989785194397 and batch: 1400, loss is 4.19728147983551 and perplexity is 66.50528909987518
At time: 291.9040584564209 and batch: 1450, loss is 4.12648111820221 and perplexity is 61.959510682345616
At time: 292.9485297203064 and batch: 1500, loss is 4.138425650596619 and perplexity is 62.70402565467864
At time: 293.9933109283447 and batch: 1550, loss is 4.144492816925049 and perplexity is 63.08561782883341
At time: 295.0474863052368 and batch: 1600, loss is 4.239311738014221 and perplexity is 69.3600974884571
At time: 296.1041188240051 and batch: 1650, loss is 4.181045641899109 and perplexity is 65.4342382357927
At time: 297.1566662788391 and batch: 1700, loss is 4.217217807769775 and perplexity is 67.84446512378823
At time: 298.20584869384766 and batch: 1750, loss is 4.220613498687744 and perplexity is 68.0752355486157
At time: 299.2567868232727 and batch: 1800, loss is 4.188030204772949 and perplexity is 65.89286758513136
At time: 300.3115236759186 and batch: 1850, loss is 4.214895691871643 and perplexity is 67.68710518743892
At time: 301.36595606803894 and batch: 1900, loss is 4.2947868061065675 and perplexity is 73.31658213112863
At time: 302.41783452033997 and batch: 1950, loss is 4.225531969070435 and perplexity is 68.41088634605576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.66584955259811 and perplexity of 106.25581679353641
finished 7 epochs...
Completing Train Step...
At time: 305.79074597358704 and batch: 50, loss is 4.198661065101623 and perplexity is 66.5971021342287
At time: 306.8745758533478 and batch: 100, loss is 4.163768305778503 and perplexity is 64.31341917266707
At time: 307.94808173179626 and batch: 150, loss is 4.137411985397339 and perplexity is 62.640496969865936
At time: 309.0047047138214 and batch: 200, loss is 4.119864263534546 and perplexity is 61.55088699753754
At time: 310.0703721046448 and batch: 250, loss is 4.125808005332947 and perplexity is 61.91781897151977
At time: 311.1264853477478 and batch: 300, loss is 4.152932176589966 and perplexity is 63.62027294749723
At time: 312.18617510795593 and batch: 350, loss is 4.160944576263428 and perplexity is 64.13207163143323
At time: 313.2401192188263 and batch: 400, loss is 4.11915894985199 and perplexity is 61.507489620945506
At time: 314.2935981750488 and batch: 450, loss is 4.1358721780776975 and perplexity is 62.54411689654009
At time: 315.3577070236206 and batch: 500, loss is 4.164658613204956 and perplexity is 64.37070338387258
At time: 316.42172050476074 and batch: 550, loss is 4.139923620223999 and perplexity is 62.798024766954235
At time: 317.5290377140045 and batch: 600, loss is 4.1293277215957644 and perplexity is 62.13613610771607
At time: 318.58988857269287 and batch: 650, loss is 4.171218695640564 and perplexity is 64.79436862460386
At time: 319.64952516555786 and batch: 700, loss is 4.195565142631531 and perplexity is 66.39124149799963
At time: 320.71839785575867 and batch: 750, loss is 4.1486672592163085 and perplexity is 63.349515529506824
At time: 321.7795042991638 and batch: 800, loss is 4.119185090065002 and perplexity is 61.509097460840636
At time: 322.83536982536316 and batch: 850, loss is 4.127393336296081 and perplexity is 62.016057056469066
At time: 323.89443039894104 and batch: 900, loss is 4.145065712928772 and perplexity is 63.121769681817206
At time: 324.95261907577515 and batch: 950, loss is 4.220280480384827 and perplexity is 68.05256902359595
At time: 326.0103278160095 and batch: 1000, loss is 4.176677970886231 and perplexity is 65.1490662322885
At time: 327.0688064098358 and batch: 1050, loss is 4.140170722007752 and perplexity is 62.81354418824968
At time: 328.1252782344818 and batch: 1100, loss is 4.1867587184906006 and perplexity is 65.80913894907852
At time: 329.1797397136688 and batch: 1150, loss is 4.1311367321014405 and perplexity is 62.248642762895955
At time: 330.2341523170471 and batch: 1200, loss is 4.188710055351257 and perplexity is 65.93768012045349
At time: 331.29226660728455 and batch: 1250, loss is 4.183946938514709 and perplexity is 65.6243580333317
At time: 332.34877038002014 and batch: 1300, loss is 4.1866618299484255 and perplexity is 65.80276310642198
At time: 333.4057741165161 and batch: 1350, loss is 4.092381086349487 and perplexity is 59.882307029108745
At time: 334.4636571407318 and batch: 1400, loss is 4.101633110046387 and perplexity is 60.43891043629429
At time: 335.52620673179626 and batch: 1450, loss is 4.029441971778869 and perplexity is 56.22952482897342
At time: 336.580050945282 and batch: 1500, loss is 4.046380581855774 and perplexity is 57.190087153540155
At time: 337.6313359737396 and batch: 1550, loss is 4.055341882705688 and perplexity is 57.704887927380575
At time: 338.68377804756165 and batch: 1600, loss is 4.1496786832809445 and perplexity is 63.41362116752399
At time: 339.7393310070038 and batch: 1650, loss is 4.087706427574158 and perplexity is 59.60303094583656
At time: 340.7933382987976 and batch: 1700, loss is 4.130567450523376 and perplexity is 62.21321584221494
At time: 341.85092544555664 and batch: 1750, loss is 4.129517960548401 and perplexity is 62.14795794562144
At time: 342.9048593044281 and batch: 1800, loss is 4.097282238006592 and perplexity is 60.17651969894585
At time: 343.9555516242981 and batch: 1850, loss is 4.121440396308899 and perplexity is 61.64797586019513
At time: 345.0237009525299 and batch: 1900, loss is 4.195296502113342 and perplexity is 66.37340851591843
At time: 346.08171916007996 and batch: 1950, loss is 4.1319197034835815 and perplexity is 62.29740075432149
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.668120344295058 and perplexity of 106.49737578133573
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 349.42840027809143 and batch: 50, loss is 4.1343314075469975 and perplexity is 62.447824965291794
At time: 350.51345109939575 and batch: 100, loss is 4.124957122802734 and perplexity is 61.86515658897602
At time: 351.5675687789917 and batch: 150, loss is 4.10754729270935 and perplexity is 60.797416282123095
At time: 352.6191174983978 and batch: 200, loss is 4.078290314674377 and perplexity is 59.04443610057248
At time: 353.67044949531555 and batch: 250, loss is 4.08114501953125 and perplexity is 59.21323135476526
At time: 354.72070813179016 and batch: 300, loss is 4.105796127319336 and perplexity is 60.69104311661397
At time: 355.7788212299347 and batch: 350, loss is 4.106663422584534 and perplexity is 60.74370300348328
At time: 356.84211707115173 and batch: 400, loss is 4.0618805503845214 and perplexity is 58.083437268439866
At time: 357.89603090286255 and batch: 450, loss is 4.0720434713363645 and perplexity is 58.67674441016777
At time: 358.9494209289551 and batch: 500, loss is 4.098176956176758 and perplexity is 60.23038481799487
At time: 360.0011713504791 and batch: 550, loss is 4.060698928833008 and perplexity is 58.0148451601151
At time: 361.0507674217224 and batch: 600, loss is 4.042887177467346 and perplexity is 56.99064761640838
At time: 362.10274052619934 and batch: 650, loss is 4.077587418556213 and perplexity is 59.00294857805559
At time: 363.15474915504456 and batch: 700, loss is 4.09325602054596 and perplexity is 59.934723034226096
At time: 364.20219588279724 and batch: 750, loss is 4.041201195716858 and perplexity is 56.89464337801684
At time: 365.25653886795044 and batch: 800, loss is 4.007348346710205 and perplexity is 55.00083388759684
At time: 366.3099293708801 and batch: 850, loss is 4.00659821510315 and perplexity is 54.95959149422869
At time: 367.35890793800354 and batch: 900, loss is 4.019454188346863 and perplexity is 55.67071180960168
At time: 368.4050467014313 and batch: 950, loss is 4.087074317932129 and perplexity is 59.56536720034396
At time: 369.45015597343445 and batch: 1000, loss is 4.038946323394775 and perplexity is 56.76649775169779
At time: 370.53237295150757 and batch: 1050, loss is 4.003764262199402 and perplexity is 54.80405909017267
At time: 371.58718085289 and batch: 1100, loss is 4.035570359230041 and perplexity is 56.575179213502
At time: 372.64861702919006 and batch: 1150, loss is 3.9754735708236693 and perplexity is 53.275340579585745
At time: 373.70086216926575 and batch: 1200, loss is 4.02381609916687 and perplexity is 55.914072863554466
At time: 374.75274085998535 and batch: 1250, loss is 4.0037014770507815 and perplexity is 54.80061831719354
At time: 375.81127071380615 and batch: 1300, loss is 4.003081860542298 and perplexity is 54.76667346688993
At time: 376.86588501930237 and batch: 1350, loss is 3.903871431350708 and perplexity is 49.59407799550114
At time: 377.92054057121277 and batch: 1400, loss is 3.904834747314453 and perplexity is 49.64187578103006
At time: 378.9739737510681 and batch: 1450, loss is 3.8203322982788084 and perplexity is 45.61936503891637
At time: 380.02414536476135 and batch: 1500, loss is 3.838124461174011 and perplexity is 46.43829588501723
At time: 381.0741012096405 and batch: 1550, loss is 3.8409393644332885 and perplexity is 46.569199349316996
At time: 382.123174905777 and batch: 1600, loss is 3.9233697557449343 and perplexity is 50.5705684430192
At time: 383.1762502193451 and batch: 1650, loss is 3.851162438392639 and perplexity is 47.047721534767625
At time: 384.232008934021 and batch: 1700, loss is 3.887858762741089 and perplexity is 48.80626875684291
At time: 385.28593611717224 and batch: 1750, loss is 3.8760427141189577 and perplexity is 48.23296527338809
At time: 386.3369174003601 and batch: 1800, loss is 3.8337189149856568 and perplexity is 46.23415982318208
At time: 387.3907880783081 and batch: 1850, loss is 3.8388291120529177 and perplexity is 46.47103020280596
At time: 388.44786739349365 and batch: 1900, loss is 3.9077199840545656 and perplexity is 49.78531116790221
At time: 389.5085120201111 and batch: 1950, loss is 3.8466316747665403 and perplexity is 46.83504159443705
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5895289221475295 and perplexity of 98.44804254425283
finished 9 epochs...
Completing Train Step...
At time: 392.86436796188354 and batch: 50, loss is 4.033014574050903 and perplexity is 56.4307698272529
At time: 393.9188542366028 and batch: 100, loss is 4.015164036750793 and perplexity is 55.43238760549727
At time: 394.97501516342163 and batch: 150, loss is 3.9933002758026124 and perplexity is 54.2335801088882
At time: 396.03146862983704 and batch: 200, loss is 3.964465103149414 and perplexity is 52.692077024264655
At time: 397.1135787963867 and batch: 250, loss is 3.9690432357788086 and perplexity is 52.933861379520664
At time: 398.1690580844879 and batch: 300, loss is 3.9935515260696413 and perplexity is 54.247208022309245
At time: 399.22354459762573 and batch: 350, loss is 3.9990283012390138 and perplexity is 54.54512284580336
At time: 400.28538727760315 and batch: 400, loss is 3.9575447034835816 and perplexity is 52.32868564910129
At time: 401.34498381614685 and batch: 450, loss is 3.974776725769043 and perplexity is 53.2382288540323
At time: 402.40544605255127 and batch: 500, loss is 4.003943538665771 and perplexity is 54.81388504898431
At time: 403.46861386299133 and batch: 550, loss is 3.970285758972168 and perplexity is 52.99967380826622
At time: 404.5228340625763 and batch: 600, loss is 3.9528402853012086 and perplexity is 52.0830877793709
At time: 405.57728242874146 and batch: 650, loss is 3.9897982406616213 and perplexity is 54.043984384740135
At time: 406.6341989040375 and batch: 700, loss is 4.009684658050537 and perplexity is 55.12948318342278
At time: 407.69713521003723 and batch: 750, loss is 3.9600135231018068 and perplexity is 52.45803533965494
At time: 408.7647075653076 and batch: 800, loss is 3.9291306066513063 and perplexity is 50.862738714726596
At time: 409.82110047340393 and batch: 850, loss is 3.9328951454162597 and perplexity is 51.05457432605371
At time: 410.8816645145416 and batch: 900, loss is 3.9446955823898318 and perplexity is 51.66060931893898
At time: 411.9385869503021 and batch: 950, loss is 4.017375655174256 and perplexity is 55.55511856217886
At time: 412.9984219074249 and batch: 1000, loss is 3.9696227598190306 and perplexity is 52.96454671531796
At time: 414.0581932067871 and batch: 1050, loss is 3.9366979932785036 and perplexity is 51.24909674003417
At time: 415.1193337440491 and batch: 1100, loss is 3.969287624359131 and perplexity is 52.946799391641
At time: 416.1885120868683 and batch: 1150, loss is 3.916668200492859 and perplexity is 50.23280003541347
At time: 417.25016045570374 and batch: 1200, loss is 3.967309603691101 and perplexity is 52.842173038795586
At time: 418.30518531799316 and batch: 1250, loss is 3.951306462287903 and perplexity is 52.00326277509495
At time: 419.36209535598755 and batch: 1300, loss is 3.954747552871704 and perplexity is 52.18251895445016
At time: 420.426481962204 and batch: 1350, loss is 3.8552548551559447 and perplexity is 47.24065493171715
At time: 421.48748326301575 and batch: 1400, loss is 3.8630622148513796 and perplexity is 47.61092324516777
At time: 422.5423023700714 and batch: 1450, loss is 3.782424597740173 and perplexity is 43.922406905617656
At time: 423.59365010261536 and batch: 1500, loss is 3.80276376247406 and perplexity is 44.82489882932102
At time: 424.6459770202637 and batch: 1550, loss is 3.806909341812134 and perplexity is 45.011109713052896
At time: 425.702175617218 and batch: 1600, loss is 3.894935631752014 and perplexity is 49.15288937548228
At time: 426.7631266117096 and batch: 1650, loss is 3.8242970657348634 and perplexity is 45.80059424120938
At time: 427.83768033981323 and batch: 1700, loss is 3.8662178707122803 and perplexity is 47.76140424239352
At time: 428.89878511428833 and batch: 1750, loss is 3.857547459602356 and perplexity is 47.34908331146581
At time: 429.95954751968384 and batch: 1800, loss is 3.819982304573059 and perplexity is 45.60340134205214
At time: 431.0201234817505 and batch: 1850, loss is 3.8298492574691774 and perplexity is 46.05559517394532
At time: 432.0823321342468 and batch: 1900, loss is 3.901697039604187 and perplexity is 49.48635819659365
At time: 433.14258098602295 and batch: 1950, loss is 3.8436210775375366 and perplexity is 46.694252184435726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.589323673691861 and perplexity of 98.42783830907197
finished 10 epochs...
Completing Train Step...
At time: 436.5716462135315 and batch: 50, loss is 3.983612365722656 and perplexity is 53.71070692521422
At time: 437.64776849746704 and batch: 100, loss is 3.964332871437073 and perplexity is 52.685109921339055
At time: 438.69703245162964 and batch: 150, loss is 3.943165826797485 and perplexity is 51.581641628961684
At time: 439.7476818561554 and batch: 200, loss is 3.914621033668518 and perplexity is 50.1300703020157
At time: 440.800062417984 and batch: 250, loss is 3.917184443473816 and perplexity is 50.25873906068937
At time: 441.86064410209656 and batch: 300, loss is 3.941541314125061 and perplexity is 51.49791462467399
At time: 442.9145817756653 and batch: 350, loss is 3.948192195892334 and perplexity is 51.841562680649126
At time: 443.9745705127716 and batch: 400, loss is 3.907131037712097 and perplexity is 49.75599892349805
At time: 445.0329701900482 and batch: 450, loss is 3.9262546825408937 and perplexity is 50.71667147795538
At time: 446.0882303714752 and batch: 500, loss is 3.9580249881744383 and perplexity is 52.35382435209507
At time: 447.13711285591125 and batch: 550, loss is 3.924264740943909 and perplexity is 50.61584861279786
At time: 448.1926794052124 and batch: 600, loss is 3.907813787460327 and perplexity is 49.78998141868595
At time: 449.2474603652954 and batch: 650, loss is 3.94509614944458 and perplexity is 51.68130700218864
At time: 450.3250207901001 and batch: 700, loss is 3.965575828552246 and perplexity is 52.75063596817638
At time: 451.37335777282715 and batch: 750, loss is 3.9177693796157835 and perplexity is 50.28814581331343
At time: 452.42160153388977 and batch: 800, loss is 3.886687688827515 and perplexity is 48.74914646242551
At time: 453.47609877586365 and batch: 850, loss is 3.8920697784423828 and perplexity is 49.01222606127355
At time: 454.5260145664215 and batch: 900, loss is 3.904434609413147 and perplexity is 49.62201615859693
At time: 455.5768201351166 and batch: 950, loss is 3.978440480232239 and perplexity is 53.433638400324206
At time: 456.6231725215912 and batch: 1000, loss is 3.9315548038482664 and perplexity is 50.986189597533276
At time: 457.6654121875763 and batch: 1050, loss is 3.900676655769348 and perplexity is 49.43588887006625
At time: 458.7088792324066 and batch: 1100, loss is 3.932179021835327 and perplexity is 51.01802602957475
At time: 459.7586703300476 and batch: 1150, loss is 3.88094699382782 and perplexity is 48.47009422434343
At time: 460.811053276062 and batch: 1200, loss is 3.932135968208313 and perplexity is 51.01582956579428
At time: 461.86330461502075 and batch: 1250, loss is 3.9179261302948 and perplexity is 50.296029132157784
At time: 462.9124753475189 and batch: 1300, loss is 3.9232311487197875 and perplexity is 50.56355949272342
At time: 463.962366104126 and batch: 1350, loss is 3.824446563720703 and perplexity is 45.80744184963778
At time: 465.01147270202637 and batch: 1400, loss is 3.835500831604004 and perplexity is 46.31661868649697
At time: 466.0641875267029 and batch: 1450, loss is 3.755610270500183 and perplexity is 42.760307203624684
At time: 467.11806058883667 and batch: 1500, loss is 3.7764113998413085 and perplexity is 43.65908527667618
At time: 468.16784739494324 and batch: 1550, loss is 3.7811229467391967 and perplexity is 43.865272453329055
At time: 469.2156548500061 and batch: 1600, loss is 3.8709266281127928 and perplexity is 47.98683143253208
At time: 470.26278805732727 and batch: 1650, loss is 3.800582404136658 and perplexity is 44.72722623073493
At time: 471.3147747516632 and batch: 1700, loss is 3.8442526865005493 and perplexity is 46.72375400846407
At time: 472.3676860332489 and batch: 1750, loss is 3.83688796043396 and perplexity is 46.380910383707665
At time: 473.41886281967163 and batch: 1800, loss is 3.801384220123291 and perplexity is 44.7631036173734
At time: 474.4672486782074 and batch: 1850, loss is 3.812523069381714 and perplexity is 45.2645003882516
At time: 475.51763343811035 and batch: 1900, loss is 3.885749969482422 and perplexity is 48.70345487102363
At time: 476.56599140167236 and batch: 1950, loss is 3.8282028150558474 and perplexity is 45.97982967755839
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.594488099563954 and perplexity of 98.93747644523218
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 479.8771276473999 and batch: 50, loss is 3.960738296508789 and perplexity is 52.49606930999187
At time: 480.95431327819824 and batch: 100, loss is 3.9669452476501466 and perplexity is 52.82292318094571
At time: 482.0086588859558 and batch: 150, loss is 3.960603938102722 and perplexity is 52.48901649560765
At time: 483.0611140727997 and batch: 200, loss is 3.9375395584106445 and perplexity is 51.29224434611817
At time: 484.1181242465973 and batch: 250, loss is 3.9360281562805177 and perplexity is 51.21477969362113
At time: 485.17445492744446 and batch: 300, loss is 3.9594999504089357 and perplexity is 52.43110124208334
At time: 486.23117542266846 and batch: 350, loss is 3.9630340480804445 and perplexity is 52.616725689159026
At time: 487.28830766677856 and batch: 400, loss is 3.9212703323364257 and perplexity is 50.464510776776706
At time: 488.340877532959 and batch: 450, loss is 3.9391671323776247 and perplexity is 51.37579424109728
At time: 489.3912959098816 and batch: 500, loss is 3.9700315856933592 and perplexity is 52.98620441925049
At time: 490.4410846233368 and batch: 550, loss is 3.9378774642944334 and perplexity is 51.30957922588945
At time: 491.4912943840027 and batch: 600, loss is 3.9137120771408083 and perplexity is 50.0845249498885
At time: 492.54211163520813 and batch: 650, loss is 3.9465685272216797 and perplexity is 51.757457457471965
At time: 493.5931656360626 and batch: 700, loss is 3.9607117986679077 and perplexity is 52.49467829592991
At time: 494.6461834907532 and batch: 750, loss is 3.9069902896881104 and perplexity is 49.74899635777828
At time: 495.708300113678 and batch: 800, loss is 3.8708741950988768 and perplexity is 47.98431540429384
At time: 496.7686791419983 and batch: 850, loss is 3.8774095821380614 and perplexity is 48.29893844912721
At time: 497.8195207118988 and batch: 900, loss is 3.8842532300949095 and perplexity is 48.630613018043974
At time: 498.86892318725586 and batch: 950, loss is 3.960263104438782 and perplexity is 52.47112952021368
At time: 499.92072081565857 and batch: 1000, loss is 3.9104330110549927 and perplexity is 49.92056344991134
At time: 500.9757936000824 and batch: 1050, loss is 3.8806509590148925 and perplexity is 48.45574751273497
At time: 502.03073477745056 and batch: 1100, loss is 3.9004956102371215 and perplexity is 49.426939533397835
At time: 503.1304316520691 and batch: 1150, loss is 3.8530595874786377 and perplexity is 47.13706279672613
At time: 504.1882495880127 and batch: 1200, loss is 3.8981940174102783 and perplexity is 49.31330965892818
At time: 505.2473838329315 and batch: 1250, loss is 3.8786027908325194 and perplexity is 48.356603558831225
At time: 506.30734276771545 and batch: 1300, loss is 3.8774528551101684 and perplexity is 48.30102853296526
At time: 507.3636929988861 and batch: 1350, loss is 3.773756575584412 and perplexity is 43.54333179860719
At time: 508.4187526702881 and batch: 1400, loss is 3.78894944190979 and perplexity is 44.20993077036134
At time: 509.47285199165344 and batch: 1450, loss is 3.700388231277466 and perplexity is 40.463010317283796
At time: 510.52345609664917 and batch: 1500, loss is 3.7162214422225954 and perplexity is 41.10876841681795
At time: 511.5740122795105 and batch: 1550, loss is 3.719693899154663 and perplexity is 41.25176497568457
At time: 512.6280310153961 and batch: 1600, loss is 3.8091689777374267 and perplexity is 45.1129334325395
At time: 513.6844789981842 and batch: 1650, loss is 3.7330368614196776 and perplexity is 41.80587422767794
At time: 514.7386214733124 and batch: 1700, loss is 3.773396301269531 and perplexity is 43.527647080146075
At time: 515.7907328605652 and batch: 1750, loss is 3.7656955671310426 and perplexity is 43.19373955892618
At time: 516.8461911678314 and batch: 1800, loss is 3.727104597091675 and perplexity is 41.558604889985
At time: 517.8963730335236 and batch: 1850, loss is 3.734578847885132 and perplexity is 41.870388046848504
At time: 518.9472382068634 and batch: 1900, loss is 3.8063404750823975 and perplexity is 44.98551167189592
At time: 520.0030779838562 and batch: 1950, loss is 3.750781927108765 and perplexity is 42.55434338906882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.565956577034884 and perplexity of 96.15452925243352
finished 12 epochs...
Completing Train Step...
At time: 523.3599965572357 and batch: 50, loss is 3.940960235595703 and perplexity is 51.46799898468868
At time: 524.4178514480591 and batch: 100, loss is 3.935244722366333 and perplexity is 51.17467201121236
At time: 525.4732253551483 and batch: 150, loss is 3.921061782836914 and perplexity is 50.45398752565862
At time: 526.5322511196136 and batch: 200, loss is 3.896064910888672 and perplexity is 49.20842806139787
At time: 527.5911931991577 and batch: 250, loss is 3.894428825378418 and perplexity is 49.127984689326034
At time: 528.6453058719635 and batch: 300, loss is 3.91696319103241 and perplexity is 50.247620422028525
At time: 529.7240018844604 and batch: 350, loss is 3.922861032485962 and perplexity is 50.54484856133849
At time: 530.7776291370392 and batch: 400, loss is 3.880124735832214 and perplexity is 48.430255682843935
At time: 531.839346408844 and batch: 450, loss is 3.900352716445923 and perplexity is 49.41987723521186
At time: 532.9012598991394 and batch: 500, loss is 3.932378640174866 and perplexity is 51.02821117975489
At time: 533.9655809402466 and batch: 550, loss is 3.90104745388031 and perplexity is 49.454223003193896
At time: 535.031580209732 and batch: 600, loss is 3.8776111364364625 and perplexity is 48.30867428889706
At time: 536.1010584831238 and batch: 650, loss is 3.9116537284851076 and perplexity is 49.98153956156499
At time: 537.1672639846802 and batch: 700, loss is 3.9288709115982057 and perplexity is 50.849531628076996
At time: 538.231499671936 and batch: 750, loss is 3.8783112382888794 and perplexity is 48.34250712308756
At time: 539.2895159721375 and batch: 800, loss is 3.8433109951019286 and perplexity is 46.67977536160972
At time: 540.3510222434998 and batch: 850, loss is 3.8507143831253052 and perplexity is 47.02664627711059
At time: 541.4124300479889 and batch: 900, loss is 3.8595090103149414 and perplexity is 47.44205209125429
At time: 542.4735262393951 and batch: 950, loss is 3.9371150064468385 and perplexity is 51.27047274496803
At time: 543.5367863178253 and batch: 1000, loss is 3.8867349815368653 and perplexity is 48.75145199615728
At time: 544.5953183174133 and batch: 1050, loss is 3.858226809501648 and perplexity is 47.38126083510621
At time: 545.6537840366364 and batch: 1100, loss is 3.880022473335266 and perplexity is 48.4253033371939
At time: 546.7139272689819 and batch: 1150, loss is 3.834713559150696 and perplexity is 46.28016923818062
At time: 547.783180475235 and batch: 1200, loss is 3.880749297142029 and perplexity is 48.460512794494974
At time: 548.8483242988586 and batch: 1250, loss is 3.8637185001373293 and perplexity is 47.642179849046784
At time: 549.9076735973358 and batch: 1300, loss is 3.8643407249450683 and perplexity is 47.67183321981836
At time: 550.9703996181488 and batch: 1350, loss is 3.7625632762908934 and perplexity is 43.058655875291336
At time: 552.0275614261627 and batch: 1400, loss is 3.779818477630615 and perplexity is 43.80808886569479
At time: 553.0884819030762 and batch: 1450, loss is 3.6937926483154295 and perplexity is 40.197011349256705
At time: 554.1508073806763 and batch: 1500, loss is 3.711154704093933 and perplexity is 40.90100783116469
At time: 555.2125256061554 and batch: 1550, loss is 3.7161657762527467 and perplexity is 41.106480121045436
At time: 556.2826611995697 and batch: 1600, loss is 3.807253680229187 and perplexity is 45.02661143608751
At time: 557.3423047065735 and batch: 1650, loss is 3.7326691484451295 and perplexity is 41.79050449131102
At time: 558.3996052742004 and batch: 1700, loss is 3.7744953298568724 and perplexity is 43.575511505995216
At time: 559.459254026413 and batch: 1750, loss is 3.7688401174545287 and perplexity is 43.32977822474601
At time: 560.5315766334534 and batch: 1800, loss is 3.7321210956573485 and perplexity is 41.767607363812175
At time: 561.594767332077 and batch: 1850, loss is 3.7403962802886963 and perplexity is 42.114676074623205
At time: 562.6526594161987 and batch: 1900, loss is 3.812823224067688 and perplexity is 45.27808877935902
At time: 563.7097463607788 and batch: 1950, loss is 3.75787633895874 and perplexity is 42.85731485853883
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.565825138535611 and perplexity of 96.14189167596051
finished 13 epochs...
Completing Train Step...
At time: 567.0497426986694 and batch: 50, loss is 3.9259895420074464 and perplexity is 50.70322621514588
At time: 568.1284899711609 and batch: 100, loss is 3.918835997581482 and perplexity is 50.34181266902785
At time: 569.1868591308594 and batch: 150, loss is 3.9034707307815553 and perplexity is 49.574209601126036
At time: 570.2399442195892 and batch: 200, loss is 3.877840657234192 and perplexity is 48.31976340690002
At time: 571.3001472949982 and batch: 250, loss is 3.8759385204315184 and perplexity is 48.227939964687394
At time: 572.3582947254181 and batch: 300, loss is 3.898019061088562 and perplexity is 49.30468273834775
At time: 573.4140911102295 and batch: 350, loss is 3.9045410537719727 and perplexity is 49.62729842341924
At time: 574.4666888713837 and batch: 400, loss is 3.8615959787368777 and perplexity is 47.541165543189244
At time: 575.5246179103851 and batch: 450, loss is 3.8829159355163574 and perplexity is 48.565623027969416
At time: 576.5794076919556 and batch: 500, loss is 3.9152616930007933 and perplexity is 50.16219688938246
At time: 577.6326351165771 and batch: 550, loss is 3.88417950630188 and perplexity is 48.62702791695018
At time: 578.690194606781 and batch: 600, loss is 3.8612827587127687 and perplexity is 47.526277029983596
At time: 579.7467150688171 and batch: 650, loss is 3.895662260055542 and perplexity is 49.18861823533106
At time: 580.7989530563354 and batch: 700, loss is 3.913812756538391 and perplexity is 50.089567683534106
At time: 581.8505930900574 and batch: 750, loss is 3.8637530994415283 and perplexity is 47.64382826383692
At time: 582.9329319000244 and batch: 800, loss is 3.8290167760849 and perplexity is 46.01727070273894
At time: 583.9925246238708 and batch: 850, loss is 3.8369105148315428 and perplexity is 46.38195648899781
At time: 585.0554547309875 and batch: 900, loss is 3.8461578989028933 and perplexity is 46.81285753770698
At time: 586.1056957244873 and batch: 950, loss is 3.92444269657135 and perplexity is 50.6248567894003
At time: 587.1601271629333 and batch: 1000, loss is 3.8743837165832518 and perplexity is 48.15301324130933
At time: 588.2123186588287 and batch: 1050, loss is 3.846672763824463 and perplexity is 46.83696604171053
At time: 589.2657129764557 and batch: 1100, loss is 3.8687282848358153 and perplexity is 47.881455772643186
At time: 590.3207449913025 and batch: 1150, loss is 3.8244157361984255 and perplexity is 45.80602974146969
At time: 591.37566447258 and batch: 1200, loss is 3.8707393169403077 and perplexity is 47.97784380464044
At time: 592.4284515380859 and batch: 1250, loss is 3.8550681018829347 and perplexity is 47.23183340853932
At time: 593.4851820468903 and batch: 1300, loss is 3.856251640319824 and perplexity is 47.287767192185356
At time: 594.5375530719757 and batch: 1350, loss is 3.7551838541030884 and perplexity is 42.742077394509245
At time: 595.5882840156555 and batch: 1400, loss is 3.7734495401382446 and perplexity is 43.52996450452237
At time: 596.6415739059448 and batch: 1450, loss is 3.6886137342453003 and perplexity is 39.98937261727046
At time: 597.6922569274902 and batch: 1500, loss is 3.7063774967193606 and perplexity is 40.706081208089934
At time: 598.7444431781769 and batch: 1550, loss is 3.7118832588195803 and perplexity is 40.93081731130408
At time: 599.790123462677 and batch: 1600, loss is 3.8037139701843263 and perplexity is 44.8675120362932
At time: 600.8356068134308 and batch: 1650, loss is 3.7297182130813598 and perplexity is 41.667365191153856
At time: 601.8812487125397 and batch: 1700, loss is 3.7718282985687255 and perplexity is 43.45944909325133
At time: 602.937394618988 and batch: 1750, loss is 3.767024416923523 and perplexity is 43.25117570432853
At time: 604.0002677440643 and batch: 1800, loss is 3.7309768486022947 and perplexity is 41.71984223485514
At time: 605.0549516677856 and batch: 1850, loss is 3.7397584772109984 and perplexity is 42.0878237687585
At time: 606.1111330986023 and batch: 1900, loss is 3.8125767135620117 and perplexity is 45.266928630401466
At time: 607.1617660522461 and batch: 1950, loss is 3.7580885601043703 and perplexity is 42.86641105216491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.566941088299418 and perplexity of 96.24924108440123
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 610.5268135070801 and batch: 50, loss is 3.918920621871948 and perplexity is 50.346072989466506
At time: 611.6071584224701 and batch: 100, loss is 3.921595597267151 and perplexity is 50.48092778217191
At time: 612.6649451255798 and batch: 150, loss is 3.913165497779846 and perplexity is 50.05715726223524
At time: 613.7146270275116 and batch: 200, loss is 3.8919355201721193 and perplexity is 49.005646206290656
At time: 614.7690827846527 and batch: 250, loss is 3.8948173046112062 and perplexity is 49.147073598708936
At time: 615.8279526233673 and batch: 300, loss is 3.9167044353485108 and perplexity is 50.23462024664909
At time: 616.8732750415802 and batch: 350, loss is 3.92604528427124 and perplexity is 50.706052606530754
At time: 617.9287662506104 and batch: 400, loss is 3.8818419218063354 and perplexity is 48.513490883331876
At time: 618.9799609184265 and batch: 450, loss is 3.904826455116272 and perplexity is 49.641464142464706
At time: 620.0308089256287 and batch: 500, loss is 3.9364152145385742 and perplexity is 51.23460663387904
At time: 621.0831544399261 and batch: 550, loss is 3.906350698471069 and perplexity is 49.7171875100654
At time: 622.1359970569611 and batch: 600, loss is 3.87900354385376 and perplexity is 48.37598649743054
At time: 623.1939318180084 and batch: 650, loss is 3.9112546396255494 and perplexity is 49.96159646574079
At time: 624.2540328502655 and batch: 700, loss is 3.9265947246551516 and perplexity is 50.733920214635106
At time: 625.3088848590851 and batch: 750, loss is 3.871214966773987 and perplexity is 48.00066988624701
At time: 626.3598923683167 and batch: 800, loss is 3.834146709442139 and perplexity is 46.253942771670694
At time: 627.4112832546234 and batch: 850, loss is 3.8428086185455324 and perplexity is 46.6563304263962
At time: 628.4633612632751 and batch: 900, loss is 3.8438613414764404 and perplexity is 46.705472477251625
At time: 629.5191369056702 and batch: 950, loss is 3.9224579620361326 and perplexity is 50.524479531845024
At time: 630.5749909877777 and batch: 1000, loss is 3.8748901653289796 and perplexity is 48.17740645090222
At time: 631.6267757415771 and batch: 1050, loss is 3.84752411365509 and perplexity is 46.87685766327042
At time: 632.6763393878937 and batch: 1100, loss is 3.866133451461792 and perplexity is 47.75737243062876
At time: 633.7275021076202 and batch: 1150, loss is 3.8225064516067504 and perplexity is 45.71865643147806
At time: 634.7791693210602 and batch: 1200, loss is 3.8668499994277954 and perplexity is 47.79160514193072
At time: 635.8788802623749 and batch: 1250, loss is 3.8491339111328124 and perplexity is 46.95238068257379
At time: 636.9327809810638 and batch: 1300, loss is 3.8458385038375855 and perplexity is 46.79790812952717
At time: 637.983095407486 and batch: 1350, loss is 3.7415044689178467 and perplexity is 42.16137294946334
At time: 639.0327427387238 and batch: 1400, loss is 3.7610103368759153 and perplexity is 42.991840285136185
At time: 640.0814309120178 and batch: 1450, loss is 3.6733396863937378 and perplexity is 39.38321405829
At time: 641.1342926025391 and batch: 1500, loss is 3.6875359296798704 and perplexity is 39.9462951076333
At time: 642.1888360977173 and batch: 1550, loss is 3.6942850875854494 and perplexity is 40.2168108107986
At time: 643.2481880187988 and batch: 1600, loss is 3.780910301208496 and perplexity is 43.85594569087121
At time: 644.3076384067535 and batch: 1650, loss is 3.7054188728332518 and perplexity is 40.66707808398404
At time: 645.3597228527069 and batch: 1700, loss is 3.7455927896499634 and perplexity is 42.334094995569906
At time: 646.4100587368011 and batch: 1750, loss is 3.7401207971572874 and perplexity is 42.103075789694664
At time: 647.4654788970947 and batch: 1800, loss is 3.7069560718536376 and perplexity is 40.72963954896874
At time: 648.521087884903 and batch: 1850, loss is 3.7146047067642214 and perplexity is 41.042360110065545
At time: 649.5743443965912 and batch: 1900, loss is 3.788325686454773 and perplexity is 44.182363183487546
At time: 650.6259219646454 and batch: 1950, loss is 3.738680157661438 and perplexity is 42.042464106090954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.554527956940407 and perplexity of 95.0618713462463
finished 15 epochs...
Completing Train Step...
At time: 653.9875569343567 and batch: 50, loss is 3.918067898750305 and perplexity is 50.303160027981995
At time: 655.0471796989441 and batch: 100, loss is 3.912410774230957 and perplexity is 50.0193921997426
At time: 656.0997076034546 and batch: 150, loss is 3.896070747375488 and perplexity is 49.20871526657762
At time: 657.1549482345581 and batch: 200, loss is 3.873832745552063 and perplexity is 48.12648963348967
At time: 658.2075080871582 and batch: 250, loss is 3.8757053136825563 and perplexity is 48.21669419494476
At time: 659.2677659988403 and batch: 300, loss is 3.8970197343826296 and perplexity is 49.25543586311698
At time: 660.3268313407898 and batch: 350, loss is 3.906909170150757 and perplexity is 49.744960905889144
At time: 661.3844752311707 and batch: 400, loss is 3.8630176115036012 and perplexity is 47.60879968595949
At time: 662.4838116168976 and batch: 450, loss is 3.8856369352340696 and perplexity is 48.69795002373412
At time: 663.5441315174103 and batch: 500, loss is 3.9174690437316895 and perplexity is 50.27304474639079
At time: 664.5949153900146 and batch: 550, loss is 3.888599557876587 and perplexity is 48.84243759851671
At time: 665.6453609466553 and batch: 600, loss is 3.8624458646774293 and perplexity is 47.581587285884176
At time: 666.6961646080017 and batch: 650, loss is 3.8949121952056887 and perplexity is 49.15173741501244
At time: 667.7479221820831 and batch: 700, loss is 3.9124535846710207 and perplexity is 50.02153359777115
At time: 668.7981142997742 and batch: 750, loss is 3.8589173650741575 and perplexity is 47.41399152868916
At time: 669.8529627323151 and batch: 800, loss is 3.822553052902222 and perplexity is 45.720787029738915
At time: 670.9010486602783 and batch: 850, loss is 3.831182904243469 and perplexity is 46.117058045657544
At time: 671.9465250968933 and batch: 900, loss is 3.834187431335449 and perplexity is 46.255826358144766
At time: 672.9929296970367 and batch: 950, loss is 3.913908476829529 and perplexity is 50.094362501012746
At time: 674.0416297912598 and batch: 1000, loss is 3.8663365125656126 and perplexity is 47.767071080066
At time: 675.1006782054901 and batch: 1050, loss is 3.83933434009552 and perplexity is 46.494514602422136
At time: 676.1639182567596 and batch: 1100, loss is 3.858746929168701 and perplexity is 47.40591117072279
At time: 677.2155978679657 and batch: 1150, loss is 3.8160349893569947 and perplexity is 45.423745155103546
At time: 678.2671177387238 and batch: 1200, loss is 3.8602378702163698 and perplexity is 47.476643305208135
At time: 679.3163602352142 and batch: 1250, loss is 3.843244876861572 and perplexity is 46.67668907903349
At time: 680.3774573802948 and batch: 1300, loss is 3.8408038234710693 and perplexity is 46.562887742977665
At time: 681.4360184669495 and batch: 1350, loss is 3.7374663829803465 and perplexity is 41.99146498461068
At time: 682.4953827857971 and batch: 1400, loss is 3.7590353298187256 and perplexity is 42.907014890121225
At time: 683.5532302856445 and batch: 1450, loss is 3.6725675106048583 and perplexity is 39.35281503211241
At time: 684.6071314811707 and batch: 1500, loss is 3.6881901168823243 and perplexity is 39.97243601226852
At time: 685.6598134040833 and batch: 1550, loss is 3.6957337999343873 and perplexity is 40.27511562450956
At time: 686.7143995761871 and batch: 1600, loss is 3.78375084400177 and perplexity is 43.98069747885992
At time: 687.7687685489655 and batch: 1650, loss is 3.709310336112976 and perplexity is 40.825640845524205
At time: 688.8248884677887 and batch: 1700, loss is 3.7504792737960817 and perplexity is 42.541466124844696
At time: 689.8794724941254 and batch: 1750, loss is 3.7459622621536255 and perplexity is 42.34973916950628
At time: 690.931960105896 and batch: 1800, loss is 3.7131405735015868 and perplexity is 40.98231259496039
At time: 691.9834282398224 and batch: 1850, loss is 3.7206912088394164 and perplexity is 41.29292628228117
At time: 693.0477404594421 and batch: 1900, loss is 3.794080209732056 and perplexity is 44.437344565388834
At time: 694.1094923019409 and batch: 1950, loss is 3.7440333938598633 and perplexity is 42.268130831543125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.553778785882995 and perplexity of 94.99068041399292
finished 16 epochs...
Completing Train Step...
At time: 697.4643678665161 and batch: 50, loss is 3.914596734046936 and perplexity is 50.128852175077554
At time: 698.5464832782745 and batch: 100, loss is 3.907231674194336 and perplexity is 49.76100644416539
At time: 699.6053745746613 and batch: 150, loss is 3.8897603940963745 and perplexity is 48.8991685904683
At time: 700.664694070816 and batch: 200, loss is 3.866992197036743 and perplexity is 47.79840147710953
At time: 701.7301940917969 and batch: 250, loss is 3.8685704946517943 and perplexity is 47.87390114496434
At time: 702.797694683075 and batch: 300, loss is 3.889224033355713 and perplexity is 48.87294802865395
At time: 703.8530910015106 and batch: 350, loss is 3.899360580444336 and perplexity is 49.37087031059984
At time: 704.9094972610474 and batch: 400, loss is 3.8551722526550294 and perplexity is 47.23675289663606
At time: 705.9647154808044 and batch: 450, loss is 3.8780680322647094 and perplexity is 48.33075136372544
At time: 707.0206198692322 and batch: 500, loss is 3.909995608329773 and perplexity is 49.89873283414732
At time: 708.0768268108368 and batch: 550, loss is 3.8812179803848266 and perplexity is 48.48323074812536
At time: 709.1398603916168 and batch: 600, loss is 3.855452632904053 and perplexity is 47.249999006063234
At time: 710.2050800323486 and batch: 650, loss is 3.888023729324341 and perplexity is 48.81432082438378
At time: 711.2726278305054 and batch: 700, loss is 3.906191935539246 and perplexity is 49.70929489015861
At time: 712.3374621868134 and batch: 750, loss is 3.853139877319336 and perplexity is 47.140847575926685
At time: 713.3975968360901 and batch: 800, loss is 3.816914510726929 and perplexity is 45.46371388376888
At time: 714.4550120830536 and batch: 850, loss is 3.8256872844696046 and perplexity is 45.86431136549353
At time: 715.5505681037903 and batch: 900, loss is 3.8294423151016237 and perplexity is 46.03685701394033
At time: 716.6146521568298 and batch: 950, loss is 3.9094946002960205 and perplexity is 49.87373942959437
At time: 717.6765711307526 and batch: 1000, loss is 3.8620485639572144 and perplexity is 47.562686841815164
At time: 718.7394111156464 and batch: 1050, loss is 3.8352684450149535 and perplexity is 46.305856575997566
At time: 719.8002767562866 and batch: 1100, loss is 3.8550891971588133 and perplexity is 47.232829787604736
At time: 720.8592739105225 and batch: 1150, loss is 3.8127718210220336 and perplexity is 45.27576140751187
At time: 721.9273431301117 and batch: 1200, loss is 3.857061700820923 and perplexity is 47.32608866383262
At time: 722.9923720359802 and batch: 1250, loss is 3.8404858684539795 and perplexity is 46.548085192606884
At time: 724.0584559440613 and batch: 1300, loss is 3.8384354448318483 and perplexity is 46.452739681911275
At time: 725.1196250915527 and batch: 1350, loss is 3.735588746070862 and perplexity is 41.91269423464833
At time: 726.1773505210876 and batch: 1400, loss is 3.7578240871429442 and perplexity is 42.85507554452195
At time: 727.2391686439514 and batch: 1450, loss is 3.671946339607239 and perplexity is 39.32837779537691
At time: 728.2939281463623 and batch: 1500, loss is 3.6882102632522584 and perplexity is 39.973241319863575
At time: 729.3572907447815 and batch: 1550, loss is 3.696151990890503 and perplexity is 40.29196183584134
At time: 730.4194369316101 and batch: 1600, loss is 3.7845672845840452 and perplexity is 44.01661976733007
At time: 731.4862344264984 and batch: 1650, loss is 3.710506572723389 and perplexity is 40.87450719377734
At time: 732.5498342514038 and batch: 1700, loss is 3.7519857597351076 and perplexity is 42.60560254356401
At time: 733.6065447330475 and batch: 1750, loss is 3.747800712585449 and perplexity is 42.42766867859039
At time: 734.6655747890472 and batch: 1800, loss is 3.715086145401001 and perplexity is 41.06212424519454
At time: 735.7301707267761 and batch: 1850, loss is 3.7226478910446166 and perplexity is 41.37380251507752
At time: 736.7918410301208 and batch: 1900, loss is 3.7958607053756714 and perplexity is 44.51653554247551
At time: 737.8533108234406 and batch: 1950, loss is 3.745663743019104 and perplexity is 42.33709884880485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.553822220203489 and perplexity of 94.99480635925313
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 741.1884105205536 and batch: 50, loss is 3.912779355049133 and perplexity is 50.037831786274445
At time: 742.2636530399323 and batch: 100, loss is 3.9077600908279417 and perplexity is 49.78730793613638
At time: 743.313276052475 and batch: 150, loss is 3.8914148807525635 and perplexity is 48.98013857581001
At time: 744.3619663715363 and batch: 200, loss is 3.8691576814651487 and perplexity is 47.902020323217904
At time: 745.4051742553711 and batch: 250, loss is 3.8723574352264403 and perplexity is 48.0555404752789
At time: 746.4473304748535 and batch: 300, loss is 3.892886838912964 and perplexity is 49.0522883782024
At time: 747.4928817749023 and batch: 350, loss is 3.9047504568099978 and perplexity is 49.63769161862343
At time: 748.5455605983734 and batch: 400, loss is 3.8612680673599242 and perplexity is 47.52557880980728
At time: 749.5987510681152 and batch: 450, loss is 3.885300221443176 and perplexity is 48.68155551265678
At time: 750.6512944698334 and batch: 500, loss is 3.916958198547363 and perplexity is 50.24736956216114
At time: 751.7002799510956 and batch: 550, loss is 3.88832932472229 and perplexity is 48.82924053576318
At time: 752.7480983734131 and batch: 600, loss is 3.861050696372986 and perplexity is 47.5152492505505
At time: 753.7974150180817 and batch: 650, loss is 3.8931660747528074 and perplexity is 49.06598744769051
At time: 754.8486909866333 and batch: 700, loss is 3.9103985023498535 and perplexity is 49.91884078563049
At time: 755.9023776054382 and batch: 750, loss is 3.8555499076843263 and perplexity is 47.254595462890514
At time: 756.955578327179 and batch: 800, loss is 3.8190769004821776 and perplexity is 45.562130522122864
At time: 758.0059552192688 and batch: 850, loss is 3.828195667266846 and perplexity is 45.9795010246121
At time: 759.0547659397125 and batch: 900, loss is 3.8282547187805176 and perplexity is 45.98221626391418
At time: 760.104391336441 and batch: 950, loss is 3.90751944065094 and perplexity is 49.775328053207396
At time: 761.1582100391388 and batch: 1000, loss is 3.8608998012542726 and perplexity is 47.508079972292286
At time: 762.2212104797363 and batch: 1050, loss is 3.833469634056091 and perplexity is 46.22263596524236
At time: 763.2772452831268 and batch: 1100, loss is 3.852624173164368 and perplexity is 47.1165431124581
At time: 764.3318912982941 and batch: 1150, loss is 3.811195902824402 and perplexity is 45.204466703264195
At time: 765.3845129013062 and batch: 1200, loss is 3.8561773347854613 and perplexity is 47.28425357991735
At time: 766.4357259273529 and batch: 1250, loss is 3.8384300231933595 and perplexity is 46.45248783263262
At time: 767.4831261634827 and batch: 1300, loss is 3.8351700067520142 and perplexity is 46.30129853225895
At time: 768.5398359298706 and batch: 1350, loss is 3.729484448432922 and perplexity is 41.65762597256548
At time: 769.5939848423004 and batch: 1400, loss is 3.750317668914795 and perplexity is 42.5345917717413
At time: 770.6481277942657 and batch: 1450, loss is 3.6639294719696043 and perplexity is 39.01434784635091
At time: 771.6978433132172 and batch: 1500, loss is 3.6785851955413817 and perplexity is 39.59034183829591
At time: 772.7468712329865 and batch: 1550, loss is 3.687675142288208 and perplexity is 39.95185652266922
At time: 773.795229434967 and batch: 1600, loss is 3.773692102432251 and perplexity is 43.5405245132488
At time: 774.8477580547333 and batch: 1650, loss is 3.6985658025741577 and perplexity is 40.38933651887251
At time: 775.908698797226 and batch: 1700, loss is 3.738865556716919 and perplexity is 42.050259461829775
At time: 776.9616215229034 and batch: 1750, loss is 3.7339029836654665 and perplexity is 41.84209891058849
At time: 778.0113778114319 and batch: 1800, loss is 3.702646589279175 and perplexity is 40.554493542462126
At time: 779.0607659816742 and batch: 1850, loss is 3.71106605052948 and perplexity is 40.89738197175579
At time: 780.1106972694397 and batch: 1900, loss is 3.78432487487793 and perplexity is 44.00595100462614
At time: 781.1678040027618 and batch: 1950, loss is 3.737032790184021 and perplexity is 41.973261734570436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.552137082122093 and perplexity of 94.83486179570926
finished 18 epochs...
Completing Train Step...
At time: 784.5613143444061 and batch: 50, loss is 3.91265832901001 and perplexity is 50.031776272131864
At time: 785.6131753921509 and batch: 100, loss is 3.905543360710144 and perplexity is 49.6770651455508
At time: 786.6671776771545 and batch: 150, loss is 3.887522783279419 and perplexity is 48.78987360731084
At time: 787.7214827537537 and batch: 200, loss is 3.864809274673462 and perplexity is 47.69417507805259
At time: 788.7768239974976 and batch: 250, loss is 3.8676271486282348 and perplexity is 47.82876078552379
At time: 789.8305811882019 and batch: 300, loss is 3.887947430610657 and perplexity is 48.810596496578036
At time: 790.8823585510254 and batch: 350, loss is 3.899639015197754 and perplexity is 49.38461879063931
At time: 791.9333808422089 and batch: 400, loss is 3.856011137962341 and perplexity is 47.27639574018085
At time: 792.9896275997162 and batch: 450, loss is 3.879842095375061 and perplexity is 48.41656926749616
At time: 794.0459027290344 and batch: 500, loss is 3.911726264953613 and perplexity is 49.98516517742835
At time: 795.1294627189636 and batch: 550, loss is 3.8834553384780883 and perplexity is 48.591826535358415
At time: 796.1892430782318 and batch: 600, loss is 3.856457896232605 and perplexity is 47.29752157968641
At time: 797.2425184249878 and batch: 650, loss is 3.888667631149292 and perplexity is 48.845762576260704
At time: 798.2937722206116 and batch: 700, loss is 3.906541037559509 and perplexity is 49.726651534874215
At time: 799.3456554412842 and batch: 750, loss is 3.8522196769714356 and perplexity is 47.09748850416305
At time: 800.4029505252838 and batch: 800, loss is 3.8158619594573975 and perplexity is 45.415886168979426
At time: 801.469190120697 and batch: 850, loss is 3.8247688102722166 and perplexity is 45.82220551845041
At time: 802.5283803939819 and batch: 900, loss is 3.825489192008972 and perplexity is 45.85522689101257
At time: 803.5849812030792 and batch: 950, loss is 3.9053868865966797 and perplexity is 49.66929257894122
At time: 804.6419186592102 and batch: 1000, loss is 3.8586073541641235 and perplexity is 47.39929495219423
At time: 805.701642036438 and batch: 1050, loss is 3.8313253021240232 and perplexity is 46.12362548456423
At time: 806.7553474903107 and batch: 1100, loss is 3.850998668670654 and perplexity is 47.04001717337963
At time: 807.8079209327698 and batch: 1150, loss is 3.809714117050171 and perplexity is 45.137532970545216
At time: 808.8643357753754 and batch: 1200, loss is 3.854713411331177 and perplexity is 47.21508369414544
At time: 809.9176983833313 and batch: 1250, loss is 3.8371194124221804 and perplexity is 46.391646580040515
At time: 810.9773933887482 and batch: 1300, loss is 3.833926649093628 and perplexity is 46.24376523278181
At time: 812.0362973213196 and batch: 1350, loss is 3.7287312364578247 and perplexity is 41.626260763637156
At time: 813.096727848053 and batch: 1400, loss is 3.750303740501404 and perplexity is 42.53399933648953
At time: 814.1617324352264 and batch: 1450, loss is 3.66423614025116 and perplexity is 39.026314144109165
At time: 815.2177357673645 and batch: 1500, loss is 3.6793486166000364 and perplexity is 39.62057747876846
At time: 816.2703046798706 and batch: 1550, loss is 3.688699131011963 and perplexity is 39.992787726210395
At time: 817.3269200325012 and batch: 1600, loss is 3.7750894165039064 and perplexity is 43.60140682678913
At time: 818.3763680458069 and batch: 1650, loss is 3.70031156539917 and perplexity is 40.459908303970124
At time: 819.4323663711548 and batch: 1700, loss is 3.7408802127838134 and perplexity is 42.135061667124525
At time: 820.4890403747559 and batch: 1750, loss is 3.7365220165252686 and perplexity is 41.95182837236889
At time: 821.5375237464905 and batch: 1800, loss is 3.7056297731399535 and perplexity is 40.675655687702445
At time: 822.5842311382294 and batch: 1850, loss is 3.7138020277023314 and perplexity is 41.00942948508431
At time: 823.6314713954926 and batch: 1900, loss is 3.786828474998474 and perplexity is 44.11626233898158
At time: 824.6863148212433 and batch: 1950, loss is 3.739313831329346 and perplexity is 42.06911375122638
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.551736521166425 and perplexity of 94.79688225990508
finished 19 epochs...
Completing Train Step...
At time: 828.0393505096436 and batch: 50, loss is 3.9121367263793947 and perplexity is 50.00568637088605
At time: 829.1262948513031 and batch: 100, loss is 3.90393150806427 and perplexity is 49.59705753421878
At time: 830.1916432380676 and batch: 150, loss is 3.8851463174819947 and perplexity is 48.67406380494343
At time: 831.2610774040222 and batch: 200, loss is 3.8621491050720214 and perplexity is 47.56746908777559
At time: 832.3294787406921 and batch: 250, loss is 3.8648218393325804 and perplexity is 47.69477434286915
At time: 833.3943769931793 and batch: 300, loss is 3.8848369836807253 and perplexity is 48.65900960027064
At time: 834.4584975242615 and batch: 350, loss is 3.8965036201477052 and perplexity is 49.23002099057353
At time: 835.521609544754 and batch: 400, loss is 3.8527322959899903 and perplexity is 47.12163776165196
At time: 836.581892490387 and batch: 450, loss is 3.8765105390548706 and perplexity is 48.25553513623669
At time: 837.6428389549255 and batch: 500, loss is 3.9084848499298097 and perplexity is 49.823404819913065
At time: 838.702684879303 and batch: 550, loss is 3.8803897523880004 and perplexity is 48.443092203270936
At time: 839.7653329372406 and batch: 600, loss is 3.853591537475586 and perplexity is 47.16214402752588
At time: 840.8336181640625 and batch: 650, loss is 3.885905361175537 and perplexity is 48.71102357137795
At time: 841.9016506671906 and batch: 700, loss is 3.9041039657592775 and perplexity is 49.605611666032026
At time: 842.9664862155914 and batch: 750, loss is 3.8501283597946165 and perplexity is 46.99909563867507
At time: 844.0353572368622 and batch: 800, loss is 3.813828053474426 and perplexity is 45.32360840034227
At time: 845.0925998687744 and batch: 850, loss is 3.8227294158935545 and perplexity is 45.72885119559487
At time: 846.1501836776733 and batch: 900, loss is 3.823797039985657 and perplexity is 45.77769848946957
At time: 847.2066185474396 and batch: 950, loss is 3.9039727306365966 and perplexity is 49.59910209465091
At time: 848.3073182106018 and batch: 1000, loss is 3.8571816539764403 and perplexity is 47.331765918001615
At time: 849.3686299324036 and batch: 1050, loss is 3.8300521755218506 and perplexity is 46.06494163388338
At time: 850.4358510971069 and batch: 1100, loss is 3.8499123573303224 and perplexity is 46.988944814538506
At time: 851.5066578388214 and batch: 1150, loss is 3.808827114105225 and perplexity is 45.09751359714762
At time: 852.5760653018951 and batch: 1200, loss is 3.8537960052490234 and perplexity is 47.17178815202846
At time: 853.6339228153229 and batch: 1250, loss is 3.8363236141204835 and perplexity is 46.35474287238072
At time: 854.6919219493866 and batch: 1300, loss is 3.83324613571167 and perplexity is 46.21230643698857
At time: 855.7595767974854 and batch: 1350, loss is 3.7283518218994143 and perplexity is 41.61047015007501
At time: 856.8188543319702 and batch: 1400, loss is 3.7503397989273073 and perplexity is 42.53553307320488
At time: 857.880313873291 and batch: 1450, loss is 3.6644891929626464 and perplexity is 39.03619110836624
At time: 858.9444596767426 and batch: 1500, loss is 3.679915261268616 and perplexity is 39.643034629774405
At time: 860.0085916519165 and batch: 1550, loss is 3.689426884651184 and perplexity is 40.02190321618761
At time: 861.0748825073242 and batch: 1600, loss is 3.776085252761841 and perplexity is 43.64484831531885
At time: 862.1359214782715 and batch: 1650, loss is 3.7014795446395876 and perplexity is 40.50719224489377
At time: 863.197557926178 and batch: 1700, loss is 3.7422247982025145 and perplexity is 42.19175396193347
At time: 864.2642109394073 and batch: 1750, loss is 3.738159942626953 and perplexity is 42.02059867203304
At time: 865.3271820545197 and batch: 1800, loss is 3.7074315690994264 and perplexity is 40.74901098556363
At time: 866.3871004581451 and batch: 1850, loss is 3.715465030670166 and perplexity is 41.07768502688099
At time: 867.4478363990784 and batch: 1900, loss is 3.7882827138900756 and perplexity is 44.18046459482107
At time: 868.5082671642303 and batch: 1950, loss is 3.740612745285034 and perplexity is 42.123793414582344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.551591172329215 and perplexity of 94.78310464460193
Finished Training.
Improved accuracyfrom -10000000 to -94.78310464460193
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc0f4432b38>
ELAPSED
900.5224068164825


RESULTS SO FAR:
[{'best_accuracy': -94.78310464460193, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.24245156315881022, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.32612507610596975, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5529077053070068 and batch: 50, loss is 7.225689144134521 and perplexity is 1374.2853700685278
At time: 2.600403070449829 and batch: 100, loss is 6.401430349349976 and perplexity is 602.7065024815884
At time: 3.6510367393493652 and batch: 150, loss is 6.150799827575684 and perplexity is 469.09242983846326
At time: 4.707136392593384 and batch: 200, loss is 6.018844652175903 and perplexity is 411.10335387932906
At time: 5.797739744186401 and batch: 250, loss is 5.944860591888427 and perplexity is 381.7861335036636
At time: 6.843881130218506 and batch: 300, loss is 5.872026538848877 and perplexity is 354.96760750551874
At time: 7.891563177108765 and batch: 350, loss is 5.825235738754272 and perplexity is 338.7409780424659
At time: 8.94221305847168 and batch: 400, loss is 5.764623851776123 and perplexity is 318.81909824142105
At time: 9.990212678909302 and batch: 450, loss is 5.702317428588867 and perplexity is 299.56080797662855
At time: 11.044725179672241 and batch: 500, loss is 5.66747015953064 and perplexity is 289.3017206309125
At time: 12.092466592788696 and batch: 550, loss is 5.616121501922607 and perplexity is 274.8214191793601
At time: 13.142600297927856 and batch: 600, loss is 5.652556037902832 and perplexity is 285.0190550627227
At time: 14.183960676193237 and batch: 650, loss is 5.730282392501831 and perplexity is 308.0562488703365
At time: 15.225388288497925 and batch: 700, loss is 5.643756866455078 and perplexity is 282.5221250992364
At time: 16.266287088394165 and batch: 750, loss is 5.586173839569092 and perplexity is 266.7131775407834
At time: 17.316694021224976 and batch: 800, loss is 5.579505701065063 and perplexity is 264.940613551133
At time: 18.370338439941406 and batch: 850, loss is 5.5965076923370365 and perplexity is 269.4836423822043
At time: 19.424898862838745 and batch: 900, loss is 5.6134429550170895 and perplexity is 274.08628210654
At time: 20.4759464263916 and batch: 950, loss is 5.642958345413208 and perplexity is 282.2966152866989
At time: 21.533784866333008 and batch: 1000, loss is 5.608117218017578 and perplexity is 272.63045078127834
At time: 22.58111000061035 and batch: 1050, loss is 5.51394739151001 and perplexity is 248.1286574064654
At time: 23.631287813186646 and batch: 1100, loss is 5.6002600955963135 and perplexity is 270.49675329177944
At time: 24.68142294883728 and batch: 1150, loss is 5.510527667999267 and perplexity is 247.2815752219917
At time: 25.734524965286255 and batch: 1200, loss is 5.582681922912598 and perplexity is 265.7834615437163
At time: 26.78330087661743 and batch: 1250, loss is 5.520533151626587 and perplexity is 249.76816600159245
At time: 27.83045244216919 and batch: 1300, loss is 5.537481269836426 and perplexity is 254.03734146032656
At time: 28.88075542449951 and batch: 1350, loss is 5.498985033035279 and perplexity is 244.44370402947692
At time: 29.932045936584473 and batch: 1400, loss is 5.518079223632813 and perplexity is 249.15600431462866
At time: 30.983259677886963 and batch: 1450, loss is 5.466514778137207 and perplexity is 236.6340318191667
At time: 32.030898332595825 and batch: 1500, loss is 5.460001802444458 and perplexity is 235.09784811567002
At time: 33.07922673225403 and batch: 1550, loss is 5.438306159973145 and perplexity is 230.05218165999676
At time: 34.126763105392456 and batch: 1600, loss is 5.47079966545105 and perplexity is 237.65015741728084
At time: 35.179261922836304 and batch: 1650, loss is 5.453075609207153 and perplexity is 233.47514106829263
At time: 36.24184846878052 and batch: 1700, loss is 5.467759590148926 and perplexity is 236.9287801194082
At time: 37.30690574645996 and batch: 1750, loss is 5.47188178062439 and perplexity is 237.90746144975947
At time: 38.36881613731384 and batch: 1800, loss is 5.461755676269531 and perplexity is 235.51054187841564
At time: 39.428913593292236 and batch: 1850, loss is 5.43947283744812 and perplexity is 230.32073498550477
At time: 40.48952507972717 and batch: 1900, loss is 5.453172864913941 and perplexity is 233.49784896237279
At time: 41.5524845123291 and batch: 1950, loss is 5.3878862667083744 and perplexity is 218.74053740137535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.9864076126453485 and perplexity of 146.40951793707782
finished 1 epochs...
Completing Train Step...
At time: 44.92170739173889 and batch: 50, loss is 5.203284530639649 and perplexity is 181.86861497442018
At time: 46.001035928726196 and batch: 100, loss is 5.130967798233033 and perplexity is 169.18077169216502
At time: 47.0525016784668 and batch: 150, loss is 5.072069330215454 and perplexity is 159.5040526259778
At time: 48.10546827316284 and batch: 200, loss is 5.048561334609985 and perplexity is 155.79816175365056
At time: 49.16665983200073 and batch: 250, loss is 5.056187496185303 and perplexity is 156.99084572829977
At time: 50.218530893325806 and batch: 300, loss is 5.076282978057861 and perplexity is 160.17756450761692
At time: 51.27017951011658 and batch: 350, loss is 5.060517120361328 and perplexity is 157.67203066265574
At time: 52.323983669281006 and batch: 400, loss is 5.031934041976928 and perplexity is 153.2290777706813
At time: 53.38045597076416 and batch: 450, loss is 5.002962217330933 and perplexity is 148.85344292083963
At time: 54.449323415756226 and batch: 500, loss is 4.993450527191162 and perplexity is 147.44430734995214
At time: 55.51193022727966 and batch: 550, loss is 4.9495891571044925 and perplexity is 141.1169751034888
At time: 56.56454658508301 and batch: 600, loss is 4.952380123138428 and perplexity is 141.51137791422218
At time: 57.618313789367676 and batch: 650, loss is 5.019298763275146 and perplexity is 151.30516584553737
At time: 58.67353081703186 and batch: 700, loss is 5.002721109390259 and perplexity is 148.8175575000585
At time: 59.733439207077026 and batch: 750, loss is 4.953784065246582 and perplexity is 141.7101912249922
At time: 60.80138874053955 and batch: 800, loss is 4.933325252532959 and perplexity is 138.8404250647773
At time: 61.90581798553467 and batch: 850, loss is 4.94091121673584 and perplexity is 139.89766859493656
At time: 62.9707453250885 and batch: 900, loss is 4.956265916824341 and perplexity is 142.06233168609467
At time: 64.0307023525238 and batch: 950, loss is 5.014681196212768 and perplexity is 150.60811467416522
At time: 65.09379577636719 and batch: 1000, loss is 4.9856638336181645 and perplexity is 146.30066209562034
At time: 66.15830683708191 and batch: 1050, loss is 4.898879232406617 and perplexity is 134.1393563622805
At time: 67.21688556671143 and batch: 1100, loss is 4.976106767654419 and perplexity is 144.90911715251062
At time: 68.28438591957092 and batch: 1150, loss is 4.899299793243408 and perplexity is 134.19578198661108
At time: 69.34833931922913 and batch: 1200, loss is 4.980527801513672 and perplexity is 145.55118351873463
At time: 70.41399145126343 and batch: 1250, loss is 4.928309106826783 and perplexity is 138.14572507757697
At time: 71.47325730323792 and batch: 1300, loss is 4.951153764724731 and perplexity is 141.33794061516554
At time: 72.53301978111267 and batch: 1350, loss is 4.869632186889649 and perplexity is 130.27299196891997
At time: 73.59071707725525 and batch: 1400, loss is 4.888450479507446 and perplexity is 132.74771929300357
At time: 74.64566850662231 and batch: 1450, loss is 4.818584766387939 and perplexity is 123.78977530206997
At time: 75.70373058319092 and batch: 1500, loss is 4.8133924770355225 and perplexity is 123.14868876353508
At time: 76.76970028877258 and batch: 1550, loss is 4.809671049118042 and perplexity is 122.69125148302402
At time: 77.83063793182373 and batch: 1600, loss is 4.8832443332672115 and perplexity is 132.05841112977208
At time: 78.89229393005371 and batch: 1650, loss is 4.840774049758911 and perplexity is 126.56728319835618
At time: 79.95320534706116 and batch: 1700, loss is 4.864388656616211 and perplexity is 129.59168936813762
At time: 81.00488519668579 and batch: 1750, loss is 4.8770230197906494 and perplexity is 131.23938470865485
At time: 82.05847191810608 and batch: 1800, loss is 4.835929613113404 and perplexity is 125.95561879447428
At time: 83.1150598526001 and batch: 1850, loss is 4.850989122390747 and perplexity is 127.86680323467836
At time: 84.1647675037384 and batch: 1900, loss is 4.908277111053467 and perplexity is 135.4059239574819
At time: 85.22612380981445 and batch: 1950, loss is 4.831508550643921 and perplexity is 125.399990274616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.735154262808866 and perplexity of 113.88102497005399
finished 2 epochs...
Completing Train Step...
At time: 88.58977723121643 and batch: 50, loss is 4.761965885162353 and perplexity is 116.97566072463434
At time: 89.64366006851196 and batch: 100, loss is 4.7115185546875 and perplexity is 111.22092679212275
At time: 90.69522261619568 and batch: 150, loss is 4.664538984298706 and perplexity is 106.11665250049387
At time: 91.74714183807373 and batch: 200, loss is 4.659750318527221 and perplexity is 105.60971007653497
At time: 92.79868125915527 and batch: 250, loss is 4.666348600387574 and perplexity is 106.3088567576625
At time: 93.85488605499268 and batch: 300, loss is 4.695476207733154 and perplexity is 109.45091760684721
At time: 94.91177701950073 and batch: 350, loss is 4.702143449783325 and perplexity is 110.18309144502523
At time: 95.96929240226746 and batch: 400, loss is 4.672429637908936 and perplexity is 106.95729449334479
At time: 97.02292895317078 and batch: 450, loss is 4.667969703674316 and perplexity is 106.48133415883098
At time: 98.07691311836243 and batch: 500, loss is 4.671938571929932 and perplexity is 106.90478429885307
At time: 99.12854242324829 and batch: 550, loss is 4.632980651855469 and perplexity is 102.82007868078442
At time: 100.1847562789917 and batch: 600, loss is 4.62325891494751 and perplexity is 101.82533209392366
At time: 101.23770046234131 and batch: 650, loss is 4.687380466461182 and perplexity is 108.56840839907169
At time: 102.29103684425354 and batch: 700, loss is 4.690102500915527 and perplexity is 108.8643379298534
At time: 103.33820915222168 and batch: 750, loss is 4.647976884841919 and perplexity is 104.37361199612918
At time: 104.38574528694153 and batch: 800, loss is 4.631911859512329 and perplexity is 102.71024407361845
At time: 105.43365025520325 and batch: 850, loss is 4.63082441329956 and perplexity is 102.59861291512897
At time: 106.48838877677917 and batch: 900, loss is 4.631144027709961 and perplexity is 102.63141015125925
At time: 107.54403042793274 and batch: 950, loss is 4.711700372695923 and perplexity is 111.24115059799732
At time: 108.60184979438782 and batch: 1000, loss is 4.681400556564331 and perplexity is 107.92111640200287
At time: 109.65786337852478 and batch: 1050, loss is 4.6128870677948 and perplexity is 100.77467336774983
At time: 110.71627879142761 and batch: 1100, loss is 4.6841348361968995 and perplexity is 108.21660670496601
At time: 111.76764178276062 and batch: 1150, loss is 4.615626630783081 and perplexity is 101.05113044594829
At time: 112.8198013305664 and batch: 1200, loss is 4.689712076187134 and perplexity is 108.82184289638118
At time: 113.87544441223145 and batch: 1250, loss is 4.651376142501831 and perplexity is 104.72900849612142
At time: 114.93087124824524 and batch: 1300, loss is 4.664194278717041 and perplexity is 106.08007980183814
At time: 115.98710298538208 and batch: 1350, loss is 4.570833053588867 and perplexity is 96.62456969903691
At time: 117.04105591773987 and batch: 1400, loss is 4.595000085830688 and perplexity is 98.98814404388806
At time: 118.09366011619568 and batch: 1450, loss is 4.518187398910523 and perplexity is 91.66928744606933
At time: 119.15613222122192 and batch: 1500, loss is 4.523676090240478 and perplexity is 92.17381520125053
At time: 120.21752071380615 and batch: 1550, loss is 4.530617332458496 and perplexity is 92.81584163142313
At time: 121.27679204940796 and batch: 1600, loss is 4.621044301986695 and perplexity is 101.60007791120888
At time: 122.33011150360107 and batch: 1650, loss is 4.56441291809082 and perplexity is 96.00621395690851
At time: 123.38233733177185 and batch: 1700, loss is 4.596636228561401 and perplexity is 99.15023534228266
At time: 124.43633389472961 and batch: 1750, loss is 4.606736764907837 and perplexity is 100.15678066455278
At time: 125.49411106109619 and batch: 1800, loss is 4.564716205596924 and perplexity is 96.03533585804114
At time: 126.55372452735901 and batch: 1850, loss is 4.592660779953003 and perplexity is 98.75685113461246
At time: 127.60797381401062 and batch: 1900, loss is 4.662007236480713 and perplexity is 105.84833170069511
At time: 128.66052794456482 and batch: 1950, loss is 4.591553020477295 and perplexity is 98.64751286840824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6549932435501455 and perplexity of 105.10850983612457
finished 3 epochs...
Completing Train Step...
At time: 132.0287618637085 and batch: 50, loss is 4.533888874053955 and perplexity is 93.11998976339598
At time: 133.11853098869324 and batch: 100, loss is 4.484386653900146 and perplexity is 88.62257782746642
At time: 134.18567442893982 and batch: 150, loss is 4.441447591781616 and perplexity is 84.89775004943398
At time: 135.2435278892517 and batch: 200, loss is 4.44388916015625 and perplexity is 85.10528696571954
At time: 136.3157982826233 and batch: 250, loss is 4.447861433029175 and perplexity is 85.44402071451155
At time: 137.37882447242737 and batch: 300, loss is 4.478053436279297 and perplexity is 88.06308531995401
At time: 138.44435715675354 and batch: 350, loss is 4.488152446746827 and perplexity is 88.9569412737011
At time: 139.50404500961304 and batch: 400, loss is 4.4564861297607425 and perplexity is 86.1841365301164
At time: 140.560697555542 and batch: 450, loss is 4.463990077972412 and perplexity is 86.83329038966718
At time: 141.64454078674316 and batch: 500, loss is 4.4770965671539305 and perplexity is 87.97886077488653
At time: 142.70428943634033 and batch: 550, loss is 4.435236501693725 and perplexity is 84.3720766679179
At time: 143.7649257183075 and batch: 600, loss is 4.430071144104004 and perplexity is 83.9373883481365
At time: 144.82480382919312 and batch: 650, loss is 4.484052190780639 and perplexity is 88.59294179998288
At time: 145.88207030296326 and batch: 700, loss is 4.49534893989563 and perplexity is 89.59942834618474
At time: 146.94523549079895 and batch: 750, loss is 4.454478673934936 and perplexity is 86.01129922281945
At time: 148.00824809074402 and batch: 800, loss is 4.43742169380188 and perplexity is 84.55664745186667
At time: 149.0706751346588 and batch: 850, loss is 4.431842613220215 and perplexity is 84.0862126191717
At time: 150.13125896453857 and batch: 900, loss is 4.427901411056519 and perplexity is 83.75546405766157
At time: 151.18792915344238 and batch: 950, loss is 4.523480749130249 and perplexity is 92.15581162433163
At time: 152.24457907676697 and batch: 1000, loss is 4.486785068511963 and perplexity is 88.8353866129016
At time: 153.30399560928345 and batch: 1050, loss is 4.426643371582031 and perplexity is 83.65016262823852
At time: 154.3651249408722 and batch: 1100, loss is 4.489476327896118 and perplexity is 89.07478768145879
At time: 155.4263825416565 and batch: 1150, loss is 4.434509038925171 and perplexity is 84.31072144296304
At time: 156.48414635658264 and batch: 1200, loss is 4.500006475448608 and perplexity is 90.01771420371671
At time: 157.54050540924072 and batch: 1250, loss is 4.469681558609008 and perplexity is 87.32890944578276
At time: 158.59728121757507 and batch: 1300, loss is 4.486945648193359 and perplexity is 88.8496529163892
At time: 159.65757536888123 and batch: 1350, loss is 4.381555080413818 and perplexity is 79.96228455233383
At time: 160.71983790397644 and batch: 1400, loss is 4.409098310470581 and perplexity is 82.19531542466629
At time: 161.7816812992096 and batch: 1450, loss is 4.324237532615662 and perplexity is 75.50791858046026
At time: 162.84039282798767 and batch: 1500, loss is 4.34042031288147 and perplexity is 76.73978728182364
At time: 163.89872097969055 and batch: 1550, loss is 4.351844148635864 and perplexity is 77.62147655563797
At time: 164.9556529521942 and batch: 1600, loss is 4.4514432144165035 and perplexity is 85.75061125994509
At time: 166.01488709449768 and batch: 1650, loss is 4.385788478851318 and perplexity is 80.30151430353602
At time: 167.07155871391296 and batch: 1700, loss is 4.420655202865601 and perplexity is 83.15074812276262
At time: 168.1328604221344 and batch: 1750, loss is 4.425520896911621 and perplexity is 83.55632011728648
At time: 169.19632005691528 and batch: 1800, loss is 4.3799403858184816 and perplexity is 79.83327406793244
At time: 170.24822664260864 and batch: 1850, loss is 4.417661390304565 and perplexity is 82.90218263347114
At time: 171.2984800338745 and batch: 1900, loss is 4.4893476676940915 and perplexity is 89.06332803849602
At time: 172.35390377044678 and batch: 1950, loss is 4.418196229934693 and perplexity is 82.9465338655086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.622236668786337 and perplexity of 101.72129472404137
finished 4 epochs...
Completing Train Step...
At time: 175.70420575141907 and batch: 50, loss is 4.370216116905213 and perplexity is 79.06071621068347
At time: 176.78022956848145 and batch: 100, loss is 4.3229242610931395 and perplexity is 75.4088212663465
At time: 177.8290319442749 and batch: 150, loss is 4.284800481796265 and perplexity is 72.5880626350136
At time: 178.88375902175903 and batch: 200, loss is 4.285830450057984 and perplexity is 72.66286455089426
At time: 179.93790125846863 and batch: 250, loss is 4.285314292907715 and perplexity is 72.62536877148706
At time: 180.9933624267578 and batch: 300, loss is 4.317310495376587 and perplexity is 74.9866798210086
At time: 182.03973150253296 and batch: 350, loss is 4.3312942409515385 and perplexity is 76.04264040795444
At time: 183.10166573524475 and batch: 400, loss is 4.297487707138061 and perplexity is 73.51487062168587
At time: 184.1594295501709 and batch: 450, loss is 4.3092678356170655 and perplexity is 74.38600621328507
At time: 185.21172857284546 and batch: 500, loss is 4.330524559020996 and perplexity is 75.98413428012472
At time: 186.26959085464478 and batch: 550, loss is 4.290613145828247 and perplexity is 73.01122130399084
At time: 187.31733298301697 and batch: 600, loss is 4.28139407157898 and perplexity is 72.34121858154423
At time: 188.36764478683472 and batch: 650, loss is 4.333135948181153 and perplexity is 76.1828177317259
At time: 189.41997694969177 and batch: 700, loss is 4.352168340682983 and perplexity is 77.6466449004911
At time: 190.47280168533325 and batch: 750, loss is 4.310430526733398 and perplexity is 74.47254446076563
At time: 191.52559900283813 and batch: 800, loss is 4.293547039031982 and perplexity is 73.2257429679183
At time: 192.57770323753357 and batch: 850, loss is 4.29094970703125 and perplexity is 73.0357981840458
At time: 193.6297664642334 and batch: 900, loss is 4.276074337959289 and perplexity is 71.95740436879977
At time: 194.7204291820526 and batch: 950, loss is 4.378446054458618 and perplexity is 79.71406579344657
At time: 195.7692470550537 and batch: 1000, loss is 4.342354526519776 and perplexity is 76.88836206635163
At time: 196.8188452720642 and batch: 1050, loss is 4.289566383361817 and perplexity is 72.93483588357184
At time: 197.87841248512268 and batch: 1100, loss is 4.343678121566772 and perplexity is 76.99019850178782
At time: 198.937974691391 and batch: 1150, loss is 4.298062109947205 and perplexity is 73.55710989990347
At time: 199.983473777771 and batch: 1200, loss is 4.358498587608337 and perplexity is 78.13972635274673
At time: 201.0290105342865 and batch: 1250, loss is 4.335682525634765 and perplexity is 76.37707041248447
At time: 202.07465314865112 and batch: 1300, loss is 4.345534639358521 and perplexity is 77.13326493669577
At time: 203.1244602203369 and batch: 1350, loss is 4.243078646659851 and perplexity is 69.6218633538695
At time: 204.17096424102783 and batch: 1400, loss is 4.268170223236084 and perplexity is 71.3908866494392
At time: 205.21674346923828 and batch: 1450, loss is 4.186505889892578 and perplexity is 65.79250261989944
At time: 206.27033925056458 and batch: 1500, loss is 4.196249480247498 and perplexity is 66.43669107158013
At time: 207.31784558296204 and batch: 1550, loss is 4.215235366821289 and perplexity is 67.71010070676498
At time: 208.3693516254425 and batch: 1600, loss is 4.320107879638672 and perplexity is 75.19674005161447
At time: 209.43012714385986 and batch: 1650, loss is 4.246486144065857 and perplexity is 69.85950432320426
At time: 210.48472237586975 and batch: 1700, loss is 4.2879430103302 and perplexity is 72.81653148999511
At time: 211.53803062438965 and batch: 1750, loss is 4.29103271484375 and perplexity is 73.04186097751338
At time: 212.5924563407898 and batch: 1800, loss is 4.239711327552795 and perplexity is 69.3878185959714
At time: 213.64403653144836 and batch: 1850, loss is 4.282012691497803 and perplexity is 72.3859841453178
At time: 214.6949427127838 and batch: 1900, loss is 4.353542404174805 and perplexity is 77.75340965448855
At time: 215.75409746170044 and batch: 1950, loss is 4.286188583374024 and perplexity is 72.68889220393551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.609498773619186 and perplexity of 100.43379694983952
finished 5 epochs...
Completing Train Step...
At time: 219.134259223938 and batch: 50, loss is 4.241487946510315 and perplexity is 69.51120388177466
At time: 220.18852853775024 and batch: 100, loss is 4.200266122817993 and perplexity is 66.704080156881
At time: 221.27478885650635 and batch: 150, loss is 4.162812099456787 and perplexity is 64.25195166717515
At time: 222.33323216438293 and batch: 200, loss is 4.166008496284485 and perplexity is 64.45765498122935
At time: 223.38882184028625 and batch: 250, loss is 4.160842313766479 and perplexity is 64.12551366097664
At time: 224.44497275352478 and batch: 300, loss is 4.188324756622315 and perplexity is 65.91227930987792
At time: 225.50195264816284 and batch: 350, loss is 4.204501814842224 and perplexity is 66.98721731477033
At time: 226.55544137954712 and batch: 400, loss is 4.170708818435669 and perplexity is 64.76133987405565
At time: 227.60765933990479 and batch: 450, loss is 4.1875919914245605 and perplexity is 65.86399877680249
At time: 228.66389846801758 and batch: 500, loss is 4.215296921730041 and perplexity is 67.71426872411524
At time: 229.7200469970703 and batch: 550, loss is 4.179607672691345 and perplexity is 65.34021343466222
At time: 230.7758309841156 and batch: 600, loss is 4.167040863037109 and perplexity is 64.52423328188297
At time: 231.82937455177307 and batch: 650, loss is 4.214463500976563 and perplexity is 67.65785775755428
At time: 232.8809654712677 and batch: 700, loss is 4.233885598182678 and perplexity is 68.98475914085766
At time: 233.93173909187317 and batch: 750, loss is 4.191238374710083 and perplexity is 66.1046025612778
At time: 234.9830219745636 and batch: 800, loss is 4.178232817649842 and perplexity is 65.25044183841523
At time: 236.03618383407593 and batch: 850, loss is 4.178407926559448 and perplexity is 65.26186877258667
At time: 237.0883812904358 and batch: 900, loss is 4.1605330848693844 and perplexity is 64.10568726471693
At time: 238.13387250900269 and batch: 950, loss is 4.26501386642456 and perplexity is 71.16590678323087
At time: 239.18204164505005 and batch: 1000, loss is 4.224412188529969 and perplexity is 68.33432404125911
At time: 240.2274613380432 and batch: 1050, loss is 4.17402865409851 and perplexity is 64.97669415235909
At time: 241.28286838531494 and batch: 1100, loss is 4.22491687297821 and perplexity is 68.3688200159426
At time: 242.34593200683594 and batch: 1150, loss is 4.181216297149658 and perplexity is 65.44540588499518
At time: 243.39994835853577 and batch: 1200, loss is 4.240023641586304 and perplexity is 69.40949276987163
At time: 244.45136904716492 and batch: 1250, loss is 4.221155076026917 and perplexity is 68.11211353878821
At time: 245.5034351348877 and batch: 1300, loss is 4.228461904525757 and perplexity is 68.61161975185243
At time: 246.5583255290985 and batch: 1350, loss is 4.12803469657898 and perplexity is 62.05584445003019
At time: 247.60350584983826 and batch: 1400, loss is 4.155469884872437 and perplexity is 63.78192767059982
At time: 248.64914083480835 and batch: 1450, loss is 4.06854052066803 and perplexity is 58.47156225042235
At time: 249.69427919387817 and batch: 1500, loss is 4.083819379806519 and perplexity is 59.37180080988652
At time: 250.74103355407715 and batch: 1550, loss is 4.103597521781921 and perplexity is 60.557754031897964
At time: 251.7866485118866 and batch: 1600, loss is 4.212774410247802 and perplexity is 67.54367395783441
At time: 252.83671402931213 and batch: 1650, loss is 4.135911746025085 and perplexity is 62.54659168782776
At time: 253.88213205337524 and batch: 1700, loss is 4.175626068115235 and perplexity is 65.08057178005875
At time: 254.92797541618347 and batch: 1750, loss is 4.178093223571778 and perplexity is 65.24133389886552
At time: 255.97268509864807 and batch: 1800, loss is 4.128100280761719 and perplexity is 62.059914465335474
At time: 257.0185852050781 and batch: 1850, loss is 4.165381755828857 and perplexity is 64.41726941813279
At time: 258.06601309776306 and batch: 1900, loss is 4.24231484413147 and perplexity is 69.56870630193887
At time: 259.1187243461609 and batch: 1950, loss is 4.174155135154724 and perplexity is 64.9849129930176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614610964752907 and perplexity of 100.94854834883779
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 262.4250535964966 and batch: 50, loss is 4.16306287765503 and perplexity is 64.26806667640982
At time: 263.51098823547363 and batch: 100, loss is 4.148602542877197 and perplexity is 63.34541591343476
At time: 264.57021164894104 and batch: 150, loss is 4.108800024986267 and perplexity is 60.87362689363259
At time: 265.63295674324036 and batch: 200, loss is 4.11140739440918 and perplexity is 61.032554027894854
At time: 266.69620966911316 and batch: 250, loss is 4.108161215782165 and perplexity is 60.83475267841112
At time: 267.7605736255646 and batch: 300, loss is 4.125934371948242 and perplexity is 61.925643811118505
At time: 268.8216953277588 and batch: 350, loss is 4.137621459960937 and perplexity is 62.653619935047985
At time: 269.88267731666565 and batch: 400, loss is 4.090285024642944 and perplexity is 59.75692147228421
At time: 270.94385981559753 and batch: 450, loss is 4.113152184486389 and perplexity is 61.139135977074254
At time: 272.0082232952118 and batch: 500, loss is 4.1337551021575925 and perplexity is 62.41184631554834
At time: 273.07230734825134 and batch: 550, loss is 4.0885754537582395 and perplexity is 59.65485005319849
At time: 274.16249895095825 and batch: 600, loss is 4.066815996170044 and perplexity is 58.37081350569398
At time: 275.22404384613037 and batch: 650, loss is 4.10478859424591 and perplexity is 60.62992567750405
At time: 276.2834918498993 and batch: 700, loss is 4.115518488883972 and perplexity is 61.28398108962754
At time: 277.3469285964966 and batch: 750, loss is 4.065109672546387 and perplexity is 58.271298933854595
At time: 278.41649436950684 and batch: 800, loss is 4.043960433006287 and perplexity is 57.05184597949719
At time: 279.48087978363037 and batch: 850, loss is 4.040764408111572 and perplexity is 56.86979792946918
At time: 280.54143238067627 and batch: 900, loss is 4.016447315216064 and perplexity is 55.503568457448786
At time: 281.6006746292114 and batch: 950, loss is 4.12190269947052 and perplexity is 61.67648250319071
At time: 282.65974617004395 and batch: 1000, loss is 4.068604216575623 and perplexity is 58.47528676826528
At time: 283.72402000427246 and batch: 1050, loss is 4.017027831077575 and perplexity is 55.535798513433036
At time: 284.78783535957336 and batch: 1100, loss is 4.052514081001282 and perplexity is 57.54194044711175
At time: 285.84914565086365 and batch: 1150, loss is 4.01140410900116 and perplexity is 55.2243571678966
At time: 286.90786957740784 and batch: 1200, loss is 4.052142210006714 and perplexity is 57.52054624667618
At time: 287.96683621406555 and batch: 1250, loss is 4.030015320777893 and perplexity is 56.261773214656095
At time: 289.03130435943604 and batch: 1300, loss is 4.02927794456482 and perplexity is 56.220302413052664
At time: 290.0952377319336 and batch: 1350, loss is 3.924230432510376 and perplexity is 50.61411209210885
At time: 291.1575119495392 and batch: 1400, loss is 3.9386458921432497 and perplexity is 51.349022088033664
At time: 292.21722078323364 and batch: 1450, loss is 3.8443159532546995 and perplexity is 46.72671016223404
At time: 293.2770049571991 and batch: 1500, loss is 3.8581687211990356 and perplexity is 47.37850861802525
At time: 294.3372321128845 and batch: 1550, loss is 3.8706830072402956 and perplexity is 47.9751422627108
At time: 295.4000163078308 and batch: 1600, loss is 3.9616987085342408 and perplexity is 52.546511384956545
At time: 296.4630386829376 and batch: 1650, loss is 3.8825671243667603 and perplexity is 48.548685751297334
At time: 297.52452325820923 and batch: 1700, loss is 3.9038787317276 and perplexity is 49.59444005228369
At time: 298.5925090312958 and batch: 1750, loss is 3.896669454574585 and perplexity is 49.238185699866
At time: 299.66245913505554 and batch: 1800, loss is 3.8424079418182373 and perplexity is 46.637640065259774
At time: 300.7278997898102 and batch: 1850, loss is 3.8730374479293825 and perplexity is 48.08822996662385
At time: 301.78892493247986 and batch: 1900, loss is 3.937785563468933 and perplexity is 51.30486404987012
At time: 302.84770345687866 and batch: 1950, loss is 3.871859283447266 and perplexity is 48.031607483917995
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525243288971657 and perplexity of 92.31838314123831
finished 7 epochs...
Completing Train Step...
At time: 306.1659104824066 and batch: 50, loss is 4.0537592315673825 and perplexity is 57.613633451864004
At time: 307.24118518829346 and batch: 100, loss is 4.0292144393920895 and perplexity is 56.216732246400205
At time: 308.29811000823975 and batch: 150, loss is 3.989101252555847 and perplexity is 54.00632949446502
At time: 309.3536124229431 and batch: 200, loss is 3.9895200538635254 and perplexity is 54.028952152748985
At time: 310.40807843208313 and batch: 250, loss is 3.986679821014404 and perplexity is 53.87571506555815
At time: 311.4616930484772 and batch: 300, loss is 4.007718577384948 and perplexity is 55.02120065340658
At time: 312.51401019096375 and batch: 350, loss is 4.0229536724090575 and perplexity is 55.86587185888431
At time: 313.5689504146576 and batch: 400, loss is 3.9795721054077147 and perplexity is 53.49413947656945
At time: 314.6246716976166 and batch: 450, loss is 4.0060709285736085 and perplexity is 54.93061968085941
At time: 315.6854064464569 and batch: 500, loss is 4.029097108840943 and perplexity is 56.210136693159576
At time: 316.73859691619873 and batch: 550, loss is 3.988092679977417 and perplexity is 53.95188765036572
At time: 317.79113388061523 and batch: 600, loss is 3.9709647274017335 and perplexity is 53.03567113269984
At time: 318.8461363315582 and batch: 650, loss is 4.010819754600525 and perplexity is 55.19209599865943
At time: 319.91290044784546 and batch: 700, loss is 4.026888194084168 and perplexity is 56.08611032500534
At time: 320.97220182418823 and batch: 750, loss is 3.979133243560791 and perplexity is 53.47066809044382
At time: 322.02450585365295 and batch: 800, loss is 3.9604435968399048 and perplexity is 52.48060101511112
At time: 323.07977652549744 and batch: 850, loss is 3.9593347978591917 and perplexity is 52.42244282702667
At time: 324.1341574192047 and batch: 900, loss is 3.9355416679382325 and perplexity is 51.18987035988899
At time: 325.1898629665375 and batch: 950, loss is 4.044310507774353 and perplexity is 57.07182188757286
At time: 326.2466835975647 and batch: 1000, loss is 3.99317186832428 and perplexity is 54.226616558721
At time: 327.3280930519104 and batch: 1050, loss is 3.946669507026672 and perplexity is 51.76268417932516
At time: 328.3821451663971 and batch: 1100, loss is 3.982163944244385 and perplexity is 53.63296749701032
At time: 329.43798089027405 and batch: 1150, loss is 3.9475183486938477 and perplexity is 51.80664115607876
At time: 330.498361825943 and batch: 1200, loss is 3.9905245733261108 and perplexity is 54.08325255506897
At time: 331.5549521446228 and batch: 1250, loss is 3.9733615732192993 and perplexity is 53.1629419225367
At time: 332.60902523994446 and batch: 1300, loss is 3.9750268173217775 and perplexity is 53.25154495040345
At time: 333.66567277908325 and batch: 1350, loss is 3.871015315055847 and perplexity is 47.99108742664146
At time: 334.71788573265076 and batch: 1400, loss is 3.8904356479644777 and perplexity is 48.932199093938586
At time: 335.7737555503845 and batch: 1450, loss is 3.8011964702606202 and perplexity is 44.75470013971711
At time: 336.82992148399353 and batch: 1500, loss is 3.8168471670150756 and perplexity is 45.460652291611964
At time: 337.88549065589905 and batch: 1550, loss is 3.832636442184448 and perplexity is 46.18413968029309
At time: 338.9394164085388 and batch: 1600, loss is 3.9295183181762696 and perplexity is 50.8824626080608
At time: 339.99266958236694 and batch: 1650, loss is 3.852777810096741 and perplexity is 47.123782509711084
At time: 341.04463839530945 and batch: 1700, loss is 3.8798703575134277 and perplexity is 48.41793764261254
At time: 342.09960412979126 and batch: 1750, loss is 3.876244821548462 and perplexity is 48.24271449917916
At time: 343.15599393844604 and batch: 1800, loss is 3.8261991262435915 and perplexity is 45.887792644822724
At time: 344.2122437953949 and batch: 1850, loss is 3.8616908740997316 and perplexity is 47.54567719340792
At time: 345.2653923034668 and batch: 1900, loss is 3.929728889465332 and perplexity is 50.893178121953035
At time: 346.3175575733185 and batch: 1950, loss is 3.8679884481430054 and perplexity is 47.84604441568326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.523609250090843 and perplexity of 92.16765449554354
finished 8 epochs...
Completing Train Step...
At time: 349.6971502304077 and batch: 50, loss is 3.999821491241455 and perplexity is 54.58840465500652
At time: 350.7499978542328 and batch: 100, loss is 3.9717092514038086 and perplexity is 53.07517216573323
At time: 351.80268716812134 and batch: 150, loss is 3.9327281761169433 and perplexity is 51.04605049118076
At time: 352.85471415519714 and batch: 200, loss is 3.9330715703964234 and perplexity is 51.063582422919744
At time: 353.9386394023895 and batch: 250, loss is 3.930322542190552 and perplexity is 50.92339996559259
At time: 354.9946668148041 and batch: 300, loss is 3.9518744277954103 and perplexity is 52.03280722394879
At time: 356.046767950058 and batch: 350, loss is 3.9680750370025635 and perplexity is 52.88263568204151
At time: 357.1013674736023 and batch: 400, loss is 3.9247979021072386 and perplexity is 50.64284221285735
At time: 358.1624433994293 and batch: 450, loss is 3.951242609024048 and perplexity is 51.99994230304827
At time: 359.22583198547363 and batch: 500, loss is 3.9778246593475344 and perplexity is 53.40074297973464
At time: 360.28167486190796 and batch: 550, loss is 3.9369715595245363 and perplexity is 51.26311868091932
At time: 361.3354208469391 and batch: 600, loss is 3.92164493560791 and perplexity is 50.48341848883183
At time: 362.3877055644989 and batch: 650, loss is 3.9614042234420777 and perplexity is 52.531039498940196
At time: 363.43972659111023 and batch: 700, loss is 3.978818817138672 and perplexity is 53.45385814247221
At time: 364.4922881126404 and batch: 750, loss is 3.9331588554382324 and perplexity is 51.06803970437061
At time: 365.5464324951172 and batch: 800, loss is 3.9145638704299928 and perplexity is 50.127204786751584
At time: 366.60011649131775 and batch: 850, loss is 3.914169816970825 and perplexity is 50.107455879625086
At time: 367.6462264060974 and batch: 900, loss is 3.889276156425476 and perplexity is 48.87549550312409
At time: 368.6939945220947 and batch: 950, loss is 4.000831332206726 and perplexity is 54.643558105675844
At time: 369.7455940246582 and batch: 1000, loss is 3.9503690814971923 and perplexity is 51.954538755563036
At time: 370.8003623485565 and batch: 1050, loss is 3.9062118768692016 and perplexity is 49.710286169493564
At time: 371.8573727607727 and batch: 1100, loss is 3.9398785781860353 and perplexity is 51.41235833970896
At time: 372.9164469242096 and batch: 1150, loss is 3.908234438896179 and perplexity is 49.810930051588116
At time: 373.9750180244446 and batch: 1200, loss is 3.951887345314026 and perplexity is 52.0334793630459
At time: 375.0263068675995 and batch: 1250, loss is 3.937842869758606 and perplexity is 51.307804225515454
At time: 376.0809292793274 and batch: 1300, loss is 3.9397315168380738 and perplexity is 51.40479812491096
At time: 377.13643646240234 and batch: 1350, loss is 3.836205253601074 and perplexity is 46.349256625621166
At time: 378.1950159072876 and batch: 1400, loss is 3.8583358001708983 and perplexity is 47.38642523186497
At time: 379.2506549358368 and batch: 1450, loss is 3.770596127510071 and perplexity is 43.40593259536441
At time: 380.30310320854187 and batch: 1500, loss is 3.786128807067871 and perplexity is 44.0854064007189
At time: 381.35447120666504 and batch: 1550, loss is 3.8031436824798583 and perplexity is 44.84193194054915
At time: 382.4123315811157 and batch: 1600, loss is 3.902005548477173 and perplexity is 49.501627532430746
At time: 383.4694097042084 and batch: 1650, loss is 3.827277307510376 and perplexity is 45.937294684516985
At time: 384.52228260040283 and batch: 1700, loss is 3.8560423946380613 and perplexity is 47.277873466246
At time: 385.5730528831482 and batch: 1750, loss is 3.853564600944519 and perplexity is 47.160873660077826
At time: 386.62469267845154 and batch: 1800, loss is 3.804629464149475 and perplexity is 44.90860678091879
At time: 387.6791732311249 and batch: 1850, loss is 3.8422282838821413 and perplexity is 46.62926199571714
At time: 388.73558712005615 and batch: 1900, loss is 3.911292471885681 and perplexity is 49.96348666160984
At time: 389.7909505367279 and batch: 1950, loss is 3.8512048816680906 and perplexity is 47.04971843654932
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525897642623547 and perplexity of 92.37881178107774
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 393.13664746284485 and batch: 50, loss is 3.9745172214508058 and perplexity is 53.224415096191805
At time: 394.2220284938812 and batch: 100, loss is 3.9655308961868285 and perplexity is 52.748265810573834
At time: 395.2837133407593 and batch: 150, loss is 3.93631564617157 and perplexity is 51.22950554172033
At time: 396.342045545578 and batch: 200, loss is 3.939696168899536 and perplexity is 51.402981103380476
At time: 397.3920121192932 and batch: 250, loss is 3.940724139213562 and perplexity is 51.455849010671244
At time: 398.44543957710266 and batch: 300, loss is 3.9601006650924684 and perplexity is 52.462606836462406
At time: 399.5008018016815 and batch: 350, loss is 3.976962947845459 and perplexity is 53.35474676586909
At time: 400.5645081996918 and batch: 400, loss is 3.9328492164611815 and perplexity is 51.052229496651144
At time: 401.6277959346771 and batch: 450, loss is 3.9615719938278198 and perplexity is 52.53985339103473
At time: 402.6835906505585 and batch: 500, loss is 3.983230233192444 and perplexity is 53.690186237938185
At time: 403.73391222953796 and batch: 550, loss is 3.942178792953491 and perplexity is 51.53075392102149
At time: 404.78734707832336 and batch: 600, loss is 3.9211906242370604 and perplexity is 50.46048850684316
At time: 405.8431577682495 and batch: 650, loss is 3.950001139640808 and perplexity is 51.93542602252859
At time: 406.9428958892822 and batch: 700, loss is 3.965894184112549 and perplexity is 52.76743209987545
At time: 408.0069043636322 and batch: 750, loss is 3.9186137247085573 and perplexity is 50.33062429317996
At time: 409.06336855888367 and batch: 800, loss is 3.894637355804443 and perplexity is 49.138230437141004
At time: 410.1154201030731 and batch: 850, loss is 3.89059832572937 and perplexity is 48.940159922225774
At time: 411.16728377342224 and batch: 900, loss is 3.8580551290512086 and perplexity is 47.37312709712553
At time: 412.21792364120483 and batch: 950, loss is 3.974183716773987 and perplexity is 53.20666746445987
At time: 413.2701241970062 and batch: 1000, loss is 3.924276075363159 and perplexity is 50.616422317298046
At time: 414.3322720527649 and batch: 1050, loss is 3.8779401922225953 and perplexity is 48.324573153355445
At time: 415.39045882225037 and batch: 1100, loss is 3.9054880380630492 and perplexity is 49.67431695482633
At time: 416.44658517837524 and batch: 1150, loss is 3.8738343954086303 and perplexity is 48.126569035360156
At time: 417.49926114082336 and batch: 1200, loss is 3.909852285385132 and perplexity is 49.89158171329575
At time: 418.5524115562439 and batch: 1250, loss is 3.892539372444153 and perplexity is 49.03524731354327
At time: 419.61215567588806 and batch: 1300, loss is 3.890268120765686 and perplexity is 48.924002306305276
At time: 420.668741941452 and batch: 1350, loss is 3.7804047107696532 and perplexity is 43.83377814836448
At time: 421.72577023506165 and batch: 1400, loss is 3.804208664894104 and perplexity is 44.88971324809668
At time: 422.7812340259552 and batch: 1450, loss is 3.709457802772522 and perplexity is 40.831661710331005
At time: 423.83396077156067 and batch: 1500, loss is 3.7239937448501585 and perplexity is 41.42952309210684
At time: 424.88381934165955 and batch: 1550, loss is 3.738795156478882 and perplexity is 42.04729921775631
At time: 425.94286155700684 and batch: 1600, loss is 3.8339503812789917 and perplexity is 46.24486271141296
At time: 427.00223684310913 and batch: 1650, loss is 3.7552516317367552 and perplexity is 42.74497444954971
At time: 428.05949091911316 and batch: 1700, loss is 3.7764205980300902 and perplexity is 43.659486863031525
At time: 429.1199915409088 and batch: 1750, loss is 3.7699406576156616 and perplexity is 43.37749063575184
At time: 430.17687344551086 and batch: 1800, loss is 3.716623992919922 and perplexity is 41.125320111434974
At time: 431.23120188713074 and batch: 1850, loss is 3.7528558349609376 and perplexity is 42.64268875437573
At time: 432.2830686569214 and batch: 1900, loss is 3.8253599071502684 and perplexity is 45.849298887691944
At time: 433.33571887016296 and batch: 1950, loss is 3.7691638326644896 and perplexity is 43.343807003543624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493834597565407 and perplexity of 89.46384682340589
finished 10 epochs...
Completing Train Step...
At time: 436.67953395843506 and batch: 50, loss is 3.957301778793335 and perplexity is 52.315975263244745
At time: 437.7607879638672 and batch: 100, loss is 3.9344088220596314 and perplexity is 51.13191296082425
At time: 438.82248187065125 and batch: 150, loss is 3.900938882827759 and perplexity is 49.44885399761391
At time: 439.88115215301514 and batch: 200, loss is 3.899445734024048 and perplexity is 49.37507459594272
At time: 440.933132648468 and batch: 250, loss is 3.8999515056610106 and perplexity is 49.400053424505295
At time: 441.9833936691284 and batch: 300, loss is 3.9150074243545534 and perplexity is 50.14944383690638
At time: 443.034455537796 and batch: 350, loss is 3.933889079093933 and perplexity is 51.10534441374597
At time: 444.0924243927002 and batch: 400, loss is 3.891064991950989 and perplexity is 48.963003971600635
At time: 445.1529631614685 and batch: 450, loss is 3.92088472366333 and perplexity is 50.445054975141666
At time: 446.2142219543457 and batch: 500, loss is 3.9436965703964235 and perplexity is 51.609025521348975
At time: 447.27279138565063 and batch: 550, loss is 3.9044734191894532 and perplexity is 49.62394201531471
At time: 448.3304772377014 and batch: 600, loss is 3.885452890396118 and perplexity is 48.68898824212355
At time: 449.38792061805725 and batch: 650, loss is 3.915268406867981 and perplexity is 50.162533672840766
At time: 450.4442045688629 and batch: 700, loss is 3.934161677360535 and perplexity is 51.119277541034144
At time: 451.5047607421875 and batch: 750, loss is 3.8883632230758667 and perplexity is 48.83089579467885
At time: 452.56557869911194 and batch: 800, loss is 3.866034007072449 and perplexity is 47.75262346402372
At time: 453.633327960968 and batch: 850, loss is 3.86231849193573 and perplexity is 47.57552707461822
At time: 454.69177865982056 and batch: 900, loss is 3.8325173330307005 and perplexity is 46.17863905409319
At time: 455.7492995262146 and batch: 950, loss is 3.949617805480957 and perplexity is 51.91552121496782
At time: 456.8075840473175 and batch: 1000, loss is 3.9002659273147584 and perplexity is 49.41558831312296
At time: 457.8744511604309 and batch: 1050, loss is 3.8553768301010134 and perplexity is 47.24641745944232
At time: 458.9360752105713 and batch: 1100, loss is 3.8839728927612303 and perplexity is 48.616981952392884
At time: 460.05691266059875 and batch: 1150, loss is 3.8546683979034424 and perplexity is 47.21295842922068
At time: 461.1146993637085 and batch: 1200, loss is 3.8917384576797485 and perplexity is 48.99598998297997
At time: 462.1700654029846 and batch: 1250, loss is 3.8767178106307982 and perplexity is 48.26553817368846
At time: 463.2249174118042 and batch: 1300, loss is 3.8761444807052614 and perplexity is 48.2378740273806
At time: 464.2912209033966 and batch: 1350, loss is 3.7678939294815064 and perplexity is 43.28879949956175
At time: 465.3526635169983 and batch: 1400, loss is 3.793345403671265 and perplexity is 44.40470372908757
At time: 466.4137797355652 and batch: 1450, loss is 3.701260652542114 and perplexity is 40.498326510975474
At time: 467.47302889823914 and batch: 1500, loss is 3.717830080986023 and perplexity is 41.174950792705886
At time: 468.52957797050476 and batch: 1550, loss is 3.7342248344421387 and perplexity is 41.85556799002103
At time: 469.58722853660583 and batch: 1600, loss is 3.8315876007080076 and perplexity is 46.135725233021134
At time: 470.64628529548645 and batch: 1650, loss is 3.7548732566833496 and perplexity is 42.72880387702308
At time: 471.70760130882263 and batch: 1700, loss is 3.7779357767105104 and perplexity is 43.72568892803785
At time: 472.7694113254547 and batch: 1750, loss is 3.7732073974609377 and perplexity is 43.51942531841903
At time: 473.8288538455963 and batch: 1800, loss is 3.721037411689758 and perplexity is 41.30722448595567
At time: 474.88659739494324 and batch: 1850, loss is 3.758927974700928 and perplexity is 42.90240884972878
At time: 475.9439787864685 and batch: 1900, loss is 3.8318765497207643 and perplexity is 46.14905803143673
At time: 477.0026731491089 and batch: 1950, loss is 3.7757801055908202 and perplexity is 43.63153224510971
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493754258266715 and perplexity of 89.45665964940395
finished 11 epochs...
Completing Train Step...
At time: 480.3707478046417 and batch: 50, loss is 3.941592240333557 and perplexity is 51.50053728499178
At time: 481.41984820365906 and batch: 100, loss is 3.916788058280945 and perplexity is 50.238821188548926
At time: 482.47641825675964 and batch: 150, loss is 3.8830591297149657 and perplexity is 48.5725778413714
At time: 483.5334815979004 and batch: 200, loss is 3.879995069503784 and perplexity is 48.4239763165246
At time: 484.5943069458008 and batch: 250, loss is 3.88036593914032 and perplexity is 48.44193862965312
At time: 485.6540825366974 and batch: 300, loss is 3.8946863317489626 and perplexity is 49.140637087322176
At time: 486.7426857948303 and batch: 350, loss is 3.9144125509262087 and perplexity is 50.11962013686437
At time: 487.8044590950012 and batch: 400, loss is 3.871771101951599 and perplexity is 48.02737217167161
At time: 488.86580419540405 and batch: 450, loss is 3.902048120498657 and perplexity is 49.50373496163999
At time: 489.9207706451416 and batch: 500, loss is 3.925095725059509 and perplexity is 50.657927059831884
At time: 490.98222255706787 and batch: 550, loss is 3.8863349771499633 and perplexity is 48.73195510117271
At time: 492.0361361503601 and batch: 600, loss is 3.8680867099761964 and perplexity is 47.850746086712114
At time: 493.09197306632996 and batch: 650, loss is 3.8981319093704223 and perplexity is 49.31024700103528
At time: 494.1567051410675 and batch: 700, loss is 3.918089327812195 and perplexity is 50.3042379890613
At time: 495.21320700645447 and batch: 750, loss is 3.8727648735046385 and perplexity is 48.07512413124265
At time: 496.26325607299805 and batch: 800, loss is 3.8509668064117433 and perplexity is 47.03851839605063
At time: 497.31277990341187 and batch: 850, loss is 3.8472771501541136 and perplexity is 46.865282219801976
At time: 498.3628749847412 and batch: 900, loss is 3.8183481168746947 and perplexity is 45.52893768494329
At time: 499.4235055446625 and batch: 950, loss is 3.935863904953003 and perplexity is 51.20636828887919
At time: 500.4772593975067 and batch: 1000, loss is 3.88707884311676 and perplexity is 48.768218629998245
At time: 501.5298767089844 and batch: 1050, loss is 3.8430007696151733 and perplexity is 46.66529635157163
At time: 502.5817565917969 and batch: 1100, loss is 3.871743321418762 and perplexity is 48.02603796421451
At time: 503.63019275665283 and batch: 1150, loss is 3.8434415674209594 and perplexity is 46.68587084607263
At time: 504.68111753463745 and batch: 1200, loss is 3.8811726570129395 and perplexity is 48.48103337442444
At time: 505.7349956035614 and batch: 1250, loss is 3.8671756649017333 and perplexity is 47.807171752285704
At time: 506.7911822795868 and batch: 1300, loss is 3.867199444770813 and perplexity is 47.8083086140882
At time: 507.8523201942444 and batch: 1350, loss is 3.7596787548065187 and perplexity is 42.934631219218495
At time: 508.9038164615631 and batch: 1400, loss is 3.7858586883544922 and perplexity is 44.073499715644786
At time: 509.9527220726013 and batch: 1450, loss is 3.69475447177887 and perplexity is 40.23569237711069
At time: 511.0028381347656 and batch: 1500, loss is 3.7119800090789794 and perplexity is 40.93477757007131
At time: 512.0529627799988 and batch: 1550, loss is 3.7290104961395265 and perplexity is 41.637886923251706
At time: 513.1028356552124 and batch: 1600, loss is 3.827131276130676 and perplexity is 45.930586887780855
At time: 514.1512980461121 and batch: 1650, loss is 3.751258358955383 and perplexity is 42.57462246388624
At time: 515.195011138916 and batch: 1700, loss is 3.775173683166504 and perplexity is 43.605081126635305
At time: 516.2444069385529 and batch: 1750, loss is 3.7712360286712645 and perplexity is 43.43371699072022
At time: 517.2964107990265 and batch: 1800, loss is 3.7196240758895875 and perplexity is 41.24888474331863
At time: 518.3424725532532 and batch: 1850, loss is 3.758203706741333 and perplexity is 42.87134725942461
At time: 519.3869297504425 and batch: 1900, loss is 3.8314390182495117 and perplexity is 46.128870782779664
At time: 520.4313099384308 and batch: 1950, loss is 3.7754248905181886 and perplexity is 43.61603641955257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.494685967023982 and perplexity of 89.54004604247936
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 523.7717821598053 and batch: 50, loss is 3.934325771331787 and perplexity is 51.12766659457113
At time: 524.8561220169067 and batch: 100, loss is 3.9173108530044556 and perplexity is 50.26509264587296
At time: 525.908821105957 and batch: 150, loss is 3.8898489046096802 and perplexity is 48.90349687252687
At time: 526.9644207954407 and batch: 200, loss is 3.888875713348389 and perplexity is 48.855927567494334
At time: 528.0272188186646 and batch: 250, loss is 3.8932083559036257 and perplexity is 49.06806205796398
At time: 529.0859417915344 and batch: 300, loss is 3.90438784122467 and perplexity is 49.61969548106
At time: 530.1416189670563 and batch: 350, loss is 3.9269920444488524 and perplexity is 50.75408181038372
At time: 531.1991279125214 and batch: 400, loss is 3.884700045585632 and perplexity is 48.652346784393934
At time: 532.2642209529877 and batch: 450, loss is 3.917421646118164 and perplexity is 50.270661980514305
At time: 533.3256838321686 and batch: 500, loss is 3.9374284505844117 and perplexity is 51.28654569293461
At time: 534.3840370178223 and batch: 550, loss is 3.8986448574066164 and perplexity is 49.335547083657815
At time: 535.444807767868 and batch: 600, loss is 3.876616201400757 and perplexity is 48.260634198665876
At time: 536.5051817893982 and batch: 650, loss is 3.9029166984558104 and perplexity is 49.546751493525726
At time: 537.5688006877899 and batch: 700, loss is 3.920932722091675 and perplexity is 50.44747631660807
At time: 538.629026889801 and batch: 750, loss is 3.8753633213043215 and perplexity is 48.20020727238802
At time: 539.7124993801117 and batch: 800, loss is 3.8516861248016356 and perplexity is 47.07236623959489
At time: 540.7662408351898 and batch: 850, loss is 3.8474235248565676 and perplexity is 46.87214261362412
At time: 541.8282854557037 and batch: 900, loss is 3.8107572412490844 and perplexity is 45.18464158926452
At time: 542.8845796585083 and batch: 950, loss is 3.92983766078949 and perplexity is 50.89871414140259
At time: 543.9412713050842 and batch: 1000, loss is 3.881977472305298 and perplexity is 48.5200673569396
At time: 545.0047333240509 and batch: 1050, loss is 3.8411584806442263 and perplexity is 46.579404533844674
At time: 546.0686655044556 and batch: 1100, loss is 3.865584959983826 and perplexity is 47.73118510126053
At time: 547.1278586387634 and batch: 1150, loss is 3.8381673431396486 and perplexity is 46.440287293123085
At time: 548.1858355998993 and batch: 1200, loss is 3.8759498977661133 and perplexity is 48.22848867321861
At time: 549.2420320510864 and batch: 1250, loss is 3.860512433052063 and perplexity is 47.489680416694455
At time: 550.3040251731873 and batch: 1300, loss is 3.85783212184906 and perplexity is 47.362563726492205
At time: 551.3631348609924 and batch: 1350, loss is 3.747377109527588 and perplexity is 42.409699994463686
At time: 552.4231240749359 and batch: 1400, loss is 3.7744809436798095 and perplexity is 43.5748846254803
At time: 553.4826002120972 and batch: 1450, loss is 3.677619385719299 and perplexity is 39.55212355605587
At time: 554.5374739170074 and batch: 1500, loss is 3.690270280838013 and perplexity is 40.05567177488492
At time: 555.5895450115204 and batch: 1550, loss is 3.7085952043533323 and perplexity is 40.79645557005028
At time: 556.6426620483398 and batch: 1600, loss is 3.8022364711761476 and perplexity is 44.80126928061371
At time: 557.6955134868622 and batch: 1650, loss is 3.7227171659469604 and perplexity is 41.37666878048533
At time: 558.7512440681458 and batch: 1700, loss is 3.7440138816833497 and perplexity is 42.267306096359654
At time: 559.8083777427673 and batch: 1750, loss is 3.740604500770569 and perplexity is 42.12344612578982
At time: 560.8610026836395 and batch: 1800, loss is 3.690659217834473 and perplexity is 40.071253937599586
At time: 561.9161305427551 and batch: 1850, loss is 3.728032350540161 and perplexity is 41.59717891981374
At time: 562.9726893901825 and batch: 1900, loss is 3.801115131378174 and perplexity is 44.75105999046837
At time: 564.0380752086639 and batch: 1950, loss is 3.749547209739685 and perplexity is 42.501833226432574
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487423918968023 and perplexity of 88.89215727220355
finished 13 epochs...
Completing Train Step...
At time: 567.5051155090332 and batch: 50, loss is 3.931445126533508 and perplexity is 50.980597875816585
At time: 568.6116261482239 and batch: 100, loss is 3.9078136491775513 and perplexity is 49.78997453358958
At time: 569.6746978759766 and batch: 150, loss is 3.8767241716384886 and perplexity is 48.26584519212444
At time: 570.7395143508911 and batch: 200, loss is 3.872402572631836 and perplexity is 48.057709626645405
At time: 571.8021023273468 and batch: 250, loss is 3.876360754966736 and perplexity is 48.24830776619488
At time: 572.8591063022614 and batch: 300, loss is 3.886433482170105 and perplexity is 48.73675567982816
At time: 573.9171912670135 and batch: 350, loss is 3.909039006233215 and perplexity is 49.85102242527943
At time: 574.9755029678345 and batch: 400, loss is 3.868691234588623 and perplexity is 47.879681785734405
At time: 576.0325765609741 and batch: 450, loss is 3.9009138774871825 and perplexity is 49.44761752763783
At time: 577.094643831253 and batch: 500, loss is 3.9221616840362548 and perplexity is 50.50951245742138
At time: 578.1627426147461 and batch: 550, loss is 3.8841437005996706 and perplexity is 48.62528682323999
At time: 579.2219290733337 and batch: 600, loss is 3.863152279853821 and perplexity is 47.61521151619475
At time: 580.2943003177643 and batch: 650, loss is 3.8897364282608033 and perplexity is 48.897996695077076
At time: 581.3611736297607 and batch: 700, loss is 3.9089524221420286 and perplexity is 49.84670630666432
At time: 582.4231984615326 and batch: 750, loss is 3.8637223052978515 and perplexity is 47.64236113553365
At time: 583.4824199676514 and batch: 800, loss is 3.840714678764343 and perplexity is 46.55873709301248
At time: 584.5425119400024 and batch: 850, loss is 3.8365385246276857 and perplexity is 46.364706064241616
At time: 585.6020514965057 and batch: 900, loss is 3.801853199005127 and perplexity is 44.7841014910502
At time: 586.6662311553955 and batch: 950, loss is 3.9213847589492796 and perplexity is 50.47028559020409
At time: 587.729499578476 and batch: 1000, loss is 3.87371018409729 and perplexity is 48.120591542353765
At time: 588.7934679985046 and batch: 1050, loss is 3.8327102279663086 and perplexity is 46.18754753887317
At time: 589.8536586761475 and batch: 1100, loss is 3.858302426338196 and perplexity is 47.38484379162643
At time: 590.914434671402 and batch: 1150, loss is 3.8312076473236085 and perplexity is 46.11819913783757
At time: 591.9794130325317 and batch: 1200, loss is 3.869267635345459 and perplexity is 47.90728762580203
At time: 593.0875384807587 and batch: 1250, loss is 3.8549649715423584 and perplexity is 47.226962624640976
At time: 594.1488904953003 and batch: 1300, loss is 3.8530418777465822 and perplexity is 47.13622801936598
At time: 595.2025878429413 and batch: 1350, loss is 3.743511757850647 and perplexity is 42.24608800212574
At time: 596.2558805942535 and batch: 1400, loss is 3.7715160274505615 and perplexity is 43.44588008120373
At time: 597.3094284534454 and batch: 1450, loss is 3.6766246604919433 and perplexity is 39.51279962245607
At time: 598.3677968978882 and batch: 1500, loss is 3.690741095542908 and perplexity is 40.074535014367804
At time: 599.4360613822937 and batch: 1550, loss is 3.709750323295593 and perplexity is 40.843607556489786
At time: 600.5000214576721 and batch: 1600, loss is 3.8046360874176024 and perplexity is 44.908904223647745
At time: 601.5637533664703 and batch: 1650, loss is 3.7261518669128417 and perplexity is 41.51902960819228
At time: 602.626321554184 and batch: 1700, loss is 3.7480278158187867 and perplexity is 42.437305233535255
At time: 603.6864533424377 and batch: 1750, loss is 3.745521593093872 and perplexity is 42.331081061093116
At time: 604.7467494010925 and batch: 1800, loss is 3.6956544637680055 and perplexity is 40.27192047798235
At time: 605.8078300952911 and batch: 1850, loss is 3.733620300292969 and perplexity is 41.83027251659729
At time: 606.8675813674927 and batch: 1900, loss is 3.8066886615753175 and perplexity is 45.001177746636706
At time: 607.9362683296204 and batch: 1950, loss is 3.7547831535339355 and perplexity is 42.72495405066641
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4869728265806685 and perplexity of 88.85206773948383
finished 14 epochs...
Completing Train Step...
At time: 611.3196184635162 and batch: 50, loss is 3.927824001312256 and perplexity is 50.796324586738926
At time: 612.3797450065613 and batch: 100, loss is 3.9025219440460206 and perplexity is 49.52719655483598
At time: 613.4311609268188 and batch: 150, loss is 3.87070116519928 and perplexity is 47.9760134012853
At time: 614.482590675354 and batch: 200, loss is 3.8655068492889404 and perplexity is 47.727456930831444
At time: 615.5341441631317 and batch: 250, loss is 3.869081826210022 and perplexity is 47.898386841056315
At time: 616.586900472641 and batch: 300, loss is 3.878610510826111 and perplexity is 48.35697687294179
At time: 617.642829656601 and batch: 350, loss is 3.9014357900619507 and perplexity is 49.47343159677551
At time: 618.6999611854553 and batch: 400, loss is 3.861130495071411 and perplexity is 47.51904105688463
At time: 619.7967188358307 and batch: 450, loss is 3.893323655128479 and perplexity is 49.07371989365009
At time: 620.8565747737885 and batch: 500, loss is 3.914780979156494 and perplexity is 50.13808902183436
At time: 621.9101467132568 and batch: 550, loss is 3.8768878602981567 and perplexity is 48.27374641028394
At time: 622.9616658687592 and batch: 600, loss is 3.8564169883728026 and perplexity is 47.29558677887918
At time: 624.0202217102051 and batch: 650, loss is 3.8830799531936644 and perplexity is 48.57358930194245
At time: 625.0819466114044 and batch: 700, loss is 3.902781562805176 and perplexity is 49.54005641340802
At time: 626.1409657001495 and batch: 750, loss is 3.857691946029663 and perplexity is 47.35592510561104
At time: 627.1980032920837 and batch: 800, loss is 3.835050582885742 and perplexity is 46.29576938233761
At time: 628.2512695789337 and batch: 850, loss is 3.830972285270691 and perplexity is 46.10734594107707
At time: 629.3042464256287 and batch: 900, loss is 3.797053861618042 and perplexity is 44.56968242470878
At time: 630.356862783432 and batch: 950, loss is 3.9168942165374756 and perplexity is 50.24415473731157
At time: 631.4148166179657 and batch: 1000, loss is 3.869290657043457 and perplexity is 47.90839054560513
At time: 632.4785225391388 and batch: 1050, loss is 3.828371286392212 and perplexity is 45.987576613459986
At time: 633.5333986282349 and batch: 1100, loss is 3.8543739891052247 and perplexity is 47.1990605647964
At time: 634.5860602855682 and batch: 1150, loss is 3.827636637687683 and perplexity is 45.9538043067861
At time: 635.6390535831451 and batch: 1200, loss is 3.8658287811279295 and perplexity is 47.74282439231631
At time: 636.692705154419 and batch: 1250, loss is 3.852154321670532 and perplexity is 47.09441053421199
At time: 637.7498354911804 and batch: 1300, loss is 3.85052978515625 and perplexity is 47.01796605491671
At time: 638.8145186901093 and batch: 1350, loss is 3.741398477554321 and perplexity is 42.156904444871955
At time: 639.8759648799896 and batch: 1400, loss is 3.76989953994751 and perplexity is 43.37570709115448
At time: 640.9286880493164 and batch: 1450, loss is 3.675684242248535 and perplexity is 39.47565853165992
At time: 641.9866416454315 and batch: 1500, loss is 3.6903842878341675 and perplexity is 40.06023866202653
At time: 643.0418620109558 and batch: 1550, loss is 3.709761257171631 and perplexity is 40.84405413787317
At time: 644.0994839668274 and batch: 1600, loss is 3.805186557769775 and perplexity is 44.93363204931447
At time: 645.1562321186066 and batch: 1650, loss is 3.7272213077545167 and perplexity is 41.56345550536224
At time: 646.2150545120239 and batch: 1700, loss is 3.74936007976532 and perplexity is 42.493880603580706
At time: 647.267213344574 and batch: 1750, loss is 3.7472409200668335 and perplexity is 42.40392463357125
At time: 648.3202221393585 and batch: 1800, loss is 3.6974133157730105 and perplexity is 40.34281515440592
At time: 649.3849649429321 and batch: 1850, loss is 3.7356608057022096 and perplexity is 41.91571455676401
At time: 650.4543325901031 and batch: 1900, loss is 3.8086618614196777 and perplexity is 45.09006172765187
At time: 651.5245938301086 and batch: 1950, loss is 3.7565375089645388 and perplexity is 42.79997459293405
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487106252271076 and perplexity of 88.86392367889195
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 654.9244940280914 and batch: 50, loss is 3.9259723472595214 and perplexity is 50.70235439344753
At time: 656.0066630840302 and batch: 100, loss is 3.9024449443817137 and perplexity is 49.523383124145525
At time: 657.06662940979 and batch: 150, loss is 3.872282280921936 and perplexity is 48.051929030266436
At time: 658.1252784729004 and batch: 200, loss is 3.867043876647949 and perplexity is 47.80087174374479
At time: 659.184047460556 and batch: 250, loss is 3.8716901111602784 and perplexity is 48.023482554308096
At time: 660.2434763908386 and batch: 300, loss is 3.8799264526367185 and perplexity is 48.42065372897298
At time: 661.2952878475189 and batch: 350, loss is 3.903798065185547 and perplexity is 49.59043960165303
At time: 662.3597192764282 and batch: 400, loss is 3.864856491088867 and perplexity is 47.69642707920077
At time: 663.4148423671722 and batch: 450, loss is 3.898005223274231 and perplexity is 49.30400047402291
At time: 664.468804359436 and batch: 500, loss is 3.919173450469971 and perplexity is 50.3588035257704
At time: 665.5200572013855 and batch: 550, loss is 3.882090663909912 and perplexity is 48.525559732059236
At time: 666.5795404911041 and batch: 600, loss is 3.86008113861084 and perplexity is 47.4692027977743
At time: 667.6396861076355 and batch: 650, loss is 3.885816888809204 and perplexity is 48.70671418248982
At time: 668.6932370662689 and batch: 700, loss is 3.904370679855347 and perplexity is 49.61884394644691
At time: 669.7538676261902 and batch: 750, loss is 3.859262452125549 and perplexity is 47.4303563066946
At time: 670.8086359500885 and batch: 800, loss is 3.8357336807250975 and perplexity is 46.32740472616133
At time: 671.8559994697571 and batch: 850, loss is 3.831018090248108 and perplexity is 46.10945793538621
At time: 672.9302732944489 and batch: 900, loss is 3.7942115592956545 and perplexity is 44.44318177455403
At time: 673.9767577648163 and batch: 950, loss is 3.9126516485214236 and perplexity is 50.03144203653796
At time: 675.0294132232666 and batch: 1000, loss is 3.8639759969711305 and perplexity is 47.654449139097174
At time: 676.0828492641449 and batch: 1050, loss is 3.8241771173477175 and perplexity is 45.79510086326732
At time: 677.1404006481171 and batch: 1100, loss is 3.8488362073898315 and perplexity is 46.93840486353276
At time: 678.1931598186493 and batch: 1150, loss is 3.8233524131774903 and perplexity is 45.75734902179966
At time: 679.2503063678741 and batch: 1200, loss is 3.863028130531311 and perplexity is 47.60930048687658
At time: 680.3052887916565 and batch: 1250, loss is 3.848892025947571 and perplexity is 46.94102497071946
At time: 681.3603851795197 and batch: 1300, loss is 3.8460971689224244 and perplexity is 46.81001468010724
At time: 682.4161996841431 and batch: 1350, loss is 3.7352733039855956 and perplexity is 41.899475291994854
At time: 683.4702496528625 and batch: 1400, loss is 3.7640478134155275 and perplexity is 43.12262551938251
At time: 684.5232472419739 and batch: 1450, loss is 3.668046627044678 and perplexity is 39.175307086295184
At time: 685.5742788314819 and batch: 1500, loss is 3.6804881572723387 and perplexity is 39.66575247274862
At time: 686.6295676231384 and batch: 1550, loss is 3.7006481170654295 and perplexity is 40.473527445170326
At time: 687.6861591339111 and batch: 1600, loss is 3.7953533697128297 and perplexity is 44.49395644448378
At time: 688.7438666820526 and batch: 1650, loss is 3.716601781845093 and perplexity is 41.12440668401675
At time: 689.7969717979431 and batch: 1700, loss is 3.7375273513793945 and perplexity is 41.99402521505026
At time: 690.8499825000763 and batch: 1750, loss is 3.735237536430359 and perplexity is 41.897976676999015
At time: 691.901985168457 and batch: 1800, loss is 3.686460199356079 and perplexity is 39.90334677121845
At time: 692.9555311203003 and batch: 1850, loss is 3.7242094898223876 and perplexity is 41.438462267672236
At time: 694.0172650814056 and batch: 1900, loss is 3.7967186975479126 and perplexity is 44.5547467716299
At time: 695.0754480361938 and batch: 1950, loss is 3.7465748310089113 and perplexity is 42.37568924804449
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486934502180232 and perplexity of 88.84866260251053
finished 16 epochs...
Completing Train Step...
At time: 698.4126708507538 and batch: 50, loss is 3.9249919652938843 and perplexity is 50.652671077877564
At time: 699.5062534809113 and batch: 100, loss is 3.9003623819351194 and perplexity is 49.42035490480982
At time: 700.5634233951569 and batch: 150, loss is 3.8687071084976195 and perplexity is 47.88044182947827
At time: 701.6226403713226 and batch: 200, loss is 3.863202691078186 and perplexity is 47.617611917808766
At time: 702.686475276947 and batch: 250, loss is 3.8671905040740966 and perplexity is 47.80788117641116
At time: 703.7482941150665 and batch: 300, loss is 3.8758505630493163 and perplexity is 48.22369814789138
At time: 704.8004961013794 and batch: 350, loss is 3.8995370292663574 and perplexity is 49.37958251111448
At time: 705.8546462059021 and batch: 400, loss is 3.860935778617859 and perplexity is 47.509789218505645
At time: 706.910450220108 and batch: 450, loss is 3.8937677001953124 and perplexity is 49.09551567567663
At time: 707.9663465023041 and batch: 500, loss is 3.914936671257019 and perplexity is 50.1458957339364
At time: 709.0207741260529 and batch: 550, loss is 3.8778928089141846 and perplexity is 48.322283429449676
At time: 710.0738625526428 and batch: 600, loss is 3.856314172744751 and perplexity is 47.29072430339397
At time: 711.1260287761688 and batch: 650, loss is 3.8824106645584107 and perplexity is 48.541090427426006
At time: 712.1845111846924 and batch: 700, loss is 3.9013585662841797 and perplexity is 49.46961121900221
At time: 713.2414016723633 and batch: 750, loss is 3.8563562345504763 and perplexity is 47.29271347848608
At time: 714.2990462779999 and batch: 800, loss is 3.832996382713318 and perplexity is 46.20076621605755
At time: 715.3518033027649 and batch: 850, loss is 3.8282834672927857 and perplexity is 45.98353820322436
At time: 716.4047040939331 and batch: 900, loss is 3.7917846918106077 and perplexity is 44.33545483415095
At time: 717.4558973312378 and batch: 950, loss is 3.9106199884414674 and perplexity is 49.92989833907594
At time: 718.5077128410339 and batch: 1000, loss is 3.862312521934509 and perplexity is 47.57524304951132
At time: 719.5670084953308 and batch: 1050, loss is 3.822588014602661 and perplexity is 45.72238553414194
At time: 720.6270771026611 and batch: 1100, loss is 3.8476131105422975 and perplexity is 46.881029743332824
At time: 721.6821184158325 and batch: 1150, loss is 3.822179765701294 and perplexity is 45.703723230171505
At time: 722.7336902618408 and batch: 1200, loss is 3.8618130540847777 and perplexity is 47.55148667843059
At time: 723.7873990535736 and batch: 1250, loss is 3.8478341197967527 and perplexity is 46.891392029802915
At time: 724.8500053882599 and batch: 1300, loss is 3.845368242263794 and perplexity is 46.775906045372864
At time: 725.9081616401672 and batch: 1350, loss is 3.7350084400177 and perplexity is 41.88837910027183
At time: 726.968832731247 and batch: 1400, loss is 3.7640790224075316 and perplexity is 43.1239713540585
At time: 728.026976108551 and batch: 1450, loss is 3.6686365461349486 and perplexity is 39.19842416574544
At time: 729.0818622112274 and batch: 1500, loss is 3.681522159576416 and perplexity is 39.706788164041924
At time: 730.1345031261444 and batch: 1550, loss is 3.701885619163513 and perplexity is 40.52364452389979
At time: 731.1897089481354 and batch: 1600, loss is 3.7966990423202516 and perplexity is 44.55387104654504
At time: 732.2390503883362 and batch: 1650, loss is 3.7180643272399903 and perplexity is 41.18459700043627
At time: 733.2885222434998 and batch: 1700, loss is 3.739142351150513 and perplexity is 42.06190035057227
At time: 734.3359611034393 and batch: 1750, loss is 3.7372379398345945 and perplexity is 41.98187341786041
At time: 735.385532617569 and batch: 1800, loss is 3.688493056297302 and perplexity is 39.98454707301552
At time: 736.43541431427 and batch: 1850, loss is 3.7263149499893187 and perplexity is 41.52580121142505
At time: 737.4904992580414 and batch: 1900, loss is 3.7985344457626344 and perplexity is 44.635720465210525
At time: 738.5523192882538 and batch: 1950, loss is 3.7480678033828734 and perplexity is 42.439002231927134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486872899255087 and perplexity of 88.84318943358232
finished 17 epochs...
Completing Train Step...
At time: 741.9154419898987 and batch: 50, loss is 3.9238749408721922 and perplexity is 50.596122396268676
At time: 742.9711601734161 and batch: 100, loss is 3.898607859611511 and perplexity is 49.333721810961144
At time: 744.030366897583 and batch: 150, loss is 3.8664275217056274 and perplexity is 47.77141851795132
At time: 745.0889031887054 and batch: 200, loss is 3.860692925453186 and perplexity is 47.49825271673566
At time: 746.1465065479279 and batch: 250, loss is 3.8644699239730835 and perplexity is 47.67799277222959
At time: 747.2006139755249 and batch: 300, loss is 3.8731293964385984 and perplexity is 48.09265181096799
At time: 748.2564191818237 and batch: 350, loss is 3.896760549545288 and perplexity is 49.24267125525247
At time: 749.3138942718506 and batch: 400, loss is 3.858172721862793 and perplexity is 47.378698163886696
At time: 750.3709781169891 and batch: 450, loss is 3.890942544937134 and perplexity is 48.957008965017764
At time: 751.4282927513123 and batch: 500, loss is 3.9122238111495973 and perplexity is 50.01004129421349
At time: 752.5233402252197 and batch: 550, loss is 3.8752251052856446 and perplexity is 48.193545692018596
At time: 753.5778114795685 and batch: 600, loss is 3.8539484977722167 and perplexity is 47.17898204552085
At time: 754.6318838596344 and batch: 650, loss is 3.880161848068237 and perplexity is 48.43205307127584
At time: 755.6843144893646 and batch: 700, loss is 3.899311842918396 and perplexity is 49.36846415516291
At time: 756.7365448474884 and batch: 750, loss is 3.8543812608718873 and perplexity is 47.199403786599426
At time: 757.7975356578827 and batch: 800, loss is 3.8311614274978636 and perplexity is 46.116067611969505
At time: 758.8601267337799 and batch: 850, loss is 3.826448187828064 and perplexity is 45.899222954533215
At time: 759.9233872890472 and batch: 900, loss is 3.7902331066131594 and perplexity is 44.26671793807324
At time: 760.984302520752 and batch: 950, loss is 3.9092054080963137 and perplexity is 49.859318418503584
At time: 762.0455582141876 and batch: 1000, loss is 3.861047053337097 and perplexity is 47.51507615110751
At time: 763.1066341400146 and batch: 1050, loss is 3.821377921104431 and perplexity is 45.6670906354297
At time: 764.1696572303772 and batch: 1100, loss is 3.8466492557525633 and perplexity is 46.8358650078869
At time: 765.2386612892151 and batch: 1150, loss is 3.821285648345947 and perplexity is 45.66287700140965
At time: 766.3126456737518 and batch: 1200, loss is 3.8609127950668336 and perplexity is 47.50869728738921
At time: 767.3833622932434 and batch: 1250, loss is 3.8471282148361206 and perplexity is 46.858302843842424
At time: 768.452755689621 and batch: 1300, loss is 3.8448674726486205 and perplexity is 46.752487956926075
At time: 769.5138835906982 and batch: 1350, loss is 3.734772844314575 and perplexity is 41.87851154056791
At time: 770.5831055641174 and batch: 1400, loss is 3.764056181907654 and perplexity is 43.12298639224461
At time: 771.651495218277 and batch: 1450, loss is 3.668966031074524 and perplexity is 39.21134158409369
At time: 772.7161860466003 and batch: 1500, loss is 3.682117109298706 and perplexity is 39.73041873543706
At time: 773.781571149826 and batch: 1550, loss is 3.7026288318634033 and perplexity is 40.55377340585279
At time: 774.8429572582245 and batch: 1600, loss is 3.7975430059432984 and perplexity is 44.591488764734265
At time: 775.9143555164337 and batch: 1650, loss is 3.7190174198150636 and perplexity is 41.22386844573344
At time: 776.9776313304901 and batch: 1700, loss is 3.7401776266098024 and perplexity is 42.10546855243004
At time: 778.0390543937683 and batch: 1750, loss is 3.7384743881225586 and perplexity is 42.03381393763959
At time: 779.1072463989258 and batch: 1800, loss is 3.6897029876708984 and perplexity is 40.03295491015315
At time: 780.1732792854309 and batch: 1850, loss is 3.727606053352356 and perplexity is 41.57944993859551
At time: 781.2405807971954 and batch: 1900, loss is 3.799627814292908 and perplexity is 44.68455044701148
At time: 782.3091194629669 and batch: 1950, loss is 3.748974571228027 and perplexity is 42.47750200707256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486860692223837 and perplexity of 88.84210492861189
finished 18 epochs...
Completing Train Step...
At time: 785.6692464351654 and batch: 50, loss is 3.922745385169983 and perplexity is 50.5390035232538
At time: 786.754026889801 and batch: 100, loss is 3.897042999267578 and perplexity is 49.25658179849539
At time: 787.8074550628662 and batch: 150, loss is 3.864604287147522 and perplexity is 47.68439936908503
At time: 788.858913898468 and batch: 200, loss is 3.858704352378845 and perplexity is 47.40389282217265
At time: 789.9152548313141 and batch: 250, loss is 3.86234974861145 and perplexity is 47.57701415068062
At time: 790.9749767780304 and batch: 300, loss is 3.870960669517517 and perplexity is 47.98846499948662
At time: 792.0295839309692 and batch: 350, loss is 3.8945949840545655 and perplexity is 49.1361484084414
At time: 793.0879230499268 and batch: 400, loss is 3.8559845447540284 and perplexity is 47.27513852585741
At time: 794.1393570899963 and batch: 450, loss is 3.888757724761963 and perplexity is 48.85016346571791
At time: 795.1911425590515 and batch: 500, loss is 3.9101224517822266 and perplexity is 49.90506256312691
At time: 796.2436120510101 and batch: 550, loss is 3.8731638050079344 and perplexity is 48.09430663878235
At time: 797.2999639511108 and batch: 600, loss is 3.8520992851257323 and perplexity is 47.09181869190048
At time: 798.3560230731964 and batch: 650, loss is 3.878373107910156 and perplexity is 48.34549814822068
At time: 799.4132561683655 and batch: 700, loss is 3.8976726818084715 and perplexity is 49.287607575247826
At time: 800.4724938869476 and batch: 750, loss is 3.852790470123291 and perplexity is 47.124379101825234
At time: 801.5328307151794 and batch: 800, loss is 3.829678773880005 and perplexity is 46.04774412003553
At time: 802.5912063121796 and batch: 850, loss is 3.824981369972229 and perplexity is 45.83194650794354
At time: 803.6489446163177 and batch: 900, loss is 3.788993229866028 and perplexity is 44.211866675259536
At time: 804.7109227180481 and batch: 950, loss is 3.908056826591492 and perplexity is 49.80208380312758
At time: 805.811488866806 and batch: 1000, loss is 3.8599830293655395 and perplexity is 47.46454585856094
At time: 806.8640534877777 and batch: 1050, loss is 3.8203528356552123 and perplexity is 45.6203019506083
At time: 807.9154131412506 and batch: 1100, loss is 3.845803599357605 and perplexity is 46.79627470138688
At time: 808.9661490917206 and batch: 1150, loss is 3.8205064868927003 and perplexity is 45.62731210500325
At time: 810.0221483707428 and batch: 1200, loss is 3.860147042274475 and perplexity is 47.47233129523711
At time: 811.0777308940887 and batch: 1250, loss is 3.8465261602401735 and perplexity is 46.83010007791132
At time: 812.1327350139618 and batch: 1300, loss is 3.8443923377990723 and perplexity is 46.73027949701909
At time: 813.1842911243439 and batch: 1350, loss is 3.7344773769378663 and perplexity is 41.86613963445987
At time: 814.2351515293121 and batch: 1400, loss is 3.763928689956665 and perplexity is 43.11748890902688
At time: 815.2871451377869 and batch: 1450, loss is 3.669077606201172 and perplexity is 39.21571683857722
At time: 816.338161945343 and batch: 1500, loss is 3.6824083805084227 and perplexity is 39.74199274807119
At time: 817.3999066352844 and batch: 1550, loss is 3.703040375709534 and perplexity is 40.57046649646909
At time: 818.4553644657135 and batch: 1600, loss is 3.798058614730835 and perplexity is 44.6144864565872
At time: 819.5129127502441 and batch: 1650, loss is 3.719641170501709 and perplexity is 41.24958988303079
At time: 820.5653686523438 and batch: 1700, loss is 3.7408605432510376 and perplexity is 42.13423289829882
At time: 821.6176102161407 and batch: 1750, loss is 3.7392877912521363 and perplexity is 42.06801828251927
At time: 822.673764705658 and batch: 1800, loss is 3.6904941749572755 and perplexity is 40.06464100828027
At time: 823.7280550003052 and batch: 1850, loss is 3.7284682178497315 and perplexity is 41.61531372217189
At time: 824.7842466831207 and batch: 1900, loss is 3.8003664445877074 and perplexity is 44.71756800206323
At time: 825.8411328792572 and batch: 1950, loss is 3.7495856857299805 and perplexity is 42.50346855801563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486887661246366 and perplexity of 88.8445009456502
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 829.217652797699 and batch: 50, loss is 3.9222344732284546 and perplexity is 50.51318913784124
At time: 830.2995188236237 and batch: 100, loss is 3.8969524240493776 and perplexity is 49.25212057489239
At time: 831.3555474281311 and batch: 150, loss is 3.8647127676010133 and perplexity is 47.68957247493841
At time: 832.4369926452637 and batch: 200, loss is 3.8588237810134887 and perplexity is 47.40955454244822
At time: 833.4921035766602 and batch: 250, loss is 3.8624440383911134 and perplexity is 47.581500388361775
At time: 834.5412442684174 and batch: 300, loss is 3.870740113258362 and perplexity is 47.97788201027888
At time: 835.5905151367188 and batch: 350, loss is 3.894539113044739 and perplexity is 49.13340319890036
At time: 836.6397361755371 and batch: 400, loss is 3.8565526103973387 and perplexity is 47.30200153709117
At time: 837.6976010799408 and batch: 450, loss is 3.889401841163635 and perplexity is 48.88163879302961
At time: 838.7556576728821 and batch: 500, loss is 3.9106635522842406 and perplexity is 49.93207352469624
At time: 839.8133265972137 and batch: 550, loss is 3.8741012716293337 and perplexity is 48.13941458622953
At time: 840.867730140686 and batch: 600, loss is 3.852605767250061 and perplexity is 47.11567589738411
At time: 841.9228024482727 and batch: 650, loss is 3.878839998245239 and perplexity is 48.36807546420603
At time: 842.9758009910583 and batch: 700, loss is 3.8978839635849 and perplexity is 49.298022248708854
At time: 844.0383591651917 and batch: 750, loss is 3.853258242607117 and perplexity is 47.14642774615896
At time: 845.1068489551544 and batch: 800, loss is 3.8301139068603516 and perplexity is 46.06778537216139
At time: 846.1666584014893 and batch: 850, loss is 3.825117311477661 and perplexity is 45.83817739525722
At time: 847.2285838127136 and batch: 900, loss is 3.78803795337677 and perplexity is 44.169652284896
At time: 848.2874195575714 and batch: 950, loss is 3.906561002731323 and perplexity is 49.727644345926635
At time: 849.343231678009 and batch: 1000, loss is 3.8578515100479125 and perplexity is 47.363482010197814
At time: 850.4028306007385 and batch: 1050, loss is 3.818317847251892 and perplexity is 45.5275595620307
At time: 851.4620037078857 and batch: 1100, loss is 3.843506712913513 and perplexity is 46.68891231919226
At time: 852.5207331180573 and batch: 1150, loss is 3.818372130393982 and perplexity is 45.53003100809373
At time: 853.5777018070221 and batch: 1200, loss is 3.858750605583191 and perplexity is 47.406085454821884
At time: 854.6330389976501 and batch: 1250, loss is 3.8446292018890382 and perplexity is 46.74134953314127
At time: 855.6860473155975 and batch: 1300, loss is 3.842306303977966 and perplexity is 46.63290015712929
At time: 856.7417578697205 and batch: 1350, loss is 3.731794571876526 and perplexity is 41.75397147308228
At time: 857.8040375709534 and batch: 1400, loss is 3.761068720817566 and perplexity is 42.99435039150508
At time: 858.8659629821777 and batch: 1450, loss is 3.6659015130996706 and perplexity is 39.091361657209376
At time: 859.9251620769501 and batch: 1500, loss is 3.678838224411011 and perplexity is 39.60036060520467
At time: 860.9843542575836 and batch: 1550, loss is 3.6997716093063353 and perplexity is 40.43806762699982
At time: 862.0393583774567 and batch: 1600, loss is 3.7948229455947877 and perplexity is 44.47036203495364
At time: 863.1027503013611 and batch: 1650, loss is 3.7162516689300538 and perplexity is 41.110011018314644
At time: 864.1690893173218 and batch: 1700, loss is 3.7372699403762817 and perplexity is 41.983216882046506
At time: 865.2372739315033 and batch: 1750, loss is 3.73550639629364 and perplexity is 41.90924287572661
At time: 866.2915186882019 and batch: 1800, loss is 3.6868697357177735 and perplexity is 39.91969198942672
At time: 867.3451092243195 and batch: 1850, loss is 3.72498019695282 and perplexity is 41.47041149618372
At time: 868.39945936203 and batch: 1900, loss is 3.796486539840698 and perplexity is 44.54440424436904
At time: 869.4555253982544 and batch: 1950, loss is 3.7465451669692995 and perplexity is 42.374432232564224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486786030614099 and perplexity of 88.83547208165798
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc0f4432b38>
ELAPSED
1798.2143001556396


RESULTS SO FAR:
[{'best_accuracy': -94.78310464460193, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.83547208165798, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.24245156315881022, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.32612507610596975, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.5466017702903482, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44410872475199714, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6544017791748047 and batch: 50, loss is 7.269582328796386 and perplexity is 1435.9505725649506
At time: 2.713289499282837 and batch: 100, loss is 6.470612726211548 and perplexity is 645.8793529565307
At time: 3.768958806991577 and batch: 150, loss is 6.229978847503662 and perplexity is 507.7447433133797
At time: 4.820237874984741 and batch: 200, loss is 6.115394344329834 and perplexity is 452.77456125183556
At time: 5.871262550354004 and batch: 250, loss is 6.06165491104126 and perplexity is 429.0849470257244
At time: 6.926825284957886 and batch: 300, loss is 5.985778007507324 and perplexity is 397.7318392647301
At time: 7.982820272445679 and batch: 350, loss is 5.933802328109741 and perplexity is 377.58749932030406
At time: 9.031450510025024 and batch: 400, loss is 5.876996526718139 and perplexity is 356.7361834689122
At time: 10.0778489112854 and batch: 450, loss is 5.802381858825684 and perplexity is 331.08722451209655
At time: 11.170159339904785 and batch: 500, loss is 5.786988658905029 and perplexity is 326.02975783558315
At time: 12.220282077789307 and batch: 550, loss is 5.736027545928955 and perplexity is 309.8311730079845
At time: 13.275226831436157 and batch: 600, loss is 5.773977308273316 and perplexity is 321.815148678047
At time: 14.334656476974487 and batch: 650, loss is 5.860141372680664 and perplexity is 350.77373033731976
At time: 15.389601945877075 and batch: 700, loss is 5.758523845672608 and perplexity is 316.8802193947789
At time: 16.44379997253418 and batch: 750, loss is 5.711093482971191 and perplexity is 302.2013396956267
At time: 17.498079776763916 and batch: 800, loss is 5.701520910263062 and perplexity is 299.32229730505253
At time: 18.552051782608032 and batch: 850, loss is 5.730818376541138 and perplexity is 308.2214063598752
At time: 19.611805200576782 and batch: 900, loss is 5.7421861743927005 and perplexity is 311.7451959173149
At time: 20.667015314102173 and batch: 950, loss is 5.768482961654663 and perplexity is 320.0518332729821
At time: 21.73140597343445 and batch: 1000, loss is 5.745332670211792 and perplexity is 312.7276456993999
At time: 22.794367790222168 and batch: 1050, loss is 5.6451077556610105 and perplexity is 282.90403909213575
At time: 23.856382846832275 and batch: 1100, loss is 5.735714855194092 and perplexity is 309.7343068161827
At time: 24.92155885696411 and batch: 1150, loss is 5.642802572250366 and perplexity is 282.2526444749011
At time: 25.98097586631775 and batch: 1200, loss is 5.7195780563354495 and perplexity is 304.77629739465556
At time: 27.041038513183594 and batch: 1250, loss is 5.663304462432861 and perplexity is 288.09908394209555
At time: 28.104204416275024 and batch: 1300, loss is 5.672747840881348 and perplexity is 290.8325991176213
At time: 29.15872883796692 and batch: 1350, loss is 5.645520334243774 and perplexity is 283.0207833210708
At time: 30.214937210083008 and batch: 1400, loss is 5.6651935958862305 and perplexity is 288.6438559709714
At time: 31.26798701286316 and batch: 1450, loss is 5.621730518341065 and perplexity is 276.3672282130748
At time: 32.331581592559814 and batch: 1500, loss is 5.616396398544311 and perplexity is 274.8969770438895
At time: 33.38531494140625 and batch: 1550, loss is 5.597885494232178 and perplexity is 269.8551933584302
At time: 34.44322347640991 and batch: 1600, loss is 5.613336305618287 and perplexity is 274.05705252801937
At time: 35.508487939834595 and batch: 1650, loss is 5.598206539154052 and perplexity is 269.9418429063539
At time: 36.57442569732666 and batch: 1700, loss is 5.6044089984893795 and perplexity is 271.62134936084294
At time: 37.6329128742218 and batch: 1750, loss is 5.624748048782348 and perplexity is 277.2024342332296
At time: 38.70434904098511 and batch: 1800, loss is 5.618701467514038 and perplexity is 275.5313644079657
At time: 39.77240252494812 and batch: 1850, loss is 5.589832448959351 and perplexity is 267.69076408985353
At time: 40.841591596603394 and batch: 1900, loss is 5.594104442596436 and perplexity is 268.8367834816293
At time: 41.919519901275635 and batch: 1950, loss is 5.53130126953125 and perplexity is 252.47223178298933
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.0681884765625 and perplexity of 158.8862403356322
finished 1 epochs...
Completing Train Step...
At time: 45.313069581985474 and batch: 50, loss is 5.307975978851318 and perplexity is 201.94108144715813
At time: 46.39415216445923 and batch: 100, loss is 5.225374774932861 and perplexity is 185.93083968797177
At time: 47.45143961906433 and batch: 150, loss is 5.1503683376312255 and perplexity is 172.4950150220978
At time: 48.509047746658325 and batch: 200, loss is 5.125176877975464 and perplexity is 168.20389058443408
At time: 49.57443332672119 and batch: 250, loss is 5.134222030639648 and perplexity is 169.73222202910432
At time: 50.63533020019531 and batch: 300, loss is 5.148544092178344 and perplexity is 172.1806286214664
At time: 51.691343784332275 and batch: 350, loss is 5.124939432144165 and perplexity is 168.163956013143
At time: 52.745888471603394 and batch: 400, loss is 5.1021004486083985 and perplexity is 164.36678896314334
At time: 53.80498003959656 and batch: 450, loss is 5.0621881103515625 and perplexity is 157.93571929681096
At time: 54.86143755912781 and batch: 500, loss is 5.053784599304199 and perplexity is 156.6140657777127
At time: 55.91785669326782 and batch: 550, loss is 5.011919574737549 and perplexity is 150.19276585242497
At time: 56.97543716430664 and batch: 600, loss is 5.014484558105469 and perplexity is 150.5785022911087
At time: 58.039392948150635 and batch: 650, loss is 5.080367841720581 and perplexity is 160.83320621226898
At time: 59.10163640975952 and batch: 700, loss is 5.055095453262329 and perplexity is 156.81949856250876
At time: 60.1586811542511 and batch: 750, loss is 5.0118668842315675 and perplexity is 150.18485232808308
At time: 61.216559648513794 and batch: 800, loss is 4.98815110206604 and perplexity is 146.6650040366276
At time: 62.27090549468994 and batch: 850, loss is 4.993181610107422 and perplexity is 147.4046623876483
At time: 63.32438063621521 and batch: 900, loss is 5.01605453491211 and perplexity is 150.8150927194308
At time: 64.38106226921082 and batch: 950, loss is 5.081322059631348 and perplexity is 160.9867493834543
At time: 65.44458484649658 and batch: 1000, loss is 5.04471752166748 and perplexity is 155.20045224078865
At time: 66.51055145263672 and batch: 1050, loss is 4.952693138122559 and perplexity is 141.55568002918548
At time: 67.56581664085388 and batch: 1100, loss is 5.0396417617797855 and perplexity is 154.41468787337348
At time: 68.61992001533508 and batch: 1150, loss is 4.953395099639892 and perplexity is 141.65508155306657
At time: 69.67283535003662 and batch: 1200, loss is 5.028085308074951 and perplexity is 152.64047324196977
At time: 70.73602151870728 and batch: 1250, loss is 4.977305936813354 and perplexity is 145.0829919284468
At time: 71.7948968410492 and batch: 1300, loss is 5.002427110671997 and perplexity is 148.7738117598095
At time: 72.85230469703674 and batch: 1350, loss is 4.9215860843658445 and perplexity is 137.22008330671264
At time: 73.91715145111084 and batch: 1400, loss is 4.936725988388061 and perplexity is 139.3133884323553
At time: 74.97387075424194 and batch: 1450, loss is 4.867274532318115 and perplexity is 129.9662150329823
At time: 76.0267722606659 and batch: 1500, loss is 4.864871587753296 and perplexity is 129.65428834432163
At time: 77.08335185050964 and batch: 1550, loss is 4.859426755905151 and perplexity is 128.95026094062095
At time: 78.14634442329407 and batch: 1600, loss is 4.92501145362854 and perplexity is 137.69091869446314
At time: 79.2034432888031 and batch: 1650, loss is 4.884716186523438 and perplexity is 132.25292484491257
At time: 80.26276683807373 and batch: 1700, loss is 4.90866494178772 and perplexity is 135.45844872109296
At time: 81.3246202468872 and batch: 1750, loss is 4.924004240036011 and perplexity is 137.55230434843145
At time: 82.38675618171692 and batch: 1800, loss is 4.883745203018188 and perplexity is 132.1245717608153
At time: 83.43939113616943 and batch: 1850, loss is 4.890224933624268 and perplexity is 132.9834831442077
At time: 84.49521255493164 and batch: 1900, loss is 4.951308717727661 and perplexity is 141.35984305037204
At time: 85.54665470123291 and batch: 1950, loss is 4.877158803939819 and perplexity is 131.2572061467521
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.752613156340843 and perplexity of 115.88671931579427
finished 2 epochs...
Completing Train Step...
At time: 88.92013382911682 and batch: 50, loss is 4.7951517581939695 and perplexity is 120.92273140599434
At time: 89.97546148300171 and batch: 100, loss is 4.743638916015625 and perplexity is 114.85137670147861
At time: 91.03139638900757 and batch: 150, loss is 4.688916978836059 and perplexity is 108.73535332572587
At time: 92.09460949897766 and batch: 200, loss is 4.68441146850586 and perplexity is 108.2465470557899
At time: 93.14932227134705 and batch: 250, loss is 4.693054409027099 and perplexity is 109.1861702280378
At time: 94.20182800292969 and batch: 300, loss is 4.722262563705445 and perplexity is 112.42232780740487
At time: 95.26169943809509 and batch: 350, loss is 4.720823945999146 and perplexity is 112.26071133607019
At time: 96.319256067276 and batch: 400, loss is 4.695878210067749 and perplexity is 109.49492597638971
At time: 97.36821341514587 and batch: 450, loss is 4.6946959400177 and perplexity is 109.36554989857623
At time: 98.42053532600403 and batch: 500, loss is 4.690860910415649 and perplexity is 108.94693299444577
At time: 99.52048945426941 and batch: 550, loss is 4.656022710800171 and perplexity is 105.21677132096504
At time: 100.57326531410217 and batch: 600, loss is 4.643064517974853 and perplexity is 103.86214780117224
At time: 101.61970734596252 and batch: 650, loss is 4.708300504684448 and perplexity is 110.8635875644504
At time: 102.6668312549591 and batch: 700, loss is 4.716308917999267 and perplexity is 111.75499360506716
At time: 103.71388721466064 and batch: 750, loss is 4.675674648284912 and perplexity is 107.30493576847667
At time: 104.76683950424194 and batch: 800, loss is 4.643365936279297 and perplexity is 103.893458472226
At time: 105.8215594291687 and batch: 850, loss is 4.658134832382202 and perplexity is 105.43923678881903
At time: 106.878657579422 and batch: 900, loss is 4.671854743957519 and perplexity is 106.89582306315046
At time: 107.93937134742737 and batch: 950, loss is 4.746313314437867 and perplexity is 115.15894614041065
At time: 108.99206161499023 and batch: 1000, loss is 4.707737197875977 and perplexity is 110.80115493677677
At time: 110.04333472251892 and batch: 1050, loss is 4.64036192893982 and perplexity is 103.58183006181387
At time: 111.10129809379578 and batch: 1100, loss is 4.708922786712646 and perplexity is 110.93259745215283
At time: 112.16478252410889 and batch: 1150, loss is 4.638827266693116 and perplexity is 103.42298885275196
At time: 113.22144532203674 and batch: 1200, loss is 4.710504179000854 and perplexity is 111.10816418962877
At time: 114.27999997138977 and batch: 1250, loss is 4.680840711593628 and perplexity is 107.86071421725994
At time: 115.33515644073486 and batch: 1300, loss is 4.691651973724365 and perplexity is 109.03315101319428
At time: 116.38731479644775 and batch: 1350, loss is 4.59659140586853 and perplexity is 99.1457912613344
At time: 117.43971753120422 and batch: 1400, loss is 4.613847608566284 and perplexity is 100.87151805444158
At time: 118.49427485466003 and batch: 1450, loss is 4.53463583946228 and perplexity is 93.1895731595324
At time: 119.55139708518982 and batch: 1500, loss is 4.540049352645874 and perplexity is 93.69542412245637
At time: 120.60493111610413 and batch: 1550, loss is 4.549483671188354 and perplexity is 94.58355948810924
At time: 121.66623187065125 and batch: 1600, loss is 4.637587223052979 and perplexity is 103.29481931751361
At time: 122.72002387046814 and batch: 1650, loss is 4.585243091583252 and perplexity is 98.02701378794606
At time: 123.77819681167603 and batch: 1700, loss is 4.620757913589477 and perplexity is 101.57098499387456
At time: 124.83802247047424 and batch: 1750, loss is 4.621726236343384 and perplexity is 101.66938612411873
At time: 125.90281701087952 and batch: 1800, loss is 4.582880487442017 and perplexity is 97.79568813229673
At time: 126.95880937576294 and batch: 1850, loss is 4.609967994689941 and perplexity is 100.48093366148866
At time: 128.02607464790344 and batch: 1900, loss is 4.686075315475464 and perplexity is 108.42680266236643
At time: 129.08075666427612 and batch: 1950, loss is 4.608691596984864 and perplexity is 100.35276184486675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.661099314135174 and perplexity of 105.75227324851221
finished 3 epochs...
Completing Train Step...
At time: 132.4628357887268 and batch: 50, loss is 4.547297534942627 and perplexity is 94.3770127923319
At time: 133.56329250335693 and batch: 100, loss is 4.497878684997558 and perplexity is 89.82637900380338
At time: 134.61630034446716 and batch: 150, loss is 4.449279537200928 and perplexity is 85.56527519215803
At time: 135.66972637176514 and batch: 200, loss is 4.451022882461547 and perplexity is 85.71457511197835
At time: 136.72376894950867 and batch: 250, loss is 4.452028646469116 and perplexity is 85.80082711385877
At time: 137.77974128723145 and batch: 300, loss is 4.484424648284912 and perplexity is 88.6259450517547
At time: 138.8373999595642 and batch: 350, loss is 4.490301094055176 and perplexity is 89.1482838563764
At time: 139.89365482330322 and batch: 400, loss is 4.463803968429565 and perplexity is 86.81713138940758
At time: 140.95265078544617 and batch: 450, loss is 4.476069240570069 and perplexity is 87.88852416294118
At time: 142.00787162780762 and batch: 500, loss is 4.481095762252807 and perplexity is 88.331409890173
At time: 143.0594687461853 and batch: 550, loss is 4.4441248798370365 and perplexity is 85.12535032136738
At time: 144.1159975528717 and batch: 600, loss is 4.430999507904053 and perplexity is 84.01534896325674
At time: 145.17312049865723 and batch: 650, loss is 4.493772916793823 and perplexity is 89.45832879448487
At time: 146.22583413124084 and batch: 700, loss is 4.510689888000488 and perplexity is 90.98456602399216
At time: 147.27637386322021 and batch: 750, loss is 4.470624332427978 and perplexity is 87.41127967739531
At time: 148.3287889957428 and batch: 800, loss is 4.435465860366821 and perplexity is 84.39143035485192
At time: 149.3866946697235 and batch: 850, loss is 4.454134006500244 and perplexity is 85.98165903725854
At time: 150.4435691833496 and batch: 900, loss is 4.457139797210694 and perplexity is 86.24049071130865
At time: 151.49664402008057 and batch: 950, loss is 4.541610565185547 and perplexity is 93.84181683884397
At time: 152.59515953063965 and batch: 1000, loss is 4.506234998703003 and perplexity is 90.58014135698794
At time: 153.65168237686157 and batch: 1050, loss is 4.441737546920776 and perplexity is 84.9223701575549
At time: 154.70822429656982 and batch: 1100, loss is 4.499016618728637 and perplexity is 89.9286536502613
At time: 155.76591658592224 and batch: 1150, loss is 4.441899328231812 and perplexity is 84.93611012133995
At time: 156.8186640739441 and batch: 1200, loss is 4.508256626129151 and perplexity is 90.76344587931426
At time: 157.87017059326172 and batch: 1250, loss is 4.485257091522217 and perplexity is 88.69975183607997
At time: 158.92096662521362 and batch: 1300, loss is 4.494581327438355 and perplexity is 89.53067709935412
At time: 159.97564244270325 and batch: 1350, loss is 4.390341520309448 and perplexity is 80.66796402464954
At time: 161.0321991443634 and batch: 1400, loss is 4.414284372329712 and perplexity is 82.6226926595107
At time: 162.0884358882904 and batch: 1450, loss is 4.334338259696961 and perplexity is 76.27446829601541
At time: 163.13972759246826 and batch: 1500, loss is 4.344484462738037 and perplexity is 77.05230390433015
At time: 164.19198775291443 and batch: 1550, loss is 4.35075852394104 and perplexity is 77.53725448889006
At time: 165.24569821357727 and batch: 1600, loss is 4.446741561889649 and perplexity is 85.3483879798326
At time: 166.301531791687 and batch: 1650, loss is 4.400360012054444 and perplexity is 81.48019723853567
At time: 167.3547556400299 and batch: 1700, loss is 4.427586803436279 and perplexity is 83.72911809496992
At time: 168.40547633171082 and batch: 1750, loss is 4.426820583343506 and perplexity is 83.66498773445834
At time: 169.45183873176575 and batch: 1800, loss is 4.388076543807983 and perplexity is 80.48545974368896
At time: 170.4972050189972 and batch: 1850, loss is 4.428861274719238 and perplexity is 83.83589648006902
At time: 171.55474376678467 and batch: 1900, loss is 4.5100002861022945 and perplexity is 90.92184452347418
At time: 172.61937403678894 and batch: 1950, loss is 4.425475263595581 and perplexity is 83.55250725232095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.62327511809593 and perplexity of 101.82698199825933
finished 4 epochs...
Completing Train Step...
At time: 176.13291430473328 and batch: 50, loss is 4.376469402313233 and perplexity is 79.55665443927651
At time: 177.24734354019165 and batch: 100, loss is 4.328756647109985 and perplexity is 75.84991969881895
At time: 178.30929350852966 and batch: 150, loss is 4.289476566314697 and perplexity is 72.92828538615818
At time: 179.41345739364624 and batch: 200, loss is 4.2902384376525875 and perplexity is 72.98386852742792
At time: 180.4694700241089 and batch: 250, loss is 4.2855321979522705 and perplexity is 72.64119593005132
At time: 181.53131914138794 and batch: 300, loss is 4.31723032951355 and perplexity is 74.98066869005144
At time: 182.59097504615784 and batch: 350, loss is 4.328657751083374 and perplexity is 75.8424188140519
At time: 183.6474792957306 and batch: 400, loss is 4.297013425827027 and perplexity is 73.48001215947889
At time: 184.70347714424133 and batch: 450, loss is 4.316321382522583 and perplexity is 74.91254620142058
At time: 185.7702419757843 and batch: 500, loss is 4.327941808700562 and perplexity is 75.78813944477692
At time: 186.83449578285217 and batch: 550, loss is 4.291602020263672 and perplexity is 73.08345594384551
At time: 187.89611864089966 and batch: 600, loss is 4.2741359519958495 and perplexity is 71.81805824312366
At time: 188.95238828659058 and batch: 650, loss is 4.337135877609253 and perplexity is 76.48815388071013
At time: 190.0069146156311 and batch: 700, loss is 4.360805187225342 and perplexity is 78.32017144290941
At time: 191.06403756141663 and batch: 750, loss is 4.320400447845459 and perplexity is 75.21874344559737
At time: 192.12194442749023 and batch: 800, loss is 4.280420641899109 and perplexity is 72.27083375519629
At time: 193.18111944198608 and batch: 850, loss is 4.301375160217285 and perplexity is 73.80121244144067
At time: 194.2412669658661 and batch: 900, loss is 4.303547697067261 and perplexity is 73.96172258901493
At time: 195.29772305488586 and batch: 950, loss is 4.3896402072906495 and perplexity is 80.61141036450606
At time: 196.35415720939636 and batch: 1000, loss is 4.356957874298096 and perplexity is 78.01942813262787
At time: 197.41358518600464 and batch: 1050, loss is 4.2970881748199465 and perplexity is 73.4855049216742
At time: 198.47355580329895 and batch: 1100, loss is 4.34740439414978 and perplexity is 77.27762014073859
At time: 199.53275060653687 and batch: 1150, loss is 4.294698257446289 and perplexity is 73.31009033342892
At time: 200.59243297576904 and batch: 1200, loss is 4.359829502105713 and perplexity is 78.24379288383668
At time: 201.65430164337158 and batch: 1250, loss is 4.343047046661377 and perplexity is 76.94162724721389
At time: 202.7192404270172 and batch: 1300, loss is 4.348224306106568 and perplexity is 77.34100696774172
At time: 203.77683568000793 and batch: 1350, loss is 4.238476014137268 and perplexity is 69.30215581387101
At time: 204.83654689788818 and batch: 1400, loss is 4.264989528656006 and perplexity is 71.16417478493919
At time: 205.90440702438354 and batch: 1450, loss is 4.183570218086243 and perplexity is 65.59964065311891
At time: 206.96480345726013 and batch: 1500, loss is 4.196476979255676 and perplexity is 66.45180707227797
At time: 208.02275276184082 and batch: 1550, loss is 4.2104742002487185 and perplexity is 67.38848787233822
At time: 209.08361649513245 and batch: 1600, loss is 4.308682775497436 and perplexity is 74.34249865610053
At time: 210.1466031074524 and batch: 1650, loss is 4.253999052047729 and perplexity is 70.38632886500092
At time: 211.20802807807922 and batch: 1700, loss is 4.284883575439453 and perplexity is 72.59409449219095
At time: 212.26736617088318 and batch: 1750, loss is 4.285685625076294 and perplexity is 72.65234191485482
At time: 213.32188487052917 and batch: 1800, loss is 4.243276996612549 and perplexity is 69.63567421681923
At time: 214.37698936462402 and batch: 1850, loss is 4.283278455734253 and perplexity is 72.47766574667456
At time: 215.4359200000763 and batch: 1900, loss is 4.367467975616455 and perplexity is 78.84374446320759
At time: 216.50203919410706 and batch: 1950, loss is 4.287741489410401 and perplexity is 72.8018589140578
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6084509561228195 and perplexity of 100.32861577512993
finished 5 epochs...
Completing Train Step...
At time: 219.88982486724854 and batch: 50, loss is 4.240518465042114 and perplexity is 69.4438467138177
At time: 220.93877053260803 and batch: 100, loss is 4.198638219833374 and perplexity is 66.59558072294439
At time: 222.0057089328766 and batch: 150, loss is 4.160711617469787 and perplexity is 64.11713324147452
At time: 223.06036520004272 and batch: 200, loss is 4.160776619911194 and perplexity is 64.12130114713175
At time: 224.11219143867493 and batch: 250, loss is 4.157021861076355 and perplexity is 63.88099255787428
At time: 225.1623079776764 and batch: 300, loss is 4.189262590408325 and perplexity is 65.97412306737749
At time: 226.21858191490173 and batch: 350, loss is 4.196322841644287 and perplexity is 66.44156513881721
At time: 227.26994919776917 and batch: 400, loss is 4.164176301956177 and perplexity is 64.33966415542491
At time: 228.3230516910553 and batch: 450, loss is 4.192499656677246 and perplexity is 66.18803170721331
At time: 229.37598204612732 and batch: 500, loss is 4.208573527336121 and perplexity is 67.26052604413115
At time: 230.4249460697174 and batch: 550, loss is 4.169566469192505 and perplexity is 64.68740204591575
At time: 231.4746232032776 and batch: 600, loss is 4.155802931785583 and perplexity is 63.80317358247136
At time: 232.57217478752136 and batch: 650, loss is 4.217225551605225 and perplexity is 67.84499050219651
At time: 233.62462282180786 and batch: 700, loss is 4.235298495292664 and perplexity is 69.08229639650818
At time: 234.68217825889587 and batch: 750, loss is 4.198600707054138 and perplexity is 66.593082584483
At time: 235.7434582710266 and batch: 800, loss is 4.161082563400268 and perplexity is 64.14092164295712
At time: 236.80301427841187 and batch: 850, loss is 4.1806449127197265 and perplexity is 65.408022080341
At time: 237.85738706588745 and batch: 900, loss is 4.181842966079712 and perplexity is 65.48643134082472
At time: 238.90924620628357 and batch: 950, loss is 4.267839102745056 and perplexity is 71.36725157724122
At time: 239.95881938934326 and batch: 1000, loss is 4.234127793312073 and perplexity is 69.00146893695796
At time: 241.01017999649048 and batch: 1050, loss is 4.182270774841308 and perplexity is 65.51445300344703
At time: 242.07328128814697 and batch: 1100, loss is 4.224288296699524 and perplexity is 68.32585850118791
At time: 243.12702322006226 and batch: 1150, loss is 4.174306645393371 and perplexity is 64.99475961860713
At time: 244.17917108535767 and batch: 1200, loss is 4.239293909072876 and perplexity is 69.35886088237099
At time: 245.23637652397156 and batch: 1250, loss is 4.22341028213501 and perplexity is 68.26589373111396
At time: 246.28796815872192 and batch: 1300, loss is 4.226061453819275 and perplexity is 68.44711845835961
At time: 247.33747005462646 and batch: 1350, loss is 4.118031702041626 and perplexity is 61.43819450167277
At time: 248.3861792087555 and batch: 1400, loss is 4.1462510251998905 and perplexity is 63.19663304946493
At time: 249.43998050689697 and batch: 1450, loss is 4.066738557815552 and perplexity is 58.366293540957294
At time: 250.49400186538696 and batch: 1500, loss is 4.082528314590454 and perplexity is 59.29519740368287
At time: 251.54309511184692 and batch: 1550, loss is 4.095788569450378 and perplexity is 60.0867030185236
At time: 252.58641266822815 and batch: 1600, loss is 4.200152306556702 and perplexity is 66.69648857989533
At time: 253.63000345230103 and batch: 1650, loss is 4.139256997108459 and perplexity is 62.75617610222774
At time: 254.67375111579895 and batch: 1700, loss is 4.167713894844055 and perplexity is 64.56767476030899
At time: 255.7270040512085 and batch: 1750, loss is 4.170173959732056 and perplexity is 64.72671096937742
At time: 256.7859380245209 and batch: 1800, loss is 4.127155828475952 and perplexity is 62.00132950696789
At time: 257.8449354171753 and batch: 1850, loss is 4.165970783233643 and perplexity is 64.45522413224754
At time: 258.89752197265625 and batch: 1900, loss is 4.253447346687317 and perplexity is 70.34750706014998
At time: 259.9461181163788 and batch: 1950, loss is 4.177206373214721 and perplexity is 65.1835002472903
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.607346645621366 and perplexity of 100.21788298407839
finished 6 epochs...
Completing Train Step...
At time: 263.3000156879425 and batch: 50, loss is 4.132985525131225 and perplexity is 62.363834069381156
At time: 264.37909054756165 and batch: 100, loss is 4.091644887924194 and perplexity is 59.838237992739
At time: 265.439067363739 and batch: 150, loss is 4.057119064331054 and perplexity is 57.807531174730016
At time: 266.49570059776306 and batch: 200, loss is 4.0569178581237795 and perplexity is 57.795901110690195
At time: 267.5511100292206 and batch: 250, loss is 4.048997669219971 and perplexity is 57.33995463058855
At time: 268.60386776924133 and batch: 300, loss is 4.081498351097107 and perplexity is 59.23415695513917
At time: 269.6603579521179 and batch: 350, loss is 4.086768360137939 and perplexity is 59.54714549966305
At time: 270.71702694892883 and batch: 400, loss is 4.052084884643555 and perplexity is 57.517248954983586
At time: 271.78019642829895 and batch: 450, loss is 4.085666251182556 and perplexity is 59.48155420835433
At time: 272.8433041572571 and batch: 500, loss is 4.106534996032715 and perplexity is 60.735902400074856
At time: 273.8989839553833 and batch: 550, loss is 4.0691472434997555 and perplexity is 58.50704904648244
At time: 274.9506983757019 and batch: 600, loss is 4.058288769721985 and perplexity is 57.87518851744662
At time: 276.0029602050781 and batch: 650, loss is 4.114709706306457 and perplexity is 61.234435711861416
At time: 277.0580759048462 and batch: 700, loss is 4.134402766227722 and perplexity is 62.45228131869328
At time: 278.1118447780609 and batch: 750, loss is 4.100806021690369 and perplexity is 60.388942783902245
At time: 279.1724977493286 and batch: 800, loss is 4.057932715415955 and perplexity is 57.85458547548125
At time: 280.2292630672455 and batch: 850, loss is 4.07678258895874 and perplexity is 58.95548036317623
At time: 281.28985691070557 and batch: 900, loss is 4.074784455299377 and perplexity is 58.837797046111724
At time: 282.3460955619812 and batch: 950, loss is 4.167463369369507 and perplexity is 64.55150093901094
At time: 283.39873600006104 and batch: 1000, loss is 4.131097326278686 and perplexity is 62.246189852242345
At time: 284.4505522251129 and batch: 1050, loss is 4.081597075462342 and perplexity is 59.24000509835715
At time: 285.5328588485718 and batch: 1100, loss is 4.121338768005371 and perplexity is 61.6417109993415
At time: 286.5886092185974 and batch: 1150, loss is 4.078098149299621 and perplexity is 59.03309089449477
At time: 287.6438899040222 and batch: 1200, loss is 4.139223356246948 and perplexity is 62.75406496590891
At time: 288.69964146614075 and batch: 1250, loss is 4.12368390083313 and perplexity is 61.78643863580169
At time: 289.75597953796387 and batch: 1300, loss is 4.126407866477966 and perplexity is 61.95497220758242
At time: 290.8087751865387 and batch: 1350, loss is 4.014153833389282 and perplexity is 55.3764178963556
At time: 291.86914253234863 and batch: 1400, loss is 4.046988506317138 and perplexity is 57.22486497654191
At time: 292.9271993637085 and batch: 1450, loss is 3.9664660501480102 and perplexity is 52.79761663200364
At time: 293.97863578796387 and batch: 1500, loss is 3.9895030212402345 and perplexity is 54.0280319057973
At time: 295.02967858314514 and batch: 1550, loss is 3.992946162223816 and perplexity is 54.214378661692145
At time: 296.08082914352417 and batch: 1600, loss is 4.100735764503479 and perplexity is 60.38470017570161
At time: 297.1374258995056 and batch: 1650, loss is 4.042524423599243 and perplexity is 56.96997778779664
At time: 298.19229555130005 and batch: 1700, loss is 4.072896347045899 and perplexity is 58.726809726901244
At time: 299.2482635974884 and batch: 1750, loss is 4.0703779888153075 and perplexity is 58.57910065251656
At time: 300.30384850502014 and batch: 1800, loss is 4.028935279846191 and perplexity is 56.20104099923704
At time: 301.36101055145264 and batch: 1850, loss is 4.069795947074891 and perplexity is 58.545015091392635
At time: 302.4211905002594 and batch: 1900, loss is 4.154421286582947 and perplexity is 63.71508110406687
At time: 303.47348141670227 and batch: 1950, loss is 4.082307381629944 and perplexity is 59.282098587209866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.613243209484011 and perplexity of 100.81056982188525
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 306.81514835357666 and batch: 50, loss is 4.066884894371032 and perplexity is 58.374835288279925
At time: 307.90885972976685 and batch: 100, loss is 4.045764164924622 and perplexity is 57.15484507854638
At time: 308.96683406829834 and batch: 150, loss is 4.022893915176391 and perplexity is 55.86253356872603
At time: 310.0286235809326 and batch: 200, loss is 4.021507616043091 and perplexity is 55.785145041074074
At time: 311.09882831573486 and batch: 250, loss is 4.010507550239563 and perplexity is 55.17486747514804
At time: 312.19031167030334 and batch: 300, loss is 4.035962061882019 and perplexity is 56.59734420199504
At time: 313.25167632102966 and batch: 350, loss is 4.0473243474960325 and perplexity is 57.24408667019516
At time: 314.3114593029022 and batch: 400, loss is 3.996795320510864 and perplexity is 54.42346052303792
At time: 315.37605118751526 and batch: 450, loss is 4.026557741165161 and perplexity is 56.06757956807268
At time: 316.44052290916443 and batch: 500, loss is 4.041187024116516 and perplexity is 56.89383709558245
At time: 317.5036418437958 and batch: 550, loss is 3.998776049613953 and perplexity is 54.5313654851576
At time: 318.5621249675751 and batch: 600, loss is 3.9787282085418703 and perplexity is 53.44901498281155
At time: 319.6219720840454 and batch: 650, loss is 4.0182486391067505 and perplexity is 55.6036384635172
At time: 320.6856026649475 and batch: 700, loss is 4.028799953460694 and perplexity is 56.19343603008551
At time: 321.75596809387207 and batch: 750, loss is 3.978297805786133 and perplexity is 53.42601532938366
At time: 322.81561255455017 and batch: 800, loss is 3.940397562980652 and perplexity is 51.439047496977
At time: 323.87430238723755 and batch: 850, loss is 3.9591181898117065 and perplexity is 52.41108893375822
At time: 324.93170833587646 and batch: 900, loss is 3.9477513027191162 and perplexity is 51.81871112749135
At time: 325.99056029319763 and batch: 950, loss is 4.030985107421875 and perplexity is 56.316361596149775
At time: 327.0485329627991 and batch: 1000, loss is 3.9810405158996582 and perplexity is 53.57274853329123
At time: 328.10731840133667 and batch: 1050, loss is 3.9301448822021485 and perplexity is 50.914353718547105
At time: 329.16594982147217 and batch: 1100, loss is 3.962998933792114 and perplexity is 52.614878122720356
At time: 330.21882605552673 and batch: 1150, loss is 3.9103218650817873 and perplexity is 49.91501528863734
At time: 331.271737575531 and batch: 1200, loss is 3.966304535865784 and perplexity is 52.78908975147509
At time: 332.3247141838074 and batch: 1250, loss is 3.9439793014526368 and perplexity is 51.62361905857064
At time: 333.38517355918884 and batch: 1300, loss is 3.9350154495239256 and perplexity is 51.16294039362313
At time: 334.4481472969055 and batch: 1350, loss is 3.821620044708252 and perplexity is 45.67814905468851
At time: 335.5099573135376 and batch: 1400, loss is 3.840683856010437 and perplexity is 46.55730204663304
At time: 336.56942987442017 and batch: 1450, loss is 3.7501273918151856 and perplexity is 42.52649918292748
At time: 337.6283450126648 and batch: 1500, loss is 3.7719921350479124 and perplexity is 43.466569919687814
At time: 338.68804025650024 and batch: 1550, loss is 3.7681748914718627 and perplexity is 43.300963715590434
At time: 339.75152230262756 and batch: 1600, loss is 3.8685191679000854 and perplexity is 47.871443996186215
At time: 340.8142023086548 and batch: 1650, loss is 3.7937303829193114 and perplexity is 44.421801909550084
At time: 341.8779442310333 and batch: 1700, loss is 3.81794979095459 and perplexity is 45.51080594036019
At time: 342.93657207489014 and batch: 1750, loss is 3.8027680492401124 and perplexity is 44.82509098358749
At time: 343.9964771270752 and batch: 1800, loss is 3.7511406564712524 and perplexity is 42.569611619961485
At time: 345.0570101737976 and batch: 1850, loss is 3.777385368347168 and perplexity is 43.701628565278824
At time: 346.1199927330017 and batch: 1900, loss is 3.8569452428817748 and perplexity is 47.32057748599532
At time: 347.1825888156891 and batch: 1950, loss is 3.785223708152771 and perplexity is 44.04552279923882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5177967160247094 and perplexity of 91.63348081928305
finished 8 epochs...
Completing Train Step...
At time: 350.53910779953003 and batch: 50, loss is 3.964503860473633 and perplexity is 52.694119267753344
At time: 351.59087896347046 and batch: 100, loss is 3.930561637878418 and perplexity is 50.93557698661444
At time: 352.64766240119934 and batch: 150, loss is 3.906109805107117 and perplexity is 49.7052124119386
At time: 353.70398783683777 and batch: 200, loss is 3.9034616422653197 and perplexity is 49.57375904716465
At time: 354.76245856285095 and batch: 250, loss is 3.891954569816589 and perplexity is 49.00657975531976
At time: 355.8235731124878 and batch: 300, loss is 3.9169584560394286 and perplexity is 50.24738250046178
At time: 356.8828682899475 and batch: 350, loss is 3.9317189264297485 and perplexity is 50.994558269315185
At time: 357.9376609325409 and batch: 400, loss is 3.88596622467041 and perplexity is 48.713988384734876
At time: 358.99342346191406 and batch: 450, loss is 3.921523289680481 and perplexity is 50.47727776007486
At time: 360.0492889881134 and batch: 500, loss is 3.9404311037063597 and perplexity is 51.440772828894055
At time: 361.10838890075684 and batch: 550, loss is 3.9004056215286256 and perplexity is 49.422491867067194
At time: 362.1738727092743 and batch: 600, loss is 3.8854765033721925 and perplexity is 48.69013794761193
At time: 363.2297475337982 and batch: 650, loss is 3.925921049118042 and perplexity is 50.69975352360897
At time: 364.28880548477173 and batch: 700, loss is 3.942170720100403 and perplexity is 51.53033792249472
At time: 365.38365840911865 and batch: 750, loss is 3.8968046522140503 and perplexity is 49.244843036362134
At time: 366.43792510032654 and batch: 800, loss is 3.8595324325561524 and perplexity is 47.44316330345541
At time: 367.49087023735046 and batch: 850, loss is 3.88057562828064 and perplexity is 48.452097443179014
At time: 368.5424134731293 and batch: 900, loss is 3.8715081214904785 and perplexity is 48.01474357180179
At time: 369.5973081588745 and batch: 950, loss is 3.956907753944397 and perplexity is 52.295365529634836
At time: 370.6592400074005 and batch: 1000, loss is 3.910446882247925 and perplexity is 49.921255912480866
At time: 371.72287487983704 and batch: 1050, loss is 3.8647856760025023 and perplexity is 47.69304957218851
At time: 372.7896592617035 and batch: 1100, loss is 3.897696475982666 and perplexity is 49.288780347120614
At time: 373.84764981269836 and batch: 1150, loss is 3.848903694152832 and perplexity is 46.941572691429435
At time: 374.9115221500397 and batch: 1200, loss is 3.9070202684402466 and perplexity is 49.75048779296469
At time: 375.96490025520325 and batch: 1250, loss is 3.8903514337539673 and perplexity is 48.928078480932875
At time: 377.0249671936035 and batch: 1300, loss is 3.8868988132476807 and perplexity is 48.759439684242984
At time: 378.0898907184601 and batch: 1350, loss is 3.7734577369689943 and perplexity is 43.5303213137363
At time: 379.15190625190735 and batch: 1400, loss is 3.796308660507202 and perplexity is 44.53648142010531
At time: 380.2101573944092 and batch: 1450, loss is 3.708560380935669 and perplexity is 40.79503492277482
At time: 381.2623951435089 and batch: 1500, loss is 3.7330569934844973 and perplexity is 41.80671587471975
At time: 382.323194026947 and batch: 1550, loss is 3.7330995416641235 and perplexity is 41.80849471221925
At time: 383.37935614585876 and batch: 1600, loss is 3.8372617864608767 and perplexity is 46.39825201633605
At time: 384.4436602592468 and batch: 1650, loss is 3.765783658027649 and perplexity is 43.19754470176848
At time: 385.4987761974335 and batch: 1700, loss is 3.795524559020996 and perplexity is 44.50157398610733
At time: 386.5539186000824 and batch: 1750, loss is 3.7863198375701903 and perplexity is 44.09382886249653
At time: 387.6091892719269 and batch: 1800, loss is 3.7379004764556885 and perplexity is 42.00969716252899
At time: 388.665589094162 and batch: 1850, loss is 3.768208885192871 and perplexity is 43.30243570148937
At time: 389.7227463722229 and batch: 1900, loss is 3.8504011011123658 and perplexity is 47.01191598219181
At time: 390.777628660202 and batch: 1950, loss is 3.782321448326111 and perplexity is 43.917876568735956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.517540936137355 and perplexity of 91.6100458151103
finished 9 epochs...
Completing Train Step...
At time: 394.10456562042236 and batch: 50, loss is 3.9133735418319704 and perplexity is 50.06757243944018
At time: 395.18545484542847 and batch: 100, loss is 3.8766048765182495 and perplexity is 48.26008765574862
At time: 396.24325037002563 and batch: 150, loss is 3.8516153955459593 and perplexity is 47.06903696390783
At time: 397.29722023010254 and batch: 200, loss is 3.848895010948181 and perplexity is 46.94116508991677
At time: 398.349041223526 and batch: 250, loss is 3.8382445907592775 and perplexity is 46.44387483333404
At time: 399.40445828437805 and batch: 300, loss is 3.8634765672683717 and perplexity is 47.63065503396451
At time: 400.4574820995331 and batch: 350, loss is 3.8784369659423827 and perplexity is 48.34858549517433
At time: 401.50897336006165 and batch: 400, loss is 3.8327007722854614 and perplexity is 46.18711080622933
At time: 402.5640797615051 and batch: 450, loss is 3.8709823751449584 and perplexity is 47.98950663053395
At time: 403.6254200935364 and batch: 500, loss is 3.8933928489685057 and perplexity is 49.077115610253905
At time: 404.6718454360962 and batch: 550, loss is 3.8519540786743165 and perplexity is 47.08498115245694
At time: 405.71797800064087 and batch: 600, loss is 3.839163737297058 and perplexity is 46.48658318469809
At time: 406.7664921283722 and batch: 650, loss is 3.8798422241210937 and perplexity is 48.41657550093776
At time: 407.82308745384216 and batch: 700, loss is 3.897371311187744 and perplexity is 49.2727559763889
At time: 408.87906527519226 and batch: 750, loss is 3.853059391975403 and perplexity is 47.13705358127877
At time: 409.93333530426025 and batch: 800, loss is 3.816453046798706 and perplexity is 45.442738859749184
At time: 410.9852457046509 and batch: 850, loss is 3.8380755233764647 and perplexity is 46.43602335270163
At time: 412.03849720954895 and batch: 900, loss is 3.829661259651184 and perplexity is 46.046937636370814
At time: 413.0889983177185 and batch: 950, loss is 3.9160016632080077 and perplexity is 50.19932915730068
At time: 414.1426594257355 and batch: 1000, loss is 3.871097135543823 and perplexity is 47.99501424147797
At time: 415.19749641418457 and batch: 1050, loss is 3.827158236503601 and perplexity is 45.93182521022475
At time: 416.262047290802 and batch: 1100, loss is 3.860015325546265 and perplexity is 47.466078806866086
At time: 417.317085981369 and batch: 1150, loss is 3.8129728507995604 and perplexity is 45.28486409868031
At time: 418.36984491348267 and batch: 1200, loss is 3.870811815261841 and perplexity is 47.98132224387604
At time: 419.4519600868225 and batch: 1250, loss is 3.857311897277832 and perplexity is 47.3379309649248
At time: 420.5027210712433 and batch: 1300, loss is 3.8553718852996828 and perplexity is 47.24618383587201
At time: 421.554808139801 and batch: 1350, loss is 3.7413461112976076 and perplexity is 42.15469690339239
At time: 422.60772824287415 and batch: 1400, loss is 3.767462873458862 and perplexity is 43.27014362297727
At time: 423.66427087783813 and batch: 1450, loss is 3.6799866199493407 and perplexity is 39.6458636053603
At time: 424.7200617790222 and batch: 1500, loss is 3.7047571611404417 and perplexity is 40.64017710423145
At time: 425.7740421295166 and batch: 1550, loss is 3.7057529640197755 and perplexity is 40.680666866173354
At time: 426.82670402526855 and batch: 1600, loss is 3.812047266960144 and perplexity is 45.24296855221179
At time: 427.88029646873474 and batch: 1650, loss is 3.7413340044021606 and perplexity is 42.154186543973815
At time: 428.9428126811981 and batch: 1700, loss is 3.7734336757659914 and perplexity is 43.52927393443904
At time: 429.9999418258667 and batch: 1750, loss is 3.7671113061904906 and perplexity is 43.25493393055336
At time: 431.05240631103516 and batch: 1800, loss is 3.7192362260818483 and perplexity is 41.232889473383175
At time: 432.10606718063354 and batch: 1850, loss is 3.7509886169433595 and perplexity is 42.56313984830322
At time: 433.1643772125244 and batch: 1900, loss is 3.8335784673690796 and perplexity is 46.22766680160584
At time: 434.21856451034546 and batch: 1950, loss is 3.7669890117645264 and perplexity is 43.24964441668383
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5210920466933135 and perplexity of 91.93594151920121
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 437.5416376590729 and batch: 50, loss is 3.89202618598938 and perplexity is 49.010089544680746
At time: 438.6224229335785 and batch: 100, loss is 3.877511510848999 and perplexity is 48.3038617485715
At time: 439.6747283935547 and batch: 150, loss is 3.8586968564987183 and perplexity is 47.40353748960627
At time: 440.7349593639374 and batch: 200, loss is 3.8630287504196166 and perplexity is 47.609329999334335
At time: 441.7914459705353 and batch: 250, loss is 3.8543722581863404 and perplexity is 47.19897886712185
At time: 442.84497904777527 and batch: 300, loss is 3.8783126735687254 and perplexity is 48.34257650816353
At time: 443.8965582847595 and batch: 350, loss is 3.8947032785415647 and perplexity is 49.14146987056372
At time: 444.94892835617065 and batch: 400, loss is 3.8484542417526244 and perplexity is 46.92047942947744
At time: 446.02856612205505 and batch: 450, loss is 3.8869719219207766 and perplexity is 48.763004552489
At time: 447.08338165283203 and batch: 500, loss is 3.9090276670455935 and perplexity is 49.850457158387854
At time: 448.1384823322296 and batch: 550, loss is 3.867078218460083 and perplexity is 47.802513340489604
At time: 449.19177174568176 and batch: 600, loss is 3.8457218551635743 and perplexity is 46.79244953397252
At time: 450.24281454086304 and batch: 650, loss is 3.8761993503570555 and perplexity is 48.240520895347466
At time: 451.29350090026855 and batch: 700, loss is 3.8921006298065186 and perplexity is 49.013738178632195
At time: 452.34614777565 and batch: 750, loss is 3.84381676197052 and perplexity is 46.703390416773765
At time: 453.3999056816101 and batch: 800, loss is 3.803722133636475 and perplexity is 44.86787831157576
At time: 454.455335855484 and batch: 850, loss is 3.8224019050598144 and perplexity is 45.7138769536609
At time: 455.5140781402588 and batch: 900, loss is 3.8080747652053835 and perplexity is 45.06359729245428
At time: 456.56774616241455 and batch: 950, loss is 3.8995675945281985 and perplexity is 49.38109183404984
At time: 457.62537956237793 and batch: 1000, loss is 3.8496661138534547 and perplexity is 46.9773755178834
At time: 458.6824240684509 and batch: 1050, loss is 3.806091513633728 and perplexity is 44.974313407766815
At time: 459.7394871711731 and batch: 1100, loss is 3.82630663394928 and perplexity is 45.89272620132199
At time: 460.80309200286865 and batch: 1150, loss is 3.7818024349212647 and perplexity is 43.8950885162483
At time: 461.86145639419556 and batch: 1200, loss is 3.8348311614990234 and perplexity is 46.28561221481117
At time: 462.92082166671753 and batch: 1250, loss is 3.8176347398757935 and perplexity is 45.496469970251795
At time: 463.9736256599426 and batch: 1300, loss is 3.8139535999298095 and perplexity is 45.32929897593044
At time: 465.03097772598267 and batch: 1350, loss is 3.695170769691467 and perplexity is 40.252445898845295
At time: 466.083886384964 and batch: 1400, loss is 3.7187405729293825 and perplexity is 41.212457325777905
At time: 467.1373817920685 and batch: 1450, loss is 3.6250547790527343 and perplexity is 37.526778784691885
At time: 468.18867659568787 and batch: 1500, loss is 3.644018177986145 and perplexity is 38.245204428191364
At time: 469.24083375930786 and batch: 1550, loss is 3.6467284059524534 and perplexity is 38.348998239721844
At time: 470.29521584510803 and batch: 1600, loss is 3.7439096450805662 and perplexity is 42.26290052557822
At time: 471.3520426750183 and batch: 1650, loss is 3.6705873012542725 and perplexity is 39.27496532461218
At time: 472.4076027870178 and batch: 1700, loss is 3.696184344291687 and perplexity is 40.29326543893499
At time: 473.4682674407959 and batch: 1750, loss is 3.687908344268799 and perplexity is 39.96117446117722
At time: 474.5209798812866 and batch: 1800, loss is 3.638948230743408 and perplexity is 38.05179396416806
At time: 475.57206082344055 and batch: 1850, loss is 3.6659852504730224 and perplexity is 39.094635202212416
At time: 476.6303825378418 and batch: 1900, loss is 3.7464652347564695 and perplexity is 42.37104528579334
At time: 477.69190526008606 and batch: 1950, loss is 3.686646513938904 and perplexity is 39.91078203925337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495201785065407 and perplexity of 89.58624432758822
finished 11 epochs...
Completing Train Step...
At time: 481.0590581893921 and batch: 50, loss is 3.875556716918945 and perplexity is 48.209529882545354
At time: 482.12216448783875 and batch: 100, loss is 3.8491673851013184 and perplexity is 46.95395239139156
At time: 483.17898058891296 and batch: 150, loss is 3.8225369310379027 and perplexity is 45.720049931355575
At time: 484.2316663265228 and batch: 200, loss is 3.8222379302978515 and perplexity is 45.70638164610645
At time: 485.2902009487152 and batch: 250, loss is 3.8121827363967897 and perplexity is 45.24909800684125
At time: 486.3414304256439 and batch: 300, loss is 3.833323302268982 and perplexity is 46.215872619174995
At time: 487.3950164318085 and batch: 350, loss is 3.851739330291748 and perplexity is 47.074870814539395
At time: 488.45942997932434 and batch: 400, loss is 3.8059976291656494 and perplexity is 44.97009121647752
At time: 489.51687121391296 and batch: 450, loss is 3.845236291885376 and perplexity is 46.769734354056794
At time: 490.5728073120117 and batch: 500, loss is 3.8679127502441406 and perplexity is 47.84242270773158
At time: 491.6292793750763 and batch: 550, loss is 3.8275866222381594 and perplexity is 45.95150596408316
At time: 492.68710684776306 and batch: 600, loss is 3.8090437412261964 and perplexity is 45.107283999910045
At time: 493.74667406082153 and batch: 650, loss is 3.841227355003357 and perplexity is 46.582612770961994
At time: 494.80490922927856 and batch: 700, loss is 3.8592843580245972 and perplexity is 47.43139532267192
At time: 495.86119771003723 and batch: 750, loss is 3.81342689037323 and perplexity is 45.30542988755707
At time: 496.9175822734833 and batch: 800, loss is 3.7734342861175536 and perplexity is 43.5293005026075
At time: 498.005818605423 and batch: 850, loss is 3.7938213920593262 and perplexity is 44.425844883510784
At time: 499.0662066936493 and batch: 900, loss is 3.7822097158432006 and perplexity is 43.912969789471205
At time: 500.12521958351135 and batch: 950, loss is 3.8740171241760253 and perplexity is 48.1353639475162
At time: 501.1873276233673 and batch: 1000, loss is 3.8253793573379515 and perplexity is 45.850190673833126
At time: 502.2457311153412 and batch: 1050, loss is 3.7832358741760252 and perplexity is 43.95805457744898
At time: 503.30424976348877 and batch: 1100, loss is 3.805263805389404 and perplexity is 44.93710319949888
At time: 504.36510586738586 and batch: 1150, loss is 3.7623667430877688 and perplexity is 43.0501942512522
At time: 505.4257025718689 and batch: 1200, loss is 3.817335386276245 and perplexity is 45.48285247652403
At time: 506.48613238334656 and batch: 1250, loss is 3.802516050338745 and perplexity is 44.81379653306026
At time: 507.5446231365204 and batch: 1300, loss is 3.799738268852234 and perplexity is 44.68948633193027
At time: 508.60201954841614 and batch: 1350, loss is 3.6824378252029417 and perplexity is 39.74316295613536
At time: 509.65772819519043 and batch: 1400, loss is 3.70838408946991 and perplexity is 40.78784374016327
At time: 510.7177698612213 and batch: 1450, loss is 3.616902856826782 and perplexity is 37.222106920535055
At time: 511.7771649360657 and batch: 1500, loss is 3.637976803779602 and perplexity is 38.01484737385256
At time: 512.8359086513519 and batch: 1550, loss is 3.6420021867752075 and perplexity is 38.168180098476476
At time: 513.893396615982 and batch: 1600, loss is 3.7415374374389647 and perplexity is 42.16276297049114
At time: 514.955641746521 and batch: 1650, loss is 3.6702546453475953 and perplexity is 39.26190244825436
At time: 516.0156028270721 and batch: 1700, loss is 3.698081917762756 and perplexity is 40.36979746009658
At time: 517.0835654735565 and batch: 1750, loss is 3.691617889404297 and perplexity is 40.109687529169
At time: 518.1437814235687 and batch: 1800, loss is 3.6442094659805297 and perplexity is 38.25252097640288
At time: 519.1996822357178 and batch: 1850, loss is 3.673008761405945 and perplexity is 39.37018332487508
At time: 520.2550179958344 and batch: 1900, loss is 3.7540203189849852 and perplexity is 42.692374407632784
At time: 521.3178932666779 and batch: 1950, loss is 3.6944830513000486 and perplexity is 40.224773068149055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.495388297147529 and perplexity of 89.60295480285157
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 524.66361951828 and batch: 50, loss is 3.8670930290222167 and perplexity is 47.80322132782641
At time: 525.7390813827515 and batch: 100, loss is 3.8499166345596314 and perplexity is 46.98914579746029
At time: 526.7880153656006 and batch: 150, loss is 3.827632579803467 and perplexity is 45.95361783194727
At time: 527.8372111320496 and batch: 200, loss is 3.8303361988067626 and perplexity is 46.07802700811303
At time: 528.8892142772675 and batch: 250, loss is 3.8218430185317995 and perplexity is 45.68833522181792
At time: 529.951887845993 and batch: 300, loss is 3.8412685108184816 and perplexity is 46.584529955812606
At time: 531.0024473667145 and batch: 350, loss is 3.8612301683425905 and perplexity is 47.52377767120307
At time: 532.050858259201 and batch: 400, loss is 3.8180613470077516 and perplexity is 45.51588322944301
At time: 533.0985543727875 and batch: 450, loss is 3.85690580368042 and perplexity is 47.318711237013545
At time: 534.1519212722778 and batch: 500, loss is 3.880664267539978 and perplexity is 48.456392391557465
At time: 535.2135727405548 and batch: 550, loss is 3.842962746620178 and perplexity is 46.66352203097471
At time: 536.2651841640472 and batch: 600, loss is 3.8191611099243166 and perplexity is 45.565967445267106
At time: 537.3138871192932 and batch: 650, loss is 3.848025469779968 and perplexity is 46.90036555539537
At time: 538.3632686138153 and batch: 700, loss is 3.8649834489822386 and perplexity is 47.702482901513186
At time: 539.4118719100952 and batch: 750, loss is 3.8172121953964235 and perplexity is 45.4772497490202
At time: 540.4637234210968 and batch: 800, loss is 3.774682149887085 and perplexity is 43.58365304484887
At time: 541.5205144882202 and batch: 850, loss is 3.7946561765670777 and perplexity is 44.4629463742836
At time: 542.573831319809 and batch: 900, loss is 3.77625066280365 and perplexity is 43.6520682086084
At time: 543.6219563484192 and batch: 950, loss is 3.869519419670105 and perplexity is 47.919351448539494
At time: 544.6710541248322 and batch: 1000, loss is 3.8222665548324586 and perplexity is 45.707689988734906
At time: 545.7181024551392 and batch: 1050, loss is 3.783943781852722 and perplexity is 43.98918383875855
At time: 546.7669625282288 and batch: 1100, loss is 3.7985918045043947 and perplexity is 44.6382807874017
At time: 547.8194482326508 and batch: 1150, loss is 3.7586889982223513 and perplexity is 42.89215740811491
At time: 548.8708837032318 and batch: 1200, loss is 3.809160690307617 and perplexity is 45.11255956381939
At time: 549.9153292179108 and batch: 1250, loss is 3.791473903656006 and perplexity is 44.321678040902576
At time: 550.9587404727936 and batch: 1300, loss is 3.788694586753845 and perplexity is 44.1986650771815
At time: 552.0021860599518 and batch: 1350, loss is 3.6687500524520873 and perplexity is 39.20287368702975
At time: 553.0532307624817 and batch: 1400, loss is 3.6927495574951172 and perplexity is 40.15510407606002
At time: 554.1058158874512 and batch: 1450, loss is 3.6021070766448973 and perplexity is 36.67543102971923
At time: 555.1585252285004 and batch: 1500, loss is 3.6173954582214356 and perplexity is 37.24044709914397
At time: 556.2187671661377 and batch: 1550, loss is 3.620533490180969 and perplexity is 37.35749236216868
At time: 557.2681167125702 and batch: 1600, loss is 3.716482262611389 and perplexity is 41.11949182015958
At time: 558.3171737194061 and batch: 1650, loss is 3.645934543609619 and perplexity is 38.318566495040194
At time: 559.366259098053 and batch: 1700, loss is 3.669288282394409 and perplexity is 39.22397952686113
At time: 560.4208359718323 and batch: 1750, loss is 3.661101121902466 and perplexity is 38.904157514872246
At time: 561.4752097129822 and batch: 1800, loss is 3.6155941820144655 and perplexity is 37.17342714669128
At time: 562.5248975753784 and batch: 1850, loss is 3.643616108894348 and perplexity is 38.229830304518416
At time: 563.5771825313568 and batch: 1900, loss is 3.7235675048828125 and perplexity is 41.411867936470685
At time: 564.6301798820496 and batch: 1950, loss is 3.669591965675354 and perplexity is 39.23589300252569
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48703982331032 and perplexity of 88.85802073685858
finished 13 epochs...
Completing Train Step...
At time: 567.9557836055756 and batch: 50, loss is 3.863704090118408 and perplexity is 47.6414933292801
At time: 569.0355286598206 and batch: 100, loss is 3.839881615638733 and perplexity is 46.51996687722608
At time: 570.088901758194 and batch: 150, loss is 3.8131486701965334 and perplexity is 45.29282675615245
At time: 571.1517431735992 and batch: 200, loss is 3.8134085273742677 and perplexity is 45.3045979516335
At time: 572.2090828418732 and batch: 250, loss is 3.8047869300842283 and perplexity is 44.91567891345938
At time: 573.2660179138184 and batch: 300, loss is 3.8232587289810183 and perplexity is 45.75306248211751
At time: 574.322428226471 and batch: 350, loss is 3.8423870754241944 and perplexity is 46.63666691603804
At time: 575.3750929832458 and batch: 400, loss is 3.799041929244995 and perplexity is 44.65837810477253
At time: 576.4345061779022 and batch: 450, loss is 3.838480091094971 and perplexity is 46.454813669447425
At time: 577.4961566925049 and batch: 500, loss is 3.862718729972839 and perplexity is 47.59457242127084
At time: 578.587057352066 and batch: 550, loss is 3.825677680969238 and perplexity is 45.86387090967748
At time: 579.651242017746 and batch: 600, loss is 3.8040288305282592 and perplexity is 44.88164126081388
At time: 580.7027976512909 and batch: 650, loss is 3.833213791847229 and perplexity is 46.210811776585345
At time: 581.7553505897522 and batch: 700, loss is 3.85080313205719 and perplexity is 47.03082002694299
At time: 582.8087334632874 and batch: 750, loss is 3.8045620822906496 and perplexity is 44.905580857463946
At time: 583.8612687587738 and batch: 800, loss is 3.76216513633728 and perplexity is 43.04151591631614
At time: 584.9175598621368 and batch: 850, loss is 3.7824528646469116 and perplexity is 43.92364847374495
At time: 585.9761517047882 and batch: 900, loss is 3.7656793880462645 and perplexity is 43.1930407294052
At time: 587.0314903259277 and batch: 950, loss is 3.8598913860321047 and perplexity is 47.460196248667906
At time: 588.0843982696533 and batch: 1000, loss is 3.8124275159835816 and perplexity is 45.26017541806083
At time: 589.1382808685303 and batch: 1050, loss is 3.7745523405075074 and perplexity is 43.57799584507415
At time: 590.1936564445496 and batch: 1100, loss is 3.789835071563721 and perplexity is 44.2491017389752
At time: 591.256439447403 and batch: 1150, loss is 3.7505029296875 and perplexity is 42.542472493051335
At time: 592.3137118816376 and batch: 1200, loss is 3.8022761011123656 and perplexity is 44.803044787239166
At time: 593.374876499176 and batch: 1250, loss is 3.7861603546142577 and perplexity is 44.08679720906049
At time: 594.4447195529938 and batch: 1300, loss is 3.783987202644348 and perplexity is 43.99109392541225
At time: 595.499543428421 and batch: 1350, loss is 3.6648718690872193 and perplexity is 39.051132185312056
At time: 596.5572028160095 and batch: 1400, loss is 3.6906609296798707 and perplexity is 40.07132253344994
At time: 597.6134848594666 and batch: 1450, loss is 3.6013224744796752 and perplexity is 36.64666669287895
At time: 598.6731660366058 and batch: 1500, loss is 3.6184095191955565 and perplexity is 37.27823033722186
At time: 599.7270934581757 and batch: 1550, loss is 3.6229722547531127 and perplexity is 37.448709674610505
At time: 600.7790637016296 and batch: 1600, loss is 3.719709105491638 and perplexity is 41.25239226869301
At time: 601.8402326107025 and batch: 1650, loss is 3.6500917530059813 and perplexity is 38.478196377252885
At time: 602.8943209648132 and batch: 1700, loss is 3.674108180999756 and perplexity is 39.41349147838836
At time: 603.9500133991241 and batch: 1750, loss is 3.66696280002594 and perplexity is 39.13287083094186
At time: 605.0049920082092 and batch: 1800, loss is 3.6220978546142577 and perplexity is 37.41597882968419
At time: 606.0616083145142 and batch: 1850, loss is 3.6507381534576417 and perplexity is 38.50307674124316
At time: 607.1136956214905 and batch: 1900, loss is 3.7302760648727418 and perplexity is 41.69061589008697
At time: 608.166907787323 and batch: 1950, loss is 3.6758945322036745 and perplexity is 39.48396073902645
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486595260265261 and perplexity of 88.81852652406613
finished 14 epochs...
Completing Train Step...
At time: 611.5243766307831 and batch: 50, loss is 3.8599552869796754 and perplexity is 47.46322909708
At time: 612.5868782997131 and batch: 100, loss is 3.8343672609329222 and perplexity is 46.264145272750646
At time: 613.6499397754669 and batch: 150, loss is 3.8063901233673096 and perplexity is 44.98774518084081
At time: 614.7097110748291 and batch: 200, loss is 3.805864634513855 and perplexity is 44.964110832543376
At time: 615.7691955566406 and batch: 250, loss is 3.7966020774841307 and perplexity is 44.54955109718544
At time: 616.8276960849762 and batch: 300, loss is 3.8145679950714113 and perplexity is 45.35715763422928
At time: 617.8864281177521 and batch: 350, loss is 3.8336710691452027 and perplexity is 46.231947763867
At time: 618.9475042819977 and batch: 400, loss is 3.790128049850464 and perplexity is 44.26206766426715
At time: 620.0103607177734 and batch: 450, loss is 3.829851088523865 and perplexity is 46.055679504335956
At time: 621.0734996795654 and batch: 500, loss is 3.8540057277679445 and perplexity is 47.181682175725236
At time: 622.1377487182617 and batch: 550, loss is 3.817027645111084 and perplexity is 45.468857684005386
At time: 623.1943848133087 and batch: 600, loss is 3.7962374448776246 and perplexity is 44.53330983947621
At time: 624.253664970398 and batch: 650, loss is 3.8255868101119996 and perplexity is 45.85970340976666
At time: 625.3157455921173 and batch: 700, loss is 3.843455448150635 and perplexity is 46.686518884523124
At time: 626.3803007602692 and batch: 750, loss is 3.7979513883590696 and perplexity is 44.60970286354454
At time: 627.4445078372955 and batch: 800, loss is 3.7555604791641235 and perplexity is 42.75817816380301
At time: 628.5122413635254 and batch: 850, loss is 3.776146879196167 and perplexity is 43.647538074576524
At time: 629.5777459144592 and batch: 900, loss is 3.7602405834197996 and perplexity is 42.95875990099534
At time: 630.6356446743011 and batch: 950, loss is 3.8547862005233764 and perplexity is 47.218520567029245
At time: 631.7244539260864 and batch: 1000, loss is 3.8074819231033326 and perplexity is 45.03688961221033
At time: 632.785891532898 and batch: 1050, loss is 3.7700505828857422 and perplexity is 43.382259180212365
At time: 633.8397488594055 and batch: 1100, loss is 3.7857711505889893 and perplexity is 44.0696417888214
At time: 634.8916487693787 and batch: 1150, loss is 3.746745591163635 and perplexity is 42.38292594514918
At time: 635.9468984603882 and batch: 1200, loss is 3.7988877391815183 and perplexity is 44.6514927574575
At time: 637.0028414726257 and batch: 1250, loss is 3.7834430646896364 and perplexity is 43.96716321293308
At time: 638.0656704902649 and batch: 1300, loss is 3.7813985252380373 and perplexity is 43.87736244505735
At time: 639.1295573711395 and batch: 1350, loss is 3.6627471971511842 and perplexity is 38.96824942120829
At time: 640.1905403137207 and batch: 1400, loss is 3.6893080377578737 and perplexity is 40.01714701996118
At time: 641.2481513023376 and batch: 1450, loss is 3.6004618406295776 and perplexity is 36.615140899058375
At time: 642.3053693771362 and batch: 1500, loss is 3.6183415126800536 and perplexity is 37.27569526087434
At time: 643.3667259216309 and batch: 1550, loss is 3.6234108448028564 and perplexity is 37.465137908416125
At time: 644.4267706871033 and batch: 1600, loss is 3.720644392967224 and perplexity is 41.29099316317257
At time: 645.4912688732147 and batch: 1650, loss is 3.651571025848389 and perplexity is 38.535158248866225
At time: 646.5549144744873 and batch: 1700, loss is 3.6759520292282106 and perplexity is 39.48623101455227
At time: 647.6154382228851 and batch: 1750, loss is 3.6692563486099243 and perplexity is 39.22272697675172
At time: 648.6824610233307 and batch: 1800, loss is 3.624698739051819 and perplexity is 37.51342012858811
At time: 649.7525169849396 and batch: 1850, loss is 3.653667507171631 and perplexity is 38.6160312331524
At time: 650.8131914138794 and batch: 1900, loss is 3.7330765867233278 and perplexity is 41.80753501171335
At time: 651.8716721534729 and batch: 1950, loss is 3.678487401008606 and perplexity is 39.58647030862371
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486736350835756 and perplexity of 88.83105886472065
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 655.1962969303131 and batch: 50, loss is 3.8579608249664306 and perplexity is 47.36865982837572
At time: 656.2721011638641 and batch: 100, loss is 3.834643030166626 and perplexity is 46.27690525996555
At time: 657.3225266933441 and batch: 150, loss is 3.8077283191680906 and perplexity is 45.04798789180978
At time: 658.3985023498535 and batch: 200, loss is 3.8075202322006225 and perplexity is 45.03861496784432
At time: 659.4541759490967 and batch: 250, loss is 3.7990244817733765 and perplexity is 44.6575989357853
At time: 660.5097930431366 and batch: 300, loss is 3.8160145330429076 and perplexity is 45.422815962209604
At time: 661.5696482658386 and batch: 350, loss is 3.835113139152527 and perplexity is 46.2986655634243
At time: 662.6230390071869 and batch: 400, loss is 3.792879204750061 and perplexity is 44.3840071288539
At time: 663.6749680042267 and batch: 450, loss is 3.832493152618408 and perplexity is 46.17752244906179
At time: 664.736074924469 and batch: 500, loss is 3.8571297311782837 and perplexity is 47.32930838407503
At time: 665.7929775714874 and batch: 550, loss is 3.821206097602844 and perplexity is 45.65924463009279
At time: 666.8501632213593 and batch: 600, loss is 3.7992236852645873 and perplexity is 44.66649577151335
At time: 667.9069201946259 and batch: 650, loss is 3.828050193786621 and perplexity is 45.97281271307683
At time: 668.9701495170593 and batch: 700, loss is 3.8453637409210204 and perplexity is 46.77569549146009
At time: 670.0224409103394 and batch: 750, loss is 3.798500714302063 and perplexity is 44.63421486255881
At time: 671.0739834308624 and batch: 800, loss is 3.755985445976257 and perplexity is 42.7763528320118
At time: 672.1261193752289 and batch: 850, loss is 3.7765655755996703 and perplexity is 43.665816968176586
At time: 673.1831123828888 and batch: 900, loss is 3.7580050659179687 and perplexity is 42.86283210546286
At time: 674.2382464408875 and batch: 950, loss is 3.8516737174987794 and perplexity is 47.07178220211397
At time: 675.2898616790771 and batch: 1000, loss is 3.8048312950134275 and perplexity is 44.91767163857754
At time: 676.3415613174438 and batch: 1050, loss is 3.769052653312683 and perplexity is 43.338988335049315
At time: 677.3982305526733 and batch: 1100, loss is 3.7836357975006103 and perplexity is 43.97563794454285
At time: 678.4615323543549 and batch: 1150, loss is 3.7463382482528687 and perplexity is 42.3656650765128
At time: 679.5205535888672 and batch: 1200, loss is 3.798114290237427 and perplexity is 44.61697045987045
At time: 680.5739974975586 and batch: 1250, loss is 3.781321406364441 and perplexity is 43.87397880276223
At time: 681.6298608779907 and batch: 1300, loss is 3.7779290008544923 and perplexity is 43.72539265006915
At time: 682.6837265491486 and batch: 1350, loss is 3.6578609418869017 and perplexity is 38.7783050436093
At time: 683.7432661056519 and batch: 1400, loss is 3.6815567445755004 and perplexity is 39.70816144702159
At time: 684.8065690994263 and batch: 1450, loss is 3.5912328720092774 and perplexity is 36.27877545320408
At time: 685.8615579605103 and batch: 1500, loss is 3.6076070737838744 and perplexity is 36.877701529148084
At time: 686.915757894516 and batch: 1550, loss is 3.612567801475525 and perplexity is 37.06109627392876
At time: 687.973521232605 and batch: 1600, loss is 3.7088521766662597 and perplexity is 40.80694047670501
At time: 689.0338275432587 and batch: 1650, loss is 3.6401996755599977 and perplexity is 38.09944349364608
At time: 690.0964004993439 and batch: 1700, loss is 3.6642267990112303 and perplexity is 39.025949591647866
At time: 691.1535205841064 and batch: 1750, loss is 3.657211785316467 and perplexity is 38.75314002100353
At time: 692.2100186347961 and batch: 1800, loss is 3.6131813621520994 and perplexity is 37.0838424826092
At time: 693.2702493667603 and batch: 1850, loss is 3.642515707015991 and perplexity is 38.18778526490498
At time: 694.3213613033295 and batch: 1900, loss is 3.721379632949829 and perplexity is 41.321363115501114
At time: 695.3778126239777 and batch: 1950, loss is 3.668155016899109 and perplexity is 39.179553522258686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486179653433866 and perplexity of 88.78162060739504
finished 16 epochs...
Completing Train Step...
At time: 698.7281920909882 and batch: 50, loss is 3.8566674327850343 and perplexity is 47.307433177681446
At time: 699.807591676712 and batch: 100, loss is 3.8320807313919065 and perplexity is 46.158481785273395
At time: 700.8583509922028 and batch: 150, loss is 3.8043577098846435 and perplexity is 44.89640433360707
At time: 701.9101696014404 and batch: 200, loss is 3.8040318775177 and perplexity is 44.88177801490922
At time: 702.9673392772675 and batch: 250, loss is 3.7951370239257813 and perplexity is 44.48433140566374
At time: 704.0210862159729 and batch: 300, loss is 3.8122234869003297 and perplexity is 45.25094196794068
At time: 705.0759418010712 and batch: 350, loss is 3.831039032936096 and perplexity is 46.11042360148885
At time: 706.125405550003 and batch: 400, loss is 3.7885456705093383 and perplexity is 44.19208366801753
At time: 707.1711041927338 and batch: 450, loss is 3.8282676124572754 and perplexity is 45.98280914756952
At time: 708.2181718349457 and batch: 500, loss is 3.85264769077301 and perplexity is 47.11765119390926
At time: 709.2717742919922 and batch: 550, loss is 3.8169435930252074 and perplexity is 45.46503609228324
At time: 710.3280084133148 and batch: 600, loss is 3.7953664207458497 and perplexity is 44.49453714036786
At time: 711.4174294471741 and batch: 650, loss is 3.8244525480270384 and perplexity is 45.807715976222475
At time: 712.4724857807159 and batch: 700, loss is 3.842113561630249 and perplexity is 46.62391288861358
At time: 713.5248947143555 and batch: 750, loss is 3.7957383251190184 and perplexity is 44.51108793077738
At time: 714.5792927742004 and batch: 800, loss is 3.7530383968353274 and perplexity is 42.65047439422263
At time: 715.6336417198181 and batch: 850, loss is 3.7736328411102296 and perplexity is 43.5379443206582
At time: 716.6978008747101 and batch: 900, loss is 3.7553910970687867 and perplexity is 42.75093630733056
At time: 717.754727602005 and batch: 950, loss is 3.849592995643616 and perplexity is 46.97394074185648
At time: 718.8175389766693 and batch: 1000, loss is 3.802712607383728 and perplexity is 44.822605866221146
At time: 719.8747417926788 and batch: 1050, loss is 3.7669076347351074 and perplexity is 43.24612503229824
At time: 720.9321210384369 and batch: 1100, loss is 3.781553239822388 and perplexity is 43.88415143811502
At time: 721.9986696243286 and batch: 1150, loss is 3.744295139312744 and perplexity is 42.27919577062563
At time: 723.0561950206757 and batch: 1200, loss is 3.7964162158966066 and perplexity is 44.54127181631901
At time: 724.1133170127869 and batch: 1250, loss is 3.7800059366226195 and perplexity is 43.81630185565055
At time: 725.1737699508667 and batch: 1300, loss is 3.77670361995697 and perplexity is 43.67184520388832
At time: 726.2362620830536 and batch: 1350, loss is 3.656986060142517 and perplexity is 38.74439344892907
At time: 727.2904596328735 and batch: 1400, loss is 3.6813215446472167 and perplexity is 39.69882318851888
At time: 728.3456735610962 and batch: 1450, loss is 3.591651964187622 and perplexity is 36.29398279065194
At time: 729.4094653129578 and batch: 1500, loss is 3.6084825801849365 and perplexity is 36.91000233060929
At time: 730.4685461521149 and batch: 1550, loss is 3.613822093009949 and perplexity is 37.10761085856825
At time: 731.5232956409454 and batch: 1600, loss is 3.710315299034119 and perplexity is 40.866689723651305
At time: 732.5753164291382 and batch: 1650, loss is 3.642045283317566 and perplexity is 38.16982505051245
At time: 733.627504825592 and batch: 1700, loss is 3.666157994270325 and perplexity is 39.101389141285146
At time: 734.6847305297852 and batch: 1750, loss is 3.659362564086914 and perplexity is 38.83657914923693
At time: 735.740177154541 and batch: 1800, loss is 3.6154425287246705 and perplexity is 37.16779010162055
At time: 736.7946245670319 and batch: 1850, loss is 3.644966025352478 and perplexity is 38.28147222993839
At time: 737.8476858139038 and batch: 1900, loss is 3.7235047721862795 and perplexity is 41.40927013981081
At time: 738.8998122215271 and batch: 1950, loss is 3.670002455711365 and perplexity is 39.252002251774165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485930402888808 and perplexity of 88.75949449765454
finished 17 epochs...
Completing Train Step...
At time: 742.2666516304016 and batch: 50, loss is 3.8556036806106566 and perplexity is 47.257136549091314
At time: 743.3249773979187 and batch: 100, loss is 3.8302976799011232 and perplexity is 46.076252167121346
At time: 744.3856737613678 and batch: 150, loss is 3.8021610403060913 and perplexity is 44.797890009344535
At time: 745.439813375473 and batch: 200, loss is 3.8015649700164795 and perplexity is 44.771195274832124
At time: 746.4901473522186 and batch: 250, loss is 3.792490725517273 and perplexity is 44.36676821251372
At time: 747.5412197113037 and batch: 300, loss is 3.809535412788391 and perplexity is 45.12946742173258
At time: 748.593759059906 and batch: 350, loss is 3.8282272624969482 and perplexity is 45.98095378047692
At time: 749.6507189273834 and batch: 400, loss is 3.7855176305770875 and perplexity is 44.058470668821656
At time: 750.7065677642822 and batch: 450, loss is 3.8253402042388918 and perplexity is 45.848395531918676
At time: 751.7629323005676 and batch: 500, loss is 3.8496702098846436 and perplexity is 46.97756793907278
At time: 752.8189177513123 and batch: 550, loss is 3.8140402889251708 and perplexity is 45.333228697648444
At time: 753.8721497058868 and batch: 600, loss is 3.792739706039429 and perplexity is 44.37781604892061
At time: 754.9326682090759 and batch: 650, loss is 3.821954288482666 and perplexity is 45.6934192434774
At time: 755.9843411445618 and batch: 700, loss is 3.8397510147094724 and perplexity is 46.51389172304177
At time: 757.0428047180176 and batch: 750, loss is 3.793710265159607 and perplexity is 44.420908251402864
At time: 758.0973262786865 and batch: 800, loss is 3.750986375808716 and perplexity is 42.56304445868286
At time: 759.1524901390076 and batch: 850, loss is 3.7716118144989013 and perplexity is 43.45004183313702
At time: 760.20445561409 and batch: 900, loss is 3.753610634803772 and perplexity is 42.674887599458465
At time: 761.2570748329163 and batch: 950, loss is 3.848077425956726 and perplexity is 46.90280238238173
At time: 762.3170909881592 and batch: 1000, loss is 3.8011763668060303 and perplexity is 44.753800424678886
At time: 763.3760619163513 and batch: 1050, loss is 3.7654627847671507 and perplexity is 43.183685988318686
At time: 764.4641571044922 and batch: 1100, loss is 3.780169367790222 and perplexity is 43.823463390215885
At time: 765.5220944881439 and batch: 1150, loss is 3.742993965148926 and perplexity is 42.22421894838879
At time: 766.5779025554657 and batch: 1200, loss is 3.7952971839904786 and perplexity is 44.491456589629415
At time: 767.6292202472687 and batch: 1250, loss is 3.7791785526275636 and perplexity is 43.78006394217473
At time: 768.6820602416992 and batch: 1300, loss is 3.775977373123169 and perplexity is 43.640140178813304
At time: 769.7346518039703 and batch: 1350, loss is 3.6564808893203735 and perplexity is 38.72482585474197
At time: 770.785484790802 and batch: 1400, loss is 3.681243166923523 and perplexity is 39.69571180705713
At time: 771.83838057518 and batch: 1450, loss is 3.591950945854187 and perplexity is 36.30483564843489
At time: 772.8958992958069 and batch: 1500, loss is 3.6090644502639773 and perplexity is 36.93148540615609
At time: 773.9512722492218 and batch: 1550, loss is 3.6146680402755735 and perplexity is 37.13901522185272
At time: 775.0052456855774 and batch: 1600, loss is 3.7113085079193113 and perplexity is 40.90729904642504
At time: 776.0577199459076 and batch: 1650, loss is 3.643261795043945 and perplexity is 38.216287345513635
At time: 777.1082310676575 and batch: 1700, loss is 3.66744863986969 and perplexity is 39.15188775800822
At time: 778.1653921604156 and batch: 1750, loss is 3.6608032417297363 and perplexity is 38.89257046357392
At time: 779.219384431839 and batch: 1800, loss is 3.6169573163986204 and perplexity is 37.224134075739364
At time: 780.2743701934814 and batch: 1850, loss is 3.6465772724151613 and perplexity is 38.34320285791557
At time: 781.3253445625305 and batch: 1900, loss is 3.7249008321762087 and perplexity is 41.46712033684215
At time: 782.3748452663422 and batch: 1950, loss is 3.671221179962158 and perplexity is 39.29986878093591
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485841547056686 and perplexity of 88.75160804929585
finished 18 epochs...
Completing Train Step...
At time: 785.6785588264465 and batch: 50, loss is 3.8545362520217896 and perplexity is 47.206719843414405
At time: 786.7649080753326 and batch: 100, loss is 3.828733582496643 and perplexity is 46.0042407518132
At time: 787.8266670703888 and batch: 150, loss is 3.800314021110535 and perplexity is 44.71522381310366
At time: 788.8883502483368 and batch: 200, loss is 3.7995325326919556 and perplexity is 44.68029303433683
At time: 789.9466075897217 and batch: 250, loss is 3.790302872657776 and perplexity is 44.26980635962416
At time: 791.0323970317841 and batch: 300, loss is 3.8073065948486327 and perplexity is 45.02899406513398
At time: 792.0928523540497 and batch: 350, loss is 3.8259407663345337 and perplexity is 45.87593861025773
At time: 793.153621673584 and batch: 400, loss is 3.783110885620117 and perplexity is 43.95256066703193
At time: 794.211629152298 and batch: 450, loss is 3.8230133724212645 and perplexity is 45.741838045159625
At time: 795.2680864334106 and batch: 500, loss is 3.847347207069397 and perplexity is 46.868565571917586
At time: 796.3240146636963 and batch: 550, loss is 3.8117356061935426 and perplexity is 45.22887029100105
At time: 797.3843586444855 and batch: 600, loss is 3.7906493520736695 and perplexity is 44.28514759383083
At time: 798.4496746063232 and batch: 650, loss is 3.8199556827545167 and perplexity is 45.602187312736596
At time: 799.5141386985779 and batch: 700, loss is 3.8378344535827638 and perplexity is 46.424830379329805
At time: 800.5725431442261 and batch: 750, loss is 3.7920340633392335 and perplexity is 44.346512212935686
At time: 801.6353211402893 and batch: 800, loss is 3.7493182039260864 and perplexity is 42.49210117392595
At time: 802.6926131248474 and batch: 850, loss is 3.76999146938324 and perplexity is 43.379694778721884
At time: 803.7535328865051 and batch: 900, loss is 3.7521973705291747 and perplexity is 42.61461930293812
At time: 804.8136789798737 and batch: 950, loss is 3.846823282241821 and perplexity is 46.844016398303935
At time: 805.8783533573151 and batch: 1000, loss is 3.799933876991272 and perplexity is 44.69822881420869
At time: 806.9369812011719 and batch: 1050, loss is 3.764316620826721 and perplexity is 43.13421875881678
At time: 807.9968857765198 and batch: 1100, loss is 3.7790990924835204 and perplexity is 43.776585310195784
At time: 809.0630855560303 and batch: 1150, loss is 3.7420121383666993 and perplexity is 42.18278242443983
At time: 810.1285021305084 and batch: 1200, loss is 3.794441680908203 and perplexity is 44.45341028806666
At time: 811.1894018650055 and batch: 1250, loss is 3.778547224998474 and perplexity is 43.75243310117914
At time: 812.2548248767853 and batch: 1300, loss is 3.7754272413253784 and perplexity is 43.616138952565095
At time: 813.3267567157745 and batch: 1350, loss is 3.6560904026031493 and perplexity is 38.70970727661295
At time: 814.3943865299225 and batch: 1400, loss is 3.6811257076263426 and perplexity is 39.691049450471134
At time: 815.4571003913879 and batch: 1450, loss is 3.5920698976516725 and perplexity is 36.30915443075104
At time: 816.5202255249023 and batch: 1500, loss is 3.609392924308777 and perplexity is 36.943618433131036
At time: 817.581591129303 and batch: 1550, loss is 3.6151919889450075 and perplexity is 37.15847925809497
At time: 818.64333152771 and batch: 1600, loss is 3.7119537115097048 and perplexity is 40.93370109907677
At time: 819.698165178299 and batch: 1650, loss is 3.644074788093567 and perplexity is 38.24736955460587
At time: 820.7538754940033 and batch: 1700, loss is 3.6683212518692017 and perplexity is 39.18606707554188
At time: 821.8189208507538 and batch: 1750, loss is 3.6617954397201538 and perplexity is 38.93117874419192
At time: 822.8826184272766 and batch: 1800, loss is 3.6180098247528076 and perplexity is 37.26333341302779
At time: 823.9503500461578 and batch: 1850, loss is 3.6476974582672117 and perplexity is 38.38617843710333
At time: 825.0085601806641 and batch: 1900, loss is 3.725884747505188 and perplexity is 41.50794055071415
At time: 826.0662672519684 and batch: 1950, loss is 3.672078423500061 and perplexity is 39.333572783694095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485839275981105 and perplexity of 88.75140648791492
finished 19 epochs...
Completing Train Step...
At time: 829.3884863853455 and batch: 50, loss is 3.853459415435791 and perplexity is 47.15591328047443
At time: 830.4795835018158 and batch: 100, loss is 3.827291250228882 and perplexity is 45.93793517975081
At time: 831.5415828227997 and batch: 150, loss is 3.7986616849899293 and perplexity is 44.64140024112975
At time: 832.5961611270905 and batch: 200, loss is 3.797751989364624 and perplexity is 44.60080862043206
At time: 833.6506135463715 and batch: 250, loss is 3.7883883047103883 and perplexity is 44.18512989262141
At time: 834.7063593864441 and batch: 300, loss is 3.8053599119186403 and perplexity is 44.941422156057946
At time: 835.7598266601562 and batch: 350, loss is 3.8239682865142823 and perplexity is 45.78553843268673
At time: 836.8104057312012 and batch: 400, loss is 3.7810695457458494 and perplexity is 43.862930066750046
At time: 837.8607730865479 and batch: 450, loss is 3.8210447216033936 and perplexity is 45.65187691835837
At time: 838.910587310791 and batch: 500, loss is 3.8453889989852907 and perplexity is 46.776876969903974
At time: 839.9634578227997 and batch: 550, loss is 3.809782829284668 and perplexity is 45.14063457785326
At time: 841.0170862674713 and batch: 600, loss is 3.7888705635070803 and perplexity is 44.206443699167366
At time: 842.0710692405701 and batch: 650, loss is 3.8182472085952757 and perplexity is 45.524343669968694
At time: 843.121280670166 and batch: 700, loss is 3.836187491416931 and perplexity is 46.348433368901524
At time: 844.1973514556885 and batch: 750, loss is 3.7905713891983033 and perplexity is 44.28169513097211
At time: 845.2456018924713 and batch: 800, loss is 3.747870435714722 and perplexity is 42.43062697154794
At time: 846.2972400188446 and batch: 850, loss is 3.7685974073410033 and perplexity is 43.31926292549041
At time: 847.3507866859436 and batch: 900, loss is 3.7509807682037355 and perplexity is 42.562805782611974
At time: 848.4103918075562 and batch: 950, loss is 3.845713210105896 and perplexity is 46.79204501229596
At time: 849.4768486022949 and batch: 1000, loss is 3.798850908279419 and perplexity is 44.649848232984006
At time: 850.5291097164154 and batch: 1050, loss is 3.7633198738098144 and perplexity is 43.091246274847705
At time: 851.573370218277 and batch: 1100, loss is 3.778185877799988 and perplexity is 43.736626138123974
At time: 852.6266782283783 and batch: 1150, loss is 3.741184182167053 and perplexity is 42.14787138261427
At time: 853.678304195404 and batch: 1200, loss is 3.793712134361267 and perplexity is 44.42099128311591
At time: 854.7230672836304 and batch: 1250, loss is 3.7779968309402467 and perplexity is 43.72835864779306
At time: 855.7672867774963 and batch: 1300, loss is 3.7749416208267212 and perplexity is 43.594963203522504
At time: 856.8115041255951 and batch: 1350, loss is 3.6557239532470702 and perplexity is 38.695524728059034
At time: 857.8561944961548 and batch: 1400, loss is 3.6809489488601685 and perplexity is 39.68403432955243
At time: 858.9091501235962 and batch: 1450, loss is 3.5920567893981934 and perplexity is 36.30867848427057
At time: 859.9623239040375 and batch: 1500, loss is 3.609551677703857 and perplexity is 36.949483823546856
At time: 861.0160009860992 and batch: 1550, loss is 3.6154998922348023 and perplexity is 37.16992223767744
At time: 862.0702128410339 and batch: 1600, loss is 3.7123671102523805 and perplexity is 40.95062653788071
At time: 863.1250483989716 and batch: 1650, loss is 3.644627833366394 and perplexity is 38.26852793176705
At time: 864.179780960083 and batch: 1700, loss is 3.6689268350601196 and perplexity is 39.20980468590449
At time: 865.2389557361603 and batch: 1750, loss is 3.662500190734863 and perplexity is 38.958625202239304
At time: 866.2944264411926 and batch: 1800, loss is 3.6187664222717286 and perplexity is 37.29153742683282
At time: 867.3483331203461 and batch: 1850, loss is 3.648511128425598 and perplexity is 38.41742483539912
At time: 868.4002077579498 and batch: 1900, loss is 3.726609511375427 and perplexity is 41.5380349106884
At time: 869.4514110088348 and batch: 1950, loss is 3.6727094745635984 and perplexity is 39.3584021100944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.48588015534157 and perplexity of 88.75503466281073
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc0f4432b38>
ELAPSED
2695.8085429668427


RESULTS SO FAR:
[{'best_accuracy': -94.78310464460193, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.83547208165798, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.24245156315881022, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.32612507610596975, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.75140648791492, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.5466017702903482, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44410872475199714, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.961697908824608, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.8996370580396494, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5589585304260254 and batch: 50, loss is 9.180276041030885 and perplexity is 9703.831058780117
At time: 2.603839635848999 and batch: 100, loss is 7.756946134567261 and perplexity is 2337.7545054370134
At time: 3.676753282546997 and batch: 150, loss is 7.354966897964477 and perplexity is 1563.9452247670272
At time: 4.725280284881592 and batch: 200, loss is 7.2179422855377195 and perplexity is 1363.6801074085304
At time: 5.771682977676392 and batch: 250, loss is 7.132684412002564 and perplexity is 1252.2339710081058
At time: 6.819390058517456 and batch: 300, loss is 7.006123714447021 and perplexity is 1103.3692305848554
At time: 7.8687238693237305 and batch: 350, loss is 6.957373905181885 and perplexity is 1050.8702455647606
At time: 8.913487672805786 and batch: 400, loss is 6.922364559173584 and perplexity is 1014.7165173079413
At time: 9.962013244628906 and batch: 450, loss is 6.829391984939575 and perplexity is 924.6284535099905
At time: 11.010184288024902 and batch: 500, loss is 6.806282997131348 and perplexity is 903.5062225154322
At time: 12.057474613189697 and batch: 550, loss is 6.767958869934082 and perplexity is 869.5352468878895
At time: 13.10925579071045 and batch: 600, loss is 6.820592756271362 and perplexity is 916.5281268923947
At time: 14.158902168273926 and batch: 650, loss is 6.901226072311402 and perplexity is 993.4920622841631
At time: 15.214656352996826 and batch: 700, loss is 6.769838142395019 and perplexity is 871.1708769470685
At time: 16.27142643928528 and batch: 750, loss is 6.703608255386353 and perplexity is 815.3424877903141
At time: 17.323994636535645 and batch: 800, loss is 6.7086409568786625 and perplexity is 819.4562060205848
At time: 18.37574052810669 and batch: 850, loss is 6.759334964752197 and perplexity is 862.0686990417079
At time: 19.428990125656128 and batch: 900, loss is 6.737994575500489 and perplexity is 843.8667268068926
At time: 20.472699642181396 and batch: 950, loss is 6.750843839645386 and perplexity is 854.7797553278325
At time: 21.519227027893066 and batch: 1000, loss is 6.743337650299072 and perplexity is 848.3876368731695
At time: 22.56449818611145 and batch: 1050, loss is 6.644819545745849 and perplexity is 768.7913034526
At time: 23.607351303100586 and batch: 1100, loss is 6.715454740524292 and perplexity is 825.0588693066899
At time: 24.654895305633545 and batch: 1150, loss is 6.621773548126221 and perplexity is 751.2763409972337
At time: 25.699634075164795 and batch: 1200, loss is 6.716269817352295 and perplexity is 825.7316298113034
At time: 26.74417781829834 and batch: 1250, loss is 6.630241250991821 and perplexity is 757.6649360120405
At time: 27.790812492370605 and batch: 1300, loss is 6.647511682510376 and perplexity is 770.8637832326692
At time: 28.8336501121521 and batch: 1350, loss is 6.665867691040039 and perplexity is 785.1444322926723
At time: 29.87883162498474 and batch: 1400, loss is 6.6866585063934325 and perplexity is 801.6390998455267
At time: 30.9202401638031 and batch: 1450, loss is 6.681702680587769 and perplexity is 797.6761440778288
At time: 31.966161251068115 and batch: 1500, loss is 6.665868434906006 and perplexity is 785.1450163351119
At time: 33.013458251953125 and batch: 1550, loss is 6.648726348876953 and perplexity is 771.8006944454493
At time: 34.06119155883789 and batch: 1600, loss is 6.612333698272705 and perplexity is 744.2177734646834
At time: 35.10517144203186 and batch: 1650, loss is 6.612738599777222 and perplexity is 744.5191693745585
At time: 36.15224862098694 and batch: 1700, loss is 6.634602365493774 and perplexity is 760.9764151734958
At time: 37.19207429885864 and batch: 1750, loss is 6.661214656829834 and perplexity is 781.4996146958238
At time: 38.2336802482605 and batch: 1800, loss is 6.659129772186279 and perplexity is 779.8719754598022
At time: 39.286760091781616 and batch: 1850, loss is 6.603552551269531 and perplexity is 737.7112967663863
At time: 40.33879804611206 and batch: 1900, loss is 6.539946670532227 and perplexity is 692.2496597461635
At time: 41.38543653488159 and batch: 1950, loss is 6.49767147064209 and perplexity is 663.5946330411045
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.8371837527252906 and perplexity of 342.81253505454805
finished 1 epochs...
Completing Train Step...
At time: 44.768911838531494 and batch: 50, loss is 6.027248630523681 and perplexity is 414.5728157856592
At time: 45.8375883102417 and batch: 100, loss is 5.811091632843017 and perplexity is 333.98351412222576
At time: 46.89942955970764 and batch: 150, loss is 5.663668899536133 and perplexity is 288.2040970718809
At time: 47.95934319496155 and batch: 200, loss is 5.6071850681304936 and perplexity is 272.37643674533695
At time: 49.01761174201965 and batch: 250, loss is 5.577907457351684 and perplexity is 264.5175120808023
At time: 50.07618474960327 and batch: 300, loss is 5.558640241622925 and perplexity is 259.46978013465844
At time: 51.14674687385559 and batch: 350, loss is 5.502536773681641 and perplexity is 245.31344830756942
At time: 52.210925340652466 and batch: 400, loss is 5.468699264526367 and perplexity is 237.1515206587638
At time: 53.27612257003784 and batch: 450, loss is 5.389501142501831 and perplexity is 219.09406157225808
At time: 54.33914613723755 and batch: 500, loss is 5.373538408279419 and perplexity is 215.62448691958497
At time: 55.40016555786133 and batch: 550, loss is 5.325770359039307 and perplexity is 205.56665961777955
At time: 56.4636709690094 and batch: 600, loss is 5.341321744918823 and perplexity is 208.78849312156012
At time: 57.523327112197876 and batch: 650, loss is 5.409990272521973 and perplexity is 223.62941231977103
At time: 58.61145257949829 and batch: 700, loss is 5.350230054855347 and perplexity is 210.65675490184938
At time: 59.67268133163452 and batch: 750, loss is 5.290889120101928 and perplexity is 198.51985495790427
At time: 60.73758244514465 and batch: 800, loss is 5.274965267181397 and perplexity is 195.3836901684285
At time: 61.79974412918091 and batch: 850, loss is 5.274410343170166 and perplexity is 195.2752971450783
At time: 62.85864186286926 and batch: 900, loss is 5.301321973800659 and perplexity is 200.60182512183127
At time: 63.91901397705078 and batch: 950, loss is 5.3333430576324465 and perplexity is 207.1292630669505
At time: 64.98165965080261 and batch: 1000, loss is 5.307727785110473 and perplexity is 201.8909671540077
At time: 66.04456090927124 and batch: 1050, loss is 5.211668500900268 and perplexity is 183.3998057937904
At time: 67.10810661315918 and batch: 1100, loss is 5.295099477767945 and perplexity is 199.3574566150073
At time: 68.16885304450989 and batch: 1150, loss is 5.195844202041626 and perplexity is 180.52047424161464
At time: 69.23004150390625 and batch: 1200, loss is 5.272937498092651 and perplexity is 194.98789858365006
At time: 70.29098296165466 and batch: 1250, loss is 5.211568374633789 and perplexity is 183.38144357524868
At time: 71.35406112670898 and batch: 1300, loss is 5.2408578586578365 and perplexity is 188.83202412953577
At time: 72.41634011268616 and batch: 1350, loss is 5.1788637065887455 and perplexity is 177.48102585121472
At time: 73.47892546653748 and batch: 1400, loss is 5.181754693984986 and perplexity is 177.9948636514447
At time: 74.54533767700195 and batch: 1450, loss is 5.122367935180664 and perplexity is 167.7320784348115
At time: 75.60834956169128 and batch: 1500, loss is 5.0993003654479985 and perplexity is 163.90719204032848
At time: 76.6682825088501 and batch: 1550, loss is 5.1054940509796145 and perplexity is 164.92553202758
At time: 77.73249435424805 and batch: 1600, loss is 5.1479942321777346 and perplexity is 172.0859794052014
At time: 78.79503536224365 and batch: 1650, loss is 5.119387855529785 and perplexity is 167.23296754554903
At time: 79.85725688934326 and batch: 1700, loss is 5.137020864486694 and perplexity is 170.20793973391727
At time: 80.91712427139282 and batch: 1750, loss is 5.163240432739258 and perplexity is 174.72973919615418
At time: 81.97834873199463 and batch: 1800, loss is 5.1227336025238035 and perplexity is 167.79342379360565
At time: 83.04444575309753 and batch: 1850, loss is 5.111391077041626 and perplexity is 165.90097546919094
At time: 84.11067724227905 and batch: 1900, loss is 5.161744384765625 and perplexity is 174.46853056293853
At time: 85.17845249176025 and batch: 1950, loss is 5.0785212898254395 and perplexity is 160.53649338266473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.886269644803779 and perplexity of 132.45853390731395
finished 2 epochs...
Completing Train Step...
At time: 88.52797222137451 and batch: 50, loss is 5.044372444152832 and perplexity is 155.14690529391214
At time: 89.60639095306396 and batch: 100, loss is 5.002471761703491 and perplexity is 148.7804548122724
At time: 90.66019606590271 and batch: 150, loss is 4.947900667190551 and perplexity is 140.87890156328865
At time: 91.72037672996521 and batch: 200, loss is 4.921516990661621 and perplexity is 137.21060259039575
At time: 92.77525639533997 and batch: 250, loss is 4.9286607646942135 and perplexity is 138.19431365142887
At time: 93.8285505771637 and batch: 300, loss is 4.9560143184661865 and perplexity is 142.0265935327057
At time: 94.88239526748657 and batch: 350, loss is 4.948971643447876 and perplexity is 141.02986034422693
At time: 95.93701171875 and batch: 400, loss is 4.919253787994385 and perplexity is 136.9004183259666
At time: 96.9929986000061 and batch: 450, loss is 4.893427381515503 and perplexity is 133.4100384654155
At time: 98.0578134059906 and batch: 500, loss is 4.892481689453125 and perplexity is 133.2839332887279
At time: 99.11740469932556 and batch: 550, loss is 4.858352880477906 and perplexity is 128.8118587507159
At time: 100.1722469329834 and batch: 600, loss is 4.8460882377624515 and perplexity is 127.24167587399944
At time: 101.2258448600769 and batch: 650, loss is 4.920842018127441 and perplexity is 137.1180204509646
At time: 102.27932047843933 and batch: 700, loss is 4.915452575683593 and perplexity is 136.38101857025603
At time: 103.3308355808258 and batch: 750, loss is 4.867291374206543 and perplexity is 129.9684039279078
At time: 104.38749313354492 and batch: 800, loss is 4.847312812805176 and perplexity is 127.39758829841739
At time: 105.44232702255249 and batch: 850, loss is 4.851204242706299 and perplexity is 127.89431294058105
At time: 106.4979076385498 and batch: 900, loss is 4.869155502319336 and perplexity is 130.21090764221574
At time: 107.5475332736969 and batch: 950, loss is 4.920810270309448 and perplexity is 137.11366732210928
At time: 108.597412109375 and batch: 1000, loss is 4.905260858535766 and perplexity is 134.99812082621946
At time: 109.64706134796143 and batch: 1050, loss is 4.8282046890258785 and perplexity is 124.98636970864057
At time: 110.69827580451965 and batch: 1100, loss is 4.905198402404785 and perplexity is 134.98968962919568
At time: 111.80210423469543 and batch: 1150, loss is 4.82153016090393 and perplexity is 124.15492251469766
At time: 112.86047339439392 and batch: 1200, loss is 4.888709592819214 and perplexity is 132.7821204508857
At time: 113.92030358314514 and batch: 1250, loss is 4.854046354293823 and perplexity is 128.25831987851095
At time: 114.97677421569824 and batch: 1300, loss is 4.878703804016113 and perplexity is 131.46015527810428
At time: 116.03040790557861 and batch: 1350, loss is 4.789914875030518 and perplexity is 120.2911284487345
At time: 117.0835313796997 and batch: 1400, loss is 4.794521036148072 and perplexity is 120.84648682054443
At time: 118.13740515708923 and batch: 1450, loss is 4.739253959655762 and perplexity is 114.34886098670296
At time: 119.19143652915955 and batch: 1500, loss is 4.73136757850647 and perplexity is 113.45060891962036
At time: 120.24495339393616 and batch: 1550, loss is 4.739976377487182 and perplexity is 114.43149848869092
At time: 121.3065345287323 and batch: 1600, loss is 4.806179113388062 and perplexity is 122.26356867323997
At time: 122.3646092414856 and batch: 1650, loss is 4.759988842010498 and perplexity is 116.74462325644174
At time: 123.4240927696228 and batch: 1700, loss is 4.789080629348755 and perplexity is 120.19081794189303
At time: 124.48382234573364 and batch: 1750, loss is 4.802526302337647 and perplexity is 121.81777764939963
At time: 125.53756618499756 and batch: 1800, loss is 4.777775363922119 and perplexity is 118.83968071629424
At time: 126.59070062637329 and batch: 1850, loss is 4.788360891342163 and perplexity is 120.10434316550146
At time: 127.64543867111206 and batch: 1900, loss is 4.843816318511963 and perplexity is 126.95292119897272
At time: 128.70824122428894 and batch: 1950, loss is 4.77084903717041 and perplexity is 118.01940229410806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.750356842750727 and perplexity of 115.62553730115808
finished 3 epochs...
Completing Train Step...
At time: 132.1144721508026 and batch: 50, loss is 4.741111965179443 and perplexity is 114.5615193010263
At time: 133.16692805290222 and batch: 100, loss is 4.703184728622436 and perplexity is 110.29788252096202
At time: 134.22168040275574 and batch: 150, loss is 4.658779029846191 and perplexity is 105.50718236059615
At time: 135.27568101882935 and batch: 200, loss is 4.645568332672119 and perplexity is 104.12252520568516
At time: 136.34025168418884 and batch: 250, loss is 4.651093873977661 and perplexity is 104.69945096523205
At time: 137.39729690551758 and batch: 300, loss is 4.685424766540527 and perplexity is 108.35628866026718
At time: 138.4506106376648 and batch: 350, loss is 4.688130922317505 and perplexity is 108.6499147766104
At time: 139.5493516921997 and batch: 400, loss is 4.653299789428711 and perplexity is 104.93066402630657
At time: 140.60138416290283 and batch: 450, loss is 4.6487022876739506 and perplexity is 104.44935237768294
At time: 141.66533088684082 and batch: 500, loss is 4.6506233978271485 and perplexity is 104.65020395626112
At time: 142.72242641448975 and batch: 550, loss is 4.628578395843506 and perplexity is 102.36843323011345
At time: 143.78155279159546 and batch: 600, loss is 4.616105585098267 and perplexity is 101.09954091320547
At time: 144.84020233154297 and batch: 650, loss is 4.67946491241455 and perplexity is 107.71242156902791
At time: 145.9005584716797 and batch: 700, loss is 4.6785493755340575 and perplexity is 107.61385200351566
At time: 146.95670080184937 and batch: 750, loss is 4.635560388565064 and perplexity is 103.08566984258222
At time: 148.01437330245972 and batch: 800, loss is 4.610695114135742 and perplexity is 100.55402187099523
At time: 149.06739044189453 and batch: 850, loss is 4.614149303436279 and perplexity is 100.90195506508131
At time: 150.12076449394226 and batch: 900, loss is 4.633216896057129 and perplexity is 102.84437219767523
At time: 151.17248249053955 and batch: 950, loss is 4.694085388183594 and perplexity is 109.2987969416414
At time: 152.22913885116577 and batch: 1000, loss is 4.674259157180786 and perplexity is 107.15315403465725
At time: 153.28675317764282 and batch: 1050, loss is 4.607527465820312 and perplexity is 100.23600604007547
At time: 154.34385180473328 and batch: 1100, loss is 4.670519037246704 and perplexity is 106.75313690956735
At time: 155.40123772621155 and batch: 1150, loss is 4.599561004638672 and perplexity is 99.44065207359533
At time: 156.45637702941895 and batch: 1200, loss is 4.670401887893677 and perplexity is 106.74063158115463
At time: 157.5103313922882 and batch: 1250, loss is 4.642858400344848 and perplexity is 103.84074218753321
At time: 158.5755431652069 and batch: 1300, loss is 4.660672664642334 and perplexity is 105.7071637184274
At time: 159.6408679485321 and batch: 1350, loss is 4.552868967056274 and perplexity is 94.90429540790065
At time: 160.69803762435913 and batch: 1400, loss is 4.57351863861084 and perplexity is 96.8844119542364
At time: 161.75056624412537 and batch: 1450, loss is 4.515005283355713 and perplexity is 91.37804880384905
At time: 162.80207443237305 and batch: 1500, loss is 4.503321647644043 and perplexity is 90.31663363787037
At time: 163.85206151008606 and batch: 1550, loss is 4.52672833442688 and perplexity is 92.45558198460077
At time: 164.90327501296997 and batch: 1600, loss is 4.603156690597534 and perplexity is 99.79885303314646
At time: 165.95812249183655 and batch: 1650, loss is 4.553853845596313 and perplexity is 94.9978106548263
At time: 167.0154676437378 and batch: 1700, loss is 4.582211217880249 and perplexity is 97.73025835247996
At time: 168.0717158317566 and batch: 1750, loss is 4.585594034194946 and perplexity is 98.0614216814262
At time: 169.12357592582703 and batch: 1800, loss is 4.556884851455688 and perplexity is 95.28618638904341
At time: 170.17726969718933 and batch: 1850, loss is 4.575773248672485 and perplexity is 97.10309495405555
At time: 171.23091673851013 and batch: 1900, loss is 4.644141044616699 and perplexity is 103.97401837538234
At time: 172.29221081733704 and batch: 1950, loss is 4.57429988861084 and perplexity is 96.96013247555295
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.684478050054506 and perplexity of 108.25375451846782
finished 4 epochs...
Completing Train Step...
At time: 175.6398298740387 and batch: 50, loss is 4.544054336547852 and perplexity is 94.07142522435116
At time: 176.71955847740173 and batch: 100, loss is 4.508021507263184 and perplexity is 90.7421081893929
At time: 177.77911853790283 and batch: 150, loss is 4.466963701248169 and perplexity is 87.09188417277673
At time: 178.8402190208435 and batch: 200, loss is 4.462894058227539 and perplexity is 86.73817152448679
At time: 179.89466762542725 and batch: 250, loss is 4.465132694244385 and perplexity is 86.93256422536462
At time: 180.94633650779724 and batch: 300, loss is 4.502027139663697 and perplexity is 90.19979367631568
At time: 181.99714756011963 and batch: 350, loss is 4.499068241119385 and perplexity is 89.93329610218566
At time: 183.04803705215454 and batch: 400, loss is 4.464843654632569 and perplexity is 86.90744090173946
At time: 184.10241889953613 and batch: 450, loss is 4.470434331893921 and perplexity is 87.39467306525654
At time: 185.15974688529968 and batch: 500, loss is 4.481709260940551 and perplexity is 88.38561772074343
At time: 186.21441316604614 and batch: 550, loss is 4.454253606796264 and perplexity is 85.991943084107
At time: 187.2622253894806 and batch: 600, loss is 4.444068260192871 and perplexity is 85.12053069076693
At time: 188.30825781822205 and batch: 650, loss is 4.501108379364013 and perplexity is 90.11695974493689
At time: 189.35653376579285 and batch: 700, loss is 4.508885555267334 and perplexity is 90.82054760969848
At time: 190.40657114982605 and batch: 750, loss is 4.46248646736145 and perplexity is 86.70282504197324
At time: 191.4624001979828 and batch: 800, loss is 4.446658239364624 and perplexity is 85.34127683290282
At time: 192.57735753059387 and batch: 850, loss is 4.445825395584106 and perplexity is 85.27023047063817
At time: 193.63685846328735 and batch: 900, loss is 4.4583173179626465 and perplexity is 86.3421004908512
At time: 194.6901478767395 and batch: 950, loss is 4.531962413787841 and perplexity is 92.9407704879697
At time: 195.74424409866333 and batch: 1000, loss is 4.496110744476319 and perplexity is 89.66771160707411
At time: 196.79932475090027 and batch: 1050, loss is 4.440010757446289 and perplexity is 84.7758536406149
At time: 197.84882044792175 and batch: 1100, loss is 4.51434552192688 and perplexity is 91.3177809751868
At time: 198.902930021286 and batch: 1150, loss is 4.44392671585083 and perplexity is 85.10848321390233
At time: 199.95762419700623 and batch: 1200, loss is 4.5040061569213865 and perplexity is 90.3784773753852
At time: 201.01239013671875 and batch: 1250, loss is 4.483526182174683 and perplexity is 88.54635340419182
At time: 202.06259417533875 and batch: 1300, loss is 4.491992654800415 and perplexity is 89.29921120925775
At time: 203.11354541778564 and batch: 1350, loss is 4.387056131362915 and perplexity is 80.40337326707322
At time: 204.16803526878357 and batch: 1400, loss is 4.412703599929809 and perplexity is 82.49218816347742
At time: 205.2272880077362 and batch: 1450, loss is 4.34143711566925 and perplexity is 76.81785619508356
At time: 206.2902114391327 and batch: 1500, loss is 4.341439995765686 and perplexity is 76.818077438236
At time: 207.35868668556213 and batch: 1550, loss is 4.360881090164185 and perplexity is 78.32611639970959
At time: 208.4121310710907 and batch: 1600, loss is 4.451319341659546 and perplexity is 85.73998975318875
At time: 209.4637575149536 and batch: 1650, loss is 4.393058481216431 and perplexity is 80.8874337396602
At time: 210.514466047287 and batch: 1700, loss is 4.428583421707153 and perplexity is 83.81260565957338
At time: 211.56663393974304 and batch: 1750, loss is 4.427204875946045 and perplexity is 83.69714574898398
At time: 212.62112832069397 and batch: 1800, loss is 4.399152507781983 and perplexity is 81.38186893012285
At time: 213.67728567123413 and batch: 1850, loss is 4.425522356033325 and perplexity is 83.55644203621564
At time: 214.73092126846313 and batch: 1900, loss is 4.492310094833374 and perplexity is 89.32756285354255
At time: 215.79189538955688 and batch: 1950, loss is 4.427513494491577 and perplexity is 83.7229802266646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6579493323037795 and perplexity of 105.41967961611053
finished 5 epochs...
Completing Train Step...
At time: 219.1933560371399 and batch: 50, loss is 4.40046576499939 and perplexity is 81.48881446498892
At time: 220.25490975379944 and batch: 100, loss is 4.359788112640381 and perplexity is 78.24055448210196
At time: 221.317449092865 and batch: 150, loss is 4.3166892528533936 and perplexity is 74.94010937409946
At time: 222.37507104873657 and batch: 200, loss is 4.3190734004974365 and perplexity is 75.11899081445779
At time: 223.4308226108551 and batch: 250, loss is 4.3179019260406495 and perplexity is 75.03104236024087
At time: 224.48644423484802 and batch: 300, loss is 4.355062932968139 and perplexity is 77.8717258814674
At time: 225.54613542556763 and batch: 350, loss is 4.352684202194214 and perplexity is 77.6867101492429
At time: 226.60233235359192 and batch: 400, loss is 4.316766958236695 and perplexity is 74.9459328502778
At time: 227.66056632995605 and batch: 450, loss is 4.332025527954102 and perplexity is 76.09826974055017
At time: 228.72064661979675 and batch: 500, loss is 4.3495744037628175 and perplexity is 77.4454953989024
At time: 229.78094935417175 and batch: 550, loss is 4.321651487350464 and perplexity is 75.31290395214054
At time: 230.83755826950073 and batch: 600, loss is 4.313938412666321 and perplexity is 74.73424439026199
At time: 231.893061876297 and batch: 650, loss is 4.35903299331665 and perplexity is 78.18149582848473
At time: 232.9567093849182 and batch: 700, loss is 4.3755684757232665 and perplexity is 79.48501201101354
At time: 234.01745796203613 and batch: 750, loss is 4.331772260665893 and perplexity is 76.07899897856547
At time: 235.0797197818756 and batch: 800, loss is 4.306443166732788 and perplexity is 74.1761868507292
At time: 236.1389021873474 and batch: 850, loss is 4.311528692245483 and perplexity is 74.55437256286596
At time: 237.1952805519104 and batch: 900, loss is 4.32863528251648 and perplexity is 75.84071476273523
At time: 238.2508602142334 and batch: 950, loss is 4.398529977798462 and perplexity is 81.33122204283748
At time: 239.30718874931335 and batch: 1000, loss is 4.362580261230469 and perplexity is 78.45931900538879
At time: 240.36950945854187 and batch: 1050, loss is 4.320048875808716 and perplexity is 75.19230328684556
At time: 241.4355034828186 and batch: 1100, loss is 4.377928466796875 and perplexity is 79.67281745226154
At time: 242.49651551246643 and batch: 1150, loss is 4.311593399047852 and perplexity is 74.55919689399894
At time: 243.55468082427979 and batch: 1200, loss is 4.375182466506958 and perplexity is 79.45433598481424
At time: 244.61258959770203 and batch: 1250, loss is 4.352761936187744 and perplexity is 77.69274928218694
At time: 245.67104625701904 and batch: 1300, loss is 4.363902893066406 and perplexity is 78.56316045539715
At time: 246.73242092132568 and batch: 1350, loss is 4.256566853523254 and perplexity is 70.56729923266859
At time: 247.79172658920288 and batch: 1400, loss is 4.291192626953125 and perplexity is 73.05354218953369
At time: 248.84807705879211 and batch: 1450, loss is 4.2106475925445555 and perplexity is 67.40017353003562
At time: 249.90392136573792 and batch: 1500, loss is 4.213136987686157 and perplexity is 67.56816821037846
At time: 250.96118140220642 and batch: 1550, loss is 4.230785465240478 and perplexity is 68.77122837443412
At time: 252.01964402198792 and batch: 1600, loss is 4.325653228759766 and perplexity is 75.61489055168144
At time: 253.08561968803406 and batch: 1650, loss is 4.263755931854248 and perplexity is 71.07644101170159
At time: 254.1470000743866 and batch: 1700, loss is 4.300161843299866 and perplexity is 73.71172248267833
At time: 255.20743989944458 and batch: 1750, loss is 4.30151611328125 and perplexity is 73.81161568162567
At time: 256.2646975517273 and batch: 1800, loss is 4.271808547973633 and perplexity is 71.65110296705508
At time: 257.3183934688568 and batch: 1850, loss is 4.296388721466064 and perplexity is 73.43412321044494
At time: 258.38100385665894 and batch: 1900, loss is 4.371303005218506 and perplexity is 79.14669309434458
At time: 259.4450042247772 and batch: 1950, loss is 4.303898487091065 and perplexity is 73.98767217460427
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.640529330941134 and perplexity of 103.5991713189061
finished 6 epochs...
Completing Train Step...
At time: 262.7504811286926 and batch: 50, loss is 4.277665643692017 and perplexity is 72.07200175443992
At time: 263.82500290870667 and batch: 100, loss is 4.241093893051147 and perplexity is 69.48381814751016
At time: 264.88516330718994 and batch: 150, loss is 4.20524829864502 and perplexity is 67.0372408560489
At time: 265.94489789009094 and batch: 200, loss is 4.2039814281463626 and perplexity is 66.9523671266605
At time: 267.0000901222229 and batch: 250, loss is 4.200428099632263 and perplexity is 66.71488554637126
At time: 268.05306601524353 and batch: 300, loss is 4.22996253490448 and perplexity is 68.71465772440551
At time: 269.11077976226807 and batch: 350, loss is 4.225667161941528 and perplexity is 68.42013563539984
At time: 270.15971994400024 and batch: 400, loss is 4.195035581588745 and perplexity is 66.35609259048758
At time: 271.2086145877838 and batch: 450, loss is 4.2170197057724 and perplexity is 67.83102633090616
At time: 272.2578966617584 and batch: 500, loss is 4.232818789482117 and perplexity is 68.91120484075961
At time: 273.334125995636 and batch: 550, loss is 4.209423475265503 and perplexity is 67.31771829074427
At time: 274.3822660446167 and batch: 600, loss is 4.20125078201294 and perplexity is 66.76979328995891
At time: 275.43384861946106 and batch: 650, loss is 4.243351612091065 and perplexity is 69.64087030982476
At time: 276.4877061843872 and batch: 700, loss is 4.259826188087463 and perplexity is 70.79767690516908
At time: 277.5408318042755 and batch: 750, loss is 4.2211794090270995 and perplexity is 68.11377093102398
At time: 278.59176230430603 and batch: 800, loss is 4.192381672859192 and perplexity is 66.1802230511796
At time: 279.6410663127899 and batch: 850, loss is 4.198864850997925 and perplexity is 66.61067506731742
At time: 280.6900510787964 and batch: 900, loss is 4.2147493648529055 and perplexity is 67.67720145973902
At time: 281.7419955730438 and batch: 950, loss is 4.288160123825073 and perplexity is 72.83234265797832
At time: 282.79542565345764 and batch: 1000, loss is 4.2506550741195674 and perplexity is 70.15135163313379
At time: 283.85025572776794 and batch: 1050, loss is 4.213391799926757 and perplexity is 67.5853876004759
At time: 284.89989471435547 and batch: 1100, loss is 4.265418066978454 and perplexity is 71.19467789642925
At time: 285.9500730037689 and batch: 1150, loss is 4.205379457473755 and perplexity is 67.0460339586751
At time: 286.99913573265076 and batch: 1200, loss is 4.273054809570312 and perplexity is 71.74045465126412
At time: 288.05665373802185 and batch: 1250, loss is 4.253381156921387 and perplexity is 70.34285092921975
At time: 289.1145718097687 and batch: 1300, loss is 4.25960045337677 and perplexity is 70.78169721570826
At time: 290.1677188873291 and batch: 1350, loss is 4.147963242530823 and perplexity is 63.30493210913398
At time: 291.22119760513306 and batch: 1400, loss is 4.180244374275207 and perplexity is 65.38182889895612
At time: 292.2771587371826 and batch: 1450, loss is 4.097698531150818 and perplexity is 60.20157598655842
At time: 293.32970237731934 and batch: 1500, loss is 4.104883236885071 and perplexity is 60.6356641252289
At time: 294.3831396102905 and batch: 1550, loss is 4.116822400093079 and perplexity is 61.363942079195226
At time: 295.4436733722687 and batch: 1600, loss is 4.223877644538879 and perplexity is 68.29780610005025
At time: 296.49625039100647 and batch: 1650, loss is 4.164444808959961 and perplexity is 64.35694212539592
At time: 297.55417919158936 and batch: 1700, loss is 4.194500765800476 and perplexity is 66.32061379267863
At time: 298.60574865341187 and batch: 1750, loss is 4.194943656921387 and perplexity is 66.34999310909971
At time: 299.6631498336792 and batch: 1800, loss is 4.158598775863648 and perplexity is 63.981806906593405
At time: 300.72120332717896 and batch: 1850, loss is 4.187429060935974 and perplexity is 65.85326839747826
At time: 301.7758421897888 and batch: 1900, loss is 4.2652885580062865 and perplexity is 71.18545814390428
At time: 302.8301076889038 and batch: 1950, loss is 4.191991415023804 and perplexity is 66.15440073959358
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.636251476199128 and perplexity of 103.15693569689859
finished 7 epochs...
Completing Train Step...
At time: 306.21255016326904 and batch: 50, loss is 4.181080760955811 and perplexity is 65.43653626486761
At time: 307.26628828048706 and batch: 100, loss is 4.139062132835388 and perplexity is 62.743948357004875
At time: 308.3260555267334 and batch: 150, loss is 4.109734735488892 and perplexity is 60.93055271245869
At time: 309.378160238266 and batch: 200, loss is 4.101646361351013 and perplexity is 60.43971133601423
At time: 310.4328453540802 and batch: 250, loss is 4.099354400634765 and perplexity is 60.30134451815726
At time: 311.48962354660034 and batch: 300, loss is 4.127664799690247 and perplexity is 62.0328944310724
At time: 312.54504442214966 and batch: 350, loss is 4.124069900512695 and perplexity is 61.810292784867364
At time: 313.6043267250061 and batch: 400, loss is 4.091083555221558 and perplexity is 59.80465825846877
At time: 314.65671277046204 and batch: 450, loss is 4.118641948699951 and perplexity is 61.47569839671037
At time: 315.71314334869385 and batch: 500, loss is 4.135213274955749 and perplexity is 62.502919956544126
At time: 316.7636408805847 and batch: 550, loss is 4.10998140335083 and perplexity is 60.94558417543623
At time: 317.81496262550354 and batch: 600, loss is 4.105945010185241 and perplexity is 60.70007964572343
At time: 318.8689351081848 and batch: 650, loss is 4.144085259437561 and perplexity is 63.05991205158127
At time: 319.9313876628876 and batch: 700, loss is 4.161813645362854 and perplexity is 64.18783105905858
At time: 320.9865815639496 and batch: 750, loss is 4.124197244644165 and perplexity is 61.818164464113394
At time: 322.0406811237335 and batch: 800, loss is 4.093446011543274 and perplexity is 59.94611117381687
At time: 323.0922303199768 and batch: 850, loss is 4.099360318183899 and perplexity is 60.30170135538205
At time: 324.15168476104736 and batch: 900, loss is 4.110680904388428 and perplexity is 60.988230588670156
At time: 325.2152409553528 and batch: 950, loss is 4.187248697280884 and perplexity is 65.84139193236398
At time: 326.32362246513367 and batch: 1000, loss is 4.155140137672424 and perplexity is 63.760899225764966
At time: 327.3806703090668 and batch: 1050, loss is 4.118294248580932 and perplexity is 61.45432700469417
At time: 328.43646240234375 and batch: 1100, loss is 4.166022872924804 and perplexity is 64.45858167241218
At time: 329.4943017959595 and batch: 1150, loss is 4.1066802215576175 and perplexity is 60.744723443886194
At time: 330.555517911911 and batch: 1200, loss is 4.168349375724793 and perplexity is 64.6087193232691
At time: 331.6152033805847 and batch: 1250, loss is 4.160279097557068 and perplexity is 64.08940730104402
At time: 332.6743755340576 and batch: 1300, loss is 4.157586126327515 and perplexity is 63.91704855380039
At time: 333.7441313266754 and batch: 1350, loss is 4.053530921936035 and perplexity is 57.600481205899385
At time: 334.79983496665955 and batch: 1400, loss is 4.087994003295899 and perplexity is 59.62017379529424
At time: 335.85442638397217 and batch: 1450, loss is 4.007069244384765 and perplexity is 54.98548516898886
At time: 336.9103238582611 and batch: 1500, loss is 4.014209175109864 and perplexity is 55.379482607404015
At time: 337.9663894176483 and batch: 1550, loss is 4.023631463050842 and perplexity is 55.90375005932018
At time: 339.02293395996094 and batch: 1600, loss is 4.130042781829834 and perplexity is 62.18058307698171
At time: 340.0805594921112 and batch: 1650, loss is 4.07250641822815 and perplexity is 58.70391491537774
At time: 341.13636565208435 and batch: 1700, loss is 4.1041385316848755 and perplexity is 60.59052524050476
At time: 342.1877992153168 and batch: 1750, loss is 4.09889060497284 and perplexity is 60.27338350076196
At time: 343.2351670265198 and batch: 1800, loss is 4.06599603176117 and perplexity is 58.322971133304094
At time: 344.2831189632416 and batch: 1850, loss is 4.094988131523133 and perplexity is 60.03862658617125
At time: 345.33194279670715 and batch: 1900, loss is 4.175704460144043 and perplexity is 65.085673778092
At time: 346.389771938324 and batch: 1950, loss is 4.102040457725525 and perplexity is 60.463535101249704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.639628849473111 and perplexity of 103.50592417499429
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 349.7604751586914 and batch: 50, loss is 4.1090948152542115 and perplexity is 60.89157449167397
At time: 350.85086941719055 and batch: 100, loss is 4.103140850067138 and perplexity is 60.53010533219087
At time: 351.9148359298706 and batch: 150, loss is 4.073545212745667 and perplexity is 58.76492790484153
At time: 353.0064945220947 and batch: 200, loss is 4.063191304206848 and perplexity is 58.159620273528546
At time: 354.0708336830139 and batch: 250, loss is 4.058446388244629 and perplexity is 57.88431143811025
At time: 355.1395447254181 and batch: 300, loss is 4.079398179054261 and perplexity is 59.109885576035694
At time: 356.2067003250122 and batch: 350, loss is 4.077298736572265 and perplexity is 58.9859179481376
At time: 357.2728614807129 and batch: 400, loss is 4.029978947639465 and perplexity is 56.25972683460764
At time: 358.3355236053467 and batch: 450, loss is 4.050412440299988 and perplexity is 57.42113495237445
At time: 359.4000012874603 and batch: 500, loss is 4.067697057723999 and perplexity is 58.42226444774206
At time: 360.4652192592621 and batch: 550, loss is 4.042223062515259 and perplexity is 56.95281184024014
At time: 361.52780985832214 and batch: 600, loss is 4.01899929523468 and perplexity is 55.64539334528328
At time: 362.5949721336365 and batch: 650, loss is 4.049520230293274 and perplexity is 57.369926089100176
At time: 363.66092324256897 and batch: 700, loss is 4.065094661712647 and perplexity is 58.27042423963942
At time: 364.72682332992554 and batch: 750, loss is 4.015679960250854 and perplexity is 55.460993855611264
At time: 365.79335927963257 and batch: 800, loss is 3.9785341596603394 and perplexity is 53.438644267480605
At time: 366.8577241897583 and batch: 850, loss is 3.9851541328430176 and perplexity is 53.79358019638909
At time: 367.920236825943 and batch: 900, loss is 3.9849700498580933 and perplexity is 53.783678624960146
At time: 368.98078989982605 and batch: 950, loss is 4.0544529628753665 and perplexity is 57.65361570002143
At time: 370.04069924354553 and batch: 1000, loss is 4.013250827789307 and perplexity is 55.326435251589054
At time: 371.1010675430298 and batch: 1050, loss is 3.9800016832351686 and perplexity is 53.517124309321105
At time: 372.1659781932831 and batch: 1100, loss is 4.006187624931336 and perplexity is 54.937030258142094
At time: 373.2302129268646 and batch: 1150, loss is 3.9561681747436523 and perplexity is 52.25670326365995
At time: 374.29168462753296 and batch: 1200, loss is 4.000471086502075 and perplexity is 54.623876543893324
At time: 375.3502993583679 and batch: 1250, loss is 3.9815168619155883 and perplexity is 53.598273777559044
At time: 376.409606218338 and batch: 1300, loss is 3.970220060348511 and perplexity is 52.99619191702174
At time: 377.47058367729187 and batch: 1350, loss is 3.872183198928833 and perplexity is 48.047168185226575
At time: 378.535174369812 and batch: 1400, loss is 3.895015277862549 and perplexity is 49.15680436784747
At time: 379.5992076396942 and batch: 1450, loss is 3.802917718887329 and perplexity is 44.831800441230016
At time: 380.65983152389526 and batch: 1500, loss is 3.811384873390198 and perplexity is 45.21300982408737
At time: 381.71892762184143 and batch: 1550, loss is 3.8082888460159303 and perplexity is 45.07324557660821
At time: 382.7796823978424 and batch: 1600, loss is 3.906383023262024 and perplexity is 49.718794633733346
At time: 383.8404338359833 and batch: 1650, loss is 3.840306034088135 and perplexity is 46.539714999871705
At time: 384.9062023162842 and batch: 1700, loss is 3.860786728858948 and perplexity is 47.502708423585204
At time: 385.9700903892517 and batch: 1750, loss is 3.844860076904297 and perplexity is 46.75214218875726
At time: 387.0334734916687 and batch: 1800, loss is 3.8001558351516724 and perplexity is 44.70815105196954
At time: 388.0919609069824 and batch: 1850, loss is 3.8180361795425415 and perplexity is 45.514737724450114
At time: 389.14922976493835 and batch: 1900, loss is 3.8963653326034544 and perplexity is 49.22321356256942
At time: 390.2082004547119 and batch: 1950, loss is 3.8207736158370973 and perplexity is 45.639502108800464
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5591180845748545 and perplexity of 95.49922044510195
finished 9 epochs...
Completing Train Step...
At time: 393.58871579170227 and batch: 50, loss is 4.009994978904724 and perplexity is 55.146593666467716
At time: 394.6403715610504 and batch: 100, loss is 3.9893303442001344 and perplexity is 54.01870331060565
At time: 395.69984579086304 and batch: 150, loss is 3.956900568008423 and perplexity is 52.294989739836616
At time: 396.753623008728 and batch: 200, loss is 3.9480978870391845 and perplexity is 51.83667379286356
At time: 397.80934953689575 and batch: 250, loss is 3.9441479539871214 and perplexity is 51.6323262469882
At time: 398.86591958999634 and batch: 300, loss is 3.9676740550994873 and perplexity is 52.861434952984446
At time: 399.91849756240845 and batch: 350, loss is 3.9697312545776366 and perplexity is 52.97029340276561
At time: 400.97067737579346 and batch: 400, loss is 3.925068964958191 and perplexity is 50.65657146670919
At time: 402.0258903503418 and batch: 450, loss is 3.949591693878174 and perplexity is 51.91416563519783
At time: 403.08103609085083 and batch: 500, loss is 3.971330122947693 and perplexity is 53.05505367163975
At time: 404.1374373435974 and batch: 550, loss is 3.9474772787094117 and perplexity is 51.80451350182447
At time: 405.19063234329224 and batch: 600, loss is 3.9294921350479126 and perplexity is 50.881130363452456
At time: 406.24249243736267 and batch: 650, loss is 3.9617459678649904 and perplexity is 52.5489947565986
At time: 407.31780457496643 and batch: 700, loss is 3.9821999168395994 and perplexity is 53.63489684874193
At time: 408.3694953918457 and batch: 750, loss is 3.936020727157593 and perplexity is 51.214399214140535
At time: 409.42393827438354 and batch: 800, loss is 3.898259482383728 and perplexity is 49.31653805910813
At time: 410.4760549068451 and batch: 850, loss is 3.905870804786682 and perplexity is 49.69333426974129
At time: 411.52246952056885 and batch: 900, loss is 3.9101998615264892 and perplexity is 49.90892585078346
At time: 412.56893706321716 and batch: 950, loss is 3.982318344116211 and perplexity is 53.64124905963716
At time: 413.6152358055115 and batch: 1000, loss is 3.9439287853240965 and perplexity is 51.621011299062076
At time: 414.67254614830017 and batch: 1050, loss is 3.9142582559585573 and perplexity is 50.11188752826329
At time: 415.73317766189575 and batch: 1100, loss is 3.9426556921005247 and perplexity is 51.555334754435805
At time: 416.7895448207855 and batch: 1150, loss is 3.8967198228836057 and perplexity is 49.24066580647782
At time: 417.8490867614746 and batch: 1200, loss is 3.9465144538879393 and perplexity is 51.75465883486742
At time: 418.911244392395 and batch: 1250, loss is 3.9300923347473145 and perplexity is 50.91167836913669
At time: 419.9675283432007 and batch: 1300, loss is 3.922639684677124 and perplexity is 50.533661807988736
At time: 421.0242829322815 and batch: 1350, loss is 3.8255935859680177 and perplexity is 45.86001414956675
At time: 422.0802597999573 and batch: 1400, loss is 3.8518634128570555 and perplexity is 47.0807123476803
At time: 423.13359665870667 and batch: 1450, loss is 3.7645000553131105 and perplexity is 43.14213178781962
At time: 424.1915786266327 and batch: 1500, loss is 3.774720392227173 and perplexity is 43.58531981760134
At time: 425.2513587474823 and batch: 1550, loss is 3.775563611984253 and perplexity is 43.62208731975378
At time: 426.3075988292694 and batch: 1600, loss is 3.877717761993408 and perplexity is 48.313825502819064
At time: 427.365047454834 and batch: 1650, loss is 3.8150677394866945 and perplexity is 45.37983028524361
At time: 428.41963481903076 and batch: 1700, loss is 3.8389483976364134 and perplexity is 46.47657385739182
At time: 429.47265434265137 and batch: 1750, loss is 3.8291971349716185 and perplexity is 46.02557107495315
At time: 430.52405762672424 and batch: 1800, loss is 3.787219247817993 and perplexity is 44.133505143992764
At time: 431.58387327194214 and batch: 1850, loss is 3.80937753200531 and perplexity is 45.122342908502674
At time: 432.64156460762024 and batch: 1900, loss is 3.8933291482925414 and perplexity is 49.07398946438501
At time: 433.6982190608978 and batch: 1950, loss is 3.820161519050598 and perplexity is 45.61157486418253
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.559404807867006 and perplexity of 95.52660622186829
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 437.10465240478516 and batch: 50, loss is 3.9787027835845947 and perplexity is 53.44765606116453
At time: 438.1848409175873 and batch: 100, loss is 3.9756841802597047 and perplexity is 53.28656205065217
At time: 439.23976612091064 and batch: 150, loss is 3.9542360877990723 and perplexity is 52.155836242822204
At time: 440.2944655418396 and batch: 200, loss is 3.9487881088256835 and perplexity is 51.87246494495057
At time: 441.348108291626 and batch: 250, loss is 3.944944005012512 and perplexity is 51.673444577213516
At time: 442.3990273475647 and batch: 300, loss is 3.9639809226989744 and perplexity is 52.66657072600023
At time: 443.4601159095764 and batch: 350, loss is 3.972617073059082 and perplexity is 53.12337683369276
At time: 444.5192356109619 and batch: 400, loss is 3.9330172681808473 and perplexity is 51.060809632543936
At time: 445.5765986442566 and batch: 450, loss is 3.9565345239639282 and perplexity is 52.27585097331488
At time: 446.63733553886414 and batch: 500, loss is 3.975968322753906 and perplexity is 53.30170517860186
At time: 447.69984555244446 and batch: 550, loss is 3.947588810920715 and perplexity is 51.81029169599222
At time: 448.75838136672974 and batch: 600, loss is 3.9220715951919556 and perplexity is 50.50496231877942
At time: 449.8179829120636 and batch: 650, loss is 3.9495971250534057 and perplexity is 51.914447590894085
At time: 450.8771150112152 and batch: 700, loss is 3.9635395336151125 and perplexity is 52.64332940620709
At time: 451.9349329471588 and batch: 750, loss is 3.913034086227417 and perplexity is 50.05057960568872
At time: 452.997052192688 and batch: 800, loss is 3.875875630378723 and perplexity is 48.224907002369385
At time: 454.05449771881104 and batch: 850, loss is 3.8850537538528442 and perplexity is 48.66955856546602
At time: 455.1182246208191 and batch: 900, loss is 3.884089570045471 and perplexity is 48.62265478075374
At time: 456.18101692199707 and batch: 950, loss is 3.9558996772766113 and perplexity is 52.24267435464529
At time: 457.24327778816223 and batch: 1000, loss is 3.914938631057739 and perplexity is 50.145994009995285
At time: 458.3053421974182 and batch: 1050, loss is 3.8808578300476073 and perplexity is 48.46577264018238
At time: 459.35992908477783 and batch: 1100, loss is 3.905925822257996 and perplexity is 49.69606834654428
At time: 460.45214891433716 and batch: 1150, loss is 3.8633226346969605 and perplexity is 47.623323689037996
At time: 461.513480424881 and batch: 1200, loss is 3.9042242527008058 and perplexity is 49.61157893222687
At time: 462.5763010978699 and batch: 1250, loss is 3.8834262895584106 and perplexity is 48.59041501579406
At time: 463.63077092170715 and batch: 1300, loss is 3.8721042346954344 and perplexity is 48.04337432721536
At time: 464.6917724609375 and batch: 1350, loss is 3.7724416399002076 and perplexity is 43.48611274574785
At time: 465.7436640262604 and batch: 1400, loss is 3.800185132026672 and perplexity is 44.709460880269226
At time: 466.80448150634766 and batch: 1450, loss is 3.711809763908386 and perplexity is 40.92780921506192
At time: 467.8674199581146 and batch: 1500, loss is 3.718417372703552 and perplexity is 41.199139602524696
At time: 468.9214563369751 and batch: 1550, loss is 3.7213417387008665 and perplexity is 41.31979730314757
At time: 469.97798252105713 and batch: 1600, loss is 3.8184923267364503 and perplexity is 45.53550388019639
At time: 471.03443479537964 and batch: 1650, loss is 3.748595423698425 and perplexity is 42.461399819868056
At time: 472.0966227054596 and batch: 1700, loss is 3.766221261024475 and perplexity is 43.21645221347566
At time: 473.1498613357544 and batch: 1750, loss is 3.754981155395508 and perplexity is 42.73341450866962
At time: 474.20102429389954 and batch: 1800, loss is 3.708160276412964 and perplexity is 40.77871590967148
At time: 475.25562381744385 and batch: 1850, loss is 3.724422788619995 and perplexity is 41.44730198456561
At time: 476.3093755245209 and batch: 1900, loss is 3.808666214942932 and perplexity is 45.090258028711446
At time: 477.3647668361664 and batch: 1950, loss is 3.739048943519592 and perplexity is 42.057971631597525
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.534560376544332 and perplexity of 93.18254106775385
finished 11 epochs...
Completing Train Step...
At time: 480.7079722881317 and batch: 50, loss is 3.9594431161880492 and perplexity is 52.428121445972025
At time: 481.76539874076843 and batch: 100, loss is 3.9439479064941407 and perplexity is 51.62199836263386
At time: 482.8225157260895 and batch: 150, loss is 3.914259505271912 and perplexity is 50.11195013375271
At time: 483.8862648010254 and batch: 200, loss is 3.907757530212402 and perplexity is 49.78718045014522
At time: 484.93827843666077 and batch: 250, loss is 3.9018524074554444 and perplexity is 49.49404738304393
At time: 485.9889557361603 and batch: 300, loss is 3.92011353969574 and perplexity is 50.40616755410572
At time: 487.03919100761414 and batch: 350, loss is 3.930361042022705 and perplexity is 50.925360545684676
At time: 488.121604681015 and batch: 400, loss is 3.8915420818328856 and perplexity is 48.98636929862012
At time: 489.17696046829224 and batch: 450, loss is 3.9154497957229615 and perplexity is 50.17163342265826
At time: 490.2321705818176 and batch: 500, loss is 3.9361923217773436 and perplexity is 51.22318808353923
At time: 491.2816655635834 and batch: 550, loss is 3.9080882930755614 and perplexity is 49.80365092425997
At time: 492.33077597618103 and batch: 600, loss is 3.886276569366455 and perplexity is 48.72910885881138
At time: 493.3804540634155 and batch: 650, loss is 3.9149197435379026 and perplexity is 50.14504688548314
At time: 494.43373227119446 and batch: 700, loss is 3.9325885915756227 and perplexity is 51.03892574890023
At time: 495.48953223228455 and batch: 750, loss is 3.884553899765015 and perplexity is 48.645236966795885
At time: 496.53925490379333 and batch: 800, loss is 3.8475823307037356 and perplexity is 46.87958677501299
At time: 497.58978247642517 and batch: 850, loss is 3.8570791053771973 and perplexity is 47.326912360574035
At time: 498.64009070396423 and batch: 900, loss is 3.8584042406082153 and perplexity is 47.38966849051448
At time: 499.69418454170227 and batch: 950, loss is 3.9309278678894044 and perplexity is 50.95423453980327
At time: 500.7520241737366 and batch: 1000, loss is 3.890231671333313 and perplexity is 48.92221908669065
At time: 501.8071448802948 and batch: 1050, loss is 3.8581308269500734 and perplexity is 47.37671327904094
At time: 502.85905504226685 and batch: 1100, loss is 3.884699511528015 and perplexity is 48.65232080124447
At time: 503.91891622543335 and batch: 1150, loss is 3.844162034988403 and perplexity is 46.71951862148507
At time: 504.97148275375366 and batch: 1200, loss is 3.886560683250427 and perplexity is 48.742955442101895
At time: 506.02776050567627 and batch: 1250, loss is 3.868246340751648 and perplexity is 47.85838514811429
At time: 507.0840504169464 and batch: 1300, loss is 3.85795220375061 and perplexity is 47.36825145469656
At time: 508.1400399208069 and batch: 1350, loss is 3.760144104957581 and perplexity is 42.954615505826915
At time: 509.1951382160187 and batch: 1400, loss is 3.7896896743774415 and perplexity is 44.24266851178486
At time: 510.2470166683197 and batch: 1450, loss is 3.7037686586380003 and perplexity is 40.60002403643784
At time: 511.30027198791504 and batch: 1500, loss is 3.7120264196395873 and perplexity is 40.936677420132916
At time: 512.3586013317108 and batch: 1550, loss is 3.71685941696167 and perplexity is 41.13500314027795
At time: 513.4138813018799 and batch: 1600, loss is 3.8155892133712768 and perplexity is 45.403500852879155
At time: 514.4702944755554 and batch: 1650, loss is 3.748413166999817 and perplexity is 42.453661650506625
At time: 515.5267820358276 and batch: 1700, loss is 3.7678996467590333 and perplexity is 43.28904699434979
At time: 516.578907251358 and batch: 1750, loss is 3.758554606437683 and perplexity is 42.886393441856086
At time: 517.631618976593 and batch: 1800, loss is 3.7135203218460084 and perplexity is 40.997878515698154
At time: 518.6857604980469 and batch: 1850, loss is 3.7308924770355225 and perplexity is 41.71632241488875
At time: 519.7408132553101 and batch: 1900, loss is 3.8162013626098634 and perplexity is 45.43130308004332
At time: 520.7981948852539 and batch: 1950, loss is 3.7469807720184325 and perplexity is 42.392894770094216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.534056197765262 and perplexity of 93.13557224930338
finished 12 epochs...
Completing Train Step...
At time: 524.160219669342 and batch: 50, loss is 3.9437633657455446 and perplexity is 51.61247287935893
At time: 525.2472882270813 and batch: 100, loss is 3.9255807876586912 and perplexity is 50.682505286107954
At time: 526.313000202179 and batch: 150, loss is 3.8950011920928955 and perplexity is 49.1561119613008
At time: 527.3744380474091 and batch: 200, loss is 3.888204712867737 and perplexity is 48.82315621264086
At time: 528.4311995506287 and batch: 250, loss is 3.880659384727478 and perplexity is 48.45615578865663
At time: 529.4948272705078 and batch: 300, loss is 3.900161027908325 and perplexity is 49.4104049191126
At time: 530.5576956272125 and batch: 350, loss is 3.9100820636749267 and perplexity is 49.9030470328073
At time: 531.6191320419312 and batch: 400, loss is 3.871738157272339 and perplexity is 48.02578995136272
At time: 532.6753499507904 and batch: 450, loss is 3.8958413553237916 and perplexity is 49.197428473021134
At time: 533.7313606739044 and batch: 500, loss is 3.9173500204086302 and perplexity is 50.26706143762848
At time: 534.7883057594299 and batch: 550, loss is 3.8891624927520754 and perplexity is 48.86994045047577
At time: 535.8565533161163 and batch: 600, loss is 3.8682309007644653 and perplexity is 47.85764622096555
At time: 536.9175839424133 and batch: 650, loss is 3.8975537061691283 and perplexity is 49.28174389944907
At time: 537.9771761894226 and batch: 700, loss is 3.9161310815811157 and perplexity is 50.20582629322664
At time: 539.034215927124 and batch: 750, loss is 3.868883285522461 and perplexity is 47.888878006376345
At time: 540.0902450084686 and batch: 800, loss is 3.8319447660446166 and perplexity is 46.15220625790388
At time: 541.1738348007202 and batch: 850, loss is 3.8417116355895997 and perplexity is 46.60517728932153
At time: 542.2297410964966 and batch: 900, loss is 3.8438762855529784 and perplexity is 46.70617045262236
At time: 543.2922987937927 and batch: 950, loss is 3.9166053438186648 and perplexity is 50.22964266789964
At time: 544.3579497337341 and batch: 1000, loss is 3.8765649080276487 and perplexity is 48.25815881143552
At time: 545.4164729118347 and batch: 1050, loss is 3.845577607154846 and perplexity is 46.78570030309698
At time: 546.4676277637482 and batch: 1100, loss is 3.8727151918411256 and perplexity is 48.07273573843238
At time: 547.5200455188751 and batch: 1150, loss is 3.8328969717025756 and perplexity is 46.19617357947405
At time: 548.5705888271332 and batch: 1200, loss is 3.8758361864089967 and perplexity is 48.223004858111835
At time: 549.6264448165894 and batch: 1250, loss is 3.8589820051193238 and perplexity is 47.417056470301
At time: 550.6873235702515 and batch: 1300, loss is 3.84903293132782 and perplexity is 46.94763967970533
At time: 551.7480752468109 and batch: 1350, loss is 3.7518875789642334 and perplexity is 42.60141969800358
At time: 552.8064706325531 and batch: 1400, loss is 3.7822123908996583 and perplexity is 43.91308725930173
At time: 553.8622620105743 and batch: 1450, loss is 3.697850437164307 and perplexity is 40.360453716710616
At time: 554.9203772544861 and batch: 1500, loss is 3.7063627433776856 and perplexity is 40.70548066179567
At time: 555.9797217845917 and batch: 1550, loss is 3.712072339057922 and perplexity is 40.938557251708666
At time: 557.0413122177124 and batch: 1600, loss is 3.8113654041290284 and perplexity is 45.21212956875984
At time: 558.1007599830627 and batch: 1650, loss is 3.745906891822815 and perplexity is 42.34739431535699
At time: 559.1584866046906 and batch: 1700, loss is 3.765818991661072 and perplexity is 43.199071054943374
At time: 560.2156980037689 and batch: 1750, loss is 3.757348666191101 and perplexity is 42.834706186108804
At time: 561.2770338058472 and batch: 1800, loss is 3.713106575012207 and perplexity is 40.980919281926276
At time: 562.3375172615051 and batch: 1850, loss is 3.731146903038025 and perplexity is 41.72693748235721
At time: 563.3976182937622 and batch: 1900, loss is 3.816980676651001 and perplexity is 45.46672213193042
At time: 564.458498954773 and batch: 1950, loss is 3.7479699230194092 and perplexity is 42.4348484902518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5348084915515985 and perplexity of 93.2056639230531
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 567.8357248306274 and batch: 50, loss is 3.9363561916351317 and perplexity is 51.2315827078801
At time: 568.8896539211273 and batch: 100, loss is 3.9267497396469118 and perplexity is 50.74178534244975
At time: 569.9437894821167 and batch: 150, loss is 3.9010542345047 and perplexity is 49.45455833484145
At time: 570.9948110580444 and batch: 200, loss is 3.8961635303497313 and perplexity is 49.21328120935634
At time: 572.0420711040497 and batch: 250, loss is 3.8904319763183595 and perplexity is 48.93201943254955
At time: 573.090339422226 and batch: 300, loss is 3.9075924015045165 and perplexity is 49.778959836116584
At time: 574.1417887210846 and batch: 350, loss is 3.918498077392578 and perplexity is 50.324804028124404
At time: 575.1960394382477 and batch: 400, loss is 3.8842530250549316 and perplexity is 48.63060304682518
At time: 576.2510454654694 and batch: 450, loss is 3.9079446268081663 and perplexity is 49.796496333578006
At time: 577.3038296699524 and batch: 500, loss is 3.933021969795227 and perplexity is 51.06104970134509
At time: 578.3518295288086 and batch: 550, loss is 3.904465742111206 and perplexity is 49.62356104989127
At time: 579.4002995491028 and batch: 600, loss is 3.8797225666046145 and perplexity is 48.410782440355426
At time: 580.4502844810486 and batch: 650, loss is 3.9074429988861086 and perplexity is 49.77152328470941
At time: 581.5024130344391 and batch: 700, loss is 3.9223857498168946 and perplexity is 50.520831178781606
At time: 582.5618839263916 and batch: 750, loss is 3.8737251234054564 and perplexity is 48.12131043606985
At time: 583.6139450073242 and batch: 800, loss is 3.836607313156128 and perplexity is 46.36789553384163
At time: 584.6686143875122 and batch: 850, loss is 3.846650309562683 and perplexity is 46.83591436402141
At time: 585.7202537059784 and batch: 900, loss is 3.84139386177063 and perplexity is 46.590369737001375
At time: 586.7837955951691 and batch: 950, loss is 3.9177031564712523 and perplexity is 50.28481568443205
At time: 587.8412098884583 and batch: 1000, loss is 3.8785627269744873 and perplexity is 48.35466624553971
At time: 588.8965208530426 and batch: 1050, loss is 3.842893238067627 and perplexity is 46.66027862982477
At time: 589.9532608985901 and batch: 1100, loss is 3.866106014251709 and perplexity is 47.75606211954409
At time: 591.006049156189 and batch: 1150, loss is 3.82475341796875 and perplexity is 45.821500214585704
At time: 592.0623767375946 and batch: 1200, loss is 3.8648995876312258 and perplexity is 47.69848267458496
At time: 593.1268408298492 and batch: 1250, loss is 3.8463334465026855 and perplexity is 46.82107614384432
At time: 594.186527967453 and batch: 1300, loss is 3.8340627193450927 and perplexity is 46.2500580616694
At time: 595.2391860485077 and batch: 1350, loss is 3.731868767738342 and perplexity is 41.757069559911166
At time: 596.2915239334106 and batch: 1400, loss is 3.764650821685791 and perplexity is 43.14863666088472
At time: 597.3430774211884 and batch: 1450, loss is 3.678213496208191 and perplexity is 39.57562886920362
At time: 598.3921971321106 and batch: 1500, loss is 3.685585765838623 and perplexity is 39.868469198624645
At time: 599.4416077136993 and batch: 1550, loss is 3.6951391649246217 and perplexity is 40.2511737497808
At time: 600.4941055774689 and batch: 1600, loss is 3.79217399597168 and perplexity is 44.352718171327375
At time: 601.5493378639221 and batch: 1650, loss is 3.7246050024032593 and perplexity is 41.45485494237192
At time: 602.6034743785858 and batch: 1700, loss is 3.7399247741699218 and perplexity is 42.09482342785382
At time: 603.6569805145264 and batch: 1750, loss is 3.7317551517486574 and perplexity is 41.75232555862908
At time: 604.7055225372314 and batch: 1800, loss is 3.6887019729614257 and perplexity is 39.99290138385349
At time: 605.7561705112457 and batch: 1850, loss is 3.7037766790390014 and perplexity is 40.600349666217106
At time: 606.8100745677948 and batch: 1900, loss is 3.787549419403076 and perplexity is 44.14807917917518
At time: 607.868967294693 and batch: 1950, loss is 3.7218938875198364 and perplexity is 41.342618280136534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.526082451398983 and perplexity of 92.39588577382249
finished 14 epochs...
Completing Train Step...
At time: 611.2187654972076 and batch: 50, loss is 3.9316093349456787 and perplexity is 50.98897000621358
At time: 612.301465511322 and batch: 100, loss is 3.9168084812164308 and perplexity is 50.23984722323023
At time: 613.3622360229492 and batch: 150, loss is 3.8888225841522215 and perplexity is 48.85333196028653
At time: 614.4182834625244 and batch: 200, loss is 3.8825995826721194 and perplexity is 48.55026158493853
At time: 615.4726750850677 and batch: 250, loss is 3.8769458961486816 and perplexity is 48.27654809951331
At time: 616.5207982063293 and batch: 300, loss is 3.891940507888794 and perplexity is 49.005890633178964
At time: 617.5720839500427 and batch: 350, loss is 3.9022867345809935 and perplexity is 49.51554865933136
At time: 618.6196885108948 and batch: 400, loss is 3.867901382446289 and perplexity is 47.84187884783276
At time: 619.6697778701782 and batch: 450, loss is 3.892068471908569 and perplexity is 49.01216202518476
At time: 620.7239460945129 and batch: 500, loss is 3.917621011734009 and perplexity is 50.28068522111055
At time: 621.8085672855377 and batch: 550, loss is 3.8892038440704346 and perplexity is 48.87196132872423
At time: 622.8736219406128 and batch: 600, loss is 3.8662360191345213 and perplexity is 47.762271044390054
At time: 623.9329328536987 and batch: 650, loss is 3.893370747566223 and perplexity is 49.076030949165244
At time: 624.9881393909454 and batch: 700, loss is 3.9103916120529174 and perplexity is 49.91849683117975
At time: 626.0464396476746 and batch: 750, loss is 3.862837109565735 and perplexity is 47.60020698087998
At time: 627.1008276939392 and batch: 800, loss is 3.8257773733139038 and perplexity is 45.86844341442198
At time: 628.1583049297333 and batch: 850, loss is 3.8359801816940307 and perplexity is 46.33882588391989
At time: 629.2225961685181 and batch: 900, loss is 3.8319143772125246 and perplexity is 46.15080376756736
At time: 630.2791380882263 and batch: 950, loss is 3.908517823219299 and perplexity is 49.825047688548786
At time: 631.3369314670563 and batch: 1000, loss is 3.8689909267425535 and perplexity is 47.894033101079174
At time: 632.399099111557 and batch: 1050, loss is 3.8343636274337767 and perplexity is 46.26397717232373
At time: 633.4556195735931 and batch: 1100, loss is 3.859411039352417 and perplexity is 47.43740437542109
At time: 634.5143132209778 and batch: 1150, loss is 3.819066777229309 and perplexity is 45.56166928748897
At time: 635.5685794353485 and batch: 1200, loss is 3.8594386386871338 and perplexity is 47.4387136342898
At time: 636.6258277893066 and batch: 1250, loss is 3.8421221017837524 and perplexity is 46.624311065686825
At time: 637.6807532310486 and batch: 1300, loss is 3.830791463851929 and perplexity is 46.099009499095
At time: 638.7360608577728 and batch: 1350, loss is 3.729653034210205 and perplexity is 41.66464944783221
At time: 639.7890694141388 and batch: 1400, loss is 3.762995138168335 and perplexity is 43.07725528315628
At time: 640.8426330089569 and batch: 1450, loss is 3.6783164310455323 and perplexity is 39.57970278979453
At time: 641.9008357524872 and batch: 1500, loss is 3.6863488578796386 and perplexity is 39.898904121004236
At time: 642.9650993347168 and batch: 1550, loss is 3.6967803287506102 and perplexity is 40.317286756390786
At time: 644.0205855369568 and batch: 1600, loss is 3.794361882209778 and perplexity is 44.44986310531728
At time: 645.0755081176758 and batch: 1650, loss is 3.7278588962554933 and perplexity is 41.58996433661828
At time: 646.1328377723694 and batch: 1700, loss is 3.7440896368026735 and perplexity is 42.27050818246216
At time: 647.1912117004395 and batch: 1750, loss is 3.736752300262451 and perplexity is 41.96149030863881
At time: 648.2512512207031 and batch: 1800, loss is 3.6939506244659426 and perplexity is 40.20336201998584
At time: 649.3090627193451 and batch: 1850, loss is 3.709192280769348 and perplexity is 40.82082144494895
At time: 650.36661028862 and batch: 1900, loss is 3.7926659965515137 and perplexity is 44.3745451033762
At time: 651.4181220531464 and batch: 1950, loss is 3.7265181493759156 and perplexity is 41.5342400861172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525246695585029 and perplexity of 92.31869763481247
finished 15 epochs...
Completing Train Step...
At time: 654.7814905643463 and batch: 50, loss is 3.927660117149353 and perplexity is 50.78800055571254
At time: 655.8436250686646 and batch: 100, loss is 3.9115123462677004 and perplexity is 49.9744735601876
At time: 656.9023206233978 and batch: 150, loss is 3.882709431648254 and perplexity is 48.55559507439853
At time: 657.9611721038818 and batch: 200, loss is 3.8760783195495607 and perplexity is 48.234682659459864
At time: 659.0242214202881 and batch: 250, loss is 3.869677658081055 and perplexity is 47.92693473053389
At time: 660.0897760391235 and batch: 300, loss is 3.884502720832825 and perplexity is 48.64274741921853
At time: 661.151727437973 and batch: 350, loss is 3.8947305822372438 and perplexity is 49.14281163261973
At time: 662.2144310474396 and batch: 400, loss is 3.8601689863204958 and perplexity is 47.47337304168979
At time: 663.2744519710541 and batch: 450, loss is 3.8844970941543577 and perplexity is 48.64247372288905
At time: 664.3375732898712 and batch: 500, loss is 3.9103588962554934 and perplexity is 49.91686373446388
At time: 665.3972599506378 and batch: 550, loss is 3.881851897239685 and perplexity is 48.51397482884052
At time: 666.4560270309448 and batch: 600, loss is 3.859453535079956 and perplexity is 47.43942030526649
At time: 667.5184671878815 and batch: 650, loss is 3.8865918779373168 and perplexity is 48.744475987051324
At time: 668.5818877220154 and batch: 700, loss is 3.904325737953186 and perplexity is 49.61661403132563
At time: 669.644777059555 and batch: 750, loss is 3.8573063611984253 and perplexity is 47.33766889910543
At time: 670.706892490387 and batch: 800, loss is 3.8201764965057374 and perplexity is 45.6122580146148
At time: 671.7686882019043 and batch: 850, loss is 3.830403265953064 and perplexity is 46.08111743352352
At time: 672.8264088630676 and batch: 900, loss is 3.8269955015182493 and perplexity is 45.92435110348781
At time: 673.8953700065613 and batch: 950, loss is 3.9038462018966675 and perplexity is 49.592826779773475
At time: 675.0056974887848 and batch: 1000, loss is 3.864272871017456 and perplexity is 47.6685986084397
At time: 676.0681760311127 and batch: 1050, loss is 3.8301130390167235 and perplexity is 46.067745392544744
At time: 677.1276099681854 and batch: 1100, loss is 3.8557921648025513 and perplexity is 47.266044611773154
At time: 678.1873066425323 and batch: 1150, loss is 3.8158872318267822 and perplexity is 45.41703395053414
At time: 679.2455546855927 and batch: 1200, loss is 3.8564732885360717 and perplexity is 47.29824960309476
At time: 680.307436466217 and batch: 1250, loss is 3.839815797805786 and perplexity is 46.5169051345772
At time: 681.37526679039 and batch: 1300, loss is 3.8287165451049803 and perplexity is 46.00345696622221
At time: 682.4434239864349 and batch: 1350, loss is 3.7280772161483764 and perplexity is 41.5990452444126
At time: 683.5036327838898 and batch: 1400, loss is 3.7616884231567385 and perplexity is 43.021002348300954
At time: 684.5682125091553 and batch: 1450, loss is 3.6777831506729126 and perplexity is 39.5586013381377
At time: 685.6282308101654 and batch: 1500, loss is 3.686126685142517 and perplexity is 39.890040656914024
At time: 686.689306974411 and batch: 1550, loss is 3.6970544624328614 and perplexity is 40.32834059771358
At time: 687.7518444061279 and batch: 1600, loss is 3.7948071241378782 and perplexity is 44.4696584546028
At time: 688.8162181377411 and batch: 1650, loss is 3.7288553619384768 and perplexity is 41.631427963946166
At time: 689.8778030872345 and batch: 1700, loss is 3.7454438543319704 and perplexity is 42.32779042316819
At time: 690.937136888504 and batch: 1750, loss is 3.7384332752227785 and perplexity is 42.032085841183566
At time: 692.0023639202118 and batch: 1800, loss is 3.6958444499969483 and perplexity is 40.27957231513506
At time: 693.0735516548157 and batch: 1850, loss is 3.711216883659363 and perplexity is 40.90355111712667
At time: 694.132913351059 and batch: 1900, loss is 3.794635500907898 and perplexity is 44.46202708306174
At time: 695.1933887004852 and batch: 1950, loss is 3.7282350635528565 and perplexity is 41.60561206399736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525212061682413 and perplexity of 92.31550033339677
finished 16 epochs...
Completing Train Step...
At time: 698.5630919933319 and batch: 50, loss is 3.923673052787781 and perplexity is 50.585908673088646
At time: 699.6356637477875 and batch: 100, loss is 3.906868133544922 and perplexity is 49.74291958342094
At time: 700.6820287704468 and batch: 150, loss is 3.8776576137542724 and perplexity is 48.310919598682545
At time: 701.7644417285919 and batch: 200, loss is 3.870895709991455 and perplexity is 47.985347792791025
At time: 702.8202865123749 and batch: 250, loss is 3.8638985681533815 and perplexity is 47.65075945428566
At time: 703.8772597312927 and batch: 300, loss is 3.878982810974121 and perplexity is 48.37498353432227
At time: 704.9288034439087 and batch: 350, loss is 3.8891656160354615 and perplexity is 48.87009308538722
At time: 705.9806389808655 and batch: 400, loss is 3.854575400352478 and perplexity is 47.20856794386833
At time: 707.0331840515137 and batch: 450, loss is 3.8790538024902346 and perplexity is 48.37841786964824
At time: 708.0877730846405 and batch: 500, loss is 3.9051600217819216 and perplexity is 49.65802564216522
At time: 709.1461219787598 and batch: 550, loss is 3.876601343154907 and perplexity is 48.25991713562526
At time: 710.2074525356293 and batch: 600, loss is 3.8545054531097414 and perplexity is 47.20526595019114
At time: 711.2606608867645 and batch: 650, loss is 3.881724214553833 and perplexity is 48.50778082967466
At time: 712.3131594657898 and batch: 700, loss is 3.89982253074646 and perplexity is 49.39368246769171
At time: 713.3647470474243 and batch: 750, loss is 3.853121666908264 and perplexity is 47.1399891295304
At time: 714.4199867248535 and batch: 800, loss is 3.8159525537490846 and perplexity is 45.42000077539536
At time: 715.4762256145477 and batch: 850, loss is 3.826219053268433 and perplexity is 45.88870706111744
At time: 716.5331716537476 and batch: 900, loss is 3.8231974697113036 and perplexity is 45.75025976876961
At time: 717.588620185852 and batch: 950, loss is 3.900215005874634 and perplexity is 49.41307206426751
At time: 718.6404807567596 and batch: 1000, loss is 3.8606943130493163 and perplexity is 47.498318625173056
At time: 719.6955132484436 and batch: 1050, loss is 3.8268604278564453 and perplexity is 45.918148352141884
At time: 720.7548406124115 and batch: 1100, loss is 3.85288384437561 and perplexity is 47.12877951092912
At time: 721.8082869052887 and batch: 1150, loss is 3.813252205848694 and perplexity is 45.297516421278424
At time: 722.8638215065002 and batch: 1200, loss is 3.853997950553894 and perplexity is 47.18131523511058
At time: 723.9229583740234 and batch: 1250, loss is 3.83782160282135 and perplexity is 46.42423378874426
At time: 724.977288722992 and batch: 1300, loss is 3.826808729171753 and perplexity is 45.915774505631475
At time: 726.0301868915558 and batch: 1350, loss is 3.7264540815353393 and perplexity is 41.53157916228564
At time: 727.083901643753 and batch: 1400, loss is 3.760325970649719 and perplexity is 42.96242818711423
At time: 728.1400144100189 and batch: 1450, loss is 3.676866331100464 and perplexity is 39.522349858744406
At time: 729.196261882782 and batch: 1500, loss is 3.685393476486206 and perplexity is 39.86080365352556
At time: 730.2538819313049 and batch: 1550, loss is 3.696650652885437 and perplexity is 40.312058916318875
At time: 731.3132600784302 and batch: 1600, loss is 3.79450412273407 and perplexity is 44.45618612683437
At time: 732.3783540725708 and batch: 1650, loss is 3.7289373874664307 and perplexity is 41.634842943860235
At time: 733.4331407546997 and batch: 1700, loss is 3.745725865364075 and perplexity is 42.339729010359655
At time: 734.4883596897125 and batch: 1750, loss is 3.738931269645691 and perplexity is 42.05302279832711
At time: 735.545257806778 and batch: 1800, loss is 3.6965205335617064 and perplexity is 40.30681387972221
At time: 736.6054973602295 and batch: 1850, loss is 3.711995897293091 and perplexity is 40.93542795574867
At time: 737.6646029949188 and batch: 1900, loss is 3.795470128059387 and perplexity is 44.49915178856402
At time: 738.717910528183 and batch: 1950, loss is 3.728927311897278 and perplexity is 41.634423451234305
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525402548146802 and perplexity of 92.33308686160825
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 742.1137623786926 and batch: 50, loss is 3.9218453693389894 and perplexity is 50.49353808287731
At time: 743.1696393489838 and batch: 100, loss is 3.907456612586975 and perplexity is 49.772200863951255
At time: 744.2264947891235 and batch: 150, loss is 3.879889097213745 and perplexity is 48.418844988755616
At time: 745.2792117595673 and batch: 200, loss is 3.87382951259613 and perplexity is 48.126334042920995
At time: 746.3344881534576 and batch: 250, loss is 3.8686416339874268 and perplexity is 47.87730698362905
At time: 747.3917298316956 and batch: 300, loss is 3.8818711137771604 and perplexity is 48.51490710841347
At time: 748.4485619068146 and batch: 350, loss is 3.892666997909546 and perplexity is 49.041505859168716
At time: 749.5030174255371 and batch: 400, loss is 3.860662007331848 and perplexity is 47.496784182697105
At time: 750.5553584098816 and batch: 450, loss is 3.8828774642944337 and perplexity is 48.56375468504699
At time: 751.6124823093414 and batch: 500, loss is 3.909881591796875 and perplexity is 49.893043877957254
At time: 752.6761147975922 and batch: 550, loss is 3.881033487319946 and perplexity is 48.4742867533672
At time: 753.7334163188934 and batch: 600, loss is 3.858077507019043 and perplexity is 47.37418722330161
At time: 754.788393497467 and batch: 650, loss is 3.8851731967926026 and perplexity is 48.6753721478066
At time: 755.8681552410126 and batch: 700, loss is 3.902660369873047 and perplexity is 49.53405287251415
At time: 756.922943353653 and batch: 750, loss is 3.855578303337097 and perplexity is 47.25593730702629
At time: 757.9795074462891 and batch: 800, loss is 3.8188941860198975 and perplexity is 45.553806422434036
At time: 759.0346331596375 and batch: 850, loss is 3.829703254699707 and perplexity is 46.04887142035558
At time: 760.0899965763092 and batch: 900, loss is 3.8219197273254393 and perplexity is 45.69184005332018
At time: 761.146327495575 and batch: 950, loss is 3.899786324501038 and perplexity is 49.391894140276484
At time: 762.2046926021576 and batch: 1000, loss is 3.8600665616989134 and perplexity is 47.468510848429155
At time: 763.2594676017761 and batch: 1050, loss is 3.8262471675872805 and perplexity is 45.88999720899499
At time: 764.3121535778046 and batch: 1100, loss is 3.849675626754761 and perplexity is 46.97782241114596
At time: 765.3637614250183 and batch: 1150, loss is 3.810867495536804 and perplexity is 45.18962366438134
At time: 766.4228534698486 and batch: 1200, loss is 3.8518475770950316 and perplexity is 47.079966794626856
At time: 767.4774901866913 and batch: 1250, loss is 3.8344017171859743 and perplexity is 46.26573938931089
At time: 768.5342698097229 and batch: 1300, loss is 3.822212982177734 and perplexity is 45.705241372030926
At time: 769.5834472179413 and batch: 1350, loss is 3.7191617822647096 and perplexity is 41.22982005395018
At time: 770.6367526054382 and batch: 1400, loss is 3.7529233837127687 and perplexity is 42.645569312063756
At time: 771.6909437179565 and batch: 1450, loss is 3.6667099237442016 and perplexity is 39.1229763071703
At time: 772.7402245998383 and batch: 1500, loss is 3.674917502403259 and perplexity is 39.44540257205235
At time: 773.7994227409363 and batch: 1550, loss is 3.6865513038635256 and perplexity is 39.90698231157605
At time: 774.8594980239868 and batch: 1600, loss is 3.784233331680298 and perplexity is 44.001922743539104
At time: 775.919153213501 and batch: 1650, loss is 3.7180253744125364 and perplexity is 41.18299277518032
At time: 776.9837760925293 and batch: 1700, loss is 3.7320609951019286 and perplexity is 41.76509718284344
At time: 778.0411338806152 and batch: 1750, loss is 3.726181077957153 and perplexity is 41.52024244011989
At time: 779.0945434570312 and batch: 1800, loss is 3.685599513053894 and perplexity is 39.86901728282055
At time: 780.1475305557251 and batch: 1850, loss is 3.701941556930542 and perplexity is 40.525911389487426
At time: 781.2073104381561 and batch: 1900, loss is 3.7849617195129395 and perplexity is 44.03398488409732
At time: 782.2671475410461 and batch: 1950, loss is 3.7204705476760864 and perplexity is 41.28381554236063
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5237335914789245 and perplexity of 92.17911546216125
finished 18 epochs...
Completing Train Step...
At time: 785.6615436077118 and batch: 50, loss is 3.9207380914688112 and perplexity is 50.4376586483111
At time: 786.743949174881 and batch: 100, loss is 3.9046038389205933 and perplexity is 49.63041437854322
At time: 787.7961506843567 and batch: 150, loss is 3.8763940000534056 and perplexity is 48.24991181203141
At time: 788.8477737903595 and batch: 200, loss is 3.870399260520935 and perplexity is 47.961531404592385
At time: 789.9034640789032 and batch: 250, loss is 3.864681353569031 and perplexity is 47.688074376714226
At time: 790.96644115448 and batch: 300, loss is 3.8781418800354004 and perplexity is 48.33432061375842
At time: 792.0264658927917 and batch: 350, loss is 3.8878963708877565 and perplexity is 48.80810430467217
At time: 793.0829124450684 and batch: 400, loss is 3.855862646102905 and perplexity is 47.269376101462456
At time: 794.1356773376465 and batch: 450, loss is 3.8785140705108643 and perplexity is 48.35231353571827
At time: 795.1887159347534 and batch: 500, loss is 3.905587577819824 and perplexity is 49.67926177035275
At time: 796.24281001091 and batch: 550, loss is 3.8768807077407836 and perplexity is 48.27340113077795
At time: 797.2976200580597 and batch: 600, loss is 3.854556751251221 and perplexity is 47.20768755471381
At time: 798.3596346378326 and batch: 650, loss is 3.881310710906982 and perplexity is 48.4877268318873
At time: 799.4171116352081 and batch: 700, loss is 3.8995188093185424 and perplexity is 49.37868282589414
At time: 800.473904132843 and batch: 750, loss is 3.8527503967285157 and perplexity is 47.12249070581541
At time: 801.5271637439728 and batch: 800, loss is 3.815897822380066 and perplexity is 45.41751494459917
At time: 802.5816769599915 and batch: 850, loss is 3.826453728675842 and perplexity is 45.89947727584533
At time: 803.644505739212 and batch: 900, loss is 3.819591131210327 and perplexity is 45.58556599478095
At time: 804.7011022567749 and batch: 950, loss is 3.8976364946365356 and perplexity is 49.28582402838914
At time: 805.7593483924866 and batch: 1000, loss is 3.857862505912781 and perplexity is 47.36400281550904
At time: 806.8150708675385 and batch: 1050, loss is 3.8241793584823607 and perplexity is 45.79520349636936
At time: 807.8682837486267 and batch: 1100, loss is 3.8482786130905153 and perplexity is 46.91223957204847
At time: 808.9586472511292 and batch: 1150, loss is 3.8094864797592165 and perplexity is 45.12725915421566
At time: 810.0137858390808 and batch: 1200, loss is 3.85026752948761 and perplexity is 47.00563694355121
At time: 811.0690648555756 and batch: 1250, loss is 3.8333175420761108 and perplexity is 46.21560640760171
At time: 812.1313407421112 and batch: 1300, loss is 3.8213062191009524 and perplexity is 45.6638163309266
At time: 813.193249464035 and batch: 1350, loss is 3.718671760559082 and perplexity is 41.20962149647459
At time: 814.2455418109894 and batch: 1400, loss is 3.75248863697052 and perplexity is 42.62703331925719
At time: 815.2970700263977 and batch: 1450, loss is 3.6671577739715575 and perplexity is 39.140501465034355
At time: 816.3515863418579 and batch: 1500, loss is 3.675686364173889 and perplexity is 39.47574229614949
At time: 817.4103274345398 and batch: 1550, loss is 3.6880076694488526 and perplexity is 39.96514380915057
At time: 818.4716718196869 and batch: 1600, loss is 3.7858399295806886 and perplexity is 44.07267295858739
At time: 819.5264320373535 and batch: 1650, loss is 3.719990873336792 and perplexity is 41.26401750410185
At time: 820.5827085971832 and batch: 1700, loss is 3.7340081262588503 and perplexity is 41.846498528670146
At time: 821.6370997428894 and batch: 1750, loss is 3.7284639406204225 and perplexity is 41.61513572431301
At time: 822.6964728832245 and batch: 1800, loss is 3.6878415298461915 and perplexity is 39.95850456757357
At time: 823.7553486824036 and batch: 1850, loss is 3.704113202095032 and perplexity is 40.61401491917006
At time: 824.8115005493164 and batch: 1900, loss is 3.7868474912643433 and perplexity is 44.11710127353204
At time: 825.8655796051025 and batch: 1950, loss is 3.722170343399048 and perplexity is 41.35404927003146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.523235658157703 and perplexity of 92.13322783448946
finished 19 epochs...
Completing Train Step...
At time: 829.2626383304596 and batch: 50, loss is 3.9199047803878786 and perplexity is 50.39564589574046
At time: 830.3251240253448 and batch: 100, loss is 3.9030321979522706 and perplexity is 49.552474448867336
At time: 831.3872928619385 and batch: 150, loss is 3.87459547996521 and perplexity is 48.16321136600136
At time: 832.4462740421295 and batch: 200, loss is 3.868301258087158 and perplexity is 47.86101347527815
At time: 833.5043005943298 and batch: 250, loss is 3.862450404167175 and perplexity is 47.58180328250201
At time: 834.5616106987 and batch: 300, loss is 3.875793790817261 and perplexity is 48.220960458622656
At time: 835.6196300983429 and batch: 350, loss is 3.885241861343384 and perplexity is 48.67871453511968
At time: 836.7178587913513 and batch: 400, loss is 3.8530927991867063 and perplexity is 47.13862832509174
At time: 837.7787313461304 and batch: 450, loss is 3.875825524330139 and perplexity is 48.22249070337227
At time: 838.8374078273773 and batch: 500, loss is 3.902918496131897 and perplexity is 49.54684056261612
At time: 839.8945074081421 and batch: 550, loss is 3.874244837760925 and perplexity is 48.14632627188886
At time: 840.9518744945526 and batch: 600, loss is 3.852250962257385 and perplexity is 47.09896198560743
At time: 842.0075061321259 and batch: 650, loss is 3.878986887931824 and perplexity is 48.375180757486056
At time: 843.0642535686493 and batch: 700, loss is 3.8974334192276 and perplexity is 49.27581630571544
At time: 844.1306915283203 and batch: 750, loss is 3.850917348861694 and perplexity is 47.03619204370113
At time: 845.1903517246246 and batch: 800, loss is 3.8140428256988526 and perplexity is 45.33334369793578
At time: 846.2416124343872 and batch: 850, loss is 3.824569683074951 and perplexity is 45.813081979495514
At time: 847.2930347919464 and batch: 900, loss is 3.818121409416199 and perplexity is 45.51861710511313
At time: 848.3438229560852 and batch: 950, loss is 3.8961869525909423 and perplexity is 49.214433908198956
At time: 849.3991076946259 and batch: 1000, loss is 3.8563975429534914 and perplexity is 47.29466710530445
At time: 850.4610865116119 and batch: 1050, loss is 3.8228636884689333 and perplexity is 45.73499173845804
At time: 851.5339884757996 and batch: 1100, loss is 3.8472713088989257 and perplexity is 46.8650084685286
At time: 852.6054809093475 and batch: 1150, loss is 3.808598861694336 and perplexity is 45.087221155625954
At time: 853.6666836738586 and batch: 1200, loss is 3.849342317581177 and perplexity is 46.96216688119213
At time: 854.7306916713715 and batch: 1250, loss is 3.8326304006576537 and perplexity is 46.1838606584186
At time: 855.7922406196594 and batch: 1300, loss is 3.82081748008728 and perplexity is 45.641504095246674
At time: 856.8638253211975 and batch: 1350, loss is 3.718428974151611 and perplexity is 41.199617574975456
At time: 857.9340236186981 and batch: 1400, loss is 3.752404284477234 and perplexity is 42.62343777436404
At time: 858.9972412586212 and batch: 1450, loss is 3.66753981590271 and perplexity is 39.15545763456036
At time: 860.0633554458618 and batch: 1500, loss is 3.6761853170394896 and perplexity is 39.49544374552845
At time: 861.1251864433289 and batch: 1550, loss is 3.68887478351593 and perplexity is 39.99981317651604
At time: 862.1853504180908 and batch: 1600, loss is 3.786767578125 and perplexity is 44.113575878335126
At time: 863.24329829216 and batch: 1650, loss is 3.721116290092468 and perplexity is 41.31048286234958
At time: 864.3046188354492 and batch: 1700, loss is 3.73515763759613 and perplexity is 41.89462921123707
At time: 865.3668251037598 and batch: 1750, loss is 3.7298094701766966 and perplexity is 41.671167807376754
At time: 866.4292681217194 and batch: 1800, loss is 3.6891645336151124 and perplexity is 40.01140480560795
At time: 867.4948041439056 and batch: 1850, loss is 3.7054330015182497 and perplexity is 40.66765266037907
At time: 868.557375907898 and batch: 1900, loss is 3.7879609632492066 and perplexity is 44.16625178863616
At time: 869.6191809177399 and batch: 1950, loss is 3.723171672821045 and perplexity is 41.39547903524401
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.523036655159884 and perplexity of 92.11489487016956
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc0f4432b38>
ELAPSED
3593.4906249046326


RESULTS SO FAR:
[{'best_accuracy': -94.78310464460193, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.83547208165798, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.24245156315881022, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.32612507610596975, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.75140648791492, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.5466017702903482, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44410872475199714, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -92.11489487016956, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.961697908824608, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.8996370580396494, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.4930294951606292, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.7555409501871296, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5487549304962158 and batch: 50, loss is 7.739361467361451 and perplexity is 2297.0052019582836
At time: 2.5950911045074463 and batch: 100, loss is 6.8142077827453615 and perplexity is 910.6947618249303
At time: 3.637071132659912 and batch: 150, loss is 6.603582525253296 and perplexity is 737.733409244217
At time: 4.680779457092285 and batch: 200, loss is 6.529750576019287 and perplexity is 685.22727805986
At time: 5.738602161407471 and batch: 250, loss is 6.484634485244751 and perplexity is 654.9995084944062
At time: 6.788243293762207 and batch: 300, loss is 6.414232797622681 and perplexity is 610.4722253677293
At time: 7.832804203033447 and batch: 350, loss is 6.383945178985596 and perplexity is 592.259675043459
At time: 8.874789237976074 and batch: 400, loss is 6.3505542278289795 and perplexity is 572.8100883469997
At time: 9.916974067687988 and batch: 450, loss is 6.283632745742798 and perplexity is 535.7313087527743
At time: 10.96305775642395 and batch: 500, loss is 6.264586267471313 and perplexity is 525.624073189435
At time: 12.058615922927856 and batch: 550, loss is 6.224255495071411 and perplexity is 504.84704139637194
At time: 13.106074333190918 and batch: 600, loss is 6.266929693222046 and perplexity is 526.8572785760214
At time: 14.157766342163086 and batch: 650, loss is 6.363710985183716 and perplexity is 580.3962066188022
At time: 15.218255043029785 and batch: 700, loss is 6.247627964019776 and perplexity is 516.7855357721716
At time: 16.272545337677002 and batch: 750, loss is 6.1876218795776365 and perplexity is 486.68732782967055
At time: 17.328397274017334 and batch: 800, loss is 6.1959848308563235 and perplexity is 490.7745369845451
At time: 18.384649991989136 and batch: 850, loss is 6.242051362991333 and perplexity is 513.9116497276226
At time: 19.43896460533142 and batch: 900, loss is 6.232761478424072 and perplexity is 509.1595771029987
At time: 20.49225163459778 and batch: 950, loss is 6.251631450653076 and perplexity is 518.858626784055
At time: 21.550917387008667 and batch: 1000, loss is 6.244041042327881 and perplexity is 514.935187035746
At time: 22.61030602455139 and batch: 1050, loss is 6.135485534667969 and perplexity is 461.9633387915084
At time: 23.669694423675537 and batch: 1100, loss is 6.217966432571411 and perplexity is 501.68198983571466
At time: 24.725967407226562 and batch: 1150, loss is 6.1211908912658695 and perplexity is 455.40671156899543
At time: 25.78390860557556 and batch: 1200, loss is 6.207453556060791 and perplexity is 496.43549522432795
At time: 26.84104323387146 and batch: 1250, loss is 6.14161563873291 and perplexity is 464.80391976566096
At time: 27.898155212402344 and batch: 1300, loss is 6.160979728698731 and perplexity is 473.89213319506246
At time: 28.952648401260376 and batch: 1350, loss is 6.15515832901001 and perplexity is 471.141431912324
At time: 30.008466482162476 and batch: 1400, loss is 6.176965551376343 and perplexity is 481.5285634937121
At time: 31.065186023712158 and batch: 1450, loss is 6.159091758728027 and perplexity is 472.9982831247885
At time: 32.1143114566803 and batch: 1500, loss is 6.142462673187256 and perplexity is 465.19779148812825
At time: 33.16213822364807 and batch: 1550, loss is 6.124425086975098 and perplexity is 456.88197035338453
At time: 34.21195125579834 and batch: 1600, loss is 6.116314535140991 and perplexity is 453.19139199512233
At time: 35.267542362213135 and batch: 1650, loss is 6.111597890853882 and perplexity is 451.05888250290434
At time: 36.33049273490906 and batch: 1700, loss is 6.124917030334473 and perplexity is 457.1067856983921
At time: 37.39030408859253 and batch: 1750, loss is 6.144187612533569 and perplexity is 466.0009219390043
At time: 38.449970960617065 and batch: 1800, loss is 6.152174625396729 and perplexity is 469.73778060063825
At time: 39.51122522354126 and batch: 1850, loss is 6.104093112945557 and perplexity is 447.68645624954553
At time: 40.57315278053284 and batch: 1900, loss is 6.0566794967651365 and perplexity is 426.9553738022174
At time: 41.63171911239624 and batch: 1950, loss is 6.012727565765381 and perplexity is 408.59627496680764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.4018117505450585 and perplexity of 221.80791299561574
finished 1 epochs...
Completing Train Step...
At time: 45.036858797073364 and batch: 50, loss is 5.657997703552246 and perplexity is 286.57426108197984
At time: 46.12581515312195 and batch: 100, loss is 5.556616506576538 and perplexity is 258.9452130185807
At time: 47.18136239051819 and batch: 150, loss is 5.457186212539673 and perplexity is 234.43683998846492
At time: 48.262362241744995 and batch: 200, loss is 5.4166438770294185 and perplexity is 225.1223150701947
At time: 49.321109771728516 and batch: 250, loss is 5.404994354248047 and perplexity is 222.51496421597577
At time: 50.38192534446716 and batch: 300, loss is 5.401878089904785 and perplexity is 221.82262807863532
At time: 51.431915521621704 and batch: 350, loss is 5.366292171478271 and perplexity is 214.06766817797586
At time: 52.48728346824646 and batch: 400, loss is 5.331556749343872 and perplexity is 206.75959661494863
At time: 53.546961545944214 and batch: 450, loss is 5.265234575271607 and perplexity is 193.49169183050859
At time: 54.60245156288147 and batch: 500, loss is 5.25025598526001 and perplexity is 190.6150568586997
At time: 55.65778064727783 and batch: 550, loss is 5.20667218208313 and perplexity is 182.48576720857815
At time: 56.718937397003174 and batch: 600, loss is 5.211971673965454 and perplexity is 183.4554161044156
At time: 57.77050518989563 and batch: 650, loss is 5.282152128219605 and perplexity is 196.7929435872752
At time: 58.82198905944824 and batch: 700, loss is 5.241373958587647 and perplexity is 188.92950547682946
At time: 59.87228989601135 and batch: 750, loss is 5.183531455993652 and perplexity is 178.31139928388922
At time: 60.923858642578125 and batch: 800, loss is 5.164076318740845 and perplexity is 174.87585439852774
At time: 61.975223779678345 and batch: 850, loss is 5.160966005325317 and perplexity is 174.33278068507852
At time: 63.0279061794281 and batch: 900, loss is 5.188503770828247 and perplexity is 179.20022763564975
At time: 64.08618235588074 and batch: 950, loss is 5.22545524597168 and perplexity is 185.9458023378117
At time: 65.1441376209259 and batch: 1000, loss is 5.194215774536133 and perplexity is 180.22674895612965
At time: 66.20653057098389 and batch: 1050, loss is 5.1013253307342525 and perplexity is 164.23943469076474
At time: 67.25915551185608 and batch: 1100, loss is 5.193091287612915 and perplexity is 180.0242002367506
At time: 68.31103706359863 and batch: 1150, loss is 5.096507863998413 and perplexity is 163.4501194539119
At time: 69.36345934867859 and batch: 1200, loss is 5.165402050018311 and perplexity is 175.10784653401407
At time: 70.4193103313446 and batch: 1250, loss is 5.102475528717041 and perplexity is 164.4284512396286
At time: 71.47559905052185 and batch: 1300, loss is 5.133986082077026 and perplexity is 169.69217867955706
At time: 72.53045320510864 and batch: 1350, loss is 5.0635495948791505 and perplexity is 158.1508927794329
At time: 73.5831573009491 and batch: 1400, loss is 5.0812766647338865 and perplexity is 160.9794415723433
At time: 74.63621544837952 and batch: 1450, loss is 5.0188832855224605 and perplexity is 151.24231497273595
At time: 75.68632960319519 and batch: 1500, loss is 4.999659309387207 and perplexity is 148.36260474464194
At time: 76.74382781982422 and batch: 1550, loss is 4.9877255916595455 and perplexity is 146.60260982677565
At time: 77.79960250854492 and batch: 1600, loss is 5.051650009155273 and perplexity is 156.28011548602478
At time: 78.85663342475891 and batch: 1650, loss is 5.015795946121216 and perplexity is 150.7760986688854
At time: 79.91089057922363 and batch: 1700, loss is 5.035066690444946 and perplexity is 153.7098432478678
At time: 80.967209815979 and batch: 1750, loss is 5.056186237335205 and perplexity is 156.99064810048264
At time: 82.02276587486267 and batch: 1800, loss is 5.011617202758789 and perplexity is 150.1473586338999
At time: 83.07525968551636 and batch: 1850, loss is 5.011042308807373 and perplexity is 150.0610646329266
At time: 84.12639951705933 and batch: 1900, loss is 5.068921899795532 and perplexity is 159.00281393937263
At time: 85.17741346359253 and batch: 1950, loss is 4.989968013763428 and perplexity is 146.93172362765776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.805992800690407 and perplexity of 122.24079153983605
finished 2 epochs...
Completing Train Step...
At time: 88.54826068878174 and batch: 50, loss is 4.916334457397461 and perplexity is 136.50134354505107
At time: 89.61413073539734 and batch: 100, loss is 4.866920518875122 and perplexity is 129.92021338880633
At time: 90.68190550804138 and batch: 150, loss is 4.815037860870361 and perplexity is 123.35148241625541
At time: 91.74402141571045 and batch: 200, loss is 4.798157920837403 and perplexity is 121.28679174201181
At time: 92.80162978172302 and batch: 250, loss is 4.806066150665283 and perplexity is 122.24975822767348
At time: 93.85950875282288 and batch: 300, loss is 4.838577508926392 and perplexity is 126.28957809969997
At time: 94.91678953170776 and batch: 350, loss is 4.839112205505371 and perplexity is 126.35712276141115
At time: 95.97642278671265 and batch: 400, loss is 4.80399260520935 and perplexity is 121.99653042742015
At time: 97.03813600540161 and batch: 450, loss is 4.791696910858154 and perplexity is 120.50568266424735
At time: 98.0999116897583 and batch: 500, loss is 4.795111026763916 and perplexity is 120.9178061505252
At time: 99.16046953201294 and batch: 550, loss is 4.75366982460022 and perplexity is 116.00923785310356
At time: 100.2210578918457 and batch: 600, loss is 4.740551853179932 and perplexity is 114.4973699864611
At time: 101.30796933174133 and batch: 650, loss is 4.8077186012268065 and perplexity is 122.45193690843452
At time: 102.36694931983948 and batch: 700, loss is 4.807843542098999 and perplexity is 122.46723711602421
At time: 103.43225479125977 and batch: 750, loss is 4.767588949203491 and perplexity is 117.63527514518813
At time: 104.50100588798523 and batch: 800, loss is 4.74856201171875 and perplexity is 115.41819512646697
At time: 105.56181073188782 and batch: 850, loss is 4.757319145202636 and perplexity is 116.43336617428642
At time: 106.62190389633179 and batch: 900, loss is 4.769766139984131 and perplexity is 117.89166858915466
At time: 107.68430185317993 and batch: 950, loss is 4.818255357742309 and perplexity is 123.74900459532519
At time: 108.74778342247009 and batch: 1000, loss is 4.793134031295776 and perplexity is 120.67898834439357
At time: 109.80915927886963 and batch: 1050, loss is 4.716978130340576 and perplexity is 111.82980645604003
At time: 110.87619805335999 and batch: 1100, loss is 4.796747245788574 and perplexity is 121.11581611502791
At time: 111.94403433799744 and batch: 1150, loss is 4.718258590698242 and perplexity is 111.97309180604043
At time: 113.0096161365509 and batch: 1200, loss is 4.793080654144287 and perplexity is 120.6725470156626
At time: 114.0756003856659 and batch: 1250, loss is 4.752866554260254 and perplexity is 115.91608849024296
At time: 115.14120125770569 and batch: 1300, loss is 4.774955320358276 and perplexity is 118.50501974061301
At time: 116.2028181552887 and batch: 1350, loss is 4.6772678852081295 and perplexity is 107.4760342181772
At time: 117.26287651062012 and batch: 1400, loss is 4.7008288383483885 and perplexity is 110.03833866075453
At time: 118.32981061935425 and batch: 1450, loss is 4.642173061370849 and perplexity is 103.76960046070671
At time: 119.3937041759491 and batch: 1500, loss is 4.630570735931396 and perplexity is 102.57258926997184
At time: 120.45805811882019 and batch: 1550, loss is 4.634258527755737 and perplexity is 102.95155396805355
At time: 121.51827549934387 and batch: 1600, loss is 4.71875379562378 and perplexity is 112.02855516436115
At time: 122.57703399658203 and batch: 1650, loss is 4.672844247817993 and perplexity is 107.00164924181146
At time: 123.64036917686462 and batch: 1700, loss is 4.70017674446106 and perplexity is 109.9666067232629
At time: 124.70182371139526 and batch: 1750, loss is 4.710861625671387 and perplexity is 111.14788653187391
At time: 125.77511668205261 and batch: 1800, loss is 4.669590692520142 and perplexity is 106.65407918484577
At time: 126.84044075012207 and batch: 1850, loss is 4.692239141464233 and perplexity is 109.0971905611838
At time: 127.90230965614319 and batch: 1900, loss is 4.770110816955566 and perplexity is 117.93231013614175
At time: 128.96303820610046 and batch: 1950, loss is 4.701014785766602 and perplexity is 110.05880190821804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.690871695585029 and perplexity of 108.9481080119079
finished 3 epochs...
Completing Train Step...
At time: 132.33995819091797 and batch: 50, loss is 4.64053822517395 and perplexity is 103.6000927581531
At time: 133.42459225654602 and batch: 100, loss is 4.592257452011109 and perplexity is 98.71702776857434
At time: 134.47894048690796 and batch: 150, loss is 4.5445360088348385 and perplexity is 94.11674773730203
At time: 135.5331244468689 and batch: 200, loss is 4.530959739685058 and perplexity is 92.84762788794862
At time: 136.57874250411987 and batch: 250, loss is 4.543760280609131 and perplexity is 94.0437670298275
At time: 137.6243486404419 and batch: 300, loss is 4.574692220687866 and perplexity is 96.99818050895976
At time: 138.66993474960327 and batch: 350, loss is 4.583063087463379 and perplexity is 97.8135472575275
At time: 139.7232985496521 and batch: 400, loss is 4.538823299407959 and perplexity is 93.58061893734897
At time: 140.78040838241577 and batch: 450, loss is 4.552602500915527 and perplexity is 94.87900999556571
At time: 141.8383331298828 and batch: 500, loss is 4.562362985610962 and perplexity is 95.8096092826518
At time: 142.89006757736206 and batch: 550, loss is 4.526852731704712 and perplexity is 92.46708392271005
At time: 143.9421956539154 and batch: 600, loss is 4.508069686889648 and perplexity is 90.74648021559051
At time: 145.00050449371338 and batch: 650, loss is 4.565845413208008 and perplexity is 96.14384094107815
At time: 146.06034755706787 and batch: 700, loss is 4.582201938629151 and perplexity is 97.72935149308032
At time: 147.11384677886963 and batch: 750, loss is 4.538497705459594 and perplexity is 93.5501546139076
At time: 148.1674370765686 and batch: 800, loss is 4.525303583145142 and perplexity is 92.3239495696572
At time: 149.21973133087158 and batch: 850, loss is 4.529407157897949 and perplexity is 92.70358619909932
At time: 150.27135968208313 and batch: 900, loss is 4.534288377761841 and perplexity is 93.15719897669919
At time: 151.32325863838196 and batch: 950, loss is 4.59843656539917 and perplexity is 99.32889994341681
At time: 152.37709617614746 and batch: 1000, loss is 4.572811164855957 and perplexity is 96.8158930160547
At time: 153.4308397769928 and batch: 1050, loss is 4.50646803855896 and perplexity is 90.60125259986732
At time: 154.51304244995117 and batch: 1100, loss is 4.575337867736817 and perplexity is 97.06082731964695
At time: 155.56457376480103 and batch: 1150, loss is 4.509031715393067 and perplexity is 90.83382292249333
At time: 156.6205816268921 and batch: 1200, loss is 4.577526082992554 and perplexity is 97.27344984981292
At time: 157.67261672019958 and batch: 1250, loss is 4.556019945144653 and perplexity is 95.20380839483992
At time: 158.7339015007019 and batch: 1300, loss is 4.567771921157837 and perplexity is 96.32924134531281
At time: 159.78931713104248 and batch: 1350, loss is 4.46108458518982 and perplexity is 86.58136305490618
At time: 160.84436678886414 and batch: 1400, loss is 4.487832670211792 and perplexity is 88.92849947900496
At time: 161.89730429649353 and batch: 1450, loss is 4.418766345977783 and perplexity is 82.99383649789763
At time: 162.94906044006348 and batch: 1500, loss is 4.419304733276367 and perplexity is 83.03853135582116
At time: 163.99924087524414 and batch: 1550, loss is 4.422053050994873 and perplexity is 83.26706151576354
At time: 165.05310535430908 and batch: 1600, loss is 4.518012447357178 and perplexity is 91.6532511646637
At time: 166.1078782081604 and batch: 1650, loss is 4.472058687210083 and perplexity is 87.5367484262491
At time: 167.16403007507324 and batch: 1700, loss is 4.49788914680481 and perplexity is 89.82731875498237
At time: 168.21619129180908 and batch: 1750, loss is 4.503395366668701 and perplexity is 90.32329193743121
At time: 169.2666609287262 and batch: 1800, loss is 4.463061590194702 and perplexity is 86.7527041582968
At time: 170.31740188598633 and batch: 1850, loss is 4.494512615203857 and perplexity is 89.52452545782346
At time: 171.3688895702362 and batch: 1900, loss is 4.57591477394104 and perplexity is 97.11683846815077
At time: 172.42472076416016 and batch: 1950, loss is 4.51287672996521 and perplexity is 91.18375260652373
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.642574718386628 and perplexity of 103.81128862036675
finished 4 epochs...
Completing Train Step...
At time: 175.77428913116455 and batch: 50, loss is 4.455778512954712 and perplexity is 86.12317275873289
At time: 176.85343050956726 and batch: 100, loss is 4.407529497146607 and perplexity is 82.06646741432397
At time: 177.90871024131775 and batch: 150, loss is 4.368062267303467 and perplexity is 78.8906145709932
At time: 178.97379398345947 and batch: 200, loss is 4.361828365325928 and perplexity is 78.400347937586
At time: 180.03327775001526 and batch: 250, loss is 4.366515283584595 and perplexity is 78.76866642489846
At time: 181.1131467819214 and batch: 300, loss is 4.399961853027344 and perplexity is 81.44776162017091
At time: 182.16531038284302 and batch: 350, loss is 4.4060045433044435 and perplexity is 81.94141521317894
At time: 183.2184386253357 and batch: 400, loss is 4.359264869689941 and perplexity is 78.199626372137
At time: 184.27012491226196 and batch: 450, loss is 4.380133457183838 and perplexity is 79.84868907520799
At time: 185.32530188560486 and batch: 500, loss is 4.402560710906982 and perplexity is 81.65970806729186
At time: 186.38436818122864 and batch: 550, loss is 4.3629365825653075 and perplexity is 78.48728071604852
At time: 187.4466531276703 and batch: 600, loss is 4.345261268615722 and perplexity is 77.11218184064768
At time: 188.50921607017517 and batch: 650, loss is 4.3990019512176515 and perplexity is 81.36961727784436
At time: 189.56608510017395 and batch: 700, loss is 4.424198398590088 and perplexity is 83.4458900620544
At time: 190.61908793449402 and batch: 750, loss is 4.377944669723511 and perplexity is 79.67410839553611
At time: 191.66906070709229 and batch: 800, loss is 4.362835664749145 and perplexity is 78.47936035074183
At time: 192.72065329551697 and batch: 850, loss is 4.374647588729858 and perplexity is 79.41184898988936
At time: 193.77228665351868 and batch: 900, loss is 4.366048393249511 and perplexity is 78.73189867975759
At time: 194.82446956634521 and batch: 950, loss is 4.440646505355835 and perplexity is 84.8297668481355
At time: 195.87440824508667 and batch: 1000, loss is 4.413416509628296 and perplexity is 82.55101861237566
At time: 196.92603945732117 and batch: 1050, loss is 4.35073956489563 and perplexity is 77.53578447049635
At time: 197.97913074493408 and batch: 1100, loss is 4.411408634185791 and perplexity is 82.38543274288142
At time: 199.03431963920593 and batch: 1150, loss is 4.354591064453125 and perplexity is 77.8349893339058
At time: 200.09098720550537 and batch: 1200, loss is 4.426788463592529 and perplexity is 83.662300479044
At time: 201.1484398841858 and batch: 1250, loss is 4.404865989685058 and perplexity is 81.84817360866604
At time: 202.2046413421631 and batch: 1300, loss is 4.415027027130127 and perplexity is 82.68407558917991
At time: 203.256196975708 and batch: 1350, loss is 4.302692112922668 and perplexity is 73.89846917502864
At time: 204.30735182762146 and batch: 1400, loss is 4.338266553878785 and perplexity is 76.57468613196609
At time: 205.3608856201172 and batch: 1450, loss is 4.264302206039429 and perplexity is 71.11527884368752
At time: 206.41781401634216 and batch: 1500, loss is 4.2656028270721436 and perplexity is 71.20783304702358
At time: 207.46874618530273 and batch: 1550, loss is 4.2681006240844725 and perplexity is 71.38591807720181
At time: 208.52052974700928 and batch: 1600, loss is 4.373955097198486 and perplexity is 79.3568759933374
At time: 209.57709646224976 and batch: 1650, loss is 4.326867527961731 and perplexity is 75.70676542343749
At time: 210.63489747047424 and batch: 1700, loss is 4.350325603485107 and perplexity is 77.50369429029735
At time: 211.69030594825745 and batch: 1750, loss is 4.3554886531829835 and perplexity is 77.90488450698773
At time: 212.7438759803772 and batch: 1800, loss is 4.316864938735962 and perplexity is 74.95327644995541
At time: 213.7949936389923 and batch: 1850, loss is 4.348669490814209 and perplexity is 77.37544566653958
At time: 214.84429359436035 and batch: 1900, loss is 4.426679897308349 and perplexity is 83.65321806698587
At time: 215.89619517326355 and batch: 1950, loss is 4.3695432472229 and perplexity is 79.00753654518213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6182336141896805 and perplexity of 101.31491275489356
finished 5 epochs...
Completing Train Step...
At time: 219.23262310028076 and batch: 50, loss is 4.316103324890137 and perplexity is 74.8962127298392
At time: 220.2774519920349 and batch: 100, loss is 4.270584602355957 and perplexity is 71.56345955990007
At time: 221.32160234451294 and batch: 150, loss is 4.234037189483643 and perplexity is 68.9952174229148
At time: 222.37374186515808 and batch: 200, loss is 4.225910959243774 and perplexity is 68.43681831340037
At time: 223.4266107082367 and batch: 250, loss is 4.224850759506226 and perplexity is 68.36430006529235
At time: 224.49283981323242 and batch: 300, loss is 4.259782581329346 and perplexity is 70.79458971530867
At time: 225.54780435562134 and batch: 350, loss is 4.260941619873047 and perplexity is 70.87669094352718
At time: 226.6112985610962 and batch: 400, loss is 4.218284311294556 and perplexity is 67.9168600828571
At time: 227.66410160064697 and batch: 450, loss is 4.242109942436218 and perplexity is 69.55445301639217
At time: 228.7184658050537 and batch: 500, loss is 4.273319959640503 and perplexity is 71.75947915991385
At time: 229.78197717666626 and batch: 550, loss is 4.23131646156311 and perplexity is 68.80775534078798
At time: 230.84429478645325 and batch: 600, loss is 4.218620223999023 and perplexity is 67.93967805121463
At time: 231.9033694267273 and batch: 650, loss is 4.268481826782226 and perplexity is 71.41313576915366
At time: 232.95626664161682 and batch: 700, loss is 4.2923253679275515 and perplexity is 73.13633981537733
At time: 234.03498077392578 and batch: 750, loss is 4.2511493110656735 and perplexity is 70.18603159228277
At time: 235.09490275382996 and batch: 800, loss is 4.231424732208252 and perplexity is 68.81520560416462
At time: 236.15776228904724 and batch: 850, loss is 4.244930820465088 and perplexity is 69.75093463977396
At time: 237.21534705162048 and batch: 900, loss is 4.239741811752319 and perplexity is 69.3899338603189
At time: 238.27349138259888 and batch: 950, loss is 4.31675235748291 and perplexity is 74.94483859115361
At time: 239.33425283432007 and batch: 1000, loss is 4.287423706054687 and perplexity is 72.77872737063433
At time: 240.38669562339783 and batch: 1050, loss is 4.22968807220459 and perplexity is 68.69580070181749
At time: 241.4441180229187 and batch: 1100, loss is 4.284849410057068 and perplexity is 72.59161432956179
At time: 242.50170493125916 and batch: 1150, loss is 4.229658823013306 and perplexity is 68.69379143458721
At time: 243.55645942687988 and batch: 1200, loss is 4.299008536338806 and perplexity is 73.62675924379236
At time: 244.6087555885315 and batch: 1250, loss is 4.281754732131958 and perplexity is 72.36731391093606
At time: 245.66133737564087 and batch: 1300, loss is 4.291471281051636 and perplexity is 73.07390169497364
At time: 246.72298049926758 and batch: 1350, loss is 4.180014290809631 and perplexity is 65.36678735164936
At time: 247.7864625453949 and batch: 1400, loss is 4.216754775047303 and perplexity is 67.81305818817783
At time: 248.84120726585388 and batch: 1450, loss is 4.139419503211975 and perplexity is 62.76637519256244
At time: 249.89327025413513 and batch: 1500, loss is 4.143734178543091 and perplexity is 63.03777680711107
At time: 250.94542050361633 and batch: 1550, loss is 4.1471147632598875 and perplexity is 63.25124196719869
At time: 252.00049901008606 and batch: 1600, loss is 4.253509154319763 and perplexity is 70.35185520738285
At time: 253.06405115127563 and batch: 1650, loss is 4.2014222335815425 and perplexity is 66.78124205718026
At time: 254.12864136695862 and batch: 1700, loss is 4.229222717285157 and perplexity is 68.66384021007927
At time: 255.17985224723816 and batch: 1750, loss is 4.239524688720703 and perplexity is 69.37486934300154
At time: 256.23173451423645 and batch: 1800, loss is 4.193602805137634 and perplexity is 66.26108722061717
At time: 257.29142451286316 and batch: 1850, loss is 4.22823802947998 and perplexity is 68.59626104161983
At time: 258.349063873291 and batch: 1900, loss is 4.307485847473145 and perplexity is 74.25356926771872
At time: 259.4090645313263 and batch: 1950, loss is 4.252376203536987 and perplexity is 70.27219515193781
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.615445301144622 and perplexity of 101.03280854220101
finished 6 epochs...
Completing Train Step...
At time: 262.77185440063477 and batch: 50, loss is 4.195057339668274 and perplexity is 66.35753638733448
At time: 263.8673038482666 and batch: 100, loss is 4.155439772605896 and perplexity is 63.78000708111012
At time: 264.92830991744995 and batch: 150, loss is 4.123516654968261 and perplexity is 61.77610597350652
At time: 265.99463272094727 and batch: 200, loss is 4.117145729064942 and perplexity is 61.38378602738596
At time: 267.05248045921326 and batch: 250, loss is 4.112610416412354 and perplexity is 61.106021716062415
At time: 268.109210729599 and batch: 300, loss is 4.144975967407227 and perplexity is 63.116105039868195
At time: 269.16526103019714 and batch: 350, loss is 4.141795477867126 and perplexity is 62.915683815727455
At time: 270.2215783596039 and batch: 400, loss is 4.099481935501099 and perplexity is 60.309035532495926
At time: 271.2874195575714 and batch: 450, loss is 4.129163384437561 and perplexity is 62.12592567068646
At time: 272.3509109020233 and batch: 500, loss is 4.165496950149536 and perplexity is 64.42469034913974
At time: 273.41120862960815 and batch: 550, loss is 4.127429265975952 and perplexity is 62.01828531357597
At time: 274.46916937828064 and batch: 600, loss is 4.11438355922699 and perplexity is 61.21446753594931
At time: 275.53174567222595 and batch: 650, loss is 4.159910278320313 and perplexity is 64.06577425318835
At time: 276.5906147956848 and batch: 700, loss is 4.18120831489563 and perplexity is 65.44488348522543
At time: 277.65580534935 and batch: 750, loss is 4.1438274097442624 and perplexity is 63.04365416873448
At time: 278.7172245979309 and batch: 800, loss is 4.126136636734008 and perplexity is 61.938170455004176
At time: 279.7757067680359 and batch: 850, loss is 4.1374541902542115 and perplexity is 62.643140758864945
At time: 280.833464384079 and batch: 900, loss is 4.127989649772644 and perplexity is 62.05304909538462
At time: 281.89270758628845 and batch: 950, loss is 4.2122007799148555 and perplexity is 67.50493996821133
At time: 282.9502296447754 and batch: 1000, loss is 4.182768964767456 and perplexity is 65.54709977542169
At time: 284.00938391685486 and batch: 1050, loss is 4.1279998922348025 and perplexity is 62.05368467464674
At time: 285.0666654109955 and batch: 1100, loss is 4.179253950119018 and perplexity is 65.31710521348039
At time: 286.1236672401428 and batch: 1150, loss is 4.128810682296753 and perplexity is 62.10401758744377
At time: 287.1734416484833 and batch: 1200, loss is 4.195939722061158 and perplexity is 66.416114949623
At time: 288.25041913986206 and batch: 1250, loss is 4.1785994911193844 and perplexity is 65.27437183129196
At time: 289.306312084198 and batch: 1300, loss is 4.18462564945221 and perplexity is 65.66891312119776
At time: 290.3695282936096 and batch: 1350, loss is 4.078375563621521 and perplexity is 59.04946979114014
At time: 291.4308707714081 and batch: 1400, loss is 4.1168747234344485 and perplexity is 61.36715292968492
At time: 292.4922180175781 and batch: 1450, loss is 4.0381651210784915 and perplexity is 56.72216894930282
At time: 293.552930355072 and batch: 1500, loss is 4.040471601486206 and perplexity is 56.853148513500784
At time: 294.6095929145813 and batch: 1550, loss is 4.042829742431641 and perplexity is 56.98737445052577
At time: 295.6671483516693 and batch: 1600, loss is 4.156028323173523 and perplexity is 63.81755588908318
At time: 296.7223870754242 and batch: 1650, loss is 4.100352115631104 and perplexity is 60.36153809690727
At time: 297.7789213657379 and batch: 1700, loss is 4.132290163040161 and perplexity is 62.32048369716539
At time: 298.83783054351807 and batch: 1750, loss is 4.13545268535614 and perplexity is 62.517885597030016
At time: 299.89832615852356 and batch: 1800, loss is 4.091014537811279 and perplexity is 59.800530838266745
At time: 300.9603416919708 and batch: 1850, loss is 4.12330883026123 and perplexity is 61.76326870637789
At time: 302.01923513412476 and batch: 1900, loss is 4.204834756851196 and perplexity is 67.0095238866699
At time: 303.07976937294006 and batch: 1950, loss is 4.147511467933655 and perplexity is 63.276339008236285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.614775333848111 and perplexity of 100.9651425341403
finished 7 epochs...
Completing Train Step...
At time: 306.4275677204132 and batch: 50, loss is 4.094950695037841 and perplexity is 60.0363789930814
At time: 307.5165786743164 and batch: 100, loss is 4.057882132530213 and perplexity is 57.851659097607424
At time: 308.56648683547974 and batch: 150, loss is 4.028024044036865 and perplexity is 56.14985192435823
At time: 309.6166944503784 and batch: 200, loss is 4.018127603530884 and perplexity is 55.59690885238488
At time: 310.6662485599518 and batch: 250, loss is 4.016418561935425 and perplexity is 55.501972570712056
At time: 311.71652483940125 and batch: 300, loss is 4.04494637966156 and perplexity is 57.10812379512095
At time: 312.7687554359436 and batch: 350, loss is 4.046450138092041 and perplexity is 57.19406521910235
At time: 313.82275438308716 and batch: 400, loss is 4.004976606369018 and perplexity is 54.870540762873304
At time: 314.9018681049347 and batch: 450, loss is 4.03858108997345 and perplexity is 56.745768515242695
At time: 315.9514470100403 and batch: 500, loss is 4.074098901748657 and perplexity is 58.79747440867312
At time: 317.0069303512573 and batch: 550, loss is 4.03413462638855 and perplexity is 56.49401065281897
At time: 318.068261384964 and batch: 600, loss is 4.023344030380249 and perplexity is 55.88768380423839
At time: 319.1222195625305 and batch: 650, loss is 4.064225096702575 and perplexity is 58.219776341610014
At time: 320.17386054992676 and batch: 700, loss is 4.088068652153015 and perplexity is 59.624624539248536
At time: 321.22459840774536 and batch: 750, loss is 4.050011482238769 and perplexity is 57.398116100536456
At time: 322.27441906929016 and batch: 800, loss is 4.033498139381408 and perplexity is 56.458064389935316
At time: 323.3276116847992 and batch: 850, loss is 4.048679933547974 and perplexity is 57.3217385756702
At time: 324.38050723075867 and batch: 900, loss is 4.0328890895843506 and perplexity is 56.423689086474745
At time: 325.4335939884186 and batch: 950, loss is 4.12351086139679 and perplexity is 61.7757480702581
At time: 326.49350214004517 and batch: 1000, loss is 4.089703550338745 and perplexity is 59.72218445826932
At time: 327.55011224746704 and batch: 1050, loss is 4.041099767684937 and perplexity is 56.88887295895824
At time: 328.60171723365784 and batch: 1100, loss is 4.08986086845398 and perplexity is 59.731580578836585
At time: 329.65650057792664 and batch: 1150, loss is 4.038467788696289 and perplexity is 56.73933951141052
At time: 330.7122702598572 and batch: 1200, loss is 4.102879133224487 and perplexity is 60.51426565698329
At time: 331.768545627594 and batch: 1250, loss is 4.089373435974121 and perplexity is 59.70247256106212
At time: 332.8227882385254 and batch: 1300, loss is 4.100208969116211 and perplexity is 60.352898171497465
At time: 333.8744087219238 and batch: 1350, loss is 3.9907854843139647 and perplexity is 54.09736531092594
At time: 334.9328761100769 and batch: 1400, loss is 4.031086297035217 and perplexity is 56.32206051533536
At time: 335.98376178741455 and batch: 1450, loss is 3.952439045906067 and perplexity is 52.06219418468016
At time: 337.0430335998535 and batch: 1500, loss is 3.9527871370315553 and perplexity is 52.08031972693648
At time: 338.0967261791229 and batch: 1550, loss is 3.954992184638977 and perplexity is 52.195286017833695
At time: 339.150381565094 and batch: 1600, loss is 4.0672948980331425 and perplexity is 58.398774091686384
At time: 340.20353412628174 and batch: 1650, loss is 4.013501672744751 and perplexity is 55.34031534957815
At time: 341.26065039634705 and batch: 1700, loss is 4.045283079147339 and perplexity is 57.12735530847519
At time: 342.3173096179962 and batch: 1750, loss is 4.044227356910706 and perplexity is 57.067076513586706
At time: 343.37380170822144 and batch: 1800, loss is 4.003211965560913 and perplexity is 54.773799349507335
At time: 344.4254722595215 and batch: 1850, loss is 4.032210826873779 and perplexity is 56.38543197782628
At time: 345.48091530799866 and batch: 1900, loss is 4.113935389518738 and perplexity is 61.18703921262382
At time: 346.5347409248352 and batch: 1950, loss is 4.062782273292542 and perplexity is 58.13583605544421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.623049146075582 and perplexity of 101.80397454902902
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 349.92182064056396 and batch: 50, loss is 4.037033476829529 and perplexity is 56.65801593906149
At time: 350.9772753715515 and batch: 100, loss is 4.025929565429688 and perplexity is 56.03237033499206
At time: 352.035094499588 and batch: 150, loss is 3.993801784515381 and perplexity is 54.260785543148394
At time: 353.0941619873047 and batch: 200, loss is 3.9862539958953858 and perplexity is 53.85277831664666
At time: 354.15607714653015 and batch: 250, loss is 3.9876407957077027 and perplexity is 53.92751314865685
At time: 355.20661973953247 and batch: 300, loss is 4.009528894424438 and perplexity is 55.120896683966684
At time: 356.257821559906 and batch: 350, loss is 4.001682286262512 and perplexity is 54.690077053004785
At time: 357.3062551021576 and batch: 400, loss is 3.9557237577438356 and perplexity is 52.2334846561293
At time: 358.35644245147705 and batch: 450, loss is 3.9790564823150634 and perplexity is 53.46656377287958
At time: 359.40930795669556 and batch: 500, loss is 4.00771993637085 and perplexity is 55.02127542649337
At time: 360.46477937698364 and batch: 550, loss is 3.9676965475082397 and perplexity is 52.86262394735827
At time: 361.51065707206726 and batch: 600, loss is 3.943780708312988 and perplexity is 51.61336797991241
At time: 362.557012796402 and batch: 650, loss is 3.979116907119751 and perplexity is 53.46979457716227
At time: 363.6035256385803 and batch: 700, loss is 3.9981109285354615 and perplexity is 54.49510758381839
At time: 364.6557309627533 and batch: 750, loss is 3.9442109775543215 and perplexity is 51.6355804029143
At time: 365.7195637226105 and batch: 800, loss is 3.921677212715149 and perplexity is 50.48504797384157
At time: 366.82623529434204 and batch: 850, loss is 3.9314192819595335 and perplexity is 50.9792803210094
At time: 367.8933074474335 and batch: 900, loss is 3.9064892721176148 and perplexity is 49.724077479407725
At time: 368.95348477363586 and batch: 950, loss is 3.9946741819381715 and perplexity is 54.30814316694573
At time: 370.00797176361084 and batch: 1000, loss is 3.9584183406829836 and perplexity is 52.37442191102106
At time: 371.0600440502167 and batch: 1050, loss is 3.898073601722717 and perplexity is 49.3073719203453
At time: 372.11214566230774 and batch: 1100, loss is 3.9291473770141603 and perplexity is 50.863591708463076
At time: 373.1666111946106 and batch: 1150, loss is 3.8829981470108033 and perplexity is 48.569615844542696
At time: 374.22339844703674 and batch: 1200, loss is 3.9342205858230592 and perplexity is 51.12228898777842
At time: 375.285532951355 and batch: 1250, loss is 3.914812445640564 and perplexity is 50.139666716035975
At time: 376.34126830101013 and batch: 1300, loss is 3.9172186136245726 and perplexity is 50.26045643872127
At time: 377.3968846797943 and batch: 1350, loss is 3.8057194423675536 and perplexity is 44.957582870700925
At time: 378.45023584365845 and batch: 1400, loss is 3.8328942346572874 and perplexity is 46.196047138627854
At time: 379.50650119781494 and batch: 1450, loss is 3.746419382095337 and perplexity is 42.369102505153194
At time: 380.56315898895264 and batch: 1500, loss is 3.7396867179870608 and perplexity is 42.084803687548266
At time: 381.6148569583893 and batch: 1550, loss is 3.739896087646484 and perplexity is 42.09361589103506
At time: 382.66824293136597 and batch: 1600, loss is 3.8386583614349363 and perplexity is 46.463095923091466
At time: 383.7306833267212 and batch: 1650, loss is 3.7773507022857666 and perplexity is 43.70011362819824
At time: 384.78702187538147 and batch: 1700, loss is 3.7943603086471556 and perplexity is 44.44979316072915
At time: 385.8434000015259 and batch: 1750, loss is 3.7884507942199708 and perplexity is 44.18789108599115
At time: 386.9051830768585 and batch: 1800, loss is 3.7405499410629273 and perplexity is 42.12114794557893
At time: 387.9639823436737 and batch: 1850, loss is 3.7525492334365844 and perplexity is 42.6296164450985
At time: 389.02105617523193 and batch: 1900, loss is 3.832469663619995 and perplexity is 46.176437798049
At time: 390.078644990921 and batch: 1950, loss is 3.7767895555496214 and perplexity is 43.67559833104938
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.53291498228561 and perplexity of 93.02934511809846
finished 9 epochs...
Completing Train Step...
At time: 393.4208257198334 and batch: 50, loss is 3.934072232246399 and perplexity is 51.114705375901906
At time: 394.5141499042511 and batch: 100, loss is 3.915342845916748 and perplexity is 50.16626786311419
At time: 395.5744698047638 and batch: 150, loss is 3.8834259366989134 and perplexity is 48.590397870207674
At time: 396.63303446769714 and batch: 200, loss is 3.8716247987747194 and perplexity is 48.020346128524466
At time: 397.6907377243042 and batch: 250, loss is 3.8699520301818846 and perplexity is 47.94008634843825
At time: 398.7487087249756 and batch: 300, loss is 3.894057207107544 and perplexity is 49.10973122447486
At time: 399.8073728084564 and batch: 350, loss is 3.8925487661361693 and perplexity is 49.03570793771795
At time: 400.867525100708 and batch: 400, loss is 3.8556726694107057 and perplexity is 47.26039687469728
At time: 401.93397879600525 and batch: 450, loss is 3.8827611064910887 and perplexity is 48.5581042419726
At time: 402.99577736854553 and batch: 500, loss is 3.912456169128418 and perplexity is 50.021662876460745
At time: 404.0592932701111 and batch: 550, loss is 3.875436935424805 and perplexity is 48.20375561885609
At time: 405.1295380592346 and batch: 600, loss is 3.8566023015975954 and perplexity is 47.30435208872248
At time: 406.19077467918396 and batch: 650, loss is 3.891752829551697 and perplexity is 48.9966941521341
At time: 407.24871253967285 and batch: 700, loss is 3.915117788314819 and perplexity is 50.1549788335598
At time: 408.3105161190033 and batch: 750, loss is 3.865304112434387 and perplexity is 47.71778179712369
At time: 409.3750171661377 and batch: 800, loss is 3.8443915176391603 and perplexity is 46.73024117073289
At time: 410.44403862953186 and batch: 850, loss is 3.855351810455322 and perplexity is 47.2452353856049
At time: 411.5054888725281 and batch: 900, loss is 3.8311954879760743 and perplexity is 46.11763837403587
At time: 412.5590569972992 and batch: 950, loss is 3.92290593624115 and perplexity is 50.54711826580304
At time: 413.61875081062317 and batch: 1000, loss is 3.89169442653656 and perplexity is 48.99383268102395
At time: 414.67882084846497 and batch: 1050, loss is 3.8356190633773806 and perplexity is 46.322095106198105
At time: 415.7408015727997 and batch: 1100, loss is 3.8670689153671263 and perplexity is 47.80206863133301
At time: 416.80502247810364 and batch: 1150, loss is 3.826538166999817 and perplexity is 45.903353114410166
At time: 417.8664519786835 and batch: 1200, loss is 3.87944091796875 and perplexity is 48.397149529455476
At time: 418.9261682033539 and batch: 1250, loss is 3.8642738485336303 and perplexity is 47.66864520528862
At time: 419.98660922050476 and batch: 1300, loss is 3.8695850801467895 and perplexity is 47.922497959297594
At time: 421.0508313179016 and batch: 1350, loss is 3.760942692756653 and perplexity is 42.988932238321865
At time: 422.11523270606995 and batch: 1400, loss is 3.7926742887496947 and perplexity is 44.374913067423996
At time: 423.17450499534607 and batch: 1450, loss is 3.708158349990845 and perplexity is 40.778637352726825
At time: 424.2388005256653 and batch: 1500, loss is 3.705993151664734 and perplexity is 40.6904390332732
At time: 425.2988841533661 and batch: 1550, loss is 3.7088644742965697 and perplexity is 40.80744230845874
At time: 426.36389780044556 and batch: 1600, loss is 3.8102962446212767 and perplexity is 45.16381642239783
At time: 427.42686128616333 and batch: 1650, loss is 3.7522675466537474 and perplexity is 42.61760993670526
At time: 428.4885652065277 and batch: 1700, loss is 3.773363652229309 and perplexity is 43.526225967444894
At time: 429.5484538078308 and batch: 1750, loss is 3.7735122299194335 and perplexity is 43.53269347401067
At time: 430.60784006118774 and batch: 1800, loss is 3.7292203760147093 and perplexity is 41.64662679489154
At time: 431.6681082248688 and batch: 1850, loss is 3.7447437763214113 and perplexity is 42.29816803805745
At time: 432.7339849472046 and batch: 1900, loss is 3.829255533218384 and perplexity is 46.02825896609361
At time: 433.79884219169617 and batch: 1950, loss is 3.7763237857818606 and perplexity is 43.65526029454686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.53491693541061 and perplexity of 93.21577205300308
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 437.15681076049805 and batch: 50, loss is 3.9035080099105834 and perplexity is 49.57605771893012
At time: 438.23609375953674 and batch: 100, loss is 3.908551182746887 and perplexity is 49.826709856326126
At time: 439.2844741344452 and batch: 150, loss is 3.8871033287048338 and perplexity is 48.76941276313016
At time: 440.3386924266815 and batch: 200, loss is 3.8766955518722535 and perplexity is 48.26446385468476
At time: 441.39268374443054 and batch: 250, loss is 3.8757859230041505 and perplexity is 48.220581066610265
At time: 442.4419288635254 and batch: 300, loss is 3.9031948900222777 and perplexity is 49.56053689933999
At time: 443.487900018692 and batch: 350, loss is 3.8995936059951783 and perplexity is 49.38237632539519
At time: 444.54204416275024 and batch: 400, loss is 3.8632423877716064 and perplexity is 47.619502217069545
At time: 445.59557366371155 and batch: 450, loss is 3.894347562789917 and perplexity is 49.12399258432893
At time: 446.6496458053589 and batch: 500, loss is 3.9238257122039797 and perplexity is 50.59363167785427
At time: 447.7509694099426 and batch: 550, loss is 3.8844466686248778 and perplexity is 48.64002096223775
At time: 448.805456161499 and batch: 600, loss is 3.8606701707839965 and perplexity is 47.497171922004625
At time: 449.85834765434265 and batch: 650, loss is 3.8846959924697875 and perplexity is 48.65214959119592
At time: 450.91442346572876 and batch: 700, loss is 3.90863627910614 and perplexity is 49.8309501083409
At time: 451.97765278816223 and batch: 750, loss is 3.8521851015090944 and perplexity is 47.095860114874235
At time: 453.0358214378357 and batch: 800, loss is 3.8317930936813354 and perplexity is 46.14520677453761
At time: 454.0926368236542 and batch: 850, loss is 3.838185358047485 and perplexity is 46.44112391815441
At time: 455.1451096534729 and batch: 900, loss is 3.8054645681381225 and perplexity is 44.946125801527536
At time: 456.1981403827667 and batch: 950, loss is 3.901736078262329 and perplexity is 49.4882901153235
At time: 457.24967885017395 and batch: 1000, loss is 3.867808213233948 and perplexity is 47.837421665302905
At time: 458.3019073009491 and batch: 1050, loss is 3.8157182502746583 and perplexity is 45.409359958044156
At time: 459.36496591567993 and batch: 1100, loss is 3.8358554553985598 and perplexity is 46.333046574254354
At time: 460.4217324256897 and batch: 1150, loss is 3.794597277641296 and perplexity is 44.4603276316264
At time: 461.4764177799225 and batch: 1200, loss is 3.8397667312622072 and perplexity is 46.51462276681867
At time: 462.53018164634705 and batch: 1250, loss is 3.8226168394088744 and perplexity is 45.72370349203943
At time: 463.5832133293152 and batch: 1300, loss is 3.822699537277222 and perplexity is 45.72748490120625
At time: 464.6405568122864 and batch: 1350, loss is 3.714955096244812 and perplexity is 41.0567434410435
At time: 465.7023136615753 and batch: 1400, loss is 3.7470145416259766 and perplexity is 42.39432638568567
At time: 466.7582755088806 and batch: 1450, loss is 3.65364182472229 and perplexity is 38.61503949162173
At time: 467.81374335289 and batch: 1500, loss is 3.6501957750320435 and perplexity is 38.48219916538472
At time: 468.8687012195587 and batch: 1550, loss is 3.6557138061523435 and perplexity is 38.69513208289622
At time: 469.92149472236633 and batch: 1600, loss is 3.7500751876831053 and perplexity is 42.52427918189434
At time: 470.9750757217407 and batch: 1650, loss is 3.685305805206299 and perplexity is 39.857309159036774
At time: 472.02876806259155 and batch: 1700, loss is 3.698443627357483 and perplexity is 40.38440224436114
At time: 473.0804178714752 and batch: 1750, loss is 3.698336057662964 and perplexity is 40.38005834018879
At time: 474.1313507556915 and batch: 1800, loss is 3.6468821477890017 and perplexity is 38.354894538383284
At time: 475.1878364086151 and batch: 1850, loss is 3.661967883110046 and perplexity is 38.93789274750318
At time: 476.24536895751953 and batch: 1900, loss is 3.7468449544906615 and perplexity is 42.387137462911944
At time: 477.3096740245819 and batch: 1950, loss is 3.7009937715530397 and perplexity is 40.48751971966808
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.506010969295058 and perplexity of 90.55985101444975
finished 11 epochs...
Completing Train Step...
At time: 480.7218496799469 and batch: 50, loss is 3.889411516189575 and perplexity is 48.88211172644074
At time: 481.77732610702515 and batch: 100, loss is 3.880334243774414 and perplexity is 48.44040326901509
At time: 482.83413457870483 and batch: 150, loss is 3.849167671203613 and perplexity is 46.953965825027005
At time: 483.89230704307556 and batch: 200, loss is 3.834651856422424 and perplexity is 46.27731371357148
At time: 484.9486198425293 and batch: 250, loss is 3.8317765951156617 and perplexity is 46.1444454510935
At time: 486.0086727142334 and batch: 300, loss is 3.8559975051879882 and perplexity is 47.2757512361387
At time: 487.0622065067291 and batch: 350, loss is 3.8542150926589964 and perplexity is 47.19156139761862
At time: 488.1161847114563 and batch: 400, loss is 3.8184989500045776 and perplexity is 45.53580547504667
At time: 489.17117142677307 and batch: 450, loss is 3.8516486930847167 and perplexity is 47.07060427308403
At time: 490.2291796207428 and batch: 500, loss is 3.8821744441986086 and perplexity is 48.52962538777127
At time: 491.28533720970154 and batch: 550, loss is 3.8441236305236814 and perplexity is 46.717724417833296
At time: 492.34177231788635 and batch: 600, loss is 3.8210893201828005 and perplexity is 45.653912972618414
At time: 493.3972420692444 and batch: 650, loss is 3.8474130153656008 and perplexity is 46.87165001385322
At time: 494.45152592658997 and batch: 700, loss is 3.874103856086731 and perplexity is 48.139539000656434
At time: 495.51231026649475 and batch: 750, loss is 3.8201630449295045 and perplexity is 45.6116444619756
At time: 496.5789632797241 and batch: 800, loss is 3.8001252126693728 and perplexity is 44.70678199836732
At time: 497.6325898170471 and batch: 850, loss is 3.8077628946304323 and perplexity is 45.0495454737456
At time: 498.6840558052063 and batch: 900, loss is 3.778427529335022 and perplexity is 43.74719643808062
At time: 499.7347733974457 and batch: 950, loss is 3.8747709655761717 and perplexity is 48.17166405821504
At time: 500.8151321411133 and batch: 1000, loss is 3.8416703224182127 and perplexity is 46.60325192141645
At time: 501.8715798854828 and batch: 1050, loss is 3.7912004518508913 and perplexity is 44.309559854982005
At time: 502.9353914260864 and batch: 1100, loss is 3.8128917169570924 and perplexity is 45.28119011269466
At time: 503.9891781806946 and batch: 1150, loss is 3.7739147758483886 and perplexity is 43.55022091010743
At time: 505.0424132347107 and batch: 1200, loss is 3.8222513151168824 and perplexity is 45.706993421847585
At time: 506.0977020263672 and batch: 1250, loss is 3.8067351579666138 and perplexity is 45.00327018765111
At time: 507.16017413139343 and batch: 1300, loss is 3.808536410331726 and perplexity is 45.08440548515064
At time: 508.2234809398651 and batch: 1350, loss is 3.702010517120361 and perplexity is 40.528706160392304
At time: 509.28036761283875 and batch: 1400, loss is 3.735638613700867 and perplexity is 41.914784373491635
At time: 510.3321604728699 and batch: 1450, loss is 3.6451075077056885 and perplexity is 38.28688876587693
At time: 511.3844966888428 and batch: 1500, loss is 3.6436993169784544 and perplexity is 38.233011467801184
At time: 512.4375870227814 and batch: 1550, loss is 3.6505523920059204 and perplexity is 38.49592501808977
At time: 513.4933202266693 and batch: 1600, loss is 3.7476049566268923 and perplexity is 42.41936402250836
At time: 514.5438237190247 and batch: 1650, loss is 3.6847489213943483 and perplexity is 39.83511944789711
At time: 515.5966863632202 and batch: 1700, loss is 3.700468730926514 and perplexity is 40.46626770652135
At time: 516.6488444805145 and batch: 1750, loss is 3.7026140213012697 and perplexity is 40.553172786119774
At time: 517.7023169994354 and batch: 1800, loss is 3.652982292175293 and perplexity is 38.58958001287374
At time: 518.7499737739563 and batch: 1850, loss is 3.669688873291016 and perplexity is 39.2396954436047
At time: 519.7969720363617 and batch: 1900, loss is 3.7554042863845827 and perplexity is 42.75150016664855
At time: 520.8432533740997 and batch: 1950, loss is 3.7096266174316406 and perplexity is 40.838555275234924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.505818211755087 and perplexity of 90.54239660263681
finished 12 epochs...
Completing Train Step...
At time: 524.1880459785461 and batch: 50, loss is 3.873688325881958 and perplexity is 48.11953972359741
At time: 525.2674813270569 and batch: 100, loss is 3.862721552848816 and perplexity is 47.5947067750356
At time: 526.3261713981628 and batch: 150, loss is 3.8307227754592894 and perplexity is 46.0958431409775
At time: 527.4043147563934 and batch: 200, loss is 3.8145221710205077 and perplexity is 45.355079233149745
At time: 528.4592654705048 and batch: 250, loss is 3.8110389375686644 and perplexity is 45.197371729434394
At time: 529.5156071186066 and batch: 300, loss is 3.835118045806885 and perplexity is 46.29889273553078
At time: 530.5762937068939 and batch: 350, loss is 3.8339986324310305 and perplexity is 46.24709413314856
At time: 531.6327800750732 and batch: 400, loss is 3.798116602897644 and perplexity is 44.61707364388236
At time: 532.6835427284241 and batch: 450, loss is 3.8319326305389403 and perplexity is 46.15164618094128
At time: 533.7336814403534 and batch: 500, loss is 3.8626948404312134 and perplexity is 47.593435422333066
At time: 534.7857956886292 and batch: 550, loss is 3.8251302909851073 and perplexity is 45.83877235608318
At time: 535.8404340744019 and batch: 600, loss is 3.8027435636520384 and perplexity is 44.82399342831148
At time: 536.8956880569458 and batch: 650, loss is 3.8296750211715698 and perplexity is 46.047571316601996
At time: 537.9536421298981 and batch: 700, loss is 3.856905908584595 and perplexity is 47.31871620094418
At time: 539.0066084861755 and batch: 750, loss is 3.8036910104751587 and perplexity is 44.86648190309159
At time: 540.0592572689056 and batch: 800, loss is 3.7838933801651002 and perplexity is 43.98696676552856
At time: 541.110639333725 and batch: 850, loss is 3.791916599273682 and perplexity is 44.341303397248446
At time: 542.1670031547546 and batch: 900, loss is 3.763690013885498 and perplexity is 43.10719902419898
At time: 543.2231438159943 and batch: 950, loss is 3.860427374839783 and perplexity is 47.48564120116311
At time: 544.2788074016571 and batch: 1000, loss is 3.8277992534637453 and perplexity is 45.961277727968074
At time: 545.3303689956665 and batch: 1050, loss is 3.7785415983200075 and perplexity is 43.75218692099853
At time: 546.3882372379303 and batch: 1100, loss is 3.8009715986251833 and perplexity is 44.7446372085795
At time: 547.4386751651764 and batch: 1150, loss is 3.7626786708831785 and perplexity is 43.063624898024074
At time: 548.4988868236542 and batch: 1200, loss is 3.8121910858154298 and perplexity is 45.249475812080824
At time: 549.5583922863007 and batch: 1250, loss is 3.7972730350494386 and perplexity is 44.57945198551704
At time: 550.6218640804291 and batch: 1300, loss is 3.7996210718154906 and perplexity is 44.68424916345489
At time: 551.6782579421997 and batch: 1350, loss is 3.693843193054199 and perplexity is 40.199043148042605
At time: 552.7344362735748 and batch: 1400, loss is 3.7283155870437623 and perplexity is 41.60896242801172
At time: 553.7969059944153 and batch: 1450, loss is 3.6389166116714478 and perplexity is 38.05059082077773
At time: 554.8574562072754 and batch: 1500, loss is 3.6384073638916017 and perplexity is 38.031218574935664
At time: 555.9157948493958 and batch: 1550, loss is 3.6456411027908326 and perplexity is 38.30732391311006
At time: 556.9751014709473 and batch: 1600, loss is 3.743692007064819 and perplexity is 42.253703512614244
At time: 558.0309746265411 and batch: 1650, loss is 3.681662230491638 and perplexity is 39.71235031973962
At time: 559.0848240852356 and batch: 1700, loss is 3.6983161067962644 and perplexity is 40.37925273106385
At time: 560.1382303237915 and batch: 1750, loss is 3.7016584730148314 and perplexity is 40.514440779452755
At time: 561.189982175827 and batch: 1800, loss is 3.6529640531539918 and perplexity is 38.588876183120476
At time: 562.2441928386688 and batch: 1850, loss is 3.67042715549469 and perplexity is 39.268676109066746
At time: 563.3041884899139 and batch: 1900, loss is 3.7565935468673706 and perplexity is 42.802373080953984
At time: 564.3609368801117 and batch: 1950, loss is 3.7106895446777344 and perplexity is 40.88198676649665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.50697021484375 and perplexity of 90.6467618261659
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 567.7636377811432 and batch: 50, loss is 3.866715121269226 and perplexity is 47.785159532929804
At time: 568.8501999378204 and batch: 100, loss is 3.8672464323043823 and perplexity is 47.8105550613712
At time: 569.9122111797333 and batch: 150, loss is 3.8418750095367433 and perplexity is 46.61279198309696
At time: 570.9842410087585 and batch: 200, loss is 3.8270798683166505 and perplexity is 45.928225757402835
At time: 572.0516130924225 and batch: 250, loss is 3.8246957635879517 and perplexity is 45.81885848051808
At time: 573.1129376888275 and batch: 300, loss is 3.8479181289672852 and perplexity is 46.89533150222604
At time: 574.1740741729736 and batch: 350, loss is 3.8476931428909302 and perplexity is 46.88478189239415
At time: 575.2314686775208 and batch: 400, loss is 3.811533260345459 and perplexity is 45.219719342743566
At time: 576.2929794788361 and batch: 450, loss is 3.845667600631714 and perplexity is 46.78991090039526
At time: 577.3631482124329 and batch: 500, loss is 3.8778541183471678 and perplexity is 48.32041384907204
At time: 578.4238789081573 and batch: 550, loss is 3.839417986869812 and perplexity is 46.49840388125144
At time: 579.484227180481 and batch: 600, loss is 3.8144980335235594 and perplexity is 45.35398448827542
At time: 580.5762526988983 and batch: 650, loss is 3.8379947090148927 and perplexity is 46.432270806752285
At time: 581.6350018978119 and batch: 700, loss is 3.8615448760986326 and perplexity is 47.538736126280085
At time: 582.6957457065582 and batch: 750, loss is 3.8082545137405397 and perplexity is 45.07169813609205
At time: 583.7558674812317 and batch: 800, loss is 3.7868176746368407 and perplexity is 44.115785869967425
At time: 584.8144500255585 and batch: 850, loss is 3.7946114683151246 and perplexity is 44.46095855811075
At time: 585.8782877922058 and batch: 900, loss is 3.7607675266265868 and perplexity is 42.981402692905924
At time: 586.9420344829559 and batch: 950, loss is 3.8577521514892577 and perplexity is 47.35877627667372
At time: 588.0033724308014 and batch: 1000, loss is 3.8247675132751464 and perplexity is 45.82214608722264
At time: 589.0599827766418 and batch: 1050, loss is 3.7781675815582276 and perplexity is 43.7358259295588
At time: 590.1245455741882 and batch: 1100, loss is 3.798996615409851 and perplexity is 44.65635450823809
At time: 591.1844279766083 and batch: 1150, loss is 3.7602271938323977 and perplexity is 42.958184704775796
At time: 592.2352752685547 and batch: 1200, loss is 3.8073097181320192 and perplexity is 45.029134703662685
At time: 593.2865726947784 and batch: 1250, loss is 3.7898363971710207 and perplexity is 44.249160395946355
At time: 594.3446462154388 and batch: 1300, loss is 3.7875234842300416 and perplexity is 44.14693420595013
At time: 595.3980088233948 and batch: 1350, loss is 3.6780316543579104 and perplexity is 39.56843301789731
At time: 596.4605405330658 and batch: 1400, loss is 3.711726770401001 and perplexity is 40.924412613575456
At time: 597.5231158733368 and batch: 1450, loss is 3.6230307102203367 and perplexity is 37.45089882041462
At time: 598.5837638378143 and batch: 1500, loss is 3.6184073209762575 and perplexity is 37.27814839158657
At time: 599.640905380249 and batch: 1550, loss is 3.626851453781128 and perplexity is 37.594262805035896
At time: 600.6966443061829 and batch: 1600, loss is 3.7221480226516723 and perplexity is 41.35312622704628
At time: 601.7522192001343 and batch: 1650, loss is 3.6586810159683227 and perplexity is 38.810119169684135
At time: 602.812313079834 and batch: 1700, loss is 3.6708269453048707 and perplexity is 39.28437846424609
At time: 603.8744015693665 and batch: 1750, loss is 3.675467948913574 and perplexity is 39.46712113315081
At time: 604.9359292984009 and batch: 1800, loss is 3.6258449220657347 and perplexity is 37.556442024306484
At time: 605.9985115528107 and batch: 1850, loss is 3.6404167938232423 and perplexity is 38.10771647672337
At time: 607.0575640201569 and batch: 1900, loss is 3.7266323232650755 and perplexity is 41.53898248256491
At time: 608.1152591705322 and batch: 1950, loss is 3.6845117807388306 and perplexity is 39.8256740415478
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499609942768895 and perplexity of 89.98202631445666
finished 14 epochs...
Completing Train Step...
At time: 611.475572347641 and batch: 50, loss is 3.8614663314819335 and perplexity is 47.535002361108184
At time: 612.5239934921265 and batch: 100, loss is 3.855656943321228 and perplexity is 47.259653659311226
At time: 613.5857534408569 and batch: 150, loss is 3.826874933242798 and perplexity is 45.91881441745508
At time: 614.639990568161 and batch: 200, loss is 3.8114183712005616 and perplexity is 45.21452438628356
At time: 615.6924440860748 and batch: 250, loss is 3.80946617603302 and perplexity is 45.126342912003395
At time: 616.7419896125793 and batch: 300, loss is 3.8305786085128783 and perplexity is 46.0891981230371
At time: 617.7923347949982 and batch: 350, loss is 3.830787630081177 and perplexity is 46.09883276639946
At time: 618.8474631309509 and batch: 400, loss is 3.7935514736175535 and perplexity is 44.4138551468837
At time: 619.9014000892639 and batch: 450, loss is 3.828514046669006 and perplexity is 45.99414228127355
At time: 620.9555342197418 and batch: 500, loss is 3.8612786293029786 and perplexity is 47.52608077491515
At time: 622.005166053772 and batch: 550, loss is 3.824103317260742 and perplexity is 45.79172130554793
At time: 623.0548305511475 and batch: 600, loss is 3.799546756744385 and perplexity is 44.68092857368746
At time: 624.1165053844452 and batch: 650, loss is 3.8232708406448364 and perplexity is 45.75361663118477
At time: 625.1746189594269 and batch: 700, loss is 3.848604688644409 and perplexity is 46.927539000800614
At time: 626.2342600822449 and batch: 750, loss is 3.7964894866943357 and perplexity is 44.544535510402135
At time: 627.2890589237213 and batch: 800, loss is 3.7751318073272704 and perplexity is 43.60325516550037
At time: 628.3388736248016 and batch: 850, loss is 3.783551421165466 and perplexity is 43.97192759791239
At time: 629.3887174129486 and batch: 900, loss is 3.7509914302825926 and perplexity is 42.563259593022885
At time: 630.4402635097504 and batch: 950, loss is 3.8486194038391113 and perplexity is 46.92822955375471
At time: 631.4904601573944 and batch: 1000, loss is 3.815602536201477 and perplexity is 45.40410576004105
At time: 632.5433640480042 and batch: 1050, loss is 3.7695549058914186 and perplexity is 43.360760920911396
At time: 633.6438562870026 and batch: 1100, loss is 3.7908008766174315 and perplexity is 44.29185838902767
At time: 634.6977925300598 and batch: 1150, loss is 3.7530204677581787 and perplexity is 42.64970971743178
At time: 635.747998714447 and batch: 1200, loss is 3.8006165504455565 and perplexity is 44.72875352649359
At time: 636.7976586818695 and batch: 1250, loss is 3.783757472038269 and perplexity is 43.98098898549411
At time: 637.8530218601227 and batch: 1300, loss is 3.782666606903076 and perplexity is 43.93303781688265
At time: 638.9037773609161 and batch: 1350, loss is 3.674371528625488 and perplexity is 39.423872294612664
At time: 639.9560823440552 and batch: 1400, loss is 3.7096566104888917 and perplexity is 40.83978016673038
At time: 641.0159711837769 and batch: 1450, loss is 3.6221612882614136 and perplexity is 37.418352336962585
At time: 642.0670211315155 and batch: 1500, loss is 3.619135627746582 and perplexity is 37.30530820858408
At time: 643.1166813373566 and batch: 1550, loss is 3.6284767770767212 and perplexity is 37.655415318994244
At time: 644.1657402515411 and batch: 1600, loss is 3.72498929977417 and perplexity is 41.47078899564904
At time: 645.2162108421326 and batch: 1650, loss is 3.6624217557907106 and perplexity is 38.955569604481695
At time: 646.2703230381012 and batch: 1700, loss is 3.675649333000183 and perplexity is 39.47428049014571
At time: 647.3252301216125 and batch: 1750, loss is 3.681294960975647 and perplexity is 39.697767862068815
At time: 648.3765573501587 and batch: 1800, loss is 3.631978645324707 and perplexity is 37.78751077771944
At time: 649.4265460968018 and batch: 1850, loss is 3.6470196866989135 and perplexity is 38.360170191563356
At time: 650.4745984077454 and batch: 1900, loss is 3.7327387619018553 and perplexity is 41.79341377404841
At time: 651.5250287055969 and batch: 1950, loss is 3.6902826023101807 and perplexity is 40.05616532277047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499157147074855 and perplexity of 89.94129206324317
finished 15 epochs...
Completing Train Step...
At time: 654.8598608970642 and batch: 50, loss is 3.8578135538101197 and perplexity is 47.36168430472922
At time: 655.938374042511 and batch: 100, loss is 3.850095272064209 and perplexity is 46.99754057099616
At time: 656.9894814491272 and batch: 150, loss is 3.8202975177764893 and perplexity is 45.61777840207701
At time: 658.0404617786407 and batch: 200, loss is 3.804300060272217 and perplexity is 44.89381614790257
At time: 659.0918972492218 and batch: 250, loss is 3.802083191871643 and perplexity is 44.7944026994833
At time: 660.1726016998291 and batch: 300, loss is 3.822556538581848 and perplexity is 45.72094639803251
At time: 661.2333669662476 and batch: 350, loss is 3.8229321336746214 and perplexity is 45.73812218650558
At time: 662.2912180423737 and batch: 400, loss is 3.7854573154449462 and perplexity is 44.05581335648021
At time: 663.3483221530914 and batch: 450, loss is 3.8208727836608887 and perplexity is 45.64402830332624
At time: 664.4129958152771 and batch: 500, loss is 3.853668222427368 and perplexity is 47.16576079294054
At time: 665.4643144607544 and batch: 550, loss is 3.816829686164856 and perplexity is 45.45985760770426
At time: 666.5168981552124 and batch: 600, loss is 3.792320737838745 and perplexity is 44.35922704955204
At time: 667.5683069229126 and batch: 650, loss is 3.816246075630188 and perplexity is 45.43333449623635
At time: 668.6208839416504 and batch: 700, loss is 3.8422144508361815 and perplexity is 46.628616975454186
At time: 669.6758666038513 and batch: 750, loss is 3.790519161224365 and perplexity is 44.27938244814677
At time: 670.7269251346588 and batch: 800, loss is 3.7692326307296753 and perplexity is 43.34678907618248
At time: 671.7849650382996 and batch: 850, loss is 3.7778089094161986 and perplexity is 43.72014192006602
At time: 672.8364589214325 and batch: 900, loss is 3.7459593200683594 and perplexity is 42.34961457314593
At time: 673.8904225826263 and batch: 950, loss is 3.843906784057617 and perplexity is 46.70759494270086
At time: 674.9445915222168 and batch: 1000, loss is 3.8109517192840574 and perplexity is 45.19342986410727
At time: 675.990795135498 and batch: 1050, loss is 3.765184049606323 and perplexity is 43.17165085404507
At time: 677.0426204204559 and batch: 1100, loss is 3.7866762924194335 and perplexity is 44.109549123231396
At time: 678.0871779918671 and batch: 1150, loss is 3.7493692016601563 and perplexity is 42.4942682300587
At time: 679.1392114162445 and batch: 1200, loss is 3.797425470352173 and perplexity is 44.5862479857382
At time: 680.1938629150391 and batch: 1250, loss is 3.780992660522461 and perplexity is 43.85955778521436
At time: 681.2485802173615 and batch: 1300, loss is 3.780288190841675 and perplexity is 43.82867093724333
At time: 682.3028285503387 and batch: 1350, loss is 3.672536473274231 and perplexity is 39.35159364473554
At time: 683.354748249054 and batch: 1400, loss is 3.7084650802612305 and perplexity is 40.79114731368176
At time: 684.4068644046783 and batch: 1450, loss is 3.6214949464797974 and perplexity is 37.39342723064336
At time: 685.4622540473938 and batch: 1500, loss is 3.619071698188782 and perplexity is 37.30292337295827
At time: 686.5274016857147 and batch: 1550, loss is 3.6288056898117067 and perplexity is 37.667802701706115
At time: 687.5826306343079 and batch: 1600, loss is 3.7257609939575196 and perplexity is 41.502804113647294
At time: 688.6356391906738 and batch: 1650, loss is 3.663570594787598 and perplexity is 39.00034899922164
At time: 689.6928761005402 and batch: 1700, loss is 3.6771157121658327 and perplexity is 39.532207213525794
At time: 690.7445116043091 and batch: 1750, loss is 3.683223648071289 and perplexity is 39.77440631671258
At time: 691.7998135089874 and batch: 1800, loss is 3.6342146730422975 and perplexity is 37.872099235020805
At time: 692.8584439754486 and batch: 1850, loss is 3.6495310783386232 and perplexity is 38.456628674095924
At time: 693.9159388542175 and batch: 1900, loss is 3.7350502967834474 and perplexity is 41.89013244903786
At time: 694.9718415737152 and batch: 1950, loss is 3.692473645210266 and perplexity is 40.14402631786103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499280069040697 and perplexity of 89.95234850319974
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 698.4528391361237 and batch: 50, loss is 3.8560195541381836 and perplexity is 47.27679362831494
At time: 699.541515827179 and batch: 100, loss is 3.850905833244324 and perplexity is 47.03565039602971
At time: 700.6092395782471 and batch: 150, loss is 3.822872476577759 and perplexity is 45.73539366430865
At time: 701.669853925705 and batch: 200, loss is 3.807269377708435 and perplexity is 45.027318245933685
At time: 702.7294089794159 and batch: 250, loss is 3.8057813835144043 and perplexity is 44.960367681189865
At time: 703.7893557548523 and batch: 300, loss is 3.825848865509033 and perplexity is 45.871722767351514
At time: 704.8495485782623 and batch: 350, loss is 3.8264179372787477 and perplexity is 45.89783449882654
At time: 705.9118456840515 and batch: 400, loss is 3.789423875808716 and perplexity is 44.23091043652684
At time: 706.9764025211334 and batch: 450, loss is 3.8247761821746824 and perplexity is 45.82254331652536
At time: 708.0364100933075 and batch: 500, loss is 3.8581225728988646 and perplexity is 47.3763222308373
At time: 709.0949766635895 and batch: 550, loss is 3.8217989778518677 and perplexity is 45.686323120777274
At time: 710.1565616130829 and batch: 600, loss is 3.7958934783935545 and perplexity is 44.517994507598154
At time: 711.2200975418091 and batch: 650, loss is 3.8184652948379516 and perplexity is 45.534272985714196
At time: 712.2840685844421 and batch: 700, loss is 3.8436266565322876 and perplexity is 46.694512692150255
At time: 713.3738844394684 and batch: 750, loss is 3.7920776271820067 and perplexity is 44.34844415950247
At time: 714.4335865974426 and batch: 800, loss is 3.769338836669922 and perplexity is 43.35139300715108
At time: 715.49218916893 and batch: 850, loss is 3.7780871105194094 and perplexity is 43.732306603816475
At time: 716.5501663684845 and batch: 900, loss is 3.744176526069641 and perplexity is 42.27418119550288
At time: 717.6183428764343 and batch: 950, loss is 3.8408713054656984 and perplexity is 46.566030005540135
At time: 718.6851029396057 and batch: 1000, loss is 3.8079433059692382 and perplexity is 45.05767365574317
At time: 719.7483949661255 and batch: 1050, loss is 3.7630725383758543 and perplexity is 43.080589600691326
At time: 720.8067128658295 and batch: 1100, loss is 3.78395414352417 and perplexity is 43.98963964259019
At time: 721.8653841018677 and batch: 1150, loss is 3.747833728790283 and perplexity is 42.42906950231493
At time: 722.9249746799469 and batch: 1200, loss is 3.7965170526504517 and perplexity is 44.54576344003767
At time: 723.9849739074707 and batch: 1250, loss is 3.7785985803604127 and perplexity is 43.75468008091348
At time: 725.0474591255188 and batch: 1300, loss is 3.7759588766098022 and perplexity is 43.63933299584222
At time: 726.114846944809 and batch: 1350, loss is 3.665483913421631 and perplexity is 39.0750405252541
At time: 727.1775939464569 and batch: 1400, loss is 3.7007614517211915 and perplexity is 40.47811475841667
At time: 728.236407995224 and batch: 1450, loss is 3.6135152769088745 and perplexity is 37.09622739248908
At time: 729.2985956668854 and batch: 1500, loss is 3.6091883468627928 and perplexity is 36.936061375054756
At time: 730.3593621253967 and batch: 1550, loss is 3.619435067176819 and perplexity is 37.31648056145689
At time: 731.4225914478302 and batch: 1600, loss is 3.7149403572082518 and perplexity is 41.05613830866043
At time: 732.4861009120941 and batch: 1650, loss is 3.6520829677581785 and perplexity is 38.55489106197023
At time: 733.54722905159 and batch: 1700, loss is 3.664394540786743 and perplexity is 39.03249642279663
At time: 734.6055879592896 and batch: 1750, loss is 3.6713359928131104 and perplexity is 39.30438116994787
At time: 735.6648640632629 and batch: 1800, loss is 3.6227228021621705 and perplexity is 37.4393691620107
At time: 736.7262306213379 and batch: 1850, loss is 3.6379043436050416 and perplexity is 38.012092911171585
At time: 737.7875962257385 and batch: 1900, loss is 3.7234165334701537 and perplexity is 41.405616400180975
At time: 738.8501706123352 and batch: 1950, loss is 3.6830343341827394 and perplexity is 39.76687718189539
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.498451126453489 and perplexity of 89.87781406735806
finished 17 epochs...
Completing Train Step...
At time: 742.2283565998077 and batch: 50, loss is 3.8549496650695803 and perplexity is 47.2262397519555
At time: 743.2762784957886 and batch: 100, loss is 3.848114914894104 and perplexity is 46.904560751562585
At time: 744.3302335739136 and batch: 150, loss is 3.8192462730407715 and perplexity is 45.56984815030315
At time: 745.3846211433411 and batch: 200, loss is 3.803509387969971 and perplexity is 44.85833388020395
At time: 746.4384341239929 and batch: 250, loss is 3.8019378995895385 and perplexity is 44.78789489126818
At time: 747.4825968742371 and batch: 300, loss is 3.821700835227966 and perplexity is 45.681839565167344
At time: 748.5266864299774 and batch: 350, loss is 3.822066502571106 and perplexity is 45.69854697656208
At time: 749.5696430206299 and batch: 400, loss is 3.785102729797363 and perplexity is 44.040194566634405
At time: 750.6182730197906 and batch: 450, loss is 3.820581669807434 and perplexity is 45.63074262827553
At time: 751.6720445156097 and batch: 500, loss is 3.8539770793914796 and perplexity is 47.180330516493534
At time: 752.7269449234009 and batch: 550, loss is 3.817746887207031 and perplexity is 45.50157256405548
At time: 753.7820053100586 and batch: 600, loss is 3.7920656108856203 and perplexity is 44.34791125865493
At time: 754.8365612030029 and batch: 650, loss is 3.814948682785034 and perplexity is 45.37442783393333
At time: 755.8870511054993 and batch: 700, loss is 3.8404191446304323 and perplexity is 46.544979429999366
At time: 756.9363584518433 and batch: 750, loss is 3.789065556526184 and perplexity is 44.21506448755758
At time: 757.9857556819916 and batch: 800, loss is 3.7665442562103273 and perplexity is 43.230413174030375
At time: 759.0361411571503 and batch: 850, loss is 3.7751423931121826 and perplexity is 43.6037167426241
At time: 760.0861685276031 and batch: 900, loss is 3.7416405200958254 and perplexity is 42.16710944413789
At time: 761.1418211460114 and batch: 950, loss is 3.8389100646972656 and perplexity is 46.474792307860575
At time: 762.2019522190094 and batch: 1000, loss is 3.805983748435974 and perplexity is 44.96946700313015
At time: 763.2608110904694 and batch: 1050, loss is 3.7612478923797608 and perplexity is 43.002054446583465
At time: 764.3129756450653 and batch: 1100, loss is 3.7823947048187256 and perplexity is 43.92109395618229
At time: 765.364012002945 and batch: 1150, loss is 3.74638916015625 and perplexity is 42.36782204806715
At time: 766.4507057666779 and batch: 1200, loss is 3.7949894952774046 and perplexity is 44.47776917644782
At time: 767.5053737163544 and batch: 1250, loss is 3.7772721433639527 and perplexity is 43.69668072923265
At time: 768.5601737499237 and batch: 1300, loss is 3.7750526380538942 and perplexity is 43.59980326411615
At time: 769.6146109104156 and batch: 1350, loss is 3.665080261230469 and perplexity is 39.05927098244572
At time: 770.6682996749878 and batch: 1400, loss is 3.7006906509399413 and perplexity is 40.47524897771919
At time: 771.7191338539124 and batch: 1450, loss is 3.613937077522278 and perplexity is 37.111877904423906
At time: 772.7711100578308 and batch: 1500, loss is 3.6099903106689455 and perplexity is 36.96569464023425
At time: 773.8217532634735 and batch: 1550, loss is 3.620558943748474 and perplexity is 37.3584432557241
At time: 774.8712272644043 and batch: 1600, loss is 3.7165321922302246 and perplexity is 41.12154495196849
At time: 775.921905040741 and batch: 1650, loss is 3.654022479057312 and perplexity is 38.62974127177191
At time: 776.9779016971588 and batch: 1700, loss is 3.666603193283081 and perplexity is 39.11880091669326
At time: 778.0328958034515 and batch: 1750, loss is 3.6738234424591063 and perplexity is 39.4022705359361
At time: 779.0927317142487 and batch: 1800, loss is 3.625093488693237 and perplexity is 37.52823146092397
At time: 780.1501312255859 and batch: 1850, loss is 3.640196967124939 and perplexity is 38.09934030391734
At time: 781.2026996612549 and batch: 1900, loss is 3.725407290458679 and perplexity is 41.488127022442875
At time: 782.2569456100464 and batch: 1950, loss is 3.684792995452881 and perplexity is 39.836875181974186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.498216921784157 and perplexity of 89.85676672842287
finished 18 epochs...
Completing Train Step...
At time: 785.5800135135651 and batch: 50, loss is 3.853928780555725 and perplexity is 47.1780518164888
At time: 786.6930105686188 and batch: 100, loss is 3.846178765296936 and perplexity is 46.81383436343002
At time: 787.7465422153473 and batch: 150, loss is 3.816871280670166 and perplexity is 45.46174852731858
At time: 788.8048417568207 and batch: 200, loss is 3.800936121940613 and perplexity is 44.74304984535639
At time: 789.8546421527863 and batch: 250, loss is 3.79929575920105 and perplexity is 44.669715177707836
At time: 790.9024851322174 and batch: 300, loss is 3.8188591623306274 and perplexity is 45.55221098801199
At time: 791.9551303386688 and batch: 350, loss is 3.8192408514022826 and perplexity is 45.569601087730234
At time: 793.0791726112366 and batch: 400, loss is 3.7821603870391844 and perplexity is 43.910803668617206
At time: 794.1358325481415 and batch: 450, loss is 3.81783709526062 and perplexity is 45.505677357491656
At time: 795.2055425643921 and batch: 500, loss is 3.8512867164611815 and perplexity is 47.05356889807127
At time: 796.2761836051941 and batch: 550, loss is 3.815066337585449 and perplexity is 45.37976666724761
At time: 797.346626996994 and batch: 600, loss is 3.789509587287903 and perplexity is 44.234701695761046
At time: 798.4046092033386 and batch: 650, loss is 3.812565999031067 and perplexity is 45.26644361909222
At time: 799.4586381912231 and batch: 700, loss is 3.83822979927063 and perplexity is 46.44318786436735
At time: 800.5201241970062 and batch: 750, loss is 3.7870396471023557 and perplexity is 44.12557944663708
At time: 801.57275390625 and batch: 800, loss is 3.7646473932266233 and perplexity is 43.148488727799375
At time: 802.6292533874512 and batch: 850, loss is 3.773178653717041 and perplexity is 43.518174425180916
At time: 803.6901390552521 and batch: 900, loss is 3.7399614477157592 and perplexity is 42.09636722259836
At time: 804.75270652771 and batch: 950, loss is 3.837505826950073 and perplexity is 46.40957645020997
At time: 805.8136286735535 and batch: 1000, loss is 3.804593396186829 and perplexity is 44.90698704817732
At time: 806.8714303970337 and batch: 1050, loss is 3.7599772214889526 and perplexity is 42.94744768870944
At time: 807.9267654418945 and batch: 1100, loss is 3.7812482929229736 and perplexity is 43.87077114244406
At time: 808.9802532196045 and batch: 1150, loss is 3.7453934717178345 and perplexity is 42.32565789215777
At time: 810.032949924469 and batch: 1200, loss is 3.7940013456344603 and perplexity is 44.43384019249657
At time: 811.0851714611053 and batch: 1250, loss is 3.7764336395263673 and perplexity is 43.66005625177974
At time: 812.1366918087006 and batch: 1300, loss is 3.774460725784302 and perplexity is 43.57400364192203
At time: 813.2017905712128 and batch: 1350, loss is 3.664788565635681 and perplexity is 39.04787922670777
At time: 814.2585411071777 and batch: 1400, loss is 3.7006555938720704 and perplexity is 40.473830059040395
At time: 815.31405210495 and batch: 1450, loss is 3.6141950464248658 and perplexity is 37.12145284980586
At time: 816.3658483028412 and batch: 1500, loss is 3.610543613433838 and perplexity is 36.98615352074048
At time: 817.4184575080872 and batch: 1550, loss is 3.6213097047805785 and perplexity is 37.386501050172065
At time: 818.4729514122009 and batch: 1600, loss is 3.717531204223633 and perplexity is 41.16264639556217
At time: 819.5353968143463 and batch: 1650, loss is 3.6552119302749633 and perplexity is 38.67571680196988
At time: 820.5921664237976 and batch: 1700, loss is 3.6679588031768797 and perplexity is 39.171866710380456
At time: 821.6457240581512 and batch: 1750, loss is 3.675360598564148 and perplexity is 39.462884551309656
At time: 822.6980340480804 and batch: 1800, loss is 3.6265922164916993 and perplexity is 37.58451823338099
At time: 823.74955701828 and batch: 1850, loss is 3.6416834688186643 and perplexity is 38.156017152488126
At time: 824.7973628044128 and batch: 1900, loss is 3.726696767807007 and perplexity is 41.541659529522896
At time: 825.8496382236481 and batch: 1950, loss is 3.6859258651733398 and perplexity is 39.88203074448092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.498141124636628 and perplexity of 89.84995609993503
finished 19 epochs...
Completing Train Step...
At time: 829.19615650177 and batch: 50, loss is 3.8528973388671877 and perplexity is 47.129415494138414
At time: 830.2715766429901 and batch: 100, loss is 3.8445472240448 and perplexity is 46.73751793512497
At time: 831.3185698986053 and batch: 150, loss is 3.8149651527404784 and perplexity is 45.37517515489222
At time: 832.3730564117432 and batch: 200, loss is 3.7988827085494994 and perplexity is 44.65126813279334
At time: 833.4285242557526 and batch: 250, loss is 3.797184190750122 and perplexity is 44.57549153127597
At time: 834.4853785037994 and batch: 300, loss is 3.8166048955917358 and perplexity is 45.44963980873413
At time: 835.5414302349091 and batch: 350, loss is 3.8170390558242797 and perplexity is 45.469376519059885
At time: 836.593781709671 and batch: 400, loss is 3.7798636388778686 and perplexity is 43.81006733830257
At time: 837.6506378650665 and batch: 450, loss is 3.8157071399688722 and perplexity is 45.408855448972105
At time: 838.7028107643127 and batch: 500, loss is 3.8491935777664184 and perplexity is 46.95518225664832
At time: 839.754412651062 and batch: 550, loss is 3.8129934215545656 and perplexity is 45.28579565210647
At time: 840.8161754608154 and batch: 600, loss is 3.787521481513977 and perplexity is 44.14684579226433
At time: 841.8740694522858 and batch: 650, loss is 3.8106886386871337 and perplexity is 45.18154191341474
At time: 842.9300212860107 and batch: 700, loss is 3.8365040731430056 and perplexity is 46.36310875879587
At time: 843.9825284481049 and batch: 750, loss is 3.7854389333724976 and perplexity is 44.0550035267705
At time: 845.0393486022949 and batch: 800, loss is 3.763128399848938 and perplexity is 43.08299621310557
At time: 846.1479394435883 and batch: 850, loss is 3.7716293859481813 and perplexity is 43.450805320051074
At time: 847.2063095569611 and batch: 900, loss is 3.7386328125 and perplexity is 42.0404736459603
At time: 848.2636861801147 and batch: 950, loss is 3.836352982521057 and perplexity is 46.35610425702863
At time: 849.3193452358246 and batch: 1000, loss is 3.8034595918655394 and perplexity is 44.85610016554104
At time: 850.3742015361786 and batch: 1050, loss is 3.758946542739868 and perplexity is 42.903205470722746
At time: 851.4259247779846 and batch: 1100, loss is 3.7803021764755247 and perplexity is 43.8292839132736
At time: 852.4786145687103 and batch: 1150, loss is 3.7445752477645873 and perplexity is 42.291040189481585
At time: 853.5352725982666 and batch: 1200, loss is 3.7932326555252076 and perplexity is 44.3996974632948
At time: 854.5958442687988 and batch: 1250, loss is 3.7757855224609376 and perplexity is 43.63176859209303
At time: 855.6601123809814 and batch: 1300, loss is 3.7739710712432863 and perplexity is 43.552672656001796
At time: 856.7185711860657 and batch: 1350, loss is 3.664509425163269 and perplexity is 39.03698090440591
At time: 857.7747831344604 and batch: 1400, loss is 3.7005764865875244 and perplexity is 40.47062841088776
At time: 858.8321132659912 and batch: 1450, loss is 3.6143144035339354 and perplexity is 37.12588382353133
At time: 859.886931180954 and batch: 1500, loss is 3.610880637168884 and perplexity is 36.99862083311712
At time: 860.9463613033295 and batch: 1550, loss is 3.621788139343262 and perplexity is 37.404392324012875
At time: 862.0055315494537 and batch: 1600, loss is 3.718165397644043 and perplexity is 41.18875975465793
At time: 863.0574893951416 and batch: 1650, loss is 3.655978240966797 and perplexity is 38.70536577598155
At time: 864.1087648868561 and batch: 1700, loss is 3.6688360261917112 and perplexity is 39.206244249572485
At time: 865.1608283519745 and batch: 1750, loss is 3.676370801925659 and perplexity is 39.502770232871136
At time: 866.2236371040344 and batch: 1800, loss is 3.627602581977844 and perplexity is 37.62251152373994
At time: 867.2795975208282 and batch: 1850, loss is 3.642707176208496 and perplexity is 38.19509774934861
At time: 868.3334543704987 and batch: 1900, loss is 3.727583060264587 and perplexity is 41.57849390964476
At time: 869.3849937915802 and batch: 1950, loss is 3.6867070055007933 and perplexity is 39.91319637781797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.498137434138808 and perplexity of 89.84962450947984
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc0f4432b38>
ELAPSED
4491.194621801376


RESULTS SO FAR:
[{'best_accuracy': -94.78310464460193, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.83547208165798, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.24245156315881022, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.32612507610596975, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.75140648791492, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.5466017702903482, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44410872475199714, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -92.11489487016956, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.961697908824608, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.8996370580396494, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -89.84962450947984, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.4930294951606292, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.7555409501871296, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.530388264419721, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44136510739280954, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 1 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5494625568389893 and batch: 50, loss is 7.22132737159729 and perplexity is 1368.304103827285
At time: 2.6203105449676514 and batch: 100, loss is 6.468475942611694 and perplexity is 644.5007219902199
At time: 3.673191547393799 and batch: 150, loss is 6.222870759963989 and perplexity is 504.14844577084585
At time: 4.726451635360718 and batch: 200, loss is 6.0901987266540525 and perplexity is 441.50914206298194
At time: 5.7756805419921875 and batch: 250, loss is 6.030394649505615 and perplexity is 415.8791234905079
At time: 6.822213649749756 and batch: 300, loss is 5.961547117233277 and perplexity is 388.2102666664241
At time: 7.868931531906128 and batch: 350, loss is 5.922948970794677 and perplexity is 373.51156606292204
At time: 8.920457601547241 and batch: 400, loss is 5.874133577346802 and perplexity is 355.71632643284966
At time: 9.97380542755127 and batch: 450, loss is 5.7979184436798095 and perplexity is 329.6127378505545
At time: 11.033783912658691 and batch: 500, loss is 5.7806940841674805 and perplexity is 323.9839845493871
At time: 12.099870204925537 and batch: 550, loss is 5.725183296203613 and perplexity is 306.48943844555413
At time: 13.165651082992554 and batch: 600, loss is 5.765692110061646 and perplexity is 319.15986136380894
At time: 14.234024047851562 and batch: 650, loss is 5.844712581634521 and perplexity is 345.4032522747507
At time: 15.298638105392456 and batch: 700, loss is 5.752596979141235 and perplexity is 315.00766729272647
At time: 16.36250877380371 and batch: 750, loss is 5.706740827560425 and perplexity is 300.88881994456426
At time: 17.426652431488037 and batch: 800, loss is 5.700512638092041 and perplexity is 299.0206510588265
At time: 18.490966081619263 and batch: 850, loss is 5.728909358978272 and perplexity is 307.63356755770565
At time: 19.557950496673584 and batch: 900, loss is 5.733383016586304 and perplexity is 309.0128978329384
At time: 20.633583545684814 and batch: 950, loss is 5.7580772972106935 and perplexity is 316.7387486093288
At time: 21.713972806930542 and batch: 1000, loss is 5.733470516204834 and perplexity is 309.0399375265839
At time: 22.784900665283203 and batch: 1050, loss is 5.633463773727417 and perplexity is 279.629013742882
At time: 23.860517740249634 and batch: 1100, loss is 5.719113750457764 and perplexity is 304.6348208151412
At time: 24.94266176223755 and batch: 1150, loss is 5.6290670585632325 and perplexity is 278.4022634298672
At time: 26.013527154922485 and batch: 1200, loss is 5.712211408615112 and perplexity is 302.53936723252133
At time: 27.077309131622314 and batch: 1250, loss is 5.647261581420898 and perplexity is 283.5140217614945
At time: 28.145501375198364 and batch: 1300, loss is 5.664359865188598 and perplexity is 288.4033050188561
At time: 29.21200203895569 and batch: 1350, loss is 5.632214756011963 and perplexity is 279.2799701771376
At time: 30.27785611152649 and batch: 1400, loss is 5.647963132858276 and perplexity is 283.712991216471
At time: 31.342432022094727 and batch: 1450, loss is 5.613278522491455 and perplexity is 274.04121711210837
At time: 32.40631985664368 and batch: 1500, loss is 5.5939537620544435 and perplexity is 268.79627806115286
At time: 33.47041130065918 and batch: 1550, loss is 5.583760652542114 and perplexity is 266.07032473481337
At time: 34.53728270530701 and batch: 1600, loss is 5.603069334030152 and perplexity is 271.25771152346516
At time: 35.60507583618164 and batch: 1650, loss is 5.586292610168457 and perplexity is 266.7448571060018
At time: 36.677562952041626 and batch: 1700, loss is 5.5997772121429445 and perplexity is 270.36616641708275
At time: 37.75098156929016 and batch: 1750, loss is 5.617115211486817 and perplexity is 275.0946475844044
At time: 38.823694944381714 and batch: 1800, loss is 5.603201389312744 and perplexity is 271.29353490249696
At time: 39.887126445770264 and batch: 1850, loss is 5.577385473251343 and perplexity is 264.37947417516443
At time: 40.95086169242859 and batch: 1900, loss is 5.5802704620361325 and perplexity is 265.1433072882788
At time: 42.024070262908936 and batch: 1950, loss is 5.516122646331787 and perplexity is 248.66898793014013
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.05887820221657 and perplexity of 157.41383075273538
finished 1 epochs...
Completing Train Step...
At time: 45.42150068283081 and batch: 50, loss is 5.292385816574097 and perplexity is 198.8172013876442
At time: 46.47400760650635 and batch: 100, loss is 5.215499811172485 and perplexity is 184.1038151315789
At time: 47.534953117370605 and batch: 150, loss is 5.1430184936523435 and perplexity is 171.23185128908787
At time: 48.58810472488403 and batch: 200, loss is 5.111361532211304 and perplexity is 165.89607402542703
At time: 49.63637924194336 and batch: 250, loss is 5.12390025138855 and perplexity is 167.98929403466747
At time: 50.68296456336975 and batch: 300, loss is 5.139916105270386 and perplexity is 170.70144676885843
At time: 51.735424518585205 and batch: 350, loss is 5.121026344299317 and perplexity is 167.50720148803356
At time: 52.78877568244934 and batch: 400, loss is 5.085318984985352 and perplexity is 161.63148903351916
At time: 53.843262910842896 and batch: 450, loss is 5.0516150856018065 and perplexity is 156.27465772435855
At time: 54.892253398895264 and batch: 500, loss is 5.039863128662109 and perplexity is 154.44887395510654
At time: 55.9660439491272 and batch: 550, loss is 5.0056375312805175 and perplexity is 149.25220578321466
At time: 57.01321578025818 and batch: 600, loss is 4.9962548828125 and perplexity is 147.85837394573025
At time: 58.065088748931885 and batch: 650, loss is 5.073672342300415 and perplexity is 159.75994459410015
At time: 59.11725616455078 and batch: 700, loss is 5.0491409015655515 and perplexity is 155.88848339113093
At time: 60.16722083091736 and batch: 750, loss is 5.0052047443389895 and perplexity is 149.1876253533488
At time: 61.221439361572266 and batch: 800, loss is 4.98530161857605 and perplexity is 146.24767939128347
At time: 62.26823282241821 and batch: 850, loss is 4.988805961608887 and perplexity is 146.76108046897346
At time: 63.31796145439148 and batch: 900, loss is 4.998399486541748 and perplexity is 148.1758118334671
At time: 64.36956024169922 and batch: 950, loss is 5.0634041690826415 and perplexity is 158.12789523214067
At time: 65.42210149765015 and batch: 1000, loss is 5.028107576370239 and perplexity is 152.64387232294652
At time: 66.471506357193 and batch: 1050, loss is 4.944939289093018 and perplexity is 140.46232299755587
At time: 67.52013087272644 and batch: 1100, loss is 5.034409656524658 and perplexity is 153.60888383748232
At time: 68.57006549835205 and batch: 1150, loss is 4.9485631275177 and perplexity is 140.97225916594647
At time: 69.62120056152344 and batch: 1200, loss is 5.021590490341186 and perplexity is 151.65231362137877
At time: 70.67173385620117 and batch: 1250, loss is 4.969422826766968 and perplexity is 143.9437828918396
At time: 71.7238302230835 and batch: 1300, loss is 4.987455139160156 and perplexity is 146.56296614563894
At time: 72.77490377426147 and batch: 1350, loss is 4.909364986419678 and perplexity is 135.55330888027217
At time: 73.82683753967285 and batch: 1400, loss is 4.926291847229004 and perplexity is 137.86733017956905
At time: 74.8788013458252 and batch: 1450, loss is 4.8697590827941895 and perplexity is 130.28952412698246
At time: 75.93045568466187 and batch: 1500, loss is 4.846298656463623 and perplexity is 127.26845271924743
At time: 76.98431348800659 and batch: 1550, loss is 4.8522525405883785 and perplexity is 128.02845457587847
At time: 78.03897190093994 and batch: 1600, loss is 4.916755199432373 and perplexity is 136.55878748179444
At time: 79.09211707115173 and batch: 1650, loss is 4.8823678588867185 and perplexity is 131.94271602499236
At time: 80.14787316322327 and batch: 1700, loss is 4.903143100738525 and perplexity is 134.7125300160465
At time: 81.208176612854 and batch: 1750, loss is 4.916139192581177 and perplexity is 136.47469223739725
At time: 82.25682425498962 and batch: 1800, loss is 4.870448350906372 and perplexity is 130.3793594980863
At time: 83.30606293678284 and batch: 1850, loss is 4.885755605697632 and perplexity is 132.39046253811452
At time: 84.35406732559204 and batch: 1900, loss is 4.9399303150177 and perplexity is 139.7605100119904
At time: 85.4026358127594 and batch: 1950, loss is 4.866007404327393 and perplexity is 129.80163549775457
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.744767157976018 and perplexity of 114.98102997025786
finished 2 epochs...
Completing Train Step...
At time: 88.74515414237976 and batch: 50, loss is 4.788474264144898 and perplexity is 120.1179605034101
At time: 89.84314370155334 and batch: 100, loss is 4.741311321258545 and perplexity is 114.58436011298177
At time: 90.89740586280823 and batch: 150, loss is 4.6898981475830075 and perplexity is 108.84209341255291
At time: 91.94954013824463 and batch: 200, loss is 4.677940158843994 and perplexity is 107.5483118149086
At time: 93.00478768348694 and batch: 250, loss is 4.6888994693756105 and perplexity is 108.73344944502544
At time: 94.05840516090393 and batch: 300, loss is 4.724487419128418 and perplexity is 112.67272968378637
At time: 95.10875964164734 and batch: 350, loss is 4.720483875274658 and perplexity is 112.22254124526766
At time: 96.15965294837952 and batch: 400, loss is 4.681981363296509 and perplexity is 107.98381591934165
At time: 97.21987199783325 and batch: 450, loss is 4.685415391921997 and perplexity is 108.35527286615697
At time: 98.27500748634338 and batch: 500, loss is 4.683892107009887 and perplexity is 108.19034256366508
At time: 99.32310366630554 and batch: 550, loss is 4.656644077301025 and perplexity is 105.28216981410418
At time: 100.37172222137451 and batch: 600, loss is 4.640744323730469 and perplexity is 103.62144678816757
At time: 101.41797518730164 and batch: 650, loss is 4.7085992622375485 and perplexity is 110.89671384671618
At time: 102.46713304519653 and batch: 700, loss is 4.711349048614502 and perplexity is 111.20207576731373
At time: 103.5218722820282 and batch: 750, loss is 4.67565800666809 and perplexity is 107.30315005571117
At time: 104.57892656326294 and batch: 800, loss is 4.652618818283081 and perplexity is 104.85923359560424
At time: 105.6337525844574 and batch: 850, loss is 4.657553882598877 and perplexity is 105.37799967661843
At time: 106.68639779090881 and batch: 900, loss is 4.659344434738159 and perplexity is 105.56685350522947
At time: 107.73992681503296 and batch: 950, loss is 4.735501031875611 and perplexity is 113.92052223462181
At time: 108.79658198356628 and batch: 1000, loss is 4.703838548660278 and perplexity is 110.37002106692935
At time: 109.89605927467346 and batch: 1050, loss is 4.63793493270874 and perplexity is 103.33074216857959
At time: 110.95242738723755 and batch: 1100, loss is 4.71246747970581 and perplexity is 111.32651720288335
At time: 112.00965237617493 and batch: 1150, loss is 4.640547418594361 and perplexity is 103.60104520173851
At time: 113.07604837417603 and batch: 1200, loss is 4.713654680252075 and perplexity is 111.45876259028573
At time: 114.13049077987671 and batch: 1250, loss is 4.685611877441406 and perplexity is 108.37656519997596
At time: 115.18225479125977 and batch: 1300, loss is 4.685721406936645 and perplexity is 108.3884362805629
At time: 116.23604726791382 and batch: 1350, loss is 4.596295337677002 and perplexity is 99.11644169116954
At time: 117.29164624214172 and batch: 1400, loss is 4.6148398494720455 and perplexity is 100.97165657343294
At time: 118.35051274299622 and batch: 1450, loss is 4.544355125427246 and perplexity is 94.09972511886079
At time: 119.40547275543213 and batch: 1500, loss is 4.5375572776794435 and perplexity is 93.46221880479105
At time: 120.45730471611023 and batch: 1550, loss is 4.547278690338135 and perplexity is 94.37523431161013
At time: 121.50904250144958 and batch: 1600, loss is 4.635767450332642 and perplexity is 103.10701715362153
At time: 122.56436610221863 and batch: 1650, loss is 4.585322980880737 and perplexity is 98.03484541003935
At time: 123.62036275863647 and batch: 1700, loss is 4.612548732757569 and perplexity is 100.74058353210211
At time: 124.6761724948883 and batch: 1750, loss is 4.622902183532715 and perplexity is 101.78901427738207
At time: 125.73667120933533 and batch: 1800, loss is 4.580831804275513 and perplexity is 97.59554084145942
At time: 126.79483938217163 and batch: 1850, loss is 4.613606748580932 and perplexity is 100.84722506780219
At time: 127.84467148780823 and batch: 1900, loss is 4.680531873703003 and perplexity is 107.8274078851931
At time: 128.904296875 and batch: 1950, loss is 4.606962404251099 and perplexity is 100.17938252460364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.653139194222383 and perplexity of 104.91381401771865
finished 3 epochs...
Completing Train Step...
At time: 132.26558327674866 and batch: 50, loss is 4.547616710662842 and perplexity is 94.4071404511145
At time: 133.32786321640015 and batch: 100, loss is 4.5046170043945315 and perplexity is 90.43370170502058
At time: 134.38675117492676 and batch: 150, loss is 4.459410982131958 and perplexity is 86.43658140824076
At time: 135.45014643669128 and batch: 200, loss is 4.44954927444458 and perplexity is 85.58835844670747
At time: 136.54106616973877 and batch: 250, loss is 4.457146968841553 and perplexity is 86.2411091984909
At time: 137.60304522514343 and batch: 300, loss is 4.496539354324341 and perplexity is 89.70615230876169
At time: 138.66170525550842 and batch: 350, loss is 4.498032455444336 and perplexity is 89.84019270827774
At time: 139.72127032279968 and batch: 400, loss is 4.450593576431275 and perplexity is 85.67778522562558
At time: 140.77968335151672 and batch: 450, loss is 4.470959558486938 and perplexity is 87.44058712822637
At time: 141.84541058540344 and batch: 500, loss is 4.48364441871643 and perplexity is 88.55682343776078
At time: 142.91722965240479 and batch: 550, loss is 4.4509947299957275 and perplexity is 85.71216206929896
At time: 143.98016095161438 and batch: 600, loss is 4.43272123336792 and perplexity is 84.16012492538894
At time: 145.0388641357422 and batch: 650, loss is 4.498791971206665 and perplexity is 89.90845367008716
At time: 146.0978012084961 and batch: 700, loss is 4.507911338806152 and perplexity is 90.73211182199816
At time: 147.1585032939911 and batch: 750, loss is 4.474482011795044 and perplexity is 87.74913561841312
At time: 148.2217137813568 and batch: 800, loss is 4.457042560577393 and perplexity is 86.23210538402479
At time: 149.29060220718384 and batch: 850, loss is 4.454927854537964 and perplexity is 86.04994250832893
At time: 150.35257744789124 and batch: 900, loss is 4.450484714508057 and perplexity is 85.66845868481066
At time: 151.41164445877075 and batch: 950, loss is 4.53623327255249 and perplexity is 93.3385562309229
At time: 152.4704053401947 and batch: 1000, loss is 4.503257808685302 and perplexity is 90.31086810205683
At time: 153.5337405204773 and batch: 1050, loss is 4.4442192077636715 and perplexity is 85.13338039789156
At time: 154.59895086288452 and batch: 1100, loss is 4.511930313110351 and perplexity is 91.09749559015309
At time: 155.66157388687134 and batch: 1150, loss is 4.445811805725097 and perplexity is 85.26907166810243
At time: 156.72837138175964 and batch: 1200, loss is 4.518266677856445 and perplexity is 91.67655517863683
At time: 157.78705978393555 and batch: 1250, loss is 4.500815448760986 and perplexity is 90.09056559559158
At time: 158.84436631202698 and batch: 1300, loss is 4.497420349121094 and perplexity is 89.78521778520522
At time: 159.9068787097931 and batch: 1350, loss is 4.400042877197266 and perplexity is 81.45436112480425
At time: 160.96739172935486 and batch: 1400, loss is 4.41845853805542 and perplexity is 82.96829426876819
At time: 162.02862787246704 and batch: 1450, loss is 4.343794574737549 and perplexity is 76.9991647765875
At time: 163.08295822143555 and batch: 1500, loss is 4.343465147018432 and perplexity is 76.97380329497814
At time: 164.13812160491943 and batch: 1550, loss is 4.3598658466339115 and perplexity is 78.24663666925122
At time: 165.19282150268555 and batch: 1600, loss is 4.449703941345215 and perplexity is 85.60159715660754
At time: 166.248441696167 and batch: 1650, loss is 4.3985441875457765 and perplexity is 81.33237774716262
At time: 167.31003665924072 and batch: 1700, loss is 4.4302077293396 and perplexity is 83.94885373908302
At time: 168.37651562690735 and batch: 1750, loss is 4.439505348205566 and perplexity is 84.73301796647938
At time: 169.4481930732727 and batch: 1800, loss is 4.3908923149108885 and perplexity is 80.71240774229977
At time: 170.51156854629517 and batch: 1850, loss is 4.432944116592407 and perplexity is 84.17888489596928
At time: 171.56991171836853 and batch: 1900, loss is 4.504643516540527 and perplexity is 90.43609932830607
At time: 172.62828588485718 and batch: 1950, loss is 4.43193060874939 and perplexity is 84.09361215550575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.616753724563954 and perplexity of 101.16508875541123
finished 4 epochs...
Completing Train Step...
At time: 175.98098039627075 and batch: 50, loss is 4.378302125930786 and perplexity is 79.70259349092503
At time: 177.06760168075562 and batch: 100, loss is 4.342244873046875 and perplexity is 76.87993145265689
At time: 178.12645888328552 and batch: 150, loss is 4.296231451034546 and perplexity is 73.42257510231127
At time: 179.17978358268738 and batch: 200, loss is 4.289307069778443 and perplexity is 72.9159253419122
At time: 180.23661875724792 and batch: 250, loss is 4.29640305519104 and perplexity is 73.43517580251464
At time: 181.29355335235596 and batch: 300, loss is 4.3378635501861575 and perplexity is 76.54383246818095
At time: 182.35039067268372 and batch: 350, loss is 4.337044258117675 and perplexity is 76.48114639595588
At time: 183.40662121772766 and batch: 400, loss is 4.292713384628296 and perplexity is 73.1647234429617
At time: 184.46348118782043 and batch: 450, loss is 4.318656492233276 and perplexity is 75.08767961379453
At time: 185.5197675228119 and batch: 500, loss is 4.339500246047973 and perplexity is 76.66921401977339
At time: 186.57209038734436 and batch: 550, loss is 4.300066318511963 and perplexity is 73.70468152232068
At time: 187.62902450561523 and batch: 600, loss is 4.284406070709228 and perplexity is 72.559438743485
At time: 188.69062757492065 and batch: 650, loss is 4.344915523529052 and perplexity is 77.08552529110493
At time: 189.7508978843689 and batch: 700, loss is 4.3591729927062985 and perplexity is 78.19244195639024
At time: 190.83357763290405 and batch: 750, loss is 4.326367959976197 and perplexity is 75.66895419257015
At time: 191.89105343818665 and batch: 800, loss is 4.308744859695435 and perplexity is 74.3471142937844
At time: 192.94563555717468 and batch: 850, loss is 4.3053638362884525 and perplexity is 74.09616942440668
At time: 194.00127029418945 and batch: 900, loss is 4.299695911407471 and perplexity is 73.6773858402199
At time: 195.05750155448914 and batch: 950, loss is 4.392049903869629 and perplexity is 80.80589363301371
At time: 196.11369132995605 and batch: 1000, loss is 4.35131947517395 and perplexity is 77.58076130885338
At time: 197.1710410118103 and batch: 1050, loss is 4.303361301422119 and perplexity is 73.94793773077583
At time: 198.22289109230042 and batch: 1100, loss is 4.367440443038941 and perplexity is 78.84157372158487
At time: 199.27429151535034 and batch: 1150, loss is 4.305736346244812 and perplexity is 74.12377612681188
At time: 200.32528829574585 and batch: 1200, loss is 4.372496652603149 and perplexity is 79.24122274387051
At time: 201.3808147907257 and batch: 1250, loss is 4.362301387786865 and perplexity is 78.4374418355376
At time: 202.43710207939148 and batch: 1300, loss is 4.354646921157837 and perplexity is 77.83933706134503
At time: 203.49477362632751 and batch: 1350, loss is 4.249435739517212 and perplexity is 70.06586579119958
At time: 204.5483853816986 and batch: 1400, loss is 4.2756180000305175 and perplexity is 71.9245749671506
At time: 205.60045313835144 and batch: 1450, loss is 4.195553545951843 and perplexity is 66.39047158450215
At time: 206.65229105949402 and batch: 1500, loss is 4.202830386161804 and perplexity is 66.87534647663679
At time: 207.70808124542236 and batch: 1550, loss is 4.216550464630127 and perplexity is 67.79920468922472
At time: 208.76972842216492 and batch: 1600, loss is 4.310414962768554 and perplexity is 74.47138538172176
At time: 209.82740139961243 and batch: 1650, loss is 4.257494931221008 and perplexity is 70.6328215694839
At time: 210.8843903541565 and batch: 1700, loss is 4.290241289138794 and perplexity is 72.98407664021902
At time: 211.94078731536865 and batch: 1750, loss is 4.301205687522888 and perplexity is 73.78870621088068
At time: 212.99303555488586 and batch: 1800, loss is 4.252838048934937 and perplexity is 70.30465753759722
At time: 214.04631114006042 and batch: 1850, loss is 4.292015943527222 and perplexity is 73.11371314808966
At time: 215.10263586044312 and batch: 1900, loss is 4.373244047164917 and perplexity is 79.3004693403512
At time: 216.15543031692505 and batch: 1950, loss is 4.294831943511963 and perplexity is 73.31989152610669
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.60348269440407 and perplexity of 99.8313931429348
finished 5 epochs...
Completing Train Step...
At time: 219.52791142463684 and batch: 50, loss is 4.250482048988342 and perplexity is 70.1392147363362
At time: 220.58140087127686 and batch: 100, loss is 4.214897389411926 and perplexity is 67.68722008912417
At time: 221.63763666152954 and batch: 150, loss is 4.175352902412414 and perplexity is 65.06279642784733
At time: 222.70248532295227 and batch: 200, loss is 4.165046925544739 and perplexity is 64.39570417606093
At time: 223.7601821422577 and batch: 250, loss is 4.166214323043823 and perplexity is 64.47092345692549
At time: 224.81507468223572 and batch: 300, loss is 4.207342500686646 and perplexity is 67.17777748740232
At time: 225.867005109787 and batch: 350, loss is 4.207400350570679 and perplexity is 67.18166382645063
At time: 226.9201934337616 and batch: 400, loss is 4.164945087432861 and perplexity is 64.38914657304723
At time: 227.98401808738708 and batch: 450, loss is 4.190721750259399 and perplexity is 66.07046012745938
At time: 229.04134821891785 and batch: 500, loss is 4.224065699577332 and perplexity is 68.31065105434395
At time: 230.09545373916626 and batch: 550, loss is 4.181735587120056 and perplexity is 65.47939985347945
At time: 231.14849162101746 and batch: 600, loss is 4.16928946018219 and perplexity is 64.66948553432731
At time: 232.20012164115906 and batch: 650, loss is 4.2193823385238645 and perplexity is 67.99147560199631
At time: 233.25537014007568 and batch: 700, loss is 4.237223558425903 and perplexity is 69.21541226557744
At time: 234.3096308708191 and batch: 750, loss is 4.205719456672669 and perplexity is 67.06883343219314
At time: 235.36642718315125 and batch: 800, loss is 4.191475448608398 and perplexity is 66.12027609492303
At time: 236.42213129997253 and batch: 850, loss is 4.187873930931091 and perplexity is 65.88257105812265
At time: 237.47623133659363 and batch: 900, loss is 4.178650059700012 and perplexity is 65.27767274708745
At time: 238.52754139900208 and batch: 950, loss is 4.270142755508423 and perplexity is 71.5318464554845
At time: 239.58713507652283 and batch: 1000, loss is 4.235319871902465 and perplexity is 69.08377315758646
At time: 240.6407618522644 and batch: 1050, loss is 4.187023439407349 and perplexity is 65.8265623107339
At time: 241.69375777244568 and batch: 1100, loss is 4.24719358921051 and perplexity is 69.90894357606334
At time: 242.747816324234 and batch: 1150, loss is 4.190949831008911 and perplexity is 66.08553124617654
At time: 243.82948350906372 and batch: 1200, loss is 4.254139847755432 and perplexity is 70.39623965566813
At time: 244.8756082057953 and batch: 1250, loss is 4.24652364730835 and perplexity is 69.86212433026441
At time: 245.9218454360962 and batch: 1300, loss is 4.242315430641174 and perplexity is 69.56874710467217
At time: 246.96730422973633 and batch: 1350, loss is 4.1334350967407225 and perplexity is 62.391877381904386
At time: 248.01580548286438 and batch: 1400, loss is 4.1596042442321775 and perplexity is 64.04617094217781
At time: 249.07389163970947 and batch: 1450, loss is 4.080254893302918 and perplexity is 59.160547555566396
At time: 250.1289644241333 and batch: 1500, loss is 4.091856603622436 and perplexity is 59.8509080282526
At time: 251.18506598472595 and batch: 1550, loss is 4.101402807235718 and perplexity is 60.42499278804531
At time: 252.24092936515808 and batch: 1600, loss is 4.200939936637878 and perplexity is 66.74904143399725
At time: 253.29390954971313 and batch: 1650, loss is 4.13663113117218 and perplexity is 62.5916029651704
At time: 254.34480333328247 and batch: 1700, loss is 4.177435564994812 and perplexity is 65.19844148188317
At time: 255.39713978767395 and batch: 1750, loss is 4.190873494148255 and perplexity is 66.08048667673212
At time: 256.44929909706116 and batch: 1800, loss is 4.136126718521118 and perplexity is 62.56003893010306
At time: 257.5041124820709 and batch: 1850, loss is 4.178373403549195 and perplexity is 65.25961577531223
At time: 258.559725522995 and batch: 1900, loss is 4.258167753219604 and perplexity is 70.68036087661119
At time: 259.6233434677124 and batch: 1950, loss is 4.183487281799317 and perplexity is 65.59420028810442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.602750840297965 and perplexity of 99.75835785679186
finished 6 epochs...
Completing Train Step...
At time: 262.96204137802124 and batch: 50, loss is 4.143140406608581 and perplexity is 63.00035785469041
At time: 264.0426423549652 and batch: 100, loss is 4.106990427970886 and perplexity is 60.763569769645144
At time: 265.0981001853943 and batch: 150, loss is 4.070269317626953 and perplexity is 58.57273513791618
At time: 266.1557548046112 and batch: 200, loss is 4.060342831611633 and perplexity is 57.994189912811436
At time: 267.21156120300293 and batch: 250, loss is 4.058029561042786 and perplexity is 57.860188710396685
At time: 268.26527643203735 and batch: 300, loss is 4.100242948532104 and perplexity is 60.35494896256695
At time: 269.32207202911377 and batch: 350, loss is 4.097266550064087 and perplexity is 60.17557566056969
At time: 270.3774571418762 and batch: 400, loss is 4.057544717788696 and perplexity is 57.83214238780465
At time: 271.4659287929535 and batch: 450, loss is 4.085256032943725 and perplexity is 59.45715879400811
At time: 272.52230739593506 and batch: 500, loss is 4.1211301136016845 and perplexity is 61.6288505266345
At time: 273.57767820358276 and batch: 550, loss is 4.0776349067687985 and perplexity is 59.00575058915155
At time: 274.63503670692444 and batch: 600, loss is 4.065692863464355 and perplexity is 58.30529213747139
At time: 275.69205832481384 and batch: 650, loss is 4.11733386516571 and perplexity is 61.395335619953144
At time: 276.74229097366333 and batch: 700, loss is 4.136751675605774 and perplexity is 62.599148489273915
At time: 277.7939519882202 and batch: 750, loss is 4.103647007942199 and perplexity is 60.560750876770626
At time: 278.8455286026001 and batch: 800, loss is 4.090725312232971 and perplexity is 59.78323749611089
At time: 279.89795756340027 and batch: 850, loss is 4.0899249792099 and perplexity is 59.73541013837646
At time: 280.948899269104 and batch: 900, loss is 4.076189465522766 and perplexity is 58.92052285417749
At time: 282.0003390312195 and batch: 950, loss is 4.167211751937867 and perplexity is 64.5352606993855
At time: 283.06061840057373 and batch: 1000, loss is 4.1332210922241215 and perplexity is 62.37852666695304
At time: 284.11916851997375 and batch: 1050, loss is 4.086278047561645 and perplexity is 59.51795594193057
At time: 285.1758487224579 and batch: 1100, loss is 4.1447511529922485 and perplexity is 63.10191722451041
At time: 286.2317473888397 and batch: 1150, loss is 4.091670866012573 and perplexity is 59.839792495965455
At time: 287.2894706726074 and batch: 1200, loss is 4.147367343902588 and perplexity is 63.26722002433541
At time: 288.34342074394226 and batch: 1250, loss is 4.1474532842636105 and perplexity is 63.27265746570966
At time: 289.3955867290497 and batch: 1300, loss is 4.1474011564254765 and perplexity is 63.269359284827246
At time: 290.4465742111206 and batch: 1350, loss is 4.037185850143433 and perplexity is 56.6666497664751
At time: 291.4972393512726 and batch: 1400, loss is 4.059725694656372 and perplexity is 57.95841059653052
At time: 292.5482678413391 and batch: 1450, loss is 3.983449625968933 and perplexity is 53.701966769201626
At time: 293.60260462760925 and batch: 1500, loss is 3.99512836933136 and perplexity is 54.332814843277696
At time: 294.66747760772705 and batch: 1550, loss is 4.00627941608429 and perplexity is 54.942073222935605
At time: 295.7245008945465 and batch: 1600, loss is 4.105544748306275 and perplexity is 60.67578857950922
At time: 296.7780873775482 and batch: 1650, loss is 4.04011248588562 and perplexity is 56.83273532649351
At time: 297.8420844078064 and batch: 1700, loss is 4.078150949478149 and perplexity is 59.03620793452247
At time: 298.89407992362976 and batch: 1750, loss is 4.096052112579346 and perplexity is 60.102540543090186
At time: 299.9579849243164 and batch: 1800, loss is 4.038509249687195 and perplexity is 56.74169202941851
At time: 301.014883518219 and batch: 1850, loss is 4.078232350349427 and perplexity is 59.04101372888052
At time: 302.0689125061035 and batch: 1900, loss is 4.161578526496887 and perplexity is 64.172741063052
At time: 303.12290930747986 and batch: 1950, loss is 4.087256908416748 and perplexity is 59.57624426260139
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.6055652707122094 and perplexity of 100.0395162780367
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 306.5281562805176 and batch: 50, loss is 4.072733383178711 and perplexity is 58.71724015864867
At time: 307.5869245529175 and batch: 100, loss is 4.070239205360412 and perplexity is 58.5709714066588
At time: 308.64801359176636 and batch: 150, loss is 4.031610698699951 and perplexity is 56.351603643186536
At time: 309.71025228500366 and batch: 200, loss is 4.022712130546569 and perplexity is 55.852379541691306
At time: 310.7741334438324 and batch: 250, loss is 4.01942672252655 and perplexity is 55.66918278883241
At time: 311.84244775772095 and batch: 300, loss is 4.049794430732727 and perplexity is 57.385659104946576
At time: 312.90441966056824 and batch: 350, loss is 4.0512415361404415 and perplexity is 57.46876231761452
At time: 313.96982288360596 and batch: 400, loss is 3.9999035882949827 and perplexity is 54.59288638615142
At time: 315.0281639099121 and batch: 450, loss is 4.027627682685852 and perplexity is 56.12760070324364
At time: 316.0879693031311 and batch: 500, loss is 4.0561505651474 and perplexity is 57.75157173069025
At time: 317.14996433258057 and batch: 550, loss is 4.006193895339965 and perplexity is 54.93737473685073
At time: 318.2176778316498 and batch: 600, loss is 3.982240552902222 and perplexity is 53.637076404053
At time: 319.2756016254425 and batch: 650, loss is 4.0214694261550905 and perplexity is 55.78301465331276
At time: 320.33458137512207 and batch: 700, loss is 4.033460025787353 and perplexity is 56.4559126111943
At time: 321.39136600494385 and batch: 750, loss is 3.9918741512298586 and perplexity is 54.15629139239474
At time: 322.4572639465332 and batch: 800, loss is 3.9714977073669435 and perplexity is 53.06394561705256
At time: 323.51775765419006 and batch: 850, loss is 3.9658858299255373 and perplexity is 52.76699127272095
At time: 324.60155868530273 and batch: 900, loss is 3.9420525312423704 and perplexity is 51.52424797059095
At time: 325.6611647605896 and batch: 950, loss is 4.02923957824707 and perplexity is 56.218145488443206
At time: 326.7132170200348 and batch: 1000, loss is 3.985079593658447 and perplexity is 53.78957061622339
At time: 327.7668011188507 and batch: 1050, loss is 3.9360740327835084 and perplexity is 51.21712930251042
At time: 328.8234119415283 and batch: 1100, loss is 3.978411750793457 and perplexity is 53.43210330393224
At time: 329.87818121910095 and batch: 1150, loss is 3.9271240758895876 and perplexity is 50.760783387328026
At time: 330.945006608963 and batch: 1200, loss is 3.9698138093948363 and perplexity is 52.974666536163625
At time: 332.01171827316284 and batch: 1250, loss is 3.9602744913101198 and perplexity is 52.47172700561621
At time: 333.07352924346924 and batch: 1300, loss is 3.959004716873169 and perplexity is 52.40514203089761
At time: 334.13278341293335 and batch: 1350, loss is 3.8447065019607543 and perplexity is 46.7449627824627
At time: 335.1934735774994 and batch: 1400, loss is 3.8574564027786256 and perplexity is 47.34477205062076
At time: 336.25714135169983 and batch: 1450, loss is 3.7734907913208007 and perplexity is 43.53176020407191
At time: 337.3172981739044 and batch: 1500, loss is 3.782806329727173 and perplexity is 43.93917669385821
At time: 338.3772451877594 and batch: 1550, loss is 3.782803077697754 and perplexity is 43.9390338025953
At time: 339.4388563632965 and batch: 1600, loss is 3.873338508605957 and perplexity is 48.1027096211908
At time: 340.499862909317 and batch: 1650, loss is 3.7907142782211305 and perplexity is 44.288022951195764
At time: 341.5567991733551 and batch: 1700, loss is 3.8163757944107055 and perplexity is 45.439228435251074
At time: 342.61362886428833 and batch: 1750, loss is 3.822356495857239 and perplexity is 45.711801170091995
At time: 343.66876578330994 and batch: 1800, loss is 3.7625677299499514 and perplexity is 43.058847644291134
At time: 344.72438168525696 and batch: 1850, loss is 3.7902809762954712 and perplexity is 44.26883702251747
At time: 345.7845821380615 and batch: 1900, loss is 3.867207980155945 and perplexity is 47.80871667815622
At time: 346.84552669525146 and batch: 1950, loss is 3.792515516281128 and perplexity is 44.36786811222111
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.52371457122093 and perplexity of 92.17736220827719
finished 8 epochs...
Completing Train Step...
At time: 350.1977460384369 and batch: 50, loss is 3.97415545463562 and perplexity is 53.205163751511115
At time: 351.27365589141846 and batch: 100, loss is 3.9579191398620606 and perplexity is 52.34828308141313
At time: 352.33468651771545 and batch: 150, loss is 3.91616060256958 and perplexity is 50.20730844072261
At time: 353.3893575668335 and batch: 200, loss is 3.904837255477905 and perplexity is 49.64200029112473
At time: 354.4449272155762 and batch: 250, loss is 3.9002927780151366 and perplexity is 49.41691517409227
At time: 355.5018846988678 and batch: 300, loss is 3.9337060594558717 and perplexity is 51.095991987973264
At time: 356.5572690963745 and batch: 350, loss is 3.938017921447754 and perplexity is 51.31678652947242
At time: 357.61694598197937 and batch: 400, loss is 3.890680680274963 and perplexity is 48.9441905328247
At time: 358.6717121601105 and batch: 450, loss is 3.925676465034485 and perplexity is 50.68735468719766
At time: 359.7259864807129 and batch: 500, loss is 3.9574450874328613 and perplexity is 52.32347313172705
At time: 360.7810401916504 and batch: 550, loss is 3.906669063568115 and perplexity is 49.733018247135256
At time: 361.83540320396423 and batch: 600, loss is 3.8895578718185426 and perplexity is 48.88926642219995
At time: 362.8874292373657 and batch: 650, loss is 3.9318672370910646 and perplexity is 51.002121866842835
At time: 363.94097447395325 and batch: 700, loss is 3.9477002000808716 and perplexity is 51.8160631223029
At time: 364.99364376068115 and batch: 750, loss is 3.908440270423889 and perplexity is 49.82118376665001
At time: 366.0455811023712 and batch: 800, loss is 3.891433553695679 and perplexity is 48.981053187690634
At time: 367.09947180747986 and batch: 850, loss is 3.8879854536056517 and perplexity is 48.81245245692868
At time: 368.153137922287 and batch: 900, loss is 3.8644839668273927 and perplexity is 47.678662312036955
At time: 369.20820689201355 and batch: 950, loss is 3.9536781883239747 and perplexity is 52.1267466444494
At time: 370.2633059024811 and batch: 1000, loss is 3.913633918762207 and perplexity is 50.080610577597895
At time: 371.32003808021545 and batch: 1050, loss is 3.8683994579315186 and perplexity is 47.8657136501268
At time: 372.37011671066284 and batch: 1100, loss is 3.912481904029846 and perplexity is 50.022950195588585
At time: 373.419992685318 and batch: 1150, loss is 3.867785530090332 and perplexity is 47.83633657450374
At time: 374.4693033695221 and batch: 1200, loss is 3.9110459995269777 and perplexity is 49.951173560685156
At time: 375.51874136924744 and batch: 1250, loss is 3.9075409841537474 and perplexity is 49.77640039967806
At time: 376.5792586803436 and batch: 1300, loss is 3.9077669048309325 and perplexity is 49.787647188157386
At time: 377.6401777267456 and batch: 1350, loss is 3.7943377351760863 and perplexity is 44.44878978593407
At time: 378.69453716278076 and batch: 1400, loss is 3.8135650300979616 and perplexity is 45.31168879946281
At time: 379.745956659317 and batch: 1450, loss is 3.731591877937317 and perplexity is 41.745509053796304
At time: 380.7962760925293 and batch: 1500, loss is 3.7440423154830933 and perplexity is 42.26850793356322
At time: 381.8455250263214 and batch: 1550, loss is 3.747837963104248 and perplexity is 42.429249160696806
At time: 382.9042890071869 and batch: 1600, loss is 3.841754517555237 and perplexity is 46.60717585378344
At time: 383.9618468284607 and batch: 1650, loss is 3.7639065837860106 and perplexity is 43.116535756994175
At time: 385.0165259838104 and batch: 1700, loss is 3.7943461561203002 and perplexity is 44.44916408828922
At time: 386.06765151023865 and batch: 1750, loss is 3.803782830238342 and perplexity is 44.87060172197231
At time: 387.1179025173187 and batch: 1800, loss is 3.74816659450531 and perplexity is 42.44319503569521
At time: 388.16742157936096 and batch: 1850, loss is 3.7808923053741457 and perplexity is 43.855156473638615
At time: 389.22471857070923 and batch: 1900, loss is 3.861036901473999 and perplexity is 47.514593787007776
At time: 390.2793891429901 and batch: 1950, loss is 3.789874610900879 and perplexity is 44.250851353716875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.523870139898256 and perplexity of 92.19170323407361
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 393.6468014717102 and batch: 50, loss is 3.941907639503479 and perplexity is 51.516783073521445
At time: 394.7092709541321 and batch: 100, loss is 3.9483703327178956 and perplexity is 51.85079839464317
At time: 395.7678563594818 and batch: 150, loss is 3.9156272840499877 and perplexity is 50.18053909224144
At time: 396.8295271396637 and batch: 200, loss is 3.9068411016464233 and perplexity is 49.74157495604173
At time: 397.89234495162964 and batch: 250, loss is 3.9091622591018678 and perplexity is 49.85716708546433
At time: 398.94897174835205 and batch: 300, loss is 3.936686563491821 and perplexity is 51.24851097713834
At time: 400.00147581100464 and batch: 350, loss is 3.9450130748748777 and perplexity is 51.67701377817911
At time: 401.05251359939575 and batch: 400, loss is 3.897000641822815 and perplexity is 49.25449545973896
At time: 402.1047270298004 and batch: 450, loss is 3.9374400806427 and perplexity is 51.28714216191891
At time: 403.158748626709 and batch: 500, loss is 3.9686585998535158 and perplexity is 52.91350502991228
At time: 404.2110848426819 and batch: 550, loss is 3.9198073959350586 and perplexity is 50.39073838230202
At time: 405.30917739868164 and batch: 600, loss is 3.8921768951416014 and perplexity is 49.01747637034346
At time: 406.35470962524414 and batch: 650, loss is 3.932180609703064 and perplexity is 51.01810703951659
At time: 407.4007625579834 and batch: 700, loss is 3.9386749267578125 and perplexity is 51.35051300874222
At time: 408.4470012187958 and batch: 750, loss is 3.894962511062622 and perplexity is 49.154210589019655
At time: 409.49378299713135 and batch: 800, loss is 3.8701006412506103 and perplexity is 47.9472113053159
At time: 410.55283427238464 and batch: 850, loss is 3.8658742570877074 and perplexity is 47.74499559244639
At time: 411.61054396629333 and batch: 900, loss is 3.8321525716781615 and perplexity is 46.16179794293337
At time: 412.6640317440033 and batch: 950, loss is 3.9284584856033327 and perplexity is 50.828564283442645
At time: 413.7169659137726 and batch: 1000, loss is 3.882937860488892 and perplexity is 48.56668783959336
At time: 414.7698595523834 and batch: 1050, loss is 3.8373826694488526 and perplexity is 46.403861114692106
At time: 415.8251850605011 and batch: 1100, loss is 3.873456721305847 and perplexity is 48.10839630847986
At time: 416.88019824028015 and batch: 1150, loss is 3.8323373556137086 and perplexity is 46.17032868977741
At time: 417.937020778656 and batch: 1200, loss is 3.8707469511032104 and perplexity is 47.978210076713864
At time: 418.99336767196655 and batch: 1250, loss is 3.862803840637207 and perplexity is 47.59862339933819
At time: 420.0476384162903 and batch: 1300, loss is 3.857015070915222 and perplexity is 47.32388190423194
At time: 421.10161232948303 and batch: 1350, loss is 3.739192833900452 and perplexity is 42.06402380456807
At time: 422.1545555591583 and batch: 1400, loss is 3.75952374458313 and perplexity is 42.92797642823573
At time: 423.2064116001129 and batch: 1450, loss is 3.674097766876221 and perplexity is 39.41308102355642
At time: 424.26477575302124 and batch: 1500, loss is 3.686928701400757 and perplexity is 39.92204595073015
At time: 425.31956911087036 and batch: 1550, loss is 3.693504042625427 and perplexity is 40.185411936968926
At time: 426.37747979164124 and batch: 1600, loss is 3.7812715435028075 and perplexity is 43.871791175169015
At time: 427.4352059364319 and batch: 1650, loss is 3.700591187477112 and perplexity is 40.47122336950077
At time: 428.4954402446747 and batch: 1700, loss is 3.7224743509292604 and perplexity is 41.366623123590564
At time: 429.554892539978 and batch: 1750, loss is 3.725732560157776 and perplexity is 41.501624048003286
At time: 430.60880517959595 and batch: 1800, loss is 3.665610613822937 and perplexity is 39.0799916622186
At time: 431.66429114341736 and batch: 1850, loss is 3.6928253078460695 and perplexity is 40.15814595449653
At time: 432.7156150341034 and batch: 1900, loss is 3.7747157859802245 and perplexity is 43.58511905331732
At time: 433.7667889595032 and batch: 1950, loss is 3.7040202808380127 and perplexity is 40.61024118918376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493391453942587 and perplexity of 89.4242102732041
finished 10 epochs...
Completing Train Step...
At time: 437.09908509254456 and batch: 50, loss is 3.925112833976746 and perplexity is 50.65879376952755
At time: 438.19580268859863 and batch: 100, loss is 3.914393539428711 and perplexity is 50.11866729688904
At time: 439.25594568252563 and batch: 150, loss is 3.8747297143936157 and perplexity is 48.169676961092286
At time: 440.3179740905762 and batch: 200, loss is 3.8613029956817626 and perplexity is 47.527238827510146
At time: 441.39142084121704 and batch: 250, loss is 3.863290157318115 and perplexity is 47.621777033428465
At time: 442.4599885940552 and batch: 300, loss is 3.8887358713150024 and perplexity is 48.84909593292628
At time: 443.53083539009094 and batch: 350, loss is 3.8986817932128908 and perplexity is 49.33736936552086
At time: 444.60134410858154 and batch: 400, loss is 3.850413680076599 and perplexity is 47.01250734712086
At time: 445.6639881134033 and batch: 450, loss is 3.8925533723831176 and perplexity is 49.03593380881821
At time: 446.7220091819763 and batch: 500, loss is 3.9238106346130373 and perplexity is 50.592868853522326
At time: 447.7835395336151 and batch: 550, loss is 3.8768136215209963 and perplexity is 48.27016275940607
At time: 448.8447675704956 and batch: 600, loss is 3.8518559026718138 and perplexity is 47.080358764136996
At time: 449.90937852859497 and batch: 650, loss is 3.8943384408950807 and perplexity is 49.12354448247841
At time: 450.96830320358276 and batch: 700, loss is 3.904318609237671 and perplexity is 49.61626032986009
At time: 452.02782940864563 and batch: 750, loss is 3.8634631729125974 and perplexity is 47.63001705629788
At time: 453.0931017398834 and batch: 800, loss is 3.8400053071975706 and perplexity is 46.52572136032936
At time: 454.1552231311798 and batch: 850, loss is 3.836288819313049 and perplexity is 46.353129996088825
At time: 455.2257480621338 and batch: 900, loss is 3.8044740962982178 and perplexity is 44.90162996918043
At time: 456.2969343662262 and batch: 950, loss is 3.901545181274414 and perplexity is 49.478843851463765
At time: 457.3601379394531 and batch: 1000, loss is 3.8576114892959597 and perplexity is 47.35211515582566
At time: 458.4673626422882 and batch: 1050, loss is 3.813325409889221 and perplexity is 45.30083250388015
At time: 459.5268635749817 and batch: 1100, loss is 3.8512722206115724 and perplexity is 47.0528868215566
At time: 460.5910065174103 and batch: 1150, loss is 3.8119854736328125 and perplexity is 45.24017292502304
At time: 461.65969681739807 and batch: 1200, loss is 3.851935420036316 and perplexity is 47.0841026190345
At time: 462.72971773147583 and batch: 1250, loss is 3.846174840927124 and perplexity is 46.81365064899213
At time: 463.7939898967743 and batch: 1300, loss is 3.8424339056015016 and perplexity is 46.63885097055816
At time: 464.8575801849365 and batch: 1350, loss is 3.7257149267196654 and perplexity is 41.50089223813632
At time: 465.9173777103424 and batch: 1400, loss is 3.7485644912719724 and perplexity is 42.46008640605469
At time: 466.97601079940796 and batch: 1450, loss is 3.665366883277893 and perplexity is 39.07046783522138
At time: 468.03474140167236 and batch: 1500, loss is 3.680053572654724 and perplexity is 39.648518092047475
At time: 469.0932056903839 and batch: 1550, loss is 3.688757548332214 and perplexity is 39.99512406593943
At time: 470.1565742492676 and batch: 1600, loss is 3.7780790615081785 and perplexity is 43.731954603406095
At time: 471.2140951156616 and batch: 1650, loss is 3.6995981311798096 and perplexity is 40.43105311523733
At time: 472.27738857269287 and batch: 1700, loss is 3.723957648277283 and perplexity is 41.42802765529758
At time: 473.34582901000977 and batch: 1750, loss is 3.729477548599243 and perplexity is 41.65733854286641
At time: 474.41049361228943 and batch: 1800, loss is 3.6710832643508913 and perplexity is 39.294449089248914
At time: 475.47454810142517 and batch: 1850, loss is 3.7001848459243774 and perplexity is 40.45478157047504
At time: 476.53261733055115 and batch: 1900, loss is 3.782693557739258 and perplexity is 43.9342218649433
At time: 477.59093952178955 and batch: 1950, loss is 3.712100987434387 and perplexity is 40.93973009170864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.493022971929506 and perplexity of 89.39126513040341
finished 11 epochs...
Completing Train Step...
At time: 480.9227714538574 and batch: 50, loss is 3.9088528776168823 and perplexity is 49.84174458691503
At time: 481.9787817001343 and batch: 100, loss is 3.895670976638794 and perplexity is 49.1890469938856
At time: 483.0320613384247 and batch: 150, loss is 3.85470929145813 and perplexity is 47.21488917439541
At time: 484.08949851989746 and batch: 200, loss is 3.840644679069519 and perplexity is 46.55547810968982
At time: 485.14444732666016 and batch: 250, loss is 3.841947660446167 and perplexity is 46.61617856784305
At time: 486.2291703224182 and batch: 300, loss is 3.8672309017181394 and perplexity is 47.8098125411884
At time: 487.2863643169403 and batch: 350, loss is 3.877676191329956 and perplexity is 48.311817106784474
At time: 488.3462369441986 and batch: 400, loss is 3.829103422164917 and perplexity is 46.02125809160173
At time: 489.41119623184204 and batch: 450, loss is 3.871775665283203 and perplexity is 48.02759133699696
At time: 490.4685757160187 and batch: 500, loss is 3.9032089042663576 and perplexity is 49.561231457667674
At time: 491.5198664665222 and batch: 550, loss is 3.8565680980682373 and perplexity is 47.302734140596975
At time: 492.57204961776733 and batch: 600, loss is 3.8324499464035036 and perplexity is 46.17552733620405
At time: 493.62329030036926 and batch: 650, loss is 3.8756346035003664 and perplexity is 48.21328490425084
At time: 494.67540168762207 and batch: 700, loss is 3.886466999053955 and perplexity is 48.738389211382795
At time: 495.728390455246 and batch: 750, loss is 3.8466208457946776 and perplexity is 46.83453442183552
At time: 496.7802138328552 and batch: 800, loss is 3.823756446838379 and perplexity is 45.775840266328565
At time: 497.8323965072632 and batch: 850, loss is 3.820225782394409 and perplexity is 45.61450611068462
At time: 498.8849160671234 and batch: 900, loss is 3.7891714096069338 and perplexity is 44.219745036069995
At time: 499.93748664855957 and batch: 950, loss is 3.8865418815612793 and perplexity is 48.742039000820874
At time: 500.99218249320984 and batch: 1000, loss is 3.843602194786072 and perplexity is 46.693370476801455
At time: 502.0477259159088 and batch: 1050, loss is 3.7999071359634398 and perplexity is 44.697033553609245
At time: 503.09438824653625 and batch: 1100, loss is 3.838496437072754 and perplexity is 46.45557302500578
At time: 504.14029574394226 and batch: 1150, loss is 3.8001493072509764 and perplexity is 44.70785920255175
At time: 505.1953434944153 and batch: 1200, loss is 3.8408133459091185 and perplexity is 46.56333113730268
At time: 506.2418863773346 and batch: 1250, loss is 3.836054735183716 and perplexity is 46.34228073388142
At time: 507.2996528148651 and batch: 1300, loss is 3.8329693555831907 and perplexity is 46.19951755881094
At time: 508.36005878448486 and batch: 1350, loss is 3.7166577053070067 and perplexity is 41.12670656751579
At time: 509.41717982292175 and batch: 1400, loss is 3.7408762311935426 and perplexity is 42.13489390290691
At time: 510.471066236496 and batch: 1450, loss is 3.6585218334197998 and perplexity is 38.80394176768657
At time: 511.5229158401489 and batch: 1500, loss is 3.673911828994751 and perplexity is 39.40575332003865
At time: 512.575314283371 and batch: 1550, loss is 3.6835042333602903 and perplexity is 39.78556799583206
At time: 513.630039691925 and batch: 1600, loss is 3.77338050365448 and perplexity is 43.526959452564874
At time: 514.6861021518707 and batch: 1650, loss is 3.6959407186508177 and perplexity is 40.283450161994836
At time: 515.7436459064484 and batch: 1700, loss is 3.7214529609680174 and perplexity is 41.32439324026237
At time: 516.7994966506958 and batch: 1750, loss is 3.7279668188095094 and perplexity is 41.59445307400457
At time: 517.8526329994202 and batch: 1800, loss is 3.6705153799057006 and perplexity is 39.272140717716916
At time: 518.9055259227753 and batch: 1850, loss is 3.700549993515015 and perplexity is 40.46955623379746
At time: 519.9578862190247 and batch: 1900, loss is 3.783166241645813 and perplexity is 43.95499377345256
At time: 521.0086886882782 and batch: 1950, loss is 3.712854890823364 and perplexity is 40.97060633035663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.49392941497093 and perplexity of 89.47232995541778
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 524.3519470691681 and batch: 50, loss is 3.9015089082717895 and perplexity is 49.4770491377809
At time: 525.4314377307892 and batch: 100, loss is 3.8975063705444337 and perplexity is 49.27941117252653
At time: 526.4841492176056 and batch: 150, loss is 3.8612871742248536 and perplexity is 47.52648688329747
At time: 527.535569190979 and batch: 200, loss is 3.84891658782959 and perplexity is 46.942177944796185
At time: 528.5890324115753 and batch: 250, loss is 3.855020775794983 and perplexity is 47.22959816353043
At time: 529.6458828449249 and batch: 300, loss is 3.8772940254211425 and perplexity is 48.293357504833374
At time: 530.70485496521 and batch: 350, loss is 3.8857978916168214 and perplexity is 48.70578890045907
At time: 531.7647647857666 and batch: 400, loss is 3.84041916847229 and perplexity is 46.54498053971816
At time: 532.8164439201355 and batch: 450, loss is 3.8838035821914674 and perplexity is 48.608751280267924
At time: 533.8690979480743 and batch: 500, loss is 3.9165737056732177 and perplexity is 50.22805352029813
At time: 534.9220831394196 and batch: 550, loss is 3.8739872074127195 and perplexity is 48.133923914767
At time: 535.9739909172058 and batch: 600, loss is 3.848406581878662 and perplexity is 46.91824325862981
At time: 537.0292191505432 and batch: 650, loss is 3.887127923965454 and perplexity is 48.77061227429845
At time: 538.0871107578278 and batch: 700, loss is 3.8937833166122435 and perplexity is 49.09628237770543
At time: 539.1697041988373 and batch: 750, loss is 3.8526453018188476 and perplexity is 47.11753863213477
At time: 540.222695350647 and batch: 800, loss is 3.828108243942261 and perplexity is 45.975481519471586
At time: 541.2744596004486 and batch: 850, loss is 3.823952765464783 and perplexity is 45.78482779859326
At time: 542.3253877162933 and batch: 900, loss is 3.788934278488159 and perplexity is 44.20926040162333
At time: 543.3764271736145 and batch: 950, loss is 3.8905683183670043 and perplexity is 48.93869137914642
At time: 544.4308986663818 and batch: 1000, loss is 3.845326099395752 and perplexity is 46.77393481607377
At time: 545.4867355823517 and batch: 1050, loss is 3.8014171648025514 and perplexity is 44.76457834775692
At time: 546.5446555614471 and batch: 1100, loss is 3.8349733543395996 and perplexity is 46.292194165431845
At time: 547.6014358997345 and batch: 1150, loss is 3.797544584274292 and perplexity is 44.59155914491857
At time: 548.6619691848755 and batch: 1200, loss is 3.83807373046875 and perplexity is 46.43594009727176
At time: 549.7196972370148 and batch: 1250, loss is 3.829355726242065 and perplexity is 46.03287090757253
At time: 550.7811317443848 and batch: 1300, loss is 3.8203851175308228 and perplexity is 45.621774683292344
At time: 551.8412189483643 and batch: 1350, loss is 3.698816976547241 and perplexity is 40.399482543151436
At time: 552.8980202674866 and batch: 1400, loss is 3.720907211303711 and perplexity is 41.3018466194888
At time: 553.9543423652649 and batch: 1450, loss is 3.6351036119461058 and perplexity is 37.9057801853353
At time: 555.0082149505615 and batch: 1500, loss is 3.6482710647583008 and perplexity is 38.408203314425364
At time: 556.0634491443634 and batch: 1550, loss is 3.65952938079834 and perplexity is 38.843058280052276
At time: 557.1161699295044 and batch: 1600, loss is 3.748102388381958 and perplexity is 42.44047001016188
At time: 558.1670906543732 and batch: 1650, loss is 3.670211043357849 and perplexity is 39.26019058850691
At time: 559.2278907299042 and batch: 1700, loss is 3.694132056236267 and perplexity is 40.21065684886697
At time: 560.2893481254578 and batch: 1750, loss is 3.699297490119934 and perplexity is 40.41889970757511
At time: 561.3492238521576 and batch: 1800, loss is 3.6421791553497314 and perplexity is 38.174935264609104
At time: 562.4069871902466 and batch: 1850, loss is 3.6720575141906737 and perplexity is 39.332750354449686
At time: 563.472776889801 and batch: 1900, loss is 3.754021668434143 and perplexity is 42.692432018860345
At time: 564.5321447849274 and batch: 1950, loss is 3.687504391670227 and perplexity is 39.945035300858976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.486376101471657 and perplexity of 88.7990632957901
finished 13 epochs...
Completing Train Step...
At time: 567.8842487335205 and batch: 50, loss is 3.8979589128494263 and perplexity is 49.301717237685615
At time: 568.9486446380615 and batch: 100, loss is 3.8871448373794557 and perplexity is 48.77143715883076
At time: 570.0058224201202 and batch: 150, loss is 3.8474891710281374 and perplexity is 46.87521969133806
At time: 571.0588111877441 and batch: 200, loss is 3.831980152130127 and perplexity is 46.15383943271667
At time: 572.1166393756866 and batch: 250, loss is 3.836609902381897 and perplexity is 46.368015590947024
At time: 573.1708977222443 and batch: 300, loss is 3.858394808769226 and perplexity is 47.3892215208994
At time: 574.2302858829498 and batch: 350, loss is 3.8679357051849363 and perplexity is 47.84352094031724
At time: 575.2863943576813 and batch: 400, loss is 3.8210982418060304 and perplexity is 45.654320281445855
At time: 576.344379901886 and batch: 450, loss is 3.8657691526412963 and perplexity is 47.73997764482466
At time: 577.3979337215424 and batch: 500, loss is 3.8987865924835203 and perplexity is 49.34254015678799
At time: 578.4504284858704 and batch: 550, loss is 3.856135730743408 and perplexity is 47.282286404764456
At time: 579.5012950897217 and batch: 600, loss is 3.8317271900177 and perplexity is 46.142165736560834
At time: 580.5523383617401 and batch: 650, loss is 3.871309118270874 and perplexity is 48.00518943392615
At time: 581.606053352356 and batch: 700, loss is 3.880329990386963 and perplexity is 48.44019723364987
At time: 582.6618688106537 and batch: 750, loss is 3.8402645635604857 and perplexity is 46.537785013353066
At time: 583.7077505588531 and batch: 800, loss is 3.816273641586304 and perplexity is 45.43458692680342
At time: 584.7544243335724 and batch: 850, loss is 3.8122065782547 and perplexity is 45.250176842267166
At time: 585.8061587810516 and batch: 900, loss is 3.777829999923706 and perplexity is 43.72106400977105
At time: 586.8572034835815 and batch: 950, loss is 3.879497699737549 and perplexity is 48.39989768323235
At time: 587.9118447303772 and batch: 1000, loss is 3.8343434000015257 and perplexity is 46.26304138032418
At time: 588.9679429531097 and batch: 1050, loss is 3.7910269355773925 and perplexity is 44.301872092270855
At time: 590.024290561676 and batch: 1100, loss is 3.8253279399871825 and perplexity is 45.84783323910346
At time: 591.0857081413269 and batch: 1150, loss is 3.789232587814331 and perplexity is 44.22245040355679
At time: 592.182902097702 and batch: 1200, loss is 3.8300959062576294 and perplexity is 46.06695613172205
At time: 593.2341599464417 and batch: 1250, loss is 3.823345456123352 and perplexity is 45.75703068655264
At time: 594.2924001216888 and batch: 1300, loss is 3.8156205701828 and perplexity is 45.40492458421962
At time: 595.3491353988647 and batch: 1350, loss is 3.69531213760376 and perplexity is 40.25813670532593
At time: 596.4059598445892 and batch: 1400, loss is 3.718829188346863 and perplexity is 41.21610954670837
At time: 597.4614126682281 and batch: 1450, loss is 3.6347510480880736 and perplexity is 37.892418332822984
At time: 598.5143718719482 and batch: 1500, loss is 3.649389901161194 and perplexity is 38.451199859027675
At time: 599.5653960704803 and batch: 1550, loss is 3.6618131828308105 and perplexity is 38.93186951053253
At time: 600.6175920963287 and batch: 1600, loss is 3.7514954519271853 and perplexity is 42.584717804369404
At time: 601.6723108291626 and batch: 1650, loss is 3.674428882598877 and perplexity is 39.42613347517836
At time: 602.7276563644409 and batch: 1700, loss is 3.699131531715393 and perplexity is 40.41219240804809
At time: 603.7895531654358 and batch: 1750, loss is 3.7050391244888305 and perplexity is 40.65163776031342
At time: 604.8450968265533 and batch: 1800, loss is 3.648188924789429 and perplexity is 38.40504859536673
At time: 605.8968811035156 and batch: 1850, loss is 3.6785281324386596 and perplexity is 39.58808275500856
At time: 606.9554259777069 and batch: 1900, loss is 3.7602585124969483 and perplexity is 42.95953011882044
At time: 608.0075557231903 and batch: 1950, loss is 3.6929323291778564 and perplexity is 40.16244396274386
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485762343295785 and perplexity of 88.74457886652488
finished 14 epochs...
Completing Train Step...
At time: 611.3840384483337 and batch: 50, loss is 3.89411084651947 and perplexity is 49.11236551222777
At time: 612.4719772338867 and batch: 100, loss is 3.8815361976623537 and perplexity is 48.49866140484032
At time: 613.531733751297 and batch: 150, loss is 3.8407330989837645 and perplexity is 46.559594723064556
At time: 614.5943281650543 and batch: 200, loss is 3.8246260118484496 and perplexity is 45.81566264689584
At time: 615.6560809612274 and batch: 250, loss is 3.8285865879058836 and perplexity is 45.99747887426257
At time: 616.7237839698792 and batch: 300, loss is 3.8500791788101196 and perplexity is 46.99678423372015
At time: 617.7905540466309 and batch: 350, loss is 3.8598368120193483 and perplexity is 47.45760622598702
At time: 618.8484749794006 and batch: 400, loss is 3.812479739189148 and perplexity is 45.26253911122493
At time: 619.9375507831573 and batch: 450, loss is 3.8574163055419923 and perplexity is 47.34287369415218
At time: 620.9979424476624 and batch: 500, loss is 3.8903661298751833 and perplexity is 48.928797539188764
At time: 622.0605566501617 and batch: 550, loss is 3.8478571605682372 and perplexity is 46.89247245609815
At time: 623.1219923496246 and batch: 600, loss is 3.8239836263656617 and perplexity is 45.78624078142855
At time: 624.1840269565582 and batch: 650, loss is 3.8637146663665773 and perplexity is 47.64199720020123
At time: 625.247415304184 and batch: 700, loss is 3.8735431385040284 and perplexity is 48.11255388093813
At time: 626.3045415878296 and batch: 750, loss is 3.8338914918899536 and perplexity is 46.24213945988783
At time: 627.3607556819916 and batch: 800, loss is 3.810158667564392 and perplexity is 45.157603344855026
At time: 628.4190697669983 and batch: 850, loss is 3.806157603263855 and perplexity is 44.97728584172761
At time: 629.4879450798035 and batch: 900, loss is 3.772269062995911 and perplexity is 43.47860869456187
At time: 630.5537226200104 and batch: 950, loss is 3.8739510774612427 and perplexity is 48.13218486984757
At time: 631.6132636070251 and batch: 1000, loss is 3.8291371726989745 and perplexity is 46.02281135985198
At time: 632.6704251766205 and batch: 1050, loss is 3.7860855150222776 and perplexity is 44.08349789460687
At time: 633.7285146713257 and batch: 1100, loss is 3.8208945035934447 and perplexity is 45.64501969930906
At time: 634.7940766811371 and batch: 1150, loss is 3.7853858995437624 and perplexity is 44.0526671832117
At time: 635.857500076294 and batch: 1200, loss is 3.8264328145980837 and perplexity is 45.89851734064663
At time: 636.9184279441833 and batch: 1250, loss is 3.8203574132919313 and perplexity is 45.62051078425563
At time: 637.9752912521362 and batch: 1300, loss is 3.813203911781311 and perplexity is 45.29532887279133
At time: 639.0330286026001 and batch: 1350, loss is 3.6934490823745727 and perplexity is 40.18320339733968
At time: 640.0907030105591 and batch: 1400, loss is 3.7175361728668213 and perplexity is 41.16285091857291
At time: 641.153570652008 and batch: 1450, loss is 3.6341908264160154 and perplexity is 37.87119612399194
At time: 642.2179815769196 and batch: 1500, loss is 3.6493503570556642 and perplexity is 38.44967937078608
At time: 643.2772879600525 and batch: 1550, loss is 3.662310528755188 and perplexity is 38.951236932917055
At time: 644.337545633316 and batch: 1600, loss is 3.7523873615264893 and perplexity is 42.62271646612937
At time: 645.3979296684265 and batch: 1650, loss is 3.675736999511719 and perplexity is 39.47774121430426
At time: 646.455105304718 and batch: 1700, loss is 3.7007786226272583 and perplexity is 40.478809810290265
At time: 647.5162534713745 and batch: 1750, loss is 3.707032504081726 and perplexity is 40.73275272504068
At time: 648.586834192276 and batch: 1800, loss is 3.6503686809539797 and perplexity is 38.488853540783424
At time: 649.6581947803497 and batch: 1850, loss is 3.6809826469421387 and perplexity is 39.68537162792625
At time: 650.7198185920715 and batch: 1900, loss is 3.762564430236816 and perplexity is 43.058705562680395
At time: 651.7833442687988 and batch: 1950, loss is 3.694903450012207 and perplexity is 40.24168706600612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485861418968023 and perplexity of 88.75337173090583
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 655.1240937709808 and batch: 50, loss is 3.8922647857666015 and perplexity is 49.02178473630729
At time: 656.1755268573761 and batch: 100, loss is 3.88212628364563 and perplexity is 48.5272882304566
At time: 657.233882188797 and batch: 150, loss is 3.8426847314834593 and perplexity is 46.65055066871856
At time: 658.2800679206848 and batch: 200, loss is 3.8261887645721435 and perplexity is 45.88731717305521
At time: 659.322826385498 and batch: 250, loss is 3.831321511268616 and perplexity is 46.123450636900564
At time: 660.3667743206024 and batch: 300, loss is 3.851500668525696 and perplexity is 47.063637183306575
At time: 661.4109740257263 and batch: 350, loss is 3.860516457557678 and perplexity is 47.48987153956453
At time: 662.4628291130066 and batch: 400, loss is 3.813558578491211 and perplexity is 45.311396467208475
At time: 663.517049074173 and batch: 450, loss is 3.858565301895142 and perplexity is 47.39730174620308
At time: 664.5706675052643 and batch: 500, loss is 3.8912371301651003 and perplexity is 48.971433101128675
At time: 665.6251766681671 and batch: 550, loss is 3.8496266746520997 and perplexity is 46.97552280424624
At time: 666.6783542633057 and batch: 600, loss is 3.825250496864319 and perplexity is 45.84428277720211
At time: 667.7278218269348 and batch: 650, loss is 3.8643231201171875 and perplexity is 47.67099397278718
At time: 668.7861602306366 and batch: 700, loss is 3.8737900495529174 and perplexity is 48.12443486879483
At time: 669.8372068405151 and batch: 750, loss is 3.833171133995056 and perplexity is 46.20884056465192
At time: 670.886244058609 and batch: 800, loss is 3.810466418266296 and perplexity is 45.171502767649564
At time: 671.9354186058044 and batch: 850, loss is 3.8062238121032714 and perplexity is 44.98026383420691
At time: 673.0115566253662 and batch: 900, loss is 3.770602293014526 and perplexity is 43.40620021566023
At time: 674.0742971897125 and batch: 950, loss is 3.8729838275909425 and perplexity is 48.085651528587036
At time: 675.1278548240662 and batch: 1000, loss is 3.828003029823303 and perplexity is 45.97064450415547
At time: 676.1799550056458 and batch: 1050, loss is 3.7852822971343993 and perplexity is 44.04810345716324
At time: 677.2340536117554 and batch: 1100, loss is 3.818785061836243 and perplexity is 45.54883567171532
At time: 678.2854428291321 and batch: 1150, loss is 3.784030442237854 and perplexity is 43.9929961235563
At time: 679.3382906913757 and batch: 1200, loss is 3.825571355819702 and perplexity is 45.85899468598191
At time: 680.3944461345673 and batch: 1250, loss is 3.8191709232330324 and perplexity is 45.56641460036661
At time: 681.4480402469635 and batch: 1300, loss is 3.809987173080444 and perplexity is 45.14985972898575
At time: 682.4988236427307 and batch: 1350, loss is 3.68786874294281 and perplexity is 39.95959197701492
At time: 683.5472066402435 and batch: 1400, loss is 3.7104445600509646 and perplexity is 40.87197253494353
At time: 684.596070766449 and batch: 1450, loss is 3.625682649612427 and perplexity is 37.550348142769614
At time: 685.6447730064392 and batch: 1500, loss is 3.638271656036377 and perplexity is 38.02605779001872
At time: 686.6981663703918 and batch: 1550, loss is 3.6514909982681276 and perplexity is 38.532074496790834
At time: 687.751104593277 and batch: 1600, loss is 3.740884470939636 and perplexity is 42.135241085164694
At time: 688.807382106781 and batch: 1650, loss is 3.663987789154053 and perplexity is 39.01662311961353
At time: 689.8583302497864 and batch: 1700, loss is 3.688431453704834 and perplexity is 39.98208399712387
At time: 690.913179397583 and batch: 1750, loss is 3.6948511600494385 and perplexity is 40.23958288470195
At time: 691.9602596759796 and batch: 1800, loss is 3.638279776573181 and perplexity is 38.02636658327431
At time: 693.0054092407227 and batch: 1850, loss is 3.6695566844940184 and perplexity is 39.23450873828919
At time: 694.0511105060577 and batch: 1900, loss is 3.7505534744262694 and perplexity is 42.54462284555415
At time: 695.0979156494141 and batch: 1950, loss is 3.6856888484954835 and perplexity is 39.87257915818374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485589457667151 and perplexity of 88.7292375304062
finished 16 epochs...
Completing Train Step...
At time: 698.45494556427 and batch: 50, loss is 3.8914627122879026 and perplexity is 48.98248142706986
At time: 699.5612645149231 and batch: 100, loss is 3.879920926094055 and perplexity is 48.4203861309038
At time: 700.6103971004486 and batch: 150, loss is 3.839810333251953 and perplexity is 46.516650941139474
At time: 701.6705408096313 and batch: 200, loss is 3.82298725605011 and perplexity is 45.74064344993926
At time: 702.7493827342987 and batch: 250, loss is 3.827499089241028 and perplexity is 45.94748386707909
At time: 703.7985489368439 and batch: 300, loss is 3.84786171913147 and perplexity is 46.8926862188862
At time: 704.8461682796478 and batch: 350, loss is 3.8568882846832278 and perplexity is 47.31788226790563
At time: 705.8936729431152 and batch: 400, loss is 3.809649052619934 and perplexity is 45.13459621822028
At time: 706.941187620163 and batch: 450, loss is 3.854814076423645 and perplexity is 47.21983684414552
At time: 707.9899733066559 and batch: 500, loss is 3.8875245666503906 and perplexity is 48.78996061783273
At time: 709.0369718074799 and batch: 550, loss is 3.8457728099822996 and perplexity is 46.794833895503075
At time: 710.084038734436 and batch: 600, loss is 3.8216583347320556 and perplexity is 45.67989810558851
At time: 711.1315188407898 and batch: 650, loss is 3.86099666595459 and perplexity is 47.51268205110734
At time: 712.1774787902832 and batch: 700, loss is 3.8708683538436888 and perplexity is 47.98403511648116
At time: 713.2258794307709 and batch: 750, loss is 3.830684309005737 and perplexity is 46.094070031471205
At time: 714.2737021446228 and batch: 800, loss is 3.807939872741699 and perplexity is 45.05751896276268
At time: 715.3207128047943 and batch: 850, loss is 3.8035170316696165 and perplexity is 44.85867676514519
At time: 716.3680510520935 and batch: 900, loss is 3.7682108879089355 and perplexity is 43.30252242405982
At time: 717.4154071807861 and batch: 950, loss is 3.8707666301727297 and perplexity is 47.979154252535594
At time: 718.4623391628265 and batch: 1000, loss is 3.8258843851089477 and perplexity is 45.8733521415288
At time: 719.5104496479034 and batch: 1050, loss is 3.7831627893447877 and perplexity is 43.954842027844414
At time: 720.5591971874237 and batch: 1100, loss is 3.8167181730270388 and perplexity is 45.45478851897795
At time: 721.6080524921417 and batch: 1150, loss is 3.782166004180908 and perplexity is 43.91105032251736
At time: 722.6564056873322 and batch: 1200, loss is 3.823779664039612 and perplexity is 45.77690306556119
At time: 723.7030756473541 and batch: 1250, loss is 3.817656388282776 and perplexity is 45.497454907011104
At time: 724.750857591629 and batch: 1300, loss is 3.8088486909866335 and perplexity is 45.09848667134825
At time: 725.7991163730621 and batch: 1350, loss is 3.687199764251709 and perplexity is 39.932868801091466
At time: 726.846298456192 and batch: 1400, loss is 3.710284390449524 and perplexity is 40.86542661163547
At time: 727.8934302330017 and batch: 1450, loss is 3.62596116065979 and perplexity is 37.56080778605521
At time: 728.9422419071198 and batch: 1500, loss is 3.639136233329773 and perplexity is 38.0589484723611
At time: 729.9896793365479 and batch: 1550, loss is 3.652659549713135 and perplexity is 38.5771275263879
At time: 731.0375826358795 and batch: 1600, loss is 3.742293963432312 and perplexity is 42.19467226521319
At time: 732.0847897529602 and batch: 1650, loss is 3.6656344175338744 and perplexity is 39.080921922115344
At time: 733.133058309555 and batch: 1700, loss is 3.6902460718154906 and perplexity is 40.05470207796253
At time: 734.1806762218475 and batch: 1750, loss is 3.696767554283142 and perplexity is 40.31677172781232
At time: 735.226263999939 and batch: 1800, loss is 3.640212812423706 and perplexity is 38.09994400413019
At time: 736.2733685970306 and batch: 1850, loss is 3.6717402839660647 and perplexity is 39.32027479613696
At time: 737.3198826313019 and batch: 1900, loss is 3.752483057975769 and perplexity is 42.62679550392543
At time: 738.3675601482391 and batch: 1950, loss is 3.6874702501297 and perplexity is 39.94367153909799
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485524164244186 and perplexity of 88.72344428390323
finished 17 epochs...
Completing Train Step...
At time: 741.7729730606079 and batch: 50, loss is 3.890499873161316 and perplexity is 48.9353418749789
At time: 742.8273944854736 and batch: 100, loss is 3.878271951675415 and perplexity is 48.34060794700267
At time: 743.8813161849976 and batch: 150, loss is 3.83778904914856 and perplexity is 46.42272253402653
At time: 744.9353687763214 and batch: 200, loss is 3.820702986717224 and perplexity is 45.63627874476809
At time: 745.9897744655609 and batch: 250, loss is 3.8249184036254884 and perplexity is 45.829060728562375
At time: 747.0434846878052 and batch: 300, loss is 3.845278038978577 and perplexity is 46.77168689527202
At time: 748.0985143184662 and batch: 350, loss is 3.854338512420654 and perplexity is 47.19738612831462
At time: 749.1576180458069 and batch: 400, loss is 3.8068856239318847 and perplexity is 45.01004215760297
At time: 750.2137780189514 and batch: 450, loss is 3.8521520853042603 and perplexity is 47.094305213978444
At time: 751.2673482894897 and batch: 500, loss is 3.8849059104919434 and perplexity is 48.66236362622925
At time: 752.3210170269012 and batch: 550, loss is 3.843116431236267 and perplexity is 46.67069404754358
At time: 753.5138087272644 and batch: 600, loss is 3.8191642808914184 and perplexity is 45.56611193367992
At time: 754.567312002182 and batch: 650, loss is 3.8586328840255737 and perplexity is 47.40050506507414
At time: 755.6218550205231 and batch: 700, loss is 3.8687598180770872 and perplexity is 47.882965653946115
At time: 756.6753664016724 and batch: 750, loss is 3.8287839794158938 and perplexity is 46.00655928224246
At time: 757.7293982505798 and batch: 800, loss is 3.80609094619751 and perplexity is 44.97428788771975
At time: 758.783842086792 and batch: 850, loss is 3.801612892150879 and perplexity is 44.77334085747935
At time: 759.8377397060394 and batch: 900, loss is 3.7665069627761842 and perplexity is 43.22880099352575
At time: 760.8925230503082 and batch: 950, loss is 3.8690861225128175 and perplexity is 47.89859262747165
At time: 761.9474635124207 and batch: 1000, loss is 3.8242752075195314 and perplexity is 45.79959313289939
At time: 763.0020487308502 and batch: 1050, loss is 3.781604471206665 and perplexity is 43.88639974153237
At time: 764.0584256649017 and batch: 1100, loss is 3.8152536487579347 and perplexity is 45.388267600684216
At time: 765.114718914032 and batch: 1150, loss is 3.7808855152130127 and perplexity is 43.854858691070646
At time: 766.1732738018036 and batch: 1200, loss is 3.822515063285828 and perplexity is 45.71905014757037
At time: 767.2321088314056 and batch: 1250, loss is 3.816625518798828 and perplexity is 45.45057713573349
At time: 768.2934844493866 and batch: 1300, loss is 3.8081088495254516 and perplexity is 45.06513328070423
At time: 769.350998878479 and batch: 1350, loss is 3.6867700481414794 and perplexity is 39.915712690432514
At time: 770.4066162109375 and batch: 1400, loss is 3.7101612377166746 and perplexity is 40.86039423255117
At time: 771.4618139266968 and batch: 1450, loss is 3.6261672973632812 and perplexity is 37.568551245230836
At time: 772.5173225402832 and batch: 1500, loss is 3.639702615737915 and perplexity is 38.0805104968475
At time: 773.5734791755676 and batch: 1550, loss is 3.653438591957092 and perplexity is 38.60719244778285
At time: 774.6293876171112 and batch: 1600, loss is 3.743230605125427 and perplexity is 42.23421206890779
At time: 775.6844317913055 and batch: 1650, loss is 3.6667217588424683 and perplexity is 39.12343933417936
At time: 776.7430286407471 and batch: 1700, loss is 3.691472225189209 and perplexity is 40.10384540852194
At time: 777.8166491985321 and batch: 1750, loss is 3.6980592012405396 and perplexity is 40.36888040911184
At time: 778.8756320476532 and batch: 1800, loss is 3.6414861059188843 and perplexity is 38.14848731337874
At time: 779.9331147670746 and batch: 1850, loss is 3.6731692934036255 and perplexity is 39.37650400637552
At time: 780.9914174079895 and batch: 1900, loss is 3.753716230392456 and perplexity is 42.679394117266575
At time: 782.0481135845184 and batch: 1950, loss is 3.6885725259780884 and perplexity is 39.98772475847095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485510537790698 and perplexity of 88.72223530625344
finished 18 epochs...
Completing Train Step...
At time: 785.4182512760162 and batch: 50, loss is 3.889461488723755 and perplexity is 48.884554550476324
At time: 786.4955780506134 and batch: 100, loss is 3.8767794609069823 and perplexity is 48.268513849171704
At time: 787.5454685688019 and batch: 150, loss is 3.8360404634475707 and perplexity is 46.341619353797945
At time: 788.6008992195129 and batch: 200, loss is 3.818795657157898 and perplexity is 45.549318278836964
At time: 789.6524755954742 and batch: 250, loss is 3.82280996799469 and perplexity is 45.73253489900422
At time: 790.7039139270782 and batch: 300, loss is 3.843140983581543 and perplexity is 46.67183993660518
At time: 791.7547895908356 and batch: 350, loss is 3.8522556161880495 and perplexity is 47.09918118142094
At time: 792.8057475090027 and batch: 400, loss is 3.804650344848633 and perplexity is 44.9095445138168
At time: 793.8598902225494 and batch: 450, loss is 3.849999132156372 and perplexity is 46.99302244896649
At time: 794.9111204147339 and batch: 500, loss is 3.8827730321884157 and perplexity is 48.5586833346796
At time: 795.961567401886 and batch: 550, loss is 3.840978841781616 and perplexity is 46.571037814109665
At time: 797.0134093761444 and batch: 600, loss is 3.817164173126221 and perplexity is 45.47506588068226
At time: 798.0716981887817 and batch: 650, loss is 3.85670786857605 and perplexity is 47.30934612983851
At time: 799.1296021938324 and batch: 700, loss is 3.867025628089905 and perplexity is 47.799999454721245
At time: 800.1813795566559 and batch: 750, loss is 3.8271762132644653 and perplexity is 45.93265092308442
At time: 801.2295982837677 and batch: 800, loss is 3.8045365810394287 and perplexity is 44.904435723566515
At time: 802.2790660858154 and batch: 850, loss is 3.8000472927093507 and perplexity is 44.703298583416824
At time: 803.3313794136047 and batch: 900, loss is 3.765097723007202 and perplexity is 43.16792415310742
At time: 804.3852801322937 and batch: 950, loss is 3.867686381340027 and perplexity is 47.831593896632384
At time: 805.4395852088928 and batch: 1000, loss is 3.8229540967941285 and perplexity is 45.739126749380816
At time: 806.5431799888611 and batch: 1050, loss is 3.78033392906189 and perplexity is 43.83067562849154
At time: 807.5975842475891 and batch: 1100, loss is 3.81408296585083 and perplexity is 45.33516342176321
At time: 808.6532423496246 and batch: 1150, loss is 3.77987952709198 and perplexity is 43.810763407562305
At time: 809.7069034576416 and batch: 1200, loss is 3.8215245819091797 and perplexity is 45.673788698852505
At time: 810.7584407329559 and batch: 1250, loss is 3.8158180618286135 and perplexity is 45.41389256302509
At time: 811.8100199699402 and batch: 1300, loss is 3.8075135850906374 and perplexity is 45.038315592212044
At time: 812.8783030509949 and batch: 1350, loss is 3.6863993120193483 and perplexity is 39.9009172366716
At time: 813.9402794837952 and batch: 1400, loss is 3.709998326301575 and perplexity is 40.853738150095836
At time: 814.9996445178986 and batch: 1450, loss is 3.6262513637542724 and perplexity is 37.57170963050395
At time: 816.0508439540863 and batch: 1500, loss is 3.640025091171265 and perplexity is 38.092792506188864
At time: 817.1009120941162 and batch: 1550, loss is 3.6539289808273314 and perplexity is 38.62612962818217
At time: 818.1514573097229 and batch: 1600, loss is 3.743839616775513 and perplexity is 42.259941029913215
At time: 819.2036221027374 and batch: 1650, loss is 3.6674431800842284 and perplexity is 39.15167399768419
At time: 820.2558975219727 and batch: 1700, loss is 3.692298998832703 and perplexity is 40.13701592127181
At time: 821.3084363937378 and batch: 1750, loss is 3.6989454889297484 and perplexity is 40.40467471052687
At time: 822.3623158931732 and batch: 1800, loss is 3.6423734617233277 and perplexity is 38.182353618536034
At time: 823.4134662151337 and batch: 1850, loss is 3.674161615371704 and perplexity is 39.41559756982012
At time: 824.4685609340668 and batch: 1900, loss is 3.7545721769332885 and perplexity is 42.71594103589904
At time: 825.52263879776 and batch: 1950, loss is 3.689323081970215 and perplexity is 40.01774905094676
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485531829124273 and perplexity of 88.72412434107086
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 828.9076194763184 and batch: 50, loss is 3.8890373802185056 and perplexity is 48.86382659087881
At time: 829.9595532417297 and batch: 100, loss is 3.8769077014923097 and perplexity is 48.27470422856106
At time: 831.0101671218872 and batch: 150, loss is 3.8364476776123047 and perplexity is 46.360494160399
At time: 832.0608463287354 and batch: 200, loss is 3.819097762107849 and perplexity is 45.56308103214917
At time: 833.1138172149658 and batch: 250, loss is 3.823268713951111 and perplexity is 45.75351932735882
At time: 834.1943788528442 and batch: 300, loss is 3.843283200263977 and perplexity is 46.67847792284906
At time: 835.2472801208496 and batch: 350, loss is 3.852123484611511 and perplexity is 47.092958303486164
At time: 836.2980401515961 and batch: 400, loss is 3.804638409614563 and perplexity is 44.909008511089716
At time: 837.3486261367798 and batch: 450, loss is 3.8500201654434205 and perplexity is 46.994010877091846
At time: 838.4012608528137 and batch: 500, loss is 3.8825227546691896 and perplexity is 48.54653170858056
At time: 839.4531195163727 and batch: 550, loss is 3.840820965766907 and perplexity is 46.56368594461589
At time: 840.5042159557343 and batch: 600, loss is 3.8167522287368776 and perplexity is 45.45633654042587
At time: 841.5545210838318 and batch: 650, loss is 3.85616455078125 and perplexity is 47.2836491016843
At time: 842.6035103797913 and batch: 700, loss is 3.86651668548584 and perplexity is 47.775678188113815
At time: 843.6541748046875 and batch: 750, loss is 3.826404342651367 and perplexity is 45.897210539110205
At time: 844.7053377628326 and batch: 800, loss is 3.804150619506836 and perplexity is 44.887107682928104
At time: 845.7630562782288 and batch: 850, loss is 3.7995478916168213 and perplexity is 44.68097928087051
At time: 846.814080953598 and batch: 900, loss is 3.7638282060623167 and perplexity is 43.11315651349841
At time: 847.8631155490875 and batch: 950, loss is 3.866494607925415 and perplexity is 47.77462342933508
At time: 848.9141306877136 and batch: 1000, loss is 3.821661229133606 and perplexity is 45.68003032174775
At time: 849.9639012813568 and batch: 1050, loss is 3.7790614986419677 and perplexity is 43.774939611118185
At time: 851.0141127109528 and batch: 1100, loss is 3.812723617553711 and perplexity is 45.27357901138103
At time: 852.0653088092804 and batch: 1150, loss is 3.7786779165267945 and perplexity is 43.75815154719695
At time: 853.1144769191742 and batch: 1200, loss is 3.820531477928162 and perplexity is 45.62845239302651
At time: 854.163206577301 and batch: 1250, loss is 3.8147590160369873 and perplexity is 45.36582262984792
At time: 855.2124087810516 and batch: 1300, loss is 3.806193289756775 and perplexity is 44.97889095196056
At time: 856.2628402709961 and batch: 1350, loss is 3.6842525959014893 and perplexity is 39.815353168264046
At time: 857.3135952949524 and batch: 1400, loss is 3.7074115228652955 and perplexity is 40.74819412953629
At time: 858.3625571727753 and batch: 1450, loss is 3.6234355783462524 and perplexity is 37.46606456549013
At time: 859.4113185405731 and batch: 1500, loss is 3.636505904197693 and perplexity is 37.95897245401612
At time: 860.4618635177612 and batch: 1550, loss is 3.650439624786377 and perplexity is 38.491584184418194
At time: 861.5110282897949 and batch: 1600, loss is 3.7402411460876466 and perplexity is 42.10814315475065
At time: 862.568201303482 and batch: 1650, loss is 3.6637350797653196 and perplexity is 39.006764498370075
At time: 863.6252579689026 and batch: 1700, loss is 3.6885793209075928 and perplexity is 39.98799647316486
At time: 864.6761689186096 and batch: 1750, loss is 3.6953540086746215 and perplexity is 40.25982239191118
At time: 865.7270851135254 and batch: 1800, loss is 3.6387094116210936 and perplexity is 38.04270755317859
At time: 866.7771055698395 and batch: 1850, loss is 3.6708246231079102 and perplexity is 39.284287238287746
At time: 867.827648639679 and batch: 1900, loss is 3.750851716995239 and perplexity is 42.557313355498536
At time: 868.8844964504242 and batch: 1950, loss is 3.686431522369385 and perplexity is 39.90220247988153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.485462561319041 and perplexity of 88.71797882855216
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc0f4432b38>
ELAPSED
5387.7532370090485


RESULTS SO FAR:
[{'best_accuracy': -94.78310464460193, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.83547208165798, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.24245156315881022, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.32612507610596975, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.75140648791492, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.5466017702903482, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44410872475199714, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -92.11489487016956, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.961697908824608, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.8996370580396494, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -89.84962450947984, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.4930294951606292, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.7555409501871296, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.71797882855216, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.530388264419721, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44136510739280954, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -94.78310464460193, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.45983742629302626, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.9588080873821043, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.83547208165798, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.24245156315881022, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.32612507610596975, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.75140648791492, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.5466017702903482, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44410872475199714, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -92.11489487016956, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.961697908824608, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.8996370580396494, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -89.84962450947984, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.4930294951606292, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.7555409501871296, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}, {'best_accuracy': -88.71797882855216, 'params': {'tie_weights': True, 'seq_len': 35, 'batch_size': 32, 'rnn_dropout': 0.530388264419721, 'wordvec_source': 'None', 'wordvec_dim': 300, 'dropout': 0.44136510739280954, 'num_layers': 1, 'tune_wordvecs': True, 'data': 'wikitext'}}]
