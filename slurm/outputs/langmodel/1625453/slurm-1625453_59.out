Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'type': 'continuous', 'domain': [0, 1]}, {'name': 'rnn_dropout', 'type': 'continuous', 'domain': [0, 1]}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.0027143955230713 and batch: 50, loss is 8.008666400909425 and perplexity is 3006.904432806803
At time: 3.1850085258483887 and batch: 100, loss is 7.303573999404907 and perplexity is 1485.5999842027409
At time: 4.362172603607178 and batch: 150, loss is 7.0530484008789065 and perplexity is 1156.37848044817
At time: 5.53938889503479 and batch: 200, loss is 6.939795055389404 and perplexity is 1032.5585759587361
At time: 6.717173099517822 and batch: 250, loss is 6.852575321197509 and perplexity is 946.314835908024
At time: 7.896639108657837 and batch: 300, loss is 6.749163856506348 and perplexity is 853.3449453170642
At time: 9.075332641601562 and batch: 350, loss is 6.698503465652466 and perplexity is 811.1909412305522
At time: 10.255677700042725 and batch: 400, loss is 6.665881175994873 and perplexity is 785.1550200012668
At time: 11.432164669036865 and batch: 450, loss is 6.569956245422364 and perplexity is 713.3386306195333
At time: 12.609578847885132 and batch: 500, loss is 6.559796285629273 and perplexity is 706.1278315555209
At time: 13.787928342819214 and batch: 550, loss is 6.518048152923584 and perplexity is 677.2551958537439
At time: 14.966515064239502 and batch: 600, loss is 6.5696484565734865 and perplexity is 713.1191067287912
At time: 16.146173238754272 and batch: 650, loss is 6.651005125045776 and perplexity is 773.5614609094157
At time: 17.326236248016357 and batch: 700, loss is 6.524885969161987 and perplexity is 681.9020113593322
At time: 18.503804683685303 and batch: 750, loss is 6.464046258926391 and perplexity is 641.6521015585704
At time: 19.681360244750977 and batch: 800, loss is 6.460614242553711 and perplexity is 639.4537156465287
At time: 20.860284090042114 and batch: 850, loss is 6.513295640945435 and perplexity is 674.0441686895001
At time: 22.04180407524109 and batch: 900, loss is 6.493256597518921 and perplexity is 660.671404520604
At time: 23.218018293380737 and batch: 950, loss is 6.505577011108398 and perplexity is 668.8614985445238
At time: 24.396679639816284 and batch: 1000, loss is 6.501907453536988 and perplexity is 666.4115705933019
At time: 25.57531213760376 and batch: 1050, loss is 6.396464490890503 and perplexity is 599.7209663079052
At time: 26.75412344932556 and batch: 1100, loss is 6.470411167144776 and perplexity is 645.7491832357858
At time: 27.93318247795105 and batch: 1150, loss is 6.373887023925781 and perplexity is 586.3324936203644
At time: 29.114871501922607 and batch: 1200, loss is 6.474293899536133 and perplexity is 648.2613283438099
At time: 30.294029235839844 and batch: 1250, loss is 6.392744989395141 and perplexity is 597.4944466155195
At time: 31.473950624465942 and batch: 1300, loss is 6.4040639781951905 and perplexity is 604.2958997342761
At time: 32.651161432266235 and batch: 1350, loss is 6.413248567581177 and perplexity is 609.8716758519358
At time: 33.8303656578064 and batch: 1400, loss is 6.439354820251465 and perplexity is 626.0027851749511
At time: 35.009368896484375 and batch: 1450, loss is 6.438229360580444 and perplexity is 625.2986406037749
At time: 36.18673086166382 and batch: 1500, loss is 6.418668422698975 and perplexity is 613.1860656183719
At time: 37.36509871482849 and batch: 1550, loss is 6.385267057418823 and perplexity is 593.0430880090454
At time: 38.5450119972229 and batch: 1600, loss is 6.367054872512817 and perplexity is 582.3402346338545
At time: 39.72269940376282 and batch: 1650, loss is 6.368856401443481 and perplexity is 583.390282976276
At time: 40.90068960189819 and batch: 1700, loss is 6.394626617431641 and perplexity is 598.6197673033832
At time: 42.082409143447876 and batch: 1750, loss is 6.408270397186279 and perplexity is 606.8431751811148
At time: 43.26278901100159 and batch: 1800, loss is 6.416790142059326 and perplexity is 612.0354110671881
At time: 44.45041036605835 and batch: 1850, loss is 6.3617624664306645 and perplexity is 579.2663948132162
At time: 45.62857103347778 and batch: 1900, loss is 6.304666366577148 and perplexity is 547.1190205397085
At time: 46.804041147232056 and batch: 1950, loss is 6.259345464706421 and perplexity is 522.8765868987824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.8886968568313955 and perplexity of 360.934628277601
finished 1 epochs...
Completing Train Step...
At time: 50.4309983253479 and batch: 50, loss is 6.03255705833435 and perplexity is 416.7793972079404
At time: 51.53996968269348 and batch: 100, loss is 5.855761299133301 and perplexity is 349.24067549741113
At time: 52.649662494659424 and batch: 150, loss is 5.68589506149292 and perplexity is 294.68148509614565
At time: 53.75690960884094 and batch: 200, loss is 5.59712857246399 and perplexity is 269.6510113729619
At time: 54.864553689956665 and batch: 250, loss is 5.565763998031616 and perplexity is 261.3247790792951
At time: 55.97333598136902 and batch: 300, loss is 5.5220950317382815 and perplexity is 250.15857874218548
At time: 57.104905128479004 and batch: 350, loss is 5.458326635360717 and perplexity is 234.7043496189322
At time: 58.21369433403015 and batch: 400, loss is 5.4006178760528565 and perplexity is 221.54326019866843
At time: 59.33253335952759 and batch: 450, loss is 5.3208357524871825 and perplexity is 204.55476772982675
At time: 60.450374364852905 and batch: 500, loss is 5.289663381576538 and perplexity is 198.27667059429655
At time: 61.56640934944153 and batch: 550, loss is 5.2431316089630124 and perplexity is 189.26186949735586
At time: 62.683539152145386 and batch: 600, loss is 5.236341238021851 and perplexity is 187.98106468972122
At time: 63.801711082458496 and batch: 650, loss is 5.302609815597534 and perplexity is 200.8603349609113
At time: 64.92063117027283 and batch: 700, loss is 5.262388763427734 and perplexity is 192.9418336497601
At time: 66.0383837223053 and batch: 750, loss is 5.172974767684937 and perplexity is 176.43892238685083
At time: 67.15639925003052 and batch: 800, loss is 5.165886240005493 and perplexity is 175.19265252943302
At time: 68.27270722389221 and batch: 850, loss is 5.162490034103394 and perplexity is 174.59867142090675
At time: 69.38969850540161 and batch: 900, loss is 5.184133033752442 and perplexity is 178.41869972738127
At time: 70.50698590278625 and batch: 950, loss is 5.2071035289764405 and perplexity is 182.56449885644207
At time: 71.62607216835022 and batch: 1000, loss is 5.164776496887207 and perplexity is 174.99834152650493
At time: 72.74466705322266 and batch: 1050, loss is 5.0746947860717775 and perplexity is 159.92337368865623
At time: 73.86269617080688 and batch: 1100, loss is 5.14262843132019 and perplexity is 171.1650732184868
At time: 74.97961044311523 and batch: 1150, loss is 5.041048192977906 and perplexity is 154.6320142993559
At time: 76.0996618270874 and batch: 1200, loss is 5.111907997131348 and perplexity is 165.98675518503458
At time: 77.21775841712952 and batch: 1250, loss is 5.065051507949829 and perplexity is 158.38860013564658
At time: 78.33601999282837 and batch: 1300, loss is 5.087320346832275 and perplexity is 161.95529604835212
At time: 79.4534010887146 and batch: 1350, loss is 5.010000953674316 and perplexity is 149.90487910941164
At time: 80.57157301902771 and batch: 1400, loss is 5.0110120677948 and perplexity is 150.0565267030004
At time: 81.68917226791382 and batch: 1450, loss is 4.957599363327026 and perplexity is 142.25189056066642
At time: 82.80591487884521 and batch: 1500, loss is 4.918124008178711 and perplexity is 136.74583833370437
At time: 83.92449760437012 and batch: 1550, loss is 4.914992046356201 and perplexity is 136.31822557162334
At time: 85.0441255569458 and batch: 1600, loss is 4.958060455322266 and perplexity is 142.31749689282657
At time: 86.16275238990784 and batch: 1650, loss is 4.94271029472351 and perplexity is 140.14958194897025
At time: 87.28160786628723 and batch: 1700, loss is 4.9457175731658936 and perplexity is 140.57168513826988
At time: 88.39987802505493 and batch: 1750, loss is 4.9468589115142825 and perplexity is 140.73221658613824
At time: 89.52064180374146 and batch: 1800, loss is 4.900883083343506 and perplexity is 134.40842113001023
At time: 90.64511060714722 and batch: 1850, loss is 4.9004616451263425 and perplexity is 134.3517882191122
At time: 91.76306295394897 and batch: 1900, loss is 4.985375308990479 and perplexity is 146.2584568404796
At time: 92.87986588478088 and batch: 1950, loss is 4.901088523864746 and perplexity is 134.43603690270848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.68639654115189 and perplexity of 108.46163773005387
finished 2 epochs...
Completing Train Step...
At time: 96.48705697059631 and batch: 50, loss is 4.90057596206665 and perplexity is 134.36714778237868
At time: 97.63023734092712 and batch: 100, loss is 4.831406812667847 and perplexity is 125.38723298236732
At time: 98.7491238117218 and batch: 150, loss is 4.767151021957398 and perplexity is 117.58377073151655
At time: 99.8686466217041 and batch: 200, loss is 4.742310676574707 and perplexity is 114.69892783980818
At time: 100.98602938652039 and batch: 250, loss is 4.757397060394287 and perplexity is 116.4424384557561
At time: 102.1107587814331 and batch: 300, loss is 4.777790603637695 and perplexity is 118.84149181302773
At time: 103.2404944896698 and batch: 350, loss is 4.773569068908691 and perplexity is 118.34085579775578
At time: 104.3627564907074 and batch: 400, loss is 4.727413482666016 and perplexity is 113.00290006397871
At time: 105.4888551235199 and batch: 450, loss is 4.708332290649414 and perplexity is 110.86711152656669
At time: 106.60921502113342 and batch: 500, loss is 4.715495271682739 and perplexity is 111.66410154817476
At time: 107.7288064956665 and batch: 550, loss is 4.682024879455566 and perplexity is 107.98851506249443
At time: 108.84731721878052 and batch: 600, loss is 4.656347036361694 and perplexity is 105.25090134372563
At time: 109.96402478218079 and batch: 650, loss is 4.718784780502319 and perplexity is 112.03202640931363
At time: 111.08080172538757 and batch: 700, loss is 4.7410307884216305 and perplexity is 114.5522199457702
At time: 112.20575428009033 and batch: 750, loss is 4.680031471252441 and perplexity is 107.77346428393042
At time: 113.34766888618469 and batch: 800, loss is 4.682032556533813 and perplexity is 107.98934410195662
At time: 114.46590423583984 and batch: 850, loss is 4.683877849578858 and perplexity is 108.18880005831402
At time: 115.58500528335571 and batch: 900, loss is 4.6653234481811525 and perplexity is 106.19992984146913
At time: 116.70162653923035 and batch: 950, loss is 4.71824312210083 and perplexity is 111.97135975275856
At time: 117.81805419921875 and batch: 1000, loss is 4.693543634414673 and perplexity is 109.23959994300611
At time: 118.93514132499695 and batch: 1050, loss is 4.625035018920898 and perplexity is 102.00634517228666
At time: 120.05455994606018 and batch: 1100, loss is 4.678069314956665 and perplexity is 107.56220323384844
At time: 121.17162346839905 and batch: 1150, loss is 4.622870893478393 and perplexity is 101.7858293434246
At time: 122.29122829437256 and batch: 1200, loss is 4.692232236862183 and perplexity is 109.09643729109871
At time: 123.40884518623352 and batch: 1250, loss is 4.669785137176514 and perplexity is 106.67481951698154
At time: 124.5258047580719 and batch: 1300, loss is 4.670591955184936 and perplexity is 106.76092141202211
At time: 125.64113974571228 and batch: 1350, loss is 4.557113380432129 and perplexity is 95.30796453206138
At time: 126.76214671134949 and batch: 1400, loss is 4.564941730499267 and perplexity is 96.05699666021538
At time: 127.88099956512451 and batch: 1450, loss is 4.513468713760376 and perplexity is 91.237747891039
At time: 129.00168418884277 and batch: 1500, loss is 4.5044661808013915 and perplexity is 90.42006319771868
At time: 130.12667179107666 and batch: 1550, loss is 4.50987027168274 and perplexity is 90.91002414106033
At time: 131.2431869506836 and batch: 1600, loss is 4.57272403717041 and perplexity is 96.80745803883738
At time: 132.36031818389893 and batch: 1650, loss is 4.555286979675293 and perplexity is 95.1340528580577
At time: 133.48558139801025 and batch: 1700, loss is 4.557068719863891 and perplexity is 95.30370811925545
At time: 134.60391783714294 and batch: 1750, loss is 4.553030891418457 and perplexity is 94.91966396964168
At time: 135.72343850135803 and batch: 1800, loss is 4.516409826278687 and perplexity is 91.50648337042846
At time: 136.8413908481598 and batch: 1850, loss is 4.5399642753601075 and perplexity is 93.68745310916418
At time: 137.9560284614563 and batch: 1900, loss is 4.648010883331299 and perplexity is 104.37716060159148
At time: 139.0744547843933 and batch: 1950, loss is 4.567358493804932 and perplexity is 96.28942443332346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.508744776526163 and perplexity of 90.80776290726179
finished 3 epochs...
Completing Train Step...
At time: 142.70281863212585 and batch: 50, loss is 4.55943006515503 and perplexity is 95.5290189953455
At time: 143.8454155921936 and batch: 100, loss is 4.498287200927734 and perplexity is 89.86308200694678
At time: 144.96236324310303 and batch: 150, loss is 4.44825385093689 and perplexity is 85.47755705804764
At time: 146.07862973213196 and batch: 200, loss is 4.4376225090026855 and perplexity is 84.5736294170655
At time: 147.19641089439392 and batch: 250, loss is 4.447165451049805 and perplexity is 85.38457390520294
At time: 148.31485724449158 and batch: 300, loss is 4.474358234405518 and perplexity is 87.73827493164067
At time: 149.43366765975952 and batch: 350, loss is 4.473641080856323 and perplexity is 87.67537567328223
At time: 150.55153226852417 and batch: 400, loss is 4.423290519714356 and perplexity is 83.3701656806848
At time: 151.66788721084595 and batch: 450, loss is 4.431113357543945 and perplexity is 84.02491462499488
At time: 152.78260588645935 and batch: 500, loss is 4.444386854171753 and perplexity is 85.14765389974029
At time: 153.900004863739 and batch: 550, loss is 4.409893827438355 and perplexity is 82.26072920819574
At time: 155.01723289489746 and batch: 600, loss is 4.384627981185913 and perplexity is 80.2083786359732
At time: 156.13613057136536 and batch: 650, loss is 4.448933191299439 and perplexity is 85.53564514120498
At time: 157.25761675834656 and batch: 700, loss is 4.47977572441101 and perplexity is 88.21488601138367
At time: 158.37990307807922 and batch: 750, loss is 4.4322551727294925 and perplexity is 84.12091034273266
At time: 159.4960207939148 and batch: 800, loss is 4.429396352767944 and perplexity is 83.88076723157563
At time: 160.6110496520996 and batch: 850, loss is 4.434192295074463 and perplexity is 84.28402076925758
At time: 161.72937083244324 and batch: 900, loss is 4.400935144424438 and perplexity is 81.52707261596242
At time: 162.84671306610107 and batch: 950, loss is 4.467383241653442 and perplexity is 87.12843040293265
At time: 163.9636721611023 and batch: 1000, loss is 4.443015775680542 and perplexity is 85.0309897790106
At time: 165.08154821395874 and batch: 1050, loss is 4.392876396179199 and perplexity is 80.87270668910458
At time: 166.19645857810974 and batch: 1100, loss is 4.434869985580445 and perplexity is 84.34115860863773
At time: 167.31291127204895 and batch: 1150, loss is 4.393845262527466 and perplexity is 80.95109950305633
At time: 168.43067026138306 and batch: 1200, loss is 4.455602312088013 and perplexity is 86.10799911789353
At time: 169.57724022865295 and batch: 1250, loss is 4.446609411239624 and perplexity is 85.33710988010303
At time: 170.6939914226532 and batch: 1300, loss is 4.4306751728057865 and perplexity is 83.9881042552412
At time: 171.8170051574707 and batch: 1350, loss is 4.320933299064636 and perplexity is 75.25883452508907
At time: 172.93306922912598 and batch: 1400, loss is 4.335381927490235 and perplexity is 76.35411505717525
At time: 174.05143022537231 and batch: 1450, loss is 4.280929231643677 and perplexity is 72.30759930857477
At time: 175.17169046401978 and batch: 1500, loss is 4.276488151550293 and perplexity is 71.98718748260454
At time: 176.29048228263855 and batch: 1550, loss is 4.289240875244141 and perplexity is 72.91109886593593
At time: 177.40943241119385 and batch: 1600, loss is 4.3574854850769045 and perplexity is 78.06060288503357
At time: 178.52655172348022 and batch: 1650, loss is 4.338956146240235 and perplexity is 76.62750966186118
At time: 179.64332342147827 and batch: 1700, loss is 4.342981081008912 and perplexity is 76.93655190997154
At time: 180.75743293762207 and batch: 1750, loss is 4.339647073745727 and perplexity is 76.68047201042872
At time: 181.8713276386261 and batch: 1800, loss is 4.295681266784668 and perplexity is 73.38219026847297
At time: 182.98970198631287 and batch: 1850, loss is 4.328466596603394 and perplexity is 75.82792258147711
At time: 184.10709500312805 and batch: 1900, loss is 4.434672498703003 and perplexity is 84.32450398117362
At time: 185.2236831188202 and batch: 1950, loss is 4.361349716186523 and perplexity is 78.36283065803973
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.447441633357558 and perplexity of 85.40815887059578
finished 4 epochs...
Completing Train Step...
At time: 188.82125806808472 and batch: 50, loss is 4.3474043846130375 and perplexity is 77.27761940376179
At time: 189.96585059165955 and batch: 100, loss is 4.297365436553955 and perplexity is 73.50588246501923
At time: 191.08384346961975 and batch: 150, loss is 4.249856586456299 and perplexity is 70.09535900198073
At time: 192.20294284820557 and batch: 200, loss is 4.248966093063355 and perplexity is 70.03296733172141
At time: 193.320326089859 and batch: 250, loss is 4.251704177856445 and perplexity is 70.22498629672587
At time: 194.43776082992554 and batch: 300, loss is 4.273984498977661 and perplexity is 71.80718200508265
At time: 195.55411028862 and batch: 350, loss is 4.279318437576294 and perplexity is 72.19122041296274
At time: 196.69599437713623 and batch: 400, loss is 4.221998701095581 and perplexity is 68.16959886987304
At time: 197.81502318382263 and batch: 450, loss is 4.247802205085755 and perplexity is 69.95150421917309
At time: 198.93330073356628 and batch: 500, loss is 4.2662645530700685 and perplexity is 71.25496871513522
At time: 200.0512273311615 and batch: 550, loss is 4.22908043384552 and perplexity is 68.65407117771777
At time: 201.16689467430115 and batch: 600, loss is 4.208915610313415 and perplexity is 67.28353866102255
At time: 202.29076099395752 and batch: 650, loss is 4.269056959152222 and perplexity is 71.45421958836206
At time: 203.40931916236877 and batch: 700, loss is 4.304261746406556 and perplexity is 74.01455376795218
At time: 204.52868747711182 and batch: 750, loss is 4.265650429725647 and perplexity is 71.21122280950705
At time: 205.64903664588928 and batch: 800, loss is 4.253469820022583 and perplexity is 70.34908802102596
At time: 206.7797737121582 and batch: 850, loss is 4.256606550216675 and perplexity is 70.57010057671341
At time: 207.90298914909363 and batch: 900, loss is 4.222774367332459 and perplexity is 68.22249623879729
At time: 209.02011346817017 and batch: 950, loss is 4.299289407730103 and perplexity is 73.64744179853085
At time: 210.13917636871338 and batch: 1000, loss is 4.271054992675781 and perplexity is 71.59713023708966
At time: 211.25928807258606 and batch: 1050, loss is 4.230320663452148 and perplexity is 68.73927081204145
At time: 212.37863326072693 and batch: 1100, loss is 4.269878101348877 and perplexity is 71.51291775966959
At time: 213.49763131141663 and batch: 1150, loss is 4.233798246383667 and perplexity is 68.97873346122319
At time: 214.61579298973083 and batch: 1200, loss is 4.293461632728577 and perplexity is 73.21948929495264
At time: 215.73602294921875 and batch: 1250, loss is 4.286204147338867 and perplexity is 72.69002354010227
At time: 216.86023569107056 and batch: 1300, loss is 4.267441959381103 and perplexity is 71.33891417425198
At time: 217.98637557029724 and batch: 1350, loss is 4.160408816337585 and perplexity is 64.0977214400415
At time: 219.10621881484985 and batch: 1400, loss is 4.177647371292114 and perplexity is 65.2122523849298
At time: 220.22699642181396 and batch: 1450, loss is 4.119779171943665 and perplexity is 61.54564975746848
At time: 221.3468816280365 and batch: 1500, loss is 4.117219552993775 and perplexity is 61.388317786911244
At time: 222.46991991996765 and batch: 1550, loss is 4.133392491340637 and perplexity is 62.389219207633154
At time: 223.58855438232422 and batch: 1600, loss is 4.203870115280151 and perplexity is 66.94491488154905
At time: 224.7075159549713 and batch: 1650, loss is 4.182805771827698 and perplexity is 65.5495124158726
At time: 225.82535457611084 and batch: 1700, loss is 4.191083765029907 and perplexity is 66.0943829398642
At time: 226.94471144676208 and batch: 1750, loss is 4.184678378105164 and perplexity is 65.6723758458192
At time: 228.0639955997467 and batch: 1800, loss is 4.138189058303833 and perplexity is 62.68919212030126
At time: 229.18279886245728 and batch: 1850, loss is 4.175934867858887 and perplexity is 65.1006717472138
At time: 230.30138564109802 and batch: 1900, loss is 4.278739805221558 and perplexity is 72.14946032013947
At time: 231.42121148109436 and batch: 1950, loss is 4.211457152366638 and perplexity is 67.45476009509058
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.421350381540698 and perplexity of 83.20857284660465
finished 5 epochs...
Completing Train Step...
At time: 235.03945136070251 and batch: 50, loss is 4.200577731132507 and perplexity is 66.7248689416808
At time: 236.15823340415955 and batch: 100, loss is 4.150623154640198 and perplexity is 63.47354180871375
At time: 237.2815363407135 and batch: 150, loss is 4.109518761634827 and perplexity is 60.917394727100636
At time: 238.40312886238098 and batch: 200, loss is 4.108929147720337 and perplexity is 60.881487570254976
At time: 239.52412104606628 and batch: 250, loss is 4.106554102897644 and perplexity is 60.73706288384494
At time: 240.6434943675995 and batch: 300, loss is 4.1292448902130126 and perplexity is 62.130989498796716
At time: 241.76376914978027 and batch: 350, loss is 4.135177845954895 and perplexity is 62.50070557976642
At time: 242.88753080368042 and batch: 400, loss is 4.078360986709595 and perplexity is 59.04860903849327
At time: 244.00453352928162 and batch: 450, loss is 4.111020970344543 and perplexity is 61.0089741365044
At time: 245.12454319000244 and batch: 500, loss is 4.133246989250183 and perplexity is 62.380142106201255
At time: 246.24541473388672 and batch: 550, loss is 4.09376293182373 and perplexity is 59.96511232294804
At time: 247.36433935165405 and batch: 600, loss is 4.076691012382508 and perplexity is 58.950081669335155
At time: 248.4843237400055 and batch: 650, loss is 4.136316437721252 and perplexity is 62.5719088965939
At time: 249.60431361198425 and batch: 700, loss is 4.17378725528717 and perplexity is 64.96101074867956
At time: 250.72233843803406 and batch: 750, loss is 4.134893908500671 and perplexity is 62.48296180771683
At time: 251.84139895439148 and batch: 800, loss is 4.122530202865601 and perplexity is 61.71519685078004
At time: 252.9990050792694 and batch: 850, loss is 4.12349308013916 and perplexity is 61.77464962953225
At time: 254.11851143836975 and batch: 900, loss is 4.087780146598816 and perplexity is 59.6074249851047
At time: 255.23904824256897 and batch: 950, loss is 4.170405855178833 and perplexity is 64.7417225394262
At time: 256.3610534667969 and batch: 1000, loss is 4.139978647232056 and perplexity is 62.801480449446096
At time: 257.4776191711426 and batch: 1050, loss is 4.105483431816101 and perplexity is 60.67206826717439
At time: 258.59634590148926 and batch: 1100, loss is 4.142468590736389 and perplexity is 62.95804742832917
At time: 259.71716499328613 and batch: 1150, loss is 4.107308511734009 and perplexity is 60.78290074885056
At time: 260.83658719062805 and batch: 1200, loss is 4.166911535263061 and perplexity is 64.51588904600281
At time: 261.95774841308594 and batch: 1250, loss is 4.162457966804505 and perplexity is 64.22920198155792
At time: 263.0777006149292 and batch: 1300, loss is 4.144305348396301 and perplexity is 63.07379236935928
At time: 264.19621324539185 and batch: 1350, loss is 4.037310800552368 and perplexity is 56.67373072991184
At time: 265.314329624176 and batch: 1400, loss is 4.058426370620728 and perplexity is 57.88315274333128
At time: 266.43411779403687 and batch: 1450, loss is 3.9950478076934814 and perplexity is 54.32843787903344
At time: 267.5543305873871 and batch: 1500, loss is 3.9931222772598267 and perplexity is 54.2239274697621
At time: 268.6753897666931 and batch: 1550, loss is 4.013581643104553 and perplexity is 55.344741111470725
At time: 269.8077402114868 and batch: 1600, loss is 4.0861348009109495 and perplexity is 59.50943080469889
At time: 270.92829394340515 and batch: 1650, loss is 4.064446716308594 and perplexity is 58.232680415350394
At time: 272.0468862056732 and batch: 1700, loss is 4.071322002410889 and perplexity is 58.63442622988939
At time: 273.1685163974762 and batch: 1750, loss is 4.065061883926392 and perplexity is 58.26851429543075
At time: 274.295125246048 and batch: 1800, loss is 4.018215379714966 and perplexity is 55.60178915107456
At time: 275.4182720184326 and batch: 1850, loss is 4.0616844320297245 and perplexity is 58.072047157223274
At time: 276.5418803691864 and batch: 1900, loss is 4.158393878936767 and perplexity is 63.96869857395639
At time: 277.66752219200134 and batch: 1950, loss is 4.0905368566513065 and perplexity is 59.77197207286407
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4227732103924415 and perplexity of 83.32704867018593
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 281.3190264701843 and batch: 50, loss is 4.119273481369018 and perplexity is 61.51453457046709
At time: 282.44191694259644 and batch: 100, loss is 4.101600708961487 and perplexity is 60.43695218175097
At time: 283.5590965747833 and batch: 150, loss is 4.062717733383178 and perplexity is 58.132084094931315
At time: 284.6753525733948 and batch: 200, loss is 4.058109483718872 and perplexity is 57.86481323631705
At time: 285.7914545536041 and batch: 250, loss is 4.053724489212036 and perplexity is 57.61163185330815
At time: 286.91000747680664 and batch: 300, loss is 4.063789343833923 and perplexity is 58.194412433656034
At time: 288.02897548675537 and batch: 350, loss is 4.076265478134156 and perplexity is 58.92500172720732
At time: 289.1515974998474 and batch: 400, loss is 4.019005017280579 and perplexity is 55.64571175168901
At time: 290.2723705768585 and batch: 450, loss is 4.039956855773926 and perplexity is 56.82389112977625
At time: 291.39133048057556 and batch: 500, loss is 4.052728586196899 and perplexity is 57.55428481622189
At time: 292.50639605522156 and batch: 550, loss is 4.018691368103028 and perplexity is 55.6282612567736
At time: 293.6226329803467 and batch: 600, loss is 3.9842327213287354 and perplexity is 53.7440370005424
At time: 294.739431142807 and batch: 650, loss is 4.030404257774353 and perplexity is 56.283659755712584
At time: 295.8572599887848 and batch: 700, loss is 4.074841804504395 and perplexity is 58.841171443755904
At time: 296.9752562046051 and batch: 750, loss is 4.017506403923035 and perplexity is 55.56238279930374
At time: 298.0930018424988 and batch: 800, loss is 4.004925966262817 and perplexity is 54.86776218321616
At time: 299.2082026004791 and batch: 850, loss is 4.004577422142029 and perplexity is 54.84864167964951
At time: 300.3323197364807 and batch: 900, loss is 3.9606741142272948 and perplexity is 52.49270010061699
At time: 301.4514150619507 and batch: 950, loss is 4.042073683738709 and perplexity is 56.944304934277774
At time: 302.57800364494324 and batch: 1000, loss is 4.002798852920532 and perplexity is 54.75117627389533
At time: 303.6961200237274 and batch: 1050, loss is 3.9686050748825075 and perplexity is 52.9106729118848
At time: 304.81330275535583 and batch: 1100, loss is 3.9874257898330687 and perplexity is 53.91591966290392
At time: 305.93420600891113 and batch: 1150, loss is 3.964943642616272 and perplexity is 52.71729829691737
At time: 307.0525815486908 and batch: 1200, loss is 3.9981811952590944 and perplexity is 54.49893691101789
At time: 308.1687219142914 and batch: 1250, loss is 3.997255721092224 and perplexity is 54.44852288482261
At time: 309.2877161502838 and batch: 1300, loss is 3.9756484603881836 and perplexity is 53.28465869549593
At time: 310.417200088501 and batch: 1350, loss is 3.8625275182723997 and perplexity is 47.58547265216537
At time: 311.5358724594116 and batch: 1400, loss is 3.87562873840332 and perplexity is 48.213002129485204
At time: 312.6528604030609 and batch: 1450, loss is 3.808539810180664 and perplexity is 45.08455876557931
At time: 313.7690050601959 and batch: 1500, loss is 3.808104410171509 and perplexity is 45.06493322107119
At time: 314.886027097702 and batch: 1550, loss is 3.824523940086365 and perplexity is 45.81098640013882
At time: 316.0055856704712 and batch: 1600, loss is 3.882565498352051 and perplexity is 48.54860681048435
At time: 317.1247158050537 and batch: 1650, loss is 3.8559892177581787 and perplexity is 47.27535944329212
At time: 318.2429482936859 and batch: 1700, loss is 3.8425310230255127 and perplexity is 46.6433806355744
At time: 319.3612504005432 and batch: 1750, loss is 3.832728238105774 and perplexity is 46.188379390536774
At time: 320.4815456867218 and batch: 1800, loss is 3.7800546360015868 and perplexity is 43.818435734298426
At time: 321.60084080696106 and batch: 1850, loss is 3.811742734909058 and perplexity is 45.22919271589967
At time: 322.71922183036804 and batch: 1900, loss is 3.901922483444214 and perplexity is 49.49751584887917
At time: 323.8362970352173 and batch: 1950, loss is 3.8265143966674806 and perplexity is 45.90226198941954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3735107421875 and perplexity of 79.32162120123543
finished 7 epochs...
Completing Train Step...
At time: 327.44957852363586 and batch: 50, loss is 4.026407618522644 and perplexity is 56.0591631866289
At time: 328.5672528743744 and batch: 100, loss is 3.996820106506348 and perplexity is 54.424809479402185
At time: 329.68767976760864 and batch: 150, loss is 3.95289493560791 and perplexity is 52.08593421387055
At time: 330.8079707622528 and batch: 200, loss is 3.9461334896087648 and perplexity is 51.73494591376828
At time: 331.92629766464233 and batch: 250, loss is 3.940675263404846 and perplexity is 51.4533341258967
At time: 333.0459098815918 and batch: 300, loss is 3.9509462451934816 and perplexity is 51.98453368434953
At time: 334.16429591178894 and batch: 350, loss is 3.9658677911758424 and perplexity is 52.766039430758276
At time: 335.2830011844635 and batch: 400, loss is 3.9126081228256226 and perplexity is 50.029264430602645
At time: 336.43615078926086 and batch: 450, loss is 3.9430258512496947 and perplexity is 51.574421965718685
At time: 337.5593948364258 and batch: 500, loss is 3.9582894086837768 and perplexity is 52.367669607400124
At time: 338.6787028312683 and batch: 550, loss is 3.927923502922058 and perplexity is 50.80137915427198
At time: 339.7978756427765 and batch: 600, loss is 3.8957231569290163 and perplexity is 49.19161375960021
At time: 340.9166593551636 and batch: 650, loss is 3.9438475370407104 and perplexity is 51.61681735088523
At time: 342.0392575263977 and batch: 700, loss is 3.9883460187911988 and perplexity is 53.965557489061595
At time: 343.16329860687256 and batch: 750, loss is 3.9352402877807617 and perplexity is 51.17444507325344
At time: 344.2855339050293 and batch: 800, loss is 3.9239172554016113 and perplexity is 50.59826339267561
At time: 345.4067358970642 and batch: 850, loss is 3.9264200639724733 and perplexity is 50.72505976730389
At time: 346.52782940864563 and batch: 900, loss is 3.882396030426025 and perplexity is 48.540380075880265
At time: 347.65285086631775 and batch: 950, loss is 3.968359031677246 and perplexity is 52.89765620173124
At time: 348.77208256721497 and batch: 1000, loss is 3.929720401763916 and perplexity is 50.892746157686226
At time: 349.89177441596985 and batch: 1050, loss is 3.8997476482391358 and perplexity is 49.38998388338392
At time: 351.013475894928 and batch: 1100, loss is 3.917124514579773 and perplexity is 50.25572720029108
At time: 352.13378405570984 and batch: 1150, loss is 3.8988937664031984 and perplexity is 49.34782867361394
At time: 353.2566993236542 and batch: 1200, loss is 3.936105628013611 and perplexity is 51.218747545060154
At time: 354.3782253265381 and batch: 1250, loss is 3.9378183031082155 and perplexity is 51.30654378010927
At time: 355.4954843521118 and batch: 1300, loss is 3.9191355466842652 and perplexity is 50.35689477264788
At time: 356.61683106422424 and batch: 1350, loss is 3.8069979429244993 and perplexity is 45.01509792411964
At time: 357.7402582168579 and batch: 1400, loss is 3.8247803592681886 and perplexity is 45.82273472197325
At time: 358.8639249801636 and batch: 1450, loss is 3.757596797943115 and perplexity is 42.84533615556371
At time: 359.9909200668335 and batch: 1500, loss is 3.7610041761398314 and perplexity is 42.99157542457029
At time: 361.1202712059021 and batch: 1550, loss is 3.781825580596924 and perplexity is 43.896104509488005
At time: 362.2417812347412 and batch: 1600, loss is 3.842909407615662 and perplexity is 46.66103311154118
At time: 363.3609046936035 and batch: 1650, loss is 3.818772611618042 and perplexity is 45.54826858230261
At time: 364.4826624393463 and batch: 1700, loss is 3.8107950830459596 and perplexity is 45.186351489646064
At time: 365.6070029735565 and batch: 1750, loss is 3.805503478050232 and perplexity is 44.94787468535638
At time: 366.7290074825287 and batch: 1800, loss is 3.7556848621368406 and perplexity is 42.76349688388324
At time: 367.85195755958557 and batch: 1850, loss is 3.793199462890625 and perplexity is 44.39822374481975
At time: 368.9784677028656 and batch: 1900, loss is 3.884891781806946 and perplexity is 48.6616760958793
At time: 370.09841799736023 and batch: 1950, loss is 3.812731971740723 and perplexity is 45.273957236906675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375644985465116 and perplexity of 79.49109362141168
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 373.74262404441833 and batch: 50, loss is 3.9951459264755247 and perplexity is 54.333768780714955
At time: 374.8903293609619 and batch: 100, loss is 4.000401782989502 and perplexity is 54.620091048554045
At time: 376.0123372077942 and batch: 150, loss is 3.964251871109009 and perplexity is 52.680842582981576
At time: 377.1304380893707 and batch: 200, loss is 3.961203346252441 and perplexity is 52.52048827114294
At time: 378.2482166290283 and batch: 250, loss is 3.95677996635437 and perplexity is 52.28868325786902
At time: 379.36938190460205 and batch: 300, loss is 3.963246078491211 and perplexity is 52.627883217946
At time: 380.4883613586426 and batch: 350, loss is 3.9714577770233155 and perplexity is 53.06182679777269
At time: 381.6102616786957 and batch: 400, loss is 3.921543116569519 and perplexity is 50.478278577381474
At time: 382.7340998649597 and batch: 450, loss is 3.9577040100097656 and perplexity is 52.33702261428067
At time: 383.85623383522034 and batch: 500, loss is 3.9633464193344117 and perplexity is 52.63316420906907
At time: 384.9810583591461 and batch: 550, loss is 3.937543091773987 and perplexity is 51.29242558057427
At time: 386.1047580242157 and batch: 600, loss is 3.8958028030395506 and perplexity is 49.19553183633479
At time: 387.23246335983276 and batch: 650, loss is 3.9410190200805664 and perplexity is 51.471024593424495
At time: 388.3533983230591 and batch: 700, loss is 3.9864801120758058 and perplexity is 53.86495667799501
At time: 389.4812979698181 and batch: 750, loss is 3.9279717588424683 and perplexity is 50.80383068073103
At time: 390.60308027267456 and batch: 800, loss is 3.916502413749695 and perplexity is 50.22447279338783
At time: 391.7340838909149 and batch: 850, loss is 3.918711709976196 and perplexity is 50.33555619449465
At time: 392.87860894203186 and batch: 900, loss is 3.868490390777588 and perplexity is 47.87006641359974
At time: 393.99896454811096 and batch: 950, loss is 3.953950490951538 and perplexity is 52.140942827268226
At time: 395.1181447505951 and batch: 1000, loss is 3.913613352775574 and perplexity is 50.079580631021145
At time: 396.2387173175812 and batch: 1050, loss is 3.8872571659088133 and perplexity is 48.776915890344625
At time: 397.3603057861328 and batch: 1100, loss is 3.902802596092224 and perplexity is 49.54109841459325
At time: 398.4789855480194 and batch: 1150, loss is 3.8873120975494384 and perplexity is 48.779595359952275
At time: 399.60058307647705 and batch: 1200, loss is 3.9116548252105714 and perplexity is 49.98159437762221
At time: 400.7228362560272 and batch: 1250, loss is 3.9097778272628783 and perplexity is 49.88786701810145
At time: 401.84416222572327 and batch: 1300, loss is 3.887521743774414 and perplexity is 48.7898228900194
At time: 402.965957403183 and batch: 1350, loss is 3.76829306602478 and perplexity is 43.30608108998418
At time: 404.0917418003082 and batch: 1400, loss is 3.783141736984253 and perplexity is 43.953916684403154
At time: 405.2140243053436 and batch: 1450, loss is 3.7120437526702883 and perplexity is 40.93738698296885
At time: 406.3510537147522 and batch: 1500, loss is 3.7155593109130858 and perplexity is 41.08155802357458
At time: 407.4727306365967 and batch: 1550, loss is 3.738734130859375 and perplexity is 42.04473333356608
At time: 408.59417057037354 and batch: 1600, loss is 3.809565854072571 and perplexity is 45.13084124158557
At time: 409.7160131931305 and batch: 1650, loss is 3.773970365524292 and perplexity is 43.552641920064296
At time: 410.83660912513733 and batch: 1700, loss is 3.7520042753219602 and perplexity is 42.60639141860153
At time: 411.956414937973 and batch: 1750, loss is 3.7428864145278933 and perplexity is 42.21967795161616
At time: 413.0763006210327 and batch: 1800, loss is 3.6947386693954467 and perplexity is 40.23505656229616
At time: 414.20301961898804 and batch: 1850, loss is 3.7340994548797606 and perplexity is 41.850320486195095
At time: 415.32563495635986 and batch: 1900, loss is 3.832196788787842 and perplexity is 46.16383912934341
At time: 416.44589471817017 and batch: 1950, loss is 3.7657130670547487 and perplexity is 43.194495452687065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.349025992460029 and perplexity of 77.40303505780525
finished 9 epochs...
Completing Train Step...
At time: 420.08037519454956 and batch: 50, loss is 3.982731332778931 and perplexity is 53.66340686249868
At time: 421.2270576953888 and batch: 100, loss is 3.9656114196777343 and perplexity is 52.75251345609146
At time: 422.3495419025421 and batch: 150, loss is 3.920605182647705 and perplexity is 50.430955484025496
At time: 423.47062492370605 and batch: 200, loss is 3.9136828279495237 and perplexity is 50.08306003946167
At time: 424.60113286972046 and batch: 250, loss is 3.9086428833007814 and perplexity is 49.83127920272128
At time: 425.72346591949463 and batch: 300, loss is 3.9117739677429197 and perplexity is 49.9875496661042
At time: 426.84625816345215 and batch: 350, loss is 3.92433443069458 and perplexity is 50.61937614158257
At time: 427.96737122535706 and batch: 400, loss is 3.876407890319824 and perplexity is 48.25058202081582
At time: 429.08768677711487 and batch: 450, loss is 3.91467565536499 and perplexity is 50.1328085662835
At time: 430.2092173099518 and batch: 500, loss is 3.922697105407715 and perplexity is 50.53656357107906
At time: 431.33350920677185 and batch: 550, loss is 3.8977284622192383 and perplexity is 49.29035693492358
At time: 432.4525578022003 and batch: 600, loss is 3.8607577323913573 and perplexity is 47.501331032809766
At time: 433.58162021636963 and batch: 650, loss is 3.9064839363098143 and perplexity is 49.72381216199508
At time: 434.70397424697876 and batch: 700, loss is 3.9518854999542237 and perplexity is 52.033383342643305
At time: 435.8344020843506 and batch: 750, loss is 3.8948213624954224 and perplexity is 49.1472730322478
At time: 436.9546558856964 and batch: 800, loss is 3.8845338344573976 and perplexity is 48.64426089494466
At time: 438.0747630596161 and batch: 850, loss is 3.8870606422424316 and perplexity is 48.76733101385745
At time: 439.1941177845001 and batch: 900, loss is 3.8379874086380004 and perplexity is 46.431931834912746
At time: 440.31273555755615 and batch: 950, loss is 3.9259810209274293 and perplexity is 50.702794170738926
At time: 441.43454670906067 and batch: 1000, loss is 3.8864652347564697 and perplexity is 48.738303222441125
At time: 442.55909156799316 and batch: 1050, loss is 3.8620545196533205 and perplexity is 47.56297011156751
At time: 443.67994713783264 and batch: 1100, loss is 3.877676877975464 and perplexity is 48.31185027988806
At time: 444.79957604408264 and batch: 1150, loss is 3.8623997354507447 and perplexity is 47.579392434682035
At time: 445.92575430870056 and batch: 1200, loss is 3.888077235221863 and perplexity is 48.81693274830745
At time: 447.0430328845978 and batch: 1250, loss is 3.888623385429382 and perplexity is 48.843601408142554
At time: 448.16441464424133 and batch: 1300, loss is 3.868496527671814 and perplexity is 47.87036018803534
At time: 449.2879204750061 and batch: 1350, loss is 3.750129642486572 and perplexity is 42.52659489621007
At time: 450.41314482688904 and batch: 1400, loss is 3.766990747451782 and perplexity is 43.249719484605606
At time: 451.5363781452179 and batch: 1450, loss is 3.6978488683700563 and perplexity is 40.36039039951254
At time: 452.66018414497375 and batch: 1500, loss is 3.703672003746033 and perplexity is 40.596100035140736
At time: 453.78661036491394 and batch: 1550, loss is 3.728990592956543 and perplexity is 41.63705820501632
At time: 454.9064211845398 and batch: 1600, loss is 3.8025719356536865 and perplexity is 44.816301036175055
At time: 456.03208565711975 and batch: 1650, loss is 3.7685927391052245 and perplexity is 43.31906070142932
At time: 457.15980100631714 and batch: 1700, loss is 3.749057078361511 and perplexity is 42.48100684858595
At time: 458.279771566391 and batch: 1750, loss is 3.741353545188904 and perplexity is 42.15501027799159
At time: 459.4011175632477 and batch: 1800, loss is 3.694830470085144 and perplexity is 40.23875033778157
At time: 460.52355456352234 and batch: 1850, loss is 3.735820550918579 and perplexity is 41.922410926497435
At time: 461.6512427330017 and batch: 1900, loss is 3.8334427309036254 and perplexity is 46.22139244734697
At time: 462.77143716812134 and batch: 1950, loss is 3.7669979619979856 and perplexity is 43.25003151283069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345932503633721 and perplexity of 77.1639596129963
finished 10 epochs...
Completing Train Step...
At time: 466.36879992485046 and batch: 50, loss is 3.9611091232299804 and perplexity is 52.515539865127465
At time: 467.5139491558075 and batch: 100, loss is 3.9388923406600953 and perplexity is 51.36167853788632
At time: 468.6317808628082 and batch: 150, loss is 3.895775260925293 and perplexity is 49.19417690603489
At time: 469.75010895729065 and batch: 200, loss is 3.8883383893966674 and perplexity is 48.82968315893484
At time: 470.8697204589844 and batch: 250, loss is 3.8865500545501708 and perplexity is 48.74243737059211
At time: 471.9879505634308 and batch: 300, loss is 3.88904155254364 and perplexity is 48.86403046707597
At time: 473.1057708263397 and batch: 350, loss is 3.9010129356384278 and perplexity is 49.45251595982441
At time: 474.2231192588806 and batch: 400, loss is 3.8524171781539915 and perplexity is 47.106791232457724
At time: 475.3394091129303 and batch: 450, loss is 3.890926885604858 and perplexity is 48.95624233694961
At time: 476.4577136039734 and batch: 500, loss is 3.900345554351807 and perplexity is 49.419523286667406
At time: 477.60033655166626 and batch: 550, loss is 3.8754262208938597 and perplexity is 48.20323914099176
At time: 478.72024750709534 and batch: 600, loss is 3.8404804182052614 and perplexity is 46.54783149465659
At time: 479.83875489234924 and batch: 650, loss is 3.886636004447937 and perplexity is 48.74662695814572
At time: 480.9580252170563 and batch: 700, loss is 3.931531729698181 and perplexity is 50.98501314811506
At time: 482.07432866096497 and batch: 750, loss is 3.8756235218048096 and perplexity is 48.21275062226612
At time: 483.1945514678955 and batch: 800, loss is 3.865950245857239 and perplexity is 47.748623813763025
At time: 484.3132770061493 and batch: 850, loss is 3.8687117671966553 and perplexity is 47.880664890566045
At time: 485.4431576728821 and batch: 900, loss is 3.8191409301757813 and perplexity is 45.56504794477997
At time: 486.5678782463074 and batch: 950, loss is 3.908609504699707 and perplexity is 49.82961593209073
At time: 487.68700909614563 and batch: 1000, loss is 3.8694368267059325 and perplexity is 47.91539381070091
At time: 488.8076522350311 and batch: 1050, loss is 3.846552119255066 and perplexity is 46.8313157569555
At time: 489.9282388687134 and batch: 1100, loss is 3.863070182800293 and perplexity is 47.61130260808328
At time: 491.0539071559906 and batch: 1150, loss is 3.848652639389038 and perplexity is 46.92978926518981
At time: 492.17376708984375 and batch: 1200, loss is 3.875039119720459 and perplexity is 48.184583221655664
At time: 493.2925159931183 and batch: 1250, loss is 3.8765687274932863 and perplexity is 48.258343132166836
At time: 494.41754484176636 and batch: 1300, loss is 3.857212100028992 and perplexity is 47.33320700537171
At time: 495.5427362918854 and batch: 1350, loss is 3.7385623455047607 and perplexity is 42.037511284479606
At time: 496.6687309741974 and batch: 1400, loss is 3.7562519931793212 and perplexity is 42.78775626892605
At time: 497.7872984409332 and batch: 1450, loss is 3.686743631362915 and perplexity is 39.91465825981653
At time: 498.9067933559418 and batch: 1500, loss is 3.692927107810974 and perplexity is 40.1622342604365
At time: 500.0257556438446 and batch: 1550, loss is 3.719516649246216 and perplexity is 41.24445375209535
At time: 501.14900183677673 and batch: 1600, loss is 3.794273896217346 and perplexity is 44.445952312048526
At time: 502.27769589424133 and batch: 1650, loss is 3.7609852886199953 and perplexity is 42.990763428005
At time: 503.3979232311249 and batch: 1700, loss is 3.7422165727615355 and perplexity is 42.19140691757875
At time: 504.5205907821655 and batch: 1750, loss is 3.735317254066467 and perplexity is 41.90131681778972
At time: 505.64087414741516 and batch: 1800, loss is 3.6889864778518677 and perplexity is 40.00428117860704
At time: 506.76028275489807 and batch: 1850, loss is 3.7320521211624147 and perplexity is 41.76472656354168
At time: 507.87841868400574 and batch: 1900, loss is 3.8293179655075074 and perplexity is 46.031132705371355
At time: 509.00309467315674 and batch: 1950, loss is 3.7636582708358763 and perplexity is 43.105830691958936
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.345585312954215 and perplexity of 77.13717365561136
finished 11 epochs...
Completing Train Step...
At time: 512.6387424468994 and batch: 50, loss is 3.943083152770996 and perplexity is 51.57737734323056
At time: 513.7580125331879 and batch: 100, loss is 3.9156747817993165 and perplexity is 50.18292261151388
At time: 514.8784177303314 and batch: 150, loss is 3.8736456537246706 and perplexity is 48.11748640283986
At time: 515.9996066093445 and batch: 200, loss is 3.8668524265289306 and perplexity is 47.79172113713057
At time: 517.1225545406342 and batch: 250, loss is 3.8691847133636474 and perplexity is 47.903315223270894
At time: 518.2483668327332 and batch: 300, loss is 3.8738696670532224 and perplexity is 48.12826656853583
At time: 519.36998462677 and batch: 350, loss is 3.885583086013794 and perplexity is 48.69532774770071
At time: 520.4901964664459 and batch: 400, loss is 3.8348677206039428 and perplexity is 46.287304406296705
At time: 521.6099858283997 and batch: 450, loss is 3.872366065979004 and perplexity is 48.055955232547895
At time: 522.7411434650421 and batch: 500, loss is 3.882304253578186 and perplexity is 48.53592539722529
At time: 523.8640990257263 and batch: 550, loss is 3.857433223724365 and perplexity is 47.34367465629878
At time: 524.9852428436279 and batch: 600, loss is 3.8235760593414305 and perplexity is 45.767583621802316
At time: 526.1062984466553 and batch: 650, loss is 3.869340491294861 and perplexity is 47.91077808387405
At time: 527.2253837585449 and batch: 700, loss is 3.9138809728622435 and perplexity is 50.09298472625255
At time: 528.3420276641846 and batch: 750, loss is 3.859484524726868 and perplexity is 47.4408904589311
At time: 529.4650917053223 and batch: 800, loss is 3.849862151145935 and perplexity is 46.986585738131595
At time: 530.5877366065979 and batch: 850, loss is 3.853365592956543 and perplexity is 47.15148920332145
At time: 531.7058396339417 and batch: 900, loss is 3.8044756650924683 and perplexity is 44.90170041065463
At time: 532.8457767963409 and batch: 950, loss is 3.8950460958480835 and perplexity is 49.15831930487694
At time: 533.9657683372498 and batch: 1000, loss is 3.855119757652283 and perplexity is 47.23427326824764
At time: 535.0849578380585 and batch: 1050, loss is 3.8335985803604125 and perplexity is 46.22859658761792
At time: 536.2112581729889 and batch: 1100, loss is 3.8493049335479737 and perplexity is 46.9604112788021
At time: 537.3311154842377 and batch: 1150, loss is 3.83605345249176 and perplexity is 46.34222129104883
At time: 538.448117017746 and batch: 1200, loss is 3.8626517772674562 and perplexity is 47.59138594255857
At time: 539.5667231082916 and batch: 1250, loss is 3.865134081840515 and perplexity is 47.709669004077526
At time: 540.6873872280121 and batch: 1300, loss is 3.8455390548706054 and perplexity is 46.78389664224835
At time: 541.8157596588135 and batch: 1350, loss is 3.727480912208557 and perplexity is 41.574246964231534
At time: 542.9350726604462 and batch: 1400, loss is 3.7464770078659058 and perplexity is 42.371544127682874
At time: 544.0549550056458 and batch: 1450, loss is 3.6762091588973997 and perplexity is 39.496385401511695
At time: 545.1733088493347 and batch: 1500, loss is 3.682752366065979 and perplexity is 39.75566577113145
At time: 546.2923426628113 and batch: 1550, loss is 3.7103003025054933 and perplexity is 40.866076869764385
At time: 547.4132096767426 and batch: 1600, loss is 3.7850482511520385 and perplexity is 44.03779538184734
At time: 548.5334956645966 and batch: 1650, loss is 3.751530795097351 and perplexity is 42.586222909894666
At time: 549.6522254943848 and batch: 1700, loss is 3.7337829446792603 and perplexity is 41.837076528901356
At time: 550.7737205028534 and batch: 1750, loss is 3.727745599746704 and perplexity is 41.585252605774635
At time: 551.891713142395 and batch: 1800, loss is 3.6811945819854737 and perplexity is 39.6937832402082
At time: 553.0107526779175 and batch: 1850, loss is 3.725888113975525 and perplexity is 41.50808028619996
At time: 554.1308493614197 and batch: 1900, loss is 3.823137936592102 and perplexity is 45.74753619417355
At time: 555.2517762184143 and batch: 1950, loss is 3.7583207798004152 and perplexity is 42.87636663300622
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3503145439680235 and perplexity of 77.50283714160614
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 558.880767583847 and batch: 50, loss is 3.9411757946014405 and perplexity is 51.47909457121095
At time: 559.99964594841 and batch: 100, loss is 3.9293744468688967 and perplexity is 50.87514260822463
At time: 561.1563582420349 and batch: 150, loss is 3.887780179977417 and perplexity is 48.802433576051016
At time: 562.2844462394714 and batch: 200, loss is 3.877845916748047 and perplexity is 48.32001754603346
At time: 563.4126431941986 and batch: 250, loss is 3.8820876598358156 and perplexity is 48.52541395790118
At time: 564.5320823192596 and batch: 300, loss is 3.8910329818725584 and perplexity is 48.96143668708789
At time: 565.6498529911041 and batch: 350, loss is 3.9122713565826417 and perplexity is 50.01241909980984
At time: 566.7666208744049 and batch: 400, loss is 3.8679967069625856 and perplexity is 47.846439569163465
At time: 567.8844108581543 and batch: 450, loss is 3.91005316734314 and perplexity is 49.901605038637335
At time: 568.9998829364777 and batch: 500, loss is 3.911999349594116 and perplexity is 49.99881722228835
At time: 570.1154963970184 and batch: 550, loss is 3.887951636314392 and perplexity is 48.81080177991771
At time: 571.2316274642944 and batch: 600, loss is 3.842185254096985 and perplexity is 46.62725559175934
At time: 572.3498075008392 and batch: 650, loss is 3.881903691291809 and perplexity is 48.516487629255046
At time: 573.4658505916595 and batch: 700, loss is 3.9212525033950807 and perplexity is 50.46361105599462
At time: 574.5819563865662 and batch: 750, loss is 3.8677198314666748 and perplexity is 47.83319389626593
At time: 575.6997134685516 and batch: 800, loss is 3.854402060508728 and perplexity is 47.20038552726719
At time: 576.8158297538757 and batch: 850, loss is 3.8550078201293947 and perplexity is 47.228986276614464
At time: 577.9415881633759 and batch: 900, loss is 3.804815216064453 and perplexity is 44.916949415433514
At time: 579.0582585334778 and batch: 950, loss is 3.8990967750549315 and perplexity is 49.35784772672175
At time: 580.1718935966492 and batch: 1000, loss is 3.860805015563965 and perplexity is 47.50357709954424
At time: 581.2889423370361 and batch: 1050, loss is 3.8408449840545655 and perplexity is 46.56480433805025
At time: 582.4060163497925 and batch: 1100, loss is 3.8646711540222167 and perplexity is 47.687587982447646
At time: 583.5229542255402 and batch: 1150, loss is 3.857636661529541 and perplexity is 47.35330712933119
At time: 584.6406955718994 and batch: 1200, loss is 3.8879527759552004 and perplexity is 48.81085740673101
At time: 585.7586622238159 and batch: 1250, loss is 3.885292592048645 and perplexity is 48.68118410328019
At time: 586.8762571811676 and batch: 1300, loss is 3.863259916305542 and perplexity is 47.62033692444572
At time: 587.990734577179 and batch: 1350, loss is 3.737705626487732 and perplexity is 42.001512371812005
At time: 589.1083695888519 and batch: 1400, loss is 3.7516329860687256 and perplexity is 42.59057505975243
At time: 590.2299091815948 and batch: 1450, loss is 3.670372724533081 and perplexity is 39.2665387354352
At time: 591.3526058197021 and batch: 1500, loss is 3.671267056465149 and perplexity is 39.301671762840506
At time: 592.4724791049957 and batch: 1550, loss is 3.6974230194091797 and perplexity is 40.34320662830557
At time: 593.5901100635529 and batch: 1600, loss is 3.7759729623794556 and perplexity is 43.63994769376386
At time: 594.7078518867493 and batch: 1650, loss is 3.7397924566268923 and perplexity is 42.089253912724
At time: 595.8282053470612 and batch: 1700, loss is 3.7199769496917723 and perplexity is 41.26344296256991
At time: 596.9494304656982 and batch: 1750, loss is 3.711785984039307 and perplexity is 40.92683596868897
At time: 598.0698289871216 and batch: 1800, loss is 3.665522804260254 and perplexity is 39.0765602159002
At time: 599.1903941631317 and batch: 1850, loss is 3.706185259819031 and perplexity is 40.69825674931287
At time: 600.3100292682648 and batch: 1900, loss is 3.807783122062683 and perplexity is 45.050456719590656
At time: 601.4277398586273 and batch: 1950, loss is 3.756468052864075 and perplexity is 42.79700197683323
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34229736328125 and perplexity of 76.88396700419017
finished 13 epochs...
Completing Train Step...
At time: 605.0473990440369 and batch: 50, loss is 3.95931800365448 and perplexity is 52.42156244118305
At time: 606.1640388965607 and batch: 100, loss is 3.9379875469207763 and perplexity is 51.31522783002807
At time: 607.2805397510529 and batch: 150, loss is 3.8893398666381835 and perplexity is 48.8786094705335
At time: 608.3947114944458 and batch: 200, loss is 3.878064079284668 and perplexity is 48.33056031360751
At time: 609.5110025405884 and batch: 250, loss is 3.8767291736602782 and perplexity is 48.266086619537596
At time: 610.6295886039734 and batch: 300, loss is 3.8780631256103515 and perplexity is 48.330514222015424
At time: 611.747465133667 and batch: 350, loss is 3.8970349788665772 and perplexity is 49.2561867425417
At time: 612.8651201725006 and batch: 400, loss is 3.8536978244781492 and perplexity is 47.16715701685211
At time: 613.9819083213806 and batch: 450, loss is 3.8968097972869873 and perplexity is 49.245096405323125
At time: 615.0968222618103 and batch: 500, loss is 3.900826325416565 and perplexity is 49.44328847584768
At time: 616.2126879692078 and batch: 550, loss is 3.877874102592468 and perplexity is 48.321379505724344
At time: 617.3528542518616 and batch: 600, loss is 3.8349500370025633 and perplexity is 46.29111476732273
At time: 618.4713628292084 and batch: 650, loss is 3.8756832599639894 and perplexity is 48.21563084926616
At time: 619.5894434452057 and batch: 700, loss is 3.9167658567428587 and perplexity is 50.23770582182837
At time: 620.7164626121521 and batch: 750, loss is 3.8633159446716308 and perplexity is 47.62300508886195
At time: 621.8405311107635 and batch: 800, loss is 3.848957438468933 and perplexity is 46.94409560194589
At time: 622.9591581821442 and batch: 850, loss is 3.8483955383300783 and perplexity is 46.917725117591985
At time: 624.0778994560242 and batch: 900, loss is 3.7973479652404785 and perplexity is 44.58279245752031
At time: 625.1953866481781 and batch: 950, loss is 3.8911691093444825 and perplexity is 48.96810213735103
At time: 626.3135685920715 and batch: 1000, loss is 3.8520105266571045 and perplexity is 47.08763907967922
At time: 627.4306859970093 and batch: 1050, loss is 3.831579761505127 and perplexity is 46.13536356712857
At time: 628.5485100746155 and batch: 1100, loss is 3.855084390640259 and perplexity is 47.23260276267759
At time: 629.6641840934753 and batch: 1150, loss is 3.847143568992615 and perplexity is 46.85902231908079
At time: 630.7817556858063 and batch: 1200, loss is 3.87774920463562 and perplexity is 48.31534464103098
At time: 631.9001197814941 and batch: 1250, loss is 3.8761610078811644 and perplexity is 48.2386712697979
At time: 633.0233025550842 and batch: 1300, loss is 3.8542002725601194 and perplexity is 47.190862019194995
At time: 634.1426839828491 and batch: 1350, loss is 3.7299651384353636 and perplexity is 41.67765519043266
At time: 635.2610125541687 and batch: 1400, loss is 3.74475483417511 and perplexity is 42.29863576759737
At time: 636.3759891986847 and batch: 1450, loss is 3.664583430290222 and perplexity is 39.039869948034315
At time: 637.5028603076935 and batch: 1500, loss is 3.6665217733383177 and perplexity is 39.11561599574323
At time: 638.6213130950928 and batch: 1550, loss is 3.6937935876846315 and perplexity is 40.19704910910891
At time: 639.7408664226532 and batch: 1600, loss is 3.7731008195877074 and perplexity is 43.51478735778077
At time: 640.8589174747467 and batch: 1650, loss is 3.7381498432159423 and perplexity is 42.02017429087914
At time: 641.9772806167603 and batch: 1700, loss is 3.7202022075653076 and perplexity is 41.27273892494146
At time: 643.0928025245667 and batch: 1750, loss is 3.71348846912384 and perplexity is 40.99657264246222
At time: 644.209459066391 and batch: 1800, loss is 3.6671558523178103 and perplexity is 39.14042625061531
At time: 645.3274040222168 and batch: 1850, loss is 3.7089978647232056 and perplexity is 40.81288599365786
At time: 646.4471518993378 and batch: 1900, loss is 3.8112051010131838 and perplexity is 45.204882504395016
At time: 647.5644681453705 and batch: 1950, loss is 3.7605336904525757 and perplexity is 42.971353261152714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3404790833938955 and perplexity of 76.74429745097679
finished 14 epochs...
Completing Train Step...
At time: 651.1575157642365 and batch: 50, loss is 3.9546134805679323 and perplexity is 52.175523192896726
At time: 652.3015842437744 and batch: 100, loss is 3.9328592014312744 and perplexity is 51.0527392541808
At time: 653.4213140010834 and batch: 150, loss is 3.885627145767212 and perplexity is 48.69747329909978
At time: 654.5412967205048 and batch: 200, loss is 3.8764939737319946 and perplexity is 48.25473577433746
At time: 655.6609575748444 and batch: 250, loss is 3.875446310043335 and perplexity is 48.204207512794916
At time: 656.7801122665405 and batch: 300, loss is 3.8749468517303467 and perplexity is 48.18013753210798
At time: 657.8965334892273 and batch: 350, loss is 3.8897839164733887 and perplexity is 48.90031882867568
At time: 659.0149781703949 and batch: 400, loss is 3.84315842628479 and perplexity is 46.67265402675913
At time: 660.1355288028717 and batch: 450, loss is 3.885014410018921 and perplexity is 48.66764375610492
At time: 661.2604782581329 and batch: 500, loss is 3.890221791267395 and perplexity is 48.92173573432901
At time: 662.3841080665588 and batch: 550, loss is 3.868054361343384 and perplexity is 47.849198205533206
At time: 663.5074417591095 and batch: 600, loss is 3.8269010400772094 and perplexity is 45.920013227987965
At time: 664.6275734901428 and batch: 650, loss is 3.870528130531311 and perplexity is 47.967712605919324
At time: 665.7469756603241 and batch: 700, loss is 3.9129501152038575 and perplexity is 50.04637698374119
At time: 666.8684160709381 and batch: 750, loss is 3.8624426746368408 and perplexity is 47.58143549893157
At time: 667.9881293773651 and batch: 800, loss is 3.8482435369491577 and perplexity is 46.9105941005604
At time: 669.1076257228851 and batch: 850, loss is 3.846989254951477 and perplexity is 46.85179187187708
At time: 670.2279305458069 and batch: 900, loss is 3.7950843477249148 and perplexity is 44.48198820180328
At time: 671.346714258194 and batch: 950, loss is 3.888199963569641 and perplexity is 48.822924337468656
At time: 672.488041639328 and batch: 1000, loss is 3.847217502593994 and perplexity is 46.86248690343098
At time: 673.6080317497253 and batch: 1050, loss is 3.8255164098739622 and perplexity is 45.8564749893724
At time: 674.7298355102539 and batch: 1100, loss is 3.8481157779693604 and perplexity is 46.90460123374586
At time: 675.8493328094482 and batch: 1150, loss is 3.8402525091171267 and perplexity is 46.53722402964075
At time: 676.9777181148529 and batch: 1200, loss is 3.870985198020935 and perplexity is 47.98964209915055
At time: 678.0961675643921 and batch: 1250, loss is 3.8702357482910155 and perplexity is 47.953689748762855
At time: 679.214949131012 and batch: 1300, loss is 3.8489202213287355 and perplexity is 46.94234850946951
At time: 680.33673787117 and batch: 1350, loss is 3.725739541053772 and perplexity is 41.501913767535676
At time: 681.4600331783295 and batch: 1400, loss is 3.7417787504196167 and perplexity is 42.17293862020487
At time: 682.5840623378754 and batch: 1450, loss is 3.6621021890640257 and perplexity is 38.943122689532906
At time: 683.7047297954559 and batch: 1500, loss is 3.6646486473083497 and perplexity is 39.04241609496557
At time: 684.8228578567505 and batch: 1550, loss is 3.6918842029571532 and perplexity is 40.120370705032975
At time: 685.9401586055756 and batch: 1600, loss is 3.770711760520935 and perplexity is 43.410952044241185
At time: 687.0603442192078 and batch: 1650, loss is 3.736054892539978 and perplexity is 41.9322362434423
At time: 688.1867260932922 and batch: 1700, loss is 3.719138207435608 and perplexity is 41.228848079445626
At time: 689.30779337883 and batch: 1750, loss is 3.7130432319641113 and perplexity is 40.97832350779819
At time: 690.4283437728882 and batch: 1800, loss is 3.666772150993347 and perplexity is 39.12541089811244
At time: 691.5520775318146 and batch: 1850, loss is 3.7095506381988526 and perplexity is 40.835452511011255
At time: 692.6712095737457 and batch: 1900, loss is 3.8122873067855836 and perplexity is 45.2538299700197
At time: 693.7904605865479 and batch: 1950, loss is 3.7622635650634764 and perplexity is 43.045752646405894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338688340297965 and perplexity of 76.60699110705052
finished 15 epochs...
Completing Train Step...
At time: 697.3769953250885 and batch: 50, loss is 3.95147855758667 and perplexity is 52.01221306226819
At time: 698.5221765041351 and batch: 100, loss is 3.9285551166534423 and perplexity is 50.83347613829994
At time: 699.6463296413422 and batch: 150, loss is 3.881021113395691 and perplexity is 48.473686939925635
At time: 700.7963140010834 and batch: 200, loss is 3.873219175338745 and perplexity is 48.09696971017794
At time: 701.9170141220093 and batch: 250, loss is 3.8714404678344727 and perplexity is 48.01149530873665
At time: 703.0370473861694 and batch: 300, loss is 3.869113607406616 and perplexity is 47.89990913329505
At time: 704.1570138931274 and batch: 350, loss is 3.882921090126038 and perplexity is 48.565873365445206
At time: 705.2771942615509 and batch: 400, loss is 3.8351235008239746 and perplexity is 46.299145297470744
At time: 706.3944041728973 and batch: 450, loss is 3.875253930091858 and perplexity is 48.19493488165537
At time: 707.5126233100891 and batch: 500, loss is 3.8810991764068605 and perplexity is 48.477471089589784
At time: 708.6373331546783 and batch: 550, loss is 3.8588731575012205 and perplexity is 47.411895517530546
At time: 709.7610366344452 and batch: 600, loss is 3.8185654735565184 and perplexity is 45.53883477932628
At time: 710.8804094791412 and batch: 650, loss is 3.8632983446121214 and perplexity is 47.62216692851423
At time: 711.9996981620789 and batch: 700, loss is 3.906639242172241 and perplexity is 49.73153516122405
At time: 713.1169142723083 and batch: 750, loss is 3.8585194635391233 and perplexity is 47.39512918160509
At time: 714.2355806827545 and batch: 800, loss is 3.8447508430480957 and perplexity is 46.74703555089427
At time: 715.3553743362427 and batch: 850, loss is 3.8449129629135133 and perplexity is 46.75461478836233
At time: 716.4764447212219 and batch: 900, loss is 3.7934425592422487 and perplexity is 44.40901810301208
At time: 717.5965487957001 and batch: 950, loss is 3.8869816875457763 and perplexity is 48.76348075603053
At time: 718.7166275978088 and batch: 1000, loss is 3.8446916007995604 and perplexity is 46.744266233426984
At time: 719.8342173099518 and batch: 1050, loss is 3.821963753700256 and perplexity is 45.69385174367983
At time: 720.9518213272095 and batch: 1100, loss is 3.843077826499939 and perplexity is 46.66889237248244
At time: 722.0702610015869 and batch: 1150, loss is 3.8339348888397216 and perplexity is 46.244146271235564
At time: 723.1911709308624 and batch: 1200, loss is 3.8644716930389404 and perplexity is 47.67807711781333
At time: 724.3103835582733 and batch: 1250, loss is 3.864281568527222 and perplexity is 47.66901320834461
At time: 725.4310092926025 and batch: 1300, loss is 3.8443972206115724 and perplexity is 46.73050767276902
At time: 726.5583252906799 and batch: 1350, loss is 3.721900472640991 and perplexity is 41.34289052718315
At time: 727.6759803295135 and batch: 1400, loss is 3.7395730686187743 and perplexity is 42.08002104797184
At time: 728.794091463089 and batch: 1450, loss is 3.66068829536438 and perplexity is 38.88810016088721
At time: 729.913946390152 and batch: 1500, loss is 3.6637965726852415 and perplexity is 39.00916321196698
At time: 731.0319259166718 and batch: 1550, loss is 3.6908439779281617 and perplexity is 40.078658190215464
At time: 732.150004863739 and batch: 1600, loss is 3.7687695598602295 and perplexity is 43.326721087686344
At time: 733.2732670307159 and batch: 1650, loss is 3.7338994121551514 and perplexity is 41.84194947136749
At time: 734.3887412548065 and batch: 1700, loss is 3.7173646593093874 and perplexity is 41.15579153698487
At time: 735.5064904689789 and batch: 1750, loss is 3.7115266036987307 and perplexity is 40.91622172865881
At time: 736.6262698173523 and batch: 1800, loss is 3.665458812713623 and perplexity is 39.074059726380916
At time: 737.7451531887054 and batch: 1850, loss is 3.7092625999450686 and perplexity is 40.82369203239268
At time: 738.8627285957336 and batch: 1900, loss is 3.812852783203125 and perplexity is 45.27942718029847
At time: 739.9801516532898 and batch: 1950, loss is 3.7630389642715456 and perplexity is 43.07914323276278
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338022631268169 and perplexity of 76.55601011246202
finished 16 epochs...
Completing Train Step...
At time: 743.5817494392395 and batch: 50, loss is 3.948865866661072 and perplexity is 51.876498592362765
At time: 744.7313179969788 and batch: 100, loss is 3.9248352813720704 and perplexity is 50.64473524044803
At time: 745.8493976593018 and batch: 150, loss is 3.876268768310547 and perplexity is 48.24386976981803
At time: 746.9687678813934 and batch: 200, loss is 3.868470950126648 and perplexity is 47.86913579739403
At time: 748.0858743190765 and batch: 250, loss is 3.8662287473678587 and perplexity is 47.76192372956254
At time: 749.2034273147583 and batch: 300, loss is 3.8627647066116335 and perplexity is 47.59676071004032
At time: 750.3260478973389 and batch: 350, loss is 3.877758946418762 and perplexity is 48.31581532093353
At time: 751.4510366916656 and batch: 400, loss is 3.829282865524292 and perplexity is 46.02951704174105
At time: 752.5746157169342 and batch: 450, loss is 3.8698833990097046 and perplexity is 47.936796277019766
At time: 753.6969037055969 and batch: 500, loss is 3.8748877954483034 and perplexity is 48.177292276332935
At time: 754.8199219703674 and batch: 550, loss is 3.852309446334839 and perplexity is 47.101716605498105
At time: 755.9450490474701 and batch: 600, loss is 3.812133765220642 and perplexity is 45.24688215954901
At time: 757.0931015014648 and batch: 650, loss is 3.856375608444214 and perplexity is 47.29362973136724
At time: 758.2180528640747 and batch: 700, loss is 3.90005512714386 and perplexity is 49.405172596517495
At time: 759.3384437561035 and batch: 750, loss is 3.852752933502197 and perplexity is 47.12261024506125
At time: 760.4587545394897 and batch: 800, loss is 3.8392351341247557 and perplexity is 46.48990229775364
At time: 761.5787456035614 and batch: 850, loss is 3.8406169843673705 and perplexity is 46.55418878744398
At time: 762.696784734726 and batch: 900, loss is 3.7900412130355834 and perplexity is 44.25822425416832
At time: 763.8251347541809 and batch: 950, loss is 3.8845836448669435 and perplexity is 48.64668394584797
At time: 764.9461710453033 and batch: 1000, loss is 3.8423373603820803 and perplexity is 46.63434842981054
At time: 766.0664048194885 and batch: 1050, loss is 3.8193813228607176 and perplexity is 45.57600276567132
At time: 767.1858923435211 and batch: 1100, loss is 3.840425615310669 and perplexity is 46.545280608652284
At time: 768.305447101593 and batch: 1150, loss is 3.8297575950622558 and perplexity is 46.051373800713044
At time: 769.4230082035065 and batch: 1200, loss is 3.858250608444214 and perplexity is 47.38238847242977
At time: 770.5420618057251 and batch: 1250, loss is 3.858035707473755 and perplexity is 47.37220704520284
At time: 771.6638431549072 and batch: 1300, loss is 3.838841199874878 and perplexity is 46.47159193974045
At time: 772.7838156223297 and batch: 1350, loss is 3.7179940605163573 and perplexity is 41.181703195411195
At time: 773.9082183837891 and batch: 1400, loss is 3.736120886802673 and perplexity is 41.935003621770875
At time: 775.0320205688477 and batch: 1450, loss is 3.6591663932800294 and perplexity is 38.82896129339349
At time: 776.151038646698 and batch: 1500, loss is 3.663309569358826 and perplexity is 38.990170244916506
At time: 777.2693591117859 and batch: 1550, loss is 3.689849977493286 and perplexity is 40.0388397795824
At time: 778.3902826309204 and batch: 1600, loss is 3.7674414348602294 and perplexity is 43.26921598167906
At time: 779.5121650695801 and batch: 1650, loss is 3.7322243595123292 and perplexity is 41.771920670662396
At time: 780.6311709880829 and batch: 1700, loss is 3.7152715253829958 and perplexity is 41.06973704665648
At time: 781.7513961791992 and batch: 1750, loss is 3.709442057609558 and perplexity is 40.831018814224564
At time: 782.8715822696686 and batch: 1800, loss is 3.6632750129699705 and perplexity is 38.98882290871166
At time: 783.9889876842499 and batch: 1850, loss is 3.708092670440674 and perplexity is 40.7759591181225
At time: 785.1077742576599 and batch: 1900, loss is 3.812707505226135 and perplexity is 45.27284955452212
At time: 786.2339243888855 and batch: 1950, loss is 3.764091634750366 and perplexity is 43.12451525179951
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337525833484738 and perplexity of 76.5179867020849
finished 17 epochs...
Completing Train Step...
At time: 789.8469111919403 and batch: 50, loss is 3.9478840398788453 and perplexity is 51.82558985254834
At time: 790.9603757858276 and batch: 100, loss is 3.92225161075592 and perplexity is 50.51405481642524
At time: 792.0763714313507 and batch: 150, loss is 3.8718768692016603 and perplexity is 48.032452163397515
At time: 793.1933953762054 and batch: 200, loss is 3.8625953578948975 and perplexity is 47.58870094216822
At time: 794.3091719150543 and batch: 250, loss is 3.8600787496566773 and perplexity is 47.46908939616014
At time: 795.4215996265411 and batch: 300, loss is 3.856314306259155 and perplexity is 47.29073061738726
At time: 796.5376634597778 and batch: 350, loss is 3.8710652875900267 and perplexity is 47.99348572282217
At time: 797.6520564556122 and batch: 400, loss is 3.823615436553955 and perplexity is 45.76938585715259
At time: 798.7679877281189 and batch: 450, loss is 3.865737714767456 and perplexity is 47.73847682502175
At time: 799.8856108188629 and batch: 500, loss is 3.8702954769134523 and perplexity is 47.95655404213161
At time: 801.0023789405823 and batch: 550, loss is 3.848338451385498 and perplexity is 46.915046804467444
At time: 802.1291110515594 and batch: 600, loss is 3.8079309558868406 and perplexity is 45.057117193197065
At time: 803.2450258731842 and batch: 650, loss is 3.8506577157974244 and perplexity is 47.02398147823111
At time: 804.3597574234009 and batch: 700, loss is 3.894104013442993 and perplexity is 49.112029924824796
At time: 805.4745206832886 and batch: 750, loss is 3.846677680015564 and perplexity is 46.83719630175218
At time: 806.5917520523071 and batch: 800, loss is 3.8335414123535156 and perplexity is 46.22595386642964
At time: 807.7087531089783 and batch: 850, loss is 3.835931615829468 and perplexity is 46.3365754534255
At time: 808.8246579170227 and batch: 900, loss is 3.7854741621017456 and perplexity is 44.05655555589961
At time: 809.9419329166412 and batch: 950, loss is 3.8804183912277224 and perplexity is 48.444479577090476
At time: 811.057137966156 and batch: 1000, loss is 3.8391168975830077 and perplexity is 46.484405817428566
At time: 812.2019572257996 and batch: 1050, loss is 3.8163765811920167 and perplexity is 45.43926418600086
At time: 813.3206994533539 and batch: 1100, loss is 3.8388113260269163 and perplexity is 46.470203675204814
At time: 814.4408729076385 and batch: 1150, loss is 3.8269905185699464 and perplexity is 45.92412226539056
At time: 815.5634672641754 and batch: 1200, loss is 3.854155116081238 and perplexity is 47.18873109414372
At time: 816.688972234726 and batch: 1250, loss is 3.8526094007492064 and perplexity is 47.11584709246324
At time: 817.8097786903381 and batch: 1300, loss is 3.8329846811294557 and perplexity is 46.20022559708023
At time: 818.9262933731079 and batch: 1350, loss is 3.712963194847107 and perplexity is 40.9750438521738
At time: 820.0450315475464 and batch: 1400, loss is 3.732232871055603 and perplexity is 41.77227621568593
At time: 821.1650249958038 and batch: 1450, loss is 3.6567491817474367 and perplexity is 38.73521682610527
At time: 822.2841975688934 and batch: 1500, loss is 3.66248966217041 and perplexity is 38.958215026002144
At time: 823.4014797210693 and batch: 1550, loss is 3.6888402318954467 and perplexity is 39.99843114202766
At time: 824.5192956924438 and batch: 1600, loss is 3.766583619117737 and perplexity is 43.232114882273294
At time: 825.6371567249298 and batch: 1650, loss is 3.7311289739608764 and perplexity is 41.72618936358246
At time: 826.7563977241516 and batch: 1700, loss is 3.713199620246887 and perplexity is 40.9847325385782
At time: 827.8763172626495 and batch: 1750, loss is 3.707268419265747 and perplexity is 40.74236333349515
At time: 828.9919621944427 and batch: 1800, loss is 3.6604554080963134 and perplexity is 38.87904467197541
At time: 830.1206269264221 and batch: 1850, loss is 3.7061438083648683 and perplexity is 40.69656978235259
At time: 831.2394993305206 and batch: 1900, loss is 3.811046962738037 and perplexity is 45.19773444745315
At time: 832.3561246395111 and batch: 1950, loss is 3.7643997478485107 and perplexity is 43.13780452699447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.338564282794332 and perplexity of 76.59748802444945
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 835.9521491527557 and batch: 50, loss is 3.953640937805176 and perplexity is 52.12480493225871
At time: 837.0705292224884 and batch: 100, loss is 3.9460959148406984 and perplexity is 51.73300202169552
At time: 838.1973226070404 and batch: 150, loss is 3.9060504102706908 and perplexity is 49.70226026664983
At time: 839.3157596588135 and batch: 200, loss is 3.902575798034668 and perplexity is 49.52986386373894
At time: 840.4596490859985 and batch: 250, loss is 3.9029632663726805 and perplexity is 49.54905883625412
At time: 841.5791611671448 and batch: 300, loss is 3.893820505142212 and perplexity is 49.09810823022414
At time: 842.7003571987152 and batch: 350, loss is 3.9026067590713502 and perplexity is 49.53139738341046
At time: 843.8199338912964 and batch: 400, loss is 3.8478921031951905 and perplexity is 46.89411103089798
At time: 844.9401099681854 and batch: 450, loss is 3.8902049827575684 and perplexity is 48.92091343976398
At time: 846.0636606216431 and batch: 500, loss is 3.891020655632019 and perplexity is 48.960833180361625
At time: 847.1850266456604 and batch: 550, loss is 3.871862840652466 and perplexity is 48.031778342505795
At time: 848.3052685260773 and batch: 600, loss is 3.8288379859924317 and perplexity is 46.0090440061027
At time: 849.4258279800415 and batch: 650, loss is 3.867660946846008 and perplexity is 47.83037733971482
At time: 850.5458059310913 and batch: 700, loss is 3.911443662643433 and perplexity is 49.971041250095716
At time: 851.6660075187683 and batch: 750, loss is 3.859587035179138 and perplexity is 47.445753895340424
At time: 852.785347700119 and batch: 800, loss is 3.845777082443237 and perplexity is 46.79503382503007
At time: 853.9034614562988 and batch: 850, loss is 3.845876488685608 and perplexity is 46.79968577471682
At time: 855.0219328403473 and batch: 900, loss is 3.792008786201477 and perplexity is 44.34539127420457
At time: 856.1452243328094 and batch: 950, loss is 3.88830078125 and perplexity is 48.82784679958012
At time: 857.2692105770111 and batch: 1000, loss is 3.8463807582855223 and perplexity is 46.823291384834114
At time: 858.3887047767639 and batch: 1050, loss is 3.822086143493652 and perplexity is 45.699444546998244
At time: 859.5078589916229 and batch: 1100, loss is 3.8485473680496214 and perplexity is 46.924849163445444
At time: 860.6243867874146 and batch: 1150, loss is 3.8450456619262696 and perplexity is 46.76081949125642
At time: 861.7436170578003 and batch: 1200, loss is 3.8792775535583495 and perplexity is 48.38924380343224
At time: 862.8624033927917 and batch: 1250, loss is 3.875065760612488 and perplexity is 48.18586691903407
At time: 863.9842660427094 and batch: 1300, loss is 3.8574069595336913 and perplexity is 47.34243122932928
At time: 865.1068379878998 and batch: 1350, loss is 3.7323358821868897 and perplexity is 41.776579446751875
At time: 866.2317085266113 and batch: 1400, loss is 3.7489746046066283 and perplexity is 42.477503424912186
At time: 867.3507690429688 and batch: 1450, loss is 3.6662861013412478 and perplexity is 39.106398626585445
At time: 868.4683680534363 and batch: 1500, loss is 3.6709213209152223 and perplexity is 39.28808612639462
At time: 869.5870907306671 and batch: 1550, loss is 3.694919967651367 and perplexity is 40.24235176916192
At time: 870.7088980674744 and batch: 1600, loss is 3.770139741897583 and perplexity is 43.38612727200734
At time: 871.8271136283875 and batch: 1650, loss is 3.7375835227966308 and perplexity is 41.996384145213646
At time: 872.9462819099426 and batch: 1700, loss is 3.716046996116638 and perplexity is 41.101597777710154
At time: 874.0643856525421 and batch: 1750, loss is 3.708861403465271 and perplexity is 40.80731699588009
At time: 875.1814625263214 and batch: 1800, loss is 3.6597385025024414 and perplexity is 38.851182055991636
At time: 876.2997167110443 and batch: 1850, loss is 3.6985635805130004 and perplexity is 40.38924677139637
At time: 877.4236192703247 and batch: 1900, loss is 3.803119969367981 and perplexity is 44.84086861140773
At time: 878.5444097518921 and batch: 1950, loss is 3.76106183052063 and perplexity is 42.99405414868491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.33417486146439 and perplexity of 76.26200620087543
finished 19 epochs...
Completing Train Step...
At time: 882.156699180603 and batch: 50, loss is 3.9630479049682616 and perplexity is 52.61745479827579
At time: 883.2764620780945 and batch: 100, loss is 3.953438763618469 and perplexity is 52.114267707427615
At time: 884.3980524539948 and batch: 150, loss is 3.9084275913238526 and perplexity is 49.82055208288169
At time: 885.5165722370148 and batch: 200, loss is 3.903700575828552 and perplexity is 49.58560529723363
At time: 886.6431682109833 and batch: 250, loss is 3.9033765268325804 and perplexity is 49.569539734777685
At time: 887.7688934803009 and batch: 300, loss is 3.8956354522705077 and perplexity is 49.18729961510199
At time: 888.8856890201569 and batch: 350, loss is 3.9039763402938843 and perplexity is 49.59928113073438
At time: 890.0044071674347 and batch: 400, loss is 3.847032060623169 and perplexity is 46.85379743722262
At time: 891.132705450058 and batch: 450, loss is 3.888464617729187 and perplexity is 48.83584723744994
At time: 892.2523317337036 and batch: 500, loss is 3.8867296838760375 and perplexity is 48.75119372818385
At time: 893.3710377216339 and batch: 550, loss is 3.865894317626953 and perplexity is 47.74595339241122
At time: 894.4903004169464 and batch: 600, loss is 3.820404930114746 and perplexity is 45.62267857748619
At time: 895.6084337234497 and batch: 650, loss is 3.8583304357528685 and perplexity is 47.386171031952905
At time: 896.7642984390259 and batch: 700, loss is 3.9016571855545044 and perplexity is 49.484386004115656
At time: 897.8849828243256 and batch: 750, loss is 3.8502921533584593 and perplexity is 47.0067944185352
At time: 899.0059885978699 and batch: 800, loss is 3.8371838569641112 and perplexity is 46.39463636479041
At time: 900.125161409378 and batch: 850, loss is 3.838762059211731 and perplexity is 46.46791429266448
At time: 901.2447829246521 and batch: 900, loss is 3.7868011808395385 and perplexity is 44.11505823913817
At time: 902.3637766838074 and batch: 950, loss is 3.883952035903931 and perplexity is 48.6159679655123
At time: 903.4798724651337 and batch: 1000, loss is 3.843260073661804 and perplexity is 46.67739842074276
At time: 904.5966634750366 and batch: 1050, loss is 3.8193393754959106 and perplexity is 45.574091012553644
At time: 905.7174820899963 and batch: 1100, loss is 3.845453543663025 and perplexity is 46.7798962657921
At time: 906.838606595993 and batch: 1150, loss is 3.8410290718078612 and perplexity is 46.57337713731297
At time: 907.9586820602417 and batch: 1200, loss is 3.8749318885803223 and perplexity is 48.17941661087553
At time: 909.0783395767212 and batch: 1250, loss is 3.8709625673294066 and perplexity is 47.988556072652464
At time: 910.2062523365021 and batch: 1300, loss is 3.8536806154251098 and perplexity is 47.16634532172956
At time: 911.3342580795288 and batch: 1350, loss is 3.7282193231582643 and perplexity is 41.604957180400305
At time: 912.4557650089264 and batch: 1400, loss is 3.744759874343872 and perplexity is 42.298848960397315
At time: 913.575799703598 and batch: 1450, loss is 3.6624441862106325 and perplexity is 38.95644340406603
At time: 914.6963472366333 and batch: 1500, loss is 3.6684302425384523 and perplexity is 39.19033822397118
At time: 915.8164384365082 and batch: 1550, loss is 3.6921603298187256 and perplexity is 40.131450546731436
At time: 916.9406473636627 and batch: 1600, loss is 3.767114520072937 and perplexity is 43.255072947049634
At time: 918.0605847835541 and batch: 1650, loss is 3.734541001319885 and perplexity is 41.868803426461795
At time: 919.189483165741 and batch: 1700, loss is 3.7136198902130126 and perplexity is 41.00196081074295
At time: 920.3084008693695 and batch: 1750, loss is 3.7083252620697023 and perplexity is 40.78544436793107
At time: 921.429251909256 and batch: 1800, loss is 3.659467267990112 and perplexity is 38.84064570354907
At time: 922.548702955246 and batch: 1850, loss is 3.699203791618347 and perplexity is 40.4151126946582
At time: 923.665765285492 and batch: 1900, loss is 3.8032171535491943 and perplexity is 44.84522664627121
At time: 924.7842891216278 and batch: 1950, loss is 3.762059564590454 and perplexity is 43.03697218814371
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333515681776889 and perplexity of 76.21175240042173
Finished Training.
Improved accuracyfrom -10000000 to -76.21175240042173
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5dd8c64b38>
ELAPSED
958.4767999649048


RESULTS SO FAR:
[{'best_accuracy': -76.21175240042173, 'params': {'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.1541901093865481, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2553724200355174, 'num_layers': 2}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.7301366329193115 and batch: 50, loss is 7.7127502918243405 and perplexity is 2236.6853440894192
At time: 2.9108591079711914 and batch: 100, loss is 6.92301872253418 and perplexity is 1015.3805248359748
At time: 4.0909810066223145 and batch: 150, loss is 6.4700420951843265 and perplexity is 645.5108992934362
At time: 5.271728038787842 and batch: 200, loss is 6.273844480514526 and perplexity is 530.5130093247989
At time: 6.451651573181152 and batch: 250, loss is 6.116374788284301 and perplexity is 453.21869902367007
At time: 7.631133317947388 and batch: 300, loss is 5.9863025569915775 and perplexity is 397.9405240238439
At time: 8.810027122497559 and batch: 350, loss is 5.88675332069397 and perplexity is 360.2338200279732
At time: 9.991706848144531 and batch: 400, loss is 5.798099966049194 and perplexity is 329.672575366468
At time: 11.16988468170166 and batch: 450, loss is 5.686010036468506 and perplexity is 294.71536804050834
At time: 12.355084419250488 and batch: 500, loss is 5.646325435638428 and perplexity is 283.2487354984334
At time: 13.540011405944824 and batch: 550, loss is 5.586111822128296 and perplexity is 266.69663718498634
At time: 14.726794242858887 and batch: 600, loss is 5.583095092773437 and perplexity is 265.89329794851926
At time: 15.912925720214844 and batch: 650, loss is 5.631139411926269 and perplexity is 278.979809529868
At time: 17.09897518157959 and batch: 700, loss is 5.560956649780273 and perplexity is 260.071514712327
At time: 18.286542892456055 and batch: 750, loss is 5.475012722015381 and perplexity is 238.65350306488338
At time: 19.4740309715271 and batch: 800, loss is 5.478938732147217 and perplexity is 239.59230079476322
At time: 20.661171913146973 and batch: 850, loss is 5.480780811309814 and perplexity is 240.0340555282552
At time: 21.848317623138428 and batch: 900, loss is 5.4711996364593505 and perplexity is 237.7452296021571
At time: 23.035270929336548 and batch: 950, loss is 5.48022123336792 and perplexity is 239.899775339098
At time: 24.222994565963745 and batch: 1000, loss is 5.442923374176026 and perplexity is 231.1168378419631
At time: 25.410823106765747 and batch: 1050, loss is 5.3418455410003665 and perplexity is 208.89788436297926
At time: 26.598695039749146 and batch: 1100, loss is 5.415466480255127 and perplexity is 224.85741276077425
At time: 27.78549885749817 and batch: 1150, loss is 5.308255157470703 and perplexity is 201.99746694992083
At time: 28.972431182861328 and batch: 1200, loss is 5.381542205810547 and perplexity is 217.35722665460494
At time: 30.158593893051147 and batch: 1250, loss is 5.3440335178375244 and perplexity is 209.3554484826052
At time: 31.345348834991455 and batch: 1300, loss is 5.350614929199219 and perplexity is 210.73784688628567
At time: 32.53225040435791 and batch: 1350, loss is 5.285811815261841 and perplexity is 197.51446363641747
At time: 33.71879601478577 and batch: 1400, loss is 5.283461084365845 and perplexity is 197.05070558309146
At time: 34.90373253822327 and batch: 1450, loss is 5.258652849197388 and perplexity is 192.22236428252845
At time: 36.09649467468262 and batch: 1500, loss is 5.199020900726318 and perplexity is 181.09484521343546
At time: 37.29289102554321 and batch: 1550, loss is 5.188545227050781 and perplexity is 179.20765675415527
At time: 38.48098564147949 and batch: 1600, loss is 5.227167921066284 and perplexity is 186.26453995149672
At time: 39.66677260398865 and batch: 1650, loss is 5.210525970458985 and perplexity is 183.19038559000543
At time: 40.85252666473389 and batch: 1700, loss is 5.219905405044556 and perplexity is 184.91669105716963
At time: 42.040045738220215 and batch: 1750, loss is 5.209740200042725 and perplexity is 183.0464965437469
At time: 43.22928833961487 and batch: 1800, loss is 5.17372992515564 and perplexity is 176.57221187815745
At time: 44.41587424278259 and batch: 1850, loss is 5.171783666610718 and perplexity is 176.2288909060544
At time: 45.608015298843384 and batch: 1900, loss is 5.232983064651489 and perplexity is 187.35085046072973
At time: 46.79335856437683 and batch: 1950, loss is 5.154370574951172 and perplexity is 173.18676435786355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.812134356831395 and perplexity of 122.9938503331927
finished 1 epochs...
Completing Train Step...
At time: 50.53241181373596 and batch: 50, loss is 5.0631374168395995 and perplexity is 158.08571988683406
At time: 51.68001842498779 and batch: 100, loss is 4.997948427200317 and perplexity is 148.1089908206194
At time: 52.7989764213562 and batch: 150, loss is 4.9300054168701175 and perplexity is 138.38026192583612
At time: 53.91784048080444 and batch: 200, loss is 4.899332065582275 and perplexity is 134.20011286824533
At time: 55.03636455535889 and batch: 250, loss is 4.915024366378784 and perplexity is 136.32263145095092
At time: 56.15297722816467 and batch: 300, loss is 4.92867506980896 and perplexity is 138.19629055108277
At time: 57.27147173881531 and batch: 350, loss is 4.922843761444092 and perplexity is 137.39277042971852
At time: 58.415118932724 and batch: 400, loss is 4.864039335250855 and perplexity is 129.54642812808802
At time: 59.53394055366516 and batch: 450, loss is 4.837251224517822 and perplexity is 126.12219322581203
At time: 60.65389966964722 and batch: 500, loss is 4.829373846054077 and perplexity is 125.13258385820937
At time: 61.7736234664917 and batch: 550, loss is 4.799156312942505 and perplexity is 121.40794398599859
At time: 62.89177417755127 and batch: 600, loss is 4.766828069686889 and perplexity is 117.54580291700982
At time: 64.00878882408142 and batch: 650, loss is 4.834497318267823 and perplexity is 125.77534234623604
At time: 65.12819004058838 and batch: 700, loss is 4.854811277389526 and perplexity is 128.35646516161353
At time: 66.24767327308655 and batch: 750, loss is 4.794471845626831 and perplexity is 120.84054246507183
At time: 67.36630368232727 and batch: 800, loss is 4.791179056167603 and perplexity is 120.44329438666688
At time: 68.48572206497192 and batch: 850, loss is 4.789503860473633 and perplexity is 120.24169720305457
At time: 69.60393786430359 and batch: 900, loss is 4.767485151290893 and perplexity is 117.62306548285993
At time: 70.72702550888062 and batch: 950, loss is 4.815637369155883 and perplexity is 123.42545482331535
At time: 71.85036134719849 and batch: 1000, loss is 4.7894313621521 and perplexity is 120.23298019781704
At time: 72.97380352020264 and batch: 1050, loss is 4.711253623962403 and perplexity is 111.19146485420032
At time: 74.09291219711304 and batch: 1100, loss is 4.766472206115723 and perplexity is 117.50398008985982
At time: 75.21613883972168 and batch: 1150, loss is 4.705733213424683 and perplexity is 110.57933348270589
At time: 76.33921313285828 and batch: 1200, loss is 4.77881308555603 and perplexity is 118.96306723329707
At time: 77.45938897132874 and batch: 1250, loss is 4.760389461517334 and perplexity is 116.79140279960959
At time: 78.58058619499207 and batch: 1300, loss is 4.757776708602905 and perplexity is 116.48665401157014
At time: 79.70103526115417 and batch: 1350, loss is 4.652482109069824 and perplexity is 104.8448993521106
At time: 80.81715202331543 and batch: 1400, loss is 4.652015380859375 and perplexity is 104.79597669754082
At time: 81.93609237670898 and batch: 1450, loss is 4.611736984252929 and perplexity is 100.65884069586458
At time: 83.0548415184021 and batch: 1500, loss is 4.58469822883606 and perplexity is 97.97361706817722
At time: 84.16831970214844 and batch: 1550, loss is 4.592525987625122 and perplexity is 98.74354036586877
At time: 85.28223061561584 and batch: 1600, loss is 4.65397050857544 and perplexity is 105.00106663929888
At time: 86.3994345664978 and batch: 1650, loss is 4.625872802734375 and perplexity is 102.0918402453375
At time: 87.51848363876343 and batch: 1700, loss is 4.639572076797485 and perplexity is 103.50004803353949
At time: 88.63548636436462 and batch: 1750, loss is 4.628498506546021 and perplexity is 102.36025541456239
At time: 89.75233817100525 and batch: 1800, loss is 4.5860995674133305 and perplexity is 98.11100752011644
At time: 90.86620116233826 and batch: 1850, loss is 4.61909161567688 and perplexity is 101.40187840370567
At time: 91.98204469680786 and batch: 1900, loss is 4.718686962127686 and perplexity is 112.02106815455149
At time: 93.09834432601929 and batch: 1950, loss is 4.639022808074952 and perplexity is 103.44321430429775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.551343908975291 and perplexity of 94.75967115349334
finished 2 epochs...
Completing Train Step...
At time: 96.6999659538269 and batch: 50, loss is 4.620490274429321 and perplexity is 101.54380425823146
At time: 97.8387200832367 and batch: 100, loss is 4.559793615341187 and perplexity is 95.56375490172469
At time: 98.95354771614075 and batch: 150, loss is 4.511072454452514 and perplexity is 91.01938032557237
At time: 100.06957483291626 and batch: 200, loss is 4.505849952697754 and perplexity is 90.54527054926697
At time: 101.18685007095337 and batch: 250, loss is 4.508271503448486 and perplexity is 90.7647962061272
At time: 102.30330610275269 and batch: 300, loss is 4.526665477752686 and perplexity is 92.4497707168469
At time: 103.41953134536743 and batch: 350, loss is 4.537139644622803 and perplexity is 93.42319404225384
At time: 104.53688359260559 and batch: 400, loss is 4.48028715133667 and perplexity is 88.26001301793339
At time: 105.65566492080688 and batch: 450, loss is 4.485092868804932 and perplexity is 88.68518651782172
At time: 106.77149248123169 and batch: 500, loss is 4.484062452316284 and perplexity is 88.59385090427739
At time: 107.88911175727844 and batch: 550, loss is 4.460415201187134 and perplexity is 86.52342626868875
At time: 109.00671434402466 and batch: 600, loss is 4.432510442733765 and perplexity is 84.14238662888445
At time: 110.12463569641113 and batch: 650, loss is 4.495339899063111 and perplexity is 89.59861829642102
At time: 111.24138331413269 and batch: 700, loss is 4.533657341003418 and perplexity is 93.09843190387492
At time: 112.35630679130554 and batch: 750, loss is 4.476639709472656 and perplexity is 87.93867613658104
At time: 113.49524974822998 and batch: 800, loss is 4.473411417007446 and perplexity is 87.65524212111639
At time: 114.61046624183655 and batch: 850, loss is 4.472818155288696 and perplexity is 87.60325504401429
At time: 115.72812628746033 and batch: 900, loss is 4.442456064224243 and perplexity is 84.98341027652927
At time: 116.84519648551941 and batch: 950, loss is 4.509106407165527 and perplexity is 90.8406077151077
At time: 117.9637508392334 and batch: 1000, loss is 4.489207534790039 and perplexity is 89.05084821013115
At time: 119.07912969589233 and batch: 1050, loss is 4.42593581199646 and perplexity is 83.59099608823104
At time: 120.19544863700867 and batch: 1100, loss is 4.46456657409668 and perplexity is 86.88336387723317
At time: 121.31341242790222 and batch: 1150, loss is 4.428664016723633 and perplexity is 83.81936081011976
At time: 122.43121147155762 and batch: 1200, loss is 4.489531002044678 and perplexity is 89.0796579027698
At time: 123.5486969947815 and batch: 1250, loss is 4.484801702499389 and perplexity is 88.65936813861043
At time: 124.66586494445801 and batch: 1300, loss is 4.474880180358887 and perplexity is 87.78408152243925
At time: 125.78283190727234 and batch: 1350, loss is 4.353214406967163 and perplexity is 77.72791093522025
At time: 126.89702343940735 and batch: 1400, loss is 4.369264545440674 and perplexity is 78.98552007209537
At time: 128.02071857452393 and batch: 1450, loss is 4.3258453416824345 and perplexity is 75.62941854476553
At time: 129.13777947425842 and batch: 1500, loss is 4.306172280311585 and perplexity is 74.15609625019297
At time: 130.25504207611084 and batch: 1550, loss is 4.321625471115112 and perplexity is 75.31094461939364
At time: 131.37197613716125 and batch: 1600, loss is 4.4023824882507325 and perplexity is 81.645155754026
At time: 132.48704957962036 and batch: 1650, loss is 4.365154571533203 and perplexity is 78.6615578397197
At time: 133.60179567337036 and batch: 1700, loss is 4.368939399719238 and perplexity is 78.9598424429004
At time: 134.71848893165588 and batch: 1750, loss is 4.35977313041687 and perplexity is 78.23938227340827
At time: 135.8371081352234 and batch: 1800, loss is 4.319225177764893 and perplexity is 75.13039303489472
At time: 136.9545133113861 and batch: 1850, loss is 4.361651659011841 and perplexity is 78.38649532503692
At time: 138.07075881958008 and batch: 1900, loss is 4.463102655410767 and perplexity is 86.75626674998607
At time: 139.18727135658264 and batch: 1950, loss is 4.385580320358276 and perplexity is 80.28480060093949
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.469608182685319 and perplexity of 87.32250184147223
finished 3 epochs...
Completing Train Step...
At time: 142.7719111442566 and batch: 50, loss is 4.3752622270584105 and perplexity is 79.46067355920852
At time: 143.91720604896545 and batch: 100, loss is 4.322231111526489 and perplexity is 75.35656978570172
At time: 145.03630757331848 and batch: 150, loss is 4.278518257141113 and perplexity is 72.13347751624553
At time: 146.15453171730042 and batch: 200, loss is 4.278802108764649 and perplexity is 72.15395562718483
At time: 147.2727665901184 and batch: 250, loss is 4.278417315483093 and perplexity is 72.12619661090582
At time: 148.3862771987915 and batch: 300, loss is 4.295274095535278 and perplexity is 73.3523172325118
At time: 149.502281665802 and batch: 350, loss is 4.30742769241333 and perplexity is 74.24925117251725
At time: 150.6347258090973 and batch: 400, loss is 4.246253862380981 and perplexity is 69.8432791243167
At time: 151.7541205883026 and batch: 450, loss is 4.2696114349365235 and perplexity is 71.49385020890435
At time: 152.8713173866272 and batch: 500, loss is 4.273805675506591 and perplexity is 71.79434234359938
At time: 153.98925256729126 and batch: 550, loss is 4.2530284595489505 and perplexity is 70.31804556517781
At time: 155.10459876060486 and batch: 600, loss is 4.230658168792725 and perplexity is 68.76247459852853
At time: 156.22173690795898 and batch: 650, loss is 4.288225450515747 and perplexity is 72.83710070931036
At time: 157.34002685546875 and batch: 700, loss is 4.332980804443359 and perplexity is 76.17099936142414
At time: 158.45860505104065 and batch: 750, loss is 4.278116607666016 and perplexity is 72.1045109604546
At time: 159.57671213150024 and batch: 800, loss is 4.274352426528931 and perplexity is 71.8336067066111
At time: 160.69517254829407 and batch: 850, loss is 4.272011861801148 and perplexity is 71.66567210804871
At time: 161.81198382377625 and batch: 900, loss is 4.237841429710389 and perplexity is 69.25819169599
At time: 162.92810535430908 and batch: 950, loss is 4.317388105392456 and perplexity is 74.99249976425949
At time: 164.04489421844482 and batch: 1000, loss is 4.296310386657715 and perplexity is 73.42837098777952
At time: 165.16669487953186 and batch: 1050, loss is 4.239879598617554 and perplexity is 69.39949554050621
At time: 166.28382468223572 and batch: 1100, loss is 4.270797076225281 and perplexity is 71.57866654054081
At time: 167.40322065353394 and batch: 1150, loss is 4.243578734397889 and perplexity is 69.65668910127096
At time: 168.52802658081055 and batch: 1200, loss is 4.299997353553772 and perplexity is 73.69959865731286
At time: 169.684401512146 and batch: 1250, loss is 4.304719200134278 and perplexity is 74.0484197469476
At time: 170.7997727394104 and batch: 1300, loss is 4.285696229934692 and perplexity is 72.65311238673851
At time: 171.91596627235413 and batch: 1350, loss is 4.167541389465332 and perplexity is 64.55653744977181
At time: 173.03347611427307 and batch: 1400, loss is 4.188341131210327 and perplexity is 65.91335860513307
At time: 174.15128016471863 and batch: 1450, loss is 4.136909532546997 and perplexity is 62.60903097936688
At time: 175.26886463165283 and batch: 1500, loss is 4.123713541030884 and perplexity is 61.78827002520261
At time: 176.3840720653534 and batch: 1550, loss is 4.146838006973266 and perplexity is 63.23373921045836
At time: 177.50083184242249 and batch: 1600, loss is 4.231221599578857 and perplexity is 68.80122841016806
At time: 178.6193606853485 and batch: 1650, loss is 4.188565163612366 and perplexity is 65.92812698742412
At time: 179.74451184272766 and batch: 1700, loss is 4.192415938377381 and perplexity is 66.1824907896687
At time: 180.86074304580688 and batch: 1750, loss is 4.183990249633789 and perplexity is 65.62720035926873
At time: 181.97939610481262 and batch: 1800, loss is 4.140412740707397 and perplexity is 62.828748080273115
At time: 183.09612941741943 and batch: 1850, loss is 4.186672372817993 and perplexity is 65.80345686002767
At time: 184.22311282157898 and batch: 1900, loss is 4.286459331512451 and perplexity is 72.70857525063795
At time: 185.34518814086914 and batch: 1950, loss is 4.210784258842469 and perplexity is 67.40938549169867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.437725404251453 and perplexity of 84.5823320894277
finished 4 epochs...
Completing Train Step...
At time: 188.9658064842224 and batch: 50, loss is 4.203412117958069 and perplexity is 66.91426130996899
At time: 190.0808346271515 and batch: 100, loss is 4.15612452507019 and perplexity is 63.82369555431938
At time: 191.20470356941223 and batch: 150, loss is 4.1156211185455325 and perplexity is 61.290270966624284
At time: 192.32161951065063 and batch: 200, loss is 4.117588925361633 and perplexity is 61.41099712351331
At time: 193.43992257118225 and batch: 250, loss is 4.118018155097961 and perplexity is 61.437362207550535
At time: 194.5588777065277 and batch: 300, loss is 4.131733422279358 and perplexity is 62.285797000303155
At time: 195.6813039779663 and batch: 350, loss is 4.143892555236817 and perplexity is 63.047761312417215
At time: 196.79747676849365 and batch: 400, loss is 4.087349801063538 and perplexity is 59.58177871466771
At time: 197.93771529197693 and batch: 450, loss is 4.117852435112 and perplexity is 61.427181652332024
At time: 199.05784821510315 and batch: 500, loss is 4.128123316764832 and perplexity is 62.0613440941847
At time: 200.17485451698303 and batch: 550, loss is 4.1041187572479245 and perplexity is 60.58932710882979
At time: 201.2986204624176 and batch: 600, loss is 4.085510020256042 and perplexity is 59.472262075908006
At time: 202.41360330581665 and batch: 650, loss is 4.139460945129395 and perplexity is 62.76897640539915
At time: 203.5304617881775 and batch: 700, loss is 4.184134349822998 and perplexity is 65.63665793266048
At time: 204.64996027946472 and batch: 750, loss is 4.135979809761047 and perplexity is 62.55084898741193
At time: 205.766371011734 and batch: 800, loss is 4.130847721099854 and perplexity is 62.23065481978557
At time: 206.883118391037 and batch: 850, loss is 4.1262210178375245 and perplexity is 61.94339708668831
At time: 207.99977135658264 and batch: 900, loss is 4.092300577163696 and perplexity is 59.87748614739178
At time: 209.11610078811646 and batch: 950, loss is 4.173323636054993 and perplexity is 64.93090055512653
At time: 210.24079251289368 and batch: 1000, loss is 4.156793103218079 and perplexity is 63.86638095015593
At time: 211.36160516738892 and batch: 1050, loss is 4.102941865921021 and perplexity is 60.51806199912284
At time: 212.4813780784607 and batch: 1100, loss is 4.134439520835876 and perplexity is 62.454576770005445
At time: 213.59605979919434 and batch: 1150, loss is 4.110918598175049 and perplexity is 61.0027288351414
At time: 214.71662259101868 and batch: 1200, loss is 4.16561288356781 and perplexity is 64.43215975668178
At time: 215.83597111701965 and batch: 1250, loss is 4.168584895133972 and perplexity is 64.62393772271585
At time: 216.9526879787445 and batch: 1300, loss is 4.148682951927185 and perplexity is 63.3505096629385
At time: 218.06811594963074 and batch: 1350, loss is 4.033503832817078 and perplexity is 56.458385831208005
At time: 219.1835434436798 and batch: 1400, loss is 4.059119753837585 and perplexity is 57.92330186773824
At time: 220.30647563934326 and batch: 1450, loss is 4.001594595909118 and perplexity is 54.68528147108709
At time: 221.42549848556519 and batch: 1500, loss is 3.989184331893921 and perplexity is 54.01081649095699
At time: 222.54154348373413 and batch: 1550, loss is 4.017148633003234 and perplexity is 55.542507750072666
At time: 223.65745282173157 and batch: 1600, loss is 4.105654196739197 and perplexity is 60.682429812915224
At time: 224.77573418617249 and batch: 1650, loss is 4.061259093284607 and perplexity is 58.04735211780988
At time: 225.90107893943787 and batch: 1700, loss is 4.061576805114746 and perplexity is 58.06579737826951
At time: 227.0190567970276 and batch: 1750, loss is 4.054151248931885 and perplexity is 57.636223424150614
At time: 228.1375195980072 and batch: 1800, loss is 4.012497925758362 and perplexity is 55.28479554340064
At time: 229.2529058456421 and batch: 1850, loss is 4.0565499639511104 and perplexity is 57.774642246213375
At time: 230.36909914016724 and batch: 1900, loss is 4.153331961631775 and perplexity is 63.64571246580807
At time: 231.4855797290802 and batch: 1950, loss is 4.081593542098999 and perplexity is 59.23979578226453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4383976426235465 and perplexity of 84.63921069450782
Annealing...
finished 5 epochs...
Completing Train Step...
At time: 235.11440753936768 and batch: 50, loss is 4.1165051984786984 and perplexity is 61.3444804245003
At time: 236.23295950889587 and batch: 100, loss is 4.097674107551574 and perplexity is 60.20010566534803
At time: 237.35157942771912 and batch: 150, loss is 4.057522263526916 and perplexity is 57.83084382431939
At time: 238.47154092788696 and batch: 200, loss is 4.060831160545349 and perplexity is 58.02251706965549
At time: 239.58761072158813 and batch: 250, loss is 4.058989200592041 and perplexity is 57.91574028629202
At time: 240.7048442363739 and batch: 300, loss is 4.068648314476013 and perplexity is 58.47786546249354
At time: 241.82303738594055 and batch: 350, loss is 4.080902113914489 and perplexity is 59.19884987502448
At time: 242.9431848526001 and batch: 400, loss is 4.014000306129455 and perplexity is 55.36791675925178
At time: 244.0623869895935 and batch: 450, loss is 4.035788912773132 and perplexity is 56.58754527064368
At time: 245.18252992630005 and batch: 500, loss is 4.045099258422852 and perplexity is 57.11685508174355
At time: 246.30000352859497 and batch: 550, loss is 4.014993176460266 and perplexity is 55.42291722072579
At time: 247.41615772247314 and batch: 600, loss is 3.9814370584487917 and perplexity is 53.59399662016555
At time: 248.53626418113708 and batch: 650, loss is 4.028198065757752 and perplexity is 56.15962406847565
At time: 249.65630555152893 and batch: 700, loss is 4.0795683097839355 and perplexity is 59.11994283950027
At time: 250.77246975898743 and batch: 750, loss is 4.018125305175781 and perplexity is 55.59678107109257
At time: 251.8906910419464 and batch: 800, loss is 4.010381197929382 and perplexity is 55.16789644359088
At time: 253.0320909023285 and batch: 850, loss is 4.0047543382644655 and perplexity is 54.85834614706943
At time: 254.14820885658264 and batch: 900, loss is 3.9614364194869993 and perplexity is 52.53273081787443
At time: 255.28201246261597 and batch: 950, loss is 4.047139701843261 and perplexity is 57.23351777422502
At time: 256.40150213241577 and batch: 1000, loss is 4.011473517417908 and perplexity is 55.2281903361191
At time: 257.51817440986633 and batch: 1050, loss is 3.9596843194961546 and perplexity is 52.44076880753395
At time: 258.63658118247986 and batch: 1100, loss is 3.9801655054092406 and perplexity is 53.52589231915315
At time: 259.75528025627136 and batch: 1150, loss is 3.958213334083557 and perplexity is 52.36368590940134
At time: 260.871356010437 and batch: 1200, loss is 3.991397876739502 and perplexity is 54.1305042736731
At time: 261.9889807701111 and batch: 1250, loss is 3.9847836303710937 and perplexity is 53.77365323367511
At time: 263.1088819503784 and batch: 1300, loss is 3.971061282157898 and perplexity is 53.040792226223076
At time: 264.2287709712982 and batch: 1350, loss is 3.8551831960678102 and perplexity is 47.237269830749945
At time: 265.347220659256 and batch: 1400, loss is 3.8679558753967287 and perplexity is 47.84448596399983
At time: 266.4664535522461 and batch: 1450, loss is 3.800000147819519 and perplexity is 44.70119110100891
At time: 267.58456683158875 and batch: 1500, loss is 3.7945417499542238 and perplexity is 44.45785892100806
At time: 268.7026891708374 and batch: 1550, loss is 3.817509636878967 and perplexity is 45.49077858152582
At time: 269.8229398727417 and batch: 1600, loss is 3.8971619462966918 and perplexity is 49.26244107102925
At time: 270.9485864639282 and batch: 1650, loss is 3.844686756134033 and perplexity is 46.74403977364032
At time: 272.0687029361725 and batch: 1700, loss is 3.8296708822250367 and perplexity is 46.04738072856075
At time: 273.19686675071716 and batch: 1750, loss is 3.809934391975403 and perplexity is 45.147476732385954
At time: 274.3138301372528 and batch: 1800, loss is 3.7628115367889405 and perplexity is 43.06934696567698
At time: 275.43327140808105 and batch: 1850, loss is 3.7946884298324584 and perplexity is 44.464380472619666
At time: 276.5588049888611 and batch: 1900, loss is 3.8873680067062377 and perplexity is 48.78232266223774
At time: 277.67852210998535 and batch: 1950, loss is 3.805758490562439 and perplexity is 44.95933841743369
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347600608648256 and perplexity of 77.29278461791439
finished 6 epochs...
Completing Train Step...
At time: 281.32189869880676 and batch: 50, loss is 4.0200287628173825 and perplexity is 55.70270797057149
At time: 282.43982100486755 and batch: 100, loss is 3.988123965263367 and perplexity is 53.95357557700189
At time: 283.5588917732239 and batch: 150, loss is 3.9442999267578127 and perplexity is 51.64017355093835
At time: 284.67680859565735 and batch: 200, loss is 3.9447296237945557 and perplexity is 51.66236794858204
At time: 285.80182552337646 and batch: 250, loss is 3.94430392742157 and perplexity is 51.64038014632235
At time: 286.92561316490173 and batch: 300, loss is 3.950874853134155 and perplexity is 51.98082253391159
At time: 288.0433416366577 and batch: 350, loss is 3.967578773498535 and perplexity is 52.85639847077935
At time: 289.16187024116516 and batch: 400, loss is 3.9046309089660642 and perplexity is 49.63175789430162
At time: 290.2802543640137 and batch: 450, loss is 3.934592800140381 and perplexity is 51.14132097744372
At time: 291.40031695365906 and batch: 500, loss is 3.947627511024475 and perplexity is 51.81229679845527
At time: 292.5237560272217 and batch: 550, loss is 3.918061685562134 and perplexity is 50.30284748595409
At time: 293.64276123046875 and batch: 600, loss is 3.8886623620986938 and perplexity is 48.84550520614424
At time: 294.7588324546814 and batch: 650, loss is 3.9354113054275515 and perplexity is 51.1831975548187
At time: 295.8811640739441 and batch: 700, loss is 3.989095759391785 and perplexity is 54.00603282965152
At time: 296.9997217655182 and batch: 750, loss is 3.9309131860733033 and perplexity is 50.95348644459389
At time: 298.12290120124817 and batch: 800, loss is 3.925159049034119 and perplexity is 50.661135022688214
At time: 299.24087262153625 and batch: 850, loss is 3.9247601556777956 and perplexity is 50.6409306624643
At time: 300.357519865036 and batch: 900, loss is 3.8800060081481935 and perplexity is 48.42450601207948
At time: 301.4834580421448 and batch: 950, loss is 3.969085121154785 and perplexity is 52.936078580640256
At time: 302.6008439064026 and batch: 1000, loss is 3.9358570098876955 and perplexity is 51.2060152188429
At time: 303.71859884262085 and batch: 1050, loss is 3.887785110473633 and perplexity is 48.80267419685827
At time: 304.83712434768677 and batch: 1100, loss is 3.908317904472351 and perplexity is 49.81508772307334
At time: 305.9559359550476 and batch: 1150, loss is 3.889816746711731 and perplexity is 48.9019242641511
At time: 307.07389283180237 and batch: 1200, loss is 3.927136950492859 and perplexity is 50.76143691648284
At time: 308.1921169757843 and batch: 1250, loss is 3.92398090839386 and perplexity is 50.6014842260499
At time: 309.3092894554138 and batch: 1300, loss is 3.9120327615737915 and perplexity is 50.00048780966184
At time: 310.43200039863586 and batch: 1350, loss is 3.7959516429901123 and perplexity is 44.520583954094576
At time: 311.5538430213928 and batch: 1400, loss is 3.8128497648239135 and perplexity is 45.279290510023024
At time: 312.6727046966553 and batch: 1450, loss is 3.7458651208877565 and perplexity is 42.34562546204274
At time: 313.79142332077026 and batch: 1500, loss is 3.744467797279358 and perplexity is 42.28649624082148
At time: 314.9097807407379 and batch: 1550, loss is 3.769708218574524 and perplexity is 43.36740918512826
At time: 316.02786135673523 and batch: 1600, loss is 3.854534468650818 and perplexity is 47.20663565639563
At time: 317.144850730896 and batch: 1650, loss is 3.8046236419677735 and perplexity is 44.90834531561129
At time: 318.26112389564514 and batch: 1700, loss is 3.796268482208252 and perplexity is 44.534692055987676
At time: 319.37814378738403 and batch: 1750, loss is 3.7783399295806883 and perplexity is 43.74336436226677
At time: 320.4950976371765 and batch: 1800, loss is 3.734974493980408 and perplexity is 41.886957179927194
At time: 321.60913920402527 and batch: 1850, loss is 3.7721667957305907 and perplexity is 43.47416248350555
At time: 322.7248201370239 and batch: 1900, loss is 3.866335735321045 and perplexity is 47.767033953383915
At time: 323.83754324913025 and batch: 1950, loss is 3.788956446647644 and perplexity is 44.21024045042153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.34842529296875 and perplexity of 77.35655305627765
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 327.40828561782837 and batch: 50, loss is 3.9849626064300536 and perplexity is 53.783278291508516
At time: 328.54303431510925 and batch: 100, loss is 3.9811258363723754 and perplexity is 53.57731958052003
At time: 329.657018661499 and batch: 150, loss is 3.9533537006378174 and perplexity is 52.10983490101847
At time: 330.76857352256775 and batch: 200, loss is 3.9555927991867064 and perplexity is 52.22664468223123
At time: 331.8814465999603 and batch: 250, loss is 3.9589967727661133 and perplexity is 52.40472572049266
At time: 332.9983808994293 and batch: 300, loss is 3.961816258430481 and perplexity is 52.552688584975115
At time: 334.1119554042816 and batch: 350, loss is 3.983572020530701 and perplexity is 53.708540000146066
At time: 335.22478342056274 and batch: 400, loss is 3.922462477684021 and perplexity is 50.524707683119466
At time: 336.3387415409088 and batch: 450, loss is 3.9499482488632203 and perplexity is 51.93267919010359
At time: 337.4917767047882 and batch: 500, loss is 3.9581477355957033 and perplexity is 52.36025104344948
At time: 338.60595178604126 and batch: 550, loss is 3.9323686456680296 and perplexity is 51.027701180498006
At time: 339.7205271720886 and batch: 600, loss is 3.892202591896057 and perplexity is 49.01873597658162
At time: 340.83507108688354 and batch: 650, loss is 3.929701819419861 and perplexity is 50.891800459953885
At time: 341.95628929138184 and batch: 700, loss is 3.98588454246521 and perplexity is 53.83288589786053
At time: 343.07057428359985 and batch: 750, loss is 3.929078040122986 and perplexity is 50.86006510740324
At time: 344.1958031654358 and batch: 800, loss is 3.9169808292388915 and perplexity is 50.24850670774896
At time: 345.3141779899597 and batch: 850, loss is 3.906544313430786 and perplexity is 49.726814433250496
At time: 346.43289160728455 and batch: 900, loss is 3.865896439552307 and perplexity is 47.74605470586776
At time: 347.55169677734375 and batch: 950, loss is 3.961381812095642 and perplexity is 52.52986222080761
At time: 348.66976022720337 and batch: 1000, loss is 3.925047240257263 and perplexity is 50.65547097979796
At time: 349.78883242607117 and batch: 1050, loss is 3.8688581371307373 and perplexity is 47.88767369325636
At time: 350.9061062335968 and batch: 1100, loss is 3.885516996383667 and perplexity is 48.6921095978453
At time: 352.02185106277466 and batch: 1150, loss is 3.8678542137145997 and perplexity is 47.83962226030647
At time: 353.1389856338501 and batch: 1200, loss is 3.8960466146469117 and perplexity is 49.20752774033768
At time: 354.25811886787415 and batch: 1250, loss is 3.893852458000183 and perplexity is 49.09967708016756
At time: 355.3745813369751 and batch: 1300, loss is 3.8809915828704833 and perplexity is 48.47225550762712
At time: 356.4921090602875 and batch: 1350, loss is 3.7653932571411133 and perplexity is 43.18068363352288
At time: 357.6098771095276 and batch: 1400, loss is 3.7751118040084837 and perplexity is 43.602382964410644
At time: 358.7252416610718 and batch: 1450, loss is 3.702457947731018 and perplexity is 40.54684400154886
At time: 359.8412597179413 and batch: 1500, loss is 3.699064950942993 and perplexity is 40.40950182263481
At time: 360.9585304260254 and batch: 1550, loss is 3.728898677825928 and perplexity is 41.63323130525067
At time: 362.0761876106262 and batch: 1600, loss is 3.809438166618347 and perplexity is 45.12507896725336
At time: 363.19315934181213 and batch: 1650, loss is 3.752090291976929 and perplexity is 42.61005643549563
At time: 364.3089723587036 and batch: 1700, loss is 3.7417527866363525 and perplexity is 42.171843665381566
At time: 365.42462491989136 and batch: 1750, loss is 3.717187452316284 and perplexity is 41.148499089073276
At time: 366.54023027420044 and batch: 1800, loss is 3.671747326850891 and perplexity is 39.32055172527888
At time: 367.6570074558258 and batch: 1850, loss is 3.70621376991272 and perplexity is 40.69941707696621
At time: 368.7751476764679 and batch: 1900, loss is 3.803412427902222 and perplexity is 44.853984623967314
At time: 369.8966476917267 and batch: 1950, loss is 3.726834149360657 and perplexity is 41.547366979290445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320874591206396 and perplexity of 75.2544163697919
finished 8 epochs...
Completing Train Step...
At time: 373.5146770477295 and batch: 50, loss is 3.9684479331970213 and perplexity is 52.9023590928041
At time: 374.66966581344604 and batch: 100, loss is 3.9464287996292113 and perplexity is 51.75022601777674
At time: 375.797869682312 and batch: 150, loss is 3.912413001060486 and perplexity is 50.01950358452618
At time: 376.91413617134094 and batch: 200, loss is 3.9104992628097532 and perplexity is 49.923870884398994
At time: 378.03526544570923 and batch: 250, loss is 3.912266130447388 and perplexity is 50.012157728826224
At time: 379.1542897224426 and batch: 300, loss is 3.9127447843551635 and perplexity is 50.03610197360543
At time: 380.2722203731537 and batch: 350, loss is 3.935646405220032 and perplexity is 51.19523212854979
At time: 381.39108991622925 and batch: 400, loss is 3.8748945426940917 and perplexity is 48.17761734146198
At time: 382.52085638046265 and batch: 450, loss is 3.9061047315597532 and perplexity is 49.70496023082893
At time: 383.6403090953827 and batch: 500, loss is 3.915113649368286 and perplexity is 50.154771245213645
At time: 384.7653112411499 and batch: 550, loss is 3.8899790143966673 and perplexity is 48.909860110038636
At time: 385.8842861652374 and batch: 600, loss is 3.852011342048645 and perplexity is 47.087677474557445
At time: 387.0037386417389 and batch: 650, loss is 3.891260542869568 and perplexity is 48.97257966824129
At time: 388.12600541114807 and batch: 700, loss is 3.9485993576049805 and perplexity is 51.862674877843965
At time: 389.2502384185791 and batch: 750, loss is 3.893747692108154 and perplexity is 49.0945333781469
At time: 390.37834882736206 and batch: 800, loss is 3.883236346244812 and perplexity is 48.58118646783506
At time: 391.4989812374115 and batch: 850, loss is 3.87554368019104 and perplexity is 48.20890139211858
At time: 392.6199278831482 and batch: 900, loss is 3.8340270137786865 and perplexity is 46.24840670663145
At time: 393.77068281173706 and batch: 950, loss is 3.930264463424683 and perplexity is 50.92044248325302
At time: 394.89209628105164 and batch: 1000, loss is 3.8953767251968383 and perplexity is 49.17457517516041
At time: 396.0165376663208 and batch: 1050, loss is 3.8414406061172484 and perplexity is 46.592547624295
At time: 397.1471679210663 and batch: 1100, loss is 3.858849368095398 and perplexity is 47.410767630123196
At time: 398.2746443748474 and batch: 1150, loss is 3.8430042934417723 and perplexity is 46.66546079227389
At time: 399.4027564525604 and batch: 1200, loss is 3.8738299131393434 and perplexity is 48.126353319601336
At time: 400.53272795677185 and batch: 1250, loss is 3.8737056493759154 and perplexity is 48.120373329373514
At time: 401.6524500846863 and batch: 1300, loss is 3.862016725540161 and perplexity is 47.56117254526184
At time: 402.7781174182892 and batch: 1350, loss is 3.7474804735183715 and perplexity is 42.4140838568659
At time: 403.9039695262909 and batch: 1400, loss is 3.7594960641860964 and perplexity is 42.926788181250004
At time: 405.02869296073914 and batch: 1450, loss is 3.689012622833252 and perplexity is 40.00532710346653
At time: 406.15408420562744 and batch: 1500, loss is 3.688409628868103 and perplexity is 39.981211404190596
At time: 407.2760605812073 and batch: 1550, loss is 3.7198897409439087 and perplexity is 41.259844586283826
At time: 408.39468002319336 and batch: 1600, loss is 3.8022105646133424 and perplexity is 44.8001086487514
At time: 409.5153479576111 and batch: 1650, loss is 3.745941987037659 and perplexity is 42.34888053233797
At time: 410.6361439228058 and batch: 1700, loss is 3.738841986656189 and perplexity is 42.049268346340924
At time: 411.7575640678406 and batch: 1750, loss is 3.7159981536865234 and perplexity is 41.09959032481793
At time: 412.87909293174744 and batch: 1800, loss is 3.6721494722366335 and perplexity is 39.336367483624024
At time: 414.0039322376251 and batch: 1850, loss is 3.7081623888015747 and perplexity is 40.77880205025751
At time: 415.1288502216339 and batch: 1900, loss is 3.805751419067383 and perplexity is 44.95902048881846
At time: 416.2502341270447 and batch: 1950, loss is 3.729894061088562 and perplexity is 41.67469295855585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31960335664971 and perplexity of 75.15881113637278
finished 9 epochs...
Completing Train Step...
At time: 419.8945143222809 and batch: 50, loss is 3.948907814025879 and perplexity is 51.878674720415226
At time: 421.0424258708954 and batch: 100, loss is 3.924845952987671 and perplexity is 50.645275704478514
At time: 422.16116166114807 and batch: 150, loss is 3.8903914499282837 and perplexity is 48.93003643462498
At time: 423.28180265426636 and batch: 200, loss is 3.887291135787964 and perplexity is 48.7785728644262
At time: 424.4037494659424 and batch: 250, loss is 3.8886904239654543 and perplexity is 48.846875921435505
At time: 425.5243661403656 and batch: 300, loss is 3.8888073205947875 and perplexity is 48.85258629033912
At time: 426.64445328712463 and batch: 350, loss is 3.9124008083343504 and perplexity is 50.018893714135544
At time: 427.7645890712738 and batch: 400, loss is 3.851039237976074 and perplexity is 47.04192559291466
At time: 428.8836979866028 and batch: 450, loss is 3.8839865350723266 and perplexity is 48.61764520490938
At time: 430.00275802612305 and batch: 500, loss is 3.8931372690200807 and perplexity is 49.06457408632667
At time: 431.13129806518555 and batch: 550, loss is 3.8680694818496706 and perplexity is 47.84992171510538
At time: 432.2515821456909 and batch: 600, loss is 3.8308939123153687 and perplexity is 46.10373251371294
At time: 433.37935614585876 and batch: 650, loss is 3.8709698295593262 and perplexity is 47.98890457784564
At time: 434.5006420612335 and batch: 700, loss is 3.9285291481018065 and perplexity is 50.83215608369005
At time: 435.6201603412628 and batch: 750, loss is 3.8740880250930787 and perplexity is 48.138776909952426
At time: 436.7391812801361 and batch: 800, loss is 3.864188175201416 and perplexity is 47.66456144854876
At time: 437.86693692207336 and batch: 850, loss is 3.8578078079223634 and perplexity is 47.361412170589084
At time: 438.98884654045105 and batch: 900, loss is 3.815707817077637 and perplexity is 45.408886195716526
At time: 440.1091058254242 and batch: 950, loss is 3.91249990940094 and perplexity is 50.02385088547866
At time: 441.2302026748657 and batch: 1000, loss is 3.8782711744308473 and perplexity is 48.34057037454234
At time: 442.3504981994629 and batch: 1050, loss is 3.8253895235061646 and perplexity is 45.85065679695345
At time: 443.4688458442688 and batch: 1100, loss is 3.8427570104599 and perplexity is 46.653922644631294
At time: 444.58844780921936 and batch: 1150, loss is 3.827674732208252 and perplexity is 45.9555549282738
At time: 445.71424317359924 and batch: 1200, loss is 3.859756155014038 and perplexity is 47.45377859195446
At time: 446.8353593349457 and batch: 1250, loss is 3.8604493236541746 and perplexity is 47.486683466126316
At time: 447.9541778564453 and batch: 1300, loss is 3.8491100454330445 and perplexity is 46.9512601445243
At time: 449.08109426498413 and batch: 1350, loss is 3.7349463081359864 and perplexity is 41.88577657730705
At time: 450.2105689048767 and batch: 1400, loss is 3.747915825843811 and perplexity is 42.43255294689331
At time: 451.3292796611786 and batch: 1450, loss is 3.6780224514007567 and perplexity is 39.56806887297922
At time: 452.4494912624359 and batch: 1500, loss is 3.678348240852356 and perplexity is 39.580961832519264
At time: 453.56978249549866 and batch: 1550, loss is 3.7104839944839476 and perplexity is 40.87358432978524
At time: 454.68880796432495 and batch: 1600, loss is 3.7936983060836793 and perplexity is 44.42037702156482
At time: 455.8176658153534 and batch: 1650, loss is 3.7374885749816893 and perplexity is 41.99239686959817
At time: 456.9332995414734 and batch: 1700, loss is 3.732167010307312 and perplexity is 41.769525152911065
At time: 458.0515069961548 and batch: 1750, loss is 3.7098580312728884 and perplexity is 40.848006975767156
At time: 459.1722152233124 and batch: 1800, loss is 3.666786093711853 and perplexity is 39.12595641650602
At time: 460.2907464504242 and batch: 1850, loss is 3.7036464500427244 and perplexity is 40.5950626676993
At time: 461.41818737983704 and batch: 1900, loss is 3.801406226158142 and perplexity is 44.76408868663035
At time: 462.5382423400879 and batch: 1950, loss is 3.7262466239929197 and perplexity is 41.5229640166092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.320366721929505 and perplexity of 75.21620666735564
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 466.20409321784973 and batch: 50, loss is 3.941896677017212 and perplexity is 51.51621832459
At time: 467.32370162010193 and batch: 100, loss is 3.9334967947006225 and perplexity is 51.085300516428795
At time: 468.4421820640564 and batch: 150, loss is 3.9107019090652466 and perplexity is 49.93398879503717
At time: 469.5617890357971 and batch: 200, loss is 3.9105654191970824 and perplexity is 49.9271737765907
At time: 470.68845224380493 and batch: 250, loss is 3.917120418548584 and perplexity is 50.25552135168663
At time: 471.80462312698364 and batch: 300, loss is 3.9106404066085814 and perplexity is 49.93091782649221
At time: 472.92251348495483 and batch: 350, loss is 3.943736629486084 and perplexity is 51.611092973339474
At time: 474.0429701805115 and batch: 400, loss is 3.8899362468719483 and perplexity is 48.90776840111631
At time: 475.16287326812744 and batch: 450, loss is 3.925782046318054 and perplexity is 50.692706605692514
At time: 476.2914209365845 and batch: 500, loss is 3.934196310043335 and perplexity is 51.121047969415365
At time: 477.4325530529022 and batch: 550, loss is 3.9121850061416628 and perplexity is 50.00810069181705
At time: 478.55767583847046 and batch: 600, loss is 3.8651425552368166 and perplexity is 47.71007326872316
At time: 479.6777000427246 and batch: 650, loss is 3.889959716796875 and perplexity is 48.908916276239225
At time: 480.79881715774536 and batch: 700, loss is 3.944035711288452 and perplexity is 51.62653122058245
At time: 481.9212372303009 and batch: 750, loss is 3.8892607164382933 and perplexity is 48.874740871925745
At time: 483.04313111305237 and batch: 800, loss is 3.8792721128463743 and perplexity is 48.3889805322102
At time: 484.1643068790436 and batch: 850, loss is 3.8688222646713255 and perplexity is 47.885955875436835
At time: 485.28298115730286 and batch: 900, loss is 3.8227456617355347 and perplexity is 45.729594105319904
At time: 486.4026460647583 and batch: 950, loss is 3.925864601135254 and perplexity is 50.6968917055674
At time: 487.52565479278564 and batch: 1000, loss is 3.8914950847625733 and perplexity is 48.984067136875694
At time: 488.6480209827423 and batch: 1050, loss is 3.8385996770858766 and perplexity is 46.460369346556384
At time: 489.76818799972534 and batch: 1100, loss is 3.850243821144104 and perplexity is 47.004522530974334
At time: 490.8891088962555 and batch: 1150, loss is 3.8327520656585694 and perplexity is 46.18947995969712
At time: 492.01152443885803 and batch: 1200, loss is 3.8615833377838134 and perplexity is 47.540564581345365
At time: 493.1301510334015 and batch: 1250, loss is 3.863864011764526 and perplexity is 47.64911284456332
At time: 494.24897480010986 and batch: 1300, loss is 3.8496261739730837 and perplexity is 46.975499284593596
At time: 495.3690376281738 and batch: 1350, loss is 3.733981795310974 and perplexity is 41.84539668520494
At time: 496.4877905845642 and batch: 1400, loss is 3.7458722400665283 and perplexity is 42.3459269291937
At time: 497.606764793396 and batch: 1450, loss is 3.66861891746521 and perplexity is 39.197733155762364
At time: 498.72459268569946 and batch: 1500, loss is 3.6687263298034667 and perplexity is 39.201943702063254
At time: 499.84301233291626 and batch: 1550, loss is 3.6996826839447023 and perplexity is 40.434471817094064
At time: 500.96267008781433 and batch: 1600, loss is 3.7797208881378173 and perplexity is 43.803813865122905
At time: 502.0825295448303 and batch: 1650, loss is 3.720869069099426 and perplexity is 41.30027130606086
At time: 503.20130038261414 and batch: 1700, loss is 3.717354669570923 and perplexity is 41.15538040344468
At time: 504.32138442993164 and batch: 1750, loss is 3.6924832534790037 and perplexity is 40.14441203430713
At time: 505.44025778770447 and batch: 1800, loss is 3.650942783355713 and perplexity is 38.51095642809441
At time: 506.5566711425781 and batch: 1850, loss is 3.6836118841171266 and perplexity is 39.78985117287746
At time: 507.67827916145325 and batch: 1900, loss is 3.784540696144104 and perplexity is 44.0154494496375
At time: 508.80201601982117 and batch: 1950, loss is 3.7198640441894533 and perplexity is 41.258784355810924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.304953215843023 and perplexity of 74.06575026810415
finished 11 epochs...
Completing Train Step...
At time: 512.4160444736481 and batch: 50, loss is 3.9436165952682494 and perplexity is 51.60489824795977
At time: 513.5389649868011 and batch: 100, loss is 3.9239363193511965 and perplexity is 50.599228004612655
At time: 514.6554887294769 and batch: 150, loss is 3.894139189720154 and perplexity is 49.113757533586615
At time: 515.7715635299683 and batch: 200, loss is 3.890906891822815 and perplexity is 48.95526352629576
At time: 516.8868334293365 and batch: 250, loss is 3.894696145057678 and perplexity is 49.141119321930546
At time: 518.0048582553864 and batch: 300, loss is 3.887554564476013 and perplexity is 48.791424232516
At time: 519.1225302219391 and batch: 350, loss is 3.9194340229034426 and perplexity is 50.37192735153118
At time: 520.2370736598969 and batch: 400, loss is 3.8649497604370118 and perplexity is 47.700875901329425
At time: 521.3541057109833 and batch: 450, loss is 3.9038055658340456 and perplexity is 49.59081156350436
At time: 522.472662448883 and batch: 500, loss is 3.912377963066101 and perplexity is 50.01775103214358
At time: 523.5915546417236 and batch: 550, loss is 3.889642367362976 and perplexity is 48.893397521910536
At time: 524.7106788158417 and batch: 600, loss is 3.84582573890686 and perplexity is 46.7973107612845
At time: 525.8293023109436 and batch: 650, loss is 3.8730208396911623 and perplexity is 48.087431312477115
At time: 526.9445195198059 and batch: 700, loss is 3.9284810495376585 and perplexity is 50.829711188768314
At time: 528.0697965621948 and batch: 750, loss is 3.8762529993057253 and perplexity is 48.24310901800119
At time: 529.1867895126343 and batch: 800, loss is 3.865717635154724 and perplexity is 47.73751826451847
At time: 530.305445432663 and batch: 850, loss is 3.8561046934127807 and perplexity is 47.28081891158215
At time: 531.4219386577606 and batch: 900, loss is 3.8110663223266603 and perplexity is 45.19860946546873
At time: 532.5805912017822 and batch: 950, loss is 3.9135186576843264 and perplexity is 50.07483856509238
At time: 533.6960122585297 and batch: 1000, loss is 3.8804568815231324 and perplexity is 48.446344255306165
At time: 534.8112666606903 and batch: 1050, loss is 3.8283620357513426 and perplexity is 45.987151200871956
At time: 535.9276094436646 and batch: 1100, loss is 3.8406406354904177 and perplexity is 46.55528985931209
At time: 537.0444884300232 and batch: 1150, loss is 3.82390727519989 and perplexity is 45.78274508202066
At time: 538.161116361618 and batch: 1200, loss is 3.8535023021697996 and perplexity is 47.15793568695111
At time: 539.2782781124115 and batch: 1250, loss is 3.8573895025253297 and perplexity is 47.34160477932515
At time: 540.3950846195221 and batch: 1300, loss is 3.844203329086304 and perplexity is 46.72144790169457
At time: 541.5152814388275 and batch: 1350, loss is 3.729264426231384 and perplexity is 41.64846137823223
At time: 542.6318824291229 and batch: 1400, loss is 3.742597370147705 and perplexity is 42.20747635445738
At time: 543.7492935657501 and batch: 1450, loss is 3.666254644393921 and perplexity is 39.10516847801216
At time: 544.8665494918823 and batch: 1500, loss is 3.6679470682144166 and perplexity is 39.17140703269216
At time: 545.9835910797119 and batch: 1550, loss is 3.7001494932174683 and perplexity is 40.45335140971929
At time: 547.0992300510406 and batch: 1600, loss is 3.7813010358810426 and perplexity is 43.87308507770825
At time: 548.2172396183014 and batch: 1650, loss is 3.7228105688095092 and perplexity is 41.38053366028477
At time: 549.3462810516357 and batch: 1700, loss is 3.7206789159774782 and perplexity is 41.292418677159326
At time: 550.4652442932129 and batch: 1750, loss is 3.696556272506714 and perplexity is 40.30825442846857
At time: 551.5836560726166 and batch: 1800, loss is 3.6556670093536376 and perplexity is 38.693321316958595
At time: 552.7008607387543 and batch: 1850, loss is 3.688623948097229 and perplexity is 39.989781064887005
At time: 553.8242461681366 and batch: 1900, loss is 3.789445648193359 and perplexity is 44.2318734594056
At time: 554.9421157836914 and batch: 1950, loss is 3.723638572692871 and perplexity is 41.41481109181593
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.30377679869186 and perplexity of 73.97866928100146
finished 12 epochs...
Completing Train Step...
At time: 558.5549194812775 and batch: 50, loss is 3.9382244634628294 and perplexity is 51.327386696621666
At time: 559.6712160110474 and batch: 100, loss is 3.917241735458374 and perplexity is 50.26161856607703
At time: 560.8135259151459 and batch: 150, loss is 3.8866562700271605 and perplexity is 48.747614846786256
At time: 561.9305567741394 and batch: 200, loss is 3.8825570487976075 and perplexity is 48.548196598121024
At time: 563.055148601532 and batch: 250, loss is 3.8855462074279785 and perplexity is 48.69353196599071
At time: 564.1747903823853 and batch: 300, loss is 3.87834059715271 and perplexity is 48.34392642500586
At time: 565.2938964366913 and batch: 350, loss is 3.910273790359497 and perplexity is 49.91261569581957
At time: 566.4131555557251 and batch: 400, loss is 3.8552819061279298 and perplexity is 47.24193285463472
At time: 567.5312778949738 and batch: 450, loss is 3.8948354005813597 and perplexity is 49.14796297073291
At time: 568.6493334770203 and batch: 500, loss is 3.903101305961609 and perplexity is 49.55589904006626
At time: 569.7667202949524 and batch: 550, loss is 3.8803643226623534 and perplexity is 48.44186032438996
At time: 570.8868772983551 and batch: 600, loss is 3.8373859882354737 and perplexity is 46.40401511946109
At time: 572.0110173225403 and batch: 650, loss is 3.864971480369568 and perplexity is 47.70191197238852
At time: 573.129184961319 and batch: 700, loss is 3.9207638549804686 and perplexity is 50.43895811625701
At time: 574.2477934360504 and batch: 750, loss is 3.869126434326172 and perplexity is 47.900523545516734
At time: 575.3671717643738 and batch: 800, loss is 3.858467812538147 and perplexity is 47.39268123896135
At time: 576.482976436615 and batch: 850, loss is 3.849421248435974 and perplexity is 46.96587379146006
At time: 577.5983498096466 and batch: 900, loss is 3.804541573524475 and perplexity is 44.90465990884999
At time: 578.7205719947815 and batch: 950, loss is 3.907139015197754 and perplexity is 49.75639585284905
At time: 579.8437578678131 and batch: 1000, loss is 3.8745169973373415 and perplexity is 48.15943153893409
At time: 580.961428642273 and batch: 1050, loss is 3.8229013872146607 and perplexity is 45.73671592278202
At time: 582.0802874565125 and batch: 1100, loss is 3.8354570055007935 and perplexity is 46.3145888540662
At time: 583.1977972984314 and batch: 1150, loss is 3.8191598558425905 and perplexity is 45.56591030185584
At time: 584.3146276473999 and batch: 1200, loss is 3.8492332601547243 and perplexity is 46.95704558739407
At time: 585.4351408481598 and batch: 1250, loss is 3.8536877536773684 and perplexity is 47.16668200820226
At time: 586.5563848018646 and batch: 1300, loss is 3.840934157371521 and perplexity is 46.56895686125084
At time: 587.6742749214172 and batch: 1350, loss is 3.726215372085571 and perplexity is 41.52166636506206
At time: 588.7932789325714 and batch: 1400, loss is 3.7399290370941163 and perplexity is 42.09500287527756
At time: 589.9107532501221 and batch: 1450, loss is 3.66401394367218 and perplexity is 39.01764359393512
At time: 591.0271792411804 and batch: 1500, loss is 3.666465835571289 and perplexity is 39.11342801672438
At time: 592.147102355957 and batch: 1550, loss is 3.6991278409957884 and perplexity is 40.41204325825254
At time: 593.2660031318665 and batch: 1600, loss is 3.780804843902588 and perplexity is 43.85132100484836
At time: 594.3836855888367 and batch: 1650, loss is 3.722307620048523 and perplexity is 41.35972660503132
At time: 595.501987695694 and batch: 1700, loss is 3.7209437799453737 and perplexity is 41.303356999533946
At time: 596.6200876235962 and batch: 1750, loss is 3.6971295213699342 and perplexity is 40.33136771369739
At time: 597.7382574081421 and batch: 1800, loss is 3.6564900922775267 and perplexity is 38.72518223929497
At time: 598.8555903434753 and batch: 1850, loss is 3.6894884967803954 and perplexity is 40.02436912682408
At time: 599.9744699001312 and batch: 1900, loss is 3.790112280845642 and perplexity is 44.26136970101183
At time: 601.0925188064575 and batch: 1950, loss is 3.723773708343506 and perplexity is 41.42040808742705
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.303616687863372 and perplexity of 73.96682544316108
finished 13 epochs...
Completing Train Step...
At time: 604.7140123844147 and batch: 50, loss is 3.9328459215164187 and perplexity is 51.05206128265206
At time: 605.8534457683563 and batch: 100, loss is 3.9113564682006836 and perplexity is 49.96668424295648
At time: 606.9737520217896 and batch: 150, loss is 3.880604853630066 and perplexity is 48.453513493349405
At time: 608.0932724475861 and batch: 200, loss is 3.876010274887085 and perplexity is 48.23140065842127
At time: 609.2108223438263 and batch: 250, loss is 3.8786938619613647 and perplexity is 48.361007649844176
At time: 610.3365695476532 and batch: 300, loss is 3.8713704490661622 and perplexity is 48.00813372065889
At time: 611.4568283557892 and batch: 350, loss is 3.9034677839279173 and perplexity is 49.57406351340137
At time: 612.5740871429443 and batch: 400, loss is 3.8482094049453734 and perplexity is 46.90899297531001
At time: 613.6924424171448 and batch: 450, loss is 3.888185968399048 and perplexity is 48.82224105709502
At time: 614.8092060089111 and batch: 500, loss is 3.8962672424316405 and perplexity is 49.21838548589114
At time: 615.9274327754974 and batch: 550, loss is 3.8735950422286987 and perplexity is 48.1150511664966
At time: 617.0695896148682 and batch: 600, loss is 3.831150813102722 and perplexity is 46.115578120403335
At time: 618.1846160888672 and batch: 650, loss is 3.8589550352096555 and perplexity is 47.41577765381612
At time: 619.3006656169891 and batch: 700, loss is 3.914964256286621 and perplexity is 50.14727902903368
At time: 620.4176735877991 and batch: 750, loss is 3.863580098152161 and perplexity is 47.635586533052454
At time: 621.5364410877228 and batch: 800, loss is 3.852874517440796 and perplexity is 47.128339945924644
At time: 622.6515736579895 and batch: 850, loss is 3.84427924156189 and perplexity is 46.72499477709209
At time: 623.7678456306458 and batch: 900, loss is 3.799437689781189 and perplexity is 44.67605562623877
At time: 624.8836393356323 and batch: 950, loss is 3.9021758079528808 and perplexity is 49.51005637110557
At time: 625.998067855835 and batch: 1000, loss is 3.8698273420333864 and perplexity is 47.93410916048261
At time: 627.1148228645325 and batch: 1050, loss is 3.8185216045379637 and perplexity is 45.53683707915728
At time: 628.2327868938446 and batch: 1100, loss is 3.8312611389160156 and perplexity is 46.12066613972974
At time: 629.348664522171 and batch: 1150, loss is 3.8152302265167237 and perplexity is 45.38720451818226
At time: 630.4654190540314 and batch: 1200, loss is 3.845649480819702 and perplexity is 46.78906308368686
At time: 631.5824663639069 and batch: 1250, loss is 3.8504604864120484 and perplexity is 47.014707881809144
At time: 632.697146654129 and batch: 1300, loss is 3.8379205322265624 and perplexity is 46.428826737765526
At time: 633.812736749649 and batch: 1350, loss is 3.723308506011963 and perplexity is 41.4011436982781
At time: 634.9308562278748 and batch: 1400, loss is 3.7372031354904176 and perplexity is 41.9804122917157
At time: 636.0477983951569 and batch: 1450, loss is 3.6615045166015623 and perplexity is 38.91985441159616
At time: 637.1644117832184 and batch: 1500, loss is 3.6644821977615356 and perplexity is 39.03591804331391
At time: 638.2811489105225 and batch: 1550, loss is 3.697334485054016 and perplexity is 40.33963502662857
At time: 639.3964529037476 and batch: 1600, loss is 3.779380021095276 and perplexity is 43.78888513313958
At time: 640.5135712623596 and batch: 1650, loss is 3.7208366918563844 and perplexity is 41.2989341387861
At time: 641.6305868625641 and batch: 1700, loss is 3.720013475418091 and perplexity is 41.26495016732023
At time: 642.7479820251465 and batch: 1750, loss is 3.6964090728759764 and perplexity is 40.302321504973825
At time: 643.8644392490387 and batch: 1800, loss is 3.6559420680999755 and perplexity is 38.70396571726228
At time: 644.9815554618835 and batch: 1850, loss is 3.688996114730835 and perplexity is 40.00466669688053
At time: 646.1011726856232 and batch: 1900, loss is 3.7895082998275758 and perplexity is 44.23464474537418
At time: 647.2191758155823 and batch: 1950, loss is 3.722890706062317 and perplexity is 41.383849915448046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.303790141260901 and perplexity of 73.9796563530889
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 650.8361513614655 and batch: 50, loss is 3.931960635185242 and perplexity is 51.00688559028208
At time: 651.9766619205475 and batch: 100, loss is 3.9173241901397704 and perplexity is 50.26576304268577
At time: 653.0988922119141 and batch: 150, loss is 3.890795087814331 and perplexity is 48.94979043755947
At time: 654.2144408226013 and batch: 200, loss is 3.888371443748474 and perplexity is 48.8312972191363
At time: 655.3412523269653 and batch: 250, loss is 3.894051260948181 and perplexity is 49.10943921105489
At time: 656.4597330093384 and batch: 300, loss is 3.8817309856414797 and perplexity is 48.50810928122218
At time: 657.5773334503174 and batch: 350, loss is 3.9173377418518065 and perplexity is 50.26644423444745
At time: 658.6938798427582 and batch: 400, loss is 3.8680298137664795 and perplexity is 47.84802363807689
At time: 659.8111486434937 and batch: 450, loss is 3.910396203994751 and perplexity is 49.9187260545399
At time: 660.9260392189026 and batch: 500, loss is 3.9210207223892213 and perplexity is 50.45191590487406
At time: 662.0430383682251 and batch: 550, loss is 3.905336632728577 and perplexity is 49.66679656758083
At time: 663.1618618965149 and batch: 600, loss is 3.861427731513977 and perplexity is 47.533167546952335
At time: 664.279417514801 and batch: 650, loss is 3.8795104789733887 and perplexity is 48.40051620089155
At time: 665.3976955413818 and batch: 700, loss is 3.9331582736968995 and perplexity is 51.06800999598977
At time: 666.5136351585388 and batch: 750, loss is 3.876168999671936 and perplexity is 48.23905678470627
At time: 667.6283700466156 and batch: 800, loss is 3.866260166168213 and perplexity is 47.763424375482856
At time: 668.7436695098877 and batch: 850, loss is 3.85784875869751 and perplexity is 47.36335169684178
At time: 669.8629484176636 and batch: 900, loss is 3.805916414260864 and perplexity is 44.9664391231054
At time: 670.9807524681091 and batch: 950, loss is 3.909433569908142 and perplexity is 49.870695708812704
At time: 672.0963792800903 and batch: 1000, loss is 3.8789142990112304 and perplexity is 48.371669382776346
At time: 673.2360365390778 and batch: 1050, loss is 3.828196811676025 and perplexity is 45.97955364400525
At time: 674.3509178161621 and batch: 1100, loss is 3.839506826400757 and perplexity is 46.50253496114081
At time: 675.4717643260956 and batch: 1150, loss is 3.826307463645935 and perplexity is 45.892764278379204
At time: 676.5917429924011 and batch: 1200, loss is 3.8531175088882446 and perplexity is 47.13979312091939
At time: 677.7090117931366 and batch: 1250, loss is 3.854962544441223 and perplexity is 47.22684800016548
At time: 678.8261022567749 and batch: 1300, loss is 3.8406249856948853 and perplexity is 46.554561284245885
At time: 679.9436378479004 and batch: 1350, loss is 3.71912793636322 and perplexity is 41.22842461713725
At time: 681.0583031177521 and batch: 1400, loss is 3.731994514465332 and perplexity is 41.76232070488724
At time: 682.1740164756775 and batch: 1450, loss is 3.653839473724365 and perplexity is 38.62267246994277
At time: 683.2888698577881 and batch: 1500, loss is 3.6579199552536013 and perplexity is 38.78059354947038
At time: 684.4160380363464 and batch: 1550, loss is 3.690149817466736 and perplexity is 40.0508468242449
At time: 685.5399351119995 and batch: 1600, loss is 3.7734767818450927 and perplexity is 43.531150351206676
At time: 686.6544258594513 and batch: 1650, loss is 3.715034775733948 and perplexity is 41.06001495172089
At time: 687.7778334617615 and batch: 1700, loss is 3.714177994728088 and perplexity is 41.02485057704519
At time: 688.8927495479584 and batch: 1750, loss is 3.6887670612335204 and perplexity is 39.99550453741709
At time: 690.010853767395 and batch: 1800, loss is 3.648324284553528 and perplexity is 38.41024744553444
At time: 691.1290719509125 and batch: 1850, loss is 3.6810287618637085 and perplexity is 39.687201757924164
At time: 692.247540473938 and batch: 1900, loss is 3.7850782346725462 and perplexity is 44.03911580978372
At time: 693.3634083271027 and batch: 1950, loss is 3.723800706863403 and perplexity is 41.42152639223516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.298218625090843 and perplexity of 73.568623602536
finished 15 epochs...
Completing Train Step...
At time: 696.9849927425385 and batch: 50, loss is 3.9381582593917845 and perplexity is 51.3239887271472
At time: 698.1366815567017 and batch: 100, loss is 3.916881036758423 and perplexity is 50.2434925348173
At time: 699.2565376758575 and batch: 150, loss is 3.8860193204879763 and perplexity is 48.7165749624427
At time: 700.3997266292572 and batch: 200, loss is 3.881274480819702 and perplexity is 48.48597014913475
At time: 701.5187640190125 and batch: 250, loss is 3.8853888845443727 and perplexity is 48.685871961691646
At time: 702.6416413784027 and batch: 300, loss is 3.873913469314575 and perplexity is 48.13037474161755
At time: 703.7625315189362 and batch: 350, loss is 3.9057529640197752 and perplexity is 49.687478714139154
At time: 704.882627248764 and batch: 400, loss is 3.8549717378616335 and perplexity is 47.22728217842959
At time: 706.0032138824463 and batch: 450, loss is 3.898416590690613 and perplexity is 49.324286705576455
At time: 707.1270065307617 and batch: 500, loss is 3.9089453983306885 and perplexity is 49.846356194032865
At time: 708.2483110427856 and batch: 550, loss is 3.8922367668151856 and perplexity is 49.02041121654483
At time: 709.3655252456665 and batch: 600, loss is 3.848919110298157 and perplexity is 46.94229635511386
At time: 710.489667892456 and batch: 650, loss is 3.8691233730316164 and perplexity is 47.90037690812924
At time: 711.6115145683289 and batch: 700, loss is 3.923944420814514 and perplexity is 50.59963793406274
At time: 712.7319922447205 and batch: 750, loss is 3.869236235618591 and perplexity is 47.90578337367227
At time: 713.8513758182526 and batch: 800, loss is 3.858551287651062 and perplexity is 47.39663751350204
At time: 714.9718079566956 and batch: 850, loss is 3.85046501159668 and perplexity is 47.01492063252407
At time: 716.0910439491272 and batch: 900, loss is 3.7996889257431032 and perplexity is 44.687281268132
At time: 717.2083804607391 and batch: 950, loss is 3.903784966468811 and perplexity is 49.58979003478615
At time: 718.3291673660278 and batch: 1000, loss is 3.8733067655563356 and perplexity is 48.101182718726776
At time: 719.4508516788483 and batch: 1050, loss is 3.8229176998138428 and perplexity is 45.737462013582096
At time: 720.5690178871155 and batch: 1100, loss is 3.8346061849594117 and perplexity is 46.275200209213686
At time: 721.6882178783417 and batch: 1150, loss is 3.8210643339157104 and perplexity is 45.65277226600623
At time: 722.8080294132233 and batch: 1200, loss is 3.848805994987488 and perplexity is 46.93698676298188
At time: 723.9264833927155 and batch: 1250, loss is 3.851505732536316 and perplexity is 47.06387551466855
At time: 725.0448541641235 and batch: 1300, loss is 3.8378190755844117 and perplexity is 46.42411646385404
At time: 726.1647019386292 and batch: 1350, loss is 3.7180518531799316 and perplexity is 41.18408326450399
At time: 727.284170627594 and batch: 1400, loss is 3.7322328758239744 and perplexity is 41.77227641487166
At time: 728.4035551548004 and batch: 1450, loss is 3.6546390295028686 and perplexity is 38.65356579972171
At time: 729.5221631526947 and batch: 1500, loss is 3.6597244453430178 and perplexity is 38.850635922570234
At time: 730.6365401744843 and batch: 1550, loss is 3.6918458557128906 and perplexity is 40.118832228875995
At time: 731.7542653083801 and batch: 1600, loss is 3.775413098335266 and perplexity is 43.61552209430527
At time: 732.8759121894836 and batch: 1650, loss is 3.7171451377868654 and perplexity is 41.14675794653611
At time: 733.9943554401398 and batch: 1700, loss is 3.716578679084778 and perplexity is 41.123456607680765
At time: 735.1117668151855 and batch: 1750, loss is 3.6921545457839966 and perplexity is 40.131218425699046
At time: 736.2295410633087 and batch: 1800, loss is 3.652129578590393 and perplexity is 38.55668817941081
At time: 737.3451752662659 and batch: 1850, loss is 3.6850517892837527 and perplexity is 39.847186053649935
At time: 738.4625999927521 and batch: 1900, loss is 3.78961763381958 and perplexity is 44.23948136006747
At time: 739.5810821056366 and batch: 1950, loss is 3.7279311275482176 and perplexity is 41.592968542004186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.29737066224564 and perplexity of 73.50626658510164
finished 16 epochs...
Completing Train Step...
At time: 743.2085697650909 and batch: 50, loss is 3.9381533527374266 and perplexity is 51.32373689869207
At time: 744.3314764499664 and batch: 100, loss is 3.9155077075958253 and perplexity is 50.174539040048465
At time: 745.4478123188019 and batch: 150, loss is 3.8839274787902833 and perplexity is 48.61477411232074
At time: 746.5648772716522 and batch: 200, loss is 3.8784501504898072 and perplexity is 48.349222953594996
At time: 747.6818554401398 and batch: 250, loss is 3.8821255111694337 and perplexity is 48.52725074429604
At time: 748.804281949997 and batch: 300, loss is 3.8706690454483033 and perplexity is 47.974472448429644
At time: 749.9337997436523 and batch: 350, loss is 3.901982831954956 and perplexity is 49.500503040381446
At time: 751.0529925823212 and batch: 400, loss is 3.8506623697280884 and perplexity is 47.024200325089694
At time: 752.168830871582 and batch: 450, loss is 3.894246745109558 and perplexity is 49.11904026699137
At time: 753.2844724655151 and batch: 500, loss is 3.9045577478408813 and perplexity is 49.62812691187427
At time: 754.4102845191956 and batch: 550, loss is 3.8877651405334475 and perplexity is 48.80169962010482
At time: 755.5283005237579 and batch: 600, loss is 3.844856147766113 and perplexity is 46.7519584934911
At time: 756.6780462265015 and batch: 650, loss is 3.865407609939575 and perplexity is 47.7227207240717
At time: 757.7968184947968 and batch: 700, loss is 3.920445456504822 and perplexity is 50.42290098529825
At time: 758.9136729240417 and batch: 750, loss is 3.866302146911621 and perplexity is 47.76542956163517
At time: 760.0313339233398 and batch: 800, loss is 3.855420217514038 and perplexity is 47.24846740374113
At time: 761.157710313797 and batch: 850, loss is 3.8475342988967896 and perplexity is 46.877335117827315
At time: 762.2777681350708 and batch: 900, loss is 3.7970352840423582 and perplexity is 44.56885443575138
At time: 763.3967764377594 and batch: 950, loss is 3.9013364028930666 and perplexity is 49.4685148168106
At time: 764.5160644054413 and batch: 1000, loss is 3.8710137367248536 and perplexity is 47.99101168088054
At time: 765.6393344402313 and batch: 1050, loss is 3.820782241821289 and perplexity is 45.63989579612214
At time: 766.7560777664185 and batch: 1100, loss is 3.8326427507400513 and perplexity is 46.18443103642527
At time: 767.8733384609222 and batch: 1150, loss is 3.8192295360565187 and perplexity is 45.569085454854886
At time: 768.9917941093445 and batch: 1200, loss is 3.8470701456069945 and perplexity is 46.85558189732052
At time: 770.1111755371094 and batch: 1250, loss is 3.8500293493270874 and perplexity is 46.994442466602614
At time: 771.2305133342743 and batch: 1300, loss is 3.836623969078064 and perplexity is 46.3686678403217
At time: 772.3480820655823 and batch: 1350, loss is 3.717347297668457 and perplexity is 41.155077011112695
At time: 773.4656400680542 and batch: 1400, loss is 3.7319600200653076 and perplexity is 41.76088016353635
At time: 774.5848553180695 and batch: 1450, loss is 3.6546346664428713 and perplexity is 38.65339715226293
At time: 775.70547914505 and batch: 1500, loss is 3.6601165676116945 and perplexity is 38.86587310929259
At time: 776.8247666358948 and batch: 1550, loss is 3.692394151687622 and perplexity is 40.140835254632016
At time: 777.9443323612213 and batch: 1600, loss is 3.776213164329529 and perplexity is 43.65043135334833
At time: 779.0618331432343 and batch: 1650, loss is 3.717973575592041 and perplexity is 41.18085959997854
At time: 780.1793115139008 and batch: 1700, loss is 3.717638487815857 and perplexity is 41.1670627090277
At time: 781.298713684082 and batch: 1750, loss is 3.693572940826416 and perplexity is 40.18818073493888
At time: 782.4185273647308 and batch: 1800, loss is 3.6536897563934327 and perplexity is 38.61689041935448
At time: 783.5379481315613 and batch: 1850, loss is 3.686588706970215 and perplexity is 39.908474984608226
At time: 784.6539008617401 and batch: 1900, loss is 3.7911999368667604 and perplexity is 44.309537036267706
At time: 785.7733364105225 and batch: 1950, loss is 3.7292040634155272 and perplexity is 41.64594743570242
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.297032839752907 and perplexity of 73.48143870883605
finished 17 epochs...
Completing Train Step...
At time: 789.3876504898071 and batch: 50, loss is 3.9370743894577025 and perplexity is 51.26839033502445
At time: 790.5077650547028 and batch: 100, loss is 3.913894658088684 and perplexity is 50.09367026478248
At time: 791.6268494129181 and batch: 150, loss is 3.882025094032288 and perplexity is 48.52237802135928
At time: 792.7471792697906 and batch: 200, loss is 3.8762181854248046 and perplexity is 48.241429517383736
At time: 793.8644509315491 and batch: 250, loss is 3.879658761024475 and perplexity is 48.40769366083855
At time: 794.982470035553 and batch: 300, loss is 3.868175539970398 and perplexity is 47.85499685700469
At time: 796.1022460460663 and batch: 350, loss is 3.899352316856384 and perplexity is 49.370462331756464
At time: 797.2210872173309 and batch: 400, loss is 3.8477496910095215 and perplexity is 46.88743321356363
At time: 798.3405194282532 and batch: 450, loss is 3.8914447450637817 and perplexity is 48.98160135575429
At time: 799.4602489471436 and batch: 500, loss is 3.901633520126343 and perplexity is 49.483214948790376
At time: 800.5776252746582 and batch: 550, loss is 3.8848739528656004 and perplexity is 48.660808517444444
At time: 801.6945457458496 and batch: 600, loss is 3.842247095108032 and perplexity is 46.63013915754788
At time: 802.8127887248993 and batch: 650, loss is 3.8629556846618653 and perplexity is 47.60585151464252
At time: 803.9318854808807 and batch: 700, loss is 3.9180788707733156 and perplexity is 50.30371195843922
At time: 805.0597460269928 and batch: 750, loss is 3.8642334222793577 and perplexity is 47.6667181794682
At time: 806.1784887313843 and batch: 800, loss is 3.8532788276672365 and perplexity is 47.147398268197634
At time: 807.2965552806854 and batch: 850, loss is 3.8455526399612427 and perplexity is 46.78453221004172
At time: 808.413337469101 and batch: 900, loss is 3.7951597213745116 and perplexity is 44.4853410979538
At time: 809.5314974784851 and batch: 950, loss is 3.8996049976348877 and perplexity is 49.38293887483846
At time: 810.6515309810638 and batch: 1000, loss is 3.869409079551697 and perplexity is 47.91406431332356
At time: 811.8197977542877 and batch: 1050, loss is 3.819275722503662 and perplexity is 45.571190177616074
At time: 812.9434123039246 and batch: 1100, loss is 3.8312472105026245 and perplexity is 46.12002375649958
At time: 814.0658357143402 and batch: 1150, loss is 3.8179992771148683 and perplexity is 45.51305815112353
At time: 815.1826360225677 and batch: 1200, loss is 3.8458810663223266 and perplexity is 46.79990000716718
At time: 816.3011741638184 and batch: 1250, loss is 3.8489916467666627 and perplexity is 46.945701507012366
At time: 817.4230988025665 and batch: 1300, loss is 3.835734691619873 and perplexity is 46.327451558316405
At time: 818.5417115688324 and batch: 1350, loss is 3.7166668462753294 and perplexity is 41.12708250715596
At time: 819.6619775295258 and batch: 1400, loss is 3.731493716239929 and perplexity is 41.74141144488668
At time: 820.7803425788879 and batch: 1450, loss is 3.654343409538269 and perplexity is 38.64214072279198
At time: 821.8972592353821 and batch: 1500, loss is 3.6600796127319337 and perplexity is 38.864436852163564
At time: 823.0166013240814 and batch: 1550, loss is 3.6925005769729613 and perplexity is 40.14510748181021
At time: 824.1372494697571 and batch: 1600, loss is 3.7765025091171265 and perplexity is 43.66306320552897
At time: 825.2618808746338 and batch: 1650, loss is 3.71825560092926 and perplexity is 41.19247528367577
At time: 826.3807368278503 and batch: 1700, loss is 3.718090128898621 and perplexity is 41.18565964505785
At time: 827.5007245540619 and batch: 1750, loss is 3.694182653427124 and perplexity is 40.21269144661807
At time: 828.6176500320435 and batch: 1800, loss is 3.654372901916504 and perplexity is 38.64328038822763
At time: 829.7388005256653 and batch: 1850, loss is 3.6872407484054563 and perplexity is 39.93450544946407
At time: 830.8586490154266 and batch: 1900, loss is 3.791851363182068 and perplexity is 44.33841083826838
At time: 831.9791178703308 and batch: 1950, loss is 3.729644317626953 and perplexity is 41.66428627602944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.296871593386628 and perplexity of 73.46959104907702
finished 18 epochs...
Completing Train Step...
At time: 835.5937099456787 and batch: 50, loss is 3.9357877588272094 and perplexity is 51.20246927076747
At time: 836.7085392475128 and batch: 100, loss is 3.912309236526489 and perplexity is 50.01431360331863
At time: 837.8261260986328 and batch: 150, loss is 3.880276446342468 and perplexity is 48.437603619010794
At time: 838.943811416626 and batch: 200, loss is 3.8742831707000733 and perplexity is 48.14817189745796
At time: 840.0832228660583 and batch: 250, loss is 3.877558875083923 and perplexity is 48.3061496782097
At time: 841.1996405124664 and batch: 300, loss is 3.866037731170654 and perplexity is 47.7528012998142
At time: 842.3152401447296 and batch: 350, loss is 3.897176909446716 and perplexity is 49.26317819784042
At time: 843.4307675361633 and batch: 400, loss is 3.845390787124634 and perplexity is 46.77696061355282
At time: 844.5478458404541 and batch: 450, loss is 3.889196696281433 and perplexity is 48.871612003505014
At time: 845.6651601791382 and batch: 500, loss is 3.899309458732605 and perplexity is 49.36834645171246
At time: 846.7815284729004 and batch: 550, loss is 3.8825919389724732 and perplexity is 48.549890482739535
At time: 847.8955888748169 and batch: 600, loss is 3.8401814317703247 and perplexity is 46.533916404779184
At time: 849.0089905261993 and batch: 650, loss is 3.8609829187393188 and perplexity is 47.512028888528675
At time: 850.1211624145508 and batch: 700, loss is 3.9161626625061037 and perplexity is 50.20741186469755
At time: 851.2372400760651 and batch: 750, loss is 3.86251606464386 and perplexity is 47.58492762895897
At time: 852.3551640510559 and batch: 800, loss is 3.8515194845199585 and perplexity is 47.0645227407651
At time: 853.4723091125488 and batch: 850, loss is 3.8439336442947387 and perplexity is 46.70884953662567
At time: 854.5973494052887 and batch: 900, loss is 3.7935935115814208 and perplexity is 44.415722254165985
At time: 855.7250814437866 and batch: 950, loss is 3.8981532287597656 and perplexity is 49.31129827659594
At time: 856.8450882434845 and batch: 1000, loss is 3.8680580949783323 and perplexity is 47.84937685730539
At time: 857.9604058265686 and batch: 1050, loss is 3.8179984426498415 and perplexity is 45.51302017208409
At time: 859.0858595371246 and batch: 1100, loss is 3.8300469732284546 and perplexity is 46.06470199116507
At time: 860.2041013240814 and batch: 1150, loss is 3.816950840950012 and perplexity is 45.46536562064028
At time: 861.3209390640259 and batch: 1200, loss is 3.8448697185516356 and perplexity is 46.75259295859765
At time: 862.4380424022675 and batch: 1250, loss is 3.848088126182556 and perplexity is 46.903304255644365
At time: 863.5534644126892 and batch: 1300, loss is 3.834929175376892 and perplexity is 46.29014906948759
At time: 864.6703469753265 and batch: 1350, loss is 3.7159711599349974 and perplexity is 41.09848090766262
At time: 865.7883384227753 and batch: 1400, loss is 3.7309291982650756 and perplexity is 41.71785431766676
At time: 866.9103572368622 and batch: 1450, loss is 3.653910241127014 and perplexity is 38.62540579287077
At time: 868.0301234722137 and batch: 1500, loss is 3.6598433303833007 and perplexity is 38.855254956548485
At time: 869.1503977775574 and batch: 1550, loss is 3.6923743295669555 and perplexity is 40.14003958603789
At time: 870.2769865989685 and batch: 1600, loss is 3.7765113878250123 and perplexity is 43.663450878833586
At time: 871.4013006687164 and batch: 1650, loss is 3.71824595451355 and perplexity is 41.19207792585159
At time: 872.5191051959991 and batch: 1700, loss is 3.718219780921936 and perplexity is 41.190999795335564
At time: 873.6440689563751 and batch: 1750, loss is 3.694404573440552 and perplexity is 40.22161643792434
At time: 874.7607889175415 and batch: 1800, loss is 3.6546425724029543 and perplexity is 38.65370274568589
At time: 875.8879327774048 and batch: 1850, loss is 3.6874886178970336 and perplexity is 39.94440522190131
At time: 877.0098373889923 and batch: 1900, loss is 3.7920994091033937 and perplexity is 44.349410164347475
At time: 878.1317181587219 and batch: 1950, loss is 3.7297423839569093 and perplexity is 41.66837234002415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.296795796239099 and perplexity of 73.46402247468906
finished 19 epochs...
Completing Train Step...
At time: 881.7610716819763 and batch: 50, loss is 3.934464864730835 and perplexity is 51.1347786101089
At time: 882.9045810699463 and batch: 100, loss is 3.910784225463867 and perplexity is 49.938099350344274
At time: 884.0235888957977 and batch: 150, loss is 3.878650631904602 and perplexity is 48.35891704592716
At time: 885.1451199054718 and batch: 200, loss is 3.872530632019043 and perplexity is 48.063864261561754
At time: 886.2627432346344 and batch: 250, loss is 3.8756821393966674 and perplexity is 48.21557682043609
At time: 887.3809642791748 and batch: 300, loss is 3.864113812446594 and perplexity is 47.66101711223701
At time: 888.5054934024811 and batch: 350, loss is 3.895251727104187 and perplexity is 49.16842883120522
At time: 889.6251757144928 and batch: 400, loss is 3.843334126472473 and perplexity is 46.68085514127888
At time: 890.7495520114899 and batch: 450, loss is 3.8872493171691893 and perplexity is 48.77653305453453
At time: 891.8727326393127 and batch: 500, loss is 3.8973102521896363 and perplexity is 49.269747523122476
At time: 892.9926488399506 and batch: 550, loss is 3.880628237724304 and perplexity is 48.45464654812277
At time: 894.1262545585632 and batch: 600, loss is 3.8383979177474976 and perplexity is 46.45099647873978
At time: 895.2526631355286 and batch: 650, loss is 3.8592604494094847 and perplexity is 47.4302613172532
At time: 896.402624130249 and batch: 700, loss is 3.914480667114258 and perplexity is 50.123034210610086
At time: 897.5309507846832 and batch: 750, loss is 3.8609807443618775 and perplexity is 47.51192557955719
At time: 898.6572895050049 and batch: 800, loss is 3.8499553918838503 and perplexity is 46.990967006311095
At time: 899.7754769325256 and batch: 850, loss is 3.8424997520446778 and perplexity is 46.64192207411791
At time: 900.8947734832764 and batch: 900, loss is 3.792192177772522 and perplexity is 44.35352459094704
At time: 902.0190761089325 and batch: 950, loss is 3.8968467903137207 and perplexity is 49.246918164186916
At time: 903.1478362083435 and batch: 1000, loss is 3.8668360996246336 and perplexity is 47.79094085264321
At time: 904.2805776596069 and batch: 1050, loss is 3.816836004257202 and perplexity is 45.46014482819001
At time: 905.4015424251556 and batch: 1100, loss is 3.828941373825073 and perplexity is 46.01380102734921
At time: 906.5232858657837 and batch: 1150, loss is 3.8159799194335937 and perplexity is 45.421243741814216
At time: 907.6418447494507 and batch: 1200, loss is 3.8439323472976685 and perplexity is 46.708788955423955
At time: 908.7618308067322 and batch: 1250, loss is 3.8472343635559083 and perplexity is 46.86327705669922
At time: 909.9035384654999 and batch: 1300, loss is 3.8341486835479737 and perplexity is 46.25403408193913
At time: 911.0592107772827 and batch: 1350, loss is 3.7152573823928834 and perplexity is 41.06915620187896
At time: 912.2197413444519 and batch: 1400, loss is 3.730306444168091 and perplexity is 41.69188244085874
At time: 913.3678119182587 and batch: 1450, loss is 3.6533942127227785 and perplexity is 38.6054791281612
At time: 914.496551990509 and batch: 1500, loss is 3.659494414329529 and perplexity is 38.841700099211934
At time: 915.6210823059082 and batch: 1550, loss is 3.692108654975891 and perplexity is 40.12937681391208
At time: 916.750278711319 and batch: 1600, loss is 3.7763505840301512 and perplexity is 43.656430194726994
At time: 917.8703074455261 and batch: 1650, loss is 3.7180626344680787 and perplexity is 41.18452728436628
At time: 918.9899752140045 and batch: 1700, loss is 3.718158254623413 and perplexity is 41.188465543548055
At time: 920.1128478050232 and batch: 1750, loss is 3.694412875175476 and perplexity is 40.22195034850824
At time: 921.2319424152374 and batch: 1800, loss is 3.6546869134902953 and perplexity is 38.6554167308951
At time: 922.3532466888428 and batch: 1850, loss is 3.6875181007385254 and perplexity is 39.94558291382972
At time: 923.4817178249359 and batch: 1900, loss is 3.7921362686157227 and perplexity is 44.35104489210566
At time: 924.6138801574707 and batch: 1950, loss is 3.7296672105789184 and perplexity is 41.66524010545177
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.296774221021075 and perplexity of 73.46243748948554
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5dd8c64b38>
ELAPSED
1910.0558230876923


RESULTS SO FAR:
[{'best_accuracy': -76.21175240042173, 'params': {'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}}, {'best_accuracy': -73.46243748948554, 'params': {'rnn_dropout': 0.1541901093865481, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2553724200355174, 'num_layers': 2}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.9124043211516957, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.644131086985198, 'num_layers': 2}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6998865604400635 and batch: 50, loss is 7.682644920349121 and perplexity is 2170.352596820816
At time: 2.8739123344421387 and batch: 100, loss is 6.828420810699463 and perplexity is 923.7309140783991
At time: 4.048816919326782 and batch: 150, loss is 6.595634450912476 and perplexity is 731.8930896562676
At time: 5.2250447273254395 and batch: 200, loss is 6.475787925720215 and perplexity is 649.2305715995961
At time: 6.406484603881836 and batch: 250, loss is 6.405780906677246 and perplexity is 605.3343237709292
At time: 7.586405277252197 and batch: 300, loss is 6.341321296691895 and perplexity is 567.5457124543548
At time: 8.766479730606079 and batch: 350, loss is 6.294948377609253 and perplexity is 541.8278752208398
At time: 9.942540645599365 and batch: 400, loss is 6.252568531036377 and perplexity is 519.3450669060725
At time: 11.123398065567017 and batch: 450, loss is 6.166543312072754 and perplexity is 476.5360195095758
At time: 12.304054021835327 and batch: 500, loss is 6.160144424438476 and perplexity is 473.4964543564198
At time: 13.487731456756592 and batch: 550, loss is 6.108638010025024 and perplexity is 449.7257758555693
At time: 14.667275190353394 and batch: 600, loss is 6.155627098083496 and perplexity is 471.36234021828824
At time: 15.847139120101929 and batch: 650, loss is 6.226250896453857 and perplexity is 505.8554196057526
At time: 17.027915239334106 and batch: 700, loss is 6.123979721069336 and perplexity is 456.6785360055558
At time: 18.209031343460083 and batch: 750, loss is 6.059373426437378 and perplexity is 428.1071122070193
At time: 19.38651132583618 and batch: 800, loss is 6.066831827163696 and perplexity is 431.3120435779681
At time: 20.566326141357422 and batch: 850, loss is 6.100945777893067 and perplexity is 446.2796519767499
At time: 21.745100021362305 and batch: 900, loss is 6.075611038208008 and perplexity is 435.1152933730134
At time: 22.9266095161438 and batch: 950, loss is 6.094288539886475 and perplexity is 443.31852950069907
At time: 24.10821509361267 and batch: 1000, loss is 6.077544822692871 and perplexity is 435.9575266628365
At time: 25.293137311935425 and batch: 1050, loss is 5.970101661682129 and perplexity is 391.545473898133
At time: 26.47099232673645 and batch: 1100, loss is 6.0512245082855225 and perplexity is 424.63267805576874
At time: 27.654661178588867 and batch: 1150, loss is 5.954860744476318 and perplexity is 385.6232067772211
At time: 28.83541178703308 and batch: 1200, loss is 6.035662059783935 and perplexity is 418.07550901362464
At time: 30.0155189037323 and batch: 1250, loss is 5.984651069641114 and perplexity is 397.28387265714093
At time: 31.20275068283081 and batch: 1300, loss is 5.9944383239746095 and perplexity is 401.19128117093544
At time: 32.387614250183105 and batch: 1350, loss is 5.971183109283447 and perplexity is 391.96913885612264
At time: 33.57443428039551 and batch: 1400, loss is 5.990341167449952 and perplexity is 399.5509004386733
At time: 34.75521898269653 and batch: 1450, loss is 5.973984031677246 and perplexity is 393.06855296286165
At time: 35.93595910072327 and batch: 1500, loss is 5.943998851776123 and perplexity is 381.4572747938235
At time: 37.11452651023865 and batch: 1550, loss is 5.925882272720337 and perplexity is 374.60879672658166
At time: 38.29987835884094 and batch: 1600, loss is 5.92393533706665 and perplexity is 373.88016703177516
At time: 39.48880314826965 and batch: 1650, loss is 5.920725421905518 and perplexity is 372.68196750339854
At time: 40.67731952667236 and batch: 1700, loss is 5.940698709487915 and perplexity is 380.2004864409606
At time: 41.87152123451233 and batch: 1750, loss is 5.947254066467285 and perplexity is 382.7010233548033
At time: 43.06080603599548 and batch: 1800, loss is 5.9553430557250975 and perplexity is 385.8092420474856
At time: 44.24771547317505 and batch: 1850, loss is 5.913607625961304 and perplexity is 370.03871154449433
At time: 45.435945987701416 and batch: 1900, loss is 5.900697069168091 and perplexity is 365.2920129368292
At time: 46.62414336204529 and batch: 1950, loss is 5.837154808044434 and perplexity is 342.8026125987291
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.3042599700218025 and perplexity of 201.19205915410564
finished 1 epochs...
Completing Train Step...
At time: 50.409584522247314 and batch: 50, loss is 5.5965603256225585 and perplexity is 269.4978265649741
At time: 51.554781436920166 and batch: 100, loss is 5.516616458892822 and perplexity is 248.79181412398262
At time: 52.67841935157776 and batch: 150, loss is 5.409696521759034 and perplexity is 223.56373065677812
At time: 53.80046319961548 and batch: 200, loss is 5.3670401287078855 and perplexity is 214.227841531958
At time: 54.923994064331055 and batch: 250, loss is 5.3458896923065184 and perplexity is 209.74440959919372
At time: 56.0399010181427 and batch: 300, loss is 5.32974983215332 and perplexity is 206.38633647215403
At time: 57.1554901599884 and batch: 350, loss is 5.289336681365967 and perplexity is 198.21190414444442
At time: 58.294339656829834 and batch: 400, loss is 5.235897855758667 and perplexity is 187.8977356944878
At time: 59.40980863571167 and batch: 450, loss is 5.179516401290893 and perplexity is 177.59690458912493
At time: 60.52448844909668 and batch: 500, loss is 5.161415586471557 and perplexity is 174.4111750374371
At time: 61.64600205421448 and batch: 550, loss is 5.1155226516723635 and perplexity is 166.58782563998562
At time: 62.76368427276611 and batch: 600, loss is 5.0964040184021 and perplexity is 163.43314676007475
At time: 63.87817716598511 and batch: 650, loss is 5.160820655822754 and perplexity is 174.307443343555
At time: 64.9997022151947 and batch: 700, loss is 5.13994176864624 and perplexity is 170.705827600459
At time: 66.11954855918884 and batch: 750, loss is 5.071812877655029 and perplexity is 159.46315264795993
At time: 67.24751830101013 and batch: 800, loss is 5.072123861312866 and perplexity is 159.51275079416732
At time: 68.37177634239197 and batch: 850, loss is 5.063966302871704 and perplexity is 158.21680925349057
At time: 69.49096083641052 and batch: 900, loss is 5.067144594192505 and perplexity is 158.72046832880207
At time: 70.6043758392334 and batch: 950, loss is 5.106853504180908 and perplexity is 165.14989303966425
At time: 71.71871542930603 and batch: 1000, loss is 5.061399841308594 and perplexity is 157.8112725137276
At time: 72.82861042022705 and batch: 1050, loss is 4.973166351318359 and perplexity is 144.48364984924675
At time: 73.93912744522095 and batch: 1100, loss is 5.049882078170777 and perplexity is 156.00406711672989
At time: 75.05219674110413 and batch: 1150, loss is 4.9612736320495605 and perplexity is 142.77552362807765
At time: 76.1662437915802 and batch: 1200, loss is 5.031332511901855 and perplexity is 153.13693358855332
At time: 77.27845573425293 and batch: 1250, loss is 4.993093147277832 and perplexity is 147.39162313087195
At time: 78.3907732963562 and batch: 1300, loss is 5.0083473110198975 and perplexity is 149.65719485427712
At time: 79.5020809173584 and batch: 1350, loss is 4.9144080543518065 and perplexity is 136.23864005874967
At time: 80.6124439239502 and batch: 1400, loss is 4.9145676803588865 and perplexity is 136.26038902467636
At time: 81.72504997253418 and batch: 1450, loss is 4.867700242996216 and perplexity is 130.02155481704696
At time: 82.8375313282013 and batch: 1500, loss is 4.835280456542969 and perplexity is 125.87388041032561
At time: 83.94977140426636 and batch: 1550, loss is 4.836552696228027 and perplexity is 126.03412406885266
At time: 85.06522870063782 and batch: 1600, loss is 4.887441921234131 and perplexity is 132.61390297456748
At time: 86.18179106712341 and batch: 1650, loss is 4.85664740562439 and perplexity is 128.59236059228024
At time: 87.29415440559387 and batch: 1700, loss is 4.8736623191833495 and perplexity is 130.7990687282761
At time: 88.40613412857056 and batch: 1750, loss is 4.866576013565063 and perplexity is 129.875462894244
At time: 89.51844787597656 and batch: 1800, loss is 4.825890169143677 and perplexity is 124.69742078894718
At time: 90.63152384757996 and batch: 1850, loss is 4.829102821350098 and perplexity is 125.09867443206474
At time: 91.74453115463257 and batch: 1900, loss is 4.9255391883850095 and perplexity is 137.76360215501575
At time: 92.85761880874634 and batch: 1950, loss is 4.843489027023315 and perplexity is 126.91137738724414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.650403683684593 and perplexity of 104.62721335220355
finished 2 epochs...
Completing Train Step...
At time: 96.4813334941864 and batch: 50, loss is 4.812915601730347 and perplexity is 123.08997619539853
At time: 97.63267302513123 and batch: 100, loss is 4.749079685211182 and perplexity is 115.47795953451852
At time: 98.76289629936218 and batch: 150, loss is 4.685154104232788 and perplexity is 108.3269646657494
At time: 99.88291311264038 and batch: 200, loss is 4.66616888999939 and perplexity is 106.2897536683104
At time: 100.9980902671814 and batch: 250, loss is 4.677281093597412 and perplexity is 107.477453812851
At time: 102.11441850662231 and batch: 300, loss is 4.703039598464966 and perplexity is 110.28187613343596
At time: 103.24132537841797 and batch: 350, loss is 4.705009927749634 and perplexity is 110.49938195222526
At time: 104.36673069000244 and batch: 400, loss is 4.650658388137817 and perplexity is 104.65386576347258
At time: 105.48940706253052 and batch: 450, loss is 4.647891206741333 and perplexity is 104.36466984638075
At time: 106.60775089263916 and batch: 500, loss is 4.6459645652771 and perplexity is 104.16379011979693
At time: 107.72355842590332 and batch: 550, loss is 4.6180580043792725 and perplexity is 101.29712242439716
At time: 108.84984469413757 and batch: 600, loss is 4.586632013320923 and perplexity is 98.16326023419772
At time: 109.9768238067627 and batch: 650, loss is 4.648051986694336 and perplexity is 104.38145094208954
At time: 111.09710717201233 and batch: 700, loss is 4.672505855560303 and perplexity is 106.96544683779999
At time: 112.21443772315979 and batch: 750, loss is 4.6160653591156 and perplexity is 101.0954741666201
At time: 113.36633157730103 and batch: 800, loss is 4.624160451889038 and perplexity is 101.91717278505719
At time: 114.48317766189575 and batch: 850, loss is 4.614785804748535 and perplexity is 100.96619973562899
At time: 115.59886026382446 and batch: 900, loss is 4.592583856582642 and perplexity is 98.74925471695167
At time: 116.71610045433044 and batch: 950, loss is 4.658028545379639 and perplexity is 105.42803056393682
At time: 117.83498692512512 and batch: 1000, loss is 4.631856889724731 and perplexity is 102.70459826849334
At time: 118.95645928382874 and batch: 1050, loss is 4.5652094650268555 and perplexity is 96.08271787791311
At time: 120.07399845123291 and batch: 1100, loss is 4.621418094635009 and perplexity is 101.63806237211415
At time: 121.19237351417542 and batch: 1150, loss is 4.570374059677124 and perplexity is 96.58022978647365
At time: 122.31244087219238 and batch: 1200, loss is 4.63769715309143 and perplexity is 103.3061751451349
At time: 123.43738579750061 and batch: 1250, loss is 4.615044965744018 and perplexity is 100.99236962742377
At time: 124.55737686157227 and batch: 1300, loss is 4.614828500747681 and perplexity is 100.97051068043606
At time: 125.6895821094513 and batch: 1350, loss is 4.497253189086914 and perplexity is 89.77021053947219
At time: 126.81380438804626 and batch: 1400, loss is 4.505757904052734 and perplexity is 90.53693636338109
At time: 127.94235491752625 and batch: 1450, loss is 4.459611682891846 and perplexity is 86.45393103679508
At time: 129.0604043006897 and batch: 1500, loss is 4.443930130004883 and perplexity is 85.10877378787126
At time: 130.17469334602356 and batch: 1550, loss is 4.455857877731323 and perplexity is 86.13000817634203
At time: 131.30288434028625 and batch: 1600, loss is 4.526375741958618 and perplexity is 92.42298858917472
At time: 132.42893648147583 and batch: 1650, loss is 4.490630588531494 and perplexity is 89.17766256327536
At time: 133.55613040924072 and batch: 1700, loss is 4.505555467605591 and perplexity is 90.51861024264842
At time: 134.6783196926117 and batch: 1750, loss is 4.50098292350769 and perplexity is 90.10565475373636
At time: 135.79468202590942 and batch: 1800, loss is 4.46620192527771 and perplexity is 87.02556493160122
At time: 136.91174912452698 and batch: 1850, loss is 4.48979061126709 and perplexity is 89.10278680559898
At time: 138.03806805610657 and batch: 1900, loss is 4.5960979080200195 and perplexity is 99.09687509766158
At time: 139.16456127166748 and batch: 1950, loss is 4.514930725097656 and perplexity is 91.37123606968161
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.499716399436773 and perplexity of 89.99160601104921
finished 3 epochs...
Completing Train Step...
At time: 142.75985980033875 and batch: 50, loss is 4.494814205169678 and perplexity is 89.5515292282248
At time: 143.90970706939697 and batch: 100, loss is 4.4361459827423095 and perplexity is 84.44884637768342
At time: 145.02680325508118 and batch: 150, loss is 4.387370319366455 and perplexity is 80.42863901128693
At time: 146.15134692192078 and batch: 200, loss is 4.37905071258545 and perplexity is 79.76228012627645
At time: 147.27299761772156 and batch: 250, loss is 4.3841397190094 and perplexity is 80.16922547772678
At time: 148.394517660141 and batch: 300, loss is 4.410066680908203 and perplexity is 82.27494948964873
At time: 149.51877284049988 and batch: 350, loss is 4.418578481674194 and perplexity is 82.97824638306066
At time: 150.63966822624207 and batch: 400, loss is 4.361245031356812 and perplexity is 78.35462768782735
At time: 151.76388335227966 and batch: 450, loss is 4.3759236240386965 and perplexity is 79.5132459924599
At time: 152.89241528511047 and batch: 500, loss is 4.388722152709961 and perplexity is 80.53743865019615
At time: 154.0102858543396 and batch: 550, loss is 4.355870265960693 and perplexity is 77.93461967966164
At time: 155.1269392967224 and batch: 600, loss is 4.3323407554626465 and perplexity is 76.12226178980335
At time: 156.24279499053955 and batch: 650, loss is 4.393132133483887 and perplexity is 80.89339150196244
At time: 157.35927295684814 and batch: 700, loss is 4.421214056015015 and perplexity is 83.1972301673359
At time: 158.4810609817505 and batch: 750, loss is 4.37314769744873 and perplexity is 79.2928291307087
At time: 159.6101291179657 and batch: 800, loss is 4.376791009902954 and perplexity is 79.58224457792785
At time: 160.73642683029175 and batch: 850, loss is 4.3724004173278805 and perplexity is 79.23359730991088
At time: 161.86016368865967 and batch: 900, loss is 4.343444442749023 and perplexity is 76.97220962511521
At time: 162.97958159446716 and batch: 950, loss is 4.425159749984741 and perplexity is 83.52614945740316
At time: 164.0936243534088 and batch: 1000, loss is 4.394670667648316 and perplexity is 81.01794453844673
At time: 165.20978212356567 and batch: 1050, loss is 4.336396703720093 and perplexity is 76.4316367251076
At time: 166.3290078639984 and batch: 1100, loss is 4.3828818988800045 and perplexity is 80.06845040390752
At time: 167.45192694664001 and batch: 1150, loss is 4.3443108606338505 and perplexity is 77.03892862326201
At time: 168.5724000930786 and batch: 1200, loss is 4.4047392559051515 and perplexity is 81.83780133751858
At time: 169.75010466575623 and batch: 1250, loss is 4.396013059616089 and perplexity is 81.12677540693956
At time: 170.8747386932373 and batch: 1300, loss is 4.385227308273316 and perplexity is 80.25646409794702
At time: 171.9953157901764 and batch: 1350, loss is 4.268306889533997 and perplexity is 71.40064404436059
At time: 173.1163067817688 and batch: 1400, loss is 4.284681510925293 and perplexity is 72.57942728366758
At time: 174.2413728237152 and batch: 1450, loss is 4.232750253677368 and perplexity is 68.9064821177193
At time: 175.35867357254028 and batch: 1500, loss is 4.2234697341918945 and perplexity is 68.26995239955824
At time: 176.47598552703857 and batch: 1550, loss is 4.242439441680908 and perplexity is 69.5773749322955
At time: 177.59288549423218 and batch: 1600, loss is 4.317564945220948 and perplexity is 75.00576259772001
At time: 178.70908761024475 and batch: 1650, loss is 4.277459950447082 and perplexity is 72.05717855509837
At time: 179.826922416687 and batch: 1700, loss is 4.289504342079162 and perplexity is 72.93031105316803
At time: 180.95349025726318 and batch: 1750, loss is 4.286947269439697 and perplexity is 72.74406117889983
At time: 182.07164883613586 and batch: 1800, loss is 4.251418962478637 and perplexity is 70.20495990678064
At time: 183.1872684955597 and batch: 1850, loss is 4.28579116821289 and perplexity is 72.66001027556591
At time: 184.3051953315735 and batch: 1900, loss is 4.388376703262329 and perplexity is 80.50962184142803
At time: 185.42086911201477 and batch: 1950, loss is 4.312316493988037 and perplexity is 74.6131297689618
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.436229617096657 and perplexity of 84.45590949778125
finished 4 epochs...
Completing Train Step...
At time: 189.04498028755188 and batch: 50, loss is 4.299396438598633 and perplexity is 73.65532477004466
At time: 190.16416120529175 and batch: 100, loss is 4.24185263633728 and perplexity is 69.53655853370128
At time: 191.2900140285492 and batch: 150, loss is 4.202433748245239 and perplexity is 66.84882643831479
At time: 192.40703535079956 and batch: 200, loss is 4.197174196243286 and perplexity is 66.49815455627522
At time: 193.52477526664734 and batch: 250, loss is 4.195275840759277 and perplexity is 66.3720371655916
At time: 194.64511942863464 and batch: 300, loss is 4.21909607887268 and perplexity is 67.97201517140792
At time: 195.76619029045105 and batch: 350, loss is 4.232837996482849 and perplexity is 68.9125284310325
At time: 196.89862847328186 and batch: 400, loss is 4.172686610221863 and perplexity is 64.88955106584928
At time: 198.03976964950562 and batch: 450, loss is 4.197101097106934 and perplexity is 66.49329377626972
At time: 199.154878616333 and batch: 500, loss is 4.216796088218689 and perplexity is 67.81585981854471
At time: 200.28391671180725 and batch: 550, loss is 4.182838006019592 and perplexity is 65.55162538548915
At time: 201.40494847297668 and batch: 600, loss is 4.163781495094299 and perplexity is 64.3142674282564
At time: 202.53116536140442 and batch: 650, loss is 4.219586358070374 and perplexity is 68.00534860714913
At time: 203.6497769355774 and batch: 700, loss is 4.252974605560302 and perplexity is 70.31425875991839
At time: 204.76928877830505 and batch: 750, loss is 4.205350999832153 and perplexity is 67.04412601381784
At time: 205.88579940795898 and batch: 800, loss is 4.209051551818848 and perplexity is 67.29268590829018
At time: 207.0031304359436 and batch: 850, loss is 4.204943861961365 and perplexity is 67.01683536700858
At time: 208.12169098854065 and batch: 900, loss is 4.176390919685364 and perplexity is 65.1303677984235
At time: 209.24014353752136 and batch: 950, loss is 4.263307909965516 and perplexity is 71.04460434264999
At time: 210.36532521247864 and batch: 1000, loss is 4.231099290847778 and perplexity is 68.79281393381699
At time: 211.49281120300293 and batch: 1050, loss is 4.1813347864151 and perplexity is 65.45316092250032
At time: 212.62057256698608 and batch: 1100, loss is 4.217968869209289 and perplexity is 67.89543962552229
At time: 213.74727201461792 and batch: 1150, loss is 4.18459466457367 and perplexity is 65.66687840942365
At time: 214.86663579940796 and batch: 1200, loss is 4.245182566642761 and perplexity is 69.76849638141657
At time: 215.98438692092896 and batch: 1250, loss is 4.238014879226685 and perplexity is 69.27020553770664
At time: 217.1058657169342 and batch: 1300, loss is 4.22446102142334 and perplexity is 68.33766108549673
At time: 218.23477959632874 and batch: 1350, loss is 4.111231021881103 and perplexity is 61.0217905112682
At time: 219.36446595191956 and batch: 1400, loss is 4.134056878089905 and perplexity is 62.43068355082672
At time: 220.49414253234863 and batch: 1450, loss is 4.075528650283814 and perplexity is 58.88160013656725
At time: 221.62117338180542 and batch: 1500, loss is 4.071050601005554 and perplexity is 58.61851492348275
At time: 222.7413365840912 and batch: 1550, loss is 4.090945620536804 and perplexity is 59.79640969067994
At time: 223.86023378372192 and batch: 1600, loss is 4.17406319141388 and perplexity is 64.97893831169009
At time: 224.98008751869202 and batch: 1650, loss is 4.129125771522522 and perplexity is 62.12358897746766
At time: 226.10580205917358 and batch: 1700, loss is 4.137437949180603 and perplexity is 62.64212337526653
At time: 227.23200368881226 and batch: 1750, loss is 4.135102434158325 and perplexity is 62.49599246698614
At time: 228.35333251953125 and batch: 1800, loss is 4.1000639295578 and perplexity is 60.344145248573255
At time: 229.47872138023376 and batch: 1850, loss is 4.137374167442322 and perplexity is 62.63812807916285
At time: 230.59881210327148 and batch: 1900, loss is 4.239983358383179 and perplexity is 69.40669678949148
At time: 231.71723127365112 and batch: 1950, loss is 4.165336937904358 and perplexity is 64.41438243451033
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.422774913699128 and perplexity of 83.32719060182599
finished 5 epochs...
Completing Train Step...
At time: 235.37451934814453 and batch: 50, loss is 4.159973220825195 and perplexity is 64.06980684040634
At time: 236.49495649337769 and batch: 100, loss is 4.106903162002563 and perplexity is 60.75826740925162
At time: 237.6113407611847 and batch: 150, loss is 4.063624658584595 and perplexity is 58.18482946144363
At time: 238.7270097732544 and batch: 200, loss is 4.060120916366577 and perplexity is 57.981321545841304
At time: 239.84598541259766 and batch: 250, loss is 4.0563000965118405 and perplexity is 57.76020804769379
At time: 240.9672110080719 and batch: 300, loss is 4.077724590301513 and perplexity is 59.01104267061761
At time: 242.08577394485474 and batch: 350, loss is 4.095821762084961 and perplexity is 60.088697487600854
At time: 243.20734333992004 and batch: 400, loss is 4.036226100921631 and perplexity is 56.61229008346399
At time: 244.33259916305542 and batch: 450, loss is 4.063102407455444 and perplexity is 58.1544503020236
At time: 245.467848777771 and batch: 500, loss is 4.088877310752869 and perplexity is 59.672860005028824
At time: 246.59624218940735 and batch: 550, loss is 4.054291768074036 and perplexity is 57.64432298588139
At time: 247.71738958358765 and batch: 600, loss is 4.03559271812439 and perplexity is 56.57644418609841
At time: 248.84051656723022 and batch: 650, loss is 4.0942704963684085 and perplexity is 59.99555621334692
At time: 249.95850682258606 and batch: 700, loss is 4.129113039970398 and perplexity is 62.122798052791346
At time: 251.07741355895996 and batch: 750, loss is 4.077701253890991 and perplexity is 59.00966558076874
At time: 252.1985354423523 and batch: 800, loss is 4.0780427408218385 and perplexity is 59.029820051406546
At time: 253.34439158439636 and batch: 850, loss is 4.078275599479675 and perplexity is 59.04356725659182
At time: 254.45907592773438 and batch: 900, loss is 4.047795839309693 and perplexity is 57.271083152250625
At time: 255.57313513755798 and batch: 950, loss is 4.14111469745636 and perplexity is 62.87286662686114
At time: 256.68933868408203 and batch: 1000, loss is 4.107452797889709 and perplexity is 60.79167151266662
At time: 257.80750370025635 and batch: 1050, loss is 4.06478865146637 and perplexity is 58.25259562077634
At time: 258.9311866760254 and batch: 1100, loss is 4.099191918373108 and perplexity is 60.29154741526822
At time: 260.05249977111816 and batch: 1150, loss is 4.06445496559143 and perplexity is 58.233160795182854
At time: 261.1686499118805 and batch: 1200, loss is 4.12731749534607 and perplexity is 62.01135387813494
At time: 262.2817733287811 and batch: 1250, loss is 4.118440961837768 and perplexity is 61.463343830583455
At time: 263.39436292648315 and batch: 1300, loss is 4.100098533630371 and perplexity is 60.346233437884386
At time: 264.5140585899353 and batch: 1350, loss is 3.9946898365020753 and perplexity is 54.308993343897995
At time: 265.6341321468353 and batch: 1400, loss is 4.02107846736908 and perplexity is 55.76121005625101
At time: 266.75314259529114 and batch: 1450, loss is 3.962167353630066 and perplexity is 52.57114282106989
At time: 267.875097990036 and batch: 1500, loss is 3.9572656869888307 and perplexity is 52.31408711936656
At time: 268.99981689453125 and batch: 1550, loss is 3.9773753023147584 and perplexity is 53.37675237089932
At time: 270.11815428733826 and batch: 1600, loss is 4.0625670051574705 and perplexity is 58.12332260935717
At time: 271.25012826919556 and batch: 1650, loss is 4.0175065994262695 and perplexity is 55.56239366193038
At time: 272.3809497356415 and batch: 1700, loss is 4.023421154022217 and perplexity is 55.89199423217034
At time: 273.4999098777771 and batch: 1750, loss is 4.020025715827942 and perplexity is 55.702538245267085
At time: 274.6193687915802 and batch: 1800, loss is 3.98247465133667 and perplexity is 53.64963422949384
At time: 275.73864006996155 and batch: 1850, loss is 4.022706241607666 and perplexity is 55.85205063140903
At time: 276.8653790950775 and batch: 1900, loss is 4.125403962135315 and perplexity is 61.89280655134153
At time: 277.9937834739685 and batch: 1950, loss is 4.0555246591567995 and perplexity is 57.7154359859467
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.424125352016715 and perplexity of 83.43979484834331
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 281.63873314857483 and batch: 50, loss is 4.083769650459289 and perplexity is 59.368848362400655
At time: 282.7639682292938 and batch: 100, loss is 4.0622509765625 and perplexity is 58.10495687957865
At time: 283.8800485134125 and batch: 150, loss is 4.024686179161072 and perplexity is 55.96274375045938
At time: 285.0060040950775 and batch: 200, loss is 4.020984921455383 and perplexity is 55.75599406687854
At time: 286.1282196044922 and batch: 250, loss is 4.011088943481445 and perplexity is 55.20695509707925
At time: 287.24725699424744 and batch: 300, loss is 4.0301002550125125 and perplexity is 56.26655196823944
At time: 288.36648321151733 and batch: 350, loss is 4.050743207931519 and perplexity is 57.44013114667236
At time: 289.4857437610626 and batch: 400, loss is 3.993109788894653 and perplexity is 54.22325030578306
At time: 290.6091184616089 and batch: 450, loss is 4.010680861473084 and perplexity is 55.184430728175165
At time: 291.7298741340637 and batch: 500, loss is 4.028056974411011 and perplexity is 56.15170099043538
At time: 292.851900100708 and batch: 550, loss is 3.985960383415222 and perplexity is 53.83696878989217
At time: 293.9717843532562 and batch: 600, loss is 3.957157416343689 and perplexity is 52.30842334601987
At time: 295.0894718170166 and batch: 650, loss is 4.008375854492187 and perplexity is 55.05737671655555
At time: 296.2087526321411 and batch: 700, loss is 4.042839593887329 and perplexity is 56.987935861885326
At time: 297.3317668437958 and batch: 750, loss is 3.9751535129547118 and perplexity is 53.258292116004846
At time: 298.45608401298523 and batch: 800, loss is 3.971285820007324 and perplexity is 53.05270322882682
At time: 299.57625102996826 and batch: 850, loss is 3.959227409362793 and perplexity is 52.416813561978486
At time: 300.6954925060272 and batch: 900, loss is 3.926650786399841 and perplexity is 50.73676452644508
At time: 301.81502532958984 and batch: 950, loss is 4.021951670646668 and perplexity is 55.80992219233766
At time: 302.93259716033936 and batch: 1000, loss is 3.9869658041000364 and perplexity is 53.89112481215165
At time: 304.0486364364624 and batch: 1050, loss is 3.934207639694214 and perplexity is 51.1216271563224
At time: 305.1653845310211 and batch: 1100, loss is 3.952882685661316 and perplexity is 52.085296167866154
At time: 306.29133105278015 and batch: 1150, loss is 3.919904808998108 and perplexity is 50.39564733757146
At time: 307.4155261516571 and batch: 1200, loss is 3.9675760507583617 and perplexity is 52.856254556735735
At time: 308.5353810787201 and batch: 1250, loss is 3.9527980947494505 and perplexity is 52.08089041151464
At time: 309.65542221069336 and batch: 1300, loss is 3.937073450088501 and perplexity is 51.26834217510017
At time: 310.7777497768402 and batch: 1350, loss is 3.827846941947937 and perplexity is 45.96346960389764
At time: 311.89543294906616 and batch: 1400, loss is 3.844940686225891 and perplexity is 46.75591099912076
At time: 313.01474356651306 and batch: 1450, loss is 3.784091424942017 and perplexity is 43.99567901722837
At time: 314.1356158256531 and batch: 1500, loss is 3.7686265230178835 and perplexity is 43.32052421351397
At time: 315.2584056854248 and batch: 1550, loss is 3.789382662773132 and perplexity is 44.22908758400402
At time: 316.38478803634644 and batch: 1600, loss is 3.859007353782654 and perplexity is 47.41825844453573
At time: 317.50352454185486 and batch: 1650, loss is 3.8129121685028076 and perplexity is 45.282116192494136
At time: 318.6214175224304 and batch: 1700, loss is 3.802621479034424 and perplexity is 44.818521442243295
At time: 319.73909425735474 and batch: 1750, loss is 3.7858575439453124 and perplexity is 44.07344927755599
At time: 320.86001086235046 and batch: 1800, loss is 3.743305263519287 and perplexity is 42.23736532505385
At time: 321.9813582897186 and batch: 1850, loss is 3.7715928840637205 and perplexity is 43.44921931272186
At time: 323.10010719299316 and batch: 1900, loss is 3.8731391620635987 and perplexity is 48.09312146806409
At time: 324.21970224380493 and batch: 1950, loss is 3.7939768028259278 and perplexity is 44.432749674646594
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3587390988372094 and perplexity of 78.15852209455846
finished 7 epochs...
Completing Train Step...
At time: 327.8161082267761 and batch: 50, loss is 3.993579778671265 and perplexity is 54.248740668717204
At time: 328.9598820209503 and batch: 100, loss is 3.961223130226135 and perplexity is 52.521527345379766
At time: 330.07815742492676 and batch: 150, loss is 3.91688467502594 and perplexity is 50.243675334416665
At time: 331.20233821868896 and batch: 200, loss is 3.9108734941482544 and perplexity is 49.94255745775581
At time: 332.3257555961609 and batch: 250, loss is 3.9021575117111205 and perplexity is 49.50915053143139
At time: 333.45591259002686 and batch: 300, loss is 3.916545901298523 and perplexity is 50.226656980092926
At time: 334.5733788013458 and batch: 350, loss is 3.942050824165344 and perplexity is 51.524160014806014
At time: 335.7005035877228 and batch: 400, loss is 3.88698073387146 and perplexity is 48.76343425157353
At time: 336.81882977485657 and batch: 450, loss is 3.910710406303406 and perplexity is 49.93441309783491
At time: 337.991357088089 and batch: 500, loss is 3.9334330940246582 and perplexity is 51.082046451898215
At time: 339.11002016067505 and batch: 550, loss is 3.8911088371276854 and perplexity is 48.965150810225275
At time: 340.22751784324646 and batch: 600, loss is 3.866859540939331 and perplexity is 47.79206114825797
At time: 341.3461751937866 and batch: 650, loss is 3.920522065162659 and perplexity is 50.4267639640339
At time: 342.46562337875366 and batch: 700, loss is 3.959031047821045 and perplexity is 52.406521926127745
At time: 343.5856354236603 and batch: 750, loss is 3.8917363262176514 and perplexity is 48.99588554999571
At time: 344.70710492134094 and batch: 800, loss is 3.8901967287063597 and perplexity is 48.920509645705735
At time: 345.8296399116516 and batch: 850, loss is 3.8817524576187132 and perplexity is 48.509150857422625
At time: 346.94968366622925 and batch: 900, loss is 3.8508073568344114 and perplexity is 47.031018722099866
At time: 348.06918692588806 and batch: 950, loss is 3.9471970891952513 and perplexity is 51.79000045365198
At time: 349.19277024269104 and batch: 1000, loss is 3.914990029335022 and perplexity is 50.148571493938576
At time: 350.31710958480835 and batch: 1050, loss is 3.8650523138046267 and perplexity is 47.70576803763953
At time: 351.4399428367615 and batch: 1100, loss is 3.8854793071746827 and perplexity is 48.69027446533334
At time: 352.56064200401306 and batch: 1150, loss is 3.8558261823654174 and perplexity is 47.26765251476548
At time: 353.6879563331604 and batch: 1200, loss is 3.9073872661590574 and perplexity is 49.76874945928441
At time: 354.80562925338745 and batch: 1250, loss is 3.895211157798767 and perplexity is 49.16643414266079
At time: 355.938711643219 and batch: 1300, loss is 3.882124185562134 and perplexity is 48.52718641626085
At time: 357.06342816352844 and batch: 1350, loss is 3.773090190887451 and perplexity is 43.51432485460713
At time: 358.1973783969879 and batch: 1400, loss is 3.7935952949523926 and perplexity is 44.41580146394637
At time: 359.32030868530273 and batch: 1450, loss is 3.7322027397155764 and perplexity is 41.77101757998987
At time: 360.448086977005 and batch: 1500, loss is 3.721753487586975 and perplexity is 41.33681418676238
At time: 361.5724153518677 and batch: 1550, loss is 3.7471439743041994 and perplexity is 42.39981395201877
At time: 362.70352959632874 and batch: 1600, loss is 3.819347162246704 and perplexity is 45.57444588802466
At time: 363.8297369480133 and batch: 1650, loss is 3.775675210952759 and perplexity is 43.62695577135477
At time: 364.9557206630707 and batch: 1700, loss is 3.771285376548767 and perplexity is 43.43586040535181
At time: 366.0874183177948 and batch: 1750, loss is 3.7581347227096558 and perplexity is 42.86838992305289
At time: 367.2050127983093 and batch: 1800, loss is 3.7191592931747435 and perplexity is 41.2297174293465
At time: 368.3281741142273 and batch: 1850, loss is 3.7506507873535155 and perplexity is 42.548763188793025
At time: 369.4462356567383 and batch: 1900, loss is 3.854085102081299 and perplexity is 47.18542733798372
At time: 370.5757818222046 and batch: 1950, loss is 3.7800990104675294 and perplexity is 43.82038019712451
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.359306016079215 and perplexity of 78.20284407060271
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 374.18261981010437 and batch: 50, loss is 3.9659714126586914 and perplexity is 52.77150740930328
At time: 375.3323304653168 and batch: 100, loss is 3.959129514694214 and perplexity is 52.41168248654343
At time: 376.44969367980957 and batch: 150, loss is 3.9270277547836305 and perplexity is 50.75589428799842
At time: 377.5665512084961 and batch: 200, loss is 3.928670434951782 and perplexity is 50.83933850627956
At time: 378.6841368675232 and batch: 250, loss is 3.9228341293334963 and perplexity is 50.54348876386278
At time: 379.8043179512024 and batch: 300, loss is 3.934412970542908 and perplexity is 51.13212508115005
At time: 380.92445373535156 and batch: 350, loss is 3.959212718009949 and perplexity is 52.41604349373217
At time: 382.0501124858856 and batch: 400, loss is 3.9148398637771606 and perplexity is 50.14104147111343
At time: 383.1762511730194 and batch: 450, loss is 3.9479295206069946 and perplexity is 51.82794697171295
At time: 384.29357528686523 and batch: 500, loss is 3.9693789434432984 and perplexity is 52.95163466564408
At time: 385.4117784500122 and batch: 550, loss is 3.9274425220489504 and perplexity is 50.77695053789085
At time: 386.53854393959045 and batch: 600, loss is 3.8847991371154786 and perplexity is 48.6571680587372
At time: 387.6539673805237 and batch: 650, loss is 3.9256141710281374 and perplexity is 50.684197267148235
At time: 388.778972864151 and batch: 700, loss is 3.962895016670227 and perplexity is 52.609410820095505
At time: 389.91000270843506 and batch: 750, loss is 3.893556275367737 and perplexity is 49.08513676195886
At time: 391.03639554977417 and batch: 800, loss is 3.8937120246887207 and perplexity is 49.09278233406081
At time: 392.15353059768677 and batch: 850, loss is 3.8849179887771608 and perplexity is 48.66295138768604
At time: 393.2732026576996 and batch: 900, loss is 3.8412726449966432 and perplexity is 46.58472254495712
At time: 394.43399000167847 and batch: 950, loss is 3.940764808654785 and perplexity is 51.45794173385283
At time: 395.55293798446655 and batch: 1000, loss is 3.9004752683639525 and perplexity is 49.42593410708888
At time: 396.671040058136 and batch: 1050, loss is 3.8495270681381224 and perplexity is 46.97084396920254
At time: 397.79336380958557 and batch: 1100, loss is 3.868203525543213 and perplexity is 47.85633612524379
At time: 398.91909742355347 and batch: 1150, loss is 3.837264280319214 and perplexity is 46.398367727147956
At time: 400.04293751716614 and batch: 1200, loss is 3.8811114120483396 and perplexity is 48.47806424617467
At time: 401.1642732620239 and batch: 1250, loss is 3.867922649383545 and perplexity is 47.84289630888751
At time: 402.28237652778625 and batch: 1300, loss is 3.854710144996643 and perplexity is 47.21492947413891
At time: 403.3971629142761 and batch: 1350, loss is 3.7418291091918947 and perplexity is 42.175062451093446
At time: 404.51518750190735 and batch: 1400, loss is 3.757622675895691 and perplexity is 42.84644491948705
At time: 405.6365683078766 and batch: 1450, loss is 3.696919584274292 and perplexity is 40.322901552208066
At time: 406.759485244751 and batch: 1500, loss is 3.6870918464660645 and perplexity is 39.928559566841706
At time: 407.87772965431213 and batch: 1550, loss is 3.710639615058899 and perplexity is 40.87994559543804
At time: 408.99406480789185 and batch: 1600, loss is 3.778181972503662 and perplexity is 43.73645533397213
At time: 410.1103196144104 and batch: 1650, loss is 3.729464626312256 and perplexity is 41.65680023826071
At time: 411.2329866886139 and batch: 1700, loss is 3.719421396255493 and perplexity is 41.24052528162698
At time: 412.3580811023712 and batch: 1750, loss is 3.700124979019165 and perplexity is 40.45235974039584
At time: 413.4786605834961 and batch: 1800, loss is 3.6590462017059324 and perplexity is 38.82429465986572
At time: 414.59668469429016 and batch: 1850, loss is 3.6842382097244264 and perplexity is 39.81478038166366
At time: 415.71389746665955 and batch: 1900, loss is 3.796989393234253 and perplexity is 44.56680918193454
At time: 416.8283188343048 and batch: 1950, loss is 3.7259683561325074 and perplexity is 41.5114111177291
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332196186864099 and perplexity of 76.11125769654046
finished 9 epochs...
Completing Train Step...
At time: 420.4346263408661 and batch: 50, loss is 3.953436017036438 and perplexity is 52.11412457151293
At time: 421.58190178871155 and batch: 100, loss is 3.9250452280044557 and perplexity is 50.65536904828682
At time: 422.7025191783905 and batch: 150, loss is 3.885207018852234 and perplexity is 48.677018476986916
At time: 423.8193144798279 and batch: 200, loss is 3.8831573724746704 and perplexity is 48.5773499798747
At time: 424.94461011886597 and batch: 250, loss is 3.8760343170166016 and perplexity is 48.23256025794223
At time: 426.06554436683655 and batch: 300, loss is 3.8856624221801757 and perplexity is 48.6991912015787
At time: 427.1851191520691 and batch: 350, loss is 3.9097811508178713 and perplexity is 49.8880328234465
At time: 428.30476927757263 and batch: 400, loss is 3.865526628494263 and perplexity is 47.728400951337555
At time: 429.43504071235657 and batch: 450, loss is 3.9013235473632815 and perplexity is 49.46787887693262
At time: 430.5610785484314 and batch: 500, loss is 3.9251499700546266 and perplexity is 50.66067507337023
At time: 431.6825752258301 and batch: 550, loss is 3.8837386846542357 and perplexity is 48.605596794382215
At time: 432.80793380737305 and batch: 600, loss is 3.8421303749084474 and perplexity is 46.62469679602169
At time: 433.93907356262207 and batch: 650, loss is 3.886634120941162 and perplexity is 48.74653514363005
At time: 435.05904507637024 and batch: 700, loss is 3.9276329565048216 and perplexity is 50.786621139615995
At time: 436.17921113967896 and batch: 750, loss is 3.858962364196777 and perplexity is 47.416125164713364
At time: 437.2963013648987 and batch: 800, loss is 3.85918044090271 and perplexity is 47.42646664467435
At time: 438.4143407344818 and batch: 850, loss is 3.8518381786346434 and perplexity is 47.07952431750317
At time: 439.5355899333954 and batch: 900, loss is 3.8101674699783326 and perplexity is 45.15800084252169
At time: 440.6590497493744 and batch: 950, loss is 3.9099322843551634 and perplexity is 49.89557314809927
At time: 441.78095960617065 and batch: 1000, loss is 3.8714229965209963 and perplexity is 48.01065649217927
At time: 442.90748953819275 and batch: 1050, loss is 3.8229749631881713 and perplexity is 45.74008116998037
At time: 444.03244853019714 and batch: 1100, loss is 3.843182544708252 and perplexity is 46.67377971116786
At time: 445.16299653053284 and batch: 1150, loss is 3.813993716239929 and perplexity is 45.33111745662079
At time: 446.2856638431549 and batch: 1200, loss is 3.8600616550445555 and perplexity is 47.46827793742494
At time: 447.40542244911194 and batch: 1250, loss is 3.8484226179122927 and perplexity is 46.91899564718925
At time: 448.53543496131897 and batch: 1300, loss is 3.835986752510071 and perplexity is 46.33913036882065
At time: 449.65937328338623 and batch: 1350, loss is 3.7242517852783203 and perplexity is 41.440214963392265
At time: 450.7813332080841 and batch: 1400, loss is 3.742744011878967 and perplexity is 42.2136661856949
At time: 451.9089570045471 and batch: 1450, loss is 3.6823892641067504 and perplexity is 39.74123303143611
At time: 453.03912806510925 and batch: 1500, loss is 3.6749104928970335 and perplexity is 39.44512608022648
At time: 454.16362619400024 and batch: 1550, loss is 3.7000237464904786 and perplexity is 40.44826485299939
At time: 455.28371834754944 and batch: 1600, loss is 3.77185142993927 and perplexity is 43.460454381498764
At time: 456.4184880256653 and batch: 1650, loss is 3.7244249105453493 and perplexity is 41.44738993273986
At time: 457.54453325271606 and batch: 1700, loss is 3.7173481798171997 and perplexity is 41.15511331602814
At time: 458.6726725101471 and batch: 1750, loss is 3.7000280618667603 and perplexity is 40.44843940285879
At time: 459.79249835014343 and batch: 1800, loss is 3.6612353420257566 and perplexity is 38.9093795861361
At time: 460.9256417751312 and batch: 1850, loss is 3.687524175643921 and perplexity is 39.94582558020398
At time: 462.05641531944275 and batch: 1900, loss is 3.8002051734924316 and perplexity is 44.71035693237764
At time: 463.18061900138855 and batch: 1950, loss is 3.728773717880249 and perplexity is 41.62802914396599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.331737713481105 and perplexity of 76.07637070872914
finished 10 epochs...
Completing Train Step...
At time: 466.8602533340454 and batch: 50, loss is 3.9350690269470214 and perplexity is 51.16568164556138
At time: 467.9815514087677 and batch: 100, loss is 3.90379497051239 and perplexity is 49.590286135688224
At time: 469.10106897354126 and batch: 150, loss is 3.8635161685943604 and perplexity is 47.6325413084108
At time: 470.21969389915466 and batch: 200, loss is 3.8613254261016845 and perplexity is 47.52830489539091
At time: 471.34487652778625 and batch: 250, loss is 3.8538960123062136 and perplexity is 47.176505899644035
At time: 472.4627525806427 and batch: 300, loss is 3.8634137773513793 and perplexity is 47.62766440298035
At time: 473.58938431739807 and batch: 350, loss is 3.8868698930740355 and perplexity is 48.7580295731709
At time: 474.7082257270813 and batch: 400, loss is 3.8424689531326295 and perplexity is 46.64048557578359
At time: 475.82870149612427 and batch: 450, loss is 3.879612059593201 and perplexity is 48.405433005048245
At time: 476.94761991500854 and batch: 500, loss is 3.9033255529403688 and perplexity is 49.56701304680037
At time: 478.0917205810547 and batch: 550, loss is 3.8619593238830565 and perplexity is 47.55844253349826
At time: 479.20936369895935 and batch: 600, loss is 3.8210285806655886 and perplexity is 45.651140060199154
At time: 480.326771736145 and batch: 650, loss is 3.8663475561141967 and perplexity is 47.767598600949036
At time: 481.4465479850769 and batch: 700, loss is 3.9087117767333983 and perplexity is 49.83471236885719
At time: 482.5674271583557 and batch: 750, loss is 3.8403351497650147 and perplexity is 46.54107005490229
At time: 483.68640398979187 and batch: 800, loss is 3.8409002113342283 and perplexity is 46.56737605653573
At time: 484.80477690696716 and batch: 850, loss is 3.8339239072799685 and perplexity is 46.24363844116844
At time: 485.9230008125305 and batch: 900, loss is 3.7924724435806274 and perplexity is 44.36595710948239
At time: 487.04106307029724 and batch: 950, loss is 3.8924088859558106 and perplexity is 49.02884929375297
At time: 488.1600785255432 and batch: 1000, loss is 3.8545911741256713 and perplexity is 47.20931260698492
At time: 489.2807309627533 and batch: 1050, loss is 3.807685904502869 and perplexity is 45.04607723700461
At time: 490.4002277851105 and batch: 1100, loss is 3.828539752960205 and perplexity is 45.99532463528537
At time: 491.5180666446686 and batch: 1150, loss is 3.7997071075439455 and perplexity is 44.68809377076656
At time: 492.63704562187195 and batch: 1200, loss is 3.8471430921554566 and perplexity is 46.85899997496308
At time: 493.7565038204193 and batch: 1250, loss is 3.8361354637145997 and perplexity is 46.34602202913547
At time: 494.8807489871979 and batch: 1300, loss is 3.823399157524109 and perplexity is 45.75948796917415
At time: 496.00473141670227 and batch: 1350, loss is 3.7121058225631716 and perplexity is 40.93992804105459
At time: 497.13071942329407 and batch: 1400, loss is 3.731865110397339 and perplexity is 41.75691684034776
At time: 498.2529351711273 and batch: 1450, loss is 3.670857939720154 and perplexity is 39.28559607945589
At time: 499.384094953537 and batch: 1500, loss is 3.6643572664260864 and perplexity is 39.03104153856275
At time: 500.5122301578522 and batch: 1550, loss is 3.690051655769348 and perplexity is 40.04691555809185
At time: 501.64009046554565 and batch: 1600, loss is 3.7639724111557005 and perplexity is 43.11937409855245
At time: 502.7655200958252 and batch: 1650, loss is 3.7171312284469606 and perplexity is 41.14618562627417
At time: 503.8914895057678 and batch: 1700, loss is 3.7113690900802614 and perplexity is 40.909777374070366
At time: 505.008202791214 and batch: 1750, loss is 3.6948746490478515 and perplexity is 40.240528083301314
At time: 506.1257059574127 and batch: 1800, loss is 3.657278289794922 and perplexity is 38.7557173640706
At time: 507.2497797012329 and batch: 1850, loss is 3.6839595890045165 and perplexity is 39.803688704148
At time: 508.3670630455017 and batch: 1900, loss is 3.796730189323425 and perplexity is 44.5552587877198
At time: 509.48431634902954 and batch: 1950, loss is 3.725043983459473 and perplexity is 41.47305683323004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.332825274800145 and perplexity of 76.15915343429049
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 513.1154315471649 and batch: 50, loss is 3.929725465774536 and perplexity is 50.89300387974581
At time: 514.2326018810272 and batch: 100, loss is 3.912680983543396 and perplexity is 50.03290973151674
At time: 515.3480036258698 and batch: 150, loss is 3.8842428874969483 and perplexity is 48.63011005376591
At time: 516.4653062820435 and batch: 200, loss is 3.8884714889526366 and perplexity is 48.83618280062153
At time: 517.5841116905212 and batch: 250, loss is 3.8835963726043703 and perplexity is 48.59868012444189
At time: 518.7015595436096 and batch: 300, loss is 3.892053427696228 and perplexity is 49.011424681358335
At time: 519.8198049068451 and batch: 350, loss is 3.914972152709961 and perplexity is 50.147675014741665
At time: 520.9447548389435 and batch: 400, loss is 3.8791976022720336 and perplexity is 48.38537517579924
At time: 522.0597772598267 and batch: 450, loss is 3.9216954803466795 and perplexity is 50.4859702245194
At time: 523.1792826652527 and batch: 500, loss is 3.9452535247802736 and perplexity is 51.68944100525612
At time: 524.306972026825 and batch: 550, loss is 3.918509612083435 and perplexity is 50.32538451252914
At time: 525.4241743087769 and batch: 600, loss is 3.864842720031738 and perplexity is 47.69577025350122
At time: 526.5416357517242 and batch: 650, loss is 3.8899996185302737 and perplexity is 48.910867865712945
At time: 527.6593656539917 and batch: 700, loss is 3.930505175590515 and perplexity is 50.932701128591646
At time: 528.7826879024506 and batch: 750, loss is 3.8592899513244627 and perplexity is 47.43166062143094
At time: 529.9023461341858 and batch: 800, loss is 3.860778126716614 and perplexity is 47.502299800283616
At time: 531.0324018001556 and batch: 850, loss is 3.8614084577560424 and perplexity is 47.53225141301587
At time: 532.1942443847656 and batch: 900, loss is 3.8169059419631957 and perplexity is 45.46332431761523
At time: 533.3664515018463 and batch: 950, loss is 3.918870458602905 and perplexity is 50.343547529205075
At time: 534.4929585456848 and batch: 1000, loss is 3.872743158340454 and perplexity is 48.07408018336374
At time: 535.6131646633148 and batch: 1050, loss is 3.822319598197937 and perplexity is 45.71011454274284
At time: 536.7334101200104 and batch: 1100, loss is 3.8425624990463256 and perplexity is 46.64484880670004
At time: 537.8602550029755 and batch: 1150, loss is 3.8183252239227294 and perplexity is 45.52789540509031
At time: 538.9836826324463 and batch: 1200, loss is 3.8645454835891724 and perplexity is 47.6815954391657
At time: 540.1074655056 and batch: 1250, loss is 3.850544562339783 and perplexity is 47.01866085316401
At time: 541.2394165992737 and batch: 1300, loss is 3.834888286590576 and perplexity is 46.28825636016931
At time: 542.3615140914917 and batch: 1350, loss is 3.7149235105514524 and perplexity is 41.05544665581487
At time: 543.4795427322388 and batch: 1400, loss is 3.7310303831100464 and perplexity is 41.72207574585708
At time: 544.5994296073914 and batch: 1450, loss is 3.666876435279846 and perplexity is 39.129491276427906
At time: 545.7209153175354 and batch: 1500, loss is 3.6575820207595826 and perplexity is 38.767490463328585
At time: 546.8411333560944 and batch: 1550, loss is 3.6856609535217286 and perplexity is 39.87146692914745
At time: 547.9616932868958 and batch: 1600, loss is 3.757203149795532 and perplexity is 42.82847348755026
At time: 549.0815815925598 and batch: 1650, loss is 3.7044004011154175 and perplexity is 40.62568089961766
At time: 550.1991720199585 and batch: 1700, loss is 3.6946459913253786 and perplexity is 40.23132782769351
At time: 551.3183562755585 and batch: 1750, loss is 3.678870677947998 and perplexity is 39.601645797826684
At time: 552.4396569728851 and batch: 1800, loss is 3.6414915895462037 and perplexity is 38.14869650603953
At time: 553.5599529743195 and batch: 1850, loss is 3.66718780040741 and perplexity is 39.14167673243528
At time: 554.6874206066132 and batch: 1900, loss is 3.7898359203338625 and perplexity is 44.24913929630749
At time: 555.8126354217529 and batch: 1950, loss is 3.7271370458602906 and perplexity is 41.559953437418294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.318422681231832 and perplexity of 75.07012534049899
finished 12 epochs...
Completing Train Step...
At time: 559.4520306587219 and batch: 50, loss is 3.936457858085632 and perplexity is 51.23679150582304
At time: 560.5693719387054 and batch: 100, loss is 3.9070292568206786 and perplexity is 49.75093497128535
At time: 561.7103173732758 and batch: 150, loss is 3.87022677898407 and perplexity is 47.95325963932922
At time: 562.8281784057617 and batch: 200, loss is 3.8676467180252074 and perplexity is 47.82969677468866
At time: 563.9443917274475 and batch: 250, loss is 3.8593419075012205 and perplexity is 47.43412505319478
At time: 565.0600345134735 and batch: 300, loss is 3.8653881883621217 and perplexity is 47.72179388255526
At time: 566.1807644367218 and batch: 350, loss is 3.8882458543777467 and perplexity is 48.82516491233108
At time: 567.3053846359253 and batch: 400, loss is 3.8521691370010376 and perplexity is 47.09510825863751
At time: 568.4211401939392 and batch: 450, loss is 3.896118950843811 and perplexity is 49.211087354496165
At time: 569.5380961894989 and batch: 500, loss is 3.921950340270996 and perplexity is 50.49883871483145
At time: 570.652393579483 and batch: 550, loss is 3.8939387655258177 and perplexity is 49.10391493468255
At time: 571.7662961483002 and batch: 600, loss is 3.844148373603821 and perplexity is 46.718880372533384
At time: 572.880303144455 and batch: 650, loss is 3.871527614593506 and perplexity is 48.01567953726747
At time: 573.9977879524231 and batch: 700, loss is 3.913171944618225 and perplexity is 50.05747997367806
At time: 575.1154839992523 and batch: 750, loss is 3.8444368553161623 and perplexity is 46.73235985934116
At time: 576.2322981357574 and batch: 800, loss is 3.8465202856063843 and perplexity is 46.82982496903113
At time: 577.347588300705 and batch: 850, loss is 3.8472104501724242 and perplexity is 46.86215641058291
At time: 578.4770088195801 and batch: 900, loss is 3.8030423402786253 and perplexity is 44.83738779071972
At time: 579.5969777107239 and batch: 950, loss is 3.905442924499512 and perplexity is 49.67207601992087
At time: 580.7281131744385 and batch: 1000, loss is 3.8593370485305787 and perplexity is 47.43389457273367
At time: 581.8489060401917 and batch: 1050, loss is 3.8095604848861693 and perplexity is 45.130598926337
At time: 582.9686818122864 and batch: 1100, loss is 3.8308735275268555 and perplexity is 46.10279270845488
At time: 584.0991635322571 and batch: 1150, loss is 3.8077098083496095 and perplexity is 45.04715402440078
At time: 585.215372800827 and batch: 1200, loss is 3.854951229095459 and perplexity is 47.22631361507438
At time: 586.3320202827454 and batch: 1250, loss is 3.842784252166748 and perplexity is 46.655193594426635
At time: 587.4542784690857 and batch: 1300, loss is 3.8281318950653076 and perplexity is 45.976568904101015
At time: 588.5757718086243 and batch: 1350, loss is 3.7096514320373535 and perplexity is 40.839568680455535
At time: 589.700083732605 and batch: 1400, loss is 3.726729292869568 and perplexity is 41.54301069657126
At time: 590.8232929706573 and batch: 1450, loss is 3.664266571998596 and perplexity is 39.02750180111571
At time: 591.9484610557556 and batch: 1500, loss is 3.657139220237732 and perplexity is 38.75032799837523
At time: 593.0755398273468 and batch: 1550, loss is 3.685832796096802 and perplexity is 39.878319133429855
At time: 594.2019984722137 and batch: 1600, loss is 3.758468656539917 and perplexity is 42.882707519128815
At time: 595.3188908100128 and batch: 1650, loss is 3.7068529510498047 and perplexity is 40.725439692348644
At time: 596.4364175796509 and batch: 1700, loss is 3.6980186128616332 and perplexity is 40.3672419349495
At time: 597.5546112060547 and batch: 1750, loss is 3.6834305906295777 and perplexity is 39.78263818584282
At time: 598.6707906723022 and batch: 1800, loss is 3.6464543104171754 and perplexity is 38.33848839093907
At time: 599.7854084968567 and batch: 1850, loss is 3.672374954223633 and perplexity is 39.34523812597302
At time: 600.9053649902344 and batch: 1900, loss is 3.7954307842254638 and perplexity is 44.49740105576682
At time: 602.0281662940979 and batch: 1950, loss is 3.731763458251953 and perplexity is 41.752672375899365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.317019724291424 and perplexity of 74.96487903241739
finished 13 epochs...
Completing Train Step...
At time: 605.637727022171 and batch: 50, loss is 3.9317819976806643 and perplexity is 50.99777466132499
At time: 606.7814936637878 and batch: 100, loss is 3.9001014614105225 and perplexity is 49.407461801993016
At time: 607.9042937755585 and batch: 150, loss is 3.8622739696502686 and perplexity is 47.57340895057304
At time: 609.030380487442 and batch: 200, loss is 3.8585693073272704 and perplexity is 47.39749159325851
At time: 610.1504120826721 and batch: 250, loss is 3.8499857902526857 and perplexity is 46.99239547676956
At time: 611.2787446975708 and batch: 300, loss is 3.8559514570236204 and perplexity is 47.27357432469694
At time: 612.4045770168304 and batch: 350, loss is 3.878800072669983 and perplexity is 48.366144379519184
At time: 613.5204102993011 and batch: 400, loss is 3.8424762153625487 and perplexity is 46.6408242909433
At time: 614.6422758102417 and batch: 450, loss is 3.8867768335342405 and perplexity is 48.75349238449513
At time: 615.7727444171906 and batch: 500, loss is 3.9129174041748045 and perplexity is 50.044739942024485
At time: 616.8925220966339 and batch: 550, loss is 3.884890956878662 and perplexity is 48.66163595350291
At time: 618.0569596290588 and batch: 600, loss is 3.8357615661621094 and perplexity is 46.32869660409996
At time: 619.1801097393036 and batch: 650, loss is 3.8632892179489136 and perplexity is 47.62173229901881
At time: 620.2992947101593 and batch: 700, loss is 3.905589389801025 and perplexity is 49.67935178832272
At time: 621.4182238578796 and batch: 750, loss is 3.837402868270874 and perplexity is 46.404798427490135
At time: 622.5426995754242 and batch: 800, loss is 3.8395726108551025 and perplexity is 46.50559420565318
At time: 623.6706805229187 and batch: 850, loss is 3.8402969312667845 and perplexity is 46.53929135908852
At time: 624.7895936965942 and batch: 900, loss is 3.7961399269104006 and perplexity is 44.52896725337043
At time: 625.9097836017609 and batch: 950, loss is 3.8986863803863527 and perplexity is 49.33759568511138
At time: 627.0401229858398 and batch: 1000, loss is 3.8527385425567626 and perplexity is 47.121932111027995
At time: 628.1891207695007 and batch: 1050, loss is 3.803349928855896 and perplexity is 44.85118138030535
At time: 629.3171019554138 and batch: 1100, loss is 3.825085620880127 and perplexity is 45.836724779042946
At time: 630.4462957382202 and batch: 1150, loss is 3.8023782062530516 and perplexity is 44.807619641984445
At time: 631.5911557674408 and batch: 1200, loss is 3.8501429605484008 and perplexity is 46.99978186590828
At time: 632.7275056838989 and batch: 1250, loss is 3.8386258983612063 and perplexity is 46.46158761266512
At time: 633.8486759662628 and batch: 1300, loss is 3.8244964504241943 and perplexity is 45.80972708890808
At time: 634.9674060344696 and batch: 1350, loss is 3.7064566230773925 and perplexity is 40.70930225947904
At time: 636.0871636867523 and batch: 1400, loss is 3.7240411615371705 and perplexity is 41.43148758941096
At time: 637.2067286968231 and batch: 1450, loss is 3.661839084625244 and perplexity is 38.932877928873374
At time: 638.3260400295258 and batch: 1500, loss is 3.6555254793167116 and perplexity is 38.68784543727369
At time: 639.4447767734528 and batch: 1550, loss is 3.6845920133590697 and perplexity is 39.82886948791675
At time: 640.5617997646332 and batch: 1600, loss is 3.7578853940963746 and perplexity is 42.85770293918057
At time: 641.6775186061859 and batch: 1650, loss is 3.706722388267517 and perplexity is 40.720122812733365
At time: 642.7972855567932 and batch: 1700, loss is 3.6983494091033937 and perplexity is 40.38059747573138
At time: 643.9184348583221 and batch: 1750, loss is 3.684251403808594 and perplexity is 39.81530570469269
At time: 645.0377471446991 and batch: 1800, loss is 3.64758752822876 and perplexity is 38.38195887496429
At time: 646.1567649841309 and batch: 1850, loss is 3.673538575172424 and perplexity is 39.391047716622346
At time: 647.2754888534546 and batch: 1900, loss is 3.7967840528488157 and perplexity is 44.55765875566758
At time: 648.3917741775513 and batch: 1950, loss is 3.732518434524536 and perplexity is 41.784206555140806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.316722213390261 and perplexity of 74.94257948104517
finished 14 epochs...
Completing Train Step...
At time: 652.020665884018 and batch: 50, loss is 3.92686683177948 and perplexity is 50.74772715416873
At time: 653.1645231246948 and batch: 100, loss is 3.894034948348999 and perplexity is 49.10863811499098
At time: 654.2833843231201 and batch: 150, loss is 3.855665798187256 and perplexity is 47.26007213906569
At time: 655.3973953723907 and batch: 200, loss is 3.851532664299011 and perplexity is 47.06514304486376
At time: 656.5206077098846 and batch: 250, loss is 3.842923412322998 and perplexity is 46.661686590229785
At time: 657.6475896835327 and batch: 300, loss is 3.84893319606781 and perplexity is 46.942957578144224
At time: 658.7724094390869 and batch: 350, loss is 3.87180814743042 and perplexity is 48.02915140162623
At time: 659.8895280361176 and batch: 400, loss is 3.8354400491714475 and perplexity is 46.31380353530215
At time: 661.009515285492 and batch: 450, loss is 3.880092968940735 and perplexity is 48.42871722860344
At time: 662.1260719299316 and batch: 500, loss is 3.9063046646118162 and perplexity is 49.71489888873055
At time: 663.2434141635895 and batch: 550, loss is 3.8785074234008787 and perplexity is 48.35199213364034
At time: 664.3617269992828 and batch: 600, loss is 3.829713535308838 and perplexity is 46.049344833237065
At time: 665.4825437068939 and batch: 650, loss is 3.8572748422622682 and perplexity is 47.33617688965497
At time: 666.6019098758698 and batch: 700, loss is 3.900053091049194 and perplexity is 49.40507200301152
At time: 667.7193584442139 and batch: 750, loss is 3.832152581214905 and perplexity is 46.1617983831666
At time: 668.8345091342926 and batch: 800, loss is 3.8343197298049927 and perplexity is 46.261946338002474
At time: 669.9508833885193 and batch: 850, loss is 3.835144629478455 and perplexity is 46.30012354644897
At time: 671.0673003196716 and batch: 900, loss is 3.7909994602203367 and perplexity is 44.30065489923837
At time: 672.1846075057983 and batch: 950, loss is 3.893639855384827 and perplexity is 49.0892394699781
At time: 673.303722858429 and batch: 1000, loss is 3.8477741384506228 and perplexity is 46.88857950533741
At time: 674.476348400116 and batch: 1050, loss is 3.798642840385437 and perplexity is 44.64055899952468
At time: 675.5898687839508 and batch: 1100, loss is 3.8206169843673705 and perplexity is 45.63235408632481
At time: 676.7106258869171 and batch: 1150, loss is 3.7981002616882322 and perplexity is 44.616344552895725
At time: 677.8376660346985 and batch: 1200, loss is 3.8462590885162355 and perplexity is 46.81759475233508
At time: 678.957358121872 and batch: 1250, loss is 3.835117802619934 and perplexity is 46.29888147624559
At time: 680.0816316604614 and batch: 1300, loss is 3.8212680292129515 and perplexity is 45.6620724681944
At time: 681.1989328861237 and batch: 1350, loss is 3.7034744310379026 and perplexity is 40.588080145998966
At time: 682.324887752533 and batch: 1400, loss is 3.721468963623047 and perplexity is 41.325054545563006
At time: 683.4413998126984 and batch: 1450, loss is 3.6592261743545533 and perplexity is 38.83128259980666
At time: 684.5656278133392 and batch: 1500, loss is 3.653364882469177 and perplexity is 38.60434683627326
At time: 685.6916408538818 and batch: 1550, loss is 3.6826308393478393 and perplexity is 39.75083468910154
At time: 686.8205525875092 and batch: 1600, loss is 3.7564749622344973 and perplexity is 42.79729767819441
At time: 687.9509742259979 and batch: 1650, loss is 3.7055512952804563 and perplexity is 40.67246367456325
At time: 689.0681388378143 and batch: 1700, loss is 3.6974901151657105 and perplexity is 40.34591357708655
At time: 690.1824901103973 and batch: 1750, loss is 3.68371919631958 and perplexity is 39.79412133855847
At time: 691.2983319759369 and batch: 1800, loss is 3.647349057197571 and perplexity is 38.3728069809265
At time: 692.4165933132172 and batch: 1850, loss is 3.673322010040283 and perplexity is 39.3825179128308
At time: 693.5473830699921 and batch: 1900, loss is 3.796808648109436 and perplexity is 44.55875467637448
At time: 694.6733293533325 and batch: 1950, loss is 3.7321849870681763 and perplexity is 41.7702760404254
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.316767351017442 and perplexity of 74.94596228760311
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 698.2668964862823 and batch: 50, loss is 3.927317991256714 and perplexity is 50.77062763771907
At time: 699.4273219108582 and batch: 100, loss is 3.9020812940597533 and perplexity is 49.505377204055605
At time: 700.5569632053375 and batch: 150, loss is 3.868515954017639 and perplexity is 47.871290143239904
At time: 701.7063364982605 and batch: 200, loss is 3.8661814737319946 and perplexity is 47.75966590314023
At time: 702.8381769657135 and batch: 250, loss is 3.8570760345458983 and perplexity is 47.32676702783342
At time: 703.9667630195618 and batch: 300, loss is 3.8605982065200806 and perplexity is 47.493753945976714
At time: 705.0919411182404 and batch: 350, loss is 3.8815567779541014 and perplexity is 48.49965953171224
At time: 706.2109117507935 and batch: 400, loss is 3.84750629901886 and perplexity is 46.876022576541935
At time: 707.3365573883057 and batch: 450, loss is 3.894803075790405 and perplexity is 49.14637429878092
At time: 708.4541590213776 and batch: 500, loss is 3.925645627975464 and perplexity is 50.68579166234923
At time: 709.5682878494263 and batch: 550, loss is 3.901441912651062 and perplexity is 49.47373450319639
At time: 710.6854944229126 and batch: 600, loss is 3.8519398260116575 and perplexity is 47.08431007088664
At time: 711.8019018173218 and batch: 650, loss is 3.8764105892181395 and perplexity is 48.25071224440609
At time: 712.9220390319824 and batch: 700, loss is 3.9202765464782714 and perplexity is 50.414384771011306
At time: 714.0385963916779 and batch: 750, loss is 3.8526702690124512 and perplexity is 47.11871503952966
At time: 715.1575038433075 and batch: 800, loss is 3.8503913640975953 and perplexity is 47.01145822870008
At time: 716.2758867740631 and batch: 850, loss is 3.8525524950027465 and perplexity is 47.113166006299686
At time: 717.3923914432526 and batch: 900, loss is 3.8056487131118772 and perplexity is 44.95440316677785
At time: 718.5093429088593 and batch: 950, loss is 3.9148711442947386 and perplexity is 50.14260993337358
At time: 719.6301622390747 and batch: 1000, loss is 3.8687846326828 and perplexity is 47.884153865601625
At time: 720.75577044487 and batch: 1050, loss is 3.816468653678894 and perplexity is 45.44344808466437
At time: 721.8819251060486 and batch: 1100, loss is 3.833192491531372 and perplexity is 46.209827482181424
At time: 722.9997072219849 and batch: 1150, loss is 3.811984782218933 and perplexity is 45.240141645350384
At time: 724.1223957538605 and batch: 1200, loss is 3.856441411972046 and perplexity is 47.296741921442965
At time: 725.2490363121033 and batch: 1250, loss is 3.842676591873169 and perplexity is 46.650170952961666
At time: 726.3768334388733 and batch: 1300, loss is 3.827844543457031 and perplexity is 45.963359361066004
At time: 727.4970762729645 and batch: 1350, loss is 3.702896375656128 and perplexity is 40.56462476774161
At time: 728.6161994934082 and batch: 1400, loss is 3.7223563766479493 and perplexity is 41.361743213814876
At time: 729.7423076629639 and batch: 1450, loss is 3.657405276298523 and perplexity is 38.76063912960549
At time: 730.8599514961243 and batch: 1500, loss is 3.650575728416443 and perplexity is 38.496823385281736
At time: 731.9764199256897 and batch: 1550, loss is 3.6813815784454347 and perplexity is 39.70120653119951
At time: 733.0983831882477 and batch: 1600, loss is 3.7499486923217775 and perplexity is 42.5189003980368
At time: 734.2170586585999 and batch: 1650, loss is 3.697163529396057 and perplexity is 40.33273932722697
At time: 735.3390803337097 and batch: 1700, loss is 3.6870747423171997 and perplexity is 39.92787662865547
At time: 736.4563894271851 and batch: 1750, loss is 3.6749321269989013 and perplexity is 39.445979449333194
At time: 737.5720875263214 and batch: 1800, loss is 3.63907648563385 and perplexity is 38.05667460581046
At time: 738.6935241222382 and batch: 1850, loss is 3.6654246759414675 and perplexity is 39.07272588687346
At time: 739.8122231960297 and batch: 1900, loss is 3.7942867136001586 and perplexity is 44.4465219964847
At time: 740.9269652366638 and batch: 1950, loss is 3.74134624004364 and perplexity is 42.15470233064271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314261786882267 and perplexity of 74.75841542588023
finished 16 epochs...
Completing Train Step...
At time: 744.5624878406525 and batch: 50, loss is 3.940022892951965 and perplexity is 51.41977843757063
At time: 745.6852939128876 and batch: 100, loss is 3.911942791938782 and perplexity is 49.99598948638259
At time: 746.8100707530975 and batch: 150, loss is 3.8729909753799436 and perplexity is 48.085995235906516
At time: 747.9320001602173 and batch: 200, loss is 3.8651155614852906 and perplexity is 47.708785412242165
At time: 749.0509009361267 and batch: 250, loss is 3.854457712173462 and perplexity is 47.203012380391556
At time: 750.1870186328888 and batch: 300, loss is 3.8569781160354615 and perplexity is 47.3221330881802
At time: 751.3170220851898 and batch: 350, loss is 3.873967251777649 and perplexity is 48.1329633813309
At time: 752.4452872276306 and batch: 400, loss is 3.837592558860779 and perplexity is 46.41360181601185
At time: 753.5692925453186 and batch: 450, loss is 3.8835420036315917 and perplexity is 48.59603793595232
At time: 754.6942236423492 and batch: 500, loss is 3.914028697013855 and perplexity is 50.100385216525055
At time: 755.8135216236115 and batch: 550, loss is 3.887681694030762 and perplexity is 48.79762745885258
At time: 756.9385206699371 and batch: 600, loss is 3.8401811838150026 and perplexity is 46.53390486644839
At time: 758.09738945961 and batch: 650, loss is 3.8651982402801512 and perplexity is 47.712730080192266
At time: 759.2265615463257 and batch: 700, loss is 3.9093895053863523 and perplexity is 49.868498228870784
At time: 760.3491623401642 and batch: 750, loss is 3.8424231243133544 and perplexity is 46.638348146377545
At time: 761.4655940532684 and batch: 800, loss is 3.8409071350097657 and perplexity is 46.56769847505433
At time: 762.5923433303833 and batch: 850, loss is 3.8434789276123045 and perplexity is 46.687615071722654
At time: 763.7259600162506 and batch: 900, loss is 3.7980722332000734 and perplexity is 44.61509404173579
At time: 764.8467769622803 and batch: 950, loss is 3.9069476652145387 and perplexity is 49.7468758781903
At time: 765.9661102294922 and batch: 1000, loss is 3.8611765050888063 and perplexity is 47.521227459088074
At time: 767.0854179859161 and batch: 1050, loss is 3.8093957710266113 and perplexity is 45.123165903381434
At time: 768.2040705680847 and batch: 1100, loss is 3.826554980278015 and perplexity is 45.90412490674447
At time: 769.323112487793 and batch: 1150, loss is 3.805508990287781 and perplexity is 44.948122449401815
At time: 770.4440975189209 and batch: 1200, loss is 3.8511343812942505 and perplexity is 47.04640153073339
At time: 771.5639700889587 and batch: 1250, loss is 3.8385681772232054 and perplexity is 46.45890587435203
At time: 772.6829023361206 and batch: 1300, loss is 3.8242595911026003 and perplexity is 45.798877912942345
At time: 773.8137667179108 and batch: 1350, loss is 3.7006797075271605 and perplexity is 40.474806042785836
At time: 774.9325819015503 and batch: 1400, loss is 3.7205307865142823 and perplexity is 41.286302506350346
At time: 776.0510818958282 and batch: 1450, loss is 3.656938223838806 and perplexity is 38.742540104685865
At time: 777.1705195903778 and batch: 1500, loss is 3.6517719221115112 and perplexity is 38.5429005958355
At time: 778.296334028244 and batch: 1550, loss is 3.6829292154312134 and perplexity is 39.76269715711729
At time: 779.4115722179413 and batch: 1600, loss is 3.7520176124572755 and perplexity is 42.60695966959859
At time: 780.5277836322784 and batch: 1650, loss is 3.699701452255249 and perplexity is 40.43523071093947
At time: 781.6456861495972 and batch: 1700, loss is 3.6899604034423827 and perplexity is 40.04326135058939
At time: 782.7596852779388 and batch: 1750, loss is 3.6786511659622194 and perplexity is 39.59295371596048
At time: 783.8753340244293 and batch: 1800, loss is 3.6431843614578248 and perplexity is 38.213328235904974
At time: 784.9915187358856 and batch: 1850, loss is 3.670011281967163 and perplexity is 39.25234870151556
At time: 786.1084988117218 and batch: 1900, loss is 3.799413743019104 and perplexity is 44.67498579217339
At time: 787.2260739803314 and batch: 1950, loss is 3.7466143798828124 and perplexity is 42.377365191975656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.31336187318314 and perplexity of 74.69116956598691
finished 17 epochs...
Completing Train Step...
At time: 790.8428282737732 and batch: 50, loss is 3.94092604637146 and perplexity is 51.46623936381027
At time: 791.9593353271484 and batch: 100, loss is 3.911354217529297 and perplexity is 49.96657178449652
At time: 793.0755748748779 and batch: 150, loss is 3.871439199447632 and perplexity is 48.011434411626404
At time: 794.1918251514435 and batch: 200, loss is 3.862454514503479 and perplexity is 47.58199886011739
At time: 795.3100826740265 and batch: 250, loss is 3.851323628425598 and perplexity is 47.05530576978758
At time: 796.424013376236 and batch: 300, loss is 3.8536748552322386 and perplexity is 47.16607363526596
At time: 797.5387871265411 and batch: 350, loss is 3.8700433778762817 and perplexity is 47.944465764817124
At time: 798.6568562984467 and batch: 400, loss is 3.8330397844314574 and perplexity is 46.202771452205724
At time: 799.773494720459 and batch: 450, loss is 3.8787295913696287 and perplexity is 48.36273559089953
At time: 800.8970024585724 and batch: 500, loss is 3.909137635231018 and perplexity is 49.855939424136025
At time: 802.0200080871582 and batch: 550, loss is 3.88243905544281 and perplexity is 48.54246857147623
At time: 803.1363925933838 and batch: 600, loss is 3.8356112813949585 and perplexity is 46.32173462987085
At time: 804.2545943260193 and batch: 650, loss is 3.860933084487915 and perplexity is 47.509661221132305
At time: 805.3737547397614 and batch: 700, loss is 3.9051770067214964 and perplexity is 49.65886908789307
At time: 806.4940810203552 and batch: 750, loss is 3.838630504608154 and perplexity is 46.46180162670415
At time: 807.6127088069916 and batch: 800, loss is 3.8373116064071655 and perplexity is 46.40056363234122
At time: 808.7312481403351 and batch: 850, loss is 3.839955139160156 and perplexity is 46.52338731474715
At time: 809.857239484787 and batch: 900, loss is 3.795031633377075 and perplexity is 44.479643424606856
At time: 810.9746837615967 and batch: 950, loss is 3.9039516973495485 and perplexity is 49.59805887347045
At time: 812.106082201004 and batch: 1000, loss is 3.8582643127441405 and perplexity is 47.383037819342036
At time: 813.2518301010132 and batch: 1050, loss is 3.806689963340759 and perplexity is 45.00123632765286
At time: 814.3714997768402 and batch: 1100, loss is 3.8240080881118774 and perplexity is 45.787360806529556
At time: 815.4941759109497 and batch: 1150, loss is 3.803065438270569 and perplexity is 44.83842345630253
At time: 816.6198151111603 and batch: 1200, loss is 3.8490046405792238 and perplexity is 46.94631151462145
At time: 817.747410774231 and batch: 1250, loss is 3.836971917152405 and perplexity is 46.38480453620982
At time: 818.8672494888306 and batch: 1300, loss is 3.8230049085617064 and perplexity is 45.74145089430488
At time: 819.9934968948364 and batch: 1350, loss is 3.6999954652786253 and perplexity is 40.44712094322763
At time: 821.118536233902 and batch: 1400, loss is 3.7200013732910158 and perplexity is 41.2644507766714
At time: 822.240152835846 and batch: 1450, loss is 3.656955237388611 and perplexity is 38.74319925842877
At time: 823.3594696521759 and batch: 1500, loss is 3.6525135374069215 and perplexity is 38.57149520223501
At time: 824.4764287471771 and batch: 1550, loss is 3.6838413095474243 and perplexity is 39.798981023874234
At time: 825.595237493515 and batch: 1600, loss is 3.753084897994995 and perplexity is 42.65245773685585
At time: 826.7200486660004 and batch: 1650, loss is 3.700855507850647 and perplexity is 40.481922152270066
At time: 827.8418507575989 and batch: 1700, loss is 3.6912075757980345 and perplexity is 40.09323335454957
At time: 828.9661111831665 and batch: 1750, loss is 3.68028039932251 and perplexity is 39.657512453330874
At time: 830.0853779315948 and batch: 1800, loss is 3.644805254936218 and perplexity is 38.27531819641946
At time: 831.2027635574341 and batch: 1850, loss is 3.671683177947998 and perplexity is 39.31802943592646
At time: 832.3281106948853 and batch: 1900, loss is 3.8010478353500368 and perplexity is 44.74804852320711
At time: 833.4526867866516 and batch: 1950, loss is 3.7481507730484007 and perplexity is 42.44252352782598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312925258902617 and perplexity of 74.65856545295406
finished 18 epochs...
Completing Train Step...
At time: 837.0953588485718 and batch: 50, loss is 3.940161356925964 and perplexity is 51.42689871737498
At time: 838.2147128582001 and batch: 100, loss is 3.9099448251724245 and perplexity is 49.896198883287866
At time: 839.3374817371368 and batch: 150, loss is 3.8697279357910155 and perplexity is 47.92934444763459
At time: 840.4623787403107 and batch: 200, loss is 3.860265402793884 and perplexity is 47.47795047756488
At time: 841.6068749427795 and batch: 250, loss is 3.84893253326416 and perplexity is 46.9429264641909
At time: 842.7325150966644 and batch: 300, loss is 3.8512381505966187 and perplexity is 47.051283756307356
At time: 843.8588128089905 and batch: 350, loss is 3.867385287284851 and perplexity is 47.8171942559924
At time: 844.9835109710693 and batch: 400, loss is 3.830090980529785 and perplexity is 46.066729218992386
At time: 846.1144518852234 and batch: 450, loss is 3.8756879472732546 and perplexity is 48.21585685136904
At time: 847.2365112304688 and batch: 500, loss is 3.9060874366760254 and perplexity is 49.70410059675471
At time: 848.3634436130524 and batch: 550, loss is 3.879208846092224 and perplexity is 48.3859192153161
At time: 849.4885020256042 and batch: 600, loss is 3.832727656364441 and perplexity is 46.18835252085518
At time: 850.616149187088 and batch: 650, loss is 3.8582334327697754 and perplexity is 47.38157465494019
At time: 851.7343993186951 and batch: 700, loss is 3.902519817352295 and perplexity is 49.52709122576982
At time: 852.8514256477356 and batch: 750, loss is 3.836209564208984 and perplexity is 46.349456419524024
At time: 853.9707589149475 and batch: 800, loss is 3.8349838781356813 and perplexity is 46.29268133760686
At time: 855.0910842418671 and batch: 850, loss is 3.8376419162750244 and perplexity is 46.41589272791959
At time: 856.2203605175018 and batch: 900, loss is 3.7928950548172 and perplexity is 44.38471062392199
At time: 857.3482701778412 and batch: 950, loss is 3.9019356966018677 and perplexity is 49.49816987168039
At time: 858.4683227539062 and batch: 1000, loss is 3.8563364601135253 and perplexity is 47.291778300951485
At time: 859.5839011669159 and batch: 1050, loss is 3.8048956203460693 and perplexity is 44.92056107567819
At time: 860.7074913978577 and batch: 1100, loss is 3.822348647117615 and perplexity is 45.71144239147485
At time: 861.8334152698517 and batch: 1150, loss is 3.8015025424957276 and perplexity is 44.76840040734925
At time: 862.9538834095001 and batch: 1200, loss is 3.847583131790161 and perplexity is 46.87962432962863
At time: 864.0729668140411 and batch: 1250, loss is 3.835823612213135 and perplexity is 46.33157120595133
At time: 865.1935088634491 and batch: 1300, loss is 3.8220943117141726 and perplexity is 45.6998178316635
At time: 866.3108243942261 and batch: 1350, loss is 3.699363784790039 and perplexity is 40.421579354019386
At time: 867.4293954372406 and batch: 1400, loss is 3.7194545698165893 and perplexity is 41.241893399404596
At time: 868.5487322807312 and batch: 1450, loss is 3.6566661596298218 and perplexity is 38.73200107986898
At time: 869.6688756942749 and batch: 1500, loss is 3.652643003463745 and perplexity is 38.57648922489587
At time: 870.7861530780792 and batch: 1550, loss is 3.6840880346298217 and perplexity is 39.808801642193295
At time: 871.9069533348083 and batch: 1600, loss is 3.7534557056427 and perplexity is 42.668276527061025
At time: 873.030905008316 and batch: 1650, loss is 3.7012544584274294 and perplexity is 40.498075660473425
At time: 874.1507449150085 and batch: 1700, loss is 3.6916944408416748 and perplexity is 40.112758100928986
At time: 875.2769341468811 and batch: 1750, loss is 3.680971164703369 and perplexity is 39.68491595362964
At time: 876.398087978363 and batch: 1800, loss is 3.645462574958801 and perplexity is 38.3004856000537
At time: 877.5184428691864 and batch: 1850, loss is 3.672339191436768 and perplexity is 39.343831055768284
At time: 878.638441324234 and batch: 1900, loss is 3.8016674184799193 and perplexity is 44.77578224995466
At time: 879.759042263031 and batch: 1950, loss is 3.7486574029922486 and perplexity is 42.464031629001646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3127009901889535 and perplexity of 74.64182374990628
finished 19 epochs...
Completing Train Step...
At time: 883.3534951210022 and batch: 50, loss is 3.9390652847290037 and perplexity is 51.37056200370785
At time: 884.5005342960358 and batch: 100, loss is 3.908500270843506 and perplexity is 49.824173148262986
At time: 885.6170182228088 and batch: 150, loss is 3.868149356842041 and perplexity is 47.85374387988297
At time: 886.7345082759857 and batch: 200, loss is 3.8583869791030883 and perplexity is 47.38885048056893
At time: 887.848876953125 and batch: 250, loss is 3.846953926086426 and perplexity is 46.85013668048283
At time: 888.9657688140869 and batch: 300, loss is 3.849247546195984 and perplexity is 46.957716422476544
At time: 890.0845177173615 and batch: 350, loss is 3.8652654933929442 and perplexity is 47.71593901771432
At time: 891.2021470069885 and batch: 400, loss is 3.827789235115051 and perplexity is 45.96081727416786
At time: 892.3174328804016 and batch: 450, loss is 3.8733426666259767 and perplexity is 48.10290963363624
At time: 893.4408504962921 and batch: 500, loss is 3.903758625984192 and perplexity is 49.58848383288753
At time: 894.560239315033 and batch: 550, loss is 3.876749243736267 and perplexity is 48.26705533328477
At time: 895.6767282485962 and batch: 600, loss is 3.830495843887329 and perplexity is 46.08538372566334
At time: 896.7947111129761 and batch: 650, loss is 3.856124339103699 and perplexity is 47.28174778506099
At time: 897.9569985866547 and batch: 700, loss is 3.9004548835754393 and perplexity is 49.42492658014418
At time: 899.0742480754852 and batch: 750, loss is 3.8343018817901613 and perplexity is 46.26112066146647
At time: 900.1896617412567 and batch: 800, loss is 3.8331337690353395 and perplexity is 46.207114005442286
At time: 901.3043251037598 and batch: 850, loss is 3.8358069229125977 and perplexity is 46.33079797088751
At time: 902.420487165451 and batch: 900, loss is 3.79114070892334 and perplexity is 44.30691275123141
At time: 903.5386731624603 and batch: 950, loss is 3.900296187400818 and perplexity is 49.417083655702484
At time: 904.6552298069 and batch: 1000, loss is 3.854779291152954 and perplexity is 47.218194317906935
At time: 905.7733833789825 and batch: 1050, loss is 3.803441195487976 and perplexity is 44.85527498337657
At time: 906.8914062976837 and batch: 1100, loss is 3.8210034561157227 and perplexity is 45.649993110262635
At time: 908.00714802742 and batch: 1150, loss is 3.8002461576461792 and perplexity is 44.7121893860708
At time: 909.1220474243164 and batch: 1200, loss is 3.846415414810181 and perplexity is 46.82491414550605
At time: 910.2395076751709 and batch: 1250, loss is 3.8348154401779175 and perplexity is 46.2848845495589
At time: 911.3570694923401 and batch: 1300, loss is 3.8212684392929077 and perplexity is 45.66209119329892
At time: 912.4750437736511 and batch: 1350, loss is 3.698700747489929 and perplexity is 40.394787222251196
At time: 913.5920095443726 and batch: 1400, loss is 3.7188524484634398 and perplexity is 41.217068249370996
At time: 914.7090756893158 and batch: 1450, loss is 3.6562164545059206 and perplexity is 38.714587016414676
At time: 915.8227055072784 and batch: 1500, loss is 3.652481822967529 and perplexity is 38.57027194828565
At time: 916.9370534420013 and batch: 1550, loss is 3.684013133049011 and perplexity is 39.80582001168593
At time: 918.0539829730988 and batch: 1600, loss is 3.753491621017456 and perplexity is 42.66980900172222
At time: 919.1720430850983 and batch: 1650, loss is 3.7012951278686526 and perplexity is 40.49972272807358
At time: 920.2928287982941 and batch: 1700, loss is 3.691819915771484 and perplexity is 40.117791562216155
At time: 921.4199538230896 and batch: 1750, loss is 3.6812227535247803 and perplexity is 39.69490149093433
At time: 922.5356118679047 and batch: 1800, loss is 3.645691771507263 and perplexity is 38.309264945217016
At time: 923.6533842086792 and batch: 1850, loss is 3.6725591135025026 and perplexity is 39.35248458388401
At time: 924.770800113678 and batch: 1900, loss is 3.801870861053467 and perplexity is 44.78489247700079
At time: 925.8883271217346 and batch: 1950, loss is 3.748762822151184 and perplexity is 42.468508387464894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.312589423601017 and perplexity of 74.63349668083315
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5dd8c64b38>
ELAPSED
2863.561114549637


RESULTS SO FAR:
[{'best_accuracy': -76.21175240042173, 'params': {'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}}, {'best_accuracy': -73.46243748948554, 'params': {'rnn_dropout': 0.1541901093865481, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2553724200355174, 'num_layers': 2}}, {'best_accuracy': -74.63349668083315, 'params': {'rnn_dropout': 0.9124043211516957, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.644131086985198, 'num_layers': 2}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.11345604619246663, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.06607543552697792, 'num_layers': 2}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6654343605041504 and batch: 50, loss is 7.63587721824646 and perplexity is 2071.1871374926136
At time: 2.8727777004241943 and batch: 100, loss is 6.799156532287598 and perplexity is 897.0903057407088
At time: 4.048625707626343 and batch: 150, loss is 6.398368577957154 and perplexity is 600.8639750922367
At time: 5.2254908084869385 and batch: 200, loss is 6.215598077774048 and perplexity is 500.4952347715804
At time: 6.401299715042114 and batch: 250, loss is 6.051746206283569 and perplexity is 424.8542658697494
At time: 7.578630208969116 and batch: 300, loss is 5.917332382202148 and perplexity is 371.4195856579113
At time: 8.761964797973633 and batch: 350, loss is 5.805744733810425 and perplexity is 332.2025036783293
At time: 9.942788124084473 and batch: 400, loss is 5.7094185924530025 and perplexity is 301.69560917703717
At time: 11.129059553146362 and batch: 450, loss is 5.598496723175049 and perplexity is 270.0201870823278
At time: 12.309181690216064 and batch: 500, loss is 5.551093282699585 and perplexity is 257.5189430651591
At time: 13.492542743682861 and batch: 550, loss is 5.483307838439941 and perplexity is 240.6413951573905
At time: 14.674211025238037 and batch: 600, loss is 5.472159767150879 and perplexity is 237.97360571177467
At time: 15.8609139919281 and batch: 650, loss is 5.51281813621521 and perplexity is 247.8486149557672
At time: 17.041995525360107 and batch: 700, loss is 5.450732364654541 and perplexity is 232.9286921975203
At time: 18.221969604492188 and batch: 750, loss is 5.365844621658325 and perplexity is 213.9718836673955
At time: 19.40033197402954 and batch: 800, loss is 5.363608779907227 and perplexity is 213.49401081943685
At time: 20.581807613372803 and batch: 850, loss is 5.356717500686646 and perplexity is 212.02782174053038
At time: 21.762765407562256 and batch: 900, loss is 5.351412038803101 and perplexity is 210.905895015431
At time: 22.943488597869873 and batch: 950, loss is 5.363504362106323 and perplexity is 213.47171940815133
At time: 24.13057565689087 and batch: 1000, loss is 5.324340858459473 and perplexity is 205.27301189346247
At time: 25.309664487838745 and batch: 1050, loss is 5.220915946960449 and perplexity is 185.10365157424053
At time: 26.490296840667725 and batch: 1100, loss is 5.2923151302337645 and perplexity is 198.80314822397222
At time: 27.675739765167236 and batch: 1150, loss is 5.186914873123169 and perplexity is 178.91572288953404
At time: 28.856109619140625 and batch: 1200, loss is 5.260971155166626 and perplexity is 192.66851149011322
At time: 30.042195320129395 and batch: 1250, loss is 5.216665725708008 and perplexity is 184.31858962570877
At time: 31.226251363754272 and batch: 1300, loss is 5.225272207260132 and perplexity is 185.91177017243098
At time: 32.4109160900116 and batch: 1350, loss is 5.156258392333984 and perplexity is 173.5140181425926
At time: 33.59893774986267 and batch: 1400, loss is 5.152086820602417 and perplexity is 172.79169961872856
At time: 34.78734874725342 and batch: 1450, loss is 5.119361925125122 and perplexity is 167.22863118324955
At time: 35.97682046890259 and batch: 1500, loss is 5.06052604675293 and perplexity is 157.6734381112278
At time: 37.16755175590515 and batch: 1550, loss is 5.058849544525146 and perplexity is 157.40931970038636
At time: 38.36158633232117 and batch: 1600, loss is 5.092004451751709 and perplexity is 162.71569114219216
At time: 39.550132513046265 and batch: 1650, loss is 5.06725191116333 and perplexity is 158.73750264269026
At time: 40.739049196243286 and batch: 1700, loss is 5.086531229019165 and perplexity is 161.82754465139374
At time: 41.93637204170227 and batch: 1750, loss is 5.072395448684692 and perplexity is 159.55607832626725
At time: 43.12446737289429 and batch: 1800, loss is 5.0326934432983395 and perplexity is 153.3454843288718
At time: 44.31683611869812 and batch: 1850, loss is 5.0250914478302 and perplexity is 152.18417238870902
At time: 45.50907778739929 and batch: 1900, loss is 5.10554983139038 and perplexity is 164.9347318980862
At time: 46.69559383392334 and batch: 1950, loss is 5.02204496383667 and perplexity is 151.72125124242277
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.770511219113372 and perplexity of 117.97953994242245
finished 1 epochs...
Completing Train Step...
At time: 50.322540283203125 and batch: 50, loss is 4.998583850860595 and perplexity is 148.20313268450306
At time: 51.49248695373535 and batch: 100, loss is 4.9499959373474125 and perplexity is 141.17439037780943
At time: 52.608718156814575 and batch: 150, loss is 4.887171821594238 and perplexity is 132.57808884403894
At time: 53.72209644317627 and batch: 200, loss is 4.852999324798584 and perplexity is 128.1240999129815
At time: 54.843010663986206 and batch: 250, loss is 4.869622535705567 and perplexity is 130.27173468636067
At time: 55.96758317947388 and batch: 300, loss is 4.884349889755249 and perplexity is 132.20448989728237
At time: 57.090062856674194 and batch: 350, loss is 4.878557271957398 and perplexity is 131.44089356217626
At time: 58.21206498146057 and batch: 400, loss is 4.822929773330689 and perplexity is 124.32881294831196
At time: 59.33253788948059 and batch: 450, loss is 4.795873804092407 and perplexity is 121.01007469737185
At time: 60.470977544784546 and batch: 500, loss is 4.794269208908081 and perplexity is 120.81605821484253
At time: 61.58695960044861 and batch: 550, loss is 4.7626965141296385 and perplexity is 117.06115776032921
At time: 62.704867124557495 and batch: 600, loss is 4.731983051300049 and perplexity is 113.52045617516325
At time: 63.82219219207764 and batch: 650, loss is 4.797677917480469 and perplexity is 121.22858764502242
At time: 64.94237041473389 and batch: 700, loss is 4.814101066589355 and perplexity is 123.2359815616911
At time: 66.05910086631775 and batch: 750, loss is 4.755920791625977 and perplexity is 116.27066494369004
At time: 67.17491912841797 and batch: 800, loss is 4.751554746627807 and perplexity is 115.76412857351895
At time: 68.28842902183533 and batch: 850, loss is 4.745345764160156 and perplexity is 115.04757795593868
At time: 69.4052631855011 and batch: 900, loss is 4.723706512451172 and perplexity is 112.58477714266566
At time: 70.53071546554565 and batch: 950, loss is 4.775432024002075 and perplexity is 118.56152498238913
At time: 71.64850878715515 and batch: 1000, loss is 4.74845253944397 and perplexity is 115.40556072566635
At time: 72.7652223110199 and batch: 1050, loss is 4.678261194229126 and perplexity is 107.58284417136997
At time: 73.88121962547302 and batch: 1100, loss is 4.730141735076904 and perplexity is 113.31162144194376
At time: 75.00461935997009 and batch: 1150, loss is 4.6710649108886715 and perplexity is 106.81142654114294
At time: 76.11986660957336 and batch: 1200, loss is 4.739164419174195 and perplexity is 114.33862259300575
At time: 77.23704862594604 and batch: 1250, loss is 4.717297458648682 and perplexity is 111.8655225812129
At time: 78.35924434661865 and batch: 1300, loss is 4.722430200576782 and perplexity is 112.44117551444813
At time: 79.47721219062805 and batch: 1350, loss is 4.608284301757813 and perplexity is 100.31189696654583
At time: 80.59400963783264 and batch: 1400, loss is 4.617470684051514 and perplexity is 101.23764603281046
At time: 81.71033525466919 and batch: 1450, loss is 4.569213275909424 and perplexity is 96.46818606530398
At time: 82.8244960308075 and batch: 1500, loss is 4.555226516723633 and perplexity is 95.1283009463091
At time: 83.9397406578064 and batch: 1550, loss is 4.558543672561646 and perplexity is 95.44438029755386
At time: 85.0587968826294 and batch: 1600, loss is 4.628231344223022 and perplexity is 102.33291226363559
At time: 86.1765067577362 and batch: 1650, loss is 4.59084789276123 and perplexity is 98.57797829122379
At time: 87.29126596450806 and batch: 1700, loss is 4.6027663135528565 and perplexity is 99.75990145523276
At time: 88.40913105010986 and batch: 1750, loss is 4.590685453414917 and perplexity is 98.56196664936478
At time: 89.52514886856079 and batch: 1800, loss is 4.552908916473388 and perplexity is 94.90808685491635
At time: 90.64061903953552 and batch: 1850, loss is 4.581220302581787 and perplexity is 97.6334639098232
At time: 91.7559289932251 and batch: 1900, loss is 4.682765340805053 and perplexity is 108.06850599552901
At time: 92.87325620651245 and batch: 1950, loss is 4.6062833690643314 and perplexity is 100.11138028944897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.54569829896439 and perplexity of 94.22620230088
finished 2 epochs...
Completing Train Step...
At time: 96.4676513671875 and batch: 50, loss is 4.603486680984497 and perplexity is 99.83179112960606
At time: 97.60620641708374 and batch: 100, loss is 4.5537574768066404 and perplexity is 94.98865627189743
At time: 98.72347569465637 and batch: 150, loss is 4.493248291015625 and perplexity is 89.41140895787886
At time: 99.83974194526672 and batch: 200, loss is 4.488153886795044 and perplexity is 88.95706937607805
At time: 100.96198797225952 and batch: 250, loss is 4.496782989501953 and perplexity is 89.72801054572193
At time: 102.07833576202393 and batch: 300, loss is 4.519089593887329 and perplexity is 91.75202833532563
At time: 103.19240832328796 and batch: 350, loss is 4.519518737792969 and perplexity is 91.79141160905736
At time: 104.30820441246033 and batch: 400, loss is 4.462187671661377 and perplexity is 86.67692248064623
At time: 105.42291021347046 and batch: 450, loss is 4.470873174667358 and perplexity is 87.43303400256252
At time: 106.54040002822876 and batch: 500, loss is 4.471929512023926 and perplexity is 87.52544158077319
At time: 107.65534448623657 and batch: 550, loss is 4.448987045288086 and perplexity is 85.54025170090704
At time: 108.77914619445801 and batch: 600, loss is 4.425224046707154 and perplexity is 83.53152008770417
At time: 109.89392375946045 and batch: 650, loss is 4.482419557571411 and perplexity is 88.44842002872042
At time: 111.00783610343933 and batch: 700, loss is 4.51423529624939 and perplexity is 91.30771596563335
At time: 112.12289381027222 and batch: 750, loss is 4.466807880401611 and perplexity is 87.07831449890315
At time: 113.24627661705017 and batch: 800, loss is 4.460472831726074 and perplexity is 86.52841280406254
At time: 114.36285758018494 and batch: 850, loss is 4.459764289855957 and perplexity is 86.46712551550512
At time: 115.52881407737732 and batch: 900, loss is 4.4309475708007815 and perplexity is 84.01098556271342
At time: 116.64538264274597 and batch: 950, loss is 4.491401033401489 and perplexity is 89.2463955099886
At time: 117.76314878463745 and batch: 1000, loss is 4.468218116760254 and perplexity is 87.20120213399812
At time: 118.88178086280823 and batch: 1050, loss is 4.408081760406494 and perplexity is 82.11180222636897
At time: 120.01122188568115 and batch: 1100, loss is 4.452072219848633 and perplexity is 85.80456582731507
At time: 121.1310522556305 and batch: 1150, loss is 4.407535629272461 and perplexity is 82.06697065777354
At time: 122.24737596511841 and batch: 1200, loss is 4.468683986663819 and perplexity is 87.24183601394294
At time: 123.36400604248047 and batch: 1250, loss is 4.466225004196167 and perplexity is 87.02757341069457
At time: 124.47855973243713 and batch: 1300, loss is 4.451856737136841 and perplexity is 85.78607841871646
At time: 125.59388375282288 and batch: 1350, loss is 4.336760020256042 and perplexity is 76.45941064765668
At time: 126.71173810958862 and batch: 1400, loss is 4.361376333236694 and perplexity is 78.3649164731939
At time: 127.83628463745117 and batch: 1450, loss is 4.299479088783264 and perplexity is 73.66141264781463
At time: 128.95876336097717 and batch: 1500, loss is 4.297574310302735 and perplexity is 73.52123751782496
At time: 130.07389330863953 and batch: 1550, loss is 4.308134279251099 and perplexity is 74.30173325550092
At time: 131.18929386138916 and batch: 1600, loss is 4.388132829666137 and perplexity is 80.48999006435484
At time: 132.30628991127014 and batch: 1650, loss is 4.34720850944519 and perplexity is 77.26248411945181
At time: 133.42643237113953 and batch: 1700, loss is 4.353266563415527 and perplexity is 77.73196505271663
At time: 134.54222869873047 and batch: 1750, loss is 4.347210264205932 and perplexity is 77.26261969674474
At time: 135.6570611000061 and batch: 1800, loss is 4.306304006576538 and perplexity is 74.165865199175
At time: 136.7734637260437 and batch: 1850, loss is 4.345561857223511 and perplexity is 77.13536436805796
At time: 137.8890950679779 and batch: 1900, loss is 4.450209217071533 and perplexity is 85.64486049482177
At time: 139.00377011299133 and batch: 1950, loss is 4.375216150283814 and perplexity is 79.45701235201258
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.471119015715843 and perplexity of 87.45453127366147
finished 3 epochs...
Completing Train Step...
At time: 142.6070625782013 and batch: 50, loss is 4.374202404022217 and perplexity is 79.37650391724021
At time: 143.7544651031494 and batch: 100, loss is 4.328744535446167 and perplexity is 75.84900103565417
At time: 144.87971878051758 and batch: 150, loss is 4.274214181900025 and perplexity is 71.8236767827041
At time: 146.0001094341278 and batch: 200, loss is 4.272140722274781 and perplexity is 71.67490757553036
At time: 147.1214587688446 and batch: 250, loss is 4.2764029216766355 and perplexity is 71.98105228516522
At time: 148.2408003807068 and batch: 300, loss is 4.295627765655517 and perplexity is 73.37826434345568
At time: 149.37050652503967 and batch: 350, loss is 4.301534910202026 and perplexity is 73.8130031257578
At time: 150.48865389823914 and batch: 400, loss is 4.240307755470276 and perplexity is 69.42921577210373
At time: 151.60762119293213 and batch: 450, loss is 4.2703741264343265 and perplexity is 71.54839875981764
At time: 152.72417974472046 and batch: 500, loss is 4.273243856430054 and perplexity is 71.754018240969
At time: 153.84735679626465 and batch: 550, loss is 4.250293827056884 and perplexity is 70.126014240218
At time: 154.96838450431824 and batch: 600, loss is 4.233399772644043 and perplexity is 68.95125272288627
At time: 156.08799171447754 and batch: 650, loss is 4.284907884597779 and perplexity is 72.59585921497683
At time: 157.20833277702332 and batch: 700, loss is 4.320225601196289 and perplexity is 75.20559285005343
At time: 158.3321075439453 and batch: 750, loss is 4.276605477333069 and perplexity is 71.99563393120921
At time: 159.4578995704651 and batch: 800, loss is 4.270216064453125 and perplexity is 71.53709057187872
At time: 160.57534217834473 and batch: 850, loss is 4.266630439758301 and perplexity is 71.28104472980093
At time: 161.6985981464386 and batch: 900, loss is 4.238230338096619 and perplexity is 69.28513202587628
At time: 162.8208372592926 and batch: 950, loss is 4.306499671936035 and perplexity is 74.18037830966179
At time: 163.9386613368988 and batch: 1000, loss is 4.28300892829895 and perplexity is 72.45813365964403
At time: 165.06852507591248 and batch: 1050, loss is 4.231395168304443 and perplexity is 68.81317118811836
At time: 166.18729162216187 and batch: 1100, loss is 4.268061761856079 and perplexity is 71.3831439152548
At time: 167.30358934402466 and batch: 1150, loss is 4.2337564277648925 and perplexity is 68.97584892617904
At time: 168.42758584022522 and batch: 1200, loss is 4.288926844596863 and perplexity is 72.88820614106204
At time: 169.55139875411987 and batch: 1250, loss is 4.294813213348388 and perplexity is 73.31851824540604
At time: 170.67143034934998 and batch: 1300, loss is 4.268059415817261 and perplexity is 71.38297644782465
At time: 171.79496359825134 and batch: 1350, loss is 4.157790193557739 and perplexity is 63.93009325981612
At time: 172.92032885551453 and batch: 1400, loss is 4.189660086631775 and perplexity is 66.00035274489568
At time: 174.04666996002197 and batch: 1450, loss is 4.125688147544861 and perplexity is 61.91039808342926
At time: 175.17020773887634 and batch: 1500, loss is 4.125794978141784 and perplexity is 61.91701236150963
At time: 176.30179643630981 and batch: 1550, loss is 4.1384687423706055 and perplexity is 62.70672774059861
At time: 177.42884469032288 and batch: 1600, loss is 4.227627143859864 and perplexity is 68.5543693689687
At time: 178.5473530292511 and batch: 1650, loss is 4.185416088104248 and perplexity is 65.72084088851965
At time: 179.6680247783661 and batch: 1700, loss is 4.18611358165741 and perplexity is 65.76669674156962
At time: 180.78688144683838 and batch: 1750, loss is 4.18056016921997 and perplexity is 65.40247941049371
At time: 181.90473222732544 and batch: 1800, loss is 4.144224462509155 and perplexity is 63.06869079603322
At time: 183.02362990379333 and batch: 1850, loss is 4.182476849555969 and perplexity is 65.52795526684562
At time: 184.14462757110596 and batch: 1900, loss is 4.2883627986907955 and perplexity is 72.84710543921857
At time: 185.26362538337708 and batch: 1950, loss is 4.217254848480224 and perplexity is 67.8469781775188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4419734511264535 and perplexity of 84.94240606501566
finished 4 epochs...
Completing Train Step...
At time: 188.9156539440155 and batch: 50, loss is 4.213687047958374 and perplexity is 67.60534499917738
At time: 190.0355875492096 and batch: 100, loss is 4.173801274299621 and perplexity is 64.9619214442816
At time: 191.1588056087494 and batch: 150, loss is 4.123918404579163 and perplexity is 61.800929486128766
At time: 192.27686309814453 and batch: 200, loss is 4.117782578468323 and perplexity is 61.42289070546858
At time: 193.3941593170166 and batch: 250, loss is 4.122975172996521 and perplexity is 61.74266438066448
At time: 194.51162791252136 and batch: 300, loss is 4.135922546386719 and perplexity is 62.547267217284904
At time: 195.62863898277283 and batch: 350, loss is 4.149285230636597 and perplexity is 63.38867581831658
At time: 196.74582314491272 and batch: 400, loss is 4.084390025138855 and perplexity is 59.40569071953083
At time: 197.86501383781433 and batch: 450, loss is 4.121509561538696 and perplexity is 61.652239904072104
At time: 198.98318028450012 and batch: 500, loss is 4.1309587144851685 and perplexity is 62.23756239417481
At time: 200.12525939941406 and batch: 550, loss is 4.105040335655213 and perplexity is 60.64519066177371
At time: 201.24212408065796 and batch: 600, loss is 4.091734981536865 and perplexity is 59.84362927863218
At time: 202.3583481311798 and batch: 650, loss is 4.140107760429382 and perplexity is 62.809589472863465
At time: 203.47631311416626 and batch: 700, loss is 4.181527853012085 and perplexity is 65.46579896149387
At time: 204.59585094451904 and batch: 750, loss is 4.13605899810791 and perplexity is 62.55580248186505
At time: 205.7132909297943 and batch: 800, loss is 4.13041645526886 and perplexity is 62.2038226510361
At time: 206.83059740066528 and batch: 850, loss is 4.12870913028717 and perplexity is 62.097711119877246
At time: 207.9482901096344 and batch: 900, loss is 4.099470930099487 and perplexity is 60.30837181099137
At time: 209.06393837928772 and batch: 950, loss is 4.175293188095093 and perplexity is 65.05891136337378
At time: 210.18138360977173 and batch: 1000, loss is 4.15057481765747 and perplexity is 63.47047376337031
At time: 211.30005955696106 and batch: 1050, loss is 4.099820771217346 and perplexity is 60.32947385016723
At time: 212.41805505752563 and batch: 1100, loss is 4.130989422798157 and perplexity is 62.239473634065774
At time: 213.53622579574585 and batch: 1150, loss is 4.104848928451538 and perplexity is 60.633583846262326
At time: 214.65378594398499 and batch: 1200, loss is 4.154371523857117 and perplexity is 63.7119105468431
At time: 215.77020740509033 and batch: 1250, loss is 4.168116044998169 and perplexity is 64.59364588246002
At time: 216.8885633945465 and batch: 1300, loss is 4.132129907608032 and perplexity is 62.31049730132848
At time: 218.0074017047882 and batch: 1350, loss is 4.025538473129273 and perplexity is 56.01046079098629
At time: 219.12601566314697 and batch: 1400, loss is 4.059211044311524 and perplexity is 57.92858995479015
At time: 220.2431709766388 and batch: 1450, loss is 3.997187657356262 and perplexity is 54.44481704105567
At time: 221.36002922058105 and batch: 1500, loss is 4.0019827079772945 and perplexity is 54.706509607959205
At time: 222.47636890411377 and batch: 1550, loss is 4.014810848236084 and perplexity is 55.41281297982206
At time: 223.5915768146515 and batch: 1600, loss is 4.102523007392883 and perplexity is 60.49271880072608
At time: 224.72094225883484 and batch: 1650, loss is 4.06319902420044 and perplexity is 58.16006926715748
At time: 225.8409538269043 and batch: 1700, loss is 4.063702564239502 and perplexity is 58.18936256526343
At time: 226.96326065063477 and batch: 1750, loss is 4.05804958820343 and perplexity is 57.861347497294474
At time: 228.0843427181244 and batch: 1800, loss is 4.0161617612838745 and perplexity is 55.48772145791939
At time: 229.20454335212708 and batch: 1850, loss is 4.058235144615173 and perplexity is 57.87208503749357
At time: 230.32311630249023 and batch: 1900, loss is 4.164696660041809 and perplexity is 64.37315253211318
At time: 231.4439661502838 and batch: 1950, loss is 4.096162881851196 and perplexity is 60.10919842648013
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.432774459484012 and perplexity of 84.16460456118432
finished 5 epochs...
Completing Train Step...
At time: 235.10274004936218 and batch: 50, loss is 4.087738804817199 and perplexity is 59.60496075889633
At time: 236.22529697418213 and batch: 100, loss is 4.053580040931702 and perplexity is 57.603310553172896
At time: 237.3479471206665 and batch: 150, loss is 4.009698481559753 and perplexity is 55.13024527160901
At time: 238.47055339813232 and batch: 200, loss is 4.00040530204773 and perplexity is 54.62028326017306
At time: 239.59751224517822 and batch: 250, loss is 4.006904973983764 and perplexity is 54.97645342313548
At time: 240.72008442878723 and batch: 300, loss is 4.014623670578003 and perplexity is 55.40244190990741
At time: 241.84852266311646 and batch: 350, loss is 4.029509201049804 and perplexity is 56.23330522600794
At time: 242.97211909294128 and batch: 400, loss is 3.9656689882278444 and perplexity is 52.75555042922202
At time: 244.09579825401306 and batch: 450, loss is 4.0049408388137815 and perplexity is 54.86857821287372
At time: 245.2263045310974 and batch: 500, loss is 4.018094735145569 and perplexity is 55.5950815017936
At time: 246.3546760082245 and batch: 550, loss is 3.9938525104522706 and perplexity is 54.26353804214239
At time: 247.4754593372345 and batch: 600, loss is 3.9807432746887206 and perplexity is 53.556826871048244
At time: 248.60134625434875 and batch: 650, loss is 4.029665727615356 and perplexity is 56.242107921054426
At time: 249.7275459766388 and batch: 700, loss is 4.072603030204773 and perplexity is 58.70958669060953
At time: 250.84780025482178 and batch: 750, loss is 4.025306062698364 and perplexity is 55.997444888232856
At time: 251.96717882156372 and batch: 800, loss is 4.021641721725464 and perplexity is 55.79262664766786
At time: 253.08846068382263 and batch: 850, loss is 4.019759383201599 and perplexity is 55.68770481736282
At time: 254.20923399925232 and batch: 900, loss is 3.991497893333435 and perplexity is 54.13591849308981
At time: 255.3631238937378 and batch: 950, loss is 4.071065983772278 and perplexity is 58.61941664535897
At time: 256.48748445510864 and batch: 1000, loss is 4.043785943984985 and perplexity is 57.04189192719043
At time: 257.6046178340912 and batch: 1050, loss is 4.001699419021606 and perplexity is 54.69101405294644
At time: 258.72483086586 and batch: 1100, loss is 4.021826634407043 and perplexity is 55.802944365782686
At time: 259.85154485702515 and batch: 1150, loss is 4.000159978866577 and perplexity is 54.606885282012726
At time: 260.97771739959717 and batch: 1200, loss is 4.048493528366089 and perplexity is 57.31105450237931
At time: 262.1074335575104 and batch: 1250, loss is 4.066513419151306 and perplexity is 58.353154510699866
At time: 263.228049993515 and batch: 1300, loss is 4.02459005355835 and perplexity is 55.95736455652966
At time: 264.352192401886 and batch: 1350, loss is 3.9213436222076417 and perplexity is 50.46820944980849
At time: 265.4759843349457 and batch: 1400, loss is 3.9567428493499754 and perplexity is 52.28674249460064
At time: 266.59674286842346 and batch: 1450, loss is 3.899431209564209 and perplexity is 49.37435745486277
At time: 267.7236602306366 and batch: 1500, loss is 3.9024619007110597 and perplexity is 49.52422286605955
At time: 268.84467124938965 and batch: 1550, loss is 3.915723834037781 and perplexity is 50.185384256574764
At time: 269.96444177627563 and batch: 1600, loss is 4.00242995262146 and perplexity is 54.73098227360875
At time: 271.0827178955078 and batch: 1650, loss is 3.9678462171554565 and perplexity is 52.87053646975287
At time: 272.20219564437866 and batch: 1700, loss is 3.965785698890686 and perplexity is 52.76170792379684
At time: 273.32970333099365 and batch: 1750, loss is 3.96271852016449 and perplexity is 52.60012626228697
At time: 274.45698499679565 and batch: 1800, loss is 3.9166316175460816 and perplexity is 50.23096240517647
At time: 275.57835125923157 and batch: 1850, loss is 3.957083697319031 and perplexity is 52.304567362200835
At time: 276.6979730129242 and batch: 1900, loss is 4.066478853225708 and perplexity is 58.35113751476249
At time: 277.81747341156006 and batch: 1950, loss is 4.00297905921936 and perplexity is 54.761043669784875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.43144048646439 and perplexity of 84.05240610098987
finished 6 epochs...
Completing Train Step...
At time: 281.49827694892883 and batch: 50, loss is 3.992483205795288 and perplexity is 54.189285575523016
At time: 282.6178181171417 and batch: 100, loss is 3.9587938928604127 and perplexity is 52.394094933103254
At time: 283.7585389614105 and batch: 150, loss is 3.9144942998886108 and perplexity is 50.123717531283134
At time: 284.8769886493683 and batch: 200, loss is 3.9045950317382814 and perplexity is 49.62997727636039
At time: 285.9922761917114 and batch: 250, loss is 3.9124382734298706 and perplexity is 50.02076771187089
At time: 287.1091830730438 and batch: 300, loss is 3.919614315032959 and perplexity is 50.38100983230653
At time: 288.227609872818 and batch: 350, loss is 3.9335381174087525 and perplexity is 51.08741154300813
At time: 289.3468225002289 and batch: 400, loss is 3.8704559278488158 and perplexity is 47.96424933342631
At time: 290.46434354782104 and batch: 450, loss is 3.9149243211746216 and perplexity is 50.14527643181643
At time: 291.5791184902191 and batch: 500, loss is 3.9273544359207153 and perplexity is 50.772477989901994
At time: 292.6966292858124 and batch: 550, loss is 3.905520062446594 and perplexity is 49.675907769677124
At time: 293.8134915828705 and batch: 600, loss is 3.894660692214966 and perplexity is 49.13937716043899
At time: 294.9309220314026 and batch: 650, loss is 3.941466565132141 and perplexity is 51.49406535128477
At time: 296.0491306781769 and batch: 700, loss is 3.983782796859741 and perplexity is 53.71986168217478
At time: 297.16680574417114 and batch: 750, loss is 3.937175760269165 and perplexity is 51.27358771678203
At time: 298.28500533103943 and batch: 800, loss is 3.9344373512268067 and perplexity is 51.133371732525774
At time: 299.4020848274231 and batch: 850, loss is 3.9314931726455686 and perplexity is 50.98304735417852
At time: 300.52852296829224 and batch: 900, loss is 3.9042811012268066 and perplexity is 49.61439935752949
At time: 301.65533924102783 and batch: 950, loss is 3.99038076877594 and perplexity is 54.07547569645073
At time: 302.7764108181 and batch: 1000, loss is 3.9577874040603636 and perplexity is 52.34138739258846
At time: 303.8943090438843 and batch: 1050, loss is 3.9165689897537233 and perplexity is 50.2278166493999
At time: 305.0111391544342 and batch: 1100, loss is 3.9348699283599853 and perplexity is 51.155495644683846
At time: 306.1279709339142 and batch: 1150, loss is 3.9144631576538087 and perplexity is 50.122156591008334
At time: 307.2439045906067 and batch: 1200, loss is 3.9666673231124876 and perplexity is 52.80824443432926
At time: 308.36690163612366 and batch: 1250, loss is 3.9864753770828245 and perplexity is 53.86470162840704
At time: 309.48513531684875 and batch: 1300, loss is 3.9381882476806642 and perplexity is 51.32552786882561
At time: 310.60072016716003 and batch: 1350, loss is 3.838154520988464 and perplexity is 46.439691832555916
At time: 311.71755146980286 and batch: 1400, loss is 3.8751848697662354 and perplexity is 48.19160663868518
At time: 312.8454463481903 and batch: 1450, loss is 3.8148303174972535 and perplexity is 45.36905739456796
At time: 313.9678318500519 and batch: 1500, loss is 3.8200475120544435 and perplexity is 45.60637512195151
At time: 315.0879375934601 and batch: 1550, loss is 3.834748635292053 and perplexity is 46.281792596409254
At time: 316.2103581428528 and batch: 1600, loss is 3.923100652694702 and perplexity is 50.55696157970553
At time: 317.3282973766327 and batch: 1650, loss is 3.884792380332947 and perplexity is 48.656839293944714
At time: 318.445280790329 and batch: 1700, loss is 3.8875077772140503 and perplexity is 48.78914146877144
At time: 319.56354999542236 and batch: 1750, loss is 3.880990686416626 and perplexity is 48.472212054506166
At time: 320.6805920600891 and batch: 1800, loss is 3.838080892562866 and perplexity is 46.43627267703608
At time: 321.7963285446167 and batch: 1850, loss is 3.877261271476746 and perplexity is 48.29177573279171
At time: 322.9147343635559 and batch: 1900, loss is 3.981372609138489 and perplexity is 53.59054263535167
At time: 324.0350275039673 and batch: 1950, loss is 3.923722171783447 and perplexity is 50.58839346314223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.43695068359375 and perplexity of 84.51682978575137
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 327.6557033061981 and batch: 50, loss is 3.953728494644165 and perplexity is 52.12936901521694
At time: 328.81605434417725 and batch: 100, loss is 3.9513891983032225 and perplexity is 52.00756549583312
At time: 329.9357454776764 and batch: 150, loss is 3.915486340522766 and perplexity is 50.17346696846064
At time: 331.05600142478943 and batch: 200, loss is 3.9017198371887205 and perplexity is 49.48748637888776
At time: 332.174275636673 and batch: 250, loss is 3.9096360635757446 and perplexity is 49.88079523140285
At time: 333.2938313484192 and batch: 300, loss is 3.9121728706359864 and perplexity is 50.00749382190958
At time: 334.4132127761841 and batch: 350, loss is 3.9182250547409057 and perplexity is 50.311066092152934
At time: 335.52929973602295 and batch: 400, loss is 3.8566953229904173 and perplexity is 47.30875261010845
At time: 336.64962100982666 and batch: 450, loss is 3.8894287014007567 and perplexity is 48.882951783072016
At time: 337.76971316337585 and batch: 500, loss is 3.8977854585647584 and perplexity is 49.293166385201694
At time: 338.8894326686859 and batch: 550, loss is 3.8724298524856566 and perplexity is 48.059020651821186
At time: 340.04994797706604 and batch: 600, loss is 3.841601915359497 and perplexity is 46.60006403906399
At time: 341.17759442329407 and batch: 650, loss is 3.8847000789642334 and perplexity is 48.65234840834124
At time: 342.30221605300903 and batch: 700, loss is 3.9283565711975097 and perplexity is 50.82338438447251
At time: 343.4224925041199 and batch: 750, loss is 3.868467354774475 and perplexity is 47.86896369130202
At time: 344.54386734962463 and batch: 800, loss is 3.862968578338623 and perplexity is 47.6064653330609
At time: 345.665043592453 and batch: 850, loss is 3.850557413101196 and perplexity is 47.019265082639
At time: 346.7846450805664 and batch: 900, loss is 3.81720507144928 and perplexity is 45.476925772650745
At time: 347.9041202068329 and batch: 950, loss is 3.901068649291992 and perplexity is 49.45527121691849
At time: 349.02107548713684 and batch: 1000, loss is 3.8646099090576174 and perplexity is 47.684667447244784
At time: 350.1391611099243 and batch: 1050, loss is 3.8158651876449583 and perplexity is 45.41603278021486
At time: 351.26003193855286 and batch: 1100, loss is 3.8299659585952757 and perplexity is 46.060970227396545
At time: 352.3811433315277 and batch: 1150, loss is 3.802937345504761 and perplexity is 44.832680346460805
At time: 353.5030765533447 and batch: 1200, loss is 3.8336485242843628 and perplexity is 46.230905482787385
At time: 354.6237778663635 and batch: 1250, loss is 3.842453818321228 and perplexity is 46.639779686172496
At time: 355.750141620636 and batch: 1300, loss is 3.8024037313461303 and perplexity is 44.80876337524333
At time: 356.8692708015442 and batch: 1350, loss is 3.6907516002655028 and perplexity is 40.07495598845235
At time: 357.98948097229004 and batch: 1400, loss is 3.716951637268066 and perplexity is 41.138796797794605
At time: 359.10971760749817 and batch: 1450, loss is 3.659499096870422 and perplexity is 38.841881977486835
At time: 360.2360875606537 and batch: 1500, loss is 3.6692550134658815 and perplexity is 39.22267460879642
At time: 361.3586575984955 and batch: 1550, loss is 3.6764847946166994 and perplexity is 39.507273516619364
At time: 362.48220014572144 and batch: 1600, loss is 3.744522018432617 and perplexity is 42.28878912557582
At time: 363.60394644737244 and batch: 1650, loss is 3.694028072357178 and perplexity is 40.20647580617139
At time: 364.7256541252136 and batch: 1700, loss is 3.694901008605957 and perplexity is 40.24158881981974
At time: 365.84818601608276 and batch: 1750, loss is 3.6709698247909546 and perplexity is 39.28999179705769
At time: 366.97063159942627 and batch: 1800, loss is 3.621568660736084 and perplexity is 37.39618376091821
At time: 368.09173679351807 and batch: 1850, loss is 3.646927947998047 and perplexity is 38.356651240799415
At time: 369.21389985084534 and batch: 1900, loss is 3.73994722366333 and perplexity is 42.09576844592243
At time: 370.33258509635925 and batch: 1950, loss is 3.677202081680298 and perplexity is 39.535621738521876
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.368716501635174 and perplexity of 78.94224440665903
finished 8 epochs...
Completing Train Step...
At time: 373.9793038368225 and batch: 50, loss is 3.8786680936813354 and perplexity is 48.35976148591238
At time: 375.13037061691284 and batch: 100, loss is 3.852129411697388 and perplexity is 47.093237428321416
At time: 376.2550036907196 and batch: 150, loss is 3.8113858699798584 and perplexity is 45.21305488292794
At time: 377.3715033531189 and batch: 200, loss is 3.797595376968384 and perplexity is 44.593824127863115
At time: 378.4895942211151 and batch: 250, loss is 3.800295519828796 and perplexity is 44.7143965318028
At time: 379.6113739013672 and batch: 300, loss is 3.8015289068222047 and perplexity is 44.76958071163234
At time: 380.7304620742798 and batch: 350, loss is 3.8118932485580443 and perplexity is 45.23600083908094
At time: 381.84976744651794 and batch: 400, loss is 3.749275064468384 and perplexity is 42.49026812726328
At time: 382.9731070995331 and batch: 450, loss is 3.794098358154297 and perplexity is 44.43815104039938
At time: 384.0926413536072 and batch: 500, loss is 3.803763828277588 and perplexity is 44.86974910066013
At time: 385.2105391025543 and batch: 550, loss is 3.778919243812561 and perplexity is 43.76871285745491
At time: 386.3294765949249 and batch: 600, loss is 3.7534465742111207 and perplexity is 42.667886906392205
At time: 387.44915556907654 and batch: 650, loss is 3.798101363182068 and perplexity is 44.61639369755129
At time: 388.5674910545349 and batch: 700, loss is 3.84131805896759 and perplexity is 46.5868381902329
At time: 389.6932895183563 and batch: 750, loss is 3.7865513801574706 and perplexity is 44.10403964378418
At time: 390.81091570854187 and batch: 800, loss is 3.781731324195862 and perplexity is 43.89196721564258
At time: 391.92649245262146 and batch: 850, loss is 3.771685070991516 and perplexity is 43.45322494739615
At time: 393.0402817726135 and batch: 900, loss is 3.737694344520569 and perplexity is 42.00103851480165
At time: 394.1570920944214 and batch: 950, loss is 3.825563979148865 and perplexity is 45.8586564005209
At time: 395.2752823829651 and batch: 1000, loss is 3.790560178756714 and perplexity is 44.28119871639789
At time: 396.42751812934875 and batch: 1050, loss is 3.747765555381775 and perplexity is 42.42617706662185
At time: 397.54387855529785 and batch: 1100, loss is 3.7622699165344238 and perplexity is 43.0460260511215
At time: 398.6583425998688 and batch: 1150, loss is 3.739693355560303 and perplexity is 42.085083029442195
At time: 399.78269362449646 and batch: 1200, loss is 3.7732279014587404 and perplexity is 43.52031764976829
At time: 400.90206027030945 and batch: 1250, loss is 3.7873545265197754 and perplexity is 44.13947587112075
At time: 402.0191478729248 and batch: 1300, loss is 3.7481018686294556 and perplexity is 42.44044795162713
At time: 403.1352880001068 and batch: 1350, loss is 3.6361060762405395 and perplexity is 37.94379842930599
At time: 404.2533357143402 and batch: 1400, loss is 3.6681027221679687 and perplexity is 39.177504691613045
At time: 405.3750514984131 and batch: 1450, loss is 3.6094179201126098 and perplexity is 36.94454188011137
At time: 406.4929668903351 and batch: 1500, loss is 3.6228674125671385 and perplexity is 37.444783675835055
At time: 407.6111550331116 and batch: 1550, loss is 3.6326398468017578 and perplexity is 37.81250419759223
At time: 408.72824239730835 and batch: 1600, loss is 3.706850275993347 and perplexity is 40.725330749643916
At time: 409.8441741466522 and batch: 1650, loss is 3.657624807357788 and perplexity is 38.769149227852665
At time: 410.96181178092957 and batch: 1700, loss is 3.6639391040802 and perplexity is 39.01472363867402
At time: 412.0761044025421 and batch: 1750, loss is 3.6440174055099486 and perplexity is 38.24517488469273
At time: 413.1911642551422 and batch: 1800, loss is 3.5979556941986086 and perplexity is 36.523492884016015
At time: 414.3078603744507 and batch: 1850, loss is 3.627858567237854 and perplexity is 37.63214356491225
At time: 415.4255657196045 and batch: 1900, loss is 3.7222991466522215 and perplexity is 41.359376149161655
At time: 416.5416395664215 and batch: 1950, loss is 3.6633064222335814 and perplexity is 38.99004753816053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372880234829215 and perplexity of 79.27162409882374
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 420.1962547302246 and batch: 50, loss is 3.8567087507247924 and perplexity is 47.309387863737115
At time: 421.3453507423401 and batch: 100, loss is 3.8592383432388306 and perplexity is 47.429212827391446
At time: 422.465487241745 and batch: 150, loss is 3.8388455963134764 and perplexity is 46.4717962496901
At time: 423.62152671813965 and batch: 200, loss is 3.8337616539001464 and perplexity is 46.23613586321187
At time: 424.7545449733734 and batch: 250, loss is 3.841987795829773 and perplexity is 46.618049563598426
At time: 425.8734996318817 and batch: 300, loss is 3.8424519062042237 and perplexity is 46.63969050554194
At time: 426.99062991142273 and batch: 350, loss is 3.850774269104004 and perplexity is 47.029462598176046
At time: 428.1093726158142 and batch: 400, loss is 3.783690276145935 and perplexity is 43.97803374298469
At time: 429.2351701259613 and batch: 450, loss is 3.8343902015686036 and perplexity is 46.26520661382633
At time: 430.35312390327454 and batch: 500, loss is 3.844524874687195 and perplexity is 46.736473393295526
At time: 431.47898960113525 and batch: 550, loss is 3.8257593536376953 and perplexity is 45.86761688737036
At time: 432.6038691997528 and batch: 600, loss is 3.7835494661331177 and perplexity is 43.97184163145554
At time: 433.719655752182 and batch: 650, loss is 3.81870397567749 and perplexity is 45.545142441332
At time: 434.8393566608429 and batch: 700, loss is 3.868115520477295 and perplexity is 47.85212471054414
At time: 435.95925307273865 and batch: 750, loss is 3.804147229194641 and perplexity is 44.8869555018775
At time: 437.07821774482727 and batch: 800, loss is 3.7914500427246094 and perplexity is 44.32062049700051
At time: 438.2040159702301 and batch: 850, loss is 3.789155988693237 and perplexity is 44.21906313245591
At time: 439.3296365737915 and batch: 900, loss is 3.745392179489136 and perplexity is 42.32560319776329
At time: 440.448627948761 and batch: 950, loss is 3.833485651016235 and perplexity is 46.22337631728944
At time: 441.56608986854553 and batch: 1000, loss is 3.791781868934631 and perplexity is 44.33532968083724
At time: 442.6847069263458 and batch: 1050, loss is 3.7434803819656373 and perplexity is 42.24476251452076
At time: 443.80325078964233 and batch: 1100, loss is 3.7616537380218507 and perplexity is 43.01951018490959
At time: 444.92100191116333 and batch: 1150, loss is 3.7418428897857665 and perplexity is 42.175643652505244
At time: 446.03863501548767 and batch: 1200, loss is 3.771277470588684 and perplexity is 43.43551700453073
At time: 447.16181993484497 and batch: 1250, loss is 3.7709598684310914 and perplexity is 43.42172398107689
At time: 448.27856707572937 and batch: 1300, loss is 3.728517270088196 and perplexity is 41.61735509653094
At time: 449.39688062667847 and batch: 1350, loss is 3.611072988510132 and perplexity is 37.00573825195928
At time: 450.5157308578491 and batch: 1400, loss is 3.6395268344879153 and perplexity is 38.07381724540303
At time: 451.6342442035675 and batch: 1450, loss is 3.581678242683411 and perplexity is 35.9337959016773
At time: 452.7519271373749 and batch: 1500, loss is 3.592510209083557 and perplexity is 36.32514528674896
At time: 453.86798191070557 and batch: 1550, loss is 3.6093504190444947 and perplexity is 36.9420481682385
At time: 454.993691444397 and batch: 1600, loss is 3.6874749755859373 and perplexity is 39.94386029161578
At time: 456.11231422424316 and batch: 1650, loss is 3.6349995136260986 and perplexity is 37.90183446267456
At time: 457.23767280578613 and batch: 1700, loss is 3.6296558380126953 and perplexity is 37.69983953250564
At time: 458.35460901260376 and batch: 1750, loss is 3.6056172609329225 and perplexity is 36.80439476229248
At time: 459.47524309158325 and batch: 1800, loss is 3.559449667930603 and perplexity is 35.1438510339361
At time: 460.59490489959717 and batch: 1850, loss is 3.579466242790222 and perplexity is 35.854398195214074
At time: 461.71062994003296 and batch: 1900, loss is 3.6691644477844236 and perplexity is 39.219122541392004
At time: 462.82778692245483 and batch: 1950, loss is 3.614434380531311 and perplexity is 37.130338342811974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347588685501454 and perplexity of 77.29186305019064
finished 10 epochs...
Completing Train Step...
At time: 466.4692311286926 and batch: 50, loss is 3.852346224784851 and perplexity is 47.10344896548433
At time: 467.58962059020996 and batch: 100, loss is 3.832223811149597 and perplexity is 46.16508660215913
At time: 468.71682929992676 and batch: 150, loss is 3.798127007484436 and perplexity is 44.61753786851252
At time: 469.8361506462097 and batch: 200, loss is 3.786801052093506 and perplexity is 44.115052559499816
At time: 470.96199226379395 and batch: 250, loss is 3.790818371772766 and perplexity is 44.29263328874872
At time: 472.08554577827454 and batch: 300, loss is 3.7895257091522216 and perplexity is 44.23541484736861
At time: 473.20563411712646 and batch: 350, loss is 3.7990169143676757 and perplexity is 44.6572609948952
At time: 474.3259358406067 and batch: 400, loss is 3.7332983303070066 and perplexity is 41.81680659227039
At time: 475.44363379478455 and batch: 450, loss is 3.787956190109253 and perplexity is 44.166040977438264
At time: 476.562415599823 and batch: 500, loss is 3.7979148054122924 and perplexity is 44.60807093900942
At time: 477.6860022544861 and batch: 550, loss is 3.77826274394989 and perplexity is 43.73998813339508
At time: 478.80923223495483 and batch: 600, loss is 3.741074047088623 and perplexity is 42.143229679105765
At time: 479.95949697494507 and batch: 650, loss is 3.7765043067932127 and perplexity is 43.6631416976441
At time: 481.08044600486755 and batch: 700, loss is 3.8284210443496702 and perplexity is 45.98986491827094
At time: 482.2065510749817 and batch: 750, loss is 3.767543568611145 and perplexity is 43.27363545469129
At time: 483.3249566555023 and batch: 800, loss is 3.7542478704452513 and perplexity is 42.702090225153775
At time: 484.45096826553345 and batch: 850, loss is 3.7519335317611695 and perplexity is 42.60337739737269
At time: 485.58010363578796 and batch: 900, loss is 3.710158920288086 and perplexity is 40.860299541615156
At time: 486.70246386528015 and batch: 950, loss is 3.799667167663574 and perplexity is 44.68630896928994
At time: 487.8282742500305 and batch: 1000, loss is 3.759645767211914 and perplexity is 42.9332149323694
At time: 488.95257902145386 and batch: 1050, loss is 3.7138807010650634 and perplexity is 41.01265596172284
At time: 490.07239270210266 and batch: 1100, loss is 3.731380372047424 and perplexity is 41.7366805664263
At time: 491.19233655929565 and batch: 1150, loss is 3.7140226650238035 and perplexity is 41.0184786940209
At time: 492.3139293193817 and batch: 1200, loss is 3.7461431980133058 and perplexity is 42.35740244923029
At time: 493.4339988231659 and batch: 1250, loss is 3.7480659818649293 and perplexity is 42.438924928593444
At time: 494.5549108982086 and batch: 1300, loss is 3.7081109857559205 and perplexity is 40.77670594950744
At time: 495.6726264953613 and batch: 1350, loss is 3.592774486541748 and perplexity is 36.33474647244636
At time: 496.7919113636017 and batch: 1400, loss is 3.6239523887634277 and perplexity is 37.485432422272126
At time: 497.91688346862793 and batch: 1450, loss is 3.567454104423523 and perplexity is 35.42628661851124
At time: 499.0416214466095 and batch: 1500, loss is 3.579749445915222 and perplexity is 35.86455371079695
At time: 500.16339588165283 and batch: 1550, loss is 3.598378610610962 and perplexity is 36.53894253531841
At time: 501.2829306125641 and batch: 1600, loss is 3.6797006225585935 and perplexity is 39.63452661306763
At time: 502.40187883377075 and batch: 1650, loss is 3.6278559827804564 and perplexity is 37.63204630636611
At time: 503.5200674533844 and batch: 1700, loss is 3.6262618780136107 and perplexity is 37.57210467127957
At time: 504.6389310359955 and batch: 1750, loss is 3.6042466735839844 and perplexity is 36.75398567736416
At time: 505.7601866722107 and batch: 1800, loss is 3.5601610136032105 and perplexity is 35.16885935401344
At time: 506.8801050186157 and batch: 1850, loss is 3.5820465660095215 and perplexity is 35.94703359462948
At time: 508.0006489753723 and batch: 1900, loss is 3.671490912437439 and perplexity is 39.31047066159187
At time: 509.1225039958954 and batch: 1950, loss is 3.6180749797821044 and perplexity is 37.265761385704465
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.347891022438227 and perplexity of 77.3152347681915
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 512.7547333240509 and batch: 50, loss is 3.84867112159729 and perplexity is 46.930656639343695
At time: 513.8739516735077 and batch: 100, loss is 3.8511526441574095 and perplexity is 47.04726074057247
At time: 514.9941356182098 and batch: 150, loss is 3.8233230018615725 and perplexity is 45.756003257742464
At time: 516.1149713993073 and batch: 200, loss is 3.823081111907959 and perplexity is 45.744936678738014
At time: 517.2333042621613 and batch: 250, loss is 3.83596743106842 and perplexity is 46.338235038666646
At time: 518.3521733283997 and batch: 300, loss is 3.8330902576446535 and perplexity is 46.205103513392295
At time: 519.4720249176025 and batch: 350, loss is 3.8464227533340454 and perplexity is 46.825257772516814
At time: 520.5941996574402 and batch: 400, loss is 3.7863492298126222 and perplexity is 44.095124898050805
At time: 521.7135488986969 and batch: 450, loss is 3.839627103805542 and perplexity is 46.5081285017434
At time: 522.8322675228119 and batch: 500, loss is 3.8477063512802125 and perplexity is 46.88540116893462
At time: 523.9506702423096 and batch: 550, loss is 3.831677131652832 and perplexity is 46.13985599300407
At time: 525.0696334838867 and batch: 600, loss is 3.7892581748962404 and perplexity is 44.22358194149381
At time: 526.1884903907776 and batch: 650, loss is 3.815745644569397 and perplexity is 45.41060393247357
At time: 527.3097267150879 and batch: 700, loss is 3.8570064306259155 and perplexity is 47.32347301396764
At time: 528.4305424690247 and batch: 750, loss is 3.7963953018188477 and perplexity is 44.54034028643784
At time: 529.5482409000397 and batch: 800, loss is 3.782394232749939 and perplexity is 43.921073222409646
At time: 530.6655163764954 and batch: 850, loss is 3.7762994050979612 and perplexity is 43.6541959624197
At time: 531.7798402309418 and batch: 900, loss is 3.731033444404602 and perplexity is 41.72220346961591
At time: 532.9037535190582 and batch: 950, loss is 3.825390877723694 and perplexity is 45.85071888875866
At time: 534.0318982601166 and batch: 1000, loss is 3.780472869873047 and perplexity is 43.836765921202236
At time: 535.1934475898743 and batch: 1050, loss is 3.7324156904220582 and perplexity is 41.77991369487736
At time: 536.3096680641174 and batch: 1100, loss is 3.7521540307998658 and perplexity is 42.61277243689455
At time: 537.42622423172 and batch: 1150, loss is 3.7371990203857424 and perplexity is 41.980239538280266
At time: 538.5404119491577 and batch: 1200, loss is 3.7690584373474123 and perplexity is 43.33923900998794
At time: 539.6608791351318 and batch: 1250, loss is 3.770710892677307 and perplexity is 43.41091437033941
At time: 540.7827203273773 and batch: 1300, loss is 3.7345423984527586 and perplexity is 41.8688619227843
At time: 541.9019448757172 and batch: 1350, loss is 3.608596963882446 and perplexity is 36.91422447461857
At time: 543.0192227363586 and batch: 1400, loss is 3.627518444061279 and perplexity is 37.619346177169085
At time: 544.1451601982117 and batch: 1450, loss is 3.5627553176879885 and perplexity is 35.2602165223908
At time: 545.2641599178314 and batch: 1500, loss is 3.572730293273926 and perplexity is 35.61369636682947
At time: 546.3782548904419 and batch: 1550, loss is 3.5963834428787234 and perplexity is 36.46611389303939
At time: 547.4946761131287 and batch: 1600, loss is 3.6785253190994265 and perplexity is 39.587971380458846
At time: 548.6118357181549 and batch: 1650, loss is 3.6356033802032472 and perplexity is 37.92472902565416
At time: 549.7330062389374 and batch: 1700, loss is 3.6299215364456177 and perplexity is 37.70985765163119
At time: 550.8486123085022 and batch: 1750, loss is 3.6047057056427003 and perplexity is 36.7708608078923
At time: 551.9654357433319 and batch: 1800, loss is 3.55894859790802 and perplexity is 35.12624591477194
At time: 553.0797026157379 and batch: 1850, loss is 3.5698980331420898 and perplexity is 35.51297182085212
At time: 554.2032988071442 and batch: 1900, loss is 3.6647525930404665 and perplexity is 39.04647459841857
At time: 555.3213489055634 and batch: 1950, loss is 3.6190329027175903 and perplexity is 37.301476216540934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.335079317314681 and perplexity of 76.33101302064549
finished 12 epochs...
Completing Train Step...
At time: 559.0289390087128 and batch: 50, loss is 3.856037931442261 and perplexity is 47.27766245631058
At time: 560.1577770709991 and batch: 100, loss is 3.8445012187957763 and perplexity is 46.73536781343244
At time: 561.2803430557251 and batch: 150, loss is 3.803733410835266 and perplexity is 44.868384298411875
At time: 562.4018545150757 and batch: 200, loss is 3.795996627807617 and perplexity is 44.522586749486315
At time: 563.5793168544769 and batch: 250, loss is 3.804772663116455 and perplexity is 44.91503810748699
At time: 564.7002866268158 and batch: 300, loss is 3.8007470846176146 and perplexity is 44.734592538389364
At time: 565.8174841403961 and batch: 350, loss is 3.8135987663269044 and perplexity is 45.31321747075559
At time: 566.9423751831055 and batch: 400, loss is 3.754032335281372 and perplexity is 42.69288741493934
At time: 568.0622098445892 and batch: 450, loss is 3.8093737077713015 and perplexity is 45.12217035043433
At time: 569.1817288398743 and batch: 500, loss is 3.8193966245651243 and perplexity is 45.57670016152934
At time: 570.3018772602081 and batch: 550, loss is 3.806311330795288 and perplexity is 44.98420062033291
At time: 571.4199326038361 and batch: 600, loss is 3.767795886993408 and perplexity is 43.284555565998325
At time: 572.5401482582092 and batch: 650, loss is 3.7958663511276245 and perplexity is 44.516786872502465
At time: 573.6572721004486 and batch: 700, loss is 3.8402735137939454 and perplexity is 46.538201539257635
At time: 574.7749404907227 and batch: 750, loss is 3.7807350635528563 and perplexity is 43.84826115109251
At time: 575.8951480388641 and batch: 800, loss is 3.766182928085327 and perplexity is 43.214795631593795
At time: 577.0156331062317 and batch: 850, loss is 3.759452919960022 and perplexity is 42.924936178147966
At time: 578.1428890228271 and batch: 900, loss is 3.714687714576721 and perplexity is 41.04576708799904
At time: 579.2636346817017 and batch: 950, loss is 3.8080444955825805 and perplexity is 45.06223325500665
At time: 580.3815865516663 and batch: 1000, loss is 3.7641528940200804 and perplexity is 43.127157109028914
At time: 581.5002059936523 and batch: 1050, loss is 3.7169314575195314 and perplexity is 41.137966635596456
At time: 582.6205606460571 and batch: 1100, loss is 3.737430386543274 and perplexity is 41.98995346868854
At time: 583.7410659790039 and batch: 1150, loss is 3.724545021057129 and perplexity is 41.45236849893969
At time: 584.8592653274536 and batch: 1200, loss is 3.757629542350769 and perplexity is 42.846739123686405
At time: 585.9778451919556 and batch: 1250, loss is 3.759993705749512 and perplexity is 42.9481556514626
At time: 587.1033065319061 and batch: 1300, loss is 3.7254610109329223 and perplexity is 41.49035584416813
At time: 588.2192485332489 and batch: 1350, loss is 3.601928400993347 and perplexity is 36.66887860858059
At time: 589.3378829956055 and batch: 1400, loss is 3.6228351736068727 and perplexity is 37.44357651440088
At time: 590.4582033157349 and batch: 1450, loss is 3.5602601194381713 and perplexity is 35.172344965903726
At time: 591.5777904987335 and batch: 1500, loss is 3.572152876853943 and perplexity is 35.59313836960473
At time: 592.6977393627167 and batch: 1550, loss is 3.5968485975265505 and perplexity is 36.48308022108219
At time: 593.8200395107269 and batch: 1600, loss is 3.680445032119751 and perplexity is 39.66404191800496
At time: 594.9417262077332 and batch: 1650, loss is 3.638268871307373 and perplexity is 38.02595189790013
At time: 596.0609550476074 and batch: 1700, loss is 3.6342375469207764 and perplexity is 37.87296552672413
At time: 597.1806230545044 and batch: 1750, loss is 3.6105406045913697 and perplexity is 36.98604223539846
At time: 598.3088314533234 and batch: 1800, loss is 3.5656808948516847 and perplexity is 35.363524050023436
At time: 599.4360947608948 and batch: 1850, loss is 3.5772139120101927 and perplexity is 35.773733106891335
At time: 600.5626537799835 and batch: 1900, loss is 3.6720568132400513 and perplexity is 39.332722784143506
At time: 601.6797242164612 and batch: 1950, loss is 3.624723343849182 and perplexity is 37.5143431500441
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333713265352471 and perplexity of 76.2268120786859
finished 13 epochs...
Completing Train Step...
At time: 605.2819967269897 and batch: 50, loss is 3.850452013015747 and perplexity is 47.014309509245045
At time: 606.4283680915833 and batch: 100, loss is 3.8373327159881594 and perplexity is 46.40154313913583
At time: 607.5481765270233 and batch: 150, loss is 3.7947509908676147 and perplexity is 44.46716229730563
At time: 608.6617813110352 and batch: 200, loss is 3.7856378698349 and perplexity is 44.063768545135204
At time: 609.7776098251343 and batch: 250, loss is 3.79351327419281 and perplexity is 44.4121585955703
At time: 610.8970420360565 and batch: 300, loss is 3.789031434059143 and perplexity is 44.21355578621732
At time: 612.0130290985107 and batch: 350, loss is 3.8014472341537475 and perplexity is 44.765924409821906
At time: 613.127748966217 and batch: 400, loss is 3.741660785675049 and perplexity is 42.16796399369391
At time: 614.2422888278961 and batch: 450, loss is 3.797296390533447 and perplexity is 44.58049317235366
At time: 615.3556189537048 and batch: 500, loss is 3.807403678894043 and perplexity is 45.03336587425161
At time: 616.4781038761139 and batch: 550, loss is 3.794720869064331 and perplexity is 44.46582288636316
At time: 617.6030209064484 and batch: 600, loss is 3.757458882331848 and perplexity is 42.83942752229363
At time: 618.7183105945587 and batch: 650, loss is 3.7860187005996706 and perplexity is 44.0805525795444
At time: 619.8664846420288 and batch: 700, loss is 3.8310778617858885 and perplexity is 46.11221405096105
At time: 620.9820337295532 and batch: 750, loss is 3.7721228122711183 and perplexity is 43.47225038149261
At time: 622.0948083400726 and batch: 800, loss is 3.757790274620056 and perplexity is 42.85362653079677
At time: 623.2067360877991 and batch: 850, loss is 3.7508285999298097 and perplexity is 42.55632956667239
At time: 624.3201687335968 and batch: 900, loss is 3.7064292573928834 and perplexity is 40.708188236799884
At time: 625.4348130226135 and batch: 950, loss is 3.799984974861145 and perplexity is 44.70051285684256
At time: 626.5536942481995 and batch: 1000, loss is 3.75665566444397 and perplexity is 42.805031943222666
At time: 627.6729340553284 and batch: 1050, loss is 3.709959044456482 and perplexity is 40.85213337140191
At time: 628.7881345748901 and batch: 1100, loss is 3.7305212879180907 and perplexity is 41.700840643499355
At time: 629.9040057659149 and batch: 1150, loss is 3.718201413154602 and perplexity is 41.190243215583436
At time: 631.0228102207184 and batch: 1200, loss is 3.751636061668396 and perplexity is 42.59070605151249
At time: 632.1392648220062 and batch: 1250, loss is 3.7541939306259153 and perplexity is 42.6997869442416
At time: 633.2538647651672 and batch: 1300, loss is 3.7201028299331664 and perplexity is 41.26863754167137
At time: 634.368982553482 and batch: 1350, loss is 3.597294797897339 and perplexity is 36.49936261733983
At time: 635.4856009483337 and batch: 1400, loss is 3.6190692806243896 and perplexity is 37.302833190848006
At time: 636.6011598110199 and batch: 1450, loss is 3.557710580825806 and perplexity is 35.08278592994808
At time: 637.7168927192688 and batch: 1500, loss is 3.570614037513733 and perplexity is 35.5384083691791
At time: 638.8376352787018 and batch: 1550, loss is 3.5956998300552367 and perplexity is 36.44119370880863
At time: 639.961724281311 and batch: 1600, loss is 3.6800248861312865 and perplexity is 39.64738073021752
At time: 641.0783460140228 and batch: 1650, loss is 3.638243308067322 and perplexity is 38.02497984378808
At time: 642.1962652206421 and batch: 1700, loss is 3.634875988960266 and perplexity is 37.897152940385816
At time: 643.312157869339 and batch: 1750, loss is 3.6116799545288085 and perplexity is 37.02820629555395
At time: 644.4319543838501 and batch: 1800, loss is 3.567192621231079 and perplexity is 35.417024450993146
At time: 645.5535817146301 and batch: 1850, loss is 3.5789502668380737 and perplexity is 35.83590295992524
At time: 646.6707992553711 and batch: 1900, loss is 3.673712954521179 and perplexity is 39.39791730080935
At time: 647.7875924110413 and batch: 1950, loss is 3.6256736087799073 and perplexity is 37.55000865789562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333589207848838 and perplexity of 76.2173561572206
finished 14 epochs...
Completing Train Step...
At time: 651.3987789154053 and batch: 50, loss is 3.8445381116867066 and perplexity is 46.73709204806557
At time: 652.5423665046692 and batch: 100, loss is 3.8310016536712648 and perplexity is 46.10870005996612
At time: 653.6625587940216 and batch: 150, loss is 3.787609295845032 and perplexity is 44.150722688216774
At time: 654.781952381134 and batch: 200, loss is 3.7779223489761353 and perplexity is 43.7251017950435
At time: 655.901171207428 and batch: 250, loss is 3.7853156518936157 and perplexity is 44.04957269555091
At time: 657.0292234420776 and batch: 300, loss is 3.78055269241333 and perplexity is 43.84026522287557
At time: 658.1478538513184 and batch: 350, loss is 3.7927682161331178 and perplexity is 44.37908128264976
At time: 659.266998052597 and batch: 400, loss is 3.7328872442245484 and perplexity is 41.79961981793136
At time: 660.3919720649719 and batch: 450, loss is 3.7887813520431517 and perplexity is 44.20250015351724
At time: 661.5223603248596 and batch: 500, loss is 3.798932819366455 and perplexity is 44.65350570038028
At time: 662.6407010555267 and batch: 550, loss is 3.7863703918457032 and perplexity is 44.096058050416275
At time: 663.7590110301971 and batch: 600, loss is 3.749940414428711 and perplexity is 42.51854843258276
At time: 664.8836679458618 and batch: 650, loss is 3.778769063949585 and perplexity is 43.76214017171021
At time: 666.0023739337921 and batch: 700, loss is 3.8241829681396484 and perplexity is 45.79536880165776
At time: 667.1339015960693 and batch: 750, loss is 3.7657189893722536 and perplexity is 43.1947512649611
At time: 668.2527260780334 and batch: 800, loss is 3.7515320205688476 and perplexity is 42.58627509812897
At time: 669.3709182739258 and batch: 850, loss is 3.7443366384506227 and perplexity is 42.28095035720697
At time: 670.4891502857208 and batch: 900, loss is 3.7000966930389403 and perplexity is 40.451215521930926
At time: 671.606189250946 and batch: 950, loss is 3.793886480331421 and perplexity is 44.42873657909731
At time: 672.723895072937 and batch: 1000, loss is 3.7509651231765746 and perplexity is 42.56213989156842
At time: 673.8438980579376 and batch: 1050, loss is 3.7047425222396853 and perplexity is 40.639582181066615
At time: 674.9623641967773 and batch: 1100, loss is 3.7253408908843992 and perplexity is 41.48537231992747
At time: 676.1044087409973 and batch: 1150, loss is 3.713308057785034 and perplexity is 40.98917706304859
At time: 677.2234890460968 and batch: 1200, loss is 3.746897215843201 and perplexity is 42.38935272993195
At time: 678.3415529727936 and batch: 1250, loss is 3.7495585012435915 and perplexity is 42.50231313875794
At time: 679.4579265117645 and batch: 1300, loss is 3.7155126571655273 and perplexity is 41.079641459645025
At time: 680.5751812458038 and batch: 1350, loss is 3.59296190738678 and perplexity is 36.341556999531676
At time: 681.6946520805359 and batch: 1400, loss is 3.615310745239258 and perplexity is 37.1628923234261
At time: 682.811781167984 and batch: 1450, loss is 3.5548517894744873 and perplexity is 34.98263478876816
At time: 683.9304661750793 and batch: 1500, loss is 3.5684128284454344 and perplexity is 35.46026693677047
At time: 685.0486752986908 and batch: 1550, loss is 3.593748779296875 and perplexity is 36.37016440360902
At time: 686.1730225086212 and batch: 1600, loss is 3.6786446523666383 and perplexity is 39.59269582431202
At time: 687.29319190979 and batch: 1650, loss is 3.637021551132202 and perplexity is 37.97855092915568
At time: 688.4124717712402 and batch: 1700, loss is 3.6341446590423585 and perplexity is 37.86944775068887
At time: 689.5329616069794 and batch: 1750, loss is 3.611224179267883 and perplexity is 37.01133360053857
At time: 690.6497848033905 and batch: 1800, loss is 3.5669649839401245 and perplexity is 35.40896313305655
At time: 691.7765762805939 and batch: 1850, loss is 3.578929233551025 and perplexity is 35.835149221018476
At time: 692.8938276767731 and batch: 1900, loss is 3.6737037181854246 and perplexity is 39.397553410097636
At time: 694.0107989311218 and batch: 1950, loss is 3.6253022384643554 and perplexity is 37.536066288382685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.333906874545785 and perplexity of 76.24157171903626
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 697.6185579299927 and batch: 50, loss is 3.8446828508377076 and perplexity is 46.74385722467001
At time: 698.7652175426483 and batch: 100, loss is 3.8421071767807007 and perplexity is 46.623615202894776
At time: 699.8811411857605 and batch: 150, loss is 3.8022872400283814 and perplexity is 44.80354384737179
At time: 700.998616695404 and batch: 200, loss is 3.7976052951812744 and perplexity is 44.59426642109779
At time: 702.120080947876 and batch: 250, loss is 3.806715683937073 and perplexity is 45.00239380117145
At time: 703.2640397548676 and batch: 300, loss is 3.7976242971420286 and perplexity is 44.59511380764916
At time: 704.3913950920105 and batch: 350, loss is 3.8099452018737794 and perplexity is 45.147964774659215
At time: 705.511177778244 and batch: 400, loss is 3.755010209083557 and perplexity is 42.7346560900002
At time: 706.6299514770508 and batch: 450, loss is 3.8119158267974855 and perplexity is 45.237022199869465
At time: 707.7469065189362 and batch: 500, loss is 3.825956711769104 and perplexity is 45.87667012786734
At time: 708.8662371635437 and batch: 550, loss is 3.8200476932525635 and perplexity is 45.606383385741694
At time: 709.9891912937164 and batch: 600, loss is 3.7823525428771974 and perplexity is 43.91924219662421
At time: 711.1121640205383 and batch: 650, loss is 3.8061290550231934 and perplexity is 44.976001837675206
At time: 712.2380576133728 and batch: 700, loss is 3.8472528219223023 and perplexity is 46.86414208422102
At time: 713.3621563911438 and batch: 750, loss is 3.783733401298523 and perplexity is 43.97993034329568
At time: 714.4841854572296 and batch: 800, loss is 3.7685999965667722 and perplexity is 43.31937508898748
At time: 715.6106140613556 and batch: 850, loss is 3.762550172805786 and perplexity is 43.058091660531936
At time: 716.7311570644379 and batch: 900, loss is 3.7138641834259034 and perplexity is 41.01197853506544
At time: 717.8568308353424 and batch: 950, loss is 3.808579978942871 and perplexity is 45.086369792872695
At time: 718.9759542942047 and batch: 1000, loss is 3.76553964138031 and perplexity is 43.187005067712455
At time: 720.0969438552856 and batch: 1050, loss is 3.716733207702637 and perplexity is 41.129811849612665
At time: 721.2134816646576 and batch: 1100, loss is 3.7361883449554445 and perplexity is 41.93783257506857
At time: 722.3316638469696 and batch: 1150, loss is 3.7271674823760987 and perplexity is 41.56121839684846
At time: 723.4518420696259 and batch: 1200, loss is 3.7618198156356812 and perplexity is 43.02665535581931
At time: 724.5685346126556 and batch: 1250, loss is 3.766844277381897 and perplexity is 43.243385159076055
At time: 725.686342716217 and batch: 1300, loss is 3.7449621534347535 and perplexity is 42.30740599853612
At time: 726.8115434646606 and batch: 1350, loss is 3.622647614479065 and perplexity is 37.436554288409724
At time: 727.9355843067169 and batch: 1400, loss is 3.644810061454773 and perplexity is 38.27550216788869
At time: 729.0544762611389 and batch: 1450, loss is 3.568489713668823 and perplexity is 35.46299341212682
At time: 730.1748969554901 and batch: 1500, loss is 3.566534037590027 and perplexity is 35.393707057144844
At time: 731.2950332164764 and batch: 1550, loss is 3.5905938386917113 and perplexity is 36.25559951285669
At time: 732.4212787151337 and batch: 1600, loss is 3.673970832824707 and perplexity is 39.4080784790028
At time: 733.5450031757355 and batch: 1650, loss is 3.6262929105758666 and perplexity is 37.5732706480484
At time: 734.6672570705414 and batch: 1700, loss is 3.6269171047210693 and perplexity is 37.596730984743715
At time: 735.7836685180664 and batch: 1750, loss is 3.605391812324524 and perplexity is 36.79609819796996
At time: 736.9015979766846 and batch: 1800, loss is 3.5642643356323243 and perplexity is 35.313464988184954
At time: 738.0203337669373 and batch: 1850, loss is 3.5737596225738524 and perplexity is 35.6503734611441
At time: 739.1395835876465 and batch: 1900, loss is 3.6698359060287475 and perplexity is 39.24546538762848
At time: 740.2566888332367 and batch: 1950, loss is 3.6252050399780273 and perplexity is 37.53241801686285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3269650481468025 and perplexity of 75.71414872121716
finished 16 epochs...
Completing Train Step...
At time: 743.8774468898773 and batch: 50, loss is 3.848909592628479 and perplexity is 46.941849575969385
At time: 745.0010647773743 and batch: 100, loss is 3.838906474113464 and perplexity is 46.47462543652372
At time: 746.118396282196 and batch: 150, loss is 3.796757960319519 and perplexity is 44.55649614881885
At time: 747.2367537021637 and batch: 200, loss is 3.787734851837158 and perplexity is 44.156266424024324
At time: 748.367502450943 and batch: 250, loss is 3.7950606966018676 and perplexity is 44.48093616526791
At time: 749.4816172122955 and batch: 300, loss is 3.7874392652511597 and perplexity is 44.143216352789636
At time: 750.5991234779358 and batch: 350, loss is 3.7993037939071654 and perplexity is 44.670074087183416
At time: 751.715784072876 and batch: 400, loss is 3.742800598144531 and perplexity is 42.21605496700558
At time: 752.8319299221039 and batch: 450, loss is 3.8001204538345337 and perplexity is 44.70656924668182
At time: 753.9498634338379 and batch: 500, loss is 3.8134829807281494 and perplexity is 45.3079711564689
At time: 755.0674414634705 and batch: 550, loss is 3.805594115257263 and perplexity is 44.95194881981113
At time: 756.1832687854767 and batch: 600, loss is 3.7691868257522585 and perplexity is 43.34480362295993
At time: 757.3002142906189 and batch: 650, loss is 3.7938007497787476 and perplexity is 44.4249278422207
At time: 758.4171574115753 and batch: 700, loss is 3.836828575134277 and perplexity is 46.378156121227136
At time: 759.5605852603912 and batch: 750, loss is 3.776616816520691 and perplexity is 43.668054502181306
At time: 760.6789371967316 and batch: 800, loss is 3.762279682159424 and perplexity is 43.046446424522266
At time: 761.7974863052368 and batch: 850, loss is 3.757016730308533 and perplexity is 42.82049016963989
At time: 762.9134969711304 and batch: 900, loss is 3.7092851305007937 and perplexity is 40.824611823222575
At time: 764.0304462909698 and batch: 950, loss is 3.80461323261261 and perplexity is 44.9078778511281
At time: 765.1495780944824 and batch: 1000, loss is 3.761145553588867 and perplexity is 42.99765389350294
At time: 766.269777059555 and batch: 1050, loss is 3.7124151468276976 and perplexity is 40.95259371298447
At time: 767.3878507614136 and batch: 1100, loss is 3.7308606338500976 and perplexity is 41.71499405544856
At time: 768.5060713291168 and batch: 1150, loss is 3.7206163883209227 and perplexity is 41.2898368397049
At time: 769.6228680610657 and batch: 1200, loss is 3.755820369720459 and perplexity is 42.76929205464898
At time: 770.7408218383789 and batch: 1250, loss is 3.7610193347930907 and perplexity is 42.99222712389466
At time: 771.857919216156 and batch: 1300, loss is 3.7381967735290527 and perplexity is 42.02214635709004
At time: 772.9785618782043 and batch: 1350, loss is 3.617430214881897 and perplexity is 37.24174147521318
At time: 774.0954613685608 and batch: 1400, loss is 3.641083493232727 and perplexity is 38.133131339890966
At time: 775.2118752002716 and batch: 1450, loss is 3.5673411464691163 and perplexity is 35.42228516364493
At time: 776.328498840332 and batch: 1500, loss is 3.567601203918457 and perplexity is 35.43149819068064
At time: 777.4426012039185 and batch: 1550, loss is 3.5932294940948486 and perplexity is 36.351282818327164
At time: 778.5583205223083 and batch: 1600, loss is 3.6769789552688597 and perplexity is 39.526801281194466
At time: 779.6796288490295 and batch: 1650, loss is 3.6306005477905274 and perplexity is 37.735471767945235
At time: 780.796816110611 and batch: 1700, loss is 3.6320071744918825 and perplexity is 37.78858883930958
At time: 781.9218308925629 and batch: 1750, loss is 3.611781430244446 and perplexity is 37.03196394993868
At time: 783.0378828048706 and batch: 1800, loss is 3.5702395677566527 and perplexity is 35.525102801451915
At time: 784.1513993740082 and batch: 1850, loss is 3.579688215255737 and perplexity is 35.86235776775131
At time: 785.2688882350922 and batch: 1900, loss is 3.676021943092346 and perplexity is 39.488991746048214
At time: 786.3860657215118 and batch: 1950, loss is 3.6301304149627684 and perplexity is 37.717735253481685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.32582269712936 and perplexity of 75.62770596977363
finished 17 epochs...
Completing Train Step...
At time: 790.0276341438293 and batch: 50, loss is 3.8483888959884642 and perplexity is 46.91741347506902
At time: 791.1447103023529 and batch: 100, loss is 3.836447377204895 and perplexity is 46.36048023336513
At time: 792.2632901668549 and batch: 150, loss is 3.793817610740662 and perplexity is 44.42567689555195
At time: 793.3835508823395 and batch: 200, loss is 3.783619999885559 and perplexity is 43.97494323983032
At time: 794.505209684372 and batch: 250, loss is 3.7903773164749146 and perplexity is 44.27310209566563
At time: 795.6253097057343 and batch: 300, loss is 3.7828249979019164 and perplexity is 43.939996965743276
At time: 796.7466206550598 and batch: 350, loss is 3.7942664194107056 and perplexity is 44.445619999499456
At time: 797.8653907775879 and batch: 400, loss is 3.737138285636902 and perplexity is 41.97768995640054
At time: 798.9906747341156 and batch: 450, loss is 3.7944194364547728 and perplexity is 44.45242145724972
At time: 800.1146891117096 and batch: 500, loss is 3.80766273021698 and perplexity is 45.0450333384284
At time: 801.2465240955353 and batch: 550, loss is 3.7993163681030273 and perplexity is 44.67063578097557
At time: 802.3724710941315 and batch: 600, loss is 3.7636290693283083 and perplexity is 43.104571955096354
At time: 803.4931633472443 and batch: 650, loss is 3.7886275911331175 and perplexity is 44.195704059368055
At time: 804.612555027008 and batch: 700, loss is 3.83239248752594 and perplexity is 46.172874218455725
At time: 805.7367510795593 and batch: 750, loss is 3.7730178880691527 and perplexity is 43.51117876002092
At time: 806.8655817508698 and batch: 800, loss is 3.7588748025894163 and perplexity is 42.90012769870865
At time: 807.9915194511414 and batch: 850, loss is 3.753325400352478 and perplexity is 42.66271698713149
At time: 809.1153664588928 and batch: 900, loss is 3.705948038101196 and perplexity is 40.688603383973145
At time: 810.2351417541504 and batch: 950, loss is 3.801594557762146 and perplexity is 44.77251997316842
At time: 811.3568572998047 and batch: 1000, loss is 3.7582673835754394 and perplexity is 42.874077258009876
At time: 812.4832663536072 and batch: 1050, loss is 3.709927759170532 and perplexity is 40.850855320719916
At time: 813.6049931049347 and batch: 1100, loss is 3.728417491912842 and perplexity is 41.613202799934086
At time: 814.7824993133545 and batch: 1150, loss is 3.718133668899536 and perplexity is 41.18745290775554
At time: 815.9042658805847 and batch: 1200, loss is 3.753725700378418 and perplexity is 42.6797982924435
At time: 817.0273916721344 and batch: 1250, loss is 3.759205656051636 and perplexity is 42.91432370275648
At time: 818.1579391956329 and batch: 1300, loss is 3.736618161201477 and perplexity is 41.955862011227445
At time: 819.2850782871246 and batch: 1350, loss is 3.6163717317581177 and perplexity is 37.2023425755752
At time: 820.4134957790375 and batch: 1400, loss is 3.640603699684143 and perplexity is 38.11483969794357
At time: 821.5373511314392 and batch: 1450, loss is 3.567665991783142 and perplexity is 35.43379379615389
At time: 822.6659774780273 and batch: 1500, loss is 3.5685501766204832 and perplexity is 35.46513767420677
At time: 823.7947764396667 and batch: 1550, loss is 3.5947066354751587 and perplexity is 36.40501848021966
At time: 824.9260973930359 and batch: 1600, loss is 3.678632664680481 and perplexity is 39.59222120234516
At time: 826.0480923652649 and batch: 1650, loss is 3.6323323106765746 and perplexity is 37.800877274508906
At time: 827.1674988269806 and batch: 1700, loss is 3.63378821849823 and perplexity is 37.85595194949502
At time: 828.2975168228149 and batch: 1750, loss is 3.6140146350860594 and perplexity is 37.11475632288165
At time: 829.4222164154053 and batch: 1800, loss is 3.5723459005355833 and perplexity is 35.600009351323735
At time: 830.5450389385223 and batch: 1850, loss is 3.5817313766479493 and perplexity is 35.93570525743984
At time: 831.672943353653 and batch: 1900, loss is 3.6780553388595583 and perplexity is 39.569370187612485
At time: 832.8028635978699 and batch: 1950, loss is 3.631540970802307 and perplexity is 37.770975765727805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325386082848837 and perplexity of 75.59469304082658
finished 18 epochs...
Completing Train Step...
At time: 836.4597144126892 and batch: 50, loss is 3.8469335556030275 and perplexity is 46.84918233027169
At time: 837.5866425037384 and batch: 100, loss is 3.8342563247680665 and perplexity is 46.259013190575786
At time: 838.7212421894073 and batch: 150, loss is 3.7913209104537966 and perplexity is 44.31489764414234
At time: 839.8467144966125 and batch: 200, loss is 3.7806774854660032 and perplexity is 43.84573652478587
At time: 840.9757850170135 and batch: 250, loss is 3.7871476888656614 and perplexity is 44.1303471095961
At time: 842.0995619297028 and batch: 300, loss is 3.7795121479034424 and perplexity is 43.794671201004306
At time: 843.2529690265656 and batch: 350, loss is 3.790792212486267 and perplexity is 44.29147464021949
At time: 844.3804790973663 and batch: 400, loss is 3.7333798217773437 and perplexity is 41.820214444177935
At time: 845.506454706192 and batch: 450, loss is 3.7906729125976564 and perplexity is 44.286190987404375
At time: 846.6282410621643 and batch: 500, loss is 3.803908290863037 and perplexity is 44.876231568849455
At time: 847.7462725639343 and batch: 550, loss is 3.795476350784302 and perplexity is 44.4994286954061
At time: 848.867112159729 and batch: 600, loss is 3.7601657152175902 and perplexity is 42.955543776266644
At time: 849.9893572330475 and batch: 650, loss is 3.7853937673568727 and perplexity is 44.0530137827276
At time: 851.1112332344055 and batch: 700, loss is 3.8294897270202637 and perplexity is 46.03903976140323
At time: 852.2296240329742 and batch: 750, loss is 3.7705061864852905 and perplexity is 43.40202879686369
At time: 853.3536841869354 and batch: 800, loss is 3.7564873695373535 and perplexity is 42.79782868052228
At time: 854.4823203086853 and batch: 850, loss is 3.750769381523132 and perplexity is 42.55380952325863
At time: 855.6054489612579 and batch: 900, loss is 3.7035752439498903 and perplexity is 40.59217215481067
At time: 856.7355563640594 and batch: 950, loss is 3.7994617414474487 and perplexity is 44.677130172740775
At time: 857.8638200759888 and batch: 1000, loss is 3.7563249254226685 and perplexity is 42.79087698977774
At time: 858.9929246902466 and batch: 1050, loss is 3.7082227754592894 and perplexity is 40.78126462017136
At time: 860.1263604164124 and batch: 1100, loss is 3.726761155128479 and perplexity is 41.544334371821556
At time: 861.2433791160583 and batch: 1150, loss is 3.716550517082214 and perplexity is 41.12229850509767
At time: 862.3641893863678 and batch: 1200, loss is 3.752361731529236 and perplexity is 42.62162406002265
At time: 863.491765499115 and batch: 1250, loss is 3.757978343963623 and perplexity is 42.861686742123446
At time: 864.6202306747437 and batch: 1300, loss is 3.7356120014190672 and perplexity is 41.913668940280495
At time: 865.7404692173004 and batch: 1350, loss is 3.6155466175079347 and perplexity is 37.17165905302257
At time: 866.86119389534 and batch: 1400, loss is 3.64002242565155 and perplexity is 38.09269096923477
At time: 867.9815573692322 and batch: 1450, loss is 3.5675030326843262 and perplexity is 35.42802000750772
At time: 869.1086339950562 and batch: 1500, loss is 3.568732681274414 and perplexity is 35.47161081755604
At time: 870.2373485565186 and batch: 1550, loss is 3.5951583623886108 and perplexity is 36.421467321764396
At time: 871.3663148880005 and batch: 1600, loss is 3.679267616271973 and perplexity is 39.617368328967466
At time: 872.4846487045288 and batch: 1650, loss is 3.632994785308838 and perplexity is 37.82592769349797
At time: 873.6039361953735 and batch: 1700, loss is 3.6344369506835936 and perplexity is 37.88051829155905
At time: 874.7296512126923 and batch: 1750, loss is 3.614886221885681 and perplexity is 37.147119156024196
At time: 875.8551898002625 and batch: 1800, loss is 3.573184652328491 and perplexity is 35.62988144888112
At time: 876.9805619716644 and batch: 1850, loss is 3.5825260925292968 and perplexity is 35.96427528413865
At time: 878.1089758872986 and batch: 1900, loss is 3.6788257551193237 and perplexity is 39.59986681983595
At time: 879.2287530899048 and batch: 1950, loss is 3.631942253112793 and perplexity is 37.78613563164196
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325187647619913 and perplexity of 75.57969387883786
finished 19 epochs...
Completing Train Step...
At time: 882.865154504776 and batch: 50, loss is 3.845333218574524 and perplexity is 46.7742678092629
At time: 884.0094518661499 and batch: 100, loss is 3.832274680137634 and perplexity is 46.167435033127866
At time: 885.138462305069 and batch: 150, loss is 3.7891419315338135 and perplexity is 44.2184415424048
At time: 886.2570953369141 and batch: 200, loss is 3.7782867765426635 and perplexity is 43.74103933134926
At time: 887.3765554428101 and batch: 250, loss is 3.7845702886581423 and perplexity is 44.01675199671597
At time: 888.4948194026947 and batch: 300, loss is 3.776839098930359 and perplexity is 43.677762221449214
At time: 889.6111755371094 and batch: 350, loss is 3.788034715652466 and perplexity is 44.1695092759708
At time: 890.7308728694916 and batch: 400, loss is 3.730467038154602 and perplexity is 41.69857844411961
At time: 891.8528945446014 and batch: 450, loss is 3.787808742523193 and perplexity is 44.15952928138905
At time: 892.9710967540741 and batch: 500, loss is 3.8010539531707765 and perplexity is 44.74832228458384
At time: 894.0907378196716 and batch: 550, loss is 3.792610034942627 and perplexity is 44.372061901921214
At time: 895.2089152336121 and batch: 600, loss is 3.757532901763916 and perplexity is 42.842598589747794
At time: 896.3263471126556 and batch: 650, loss is 3.782892279624939 and perplexity is 43.94295342390543
At time: 897.44491147995 and batch: 700, loss is 3.8271951723098754 and perplexity is 45.933521770554265
At time: 898.5659143924713 and batch: 750, loss is 3.7684518098831177 and perplexity is 43.312956210062985
At time: 899.7499330043793 and batch: 800, loss is 3.7545361518859863 and perplexity is 42.7144022198208
At time: 900.8756139278412 and batch: 850, loss is 3.7487320137023925 and perplexity is 42.467200018753495
At time: 901.9947240352631 and batch: 900, loss is 3.7016627597808838 and perplexity is 40.514614455754376
At time: 903.1129188537598 and batch: 950, loss is 3.797736716270447 and perplexity is 44.60012743328357
At time: 904.2309081554413 and batch: 1000, loss is 3.7547588109970094 and perplexity is 42.72391402955319
At time: 905.3606133460999 and batch: 1050, loss is 3.7068119430541993 and perplexity is 40.72376965793933
At time: 906.4786298274994 and batch: 1100, loss is 3.725370726585388 and perplexity is 41.4866100835561
At time: 907.5988512039185 and batch: 1150, loss is 3.715242652893066 and perplexity is 41.06855127820532
At time: 908.7293863296509 and batch: 1200, loss is 3.7511943101882936 and perplexity is 42.57189569913202
At time: 909.8501815795898 and batch: 1250, loss is 3.756861982345581 and perplexity is 42.81386429869678
At time: 910.973940372467 and batch: 1300, loss is 3.7346736192703247 and perplexity is 41.87435634956007
At time: 912.1013007164001 and batch: 1350, loss is 3.614683494567871 and perplexity is 37.13958918348468
At time: 913.2301514148712 and batch: 1400, loss is 3.6392973709106444 and perplexity is 38.06508169338138
At time: 914.3590357303619 and batch: 1450, loss is 3.567065043449402 and perplexity is 35.412506313793166
At time: 915.4916160106659 and batch: 1500, loss is 3.568548674583435 and perplexity is 35.46508440429608
At time: 916.6236865520477 and batch: 1550, loss is 3.595134744644165 and perplexity is 36.42060713901468
At time: 917.750973701477 and batch: 1600, loss is 3.6794083309173584 and perplexity is 39.62294346514544
At time: 918.881062746048 and batch: 1650, loss is 3.633172378540039 and perplexity is 37.83264591875823
At time: 920.0105812549591 and batch: 1700, loss is 3.6346011400222777 and perplexity is 37.88673837942843
At time: 921.1327741146088 and batch: 1750, loss is 3.615193848609924 and perplexity is 37.158548360479465
At time: 922.2582721710205 and batch: 1800, loss is 3.573493871688843 and perplexity is 35.64090060161203
At time: 923.3863015174866 and batch: 1850, loss is 3.582807183265686 and perplexity is 35.97438592969981
At time: 924.5067148208618 and batch: 1900, loss is 3.679095940589905 and perplexity is 39.61056757401668
At time: 925.627926826477 and batch: 1950, loss is 3.631965689659119 and perplexity is 37.787021218537674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325106740552326 and perplexity of 75.57357919480093
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5dd8c64b38>
ELAPSED
3816.620712995529


RESULTS SO FAR:
[{'best_accuracy': -76.21175240042173, 'params': {'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}}, {'best_accuracy': -73.46243748948554, 'params': {'rnn_dropout': 0.1541901093865481, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2553724200355174, 'num_layers': 2}}, {'best_accuracy': -74.63349668083315, 'params': {'rnn_dropout': 0.9124043211516957, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.644131086985198, 'num_layers': 2}}, {'best_accuracy': -75.57357919480093, 'params': {'rnn_dropout': 0.11345604619246663, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.06607543552697792, 'num_layers': 2}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.7362722002869169, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.3951791952761644, 'num_layers': 2}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6779916286468506 and batch: 50, loss is 7.668609390258789 and perplexity is 2140.1033264941857
At time: 2.859492778778076 and batch: 100, loss is 6.819358491897583 and perplexity is 915.3975867140605
At time: 4.068653106689453 and batch: 150, loss is 6.506666927337647 and perplexity is 669.5908989673804
At time: 5.246907472610474 and batch: 200, loss is 6.34425947189331 and perplexity is 569.2157133685854
At time: 6.434561252593994 and batch: 250, loss is 6.232284870147705 and perplexity is 508.91696525455995
At time: 7.621905326843262 and batch: 300, loss is 6.13248230934143 and perplexity is 460.5780400159105
At time: 8.808182716369629 and batch: 350, loss is 6.04059760093689 and perplexity is 420.1440383501989
At time: 9.98806118965149 and batch: 400, loss is 5.967635631561279 and perplexity is 390.5811005414111
At time: 11.17239785194397 and batch: 450, loss is 5.871858234405518 and perplexity is 354.90786990711973
At time: 12.353567838668823 and batch: 500, loss is 5.842702627182007 and perplexity is 344.70970470293264
At time: 13.54179835319519 and batch: 550, loss is 5.784755764007568 and perplexity is 325.3025798110733
At time: 14.731927871704102 and batch: 600, loss is 5.803387117385864 and perplexity is 331.4202201240062
At time: 15.92042326927185 and batch: 650, loss is 5.854568243026733 and perplexity is 348.82426022962954
At time: 17.111040115356445 and batch: 700, loss is 5.775636005401611 and perplexity is 322.3493854870457
At time: 18.305084943771362 and batch: 750, loss is 5.6997599792480464 and perplexity is 298.7956751969267
At time: 19.491673707962036 and batch: 800, loss is 5.70191840171814 and perplexity is 299.4412990100592
At time: 20.680009126663208 and batch: 850, loss is 5.715563154220581 and perplexity is 303.5551035210297
At time: 21.875646829605103 and batch: 900, loss is 5.699636869430542 and perplexity is 298.7588927800668
At time: 23.06457281112671 and batch: 950, loss is 5.710221824645996 and perplexity is 301.9380381531577
At time: 24.25954842567444 and batch: 1000, loss is 5.678652038574219 and perplexity is 292.55481141632436
At time: 25.458059549331665 and batch: 1050, loss is 5.579726448059082 and perplexity is 264.9991048508198
At time: 26.650838136672974 and batch: 1100, loss is 5.656194343566894 and perplexity is 286.0579302318404
At time: 27.846137285232544 and batch: 1150, loss is 5.558076047897339 and perplexity is 259.3234302014665
At time: 29.037018299102783 and batch: 1200, loss is 5.6223570823669435 and perplexity is 276.5404442360025
At time: 30.228283405303955 and batch: 1250, loss is 5.5815729141235355 and perplexity is 265.4888687320789
At time: 31.416730642318726 and batch: 1300, loss is 5.588340253829956 and perplexity is 267.2916151136373
At time: 32.60965013504028 and batch: 1350, loss is 5.551228618621826 and perplexity is 257.5537969872538
At time: 33.79872155189514 and batch: 1400, loss is 5.552938451766968 and perplexity is 257.9945477037128
At time: 34.986157178878784 and batch: 1450, loss is 5.517245092391968 and perplexity is 248.94826216174073
At time: 36.174708127975464 and batch: 1500, loss is 5.48153938293457 and perplexity is 240.2162076307275
At time: 37.3634512424469 and batch: 1550, loss is 5.468120212554932 and perplexity is 237.01423735411748
At time: 38.553388595581055 and batch: 1600, loss is 5.487844247817993 and perplexity is 241.7355228683962
At time: 39.74371409416199 and batch: 1650, loss is 5.475457572937012 and perplexity is 238.75969191302454
At time: 40.93720245361328 and batch: 1700, loss is 5.489669599533081 and perplexity is 242.17717818517718
At time: 42.127455949783325 and batch: 1750, loss is 5.482233476638794 and perplexity is 240.38299806549577
At time: 43.31651329994202 and batch: 1800, loss is 5.478513126373291 and perplexity is 239.49035062498615
At time: 44.507336378097534 and batch: 1850, loss is 5.453558177947998 and perplexity is 233.58783606249023
At time: 45.695035219192505 and batch: 1900, loss is 5.4760931205749515 and perplexity is 238.9114833014749
At time: 46.88337731361389 and batch: 1950, loss is 5.4144000053405765 and perplexity is 224.6177357981651
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.988330078125 and perplexity of 146.6912559101958
finished 1 epochs...
Completing Train Step...
At time: 50.55833148956299 and batch: 50, loss is 5.247559099197388 and perplexity is 190.10168233598523
At time: 51.71258807182312 and batch: 100, loss is 5.174261674880982 and perplexity is 176.66612907133452
At time: 52.82896566390991 and batch: 150, loss is 5.093078565597534 and perplexity is 162.89056021681566
At time: 53.94660687446594 and batch: 200, loss is 5.044403743743897 and perplexity is 155.15176140459954
At time: 55.06402373313904 and batch: 250, loss is 5.071084775924683 and perplexity is 159.34708950860414
At time: 56.18407487869263 and batch: 300, loss is 5.06965087890625 and perplexity is 159.1187659274336
At time: 57.303791999816895 and batch: 350, loss is 5.062591056823731 and perplexity is 157.99937176113772
At time: 58.42299437522888 and batch: 400, loss is 5.006438255310059 and perplexity is 149.371763470816
At time: 59.54170823097229 and batch: 450, loss is 4.968486070632935 and perplexity is 143.80900580674606
At time: 60.66052460670471 and batch: 500, loss is 4.968512630462646 and perplexity is 143.81282540017492
At time: 61.77746605873108 and batch: 550, loss is 4.921477584838867 and perplexity is 137.2051958002404
At time: 62.954933166503906 and batch: 600, loss is 4.896918058395386 and perplexity is 133.87654353777612
At time: 64.08333420753479 and batch: 650, loss is 4.964966306686401 and perplexity is 143.303721814762
At time: 65.21164560317993 and batch: 700, loss is 4.970037851333618 and perplexity is 144.0323390838601
At time: 66.33309364318848 and batch: 750, loss is 4.911669034957885 and perplexity is 135.86599036177608
At time: 67.45137476921082 and batch: 800, loss is 4.912905960083008 and perplexity is 136.03415039815107
At time: 68.56916809082031 and batch: 850, loss is 4.900763473510742 and perplexity is 134.39234552265637
At time: 69.69134020805359 and batch: 900, loss is 4.883771057128906 and perplexity is 132.12798776828092
At time: 70.81368327140808 and batch: 950, loss is 4.928166790008545 and perplexity is 138.1260660164715
At time: 71.93364930152893 and batch: 1000, loss is 4.901483097076416 and perplexity is 134.4890922279701
At time: 73.05243754386902 and batch: 1050, loss is 4.81935154914856 and perplexity is 123.88473156847421
At time: 74.17300748825073 and batch: 1100, loss is 4.883295087814331 and perplexity is 132.06511386471803
At time: 75.29261803627014 and batch: 1150, loss is 4.8112239646911625 and perplexity is 122.88192865259178
At time: 76.40986108779907 and batch: 1200, loss is 4.8905449390411375 and perplexity is 133.02604538887928
At time: 77.52736687660217 and batch: 1250, loss is 4.862000055313111 and perplexity is 129.2825158831334
At time: 78.65102624893188 and batch: 1300, loss is 4.868148307800293 and perplexity is 130.07982595317958
At time: 79.77125573158264 and batch: 1350, loss is 4.76170485496521 and perplexity is 116.94513052967915
At time: 80.89179039001465 and batch: 1400, loss is 4.769812364578247 and perplexity is 117.89711820963713
At time: 82.00997471809387 and batch: 1450, loss is 4.71696964263916 and perplexity is 111.82885728206163
At time: 83.12635087966919 and batch: 1500, loss is 4.6964764976501465 and perplexity is 109.56045503159221
At time: 84.2467429637909 and batch: 1550, loss is 4.702972793579102 and perplexity is 110.2745090113706
At time: 85.36802673339844 and batch: 1600, loss is 4.756582050323487 and perplexity is 116.34757535818703
At time: 86.4883041381836 and batch: 1650, loss is 4.729333744049073 and perplexity is 113.2201036462275
At time: 87.61006712913513 and batch: 1700, loss is 4.740918426513672 and perplexity is 114.53934936287139
At time: 88.73160815238953 and batch: 1750, loss is 4.723752584457397 and perplexity is 112.58996426870877
At time: 89.85736608505249 and batch: 1800, loss is 4.6905067443847654 and perplexity is 108.90835452360537
At time: 90.97934651374817 and batch: 1850, loss is 4.709921922683716 and perplexity is 111.04348958956808
At time: 92.10207223892212 and batch: 1900, loss is 4.8142321586608885 and perplexity is 123.25213788076097
At time: 93.22311234474182 and batch: 1950, loss is 4.7298415088653565 and perplexity is 113.27760742931851
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.586328976653343 and perplexity of 98.1335176737084
finished 2 epochs...
Completing Train Step...
At time: 96.88954734802246 and batch: 50, loss is 4.701238975524903 and perplexity is 110.08347873045878
At time: 98.03598999977112 and batch: 100, loss is 4.63910026550293 and perplexity is 103.45122705993928
At time: 99.15482902526855 and batch: 150, loss is 4.583572273254394 and perplexity is 97.86336520817981
At time: 100.27757406234741 and batch: 200, loss is 4.564048643112183 and perplexity is 95.97124766442968
At time: 101.39815044403076 and batch: 250, loss is 4.580837554931641 and perplexity is 97.59610208146819
At time: 102.51766967773438 and batch: 300, loss is 4.5963476943969725 and perplexity is 99.12163123880427
At time: 103.63396334648132 and batch: 350, loss is 4.6000016403198245 and perplexity is 99.48447882816282
At time: 104.7534863948822 and batch: 400, loss is 4.547657623291015 and perplexity is 94.41100297436114
At time: 105.87588286399841 and batch: 450, loss is 4.55012433052063 and perplexity is 94.64417474296623
At time: 107.00096035003662 and batch: 500, loss is 4.552418422698975 and perplexity is 94.8615464439965
At time: 108.1241614818573 and batch: 550, loss is 4.519299182891846 and perplexity is 91.77126056696859
At time: 109.25153136253357 and batch: 600, loss is 4.4932622051239015 and perplexity is 89.4126530465594
At time: 110.37734818458557 and batch: 650, loss is 4.558961229324341 and perplexity is 95.48424206570462
At time: 111.49481558799744 and batch: 700, loss is 4.594053010940552 and perplexity is 98.89443923798136
At time: 112.61800336837769 and batch: 750, loss is 4.5405673408508305 and perplexity is 93.74396981897385
At time: 113.74262619018555 and batch: 800, loss is 4.538961753845215 and perplexity is 93.59357648627643
At time: 114.86240196228027 and batch: 850, loss is 4.534195413589478 and perplexity is 93.14853909733218
At time: 115.98207235336304 and batch: 900, loss is 4.503407888412475 and perplexity is 90.3244229496308
At time: 117.1009259223938 and batch: 950, loss is 4.560528993606567 and perplexity is 95.63405625591339
At time: 118.2190511226654 and batch: 1000, loss is 4.5428079319000245 and perplexity is 93.9542472035086
At time: 119.3619453907013 and batch: 1050, loss is 4.480727949142456 and perplexity is 88.29892641385003
At time: 120.48429989814758 and batch: 1100, loss is 4.524342212677002 and perplexity is 92.23523470179869
At time: 121.6046621799469 and batch: 1150, loss is 4.4857737255096435 and perplexity is 88.74558898204899
At time: 122.72298550605774 and batch: 1200, loss is 4.5517500877380375 and perplexity is 94.79816833732073
At time: 123.84351801872253 and batch: 1250, loss is 4.539895181655884 and perplexity is 93.68098011961357
At time: 124.9608142375946 and batch: 1300, loss is 4.5316515636444095 and perplexity is 92.91188432599924
At time: 126.08265161514282 and batch: 1350, loss is 4.41482177734375 and perplexity is 82.667106441845
At time: 127.20244908332825 and batch: 1400, loss is 4.4279547214508055 and perplexity is 83.75992921349268
At time: 128.3296194076538 and batch: 1450, loss is 4.3887795734405515 and perplexity is 80.54206330153751
At time: 129.45800018310547 and batch: 1500, loss is 4.376213760375976 and perplexity is 79.53631902141758
At time: 130.5881986618042 and batch: 1550, loss is 4.38766505241394 and perplexity is 80.45234748283123
At time: 131.70869088172913 and batch: 1600, loss is 4.453916625976563 and perplexity is 85.96297033054407
At time: 132.83707475662231 and batch: 1650, loss is 4.421684522628784 and perplexity is 83.23638089532076
At time: 133.96569418907166 and batch: 1700, loss is 4.430654678344727 and perplexity is 83.9863829819474
At time: 135.08567023277283 and batch: 1750, loss is 4.416479368209838 and perplexity is 82.8042483135649
At time: 136.2049856185913 and batch: 1800, loss is 4.384316167831421 and perplexity is 80.1833724911999
At time: 137.3266191482544 and batch: 1850, loss is 4.418376483917236 and perplexity is 82.96148665618561
At time: 138.4442594051361 and batch: 1900, loss is 4.52417028427124 and perplexity is 92.21937820807123
At time: 139.56696033477783 and batch: 1950, loss is 4.445635347366333 and perplexity is 85.25402655511955
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.474730025890262 and perplexity of 87.77090133988092
finished 3 epochs...
Completing Train Step...
At time: 143.2211480140686 and batch: 50, loss is 4.424837875366211 and perplexity is 83.4992688362362
At time: 144.36770701408386 and batch: 100, loss is 4.3726854991912845 and perplexity is 79.2561885915055
At time: 145.48454546928406 and batch: 150, loss is 4.321305131912231 and perplexity is 75.28682343511278
At time: 146.62504744529724 and batch: 200, loss is 4.315326108932495 and perplexity is 74.83802481335633
At time: 147.74455785751343 and batch: 250, loss is 4.325869436264038 and perplexity is 75.63124082591575
At time: 148.86506724357605 and batch: 300, loss is 4.342433576583862 and perplexity is 76.89444033654115
At time: 149.98821902275085 and batch: 350, loss is 4.3463001537323 and perplexity is 77.19233416598877
At time: 151.11178946495056 and batch: 400, loss is 4.292722253799439 and perplexity is 73.16537235629316
At time: 152.23480772972107 and batch: 450, loss is 4.320938768386841 and perplexity is 75.25924614102948
At time: 153.36194372177124 and batch: 500, loss is 4.32580156326294 and perplexity is 75.62610768082705
At time: 154.48488521575928 and batch: 550, loss is 4.2871802806854244 and perplexity is 72.76101333815957
At time: 155.60467982292175 and batch: 600, loss is 4.2682986116409305 and perplexity is 71.40005299991064
At time: 156.72397446632385 and batch: 650, loss is 4.329354467391968 and perplexity is 75.89527787586988
At time: 157.84228014945984 and batch: 700, loss is 4.367065525054931 and perplexity is 78.81202013814017
At time: 158.9604630470276 and batch: 750, loss is 4.323249673843383 and perplexity is 75.43336425135098
At time: 160.07857084274292 and batch: 800, loss is 4.320039730072022 and perplexity is 75.19161560098297
At time: 161.198162317276 and batch: 850, loss is 4.314484357833862 and perplexity is 74.7750563293635
At time: 162.31861424446106 and batch: 900, loss is 4.28866397857666 and perplexity is 72.86904882640789
At time: 163.434996843338 and batch: 950, loss is 4.350018701553345 and perplexity is 77.47991190641739
At time: 164.55057191848755 and batch: 1000, loss is 4.325189628601074 and perplexity is 75.57984360093592
At time: 165.67255115509033 and batch: 1050, loss is 4.276036872863769 and perplexity is 71.954708528272
At time: 166.79800271987915 and batch: 1100, loss is 4.311790580749512 and perplexity is 74.57390005286621
At time: 167.92038869857788 and batch: 1150, loss is 4.282509179115295 and perplexity is 72.4219318131735
At time: 169.0499951839447 and batch: 1200, loss is 4.344658079147339 and perplexity is 77.06568261001031
At time: 170.1673457622528 and batch: 1250, loss is 4.346595869064331 and perplexity is 77.2151644981902
At time: 171.2865390777588 and batch: 1300, loss is 4.329640111923218 and perplexity is 75.91696004349167
At time: 172.40601658821106 and batch: 1350, loss is 4.209088115692139 and perplexity is 67.29514643451404
At time: 173.52335262298584 and batch: 1400, loss is 4.227499575614929 and perplexity is 68.54562456617712
At time: 174.64135718345642 and batch: 1450, loss is 4.185905256271362 and perplexity is 65.75299729610254
At time: 175.7631597518921 and batch: 1500, loss is 4.174873280525207 and perplexity is 65.03159836887166
At time: 176.88661289215088 and batch: 1550, loss is 4.192884812355041 and perplexity is 66.21352931338615
At time: 178.00469303131104 and batch: 1600, loss is 4.26861120223999 and perplexity is 71.42237547396677
At time: 179.12356734275818 and batch: 1650, loss is 4.23027319431305 and perplexity is 68.73600789547828
At time: 180.2391014099121 and batch: 1700, loss is 4.24157425403595 and perplexity is 69.51720348068713
At time: 181.3558828830719 and batch: 1750, loss is 4.224010982513428 and perplexity is 68.30691339834262
At time: 182.47628211975098 and batch: 1800, loss is 4.18963698387146 and perplexity is 65.99882797217883
At time: 183.59752893447876 and batch: 1850, loss is 4.229132695198059 and perplexity is 68.65765922609214
At time: 184.72778487205505 and batch: 1900, loss is 4.333644075393677 and perplexity is 76.22153813115335
At time: 185.85988974571228 and batch: 1950, loss is 4.254537229537964 and perplexity is 70.42421939781771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.436061557503634 and perplexity of 84.44171706462332
finished 4 epochs...
Completing Train Step...
At time: 189.55869102478027 and batch: 50, loss is 4.2441093492507935 and perplexity is 69.69365978284122
At time: 190.68216633796692 and batch: 100, loss is 4.194572348594665 and perplexity is 66.3253613774469
At time: 191.80859470367432 and batch: 150, loss is 4.149302797317505 and perplexity is 63.389789356738426
At time: 192.93790674209595 and batch: 200, loss is 4.142931122779846 and perplexity is 62.98717427818967
At time: 194.0602285861969 and batch: 250, loss is 4.148767819404602 and perplexity is 63.35588628903381
At time: 195.17918634414673 and batch: 300, loss is 4.168861827850342 and perplexity is 64.64183668362142
At time: 196.3001720905304 and batch: 350, loss is 4.173656826019287 and perplexity is 64.95253848413431
At time: 197.42950963974 and batch: 400, loss is 4.121977009773254 and perplexity is 61.681065871570745
At time: 198.55154299736023 and batch: 450, loss is 4.159809036254883 and perplexity is 64.05928843020419
At time: 199.67886185646057 and batch: 500, loss is 4.165895538330078 and perplexity is 64.45037438758503
At time: 200.80282640457153 and batch: 550, loss is 4.127431058883667 and perplexity is 62.0183965067379
At time: 201.92255020141602 and batch: 600, loss is 4.1132218408584595 and perplexity is 61.143394855805234
At time: 203.07465386390686 and batch: 650, loss is 4.1704139184951785 and perplexity is 64.74224457452044
At time: 204.20842337608337 and batch: 700, loss is 4.212022843360901 and perplexity is 67.49292944040616
At time: 205.3406946659088 and batch: 750, loss is 4.169301385879517 and perplexity is 64.6702567676368
At time: 206.46518874168396 and batch: 800, loss is 4.165294647216797 and perplexity is 64.41165836359019
At time: 207.59010195732117 and batch: 850, loss is 4.161385111808777 and perplexity is 64.16033031260346
At time: 208.71490669250488 and batch: 900, loss is 4.129900426864624 and perplexity is 62.171731992253896
At time: 209.83453392982483 and batch: 950, loss is 4.199257202148438 and perplexity is 66.63681496999163
At time: 210.95696926116943 and batch: 1000, loss is 4.1754618167877195 and perplexity is 65.06988308758844
At time: 212.07979106903076 and batch: 1050, loss is 4.131231527328492 and perplexity is 62.25454391681648
At time: 213.2003812789917 and batch: 1100, loss is 4.160135374069214 and perplexity is 64.08019680979002
At time: 214.31729197502136 and batch: 1150, loss is 4.136847367286682 and perplexity is 62.60513899363241
At time: 215.4450011253357 and batch: 1200, loss is 4.198054928779602 and perplexity is 66.5567474431413
At time: 216.56595277786255 and batch: 1250, loss is 4.204653463363647 and perplexity is 66.997376597531
At time: 217.6867368221283 and batch: 1300, loss is 4.1832898902893065 and perplexity is 65.58125382766436
At time: 218.81133151054382 and batch: 1350, loss is 4.0615590381622315 and perplexity is 58.064765735169374
At time: 219.93319654464722 and batch: 1400, loss is 4.085547022819519 and perplexity is 59.47446274277546
At time: 221.05796241760254 and batch: 1450, loss is 4.040173463821411 and perplexity is 56.836200975042026
At time: 222.18729186058044 and batch: 1500, loss is 4.0336720705032345 and perplexity is 56.46788505844598
At time: 223.3076193332672 and batch: 1550, loss is 4.049658155441284 and perplexity is 57.37783939035643
At time: 224.4309823513031 and batch: 1600, loss is 4.128853354454041 and perplexity is 62.10666775639427
At time: 225.5556411743164 and batch: 1650, loss is 4.089237012863159 and perplexity is 59.69432831956724
At time: 226.67467522621155 and batch: 1700, loss is 4.105931887626648 and perplexity is 60.699283110597946
At time: 227.79182839393616 and batch: 1750, loss is 4.08795168876648 and perplexity is 59.617651049071
At time: 228.90853118896484 and batch: 1800, loss is 4.048424410820007 and perplexity is 57.30709343981976
At time: 230.02550411224365 and batch: 1850, loss is 4.091243467330933 and perplexity is 59.81422251222093
At time: 231.14488053321838 and batch: 1900, loss is 4.1967825603485105 and perplexity is 66.47211659104836
At time: 232.26535320281982 and batch: 1950, loss is 4.119743285179138 and perplexity is 61.54344112285858
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419190020893895 and perplexity of 83.02900635438061
finished 5 epochs...
Completing Train Step...
At time: 235.9388747215271 and batch: 50, loss is 4.111665730476379 and perplexity is 61.0483229746297
At time: 237.0636420249939 and batch: 100, loss is 4.065702624320984 and perplexity is 58.305861249846146
At time: 238.18168425559998 and batch: 150, loss is 4.02031711101532 and perplexity is 55.718772061949636
At time: 239.30295538902283 and batch: 200, loss is 4.019260444641113 and perplexity is 55.65992700437176
At time: 240.42111158370972 and batch: 250, loss is 4.018532428741455 and perplexity is 55.61942043903964
At time: 241.53988218307495 and batch: 300, loss is 4.038299078941345 and perplexity is 56.72976783878583
At time: 242.65781259536743 and batch: 350, loss is 4.04991418838501 and perplexity is 57.39253188828168
At time: 243.78366041183472 and batch: 400, loss is 3.9956632471084594 and perplexity is 54.361884032043115
At time: 244.9029664993286 and batch: 450, loss is 4.036525068283081 and perplexity is 56.629217840753235
At time: 246.02842211723328 and batch: 500, loss is 4.0436866044998165 and perplexity is 57.036225696458224
At time: 247.14982104301453 and batch: 550, loss is 4.009788012504577 and perplexity is 55.1351813555194
At time: 248.2652666568756 and batch: 600, loss is 3.9948321390151977 and perplexity is 54.316722200040765
At time: 249.38283681869507 and batch: 650, loss is 4.048976721763611 and perplexity is 57.338753516971444
At time: 250.50162863731384 and batch: 700, loss is 4.092317214012146 and perplexity is 59.878482328341015
At time: 251.61877012252808 and batch: 750, loss is 4.051694588661194 and perplexity is 57.494804584058826
At time: 252.73623776435852 and batch: 800, loss is 4.052825207710266 and perplexity is 57.5598460669855
At time: 253.85707998275757 and batch: 850, loss is 4.045705075263977 and perplexity is 57.151467917925125
At time: 254.97670340538025 and batch: 900, loss is 4.01016402721405 and perplexity is 55.155916892907754
At time: 256.0961000919342 and batch: 950, loss is 4.080389847755432 and perplexity is 59.16853207363323
At time: 257.21216225624084 and batch: 1000, loss is 4.05753613948822 and perplexity is 57.831646288437916
At time: 258.37088680267334 and batch: 1050, loss is 4.0232093811035154 and perplexity is 55.8801590746469
At time: 259.49155282974243 and batch: 1100, loss is 4.042345099449157 and perplexity is 56.95976261089078
At time: 260.61281538009644 and batch: 1150, loss is 4.025747966766358 and perplexity is 56.022195855299934
At time: 261.7309534549713 and batch: 1200, loss is 4.086696124076843 and perplexity is 59.542844203778834
At time: 262.8495833873749 and batch: 1250, loss is 4.094468297958374 and perplexity is 60.00742460351134
At time: 263.9689886569977 and batch: 1300, loss is 4.071194667816162 and perplexity is 58.62696051432038
At time: 265.0856227874756 and batch: 1350, loss is 3.952960000038147 and perplexity is 52.0893232657557
At time: 266.2045166492462 and batch: 1400, loss is 3.977305197715759 and perplexity is 53.37301054623957
At time: 267.3251688480377 and batch: 1450, loss is 3.9296801900863647 and perplexity is 50.89069971613373
At time: 268.4534749984741 and batch: 1500, loss is 3.922666521072388 and perplexity is 50.535017967508274
At time: 269.5752742290497 and batch: 1550, loss is 3.942203688621521 and perplexity is 51.5320368295338
At time: 270.6960873603821 and batch: 1600, loss is 4.020015869140625 and perplexity is 55.70198976249059
At time: 271.8229920864105 and batch: 1650, loss is 3.9851502323150636 and perplexity is 53.793370373434996
At time: 272.9412844181061 and batch: 1700, loss is 3.999390425682068 and perplexity is 54.56487854483008
At time: 274.0607793331146 and batch: 1750, loss is 3.9805369329452516 and perplexity is 53.545777002080825
At time: 275.1798598766327 and batch: 1800, loss is 3.940871391296387 and perplexity is 51.46342654950209
At time: 276.2995858192444 and batch: 1850, loss is 3.9829933738708494 and perplexity is 53.67747072280318
At time: 277.42065501213074 and batch: 1900, loss is 4.0887774562835695 and perplexity is 59.666901700748056
At time: 278.5423448085785 and batch: 1950, loss is 4.012299547195434 and perplexity is 55.273829312877474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4157277661700585 and perplexity of 82.74203585406438
finished 6 epochs...
Completing Train Step...
At time: 282.19241189956665 and batch: 50, loss is 4.0052478313446045 and perplexity is 54.88542504235505
At time: 283.3106861114502 and batch: 100, loss is 3.9653290843963624 and perplexity is 52.73762166270002
At time: 284.4333350658417 and batch: 150, loss is 3.9184471130371095 and perplexity is 50.322239322277866
At time: 285.5694921016693 and batch: 200, loss is 3.920278024673462 and perplexity is 50.4144592933675
At time: 286.71954131126404 and batch: 250, loss is 3.9171552991867067 and perplexity is 50.25727432691284
At time: 287.8426079750061 and batch: 300, loss is 3.934348840713501 and perplexity is 51.128846091833026
At time: 288.96078991889954 and batch: 350, loss is 3.9505992698669434 and perplexity is 51.966499462695374
At time: 290.0939145088196 and batch: 400, loss is 3.9004270792007447 and perplexity is 49.42355237007091
At time: 291.2134585380554 and batch: 450, loss is 3.939793949127197 and perplexity is 51.40800754431448
At time: 292.33454298973083 and batch: 500, loss is 3.9508863735198974 and perplexity is 51.98142137648782
At time: 293.4510233402252 and batch: 550, loss is 3.918655972480774 and perplexity is 50.33275069484817
At time: 294.5660262107849 and batch: 600, loss is 3.9034580326080324 and perplexity is 49.57358010320701
At time: 295.6895616054535 and batch: 650, loss is 3.952614817619324 and perplexity is 52.07134605004388
At time: 296.8163421154022 and batch: 700, loss is 3.999375705718994 and perplexity is 54.56407535774423
At time: 297.9363248348236 and batch: 750, loss is 3.9581190061569216 and perplexity is 52.35874678443089
At time: 299.05286860466003 and batch: 800, loss is 3.957403063774109 and perplexity is 52.32127435414809
At time: 300.16507863998413 and batch: 850, loss is 3.9542987537384033 and perplexity is 52.1591047397026
At time: 301.2941334247589 and batch: 900, loss is 3.913736138343811 and perplexity is 50.08573005830874
At time: 302.43491220474243 and batch: 950, loss is 3.9885273456573485 and perplexity is 53.975343781713185
At time: 303.55811309814453 and batch: 1000, loss is 3.9660642766952514 and perplexity is 52.776408212047315
At time: 304.6734712123871 and batch: 1050, loss is 3.9321646738052367 and perplexity is 51.017294026653545
At time: 305.799667596817 and batch: 1100, loss is 3.951820206642151 and perplexity is 52.029986021618896
At time: 306.9182035923004 and batch: 1150, loss is 3.937029719352722 and perplexity is 51.26610022179619
At time: 308.039559841156 and batch: 1200, loss is 3.9929207944869995 and perplexity is 54.21300338304651
At time: 309.15725564956665 and batch: 1250, loss is 4.003658118247986 and perplexity is 54.79824227950231
At time: 310.2792024612427 and batch: 1300, loss is 3.980808148384094 and perplexity is 53.56030141302182
At time: 311.40274262428284 and batch: 1350, loss is 3.8677664756774903 and perplexity is 47.83542508988174
At time: 312.52156472206116 and batch: 1400, loss is 3.8914032125473024 and perplexity is 48.979567068833624
At time: 313.6436924934387 and batch: 1450, loss is 3.8414997625350953 and perplexity is 46.595303954037306
At time: 314.775226354599 and batch: 1500, loss is 3.8328262615203856 and perplexity is 46.19290715510986
At time: 315.9109456539154 and batch: 1550, loss is 3.855064868927002 and perplexity is 47.231680710350126
At time: 317.0397353172302 and batch: 1600, loss is 3.935584225654602 and perplexity is 51.19204893022992
At time: 318.1683051586151 and batch: 1650, loss is 3.899688329696655 and perplexity is 49.3870542284191
At time: 319.29516434669495 and batch: 1700, loss is 3.9109141540527346 and perplexity is 49.944588158655314
At time: 320.42178297042847 and batch: 1750, loss is 3.895157747268677 and perplexity is 49.1638082074775
At time: 321.54461669921875 and batch: 1800, loss is 3.8546304512023926 and perplexity is 47.21116688719326
At time: 322.6680974960327 and batch: 1850, loss is 3.896964440345764 and perplexity is 49.25271240652668
At time: 323.7950060367584 and batch: 1900, loss is 4.001920185089111 and perplexity is 54.70308930590079
At time: 324.9246618747711 and batch: 1950, loss is 3.9240531063079835 and perplexity is 50.60513767954685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425455634538517 and perplexity of 83.55086721148452
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 328.5816082954407 and batch: 50, loss is 3.9641803026199343 and perplexity is 52.677072429588435
At time: 329.73195910453796 and batch: 100, loss is 3.95511372089386 and perplexity is 52.201630022924356
At time: 330.85704040527344 and batch: 150, loss is 3.9080351209640503 and perplexity is 49.801002829382384
At time: 331.9823942184448 and batch: 200, loss is 3.905216836929321 and perplexity is 49.66084705036025
At time: 333.10512137413025 and batch: 250, loss is 3.908136081695557 and perplexity is 49.80603102887888
At time: 334.22709465026855 and batch: 300, loss is 3.931211051940918 and perplexity is 50.96866600966663
At time: 335.3490424156189 and batch: 350, loss is 3.9524510288238526 and perplexity is 52.06281804541064
At time: 336.4708914756775 and batch: 400, loss is 3.8888882780075074 and perplexity is 48.85654142942661
At time: 337.6008360385895 and batch: 450, loss is 3.9211382818222047 and perplexity is 50.45784735214273
At time: 338.72567677497864 and batch: 500, loss is 3.9222180700302123 and perplexity is 50.51236056678159
At time: 339.85141015052795 and batch: 550, loss is 3.893957805633545 and perplexity is 49.104849887413515
At time: 340.98224997520447 and batch: 600, loss is 3.8570976400375367 and perplexity is 47.3277895569488
At time: 342.10470151901245 and batch: 650, loss is 3.8894695329666136 and perplexity is 48.88494779128682
At time: 343.25293469429016 and batch: 700, loss is 3.9379317378997802 and perplexity is 51.3123640573136
At time: 344.37230157852173 and batch: 750, loss is 3.8908859968185423 and perplexity is 48.9542406165421
At time: 345.49585914611816 and batch: 800, loss is 3.877852621078491 and perplexity is 48.320341500484105
At time: 346.62505984306335 and batch: 850, loss is 3.871666030883789 and perplexity is 48.02232614949354
At time: 347.7529034614563 and batch: 900, loss is 3.827114906311035 and perplexity is 45.92983501851149
At time: 348.8741102218628 and batch: 950, loss is 3.9060996770858765 and perplexity is 49.704708999040825
At time: 350.00699162483215 and batch: 1000, loss is 3.8702899551391603 and perplexity is 47.95628923759546
At time: 351.1449613571167 and batch: 1050, loss is 3.833860158920288 and perplexity is 46.24069057903385
At time: 352.27481269836426 and batch: 1100, loss is 3.8345060539245606 and perplexity is 46.270566857503816
At time: 353.40643882751465 and batch: 1150, loss is 3.8176532220840453 and perplexity is 45.49731085325517
At time: 354.5344636440277 and batch: 1200, loss is 3.859487323760986 and perplexity is 47.44102324778794
At time: 355.65619587898254 and batch: 1250, loss is 3.856892943382263 and perplexity is 47.318102708191596
At time: 356.78685688972473 and batch: 1300, loss is 3.8529008626937866 and perplexity is 47.12958157031894
At time: 357.9166507720947 and batch: 1350, loss is 3.7267100524902346 and perplexity is 41.54221140097621
At time: 359.04097604751587 and batch: 1400, loss is 3.736484980583191 and perplexity is 41.950274675654725
At time: 360.17045855522156 and batch: 1450, loss is 3.6813048219680784 and perplexity is 39.69815932338735
At time: 361.29700350761414 and batch: 1500, loss is 3.669633946418762 and perplexity is 39.23754018905704
At time: 362.42121410369873 and batch: 1550, loss is 3.681439161300659 and perplexity is 39.70349270584904
At time: 363.54475498199463 and batch: 1600, loss is 3.756823558807373 and perplexity is 42.81221927015018
At time: 364.66520595550537 and batch: 1650, loss is 3.709444317817688 and perplexity is 40.83111110092954
At time: 365.79203033447266 and batch: 1700, loss is 3.7072611951828005 and perplexity is 40.74206900834611
At time: 366.91662192344666 and batch: 1750, loss is 3.6797223615646364 and perplexity is 39.635388237646566
At time: 368.0409805774689 and batch: 1800, loss is 3.6294823122024535 and perplexity is 37.69329820486578
At time: 369.16435384750366 and batch: 1850, loss is 3.665160312652588 and perplexity is 39.06239785778853
At time: 370.28692054748535 and batch: 1900, loss is 3.762131414413452 and perplexity is 43.040064498067416
At time: 371.4165213108063 and batch: 1950, loss is 3.676890172958374 and perplexity is 39.523292156227036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358997717569041 and perplexity of 78.17873796641328
finished 8 epochs...
Completing Train Step...
At time: 375.0966811180115 and batch: 50, loss is 3.8861208295822145 and perplexity is 48.721520388840155
At time: 376.24500155448914 and batch: 100, loss is 3.8604045963287352 and perplexity is 47.48455956127953
At time: 377.37733125686646 and batch: 150, loss is 3.8046024370193483 and perplexity is 44.90739304656146
At time: 378.50194573402405 and batch: 200, loss is 3.794357476234436 and perplexity is 44.44966726074792
At time: 379.6284279823303 and batch: 250, loss is 3.794150652885437 and perplexity is 44.44047498232483
At time: 380.75248765945435 and batch: 300, loss is 3.8173904609680176 and perplexity is 45.485357499586165
At time: 381.87702918052673 and batch: 350, loss is 3.8362669563293457 and perplexity is 46.35211658944121
At time: 383.00357699394226 and batch: 400, loss is 3.779691414833069 and perplexity is 43.802522840993184
At time: 384.13042998313904 and batch: 450, loss is 3.818526487350464 and perplexity is 45.53705942753743
At time: 385.2568247318268 and batch: 500, loss is 3.8249384355545044 and perplexity is 45.82997878224892
At time: 386.385183095932 and batch: 550, loss is 3.796544852256775 and perplexity is 44.54700181193771
At time: 387.50695633888245 and batch: 600, loss is 3.7656243658065796 and perplexity is 43.19066421694659
At time: 388.63873767852783 and batch: 650, loss is 3.799413633346558 and perplexity is 44.67498089255421
At time: 389.76954793930054 and batch: 700, loss is 3.8512620878219606 and perplexity is 47.05241004696934
At time: 390.8940818309784 and batch: 750, loss is 3.805998454093933 and perplexity is 44.97012831359298
At time: 392.01727509498596 and batch: 800, loss is 3.792515630722046 and perplexity is 44.36787318972096
At time: 393.14138746261597 and batch: 850, loss is 3.790709719657898 and perplexity is 44.287821061902854
At time: 394.26697731018066 and batch: 900, loss is 3.747583613395691 and perplexity is 42.41845866587626
At time: 395.4007179737091 and batch: 950, loss is 3.8290170764923097 and perplexity is 46.0172845266701
At time: 396.52983832359314 and batch: 1000, loss is 3.798295359611511 and perplexity is 44.62504995823794
At time: 397.661016702652 and batch: 1050, loss is 3.765561990737915 and perplexity is 43.18797028031851
At time: 398.79730439186096 and batch: 1100, loss is 3.765698719024658 and perplexity is 43.193875701212676
At time: 399.9468605518341 and batch: 1150, loss is 3.752967801094055 and perplexity is 42.64746355864449
At time: 401.0739495754242 and batch: 1200, loss is 3.7957836771011353 and perplexity is 44.51310664261716
At time: 402.20647287368774 and batch: 1250, loss is 3.798965153694153 and perplexity is 44.65494956480953
At time: 403.33877539634705 and batch: 1300, loss is 3.7979189586639404 and perplexity is 44.6082562079383
At time: 404.46366333961487 and batch: 1350, loss is 3.6709971475601195 and perplexity is 39.291065323099836
At time: 405.58868503570557 and batch: 1400, loss is 3.6867514562606813 and perplexity is 39.914970589158756
At time: 406.71489787101746 and batch: 1450, loss is 3.634208517074585 and perplexity is 37.87186609631831
At time: 407.84420466423035 and batch: 1500, loss is 3.6225162506103517 and perplexity is 37.43163680080426
At time: 408.9750473499298 and batch: 1550, loss is 3.639833483695984 and perplexity is 38.08549434160413
At time: 410.11070823669434 and batch: 1600, loss is 3.718055691719055 and perplexity is 41.184241351522274
At time: 411.2512445449829 and batch: 1650, loss is 3.673552408218384 and perplexity is 39.39159261856463
At time: 412.3812749385834 and batch: 1700, loss is 3.67715847492218 and perplexity is 39.53389775581661
At time: 413.5018141269684 and batch: 1750, loss is 3.653866000175476 and perplexity is 38.6236970059644
At time: 414.63071870803833 and batch: 1800, loss is 3.6064726543426513 and perplexity is 36.835890467710186
At time: 415.75677275657654 and batch: 1850, loss is 3.6456603384017945 and perplexity is 38.30806078497691
At time: 416.8849456310272 and batch: 1900, loss is 3.7470674562454223 and perplexity is 42.396569724685214
At time: 418.01284289360046 and batch: 1950, loss is 3.663017554283142 and perplexity is 38.97878618964029
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364758868550146 and perplexity of 78.63043738426516
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 421.6931309700012 and batch: 50, loss is 3.86254225730896 and perplexity is 47.58617402135526
At time: 422.84977769851685 and batch: 100, loss is 3.8765665435791017 and perplexity is 48.25823774020182
At time: 423.9815230369568 and batch: 150, loss is 3.83625937461853 and perplexity is 46.35176516242974
At time: 425.10797357559204 and batch: 200, loss is 3.825463137626648 and perplexity is 45.854032176963436
At time: 426.23934388160706 and batch: 250, loss is 3.8230851316452026 and perplexity is 45.74512056173326
At time: 427.39006328582764 and batch: 300, loss is 3.8430074357986452 and perplexity is 46.665607432035735
At time: 428.51321840286255 and batch: 350, loss is 3.870464787483215 and perplexity is 47.964674281022084
At time: 429.63918590545654 and batch: 400, loss is 3.823278250694275 and perplexity is 45.75395566900214
At time: 430.7632930278778 and batch: 450, loss is 3.8598052215576173 and perplexity is 47.45610704197377
At time: 431.8910219669342 and batch: 500, loss is 3.8700742149353027 and perplexity is 47.945944253933654
At time: 433.0173969268799 and batch: 550, loss is 3.839458966255188 and perplexity is 46.5003093963066
At time: 434.1426737308502 and batch: 600, loss is 3.800507745742798 and perplexity is 44.723887092511625
At time: 435.26810812950134 and batch: 650, loss is 3.82442138671875 and perplexity is 45.80628857010299
At time: 436.3972668647766 and batch: 700, loss is 3.8743323469161988 and perplexity is 48.15053970058455
At time: 437.5235438346863 and batch: 750, loss is 3.8224006843566896 and perplexity is 45.713821150622515
At time: 438.6519992351532 and batch: 800, loss is 3.796989221572876 and perplexity is 44.566801531535354
At time: 439.77803564071655 and batch: 850, loss is 3.7961226415634157 and perplexity is 44.5281975613728
At time: 440.9003484249115 and batch: 900, loss is 3.7523275136947634 and perplexity is 42.62016566529731
At time: 442.02251744270325 and batch: 950, loss is 3.841431760787964 and perplexity is 46.59213549969174
At time: 443.1500680446625 and batch: 1000, loss is 3.8063405990600585 and perplexity is 44.985517249094784
At time: 444.27452516555786 and batch: 1050, loss is 3.7667638206481935 and perplexity is 43.23990607751153
At time: 445.3983838558197 and batch: 1100, loss is 3.768778247833252 and perplexity is 43.32709751070547
At time: 446.52371406555176 and batch: 1150, loss is 3.7522674417495727 and perplexity is 42.617605465940294
At time: 447.6507840156555 and batch: 1200, loss is 3.779947352409363 and perplexity is 43.81373498726824
At time: 448.77903175354004 and batch: 1250, loss is 3.7789444637298586 and perplexity is 43.76981671469293
At time: 449.90704011917114 and batch: 1300, loss is 3.773574557304382 and perplexity is 43.53540683751223
At time: 451.03679943084717 and batch: 1350, loss is 3.6489707899093626 and perplexity is 38.435087905106776
At time: 452.16025376319885 and batch: 1400, loss is 3.6659278440475465 and perplexity is 39.092390983367075
At time: 453.2851345539093 and batch: 1450, loss is 3.602796130180359 and perplexity is 36.70071107378647
At time: 454.412556886673 and batch: 1500, loss is 3.5945353507995605 and perplexity is 36.39878339244187
At time: 455.53572130203247 and batch: 1550, loss is 3.610846829414368 and perplexity is 36.99737001397036
At time: 456.66528701782227 and batch: 1600, loss is 3.6881910228729247 and perplexity is 39.972472226936226
At time: 457.79329347610474 and batch: 1650, loss is 3.6350681972503662 and perplexity is 37.904437787433714
At time: 458.92043471336365 and batch: 1700, loss is 3.6272287130355836 and perplexity is 37.60844826422316
At time: 460.04871916770935 and batch: 1750, loss is 3.599722318649292 and perplexity is 36.58807320736235
At time: 461.17274475097656 and batch: 1800, loss is 3.5551469039916994 and perplexity is 34.992960195658455
At time: 462.30441451072693 and batch: 1850, loss is 3.5935623836517334 and perplexity is 36.36338579512227
At time: 463.43576550483704 and batch: 1900, loss is 3.69772216796875 and perplexity is 40.35527704579087
At time: 464.56201934814453 and batch: 1950, loss is 3.621604309082031 and perplexity is 37.39751689677593
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336335222111192 and perplexity of 76.42693772956319
finished 10 epochs...
Completing Train Step...
At time: 468.2450530529022 and batch: 50, loss is 3.8559910917282103 and perplexity is 47.27544803598196
At time: 469.3656418323517 and batch: 100, loss is 3.8478724431991576 and perplexity is 46.89318910192374
At time: 470.48956537246704 and batch: 150, loss is 3.795161600112915 and perplexity is 44.48542467435102
At time: 471.61551213264465 and batch: 200, loss is 3.7796400356292725 and perplexity is 43.8002723600598
At time: 472.74757075309753 and batch: 250, loss is 3.773774013519287 and perplexity is 43.544091111011745
At time: 473.87052392959595 and batch: 300, loss is 3.7905863761901855 and perplexity is 44.282358785350645
At time: 474.99351978302 and batch: 350, loss is 3.817432246208191 and perplexity is 45.48725815588306
At time: 476.11787819862366 and batch: 400, loss is 3.769205484390259 and perplexity is 43.345612385505106
At time: 477.24079036712646 and batch: 450, loss is 3.8079767656326293 and perplexity is 45.0591812955593
At time: 478.374480009079 and batch: 500, loss is 3.8178092861175537 and perplexity is 45.5044119011954
At time: 479.50311255455017 and batch: 550, loss is 3.7896435117721556 and perplexity is 44.24062620208109
At time: 480.62929797172546 and batch: 600, loss is 3.7533845996856687 and perplexity is 42.66524266628775
At time: 481.7524793148041 and batch: 650, loss is 3.780195870399475 and perplexity is 43.82462484173291
At time: 482.87866616249084 and batch: 700, loss is 3.831985411643982 and perplexity is 46.154082180113
At time: 484.05148243904114 and batch: 750, loss is 3.7824747562408447 and perplexity is 43.924610042946505
At time: 485.1866159439087 and batch: 800, loss is 3.7584786367416383 and perplexity is 42.88313549933588
At time: 486.3181221485138 and batch: 850, loss is 3.759117760658264 and perplexity is 42.91055189715794
At time: 487.4479203224182 and batch: 900, loss is 3.716816473007202 and perplexity is 41.13323667850575
At time: 488.57572507858276 and batch: 950, loss is 3.806582126617432 and perplexity is 44.99638380342647
At time: 489.70133543014526 and batch: 1000, loss is 3.7729962825775147 and perplexity is 43.510238689767434
At time: 490.8252546787262 and batch: 1050, loss is 3.7364505529403687 and perplexity is 41.94883045144265
At time: 491.95536041259766 and batch: 1100, loss is 3.7392863845825195 and perplexity is 42.06795910675773
At time: 493.0797519683838 and batch: 1150, loss is 3.725329637527466 and perplexity is 41.48490547285204
At time: 494.204021692276 and batch: 1200, loss is 3.7553335094451903 and perplexity is 42.748474453388944
At time: 495.32972621917725 and batch: 1250, loss is 3.7572925901412964 and perplexity is 42.83230425233746
At time: 496.4537181854248 and batch: 1300, loss is 3.7535864686965943 and perplexity is 42.67385632601193
At time: 497.5792465209961 and batch: 1350, loss is 3.630210294723511 and perplexity is 37.720748257486896
At time: 498.70548367500305 and batch: 1400, loss is 3.649509048461914 and perplexity is 38.45578148863932
At time: 499.83048701286316 and batch: 1450, loss is 3.5889279508590697 and perplexity is 36.19525203078742
At time: 500.95498538017273 and batch: 1500, loss is 3.5833860731124876 and perplexity is 35.99521716537311
At time: 502.0799036026001 and batch: 1550, loss is 3.6017739534378053 and perplexity is 36.66321562724311
At time: 503.20166301727295 and batch: 1600, loss is 3.6813073635101317 and perplexity is 39.69826021805692
At time: 504.32393622398376 and batch: 1650, loss is 3.6303932523727416 and perplexity is 37.72765018827658
At time: 505.4470372200012 and batch: 1700, loss is 3.625190315246582 and perplexity is 37.531865366155884
At time: 506.57199597358704 and batch: 1750, loss is 3.6004414892196657 and perplexity is 36.61439573689953
At time: 507.6989758014679 and batch: 1800, loss is 3.5572158193588255 and perplexity is 35.065432612546005
At time: 508.8298156261444 and batch: 1850, loss is 3.597339367866516 and perplexity is 36.50098942905987
At time: 509.95294642448425 and batch: 1900, loss is 3.7022705554962156 and perplexity is 40.5392465497112
At time: 511.0805342197418 and batch: 1950, loss is 3.6261025524139403 and perplexity is 37.56611895002392
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.336196686500727 and perplexity of 76.4163506104523
finished 11 epochs...
Completing Train Step...
At time: 514.8129556179047 and batch: 50, loss is 3.837804522514343 and perplexity is 46.42344085535037
At time: 515.9418580532074 and batch: 100, loss is 3.8277159214019774 and perplexity is 45.95744783951198
At time: 517.0657143592834 and batch: 150, loss is 3.7733152866363526 and perplexity is 43.524120846624946
At time: 518.1915640830994 and batch: 200, loss is 3.757519702911377 and perplexity is 42.8420331203384
At time: 519.3233251571655 and batch: 250, loss is 3.751070022583008 and perplexity is 42.566604868962216
At time: 520.4533200263977 and batch: 300, loss is 3.7668462324142458 and perplexity is 43.24346970137556
At time: 521.5838115215302 and batch: 350, loss is 3.7935285329818726 and perplexity is 44.4128362765004
At time: 522.7104732990265 and batch: 400, loss is 3.744735350608826 and perplexity is 42.2978116473521
At time: 523.8389556407928 and batch: 450, loss is 3.7845478010177613 and perplexity is 44.015762174955746
At time: 524.9606931209564 and batch: 500, loss is 3.794520335197449 and perplexity is 44.456906876966464
At time: 526.0873584747314 and batch: 550, loss is 3.766005697250366 and perplexity is 43.20713731594623
At time: 527.2143642902374 and batch: 600, loss is 3.7310668897628783 and perplexity is 41.723598906994354
At time: 528.3388130664825 and batch: 650, loss is 3.758591318130493 and perplexity is 42.88796790285825
At time: 529.4676399230957 and batch: 700, loss is 3.8110685253143313 and perplexity is 45.198709037557805
At time: 530.5994548797607 and batch: 750, loss is 3.7625395393371583 and perplexity is 43.05763380609938
At time: 531.7272658348083 and batch: 800, loss is 3.738659729957581 and perplexity is 42.041605283856676
At time: 532.8543972969055 and batch: 850, loss is 3.7404891538619993 and perplexity is 42.118587596714455
At time: 533.9846260547638 and batch: 900, loss is 3.698309302330017 and perplexity is 40.378977972736344
At time: 535.1138536930084 and batch: 950, loss is 3.788367762565613 and perplexity is 44.18422224460878
At time: 536.2382588386536 and batch: 1000, loss is 3.75557674407959 and perplexity is 42.758873627612154
At time: 537.3623471260071 and batch: 1050, loss is 3.7202683687210083 and perplexity is 41.2754696673812
At time: 538.4839353561401 and batch: 1100, loss is 3.7230483198165896 and perplexity is 41.39037309345725
At time: 539.6543588638306 and batch: 1150, loss is 3.7099335050582884 and perplexity is 40.85109004582369
At time: 540.7822575569153 and batch: 1200, loss is 3.7409534311294554 and perplexity is 42.138146839577544
At time: 541.9094157218933 and batch: 1250, loss is 3.7437840127944946 and perplexity is 42.257591274282845
At time: 543.0364904403687 and batch: 1300, loss is 3.740668439865112 and perplexity is 42.12613954690068
At time: 544.1683053970337 and batch: 1350, loss is 3.617928771972656 and perplexity is 37.260313238655364
At time: 545.3026463985443 and batch: 1400, loss is 3.6383954668045044 and perplexity is 38.03076611690734
At time: 546.43794298172 and batch: 1450, loss is 3.5782458448410033 and perplexity is 35.81066825058104
At time: 547.5712871551514 and batch: 1500, loss is 3.573690643310547 and perplexity is 35.647914409458956
At time: 548.7005922794342 and batch: 1550, loss is 3.5928601455688476 and perplexity is 36.33785900478544
At time: 549.8277850151062 and batch: 1600, loss is 3.6732302284240723 and perplexity is 39.37890348755774
At time: 550.9618637561798 and batch: 1650, loss is 3.6229494190216065 and perplexity is 37.447854515695255
At time: 552.0854918956757 and batch: 1700, loss is 3.6191679573059083 and perplexity is 37.306514292254974
At time: 553.2100126743317 and batch: 1750, loss is 3.5955938625335695 and perplexity is 36.43733233041868
At time: 554.3348009586334 and batch: 1800, loss is 3.552735252380371 and perplexity is 34.90867104570218
At time: 555.4681224822998 and batch: 1850, loss is 3.5935160541534423 and perplexity is 36.36170113672721
At time: 556.6054911613464 and batch: 1900, loss is 3.6992110776901246 and perplexity is 40.415407163142945
At time: 557.7342553138733 and batch: 1950, loss is 3.622763924598694 and perplexity is 37.440908791748996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.337984874636628 and perplexity of 76.55311966996295
Annealing...
finished 12 epochs...
Completing Train Step...
At time: 561.4158596992493 and batch: 50, loss is 3.8341971397399903 and perplexity is 46.25627543059932
At time: 562.5388314723969 and batch: 100, loss is 3.846311888694763 and perplexity is 46.82006679495781
At time: 563.6698613166809 and batch: 150, loss is 3.8062162733078004 and perplexity is 44.979924738475816
At time: 564.7924494743347 and batch: 200, loss is 3.7972888946533203 and perplexity is 44.58015900357329
At time: 565.9151346683502 and batch: 250, loss is 3.7880497121810914 and perplexity is 44.17017167024783
At time: 567.035945892334 and batch: 300, loss is 3.798825764656067 and perplexity is 44.64872558813104
At time: 568.1823151111603 and batch: 350, loss is 3.825295090675354 and perplexity is 45.84632719406914
At time: 569.3182318210602 and batch: 400, loss is 3.7851625299453735 and perplexity is 44.042828255534594
At time: 570.4429812431335 and batch: 450, loss is 3.8269628715515136 and perplexity is 45.922852617886846
At time: 571.5688078403473 and batch: 500, loss is 3.837050938606262 and perplexity is 46.388470075727376
At time: 572.6880834102631 and batch: 550, loss is 3.8136157464981078 and perplexity is 45.31398690347855
At time: 573.8085706233978 and batch: 600, loss is 3.7758393049240113 and perplexity is 43.63411527918092
At time: 574.9299190044403 and batch: 650, loss is 3.7936929082870483 and perplexity is 44.42013725005051
At time: 576.053304195404 and batch: 700, loss is 3.839542713165283 and perplexity is 46.50420381660757
At time: 577.1832563877106 and batch: 750, loss is 3.791098279953003 and perplexity is 44.30503289442503
At time: 578.3070876598358 and batch: 800, loss is 3.761983346939087 and perplexity is 43.03369213620209
At time: 579.433454990387 and batch: 850, loss is 3.7604695320129395 and perplexity is 42.96859637461814
At time: 580.5587902069092 and batch: 900, loss is 3.715907211303711 and perplexity is 41.09585280009346
At time: 581.68652510643 and batch: 950, loss is 3.8146122121810913 and perplexity is 45.359163240983904
At time: 582.8157939910889 and batch: 1000, loss is 3.781140213012695 and perplexity is 43.866029849659014
At time: 583.9449145793915 and batch: 1050, loss is 3.743202986717224 and perplexity is 42.23304564330622
At time: 585.0774674415588 and batch: 1100, loss is 3.7426600313186644 and perplexity is 42.210121207212914
At time: 586.2018935680389 and batch: 1150, loss is 3.738993525505066 and perplexity is 42.05564092689681
At time: 587.3324615955353 and batch: 1200, loss is 3.759593925476074 and perplexity is 42.93098925767405
At time: 588.4552528858185 and batch: 1250, loss is 3.7559060621261597 and perplexity is 42.77295721521122
At time: 589.5807230472565 and batch: 1300, loss is 3.7475195646286013 and perplexity is 42.41574190290046
At time: 590.714325428009 and batch: 1350, loss is 3.6209013080596923 and perplexity is 37.37123564312103
At time: 591.8410170078278 and batch: 1400, loss is 3.6417817640304566 and perplexity is 38.15976789061206
At time: 592.9725158214569 and batch: 1450, loss is 3.573651099205017 and perplexity is 35.64650477244122
At time: 594.0966370105743 and batch: 1500, loss is 3.5691067123413087 and perplexity is 35.48488078352966
At time: 595.2201662063599 and batch: 1550, loss is 3.588545742034912 and perplexity is 36.18142052949794
At time: 596.3475065231323 and batch: 1600, loss is 3.6685556602478027 and perplexity is 39.19525369465699
At time: 597.476283788681 and batch: 1650, loss is 3.6200801706314087 and perplexity is 37.34056131843486
At time: 598.6037657260895 and batch: 1700, loss is 3.6073451328277586 and perplexity is 36.86804301378579
At time: 599.7322754859924 and batch: 1750, loss is 3.577330594062805 and perplexity is 35.777907503033674
At time: 600.8625545501709 and batch: 1800, loss is 3.533378930091858 and perplexity is 34.23946513491679
At time: 601.9882872104645 and batch: 1850, loss is 3.572888741493225 and perplexity is 35.61933974068091
At time: 603.1128749847412 and batch: 1900, loss is 3.688424816131592 and perplexity is 39.981818613993724
At time: 604.2401134967804 and batch: 1950, loss is 3.6236362934112547 and perplexity is 37.47358532381428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.328638546965843 and perplexity of 75.84096234131235
finished 13 epochs...
Completing Train Step...
At time: 607.9297559261322 and batch: 50, loss is 3.8464150619506836 and perplexity is 46.8248976228933
At time: 609.0800762176514 and batch: 100, loss is 3.838644666671753 and perplexity is 46.462459626353
At time: 610.2088248729706 and batch: 150, loss is 3.7868617391586303 and perplexity is 44.1177298538052
At time: 611.3339591026306 and batch: 200, loss is 3.774624252319336 and perplexity is 43.58112973039155
At time: 612.4606585502625 and batch: 250, loss is 3.764215431213379 and perplexity is 43.12985424472422
At time: 613.5863234996796 and batch: 300, loss is 3.774071702957153 and perplexity is 43.55705565662538
At time: 614.7126686573029 and batch: 350, loss is 3.800838465690613 and perplexity is 44.73868062023947
At time: 615.8424098491669 and batch: 400, loss is 3.76130989074707 and perplexity is 43.004720586397404
At time: 616.9672996997833 and batch: 450, loss is 3.8044061279296875 and perplexity is 44.89857818236074
At time: 618.0960841178894 and batch: 500, loss is 3.814524383544922 and perplexity is 45.35517958248088
At time: 619.2337336540222 and batch: 550, loss is 3.7910701036453247 and perplexity is 44.30378455977333
At time: 620.3617703914642 and batch: 600, loss is 3.7546004009246827 and perplexity is 42.71714666726502
At time: 621.4895231723785 and batch: 650, loss is 3.772923345565796 and perplexity is 43.507065298708476
At time: 622.617020368576 and batch: 700, loss is 3.8204677963256835 and perplexity is 45.62554679257714
At time: 623.7398855686188 and batch: 750, loss is 3.7740319204330444 and perplexity is 43.55532288147593
At time: 624.8910763263702 and batch: 800, loss is 3.745231795310974 and perplexity is 42.318815385022646
At time: 626.0177567005157 and batch: 850, loss is 3.7437616205215454 and perplexity is 42.25664504135904
At time: 627.1572794914246 and batch: 900, loss is 3.7002826738357544 and perplexity is 40.45873937084981
At time: 628.2895641326904 and batch: 950, loss is 3.7995190620422363 and perplexity is 44.6796911658138
At time: 629.4238247871399 and batch: 1000, loss is 3.766945524215698 and perplexity is 43.247763636556016
At time: 630.5496501922607 and batch: 1050, loss is 3.7297465991973877 and perplexity is 41.668547982604096
At time: 631.6781144142151 and batch: 1100, loss is 3.7298680925369263 and perplexity is 41.67361074119172
At time: 632.8077025413513 and batch: 1150, loss is 3.7277415370941163 and perplexity is 41.58508365968371
At time: 633.9313225746155 and batch: 1200, loss is 3.7490882778167727 and perplexity is 42.48233225353444
At time: 635.0588374137878 and batch: 1250, loss is 3.7470795059204103 and perplexity is 42.3970805926489
At time: 636.1827616691589 and batch: 1300, loss is 3.739685263633728 and perplexity is 42.08474248141827
At time: 637.3064579963684 and batch: 1350, loss is 3.6144153308868407 and perplexity is 37.129631029804536
At time: 638.4325604438782 and batch: 1400, loss is 3.637072548866272 and perplexity is 37.98048779858389
At time: 639.5596032142639 and batch: 1450, loss is 3.5706459951400755 and perplexity is 35.53954411050228
At time: 640.6857523918152 and batch: 1500, loss is 3.5673010540008545 and perplexity is 35.42086502526986
At time: 641.817085981369 and batch: 1550, loss is 3.5882717514038087 and perplexity is 36.171508517214114
At time: 642.9490711688995 and batch: 1600, loss is 3.669710841178894 and perplexity is 39.24055746630295
At time: 644.075478553772 and batch: 1650, loss is 3.621983518600464 and perplexity is 37.411701080367685
At time: 645.2028501033783 and batch: 1700, loss is 3.6108324193954466 and perplexity is 36.996836885009635
At time: 646.3365256786346 and batch: 1750, loss is 3.582117133140564 and perplexity is 35.94957036316493
At time: 647.4667575359344 and batch: 1800, loss is 3.5389843463897703 and perplexity is 34.43193051114485
At time: 648.5992829799652 and batch: 1850, loss is 3.579334011077881 and perplexity is 35.84965742019307
At time: 649.7253234386444 and batch: 1900, loss is 3.6949282026290895 and perplexity is 40.242683165396755
At time: 650.8581488132477 and batch: 1950, loss is 3.6299930667877196 and perplexity is 37.71255514712487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327323310319767 and perplexity of 75.74127909626556
finished 14 epochs...
Completing Train Step...
At time: 654.5291185379028 and batch: 50, loss is 3.842201099395752 and perplexity is 46.627994420408335
At time: 655.691034078598 and batch: 100, loss is 3.8323164319992067 and perplexity is 46.16936264972504
At time: 656.8205683231354 and batch: 150, loss is 3.77915855884552 and perplexity is 43.77918862186891
At time: 657.9476053714752 and batch: 200, loss is 3.766136646270752 and perplexity is 43.21279561871794
At time: 659.071626663208 and batch: 250, loss is 3.7550482034683226 and perplexity is 42.736279797812195
At time: 660.1981101036072 and batch: 300, loss is 3.7646035242080687 and perplexity is 43.146595887465594
At time: 661.3194780349731 and batch: 350, loss is 3.7915448713302613 and perplexity is 44.32482355892597
At time: 662.448480129242 and batch: 400, loss is 3.7516468286514284 and perplexity is 42.59116462739061
At time: 663.5721523761749 and batch: 450, loss is 3.7948205852508545 and perplexity is 44.47025706972828
At time: 664.6938362121582 and batch: 500, loss is 3.804541754722595 and perplexity is 44.90466804549069
At time: 665.8188688755035 and batch: 550, loss is 3.7814583873748777 and perplexity is 43.87998911635053
At time: 666.9440541267395 and batch: 600, loss is 3.7451382160186766 and perplexity is 42.31485540551699
At time: 668.0677568912506 and batch: 650, loss is 3.7637018871307375 and perplexity is 43.107710849583086
At time: 669.1915574073792 and batch: 700, loss is 3.8116275548934935 and perplexity is 45.22398351678227
At time: 670.3141858577728 and batch: 750, loss is 3.765919165611267 and perplexity is 43.20339869329041
At time: 671.4439754486084 and batch: 800, loss is 3.737527298927307 and perplexity is 41.994023012376026
At time: 672.5671682357788 and batch: 850, loss is 3.736107630729675 and perplexity is 41.93444773198616
At time: 673.6941869258881 and batch: 900, loss is 3.6930473899841307 and perplexity is 40.16706535179343
At time: 674.820277929306 and batch: 950, loss is 3.7924662971496583 and perplexity is 44.365684418027676
At time: 675.941924571991 and batch: 1000, loss is 3.76034884929657 and perplexity is 42.96341112058062
At time: 677.0657603740692 and batch: 1050, loss is 3.7234439563751223 and perplexity is 41.40675187803367
At time: 678.1909897327423 and batch: 1100, loss is 3.7238829851150514 and perplexity is 41.42493462321704
At time: 679.3119685649872 and batch: 1150, loss is 3.722350664138794 and perplexity is 41.36150693515295
At time: 680.4339714050293 and batch: 1200, loss is 3.744006643295288 and perplexity is 42.26700015030308
At time: 681.5834438800812 and batch: 1250, loss is 3.742774028778076 and perplexity is 42.21493332807157
At time: 682.7098407745361 and batch: 1300, loss is 3.735740919113159 and perplexity is 41.919072702143986
At time: 683.8386242389679 and batch: 1350, loss is 3.6110380554199217 and perplexity is 37.004445549745796
At time: 684.9632544517517 and batch: 1400, loss is 3.6342856454849244 and perplexity is 37.87478720579572
At time: 686.0851593017578 and batch: 1450, loss is 3.56844877243042 and perplexity is 35.461541542979916
At time: 687.2103786468506 and batch: 1500, loss is 3.5655622053146363 and perplexity is 35.35932701880231
At time: 688.3386850357056 and batch: 1550, loss is 3.587069425582886 and perplexity is 36.12804471260531
At time: 689.4626195430756 and batch: 1600, loss is 3.669086594581604 and perplexity is 39.216069325943224
At time: 690.5860993862152 and batch: 1650, loss is 3.6216909217834474 and perplexity is 37.40075613701827
At time: 691.7110211849213 and batch: 1700, loss is 3.6111832904815673 and perplexity is 37.00982028296678
At time: 692.8317143917084 and batch: 1750, loss is 3.583106746673584 and perplexity is 35.9851641536461
At time: 693.9560413360596 and batch: 1800, loss is 3.5402249193191526 and perplexity is 34.47467233873877
At time: 695.0899260044098 and batch: 1850, loss is 3.5808134412765504 and perplexity is 35.902733737665166
At time: 696.223970413208 and batch: 1900, loss is 3.6962098598480226 and perplexity is 40.294293557135695
At time: 697.3529570102692 and batch: 1950, loss is 3.630975117683411 and perplexity is 37.7496089870863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327208053234012 and perplexity of 75.7325498802272
finished 15 epochs...
Completing Train Step...
At time: 701.0269186496735 and batch: 50, loss is 3.837310333251953 and perplexity is 46.40050455725938
At time: 702.1818385124207 and batch: 100, loss is 3.826578416824341 and perplexity is 45.90520075350141
At time: 703.3124799728394 and batch: 150, loss is 3.7727990484237672 and perplexity is 43.50165783090714
At time: 704.4449963569641 and batch: 200, loss is 3.759384069442749 and perplexity is 42.921980875826414
At time: 705.5717322826385 and batch: 250, loss is 3.748032684326172 and perplexity is 42.437511840372125
At time: 706.6964535713196 and batch: 300, loss is 3.7574193572998045 and perplexity is 42.837734326010114
At time: 707.8232662677765 and batch: 350, loss is 3.7845024251937867 and perplexity is 44.01376496879197
At time: 708.9779074192047 and batch: 400, loss is 3.744426131248474 and perplexity is 42.284734367068545
At time: 710.108077287674 and batch: 450, loss is 3.7877829551696776 and perplexity is 44.15839053867903
At time: 711.2397263050079 and batch: 500, loss is 3.797316837310791 and perplexity is 44.58140470909039
At time: 712.3652119636536 and batch: 550, loss is 3.774518437385559 and perplexity is 43.576518440011206
At time: 713.4847922325134 and batch: 600, loss is 3.7383346271514895 and perplexity is 42.02793966149276
At time: 714.6086180210114 and batch: 650, loss is 3.757028317451477 and perplexity is 42.82098633965502
At time: 715.7336790561676 and batch: 700, loss is 3.8052147579193116 and perplexity is 44.93489920232434
At time: 716.8593518733978 and batch: 750, loss is 3.7599764347076414 and perplexity is 42.94741389847353
At time: 717.9871881008148 and batch: 800, loss is 3.7318727445602415 and perplexity is 41.757235620670045
At time: 719.1164753437042 and batch: 850, loss is 3.7306000232696532 and perplexity is 41.70412410310835
At time: 720.2413794994354 and batch: 900, loss is 3.6877228832244873 and perplexity is 39.953763907235505
At time: 721.3686079978943 and batch: 950, loss is 3.7872461175918577 and perplexity is 44.13469101722784
At time: 722.492148399353 and batch: 1000, loss is 3.75542019367218 and perplexity is 42.7521802324659
At time: 723.6158709526062 and batch: 1050, loss is 3.718726716041565 and perplexity is 41.2118862533367
At time: 724.745728969574 and batch: 1100, loss is 3.7193212604522703 and perplexity is 41.23639583525874
At time: 725.884039402008 and batch: 1150, loss is 3.7181389570236205 and perplexity is 41.18767071269313
At time: 727.0157933235168 and batch: 1200, loss is 3.7399994039535525 and perplexity is 42.09796507264689
At time: 728.1416177749634 and batch: 1250, loss is 3.7392602348327637 and perplexity is 42.06685905453746
At time: 729.2679677009583 and batch: 1300, loss is 3.73244610786438 and perplexity is 41.7811845523204
At time: 730.3923208713531 and batch: 1350, loss is 3.608079390525818 and perplexity is 36.89512359902846
At time: 731.518652677536 and batch: 1400, loss is 3.631648449897766 and perplexity is 37.775035574206065
At time: 732.6445288658142 and batch: 1450, loss is 3.566083092689514 and perplexity is 35.37775004357454
At time: 733.7700002193451 and batch: 1500, loss is 3.563459725379944 and perplexity is 35.28506284007046
At time: 734.8944265842438 and batch: 1550, loss is 3.5852437162399293 and perplexity is 36.062145578467856
At time: 736.0190587043762 and batch: 1600, loss is 3.667610502243042 and perplexity is 39.158225488388155
At time: 737.1498131752014 and batch: 1650, loss is 3.620416784286499 and perplexity is 37.353132777006984
At time: 738.2813832759857 and batch: 1700, loss is 3.610318398475647 and perplexity is 36.97782462365298
At time: 739.4089162349701 and batch: 1750, loss is 3.5827054023742675 and perplexity is 35.97072461096096
At time: 740.537609577179 and batch: 1800, loss is 3.539933166503906 and perplexity is 34.464615723123536
At time: 741.6596431732178 and batch: 1850, loss is 3.580604248046875 and perplexity is 35.89522391436989
At time: 742.7846720218658 and batch: 1900, loss is 3.6959491109848024 and perplexity is 40.28378823558126
At time: 743.9113836288452 and batch: 1950, loss is 3.6304331731796267 and perplexity is 37.7291563365771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327494208757267 and perplexity of 75.75422426864073
Annealing...
finished 16 epochs...
Completing Train Step...
At time: 747.6058535575867 and batch: 50, loss is 3.837929468154907 and perplexity is 46.42924162428808
At time: 748.7319219112396 and batch: 100, loss is 3.836550965309143 and perplexity is 46.36528287636859
At time: 749.8598701953888 and batch: 150, loss is 3.7883374166488646 and perplexity is 44.182881454222816
At time: 750.9866852760315 and batch: 200, loss is 3.779183235168457 and perplexity is 43.78026894459441
At time: 752.110368013382 and batch: 250, loss is 3.7672250175476076 and perplexity is 43.25985278745226
At time: 753.2314467430115 and batch: 300, loss is 3.772784161567688 and perplexity is 43.50101023280816
At time: 754.3585684299469 and batch: 350, loss is 3.799537239074707 and perplexity is 44.68050331739213
At time: 755.4895431995392 and batch: 400, loss is 3.761638865470886 and perplexity is 43.01887037980968
At time: 756.6144134998322 and batch: 450, loss is 3.808072147369385 and perplexity is 45.063479323501475
At time: 757.7414343357086 and batch: 500, loss is 3.8177039670944213 and perplexity is 45.49961967334655
At time: 758.8707165718079 and batch: 550, loss is 3.79924702167511 and perplexity is 44.667538139357795
At time: 759.9987714290619 and batch: 600, loss is 3.764583716392517 and perplexity is 43.145741256116786
At time: 761.125262260437 and batch: 650, loss is 3.7789913272857665 and perplexity is 43.77186797200985
At time: 762.2520000934601 and batch: 700, loss is 3.8237991523742676 and perplexity is 45.77779518986062
At time: 763.3719623088837 and batch: 750, loss is 3.7780137825012208 and perplexity is 43.729099918013794
At time: 764.4928703308105 and batch: 800, loss is 3.7484114170074463 and perplexity is 42.45358735698764
At time: 765.646363735199 and batch: 850, loss is 3.744167461395264 and perplexity is 42.27379799555256
At time: 766.7703173160553 and batch: 900, loss is 3.696028871536255 and perplexity is 40.28700142088653
At time: 767.8917105197906 and batch: 950, loss is 3.7974342918395996 and perplexity is 44.58664130449903
At time: 769.0118803977966 and batch: 1000, loss is 3.764820156097412 and perplexity is 43.15594382854595
At time: 770.1302344799042 and batch: 1050, loss is 3.727097396850586 and perplexity is 41.55830565908773
At time: 771.2514731884003 and batch: 1100, loss is 3.7249001026153565 and perplexity is 41.46709008406554
At time: 772.3790023326874 and batch: 1150, loss is 3.72818660736084 and perplexity is 41.60359606331447
At time: 773.5086710453033 and batch: 1200, loss is 3.7506609773635864 and perplexity is 42.54919676332749
At time: 774.6394937038422 and batch: 1250, loss is 3.7493492794036865 and perplexity is 42.49342165678138
At time: 775.7712969779968 and batch: 1300, loss is 3.737570381164551 and perplexity is 41.995832247810945
At time: 776.8913094997406 and batch: 1350, loss is 3.6090694427490235 and perplexity is 36.931669786504976
At time: 778.0217368602753 and batch: 1400, loss is 3.6314553451538085 and perplexity is 37.7677417398932
At time: 779.1469376087189 and batch: 1450, loss is 3.5632204246520995 and perplexity is 35.27662010906692
At time: 780.2779500484467 and batch: 1500, loss is 3.5570530319213867 and perplexity is 35.059724865215706
At time: 781.4071023464203 and batch: 1550, loss is 3.5800743865966798 and perplexity is 35.8762094569304
At time: 782.5394070148468 and batch: 1600, loss is 3.6626025819778443 and perplexity is 38.96261442852603
At time: 783.666356086731 and batch: 1650, loss is 3.617599148750305 and perplexity is 37.24803339811133
At time: 784.7925090789795 and batch: 1700, loss is 3.6064513540267944 and perplexity is 36.83510585996458
At time: 785.920469045639 and batch: 1750, loss is 3.575804271697998 and perplexity is 35.723340536629934
At time: 787.0471885204315 and batch: 1800, loss is 3.5324188327789305 and perplexity is 34.206607692139904
At time: 788.1703979969025 and batch: 1850, loss is 3.5691133832931516 and perplexity is 35.48511750225009
At time: 789.3016839027405 and batch: 1900, loss is 3.685077819824219 and perplexity is 39.8482233109391
At time: 790.42675614357 and batch: 1950, loss is 3.624111771583557 and perplexity is 37.49140743234969
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3250295239825585 and perplexity of 75.56774388754455
finished 17 epochs...
Completing Train Step...
At time: 794.076690196991 and batch: 50, loss is 3.8387284231185914 and perplexity is 46.46635131985762
At time: 795.2007596492767 and batch: 100, loss is 3.8316148471832276 and perplexity is 46.13698228604051
At time: 796.3351664543152 and batch: 150, loss is 3.7807983350753784 and perplexity is 43.8510355851059
At time: 797.4655060768127 and batch: 200, loss is 3.770071015357971 and perplexity is 43.383145596074094
At time: 798.5947513580322 and batch: 250, loss is 3.7586112022399902 and perplexity is 42.888820700386674
At time: 799.7197756767273 and batch: 300, loss is 3.7636041402816773 and perplexity is 43.10349741260579
At time: 800.8522255420685 and batch: 350, loss is 3.790060968399048 and perplexity is 44.25909860011124
At time: 801.9751152992249 and batch: 400, loss is 3.7523519563674927 and perplexity is 42.62120742879003
At time: 803.0990016460419 and batch: 450, loss is 3.7989233255386354 and perplexity is 44.65308176969799
At time: 804.2226762771606 and batch: 500, loss is 3.809808192253113 and perplexity is 45.14177949286281
At time: 805.3433058261871 and batch: 550, loss is 3.7902544021606444 and perplexity is 44.26766063210465
At time: 806.4720981121063 and batch: 600, loss is 3.7562058401107787 and perplexity is 42.78578152824871
At time: 807.6067092418671 and batch: 650, loss is 3.7707112073898315 and perplexity is 43.41092803230001
At time: 808.732399225235 and batch: 700, loss is 3.81676558971405 and perplexity is 45.4569438855581
At time: 809.859180688858 and batch: 750, loss is 3.770729637145996 and perplexity is 43.41172809249097
At time: 810.9771502017975 and batch: 800, loss is 3.7412880086898803 and perplexity is 42.152247676728265
At time: 812.103768825531 and batch: 850, loss is 3.7370259237289427 and perplexity is 41.972973528043724
At time: 813.2253293991089 and batch: 900, loss is 3.689669661521912 and perplexity is 40.03162078816414
At time: 814.355217218399 and batch: 950, loss is 3.791104063987732 and perplexity is 44.30528915701508
At time: 815.4787244796753 and batch: 1000, loss is 3.758746304512024 and perplexity is 42.894615468942526
At time: 816.6080737113953 and batch: 1050, loss is 3.722090344429016 and perplexity is 41.35074112100923
At time: 817.7410025596619 and batch: 1100, loss is 3.7202080345153807 and perplexity is 41.27297941983122
At time: 818.86496758461 and batch: 1150, loss is 3.723345022201538 and perplexity is 41.40265553789316
At time: 819.9887399673462 and batch: 1200, loss is 3.7461441135406495 and perplexity is 42.357441228608195
At time: 821.115415096283 and batch: 1250, loss is 3.745482630729675 and perplexity is 42.32943177422624
At time: 822.236807346344 and batch: 1300, loss is 3.7347281694412233 and perplexity is 41.87664066515954
At time: 823.3578042984009 and batch: 1350, loss is 3.6072972583770753 and perplexity is 36.86627801872815
At time: 824.4862084388733 and batch: 1400, loss is 3.6306323480606078 and perplexity is 37.7366717852194
At time: 825.6075110435486 and batch: 1450, loss is 3.5636541175842287 and perplexity is 35.29192264793925
At time: 826.7283771038055 and batch: 1500, loss is 3.5582885456085207 and perplexity is 35.10306840540878
At time: 827.8518738746643 and batch: 1550, loss is 3.5818495988845824 and perplexity is 35.9399539080279
At time: 828.9750485420227 and batch: 1600, loss is 3.6652535247802733 and perplexity is 39.06603911670746
At time: 830.1005170345306 and batch: 1650, loss is 3.620513515472412 and perplexity is 37.35674616459889
At time: 831.2314076423645 and batch: 1700, loss is 3.6102233028411863 and perplexity is 36.97430836115267
At time: 832.3450419902802 and batch: 1750, loss is 3.579950366020203 and perplexity is 35.87176034464818
At time: 833.4578194618225 and batch: 1800, loss is 3.536539607048035 and perplexity is 34.347856227740735
At time: 834.5759651660919 and batch: 1850, loss is 3.5733908128738405 and perplexity is 35.637227681897045
At time: 835.6974794864655 and batch: 1900, loss is 3.6897533702850343 and perplexity is 40.034971925883944
At time: 836.8162145614624 and batch: 1950, loss is 3.628315052986145 and perplexity is 37.649326023602654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324352459574855 and perplexity of 75.51659697461886
finished 18 epochs...
Completing Train Step...
At time: 840.4090235233307 and batch: 50, loss is 3.8383649158477784 and perplexity is 46.44946353290734
At time: 841.530145406723 and batch: 100, loss is 3.829579081535339 and perplexity is 46.04315374127425
At time: 842.6521968841553 and batch: 150, loss is 3.7777735805511474 and perplexity is 43.718597364355965
At time: 843.7750818729401 and batch: 200, loss is 3.76628089427948 and perplexity is 43.21902942803399
At time: 844.8972444534302 and batch: 250, loss is 3.754775309562683 and perplexity is 42.72461891866946
At time: 846.0252771377563 and batch: 300, loss is 3.759444446563721 and perplexity is 42.9245724596935
At time: 847.1589303016663 and batch: 350, loss is 3.785736517906189 and perplexity is 44.068115565324966
At time: 848.2819957733154 and batch: 400, loss is 3.7480880498886107 and perplexity is 42.43986148212768
At time: 849.4292771816254 and batch: 450, loss is 3.7946940422058106 and perplexity is 44.464630024024046
At time: 850.5517537593842 and batch: 500, loss is 3.8059209156036378 and perplexity is 44.96664153291677
At time: 851.6756036281586 and batch: 550, loss is 3.786042876243591 and perplexity is 44.08161826816919
At time: 852.7977328300476 and batch: 600, loss is 3.7520844078063966 and perplexity is 42.609805711394834
At time: 853.9169855117798 and batch: 650, loss is 3.76676992893219 and perplexity is 43.240170199944494
At time: 855.0379459857941 and batch: 700, loss is 3.813256540298462 and perplexity is 45.29771276151348
At time: 856.1602399349213 and batch: 750, loss is 3.7672805786132812 and perplexity is 43.26225641774753
At time: 857.2840657234192 and batch: 800, loss is 3.7378691673278808 and perplexity is 42.008381896141394
At time: 858.4112422466278 and batch: 850, loss is 3.7336294841766358 and perplexity is 41.8306566827179
At time: 859.5384685993195 and batch: 900, loss is 3.686583890914917 and perplexity is 39.90828278364868
At time: 860.6650085449219 and batch: 950, loss is 3.788143501281738 and perplexity is 44.17431454519942
At time: 861.7867345809937 and batch: 1000, loss is 3.7559562635421755 and perplexity is 42.77510453212933
At time: 862.9072949886322 and batch: 1050, loss is 3.7197017812728883 and perplexity is 41.25209012825456
At time: 864.0305888652802 and batch: 1100, loss is 3.7179537343978883 and perplexity is 41.18004253065369
At time: 865.151921749115 and batch: 1150, loss is 3.721202058792114 and perplexity is 41.31402616069631
At time: 866.2766771316528 and batch: 1200, loss is 3.7441248655319215 and perplexity is 42.27199734498059
At time: 867.4001934528351 and batch: 1250, loss is 3.7439053869247436 and perplexity is 42.262720563945415
At time: 868.5254013538361 and batch: 1300, loss is 3.7335805320739746 and perplexity is 41.828609034236344
At time: 869.6540651321411 and batch: 1350, loss is 3.606599063873291 and perplexity is 36.840547169654464
At time: 870.7811467647552 and batch: 1400, loss is 3.6303222942352296 and perplexity is 37.7249731994647
At time: 871.9091563224792 and batch: 1450, loss is 3.5638570547103883 and perplexity is 35.299085416069275
At time: 873.0334794521332 and batch: 1500, loss is 3.5588291263580323 and perplexity is 35.122049578403654
At time: 874.1586470603943 and batch: 1550, loss is 3.5826401472091676 and perplexity is 35.968377411971964
At time: 875.2816534042358 and batch: 1600, loss is 3.666441330909729 and perplexity is 39.11246956715165
At time: 876.4065480232239 and batch: 1650, loss is 3.6217694997787477 and perplexity is 37.40369512892677
At time: 877.5335328578949 and batch: 1700, loss is 3.61178249835968 and perplexity is 37.03200350436464
At time: 878.6606729030609 and batch: 1750, loss is 3.581650218963623 and perplexity is 35.93278891715983
At time: 879.7877051830292 and batch: 1800, loss is 3.5382255601882933 and perplexity is 34.40581394708006
At time: 880.9178915023804 and batch: 1850, loss is 3.5751370191574097 and perplexity is 35.69951199760926
At time: 882.0455148220062 and batch: 1900, loss is 3.6915073108673098 and perplexity is 40.10525250381685
At time: 883.1736104488373 and batch: 1950, loss is 3.629710998535156 and perplexity is 37.70191913270633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.324068007358285 and perplexity of 75.49511916607158
finished 19 epochs...
Completing Train Step...
At time: 886.794933795929 and batch: 50, loss is 3.8372265577316282 and perplexity is 46.39661749366942
At time: 887.942845582962 and batch: 100, loss is 3.8277258825302125 and perplexity is 45.95790562982332
At time: 889.0657494068146 and batch: 150, loss is 3.7754935789108277 and perplexity is 43.61903243788218
At time: 890.1926927566528 and batch: 200, loss is 3.7636794662475586 and perplexity is 43.10674434746897
At time: 891.3234732151031 and batch: 250, loss is 3.75207649230957 and perplexity is 42.60946843494781
At time: 892.45556807518 and batch: 300, loss is 3.7566098260879515 and perplexity is 42.80306987589838
At time: 893.5797460079193 and batch: 350, loss is 3.782863564491272 and perplexity is 43.94169161424073
At time: 894.708393573761 and batch: 400, loss is 3.745224537849426 and perplexity is 42.31850825896173
At time: 895.8353016376495 and batch: 450, loss is 3.7918201971054075 and perplexity is 44.337029005490464
At time: 896.9648356437683 and batch: 500, loss is 3.803178882598877 and perplexity is 44.843510409671474
At time: 898.0915205478668 and batch: 550, loss is 3.78320366859436 and perplexity is 43.95663890552884
At time: 899.2131073474884 and batch: 600, loss is 3.7492599439620973 and perplexity is 42.48962565775418
At time: 900.3379461765289 and batch: 650, loss is 3.764074754714966 and perplexity is 43.12378731459927
At time: 901.461817741394 and batch: 700, loss is 3.810804696083069 and perplexity is 45.18678586980763
At time: 902.5911152362823 and batch: 750, loss is 3.7649501514434816 and perplexity is 43.16155426505631
At time: 903.7216248512268 and batch: 800, loss is 3.73560275554657 and perplexity is 41.91328141363309
At time: 904.8500661849976 and batch: 850, loss is 3.7313703870773316 and perplexity is 41.73626382899965
At time: 906.0103647708893 and batch: 900, loss is 3.684478507041931 and perplexity is 39.824348916186956
At time: 907.1386756896973 and batch: 950, loss is 3.786144371032715 and perplexity is 44.086092549773845
At time: 908.2686629295349 and batch: 1000, loss is 3.7540919303894045 and perplexity is 42.69543177799209
At time: 909.3950312137604 and batch: 1050, loss is 3.718013482093811 and perplexity is 41.182503016816355
At time: 910.517908334732 and batch: 1100, loss is 3.7163897371292114 and perplexity is 41.11568739535785
At time: 911.640481710434 and batch: 1150, loss is 3.7197562980651857 and perplexity is 41.25433912118729
At time: 912.7705523967743 and batch: 1200, loss is 3.7427548360824585 and perplexity is 42.21412311748077
At time: 913.8949437141418 and batch: 1250, loss is 3.7428305625915526 and perplexity is 42.21731996670051
At time: 915.0194811820984 and batch: 1300, loss is 3.7327142667770388 and perplexity is 41.79239005169966
At time: 916.1439595222473 and batch: 1350, loss is 3.6059811449050905 and perplexity is 36.8177897286108
At time: 917.2726292610168 and batch: 1400, loss is 3.6299049758911135 and perplexity is 37.70923316064918
At time: 918.4028506278992 and batch: 1450, loss is 3.5637166118621826 and perplexity is 35.29412826008109
At time: 919.5290200710297 and batch: 1500, loss is 3.5588690042495728 and perplexity is 35.12345019961415
At time: 920.6546070575714 and batch: 1550, loss is 3.5828280591964723 and perplexity is 35.97513693632951
At time: 921.7843315601349 and batch: 1600, loss is 3.666863913536072 and perplexity is 39.12900131003175
At time: 922.91277384758 and batch: 1650, loss is 3.6222026538848877 and perplexity is 37.41990020245037
At time: 924.047285079956 and batch: 1700, loss is 3.6123939752578735 and perplexity is 37.05465464361979
At time: 925.1748950481415 and batch: 1750, loss is 3.5823590087890627 and perplexity is 35.95826674048832
At time: 926.2987427711487 and batch: 1800, loss is 3.5389490222930906 and perplexity is 34.430714255784295
At time: 927.4221744537354 and batch: 1850, loss is 3.575897226333618 and perplexity is 35.72666134107234
At time: 928.5440983772278 and batch: 1900, loss is 3.6922048807144163 and perplexity is 40.13323847862535
At time: 929.6671826839447 and batch: 1950, loss is 3.6301485204696657 and perplexity is 37.71841815837962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3239408271257265 and perplexity of 75.48551828979276
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5dd8c64b38>
ELAPSED
4774.58330488205


RESULTS SO FAR:
[{'best_accuracy': -76.21175240042173, 'params': {'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}}, {'best_accuracy': -73.46243748948554, 'params': {'rnn_dropout': 0.1541901093865481, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2553724200355174, 'num_layers': 2}}, {'best_accuracy': -74.63349668083315, 'params': {'rnn_dropout': 0.9124043211516957, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.644131086985198, 'num_layers': 2}}, {'best_accuracy': -75.57357919480093, 'params': {'rnn_dropout': 0.11345604619246663, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.06607543552697792, 'num_layers': 2}}, {'best_accuracy': -75.48551828979276, 'params': {'rnn_dropout': 0.7362722002869169, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.3951791952761644, 'num_layers': 2}}]
SETTINGS FOR THIS RUN
{'rnn_dropout': 0.16227600235143344, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2602472106168877, 'num_layers': 2}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: gigavec
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.6696994304656982 and batch: 50, loss is 7.676411142349243 and perplexity is 2156.865182999255
At time: 2.874135732650757 and batch: 100, loss is 6.809171724319458 and perplexity is 906.1199789020139
At time: 4.055511951446533 and batch: 150, loss is 6.44697943687439 and perplexity is 630.7940590182742
At time: 5.244765281677246 and batch: 200, loss is 6.243138427734375 and perplexity is 514.4706087203431
At time: 6.426000595092773 and batch: 250, loss is 6.157201929092407 and perplexity is 472.1052410662043
At time: 7.613745212554932 and batch: 300, loss is 6.0215650653839115 and perplexity is 412.223247469074
At time: 8.803508758544922 and batch: 350, loss is 5.904380588531494 and perplexity is 366.6400543839447
At time: 9.990021228790283 and batch: 400, loss is 5.809585752487183 and perplexity is 333.4809534022649
At time: 11.176971912384033 and batch: 450, loss is 5.698858842849732 and perplexity is 298.5265408199518
At time: 12.36691951751709 and batch: 500, loss is 5.65767427444458 and perplexity is 286.4815896115715
At time: 13.555802822113037 and batch: 550, loss is 5.600275011062622 and perplexity is 270.50078790707863
At time: 14.739121913909912 and batch: 600, loss is 5.596308364868164 and perplexity is 269.42993224299653
At time: 15.922764778137207 and batch: 650, loss is 5.645023450851441 and perplexity is 282.88018992630737
At time: 17.106703996658325 and batch: 700, loss is 5.572033090591431 and perplexity is 262.9681942861497
At time: 18.29082679748535 and batch: 750, loss is 5.490115098953247 and perplexity is 242.28509201362525
At time: 19.473357915878296 and batch: 800, loss is 5.492003526687622 and perplexity is 242.74306218669804
At time: 20.661707878112793 and batch: 850, loss is 5.486169757843018 and perplexity is 241.33107787280557
At time: 21.85622501373291 and batch: 900, loss is 5.4808194541931154 and perplexity is 240.04333131547173
At time: 23.042123794555664 and batch: 950, loss is 5.486772356033325 and perplexity is 241.47654736902214
At time: 24.231303453445435 and batch: 1000, loss is 5.454877014160156 and perplexity is 233.8961033917861
At time: 25.417038917541504 and batch: 1050, loss is 5.356074428558349 and perplexity is 211.891516389729
At time: 26.599998712539673 and batch: 1100, loss is 5.425708684921265 and perplexity is 227.17228285328082
At time: 27.782891273498535 and batch: 1150, loss is 5.3188198471069335 and perplexity is 204.1428200362991
At time: 28.967910289764404 and batch: 1200, loss is 5.395130014419555 and perplexity is 220.33079141432344
At time: 30.155102968215942 and batch: 1250, loss is 5.352012643814087 and perplexity is 211.0326042001004
At time: 31.338225603103638 and batch: 1300, loss is 5.360376682281494 and perplexity is 212.8050912613237
At time: 32.52080416679382 and batch: 1350, loss is 5.291043863296509 and perplexity is 198.55057693139503
At time: 33.71551823616028 and batch: 1400, loss is 5.299304647445679 and perplexity is 200.19755368397094
At time: 34.90629291534424 and batch: 1450, loss is 5.2665008926391605 and perplexity is 193.73686892359348
At time: 36.10239768028259 and batch: 1500, loss is 5.211623859405518 and perplexity is 183.3916187350654
At time: 37.29646897315979 and batch: 1550, loss is 5.201992034912109 and perplexity is 181.63370241103718
At time: 38.49014854431152 and batch: 1600, loss is 5.226268548965454 and perplexity is 186.09709413022713
At time: 39.6840717792511 and batch: 1650, loss is 5.209590578079224 and perplexity is 183.01911081632636
At time: 40.88330554962158 and batch: 1700, loss is 5.221548051834106 and perplexity is 185.22069348201538
At time: 42.07640814781189 and batch: 1750, loss is 5.2138316822052 and perplexity is 183.79696223083184
At time: 43.27111554145813 and batch: 1800, loss is 5.183886108398437 and perplexity is 178.37464906562647
At time: 44.46365189552307 and batch: 1850, loss is 5.16576889038086 and perplexity is 175.17209494365622
At time: 45.65942120552063 and batch: 1900, loss is 5.240789546966552 and perplexity is 188.81912513517997
At time: 46.85949993133545 and batch: 1950, loss is 5.158792848587036 and perplexity is 173.95433958288092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.808282044876454 and perplexity of 122.52095111565517
finished 1 epochs...
Completing Train Step...
At time: 50.55602693557739 and batch: 50, loss is 5.0579456615447995 and perplexity is 157.2671043780485
At time: 51.70199489593506 and batch: 100, loss is 4.997205333709717 and perplexity is 147.99897287551323
At time: 52.826416969299316 and batch: 150, loss is 4.9327896690368656 and perplexity is 138.76608433413327
At time: 53.960124492645264 and batch: 200, loss is 4.891712923049926 and perplexity is 133.18150845415963
At time: 55.07960891723633 and batch: 250, loss is 4.91560842514038 and perplexity is 136.40227513428522
At time: 56.20513844490051 and batch: 300, loss is 4.925655918121338 and perplexity is 137.7796842025793
At time: 57.33641004562378 and batch: 350, loss is 4.9175293922424315 and perplexity is 136.6645512487044
At time: 58.459662675857544 and batch: 400, loss is 4.864016637802124 and perplexity is 129.54348778804663
At time: 59.586846590042114 and batch: 450, loss is 4.837691555023193 and perplexity is 126.17774090366464
At time: 60.750802755355835 and batch: 500, loss is 4.832248411178589 and perplexity is 125.49280310851061
At time: 61.871092319488525 and batch: 550, loss is 4.796083641052246 and perplexity is 121.03546974787317
At time: 63.00277042388916 and batch: 600, loss is 4.768293266296387 and perplexity is 117.7181568642799
At time: 64.12011337280273 and batch: 650, loss is 4.833226299285888 and perplexity is 125.61558104998248
At time: 65.23702263832092 and batch: 700, loss is 4.853633508682251 and perplexity is 128.20537992276766
At time: 66.35524344444275 and batch: 750, loss is 4.795942916870117 and perplexity is 121.01843832877861
At time: 67.47703814506531 and batch: 800, loss is 4.795711488723755 and perplexity is 120.99043449648302
At time: 68.6057403087616 and batch: 850, loss is 4.7840635871887205 and perplexity is 119.58932565876648
At time: 69.72341012954712 and batch: 900, loss is 4.761763458251953 and perplexity is 116.95198409951571
At time: 70.8385021686554 and batch: 950, loss is 4.813005247116089 and perplexity is 123.10101113840405
At time: 71.95062303543091 and batch: 1000, loss is 4.782889356613159 and perplexity is 119.44898262973072
At time: 73.06982231140137 and batch: 1050, loss is 4.714266166687012 and perplexity is 111.526938954001
At time: 74.195974111557 and batch: 1100, loss is 4.7643852710723875 and perplexity is 117.2590126205858
At time: 75.31746482849121 and batch: 1150, loss is 4.703124132156372 and perplexity is 110.2911990615659
At time: 76.45202589035034 and batch: 1200, loss is 4.784317235946656 and perplexity is 119.61966319005805
At time: 77.58196806907654 and batch: 1250, loss is 4.76182451248169 and perplexity is 116.95912473080175
At time: 78.70378494262695 and batch: 1300, loss is 4.762103815078735 and perplexity is 116.99179628049913
At time: 79.82606148719788 and batch: 1350, loss is 4.647787742614746 and perplexity is 104.35387240555207
At time: 80.94719076156616 and batch: 1400, loss is 4.653119287490845 and perplexity is 104.91172554737568
At time: 82.07060599327087 and batch: 1450, loss is 4.607319650650024 and perplexity is 100.21517764171477
At time: 83.19353199005127 and batch: 1500, loss is 4.588117074966431 and perplexity is 98.30914702559714
At time: 84.31681156158447 and batch: 1550, loss is 4.5985445785522465 and perplexity is 99.33962935053947
At time: 85.4371247291565 and batch: 1600, loss is 4.649418859481812 and perplexity is 104.52422466142625
At time: 86.55833601951599 and batch: 1650, loss is 4.625618190765381 and perplexity is 102.06584974976039
At time: 87.69615077972412 and batch: 1700, loss is 4.639476413726807 and perplexity is 103.49014737470051
At time: 88.82398200035095 and batch: 1750, loss is 4.627218370437622 and perplexity is 102.22930419111908
At time: 89.95717430114746 and batch: 1800, loss is 4.582267999649048 and perplexity is 97.73580780696682
At time: 91.08151865005493 and batch: 1850, loss is 4.6097306060791015 and perplexity is 100.4570834632256
At time: 92.2016851902008 and batch: 1900, loss is 4.717668781280517 and perplexity is 111.90706849446094
At time: 93.32134866714478 and batch: 1950, loss is 4.635659255981445 and perplexity is 103.09586216026129
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.544246513898982 and perplexity of 94.08950535890837
finished 2 epochs...
Completing Train Step...
At time: 96.98255562782288 and batch: 50, loss is 4.6120459079742435 and perplexity is 100.68994140314129
At time: 98.13227987289429 and batch: 100, loss is 4.56219482421875 and perplexity is 95.79349915995584
At time: 99.26004552841187 and batch: 150, loss is 4.508251142501831 and perplexity is 90.76294816776748
At time: 100.3834319114685 and batch: 200, loss is 4.500330076217652 and perplexity is 90.04684871898208
At time: 101.50847578048706 and batch: 250, loss is 4.505903882980347 and perplexity is 90.55015381297183
At time: 102.63171768188477 and batch: 300, loss is 4.530768871307373 and perplexity is 92.82990790298791
At time: 103.75597786903381 and batch: 350, loss is 4.5294508934021 and perplexity is 92.70764072584106
At time: 104.87916135787964 and batch: 400, loss is 4.474157276153565 and perplexity is 87.72064497278323
At time: 106.0071439743042 and batch: 450, loss is 4.481188135147095 and perplexity is 88.33956969502765
At time: 107.12928915023804 and batch: 500, loss is 4.484465589523316 and perplexity is 88.6295735819776
At time: 108.25357222557068 and batch: 550, loss is 4.456317272186279 and perplexity is 86.16958491447456
At time: 109.38180112838745 and batch: 600, loss is 4.42591254234314 and perplexity is 83.58905097736245
At time: 110.5091061592102 and batch: 650, loss is 4.491271734237671 and perplexity is 89.23485677166603
At time: 111.6345784664154 and batch: 700, loss is 4.534265594482422 and perplexity is 93.15507657438279
At time: 112.7571771144867 and batch: 750, loss is 4.472917890548706 and perplexity is 87.61199261314844
At time: 113.87994074821472 and batch: 800, loss is 4.474094114303589 and perplexity is 87.7151045495392
At time: 115.00742864608765 and batch: 850, loss is 4.4678825092315675 and perplexity is 87.17194166434302
At time: 116.1522605419159 and batch: 900, loss is 4.4350237369537355 and perplexity is 84.35412717454061
At time: 117.27635979652405 and batch: 950, loss is 4.5022493267059325 and perplexity is 90.2198371282981
At time: 118.39861583709717 and batch: 1000, loss is 4.48405611038208 and perplexity is 88.59328904968574
At time: 119.52485489845276 and batch: 1050, loss is 4.4239309215545655 and perplexity is 83.42357318751286
At time: 120.65151453018188 and batch: 1100, loss is 4.464179277420044 and perplexity is 86.84972075450389
At time: 121.7770676612854 and batch: 1150, loss is 4.422290821075439 and perplexity is 83.28686228561067
At time: 122.90320467948914 and batch: 1200, loss is 4.490073909759522 and perplexity is 89.12803306671752
At time: 124.02982831001282 and batch: 1250, loss is 4.483182306289673 and perplexity is 88.5159096832813
At time: 125.15708422660828 and batch: 1300, loss is 4.473285837173462 and perplexity is 87.64423508150855
At time: 126.27678847312927 and batch: 1350, loss is 4.348546686172486 and perplexity is 77.36594418608121
At time: 127.39804911613464 and batch: 1400, loss is 4.371449413299561 and perplexity is 79.15828165811138
At time: 128.52122712135315 and batch: 1450, loss is 4.319209690093994 and perplexity is 75.12922944910356
At time: 129.6526596546173 and batch: 1500, loss is 4.310921134948731 and perplexity is 74.50909026699814
At time: 130.77785730361938 and batch: 1550, loss is 4.331258506774902 and perplexity is 76.03992313536024
At time: 131.90109014511108 and batch: 1600, loss is 4.387715311050415 and perplexity is 80.45639100972713
At time: 133.02442693710327 and batch: 1650, loss is 4.360163745880127 and perplexity is 78.26994975563686
At time: 134.14847230911255 and batch: 1700, loss is 4.376160507202148 and perplexity is 79.53208357277164
At time: 135.27018213272095 and batch: 1750, loss is 4.361164846420288 and perplexity is 78.34834507886853
At time: 136.39516520500183 and batch: 1800, loss is 4.314251527786255 and perplexity is 74.75764847605281
At time: 137.52451491355896 and batch: 1850, loss is 4.353946056365967 and perplexity is 77.78480132389772
At time: 138.65263843536377 and batch: 1900, loss is 4.461672773361206 and perplexity is 86.63230416852917
At time: 139.7902865409851 and batch: 1950, loss is 4.382105617523194 and perplexity is 80.00631887748315
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.454283532430959 and perplexity of 85.99451648608758
finished 3 epochs...
Completing Train Step...
At time: 143.4408881664276 and batch: 50, loss is 4.36399610042572 and perplexity is 78.57048346139631
At time: 144.59519910812378 and batch: 100, loss is 4.323271017074585 and perplexity is 75.43497426026588
At time: 145.71778535842896 and batch: 150, loss is 4.276002445220947 and perplexity is 71.95223133990955
At time: 146.83998322486877 and batch: 200, loss is 4.275389966964721 and perplexity is 71.90817565567845
At time: 147.96108031272888 and batch: 250, loss is 4.27637179851532 and perplexity is 71.97881204212518
At time: 149.08420491218567 and batch: 300, loss is 4.296455211639405 and perplexity is 73.43900602035394
At time: 150.20793652534485 and batch: 350, loss is 4.299415645599365 and perplexity is 73.65673948150759
At time: 151.3333957195282 and batch: 400, loss is 4.247398977279663 and perplexity is 69.92330351363039
At time: 152.47709727287292 and batch: 450, loss is 4.265648107528687 and perplexity is 71.21105744321393
At time: 153.6079261302948 and batch: 500, loss is 4.271700773239136 and perplexity is 71.64338120456932
At time: 154.7289435863495 and batch: 550, loss is 4.246864471435547 and perplexity is 69.88593908590452
At time: 155.84790802001953 and batch: 600, loss is 4.224881720542908 and perplexity is 68.36641672766127
At time: 156.9698724746704 and batch: 650, loss is 4.281095352172851 and perplexity is 72.31961208299182
At time: 158.1028208732605 and batch: 700, loss is 4.325480375289917 and perplexity is 75.60182138503531
At time: 159.24304747581482 and batch: 750, loss is 4.2722063684463505 and perplexity is 71.67961291325231
At time: 160.37012481689453 and batch: 800, loss is 4.272409930229187 and perplexity is 71.6942056282591
At time: 161.4924488067627 and batch: 850, loss is 4.267520942687988 and perplexity is 71.34454898012793
At time: 162.61566805839539 and batch: 900, loss is 4.23451940536499 and perplexity is 69.02849603558606
At time: 163.7401683330536 and batch: 950, loss is 4.307585020065307 and perplexity is 74.26093355182185
At time: 164.8753411769867 and batch: 1000, loss is 4.291743249893188 and perplexity is 73.09377822214086
At time: 166.01232028007507 and batch: 1050, loss is 4.240062866210938 and perplexity is 69.41221538456797
At time: 167.15083599090576 and batch: 1100, loss is 4.277015585899353 and perplexity is 72.02516601268529
At time: 168.28263974189758 and batch: 1150, loss is 4.239760575294494 and perplexity is 69.39123587348458
At time: 169.4085705280304 and batch: 1200, loss is 4.301371402740479 and perplexity is 73.80093513561764
At time: 170.53397345542908 and batch: 1250, loss is 4.304268684387207 and perplexity is 74.01506728127552
At time: 171.67035579681396 and batch: 1300, loss is 4.285987310409546 and perplexity is 72.67426336736101
At time: 172.80859684944153 and batch: 1350, loss is 4.163378849029541 and perplexity is 64.28837675430738
At time: 173.94594025611877 and batch: 1400, loss is 4.187174048423767 and perplexity is 65.83647713114965
At time: 175.07896757125854 and batch: 1450, loss is 4.1340930461883545 and perplexity is 62.43294159076992
At time: 176.2163290977478 and batch: 1500, loss is 4.131290173530578 and perplexity is 62.258195016440354
At time: 177.34362030029297 and batch: 1550, loss is 4.154666037559509 and perplexity is 63.73067734090807
At time: 178.47375416755676 and batch: 1600, loss is 4.221053252220154 and perplexity is 68.1051784571852
At time: 179.60629510879517 and batch: 1650, loss is 4.186198296546936 and perplexity is 65.77226839601632
At time: 180.73777651786804 and batch: 1700, loss is 4.1993218564987185 and perplexity is 66.6411234692484
At time: 181.86317253112793 and batch: 1750, loss is 4.186747093200683 and perplexity is 65.80837390320596
At time: 182.9917495250702 and batch: 1800, loss is 4.140962476730347 and perplexity is 62.86329680183799
At time: 184.12630367279053 and batch: 1850, loss is 4.178676943778992 and perplexity is 65.27942770078725
At time: 185.24859833717346 and batch: 1900, loss is 4.286031045913696 and perplexity is 72.67744188241464
At time: 186.3696961402893 and batch: 1950, loss is 4.2104635381698605 and perplexity is 67.38776937479675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.429107807957849 and perplexity of 83.8565673630653
finished 4 epochs...
Completing Train Step...
At time: 190.03523111343384 and batch: 50, loss is 4.1967478942871095 and perplexity is 66.46981230451365
At time: 191.16831231117249 and batch: 100, loss is 4.162979927062988 and perplexity is 64.26273582333143
At time: 192.2857792377472 and batch: 150, loss is 4.119903082847595 and perplexity is 61.55327640706568
At time: 193.42009735107422 and batch: 200, loss is 4.119917063713074 and perplexity is 61.55413698115867
At time: 194.5538010597229 and batch: 250, loss is 4.117587580680847 and perplexity is 61.41091454538093
At time: 195.67485570907593 and batch: 300, loss is 4.128897662162781 and perplexity is 62.10941962150402
At time: 196.7966136932373 and batch: 350, loss is 4.136701474189758 and perplexity is 62.59600600225765
At time: 197.91765356063843 and batch: 400, loss is 4.088963465690613 and perplexity is 59.67800133804
At time: 199.04164838790894 and batch: 450, loss is 4.111897697448731 and perplexity is 61.06248581186899
At time: 200.17325830459595 and batch: 500, loss is 4.121524815559387 and perplexity is 61.653180355788066
At time: 201.35382533073425 and batch: 550, loss is 4.098287982940674 and perplexity is 60.2370723739526
At time: 202.49147939682007 and batch: 600, loss is 4.078443198204041 and perplexity is 59.05346371243954
At time: 203.62944388389587 and batch: 650, loss is 4.131986675262451 and perplexity is 62.3015730617808
At time: 204.7550287246704 and batch: 700, loss is 4.176916513442993 and perplexity is 65.16460891083969
At time: 205.88170719146729 and batch: 750, loss is 4.125320386886597 and perplexity is 61.887634060789246
At time: 207.00436854362488 and batch: 800, loss is 4.124872636795044 and perplexity is 61.85993006966766
At time: 208.13827800750732 and batch: 850, loss is 4.124361152648926 and perplexity is 61.82829778655233
At time: 209.2646565437317 and batch: 900, loss is 4.089001274108886 and perplexity is 59.680257711531
At time: 210.39766240119934 and batch: 950, loss is 4.168680629730225 and perplexity is 64.63012476545425
At time: 211.53193593025208 and batch: 1000, loss is 4.152329730987549 and perplexity is 63.58195673671066
At time: 212.65537428855896 and batch: 1050, loss is 4.103035173416138 and perplexity is 60.52370905134937
At time: 213.78242540359497 and batch: 1100, loss is 4.1352601242065425 and perplexity is 62.505848240109906
At time: 214.9079942703247 and batch: 1150, loss is 4.103737254142761 and perplexity is 60.566216501062605
At time: 216.03888535499573 and batch: 1200, loss is 4.161667075157165 and perplexity is 64.17842372489183
At time: 217.16163873672485 and batch: 1250, loss is 4.170546174049377 and perplexity is 64.7508076622022
At time: 218.28319811820984 and batch: 1300, loss is 4.149346618652344 and perplexity is 63.3925672427881
At time: 219.40754175186157 and batch: 1350, loss is 4.02280867099762 and perplexity is 55.857771815886586
At time: 220.5281205177307 and batch: 1400, loss is 4.054904065132141 and perplexity is 57.679629243117795
At time: 221.66178846359253 and batch: 1450, loss is 4.003227796554565 and perplexity is 54.774666480040885
At time: 222.79346776008606 and batch: 1500, loss is 4.00030475616455 and perplexity is 54.61479169163509
At time: 223.9192225933075 and batch: 1550, loss is 4.027651381492615 and perplexity is 56.128930876168475
At time: 225.04671788215637 and batch: 1600, loss is 4.098011021614075 and perplexity is 60.2203913445841
At time: 226.16841864585876 and batch: 1650, loss is 4.060084114074707 and perplexity is 57.97918773958749
At time: 227.28681302070618 and batch: 1700, loss is 4.06810652256012 and perplexity is 58.44619120892934
At time: 228.41176009178162 and batch: 1750, loss is 4.060057988166809 and perplexity is 57.97767300045568
At time: 229.5334289073944 and batch: 1800, loss is 4.012932486534119 and perplexity is 55.308825367870966
At time: 230.6551170349121 and batch: 1850, loss is 4.058222618103027 and perplexity is 57.87136010665788
At time: 231.77662324905396 and batch: 1900, loss is 4.157581429481507 and perplexity is 63.91674834597106
At time: 232.90265774726868 and batch: 1950, loss is 4.0843913364410405 and perplexity is 59.40576861839395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.423713151798692 and perplexity of 83.405408034328
finished 5 epochs...
Completing Train Step...
At time: 236.5663571357727 and batch: 50, loss is 4.073560733795166 and perplexity is 58.7658400052747
At time: 237.69084548950195 and batch: 100, loss is 4.038032913208008 and perplexity is 56.714670327836146
At time: 238.8159885406494 and batch: 150, loss is 4.00001663684845 and perplexity is 54.599058381847996
At time: 239.93940114974976 and batch: 200, loss is 3.999247794151306 and perplexity is 54.55709642767823
At time: 241.0638279914856 and batch: 250, loss is 3.9933361768722535 and perplexity is 54.23552718737547
At time: 242.19074988365173 and batch: 300, loss is 4.0076662540435795 and perplexity is 55.0183218356576
At time: 243.31653594970703 and batch: 350, loss is 4.015782923698425 and perplexity is 55.466704604738496
At time: 244.4448025226593 and batch: 400, loss is 3.9708222770690917 and perplexity is 53.02811672178206
At time: 245.5721447467804 and batch: 450, loss is 3.997735848426819 and perplexity is 54.47467138579065
At time: 246.7056074142456 and batch: 500, loss is 4.009790596961975 and perplexity is 55.13532385023085
At time: 247.8331480026245 and batch: 550, loss is 3.984911046028137 and perplexity is 53.78050527555295
At time: 248.9574089050293 and batch: 600, loss is 3.965542240142822 and perplexity is 52.74886418797391
At time: 250.08153462409973 and batch: 650, loss is 4.0162495565414424 and perplexity is 55.49259323057279
At time: 251.20635199546814 and batch: 700, loss is 4.065548071861267 and perplexity is 58.29685063189857
At time: 252.32943892478943 and batch: 750, loss is 4.013985781669617 and perplexity is 55.367112576008644
At time: 253.45261216163635 and batch: 800, loss is 4.010750637054444 and perplexity is 55.1882813882507
At time: 254.58202195167542 and batch: 850, loss is 4.0103001260757445 and perplexity is 55.163424061259526
At time: 255.7083420753479 and batch: 900, loss is 3.976098051071167 and perplexity is 53.30862036766004
At time: 256.878915309906 and batch: 950, loss is 4.0606049013137815 and perplexity is 58.00939042459802
At time: 258.007022857666 and batch: 1000, loss is 4.043846364021301 and perplexity is 57.045338504492335
At time: 259.130882024765 and batch: 1050, loss is 3.9974438190460204 and perplexity is 54.458765503842116
At time: 260.25629138946533 and batch: 1100, loss is 4.022204751968384 and perplexity is 55.824048428678864
At time: 261.37757873535156 and batch: 1150, loss is 3.995341248512268 and perplexity is 54.34438239960023
At time: 262.49710869789124 and batch: 1200, loss is 4.053743734359741 and perplexity is 57.612740608341724
At time: 263.616712808609 and batch: 1250, loss is 4.065931015014648 and perplexity is 58.31917928674163
At time: 264.7406871318817 and batch: 1300, loss is 4.042309346199036 and perplexity is 56.95772615065655
At time: 265.8637731075287 and batch: 1350, loss is 3.9166907548904417 and perplexity is 50.233933018734
At time: 266.9880316257477 and batch: 1400, loss is 3.952412633895874 and perplexity is 52.06081913563566
At time: 268.1157383918762 and batch: 1450, loss is 3.9014217853546143 and perplexity is 49.472738740696705
At time: 269.23792266845703 and batch: 1500, loss is 3.8953573369979857 and perplexity is 49.17362177796078
At time: 270.3660774230957 and batch: 1550, loss is 3.923618040084839 and perplexity is 50.58312588206689
At time: 271.49585223197937 and batch: 1600, loss is 3.9987409257888795 and perplexity is 54.529450168652104
At time: 272.63062357902527 and batch: 1650, loss is 3.956512460708618 and perplexity is 52.27469761059181
At time: 273.7617778778076 and batch: 1700, loss is 3.965026340484619 and perplexity is 52.72165808538166
At time: 274.88966250419617 and batch: 1750, loss is 3.95425838470459 and perplexity is 52.15699916953988
At time: 276.01564383506775 and batch: 1800, loss is 3.914266996383667 and perplexity is 50.1123255293775
At time: 277.13814878463745 and batch: 1850, loss is 3.9579517126083372 and perplexity is 52.3499882365266
At time: 278.25927686691284 and batch: 1900, loss is 4.054240283966064 and perplexity is 57.641355295727934
At time: 279.3821280002594 and batch: 1950, loss is 3.983090190887451 and perplexity is 53.682667866959214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.425836891351744 and perplexity of 83.58272762197325
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 283.1927366256714 and batch: 50, loss is 4.011628942489624 and perplexity is 55.23677484866979
At time: 284.3212113380432 and batch: 100, loss is 4.003647384643554 and perplexity is 54.79765410000277
At time: 285.5024402141571 and batch: 150, loss is 3.9794143056869506 and perplexity is 53.48569878228465
At time: 286.64581751823425 and batch: 200, loss is 3.976254963874817 and perplexity is 53.31698582904746
At time: 287.79151129722595 and batch: 250, loss is 3.9646618509292604 and perplexity is 52.702445093348516
At time: 288.9353840351105 and batch: 300, loss is 3.974640645980835 and perplexity is 53.23098470002793
At time: 290.07700181007385 and batch: 350, loss is 3.9701409482955934 and perplexity is 52.99199944532208
At time: 291.22545051574707 and batch: 400, loss is 3.929164128303528 and perplexity is 50.86444374634241
At time: 292.36708188056946 and batch: 450, loss is 3.9439005422592164 and perplexity is 51.61955338407887
At time: 293.51202034950256 and batch: 500, loss is 3.955146799087524 and perplexity is 52.203356787110806
At time: 294.65381598472595 and batch: 550, loss is 3.924531326293945 and perplexity is 50.62934385525473
At time: 295.79609656333923 and batch: 600, loss is 3.90293803691864 and perplexity is 49.54780875632094
At time: 296.93884205818176 and batch: 650, loss is 3.9354939746856687 and perplexity is 51.18742900669171
At time: 298.0793602466583 and batch: 700, loss is 3.989739408493042 and perplexity is 54.04080495346746
At time: 299.2181305885315 and batch: 750, loss is 3.9277663469314574 and perplexity is 50.79339604052062
At time: 300.3497862815857 and batch: 800, loss is 3.9196583890914916 and perplexity is 50.383230376816655
At time: 301.48043298721313 and batch: 850, loss is 3.9181373071670533 and perplexity is 50.30665161184823
At time: 302.603639125824 and batch: 900, loss is 3.878623013496399 and perplexity is 48.35758146805928
At time: 303.7325105667114 and batch: 950, loss is 3.966462769508362 and perplexity is 52.797443422333295
At time: 304.8558931350708 and batch: 1000, loss is 3.928410539627075 and perplexity is 50.82612731672814
At time: 305.9876878261566 and batch: 1050, loss is 3.8748012351989747 and perplexity is 48.17312221838474
At time: 307.11259269714355 and batch: 1100, loss is 3.886512460708618 and perplexity is 48.74060498956805
At time: 308.24171209335327 and batch: 1150, loss is 3.8583383703231813 and perplexity is 47.38654702235047
At time: 309.37755608558655 and batch: 1200, loss is 3.902427306175232 and perplexity is 49.522509628191784
At time: 310.50591111183167 and batch: 1250, loss is 3.908744993209839 and perplexity is 49.83636772989899
At time: 311.6300950050354 and batch: 1300, loss is 3.8838684368133545 and perplexity is 48.611903884681986
At time: 312.76121163368225 and batch: 1350, loss is 3.759216408729553 and perplexity is 42.91478514913818
At time: 313.8954598903656 and batch: 1400, loss is 3.784975318908691 and perplexity is 44.03458372375621
At time: 315.0194137096405 and batch: 1450, loss is 3.724028868675232 and perplexity is 41.430978280984554
At time: 316.143682718277 and batch: 1500, loss is 3.7142962408065796 and perplexity is 41.02970189156543
At time: 317.27126598358154 and batch: 1550, loss is 3.7352040815353393 and perplexity is 41.896575008034226
At time: 318.39842462539673 and batch: 1600, loss is 3.8024417114257814 and perplexity is 44.81046524796381
At time: 319.5219430923462 and batch: 1650, loss is 3.763708162307739 and perplexity is 43.10798135894755
At time: 320.6513798236847 and batch: 1700, loss is 3.754871368408203 and perplexity is 42.728723193360864
At time: 321.7777473926544 and batch: 1750, loss is 3.7254503679275515 and perplexity is 41.489914264437914
At time: 322.9037821292877 and batch: 1800, loss is 3.6809792852401735 and perplexity is 39.685238217758695
At time: 324.0328438282013 and batch: 1850, loss is 3.7105064296722414 and perplexity is 40.874501346632606
At time: 325.1563959121704 and batch: 1900, loss is 3.806398286819458 and perplexity is 44.9881124376449
At time: 326.278217792511 and batch: 1950, loss is 3.731753878593445 and perplexity is 41.75227240147201
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.350368198128634 and perplexity of 77.50699560283627
finished 7 epochs...
Completing Train Step...
At time: 329.9379539489746 and batch: 50, loss is 3.931308178901672 and perplexity is 50.97361668170782
At time: 331.0856103897095 and batch: 100, loss is 3.899465708732605 and perplexity is 49.376060858517874
At time: 332.2229588031769 and batch: 150, loss is 3.8715254211425782 and perplexity is 48.015574217346156
At time: 333.35127687454224 and batch: 200, loss is 3.8665613746643066 and perplexity is 47.77781329163039
At time: 334.47777223587036 and batch: 250, loss is 3.8488408279418946 and perplexity is 46.938621745377255
At time: 335.6124849319458 and batch: 300, loss is 3.859121551513672 and perplexity is 47.423673811264344
At time: 336.73447036743164 and batch: 350, loss is 3.8611058616638183 and perplexity is 47.517870515395124
At time: 337.8584361076355 and batch: 400, loss is 3.8221564197540285 and perplexity is 45.702656245914056
At time: 338.98203778266907 and batch: 450, loss is 3.844457187652588 and perplexity is 46.73331004706352
At time: 340.1042160987854 and batch: 500, loss is 3.8561654329299926 and perplexity is 47.28369081291429
At time: 341.2269079685211 and batch: 550, loss is 3.829918041229248 and perplexity is 46.058763159905425
At time: 342.3754053115845 and batch: 600, loss is 3.8112518072128294 and perplexity is 45.20699390196952
At time: 343.50202798843384 and batch: 650, loss is 3.8461540794372557 and perplexity is 46.81267873794768
At time: 344.6302111148834 and batch: 700, loss is 3.902296257019043 and perplexity is 49.51602017032093
At time: 345.7569034099579 and batch: 750, loss is 3.840751872062683 and perplexity is 46.560468798215226
At time: 346.88155937194824 and batch: 800, loss is 3.83643132686615 and perplexity is 46.35973613792451
At time: 348.01738929748535 and batch: 850, loss is 3.837479853630066 and perplexity is 46.40837105508355
At time: 349.14075469970703 and batch: 900, loss is 3.796879358291626 and perplexity is 44.56190554543375
At time: 350.26505160331726 and batch: 950, loss is 3.8887459230422974 and perplexity is 48.849586953185
At time: 351.3944683074951 and batch: 1000, loss is 3.855108642578125 and perplexity is 47.23374825871523
At time: 352.5176467895508 and batch: 1050, loss is 3.806432857513428 and perplexity is 44.98966773479596
At time: 353.64310812950134 and batch: 1100, loss is 3.819264750480652 and perplexity is 45.57069017221189
At time: 354.76466131210327 and batch: 1150, loss is 3.7938767528533934 and perplexity is 44.42830440164045
At time: 355.88988280296326 and batch: 1200, loss is 3.840120244026184 and perplexity is 46.53106918651666
At time: 357.0171329975128 and batch: 1250, loss is 3.849767942428589 and perplexity is 46.98215940065978
At time: 358.1442036628723 and batch: 1300, loss is 3.825518865585327 and perplexity is 45.856587599777455
At time: 359.27194476127625 and batch: 1350, loss is 3.7026323890686035 and perplexity is 40.55391766420301
At time: 360.39638900756836 and batch: 1400, loss is 3.733654680252075 and perplexity is 41.831710664377404
At time: 361.5181655883789 and batch: 1450, loss is 3.675183448791504 and perplexity is 39.45589432945991
At time: 362.6431887149811 and batch: 1500, loss is 3.666825098991394 and perplexity is 39.127482565137086
At time: 363.7854964733124 and batch: 1550, loss is 3.691435389518738 and perplexity is 40.1023681836953
At time: 364.91782665252686 and batch: 1600, loss is 3.761942772865295 and perplexity is 43.031946119423566
At time: 366.0418562889099 and batch: 1650, loss is 3.7277033281326295 and perplexity is 41.5834947671789
At time: 367.1719388961792 and batch: 1700, loss is 3.722525119781494 and perplexity is 41.368723312878984
At time: 368.30363941192627 and batch: 1750, loss is 3.6972742557525633 and perplexity is 40.33720547175598
At time: 369.46649980545044 and batch: 1800, loss is 3.655786061286926 and perplexity is 38.69792810588486
At time: 370.599986076355 and batch: 1850, loss is 3.6896969079971313 and perplexity is 40.032711523587224
At time: 371.7417342662811 and batch: 1900, loss is 3.7893361186981203 and perplexity is 44.22702902994092
At time: 372.8673241138458 and batch: 1950, loss is 3.7164378690719606 and perplexity is 41.11766642089645
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.354323276253634 and perplexity of 77.81414883279938
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 376.589551448822 and batch: 50, loss is 3.904088225364685 and perplexity is 49.604830860275506
At time: 377.7675278186798 and batch: 100, loss is 3.902835569381714 and perplexity is 49.5427319745047
At time: 378.91821455955505 and batch: 150, loss is 3.8905680990219116 and perplexity is 48.938680644685796
At time: 380.05726313591003 and batch: 200, loss is 3.8946074724197386 and perplexity is 49.13676204243756
At time: 381.19082832336426 and batch: 250, loss is 3.887100477218628 and perplexity is 48.769273698020676
At time: 382.32426285743713 and batch: 300, loss is 3.8826355075836183 and perplexity is 48.55200578011907
At time: 383.4513187408447 and batch: 350, loss is 3.8877752590179444 and perplexity is 48.80219342184411
At time: 384.576012134552 and batch: 400, loss is 3.8568660736083986 and perplexity is 47.316831298553446
At time: 385.6982684135437 and batch: 450, loss is 3.8755931997299196 and perplexity is 48.21128873379495
At time: 386.81949830055237 and batch: 500, loss is 3.8737223148345947 and perplexity is 48.121175284149324
At time: 387.94169640541077 and batch: 550, loss is 3.848885097503662 and perplexity is 46.94069974358759
At time: 389.06057572364807 and batch: 600, loss is 3.820018086433411 and perplexity is 45.60503314578483
At time: 390.1824383735657 and batch: 650, loss is 3.859581251144409 and perplexity is 47.4454794682458
At time: 391.31371426582336 and batch: 700, loss is 3.911815323829651 and perplexity is 49.98961699829176
At time: 392.43931555747986 and batch: 750, loss is 3.845517859458923 and perplexity is 46.78290504880757
At time: 393.56900668144226 and batch: 800, loss is 3.8368032646179198 and perplexity is 46.376982281003315
At time: 394.6928782463074 and batch: 850, loss is 3.8407807636260984 and perplexity is 46.56181402238488
At time: 395.8110978603363 and batch: 900, loss is 3.7985966205596924 and perplexity is 44.638495768348044
At time: 396.93197679519653 and batch: 950, loss is 3.893485813140869 and perplexity is 49.08167823576565
At time: 398.05455112457275 and batch: 1000, loss is 3.8571983671188352 and perplexity is 47.33255698715581
At time: 399.21857929229736 and batch: 1050, loss is 3.8018712329864504 and perplexity is 44.78490913398256
At time: 400.33916664123535 and batch: 1100, loss is 3.809573998451233 and perplexity is 45.13120880574277
At time: 401.46341347694397 and batch: 1150, loss is 3.78230402469635 and perplexity is 43.91711136658106
At time: 402.58770728111267 and batch: 1200, loss is 3.8156087493896482 and perplexity is 45.404387865170264
At time: 403.7131118774414 and batch: 1250, loss is 3.816702251434326 and perplexity is 45.45406481210961
At time: 404.8384518623352 and batch: 1300, loss is 3.7971180963516233 and perplexity is 44.57254543833662
At time: 405.96367955207825 and batch: 1350, loss is 3.675069069862366 and perplexity is 39.45138166460012
At time: 407.0876908302307 and batch: 1400, loss is 3.7029528522491457 and perplexity is 40.566915784239335
At time: 408.21652030944824 and batch: 1450, loss is 3.6354185962677 and perplexity is 37.917721792402254
At time: 409.3383936882019 and batch: 1500, loss is 3.6345622444152834 and perplexity is 37.88526478040058
At time: 410.46437788009644 and batch: 1550, loss is 3.6590353298187255 and perplexity is 38.82387256880776
At time: 411.5901825428009 and batch: 1600, loss is 3.7234901857376097 and perplexity is 41.408666130022645
At time: 412.7132351398468 and batch: 1650, loss is 3.684875946044922 and perplexity is 39.84017981141418
At time: 413.8423264026642 and batch: 1700, loss is 3.671723575592041 and perplexity is 39.319617823767445
At time: 414.9654052257538 and batch: 1750, loss is 3.6441538333892822 and perplexity is 38.250392948733605
At time: 416.0991253852844 and batch: 1800, loss is 3.596894416809082 and perplexity is 36.48475188793947
At time: 417.23116087913513 and batch: 1850, loss is 3.6256742429733277 and perplexity is 37.550032471871596
At time: 418.3677294254303 and batch: 1900, loss is 3.726644206047058 and perplexity is 41.5394760841702
At time: 419.49624037742615 and batch: 1950, loss is 3.6587389135360717 and perplexity is 38.812366246237616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.329986430323401 and perplexity of 75.94325603677103
finished 9 epochs...
Completing Train Step...
At time: 423.22304797172546 and batch: 50, loss is 3.897680764198303 and perplexity is 49.28800593851598
At time: 424.37408089637756 and batch: 100, loss is 3.8767624711990356 and perplexity is 48.26769378818471
At time: 425.4981276988983 and batch: 150, loss is 3.849750666618347 and perplexity is 46.98134775280018
At time: 426.66685676574707 and batch: 200, loss is 3.84659610748291 and perplexity is 46.83337582885238
At time: 427.7897148132324 and batch: 250, loss is 3.8378039407730102 and perplexity is 46.42341384892387
At time: 428.92276549339294 and batch: 300, loss is 3.8315655755996705 and perplexity is 46.13470909986492
At time: 430.0547549724579 and batch: 350, loss is 3.8390101480484007 and perplexity is 46.479443893587316
At time: 431.18077301979065 and batch: 400, loss is 3.8056790113449095 and perplexity is 44.95576522639472
At time: 432.317031621933 and batch: 450, loss is 3.8286936283111572 and perplexity is 46.00240272656371
At time: 433.45713353157043 and batch: 500, loss is 3.828678069114685 and perplexity is 46.001686971709795
At time: 434.5822162628174 and batch: 550, loss is 3.8039029598236085 and perplexity is 44.87599233252725
At time: 435.70587730407715 and batch: 600, loss is 3.7789528703689577 and perplexity is 43.77018467329213
At time: 436.8304080963135 and batch: 650, loss is 3.819835000038147 and perplexity is 45.59668424896832
At time: 437.9501187801361 and batch: 700, loss is 3.8728850364685057 and perplexity is 48.08090132774212
At time: 439.0707845687866 and batch: 750, loss is 3.8076677942276 and perplexity is 45.04526144753318
At time: 440.1939287185669 and batch: 800, loss is 3.799761724472046 and perplexity is 44.69053456382469
At time: 441.3235366344452 and batch: 850, loss is 3.8045106983184813 and perplexity is 44.90327348962833
At time: 442.45971298217773 and batch: 900, loss is 3.7628551959991454 and perplexity is 43.07122738039795
At time: 443.58628129959106 and batch: 950, loss is 3.860526065826416 and perplexity is 47.49032783720473
At time: 444.7114689350128 and batch: 1000, loss is 3.8261576986312864 and perplexity is 45.88589166251635
At time: 445.83238792419434 and batch: 1050, loss is 3.773537588119507 and perplexity is 43.53379739875824
At time: 446.9615800380707 and batch: 1100, loss is 3.7831129455566406 and perplexity is 43.952651206610206
At time: 448.09107208251953 and batch: 1150, loss is 3.7575213289260865 and perplexity is 42.842102782171075
At time: 449.2207987308502 and batch: 1200, loss is 3.792586073875427 and perplexity is 44.37099871270181
At time: 450.34259271621704 and batch: 1250, loss is 3.79655734539032 and perplexity is 44.54755834705681
At time: 451.4650602340698 and batch: 1300, loss is 3.778022789955139 and perplexity is 43.72949380764016
At time: 452.59741973876953 and batch: 1350, loss is 3.6572139930725096 and perplexity is 38.75322557857702
At time: 453.7254674434662 and batch: 1400, loss is 3.687685809135437 and perplexity is 39.95228268529216
At time: 454.85584926605225 and batch: 1450, loss is 3.622027440071106 and perplexity is 37.41334429338425
At time: 455.9812822341919 and batch: 1500, loss is 3.62237416267395 and perplexity is 37.42631859461053
At time: 457.1090431213379 and batch: 1550, loss is 3.6477316761016847 and perplexity is 38.38749195147582
At time: 458.2305293083191 and batch: 1600, loss is 3.7156183671951295 and perplexity is 41.08398421929236
At time: 459.350138425827 and batch: 1650, loss is 3.6785969352722168 and perplexity is 39.59080662098097
At time: 460.4689221382141 and batch: 1700, loss is 3.6684352684020998 and perplexity is 39.19053518976235
At time: 461.59232449531555 and batch: 1750, loss is 3.6434424543380737 and perplexity is 38.223192096694646
At time: 462.71523547172546 and batch: 1800, loss is 3.5979113817214965 and perplexity is 36.52187447343169
At time: 463.8374111652374 and batch: 1850, loss is 3.6279796600341796 and perplexity is 37.63670082232821
At time: 464.95940589904785 and batch: 1900, loss is 3.7302266788482665 and perplexity is 41.68855700715067
At time: 466.0784652233124 and batch: 1950, loss is 3.661871285438538 and perplexity is 38.934131619391366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.329466354015262 and perplexity of 75.90377001730499
finished 10 epochs...
Completing Train Step...
At time: 469.756737947464 and batch: 50, loss is 3.8783423566818236 and perplexity is 48.3440114876267
At time: 470.88384532928467 and batch: 100, loss is 3.8564396905899048 and perplexity is 47.29666050574615
At time: 472.0090260505676 and batch: 150, loss is 3.8275847959518434 and perplexity is 45.95142204355326
At time: 473.1393644809723 and batch: 200, loss is 3.8234005069732664 and perplexity is 45.759549719318294
At time: 474.263245344162 and batch: 250, loss is 3.814594793319702 and perplexity is 45.358373142888
At time: 475.3867063522339 and batch: 300, loss is 3.807339239120483 and perplexity is 45.0304640278502
At time: 476.50848865509033 and batch: 350, loss is 3.8156616163253783 and perplexity is 45.406788319477165
At time: 477.63846039772034 and batch: 400, loss is 3.7818337202072145 and perplexity is 43.896461808126126
At time: 478.76763105392456 and batch: 450, loss is 3.806358094215393 and perplexity is 44.9863042845915
At time: 479.89563846588135 and batch: 500, loss is 3.8066621255874633 and perplexity is 44.99998361177445
At time: 481.0263886451721 and batch: 550, loss is 3.7817226362228396 and perplexity is 43.89158588507201
At time: 482.1576852798462 and batch: 600, loss is 3.7580762195587156 and perplexity is 42.8658820605263
At time: 483.31413221359253 and batch: 650, loss is 3.7995828771591187 and perplexity is 44.682542496505846
At time: 484.4390273094177 and batch: 700, loss is 3.852823257446289 and perplexity is 47.12592420939375
At time: 485.5658805370331 and batch: 750, loss is 3.787828130722046 and perplexity is 44.16038546342388
At time: 486.68754410743713 and batch: 800, loss is 3.779931697845459 and perplexity is 43.813049107722605
At time: 487.8078410625458 and batch: 850, loss is 3.7852464628219606 and perplexity is 44.046525051942325
At time: 488.9342715740204 and batch: 900, loss is 3.743382592201233 and perplexity is 42.24063161113047
At time: 490.05595326423645 and batch: 950, loss is 3.842770619392395 and perplexity is 46.654557559035446
At time: 491.1829569339752 and batch: 1000, loss is 3.808862738609314 and perplexity is 45.09912020232226
At time: 492.30872416496277 and batch: 1050, loss is 3.7574773740768435 and perplexity is 42.84021970538752
At time: 493.443186044693 and batch: 1100, loss is 3.767979693412781 and perplexity is 43.292512276395875
At time: 494.5728621482849 and batch: 1150, loss is 3.7428181028366088 and perplexity is 42.21679395251635
At time: 495.70307064056396 and batch: 1200, loss is 3.778426699638367 and perplexity is 43.747160141193135
At time: 496.8306927680969 and batch: 1250, loss is 3.7836210346221923 and perplexity is 43.974988742338574
At time: 497.95686411857605 and batch: 1300, loss is 3.765378499031067 and perplexity is 43.18004637294433
At time: 499.07884883880615 and batch: 1350, loss is 3.645121483802795 and perplexity is 38.287423870891566
At time: 500.20488595962524 and batch: 1400, loss is 3.6766666269302366 and perplexity is 39.514457868718324
At time: 501.33107113838196 and batch: 1450, loss is 3.6115708446502683 and perplexity is 37.02416637286423
At time: 502.4549095630646 and batch: 1500, loss is 3.6120235252380373 and perplexity is 37.04093028832283
At time: 503.5770890712738 and batch: 1550, loss is 3.6379268169403076 and perplexity is 38.01294717927883
At time: 504.6999716758728 and batch: 1600, loss is 3.707241110801697 and perplexity is 40.74125073732245
At time: 505.8274505138397 and batch: 1650, loss is 3.6705262804031373 and perplexity is 39.27256880591932
At time: 506.9450948238373 and batch: 1700, loss is 3.661673059463501 and perplexity is 38.92641462806824
At time: 508.0606439113617 and batch: 1750, loss is 3.6378182411193847 and perplexity is 38.008820116386815
At time: 509.1779475212097 and batch: 1800, loss is 3.592875485420227 and perplexity is 36.33841642641739
At time: 510.2951090335846 and batch: 1850, loss is 3.6235221815109253 and perplexity is 37.469309385753164
At time: 511.41282176971436 and batch: 1900, loss is 3.726576080322266 and perplexity is 41.536646273647015
At time: 512.5309591293335 and batch: 1950, loss is 3.657763843536377 and perplexity is 38.77453991695017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.330839786973111 and perplexity of 76.00809037878463
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 516.1747980117798 and batch: 50, loss is 3.8744740962982176 and perplexity is 48.15736549359552
At time: 517.2970952987671 and batch: 100, loss is 3.871334776878357 and perplexity is 48.00642119604155
At time: 518.4144713878632 and batch: 150, loss is 3.852539577484131 and perplexity is 47.11255742503145
At time: 519.530513048172 and batch: 200, loss is 3.852752141952515 and perplexity is 47.12257294518885
At time: 520.6485645771027 and batch: 250, loss is 3.8557339906692505 and perplexity is 47.263295030571335
At time: 521.7639842033386 and batch: 300, loss is 3.8453870534896852 and perplexity is 46.776785965783915
At time: 522.8791463375092 and batch: 350, loss is 3.8534077835083007 and perplexity is 47.15347859263355
At time: 523.9987626075745 and batch: 400, loss is 3.8205949592590334 and perplexity is 45.63134903985055
At time: 525.1222116947174 and batch: 450, loss is 3.8575905895233156 and perplexity is 47.351125517726324
At time: 526.2436814308167 and batch: 500, loss is 3.859231491088867 and perplexity is 47.42888783642594
At time: 527.3693180084229 and batch: 550, loss is 3.8347945833206176 and perplexity is 46.2839192023938
At time: 528.4956912994385 and batch: 600, loss is 3.7939859867095946 and perplexity is 44.43315774172442
At time: 529.6120111942291 and batch: 650, loss is 3.8248838233947753 and perplexity is 45.82747597646972
At time: 530.7301826477051 and batch: 700, loss is 3.875386662483215 and perplexity is 48.201332335178776
At time: 531.8509969711304 and batch: 750, loss is 3.8102886199951174 and perplexity is 45.16347206649447
At time: 532.9709467887878 and batch: 800, loss is 3.802051181793213 and perplexity is 44.79296885008859
At time: 534.0930798053741 and batch: 850, loss is 3.8100329875946044 and perplexity is 45.15192829525846
At time: 535.2180736064911 and batch: 900, loss is 3.7640502309799193 and perplexity is 43.122729771232464
At time: 536.3393876552582 and batch: 950, loss is 3.86244243144989 and perplexity is 47.58142392774877
At time: 537.4622168540955 and batch: 1000, loss is 3.82597177028656 and perplexity is 45.87736096770679
At time: 538.6100754737854 and batch: 1050, loss is 3.7734278583526613 and perplexity is 43.529020707397166
At time: 539.7303402423859 and batch: 1100, loss is 3.7809028100967406 and perplexity is 43.855617162311425
At time: 540.8452279567719 and batch: 1150, loss is 3.759511122703552 and perplexity is 42.927434599906185
At time: 541.961389541626 and batch: 1200, loss is 3.7933855724334715 and perplexity is 44.40648744689716
At time: 543.0758862495422 and batch: 1250, loss is 3.7893469524383545 and perplexity is 44.22750817668024
At time: 544.190687417984 and batch: 1300, loss is 3.7652107954025267 and perplexity is 43.17280552966187
At time: 545.3066596984863 and batch: 1350, loss is 3.6442640829086304 and perplexity is 38.25461026864556
At time: 546.4245884418488 and batch: 1400, loss is 3.67578978061676 and perplexity is 39.479824948100486
At time: 547.5397660732269 and batch: 1450, loss is 3.6007938241958617 and perplexity is 36.62729854207122
At time: 548.6576406955719 and batch: 1500, loss is 3.604529390335083 and perplexity is 36.76437811377349
At time: 549.7796545028687 and batch: 1550, loss is 3.6358786725997927 and perplexity is 37.93517085240778
At time: 550.8989627361298 and batch: 1600, loss is 3.7041546583175657 and perplexity is 40.61569865771102
At time: 552.0180659294128 and batch: 1650, loss is 3.665712809562683 and perplexity is 39.083985674957866
At time: 553.1420543193817 and batch: 1700, loss is 3.6489741897583006 and perplexity is 38.43521857882171
At time: 554.2587292194366 and batch: 1750, loss is 3.624545850753784 and perplexity is 37.50768520404379
At time: 555.3756773471832 and batch: 1800, loss is 3.58088011264801 and perplexity is 35.90512750195949
At time: 556.4923074245453 and batch: 1850, loss is 3.605117530822754 and perplexity is 36.786007092861944
At time: 557.608912229538 and batch: 1900, loss is 3.713513331413269 and perplexity is 40.99759192378763
At time: 558.7242813110352 and batch: 1950, loss is 3.647334265708923 and perplexity is 38.37223939418539
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.316318813590116 and perplexity of 74.91235375639567
finished 12 epochs...
Completing Train Step...
At time: 562.3783168792725 and batch: 50, loss is 3.878677291870117 and perplexity is 48.36020631017375
At time: 563.4964230060577 and batch: 100, loss is 3.8639414739608764 and perplexity is 47.652803992458765
At time: 564.6091151237488 and batch: 150, loss is 3.8353543138504027 and perplexity is 46.30983297669823
At time: 565.7222065925598 and batch: 200, loss is 3.828955898284912 and perplexity is 46.01446935780782
At time: 566.8602409362793 and batch: 250, loss is 3.826262640953064 and perplexity is 45.89070728720124
At time: 567.9759941101074 and batch: 300, loss is 3.818593692779541 and perplexity is 45.54011986799313
At time: 569.0904350280762 and batch: 350, loss is 3.8283797979354857 and perplexity is 45.987968040374206
At time: 570.2038707733154 and batch: 400, loss is 3.7957985639572143 and perplexity is 44.51376930776187
At time: 571.3182163238525 and batch: 450, loss is 3.8337002086639402 and perplexity is 46.23329496020337
At time: 572.4338066577911 and batch: 500, loss is 3.8356652736663817 and perplexity is 46.32423571305875
At time: 573.5502769947052 and batch: 550, loss is 3.809977021217346 and perplexity is 45.14940137611745
At time: 574.666264295578 and batch: 600, loss is 3.7731815814971923 and perplexity is 43.51830183701473
At time: 575.7823400497437 and batch: 650, loss is 3.8059365940093994 and perplexity is 44.967346543695164
At time: 576.8980112075806 and batch: 700, loss is 3.8585233449935914 and perplexity is 47.39531314399804
At time: 578.0122611522675 and batch: 750, loss is 3.796061091423035 and perplexity is 44.52545692890601
At time: 579.1304085254669 and batch: 800, loss is 3.787495436668396 and perplexity is 44.1456960094558
At time: 580.2448742389679 and batch: 850, loss is 3.7947066020965576 and perplexity is 44.465188498426436
At time: 581.3602221012115 and batch: 900, loss is 3.750206880569458 and perplexity is 42.5298796957257
At time: 582.4754672050476 and batch: 950, loss is 3.8487846660614013 and perplexity is 46.93598565813677
At time: 583.5916073322296 and batch: 1000, loss is 3.812511820793152 and perplexity is 45.263991229373936
At time: 584.7068362236023 and batch: 1050, loss is 3.761085410118103 and perplexity is 42.995067943127864
At time: 585.8189964294434 and batch: 1100, loss is 3.7701478099822996 and perplexity is 43.3864773163698
At time: 586.934775352478 and batch: 1150, loss is 3.7500971364974975 and perplexity is 42.52521254964839
At time: 588.0535461902618 and batch: 1200, loss is 3.7854525899887084 and perplexity is 44.05560517315405
At time: 589.1719229221344 and batch: 1250, loss is 3.7824285984039308 and perplexity is 43.92258262475061
At time: 590.2876026630402 and batch: 1300, loss is 3.7596053075790405 and perplexity is 42.93147790539514
At time: 591.4008362293243 and batch: 1350, loss is 3.639722728729248 and perplexity is 38.08127641752753
At time: 592.5138828754425 and batch: 1400, loss is 3.672751536369324 and perplexity is 39.36005763037447
At time: 593.6302967071533 and batch: 1450, loss is 3.599143943786621 and perplexity is 36.566917704041046
At time: 594.746649980545 and batch: 1500, loss is 3.6043322467803955 and perplexity is 36.75713096797379
At time: 595.8625745773315 and batch: 1550, loss is 3.635963339805603 and perplexity is 37.938382853299444
At time: 596.9788467884064 and batch: 1600, loss is 3.7049249982833863 and perplexity is 40.646998607880214
At time: 598.0948498249054 and batch: 1650, loss is 3.6674867725372313 and perplexity is 39.15338075239347
At time: 599.2072365283966 and batch: 1700, loss is 3.652236571311951 and perplexity is 38.560813685109
At time: 600.3230407238007 and batch: 1750, loss is 3.6289318895339964 and perplexity is 37.67255666791463
At time: 601.4390106201172 and batch: 1800, loss is 3.585622763633728 and perplexity is 36.07581743174065
At time: 602.5555312633514 and batch: 1850, loss is 3.609902648925781 and perplexity is 36.96245430503359
At time: 603.6709704399109 and batch: 1900, loss is 3.7183896827697756 and perplexity is 41.19799881687166
At time: 604.7864599227905 and batch: 1950, loss is 3.6513065195083616 and perplexity is 38.52496680310587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.314967239734738 and perplexity of 74.81117256993957
finished 13 epochs...
Completing Train Step...
At time: 608.3887937068939 and batch: 50, loss is 3.8730517292022704 and perplexity is 48.08891673266263
At time: 609.5268354415894 and batch: 100, loss is 3.857192301750183 and perplexity is 47.33226989861908
At time: 610.6424036026001 and batch: 150, loss is 3.8273312044143677 and perplexity is 45.93977062920052
At time: 611.7603344917297 and batch: 200, loss is 3.819765863418579 and perplexity is 45.59353195732649
At time: 612.8732008934021 and batch: 250, loss is 3.8161159992218017 and perplexity is 45.4274250756105
At time: 613.9885053634644 and batch: 300, loss is 3.808667769432068 and perplexity is 45.09032812108217
At time: 615.1025168895721 and batch: 350, loss is 3.8189310884475707 and perplexity is 45.555487499498504
At time: 616.2197012901306 and batch: 400, loss is 3.785970516204834 and perplexity is 44.07842863596517
At time: 617.3337914943695 and batch: 450, loss is 3.824230604171753 and perplexity is 45.797550363276294
At time: 618.4513125419617 and batch: 500, loss is 3.8258847045898436 and perplexity is 45.873366797190776
At time: 619.570075750351 and batch: 550, loss is 3.7998474073410033 and perplexity is 44.69436394109502
At time: 620.6800026893616 and batch: 600, loss is 3.764312562942505 and perplexity is 43.13404372550643
At time: 621.7909114360809 and batch: 650, loss is 3.7973832988739016 and perplexity is 44.58436775739635
At time: 622.9295268058777 and batch: 700, loss is 3.850432906150818 and perplexity is 47.01341122176528
At time: 624.0475707054138 and batch: 750, loss is 3.788695240020752 and perplexity is 44.198693950716155
At time: 625.1658308506012 and batch: 800, loss is 3.7802826881408693 and perplexity is 43.82842976184401
At time: 626.2784533500671 and batch: 850, loss is 3.7871954917907713 and perplexity is 44.13245671969642
At time: 627.3977010250092 and batch: 900, loss is 3.7428275299072267 and perplexity is 42.2171919350901
At time: 628.5102980136871 and batch: 950, loss is 3.8421022367477415 and perplexity is 46.6233848812679
At time: 629.6248044967651 and batch: 1000, loss is 3.8059803009033204 and perplexity is 44.96931196969148
At time: 630.738392829895 and batch: 1050, loss is 3.7549694681167605 and perplexity is 42.732915074260944
At time: 631.8507752418518 and batch: 1100, loss is 3.764566125869751 and perplexity is 43.144982306648146
At time: 632.9679038524628 and batch: 1150, loss is 3.745050320625305 and perplexity is 42.31113628810469
At time: 634.08935379982 and batch: 1200, loss is 3.7810954952239992 and perplexity is 43.864068301663636
At time: 635.2207534313202 and batch: 1250, loss is 3.778487582206726 and perplexity is 43.74982366174112
At time: 636.3457236289978 and batch: 1300, loss is 3.7563958263397215 and perplexity is 42.79391100975395
At time: 637.4742436408997 and batch: 1350, loss is 3.6368055534362793 and perplexity is 37.970348535541454
At time: 638.6005046367645 and batch: 1400, loss is 3.670597276687622 and perplexity is 39.2753571113652
At time: 639.7242004871368 and batch: 1450, loss is 3.5974860429763793 and perplexity is 36.50634360834731
At time: 640.8447694778442 and batch: 1500, loss is 3.6030494737625123 and perplexity is 36.71001014127727
At time: 641.962601184845 and batch: 1550, loss is 3.634788465499878 and perplexity is 37.89383619557022
At time: 643.0833563804626 and batch: 1600, loss is 3.704215021133423 and perplexity is 40.618150409646596
At time: 644.2018268108368 and batch: 1650, loss is 3.6670734071731568 and perplexity is 39.137199445530314
At time: 645.3186197280884 and batch: 1700, loss is 3.652307753562927 and perplexity is 38.56355862832103
At time: 646.436005115509 and batch: 1750, loss is 3.629544749259949 and perplexity is 37.69565173696603
At time: 647.5547659397125 and batch: 1800, loss is 3.586271424293518 and perplexity is 36.09922598656191
At time: 648.6708562374115 and batch: 1850, loss is 3.610552635192871 and perplexity is 36.9864872024103
At time: 649.7880370616913 and batch: 1900, loss is 3.7191907453536985 and perplexity is 41.2310142141906
At time: 650.906170129776 and batch: 1950, loss is 3.651634860038757 and perplexity is 38.53761818800703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3148196198219475 and perplexity of 74.80012976625795
finished 14 epochs...
Completing Train Step...
At time: 654.5470478534698 and batch: 50, loss is 3.8674834632873534 and perplexity is 47.82188898742654
At time: 655.6905057430267 and batch: 100, loss is 3.85123646736145 and perplexity is 47.05120455799847
At time: 656.8072950839996 and batch: 150, loss is 3.8208499574661254 and perplexity is 45.642986435737384
At time: 657.9266765117645 and batch: 200, loss is 3.812876262664795 and perplexity is 45.28049032935443
At time: 659.0465636253357 and batch: 250, loss is 3.808966999053955 and perplexity is 45.10382250177513
At time: 660.1647427082062 and batch: 300, loss is 3.801477355957031 and perplexity is 44.767272860499574
At time: 661.2832527160645 and batch: 350, loss is 3.8119381189346315 and perplexity is 45.23803064101253
At time: 662.403222322464 and batch: 400, loss is 3.7787855195999147 and perplexity is 43.762860312111734
At time: 663.5260162353516 and batch: 450, loss is 3.8173062419891357 and perplexity is 45.48152693052904
At time: 664.651093006134 and batch: 500, loss is 3.8187582874298096 and perplexity is 45.54761614500261
At time: 665.775931596756 and batch: 550, loss is 3.7925061798095703 and perplexity is 44.36745387481617
At time: 666.900895357132 and batch: 600, loss is 3.757763533592224 and perplexity is 42.85248059609881
At time: 668.0203239917755 and batch: 650, loss is 3.791083645820618 and perplexity is 44.30438453345245
At time: 669.14098072052 and batch: 700, loss is 3.844354019165039 and perplexity is 46.72848889084778
At time: 670.2556290626526 and batch: 750, loss is 3.7830208206176756 and perplexity is 43.94860225780789
At time: 671.373105764389 and batch: 800, loss is 3.7747389554977415 and perplexity is 43.58612891119562
At time: 672.4923787117004 and batch: 850, loss is 3.7815347146987914 and perplexity is 43.88333848631574
At time: 673.6114492416382 and batch: 900, loss is 3.7372385168075564 and perplexity is 41.98189764027325
At time: 674.729681968689 and batch: 950, loss is 3.837046990394592 and perplexity is 46.388286924590034
At time: 675.846043586731 and batch: 1000, loss is 3.8010272645950316 and perplexity is 44.747128031531616
At time: 676.961873292923 and batch: 1050, loss is 3.750303645133972 and perplexity is 42.53399528013144
At time: 678.0794475078583 and batch: 1100, loss is 3.7602197980880736 and perplexity is 42.95786699819993
At time: 679.2401280403137 and batch: 1150, loss is 3.740974998474121 and perplexity is 42.139055657314366
At time: 680.3614797592163 and batch: 1200, loss is 3.777475175857544 and perplexity is 43.70555347598023
At time: 681.4906117916107 and batch: 1250, loss is 3.775141839981079 and perplexity is 43.60369262405881
At time: 682.6193571090698 and batch: 1300, loss is 3.7535339546203614 and perplexity is 42.67161540670809
At time: 683.7459983825684 and batch: 1350, loss is 3.6340371274948122 and perplexity is 37.86537580930251
At time: 684.8793823719025 and batch: 1400, loss is 3.6682950258255005 and perplexity is 39.18503939351036
At time: 686.0076515674591 and batch: 1450, loss is 3.5954521799087527 and perplexity is 36.43217015923639
At time: 687.1331584453583 and batch: 1500, loss is 3.601155548095703 and perplexity is 36.64054990786388
At time: 688.2637786865234 and batch: 1550, loss is 3.6328857851028444 and perplexity is 37.821804884285086
At time: 689.3960502147675 and batch: 1600, loss is 3.7026748275756836 and perplexity is 40.55563874844479
At time: 690.5202269554138 and batch: 1650, loss is 3.6656430530548096 and perplexity is 39.081259407691945
At time: 691.6511161327362 and batch: 1700, loss is 3.6511546754837036 and perplexity is 38.519117461201716
At time: 692.7767961025238 and batch: 1750, loss is 3.6287800741195677 and perplexity is 37.66683782722657
At time: 693.9023995399475 and batch: 1800, loss is 3.5855082750320433 and perplexity is 36.07168739827364
At time: 695.0289013385773 and batch: 1850, loss is 3.60986234664917 and perplexity is 36.960964663994126
At time: 696.1568894386292 and batch: 1900, loss is 3.718723330497742 and perplexity is 41.211746728925945
At time: 697.2808573246002 and batch: 1950, loss is 3.650906867980957 and perplexity is 38.5095733174997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.315087606740552 and perplexity of 74.82017790874522
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 700.9312727451324 and batch: 50, loss is 3.8673470306396482 and perplexity is 47.81536496554863
At time: 702.0809373855591 and batch: 100, loss is 3.85926118850708 and perplexity is 47.430296372858244
At time: 703.2022795677185 and batch: 150, loss is 3.8323867321014404 and perplexity is 46.17260847472896
At time: 704.3193337917328 and batch: 200, loss is 3.826936445236206 and perplexity is 45.921639062138716
At time: 705.4374759197235 and batch: 250, loss is 3.8280538272857667 and perplexity is 45.97297975555602
At time: 706.5922362804413 and batch: 300, loss is 3.8223200178146364 and perplexity is 45.71013372347425
At time: 707.723237991333 and batch: 350, loss is 3.8338431406021116 and perplexity is 46.239903646945024
At time: 708.849550485611 and batch: 400, loss is 3.8044533252716066 and perplexity is 44.90069732591547
At time: 709.9693493843079 and batch: 450, loss is 3.851395649909973 and perplexity is 47.05869488479993
At time: 711.0884673595428 and batch: 500, loss is 3.858834490776062 and perplexity is 47.41006229024
At time: 712.2087249755859 and batch: 550, loss is 3.845291028022766 and perplexity is 46.772294418725465
At time: 713.3316805362701 and batch: 600, loss is 3.7990699911117556 and perplexity is 44.65963131981234
At time: 714.4575996398926 and batch: 650, loss is 3.8192477321624754 and perplexity is 45.56991464230614
At time: 715.5849163532257 and batch: 700, loss is 3.8654968452453615 and perplexity is 47.7269794656607
At time: 716.7089381217957 and batch: 750, loss is 3.799671421051025 and perplexity is 44.68649903787996
At time: 717.8323407173157 and batch: 800, loss is 3.7903230953216553 and perplexity is 44.27070162209044
At time: 718.9618144035339 and batch: 850, loss is 3.7951332569122314 and perplexity is 44.4841638329002
At time: 720.0922408103943 and batch: 900, loss is 3.74488160610199 and perplexity is 42.30399838706564
At time: 721.2140066623688 and batch: 950, loss is 3.849978370666504 and perplexity is 46.9920468139349
At time: 722.3353087902069 and batch: 1000, loss is 3.810140972137451 and perplexity is 45.156804268854216
At time: 723.4561853408813 and batch: 1050, loss is 3.762789568901062 and perplexity is 43.068400833484134
At time: 724.5764439105988 and batch: 1100, loss is 3.7689030075073244 and perplexity is 43.332503322476065
At time: 725.7051520347595 and batch: 1150, loss is 3.7506468677520752 and perplexity is 42.54859641492639
At time: 726.8257787227631 and batch: 1200, loss is 3.7880892086029054 and perplexity is 44.171916268432184
At time: 727.947548866272 and batch: 1250, loss is 3.783850111961365 and perplexity is 43.98506356966307
At time: 729.0759544372559 and batch: 1300, loss is 3.7585044002532957 and perplexity is 42.884240333729366
At time: 730.2003736495972 and batch: 1350, loss is 3.6336719942092897 and perplexity is 37.85155242406833
At time: 731.3306531906128 and batch: 1400, loss is 3.6684982633590697 and perplexity is 39.193004073603056
At time: 732.4531457424164 and batch: 1450, loss is 3.5897749519348143 and perplexity is 36.22592243529354
At time: 733.5712463855743 and batch: 1500, loss is 3.5940809535980223 and perplexity is 36.38224764431231
At time: 734.6904256343842 and batch: 1550, loss is 3.6292731285095217 and perplexity is 37.68541420617923
At time: 735.8070080280304 and batch: 1600, loss is 3.700944838523865 and perplexity is 40.48553859115613
At time: 736.920964717865 and batch: 1650, loss is 3.6639802074432373 and perplexity is 39.01632730798141
At time: 738.0363593101501 and batch: 1700, loss is 3.648198652267456 and perplexity is 38.40542218145009
At time: 739.1499881744385 and batch: 1750, loss is 3.6278259706497193 and perplexity is 37.630916905420406
At time: 740.2635846138 and batch: 1800, loss is 3.583359980583191 and perplexity is 35.99427797136771
At time: 741.3808128833771 and batch: 1850, loss is 3.6100424623489378 and perplexity is 36.96762251358229
At time: 742.4970741271973 and batch: 1900, loss is 3.719999132156372 and perplexity is 41.26435829758485
At time: 743.6159501075745 and batch: 1950, loss is 3.6514883613586426 and perplexity is 38.53197289133208
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.308074241460756 and perplexity of 74.29727247752659
finished 16 epochs...
Completing Train Step...
At time: 747.2933011054993 and batch: 50, loss is 3.8734681606292725 and perplexity is 48.10894663913241
At time: 748.4113621711731 and batch: 100, loss is 3.855393853187561 and perplexity is 47.24722174614149
At time: 749.5339059829712 and batch: 150, loss is 3.82591733455658 and perplexity is 45.87486366804474
At time: 750.651969909668 and batch: 200, loss is 3.818570442199707 and perplexity is 45.53906104610964
At time: 751.7711789608002 and batch: 250, loss is 3.8169459962844847 and perplexity is 45.46514535668432
At time: 752.8884763717651 and batch: 300, loss is 3.8103239345550537 and perplexity is 45.16506702279813
At time: 754.0042960643768 and batch: 350, loss is 3.821150093078613 and perplexity is 45.656687577424464
At time: 755.1257679462433 and batch: 400, loss is 3.790005340576172 and perplexity is 44.25663663129128
At time: 756.2501544952393 and batch: 450, loss is 3.8356933212280273 and perplexity is 46.325535013136616
At time: 757.3715238571167 and batch: 500, loss is 3.8428885316848755 and perplexity is 46.660059029211006
At time: 758.4938476085663 and batch: 550, loss is 3.8262032508850097 and perplexity is 45.88798191590319
At time: 759.6143107414246 and batch: 600, loss is 3.7840831661224366 and perplexity is 43.995315666353484
At time: 760.7310733795166 and batch: 650, loss is 3.8067821311950683 and perplexity is 45.00538418619311
At time: 761.858375787735 and batch: 700, loss is 3.8544777822494507 and perplexity is 47.20395975794386
At time: 762.9998388290405 and batch: 750, loss is 3.7907619047164918 and perplexity is 44.29013228474509
At time: 764.1188273429871 and batch: 800, loss is 3.7825861501693727 and perplexity is 43.92950325034998
At time: 765.2370262145996 and batch: 850, loss is 3.7883303928375245 and perplexity is 44.18257112308888
At time: 766.3557305335999 and batch: 900, loss is 3.7394385862350465 and perplexity is 42.074362406936295
At time: 767.4764714241028 and batch: 950, loss is 3.8427309226989745 and perplexity is 46.65270556412664
At time: 768.5981395244598 and batch: 1000, loss is 3.8036406421661377 and perplexity is 44.86422211117784
At time: 769.7205066680908 and batch: 1050, loss is 3.7558152627944947 and perplexity is 42.76907363559863
At time: 770.8431575298309 and batch: 1100, loss is 3.762605166435242 and perplexity is 43.060459646381254
At time: 771.9606521129608 and batch: 1150, loss is 3.7439709663391114 and perplexity is 42.265492219290365
At time: 773.0810315608978 and batch: 1200, loss is 3.7827090406417847 and perplexity is 43.934902099484006
At time: 774.2003591060638 and batch: 1250, loss is 3.779436926841736 and perplexity is 43.791377043236054
At time: 775.317165851593 and batch: 1300, loss is 3.754733691215515 and perplexity is 42.72284082764754
At time: 776.4366805553436 and batch: 1350, loss is 3.6316484069824218 and perplexity is 37.77503395307745
At time: 777.5564799308777 and batch: 1400, loss is 3.667286925315857 and perplexity is 39.14555683986232
At time: 778.6820135116577 and batch: 1450, loss is 3.589824776649475 and perplexity is 36.227727426508416
At time: 779.8049099445343 and batch: 1500, loss is 3.596213665008545 and perplexity is 36.45992327941841
At time: 780.9262583255768 and batch: 1550, loss is 3.632264008522034 and perplexity is 37.798295481319556
At time: 782.0467972755432 and batch: 1600, loss is 3.703955593109131 and perplexity is 40.60761428987688
At time: 783.1634800434113 and batch: 1650, loss is 3.6677370977401735 and perplexity is 39.163183057206965
At time: 784.2826776504517 and batch: 1700, loss is 3.6524856281280518 and perplexity is 38.57041871464106
At time: 785.407247543335 and batch: 1750, loss is 3.632645945549011 and perplexity is 37.81273480720157
At time: 786.5274426937103 and batch: 1800, loss is 3.5882147455215456 and perplexity is 36.16944658722993
At time: 787.652526140213 and batch: 1850, loss is 3.6154161357879637 and perplexity is 37.16680914743405
At time: 788.7713258266449 and batch: 1900, loss is 3.7258630132675172 and perplexity is 41.50703841707262
At time: 789.8934297561646 and batch: 1950, loss is 3.6560060739517213 and perplexity is 38.70644307683586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3069091796875 and perplexity of 74.21076197033383
finished 17 epochs...
Completing Train Step...
At time: 793.5460634231567 and batch: 50, loss is 3.873428392410278 and perplexity is 48.1070334700488
At time: 794.6620435714722 and batch: 100, loss is 3.8535138607025146 and perplexity is 47.15848076664368
At time: 795.7756404876709 and batch: 150, loss is 3.8232296323776245 and perplexity is 45.75173124277178
At time: 796.8929586410522 and batch: 200, loss is 3.815127577781677 and perplexity is 45.38254581816009
At time: 798.0094573497772 and batch: 250, loss is 3.8126049852371215 and perplexity is 45.268208420391744
At time: 799.1258962154388 and batch: 300, loss is 3.8059027099609377 and perplexity is 44.965822893759544
At time: 800.2441952228546 and batch: 350, loss is 3.816722021102905 and perplexity is 45.45496343278921
At time: 801.3664832115173 and batch: 400, loss is 3.7851697158813478 and perplexity is 44.043144745615706
At time: 802.4866943359375 and batch: 450, loss is 3.8303938150405883 and perplexity is 46.08068192697384
At time: 803.607574224472 and batch: 500, loss is 3.8374399042129514 and perplexity is 46.40651710474304
At time: 804.7264716625214 and batch: 550, loss is 3.8200184965133666 and perplexity is 45.60505184749864
At time: 805.845803976059 and batch: 600, loss is 3.7789042234420775 and perplexity is 43.76805544010954
At time: 806.9635949134827 and batch: 650, loss is 3.802111964225769 and perplexity is 44.795691558442286
At time: 808.0799906253815 and batch: 700, loss is 3.8503226232528687 and perplexity is 47.00822673241878
At time: 809.1955835819244 and batch: 750, loss is 3.7872283840179444 and perplexity is 44.133908358362234
At time: 810.3117446899414 and batch: 800, loss is 3.7792989444732665 and perplexity is 43.78533502216887
At time: 811.4355030059814 and batch: 850, loss is 3.7850998735427854 and perplexity is 44.04006877680671
At time: 812.5588943958282 and batch: 900, loss is 3.736762065887451 and perplexity is 41.961900090818496
At time: 813.6800253391266 and batch: 950, loss is 3.8399018001556398 and perplexity is 46.52090586976054
At time: 814.8015568256378 and batch: 1000, loss is 3.800972652435303 and perplexity is 44.74468436095583
At time: 815.9161343574524 and batch: 1050, loss is 3.7531317138671874 and perplexity is 42.654454595607916
At time: 817.0311844348907 and batch: 1100, loss is 3.7603862953186034 and perplexity is 42.9650199595422
At time: 818.1704070568085 and batch: 1150, loss is 3.7418389320373535 and perplexity is 42.175476732248825
At time: 819.2888081073761 and batch: 1200, loss is 3.7808648109436036 and perplexity is 43.8539507176609
At time: 820.4048826694489 and batch: 1250, loss is 3.7779443311691283 and perplexity is 43.72606297923423
At time: 821.5256793498993 and batch: 1300, loss is 3.753585767745972 and perplexity is 42.67382641375626
At time: 822.6482660770416 and batch: 1350, loss is 3.6310923671722413 and perplexity is 37.75403536893402
At time: 823.7672522068024 and batch: 1400, loss is 3.6670949029922486 and perplexity is 39.13804074073149
At time: 824.8885061740875 and batch: 1450, loss is 3.5900008296966552 and perplexity is 36.23410598978054
At time: 826.0076575279236 and batch: 1500, loss is 3.5970370149612427 and perplexity is 36.48995491710308
At time: 827.127031326294 and batch: 1550, loss is 3.633215832710266 and perplexity is 37.834289940713674
At time: 828.2465169429779 and batch: 1600, loss is 3.7049685668945314 and perplexity is 40.648769579735884
At time: 829.3645496368408 and batch: 1650, loss is 3.66884747505188 and perplexity is 39.20669311895016
At time: 830.4807586669922 and batch: 1700, loss is 3.6538741064071654 and perplexity is 38.62401009987004
At time: 831.5960774421692 and batch: 1750, loss is 3.6343073081970214 and perplexity is 37.875607685293566
At time: 832.7178335189819 and batch: 1800, loss is 3.58982958316803 and perplexity is 36.22790155617097
At time: 833.8484885692596 and batch: 1850, loss is 3.6171400928497315 and perplexity is 37.23093839267692
At time: 834.968504190445 and batch: 1900, loss is 3.7275456380844116 and perplexity is 41.576937980867555
At time: 836.0931761264801 and batch: 1950, loss is 3.657207646369934 and perplexity is 38.752979624160936
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.306449854651163 and perplexity of 74.17668293667109
finished 18 epochs...
Completing Train Step...
At time: 839.7466900348663 and batch: 50, loss is 3.872064719200134 and perplexity is 48.04147590699168
At time: 840.8627464771271 and batch: 100, loss is 3.8515836668014525 and perplexity is 47.06754354615207
At time: 841.9794776439667 and batch: 150, loss is 3.8209315586090087 and perplexity is 45.64671110756182
At time: 843.0957326889038 and batch: 200, loss is 3.8124971055984496 and perplexity is 45.26332516583063
At time: 844.2136785984039 and batch: 250, loss is 3.809530782699585 and perplexity is 45.12925846877438
At time: 845.3332376480103 and batch: 300, loss is 3.8028080606460573 and perplexity is 44.826884534380355
At time: 846.4764454364777 and batch: 350, loss is 3.813758020401001 and perplexity is 45.320434359892474
At time: 847.5941770076752 and batch: 400, loss is 3.7820870065689087 and perplexity is 43.90758159141403
At time: 848.7182245254517 and batch: 450, loss is 3.827199110984802 and perplexity is 45.93370268812104
At time: 849.8403449058533 and batch: 500, loss is 3.834169239997864 and perplexity is 46.254984910445756
At time: 850.9601759910583 and batch: 550, loss is 3.8165380334854127 and perplexity is 45.446601051674875
At time: 852.0760860443115 and batch: 600, loss is 3.7758803749084473 and perplexity is 43.635907368416596
At time: 853.1908242702484 and batch: 650, loss is 3.799297227859497 and perplexity is 44.669780782310546
At time: 854.3062801361084 and batch: 700, loss is 3.8478065872192384 and perplexity is 46.89010100668978
At time: 855.4239363670349 and batch: 750, loss is 3.7849889516830446 and perplexity is 44.03518404139185
At time: 856.545060634613 and batch: 800, loss is 3.7771589851379392 and perplexity is 43.69173637011138
At time: 857.6654846668243 and batch: 850, loss is 3.782859272956848 and perplexity is 43.94150303736317
At time: 858.7839732170105 and batch: 900, loss is 3.734776382446289 and perplexity is 41.87865971251984
At time: 859.9007740020752 and batch: 950, loss is 3.838011064529419 and perplexity is 46.433030236642374
At time: 861.0167255401611 and batch: 1000, loss is 3.799145712852478 and perplexity is 44.66301315287343
At time: 862.1340997219086 and batch: 1050, loss is 3.7513777208328247 and perplexity is 42.579704554052775
At time: 863.2519714832306 and batch: 1100, loss is 3.7589178800582888 and perplexity is 42.901975767428986
At time: 864.3678929805756 and batch: 1150, loss is 3.7404973888397217 and perplexity is 42.11893444377315
At time: 865.4834809303284 and batch: 1200, loss is 3.77965895652771 and perplexity is 43.80110110840496
At time: 866.6008303165436 and batch: 1250, loss is 3.7769237422943114 and perplexity is 43.68145941064261
At time: 867.7206830978394 and batch: 1300, loss is 3.7527944564819338 and perplexity is 42.64007149132199
At time: 868.8406443595886 and batch: 1350, loss is 3.630556650161743 and perplexity is 37.73381530657119
At time: 869.9611079692841 and batch: 1400, loss is 3.666809530258179 and perplexity is 39.12687340454159
At time: 871.0764265060425 and batch: 1450, loss is 3.589903264045715 and perplexity is 36.23057095809505
At time: 872.1930682659149 and batch: 1500, loss is 3.5972246980667113 and perplexity is 36.496804107878916
At time: 873.3084082603455 and batch: 1550, loss is 3.6334214544296266 and perplexity is 37.8420702923393
At time: 874.4246253967285 and batch: 1600, loss is 3.705253925323486 and perplexity is 40.660370703922666
At time: 875.5409917831421 and batch: 1650, loss is 3.6691624402999876 and perplexity is 39.219043809692934
At time: 876.6580781936646 and batch: 1700, loss is 3.6543627166748047 and perplexity is 38.64288679908122
At time: 877.7775385379791 and batch: 1750, loss is 3.634965419769287 and perplexity is 37.900542264985624
At time: 878.8987104892731 and batch: 1800, loss is 3.5904534006118776 and perplexity is 36.2505082035931
At time: 880.0174629688263 and batch: 1850, loss is 3.617791805267334 and perplexity is 37.25521016579532
At time: 881.1364569664001 and batch: 1900, loss is 3.728103828430176 and perplexity is 41.600152304657875
At time: 882.2506091594696 and batch: 1950, loss is 3.6575000858306885 and perplexity is 38.764314181880046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.306236373546511 and perplexity of 74.16084930660892
finished 19 epochs...
Completing Train Step...
At time: 885.8952720165253 and batch: 50, loss is 3.870497922897339 and perplexity is 47.96626363669953
At time: 887.0373187065125 and batch: 100, loss is 3.8497524881362915 and perplexity is 46.981433330246105
At time: 888.1587145328522 and batch: 150, loss is 3.8188971090316772 and perplexity is 45.55393957694143
At time: 889.2807700634003 and batch: 200, loss is 3.8102895498275755 and perplexity is 45.16351406097625
At time: 890.4041540622711 and batch: 250, loss is 3.8070774126052855 and perplexity is 45.018675401730846
At time: 891.5297472476959 and batch: 300, loss is 3.8003060817718506 and perplexity is 44.714868805206734
At time: 892.6494958400726 and batch: 350, loss is 3.8113692140579225 and perplexity is 45.212301824086786
At time: 893.7686238288879 and batch: 400, loss is 3.7796401023864745 and perplexity is 43.80027528404352
At time: 894.8860139846802 and batch: 450, loss is 3.8247327995300293 and perplexity is 45.82055545653119
At time: 896.0039327144623 and batch: 500, loss is 3.8316601800918577 and perplexity is 46.13907385705109
At time: 897.1218430995941 and batch: 550, loss is 3.8139317083358764 and perplexity is 45.32830665618575
At time: 898.2444257736206 and batch: 600, loss is 3.77359206199646 and perplexity is 43.536168918073365
At time: 899.374368429184 and batch: 650, loss is 3.7971444129943848 and perplexity is 44.57371845352673
At time: 900.4994072914124 and batch: 700, loss is 3.8458556842803957 and perplexity is 46.798712145218076
At time: 901.6205286979675 and batch: 750, loss is 3.783209829330444 and perplexity is 43.95690971161446
At time: 902.7633361816406 and batch: 800, loss is 3.775455102920532 and perplexity is 43.61735418469983
At time: 903.8842227458954 and batch: 850, loss is 3.781020202636719 and perplexity is 43.86076578680156
At time: 905.002730846405 and batch: 900, loss is 3.7330739450454713 and perplexity is 41.80742456981975
At time: 906.1200239658356 and batch: 950, loss is 3.8364450263977052 and perplexity is 46.360371248942975
At time: 907.2387557029724 and batch: 1000, loss is 3.7976313638687134 and perplexity is 44.59542895024343
At time: 908.3560883998871 and batch: 1050, loss is 3.749941740036011 and perplexity is 42.51860479551831
At time: 909.4804480075836 and batch: 1100, loss is 3.7576613998413086 and perplexity is 42.8481041350155
At time: 910.6009013652802 and batch: 1150, loss is 3.739352059364319 and perplexity is 42.070722001518085
At time: 911.7208108901978 and batch: 1200, loss is 3.778617343902588 and perplexity is 43.75550108140095
At time: 912.8421883583069 and batch: 1250, loss is 3.7760055351257322 and perplexity is 43.6413691898585
At time: 913.9673388004303 and batch: 1300, loss is 3.7520606327056885 and perplexity is 42.6087926710155
At time: 915.0894775390625 and batch: 1350, loss is 3.6299553871154786 and perplexity is 37.71113417717856
At time: 916.210795879364 and batch: 1400, loss is 3.6664086818695067 and perplexity is 39.1111926034055
At time: 917.3280098438263 and batch: 1450, loss is 3.589632987976074 and perplexity is 36.220780024962714
At time: 918.4531011581421 and batch: 1500, loss is 3.5971140670776367 and perplexity is 36.4927666536803
At time: 919.5734062194824 and batch: 1550, loss is 3.6333096742630007 and perplexity is 37.8378405358224
At time: 920.6929650306702 and batch: 1600, loss is 3.7052223300933838 and perplexity is 40.65908605044879
At time: 921.8123524188995 and batch: 1650, loss is 3.66914354801178 and perplexity is 39.21830287921301
At time: 922.9304423332214 and batch: 1700, loss is 3.6544705486297606 and perplexity is 38.64705396178252
At time: 924.055801153183 and batch: 1750, loss is 3.6351839017868044 and perplexity is 37.90882375657023
At time: 925.1780335903168 and batch: 1800, loss is 3.5906531858444213 and perplexity is 36.25775124330648
At time: 926.3017156124115 and batch: 1850, loss is 3.6180037164688112 and perplexity is 37.26310579869982
At time: 927.4213290214539 and batch: 1900, loss is 3.7282404136657714 and perplexity is 41.605834659315256
At time: 928.541351556778 and batch: 1950, loss is 3.6574618339538576 and perplexity is 38.76283140246825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.306141556140989 and perplexity of 74.15381790064141
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f5dd8c64b38>
ELAPSED
5730.8719391822815


RESULTS SO FAR:
[{'best_accuracy': -76.21175240042173, 'params': {'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}}, {'best_accuracy': -73.46243748948554, 'params': {'rnn_dropout': 0.1541901093865481, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2553724200355174, 'num_layers': 2}}, {'best_accuracy': -74.63349668083315, 'params': {'rnn_dropout': 0.9124043211516957, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.644131086985198, 'num_layers': 2}}, {'best_accuracy': -75.57357919480093, 'params': {'rnn_dropout': 0.11345604619246663, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.06607543552697792, 'num_layers': 2}}, {'best_accuracy': -75.48551828979276, 'params': {'rnn_dropout': 0.7362722002869169, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.3951791952761644, 'num_layers': 2}}, {'best_accuracy': -74.15381790064141, 'params': {'rnn_dropout': 0.16227600235143344, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2602472106168877, 'num_layers': 2}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -76.21175240042173, 'params': {'rnn_dropout': 0.5634493180063415, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.9433201361303177, 'num_layers': 2}}, {'best_accuracy': -73.46243748948554, 'params': {'rnn_dropout': 0.1541901093865481, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2553724200355174, 'num_layers': 2}}, {'best_accuracy': -74.63349668083315, 'params': {'rnn_dropout': 0.9124043211516957, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.644131086985198, 'num_layers': 2}}, {'best_accuracy': -75.57357919480093, 'params': {'rnn_dropout': 0.11345604619246663, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.06607543552697792, 'num_layers': 2}}, {'best_accuracy': -75.48551828979276, 'params': {'rnn_dropout': 0.7362722002869169, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.3951791952761644, 'num_layers': 2}}, {'best_accuracy': -74.15381790064141, 'params': {'rnn_dropout': 0.16227600235143344, 'batch_size': 32, 'wordvec_source': 'gigavec', 'wordvec_dim': 300, 'tie_weights': True, 'data': 'wikitext', 'tune_wordvecs': True, 'seq_len': 35, 'dropout': 0.2602472106168877, 'num_layers': 2}}]
