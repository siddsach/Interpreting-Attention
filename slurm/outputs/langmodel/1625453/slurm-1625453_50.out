Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'name': 'dropout', 'domain': [0, 1], 'type': 'continuous'}, {'name': 'rnn_dropout', 'domain': [0, 1], 'type': 'continuous'}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 2.1305370330810547 and batch: 50, loss is 7.478015632629394 and perplexity is 1768.727486145228
At time: 3.429450273513794 and batch: 100, loss is 6.601068801879883 and perplexity is 735.8812803751364
At time: 4.727624893188477 and batch: 150, loss is 6.298668718338012 and perplexity is 543.8474138896242
At time: 6.02560830116272 and batch: 200, loss is 6.177950353622436 and perplexity is 482.00300748300765
At time: 7.325756072998047 and batch: 250, loss is 6.0983446502685545 and perplexity is 445.1203300715034
At time: 8.624237060546875 and batch: 300, loss is 6.027013339996338 and perplexity is 414.47528220402467
At time: 9.92214322090149 and batch: 350, loss is 5.974166650772094 and perplexity is 393.14034134098176
At time: 11.222017049789429 and batch: 400, loss is 5.914015054702759 and perplexity is 370.1895066680762
At time: 12.521751403808594 and batch: 450, loss is 5.843794994354248 and perplexity is 345.0864600084027
At time: 13.821325302124023 and batch: 500, loss is 5.818798055648804 and perplexity is 336.5672752829545
At time: 15.120255947113037 and batch: 550, loss is 5.763141508102417 and perplexity is 318.346848872493
At time: 16.419714212417603 and batch: 600, loss is 5.805273571014404 and perplexity is 332.0460190856053
At time: 17.72057557106018 and batch: 650, loss is 5.883650875091552 and perplexity is 359.11794606136516
At time: 19.018468141555786 and batch: 700, loss is 5.784432144165039 and perplexity is 325.19732247402055
At time: 20.318398237228394 and batch: 750, loss is 5.730541048049926 and perplexity is 308.13593963401706
At time: 21.618452310562134 and batch: 800, loss is 5.730712480545044 and perplexity is 308.18876867516184
At time: 22.931410312652588 and batch: 850, loss is 5.7571813678741455 and perplexity is 316.455100155887
At time: 24.225010633468628 and batch: 900, loss is 5.751130533218384 and perplexity is 314.54606412412215
At time: 25.518204927444458 and batch: 950, loss is 5.783793973922729 and perplexity is 324.98985742598995
At time: 26.811919450759888 and batch: 1000, loss is 5.745750732421875 and perplexity is 312.85841264256914
At time: 28.1056649684906 and batch: 1050, loss is 5.652059097290039 and perplexity is 284.87745270573726
At time: 29.400770664215088 and batch: 1100, loss is 5.737070093154907 and perplexity is 310.1543550749287
At time: 30.695025205612183 and batch: 1150, loss is 5.644294128417969 and perplexity is 282.6739542730952
At time: 31.98874592781067 and batch: 1200, loss is 5.720876455307007 and perplexity is 305.17227563899075
At time: 33.2821946144104 and batch: 1250, loss is 5.653187046051025 and perplexity is 285.19896116399616
At time: 34.575007915496826 and batch: 1300, loss is 5.66405834197998 and perplexity is 288.31635783790597
At time: 35.869102239608765 and batch: 1350, loss is 5.637408361434937 and perplexity is 280.73421325831555
At time: 37.16378355026245 and batch: 1400, loss is 5.6556073188781735 and perplexity is 285.8900564422402
At time: 38.45766997337341 and batch: 1450, loss is 5.619995212554931 and perplexity is 275.8880624326767
At time: 39.75092673301697 and batch: 1500, loss is 5.599103784561157 and perplexity is 270.18415567584054
At time: 41.044517993927 and batch: 1550, loss is 5.575857400894165 and perplexity is 263.97579171542617
At time: 42.34227991104126 and batch: 1600, loss is 5.600599937438965 and perplexity is 270.588695028789
At time: 43.64222264289856 and batch: 1650, loss is 5.582470188140869 and perplexity is 265.7271919004873
At time: 44.94259285926819 and batch: 1700, loss is 5.597633047103882 and perplexity is 269.78707778796297
At time: 46.24218702316284 and batch: 1750, loss is 5.611159763336182 and perplexity is 273.46120444498405
At time: 47.5417263507843 and batch: 1800, loss is 5.610224914550781 and perplexity is 273.20567902757716
At time: 48.84208822250366 and batch: 1850, loss is 5.5770368576049805 and perplexity is 264.28732341742125
At time: 50.14153337478638 and batch: 1900, loss is 5.567020769119263 and perplexity is 261.65341097040186
At time: 51.44149470329285 and batch: 1950, loss is 5.50891414642334 and perplexity is 246.882902784825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.052402797965116 and perplexity of 156.397805700544
finished 1 epochs...
Completing Train Step...
At time: 55.52853512763977 and batch: 50, loss is 5.308083848953247 and perplexity is 201.9628660271288
At time: 56.77833652496338 and batch: 100, loss is 5.227356767654419 and perplexity is 186.29971869594533
At time: 57.9982385635376 and batch: 150, loss is 5.139210805892945 and perplexity is 170.58109359222345
At time: 59.21778082847595 and batch: 200, loss is 5.116754789352417 and perplexity is 166.79321128270533
At time: 60.437477111816406 and batch: 250, loss is 5.109634628295899 and perplexity is 165.60983467070852
At time: 61.65655732154846 and batch: 300, loss is 5.121703996658325 and perplexity is 167.6207516076807
At time: 62.87661075592041 and batch: 350, loss is 5.088714170455932 and perplexity is 162.18119055794145
At time: 64.14404153823853 and batch: 400, loss is 5.048563833236694 and perplexity is 155.7985510355851
At time: 65.37169098854065 and batch: 450, loss is 5.018859243392944 and perplexity is 151.23867882912148
At time: 66.59913849830627 and batch: 500, loss is 5.002472133636474 and perplexity is 148.78051014864107
At time: 67.82691025733948 and batch: 550, loss is 4.955858564376831 and perplexity is 142.00447403261174
At time: 69.05421566963196 and batch: 600, loss is 4.948233671188355 and perplexity is 140.9258226127303
At time: 70.28203010559082 and batch: 650, loss is 5.015423593521118 and perplexity is 150.7199672475023
At time: 71.50921511650085 and batch: 700, loss is 4.991744441986084 and perplexity is 147.19296926167107
At time: 72.73816752433777 and batch: 750, loss is 4.948002815246582 and perplexity is 140.89329280422518
At time: 73.96591639518738 and batch: 800, loss is 4.92254132270813 and perplexity is 137.3512238168687
At time: 75.19424104690552 and batch: 850, loss is 4.927878761291504 and perplexity is 138.0862874718435
At time: 76.42267394065857 and batch: 900, loss is 4.929637308120728 and perplexity is 138.32933231507113
At time: 77.65016102790833 and batch: 950, loss is 4.994879150390625 and perplexity is 147.65510024401874
At time: 78.877849817276 and batch: 1000, loss is 4.953024635314941 and perplexity is 141.6026131183448
At time: 80.10587620735168 and batch: 1050, loss is 4.865179319381713 and perplexity is 129.6941932092848
At time: 81.33247876167297 and batch: 1100, loss is 4.948668298721313 and perplexity is 140.98708616779209
At time: 82.55912518501282 and batch: 1150, loss is 4.854049568176269 and perplexity is 128.25873208633618
At time: 83.78693985939026 and batch: 1200, loss is 4.935079984664917 and perplexity is 139.0842666956581
At time: 85.01411414146423 and batch: 1250, loss is 4.876246109008789 and perplexity is 131.1374630128287
At time: 86.24066281318665 and batch: 1300, loss is 4.908935928344727 and perplexity is 135.49516111378722
At time: 87.46957278251648 and batch: 1350, loss is 4.809780044555664 and perplexity is 122.70462499848466
At time: 88.6983072757721 and batch: 1400, loss is 4.832480897903443 and perplexity is 125.52198191100872
At time: 89.92711687088013 and batch: 1450, loss is 4.773957796096802 and perplexity is 118.38686704820127
At time: 91.15529417991638 and batch: 1500, loss is 4.74630292892456 and perplexity is 115.15775016185361
At time: 92.38400101661682 and batch: 1550, loss is 4.7399196434021 and perplexity is 114.42500650647965
At time: 93.61377310752869 and batch: 1600, loss is 4.8198458766937256 and perplexity is 123.94598634242766
At time: 94.84165406227112 and batch: 1650, loss is 4.774053287506104 and perplexity is 118.39817251675747
At time: 96.07069182395935 and batch: 1700, loss is 4.801073980331421 and perplexity is 121.64098741941505
At time: 97.2996723651886 and batch: 1750, loss is 4.812000131607055 and perplexity is 122.97734256394362
At time: 98.52701807022095 and batch: 1800, loss is 4.757232608795166 and perplexity is 116.42329088501401
At time: 99.75583982467651 and batch: 1850, loss is 4.76978741645813 and perplexity is 117.89417693486044
At time: 100.98423910140991 and batch: 1900, loss is 4.834680233001709 and perplexity is 125.7983506137222
At time: 102.21750020980835 and batch: 1950, loss is 4.756653461456299 and perplexity is 116.35588416701053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.628931515715843 and perplexity of 102.40458794128486
finished 2 epochs...
Completing Train Step...
At time: 106.2040421962738 and batch: 50, loss is 4.695477304458618 and perplexity is 109.45103764452136
At time: 107.43295860290527 and batch: 100, loss is 4.648405447006225 and perplexity is 104.41835216346945
At time: 108.6613404750824 and batch: 150, loss is 4.595565118789673 and perplexity is 99.04409141238668
At time: 109.89051985740662 and batch: 200, loss is 4.591293869018554 and perplexity is 98.6219515338189
At time: 111.11909556388855 and batch: 250, loss is 4.586121740341187 and perplexity is 98.11318295252588
At time: 112.34799480438232 and batch: 300, loss is 4.612100458145141 and perplexity is 100.69543420646782
At time: 113.57590198516846 and batch: 350, loss is 4.615661640167236 and perplexity is 101.05466824572113
At time: 114.80636620521545 and batch: 400, loss is 4.585324726104736 and perplexity is 98.03501650295361
At time: 116.0355703830719 and batch: 450, loss is 4.580313262939453 and perplexity is 97.54494663804458
At time: 117.26617765426636 and batch: 500, loss is 4.584618673324585 and perplexity is 97.96582303699353
At time: 118.49599957466125 and batch: 550, loss is 4.5469612121582035 and perplexity is 94.34527698963996
At time: 119.72350883483887 and batch: 600, loss is 4.527568645477295 and perplexity is 92.53330608345098
At time: 120.95211625099182 and batch: 650, loss is 4.58236668586731 and perplexity is 97.74545346016677
At time: 122.18045449256897 and batch: 700, loss is 4.599493417739868 and perplexity is 99.43393141542343
At time: 123.40933012962341 and batch: 750, loss is 4.561144638061523 and perplexity is 95.69295095959097
At time: 124.63770079612732 and batch: 800, loss is 4.536211194992066 and perplexity is 93.33649556605512
At time: 125.86697459220886 and batch: 850, loss is 4.539526424407959 and perplexity is 93.64644094787812
At time: 127.1271071434021 and batch: 900, loss is 4.524559602737427 and perplexity is 92.25528790464834
At time: 128.35623717308044 and batch: 950, loss is 4.598329963684082 and perplexity is 99.31831187668817
At time: 129.58505964279175 and batch: 1000, loss is 4.582058839797973 and perplexity is 97.71536753767762
At time: 130.8133282661438 and batch: 1050, loss is 4.5027765369415285 and perplexity is 90.26741449042008
At time: 132.0426561832428 and batch: 1100, loss is 4.57188684463501 and perplexity is 96.7264454738853
At time: 133.27161359786987 and batch: 1150, loss is 4.510292863845825 and perplexity is 90.94845012349589
At time: 134.50125885009766 and batch: 1200, loss is 4.584314060211182 and perplexity is 97.9359859072523
At time: 135.73122453689575 and batch: 1250, loss is 4.548942432403565 and perplexity is 94.53238104843844
At time: 136.96101450920105 and batch: 1300, loss is 4.561312255859375 and perplexity is 95.7089921456573
At time: 138.18939471244812 and batch: 1350, loss is 4.453085088729859 and perplexity is 85.89151863036906
At time: 139.41896843910217 and batch: 1400, loss is 4.47739917755127 and perplexity is 88.00548812155586
At time: 140.64806413650513 and batch: 1450, loss is 4.413603973388672 and perplexity is 82.56649538736951
At time: 141.877055644989 and batch: 1500, loss is 4.40601035118103 and perplexity is 81.94189112018785
At time: 143.105890750885 and batch: 1550, loss is 4.402327327728272 and perplexity is 81.6406522887861
At time: 144.334716796875 and batch: 1600, loss is 4.500333604812622 and perplexity is 90.04716645840011
At time: 145.56419396400452 and batch: 1650, loss is 4.442924823760986 and perplexity is 85.02325639895668
At time: 146.79330372810364 and batch: 1700, loss is 4.48072491645813 and perplexity is 88.29865863148595
At time: 148.02252054214478 and batch: 1750, loss is 4.48509165763855 and perplexity is 88.68507910537025
At time: 149.251158952713 and batch: 1800, loss is 4.427188367843628 and perplexity is 83.69576407933431
At time: 150.48076725006104 and batch: 1850, loss is 4.4602774715423585 and perplexity is 86.51151024853748
At time: 151.7096302509308 and batch: 1900, loss is 4.538589000701904 and perplexity is 93.55869568781497
At time: 152.93782448768616 and batch: 1950, loss is 4.468018312454223 and perplexity is 87.18378069881751
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.509031783702762 and perplexity of 90.83382912732425
finished 3 epochs...
Completing Train Step...
At time: 156.88928413391113 and batch: 50, loss is 4.419764952659607 and perplexity is 83.07675609271463
At time: 158.14748573303223 and batch: 100, loss is 4.374221639633179 and perplexity is 79.37803078747417
At time: 159.3750011920929 and batch: 150, loss is 4.327899227142334 and perplexity is 75.7849123364123
At time: 160.60243725776672 and batch: 200, loss is 4.33102707862854 and perplexity is 76.02232739305305
At time: 161.83088660240173 and batch: 250, loss is 4.322889003753662 and perplexity is 75.40616259880457
At time: 163.05982971191406 and batch: 300, loss is 4.350080375671387 and perplexity is 77.48469055900826
At time: 164.28891468048096 and batch: 350, loss is 4.364098615646363 and perplexity is 78.5785385447216
At time: 165.51589059829712 and batch: 400, loss is 4.33052170753479 and perplexity is 75.98391761272283
At time: 166.74403357505798 and batch: 450, loss is 4.335494184494019 and perplexity is 76.36268682246951
At time: 167.97284650802612 and batch: 500, loss is 4.352036943435669 and perplexity is 77.63644301535251
At time: 169.20091128349304 and batch: 550, loss is 4.313905162811279 and perplexity is 74.73175952878024
At time: 170.42923784255981 and batch: 600, loss is 4.295184602737427 and perplexity is 73.34575302214293
At time: 171.65698981285095 and batch: 650, loss is 4.346916837692261 and perplexity is 77.23995212140642
At time: 172.88400650024414 and batch: 700, loss is 4.373385171890259 and perplexity is 79.31166138702504
At time: 174.11230850219727 and batch: 750, loss is 4.337821044921875 and perplexity is 76.54057902149749
At time: 175.3409309387207 and batch: 800, loss is 4.3117808961868285 and perplexity is 74.57317784075377
At time: 176.56884694099426 and batch: 850, loss is 4.313368186950684 and perplexity is 74.6916411501579
At time: 177.79735660552979 and batch: 900, loss is 4.291314430236817 and perplexity is 73.06244089279235
At time: 179.02655816078186 and batch: 950, loss is 4.374173974990844 and perplexity is 79.37424735219624
At time: 180.25525760650635 and batch: 1000, loss is 4.361858930587768 and perplexity is 78.40274430137168
At time: 181.48356342315674 and batch: 1050, loss is 4.296271095275879 and perplexity is 73.42548594229652
At time: 182.71424269676208 and batch: 1100, loss is 4.35152850151062 and perplexity is 77.59697942613359
At time: 183.93985724449158 and batch: 1150, loss is 4.300635018348694 and perplexity is 73.74660928369426
At time: 185.16589331626892 and batch: 1200, loss is 4.372926177978516 and perplexity is 79.27526617054852
At time: 186.39247751235962 and batch: 1250, loss is 4.344911861419678 and perplexity is 77.08524299599699
At time: 187.61868381500244 and batch: 1300, loss is 4.347513847351074 and perplexity is 77.2860788865613
At time: 188.84587240219116 and batch: 1350, loss is 4.235087237358093 and perplexity is 69.067703754716
At time: 190.07330584526062 and batch: 1400, loss is 4.264860000610351 and perplexity is 71.1549576254119
At time: 191.30034160614014 and batch: 1450, loss is 4.196574330329895 and perplexity is 66.45827654198004
At time: 192.52799105644226 and batch: 1500, loss is 4.200062999725342 and perplexity is 66.69053239380541
At time: 193.7541937828064 and batch: 1550, loss is 4.198852014541626 and perplexity is 66.60982002778573
At time: 194.9823637008667 and batch: 1600, loss is 4.300327844619751 and perplexity is 73.72395974157396
At time: 196.21001410484314 and batch: 1650, loss is 4.241664819717407 and perplexity is 69.52349963869699
At time: 197.43703150749207 and batch: 1700, loss is 4.279189262390137 and perplexity is 72.18189570090064
At time: 198.6639106273651 and batch: 1750, loss is 4.282618656158447 and perplexity is 72.4298607861401
At time: 199.89146757125854 and batch: 1800, loss is 4.225203504562378 and perplexity is 68.38841948791114
At time: 201.1187047958374 and batch: 1850, loss is 4.261811695098877 and perplexity is 70.93838583211094
At time: 202.34675216674805 and batch: 1900, loss is 4.34813645362854 and perplexity is 77.3342126670789
At time: 203.57789301872253 and batch: 1950, loss is 4.281358137130737 and perplexity is 72.33861908647528
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.46454340025436 and perplexity of 86.88135047918763
finished 4 epochs...
Completing Train Step...
At time: 207.57398962974548 and batch: 50, loss is 4.232737941741943 and perplexity is 68.90563375078365
At time: 208.8004651069641 and batch: 100, loss is 4.193002362251281 and perplexity is 66.2213131643731
At time: 210.02844762802124 and batch: 150, loss is 4.150431399345398 and perplexity is 63.461371587881644
At time: 211.25462174415588 and batch: 200, loss is 4.15355001449585 and perplexity is 63.65959210889031
At time: 212.48255610466003 and batch: 250, loss is 4.1467910003662105 and perplexity is 63.23076687678684
At time: 213.70912861824036 and batch: 300, loss is 4.171268243789672 and perplexity is 64.79757914517886
At time: 214.93568062782288 and batch: 350, loss is 4.1840696620941165 and perplexity is 65.63241218365283
At time: 216.16264986991882 and batch: 400, loss is 4.151651678085327 and perplexity is 63.53885941919818
At time: 217.3900589942932 and batch: 450, loss is 4.161995739936828 and perplexity is 64.19952037905817
At time: 218.61812233924866 and batch: 500, loss is 4.1862230968475345 and perplexity is 65.7738995882705
At time: 219.84468340873718 and batch: 550, loss is 4.147731590270996 and perplexity is 63.29026907698054
At time: 221.10291934013367 and batch: 600, loss is 4.136665472984314 and perplexity is 62.593752511150015
At time: 222.3301272392273 and batch: 650, loss is 4.186301956176758 and perplexity is 65.77908667839496
At time: 223.55723690986633 and batch: 700, loss is 4.213882913589478 and perplexity is 67.61858785960987
At time: 224.7839081287384 and batch: 750, loss is 4.180658922195435 and perplexity is 65.40893841885617
At time: 226.01062631607056 and batch: 800, loss is 4.150250816345215 and perplexity is 63.44991257768696
At time: 227.23827075958252 and batch: 850, loss is 4.15074728012085 and perplexity is 63.48142098159239
At time: 228.46625900268555 and batch: 900, loss is 4.1349646091461185 and perplexity is 62.48737954961287
At time: 229.69330096244812 and batch: 950, loss is 4.217331581115722 and perplexity is 67.85218445470807
At time: 230.92108917236328 and batch: 1000, loss is 4.202988400459289 and perplexity is 66.88591457246248
At time: 232.14807677268982 and batch: 1050, loss is 4.144074215888977 and perplexity is 63.059215650224196
At time: 233.37506318092346 and batch: 1100, loss is 4.196382536888122 and perplexity is 66.44553150263432
At time: 234.60309147834778 and batch: 1150, loss is 4.142487292289734 and perplexity is 62.95922485262144
At time: 235.8301501274109 and batch: 1200, loss is 4.216585111618042 and perplexity is 67.80155376814426
At time: 237.05807542800903 and batch: 1250, loss is 4.194183745384216 and perplexity is 66.29959213641064
At time: 238.2844533920288 and batch: 1300, loss is 4.1912294340133665 and perplexity is 66.1040115427168
At time: 239.51277351379395 and batch: 1350, loss is 4.078221597671509 and perplexity is 59.0403788832891
At time: 240.74050569534302 and batch: 1400, loss is 4.11589391708374 and perplexity is 61.306993143739376
At time: 241.96794891357422 and batch: 1450, loss is 4.042434182167053 and perplexity is 56.964836967370225
At time: 243.19544577598572 and batch: 1500, loss is 4.046284151077271 and perplexity is 57.18457253480701
At time: 244.42319679260254 and batch: 1550, loss is 4.0508412170410155 and perplexity is 57.44576107866322
At time: 245.65101432800293 and batch: 1600, loss is 4.1553346014022825 and perplexity is 63.77329961372131
At time: 246.87779784202576 and batch: 1650, loss is 4.093687419891357 and perplexity is 59.96058441239937
At time: 248.10244631767273 and batch: 1700, loss is 4.130713357925415 and perplexity is 62.222293873170806
At time: 249.32836389541626 and batch: 1750, loss is 4.1344814872741695 and perplexity is 62.45719782114531
At time: 250.55292916297913 and batch: 1800, loss is 4.077525525093079 and perplexity is 58.999296794244906
At time: 251.77811074256897 and batch: 1850, loss is 4.115590877532959 and perplexity is 61.28841751479464
At time: 253.00238966941833 and batch: 1900, loss is 4.205333118438721 and perplexity is 67.04292718214167
At time: 254.2272846698761 and batch: 1950, loss is 4.134759430885315 and perplexity is 62.47455981296531
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.456443041424419 and perplexity of 86.18042307905961
finished 5 epochs...
Completing Train Step...
At time: 258.17575001716614 and batch: 50, loss is 4.095172562599182 and perplexity is 60.04970059584144
At time: 259.43339824676514 and batch: 100, loss is 4.054228477478027 and perplexity is 57.64067475777358
At time: 260.6593687534332 and batch: 150, loss is 4.0164155006408695 and perplexity is 55.50180266308567
At time: 261.88422751426697 and batch: 200, loss is 4.018636040687561 and perplexity is 55.625183573992246
At time: 263.108553647995 and batch: 250, loss is 4.011568188667297 and perplexity is 55.23341910540288
At time: 264.33197355270386 and batch: 300, loss is 4.0364349794387815 and perplexity is 56.62411640975886
At time: 265.55856585502625 and batch: 350, loss is 4.043917417526245 and perplexity is 57.049391919736756
At time: 266.7851424217224 and batch: 400, loss is 4.0136742639541625 and perplexity is 55.349867425812015
At time: 268.01131772994995 and batch: 450, loss is 4.0306032848358155 and perplexity is 56.29486284194382
At time: 269.23751187324524 and batch: 500, loss is 4.056803240776062 and perplexity is 57.789277077417744
At time: 270.4620451927185 and batch: 550, loss is 4.01542760848999 and perplexity is 55.44699994192115
At time: 271.68745708465576 and batch: 600, loss is 4.0125051832199095 and perplexity is 55.2851967721344
At time: 272.9130883216858 and batch: 650, loss is 4.058197612762451 and perplexity is 57.8699130316812
At time: 274.1391234397888 and batch: 700, loss is 4.088298621177674 and perplexity is 59.6383379327669
At time: 275.36606073379517 and batch: 750, loss is 4.053368105888366 and perplexity is 57.591103686631634
At time: 276.59126019477844 and batch: 800, loss is 4.023923234939575 and perplexity is 55.92006358186017
At time: 277.81800746917725 and batch: 850, loss is 4.0220451927185055 and perplexity is 55.81514189596514
At time: 279.04466938972473 and batch: 900, loss is 4.012756242752075 and perplexity is 55.29907839025505
At time: 280.26989698410034 and batch: 950, loss is 4.087903599739075 and perplexity is 59.61478416314934
At time: 281.49755120277405 and batch: 1000, loss is 4.076304903030396 and perplexity is 58.927324885081184
At time: 282.7540581226349 and batch: 1050, loss is 4.0249413919448855 and perplexity is 55.97702798076335
At time: 283.9804174900055 and batch: 1100, loss is 4.0728764295578 and perplexity is 58.725640048016
At time: 285.2078523635864 and batch: 1150, loss is 4.023774495124817 and perplexity is 55.91174666050574
At time: 286.4342064857483 and batch: 1200, loss is 4.095257053375244 and perplexity is 60.05477445599123
At time: 287.65992641448975 and batch: 1250, loss is 4.072470092773438 and perplexity is 58.701782507705644
At time: 288.885799407959 and batch: 1300, loss is 4.071433057785034 and perplexity is 58.640938259623425
At time: 290.1142690181732 and batch: 1350, loss is 3.9583848762512206 and perplexity is 52.37266926007879
At time: 291.3398962020874 and batch: 1400, loss is 3.993293538093567 and perplexity is 54.233214700035944
At time: 292.56495666503906 and batch: 1450, loss is 3.9215447998046873 and perplexity is 50.47836354426671
At time: 293.79053115844727 and batch: 1500, loss is 3.9258216333389284 and perplexity is 50.694713418648696
At time: 295.01705718040466 and batch: 1550, loss is 3.932749466896057 and perplexity is 51.04713731293601
At time: 296.2444267272949 and batch: 1600, loss is 4.040199136734008 and perplexity is 56.837660144592526
At time: 297.47194600105286 and batch: 1650, loss is 3.979427556991577 and perplexity is 53.48640754226836
At time: 298.6986849308014 and batch: 1700, loss is 4.011147437095642 and perplexity is 55.2101844458589
At time: 299.9250543117523 and batch: 1750, loss is 4.014303421974182 and perplexity is 55.38470219594839
At time: 301.1507167816162 and batch: 1800, loss is 3.9594776105880736 and perplexity is 52.429929953757224
At time: 302.3771755695343 and batch: 1850, loss is 3.9941958713531496 and perplexity is 54.282173218561816
At time: 303.6038875579834 and batch: 1900, loss is 4.085896883010864 and perplexity is 59.495274130016504
At time: 304.82988119125366 and batch: 1950, loss is 4.020185360908508 and perplexity is 55.71143159134356
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.460723451126453 and perplexity of 86.55010122065073
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 308.80175280570984 and batch: 50, loss is 4.008499217033386 and perplexity is 55.064169153416586
At time: 310.02575945854187 and batch: 100, loss is 4.000810174942017 and perplexity is 54.64240200968231
At time: 311.2502417564392 and batch: 150, loss is 3.97074866771698 and perplexity is 53.02421350012503
At time: 312.4730598926544 and batch: 200, loss is 3.9757514810562133 and perplexity is 53.2901483994021
At time: 313.6970684528351 and batch: 250, loss is 3.959114837646484 and perplexity is 52.4109132434231
At time: 314.9494025707245 and batch: 300, loss is 3.973812847137451 and perplexity is 53.1869383857203
At time: 316.1740493774414 and batch: 350, loss is 3.9779715013504027 and perplexity is 53.40858502754535
At time: 317.39792943000793 and batch: 400, loss is 3.945285964012146 and perplexity is 51.691117798215025
At time: 318.62054920196533 and batch: 450, loss is 3.9630006313323975 and perplexity is 52.614967438671286
At time: 319.84328961372375 and batch: 500, loss is 3.9788523626327517 and perplexity is 53.45565130863022
At time: 321.06558108329773 and batch: 550, loss is 3.9235406494140626 and perplexity is 50.57921137150017
At time: 322.2882647514343 and batch: 600, loss is 3.910118999481201 and perplexity is 49.90489027612564
At time: 323.5110490322113 and batch: 650, loss is 3.963473572731018 and perplexity is 52.63985712017657
At time: 324.7337474822998 and batch: 700, loss is 3.987707986831665 and perplexity is 53.93113672061238
At time: 325.9603343009949 and batch: 750, loss is 3.935967803001404 and perplexity is 51.21168880700103
At time: 327.18274760246277 and batch: 800, loss is 3.9063881492614745 and perplexity is 49.71904949290053
At time: 328.4060091972351 and batch: 850, loss is 3.895564203262329 and perplexity is 49.18379519363418
At time: 329.6298370361328 and batch: 900, loss is 3.881227760314941 and perplexity is 48.483704913052456
At time: 330.8522844314575 and batch: 950, loss is 3.9592601346969603 and perplexity is 52.41852894778643
At time: 332.0770845413208 and batch: 1000, loss is 3.9250698852539063 and perplexity is 50.65661808575631
At time: 333.2999212741852 and batch: 1050, loss is 3.866608533859253 and perplexity is 47.78006650797104
At time: 334.52312660217285 and batch: 1100, loss is 3.9008075284957884 and perplexity is 49.442359103005955
At time: 335.7467505931854 and batch: 1150, loss is 3.859668073654175 and perplexity is 47.449598982680975
At time: 336.97098445892334 and batch: 1200, loss is 3.9188848447799685 and perplexity is 50.34427178560346
At time: 338.1931757926941 and batch: 1250, loss is 3.8745298957824708 and perplexity is 48.16005272472541
At time: 339.4167466163635 and batch: 1300, loss is 3.8724094581604005 and perplexity is 48.05804053051701
At time: 340.63908982276917 and batch: 1350, loss is 3.752005014419556 and perplexity is 42.60642290889462
At time: 341.86362886428833 and batch: 1400, loss is 3.7790002059936523 and perplexity is 43.7722566113645
At time: 343.08719062805176 and batch: 1450, loss is 3.698115882873535 and perplexity is 40.37116864802558
At time: 344.3100700378418 and batch: 1500, loss is 3.697878570556641 and perplexity is 40.361589209162354
At time: 345.5336000919342 and batch: 1550, loss is 3.7040834331512453 and perplexity is 40.61280590083868
At time: 346.75756335258484 and batch: 1600, loss is 3.8006821346282957 and perplexity is 44.73168712143623
At time: 347.9815399646759 and batch: 1650, loss is 3.7243674898147585 and perplexity is 41.44501006165646
At time: 349.2049207687378 and batch: 1700, loss is 3.7365199184417723 and perplexity is 41.951740354022476
At time: 350.4302558898926 and batch: 1750, loss is 3.7239246129989625 and perplexity is 41.42665909147929
At time: 351.65421414375305 and batch: 1800, loss is 3.6697101640701293 and perplexity is 39.24053089618656
At time: 352.8783612251282 and batch: 1850, loss is 3.705616035461426 and perplexity is 40.67509690245892
At time: 354.1023037433624 and batch: 1900, loss is 3.7806493425369263 and perplexity is 43.84450259469582
At time: 355.32590317726135 and batch: 1950, loss is 3.704088878631592 and perplexity is 40.613027057677186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.403362611282703 and perplexity of 81.72521728029308
finished 7 epochs...
Completing Train Step...
At time: 359.27034616470337 and batch: 50, loss is 3.9012426376342773 and perplexity is 49.46387660617178
At time: 360.5268290042877 and batch: 100, loss is 3.8775453090667726 and perplexity is 48.305494360599724
At time: 361.75186944007874 and batch: 150, loss is 3.8463409996032714 and perplexity is 46.821429789477534
At time: 362.9764814376831 and batch: 200, loss is 3.8503912448883058 and perplexity is 47.01145262449788
At time: 364.20116329193115 and batch: 250, loss is 3.827811303138733 and perplexity is 45.96183154976339
At time: 365.4253158569336 and batch: 300, loss is 3.8436234426498412 and perplexity is 46.69436262171672
At time: 366.650821685791 and batch: 350, loss is 3.8551567220687866 and perplexity is 47.236019287868075
At time: 367.875376701355 and batch: 400, loss is 3.8250001573562624 and perplexity is 45.83280757841219
At time: 369.1010525226593 and batch: 450, loss is 3.8475491285324095 and perplexity is 46.87803029678056
At time: 370.3263590335846 and batch: 500, loss is 3.8644774532318116 and perplexity is 47.67835175352423
At time: 371.551221370697 and batch: 550, loss is 3.8132158184051512 and perplexity is 45.29586819044466
At time: 372.7756311893463 and batch: 600, loss is 3.8060049295425413 and perplexity is 44.97041951629062
At time: 374.00123858451843 and batch: 650, loss is 3.8570693206787108 and perplexity is 47.32644928327183
At time: 375.2270464897156 and batch: 700, loss is 3.8877427911758424 and perplexity is 48.80060894565626
At time: 376.4872658252716 and batch: 750, loss is 3.8373138666152955 and perplexity is 46.4006685073909
At time: 377.712055683136 and batch: 800, loss is 3.808169279098511 and perplexity is 45.067856629752825
At time: 378.93854570388794 and batch: 850, loss is 3.7993592405319214 and perplexity is 44.672550960685655
At time: 380.16365933418274 and batch: 900, loss is 3.78710825920105 and perplexity is 44.12860709911462
At time: 381.3895308971405 and batch: 950, loss is 3.8666855001449587 and perplexity is 47.78374410374455
At time: 382.613573551178 and batch: 1000, loss is 3.8388534021377563 and perplexity is 46.472159001781385
At time: 383.8355858325958 and batch: 1050, loss is 3.784203281402588 and perplexity is 44.00060049340799
At time: 385.0568914413452 and batch: 1100, loss is 3.820130729675293 and perplexity is 45.610170533905105
At time: 386.28317856788635 and batch: 1150, loss is 3.7839548635482787 and perplexity is 43.98967131620267
At time: 387.50856471061707 and batch: 1200, loss is 3.842862482070923 and perplexity is 46.6588435685175
At time: 388.7327127456665 and batch: 1250, loss is 3.805872745513916 and perplexity is 44.96447553792814
At time: 389.95772099494934 and batch: 1300, loss is 3.802429575920105 and perplexity is 44.80992145360805
At time: 391.1826493740082 and batch: 1350, loss is 3.685886511802673 and perplexity is 39.8804612830241
At time: 392.4072985649109 and batch: 1400, loss is 3.7160585355758666 and perplexity is 41.10207207065848
At time: 393.63245820999146 and batch: 1450, loss is 3.6390884494781495 and perplexity is 38.05712991266359
At time: 394.85632944107056 and batch: 1500, loss is 3.6421244764328002 and perplexity is 38.17284795756129
At time: 396.0799734592438 and batch: 1550, loss is 3.652026343345642 and perplexity is 38.55270797572201
At time: 397.30460834503174 and batch: 1600, loss is 3.750916113853455 and perplexity is 42.56005400101626
At time: 398.52924132347107 and batch: 1650, loss is 3.679796690940857 and perplexity is 39.638334420823156
At time: 399.75427770614624 and batch: 1700, loss is 3.6971060609817505 and perplexity is 40.33042153525375
At time: 400.97881388664246 and batch: 1750, loss is 3.6867632818222047 and perplexity is 39.9154426088901
At time: 402.20397543907166 and batch: 1800, loss is 3.637621841430664 and perplexity is 38.00135592895336
At time: 403.42931866645813 and batch: 1850, loss is 3.67964195728302 and perplexity is 39.63220151084369
At time: 404.6542053222656 and batch: 1900, loss is 3.7600202465057375 and perplexity is 42.94929554311881
At time: 405.87947249412537 and batch: 1950, loss is 3.68506995677948 and perplexity is 39.84790998380829
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.407950183957122 and perplexity of 82.1009989577239
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 409.85977363586426 and batch: 50, loss is 3.855419216156006 and perplexity is 47.24842009113248
At time: 411.08612418174744 and batch: 100, loss is 3.8570910406112673 and perplexity is 47.327477221721736
At time: 412.3119719028473 and batch: 150, loss is 3.8397830057144167 and perplexity is 46.515379772983835
At time: 413.5392372608185 and batch: 200, loss is 3.8536687755584715 and perplexity is 47.16578688179707
At time: 414.76529335975647 and batch: 250, loss is 3.839980707168579 and perplexity is 46.524576840312704
At time: 415.9910354614258 and batch: 300, loss is 3.856570620536804 and perplexity is 47.30285346040746
At time: 417.2166745662689 and batch: 350, loss is 3.8685936069488527 and perplexity is 47.87500763357565
At time: 418.44272899627686 and batch: 400, loss is 3.8297266244888304 and perplexity is 46.049947585344874
At time: 419.6686387062073 and batch: 450, loss is 3.856838002204895 and perplexity is 47.3155030673323
At time: 420.8951427936554 and batch: 500, loss is 3.8768302154541017 and perplexity is 48.27096375790372
At time: 422.12174558639526 and batch: 550, loss is 3.824627385139465 and perplexity is 45.815725565176926
At time: 423.3480763435364 and batch: 600, loss is 3.8017225217819215 and perplexity is 44.77824961138562
At time: 424.5743246078491 and batch: 650, loss is 3.8380097913742066 and perplexity is 46.43297112022553
At time: 425.8006067276001 and batch: 700, loss is 3.8695390462875365 and perplexity is 47.92029195254737
At time: 427.0261890888214 and batch: 750, loss is 3.8261036396026613 and perplexity is 45.88341118283224
At time: 428.2514045238495 and batch: 800, loss is 3.798788933753967 and perplexity is 44.647081165573
At time: 429.4778401851654 and batch: 850, loss is 3.786802682876587 and perplexity is 44.11512450163981
At time: 430.7027711868286 and batch: 900, loss is 3.770563716888428 and perplexity is 43.4045258049036
At time: 431.92787408828735 and batch: 950, loss is 3.8607587814331055 and perplexity is 47.50138086371525
At time: 433.1552839279175 and batch: 1000, loss is 3.816822566986084 and perplexity is 45.459533972003015
At time: 434.38200640678406 and batch: 1050, loss is 3.75856990814209 and perplexity is 42.887049681792405
At time: 435.60916328430176 and batch: 1100, loss is 3.7863764333724976 and perplexity is 44.09632445873727
At time: 436.8365828990936 and batch: 1150, loss is 3.753682703971863 and perplexity is 42.67796325393474
At time: 438.0988349914551 and batch: 1200, loss is 3.802635612487793 and perplexity is 44.81915488720254
At time: 439.3238401412964 and batch: 1250, loss is 3.766353254318237 and perplexity is 43.22215687182807
At time: 440.5493814945221 and batch: 1300, loss is 3.756450500488281 and perplexity is 42.79625079436423
At time: 441.77640175819397 and batch: 1350, loss is 3.636723670959473 and perplexity is 37.96723955664534
At time: 443.0025134086609 and batch: 1400, loss is 3.6586729764938353 and perplexity is 38.80980715797543
At time: 444.23208475112915 and batch: 1450, loss is 3.5800037670135496 and perplexity is 35.87367598343173
At time: 445.45754194259644 and batch: 1500, loss is 3.580931854248047 and perplexity is 35.90698533876929
At time: 446.6848940849304 and batch: 1550, loss is 3.590227656364441 and perplexity is 36.24232578350137
At time: 447.91045117378235 and batch: 1600, loss is 3.688841609954834 and perplexity is 39.998486262279144
At time: 449.1364402770996 and batch: 1650, loss is 3.621590247154236 and perplexity is 37.39699101929104
At time: 450.36297130584717 and batch: 1700, loss is 3.6323248767852783 and perplexity is 37.80059626794083
At time: 451.58931255340576 and batch: 1750, loss is 3.61538236618042 and perplexity is 37.16555406006752
At time: 452.8147611618042 and batch: 1800, loss is 3.5521833658218385 and perplexity is 34.88941073461808
At time: 454.04222083091736 and batch: 1850, loss is 3.586173596382141 and perplexity is 36.0956946474159
At time: 455.2686412334442 and batch: 1900, loss is 3.67732762336731 and perplexity is 39.540585418739866
At time: 456.4953844547272 and batch: 1950, loss is 3.6123166370391844 and perplexity is 37.05178901344831
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382685319767442 and perplexity of 80.05271216593799
finished 9 epochs...
Completing Train Step...
At time: 460.43958020210266 and batch: 50, loss is 3.8514893770217897 and perplexity is 47.06310576706374
At time: 461.69701075553894 and batch: 100, loss is 3.827282314300537 and perplexity is 45.937524683487815
At time: 462.9218764305115 and batch: 150, loss is 3.7980565357208254 and perplexity is 44.61439370271971
At time: 464.1470000743866 and batch: 200, loss is 3.805475549697876 and perplexity is 44.94661938280386
At time: 465.37390184402466 and batch: 250, loss is 3.791185622215271 and perplexity is 44.30890276522707
At time: 466.59992122650146 and batch: 300, loss is 3.8044604587554933 and perplexity is 44.90101762545878
At time: 467.8247525691986 and batch: 350, loss is 3.821417851448059 and perplexity is 45.668914174458294
At time: 469.05126905441284 and batch: 400, loss is 3.7841964244842528 and perplexity is 44.00029878591809
At time: 470.30572032928467 and batch: 450, loss is 3.812674193382263 and perplexity is 45.27134145754499
At time: 471.5296893119812 and batch: 500, loss is 3.8324027824401856 and perplexity is 46.1733495666831
At time: 472.75589084625244 and batch: 550, loss is 3.7811763668060303 and perplexity is 43.86761580170555
At time: 473.98082637786865 and batch: 600, loss is 3.7582456731796263 and perplexity is 42.87314645492658
At time: 475.20549035072327 and batch: 650, loss is 3.796062932014465 and perplexity is 44.525538882155885
At time: 476.4317514896393 and batch: 700, loss is 3.830173177719116 and perplexity is 46.07051593028224
At time: 477.6571247577667 and batch: 750, loss is 3.7887176752090452 and perplexity is 44.199685567860776
At time: 478.883358001709 and batch: 800, loss is 3.7616643857955934 and perplexity is 43.01996824935924
At time: 480.11081099510193 and batch: 850, loss is 3.7505181646347046 and perplexity is 42.54312063031088
At time: 481.33630204200745 and batch: 900, loss is 3.734503607749939 and perplexity is 41.867237831704074
At time: 482.5612802505493 and batch: 950, loss is 3.822946882247925 and perplexity is 45.73879676352792
At time: 483.78627586364746 and batch: 1000, loss is 3.7824092721939087 and perplexity is 43.921733775896634
At time: 485.01261734962463 and batch: 1050, loss is 3.727275471687317 and perplexity is 41.565706806542295
At time: 486.2389335632324 and batch: 1100, loss is 3.7567948865890504 and perplexity is 42.810991766450094
At time: 487.4647467136383 and batch: 1150, loss is 3.7270072174072264 and perplexity is 41.55455812319432
At time: 488.6903192996979 and batch: 1200, loss is 3.7773191833496096 and perplexity is 43.6987362688133
At time: 489.91604685783386 and batch: 1250, loss is 3.7438074731826783 and perplexity is 42.25858266540701
At time: 491.14043831825256 and batch: 1300, loss is 3.735421743392944 and perplexity is 41.905695286910166
At time: 492.36589431762695 and batch: 1350, loss is 3.617684106826782 and perplexity is 37.25119805381101
At time: 493.5920476913452 and batch: 1400, loss is 3.642356662750244 and perplexity is 38.18171219959292
At time: 494.81674432754517 and batch: 1450, loss is 3.566244339942932 and perplexity is 35.383455068548614
At time: 496.0409605503082 and batch: 1500, loss is 3.5695756530761718 and perplexity is 35.50152499186945
At time: 497.2663993835449 and batch: 1550, loss is 3.5806315040588377 and perplexity is 35.896202288355525
At time: 498.4924736022949 and batch: 1600, loss is 3.6813896036148073 and perplexity is 39.70152514138467
At time: 499.7177963256836 and batch: 1650, loss is 3.6159459400177 and perplexity is 37.186505497270176
At time: 500.94503951072693 and batch: 1700, loss is 3.6284369897842406 and perplexity is 37.65391714177587
At time: 502.1704156398773 and batch: 1750, loss is 3.6129685115814207 and perplexity is 37.07595000556274
At time: 503.3960199356079 and batch: 1800, loss is 3.5516005468368532 and perplexity is 34.86908244809808
At time: 504.622683763504 and batch: 1850, loss is 3.5873653078079224 and perplexity is 36.138735940455234
At time: 505.8483693599701 and batch: 1900, loss is 3.6801372289657595 and perplexity is 39.65183507955061
At time: 507.07765769958496 and batch: 1950, loss is 3.6160002994537352 and perplexity is 37.18852698968022
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.384529149255087 and perplexity of 80.20045187875901
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 511.0606789588928 and batch: 50, loss is 3.84384473323822 and perplexity is 46.704696788079964
At time: 512.2849686145782 and batch: 100, loss is 3.8361251306533815 and perplexity is 46.34554313532684
At time: 513.5092308521271 and batch: 150, loss is 3.8138949060440064 and perplexity is 45.32663850131037
At time: 514.7339472770691 and batch: 200, loss is 3.820307755470276 and perplexity is 45.61824542531413
At time: 515.9584558010101 and batch: 250, loss is 3.811787347793579 and perplexity is 45.23121056566201
At time: 517.1826305389404 and batch: 300, loss is 3.8243394756317137 and perplexity is 45.802536680875875
At time: 518.4068048000336 and batch: 350, loss is 3.847150740623474 and perplexity is 46.859358375896335
At time: 519.6316628456116 and batch: 400, loss is 3.8154201984405516 and perplexity is 45.39582763179055
At time: 520.8561894893646 and batch: 450, loss is 3.839756140708923 and perplexity is 46.51413015383629
At time: 522.0832939147949 and batch: 500, loss is 3.8629758882522585 and perplexity is 47.6068133334829
At time: 523.3075802326202 and batch: 550, loss is 3.820504140853882 and perplexity is 45.62720506168343
At time: 524.5317344665527 and batch: 600, loss is 3.7947843074798584 and perplexity is 44.46864381718894
At time: 525.7562954425812 and batch: 650, loss is 3.81889301776886 and perplexity is 45.5537532041835
At time: 526.9817824363708 and batch: 700, loss is 3.8411752080917356 and perplexity is 46.5801836949057
At time: 528.2056248188019 and batch: 750, loss is 3.799876208305359 and perplexity is 44.69565120041486
At time: 529.4316515922546 and batch: 800, loss is 3.7676737213134768 and perplexity is 43.27926800182309
At time: 530.655889749527 and batch: 850, loss is 3.7576052474975588 and perplexity is 42.84569818109369
At time: 531.9101998806 and batch: 900, loss is 3.743054485321045 and perplexity is 42.226774442715836
At time: 533.1353414058685 and batch: 950, loss is 3.8505718898773194 and perplexity is 47.01994577494018
At time: 534.3612468242645 and batch: 1000, loss is 3.8129025077819825 and perplexity is 45.2816787367243
At time: 535.5853028297424 and batch: 1050, loss is 3.7477243661880495 and perplexity is 42.42442960258418
At time: 536.8102722167969 and batch: 1100, loss is 3.7686089992523195 and perplexity is 43.319765081454996
At time: 538.0339834690094 and batch: 1150, loss is 3.7401694440841675 and perplexity is 42.1051240247638
At time: 539.2583191394806 and batch: 1200, loss is 3.7898264217376707 and perplexity is 44.24871899359763
At time: 540.4838030338287 and batch: 1250, loss is 3.759199929237366 and perplexity is 42.914077941098824
At time: 541.7083415985107 and batch: 1300, loss is 3.747501783370972 and perplexity is 42.41498770437146
At time: 542.9335000514984 and batch: 1350, loss is 3.6213743448257447 and perplexity is 37.38891779339691
At time: 544.1580879688263 and batch: 1400, loss is 3.645570158958435 and perplexity is 38.304606341141394
At time: 545.3840229511261 and batch: 1450, loss is 3.5604905891418457 and perplexity is 35.18045206000946
At time: 546.610787153244 and batch: 1500, loss is 3.556249904632568 and perplexity is 35.03157874740851
At time: 547.8374147415161 and batch: 1550, loss is 3.5653741788864135 and perplexity is 35.35267915584515
At time: 549.0623269081116 and batch: 1600, loss is 3.66372230052948 and perplexity is 39.006266024912264
At time: 550.286289691925 and batch: 1650, loss is 3.601905388832092 and perplexity is 36.66803478814212
At time: 551.5120856761932 and batch: 1700, loss is 3.6245000982284545 and perplexity is 37.50596917198313
At time: 552.7378296852112 and batch: 1750, loss is 3.6203074932098387 and perplexity is 37.34905063598401
At time: 553.963128566742 and batch: 1800, loss is 3.557170476913452 and perplexity is 35.063842696128894
At time: 555.1884677410126 and batch: 1850, loss is 3.5709644746780396 and perplexity is 35.550864530655446
At time: 556.4130928516388 and batch: 1900, loss is 3.6605427074432373 and perplexity is 38.88243893534062
At time: 557.6375303268433 and batch: 1950, loss is 3.5987541103363037 and perplexity is 36.5526654745234
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370614269167878 and perplexity of 79.09220068112134
finished 11 epochs...
Completing Train Step...
At time: 561.5721063613892 and batch: 50, loss is 3.8510564374923706 and perplexity is 47.042734698238604
At time: 562.8226063251495 and batch: 100, loss is 3.836987419128418 and perplexity is 46.385523597910534
At time: 564.0424818992615 and batch: 150, loss is 3.8080931425094606 and perplexity is 45.064425447494145
At time: 565.265435218811 and batch: 200, loss is 3.806891231536865 and perplexity is 45.010294556847214
At time: 566.4896378517151 and batch: 250, loss is 3.7969436931610105 and perplexity is 44.564772522028846
At time: 567.7138669490814 and batch: 300, loss is 3.805312366485596 and perplexity is 44.939285447475676
At time: 568.9395661354065 and batch: 350, loss is 3.8269915533065797 and perplexity is 45.924169784786805
At time: 570.1632959842682 and batch: 400, loss is 3.794672899246216 and perplexity is 44.46368992008638
At time: 571.3871901035309 and batch: 450, loss is 3.8195602798461916 and perplexity is 45.584159639579234
At time: 572.6128816604614 and batch: 500, loss is 3.842006592750549 and perplexity is 46.61892584761851
At time: 573.837723493576 and batch: 550, loss is 3.800346221923828 and perplexity is 44.71666370285971
At time: 575.0614840984344 and batch: 600, loss is 3.7744138050079346 and perplexity is 43.57195916380635
At time: 576.2870335578918 and batch: 650, loss is 3.7974013233184816 and perplexity is 44.58517137310447
At time: 577.5105724334717 and batch: 700, loss is 3.8225141668319704 and perplexity is 45.71900916256988
At time: 578.7334291934967 and batch: 750, loss is 3.7826149034500123 and perplexity is 43.930766385844855
At time: 579.9582009315491 and batch: 800, loss is 3.751302890777588 and perplexity is 42.576518431619384
At time: 581.1821286678314 and batch: 850, loss is 3.742645411491394 and perplexity is 42.209504107042754
At time: 582.4057693481445 and batch: 900, loss is 3.7282971239089964 and perplexity is 41.60819420322288
At time: 583.6314253807068 and batch: 950, loss is 3.8353209781646727 and perplexity is 46.30828923239094
At time: 584.8572540283203 and batch: 1000, loss is 3.7989538049697877 and perplexity is 44.654442790971
At time: 586.083247423172 and batch: 1050, loss is 3.7340679788589477 and perplexity is 41.84900322536762
At time: 587.3092813491821 and batch: 1100, loss is 3.7548667097091677 and perplexity is 42.72852413356301
At time: 588.5335211753845 and batch: 1150, loss is 3.727089786529541 and perplexity is 41.557989388243044
At time: 589.7589049339294 and batch: 1200, loss is 3.776914343833923 and perplexity is 43.681048874105855
At time: 590.9828586578369 and batch: 1250, loss is 3.747462854385376 and perplexity is 42.41333656406488
At time: 592.2067246437073 and batch: 1300, loss is 3.7363371419906617 and perplexity is 41.944073264505704
At time: 593.430743932724 and batch: 1350, loss is 3.6125149154663085 and perplexity is 37.05913631227738
At time: 594.6551885604858 and batch: 1400, loss is 3.6379804277420043 and perplexity is 38.014985138479794
At time: 595.8786001205444 and batch: 1450, loss is 3.5550301265716553 and perplexity is 34.98887404663671
At time: 597.1031517982483 and batch: 1500, loss is 3.5532042598724365 and perplexity is 34.925047313956725
At time: 598.327799320221 and batch: 1550, loss is 3.5637493658065797 and perplexity is 35.29528430092801
At time: 599.5508954524994 and batch: 1600, loss is 3.6631585645675657 and perplexity is 38.98428298691075
At time: 600.7744011878967 and batch: 1650, loss is 3.6027774143218996 and perplexity is 36.700024194900436
At time: 601.9984707832336 and batch: 1700, loss is 3.6260933446884156 and perplexity is 37.56577305310406
At time: 603.2229199409485 and batch: 1750, loss is 3.6220722007751465 and perplexity is 37.4150189784951
At time: 604.4481363296509 and batch: 1800, loss is 3.559758143424988 and perplexity is 35.15469372302434
At time: 605.6733074188232 and batch: 1850, loss is 3.5752349996566775 and perplexity is 35.703010024984835
At time: 606.8975811004639 and batch: 1900, loss is 3.6647301435470583 and perplexity is 39.0455980346837
At time: 608.1217720508575 and batch: 1950, loss is 3.6026633167266846 and perplexity is 36.69583704927163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369308684593023 and perplexity of 78.9890065029427
finished 12 epochs...
Completing Train Step...
At time: 612.0957956314087 and batch: 50, loss is 3.8448094511032105 and perplexity is 46.74977538401765
At time: 613.3209822177887 and batch: 100, loss is 3.8290149068832395 and perplexity is 46.01718468726052
At time: 614.5461256504059 and batch: 150, loss is 3.798861765861511 and perplexity is 44.65033302500843
At time: 615.7706971168518 and batch: 200, loss is 3.797271876335144 and perplexity is 44.579400330698704
At time: 616.9965879917145 and batch: 250, loss is 3.7868384552001952 and perplexity is 44.116702630376
At time: 618.2210817337036 and batch: 300, loss is 3.794959530830383 and perplexity is 44.47643644465709
At time: 619.4464905261993 and batch: 350, loss is 3.81659188747406 and perplexity is 45.44904859831645
At time: 620.6720173358917 and batch: 400, loss is 3.7838339471817015 and perplexity is 43.984352566548615
At time: 621.8980121612549 and batch: 450, loss is 3.8090550994873045 and perplexity is 45.10779634312925
At time: 623.1242070198059 and batch: 500, loss is 3.8313928174972536 and perplexity is 46.126739643479176
At time: 624.3497538566589 and batch: 550, loss is 3.7899833297729493 and perplexity is 44.255662517891636
At time: 625.6093347072601 and batch: 600, loss is 3.7641633224487303 and perplexity is 43.127606859854794
At time: 626.8348982334137 and batch: 650, loss is 3.787158141136169 and perplexity is 44.13080837433232
At time: 628.0609970092773 and batch: 700, loss is 3.8131171226501466 and perplexity is 45.29139790113793
At time: 629.2867450714111 and batch: 750, loss is 3.773854308128357 and perplexity is 43.54758760715784
At time: 630.5122826099396 and batch: 800, loss is 3.742909789085388 and perplexity is 42.22066482943973
At time: 631.7370049953461 and batch: 850, loss is 3.734724678993225 and perplexity is 41.87649449717806
At time: 632.9619326591492 and batch: 900, loss is 3.7205259799957275 and perplexity is 41.28610406344821
At time: 634.1868424415588 and batch: 950, loss is 3.827152118682861 and perplexity is 45.931544208411424
At time: 635.4104351997375 and batch: 1000, loss is 3.7914542245864866 and perplexity is 44.32080584010128
At time: 636.6352488994598 and batch: 1050, loss is 3.7267198085784914 and perplexity is 41.542616692434045
At time: 637.8607394695282 and batch: 1100, loss is 3.7477106285095214 and perplexity is 42.4238467934118
At time: 639.0861239433289 and batch: 1150, loss is 3.7203496503829956 and perplexity is 41.278824742506266
At time: 640.3117568492889 and batch: 1200, loss is 3.770331630706787 and perplexity is 43.394453383123775
At time: 641.5384140014648 and batch: 1250, loss is 3.741500792503357 and perplexity is 42.16121794706585
At time: 642.7632412910461 and batch: 1300, loss is 3.73082040309906 and perplexity is 41.713315863665855
At time: 643.9880125522614 and batch: 1350, loss is 3.6080184984207153 and perplexity is 36.89287704568387
At time: 645.2139964103699 and batch: 1400, loss is 3.633929977416992 and perplexity is 37.86131874869891
At time: 646.4393892288208 and batch: 1450, loss is 3.552003650665283 and perplexity is 34.88314114209305
At time: 647.6651382446289 and batch: 1500, loss is 3.550852074623108 and perplexity is 34.842993673346314
At time: 648.8910546302795 and batch: 1550, loss is 3.5621209573745727 and perplexity is 35.237855933471494
At time: 650.1158294677734 and batch: 1600, loss is 3.6619572830200195 and perplexity is 38.93748000452217
At time: 651.3413293361664 and batch: 1650, loss is 3.602064824104309 and perplexity is 36.6738814323185
At time: 652.5670857429504 and batch: 1700, loss is 3.6255155420303344 and perplexity is 37.54407371915123
At time: 653.7929503917694 and batch: 1750, loss is 3.6217109107971193 and perplexity is 37.40150374871602
At time: 655.0190813541412 and batch: 1800, loss is 3.5597729158401488 and perplexity is 35.155213046590696
At time: 656.2459373474121 and batch: 1850, loss is 3.576106925010681 and perplexity is 35.73415396026015
At time: 657.4712636470795 and batch: 1900, loss is 3.665612230300903 and perplexity is 39.0800548342151
At time: 658.696747303009 and batch: 1950, loss is 3.603198432922363 and perplexity is 36.71547884084237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3693359375 and perplexity of 78.99115921232274
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 662.6392149925232 and batch: 50, loss is 3.84210542678833 and perplexity is 46.62353361199528
At time: 663.8943467140198 and batch: 100, loss is 3.832409071922302 and perplexity is 46.17363997405271
At time: 665.1188569068909 and batch: 150, loss is 3.8063577938079836 and perplexity is 44.98629077037439
At time: 666.3434174060822 and batch: 200, loss is 3.8056425714492796 and perplexity is 44.95412707284916
At time: 667.5672078132629 and batch: 250, loss is 3.799902944564819 and perplexity is 44.69684621091707
At time: 668.7913823127747 and batch: 300, loss is 3.8104499912261964 and perplexity is 45.17076073965691
At time: 670.0151588916779 and batch: 350, loss is 3.835155415534973 and perplexity is 46.30062294489161
At time: 671.2389600276947 and batch: 400, loss is 3.81311203956604 and perplexity is 45.29116768173821
At time: 672.4638969898224 and batch: 450, loss is 3.8364629125595093 and perplexity is 46.361200465460165
At time: 673.6889865398407 and batch: 500, loss is 3.8593374061584473 and perplexity is 47.43391153641932
At time: 674.9133639335632 and batch: 550, loss is 3.822033748626709 and perplexity is 45.69705019340829
At time: 676.1372058391571 and batch: 600, loss is 3.7919227123260497 and perplexity is 44.341574458786674
At time: 677.3613901138306 and batch: 650, loss is 3.808767333030701 and perplexity is 45.094817699909036
At time: 678.5852115154266 and batch: 700, loss is 3.832249917984009 and perplexity is 46.16629184216308
At time: 679.8085370063782 and batch: 750, loss is 3.791736907958984 and perplexity is 44.33333636597018
At time: 681.0313885211945 and batch: 800, loss is 3.7543852138519287 and perplexity is 42.70795547846526
At time: 682.2535150051117 and batch: 850, loss is 3.7427565002441407 and perplexity is 42.21419336866536
At time: 683.4743411540985 and batch: 900, loss is 3.72348397731781 and perplexity is 41.408409048438
At time: 684.6985313892365 and batch: 950, loss is 3.831136021614075 and perplexity is 46.11489600739785
At time: 685.9229862689972 and batch: 1000, loss is 3.803530421257019 and perplexity is 44.859277408339665
At time: 687.1815023422241 and batch: 1050, loss is 3.7423637390136717 and perplexity is 42.19761652571834
At time: 688.4058775901794 and batch: 1100, loss is 3.7594705772399903 and perplexity is 42.92569412245529
At time: 689.6297340393066 and batch: 1150, loss is 3.7295243740081787 and perplexity is 41.6592892104489
At time: 690.8535251617432 and batch: 1200, loss is 3.778399496078491 and perplexity is 43.745970078889876
At time: 692.0785858631134 and batch: 1250, loss is 3.75139066696167 and perplexity is 42.58025579996237
At time: 693.3017349243164 and batch: 1300, loss is 3.741359519958496 and perplexity is 42.15526214521758
At time: 694.5251934528351 and batch: 1350, loss is 3.617777500152588 and perplexity is 37.25467722955088
At time: 695.7492804527283 and batch: 1400, loss is 3.6455012559890747 and perplexity is 38.30196713095007
At time: 696.9740645885468 and batch: 1450, loss is 3.558564052581787 and perplexity is 35.11274087789314
At time: 698.1981387138367 and batch: 1500, loss is 3.549611201286316 and perplexity is 34.79978474547061
At time: 699.4224851131439 and batch: 1550, loss is 3.56002272605896 and perplexity is 35.16399627507866
At time: 700.6465322971344 and batch: 1600, loss is 3.6567492723464965 and perplexity is 38.73522033547966
At time: 701.8693134784698 and batch: 1650, loss is 3.59213906288147 and perplexity is 36.31166584861139
At time: 703.0934534072876 and batch: 1700, loss is 3.610892333984375 and perplexity is 36.999053601689425
At time: 704.3170909881592 and batch: 1750, loss is 3.609618215560913 and perplexity is 36.95194244481458
At time: 705.5427389144897 and batch: 1800, loss is 3.551157178878784 and perplexity is 34.853626040904366
At time: 706.766923904419 and batch: 1850, loss is 3.570183038711548 and perplexity is 35.52309465807305
At time: 707.990118265152 and batch: 1900, loss is 3.6607195806503294 and perplexity is 38.88931680525221
At time: 709.2155995368958 and batch: 1950, loss is 3.603895721435547 and perplexity is 36.74108905030891
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.360474200581395 and perplexity of 78.29425280180882
finished 14 epochs...
Completing Train Step...
At time: 713.1922287940979 and batch: 50, loss is 3.845429039001465 and perplexity is 46.77874995431134
At time: 714.4174537658691 and batch: 100, loss is 3.8275836181640623 and perplexity is 45.95136792256172
At time: 715.6436958312988 and batch: 150, loss is 3.7991216373443604 and perplexity is 44.66193788108161
At time: 716.869307756424 and batch: 200, loss is 3.796587963104248 and perplexity is 44.548922312335115
At time: 718.0935792922974 and batch: 250, loss is 3.789262156486511 and perplexity is 44.22375802202795
At time: 719.3486678600311 and batch: 300, loss is 3.797196102142334 and perplexity is 44.57602249060087
At time: 720.5736649036407 and batch: 350, loss is 3.820617127418518 and perplexity is 45.63236061408588
At time: 721.7991328239441 and batch: 400, loss is 3.7956994581222534 and perplexity is 44.50935795208652
At time: 723.0249409675598 and batch: 450, loss is 3.8206253957748415 and perplexity is 45.63273792026318
At time: 724.2515361309052 and batch: 500, loss is 3.843538689613342 and perplexity is 46.69040530039701
At time: 725.477169752121 and batch: 550, loss is 3.8051408767700194 and perplexity is 44.931579482961794
At time: 726.7030365467072 and batch: 600, loss is 3.7770305061340332 and perplexity is 43.686123259934746
At time: 727.9293072223663 and batch: 650, loss is 3.7964788770675657 and perplexity is 44.54406291201278
At time: 729.1542806625366 and batch: 700, loss is 3.820743751525879 and perplexity is 45.63813913685785
At time: 730.3795886039734 and batch: 750, loss is 3.7814386510849 and perplexity is 43.87912309670714
At time: 731.6055736541748 and batch: 800, loss is 3.746283311843872 and perplexity is 42.36333772293755
At time: 732.8294076919556 and batch: 850, loss is 3.7364345026016235 and perplexity is 41.948157163907204
At time: 734.054074048996 and batch: 900, loss is 3.71798442363739 and perplexity is 41.18130633423409
At time: 735.2795979976654 and batch: 950, loss is 3.826310982704163 and perplexity is 45.892925777973105
At time: 736.5061643123627 and batch: 1000, loss is 3.7977452945709227 and perplexity is 44.60051002821895
At time: 737.7313117980957 and batch: 1050, loss is 3.7364062118530272 and perplexity is 41.9469704359256
At time: 738.9574639797211 and batch: 1100, loss is 3.75365891456604 and perplexity is 42.67694798262359
At time: 740.1836831569672 and batch: 1150, loss is 3.723607244491577 and perplexity is 41.413513660600685
At time: 741.4113264083862 and batch: 1200, loss is 3.772445840835571 and perplexity is 43.486295428480425
At time: 742.6382808685303 and batch: 1250, loss is 3.7450075483322145 and perplexity is 42.30932658248529
At time: 743.8625574111938 and batch: 1300, loss is 3.734813885688782 and perplexity is 41.88023032750171
At time: 745.0879559516907 and batch: 1350, loss is 3.6119343662261962 and perplexity is 37.03762790280155
At time: 746.3117015361786 and batch: 1400, loss is 3.6404279804229738 and perplexity is 38.10814277487868
At time: 747.5371510982513 and batch: 1450, loss is 3.555446219444275 and perplexity is 35.00343569703789
At time: 748.7634963989258 and batch: 1500, loss is 3.548615298271179 and perplexity is 34.76514478679918
At time: 749.9889824390411 and batch: 1550, loss is 3.5602948236465455 and perplexity is 35.173565615473144
At time: 751.2127039432526 and batch: 1600, loss is 3.658185977935791 and perplexity is 38.79091143931884
At time: 752.4399147033691 and batch: 1650, loss is 3.5954681873321532 and perplexity is 36.4327533490772
At time: 753.665158033371 and batch: 1700, loss is 3.615503706932068 and perplexity is 37.170064029948605
At time: 754.8902399539948 and batch: 1750, loss is 3.615596957206726 and perplexity is 37.17353031024174
At time: 756.1154370307922 and batch: 1800, loss is 3.557325029373169 and perplexity is 35.06926231806187
At time: 757.3411304950714 and batch: 1850, loss is 3.576188745498657 and perplexity is 35.737077865790646
At time: 758.5662572383881 and batch: 1900, loss is 3.6661642265319823 and perplexity is 39.101632832132815
At time: 759.791876077652 and batch: 1950, loss is 3.608802833557129 and perplexity is 36.921824776311304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.358641442587209 and perplexity of 78.15088979906189
finished 15 epochs...
Completing Train Step...
At time: 763.7585003376007 and batch: 50, loss is 3.845100107192993 and perplexity is 46.76336546585333
At time: 765.0147867202759 and batch: 100, loss is 3.8253133296966553 and perplexity is 45.84716339383313
At time: 766.2407717704773 and batch: 150, loss is 3.7957129144668578 and perplexity is 44.50995688937499
At time: 767.4676067829132 and batch: 200, loss is 3.79230348110199 and perplexity is 44.358461560653126
At time: 768.6942420005798 and batch: 250, loss is 3.7842835855484007 and perplexity is 44.00413406592421
At time: 769.920179605484 and batch: 300, loss is 3.7917234182357786 and perplexity is 44.33273832556753
At time: 771.1468374729156 and batch: 350, loss is 3.8148856210708617 and perplexity is 45.37156653495469
At time: 772.372350692749 and batch: 400, loss is 3.7891089582443236 and perplexity is 44.21698353896874
At time: 773.5982401371002 and batch: 450, loss is 3.8145484209060667 and perplexity is 45.35626981441538
At time: 774.8252770900726 and batch: 500, loss is 3.837540078163147 and perplexity is 46.41116606172453
At time: 776.0515253543854 and batch: 550, loss is 3.798973035812378 and perplexity is 44.655301541788496
At time: 777.2765626907349 and batch: 600, loss is 3.771322474479675 and perplexity is 43.43747181578987
At time: 778.5027387142181 and batch: 650, loss is 3.7913235807418824 and perplexity is 44.31501597784354
At time: 779.7282457351685 and batch: 700, loss is 3.815923557281494 and perplexity is 45.418683774909184
At time: 780.9833433628082 and batch: 750, loss is 3.777072796821594 and perplexity is 43.687970815191186
At time: 782.2089545726776 and batch: 800, loss is 3.742733888626099 and perplexity is 42.21323884824063
At time: 783.4345934391022 and batch: 850, loss is 3.7333577775955202 and perplexity is 41.81929256192794
At time: 784.6601901054382 and batch: 900, loss is 3.714994945526123 and perplexity is 41.05837955536138
At time: 785.8855822086334 and batch: 950, loss is 3.823334002494812 and perplexity is 45.756506605521366
At time: 787.1099164485931 and batch: 1000, loss is 3.7946115589141844 and perplexity is 44.46096258623197
At time: 788.3353981971741 and batch: 1050, loss is 3.7333003425598146 and perplexity is 41.816890738341534
At time: 789.5598347187042 and batch: 1100, loss is 3.750704455375671 and perplexity is 42.55104675803531
At time: 790.7852349281311 and batch: 1150, loss is 3.7209054613113404 and perplexity is 41.30177434163557
At time: 792.0154948234558 and batch: 1200, loss is 3.7699315977096557 and perplexity is 43.37709764154416
At time: 793.2472534179688 and batch: 1250, loss is 3.74239595413208 and perplexity is 42.19897594882814
At time: 794.4773578643799 and batch: 1300, loss is 3.732347502708435 and perplexity is 41.777064915214126
At time: 795.7159790992737 and batch: 1350, loss is 3.609927887916565 and perplexity is 36.96338721184991
At time: 796.9617466926575 and batch: 1400, loss is 3.638639559745789 and perplexity is 38.04005029152276
At time: 798.1887652873993 and batch: 1450, loss is 3.5544896650314333 and perplexity is 34.96996901506025
At time: 799.4148890972137 and batch: 1500, loss is 3.548361005783081 and perplexity is 34.75630539557528
At time: 800.643009185791 and batch: 1550, loss is 3.560663728713989 and perplexity is 35.186543715765055
At time: 801.8673589229584 and batch: 1600, loss is 3.658862247467041 and perplexity is 38.8171534231416
At time: 803.0910367965698 and batch: 1650, loss is 3.596884183883667 and perplexity is 36.484378544104814
At time: 804.3157999515533 and batch: 1700, loss is 3.617312831878662 and perplexity is 37.23737018431577
At time: 805.5405685901642 and batch: 1750, loss is 3.6176920127868653 and perplexity is 37.251492561460054
At time: 806.7658143043518 and batch: 1800, loss is 3.559375214576721 and perplexity is 35.14123455376237
At time: 807.9920253753662 and batch: 1850, loss is 3.5781604051589966 and perplexity is 35.807608729177396
At time: 809.2170102596283 and batch: 1900, loss is 3.6677958393096923 and perplexity is 39.16548363161611
At time: 810.4419605731964 and batch: 1950, loss is 3.6100701904296875 and perplexity is 36.96864756901582
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357928324854651 and perplexity of 78.09517888031392
finished 16 epochs...
Completing Train Step...
At time: 814.4139142036438 and batch: 50, loss is 3.843474588394165 and perplexity is 46.68741248441598
At time: 815.6375925540924 and batch: 100, loss is 3.8229471254348755 and perplexity is 45.73880788660778
At time: 816.8632490634918 and batch: 150, loss is 3.7928054475784303 and perplexity is 44.380733610746645
At time: 818.0867648124695 and batch: 200, loss is 3.789018807411194 and perplexity is 44.212997520738355
At time: 819.309898853302 and batch: 250, loss is 3.780703053474426 and perplexity is 43.84685758727825
At time: 820.534245967865 and batch: 300, loss is 3.7880072259902953 and perplexity is 44.168295087771455
At time: 821.7588832378387 and batch: 350, loss is 3.811070833206177 and perplexity is 45.198813351410195
At time: 822.9839379787445 and batch: 400, loss is 3.7849569940567016 and perplexity is 44.03377680392041
At time: 824.208181142807 and batch: 450, loss is 3.810734148025513 and perplexity is 45.18359814228262
At time: 825.4328346252441 and batch: 500, loss is 3.833809356689453 and perplexity is 46.238341508466604
At time: 826.6565256118774 and batch: 550, loss is 3.795295834541321 and perplexity is 44.4913965507113
At time: 827.8797330856323 and batch: 600, loss is 3.7678247117996215 and perplexity is 43.28580325290663
At time: 829.104612827301 and batch: 650, loss is 3.7880113744735717 and perplexity is 44.16847831958504
At time: 830.3295195102692 and batch: 700, loss is 3.812838912010193 and perplexity is 45.27879910498429
At time: 831.5532119274139 and batch: 750, loss is 3.774235553741455 and perplexity is 43.5641930990784
At time: 832.7780067920685 and batch: 800, loss is 3.7402612495422365 and perplexity is 42.10898968240347
At time: 834.0025722980499 and batch: 850, loss is 3.731096887588501 and perplexity is 41.7248505430118
At time: 835.2273750305176 and batch: 900, loss is 3.712764720916748 and perplexity is 40.96691218116287
At time: 836.4525990486145 and batch: 950, loss is 3.821095781326294 and perplexity is 45.654207950054115
At time: 837.6767265796661 and batch: 1000, loss is 3.792367238998413 and perplexity is 44.361289853012835
At time: 838.900705575943 and batch: 1050, loss is 3.731124858856201 and perplexity is 41.726017656298836
At time: 840.1261072158813 and batch: 1100, loss is 3.74857798576355 and perplexity is 42.460659387199115
At time: 841.350044965744 and batch: 1150, loss is 3.7189877939224245 and perplexity is 41.222647169923476
At time: 842.615067243576 and batch: 1200, loss is 3.7681719350814817 and perplexity is 43.30083570122705
At time: 843.83962225914 and batch: 1250, loss is 3.7406862497329714 and perplexity is 42.12688981456049
At time: 845.06378698349 and batch: 1300, loss is 3.7307722663879392 and perplexity is 41.71130797015732
At time: 846.2887766361237 and batch: 1350, loss is 3.6086499738693236 and perplexity is 36.916181349040045
At time: 847.5130095481873 and batch: 1400, loss is 3.6374525022506714 and perplexity is 37.99492135532983
At time: 848.7381865978241 and batch: 1450, loss is 3.553766174316406 and perplexity is 34.94467771728583
At time: 849.9618065357208 and batch: 1500, loss is 3.547977590560913 and perplexity is 34.74298185340796
At time: 851.1867182254791 and batch: 1550, loss is 3.5606699419021606 and perplexity is 35.18676233706143
At time: 852.410537481308 and batch: 1600, loss is 3.6589677143096924 and perplexity is 38.82124756164798
At time: 853.6341741085052 and batch: 1650, loss is 3.597351942062378 and perplexity is 36.50144840253571
At time: 854.8579030036926 and batch: 1700, loss is 3.617931776046753 and perplexity is 37.260425171565345
At time: 856.0822989940643 and batch: 1750, loss is 3.6183481216430664 and perplexity is 37.27594161537967
At time: 857.3070335388184 and batch: 1800, loss is 3.5600192165374756 and perplexity is 35.1638728664948
At time: 858.5329349040985 and batch: 1850, loss is 3.578819999694824 and perplexity is 35.83123502326686
At time: 859.7581605911255 and batch: 1900, loss is 3.668263578414917 and perplexity is 39.18380714486343
At time: 860.9870095252991 and batch: 1950, loss is 3.610299406051636 and perplexity is 36.977122331797844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357584540788517 and perplexity of 78.06833561658055
finished 17 epochs...
Completing Train Step...
At time: 864.9142713546753 and batch: 50, loss is 3.841575231552124 and perplexity is 46.59882058852167
At time: 866.1667587757111 and batch: 100, loss is 3.8206640815734865 and perplexity is 45.634503293321195
At time: 867.3887734413147 and batch: 150, loss is 3.79021737575531 and perplexity is 44.266021590102994
At time: 868.6111767292023 and batch: 200, loss is 3.7862600231170656 and perplexity is 44.09119149311413
At time: 869.8334333896637 and batch: 250, loss is 3.777785840034485 and perplexity is 43.71913333505724
At time: 871.0569639205933 and batch: 300, loss is 3.7850453567504885 and perplexity is 44.03766791896859
At time: 872.2801141738892 and batch: 350, loss is 3.8080341911315916 and perplexity is 45.061768915825006
At time: 873.5032734870911 and batch: 400, loss is 3.7817362213134764 and perplexity is 43.892182160294674
At time: 874.756514787674 and batch: 450, loss is 3.8077809762954713 and perplexity is 45.050360051901464
At time: 875.9851596355438 and batch: 500, loss is 3.8309113025665282 and perplexity is 46.104534276172146
At time: 877.2088067531586 and batch: 550, loss is 3.792492904663086 and perplexity is 44.366864894276254
At time: 878.4312767982483 and batch: 600, loss is 3.765132784843445 and perplexity is 43.16943772632919
At time: 879.6536929607391 and batch: 650, loss is 3.7854283046722412 and perplexity is 44.05453528183164
At time: 880.877037525177 and batch: 700, loss is 3.810424814224243 and perplexity is 45.169623489641864
At time: 882.1007478237152 and batch: 750, loss is 3.7719935464859007 and perplexity is 43.466631270099114
At time: 883.3243081569672 and batch: 800, loss is 3.738221735954285 and perplexity is 42.02319534486916
At time: 884.5463855266571 and batch: 850, loss is 3.72919132232666 and perplexity is 41.645416824365476
At time: 885.7730157375336 and batch: 900, loss is 3.710882053375244 and perplexity is 40.8898576621043
At time: 886.9971709251404 and batch: 950, loss is 3.8192117738723756 and perplexity is 45.568276055556176
At time: 888.221048116684 and batch: 1000, loss is 3.790492744445801 and perplexity is 44.27821274495564
At time: 889.4451324939728 and batch: 1050, loss is 3.729327983856201 and perplexity is 41.65110853963746
At time: 890.6704115867615 and batch: 1100, loss is 3.7467869758605956 and perplexity is 42.384679985990694
At time: 891.8940370082855 and batch: 1150, loss is 3.717355742454529 and perplexity is 41.1554245584013
At time: 893.1192462444305 and batch: 1200, loss is 3.766659684181213 and perplexity is 43.23540346090742
At time: 894.3442754745483 and batch: 1250, loss is 3.7392771100997924 and perplexity is 42.06756895000689
At time: 895.5678145885468 and batch: 1300, loss is 3.7294763708114624 and perplexity is 41.657289479391
At time: 896.791202545166 and batch: 1350, loss is 3.6075675535202025 and perplexity is 36.8762441414584
At time: 898.0141055583954 and batch: 1400, loss is 3.6364227724075318 and perplexity is 37.95581698784494
At time: 899.2383458614349 and batch: 1450, loss is 3.5530566787719726 and perplexity is 34.9198934173586
At time: 900.462278842926 and batch: 1500, loss is 3.547476305961609 and perplexity is 34.725570096158435
At time: 901.6849043369293 and batch: 1550, loss is 3.560444221496582 and perplexity is 35.17882086310579
At time: 902.9071798324585 and batch: 1600, loss is 3.6587885665893554 and perplexity is 38.8142934465722
At time: 904.1296858787537 and batch: 1650, loss is 3.5973862314224245 and perplexity is 36.502700035300926
At time: 905.3549966812134 and batch: 1700, loss is 3.6180421113967896 and perplexity is 37.264536540429646
At time: 906.5816051959991 and batch: 1750, loss is 3.6184379196166994 and perplexity is 37.27928906969705
At time: 907.8046295642853 and batch: 1800, loss is 3.5601259374618532 and perplexity is 35.167625787765864
At time: 909.0283205509186 and batch: 1850, loss is 3.5789848661422727 and perplexity is 35.83714287868304
At time: 910.2518804073334 and batch: 1900, loss is 3.6683124256134034 and perplexity is 39.185721210816496
At time: 911.4740726947784 and batch: 1950, loss is 3.610188698768616 and perplexity is 36.97302892163993
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357419036155523 and perplexity of 78.05541601450237
finished 18 epochs...
Completing Train Step...
At time: 915.4650945663452 and batch: 50, loss is 3.8396752166748045 and perplexity is 46.51036619508014
At time: 916.690042257309 and batch: 100, loss is 3.8185180234909057 and perplexity is 45.536674009892806
At time: 917.9101977348328 and batch: 150, loss is 3.7878647947311403 and perplexity is 44.16200458987978
At time: 919.1555821895599 and batch: 200, loss is 3.783827848434448 and perplexity is 43.984084317917194
At time: 920.3937258720398 and batch: 250, loss is 3.7752497673034666 and perplexity is 43.60839890781367
At time: 921.6314883232117 and batch: 300, loss is 3.7824935722351074 and perplexity is 43.92543653593268
At time: 922.866367816925 and batch: 350, loss is 3.8054087066650393 and perplexity is 44.94361511485686
At time: 924.0915176868439 and batch: 400, loss is 3.7789878940582273 and perplexity is 43.77171769348526
At time: 925.3150839805603 and batch: 450, loss is 3.805251092910767 and perplexity is 44.93653194116549
At time: 926.5393173694611 and batch: 500, loss is 3.8284179544448853 and perplexity is 45.98972281418681
At time: 927.7637004852295 and batch: 550, loss is 3.7900900650024414 and perplexity is 44.260386408285086
At time: 928.9880895614624 and batch: 600, loss is 3.7628230667114257 and perplexity is 43.06984355477179
At time: 930.2117006778717 and batch: 650, loss is 3.783209857940674 and perplexity is 43.956910969231764
At time: 931.4346299171448 and batch: 700, loss is 3.808341727256775 and perplexity is 45.075629168786286
At time: 932.6583724021912 and batch: 750, loss is 3.7700466680526734 and perplexity is 43.38208934624196
At time: 933.8823056221008 and batch: 800, loss is 3.736403799057007 and perplexity is 41.94686922656437
At time: 935.106611251831 and batch: 850, loss is 3.7274771404266356 and perplexity is 41.57409015553416
At time: 936.3622965812683 and batch: 900, loss is 3.709183111190796 and perplexity is 40.820447136936274
At time: 937.5853180885315 and batch: 950, loss is 3.8175113201141357 and perplexity is 45.49085515326861
At time: 938.8110592365265 and batch: 1000, loss is 3.7887996673583983 and perplexity is 44.20330974365617
At time: 940.0342764854431 and batch: 1050, loss is 3.7277142238616943 and perplexity is 41.58394785213979
At time: 941.2569408416748 and batch: 1100, loss is 3.7451670789718627 and perplexity is 42.316076754833425
At time: 942.4815621376038 and batch: 1150, loss is 3.715867295265198 and perplexity is 41.09421244918873
At time: 943.7061655521393 and batch: 1200, loss is 3.7652675437927248 and perplexity is 43.175255586393746
At time: 944.9316084384918 and batch: 1250, loss is 3.7380034589767455 and perplexity is 42.01402364982409
At time: 946.1552724838257 and batch: 1300, loss is 3.7283039808273317 and perplexity is 41.60847950819077
At time: 947.3785328865051 and batch: 1350, loss is 3.6065618801116943 and perplexity is 36.839177324999554
At time: 948.6021101474762 and batch: 1400, loss is 3.635456681251526 and perplexity is 37.91916591572296
At time: 949.8256566524506 and batch: 1450, loss is 3.5523380756378176 and perplexity is 34.89480888649523
At time: 951.0475511550903 and batch: 1500, loss is 3.5469043970108034 and perplexity is 34.705715909733236
At time: 952.2698307037354 and batch: 1550, loss is 3.560082025527954 and perplexity is 35.166081543212506
At time: 953.4914124011993 and batch: 1600, loss is 3.658458557128906 and perplexity is 38.801486475861154
At time: 954.7138066291809 and batch: 1650, loss is 3.5972032070159914 and perplexity is 36.49601976163896
At time: 955.9363098144531 and batch: 1700, loss is 3.6179095792770384 and perplexity is 37.25959811966731
At time: 957.1600952148438 and batch: 1750, loss is 3.618273386955261 and perplexity is 37.273155913615966
At time: 958.3831820487976 and batch: 1800, loss is 3.559993929862976 and perplexity is 35.162983700329555
At time: 959.6080005168915 and batch: 1850, loss is 3.578929042816162 and perplexity is 35.83514238600685
At time: 960.8319895267487 and batch: 1900, loss is 3.668184199333191 and perplexity is 39.180696893679816
At time: 962.0556967258453 and batch: 1950, loss is 3.609945387840271 and perplexity is 36.96403407396604
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.357367085301599 and perplexity of 78.0513610743167
finished 19 epochs...
Completing Train Step...
At time: 965.9885873794556 and batch: 50, loss is 3.8378391075134277 and perplexity is 46.425046437774235
At time: 967.2562963962555 and batch: 100, loss is 3.8165006923675535 and perplexity is 45.44490405647275
At time: 968.4810152053833 and batch: 150, loss is 3.7856885242462157 and perplexity is 44.0660006259231
At time: 969.7070600986481 and batch: 200, loss is 3.7816142797470094 and perplexity is 43.886830205165914
At time: 970.9318013191223 and batch: 250, loss is 3.7729588747024536 and perplexity is 43.50861109463728
At time: 972.1570270061493 and batch: 300, loss is 3.7801993036270143 and perplexity is 43.82477530190009
At time: 973.3828113079071 and batch: 350, loss is 3.8031148672103883 and perplexity is 44.84063982681312
At time: 974.608104467392 and batch: 400, loss is 3.7765495777130127 and perplexity is 43.665118412973634
At time: 975.8328564167023 and batch: 450, loss is 3.80299458026886 and perplexity is 44.835246407777625
At time: 977.0580317974091 and batch: 500, loss is 3.8261805534362794 and perplexity is 45.88694038760638
At time: 978.283497095108 and batch: 550, loss is 3.7879323053359983 and perplexity is 44.16498609416183
At time: 979.5074088573456 and batch: 600, loss is 3.760746431350708 and perplexity is 42.98049599792199
At time: 980.7327861785889 and batch: 650, loss is 3.7812131309509276 and perplexity is 43.869228586735325
At time: 981.9589884281158 and batch: 700, loss is 3.806456136703491 and perplexity is 44.99071507001254
At time: 983.1822476387024 and batch: 750, loss is 3.768272671699524 and perplexity is 43.30519790068692
At time: 984.4022266864777 and batch: 800, loss is 3.7347134494781495 and perplexity is 41.87602424709213
At time: 985.6271390914917 and batch: 850, loss is 3.725875525474548 and perplexity is 41.50755776497962
At time: 986.8507776260376 and batch: 900, loss is 3.70759081363678 and perplexity is 40.75550055966654
At time: 988.0765306949615 and batch: 950, loss is 3.8159092473983764 and perplexity is 45.418033843503245
At time: 989.3023099899292 and batch: 1000, loss is 3.7872090482711793 and perplexity is 44.13305500453661
At time: 990.5268728733063 and batch: 1050, loss is 3.7262079334259033 and perplexity is 41.5213575006659
At time: 991.7533552646637 and batch: 1100, loss is 3.7436493015289307 and perplexity is 42.25189908409228
At time: 992.9783744812012 and batch: 1150, loss is 3.7144653511047365 and perplexity is 41.03664102340839
At time: 994.2043733596802 and batch: 1200, loss is 3.7639448070526123 and perplexity is 43.11818384333277
At time: 995.4299342632294 and batch: 1250, loss is 3.7367992925643922 and perplexity is 41.96346222199331
At time: 996.6558668613434 and batch: 1300, loss is 3.7271907901763917 and perplexity is 41.56218710871601
At time: 997.8809397220612 and batch: 1350, loss is 3.60558753490448 and perplexity is 36.803300730067676
At time: 999.1063194274902 and batch: 1400, loss is 3.634511504173279 and perplexity is 37.88334252166557
At time: 1000.331794500351 and batch: 1450, loss is 3.5516011142730712 and perplexity is 34.86910223408396
At time: 1001.5578243732452 and batch: 1500, loss is 3.546277709007263 and perplexity is 34.68397306761909
At time: 1002.7836275100708 and batch: 1550, loss is 3.5596238470077513 and perplexity is 35.149972890610826
At time: 1004.007937669754 and batch: 1600, loss is 3.6580299711227418 and perplexity is 38.78486026487441
At time: 1005.232745885849 and batch: 1650, loss is 3.59688823223114 and perplexity is 36.484526245845466
At time: 1006.4591288566589 and batch: 1700, loss is 3.6176337575912476 and perplexity is 37.2493225316822
At time: 1007.6841614246368 and batch: 1750, loss is 3.617974615097046 and perplexity is 37.262021406983564
At time: 1008.9082038402557 and batch: 1800, loss is 3.5597331857681276 and perplexity is 35.15381635518994
At time: 1010.1331253051758 and batch: 1850, loss is 3.5787521028518676 and perplexity is 35.828802278118346
At time: 1011.3579525947571 and batch: 1900, loss is 3.6679641675949095 and perplexity is 39.172076845212125
At time: 1012.5835628509521 and batch: 1950, loss is 3.6096365642547608 and perplexity is 36.952620470914006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3573792923328485 and perplexity of 78.05231385553573
Annealing...
Finished Training.
Improved accuracyfrom -10000000 to -78.0513610743167
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f8261144b38>
ELAPSED
1054.5023107528687


RESULTS SO FAR:
[{'best_accuracy': -78.0513610743167, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.02990420607447708, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.45043527467939715}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8251140117645264 and batch: 50, loss is 7.386705188751221 and perplexity is 1614.3782689530487
At time: 3.1187663078308105 and batch: 100, loss is 6.464737377166748 and perplexity is 642.0957123060031
At time: 4.410585403442383 and batch: 150, loss is 6.109778127670288 and perplexity is 450.2388085513938
At time: 5.70598578453064 and batch: 200, loss is 5.957392597198487 and perplexity is 386.6007849628143
At time: 7.000152349472046 and batch: 250, loss is 5.855816736221313 and perplexity is 349.2600369201417
At time: 8.29348611831665 and batch: 300, loss is 5.760949153900146 and perplexity is 317.6496843156492
At time: 9.589096307754517 and batch: 350, loss is 5.703702182769775 and perplexity is 299.9759134010644
At time: 10.894001960754395 and batch: 400, loss is 5.625277032852173 and perplexity is 277.34910869586247
At time: 12.227113485336304 and batch: 450, loss is 5.545569076538086 and perplexity is 256.1002774416307
At time: 13.53243637084961 and batch: 500, loss is 5.504162044525146 and perplexity is 245.712473276612
At time: 14.83666467666626 and batch: 550, loss is 5.438218278884888 and perplexity is 230.03196531224688
At time: 16.14050817489624 and batch: 600, loss is 5.463743696212768 and perplexity is 235.97920723619566
At time: 17.44388175010681 and batch: 650, loss is 5.5184721088409425 and perplexity is 249.25391325546843
At time: 18.748085737228394 and batch: 700, loss is 5.446309881210327 and perplexity is 231.90084340997
At time: 20.052167892456055 and batch: 750, loss is 5.386869335174561 and perplexity is 218.51820631807365
At time: 21.355868101119995 and batch: 800, loss is 5.364368715286255 and perplexity is 213.65631413367356
At time: 22.6596896648407 and batch: 850, loss is 5.36570032119751 and perplexity is 213.94100965360164
At time: 23.964240550994873 and batch: 900, loss is 5.370987462997436 and perplexity is 215.07514162478864
At time: 25.26798105239868 and batch: 950, loss is 5.408450241088867 and perplexity is 223.28528104993262
At time: 26.571685314178467 and batch: 1000, loss is 5.362514200210572 and perplexity is 213.26045245727596
At time: 27.876813173294067 and batch: 1050, loss is 5.26753005027771 and perplexity is 193.93635733701944
At time: 29.18061089515686 and batch: 1100, loss is 5.346090774536133 and perplexity is 209.78658971341875
At time: 30.48458957672119 and batch: 1150, loss is 5.2545621299743654 and perplexity is 191.43764269399946
At time: 31.78784966468811 and batch: 1200, loss is 5.322256460189819 and perplexity is 204.84558679948168
At time: 33.09174656867981 and batch: 1250, loss is 5.263105297088623 and perplexity is 193.0801325101411
At time: 34.39534258842468 and batch: 1300, loss is 5.274616804122925 and perplexity is 195.31561803117822
At time: 35.70725226402283 and batch: 1350, loss is 5.211035203933716 and perplexity is 183.28369602297835
At time: 37.01020336151123 and batch: 1400, loss is 5.237914800643921 and perplexity is 188.27709751878743
At time: 38.31303644180298 and batch: 1450, loss is 5.176822671890259 and perplexity is 177.11915034498745
At time: 39.61668157577515 and batch: 1500, loss is 5.141726598739624 and perplexity is 171.01078056233274
At time: 40.92106103897095 and batch: 1550, loss is 5.1316999816894535 and perplexity is 169.30468841369338
At time: 42.22655916213989 and batch: 1600, loss is 5.174634475708007 and perplexity is 176.7320026284551
At time: 43.530168771743774 and batch: 1650, loss is 5.1454616355896 and perplexity is 171.6507064589383
At time: 44.83367562294006 and batch: 1700, loss is 5.163899002075195 and perplexity is 174.84484874411396
At time: 46.13898992538452 and batch: 1750, loss is 5.173558988571167 and perplexity is 176.5420318068588
At time: 47.44304966926575 and batch: 1800, loss is 5.140573587417602 and perplexity is 170.8137168263479
At time: 48.7478563785553 and batch: 1850, loss is 5.125276575088501 and perplexity is 168.22066086268725
At time: 50.052186012268066 and batch: 1900, loss is 5.166042041778565 and perplexity is 175.21994998176672
At time: 51.35582613945007 and batch: 1950, loss is 5.080527744293213 and perplexity is 160.8589259119752
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.833809502180233 and perplexity of 125.68886178711756
finished 1 epochs...
Completing Train Step...
At time: 55.313424587249756 and batch: 50, loss is 5.035153341293335 and perplexity is 153.7231629132628
At time: 56.5672025680542 and batch: 100, loss is 4.966105127334595 and perplexity is 143.46701201360497
At time: 57.79150748252869 and batch: 150, loss is 4.898818702697754 and perplexity is 134.13123719182082
At time: 59.017608880996704 and batch: 200, loss is 4.86851375579834 and perplexity is 130.1273720524446
At time: 60.24285840988159 and batch: 250, loss is 4.883848628997803 and perplexity is 132.13823758076902
At time: 61.468942165374756 and batch: 300, loss is 4.896118030548096 and perplexity is 133.76948140690044
At time: 62.69536757469177 and batch: 350, loss is 4.895097856521606 and perplexity is 133.63308284339777
At time: 63.92136359214783 and batch: 400, loss is 4.8526682281494145 and perplexity is 128.08168547484908
At time: 65.14655494689941 and batch: 450, loss is 4.8293486595153805 and perplexity is 125.12943224123318
At time: 66.37267422676086 and batch: 500, loss is 4.835162134170532 and perplexity is 125.85898759526162
At time: 67.5982449054718 and batch: 550, loss is 4.780745248794556 and perplexity is 119.19314550135489
At time: 68.82399463653564 and batch: 600, loss is 4.764144849777222 and perplexity is 117.23082444555628
At time: 70.05007863044739 and batch: 650, loss is 4.821807918548584 and perplexity is 124.18941228322416
At time: 71.27620816230774 and batch: 700, loss is 4.826912050247192 and perplexity is 124.82491185617044
At time: 72.50241255760193 and batch: 750, loss is 4.788092470169067 and perplexity is 120.07210894318251
At time: 73.72759079933167 and batch: 800, loss is 4.762611417770386 and perplexity is 117.05119670582467
At time: 74.95285654067993 and batch: 850, loss is 4.765051069259644 and perplexity is 117.33710945410823
At time: 76.17793202400208 and batch: 900, loss is 4.770584688186646 and perplexity is 117.98820810830446
At time: 77.4026620388031 and batch: 950, loss is 4.826777191162109 and perplexity is 124.80807921780455
At time: 78.62856435775757 and batch: 1000, loss is 4.79978726387024 and perplexity is 121.48457061216929
At time: 79.85497999191284 and batch: 1050, loss is 4.724822597503662 and perplexity is 112.71050147604646
At time: 81.0805881023407 and batch: 1100, loss is 4.7878961086273195 and perplexity is 120.04853371345953
At time: 82.30612182617188 and batch: 1150, loss is 4.7153106212615965 and perplexity is 111.64348462831742
At time: 83.53196716308594 and batch: 1200, loss is 4.7949750614166256 and perplexity is 120.90136663664579
At time: 84.79932260513306 and batch: 1250, loss is 4.7481701374053955 and perplexity is 115.37297456147077
At time: 86.0266284942627 and batch: 1300, loss is 4.772223701477051 and perplexity is 118.18175091579474
At time: 87.25152635574341 and batch: 1350, loss is 4.663358249664307 and perplexity is 105.99143083492676
At time: 88.4783570766449 and batch: 1400, loss is 4.688107271194458 and perplexity is 108.64734511449473
At time: 89.70432424545288 and batch: 1450, loss is 4.619812898635864 and perplexity is 101.47504423406848
At time: 90.93000411987305 and batch: 1500, loss is 4.603904609680176 and perplexity is 99.87352241960447
At time: 92.15719318389893 and batch: 1550, loss is 4.599025764465332 and perplexity is 99.38744168318202
At time: 93.38289284706116 and batch: 1600, loss is 4.685195007324219 and perplexity is 108.33139566410965
At time: 94.60922980308533 and batch: 1650, loss is 4.636051874160767 and perplexity is 103.1363474170621
At time: 95.83490085601807 and batch: 1700, loss is 4.664071826934815 and perplexity is 106.06709090228091
At time: 97.06114745140076 and batch: 1750, loss is 4.671990947723389 and perplexity is 106.9103836683895
At time: 98.28784203529358 and batch: 1800, loss is 4.612325792312622 and perplexity is 100.71812688492574
At time: 99.5147020816803 and batch: 1850, loss is 4.638195934295655 and perplexity is 103.35771517610843
At time: 100.74128794670105 and batch: 1900, loss is 4.71472804069519 and perplexity is 111.57846224603429
At time: 101.96732473373413 and batch: 1950, loss is 4.642599096298218 and perplexity is 103.81381935362964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.58115603424782 and perplexity of 97.62718937138746
finished 2 epochs...
Completing Train Step...
At time: 105.89165759086609 and batch: 50, loss is 4.615852003097534 and perplexity is 101.07390713961671
At time: 107.14953303337097 and batch: 100, loss is 4.5589985847473145 and perplexity is 95.4878089865758
At time: 108.37573909759521 and batch: 150, loss is 4.5117590045928955 and perplexity is 91.08189114986452
At time: 109.60324001312256 and batch: 200, loss is 4.499836311340332 and perplexity is 90.00239772284479
At time: 110.82911229133606 and batch: 250, loss is 4.510645704269409 and perplexity is 90.98054607520342
At time: 112.05500435829163 and batch: 300, loss is 4.533513326644897 and perplexity is 93.08502535831566
At time: 113.28091239929199 and batch: 350, loss is 4.542729587554931 and perplexity is 93.94688670787309
At time: 114.5339105129242 and batch: 400, loss is 4.500383682250977 and perplexity is 90.05167590273726
At time: 115.76057362556458 and batch: 450, loss is 4.502979431152344 and perplexity is 90.28573108434806
At time: 116.988520860672 and batch: 500, loss is 4.520137090682983 and perplexity is 91.84818864601766
At time: 118.21605825424194 and batch: 550, loss is 4.46590087890625 and perplexity is 86.999370144175
At time: 119.44292616844177 and batch: 600, loss is 4.445637979507446 and perplexity is 85.25425095604322
At time: 120.66938495635986 and batch: 650, loss is 4.497357006072998 and perplexity is 89.77953069595746
At time: 121.89548802375793 and batch: 700, loss is 4.526344833374023 and perplexity is 92.42013196956067
At time: 123.1226851940155 and batch: 750, loss is 4.486385383605957 and perplexity is 88.79988754444675
At time: 124.34941053390503 and batch: 800, loss is 4.463761234283448 and perplexity is 86.81342141270116
At time: 125.57651019096375 and batch: 850, loss is 4.462194900512696 and perplexity is 86.67754905749628
At time: 126.80386304855347 and batch: 900, loss is 4.458532762527466 and perplexity is 86.360704431104
At time: 128.03124523162842 and batch: 950, loss is 4.527958869934082 and perplexity is 92.56942188872904
At time: 129.25868940353394 and batch: 1000, loss is 4.505759124755859 and perplexity is 90.5370468821697
At time: 130.4847273826599 and batch: 1050, loss is 4.443867177963257 and perplexity is 85.10341618543875
At time: 131.71282839775085 and batch: 1100, loss is 4.499060392379761 and perplexity is 89.93259024193105
At time: 132.93981742858887 and batch: 1150, loss is 4.436049022674561 and perplexity is 84.44065860876705
At time: 134.16691493988037 and batch: 1200, loss is 4.5130191421508785 and perplexity is 91.19673920873309
At time: 135.39516353607178 and batch: 1250, loss is 4.488919639587403 and perplexity is 89.02521458821617
At time: 136.62088298797607 and batch: 1300, loss is 4.500181703567505 and perplexity is 90.0334892205169
At time: 137.84821891784668 and batch: 1350, loss is 4.373382434844971 and perplexity is 79.31144430771302
At time: 139.07469367980957 and batch: 1400, loss is 4.40745065689087 and perplexity is 82.05999752809267
At time: 140.301687002182 and batch: 1450, loss is 4.334019646644593 and perplexity is 76.2501701259165
At time: 141.52688455581665 and batch: 1500, loss is 4.332194843292236 and perplexity is 76.1111554356649
At time: 142.7536871433258 and batch: 1550, loss is 4.333746671676636 and perplexity is 76.2293585788146
At time: 143.98018836975098 and batch: 1600, loss is 4.426500825881958 and perplexity is 83.63823950706048
At time: 145.20691466331482 and batch: 1650, loss is 4.373640007972718 and perplexity is 79.33187543563126
At time: 146.43422269821167 and batch: 1700, loss is 4.401611394882202 and perplexity is 81.58222398210566
At time: 147.66113018989563 and batch: 1750, loss is 4.408128108978271 and perplexity is 82.11560807932544
At time: 148.8889856338501 and batch: 1800, loss is 4.351255111694336 and perplexity is 77.57576810179623
At time: 150.11705374717712 and batch: 1850, loss is 4.388990497589111 and perplexity is 80.55905335940638
At time: 151.34409308433533 and batch: 1900, loss is 4.4738821697235105 and perplexity is 87.69651577850314
At time: 152.57077860832214 and batch: 1950, loss is 4.398500938415527 and perplexity is 81.32886026862843
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.510805209847383 and perplexity of 90.99505913721595
finished 3 epochs...
Completing Train Step...
At time: 156.5389142036438 and batch: 50, loss is 4.375124678611756 and perplexity is 79.44974461863694
At time: 157.76476097106934 and batch: 100, loss is 4.328229656219483 and perplexity is 75.80995801273941
At time: 158.9902048110962 and batch: 150, loss is 4.291629142761231 and perplexity is 73.08543817658237
At time: 160.21690344810486 and batch: 200, loss is 4.283886823654175 and perplexity is 72.52177224855569
At time: 161.44208240509033 and batch: 250, loss is 4.291785717010498 and perplexity is 73.09688237010687
At time: 162.66891169548035 and batch: 300, loss is 4.31016881942749 and perplexity is 74.45305700190708
At time: 163.89553046226501 and batch: 350, loss is 4.3218059062957765 and perplexity is 75.32453458930951
At time: 165.12176966667175 and batch: 400, loss is 4.2832035446167 and perplexity is 72.4722365670913
At time: 166.34821796417236 and batch: 450, loss is 4.2972333621978756 and perplexity is 73.4961748640013
At time: 167.57507252693176 and batch: 500, loss is 4.314305095672608 and perplexity is 74.76165319253148
At time: 168.80149936676025 and batch: 550, loss is 4.262777366638184 and perplexity is 71.00692209878846
At time: 170.02724266052246 and batch: 600, loss is 4.243374066352844 and perplexity is 69.64243406171364
At time: 171.25353837013245 and batch: 650, loss is 4.300834965705872 and perplexity is 73.76135619757545
At time: 172.47827339172363 and batch: 700, loss is 4.329053597450256 and perplexity is 75.87244670281825
At time: 173.70543217658997 and batch: 750, loss is 4.294704661369324 and perplexity is 73.31055980710838
At time: 174.93134474754333 and batch: 800, loss is 4.2653315782547 and perplexity is 71.18852062587096
At time: 176.18435287475586 and batch: 850, loss is 4.2672781562805175 and perplexity is 71.32722959592903
At time: 177.41084170341492 and batch: 900, loss is 4.257827010154724 and perplexity is 70.65628113655445
At time: 178.63727736473083 and batch: 950, loss is 4.332853212356567 and perplexity is 76.16128116465826
At time: 179.86383414268494 and batch: 1000, loss is 4.320676031112671 and perplexity is 75.23947532922064
At time: 181.08910036087036 and batch: 1050, loss is 4.261116533279419 and perplexity is 70.88908931126126
At time: 182.3161494731903 and batch: 1100, loss is 4.30820032119751 and perplexity is 74.30664044862534
At time: 183.54249358177185 and batch: 1150, loss is 4.255960583686829 and perplexity is 70.52452937405344
At time: 184.76870441436768 and batch: 1200, loss is 4.328201146125793 and perplexity is 75.80779669454371
At time: 185.99641919136047 and batch: 1250, loss is 4.3107993698120115 and perplexity is 74.5000182097763
At time: 187.22240257263184 and batch: 1300, loss is 4.312946767807007 and perplexity is 74.66017129417017
At time: 188.44877195358276 and batch: 1350, loss is 4.184815821647644 and perplexity is 65.6814027101264
At time: 189.67576599121094 and batch: 1400, loss is 4.21840615272522 and perplexity is 67.92513567440051
At time: 190.90120935440063 and batch: 1450, loss is 4.148748393058777 and perplexity is 63.35465552763133
At time: 192.12772393226624 and batch: 1500, loss is 4.147738308906555 and perplexity is 63.29069430266137
At time: 193.3547966480255 and batch: 1550, loss is 4.155021734237671 and perplexity is 63.75335016322
At time: 194.58087873458862 and batch: 1600, loss is 4.252619466781616 and perplexity is 70.28929187355534
At time: 195.80781245231628 and batch: 1650, loss is 4.19511004447937 and perplexity is 66.36103384092007
At time: 197.03460264205933 and batch: 1700, loss is 4.226147804260254 and perplexity is 68.45302915241408
At time: 198.26206851005554 and batch: 1750, loss is 4.23749577999115 and perplexity is 69.23425675826586
At time: 199.48973417282104 and batch: 1800, loss is 4.173792591094971 and perplexity is 64.96135736907222
At time: 200.71684503555298 and batch: 1850, loss is 4.216131205558777 and perplexity is 67.7707852156058
At time: 201.94380450248718 and batch: 1900, loss is 4.303004789352417 and perplexity is 73.92157909730989
At time: 203.17066645622253 and batch: 1950, loss is 4.226379175186157 and perplexity is 68.46886902552231
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.479328386173692 and perplexity of 88.17543294486062
finished 4 epochs...
Completing Train Step...
At time: 207.1518337726593 and batch: 50, loss is 4.204184737205505 and perplexity is 66.96598053324594
At time: 208.3800346851349 and batch: 100, loss is 4.160050849914551 and perplexity is 64.07478071422271
At time: 209.60692930221558 and batch: 150, loss is 4.126895270347595 and perplexity is 61.985176661064955
At time: 210.8333704471588 and batch: 200, loss is 4.126389036178589 and perplexity is 61.953805587891765
At time: 212.06008529663086 and batch: 250, loss is 4.125567321777344 and perplexity is 61.90291816395613
At time: 213.2872486114502 and batch: 300, loss is 4.147845335006714 and perplexity is 63.297468421346245
At time: 214.5149281024933 and batch: 350, loss is 4.160949506759644 and perplexity is 64.13238783514923
At time: 215.74213123321533 and batch: 400, loss is 4.124682559967041 and perplexity is 61.84817304778362
At time: 216.9694550037384 and batch: 450, loss is 4.145671491622925 and perplexity is 63.16001908919601
At time: 218.19722080230713 and batch: 500, loss is 4.166212449073791 and perplexity is 64.47080264046022
At time: 219.42329835891724 and batch: 550, loss is 4.121251783370972 and perplexity is 61.63634935084036
At time: 220.65054607391357 and batch: 600, loss is 4.093907122611999 and perplexity is 59.97375936315933
At time: 221.87788033485413 and batch: 650, loss is 4.14744731426239 and perplexity is 63.27227972899492
At time: 223.10344886779785 and batch: 700, loss is 4.179700889587402 and perplexity is 65.34630453043843
At time: 224.3309826850891 and batch: 750, loss is 4.147363739013672 and perplexity is 63.266991953446265
At time: 225.55820441246033 and batch: 800, loss is 4.119720816612244 and perplexity is 61.542058345469385
At time: 226.78559756278992 and batch: 850, loss is 4.123401889801025 and perplexity is 61.7690166351856
At time: 228.01316833496094 and batch: 900, loss is 4.107803874015808 and perplexity is 60.81301776406071
At time: 229.2387354373932 and batch: 950, loss is 4.18635778427124 and perplexity is 65.78275910197226
At time: 230.4660086631775 and batch: 1000, loss is 4.178361673355102 and perplexity is 65.25885027184255
At time: 231.69374537467957 and batch: 1050, loss is 4.119509291648865 and perplexity is 61.529042040516856
At time: 232.9211974143982 and batch: 1100, loss is 4.163288288116455 and perplexity is 64.28255500382319
At time: 234.14362978935242 and batch: 1150, loss is 4.113305726051331 and perplexity is 61.14852409640616
At time: 235.36653590202332 and batch: 1200, loss is 4.1887248468399045 and perplexity is 65.93865544411365
At time: 236.58858847618103 and batch: 1250, loss is 4.173574934005737 and perplexity is 64.94721960776238
At time: 237.81143403053284 and batch: 1300, loss is 4.166201810836792 and perplexity is 64.47011678843036
At time: 239.03448176383972 and batch: 1350, loss is 4.0395492792129515 and perplexity is 56.80073576276138
At time: 240.26105403900146 and batch: 1400, loss is 4.08218964099884 and perplexity is 59.27511908640255
At time: 241.4869728088379 and batch: 1450, loss is 4.007805233001709 and perplexity is 55.02596875607256
At time: 242.7138376235962 and batch: 1500, loss is 4.008215432167053 and perplexity is 55.04854499258868
At time: 243.94077014923096 and batch: 1550, loss is 4.020520386695861 and perplexity is 55.73009948451522
At time: 245.16746640205383 and batch: 1600, loss is 4.120381879806518 and perplexity is 61.582754985184756
At time: 246.39394617080688 and batch: 1650, loss is 4.0592415285110475 and perplexity is 57.93035588840086
At time: 247.61989045143127 and batch: 1700, loss is 4.08994649887085 and perplexity is 59.73669563798106
At time: 248.84738612174988 and batch: 1750, loss is 4.0971157836914065 and perplexity is 60.16650389117945
At time: 250.0741674900055 and batch: 1800, loss is 4.036010670661926 and perplexity is 56.60009539670824
At time: 251.30085611343384 and batch: 1850, loss is 4.080868515968323 and perplexity is 59.19686094866537
At time: 252.5277488231659 and batch: 1900, loss is 4.172163624763488 and perplexity is 64.85562364678808
At time: 253.7553906440735 and batch: 1950, loss is 4.098659892082214 and perplexity is 60.25947925823237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.462126691951308 and perplexity of 86.67163710819555
finished 5 epochs...
Completing Train Step...
At time: 257.7108187675476 and batch: 50, loss is 4.071949543952942 and perplexity is 58.671233315922976
At time: 258.9361267089844 and batch: 100, loss is 4.028185338973999 and perplexity is 56.15890934163258
At time: 260.1613144874573 and batch: 150, loss is 3.9951036548614502 and perplexity is 54.331472053153384
At time: 261.3871822357178 and batch: 200, loss is 4.002180638313294 and perplexity is 54.71733875746051
At time: 262.6122694015503 and batch: 250, loss is 4.002166800498962 and perplexity is 54.71658159432481
At time: 263.8367509841919 and batch: 300, loss is 4.018845376968383 and perplexity is 55.636829161921206
At time: 265.0618989467621 and batch: 350, loss is 4.030654392242432 and perplexity is 56.29773999991089
At time: 266.2859106063843 and batch: 400, loss is 3.9970983600616456 and perplexity is 54.43995548325323
At time: 267.53563952445984 and batch: 450, loss is 4.025818576812744 and perplexity is 56.026151724808386
At time: 268.7601342201233 and batch: 500, loss is 4.045757451057434 and perplexity is 57.154461349795554
At time: 269.98407435417175 and batch: 550, loss is 4.0045665788650515 and perplexity is 54.84804694386038
At time: 271.2095265388489 and batch: 600, loss is 3.974493455886841 and perplexity is 53.22315020298086
At time: 272.4358329772949 and batch: 650, loss is 4.031115660667419 and perplexity is 56.32371435988652
At time: 273.66155791282654 and batch: 700, loss is 4.061887111663818 and perplexity is 58.08381837134456
At time: 274.8874740600586 and batch: 750, loss is 4.028393840789795 and perplexity is 56.1706197969866
At time: 276.1120641231537 and batch: 800, loss is 4.000773787498474 and perplexity is 54.640413748538236
At time: 277.3358871936798 and batch: 850, loss is 4.003200788497924 and perplexity is 54.77318714272321
At time: 278.5613341331482 and batch: 900, loss is 3.99089964389801 and perplexity is 54.10354139617075
At time: 279.7850778102875 and batch: 950, loss is 4.073502335548401 and perplexity is 58.76240828345299
At time: 281.00997710227966 and batch: 1000, loss is 4.064395871162414 and perplexity is 58.22971964147337
At time: 282.2352135181427 and batch: 1050, loss is 4.009108057022095 and perplexity is 55.09770462937567
At time: 283.46027731895447 and batch: 1100, loss is 4.045601224899292 and perplexity is 57.145533025315245
At time: 284.6856141090393 and batch: 1150, loss is 4.0038462734222415 and perplexity is 54.808553822381946
At time: 285.9117286205292 and batch: 1200, loss is 4.0750464344024655 and perplexity is 58.853213338694644
At time: 287.13646697998047 and batch: 1250, loss is 4.060390787124634 and perplexity is 57.996971120626355
At time: 288.3616044521332 and batch: 1300, loss is 4.054555416107178 and perplexity is 57.65952280187118
At time: 289.5867748260498 and batch: 1350, loss is 3.923651943206787 and perplexity is 50.58484083702319
At time: 290.8118453025818 and batch: 1400, loss is 3.9735908842086793 and perplexity is 53.17513416720173
At time: 292.03595328330994 and batch: 1450, loss is 3.900553026199341 and perplexity is 49.4297775101625
At time: 293.2624216079712 and batch: 1500, loss is 3.9033541297912597 and perplexity is 49.56842953618062
At time: 294.4875211715698 and batch: 1550, loss is 3.9084628105163572 and perplexity is 49.82230675339504
At time: 295.7123477458954 and batch: 1600, loss is 4.014375891685486 and perplexity is 55.38871605476702
At time: 296.9377086162567 and batch: 1650, loss is 3.9510493087768555 and perplexity is 51.989891672773055
At time: 298.16364908218384 and batch: 1700, loss is 3.983554401397705 and perplexity is 53.70759371057323
At time: 299.39012241363525 and batch: 1750, loss is 3.984628982543945 and perplexity is 53.76533789803555
At time: 300.6153690814972 and batch: 1800, loss is 3.928575048446655 and perplexity is 50.834489350732156
At time: 301.839882850647 and batch: 1850, loss is 3.9725122833251953 and perplexity is 53.117810340831944
At time: 303.06509470939636 and batch: 1900, loss is 4.060955243110657 and perplexity is 58.02971709910894
At time: 304.2899272441864 and batch: 1950, loss is 3.987062635421753 and perplexity is 53.896343413653966
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.471418797692587 and perplexity of 87.48075249605054
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 308.2075455188751 and batch: 50, loss is 4.007279973030091 and perplexity is 54.99707340673502
At time: 309.45970368385315 and batch: 100, loss is 3.9869836664199827 and perplexity is 53.89208744126268
At time: 310.6863193511963 and batch: 150, loss is 3.9546205854415892 and perplexity is 52.17589389471389
At time: 311.9125599861145 and batch: 200, loss is 3.9575109910964965 and perplexity is 52.32692155393113
At time: 313.13929057121277 and batch: 250, loss is 3.959157166481018 and perplexity is 52.41313178325133
At time: 314.3666296005249 and batch: 300, loss is 3.967289729118347 and perplexity is 52.84112283361928
At time: 315.5945842266083 and batch: 350, loss is 3.9820320892333982 and perplexity is 53.62589618769579
At time: 316.82084345817566 and batch: 400, loss is 3.9401879358291625 and perplexity is 51.428265606102904
At time: 318.04813861846924 and batch: 450, loss is 3.9645403814315796 and perplexity is 52.69604374260878
At time: 319.27472472190857 and batch: 500, loss is 3.9849991369247437 and perplexity is 53.785243057157274
At time: 320.5008761882782 and batch: 550, loss is 3.933102459907532 and perplexity is 51.065159776377946
At time: 321.72803831100464 and batch: 600, loss is 3.884500117301941 and perplexity is 48.642620776488215
At time: 322.95434641838074 and batch: 650, loss is 3.938005313873291 and perplexity is 51.31613955334345
At time: 324.18107652664185 and batch: 700, loss is 3.9668584871292114 and perplexity is 52.81834043541678
At time: 325.40933656692505 and batch: 750, loss is 3.9183674669265747 and perplexity is 50.318231511247845
At time: 326.6350448131561 and batch: 800, loss is 3.88515043258667 and perplexity is 48.674264104223084
At time: 327.8610608577728 and batch: 850, loss is 3.886777629852295 and perplexity is 48.7535312077968
At time: 329.11523628234863 and batch: 900, loss is 3.8641172361373903 and perplexity is 47.66118028910197
At time: 330.3413026332855 and batch: 950, loss is 3.945134902000427 and perplexity is 51.683309823731456
At time: 331.56720781326294 and batch: 1000, loss is 3.913831615447998 and perplexity is 50.09051232707075
At time: 332.7940604686737 and batch: 1050, loss is 3.854443745613098 and perplexity is 47.202353121273596
At time: 334.0202157497406 and batch: 1100, loss is 3.878966770172119 and perplexity is 48.37420756701314
At time: 335.24614787101746 and batch: 1150, loss is 3.8396690464019776 and perplexity is 46.51007921431681
At time: 336.4724850654602 and batch: 1200, loss is 3.896836185455322 and perplexity is 49.246395910362445
At time: 337.6986949443817 and batch: 1250, loss is 3.8691648197174073 and perplexity is 47.90236226114309
At time: 338.9260756969452 and batch: 1300, loss is 3.8646113872528076 and perplexity is 47.68473793454295
At time: 340.1520278453827 and batch: 1350, loss is 3.7313875102996827 and perplexity is 41.73697849444397
At time: 341.37881684303284 and batch: 1400, loss is 3.762226390838623 and perplexity is 43.04415248366062
At time: 342.6050937175751 and batch: 1450, loss is 3.6854207420349123 and perplexity is 39.86189049502565
At time: 343.83151268959045 and batch: 1500, loss is 3.674578857421875 and perplexity is 39.43204684598509
At time: 345.0571892261505 and batch: 1550, loss is 3.682421636581421 and perplexity is 39.74251957431998
At time: 346.28278255462646 and batch: 1600, loss is 3.770794401168823 and perplexity is 43.41453970168468
At time: 347.50834465026855 and batch: 1650, loss is 3.700902471542358 and perplexity is 40.48382337742582
At time: 348.7335112094879 and batch: 1700, loss is 3.717752466201782 and perplexity is 41.17175513180085
At time: 349.95995926856995 and batch: 1750, loss is 3.7034930181503296 and perplexity is 40.58883456821908
At time: 351.1869602203369 and batch: 1800, loss is 3.6414477014541626 and perplexity is 38.14702226927582
At time: 352.4120862483978 and batch: 1850, loss is 3.6766439056396485 and perplexity is 39.51356005943839
At time: 353.63840317726135 and batch: 1900, loss is 3.757481822967529 and perplexity is 42.84041029726589
At time: 354.86480259895325 and batch: 1950, loss is 3.679216032028198 and perplexity is 39.615324749690565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.409629644349564 and perplexity of 82.23900018501394
finished 7 epochs...
Completing Train Step...
At time: 358.7801058292389 and batch: 50, loss is 3.8881465911865236 and perplexity is 48.820318611183524
At time: 360.03064155578613 and batch: 100, loss is 3.859747791290283 and perplexity is 47.453381703318925
At time: 361.25468492507935 and batch: 150, loss is 3.8258955574035642 and perplexity is 45.87386465499694
At time: 362.48003482818604 and batch: 200, loss is 3.82838698387146 and perplexity is 45.98829850815549
At time: 363.7048306465149 and batch: 250, loss is 3.8316391611099245 and perplexity is 46.138104070883266
At time: 364.92774534225464 and batch: 300, loss is 3.8356519746780395 and perplexity is 46.32361965168455
At time: 366.1512107849121 and batch: 350, loss is 3.8536289167404174 and perplexity is 47.16390694674561
At time: 367.3751723766327 and batch: 400, loss is 3.8171373271942137 and perplexity is 45.47384507654249
At time: 368.59972190856934 and batch: 450, loss is 3.8476013231277464 and perplexity is 46.88047714045754
At time: 369.82299733161926 and batch: 500, loss is 3.86813889503479 and perplexity is 47.85324324585702
At time: 371.04710149765015 and batch: 550, loss is 3.819925193786621 and perplexity is 45.6007969703068
At time: 372.2730522155762 and batch: 600, loss is 3.7774449682235716 and perplexity is 43.70423325455875
At time: 373.4973831176758 and batch: 650, loss is 3.8299947500228884 and perplexity is 46.06229640757783
At time: 374.72126269340515 and batch: 700, loss is 3.862473349571228 and perplexity is 47.58289507872969
At time: 375.946750164032 and batch: 750, loss is 3.817652897834778 and perplexity is 45.49729610078785
At time: 377.1696960926056 and batch: 800, loss is 3.7857647800445555 and perplexity is 44.069361042104454
At time: 378.3934712409973 and batch: 850, loss is 3.7914338397979734 and perplexity is 44.31990237905596
At time: 379.61796021461487 and batch: 900, loss is 3.770309610366821 and perplexity is 43.39349783302846
At time: 380.841322183609 and batch: 950, loss is 3.8531350326538085 and perplexity is 47.14061919484072
At time: 382.0650477409363 and batch: 1000, loss is 3.8260349369049074 and perplexity is 45.88025897698559
At time: 383.2899513244629 and batch: 1050, loss is 3.771905446052551 and perplexity is 43.4628020097302
At time: 384.5155165195465 and batch: 1100, loss is 3.796869010925293 and perplexity is 44.56144444945816
At time: 385.74007081985474 and batch: 1150, loss is 3.759529957771301 and perplexity is 42.928243148659675
At time: 386.9646418094635 and batch: 1200, loss is 3.8225368738174437 and perplexity is 45.7200473152334
At time: 388.18753385543823 and batch: 1250, loss is 3.7968806552886964 and perplexity is 44.56196334213219
At time: 389.41152334213257 and batch: 1300, loss is 3.794122657775879 and perplexity is 44.439230883773305
At time: 390.6367449760437 and batch: 1350, loss is 3.6624179792404177 and perplexity is 38.95542248709169
At time: 391.86037254333496 and batch: 1400, loss is 3.7001595067977906 and perplexity is 40.45375649463111
At time: 393.08495235443115 and batch: 1450, loss is 3.624745206832886 and perplexity is 37.51516333448286
At time: 394.3092312812805 and batch: 1500, loss is 3.6179138135910036 and perplexity is 37.25975588883799
At time: 395.533052444458 and batch: 1550, loss is 3.630173087120056 and perplexity is 37.719344784953805
At time: 396.757292509079 and batch: 1600, loss is 3.7212232398986815 and perplexity is 41.31490124675475
At time: 397.9812252521515 and batch: 1650, loss is 3.6554833698272704 and perplexity is 38.68621634615508
At time: 399.20400500297546 and batch: 1700, loss is 3.6765110683441162 and perplexity is 39.50831153359095
At time: 400.4274117946625 and batch: 1750, loss is 3.666087718009949 and perplexity is 39.098641338434575
At time: 401.652220249176 and batch: 1800, loss is 3.608739762306213 and perplexity is 36.91949614407221
At time: 402.87619709968567 and batch: 1850, loss is 3.649819264411926 and perplexity is 38.46771293599422
At time: 404.10012888908386 and batch: 1900, loss is 3.7367366313934327 and perplexity is 41.96083282469438
At time: 405.32477736473083 and batch: 1950, loss is 3.6605311822891236 and perplexity is 38.88199081182193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.416774448128634 and perplexity of 82.82868578976012
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 409.2431149482727 and batch: 50, loss is 3.84621169090271 and perplexity is 46.81537576266064
At time: 410.49820613861084 and batch: 100, loss is 3.853902106285095 and perplexity is 47.17679339315068
At time: 411.72360348701477 and batch: 150, loss is 3.832139935493469 and perplexity is 46.161214637614215
At time: 412.95183420181274 and batch: 200, loss is 3.8499215745925905 and perplexity is 46.989377925962614
At time: 414.17791056632996 and batch: 250, loss is 3.847187557220459 and perplexity is 46.86108360976706
At time: 415.40496301651 and batch: 300, loss is 3.8465498971939085 and perplexity is 46.83121169502342
At time: 416.6307988166809 and batch: 350, loss is 3.870817518234253 and perplexity is 47.98159588081337
At time: 417.85572957992554 and batch: 400, loss is 3.8336118602752687 and perplexity is 46.229210503520896
At time: 419.0818774700165 and batch: 450, loss is 3.8663965702056884 and perplexity is 47.76993994377613
At time: 420.3254301548004 and batch: 500, loss is 3.889382176399231 and perplexity is 48.88067755657034
At time: 421.58727073669434 and batch: 550, loss is 3.8557590675354003 and perplexity is 47.264480260755484
At time: 422.81515169143677 and batch: 600, loss is 3.795598449707031 and perplexity is 44.50486235942739
At time: 424.04326605796814 and batch: 650, loss is 3.8206077575683595 and perplexity is 45.631933047707676
At time: 425.2703995704651 and batch: 700, loss is 3.8565618324279787 and perplexity is 47.30243775961011
At time: 426.49903893470764 and batch: 750, loss is 3.8085239267349245 and perplexity is 45.08384267312349
At time: 427.7263386249542 and batch: 800, loss is 3.7721784019470217 and perplexity is 43.474667056972585
At time: 428.9535620212555 and batch: 850, loss is 3.777748293876648 and perplexity is 43.7174918803919
At time: 430.18085193634033 and batch: 900, loss is 3.752164936065674 and perplexity is 42.61323714303867
At time: 431.40697741508484 and batch: 950, loss is 3.8494073390960692 and perplexity is 46.96522053170079
At time: 432.6344795227051 and batch: 1000, loss is 3.815715684890747 and perplexity is 45.40924346575213
At time: 433.86164379119873 and batch: 1050, loss is 3.755542812347412 and perplexity is 42.7574227695792
At time: 435.08959341049194 and batch: 1100, loss is 3.771562933921814 and perplexity is 43.447918021924735
At time: 436.31660556793213 and batch: 1150, loss is 3.7301292848587035 and perplexity is 41.68449698997846
At time: 437.54431915283203 and batch: 1200, loss is 3.7880721569061278 and perplexity is 44.17116306873157
At time: 438.77135729789734 and batch: 1250, loss is 3.760281138420105 and perplexity is 42.960502128844034
At time: 439.9980220794678 and batch: 1300, loss is 3.7574931144714356 and perplexity is 42.84089403265717
At time: 441.22527027130127 and batch: 1350, loss is 3.624895634651184 and perplexity is 37.52080708313412
At time: 442.45154881477356 and batch: 1400, loss is 3.6511661863327025 and perplexity is 38.51956085149828
At time: 443.6789674758911 and batch: 1450, loss is 3.57083016872406 and perplexity is 35.546090158500334
At time: 444.9064555168152 and batch: 1500, loss is 3.5617953729629517 and perplexity is 35.22638490437607
At time: 446.13372111320496 and batch: 1550, loss is 3.572687702178955 and perplexity is 35.61217957280644
At time: 447.36094975471497 and batch: 1600, loss is 3.6563088512420654 and perplexity is 38.71816428315753
At time: 448.58840894699097 and batch: 1650, loss is 3.5920519161224367 and perplexity is 36.3085015424991
At time: 449.81650018692017 and batch: 1700, loss is 3.6038899564743043 and perplexity is 36.74087723996506
At time: 451.0434057712555 and batch: 1750, loss is 3.589590702056885 and perplexity is 36.219248428368324
At time: 452.27035188674927 and batch: 1800, loss is 3.53300142288208 and perplexity is 34.22654192942451
At time: 453.49720454216003 and batch: 1850, loss is 3.567386050224304 and perplexity is 35.423875792978464
At time: 454.7249743938446 and batch: 1900, loss is 3.66103497505188 and perplexity is 38.9015842124868
At time: 455.9518654346466 and batch: 1950, loss is 3.592065773010254 and perplexity is 36.309004668817664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.387857978288517 and perplexity of 80.46787031966143
finished 9 epochs...
Completing Train Step...
At time: 459.9546387195587 and batch: 50, loss is 3.838026371002197 and perplexity is 46.43374096799508
At time: 461.18162655830383 and batch: 100, loss is 3.82278666973114 and perplexity is 45.73146942276526
At time: 462.4099078178406 and batch: 150, loss is 3.7890238761901855 and perplexity is 44.21322162721932
At time: 463.63683009147644 and batch: 200, loss is 3.7966982173919677 and perplexity is 44.55383429281182
At time: 464.86420249938965 and batch: 250, loss is 3.795278301239014 and perplexity is 44.49061647644418
At time: 466.09200501441956 and batch: 300, loss is 3.7942141914367675 and perplexity is 44.44329875543393
At time: 467.3199682235718 and batch: 350, loss is 3.818313550949097 and perplexity is 45.52736396226947
At time: 468.5476803779602 and batch: 400, loss is 3.7816022968292238 and perplexity is 43.88630431603855
At time: 469.7757592201233 and batch: 450, loss is 3.8160336065292357 and perplexity is 45.423682341931254
At time: 471.00350189208984 and batch: 500, loss is 3.8391685104370117 and perplexity is 46.486805072195146
At time: 472.2321391105652 and batch: 550, loss is 3.805428900718689 and perplexity is 44.94452271779576
At time: 473.4609489440918 and batch: 600, loss is 3.749608373641968 and perplexity is 42.50443288390866
At time: 474.68804907798767 and batch: 650, loss is 3.77652099609375 and perplexity is 43.663870411019126
At time: 475.91535353660583 and batch: 700, loss is 3.815757155418396 and perplexity is 45.41112665008684
At time: 477.14291286468506 and batch: 750, loss is 3.77013060092926 and perplexity is 43.385730682604915
At time: 478.37064599990845 and batch: 800, loss is 3.7331387996673584 and perplexity is 41.810136062457765
At time: 479.59852719306946 and batch: 850, loss is 3.7405917501449584 and perplexity is 42.12290902892301
At time: 480.8260774612427 and batch: 900, loss is 3.7166824674606325 and perplexity is 41.127724965950755
At time: 482.0879898071289 and batch: 950, loss is 3.813749990463257 and perplexity is 45.320070441087154
At time: 483.3161141872406 and batch: 1000, loss is 3.781724591255188 and perplexity is 43.89167169462612
At time: 484.54447388648987 and batch: 1050, loss is 3.724104976654053 and perplexity is 41.43413162899804
At time: 485.7726676464081 and batch: 1100, loss is 3.741327085494995 and perplexity is 42.15389488407947
At time: 487.0001845359802 and batch: 1150, loss is 3.702074499130249 and perplexity is 40.53129935142851
At time: 488.234361410141 and batch: 1200, loss is 3.762866816520691 and perplexity is 43.07172789343182
At time: 489.4627561569214 and batch: 1250, loss is 3.736781268119812 and perplexity is 41.9627058607106
At time: 490.6911928653717 and batch: 1300, loss is 3.7351404571533204 and perplexity is 41.893909449138796
At time: 491.9192063808441 and batch: 1350, loss is 3.6037035179138184 and perplexity is 36.734027962206035
At time: 493.14782333374023 and batch: 1400, loss is 3.633395342826843 and perplexity is 37.841082188131864
At time: 494.3755450248718 and batch: 1450, loss is 3.5545351362228392 and perplexity is 34.97155917736781
At time: 495.60366320610046 and batch: 1500, loss is 3.5478269910812377 and perplexity is 34.73774997238763
At time: 496.8380174636841 and batch: 1550, loss is 3.561611199378967 and perplexity is 35.21989773221863
At time: 498.0643846988678 and batch: 1600, loss is 3.648092269897461 and perplexity is 38.40133673893115
At time: 499.29109239578247 and batch: 1650, loss is 3.5857306146621704 and perplexity is 36.07970845557425
At time: 500.51837825775146 and batch: 1700, loss is 3.599825372695923 and perplexity is 36.59184395065664
At time: 501.7460436820984 and batch: 1750, loss is 3.5876208925247193 and perplexity is 36.147973629501756
At time: 502.9723045825958 and batch: 1800, loss is 3.532061228752136 and perplexity is 34.19437745840696
At time: 504.203989982605 and batch: 1850, loss is 3.5697079515457153 and perplexity is 35.5062220999956
At time: 505.4306626319885 and batch: 1900, loss is 3.664144153594971 and perplexity is 39.02272440907406
At time: 506.6587345600128 and batch: 1950, loss is 3.596034207344055 and perplexity is 36.45338085380099
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388790254814681 and perplexity of 80.54292360604339
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 510.61830496788025 and batch: 50, loss is 3.829862494468689 and perplexity is 46.05620481587105
At time: 511.8523304462433 and batch: 100, loss is 3.8313539600372315 and perplexity is 46.12494731036051
At time: 513.1047968864441 and batch: 150, loss is 3.804439415931702 and perplexity is 44.90007279119785
At time: 514.3312184810638 and batch: 200, loss is 3.8245737981796264 and perplexity is 45.813270505511255
At time: 515.5567183494568 and batch: 250, loss is 3.8187811279296877 and perplexity is 45.54865648720454
At time: 516.7818157672882 and batch: 300, loss is 3.8212597274780276 and perplexity is 45.66169339534618
At time: 518.0069801807404 and batch: 350, loss is 3.854014401435852 and perplexity is 47.18209141574255
At time: 519.2324512004852 and batch: 400, loss is 3.8221175861358643 and perplexity is 45.70088148087281
At time: 520.4574747085571 and batch: 450, loss is 3.8572458171844484 and perplexity is 47.33480297337616
At time: 521.6831548213959 and batch: 500, loss is 3.873690071105957 and perplexity is 48.119623703046244
At time: 522.9082958698273 and batch: 550, loss is 3.847029938697815 and perplexity is 46.85369801706738
At time: 524.1388876438141 and batch: 600, loss is 3.792320981025696 and perplexity is 44.35923783713853
At time: 525.3649914264679 and batch: 650, loss is 3.8048670721054076 and perplexity is 44.91927869099494
At time: 526.590749502182 and batch: 700, loss is 3.837081136703491 and perplexity is 46.38987094040865
At time: 527.8158502578735 and batch: 750, loss is 3.7820001792907716 and perplexity is 43.90376938111918
At time: 529.0440104007721 and batch: 800, loss is 3.740392189025879 and perplexity is 42.11450377276738
At time: 530.2691144943237 and batch: 850, loss is 3.743954644203186 and perplexity is 42.26480236181139
At time: 531.4935784339905 and batch: 900, loss is 3.716380515098572 and perplexity is 41.11530822697728
At time: 532.7201933860779 and batch: 950, loss is 3.8260739612579346 and perplexity is 45.88204945934487
At time: 533.9473373889923 and batch: 1000, loss is 3.795322971343994 and perplexity is 44.49260392134218
At time: 535.1739957332611 and batch: 1050, loss is 3.737044277191162 and perplexity is 41.97374388449693
At time: 536.4004817008972 and batch: 1100, loss is 3.752703013420105 and perplexity is 42.636172530897376
At time: 537.628185749054 and batch: 1150, loss is 3.714305491447449 and perplexity is 41.03008144435815
At time: 538.8560824394226 and batch: 1200, loss is 3.7688740396499636 and perplexity is 43.3312480908815
At time: 540.0830292701721 and batch: 1250, loss is 3.7447589015960694 and perplexity is 42.29880781430494
At time: 541.3114132881165 and batch: 1300, loss is 3.7407588863372805 and perplexity is 42.12994987992176
At time: 542.5390205383301 and batch: 1350, loss is 3.6040455007553103 and perplexity is 36.74659251777675
At time: 543.7659153938293 and batch: 1400, loss is 3.6350897693634034 and perplexity is 37.90525547506987
At time: 544.9937093257904 and batch: 1450, loss is 3.5539675903320314 and perplexity is 34.95171684391157
At time: 546.2197470664978 and batch: 1500, loss is 3.5446327209472654 and perplexity is 34.626965247496486
At time: 547.4467751979828 and batch: 1550, loss is 3.561143846511841 and perplexity is 35.203441457776634
At time: 548.6732594966888 and batch: 1600, loss is 3.64459840297699 and perplexity is 38.26740169066103
At time: 549.900726556778 and batch: 1650, loss is 3.5835510301589966 and perplexity is 36.00115531984191
At time: 551.129106760025 and batch: 1700, loss is 3.5947287321090697 and perplexity is 36.40582291747319
At time: 552.3571605682373 and batch: 1750, loss is 3.5812608671188353 and perplexity is 35.918801142766156
At time: 553.5859799385071 and batch: 1800, loss is 3.5148023796081542 and perplexity is 33.609285387446135
At time: 554.8138062953949 and batch: 1850, loss is 3.5417884969711304 and perplexity is 34.52861832934906
At time: 556.0404741764069 and batch: 1900, loss is 3.641747145652771 and perplexity is 38.1584468842205
At time: 557.2674539089203 and batch: 1950, loss is 3.585171093940735 and perplexity is 36.059526757635616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.372020632721657 and perplexity of 79.2035113228159
finished 11 epochs...
Completing Train Step...
At time: 561.3252730369568 and batch: 50, loss is 3.8367977571487426 and perplexity is 46.37672686190623
At time: 562.5530424118042 and batch: 100, loss is 3.8270554113388062 and perplexity is 45.92710250553879
At time: 563.7824115753174 and batch: 150, loss is 3.7896429347991942 and perplexity is 44.24060067644334
At time: 565.0101895332336 and batch: 200, loss is 3.8019046354293824 and perplexity is 44.786405084338185
At time: 566.236918926239 and batch: 250, loss is 3.797351050376892 and perplexity is 44.582930001728904
At time: 567.4658372402191 and batch: 300, loss is 3.795302400588989 and perplexity is 44.49168868430096
At time: 568.6950018405914 and batch: 350, loss is 3.825854935646057 and perplexity is 45.872001215839354
At time: 569.9236006736755 and batch: 400, loss is 3.794325032234192 and perplexity is 44.448225159126366
At time: 571.1515805721283 and batch: 450, loss is 3.8300937032699585 and perplexity is 46.06685464689744
At time: 572.3794369697571 and batch: 500, loss is 3.8488604736328127 and perplexity is 46.9395438960903
At time: 573.6072700023651 and batch: 550, loss is 3.8211822366714476 and perplexity is 45.658155170986866
At time: 574.8767011165619 and batch: 600, loss is 3.768614258766174 and perplexity is 43.31999292295879
At time: 576.1037981510162 and batch: 650, loss is 3.784304404258728 and perplexity is 44.00505018478071
At time: 577.332533121109 and batch: 700, loss is 3.820682578086853 and perplexity is 45.63534738032765
At time: 578.5606560707092 and batch: 750, loss is 3.7681942129135133 and perplexity is 43.30180036071685
At time: 579.7877969741821 and batch: 800, loss is 3.7270932006835937 and perplexity is 41.55813127386315
At time: 581.0282008647919 and batch: 850, loss is 3.7296783256530763 and perplexity is 41.665703220259125
At time: 582.258770942688 and batch: 900, loss is 3.7024189233779907 and perplexity is 40.545261718068396
At time: 583.4826807975769 and batch: 950, loss is 3.8110287380218506 and perplexity is 45.19691073907653
At time: 584.7057733535767 and batch: 1000, loss is 3.7800779485702516 and perplexity is 43.81945726649749
At time: 585.9291269779205 and batch: 1050, loss is 3.722862482070923 and perplexity is 41.382681914507074
At time: 587.1532561779022 and batch: 1100, loss is 3.7394028806686403 and perplexity is 42.072860144815095
At time: 588.3784682750702 and batch: 1150, loss is 3.7027163743972777 and perplexity is 40.55732374133532
At time: 589.6029794216156 and batch: 1200, loss is 3.7586541318893434 and perplexity is 42.890661941942156
At time: 590.8265650272369 and batch: 1250, loss is 3.7357588243484496 and perplexity is 41.91982327972349
At time: 592.0506062507629 and batch: 1300, loss is 3.731988205909729 and perplexity is 41.762057245795994
At time: 593.273983001709 and batch: 1350, loss is 3.59601016998291 and perplexity is 36.45250462125165
At time: 594.4985294342041 and batch: 1400, loss is 3.6287823295593262 and perplexity is 37.66692278260599
At time: 595.7220551967621 and batch: 1450, loss is 3.5489621353149414 and perplexity is 34.777204718137575
At time: 596.9459021091461 and batch: 1500, loss is 3.5415124797821047 and perplexity is 34.51908915234567
At time: 598.1702506542206 and batch: 1550, loss is 3.5589218521118164 and perplexity is 35.125306447920764
At time: 599.3934087753296 and batch: 1600, loss is 3.6435397815704347 and perplexity is 38.22691243523561
At time: 600.6164484024048 and batch: 1650, loss is 3.583444995880127 and perplexity is 35.99733816567726
At time: 601.8409967422485 and batch: 1700, loss is 3.5967083883285524 and perplexity is 36.477965316250625
At time: 603.0647721290588 and batch: 1750, loss is 3.5851602125167847 and perplexity is 36.059134380772335
At time: 604.2885348796844 and batch: 1800, loss is 3.519868965148926 and perplexity is 33.780001816326056
At time: 605.5118429660797 and batch: 1850, loss is 3.54771942615509 and perplexity is 34.734013609831706
At time: 606.7357161045074 and batch: 1900, loss is 3.6472847127914427 and perplexity is 38.37033798488373
At time: 607.9603333473206 and batch: 1950, loss is 3.5900520420074464 and perplexity is 36.235961669594154
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370726119640262 and perplexity of 79.10104767589043
finished 12 epochs...
Completing Train Step...
At time: 611.8681788444519 and batch: 50, loss is 3.83082471370697 and perplexity is 46.100542309961114
At time: 613.1183578968048 and batch: 100, loss is 3.8188706731796263 and perplexity is 45.55273533565207
At time: 614.3428361415863 and batch: 150, loss is 3.780269479751587 and perplexity is 43.827850862705255
At time: 615.5669829845428 and batch: 200, loss is 3.7882227230072023 and perplexity is 44.177814249243355
At time: 616.7906467914581 and batch: 250, loss is 3.7861455917358398 and perplexity is 44.08614636583763
At time: 618.0151047706604 and batch: 300, loss is 3.7838011264801024 and perplexity is 43.982908992927676
At time: 619.238312959671 and batch: 350, loss is 3.8143010902404786 and perplexity is 45.34505320517648
At time: 620.4619438648224 and batch: 400, loss is 3.782574143409729 and perplexity is 43.928975802529656
At time: 621.685487985611 and batch: 450, loss is 3.8184149646759034 and perplexity is 45.531981296047114
At time: 622.9096086025238 and batch: 500, loss is 3.837221956253052 and perplexity is 46.396404001119194
At time: 624.1336712837219 and batch: 550, loss is 3.8089102602005003 and perplexity is 45.10126343519989
At time: 625.3679821491241 and batch: 600, loss is 3.7577662515640258 and perplexity is 42.85259706809099
At time: 626.5919001102448 and batch: 650, loss is 3.773718776702881 and perplexity is 43.541685940473066
At time: 627.8155834674835 and batch: 700, loss is 3.8112051057815552 and perplexity is 45.20488271994869
At time: 629.0391826629639 and batch: 750, loss is 3.7595995044708252 and perplexity is 42.931228770105896
At time: 630.2630844116211 and batch: 800, loss is 3.7186812686920168 and perplexity is 41.21001332489675
At time: 631.4870824813843 and batch: 850, loss is 3.721104578971863 and perplexity is 41.30999907313538
At time: 632.7108716964722 and batch: 900, loss is 3.6944554471969604 and perplexity is 40.22366271469181
At time: 633.9335248470306 and batch: 950, loss is 3.802787480354309 and perplexity is 44.82596199351159
At time: 635.181821346283 and batch: 1000, loss is 3.7718417501449584 and perplexity is 43.46003369527575
At time: 636.4060418605804 and batch: 1050, loss is 3.715410795211792 and perplexity is 41.07545722021822
At time: 637.6307861804962 and batch: 1100, loss is 3.7324866819381715 and perplexity is 41.78287981957723
At time: 638.8545026779175 and batch: 1150, loss is 3.696272487640381 and perplexity is 40.29681717880942
At time: 640.0793867111206 and batch: 1200, loss is 3.752973108291626 and perplexity is 42.647689897760095
At time: 641.3043057918549 and batch: 1250, loss is 3.7305000972747804 and perplexity is 41.699956985222215
At time: 642.5307652950287 and batch: 1300, loss is 3.7272331047058107 and perplexity is 41.563945830314616
At time: 643.757089138031 and batch: 1350, loss is 3.5914797830581664 and perplexity is 36.28773418966363
At time: 644.9837372303009 and batch: 1400, loss is 3.6250193405151365 and perplexity is 37.52544891409547
At time: 646.2101697921753 and batch: 1450, loss is 3.545486989021301 and perplexity is 34.65655859693528
At time: 647.43647813797 and batch: 1500, loss is 3.539034490585327 and perplexity is 34.43365711589104
At time: 648.6629250049591 and batch: 1550, loss is 3.557046513557434 and perplexity is 35.059496333913785
At time: 649.8910322189331 and batch: 1600, loss is 3.6422342109680175 and perplexity is 38.17703706713062
At time: 651.1173405647278 and batch: 1650, loss is 3.582411036491394 and perplexity is 35.96013761515488
At time: 652.3440778255463 and batch: 1700, loss is 3.5964259052276613 and perplexity is 36.46766236276753
At time: 653.5727913379669 and batch: 1750, loss is 3.585386190414429 and perplexity is 36.06728386891798
At time: 654.7990574836731 and batch: 1800, loss is 3.520618214607239 and perplexity is 33.80532094837727
At time: 656.0241899490356 and batch: 1850, loss is 3.5489777612686155 and perplexity is 34.77774814937322
At time: 657.2502429485321 and batch: 1900, loss is 3.648374843597412 and perplexity is 38.41218948001392
At time: 658.4746479988098 and batch: 1950, loss is 3.5906794548034666 and perplexity is 36.258703709199054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370738326671511 and perplexity of 79.10201327074482
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 662.4868433475494 and batch: 50, loss is 3.82861487865448 and perplexity is 45.99878019578106
At time: 663.7593169212341 and batch: 100, loss is 3.8236288738250734 and perplexity is 45.77000087693136
At time: 664.9876492023468 and batch: 150, loss is 3.7881099367141724 and perplexity is 44.17283187831687
At time: 666.2579116821289 and batch: 200, loss is 3.801360774040222 and perplexity is 44.76205411023104
At time: 667.4862790107727 and batch: 250, loss is 3.800025429725647 and perplexity is 44.70232124661218
At time: 668.7153260707855 and batch: 300, loss is 3.7961162662506105 and perplexity is 44.52791368108961
At time: 669.9447457790375 and batch: 350, loss is 3.8305916452407835 and perplexity is 46.08979897928899
At time: 671.1736001968384 and batch: 400, loss is 3.8020284175872803 and perplexity is 44.791949185327326
At time: 672.4030730724335 and batch: 450, loss is 3.839609155654907 and perplexity is 46.50729377433823
At time: 673.6321415901184 and batch: 500, loss is 3.8605140161514284 and perplexity is 47.48975559763689
At time: 674.8611128330231 and batch: 550, loss is 3.832536458969116 and perplexity is 46.17952227234601
At time: 676.0895664691925 and batch: 600, loss is 3.781838979721069 and perplexity is 43.89669268278232
At time: 677.319678068161 and batch: 650, loss is 3.7964339590072633 and perplexity is 44.542062124044875
At time: 678.5502226352692 and batch: 700, loss is 3.8337599182128907 and perplexity is 46.236055611809746
At time: 679.778911113739 and batch: 750, loss is 3.7811188983917234 and perplexity is 43.865094871823615
At time: 681.0067822933197 and batch: 800, loss is 3.7363820695877075 and perplexity is 41.945957753260245
At time: 682.2351195812225 and batch: 850, loss is 3.7360426568984986 and perplexity is 41.931723178772025
At time: 683.4639601707458 and batch: 900, loss is 3.7050992107391356 and perplexity is 40.654080438180145
At time: 684.6931774616241 and batch: 950, loss is 3.811701440811157 and perplexity is 45.22732505574963
At time: 685.9376966953278 and batch: 1000, loss is 3.779141321182251 and perplexity is 43.77843397746144
At time: 687.1879861354828 and batch: 1050, loss is 3.723467721939087 and perplexity is 41.4077359445374
At time: 688.4160215854645 and batch: 1100, loss is 3.739314556121826 and perplexity is 42.06914424261473
At time: 689.6422634124756 and batch: 1150, loss is 3.7034610652923585 and perplexity is 40.58753765967298
At time: 690.8688414096832 and batch: 1200, loss is 3.7597904109954836 and perplexity is 42.939425404160275
At time: 692.0939021110535 and batch: 1250, loss is 3.736346583366394 and perplexity is 41.94446927613058
At time: 693.318421125412 and batch: 1300, loss is 3.730131230354309 and perplexity is 41.684578087063066
At time: 694.5439727306366 and batch: 1350, loss is 3.5901534605026244 and perplexity is 36.239636852660624
At time: 695.7689211368561 and batch: 1400, loss is 3.6255020761489867 and perplexity is 37.54356815851313
At time: 696.993382692337 and batch: 1450, loss is 3.5467087841033935 and perplexity is 34.69892768769397
At time: 698.217866897583 and batch: 1500, loss is 3.537439751625061 and perplexity is 34.37878818378427
At time: 699.44282746315 and batch: 1550, loss is 3.554995927810669 and perplexity is 34.98767749095649
At time: 700.6679327487946 and batch: 1600, loss is 3.639719595909119 and perplexity is 38.0811571159251
At time: 701.8924396038055 and batch: 1650, loss is 3.578251991271973 and perplexity is 35.810888359057856
At time: 703.1179013252258 and batch: 1700, loss is 3.5897936058044433 and perplexity is 36.226598195230586
At time: 704.3439645767212 and batch: 1750, loss is 3.5817044448852537 and perplexity is 35.93473745858588
At time: 705.5692083835602 and batch: 1800, loss is 3.5169199466705323 and perplexity is 33.680530709924234
At time: 706.7953186035156 and batch: 1850, loss is 3.5430733251571653 and perplexity is 34.57301018324923
At time: 708.0210287570953 and batch: 1900, loss is 3.6412737274169924 and perplexity is 38.140386255069444
At time: 709.2459890842438 and batch: 1950, loss is 3.5859453582763674 and perplexity is 36.08745717453135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364778172692588 and perplexity of 78.6319552920796
finished 14 epochs...
Completing Train Step...
At time: 713.1514842510223 and batch: 50, loss is 3.827129936218262 and perplexity is 45.930525344858516
At time: 714.4031100273132 and batch: 100, loss is 3.8176494312286375 and perplexity is 45.497138379855194
At time: 715.6269862651825 and batch: 150, loss is 3.780487174987793 and perplexity is 43.83739301565415
At time: 716.8510282039642 and batch: 200, loss is 3.7875273180007936 and perplexity is 44.14710345549971
At time: 718.0752608776093 and batch: 250, loss is 3.7891845750808715 and perplexity is 44.22032721380311
At time: 719.298725605011 and batch: 300, loss is 3.7853235721588137 and perplexity is 44.04992158123014
At time: 720.5213718414307 and batch: 350, loss is 3.816709976196289 and perplexity is 45.4544159352967
At time: 721.7449395656586 and batch: 400, loss is 3.788556990623474 and perplexity is 44.19258393028006
At time: 722.967561006546 and batch: 450, loss is 3.8260862922668455 and perplexity is 45.88261523479389
At time: 724.190774679184 and batch: 500, loss is 3.8456342935562136 and perplexity is 46.78835249125342
At time: 725.4140613079071 and batch: 550, loss is 3.818414716720581 and perplexity is 45.531970006151404
At time: 726.6381287574768 and batch: 600, loss is 3.7677389669418333 and perplexity is 43.28209187698044
At time: 727.8851613998413 and batch: 650, loss is 3.7820788621902466 and perplexity is 43.907223992899624
At time: 729.108998298645 and batch: 700, loss is 3.8211496829986573 and perplexity is 45.65666885453588
At time: 730.3313348293304 and batch: 750, loss is 3.769734082221985 and perplexity is 43.36853083901569
At time: 731.5538115501404 and batch: 800, loss is 3.725904426574707 and perplexity is 41.50875739639919
At time: 732.7776470184326 and batch: 850, loss is 3.7263174533843992 and perplexity is 41.52590516704164
At time: 734.0011444091797 and batch: 900, loss is 3.6963735103607176 and perplexity is 40.300888278535055
At time: 735.2240245342255 and batch: 950, loss is 3.804032039642334 and perplexity is 44.881785291351655
At time: 736.4484028816223 and batch: 1000, loss is 3.771599040031433 and perplexity is 43.44948678553636
At time: 737.6715347766876 and batch: 1050, loss is 3.7163562870025633 and perplexity is 41.11431209340939
At time: 738.8952987194061 and batch: 1100, loss is 3.7318024253845214 and perplexity is 41.754299389518735
At time: 740.1184213161469 and batch: 1150, loss is 3.6968247222900392 and perplexity is 40.31907662317904
At time: 741.3413684368134 and batch: 1200, loss is 3.7537248086929322 and perplexity is 42.67976023550379
At time: 742.5652515888214 and batch: 1250, loss is 3.730958046913147 and perplexity is 41.719057838724154
At time: 743.7884564399719 and batch: 1300, loss is 3.7259600830078123 and perplexity is 41.51106769006926
At time: 745.0129570960999 and batch: 1350, loss is 3.5871055459976198 and perplexity is 36.12934969613198
At time: 746.2371251583099 and batch: 1400, loss is 3.6235285997390747 and perplexity is 37.46954987310116
At time: 747.4612216949463 and batch: 1450, loss is 3.545946087837219 and perplexity is 34.67247303482119
At time: 748.6847157478333 and batch: 1500, loss is 3.538626375198364 and perplexity is 34.41960707780602
At time: 749.9081375598907 and batch: 1550, loss is 3.5580940008163453 and perplexity is 35.096239950502834
At time: 751.132429599762 and batch: 1600, loss is 3.6432765340805053 and perplexity is 38.21685062092107
At time: 752.3566415309906 and batch: 1650, loss is 3.5830228996276854 and perplexity is 35.982147030425836
At time: 753.5804224014282 and batch: 1700, loss is 3.5954872226715087 and perplexity is 36.433446865501494
At time: 754.8038563728333 and batch: 1750, loss is 3.5883038997650147 and perplexity is 36.17267139062743
At time: 756.0274169445038 and batch: 1800, loss is 3.5232641553878783 and perplexity is 33.894886265686075
At time: 757.2511978149414 and batch: 1850, loss is 3.5487175226211547 and perplexity is 34.76869881277772
At time: 758.4739837646484 and batch: 1900, loss is 3.6467669296264646 and perplexity is 38.35047561248542
At time: 759.6982781887054 and batch: 1950, loss is 3.5902261972427367 and perplexity is 36.24227290157578
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363550088571948 and perplexity of 78.53544790813272
finished 15 epochs...
Completing Train Step...
At time: 763.6302073001862 and batch: 50, loss is 3.8258166027069094 and perplexity is 45.870242840910215
At time: 764.8569962978363 and batch: 100, loss is 3.814283962249756 and perplexity is 45.34427654217722
At time: 766.0827994346619 and batch: 150, loss is 3.7764296674728395 and perplexity is 43.6598828320437
At time: 767.3076777458191 and batch: 200, loss is 3.782812089920044 and perplexity is 43.939429792719515
At time: 768.5325889587402 and batch: 250, loss is 3.784207248687744 and perplexity is 44.00077505668345
At time: 769.7570645809174 and batch: 300, loss is 3.7802367305755613 and perplexity is 43.82641556020514
At time: 770.982460975647 and batch: 350, loss is 3.811039757728577 and perplexity is 45.197408798522034
At time: 772.2070281505585 and batch: 400, loss is 3.7827373504638673 and perplexity is 43.936145906351555
At time: 773.4345736503601 and batch: 450, loss is 3.8200142097473146 and perplexity is 45.604856349729616
At time: 774.6602725982666 and batch: 500, loss is 3.839634280204773 and perplexity is 46.50846226383862
At time: 775.8859324455261 and batch: 550, loss is 3.812195200920105 and perplexity is 45.249662018793416
At time: 777.1118836402893 and batch: 600, loss is 3.7617196464538574 and perplexity is 43.02234562681031
At time: 778.3376445770264 and batch: 650, loss is 3.7761760568618774 and perplexity is 43.64881162643108
At time: 779.5630483627319 and batch: 700, loss is 3.8159918785095215 and perplexity is 45.42178694116493
At time: 780.7891726493835 and batch: 750, loss is 3.765094494819641 and perplexity is 43.16778479917657
At time: 782.0146405696869 and batch: 800, loss is 3.721653895378113 and perplexity is 41.33269756712522
At time: 783.239874124527 and batch: 850, loss is 3.722163586616516 and perplexity is 41.353769850657706
At time: 784.465213060379 and batch: 900, loss is 3.692776069641113 and perplexity is 40.15616868815428
At time: 785.6907050609589 and batch: 950, loss is 3.800592541694641 and perplexity is 44.72767965788259
At time: 786.9154033660889 and batch: 1000, loss is 3.7682233905792235 and perplexity is 43.3030638246048
At time: 788.1644821166992 and batch: 1050, loss is 3.713089175224304 and perplexity is 40.980206228826205
At time: 789.390095949173 and batch: 1100, loss is 3.7288321685791015 and perplexity is 41.63046240247345
At time: 790.6165502071381 and batch: 1150, loss is 3.6944505739212037 and perplexity is 40.22346669416908
At time: 791.8425333499908 and batch: 1200, loss is 3.7515153074264527 and perplexity is 42.585563353596946
At time: 793.0686452388763 and batch: 1250, loss is 3.7290580320358275 and perplexity is 41.6398662645712
At time: 794.2939069271088 and batch: 1300, loss is 3.7243950033187865 and perplexity is 41.44615037479467
At time: 795.5194742679596 and batch: 1350, loss is 3.5860965871810913 and perplexity is 36.092915053838276
At time: 796.7450115680695 and batch: 1400, loss is 3.622973680496216 and perplexity is 37.44876306688811
At time: 797.9707720279694 and batch: 1450, loss is 3.545850133895874 and perplexity is 34.6691462339897
At time: 799.1956696510315 and batch: 1500, loss is 3.5392178392410276 and perplexity is 34.43997105944294
At time: 800.4196965694427 and batch: 1550, loss is 3.5592508125305176 and perplexity is 35.13686318418706
At time: 801.6448593139648 and batch: 1600, loss is 3.644407901763916 and perplexity is 38.260112398549325
At time: 802.8702907562256 and batch: 1650, loss is 3.584481883049011 and perplexity is 36.034682701424344
At time: 804.0958111286163 and batch: 1700, loss is 3.5972813463211057 and perplexity is 36.498871646683284
At time: 805.3208484649658 and batch: 1750, loss is 3.590363874435425 and perplexity is 36.247262979467585
At time: 806.5468137264252 and batch: 1800, loss is 3.525433440208435 and perplexity is 33.968493736876546
At time: 807.7732005119324 and batch: 1850, loss is 3.550757117271423 and perplexity is 34.839685232025225
At time: 808.9982750415802 and batch: 1900, loss is 3.6485408687591554 and perplexity is 38.418567399418166
At time: 810.2237949371338 and batch: 1950, loss is 3.5914652490615846 and perplexity is 36.287206787691595
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.363058116824128 and perplexity of 78.49682018921182
finished 16 epochs...
Completing Train Step...
At time: 814.1528196334839 and batch: 50, loss is 3.8239401721954347 and perplexity is 45.78425122155524
At time: 815.3784136772156 and batch: 100, loss is 3.811397924423218 and perplexity is 45.2135999044221
At time: 816.6051261425018 and batch: 150, loss is 3.7732374620437623 and perplexity is 43.52073373145434
At time: 817.8313801288605 and batch: 200, loss is 3.7793543195724486 and perplexity is 43.78775970657139
At time: 819.0813660621643 and batch: 250, loss is 3.7805692625045775 and perplexity is 43.84099166608923
At time: 820.3062961101532 and batch: 300, loss is 3.776553363800049 and perplexity is 43.66528373322535
At time: 821.5318260192871 and batch: 350, loss is 3.8071563911437987 and perplexity is 45.02223105132803
At time: 822.7578794956207 and batch: 400, loss is 3.7787818717956543 and perplexity is 43.76270067405461
At time: 823.9844651222229 and batch: 450, loss is 3.8159893465042116 and perplexity is 45.42167193310482
At time: 825.211377620697 and batch: 500, loss is 3.835676884651184 and perplexity is 46.32477358617822
At time: 826.4386940002441 and batch: 550, loss is 3.808120412826538 and perplexity is 45.065654385421695
At time: 827.6651957035065 and batch: 600, loss is 3.757925758361816 and perplexity is 42.85943289379217
At time: 828.8918523788452 and batch: 650, loss is 3.772489094734192 and perplexity is 43.48817642097411
At time: 830.1189467906952 and batch: 700, loss is 3.8126970195770262 and perplexity is 45.27237484179636
At time: 831.3435072898865 and batch: 750, loss is 3.7621106910705566 and perplexity is 43.039172573294444
At time: 832.5683269500732 and batch: 800, loss is 3.7188985776901244 and perplexity is 41.21896960470924
At time: 833.8019516468048 and batch: 850, loss is 3.719430785179138 and perplexity is 41.24091248758766
At time: 835.0270390510559 and batch: 900, loss is 3.6903625202178953 and perplexity is 40.05936665561435
At time: 836.2532391548157 and batch: 950, loss is 3.7982279205322267 and perplexity is 44.622040587431464
At time: 837.4800865650177 and batch: 1000, loss is 3.7659076642990112 and perplexity is 43.20290180036899
At time: 838.7080273628235 and batch: 1050, loss is 3.7108817005157473 and perplexity is 40.88984323373225
At time: 839.9335827827454 and batch: 1100, loss is 3.726896433830261 and perplexity is 41.549954815596365
At time: 841.1587603092194 and batch: 1150, loss is 3.6929399061203 and perplexity is 40.16274827242302
At time: 842.3845109939575 and batch: 1200, loss is 3.750050163269043 and perplexity is 42.523215050039084
At time: 843.6107289791107 and batch: 1250, loss is 3.727765703201294 and perplexity is 41.58608862141538
At time: 844.836451292038 and batch: 1300, loss is 3.7232400369644165 and perplexity is 41.39830909844403
At time: 846.0628848075867 and batch: 1350, loss is 3.5852175760269165 and perplexity is 36.061202918621454
At time: 847.288366317749 and batch: 1400, loss is 3.622354283332825 and perplexity is 37.425574591451294
At time: 848.5140542984009 and batch: 1450, loss is 3.5454619264602663 and perplexity is 34.65569002570454
At time: 849.7400760650635 and batch: 1500, loss is 3.5391664791107176 and perplexity is 34.43820226346463
At time: 850.9659502506256 and batch: 1550, loss is 3.5594560050964357 and perplexity is 35.14407374705379
At time: 852.1912562847137 and batch: 1600, loss is 3.64457332611084 and perplexity is 38.26644207618305
At time: 853.4185883998871 and batch: 1650, loss is 3.584752359390259 and perplexity is 36.044430548781065
At time: 854.6445398330688 and batch: 1700, loss is 3.5977715253829956 and perplexity is 36.516767014956194
At time: 855.8707926273346 and batch: 1750, loss is 3.590965819358826 and perplexity is 36.26908840359787
At time: 857.0960607528687 and batch: 1800, loss is 3.526216082572937 and perplexity is 33.995089325192865
At time: 858.3214387893677 and batch: 1850, loss is 3.5515990829467774 and perplexity is 34.86903140363169
At time: 859.5474116802216 and batch: 1900, loss is 3.649182758331299 and perplexity is 38.443235793554024
At time: 860.7740330696106 and batch: 1950, loss is 3.5918144035339354 and perplexity is 36.299878840353834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362842932412791 and perplexity of 78.47993071440862
finished 17 epochs...
Completing Train Step...
At time: 864.7012763023376 and batch: 50, loss is 3.8220307874679564 and perplexity is 45.696914877388494
At time: 865.9260120391846 and batch: 100, loss is 3.8088979291915894 and perplexity is 45.100707294547476
At time: 867.1514914035797 and batch: 150, loss is 3.7705547618865967 and perplexity is 43.40413711903588
At time: 868.3769135475159 and batch: 200, loss is 3.7765295028686525 and perplexity is 43.66424185131597
At time: 869.6028261184692 and batch: 250, loss is 3.777606601715088 and perplexity is 43.71129789329947
At time: 870.8277087211609 and batch: 300, loss is 3.7735503768920897 and perplexity is 43.53435414615288
At time: 872.0526571273804 and batch: 350, loss is 3.8040446424484253 and perplexity is 44.882350931353024
At time: 873.2782502174377 and batch: 400, loss is 3.775653681755066 and perplexity is 43.62601652810984
At time: 874.5036056041718 and batch: 450, loss is 3.812844090461731 and perplexity is 45.27903357965827
At time: 875.7290894985199 and batch: 500, loss is 3.8325600624084473 and perplexity is 46.18061228076223
At time: 876.9536216259003 and batch: 550, loss is 3.804918704032898 and perplexity is 44.921598019810425
At time: 878.1787753105164 and batch: 600, loss is 3.7549997901916505 and perplexity is 42.73421084455722
At time: 879.4029088020325 and batch: 650, loss is 3.7696302795410155 and perplexity is 43.364029302884695
At time: 880.6509568691254 and batch: 700, loss is 3.8100812673568725 and perplexity is 45.15410827224646
At time: 881.8758015632629 and batch: 750, loss is 3.7597311782836913 and perplexity is 42.93688206087609
At time: 883.0999851226807 and batch: 800, loss is 3.7166797018051145 and perplexity is 41.127611220988555
At time: 884.3253002166748 and batch: 850, loss is 3.7172160530090332 and perplexity is 41.14967598148271
At time: 885.550400018692 and batch: 900, loss is 3.6883580350875853 and perplexity is 39.97914867555702
At time: 886.7758300304413 and batch: 950, loss is 3.7962476778030396 and perplexity is 44.533765547845896
At time: 888.0010361671448 and batch: 1000, loss is 3.7639639949798585 and perplexity is 43.119011199844955
At time: 889.2245090007782 and batch: 1050, loss is 3.709054455757141 and perplexity is 40.815195702427914
At time: 890.4492330551147 and batch: 1100, loss is 3.725270948410034 and perplexity is 41.48247083180727
At time: 891.6749668121338 and batch: 1150, loss is 3.6916246461868285 and perplexity is 40.109958542520644
At time: 892.9010682106018 and batch: 1200, loss is 3.7487722206115723 and perplexity is 42.46890752793437
At time: 894.1272609233856 and batch: 1250, loss is 3.7266085815429686 and perplexity is 41.53799628729323
At time: 895.3536405563354 and batch: 1300, loss is 3.72216947555542 and perplexity is 41.35401338119888
At time: 896.5788147449493 and batch: 1350, loss is 3.5842987489700318 and perplexity is 36.028084127226855
At time: 897.8040993213654 and batch: 1400, loss is 3.621609525680542 and perplexity is 37.397711985115734
At time: 899.0290608406067 and batch: 1450, loss is 3.544847135543823 and perplexity is 34.6343905703004
At time: 900.253607749939 and batch: 1500, loss is 3.538805513381958 and perplexity is 34.42577349600193
At time: 901.4769387245178 and batch: 1550, loss is 3.5592448616027834 and perplexity is 35.136654087875606
At time: 902.7010636329651 and batch: 1600, loss is 3.6443526124954224 and perplexity is 38.25799708339997
At time: 903.924635887146 and batch: 1650, loss is 3.584576754570007 and perplexity is 36.03810152875295
At time: 905.1490468978882 and batch: 1700, loss is 3.597769846916199 and perplexity is 36.51670572282668
At time: 906.3737452030182 and batch: 1750, loss is 3.5910215520858766 and perplexity is 36.27110983513167
At time: 907.5993452072144 and batch: 1800, loss is 3.526461372375488 and perplexity is 34.00342899671752
At time: 908.8247261047363 and batch: 1850, loss is 3.5519521331787107 and perplexity is 34.8813440966277
At time: 910.0498962402344 and batch: 1900, loss is 3.649397654533386 and perplexity is 38.45149798664717
At time: 911.2737989425659 and batch: 1950, loss is 3.5918314456939697 and perplexity is 36.30049747396966
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362764580305233 and perplexity of 78.47378188732603
finished 18 epochs...
Completing Train Step...
At time: 915.1754925251007 and batch: 50, loss is 3.8201864099502565 and perplexity is 45.61271019144533
At time: 916.4240612983704 and batch: 100, loss is 3.8066546010971067 and perplexity is 44.99964501110561
At time: 917.6483981609344 and batch: 150, loss is 3.768182091712952 and perplexity is 43.301275494091016
At time: 918.8729169368744 and batch: 200, loss is 3.77407133102417 and perplexity is 43.55703945632275
At time: 920.0968039035797 and batch: 250, loss is 3.7750325632095336 and perplexity is 43.59892801363676
At time: 921.3193576335907 and batch: 300, loss is 3.7709150886535645 and perplexity is 43.41977960947177
At time: 922.5434765815735 and batch: 350, loss is 3.8013731908798216 and perplexity is 44.76260991692775
At time: 923.7679562568665 and batch: 400, loss is 3.7729744052886964 and perplexity is 43.50928681412133
At time: 924.9914536476135 and batch: 450, loss is 3.8101573038101195 and perplexity is 45.157541761022514
At time: 926.21484208107 and batch: 500, loss is 3.8298836517333985 and perplexity is 46.057179249495995
At time: 927.4381303787231 and batch: 550, loss is 3.8021688318252562 and perplexity is 44.798239054322885
At time: 928.661652803421 and batch: 600, loss is 3.752500834465027 and perplexity is 42.62755326543295
At time: 929.8846426010132 and batch: 650, loss is 3.7671748781204224 and perplexity is 43.25768381758929
At time: 931.1082475185394 and batch: 700, loss is 3.8077965068817137 and perplexity is 45.05105971583658
At time: 932.3315584659576 and batch: 750, loss is 3.757644739151001 and perplexity is 42.84739026196905
At time: 933.5556573867798 and batch: 800, loss is 3.714717736244202 and perplexity is 41.046999368867525
At time: 934.7797570228577 and batch: 850, loss is 3.7152595138549804 and perplexity is 41.069243739322054
At time: 936.0024213790894 and batch: 900, loss is 3.6865513467788698 and perplexity is 39.90698402419797
At time: 937.225284576416 and batch: 950, loss is 3.7944561672210693 and perplexity is 44.45405425874042
At time: 938.4490804672241 and batch: 1000, loss is 3.7621982669830323 and perplexity is 43.04294193315491
At time: 939.6711182594299 and batch: 1050, loss is 3.707407670021057 and perplexity is 40.74803713339375
At time: 940.9200205802917 and batch: 1100, loss is 3.723775277137756 and perplexity is 41.42047306757606
At time: 942.1443557739258 and batch: 1150, loss is 3.6903695106506347 and perplexity is 40.05964668890131
At time: 943.3691997528076 and batch: 1200, loss is 3.747561979293823 and perplexity is 42.41754099054698
At time: 944.5930972099304 and batch: 1250, loss is 3.725494427680969 and perplexity is 41.491742340101716
At time: 945.8175764083862 and batch: 1300, loss is 3.7211288356781007 and perplexity is 41.31100112980083
At time: 947.0417840480804 and batch: 1350, loss is 3.5833471393585206 and perplexity is 35.993815763725095
At time: 948.2652544975281 and batch: 1400, loss is 3.6207905292510985 and perplexity is 37.3670959314612
At time: 949.4900314807892 and batch: 1450, loss is 3.544112596511841 and perplexity is 34.608959599741276
At time: 950.7148478031158 and batch: 1500, loss is 3.5382931995391846 and perplexity is 34.40814121270881
At time: 951.9393165111542 and batch: 1550, loss is 3.558832969665527 and perplexity is 35.12218456349943
At time: 953.1653733253479 and batch: 1600, loss is 3.6439544343948365 and perplexity is 38.24276661920896
At time: 954.3915226459503 and batch: 1650, loss is 3.584207282066345 and perplexity is 36.024788900630355
At time: 955.6152987480164 and batch: 1700, loss is 3.597545609474182 and perplexity is 36.508518228150244
At time: 956.8391416072845 and batch: 1750, loss is 3.590830535888672 and perplexity is 36.264182127335836
At time: 958.0631647109985 and batch: 1800, loss is 3.526452217102051 and perplexity is 34.00311768745232
At time: 959.28839802742 and batch: 1850, loss is 3.5520596599578855 and perplexity is 34.88509497686812
At time: 960.5135087966919 and batch: 1900, loss is 3.6494115209579467 and perplexity is 38.45203117513994
At time: 961.7377367019653 and batch: 1950, loss is 3.591693572998047 and perplexity is 36.29549297151964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362768270803052 and perplexity of 78.47407149518136
Annealing...
finished 19 epochs...
Completing Train Step...
At time: 965.6397774219513 and batch: 50, loss is 3.819578766822815 and perplexity is 45.58500236066254
At time: 966.8898453712463 and batch: 100, loss is 3.8077954769134523 and perplexity is 45.05101331469883
At time: 968.1157350540161 and batch: 150, loss is 3.770024619102478 and perplexity is 43.381132827259755
At time: 969.3410265445709 and batch: 200, loss is 3.7762152051925657 and perplexity is 43.650520437991126
At time: 970.5665674209595 and batch: 250, loss is 3.7780003261566164 and perplexity is 43.728511488135126
At time: 971.8155159950256 and batch: 300, loss is 3.773323445320129 and perplexity is 43.52447594761216
At time: 973.04225730896 and batch: 350, loss is 3.803841004371643 and perplexity is 44.87321210626585
At time: 974.2689468860626 and batch: 400, loss is 3.7764329290390015 and perplexity is 43.6600252318724
At time: 975.4948372840881 and batch: 450, loss is 3.81398832321167 and perplexity is 45.33087298528255
At time: 976.7210874557495 and batch: 500, loss is 3.8340901947021484 and perplexity is 46.25132881598562
At time: 977.9468419551849 and batch: 550, loss is 3.806847138404846 and perplexity is 45.00830995574107
At time: 979.1728160381317 and batch: 600, loss is 3.7573389434814453 and perplexity is 42.83428971872197
At time: 980.399551153183 and batch: 650, loss is 3.772080492973328 and perplexity is 43.470410705310265
At time: 981.6259505748749 and batch: 700, loss is 3.8132491588592528 and perplexity is 45.297378400434454
At time: 982.8514304161072 and batch: 750, loss is 3.764328942298889 and perplexity is 43.134750239167005
At time: 984.0770618915558 and batch: 800, loss is 3.7208147716522215 and perplexity is 41.29802886763997
At time: 985.3040850162506 and batch: 850, loss is 3.721010837554932 and perplexity is 41.306126796788014
At time: 986.5312402248383 and batch: 900, loss is 3.6912832355499265 and perplexity is 40.09626691339543
At time: 987.7571151256561 and batch: 950, loss is 3.7982132959365846 and perplexity is 44.62138801290298
At time: 988.983512878418 and batch: 1000, loss is 3.765358738899231 and perplexity is 43.17919313796538
At time: 990.2102890014648 and batch: 1050, loss is 3.71096351146698 and perplexity is 40.89318860754519
At time: 991.4379825592041 and batch: 1100, loss is 3.7276903915405275 and perplexity is 41.582956821948514
At time: 992.6646866798401 and batch: 1150, loss is 3.6942170906066893 and perplexity is 40.214076282139
At time: 993.8905811309814 and batch: 1200, loss is 3.7506968069076536 and perplexity is 42.550721308959666
At time: 995.1163215637207 and batch: 1250, loss is 3.727974228858948 and perplexity is 41.59476129210017
At time: 996.3421387672424 and batch: 1300, loss is 3.7222279691696167 and perplexity is 41.356432397650906
At time: 997.5678136348724 and batch: 1350, loss is 3.5814393663406374 and perplexity is 35.92521319307417
At time: 998.794214963913 and batch: 1400, loss is 3.6182186937332155 and perplexity is 37.271117380370725
At time: 1000.0213971138 and batch: 1450, loss is 3.541352882385254 and perplexity is 34.513580435175456
At time: 1001.2473411560059 and batch: 1500, loss is 3.5336544847488405 and perplexity is 34.24890127901432
At time: 1002.4736206531525 and batch: 1550, loss is 3.552906370162964 and perplexity is 34.9146450511995
At time: 1003.6994414329529 and batch: 1600, loss is 3.6381215047836304 and perplexity is 38.0203485584394
At time: 1004.9261062145233 and batch: 1650, loss is 3.5769572925567625 and perplexity is 35.76455404886708
At time: 1006.1533677577972 and batch: 1700, loss is 3.5894356679916384 and perplexity is 36.21363364629679
At time: 1007.3800239562988 and batch: 1750, loss is 3.5825716781616213 and perplexity is 35.96591477573692
At time: 1008.6061372756958 and batch: 1800, loss is 3.519819583892822 and perplexity is 33.778333758590904
At time: 1009.8335976600647 and batch: 1850, loss is 3.5468880939483642 and perplexity is 34.705150104891956
At time: 1011.0606517791748 and batch: 1900, loss is 3.6442039108276365 and perplexity is 38.25230847839053
At time: 1012.2873675823212 and batch: 1950, loss is 3.5880563259124756 and perplexity is 36.16371709148552
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.362106536155523 and perplexity of 78.42215966096434
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f8261144b38>
ELAPSED
2102.9438700675964


RESULTS SO FAR:
[{'best_accuracy': -78.0513610743167, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}}, {'best_accuracy': -78.42215966096434, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.02990420607447708, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.45043527467939715}}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.9149200001362663, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.10734533781315092}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.9346611499786377 and batch: 50, loss is 7.930251178741455 and perplexity is 2780.1250251291235
At time: 3.2297399044036865 and batch: 100, loss is 7.074867763519287 and perplexity is 1181.8872018664333
At time: 4.524181604385376 and batch: 150, loss is 6.826896886825562 and perplexity is 922.3242905511843
At time: 5.818297386169434 and batch: 200, loss is 6.746721763610839 and perplexity is 851.2635402154197
At time: 7.113638639450073 and batch: 250, loss is 6.704589185714721 and perplexity is 816.1426743640709
At time: 8.40863561630249 and batch: 300, loss is 6.625022573471069 and perplexity is 753.721226466829
At time: 9.702902555465698 and batch: 350, loss is 6.592113122940064 and perplexity is 729.3203863712731
At time: 10.999866724014282 and batch: 400, loss is 6.569854726791382 and perplexity is 713.2662171340477
At time: 12.303247690200806 and batch: 450, loss is 6.487922525405883 and perplexity is 657.1567177356657
At time: 13.662424564361572 and batch: 500, loss is 6.4770733261108395 and perplexity is 650.0656294067743
At time: 14.96686053276062 and batch: 550, loss is 6.437846279144287 and perplexity is 625.0591461783681
At time: 16.269084215164185 and batch: 600, loss is 6.494369459152222 and perplexity is 661.4070496386054
At time: 17.572596549987793 and batch: 650, loss is 6.582330284118652 and perplexity is 722.2203484704783
At time: 18.87596845626831 and batch: 700, loss is 6.462665586471558 and perplexity is 640.7668014717187
At time: 20.17799472808838 and batch: 750, loss is 6.396338968276978 and perplexity is 599.6456924892102
At time: 21.480915307998657 and batch: 800, loss is 6.395044984817505 and perplexity is 598.8702626864524
At time: 22.78520131111145 and batch: 850, loss is 6.452701005935669 and perplexity is 634.4135354585687
At time: 24.091217756271362 and batch: 900, loss is 6.440797920227051 and perplexity is 626.9068219297725
At time: 25.39963436126709 and batch: 950, loss is 6.450265016555786 and perplexity is 632.8699916152304
At time: 26.70150327682495 and batch: 1000, loss is 6.445966148376465 and perplexity is 630.1552063793893
At time: 28.003371715545654 and batch: 1050, loss is 6.33933048248291 and perplexity is 566.4169583284315
At time: 29.30524230003357 and batch: 1100, loss is 6.416995420455932 and perplexity is 612.1610616112682
At time: 30.608888149261475 and batch: 1150, loss is 6.322321996688843 and perplexity is 556.864529992938
At time: 31.91094970703125 and batch: 1200, loss is 6.410599327087402 and perplexity is 608.2581174081731
At time: 33.212480306625366 and batch: 1250, loss is 6.337584428787231 and perplexity is 565.4288268214251
At time: 34.515636920928955 and batch: 1300, loss is 6.354490451812744 and perplexity is 575.0692405024272
At time: 35.81896495819092 and batch: 1350, loss is 6.361959686279297 and perplexity is 579.3806489101368
At time: 37.12134075164795 and batch: 1400, loss is 6.389993028640747 and perplexity is 595.8524257722156
At time: 38.42453742027283 and batch: 1450, loss is 6.379732942581176 and perplexity is 589.7701841224197
At time: 39.72723889350891 and batch: 1500, loss is 6.3622484874725345 and perplexity is 579.5479988971555
At time: 41.030662298202515 and batch: 1550, loss is 6.3448476886749265 and perplexity is 569.5506340968881
At time: 42.33363223075867 and batch: 1600, loss is 6.31894965171814 and perplexity is 554.9897536688808
At time: 43.63617753982544 and batch: 1650, loss is 6.314752702713013 and perplexity is 552.6653710439161
At time: 44.939701795578 and batch: 1700, loss is 6.341381225585938 and perplexity is 567.5797258604036
At time: 46.24270462989807 and batch: 1750, loss is 6.357068128585816 and perplexity is 576.5534952692633
At time: 47.546682596206665 and batch: 1800, loss is 6.360793838500976 and perplexity is 578.7055728622219
At time: 48.85024976730347 and batch: 1850, loss is 6.299038400650025 and perplexity is 544.0485018260094
At time: 50.15415644645691 and batch: 1900, loss is 6.248940620422363 and perplexity is 517.4643430373499
At time: 51.45775651931763 and batch: 1950, loss is 6.199751033782959 and perplexity is 492.6263784985992
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.645689498546512 and perplexity of 283.0686643843106
finished 1 epochs...
Completing Train Step...
At time: 55.43056917190552 and batch: 50, loss is 5.915880489349365 and perplexity is 370.8807155016363
At time: 56.6792778968811 and batch: 100, loss is 5.743683261871338 and perplexity is 312.2122552737713
At time: 57.90075182914734 and batch: 150, loss is 5.570949869155884 and perplexity is 262.68349572486204
At time: 59.12216377258301 and batch: 200, loss is 5.509692087173462 and perplexity is 247.0750377805411
At time: 60.34363079071045 and batch: 250, loss is 5.468333978652954 and perplexity is 237.06490837849296
At time: 61.56516695022583 and batch: 300, loss is 5.440616846084595 and perplexity is 230.58437466977193
At time: 62.78667593002319 and batch: 350, loss is 5.384912042617798 and perplexity is 218.09092055736042
At time: 64.0079779624939 and batch: 400, loss is 5.339503326416016 and perplexity is 208.40917324815575
At time: 65.22840309143066 and batch: 450, loss is 5.267413330078125 and perplexity is 193.9137223676891
At time: 66.44989943504333 and batch: 500, loss is 5.243404989242554 and perplexity is 189.31361703320115
At time: 67.67136240005493 and batch: 550, loss is 5.188840017318726 and perplexity is 179.26049321476214
At time: 68.89346218109131 and batch: 600, loss is 5.197589931488037 and perplexity is 180.83588938382485
At time: 70.11507248878479 and batch: 650, loss is 5.266566972732544 and perplexity is 193.7496714969768
At time: 71.33660316467285 and batch: 700, loss is 5.2078999996185305 and perplexity is 182.70996404175403
At time: 72.56147575378418 and batch: 750, loss is 5.1477961826324465 and perplexity is 172.0519012299247
At time: 73.78706502914429 and batch: 800, loss is 5.1284637546539305 and perplexity is 168.75766562619674
At time: 75.01344275474548 and batch: 850, loss is 5.1199337768554685 and perplexity is 167.32428851365336
At time: 76.23963928222656 and batch: 900, loss is 5.1372582054138185 and perplexity is 170.24834183848444
At time: 77.46519231796265 and batch: 950, loss is 5.173120727539063 and perplexity is 176.464677265768
At time: 78.69136023521423 and batch: 1000, loss is 5.130606489181519 and perplexity is 169.11965618946752
At time: 79.91678380966187 and batch: 1050, loss is 5.033272857666016 and perplexity is 153.43436065133284
At time: 81.14337944984436 and batch: 1100, loss is 5.12047137260437 and perplexity is 167.41426552330816
At time: 82.36979246139526 and batch: 1150, loss is 5.022705707550049 and perplexity is 151.82153323206583
At time: 83.59495210647583 and batch: 1200, loss is 5.09345516204834 and perplexity is 162.95191577608077
At time: 84.82086825370789 and batch: 1250, loss is 5.033067464828491 and perplexity is 153.402849568811
At time: 86.046062707901 and batch: 1300, loss is 5.0710070705413814 and perplexity is 159.33470786300242
At time: 87.27110028266907 and batch: 1350, loss is 4.998350648880005 and perplexity is 148.16857544999573
At time: 88.49652743339539 and batch: 1400, loss is 5.009519834518432 and perplexity is 149.8327743473936
At time: 89.72295093536377 and batch: 1450, loss is 4.946260204315186 and perplexity is 140.6479844126437
At time: 90.94753384590149 and batch: 1500, loss is 4.913466501235962 and perplexity is 136.11042451304934
At time: 92.17503571510315 and batch: 1550, loss is 4.900865545272827 and perplexity is 134.4060638862915
At time: 93.40168046951294 and batch: 1600, loss is 4.963681468963623 and perplexity is 143.11971801998112
At time: 94.62913250923157 and batch: 1650, loss is 4.9249303436279295 and perplexity is 137.67975103687428
At time: 95.85807538032532 and batch: 1700, loss is 4.951449213027954 and perplexity is 141.379704839182
At time: 97.08678221702576 and batch: 1750, loss is 4.962160882949829 and perplexity is 142.90225755403398
At time: 98.31495070457458 and batch: 1800, loss is 4.914703950881958 and perplexity is 136.27895856437445
At time: 99.54838633537292 and batch: 1850, loss is 4.908294324874878 and perplexity is 135.40825483093644
At time: 100.77654457092285 and batch: 1900, loss is 4.960450067520141 and perplexity is 142.65798717721756
At time: 102.00540685653687 and batch: 1950, loss is 4.883720951080322 and perplexity is 132.12136752276504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.698385833030523 and perplexity of 109.76984251652952
finished 2 epochs...
Completing Train Step...
At time: 106.09991884231567 and batch: 50, loss is 4.842792015075684 and perplexity is 126.82294946215512
At time: 107.38055872917175 and batch: 100, loss is 4.783860158920288 and perplexity is 119.5650002836431
At time: 108.61194825172424 and batch: 150, loss is 4.729480676651001 and perplexity is 113.23674059287181
At time: 109.84334087371826 and batch: 200, loss is 4.719933309555054 and perplexity is 112.16077236656503
At time: 111.07431316375732 and batch: 250, loss is 4.724583520889282 and perplexity is 112.68355825182421
At time: 112.3064067363739 and batch: 300, loss is 4.74583550453186 and perplexity is 115.10393519861258
At time: 113.54116892814636 and batch: 350, loss is 4.744422779083252 and perplexity is 114.94143974787744
At time: 114.7742166519165 and batch: 400, loss is 4.71839409828186 and perplexity is 111.98826603722978
At time: 116.00546646118164 and batch: 450, loss is 4.70117712020874 and perplexity is 110.07666969266741
At time: 117.23668479919434 and batch: 500, loss is 4.705281553268432 and perplexity is 110.52940048088956
At time: 118.6143479347229 and batch: 550, loss is 4.663395643234253 and perplexity is 105.99539430701311
At time: 119.84788918495178 and batch: 600, loss is 4.6425810718536376 and perplexity is 103.81194818405946
At time: 121.07888174057007 and batch: 650, loss is 4.705905437469482 and perplexity is 110.59837954283722
At time: 122.30911803245544 and batch: 700, loss is 4.7116528987884525 and perplexity is 111.23586967126109
At time: 123.5403892993927 and batch: 750, loss is 4.676300582885742 and perplexity is 107.37212266572223
At time: 124.77190446853638 and batch: 800, loss is 4.6475371074676515 and perplexity is 104.3277209347676
At time: 126.0035502910614 and batch: 850, loss is 4.6465065479278564 and perplexity is 104.22026038844952
At time: 127.23575854301453 and batch: 900, loss is 4.649225492477417 and perplexity is 104.50401507921289
At time: 128.4665825366974 and batch: 950, loss is 4.708181476593017 and perplexity is 110.85039246852251
At time: 129.69886946678162 and batch: 1000, loss is 4.691106433868408 and perplexity is 108.9736853056276
At time: 130.93104600906372 and batch: 1050, loss is 4.61152346611023 and perplexity is 100.63735050150771
At time: 132.16190266609192 and batch: 1100, loss is 4.684116353988648 and perplexity is 108.21460664158744
At time: 133.39244747161865 and batch: 1150, loss is 4.612472553253173 and perplexity is 100.73290945668349
At time: 134.62462377548218 and batch: 1200, loss is 4.686471471786499 and perplexity is 108.46976513389167
At time: 135.85694122314453 and batch: 1250, loss is 4.641960258483887 and perplexity is 103.7475203395898
At time: 137.08754682540894 and batch: 1300, loss is 4.6725796127319335 and perplexity is 106.97333659758057
At time: 138.31873393058777 and batch: 1350, loss is 4.577095203399658 and perplexity is 97.23154573380458
At time: 139.55052542686462 and batch: 1400, loss is 4.581932554244995 and perplexity is 97.70302827760518
At time: 140.7829144001007 and batch: 1450, loss is 4.513704776763916 and perplexity is 91.25928829018805
At time: 142.01501560211182 and batch: 1500, loss is 4.500731754302978 and perplexity is 90.08302583005515
At time: 143.24687314033508 and batch: 1550, loss is 4.501684103012085 and perplexity is 90.16885714760188
At time: 144.47752594947815 and batch: 1600, loss is 4.586122074127197 and perplexity is 98.11321570133924
At time: 145.70371007919312 and batch: 1650, loss is 4.543709859848023 and perplexity is 94.03902539105587
At time: 146.9358696937561 and batch: 1700, loss is 4.581568717956543 and perplexity is 97.66748683645123
At time: 148.16697478294373 and batch: 1750, loss is 4.580681056976318 and perplexity is 97.58082968612545
At time: 149.39805388450623 and batch: 1800, loss is 4.536373395919799 and perplexity is 93.35163606009522
At time: 150.62826204299927 and batch: 1850, loss is 4.5566448402404784 and perplexity is 95.26331937993456
At time: 151.85869789123535 and batch: 1900, loss is 4.62642168045044 and perplexity is 102.14789156269251
At time: 153.0899977684021 and batch: 1950, loss is 4.5560082340240475 and perplexity is 95.20269345808629
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.545946413971657 and perplexity of 94.24958413632079
finished 3 epochs...
Completing Train Step...
At time: 157.13325572013855 and batch: 50, loss is 4.5218894672393795 and perplexity is 92.00928236575315
At time: 158.3645932674408 and batch: 100, loss is 4.468140487670898 and perplexity is 87.19443304682817
At time: 159.5946934223175 and batch: 150, loss is 4.420551061630249 and perplexity is 83.14208915201849
At time: 160.82601857185364 and batch: 200, loss is 4.422294635772705 and perplexity is 83.28718000038248
At time: 162.05729603767395 and batch: 250, loss is 4.423759574890137 and perplexity is 83.4092800610872
At time: 163.2875940799713 and batch: 300, loss is 4.448021259307861 and perplexity is 85.4576780057463
At time: 164.51973462104797 and batch: 350, loss is 4.458630542755127 and perplexity is 86.3691492133039
At time: 165.75079226493835 and batch: 400, loss is 4.431215753555298 and perplexity is 84.03351888161998
At time: 166.98211359977722 and batch: 450, loss is 4.438000383377076 and perplexity is 84.60559366322579
At time: 168.21324014663696 and batch: 500, loss is 4.448131294250488 and perplexity is 85.46708185380913
At time: 169.4447100162506 and batch: 550, loss is 4.402040700912476 and perplexity is 81.6172552418518
At time: 170.67565083503723 and batch: 600, loss is 4.3826328563690184 and perplexity is 80.04851243877167
At time: 171.90829730033875 and batch: 650, loss is 4.441916379928589 and perplexity is 84.93755843848328
At time: 173.13961935043335 and batch: 700, loss is 4.4588872337341305 and perplexity is 86.39132224045741
At time: 174.37060499191284 and batch: 750, loss is 4.427814073562622 and perplexity is 83.74814938475788
At time: 175.60113310813904 and batch: 800, loss is 4.400963220596314 and perplexity is 81.52936161619873
At time: 176.83177995681763 and batch: 850, loss is 4.39903754234314 and perplexity is 81.37251336564105
At time: 178.06209063529968 and batch: 900, loss is 4.396586179733276 and perplexity is 81.17328412023438
At time: 179.34060168266296 and batch: 950, loss is 4.469168567657471 and perplexity is 87.28412199419034
At time: 180.5720727443695 and batch: 1000, loss is 4.451005306243896 and perplexity is 85.71306858718985
At time: 181.80207061767578 and batch: 1050, loss is 4.38639946937561 and perplexity is 80.35059275957077
At time: 183.03308367729187 and batch: 1100, loss is 4.445360612869263 and perplexity is 85.23060755016229
At time: 184.26477456092834 and batch: 1150, loss is 4.38160478591919 and perplexity is 79.96625921687867
At time: 185.4942581653595 and batch: 1200, loss is 4.458994970321656 and perplexity is 86.40063024810486
At time: 186.72384071350098 and batch: 1250, loss is 4.419421234130859 and perplexity is 83.04820597921992
At time: 187.95427680015564 and batch: 1300, loss is 4.43805115699768 and perplexity is 84.60988950459628
At time: 189.18630051612854 and batch: 1350, loss is 4.334464402198791 and perplexity is 76.28409035513462
At time: 190.41724181175232 and batch: 1400, loss is 4.348426265716553 and perplexity is 77.35662830473123
At time: 191.64918613433838 and batch: 1450, loss is 4.274234104156494 and perplexity is 71.82510768666691
At time: 192.88778853416443 and batch: 1500, loss is 4.27679470539093 and perplexity is 72.00925881425692
At time: 194.11685752868652 and batch: 1550, loss is 4.274590301513672 and perplexity is 71.85069615720614
At time: 195.34487891197205 and batch: 1600, loss is 4.367949085235596 and perplexity is 78.8816860733829
At time: 196.57379984855652 and batch: 1650, loss is 4.3224291372299195 and perplexity is 75.3714938010622
At time: 197.80275869369507 and batch: 1700, loss is 4.361602687835694 and perplexity is 78.38265674015759
At time: 199.03140449523926 and batch: 1750, loss is 4.364751453399658 and perplexity is 78.62985432990078
At time: 200.2613582611084 and batch: 1800, loss is 4.31145770072937 and perplexity is 74.54908002278984
At time: 201.49184274673462 and batch: 1850, loss is 4.346920051574707 and perplexity is 77.24020036193161
At time: 202.7217996120453 and batch: 1900, loss is 4.424306192398071 and perplexity is 83.45488549712216
At time: 203.9514102935791 and batch: 1950, loss is 4.35198637008667 and perplexity is 77.63251677970712
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.488544694767442 and perplexity of 88.99184130212177
finished 4 epochs...
Completing Train Step...
At time: 207.95076632499695 and batch: 50, loss is 4.3192692518234255 and perplexity is 75.13370440920724
At time: 209.17987942695618 and batch: 100, loss is 4.271256222724914 and perplexity is 71.61153918083266
At time: 210.43665981292725 and batch: 150, loss is 4.2224605274200435 and perplexity is 68.20108865600562
At time: 211.66573810577393 and batch: 200, loss is 4.229383449554444 and perplexity is 68.67487759194216
At time: 212.89357376098633 and batch: 250, loss is 4.227961988449096 and perplexity is 68.57732827223792
At time: 214.1233685016632 and batch: 300, loss is 4.252226533889771 and perplexity is 70.26167832432486
At time: 215.353444814682 and batch: 350, loss is 4.264521899223328 and perplexity is 71.1309041020391
At time: 216.58297061920166 and batch: 400, loss is 4.2412550830841065 and perplexity is 69.49501914916817
At time: 217.81219339370728 and batch: 450, loss is 4.258751544952393 and perplexity is 70.721635533691
At time: 219.04215025901794 and batch: 500, loss is 4.273157739639283 and perplexity is 71.74783928125305
At time: 220.2717263698578 and batch: 550, loss is 4.221084580421448 and perplexity is 68.10731210334659
At time: 221.50001525878906 and batch: 600, loss is 4.20934600353241 and perplexity is 67.3125032724513
At time: 222.72949743270874 and batch: 650, loss is 4.2672023105621335 and perplexity is 71.32181993611233
At time: 223.95819306373596 and batch: 700, loss is 4.2888963460922245 and perplexity is 72.88598319366743
At time: 225.18826818466187 and batch: 750, loss is 4.255628595352173 and perplexity is 70.50111993903884
At time: 226.41740322113037 and batch: 800, loss is 4.222767953872681 and perplexity is 68.22205869796477
At time: 227.64598393440247 and batch: 850, loss is 4.226201753616333 and perplexity is 68.45672224887772
At time: 228.87448620796204 and batch: 900, loss is 4.219845609664917 and perplexity is 68.02298138777748
At time: 230.10211205482483 and batch: 950, loss is 4.301747283935547 and perplexity is 73.82868073351112
At time: 231.33137917518616 and batch: 1000, loss is 4.279697980880737 and perplexity is 72.2186253076532
At time: 232.56188344955444 and batch: 1050, loss is 4.2194507026672365 and perplexity is 67.99612393987046
At time: 233.791512966156 and batch: 1100, loss is 4.277499828338623 and perplexity is 72.06005210074463
At time: 235.02123475074768 and batch: 1150, loss is 4.218980216979981 and perplexity is 67.96414026128936
At time: 236.2528591156006 and batch: 1200, loss is 4.294862432479858 and perplexity is 73.3221270080041
At time: 237.4821813106537 and batch: 1250, loss is 4.2611577558517455 and perplexity is 70.8920116021043
At time: 238.71134090423584 and batch: 1300, loss is 4.271106357574463 and perplexity is 71.60080791088106
At time: 239.93950009346008 and batch: 1350, loss is 4.1628383445739745 and perplexity is 64.25363798930492
At time: 241.16861200332642 and batch: 1400, loss is 4.185067090988159 and perplexity is 65.69790850648296
At time: 242.39827513694763 and batch: 1450, loss is 4.108140840530395 and perplexity is 60.83351316763663
At time: 243.62725687026978 and batch: 1500, loss is 4.115342612266541 and perplexity is 61.273203618111154
At time: 244.85535764694214 and batch: 1550, loss is 4.110415720939637 and perplexity is 60.9720596635726
At time: 246.08733677864075 and batch: 1600, loss is 4.211133713722229 and perplexity is 67.4329461468536
At time: 247.3169596195221 and batch: 1650, loss is 4.158419308662414 and perplexity is 63.97032530109465
At time: 248.5464277267456 and batch: 1700, loss is 4.20242178440094 and perplexity is 66.84802667414782
At time: 249.77612257003784 and batch: 1750, loss is 4.20394654750824 and perplexity is 66.95003182609992
At time: 251.00540399551392 and batch: 1800, loss is 4.152196311950684 and perplexity is 63.57347425915545
At time: 252.23403549194336 and batch: 1850, loss is 4.193656039237976 and perplexity is 66.26461466387235
At time: 253.4638695716858 and batch: 1900, loss is 4.268335876464843 and perplexity is 71.40271375988912
At time: 254.69285368919373 and batch: 1950, loss is 4.193474569320679 and perplexity is 66.25259072075453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4694568722747094 and perplexity of 87.30929003743007
finished 5 epochs...
Completing Train Step...
At time: 258.68271231651306 and batch: 50, loss is 4.163177280426026 and perplexity is 64.27541954191024
At time: 259.9065637588501 and batch: 100, loss is 4.119983348846436 and perplexity is 61.55821724056621
At time: 261.1308546066284 and batch: 150, loss is 4.071864576339721 and perplexity is 58.66624837304575
At time: 262.3555865287781 and batch: 200, loss is 4.08202896118164 and perplexity is 59.265595536244874
At time: 263.57822728157043 and batch: 250, loss is 4.08526683807373 and perplexity is 59.45780123980945
At time: 264.80139207839966 and batch: 300, loss is 4.10105610370636 and perplexity is 60.4040468610075
At time: 266.0249412059784 and batch: 350, loss is 4.117016153335571 and perplexity is 61.37583269383058
At time: 267.2485156059265 and batch: 400, loss is 4.093408870697021 and perplexity is 59.943884765863906
At time: 268.4710068702698 and batch: 450, loss is 4.117453098297119 and perplexity is 61.40265641450498
At time: 269.6937789916992 and batch: 500, loss is 4.1313867139816285 and perplexity is 62.26420574080316
At time: 270.91702008247375 and batch: 550, loss is 4.085184259414673 and perplexity is 59.45289149703534
At time: 272.1751880645752 and batch: 600, loss is 4.077780275344849 and perplexity is 59.01432879457913
At time: 273.3977687358856 and batch: 650, loss is 4.131416163444519 and perplexity is 62.266039415219765
At time: 274.62100863456726 and batch: 700, loss is 4.152413806915283 and perplexity is 63.58730267343962
At time: 275.8451793193817 and batch: 750, loss is 4.119998440742493 and perplexity is 61.55914627779272
At time: 277.06802105903625 and batch: 800, loss is 4.085013856887818 and perplexity is 59.442761437213804
At time: 278.2902874946594 and batch: 850, loss is 4.090594749450684 and perplexity is 59.775432539818766
At time: 279.5132520198822 and batch: 900, loss is 4.08227053642273 and perplexity is 59.279914366242615
At time: 280.735769033432 and batch: 950, loss is 4.165591311454773 and perplexity is 64.43076983384012
At time: 281.95892691612244 and batch: 1000, loss is 4.14772472858429 and perplexity is 63.28983480047254
At time: 283.181663274765 and batch: 1050, loss is 4.090594563484192 and perplexity is 59.775421423592306
At time: 284.40743613243103 and batch: 1100, loss is 4.145234231948852 and perplexity is 63.132407796926934
At time: 285.63676142692566 and batch: 1150, loss is 4.091646218299866 and perplexity is 59.83831760012803
At time: 286.86702728271484 and batch: 1200, loss is 4.161995010375977 and perplexity is 64.19947354161849
At time: 288.09470558166504 and batch: 1250, loss is 4.1315524196624756 and perplexity is 62.27452412829195
At time: 289.324138879776 and batch: 1300, loss is 4.137792119979858 and perplexity is 62.66431331545187
At time: 290.55328702926636 and batch: 1350, loss is 4.029030861854554 and perplexity is 56.20641306434009
At time: 291.7825257778168 and batch: 1400, loss is 4.05647162437439 and perplexity is 57.77011638247405
At time: 293.0113732814789 and batch: 1450, loss is 3.978018822669983 and perplexity is 53.41111245206582
At time: 294.2411148548126 and batch: 1500, loss is 3.984437313079834 and perplexity is 53.755033712063316
At time: 295.4699800014496 and batch: 1550, loss is 3.985052771568298 and perplexity is 53.78812788685985
At time: 296.69957995414734 and batch: 1600, loss is 4.088910565376282 and perplexity is 59.67484443651186
At time: 297.9288468360901 and batch: 1650, loss is 4.034817633628845 and perplexity is 56.532609651325345
At time: 299.15867042541504 and batch: 1700, loss is 4.078605971336365 and perplexity is 59.06307681205853
At time: 300.38769364356995 and batch: 1750, loss is 4.080577039718628 and perplexity is 59.17960898403347
At time: 301.61738109588623 and batch: 1800, loss is 4.028278474807739 and perplexity is 56.164139992052775
At time: 302.84547781944275 and batch: 1850, loss is 4.075952744483947 and perplexity is 58.90657677752969
At time: 304.0747890472412 and batch: 1900, loss is 4.148816809654236 and perplexity is 63.3589901857486
At time: 305.3044002056122 and batch: 1950, loss is 4.0720431423187256 and perplexity is 58.67672510448704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.480497138444767 and perplexity of 88.27854842885822
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 309.28114891052246 and batch: 50, loss is 4.0803635835647585 and perplexity is 59.16697808043223
At time: 310.53671765327454 and batch: 100, loss is 4.056665821075439 and perplexity is 57.78133623788898
At time: 311.76466488838196 and batch: 150, loss is 4.015295829772949 and perplexity is 55.43969368881994
At time: 312.9924838542938 and batch: 200, loss is 4.016157865524292 and perplexity is 55.48750529151788
At time: 314.2216682434082 and batch: 250, loss is 4.02627206325531 and perplexity is 56.05156458680339
At time: 315.45029067993164 and batch: 300, loss is 4.038642373085022 and perplexity is 56.7492461790658
At time: 316.6792802810669 and batch: 350, loss is 4.048635516166687 and perplexity is 57.319192550696165
At time: 317.9063835144043 and batch: 400, loss is 4.018851037025452 and perplexity is 55.63714407044056
At time: 319.13465189933777 and batch: 450, loss is 4.036651487350464 and perplexity is 56.63637730619625
At time: 320.36339378356934 and batch: 500, loss is 4.0421394348144535 and perplexity is 56.94804920667837
At time: 321.5918824672699 and batch: 550, loss is 3.990836672782898 and perplexity is 54.100134543105305
At time: 322.82093358039856 and batch: 600, loss is 3.971481294631958 and perplexity is 53.06307469972296
At time: 324.0517406463623 and batch: 650, loss is 4.014655022621155 and perplexity is 55.4041789168861
At time: 325.2796392440796 and batch: 700, loss is 4.027532868385315 and perplexity is 56.12227925632075
At time: 326.5085165500641 and batch: 750, loss is 3.9849088191986084 and perplexity is 53.78038551566907
At time: 327.73573303222656 and batch: 800, loss is 3.949205741882324 and perplexity is 51.89413312540029
At time: 328.96435284614563 and batch: 850, loss is 3.951656346321106 and perplexity is 52.02146106987516
At time: 330.1918933391571 and batch: 900, loss is 3.9331100368499756 and perplexity is 51.065546695620284
At time: 331.4194407463074 and batch: 950, loss is 4.0187509775161745 and perplexity is 55.63157732361491
At time: 332.675265789032 and batch: 1000, loss is 3.9941684913635256 and perplexity is 54.28068699356883
At time: 333.90493607521057 and batch: 1050, loss is 3.9309861040115357 and perplexity is 50.957202003234976
At time: 335.13275814056396 and batch: 1100, loss is 3.9670794200897217 and perplexity is 52.83001103690121
At time: 336.3608617782593 and batch: 1150, loss is 3.9273575496673585 and perplexity is 50.77263608278103
At time: 337.58970737457275 and batch: 1200, loss is 3.9692096757888793 and perplexity is 52.942672425176674
At time: 338.8171982765198 and batch: 1250, loss is 3.9285939168930053 and perplexity is 50.83544852761627
At time: 340.04497742652893 and batch: 1300, loss is 3.93626353263855 and perplexity is 51.226835860755536
At time: 341.2722566127777 and batch: 1350, loss is 3.819063763618469 and perplexity is 45.56153198255541
At time: 342.50088763237 and batch: 1400, loss is 3.83633780002594 and perplexity is 46.3554004610448
At time: 343.7282347679138 and batch: 1450, loss is 3.748720350265503 and perplexity is 42.46670470813471
At time: 344.9558355808258 and batch: 1500, loss is 3.750619287490845 and perplexity is 42.54742292970487
At time: 346.18285751342773 and batch: 1550, loss is 3.7515809631347654 and perplexity is 42.58835943071103
At time: 347.41105031967163 and batch: 1600, loss is 3.850023031234741 and perplexity is 46.99414555231332
At time: 348.6389579772949 and batch: 1650, loss is 3.7816817712783815 and perplexity is 43.889792294500374
At time: 349.866406917572 and batch: 1700, loss is 3.81233696937561 and perplexity is 45.25607744823197
At time: 351.09470438957214 and batch: 1750, loss is 3.8005282640457154 and perplexity is 44.7248047601891
At time: 352.3228425979614 and batch: 1800, loss is 3.733741002082825 and perplexity is 41.83532181008346
At time: 353.55088353157043 and batch: 1850, loss is 3.7721144199371337 and perplexity is 43.47188554937924
At time: 354.7796413898468 and batch: 1900, loss is 3.832839050292969 and perplexity is 46.19349790947192
At time: 356.00735449790955 and batch: 1950, loss is 3.753953275680542 and perplexity is 42.68951226572277
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418278467932413 and perplexity of 82.95335550286659
finished 7 epochs...
Completing Train Step...
At time: 359.9624059200287 and batch: 50, loss is 3.9696546030044555 and perplexity is 52.96623330205297
At time: 361.22039222717285 and batch: 100, loss is 3.9350249671936037 and perplexity is 51.16342734790689
At time: 362.4502947330475 and batch: 150, loss is 3.8922772073745726 and perplexity is 49.02239366948129
At time: 363.7070093154907 and batch: 200, loss is 3.8925505542755126 and perplexity is 49.035795620474936
At time: 364.93589091300964 and batch: 250, loss is 3.8976729488372803 and perplexity is 49.287620736460724
At time: 366.16578698158264 and batch: 300, loss is 3.909369344711304 and perplexity is 49.867492856417364
At time: 367.3955523967743 and batch: 350, loss is 3.9237877321243286 and perplexity is 50.59171016418316
At time: 368.62597370147705 and batch: 400, loss is 3.8983162593841554 and perplexity is 49.319338183701184
At time: 369.85603523254395 and batch: 450, loss is 3.9206175661087035 and perplexity is 50.43157999766266
At time: 371.08646035194397 and batch: 500, loss is 3.9310036659240724 and perplexity is 50.95809691701784
At time: 372.316232919693 and batch: 550, loss is 3.8824684953689577 and perplexity is 48.5438976792023
At time: 373.54585552215576 and batch: 600, loss is 3.8688716650009156 and perplexity is 47.88832151587105
At time: 374.77675676345825 and batch: 650, loss is 3.9125060272216796 and perplexity is 50.02415692336723
At time: 376.00625705718994 and batch: 700, loss is 3.9298410320281985 and perplexity is 50.89888573340716
At time: 377.23577857017517 and batch: 750, loss is 3.889715747833252 and perplexity is 48.89698547405529
At time: 378.4678373336792 and batch: 800, loss is 3.8541440534591676 and perplexity is 47.18820906593315
At time: 379.6981244087219 and batch: 850, loss is 3.8601126956939695 and perplexity is 47.470700810989435
At time: 380.92842984199524 and batch: 900, loss is 3.8403121185302735 and perplexity is 46.53999816893623
At time: 382.15759468078613 and batch: 950, loss is 3.927208595275879 and perplexity is 50.76507383889821
At time: 383.3877856731415 and batch: 1000, loss is 3.906996417045593 and perplexity is 49.74930118859728
At time: 384.61907935142517 and batch: 1050, loss is 3.8469587755203247 and perplexity is 46.8503638776747
At time: 385.8488829135895 and batch: 1100, loss is 3.884902081489563 and perplexity is 48.66217729827981
At time: 387.07933831214905 and batch: 1150, loss is 3.8493341493606565 and perplexity is 46.96178328542358
At time: 388.3117952346802 and batch: 1200, loss is 3.891220545768738 and perplexity is 48.97062094620625
At time: 389.5420296192169 and batch: 1250, loss is 3.8568310546875 and perplexity is 47.31517434319359
At time: 390.7724573612213 and batch: 1300, loss is 3.8652243041992187 and perplexity is 47.713973677134
At time: 392.0014617443085 and batch: 1350, loss is 3.7500571489334105 and perplexity is 42.52351210398481
At time: 393.2307868003845 and batch: 1400, loss is 3.773241624832153 and perplexity is 43.52091489943656
At time: 394.4607722759247 and batch: 1450, loss is 3.6890662479400635 and perplexity is 40.00747245092721
At time: 395.69020104408264 and batch: 1500, loss is 3.6941799402236937 and perplexity is 40.212582341553706
At time: 396.9218256473541 and batch: 1550, loss is 3.6960296392440797 and perplexity is 40.28703234954464
At time: 398.1521625518799 and batch: 1600, loss is 3.801022729873657 and perplexity is 44.746925116233776
At time: 399.38142681121826 and batch: 1650, loss is 3.7356327867507932 and perplexity is 41.914540138847315
At time: 400.61143469810486 and batch: 1700, loss is 3.7711007308959963 and perplexity is 43.42784090295952
At time: 401.8423342704773 and batch: 1750, loss is 3.763419437408447 and perplexity is 43.095536807983315
At time: 403.07205414772034 and batch: 1800, loss is 3.7001718044281007 and perplexity is 40.45425398303209
At time: 404.302654504776 and batch: 1850, loss is 3.744708571434021 and perplexity is 42.29667896202639
At time: 405.53278613090515 and batch: 1900, loss is 3.8082134103775025 and perplexity is 45.06984557579435
At time: 406.7623767852783 and batch: 1950, loss is 3.7328384590148924 and perplexity is 41.797580664455666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.424069994549418 and perplexity of 83.43517596047485
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 410.72591495513916 and batch: 50, loss is 3.926966013908386 and perplexity is 50.752760671398384
At time: 411.98244166374207 and batch: 100, loss is 3.9231651401519776 and perplexity is 50.56022197473154
At time: 413.20891308784485 and batch: 150, loss is 3.8972462129592897 and perplexity is 49.26659242743775
At time: 414.4333736896515 and batch: 200, loss is 3.896633348464966 and perplexity is 49.23640793263
At time: 415.65898847579956 and batch: 250, loss is 3.900212092399597 and perplexity is 49.412928100725274
At time: 416.8848659992218 and batch: 300, loss is 3.9059408378601073 and perplexity is 49.696814568535544
At time: 418.1099500656128 and batch: 350, loss is 3.927442932128906 and perplexity is 50.776971360504746
At time: 419.33521842956543 and batch: 400, loss is 3.9069806814193724 and perplexity is 49.74851835834821
At time: 420.56179761886597 and batch: 450, loss is 3.9259348154067992 and perplexity is 50.70045147586
At time: 421.78678822517395 and batch: 500, loss is 3.9339100885391236 and perplexity is 51.106418119957326
At time: 423.01264786720276 and batch: 550, loss is 3.877559571266174 and perplexity is 48.306183308105425
At time: 424.24106097221375 and batch: 600, loss is 3.854025988578796 and perplexity is 47.18263812454758
At time: 425.49450039863586 and batch: 650, loss is 3.8939598608016968 and perplexity is 49.1049508062408
At time: 426.7205104827881 and batch: 700, loss is 3.9171333742141723 and perplexity is 50.25617244963293
At time: 427.94588232040405 and batch: 750, loss is 3.880941672325134 and perplexity is 48.469836291293134
At time: 429.17183685302734 and batch: 800, loss is 3.8401403427124023 and perplexity is 46.532004409273995
At time: 430.39891242980957 and batch: 850, loss is 3.841189489364624 and perplexity is 46.58084892397038
At time: 431.62494015693665 and batch: 900, loss is 3.8163156127929687 and perplexity is 45.436493911259994
At time: 432.85031151771545 and batch: 950, loss is 3.904180121421814 and perplexity is 49.609389558106095
At time: 434.0751643180847 and batch: 1000, loss is 3.875324249267578 and perplexity is 48.19832402890976
At time: 435.3010950088501 and batch: 1050, loss is 3.8161621284484863 and perplexity is 45.4295206559329
At time: 436.52703332901 and batch: 1100, loss is 3.8549357509613036 and perplexity is 47.225582645513626
At time: 437.7529356479645 and batch: 1150, loss is 3.8263509702682494 and perplexity is 45.89476096097578
At time: 438.97835063934326 and batch: 1200, loss is 3.8657158613204956 and perplexity is 47.7374335861497
At time: 440.20453786849976 and batch: 1250, loss is 3.824016408920288 and perplexity is 45.78774179597153
At time: 441.4309937953949 and batch: 1300, loss is 3.822557587623596 and perplexity is 45.72099436123921
At time: 442.6569073200226 and batch: 1350, loss is 3.6959871196746827 and perplexity is 40.28531939869408
At time: 443.8836302757263 and batch: 1400, loss is 3.7168161344528197 and perplexity is 41.13322275267058
At time: 445.1105148792267 and batch: 1450, loss is 3.633049578666687 and perplexity is 37.82800035987371
At time: 446.33577370643616 and batch: 1500, loss is 3.6262919664382935 and perplexity is 37.573235173728584
At time: 447.56139945983887 and batch: 1550, loss is 3.626743083000183 and perplexity is 37.590188906166446
At time: 448.7858428955078 and batch: 1600, loss is 3.727120442390442 and perplexity is 41.55926340371297
At time: 450.01116609573364 and batch: 1650, loss is 3.66387508392334 and perplexity is 39.0122259898976
At time: 451.2365403175354 and batch: 1700, loss is 3.7001612901687624 and perplexity is 40.45382863875047
At time: 452.4629476070404 and batch: 1750, loss is 3.6915638923645018 and perplexity is 40.10752178324778
At time: 453.68871307373047 and batch: 1800, loss is 3.6321494913101198 and perplexity is 37.79396717374352
At time: 454.9155128002167 and batch: 1850, loss is 3.6622245121002197 and perplexity is 38.947886621902555
At time: 456.1420247554779 and batch: 1900, loss is 3.725391330718994 and perplexity is 41.48746488801934
At time: 457.3672227859497 and batch: 1950, loss is 3.6521903562545774 and perplexity is 38.55903163607124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.401940634084302 and perplexity of 81.60908847061376
finished 9 epochs...
Completing Train Step...
At time: 461.3685269355774 and batch: 50, loss is 3.912398028373718 and perplexity is 50.01875466377342
At time: 462.5965542793274 and batch: 100, loss is 3.8937586450576784 and perplexity is 49.09507111103778
At time: 463.8245186805725 and batch: 150, loss is 3.863775486946106 and perplexity is 47.644894902199916
At time: 465.0519003868103 and batch: 200, loss is 3.8575795459747315 and perplexity is 47.35060259615862
At time: 466.28013014793396 and batch: 250, loss is 3.8559735870361327 and perplexity is 47.27462050106415
At time: 467.5069019794464 and batch: 300, loss is 3.8577235555648803 and perplexity is 47.3574220280518
At time: 468.73394894599915 and batch: 350, loss is 3.8795721340179443 and perplexity is 48.40350042886984
At time: 469.9640266895294 and batch: 400, loss is 3.8577322912216188 and perplexity is 47.35783572804163
At time: 471.19146966934204 and batch: 450, loss is 3.87975869178772 and perplexity is 48.41253132032447
At time: 472.41950273513794 and batch: 500, loss is 3.887734513282776 and perplexity is 48.800204981105814
At time: 473.6472284793854 and batch: 550, loss is 3.8337869882583617 and perplexity is 46.23730724087831
At time: 474.8751881122589 and batch: 600, loss is 3.813255796432495 and perplexity is 45.29767906609911
At time: 476.10238099098206 and batch: 650, loss is 3.8556222438812258 and perplexity is 47.258013804245735
At time: 477.3295614719391 and batch: 700, loss is 3.8807588052749633 and perplexity is 48.460973565683226
At time: 478.5570888519287 and batch: 750, loss is 3.846956281661987 and perplexity is 46.85024703964981
At time: 479.78404903411865 and batch: 800, loss is 3.807171354293823 and perplexity is 45.02290473076585
At time: 481.0122091770172 and batch: 850, loss is 3.808705415725708 and perplexity is 45.09202563676732
At time: 482.238924741745 and batch: 900, loss is 3.7845785093307494 and perplexity is 44.01711384551068
At time: 483.4650309085846 and batch: 950, loss is 3.8717724323272704 and perplexity is 48.027436066161606
At time: 484.69126749038696 and batch: 1000, loss is 3.843834557533264 and perplexity is 46.7042215372834
At time: 485.9453492164612 and batch: 1050, loss is 3.7855306339263914 and perplexity is 44.05904358023044
At time: 487.173437833786 and batch: 1100, loss is 3.824557247161865 and perplexity is 45.81251225553235
At time: 488.39998030662537 and batch: 1150, loss is 3.797909150123596 and perplexity is 44.60781866820341
At time: 489.6274735927582 and batch: 1200, loss is 3.8390638542175295 and perplexity is 46.48194019349483
At time: 490.85360503196716 and batch: 1250, loss is 3.800079593658447 and perplexity is 44.70474256570969
At time: 492.08175826072693 and batch: 1300, loss is 3.8007898139953613 and perplexity is 44.73650406053107
At time: 493.307904958725 and batch: 1350, loss is 3.676852836608887 and perplexity is 39.52181652832565
At time: 494.53695154190063 and batch: 1400, loss is 3.699346385002136 and perplexity is 40.42087603323076
At time: 495.7649841308594 and batch: 1450, loss is 3.6170276021957397 and perplexity is 37.22675049562246
At time: 496.9927558898926 and batch: 1500, loss is 3.6122012090682984 and perplexity is 37.047512447447204
At time: 498.2203803062439 and batch: 1550, loss is 3.6147314500808716 and perplexity is 37.141370274242824
At time: 499.44802165031433 and batch: 1600, loss is 3.717887659072876 and perplexity is 41.17732163585245
At time: 500.67459535598755 and batch: 1650, loss is 3.656068377494812 and perplexity is 38.70885470050556
At time: 501.90279936790466 and batch: 1700, loss is 3.6958232307434082 and perplexity is 40.278717621745635
At time: 503.13045048713684 and batch: 1750, loss is 3.6899838733673094 and perplexity is 40.044201173955855
At time: 504.35828399658203 and batch: 1800, loss is 3.6334849882125853 and perplexity is 37.84447461859712
At time: 505.58641242980957 and batch: 1850, loss is 3.6646808624267577 and perplexity is 39.0436738712826
At time: 506.8137381076813 and batch: 1900, loss is 3.728964967727661 and perplexity is 41.63599125954026
At time: 508.0414493083954 and batch: 1950, loss is 3.6562094116210937 and perplexity is 38.714314354997356
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.402894201944041 and perplexity of 81.6869453894701
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 512.0190424919128 and batch: 50, loss is 3.9014026594161986 and perplexity is 49.47179253719084
At time: 513.2454822063446 and batch: 100, loss is 3.8984330606460573 and perplexity is 49.3250990810707
At time: 514.4710371494293 and batch: 150, loss is 3.8827492237091064 and perplexity is 48.55752724003462
At time: 515.6967763900757 and batch: 200, loss is 3.891331925392151 and perplexity is 48.9760755792874
At time: 516.9517908096313 and batch: 250, loss is 3.893687129020691 and perplexity is 49.09156015166275
At time: 518.1779155731201 and batch: 300, loss is 3.8923308658599853 and perplexity is 49.02502420745161
At time: 519.4050793647766 and batch: 350, loss is 3.914039978981018 and perplexity is 50.10095045061438
At time: 520.6318924427032 and batch: 400, loss is 3.895753655433655 and perplexity is 49.19311405313888
At time: 521.8580532073975 and batch: 450, loss is 3.91759446144104 and perplexity is 50.27935027190897
At time: 523.0854158401489 and batch: 500, loss is 3.927481927871704 and perplexity is 50.77895148482794
At time: 524.3119418621063 and batch: 550, loss is 3.878290319442749 and perplexity is 48.34149586419671
At time: 525.5378234386444 and batch: 600, loss is 3.8415796041488646 and perplexity is 46.599024346818176
At time: 526.7638573646545 and batch: 650, loss is 3.8654209756851197 and perplexity is 47.72335857807627
At time: 527.9896113872528 and batch: 700, loss is 3.8839207983016966 and perplexity is 48.61444934296195
At time: 529.215817451477 and batch: 750, loss is 3.85435760974884 and perplexity is 47.19828748089371
At time: 530.4415271282196 and batch: 800, loss is 3.818487811088562 and perplexity is 45.5352982583587
At time: 531.6678938865662 and batch: 850, loss is 3.8238031578063967 and perplexity is 45.77797855007949
At time: 532.8937509059906 and batch: 900, loss is 3.799363098144531 and perplexity is 44.67272329041394
At time: 534.118567943573 and batch: 950, loss is 3.9001134777069093 and perplexity is 49.408055500264766
At time: 535.3444859981537 and batch: 1000, loss is 3.8678315114974975 and perplexity is 47.83853620714378
At time: 536.5702822208405 and batch: 1050, loss is 3.811021852493286 and perplexity is 45.196599535528
At time: 537.7960543632507 and batch: 1100, loss is 3.8397896003723146 and perplexity is 46.5156865270119
At time: 539.0226018428802 and batch: 1150, loss is 3.8079941368103025 and perplexity is 45.05996403340191
At time: 540.2489576339722 and batch: 1200, loss is 3.8491115808486938 and perplexity is 46.95133223427922
At time: 541.4753663539886 and batch: 1250, loss is 3.8079018449783324 and perplexity is 45.05580555867234
At time: 542.7014119625092 and batch: 1300, loss is 3.811115484237671 and perplexity is 45.20083157010608
At time: 543.9276247024536 and batch: 1350, loss is 3.684050803184509 and perplexity is 39.807319530562744
At time: 545.1534814834595 and batch: 1400, loss is 3.710217347145081 and perplexity is 40.86268695023695
At time: 546.3797914981842 and batch: 1450, loss is 3.627095217704773 and perplexity is 37.60342804707609
At time: 547.6047270298004 and batch: 1500, loss is 3.6188407135009766 and perplexity is 37.294307963900835
At time: 548.831999540329 and batch: 1550, loss is 3.6128059244155883 and perplexity is 37.069922421947936
At time: 550.0586078166962 and batch: 1600, loss is 3.7048743534088135 and perplexity is 40.64494009786089
At time: 551.2852094173431 and batch: 1650, loss is 3.632571105957031 and perplexity is 37.8099050234482
At time: 552.5148680210114 and batch: 1700, loss is 3.6666853713989256 and perplexity is 39.122015758139696
At time: 553.7426066398621 and batch: 1750, loss is 3.664360556602478 and perplexity is 39.03116995778542
At time: 554.9702868461609 and batch: 1800, loss is 3.6136947679519653 and perplexity is 37.102886430639465
At time: 556.1988728046417 and batch: 1850, loss is 3.6463554668426514 and perplexity is 38.334699064983006
At time: 557.4258444309235 and batch: 1900, loss is 3.7161633491516115 and perplexity is 41.10638035158195
At time: 558.6536245346069 and batch: 1950, loss is 3.651390690803528 and perplexity is 38.52820963593273
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3865265602289245 and perplexity of 80.36080523391118
finished 11 epochs...
Completing Train Step...
At time: 562.6523008346558 and batch: 50, loss is 3.9112203979492186 and perplexity is 49.9598857262151
At time: 563.8795254230499 and batch: 100, loss is 3.896232719421387 and perplexity is 49.216686348394184
At time: 565.1085813045502 and batch: 150, loss is 3.8682869482040405 and perplexity is 47.860328594669724
At time: 566.3375363349915 and batch: 200, loss is 3.871295304298401 and perplexity is 48.00452629614104
At time: 567.5674307346344 and batch: 250, loss is 3.873954701423645 and perplexity is 48.132359299391936
At time: 568.7984693050385 and batch: 300, loss is 3.8693894386291503 and perplexity is 47.91312324613923
At time: 570.0299382209778 and batch: 350, loss is 3.8908868551254274 and perplexity is 48.954282634321906
At time: 571.2604296207428 and batch: 400, loss is 3.872644600868225 and perplexity is 48.069342357019075
At time: 572.4915673732758 and batch: 450, loss is 3.895557894706726 and perplexity is 49.183484915906156
At time: 573.7237186431885 and batch: 500, loss is 3.906882853507996 and perplexity is 49.7436518027495
At time: 574.9544343948364 and batch: 550, loss is 3.8586853694915773 and perplexity is 47.40299296796009
At time: 576.1859498023987 and batch: 600, loss is 3.8231385374069213 and perplexity is 45.74756367997949
At time: 577.4175074100494 and batch: 650, loss is 3.846313076019287 and perplexity is 46.820122385604336
At time: 578.6953876018524 and batch: 700, loss is 3.866418414115906 and perplexity is 47.77098343745231
At time: 579.9254360198975 and batch: 750, loss is 3.8382378816604614 and perplexity is 46.44356323783365
At time: 581.1557652950287 and batch: 800, loss is 3.8029851865768434 and perplexity is 44.83482524125954
At time: 582.388365983963 and batch: 850, loss is 3.8085462760925295 and perplexity is 45.084850279305236
At time: 583.6184370517731 and batch: 900, loss is 3.7853117322921754 and perplexity is 44.04940003912069
At time: 584.8494789600372 and batch: 950, loss is 3.886817374229431 and perplexity is 48.755468925034265
At time: 586.0806849002838 and batch: 1000, loss is 3.8542780828475953 and perplexity is 47.19453409659579
At time: 587.3127548694611 and batch: 1050, loss is 3.7974690532684328 and perplexity is 44.588191226796255
At time: 588.543655872345 and batch: 1100, loss is 3.8262304162979124 and perplexity is 45.8892284988111
At time: 589.7741985321045 and batch: 1150, loss is 3.7953007125854494 and perplexity is 44.49161358223637
At time: 591.0047838687897 and batch: 1200, loss is 3.8375465154647825 and perplexity is 46.41146482536135
At time: 592.2361257076263 and batch: 1250, loss is 3.797120981216431 and perplexity is 44.57267402428981
At time: 593.4650673866272 and batch: 1300, loss is 3.8005135679244995 and perplexity is 44.72414748386671
At time: 594.6970450878143 and batch: 1350, loss is 3.674825429916382 and perplexity is 39.44177090293263
At time: 595.9295945167542 and batch: 1400, loss is 3.7021926641464233 and perplexity is 40.536089016051754
At time: 597.1605644226074 and batch: 1450, loss is 3.6205249786376954 and perplexity is 37.35717439360904
At time: 598.391125202179 and batch: 1500, loss is 3.614716200828552 and perplexity is 37.14080390043442
At time: 599.6220202445984 and batch: 1550, loss is 3.6102214813232423 and perplexity is 36.97424101184786
At time: 600.8532137870789 and batch: 1600, loss is 3.7039549732208252 and perplexity is 40.60758911769946
At time: 602.0833623409271 and batch: 1650, loss is 3.6330330753326416 and perplexity is 37.82737607689889
At time: 603.3131041526794 and batch: 1700, loss is 3.668740863800049 and perplexity is 39.20251346711951
At time: 604.5425989627838 and batch: 1750, loss is 3.6677785682678223 and perplexity is 39.164807208749735
At time: 605.7723562717438 and batch: 1800, loss is 3.6183803415298463 and perplexity is 37.277142661346815
At time: 607.0024576187134 and batch: 1850, loss is 3.6516996955871583 and perplexity is 38.54011687661737
At time: 608.2326736450195 and batch: 1900, loss is 3.7214702939987183 and perplexity is 41.32510952344676
At time: 609.4625747203827 and batch: 1950, loss is 3.6565839290618896 and perplexity is 38.72881625636975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385450922056686 and perplexity of 80.2744125562104
finished 12 epochs...
Completing Train Step...
At time: 613.4468157291412 and batch: 50, loss is 3.9055449199676513 and perplexity is 49.677142604947946
At time: 614.7042210102081 and batch: 100, loss is 3.8884762477874757 and perplexity is 48.836415204502636
At time: 615.9342200756073 and batch: 150, loss is 3.859116864204407 and perplexity is 47.42345152235966
At time: 617.1653969287872 and batch: 200, loss is 3.8613322734832765 and perplexity is 47.52863034094517
At time: 618.3960962295532 and batch: 250, loss is 3.8638315105438235 and perplexity is 47.64756421539677
At time: 619.6260802745819 and batch: 300, loss is 3.858667869567871 and perplexity is 47.40216342645818
At time: 620.8570232391357 and batch: 350, loss is 3.880299391746521 and perplexity is 48.43871505214827
At time: 622.0882427692413 and batch: 400, loss is 3.8619114685058595 and perplexity is 47.55616666074873
At time: 623.3181960582733 and batch: 450, loss is 3.8852042961120605 and perplexity is 48.676885942293616
At time: 624.549352645874 and batch: 500, loss is 3.8967982435226443 and perplexity is 49.24452744237105
At time: 625.7789540290833 and batch: 550, loss is 3.8489580488204957 and perplexity is 46.94412425435674
At time: 627.0088438987732 and batch: 600, loss is 3.81422203540802 and perplexity is 45.34146860128452
At time: 628.2364974021912 and batch: 650, loss is 3.837288022041321 and perplexity is 46.39946931737752
At time: 629.4617881774902 and batch: 700, loss is 3.858110475540161 and perplexity is 47.375749105939875
At time: 630.6887209415436 and batch: 750, loss is 3.830208821296692 and perplexity is 46.07215807755658
At time: 631.9143486022949 and batch: 800, loss is 3.795041241645813 and perplexity is 44.48007079902741
At time: 633.1386222839355 and batch: 850, loss is 3.8006905937194824 and perplexity is 44.73206551245695
At time: 634.363879442215 and batch: 900, loss is 3.777841763496399 and perplexity is 43.72157832871085
At time: 635.5893204212189 and batch: 950, loss is 3.879525370597839 and perplexity is 48.40123696856871
At time: 636.8212542533875 and batch: 1000, loss is 3.8468931531906128 and perplexity is 46.84728954852262
At time: 638.0509481430054 and batch: 1050, loss is 3.7901834440231323 and perplexity is 44.26451959279665
At time: 639.3275241851807 and batch: 1100, loss is 3.8189292049407957 and perplexity is 45.555401695509964
At time: 640.5580544471741 and batch: 1150, loss is 3.788291811943054 and perplexity is 44.18086655285708
At time: 641.7893631458282 and batch: 1200, loss is 3.8310706567764283 and perplexity is 46.111881813219476
At time: 643.0198900699615 and batch: 1250, loss is 3.79108118057251 and perplexity is 44.30427531228693
At time: 644.2502219676971 and batch: 1300, loss is 3.7948199892044068 and perplexity is 44.47023056339742
At time: 645.4789967536926 and batch: 1350, loss is 3.669951529502869 and perplexity is 39.25000334702236
At time: 646.7094120979309 and batch: 1400, loss is 3.6979909133911133 and perplexity is 40.36612379920751
At time: 647.9384820461273 and batch: 1450, loss is 3.6168321418762206 and perplexity is 37.21947485414869
At time: 649.16810297966 and batch: 1500, loss is 3.611866707801819 and perplexity is 37.03512208002595
At time: 650.3985743522644 and batch: 1550, loss is 3.607926149368286 and perplexity is 36.88947018076011
At time: 651.6276984214783 and batch: 1600, loss is 3.702467613220215 and perplexity is 40.547235908525515
At time: 652.8591201305389 and batch: 1650, loss is 3.6320437240600585 and perplexity is 37.78997002115429
At time: 654.0880155563354 and batch: 1700, loss is 3.6683185482025147 and perplexity is 39.18596112962096
At time: 655.3182263374329 and batch: 1750, loss is 3.668089647293091 and perplexity is 39.176992453989904
At time: 656.5487685203552 and batch: 1800, loss is 3.6191677808761598 and perplexity is 37.30650771027662
At time: 657.7803068161011 and batch: 1850, loss is 3.6527335405349732 and perplexity is 38.57998198535832
At time: 659.0116083621979 and batch: 1900, loss is 3.722314267158508 and perplexity is 41.36000152859674
At time: 660.2431421279907 and batch: 1950, loss is 3.657490372657776 and perplexity is 38.76393765922217
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385523880359738 and perplexity of 80.2802694547811
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 664.20747590065 and batch: 50, loss is 3.9038738203048706 and perplexity is 49.59419647362172
At time: 665.4640355110168 and batch: 100, loss is 3.8932768583297728 and perplexity is 49.071423454391876
At time: 666.6925933361053 and batch: 150, loss is 3.8682025241851807 and perplexity is 47.85628820394122
At time: 667.921571969986 and batch: 200, loss is 3.87493492603302 and perplexity is 48.17956295379675
At time: 669.1497042179108 and batch: 250, loss is 3.8799994659423827 and perplexity is 48.42418921003116
At time: 670.4053993225098 and batch: 300, loss is 3.875182204246521 and perplexity is 48.19147818317882
At time: 671.6352968215942 and batch: 350, loss is 3.8954698276519775 and perplexity is 49.17915366197052
At time: 672.864768743515 and batch: 400, loss is 3.884251871109009 and perplexity is 48.63054692977145
At time: 674.0939319133759 and batch: 450, loss is 3.910648865699768 and perplexity is 49.93134019846558
At time: 675.3239870071411 and batch: 500, loss is 3.926527280807495 and perplexity is 50.730498639232536
At time: 676.553439617157 and batch: 550, loss is 3.8914854240417482 and perplexity is 48.98359391776403
At time: 677.7827136516571 and batch: 600, loss is 3.8580523109436036 and perplexity is 47.372993594743896
At time: 679.0128331184387 and batch: 650, loss is 3.877442240715027 and perplexity is 48.30051584948359
At time: 680.2418880462646 and batch: 700, loss is 3.891869969367981 and perplexity is 49.00243395205858
At time: 681.4713571071625 and batch: 750, loss is 3.8562279081344606 and perplexity is 47.28664496344545
At time: 682.699666261673 and batch: 800, loss is 3.8109380769729615 and perplexity is 45.192813325483094
At time: 683.9281377792358 and batch: 850, loss is 3.813714461326599 and perplexity is 45.31846028671499
At time: 685.1583771705627 and batch: 900, loss is 3.7841137409210206 and perplexity is 43.996660834832646
At time: 686.3880937099457 and batch: 950, loss is 3.8869520568847657 and perplexity is 48.76203588326893
At time: 687.6175439357758 and batch: 1000, loss is 3.856928768157959 and perplexity is 47.3197978989722
At time: 688.8478178977966 and batch: 1050, loss is 3.8007022094726564 and perplexity is 44.73258511210667
At time: 690.0777153968811 and batch: 1100, loss is 3.825122561454773 and perplexity is 45.83841804527109
At time: 691.3068852424622 and batch: 1150, loss is 3.7943127965927124 and perplexity is 44.447681309906095
At time: 692.5366086959839 and batch: 1200, loss is 3.8356151580810547 and perplexity is 46.32191420504352
At time: 693.7659168243408 and batch: 1250, loss is 3.7942535305023193 and perplexity is 44.445047147666834
At time: 694.9949772357941 and batch: 1300, loss is 3.7941852903366087 and perplexity is 44.44201431376619
At time: 696.2259883880615 and batch: 1350, loss is 3.6663525915145874 and perplexity is 39.108998904254314
At time: 697.4563813209534 and batch: 1400, loss is 3.6972559881210327 and perplexity is 40.3364686132798
At time: 698.688042640686 and batch: 1450, loss is 3.6167248058319093 and perplexity is 37.21548007734211
At time: 699.9179084300995 and batch: 1500, loss is 3.6145685577392577 and perplexity is 37.13532072219433
At time: 701.147472858429 and batch: 1550, loss is 3.615758490562439 and perplexity is 37.1795355603475
At time: 702.3764719963074 and batch: 1600, loss is 3.7104091119766234 and perplexity is 40.8705237279015
At time: 703.6057105064392 and batch: 1650, loss is 3.635786099433899 and perplexity is 37.931659236086475
At time: 704.8341805934906 and batch: 1700, loss is 3.662414216995239 and perplexity is 38.95527592751696
At time: 706.0640728473663 and batch: 1750, loss is 3.6599949169158936 and perplexity is 38.86114533636021
At time: 707.2934153079987 and batch: 1800, loss is 3.6060208082199097 and perplexity is 36.81925007315661
At time: 708.5226888656616 and batch: 1850, loss is 3.6422483921051025 and perplexity is 38.17757846476558
At time: 709.7516529560089 and batch: 1900, loss is 3.711750135421753 and perplexity is 40.92536882449633
At time: 710.9800500869751 and batch: 1950, loss is 3.6566802263259888 and perplexity is 38.732545914992116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379714185138082 and perplexity of 79.81521776927022
finished 14 epochs...
Completing Train Step...
At time: 714.9599545001984 and batch: 50, loss is 3.9089831590652464 and perplexity is 49.84823846459552
At time: 716.2214720249176 and batch: 100, loss is 3.8918562078475953 and perplexity is 49.00175960870482
At time: 717.455244064331 and batch: 150, loss is 3.860962748527527 and perplexity is 47.5110705705081
At time: 718.6883780956268 and batch: 200, loss is 3.864271583557129 and perplexity is 47.66853723704965
At time: 719.9192891120911 and batch: 250, loss is 3.867423725128174 and perplexity is 47.819032281137986
At time: 721.1514012813568 and batch: 300, loss is 3.8623527574539183 and perplexity is 47.57715730263666
At time: 722.3831875324249 and batch: 350, loss is 3.8831861209869385 and perplexity is 48.57874652649077
At time: 723.6153962612152 and batch: 400, loss is 3.8709722757339478 and perplexity is 47.98902196722971
At time: 724.8477513790131 and batch: 450, loss is 3.8978059673309327 and perplexity is 49.294177337591734
At time: 726.0794081687927 and batch: 500, loss is 3.913254909515381 and perplexity is 50.06163315963791
At time: 727.3099544048309 and batch: 550, loss is 3.8751195669174194 and perplexity is 48.18845969223606
At time: 728.541029214859 and batch: 600, loss is 3.8427592420578005 and perplexity is 46.6540267575433
At time: 729.7733829021454 and batch: 650, loss is 3.8619780683517457 and perplexity is 47.55933399959024
At time: 731.0048184394836 and batch: 700, loss is 3.8780951833724977 and perplexity is 48.33206361497966
At time: 732.2634160518646 and batch: 750, loss is 3.842733416557312 and perplexity is 46.65282190951046
At time: 733.4948179721832 and batch: 800, loss is 3.799049835205078 and perplexity is 44.658731173522874
At time: 734.7267272472382 and batch: 850, loss is 3.8019042778015137 and perplexity is 44.78638906747445
At time: 735.9584195613861 and batch: 900, loss is 3.773555178642273 and perplexity is 43.534563187747764
At time: 737.1896522045135 and batch: 950, loss is 3.8769547653198244 and perplexity is 48.276976274379365
At time: 738.4205052852631 and batch: 1000, loss is 3.8472107219696046 and perplexity is 46.86216914758662
At time: 739.6518404483795 and batch: 1050, loss is 3.7920803785324098 and perplexity is 44.34856617778004
At time: 740.8827168941498 and batch: 1100, loss is 3.81842098236084 and perplexity is 45.53225529398951
At time: 742.1161828041077 and batch: 1150, loss is 3.788762707710266 and perplexity is 44.2016760350726
At time: 743.3482882976532 and batch: 1200, loss is 3.8310423851013184 and perplexity is 46.1105781715063
At time: 744.5789318084717 and batch: 1250, loss is 3.7904806470870973 and perplexity is 44.27767709877327
At time: 745.8112368583679 and batch: 1300, loss is 3.791841082572937 and perplexity is 44.33795501474015
At time: 747.0377492904663 and batch: 1350, loss is 3.6649963521957396 and perplexity is 39.05599369421932
At time: 748.2675547599792 and batch: 1400, loss is 3.6962043333053587 and perplexity is 40.29407086961859
At time: 749.4982044696808 and batch: 1450, loss is 3.6171644020080564 and perplexity is 37.23184345645352
At time: 750.7294814586639 and batch: 1500, loss is 3.6171580839157103 and perplexity is 37.23160822297146
At time: 751.9589252471924 and batch: 1550, loss is 3.6181539058685304 and perplexity is 37.268702742481686
At time: 753.1857168674469 and batch: 1600, loss is 3.7135886096954347 and perplexity is 41.00067826824648
At time: 754.4131224155426 and batch: 1650, loss is 3.639690647125244 and perplexity is 38.08005472869451
At time: 755.6396701335907 and batch: 1700, loss is 3.666223111152649 and perplexity is 39.10393538474138
At time: 756.867862701416 and batch: 1750, loss is 3.6644331979751588 and perplexity is 39.034005338530214
At time: 758.0956115722656 and batch: 1800, loss is 3.6107771158218385 and perplexity is 36.99479088429379
At time: 759.3236002922058 and batch: 1850, loss is 3.647588849067688 and perplexity is 38.382009571383186
At time: 760.5503385066986 and batch: 1900, loss is 3.717590317726135 and perplexity is 41.1650797356838
At time: 761.7778911590576 and batch: 1950, loss is 3.662913374900818 and perplexity is 38.97472561528905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378157362827035 and perplexity of 79.69105633121191
finished 15 epochs...
Completing Train Step...
At time: 765.7914509773254 and batch: 50, loss is 3.909288544654846 and perplexity is 49.863463722958464
At time: 767.0166308879852 and batch: 100, loss is 3.8894141149520873 and perplexity is 48.88223875960528
At time: 768.2405967712402 and batch: 150, loss is 3.85666895866394 and perplexity is 47.3075053631509
At time: 769.4653608798981 and batch: 200, loss is 3.8588733434677125 and perplexity is 47.41190433455525
At time: 770.6892807483673 and batch: 250, loss is 3.861236324310303 and perplexity is 47.524070226944474
At time: 771.9133706092834 and batch: 300, loss is 3.856270880699158 and perplexity is 47.28867703551682
At time: 773.1367928981781 and batch: 350, loss is 3.8773308610916137 and perplexity is 48.295136455800595
At time: 774.361839056015 and batch: 400, loss is 3.864715781211853 and perplexity is 47.6897161929675
At time: 775.5883166790009 and batch: 450, loss is 3.891384701728821 and perplexity is 48.97866042534969
At time: 776.8145794868469 and batch: 500, loss is 3.9067896032333373 and perplexity is 49.739013409825446
At time: 778.0441198348999 and batch: 550, loss is 3.8677850914001466 and perplexity is 47.83631558917698
At time: 779.2707524299622 and batch: 600, loss is 3.8359583139419557 and perplexity is 46.337812569043514
At time: 780.4974188804626 and batch: 650, loss is 3.855203595161438 and perplexity is 47.238233438068264
At time: 781.725035905838 and batch: 700, loss is 3.8719294977188112 and perplexity is 48.034980106650366
At time: 782.9512875080109 and batch: 750, loss is 3.8370175695419313 and perplexity is 46.38692216171158
At time: 784.1777498722076 and batch: 800, loss is 3.794095916748047 and perplexity is 44.438042548952126
At time: 785.4033279418945 and batch: 850, loss is 3.7971451759338377 and perplexity is 44.573752460588075
At time: 786.6292088031769 and batch: 900, loss is 3.7695372486114502 and perplexity is 43.35999529457563
At time: 787.8547945022583 and batch: 950, loss is 3.8733942794799803 and perplexity is 48.10539242615976
At time: 789.081125497818 and batch: 1000, loss is 3.843836283683777 and perplexity is 46.70430215586894
At time: 790.3078625202179 and batch: 1050, loss is 3.7891732835769654 and perplexity is 44.219827902624644
At time: 791.5341949462891 and batch: 1100, loss is 3.8162406206130983 and perplexity is 45.433086657296215
At time: 792.8064522743225 and batch: 1150, loss is 3.786975588798523 and perplexity is 44.12275292739407
At time: 794.032744884491 and batch: 1200, loss is 3.8298527097702024 and perplexity is 46.0557541719982
At time: 795.2595455646515 and batch: 1250, loss is 3.789399743080139 and perplexity is 44.22984303685026
At time: 796.4869856834412 and batch: 1300, loss is 3.791031150817871 and perplexity is 44.30205883570895
At time: 797.7126867771149 and batch: 1350, loss is 3.6643797063827517 and perplexity is 39.03191740327062
At time: 798.9405207633972 and batch: 1400, loss is 3.695603952407837 and perplexity is 40.269886339876365
At time: 800.1679937839508 and batch: 1450, loss is 3.617014179229736 and perplexity is 37.2262508055698
At time: 801.394434928894 and batch: 1500, loss is 3.617704906463623 and perplexity is 37.25197287326037
At time: 802.6221070289612 and batch: 1550, loss is 3.618903179168701 and perplexity is 37.29663765051208
At time: 803.8481621742249 and batch: 1600, loss is 3.7146176958084105 and perplexity is 41.04289321455689
At time: 805.0750954151154 and batch: 1650, loss is 3.6410091304779053 and perplexity is 38.130295760626595
At time: 806.3026361465454 and batch: 1700, loss is 3.667493615150452 and perplexity is 39.15364866475084
At time: 807.5289113521576 and batch: 1750, loss is 3.666002035140991 and perplexity is 39.095291398190646
At time: 808.7564239501953 and batch: 1800, loss is 3.612573709487915 and perplexity is 37.061315231991536
At time: 809.9845094680786 and batch: 1850, loss is 3.649545125961304 and perplexity is 38.45716890209955
At time: 811.2117896080017 and batch: 1900, loss is 3.719696865081787 and perplexity is 41.251887325594666
At time: 812.4388556480408 and batch: 1950, loss is 3.6648951959609986 and perplexity is 39.05204313676826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377462413699128 and perplexity of 79.63569434022432
finished 16 epochs...
Completing Train Step...
At time: 816.465558052063 and batch: 50, loss is 3.907928018569946 and perplexity is 49.7956693083721
At time: 817.6952538490295 and batch: 100, loss is 3.886758008003235 and perplexity is 48.75257458275169
At time: 818.9247119426727 and batch: 150, loss is 3.853310770988464 and perplexity is 47.148904336739854
At time: 820.1534540653229 and batch: 200, loss is 3.8550668573379516 and perplexity is 47.23177462643459
At time: 821.3832659721375 and batch: 250, loss is 3.8571110582351684 and perplexity is 47.3284246148432
At time: 822.615021944046 and batch: 300, loss is 3.852167944908142 and perplexity is 47.095052116927
At time: 823.8742978572845 and batch: 350, loss is 3.873393831253052 and perplexity is 48.1053708640323
At time: 825.10693192482 and batch: 400, loss is 3.8605805587768556 and perplexity is 47.492915795798034
At time: 826.3379209041595 and batch: 450, loss is 3.887181158065796 and perplexity is 48.77320860307201
At time: 827.5683467388153 and batch: 500, loss is 3.902589373588562 and perplexity is 49.53053626363929
At time: 828.8000390529633 and batch: 550, loss is 3.8633698558807374 and perplexity is 47.625572571855024
At time: 830.0306384563446 and batch: 600, loss is 3.8319045066833497 and perplexity is 46.1503482369605
At time: 831.2607786655426 and batch: 650, loss is 3.8511671113967894 and perplexity is 47.047941389479305
At time: 832.4919176101685 and batch: 700, loss is 3.868298044204712 and perplexity is 47.86085965585427
At time: 833.7233757972717 and batch: 750, loss is 3.8336947345733643 and perplexity is 46.233041875651836
At time: 834.9550008773804 and batch: 800, loss is 3.7911562156677245 and perplexity is 44.30759981252894
At time: 836.1873590946198 and batch: 850, loss is 3.794316668510437 and perplexity is 44.44785340800435
At time: 837.4179563522339 and batch: 900, loss is 3.767147979736328 and perplexity is 43.25652027144376
At time: 838.6488029956818 and batch: 950, loss is 3.871274948120117 and perplexity is 48.00354911739117
At time: 839.8793425559998 and batch: 1000, loss is 3.841832609176636 and perplexity is 46.610815625830696
At time: 841.1102814674377 and batch: 1050, loss is 3.787414026260376 and perplexity is 44.14210223661859
At time: 842.3413994312286 and batch: 1100, loss is 3.8147703790664673 and perplexity is 45.36633812595664
At time: 843.5719561576843 and batch: 1150, loss is 3.7857107019424436 and perplexity is 44.06697791913598
At time: 844.8038129806519 and batch: 1200, loss is 3.828912229537964 and perplexity is 46.01246000746272
At time: 846.0341544151306 and batch: 1250, loss is 3.7885272455215455 and perplexity is 44.19126943691653
At time: 847.2655682563782 and batch: 1300, loss is 3.7902125930786132 and perplexity is 44.265809880539344
At time: 848.4948198795319 and batch: 1350, loss is 3.6636187076568603 and perplexity is 39.0022254630549
At time: 849.7247042655945 and batch: 1400, loss is 3.6948448038101196 and perplexity is 40.239327113095925
At time: 850.9556303024292 and batch: 1450, loss is 3.616417951583862 and perplexity is 37.204062101104114
At time: 852.1858887672424 and batch: 1500, loss is 3.617425870895386 and perplexity is 37.24157969794195
At time: 853.4162437915802 and batch: 1550, loss is 3.6188339042663573 and perplexity is 37.29405401907253
At time: 854.6468849182129 and batch: 1600, loss is 3.7147361516952513 and perplexity is 41.04775527483528
At time: 855.8939390182495 and batch: 1650, loss is 3.641272072792053 and perplexity is 38.140323147087365
At time: 857.1170988082886 and batch: 1700, loss is 3.6677940320968627 and perplexity is 39.16541285131557
At time: 858.3396565914154 and batch: 1750, loss is 3.666494565010071 and perplexity is 39.114551739702016
At time: 859.561594247818 and batch: 1800, loss is 3.613246855735779 and perplexity is 37.08627131588562
At time: 860.7850058078766 and batch: 1850, loss is 3.650311493873596 and perplexity is 38.48665253855716
At time: 862.0079517364502 and batch: 1900, loss is 3.7204822444915773 and perplexity is 41.28429843435793
At time: 863.230776309967 and batch: 1950, loss is 3.6655052375793455 and perplexity is 39.07587377646513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377123739553053 and perplexity of 79.60872835604512
finished 17 epochs...
Completing Train Step...
At time: 867.2664158344269 and batch: 50, loss is 3.9062193202972413 and perplexity is 49.71065618580859
At time: 868.4906272888184 and batch: 100, loss is 3.8843129682540893 and perplexity is 48.63351820811995
At time: 869.7144539356232 and batch: 150, loss is 3.85054949760437 and perplexity is 47.01889290326847
At time: 870.9383382797241 and batch: 200, loss is 3.852066469192505 and perplexity is 47.090273355278704
At time: 872.1612102985382 and batch: 250, loss is 3.853936595916748 and perplexity is 47.17842053143691
At time: 873.3844859600067 and batch: 300, loss is 3.8489834022521974 and perplexity is 46.945314464092704
At time: 874.6085917949677 and batch: 350, loss is 3.8703335618972776 and perplexity is 47.95838050149674
At time: 875.8310837745667 and batch: 400, loss is 3.857419810295105 and perplexity is 47.343039619526884
At time: 877.0533585548401 and batch: 450, loss is 3.884007019996643 and perplexity is 48.618641143892674
At time: 878.2767333984375 and batch: 500, loss is 3.8994234561920167 and perplexity is 49.373974638576726
At time: 879.500714302063 and batch: 550, loss is 3.8601669549942015 and perplexity is 47.47327660787679
At time: 880.7238914966583 and batch: 600, loss is 3.828991422653198 and perplexity is 46.01610402179881
At time: 881.9469830989838 and batch: 650, loss is 3.8482367277145384 and perplexity is 46.91027467640656
At time: 883.1700019836426 and batch: 700, loss is 3.8656743288040163 and perplexity is 47.73545097157437
At time: 884.393942117691 and batch: 750, loss is 3.831269612312317 and perplexity is 46.121056940067334
At time: 885.6525421142578 and batch: 800, loss is 3.788958930969238 and perplexity is 44.21035028301299
At time: 886.8750050067902 and batch: 850, loss is 3.792166247367859 and perplexity is 44.35237450101737
At time: 888.0977191925049 and batch: 900, loss is 3.7652687406539918 and perplexity is 43.17530726121578
At time: 889.3210244178772 and batch: 950, loss is 3.8695525121688843 and perplexity is 47.92093724585767
At time: 890.5461826324463 and batch: 1000, loss is 3.840173463821411 and perplexity is 46.5335456263877
At time: 891.7698111534119 and batch: 1050, loss is 3.7859007358551025 and perplexity is 44.07535293511233
At time: 892.9935042858124 and batch: 1100, loss is 3.8133984184265137 and perplexity is 45.304139972134635
At time: 894.2162606716156 and batch: 1150, loss is 3.7844873332977294 and perplexity is 44.01310072263835
At time: 895.4399516582489 and batch: 1200, loss is 3.8278876686096193 and perplexity is 45.96534158069336
At time: 896.6638240814209 and batch: 1250, loss is 3.787579689025879 and perplexity is 44.14941554510495
At time: 897.8871705532074 and batch: 1300, loss is 3.7892955589294433 and perplexity is 44.22523522825253
At time: 899.1116008758545 and batch: 1350, loss is 3.6627546405792235 and perplexity is 38.968539479648186
At time: 900.3345673084259 and batch: 1400, loss is 3.6940015745162964 and perplexity is 40.20541043548815
At time: 901.5580024719238 and batch: 1450, loss is 3.6156540012359617 and perplexity is 37.175650898674434
At time: 902.7818157672882 and batch: 1500, loss is 3.6168583965301515 and perplexity is 37.22045205140841
At time: 904.0063314437866 and batch: 1550, loss is 3.6184322214126587 and perplexity is 37.27907664530666
At time: 905.2294025421143 and batch: 1600, loss is 3.7144969749450683 and perplexity is 41.03793878011179
At time: 906.4561109542847 and batch: 1650, loss is 3.6411258363723755 and perplexity is 38.13474605058224
At time: 907.6789817810059 and batch: 1700, loss is 3.667717237472534 and perplexity is 39.16240527363336
At time: 908.9024245738983 and batch: 1750, loss is 3.666559252738953 and perplexity is 39.11708205305952
At time: 910.1263101100922 and batch: 1800, loss is 3.613452262878418 and perplexity is 37.093889883335045
At time: 911.3497409820557 and batch: 1850, loss is 3.6505956983566286 and perplexity is 38.49759217221836
At time: 912.5737245082855 and batch: 1900, loss is 3.7207422399520875 and perplexity is 41.29503356002271
At time: 913.8005402088165 and batch: 1950, loss is 3.6656204414367677 and perplexity is 39.08037572717238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3769710097202035 and perplexity of 79.5965706567153
finished 18 epochs...
Completing Train Step...
At time: 917.859160900116 and batch: 50, loss is 3.904484176635742 and perplexity is 49.6244758450769
At time: 919.1068670749664 and batch: 100, loss is 3.882089409828186 and perplexity is 48.525498877079684
At time: 920.3287878036499 and batch: 150, loss is 3.848154067993164 and perplexity is 46.906397246428064
At time: 921.5521488189697 and batch: 200, loss is 3.8495104265213014 and perplexity is 46.97006230491954
At time: 922.7744295597076 and batch: 250, loss is 3.851264591217041 and perplexity is 47.05252783788862
At time: 923.9978034496307 and batch: 300, loss is 3.8462923336029053 and perplexity is 46.819151233202824
At time: 925.2199599742889 and batch: 350, loss is 3.8677394151687623 and perplexity is 47.834130656457674
At time: 926.4422907829285 and batch: 400, loss is 3.8547750997543333 and perplexity is 47.21799640804716
At time: 927.671288728714 and batch: 450, loss is 3.8813740730285646 and perplexity is 48.49079921446539
At time: 928.8930287361145 and batch: 500, loss is 3.8967991065979004 and perplexity is 49.244569944122524
At time: 930.1149260997772 and batch: 550, loss is 3.8575540590286255 and perplexity is 47.34939578928114
At time: 931.336944103241 and batch: 600, loss is 3.82662070274353 and perplexity is 45.90714193815295
At time: 932.5582747459412 and batch: 650, loss is 3.8458326387405397 and perplexity is 46.79763365605936
At time: 933.7797367572784 and batch: 700, loss is 3.863514437675476 and perplexity is 47.632458860416904
At time: 935.005179643631 and batch: 750, loss is 3.8292465209960938 and perplexity is 46.02784415106138
At time: 936.2267315387726 and batch: 800, loss is 3.787087278366089 and perplexity is 44.12768125380455
At time: 937.4491670131683 and batch: 850, loss is 3.7903122234344484 and perplexity is 44.270220318632184
At time: 938.6716992855072 and batch: 900, loss is 3.763597025871277 and perplexity is 43.10319075772634
At time: 939.8940713405609 and batch: 950, loss is 3.8679802227020263 and perplexity is 47.84565086248742
At time: 941.1163737773895 and batch: 1000, loss is 3.838637309074402 and perplexity is 46.46211777554074
At time: 942.3383047580719 and batch: 1050, loss is 3.784464888572693 and perplexity is 44.012112871780694
At time: 943.5605323314667 and batch: 1100, loss is 3.812050313949585 and perplexity is 45.24310640726928
At time: 944.7837827205658 and batch: 1150, loss is 3.7832631158828733 and perplexity is 43.959252086196415
At time: 946.0318536758423 and batch: 1200, loss is 3.8268024492263795 and perplexity is 45.9154861579812
At time: 947.254955291748 and batch: 1250, loss is 3.7865746545791628 and perplexity is 44.105066151746826
At time: 948.4767925739288 and batch: 1300, loss is 3.7883265018463135 and perplexity is 44.182399209427416
At time: 949.6999325752258 and batch: 1350, loss is 3.661849608421326 and perplexity is 38.933287652697494
At time: 950.9231283664703 and batch: 1400, loss is 3.6931317901611327 and perplexity is 40.170455602285635
At time: 952.1464133262634 and batch: 1450, loss is 3.614836082458496 and perplexity is 37.14525666744058
At time: 953.3691885471344 and batch: 1500, loss is 3.6161860418319702 and perplexity is 37.19543511667245
At time: 954.5913174152374 and batch: 1550, loss is 3.617887086868286 and perplexity is 37.25876007098135
At time: 955.8134286403656 and batch: 1600, loss is 3.714103422164917 and perplexity is 41.021791362852085
At time: 957.0371379852295 and batch: 1650, loss is 3.6408022594451905 and perplexity is 38.12240852281352
At time: 958.2607114315033 and batch: 1700, loss is 3.6674707651138307 and perplexity is 39.152754012666456
At time: 959.4839906692505 and batch: 1750, loss is 3.666425199508667 and perplexity is 39.111838633307485
At time: 960.706059217453 and batch: 1800, loss is 3.613429894447327 and perplexity is 37.093060160495135
At time: 961.9284491539001 and batch: 1850, loss is 3.6506449222564696 and perplexity is 38.49948722048002
At time: 963.1502029895782 and batch: 1900, loss is 3.720755009651184 and perplexity is 41.29556088854235
At time: 964.3727135658264 and batch: 1950, loss is 3.6655230855941774 and perplexity is 39.07657120946374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3769281431686045 and perplexity of 79.59315869934208
finished 19 epochs...
Completing Train Step...
At time: 968.3077290058136 and batch: 50, loss is 3.902792897224426 and perplexity is 49.54061792435928
At time: 969.5538401603699 and batch: 100, loss is 3.880037775039673 and perplexity is 48.42604433254062
At time: 970.7753913402557 and batch: 150, loss is 3.8459914255142214 and perplexity is 46.80506509131474
At time: 971.9973862171173 and batch: 200, loss is 3.8472227573394777 and perplexity is 46.862733154519375
At time: 973.2189404964447 and batch: 250, loss is 3.8488906717300413 and perplexity is 46.94096140240362
At time: 974.4405505657196 and batch: 300, loss is 3.843897738456726 and perplexity is 46.7071724463493
At time: 975.6618473529816 and batch: 350, loss is 3.8654232454299926 and perplexity is 47.723466898047654
At time: 976.9080832004547 and batch: 400, loss is 3.852434868812561 and perplexity is 47.10762458998902
At time: 978.129424571991 and batch: 450, loss is 3.8790569829940797 and perplexity is 48.37857173763698
At time: 979.3505027294159 and batch: 500, loss is 3.8944896841049195 and perplexity is 49.13097464689139
At time: 980.5716969966888 and batch: 550, loss is 3.855267434120178 and perplexity is 47.24124917396337
At time: 981.7929410934448 and batch: 600, loss is 3.8245418643951417 and perplexity is 45.81180753776357
At time: 983.0148601531982 and batch: 650, loss is 3.843717875480652 and perplexity is 46.69877231076842
At time: 984.2389385700226 and batch: 700, loss is 3.86160014629364 and perplexity is 47.541363674108055
At time: 985.4601588249207 and batch: 750, loss is 3.82743483543396 and perplexity is 45.9445316611617
At time: 986.6809225082397 and batch: 800, loss is 3.785385990142822 and perplexity is 44.05267117434211
At time: 987.9020957946777 and batch: 850, loss is 3.7886168909072877 and perplexity is 44.19523115788399
At time: 989.1230454444885 and batch: 900, loss is 3.762035837173462 and perplexity is 43.03595104407312
At time: 990.3435316085815 and batch: 950, loss is 3.866490478515625 and perplexity is 47.774426148744695
At time: 991.5655174255371 and batch: 1000, loss is 3.8371699380874635 and perplexity is 46.393990608063845
At time: 992.787505865097 and batch: 1050, loss is 3.7830763244628907 and perplexity is 43.951041641922004
At time: 994.0078451633453 and batch: 1100, loss is 3.810727906227112 and perplexity is 45.18331611625217
At time: 995.2297325134277 and batch: 1150, loss is 3.782049884796143 and perplexity is 43.90595169440002
At time: 996.4523465633392 and batch: 1200, loss is 3.825696449279785 and perplexity is 45.86473170512742
At time: 997.6734066009521 and batch: 1250, loss is 3.785546522140503 and perplexity is 44.05974360530945
At time: 998.8948831558228 and batch: 1300, loss is 3.7873392868041993 and perplexity is 44.13880320318844
At time: 1000.1163778305054 and batch: 1350, loss is 3.660934362411499 and perplexity is 38.89767041827607
At time: 1001.3382005691528 and batch: 1400, loss is 3.6922595500946045 and perplexity is 40.13543259787294
At time: 1002.5595436096191 and batch: 1450, loss is 3.614005026817322 and perplexity is 37.11439971604196
At time: 1003.7797706127167 and batch: 1500, loss is 3.6154714822769165 and perplexity is 37.1688662567523
At time: 1005.0000066757202 and batch: 1550, loss is 3.617271876335144 and perplexity is 37.23584513881045
At time: 1006.2218263149261 and batch: 1600, loss is 3.713632550239563 and perplexity is 41.00247989994126
At time: 1007.4424998760223 and batch: 1650, loss is 3.640388345718384 and perplexity is 38.10663239982916
At time: 1008.6642055511475 and batch: 1700, loss is 3.667133345603943 and perplexity is 39.139545338154306
At time: 1009.887095451355 and batch: 1750, loss is 3.6661813402175905 and perplexity is 39.10230201090991
At time: 1011.1087350845337 and batch: 1800, loss is 3.6132786417007448 and perplexity is 37.087450157541596
At time: 1012.3299322128296 and batch: 1850, loss is 3.6505586528778076 and perplexity is 38.496166036898984
At time: 1013.5512912273407 and batch: 1900, loss is 3.7206326484680177 and perplexity is 41.29050822398383
At time: 1014.7738769054413 and batch: 1950, loss is 3.665316824913025 and perplexity is 39.06851208043826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.376956531613372 and perplexity of 79.59541825740419
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f8261144b38>
ELAPSED
3153.888606071472


RESULTS SO FAR:
[{'best_accuracy': -78.0513610743167, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}}, {'best_accuracy': -78.42215966096434, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.02990420607447708, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.45043527467939715}}, {'best_accuracy': -79.59315869934208, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.9149200001362663, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.10734533781315092}}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.46354086461744826, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.20663157340468064}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.890554666519165 and batch: 50, loss is 7.413953895568848 and perplexity is 1658.9728015457258
At time: 3.189842700958252 and batch: 100, loss is 6.528234434127808 and perplexity is 684.1891634417976
At time: 4.4884138107299805 and batch: 150, loss is 6.233476705551148 and perplexity is 509.52387210585783
At time: 5.786850214004517 and batch: 200, loss is 6.1006953907012935 and perplexity is 446.16792325624994
At time: 7.08685302734375 and batch: 250, loss is 6.018153810501099 and perplexity is 410.81944462927993
At time: 8.385459184646606 and batch: 300, loss is 5.950144166946411 and perplexity is 383.80866759635654
At time: 9.684382438659668 and batch: 350, loss is 5.899600582122803 and perplexity is 364.8916944890008
At time: 10.985553979873657 and batch: 400, loss is 5.8452553462982175 and perplexity is 345.59077584079023
At time: 12.29276156425476 and batch: 450, loss is 5.775842790603638 and perplexity is 322.416049462171
At time: 13.603397130966187 and batch: 500, loss is 5.741479473114014 and perplexity is 311.52496301733754
At time: 14.942206859588623 and batch: 550, loss is 5.687381935119629 and perplexity is 295.11996512602843
At time: 16.244464874267578 and batch: 600, loss is 5.723367147445678 and perplexity is 305.9333131885586
At time: 17.54573965072632 and batch: 650, loss is 5.802081289291382 and perplexity is 330.9877247332619
At time: 18.84869885444641 and batch: 700, loss is 5.7008442687988286 and perplexity is 299.1198319334839
At time: 20.151975631713867 and batch: 750, loss is 5.649982299804687 and perplexity is 284.2864338539836
At time: 21.454836130142212 and batch: 800, loss is 5.6475708961486815 and perplexity is 283.6017303880441
At time: 22.757237672805786 and batch: 850, loss is 5.6715717792510985 and perplexity is 290.4907631064817
At time: 24.05992603302002 and batch: 900, loss is 5.667503118515015 and perplexity is 289.31125587893746
At time: 25.362005949020386 and batch: 950, loss is 5.702337408065796 and perplexity is 299.56679310467
At time: 26.665215730667114 and batch: 1000, loss is 5.673309831619263 and perplexity is 290.99609028056585
At time: 27.96710467338562 and batch: 1050, loss is 5.573291501998901 and perplexity is 263.2993247671305
At time: 29.268945932388306 and batch: 1100, loss is 5.654971265792847 and perplexity is 285.7082730078617
At time: 30.576605796813965 and batch: 1150, loss is 5.562282819747924 and perplexity is 260.41664254308
At time: 31.885942220687866 and batch: 1200, loss is 5.642500352859497 and perplexity is 282.16735514131125
At time: 33.19623637199402 and batch: 1250, loss is 5.573506164550781 and perplexity is 263.35585133894523
At time: 34.50415539741516 and batch: 1300, loss is 5.583511047363281 and perplexity is 266.00392049159194
At time: 35.813952922821045 and batch: 1350, loss is 5.549540538787841 and perplexity is 257.119392374384
At time: 37.123223304748535 and batch: 1400, loss is 5.572576150894165 and perplexity is 263.1110406569344
At time: 38.440043449401855 and batch: 1450, loss is 5.529698905944824 and perplexity is 252.06800341909238
At time: 39.75593876838684 and batch: 1500, loss is 5.51705307006836 and perplexity is 248.90046312736993
At time: 41.07109880447388 and batch: 1550, loss is 5.495575876235962 and perplexity is 243.61177600611964
At time: 42.39021134376526 and batch: 1600, loss is 5.523023653030395 and perplexity is 250.3909892187676
At time: 43.70682978630066 and batch: 1650, loss is 5.500259008407593 and perplexity is 244.75531774027817
At time: 45.018524169921875 and batch: 1700, loss is 5.507817783355713 and perplexity is 246.6123778120755
At time: 46.32527017593384 and batch: 1750, loss is 5.5178350067138675 and perplexity is 249.09516363238257
At time: 47.64001941680908 and batch: 1800, loss is 5.529285278320312 and perplexity is 251.96376268953165
At time: 48.94417977333069 and batch: 1850, loss is 5.4918226146697995 and perplexity is 242.69915102165396
At time: 50.247984886169434 and batch: 1900, loss is 5.494324426651001 and perplexity is 243.30709883396923
At time: 51.55154824256897 and batch: 1950, loss is 5.428393497467041 and perplexity is 227.78301733527866
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.996745548691861 and perplexity of 147.93094080638852
finished 1 epochs...
Completing Train Step...
At time: 55.643637895584106 and batch: 50, loss is 5.248312501907349 and perplexity is 190.24495942452148
At time: 56.90878486633301 and batch: 100, loss is 5.174250202178955 and perplexity is 176.6641022451041
At time: 58.13023519515991 and batch: 150, loss is 5.091549501419068 and perplexity is 162.64168042125866
At time: 59.39326548576355 and batch: 200, loss is 5.068957271575928 and perplexity is 159.00843825146006
At time: 60.61448264122009 and batch: 250, loss is 5.064272813796997 and perplexity is 158.2653118670024
At time: 61.83609652519226 and batch: 300, loss is 5.072756233215332 and perplexity is 159.6136540766925
At time: 63.058300495147705 and batch: 350, loss is 5.0509923076629635 and perplexity is 156.1773636145848
At time: 64.2814450263977 and batch: 400, loss is 5.025538654327392 and perplexity is 152.25224535957395
At time: 65.5039746761322 and batch: 450, loss is 4.986167850494385 and perplexity is 146.37441868404005
At time: 66.72690272331238 and batch: 500, loss is 4.975282421112061 and perplexity is 144.7897110455973
At time: 67.94903779029846 and batch: 550, loss is 4.928896226882935 and perplexity is 138.22685701820586
At time: 69.17161560058594 and batch: 600, loss is 4.9137529850006105 and perplexity is 136.14942352589705
At time: 70.39412379264832 and batch: 650, loss is 4.981342458724976 and perplexity is 145.66980615183328
At time: 71.61693835258484 and batch: 700, loss is 4.96048900604248 and perplexity is 142.66354217658915
At time: 72.84140348434448 and batch: 750, loss is 4.919441289901734 and perplexity is 136.92608982217163
At time: 74.06424927711487 and batch: 800, loss is 4.897503480911255 and perplexity is 133.9549408262398
At time: 75.28679275512695 and batch: 850, loss is 4.892251853942871 and perplexity is 133.2533034279615
At time: 76.50870561599731 and batch: 900, loss is 4.905976934432983 and perplexity is 135.0948243461104
At time: 77.73038864135742 and batch: 950, loss is 4.967592048645019 and perplexity is 143.6804948478657
At time: 78.95249581336975 and batch: 1000, loss is 4.9327615451812745 and perplexity is 138.7621817516946
At time: 80.17525815963745 and batch: 1050, loss is 4.841562147140503 and perplexity is 126.66706985847799
At time: 81.39677214622498 and batch: 1100, loss is 4.923959770202637 and perplexity is 137.54618755638424
At time: 82.61879968643188 and batch: 1150, loss is 4.828484973907471 and perplexity is 125.02140640837423
At time: 83.8408191204071 and batch: 1200, loss is 4.908899087905883 and perplexity is 135.4901695045377
At time: 85.062166929245 and batch: 1250, loss is 4.862858438491822 and perplexity is 129.39353746278022
At time: 86.28368830680847 and batch: 1300, loss is 4.886975202560425 and perplexity is 132.55202403080875
At time: 87.50629496574402 and batch: 1350, loss is 4.791492004394531 and perplexity is 120.4809928006088
At time: 88.72813081741333 and batch: 1400, loss is 4.808879680633545 and perplexity is 122.59419590170624
At time: 89.95012784004211 and batch: 1450, loss is 4.7445752143859865 and perplexity is 114.95896221652959
At time: 91.17217898368835 and batch: 1500, loss is 4.73263261795044 and perplexity is 113.59421923204906
At time: 92.3932991027832 and batch: 1550, loss is 4.723762531280517 and perplexity is 112.59108418673823
At time: 93.61588478088379 and batch: 1600, loss is 4.800089550018311 and perplexity is 121.5212992660717
At time: 94.83839392662048 and batch: 1650, loss is 4.756927480697632 and perplexity is 116.38777228689429
At time: 96.06043195724487 and batch: 1700, loss is 4.777479104995727 and perplexity is 118.80447861479834
At time: 97.28182101249695 and batch: 1750, loss is 4.793660430908203 and perplexity is 120.74253043988614
At time: 98.50382995605469 and batch: 1800, loss is 4.748314170837403 and perplexity is 115.38959332375768
At time: 99.72574853897095 and batch: 1850, loss is 4.753338975906372 and perplexity is 115.97086269682082
At time: 100.95555210113525 and batch: 1900, loss is 4.8215569972991945 and perplexity is 124.15825442998037
At time: 102.18695378303528 and batch: 1950, loss is 4.749571714401245 and perplexity is 115.53479204189817
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.622542980105378 and perplexity of 101.75245788057298
finished 2 epochs...
Completing Train Step...
At time: 106.37173056602478 and batch: 50, loss is 4.6884325504302975 and perplexity is 108.68269158831495
At time: 107.65741157531738 and batch: 100, loss is 4.634821996688843 and perplexity is 103.0095803168167
At time: 108.90968537330627 and batch: 150, loss is 4.581409521102906 and perplexity is 97.65193971740325
At time: 110.16050839424133 and batch: 200, loss is 4.572630310058594 and perplexity is 96.79838498059559
At time: 111.38596892356873 and batch: 250, loss is 4.576247882843018 and perplexity is 97.14919434029176
At time: 112.61208772659302 and batch: 300, loss is 4.600598888397217 and perplexity is 99.54391348872498
At time: 113.83881378173828 and batch: 350, loss is 4.610836791992187 and perplexity is 100.56826915850957
At time: 115.06255292892456 and batch: 400, loss is 4.578678379058838 and perplexity is 97.38560226741399
At time: 116.28940510749817 and batch: 450, loss is 4.577013711929322 and perplexity is 97.22362251502143
At time: 117.51202440261841 and batch: 500, loss is 4.577216310501099 and perplexity is 97.24332187754993
At time: 118.7345826625824 and batch: 550, loss is 4.536274690628051 and perplexity is 93.3424222143579
At time: 119.9577808380127 and batch: 600, loss is 4.510157794952392 and perplexity is 90.9361666465548
At time: 121.23643040657043 and batch: 650, loss is 4.574418144226074 and perplexity is 96.97159923366297
At time: 122.46042275428772 and batch: 700, loss is 4.584966115951538 and perplexity is 97.99986645362564
At time: 123.68547463417053 and batch: 750, loss is 4.560004262924195 and perplexity is 95.58388729606355
At time: 124.91019654273987 and batch: 800, loss is 4.538006649017334 and perplexity is 93.50422748513913
At time: 126.13374376296997 and batch: 850, loss is 4.527192497253418 and perplexity is 92.49850639004998
At time: 127.35929608345032 and batch: 900, loss is 4.524760189056397 and perplexity is 92.27379490931855
At time: 128.58363127708435 and batch: 950, loss is 4.600205707550049 and perplexity is 99.50478242178617
At time: 129.80783200263977 and batch: 1000, loss is 4.576606550216675 and perplexity is 97.184044836173
At time: 131.03153705596924 and batch: 1050, loss is 4.501502552032471 and perplexity is 90.15248838918305
At time: 132.25652837753296 and batch: 1100, loss is 4.561692247390747 and perplexity is 95.74536766290538
At time: 133.4809398651123 and batch: 1150, loss is 4.4987544822692875 and perplexity is 89.90508316087661
At time: 134.7050633430481 and batch: 1200, loss is 4.57900782585144 and perplexity is 97.41769092718947
At time: 135.9321882724762 and batch: 1250, loss is 4.547134971618652 and perplexity is 94.36167179840086
At time: 137.15740060806274 and batch: 1300, loss is 4.557534694671631 and perplexity is 95.34812759469771
At time: 138.3820879459381 and batch: 1350, loss is 4.438783454895019 and perplexity is 84.67187184077191
At time: 139.6064419746399 and batch: 1400, loss is 4.466395540237427 and perplexity is 87.04241601410794
At time: 140.8309509754181 and batch: 1450, loss is 4.404166975021362 and perplexity is 81.7909805268471
At time: 142.05586767196655 and batch: 1500, loss is 4.402521891593933 and perplexity is 81.65653815504818
At time: 143.28091192245483 and batch: 1550, loss is 4.401536636352539 and perplexity is 81.57612524296329
At time: 144.5052227973938 and batch: 1600, loss is 4.485368242263794 and perplexity is 88.70961142721453
At time: 145.7294270992279 and batch: 1650, loss is 4.441070194244385 and perplexity is 84.865715892835
At time: 146.95441198349 and batch: 1700, loss is 4.461780824661255 and perplexity is 86.6416654073587
At time: 148.17963027954102 and batch: 1750, loss is 4.4779821968078615 and perplexity is 88.05681197576034
At time: 149.40440678596497 and batch: 1800, loss is 4.4304163455963135 and perplexity is 83.96636866159075
At time: 150.62885451316833 and batch: 1850, loss is 4.4592072296142575 and perplexity is 86.41897153124671
At time: 151.85267734527588 and batch: 1900, loss is 4.530777549743652 and perplexity is 92.83071352492419
At time: 153.07703471183777 and batch: 1950, loss is 4.463909215927124 and perplexity is 86.82626915608665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.516221157340116 and perplexity of 91.48922056786714
finished 3 epochs...
Completing Train Step...
At time: 157.07727479934692 and batch: 50, loss is 4.422947931289673 and perplexity is 83.34160891884602
At time: 158.30468916893005 and batch: 100, loss is 4.368194341659546 and perplexity is 78.90103468621322
At time: 159.5332634449005 and batch: 150, loss is 4.3271026515960695 and perplexity is 75.72456796608509
At time: 160.75928354263306 and batch: 200, loss is 4.324982643127441 and perplexity is 75.56420129013249
At time: 161.98459911346436 and batch: 250, loss is 4.330093183517456 and perplexity is 75.95136365466928
At time: 163.20893454551697 and batch: 300, loss is 4.350163955688476 and perplexity is 77.49116700141616
At time: 164.43460392951965 and batch: 350, loss is 4.3649586486816405 and perplexity is 78.64614775264276
At time: 165.66250586509705 and batch: 400, loss is 4.332652492523193 and perplexity is 76.14599561910076
At time: 166.8891408443451 and batch: 450, loss is 4.339276943206787 and perplexity is 76.65209547783193
At time: 168.11630964279175 and batch: 500, loss is 4.349379835128784 and perplexity is 77.43042840048075
At time: 169.3431680202484 and batch: 550, loss is 4.311701011657715 and perplexity is 74.56722083549691
At time: 170.5710470676422 and batch: 600, loss is 4.290482420921325 and perplexity is 73.00167754269889
At time: 171.80015325546265 and batch: 650, loss is 4.34567042350769 and perplexity is 77.143739122546
At time: 173.02899551391602 and batch: 700, loss is 4.367824277877808 and perplexity is 78.87184167290579
At time: 174.2593035697937 and batch: 750, loss is 4.339449110031128 and perplexity is 76.66529356179295
At time: 175.48781609535217 and batch: 800, loss is 4.317434034347534 and perplexity is 74.99594417051075
At time: 176.71814846992493 and batch: 850, loss is 4.304709243774414 and perplexity is 74.04768249790344
At time: 177.9503824710846 and batch: 900, loss is 4.298145008087158 and perplexity is 73.56320790024748
At time: 179.18076419830322 and batch: 950, loss is 4.379816703796386 and perplexity is 79.82340073775454
At time: 180.4120056629181 and batch: 1000, loss is 4.363990402221679 and perplexity is 78.57003575202552
At time: 181.69335627555847 and batch: 1050, loss is 4.2937616348266605 and perplexity is 73.24145859061436
At time: 182.92390847206116 and batch: 1100, loss is 4.349088582992554 and perplexity is 77.4078799066078
At time: 184.1558814048767 and batch: 1150, loss is 4.2893078327178955 and perplexity is 72.91598097236961
At time: 185.38760590553284 and batch: 1200, loss is 4.372636604309082 and perplexity is 79.25231346423823
At time: 186.617742061615 and batch: 1250, loss is 4.347839422225952 and perplexity is 77.31124538859271
At time: 187.8493390083313 and batch: 1300, loss is 4.351945867538452 and perplexity is 77.62937252862852
At time: 189.08021521568298 and batch: 1350, loss is 4.229160609245301 and perplexity is 68.65957576598434
At time: 190.3105926513672 and batch: 1400, loss is 4.256959629058838 and perplexity is 70.59502178543326
At time: 191.5414755344391 and batch: 1450, loss is 4.200876750946045 and perplexity is 66.74482398287772
At time: 192.77147245407104 and batch: 1500, loss is 4.194024682044983 and perplexity is 66.28904714057896
At time: 193.99846482276917 and batch: 1550, loss is 4.199987964630127 and perplexity is 66.68552845109534
At time: 195.22531366348267 and batch: 1600, loss is 4.288447403907776 and perplexity is 72.85326894510938
At time: 196.4531192779541 and batch: 1650, loss is 4.238595185279846 and perplexity is 69.31041512308836
At time: 197.680912733078 and batch: 1700, loss is 4.263404350280762 and perplexity is 71.05145623708349
At time: 198.90732645988464 and batch: 1750, loss is 4.284818935394287 and perplexity is 72.58940215830215
At time: 200.13492512702942 and batch: 1800, loss is 4.232196974754333 and perplexity is 68.86836815830058
At time: 201.36089062690735 and batch: 1850, loss is 4.264309501647949 and perplexity is 71.11579767481435
At time: 202.58812856674194 and batch: 1900, loss is 4.344822654724121 and perplexity is 77.07836678289982
At time: 203.81622958183289 and batch: 1950, loss is 4.274450883865357 and perplexity is 71.84067960037675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.482136287245639 and perplexity of 88.4233687642723
finished 4 epochs...
Completing Train Step...
At time: 207.81203746795654 and batch: 50, loss is 4.239764122962952 and perplexity is 69.39148205102
At time: 209.03820133209229 and batch: 100, loss is 4.191755847930908 and perplexity is 66.13881877510022
At time: 210.2652838230133 and batch: 150, loss is 4.152365942001342 and perplexity is 63.58425914550911
At time: 211.49156832695007 and batch: 200, loss is 4.157501482963562 and perplexity is 63.91163862875724
At time: 212.74682188034058 and batch: 250, loss is 4.152235069274902 and perplexity is 63.575938244657436
At time: 213.97309064865112 and batch: 300, loss is 4.172456340789795 and perplexity is 64.8746107059983
At time: 215.20024251937866 and batch: 350, loss is 4.1887968730926515 and perplexity is 65.94340492941822
At time: 216.42633652687073 and batch: 400, loss is 4.157396440505981 and perplexity is 63.90492554575319
At time: 217.6549642086029 and batch: 450, loss is 4.1769723081588745 and perplexity is 65.16824485311162
At time: 218.88229370117188 and batch: 500, loss is 4.1889505958557125 and perplexity is 65.95354271101355
At time: 220.11177706718445 and batch: 550, loss is 4.151187644004822 and perplexity is 63.50938206276921
At time: 221.34327220916748 and batch: 600, loss is 4.133152599334717 and perplexity is 62.374254327738925
At time: 222.57356977462769 and batch: 650, loss is 4.185468878746033 and perplexity is 65.72431042546748
At time: 223.80465459823608 and batch: 700, loss is 4.215103378295899 and perplexity is 67.70116434018057
At time: 225.0362946987152 and batch: 750, loss is 4.185628275871277 and perplexity is 65.73478752659571
At time: 226.26627159118652 and batch: 800, loss is 4.159747672080994 and perplexity is 64.05535760549691
At time: 227.4953489303589 and batch: 850, loss is 4.146038889884949 and perplexity is 63.1832282336774
At time: 228.72388911247253 and batch: 900, loss is 4.136639819145203 and perplexity is 62.59214676169066
At time: 229.9509391784668 and batch: 950, loss is 4.228437900543213 and perplexity is 68.60997281949615
At time: 231.1781005859375 and batch: 1000, loss is 4.210549035072327 and perplexity is 67.39353106664228
At time: 232.4060182571411 and batch: 1050, loss is 4.148969650268555 and perplexity is 63.36867475280993
At time: 233.6340572834015 and batch: 1100, loss is 4.191090998649597 and perplexity is 66.09486104322323
At time: 234.86896467208862 and batch: 1150, loss is 4.13998330116272 and perplexity is 62.801772723861816
At time: 236.09593081474304 and batch: 1200, loss is 4.217432088851929 and perplexity is 67.85900446689054
At time: 237.32143211364746 and batch: 1250, loss is 4.2006639909744266 and perplexity is 66.73062486657679
At time: 238.54761004447937 and batch: 1300, loss is 4.201115245819092 and perplexity is 66.76074417956724
At time: 239.77298164367676 and batch: 1350, loss is 4.078363418579102 and perplexity is 59.048752637179604
At time: 240.99767971038818 and batch: 1400, loss is 4.112286305427551 and perplexity is 61.086219792370485
At time: 242.22474813461304 and batch: 1450, loss is 4.048773593902588 and perplexity is 57.32710760146081
At time: 243.44973278045654 and batch: 1500, loss is 4.042953066825866 and perplexity is 56.99440281733402
At time: 244.6755862236023 and batch: 1550, loss is 4.05685405254364 and perplexity is 57.7922135273356
At time: 245.90302443504333 and batch: 1600, loss is 4.142330832481385 and perplexity is 62.949375034937574
At time: 247.12733340263367 and batch: 1650, loss is 4.093549556732178 and perplexity is 59.952318626592806
At time: 248.35326433181763 and batch: 1700, loss is 4.118391122817993 and perplexity is 61.46028063410883
At time: 249.5791118144989 and batch: 1750, loss is 4.136539692878723 and perplexity is 62.58587995746555
At time: 250.80743932724 and batch: 1800, loss is 4.085784206390381 and perplexity is 59.48857078125521
At time: 252.0332899093628 and batch: 1850, loss is 4.122249803543091 and perplexity is 61.69789437730878
At time: 253.2603645324707 and batch: 1900, loss is 4.199514660835266 and perplexity is 66.6539734055676
At time: 254.48650741577148 and batch: 1950, loss is 4.128392152786255 and perplexity is 62.07803066188987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.473490870276163 and perplexity of 87.66220689330639
finished 5 epochs...
Completing Train Step...
At time: 258.46239399909973 and batch: 50, loss is 4.101928353309631 and perplexity is 60.45675725188485
At time: 259.6871852874756 and batch: 100, loss is 4.0558429479599 and perplexity is 57.73380908680812
At time: 260.9107577800751 and batch: 150, loss is 4.019070196151733 and perplexity is 55.64933879456757
At time: 262.1351375579834 and batch: 200, loss is 4.0271035051345825 and perplexity is 56.098187584470146
At time: 263.35921573638916 and batch: 250, loss is 4.0212656593322755 and perplexity is 55.77164908365215
At time: 264.58448100090027 and batch: 300, loss is 4.036896367073059 and perplexity is 56.6502481048291
At time: 265.80963492393494 and batch: 350, loss is 4.050533628463745 and perplexity is 57.42809413595697
At time: 267.03794527053833 and batch: 400, loss is 4.024065704345703 and perplexity is 55.92803104765588
At time: 268.26338720321655 and batch: 450, loss is 4.0496320104598995 and perplexity is 57.37633926742412
At time: 269.4876072406769 and batch: 500, loss is 4.06150737285614 and perplexity is 58.06176587876947
At time: 270.7124066352844 and batch: 550, loss is 4.024697642326355 and perplexity is 55.9633852643176
At time: 271.9379277229309 and batch: 600, loss is 4.009200339317322 and perplexity is 55.10278940663444
At time: 273.1623706817627 and batch: 650, loss is 4.062486510276795 and perplexity is 58.11864416773708
At time: 274.4319829940796 and batch: 700, loss is 4.092623934745789 and perplexity is 59.89685111727037
At time: 275.6567039489746 and batch: 750, loss is 4.0608251714706425 and perplexity is 58.022169569506715
At time: 276.8815779685974 and batch: 800, loss is 4.038418307304382 and perplexity is 56.73653203937497
At time: 278.10691571235657 and batch: 850, loss is 4.023989748954773 and perplexity is 55.923783173520235
At time: 279.3307771682739 and batch: 900, loss is 4.0106626939773555 and perplexity is 55.183428174372615
At time: 280.55407309532166 and batch: 950, loss is 4.107765192985535 and perplexity is 60.81066549937389
At time: 281.77873063087463 and batch: 1000, loss is 4.085436305999756 and perplexity is 59.46787828391537
At time: 283.00276279449463 and batch: 1050, loss is 4.030205855369568 and perplexity is 56.272494049955
At time: 284.2271525859833 and batch: 1100, loss is 4.067131767272949 and perplexity is 58.38924823227591
At time: 285.4523003101349 and batch: 1150, loss is 4.018640375137329 and perplexity is 55.62542467907881
At time: 286.6781315803528 and batch: 1200, loss is 4.0944733238220214 and perplexity is 60.00772619340308
At time: 287.9039828777313 and batch: 1250, loss is 4.083959975242615 and perplexity is 59.38014880094416
At time: 289.13096475601196 and batch: 1300, loss is 4.079826927185058 and perplexity is 59.135234262700784
At time: 290.35760498046875 and batch: 1350, loss is 3.959971699714661 and perplexity is 52.45584141281306
At time: 291.5843665599823 and batch: 1400, loss is 4.0001061201095585 and perplexity is 54.60394430224624
At time: 292.81159138679504 and batch: 1450, loss is 3.9320976972579955 and perplexity is 51.01387717887566
At time: 294.038423538208 and batch: 1500, loss is 3.921391553878784 and perplexity is 50.47062853340188
At time: 295.2652995586395 and batch: 1550, loss is 3.942619071006775 and perplexity is 51.553446776258575
At time: 296.49360966682434 and batch: 1600, loss is 4.025767693519592 and perplexity is 56.023301002233666
At time: 297.72164607048035 and batch: 1650, loss is 3.974361548423767 and perplexity is 53.21613013527061
At time: 298.95605731010437 and batch: 1700, loss is 4.000011591911316 and perplexity is 54.59878293372571
At time: 300.18689227104187 and batch: 1750, loss is 4.01944146156311 and perplexity is 55.670003304999604
At time: 301.41659331321716 and batch: 1800, loss is 3.9698059225082396 and perplexity is 52.97424873262374
At time: 302.6465034484863 and batch: 1850, loss is 4.008127861022949 and perplexity is 55.043724539591786
At time: 303.87647891044617 and batch: 1900, loss is 4.081848721504212 and perplexity is 59.25491448702617
At time: 305.10643577575684 and batch: 1950, loss is 4.013618035316467 and perplexity is 55.34675526566713
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.471335619549419 and perplexity of 87.47347631210884
finished 6 epochs...
Completing Train Step...
At time: 309.0786111354828 and batch: 50, loss is 3.985900001525879 and perplexity is 53.8337181101422
At time: 310.33575081825256 and batch: 100, loss is 3.941446485519409 and perplexity is 51.49303138077541
At time: 311.5644180774689 and batch: 150, loss is 3.9132073593139647 and perplexity is 50.059252775492254
At time: 312.79289174079895 and batch: 200, loss is 3.920801320075989 and perplexity is 50.44084785204012
At time: 314.02233028411865 and batch: 250, loss is 3.9139381980895998 and perplexity is 50.09585139071445
At time: 315.2516007423401 and batch: 300, loss is 3.925822501182556 and perplexity is 50.69475741375178
At time: 316.47991824150085 and batch: 350, loss is 3.940989294052124 and perplexity is 51.469494587024094
At time: 317.7131698131561 and batch: 400, loss is 3.918571124076843 and perplexity is 50.32848022246021
At time: 318.94260835647583 and batch: 450, loss is 3.9435829019546507 and perplexity is 51.6031595372315
At time: 320.17196798324585 and batch: 500, loss is 3.956967554092407 and perplexity is 52.29849289374125
At time: 321.4021029472351 and batch: 550, loss is 3.9260087156295778 and perplexity is 50.70419838896619
At time: 322.6297595500946 and batch: 600, loss is 3.904927816390991 and perplexity is 49.646496119568596
At time: 323.8595061302185 and batch: 650, loss is 3.9560580587387086 and perplexity is 52.25094928107363
At time: 325.0868806838989 and batch: 700, loss is 3.9903506517410277 and perplexity is 54.07384712798524
At time: 326.3168377876282 and batch: 750, loss is 3.9624275493621828 and perplexity is 52.58482338779978
At time: 327.55129766464233 and batch: 800, loss is 3.9308552885055543 and perplexity is 50.95053644706008
At time: 328.7799780368805 and batch: 850, loss is 3.9234443426132204 and perplexity is 50.57434048401742
At time: 330.0093832015991 and batch: 900, loss is 3.907815351486206 and perplexity is 49.7900592915663
At time: 331.2380578517914 and batch: 950, loss is 4.004865503311157 and perplexity is 54.86444481665345
At time: 332.46723198890686 and batch: 1000, loss is 3.9843197536468504 and perplexity is 53.74871467221877
At time: 333.69561767578125 and batch: 1050, loss is 3.9305189514160155 and perplexity is 50.93340277342751
At time: 334.9729895591736 and batch: 1100, loss is 3.961676149368286 and perplexity is 52.54532599285664
At time: 336.2023983001709 and batch: 1150, loss is 3.923674726486206 and perplexity is 50.58599333871518
At time: 337.43151783943176 and batch: 1200, loss is 3.9899907875061036 and perplexity is 54.054391385282074
At time: 338.6609539985657 and batch: 1250, loss is 3.9853385400772097 and perplexity is 53.80350103643961
At time: 339.89078521728516 and batch: 1300, loss is 3.980169358253479 and perplexity is 53.526098546476256
At time: 341.12065052986145 and batch: 1350, loss is 3.8617280435562136 and perplexity is 47.54744447323148
At time: 342.3502404689789 and batch: 1400, loss is 3.8998058605194093 and perplexity is 49.39285907065323
At time: 343.5793764591217 and batch: 1450, loss is 3.8325259017944338 and perplexity is 46.179034749636074
At time: 344.8087508678436 and batch: 1500, loss is 3.8293000173568728 and perplexity is 46.03030653908178
At time: 346.03689312934875 and batch: 1550, loss is 3.8467956352233887 and perplexity is 46.842721318821745
At time: 347.2673087120056 and batch: 1600, loss is 3.927589693069458 and perplexity is 50.784423983443595
At time: 348.49706077575684 and batch: 1650, loss is 3.878757200241089 and perplexity is 48.36407084988233
At time: 349.72576665878296 and batch: 1700, loss is 3.9037862491607664 and perplexity is 49.589853643251686
At time: 350.9543676376343 and batch: 1750, loss is 3.9206248474121095 and perplexity is 50.431947206634746
At time: 352.1834259033203 and batch: 1800, loss is 3.8718954038619997 and perplexity is 48.03334243683407
At time: 353.4133355617523 and batch: 1850, loss is 3.913650269508362 and perplexity is 50.08142943964321
At time: 354.6415810585022 and batch: 1900, loss is 3.9859047412872313 and perplexity is 53.83397326972345
At time: 355.86889147758484 and batch: 1950, loss is 3.9211829805374148 and perplexity is 50.46010280349915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.481441622002181 and perplexity of 88.3619654531245
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 359.8211841583252 and batch: 50, loss is 3.924951739311218 and perplexity is 50.65063356538953
At time: 361.07430386543274 and batch: 100, loss is 3.9130680894851686 and perplexity is 50.05228151738278
At time: 362.3007779121399 and batch: 150, loss is 3.884418749809265 and perplexity is 48.638663009417414
At time: 363.5284502506256 and batch: 200, loss is 3.890917067527771 and perplexity is 48.95576168314799
At time: 364.7574260234833 and batch: 250, loss is 3.884693751335144 and perplexity is 48.65204055530017
At time: 366.01347947120667 and batch: 300, loss is 3.8996326541900634 and perplexity is 49.3843046556985
At time: 367.2424931526184 and batch: 350, loss is 3.907476644515991 and perplexity is 49.77319790713224
At time: 368.47037625312805 and batch: 400, loss is 3.8790230798721312 and perplexity is 48.37693158082305
At time: 369.6999933719635 and batch: 450, loss is 3.8944113492965697 and perplexity is 49.127126132146685
At time: 370.92928290367126 and batch: 500, loss is 3.9115487718582154 and perplexity is 49.97629394305176
At time: 372.15897488594055 and batch: 550, loss is 3.8651727628707886 and perplexity is 47.7115144989212
At time: 373.3879451751709 and batch: 600, loss is 3.8298972129821776 and perplexity is 46.05780384659701
At time: 374.6170904636383 and batch: 650, loss is 3.871755533218384 and perplexity is 48.026624452147786
At time: 375.8468277454376 and batch: 700, loss is 3.904856171607971 and perplexity is 49.64293933454047
At time: 377.0749661922455 and batch: 750, loss is 3.8642844438552855 and perplexity is 47.66915027259311
At time: 378.30388951301575 and batch: 800, loss is 3.8302794313430786 and perplexity is 46.07541134963107
At time: 379.5344386100769 and batch: 850, loss is 3.8175175476074217 and perplexity is 45.49113844814576
At time: 380.76452255249023 and batch: 900, loss is 3.7947362947463987 and perplexity is 44.46650880730027
At time: 381.99445700645447 and batch: 950, loss is 3.889128646850586 and perplexity is 48.86828643127652
At time: 383.2223918437958 and batch: 1000, loss is 3.8533783864974978 and perplexity is 47.15209244168841
At time: 384.44996762275696 and batch: 1050, loss is 3.7910298919677734 and perplexity is 44.30200306609297
At time: 385.6786208152771 and batch: 1100, loss is 3.812618546485901 and perplexity is 45.268822317990534
At time: 386.906929731369 and batch: 1150, loss is 3.761989688873291 and perplexity is 43.03396505391159
At time: 388.1357100009918 and batch: 1200, loss is 3.8164973068237305 and perplexity is 45.44475020101898
At time: 389.3650715351105 and batch: 1250, loss is 3.8051550436019896 and perplexity is 44.932216025607374
At time: 390.59260725975037 and batch: 1300, loss is 3.8023473739624025 and perplexity is 44.80623814172987
At time: 391.82181549072266 and batch: 1350, loss is 3.6818869590759276 and perplexity is 39.72127582287606
At time: 393.05025601387024 and batch: 1400, loss is 3.706876482963562 and perplexity is 40.72639805115917
At time: 394.2795569896698 and batch: 1450, loss is 3.6251378297805785 and perplexity is 37.52989554040622
At time: 395.5084013938904 and batch: 1500, loss is 3.614395499229431 and perplexity is 37.1288946949836
At time: 396.73827481269836 and batch: 1550, loss is 3.625199317932129 and perplexity is 37.532203255258715
At time: 397.9680998325348 and batch: 1600, loss is 3.6998026371002197 and perplexity is 40.43932235049278
At time: 399.1976044178009 and batch: 1650, loss is 3.6358050394058226 and perplexity is 37.93237766745094
At time: 400.4268436431885 and batch: 1700, loss is 3.646977744102478 and perplexity is 38.35856130016659
At time: 401.6561014652252 and batch: 1750, loss is 3.6471617937088014 and perplexity is 38.365621827996776
At time: 402.88498163223267 and batch: 1800, loss is 3.592810859680176 and perplexity is 36.33606810524537
At time: 404.11320900917053 and batch: 1850, loss is 3.622028532028198 and perplexity is 37.4133851471732
At time: 405.3416624069214 and batch: 1900, loss is 3.687634973526001 and perplexity is 39.95025173827614
At time: 406.5706775188446 and batch: 1950, loss is 3.619003858566284 and perplexity is 37.300392842554665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419147154342297 and perplexity of 83.0254472634791
finished 8 epochs...
Completing Train Step...
At time: 410.54038166999817 and batch: 50, loss is 3.8260765361785887 and perplexity is 45.88216760213378
At time: 411.80249786376953 and batch: 100, loss is 3.7954508447647095 and perplexity is 44.49829370658053
At time: 413.0311255455017 and batch: 150, loss is 3.7648212099075318 and perplexity is 43.15598930674024
At time: 414.2577075958252 and batch: 200, loss is 3.7669951152801513 and perplexity is 43.24990839236989
At time: 415.4886770248413 and batch: 250, loss is 3.7582124996185304 and perplexity is 42.87172422357365
At time: 416.72091937065125 and batch: 300, loss is 3.7715293836593626 and perplexity is 43.44646035732479
At time: 417.9516758918762 and batch: 350, loss is 3.7807340383529664 and perplexity is 43.848216197883055
At time: 419.18242025375366 and batch: 400, loss is 3.7563032341003417 and perplexity is 42.789948809139084
At time: 420.4127697944641 and batch: 450, loss is 3.779950695037842 and perplexity is 43.81388144055135
At time: 421.64305686950684 and batch: 500, loss is 3.798061656951904 and perplexity is 44.614622183924354
At time: 422.87280535697937 and batch: 550, loss is 3.754500541687012 and perplexity is 42.712881178541124
At time: 424.1039237976074 and batch: 600, loss is 3.7246038007736204 and perplexity is 41.454805129019476
At time: 425.3357255458832 and batch: 650, loss is 3.7678536319732667 and perplexity is 43.28705510395486
At time: 426.5666768550873 and batch: 700, loss is 3.8037541580200194 and perplexity is 44.869315200727264
At time: 427.8420784473419 and batch: 750, loss is 3.7681889724731445 and perplexity is 43.30157344080878
At time: 429.0719745159149 and batch: 800, loss is 3.7332299900054933 and perplexity is 41.81394891674786
At time: 430.3025543689728 and batch: 850, loss is 3.7221421098709104 and perplexity is 41.35288171579995
At time: 431.53251576423645 and batch: 900, loss is 3.7013604068756103 and perplexity is 40.50236659604893
At time: 432.7632722854614 and batch: 950, loss is 3.7966625833511354 and perplexity is 44.55224668794795
At time: 433.9953544139862 and batch: 1000, loss is 3.7665757513046265 and perplexity is 43.23177474141112
At time: 435.2275469303131 and batch: 1050, loss is 3.7077283668518066 and perplexity is 40.76110699538133
At time: 436.45852756500244 and batch: 1100, loss is 3.7299877882003782 and perplexity is 41.67859919021973
At time: 437.68978214263916 and batch: 1150, loss is 3.68526762008667 and perplexity is 39.855787231976116
At time: 438.9204730987549 and batch: 1200, loss is 3.7419397020339966 and perplexity is 42.179726969042136
At time: 440.15141582489014 and batch: 1250, loss is 3.7363989639282225 and perplexity is 41.946666408539876
At time: 441.3819909095764 and batch: 1300, loss is 3.735466413497925 and perplexity is 41.907567260528246
At time: 442.61213636398315 and batch: 1350, loss is 3.615732789039612 and perplexity is 37.17858000194529
At time: 443.8445861339569 and batch: 1400, loss is 3.6469442462921142 and perplexity is 38.357276393875225
At time: 445.077107667923 and batch: 1450, loss is 3.5667919397354124 and perplexity is 35.40283634730918
At time: 446.30888319015503 and batch: 1500, loss is 3.5597631692886353 and perplexity is 35.15487040616555
At time: 447.53940510749817 and batch: 1550, loss is 3.5746398401260375 and perplexity is 35.68176736031014
At time: 448.76977157592773 and batch: 1600, loss is 3.6530828428268434 and perplexity is 38.59346041537232
At time: 450.00019121170044 and batch: 1650, loss is 3.591411690711975 and perplexity is 36.28526335682805
At time: 451.2312660217285 and batch: 1700, loss is 3.608029284477234 and perplexity is 36.893274976486865
At time: 452.4618294239044 and batch: 1750, loss is 3.6131506538391114 and perplexity is 37.08270371785231
At time: 453.69319581985474 and batch: 1800, loss is 3.562954378128052 and perplexity is 35.267236135248915
At time: 454.9286665916443 and batch: 1850, loss is 3.5973401165008543 and perplexity is 36.50101675496416
At time: 456.1585445404053 and batch: 1900, loss is 3.6672775554656982 and perplexity is 39.145190053578716
At time: 457.3906629085541 and batch: 1950, loss is 3.6018138217926023 and perplexity is 36.66467735846996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.427637570403343 and perplexity of 83.73336887624927
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 461.3875000476837 and batch: 50, loss is 3.787259726524353 and perplexity is 44.13529164734554
At time: 462.6165554523468 and batch: 100, loss is 3.787372145652771 and perplexity is 44.14025357726772
At time: 463.8450267314911 and batch: 150, loss is 3.7768451833724974 and perplexity is 43.67802797707468
At time: 465.07325196266174 and batch: 200, loss is 3.7929027700424194 and perplexity is 44.38505306328176
At time: 466.30151414871216 and batch: 250, loss is 3.7808735036849974 and perplexity is 43.85433193037048
At time: 467.5301978588104 and batch: 300, loss is 3.789602165222168 and perplexity is 44.238797042633315
At time: 468.7581219673157 and batch: 350, loss is 3.8056069469451903 and perplexity is 44.95252563289084
At time: 469.98530769348145 and batch: 400, loss is 3.786697602272034 and perplexity is 44.11048910123684
At time: 471.2128791809082 and batch: 450, loss is 3.8069310283660887 and perplexity is 45.01208585949684
At time: 472.4415109157562 and batch: 500, loss is 3.8273420095443726 and perplexity is 45.94026701707632
At time: 473.6679992675781 and batch: 550, loss is 3.7845413303375244 and perplexity is 44.01547736395479
At time: 474.89388728141785 and batch: 600, loss is 3.742835512161255 and perplexity is 42.21752892478546
At time: 476.11980843544006 and batch: 650, loss is 3.7689081048965454 and perplexity is 43.33272420567438
At time: 477.34601044654846 and batch: 700, loss is 3.8021242380142213 and perplexity is 44.79624137465821
At time: 478.572229385376 and batch: 750, loss is 3.7654145097732545 and perplexity is 43.18160134645963
At time: 479.79954624176025 and batch: 800, loss is 3.733280620574951 and perplexity is 41.81606603438778
At time: 481.0258617401123 and batch: 850, loss is 3.7212885189056397 and perplexity is 41.31759833051123
At time: 482.2522654533386 and batch: 900, loss is 3.699136700630188 and perplexity is 40.41240129576718
At time: 483.4786789417267 and batch: 950, loss is 3.8022106075286866 and perplexity is 44.80011057136352
At time: 484.7062487602234 and batch: 1000, loss is 3.7582527208328247 and perplexity is 42.873448611059054
At time: 485.9335744380951 and batch: 1050, loss is 3.693388247489929 and perplexity is 40.18075893115156
At time: 487.1634223461151 and batch: 1100, loss is 3.710410838127136 and perplexity is 40.87059427663788
At time: 488.4199504852295 and batch: 1150, loss is 3.664752597808838 and perplexity is 39.046474784606666
At time: 489.6503164768219 and batch: 1200, loss is 3.713977427482605 and perplexity is 41.01662316087128
At time: 490.8775260448456 and batch: 1250, loss is 3.6989629888534545 and perplexity is 40.40538179543862
At time: 492.1049966812134 and batch: 1300, loss is 3.6952729415893555 and perplexity is 40.25655877774417
At time: 493.3336343765259 and batch: 1350, loss is 3.574115481376648 and perplexity is 35.663062217932186
At time: 494.5612099170685 and batch: 1400, loss is 3.608000407218933 and perplexity is 36.89220961523823
At time: 495.7887933254242 and batch: 1450, loss is 3.5240014457702635 and perplexity is 33.91988585418741
At time: 497.0174570083618 and batch: 1500, loss is 3.5150268363952635 and perplexity is 33.616830066356755
At time: 498.24510502815247 and batch: 1550, loss is 3.528920125961304 and perplexity is 34.08713791732595
At time: 499.4725134372711 and batch: 1600, loss is 3.606657795906067 and perplexity is 36.8427109534194
At time: 500.7015733718872 and batch: 1650, loss is 3.541139850616455 and perplexity is 34.506228729189026
At time: 501.9300465583801 and batch: 1700, loss is 3.5415174055099485 and perplexity is 34.51925918440302
At time: 503.1552264690399 and batch: 1750, loss is 3.5432932329177858 and perplexity is 34.58061389252323
At time: 504.3813078403473 and batch: 1800, loss is 3.4861025857925414 and perplexity is 32.658415971266656
At time: 505.60594606399536 and batch: 1850, loss is 3.5151670360565186 and perplexity is 33.62154346494525
At time: 506.8319501876831 and batch: 1900, loss is 3.5904416275024413 and perplexity is 36.25008142490516
At time: 508.0585286617279 and batch: 1950, loss is 3.5288590240478515 and perplexity is 34.085055191604994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.402083995730378 and perplexity of 81.62078892254966
finished 10 epochs...
Completing Train Step...
At time: 512.0565621852875 and batch: 50, loss is 3.785673851966858 and perplexity is 44.06535408199489
At time: 513.2835493087769 and batch: 100, loss is 3.7634827756881712 and perplexity is 43.09826649159434
At time: 514.5110771656036 and batch: 150, loss is 3.735370774269104 and perplexity is 41.903559444768945
At time: 515.7379806041718 and batch: 200, loss is 3.7456231784820555 and perplexity is 42.33538149882206
At time: 516.9645912647247 and batch: 250, loss is 3.7297524118423464 and perplexity is 41.66879018778339
At time: 518.1902906894684 and batch: 300, loss is 3.7358327770233153 and perplexity is 41.92292347741746
At time: 519.4442884922028 and batch: 350, loss is 3.751347556114197 and perplexity is 42.578420168617306
At time: 520.6702346801758 and batch: 400, loss is 3.733395748138428 and perplexity is 41.820880493317645
At time: 521.8966040611267 and batch: 450, loss is 3.7552264881134034 and perplexity is 42.743899699523574
At time: 523.1233551502228 and batch: 500, loss is 3.7748137807846067 and perplexity is 43.58939037781331
At time: 524.3502089977264 and batch: 550, loss is 3.734708557128906 and perplexity is 41.87581937545774
At time: 525.576913356781 and batch: 600, loss is 3.697023458480835 and perplexity is 40.32709027915889
At time: 526.8060047626495 and batch: 650, loss is 3.723515520095825 and perplexity is 41.40971520529237
At time: 528.036363363266 and batch: 700, loss is 3.7587523603439332 and perplexity is 42.89487523231016
At time: 529.2665615081787 and batch: 750, loss is 3.724567971229553 and perplexity is 41.45331984886092
At time: 530.4964225292206 and batch: 800, loss is 3.693571591377258 and perplexity is 40.18812650306883
At time: 531.7225933074951 and batch: 850, loss is 3.681834349632263 and perplexity is 39.719186163621764
At time: 532.9499831199646 and batch: 900, loss is 3.661472191810608 and perplexity is 38.91859635577165
At time: 534.176807641983 and batch: 950, loss is 3.7664714193344118 and perplexity is 43.22726452046068
At time: 535.4037177562714 and batch: 1000, loss is 3.723569769859314 and perplexity is 41.41196173348467
At time: 536.6314175128937 and batch: 1050, loss is 3.6612391805648805 and perplexity is 38.90952894159858
At time: 537.858304977417 and batch: 1100, loss is 3.6790638875961306 and perplexity is 39.60929795708845
At time: 539.0852589607239 and batch: 1150, loss is 3.636437773704529 and perplexity is 37.95638637859913
At time: 540.3129150867462 and batch: 1200, loss is 3.688361258506775 and perplexity is 39.97927754531975
At time: 541.5384004116058 and batch: 1250, loss is 3.6768341732025145 and perplexity is 39.52107892348634
At time: 542.7648515701294 and batch: 1300, loss is 3.674656481742859 and perplexity is 39.43510785064918
At time: 543.9915211200714 and batch: 1350, loss is 3.553570055961609 and perplexity is 34.9378250965673
At time: 545.2185485363007 and batch: 1400, loss is 3.590176239013672 and perplexity is 36.240462347030764
At time: 546.445081949234 and batch: 1450, loss is 3.508813419342041 and perplexity is 33.408602254179456
At time: 547.6728966236115 and batch: 1500, loss is 3.502121338844299 and perplexity is 33.18577561706106
At time: 548.9006178379059 and batch: 1550, loss is 3.5181162929534913 and perplexity is 33.72084839979764
At time: 550.1281616687775 and batch: 1600, loss is 3.59817862033844 and perplexity is 36.53163583290217
At time: 551.3549404144287 and batch: 1650, loss is 3.5347213315963746 and perplexity is 34.285459108710626
At time: 552.5821697711945 and batch: 1700, loss is 3.537283024787903 and perplexity is 34.37340052725311
At time: 553.8095424175262 and batch: 1750, loss is 3.541453866958618 and perplexity is 34.51706595035964
At time: 555.037359714508 and batch: 1800, loss is 3.486636185646057 and perplexity is 32.67584714746791
At time: 556.2627825737 and batch: 1850, loss is 3.517218518257141 and perplexity is 33.69058826079086
At time: 557.4881558418274 and batch: 1900, loss is 3.593434009552002 and perplexity is 36.358717977827474
At time: 558.7133429050446 and batch: 1950, loss is 3.5325386476516725 and perplexity is 34.21070639802553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.404032294694767 and perplexity of 81.77996563263862
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 562.6919734477997 and batch: 50, loss is 3.7759807443618776 and perplexity is 43.640287300391115
At time: 563.9191727638245 and batch: 100, loss is 3.770897831916809 and perplexity is 43.41903033223012
At time: 565.1463825702667 and batch: 150, loss is 3.752486729621887 and perplexity is 42.626952014721
At time: 566.3734407424927 and batch: 200, loss is 3.773748025894165 and perplexity is 43.54295951819944
At time: 567.5994126796722 and batch: 250, loss is 3.76628369808197 and perplexity is 43.21915060582621
At time: 568.8257782459259 and batch: 300, loss is 3.7690293121337892 and perplexity is 43.337976763775195
At time: 570.0529382228851 and batch: 350, loss is 3.7875674676895144 and perplexity is 44.14887598354436
At time: 571.2780754566193 and batch: 400, loss is 3.7752709436416625 and perplexity is 43.60932238379501
At time: 572.5054326057434 and batch: 450, loss is 3.8006391620635984 and perplexity is 44.729764927418486
At time: 573.7323939800262 and batch: 500, loss is 3.821691288948059 and perplexity is 45.68140347562171
At time: 574.9592847824097 and batch: 550, loss is 3.787740592956543 and perplexity is 44.15651993114916
At time: 576.1862833499908 and batch: 600, loss is 3.7452785062789915 and perplexity is 42.320792184023375
At time: 577.4129679203033 and batch: 650, loss is 3.7603031826019286 and perplexity is 42.96144916840251
At time: 578.6392667293549 and batch: 700, loss is 3.789858260154724 and perplexity is 44.25012782519439
At time: 579.8667585849762 and batch: 750, loss is 3.7420597076416016 and perplexity is 42.184789076540234
At time: 581.1410765647888 and batch: 800, loss is 3.7055437994003295 and perplexity is 40.672158799793735
At time: 582.3688871860504 and batch: 850, loss is 3.6916436338424683 and perplexity is 40.110720143831664
At time: 583.5971114635468 and batch: 900, loss is 3.6710784244537353 and perplexity is 39.294258908616754
At time: 584.8252923488617 and batch: 950, loss is 3.781994652748108 and perplexity is 43.90352674573508
At time: 586.0535016059875 and batch: 1000, loss is 3.7443175506591797 and perplexity is 42.28014331494689
At time: 587.2810544967651 and batch: 1050, loss is 3.6830242681503296 and perplexity is 39.76647688923553
At time: 588.5082154273987 and batch: 1100, loss is 3.6999958515167237 and perplexity is 40.44713656544973
At time: 589.7383224964142 and batch: 1150, loss is 3.661680598258972 and perplexity is 38.9267080874527
At time: 590.966495513916 and batch: 1200, loss is 3.703227128982544 and perplexity is 40.578043871402606
At time: 592.1936767101288 and batch: 1250, loss is 3.6885086345672606 and perplexity is 39.985169967935796
At time: 593.4222269058228 and batch: 1300, loss is 3.681287384033203 and perplexity is 39.69746707550611
At time: 594.6473650932312 and batch: 1350, loss is 3.5538317203521728 and perplexity is 34.94696827744909
At time: 595.8728079795837 and batch: 1400, loss is 3.5897227144241333 and perplexity is 36.224030132708414
At time: 597.098715543747 and batch: 1450, loss is 3.509207396507263 and perplexity is 33.421767073738444
At time: 598.3244807720184 and batch: 1500, loss is 3.4965352392196656 and perplexity is 33.00091337849519
At time: 599.548907995224 and batch: 1550, loss is 3.5140619802474977 and perplexity is 33.58441030391747
At time: 600.7741937637329 and batch: 1600, loss is 3.5926136922836305 and perplexity is 36.32890452353194
At time: 601.9997978210449 and batch: 1650, loss is 3.5320421743392942 and perplexity is 34.19372591082945
At time: 603.2246530056 and batch: 1700, loss is 3.535011568069458 and perplexity is 34.29541144363582
At time: 604.4490978717804 and batch: 1750, loss is 3.5397100114822386 and perplexity is 34.456925629128534
At time: 605.6791560649872 and batch: 1800, loss is 3.480627236366272 and perplexity is 32.480088380564624
At time: 606.9021940231323 and batch: 1850, loss is 3.497262406349182 and perplexity is 33.024919285043325
At time: 608.125111579895 and batch: 1900, loss is 3.5745576429367065 and perplexity is 35.67883453985921
At time: 609.3480567932129 and batch: 1950, loss is 3.518828716278076 and perplexity is 33.744880478212586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388759311409884 and perplexity of 80.54043137231403
finished 12 epochs...
Completing Train Step...
At time: 613.3349289894104 and batch: 50, loss is 3.7768759870529176 and perplexity is 43.679373441812395
At time: 614.5931868553162 and batch: 100, loss is 3.7578801822662355 and perplexity is 42.85747957269478
At time: 615.8236830234528 and batch: 150, loss is 3.7319389247894286 and perplexity is 41.7599992155403
At time: 617.0554437637329 and batch: 200, loss is 3.747532410621643 and perplexity is 42.41628677872553
At time: 618.2876944541931 and batch: 250, loss is 3.7385494184494017 and perplexity is 42.036967866756484
At time: 619.5180213451385 and batch: 300, loss is 3.740124979019165 and perplexity is 42.10325185931039
At time: 620.7494864463806 and batch: 350, loss is 3.7577158308029173 and perplexity is 42.8504364620015
At time: 621.9803302288055 and batch: 400, loss is 3.7449415063858034 and perplexity is 42.30653248447129
At time: 623.2104659080505 and batch: 450, loss is 3.7708050537109377 and perplexity is 43.41500217936051
At time: 624.44296002388 and batch: 500, loss is 3.792013158798218 and perplexity is 44.34558517914188
At time: 625.6741394996643 and batch: 550, loss is 3.759396505355835 and perplexity is 42.92251465316906
At time: 626.905045747757 and batch: 600, loss is 3.720742034912109 and perplexity is 41.29502509289079
At time: 628.1355345249176 and batch: 650, loss is 3.73595458984375 and perplexity is 41.928030538013516
At time: 629.3653028011322 and batch: 700, loss is 3.7675706720352173 and perplexity is 43.27480833427862
At time: 630.5985460281372 and batch: 750, loss is 3.723527970314026 and perplexity is 41.41023076849174
At time: 631.8286092281342 and batch: 800, loss is 3.6880737018585203 and perplexity is 39.96778289103052
At time: 633.0583651065826 and batch: 850, loss is 3.6741385459899902 and perplexity is 39.41468828684265
At time: 634.2895300388336 and batch: 900, loss is 3.653610372543335 and perplexity is 38.61382498358885
At time: 635.5196766853333 and batch: 950, loss is 3.7642764139175413 and perplexity is 43.132484500065424
At time: 636.7501134872437 and batch: 1000, loss is 3.726303415298462 and perplexity is 41.525322226907974
At time: 637.9802613258362 and batch: 1050, loss is 3.6665969276428223 and perplexity is 39.11855581312723
At time: 639.2097053527832 and batch: 1100, loss is 3.6850886487960817 and perplexity is 39.848654828564555
At time: 640.4391963481903 and batch: 1150, loss is 3.647447214126587 and perplexity is 38.37657372268034
At time: 641.7148096561432 and batch: 1200, loss is 3.6911215877532957 and perplexity is 40.08978596402546
At time: 642.94970536232 and batch: 1250, loss is 3.67797465801239 and perplexity is 39.56617782608679
At time: 644.1795501708984 and batch: 1300, loss is 3.6719019651412963 and perplexity is 39.326632658335896
At time: 645.4086611270905 and batch: 1350, loss is 3.545665249824524 and perplexity is 34.66273705357966
At time: 646.637316942215 and batch: 1400, loss is 3.583082466125488 and perplexity is 35.98429042474447
At time: 647.8675360679626 and batch: 1450, loss is 3.5038810634613036 and perplexity is 33.24422485554772
At time: 649.0967381000519 and batch: 1500, loss is 3.4931056785583494 and perplexity is 32.88792859900516
At time: 650.3258078098297 and batch: 1550, loss is 3.511852111816406 and perplexity is 33.51027512048081
At time: 651.5566606521606 and batch: 1600, loss is 3.592432017326355 and perplexity is 36.32230507085056
At time: 652.7870545387268 and batch: 1650, loss is 3.5306306743621825 and perplexity is 34.14549551409847
At time: 654.0179510116577 and batch: 1700, loss is 3.5376712608337404 and perplexity is 34.386748111194755
At time: 655.2476603984833 and batch: 1750, loss is 3.5446394205093386 and perplexity is 34.62719723377667
At time: 656.4770777225494 and batch: 1800, loss is 3.4863161516189574 and perplexity is 32.66539143769711
At time: 657.7077679634094 and batch: 1850, loss is 3.5034795570373536 and perplexity is 33.23087976495806
At time: 658.936178445816 and batch: 1900, loss is 3.5811082983016966 and perplexity is 35.91332147178685
At time: 660.1655530929565 and batch: 1950, loss is 3.524290165901184 and perplexity is 33.929680621977326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.38774896666061 and perplexity of 80.4590988642277
finished 13 epochs...
Completing Train Step...
At time: 664.1429331302643 and batch: 50, loss is 3.7708204889297487 and perplexity is 43.415672304590586
At time: 665.4010765552521 and batch: 100, loss is 3.749317560195923 and perplexity is 42.492073820487526
At time: 666.6308538913727 and batch: 150, loss is 3.722063341140747 and perplexity is 41.34962453010248
At time: 667.8600606918335 and batch: 200, loss is 3.736671347618103 and perplexity is 41.95809355252759
At time: 669.0886416435242 and batch: 250, loss is 3.726685423851013 and perplexity is 41.54118828543818
At time: 670.3184287548065 and batch: 300, loss is 3.7281322574615476 and perplexity is 41.601334973503796
At time: 671.5479497909546 and batch: 350, loss is 3.7454754590988157 and perplexity is 42.32912820425562
At time: 672.8245038986206 and batch: 400, loss is 3.7325629091262815 and perplexity is 41.78606493241158
At time: 674.0523526668549 and batch: 450, loss is 3.758722143173218 and perplexity is 42.89357909012542
At time: 675.2798855304718 and batch: 500, loss is 3.779395456314087 and perplexity is 43.78956102937939
At time: 676.5077404975891 and batch: 550, loss is 3.7471782636642454 and perplexity is 42.40126783943155
At time: 677.7356188297272 and batch: 600, loss is 3.7094330835342406 and perplexity is 40.83065239523057
At time: 678.9635875225067 and batch: 650, loss is 3.724785418510437 and perplexity is 41.462334740642
At time: 680.1924781799316 and batch: 700, loss is 3.7573484420776366 and perplexity is 42.834696586275484
At time: 681.419661283493 and batch: 750, loss is 3.714344940185547 and perplexity is 41.03170006122118
At time: 682.6466963291168 and batch: 800, loss is 3.6792594814300537 and perplexity is 39.6170460492497
At time: 683.8760516643524 and batch: 850, loss is 3.665108118057251 and perplexity is 39.0603590649469
At time: 685.1060192584991 and batch: 900, loss is 3.644609546661377 and perplexity is 38.26782813288386
At time: 686.3368110656738 and batch: 950, loss is 3.755610990524292 and perplexity is 42.760337992087855
At time: 687.5678818225861 and batch: 1000, loss is 3.717558670043945 and perplexity is 41.163776976937754
At time: 688.7992460727692 and batch: 1050, loss is 3.658668794631958 and perplexity is 38.80964486106176
At time: 690.0287935733795 and batch: 1100, loss is 3.6778438329696654 and perplexity is 39.56100191775884
At time: 691.2592208385468 and batch: 1150, loss is 3.6406680583953857 and perplexity is 38.11729279884411
At time: 692.489465713501 and batch: 1200, loss is 3.6850254011154173 and perplexity is 39.84613457327004
At time: 693.7204737663269 and batch: 1250, loss is 3.6726291608810424 and perplexity is 39.355241218814534
At time: 694.9515104293823 and batch: 1300, loss is 3.667205057144165 and perplexity is 39.142352195874935
At time: 696.1817896366119 and batch: 1350, loss is 3.5412534713745116 and perplexity is 34.51014957579548
At time: 697.4133911132812 and batch: 1400, loss is 3.5791362571716308 and perplexity is 35.84256871133352
At time: 698.6446678638458 and batch: 1450, loss is 3.500076999664307 and perplexity is 33.118001935548925
At time: 699.8760476112366 and batch: 1500, loss is 3.4907989263534547 and perplexity is 32.81215173002617
At time: 701.1077635288239 and batch: 1550, loss is 3.5099424076080323 and perplexity is 33.446341473667
At time: 702.3380537033081 and batch: 1600, loss is 3.591274423599243 and perplexity is 36.28028292532488
At time: 703.5686960220337 and batch: 1650, loss is 3.5299527406692506 and perplexity is 34.12235497698877
At time: 704.8018391132355 and batch: 1700, loss is 3.537229356765747 and perplexity is 34.37155582433327
At time: 706.0324642658234 and batch: 1750, loss is 3.5453489875793456 and perplexity is 34.65177627186715
At time: 707.2605128288269 and batch: 1800, loss is 3.4872606420516967 and perplexity is 32.6962581617599
At time: 708.4876732826233 and batch: 1850, loss is 3.5048032236099242 and perplexity is 33.27489549432823
At time: 709.7160053253174 and batch: 1900, loss is 3.5825164985656737 and perplexity is 35.96393024584499
At time: 710.94256067276 and batch: 1950, loss is 3.525164408683777 and perplexity is 33.9593563703911
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.387995946130087 and perplexity of 80.47897306393838
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 714.9178647994995 and batch: 50, loss is 3.7681729125976564 and perplexity is 43.30087802851501
At time: 716.1745934486389 and batch: 100, loss is 3.7520392370224 and perplexity is 42.60788103653476
At time: 717.4017558097839 and batch: 150, loss is 3.727670040130615 and perplexity is 41.58211055876021
At time: 718.6277182102203 and batch: 200, loss is 3.745445213317871 and perplexity is 42.32784794607767
At time: 719.8543424606323 and batch: 250, loss is 3.739220004081726 and perplexity is 42.065166707246334
At time: 721.0813934803009 and batch: 300, loss is 3.7410575199127196 and perplexity is 42.14253317629135
At time: 722.3066473007202 and batch: 350, loss is 3.760637154579163 and perplexity is 42.9757994846945
At time: 723.5332961082458 and batch: 400, loss is 3.752273931503296 and perplexity is 42.61788204460151
At time: 724.7600057125092 and batch: 450, loss is 3.780635838508606 and perplexity is 43.84391052128878
At time: 725.9851484298706 and batch: 500, loss is 3.7999275398254393 and perplexity is 44.6979455550178
At time: 727.2113471031189 and batch: 550, loss is 3.7698869705200195 and perplexity is 43.375161886775814
At time: 728.4368059635162 and batch: 600, loss is 3.731524133682251 and perplexity is 41.74268113117194
At time: 729.6630432605743 and batch: 650, loss is 3.7426177787780763 and perplexity is 42.20833776003123
At time: 730.8900804519653 and batch: 700, loss is 3.7786587142944335 and perplexity is 43.75731130107058
At time: 732.1160125732422 and batch: 750, loss is 3.7322741603851317 and perplexity is 41.774001000571126
At time: 733.3426175117493 and batch: 800, loss is 3.693657088279724 and perplexity is 40.19156261028691
At time: 734.5974144935608 and batch: 850, loss is 3.6764752578735354 and perplexity is 39.5068967476953
At time: 735.8238694667816 and batch: 900, loss is 3.6508358669281007 and perplexity is 38.50683919431307
At time: 737.050323009491 and batch: 950, loss is 3.760621747970581 and perplexity is 42.97513737847376
At time: 738.2764503955841 and batch: 1000, loss is 3.724233570098877 and perplexity is 41.43946012931527
At time: 739.5037677288055 and batch: 1050, loss is 3.6687410974502566 and perplexity is 39.20252262679599
At time: 740.7291316986084 and batch: 1100, loss is 3.6852455139160156 and perplexity is 39.85490618288035
At time: 741.9548153877258 and batch: 1150, loss is 3.6518015575408938 and perplexity is 38.54404284816979
At time: 743.1804418563843 and batch: 1200, loss is 3.699911184310913 and perplexity is 40.443712164382966
At time: 744.4062588214874 and batch: 1250, loss is 3.685238628387451 and perplexity is 39.854631761730154
At time: 745.6370570659637 and batch: 1300, loss is 3.676309804916382 and perplexity is 39.50036075551496
At time: 746.8626718521118 and batch: 1350, loss is 3.544606337547302 and perplexity is 34.62605168247437
At time: 748.0901172161102 and batch: 1400, loss is 3.580474576950073 and perplexity is 35.890569643083715
At time: 749.3165190219879 and batch: 1450, loss is 3.498861746788025 and perplexity is 33.07777963352431
At time: 750.5412273406982 and batch: 1500, loss is 3.4882884550094606 and perplexity is 32.7298810756423
At time: 751.7667391300201 and batch: 1550, loss is 3.5055079793930055 and perplexity is 33.298354434800295
At time: 752.9940927028656 and batch: 1600, loss is 3.5810126781463625 and perplexity is 35.90988759858551
At time: 754.2242605686188 and batch: 1650, loss is 3.5173011684417723 and perplexity is 33.69337290920522
At time: 755.4504754543304 and batch: 1700, loss is 3.5240886545181276 and perplexity is 33.92284409395077
At time: 756.6770164966583 and batch: 1750, loss is 3.5336912059783936 and perplexity is 34.250158963871854
At time: 757.9021611213684 and batch: 1800, loss is 3.478135333061218 and perplexity is 32.399251901155814
At time: 759.1283106803894 and batch: 1850, loss is 3.4963807821273805 and perplexity is 32.99581654700302
At time: 760.354590177536 and batch: 1900, loss is 3.5745844984054567 and perplexity is 35.679792724551426
At time: 761.5812587738037 and batch: 1950, loss is 3.5203512382507323 and perplexity is 33.7962969316131
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385083575581396 and perplexity of 80.24492944929113
finished 15 epochs...
Completing Train Step...
At time: 765.5817477703094 and batch: 50, loss is 3.770147581100464 and perplexity is 43.386467385994365
At time: 766.8103930950165 and batch: 100, loss is 3.748369221687317 and perplexity is 42.451796052071074
At time: 768.0389220714569 and batch: 150, loss is 3.7204836559295655 and perplexity is 41.28435670462618
At time: 769.2675383090973 and batch: 200, loss is 3.735593547821045 and perplexity is 41.91289548941874
At time: 770.4957478046417 and batch: 250, loss is 3.727104034423828 and perplexity is 41.55858150630084
At time: 771.7232978343964 and batch: 300, loss is 3.7294865465164184 and perplexity is 41.65771337383471
At time: 772.9522395133972 and batch: 350, loss is 3.7480858516693116 and perplexity is 42.439768190107664
At time: 774.1808171272278 and batch: 400, loss is 3.737915139198303 and perplexity is 42.01031314442179
At time: 775.4096910953522 and batch: 450, loss is 3.7666343307495116 and perplexity is 43.23430730895434
At time: 776.6379821300507 and batch: 500, loss is 3.7865120458602903 and perplexity is 44.102304876500135
At time: 777.8668332099915 and batch: 550, loss is 3.757522530555725 and perplexity is 42.842154262542486
At time: 779.0944967269897 and batch: 600, loss is 3.7204426431655886 and perplexity is 41.282663553769346
At time: 780.321453332901 and batch: 650, loss is 3.732022318840027 and perplexity is 41.76348189624328
At time: 781.5479850769043 and batch: 700, loss is 3.767317385673523 and perplexity is 43.26384880353104
At time: 782.774656534195 and batch: 750, loss is 3.722834644317627 and perplexity is 41.38152992965163
At time: 784.0018074512482 and batch: 800, loss is 3.6844623374938963 and perplexity is 39.823704979670296
At time: 785.2293331623077 and batch: 850, loss is 3.667804002761841 and perplexity is 39.16580335847265
At time: 786.4555594921112 and batch: 900, loss is 3.6437110042572023 and perplexity is 38.23345831027476
At time: 787.6812045574188 and batch: 950, loss is 3.753235549926758 and perplexity is 42.658883896052835
At time: 788.9083724021912 and batch: 1000, loss is 3.7166538047790527 and perplexity is 41.12654615196002
At time: 790.1353175640106 and batch: 1050, loss is 3.660912070274353 and perplexity is 38.89680331573727
At time: 791.3620073795319 and batch: 1100, loss is 3.6782277154922487 and perplexity is 39.57619161031315
At time: 792.5896685123444 and batch: 1150, loss is 3.6445609188079833 and perplexity is 38.265967295792336
At time: 793.8185846805573 and batch: 1200, loss is 3.691882314682007 and perplexity is 40.120294946805636
At time: 795.0463407039642 and batch: 1250, loss is 3.678394651412964 and perplexity is 39.582798849775486
At time: 796.2746450901031 and batch: 1300, loss is 3.670616111755371 and perplexity is 39.27609687234397
At time: 797.502222776413 and batch: 1350, loss is 3.5403870153427124 and perplexity is 34.480260998975965
At time: 798.7305374145508 and batch: 1400, loss is 3.577427320480347 and perplexity is 35.781368339228024
At time: 799.9592320919037 and batch: 1450, loss is 3.497116861343384 and perplexity is 33.02011302274672
At time: 801.1875100135803 and batch: 1500, loss is 3.4881951808929443 and perplexity is 32.72682836727283
At time: 802.416624546051 and batch: 1550, loss is 3.5070925092697145 and perplexity is 33.351158496005695
At time: 803.646518945694 and batch: 1600, loss is 3.5838948822021486 and perplexity is 36.01353651918282
At time: 804.8752021789551 and batch: 1650, loss is 3.5214680194854737 and perplexity is 33.834061085054074
At time: 806.1040258407593 and batch: 1700, loss is 3.5294816637039186 and perplexity is 34.106284507067514
At time: 807.3360714912415 and batch: 1750, loss is 3.540653486251831 and perplexity is 34.489450209745314
At time: 808.5677690505981 and batch: 1800, loss is 3.4849424934387208 and perplexity is 32.62055116019598
At time: 809.803946018219 and batch: 1850, loss is 3.5027525758743288 and perplexity is 33.206730320497385
At time: 811.0353443622589 and batch: 1900, loss is 3.5806818151474 and perplexity is 35.89800831079901
At time: 812.2667677402496 and batch: 1950, loss is 3.5254828405380247 and perplexity is 33.97017183311173
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3841297238372094 and perplexity of 80.16842417651836
finished 16 epochs...
Completing Train Step...
At time: 816.2665214538574 and batch: 50, loss is 3.7697338819503785 and perplexity is 43.36852215353122
At time: 817.4941816329956 and batch: 100, loss is 3.745754280090332 and perplexity is 42.340932099261934
At time: 818.7220242023468 and batch: 150, loss is 3.7166736364364623 and perplexity is 41.127361767621224
At time: 819.9471683502197 and batch: 200, loss is 3.730869936943054 and perplexity is 41.7153821357211
At time: 821.1723341941833 and batch: 250, loss is 3.72150417804718 and perplexity is 41.32650980918408
At time: 822.397791147232 and batch: 300, loss is 3.723559560775757 and perplexity is 41.41153895746514
At time: 823.6223108768463 and batch: 350, loss is 3.741905174255371 and perplexity is 42.17827062190922
At time: 824.848495721817 and batch: 400, loss is 3.7314462518692015 and perplexity is 41.739430262077335
At time: 826.1151435375214 and batch: 450, loss is 3.76020742893219 and perplexity is 42.957335648932784
At time: 827.3394219875336 and batch: 500, loss is 3.780119466781616 and perplexity is 43.82127660975383
At time: 828.567498922348 and batch: 550, loss is 3.7512633705139162 and perplexity is 42.57483582963339
At time: 829.7924702167511 and batch: 600, loss is 3.7150315952301027 and perplexity is 41.05988436039313
At time: 831.0175848007202 and batch: 650, loss is 3.726578450202942 and perplexity is 41.536744710659015
At time: 832.2426717281342 and batch: 700, loss is 3.7618487739562987 and perplexity is 43.02790135354111
At time: 833.468133687973 and batch: 750, loss is 3.718114104270935 and perplexity is 41.18664709841907
At time: 834.6942489147186 and batch: 800, loss is 3.6800217962265016 and perplexity is 39.64725822377536
At time: 835.9202945232391 and batch: 850, loss is 3.6634825468063354 and perplexity is 38.996915248393364
At time: 837.1458010673523 and batch: 900, loss is 3.639939422607422 and perplexity is 38.08952929114157
At time: 838.3705649375916 and batch: 950, loss is 3.7493287992477415 and perplexity is 42.492551393790805
At time: 839.5957772731781 and batch: 1000, loss is 3.7126106452941894 and perplexity is 40.96060066490213
At time: 840.8207895755768 and batch: 1050, loss is 3.6569563245773313 and perplexity is 38.74324137962088
At time: 842.0463242530823 and batch: 1100, loss is 3.6746861791610717 and perplexity is 39.43627898892909
At time: 843.2700986862183 and batch: 1150, loss is 3.6411416339874267 and perplexity is 38.135348493378984
At time: 844.4946007728577 and batch: 1200, loss is 3.688454713821411 and perplexity is 39.98301399587453
At time: 845.7197947502136 and batch: 1250, loss is 3.675541296005249 and perplexity is 39.470016037867836
At time: 846.9453649520874 and batch: 1300, loss is 3.6683363914489746 and perplexity is 39.18666034062124
At time: 848.1692516803741 and batch: 1350, loss is 3.5388013982772826 and perplexity is 34.42563183063195
At time: 849.3950934410095 and batch: 1400, loss is 3.5763759422302246 and perplexity is 35.74376835616232
At time: 850.6198205947876 and batch: 1450, loss is 3.4968085432052614 and perplexity is 33.00993389226487
At time: 851.8447716236115 and batch: 1500, loss is 3.4884435081481935 and perplexity is 32.734956339891085
At time: 853.0736200809479 and batch: 1550, loss is 3.507987952232361 and perplexity is 33.38103593095013
At time: 854.2992384433746 and batch: 1600, loss is 3.585308322906494 and perplexity is 36.064475508746554
At time: 855.523514509201 and batch: 1650, loss is 3.5234305000305177 and perplexity is 33.90052496740015
At time: 856.7495620250702 and batch: 1700, loss is 3.5317922830581665 and perplexity is 34.185182264390896
At time: 857.9743766784668 and batch: 1750, loss is 3.5436316394805907 and perplexity is 34.59231817950236
At time: 859.2014708518982 and batch: 1800, loss is 3.4877329778671267 and perplexity is 32.71170542338051
At time: 860.4269444942474 and batch: 1850, loss is 3.505344886779785 and perplexity is 33.292924161990314
At time: 861.6594662666321 and batch: 1900, loss is 3.5830822515487672 and perplexity is 35.98428270335426
At time: 862.8825788497925 and batch: 1950, loss is 3.5273655080795288 and perplexity is 34.034186613367694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383733988917151 and perplexity of 80.13670500819087
finished 17 epochs...
Completing Train Step...
At time: 866.8574731349945 and batch: 50, loss is 3.7683012771606443 and perplexity is 43.30643668355967
At time: 868.0826277732849 and batch: 100, loss is 3.7432830142974853 and perplexity is 42.23642558699867
At time: 869.3080260753632 and batch: 150, loss is 3.713690776824951 and perplexity is 41.004867403845715
At time: 870.5333578586578 and batch: 200, loss is 3.727404546737671 and perplexity is 41.571072248506255
At time: 871.758691072464 and batch: 250, loss is 3.717635865211487 and perplexity is 41.1669547442507
At time: 872.9835441112518 and batch: 300, loss is 3.719475841522217 and perplexity is 41.24277069415126
At time: 874.2094023227692 and batch: 350, loss is 3.737732181549072 and perplexity is 42.00262773935868
At time: 875.4353251457214 and batch: 400, loss is 3.7271580839157106 and perplexity is 41.56082778721924
At time: 876.6614141464233 and batch: 450, loss is 3.7559964561462404 and perplexity is 42.776823809520515
At time: 877.8866918087006 and batch: 500, loss is 3.775893559455872 and perplexity is 43.63648269189939
At time: 879.1120157241821 and batch: 550, loss is 3.7470559549331663 and perplexity is 42.396082111302334
At time: 880.3360674381256 and batch: 600, loss is 3.711316161155701 and perplexity is 40.90761212085271
At time: 881.5616278648376 and batch: 650, loss is 3.7228184080123903 and perplexity is 41.380858051954945
At time: 882.7867028713226 and batch: 700, loss is 3.7582388305664063 and perplexity is 42.87285309157154
At time: 884.0120470523834 and batch: 750, loss is 3.714927706718445 and perplexity is 41.05561893168644
At time: 885.2365598678589 and batch: 800, loss is 3.677050623893738 and perplexity is 39.52963421420312
At time: 886.4622814655304 and batch: 850, loss is 3.6605471992492675 and perplexity is 38.88261358810656
At time: 887.7331428527832 and batch: 900, loss is 3.63726215839386 and perplexity is 37.98768994370903
At time: 888.9581360816956 and batch: 950, loss is 3.7466519260406494 and perplexity is 42.378956329088226
At time: 890.1831226348877 and batch: 1000, loss is 3.709894938468933 and perplexity is 40.849514588989365
At time: 891.4077122211456 and batch: 1050, loss is 3.654372534751892 and perplexity is 38.64326619978518
At time: 892.6348657608032 and batch: 1100, loss is 3.6723340129852295 and perplexity is 39.34362731617336
At time: 893.8598153591156 and batch: 1150, loss is 3.639001979827881 and perplexity is 38.053839268222305
At time: 895.0853581428528 and batch: 1200, loss is 3.6864384746551515 and perplexity is 39.90247989236021
At time: 896.3110721111298 and batch: 1250, loss is 3.6738466835021972 and perplexity is 39.40318629644508
At time: 897.5363490581512 and batch: 1300, loss is 3.6669657802581788 and perplexity is 39.13298745615889
At time: 898.762181520462 and batch: 1350, loss is 3.537773051261902 and perplexity is 34.39024853115968
At time: 899.9880766868591 and batch: 1400, loss is 3.5756121683120727 and perplexity is 35.71647862107599
At time: 901.2138257026672 and batch: 1450, loss is 3.49644898891449 and perplexity is 32.998067162390484
At time: 902.4415447711945 and batch: 1500, loss is 3.488376383781433 and perplexity is 32.732759100420814
At time: 903.6671550273895 and batch: 1550, loss is 3.5082000160217284 and perplexity is 33.388115590565846
At time: 904.893152475357 and batch: 1600, loss is 3.585788359642029 and perplexity is 36.08179193776706
At time: 906.1181635856628 and batch: 1650, loss is 3.524174757003784 and perplexity is 33.92576506089725
At time: 907.3427436351776 and batch: 1700, loss is 3.5326180696487426 and perplexity is 34.21342358854976
At time: 908.5675477981567 and batch: 1750, loss is 3.5448556613922118 and perplexity is 34.63468585912222
At time: 909.7945215702057 and batch: 1800, loss is 3.4888518953323366 and perplexity is 32.74832760667494
At time: 911.0196661949158 and batch: 1850, loss is 3.506441240310669 and perplexity is 33.329444993161715
At time: 912.2448818683624 and batch: 1900, loss is 3.584084529876709 and perplexity is 36.020367050313084
At time: 913.4714403152466 and batch: 1950, loss is 3.5280452823638915 and perplexity is 34.05733004347978
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383596021075581 and perplexity of 80.12564948264139
finished 18 epochs...
Completing Train Step...
At time: 917.4233820438385 and batch: 50, loss is 3.766603879928589 and perplexity is 43.232990808849124
At time: 918.6777601242065 and batch: 100, loss is 3.741000781059265 and perplexity is 42.14014212511064
At time: 919.9038972854614 and batch: 150, loss is 3.7111295652389527 and perplexity is 40.89997963958411
At time: 921.1306753158569 and batch: 200, loss is 3.724546947479248 and perplexity is 41.45244835377618
At time: 922.3566064834595 and batch: 250, loss is 3.7145585441589355 and perplexity is 41.04046553152546
At time: 923.5831587314606 and batch: 300, loss is 3.7162632656097414 and perplexity is 41.110487760708686
At time: 924.8105361461639 and batch: 350, loss is 3.7344653463363646 and perplexity is 41.86563596264726
At time: 926.0376229286194 and batch: 400, loss is 3.7238226413726805 and perplexity is 41.422434963054585
At time: 927.2644393444061 and batch: 450, loss is 3.7527503490448 and perplexity is 42.6381907885261
At time: 928.4915766716003 and batch: 500, loss is 3.7726116228103637 and perplexity is 43.49350527002734
At time: 929.7177879810333 and batch: 550, loss is 3.7437888097763063 and perplexity is 42.25779398366579
At time: 930.9434943199158 and batch: 600, loss is 3.7083763599395754 and perplexity is 40.787528470506246
At time: 932.1685810089111 and batch: 650, loss is 3.7198470878601073 and perplexity is 41.258084764206245
At time: 933.3938503265381 and batch: 700, loss is 3.7554445123672484 and perplexity is 42.75321992234238
At time: 934.6201343536377 and batch: 750, loss is 3.7124254941940307 and perplexity is 40.953017466666275
At time: 935.8465359210968 and batch: 800, loss is 3.674711866378784 and perplexity is 39.43729201022404
At time: 937.0728058815002 and batch: 850, loss is 3.658212161064148 and perplexity is 38.79192712002893
At time: 938.298791885376 and batch: 900, loss is 3.635073757171631 and perplexity is 37.90464853370926
At time: 939.5264916419983 and batch: 950, loss is 3.744507865905762 and perplexity is 42.28819063658712
At time: 940.7535560131073 and batch: 1000, loss is 3.7077579927444457 and perplexity is 40.762314597449084
At time: 941.9806337356567 and batch: 1050, loss is 3.652355227470398 and perplexity is 38.565389434592525
At time: 943.2078783512115 and batch: 1100, loss is 3.6704690074920654 and perplexity is 39.27031961598798
At time: 944.4339044094086 and batch: 1150, loss is 3.637344536781311 and perplexity is 37.99081943724913
At time: 945.6605403423309 and batch: 1200, loss is 3.6849186706542967 and perplexity is 39.84188200389654
At time: 946.8864850997925 and batch: 1250, loss is 3.6725440311431883 and perplexity is 39.35189106004748
At time: 948.1138298511505 and batch: 1300, loss is 3.6658672094345093 and perplexity is 39.09002070322834
At time: 949.3409602642059 and batch: 1350, loss is 3.5368620586395263 and perplexity is 34.358933534497304
At time: 950.5680379867554 and batch: 1400, loss is 3.574841651916504 and perplexity is 35.6889690883405
At time: 951.794356584549 and batch: 1450, loss is 3.4959194660186768 and perplexity is 32.980598555732186
At time: 953.0211391448975 and batch: 1500, loss is 3.4880572843551634 and perplexity is 32.7223157620919
At time: 954.2469282150269 and batch: 1550, loss is 3.5080209732055665 and perplexity is 33.38213822344246
At time: 955.4721329212189 and batch: 1600, loss is 3.5857819652557374 and perplexity is 36.08156121758898
At time: 956.6990156173706 and batch: 1650, loss is 3.5243234729766844 and perplexity is 33.930810739231845
At time: 957.9267854690552 and batch: 1700, loss is 3.532769718170166 and perplexity is 34.21861239707742
At time: 959.1532790660858 and batch: 1750, loss is 3.5452983140945435 and perplexity is 34.65002039009757
At time: 960.3791947364807 and batch: 1800, loss is 3.4892388725280763 and perplexity is 32.76100291502679
At time: 961.6060502529144 and batch: 1850, loss is 3.5068965673446657 and perplexity is 33.34462424599505
At time: 962.8328912258148 and batch: 1900, loss is 3.584507842063904 and perplexity is 36.035618138430706
At time: 964.0596823692322 and batch: 1950, loss is 3.528242826461792 and perplexity is 34.064058532584895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383583814044331 and perplexity of 80.12467139230405
finished 19 epochs...
Completing Train Step...
At time: 967.9998998641968 and batch: 50, loss is 3.7648742485046385 and perplexity is 43.158278300571794
At time: 969.2536709308624 and batch: 100, loss is 3.73888925075531 and perplexity is 42.05125581409558
At time: 970.4786028862 and batch: 150, loss is 3.7088355112075804 and perplexity is 40.806260415991446
At time: 971.7042496204376 and batch: 200, loss is 3.7220480155944826 and perplexity is 41.34899082937464
At time: 972.9291436672211 and batch: 250, loss is 3.711920533180237 and perplexity is 40.93234300978506
At time: 974.1548147201538 and batch: 300, loss is 3.713534798622131 and perplexity is 40.998472037103056
At time: 975.3821640014648 and batch: 350, loss is 3.7316918087005617 and perplexity is 41.74968092282365
At time: 976.6080136299133 and batch: 400, loss is 3.7209977197647093 and perplexity is 41.30558495523567
At time: 977.8328807353973 and batch: 450, loss is 3.7500131845474245 and perplexity is 42.521642624980736
At time: 979.0856380462646 and batch: 500, loss is 3.769836196899414 and perplexity is 43.372959628671246
At time: 980.3104610443115 and batch: 550, loss is 3.741028890609741 and perplexity is 42.141326682211385
At time: 981.5343506336212 and batch: 600, loss is 3.705862898826599 and perplexity is 40.68513933326214
At time: 982.7595479488373 and batch: 650, loss is 3.7173171424865723 and perplexity is 41.153835990991624
At time: 983.9839615821838 and batch: 700, loss is 3.75307888507843 and perplexity is 42.65220127195723
At time: 985.2092370986938 and batch: 750, loss is 3.710284266471863 and perplexity is 40.865421545235776
At time: 986.4346714019775 and batch: 800, loss is 3.6726994371414183 and perplexity is 39.35800705517876
At time: 987.6600193977356 and batch: 850, loss is 3.6561891269683837 and perplexity is 38.713529056540544
At time: 988.885498046875 and batch: 900, loss is 3.6331476020812987 and perplexity is 37.831708571379714
At time: 990.1107132434845 and batch: 950, loss is 3.742639632225037 and perplexity is 42.20926016778062
At time: 991.3354184627533 and batch: 1000, loss is 3.705914306640625 and perplexity is 40.68723092110012
At time: 992.5610904693604 and batch: 1050, loss is 3.65060839176178 and perplexity is 38.498080840854584
At time: 993.7875196933746 and batch: 1100, loss is 3.6688374423980714 and perplexity is 39.20629977374427
At time: 995.0138070583344 and batch: 1150, loss is 3.635897512435913 and perplexity is 37.93588555154223
At time: 996.2393009662628 and batch: 1200, loss is 3.683593583106995 and perplexity is 39.789122985071316
At time: 997.4645266532898 and batch: 1250, loss is 3.671387858390808 and perplexity is 39.306419767249345
At time: 998.689877986908 and batch: 1300, loss is 3.6648562431335447 and perplexity is 39.05052197889713
At time: 999.914559841156 and batch: 1350, loss is 3.535968441963196 and perplexity is 34.32824353310076
At time: 1001.1399652957916 and batch: 1400, loss is 3.5740284729003906 and perplexity is 35.65995936421918
At time: 1002.3654880523682 and batch: 1450, loss is 3.495265030860901 and perplexity is 32.95902195352644
At time: 1003.5909304618835 and batch: 1500, loss is 3.4875845193862913 and perplexity is 32.70684945375167
At time: 1004.8168318271637 and batch: 1550, loss is 3.507630729675293 and perplexity is 33.36911360152657
At time: 1006.0436367988586 and batch: 1600, loss is 3.585520281791687 and perplexity is 36.07212050495428
At time: 1007.2682375907898 and batch: 1650, loss is 3.5241694927215574 and perplexity is 33.9255864665653
At time: 1008.4940383434296 and batch: 1700, loss is 3.5325997829437257 and perplexity is 34.212797943485484
At time: 1009.718766450882 and batch: 1750, loss is 3.545366349220276 and perplexity is 34.652377888786894
At time: 1010.9439733028412 and batch: 1800, loss is 3.489276418685913 and perplexity is 32.762232987905236
At time: 1012.1696770191193 and batch: 1850, loss is 3.5070442724227906 and perplexity is 33.34954978007859
At time: 1013.3946964740753 and batch: 1900, loss is 3.5846582508087157 and perplexity is 36.04103861815698
At time: 1014.619247674942 and batch: 1950, loss is 3.52822012424469 and perplexity is 34.063285211710784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.383646836391715 and perplexity of 80.1297211963021
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f8261144b38>
ELAPSED
4205.100646495819


RESULTS SO FAR:
[{'best_accuracy': -78.0513610743167, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}}, {'best_accuracy': -78.42215966096434, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.02990420607447708, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.45043527467939715}}, {'best_accuracy': -79.59315869934208, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.9149200001362663, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.10734533781315092}}, {'best_accuracy': -80.12467139230405, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.46354086461744826, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.20663157340468064}}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.45994889588664123, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.6843673700358436}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8464488983154297 and batch: 50, loss is 7.430650472640991 and perplexity is 1686.9045017934013
At time: 3.143815040588379 and batch: 100, loss is 6.6105671310424805 and perplexity is 742.904223312863
At time: 4.441672325134277 and batch: 150, loss is 6.2901211357116695 and perplexity is 539.2186437627507
At time: 5.739682674407959 and batch: 200, loss is 6.179233770370484 and perplexity is 482.6220153529874
At time: 7.038811922073364 and batch: 250, loss is 6.111863260269165 and perplexity is 451.1785956182095
At time: 8.335571050643921 and batch: 300, loss is 6.037845096588135 and perplexity is 418.9891801627555
At time: 9.633152961730957 and batch: 350, loss is 5.988645162582397 and perplexity is 398.87383448256674
At time: 10.93602204322815 and batch: 400, loss is 5.9367741775512695 and perplexity is 378.7113015777348
At time: 12.241721391677856 and batch: 450, loss is 5.864613580703735 and perplexity is 352.3459765139057
At time: 13.548747301101685 and batch: 500, loss is 5.839982299804688 and perplexity is 343.77325575734466
At time: 14.856361150741577 and batch: 550, loss is 5.782424583435058 and perplexity is 324.54512398301256
At time: 16.163342714309692 and batch: 600, loss is 5.8254607391357425 and perplexity is 338.8172034667983
At time: 17.471479654312134 and batch: 650, loss is 5.906356973648071 and perplexity is 367.3653928685592
At time: 18.778618335723877 and batch: 700, loss is 5.809729690551758 and perplexity is 333.5289574599929
At time: 20.085164546966553 and batch: 750, loss is 5.7568933963775635 and perplexity is 316.36398322726296
At time: 21.392189979553223 and batch: 800, loss is 5.753026914596558 and perplexity is 315.14312937548357
At time: 22.698159217834473 and batch: 850, loss is 5.783641147613525 and perplexity is 324.94019422056965
At time: 24.000953197479248 and batch: 900, loss is 5.782036256790161 and perplexity is 324.4191189310415
At time: 25.304444074630737 and batch: 950, loss is 5.808383255004883 and perplexity is 333.0801844055511
At time: 26.60677409172058 and batch: 1000, loss is 5.78396674156189 and perplexity is 325.0460100069432
At time: 27.907726287841797 and batch: 1050, loss is 5.681759843826294 and perplexity is 293.46542907400357
At time: 29.21058702468872 and batch: 1100, loss is 5.765975580215454 and perplexity is 319.25034648310873
At time: 30.51331639289856 and batch: 1150, loss is 5.683493700027466 and perplexity is 293.97469729938587
At time: 31.816917896270752 and batch: 1200, loss is 5.757258644104004 and perplexity is 316.47955555784506
At time: 33.11918830871582 and batch: 1250, loss is 5.695712757110596 and perplexity is 297.5888265652931
At time: 34.42505717277527 and batch: 1300, loss is 5.70159481048584 and perplexity is 299.34441810686195
At time: 35.73234534263611 and batch: 1350, loss is 5.674124736785888 and perplexity is 291.2333211452037
At time: 37.03919553756714 and batch: 1400, loss is 5.692790746688843 and perplexity is 296.72053810443555
At time: 38.34645962715149 and batch: 1450, loss is 5.6684160232543945 and perplexity is 289.575490087565
At time: 39.653202056884766 and batch: 1500, loss is 5.646184215545654 and perplexity is 283.20873791002634
At time: 40.96104145050049 and batch: 1550, loss is 5.624875869750976 and perplexity is 277.2378687814703
At time: 42.268900632858276 and batch: 1600, loss is 5.649674100875854 and perplexity is 284.1988305798991
At time: 43.575101137161255 and batch: 1650, loss is 5.627791452407837 and perplexity is 278.04735819673425
At time: 44.884018421173096 and batch: 1700, loss is 5.637041034698487 and perplexity is 280.63111101321437
At time: 46.191874742507935 and batch: 1750, loss is 5.655559492111206 and perplexity is 285.8763835720997
At time: 47.50017809867859 and batch: 1800, loss is 5.650850734710693 and perplexity is 284.5334253489412
At time: 48.808021783828735 and batch: 1850, loss is 5.613253202438354 and perplexity is 274.03427846178323
At time: 50.11575436592102 and batch: 1900, loss is 5.6009533405303955 and perplexity is 270.6843388095269
At time: 51.4235897064209 and batch: 1950, loss is 5.548567028045654 and perplexity is 256.8692056833575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.0905489189680235 and perplexity of 162.4790253984719
finished 1 epochs...
Completing Train Step...
At time: 55.44043970108032 and batch: 50, loss is 5.356146039962769 and perplexity is 211.90669078212557
At time: 56.66335964202881 and batch: 100, loss is 5.270072031021118 and perplexity is 194.429966930062
At time: 57.88619780540466 and batch: 150, loss is 5.177553052902222 and perplexity is 177.24856206343247
At time: 59.10894846916199 and batch: 200, loss is 5.145530767440796 and perplexity is 171.66257340022204
At time: 60.33319044113159 and batch: 250, loss is 5.145401649475097 and perplexity is 171.64041010882835
At time: 61.556941986083984 and batch: 300, loss is 5.155645160675049 and perplexity is 173.40764647197
At time: 62.7808051109314 and batch: 350, loss is 5.121421184539795 and perplexity is 167.5733531305567
At time: 64.0040214061737 and batch: 400, loss is 5.084644842147827 and perplexity is 161.52256304283222
At time: 65.25913000106812 and batch: 450, loss is 5.047388572692871 and perplexity is 155.61555470101734
At time: 66.48131275177002 and batch: 500, loss is 5.030701589584351 and perplexity is 153.04034655218052
At time: 67.70457077026367 and batch: 550, loss is 4.980855646133423 and perplexity is 145.59890951407763
At time: 68.92732739448547 and batch: 600, loss is 4.976519804000855 and perplexity is 144.96898224720348
At time: 70.15153479576111 and batch: 650, loss is 5.04139814376831 and perplexity is 154.6861373646342
At time: 71.37571382522583 and batch: 700, loss is 5.025292139053345 and perplexity is 152.21471748137247
At time: 72.59798002243042 and batch: 750, loss is 4.970113468170166 and perplexity is 144.0432307654943
At time: 73.82126641273499 and batch: 800, loss is 4.948863172531128 and perplexity is 141.01456353563108
At time: 75.04475665092468 and batch: 850, loss is 4.947638826370239 and perplexity is 140.84201854508925
At time: 76.26995015144348 and batch: 900, loss is 4.958482007980347 and perplexity is 142.37750385909263
At time: 77.49323034286499 and batch: 950, loss is 5.013710203170777 and perplexity is 150.46194621851018
At time: 78.71670579910278 and batch: 1000, loss is 4.980446691513062 and perplexity is 145.53937834091607
At time: 79.93966317176819 and batch: 1050, loss is 4.891134929656983 and perplexity is 133.1045526643223
At time: 81.16275429725647 and batch: 1100, loss is 4.971931314468383 and perplexity is 144.30531736372728
At time: 82.38593983650208 and batch: 1150, loss is 4.877714643478393 and perplexity is 131.3301843718638
At time: 83.60871911048889 and batch: 1200, loss is 4.954070911407471 and perplexity is 141.7508460798697
At time: 84.83025217056274 and batch: 1250, loss is 4.900017604827881 and perplexity is 134.29214385420337
At time: 86.05214047431946 and batch: 1300, loss is 4.92999677658081 and perplexity is 138.37906628550402
At time: 87.27399945259094 and batch: 1350, loss is 4.840447244644165 and perplexity is 126.52592712090426
At time: 88.49721121788025 and batch: 1400, loss is 4.853940210342407 and perplexity is 128.24470675612517
At time: 89.72090339660645 and batch: 1450, loss is 4.792637300491333 and perplexity is 120.6190582592259
At time: 90.94474148750305 and batch: 1500, loss is 4.773192129135132 and perplexity is 118.29625682845929
At time: 92.16820693016052 and batch: 1550, loss is 4.773504543304443 and perplexity is 118.33322002888214
At time: 93.39185309410095 and batch: 1600, loss is 4.843677968978882 and perplexity is 126.93535853652261
At time: 94.61344933509827 and batch: 1650, loss is 4.792517147064209 and perplexity is 120.60456633664407
At time: 95.83661127090454 and batch: 1700, loss is 4.819920320510864 and perplexity is 123.95521369822549
At time: 97.05994701385498 and batch: 1750, loss is 4.8336945915222165 and perplexity is 125.67441962709921
At time: 98.28165555000305 and batch: 1800, loss is 4.7875724792480465 and perplexity is 120.00968876703321
At time: 99.50396227836609 and batch: 1850, loss is 4.788866214752197 and perplexity is 120.16505003876009
At time: 100.72670841217041 and batch: 1900, loss is 4.85601393699646 and perplexity is 128.51092716153855
At time: 101.9495279788971 and batch: 1950, loss is 4.774387311935425 and perplexity is 118.4377270044799
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.654890477380087 and perplexity of 105.09770879212866
finished 2 epochs...
Completing Train Step...
At time: 105.91314339637756 and batch: 50, loss is 4.72332724571228 and perplexity is 112.54208557764694
At time: 107.17173790931702 and batch: 100, loss is 4.661917304992675 and perplexity is 105.83881303073944
At time: 108.3973171710968 and batch: 150, loss is 4.608860549926757 and perplexity is 100.36971817157792
At time: 109.62351727485657 and batch: 200, loss is 4.602866172790527 and perplexity is 99.769863900355
At time: 110.84878420829773 and batch: 250, loss is 4.608641500473023 and perplexity is 100.34773464746829
At time: 112.07444190979004 and batch: 300, loss is 4.633549537658691 and perplexity is 102.87858820487295
At time: 113.30027055740356 and batch: 350, loss is 4.64440613746643 and perplexity is 104.0015847978808
At time: 114.52677345275879 and batch: 400, loss is 4.606854648590088 and perplexity is 100.1685882106047
At time: 115.75170612335205 and batch: 450, loss is 4.6010330867767335 and perplexity is 99.58714467942981
At time: 116.97733521461487 and batch: 500, loss is 4.6073193359375 and perplexity is 100.21514610274828
At time: 118.20394444465637 and batch: 550, loss is 4.56362060546875 and perplexity is 95.93017714823264
At time: 119.43032240867615 and batch: 600, loss is 4.540122089385986 and perplexity is 93.70223947003052
At time: 120.65598917007446 and batch: 650, loss is 4.60329122543335 and perplexity is 99.81228035865513
At time: 121.88129162788391 and batch: 700, loss is 4.625928173065185 and perplexity is 102.09749326080812
At time: 123.10623288154602 and batch: 750, loss is 4.582152795791626 and perplexity is 97.72454891344566
At time: 124.33152747154236 and batch: 800, loss is 4.549119443893432 and perplexity is 94.54911584713068
At time: 125.55771040916443 and batch: 850, loss is 4.5528974437713625 and perplexity is 94.90699800896205
At time: 126.7831506729126 and batch: 900, loss is 4.548597354888916 and perplexity is 94.49976567707166
At time: 128.0411446094513 and batch: 950, loss is 4.62421236038208 and perplexity is 101.9224632892214
At time: 129.26665139198303 and batch: 1000, loss is 4.601013698577881 and perplexity is 99.585213882783
At time: 130.4919741153717 and batch: 1050, loss is 4.527928409576416 and perplexity is 92.5666022339734
At time: 131.71776127815247 and batch: 1100, loss is 4.5929860496521 and perplexity is 98.78897897068731
At time: 132.94290828704834 and batch: 1150, loss is 4.5195880699157716 and perplexity is 91.79777592310245
At time: 134.16873574256897 and batch: 1200, loss is 4.603824357986451 and perplexity is 99.86550772187285
At time: 135.39438486099243 and batch: 1250, loss is 4.56290075302124 and perplexity is 95.86114642437109
At time: 136.62014961242676 and batch: 1300, loss is 4.5824575614929195 and perplexity is 97.75433654302219
At time: 137.84578776359558 and batch: 1350, loss is 4.471653337478638 and perplexity is 87.50127261932307
At time: 139.0717329978943 and batch: 1400, loss is 4.49659893989563 and perplexity is 89.71149766034652
At time: 140.29838252067566 and batch: 1450, loss is 4.4305620288848875 and perplexity is 83.97860204938544
At time: 141.5241403579712 and batch: 1500, loss is 4.428731174468994 and perplexity is 83.82499011843309
At time: 142.75045323371887 and batch: 1550, loss is 4.430873136520386 and perplexity is 84.00473249818182
At time: 143.9716272354126 and batch: 1600, loss is 4.517096395492554 and perplexity is 91.5693304767553
At time: 145.1932783126831 and batch: 1650, loss is 4.466774196624756 and perplexity is 87.07538142178743
At time: 146.4160566329956 and batch: 1700, loss is 4.496616363525391 and perplexity is 89.71306077388452
At time: 147.63934564590454 and batch: 1750, loss is 4.505764570236206 and perplexity is 90.5375399012215
At time: 148.86272478103638 and batch: 1800, loss is 4.449477338790894 and perplexity is 85.58220181363805
At time: 150.08450436592102 and batch: 1850, loss is 4.476114807128906 and perplexity is 87.89252903179192
At time: 151.3062653541565 and batch: 1900, loss is 4.562285785675049 and perplexity is 95.80221307245246
At time: 152.5286419391632 and batch: 1950, loss is 4.484472494125367 and perplexity is 88.63018553602576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.525389489462209 and perplexity of 92.33188112082212
finished 3 epochs...
Completing Train Step...
At time: 156.50830173492432 and batch: 50, loss is 4.442384738922119 and perplexity is 84.97734902527861
At time: 157.7311749458313 and batch: 100, loss is 4.381082973480225 and perplexity is 79.92454271316366
At time: 158.98589897155762 and batch: 150, loss is 4.33740382194519 and perplexity is 76.50865119425568
At time: 160.20866084098816 and batch: 200, loss is 4.341927824020385 and perplexity is 76.85556060881355
At time: 161.4322497844696 and batch: 250, loss is 4.3455174541473385 and perplexity is 77.13193939663853
At time: 162.65514302253723 and batch: 300, loss is 4.371201086044311 and perplexity is 79.13862693979907
At time: 163.8783838748932 and batch: 350, loss is 4.382706642150879 and perplexity is 80.05441909875981
At time: 165.1002697944641 and batch: 400, loss is 4.3479709815979 and perplexity is 77.32141707655629
At time: 166.32333254814148 and batch: 450, loss is 4.3551552295684814 and perplexity is 77.8789135087207
At time: 167.5457842350006 and batch: 500, loss is 4.3739831829071045 and perplexity is 79.35910481873232
At time: 168.76759886741638 and batch: 550, loss is 4.326906356811524 and perplexity is 75.7097050871319
At time: 169.9906632900238 and batch: 600, loss is 4.309682960510254 and perplexity is 74.41689210647709
At time: 171.21394062042236 and batch: 650, loss is 4.365636796951294 and perplexity is 78.6994995898395
At time: 172.43784046173096 and batch: 700, loss is 4.395144243240356 and perplexity is 81.05632174603456
At time: 173.66102647781372 and batch: 750, loss is 4.35358045578003 and perplexity is 77.75636835282887
At time: 174.88406491279602 and batch: 800, loss is 4.324685468673706 and perplexity is 75.54174887619928
At time: 176.10619831085205 and batch: 850, loss is 4.3172562885284425 and perplexity is 74.98261513961046
At time: 177.32964968681335 and batch: 900, loss is 4.3100846481323245 and perplexity is 74.44679045540555
At time: 178.5532329082489 and batch: 950, loss is 4.392559394836426 and perplexity is 80.84707399550425
At time: 179.7763123512268 and batch: 1000, loss is 4.3785753917694095 and perplexity is 79.72437646311128
At time: 180.99983525276184 and batch: 1050, loss is 4.31199047088623 and perplexity is 74.58880812988254
At time: 182.22379899024963 and batch: 1100, loss is 4.368487520217895 and perplexity is 78.92417016906285
At time: 183.44772958755493 and batch: 1150, loss is 4.308806529045105 and perplexity is 74.35169937335075
At time: 184.67157745361328 and batch: 1200, loss is 4.393059277534485 and perplexity is 80.88749815180968
At time: 185.895432472229 and batch: 1250, loss is 4.357750177383423 and perplexity is 78.08126766084237
At time: 187.11916613578796 and batch: 1300, loss is 4.365902643203736 and perplexity is 78.72042433813425
At time: 188.34158897399902 and batch: 1350, loss is 4.252737436294556 and perplexity is 70.29758435620299
At time: 189.5643539428711 and batch: 1400, loss is 4.281634006500244 and perplexity is 72.35857784859267
At time: 190.7884066104889 and batch: 1450, loss is 4.212092804908752 and perplexity is 67.49765151539872
At time: 192.01212978363037 and batch: 1500, loss is 4.215838203430176 and perplexity is 67.75093114006587
At time: 193.23566055297852 and batch: 1550, loss is 4.21727331161499 and perplexity is 67.84823085698451
At time: 194.45814776420593 and batch: 1600, loss is 4.318737602233886 and perplexity is 75.09377022253513
At time: 195.68012356758118 and batch: 1650, loss is 4.258484773635864 and perplexity is 70.70277154616988
At time: 196.90329957008362 and batch: 1700, loss is 4.293393273353576 and perplexity is 73.21448422750015
At time: 198.12704944610596 and batch: 1750, loss is 4.302481169700623 and perplexity is 73.88288243785271
At time: 199.34917640686035 and batch: 1800, loss is 4.243503670692444 and perplexity is 69.65146060831552
At time: 200.57355070114136 and batch: 1850, loss is 4.280856037139893 and perplexity is 72.30230698341046
At time: 201.79678869247437 and batch: 1900, loss is 4.371332912445069 and perplexity is 79.14906018782308
At time: 203.0187554359436 and batch: 1950, loss is 4.292433977127075 and perplexity is 73.144283526073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4799901208212205 and perplexity of 88.23380099385132
finished 4 epochs...
Completing Train Step...
At time: 206.97157883644104 and batch: 50, loss is 4.253413624763489 and perplexity is 70.34513484687346
At time: 208.22711300849915 and batch: 100, loss is 4.193356051445007 and perplexity is 66.24473906973425
At time: 209.45229411125183 and batch: 150, loss is 4.1587182235717775 and perplexity is 63.98944984324695
At time: 210.6775496006012 and batch: 200, loss is 4.1687888383865355 and perplexity is 64.6371186828067
At time: 211.9025640487671 and batch: 250, loss is 4.163073554039001 and perplexity is 64.26875283062958
At time: 213.12881875038147 and batch: 300, loss is 4.187952961921692 and perplexity is 65.88777802873
At time: 214.35481715202332 and batch: 350, loss is 4.19955461025238 and perplexity is 66.6566362461426
At time: 215.57998275756836 and batch: 400, loss is 4.16798053264618 and perplexity is 64.58489323864198
At time: 216.80372738838196 and batch: 450, loss is 4.18374011516571 and perplexity is 65.610786787301
At time: 218.02958250045776 and batch: 500, loss is 4.202522845268249 and perplexity is 66.85478273508237
At time: 219.25372505187988 and batch: 550, loss is 4.159198112487793 and perplexity is 64.02016504032053
At time: 220.4787917137146 and batch: 600, loss is 4.145838985443115 and perplexity is 63.170598888077286
At time: 221.73461842536926 and batch: 650, loss is 4.199641680717468 and perplexity is 66.6624403231399
At time: 222.95885062217712 and batch: 700, loss is 4.234823303222656 and perplexity is 69.04947683549779
At time: 224.18339204788208 and batch: 750, loss is 4.190319938659668 and perplexity is 66.04391758308878
At time: 225.4083342552185 and batch: 800, loss is 4.162468690872192 and perplexity is 64.22989078356085
At time: 226.63366746902466 and batch: 850, loss is 4.1529666662216185 and perplexity is 63.62246722511654
At time: 227.85868978500366 and batch: 900, loss is 4.1425136280059816 and perplexity is 62.960882950735844
At time: 229.08308792114258 and batch: 950, loss is 4.2309022760391235 and perplexity is 68.77926206574617
At time: 230.30816984176636 and batch: 1000, loss is 4.220858526229859 and perplexity is 68.09191789999538
At time: 231.53309726715088 and batch: 1050, loss is 4.154074416160584 and perplexity is 63.69298405960054
At time: 232.75794196128845 and batch: 1100, loss is 4.205750503540039 and perplexity is 67.07091574169382
At time: 233.98338532447815 and batch: 1150, loss is 4.147518405914306 and perplexity is 63.27677801977494
At time: 235.2077498435974 and batch: 1200, loss is 4.233593554496765 and perplexity is 68.96461551907827
At time: 236.4333803653717 and batch: 1250, loss is 4.203028259277343 and perplexity is 66.8885806190942
At time: 237.65774750709534 and batch: 1300, loss is 4.21169759273529 and perplexity is 67.4709808924643
At time: 238.88285899162292 and batch: 1350, loss is 4.090166969299316 and perplexity is 59.74986726478729
At time: 240.1087110042572 and batch: 1400, loss is 4.125862731933593 and perplexity is 61.9212076159952
At time: 241.333500623703 and batch: 1450, loss is 4.056868033409119 and perplexity is 57.79302151814683
At time: 242.5573272705078 and batch: 1500, loss is 4.063042154312134 and perplexity is 58.15094641915646
At time: 243.78263807296753 and batch: 1550, loss is 4.06839467048645 and perplexity is 58.46303478433221
At time: 245.00831818580627 and batch: 1600, loss is 4.173191814422608 and perplexity is 64.9223418219486
At time: 246.233647108078 and batch: 1650, loss is 4.112517414093017 and perplexity is 61.10033897857538
At time: 247.45908188819885 and batch: 1700, loss is 4.146145257949829 and perplexity is 63.18994926884293
At time: 248.68383240699768 and batch: 1750, loss is 4.153430118560791 and perplexity is 63.65196004010508
At time: 249.9086389541626 and batch: 1800, loss is 4.096618237495423 and perplexity is 60.13657572198352
At time: 251.13273310661316 and batch: 1850, loss is 4.134098773002624 and perplexity is 62.43329913365452
At time: 252.35624527931213 and batch: 1900, loss is 4.223372206687928 and perplexity is 68.26329452617293
At time: 253.58158826828003 and batch: 1950, loss is 4.145693273544311 and perplexity is 63.1613948507499
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.469623228561047 and perplexity of 87.32381569486718
finished 5 epochs...
Completing Train Step...
At time: 257.54605507850647 and batch: 50, loss is 4.109322075843811 and perplexity is 60.90541431935872
At time: 258.77197313308716 and batch: 100, loss is 4.0606936168670655 and perplexity is 58.014536988051944
At time: 259.9979944229126 and batch: 150, loss is 4.0211236906051635 and perplexity is 55.76373181563834
At time: 261.2240741252899 and batch: 200, loss is 4.03661217212677 and perplexity is 56.634150678123696
At time: 262.4489369392395 and batch: 250, loss is 4.027939434051514 and perplexity is 56.14510128718794
At time: 263.6721043586731 and batch: 300, loss is 4.051126961708069 and perplexity is 57.462178243983274
At time: 264.89742064476013 and batch: 350, loss is 4.057300124168396 and perplexity is 57.81799874452129
At time: 266.1230607032776 and batch: 400, loss is 4.03098304271698 and perplexity is 56.31624531960235
At time: 267.349258184433 and batch: 450, loss is 4.050009846687317 and perplexity is 57.39802222304107
At time: 268.5756857395172 and batch: 500, loss is 4.0743395662307735 and perplexity is 58.811626575295044
At time: 269.8013207912445 and batch: 550, loss is 4.027387323379517 and perplexity is 56.11411153326108
At time: 271.0265533924103 and batch: 600, loss is 4.017892050743103 and perplexity is 55.58381438779207
At time: 272.2526457309723 and batch: 650, loss is 4.0683972263336186 and perplexity is 58.46318420710508
At time: 273.47810912132263 and batch: 700, loss is 4.107893347740173 and perplexity is 60.818459174677976
At time: 274.70405101776123 and batch: 750, loss is 4.063187556266785 and perplexity is 58.15940229516615
At time: 275.93012952804565 and batch: 800, loss is 4.031713886260986 and perplexity is 56.35741872774394
At time: 277.15599608421326 and batch: 850, loss is 4.026792001724243 and perplexity is 56.08071552916743
At time: 278.38133430480957 and batch: 900, loss is 4.012925996780395 and perplexity is 55.30846642838029
At time: 279.60739398002625 and batch: 950, loss is 4.106396293640136 and perplexity is 60.727478769298926
At time: 280.83161878585815 and batch: 1000, loss is 4.093796429634094 and perplexity is 59.967121056552976
At time: 282.05630898475647 and batch: 1050, loss is 4.028793406486511 and perplexity is 56.193068134314906
At time: 283.3255064487457 and batch: 1100, loss is 4.08178593635559 and perplexity is 59.2511942752018
At time: 284.5503776073456 and batch: 1150, loss is 4.026453642845154 and perplexity is 56.06174333100931
At time: 285.7774634361267 and batch: 1200, loss is 4.1114346790313725 and perplexity is 61.03421930079102
At time: 287.0018754005432 and batch: 1250, loss is 4.079750442504883 and perplexity is 59.1307114961845
At time: 288.2276713848114 and batch: 1300, loss is 4.0885620164871215 and perplexity is 59.654048460190445
At time: 289.4531843662262 and batch: 1350, loss is 3.966017761230469 and perplexity is 52.77395334998474
At time: 290.6793532371521 and batch: 1400, loss is 4.004932527542114 and perplexity is 54.86812218710927
At time: 291.90557837486267 and batch: 1450, loss is 3.9325176811218263 and perplexity is 51.03530668383039
At time: 293.1307110786438 and batch: 1500, loss is 3.9389368438720704 and perplexity is 51.36396434841627
At time: 294.35458993911743 and batch: 1550, loss is 3.951480498313904 and perplexity is 52.012314003884526
At time: 295.5794606208801 and batch: 1600, loss is 4.055555596351623 and perplexity is 57.71722156725443
At time: 296.80648016929626 and batch: 1650, loss is 3.99290078163147 and perplexity is 54.21191843689845
At time: 298.03251576423645 and batch: 1700, loss is 4.027612771987915 and perplexity is 56.12676380778299
At time: 299.2573711872101 and batch: 1750, loss is 4.035136437416076 and perplexity is 56.55063533455963
At time: 300.48355174064636 and batch: 1800, loss is 3.9761328983306883 and perplexity is 53.31047805935625
At time: 301.70914244651794 and batch: 1850, loss is 4.019347124099731 and perplexity is 55.66475178581291
At time: 302.9343945980072 and batch: 1900, loss is 4.1074341297149655 and perplexity is 60.790536653712756
At time: 304.1611428260803 and batch: 1950, loss is 4.0250890254974365 and perplexity is 55.98529267832372
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.467984079760174 and perplexity of 87.18079621421056
finished 6 epochs...
Completing Train Step...
At time: 308.0935504436493 and batch: 50, loss is 3.9924229907989504 and perplexity is 54.186022666129574
At time: 309.34607911109924 and batch: 100, loss is 3.9457512283325196 and perplexity is 51.715173426685645
At time: 310.569304227829 and batch: 150, loss is 3.9105705499649046 and perplexity is 49.92742994198452
At time: 311.79376745224 and batch: 200, loss is 3.9246500635147097 and perplexity is 50.63535579974696
At time: 313.017201423645 and batch: 250, loss is 3.915046491622925 and perplexity is 50.15140307695826
At time: 314.27202463150024 and batch: 300, loss is 3.933826127052307 and perplexity is 51.10212732923922
At time: 315.49662470817566 and batch: 350, loss is 3.9446073722839357 and perplexity is 51.65605253210058
At time: 316.7210669517517 and batch: 400, loss is 3.9209359979629514 and perplexity is 50.44764157631739
At time: 317.94774556159973 and batch: 450, loss is 3.94406476020813 and perplexity is 51.62803093732358
At time: 319.1722674369812 and batch: 500, loss is 3.967585644721985 and perplexity is 52.85676166015177
At time: 320.39710807800293 and batch: 550, loss is 3.9205844354629518 and perplexity is 50.429909194528605
At time: 321.6222822666168 and batch: 600, loss is 3.912216820716858 and perplexity is 50.00969170360542
At time: 322.8439288139343 and batch: 650, loss is 3.9633628034591677 and perplexity is 52.634026564462225
At time: 324.0643048286438 and batch: 700, loss is 3.9994317054748536 and perplexity is 54.567131018200286
At time: 325.2897906303406 and batch: 750, loss is 3.959000000953674 and perplexity is 52.404894893049416
At time: 326.51429057121277 and batch: 800, loss is 3.92864688873291 and perplexity is 50.838141446180956
At time: 327.739727973938 and batch: 850, loss is 3.924247603416443 and perplexity is 50.614981189734806
At time: 328.9638030529022 and batch: 900, loss is 3.9078029203414917 and perplexity is 49.789440347981
At time: 330.18942165374756 and batch: 950, loss is 4.006469497680664 and perplexity is 54.95251769254119
At time: 331.4146931171417 and batch: 1000, loss is 3.986383695602417 and perplexity is 53.85976345919283
At time: 332.639297246933 and batch: 1050, loss is 3.925073742866516 and perplexity is 50.65681349974192
At time: 333.86396622657776 and batch: 1100, loss is 3.9802034950256346 and perplexity is 53.52792578589457
At time: 335.08894395828247 and batch: 1150, loss is 3.9239038228988647 and perplexity is 50.597583735928374
At time: 336.3148925304413 and batch: 1200, loss is 4.009575147628784 and perplexity is 55.123446261027325
At time: 337.5400354862213 and batch: 1250, loss is 3.9810903882980346 and perplexity is 53.57542040137388
At time: 338.7656030654907 and batch: 1300, loss is 3.98780659198761 and perplexity is 53.93645487095321
At time: 339.99159359931946 and batch: 1350, loss is 3.865382308959961 and perplexity is 47.721513307762
At time: 341.21774435043335 and batch: 1400, loss is 3.9037382555007936 and perplexity is 49.587473701789335
At time: 342.443297624588 and batch: 1450, loss is 3.8277020835876465 and perplexity is 45.956811893281724
At time: 343.6688814163208 and batch: 1500, loss is 3.842307186126709 and perplexity is 46.63294129430169
At time: 344.8939402103424 and batch: 1550, loss is 3.852316756248474 and perplexity is 47.10206091623701
At time: 346.1198434829712 and batch: 1600, loss is 3.9592822265625 and perplexity is 52.41968698367126
At time: 347.3455982208252 and batch: 1650, loss is 3.8939056539535524 and perplexity is 49.102289053772566
At time: 348.57034492492676 and batch: 1700, loss is 3.9309392786026 and perplexity is 50.95481596727694
At time: 349.7966022491455 and batch: 1750, loss is 3.937440767288208 and perplexity is 51.287177378016786
At time: 351.0217225551605 and batch: 1800, loss is 3.8782761764526366 and perplexity is 48.3408121757334
At time: 352.24820709228516 and batch: 1850, loss is 3.9211363983154297 and perplexity is 50.45775231453489
At time: 353.4739513397217 and batch: 1900, loss is 4.005216474533081 and perplexity is 54.88370403740937
At time: 354.6989607810974 and batch: 1950, loss is 3.9271716928482054 and perplexity is 50.76320051899776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.476125034066134 and perplexity of 87.89342790776548
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 358.736380815506 and batch: 50, loss is 3.9289283323287965 and perplexity is 50.8524515291639
At time: 359.9621775150299 and batch: 100, loss is 3.9076371812820434 and perplexity is 49.78118897677341
At time: 361.1869583129883 and batch: 150, loss is 3.8806103897094726 and perplexity is 48.45378173659013
At time: 362.4119305610657 and batch: 200, loss is 3.8834004735946657 and perplexity is 48.5891606235934
At time: 363.6374080181122 and batch: 250, loss is 3.87767991065979 and perplexity is 48.31199679470133
At time: 364.8618538379669 and batch: 300, loss is 3.9059600019454956 and perplexity is 49.697766971659405
At time: 366.0865409374237 and batch: 350, loss is 3.9158649110794066 and perplexity is 50.19246476155514
At time: 367.31135869026184 and batch: 400, loss is 3.8749887275695802 and perplexity is 48.182155158046115
At time: 368.5364637374878 and batch: 450, loss is 3.893624811172485 and perplexity is 49.088500966590935
At time: 369.76174998283386 and batch: 500, loss is 3.911754927635193 and perplexity is 49.98659790683438
At time: 370.9867134094238 and batch: 550, loss is 3.8613539218902586 and perplexity is 47.52965927121541
At time: 372.2118651866913 and batch: 600, loss is 3.834648971557617 and perplexity is 46.27718020997035
At time: 373.4378321170807 and batch: 650, loss is 3.8723230838775633 and perplexity is 48.05388973099537
At time: 374.66063117980957 and batch: 700, loss is 3.9062484455108644 and perplexity is 49.71210404037378
At time: 375.88449120521545 and batch: 750, loss is 3.8550351285934448 and perplexity is 47.230276045299036
At time: 377.14067363739014 and batch: 800, loss is 3.824221987724304 and perplexity is 45.797155752790374
At time: 378.36541771888733 and batch: 850, loss is 3.814580354690552 and perplexity is 45.35771823488734
At time: 379.59235525131226 and batch: 900, loss is 3.7862242794036867 and perplexity is 44.08961553836827
At time: 380.81637954711914 and batch: 950, loss is 3.878296694755554 and perplexity is 48.34180405733673
At time: 382.04245042800903 and batch: 1000, loss is 3.851524829864502 and perplexity is 47.0647743175273
At time: 383.2630319595337 and batch: 1050, loss is 3.7831670665740966 and perplexity is 43.955030033185075
At time: 384.4838263988495 and batch: 1100, loss is 3.82250994682312 and perplexity is 45.71881622835368
At time: 385.7042751312256 and batch: 1150, loss is 3.7762746524810793 and perplexity is 43.653115420204934
At time: 386.9255442619324 and batch: 1200, loss is 3.833213348388672 and perplexity is 46.21079128400998
At time: 388.1468780040741 and batch: 1250, loss is 3.80632520198822 and perplexity is 44.98482460918634
At time: 389.36677384376526 and batch: 1300, loss is 3.8155237579345704 and perplexity is 45.400529044164415
At time: 390.58681178092957 and batch: 1350, loss is 3.688895525932312 and perplexity is 40.00064287790112
At time: 391.8069610595703 and batch: 1400, loss is 3.707457766532898 and perplexity is 40.75007851905121
At time: 393.02564311027527 and batch: 1450, loss is 3.6163604784011842 and perplexity is 37.20192392669105
At time: 394.2499465942383 and batch: 1500, loss is 3.6193538331985473 and perplexity is 37.31344931840742
At time: 395.475136756897 and batch: 1550, loss is 3.6279251050949095 and perplexity is 37.634647610407455
At time: 396.7016353607178 and batch: 1600, loss is 3.7216310262680055 and perplexity is 41.33175233592187
At time: 397.9272291660309 and batch: 1650, loss is 3.6457044792175295 and perplexity is 38.309751771349674
At time: 399.1535222530365 and batch: 1700, loss is 3.6776000690460204 and perplexity is 39.55135954798673
At time: 400.37828183174133 and batch: 1750, loss is 3.663990550041199 and perplexity is 39.01673084025548
At time: 401.60278964042664 and batch: 1800, loss is 3.5994955921173095 and perplexity is 36.579778660744545
At time: 402.8276171684265 and batch: 1850, loss is 3.633631052970886 and perplexity is 37.85000276635927
At time: 404.0540738105774 and batch: 1900, loss is 3.706335606575012 and perplexity is 40.704376060186966
At time: 405.28013920783997 and batch: 1950, loss is 3.623568263053894 and perplexity is 37.47103606912744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.413685785337936 and perplexity of 82.57325058962542
finished 8 epochs...
Completing Train Step...
At time: 409.2371220588684 and batch: 50, loss is 3.823537745475769 and perplexity is 45.765830122343665
At time: 410.49129581451416 and batch: 100, loss is 3.7883514595031738 and perplexity is 44.18350191234653
At time: 411.71538853645325 and batch: 150, loss is 3.757024731636047 and perplexity is 42.82083279177678
At time: 412.93879079818726 and batch: 200, loss is 3.759696726799011 and perplexity is 42.93540284702225
At time: 414.1626102924347 and batch: 250, loss is 3.754006824493408 and perplexity is 42.691798299633085
At time: 415.3874931335449 and batch: 300, loss is 3.7737055158615114 and perplexity is 43.54110854491124
At time: 416.61127614974976 and batch: 350, loss is 3.787510313987732 and perplexity is 44.14635278395815
At time: 417.8345456123352 and batch: 400, loss is 3.753072152137756 and perplexity is 42.65191409818322
At time: 419.05859088897705 and batch: 450, loss is 3.774825348854065 and perplexity is 43.58989462582543
At time: 420.2817039489746 and batch: 500, loss is 3.799870090484619 and perplexity is 44.69537776126939
At time: 421.5056691169739 and batch: 550, loss is 3.7494576025009154 and perplexity is 42.49802492514274
At time: 422.73017859458923 and batch: 600, loss is 3.7305818796157837 and perplexity is 41.703367444779985
At time: 423.95482635498047 and batch: 650, loss is 3.7689488887786866 and perplexity is 43.334491518429935
At time: 425.17848563194275 and batch: 700, loss is 3.80497407913208 and perplexity is 44.924085626631296
At time: 426.40268993377686 and batch: 750, loss is 3.7564031457901 and perplexity is 42.794224238808425
At time: 427.62628650665283 and batch: 800, loss is 3.727279644012451 and perplexity is 41.56588023254732
At time: 428.8493616580963 and batch: 850, loss is 3.7221313762664794 and perplexity is 41.352437852707666
At time: 430.0733780860901 and batch: 900, loss is 3.695880889892578 and perplexity is 40.28104012528951
At time: 431.296484708786 and batch: 950, loss is 3.7903247451782227 and perplexity is 44.270774662458514
At time: 432.5200035572052 and batch: 1000, loss is 3.7666419839859007 and perplexity is 43.23463819259446
At time: 433.74342942237854 and batch: 1050, loss is 3.7018336486816406 and perplexity is 40.52153854529148
At time: 434.9665689468384 and batch: 1100, loss is 3.7431688690185547 and perplexity is 42.23160477356079
At time: 436.19084191322327 and batch: 1150, loss is 3.6993223237991333 and perplexity is 40.419903470027535
At time: 437.41373324394226 and batch: 1200, loss is 3.7604833602905274 and perplexity is 42.96919056040464
At time: 438.66681003570557 and batch: 1250, loss is 3.7334115934371948 and perplexity is 41.82154316291384
At time: 439.8897864818573 and batch: 1300, loss is 3.7473660707473755 and perplexity is 42.40923184569047
At time: 441.1126883029938 and batch: 1350, loss is 3.6221447515487672 and perplexity is 37.417733565538526
At time: 442.33593821525574 and batch: 1400, loss is 3.645721225738525 and perplexity is 38.31039333178399
At time: 443.559853553772 and batch: 1450, loss is 3.5592993688583374 and perplexity is 35.13856934265645
At time: 444.78220295906067 and batch: 1500, loss is 3.564518370628357 and perplexity is 35.322436983675296
At time: 446.00490522384644 and batch: 1550, loss is 3.575743570327759 and perplexity is 35.72117214672263
At time: 447.2282886505127 and batch: 1600, loss is 3.675777153968811 and perplexity is 39.47932645339694
At time: 448.4507656097412 and batch: 1650, loss is 3.6031219005584716 and perplexity is 36.712669025977526
At time: 449.6748538017273 and batch: 1700, loss is 3.63946985244751 and perplexity is 38.071647783421135
At time: 450.89901065826416 and batch: 1750, loss is 3.6294019508361814 and perplexity is 37.690269241630176
At time: 452.1231462955475 and batch: 1800, loss is 3.5688130760192873 and perplexity is 35.47446266329313
At time: 453.3476810455322 and batch: 1850, loss is 3.6091583728790284 and perplexity is 36.93495427074303
At time: 454.57366609573364 and batch: 1900, loss is 3.6862502336502074 and perplexity is 39.89496931636688
At time: 455.7968964576721 and batch: 1950, loss is 3.608123846054077 and perplexity is 36.89676382769658
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.419358648255814 and perplexity of 83.04300849722395
Annealing...
finished 9 epochs...
Completing Train Step...
At time: 459.78223991394043 and batch: 50, loss is 3.784845952987671 and perplexity is 44.02888751773145
At time: 461.0086750984192 and batch: 100, loss is 3.777645859718323 and perplexity is 43.71301394525773
At time: 462.2356240749359 and batch: 150, loss is 3.7626882791519165 and perplexity is 43.06403866689272
At time: 463.46036314964294 and batch: 200, loss is 3.7657115602493287 and perplexity is 43.19443036703624
At time: 464.6862139701843 and batch: 250, loss is 3.7655564022064207 and perplexity is 43.18772892366083
At time: 465.9126214981079 and batch: 300, loss is 3.782899513244629 and perplexity is 43.94327129166822
At time: 467.1384973526001 and batch: 350, loss is 3.809475955963135 and perplexity is 45.12678424664151
At time: 468.3646535873413 and batch: 400, loss is 3.782209496498108 and perplexity is 43.91296015737783
At time: 469.6214783191681 and batch: 450, loss is 3.800909762382507 and perplexity is 44.741870453878356
At time: 470.84693789482117 and batch: 500, loss is 3.8215035963058472 and perplexity is 45.672830216897374
At time: 472.07363629341125 and batch: 550, loss is 3.7703226232528686 and perplexity is 43.394062511345
At time: 473.29912543296814 and batch: 600, loss is 3.7412108039855956 and perplexity is 42.14899345053385
At time: 474.5251717567444 and batch: 650, loss is 3.772282848358154 and perplexity is 43.47920806706384
At time: 475.74968934059143 and batch: 700, loss is 3.804427618980408 and perplexity is 44.89954311035035
At time: 476.97552371025085 and batch: 750, loss is 3.74461697101593 and perplexity is 42.292804745992214
At time: 478.20088481903076 and batch: 800, loss is 3.7157505178451538 and perplexity is 41.08941385326945
At time: 479.4277241230011 and batch: 850, loss is 3.716066670417786 and perplexity is 41.1024064308773
At time: 480.65434861183167 and batch: 900, loss is 3.697944803237915 and perplexity is 40.36426255396658
At time: 481.87897968292236 and batch: 950, loss is 3.795833458900452 and perplexity is 44.515322640316725
At time: 483.1060619354248 and batch: 1000, loss is 3.756686849594116 and perplexity is 42.80636684538528
At time: 484.33074283599854 and batch: 1050, loss is 3.683747367858887 and perplexity is 39.79524241600309
At time: 485.55541825294495 and batch: 1100, loss is 3.715744595527649 and perplexity is 41.08917050943511
At time: 486.78055024147034 and batch: 1150, loss is 3.678000040054321 and perplexity is 39.567182109216745
At time: 488.00705742836 and batch: 1200, loss is 3.726602005958557 and perplexity is 41.53772315159037
At time: 489.23198199272156 and batch: 1250, loss is 3.6963247442245484 and perplexity is 40.29892300784924
At time: 490.45970487594604 and batch: 1300, loss is 3.711216697692871 and perplexity is 40.903543510437466
At time: 491.68524408340454 and batch: 1350, loss is 3.584316759109497 and perplexity is 36.028733003889805
At time: 492.91046047210693 and batch: 1400, loss is 3.6116365146636964 and perplexity is 37.026597830203144
At time: 494.1361041069031 and batch: 1450, loss is 3.5189112424850464 and perplexity is 33.7476654301173
At time: 495.3609936237335 and batch: 1500, loss is 3.514239239692688 and perplexity is 33.59036398551254
At time: 496.5864155292511 and batch: 1550, loss is 3.523841676712036 and perplexity is 33.91446693886834
At time: 497.81342601776123 and batch: 1600, loss is 3.620669655799866 and perplexity is 37.362579514576375
At time: 499.0385699272156 and batch: 1650, loss is 3.539387068748474 and perplexity is 34.445799811966346
At time: 500.2635886669159 and batch: 1700, loss is 3.567403416633606 and perplexity is 35.42449098384635
At time: 501.4889087677002 and batch: 1750, loss is 3.5531982707977297 and perplexity is 34.924838145865586
At time: 502.71318316459656 and batch: 1800, loss is 3.488064503669739 and perplexity is 32.72255199563575
At time: 503.93400478363037 and batch: 1850, loss is 3.529069671630859 and perplexity is 34.09223588236882
At time: 505.15587544441223 and batch: 1900, loss is 3.6101899671554567 and perplexity is 36.97307581777303
At time: 506.37761187553406 and batch: 1950, loss is 3.5383171319961546 and perplexity is 34.40896469392173
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.397412961028343 and perplexity of 81.24042442455344
finished 10 epochs...
Completing Train Step...
At time: 510.29376244544983 and batch: 50, loss is 3.7855337190628053 and perplexity is 44.059179508599826
At time: 511.560585975647 and batch: 100, loss is 3.756066765785217 and perplexity is 42.779831538294054
At time: 512.7824387550354 and batch: 150, loss is 3.7264104890823364 and perplexity is 41.529768738333566
At time: 514.0033123493195 and batch: 200, loss is 3.7230157232284546 and perplexity is 41.38902393050194
At time: 515.2261092662811 and batch: 250, loss is 3.718284821510315 and perplexity is 41.19367896932476
At time: 516.4487636089325 and batch: 300, loss is 3.7300255823135378 and perplexity is 41.68017442568098
At time: 517.6719958782196 and batch: 350, loss is 3.75681658744812 and perplexity is 42.81192081182956
At time: 518.8949196338654 and batch: 400, loss is 3.7298395681381225 and perplexity is 41.67242204345287
At time: 520.1183905601501 and batch: 450, loss is 3.7489801168441774 and perplexity is 42.47773757164689
At time: 521.3407661914825 and batch: 500, loss is 3.7707074165344237 and perplexity is 43.410763468060644
At time: 522.56414270401 and batch: 550, loss is 3.717625241279602 and perplexity is 41.1665173916508
At time: 523.7872848510742 and batch: 600, loss is 3.6918319177627565 and perplexity is 40.118273058489805
At time: 525.0102260112762 and batch: 650, loss is 3.7278165864944457 and perplexity is 41.58820471239012
At time: 526.2323508262634 and batch: 700, loss is 3.7610463666915894 and perplexity is 42.99338930112236
At time: 527.4554672241211 and batch: 750, loss is 3.7059536361694336 and perplexity is 40.68883116218893
At time: 528.6789081096649 and batch: 800, loss is 3.676990842819214 and perplexity is 39.527271160827894
At time: 529.9023826122284 and batch: 850, loss is 3.6780319356918336 and perplexity is 39.568444149841376
At time: 531.1259107589722 and batch: 900, loss is 3.6612633275985718 and perplexity is 38.910468502648605
At time: 532.3797821998596 and batch: 950, loss is 3.761715135574341 and perplexity is 43.02215155863038
At time: 533.6028797626495 and batch: 1000, loss is 3.723787798881531 and perplexity is 41.420991727374094
At time: 534.8263487815857 and batch: 1050, loss is 3.6535968494415285 and perplexity is 38.61330280843318
At time: 536.0496966838837 and batch: 1100, loss is 3.6883624744415284 and perplexity is 39.97932615754229
At time: 537.273580789566 and batch: 1150, loss is 3.651112174987793 and perplexity is 38.51748041439548
At time: 538.4969568252563 and batch: 1200, loss is 3.701305432319641 and perplexity is 40.500140057631654
At time: 539.720198392868 and batch: 1250, loss is 3.672579665184021 and perplexity is 39.353293351924876
At time: 540.9435594081879 and batch: 1300, loss is 3.688124318122864 and perplexity is 39.96980596209426
At time: 542.1656167507172 and batch: 1350, loss is 3.5625643348693847 and perplexity is 35.25348306986211
At time: 543.3875093460083 and batch: 1400, loss is 3.591965970993042 and perplexity is 36.305381137729626
At time: 544.6114733219147 and batch: 1450, loss is 3.501398959159851 and perplexity is 33.161811543564674
At time: 545.8340587615967 and batch: 1500, loss is 3.499827547073364 and perplexity is 33.10974159448383
At time: 547.0573365688324 and batch: 1550, loss is 3.5112393617630007 and perplexity is 33.48974798725437
At time: 548.280356168747 and batch: 1600, loss is 3.61150230884552 and perplexity is 37.0216289787789
At time: 549.501113653183 and batch: 1650, loss is 3.5327516841888427 and perplexity is 34.217995304824875
At time: 550.7247362136841 and batch: 1700, loss is 3.563423476219177 and perplexity is 35.28378380933694
At time: 551.9474318027496 and batch: 1750, loss is 3.551283669471741 and perplexity is 34.85803497556747
At time: 553.1714704036713 and batch: 1800, loss is 3.4881848287582398 and perplexity is 32.72648957649073
At time: 554.3943231105804 and batch: 1850, loss is 3.531240849494934 and perplexity is 34.166336604067446
At time: 555.6180012226105 and batch: 1900, loss is 3.6139302349090574 and perplexity is 37.111623963066336
At time: 556.8407189846039 and batch: 1950, loss is 3.543172125816345 and perplexity is 34.576426188194155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.399321800054506 and perplexity of 81.39564741791905
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 560.8006558418274 and batch: 50, loss is 3.777586245536804 and perplexity is 43.71040810738288
At time: 562.0258238315582 and batch: 100, loss is 3.7670339822769163 and perplexity is 43.25158941908748
At time: 563.2782528400421 and batch: 150, loss is 3.7488784790039062 and perplexity is 42.47342044553591
At time: 564.50177526474 and batch: 200, loss is 3.7549052381515504 and perplexity is 42.73017042875758
At time: 565.7255096435547 and batch: 250, loss is 3.7565291690826417 and perplexity is 42.79961764768919
At time: 566.9499197006226 and batch: 300, loss is 3.7584723806381226 and perplexity is 42.88286721884032
At time: 568.1749277114868 and batch: 350, loss is 3.7849867820739744 and perplexity is 44.035088502360786
At time: 569.3995931148529 and batch: 400, loss is 3.7658102703094483 and perplexity is 43.19869430229779
At time: 570.6257922649384 and batch: 450, loss is 3.787161989212036 and perplexity is 44.13097819335775
At time: 571.8506217002869 and batch: 500, loss is 3.820593137741089 and perplexity is 45.63126592160514
At time: 573.0758645534515 and batch: 550, loss is 3.77141930103302 and perplexity is 43.44167792009982
At time: 574.3025217056274 and batch: 600, loss is 3.7281366968154908 and perplexity is 41.601519656964186
At time: 575.5273501873016 and batch: 650, loss is 3.747847008705139 and perplexity is 42.429632960486664
At time: 576.7512636184692 and batch: 700, loss is 3.771319317817688 and perplexity is 43.437334698590185
At time: 577.9753184318542 and batch: 750, loss is 3.7089592885971068 and perplexity is 40.81131162098811
At time: 579.1995227336884 and batch: 800, loss is 3.673437819480896 and perplexity is 39.387079044306155
At time: 580.4230890274048 and batch: 850, loss is 3.6774296712875367 and perplexity is 39.54462065913685
At time: 581.6485066413879 and batch: 900, loss is 3.66205304145813 and perplexity is 38.94120877531915
At time: 582.8727707862854 and batch: 950, loss is 3.7722414112091065 and perplexity is 43.47740644996588
At time: 584.0978705883026 and batch: 1000, loss is 3.74054847240448 and perplexity is 42.12108608404462
At time: 585.3218314647675 and batch: 1050, loss is 3.6777275514602663 and perplexity is 39.556401972191985
At time: 586.5466475486755 and batch: 1100, loss is 3.7056812381744386 and perplexity is 40.677749115593826
At time: 587.7725336551666 and batch: 1150, loss is 3.676737456321716 and perplexity is 39.51725675284427
At time: 588.9960997104645 and batch: 1200, loss is 3.725387635231018 and perplexity is 41.48731157187498
At time: 590.2194631099701 and batch: 1250, loss is 3.6966325998306275 and perplexity is 40.311331167078855
At time: 591.4437913894653 and batch: 1300, loss is 3.7005274868011475 and perplexity is 40.468645407324864
At time: 592.6677558422089 and batch: 1350, loss is 3.5641657638549806 and perplexity is 35.30998424873106
At time: 593.8907556533813 and batch: 1400, loss is 3.5935531425476075 and perplexity is 36.36304975884045
At time: 595.1143715381622 and batch: 1450, loss is 3.501859998703003 and perplexity is 33.17710397494572
At time: 596.3384952545166 and batch: 1500, loss is 3.4964647579193113 and perplexity is 32.99858751317336
At time: 597.5627400875092 and batch: 1550, loss is 3.5076072216033936 and perplexity is 33.36832916722512
At time: 598.7866876125336 and batch: 1600, loss is 3.6062417459487914 and perplexity is 36.82738573335095
At time: 600.0113956928253 and batch: 1650, loss is 3.530853247642517 and perplexity is 34.15309623487099
At time: 601.2369277477264 and batch: 1700, loss is 3.558700180053711 and perplexity is 35.11752101188756
At time: 602.4623637199402 and batch: 1750, loss is 3.546081848144531 and perplexity is 34.67718049995189
At time: 603.6871428489685 and batch: 1800, loss is 3.4730434370040895 and perplexity is 32.23469758043356
At time: 604.9117903709412 and batch: 1850, loss is 3.503843832015991 and perplexity is 33.24298714804902
At time: 606.1366250514984 and batch: 1900, loss is 3.5861676931381226 and perplexity is 36.09548156635131
At time: 607.3602182865143 and batch: 1950, loss is 3.5238256311416625 and perplexity is 33.91392276626817
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386414141987645 and perplexity of 80.3517717212943
finished 12 epochs...
Completing Train Step...
At time: 611.3158240318298 and batch: 50, loss is 3.7814291524887085 and perplexity is 43.878706308615065
At time: 612.5717782974243 and batch: 100, loss is 3.7616521549224853 and perplexity is 43.019442080804225
At time: 613.7973930835724 and batch: 150, loss is 3.7368250370025633 and perplexity is 41.964542561658234
At time: 615.0219070911407 and batch: 200, loss is 3.737604570388794 and perplexity is 41.99726807728176
At time: 616.2468094825745 and batch: 250, loss is 3.736824402809143 and perplexity is 41.96451594802989
At time: 617.4728457927704 and batch: 300, loss is 3.736075448989868 and perplexity is 41.933098230215066
At time: 618.6976976394653 and batch: 350, loss is 3.7623382711410525 and perplexity is 43.04896854586454
At time: 619.9234483242035 and batch: 400, loss is 3.7432183837890625 and perplexity is 42.23369591355006
At time: 621.1486568450928 and batch: 450, loss is 3.7638301944732664 and perplexity is 43.11324224025613
At time: 622.3737328052521 and batch: 500, loss is 3.7973151922225954 and perplexity is 44.581331368808094
At time: 623.5983490943909 and batch: 550, loss is 3.7482404613494875 and perplexity is 42.446330296363776
At time: 624.8242330551147 and batch: 600, loss is 3.70853994846344 and perplexity is 40.794201387872285
At time: 626.0805411338806 and batch: 650, loss is 3.7302381467819212 and perplexity is 41.6890350914979
At time: 627.3071835041046 and batch: 700, loss is 3.7585414600372316 and perplexity is 42.88582964385996
At time: 628.5326025485992 and batch: 750, loss is 3.6988975286483763 and perplexity is 40.40273693742745
At time: 629.7572615146637 and batch: 800, loss is 3.662245945930481 and perplexity is 38.94872143324002
At time: 630.984171628952 and batch: 850, loss is 3.6639876317977906 and perplexity is 39.016616980104025
At time: 632.2088198661804 and batch: 900, loss is 3.648197040557861 and perplexity is 38.40536028311255
At time: 633.4338805675507 and batch: 950, loss is 3.7568797302246093 and perplexity is 42.81462416072404
At time: 634.6588168144226 and batch: 1000, loss is 3.7254637908935546 and perplexity is 41.49047118588432
At time: 635.8840224742889 and batch: 1050, loss is 3.661845073699951 and perplexity is 38.933111101486084
At time: 637.1096224784851 and batch: 1100, loss is 3.691132860183716 and perplexity is 40.09023787589537
At time: 638.3379771709442 and batch: 1150, loss is 3.6629320859909056 and perplexity is 38.97545488171384
At time: 639.5633554458618 and batch: 1200, loss is 3.711658682823181 and perplexity is 40.92162626430586
At time: 640.7890613079071 and batch: 1250, loss is 3.6848719835281374 and perplexity is 39.840021944345764
At time: 642.0153911113739 and batch: 1300, loss is 3.6907045078277587 and perplexity is 40.073068805518744
At time: 643.2405760288239 and batch: 1350, loss is 3.5560114097595217 and perplexity is 35.02322489169801
At time: 644.4668011665344 and batch: 1400, loss is 3.58706778049469 and perplexity is 36.127985278834295
At time: 645.6923732757568 and batch: 1450, loss is 3.4973384094238282 and perplexity is 33.027429375835034
At time: 646.9176604747772 and batch: 1500, loss is 3.4934631061553953 and perplexity is 32.89968575333666
At time: 648.1424851417542 and batch: 1550, loss is 3.505437717437744 and perplexity is 33.29601490950149
At time: 649.3693788051605 and batch: 1600, loss is 3.605662713050842 and perplexity is 36.80606763800076
At time: 650.5949466228485 and batch: 1650, loss is 3.531005449295044 and perplexity is 34.15829478816101
At time: 651.8220205307007 and batch: 1700, loss is 3.560601396560669 and perplexity is 35.18435053108103
At time: 653.0477454662323 and batch: 1750, loss is 3.54866126537323 and perplexity is 34.76674287648691
At time: 654.2730183601379 and batch: 1800, loss is 3.476677236557007 and perplexity is 32.35204508962676
At time: 655.4980359077454 and batch: 1850, loss is 3.5086668157577514 and perplexity is 33.403704792344385
At time: 656.723893404007 and batch: 1900, loss is 3.5911519145965576 and perplexity is 36.27583853629094
At time: 657.9486064910889 and batch: 1950, loss is 3.5289444732666015 and perplexity is 34.08796785738291
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385624091569768 and perplexity of 80.28831484083688
finished 13 epochs...
Completing Train Step...
At time: 661.9305100440979 and batch: 50, loss is 3.7753090047836304 and perplexity is 43.61098223599311
At time: 663.1534123420715 and batch: 100, loss is 3.754095377922058 and perplexity is 42.695578972141035
At time: 664.3779723644257 and batch: 150, loss is 3.7280586338043213 and perplexity is 41.598272243823615
At time: 665.6024158000946 and batch: 200, loss is 3.727988910675049 and perplexity is 41.595371983219245
At time: 666.8274700641632 and batch: 250, loss is 3.7266933870315553 and perplexity is 41.541519086737544
At time: 668.051659822464 and batch: 300, loss is 3.725257167816162 and perplexity is 41.48189918266276
At time: 669.275054693222 and batch: 350, loss is 3.7514811897277833 and perplexity is 42.58411045696367
At time: 670.5009880065918 and batch: 400, loss is 3.731763172149658 and perplexity is 41.75266043036567
At time: 671.7254626750946 and batch: 450, loss is 3.752487497329712 and perplexity is 42.62698473977817
At time: 672.9500358104706 and batch: 500, loss is 3.78620445728302 and perplexity is 44.088741597350634
At time: 674.174919128418 and batch: 550, loss is 3.737143940925598 and perplexity is 41.977927353027304
At time: 675.3971979618073 and batch: 600, loss is 3.698578267097473 and perplexity is 40.389839955836784
At time: 676.6206049919128 and batch: 650, loss is 3.7203675937652587 and perplexity is 41.2795654308832
At time: 677.8470339775085 and batch: 700, loss is 3.7499440050125123 and perplexity is 42.51870109926811
At time: 679.0702812671661 and batch: 750, loss is 3.6913582134246825 and perplexity is 40.099273358981286
At time: 680.2949020862579 and batch: 800, loss is 3.654480233192444 and perplexity is 38.64742824341151
At time: 681.519690990448 and batch: 850, loss is 3.655661301612854 and perplexity is 38.69310046614075
At time: 682.7436609268188 and batch: 900, loss is 3.639692826271057 and perplexity is 38.080137710776754
At time: 683.9685337543488 and batch: 950, loss is 3.7482243394851684 and perplexity is 42.445645987902076
At time: 685.1929469108582 and batch: 1000, loss is 3.7169181299209595 and perplexity is 41.13741836894462
At time: 686.4170274734497 and batch: 1050, loss is 3.6535251092910768 and perplexity is 38.610532783642455
At time: 687.6720387935638 and batch: 1100, loss is 3.683812336921692 and perplexity is 39.797827959596226
At time: 688.8965990543365 and batch: 1150, loss is 3.6562042808532715 and perplexity is 38.714115721348584
At time: 690.1214661598206 and batch: 1200, loss is 3.7053192853927612 and perplexity is 40.66302835541982
At time: 691.3459904193878 and batch: 1250, loss is 3.679425482749939 and perplexity is 39.62362307706638
At time: 692.5712807178497 and batch: 1300, loss is 3.6859953927993776 and perplexity is 39.88480374379906
At time: 693.7971794605255 and batch: 1350, loss is 3.551966495513916 and perplexity is 34.88184507778164
At time: 695.0224080085754 and batch: 1400, loss is 3.5836671209335327 and perplexity is 36.00533496445158
At time: 696.2473564147949 and batch: 1450, loss is 3.4945863676071167 and perplexity is 32.93666146492513
At time: 697.4718344211578 and batch: 1500, loss is 3.4911624145507814 and perplexity is 32.82408072780253
At time: 698.6974718570709 and batch: 1550, loss is 3.5033926582336425 and perplexity is 33.22799216672645
At time: 699.9217193126678 and batch: 1600, loss is 3.6039919090270995 and perplexity is 36.74462325714637
At time: 701.14537525177 and batch: 1650, loss is 3.5297045040130617 and perplexity is 34.113885608935284
At time: 702.3701803684235 and batch: 1700, loss is 3.560111780166626 and perplexity is 35.167127912829436
At time: 703.5951747894287 and batch: 1750, loss is 3.548376383781433 and perplexity is 34.75683988209203
At time: 704.8195540904999 and batch: 1800, loss is 3.4767889833450316 and perplexity is 32.35566052875465
At time: 706.0445749759674 and batch: 1850, loss is 3.509331908226013 and perplexity is 33.42592873448285
At time: 707.2692067623138 and batch: 1900, loss is 3.5917730712890625 and perplexity is 36.298378515878845
At time: 708.4935193061829 and batch: 1950, loss is 3.529740123748779 and perplexity is 34.115100758166484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.385944029342297 and perplexity of 80.31400621504855
Annealing...
finished 14 epochs...
Completing Train Step...
At time: 712.4445214271545 and batch: 50, loss is 3.7728975296020506 and perplexity is 43.505942136385876
At time: 713.7007744312286 and batch: 100, loss is 3.7589445734024047 and perplexity is 42.90312097991611
At time: 714.9268972873688 and batch: 150, loss is 3.738936882019043 and perplexity is 42.053258816253944
At time: 716.1536002159119 and batch: 200, loss is 3.7442749691009523 and perplexity is 42.27834299889287
At time: 717.3800237178802 and batch: 250, loss is 3.748674554824829 and perplexity is 42.46475997120902
At time: 718.6362903118134 and batch: 300, loss is 3.742491445541382 and perplexity is 42.20300578091669
At time: 719.8617701530457 and batch: 350, loss is 3.768495616912842 and perplexity is 43.31485366358372
At time: 721.0887622833252 and batch: 400, loss is 3.754532051086426 and perplexity is 42.7142270569781
At time: 722.3144619464874 and batch: 450, loss is 3.7779839420318604 and perplexity is 43.727795040616705
At time: 723.5408298969269 and batch: 500, loss is 3.819045639038086 and perplexity is 45.56070620639005
At time: 724.7671253681183 and batch: 550, loss is 3.778853974342346 and perplexity is 43.765856189982316
At time: 725.9926602840424 and batch: 600, loss is 3.7417507934570313 and perplexity is 42.17175960941861
At time: 727.2189228534698 and batch: 650, loss is 3.760623421669006 and perplexity is 42.97520930595371
At time: 728.4445896148682 and batch: 700, loss is 3.7945146465301516 and perplexity is 44.456653977133506
At time: 729.6706111431122 and batch: 750, loss is 3.732328233718872 and perplexity is 41.776259921142035
At time: 730.8969278335571 and batch: 800, loss is 3.6902145910263062 and perplexity is 40.05344114417827
At time: 732.1223955154419 and batch: 850, loss is 3.683930630683899 and perplexity is 39.80253607285797
At time: 733.3470611572266 and batch: 900, loss is 3.656783466339111 and perplexity is 38.736544869963176
At time: 734.5730376243591 and batch: 950, loss is 3.7657394504547117 and perplexity is 43.19563508537042
At time: 735.7989444732666 and batch: 1000, loss is 3.7291585779190064 and perplexity is 41.64405319218586
At time: 737.0244383811951 and batch: 1050, loss is 3.6682634782791137 and perplexity is 39.183803221161625
At time: 738.2496151924133 and batch: 1100, loss is 3.6888743591308595 and perplexity is 39.999796201196105
At time: 739.4756445884705 and batch: 1150, loss is 3.656164584159851 and perplexity is 38.71257892946873
At time: 740.7003314495087 and batch: 1200, loss is 3.7074654483795166 and perplexity is 40.75039155610645
At time: 741.926441192627 and batch: 1250, loss is 3.6787944507598875 and perplexity is 39.598627190774394
At time: 743.14674949646 and batch: 1300, loss is 3.6833175659179687 and perplexity is 39.7781420187286
At time: 744.3663849830627 and batch: 1350, loss is 3.549671812057495 and perplexity is 34.801894051183574
At time: 745.5869340896606 and batch: 1400, loss is 3.580858039855957 and perplexity is 35.904334984293065
At time: 746.8083057403564 and batch: 1450, loss is 3.4902570247650146 and perplexity is 32.794375589777864
At time: 748.0295386314392 and batch: 1500, loss is 3.486037015914917 and perplexity is 32.65627463313242
At time: 749.2502160072327 and batch: 1550, loss is 3.4972257661819457 and perplexity is 33.02370926864549
At time: 750.4717762470245 and batch: 1600, loss is 3.595817527770996 and perplexity is 36.445483006483016
At time: 751.6926689147949 and batch: 1650, loss is 3.5226705360412596 and perplexity is 33.874771576272394
At time: 752.9132776260376 and batch: 1700, loss is 3.5540838289260863 and perplexity is 34.95577981846996
At time: 754.1364667415619 and batch: 1750, loss is 3.548247804641724 and perplexity is 34.75237116481905
At time: 755.3612871170044 and batch: 1800, loss is 3.479500870704651 and perplexity is 32.44352452033036
At time: 756.5867910385132 and batch: 1850, loss is 3.5079593324661253 and perplexity is 33.380080587176
At time: 757.812739610672 and batch: 1900, loss is 3.5894678926467893 and perplexity is 36.21480063695564
At time: 759.0377812385559 and batch: 1950, loss is 3.528503222465515 and perplexity is 34.072929832272735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.378126987191134 and perplexity of 79.6886357014645
finished 15 epochs...
Completing Train Step...
At time: 763.0169477462769 and batch: 50, loss is 3.7708040618896486 and perplexity is 43.414959119458445
At time: 764.2415647506714 and batch: 100, loss is 3.751374921798706 and perplexity is 42.57958537217376
At time: 765.465765953064 and batch: 150, loss is 3.7275089979171754 and perplexity is 41.57541462281498
At time: 766.6898577213287 and batch: 200, loss is 3.7281373071670534 and perplexity is 41.601545048524464
At time: 767.9137370586395 and batch: 250, loss is 3.7312116861343383 and perplexity is 41.72964077012971
At time: 769.1365883350372 and batch: 300, loss is 3.726915035247803 and perplexity is 41.55072771084319
At time: 770.3603227138519 and batch: 350, loss is 3.7541796731948853 and perplexity is 42.69917815931411
At time: 771.58411860466 and batch: 400, loss is 3.7386053800582886 and perplexity is 42.03932038893588
At time: 772.8073945045471 and batch: 450, loss is 3.760864200592041 and perplexity is 42.985558076400494
At time: 774.0327217578888 and batch: 500, loss is 3.799680848121643 and perplexity is 44.68692030264771
At time: 775.256537437439 and batch: 550, loss is 3.7583470153808594 and perplexity is 42.87749153412833
At time: 776.4800264835358 and batch: 600, loss is 3.7223722743988037 and perplexity is 41.36240077773027
At time: 777.703191280365 and batch: 650, loss is 3.743017387390137 and perplexity is 42.225207945812166
At time: 778.9265854358673 and batch: 700, loss is 3.7779817676544187 and perplexity is 43.72769995998897
At time: 780.1500308513641 and batch: 750, loss is 3.717835841178894 and perplexity is 41.175187969047
At time: 781.4214625358582 and batch: 800, loss is 3.6767261838912964 and perplexity is 39.516811299827815
At time: 782.6453084945679 and batch: 850, loss is 3.6711806440353394 and perplexity is 39.298275756618594
At time: 783.8685405254364 and batch: 900, loss is 3.6460344886779783 and perplexity is 38.322396438176746
At time: 785.0929801464081 and batch: 950, loss is 3.7546994256973267 and perplexity is 42.72137693244881
At time: 786.3182291984558 and batch: 1000, loss is 3.71906183719635 and perplexity is 41.22569954268225
At time: 787.5420815944672 and batch: 1050, loss is 3.657735753059387 and perplexity is 38.773450736926705
At time: 788.7668752670288 and batch: 1100, loss is 3.681027274131775 and perplexity is 39.68714271405067
At time: 789.9914152622223 and batch: 1150, loss is 3.6509208393096926 and perplexity is 38.5101113511665
At time: 791.2153594493866 and batch: 1200, loss is 3.702619333267212 and perplexity is 40.55338820376461
At time: 792.4396018981934 and batch: 1250, loss is 3.6753257751464843 and perplexity is 39.46151034272617
At time: 793.6641762256622 and batch: 1300, loss is 3.680793299674988 and perplexity is 39.6778580226254
At time: 794.8871741294861 and batch: 1350, loss is 3.5481320142745973 and perplexity is 34.748347407964
At time: 796.1108365058899 and batch: 1400, loss is 3.5803444528579713 and perplexity is 35.88589971913529
At time: 797.3355255126953 and batch: 1450, loss is 3.491356110572815 and perplexity is 32.83043923745556
At time: 798.5597083568573 and batch: 1500, loss is 3.4884860706329346 and perplexity is 32.736349650621975
At time: 799.7826597690582 and batch: 1550, loss is 3.5007755947113037 and perplexity is 33.141146090922426
At time: 801.0055742263794 and batch: 1600, loss is 3.6003849411010744 and perplexity is 36.61232532024689
At time: 802.2282660007477 and batch: 1650, loss is 3.528049659729004 and perplexity is 34.05747912517443
At time: 803.4502167701721 and batch: 1700, loss is 3.5605636644363403 and perplexity is 35.18302297583826
At time: 804.6712830066681 and batch: 1750, loss is 3.555595498085022 and perplexity is 35.00866135236987
At time: 805.8936200141907 and batch: 1800, loss is 3.4870915365219117 and perplexity is 32.69072951117733
At time: 807.1168026924133 and batch: 1850, loss is 3.514903116226196 and perplexity is 33.61267124372786
At time: 808.3409259319305 and batch: 1900, loss is 3.5958534479141235 and perplexity is 36.44679215696126
At time: 809.5646326541901 and batch: 1950, loss is 3.5338782358169554 and perplexity is 34.25656536464896
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3762990552325585 and perplexity of 79.54310334967163
finished 16 epochs...
Completing Train Step...
At time: 813.4968938827515 and batch: 50, loss is 3.7692590951919556 and perplexity is 43.34793624082644
At time: 814.7543823719025 and batch: 100, loss is 3.74764413356781 and perplexity is 42.42102591598017
At time: 815.9798123836517 and batch: 150, loss is 3.7228604316711427 and perplexity is 41.38259706355216
At time: 817.205783367157 and batch: 200, loss is 3.722347583770752 and perplexity is 41.361379526685056
At time: 818.4314901828766 and batch: 250, loss is 3.7248692464828492 and perplexity is 41.46581058977944
At time: 819.6573202610016 and batch: 300, loss is 3.7204656839370727 and perplexity is 41.28361474914464
At time: 820.8843836784363 and batch: 350, loss is 3.7479599285125733 and perplexity is 42.43442437698789
At time: 822.1109416484833 and batch: 400, loss is 3.731900625228882 and perplexity is 41.75839985654949
At time: 823.3368575572968 and batch: 450, loss is 3.753976616859436 and perplexity is 42.690508700894405
At time: 824.5628335475922 and batch: 500, loss is 3.792567024230957 and perplexity is 44.37015346900237
At time: 825.7885627746582 and batch: 550, loss is 3.751207666397095 and perplexity is 42.57246430205722
At time: 827.0140488147736 and batch: 600, loss is 3.7157507371902465 and perplexity is 41.08942286603173
At time: 828.2406854629517 and batch: 650, loss is 3.7370088958740233 and perplexity is 41.972258824424905
At time: 829.4655494689941 and batch: 700, loss is 3.7725252962112426 and perplexity is 43.48975078569179
At time: 830.6903381347656 and batch: 750, loss is 3.713284063339233 and perplexity is 40.98819356226045
At time: 831.9155979156494 and batch: 800, loss is 3.672406005859375 and perplexity is 39.346459878944096
At time: 833.1411135196686 and batch: 850, loss is 3.666951632499695 and perplexity is 39.132433816020004
At time: 834.3665549755096 and batch: 900, loss is 3.6426110458374024 and perplexity is 38.19142621690373
At time: 835.5916464328766 and batch: 950, loss is 3.751362137794495 and perplexity is 42.57904103805444
At time: 836.8186001777649 and batch: 1000, loss is 3.716054720878601 and perplexity is 41.10191527899559
At time: 838.0450320243835 and batch: 1050, loss is 3.6545108556747437 and perplexity is 38.648611741719556
At time: 839.2710468769073 and batch: 1100, loss is 3.6782584810256957 and perplexity is 39.57740921168983
At time: 840.497341632843 and batch: 1150, loss is 3.6486183118820192 and perplexity is 38.42154276846298
At time: 841.7228634357452 and batch: 1200, loss is 3.7001735544204712 and perplexity is 40.454324777729866
At time: 842.9971439838409 and batch: 1250, loss is 3.6734080123901367 and perplexity is 39.38590504756314
At time: 844.2226181030273 and batch: 1300, loss is 3.6794149827957154 and perplexity is 39.623207033022126
At time: 845.4478342533112 and batch: 1350, loss is 3.5470926666259768 and perplexity is 34.71225055663031
At time: 846.673615694046 and batch: 1400, loss is 3.5797857666015624 and perplexity is 35.86585635965942
At time: 847.899617433548 and batch: 1450, loss is 3.4914080238342287 and perplexity is 32.83214361686958
At time: 849.1239819526672 and batch: 1500, loss is 3.4890501070022584 and perplexity is 32.75481935072546
At time: 850.3501954078674 and batch: 1550, loss is 3.501793622970581 and perplexity is 33.17490189345294
At time: 851.5758275985718 and batch: 1600, loss is 3.60205614566803 and perplexity is 36.67356316175642
At time: 852.799966096878 and batch: 1650, loss is 3.529770917892456 and perplexity is 34.11615131965627
At time: 854.0260510444641 and batch: 1700, loss is 3.5628011989593507 and perplexity is 35.2618343430669
At time: 855.2516613006592 and batch: 1750, loss is 3.5580340242385864 and perplexity is 35.094135061261056
At time: 856.4764959812164 and batch: 1800, loss is 3.489531307220459 and perplexity is 32.77058476980148
At time: 857.7012841701508 and batch: 1850, loss is 3.5172769832611084 and perplexity is 33.69255803874817
At time: 858.9270293712616 and batch: 1900, loss is 3.5980137538909913 and perplexity is 36.52561348833782
At time: 860.1535813808441 and batch: 1950, loss is 3.5355993270874024 and perplexity is 34.31557480600449
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3756364689316865 and perplexity of 79.49041663573828
finished 17 epochs...
Completing Train Step...
At time: 864.1179621219635 and batch: 50, loss is 3.7673362064361573 and perplexity is 43.26466306982254
At time: 865.3411288261414 and batch: 100, loss is 3.744720425605774 and perplexity is 42.29718035709518
At time: 866.564759016037 and batch: 150, loss is 3.7195974254608153 and perplexity is 41.247785457502125
At time: 867.7874376773834 and batch: 200, loss is 3.7186211490631105 and perplexity is 41.207535868661054
At time: 869.0104081630707 and batch: 250, loss is 3.7208701610565185 and perplexity is 41.300316404209646
At time: 870.2335960865021 and batch: 300, loss is 3.7163204622268675 and perplexity is 41.1128392087838
At time: 871.4563264846802 and batch: 350, loss is 3.743875889778137 and perplexity is 42.261473952666776
At time: 872.67973279953 and batch: 400, loss is 3.7275724172592164 and perplexity is 41.578051391865635
At time: 873.9338181018829 and batch: 450, loss is 3.749640588760376 and perplexity is 42.50580219130297
At time: 875.1580312252045 and batch: 500, loss is 3.7882311296463014 and perplexity is 44.178185637744996
At time: 876.3818397521973 and batch: 550, loss is 3.7469634580612183 and perplexity is 42.39216078768207
At time: 877.604873418808 and batch: 600, loss is 3.7118815565109253 and perplexity is 40.93074763447883
At time: 878.8287522792816 and batch: 650, loss is 3.733469638824463 and perplexity is 41.82397078103823
At time: 880.0516002178192 and batch: 700, loss is 3.7693252325057984 and perplexity is 43.350803251697194
At time: 881.2740688323975 and batch: 750, loss is 3.710610480308533 and perplexity is 40.878754585778104
At time: 882.4971299171448 and batch: 800, loss is 3.669868187904358 and perplexity is 39.24673232530984
At time: 883.7199065685272 and batch: 850, loss is 3.664415135383606 and perplexity is 39.03330028960264
At time: 884.9414336681366 and batch: 900, loss is 3.6404882144927977 and perplexity is 38.11043825254373
At time: 886.1641671657562 and batch: 950, loss is 3.749323534965515 and perplexity is 42.49232770159653
At time: 887.3872272968292 and batch: 1000, loss is 3.7141889095306397 and perplexity is 41.025298357632664
At time: 888.6099050045013 and batch: 1050, loss is 3.652558946609497 and perplexity is 38.57324674284202
At time: 889.8340699672699 and batch: 1100, loss is 3.676416292190552 and perplexity is 39.504567265226456
At time: 891.0578870773315 and batch: 1150, loss is 3.6469105863571167 and perplexity is 38.35598531217411
At time: 892.2812080383301 and batch: 1200, loss is 3.6983734655380247 and perplexity is 40.38156890061938
At time: 893.5190675258636 and batch: 1250, loss is 3.671926984786987 and perplexity is 39.327616609060215
At time: 894.7392930984497 and batch: 1300, loss is 3.678243794441223 and perplexity is 39.576827958994556
At time: 895.9621512889862 and batch: 1350, loss is 3.546081943511963 and perplexity is 34.67718380702569
At time: 897.1863918304443 and batch: 1400, loss is 3.5790922498703 and perplexity is 35.84099141131839
At time: 898.4113593101501 and batch: 1450, loss is 3.491006336212158 and perplexity is 32.81895799959956
At time: 899.6341726779938 and batch: 1500, loss is 3.488933482170105 and perplexity is 32.75099954816272
At time: 900.8575484752655 and batch: 1550, loss is 3.501924548149109 and perplexity is 33.17924560775057
At time: 902.0812466144562 and batch: 1600, loss is 3.6025883102416993 and perplexity is 36.69308472674329
At time: 903.304093837738 and batch: 1650, loss is 3.530282301902771 and perplexity is 34.13360223561402
At time: 904.5285103321075 and batch: 1700, loss is 3.5636119174957277 and perplexity is 35.29043335710446
At time: 905.753525018692 and batch: 1750, loss is 3.5589215898513795 and perplexity is 35.125297235943755
At time: 906.9766845703125 and batch: 1800, loss is 3.490413589477539 and perplexity is 32.799510433721686
At time: 908.1997621059418 and batch: 1850, loss is 3.518221526145935 and perplexity is 33.72439713904596
At time: 909.4224057197571 and batch: 1900, loss is 3.5988717889785766 and perplexity is 36.55696719567329
At time: 910.646151304245 and batch: 1950, loss is 3.536247091293335 and perplexity is 34.33781040800586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375353436137354 and perplexity of 79.46792142458665
finished 18 epochs...
Completing Train Step...
At time: 914.6049313545227 and batch: 50, loss is 3.765437569618225 and perplexity is 43.18259711897339
At time: 915.8615062236786 and batch: 100, loss is 3.7422636938095093 and perplexity is 42.19339506772969
At time: 917.0863482952118 and batch: 150, loss is 3.7169585180282594 and perplexity is 41.13907986496386
At time: 918.3125267028809 and batch: 200, loss is 3.715690007209778 and perplexity is 41.08692758195366
At time: 919.5375430583954 and batch: 250, loss is 3.717790598869324 and perplexity is 41.17332515058571
At time: 920.763072013855 and batch: 300, loss is 3.7131486463546755 and perplexity is 40.98264344048464
At time: 921.9880602359772 and batch: 350, loss is 3.7407325887680054 and perplexity is 42.12884197921385
At time: 923.2118451595306 and batch: 400, loss is 3.7242597579956054 and perplexity is 41.44054535582746
At time: 924.4367754459381 and batch: 450, loss is 3.7463348627090456 and perplexity is 42.36552164593988
At time: 925.6619098186493 and batch: 500, loss is 3.7849346685409544 and perplexity is 44.03279373811674
At time: 926.8873753547668 and batch: 550, loss is 3.743728060722351 and perplexity is 42.255226940632554
At time: 928.111670255661 and batch: 600, loss is 3.7089275312423706 and perplexity is 40.8100155822672
At time: 929.3364813327789 and batch: 650, loss is 3.7307262992858887 and perplexity is 41.70939066627399
At time: 930.5607867240906 and batch: 700, loss is 3.76681351184845 and perplexity is 43.2420547737287
At time: 931.78595662117 and batch: 750, loss is 3.7084595727920533 and perplexity is 40.79092265831387
At time: 933.0105929374695 and batch: 800, loss is 3.6678283405303955 and perplexity is 39.16675657832962
At time: 934.2355301380157 and batch: 850, loss is 3.6623640489578246 and perplexity is 38.953321666797855
At time: 935.4595100879669 and batch: 900, loss is 3.6386947679519652 and perplexity is 38.042150472435296
At time: 936.7319693565369 and batch: 950, loss is 3.7475791549682618 and perplexity is 42.41826954667823
At time: 937.9583463668823 and batch: 1000, loss is 3.712561993598938 and perplexity is 40.95860791071709
At time: 939.183268070221 and batch: 1050, loss is 3.6509124565124513 and perplexity is 38.509788530064384
At time: 940.4078598022461 and batch: 1100, loss is 3.6748360919952394 and perplexity is 39.44219143644616
At time: 941.634060382843 and batch: 1150, loss is 3.645398669242859 and perplexity is 38.29803805830728
At time: 942.859405040741 and batch: 1200, loss is 3.69683376789093 and perplexity is 40.31944133510399
At time: 944.0840842723846 and batch: 1250, loss is 3.670633497238159 and perplexity is 39.276779712185856
At time: 945.3091142177582 and batch: 1300, loss is 3.6771472787857054 and perplexity is 39.5334551313798
At time: 946.5333659648895 and batch: 1350, loss is 3.5450835704803465 and perplexity is 34.64258031836954
At time: 947.7580828666687 and batch: 1400, loss is 3.578329882621765 and perplexity is 35.81367782612567
At time: 948.9834141731262 and batch: 1450, loss is 3.490424437522888 and perplexity is 32.79986624622823
At time: 950.2080335617065 and batch: 1500, loss is 3.4885247278213503 and perplexity is 32.73761517031902
At time: 951.4331541061401 and batch: 1550, loss is 3.5016821575164796 and perplexity is 33.17120424403253
At time: 952.659018278122 and batch: 1600, loss is 3.6026275873184206 and perplexity is 36.69452595215061
At time: 953.8822646141052 and batch: 1650, loss is 3.5303081607818605 and perplexity is 34.134484903719475
At time: 955.1070337295532 and batch: 1700, loss is 3.5638490390777586 and perplexity is 35.298802472702405
At time: 956.3309094905853 and batch: 1750, loss is 3.5592146825790407 and perplexity is 35.13559371395825
At time: 957.5553014278412 and batch: 1800, loss is 3.490711145401001 and perplexity is 32.80927157450851
At time: 958.7791221141815 and batch: 1850, loss is 3.518610510826111 and perplexity is 33.737517964615854
At time: 960.0042290687561 and batch: 1900, loss is 3.599227228164673 and perplexity is 36.56996328386215
At time: 961.2280111312866 and batch: 1950, loss is 3.5364946126937866 and perplexity is 34.34631080289791
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375239598473837 and perplexity of 79.45887549698051
finished 19 epochs...
Completing Train Step...
At time: 965.216917514801 and batch: 50, loss is 3.7636245584487913 and perplexity is 43.10437751600418
At time: 966.4422335624695 and batch: 100, loss is 3.7400841236114504 and perplexity is 42.10153174892771
At time: 967.6990747451782 and batch: 150, loss is 3.7146548938751223 and perplexity is 41.04441995923253
At time: 968.9238216876984 and batch: 200, loss is 3.7131694078445436 and perplexity is 40.98349431005383
At time: 970.1500098705292 and batch: 250, loss is 3.715173349380493 and perplexity is 41.065705181968816
At time: 971.3754994869232 and batch: 300, loss is 3.7104754114151 and perplexity is 40.873233510502445
At time: 972.6009242534637 and batch: 350, loss is 3.7380802726745603 and perplexity is 42.017251026292485
At time: 973.8266098499298 and batch: 400, loss is 3.7214766550064087 and perplexity is 41.3253723936223
At time: 975.0514435768127 and batch: 450, loss is 3.743555717468262 and perplexity is 42.24794516481982
At time: 976.2758779525757 and batch: 500, loss is 3.7821599197387696 and perplexity is 43.910783149085226
At time: 977.5016984939575 and batch: 550, loss is 3.740981116294861 and perplexity is 42.13931345729161
At time: 978.7270212173462 and batch: 600, loss is 3.706399736404419 and perplexity is 40.70698650858273
At time: 979.9528679847717 and batch: 650, loss is 3.7283462476730347 and perplexity is 41.61023820454109
At time: 981.1790335178375 and batch: 700, loss is 3.7646084880828856 and perplexity is 43.14681006229793
At time: 982.4045269489288 and batch: 750, loss is 3.7065279388427737 and perplexity is 40.71220557805277
At time: 983.6298787593842 and batch: 800, loss is 3.6659912872314453 and perplexity is 39.09487120779311
At time: 984.8550617694855 and batch: 850, loss is 3.660516285896301 and perplexity is 38.881411614727064
At time: 986.0804142951965 and batch: 900, loss is 3.6370281648635863 and perplexity is 37.978802109920515
At time: 987.3058934211731 and batch: 950, loss is 3.7459411096572874 and perplexity is 42.34884337627774
At time: 988.5321388244629 and batch: 1000, loss is 3.711015830039978 and perplexity is 40.895328136786546
At time: 989.7563188076019 and batch: 1050, loss is 3.6493763875961305 and perplexity is 38.45068024974751
At time: 990.9807960987091 and batch: 1100, loss is 3.673366599082947 and perplexity is 39.384273980752624
At time: 992.2061941623688 and batch: 1150, loss is 3.643981924057007 and perplexity is 38.2438179143936
At time: 993.4305927753448 and batch: 1200, loss is 3.695425591468811 and perplexity is 40.262704405641635
At time: 994.6565525531769 and batch: 1250, loss is 3.6694331979751587 and perplexity is 39.229664104515564
At time: 995.8821885585785 and batch: 1300, loss is 3.676084361076355 and perplexity is 39.4914566462298
At time: 997.1075491905212 and batch: 1350, loss is 3.5440931224823 and perplexity is 34.60828563040212
At time: 998.3337161540985 and batch: 1400, loss is 3.577527890205383 and perplexity is 35.784967042560595
At time: 999.5597679615021 and batch: 1450, loss is 3.4897545099258425 and perplexity is 32.77790006934606
At time: 1000.7844724655151 and batch: 1500, loss is 3.487965393066406 and perplexity is 32.71930900447493
At time: 1002.0106148719788 and batch: 1550, loss is 3.5012464475631715 and perplexity is 33.15675436838611
At time: 1003.2375123500824 and batch: 1600, loss is 3.6024162912368776 and perplexity is 36.68677336167768
At time: 1004.4638741016388 and batch: 1650, loss is 3.5300965309143066 and perplexity is 34.12726179154038
At time: 1005.6899216175079 and batch: 1700, loss is 3.56380841255188 and perplexity is 35.297368434120465
At time: 1006.9160003662109 and batch: 1750, loss is 3.5592276525497435 and perplexity is 35.13604942453462
At time: 1008.1400408744812 and batch: 1800, loss is 3.4907362556457517 and perplexity is 32.81009543369144
At time: 1009.3659451007843 and batch: 1850, loss is 3.5187329196929933 and perplexity is 33.74164798873195
At time: 1010.5896949768066 and batch: 1900, loss is 3.5993420314788818 and perplexity is 36.57416187784928
At time: 1011.8151228427887 and batch: 1950, loss is 3.5365480279922483 and perplexity is 34.34814547033972
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.375223984829215 and perplexity of 79.45763486402183
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f8261144b38>
ELAPSED
5253.535824775696


RESULTS SO FAR:
[{'best_accuracy': -78.0513610743167, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}}, {'best_accuracy': -78.42215966096434, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.02990420607447708, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.45043527467939715}}, {'best_accuracy': -79.59315869934208, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.9149200001362663, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.10734533781315092}}, {'best_accuracy': -80.12467139230405, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.46354086461744826, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.20663157340468064}}, {'best_accuracy': -79.45763486402183, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.45994889588664123, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.6843673700358436}}]
SETTINGS FOR THIS RUN
{'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.4921000806491009, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5501205754920423}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 300 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.8506169319152832 and batch: 50, loss is 7.528156499862671 and perplexity is 1859.6740322355945
At time: 3.1440346240997314 and batch: 100, loss is 6.677096977233886 and perplexity is 794.010731766005
At time: 4.437025308609009 and batch: 150, loss is 6.312588529586792 and perplexity is 551.4706008112482
At time: 5.730957746505737 and batch: 200, loss is 6.170503988265991 and perplexity is 478.42716701652654
At time: 7.0249152183532715 and batch: 250, loss is 6.102569465637207 and perplexity is 447.00485937397934
At time: 8.365259885787964 and batch: 300, loss is 6.025213603973389 and perplexity is 413.7300069585384
At time: 9.660216569900513 and batch: 350, loss is 5.97083963394165 and perplexity is 391.83453024087356
At time: 10.955887079238892 and batch: 400, loss is 5.922704086303711 and perplexity is 373.42011007173073
At time: 12.25776982307434 and batch: 450, loss is 5.849053258895874 and perplexity is 346.90579498520924
At time: 13.561673641204834 and batch: 500, loss is 5.830206689834594 and perplexity is 340.4290350215081
At time: 14.864997148513794 and batch: 550, loss is 5.7733230304718015 and perplexity is 321.60466103628056
At time: 16.167983293533325 and batch: 600, loss is 5.80895736694336 and perplexity is 333.2714646187614
At time: 17.470478773117065 and batch: 650, loss is 5.891516666412354 and perplexity is 361.95383150469553
At time: 18.773914337158203 and batch: 700, loss is 5.790646924972534 and perplexity is 327.2246457119667
At time: 20.076969385147095 and batch: 750, loss is 5.739343128204346 and perplexity is 310.86014863761824
At time: 21.379560232162476 and batch: 800, loss is 5.736506357192993 and perplexity is 309.9795591852223
At time: 22.68337368965149 and batch: 850, loss is 5.767659158706665 and perplexity is 319.7882822011994
At time: 23.98605489730835 and batch: 900, loss is 5.7644085025787355 and perplexity is 318.75044819663435
At time: 25.2892484664917 and batch: 950, loss is 5.795783538818359 and perplexity is 328.9097966374178
At time: 26.593185901641846 and batch: 1000, loss is 5.765827646255493 and perplexity is 319.2031220082725
At time: 27.8969304561615 and batch: 1050, loss is 5.667234296798706 and perplexity is 289.2334931832037
At time: 29.201066732406616 and batch: 1100, loss is 5.751928462982177 and perplexity is 314.79714995187646
At time: 30.50278639793396 and batch: 1150, loss is 5.666696767807007 and perplexity is 289.07806357295067
At time: 31.80375385284424 and batch: 1200, loss is 5.741951484680175 and perplexity is 311.67204111157986
At time: 33.10689306259155 and batch: 1250, loss is 5.67483380317688 and perplexity is 291.43989813490987
At time: 34.409919023513794 and batch: 1300, loss is 5.689079504013062 and perplexity is 295.6213770689043
At time: 35.713797092437744 and batch: 1350, loss is 5.668729162216186 and perplexity is 289.66618165468185
At time: 37.01815056800842 and batch: 1400, loss is 5.676666240692139 and perplexity is 291.97443313912
At time: 38.32107186317444 and batch: 1450, loss is 5.649135131835937 and perplexity is 284.0456974797427
At time: 39.62467002868652 and batch: 1500, loss is 5.630571393966675 and perplexity is 278.82138898480775
At time: 40.92802619934082 and batch: 1550, loss is 5.611540374755859 and perplexity is 273.5653067122337
At time: 42.231560468673706 and batch: 1600, loss is 5.6331032943725585 and perplexity is 279.5282314224725
At time: 43.53565430641174 and batch: 1650, loss is 5.607074785232544 and perplexity is 272.34639993886293
At time: 44.83938932418823 and batch: 1700, loss is 5.6187837696075436 and perplexity is 275.55404214928296
At time: 46.14266848564148 and batch: 1750, loss is 5.638267574310302 and perplexity is 280.97552736415025
At time: 47.44668793678284 and batch: 1800, loss is 5.6387990379333495 and perplexity is 281.1248953242136
At time: 48.75132703781128 and batch: 1850, loss is 5.603667831420898 and perplexity is 271.42010714786306
At time: 50.05587124824524 and batch: 1900, loss is 5.593155813217163 and perplexity is 268.58187793515043
At time: 51.358806133270264 and batch: 1950, loss is 5.529451293945312 and perplexity is 252.00559608347436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.077830895712209 and perplexity of 160.4256981832522
finished 1 epochs...
Completing Train Step...
At time: 55.31291484832764 and batch: 50, loss is 5.3380269527435305 and perplexity is 208.10171045250365
At time: 56.5676703453064 and batch: 100, loss is 5.262920141220093 and perplexity is 193.04438589995965
At time: 57.79255795478821 and batch: 150, loss is 5.169562788009643 and perplexity is 175.83794221882653
At time: 59.017505168914795 and batch: 200, loss is 5.134490079879761 and perplexity is 169.77772472045032
At time: 60.24117970466614 and batch: 250, loss is 5.139534149169922 and perplexity is 170.6362587601784
At time: 61.46572494506836 and batch: 300, loss is 5.141628093719483 and perplexity is 170.99393597160102
At time: 62.688496112823486 and batch: 350, loss is 5.112966775894165 and perplexity is 166.1625915057883
At time: 63.913222551345825 and batch: 400, loss is 5.077354373931885 and perplexity is 160.34927005522428
At time: 65.13867211341858 and batch: 450, loss is 5.033742122650146 and perplexity is 153.5063789206534
At time: 66.3628945350647 and batch: 500, loss is 5.022152376174927 and perplexity is 151.73754885204846
At time: 67.58694887161255 and batch: 550, loss is 4.9731826496124265 and perplexity is 144.48600470544991
At time: 68.81103229522705 and batch: 600, loss is 4.968297166824341 and perplexity is 143.78184230356445
At time: 70.03432703018188 and batch: 650, loss is 5.034301662445069 and perplexity is 153.5922958831721
At time: 71.25748610496521 and batch: 700, loss is 5.009539165496826 and perplexity is 149.83567078951268
At time: 72.48205709457397 and batch: 750, loss is 4.961747627258301 and perplexity is 142.84321458352974
At time: 73.70670509338379 and batch: 800, loss is 4.941029863357544 and perplexity is 139.9142679654098
At time: 74.93215131759644 and batch: 850, loss is 4.940635232925415 and perplexity is 139.85906443059545
At time: 76.18458700180054 and batch: 900, loss is 4.950017223358154 and perplexity is 141.17739544938235
At time: 77.40856885910034 and batch: 950, loss is 4.998054656982422 and perplexity is 148.12472524215937
At time: 78.63385248184204 and batch: 1000, loss is 4.973679456710816 and perplexity is 144.55780421198094
At time: 79.85698795318604 and batch: 1050, loss is 4.881152944564819 and perplexity is 131.78251426503465
At time: 81.08113145828247 and batch: 1100, loss is 4.957634477615357 and perplexity is 142.25688572226736
At time: 82.30552840232849 and batch: 1150, loss is 4.868908205032349 and perplexity is 130.17871081927728
At time: 83.53002071380615 and batch: 1200, loss is 4.943844223022461 and perplexity is 140.3085916617971
At time: 84.75459241867065 and batch: 1250, loss is 4.890842685699463 and perplexity is 133.06565934653312
At time: 85.97926640510559 and batch: 1300, loss is 4.921037845611572 and perplexity is 137.14487455723872
At time: 87.20408654212952 and batch: 1350, loss is 4.833034229278565 and perplexity is 125.59145638129705
At time: 88.42901968955994 and batch: 1400, loss is 4.849387464523315 and perplexity is 127.66216828462902
At time: 89.65379810333252 and batch: 1450, loss is 4.790221939086914 and perplexity is 120.32807120219002
At time: 90.87921214103699 and batch: 1500, loss is 4.767084770202636 and perplexity is 117.57598085842336
At time: 92.10391855239868 and batch: 1550, loss is 4.7650736045837405 and perplexity is 117.33975371369284
At time: 93.32966256141663 and batch: 1600, loss is 4.834820327758789 and perplexity is 125.81597553764334
At time: 94.55451083183289 and batch: 1650, loss is 4.787507705688476 and perplexity is 120.00191556406058
At time: 95.77918744087219 and batch: 1700, loss is 4.814753675460816 and perplexity is 123.31643270525106
At time: 97.00485181808472 and batch: 1750, loss is 4.826545610427856 and perplexity is 124.77917941762621
At time: 98.22868180274963 and batch: 1800, loss is 4.776256370544433 and perplexity is 118.65930106071416
At time: 99.45287442207336 and batch: 1850, loss is 4.7775529098510745 and perplexity is 118.81324728573837
At time: 100.67688846588135 and batch: 1900, loss is 4.851854333877563 and perplexity is 127.97748293538925
At time: 101.90153050422668 and batch: 1950, loss is 4.769260730743408 and perplexity is 117.83210010494469
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.637617528161337 and perplexity of 103.29794972563937
finished 2 epochs...
Completing Train Step...
At time: 105.85343980789185 and batch: 50, loss is 4.7113653087615965 and perplexity is 111.20388394412349
At time: 107.10485792160034 and batch: 100, loss is 4.656239280700683 and perplexity is 105.23956057430637
At time: 108.3282961845398 and batch: 150, loss is 4.6068290424346925 and perplexity is 100.16602331100802
At time: 109.55305504798889 and batch: 200, loss is 4.594035940170288 and perplexity is 98.89275104813814
At time: 110.77703166007996 and batch: 250, loss is 4.603688888549804 and perplexity is 99.8519799141243
At time: 112.00008511543274 and batch: 300, loss is 4.626136951446533 and perplexity is 102.11881123547944
At time: 113.22350144386292 and batch: 350, loss is 4.6297816467285156 and perplexity is 102.49168227288443
At time: 114.44817471504211 and batch: 400, loss is 4.59413293838501 and perplexity is 98.90234393367759
At time: 115.67153739929199 and batch: 450, loss is 4.595330038070679 and perplexity is 99.02081079268496
At time: 116.89528441429138 and batch: 500, loss is 4.6037601852417 and perplexity is 99.8590992837621
At time: 118.11923241615295 and batch: 550, loss is 4.558809432983399 and perplexity is 95.46974900716585
At time: 119.34228849411011 and batch: 600, loss is 4.530875101089477 and perplexity is 92.83976972767766
At time: 120.56603002548218 and batch: 650, loss is 4.591215562820435 and perplexity is 98.6142291261033
At time: 121.78972601890564 and batch: 700, loss is 4.613842849731445 and perplexity is 100.87103802468938
At time: 123.01407217979431 and batch: 750, loss is 4.576988458633423 and perplexity is 97.2211673291146
At time: 124.23867726325989 and batch: 800, loss is 4.547759914398194 and perplexity is 94.42066087433543
At time: 125.4635009765625 and batch: 850, loss is 4.54626874923706 and perplexity is 94.27996899783068
At time: 126.68708062171936 and batch: 900, loss is 4.545633821487427 and perplexity is 94.22012702895306
At time: 127.91078281402588 and batch: 950, loss is 4.607378396987915 and perplexity is 100.22106508933364
At time: 129.13467121124268 and batch: 1000, loss is 4.588289337158203 and perplexity is 98.32608343344452
At time: 130.35901045799255 and batch: 1050, loss is 4.51861198425293 and perplexity is 91.70821714577296
At time: 131.5832917690277 and batch: 1100, loss is 4.587191133499146 and perplexity is 98.218160640287
At time: 132.80775475502014 and batch: 1150, loss is 4.5189853858947755 and perplexity is 91.74246753880448
At time: 134.03253483772278 and batch: 1200, loss is 4.590737028121948 and perplexity is 98.56705008500637
At time: 135.25642490386963 and batch: 1250, loss is 4.5628003406524655 and perplexity is 95.8515212628359
At time: 136.4798231124878 and batch: 1300, loss is 4.5729552841186525 and perplexity is 96.82984705667224
At time: 137.70295810699463 and batch: 1350, loss is 4.463388433456421 and perplexity is 86.78106332933639
At time: 138.92652940750122 and batch: 1400, loss is 4.486020278930664 and perplexity is 88.76747220819429
At time: 140.1503574848175 and batch: 1450, loss is 4.425089626312256 and perplexity is 83.5202925024127
At time: 141.3742904663086 and batch: 1500, loss is 4.418011894226074 and perplexity is 82.93124526657174
At time: 142.59844183921814 and batch: 1550, loss is 4.423672895431519 and perplexity is 83.40205050317941
At time: 143.82385635375977 and batch: 1600, loss is 4.512519435882568 and perplexity is 91.15117901080735
At time: 145.04723072052002 and batch: 1650, loss is 4.455029182434082 and perplexity is 86.05866220973142
At time: 146.27101516723633 and batch: 1700, loss is 4.4889945220947265 and perplexity is 89.03188126910534
At time: 147.49618077278137 and batch: 1750, loss is 4.499894428253174 and perplexity is 90.00762853634666
At time: 148.71944165229797 and batch: 1800, loss is 4.4472628021240235 and perplexity is 85.39288658981216
At time: 149.94413304328918 and batch: 1850, loss is 4.470262222290039 and perplexity is 87.37963289700967
At time: 151.1688265800476 and batch: 1900, loss is 4.552661027908325 and perplexity is 94.88456314120327
At time: 152.3927357196808 and batch: 1950, loss is 4.480778064727783 and perplexity is 88.3033516771174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.535355820766715 and perplexity of 93.25669206925626
finished 3 epochs...
Completing Train Step...
At time: 156.3729386329651 and batch: 50, loss is 4.436942987442016 and perplexity is 84.51617933390827
At time: 157.59890699386597 and batch: 100, loss is 4.3870876598358155 and perplexity is 80.40590830261111
At time: 158.82508540153503 and batch: 150, loss is 4.343541955947876 and perplexity is 76.979715797468
At time: 160.05014562606812 and batch: 200, loss is 4.339162693023682 and perplexity is 76.64333846214303
At time: 161.2768259048462 and batch: 250, loss is 4.340519371032715 and perplexity is 76.7473893597964
At time: 162.50257515907288 and batch: 300, loss is 4.364786739349365 and perplexity is 78.63262890793766
At time: 163.72836995124817 and batch: 350, loss is 4.3717954730987545 and perplexity is 79.18567989760768
At time: 164.95457339286804 and batch: 400, loss is 4.340175495147705 and perplexity is 76.72100232055136
At time: 166.1797914505005 and batch: 450, loss is 4.3492394542694095 and perplexity is 77.4195594133169
At time: 167.40524053573608 and batch: 500, loss is 4.364437227249145 and perplexity is 78.60515065493293
At time: 168.65835618972778 and batch: 550, loss is 4.323491888046265 and perplexity is 75.45163749647419
At time: 169.88367772102356 and batch: 600, loss is 4.297160711288452 and perplexity is 73.49083549401568
At time: 171.10897207260132 and batch: 650, loss is 4.351908283233643 and perplexity is 77.62645493745737
At time: 172.33568167686462 and batch: 700, loss is 4.3891668796539305 and perplexity is 80.57326378477305
At time: 173.56014227867126 and batch: 750, loss is 4.352290878295898 and perplexity is 77.6561601179822
At time: 174.78438520431519 and batch: 800, loss is 4.322200789451599 and perplexity is 75.35428485279135
At time: 176.00993943214417 and batch: 850, loss is 4.318811655044556 and perplexity is 75.09933133318926
At time: 177.23567652702332 and batch: 900, loss is 4.313460960388183 and perplexity is 74.69857087190195
At time: 178.4613778591156 and batch: 950, loss is 4.385711193084717 and perplexity is 80.2953083792617
At time: 179.68661665916443 and batch: 1000, loss is 4.367205362319947 and perplexity is 78.82304176608582
At time: 180.91270112991333 and batch: 1050, loss is 4.305394592285157 and perplexity is 74.09844836099458
At time: 182.1383397579193 and batch: 1100, loss is 4.3694679546356205 and perplexity is 79.00158808728128
At time: 183.3648829460144 and batch: 1150, loss is 4.306956701278686 and perplexity is 74.2142886676223
At time: 184.59085273742676 and batch: 1200, loss is 4.3810328674316406 and perplexity is 79.92053811047167
At time: 185.8167610168457 and batch: 1250, loss is 4.358532838821411 and perplexity is 78.14240277899873
At time: 187.04275107383728 and batch: 1300, loss is 4.364030876159668 and perplexity is 78.57321585513553
At time: 188.26806354522705 and batch: 1350, loss is 4.242544174194336 and perplexity is 69.58466232725681
At time: 189.49391841888428 and batch: 1400, loss is 4.274574584960938 and perplexity is 71.8495669208249
At time: 190.71968269348145 and batch: 1450, loss is 4.209374313354492 and perplexity is 67.31440890441677
At time: 191.9443655014038 and batch: 1500, loss is 4.210076632499695 and perplexity is 67.36170170791509
At time: 193.17103052139282 and batch: 1550, loss is 4.214854974746704 and perplexity is 67.68434921922815
At time: 194.39782691001892 and batch: 1600, loss is 4.31669732093811 and perplexity is 74.94071399968966
At time: 195.62395930290222 and batch: 1650, loss is 4.250062255859375 and perplexity is 70.10977695524018
At time: 196.85090947151184 and batch: 1700, loss is 4.287227954864502 and perplexity is 72.76448224242723
At time: 198.07667350769043 and batch: 1750, loss is 4.300000438690185 and perplexity is 73.69982603097904
At time: 199.30241441726685 and batch: 1800, loss is 4.248626852035523 and perplexity is 70.00921330529967
At time: 200.52749943733215 and batch: 1850, loss is 4.278864326477051 and perplexity is 72.1584450209032
At time: 201.75270462036133 and batch: 1900, loss is 4.359980316162109 and perplexity is 78.25559403749686
At time: 202.97784161567688 and batch: 1950, loss is 4.293387784957885 and perplexity is 73.21408239854311
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.487532646711482 and perplexity of 88.90182284132321
finished 4 epochs...
Completing Train Step...
At time: 206.95933938026428 and batch: 50, loss is 4.247859168052673 and perplexity is 69.95548897788458
At time: 208.18408584594727 and batch: 100, loss is 4.205063643455506 and perplexity is 67.02486322446624
At time: 209.40601062774658 and batch: 150, loss is 4.162454385757446 and perplexity is 64.22897197417491
At time: 210.62902903556824 and batch: 200, loss is 4.1704353952407835 and perplexity is 64.74363504216838
At time: 211.85348057746887 and batch: 250, loss is 4.161478276252747 and perplexity is 64.16630805255407
At time: 213.0774314403534 and batch: 300, loss is 4.183084545135498 and perplexity is 65.5677884175858
At time: 214.3011155128479 and batch: 350, loss is 4.191970791816711 and perplexity is 66.15303643775526
At time: 215.52605485916138 and batch: 400, loss is 4.161506409645081 and perplexity is 64.1681132938668
At time: 216.75019788742065 and batch: 450, loss is 4.18200957775116 and perplexity is 65.49734305359168
At time: 217.97427797317505 and batch: 500, loss is 4.20056257724762 and perplexity is 66.72385780835904
At time: 219.19891834259033 and batch: 550, loss is 4.161053137779236 and perplexity is 64.13903428427268
At time: 220.4228265285492 and batch: 600, loss is 4.13767903804779 and perplexity is 62.65722751447603
At time: 221.64782857894897 and batch: 650, loss is 4.183927326202393 and perplexity is 65.62307100054728
At time: 222.8712821006775 and batch: 700, loss is 4.227237315177917 and perplexity is 68.52765011781952
At time: 224.09412026405334 and batch: 750, loss is 4.193982634544373 and perplexity is 66.28625991042732
At time: 225.31828236579895 and batch: 800, loss is 4.163051018714905 and perplexity is 64.2673045297743
At time: 226.54208946228027 and batch: 850, loss is 4.1609925365448 and perplexity is 64.13514749739275
At time: 227.76624608039856 and batch: 900, loss is 4.148493075370789 and perplexity is 63.338482028236825
At time: 229.02476024627686 and batch: 950, loss is 4.2283823204040525 and perplexity is 68.60615957363039
At time: 230.24863147735596 and batch: 1000, loss is 4.211195878982544 and perplexity is 67.43713826380527
At time: 231.47216653823853 and batch: 1050, loss is 4.151087498664856 and perplexity is 63.50302221257147
At time: 232.6960437297821 and batch: 1100, loss is 4.205627593994141 and perplexity is 67.06267259248827
At time: 233.91826057434082 and batch: 1150, loss is 4.153432717323303 and perplexity is 63.65212545664763
At time: 235.1395137310028 and batch: 1200, loss is 4.22796995639801 and perplexity is 68.57787469506319
At time: 236.36009430885315 and batch: 1250, loss is 4.209818825721741 and perplexity is 67.34433764302325
At time: 237.5806701183319 and batch: 1300, loss is 4.213051815032959 and perplexity is 67.56241349529586
At time: 238.80165839195251 and batch: 1350, loss is 4.089532032012939 and perplexity is 59.71194188759695
At time: 240.0215585231781 and batch: 1400, loss is 4.124693603515625 and perplexity is 61.84885607485902
At time: 241.24295806884766 and batch: 1450, loss is 4.052669291496277 and perplexity is 57.550872253308626
At time: 242.46340489387512 and batch: 1500, loss is 4.056300940513611 and perplexity is 57.76025679743223
At time: 243.68347597122192 and batch: 1550, loss is 4.067240400314331 and perplexity is 58.395591578437646
At time: 244.90753698349 and batch: 1600, loss is 4.169436144828796 and perplexity is 64.67897225071992
At time: 246.13150930404663 and batch: 1650, loss is 4.1009058046340945 and perplexity is 60.39496887102705
At time: 247.35527849197388 and batch: 1700, loss is 4.137706985473633 and perplexity is 62.65897864716522
At time: 248.57893323898315 and batch: 1750, loss is 4.154000101089477 and perplexity is 63.688250886836364
At time: 249.80401134490967 and batch: 1800, loss is 4.097953810691833 and perplexity is 60.21694617900903
At time: 251.0277168750763 and batch: 1850, loss is 4.129403176307679 and perplexity is 62.14082474885334
At time: 252.25081634521484 and batch: 1900, loss is 4.212468347549438 and perplexity is 67.52300452195847
At time: 253.47489023208618 and batch: 1950, loss is 4.146865663528442 and perplexity is 63.2354880620393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.466738678688227 and perplexity of 87.07228873884006
finished 5 epochs...
Completing Train Step...
At time: 257.4344849586487 and batch: 50, loss is 4.107313604354858 and perplexity is 60.7832102939064
At time: 258.6594135761261 and batch: 100, loss is 4.068726940155029 and perplexity is 58.4824635051327
At time: 259.9113256931305 and batch: 150, loss is 4.032480235099793 and perplexity is 56.40062472346185
At time: 261.1358232498169 and batch: 200, loss is 4.031030597686768 and perplexity is 56.318923500626994
At time: 262.36101245880127 and batch: 250, loss is 4.023607902526855 and perplexity is 55.90243295319187
At time: 263.5857014656067 and batch: 300, loss is 4.043307871818542 and perplexity is 57.01462830384781
At time: 264.8109538555145 and batch: 350, loss is 4.057257590293884 and perplexity is 57.81553957331755
At time: 266.03539204597473 and batch: 400, loss is 4.023672685623169 and perplexity is 55.90605460319965
At time: 267.2601728439331 and batch: 450, loss is 4.0534412384033205 and perplexity is 57.59531562289609
At time: 268.4855213165283 and batch: 500, loss is 4.076478977203369 and perplexity is 58.9375835032804
At time: 269.71030926704407 and batch: 550, loss is 4.037850599288941 and perplexity is 56.70433139651425
At time: 270.9365315437317 and batch: 600, loss is 4.0094049310684206 and perplexity is 55.114064136128576
At time: 272.1621744632721 and batch: 650, loss is 4.056997570991516 and perplexity is 57.8005083713377
At time: 273.38736033439636 and batch: 700, loss is 4.105783171653748 and perplexity is 60.6902568288486
At time: 274.6115050315857 and batch: 750, loss is 4.069180903434753 and perplexity is 58.5090184230946
At time: 275.8371901512146 and batch: 800, loss is 4.038070859909058 and perplexity is 56.716822503309935
At time: 277.063227891922 and batch: 850, loss is 4.03444920539856 and perplexity is 56.51178527837711
At time: 278.28869462013245 and batch: 900, loss is 4.019063954353332 and perplexity is 55.648991443697724
At time: 279.5151011943817 and batch: 950, loss is 4.105665011405945 and perplexity is 60.68308607671973
At time: 280.74039483070374 and batch: 1000, loss is 4.087206325531006 and perplexity is 59.57323080046036
At time: 281.96609926223755 and batch: 1050, loss is 4.031751260757447 and perplexity is 56.3595250972527
At time: 283.1909484863281 and batch: 1100, loss is 4.081558084487915 and perplexity is 59.237695317863896
At time: 284.4149122238159 and batch: 1150, loss is 4.0338386535644535 and perplexity is 56.477292435132625
At time: 285.64053893089294 and batch: 1200, loss is 4.111124510765076 and perplexity is 61.01529135838101
At time: 286.8656704425812 and batch: 1250, loss is 4.090278477668762 and perplexity is 59.75653024654279
At time: 288.0920865535736 and batch: 1300, loss is 4.092656211853027 and perplexity is 59.89878444555809
At time: 289.31734347343445 and batch: 1350, loss is 3.9696331596374512 and perplexity is 52.96509753985077
At time: 290.5434629917145 and batch: 1400, loss is 4.003858823776245 and perplexity is 54.80924169345133
At time: 291.7677674293518 and batch: 1450, loss is 3.930807728767395 and perplexity is 50.94811331050991
At time: 292.9926280975342 and batch: 1500, loss is 3.935611591339111 and perplexity is 51.19344985485887
At time: 294.21663308143616 and batch: 1550, loss is 3.9437956047058105 and perplexity is 51.614136838643326
At time: 295.4395070075989 and batch: 1600, loss is 4.053206110000611 and perplexity is 57.581774920294386
At time: 296.6625564098358 and batch: 1650, loss is 3.9860791206359862 and perplexity is 53.843361621466656
At time: 297.88810658454895 and batch: 1700, loss is 4.019485726356506 and perplexity is 55.67246758073418
At time: 299.1128807067871 and batch: 1750, loss is 4.036924858093261 and perplexity is 56.65186215118515
At time: 300.3388411998749 and batch: 1800, loss is 3.9820643424987794 and perplexity is 53.62762582584992
At time: 301.56395292282104 and batch: 1850, loss is 4.014814882278443 and perplexity is 55.41303651790772
At time: 302.78788328170776 and batch: 1900, loss is 4.099899506568908 and perplexity is 60.334224099504205
At time: 304.0123655796051 and batch: 1950, loss is 4.030061030387879 and perplexity is 56.26434497714354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.472102959211482 and perplexity of 87.54062393908563
Annealing...
finished 6 epochs...
Completing Train Step...
At time: 307.97037506103516 and batch: 50, loss is 4.032735753059387 and perplexity is 56.41503793735013
At time: 309.22265338897705 and batch: 100, loss is 4.025161104202271 and perplexity is 55.98932817114453
At time: 310.4486951828003 and batch: 150, loss is 3.9951632690429686 and perplexity is 54.3347110759354
At time: 311.6748101711273 and batch: 200, loss is 3.9853354787826536 and perplexity is 53.80333632832691
At time: 312.90099716186523 and batch: 250, loss is 3.9740548658370973 and perplexity is 53.19981217717288
At time: 314.1287257671356 and batch: 300, loss is 3.9857313728332517 and perplexity is 53.82464096599301
At time: 315.35443353652954 and batch: 350, loss is 4.0050094079971315 and perplexity is 54.872340635465
At time: 316.5797119140625 and batch: 400, loss is 3.9671899700164794 and perplexity is 52.83585171358919
At time: 317.80507016181946 and batch: 450, loss is 3.98536328792572 and perplexity is 53.80483257380887
At time: 319.0318329334259 and batch: 500, loss is 3.999063048362732 and perplexity is 54.54701816486337
At time: 320.2580420970917 and batch: 550, loss is 3.9491481494903566 and perplexity is 51.89114450420627
At time: 321.5116755962372 and batch: 600, loss is 3.9118369817733765 and perplexity is 49.99069968232788
At time: 322.73755168914795 and batch: 650, loss is 3.9537335872650146 and perplexity is 52.12963449100444
At time: 323.9630858898163 and batch: 700, loss is 4.000737881660461 and perplexity is 54.638451873914796
At time: 325.18801403045654 and batch: 750, loss is 3.949519715309143 and perplexity is 51.91042906232118
At time: 326.41455578804016 and batch: 800, loss is 3.911748514175415 and perplexity is 49.986277320827305
At time: 327.6400418281555 and batch: 850, loss is 3.9064172887802124 and perplexity is 49.720498303183575
At time: 328.8653173446655 and batch: 900, loss is 3.883873853683472 and perplexity is 48.612167209764685
At time: 330.09166383743286 and batch: 950, loss is 3.9697201824188233 and perplexity is 52.96970691051155
At time: 331.3179233074188 and batch: 1000, loss is 3.940746192932129 and perplexity is 51.45698381599724
At time: 332.5440263748169 and batch: 1050, loss is 3.8749653244018556 and perplexity is 48.18102755618239
At time: 333.77019810676575 and batch: 1100, loss is 3.9076200199127196 and perplexity is 49.780334670734554
At time: 334.9950397014618 and batch: 1150, loss is 3.8648310136795043 and perplexity is 47.69521191328264
At time: 336.220401763916 and batch: 1200, loss is 3.92255952835083 and perplexity is 50.52961137763999
At time: 337.44657492637634 and batch: 1250, loss is 3.8965117597579955 and perplexity is 49.2304217053898
At time: 338.6712839603424 and batch: 1300, loss is 3.9050918102264403 and perplexity is 49.65463850651624
At time: 339.89667081832886 and batch: 1350, loss is 3.7784111976623533 and perplexity is 43.746481979022406
At time: 341.12336111068726 and batch: 1400, loss is 3.795112352371216 and perplexity is 44.48323392159253
At time: 342.34957122802734 and batch: 1450, loss is 3.715416741371155 and perplexity is 41.07570146215891
At time: 343.57502579689026 and batch: 1500, loss is 3.7024681615829467 and perplexity is 40.54725814312465
At time: 344.80210995674133 and batch: 1550, loss is 3.705130968093872 and perplexity is 40.65537152473475
At time: 346.027640581131 and batch: 1600, loss is 3.804959373474121 and perplexity is 44.92342499325149
At time: 347.25440979003906 and batch: 1650, loss is 3.72536340713501 and perplexity is 41.48630642548354
At time: 348.4804003238678 and batch: 1700, loss is 3.7476725244522093 and perplexity is 42.42223030351979
At time: 349.7069571018219 and batch: 1750, loss is 3.75851900100708 and perplexity is 42.884866480534804
At time: 350.93348240852356 and batch: 1800, loss is 3.692215347290039 and perplexity is 40.13365853839916
At time: 352.1592240333557 and batch: 1850, loss is 3.7157277631759644 and perplexity is 41.08847888788749
At time: 353.38537764549255 and batch: 1900, loss is 3.79189932346344 and perplexity is 44.34053737192195
At time: 354.61158323287964 and batch: 1950, loss is 3.7178853654861452 and perplexity is 41.177227192202245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.409712822492732 and perplexity of 82.24584095684278
finished 7 epochs...
Completing Train Step...
At time: 358.567289352417 and batch: 50, loss is 3.9178681707382204 and perplexity is 50.293114081089925
At time: 359.8168349266052 and batch: 100, loss is 3.9000908946990966 and perplexity is 49.406939730360165
At time: 361.0415098667145 and batch: 150, loss is 3.866791615486145 and perplexity is 47.78881496109639
At time: 362.2660343647003 and batch: 200, loss is 3.8582279825210573 and perplexity is 47.3813164142774
At time: 363.4901382923126 and batch: 250, loss is 3.842766327857971 and perplexity is 46.654357339825275
At time: 364.7151038646698 and batch: 300, loss is 3.8572071599960327 and perplexity is 47.3329731783466
At time: 365.9405014514923 and batch: 350, loss is 3.8812563896179197 and perplexity is 48.48509298759964
At time: 367.16538548469543 and batch: 400, loss is 3.8452188062667845 and perplexity is 46.76891656347005
At time: 368.3894672393799 and batch: 450, loss is 3.875613408088684 and perplexity is 48.21226301465846
At time: 369.61454677581787 and batch: 500, loss is 3.8872438287734985 and perplexity is 48.77626535035534
At time: 370.8391091823578 and batch: 550, loss is 3.840681929588318 and perplexity is 46.55721235770296
At time: 372.0646958351135 and batch: 600, loss is 3.805718669891357 and perplexity is 44.95754814205173
At time: 373.29020595550537 and batch: 650, loss is 3.847564935684204 and perplexity is 46.87877131077794
At time: 374.51549768447876 and batch: 700, loss is 3.8957781744003297 and perplexity is 49.19432023225005
At time: 375.7406516075134 and batch: 750, loss is 3.84880551815033 and perplexity is 46.93696438168784
At time: 376.9664936065674 and batch: 800, loss is 3.8127516317367554 and perplexity is 45.274847331475925
At time: 378.1914551258087 and batch: 850, loss is 3.811725606918335 and perplexity is 45.2284180373408
At time: 379.41719603538513 and batch: 900, loss is 3.7888492727279663 and perplexity is 44.205502519558415
At time: 380.64294242858887 and batch: 950, loss is 3.878899827003479 and perplexity is 48.37096935266753
At time: 381.868200302124 and batch: 1000, loss is 3.852934169769287 and perplexity is 47.13115134499275
At time: 383.1228280067444 and batch: 1050, loss is 3.791793522834778 and perplexity is 44.335846363352985
At time: 384.3493778705597 and batch: 1100, loss is 3.823406066894531 and perplexity is 45.75980413951912
At time: 385.5748028755188 and batch: 1150, loss is 3.788726258277893 and perplexity is 44.20006493843313
At time: 386.79963183403015 and batch: 1200, loss is 3.8478572750091553 and perplexity is 46.89247782251605
At time: 388.0242829322815 and batch: 1250, loss is 3.8257665538787844 and perplexity is 45.86794714645911
At time: 389.24854016304016 and batch: 1300, loss is 3.8356565380096437 and perplexity is 46.323831042204446
At time: 390.47408986091614 and batch: 1350, loss is 3.709656558036804 and perplexity is 40.83977802459871
At time: 391.7004897594452 and batch: 1400, loss is 3.733450183868408 and perplexity is 41.82315710543967
At time: 392.92599415779114 and batch: 1450, loss is 3.655274987220764 and perplexity is 38.67815565144046
At time: 394.15203881263733 and batch: 1500, loss is 3.6458823108673095 and perplexity is 38.31656506350137
At time: 395.37659907341003 and batch: 1550, loss is 3.6527834272384645 and perplexity is 38.5819066614878
At time: 396.60122323036194 and batch: 1600, loss is 3.7560640573501587 and perplexity is 42.77971567205543
At time: 397.82804918289185 and batch: 1650, loss is 3.6805457782745363 and perplexity is 39.668038119009005
At time: 399.05249214172363 and batch: 1700, loss is 3.7044618797302244 and perplexity is 40.628178586981356
At time: 400.27809977531433 and batch: 1750, loss is 3.7194049739837647 and perplexity is 41.239848024075656
At time: 401.5040557384491 and batch: 1800, loss is 3.658950753211975 and perplexity is 38.82058911625857
At time: 402.7301027774811 and batch: 1850, loss is 3.688252511024475 and perplexity is 39.97493013593172
At time: 403.95681381225586 and batch: 1900, loss is 3.765834803581238 and perplexity is 43.19975412060642
At time: 405.18325996398926 and batch: 1950, loss is 3.697457709312439 and perplexity is 40.344606154515255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.415901787336483 and perplexity of 82.75643597258242
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 409.13552236557007 and batch: 50, loss is 3.87234272480011 and perplexity is 48.05483356299048
At time: 410.3929297924042 and batch: 100, loss is 3.882878475189209 and perplexity is 48.56380377791769
At time: 411.61994075775146 and batch: 150, loss is 3.867316164970398 and perplexity is 47.81388913508489
At time: 412.8736252784729 and batch: 200, loss is 3.872721109390259 and perplexity is 48.07302021204978
At time: 414.0984661579132 and batch: 250, loss is 3.8607644128799437 and perplexity is 47.50164836596954
At time: 415.31998085975647 and batch: 300, loss is 3.8736374139785767 and perplexity is 48.11708992860265
At time: 416.54192185401917 and batch: 350, loss is 3.8988144969940186 and perplexity is 49.34391705542856
At time: 417.76403880119324 and batch: 400, loss is 3.867834486961365 and perplexity is 47.8386785491915
At time: 418.9854085445404 and batch: 450, loss is 3.8941118478775025 and perplexity is 49.112414691314086
At time: 420.2102348804474 and batch: 500, loss is 3.9042231845855713 and perplexity is 49.61152594137191
At time: 421.43646574020386 and batch: 550, loss is 3.851792449951172 and perplexity is 47.07737148206121
At time: 422.66305327415466 and batch: 600, loss is 3.8022263479232787 and perplexity is 44.80081574833155
At time: 423.8944253921509 and batch: 650, loss is 3.833791570663452 and perplexity is 46.23751911943584
At time: 425.12220668792725 and batch: 700, loss is 3.879509835243225 and perplexity is 48.40048504402936
At time: 426.3485677242279 and batch: 750, loss is 3.834508190155029 and perplexity is 46.270665702204106
At time: 427.5739440917969 and batch: 800, loss is 3.7933043527603147 and perplexity is 44.40288091296342
At time: 428.79941272735596 and batch: 850, loss is 3.794202651977539 and perplexity is 44.44278590675896
At time: 430.0261745452881 and batch: 900, loss is 3.7674009704589846 and perplexity is 43.26746515418536
At time: 431.2521333694458 and batch: 950, loss is 3.867331142425537 and perplexity is 47.81460527082737
At time: 432.47730326652527 and batch: 1000, loss is 3.8326629781723023 and perplexity is 46.185365238323335
At time: 433.7033123970032 and batch: 1050, loss is 3.7718453502655027 and perplexity is 43.460190156917555
At time: 434.9285137653351 and batch: 1100, loss is 3.7969487142562866 and perplexity is 44.5649962865594
At time: 436.1541361808777 and batch: 1150, loss is 3.766463770866394 and perplexity is 43.22693389937488
At time: 437.37886476516724 and batch: 1200, loss is 3.8114978456497193 and perplexity is 45.218117928498586
At time: 438.6055965423584 and batch: 1250, loss is 3.780645213127136 and perplexity is 43.84432154315137
At time: 439.8308970928192 and batch: 1300, loss is 3.7912674617767332 and perplexity is 44.31252913478647
At time: 441.0574691295624 and batch: 1350, loss is 3.666994390487671 and perplexity is 39.13410707592694
At time: 442.2834117412567 and batch: 1400, loss is 3.6905759716033937 and perplexity is 40.067918295576405
At time: 443.50968766212463 and batch: 1450, loss is 3.61363872051239 and perplexity is 37.100806967129024
At time: 444.73494362831116 and batch: 1500, loss is 3.5932278776168824 and perplexity is 36.35122405732694
At time: 445.9609258174896 and batch: 1550, loss is 3.5943393087387085 and perplexity is 36.39164839933534
At time: 447.1869010925293 and batch: 1600, loss is 3.6908261966705322 and perplexity is 40.0779455476046
At time: 448.4143588542938 and batch: 1650, loss is 3.605588412284851 and perplexity is 36.80333302057549
At time: 449.6409697532654 and batch: 1700, loss is 3.62413453578949 and perplexity is 37.49226090418345
At time: 450.8666136264801 and batch: 1750, loss is 3.63898344039917 and perplexity is 38.05313377832173
At time: 452.0921902656555 and batch: 1800, loss is 3.5754021549224855 and perplexity is 35.70897846993031
At time: 453.3170337677002 and batch: 1850, loss is 3.6029755878448486 and perplexity is 36.70729788869041
At time: 454.54383969306946 and batch: 1900, loss is 3.686359529495239 and perplexity is 39.899329909043814
At time: 455.7701337337494 and batch: 1950, loss is 3.621603183746338 and perplexity is 37.397474812039015
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.386856150072674 and perplexity of 80.38729570440704
finished 9 epochs...
Completing Train Step...
At time: 459.7459738254547 and batch: 50, loss is 3.8581799936294554 and perplexity is 47.37904269197719
At time: 460.9701478481293 and batch: 100, loss is 3.848780574798584 and perplexity is 46.93579363107666
At time: 462.1942558288574 and batch: 150, loss is 3.8232274436950684 and perplexity is 45.75163110686528
At time: 463.41871094703674 and batch: 200, loss is 3.8230481910705567 and perplexity is 45.74343074190411
At time: 464.6416108608246 and batch: 250, loss is 3.8118648386001586 and perplexity is 45.23471570445757
At time: 465.8662140369415 and batch: 300, loss is 3.81769944190979 and perplexity is 45.499413779632725
At time: 467.09223341941833 and batch: 350, loss is 3.8431599283218385 and perplexity is 46.67272413086729
At time: 468.316609621048 and batch: 400, loss is 3.8124977064132692 and perplexity is 45.263352360715345
At time: 469.54073119163513 and batch: 450, loss is 3.842017560005188 and perplexity is 46.61943713205296
At time: 470.764931678772 and batch: 500, loss is 3.8536936044692993 and perplexity is 47.16695797145206
At time: 471.98886370658875 and batch: 550, loss is 3.8028781461715697 and perplexity is 44.83002636023701
At time: 473.21232748031616 and batch: 600, loss is 3.7598623991012574 and perplexity is 42.942516643323025
At time: 474.46133375167847 and batch: 650, loss is 3.793646788597107 and perplexity is 44.41808865433405
At time: 475.6824760437012 and batch: 700, loss is 3.8417414140701296 and perplexity is 46.60656514134999
At time: 476.90359354019165 and batch: 750, loss is 3.799027280807495 and perplexity is 44.657723934103316
At time: 478.12469387054443 and batch: 800, loss is 3.75774956703186 and perplexity is 42.85188209852131
At time: 479.3453269004822 and batch: 850, loss is 3.7584332609176636 and perplexity is 42.88118968587476
At time: 480.567898273468 and batch: 900, loss is 3.732453932762146 and perplexity is 41.781511487097184
At time: 481.7894079685211 and batch: 950, loss is 3.832287621498108 and perplexity is 46.168032506412835
At time: 483.0105080604553 and batch: 1000, loss is 3.7989739084243777 and perplexity is 44.655340508557465
At time: 484.2325212955475 and batch: 1050, loss is 3.741262369155884 and perplexity is 42.151166926595955
At time: 485.456027507782 and batch: 1100, loss is 3.7678012895584105 and perplexity is 43.28478941425506
At time: 486.67996096611023 and batch: 1150, loss is 3.739664840698242 and perplexity is 42.083882996214264
At time: 487.90447211265564 and batch: 1200, loss is 3.7879229831695556 and perplexity is 44.16457438272954
At time: 489.1287474632263 and batch: 1250, loss is 3.7585579919815064 and perplexity is 42.8865386358663
At time: 490.3524866104126 and batch: 1300, loss is 3.77011031627655 and perplexity is 43.38485062705129
At time: 491.5766246318817 and batch: 1350, loss is 3.64654972076416 and perplexity is 38.342146453925075
At time: 492.8003237247467 and batch: 1400, loss is 3.6723336029052733 and perplexity is 39.343611182143704
At time: 494.025958776474 and batch: 1450, loss is 3.5971295070648193 and perplexity is 36.49333010587952
At time: 495.249746799469 and batch: 1500, loss is 3.5792333126068114 and perplexity is 35.84604759625741
At time: 496.4746947288513 and batch: 1550, loss is 3.583048896789551 and perplexity is 35.98308247628587
At time: 497.6988892555237 and batch: 1600, loss is 3.6813876914978025 and perplexity is 39.701449227495914
At time: 498.9219219684601 and batch: 1650, loss is 3.599219255447388 and perplexity is 36.56967172304603
At time: 500.1462812423706 and batch: 1700, loss is 3.620412516593933 and perplexity is 37.35297336566007
At time: 501.3702726364136 and batch: 1750, loss is 3.636592049598694 and perplexity is 37.96224258577114
At time: 502.59469294548035 and batch: 1800, loss is 3.575315866470337 and perplexity is 35.70589733038563
At time: 503.819974899292 and batch: 1850, loss is 3.605433382987976 and perplexity is 36.797627867978974
At time: 505.0454480648041 and batch: 1900, loss is 3.6896814823150637 and perplexity is 40.032093996469854
At time: 506.27038979530334 and batch: 1950, loss is 3.626078653335571 and perplexity is 37.56522116513126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.388204033430233 and perplexity of 80.49572145866544
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 510.2368106842041 and batch: 50, loss is 3.847214765548706 and perplexity is 46.862358638857536
At time: 511.46373462677 and batch: 100, loss is 3.850052471160889 and perplexity is 46.995529076853074
At time: 512.690530538559 and batch: 150, loss is 3.8338705921173095 and perplexity is 46.24117301978576
At time: 513.9178907871246 and batch: 200, loss is 3.8427698469161986 and perplexity is 46.6545215195142
At time: 515.1439323425293 and batch: 250, loss is 3.838911280632019 and perplexity is 46.474848818210056
At time: 516.3702456951141 and batch: 300, loss is 3.8444943904876707 and perplexity is 46.73504869103111
At time: 517.5968987941742 and batch: 350, loss is 3.8736320304870606 and perplexity is 48.1168308913545
At time: 518.8235375881195 and batch: 400, loss is 3.8521566581726074 and perplexity is 47.09452057052849
At time: 520.0485515594482 and batch: 450, loss is 3.8782597255706786 and perplexity is 48.34001693327978
At time: 521.2755515575409 and batch: 500, loss is 3.8887415075302125 and perplexity is 48.849371257719675
At time: 522.5025546550751 and batch: 550, loss is 3.8429065704345704 and perplexity is 46.66090072592814
At time: 523.7301440238953 and batch: 600, loss is 3.797638120651245 and perplexity is 44.595730272876736
At time: 524.9564414024353 and batch: 650, loss is 3.8204206466674804 and perplexity is 45.6233956143546
At time: 526.1824674606323 and batch: 700, loss is 3.855052032470703 and perplexity is 47.23107442683604
At time: 527.4090480804443 and batch: 750, loss is 3.8107110691070556 and perplexity is 45.182555365738615
At time: 528.6346185207367 and batch: 800, loss is 3.7721322536468507 and perplexity is 43.472660821279945
At time: 529.8601052761078 and batch: 850, loss is 3.771110010147095 and perplexity is 43.4282438826696
At time: 531.0871953964233 and batch: 900, loss is 3.73680495262146 and perplexity is 41.96369973825643
At time: 532.3129663467407 and batch: 950, loss is 3.8507320642471314 and perplexity is 47.02747776832332
At time: 533.5373449325562 and batch: 1000, loss is 3.8195654153823853 and perplexity is 45.58439373928203
At time: 534.8060312271118 and batch: 1050, loss is 3.76276216506958 and perplexity is 43.06722061045689
At time: 536.0323214530945 and batch: 1100, loss is 3.782025156021118 and perplexity is 43.90486596742273
At time: 537.2592313289642 and batch: 1150, loss is 3.763347659111023 and perplexity is 43.09244359473878
At time: 538.4852440357208 and batch: 1200, loss is 3.8077072048187257 and perplexity is 45.04703674289673
At time: 539.7125153541565 and batch: 1250, loss is 3.7703508138656616 and perplexity is 43.39528583380179
At time: 540.9400954246521 and batch: 1300, loss is 3.7753149318695067 and perplexity is 43.61124072279602
At time: 542.1660592556 and batch: 1350, loss is 3.640468120574951 and perplexity is 38.10967247222218
At time: 543.3925075531006 and batch: 1400, loss is 3.6705257511138916 and perplexity is 39.2725480193765
At time: 544.6188387870789 and batch: 1450, loss is 3.600178699493408 and perplexity is 36.60477511402254
At time: 545.8452460765839 and batch: 1500, loss is 3.5794700050354002 and perplexity is 35.854533088504546
At time: 547.0716009140015 and batch: 1550, loss is 3.5863834381103517 and perplexity is 36.103269825128066
At time: 548.2988679409027 and batch: 1600, loss is 3.6793195724487306 and perplexity is 39.61942674943241
At time: 549.5265882015228 and batch: 1650, loss is 3.5935050868988037 and perplexity is 36.361302350878546
At time: 550.7540822029114 and batch: 1700, loss is 3.609379301071167 and perplexity is 36.943115144867164
At time: 551.9811074733734 and batch: 1750, loss is 3.6231156969070435 and perplexity is 37.45408178347238
At time: 553.2104918956757 and batch: 1800, loss is 3.557054738998413 and perplexity is 35.05978471491766
At time: 554.437641620636 and batch: 1850, loss is 3.5782672548294068 and perplexity is 35.81143496478065
At time: 555.6647686958313 and batch: 1900, loss is 3.6686537504196166 and perplexity is 39.19909855239448
At time: 556.8908832073212 and batch: 1950, loss is 3.6179518127441406 and perplexity is 37.26117175490854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.370866074672965 and perplexity of 79.11211904033331
finished 11 epochs...
Completing Train Step...
At time: 560.8498191833496 and batch: 50, loss is 3.8540538597106933 and perplexity is 47.183953176403904
At time: 562.0734486579895 and batch: 100, loss is 3.8463777017593386 and perplexity is 46.82314826843671
At time: 563.2987418174744 and batch: 150, loss is 3.8170516777038572 and perplexity is 45.46995043167669
At time: 564.5232820510864 and batch: 200, loss is 3.8190111112594605 and perplexity is 45.55913312356982
At time: 565.7738695144653 and batch: 250, loss is 3.8152525568008424 and perplexity is 45.388218038670566
At time: 566.9987738132477 and batch: 300, loss is 3.816772961616516 and perplexity is 45.457278990949995
At time: 568.222874879837 and batch: 350, loss is 3.8439426612854004 and perplexity is 46.70927071178462
At time: 569.4454431533813 and batch: 400, loss is 3.8232315254211424 and perplexity is 45.75181785287202
At time: 570.6699664592743 and batch: 450, loss is 3.852015662193298 and perplexity is 47.08788090057493
At time: 571.8932230472565 and batch: 500, loss is 3.8630417680740354 and perplexity is 47.60994976517332
At time: 573.1164176464081 and batch: 550, loss is 3.818912582397461 and perplexity is 45.5546444551648
At time: 574.3401510715485 and batch: 600, loss is 3.776258821487427 and perplexity is 43.65242435348196
At time: 575.5632002353668 and batch: 650, loss is 3.799041986465454 and perplexity is 44.6583806601455
At time: 576.7868661880493 and batch: 700, loss is 3.837316856384277 and perplexity is 46.40080723487771
At time: 578.0114290714264 and batch: 750, loss is 3.7957823181152346 and perplexity is 44.513046149973945
At time: 579.2360227108002 and batch: 800, loss is 3.7579372835159304 and perplexity is 42.85992685820801
At time: 580.4609501361847 and batch: 850, loss is 3.7572052907943725 and perplexity is 42.828565183360496
At time: 581.6857624053955 and batch: 900, loss is 3.723143849372864 and perplexity is 41.394327286301035
At time: 582.9104595184326 and batch: 950, loss is 3.8364112520217897 and perplexity is 46.358805482778365
At time: 584.1344003677368 and batch: 1000, loss is 3.8050190877914427 and perplexity is 44.92610764500227
At time: 585.3582954406738 and batch: 1050, loss is 3.7480424499511718 and perplexity is 42.43792627122227
At time: 586.5815353393555 and batch: 1100, loss is 3.768562455177307 and perplexity is 43.317748849981704
At time: 587.8064301013947 and batch: 1150, loss is 3.7508486986160277 and perplexity is 42.55718490158247
At time: 589.0311169624329 and batch: 1200, loss is 3.7966731643676757 and perplexity is 44.55271809850106
At time: 590.2538113594055 and batch: 1250, loss is 3.7608257293701173 and perplexity is 42.98390440126588
At time: 591.4766449928284 and batch: 1300, loss is 3.7664110803604127 and perplexity is 43.22465631035988
At time: 592.7007572650909 and batch: 1350, loss is 3.632739281654358 and perplexity is 37.81626426531136
At time: 593.9228601455688 and batch: 1400, loss is 3.663845992088318 and perplexity is 39.01109106916381
At time: 595.1454272270203 and batch: 1450, loss is 3.5937170219421386 and perplexity is 36.36900940173622
At time: 596.3692617416382 and batch: 1500, loss is 3.5762916469573973 and perplexity is 35.74075545244542
At time: 597.5925056934357 and batch: 1550, loss is 3.5839272356033325 and perplexity is 36.014701698426535
At time: 598.815904378891 and batch: 1600, loss is 3.6770961093902588 and perplexity is 39.53143228013529
At time: 600.0395061969757 and batch: 1650, loss is 3.592907733917236 and perplexity is 36.339588304626396
At time: 601.2635324001312 and batch: 1700, loss is 3.6109115076065064 and perplexity is 36.99976301436338
At time: 602.4930529594421 and batch: 1750, loss is 3.626376886367798 and perplexity is 37.57642602569233
At time: 603.7297251224518 and batch: 1800, loss is 3.561993999481201 and perplexity is 35.23338249349052
At time: 604.9513351917267 and batch: 1850, loss is 3.583929853439331 and perplexity is 36.01479597913253
At time: 606.1781256198883 and batch: 1900, loss is 3.67471435546875 and perplexity is 39.43739017331402
At time: 607.41490650177 and batch: 1950, loss is 3.623726692199707 and perplexity is 37.476973043647085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369826205941134 and perplexity of 79.02989557964648
finished 12 epochs...
Completing Train Step...
At time: 611.542017698288 and batch: 50, loss is 3.8489701557159424 and perplexity is 46.94469260540139
At time: 612.8102743625641 and batch: 100, loss is 3.8389749336242676 and perplexity is 46.47780717555479
At time: 614.0363631248474 and batch: 150, loss is 3.8084791135787963 and perplexity is 45.08182236911136
At time: 615.2634828090668 and batch: 200, loss is 3.809054985046387 and perplexity is 45.10779118095194
At time: 616.4955940246582 and batch: 250, loss is 3.8045740604400633 and perplexity is 44.90611874644242
At time: 617.7491092681885 and batch: 300, loss is 3.8054098749160765 and perplexity is 44.9436676203125
At time: 618.9953663349152 and batch: 350, loss is 3.832534422874451 and perplexity is 46.17942824656279
At time: 620.2245309352875 and batch: 400, loss is 3.811551947593689 and perplexity is 45.220564382759534
At time: 621.4505014419556 and batch: 450, loss is 3.840491533279419 and perplexity is 46.54834888013091
At time: 622.6758966445923 and batch: 500, loss is 3.8517204618453977 and perplexity is 47.07398259324469
At time: 623.9031372070312 and batch: 550, loss is 3.807299427986145 and perplexity is 45.02867134968199
At time: 625.1301896572113 and batch: 600, loss is 3.765539889335632 and perplexity is 43.18701577616154
At time: 626.3553740978241 and batch: 650, loss is 3.788347601890564 and perplexity is 44.183331469841164
At time: 627.6481397151947 and batch: 700, loss is 3.827944903373718 and perplexity is 45.967972471463945
At time: 628.8732280731201 and batch: 750, loss is 3.7871629190444946 and perplexity is 44.13101922779278
At time: 630.1005790233612 and batch: 800, loss is 3.7497113847732546 and perplexity is 42.50881153914598
At time: 631.3270564079285 and batch: 850, loss is 3.7492045307159425 and perplexity is 42.487271234902295
At time: 632.5527501106262 and batch: 900, loss is 3.7156997680664063 and perplexity is 41.08732862752036
At time: 633.7781262397766 and batch: 950, loss is 3.828939747810364 and perplexity is 46.013726208292745
At time: 635.0029940605164 and batch: 1000, loss is 3.797715816497803 and perplexity is 44.599195310500924
At time: 636.2304089069366 and batch: 1050, loss is 3.741147632598877 and perplexity is 42.14633092426741
At time: 637.4559931755066 and batch: 1100, loss is 3.7618077182769776 and perplexity is 43.02613485008403
At time: 638.6827373504639 and batch: 1150, loss is 3.7443988132476806 and perplexity is 42.28357924843939
At time: 639.9089562892914 and batch: 1200, loss is 3.7908262062072753 and perplexity is 44.29298029784276
At time: 641.1344349384308 and batch: 1250, loss is 3.755484366416931 and perplexity is 42.75492384524715
At time: 642.3610410690308 and batch: 1300, loss is 3.7612757301330566 and perplexity is 43.00325154382853
At time: 643.5876202583313 and batch: 1350, loss is 3.628026523590088 and perplexity is 37.63846465329077
At time: 644.8139002323151 and batch: 1400, loss is 3.659273262023926 and perplexity is 38.833111117453015
At time: 646.0399219989777 and batch: 1450, loss is 3.589261283874512 and perplexity is 36.20731911435848
At time: 647.2662570476532 and batch: 1500, loss is 3.573158273696899 and perplexity is 35.62894159376082
At time: 648.4932816028595 and batch: 1550, loss is 3.58127739906311 and perplexity is 35.91939495529349
At time: 649.720956325531 and batch: 1600, loss is 3.674872455596924 and perplexity is 39.443625722662865
At time: 650.9478068351746 and batch: 1650, loss is 3.5914978408813476 and perplexity is 36.28838947306775
At time: 652.1729583740234 and batch: 1700, loss is 3.610576338768005 and perplexity is 36.987363924779345
At time: 653.3999865055084 and batch: 1750, loss is 3.6266614770889283 and perplexity is 37.587121449709514
At time: 654.6273860931396 and batch: 1800, loss is 3.5630438566207885 and perplexity is 35.270391935567304
At time: 655.8531241416931 and batch: 1850, loss is 3.5852331495285035 and perplexity is 36.06176452219539
At time: 657.0799887180328 and batch: 1900, loss is 3.675934257507324 and perplexity is 39.48552928251133
At time: 658.3050651550293 and batch: 1950, loss is 3.624860644340515 and perplexity is 37.51949424140624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3699866006540695 and perplexity of 79.04257257369552
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 662.4217255115509 and batch: 50, loss is 3.846887240409851 and perplexity is 46.84701255158914
At time: 663.6802496910095 and batch: 100, loss is 3.8425449466705324 and perplexity is 46.64403008597023
At time: 664.9068355560303 and batch: 150, loss is 3.815233001708984 and perplexity is 45.38733047657574
At time: 666.1336431503296 and batch: 200, loss is 3.819107241630554 and perplexity is 45.56351295045751
At time: 667.3609528541565 and batch: 250, loss is 3.8166598415374757 and perplexity is 45.452137150785745
At time: 668.58704662323 and batch: 300, loss is 3.817556300163269 and perplexity is 45.492901380187874
At time: 669.8129727840424 and batch: 350, loss is 3.847071805000305 and perplexity is 46.8556596492242
At time: 671.0392520427704 and batch: 400, loss is 3.832443618774414 and perplexity is 46.17523515551846
At time: 672.2660269737244 and batch: 450, loss is 3.864849343299866 and perplexity is 47.696086156422325
At time: 673.4917058944702 and batch: 500, loss is 3.8799866914749144 and perplexity is 48.4235706207525
At time: 674.7166113853455 and batch: 550, loss is 3.8401993560791015 and perplexity is 46.53475050054069
At time: 675.9432039260864 and batch: 600, loss is 3.797005124092102 and perplexity is 44.56751026158883
At time: 677.1692342758179 and batch: 650, loss is 3.8167420959472658 and perplexity is 45.45587594326476
At time: 678.3958494663239 and batch: 700, loss is 3.847218976020813 and perplexity is 46.86255595192684
At time: 679.6230611801147 and batch: 750, loss is 3.801483769416809 and perplexity is 44.767559974524126
At time: 680.8496725559235 and batch: 800, loss is 3.759885196685791 and perplexity is 42.94349564013562
At time: 682.0764825344086 and batch: 850, loss is 3.7559067010879517 and perplexity is 42.772984545505345
At time: 683.3037450313568 and batch: 900, loss is 3.719453701972961 and perplexity is 41.24185760790573
At time: 684.529904127121 and batch: 950, loss is 3.8342354536056518 and perplexity is 46.258047721273606
At time: 685.7594051361084 and batch: 1000, loss is 3.805528793334961 and perplexity is 44.949012568004854
At time: 686.985461473465 and batch: 1050, loss is 3.7516814184188845 and perplexity is 42.5926378713502
At time: 688.2117848396301 and batch: 1100, loss is 3.7693139362335204 and perplexity is 43.35031355198609
At time: 689.4840841293335 and batch: 1150, loss is 3.7559527063369753 and perplexity is 42.77495237257568
At time: 690.7114772796631 and batch: 1200, loss is 3.8071457529067994 and perplexity is 45.02175209671149
At time: 691.9379360675812 and batch: 1250, loss is 3.7729638195037842 and perplexity is 43.50882623660723
At time: 693.1647024154663 and batch: 1300, loss is 3.7770012044906616 and perplexity is 43.68484320348466
At time: 694.3907246589661 and batch: 1350, loss is 3.634612493515015 and perplexity is 37.8871685286793
At time: 695.6162292957306 and batch: 1400, loss is 3.6636059141159056 and perplexity is 39.001726489677935
At time: 696.8432500362396 and batch: 1450, loss is 3.5882654190063477 and perplexity is 36.17127946557064
At time: 698.0696046352386 and batch: 1500, loss is 3.5639986562728883 and perplexity is 35.30408417562674
At time: 699.2964041233063 and batch: 1550, loss is 3.575118689537048 and perplexity is 35.69885764510428
At time: 700.5217597484589 and batch: 1600, loss is 3.670319833755493 and perplexity is 39.26446195259011
At time: 701.7474136352539 and batch: 1650, loss is 3.5874724817276 and perplexity is 36.14260927799484
At time: 702.9737288951874 and batch: 1700, loss is 3.60695951461792 and perplexity is 36.85382876585112
At time: 704.2003712654114 and batch: 1750, loss is 3.621671462059021 and perplexity is 37.40002833569193
At time: 705.4263370037079 and batch: 1800, loss is 3.557699236869812 and perplexity is 35.082387954625666
At time: 706.6530950069427 and batch: 1850, loss is 3.575304126739502 and perplexity is 35.70547815522225
At time: 707.879791021347 and batch: 1900, loss is 3.663091540336609 and perplexity is 38.981670182885715
At time: 709.1060461997986 and batch: 1950, loss is 3.6175654840469362 and perplexity is 37.246779475222496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.365902355105378 and perplexity of 78.72040165891255
finished 14 epochs...
Completing Train Step...
At time: 713.0590465068817 and batch: 50, loss is 3.8471024894714354 and perplexity is 46.85709741241838
At time: 714.3120760917664 and batch: 100, loss is 3.8387954473495483 and perplexity is 46.46946579569172
At time: 715.5359477996826 and batch: 150, loss is 3.8084194087982177 and perplexity is 45.07913084914783
At time: 716.7586307525635 and batch: 200, loss is 3.8095754194259643 and perplexity is 45.13127293609564
At time: 717.9846544265747 and batch: 250, loss is 3.8062267303466797 and perplexity is 44.980395097756876
At time: 719.2564046382904 and batch: 300, loss is 3.8058668899536134 and perplexity is 44.96421224650102
At time: 720.4809551239014 and batch: 350, loss is 3.8355999755859376 and perplexity is 46.32121092814605
At time: 721.7064318656921 and batch: 400, loss is 3.8213640117645262 and perplexity is 45.66645544076117
At time: 722.9312071800232 and batch: 450, loss is 3.854544472694397 and perplexity is 47.20710791599822
At time: 724.1570808887482 and batch: 500, loss is 3.8692774868011472 and perplexity is 47.90775958464795
At time: 725.3827233314514 and batch: 550, loss is 3.8292423820495607 and perplexity is 46.027653644669655
At time: 726.6084063053131 and batch: 600, loss is 3.785688042640686 and perplexity is 44.065979403498645
At time: 727.8325848579407 and batch: 650, loss is 3.8038374757766724 and perplexity is 44.873053767154666
At time: 729.0616753101349 and batch: 700, loss is 3.8373722887039183 and perplexity is 46.40337941054614
At time: 730.2884664535522 and batch: 750, loss is 3.7929642248153685 and perplexity is 44.387780820456086
At time: 731.5140607357025 and batch: 800, loss is 3.75235134601593 and perplexity is 42.62118141487741
At time: 732.7404990196228 and batch: 850, loss is 3.7492457151412966 and perplexity is 42.489021084786
At time: 733.9644958972931 and batch: 900, loss is 3.7139460945129397 and perplexity is 41.01533800839593
At time: 735.190868139267 and batch: 950, loss is 3.8276619338989257 and perplexity is 45.954966778630244
At time: 736.4176168441772 and batch: 1000, loss is 3.7985768270492555 and perplexity is 44.637612224560414
At time: 737.6431155204773 and batch: 1050, loss is 3.744324722290039 and perplexity is 42.280446533614715
At time: 738.8677129745483 and batch: 1100, loss is 3.7624278402328493 and perplexity is 43.052824575567946
At time: 740.0940725803375 and batch: 1150, loss is 3.7489957189559937 and perplexity is 42.4784003192283
At time: 741.319756269455 and batch: 1200, loss is 3.7998723793029785 and perplexity is 44.695480060987656
At time: 742.5446348190308 and batch: 1250, loss is 3.7667207431793215 and perplexity is 43.23804345192233
At time: 743.7700517177582 and batch: 1300, loss is 3.7713336086273195 and perplexity is 43.43795545770683
At time: 744.995169878006 and batch: 1350, loss is 3.630526456832886 and perplexity is 37.73267601427621
At time: 746.2205288410187 and batch: 1400, loss is 3.6613074350357055 and perplexity is 38.91218478154198
At time: 747.4472908973694 and batch: 1450, loss is 3.5872254371643066 and perplexity is 36.13368154568875
At time: 748.6726229190826 and batch: 1500, loss is 3.565328845977783 and perplexity is 35.35107655239675
At time: 749.8992805480957 and batch: 1550, loss is 3.577219386100769 and perplexity is 35.773928936082605
At time: 751.1250364780426 and batch: 1600, loss is 3.672863221168518 and perplexity is 39.364453795995054
At time: 752.3500530719757 and batch: 1650, loss is 3.5906072521209715 and perplexity is 36.25608582803761
At time: 753.5755560398102 and batch: 1700, loss is 3.610529131889343 and perplexity is 36.98561790799084
At time: 754.802088022232 and batch: 1750, loss is 3.6265895128250123 and perplexity is 37.58441661750847
At time: 756.0264120101929 and batch: 1800, loss is 3.5627288818359375 and perplexity is 35.259284400844294
At time: 757.2517330646515 and batch: 1850, loss is 3.5796699571609496 and perplexity is 35.861702995401345
At time: 758.4766020774841 and batch: 1900, loss is 3.667451286315918 and perplexity is 39.151991371511
At time: 759.701089143753 and batch: 1950, loss is 3.6217825651168822 and perplexity is 37.404183824043585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364816497093023 and perplexity of 78.6349688723677
finished 15 epochs...
Completing Train Step...
At time: 763.6652772426605 and batch: 50, loss is 3.8463406133651734 and perplexity is 46.82141170526104
At time: 764.8912181854248 and batch: 100, loss is 3.8363903856277464 and perplexity is 46.35783815176818
At time: 766.116908788681 and batch: 150, loss is 3.8053211259841917 and perplexity is 44.93967909480752
At time: 767.3415837287903 and batch: 200, loss is 3.8053232288360594 and perplexity is 44.93977359639501
At time: 768.5685906410217 and batch: 250, loss is 3.8012468910217283 and perplexity is 44.756956762651164
At time: 769.7947256565094 and batch: 300, loss is 3.8003172063827515 and perplexity is 44.71536624349058
At time: 771.0210888385773 and batch: 350, loss is 3.829856514930725 and perplexity is 46.055929421869244
At time: 772.2489652633667 and batch: 400, loss is 3.815517182350159 and perplexity is 45.40023051013487
At time: 773.476158618927 and batch: 450, loss is 3.848934097290039 and perplexity is 46.94299988420014
At time: 774.7013459205627 and batch: 500, loss is 3.8637023544311524 and perplexity is 47.64141063861905
At time: 775.9291136264801 and batch: 550, loss is 3.823544292449951 and perplexity is 45.76612975103272
At time: 777.1756589412689 and batch: 600, loss is 3.7802993726730345 and perplexity is 43.829161024790494
At time: 778.4191699028015 and batch: 650, loss is 3.7982410287857054 and perplexity is 44.62262550828386
At time: 779.6436197757721 and batch: 700, loss is 3.8324992799758912 and perplexity is 46.17780539611638
At time: 780.9206988811493 and batch: 750, loss is 3.7887097597122192 and perplexity is 44.19933570677462
At time: 782.1459066867828 and batch: 800, loss is 3.7484298276901247 and perplexity is 42.454368963707964
At time: 783.3717911243439 and batch: 850, loss is 3.7456143999099734 and perplexity is 42.3350098562552
At time: 784.5977592468262 and batch: 900, loss is 3.710667414665222 and perplexity is 40.88108205762863
At time: 785.8231456279755 and batch: 950, loss is 3.8238750219345095 and perplexity is 45.78126846280669
At time: 787.0481345653534 and batch: 1000, loss is 3.794887270927429 and perplexity is 44.47322269778977
At time: 788.2730283737183 and batch: 1050, loss is 3.7407680463790896 and perplexity is 42.130335793791566
At time: 789.4981429576874 and batch: 1100, loss is 3.7593466567993166 and perplexity is 42.92037508109919
At time: 790.7272291183472 and batch: 1150, loss is 3.7459782648086546 and perplexity is 42.35041688319537
At time: 791.9534573554993 and batch: 1200, loss is 3.7969113206863403 and perplexity is 44.56332987341037
At time: 793.1804308891296 and batch: 1250, loss is 3.7642766523361204 and perplexity is 43.13249478365232
At time: 794.4051234722137 and batch: 1300, loss is 3.7691772842407225 and perplexity is 43.344390049989194
At time: 795.6297414302826 and batch: 1350, loss is 3.628957223892212 and perplexity is 37.67351109004994
At time: 796.854514837265 and batch: 1400, loss is 3.6604235124588014 and perplexity is 38.87780461983597
At time: 798.0791583061218 and batch: 1450, loss is 3.586702046394348 and perplexity is 36.11477445861216
At time: 799.3040256500244 and batch: 1500, loss is 3.565839800834656 and perplexity is 35.36914397208172
At time: 800.5284216403961 and batch: 1550, loss is 3.578133521080017 and perplexity is 35.80664608753618
At time: 801.753675699234 and batch: 1600, loss is 3.6738134002685547 and perplexity is 39.401874852813975
At time: 802.978845834732 and batch: 1650, loss is 3.5918985319137575 and perplexity is 36.30293281880974
At time: 804.2044901847839 and batch: 1700, loss is 3.611911973953247 and perplexity is 37.03679855541369
At time: 805.4293487071991 and batch: 1750, loss is 3.6284013891220095 and perplexity is 37.65257666125117
At time: 806.6541543006897 and batch: 1800, loss is 3.5647816896438598 and perplexity is 35.3317392776887
At time: 807.880936384201 and batch: 1850, loss is 3.581510443687439 and perplexity is 35.92776675266026
At time: 809.1067996025085 and batch: 1900, loss is 3.669167742729187 and perplexity is 39.219251766447336
At time: 810.3325335979462 and batch: 1950, loss is 3.6233914041519166 and perplexity is 37.46440956882736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364334461300872 and perplexity of 78.59707313714067
finished 16 epochs...
Completing Train Step...
At time: 814.3426961898804 and batch: 50, loss is 3.8448704624176027 and perplexity is 46.75262773627336
At time: 815.5685298442841 and batch: 100, loss is 3.8340765333175657 and perplexity is 46.25069696311121
At time: 816.7948381900787 and batch: 150, loss is 3.8027126359939576 and perplexity is 44.82260714860622
At time: 818.0220413208008 and batch: 200, loss is 3.8021654510498046 and perplexity is 44.798087601792034
At time: 819.2480447292328 and batch: 250, loss is 3.797695822715759 and perplexity is 44.59830361282479
At time: 820.4750530719757 and batch: 300, loss is 3.7964885091781615 and perplexity is 44.54449196741948
At time: 821.7005078792572 and batch: 350, loss is 3.8259686183929444 and perplexity is 45.87721636737355
At time: 822.9268391132355 and batch: 400, loss is 3.811565456390381 and perplexity is 45.22117526229619
At time: 824.1536338329315 and batch: 450, loss is 3.845135545730591 and perplexity is 46.765022720503765
At time: 825.3795189857483 and batch: 500, loss is 3.859931025505066 and perplexity is 47.46207758312116
At time: 826.6067426204681 and batch: 550, loss is 3.819747734069824 and perplexity is 45.5927053837773
At time: 827.8329739570618 and batch: 600, loss is 3.776814351081848 and perplexity is 43.676681304181706
At time: 829.0601308345795 and batch: 650, loss is 3.7947043132781983 and perplexity is 44.46508672580312
At time: 830.2886664867401 and batch: 700, loss is 3.8293459892272947 and perplexity is 46.032422687010744
At time: 831.5146703720093 and batch: 750, loss is 3.7858570051193237 and perplexity is 44.0734255296425
At time: 832.7410054206848 and batch: 800, loss is 3.7456777715682983 and perplexity is 42.33769278104479
At time: 833.9677908420563 and batch: 850, loss is 3.7429536104202272 and perplexity is 42.22251503586931
At time: 835.2038424015045 and batch: 900, loss is 3.7082044792175295 and perplexity is 40.780518483120375
At time: 836.4391074180603 and batch: 950, loss is 3.8211947107315063 and perplexity is 45.65872471710891
At time: 837.6645817756653 and batch: 1000, loss is 3.7922932004928587 and perplexity is 44.358005530992294
At time: 838.8905317783356 and batch: 1050, loss is 3.7383570766448972 and perplexity is 42.02888317803783
At time: 840.1159722805023 and batch: 1100, loss is 3.757233428955078 and perplexity is 42.82977031736546
At time: 841.4730305671692 and batch: 1150, loss is 3.7439592266082764 and perplexity is 42.26499603670063
At time: 842.6994459629059 and batch: 1200, loss is 3.7949456357955933 and perplexity is 44.47581844731892
At time: 843.9256443977356 and batch: 1250, loss is 3.7626380825042727 and perplexity is 43.06187705077104
At time: 845.1522462368011 and batch: 1300, loss is 3.7677082681655882 and perplexity is 43.28076319012112
At time: 846.3774206638336 and batch: 1350, loss is 3.627770094871521 and perplexity is 37.62881430739669
At time: 847.6038382053375 and batch: 1400, loss is 3.659542441368103 and perplexity is 38.84356559583766
At time: 848.8302757740021 and batch: 1450, loss is 3.585984916687012 and perplexity is 36.0888847652178
At time: 850.0596370697021 and batch: 1500, loss is 3.5657266187667847 and perplexity is 35.36514104576214
At time: 851.2857263088226 and batch: 1550, loss is 3.578291597366333 and perplexity is 35.81230671656894
At time: 852.5120134353638 and batch: 1600, loss is 3.67395742893219 and perplexity is 39.40755026089466
At time: 853.7362232208252 and batch: 1650, loss is 3.592261996269226 and perplexity is 36.31613003910264
At time: 854.9610652923584 and batch: 1700, loss is 3.6123610448837282 and perplexity is 37.05343444006954
At time: 856.1866025924683 and batch: 1750, loss is 3.6289929819107054 and perplexity is 37.67485824424185
At time: 857.4118411540985 and batch: 1800, loss is 3.5656005859375 and perplexity is 35.36068415784109
At time: 858.6373958587646 and batch: 1850, loss is 3.5822956228256224 and perplexity is 35.95598756334202
At time: 859.8622183799744 and batch: 1900, loss is 3.669860587120056 and perplexity is 39.24643402049656
At time: 861.0884776115417 and batch: 1950, loss is 3.623997755050659 and perplexity is 37.48713303574135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364097417787064 and perplexity of 78.57844441874488
finished 17 epochs...
Completing Train Step...
At time: 865.1038208007812 and batch: 50, loss is 3.843195037841797 and perplexity is 46.674362816573236
At time: 866.3303339481354 and batch: 100, loss is 3.8318602943420412 and perplexity is 46.148307867117836
At time: 867.5530705451965 and batch: 150, loss is 3.800379891395569 and perplexity is 44.71816931465104
At time: 868.7759928703308 and batch: 200, loss is 3.799529194831848 and perplexity is 44.68014389801802
At time: 870.0026602745056 and batch: 250, loss is 3.7948139190673826 and perplexity is 44.46996062382369
At time: 871.2279205322266 and batch: 300, loss is 3.793455891609192 and perplexity is 44.40961018428394
At time: 872.4964489936829 and batch: 350, loss is 3.8229139757156374 and perplexity is 45.73729168309906
At time: 873.7232730388641 and batch: 400, loss is 3.8084694719314576 and perplexity is 45.08138770817411
At time: 874.9486849308014 and batch: 450, loss is 3.8421722173690798 and perplexity is 46.6266477288775
At time: 876.1754908561707 and batch: 500, loss is 3.8569886350631712 and perplexity is 47.322630873627546
At time: 877.401645898819 and batch: 550, loss is 3.816803870201111 and perplexity is 45.458684032816954
At time: 878.6272859573364 and batch: 600, loss is 3.77412446975708 and perplexity is 43.5593540837064
At time: 879.8548452854156 and batch: 650, loss is 3.7919696807861327 and perplexity is 44.34365716316699
At time: 881.0814111232758 and batch: 700, loss is 3.8269036054611205 and perplexity is 45.9201310306022
At time: 882.3071174621582 and batch: 750, loss is 3.7835751581192016 and perplexity is 43.97297136991137
At time: 883.5332307815552 and batch: 800, loss is 3.7434372329711914 and perplexity is 42.24293973482349
At time: 884.7595300674438 and batch: 850, loss is 3.7407526350021363 and perplexity is 42.12968651230865
At time: 885.9859058856964 and batch: 900, loss is 3.706143126487732 and perplexity is 40.69654203230158
At time: 887.2126166820526 and batch: 950, loss is 3.819010238647461 and perplexity is 45.559093368140914
At time: 888.4402918815613 and batch: 1000, loss is 3.7901755237579344 and perplexity is 44.26416900745099
At time: 889.6665499210358 and batch: 1050, loss is 3.7364399099349974 and perplexity is 41.94838399219068
At time: 890.8933856487274 and batch: 1100, loss is 3.755513997077942 and perplexity is 42.75619072067125
At time: 892.1193997859955 and batch: 1150, loss is 3.7423041534423827 and perplexity is 42.19510223153919
At time: 893.3470463752747 and batch: 1200, loss is 3.7933218479156494 and perplexity is 44.40365775505776
At time: 894.5709538459778 and batch: 1250, loss is 3.7612618827819824 and perplexity is 43.00265606682997
At time: 895.7957589626312 and batch: 1300, loss is 3.7664361143112184 and perplexity is 43.225738407824075
At time: 897.0219535827637 and batch: 1350, loss is 3.626668276786804 and perplexity is 37.58737703164834
At time: 898.2477729320526 and batch: 1400, loss is 3.6586004590988157 and perplexity is 38.80699287390262
At time: 899.4740915298462 and batch: 1450, loss is 3.5851298332214356 and perplexity is 36.05803894631829
At time: 900.7001869678497 and batch: 1500, loss is 3.5652931785583495 and perplexity is 35.34981569320786
At time: 901.9264500141144 and batch: 1550, loss is 3.578061065673828 and perplexity is 35.80405179643598
At time: 903.1525356769562 and batch: 1600, loss is 3.6737153482437135 and perplexity is 39.39801160860467
At time: 904.378847360611 and batch: 1650, loss is 3.592182321548462 and perplexity is 36.313236676847986
At time: 905.6061260700226 and batch: 1700, loss is 3.612390842437744 and perplexity is 37.054538558233666
At time: 906.8354926109314 and batch: 1750, loss is 3.6290663290023804 and perplexity is 37.677621686867326
At time: 908.0608336925507 and batch: 1800, loss is 3.565859932899475 and perplexity is 35.36985603314837
At time: 909.2878723144531 and batch: 1850, loss is 3.582590765953064 and perplexity is 35.96660129216922
At time: 910.5137555599213 and batch: 1900, loss is 3.6701044178009035 and perplexity is 39.25600467198643
At time: 911.7397134304047 and batch: 1950, loss is 3.624169750213623 and perplexity is 37.49358119580716
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364004303688227 and perplexity of 78.57112799834107
finished 18 epochs...
Completing Train Step...
At time: 915.7428996562958 and batch: 50, loss is 3.841482095718384 and perplexity is 46.594480770614275
At time: 917.0115330219269 and batch: 100, loss is 3.829755034446716 and perplexity is 46.05125588100064
At time: 918.2349207401276 and batch: 150, loss is 3.798233675956726 and perplexity is 44.62229740695612
At time: 919.4594731330872 and batch: 200, loss is 3.7971946477890013 and perplexity is 44.57595766136114
At time: 920.6834018230438 and batch: 250, loss is 3.792305488586426 and perplexity is 44.358550609663695
At time: 921.9079148769379 and batch: 300, loss is 3.790854911804199 and perplexity is 44.294251772530885
At time: 923.1319365501404 and batch: 350, loss is 3.8203025913238524 and perplexity is 45.61800984662345
At time: 924.3566935062408 and batch: 400, loss is 3.8058242177963257 and perplexity is 44.9622935675011
At time: 925.5817167758942 and batch: 450, loss is 3.8396527194976806 and perplexity is 46.509319854903644
At time: 926.8069431781769 and batch: 500, loss is 3.854467167854309 and perplexity is 47.20345871912187
At time: 928.0320446491241 and batch: 550, loss is 3.814279341697693 and perplexity is 45.34406702707073
At time: 929.2574577331543 and batch: 600, loss is 3.7718099260330202 and perplexity is 43.45865064030596
At time: 930.483149766922 and batch: 650, loss is 3.7896213054656984 and perplexity is 44.23964379208568
At time: 931.7080895900726 and batch: 700, loss is 3.824800190925598 and perplexity is 45.8236434717608
At time: 932.9321489334106 and batch: 750, loss is 3.781572365760803 and perplexity is 43.88499077171932
At time: 934.2016835212708 and batch: 800, loss is 3.741462969779968 and perplexity is 42.15962332513837
At time: 935.4258675575256 and batch: 850, loss is 3.738814105987549 and perplexity is 42.04809600096657
At time: 936.6517038345337 and batch: 900, loss is 3.7043122005462648 and perplexity is 40.622097849455955
At time: 937.8761491775513 and batch: 950, loss is 3.817110061645508 and perplexity is 45.47260522410742
At time: 939.1003820896149 and batch: 1000, loss is 3.788321924209595 and perplexity is 44.182196958917395
At time: 940.3248455524445 and batch: 1050, loss is 3.734769568443298 and perplexity is 41.878374352179534
At time: 941.5500206947327 and batch: 1100, loss is 3.7538962316513063 and perplexity is 42.68707715339199
At time: 942.7748279571533 and batch: 1150, loss is 3.7407505464553834 and perplexity is 42.12959852258057
At time: 944.0020942687988 and batch: 1200, loss is 3.791805844306946 and perplexity is 44.33639264961551
At time: 945.2273223400116 and batch: 1250, loss is 3.759930896759033 and perplexity is 42.94545820587601
At time: 946.451000213623 and batch: 1300, loss is 3.765197982788086 and perplexity is 43.17225237669398
At time: 947.675701379776 and batch: 1350, loss is 3.6255866050720216 and perplexity is 37.54674181002724
At time: 948.900351524353 and batch: 1400, loss is 3.657633676528931 and perplexity is 38.76949307959706
At time: 950.1241614818573 and batch: 1450, loss is 3.584244418144226 and perplexity is 36.0261267448376
At time: 951.3525850772858 and batch: 1500, loss is 3.5647243547439573 and perplexity is 35.32971359402558
At time: 952.5775170326233 and batch: 1550, loss is 3.577660059928894 and perplexity is 35.789697044335085
At time: 953.8006069660187 and batch: 1600, loss is 3.673300447463989 and perplexity is 39.38166873343894
At time: 955.0253732204437 and batch: 1650, loss is 3.591898970603943 and perplexity is 36.30294874455356
At time: 956.2498338222504 and batch: 1700, loss is 3.612239670753479 and perplexity is 37.048937384610255
At time: 957.4735748767853 and batch: 1750, loss is 3.6289315032958984 and perplexity is 37.672542117340804
At time: 958.698098897934 and batch: 1800, loss is 3.565876121520996 and perplexity is 35.37042862699569
At time: 959.9240756034851 and batch: 1850, loss is 3.5826668787002562 and perplexity is 35.96933891318335
At time: 961.149405002594 and batch: 1900, loss is 3.670127067565918 and perplexity is 39.25689382133714
At time: 962.3744423389435 and batch: 1950, loss is 3.6241343021392822 and perplexity is 37.49225214410993
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3639864189680235 and perplexity of 78.56972278826667
finished 19 epochs...
Completing Train Step...
At time: 966.4385569095612 and batch: 50, loss is 3.8398029613494873 and perplexity is 46.51630802618967
At time: 967.6927983760834 and batch: 100, loss is 3.8277708768844603 and perplexity is 45.95997352263112
At time: 968.9194195270538 and batch: 150, loss is 3.7962413740158083 and perplexity is 44.5334848173481
At time: 970.1456637382507 and batch: 200, loss is 3.795053825378418 and perplexity is 44.48063052786632
At time: 971.3709666728973 and batch: 250, loss is 3.7900395965576172 and perplexity is 44.25815271178181
At time: 972.5963852405548 and batch: 300, loss is 3.7885239934921264 and perplexity is 44.19112572584193
At time: 973.8234601020813 and batch: 350, loss is 3.817964277267456 and perplexity is 45.51146522890916
At time: 975.0507228374481 and batch: 400, loss is 3.803454527854919 and perplexity is 44.85587301434857
At time: 976.2760334014893 and batch: 450, loss is 3.837399411201477 and perplexity is 46.404638003158915
At time: 977.5016050338745 and batch: 500, loss is 3.8522173309326173 and perplexity is 47.09737801175639
At time: 978.7280716896057 and batch: 550, loss is 3.8120224380493166 and perplexity is 45.241845232525506
At time: 979.9550199508667 and batch: 600, loss is 3.7697329759597777 and perplexity is 43.36848286207558
At time: 981.1819050312042 and batch: 650, loss is 3.787499899864197 and perplexity is 44.14589304078055
At time: 982.4076602458954 and batch: 700, loss is 3.8229014587402346 and perplexity is 45.73671919412699
At time: 983.6340448856354 and batch: 750, loss is 3.779739875793457 and perplexity is 43.80464560475265
At time: 984.8611013889313 and batch: 800, loss is 3.7396546030044555 and perplexity is 42.08345215651221
At time: 986.0877439975739 and batch: 850, loss is 3.7370326042175295 and perplexity is 41.97325392895093
At time: 987.3135027885437 and batch: 900, loss is 3.702606687545776 and perplexity is 40.55287538015663
At time: 988.5389204025269 and batch: 950, loss is 3.815379009246826 and perplexity is 45.393957852759506
At time: 989.7649257183075 and batch: 1000, loss is 3.7865860843658448 and perplexity is 44.10557026612549
At time: 990.9908893108368 and batch: 1050, loss is 3.733162498474121 and perplexity is 41.811126924534115
At time: 992.2177085876465 and batch: 1100, loss is 3.7523921871185304 and perplexity is 42.622922146466976
At time: 993.4441590309143 and batch: 1150, loss is 3.7393005418777467 and perplexity is 42.068554679490255
At time: 994.6716678142548 and batch: 1200, loss is 3.790388140678406 and perplexity is 44.2735813193255
At time: 995.9274830818176 and batch: 1250, loss is 3.7586773300170897 and perplexity is 42.89165693653797
At time: 997.153032541275 and batch: 1300, loss is 3.764011754989624 and perplexity is 43.121070613419356
At time: 998.3790941238403 and batch: 1350, loss is 3.624530415534973 and perplexity is 37.50710626918357
At time: 999.6051249504089 and batch: 1400, loss is 3.656667971611023 and perplexity is 38.7320712615904
At time: 1000.831197977066 and batch: 1450, loss is 3.583333592414856 and perplexity is 35.99332816083344
At time: 1002.058580160141 and batch: 1500, loss is 3.564069094657898 and perplexity is 35.306571025884146
At time: 1003.2861785888672 and batch: 1550, loss is 3.577147126197815 and perplexity is 35.77134400884382
At time: 1004.5121116638184 and batch: 1600, loss is 3.6727860355377198 and perplexity is 39.36141554305402
At time: 1005.7382478713989 and batch: 1650, loss is 3.5914945125579836 and perplexity is 36.28826869377422
At time: 1006.9656195640564 and batch: 1700, loss is 3.6119706535339358 and perplexity is 37.038971922988495
At time: 1008.191867351532 and batch: 1750, loss is 3.628665008544922 and perplexity is 37.66250392023342
At time: 1009.4179036617279 and batch: 1800, loss is 3.565734543800354 and perplexity is 35.36542131680269
At time: 1010.6460394859314 and batch: 1850, loss is 3.5825962352752687 and perplexity is 35.966798005638246
At time: 1011.8726375102997 and batch: 1900, loss is 3.6700205564498902 and perplexity is 39.252712748433765
At time: 1013.1001772880554 and batch: 1950, loss is 3.623979935646057 and perplexity is 37.48646504330205
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.364031272710756 and perplexity of 78.57324701343593
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f8261144b38>
ELAPSED
6303.533533334732


RESULTS SO FAR:
[{'best_accuracy': -78.0513610743167, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}}, {'best_accuracy': -78.42215966096434, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.02990420607447708, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.45043527467939715}}, {'best_accuracy': -79.59315869934208, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.9149200001362663, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.10734533781315092}}, {'best_accuracy': -80.12467139230405, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.46354086461744826, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.20663157340468064}}, {'best_accuracy': -79.45763486402183, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.45994889588664123, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.6843673700358436}}, {'best_accuracy': -78.56972278826667, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.4921000806491009, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5501205754920423}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -78.0513610743167, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.48583667132627495, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5543870512900133}}, {'best_accuracy': -78.42215966096434, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.02990420607447708, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.45043527467939715}}, {'best_accuracy': -79.59315869934208, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.9149200001362663, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.10734533781315092}}, {'best_accuracy': -80.12467139230405, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.46354086461744826, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.20663157340468064}}, {'best_accuracy': -79.45763486402183, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.45994889588664123, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.6843673700358436}}, {'best_accuracy': -78.56972278826667, 'params': {'tune_wordvecs': True, 'tie_weights': True, 'data': 'wikitext', 'seq_len': 35, 'num_layers': 2, 'wordvec_dim': 300, 'dropout': 0.4921000806491009, 'batch_size': 32, 'wordvec_source': 'None', 'rnn_dropout': 0.5501205754920423}}]
