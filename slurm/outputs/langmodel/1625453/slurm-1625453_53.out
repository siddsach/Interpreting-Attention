Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'domain': [0, 1], 'type': 'continuous', 'name': 'dropout'}, {'domain': [0, 1], 'type': 'continuous', 'name': 'rnn_dropout'}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.7699000835418701 and batch: 50, loss is 7.547290115356446 and perplexity is 1895.5989105288793
At time: 2.7342991828918457 and batch: 100, loss is 6.7032603931427 and perplexity is 815.0589102489852
At time: 3.6973907947540283 and batch: 150, loss is 6.409486951828003 and perplexity is 607.5818823103659
At time: 4.663313865661621 and batch: 200, loss is 6.205703849792481 and perplexity is 495.5676383951989
At time: 5.624939918518066 and batch: 250, loss is 6.023688039779663 and perplexity is 413.0993164757811
At time: 6.592732667922974 and batch: 300, loss is 5.898257389068603 and perplexity is 364.401903514984
At time: 7.559025287628174 and batch: 350, loss is 5.775488052368164 and perplexity is 322.3016964455893
At time: 8.524861097335815 and batch: 400, loss is 5.6762340545654295 and perplexity is 291.84827310403557
At time: 9.493446826934814 and batch: 450, loss is 5.567792177200317 and perplexity is 261.85533039718564
At time: 10.462541818618774 and batch: 500, loss is 5.508569622039795 and perplexity is 246.79786025538903
At time: 11.430047988891602 and batch: 550, loss is 5.4431616401672365 and perplexity is 231.1719116852684
At time: 12.397104024887085 and batch: 600, loss is 5.44904239654541 and perplexity is 232.53538256997624
At time: 13.364827871322632 and batch: 650, loss is 5.494363756179809 and perplexity is 243.31666817569962
At time: 14.33219575881958 and batch: 700, loss is 5.430488519668579 and perplexity is 228.26072804627475
At time: 15.299381256103516 and batch: 750, loss is 5.364012289047241 and perplexity is 213.58017498698624
At time: 16.268292903900146 and batch: 800, loss is 5.339843368530273 and perplexity is 208.4800531944581
At time: 17.237696409225464 and batch: 850, loss is 5.332854747772217 and perplexity is 207.02814449605967
At time: 18.212955951690674 and batch: 900, loss is 5.332466945648194 and perplexity is 206.94787410741114
At time: 19.195010662078857 and batch: 950, loss is 5.371571350097656 and perplexity is 215.20075789485233
At time: 20.16413402557373 and batch: 1000, loss is 5.322024850845337 and perplexity is 204.79814814123338
At time: 21.133719205856323 and batch: 1050, loss is 5.215622396469116 and perplexity is 184.12638493570248
At time: 22.10262441635132 and batch: 1100, loss is 5.287727756500244 and perplexity is 197.89325249520468
At time: 23.072444915771484 and batch: 1150, loss is 5.180851888656616 and perplexity is 177.8342414563143
At time: 24.041887283325195 and batch: 1200, loss is 5.262598152160645 and perplexity is 192.98223772576497
At time: 25.01161766052246 and batch: 1250, loss is 5.207826137542725 and perplexity is 182.69646920292402
At time: 25.98586344718933 and batch: 1300, loss is 5.223334407806396 and perplexity is 185.55185927594118
At time: 26.959580898284912 and batch: 1350, loss is 5.151360645294189 and perplexity is 172.6662681011462
At time: 27.934581518173218 and batch: 1400, loss is 5.156792449951172 and perplexity is 173.60670937469663
At time: 28.919039249420166 and batch: 1450, loss is 5.112227783203125 and perplexity is 166.03984392550979
At time: 29.896552562713623 and batch: 1500, loss is 5.078992261886596 and perplexity is 160.6121193933152
At time: 30.87261652946472 and batch: 1550, loss is 5.06773159980774 and perplexity is 158.81366548591495
At time: 31.848937034606934 and batch: 1600, loss is 5.115179786682129 and perplexity is 166.530718297388
At time: 32.82924771308899 and batch: 1650, loss is 5.075353641510009 and perplexity is 160.02877479134344
At time: 33.81880259513855 and batch: 1700, loss is 5.108659400939941 and perplexity is 165.44840615706744
At time: 34.84587574005127 and batch: 1750, loss is 5.1075544357299805 and perplexity is 165.26569238898932
At time: 35.89781641960144 and batch: 1800, loss is 5.062130813598633 and perplexity is 157.92667035216368
At time: 36.977299213409424 and batch: 1850, loss is 5.047812366485596 and perplexity is 155.68151758349399
At time: 38.05925464630127 and batch: 1900, loss is 5.119051284790039 and perplexity is 167.17669129295354
At time: 39.14186358451843 and batch: 1950, loss is 5.037908897399903 and perplexity is 154.14733986684556
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.760081588390261 and perplexity of 116.75545139973345
finished 1 epochs...
Completing Train Step...
At time: 42.39190173149109 and batch: 50, loss is 4.955717287063599 and perplexity is 141.9844134391402
At time: 43.38196134567261 and batch: 100, loss is 4.923742589950561 and perplexity is 137.5163184843024
At time: 44.386510610580444 and batch: 150, loss is 4.862130537033081 and perplexity is 129.29938598876416
At time: 45.38904142379761 and batch: 200, loss is 4.83384337425232 and perplexity is 125.69311920140782
At time: 46.3926899433136 and batch: 250, loss is 4.834450340270996 and perplexity is 125.76943381138906
At time: 47.39635729789734 and batch: 300, loss is 4.851168670654297 and perplexity is 127.8897635583463
At time: 48.440828800201416 and batch: 350, loss is 4.841953945159912 and perplexity is 126.7167074889006
At time: 49.4399778842926 and batch: 400, loss is 4.786323957443237 and perplexity is 119.85994755085737
At time: 50.442294120788574 and batch: 450, loss is 4.77168568611145 and perplexity is 118.11818441927767
At time: 51.44573760032654 and batch: 500, loss is 4.7641951274871825 and perplexity is 117.23671869111955
At time: 52.449328660964966 and batch: 550, loss is 4.721606464385986 and perplexity is 112.34859178636016
At time: 53.4538152217865 and batch: 600, loss is 4.705918207168579 and perplexity is 110.59979185988193
At time: 54.46035861968994 and batch: 650, loss is 4.775125350952148 and perplexity is 118.52517093260735
At time: 55.47687268257141 and batch: 700, loss is 4.785488805770874 and perplexity is 119.75988810343412
At time: 56.48653769493103 and batch: 750, loss is 4.736183786392212 and perplexity is 113.9983285439932
At time: 57.48957848548889 and batch: 800, loss is 4.713922929763794 and perplexity is 111.48866535944968
At time: 58.49290323257446 and batch: 850, loss is 4.698968667984008 and perplexity is 109.83383886542966
At time: 59.49655199050903 and batch: 900, loss is 4.701216707229614 and perplexity is 110.08102738634173
At time: 60.500300884246826 and batch: 950, loss is 4.7616606712341305 and perplexity is 116.93996357162939
At time: 61.50290369987488 and batch: 1000, loss is 4.739578142166137 and perplexity is 114.38593689687234
At time: 62.50706744194031 and batch: 1050, loss is 4.654811544418335 and perplexity is 105.08941344609272
At time: 63.512858629226685 and batch: 1100, loss is 4.721794357299805 and perplexity is 112.36970327392169
At time: 64.51689124107361 and batch: 1150, loss is 4.652925968170166 and perplexity is 104.89144604413468
At time: 65.51995539665222 and batch: 1200, loss is 4.72685094833374 and perplexity is 112.93934992928813
At time: 66.5239577293396 and batch: 1250, loss is 4.692144966125488 and perplexity is 109.08691678008256
At time: 67.52733516693115 and batch: 1300, loss is 4.704264116287232 and perplexity is 110.41700097073566
At time: 68.53130030632019 and batch: 1350, loss is 4.603320455551147 and perplexity is 99.81519792600784
At time: 69.53454661369324 and batch: 1400, loss is 4.607513828277588 and perplexity is 100.2346390765816
At time: 70.53782033920288 and batch: 1450, loss is 4.559664535522461 and perplexity is 95.55142034565345
At time: 71.5409255027771 and batch: 1500, loss is 4.552316198348999 and perplexity is 94.8518497796996
At time: 72.54553818702698 and batch: 1550, loss is 4.550066366195678 and perplexity is 94.63868891625933
At time: 73.54941129684448 and batch: 1600, loss is 4.619292478561402 and perplexity is 101.42224832320966
At time: 74.55319929122925 and batch: 1650, loss is 4.582029390335083 and perplexity is 97.71248991495992
At time: 75.55535674095154 and batch: 1700, loss is 4.617479152679444 and perplexity is 101.23850338039745
At time: 76.55729794502258 and batch: 1750, loss is 4.605314474105835 and perplexity is 100.01442985277751
At time: 77.55923461914062 and batch: 1800, loss is 4.556159839630127 and perplexity is 95.21712781426542
At time: 78.56193733215332 and batch: 1850, loss is 4.58356876373291 and perplexity is 97.8630217551998
At time: 79.56586003303528 and batch: 1900, loss is 4.6735523986816405 and perplexity is 107.07744938793553
At time: 80.57038402557373 and batch: 1950, loss is 4.591510486602783 and perplexity is 98.64331709670688
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.503274607103925 and perplexity of 90.3123851945677
finished 2 epochs...
Completing Train Step...
At time: 83.78114891052246 and batch: 50, loss is 4.56549674987793 and perplexity is 96.11032495256678
At time: 84.79207181930542 and batch: 100, loss is 4.539224729537964 and perplexity is 93.61819255846223
At time: 85.76043391227722 and batch: 150, loss is 4.493477821350098 and perplexity is 89.43193394394595
At time: 86.73247838020325 and batch: 200, loss is 4.484006366729736 and perplexity is 88.58888220552241
At time: 87.73164582252502 and batch: 250, loss is 4.479608888626099 and perplexity is 88.20016983926126
At time: 88.72625637054443 and batch: 300, loss is 4.508760423660278 and perplexity is 90.80918379962314
At time: 89.70879626274109 and batch: 350, loss is 4.504550361633301 and perplexity is 90.4276751542459
At time: 90.69383931159973 and batch: 400, loss is 4.458382053375244 and perplexity is 86.3476900632707
At time: 91.68343424797058 and batch: 450, loss is 4.469324941635132 and perplexity is 87.29777202676034
At time: 92.67271780967712 and batch: 500, loss is 4.4731158256530765 and perplexity is 87.6293358184084
At time: 93.66391348838806 and batch: 550, loss is 4.435543241500855 and perplexity is 84.39796091210322
At time: 94.65571618080139 and batch: 600, loss is 4.422158422470093 and perplexity is 83.27583595115217
At time: 95.65398716926575 and batch: 650, loss is 4.485955991744995 and perplexity is 88.76176578065412
At time: 96.65234470367432 and batch: 700, loss is 4.509211483001709 and perplexity is 90.85015336942269
At time: 97.65057134628296 and batch: 750, loss is 4.466199407577514 and perplexity is 87.02534582759517
At time: 98.67721462249756 and batch: 800, loss is 4.446361904144287 and perplexity is 85.31599095356202
At time: 99.68131113052368 and batch: 850, loss is 4.434547100067139 and perplexity is 84.31393046637046
At time: 100.68673014640808 and batch: 900, loss is 4.432832660675049 and perplexity is 84.16950318396442
At time: 101.69083571434021 and batch: 950, loss is 4.505866050720215 and perplexity is 90.5467281607983
At time: 102.70434880256653 and batch: 1000, loss is 4.482369995117187 and perplexity is 88.44403641658371
At time: 103.7149269580841 and batch: 1050, loss is 4.412106494903565 and perplexity is 82.44294636602451
At time: 104.71921706199646 and batch: 1100, loss is 4.468388652801513 and perplexity is 87.21607434989146
At time: 105.72369265556335 and batch: 1150, loss is 4.414799451828003 and perplexity is 82.66526087666001
At time: 106.72907733917236 and batch: 1200, loss is 4.486809520721436 and perplexity is 88.83755886094171
At time: 107.76090335845947 and batch: 1250, loss is 4.460779733657837 and perplexity is 86.55497261652492
At time: 108.78361558914185 and batch: 1300, loss is 4.466950130462647 and perplexity is 87.09070227551557
At time: 109.78863453865051 and batch: 1350, loss is 4.3575922393798825 and perplexity is 78.06893663510854
At time: 110.79175305366516 and batch: 1400, loss is 4.3757462978363035 and perplexity is 79.49914746056463
At time: 111.79629611968994 and batch: 1450, loss is 4.316592831611633 and perplexity is 74.93288390404592
At time: 112.80159020423889 and batch: 1500, loss is 4.320801591873169 and perplexity is 75.24892304808137
At time: 113.80634880065918 and batch: 1550, loss is 4.320014867782593 and perplexity is 75.18974618851229
At time: 114.81056046485901 and batch: 1600, loss is 4.397841987609863 and perplexity is 81.2752862039058
At time: 115.81462216377258 and batch: 1650, loss is 4.360884208679199 and perplexity is 78.32636066126045
At time: 116.81933879852295 and batch: 1700, loss is 4.391540174484253 and perplexity is 80.76471499039107
At time: 117.82374262809753 and batch: 1750, loss is 4.383950157165527 and perplexity is 80.15402989182054
At time: 118.8274655342102 and batch: 1800, loss is 4.336860218048096 and perplexity is 76.46707209560897
At time: 119.83203625679016 and batch: 1850, loss is 4.369806566238403 and perplexity is 79.02834347123198
At time: 120.83618593215942 and batch: 1900, loss is 4.462744493484497 and perplexity is 86.72519952225207
At time: 121.84091520309448 and batch: 1950, loss is 4.383755121231079 and perplexity is 80.13839850009191
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.427492789335029 and perplexity of 83.72124674719844
finished 3 epochs...
Completing Train Step...
At time: 125.06016612052917 and batch: 50, loss is 4.359894723892212 and perplexity is 78.24889625021451
At time: 126.05692553520203 and batch: 100, loss is 4.343776121139526 and perplexity is 76.997743878063
At time: 127.02954769134521 and batch: 150, loss is 4.303173036575317 and perplexity is 73.93401724401791
At time: 128.00827813148499 and batch: 200, loss is 4.298743381500244 and perplexity is 73.60723934034401
At time: 128.989892244339 and batch: 250, loss is 4.289034900665283 and perplexity is 72.89608257959266
At time: 129.97212433815002 and batch: 300, loss is 4.313273448944091 and perplexity is 74.6845653481452
At time: 130.96379446983337 and batch: 350, loss is 4.312677316665649 and perplexity is 74.64005673586806
At time: 131.96243286132812 and batch: 400, loss is 4.270022687911987 and perplexity is 71.52325831420103
At time: 132.96729803085327 and batch: 450, loss is 4.294893283843994 and perplexity is 73.32438913053821
At time: 133.97095704078674 and batch: 500, loss is 4.302196235656738 and perplexity is 73.86183368828091
At time: 134.97272109985352 and batch: 550, loss is 4.268371868133545 and perplexity is 71.40528370895525
At time: 135.97443532943726 and batch: 600, loss is 4.254536991119385 and perplexity is 70.4242026073774
At time: 136.9792070388794 and batch: 650, loss is 4.318148651123047 and perplexity is 75.0495566842297
At time: 137.9836847782135 and batch: 700, loss is 4.340133447647094 and perplexity is 76.71777646197953
At time: 138.98910999298096 and batch: 750, loss is 4.307537117004395 and perplexity is 74.25737631100053
At time: 139.99337601661682 and batch: 800, loss is 4.283733496665954 and perplexity is 72.51065355605601
At time: 140.99759197235107 and batch: 850, loss is 4.277710285186767 and perplexity is 72.0752192281438
At time: 142.0025188922882 and batch: 900, loss is 4.27089632987976 and perplexity is 71.58577133736041
At time: 143.00707936286926 and batch: 950, loss is 4.354007406234741 and perplexity is 77.78957355763806
At time: 144.008859872818 and batch: 1000, loss is 4.325072498321533 and perplexity is 75.57099143116594
At time: 145.01034379005432 and batch: 1050, loss is 4.2643423175811765 and perplexity is 71.11813144437448
At time: 146.01262974739075 and batch: 1100, loss is 4.31208794593811 and perplexity is 74.59607903218469
At time: 147.01567721366882 and batch: 1150, loss is 4.264950494766236 and perplexity is 71.1613970245988
At time: 148.0186824798584 and batch: 1200, loss is 4.334434189796448 and perplexity is 76.28178566431971
At time: 149.04927277565002 and batch: 1250, loss is 4.312584171295166 and perplexity is 74.63310468391126
At time: 150.05238842964172 and batch: 1300, loss is 4.314318552017212 and perplexity is 74.7626592178687
At time: 151.0558032989502 and batch: 1350, loss is 4.205401687622071 and perplexity is 67.04752441852051
At time: 152.05887055397034 and batch: 1400, loss is 4.2285951805114745 and perplexity is 68.62076464249017
At time: 153.0610899925232 and batch: 1450, loss is 4.166415843963623 and perplexity is 64.4839170059129
At time: 154.06483364105225 and batch: 1500, loss is 4.175874333381653 and perplexity is 65.09673103135782
At time: 155.06819438934326 and batch: 1550, loss is 4.1738462734222415 and perplexity is 64.96484473952268
At time: 156.07086396217346 and batch: 1600, loss is 4.258274583816529 and perplexity is 70.6879121050984
At time: 157.07431507110596 and batch: 1650, loss is 4.218807730674744 and perplexity is 67.95241838880739
At time: 158.07774567604065 and batch: 1700, loss is 4.246038694381713 and perplexity is 69.82825270234578
At time: 159.0809450149536 and batch: 1750, loss is 4.244500160217285 and perplexity is 69.72090215234094
At time: 160.08403396606445 and batch: 1800, loss is 4.1961995792388915 and perplexity is 66.43337589640319
At time: 161.0871729850769 and batch: 1850, loss is 4.233970861434937 and perplexity is 68.99064125653888
At time: 162.09023022651672 and batch: 1900, loss is 4.323795642852783 and perplexity is 75.47455977522334
At time: 163.09410405158997 and batch: 1950, loss is 4.242992630004883 and perplexity is 69.61587497162519
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.394919887808866 and perplexity of 81.03813835984124
finished 4 epochs...
Completing Train Step...
At time: 166.2890853881836 and batch: 50, loss is 4.226898250579834 and perplexity is 68.50441875636339
At time: 167.2876913547516 and batch: 100, loss is 4.213239965438842 and perplexity is 67.57512658676664
At time: 168.26791167259216 and batch: 150, loss is 4.175317521095276 and perplexity is 65.06049446113656
At time: 169.26053953170776 and batch: 200, loss is 4.175712246894836 and perplexity is 65.08618058598707
At time: 170.2631595134735 and batch: 250, loss is 4.157164316177369 and perplexity is 63.89009337933577
At time: 171.28255081176758 and batch: 300, loss is 4.1828622627258305 and perplexity is 65.5532154712946
At time: 172.28647756576538 and batch: 350, loss is 4.185020704269409 and perplexity is 65.69486106675949
At time: 173.31405210494995 and batch: 400, loss is 4.143486714363098 and perplexity is 63.02217914537581
At time: 174.31879544258118 and batch: 450, loss is 4.172688307762146 and perplexity is 64.88966121856967
At time: 175.3225440979004 and batch: 500, loss is 4.1877018117904665 and perplexity is 65.87123238243953
At time: 176.3263223171234 and batch: 550, loss is 4.151529583930969 and perplexity is 63.53110216945562
At time: 177.32906532287598 and batch: 600, loss is 4.143422589302063 and perplexity is 63.018137973863155
At time: 178.333881855011 and batch: 650, loss is 4.205036091804504 and perplexity is 67.02301660426508
At time: 179.33828043937683 and batch: 700, loss is 4.22222665309906 and perplexity is 68.1851400377647
At time: 180.34166765213013 and batch: 750, loss is 4.195430822372437 and perplexity is 66.38232440812637
At time: 181.34463167190552 and batch: 800, loss is 4.173133182525635 and perplexity is 64.91853541348121
At time: 182.34853219985962 and batch: 850, loss is 4.167324395179748 and perplexity is 64.54253056980956
At time: 183.3550124168396 and batch: 900, loss is 4.157401080131531 and perplexity is 63.9052220413663
At time: 184.36005401611328 and batch: 950, loss is 4.244902701377868 and perplexity is 69.74897333473437
At time: 185.36419081687927 and batch: 1000, loss is 4.215281820297241 and perplexity is 67.71324614935767
At time: 186.369145154953 and batch: 1050, loss is 4.1572933721542356 and perplexity is 63.89833930983082
At time: 187.37330436706543 and batch: 1100, loss is 4.198035554885864 and perplexity is 66.55545799227973
At time: 188.38733220100403 and batch: 1150, loss is 4.157078919410705 and perplexity is 63.88463760489541
At time: 189.3920021057129 and batch: 1200, loss is 4.223783354759217 and perplexity is 68.29136661855507
At time: 190.39480113983154 and batch: 1250, loss is 4.209084906578064 and perplexity is 67.29493047705897
At time: 191.39844131469727 and batch: 1300, loss is 4.206292209625244 and perplexity is 67.10725830749716
At time: 192.4018738269806 and batch: 1350, loss is 4.096802916526794 and perplexity is 60.14768271212038
At time: 193.4052495956421 and batch: 1400, loss is 4.123989300727844 and perplexity is 61.80531108933183
At time: 194.4103798866272 and batch: 1450, loss is 4.059690222740174 and perplexity is 57.95635473710971
At time: 195.4138855934143 and batch: 1500, loss is 4.0692608308792115 and perplexity is 58.51369508630931
At time: 196.44571495056152 and batch: 1550, loss is 4.070368900299072 and perplexity is 58.57856825782855
At time: 197.4590356349945 and batch: 1600, loss is 4.1605782270431515 and perplexity is 64.10858120010967
At time: 198.46228122711182 and batch: 1650, loss is 4.120386543273926 and perplexity is 61.58304217502516
At time: 199.46566796302795 and batch: 1700, loss is 4.1449579238891605 and perplexity is 63.11496621356088
At time: 200.469407081604 and batch: 1750, loss is 4.143253355026245 and perplexity is 63.00747404729615
At time: 201.4731695652008 and batch: 1800, loss is 4.093086504936219 and perplexity is 59.924564024186
At time: 202.477787733078 and batch: 1850, loss is 4.138439636230469 and perplexity is 62.704902616354794
At time: 203.48184370994568 and batch: 1900, loss is 4.223863649368286 and perplexity is 68.29685026729129
At time: 204.4857199192047 and batch: 1950, loss is 4.1430713129043575 and perplexity is 62.9960050769753
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3807117550872094 and perplexity of 79.89487875909853
finished 5 epochs...
Completing Train Step...
At time: 207.6892499923706 and batch: 50, loss is 4.128482618331909 and perplexity is 62.08364683883829
At time: 208.6633174419403 and batch: 100, loss is 4.11229597568512 and perplexity is 61.08681051470601
At time: 209.65770506858826 and batch: 150, loss is 4.084412655830383 and perplexity is 59.407035126604875
At time: 210.65412259101868 and batch: 200, loss is 4.082687373161316 and perplexity is 59.304629563153895
At time: 211.65155339241028 and batch: 250, loss is 4.063998727798462 and perplexity is 58.20659868620383
At time: 212.65028595924377 and batch: 300, loss is 4.0844545078277585 and perplexity is 59.40952148171217
At time: 213.6671941280365 and batch: 350, loss is 4.090274229049682 and perplexity is 59.75627636434758
At time: 214.67123222351074 and batch: 400, loss is 4.050102372169494 and perplexity is 57.40333324842208
At time: 215.67459201812744 and batch: 450, loss is 4.083639464378357 and perplexity is 59.361119867785014
At time: 216.67643427848816 and batch: 500, loss is 4.098784351348877 and perplexity is 60.26697957556268
At time: 217.6792507171631 and batch: 550, loss is 4.0646080493927 and perplexity is 58.24207603116904
At time: 218.68211817741394 and batch: 600, loss is 4.055296306610107 and perplexity is 57.702258023823724
At time: 219.702641248703 and batch: 650, loss is 4.117596592903137 and perplexity is 61.41146799668777
At time: 220.70554065704346 and batch: 700, loss is 4.134897041320801 and perplexity is 62.48315755590396
At time: 221.70933938026428 and batch: 750, loss is 4.110408177375794 and perplexity is 60.971599718682704
At time: 222.7149178981781 and batch: 800, loss is 4.087814559936524 and perplexity is 59.609476310846865
At time: 223.77820301055908 and batch: 850, loss is 4.084291319847107 and perplexity is 59.39982735287428
At time: 224.7820167541504 and batch: 900, loss is 4.071949439048767 and perplexity is 58.671227161065964
At time: 225.78527736663818 and batch: 950, loss is 4.162389760017395 and perplexity is 64.22482126345119
At time: 226.7862410545349 and batch: 1000, loss is 4.130429692268372 and perplexity is 62.20464604845579
At time: 227.78808045387268 and batch: 1050, loss is 4.0759760808944705 and perplexity is 58.90795146162792
At time: 228.7918438911438 and batch: 1100, loss is 4.112781553268433 and perplexity is 61.11648010338865
At time: 229.79460859298706 and batch: 1150, loss is 4.071351847648621 and perplexity is 58.636176214393714
At time: 230.79725980758667 and batch: 1200, loss is 4.138774256706238 and perplexity is 62.72588847165395
At time: 231.80025506019592 and batch: 1250, loss is 4.127742276191712 and perplexity is 62.03770070889306
At time: 232.81786251068115 and batch: 1300, loss is 4.124282689094543 and perplexity is 61.823446708865454
At time: 233.82271933555603 and batch: 1350, loss is 4.018489513397217 and perplexity is 55.61703356368231
At time: 234.8267743587494 and batch: 1400, loss is 4.045056419372559 and perplexity is 57.11440830232536
At time: 235.82939624786377 and batch: 1450, loss is 3.979262671470642 and perplexity is 53.477589135131616
At time: 236.8326051235199 and batch: 1500, loss is 3.9873875761032105 and perplexity is 53.913859373880776
At time: 237.8360161781311 and batch: 1550, loss is 3.9949711751937866 and perplexity is 54.32427471455314
At time: 238.8388636112213 and batch: 1600, loss is 4.086937160491943 and perplexity is 59.55719792730612
At time: 239.8419988155365 and batch: 1650, loss is 4.045217590332031 and perplexity is 57.123614228155176
At time: 240.84487891197205 and batch: 1700, loss is 4.065858860015869 and perplexity is 58.31497141824257
At time: 241.84869527816772 and batch: 1750, loss is 4.0657430934906005 and perplexity is 58.30822088738066
At time: 242.85214233398438 and batch: 1800, loss is 4.0180060052871704 and perplexity is 55.59014877692752
At time: 243.86613726615906 and batch: 1850, loss is 4.058081712722778 and perplexity is 57.86320629512797
At time: 244.88810086250305 and batch: 1900, loss is 4.146531820297241 and perplexity is 63.21438084582478
At time: 245.88872075080872 and batch: 1950, loss is 4.067059440612793 and perplexity is 58.385025285679895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37625363372093 and perplexity of 79.53949046372986
finished 6 epochs...
Completing Train Step...
At time: 249.10474753379822 and batch: 50, loss is 4.052473001480102 and perplexity is 57.53957670030157
At time: 250.07838439941406 and batch: 100, loss is 4.035927748680114 and perplexity is 56.595402199214526
At time: 251.0555510520935 and batch: 150, loss is 4.004388628005981 and perplexity is 54.83828755515994
At time: 252.03846740722656 and batch: 200, loss is 4.011708836555481 and perplexity is 55.24118811549186
At time: 253.02200722694397 and batch: 250, loss is 3.9894267606735228 and perplexity is 54.023911854566556
At time: 254.004576921463 and batch: 300, loss is 4.005861582756043 and perplexity is 54.91912138897458
At time: 255.00290393829346 and batch: 350, loss is 4.0131294298172 and perplexity is 55.319719142214886
At time: 256.00474762916565 and batch: 400, loss is 3.9743586492538454 and perplexity is 53.21597585289043
At time: 257.0056347846985 and batch: 450, loss is 4.011466031074524 and perplexity is 55.227776880469385
At time: 257.99485445022583 and batch: 500, loss is 4.031362814903259 and perplexity is 56.33763672488368
At time: 258.98481798171997 and batch: 550, loss is 3.9909432458877565 and perplexity is 54.10590046965771
At time: 259.97449135780334 and batch: 600, loss is 3.985325574874878 and perplexity is 53.80280346768459
At time: 260.9692931175232 and batch: 650, loss is 4.050704584121704 and perplexity is 57.437912632815234
At time: 261.96746301651 and batch: 700, loss is 4.0676805210113525 and perplexity is 58.42129834353085
At time: 262.9663405418396 and batch: 750, loss is 4.039744706153869 and perplexity is 56.81183724152206
At time: 263.9753170013428 and batch: 800, loss is 4.024055976867675 and perplexity is 55.9274870116088
At time: 264.9762177467346 and batch: 850, loss is 4.016073217391968 and perplexity is 55.48280857661451
At time: 265.9746205806732 and batch: 900, loss is 4.00131736278534 and perplexity is 54.67012300099224
At time: 266.97334814071655 and batch: 950, loss is 4.096374869346619 and perplexity is 60.12194217561642
At time: 267.9708869457245 and batch: 1000, loss is 4.060807690620423 and perplexity is 58.0211553015162
At time: 268.96960377693176 and batch: 1050, loss is 4.012050514221191 and perplexity is 55.260066020593825
At time: 269.967178106308 and batch: 1100, loss is 4.045015215873718 and perplexity is 57.112055037350814
At time: 270.9651916027069 and batch: 1150, loss is 4.003562264442444 and perplexity is 54.79298991117654
At time: 271.9642312526703 and batch: 1200, loss is 4.0738791608810425 and perplexity is 58.78455562007789
At time: 272.9615652561188 and batch: 1250, loss is 4.063691816329956 and perplexity is 58.188737154618956
At time: 273.95808386802673 and batch: 1300, loss is 4.058134379386902 and perplexity is 57.8662538374303
At time: 274.9560992717743 and batch: 1350, loss is 3.9509026622772216 and perplexity is 51.98226809614198
At time: 275.9592835903168 and batch: 1400, loss is 3.982229871749878 and perplexity is 53.63650350132828
At time: 276.96378660202026 and batch: 1450, loss is 3.9136929512023926 and perplexity is 50.08356704550917
At time: 277.96897864341736 and batch: 1500, loss is 3.928327007293701 and perplexity is 50.82188186903556
At time: 278.9729356765747 and batch: 1550, loss is 3.9299432229995728 and perplexity is 50.904087405759576
At time: 279.97527861595154 and batch: 1600, loss is 4.022771344184876 and perplexity is 55.85568686221031
At time: 280.9788439273834 and batch: 1650, loss is 3.9871159172058106 and perplexity is 53.899215183491066
At time: 281.98413348197937 and batch: 1700, loss is 4.00287700176239 and perplexity is 54.755455182105194
At time: 282.989444732666 and batch: 1750, loss is 4.001161193847656 and perplexity is 54.66158589259305
At time: 283.99432468414307 and batch: 1800, loss is 3.954089002609253 and perplexity is 52.14816545589164
At time: 284.998304605484 and batch: 1850, loss is 3.9971288299560546 and perplexity is 54.4416142882201
At time: 286.0033872127533 and batch: 1900, loss is 4.08351888179779 and perplexity is 59.35396238230873
At time: 287.00730443000793 and batch: 1950, loss is 4.004585795402527 and perplexity is 54.84910094353699
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377838560592297 and perplexity of 79.66565469362942
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 290.2298846244812 and batch: 50, loss is 4.022197117805481 and perplexity is 55.82362226042599
At time: 291.20104575157166 and batch: 100, loss is 4.020622496604919 and perplexity is 55.735790370448356
At time: 292.17306780815125 and batch: 150, loss is 3.9912103366851808 and perplexity is 54.12035358782102
At time: 293.1446945667267 and batch: 200, loss is 3.995301022529602 and perplexity is 54.34219638738338
At time: 294.1186742782593 and batch: 250, loss is 3.9767179679870606 and perplexity is 53.341677528476836
At time: 295.1008884906769 and batch: 300, loss is 3.9826324701309206 and perplexity is 53.658101818234684
At time: 296.0837664604187 and batch: 350, loss is 3.992995820045471 and perplexity is 54.21707089648358
At time: 297.06809520721436 and batch: 400, loss is 3.9504108810424805 and perplexity is 51.95671047704684
At time: 298.0832076072693 and batch: 450, loss is 3.9722452640533445 and perplexity is 53.103628755255016
At time: 299.07510709762573 and batch: 500, loss is 3.9850746297836306 and perplexity is 53.789303612191105
At time: 300.074177980423 and batch: 550, loss is 3.9457330560684203 and perplexity is 51.71423365343512
At time: 301.07305002212524 and batch: 600, loss is 3.9218642616271975 and perplexity is 50.49449203036251
At time: 302.0709071159363 and batch: 650, loss is 3.971897678375244 and perplexity is 53.085173901951684
At time: 303.0670475959778 and batch: 700, loss is 4.000162205696106 and perplexity is 54.60700688237274
At time: 304.07983446121216 and batch: 750, loss is 3.956745538711548 and perplexity is 52.28688311274574
At time: 305.07904529571533 and batch: 800, loss is 3.9394928121566775 and perplexity is 51.39252902335656
At time: 306.0761287212372 and batch: 850, loss is 3.929757194519043 and perplexity is 50.8946186764807
At time: 307.0724630355835 and batch: 900, loss is 3.897467074394226 and perplexity is 49.27747471943078
At time: 308.0793719291687 and batch: 950, loss is 3.9918800497055056 and perplexity is 54.156610832902764
At time: 309.09984731674194 and batch: 1000, loss is 3.956028690338135 and perplexity is 52.24941477679787
At time: 310.0961329936981 and batch: 1050, loss is 3.900521321296692 and perplexity is 49.42821036872174
At time: 311.0928452014923 and batch: 1100, loss is 3.9201242113113404 and perplexity is 50.406705472219976
At time: 312.08966588974 and batch: 1150, loss is 3.8797573471069335 and perplexity is 48.41246622096756
At time: 313.0922386646271 and batch: 1200, loss is 3.9309688425064087 and perplexity is 50.956322412822885
At time: 314.0970525741577 and batch: 1250, loss is 3.912511420249939 and perplexity is 50.02442670578665
At time: 315.0936665534973 and batch: 1300, loss is 3.911888837814331 and perplexity is 49.99329206931284
At time: 316.091689825058 and batch: 1350, loss is 3.8024589729309084 and perplexity is 44.811238750715326
At time: 317.08799481391907 and batch: 1400, loss is 3.8233099794387817 and perplexity is 45.75540740760254
At time: 318.10810685157776 and batch: 1450, loss is 3.7402429389953613 and perplexity is 42.108218650833045
At time: 319.1403121948242 and batch: 1500, loss is 3.7590215396881104 and perplexity is 42.906423200861326
At time: 320.14802861213684 and batch: 1550, loss is 3.759467487335205 and perplexity is 42.92556148635252
At time: 321.16052746772766 and batch: 1600, loss is 3.840270652770996 and perplexity is 46.53806839258549
At time: 322.16234064102173 and batch: 1650, loss is 3.7944624042510986 and perplexity is 44.45433152087641
At time: 323.16362738609314 and batch: 1700, loss is 3.797157783508301 and perplexity is 44.574314431033855
At time: 324.1634256839752 and batch: 1750, loss is 3.788386278152466 and perplexity is 44.18504034898711
At time: 325.1601355075836 and batch: 1800, loss is 3.7452307319641114 and perplexity is 42.318770385467005
At time: 326.15873980522156 and batch: 1850, loss is 3.77356782913208 and perplexity is 43.53511392477917
At time: 327.1561028957367 and batch: 1900, loss is 3.8482993841171265 and perplexity is 46.91321399754489
At time: 328.15213656425476 and batch: 1950, loss is 3.769701771736145 and perplexity is 43.36712960335155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.297562000363372 and perplexity of 73.5203324814197
finished 8 epochs...
Completing Train Step...
At time: 331.3110864162445 and batch: 50, loss is 3.9292905139923096 and perplexity is 50.87087269035449
At time: 332.3036286830902 and batch: 100, loss is 3.919785904884338 and perplexity is 50.38965544402439
At time: 333.27415585517883 and batch: 150, loss is 3.8869800329208375 and perplexity is 48.76340007082592
At time: 334.24299359321594 and batch: 200, loss is 3.8922158908843993 and perplexity is 49.01938788051474
At time: 335.211874961853 and batch: 250, loss is 3.8713252115249634 and perplexity is 48.005961999853845
At time: 336.1860091686249 and batch: 300, loss is 3.8785688972473142 and perplexity is 48.35496460794339
At time: 337.1665596961975 and batch: 350, loss is 3.8931646871566774 and perplexity is 49.06591936396345
At time: 338.15006709098816 and batch: 400, loss is 3.852795090675354 and perplexity is 47.124596842975336
At time: 339.1339180469513 and batch: 450, loss is 3.88194531917572 and perplexity is 48.518507310007074
At time: 340.1167736053467 and batch: 500, loss is 3.8983535814285277 and perplexity is 49.32117891657903
At time: 341.098863363266 and batch: 550, loss is 3.8618032693862916 and perplexity is 47.551021403747164
At time: 342.08213567733765 and batch: 600, loss is 3.8450536251068117 and perplexity is 46.76119185758693
At time: 343.0651307106018 and batch: 650, loss is 3.8953992986679076 and perplexity is 49.1756852285393
At time: 344.0479853153229 and batch: 700, loss is 3.9247285079956056 and perplexity is 50.63932801974499
At time: 345.0318343639374 and batch: 750, loss is 3.8876077127456665 and perplexity is 48.79401748120061
At time: 346.0219147205353 and batch: 800, loss is 3.870427360534668 and perplexity is 47.96287914321917
At time: 347.01966619491577 and batch: 850, loss is 3.862280025482178 and perplexity is 47.57369704801333
At time: 348.05916833877563 and batch: 900, loss is 3.83115394115448 and perplexity is 46.11572237254416
At time: 349.0580880641937 and batch: 950, loss is 3.9284483671188353 and perplexity is 50.82804997800492
At time: 350.0565097332001 and batch: 1000, loss is 3.8959480333328247 and perplexity is 49.202677036688364
At time: 351.0572645664215 and batch: 1050, loss is 3.843242630958557 and perplexity is 46.67658424783447
At time: 352.0565333366394 and batch: 1100, loss is 3.865122232437134 and perplexity is 47.70910367631372
At time: 353.05614137649536 and batch: 1150, loss is 3.828091640472412 and perplexity is 45.974718173287506
At time: 354.0557556152344 and batch: 1200, loss is 3.881961078643799 and perplexity is 48.51927194189934
At time: 355.05526304244995 and batch: 1250, loss is 3.866686015129089 and perplexity is 47.783768711620795
At time: 356.05371832847595 and batch: 1300, loss is 3.868673939704895 and perplexity is 47.87885371936567
At time: 357.0521981716156 and batch: 1350, loss is 3.7587081956863404 and perplexity is 42.89298083666601
At time: 358.05135130882263 and batch: 1400, loss is 3.784964346885681 and perplexity is 44.0341005779409
At time: 359.04934430122375 and batch: 1450, loss is 3.7040748739242555 and perplexity is 40.61245828810193
At time: 360.04759311676025 and batch: 1500, loss is 3.7247277784347532 and perplexity is 41.459944917404975
At time: 361.0460557937622 and batch: 1550, loss is 3.7282498502731323 and perplexity is 41.60622727909335
At time: 362.0456030368805 and batch: 1600, loss is 3.8130380296707154 and perplexity is 45.28781581119627
At time: 363.0447664260864 and batch: 1650, loss is 3.7706373929977417 and perplexity is 43.40772379929797
At time: 364.05262756347656 and batch: 1700, loss is 3.7789379119873048 and perplexity is 43.769529947061606
At time: 365.05700063705444 and batch: 1750, loss is 3.771932668685913 and perplexity is 43.46398519775886
At time: 366.0545699596405 and batch: 1800, loss is 3.73265748500824 and perplexity is 41.790017073241785
At time: 367.0515630245209 and batch: 1850, loss is 3.765065336227417 and perplexity is 43.16652610569334
At time: 368.04926228523254 and batch: 1900, loss is 3.841353621482849 and perplexity is 46.58849496483627
At time: 369.0479292869568 and batch: 1950, loss is 3.7643682098388673 and perplexity is 43.136444067952496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.29618033475654 and perplexity of 73.41882210947077
finished 9 epochs...
Completing Train Step...
At time: 372.2439978122711 and batch: 50, loss is 3.885252208709717 and perplexity is 48.67921823421758
At time: 373.2459976673126 and batch: 100, loss is 3.8741702318191527 and perplexity is 48.14273440386348
At time: 374.237468957901 and batch: 150, loss is 3.8406463050842286 and perplexity is 46.555553809643584
At time: 375.22317695617676 and batch: 200, loss is 3.8458823204040526 and perplexity is 46.79995869810336
At time: 376.198579788208 and batch: 250, loss is 3.824636015892029 and perplexity is 45.816120991074214
At time: 377.17286682128906 and batch: 300, loss is 3.8322710466384886 and perplexity is 46.16726728409688
At time: 378.15300846099854 and batch: 350, loss is 3.8480331659317017 and perplexity is 46.90072650911402
At time: 379.1365818977356 and batch: 400, loss is 3.8079188156127928 and perplexity is 45.05657019076692
At time: 380.1206419467926 and batch: 450, loss is 3.8406143045425414 and perplexity is 46.554064030540125
At time: 381.1038489341736 and batch: 500, loss is 3.8581545829772947 and perplexity is 47.37783877489986
At time: 382.086585521698 and batch: 550, loss is 3.822338981628418 and perplexity is 45.711000570157445
At time: 383.070645570755 and batch: 600, loss is 3.8074480962753294 and perplexity is 45.035366182858155
At time: 384.05450773239136 and batch: 650, loss is 3.8568666219711303 and perplexity is 47.31685724534742
At time: 385.0378851890564 and batch: 700, loss is 3.8864888668060305 and perplexity is 48.73945502204802
At time: 386.02180671691895 and batch: 750, loss is 3.8516360473632814 and perplexity is 47.07000903509822
At time: 387.00523829460144 and batch: 800, loss is 3.8328552436828613 and perplexity is 46.194245944850664
At time: 387.9897587299347 and batch: 850, loss is 3.82669234752655 and perplexity is 45.91043106319909
At time: 388.97389101982117 and batch: 900, loss is 3.796611886024475 and perplexity is 44.549988065397706
At time: 389.9581985473633 and batch: 950, loss is 3.8950408506393432 and perplexity is 49.158061459907096
At time: 390.9425723552704 and batch: 1000, loss is 3.863081684112549 and perplexity is 47.611850203690516
At time: 391.92635774612427 and batch: 1050, loss is 3.812182655334473 and perplexity is 45.249094338844685
At time: 392.9089787006378 and batch: 1100, loss is 3.8358607959747313 and perplexity is 46.33329402007959
At time: 393.8924722671509 and batch: 1150, loss is 3.799054799079895 and perplexity is 44.6589528544241
At time: 394.8800427913666 and batch: 1200, loss is 3.853370909690857 and perplexity is 47.151739895928465
At time: 395.87063241004944 and batch: 1250, loss is 3.839878058433533 and perplexity is 46.519801396452316
At time: 396.8608088493347 and batch: 1300, loss is 3.8414534282684327 and perplexity is 46.593145044814804
At time: 397.8505742549896 and batch: 1350, loss is 3.7320668935775756 and perplexity is 41.765343533978616
At time: 398.8401827812195 and batch: 1400, loss is 3.761055269241333 and perplexity is 42.99377205361299
At time: 399.83057975769043 and batch: 1450, loss is 3.679913196563721 and perplexity is 39.642952778691246
At time: 400.82309651374817 and batch: 1500, loss is 3.7013175821304323 and perplexity is 40.50063212965966
At time: 401.81407833099365 and batch: 1550, loss is 3.706112432479858 and perplexity is 40.69529291149038
At time: 402.80554485321045 and batch: 1600, loss is 3.7926813173294067 and perplexity is 44.37522496113379
At time: 403.79706835746765 and batch: 1650, loss is 3.751439514160156 and perplexity is 42.58233577696914
At time: 404.78758692741394 and batch: 1700, loss is 3.761751012802124 and perplexity is 43.023695101850436
At time: 405.77843594551086 and batch: 1750, loss is 3.7555425214767455 and perplexity is 42.75741033270094
At time: 406.76912212371826 and batch: 1800, loss is 3.718046951293945 and perplexity is 41.18388138531816
At time: 407.7607202529907 and batch: 1850, loss is 3.7519328737258912 and perplexity is 42.60334936285662
At time: 408.75405168533325 and batch: 1900, loss is 3.8284523773193357 and perplexity is 45.991305939888974
At time: 409.7580347061157 and batch: 1950, loss is 3.751592655181885 and perplexity is 42.58885737872724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.29861691497093 and perplexity of 73.59793107685657
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 412.9399719238281 and batch: 50, loss is 3.8764718675613405 and perplexity is 48.25366905870411
At time: 413.93431329727173 and batch: 100, loss is 3.886454644203186 and perplexity is 48.737787059577116
At time: 414.90156078338623 and batch: 150, loss is 3.855017080307007 and perplexity is 47.2294236274408
At time: 415.86869859695435 and batch: 200, loss is 3.8658066320419313 and perplexity is 47.741766944103844
At time: 416.8419117927551 and batch: 250, loss is 3.852322974205017 and perplexity is 47.10235379571542
At time: 417.8212516307831 and batch: 300, loss is 3.853980612754822 and perplexity is 47.180497222038376
At time: 418.8044226169586 and batch: 350, loss is 3.8699975347518922 and perplexity is 47.94226789108836
At time: 419.7880971431732 and batch: 400, loss is 3.838500642776489 and perplexity is 46.45576840379362
At time: 420.77073216438293 and batch: 450, loss is 3.8708615589141844 and perplexity is 47.98370906945294
At time: 421.7543053627014 and batch: 500, loss is 3.8814202451705935 and perplexity is 48.49303819022257
At time: 422.7600209712982 and batch: 550, loss is 3.8455647325515745 and perplexity is 46.785097959644276
At time: 423.74432015419006 and batch: 600, loss is 3.8188293027877807 and perplexity is 45.550850840123026
At time: 424.7270414829254 and batch: 650, loss is 3.857573165893555 and perplexity is 47.350300496434
At time: 425.7097885608673 and batch: 700, loss is 3.8862856912612913 and perplexity is 48.72955336264521
At time: 426.7055809497833 and batch: 750, loss is 3.847941560745239 and perplexity is 46.89643035609488
At time: 427.69055104255676 and batch: 800, loss is 3.8306644916534425 and perplexity is 46.09315657809783
At time: 428.68386721611023 and batch: 850, loss is 3.826422061920166 and perplexity is 45.89802381132614
At time: 429.6677529811859 and batch: 900, loss is 3.790867118835449 and perplexity is 44.29479247714665
At time: 430.6494493484497 and batch: 950, loss is 3.8891545295715333 and perplexity is 48.86955129186635
At time: 431.63056778907776 and batch: 1000, loss is 3.856518030166626 and perplexity is 47.300365851246205
At time: 432.61264157295227 and batch: 1050, loss is 3.8005766534805296 and perplexity is 44.726969020576874
At time: 433.5943727493286 and batch: 1100, loss is 3.824222354888916 and perplexity is 45.79717256788837
At time: 434.5773894786835 and batch: 1150, loss is 3.784464731216431 and perplexity is 44.01210594619966
At time: 435.5877079963684 and batch: 1200, loss is 3.8347132349014283 and perplexity is 46.280154231872075
At time: 436.59709191322327 and batch: 1250, loss is 3.8195272731781005 and perplexity is 45.582655083182125
At time: 437.5852165222168 and batch: 1300, loss is 3.8139691162109375 and perplexity is 45.33000232353334
At time: 438.5729546546936 and batch: 1350, loss is 3.704148235321045 and perplexity is 40.61543778405765
At time: 439.5610818862915 and batch: 1400, loss is 3.7280073308944703 and perplexity is 41.59613818615488
At time: 440.5496759414673 and batch: 1450, loss is 3.640182361602783 and perplexity is 38.098783847222094
At time: 441.56805539131165 and batch: 1500, loss is 3.665276064872742 and perplexity is 39.066919678765466
At time: 442.574581861496 and batch: 1550, loss is 3.675083956718445 and perplexity is 39.45196897601267
At time: 443.5681371688843 and batch: 1600, loss is 3.757269539833069 and perplexity is 42.83131696590102
At time: 444.57509326934814 and batch: 1650, loss is 3.7066604566574095 and perplexity is 40.7176010280537
At time: 445.5720283985138 and batch: 1700, loss is 3.7091132164001466 and perplexity is 40.81759410003679
At time: 446.56595611572266 and batch: 1750, loss is 3.700062003135681 and perplexity is 40.44981229751675
At time: 447.560964345932 and batch: 1800, loss is 3.6651116704940794 and perplexity is 39.06049782465144
At time: 448.5552613735199 and batch: 1850, loss is 3.6937962770462036 and perplexity is 40.19715721365346
At time: 449.54785537719727 and batch: 1900, loss is 3.7696871519088746 and perplexity is 43.366495588042135
At time: 450.542298078537 and batch: 1950, loss is 3.696055221557617 and perplexity is 40.28806299822082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.269817405523256 and perplexity of 71.5085773558071
finished 11 epochs...
Completing Train Step...
At time: 453.7549560070038 and batch: 50, loss is 3.8659427785873413 and perplexity is 47.748267263233004
At time: 454.7232811450958 and batch: 100, loss is 3.8606156587600706 and perplexity is 47.49458282560148
At time: 455.69027972221375 and batch: 150, loss is 3.822954897880554 and perplexity is 45.73916339038905
At time: 456.65720677375793 and batch: 200, loss is 3.830344181060791 and perplexity is 46.078394816097706
At time: 457.6233162879944 and batch: 250, loss is 3.8152467250823974 and perplexity is 45.38795334813404
At time: 458.59307742118835 and batch: 300, loss is 3.8147190380096436 and perplexity is 45.36400903000267
At time: 459.56518149375916 and batch: 350, loss is 3.831306176185608 and perplexity is 46.12274333537972
At time: 460.5387568473816 and batch: 400, loss is 3.8003963232040405 and perplexity is 44.71890412108151
At time: 461.5181863307953 and batch: 450, loss is 3.833635678291321 and perplexity is 46.23031160471172
At time: 462.5012695789337 and batch: 500, loss is 3.844702181816101 and perplexity is 46.744760837897886
At time: 463.48604941368103 and batch: 550, loss is 3.8109689950942993 and perplexity is 45.194210623969894
At time: 464.48802638053894 and batch: 600, loss is 3.787170581817627 and perplexity is 44.131357395076876
At time: 465.4719092845917 and batch: 650, loss is 3.8284733057022096 and perplexity is 45.99226847362065
At time: 466.45562195777893 and batch: 700, loss is 3.8579739046096804 and perplexity is 47.36927939759936
At time: 467.43981528282166 and batch: 750, loss is 3.821955752372742 and perplexity is 45.693486133669325
At time: 468.42395544052124 and batch: 800, loss is 3.80455687046051 and perplexity is 44.90534681781409
At time: 469.4071617126465 and batch: 850, loss is 3.8022345018386843 and perplexity is 44.80118105188259
At time: 470.38973474502563 and batch: 900, loss is 3.766562695503235 and perplexity is 43.23121031963079
At time: 471.41524505615234 and batch: 950, loss is 3.8660000801086425 and perplexity is 47.75100338997805
At time: 472.39757561683655 and batch: 1000, loss is 3.834446220397949 and perplexity is 46.26779840913426
At time: 473.38180017471313 and batch: 1050, loss is 3.780341558456421 and perplexity is 43.83101003128412
At time: 474.36518120765686 and batch: 1100, loss is 3.8045151090621947 and perplexity is 44.90347154689638
At time: 475.34877824783325 and batch: 1150, loss is 3.7667123794555666 and perplexity is 43.237681822383486
At time: 476.33314752578735 and batch: 1200, loss is 3.8182341861724853 and perplexity is 45.523750836578245
At time: 477.31696462631226 and batch: 1250, loss is 3.8047217559814452 and perplexity is 44.912751669776576
At time: 478.3000342845917 and batch: 1300, loss is 3.8011085987091064 and perplexity is 44.75076764755792
At time: 479.2863736152649 and batch: 1350, loss is 3.692776093482971 and perplexity is 40.156169645551955
At time: 480.27004194259644 and batch: 1400, loss is 3.718918604850769 and perplexity is 41.21979511190137
At time: 481.2549250125885 and batch: 1450, loss is 3.632429542541504 and perplexity is 37.80455290299348
At time: 482.2391400337219 and batch: 1500, loss is 3.65852915763855 and perplexity is 38.80422597728525
At time: 483.23368072509766 and batch: 1550, loss is 3.6698097085952757 and perplexity is 39.24443727062698
At time: 484.23435068130493 and batch: 1600, loss is 3.7540547275543212 and perplexity is 42.69384341643081
At time: 485.22204542160034 and batch: 1650, loss is 3.7049999713897703 and perplexity is 40.6500461538716
At time: 486.2031590938568 and batch: 1700, loss is 3.7097234392166136 and perplexity is 40.84250952847823
At time: 487.18651366233826 and batch: 1750, loss is 3.7016291856765746 and perplexity is 40.51325423669679
At time: 488.16930103302 and batch: 1800, loss is 3.6689477825164794 and perplexity is 39.210626040179626
At time: 489.15082478523254 and batch: 1850, loss is 3.6983603620529175 and perplexity is 40.38103976479945
At time: 490.1324939727783 and batch: 1900, loss is 3.775510063171387 and perplexity is 43.61975147130458
At time: 491.11326026916504 and batch: 1950, loss is 3.701845326423645 and perplexity is 40.5220117481272
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268570868913518 and perplexity of 71.41949483007271
finished 12 epochs...
Completing Train Step...
At time: 494.26956510543823 and batch: 50, loss is 3.8524137926101685 and perplexity is 47.10663175062161
At time: 495.22514629364014 and batch: 100, loss is 3.8452765274047853 and perplexity is 46.77161619646936
At time: 496.2178301811218 and batch: 150, loss is 3.806846466064453 and perplexity is 45.00827969484643
At time: 497.1824426651001 and batch: 200, loss is 3.81336305141449 and perplexity is 45.302537728404964
At time: 498.1574637889862 and batch: 250, loss is 3.7978403902053834 and perplexity is 44.60475154368896
At time: 499.1377990245819 and batch: 300, loss is 3.7974587297439575 and perplexity is 44.587730921888806
At time: 500.11916947364807 and batch: 350, loss is 3.81374587059021 and perplexity is 45.31988372853508
At time: 501.0998692512512 and batch: 400, loss is 3.7832403945922852 and perplexity is 43.958253286602776
At time: 502.08123803138733 and batch: 450, loss is 3.8168761491775514 and perplexity is 45.46196985871581
At time: 503.06246423721313 and batch: 500, loss is 3.828393120765686 and perplexity is 45.988580734345064
At time: 504.0416874885559 and batch: 550, loss is 3.7951094055175782 and perplexity is 44.48310283620598
At time: 505.0224325656891 and batch: 600, loss is 3.772252802848816 and perplexity is 43.47790173173669
At time: 506.002681016922 and batch: 650, loss is 3.8140846586227415 and perplexity is 45.33524016391941
At time: 506.9833207130432 and batch: 700, loss is 3.843950042724609 and perplexity is 46.709615494699364
At time: 507.9648103713989 and batch: 750, loss is 3.808608903884888 and perplexity is 45.08767393236569
At time: 508.94543290138245 and batch: 800, loss is 3.7912447118759154 and perplexity is 44.311521040610735
At time: 509.9260997772217 and batch: 850, loss is 3.7897290897369387 and perplexity is 44.24441238683688
At time: 510.9066815376282 and batch: 900, loss is 3.753950762748718 and perplexity is 42.68940499002363
At time: 511.88786149024963 and batch: 950, loss is 3.854094138145447 and perplexity is 47.18585371045835
At time: 512.868558883667 and batch: 1000, loss is 3.8229004669189455 and perplexity is 45.7366738314977
At time: 513.849821805954 and batch: 1050, loss is 3.7698893260955813 and perplexity is 43.37526406036748
At time: 514.8323745727539 and batch: 1100, loss is 3.7937999391555786 and perplexity is 44.424891830359506
At time: 515.8137888908386 and batch: 1150, loss is 3.7567562580108644 and perplexity is 42.80933807064759
At time: 516.7941317558289 and batch: 1200, loss is 3.809140529632568 and perplexity is 45.111650073333394
At time: 517.7728788852692 and batch: 1250, loss is 3.796064143180847 and perplexity is 44.52559281002437
At time: 518.7551422119141 and batch: 1300, loss is 3.7929254293441774 and perplexity is 44.38605880898737
At time: 519.7354180812836 and batch: 1350, loss is 3.6854035234451294 and perplexity is 39.86120413539433
At time: 520.7153751850128 and batch: 1400, loss is 3.712473363876343 and perplexity is 40.954977921524936
At time: 521.7001187801361 and batch: 1450, loss is 3.626571969985962 and perplexity is 37.583757285920235
At time: 522.6876916885376 and batch: 1500, loss is 3.652894368171692 and perplexity is 38.58618721165825
At time: 523.6760203838348 and batch: 1550, loss is 3.664851522445679 and perplexity is 39.050337634006986
At time: 524.6641223430634 and batch: 1600, loss is 3.75001398563385 and perplexity is 42.52167668850508
At time: 525.6524906158447 and batch: 1650, loss is 3.701663761138916 and perplexity is 40.51465502540929
At time: 526.6411905288696 and batch: 1700, loss is 3.707225828170776 and perplexity is 40.7406281085819
At time: 527.6304814815521 and batch: 1750, loss is 3.6995041799545287 and perplexity is 40.42725474669125
At time: 528.6193137168884 and batch: 1800, loss is 3.6678137445449828 and perplexity is 39.16618490509401
At time: 529.6089751720428 and batch: 1850, loss is 3.697549810409546 and perplexity is 40.34832210812351
At time: 530.5980055332184 and batch: 1900, loss is 3.775459399223328 and perplexity is 43.617541578463104
At time: 531.5869326591492 and batch: 1950, loss is 3.7015976428985597 and perplexity is 40.5119763562658
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268751703306686 and perplexity of 71.4324110988983
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 534.7996380329132 and batch: 50, loss is 3.850795392990112 and perplexity is 47.03045605368049
At time: 535.7571983337402 and batch: 100, loss is 3.856998462677002 and perplexity is 47.323095944454494
At time: 536.7152991294861 and batch: 150, loss is 3.8219655990600585 and perplexity is 45.693936065354855
At time: 537.6733105182648 and batch: 200, loss is 3.833354392051697 and perplexity is 46.21730948294848
At time: 538.636887550354 and batch: 250, loss is 3.825966782569885 and perplexity is 45.87713214499915
At time: 539.6115868091583 and batch: 300, loss is 3.819776258468628 and perplexity is 45.59400590683644
At time: 540.5936727523804 and batch: 350, loss is 3.8304817152023314 and perplexity is 46.084732604393444
At time: 541.5692555904388 and batch: 400, loss is 3.8026368951797487 and perplexity is 44.81921237640884
At time: 542.5513188838959 and batch: 450, loss is 3.8423568868637084 and perplexity is 46.635259043448904
At time: 543.5383424758911 and batch: 500, loss is 3.8527992582321167 and perplexity is 47.124793237816846
At time: 544.5208783149719 and batch: 550, loss is 3.819865832328796 and perplexity is 45.598090120862736
At time: 545.5265657901764 and batch: 600, loss is 3.789644927978516 and perplexity is 44.24068885598166
At time: 546.5091052055359 and batch: 650, loss is 3.8290162563323973 and perplexity is 46.01724678515354
At time: 547.4910652637482 and batch: 700, loss is 3.8599774074554443 and perplexity is 47.46427901790149
At time: 548.4734723567963 and batch: 750, loss is 3.8217820215225218 and perplexity is 45.6855484550036
At time: 549.45578956604 and batch: 800, loss is 3.8026429271697997 and perplexity is 44.81948272626737
At time: 550.4373853206635 and batch: 850, loss is 3.7970748424530028 and perplexity is 44.57061754366975
At time: 551.4176595211029 and batch: 900, loss is 3.75933705329895 and perplexity is 42.91996289724057
At time: 552.409348487854 and batch: 950, loss is 3.864928345680237 and perplexity is 47.69985440961158
At time: 553.405730009079 and batch: 1000, loss is 3.8331514406204223 and perplexity is 46.2079305656038
At time: 554.3887763023376 and batch: 1050, loss is 3.7824003076553345 and perplexity is 43.92134003958479
At time: 555.3718473911285 and batch: 1100, loss is 3.801232838630676 and perplexity is 44.75632782481148
At time: 556.3554859161377 and batch: 1150, loss is 3.7673833656311033 and perplexity is 43.26670344461336
At time: 557.3381249904633 and batch: 1200, loss is 3.8164499473571776 and perplexity is 45.44259801285547
At time: 558.3211984634399 and batch: 1250, loss is 3.802216582298279 and perplexity is 44.80037824250154
At time: 559.3038837909698 and batch: 1300, loss is 3.794573411941528 and perplexity is 44.45926656745712
At time: 560.286276102066 and batch: 1350, loss is 3.6809159469604493 and perplexity is 39.682724702641245
At time: 561.2691721916199 and batch: 1400, loss is 3.7098840284347534 and perplexity is 40.849068921820106
At time: 562.2519488334656 and batch: 1450, loss is 3.620620536804199 and perplexity is 37.36074434726625
At time: 563.2345108985901 and batch: 1500, loss is 3.64330246925354 and perplexity is 38.21784179440783
At time: 564.2175912857056 and batch: 1550, loss is 3.6566600942611696 and perplexity is 38.73176615671624
At time: 565.2005393505096 and batch: 1600, loss is 3.742995357513428 and perplexity is 42.22427773993331
At time: 566.1832976341248 and batch: 1650, loss is 3.6915570449829103 and perplexity is 40.107247152681694
At time: 567.1666760444641 and batch: 1700, loss is 3.690795440673828 and perplexity is 40.07671292939873
At time: 568.1499979496002 and batch: 1750, loss is 3.6837056016922 and perplexity is 39.79358035598418
At time: 569.1325995922089 and batch: 1800, loss is 3.6491965293884276 and perplexity is 38.443765201195596
At time: 570.1152663230896 and batch: 1850, loss is 3.6765987491607666 and perplexity is 39.511775806483605
At time: 571.0980019569397 and batch: 1900, loss is 3.756358289718628 and perplexity is 42.792304701079146
At time: 572.0790750980377 and batch: 1950, loss is 3.6928701496124265 and perplexity is 40.15994675707004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.254479128815407 and perplexity of 70.42012781864823
finished 14 epochs...
Completing Train Step...
At time: 575.2122316360474 and batch: 50, loss is 3.8549360752105715 and perplexity is 47.2255979583767
At time: 576.189658164978 and batch: 100, loss is 3.8517265558242797 and perplexity is 47.07426946197459
At time: 577.1487665176392 and batch: 150, loss is 3.8103573226928713 and perplexity is 45.16657502545498
At time: 578.1180007457733 and batch: 200, loss is 3.817892589569092 and perplexity is 45.5082027336595
At time: 579.0902299880981 and batch: 250, loss is 3.8082073450088503 and perplexity is 45.06957221139486
At time: 580.0625259876251 and batch: 300, loss is 3.8013019037246703 and perplexity is 44.75941903154555
At time: 581.0345969200134 and batch: 350, loss is 3.8120616388320925 and perplexity is 45.243618783034904
At time: 582.006105184555 and batch: 400, loss is 3.7832822465896605 and perplexity is 43.9600930658029
At time: 582.98446393013 and batch: 450, loss is 3.8230357933044434 and perplexity is 45.74286362906403
At time: 583.9669120311737 and batch: 500, loss is 3.834956293106079 and perplexity is 46.29140437023446
At time: 584.9475858211517 and batch: 550, loss is 3.8033972644805907 and perplexity is 44.85330448924322
At time: 585.9275171756744 and batch: 600, loss is 3.7753631114959716 and perplexity is 43.6133419467014
At time: 586.9081797599792 and batch: 650, loss is 3.8151928186416626 and perplexity is 45.38550671106215
At time: 587.8897671699524 and batch: 700, loss is 3.84650851726532 and perplexity is 46.829273862921724
At time: 588.8701944351196 and batch: 750, loss is 3.8100145387649538 and perplexity is 45.15109530270883
At time: 589.8518590927124 and batch: 800, loss is 3.7912518787384033 and perplexity is 44.311838616326675
At time: 590.8328862190247 and batch: 850, loss is 3.787536520957947 and perplexity is 44.14750974127076
At time: 591.814521074295 and batch: 900, loss is 3.750027446746826 and perplexity is 42.52224908145143
At time: 592.7957189083099 and batch: 950, loss is 3.855780506134033 and perplexity is 47.26549355583916
At time: 593.8004715442657 and batch: 1000, loss is 3.823321862220764 and perplexity is 45.75595111236363
At time: 594.7821688652039 and batch: 1050, loss is 3.772897539138794 and perplexity is 43.505942551290886
At time: 595.7631883621216 and batch: 1100, loss is 3.7930210781097413 and perplexity is 44.39030448376423
At time: 596.7432363033295 and batch: 1150, loss is 3.7596230792999266 and perplexity is 42.93224087841735
At time: 597.7239384651184 and batch: 1200, loss is 3.8089841842651366 and perplexity is 45.10459762715025
At time: 598.7052755355835 and batch: 1250, loss is 3.795836133956909 and perplexity is 44.51544172147727
At time: 599.6870980262756 and batch: 1300, loss is 3.788837819099426 and perplexity is 44.204996209052666
At time: 600.6687078475952 and batch: 1350, loss is 3.6769108533859254 and perplexity is 39.52410952325878
At time: 601.6503200531006 and batch: 1400, loss is 3.706575288772583 and perplexity is 40.7141333437687
At time: 602.6313369274139 and batch: 1450, loss is 3.6187310361862184 and perplexity is 37.29021784864812
At time: 603.614818572998 and batch: 1500, loss is 3.643176803588867 and perplexity is 38.21303942566912
At time: 604.5952279567719 and batch: 1550, loss is 3.6579156494140626 and perplexity is 38.78042656681684
At time: 605.5771217346191 and batch: 1600, loss is 3.7452739810943605 and perplexity is 42.32060067505832
At time: 606.5593602657318 and batch: 1650, loss is 3.694018678665161 and perplexity is 40.20609812069452
At time: 607.5403535366058 and batch: 1700, loss is 3.69402072429657 and perplexity is 40.20618036763578
At time: 608.5212271213531 and batch: 1750, loss is 3.688039608001709 and perplexity is 39.96642025839238
At time: 609.5016145706177 and batch: 1800, loss is 3.654237594604492 and perplexity is 38.63805202355693
At time: 610.4842376708984 and batch: 1850, loss is 3.681227307319641 and perplexity is 39.695082253784314
At time: 611.4669778347015 and batch: 1900, loss is 3.7613371562957765 and perplexity is 43.00589314968637
At time: 612.4493114948273 and batch: 1950, loss is 3.697465615272522 and perplexity is 40.34492511862194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253321731922238 and perplexity of 70.33867092956261
finished 15 epochs...
Completing Train Step...
At time: 615.5728635787964 and batch: 50, loss is 3.851590714454651 and perplexity is 47.0678752630448
At time: 616.5613760948181 and batch: 100, loss is 3.847057318687439 and perplexity is 46.85498088839536
At time: 617.5219671726227 and batch: 150, loss is 3.804774298667908 and perplexity is 44.9151115684029
At time: 618.5310461521149 and batch: 200, loss is 3.811625056266785 and perplexity is 45.22387051907035
At time: 619.5044221878052 and batch: 250, loss is 3.8012438726425173 and perplexity is 44.7568216693872
At time: 620.4872362613678 and batch: 300, loss is 3.7941320514678956 and perplexity is 44.43964833418239
At time: 621.4757950305939 and batch: 350, loss is 3.8050330781936648 and perplexity is 44.926736183715235
At time: 622.465906381607 and batch: 400, loss is 3.77607852935791 and perplexity is 43.64455487436059
At time: 623.4481813907623 and batch: 450, loss is 3.815803060531616 and perplexity is 45.41321130084486
At time: 624.4230914115906 and batch: 500, loss is 3.827793083190918 and perplexity is 45.96099413521992
At time: 625.397136926651 and batch: 550, loss is 3.796543550491333 and perplexity is 44.546943822227966
At time: 626.3718020915985 and batch: 600, loss is 3.76914493560791 and perplexity is 43.34298794090927
At time: 627.3507478237152 and batch: 650, loss is 3.809090232849121 and perplexity is 45.10938115949873
At time: 628.3349707126617 and batch: 700, loss is 3.840682587623596 and perplexity is 46.55724299400123
At time: 629.3191487789154 and batch: 750, loss is 3.8046723413467407 and perplexity is 44.91053237739245
At time: 630.3144183158875 and batch: 800, loss is 3.785993504524231 and perplexity is 44.07944193660816
At time: 631.3049261569977 and batch: 850, loss is 3.7825563383102416 and perplexity is 43.9281936497083
At time: 632.2898759841919 and batch: 900, loss is 3.7453336334228515 and perplexity is 42.323125272730046
At time: 633.2748365402222 and batch: 950, loss is 3.8513166093826294 and perplexity is 47.054975487733614
At time: 634.2598822116852 and batch: 1000, loss is 3.8187215662002565 and perplexity is 45.54594361124349
At time: 635.2448620796204 and batch: 1050, loss is 3.768686261177063 and perplexity is 43.323112179184555
At time: 636.2560966014862 and batch: 1100, loss is 3.789221477508545 and perplexity is 44.22195908133958
At time: 637.2583510875702 and batch: 1150, loss is 3.7561405658721925 and perplexity is 42.782988810084404
At time: 638.2426555156708 and batch: 1200, loss is 3.805689263343811 and perplexity is 44.95622611521294
At time: 639.2270829677582 and batch: 1250, loss is 3.7929913854599 and perplexity is 44.38898643756508
At time: 640.2111873626709 and batch: 1300, loss is 3.786169376373291 and perplexity is 44.087194951315624
At time: 641.195454120636 and batch: 1350, loss is 3.674916672706604 and perplexity is 39.44536984434734
At time: 642.1804611682892 and batch: 1400, loss is 3.704945306777954 and perplexity is 40.64782409561281
At time: 643.1640207767487 and batch: 1450, loss is 3.617649531364441 and perplexity is 37.24991009868149
At time: 644.1457452774048 and batch: 1500, loss is 3.6426708936691283 and perplexity is 38.19371195935101
At time: 645.1276469230652 and batch: 1550, loss is 3.657835307121277 and perplexity is 38.77731098358948
At time: 646.1102085113525 and batch: 1600, loss is 3.7456239604949952 and perplexity is 42.335414605651145
At time: 647.0918402671814 and batch: 1650, loss is 3.6943895864486693 and perplexity is 40.221013641402344
At time: 648.0736103057861 and batch: 1700, loss is 3.694741477966309 and perplexity is 40.23516956546234
At time: 649.0589835643768 and batch: 1750, loss is 3.689189896583557 and perplexity is 40.01241962647484
At time: 650.0435411930084 and batch: 1800, loss is 3.655746145248413 and perplexity is 38.69638346872431
At time: 651.0274271965027 and batch: 1850, loss is 3.6825545167922975 and perplexity is 39.747800919587135
At time: 652.0114307403564 and batch: 1900, loss is 3.7627790546417237 and perplexity is 43.067948003529075
At time: 652.9955642223358 and batch: 1950, loss is 3.6986212158203124 and perplexity is 40.391574685130514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25301144622093 and perplexity of 70.3168492313797
finished 16 epochs...
Completing Train Step...
At time: 656.1238129138947 and batch: 50, loss is 3.847769594192505 and perplexity is 46.88836643201349
At time: 657.108612537384 and batch: 100, loss is 3.8426843547821044 and perplexity is 46.65053309539622
At time: 658.0628476142883 and batch: 150, loss is 3.800052742958069 and perplexity is 44.70354222817659
At time: 659.0175535678864 and batch: 200, loss is 3.806662712097168 and perplexity is 45.00001000470929
At time: 659.9808518886566 and batch: 250, loss is 3.796040711402893 and perplexity is 44.524549508443634
At time: 660.9533596038818 and batch: 300, loss is 3.7889002895355226 and perplexity is 44.207757800701515
At time: 661.9254410266876 and batch: 350, loss is 3.7998499155044554 and perplexity is 44.69447604200575
At time: 662.898903131485 and batch: 400, loss is 3.7708824825286866 and perplexity is 43.41836388179647
At time: 663.8986659049988 and batch: 450, loss is 3.810699806213379 and perplexity is 45.18204648228724
At time: 664.8861305713654 and batch: 500, loss is 3.8227539825439454 and perplexity is 45.729974614094225
At time: 665.8668215274811 and batch: 550, loss is 3.791690444946289 and perplexity is 44.33127655345272
At time: 666.8597695827484 and batch: 600, loss is 3.76467050075531 and perplexity is 43.14948579426026
At time: 667.8569555282593 and batch: 650, loss is 3.8046653699874877 and perplexity is 44.910219291028326
At time: 668.8320276737213 and batch: 700, loss is 3.836527090072632 and perplexity is 46.36417590748862
At time: 669.8044989109039 and batch: 750, loss is 3.800748448371887 and perplexity is 44.734653545422674
At time: 670.7763028144836 and batch: 800, loss is 3.782141261100769 and perplexity is 43.90996384132174
At time: 671.7477993965149 and batch: 850, loss is 3.778847141265869 and perplexity is 43.76555713556162
At time: 672.7202637195587 and batch: 900, loss is 3.741815938949585 and perplexity is 42.174506998959274
At time: 673.6935882568359 and batch: 950, loss is 3.847983422279358 and perplexity is 46.89839355370522
At time: 674.665581703186 and batch: 1000, loss is 3.8153303384780886 and perplexity is 45.3917485476995
At time: 675.6386752128601 and batch: 1050, loss is 3.76560357093811 and perplexity is 43.18976608210342
At time: 676.6111817359924 and batch: 1100, loss is 3.7863123083114623 and perplexity is 44.09349686990054
At time: 677.5857782363892 and batch: 1150, loss is 3.753471364974976 and perplexity is 42.668944689012264
At time: 678.5578229427338 and batch: 1200, loss is 3.803143873214722 and perplexity is 44.841940493469735
At time: 679.5318105220795 and batch: 1250, loss is 3.790673027038574 and perplexity is 44.286196055557
At time: 680.5066754817963 and batch: 1300, loss is 3.7839341974258422 and perplexity is 43.98876222966299
At time: 681.4812557697296 and batch: 1350, loss is 3.6731123065948488 and perplexity is 39.37426012900772
At time: 682.4606096744537 and batch: 1400, loss is 3.7034363317489625 and perplexity is 40.58653379846351
At time: 683.4448220729828 and batch: 1450, loss is 3.616450242996216 and perplexity is 37.20526349221186
At time: 684.4286227226257 and batch: 1500, loss is 3.6417368936538694 and perplexity is 38.15805568587025
At time: 685.4122297763824 and batch: 1550, loss is 3.65711350440979 and perplexity is 38.7493315144205
At time: 686.3953742980957 and batch: 1600, loss is 3.7451718616485596 and perplexity is 42.31627913943159
At time: 687.3790943622589 and batch: 1650, loss is 3.6939488363265993 and perplexity is 40.203290130836756
At time: 688.3621571063995 and batch: 1700, loss is 3.6945359182357786 and perplexity is 40.22689968485496
At time: 689.3446054458618 and batch: 1750, loss is 3.6892540502548217 and perplexity is 40.01498665243125
At time: 690.3268218040466 and batch: 1800, loss is 3.6560809803009033 and perplexity is 38.70934254376946
At time: 691.3098459243774 and batch: 1850, loss is 3.6828122663497926 and perplexity is 39.75804721811829
At time: 692.2939488887787 and batch: 1900, loss is 3.7631434392929077 and perplexity is 43.083644162285545
At time: 693.2773823738098 and batch: 1950, loss is 3.698760313987732 and perplexity is 40.39719346992067
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252964321402616 and perplexity of 70.31353564071205
finished 17 epochs...
Completing Train Step...
At time: 696.4667930603027 and batch: 50, loss is 3.8440956926345824 and perplexity is 46.71641924146157
At time: 697.4119894504547 and batch: 100, loss is 3.8386726427078246 and perplexity is 46.46375947998178
At time: 698.3571438789368 and batch: 150, loss is 3.795849571228027 and perplexity is 44.5160398915555
At time: 699.30131483078 and batch: 200, loss is 3.802363929748535 and perplexity is 44.80697995036655
At time: 700.2511887550354 and batch: 250, loss is 3.7916231107711793 and perplexity is 44.32829164400876
At time: 701.2079923152924 and batch: 300, loss is 3.78451726436615 and perplexity is 44.01441810148266
At time: 702.1699821949005 and batch: 350, loss is 3.7954770135879516 and perplexity is 44.499458189799626
At time: 703.1414983272552 and batch: 400, loss is 3.76654333114624 and perplexity is 43.23037318314618
At time: 704.1162869930267 and batch: 450, loss is 3.806483254432678 and perplexity is 44.991935132582334
At time: 705.0897779464722 and batch: 500, loss is 3.8186251449584963 and perplexity is 45.541552226518135
At time: 706.0635948181152 and batch: 550, loss is 3.7877183151245117 and perplexity is 44.15553623057245
At time: 707.0375373363495 and batch: 600, loss is 3.7609552001953124 and perplexity is 42.9894699231174
At time: 708.0108845233917 and batch: 650, loss is 3.8009710359573363 and perplexity is 44.7446120322179
At time: 708.9844663143158 and batch: 700, loss is 3.833065643310547 and perplexity is 46.20396621953391
At time: 709.9586663246155 and batch: 750, loss is 3.7974273347854615 and perplexity is 44.58633111390065
At time: 710.9311263561249 and batch: 800, loss is 3.778881158828735 and perplexity is 43.76704595847577
At time: 711.9038710594177 and batch: 850, loss is 3.7756964492797853 and perplexity is 43.62788234474801
At time: 712.8766510486603 and batch: 900, loss is 3.7388140249252317 and perplexity is 42.04809259245061
At time: 713.8505825996399 and batch: 950, loss is 3.8451141214370725 and perplexity is 46.76402082366311
At time: 714.8240361213684 and batch: 1000, loss is 3.812416925430298 and perplexity is 45.25969609029962
At time: 715.822048664093 and batch: 1050, loss is 3.7629570055007933 and perplexity is 43.075612663820884
At time: 716.7952291965485 and batch: 1100, loss is 3.7837352418899535 and perplexity is 43.98001129245307
At time: 717.7683162689209 and batch: 1150, loss is 3.7510915899276736 and perplexity is 42.56752292750068
At time: 718.741676568985 and batch: 1200, loss is 3.800859975814819 and perplexity is 44.73964296516648
At time: 719.717376947403 and batch: 1250, loss is 3.7885225772857667 and perplexity is 44.19106314213295
At time: 720.6999270915985 and batch: 1300, loss is 3.7818308162689207 and perplexity is 43.8963343356948
At time: 721.6828529834747 and batch: 1350, loss is 3.671328525543213 and perplexity is 39.30408767462132
At time: 722.6649222373962 and batch: 1400, loss is 3.70191605091095 and perplexity is 40.52487774797964
At time: 723.6472587585449 and batch: 1450, loss is 3.615139293670654 and perplexity is 37.15652123342569
At time: 724.6332986354828 and batch: 1500, loss is 3.6405694007873537 and perplexity is 38.113532423409794
At time: 725.6168930530548 and batch: 1550, loss is 3.656069393157959 and perplexity is 38.70889401568271
At time: 726.6006925106049 and batch: 1600, loss is 3.7443509531021117 and perplexity is 42.28155559860786
At time: 727.5833303928375 and batch: 1650, loss is 3.6931408643722534 and perplexity is 40.17082011913443
At time: 728.5666346549988 and batch: 1700, loss is 3.6939189291000365 and perplexity is 40.20208777990982
At time: 729.5504755973816 and batch: 1750, loss is 3.688836121559143 and perplexity is 39.99826673536193
At time: 730.5341002941132 and batch: 1800, loss is 3.6558955001831053 and perplexity is 38.7021633961697
At time: 731.5176584720612 and batch: 1850, loss is 3.682589693069458 and perplexity is 39.74919912384047
At time: 732.5010004043579 and batch: 1900, loss is 3.7630328798294066 and perplexity is 43.078881121005786
At time: 733.4849536418915 and batch: 1950, loss is 3.698463268280029 and perplexity is 40.3851954390672
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253038131359012 and perplexity of 70.31872567124732
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 736.6454923152924 and batch: 50, loss is 3.84426007270813 and perplexity is 46.724099121084656
At time: 737.5883872509003 and batch: 100, loss is 3.844339756965637 and perplexity is 46.727822444573974
At time: 738.5332050323486 and batch: 150, loss is 3.8035111951828005 and perplexity is 44.858414948833705
At time: 739.4835860729218 and batch: 200, loss is 3.8115893459320067 and perplexity is 45.222255588349185
At time: 740.4669122695923 and batch: 250, loss is 3.804333667755127 and perplexity is 44.895324941414756
At time: 741.4259400367737 and batch: 300, loss is 3.795349063873291 and perplexity is 44.49376486105935
At time: 742.3860847949982 and batch: 350, loss is 3.8032842206954958 and perplexity is 44.84823438850683
At time: 743.3445491790771 and batch: 400, loss is 3.7730625915527343 and perplexity is 43.51312390476328
At time: 744.3021790981293 and batch: 450, loss is 3.8142417764663694 and perplexity is 45.34236369869688
At time: 745.2710752487183 and batch: 500, loss is 3.828114080429077 and perplexity is 45.975749855546404
At time: 746.2444443702698 and batch: 550, loss is 3.7991843748092653 and perplexity is 44.66473994573831
At time: 747.2187757492065 and batch: 600, loss is 3.770782551765442 and perplexity is 43.41402526833902
At time: 748.1920278072357 and batch: 650, loss is 3.810014238357544 and perplexity is 45.15108173898729
At time: 749.1659719944 and batch: 700, loss is 3.8440557861328126 and perplexity is 46.71455498979257
At time: 750.1396088600159 and batch: 750, loss is 3.8068445539474487 and perplexity is 45.00819363383177
At time: 751.1130259037018 and batch: 800, loss is 3.7861836767196655 and perplexity is 44.087825417982046
At time: 752.0862305164337 and batch: 850, loss is 3.7799346113204955 and perplexity is 43.813176756133394
At time: 753.0604972839355 and batch: 900, loss is 3.7409100341796875 and perplexity is 42.13631821221455
At time: 754.0350546836853 and batch: 950, loss is 3.846885576248169 and perplexity is 46.84693459065081
At time: 755.0088102817535 and batch: 1000, loss is 3.814229226112366 and perplexity is 45.341794639552056
At time: 755.9822676181793 and batch: 1050, loss is 3.7668883419036865 and perplexity is 43.245290700146725
At time: 756.9563715457916 and batch: 1100, loss is 3.7852294731140135 and perplexity is 44.04577672070259
At time: 757.9300837516785 and batch: 1150, loss is 3.7546270513534545 and perplexity is 42.71828511270957
At time: 758.9039220809937 and batch: 1200, loss is 3.8056121349334715 and perplexity is 44.95275884667199
At time: 759.8771014213562 and batch: 1250, loss is 3.7929324436187746 and perplexity is 44.38637014608404
At time: 760.8508057594299 and batch: 1300, loss is 3.7854769945144655 and perplexity is 44.056680342424684
At time: 761.8243403434753 and batch: 1350, loss is 3.6713221406936647 and perplexity is 39.30383672473603
At time: 762.7979304790497 and batch: 1400, loss is 3.7033553552627563 and perplexity is 40.583247376632464
At time: 763.7717802524567 and batch: 1450, loss is 3.6128212356567384 and perplexity is 37.0704900128148
At time: 764.7482028007507 and batch: 1500, loss is 3.6360069370269774 and perplexity is 37.940036897430886
At time: 765.7322382926941 and batch: 1550, loss is 3.648551197052002 and perplexity is 38.41896419968215
At time: 766.7165262699127 and batch: 1600, loss is 3.7378284311294556 and perplexity is 42.00667066921563
At time: 767.6994779109955 and batch: 1650, loss is 3.6857999086380007 and perplexity is 39.87700765841796
At time: 768.7127289772034 and batch: 1700, loss is 3.683703441619873 and perplexity is 39.79349439906531
At time: 769.6996154785156 and batch: 1750, loss is 3.6800560903549195 and perplexity is 39.64861791525489
At time: 770.683123588562 and batch: 1800, loss is 3.646373219490051 and perplexity is 38.335379613419434
At time: 771.6658687591553 and batch: 1850, loss is 3.6727692317962646 and perplexity is 39.36075412956105
At time: 772.6491658687592 and batch: 1900, loss is 3.750971531867981 and perplexity is 42.56241266006263
At time: 773.6431334018707 and batch: 1950, loss is 3.6911808109283446 and perplexity is 40.09216027874382
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249714128361192 and perplexity of 70.08537406189612
finished 19 epochs...
Completing Train Step...
At time: 776.815277338028 and batch: 50, loss is 3.84399329662323 and perplexity is 46.71163591136773
At time: 777.7777576446533 and batch: 100, loss is 3.8410631227493286 and perplexity is 46.57496303165225
At time: 778.7329499721527 and batch: 150, loss is 3.7991239643096923 and perplexity is 44.66204180798364
At time: 779.6828525066376 and batch: 200, loss is 3.805020079612732 and perplexity is 44.926152203694365
At time: 780.6454772949219 and batch: 250, loss is 3.7971562242507932 and perplexity is 44.57424492825362
At time: 781.6224257946014 and batch: 300, loss is 3.788267798423767 and perplexity is 44.179805627504315
At time: 782.5941421985626 and batch: 350, loss is 3.7966541481018066 and perplexity is 44.551870880223994
At time: 783.5658113956451 and batch: 400, loss is 3.7667263841629026 and perplexity is 43.238287357703456
At time: 784.5326182842255 and batch: 450, loss is 3.8082549476623537 and perplexity is 45.071717693689315
At time: 785.4995076656342 and batch: 500, loss is 3.822320942878723 and perplexity is 45.71017600829691
At time: 786.4698061943054 and batch: 550, loss is 3.792965531349182 and perplexity is 44.38783881463053
At time: 787.4419095516205 and batch: 600, loss is 3.7651214361190797 and perplexity is 43.1689478110594
At time: 788.41614818573 and batch: 650, loss is 3.8043419170379638 and perplexity is 44.89569529717583
At time: 789.4325847625732 and batch: 700, loss is 3.8384405326843263 and perplexity is 46.45297602719922
At time: 790.4071524143219 and batch: 750, loss is 3.8016216373443603 and perplexity is 44.77373241072005
At time: 791.3807938098907 and batch: 800, loss is 3.7816380739212034 and perplexity is 43.88787446847228
At time: 792.3556070327759 and batch: 850, loss is 3.77636908531189 and perplexity is 43.65723790211352
At time: 793.3295049667358 and batch: 900, loss is 3.7379739332199096 and perplexity is 42.012783172291215
At time: 794.3039600849152 and batch: 950, loss is 3.844437608718872 and perplexity is 46.732395067640965
At time: 795.2770054340363 and batch: 1000, loss is 3.8113663005828857 and perplexity is 45.212170099365956
At time: 796.2591872215271 and batch: 1050, loss is 3.7635499238967896 and perplexity is 43.10116056014848
At time: 797.2496166229248 and batch: 1100, loss is 3.7823798513412474 and perplexity is 43.92044158004743
At time: 798.2231347560883 and batch: 1150, loss is 3.75214129447937 and perplexity is 42.61222971042377
At time: 799.195716381073 and batch: 1200, loss is 3.8029625988006592 and perplexity is 44.83381253369918
At time: 800.1753325462341 and batch: 1250, loss is 3.7907845973968506 and perplexity is 44.29113735796394
At time: 801.1581099033356 and batch: 1300, loss is 3.78347008228302 and perplexity is 43.96835111591806
At time: 802.1408925056458 and batch: 1350, loss is 3.66998619556427 and perplexity is 39.25136401363272
At time: 803.1242549419403 and batch: 1400, loss is 3.7023679876327513 and perplexity is 40.543196567542296
At time: 804.1066217422485 and batch: 1450, loss is 3.612870526313782 and perplexity is 37.07231728665786
At time: 805.0898518562317 and batch: 1500, loss is 3.6370627212524416 and perplexity is 37.98011454285082
At time: 806.0722503662109 and batch: 1550, loss is 3.6502033138275145 and perplexity is 38.48248927590705
At time: 807.0546505451202 and batch: 1600, loss is 3.739801845550537 and perplexity is 42.089649087370375
At time: 808.0376045703888 and batch: 1650, loss is 3.687904644012451 and perplexity is 39.961026594861316
At time: 809.0203313827515 and batch: 1700, loss is 3.68586905002594 and perplexity is 39.87976490539317
At time: 810.002925157547 and batch: 1750, loss is 3.6829130029678345 and perplexity is 39.762052511071445
At time: 810.9857404232025 and batch: 1800, loss is 3.6492924547195433 and perplexity is 38.447453108980916
At time: 811.968629360199 and batch: 1850, loss is 3.6754719114303587 and perplexity is 39.467277522590585
At time: 812.9502255916595 and batch: 1900, loss is 3.7533407497406004 and perplexity is 42.66337183875865
At time: 813.9325647354126 and batch: 1950, loss is 3.6935014724731445 and perplexity is 40.18530865447343
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.248941962663517 and perplexity of 70.031277428607
Finished Training.
Improved accuracyfrom -10000000 to -70.031277428607
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f05ce5c4b38>
ELAPSED
846.4119715690613


RESULTS SO FAR:
[{'best_accuracy': -70.031277428607, 'params': {'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'rnn_dropout': 0.7288706260952753, 'num_layers': 2, 'dropout': 0.4475108336446092, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5004630088806152 and batch: 50, loss is 7.615418186187744 and perplexity is 2029.2431828403535
At time: 2.4635589122772217 and batch: 100, loss is 6.75588228225708 and perplexity is 859.0973819938765
At time: 3.43611478805542 and batch: 150, loss is 6.484856519699097 and perplexity is 655.144957099575
At time: 4.406551361083984 and batch: 200, loss is 6.2933171939849855 and perplexity is 540.9447749088015
At time: 5.377098083496094 and batch: 250, loss is 6.210238199234009 and perplexity is 497.81981746425475
At time: 6.347843170166016 and batch: 300, loss is 6.115215177536011 and perplexity is 452.6934463521365
At time: 7.3169426918029785 and batch: 350, loss is 6.055902299880981 and perplexity is 426.62367433061934
At time: 8.290254831314087 and batch: 400, loss is 5.990381231307984 and perplexity is 399.5669083098914
At time: 9.263086080551147 and batch: 450, loss is 5.902350425720215 and perplexity is 365.8964704340438
At time: 10.235373735427856 and batch: 500, loss is 5.873847894668579 and perplexity is 355.61471895446596
At time: 11.208177089691162 and batch: 550, loss is 5.811572561264038 and perplexity is 334.14417491639387
At time: 12.182258129119873 and batch: 600, loss is 5.844632024765015 and perplexity is 345.3754287907315
At time: 13.15454912185669 and batch: 650, loss is 5.89276089668274 and perplexity is 362.40446570655723
At time: 14.127301931381226 and batch: 700, loss is 5.818498754501343 and perplexity is 336.466555384807
At time: 15.100522756576538 and batch: 750, loss is 5.750479354858398 and perplexity is 314.34130520846867
At time: 16.081709623336792 and batch: 800, loss is 5.750303602218628 and perplexity is 314.2860637488477
At time: 17.05370306968689 and batch: 850, loss is 5.768978958129883 and perplexity is 320.2106172290591
At time: 18.02683925628662 and batch: 900, loss is 5.759314289093018 and perplexity is 317.1307942988531
At time: 18.999866008758545 and batch: 950, loss is 5.778343172073364 and perplexity is 323.22322127598136
At time: 19.972858905792236 and batch: 1000, loss is 5.746360006332398 and perplexity is 313.0490871916954
At time: 20.946175813674927 and batch: 1050, loss is 5.646934261322022 and perplexity is 283.4212371098277
At time: 21.92206835746765 and batch: 1100, loss is 5.7253929615020756 and perplexity is 306.5537053821792
At time: 22.93038535118103 and batch: 1150, loss is 5.624279613494873 and perplexity is 277.07261324000183
At time: 23.980891942977905 and batch: 1200, loss is 5.703939924240112 and perplexity is 300.0472385939242
At time: 25.064778566360474 and batch: 1250, loss is 5.646414937973023 and perplexity is 283.27408805607126
At time: 26.152052402496338 and batch: 1300, loss is 5.661964569091797 and perplexity is 287.71332039667163
At time: 27.246888637542725 and batch: 1350, loss is 5.619259920120239 and perplexity is 275.68527858939734
At time: 28.334559679031372 and batch: 1400, loss is 5.632463865280151 and perplexity is 279.3495500722667
At time: 29.421695947647095 and batch: 1450, loss is 5.612339868545532 and perplexity is 273.7841079294726
At time: 30.509677171707153 and batch: 1500, loss is 5.57021206855774 and perplexity is 262.4897591628577
At time: 31.59624934196472 and batch: 1550, loss is 5.548101615905762 and perplexity is 256.7496834523741
At time: 32.68010473251343 and batch: 1600, loss is 5.577190380096436 and perplexity is 264.3279005804463
At time: 33.76377558708191 and batch: 1650, loss is 5.572273674011231 and perplexity is 263.03146768458987
At time: 34.84765434265137 and batch: 1700, loss is 5.586051635742187 and perplexity is 266.6805861612382
At time: 35.9324586391449 and batch: 1750, loss is 5.594977149963379 and perplexity is 269.0715017283534
At time: 37.017624616622925 and batch: 1800, loss is 5.577460012435913 and perplexity is 264.39918154006295
At time: 38.10324215888977 and batch: 1850, loss is 5.542397222518921 and perplexity is 255.28925165497307
At time: 39.186511516571045 and batch: 1900, loss is 5.564771738052368 and perplexity is 261.0656055644469
At time: 40.27066493034363 and batch: 1950, loss is 5.4899891757965085 and perplexity is 242.25458463084155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.997841342659884 and perplexity of 148.09313148656324
finished 1 epochs...
Completing Train Step...
At time: 43.53309392929077 and batch: 50, loss is 5.232618627548217 and perplexity is 187.28258529942664
At time: 44.56365966796875 and batch: 100, loss is 5.157261209487915 and perplexity is 173.68810825211818
At time: 45.56841778755188 and batch: 150, loss is 5.077364931106567 and perplexity is 160.35096289941418
At time: 46.571876525878906 and batch: 200, loss is 5.0346087455749515 and perplexity is 153.63946872873964
At time: 47.57537865638733 and batch: 250, loss is 5.041168212890625 and perplexity is 154.6505743339803
At time: 48.578025341033936 and batch: 300, loss is 5.042155084609985 and perplexity is 154.8032699452708
At time: 49.5812873840332 and batch: 350, loss is 5.033342123031616 and perplexity is 153.44498870649286
At time: 50.60760521888733 and batch: 400, loss is 4.9808010005950925 and perplexity is 145.59095340067188
At time: 51.611048221588135 and batch: 450, loss is 4.937768936157227 and perplexity is 139.4587608147594
At time: 52.61597752571106 and batch: 500, loss is 4.923138408660889 and perplexity is 137.4332587917323
At time: 53.61947798728943 and batch: 550, loss is 4.881404066085816 and perplexity is 131.81561184604112
At time: 54.62190341949463 and batch: 600, loss is 4.868365125656128 and perplexity is 130.10803263987626
At time: 55.62668228149414 and batch: 650, loss is 4.944602136611938 and perplexity is 140.4149737592642
At time: 56.634316205978394 and batch: 700, loss is 4.928493375778198 and perplexity is 138.1711833909959
At time: 57.64019298553467 and batch: 750, loss is 4.8868668746948245 and perplexity is 132.53766573068052
At time: 58.66989254951477 and batch: 800, loss is 4.865119695663452 and perplexity is 129.6864605897748
At time: 59.683735609054565 and batch: 850, loss is 4.844913711547852 and perplexity is 127.09231492144336
At time: 60.690837144851685 and batch: 900, loss is 4.851623687744141 and perplexity is 127.94796882757332
At time: 61.69566345214844 and batch: 950, loss is 4.910921173095703 and perplexity is 135.76441935449225
At time: 62.70196318626404 and batch: 1000, loss is 4.878764753341675 and perplexity is 131.4681679300871
At time: 63.70961308479309 and batch: 1050, loss is 4.783139591217041 and perplexity is 119.47887663868488
At time: 64.71546030044556 and batch: 1100, loss is 4.860806274414062 and perplexity is 129.12827296953105
At time: 65.72035098075867 and batch: 1150, loss is 4.777611999511719 and perplexity is 118.8202681276281
At time: 66.72706174850464 and batch: 1200, loss is 4.868209953308106 and perplexity is 130.0878450372743
At time: 67.73237371444702 and batch: 1250, loss is 4.817920484542847 and perplexity is 123.70757130806197
At time: 68.73780560493469 and batch: 1300, loss is 4.841864652633667 and perplexity is 126.7053931391224
At time: 69.74310851097107 and batch: 1350, loss is 4.738467960357666 and perplexity is 114.25901817504821
At time: 70.74662733078003 and batch: 1400, loss is 4.754541816711426 and perplexity is 116.11044111114721
At time: 71.74984788894653 and batch: 1450, loss is 4.69951714515686 and perplexity is 109.89409674237841
At time: 72.753573179245 and batch: 1500, loss is 4.680902290344238 and perplexity is 107.86735634978632
At time: 73.75919318199158 and batch: 1550, loss is 4.6745388889312744 and perplexity is 107.18313236675591
At time: 74.76585388183594 and batch: 1600, loss is 4.737434034347534 and perplexity is 114.14094385483874
At time: 75.77099370956421 and batch: 1650, loss is 4.70575798034668 and perplexity is 110.5820722263477
At time: 76.79183721542358 and batch: 1700, loss is 4.727256155014038 and perplexity is 112.98512298149491
At time: 77.79724407196045 and batch: 1750, loss is 4.72546199798584 and perplexity is 112.782591669833
At time: 78.80373167991638 and batch: 1800, loss is 4.681320734024048 and perplexity is 107.91250220814953
At time: 79.82442116737366 and batch: 1850, loss is 4.694086065292359 and perplexity is 109.29887094883982
At time: 80.8290650844574 and batch: 1900, loss is 4.775150737762451 and perplexity is 118.52817994683241
At time: 81.83523368835449 and batch: 1950, loss is 4.6930246162414555 and perplexity is 109.1829173163298
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.565186966297238 and perplexity of 96.08055616314071
finished 2 epochs...
Completing Train Step...
At time: 85.08279204368591 and batch: 50, loss is 4.64456241607666 and perplexity is 104.01783929109641
At time: 86.08157253265381 and batch: 100, loss is 4.602306718826294 and perplexity is 99.71406286499558
At time: 87.06225371360779 and batch: 150, loss is 4.557914972305298 and perplexity is 95.38439325010577
At time: 88.04793405532837 and batch: 200, loss is 4.5490577602386475 and perplexity is 94.54328389197855
At time: 89.04612803459167 and batch: 250, loss is 4.5526806926727295 and perplexity is 94.88642904212925
At time: 90.04750370979309 and batch: 300, loss is 4.573293628692627 and perplexity is 96.86261445304547
At time: 91.04720187187195 and batch: 350, loss is 4.581392116546631 and perplexity is 97.65024014351334
At time: 92.04574680328369 and batch: 400, loss is 4.539432563781738 and perplexity is 93.63765164677852
At time: 93.04539346694946 and batch: 450, loss is 4.5356677055358885 and perplexity is 93.2857819472453
At time: 94.04552435874939 and batch: 500, loss is 4.535741415023804 and perplexity is 93.29265824788357
At time: 95.04465937614441 and batch: 550, loss is 4.499755964279175 and perplexity is 89.99516658519488
At time: 96.04473066329956 and batch: 600, loss is 4.486798105239868 and perplexity is 88.83654474321432
At time: 97.0458128452301 and batch: 650, loss is 4.555641050338745 and perplexity is 95.16774299926345
At time: 98.0458631515503 and batch: 700, loss is 4.56618013381958 and perplexity is 96.1760276527943
At time: 99.04588389396667 and batch: 750, loss is 4.536031665802002 and perplexity is 93.31974044466446
At time: 100.0851309299469 and batch: 800, loss is 4.509723987579346 and perplexity is 90.89672642233546
At time: 101.08542561531067 and batch: 850, loss is 4.495696125030517 and perplexity is 89.6305413364723
At time: 102.08485507965088 and batch: 900, loss is 4.492989110946655 and perplexity is 89.38823830555377
At time: 103.08458232879639 and batch: 950, loss is 4.566398038864135 and perplexity is 96.19698717789531
At time: 104.08904647827148 and batch: 1000, loss is 4.537808313369751 and perplexity is 93.48568410259674
At time: 105.09434771537781 and batch: 1050, loss is 4.459965581893921 and perplexity is 86.48453241129303
At time: 106.0998466014862 and batch: 1100, loss is 4.524804801940918 and perplexity is 92.2779116013032
At time: 107.10673713684082 and batch: 1150, loss is 4.472946386337281 and perplexity is 87.61448922153782
At time: 108.11248445510864 and batch: 1200, loss is 4.557112455368042 and perplexity is 95.307876366127
At time: 109.11737847328186 and batch: 1250, loss is 4.5217904949188235 and perplexity is 92.00017644418925
At time: 110.12326574325562 and batch: 1300, loss is 4.533585138320923 and perplexity is 93.09171019002119
At time: 111.12940645217896 and batch: 1350, loss is 4.423353252410888 and perplexity is 83.37539588003885
At time: 112.13545489311218 and batch: 1400, loss is 4.436696891784668 and perplexity is 84.49538282826833
At time: 113.14179229736328 and batch: 1450, loss is 4.387983837127686 and perplexity is 80.47799854976049
At time: 114.14964509010315 and batch: 1500, loss is 4.384835114479065 and perplexity is 80.22499418233548
At time: 115.15588927268982 and batch: 1550, loss is 4.3842084598541256 and perplexity is 80.17473656742345
At time: 116.18246722221375 and batch: 1600, loss is 4.460227069854736 and perplexity is 86.50715003230421
At time: 117.19445395469666 and batch: 1650, loss is 4.4200270462036135 and perplexity is 83.09853282778973
At time: 118.19993209838867 and batch: 1700, loss is 4.441924152374267 and perplexity is 84.93821861360787
At time: 119.20657777786255 and batch: 1750, loss is 4.441209545135498 and perplexity is 84.87754282999761
At time: 120.2130696773529 and batch: 1800, loss is 4.402055349349975 and perplexity is 81.6184508158707
At time: 121.220046043396 and batch: 1850, loss is 4.430027093887329 and perplexity is 83.93369096942837
At time: 122.22692489624023 and batch: 1900, loss is 4.51773060798645 and perplexity is 91.62742330985444
At time: 123.23525714874268 and batch: 1950, loss is 4.445473985671997 and perplexity is 85.24027093079091
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.4495361328125 and perplexity of 85.58723368338104
finished 3 epochs...
Completing Train Step...
At time: 126.45776844024658 and batch: 50, loss is 4.401182551383972 and perplexity is 81.54724547646815
At time: 127.45593237876892 and batch: 100, loss is 4.368470897674561 and perplexity is 78.92285825952773
At time: 128.4316143989563 and batch: 150, loss is 4.332581453323364 and perplexity is 76.14058646063519
At time: 129.40890455245972 and batch: 200, loss is 4.327076997756958 and perplexity is 75.72262536511938
At time: 130.39200830459595 and batch: 250, loss is 4.328583364486694 and perplexity is 75.83677736445908
At time: 131.38039755821228 and batch: 300, loss is 4.3486911582946775 and perplexity is 77.37712221566053
At time: 132.37075471878052 and batch: 350, loss is 4.359932193756103 and perplexity is 78.25182828063774
At time: 133.3774127960205 and batch: 400, loss is 4.3189022254943845 and perplexity is 75.1061334214394
At time: 134.3773808479309 and batch: 450, loss is 4.331386594772339 and perplexity is 76.04966356064237
At time: 135.3772258758545 and batch: 500, loss is 4.33447380065918 and perplexity is 76.28480731150525
At time: 136.3757700920105 and batch: 550, loss is 4.30215012550354 and perplexity is 73.8584279863334
At time: 137.3741273880005 and batch: 600, loss is 4.293074731826782 and perplexity is 73.19116608800593
At time: 138.38816022872925 and batch: 650, loss is 4.357186670303345 and perplexity is 78.03728070833756
At time: 139.3904001712799 and batch: 700, loss is 4.370974607467652 and perplexity is 79.12070576566855
At time: 140.38978600502014 and batch: 750, loss is 4.346615514755249 and perplexity is 77.2166814583469
At time: 141.38872003555298 and batch: 800, loss is 4.322332201004028 and perplexity is 75.36418792702096
At time: 142.3871147632599 and batch: 850, loss is 4.307417612075806 and perplexity is 74.24850271877688
At time: 143.3860239982605 and batch: 900, loss is 4.299626007080078 and perplexity is 73.67223565213095
At time: 144.38541650772095 and batch: 950, loss is 4.386991987228393 and perplexity is 80.39821602768751
At time: 145.38511776924133 and batch: 1000, loss is 4.354671239852905 and perplexity is 77.84123003546459
At time: 146.38378047943115 and batch: 1050, loss is 4.2836030578613284 and perplexity is 72.50119596991503
At time: 147.3826904296875 and batch: 1100, loss is 4.339352340698242 and perplexity is 76.6578750714264
At time: 148.38129353523254 and batch: 1150, loss is 4.299630913734436 and perplexity is 73.67259713721396
At time: 149.38030076026917 and batch: 1200, loss is 4.376579089164734 and perplexity is 79.56538123681665
At time: 150.41747403144836 and batch: 1250, loss is 4.348909511566162 and perplexity is 77.3940196081677
At time: 151.4172101020813 and batch: 1300, loss is 4.356900320053101 and perplexity is 78.01493791256362
At time: 152.41830468177795 and batch: 1350, loss is 4.243073511123657 and perplexity is 69.62150580918848
At time: 153.4175102710724 and batch: 1400, loss is 4.266985988616943 and perplexity is 71.30639312992776
At time: 154.4164695739746 and batch: 1450, loss is 4.208099660873413 and perplexity is 67.22866108703826
At time: 155.4154143333435 and batch: 1500, loss is 4.212628011703491 and perplexity is 67.53378638607026
At time: 156.4149684906006 and batch: 1550, loss is 4.213365488052368 and perplexity is 67.58360932564176
At time: 157.41281747817993 and batch: 1600, loss is 4.295761604309082 and perplexity is 73.38808584879015
At time: 158.41172862052917 and batch: 1650, loss is 4.250925030708313 and perplexity is 70.17029200914118
At time: 159.41081738471985 and batch: 1700, loss is 4.275255131721496 and perplexity is 71.89848055295951
At time: 160.4101402759552 and batch: 1750, loss is 4.277767772674561 and perplexity is 72.07936277052914
At time: 161.40934896469116 and batch: 1800, loss is 4.2343247127532955 and perplexity is 69.01505800559656
At time: 162.40817999839783 and batch: 1850, loss is 4.273032655715943 and perplexity is 71.7388653412841
At time: 163.4187295436859 and batch: 1900, loss is 4.360845956802368 and perplexity is 78.32336458826293
At time: 164.42237544059753 and batch: 1950, loss is 4.2875933265686035 and perplexity is 72.791073182795
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.39865836210029 and perplexity of 81.34166436529712
finished 4 epochs...
Completing Train Step...
At time: 167.6369068622589 and batch: 50, loss is 4.249070782661438 and perplexity is 70.0402994387149
At time: 168.6039252281189 and batch: 100, loss is 4.221210165023804 and perplexity is 68.11586587015404
At time: 169.57474780082703 and batch: 150, loss is 4.187073445320129 and perplexity is 65.82985411037149
At time: 170.55840063095093 and batch: 200, loss is 4.187666931152344 and perplexity is 65.86893479189105
At time: 171.5478641986847 and batch: 250, loss is 4.182877159118652 and perplexity is 65.55419198501623
At time: 172.53712844848633 and batch: 300, loss is 4.200468125343323 and perplexity is 66.71755591054482
At time: 173.53288984298706 and batch: 350, loss is 4.214852418899536 and perplexity is 67.68417622859698
At time: 174.53004956245422 and batch: 400, loss is 4.179551386833191 and perplexity is 65.33653580817725
At time: 175.55011653900146 and batch: 450, loss is 4.200103468894959 and perplexity is 66.69323135888479
At time: 176.5648365020752 and batch: 500, loss is 4.206232562065124 and perplexity is 67.10325564264859
At time: 177.57118391990662 and batch: 550, loss is 4.172131781578064 and perplexity is 64.85355847001955
At time: 178.56608748435974 and batch: 600, loss is 4.164018206596374 and perplexity is 64.32949315708568
At time: 179.56422185897827 and batch: 650, loss is 4.228068513870239 and perplexity is 68.58463389012307
At time: 180.5597801208496 and batch: 700, loss is 4.24148624420166 and perplexity is 69.51108555235139
At time: 181.55710291862488 and batch: 750, loss is 4.217528667449951 and perplexity is 67.86555851089022
At time: 182.55509996414185 and batch: 800, loss is 4.196484441757202 and perplexity is 66.45230297083998
At time: 183.5555989742279 and batch: 850, loss is 4.181836280822754 and perplexity is 65.48599354866734
At time: 184.5540473461151 and batch: 900, loss is 4.17032069683075 and perplexity is 64.7362094760277
At time: 185.5522119998932 and batch: 950, loss is 4.261639413833618 and perplexity is 70.92616552993913
At time: 186.55076241493225 and batch: 1000, loss is 4.22822681427002 and perplexity is 68.59549172446376
At time: 187.54985070228577 and batch: 1050, loss is 4.16478533744812 and perplexity is 64.37886122942831
At time: 188.548095703125 and batch: 1100, loss is 4.217290301322937 and perplexity is 67.84938358840371
At time: 189.56291484832764 and batch: 1150, loss is 4.17994191646576 and perplexity is 65.36205664449676
At time: 190.56014752388 and batch: 1200, loss is 4.251494174003601 and perplexity is 70.210240327447
At time: 191.55929255485535 and batch: 1250, loss is 4.231362271308899 and perplexity is 68.81090747876719
At time: 192.55559182167053 and batch: 1300, loss is 4.238476572036743 and perplexity is 69.30219447751816
At time: 193.55243945121765 and batch: 1350, loss is 4.124302515983581 and perplexity is 61.824672487634956
At time: 194.54715132713318 and batch: 1400, loss is 4.148888087272644 and perplexity is 63.363506424625214
At time: 195.54508018493652 and batch: 1450, loss is 4.087634925842285 and perplexity is 59.59876937825559
At time: 196.54220366477966 and batch: 1500, loss is 4.093540391921997 and perplexity is 59.95176917749048
At time: 197.53934407234192 and batch: 1550, loss is 4.096283173561096 and perplexity is 60.116429499649904
At time: 198.54216313362122 and batch: 1600, loss is 4.187088651657104 and perplexity is 65.83085514892717
At time: 199.5660262107849 and batch: 1650, loss is 4.134608845710755 and perplexity is 62.46515277876804
At time: 200.5804181098938 and batch: 1700, loss is 4.15870310306549 and perplexity is 63.988482297683206
At time: 201.57902026176453 and batch: 1750, loss is 4.164192452430725 and perplexity is 64.34070327992443
At time: 202.57737565040588 and batch: 1800, loss is 4.120391807556152 and perplexity is 61.58336636639283
At time: 203.57682585716248 and batch: 1850, loss is 4.160562767982483 and perplexity is 64.10759014932388
At time: 204.59193873405457 and batch: 1900, loss is 4.247116174697876 and perplexity is 69.90353181874461
At time: 205.59032797813416 and batch: 1950, loss is 4.176181101799012 and perplexity is 65.11670371584928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.382574604832849 and perplexity of 80.04384962576333
finished 5 epochs...
Completing Train Step...
At time: 208.9479911327362 and batch: 50, loss is 4.142445869445801 and perplexity is 62.95661695648985
At time: 209.90678548812866 and batch: 100, loss is 4.115953512191773 and perplexity is 61.31064684948933
At time: 210.86502814292908 and batch: 150, loss is 4.083820414543152 and perplexity is 59.37186224409559
At time: 211.8316731452942 and batch: 200, loss is 4.084982523918152 and perplexity is 59.44089894815164
At time: 212.80012583732605 and batch: 250, loss is 4.078819236755371 and perplexity is 59.07567426713568
At time: 213.7737603187561 and batch: 300, loss is 4.095642333030701 and perplexity is 60.07791679665241
At time: 214.76776432991028 and batch: 350, loss is 4.110709819793701 and perplexity is 60.98999411357095
At time: 215.74885272979736 and batch: 400, loss is 4.073781356811524 and perplexity is 58.77880653246006
At time: 216.73942685127258 and batch: 450, loss is 4.096282157897949 and perplexity is 60.11636844163897
At time: 217.72340607643127 and batch: 500, loss is 4.1062713670730595 and perplexity is 60.71989276770548
At time: 218.70723009109497 and batch: 550, loss is 4.072225441932678 and perplexity is 58.68742282388704
At time: 219.69135189056396 and batch: 600, loss is 4.0723032379150395 and perplexity is 58.691988647196915
At time: 220.68454265594482 and batch: 650, loss is 4.13060878276825 and perplexity is 62.21578730722837
At time: 221.6808660030365 and batch: 700, loss is 4.145848650932312 and perplexity is 63.171209465769145
At time: 222.67256665229797 and batch: 750, loss is 4.117630019187927 and perplexity is 61.4135207882148
At time: 223.6638355255127 and batch: 800, loss is 4.098535060882568 and perplexity is 60.25195746463358
At time: 224.69612669944763 and batch: 850, loss is 4.08837619304657 and perplexity is 59.64296436953657
At time: 225.68679428100586 and batch: 900, loss is 4.075062875747681 and perplexity is 58.854180972646745
At time: 226.6783845424652 and batch: 950, loss is 4.171886100769043 and perplexity is 64.83762715239637
At time: 227.67845225334167 and batch: 1000, loss is 4.138661365509034 and perplexity is 62.718807670696236
At time: 228.68082880973816 and batch: 1050, loss is 4.073922634124756 and perplexity is 58.78711123094089
At time: 229.67137956619263 and batch: 1100, loss is 4.121118350028992 and perplexity is 61.62812555543549
At time: 230.66370034217834 and batch: 1150, loss is 4.086513924598694 and perplexity is 59.53199651688884
At time: 231.6586148738861 and batch: 1200, loss is 4.163185353279114 and perplexity is 64.27593843002384
At time: 232.6586811542511 and batch: 1250, loss is 4.144542651176453 and perplexity is 63.08876173170863
At time: 233.65840363502502 and batch: 1300, loss is 4.148873677253723 and perplexity is 63.362593361877416
At time: 234.6583411693573 and batch: 1350, loss is 4.03261905670166 and perplexity is 56.40845489201797
At time: 235.65812802314758 and batch: 1400, loss is 4.058595719337464 and perplexity is 57.89295601103097
At time: 236.6578345298767 and batch: 1450, loss is 3.9921566104888915 and perplexity is 54.17159049891884
At time: 237.6557958126068 and batch: 1500, loss is 4.003062119483948 and perplexity is 54.765592325464866
At time: 238.65405535697937 and batch: 1550, loss is 4.005191950798035 and perplexity is 54.88235810049697
At time: 239.6543378829956 and batch: 1600, loss is 4.102422175407409 and perplexity is 60.48661950728978
At time: 240.65470004081726 and batch: 1650, loss is 4.050707187652588 and perplexity is 57.438062174389316
At time: 241.65552353858948 and batch: 1700, loss is 4.076137981414795 and perplexity is 58.91748946170355
At time: 242.65437364578247 and batch: 1750, loss is 4.07683189868927 and perplexity is 58.95838751370101
At time: 243.66728115081787 and batch: 1800, loss is 4.037872924804687 and perplexity is 56.705597364089364
At time: 244.66557836532593 and batch: 1850, loss is 4.07723858833313 and perplexity is 58.98237015573705
At time: 245.6624596118927 and batch: 1900, loss is 4.159400515556335 and perplexity is 64.03312422961885
At time: 246.65851068496704 and batch: 1950, loss is 4.090646467208862 and perplexity is 59.77852407112671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377906692859739 and perplexity of 79.67108268022938
finished 6 epochs...
Completing Train Step...
At time: 249.90381288528442 and batch: 50, loss is 4.063939809799194 and perplexity is 58.20316937089025
At time: 250.8726568222046 and batch: 100, loss is 4.034711985588074 and perplexity is 56.52663740735951
At time: 251.83993220329285 and batch: 150, loss is 4.005865797996521 and perplexity is 54.919352886766006
At time: 252.80707669258118 and batch: 200, loss is 4.004235181808472 and perplexity is 54.82987347402757
At time: 253.77728819847107 and batch: 250, loss is 3.9976945447921755 and perplexity is 54.47242143033239
At time: 254.75797963142395 and batch: 300, loss is 4.009501795768738 and perplexity is 55.11940300200406
At time: 255.74934601783752 and batch: 350, loss is 4.02959321975708 and perplexity is 56.23803007410392
At time: 256.7386417388916 and batch: 400, loss is 3.9919178009033205 and perplexity is 54.15865534842251
At time: 257.7200062274933 and batch: 450, loss is 4.018794231414795 and perplexity is 55.63398365826185
At time: 258.7027597427368 and batch: 500, loss is 4.029693236351013 and perplexity is 56.24365509161429
At time: 259.6849932670593 and batch: 550, loss is 4.000564994812012 and perplexity is 54.629006420687034
At time: 260.6680335998535 and batch: 600, loss is 3.9983140134811403 and perplexity is 54.50617584364225
At time: 261.6499001979828 and batch: 650, loss is 4.053632369041443 and perplexity is 57.60632490439595
At time: 262.6317822933197 and batch: 700, loss is 4.07166621685028 and perplexity is 58.65461252005013
At time: 263.613520860672 and batch: 750, loss is 4.0415795707702635 and perplexity is 56.91617496499429
At time: 264.60136580467224 and batch: 800, loss is 4.025078825950622 and perplexity is 55.98472165662222
At time: 265.5895404815674 and batch: 850, loss is 4.017724647521972 and perplexity is 55.57451025701329
At time: 266.578125 and batch: 900, loss is 4.002282514572143 and perplexity is 54.72291343918635
At time: 267.56686329841614 and batch: 950, loss is 4.096202630996704 and perplexity is 60.11158776324145
At time: 268.55406618118286 and batch: 1000, loss is 4.067341294288635 and perplexity is 58.40148363898554
At time: 269.54208183288574 and batch: 1050, loss is 4.004575128555298 and perplexity is 54.848515879676995
At time: 270.53099370002747 and batch: 1100, loss is 4.0456170558929445 and perplexity is 57.146437703046814
At time: 271.5190215110779 and batch: 1150, loss is 4.013259081840515 and perplexity is 55.3268919207035
At time: 272.5077168941498 and batch: 1200, loss is 4.08962278842926 and perplexity is 59.717361375377145
At time: 273.49580812454224 and batch: 1250, loss is 4.072949829101563 and perplexity is 58.72995064139857
At time: 274.4838514328003 and batch: 1300, loss is 4.075733995437622 and perplexity is 58.89369242930812
At time: 275.4715721607208 and batch: 1350, loss is 3.9628737783432006 and perplexity is 52.608293496088926
At time: 276.459632396698 and batch: 1400, loss is 3.989137706756592 and perplexity is 54.008298287927076
At time: 277.44908690452576 and batch: 1450, loss is 3.9199144792556764 and perplexity is 50.3961346788179
At time: 278.43532633781433 and batch: 1500, loss is 3.935963158607483 and perplexity is 51.21145096029718
At time: 279.43574023246765 and batch: 1550, loss is 3.937055196762085 and perplexity is 51.26740636585648
At time: 280.43522572517395 and batch: 1600, loss is 4.033303318023681 and perplexity is 56.447066224549765
At time: 281.4364731311798 and batch: 1650, loss is 3.979098744392395 and perplexity is 53.46882342868094
At time: 282.4486560821533 and batch: 1700, loss is 4.010858631134033 and perplexity is 55.19424171773769
At time: 283.44307231903076 and batch: 1750, loss is 4.012971258163452 and perplexity is 55.3109698227187
At time: 284.43364000320435 and batch: 1800, loss is 3.970462427139282 and perplexity is 53.0090379906477
At time: 285.424115896225 and batch: 1850, loss is 4.009074158668518 and perplexity is 55.09583693955887
At time: 286.4142427444458 and batch: 1900, loss is 4.092119612693787 and perplexity is 59.86665143023059
At time: 287.4324517250061 and batch: 1950, loss is 4.020770745277405 and perplexity is 55.74405373988235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379075445130814 and perplexity of 79.7642528748835
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 290.6620099544525 and batch: 50, loss is 4.028905339241028 and perplexity is 56.199358331248895
At time: 291.66100788116455 and batch: 100, loss is 4.025912580490112 and perplexity is 56.03141863664993
At time: 292.63943576812744 and batch: 150, loss is 3.9947080707550047 and perplexity is 54.30998363684756
At time: 293.6057255268097 and batch: 200, loss is 3.987125964164734 and perplexity is 53.89975670941236
At time: 294.5808551311493 and batch: 250, loss is 3.9774949407577513 and perplexity is 53.38313866446048
At time: 295.55635476112366 and batch: 300, loss is 3.981641564369202 and perplexity is 53.60495803057127
At time: 296.5358250141144 and batch: 350, loss is 3.9969776344299315 and perplexity is 54.43338358194347
At time: 297.5198893547058 and batch: 400, loss is 3.960475745201111 and perplexity is 52.482288207548955
At time: 298.5143871307373 and batch: 450, loss is 3.9799446439743043 and perplexity is 53.51407181916364
At time: 299.52215909957886 and batch: 500, loss is 3.984405279159546 and perplexity is 53.75331175517897
At time: 300.5096912384033 and batch: 550, loss is 3.9480445909500124 and perplexity is 51.833911174493736
At time: 301.4941499233246 and batch: 600, loss is 3.9313362884521483 and perplexity is 50.97504954729739
At time: 302.48436164855957 and batch: 650, loss is 3.98371346950531 and perplexity is 53.71613755537738
At time: 303.4852075576782 and batch: 700, loss is 4.003921728134156 and perplexity is 54.81268954204885
At time: 304.4860098361969 and batch: 750, loss is 3.9621330881118775 and perplexity is 52.56934147448157
At time: 305.47134351730347 and batch: 800, loss is 3.938543257713318 and perplexity is 51.34375218086569
At time: 306.45482993125916 and batch: 850, loss is 3.9302458572387695 and perplexity is 50.91949505684741
At time: 307.4387056827545 and batch: 900, loss is 3.9013071250915528 and perplexity is 49.46706650865435
At time: 308.4230890274048 and batch: 950, loss is 3.995960922241211 and perplexity is 54.378068621844434
At time: 309.4120419025421 and batch: 1000, loss is 3.9663362455368043 and perplexity is 52.79076370268466
At time: 310.4036843776703 and batch: 1050, loss is 3.893874807357788 and perplexity is 49.1007744386715
At time: 311.4057846069336 and batch: 1100, loss is 3.9231444120407106 and perplexity is 50.559173967686405
At time: 312.4032757282257 and batch: 1150, loss is 3.894445986747742 and perplexity is 49.12882780004987
At time: 313.40339517593384 and batch: 1200, loss is 3.9482656717300415 and perplexity is 51.84537192283707
At time: 314.4044098854065 and batch: 1250, loss is 3.927338809967041 and perplexity is 50.77168462771154
At time: 315.3965926170349 and batch: 1300, loss is 3.9304837131500245 and perplexity is 50.931608000255295
At time: 316.3882522583008 and batch: 1350, loss is 3.820095725059509 and perplexity is 45.60857399535301
At time: 317.38005018234253 and batch: 1400, loss is 3.8326820230484007 and perplexity is 46.186244841257796
At time: 318.3710241317749 and batch: 1450, loss is 3.748627381324768 and perplexity is 42.46275680710043
At time: 319.3634102344513 and batch: 1500, loss is 3.7622056341171266 and perplexity is 43.04325903744801
At time: 320.3551199436188 and batch: 1550, loss is 3.7621632480621336 and perplexity is 43.041434642168106
At time: 321.3468506336212 and batch: 1600, loss is 3.851352195739746 and perplexity is 47.05665003269074
At time: 322.33878231048584 and batch: 1650, loss is 3.787437858581543 and perplexity is 44.14315425791207
At time: 323.33161425590515 and batch: 1700, loss is 3.8058917999267576 and perplexity is 44.965332317770944
At time: 324.32370710372925 and batch: 1750, loss is 3.7982517957687376 and perplexity is 44.62310596192207
At time: 325.31316113471985 and batch: 1800, loss is 3.7552223110198977 and perplexity is 42.743721154630634
At time: 326.3050410747528 and batch: 1850, loss is 3.7733267736434937 and perplexity is 43.524620811383464
At time: 327.2980706691742 and batch: 1900, loss is 3.8554345083236696 and perplexity is 47.24914262741892
At time: 328.2896089553833 and batch: 1950, loss is 3.7847410821914673 and perplexity is 44.02427041534534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.295529671602471 and perplexity of 73.37106672512826
finished 8 epochs...
Completing Train Step...
At time: 331.4938955307007 and batch: 50, loss is 3.9402612161636354 and perplexity is 51.43203442469634
At time: 332.47625494003296 and batch: 100, loss is 3.927632465362549 and perplexity is 50.7865961961656
At time: 333.4356360435486 and batch: 150, loss is 3.8893960094451905 and perplexity is 48.881353729906266
At time: 334.4030601978302 and batch: 200, loss is 3.8842384099960325 and perplexity is 48.62989231289107
At time: 335.3713970184326 and batch: 250, loss is 3.8760205268859864 and perplexity is 48.23189512922249
At time: 336.34955501556396 and batch: 300, loss is 3.881553626060486 and perplexity is 48.49950666618592
At time: 337.33144640922546 and batch: 350, loss is 3.8998893308639526 and perplexity is 49.39698208169002
At time: 338.3131902217865 and batch: 400, loss is 3.8643065452575684 and perplexity is 47.670203839302374
At time: 339.29512333869934 and batch: 450, loss is 3.89050856590271 and perplexity is 48.93576725909974
At time: 340.27799677848816 and batch: 500, loss is 3.898883776664734 and perplexity is 49.34733570417403
At time: 341.2615532875061 and batch: 550, loss is 3.8655153703689575 and perplexity is 47.72786362204369
At time: 342.2440276145935 and batch: 600, loss is 3.853238105773926 and perplexity is 47.14547837596657
At time: 343.22581362724304 and batch: 650, loss is 3.904542922973633 and perplexity is 49.62739118693453
At time: 344.20840430259705 and batch: 700, loss is 3.926445970535278 and perplexity is 50.72637389627273
At time: 345.18992614746094 and batch: 750, loss is 3.8889894390106203 and perplexity is 48.86148405616257
At time: 346.1724045276642 and batch: 800, loss is 3.867444486618042 and perplexity is 47.820025085798214
At time: 347.1539182662964 and batch: 850, loss is 3.8635453844070433 and perplexity is 47.63393295214418
At time: 348.15570092201233 and batch: 900, loss is 3.832364330291748 and perplexity is 46.17157413632647
At time: 349.1701285839081 and batch: 950, loss is 3.931592411994934 and perplexity is 50.98810712968687
At time: 350.1537024974823 and batch: 1000, loss is 3.9044676446914672 and perplexity is 49.62365546278883
At time: 351.13702297210693 and batch: 1050, loss is 3.8379894399642946 and perplexity is 46.43202615341257
At time: 352.11914682388306 and batch: 1100, loss is 3.866204514503479 and perplexity is 47.76076633536584
At time: 353.1018702983856 and batch: 1150, loss is 3.8415564346313475 and perplexity is 46.59794468241499
At time: 354.09001755714417 and batch: 1200, loss is 3.8970331001281737 and perplexity is 49.256094203138986
At time: 355.08031010627747 and batch: 1250, loss is 3.881408700942993 and perplexity is 48.492478378783964
At time: 356.0703225135803 and batch: 1300, loss is 3.8836454057693484 and perplexity is 48.60106312996482
At time: 357.05960726737976 and batch: 1350, loss is 3.7750772523880003 and perplexity is 43.600876457448564
At time: 358.0494441986084 and batch: 1400, loss is 3.7934554767608644 and perplexity is 44.409591761035244
At time: 359.0389075279236 and batch: 1450, loss is 3.7124128913879395 and perplexity is 40.95250134698058
At time: 360.02809715270996 and batch: 1500, loss is 3.7277489471435548 and perplexity is 41.58539180835123
At time: 361.01793360710144 and batch: 1550, loss is 3.732323422431946 and perplexity is 41.77605892405238
At time: 362.0081272125244 and batch: 1600, loss is 3.8251925897598267 and perplexity is 45.84162814439074
At time: 363.01606154441833 and batch: 1650, loss is 3.7619806957244872 and perplexity is 43.03357804480045
At time: 364.02894401550293 and batch: 1700, loss is 3.7852732229232786 and perplexity is 44.04770375718649
At time: 365.03626537323 and batch: 1750, loss is 3.7806312894821166 and perplexity is 43.84371107463207
At time: 366.0328769683838 and batch: 1800, loss is 3.741443395614624 and perplexity is 42.158798093777186
At time: 367.0221610069275 and batch: 1850, loss is 3.763565864562988 and perplexity is 43.10184762683787
At time: 368.0184371471405 and batch: 1900, loss is 3.848673253059387 and perplexity is 46.930756670366115
At time: 369.0160970687866 and batch: 1950, loss is 3.7803161191940307 and perplexity is 43.82989501690173
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.294611589298692 and perplexity of 73.30373695902117
finished 9 epochs...
Completing Train Step...
At time: 372.19154930114746 and batch: 50, loss is 3.895684676170349 and perplexity is 49.18972086540292
At time: 373.16752433776855 and batch: 100, loss is 3.8822456073760985 and perplexity is 48.53307903300098
At time: 374.13067650794983 and batch: 150, loss is 3.844063754081726 and perplexity is 46.71492721046316
At time: 375.0985805988312 and batch: 200, loss is 3.837084903717041 and perplexity is 46.39004569201021
At time: 376.0664129257202 and batch: 250, loss is 3.829315142631531 and perplexity is 46.03100276537607
At time: 377.0404133796692 and batch: 300, loss is 3.836196599006653 and perplexity is 46.34885549333917
At time: 378.022803068161 and batch: 350, loss is 3.8544973134994507 and perplexity is 47.204881719286384
At time: 379.0067558288574 and batch: 400, loss is 3.8192057704925535 and perplexity is 45.56800249270833
At time: 379.9890465736389 and batch: 450, loss is 3.848024649620056 and perplexity is 46.90032708961146
At time: 380.96993136405945 and batch: 500, loss is 3.8574607515335084 and perplexity is 47.344977941877076
At time: 381.95242166519165 and batch: 550, loss is 3.8255367565155027 and perplexity is 45.85740802412335
At time: 382.9392545223236 and batch: 600, loss is 3.8145856523513793 and perplexity is 45.357958525330936
At time: 383.9291286468506 and batch: 650, loss is 3.865208177566528 and perplexity is 47.71320421761071
At time: 384.9186644554138 and batch: 700, loss is 3.8869074535369874 and perplexity is 48.75986098172835
At time: 385.90795731544495 and batch: 750, loss is 3.851656937599182 and perplexity is 47.070992348961596
At time: 386.89913535118103 and batch: 800, loss is 3.8302543926239014 and perplexity is 46.07425769478839
At time: 387.88907504081726 and batch: 850, loss is 3.8275089502334594 and perplexity is 45.94793695710371
At time: 388.879341840744 and batch: 900, loss is 3.7968777227401733 and perplexity is 44.56183266220401
At time: 389.87071919441223 and batch: 950, loss is 3.89705361366272 and perplexity is 49.257104630092705
At time: 390.86126589775085 and batch: 1000, loss is 3.8722889900207518 and perplexity is 48.05225141648804
At time: 391.8520450592041 and batch: 1050, loss is 3.8075575494766234 and perplexity is 45.04029571763007
At time: 392.8419978618622 and batch: 1100, loss is 3.8346885776519777 and perplexity is 46.27901310463315
At time: 393.8333215713501 and batch: 1150, loss is 3.811569957733154 and perplexity is 45.22137881876479
At time: 394.8241286277771 and batch: 1200, loss is 3.867149519920349 and perplexity is 47.8059218510096
At time: 395.8137421607971 and batch: 1250, loss is 3.853162603378296 and perplexity is 47.14191891378172
At time: 396.80575680732727 and batch: 1300, loss is 3.8548778438568116 and perplexity is 47.222848027942334
At time: 397.79551815986633 and batch: 1350, loss is 3.748085389137268 and perplexity is 42.43974856035948
At time: 398.78602719306946 and batch: 1400, loss is 3.7690184116363525 and perplexity is 43.33750436084529
At time: 399.7753291130066 and batch: 1450, loss is 3.688129801750183 and perplexity is 39.970025142215135
At time: 400.76608514785767 and batch: 1500, loss is 3.7040017652511597 and perplexity is 40.609489273697
At time: 401.75784039497375 and batch: 1550, loss is 3.7104191064834593 and perplexity is 40.870932210671576
At time: 402.7480447292328 and batch: 1600, loss is 3.8044104766845703 and perplexity is 44.8987734356964
At time: 403.73789381980896 and batch: 1650, loss is 3.741589460372925 and perplexity is 42.164956458180065
At time: 404.7280032634735 and batch: 1700, loss is 3.766793966293335 and perplexity is 43.24120959202364
At time: 405.7192885875702 and batch: 1750, loss is 3.762704191207886 and perplexity is 43.06472390973805
At time: 406.7105951309204 and batch: 1800, loss is 3.725699849128723 and perplexity is 41.500266509376665
At time: 407.7064561843872 and batch: 1850, loss is 3.749307632446289 and perplexity is 42.49165197191122
At time: 408.6998088359833 and batch: 1900, loss is 3.8356679821014406 and perplexity is 46.32436117941274
At time: 409.68903160095215 and batch: 1950, loss is 3.7678321695327757 and perplexity is 43.286126068080385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.297072015806686 and perplexity of 73.48431747801969
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 412.87108612060547 and batch: 50, loss is 3.8853151750564576 and perplexity is 48.68228348325473
At time: 413.82984161376953 and batch: 100, loss is 3.8974653911590575 and perplexity is 49.27739177392212
At time: 414.78709053993225 and batch: 150, loss is 3.8630640792846678 and perplexity is 47.6110120126407
At time: 415.7455654144287 and batch: 200, loss is 3.860720167160034 and perplexity is 47.499546667836604
At time: 416.7047691345215 and batch: 250, loss is 3.856427483558655 and perplexity is 47.29608315745721
At time: 417.66611886024475 and batch: 300, loss is 3.8627200317382813 and perplexity is 47.59463437828078
At time: 418.636390209198 and batch: 350, loss is 3.875660820007324 and perplexity is 48.214548904738756
At time: 419.60955119132996 and batch: 400, loss is 3.8396794033050536 and perplexity is 46.510560917193764
At time: 420.58279275894165 and batch: 450, loss is 3.875353941917419 and perplexity is 48.1997551861154
At time: 421.56613969802856 and batch: 500, loss is 3.877781181335449 and perplexity is 48.3168896310054
At time: 422.5713975429535 and batch: 550, loss is 3.8474295377731322 and perplexity is 46.8724244527542
At time: 423.5659165382385 and batch: 600, loss is 3.8287552118301393 and perplexity is 46.00523580363978
At time: 424.54895424842834 and batch: 650, loss is 3.867740497589111 and perplexity is 47.834182433122095
At time: 425.5315577983856 and batch: 700, loss is 3.8915634632110594 and perplexity is 48.98741670590491
At time: 426.5189723968506 and batch: 750, loss is 3.8536345291137697 and perplexity is 47.164171648942954
At time: 427.5161771774292 and batch: 800, loss is 3.8280317258834837 and perplexity is 45.97196369946447
At time: 428.5004527568817 and batch: 850, loss is 3.8217129468917848 and perplexity is 45.68239285160137
At time: 429.4837260246277 and batch: 900, loss is 3.7873603534698486 and perplexity is 44.139733070392246
At time: 430.46527647972107 and batch: 950, loss is 3.8870549058914183 and perplexity is 48.767051268131134
At time: 431.44735312461853 and batch: 1000, loss is 3.8633915758132935 and perplexity is 47.62660700731312
At time: 432.42893290519714 and batch: 1050, loss is 3.7953648567199707 and perplexity is 44.494467549814715
At time: 433.41145372390747 and batch: 1100, loss is 3.820266785621643 and perplexity is 45.616376490989396
At time: 434.39448523521423 and batch: 1150, loss is 3.801058750152588 and perplexity is 44.748536941986785
At time: 435.37793469429016 and batch: 1200, loss is 3.8511545276641845 and perplexity is 47.047349354490265
At time: 436.36081886291504 and batch: 1250, loss is 3.8261200046539305 and perplexity is 45.88416207335282
At time: 437.3437645435333 and batch: 1300, loss is 3.8304398584365846 and perplexity is 46.08280368690573
At time: 438.32945466041565 and batch: 1350, loss is 3.717972393035889 and perplexity is 41.180810901328464
At time: 439.3197102546692 and batch: 1400, loss is 3.7345889902114866 and perplexity is 41.87081271214222
At time: 440.309312582016 and batch: 1450, loss is 3.647647571563721 and perplexity is 38.38426352496622
At time: 441.2995626926422 and batch: 1500, loss is 3.6575006103515624 and perplexity is 38.76433451457733
At time: 442.28871297836304 and batch: 1550, loss is 3.6668805408477785 and perplexity is 39.12965192554228
At time: 443.277822971344 and batch: 1600, loss is 3.75426206111908 and perplexity is 42.702696200887544
At time: 444.26859307289124 and batch: 1650, loss is 3.692531533241272 and perplexity is 40.1463502437643
At time: 445.27299070358276 and batch: 1700, loss is 3.713948063850403 and perplexity is 41.01541878151718
At time: 446.2623589038849 and batch: 1750, loss is 3.7065314722061156 and perplexity is 40.71234942932166
At time: 447.2526412010193 and batch: 1800, loss is 3.666971664428711 and perplexity is 39.13321772200798
At time: 448.24100065231323 and batch: 1850, loss is 3.6846397972106932 and perplexity is 39.830772710177975
At time: 449.2297341823578 and batch: 1900, loss is 3.7699862480163575 and perplexity is 43.37946827801152
At time: 450.22074341773987 and batch: 1950, loss is 3.709617466926575 and perplexity is 40.83818158353774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.267253928960756 and perplexity of 71.32550154926292
finished 11 epochs...
Completing Train Step...
At time: 453.42846870422363 and batch: 50, loss is 3.8735812425613405 and perplexity is 48.11438719937686
At time: 454.38568234443665 and batch: 100, loss is 3.8674631023406985 and perplexity is 47.82091529840858
At time: 455.3426628112793 and batch: 150, loss is 3.827140555381775 and perplexity is 45.93101309120712
At time: 456.30153465270996 and batch: 200, loss is 3.823003339767456 and perplexity is 45.74137913543599
At time: 457.2606074810028 and batch: 250, loss is 3.8169608402252195 and perplexity is 45.46582024361647
At time: 458.2258222103119 and batch: 300, loss is 3.823545331954956 and perplexity is 45.76617732517839
At time: 459.1986870765686 and batch: 350, loss is 3.83692018032074 and perplexity is 46.38240479546374
At time: 460.1715474128723 and batch: 400, loss is 3.802999095916748 and perplexity is 44.8354488684205
At time: 461.1441240310669 and batch: 450, loss is 3.8391724491119383 and perplexity is 46.48698816896928
At time: 462.1270852088928 and batch: 500, loss is 3.842889666557312 and perplexity is 46.66011198245593
At time: 463.109002828598 and batch: 550, loss is 3.8150390577316284 and perplexity is 45.378528730731944
At time: 464.0912039279938 and batch: 600, loss is 3.7977394914627074 and perplexity is 44.600251207383785
At time: 465.0737044811249 and batch: 650, loss is 3.8381919193267824 and perplexity is 46.44142863233897
At time: 466.05650639533997 and batch: 700, loss is 3.864299483299255 and perplexity is 47.66986719549876
At time: 467.0381426811218 and batch: 750, loss is 3.828518581390381 and perplexity is 45.99435085236657
At time: 468.02110171318054 and batch: 800, loss is 3.80349027633667 and perplexity is 44.85747657236865
At time: 469.00300455093384 and batch: 850, loss is 3.79784245967865 and perplexity is 44.604843852125356
At time: 469.9899671077728 and batch: 900, loss is 3.7635264444351195 and perplexity is 43.10014857998159
At time: 471.0030572414398 and batch: 950, loss is 3.863886661529541 and perplexity is 47.650192097994776
At time: 471.9928615093231 and batch: 1000, loss is 3.841002492904663 and perplexity is 46.572139284480876
At time: 472.98266649246216 and batch: 1050, loss is 3.7761346817016603 and perplexity is 43.64700568721752
At time: 473.98145961761475 and batch: 1100, loss is 3.801159129142761 and perplexity is 44.75302898038611
At time: 474.97766375541687 and batch: 1150, loss is 3.7838966512680052 and perplexity is 43.98711065165866
At time: 475.96696972846985 and batch: 1200, loss is 3.834777693748474 and perplexity is 46.28313749340273
At time: 476.9559283256531 and batch: 1250, loss is 3.812508234977722 and perplexity is 45.263828921346764
At time: 477.9522762298584 and batch: 1300, loss is 3.8174967861175535 and perplexity is 45.49019399413994
At time: 478.9473011493683 and batch: 1350, loss is 3.706669487953186 and perplexity is 40.717968762412454
At time: 479.9344127178192 and batch: 1400, loss is 3.7251824426651 and perplexity is 41.478799557291424
At time: 480.9234414100647 and batch: 1450, loss is 3.6402180433273315 and perplexity is 38.10014330178665
At time: 481.90966176986694 and batch: 1500, loss is 3.651320948600769 and perplexity is 38.52552268742232
At time: 482.8971378803253 and batch: 1550, loss is 3.662597794532776 and perplexity is 38.962427897596235
At time: 483.88886523246765 and batch: 1600, loss is 3.7516868686676026 and perplexity is 42.59287001245277
At time: 484.8765685558319 and batch: 1650, loss is 3.691023416519165 and perplexity is 40.085850493439494
At time: 485.86499667167664 and batch: 1700, loss is 3.7143146848678588 and perplexity is 41.03045865288024
At time: 486.85234665870667 and batch: 1750, loss is 3.7084453535079955 and perplexity is 40.79034264472131
At time: 487.84183740615845 and batch: 1800, loss is 3.6703699827194214 and perplexity is 39.266431074050516
At time: 488.83131408691406 and batch: 1850, loss is 3.6888606691360475 and perplexity is 39.99924860794191
At time: 489.8208689689636 and batch: 1900, loss is 3.775282597541809 and perplexity is 43.609830605444905
At time: 490.8171720504761 and batch: 1950, loss is 3.715343494415283 and perplexity is 41.07269290225179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2662353515625 and perplexity of 71.25288799300725
finished 12 epochs...
Completing Train Step...
At time: 494.10324239730835 and batch: 50, loss is 3.8599655532836916 and perplexity is 47.46371637152075
At time: 495.05518221855164 and batch: 100, loss is 3.8520340585708617 and perplexity is 47.088747154978584
At time: 496.047358751297 and batch: 150, loss is 3.8107045125961303 and perplexity is 45.18225912679188
At time: 497.00585556030273 and batch: 200, loss is 3.806299591064453 and perplexity is 44.98367252102568
At time: 497.9657905101776 and batch: 250, loss is 3.799220337867737 and perplexity is 44.66634625527633
At time: 498.93407678604126 and batch: 300, loss is 3.806254849433899 and perplexity is 44.98165992319256
At time: 499.9046688079834 and batch: 350, loss is 3.819703583717346 and perplexity is 45.5906924941994
At time: 500.8961868286133 and batch: 400, loss is 3.7863307762145997 and perplexity is 44.09431119184911
At time: 501.86948919296265 and batch: 450, loss is 3.8227710199356078 and perplexity is 45.730753740219555
At time: 502.8431980609894 and batch: 500, loss is 3.8269346618652342 and perplexity is 45.921557166893656
At time: 503.82561111450195 and batch: 550, loss is 3.7994444465637205 and perplexity is 44.67635749365084
At time: 504.80874013900757 and batch: 600, loss is 3.7830157232284547 and perplexity is 43.94837823524743
At time: 505.79208064079285 and batch: 650, loss is 3.8236602640151975 and perplexity is 45.771437628510704
At time: 506.77548909187317 and batch: 700, loss is 3.8502210187911987 and perplexity is 47.003450729483276
At time: 507.75911831855774 and batch: 750, loss is 3.815321807861328 and perplexity is 45.39136132974016
At time: 508.7432630062103 and batch: 800, loss is 3.7906789350509644 and perplexity is 44.28645769972492
At time: 509.7275049686432 and batch: 850, loss is 3.784965534210205 and perplexity is 44.03415286073945
At time: 510.7114067077637 and batch: 900, loss is 3.751134099960327 and perplexity is 42.5693325127528
At time: 511.6944589614868 and batch: 950, loss is 3.8518117332458495 and perplexity is 47.07827929764095
At time: 512.6788535118103 and batch: 1000, loss is 3.8294110012054445 and perplexity is 46.03541544315009
At time: 513.6628932952881 and batch: 1050, loss is 3.7659396934509277 and perplexity is 43.20428557483443
At time: 514.6453528404236 and batch: 1100, loss is 3.790629754066467 and perplexity is 44.284279701693826
At time: 515.6280674934387 and batch: 1150, loss is 3.774033885002136 and perplexity is 43.5554084490011
At time: 516.6087415218353 and batch: 1200, loss is 3.825304775238037 and perplexity is 45.84677119784862
At time: 517.590832233429 and batch: 1250, loss is 3.8040101432800295 and perplexity is 44.88080255427926
At time: 518.5714321136475 and batch: 1300, loss is 3.809359083175659 and perplexity is 45.121510461763755
At time: 519.5535130500793 and batch: 1350, loss is 3.6991535091400145 and perplexity is 40.413080573720286
At time: 520.5354857444763 and batch: 1400, loss is 3.7185474586486817 and perplexity is 41.20449938014673
At time: 521.5159499645233 and batch: 1450, loss is 3.634307475090027 and perplexity is 37.8756140064681
At time: 522.4966814517975 and batch: 1500, loss is 3.645921049118042 and perplexity is 38.3180494089563
At time: 523.4825356006622 and batch: 1550, loss is 3.6579066276550294 and perplexity is 38.78007670073136
At time: 524.4708535671234 and batch: 1600, loss is 3.747704949378967 and perplexity is 42.42360586353138
At time: 525.4580080509186 and batch: 1650, loss is 3.6873246145248415 and perplexity is 39.9378547419098
At time: 526.460666179657 and batch: 1700, loss is 3.71156533241272 and perplexity is 40.917806391993444
At time: 527.4639000892639 and batch: 1750, loss is 3.706580276489258 and perplexity is 40.71433641483691
At time: 528.4725935459137 and batch: 1800, loss is 3.6690578413009645 and perplexity is 39.214941751507126
At time: 529.4603924751282 and batch: 1850, loss is 3.687996997833252 and perplexity is 39.96471731877409
At time: 530.4479179382324 and batch: 1900, loss is 3.7748918867111207 and perplexity is 43.59279510049773
At time: 531.4352672100067 and batch: 1950, loss is 3.7151273822784425 and perplexity is 41.06381755389267
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.266675088571947 and perplexity of 71.28422741493462
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 534.6215937137604 and batch: 50, loss is 3.858509211540222 and perplexity is 47.39464328928348
At time: 535.6178426742554 and batch: 100, loss is 3.86340558052063 and perplexity is 47.62727400867625
At time: 536.5739216804504 and batch: 150, loss is 3.8262432861328124 and perplexity is 45.88981908940596
At time: 537.5316984653473 and batch: 200, loss is 3.8247400093078614 and perplexity is 45.82088581374707
At time: 538.4886038303375 and batch: 250, loss is 3.820305199623108 and perplexity is 45.61812883219976
At time: 539.4459898471832 and batch: 300, loss is 3.8300735902786256 and perplexity is 46.0659281139669
At time: 540.4080209732056 and batch: 350, loss is 3.8393430709838867 and perplexity is 46.49492054261089
At time: 541.3727107048035 and batch: 400, loss is 3.809928755760193 and perplexity is 45.14722227220799
At time: 542.343700170517 and batch: 450, loss is 3.8494018840789797 and perplexity is 46.96496433631895
At time: 543.3206479549408 and batch: 500, loss is 3.852409062385559 and perplexity is 47.10640892619984
At time: 544.2988440990448 and batch: 550, loss is 3.826082720756531 and perplexity is 45.88245136485295
At time: 545.2955338954926 and batch: 600, loss is 3.805590271949768 and perplexity is 44.95177605598131
At time: 546.268102645874 and batch: 650, loss is 3.8392799997329714 and perplexity is 46.49198814228711
At time: 547.2415945529938 and batch: 700, loss is 3.8638164138793947 and perplexity is 47.6468449015386
At time: 548.2176666259766 and batch: 750, loss is 3.825507698059082 and perplexity is 45.856075497991384
At time: 549.1930749416351 and batch: 800, loss is 3.8008601474761963 and perplexity is 44.73965064523586
At time: 550.1728637218475 and batch: 850, loss is 3.7950759363174438 and perplexity is 44.48161404724898
At time: 551.1591136455536 and batch: 900, loss is 3.7606637573242185 and perplexity is 42.976942774139005
At time: 552.1423218250275 and batch: 950, loss is 3.865481662750244 and perplexity is 47.72625485652868
At time: 553.1273658275604 and batch: 1000, loss is 3.83652400970459 and perplexity is 46.36403308898283
At time: 554.114875793457 and batch: 1050, loss is 3.7719916200637815 and perplexity is 43.46654753509984
At time: 555.0994386672974 and batch: 1100, loss is 3.7915902614593504 and perplexity is 44.326835514050266
At time: 556.0822687149048 and batch: 1150, loss is 3.776379270553589 and perplexity is 43.65768256389795
At time: 557.0647990703583 and batch: 1200, loss is 3.8256668710708617 and perplexity is 45.86337512857347
At time: 558.0480244159698 and batch: 1250, loss is 3.80153742313385 and perplexity is 44.769961984957426
At time: 559.0308446884155 and batch: 1300, loss is 3.805865921974182 and perplexity is 44.96416872208949
At time: 560.0137851238251 and batch: 1350, loss is 3.693645725250244 and perplexity is 40.19110591497085
At time: 560.9981980323792 and batch: 1400, loss is 3.709615912437439 and perplexity is 40.83811810107747
At time: 561.9825723171234 and batch: 1450, loss is 3.6247692918777465 and perplexity is 37.51606689975589
At time: 562.9651265144348 and batch: 1500, loss is 3.63737238407135 and perplexity is 37.99187739334735
At time: 563.949049949646 and batch: 1550, loss is 3.647620286941528 and perplexity is 38.38321623912526
At time: 564.9330599308014 and batch: 1600, loss is 3.731806364059448 and perplexity is 41.75446384645469
At time: 565.9162364006042 and batch: 1650, loss is 3.6703985261917116 and perplexity is 39.26755189033373
At time: 566.8988366127014 and batch: 1700, loss is 3.692989640235901 and perplexity is 40.16474578086021
At time: 567.882602930069 and batch: 1750, loss is 3.6888359880447386 and perplexity is 39.99826139501753
At time: 568.8646051883698 and batch: 1800, loss is 3.6523163414001463 and perplexity is 38.56388980730718
At time: 569.847115278244 and batch: 1850, loss is 3.6684225273132323 and perplexity is 39.19003586285172
At time: 570.8292503356934 and batch: 1900, loss is 3.75464017868042 and perplexity is 42.71884589328642
At time: 571.8124949932098 and batch: 1950, loss is 3.698790168762207 and perplexity is 40.398399537024495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.256337436409884 and perplexity of 70.55111174349479
finished 14 epochs...
Completing Train Step...
At time: 574.9703781604767 and batch: 50, loss is 3.858734860420227 and perplexity is 47.405339044157124
At time: 575.9436149597168 and batch: 100, loss is 3.8543514728546144 and perplexity is 47.19799783088459
At time: 576.8929016590118 and batch: 150, loss is 3.8123548555374147 and perplexity is 45.256886912994936
At time: 577.8423185348511 and batch: 200, loss is 3.8079727935791015 and perplexity is 45.05900231843473
At time: 578.7948310375214 and batch: 250, loss is 3.803381896018982 and perplexity is 44.85261516825207
At time: 579.755654335022 and batch: 300, loss is 3.812394871711731 and perplexity is 45.25869795670594
At time: 580.7240285873413 and batch: 350, loss is 3.821642475128174 and perplexity is 45.67917364624403
At time: 581.6913919448853 and batch: 400, loss is 3.7916434383392335 and perplexity is 44.32919273953238
At time: 582.6580407619476 and batch: 450, loss is 3.831845245361328 and perplexity is 46.14761338734842
At time: 583.6237595081329 and batch: 500, loss is 3.835229744911194 and perplexity is 46.30406456921906
At time: 584.5878024101257 and batch: 550, loss is 3.809012246131897 and perplexity is 45.105863364118534
At time: 585.5531466007233 and batch: 600, loss is 3.7906328773498537 and perplexity is 44.2844180142649
At time: 586.5208783149719 and batch: 650, loss is 3.825107045173645 and perplexity is 45.837706809008125
At time: 587.4943656921387 and batch: 700, loss is 3.8513989353179934 and perplexity is 47.0588494920675
At time: 588.467232465744 and batch: 750, loss is 3.814971995353699 and perplexity is 45.37548564072789
At time: 589.441516160965 and batch: 800, loss is 3.7909470415115356 and perplexity is 44.29833277697136
At time: 590.4161353111267 and batch: 850, loss is 3.7858096837997435 and perplexity is 44.071339966334214
At time: 591.3925273418427 and batch: 900, loss is 3.751495151519775 and perplexity is 42.584705011606545
At time: 592.3702561855316 and batch: 950, loss is 3.856010103225708 and perplexity is 47.276346821587595
At time: 593.3503384590149 and batch: 1000, loss is 3.827316255569458 and perplexity is 45.93908388782721
At time: 594.3728060722351 and batch: 1050, loss is 3.763822259902954 and perplexity is 43.112900156561324
At time: 595.3558912277222 and batch: 1100, loss is 3.7836803197860718 and perplexity is 43.977595884034415
At time: 596.3368458747864 and batch: 1150, loss is 3.769684228897095 and perplexity is 43.366368827449946
At time: 597.318478345871 and batch: 1200, loss is 3.820067844390869 and perplexity is 45.60730241554063
At time: 598.298898935318 and batch: 1250, loss is 3.796962523460388 and perplexity is 44.56561169793807
At time: 599.2813627719879 and batch: 1300, loss is 3.801518054008484 and perplexity is 44.769094838349076
At time: 600.2636659145355 and batch: 1350, loss is 3.6902064085006714 and perplexity is 40.053113407210205
At time: 601.2477269172668 and batch: 1400, loss is 3.707450370788574 and perplexity is 40.74977714300377
At time: 602.228978395462 and batch: 1450, loss is 3.6235039138793947 and perplexity is 37.46862491646744
At time: 603.2110869884491 and batch: 1500, loss is 3.6368332004547117 and perplexity is 37.9713983169789
At time: 604.1958422660828 and batch: 1550, loss is 3.648303713798523 and perplexity is 38.40945732587126
At time: 605.1775760650635 and batch: 1600, loss is 3.7339121294021607 and perplexity is 41.84248158915779
At time: 606.1595585346222 and batch: 1650, loss is 3.6730873584747314 and perplexity is 39.37327782748983
At time: 607.1413481235504 and batch: 1700, loss is 3.6964278697967528 and perplexity is 40.303079071638194
At time: 608.1229639053345 and batch: 1750, loss is 3.692878246307373 and perplexity is 40.16027192122437
At time: 609.1027812957764 and batch: 1800, loss is 3.656748538017273 and perplexity is 38.735191891085826
At time: 610.0840814113617 and batch: 1850, loss is 3.6727461433410644 and perplexity is 39.35984536104376
At time: 611.0658528804779 and batch: 1900, loss is 3.7593063497543335 and perplexity is 42.9186451224751
At time: 612.0474879741669 and batch: 1950, loss is 3.7030836009979247 and perplexity is 40.57222020448554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.255178620094477 and perplexity of 70.46940331580946
finished 15 epochs...
Completing Train Step...
At time: 615.186274766922 and batch: 50, loss is 3.8554955434799196 and perplexity is 47.25202657423204
At time: 616.1751937866211 and batch: 100, loss is 3.8493556594848632 and perplexity is 46.96279345007937
At time: 617.1207234859467 and batch: 150, loss is 3.8065542507171632 and perplexity is 44.99512950620153
At time: 618.0993001461029 and batch: 200, loss is 3.8014241361618044 and perplexity is 44.76489041880217
At time: 619.0545480251312 and batch: 250, loss is 3.7965320444107054 and perplexity is 44.546431264449396
At time: 620.0160763263702 and batch: 300, loss is 3.805368871688843 and perplexity is 44.94182482267694
At time: 620.9801406860352 and batch: 350, loss is 3.8145907497406006 and perplexity is 45.358189733089105
At time: 621.9443440437317 and batch: 400, loss is 3.784170985221863 and perplexity is 43.99917946500945
At time: 622.9089069366455 and batch: 450, loss is 3.824518985748291 and perplexity is 45.81075943758692
At time: 623.8804752826691 and batch: 500, loss is 3.828016605377197 and perplexity is 45.97126858535359
At time: 624.8507525920868 and batch: 550, loss is 3.8019759321212767 and perplexity is 44.78959832069478
At time: 625.8288469314575 and batch: 600, loss is 3.784245834350586 and perplexity is 44.00247288851033
At time: 626.8087818622589 and batch: 650, loss is 3.819032382965088 and perplexity is 45.56010225434577
At time: 627.788741350174 and batch: 700, loss is 3.8457061290740966 and perplexity is 46.79171367751035
At time: 628.7680702209473 and batch: 750, loss is 3.809854311943054 and perplexity is 45.14386146574602
At time: 629.7484354972839 and batch: 800, loss is 3.786050543785095 and perplexity is 44.08195626710263
At time: 630.7278580665588 and batch: 850, loss is 3.7810645961761473 and perplexity is 43.86271296465762
At time: 631.7066254615784 and batch: 900, loss is 3.7467898750305175 and perplexity is 42.38480286655819
At time: 632.6873581409454 and batch: 950, loss is 3.8514043140411376 and perplexity is 47.05910260927112
At time: 633.6684987545013 and batch: 1000, loss is 3.8228734874725343 and perplexity is 45.73543989800253
At time: 634.6488590240479 and batch: 1050, loss is 3.7600468301773073 and perplexity is 42.950437308261776
At time: 635.6281945705414 and batch: 1100, loss is 3.779902539253235 and perplexity is 43.811771599514834
At time: 636.6083846092224 and batch: 1150, loss is 3.7664613580703734 and perplexity is 43.2268296017266
At time: 637.5884056091309 and batch: 1200, loss is 3.8172131538391114 and perplexity is 45.47729333637858
At time: 638.5691590309143 and batch: 1250, loss is 3.794638166427612 and perplexity is 44.46214559762942
At time: 639.5487594604492 and batch: 1300, loss is 3.7992408514022826 and perplexity is 44.667262529311245
At time: 640.5297694206238 and batch: 1350, loss is 3.68834997177124 and perplexity is 39.978826312333695
At time: 641.5095891952515 and batch: 1400, loss is 3.706067690849304 and perplexity is 40.69347217846122
At time: 642.5051822662354 and batch: 1450, loss is 3.622578797340393 and perplexity is 37.43397810050581
At time: 643.4943454265594 and batch: 1500, loss is 3.636111607551575 and perplexity is 37.944008308837425
At time: 644.4761672019958 and batch: 1550, loss is 3.6481576776504516 and perplexity is 38.40384856622468
At time: 645.4578921794891 and batch: 1600, loss is 3.734320731163025 and perplexity is 41.85958199420395
At time: 646.4395568370819 and batch: 1650, loss is 3.673713917732239 and perplexity is 39.3979552493373
At time: 647.4209840297699 and batch: 1700, loss is 3.697317957878113 and perplexity is 40.33896833189391
At time: 648.4015476703644 and batch: 1750, loss is 3.6941396045684813 and perplexity is 40.21096037340897
At time: 649.3831329345703 and batch: 1800, loss is 3.6580874919891357 and perplexity is 38.78709126780381
At time: 650.3650009632111 and batch: 1850, loss is 3.674007258415222 and perplexity is 39.40951396767657
At time: 651.346560716629 and batch: 1900, loss is 3.7606199407577514 and perplexity is 42.97505971332432
At time: 652.3293960094452 and batch: 1950, loss is 3.704240097999573 and perplexity is 40.61916899833913
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.254842784792878 and perplexity of 70.4457411760067
finished 16 epochs...
Completing Train Step...
At time: 655.5056321620941 and batch: 50, loss is 3.8519317626953127 and perplexity is 47.08393041673029
At time: 656.4556601047516 and batch: 100, loss is 3.8450270318984985 and perplexity is 46.75994834400547
At time: 657.4053399562836 and batch: 150, loss is 3.801785988807678 and perplexity is 44.78109164389376
At time: 658.3594305515289 and batch: 200, loss is 3.796403374671936 and perplexity is 44.54069985551284
At time: 659.317519903183 and batch: 250, loss is 3.79128427028656 and perplexity is 44.31327396862764
At time: 660.2847929000854 and batch: 300, loss is 3.8002318477630617 and perplexity is 44.71154956444465
At time: 661.2586753368378 and batch: 350, loss is 3.809441924095154 and perplexity is 45.12524852400953
At time: 662.2318058013916 and batch: 400, loss is 3.778880195617676 and perplexity is 43.76700380159337
At time: 663.2061893939972 and batch: 450, loss is 3.819349241256714 and perplexity is 45.57454063785235
At time: 664.1800708770752 and batch: 500, loss is 3.8229830932617186 and perplexity is 45.74045304171601
At time: 665.1542921066284 and batch: 550, loss is 3.797032980918884 and perplexity is 44.56875178829472
At time: 666.1280355453491 and batch: 600, loss is 3.779688892364502 and perplexity is 43.802412350645525
At time: 667.1423239707947 and batch: 650, loss is 3.81461443901062 and perplexity is 45.35926424822047
At time: 668.1151700019836 and batch: 700, loss is 3.841497778892517 and perplexity is 46.59521152570011
At time: 669.088947057724 and batch: 750, loss is 3.8059851503372193 and perplexity is 44.96953004592613
At time: 670.0707800388336 and batch: 800, loss is 3.7823088788986206 and perplexity is 43.917324549640185
At time: 671.0526061058044 and batch: 850, loss is 3.7773768758773802 and perplexity is 43.70125743209447
At time: 672.0364580154419 and batch: 900, loss is 3.7431818294525145 and perplexity is 42.23215211703237
At time: 673.0209493637085 and batch: 950, loss is 3.8479624223709106 and perplexity is 46.897408702075204
At time: 674.0044364929199 and batch: 1000, loss is 3.819538450241089 and perplexity is 45.583164566236434
At time: 674.9883682727814 and batch: 1050, loss is 3.75718798160553 and perplexity is 42.827823862053734
At time: 675.9711339473724 and batch: 1100, loss is 3.776966762542725 and perplexity is 43.683338638299645
At time: 676.9504315853119 and batch: 1150, loss is 3.763896179199219 and perplexity is 43.116087149589525
At time: 677.9305894374847 and batch: 1200, loss is 3.81481463432312 and perplexity is 45.368345869320066
At time: 678.9127027988434 and batch: 1250, loss is 3.79261869430542 and perplexity is 44.37244613736671
At time: 679.8939454555511 and batch: 1300, loss is 3.7972333002090455 and perplexity is 44.577680663299425
At time: 680.8750593662262 and batch: 1350, loss is 3.686633048057556 and perplexity is 39.91024460901643
At time: 681.8568377494812 and batch: 1400, loss is 3.7046569061279295 and perplexity is 40.63610292699912
At time: 682.8383448123932 and batch: 1450, loss is 3.6214717054367065 and perplexity is 37.392558178488656
At time: 683.8203730583191 and batch: 1500, loss is 3.635065989494324 and perplexity is 37.90435410377453
At time: 684.8032791614532 and batch: 1550, loss is 3.64744882106781 and perplexity is 38.37663539162821
At time: 685.7856142520905 and batch: 1600, loss is 3.7339547061920166 and perplexity is 41.844263145629675
At time: 686.7669713497162 and batch: 1650, loss is 3.6734667730331423 and perplexity is 39.38821945666651
At time: 687.7481360435486 and batch: 1700, loss is 3.697213339805603 and perplexity is 40.3347483675261
At time: 688.7294805049896 and batch: 1750, loss is 3.6942747163772585 and perplexity is 40.2163937160438
At time: 689.7125706672668 and batch: 1800, loss is 3.658363676071167 and perplexity is 38.7978051244305
At time: 690.6950891017914 and batch: 1850, loss is 3.674235987663269 and perplexity is 39.41852910714601
At time: 691.6781244277954 and batch: 1900, loss is 3.7608984518051147 and perplexity is 42.98703040912371
At time: 692.6626253128052 and batch: 1950, loss is 3.7044328165054323 and perplexity is 40.62699781825275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.254779762445494 and perplexity of 70.44130165993046
finished 17 epochs...
Completing Train Step...
At time: 695.8615775108337 and batch: 50, loss is 3.8484801197052003 and perplexity is 46.92169365112967
At time: 696.8125658035278 and batch: 100, loss is 3.8411264705657957 and perplexity is 46.57791354731572
At time: 697.7744145393372 and batch: 150, loss is 3.797583346366882 and perplexity is 44.593287640562735
At time: 698.741152048111 and batch: 200, loss is 3.7921148777008056 and perplexity is 44.350096192824694
At time: 699.708417892456 and batch: 250, loss is 3.7868060636520386 and perplexity is 44.11527364522188
At time: 700.6823883056641 and batch: 300, loss is 3.7958694982528685 and perplexity is 44.51692697262667
At time: 701.6561231613159 and batch: 350, loss is 3.805087323188782 and perplexity is 44.929173300400244
At time: 702.6299512386322 and batch: 400, loss is 3.774523696899414 and perplexity is 43.57674763191641
At time: 703.6036677360535 and batch: 450, loss is 3.815146007537842 and perplexity is 45.383382215120925
At time: 704.5765910148621 and batch: 500, loss is 3.818860969543457 and perplexity is 45.55229331062649
At time: 705.5492420196533 and batch: 550, loss is 3.7929554414749145 and perplexity is 44.38739094917733
At time: 706.5219979286194 and batch: 600, loss is 3.775890226364136 and perplexity is 43.636337247741935
At time: 707.4948625564575 and batch: 650, loss is 3.8108863067626952 and perplexity is 45.19047374459553
At time: 708.4668011665344 and batch: 700, loss is 3.8379293727874755 and perplexity is 46.429237196450764
At time: 709.4393012523651 and batch: 750, loss is 3.8026852369308473 and perplexity is 44.82137906798839
At time: 710.4104528427124 and batch: 800, loss is 3.7790822839736937 and perplexity is 43.7758494972154
At time: 711.3818130493164 and batch: 850, loss is 3.774193353652954 and perplexity is 43.56235472506419
At time: 712.3549883365631 and batch: 900, loss is 3.7400414752960205 and perplexity is 42.09973622780985
At time: 713.3273990154266 and batch: 950, loss is 3.8450092267990112 and perplexity is 46.7591157858851
At time: 714.3071751594543 and batch: 1000, loss is 3.816655492782593 and perplexity is 45.45193949101216
At time: 715.3150699138641 and batch: 1050, loss is 3.7547053241729738 and perplexity is 42.72162892419344
At time: 716.2983484268188 and batch: 1100, loss is 3.7743731546401977 and perplexity is 43.57018798364313
At time: 717.281215429306 and batch: 1150, loss is 3.761585750579834 and perplexity is 43.01658549787743
At time: 718.2651722431183 and batch: 1200, loss is 3.812616925239563 and perplexity is 45.26874892613762
At time: 719.2503936290741 and batch: 1250, loss is 3.790717349052429 and perplexity is 44.28815895245161
At time: 720.2324621677399 and batch: 1300, loss is 3.795305833816528 and perplexity is 44.49184143465403
At time: 721.2135953903198 and batch: 1350, loss is 3.6849164295196535 and perplexity is 39.841792712974595
At time: 722.1960747241974 and batch: 1400, loss is 3.7031650304794312 and perplexity is 40.57552411385635
At time: 723.2014317512512 and batch: 1450, loss is 3.6202282524108886 and perplexity is 37.34609118462778
At time: 724.1917798519135 and batch: 1500, loss is 3.633891530036926 and perplexity is 37.85986310817015
At time: 725.174026966095 and batch: 1550, loss is 3.646464719772339 and perplexity is 38.338887471958245
At time: 726.1581513881683 and batch: 1600, loss is 3.7332494258880615 and perplexity is 41.814761615646454
At time: 727.1434972286224 and batch: 1650, loss is 3.672825951576233 and perplexity is 39.362986726190265
At time: 728.1267359256744 and batch: 1700, loss is 3.696643285751343 and perplexity is 40.3117619330692
At time: 729.1103677749634 and batch: 1750, loss is 3.6939204502105714 and perplexity is 40.202148931775575
At time: 730.0936751365662 and batch: 1800, loss is 3.6581423044204713 and perplexity is 38.78921734084771
At time: 731.0780167579651 and batch: 1850, loss is 3.67399778842926 and perplexity is 39.40914076189965
At time: 732.0622215270996 and batch: 1900, loss is 3.760707960128784 and perplexity is 42.97884251752796
At time: 733.0451731681824 and batch: 1950, loss is 3.704195327758789 and perplexity is 40.61735050907003
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25484505586846 and perplexity of 70.445901163791
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 736.2497270107269 and batch: 50, loss is 3.8484412240982055 and perplexity is 46.9198686388666
At time: 737.2082316875458 and batch: 100, loss is 3.845930981636047 and perplexity is 46.80223609716098
At time: 738.1666080951691 and batch: 150, loss is 3.8040674209594725 and perplexity is 44.883373296123466
At time: 739.1274631023407 and batch: 200, loss is 3.799957823753357 and perplexity is 44.69929920487588
At time: 740.1351249217987 and batch: 250, loss is 3.7952996778488157 and perplexity is 44.49156754515772
At time: 741.1001002788544 and batch: 300, loss is 3.805671463012695 and perplexity is 44.95542588662456
At time: 742.066086769104 and batch: 350, loss is 3.8132068634033205 and perplexity is 45.295462567678264
At time: 743.0329427719116 and batch: 400, loss is 3.784526295661926 and perplexity is 44.014815610505956
At time: 744.0046916007996 and batch: 450, loss is 3.82640522480011 and perplexity is 45.897251027294644
At time: 744.9759907722473 and batch: 500, loss is 3.830869965553284 and perplexity is 46.10262849181814
At time: 745.9482717514038 and batch: 550, loss is 3.8057769107818604 and perplexity is 44.960166585939874
At time: 746.9304625988007 and batch: 600, loss is 3.785245099067688 and perplexity is 44.04646498334655
At time: 747.9123454093933 and batch: 650, loss is 3.8180787658691404 and perplexity is 45.516676071209154
At time: 748.8945748806 and batch: 700, loss is 3.845347385406494 and perplexity is 46.77493045714929
At time: 749.8768200874329 and batch: 750, loss is 3.8076362371444703 and perplexity is 45.04383997290199
At time: 750.8588869571686 and batch: 800, loss is 3.783369975090027 and perplexity is 43.96394978801328
At time: 751.841151714325 and batch: 850, loss is 3.778737850189209 and perplexity is 43.76077421207183
At time: 752.8234186172485 and batch: 900, loss is 3.743885865211487 and perplexity is 42.26189553128618
At time: 753.8054220676422 and batch: 950, loss is 3.8512898874282837 and perplexity is 47.05371810362685
At time: 754.7868325710297 and batch: 1000, loss is 3.8211642360687255 and perplexity is 45.65733330407168
At time: 755.768173456192 and batch: 1050, loss is 3.7588707447052 and perplexity is 42.89995361531079
At time: 756.7477281093597 and batch: 1100, loss is 3.774826612472534 and perplexity is 43.58994970685614
At time: 757.7303586006165 and batch: 1150, loss is 3.7616166973114016 and perplexity is 43.017916741200494
At time: 758.7122912406921 and batch: 1200, loss is 3.812044129371643 and perplexity is 45.24282659861661
At time: 759.6950860023499 and batch: 1250, loss is 3.7891273880004883 and perplexity is 44.21779845470303
At time: 760.6777210235596 and batch: 1300, loss is 3.791968412399292 and perplexity is 44.343600918291436
At time: 761.6594185829163 and batch: 1350, loss is 3.680403971672058 and perplexity is 39.662413328122035
At time: 762.6425976753235 and batch: 1400, loss is 3.69736798286438 and perplexity is 40.340986338705704
At time: 763.6247489452362 and batch: 1450, loss is 3.613392400741577 and perplexity is 37.091669430284085
At time: 764.6069474220276 and batch: 1500, loss is 3.626726145744324 and perplexity is 37.58955223691088
At time: 765.58922290802 and batch: 1550, loss is 3.6406780672073364 and perplexity is 38.11767430956904
At time: 766.5711181163788 and batch: 1600, loss is 3.7263803052902222 and perplexity is 41.52851523134532
At time: 767.5535674095154 and batch: 1650, loss is 3.6640467071533203 and perplexity is 39.01892196870703
At time: 768.5361893177032 and batch: 1700, loss is 3.6856974744796753 and perplexity is 39.87292309990466
At time: 769.5176377296448 and batch: 1750, loss is 3.6847494411468507 and perplexity is 39.835140152305506
At time: 770.5001463890076 and batch: 1800, loss is 3.6491639184951783 and perplexity is 38.442511536114196
At time: 771.4826045036316 and batch: 1850, loss is 3.664926357269287 and perplexity is 39.053260068484235
At time: 772.4647765159607 and batch: 1900, loss is 3.7512327003479005 and perplexity is 42.5735300723744
At time: 773.4474332332611 and batch: 1950, loss is 3.696662564277649 and perplexity is 40.31253909192328
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253088095021802 and perplexity of 70.32223914011675
finished 19 epochs...
Completing Train Step...
At time: 776.6129016876221 and batch: 50, loss is 3.8473004293441773 and perplexity is 46.86637321831289
At time: 777.5995163917542 and batch: 100, loss is 3.8426832437515257 and perplexity is 46.65048126525624
At time: 778.5471441745758 and batch: 150, loss is 3.7997877979278565 and perplexity is 44.69169981569379
At time: 779.5021498203278 and batch: 200, loss is 3.7945807361602784 and perplexity is 44.45959219804343
At time: 780.461713552475 and batch: 250, loss is 3.789886541366577 and perplexity is 44.251379290130316
At time: 781.4285366535187 and batch: 300, loss is 3.799794626235962 and perplexity is 44.69200498543179
At time: 782.3953604698181 and batch: 350, loss is 3.80803297996521 and perplexity is 45.06171433855846
At time: 783.3660995960236 and batch: 400, loss is 3.7788064813613893 and perplexity is 43.76377766836571
At time: 784.3396942615509 and batch: 450, loss is 3.8205253076553345 and perplexity is 45.628170853895135
At time: 785.3211584091187 and batch: 500, loss is 3.825196304321289 and perplexity is 45.84179842625228
At time: 786.3041892051697 and batch: 550, loss is 3.7994638967514036 and perplexity is 44.6772264656399
At time: 787.2878754138947 and batch: 600, loss is 3.7798435401916506 and perplexity is 43.80918682235458
At time: 788.2711000442505 and batch: 650, loss is 3.8125639247894285 and perplexity is 45.26634972564742
At time: 789.3050127029419 and batch: 700, loss is 3.8403883028030394 and perplexity is 46.54354391991477
At time: 790.2879452705383 and batch: 750, loss is 3.8037221002578736 and perplexity is 44.86787681394877
At time: 791.2713556289673 and batch: 800, loss is 3.779521360397339 and perplexity is 43.79507466100389
At time: 792.2546741962433 and batch: 850, loss is 3.7750361347198487 and perplexity is 43.59908372793595
At time: 793.2386927604675 and batch: 900, loss is 3.740787525177002 and perplexity is 42.13115645008115
At time: 794.2226555347443 and batch: 950, loss is 3.848196601867676 and perplexity is 46.90839239967284
At time: 795.206113576889 and batch: 1000, loss is 3.818263077735901 and perplexity is 45.52506610791248
At time: 796.189371585846 and batch: 1050, loss is 3.756039619445801 and perplexity is 42.77867023822954
At time: 797.1728434562683 and batch: 1100, loss is 3.7722451066970826 and perplexity is 43.47756712049553
At time: 798.1558742523193 and batch: 1150, loss is 3.759460926055908 and perplexity is 42.92527984067861
At time: 799.1546080112457 and batch: 1200, loss is 3.8102338409423826 and perplexity is 45.16099812203724
At time: 800.1357476711273 and batch: 1250, loss is 3.7876882123947144 and perplexity is 44.154207048402355
At time: 801.1184620857239 and batch: 1300, loss is 3.7907615518569946 and perplexity is 44.29011665655404
At time: 802.1008214950562 and batch: 1350, loss is 3.6799264574050903 and perplexity is 39.64347848108508
At time: 803.0845830440521 and batch: 1400, loss is 3.6972652292251587 and perplexity is 40.33684136850866
At time: 804.0679025650024 and batch: 1450, loss is 3.613964877128601 and perplexity is 37.11290961436006
At time: 805.0511698722839 and batch: 1500, loss is 3.6279110145568847 and perplexity is 37.634117321710285
At time: 806.0345101356506 and batch: 1550, loss is 3.641837091445923 and perplexity is 38.1618792303512
At time: 807.0171341896057 and batch: 1600, loss is 3.727665090560913 and perplexity is 41.581904745714986
At time: 808.0005843639374 and batch: 1650, loss is 3.665946388244629 and perplexity is 39.093115927091624
At time: 808.9831073284149 and batch: 1700, loss is 3.68800546169281 and perplexity is 39.965055575960236
At time: 809.966655254364 and batch: 1750, loss is 3.687253308296204 and perplexity is 39.935007025639436
At time: 810.9559948444366 and batch: 1800, loss is 3.6517470932006835 and perplexity is 38.54194362947382
At time: 811.9489529132843 and batch: 1850, loss is 3.6674921178817748 and perplexity is 39.15359004126299
At time: 812.9304361343384 and batch: 1900, loss is 3.7538590145111086 and perplexity is 42.68548849201984
At time: 813.9124422073364 and batch: 1950, loss is 3.698788323402405 and perplexity is 40.3983249875107
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.252706554324128 and perplexity of 70.29541346180265
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f05ce5c4b38>
ELAPSED
1686.819445848465


RESULTS SO FAR:
[{'best_accuracy': -70.031277428607, 'params': {'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.29541346180265, 'params': {'tie_weights': True, 'rnn_dropout': 0.7288706260952753, 'num_layers': 2, 'dropout': 0.4475108336446092, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'rnn_dropout': 0.8506975178466405, 'num_layers': 2, 'dropout': 0.6098755685920833, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4365606307983398 and batch: 50, loss is 7.622424783706665 and perplexity is 2043.51119984591
At time: 2.398998498916626 and batch: 100, loss is 6.796667795181275 and perplexity is 894.860459710305
At time: 3.3660924434661865 and batch: 150, loss is 6.550840549468994 and perplexity is 699.8321702202967
At time: 4.3337836265563965 and batch: 200, loss is 6.4176006031036374 and perplexity is 612.5316429867548
At time: 5.30073881149292 and batch: 250, loss is 6.368160305023193 and perplexity is 582.9843283968221
At time: 6.265212535858154 and batch: 300, loss is 6.294074592590332 and perplexity is 541.3546409232672
At time: 7.231405019760132 and batch: 350, loss is 6.2484313583374025 and perplexity is 517.2008851573703
At time: 8.199189901351929 and batch: 400, loss is 6.20722526550293 and perplexity is 496.3221766234565
At time: 9.16763687133789 and batch: 450, loss is 6.121698703765869 and perplexity is 455.6380315183238
At time: 10.135668992996216 and batch: 500, loss is 6.102721395492554 and perplexity is 447.07277791690007
At time: 11.104700565338135 and batch: 550, loss is 6.060667982101441 and perplexity is 428.6616795756679
At time: 12.072662353515625 and batch: 600, loss is 6.093982076644897 and perplexity is 443.1826894831461
At time: 13.052728176116943 and batch: 650, loss is 6.1714101409912105 and perplexity is 478.8608915784065
At time: 14.03385043144226 and batch: 700, loss is 6.073167381286621 and perplexity is 434.05331895379237
At time: 15.00346326828003 and batch: 750, loss is 6.010455570220947 and perplexity is 407.66899983197817
At time: 15.976785659790039 and batch: 800, loss is 6.021543645858765 and perplexity is 412.21441793742144
At time: 16.945666313171387 and batch: 850, loss is 6.048169803619385 and perplexity is 423.33752978755575
At time: 17.915374279022217 and batch: 900, loss is 6.037162523269654 and perplexity is 418.70328691029715
At time: 18.8858425617218 and batch: 950, loss is 6.0607073116302494 and perplexity is 428.6785389690778
At time: 19.85533380508423 and batch: 1000, loss is 6.036210985183716 and perplexity is 418.3050642781418
At time: 20.825817584991455 and batch: 1050, loss is 5.945126867294311 and perplexity is 381.8878072973377
At time: 21.80039930343628 and batch: 1100, loss is 6.02962926864624 and perplexity is 415.5609393511327
At time: 22.806955337524414 and batch: 1150, loss is 5.933238487243653 and perplexity is 377.37466006703636
At time: 23.863760232925415 and batch: 1200, loss is 6.009609375 and perplexity is 407.3241781863821
At time: 24.94493055343628 and batch: 1250, loss is 5.945335702896118 and perplexity is 381.9675673954816
At time: 26.026960611343384 and batch: 1300, loss is 5.962229633331299 and perplexity is 388.47531686306553
At time: 27.109489917755127 and batch: 1350, loss is 5.934207010269165 and perplexity is 377.74033316738024
At time: 28.192864894866943 and batch: 1400, loss is 5.948012228012085 and perplexity is 382.99128257165097
At time: 29.276682138442993 and batch: 1450, loss is 5.932857465744019 and perplexity is 377.23089959778775
At time: 30.360458374023438 and batch: 1500, loss is 5.904887523651123 and perplexity is 366.8259642219061
At time: 31.4426851272583 and batch: 1550, loss is 5.876227140426636 and perplexity is 356.4618210985254
At time: 32.52455806732178 and batch: 1600, loss is 5.889917488098145 and perplexity is 361.3754653651603
At time: 33.60646462440491 and batch: 1650, loss is 5.888494272232055 and perplexity is 360.86151588651563
At time: 34.68934655189514 and batch: 1700, loss is 5.906582288742065 and perplexity is 367.4481751622834
At time: 35.771934032440186 and batch: 1750, loss is 5.915567855834961 and perplexity is 370.7647838831234
At time: 36.854928493499756 and batch: 1800, loss is 5.924222869873047 and perplexity is 373.987685302232
At time: 37.93822932243347 and batch: 1850, loss is 5.878095245361328 and perplexity is 357.1283515661376
At time: 39.02118802070618 and batch: 1900, loss is 5.865081920623779 and perplexity is 352.5110328485923
At time: 40.102421283721924 and batch: 1950, loss is 5.792040395736694 and perplexity is 327.6809415326872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.242915379723837 and perplexity of 189.22094997146797
finished 1 epochs...
Completing Train Step...
At time: 43.39159536361694 and batch: 50, loss is 5.501833190917969 and perplexity is 245.14091069800503
At time: 44.41651725769043 and batch: 100, loss is 5.390514087677002 and perplexity is 219.31610428439762
At time: 45.422011375427246 and batch: 150, loss is 5.2787757396698 and perplexity is 196.12961460421866
At time: 46.429609060287476 and batch: 200, loss is 5.216402006149292 and perplexity is 184.26998761752125
At time: 47.43840265274048 and batch: 250, loss is 5.21646390914917 and perplexity is 184.28139483560915
At time: 48.4466986656189 and batch: 300, loss is 5.195114326477051 and perplexity is 180.3887648301477
At time: 49.45531463623047 and batch: 350, loss is 5.178561525344849 and perplexity is 177.42740251644597
At time: 50.485493421554565 and batch: 400, loss is 5.125166435241699 and perplexity is 168.20213408515784
At time: 51.48920011520386 and batch: 450, loss is 5.0707981300354 and perplexity is 159.3014198662477
At time: 52.4943368434906 and batch: 500, loss is 5.051176586151123 and perplexity is 156.20614639497862
At time: 53.49959707260132 and batch: 550, loss is 4.993716173171997 and perplexity is 147.4834805404666
At time: 54.50533127784729 and batch: 600, loss is 4.991170101165771 and perplexity is 147.10845460339334
At time: 55.511319160461426 and batch: 650, loss is 5.063668279647827 and perplexity is 158.16966399546513
At time: 56.51906204223633 and batch: 700, loss is 5.03910496711731 and perplexity is 154.3318211363161
At time: 57.52506613731384 and batch: 750, loss is 4.986795682907104 and perplexity is 146.46634614298236
At time: 58.53215003013611 and batch: 800, loss is 4.965712404251098 and perplexity is 143.41068026837928
At time: 59.53864669799805 and batch: 850, loss is 4.953787822723388 and perplexity is 141.71072369874932
At time: 60.54518103599548 and batch: 900, loss is 4.958411531448364 and perplexity is 142.36746993997033
At time: 61.55195903778076 and batch: 950, loss is 5.009036569595337 and perplexity is 149.76038291674996
At time: 62.55963158607483 and batch: 1000, loss is 4.974011077880859 and perplexity is 144.60575058973018
At time: 63.57065963745117 and batch: 1050, loss is 4.88590708732605 and perplexity is 132.41051878000454
At time: 64.5762619972229 and batch: 1100, loss is 4.959703197479248 and perplexity is 142.5514799789695
At time: 65.58175897598267 and batch: 1150, loss is 4.868591547012329 and perplexity is 130.1374952124312
At time: 66.58795928955078 and batch: 1200, loss is 4.9501008129119874 and perplexity is 141.18919689811136
At time: 67.60241436958313 and batch: 1250, loss is 4.901391077041626 and perplexity is 134.47671710641265
At time: 68.6133873462677 and batch: 1300, loss is 4.921709480285645 and perplexity is 137.23701674984477
At time: 69.62001991271973 and batch: 1350, loss is 4.826348791122436 and perplexity is 124.7546228828817
At time: 70.6260232925415 and batch: 1400, loss is 4.837270154953003 and perplexity is 126.12458079641449
At time: 71.63205885887146 and batch: 1450, loss is 4.783603324890136 and perplexity is 119.5342958658936
At time: 72.63761043548584 and batch: 1500, loss is 4.759194717407227 and perplexity is 116.65195028062952
At time: 73.64345669746399 and batch: 1550, loss is 4.7620362949371335 and perplexity is 116.98389724452309
At time: 74.64731454849243 and batch: 1600, loss is 4.8202839279174805 and perplexity is 124.000292927089
At time: 75.65411400794983 and batch: 1650, loss is 4.783881416320801 and perplexity is 119.56754195175597
At time: 76.66025686264038 and batch: 1700, loss is 4.809280061721802 and perplexity is 122.64329012681915
At time: 77.66564583778381 and batch: 1750, loss is 4.8105405330657955 and perplexity is 122.79797594759904
At time: 78.67218065261841 and batch: 1800, loss is 4.75945897102356 and perplexity is 116.68278005360357
At time: 79.67825412750244 and batch: 1850, loss is 4.768806009292603 and perplexity is 117.77853150175305
At time: 80.68547224998474 and batch: 1900, loss is 4.8443221092224125 and perplexity is 127.01714904873522
At time: 81.69196581840515 and batch: 1950, loss is 4.762594871520996 and perplexity is 117.04925996355551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.602969431322674 and perplexity of 99.7801665219615
finished 2 epochs...
Completing Train Step...
At time: 84.95182538032532 and batch: 50, loss is 4.719414014816284 and perplexity is 112.10254298799221
At time: 85.98074579238892 and batch: 100, loss is 4.672314405441284 and perplexity is 106.9449702504571
At time: 86.98349571228027 and batch: 150, loss is 4.625798120498657 and perplexity is 102.08421608315767
At time: 87.98645758628845 and batch: 200, loss is 4.608293371200562 and perplexity is 100.31280674367797
At time: 88.9913969039917 and batch: 250, loss is 4.613872900009155 and perplexity is 100.8740692729396
At time: 89.99448990821838 and batch: 300, loss is 4.629149255752563 and perplexity is 102.4268879477375
At time: 90.99662256240845 and batch: 350, loss is 4.635402746200562 and perplexity is 103.0694204546716
At time: 92.00003576278687 and batch: 400, loss is 4.597180557250977 and perplexity is 99.20422035141932
At time: 93.00251841545105 and batch: 450, loss is 4.588860321044922 and perplexity is 98.38224207404285
At time: 94.00572156906128 and batch: 500, loss is 4.592044324874878 and perplexity is 98.69599073301
At time: 95.00807881355286 and batch: 550, loss is 4.556708307266235 and perplexity is 95.2693656513467
At time: 96.00915217399597 and batch: 600, loss is 4.535178508758545 and perplexity is 93.24015800379763
At time: 97.01126337051392 and batch: 650, loss is 4.60558385848999 and perplexity is 100.0413758076168
At time: 98.01265597343445 and batch: 700, loss is 4.6235057067871095 and perplexity is 101.85046485610174
At time: 99.01344013214111 and batch: 750, loss is 4.578695945739746 and perplexity is 97.38731302424019
At time: 100.0374219417572 and batch: 800, loss is 4.5621499252319335 and perplexity is 95.78919822545448
At time: 101.03939151763916 and batch: 850, loss is 4.5478715896606445 and perplexity is 94.4312059152185
At time: 102.04383945465088 and batch: 900, loss is 4.545764026641845 and perplexity is 94.23239577385175
At time: 103.04752588272095 and batch: 950, loss is 4.615346755981445 and perplexity is 101.0228527381532
At time: 104.05013513565063 and batch: 1000, loss is 4.59126844406128 and perplexity is 98.61944410679055
At time: 105.05299687385559 and batch: 1050, loss is 4.517551965713501 and perplexity is 91.61105624065868
At time: 106.05578446388245 and batch: 1100, loss is 4.57771900177002 and perplexity is 97.29221753509908
At time: 107.0597071647644 and batch: 1150, loss is 4.515894842147827 and perplexity is 91.45937111569494
At time: 108.06054711341858 and batch: 1200, loss is 4.596025524139404 and perplexity is 99.08970234088424
At time: 109.06294536590576 and batch: 1250, loss is 4.56583381652832 and perplexity is 96.14272599821565
At time: 110.06545519828796 and batch: 1300, loss is 4.5760282611846925 and perplexity is 97.1278606158855
At time: 111.0736620426178 and batch: 1350, loss is 4.4674013805389405 and perplexity is 87.13001082988895
At time: 112.0774998664856 and batch: 1400, loss is 4.482980642318726 and perplexity is 88.4980610132199
At time: 113.08160829544067 and batch: 1450, loss is 4.423681468963623 and perplexity is 83.40276555640219
At time: 114.08748507499695 and batch: 1500, loss is 4.427314691543579 and perplexity is 83.70633750574616
At time: 115.09318208694458 and batch: 1550, loss is 4.433786287307739 and perplexity is 84.24980774806066
At time: 116.09875202178955 and batch: 1600, loss is 4.502363548278809 and perplexity is 90.23014276855156
At time: 117.10345315933228 and batch: 1650, loss is 4.466742706298828 and perplexity is 87.0726394328195
At time: 118.10746550559998 and batch: 1700, loss is 4.486143980026245 and perplexity is 88.77845352094461
At time: 119.11062812805176 and batch: 1750, loss is 4.485644979476929 and perplexity is 88.73416407501811
At time: 120.11504888534546 and batch: 1800, loss is 4.443597078323364 and perplexity is 85.08043288740343
At time: 121.11950612068176 and batch: 1850, loss is 4.472983379364013 and perplexity is 87.61773040663
At time: 122.12415432929993 and batch: 1900, loss is 4.561087388992309 and perplexity is 95.68747278402991
At time: 123.13063049316406 and batch: 1950, loss is 4.490071516036988 and perplexity is 89.1278197191917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.464407703488372 and perplexity of 86.86956176076649
finished 3 epochs...
Completing Train Step...
At time: 126.37543082237244 and batch: 50, loss is 4.455665483474731 and perplexity is 86.11343885142126
At time: 127.37569499015808 and batch: 100, loss is 4.416304216384888 and perplexity is 82.78974626842604
At time: 128.35050654411316 and batch: 150, loss is 4.376505861282348 and perplexity is 79.55955504575991
At time: 129.33694648742676 and batch: 200, loss is 4.3662473011016845 and perplexity is 78.74756063021232
At time: 130.32834720611572 and batch: 250, loss is 4.369765110015869 and perplexity is 79.02506732254739
At time: 131.31946539878845 and batch: 300, loss is 4.390680027008057 and perplexity is 80.69527529309785
At time: 132.31039714813232 and batch: 350, loss is 4.391928730010986 and perplexity is 80.7961026642978
At time: 133.30072617530823 and batch: 400, loss is 4.355939044952392 and perplexity is 77.9399801285627
At time: 134.29144310951233 and batch: 450, loss is 4.366482381820679 and perplexity is 78.76607483946586
At time: 135.29063606262207 and batch: 500, loss is 4.37479040145874 and perplexity is 79.42319082260893
At time: 136.2910053730011 and batch: 550, loss is 4.344600954055786 and perplexity is 77.06128035157651
At time: 137.28969073295593 and batch: 600, loss is 4.327471151351928 and perplexity is 75.75247759292263
At time: 138.28885507583618 and batch: 650, loss is 4.390902509689331 and perplexity is 80.71323059160866
At time: 139.28841733932495 and batch: 700, loss is 4.415261173248291 and perplexity is 82.70343801124267
At time: 140.28836226463318 and batch: 750, loss is 4.374489688873291 and perplexity is 79.39931086023465
At time: 141.2885193824768 and batch: 800, loss is 4.354246692657471 and perplexity is 77.80818977363538
At time: 142.28593802452087 and batch: 850, loss is 4.344143714904785 and perplexity is 77.02605297145593
At time: 143.28479981422424 and batch: 900, loss is 4.338495655059814 and perplexity is 76.5922314927506
At time: 144.28269600868225 and batch: 950, loss is 4.41405327796936 and perplexity is 82.60360122724613
At time: 145.28154921531677 and batch: 1000, loss is 4.392476978302002 and perplexity is 80.84041113441596
At time: 146.27993750572205 and batch: 1050, loss is 4.324239225387573 and perplexity is 75.50804639825208
At time: 147.2796630859375 and batch: 1100, loss is 4.373816728591919 and perplexity is 79.3458962526279
At time: 148.27988481521606 and batch: 1150, loss is 4.32671826839447 and perplexity is 75.69546630766317
At time: 149.27910470962524 and batch: 1200, loss is 4.4042590045928955 and perplexity is 81.79850806211286
At time: 150.30218720436096 and batch: 1250, loss is 4.384096479415893 and perplexity is 80.16575906794901
At time: 151.31086945533752 and batch: 1300, loss is 4.3881877899169925 and perplexity is 80.49441393596754
At time: 152.3164200782776 and batch: 1350, loss is 4.2774222421646115 and perplexity is 72.0544614538843
At time: 153.3153989315033 and batch: 1400, loss is 4.295695705413818 and perplexity is 73.38324981435365
At time: 154.31479954719543 and batch: 1450, loss is 4.233560299873352 and perplexity is 68.96232216489287
At time: 155.3141086101532 and batch: 1500, loss is 4.243020548820495 and perplexity is 69.61781859153386
At time: 156.3136284351349 and batch: 1550, loss is 4.25088885307312 and perplexity is 70.16775345983515
At time: 157.3128490447998 and batch: 1600, loss is 4.3305689716339115 and perplexity is 75.98750900900791
At time: 158.3122124671936 and batch: 1650, loss is 4.290861287117004 and perplexity is 73.02934065052501
At time: 159.31081223487854 and batch: 1700, loss is 4.312264890670776 and perplexity is 74.60927958329653
At time: 160.30887460708618 and batch: 1750, loss is 4.311439037322998 and perplexity is 74.54768869599818
At time: 161.30611157417297 and batch: 1800, loss is 4.267385330200195 and perplexity is 71.33487442436036
At time: 162.30644989013672 and batch: 1850, loss is 4.302553281784058 and perplexity is 73.88821047854125
At time: 163.30667567253113 and batch: 1900, loss is 4.3958367824554445 and perplexity is 81.11247586969652
At time: 164.30693340301514 and batch: 1950, loss is 4.321419038772583 and perplexity is 75.2953996092294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.403727970566861 and perplexity of 81.75508180248424
finished 4 epochs...
Completing Train Step...
At time: 167.53599905967712 and batch: 50, loss is 4.291994938850403 and perplexity is 73.11217743430258
At time: 168.51702690124512 and batch: 100, loss is 4.253058261871338 and perplexity is 70.32014123746922
At time: 169.49479126930237 and batch: 150, loss is 4.224075222015381 and perplexity is 68.31130154138386
At time: 170.4740879535675 and batch: 200, loss is 4.2139355659484865 and perplexity is 67.62214823150369
At time: 171.46475887298584 and batch: 250, loss is 4.216817646026612 and perplexity is 67.81732179558324
At time: 172.45546221733093 and batch: 300, loss is 4.235938792228699 and perplexity is 69.12654374343373
At time: 173.44614434242249 and batch: 350, loss is 4.240920295715332 and perplexity is 69.47175698872032
At time: 174.43660259246826 and batch: 400, loss is 4.203800172805786 and perplexity is 66.94023275229785
At time: 175.4511935710907 and batch: 450, loss is 4.224407014846801 and perplexity is 68.33397050203163
At time: 176.44061923027039 and batch: 500, loss is 4.235781316757202 and perplexity is 69.11565886543795
At time: 177.45251750946045 and batch: 550, loss is 4.205168461799621 and perplexity is 67.0318890278541
At time: 178.4550986289978 and batch: 600, loss is 4.192886481285095 and perplexity is 66.2136398192274
At time: 179.4462571144104 and batch: 650, loss is 4.255089049339294 and perplexity is 70.46309160081395
At time: 180.43677306175232 and batch: 700, loss is 4.28234972000122 and perplexity is 72.41038439678185
At time: 181.42694473266602 and batch: 750, loss is 4.240226955413818 and perplexity is 69.4236061141829
At time: 182.41868472099304 and batch: 800, loss is 4.215767583847046 and perplexity is 67.74614676648933
At time: 183.40914726257324 and batch: 850, loss is 4.208037190437317 and perplexity is 67.22446141444105
At time: 184.399480342865 and batch: 900, loss is 4.200148010253907 and perplexity is 66.69620203220055
At time: 185.38981437683105 and batch: 950, loss is 4.283310098648071 and perplexity is 72.4799591874909
At time: 186.38045692443848 and batch: 1000, loss is 4.255685262680053 and perplexity is 70.50511516231664
At time: 187.37796449661255 and batch: 1050, loss is 4.198004260063171 and perplexity is 66.55337518361333
At time: 188.37699222564697 and batch: 1100, loss is 4.234357080459595 and perplexity is 69.01729190087714
At time: 189.37569665908813 and batch: 1150, loss is 4.200498385429382 and perplexity is 66.71957482007436
At time: 190.37372946739197 and batch: 1200, loss is 4.277282953262329 and perplexity is 72.04442576599004
At time: 191.3712613582611 and batch: 1250, loss is 4.2563954973220826 and perplexity is 70.55520812431791
At time: 192.36991691589355 and batch: 1300, loss is 4.261611557006836 and perplexity is 70.92418977955083
At time: 193.3714256286621 and batch: 1350, loss is 4.148024568557739 and perplexity is 63.30881446814804
At time: 194.37068796157837 and batch: 1400, loss is 4.173722991943359 and perplexity is 64.9568362710459
At time: 195.37075352668762 and batch: 1450, loss is 4.104524807929993 and perplexity is 60.613934442002495
At time: 196.3701639175415 and batch: 1500, loss is 4.115199189186097 and perplexity is 61.264416256669854
At time: 197.3680567741394 and batch: 1550, loss is 4.128197779655457 and perplexity is 62.065965533322746
At time: 198.36725163459778 and batch: 1600, loss is 4.210835480690003 and perplexity is 67.41283841339646
At time: 199.3654294013977 and batch: 1650, loss is 4.169276671409607 and perplexity is 64.66865849627216
At time: 200.36391234397888 and batch: 1700, loss is 4.189709162712097 and perplexity is 66.00359186298924
At time: 201.36342573165894 and batch: 1750, loss is 4.191492123603821 and perplexity is 66.12137865941686
At time: 202.36281394958496 and batch: 1800, loss is 4.1468828010559085 and perplexity is 63.236571771238836
At time: 203.361820936203 and batch: 1850, loss is 4.1835997104644775 and perplexity is 65.6015753710627
At time: 204.36037826538086 and batch: 1900, loss is 4.27584620475769 and perplexity is 71.94099036812283
At time: 205.35691905021667 and batch: 1950, loss is 4.206723208427429 and perplexity is 67.13618768926227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379217103470204 and perplexity of 79.77555294684421
finished 5 epochs...
Completing Train Step...
At time: 208.59161591529846 and batch: 50, loss is 4.176722130775452 and perplexity is 65.15194327136057
At time: 209.55846238136292 and batch: 100, loss is 4.138752412796021 and perplexity is 62.72451830794278
At time: 210.5290184020996 and batch: 150, loss is 4.114599089622498 and perplexity is 61.22766253625887
At time: 211.5087685585022 and batch: 200, loss is 4.106764340400696 and perplexity is 60.749833434665675
At time: 212.48943853378296 and batch: 250, loss is 4.104382495880127 and perplexity is 60.60530896251104
At time: 213.4694516658783 and batch: 300, loss is 4.127845950126648 and perplexity is 62.044132734850926
At time: 214.44899654388428 and batch: 350, loss is 4.132076783180237 and perplexity is 62.307187179738634
At time: 215.43230891227722 and batch: 400, loss is 4.095425844192505 and perplexity is 60.064912005990685
At time: 216.41615104675293 and batch: 450, loss is 4.121326723098755 and perplexity is 61.64096853516032
At time: 217.40128087997437 and batch: 500, loss is 4.133489899635315 and perplexity is 62.39529673107821
At time: 218.38898348808289 and batch: 550, loss is 4.1063696384429935 and perplexity is 60.72586008795358
At time: 219.38140273094177 and batch: 600, loss is 4.099434871673584 and perplexity is 60.30619722524134
At time: 220.37371611595154 and batch: 650, loss is 4.152049522399903 and perplexity is 63.56414302230814
At time: 221.36603307724 and batch: 700, loss is 4.17938148021698 and perplexity is 65.32543564148571
At time: 222.35867166519165 and batch: 750, loss is 4.140935025215149 and perplexity is 62.86157113277667
At time: 223.3514609336853 and batch: 800, loss is 4.117728247642517 and perplexity is 61.41955363974674
At time: 224.38478899002075 and batch: 850, loss is 4.106146016120911 and perplexity is 60.71228194835437
At time: 225.37070322036743 and batch: 900, loss is 4.098041625022888 and perplexity is 60.222234322039874
At time: 226.3566026687622 and batch: 950, loss is 4.186282715797424 and perplexity is 65.77782107599043
At time: 227.3419053554535 and batch: 1000, loss is 4.15862048625946 and perplexity is 63.9831959920249
At time: 228.33043718338013 and batch: 1050, loss is 4.102546610832214 and perplexity is 60.49414665379532
At time: 229.32179522514343 and batch: 1100, loss is 4.133767046928406 and perplexity is 62.41259181520102
At time: 230.31336736679077 and batch: 1150, loss is 4.105160427093506 and perplexity is 60.65247406727442
At time: 231.304607629776 and batch: 1200, loss is 4.186395378112793 and perplexity is 65.78523217508071
At time: 232.29578614234924 and batch: 1250, loss is 4.160395102500916 and perplexity is 64.09684242038614
At time: 233.286705493927 and batch: 1300, loss is 4.167947306632995 and perplexity is 64.58274737577715
At time: 234.27796983718872 and batch: 1350, loss is 4.051260471343994 and perplexity is 57.46985051062947
At time: 235.27376174926758 and batch: 1400, loss is 4.082991404533386 and perplexity is 59.322662772241834
At time: 236.27334213256836 and batch: 1450, loss is 4.012014536857605 and perplexity is 55.25807794486989
At time: 237.2714033126831 and batch: 1500, loss is 4.021168446540832 and perplexity is 55.76622762948295
At time: 238.27043890953064 and batch: 1550, loss is 4.032462506294251 and perplexity is 56.3996248166173
At time: 239.27012395858765 and batch: 1600, loss is 4.121831693649292 and perplexity is 61.672103269377494
At time: 240.26972079277039 and batch: 1650, loss is 4.084926300048828 and perplexity is 59.43755704476494
At time: 241.2712757587433 and batch: 1700, loss is 4.100970001220703 and perplexity is 60.398846146329475
At time: 242.27557396888733 and batch: 1750, loss is 4.102555432319641 and perplexity is 60.49468030450321
At time: 243.27717518806458 and batch: 1800, loss is 4.056527214050293 and perplexity is 57.77332789378326
At time: 244.2760579586029 and batch: 1850, loss is 4.09588020324707 and perplexity is 60.09220924352618
At time: 245.2753551006317 and batch: 1900, loss is 4.183509407043457 and perplexity is 65.59565159185512
At time: 246.2750072479248 and batch: 1950, loss is 4.118640866279602 and perplexity is 61.47563185419947
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.369910235737645 and perplexity of 79.03653672471346
finished 6 epochs...
Completing Train Step...
At time: 249.6226806640625 and batch: 50, loss is 4.090746421813964 and perplexity is 59.784499508525094
At time: 250.57511806488037 and batch: 100, loss is 4.05433180809021 and perplexity is 57.646631111714505
At time: 251.53549814224243 and batch: 150, loss is 4.030777277946473 and perplexity is 56.30465861241727
At time: 252.50119423866272 and batch: 200, loss is 4.025768437385559 and perplexity is 56.02334267607615
At time: 253.5002739429474 and batch: 250, loss is 4.019124255180359 and perplexity is 55.65234722508217
At time: 254.4857177734375 and batch: 300, loss is 4.040558586120605 and perplexity is 56.85809407892967
At time: 255.48782205581665 and batch: 350, loss is 4.048286304473877 and perplexity is 57.2991795130318
At time: 256.47561740875244 and batch: 400, loss is 4.005546870231629 and perplexity is 54.901840373062356
At time: 257.4606535434723 and batch: 450, loss is 4.041968770027161 and perplexity is 56.93833100927442
At time: 258.4447560310364 and batch: 500, loss is 4.056260948181152 and perplexity is 57.75794687622934
At time: 259.42992329597473 and batch: 550, loss is 4.027760930061341 and perplexity is 56.13508005702089
At time: 260.4143776893616 and batch: 600, loss is 4.018444337844849 and perplexity is 55.61452109022161
At time: 261.3981137275696 and batch: 650, loss is 4.072429790496826 and perplexity is 58.69941673990264
At time: 262.3820552825928 and batch: 700, loss is 4.099051299095154 and perplexity is 60.283069857471986
At time: 263.3666310310364 and batch: 750, loss is 4.062551980018616 and perplexity is 58.12244930492503
At time: 264.35178804397583 and batch: 800, loss is 4.039262065887451 and perplexity is 56.78442417711659
At time: 265.3354482650757 and batch: 850, loss is 4.029384269714355 and perplexity is 56.22628036291123
At time: 266.3197727203369 and batch: 900, loss is 4.019855952262878 and perplexity is 55.69308278641036
At time: 267.3310351371765 and batch: 950, loss is 4.109607491493225 and perplexity is 60.92280015871682
At time: 268.39746475219727 and batch: 1000, loss is 4.0815047264099125 and perplexity is 59.23453459262232
At time: 269.44943857192993 and batch: 1050, loss is 4.026602463722229 and perplexity is 56.070087109671015
At time: 270.5030303001404 and batch: 1100, loss is 4.056764602661133 and perplexity is 57.78704425182473
At time: 271.5080306529999 and batch: 1150, loss is 4.029649376869202 and perplexity is 56.24118832814266
At time: 272.49343490600586 and batch: 1200, loss is 4.109713721275329 and perplexity is 60.92927231826482
At time: 273.48547530174255 and batch: 1250, loss is 4.083338971138001 and perplexity is 59.34328493229775
At time: 274.47731137275696 and batch: 1300, loss is 4.096829771995544 and perplexity is 60.149298028023786
At time: 275.47003078460693 and batch: 1350, loss is 3.9747359132766724 and perplexity is 53.236056113561155
At time: 276.4630036354065 and batch: 1400, loss is 4.011129851341248 and perplexity is 55.209213541652254
At time: 277.45539379119873 and batch: 1450, loss is 3.9382398748397827 and perplexity is 51.3281777284215
At time: 278.4450626373291 and batch: 1500, loss is 3.949252200126648 and perplexity is 51.89654409172021
At time: 279.4373188018799 and batch: 1550, loss is 3.961089401245117 and perplexity is 52.51450416465822
At time: 280.4286775588989 and batch: 1600, loss is 4.052784285545349 and perplexity is 57.55749064166702
At time: 281.420649766922 and batch: 1650, loss is 4.011605286598206 and perplexity is 55.23546818897684
At time: 282.4120156764984 and batch: 1700, loss is 4.031900005340576 and perplexity is 56.367908894825455
At time: 283.4024124145508 and batch: 1750, loss is 4.030546503067017 and perplexity is 56.29166641080773
At time: 284.3935618400574 and batch: 1800, loss is 3.9902665710449217 and perplexity is 54.06930075241148
At time: 285.38351559638977 and batch: 1850, loss is 4.022971415519715 and perplexity is 55.8668631020245
At time: 286.37347745895386 and batch: 1900, loss is 4.115817098617554 and perplexity is 61.30228381544358
At time: 287.3639888763428 and batch: 1950, loss is 4.046849479675293 and perplexity is 57.2169097487413
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3714937431867735 and perplexity of 79.16179081358888
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 290.57952523231506 and batch: 50, loss is 4.053029751777649 and perplexity is 57.571620796202396
At time: 291.57197070121765 and batch: 100, loss is 4.033056144714355 and perplexity is 56.43311574055398
At time: 292.53866839408875 and batch: 150, loss is 4.013895864486694 and perplexity is 55.362134345036864
At time: 293.5072088241577 and batch: 200, loss is 4.008404784202575 and perplexity is 55.05896953355845
At time: 294.47572803497314 and batch: 250, loss is 3.997867798805237 and perplexity is 54.48185981354164
At time: 295.44569301605225 and batch: 300, loss is 4.00972508430481 and perplexity is 55.13171190697706
At time: 296.4161853790283 and batch: 350, loss is 4.011594457626343 and perplexity is 55.234870048884595
At time: 297.39166164398193 and batch: 400, loss is 3.972301893234253 and perplexity is 53.106636055404365
At time: 298.37442660331726 and batch: 450, loss is 3.998703360557556 and perplexity is 54.52740179571663
At time: 299.38093090057373 and batch: 500, loss is 4.004401183128357 and perplexity is 54.83897606089319
At time: 300.3636865615845 and batch: 550, loss is 3.976405506134033 and perplexity is 53.32501289273976
At time: 301.3470928668976 and batch: 600, loss is 3.9570611572265624 and perplexity is 52.303388425702686
At time: 302.34760069847107 and batch: 650, loss is 3.9943611288070677 and perplexity is 54.291144493565675
At time: 303.3515729904175 and batch: 700, loss is 4.018608355522156 and perplexity is 55.62364360290161
At time: 304.35088181495667 and batch: 750, loss is 3.9685075235366822 and perplexity is 52.90551165628153
At time: 305.3484785556793 and batch: 800, loss is 3.943201584815979 and perplexity is 51.58348611923445
At time: 306.3466942310333 and batch: 850, loss is 3.9351606512069703 and perplexity is 51.17036987805157
At time: 307.34477519989014 and batch: 900, loss is 3.9118821573257447 and perplexity is 49.99295809081135
At time: 308.34272289276123 and batch: 950, loss is 4.000011401176453 and perplexity is 54.59877251983529
At time: 309.34196043014526 and batch: 1000, loss is 3.963339591026306 and perplexity is 52.63280481483431
At time: 310.34270572662354 and batch: 1050, loss is 3.907984719276428 and perplexity is 49.79849283804894
At time: 311.34302496910095 and batch: 1100, loss is 3.927415089607239 and perplexity is 50.77555762126057
At time: 312.3427577018738 and batch: 1150, loss is 3.9023622274398804 and perplexity is 49.51928687076136
At time: 313.34300112724304 and batch: 1200, loss is 3.970267581939697 and perplexity is 52.998710440230084
At time: 314.343713760376 and batch: 1250, loss is 3.9386126136779787 and perplexity is 51.34731329981849
At time: 315.3439619541168 and batch: 1300, loss is 3.9415651607513427 and perplexity is 51.499142690840884
At time: 316.34387159347534 and batch: 1350, loss is 3.820975995063782 and perplexity is 45.64873953064313
At time: 317.34402799606323 and batch: 1400, loss is 3.8491468477249144 and perplexity is 46.95298809029978
At time: 318.3437442779541 and batch: 1450, loss is 3.7706871700286864 and perplexity is 43.40988456068646
At time: 319.3441107273102 and batch: 1500, loss is 3.7801708507537843 and perplexity is 43.82352837886345
At time: 320.34403800964355 and batch: 1550, loss is 3.782491669654846 and perplexity is 43.92535296434366
At time: 321.3436818122864 and batch: 1600, loss is 3.872928514480591 and perplexity is 48.082991835196346
At time: 322.34401965141296 and batch: 1650, loss is 3.8233534574508665 and perplexity is 45.75739680500596
At time: 323.3444573879242 and batch: 1700, loss is 3.8262267446517946 and perplexity is 45.88906001011275
At time: 324.34501910209656 and batch: 1750, loss is 3.8153432178497315 and perplexity is 45.39233316866334
At time: 325.3450708389282 and batch: 1800, loss is 3.7738172960281373 and perplexity is 43.54597584930845
At time: 326.3457205295563 and batch: 1850, loss is 3.793391995429993 and perplexity is 44.406772670527545
At time: 327.3481137752533 and batch: 1900, loss is 3.8798609018325805 and perplexity is 48.417479820211426
At time: 328.3486888408661 and batch: 1950, loss is 3.8175284385681154 and perplexity is 45.491633893044444
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.290721520712209 and perplexity of 73.0191343154057
finished 8 epochs...
Completing Train Step...
At time: 331.5522611141205 and batch: 50, loss is 3.965793194770813 and perplexity is 52.76210342071702
At time: 332.528635263443 and batch: 100, loss is 3.938003888130188 and perplexity is 51.31606638976358
At time: 333.48103070259094 and batch: 150, loss is 3.9091254568099973 and perplexity is 49.855332261212496
At time: 334.4413607120514 and batch: 200, loss is 3.9075204372406005 and perplexity is 49.7753776588094
At time: 335.4080138206482 and batch: 250, loss is 3.897785849571228 and perplexity is 49.293185659152414
At time: 336.3753571510315 and batch: 300, loss is 3.9071056604385377 and perplexity is 49.75473626792359
At time: 337.34494161605835 and batch: 350, loss is 3.9144875478744505 and perplexity is 50.12337909637516
At time: 338.31395149230957 and batch: 400, loss is 3.876250367164612 and perplexity is 48.242982035497626
At time: 339.28973269462585 and batch: 450, loss is 3.909072184562683 and perplexity is 49.85267642636411
At time: 340.27126121520996 and batch: 500, loss is 3.9182180166244507 and perplexity is 50.310711998256885
At time: 341.2633900642395 and batch: 550, loss is 3.8925591707229614 and perplexity is 49.03621813665131
At time: 342.2487087249756 and batch: 600, loss is 3.8790567255020143 and perplexity is 48.37855928054023
At time: 343.23316526412964 and batch: 650, loss is 3.9179511642456055 and perplexity is 50.29728825623716
At time: 344.2186806201935 and batch: 700, loss is 3.943724055290222 and perplexity is 51.61044400942789
At time: 345.20371556282043 and batch: 750, loss is 3.8984264135360718 and perplexity is 49.32477121280175
At time: 346.19883275032043 and batch: 800, loss is 3.872533836364746 and perplexity is 48.06401827504543
At time: 347.1833233833313 and batch: 850, loss is 3.8708950757980345 and perplexity is 47.98531736080883
At time: 348.16977763175964 and batch: 900, loss is 3.8459610891342164 and perplexity is 46.80364521661101
At time: 349.19072461128235 and batch: 950, loss is 3.938538875579834 and perplexity is 51.34352718618304
At time: 350.1669659614563 and batch: 1000, loss is 3.901573796272278 and perplexity is 49.48025970873215
At time: 351.1486117839813 and batch: 1050, loss is 3.8520915031433107 and perplexity is 47.09145222562113
At time: 352.13339924812317 and batch: 1100, loss is 3.8726535749435427 and perplexity is 48.06977373685346
At time: 353.1187174320221 and batch: 1150, loss is 3.850860538482666 and perplexity is 47.0335199757044
At time: 354.1039652824402 and batch: 1200, loss is 3.920425686836243 and perplexity is 50.421904151110546
At time: 355.08899974823 and batch: 1250, loss is 3.8920149183273316 and perplexity is 49.009537318665956
At time: 356.0741214752197 and batch: 1300, loss is 3.899148449897766 and perplexity is 49.36039835164668
At time: 357.05668687820435 and batch: 1350, loss is 3.7792589616775514 and perplexity is 43.78358439706104
At time: 358.0400171279907 and batch: 1400, loss is 3.811722617149353 and perplexity is 45.228282815021586
At time: 359.02358865737915 and batch: 1450, loss is 3.7338982582092286 and perplexity is 41.841901188048354
At time: 360.00992226600647 and batch: 1500, loss is 3.745074820518494 and perplexity is 42.31217291912307
At time: 360.99620842933655 and batch: 1550, loss is 3.7507380485534667 and perplexity is 42.552476206924176
At time: 361.9807515144348 and batch: 1600, loss is 3.8467881441116334 and perplexity is 46.84237041607575
At time: 362.9684715270996 and batch: 1650, loss is 3.7981986093521116 and perplexity is 44.620732681930924
At time: 363.9572126865387 and batch: 1700, loss is 3.8053921937942503 and perplexity is 44.94287297287514
At time: 364.9500300884247 and batch: 1750, loss is 3.7973795795440672 and perplexity is 44.584201933735585
At time: 365.94363284111023 and batch: 1800, loss is 3.7599833583831788 and perplexity is 42.94771125346192
At time: 366.9368999004364 and batch: 1850, loss is 3.7847004175186156 and perplexity is 44.022480219190484
At time: 367.9300558567047 and batch: 1900, loss is 3.8730578899383543 and perplexity is 48.089212996699786
At time: 368.92330050468445 and batch: 1950, loss is 3.812322359085083 and perplexity is 45.2554162486225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2890974177870635 and perplexity of 72.90063997532079
finished 9 epochs...
Completing Train Step...
At time: 372.10945534706116 and batch: 50, loss is 3.922044429779053 and perplexity is 50.50359034925954
At time: 373.0974428653717 and batch: 100, loss is 3.8923303651809693 and perplexity is 49.02499966165687
At time: 374.06134939193726 and batch: 150, loss is 3.8620886468887328 and perplexity is 47.56459333194327
At time: 375.03111362457275 and batch: 200, loss is 3.861686177253723 and perplexity is 47.54545387920821
At time: 376.00132060050964 and batch: 250, loss is 3.8514640855789186 and perplexity is 47.06191548826489
At time: 376.9830632209778 and batch: 300, loss is 3.8608963441848756 and perplexity is 47.5079157338468
At time: 377.96673703193665 and batch: 350, loss is 3.8692287540435792 and perplexity is 47.90542496430119
At time: 378.95025277137756 and batch: 400, loss is 3.831594023704529 and perplexity is 46.136021563575476
At time: 379.93275237083435 and batch: 450, loss is 3.8663989973068236 and perplexity is 47.7700558863923
At time: 380.9171054363251 and batch: 500, loss is 3.8775187969207763 and perplexity is 48.30421369525748
At time: 381.9001350402832 and batch: 550, loss is 3.851833324432373 and perplexity is 47.079295784524014
At time: 382.88338899612427 and batch: 600, loss is 3.8401243448257447 and perplexity is 46.531260001495994
At time: 383.8663432598114 and batch: 650, loss is 3.8795419263839723 and perplexity is 48.402038295729824
At time: 384.8493764400482 and batch: 700, loss is 3.9053408336639404 and perplexity is 49.667005215021184
At time: 385.83230686187744 and batch: 750, loss is 3.861960210800171 and perplexity is 47.558484713913586
At time: 386.81509733200073 and batch: 800, loss is 3.8349095296859743 and perplexity is 46.289239676459296
At time: 387.7977645397186 and batch: 850, loss is 3.835555005073547 and perplexity is 46.31912788639414
At time: 388.7807641029358 and batch: 900, loss is 3.8108032274246217 and perplexity is 45.18671950590159
At time: 389.763391494751 and batch: 950, loss is 3.9048333740234376 and perplexity is 49.641807608334865
At time: 390.7467110157013 and batch: 1000, loss is 3.867511677742004 and perplexity is 47.82323827497931
At time: 391.7294476032257 and batch: 1050, loss is 3.820946316719055 and perplexity is 45.6473847717186
At time: 392.7127161026001 and batch: 1100, loss is 3.8411545038223265 and perplexity is 46.57921929621697
At time: 393.6961314678192 and batch: 1150, loss is 3.8211855459213258 and perplexity is 45.65830626548131
At time: 394.6789050102234 and batch: 1200, loss is 3.891305055618286 and perplexity is 48.97475962089162
At time: 395.6623294353485 and batch: 1250, loss is 3.86412868976593 and perplexity is 47.661726185683015
At time: 396.645485162735 and batch: 1300, loss is 3.8724264240264894 and perplexity is 48.05885588371372
At time: 397.629043340683 and batch: 1350, loss is 3.753103075027466 and perplexity is 42.65323303901141
At time: 398.61273193359375 and batch: 1400, loss is 3.786836609840393 and perplexity is 44.11662121926147
At time: 399.59556674957275 and batch: 1450, loss is 3.7093261909484863 and perplexity is 40.826288134475725
At time: 400.57938623428345 and batch: 1500, loss is 3.7211436319351194 and perplexity is 41.31161238251336
At time: 401.5639796257019 and batch: 1550, loss is 3.727535591125488 and perplexity is 41.576520261177905
At time: 402.5470769405365 and batch: 1600, loss is 3.8267706298828124 and perplexity is 45.914025180595885
At time: 403.5303330421448 and batch: 1650, loss is 3.778321690559387 and perplexity is 43.74256653338821
At time: 404.51254868507385 and batch: 1700, loss is 3.787231936454773 and perplexity is 44.13406514156216
At time: 405.5222342014313 and batch: 1750, loss is 3.7788313388824464 and perplexity is 43.764865540911494
At time: 406.51474118232727 and batch: 1800, loss is 3.7439862728118896 and perplexity is 42.26613915984765
At time: 407.49912333488464 and batch: 1850, loss is 3.7712744855880738 and perplexity is 43.43538734967947
At time: 408.4826316833496 and batch: 1900, loss is 3.859472599029541 and perplexity is 47.44032469660413
At time: 409.46755027770996 and batch: 1950, loss is 3.798751211166382 and perplexity is 44.64539699390916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.291509300054506 and perplexity of 73.07667994466473
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 412.66552472114563 and batch: 50, loss is 3.9122259426116943 and perplexity is 50.010147888834574
At time: 413.61749482154846 and batch: 100, loss is 3.908422508239746 and perplexity is 49.82029884146885
At time: 414.5680830478668 and batch: 150, loss is 3.884434099197388 and perplexity is 48.63940958886347
At time: 415.5231626033783 and batch: 200, loss is 3.8835352659225464 and perplexity is 48.595710511091
At time: 416.4847033023834 and batch: 250, loss is 3.879461073875427 and perplexity is 48.398125027715814
At time: 417.446008682251 and batch: 300, loss is 3.8839358282089234 and perplexity is 48.61518001911644
At time: 418.41077160835266 and batch: 350, loss is 3.889128074645996 and perplexity is 48.86825846862673
At time: 419.3861484527588 and batch: 400, loss is 3.8535847520828246 and perplexity is 47.16182401494089
At time: 420.36074471473694 and batch: 450, loss is 3.887953643798828 and perplexity is 48.81089976694095
At time: 421.3359682559967 and batch: 500, loss is 3.9000101280212403 and perplexity is 49.40294945711781
At time: 422.33093214035034 and batch: 550, loss is 3.867539129257202 and perplexity is 47.82455111335125
At time: 423.31587052345276 and batch: 600, loss is 3.8501378011703493 and perplexity is 46.999539376890844
At time: 424.29199266433716 and batch: 650, loss is 3.8827060222625733 and perplexity is 48.555429529930166
At time: 425.2669765949249 and batch: 700, loss is 3.913016858100891 and perplexity is 50.049717335398256
At time: 426.24194169044495 and batch: 750, loss is 3.8586371612548827 and perplexity is 47.40070780833726
At time: 427.21755838394165 and batch: 800, loss is 3.8316614389419557 and perplexity is 46.13913193926528
At time: 428.19287276268005 and batch: 850, loss is 3.8291708755493166 and perplexity is 46.024362485914104
At time: 429.1683542728424 and batch: 900, loss is 3.8004256200790407 and perplexity is 44.720214264417145
At time: 430.14396238327026 and batch: 950, loss is 3.894217085838318 and perplexity is 49.11758345365716
At time: 431.1191511154175 and batch: 1000, loss is 3.8541074275970457 and perplexity is 47.18648078874414
At time: 432.09361958503723 and batch: 1050, loss is 3.806483368873596 and perplexity is 44.99194028150099
At time: 433.070063829422 and batch: 1100, loss is 3.822508735656738 and perplexity is 45.71876085529398
At time: 434.0454316139221 and batch: 1150, loss is 3.806815104484558 and perplexity is 45.00686818622054
At time: 435.02018332481384 and batch: 1200, loss is 3.864058799743652 and perplexity is 47.658395222979976
At time: 435.995014667511 and batch: 1250, loss is 3.8344825172424315 and perplexity is 46.26947781469603
At time: 436.96970200538635 and batch: 1300, loss is 3.8418374109268187 and perplexity is 46.6110394398605
At time: 437.94462966918945 and batch: 1350, loss is 3.7194865322113038 and perplexity is 41.24321161014667
At time: 438.9225869178772 and batch: 1400, loss is 3.7515743923187257 and perplexity is 42.58807959135517
At time: 439.8974258899689 and batch: 1450, loss is 3.668359680175781 and perplexity is 39.18757295867519
At time: 440.87215971946716 and batch: 1500, loss is 3.6819740533828735 and perplexity is 39.724735470520486
At time: 441.84771037101746 and batch: 1550, loss is 3.6883100938796995 and perplexity is 39.977232072821764
At time: 442.8226191997528 and batch: 1600, loss is 3.785087194442749 and perplexity is 44.03951039190899
At time: 443.79917669296265 and batch: 1650, loss is 3.7268361377716066 and perplexity is 41.54744959261201
At time: 444.78518986701965 and batch: 1700, loss is 3.7334750175476072 and perplexity is 41.82419574120285
At time: 445.7704336643219 and batch: 1750, loss is 3.7244712591171263 and perplexity is 41.44931100458625
At time: 446.7549684047699 and batch: 1800, loss is 3.6874021339416503 and perplexity is 39.940950821119564
At time: 447.7397527694702 and batch: 1850, loss is 3.7108837223052977 and perplexity is 40.88992590447359
At time: 448.72415041923523 and batch: 1900, loss is 3.7961551666259767 and perplexity is 44.5296458673372
At time: 449.70842480659485 and batch: 1950, loss is 3.7435597515106203 and perplexity is 42.24811559516393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.267363508357558 and perplexity of 71.33331778294061
finished 11 epochs...
Completing Train Step...
At time: 452.87943387031555 and batch: 50, loss is 3.8996532344818116 and perplexity is 49.38532100955449
At time: 453.83015275001526 and batch: 100, loss is 3.881786665916443 and perplexity is 48.510810301280976
At time: 454.7816607952118 and batch: 150, loss is 3.8494113302230835 and perplexity is 46.96540797623524
At time: 455.74300599098206 and batch: 200, loss is 3.847091155052185 and perplexity is 46.85656631744129
At time: 456.71212220191956 and batch: 250, loss is 3.841398181915283 and perplexity is 46.59057101457285
At time: 457.6837842464447 and batch: 300, loss is 3.8447100162506103 and perplexity is 46.745127058099875
At time: 458.657639503479 and batch: 350, loss is 3.849733438491821 and perplexity is 46.98053835916893
At time: 459.63361835479736 and batch: 400, loss is 3.8132341957092284 and perplexity is 45.29670061403666
At time: 460.61515188217163 and batch: 450, loss is 3.851137409210205 and perplexity is 47.04654398349885
At time: 461.6015524864197 and batch: 500, loss is 3.8645922899246217 and perplexity is 47.6838272921486
At time: 462.58523750305176 and batch: 550, loss is 3.83364905834198 and perplexity is 46.230930172761205
At time: 463.57034134864807 and batch: 600, loss is 3.8194315147399904 and perplexity is 45.57829036830893
At time: 464.5557975769043 and batch: 650, loss is 3.8529875755310057 and perplexity is 47.133668487245366
At time: 465.5388720035553 and batch: 700, loss is 3.8845722913742065 and perplexity is 48.64613163921042
At time: 466.5231304168701 and batch: 750, loss is 3.8325890064239503 and perplexity is 46.18194895246425
At time: 467.51105189323425 and batch: 800, loss is 3.807095141410828 and perplexity is 45.01947353614778
At time: 468.49570965766907 and batch: 850, loss is 3.8052938175201416 and perplexity is 44.93845187795332
At time: 469.47925877571106 and batch: 900, loss is 3.7783951950073242 and perplexity is 43.74578192476394
At time: 470.4882924556732 and batch: 950, loss is 3.8728554105758666 and perplexity is 48.079476909221334
At time: 471.4731454849243 and batch: 1000, loss is 3.833143153190613 and perplexity is 46.207547622209404
At time: 472.4583067893982 and batch: 1050, loss is 3.787620325088501 and perplexity is 44.151209639971995
At time: 473.4431722164154 and batch: 1100, loss is 3.8044153547286985 and perplexity is 44.89899245442871
At time: 474.4266514778137 and batch: 1150, loss is 3.7895923328399657 and perplexity is 44.23836207201103
At time: 475.412095785141 and batch: 1200, loss is 3.8483624935150145 and perplexity is 46.91617475565811
At time: 476.396488904953 and batch: 1250, loss is 3.8211251306533813 and perplexity is 45.65554788999923
At time: 477.38240814208984 and batch: 1300, loss is 3.829845457077026 and perplexity is 46.05542014495549
At time: 478.3666625022888 and batch: 1350, loss is 3.7092524671554568 and perplexity is 40.823278376605884
At time: 479.3511836528778 and batch: 1400, loss is 3.7427881574630737 and perplexity is 42.21552977378023
At time: 480.3359308242798 and batch: 1450, loss is 3.661462917327881 and perplexity is 38.91823540759579
At time: 481.32095432281494 and batch: 1500, loss is 3.6766624784469606 and perplexity is 39.514293943990715
At time: 482.3050584793091 and batch: 1550, loss is 3.684248170852661 and perplexity is 39.81517698377198
At time: 483.2934787273407 and batch: 1600, loss is 3.783169503211975 and perplexity is 43.955137135806694
At time: 484.2782361507416 and batch: 1650, loss is 3.7256106472015382 and perplexity is 41.49656477072892
At time: 485.26273465156555 and batch: 1700, loss is 3.7341968059539794 and perplexity is 41.854394858169854
At time: 486.24743819236755 and batch: 1750, loss is 3.726382279396057 and perplexity is 41.528597213110466
At time: 487.232449054718 and batch: 1800, loss is 3.6911254692077637 and perplexity is 40.08994157100631
At time: 488.2169201374054 and batch: 1850, loss is 3.7152704620361328 and perplexity is 41.06969337530364
At time: 489.2024862766266 and batch: 1900, loss is 3.800866541862488 and perplexity is 44.739936728759304
At time: 490.1873438358307 and batch: 1950, loss is 3.7487370681762697 and perplexity is 42.4674146686491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.266171761446221 and perplexity of 71.24835715763423
finished 12 epochs...
Completing Train Step...
At time: 493.3392426967621 and batch: 50, loss is 3.8859544658660887 and perplexity is 48.713415569845566
At time: 494.2860109806061 and batch: 100, loss is 3.8664166259765627 and perplexity is 47.77089801635373
At time: 495.2749192714691 and batch: 150, loss is 3.833024697303772 and perplexity is 46.20207439035175
At time: 496.223521232605 and batch: 200, loss is 3.830560731887817 and perplexity is 46.08837421108729
At time: 497.172345161438 and batch: 250, loss is 3.824096846580505 and perplexity is 45.791425002920505
At time: 498.1258714199066 and batch: 300, loss is 3.82744544506073 and perplexity is 45.94501911808061
At time: 499.09043288230896 and batch: 350, loss is 3.8322299575805663 and perplexity is 46.16537035354914
At time: 500.0588171482086 and batch: 400, loss is 3.7957657957077027 and perplexity is 44.51231069336074
At time: 501.0284547805786 and batch: 450, loss is 3.834767575263977 and perplexity is 46.28266918056285
At time: 502.0019121170044 and batch: 500, loss is 3.8487915802001953 and perplexity is 46.93631018117794
At time: 502.97582054138184 and batch: 550, loss is 3.818105068206787 and perplexity is 45.51787328193638
At time: 503.9515495300293 and batch: 600, loss is 3.8046770095825195 and perplexity is 44.9107420308359
At time: 504.9264988899231 and batch: 650, loss is 3.838591685295105 and perplexity is 46.45999804648908
At time: 505.90068888664246 and batch: 700, loss is 3.870460524559021 and perplexity is 47.96446981168745
At time: 506.8758497238159 and batch: 750, loss is 3.8194764947891233 and perplexity is 45.58034052815689
At time: 507.87313175201416 and batch: 800, loss is 3.7942085742950438 and perplexity is 44.443049111827285
At time: 508.84565448760986 and batch: 850, loss is 3.79301203250885 and perplexity is 44.38990294860249
At time: 509.8231463432312 and batch: 900, loss is 3.766647300720215 and perplexity is 43.23486806028997
At time: 510.80690813064575 and batch: 950, loss is 3.8614182758331297 and perplexity is 47.53271809061531
At time: 511.79063749313354 and batch: 1000, loss is 3.821901197433472 and perplexity is 45.69099339630445
At time: 512.7743020057678 and batch: 1050, loss is 3.7773784589767456 and perplexity is 43.70132661558214
At time: 513.7580940723419 and batch: 1100, loss is 3.794272656440735 and perplexity is 44.44589720903055
At time: 514.7414083480835 and batch: 1150, loss is 3.7798286867141724 and perplexity is 43.80853610841747
At time: 515.7252526283264 and batch: 1200, loss is 3.8390191793441772 and perplexity is 46.47986366508819
At time: 516.7083079814911 and batch: 1250, loss is 3.812953495979309 and perplexity is 45.28398762675758
At time: 517.6919417381287 and batch: 1300, loss is 3.822356538772583 and perplexity is 45.71180313182972
At time: 518.674810886383 and batch: 1350, loss is 3.70213951587677 and perplexity is 40.53393465031295
At time: 519.6571178436279 and batch: 1400, loss is 3.7364271068573 and perplexity is 41.94784692720919
At time: 520.6403908729553 and batch: 1450, loss is 3.6557797813415527 and perplexity is 38.697685085773365
At time: 521.6230182647705 and batch: 1500, loss is 3.671543083190918 and perplexity is 39.31252157196421
At time: 522.6052632331848 and batch: 1550, loss is 3.6795126962661744 and perplexity is 39.62707894325785
At time: 523.5893454551697 and batch: 1600, loss is 3.779544234275818 and perplexity is 43.796076435676845
At time: 524.573812007904 and batch: 1650, loss is 3.722096629142761 and perplexity is 41.351000999396945
At time: 525.558669090271 and batch: 1700, loss is 3.7315699672698974 and perplexity is 41.744594391851635
At time: 526.5425627231598 and batch: 1750, loss is 3.724156255722046 and perplexity is 41.436256387128424
At time: 527.5260627269745 and batch: 1800, loss is 3.6897088050842286 and perplexity is 40.033187799076096
At time: 528.5081675052643 and batch: 1850, loss is 3.7143731260299684 and perplexity is 41.03285659063426
At time: 529.4912104606628 and batch: 1900, loss is 3.8001486587524416 and perplexity is 44.70783020957997
At time: 530.473135471344 and batch: 1950, loss is 3.7481157875061033 and perplexity is 42.441038679098156
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.266298941678779 and perplexity of 71.25741911650577
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 533.6306259632111 and batch: 50, loss is 3.883457889556885 and perplexity is 48.5919504970949
At time: 534.6067190170288 and batch: 100, loss is 3.8776707553863528 and perplexity is 48.311554487185106
At time: 535.5590407848358 and batch: 150, loss is 3.848856821060181 and perplexity is 46.939372446310024
At time: 536.5152640342712 and batch: 200, loss is 3.849140472412109 and perplexity is 46.95268875126776
At time: 537.4761259555817 and batch: 250, loss is 3.8463325929641723 and perplexity is 46.821036180269665
At time: 538.4361503124237 and batch: 300, loss is 3.849658250808716 and perplexity is 46.977006134130235
At time: 539.4032056331635 and batch: 350, loss is 3.854459743499756 and perplexity is 47.20310826520914
At time: 540.373946428299 and batch: 400, loss is 3.817924017906189 and perplexity is 45.509633003271084
At time: 541.3484358787537 and batch: 450, loss is 3.85853919506073 and perplexity is 47.3960643688469
At time: 542.3212518692017 and batch: 500, loss is 3.8739204740524293 and perplexity is 48.130711883456236
At time: 543.2996225357056 and batch: 550, loss is 3.8445323705673218 and perplexity is 46.736823725610655
At time: 544.2994573116302 and batch: 600, loss is 3.822703227996826 and perplexity is 45.72765366884267
At time: 545.274106502533 and batch: 650, loss is 3.851623888015747 and perplexity is 47.06943669797955
At time: 546.2492501735687 and batch: 700, loss is 3.886658720970154 and perplexity is 48.747734324557726
At time: 547.2250049114227 and batch: 750, loss is 3.831849579811096 and perplexity is 46.147813412294056
At time: 548.2004704475403 and batch: 800, loss is 3.8058442783355715 and perplexity is 44.96319554440283
At time: 549.1758995056152 and batch: 850, loss is 3.8048609590530393 and perplexity is 44.91900409793126
At time: 550.1509590148926 and batch: 900, loss is 3.7736834049224854 and perplexity is 43.54014582075848
At time: 551.1230490207672 and batch: 950, loss is 3.8694276809692383 and perplexity is 47.91495559112944
At time: 552.1087107658386 and batch: 1000, loss is 3.8290370082855225 and perplexity is 46.018201742810355
At time: 553.103700876236 and batch: 1050, loss is 3.7849569845199587 and perplexity is 44.0337763839816
At time: 554.086434841156 and batch: 1100, loss is 3.799616813659668 and perplexity is 44.684058891364245
At time: 555.0809943675995 and batch: 1150, loss is 3.786250925064087 and perplexity is 44.09079035094285
At time: 556.0689771175385 and batch: 1200, loss is 3.8394827365875246 and perplexity is 46.50141473725182
At time: 557.0522546768188 and batch: 1250, loss is 3.813744421005249 and perplexity is 45.319818033560814
At time: 558.0529356002808 and batch: 1300, loss is 3.821758718490601 and perplexity is 45.68448385561386
At time: 559.0464944839478 and batch: 1350, loss is 3.6966381549835203 and perplexity is 40.3115551033088
At time: 560.0306181907654 and batch: 1400, loss is 3.729024648666382 and perplexity is 41.63847620873452
At time: 561.0196421146393 and batch: 1450, loss is 3.6425932693481444 and perplexity is 38.190747313460115
At time: 562.0308394432068 and batch: 1500, loss is 3.6603216314315796 and perplexity is 38.873843910929146
At time: 563.0155630111694 and batch: 1550, loss is 3.67016037940979 and perplexity is 39.25820156263652
At time: 564.0004460811615 and batch: 1600, loss is 3.7665603017807006 and perplexity is 43.231106836232314
At time: 564.9844467639923 and batch: 1650, loss is 3.7075008726119996 and perplexity is 40.751835133019355
At time: 565.9687883853912 and batch: 1700, loss is 3.71177059173584 and perplexity is 40.926206015258025
At time: 566.9533090591431 and batch: 1750, loss is 3.7058959293365477 and perplexity is 40.68648320635593
At time: 567.9372973442078 and batch: 1800, loss is 3.6709022378921508 and perplexity is 39.2873363980942
At time: 568.9216494560242 and batch: 1850, loss is 3.6965570783615114 and perplexity is 40.30828691108187
At time: 569.904736995697 and batch: 1900, loss is 3.7814040613174438 and perplexity is 43.87760535429238
At time: 570.8887987136841 and batch: 1950, loss is 3.7346042442321776 and perplexity is 41.87145141525706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2549177302870635 and perplexity of 70.45102096473813
finished 14 epochs...
Completing Train Step...
At time: 574.0253574848175 and batch: 50, loss is 3.8839127826690674 and perplexity is 48.61405966895728
At time: 574.9991059303284 and batch: 100, loss is 3.867210741043091 and perplexity is 47.80884867280977
At time: 575.9519608020782 and batch: 150, loss is 3.8347033071517944 and perplexity is 46.27969477636853
At time: 576.9167251586914 and batch: 200, loss is 3.832447733879089 and perplexity is 46.17542517183549
At time: 577.892749786377 and batch: 250, loss is 3.8290338945388793 and perplexity is 46.018058454012234
At time: 578.8664512634277 and batch: 300, loss is 3.831078500747681 and perplexity is 46.1122435149134
At time: 579.8434348106384 and batch: 350, loss is 3.835659236907959 and perplexity is 46.32395606568273
At time: 580.8268558979034 and batch: 400, loss is 3.799267740249634 and perplexity is 44.66846359666258
At time: 581.8111174106598 and batch: 450, loss is 3.840422329902649 and perplexity is 46.54512768866529
At time: 582.7955327033997 and batch: 500, loss is 3.8560349559783935 and perplexity is 47.27752178354349
At time: 583.7801313400269 and batch: 550, loss is 3.8278029584884643 and perplexity is 45.961448015953636
At time: 584.7644205093384 and batch: 600, loss is 3.8086727237701417 and perplexity is 45.09055151436491
At time: 585.748072385788 and batch: 650, loss is 3.838364543914795 and perplexity is 46.449446256822995
At time: 586.7315695285797 and batch: 700, loss is 3.8738198566436766 and perplexity is 48.12586933957129
At time: 587.7303192615509 and batch: 750, loss is 3.8206390953063964 and perplexity is 45.63336307167839
At time: 588.7135162353516 and batch: 800, loss is 3.795237226486206 and perplexity is 44.488789072900474
At time: 589.6966230869293 and batch: 850, loss is 3.7938226461410522 and perplexity is 44.42590059718595
At time: 590.6804339885712 and batch: 900, loss is 3.763796453475952 and perplexity is 43.11178758100645
At time: 591.665444612503 and batch: 950, loss is 3.8596334314346312 and perplexity is 47.447955251727166
At time: 592.6504368782043 and batch: 1000, loss is 3.8196412229537966 and perplexity is 45.587849512450894
At time: 593.6513698101044 and batch: 1050, loss is 3.776371693611145 and perplexity is 43.65735177340313
At time: 594.6269133090973 and batch: 1100, loss is 3.79149275302887 and perplexity is 44.3225134846117
At time: 595.6176676750183 and batch: 1150, loss is 3.779408597946167 and perplexity is 43.79013649946068
At time: 596.5923180580139 and batch: 1200, loss is 3.833537907600403 and perplexity is 46.22579185615785
At time: 597.5676641464233 and batch: 1250, loss is 3.8081294536590575 and perplexity is 45.06606181829714
At time: 598.5435557365417 and batch: 1300, loss is 3.816851325035095 and perplexity is 45.46084131830728
At time: 599.5189044475555 and batch: 1350, loss is 3.6932022094726564 and perplexity is 40.1732844777153
At time: 600.4941792488098 and batch: 1400, loss is 3.726989469528198 and perplexity is 41.55382062446822
At time: 601.4776322841644 and batch: 1450, loss is 3.6421309995651243 and perplexity is 38.173096964911856
At time: 602.4627406597137 and batch: 1500, loss is 3.6609334802627562 and perplexity is 38.897636104760146
At time: 603.4469585418701 and batch: 1550, loss is 3.671848802566528 and perplexity is 39.32454200885946
At time: 604.4323499202728 and batch: 1600, loss is 3.768901505470276 and perplexity is 43.33243823549955
At time: 605.4170897006989 and batch: 1650, loss is 3.710057744979858 and perplexity is 40.85616569733976
At time: 606.4016926288605 and batch: 1700, loss is 3.7153493928909302 and perplexity is 41.07293516924513
At time: 607.3859474658966 and batch: 1750, loss is 3.7103602933883666 and perplexity is 40.868528535333425
At time: 608.3698165416718 and batch: 1800, loss is 3.6755724430084227 and perplexity is 39.47124542972846
At time: 609.3546874523163 and batch: 1850, loss is 3.7015428018569945 and perplexity is 40.50975469820613
At time: 610.3382294178009 and batch: 1900, loss is 3.78630184173584 and perplexity is 44.0930353643963
At time: 611.3224363327026 and batch: 1950, loss is 3.739000668525696 and perplexity is 42.05594133228046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2537410292514535 and perplexity of 70.36816993041789
finished 15 epochs...
Completing Train Step...
At time: 614.4731168746948 and batch: 50, loss is 3.8803182792663575 and perplexity is 48.439629947979704
At time: 615.4522004127502 and batch: 100, loss is 3.862047553062439 and perplexity is 47.56263876096783
At time: 616.4046564102173 and batch: 150, loss is 3.828901801109314 and perplexity is 46.01198017230849
At time: 617.3921728134155 and batch: 200, loss is 3.826151008605957 and perplexity is 45.885584685765714
At time: 618.3618001937866 and batch: 250, loss is 3.822260270118713 and perplexity is 45.707402729890035
At time: 619.3290824890137 and batch: 300, loss is 3.8238822984695435 and perplexity is 45.781601593022586
At time: 620.2995412349701 and batch: 350, loss is 3.8285180568695067 and perplexity is 45.99432672737578
At time: 621.2746090888977 and batch: 400, loss is 3.791750583648682 and perplexity is 44.33394265906731
At time: 622.2495405673981 and batch: 450, loss is 3.8331948375701903 and perplexity is 46.209935892357656
At time: 623.2257387638092 and batch: 500, loss is 3.848877954483032 and perplexity is 46.94036444639845
At time: 624.2009534835815 and batch: 550, loss is 3.8210921907424926 and perplexity is 45.65404402508888
At time: 625.1756546497345 and batch: 600, loss is 3.8026545524597166 and perplexity is 44.820003768776616
At time: 626.1569299697876 and batch: 650, loss is 3.832369089126587 and perplexity is 46.17179385974486
At time: 627.1414766311646 and batch: 700, loss is 3.8679705667495727 and perplexity is 47.845188869388075
At time: 628.1268503665924 and batch: 750, loss is 3.815384373664856 and perplexity is 45.39420136557861
At time: 629.1115591526031 and batch: 800, loss is 3.790221347808838 and perplexity is 44.266197417459416
At time: 630.0966999530792 and batch: 850, loss is 3.7888238859176635 and perplexity is 44.20438029709649
At time: 631.082436800003 and batch: 900, loss is 3.7593059301376344 and perplexity is 42.91862711309868
At time: 632.0680351257324 and batch: 950, loss is 3.855196852684021 and perplexity is 47.23791493641984
At time: 633.0528697967529 and batch: 1000, loss is 3.8154347229003904 and perplexity is 45.39648698645422
At time: 634.0370609760284 and batch: 1050, loss is 3.7725676774978636 and perplexity is 43.49159397634303
At time: 635.0208933353424 and batch: 1100, loss is 3.787789978981018 and perplexity is 44.15870069997253
At time: 636.0031468868256 and batch: 1150, loss is 3.776170129776001 and perplexity is 43.64855291694287
At time: 636.985753774643 and batch: 1200, loss is 3.8305237007141115 and perplexity is 46.08666753609636
At time: 637.9713501930237 and batch: 1250, loss is 3.8055705213546753 and perplexity is 44.9508882404212
At time: 638.9563813209534 and batch: 1300, loss is 3.814592342376709 and perplexity is 45.35826197223741
At time: 639.9409689903259 and batch: 1350, loss is 3.6914648485183714 and perplexity is 40.10354957674617
At time: 640.9268732070923 and batch: 1400, loss is 3.72562077999115 and perplexity is 41.496985248819655
At time: 641.91406083107 and batch: 1450, loss is 3.6413641119003297 and perplexity is 38.14383370997126
At time: 642.8978514671326 and batch: 1500, loss is 3.6606103372573853 and perplexity is 38.88506863638154
At time: 643.8811957836151 and batch: 1550, loss is 3.6718707418441774 and perplexity is 39.325404770369175
At time: 644.8652997016907 and batch: 1600, loss is 3.769326295852661 and perplexity is 43.35084934866233
At time: 645.8493049144745 and batch: 1650, loss is 3.7105538511276244 and perplexity is 40.87643972093442
At time: 646.8343541622162 and batch: 1700, loss is 3.7162197160720827 and perplexity is 41.108697456957515
At time: 647.8338577747345 and batch: 1750, loss is 3.711568760871887 and perplexity is 40.91794667726235
At time: 648.8184068202972 and batch: 1800, loss is 3.676862134933472 and perplexity is 39.52218401671243
At time: 649.8047201633453 and batch: 1850, loss is 3.703072304725647 and perplexity is 40.57176189222782
At time: 650.7903983592987 and batch: 1900, loss is 3.7876425123214723 and perplexity is 44.15218924401355
At time: 651.7754108905792 and batch: 1950, loss is 3.740090079307556 and perplexity is 42.10178249360307
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253381631540698 and perplexity of 70.34288431530311
finished 16 epochs...
Completing Train Step...
At time: 655.1167058944702 and batch: 50, loss is 3.8764596033096312 and perplexity is 48.25307726718982
At time: 656.0566108226776 and batch: 100, loss is 3.857618656158447 and perplexity is 47.35245452313957
At time: 657.0241947174072 and batch: 150, loss is 3.8242204093933108 and perplexity is 45.79708346977708
At time: 658.0188269615173 and batch: 200, loss is 3.821345453262329 and perplexity is 45.66560794761166
At time: 658.9794459342957 and batch: 250, loss is 3.817136344909668 and perplexity is 45.47380040830918
At time: 659.9399440288544 and batch: 300, loss is 3.818596043586731 and perplexity is 45.54022692416017
At time: 660.9004392623901 and batch: 350, loss is 3.823280906677246 and perplexity is 45.75407719089065
At time: 661.8617038726807 and batch: 400, loss is 3.786367988586426 and perplexity is 44.09595207628301
At time: 662.8380761146545 and batch: 450, loss is 3.828073887825012 and perplexity is 45.973902007571034
At time: 663.8082928657532 and batch: 500, loss is 3.843894248008728 and perplexity is 46.707009417677256
At time: 664.7842979431152 and batch: 550, loss is 3.81637047290802 and perplexity is 45.4389866309183
At time: 665.7657291889191 and batch: 600, loss is 3.7983192443847655 and perplexity is 44.626115830166654
At time: 666.7781074047089 and batch: 650, loss is 3.8279736375808717 and perplexity is 45.96929334368439
At time: 667.7621212005615 and batch: 700, loss is 3.8637319946289064 and perplexity is 47.64282276037934
At time: 668.7461938858032 and batch: 750, loss is 3.8115306091308594 and perplexity is 45.21959945572239
At time: 669.7290806770325 and batch: 800, loss is 3.7865019035339356 and perplexity is 44.101857578799404
At time: 670.7123720645905 and batch: 850, loss is 3.7851700973510742 and perplexity is 44.04316154674529
At time: 671.6963005065918 and batch: 900, loss is 3.755958089828491 and perplexity is 42.77518265178872
At time: 672.6793828010559 and batch: 950, loss is 3.8518877696990965 and perplexity is 47.0818590991197
At time: 673.6652109622955 and batch: 1000, loss is 3.812330412864685 and perplexity is 45.255780727238474
At time: 674.6484575271606 and batch: 1050, loss is 3.7697593069076536 and perplexity is 43.3696248103715
At time: 675.631424665451 and batch: 1100, loss is 3.7850061225891114 and perplexity is 44.03594017189236
At time: 676.6150867938995 and batch: 1150, loss is 3.7736612510681153 and perplexity is 43.539181249393245
At time: 677.5985507965088 and batch: 1200, loss is 3.8280883026123047 and perplexity is 45.974564716365876
At time: 678.5810241699219 and batch: 1250, loss is 3.8034835147857664 and perplexity is 44.8571732672828
At time: 679.5634398460388 and batch: 1300, loss is 3.8126948261260987 and perplexity is 45.27227553917268
At time: 680.5465705394745 and batch: 1350, loss is 3.689848198890686 and perplexity is 40.03876856646121
At time: 681.5303874015808 and batch: 1400, loss is 3.7242064094543457 and perplexity is 41.43833462215395
At time: 682.5137376785278 and batch: 1450, loss is 3.640304675102234 and perplexity is 38.103444127801076
At time: 683.497864484787 and batch: 1500, loss is 3.6597781705856325 and perplexity is 38.85272323848118
At time: 684.4824712276459 and batch: 1550, loss is 3.6711901426315308 and perplexity is 39.29864903684384
At time: 685.4672679901123 and batch: 1600, loss is 3.7689565324783327 and perplexity is 43.33482275553335
At time: 686.4528059959412 and batch: 1650, loss is 3.710217308998108 and perplexity is 40.862685391449176
At time: 687.4380919933319 and batch: 1700, loss is 3.7161024236679077 and perplexity is 41.10387600176585
At time: 688.4229760169983 and batch: 1750, loss is 3.711638321876526 and perplexity is 40.9207930697388
At time: 689.4078590869904 and batch: 1800, loss is 3.6769979763031007 and perplexity is 39.52755312898551
At time: 690.3920948505402 and batch: 1850, loss is 3.703453402519226 and perplexity is 40.5872266477715
At time: 691.3777968883514 and batch: 1900, loss is 3.7878906869888307 and perplexity is 44.163148058686176
At time: 692.3611149787903 and batch: 1950, loss is 3.740198349952698 and perplexity is 42.10634112753394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253306118277616 and perplexity of 70.3375726951253
finished 17 epochs...
Completing Train Step...
At time: 695.514890909195 and batch: 50, loss is 3.8728217935562133 and perplexity is 48.07786064766825
At time: 696.4650218486786 and batch: 100, loss is 3.8535973691940306 and perplexity is 47.16241906467307
At time: 697.419007062912 and batch: 150, loss is 3.8200924444198607 and perplexity is 45.60842437030229
At time: 698.3851306438446 and batch: 200, loss is 3.817204337120056 and perplexity is 45.47689237762741
At time: 699.3528578281403 and batch: 250, loss is 3.81277072429657 and perplexity is 45.27571175245867
At time: 700.3195743560791 and batch: 300, loss is 3.814151940345764 and perplexity is 45.33829049960606
At time: 701.2877812385559 and batch: 350, loss is 3.818890919685364 and perplexity is 45.55365762870599
At time: 702.2594630718231 and batch: 400, loss is 3.781916370391846 and perplexity is 43.90009000873289
At time: 703.2343504428864 and batch: 450, loss is 3.8238612365722657 and perplexity is 45.780637355786986
At time: 704.2096195220947 and batch: 500, loss is 3.8398317241668702 and perplexity is 46.5176459855044
At time: 705.1838705539703 and batch: 550, loss is 3.8125035333633424 and perplexity is 45.263616108778116
At time: 706.1584300994873 and batch: 600, loss is 3.794702563285828 and perplexity is 44.46500891230868
At time: 707.1332030296326 and batch: 650, loss is 3.8242885303497314 and perplexity is 45.800203317166606
At time: 708.1148102283478 and batch: 700, loss is 3.860187544822693 and perplexity is 47.474254084563086
At time: 709.0990214347839 and batch: 750, loss is 3.8082750177383424 and perplexity is 45.07262229556605
At time: 710.0843362808228 and batch: 800, loss is 3.783329782485962 and perplexity is 43.962182797896524
At time: 711.0693786144257 and batch: 850, loss is 3.7820794439315795 and perplexity is 43.907249535554065
At time: 712.0538191795349 and batch: 900, loss is 3.7530628633499146 and perplexity is 42.651517915442156
At time: 713.0383200645447 and batch: 950, loss is 3.849021677970886 and perplexity is 46.94711136413149
At time: 714.0233500003815 and batch: 1000, loss is 3.809646878242493 and perplexity is 45.134498078679144
At time: 715.032674074173 and batch: 1050, loss is 3.767317337989807 and perplexity is 43.26384674055
At time: 716.0178189277649 and batch: 1100, loss is 3.782558059692383 and perplexity is 43.92826926698143
At time: 717.0029249191284 and batch: 1150, loss is 3.771415600776672 and perplexity is 43.44151717505273
At time: 717.9881556034088 and batch: 1200, loss is 3.8258637046813964 and perplexity is 45.87240347080279
At time: 718.9739878177643 and batch: 1250, loss is 3.8015436267852785 and perplexity is 44.77023972305754
At time: 719.9587562084198 and batch: 1300, loss is 3.810887517929077 and perplexity is 45.19052847781125
At time: 720.9430093765259 and batch: 1350, loss is 3.6882298231124877 and perplexity is 39.9740231985234
At time: 721.926118850708 and batch: 1400, loss is 3.722736287117004 and perplexity is 41.37745995836903
At time: 722.9301896095276 and batch: 1450, loss is 3.639080777168274 and perplexity is 38.05683792769003
At time: 723.9152097702026 and batch: 1500, loss is 3.6586842012405394 and perplexity is 38.81024279067534
At time: 724.8995208740234 and batch: 1550, loss is 3.670165572166443 and perplexity is 39.25840542145317
At time: 725.883111000061 and batch: 1600, loss is 3.768213176727295 and perplexity is 43.302621535781576
At time: 726.8671808242798 and batch: 1650, loss is 3.7094850540161133 and perplexity is 40.83277443905207
At time: 727.8512616157532 and batch: 1700, loss is 3.715543022155762 and perplexity is 41.08088886149537
At time: 728.8340241909027 and batch: 1750, loss is 3.711198878288269 and perplexity is 40.90281464014004
At time: 729.8187339305878 and batch: 1800, loss is 3.6766160345077514 and perplexity is 39.51245878714117
At time: 730.8031189441681 and batch: 1850, loss is 3.7033164262771607 and perplexity is 40.581667542730784
At time: 731.7896809577942 and batch: 1900, loss is 3.7876611232757567 and perplexity is 44.153010966035616
At time: 732.773864030838 and batch: 1950, loss is 3.7398858213424684 and perplexity is 42.09318374739546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25336431458939 and perplexity of 70.34166620154757
Annealing...
finished 18 epochs...
Completing Train Step...
At time: 735.9342682361603 and batch: 50, loss is 3.8725238752365114 and perplexity is 48.06353950558046
At time: 736.8874337673187 and batch: 100, loss is 3.857938165664673 and perplexity is 47.3675864997793
At time: 737.8432464599609 and batch: 150, loss is 3.8263249349594117 and perplexity is 45.89356609225458
At time: 738.8096745014191 and batch: 200, loss is 3.8240429162979126 and perplexity is 45.7889555250202
At time: 739.8027002811432 and batch: 250, loss is 3.821253914833069 and perplexity is 45.661427980905636
At time: 740.777512550354 and batch: 300, loss is 3.82202908039093 and perplexity is 45.696836869301514
At time: 741.7517173290253 and batch: 350, loss is 3.8275724267959594 and perplexity is 45.950853666766086
At time: 742.7261362075806 and batch: 400, loss is 3.792439398765564 and perplexity is 44.36449106885725
At time: 743.7012939453125 and batch: 450, loss is 3.8348715543746947 and perplexity is 46.28748186155068
At time: 744.6758735179901 and batch: 500, loss is 3.850749788284302 and perplexity is 47.02831129247401
At time: 745.6504337787628 and batch: 550, loss is 3.8252480840682983 and perplexity is 45.84417216443249
At time: 746.624005317688 and batch: 600, loss is 3.8042298316955567 and perplexity is 44.8906634298004
At time: 747.5981431007385 and batch: 650, loss is 3.8305440235137937 and perplexity is 46.08760415572605
At time: 748.5762379169464 and batch: 700, loss is 3.8658076524734497 and perplexity is 47.74181566133243
At time: 749.5599901676178 and batch: 750, loss is 3.814489483833313 and perplexity is 45.35359672741423
At time: 750.5421454906464 and batch: 800, loss is 3.7886253643035888 and perplexity is 44.19560564317879
At time: 751.5270130634308 and batch: 850, loss is 3.7888440895080566 and perplexity is 44.205273393311444
At time: 752.511022567749 and batch: 900, loss is 3.7580564641952514 and perplexity is 42.86503523781065
At time: 753.4947717189789 and batch: 950, loss is 3.85461989402771 and perplexity is 47.21066847328839
At time: 754.4763882160187 and batch: 1000, loss is 3.815377907752991 and perplexity is 45.393907851622316
At time: 755.4597640037537 and batch: 1050, loss is 3.7732256269454956 and perplexity is 43.52021866234195
At time: 756.443083524704 and batch: 1100, loss is 3.785631513595581 and perplexity is 44.063488466167165
At time: 757.4276344776154 and batch: 1150, loss is 3.7749143695831298 and perplexity is 43.593775202748205
At time: 758.4103727340698 and batch: 1200, loss is 3.8288551998138427 and perplexity is 46.009836004386145
At time: 759.3949918746948 and batch: 1250, loss is 3.804371795654297 and perplexity is 44.897036738470725
At time: 760.3791570663452 and batch: 1300, loss is 3.81164511680603 and perplexity is 45.2247777433994
At time: 761.3626663684845 and batch: 1350, loss is 3.685224084854126 and perplexity is 39.854052138779856
At time: 762.3461458683014 and batch: 1400, loss is 3.7185096025466917 and perplexity is 41.202939567940135
At time: 763.3299052715302 and batch: 1450, loss is 3.6316402196884154 and perplexity is 37.774724679034435
At time: 764.3123695850372 and batch: 1500, loss is 3.650836453437805 and perplexity is 38.50686177895457
At time: 765.295089006424 and batch: 1550, loss is 3.662977194786072 and perplexity is 38.9772130571789
At time: 766.2790856361389 and batch: 1600, loss is 3.7608190774917603 and perplexity is 42.983618478513456
At time: 767.2649912834167 and batch: 1650, loss is 3.702415270805359 and perplexity is 40.54511362382556
At time: 768.2488934993744 and batch: 1700, loss is 3.705473999977112 and perplexity is 40.66932000564274
At time: 769.2337596416473 and batch: 1750, loss is 3.7015491771697997 and perplexity is 40.51001296138725
At time: 770.2169561386108 and batch: 1800, loss is 3.6662836122512816 and perplexity is 39.10630128736216
At time: 771.1993820667267 and batch: 1850, loss is 3.694461131095886 and perplexity is 40.22389134257485
At time: 772.1833393573761 and batch: 1900, loss is 3.7787157917022705 and perplexity is 43.75980892625187
At time: 773.1666214466095 and batch: 1950, loss is 3.732841796875 and perplexity is 41.797720179165594
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25054931640625 and perplexity of 70.1439329788958
finished 19 epochs...
Completing Train Step...
At time: 776.3029179573059 and batch: 50, loss is 3.872222189903259 and perplexity is 48.04904162765596
At time: 777.2858986854553 and batch: 100, loss is 3.854775252342224 and perplexity is 47.21800361294219
At time: 778.2466087341309 and batch: 150, loss is 3.8215999221801757 and perplexity is 45.67722990409953
At time: 779.2065825462341 and batch: 200, loss is 3.8187216091156007 and perplexity is 45.54594556586337
At time: 780.165524482727 and batch: 250, loss is 3.8146919202804566 and perplexity is 45.362778877770495
At time: 781.1260769367218 and batch: 300, loss is 3.8150491762161254 and perplexity is 45.37898789499442
At time: 782.093090057373 and batch: 350, loss is 3.821167769432068 and perplexity is 45.65749462830449
At time: 783.0708811283112 and batch: 400, loss is 3.7861521148681643 and perplexity is 44.086433946542016
At time: 784.0383930206299 and batch: 450, loss is 3.828671135902405 and perplexity is 46.0013680333544
At time: 785.0070381164551 and batch: 500, loss is 3.8447326946258547 and perplexity is 46.746187173652956
At time: 785.9754238128662 and batch: 550, loss is 3.8190763187408447 and perplexity is 45.56210401675604
At time: 786.9448323249817 and batch: 600, loss is 3.7992616271972657 and perplexity is 44.66819053684002
At time: 787.9230878353119 and batch: 650, loss is 3.8256148433685304 and perplexity is 45.86098902461667
At time: 788.9304096698761 and batch: 700, loss is 3.861548228263855 and perplexity is 47.53889548424513
At time: 789.9140536785126 and batch: 750, loss is 3.8105891132354737 and perplexity is 45.177045423810405
At time: 790.8977584838867 and batch: 800, loss is 3.784647750854492 and perplexity is 44.0201617630641
At time: 791.8816587924957 and batch: 850, loss is 3.7845574426651 and perplexity is 44.01618656145787
At time: 792.8660190105438 and batch: 900, loss is 3.7539241790771483 and perplexity is 42.688270163985855
At time: 793.8500943183899 and batch: 950, loss is 3.850654616355896 and perplexity is 47.02383573037595
At time: 794.8338344097137 and batch: 1000, loss is 3.811450901031494 and perplexity is 45.215995231040566
At time: 795.8195235729218 and batch: 1050, loss is 3.7694623279571533 and perplexity is 43.35674685704691
At time: 796.8041639328003 and batch: 1100, loss is 3.7825524520874025 and perplexity is 43.92802293529057
At time: 797.787755727768 and batch: 1150, loss is 3.772202548980713 and perplexity is 43.47571685389742
At time: 798.7723393440247 and batch: 1200, loss is 3.8267414665222166 and perplexity is 45.91268619284792
At time: 799.7567369937897 and batch: 1250, loss is 3.80250955581665 and perplexity is 44.81350548981362
At time: 800.7397882938385 and batch: 1300, loss is 3.809965763092041 and perplexity is 45.14889308136055
At time: 801.7234072685242 and batch: 1350, loss is 3.684301290512085 and perplexity is 39.81729200858746
At time: 802.7080235481262 and batch: 1400, loss is 3.7180591726303103 and perplexity is 41.18438471046104
At time: 803.6916751861572 and batch: 1450, loss is 3.6322038125991822 and perplexity is 37.79602024652145
At time: 804.6755542755127 and batch: 1500, loss is 3.6518981409072877 and perplexity is 38.54776574136438
At time: 805.6595375537872 and batch: 1550, loss is 3.664636187553406 and perplexity is 39.04192963905918
At time: 806.6427063941956 and batch: 1600, loss is 3.762604513168335 and perplexity is 43.06043151641716
At time: 807.6247034072876 and batch: 1650, loss is 3.70421133518219 and perplexity is 40.61800069340093
At time: 808.6066470146179 and batch: 1700, loss is 3.707546434402466 and perplexity is 40.75369190189134
At time: 809.5886495113373 and batch: 1750, loss is 3.703875308036804 and perplexity is 40.6043542354952
At time: 810.5723299980164 and batch: 1800, loss is 3.668808536529541 and perplexity is 39.205166497976684
At time: 811.5550150871277 and batch: 1850, loss is 3.6971790075302122 and perplexity is 40.333363607608455
At time: 812.5376811027527 and batch: 1900, loss is 3.7813822269439696 and perplexity is 43.87664732472895
At time: 813.521507024765 and batch: 1950, loss is 3.7351992607116697 and perplexity is 41.89637303252059
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249997728924418 and perplexity of 70.10525313217852
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f05ce5c4b38>
ELAPSED
2526.9389836788177


RESULTS SO FAR:
[{'best_accuracy': -70.031277428607, 'params': {'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.29541346180265, 'params': {'tie_weights': True, 'rnn_dropout': 0.7288706260952753, 'num_layers': 2, 'dropout': 0.4475108336446092, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.10525313217852, 'params': {'tie_weights': True, 'rnn_dropout': 0.8506975178466405, 'num_layers': 2, 'dropout': 0.6098755685920833, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'rnn_dropout': 0.3930815480094526, 'num_layers': 2, 'dropout': 0.9281289718292313, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5524797439575195 and batch: 50, loss is 7.914431762695313 and perplexity is 2736.491112167115
At time: 2.622669219970703 and batch: 100, loss is 7.157483463287353 and perplexity is 1283.6764458570076
At time: 3.59591007232666 and batch: 150, loss is 6.894378547668457 and perplexity is 986.7123395552828
At time: 4.563920021057129 and batch: 200, loss is 6.8005160713195805 and perplexity is 898.3107644692298
At time: 5.533006191253662 and batch: 250, loss is 6.748347730636596 and perplexity is 852.648792544153
At time: 6.502275705337524 and batch: 300, loss is 6.670505237579346 and perplexity is 788.7940321912532
At time: 7.486346960067749 and batch: 350, loss is 6.641740608215332 and perplexity is 766.4278833337896
At time: 8.458317041397095 and batch: 400, loss is 6.61849760055542 and perplexity is 748.8192259803742
At time: 9.426144361495972 and batch: 450, loss is 6.532276573181153 and perplexity is 686.960348163042
At time: 10.39444613456726 and batch: 500, loss is 6.525769109725952 and perplexity is 682.5044926849034
At time: 11.364754915237427 and batch: 550, loss is 6.488925466537475 and perplexity is 657.8161378622934
At time: 12.336581707000732 and batch: 600, loss is 6.545477237701416 and perplexity is 696.0887995117129
At time: 13.308289289474487 and batch: 650, loss is 6.629636011123657 and perplexity is 757.206505730192
At time: 14.278997898101807 and batch: 700, loss is 6.5093355560302735 and perplexity is 671.3801748472903
At time: 15.25160527229309 and batch: 750, loss is 6.452886028289795 and perplexity is 634.5309270040837
At time: 16.22356414794922 and batch: 800, loss is 6.454927530288696 and perplexity is 635.8276463371177
At time: 17.196385145187378 and batch: 850, loss is 6.51127851486206 and perplexity is 672.6859069686038
At time: 18.169967651367188 and batch: 900, loss is 6.491905851364136 and perplexity is 659.7796075925982
At time: 19.142650604248047 and batch: 950, loss is 6.505488653182983 and perplexity is 668.8024019409872
At time: 20.114052295684814 and batch: 1000, loss is 6.499722585678101 and perplexity is 664.9571388211172
At time: 21.08564281463623 and batch: 1050, loss is 6.401480255126953 and perplexity is 602.7365817684424
At time: 22.059170961380005 and batch: 1100, loss is 6.474349164962769 and perplexity is 648.2971557726923
At time: 23.034244775772095 and batch: 1150, loss is 6.381365709304809 and perplexity is 590.7339278238626
At time: 24.04014778137207 and batch: 1200, loss is 6.478647499084473 and perplexity is 651.0897510124682
At time: 25.08770489692688 and batch: 1250, loss is 6.397813510894776 and perplexity is 600.5305478364978
At time: 26.16974902153015 and batch: 1300, loss is 6.413378343582154 and perplexity is 609.9508276950305
At time: 27.252304077148438 and batch: 1350, loss is 6.426161918640137 and perplexity is 617.7982319550939
At time: 28.335862636566162 and batch: 1400, loss is 6.446150875091552 and perplexity is 630.2716236330162
At time: 29.41974902153015 and batch: 1450, loss is 6.453873252868652 and perplexity is 635.1576608438908
At time: 30.505127429962158 and batch: 1500, loss is 6.428779401779175 and perplexity is 619.4174265934417
At time: 31.59083390235901 and batch: 1550, loss is 6.401307563781739 and perplexity is 602.6325033643056
At time: 32.676870346069336 and batch: 1600, loss is 6.384661407470703 and perplexity is 592.6840202392235
At time: 33.76194953918457 and batch: 1650, loss is 6.383396244049072 and perplexity is 591.9346522326829
At time: 34.847169160842896 and batch: 1700, loss is 6.416739139556885 and perplexity is 612.0041965256579
At time: 35.93215465545654 and batch: 1750, loss is 6.4276671218872075 and perplexity is 618.7288440643491
At time: 37.01666307449341 and batch: 1800, loss is 6.435480098724366 and perplexity is 623.5818918797253
At time: 38.102468729019165 and batch: 1850, loss is 6.378474569320678 and perplexity is 589.0284998485815
At time: 39.186896085739136 and batch: 1900, loss is 6.333810005187988 and perplexity is 563.2986814780905
At time: 40.27229022979736 and batch: 1950, loss is 6.279937038421631 and perplexity is 533.7550567067608
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.786846498001453 and perplexity of 325.98341244494594
finished 1 epochs...
Completing Train Step...
At time: 43.51992678642273 and batch: 50, loss is 6.027481861114502 and perplexity is 414.66951812495665
At time: 44.54329490661621 and batch: 100, loss is 5.862522821426392 and perplexity is 351.6100754587227
At time: 45.549872398376465 and batch: 150, loss is 5.668229932785034 and perplexity is 289.5216078623392
At time: 46.557122468948364 and batch: 200, loss is 5.563548812866211 and perplexity is 260.74653699842065
At time: 47.56302618980408 and batch: 250, loss is 5.522104759216308 and perplexity is 250.1610121660989
At time: 48.56929087638855 and batch: 300, loss is 5.482570343017578 and perplexity is 240.4639886563129
At time: 49.575515031814575 and batch: 350, loss is 5.427691507339477 and perplexity is 227.62317201736442
At time: 50.58118438720703 and batch: 400, loss is 5.366742153167724 and perplexity is 214.16401638479854
At time: 51.58745336532593 and batch: 450, loss is 5.2899826145172115 and perplexity is 198.33997714314748
At time: 52.61438298225403 and batch: 500, loss is 5.263760328292847 and perplexity is 193.20664745294488
At time: 53.61973786354065 and batch: 550, loss is 5.20714958190918 and perplexity is 182.57290668062947
At time: 54.62485122680664 and batch: 600, loss is 5.206734037399292 and perplexity is 182.49705527251362
At time: 55.629433155059814 and batch: 650, loss is 5.269626064300537 and perplexity is 194.34327696718356
At time: 56.63478684425354 and batch: 700, loss is 5.225607061386109 and perplexity is 185.9740339197954
At time: 57.642117738723755 and batch: 750, loss is 5.16097014427185 and perplexity is 174.33350224062997
At time: 58.648049116134644 and batch: 800, loss is 5.1417320728302 and perplexity is 171.01171669339715
At time: 59.65355157852173 and batch: 850, loss is 5.135032243728638 and perplexity is 169.86979702201972
At time: 60.65955209732056 and batch: 900, loss is 5.1462680435180665 and perplexity is 171.78918277624962
At time: 61.664873123168945 and batch: 950, loss is 5.181610870361328 and perplexity is 177.96926562600638
At time: 62.669374227523804 and batch: 1000, loss is 5.142780475616455 and perplexity is 171.1910998701412
At time: 63.68045353889465 and batch: 1050, loss is 5.0430690288543705 and perplexity is 154.94481617567791
At time: 64.68718004226685 and batch: 1100, loss is 5.117300491333008 and perplexity is 166.88425550769918
At time: 65.69401669502258 and batch: 1150, loss is 5.008800868988037 and perplexity is 149.72508846317245
At time: 66.70013236999512 and batch: 1200, loss is 5.093281154632568 and perplexity is 162.92356340115487
At time: 67.70760154724121 and batch: 1250, loss is 5.030954313278198 and perplexity is 153.0790283615679
At time: 68.71509146690369 and batch: 1300, loss is 5.060775833129883 and perplexity is 157.71282770736278
At time: 69.72205758094788 and batch: 1350, loss is 4.98219633102417 and perplexity is 145.79424268302824
At time: 70.72887992858887 and batch: 1400, loss is 4.988646030426025 and perplexity is 146.7376106726022
At time: 71.73440265655518 and batch: 1450, loss is 4.940189027786255 and perplexity is 139.79667251811958
At time: 72.74008417129517 and batch: 1500, loss is 4.906221284866333 and perplexity is 135.12783885837356
At time: 73.74448013305664 and batch: 1550, loss is 4.9000004863739015 and perplexity is 134.28984499999544
At time: 74.75000500679016 and batch: 1600, loss is 4.9515072536468505 and perplexity is 141.38791084288877
At time: 75.75631475448608 and batch: 1650, loss is 4.9161418914794925 and perplexity is 136.47506056921128
At time: 76.76265335083008 and batch: 1700, loss is 4.946061925888062 and perplexity is 140.6200997160744
At time: 77.76829171180725 and batch: 1750, loss is 4.949886713027954 and perplexity is 141.15897154316667
At time: 78.77329182624817 and batch: 1800, loss is 4.903050479888916 and perplexity is 134.70005340486944
At time: 79.7798855304718 and batch: 1850, loss is 4.891929311752319 and perplexity is 133.21033054623186
At time: 80.78344416618347 and batch: 1900, loss is 4.962873258590698 and perplexity is 143.00409390990373
At time: 81.78829169273376 and batch: 1950, loss is 4.886389036178588 and perplexity is 132.47434925787184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.673210676326308 and perplexity of 107.04086488095564
finished 2 epochs...
Completing Train Step...
At time: 85.02680039405823 and batch: 50, loss is 4.870207815170288 and perplexity is 130.3480023742849
At time: 86.05582118034363 and batch: 100, loss is 4.823034009933472 and perplexity is 124.34177323685823
At time: 87.06301975250244 and batch: 150, loss is 4.760490846633911 and perplexity is 116.803244309864
At time: 88.06854248046875 and batch: 200, loss is 4.736757469177246 and perplexity is 114.06374618529472
At time: 89.07514667510986 and batch: 250, loss is 4.756582155227661 and perplexity is 116.34758756353399
At time: 90.08261823654175 and batch: 300, loss is 4.764665746688843 and perplexity is 117.29190552704902
At time: 91.08928942680359 and batch: 350, loss is 4.7772375583648685 and perplexity is 118.77578525878924
At time: 92.09647226333618 and batch: 400, loss is 4.727986936569214 and perplexity is 113.06772060211202
At time: 93.10376167297363 and batch: 450, loss is 4.719610795974732 and perplexity is 112.12460482687226
At time: 94.11110424995422 and batch: 500, loss is 4.726626968383789 and perplexity is 112.91405661204712
At time: 95.11600732803345 and batch: 550, loss is 4.682957143783569 and perplexity is 108.08923584482255
At time: 96.1213207244873 and batch: 600, loss is 4.65777174949646 and perplexity is 105.40096055559842
At time: 97.13203263282776 and batch: 650, loss is 4.732670412063599 and perplexity is 113.59851250595466
At time: 98.19761443138123 and batch: 700, loss is 4.744648294448853 and perplexity is 114.96736373170329
At time: 99.23810505867004 and batch: 750, loss is 4.709628009796143 and perplexity is 111.01085727266081
At time: 100.26283740997314 and batch: 800, loss is 4.683780975341797 and perplexity is 108.17831985848875
At time: 101.3140926361084 and batch: 850, loss is 4.678034610748291 and perplexity is 107.55847043750651
At time: 102.40876078605652 and batch: 900, loss is 4.684804019927978 and perplexity is 108.28904773308095
At time: 103.43906140327454 and batch: 950, loss is 4.73580189704895 and perplexity is 113.9548021088424
At time: 104.45862412452698 and batch: 1000, loss is 4.707020597457886 and perplexity is 110.72178322512154
At time: 105.45934128761292 and batch: 1050, loss is 4.629744253158569 and perplexity is 102.48784981464955
At time: 106.46331071853638 and batch: 1100, loss is 4.697951068878174 and perplexity is 109.72212889683163
At time: 107.47168612480164 and batch: 1150, loss is 4.628099746704102 and perplexity is 102.31944639233488
At time: 108.47914600372314 and batch: 1200, loss is 4.705419359207153 and perplexity is 110.54463313823028
At time: 109.48727250099182 and batch: 1250, loss is 4.670512084960937 and perplexity is 106.75239473383297
At time: 110.49392127990723 and batch: 1300, loss is 4.685254812240601 and perplexity is 108.33787460790327
At time: 111.5001962184906 and batch: 1350, loss is 4.589970073699951 and perplexity is 98.4914826321807
At time: 112.5067527294159 and batch: 1400, loss is 4.596150960922241 and perplexity is 99.10213261394861
At time: 113.51348066329956 and batch: 1450, loss is 4.538733282089233 and perplexity is 93.57219544008359
At time: 114.52184724807739 and batch: 1500, loss is 4.54155797958374 and perplexity is 93.83688224017645
At time: 115.52894496917725 and batch: 1550, loss is 4.540123205184937 and perplexity is 93.70234402294936
At time: 116.5353946685791 and batch: 1600, loss is 4.6085731983184814 and perplexity is 100.34088091505355
At time: 117.5429425239563 and batch: 1650, loss is 4.566106214523315 and perplexity is 96.16891865126205
At time: 118.55015063285828 and batch: 1700, loss is 4.6021262550354 and perplexity is 99.69606971081076
At time: 119.55571341514587 and batch: 1750, loss is 4.60175892829895 and perplexity is 99.6594554040056
At time: 120.56155800819397 and batch: 1800, loss is 4.559399356842041 and perplexity is 95.5260855053722
At time: 121.56895422935486 and batch: 1850, loss is 4.571161346435547 and perplexity is 96.65629606156662
At time: 122.58737444877625 and batch: 1900, loss is 4.660125694274902 and perplexity is 105.64936084191957
At time: 123.59504532814026 and batch: 1950, loss is 4.595292949676514 and perplexity is 99.01713833792691
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.521794660701308 and perplexity of 92.00055969771111
finished 3 epochs...
Completing Train Step...
At time: 126.82001662254333 and batch: 50, loss is 4.57309962272644 and perplexity is 96.84382435069601
At time: 127.83166551589966 and batch: 100, loss is 4.534704723358154 and perplexity is 93.19599264148343
At time: 128.8158040046692 and batch: 150, loss is 4.484514265060425 and perplexity is 88.63388777907255
At time: 129.8005392551422 and batch: 200, loss is 4.478402757644654 and perplexity is 88.09385301074849
At time: 130.78662991523743 and batch: 250, loss is 4.488392448425293 and perplexity is 88.97829365111872
At time: 131.7808005809784 and batch: 300, loss is 4.505189256668091 and perplexity is 90.48546740653521
At time: 132.78411841392517 and batch: 350, loss is 4.518724184036255 and perplexity is 91.71850736513528
At time: 133.79172801971436 and batch: 400, loss is 4.466857023239136 and perplexity is 87.08259387951408
At time: 134.7986741065979 and batch: 450, loss is 4.48557975769043 and perplexity is 88.72837686304187
At time: 135.8060131072998 and batch: 500, loss is 4.498168287277221 and perplexity is 89.85239669514628
At time: 136.8126630783081 and batch: 550, loss is 4.451249628067017 and perplexity is 85.73401271882236
At time: 137.81752061843872 and batch: 600, loss is 4.431919193267822 and perplexity is 84.09265219190544
At time: 138.82314538955688 and batch: 650, loss is 4.499848785400391 and perplexity is 90.00352042516172
At time: 139.82992935180664 and batch: 700, loss is 4.521445989608765 and perplexity is 91.96848735372126
At time: 140.83415365219116 and batch: 750, loss is 4.490413446426391 and perplexity is 89.15830044014038
At time: 141.8386824131012 and batch: 800, loss is 4.468147916793823 and perplexity is 87.19508082739584
At time: 142.84487581253052 and batch: 850, loss is 4.46161735534668 and perplexity is 86.62750331126651
At time: 143.84893774986267 and batch: 900, loss is 4.456674861907959 and perplexity is 86.20040378228815
At time: 144.8524284362793 and batch: 950, loss is 4.520888204574585 and perplexity is 91.91720301200802
At time: 145.8553512096405 and batch: 1000, loss is 4.494277725219726 and perplexity is 89.50349951294797
At time: 146.85888290405273 and batch: 1050, loss is 4.429515771865844 and perplexity is 83.8907847952619
At time: 147.86193418502808 and batch: 1100, loss is 4.486452941894531 and perplexity is 88.80588691552616
At time: 148.8657510280609 and batch: 1150, loss is 4.427171630859375 and perplexity is 83.69436327637153
At time: 149.86853623390198 and batch: 1200, loss is 4.507693901062011 and perplexity is 90.71238538099661
At time: 150.87365674972534 and batch: 1250, loss is 4.483399143218994 and perplexity is 88.53510528241529
At time: 151.87846064567566 and batch: 1300, loss is 4.491343145370483 and perplexity is 89.24122936140867
At time: 152.88229942321777 and batch: 1350, loss is 4.382219324111938 and perplexity is 80.01541664030871
At time: 153.8857250213623 and batch: 1400, loss is 4.396660871505738 and perplexity is 81.17934732313469
At time: 154.8896336555481 and batch: 1450, loss is 4.334865283966065 and perplexity is 76.31467738657301
At time: 155.89275908470154 and batch: 1500, loss is 4.346332030296326 and perplexity is 77.19479483158968
At time: 156.89696264266968 and batch: 1550, loss is 4.3437614917755125 and perplexity is 76.99661745827902
At time: 157.9012930393219 and batch: 1600, loss is 4.424029445648193 and perplexity is 83.43179282435781
At time: 158.90783214569092 and batch: 1650, loss is 4.379239597320557 and perplexity is 79.77734742637632
At time: 159.91210198402405 and batch: 1700, loss is 4.414404182434082 and perplexity is 82.63259228596736
At time: 160.9203336238861 and batch: 1750, loss is 4.411484107971192 and perplexity is 82.39165091800407
At time: 161.92761850357056 and batch: 1800, loss is 4.371570100784302 and perplexity is 79.16783564853306
At time: 162.93361020088196 and batch: 1850, loss is 4.391197919845581 and perplexity is 80.73707762182319
At time: 163.93998003005981 and batch: 1900, loss is 4.479256229400635 and perplexity is 88.16907071969798
At time: 164.94572257995605 and batch: 1950, loss is 4.41316514968872 and perplexity is 82.53027120096863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.457154739734738 and perplexity of 86.24177937154263
finished 4 epochs...
Completing Train Step...
At time: 168.16554617881775 and batch: 50, loss is 4.392754292488098 and perplexity is 80.86283243596213
At time: 169.13462471961975 and batch: 100, loss is 4.356849918365478 and perplexity is 78.01100592712325
At time: 170.10363793373108 and batch: 150, loss is 4.319084939956665 and perplexity is 75.11985765199096
At time: 171.07321882247925 and batch: 200, loss is 4.3220061016082765 and perplexity is 75.33961571758574
At time: 172.04364609718323 and batch: 250, loss is 4.320288810729981 and perplexity is 75.21034671075157
At time: 173.02516961097717 and batch: 300, loss is 4.340070266723632 and perplexity is 76.71292951513561
At time: 174.00951600074768 and batch: 350, loss is 4.346768159866333 and perplexity is 77.22846910690619
At time: 174.99195885658264 and batch: 400, loss is 4.300333576202393 and perplexity is 73.72438229775283
At time: 175.9767198562622 and batch: 450, loss is 4.33321213722229 and perplexity is 76.18862224867752
At time: 176.9668300151825 and batch: 500, loss is 4.3410727977752686 and perplexity is 76.78987517279742
At time: 177.98147010803223 and batch: 550, loss is 4.299170703887939 and perplexity is 73.6387000830717
At time: 178.9724576473236 and batch: 600, loss is 4.287339220046997 and perplexity is 72.7725788462498
At time: 179.96432042121887 and batch: 650, loss is 4.350235567092896 and perplexity is 77.49671645141484
At time: 180.9564847946167 and batch: 700, loss is 4.372738208770752 and perplexity is 79.26036626197701
At time: 181.948424577713 and batch: 750, loss is 4.340050220489502 and perplexity is 76.71139172520323
At time: 182.95136642456055 and batch: 800, loss is 4.323517875671387 and perplexity is 75.4535983308229
At time: 183.94374346733093 and batch: 850, loss is 4.320771389007568 and perplexity is 75.24665034929313
At time: 184.93585181236267 and batch: 900, loss is 4.307256240844726 and perplexity is 74.23652211317584
At time: 185.92875027656555 and batch: 950, loss is 4.376892948150635 and perplexity is 79.59035746598644
At time: 186.92099976539612 and batch: 1000, loss is 4.352802867889404 and perplexity is 77.69592944370596
At time: 187.91219115257263 and batch: 1050, loss is 4.2917718505859375 and perplexity is 73.09586878472929
At time: 188.90431308746338 and batch: 1100, loss is 4.345534038543701 and perplexity is 77.13321859390105
At time: 189.89730310440063 and batch: 1150, loss is 4.291757640838623 and perplexity is 73.09483011828371
At time: 190.90354108810425 and batch: 1200, loss is 4.374051451683044 and perplexity is 79.36452275261374
At time: 191.89406204223633 and batch: 1250, loss is 4.351510047912598 and perplexity is 77.5955474958797
At time: 192.88675260543823 and batch: 1300, loss is 4.359614343643188 and perplexity is 78.22695988060417
At time: 193.87779426574707 and batch: 1350, loss is 4.244877471923828 and perplexity is 69.74721362841555
At time: 194.86994194984436 and batch: 1400, loss is 4.261439657211303 and perplexity is 70.91199897365797
At time: 195.87739038467407 and batch: 1450, loss is 4.1946376514434816 and perplexity is 66.3296927539177
At time: 196.86930775642395 and batch: 1500, loss is 4.2061372756958 and perplexity is 67.09686192167067
At time: 197.86148166656494 and batch: 1550, loss is 4.2069501256942745 and perplexity is 67.15142377807956
At time: 198.85315608978271 and batch: 1600, loss is 4.298608331680298 and perplexity is 73.59729936713529
At time: 199.84547686576843 and batch: 1650, loss is 4.2501157903671265 and perplexity is 70.11353034810514
At time: 200.8378210067749 and batch: 1700, loss is 4.287744226455689 and perplexity is 72.80205817631541
At time: 201.82955813407898 and batch: 1750, loss is 4.284863967895507 and perplexity is 72.59267111424751
At time: 202.82205939292908 and batch: 1800, loss is 4.242552533149719 and perplexity is 69.58524398477556
At time: 203.81396484375 and batch: 1850, loss is 4.26619234085083 and perplexity is 71.24982342149133
At time: 204.80538177490234 and batch: 1900, loss is 4.3482811164855955 and perplexity is 77.34540086447022
At time: 205.80481910705566 and batch: 1950, loss is 4.288861303329468 and perplexity is 72.8834291122014
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.418200967478198 and perplexity of 82.94692682925222
finished 5 epochs...
Completing Train Step...
At time: 209.02190256118774 and batch: 50, loss is 4.264148087501526 and perplexity is 71.10431950542984
At time: 209.98981285095215 and batch: 100, loss is 4.2318934011459355 and perplexity is 68.8474647123021
At time: 210.96114420890808 and batch: 150, loss is 4.198949756622315 and perplexity is 66.61633092837886
At time: 211.9442901611328 and batch: 200, loss is 4.205480976104736 and perplexity is 67.05284072575633
At time: 212.9353277683258 and batch: 250, loss is 4.19922025680542 and perplexity is 66.63435309548264
At time: 213.92634963989258 and batch: 300, loss is 4.216695485115051 and perplexity is 67.80903767574121
At time: 214.9178273677826 and batch: 350, loss is 4.223937711715698 and perplexity is 68.30190867965958
At time: 215.90928411483765 and batch: 400, loss is 4.179383931159973 and perplexity is 65.32559575060064
At time: 216.90028738975525 and batch: 450, loss is 4.219226040840149 and perplexity is 67.98084952228477
At time: 217.89250373840332 and batch: 500, loss is 4.228542203903198 and perplexity is 68.6171294434132
At time: 218.8849139213562 and batch: 550, loss is 4.185315017700195 and perplexity is 65.71419879224166
At time: 219.8805661201477 and batch: 600, loss is 4.179529142379761 and perplexity is 65.33508244881382
At time: 220.8810625076294 and batch: 650, loss is 4.238264136314392 and perplexity is 69.28747377943024
At time: 221.88098573684692 and batch: 700, loss is 4.259969711303711 and perplexity is 70.80783874467389
At time: 222.8809175491333 and batch: 750, loss is 4.231807703971863 and perplexity is 68.84156493193505
At time: 223.8803985118866 and batch: 800, loss is 4.218020486831665 and perplexity is 67.89894431713704
At time: 224.880690574646 and batch: 850, loss is 4.215037322044372 and perplexity is 67.69669240274162
At time: 225.88204264640808 and batch: 900, loss is 4.19277398109436 and perplexity is 66.2061911911124
At time: 226.90585112571716 and batch: 950, loss is 4.2686137771606445 and perplexity is 71.42255938115335
At time: 227.90587496757507 and batch: 1000, loss is 4.248404188156128 and perplexity is 69.99362651764342
At time: 228.90378046035767 and batch: 1050, loss is 4.195224432945252 and perplexity is 66.36862521194982
At time: 229.9035143852234 and batch: 1100, loss is 4.239669117927551 and perplexity is 69.38488982396359
At time: 230.90426063537598 and batch: 1150, loss is 4.1898264503479 and perplexity is 66.0113337222367
At time: 231.90357327461243 and batch: 1200, loss is 4.273423490524292 and perplexity is 71.76690886680692
At time: 232.9027030467987 and batch: 1250, loss is 4.248012175559998 and perplexity is 69.96619351179291
At time: 233.90145778656006 and batch: 1300, loss is 4.255966472625732 and perplexity is 70.52494468992103
At time: 234.90230083465576 and batch: 1350, loss is 4.142039704322815 and perplexity is 62.931051366697844
At time: 235.90303683280945 and batch: 1400, loss is 4.163684525489807 and perplexity is 64.3080312015478
At time: 236.90357637405396 and batch: 1450, loss is 4.0902445602416995 and perplexity is 59.75450349315797
At time: 237.9035828113556 and batch: 1500, loss is 4.106440110206604 and perplexity is 60.73013969720477
At time: 238.90367817878723 and batch: 1550, loss is 4.10717465877533 and perplexity is 60.77476532223586
At time: 239.90396761894226 and batch: 1600, loss is 4.202932834625244 and perplexity is 66.88219810408869
At time: 240.90354704856873 and batch: 1650, loss is 4.15326051235199 and perplexity is 63.641165187942775
At time: 241.90326595306396 and batch: 1700, loss is 4.188654608726502 and perplexity is 65.93402420000176
At time: 242.9038655757904 and batch: 1750, loss is 4.189343118667603 and perplexity is 65.97943606258575
At time: 243.90398716926575 and batch: 1800, loss is 4.144695272445679 and perplexity is 63.098391153406624
At time: 244.90661001205444 and batch: 1850, loss is 4.1689373922348025 and perplexity is 64.64672148877716
At time: 245.906822681427 and batch: 1900, loss is 4.251960515975952 and perplexity is 70.24298994506766
At time: 246.9061381816864 and batch: 1950, loss is 4.191225748062134 and perplexity is 66.10376788700306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.405182878361192 and perplexity of 81.87411447801162
finished 6 epochs...
Completing Train Step...
At time: 250.10380125045776 and batch: 50, loss is 4.1665230560302735 and perplexity is 64.4908308305369
At time: 251.06239128112793 and batch: 100, loss is 4.137481737136841 and perplexity is 62.64486640587894
At time: 252.04694771766663 and batch: 150, loss is 4.107638854980468 and perplexity is 60.80298328649588
At time: 253.0110490322113 and batch: 200, loss is 4.111923575401306 and perplexity is 61.064066004426955
At time: 253.98020768165588 and batch: 250, loss is 4.108490619659424 and perplexity is 60.85479518267353
At time: 254.95406675338745 and batch: 300, loss is 4.124667301177978 and perplexity is 61.84722932675722
At time: 255.93654608726501 and batch: 350, loss is 4.130478253364563 and perplexity is 62.20766684760216
At time: 256.91845870018005 and batch: 400, loss is 4.086249008178711 and perplexity is 59.51622760231156
At time: 257.9005286693573 and batch: 450, loss is 4.134625463485718 and perplexity is 62.46619081924489
At time: 258.88205337524414 and batch: 500, loss is 4.142588834762574 and perplexity is 62.96561821259436
At time: 259.86333107948303 and batch: 550, loss is 4.099373097419739 and perplexity is 60.30247196996916
At time: 260.84520173072815 and batch: 600, loss is 4.094073915481568 and perplexity is 59.98376339285954
At time: 261.82763743400574 and batch: 650, loss is 4.15052845954895 and perplexity is 63.4675314604601
At time: 262.8097369670868 and batch: 700, loss is 4.171899251937866 and perplexity is 64.83847984858411
At time: 263.7919352054596 and batch: 750, loss is 4.145807371139527 and perplexity is 63.16860182515423
At time: 264.77412033081055 and batch: 800, loss is 4.1354492568969725 and perplexity is 62.51767125737945
At time: 265.756530046463 and batch: 850, loss is 4.131773433685303 and perplexity is 62.28828919246926
At time: 266.73902130126953 and batch: 900, loss is 4.106179251670837 and perplexity is 60.71429978796402
At time: 267.7213361263275 and batch: 950, loss is 4.1872908306121825 and perplexity is 65.84416610798563
At time: 268.7037527561188 and batch: 1000, loss is 4.167114429473877 and perplexity is 64.52898027441817
At time: 269.6861050128937 and batch: 1050, loss is 4.116365809440612 and perplexity is 61.335930272294625
At time: 270.66791558265686 and batch: 1100, loss is 4.154934902191162 and perplexity is 63.747814569690426
At time: 271.64977741241455 and batch: 1150, loss is 4.109459047317505 and perplexity is 60.913757195068925
At time: 272.6328248977661 and batch: 1200, loss is 4.1910159349441525 and perplexity is 66.08989990424557
At time: 273.61653089523315 and batch: 1250, loss is 4.1668810415267945 and perplexity is 64.51392174549255
At time: 274.6018793582916 and batch: 1300, loss is 4.174828710556031 and perplexity is 65.02869997712794
At time: 275.5855302810669 and batch: 1350, loss is 4.061700692176819 and perplexity is 58.07299142492908
At time: 276.5695948600769 and batch: 1400, loss is 4.08459273815155 and perplexity is 59.41773424671641
At time: 277.5541834831238 and batch: 1450, loss is 4.011897501945495 and perplexity is 55.251611198999136
At time: 278.53847908973694 and batch: 1500, loss is 4.0276582098007205 and perplexity is 56.12931414311067
At time: 279.5218982696533 and batch: 1550, loss is 4.026461200714111 and perplexity is 56.06216703992009
At time: 280.5061800479889 and batch: 1600, loss is 4.123740830421448 and perplexity is 61.789956212443016
At time: 281.4898076057434 and batch: 1650, loss is 4.07304886341095 and perplexity is 58.735767209515814
At time: 282.4733247756958 and batch: 1700, loss is 4.111586747169494 and perplexity is 61.04350136661716
At time: 283.45723390579224 and batch: 1750, loss is 4.114877572059632 and perplexity is 61.24471573934053
At time: 284.4410617351532 and batch: 1800, loss is 4.069035115242005 and perplexity is 58.500489120790114
At time: 285.4251346588135 and batch: 1850, loss is 4.093101205825806 and perplexity is 59.92544497506066
At time: 286.40901923179626 and batch: 1900, loss is 4.17510986328125 and perplexity is 65.04698554374198
At time: 287.393189907074 and batch: 1950, loss is 4.115052628517151 and perplexity is 61.255437960789294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.400106456667878 and perplexity of 81.45954011460057
finished 7 epochs...
Completing Train Step...
At time: 290.5168149471283 and batch: 50, loss is 4.0892523622512815 and perplexity is 59.69524459801346
At time: 291.4918210506439 and batch: 100, loss is 4.062161693572998 and perplexity is 58.09976932690711
At time: 292.45742535591125 and batch: 150, loss is 4.033694686889649 and perplexity is 56.46916217239625
At time: 293.4253923892975 and batch: 200, loss is 4.038453016281128 and perplexity is 56.7385013405222
At time: 294.40019845962524 and batch: 250, loss is 4.033255200386048 and perplexity is 56.4443501904168
At time: 295.381906747818 and batch: 300, loss is 4.045963659286499 and perplexity is 57.16624828529342
At time: 296.36543822288513 and batch: 350, loss is 4.053391485214234 and perplexity is 57.592450143551346
At time: 297.34993720054626 and batch: 400, loss is 4.014314203262329 and perplexity is 55.3852993176006
At time: 298.33188128471375 and batch: 450, loss is 4.062425971031189 and perplexity is 58.115125815363804
At time: 299.3157277107239 and batch: 500, loss is 4.070739722251892 and perplexity is 58.600294504939036
At time: 300.30059361457825 and batch: 550, loss is 4.030521268844605 and perplexity is 56.29024595229973
At time: 301.309770822525 and batch: 600, loss is 4.028392119407654 and perplexity is 56.17052310596806
At time: 302.2938551902771 and batch: 650, loss is 4.079694819450379 and perplexity is 59.12742255686733
At time: 303.28172397613525 and batch: 700, loss is 4.1035015535354615 and perplexity is 60.55194268929062
At time: 304.2658221721649 and batch: 750, loss is 4.077291312217713 and perplexity is 58.98548001739482
At time: 305.2488875389099 and batch: 800, loss is 4.070142693519593 and perplexity is 58.565318887161666
At time: 306.2309808731079 and batch: 850, loss is 4.062155985832215 and perplexity is 58.099437709430624
At time: 307.21488642692566 and batch: 900, loss is 4.0343406391143795 and perplexity is 56.50565033686696
At time: 308.19915866851807 and batch: 950, loss is 4.120288243293762 and perplexity is 61.576988860726146
At time: 309.18411469459534 and batch: 1000, loss is 4.094333639144898 and perplexity is 59.99934461894721
At time: 310.1682243347168 and batch: 1050, loss is 4.049644341468811 and perplexity is 57.37704677993712
At time: 311.1529359817505 and batch: 1100, loss is 4.085564703941345 and perplexity is 59.47551432729333
At time: 312.1363136768341 and batch: 1150, loss is 4.047337298393249 and perplexity is 57.24482803727857
At time: 313.1206111907959 and batch: 1200, loss is 4.125681447982788 and perplexity is 61.909983312263726
At time: 314.10490703582764 and batch: 1250, loss is 4.099074773788452 and perplexity is 60.284485000657895
At time: 315.08921360969543 and batch: 1300, loss is 4.10520498752594 and perplexity is 60.65517682796468
At time: 316.0727972984314 and batch: 1350, loss is 3.9986060094833373 and perplexity is 54.522093752953474
At time: 317.0573585033417 and batch: 1400, loss is 4.022893919944763 and perplexity is 55.86253383509934
At time: 318.04106163978577 and batch: 1450, loss is 3.947524309158325 and perplexity is 51.80694994864335
At time: 319.02478981018066 and batch: 1500, loss is 3.962576675415039 and perplexity is 52.592665739686694
At time: 320.00801730155945 and batch: 1550, loss is 3.963770408630371 and perplexity is 52.65548483882586
At time: 320.99318647384644 and batch: 1600, loss is 4.061199145317078 and perplexity is 58.043872401331946
At time: 321.9785919189453 and batch: 1650, loss is 4.009652805328369 and perplexity is 55.12772718727848
At time: 322.9631550312042 and batch: 1700, loss is 4.046342935562134 and perplexity is 57.187934199251465
At time: 323.9480605125427 and batch: 1750, loss is 4.051442036628723 and perplexity is 57.48028598773227
At time: 324.93255281448364 and batch: 1800, loss is 4.006698913574219 and perplexity is 54.96512611972223
At time: 325.9162585735321 and batch: 1850, loss is 4.032475891113282 and perplexity is 56.400379720440995
At time: 326.89933156967163 and batch: 1900, loss is 4.111526246070862 and perplexity is 61.03980827943916
At time: 327.88455390930176 and batch: 1950, loss is 4.049758520126343 and perplexity is 57.38359838813136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.401465695403343 and perplexity of 81.57033836047272
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 331.0308427810669 and batch: 50, loss is 4.058501653671264 and perplexity is 57.88751052767606
At time: 332.0059394836426 and batch: 100, loss is 4.049207563400269 and perplexity is 57.351991216524524
At time: 332.9629759788513 and batch: 150, loss is 4.023265228271485 and perplexity is 55.883279910420995
At time: 333.9232506752014 and batch: 200, loss is 4.024497256278992 and perplexity is 55.952172106265145
At time: 334.88400745391846 and batch: 250, loss is 4.012613334655762 and perplexity is 55.29117626888643
At time: 335.85157227516174 and batch: 300, loss is 4.019713668823242 and perplexity is 55.685159146742315
At time: 336.829909324646 and batch: 350, loss is 4.0251338052749634 and perplexity is 55.98779974340712
At time: 337.8154888153076 and batch: 400, loss is 3.985908365249634 and perplexity is 53.83416836237207
At time: 338.7995972633362 and batch: 450, loss is 4.026484651565552 and perplexity is 56.06348176088637
At time: 339.7837345600128 and batch: 500, loss is 4.028660354614257 and perplexity is 56.18559203875723
At time: 340.76677918434143 and batch: 550, loss is 3.991650309562683 and perplexity is 54.14417031449318
At time: 341.74919962882996 and batch: 600, loss is 3.9695148611068727 and perplexity is 52.958832217236385
At time: 342.7306115627289 and batch: 650, loss is 4.008634181022644 and perplexity is 55.071601334877826
At time: 343.7149429321289 and batch: 700, loss is 4.025986866950989 and perplexity is 56.035581167046274
At time: 344.6984522342682 and batch: 750, loss is 3.9851000547409057 and perplexity is 53.79067122032292
At time: 345.6830153465271 and batch: 800, loss is 3.97782968044281 and perplexity is 53.40101111062608
At time: 346.6667847633362 and batch: 850, loss is 3.9701579093933104 and perplexity is 52.992898255425274
At time: 347.6512348651886 and batch: 900, loss is 3.938539171218872 and perplexity is 51.343542365336276
At time: 348.63602566719055 and batch: 950, loss is 4.016323490142822 and perplexity is 55.49669614951014
At time: 349.62138748168945 and batch: 1000, loss is 3.989129314422607 and perplexity is 54.007845034151835
At time: 350.6281740665436 and batch: 1050, loss is 3.941865077018738 and perplexity is 51.514590437890305
At time: 351.6120045185089 and batch: 1100, loss is 3.964513564109802 and perplexity is 52.69463059479584
At time: 352.5962405204773 and batch: 1150, loss is 3.925146279335022 and perplexity is 50.660488099368585
At time: 353.5804879665375 and batch: 1200, loss is 3.986517028808594 and perplexity is 53.866945232912585
At time: 354.5652141571045 and batch: 1250, loss is 3.9626614332199095 and perplexity is 52.597123567502265
At time: 355.5491364002228 and batch: 1300, loss is 3.967884478569031 and perplexity is 52.872559409914665
At time: 356.5335056781769 and batch: 1350, loss is 3.856798219680786 and perplexity is 47.31362077463221
At time: 357.5179510116577 and batch: 1400, loss is 3.8708568477630614 and perplexity is 47.98348301148057
At time: 358.5036463737488 and batch: 1450, loss is 3.782094945907593 and perplexity is 43.90793018995891
At time: 359.48750042915344 and batch: 1500, loss is 3.7936643409729003 and perplexity is 44.41886830416046
At time: 360.4721829891205 and batch: 1550, loss is 3.7910697889328 and perplexity is 44.303770616819634
At time: 361.4561927318573 and batch: 1600, loss is 3.882380471229553 and perplexity is 48.539624832445334
At time: 362.44058084487915 and batch: 1650, loss is 3.8271872282028196 and perplexity is 45.933156871189276
At time: 363.4266936779022 and batch: 1700, loss is 3.847076997756958 and perplexity is 46.85590295989429
At time: 364.4117534160614 and batch: 1750, loss is 3.8444309759140016 and perplexity is 46.732085101811336
At time: 365.3961169719696 and batch: 1800, loss is 3.799264659881592 and perplexity is 44.66832600156676
At time: 366.3818392753601 and batch: 1850, loss is 3.8081359243392945 and perplexity is 45.06635342731616
At time: 367.36600947380066 and batch: 1900, loss is 3.8915657711029055 and perplexity is 48.98752976369495
At time: 368.35052013397217 and batch: 1950, loss is 3.8228946256637575 and perplexity is 45.73640667269467
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327592148891715 and perplexity of 75.76164401088994
finished 9 epochs...
Completing Train Step...
At time: 371.5165240764618 and batch: 50, loss is 3.968332209587097 and perplexity is 52.89623739505569
At time: 372.503901720047 and batch: 100, loss is 3.9501120615005494 and perplexity is 51.94118711607916
At time: 373.46473240852356 and batch: 150, loss is 3.923020372390747 and perplexity is 50.55290301437646
At time: 374.44754910469055 and batch: 200, loss is 3.924616756439209 and perplexity is 50.63366931221447
At time: 375.4107081890106 and batch: 250, loss is 3.913101315498352 and perplexity is 50.0539445827767
At time: 376.37919306755066 and batch: 300, loss is 3.922927055358887 and perplexity is 50.54818578761748
At time: 377.3475065231323 and batch: 350, loss is 3.9329123735427856 and perplexity is 51.05545390829668
At time: 378.31600642204285 and batch: 400, loss is 3.894374957084656 and perplexity is 49.12533831989319
At time: 379.2844169139862 and batch: 450, loss is 3.9424432420730593 and perplexity is 51.544382985544225
At time: 380.25826048851013 and batch: 500, loss is 3.9490816450119017 and perplexity is 51.887693625455306
At time: 381.2385790348053 and batch: 550, loss is 3.913487114906311 and perplexity is 50.073259090486005
At time: 382.2228603363037 and batch: 600, loss is 3.897546048164368 and perplexity is 49.281366501064745
At time: 383.20760583877563 and batch: 650, loss is 3.9373787593841554 and perplexity is 51.283997266239844
At time: 384.19258284568787 and batch: 700, loss is 3.9570039081573487 and perplexity is 52.30039419110798
At time: 385.17675614356995 and batch: 750, loss is 3.921278190612793 and perplexity is 50.464907342407294
At time: 386.1598711013794 and batch: 800, loss is 3.913717021942139 and perplexity is 50.08477260852643
At time: 387.1446008682251 and batch: 850, loss is 3.9080141162872315 and perplexity is 49.79995678639864
At time: 388.13018894195557 and batch: 900, loss is 3.876958951950073 and perplexity is 48.27717839265165
At time: 389.1153244972229 and batch: 950, loss is 3.9590245485305786 and perplexity is 52.406181322026264
At time: 390.10092973709106 and batch: 1000, loss is 3.932509937286377 and perplexity is 51.03491147634354
At time: 391.0847430229187 and batch: 1050, loss is 3.8895797443389895 and perplexity is 48.890335765373976
At time: 392.069442987442 and batch: 1100, loss is 3.9121300411224365 and perplexity is 50.005352071140734
At time: 393.0557761192322 and batch: 1150, loss is 3.8772901058197022 and perplexity is 48.29316821449071
At time: 394.0404603481293 and batch: 1200, loss is 3.938715581893921 and perplexity is 51.352600713275486
At time: 395.02538871765137 and batch: 1250, loss is 3.9196678304672243 and perplexity is 50.38370606607085
At time: 396.0098628997803 and batch: 1300, loss is 3.9266353464126587 and perplexity is 50.73598115749872
At time: 396.9934697151184 and batch: 1350, loss is 3.816934332847595 and perplexity is 45.464615079923206
At time: 397.97655272483826 and batch: 1400, loss is 3.835384478569031 and perplexity is 46.3112299208488
At time: 398.9601798057556 and batch: 1450, loss is 3.748021297454834 and perplexity is 42.437028612636134
At time: 399.94350123405457 and batch: 1500, loss is 3.7626304769515992 and perplexity is 43.061549542642354
At time: 400.9264006614685 and batch: 1550, loss is 3.76320818901062 and perplexity is 43.08643390639968
At time: 401.90987753868103 and batch: 1600, loss is 3.857480230331421 and perplexity is 47.34590017411654
At time: 402.8932466506958 and batch: 1650, loss is 3.804507737159729 and perplexity is 44.9031405241039
At time: 403.87700057029724 and batch: 1700, loss is 3.8286556816101074 and perplexity is 46.00065712026008
At time: 404.86123037338257 and batch: 1750, loss is 3.8291807794570922 and perplexity is 46.024818309212804
At time: 405.84385657310486 and batch: 1800, loss is 3.787031526565552 and perplexity is 44.125221124700076
At time: 406.8272247314453 and batch: 1850, loss is 3.8000901412963866 and perplexity is 44.70521409763521
At time: 407.8323905467987 and batch: 1900, loss is 3.8873357820510863 and perplexity is 48.78075069404066
At time: 408.81963562965393 and batch: 1950, loss is 3.820022144317627 and perplexity is 45.60521820610449
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.325947038517442 and perplexity of 75.63711020836728
finished 10 epochs...
Completing Train Step...
At time: 411.9555974006653 and batch: 50, loss is 3.9253625869750977 and perplexity is 50.67144753525656
At time: 412.9035289287567 and batch: 100, loss is 3.906709852218628 and perplexity is 49.7350468312068
At time: 413.85659074783325 and batch: 150, loss is 3.8806422472000124 and perplexity is 48.455325377071546
At time: 414.82663226127625 and batch: 200, loss is 3.880482153892517 and perplexity is 48.44756862468481
At time: 415.79976892471313 and batch: 250, loss is 3.868600730895996 and perplexity is 47.87534869381436
At time: 416.77216625213623 and batch: 300, loss is 3.881042094230652 and perplexity is 48.47470396902029
At time: 417.74455738067627 and batch: 350, loss is 3.889958338737488 and perplexity is 48.90884887689448
At time: 418.71696376800537 and batch: 400, loss is 3.851887278556824 and perplexity is 47.08183597523409
At time: 419.69022965431213 and batch: 450, loss is 3.9027862405776976 and perplexity is 49.540288151064644
At time: 420.6620411872864 and batch: 500, loss is 3.9106575441360474 and perplexity is 49.931773526300134
At time: 421.64252161979675 and batch: 550, loss is 3.8754896831512453 and perplexity is 48.20629832443126
At time: 422.62657594680786 and batch: 600, loss is 3.8619228982925415 and perplexity is 47.55671022069546
At time: 423.6804759502411 and batch: 650, loss is 3.9016294622421266 and perplexity is 49.48301415204087
At time: 424.66492199897766 and batch: 700, loss is 3.9220876455307008 and perplexity is 50.50577294703836
At time: 425.6495430469513 and batch: 750, loss is 3.888457841873169 and perplexity is 48.835516333901616
At time: 426.6333887577057 and batch: 800, loss is 3.8795287799835205 and perplexity is 48.401401987334296
At time: 427.6213574409485 and batch: 850, loss is 3.8750095796585082 and perplexity is 48.18315986710532
At time: 428.6090974807739 and batch: 900, loss is 3.8442971181869505 and perplexity is 46.72583006977077
At time: 429.59178280830383 and batch: 950, loss is 3.928427605628967 and perplexity is 50.826994722914655
At time: 430.5769181251526 and batch: 1000, loss is 3.9023271894454954 and perplexity is 49.51755184466213
At time: 431.57075786590576 and batch: 1050, loss is 3.8615746450424195 and perplexity is 47.54015132530791
At time: 432.55885100364685 and batch: 1100, loss is 3.8828913354873658 and perplexity is 48.56442832692983
At time: 433.54370951652527 and batch: 1150, loss is 3.8491002893447877 and perplexity is 46.95080208612099
At time: 434.52755188941956 and batch: 1200, loss is 3.9105521488189696 and perplexity is 49.926511228512716
At time: 435.51293420791626 and batch: 1250, loss is 3.8942309761047365 and perplexity is 49.11826571471555
At time: 436.4972174167633 and batch: 1300, loss is 3.9010666275024413 and perplexity is 49.455171228868984
At time: 437.48155975341797 and batch: 1350, loss is 3.7922862148284913 and perplexity is 44.35769566193597
At time: 438.46754813194275 and batch: 1400, loss is 3.8120290517807005 and perplexity is 45.24214445092666
At time: 439.451575756073 and batch: 1450, loss is 3.725758571624756 and perplexity is 41.502703580166866
At time: 440.436208486557 and batch: 1500, loss is 3.7410774183273316 and perplexity is 42.143371754232454
At time: 441.4204182624817 and batch: 1550, loss is 3.7432842206954957 and perplexity is 42.2364765409692
At time: 442.40332674980164 and batch: 1600, loss is 3.837945218086243 and perplexity is 46.42997288741429
At time: 443.38741159439087 and batch: 1650, loss is 3.7860912561416624 and perplexity is 44.08375098395769
At time: 444.37263107299805 and batch: 1700, loss is 3.8111538648605348 and perplexity is 45.20256643946818
At time: 445.35760378837585 and batch: 1750, loss is 3.8133056926727296 and perplexity is 45.29993930636414
At time: 446.34224939346313 and batch: 1800, loss is 3.7728101921081545 and perplexity is 43.5021426023534
At time: 447.32631945610046 and batch: 1850, loss is 3.7877085638046264 and perplexity is 44.15510565791329
At time: 448.3112165927887 and batch: 1900, loss is 3.8767514705657957 and perplexity is 48.26716281590853
At time: 449.29628920555115 and batch: 1950, loss is 3.8091830110549925 and perplexity is 45.11356652110284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.327839980014535 and perplexity of 75.78042243103422
Annealing...
finished 11 epochs...
Completing Train Step...
At time: 452.47128558158875 and batch: 50, loss is 3.9170719051361083 and perplexity is 50.253083343988635
At time: 453.4317898750305 and batch: 100, loss is 3.920886778831482 and perplexity is 50.44515864831859
At time: 454.39242219924927 and batch: 150, loss is 3.903480176925659 and perplexity is 49.574677888465516
At time: 455.3524911403656 and batch: 200, loss is 3.901954131126404 and perplexity is 49.49908235531797
At time: 456.3128743171692 and batch: 250, loss is 3.892128348350525 and perplexity is 49.01509678692005
At time: 457.2783131599426 and batch: 300, loss is 3.90792106628418 and perplexity is 49.79532311585257
At time: 458.2463481426239 and batch: 350, loss is 3.917712926864624 and perplexity is 50.285306989262025
At time: 459.21558594703674 and batch: 400, loss is 3.886510353088379 and perplexity is 48.74050226299075
At time: 460.1855492591858 and batch: 450, loss is 3.9353141450881957 and perplexity is 51.1782248195552
At time: 461.159250497818 and batch: 500, loss is 3.937277226448059 and perplexity is 51.27879051575544
At time: 462.13958835601807 and batch: 550, loss is 3.90226505279541 and perplexity is 49.51447508546082
At time: 463.12591457366943 and batch: 600, loss is 3.878725700378418 and perplexity is 48.36254741228653
At time: 464.1102976799011 and batch: 650, loss is 3.910349202156067 and perplexity is 49.91637983776927
At time: 465.09571170806885 and batch: 700, loss is 3.9266063165664673 and perplexity is 50.734508321147565
At time: 466.0808210372925 and batch: 750, loss is 3.8883720684051513 and perplexity is 48.83132772194168
At time: 467.06541538238525 and batch: 800, loss is 3.8752596092224123 and perplexity is 48.19520858775983
At time: 468.0511360168457 and batch: 850, loss is 3.8695569038391113 and perplexity is 47.92114769927314
At time: 469.0374355316162 and batch: 900, loss is 3.83932692527771 and perplexity is 46.49416985534529
At time: 470.02216124534607 and batch: 950, loss is 3.9249477577209473 and perplexity is 50.6504318957212
At time: 471.0054793357849 and batch: 1000, loss is 3.8925012063980104 and perplexity is 49.03337586774476
At time: 472.0273985862732 and batch: 1050, loss is 3.8522767543792726 and perplexity is 47.10017678344178
At time: 473.011595249176 and batch: 1100, loss is 3.872743730545044 and perplexity is 48.07410769158095
At time: 473.99732279777527 and batch: 1150, loss is 3.836930527687073 and perplexity is 46.38288473368061
At time: 474.9817454814911 and batch: 1200, loss is 3.887515263557434 and perplexity is 48.789506722405086
At time: 475.9648206233978 and batch: 1250, loss is 3.8697526025772095 and perplexity is 47.93052672510794
At time: 476.9485116004944 and batch: 1300, loss is 3.877244291305542 and perplexity is 48.290955737133885
At time: 477.93286895751953 and batch: 1350, loss is 3.7611612272262573 and perplexity is 42.99832782842019
At time: 478.9181351661682 and batch: 1400, loss is 3.7775662183761596 and perplexity is 43.709532720783656
At time: 479.9020595550537 and batch: 1450, loss is 3.687930717468262 and perplexity is 39.96206853050577
At time: 480.886926651001 and batch: 1500, loss is 3.702559161186218 and perplexity is 40.550948095418974
At time: 481.87184476852417 and batch: 1550, loss is 3.7019338035583496 and perplexity is 40.52559717823109
At time: 482.8716251850128 and batch: 1600, loss is 3.792201199531555 and perplexity is 44.35392473956319
At time: 483.85603380203247 and batch: 1650, loss is 3.742101788520813 and perplexity is 42.18656428690487
At time: 484.8428316116333 and batch: 1700, loss is 3.7566976308822633 and perplexity is 42.806828355648605
At time: 485.8284001350403 and batch: 1750, loss is 3.7621911907196046 and perplexity is 43.04263735103674
At time: 486.81404161453247 and batch: 1800, loss is 3.7211564016342162 and perplexity is 41.31213992274095
At time: 487.7986443042755 and batch: 1850, loss is 3.736196403503418 and perplexity is 41.938170534466
At time: 488.78398966789246 and batch: 1900, loss is 3.822594180107117 and perplexity is 45.72266743658272
At time: 489.78474855422974 and batch: 1950, loss is 3.7553764820098876 and perplexity is 42.75031150444422
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3029441656068315 and perplexity of 73.91709783014241
finished 12 epochs...
Completing Train Step...
At time: 492.9426574707031 and batch: 50, loss is 3.908861560821533 and perplexity is 49.84217737486242
At time: 493.8949773311615 and batch: 100, loss is 3.895171031951904 and perplexity is 49.16446133743408
At time: 494.8479971885681 and batch: 150, loss is 3.871355957984924 and perplexity is 48.007438035933674
At time: 495.8070001602173 and batch: 200, loss is 3.8666714668273925 and perplexity is 47.78307354399414
At time: 496.79205560684204 and batch: 250, loss is 3.853720531463623 and perplexity is 47.16822805296128
At time: 497.75691771507263 and batch: 300, loss is 3.8702670764923095 and perplexity is 47.955192075140566
At time: 498.7248601913452 and batch: 350, loss is 3.8794209480285646 and perplexity is 48.39618305092451
At time: 499.69309997558594 and batch: 400, loss is 3.847874040603638 and perplexity is 46.89326400937393
At time: 500.66729259490967 and batch: 450, loss is 3.8983555936813357 and perplexity is 49.32127816335965
At time: 501.6431646347046 and batch: 500, loss is 3.900830464363098 and perplexity is 49.4434931193986
At time: 502.62863397598267 and batch: 550, loss is 3.868447027206421 and perplexity is 47.8679906415748
At time: 503.6135356426239 and batch: 600, loss is 3.8489711093902588 and perplexity is 46.94473737537037
At time: 504.5989511013031 and batch: 650, loss is 3.881734399795532 and perplexity is 48.50827489566278
At time: 505.5832278728485 and batch: 700, loss is 3.8998662185668946 and perplexity is 49.395840417159675
At time: 506.5673530101776 and batch: 750, loss is 3.864046473503113 and perplexity is 47.657807777757235
At time: 507.55337023735046 and batch: 800, loss is 3.851713080406189 and perplexity is 47.07363512078629
At time: 508.53799700737 and batch: 850, loss is 3.846669054031372 and perplexity is 46.83679228657981
At time: 509.5223317146301 and batch: 900, loss is 3.816185932159424 and perplexity is 45.43060205998128
At time: 510.5056526660919 and batch: 950, loss is 3.9036319351196287 and perplexity is 49.582201822943404
At time: 511.48934030532837 and batch: 1000, loss is 3.8728513050079347 and perplexity is 48.07927951606796
At time: 512.4738395214081 and batch: 1050, loss is 3.834581203460693 and perplexity is 46.274044199798446
At time: 513.4585974216461 and batch: 1100, loss is 3.855947742462158 and perplexity is 47.273398724425704
At time: 514.4424469470978 and batch: 1150, loss is 3.821918387413025 and perplexity is 45.69177883029747
At time: 515.4252276420593 and batch: 1200, loss is 3.8732799768447874 and perplexity is 48.09989416727719
At time: 516.4102911949158 and batch: 1250, loss is 3.8578953742980957 and perplexity is 47.36555961938831
At time: 517.3944647312164 and batch: 1300, loss is 3.8652326822280885 and perplexity is 47.71437342785752
At time: 518.3781688213348 and batch: 1350, loss is 3.75093560218811 and perplexity is 42.56088343367369
At time: 519.362979888916 and batch: 1400, loss is 3.769507966041565 and perplexity is 43.358725621072935
At time: 520.347948551178 and batch: 1450, loss is 3.6813802242279055 and perplexity is 39.7011527671661
At time: 521.3331248760223 and batch: 1500, loss is 3.6972987031936646 and perplexity is 40.33819162526536
At time: 522.3182806968689 and batch: 1550, loss is 3.698421349525452 and perplexity is 40.38350257745261
At time: 523.3035974502563 and batch: 1600, loss is 3.7906059312820433 and perplexity is 44.28322473941125
At time: 524.2881426811218 and batch: 1650, loss is 3.7414060688018798 and perplexity is 42.15722446958459
At time: 525.2729408740997 and batch: 1700, loss is 3.757891516685486 and perplexity is 42.8579653400892
At time: 526.2574229240417 and batch: 1750, loss is 3.7645817041397094 and perplexity is 43.145654436065165
At time: 527.2417674064636 and batch: 1800, loss is 3.724838147163391 and perplexity is 41.46452105134129
At time: 528.2273244857788 and batch: 1850, loss is 3.740694313049316 and perplexity is 42.12722949836918
At time: 529.2127819061279 and batch: 1900, loss is 3.8278165292739867 and perplexity is 45.96207175313925
At time: 530.1969146728516 and batch: 1950, loss is 3.759974284172058 and perplexity is 42.94732153863104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.301487270621366 and perplexity of 73.80948678900072
finished 13 epochs...
Completing Train Step...
At time: 533.3450016975403 and batch: 50, loss is 3.8957553911209106 and perplexity is 49.193199437074114
At time: 534.3220255374908 and batch: 100, loss is 3.880745530128479 and perplexity is 48.46033024343048
At time: 535.2784447669983 and batch: 150, loss is 3.8559557723999025 and perplexity is 47.27377832839853
At time: 536.2400534152985 and batch: 200, loss is 3.851087908744812 and perplexity is 47.04421521531457
At time: 537.2075788974762 and batch: 250, loss is 3.8373504114151 and perplexity is 46.40236424151724
At time: 538.1762783527374 and batch: 300, loss is 3.8541165018081665 and perplexity is 47.18690897077557
At time: 539.1506772041321 and batch: 350, loss is 3.863110032081604 and perplexity is 47.61319992207753
At time: 540.1248595714569 and batch: 400, loss is 3.8315642976760866 and perplexity is 46.1346501432698
At time: 541.098299741745 and batch: 450, loss is 3.882735004425049 and perplexity is 48.55683679167052
At time: 542.0718615055084 and batch: 500, loss is 3.8851693868637085 and perplexity is 48.67518669845309
At time: 543.0487532615662 and batch: 550, loss is 3.8534256982803345 and perplexity is 47.15432334401988
At time: 544.0217323303223 and batch: 600, loss is 3.8348749542236327 and perplexity is 46.28763923226425
At time: 544.9940385818481 and batch: 650, loss is 3.8678643798828123 and perplexity is 47.840108608425744
At time: 546.0016152858734 and batch: 700, loss is 3.886661801338196 and perplexity is 48.74788448575193
At time: 546.9860949516296 and batch: 750, loss is 3.8517674255371093 and perplexity is 47.07619341316456
At time: 547.9706711769104 and batch: 800, loss is 3.839563021659851 and perplexity is 46.505148256568205
At time: 548.9549422264099 and batch: 850, loss is 3.8351412630081176 and perplexity is 46.29996767871881
At time: 549.9412987232208 and batch: 900, loss is 3.804456911087036 and perplexity is 44.90085833181741
At time: 550.924703836441 and batch: 950, loss is 3.892620530128479 and perplexity is 49.03922706215699
At time: 551.9085440635681 and batch: 1000, loss is 3.862254810333252 and perplexity is 47.572497485280955
At time: 552.8924732208252 and batch: 1050, loss is 3.8251770162582397 and perplexity is 45.84091423528113
At time: 553.8769459724426 and batch: 1100, loss is 3.8465731573104858 and perplexity is 46.83230100713562
At time: 554.8613724708557 and batch: 1150, loss is 3.813190655708313 and perplexity is 45.29472843858503
At time: 555.8463032245636 and batch: 1200, loss is 3.8650020790100097 and perplexity is 47.703371608372684
At time: 556.83021068573 and batch: 1250, loss is 3.850519018173218 and perplexity is 47.017459815999324
At time: 557.8122563362122 and batch: 1300, loss is 3.8576199054718017 and perplexity is 47.35251368123033
At time: 558.7965044975281 and batch: 1350, loss is 3.7440423727035523 and perplexity is 42.268510352186716
At time: 559.7805345058441 and batch: 1400, loss is 3.7637707567214966 and perplexity is 43.110679762220585
At time: 560.7659430503845 and batch: 1450, loss is 3.6761969137191772 and perplexity is 39.49590176419443
At time: 561.7496068477631 and batch: 1500, loss is 3.6924694967269898 and perplexity is 40.143859781384634
At time: 562.7341766357422 and batch: 1550, loss is 3.694380178451538 and perplexity is 40.22063524400138
At time: 563.716367483139 and batch: 1600, loss is 3.787414131164551 and perplexity is 44.142106867309636
At time: 564.6992886066437 and batch: 1650, loss is 3.738487844467163 and perplexity is 42.03437956293059
At time: 565.6828446388245 and batch: 1700, loss is 3.755776014328003 and perplexity is 42.76739504798636
At time: 566.665910243988 and batch: 1750, loss is 3.7629519844055177 and perplexity is 43.07539637760864
At time: 567.648567199707 and batch: 1800, loss is 3.723782153129578 and perplexity is 41.42075787538929
At time: 568.6321625709534 and batch: 1850, loss is 3.7402000713348387 and perplexity is 42.10641360869995
At time: 569.6159963607788 and batch: 1900, loss is 3.8277310609817503 and perplexity is 45.95814362122662
At time: 570.6004157066345 and batch: 1950, loss is 3.759374294281006 and perplexity is 42.92156130857169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.301423680505088 and perplexity of 73.804793384382
finished 14 epochs...
Completing Train Step...
At time: 573.7272474765778 and batch: 50, loss is 3.884438643455505 and perplexity is 48.63963061939753
At time: 574.7032449245453 and batch: 100, loss is 3.8689454221725463 and perplexity is 47.89185375328252
At time: 575.6539704799652 and batch: 150, loss is 3.843679819107056 and perplexity is 46.696995158659085
At time: 576.6145944595337 and batch: 200, loss is 3.8389213466644287 and perplexity is 46.47531663789904
At time: 577.582106590271 and batch: 250, loss is 3.8248903608322142 and perplexity is 45.82777557170619
At time: 578.5490560531616 and batch: 300, loss is 3.8418746042251586 and perplexity is 46.6127730903962
At time: 579.5198247432709 and batch: 350, loss is 3.850877833366394 and perplexity is 47.03433342199792
At time: 580.4944138526917 and batch: 400, loss is 3.8194879484176636 and perplexity is 45.58086259143579
At time: 581.4689311981201 and batch: 450, loss is 3.8711173248291018 and perplexity is 47.995983236294066
At time: 582.4442551136017 and batch: 500, loss is 3.8736222696304323 and perplexity is 48.11636123215891
At time: 583.4293439388275 and batch: 550, loss is 3.8423241138458253 and perplexity is 46.6337306903148
At time: 584.4138362407684 and batch: 600, loss is 3.8243417596817015 and perplexity is 45.8026412962787
At time: 585.4001803398132 and batch: 650, loss is 3.857452392578125 and perplexity is 47.34458218897288
At time: 586.3846747875214 and batch: 700, loss is 3.8766696786880495 and perplexity is 48.26321511547545
At time: 587.3710253238678 and batch: 750, loss is 3.8424213695526124 and perplexity is 46.63826630730695
At time: 588.3608095645905 and batch: 800, loss is 3.8302212142944336 and perplexity is 46.07272905324564
At time: 589.3679332733154 and batch: 850, loss is 3.826285786628723 and perplexity is 45.89176947092031
At time: 590.3711624145508 and batch: 900, loss is 3.795383629798889 and perplexity is 44.495302855806074
At time: 591.3558087348938 and batch: 950, loss is 3.8840864276885987 and perplexity is 48.62250199126039
At time: 592.3405771255493 and batch: 1000, loss is 3.8538467121124267 and perplexity is 47.174180146091516
At time: 593.3248252868652 and batch: 1050, loss is 3.8177771949768067 and perplexity is 45.50295163613937
At time: 594.3101975917816 and batch: 1100, loss is 3.838916039466858 and perplexity is 46.475069984865996
At time: 595.3303837776184 and batch: 1150, loss is 3.80589816570282 and perplexity is 44.96561855791811
At time: 596.3146076202393 and batch: 1200, loss is 3.8579818916320803 and perplexity is 47.36965773860588
At time: 597.2936542034149 and batch: 1250, loss is 3.844133915901184 and perplexity is 46.71820492973612
At time: 598.270758152008 and batch: 1300, loss is 3.8509651803970337 and perplexity is 47.03844191078998
At time: 599.2551543712616 and batch: 1350, loss is 3.737792663574219 and perplexity is 42.00516822017178
At time: 600.2371916770935 and batch: 1400, loss is 3.758358335494995 and perplexity is 42.87797691497363
At time: 601.2212581634521 and batch: 1450, loss is 3.6711281728744507 and perplexity is 39.29621378456623
At time: 602.2054862976074 and batch: 1500, loss is 3.687502913475037 and perplexity is 39.944976254343565
At time: 603.2082860469818 and batch: 1550, loss is 3.6899466133117675 and perplexity is 40.04270915259256
At time: 604.1912894248962 and batch: 1600, loss is 3.783518452644348 and perplexity is 43.97047793238557
At time: 605.1753830909729 and batch: 1650, loss is 3.734770140647888 and perplexity is 41.87839831518442
At time: 606.1596376895905 and batch: 1700, loss is 3.752522840499878 and perplexity is 42.62849133917734
At time: 607.1438393592834 and batch: 1750, loss is 3.7599724388122557 and perplexity is 42.94724228544337
At time: 608.1279411315918 and batch: 1800, loss is 3.721152620315552 and perplexity is 41.31198370867054
At time: 609.111004114151 and batch: 1850, loss is 3.738060827255249 and perplexity is 42.016433991171795
At time: 610.0939161777496 and batch: 1900, loss is 3.825955810546875 and perplexity is 45.876628782811075
At time: 611.0768277645111 and batch: 1950, loss is 3.75718918800354 and perplexity is 42.82787552948639
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.301826512536337 and perplexity of 73.83453030830759
Annealing...
finished 15 epochs...
Completing Train Step...
At time: 614.223201751709 and batch: 50, loss is 3.884708309173584 and perplexity is 48.6527488290018
At time: 615.2112131118774 and batch: 100, loss is 3.8841073989868162 and perplexity is 48.623521678941785
At time: 616.1707408428192 and batch: 150, loss is 3.866063928604126 and perplexity is 47.754052317036
At time: 617.1312000751495 and batch: 200, loss is 3.865306897163391 and perplexity is 47.71791467839968
At time: 618.0916712284088 and batch: 250, loss is 3.85046923160553 and perplexity is 47.01511903632385
At time: 619.0754554271698 and batch: 300, loss is 3.867052044868469 and perplexity is 47.80126219340088
At time: 620.0375797748566 and batch: 350, loss is 3.8769309902191162 and perplexity is 48.275828498050856
At time: 621.0065696239471 and batch: 400, loss is 3.8500549030303954 and perplexity is 46.995643363986154
At time: 621.9772984981537 and batch: 450, loss is 3.905003538131714 and perplexity is 49.650255581010256
At time: 622.9515979290009 and batch: 500, loss is 3.9085489749908446 and perplexity is 49.826599851227805
At time: 623.9345088005066 and batch: 550, loss is 3.877610387802124 and perplexity is 48.30863812337818
At time: 624.9181272983551 and batch: 600, loss is 3.8552429771423338 and perplexity is 47.2400938099074
At time: 625.9029951095581 and batch: 650, loss is 3.8852061462402343 and perplexity is 48.67697600085502
At time: 626.8907246589661 and batch: 700, loss is 3.8985608959198 and perplexity is 49.33140497166315
At time: 627.8766651153564 and batch: 750, loss is 3.8610046434402467 and perplexity is 47.513061084358796
At time: 628.860524892807 and batch: 800, loss is 3.8451321744918823 and perplexity is 46.764865064714705
At time: 629.8452200889587 and batch: 850, loss is 3.840661244392395 and perplexity is 46.55624932260404
At time: 630.8293008804321 and batch: 900, loss is 3.8080202960968017 and perplexity is 45.06114278532829
At time: 631.8128883838654 and batch: 950, loss is 3.900175495147705 and perplexity is 49.41111975643926
At time: 632.7974996566772 and batch: 1000, loss is 3.8637182903289795 and perplexity is 47.642169853320695
At time: 633.7816212177277 and batch: 1050, loss is 3.8215255069732668 and perplexity is 45.67383095005369
At time: 634.7662489414215 and batch: 1100, loss is 3.8395663499832153 and perplexity is 46.5053030409973
At time: 635.7502944469452 and batch: 1150, loss is 3.8117647981643676 and perplexity is 45.230190630134594
At time: 636.73428606987 and batch: 1200, loss is 3.8630826902389526 and perplexity is 47.61189810725423
At time: 637.7184219360352 and batch: 1250, loss is 3.844591064453125 and perplexity is 46.739566971910314
At time: 638.7019436359406 and batch: 1300, loss is 3.8479492807388307 and perplexity is 46.89679239763417
At time: 639.6874959468842 and batch: 1350, loss is 3.731349759101868 and perplexity is 41.73540290325304
At time: 640.6711733341217 and batch: 1400, loss is 3.7541155433654785 and perplexity is 42.696439956104136
At time: 641.655827999115 and batch: 1450, loss is 3.66388023853302 and perplexity is 39.0124270832136
At time: 642.6415240764618 and batch: 1500, loss is 3.679486780166626 and perplexity is 39.62605197724267
At time: 643.6245918273926 and batch: 1550, loss is 3.682186622619629 and perplexity is 39.73318062477796
At time: 644.6099243164062 and batch: 1600, loss is 3.774267997741699 and perplexity is 43.56560651869831
At time: 645.5935490131378 and batch: 1650, loss is 3.723570189476013 and perplexity is 41.411979110638995
At time: 646.5765814781189 and batch: 1700, loss is 3.7387659215927123 and perplexity is 42.04606998771823
At time: 647.5598905086517 and batch: 1750, loss is 3.7457433462142946 and perplexity is 42.34046915128996
At time: 648.5435514450073 and batch: 1800, loss is 3.706407675743103 and perplexity is 40.70730969641836
At time: 649.5294780731201 and batch: 1850, loss is 3.726576929092407 and perplexity is 41.53668152872711
At time: 650.5136761665344 and batch: 1900, loss is 3.8233813571929933 and perplexity is 45.758673442386055
At time: 651.4979960918427 and batch: 1950, loss is 3.7604926729202273 and perplexity is 42.969590718428094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.284482592205668 and perplexity of 72.56499131276124
finished 16 epochs...
Completing Train Step...
At time: 654.6680536270142 and batch: 50, loss is 3.8965816926956176 and perplexity is 49.23386465378638
At time: 655.6141111850739 and batch: 100, loss is 3.8813903856277467 and perplexity is 48.49159023188875
At time: 656.5609402656555 and batch: 150, loss is 3.8529509496688843 and perplexity is 47.13194220761551
At time: 657.519992351532 and batch: 200, loss is 3.8494512271881103 and perplexity is 46.967281790854244
At time: 658.4929172992706 and batch: 250, loss is 3.8341891145706177 and perplexity is 46.255904217643966
At time: 659.4765725135803 and batch: 300, loss is 3.8475844717025756 and perplexity is 46.87968714426134
At time: 660.4609291553497 and batch: 350, loss is 3.8566339015960693 and perplexity is 47.305846929794654
At time: 661.4451713562012 and batch: 400, loss is 3.827791519165039 and perplexity is 45.96092225109188
At time: 662.4286119937897 and batch: 450, loss is 3.8835903549194337 and perplexity is 48.59838767377651
At time: 663.4238703250885 and batch: 500, loss is 3.887510585784912 and perplexity is 48.78927849672496
At time: 664.4078366756439 and batch: 550, loss is 3.856898226737976 and perplexity is 47.31835270722028
At time: 665.3916800022125 and batch: 600, loss is 3.837308416366577 and perplexity is 46.40041561289599
At time: 666.3752734661102 and batch: 650, loss is 3.868630356788635 and perplexity is 47.87676706476498
At time: 667.3588333129883 and batch: 700, loss is 3.884796552658081 and perplexity is 48.657042306521774
At time: 668.3660452365875 and batch: 750, loss is 3.8485417938232422 and perplexity is 46.92458759444242
At time: 669.350165605545 and batch: 800, loss is 3.8338116121292116 and perplexity is 46.238445796378016
At time: 670.3347425460815 and batch: 850, loss is 3.8292679738998414 and perplexity is 46.02883159256337
At time: 671.3196222782135 and batch: 900, loss is 3.797296905517578 and perplexity is 44.58051613060611
At time: 672.3041803836823 and batch: 950, loss is 3.8899777555465698 and perplexity is 48.90979853989523
At time: 673.288149356842 and batch: 1000, loss is 3.8552708625793457 and perplexity is 47.241411138934836
At time: 674.2722706794739 and batch: 1050, loss is 3.814257254600525 and perplexity is 45.34306551931657
At time: 675.2574427127838 and batch: 1100, loss is 3.834083290100098 and perplexity is 46.251009470068325
At time: 676.2435619831085 and batch: 1150, loss is 3.80631667137146 and perplexity is 44.98444086252437
At time: 677.2277402877808 and batch: 1200, loss is 3.8579384422302248 and perplexity is 47.36759960002381
At time: 678.2121772766113 and batch: 1250, loss is 3.8404112672805786 and perplexity is 46.54461278035657
At time: 679.1961259841919 and batch: 1300, loss is 3.8440172243118287 and perplexity is 46.712753626217854
At time: 680.1785526275635 and batch: 1350, loss is 3.7283135747909544 and perplexity is 41.60887870034448
At time: 681.1623423099518 and batch: 1400, loss is 3.752196626663208 and perplexity is 42.61458760338493
At time: 682.1467111110687 and batch: 1450, loss is 3.6635040426254273 and perplexity is 38.9977535280384
At time: 683.1302914619446 and batch: 1500, loss is 3.679935345649719 and perplexity is 39.6438308435857
At time: 684.1146154403687 and batch: 1550, loss is 3.6832270288467406 and perplexity is 39.77454078527636
At time: 685.0980212688446 and batch: 1600, loss is 3.776237978935242 and perplexity is 43.65151453503087
At time: 686.0808346271515 and batch: 1650, loss is 3.725986976623535 and perplexity is 41.51218408778388
At time: 687.065826177597 and batch: 1700, loss is 3.742147226333618 and perplexity is 42.18848119566557
At time: 688.0501375198364 and batch: 1750, loss is 3.749755525588989 and perplexity is 42.51068795417617
At time: 689.0343961715698 and batch: 1800, loss is 3.7109852743148806 and perplexity is 40.89407856947305
At time: 690.0199434757233 and batch: 1850, loss is 3.7313901948928834 and perplexity is 41.73709054140305
At time: 691.0042643547058 and batch: 1900, loss is 3.828101944923401 and perplexity is 45.975191919958505
At time: 691.9884014129639 and batch: 1950, loss is 3.765251784324646 and perplexity is 43.174575172693025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283414902797965 and perplexity of 72.48755578606846
finished 17 epochs...
Completing Train Step...
At time: 695.1347441673279 and batch: 50, loss is 3.894323296546936 and perplexity is 49.1228005440519
At time: 696.0804302692413 and batch: 100, loss is 3.8775439977645876 and perplexity is 48.305431017540954
At time: 697.0443897247314 and batch: 150, loss is 3.8478860378265383 and perplexity is 46.89382660168955
At time: 698.0188076496124 and batch: 200, loss is 3.8438058280944825 and perplexity is 46.702879770484095
At time: 698.9933631420135 and batch: 250, loss is 3.828058977127075 and perplexity is 45.97321650971586
At time: 699.9744431972504 and batch: 300, loss is 3.8408002948760984 and perplexity is 46.56272344169602
At time: 700.9583249092102 and batch: 350, loss is 3.849934115409851 and perplexity is 46.98996721485945
At time: 701.9424080848694 and batch: 400, loss is 3.820848889350891 and perplexity is 45.642937683794266
At time: 702.9260542392731 and batch: 450, loss is 3.8767460584640503 and perplexity is 48.2669015898193
At time: 703.9089124202728 and batch: 500, loss is 3.8805743408203126 and perplexity is 48.452035063065935
At time: 704.8937153816223 and batch: 550, loss is 3.849963870048523 and perplexity is 46.99136540515634
At time: 705.8800382614136 and batch: 600, loss is 3.8311383628845217 and perplexity is 46.11500397496742
At time: 706.8645663261414 and batch: 650, loss is 3.8628188276290896 and perplexity is 47.59933676486629
At time: 707.8496425151825 and batch: 700, loss is 3.879423017501831 and perplexity is 48.39628320563517
At time: 708.835330247879 and batch: 750, loss is 3.843671078681946 and perplexity is 46.69658700885375
At time: 709.8197321891785 and batch: 800, loss is 3.8291112756729127 and perplexity is 46.02161952133936
At time: 710.8041002750397 and batch: 850, loss is 3.824617552757263 and perplexity is 45.815275089666926
At time: 711.7883296012878 and batch: 900, loss is 3.7928826999664307 and perplexity is 44.38416226083328
At time: 712.7731649875641 and batch: 950, loss is 3.8858541536331175 and perplexity is 48.70852926343635
At time: 713.7575476169586 and batch: 1000, loss is 3.8516645765304567 and perplexity is 47.07135192241056
At time: 714.7409722805023 and batch: 1050, loss is 3.8109824752807615 and perplexity is 45.19481985446238
At time: 715.7242612838745 and batch: 1100, loss is 3.8312487173080445 and perplexity is 46.1200932504537
At time: 716.7502586841583 and batch: 1150, loss is 3.8037177896499634 and perplexity is 44.86768340654091
At time: 717.7353513240814 and batch: 1200, loss is 3.8555314493179322 and perplexity is 47.25372322830369
At time: 718.7256534099579 and batch: 1250, loss is 3.8383013820648193 and perplexity is 46.446512516518276
At time: 719.7176480293274 and batch: 1300, loss is 3.8419633722305297 and perplexity is 46.616910996942394
At time: 720.7092735767365 and batch: 1350, loss is 3.7266290378570557 and perplexity is 41.53884601028291
At time: 721.7018389701843 and batch: 1400, loss is 3.75090546131134 and perplexity is 42.55960063066339
At time: 722.6926846504211 and batch: 1450, loss is 3.662781915664673 and perplexity is 38.9696023643874
At time: 723.6857266426086 and batch: 1500, loss is 3.6795400524139406 and perplexity is 39.62816300231273
At time: 724.6773374080658 and batch: 1550, loss is 3.683035063743591 and perplexity is 39.76690619426276
At time: 725.6687848567963 and batch: 1600, loss is 3.776504063606262 and perplexity is 43.66313107933911
At time: 726.6608943939209 and batch: 1650, loss is 3.7262695741653444 and perplexity is 41.52391698672834
At time: 727.6535761356354 and batch: 1700, loss is 3.742942190170288 and perplexity is 42.22203284694791
At time: 728.6426348686218 and batch: 1750, loss is 3.750736074447632 and perplexity is 42.552392203915524
At time: 729.6339979171753 and batch: 1800, loss is 3.7122061252593994 and perplexity is 40.94403463216812
At time: 730.6264846324921 and batch: 1850, loss is 3.7326112508773805 and perplexity is 41.788084992788185
At time: 731.6186420917511 and batch: 1900, loss is 3.8292653656005857 and perplexity is 46.02871153575276
At time: 732.609795331955 and batch: 1950, loss is 3.766289496421814 and perplexity is 43.21940120587571
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283173317132994 and perplexity of 72.47004594685001
finished 18 epochs...
Completing Train Step...
At time: 735.7844874858856 and batch: 50, loss is 3.891224980354309 and perplexity is 48.97083811109683
At time: 736.7401082515717 and batch: 100, loss is 3.8738964939117433 and perplexity is 48.12955771605255
At time: 737.7058672904968 and batch: 150, loss is 3.843739700317383 and perplexity is 46.699791514971594
At time: 738.6750547885895 and batch: 200, loss is 3.839502201080322 and perplexity is 46.50231987251302
At time: 739.6500129699707 and batch: 250, loss is 3.8235394763946533 and perplexity is 45.765909339351836
At time: 740.6341977119446 and batch: 300, loss is 3.836068620681763 and perplexity is 46.34292422399762
At time: 741.6432731151581 and batch: 350, loss is 3.8452947998046874 and perplexity is 46.77247083395268
At time: 742.6275546550751 and batch: 400, loss is 3.816177258491516 and perplexity is 45.43020801173508
At time: 743.6119678020477 and batch: 450, loss is 3.8721940422058108 and perplexity is 48.04768917680382
At time: 744.5965609550476 and batch: 500, loss is 3.875979332923889 and perplexity is 48.229908307285456
At time: 745.580157995224 and batch: 550, loss is 3.8454034233093264 and perplexity is 46.77755169960101
At time: 746.5652892589569 and batch: 600, loss is 3.826938982009888 and perplexity is 45.92175555509187
At time: 747.5500645637512 and batch: 650, loss is 3.858798470497131 and perplexity is 47.408354597328156
At time: 748.5322244167328 and batch: 700, loss is 3.8756421184539795 and perplexity is 48.21364722621185
At time: 749.5200660228729 and batch: 750, loss is 3.8402465772628784 and perplexity is 46.53694797842944
At time: 750.5114693641663 and batch: 800, loss is 3.8257461738586427 and perplexity is 45.86701236629786
At time: 751.503363609314 and batch: 850, loss is 3.821316237449646 and perplexity is 45.664273809252876
At time: 752.4957864284515 and batch: 900, loss is 3.7897394847869874 and perplexity is 44.244872312108484
At time: 753.48770570755 and batch: 950, loss is 3.882900371551514 and perplexity is 48.56486716020216
At time: 754.480208158493 and batch: 1000, loss is 3.8489943504333497 and perplexity is 46.94582843271321
At time: 755.4712977409363 and batch: 1050, loss is 3.808492407798767 and perplexity is 45.082421700758424
At time: 756.4630031585693 and batch: 1100, loss is 3.828936047554016 and perplexity is 46.01355594602526
At time: 757.4545018672943 and batch: 1150, loss is 3.8016049003601076 and perplexity is 44.77298303973688
At time: 758.4465470314026 and batch: 1200, loss is 3.8535385084152223 and perplexity is 47.159643129654086
At time: 759.4382238388062 and batch: 1250, loss is 3.8364624309539797 and perplexity is 46.36117813765503
At time: 760.4300303459167 and batch: 1300, loss is 3.840119981765747 and perplexity is 46.531056983259724
At time: 761.4217948913574 and batch: 1350, loss is 3.725011959075928 and perplexity is 41.47172870541758
At time: 762.4141178131104 and batch: 1400, loss is 3.7495437335968016 and perplexity is 42.50168548424426
At time: 763.4057550430298 and batch: 1450, loss is 3.661739983558655 and perplexity is 38.92901983031923
At time: 764.3977890014648 and batch: 1500, loss is 3.6786546325683593 and perplexity is 39.593090969374835
At time: 765.3882365226746 and batch: 1550, loss is 3.6823014926910402 and perplexity is 39.73774504022607
At time: 766.3801426887512 and batch: 1600, loss is 3.7761045122146606 and perplexity is 43.64568889931037
At time: 767.3717322349548 and batch: 1650, loss is 3.7258196830749513 and perplexity is 41.50523994806945
At time: 768.3628611564636 and batch: 1700, loss is 3.7428374910354614 and perplexity is 42.217612468047164
At time: 769.3553121089935 and batch: 1750, loss is 3.7507409048080445 and perplexity is 42.55259774780271
At time: 770.352700471878 and batch: 1800, loss is 3.712347149848938 and perplexity is 40.94980915501146
At time: 771.3524913787842 and batch: 1850, loss is 3.73274329662323 and perplexity is 41.79360329596489
At time: 772.3527843952179 and batch: 1900, loss is 3.8294018840789796 and perplexity is 46.03499573435891
At time: 773.3525168895721 and batch: 1950, loss is 3.766292858123779 and perplexity is 43.219546496865895
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2831682072129365 and perplexity of 72.46967563165478
finished 19 epochs...
Completing Train Step...
At time: 776.5195240974426 and batch: 50, loss is 3.888140530586243 and perplexity is 48.82002273164345
At time: 777.5025599002838 and batch: 100, loss is 3.8705473518371583 and perplexity is 47.96863461685522
At time: 778.474828004837 and batch: 150, loss is 3.8400967168807982 and perplexity is 46.52997445616495
At time: 779.4620962142944 and batch: 200, loss is 3.8358218908309936 and perplexity is 46.33149145168072
At time: 780.453714132309 and batch: 250, loss is 3.8197402143478394 and perplexity is 45.592362540597335
At time: 781.445184469223 and batch: 300, loss is 3.8321809816360473 and perplexity is 46.16310941629823
At time: 782.4362466335297 and batch: 350, loss is 3.841493606567383 and perplexity is 46.5950171157335
At time: 783.4292228221893 and batch: 400, loss is 3.812387218475342 and perplexity is 45.25835158251726
At time: 784.4214236736298 and batch: 450, loss is 3.8685144662857054 and perplexity is 47.871218923645834
At time: 785.4129428863525 and batch: 500, loss is 3.8722880411148073 and perplexity is 48.052205819442655
At time: 786.4036254882812 and batch: 550, loss is 3.841749219894409 and perplexity is 46.60692894542764
At time: 787.3961176872253 and batch: 600, loss is 3.823499011993408 and perplexity is 45.76405748670028
At time: 788.3881142139435 and batch: 650, loss is 3.855479187965393 and perplexity is 47.25125374934498
At time: 789.3811547756195 and batch: 700, loss is 3.872500305175781 and perplexity is 48.062406658386095
At time: 790.3728573322296 and batch: 750, loss is 3.837382740974426 and perplexity is 46.403864433755004
At time: 791.3954019546509 and batch: 800, loss is 3.822910199165344 and perplexity is 45.737118954242895
At time: 792.3960447311401 and batch: 850, loss is 3.81854549407959 and perplexity is 45.53792494631648
At time: 793.3974590301514 and batch: 900, loss is 3.7870920181274412 and perplexity is 44.1278904089784
At time: 794.3968260288239 and batch: 950, loss is 3.880402989387512 and perplexity is 48.44373344870285
At time: 795.3958265781403 and batch: 1000, loss is 3.846682934761047 and perplexity is 46.83744241994454
At time: 796.3953764438629 and batch: 1050, loss is 3.806337718963623 and perplexity is 44.985387686653475
At time: 797.3948731422424 and batch: 1100, loss is 3.8268258810043334 and perplexity is 45.91656205206251
At time: 798.395355463028 and batch: 1150, loss is 3.799657564163208 and perplexity is 44.68587982636603
At time: 799.3962988853455 and batch: 1200, loss is 3.85167920589447 and perplexity is 47.07204055138953
At time: 800.3982660770416 and batch: 1250, loss is 3.8347040891647337 and perplexity is 46.27973096770282
At time: 801.398782491684 and batch: 1300, loss is 3.838338270187378 and perplexity is 46.44822587276547
At time: 802.398604631424 and batch: 1350, loss is 3.7233898973464967 and perplexity is 41.40451352975061
At time: 803.3988296985626 and batch: 1400, loss is 3.748125958442688 and perplexity is 42.44147034640637
At time: 804.3986241817474 and batch: 1450, loss is 3.6605439376831055 and perplexity is 38.8824867700966
At time: 805.3995952606201 and batch: 1500, loss is 3.6775301599502566 and perplexity is 39.548594644851555
At time: 806.3998239040375 and batch: 1550, loss is 3.681311192512512 and perplexity is 39.69841222308081
At time: 807.3995282649994 and batch: 1600, loss is 3.7753931283950806 and perplexity is 43.61465110363473
At time: 808.3999156951904 and batch: 1650, loss is 3.725044832229614 and perplexity is 41.473092034337284
At time: 809.3992483615875 and batch: 1700, loss is 3.7423235416412353 and perplexity is 42.19592032650253
At time: 810.3990490436554 and batch: 1750, loss is 3.7503129291534423 and perplexity is 42.53439016840484
At time: 811.3989100456238 and batch: 1800, loss is 3.7120061540603637 and perplexity is 40.93584782305967
At time: 812.3985323905945 and batch: 1850, loss is 3.7324052619934083 and perplexity is 41.77947799830021
At time: 813.3982408046722 and batch: 1900, loss is 3.8291001749038696 and perplexity is 46.02110864880561
At time: 814.3981449604034 and batch: 1950, loss is 3.765881700515747 and perplexity is 43.20178010415206
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.283259618005087 and perplexity of 72.47630044489628
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f05ce5c4b38>
ELAPSED
3367.6659576892853


RESULTS SO FAR:
[{'best_accuracy': -70.031277428607, 'params': {'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.29541346180265, 'params': {'tie_weights': True, 'rnn_dropout': 0.7288706260952753, 'num_layers': 2, 'dropout': 0.4475108336446092, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.10525313217852, 'params': {'tie_weights': True, 'rnn_dropout': 0.8506975178466405, 'num_layers': 2, 'dropout': 0.6098755685920833, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -72.46967563165478, 'params': {'tie_weights': True, 'rnn_dropout': 0.3930815480094526, 'num_layers': 2, 'dropout': 0.9281289718292313, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'rnn_dropout': 0.5551850193968754, 'num_layers': 2, 'dropout': 0.6113123772309402, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.5125846862792969 and batch: 50, loss is 7.59814637184143 and perplexity is 1994.4954136444835
At time: 2.474031686782837 and batch: 100, loss is 6.741785364151001 and perplexity is 847.0717181017328
At time: 3.4877572059631348 and batch: 150, loss is 6.474286823272705 and perplexity is 648.2567410921109
At time: 4.4537317752838135 and batch: 200, loss is 6.345919542312622 and perplexity is 570.1614363027019
At time: 5.4188714027404785 and batch: 250, loss is 6.260466928482056 and perplexity is 523.4633029790407
At time: 6.385998249053955 and batch: 300, loss is 6.185847625732422 and perplexity is 485.8245865541885
At time: 7.353325366973877 and batch: 350, loss is 6.131544361114502 and perplexity is 460.14624419263475
At time: 8.32572627067566 and batch: 400, loss is 6.075717859268188 and perplexity is 435.1617753325341
At time: 9.301714420318604 and batch: 450, loss is 5.989228115081787 and perplexity is 399.1064267698604
At time: 10.26745343208313 and batch: 500, loss is 5.961793565750122 and perplexity is 388.3059523011754
At time: 11.234259366989136 and batch: 550, loss is 5.9109061813354495 and perplexity is 369.04042147561546
At time: 12.205268859863281 and batch: 600, loss is 5.940363178253174 and perplexity is 380.0729387016177
At time: 13.175144672393799 and batch: 650, loss is 6.004578495025635 and perplexity is 405.28012513924494
At time: 14.145747423171997 and batch: 700, loss is 5.916606378555298 and perplexity is 371.1500315446864
At time: 15.116560220718384 and batch: 750, loss is 5.846069507598877 and perplexity is 345.87225704634824
At time: 16.087921857833862 and batch: 800, loss is 5.843820543289184 and perplexity is 345.09527671254517
At time: 17.05616283416748 and batch: 850, loss is 5.868485441207886 and perplexity is 353.7128554588591
At time: 18.02569341659546 and batch: 900, loss is 5.8473665904998775 and perplexity is 346.32117311463276
At time: 18.99613118171692 and batch: 950, loss is 5.877238569259643 and perplexity is 356.82253925187035
At time: 19.966901779174805 and batch: 1000, loss is 5.8509009742736815 and perplexity is 347.5473706993794
At time: 20.95931100845337 and batch: 1050, loss is 5.7531507778167725 and perplexity is 315.18216643589466
At time: 21.99163293838501 and batch: 1100, loss is 5.824229459762574 and perplexity is 338.40028155924017
At time: 23.06573748588562 and batch: 1150, loss is 5.7334737205505375 and perplexity is 309.0409277989665
At time: 24.14977216720581 and batch: 1200, loss is 5.8093461990356445 and perplexity is 333.401076456636
At time: 25.23272466659546 and batch: 1250, loss is 5.752472419738769 and perplexity is 314.9684325694938
At time: 26.316998720169067 and batch: 1300, loss is 5.763961238861084 and perplexity is 318.60791456360823
At time: 27.39932680130005 and batch: 1350, loss is 5.728687572479248 and perplexity is 307.56534615134785
At time: 28.482789754867554 and batch: 1400, loss is 5.741896905899048 and perplexity is 311.65503089566715
At time: 29.56496262550354 and batch: 1450, loss is 5.7164442920684815 and perplexity is 303.8226952869686
At time: 30.64850878715515 and batch: 1500, loss is 5.685054121017456 and perplexity is 294.43377967531336
At time: 31.732181787490845 and batch: 1550, loss is 5.663596353530884 and perplexity is 288.1831897743215
At time: 32.81621432304382 and batch: 1600, loss is 5.677354984283447 and perplexity is 292.17559792629714
At time: 33.89954614639282 and batch: 1650, loss is 5.673583335876465 and perplexity is 291.0756898349991
At time: 34.9827094078064 and batch: 1700, loss is 5.692417449951172 and perplexity is 296.6097939670599
At time: 36.065845251083374 and batch: 1750, loss is 5.693218212127686 and perplexity is 296.8474029927159
At time: 37.14680075645447 and batch: 1800, loss is 5.688141660690308 and perplexity is 295.3442605006299
At time: 38.229894399642944 and batch: 1850, loss is 5.664006128311157 and perplexity is 288.30130417608837
At time: 39.31177830696106 and batch: 1900, loss is 5.662844610214234 and perplexity is 287.96663139579294
At time: 40.394505977630615 and batch: 1950, loss is 5.598304414749146 and perplexity is 269.96826491788295
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 5.047865188953488 and perplexity of 155.68974128265407
finished 1 epochs...
Completing Train Step...
At time: 43.68582081794739 and batch: 50, loss is 5.290439043045044 and perplexity is 198.43052582985518
At time: 44.71862053871155 and batch: 100, loss is 5.191178216934204 and perplexity is 179.68013043767797
At time: 45.72547173500061 and batch: 150, loss is 5.100582437515259 and perplexity is 164.1174676382991
At time: 46.7318274974823 and batch: 200, loss is 5.0530063343048095 and perplexity is 156.49222594989234
At time: 47.73858594894409 and batch: 250, loss is 5.057354726791382 and perplexity is 157.1741972342358
At time: 48.7454891204834 and batch: 300, loss is 5.055054197311401 and perplexity is 156.81302895842734
At time: 49.752835512161255 and batch: 350, loss is 5.048003883361816 and perplexity is 155.71133607670797
At time: 50.759734869003296 and batch: 400, loss is 4.998607130050659 and perplexity is 148.20658277355432
At time: 51.76679539680481 and batch: 450, loss is 4.955523500442505 and perplexity is 141.95690142522804
At time: 52.773977279663086 and batch: 500, loss is 4.941344556808471 and perplexity is 139.95830499794926
At time: 53.78122138977051 and batch: 550, loss is 4.885984210968018 and perplexity is 132.42073115525042
At time: 54.81303024291992 and batch: 600, loss is 4.8792533016204835 and perplexity is 131.5324121691759
At time: 55.81970024108887 and batch: 650, loss is 4.9542337417602536 and perplexity is 141.7739292994175
At time: 56.82661175727844 and batch: 700, loss is 4.943248453140259 and perplexity is 140.22502492441524
At time: 57.834781646728516 and batch: 750, loss is 4.8944688892364505 and perplexity is 133.54905843314737
At time: 58.84184455871582 and batch: 800, loss is 4.874428186416626 and perplexity is 130.8992818192212
At time: 59.847537994384766 and batch: 850, loss is 4.858684577941895 and perplexity is 128.8545924045257
At time: 60.86009478569031 and batch: 900, loss is 4.864801845550537 and perplexity is 129.64524628396566
At time: 61.88310241699219 and batch: 950, loss is 4.9188691425323485 and perplexity is 136.84777032736267
At time: 62.890355348587036 and batch: 1000, loss is 4.892136259078979 and perplexity is 133.23790092073116
At time: 63.89751577377319 and batch: 1050, loss is 4.799170923233032 and perplexity is 121.40971780429055
At time: 64.90515732765198 and batch: 1100, loss is 4.870912170410156 and perplexity is 130.43984601424094
At time: 65.91188097000122 and batch: 1150, loss is 4.78808702468872 and perplexity is 120.07145509465334
At time: 66.91870427131653 and batch: 1200, loss is 4.868338537216187 and perplexity is 130.10457331625375
At time: 67.9244556427002 and batch: 1250, loss is 4.8258970260620115 and perplexity is 124.69827583190953
At time: 68.9322018623352 and batch: 1300, loss is 4.850265913009643 and perplexity is 127.7743621941903
At time: 69.93876910209656 and batch: 1350, loss is 4.750053281784058 and perplexity is 115.59044322814813
At time: 70.94577240943909 and batch: 1400, loss is 4.758918123245239 and perplexity is 116.61968949397574
At time: 71.95261836051941 and batch: 1450, loss is 4.703832807540894 and perplexity is 110.36938742128088
At time: 72.96011710166931 and batch: 1500, loss is 4.688172369003296 and perplexity is 108.65441804881158
At time: 73.96715521812439 and batch: 1550, loss is 4.684018936157226 and perplexity is 108.2040651227546
At time: 74.97519612312317 and batch: 1600, loss is 4.74534761428833 and perplexity is 115.04779080890093
At time: 75.98297452926636 and batch: 1650, loss is 4.712593240737915 and perplexity is 111.34051862098535
At time: 76.98946738243103 and batch: 1700, loss is 4.742855653762818 and perplexity is 114.76145317487476
At time: 77.9949860572815 and batch: 1750, loss is 4.741021509170532 and perplexity is 114.55115699188919
At time: 79.00163769721985 and batch: 1800, loss is 4.6950671672821045 and perplexity is 109.40615690923354
At time: 80.00896620750427 and batch: 1850, loss is 4.711392412185669 and perplexity is 111.20689799099382
At time: 81.0150237083435 and batch: 1900, loss is 4.788130922317505 and perplexity is 120.07672606250735
At time: 82.02150535583496 and batch: 1950, loss is 4.707713203430176 and perplexity is 110.79849635636567
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.5606334597565406 and perplexity of 95.6440472994306
finished 2 epochs...
Completing Train Step...
At time: 85.25821471214294 and batch: 50, loss is 4.653692207336426 and perplexity is 104.97184877822744
At time: 86.28831124305725 and batch: 100, loss is 4.599316139221191 and perplexity is 99.41630547775206
At time: 87.29506349563599 and batch: 150, loss is 4.552977695465088 and perplexity is 94.9146147619232
At time: 88.30086731910706 and batch: 200, loss is 4.54743724822998 and perplexity is 94.39019943619296
At time: 89.30728340148926 and batch: 250, loss is 4.546132106781005 and perplexity is 94.26708723142816
At time: 90.31366991996765 and batch: 300, loss is 4.567983779907227 and perplexity is 96.34965169989367
At time: 91.31991386413574 and batch: 350, loss is 4.583732032775879 and perplexity is 97.87900106153134
At time: 92.32516622543335 and batch: 400, loss is 4.540940818786621 and perplexity is 93.77898766210346
At time: 93.32992339134216 and batch: 450, loss is 4.541114101409912 and perplexity is 93.7952393391211
At time: 94.334969997406 and batch: 500, loss is 4.538381395339965 and perplexity is 93.53927441698391
At time: 95.34090542793274 and batch: 550, loss is 4.489522533416748 and perplexity is 89.0789035234852
At time: 96.34721446037292 and batch: 600, loss is 4.485742425918579 and perplexity is 88.74281132487503
At time: 97.3537278175354 and batch: 650, loss is 4.554854650497436 and perplexity is 95.09293252060074
At time: 98.36020541191101 and batch: 700, loss is 4.565817012786865 and perplexity is 96.14111045427882
At time: 99.36635875701904 and batch: 750, loss is 4.529004306793213 and perplexity is 92.6662479783627
At time: 100.37275624275208 and batch: 800, loss is 4.501010818481445 and perplexity is 90.10816828366815
At time: 101.37929964065552 and batch: 850, loss is 4.493074760437012 and perplexity is 89.3958946904866
At time: 102.38590669631958 and batch: 900, loss is 4.490267362594604 and perplexity is 89.1452768052709
At time: 103.39198851585388 and batch: 950, loss is 4.564248027801514 and perplexity is 95.99038476958947
At time: 104.39663004875183 and batch: 1000, loss is 4.551013193130493 and perplexity is 94.72833781029719
At time: 105.4440393447876 and batch: 1050, loss is 4.470839729309082 and perplexity is 87.43010982231557
At time: 106.45059394836426 and batch: 1100, loss is 4.525466585159302 and perplexity is 92.33899978596673
At time: 107.45643472671509 and batch: 1150, loss is 4.4640423202514645 and perplexity is 86.83782687715193
At time: 108.46258592605591 and batch: 1200, loss is 4.552282257080078 and perplexity is 94.8486304421931
At time: 109.46848702430725 and batch: 1250, loss is 4.5220415401458744 and perplexity is 92.02327554871206
At time: 110.47425198554993 and batch: 1300, loss is 4.53279128074646 and perplexity is 93.01783795666272
At time: 111.47937989234924 and batch: 1350, loss is 4.421740369796753 and perplexity is 83.24102954127143
At time: 112.4837441444397 and batch: 1400, loss is 4.440611381530761 and perplexity is 84.82678735456963
At time: 113.48798704147339 and batch: 1450, loss is 4.384569034576416 and perplexity is 80.2036507633468
At time: 114.49185848236084 and batch: 1500, loss is 4.37732841014862 and perplexity is 79.62502358941082
At time: 115.49788188934326 and batch: 1550, loss is 4.384507150650024 and perplexity is 80.19868760009817
At time: 116.5023787021637 and batch: 1600, loss is 4.459337530136108 and perplexity is 86.4302327019873
At time: 117.50514006614685 and batch: 1650, loss is 4.421989679336548 and perplexity is 83.26178491118677
At time: 118.50702571868896 and batch: 1700, loss is 4.450663452148437 and perplexity is 85.68377223148387
At time: 119.51004791259766 and batch: 1750, loss is 4.444048929214477 and perplexity is 85.11888524353135
At time: 120.51264023780823 and batch: 1800, loss is 4.403585662841797 and perplexity is 81.74344825057233
At time: 121.51504111289978 and batch: 1850, loss is 4.437205905914307 and perplexity is 84.5384031200565
At time: 122.54160237312317 and batch: 1900, loss is 4.5154579067230225 and perplexity is 91.41941800562431
At time: 123.55803632736206 and batch: 1950, loss is 4.446078872680664 and perplexity is 85.29184726064551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.436804483103198 and perplexity of 84.50447428698877
finished 3 epochs...
Completing Train Step...
At time: 126.8470823764801 and batch: 50, loss is 4.403044128417969 and perplexity is 81.69919334328162
At time: 127.85885381698608 and batch: 100, loss is 4.362640380859375 and perplexity is 78.46403609232497
At time: 128.84510612487793 and batch: 150, loss is 4.323830633163452 and perplexity is 75.47720069972063
At time: 129.89249181747437 and batch: 200, loss is 4.326281995773315 and perplexity is 75.66244965082299
At time: 130.8942506313324 and batch: 250, loss is 4.3214593029022215 and perplexity is 75.29843137399573
At time: 131.90155148506165 and batch: 300, loss is 4.338886232376098 and perplexity is 76.62215252383288
At time: 132.90464639663696 and batch: 350, loss is 4.360869808197021 and perplexity is 78.3252327320211
At time: 133.90916657447815 and batch: 400, loss is 4.316995115280151 and perplexity is 74.96303424356348
At time: 134.92778396606445 and batch: 450, loss is 4.3347211265563965 and perplexity is 76.30367685328456
At time: 135.93213438987732 and batch: 500, loss is 4.334990921020508 and perplexity is 76.32426594017687
At time: 136.94380164146423 and batch: 550, loss is 4.290902490615845 and perplexity is 73.03234977687066
At time: 137.96930122375488 and batch: 600, loss is 4.288090138435364 and perplexity is 72.82724563645455
At time: 138.98581194877625 and batch: 650, loss is 4.354042501449585 and perplexity is 77.79230364734092
At time: 139.99339818954468 and batch: 700, loss is 4.375477895736695 and perplexity is 79.47781258575976
At time: 141.0145139694214 and batch: 750, loss is 4.3385966110229495 and perplexity is 76.59996432558084
At time: 142.0264856815338 and batch: 800, loss is 4.312291173934937 and perplexity is 74.61124058447129
At time: 143.03497314453125 and batch: 850, loss is 4.301798667907715 and perplexity is 73.83247444185419
At time: 144.0491383075714 and batch: 900, loss is 4.296623783111572 and perplexity is 73.45138678520588
At time: 145.07673597335815 and batch: 950, loss is 4.382107248306275 and perplexity is 80.00644935054073
At time: 146.09347796440125 and batch: 1000, loss is 4.367086668014526 and perplexity is 78.81368647511312
At time: 147.1019160747528 and batch: 1050, loss is 4.295328674316406 and perplexity is 73.35632082183373
At time: 148.10590314865112 and batch: 1100, loss is 4.343486719131469 and perplexity is 76.97546380047396
At time: 149.11235785484314 and batch: 1150, loss is 4.291821918487549 and perplexity is 73.0995286331155
At time: 150.11762738227844 and batch: 1200, loss is 4.37385552406311 and perplexity is 79.34897457377217
At time: 151.12378120422363 and batch: 1250, loss is 4.3497745800018315 and perplexity is 77.46099969864436
At time: 152.1291003227234 and batch: 1300, loss is 4.355381593704224 and perplexity is 77.8965444971061
At time: 153.13392972946167 and batch: 1350, loss is 4.241693167686463 and perplexity is 69.52547051664845
At time: 154.14054346084595 and batch: 1400, loss is 4.265526309013366 and perplexity is 71.20238457032518
At time: 155.14553332328796 and batch: 1450, loss is 4.203310775756836 and perplexity is 66.90748041503514
At time: 156.15039706230164 and batch: 1500, loss is 4.201071982383728 and perplexity is 66.75785594290454
At time: 157.15810990333557 and batch: 1550, loss is 4.21325270652771 and perplexity is 67.57598757294465
At time: 158.1639850139618 and batch: 1600, loss is 4.295346841812134 and perplexity is 73.3576535345849
At time: 159.16957426071167 and batch: 1650, loss is 4.2516756439208985 and perplexity is 70.22298253008091
At time: 160.17476391792297 and batch: 1700, loss is 4.281749877929688 and perplexity is 72.36696262620919
At time: 161.18022847175598 and batch: 1750, loss is 4.279434728622436 and perplexity is 72.19961609366862
At time: 162.18558859825134 and batch: 1800, loss is 4.232972555160522 and perplexity is 68.9218018336277
At time: 163.1920292377472 and batch: 1850, loss is 4.273260593414307 and perplexity is 71.75521919689253
At time: 164.19840288162231 and batch: 1900, loss is 4.352275800704956 and perplexity is 77.6549892589927
At time: 165.20309948921204 and batch: 1950, loss is 4.286254730224609 and perplexity is 72.69370050425255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.398381574763808 and perplexity of 81.31915313822739
finished 4 epochs...
Completing Train Step...
At time: 168.45685505867004 and batch: 50, loss is 4.249711031913757 and perplexity is 70.0851570465554
At time: 169.40553784370422 and batch: 100, loss is 4.216660327911377 and perplexity is 67.8066537414992
At time: 170.37356114387512 and batch: 150, loss is 4.184214668273926 and perplexity is 65.64192997906815
At time: 171.34438252449036 and batch: 200, loss is 4.189333081245422 and perplexity is 65.97877380245444
At time: 172.32069182395935 and batch: 250, loss is 4.1775302934646605 and perplexity is 65.20461792301906
At time: 173.29028463363647 and batch: 300, loss is 4.1945483589172365 and perplexity is 66.32377027250725
At time: 174.26285076141357 and batch: 350, loss is 4.213838610649109 and perplexity is 67.61559222370234
At time: 175.23578143119812 and batch: 400, loss is 4.168240571022034 and perplexity is 64.60168997318762
At time: 176.21399402618408 and batch: 450, loss is 4.200271625518798 and perplexity is 66.70444721048649
At time: 177.20258903503418 and batch: 500, loss is 4.206554946899414 and perplexity is 67.12489220206115
At time: 178.19213223457336 and batch: 550, loss is 4.158709793090821 and perplexity is 63.988910383682565
At time: 179.18221259117126 and batch: 600, loss is 4.160023217201233 and perplexity is 64.07301017863877
At time: 180.2136631011963 and batch: 650, loss is 4.216100568771362 and perplexity is 67.76870896827117
At time: 181.2029151916504 and batch: 700, loss is 4.245466084480285 and perplexity is 69.78827979898132
At time: 182.20929431915283 and batch: 750, loss is 4.211484265327454 and perplexity is 67.45658901815153
At time: 183.19880032539368 and batch: 800, loss is 4.188616061210633 and perplexity is 65.93148265614302
At time: 184.18917083740234 and batch: 850, loss is 4.177395691871643 and perplexity is 65.19584186822327
At time: 185.17811179161072 and batch: 900, loss is 4.165432543754577 and perplexity is 64.42054112070788
At time: 186.16819047927856 and batch: 950, loss is 4.261900329589844 and perplexity is 70.944673698486
At time: 187.18264722824097 and batch: 1000, loss is 4.243995170593262 and perplexity is 69.68570270860144
At time: 188.1815116405487 and batch: 1050, loss is 4.176108555793762 and perplexity is 65.11197993046765
At time: 189.1796178817749 and batch: 1100, loss is 4.2185442256927494 and perplexity is 67.93451494695002
At time: 190.17888879776 and batch: 1150, loss is 4.172887134552002 and perplexity is 64.90256430430162
At time: 191.1759214401245 and batch: 1200, loss is 4.2516579341888425 and perplexity is 70.22173891088825
At time: 192.1723358631134 and batch: 1250, loss is 4.2317694616317745 and perplexity is 68.83893231973565
At time: 193.16857600212097 and batch: 1300, loss is 4.2312069463729856 and perplexity is 68.80022025899028
At time: 194.16602063179016 and batch: 1350, loss is 4.11792489528656 and perplexity is 61.43163283790218
At time: 195.1779339313507 and batch: 1400, loss is 4.148941535949707 and perplexity is 63.36689321072649
At time: 196.17333841323853 and batch: 1450, loss is 4.086254005432129 and perplexity is 59.516525020726526
At time: 197.1691358089447 and batch: 1500, loss is 4.082477269172668 and perplexity is 59.292170732808195
At time: 198.16390872001648 and batch: 1550, loss is 4.096410140991211 and perplexity is 60.12406281279201
At time: 199.15865182876587 and batch: 1600, loss is 4.1856590843200685 and perplexity is 65.73681274462777
At time: 200.15367150306702 and batch: 1650, loss is 4.134776496887207 and perplexity is 62.47562601301917
At time: 201.14921307563782 and batch: 1700, loss is 4.1676582336425785 and perplexity is 64.56408094597423
At time: 202.14376139640808 and batch: 1750, loss is 4.163286981582641 and perplexity is 64.28247101654632
At time: 203.13997864723206 and batch: 1800, loss is 4.119609971046447 and perplexity is 61.53523705925346
At time: 204.1341061592102 and batch: 1850, loss is 4.1620281457901 and perplexity is 64.20160085300529
At time: 205.12877655029297 and batch: 1900, loss is 4.239552202224732 and perplexity is 69.37677811500708
At time: 206.12556385993958 and batch: 1950, loss is 4.17019365310669 and perplexity is 64.72798566929691
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.380015102652616 and perplexity of 79.8392391802738
finished 5 epochs...
Completing Train Step...
At time: 209.34411668777466 and batch: 50, loss is 4.139691834449768 and perplexity is 62.783470764933924
At time: 210.31623697280884 and batch: 100, loss is 4.109891147613525 and perplexity is 60.94008373502786
At time: 211.29122638702393 and batch: 150, loss is 4.079529004096985 and perplexity is 59.11761913520218
At time: 212.2676510810852 and batch: 200, loss is 4.0867393207550045 and perplexity is 59.5454163124096
At time: 213.24919962882996 and batch: 250, loss is 4.071699118614196 and perplexity is 58.65654239201177
At time: 214.23121643066406 and batch: 300, loss is 4.087490401268005 and perplexity is 59.59015651388387
At time: 215.21926593780518 and batch: 350, loss is 4.109523773193359 and perplexity is 60.91770001895496
At time: 216.20384216308594 and batch: 400, loss is 4.065062179565429 and perplexity is 58.26853152188079
At time: 217.2028510570526 and batch: 450, loss is 4.10128574848175 and perplexity is 60.417919927659234
At time: 218.20270705223083 and batch: 500, loss is 4.111186060905457 and perplexity is 61.019046973707646
At time: 219.20171523094177 and batch: 550, loss is 4.0642303943634035 and perplexity is 58.22008477105555
At time: 220.2003812789917 and batch: 600, loss is 4.067578682899475 and perplexity is 58.4153491317475
At time: 221.20104241371155 and batch: 650, loss is 4.124273743629455 and perplexity is 61.82289367185491
At time: 222.21063923835754 and batch: 700, loss is 4.148518209457397 and perplexity is 63.3400740031361
At time: 223.2127764225006 and batch: 750, loss is 4.115572490692139 and perplexity is 61.287290624777654
At time: 224.21289253234863 and batch: 800, loss is 4.093179421424866 and perplexity is 59.93013226294543
At time: 225.21273517608643 and batch: 850, loss is 4.086072287559509 and perplexity is 59.50571078701358
At time: 226.21317768096924 and batch: 900, loss is 4.068862643241882 and perplexity is 58.49040029446834
At time: 227.21289038658142 and batch: 950, loss is 4.169054193496704 and perplexity is 64.65427274841458
At time: 228.2133674621582 and batch: 1000, loss is 4.150194926261902 and perplexity is 63.44636645588421
At time: 229.25554513931274 and batch: 1050, loss is 4.085183115005493 and perplexity is 59.45282345863947
At time: 230.25453662872314 and batch: 1100, loss is 4.120720849037171 and perplexity is 61.60363318259689
At time: 231.2532193660736 and batch: 1150, loss is 4.081179127693177 and perplexity is 59.21525104369226
At time: 232.25216507911682 and batch: 1200, loss is 4.162396273612976 and perplexity is 64.2252395993256
At time: 233.2569396495819 and batch: 1250, loss is 4.144585237503052 and perplexity is 63.09144850753004
At time: 234.26767897605896 and batch: 1300, loss is 4.142104730606079 and perplexity is 62.93514367212242
At time: 235.26729083061218 and batch: 1350, loss is 4.030780019760132 and perplexity is 56.30481298951099
At time: 236.26679921150208 and batch: 1400, loss is 4.061235165596008 and perplexity is 58.0459631954613
At time: 237.26669311523438 and batch: 1450, loss is 3.996873722076416 and perplexity is 54.42772757481525
At time: 238.26527404785156 and batch: 1500, loss is 3.9987296628952027 and perplexity is 54.528836012711196
At time: 239.26393270492554 and batch: 1550, loss is 4.009822583198547 and perplexity is 55.13708744994832
At time: 240.26376724243164 and batch: 1600, loss is 4.099449014663696 and perplexity is 60.30705014122379
At time: 241.26289343833923 and batch: 1650, loss is 4.050553145408631 and perplexity is 57.429214967842704
At time: 242.2685227394104 and batch: 1700, loss is 4.080685219764709 and perplexity is 59.1860113831601
At time: 243.2703366279602 and batch: 1750, loss is 4.076231722831726 and perplexity is 58.923012729523144
At time: 244.26993894577026 and batch: 1800, loss is 4.03270688533783 and perplexity is 56.41340938724969
At time: 245.28782677650452 and batch: 1850, loss is 4.076744313240051 and perplexity is 58.95322384297993
At time: 246.29744148254395 and batch: 1900, loss is 4.152875661849976 and perplexity is 63.616677565910486
At time: 247.30757999420166 and batch: 1950, loss is 4.079558358192444 and perplexity is 59.119354504907584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.37191162109375 and perplexity of 79.19487768970234
finished 6 epochs...
Completing Train Step...
At time: 250.51057648658752 and batch: 50, loss is 4.060983014106751 and perplexity is 58.03132866453311
At time: 251.47756934165955 and batch: 100, loss is 4.03166895866394 and perplexity is 56.35488678122234
At time: 252.44432044029236 and batch: 150, loss is 3.999797830581665 and perplexity is 54.5871130726154
At time: 253.41397738456726 and batch: 200, loss is 4.005758690834045 and perplexity is 54.91347094571792
At time: 254.41388845443726 and batch: 250, loss is 3.9906738328933717 and perplexity is 54.09132560041604
At time: 255.38740921020508 and batch: 300, loss is 4.011158814430237 and perplexity is 55.21081259417373
At time: 256.36135601997375 and batch: 350, loss is 4.029402585029602 and perplexity is 56.22731017439186
At time: 257.34211921691895 and batch: 400, loss is 3.9810398864746093 and perplexity is 53.57271481327197
At time: 258.3311631679535 and batch: 450, loss is 4.0214501476287845 and perplexity is 55.781939249363475
At time: 259.3213255405426 and batch: 500, loss is 4.038761668205261 and perplexity is 56.75601649103677
At time: 260.31713366508484 and batch: 550, loss is 3.991436023712158 and perplexity is 54.132569227925124
At time: 261.3164093494415 and batch: 600, loss is 3.9922020387649537 and perplexity is 54.17405147678532
At time: 262.316370010376 and batch: 650, loss is 4.051496047973632 and perplexity is 57.48339065912724
At time: 263.3154890537262 and batch: 700, loss is 4.077560515403747 and perplexity is 59.00136123408644
At time: 264.3123335838318 and batch: 750, loss is 4.039755601882934 and perplexity is 56.812456251280594
At time: 265.31032371520996 and batch: 800, loss is 4.02129753112793 and perplexity is 55.77342665458208
At time: 266.3091926574707 and batch: 850, loss is 4.012109179496765 and perplexity is 55.26330796268891
At time: 267.30827951431274 and batch: 900, loss is 3.9956294298171997 and perplexity is 54.3600456914614
At time: 268.3064398765564 and batch: 950, loss is 4.095665783882141 and perplexity is 60.079325691473876
At time: 269.30508041381836 and batch: 1000, loss is 4.076007409095764 and perplexity is 58.90979697069719
At time: 270.3032248020172 and batch: 1050, loss is 4.015564451217651 and perplexity is 55.45458797980589
At time: 271.3019597530365 and batch: 1100, loss is 4.0456975030899045 and perplexity is 57.151035158700005
At time: 272.2988474369049 and batch: 1150, loss is 4.006529269218444 and perplexity is 54.955802387193245
At time: 273.31097745895386 and batch: 1200, loss is 4.087267489433288 and perplexity is 59.57687464316237
At time: 274.3231964111328 and batch: 1250, loss is 4.070651164054871 and perplexity is 58.59510519829399
At time: 275.322292804718 and batch: 1300, loss is 4.064923458099365 and perplexity is 58.2604489863862
At time: 276.3207633495331 and batch: 1350, loss is 3.9610111570358275 and perplexity is 52.51039536955043
At time: 277.3183944225311 and batch: 1400, loss is 3.9913580656051635 and perplexity is 54.12834931979152
At time: 278.3157489299774 and batch: 1450, loss is 3.9233194065093993 and perplexity is 50.56802231765579
At time: 279.31385707855225 and batch: 1500, loss is 3.930374331474304 and perplexity is 50.92603732029579
At time: 280.31224966049194 and batch: 1550, loss is 3.9405623865127564 and perplexity is 51.44752656122901
At time: 281.31122612953186 and batch: 1600, loss is 4.029503779411316 and perplexity is 56.233000350182465
At time: 282.3102469444275 and batch: 1650, loss is 3.985056538581848 and perplexity is 53.788330507848066
At time: 283.3226375579834 and batch: 1700, loss is 4.011932983398437 and perplexity is 55.25357164122133
At time: 284.3212237358093 and batch: 1750, loss is 4.009341444969177 and perplexity is 55.11056527024897
At time: 285.32073736190796 and batch: 1800, loss is 3.9660210466384886 and perplexity is 52.77412673423913
At time: 286.3217749595642 and batch: 1850, loss is 4.009535326957702 and perplexity is 55.12125125210855
At time: 287.3239209651947 and batch: 1900, loss is 4.084528818130493 and perplexity is 59.41393638527315
At time: 288.322705745697 and batch: 1950, loss is 4.0120479154586794 and perplexity is 55.259922412992445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.371989121547965 and perplexity of 79.20101556653584
Annealing...
finished 7 epochs...
Completing Train Step...
At time: 291.53052854537964 and batch: 50, loss is 4.020466446876526 and perplexity is 55.727093494089495
At time: 292.5437695980072 and batch: 100, loss is 4.020701661109924 and perplexity is 55.74020284135731
At time: 293.532870054245 and batch: 150, loss is 3.9874226093292235 and perplexity is 53.91574818338681
At time: 294.50391030311584 and batch: 200, loss is 3.991407284736633 and perplexity is 54.131013535697576
At time: 295.47404408454895 and batch: 250, loss is 3.979271388053894 and perplexity is 53.47805527902102
At time: 296.4443974494934 and batch: 300, loss is 3.989651093482971 and perplexity is 54.03603254997427
At time: 297.42266297340393 and batch: 350, loss is 3.998698983192444 and perplexity is 54.527163109892754
At time: 298.40355038642883 and batch: 400, loss is 3.9472305297851564 and perplexity is 51.79173237077634
At time: 299.3839519023895 and batch: 450, loss is 3.980046482086182 and perplexity is 53.51952186870325
At time: 300.3706111907959 and batch: 500, loss is 3.9970469999313356 and perplexity is 54.43715951184688
At time: 301.3583462238312 and batch: 550, loss is 3.9499139404296875 and perplexity is 51.930897491795236
At time: 302.3495421409607 and batch: 600, loss is 3.9295464038848875 and perplexity is 50.883891698147785
At time: 303.3370416164398 and batch: 650, loss is 3.980072054862976 and perplexity is 53.520890528990286
At time: 304.3663561344147 and batch: 700, loss is 4.003541808128357 and perplexity is 54.79186906002948
At time: 305.3535485267639 and batch: 750, loss is 3.955966601371765 and perplexity is 52.246170765350634
At time: 306.34046721458435 and batch: 800, loss is 3.925671501159668 and perplexity is 50.68710308213866
At time: 307.3444354534149 and batch: 850, loss is 3.9249169921875 and perplexity is 50.648873632135114
At time: 308.33346462249756 and batch: 900, loss is 3.897415041923523 and perplexity is 49.27491075737633
At time: 309.3199589252472 and batch: 950, loss is 3.9898009061813355 and perplexity is 54.04412844023794
At time: 310.3091914653778 and batch: 1000, loss is 3.958861083984375 and perplexity is 52.39761546950388
At time: 311.29741740226746 and batch: 1050, loss is 3.9000007247924806 and perplexity is 49.40248491206678
At time: 312.2854127883911 and batch: 1100, loss is 3.9154266929626464 and perplexity is 50.170474332825826
At time: 313.2725989818573 and batch: 1150, loss is 3.8827481126785277 and perplexity is 48.557473291167
At time: 314.26898527145386 and batch: 1200, loss is 3.9459475803375246 and perplexity is 51.72532880165865
At time: 315.26650619506836 and batch: 1250, loss is 3.9241559171676634 and perplexity is 50.610340704715064
At time: 316.26256918907166 and batch: 1300, loss is 3.9205753421783447 and perplexity is 50.42945062309655
At time: 317.2749581336975 and batch: 1350, loss is 3.814717593193054 and perplexity is 45.363943487377206
At time: 318.2742211818695 and batch: 1400, loss is 3.8327896547317506 and perplexity is 46.191216212071375
At time: 319.27260422706604 and batch: 1450, loss is 3.7501451539993287 and perplexity is 42.52725455314542
At time: 320.27073979377747 and batch: 1500, loss is 3.761670541763306 and perplexity is 43.02023307970992
At time: 321.2689366340637 and batch: 1550, loss is 3.7619618797302246 and perplexity is 43.03276833286065
At time: 322.26676893234253 and batch: 1600, loss is 3.8507901096343993 and perplexity is 47.03020757570821
At time: 323.2636992931366 and batch: 1650, loss is 3.7944591569900514 and perplexity is 44.45418716629166
At time: 324.25973296165466 and batch: 1700, loss is 3.8115377283096312 and perplexity is 45.219921383280834
At time: 325.25706005096436 and batch: 1750, loss is 3.803580851554871 and perplexity is 44.861539732105136
At time: 326.2538437843323 and batch: 1800, loss is 3.7531108331680296 and perplexity is 42.65356395007245
At time: 327.251770734787 and batch: 1850, loss is 3.782050275802612 and perplexity is 43.90596886191453
At time: 328.2496337890625 and batch: 1900, loss is 3.845517482757568 and perplexity is 46.782887425627166
At time: 329.24844217300415 and batch: 1950, loss is 3.7755020523071288 and perplexity is 43.61940204079619
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.298268872638081 and perplexity of 73.57232033830084
finished 8 epochs...
Completing Train Step...
At time: 332.4625356197357 and batch: 50, loss is 3.9336610317230223 and perplexity is 51.093691303094054
At time: 333.4860084056854 and batch: 100, loss is 3.9200746536254885 and perplexity is 50.404207494442865
At time: 334.4626729488373 and batch: 150, loss is 3.88523992061615 and perplexity is 48.67862006310434
At time: 335.44964599609375 and batch: 200, loss is 3.887936382293701 and perplexity is 48.81005722461616
At time: 336.4248962402344 and batch: 250, loss is 3.8753146743774414 and perplexity is 48.19786253746177
At time: 337.41331005096436 and batch: 300, loss is 3.88489661693573 and perplexity is 48.66191138191889
At time: 338.4021019935608 and batch: 350, loss is 3.9008452129364013 and perplexity is 49.444222345758746
At time: 339.39116978645325 and batch: 400, loss is 3.8493528366088867 and perplexity is 46.96266088012506
At time: 340.377952337265 and batch: 450, loss is 3.8902084016799927 and perplexity is 48.92108069685787
At time: 341.3657555580139 and batch: 500, loss is 3.9101180124282835 and perplexity is 49.9048410173824
At time: 342.3528895378113 and batch: 550, loss is 3.8638534688949586 and perplexity is 47.648610488829725
At time: 343.3408010005951 and batch: 600, loss is 3.850186171531677 and perplexity is 47.00181281657586
At time: 344.32885241508484 and batch: 650, loss is 3.902905831336975 and perplexity is 49.54621306601492
At time: 345.3176989555359 and batch: 700, loss is 3.927264108657837 and perplexity is 50.76789205805607
At time: 346.3059096336365 and batch: 750, loss is 3.883073854446411 and perplexity is 48.57329306480144
At time: 347.2976186275482 and batch: 800, loss is 3.8570829153060915 and perplexity is 47.3270926730884
At time: 348.29408144950867 and batch: 850, loss is 3.8575476217269897 and perplexity is 47.349090987919226
At time: 349.29138135910034 and batch: 900, loss is 3.830932517051697 and perplexity is 46.1055123705056
At time: 350.2884180545807 and batch: 950, loss is 3.926114764213562 and perplexity is 50.709575782534834
At time: 351.28555130958557 and batch: 1000, loss is 3.89813045501709 and perplexity is 49.31017528656538
At time: 352.28237223625183 and batch: 1050, loss is 3.843082809448242 and perplexity is 46.6691249217399
At time: 353.2785577774048 and batch: 1100, loss is 3.858881711959839 and perplexity is 47.41230110236354
At time: 354.2987666130066 and batch: 1150, loss is 3.8278919792175294 and perplexity is 45.965539719685424
At time: 355.2964861392975 and batch: 1200, loss is 3.894635195732117 and perplexity is 49.13812429512391
At time: 356.29558539390564 and batch: 1250, loss is 3.8774511337280275 and perplexity is 48.30094538850892
At time: 357.2947347164154 and batch: 1300, loss is 3.8767603921890257 and perplexity is 48.26759343927048
At time: 358.295291185379 and batch: 1350, loss is 3.772626657485962 and perplexity is 43.4941591856854
At time: 359.2938086986542 and batch: 1400, loss is 3.793566789627075 and perplexity is 44.41453539512135
At time: 360.29220604896545 and batch: 1450, loss is 3.714952301979065 and perplexity is 41.05662871775191
At time: 361.302268743515 and batch: 1500, loss is 3.727163152694702 and perplexity is 41.561038450403906
At time: 362.31109166145325 and batch: 1550, loss is 3.7294104719161987 and perplexity is 41.65454440048445
At time: 363.32621240615845 and batch: 1600, loss is 3.8234508228302 and perplexity is 45.76185220820069
At time: 364.3251805305481 and batch: 1650, loss is 3.770003137588501 and perplexity is 43.38020094485775
At time: 365.32478499412537 and batch: 1700, loss is 3.790981402397156 and perplexity is 44.29985493306825
At time: 366.32390689849854 and batch: 1750, loss is 3.7854496145248415 and perplexity is 44.05547408748774
At time: 367.3210799694061 and batch: 1800, loss is 3.739046082496643 and perplexity is 42.05785130294762
At time: 368.3178265094757 and batch: 1850, loss is 3.7710913801193238 and perplexity is 43.42743482081646
At time: 369.31466245651245 and batch: 1900, loss is 3.838294701576233 and perplexity is 46.446202232157965
At time: 370.31049728393555 and batch: 1950, loss is 3.769685301780701 and perplexity is 43.36641535454107
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.298033816315407 and perplexity of 73.55502873156185
finished 9 epochs...
Completing Train Step...
At time: 373.5063352584839 and batch: 50, loss is 3.8895363140106203 and perplexity is 48.88821248814525
At time: 374.52354860305786 and batch: 100, loss is 3.873375301361084 and perplexity is 48.10447948496572
At time: 375.4900426864624 and batch: 150, loss is 3.8379186010360717 and perplexity is 46.42873707494341
At time: 376.46103405952454 and batch: 200, loss is 3.841784605979919 and perplexity is 46.60857821138104
At time: 377.4326102733612 and batch: 250, loss is 3.82842734336853 and perplexity is 45.99015461020981
At time: 378.43696427345276 and batch: 300, loss is 3.83826934337616 and perplexity is 46.44502445500234
At time: 379.42136430740356 and batch: 350, loss is 3.855435781478882 and perplexity is 47.24920278294943
At time: 380.4089457988739 and batch: 400, loss is 3.80506676197052 and perplexity is 44.928249511358835
At time: 381.3970236778259 and batch: 450, loss is 3.8474830770492554 and perplexity is 46.87493403560956
At time: 382.38446259498596 and batch: 500, loss is 3.8695522928237915 and perplexity is 47.920926734636396
At time: 383.37182545661926 and batch: 550, loss is 3.8218365240097047 and perplexity is 45.68803849887889
At time: 384.35885548591614 and batch: 600, loss is 3.8116701364517214 and perplexity is 45.22590926547009
At time: 385.3468928337097 and batch: 650, loss is 3.8640038633346556 and perplexity is 47.6557771138033
At time: 386.3350329399109 and batch: 700, loss is 3.8886107635498046 and perplexity is 48.842984913978114
At time: 387.32373213768005 and batch: 750, loss is 3.844961838722229 and perplexity is 46.756900013816974
At time: 388.310293674469 and batch: 800, loss is 3.821153702735901 and perplexity is 45.65685238271696
At time: 389.2977819442749 and batch: 850, loss is 3.821667766571045 and perplexity is 45.680328953064326
At time: 390.28465270996094 and batch: 900, loss is 3.7954035425186157 and perplexity is 44.4961888871226
At time: 391.272567987442 and batch: 950, loss is 3.8909652423858643 and perplexity is 48.958120176829524
At time: 392.260285615921 and batch: 1000, loss is 3.8649493789672853 and perplexity is 47.70085770489282
At time: 393.2484540939331 and batch: 1050, loss is 3.811890230178833 and perplexity is 45.23586429988246
At time: 394.23596811294556 and batch: 1100, loss is 3.8264662218093872 and perplexity is 45.90005070772656
At time: 395.2238233089447 and batch: 1150, loss is 3.796233787536621 and perplexity is 44.53314696627396
At time: 396.2119779586792 and batch: 1200, loss is 3.864536051750183 and perplexity is 47.68114571615562
At time: 397.19954085350037 and batch: 1250, loss is 3.849434790611267 and perplexity is 46.96650981586231
At time: 398.18637561798096 and batch: 1300, loss is 3.8494823789596557 and perplexity is 46.96874492767624
At time: 399.17228960990906 and batch: 1350, loss is 3.747113127708435 and perplexity is 42.39850608226907
At time: 400.1625006198883 and batch: 1400, loss is 3.768178825378418 and perplexity is 43.30113405787049
At time: 401.17123460769653 and batch: 1450, loss is 3.691117248535156 and perplexity is 40.08961200607642
At time: 402.1725821495056 and batch: 1500, loss is 3.7030136156082154 and perplexity is 40.569380841201294
At time: 403.16945791244507 and batch: 1550, loss is 3.706278109550476 and perplexity is 40.702035746959076
At time: 404.1670415401459 and batch: 1600, loss is 3.802761001586914 and perplexity is 44.824775073004865
At time: 405.1631164550781 and batch: 1650, loss is 3.7493791437149047 and perplexity is 42.4946907125001
At time: 406.15927243232727 and batch: 1700, loss is 3.772533917427063 and perplexity is 43.49012572183548
At time: 407.1562440395355 and batch: 1750, loss is 3.768061079978943 and perplexity is 43.29603584869436
At time: 408.1511821746826 and batch: 1800, loss is 3.723378953933716 and perplexity is 41.40406042554732
At time: 409.15543842315674 and batch: 1850, loss is 3.7561903905868532 and perplexity is 42.78512051339951
At time: 410.15857911109924 and batch: 1900, loss is 3.824235215187073 and perplexity is 45.79776153696949
At time: 411.1550483703613 and batch: 1950, loss is 3.7563087368011474 and perplexity is 42.7901842700727
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.3007457644440406 and perplexity of 73.7547768849741
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 414.355272769928 and batch: 50, loss is 3.8803998374938966 and perplexity is 48.44358075944931
At time: 415.3200218677521 and batch: 100, loss is 3.887970447540283 and perplexity is 48.811719979572125
At time: 416.2857675552368 and batch: 150, loss is 3.857576622962952 and perplexity is 47.35046418999173
At time: 417.25524163246155 and batch: 200, loss is 3.8642055225372314 and perplexity is 47.6653883088746
At time: 418.23919558525085 and batch: 250, loss is 3.8569183492660524 and perplexity is 47.3193048816812
At time: 419.2272171974182 and batch: 300, loss is 3.865794425010681 and perplexity is 47.741184162419835
At time: 420.22002148628235 and batch: 350, loss is 3.8870615434646605 and perplexity is 48.767374964080005
At time: 421.21718525886536 and batch: 400, loss is 3.840065426826477 and perplexity is 46.5285185535144
At time: 422.2177777290344 and batch: 450, loss is 3.8733961963653565 and perplexity is 48.1054846387714
At time: 423.21446442604065 and batch: 500, loss is 3.893713960647583 and perplexity is 49.09287737575983
At time: 424.21288084983826 and batch: 550, loss is 3.8484677124023436 and perplexity is 46.921111483077574
At time: 425.2096338272095 and batch: 600, loss is 3.8268939065933227 and perplexity is 45.91968565948188
At time: 426.20827174186707 and batch: 650, loss is 3.869268231391907 and perplexity is 47.90731618077915
At time: 427.20594334602356 and batch: 700, loss is 3.8861723232269285 and perplexity is 48.72402930209697
At time: 428.2268500328064 and batch: 750, loss is 3.846767168045044 and perplexity is 46.841387857699836
At time: 429.2248628139496 and batch: 800, loss is 3.8150971221923826 and perplexity is 45.38116368703043
At time: 430.2229301929474 and batch: 850, loss is 3.814218273162842 and perplexity is 45.3412980158838
At time: 431.2202296257019 and batch: 900, loss is 3.7841196966171267 and perplexity is 43.996922866354545
At time: 432.21861386299133 and batch: 950, loss is 3.8853314971923827 and perplexity is 48.6830780885877
At time: 433.2169075012207 and batch: 1000, loss is 3.852081274986267 and perplexity is 47.090970569315594
At time: 434.2138526439667 and batch: 1050, loss is 3.7989815044403077 and perplexity is 44.65567971252363
At time: 435.210248708725 and batch: 1100, loss is 3.807946629524231 and perplexity is 45.05782340764826
At time: 436.20714497566223 and batch: 1150, loss is 3.780971369743347 and perplexity is 43.85862399099816
At time: 437.2045695781708 and batch: 1200, loss is 3.83921275138855 and perplexity is 46.4888617381796
At time: 438.20168232917786 and batch: 1250, loss is 3.8223047399520875 and perplexity is 45.70943537566878
At time: 439.1996216773987 and batch: 1300, loss is 3.819751114845276 and perplexity is 45.59285952273701
At time: 440.1978213787079 and batch: 1350, loss is 3.7143443965911866 and perplexity is 41.0316777566265
At time: 441.1960608959198 and batch: 1400, loss is 3.7351707077026366 and perplexity is 41.8951767820813
At time: 442.19058775901794 and batch: 1450, loss is 3.650502519607544 and perplexity is 38.49400518185522
At time: 443.1857101917267 and batch: 1500, loss is 3.6664547157287597 and perplexity is 39.11299308398224
At time: 444.1803689002991 and batch: 1550, loss is 3.667314600944519 and perplexity is 39.146640232748915
At time: 445.1778185367584 and batch: 1600, loss is 3.7604023170471192 and perplexity is 42.96570833894217
At time: 446.17537927627563 and batch: 1650, loss is 3.7049510002136232 and perplexity is 40.6480555220432
At time: 447.1729600429535 and batch: 1700, loss is 3.7164174365997313 and perplexity is 41.116826293902136
At time: 448.16983675956726 and batch: 1750, loss is 3.7127875757217406 and perplexity is 40.96784848265137
At time: 449.1675052642822 and batch: 1800, loss is 3.6706206512451174 and perplexity is 39.27627516618767
At time: 450.16521525382996 and batch: 1850, loss is 3.704113874435425 and perplexity is 40.614042225622
At time: 451.16364455223083 and batch: 1900, loss is 3.768926672935486 and perplexity is 43.33352881685484
At time: 452.16064620018005 and batch: 1950, loss is 3.7051562213897706 and perplexity is 40.656398219825384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.269184059320494 and perplexity of 71.4633020088719
finished 11 epochs...
Completing Train Step...
At time: 455.35770082473755 and batch: 50, loss is 3.867405905723572 and perplexity is 47.818180182046056
At time: 456.3156564235687 and batch: 100, loss is 3.8562045907974243 and perplexity is 47.285542377662246
At time: 457.27461981773376 and batch: 150, loss is 3.8210733842849733 and perplexity is 45.653185442322815
At time: 458.23829531669617 and batch: 200, loss is 3.824405703544617 and perplexity is 45.80557018773622
At time: 459.2078866958618 and batch: 250, loss is 3.815548801422119 and perplexity is 45.401666045985415
At time: 460.1846537590027 and batch: 300, loss is 3.8227186822891235 and perplexity is 45.72836036282926
At time: 461.1705288887024 and batch: 350, loss is 3.845599865913391 and perplexity is 46.786741706293526
At time: 462.15631437301636 and batch: 400, loss is 3.7975124311447144 and perplexity is 44.59012540978898
At time: 463.14256024360657 and batch: 450, loss is 3.8336701726913454 and perplexity is 46.231906319077666
At time: 464.15725541114807 and batch: 500, loss is 3.8545938301086426 and perplexity is 47.20943799428181
At time: 465.1650359630585 and batch: 550, loss is 3.810643539428711 and perplexity is 45.1795043053277
At time: 466.16556572914124 and batch: 600, loss is 3.7934342670440673 and perplexity is 44.40864985615972
At time: 467.15435433387756 and batch: 650, loss is 3.8384131383895874 and perplexity is 46.45170349811253
At time: 468.1435465812683 and batch: 700, loss is 3.858256664276123 and perplexity is 47.38267541307863
At time: 469.13242959976196 and batch: 750, loss is 3.820629873275757 and perplexity is 45.63294224134641
At time: 470.12117409706116 and batch: 800, loss is 3.7903744745254517 and perplexity is 44.27297627392569
At time: 471.11047768592834 and batch: 850, loss is 3.789868426322937 and perplexity is 44.25057768172396
At time: 472.0998125076294 and batch: 900, loss is 3.760820598602295 and perplexity is 42.98368386139808
At time: 473.08930683135986 and batch: 950, loss is 3.862690873146057 and perplexity is 47.59324660597772
At time: 474.0900926589966 and batch: 1000, loss is 3.8302794170379637 and perplexity is 46.075410690517025
At time: 475.086243391037 and batch: 1050, loss is 3.7793790006637575 and perplexity is 43.78884044960383
At time: 476.07444310188293 and batch: 1100, loss is 3.788577127456665 and perplexity is 44.19347383793086
At time: 477.0850775241852 and batch: 1150, loss is 3.7628854370117186 and perplexity is 43.07252991762163
At time: 478.0737521648407 and batch: 1200, loss is 3.8228682231903077 and perplexity is 45.73519913437288
At time: 479.06331181526184 and batch: 1250, loss is 3.808637661933899 and perplexity is 45.088970584546935
At time: 480.05231070518494 and batch: 1300, loss is 3.8078443956375123 and perplexity is 45.05321720669315
At time: 481.04153275489807 and batch: 1350, loss is 3.7032909870147703 and perplexity is 40.58063518817315
At time: 482.03335309028625 and batch: 1400, loss is 3.7262475156784056 and perplexity is 41.523001042050055
At time: 483.0238399505615 and batch: 1450, loss is 3.6430811882019043 and perplexity is 38.20938584578943
At time: 484.022127866745 and batch: 1500, loss is 3.6600471353530883 and perplexity is 38.8631746576208
At time: 485.0203444957733 and batch: 1550, loss is 3.6624905395507814 and perplexity is 38.958249207190306
At time: 486.0187427997589 and batch: 1600, loss is 3.7581649923324587 and perplexity is 42.869687552685306
At time: 487.0156681537628 and batch: 1650, loss is 3.7031281280517576 and perplexity is 40.574026806139734
At time: 488.01214504241943 and batch: 1700, loss is 3.7176505613327024 and perplexity is 41.16755974325326
At time: 489.02264976501465 and batch: 1750, loss is 3.715221476554871 and perplexity is 41.06768160588252
At time: 490.02161264419556 and batch: 1800, loss is 3.674086933135986 and perplexity is 39.412654034787714
At time: 491.0168442726135 and batch: 1850, loss is 3.7080536890029907 and perplexity is 40.77436964359337
At time: 492.01371908187866 and batch: 1900, loss is 3.7740029001235964 and perplexity is 43.5540589108683
At time: 493.01036739349365 and batch: 1950, loss is 3.709961929321289 and perplexity is 40.85225122445376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2683278638263085 and perplexity of 71.40214163804546
finished 12 epochs...
Completing Train Step...
At time: 496.20715069770813 and batch: 50, loss is 3.8536225938796997 and perplexity is 47.163608736873854
At time: 497.17436623573303 and batch: 100, loss is 3.8403371953964234 and perplexity is 46.541165260874365
At time: 498.1397445201874 and batch: 150, loss is 3.805040230751038 and perplexity is 44.927057525922585
At time: 499.10598945617676 and batch: 200, loss is 3.807329173088074 and perplexity is 45.030010752021234
At time: 500.0811941623688 and batch: 250, loss is 3.797559232711792 and perplexity is 44.59221234636993
At time: 501.06308579444885 and batch: 300, loss is 3.804626364707947 and perplexity is 44.908467589533664
At time: 502.0673007965088 and batch: 350, loss is 3.8280579376220705 and perplexity is 45.97316872035205
At time: 503.0491623878479 and batch: 400, loss is 3.7801618146896363 and perplexity is 43.82313238843893
At time: 504.0304985046387 and batch: 450, loss is 3.8167576885223387 and perplexity is 45.45658472294874
At time: 505.01280188560486 and batch: 500, loss is 3.837731122970581 and perplexity is 46.42003352102165
At time: 505.9944486618042 and batch: 550, loss is 3.7940004158020018 and perplexity is 44.4337988764889
At time: 506.9769947528839 and batch: 600, loss is 3.7781510305404664 and perplexity is 43.73510206311742
At time: 507.96104407310486 and batch: 650, loss is 3.8236340427398683 and perplexity is 45.770237458777494
At time: 508.9488785266876 and batch: 700, loss is 3.844224009513855 and perplexity is 46.722414131203976
At time: 509.9364638328552 and batch: 750, loss is 3.807148604393005 and perplexity is 45.021880475799584
At time: 510.92224884033203 and batch: 800, loss is 3.7776731872558593 and perplexity is 43.71420853060961
At time: 511.9077126979828 and batch: 850, loss is 3.7773556900024414 and perplexity is 43.70033159252724
At time: 512.8948974609375 and batch: 900, loss is 3.7484694385528563 and perplexity is 42.45605065119567
At time: 513.8822875022888 and batch: 950, loss is 3.8507416677474975 and perplexity is 47.0279293988919
At time: 514.870278596878 and batch: 1000, loss is 3.8190481567382815 and perplexity is 45.56082091473338
At time: 515.8650047779083 and batch: 1050, loss is 3.768967237472534 and perplexity is 43.335286657042694
At time: 516.8610475063324 and batch: 1100, loss is 3.778224129676819 and perplexity is 43.73829917815827
At time: 517.8566150665283 and batch: 1150, loss is 3.752710084915161 and perplexity is 42.63647403344668
At time: 518.8531262874603 and batch: 1200, loss is 3.813359680175781 and perplexity is 45.30238500299361
At time: 519.8485178947449 and batch: 1250, loss is 3.800353560447693 and perplexity is 44.71699185836755
At time: 520.8445255756378 and batch: 1300, loss is 3.800314021110535 and perplexity is 44.71522381310366
At time: 521.8406040668488 and batch: 1350, loss is 3.6960007524490357 and perplexity is 40.285868603106756
At time: 522.8367166519165 and batch: 1400, loss is 3.719961371421814 and perplexity is 41.26280015452296
At time: 523.8325119018555 and batch: 1450, loss is 3.637152042388916 and perplexity is 37.98350712135744
At time: 524.8276214599609 and batch: 1500, loss is 3.6543373537063597 and perplexity is 38.64190671319171
At time: 525.8228404521942 and batch: 1550, loss is 3.6574614906311034 and perplexity is 38.7628180943085
At time: 526.81876039505 and batch: 1600, loss is 3.7542769527435302 and perplexity is 42.703332118137304
At time: 527.8141362667084 and batch: 1650, loss is 3.6991881942749023 and perplexity is 40.414482331181155
At time: 528.8096714019775 and batch: 1700, loss is 3.7150774145126344 and perplexity is 41.0617657379367
At time: 529.805296421051 and batch: 1750, loss is 3.713262400627136 and perplexity is 40.987305656441194
At time: 530.8002009391785 and batch: 1800, loss is 3.6726271963119506 and perplexity is 39.35516390279997
At time: 531.7944748401642 and batch: 1850, loss is 3.706800880432129 and perplexity is 40.72331914875823
At time: 532.7884104251862 and batch: 1900, loss is 3.7731216096878053 and perplexity is 43.5156920439699
At time: 533.7833590507507 and batch: 1950, loss is 3.708940372467041 and perplexity is 40.81053963621083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.268669660701308 and perplexity of 71.42655083818214
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 536.9583883285522 and batch: 50, loss is 3.8511231422424315 and perplexity is 47.04587277676004
At time: 537.9525921344757 and batch: 100, loss is 3.8493849420547486 and perplexity is 46.96416866149534
At time: 538.9243621826172 and batch: 150, loss is 3.8205708360671995 and perplexity is 45.630248279341004
At time: 539.8963725566864 and batch: 200, loss is 3.8251780319213866 and perplexity is 45.84096079423198
At time: 540.8685626983643 and batch: 250, loss is 3.8207248067855835 and perplexity is 45.63727454235411
At time: 541.8594701290131 and batch: 300, loss is 3.8235021829605103 and perplexity is 45.764202603251114
At time: 542.8673825263977 and batch: 350, loss is 3.8509867906570436 and perplexity is 47.03945843473377
At time: 543.8556845188141 and batch: 400, loss is 3.8106802701950073 and perplexity is 45.181163813619044
At time: 544.8348729610443 and batch: 450, loss is 3.8459326457977294 and perplexity is 46.80231398371374
At time: 545.8149492740631 and batch: 500, loss is 3.8627687740325927 and perplexity is 47.59695430649614
At time: 546.7952826023102 and batch: 550, loss is 3.8202965116500853 and perplexity is 45.61773250484876
At time: 547.8052535057068 and batch: 600, loss is 3.8008674287796023 and perplexity is 44.73997640939248
At time: 548.8012144565582 and batch: 650, loss is 3.837618489265442 and perplexity is 46.41480535509287
At time: 549.7883360385895 and batch: 700, loss is 3.857856936454773 and perplexity is 47.36373902441885
At time: 550.768364906311 and batch: 750, loss is 3.816655168533325 and perplexity is 45.45192475325645
At time: 551.7725002765656 and batch: 800, loss is 3.785858178138733 and perplexity is 44.0734772286564
At time: 552.7568743228912 and batch: 850, loss is 3.783985357284546 and perplexity is 43.99101274609077
At time: 553.7446537017822 and batch: 900, loss is 3.7506204891204833 and perplexity is 42.547474055980025
At time: 554.733824968338 and batch: 950, loss is 3.856423168182373 and perplexity is 47.295879057502106
At time: 555.721581697464 and batch: 1000, loss is 3.8250780439376832 and perplexity is 45.83637747813323
At time: 556.7160377502441 and batch: 1050, loss is 3.776373853683472 and perplexity is 43.657446076542406
At time: 557.704262971878 and batch: 1100, loss is 3.784313554763794 and perplexity is 44.005452855057676
At time: 558.6931068897247 and batch: 1150, loss is 3.7633593559265135 and perplexity is 43.09294764204841
At time: 559.6812665462494 and batch: 1200, loss is 3.8179004287719724 and perplexity is 45.50855948309177
At time: 560.6691052913666 and batch: 1250, loss is 3.802289800643921 and perplexity is 44.803658572169276
At time: 561.6564383506775 and batch: 1300, loss is 3.7958426380157473 and perplexity is 44.515731253471
At time: 562.6532974243164 and batch: 1350, loss is 3.6893420362472535 and perplexity is 40.018507565637265
At time: 563.6504316329956 and batch: 1400, loss is 3.71179069519043 and perplexity is 40.92702878165239
At time: 564.6519865989685 and batch: 1450, loss is 3.626445713043213 and perplexity is 37.579012375173555
At time: 565.6585869789124 and batch: 1500, loss is 3.645580587387085 and perplexity is 38.30500580007845
At time: 566.6575849056244 and batch: 1550, loss is 3.6502528095245363 and perplexity is 38.48439404067533
At time: 567.6541330814362 and batch: 1600, loss is 3.743925986289978 and perplexity is 42.263591158128925
At time: 568.6503448486328 and batch: 1650, loss is 3.690661602020264 and perplexity is 40.07134947502774
At time: 569.6487648487091 and batch: 1700, loss is 3.6966816902160646 and perplexity is 40.313310114436575
At time: 570.6466999053955 and batch: 1750, loss is 3.69386625289917 and perplexity is 40.199970142433706
At time: 571.6435737609863 and batch: 1800, loss is 3.6518107986450197 and perplexity is 38.54439903932898
At time: 572.6417319774628 and batch: 1850, loss is 3.6852076625823975 and perplexity is 39.85339765008027
At time: 573.6390860080719 and batch: 1900, loss is 3.756249260902405 and perplexity is 42.78763936108701
At time: 574.635776758194 and batch: 1950, loss is 3.702033758163452 and perplexity is 40.529648100744396
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.255039516715116 and perplexity of 70.45960146541773
finished 14 epochs...
Completing Train Step...
At time: 577.8101644515991 and batch: 50, loss is 3.8573429679870603 and perplexity is 47.339401810863265
At time: 578.7985136508942 and batch: 100, loss is 3.8402678871154787 and perplexity is 46.53793968449784
At time: 579.7617337703705 and batch: 150, loss is 3.807549157142639 and perplexity is 45.03991772601179
At time: 580.7274477481842 and batch: 200, loss is 3.8086448955535888 and perplexity is 45.089296742192
At time: 581.6975457668304 and batch: 250, loss is 3.80228196144104 and perplexity is 44.803307348576574
At time: 582.6692600250244 and batch: 300, loss is 3.8043369960784914 and perplexity is 44.89547436782238
At time: 583.6576986312866 and batch: 350, loss is 3.8313045835494997 and perplexity is 46.12266987869176
At time: 584.6266281604767 and batch: 400, loss is 3.788884711265564 and perplexity is 44.207069125680434
At time: 585.6012125015259 and batch: 450, loss is 3.8254709672927856 and perplexity is 45.85439120013196
At time: 586.5816588401794 and batch: 500, loss is 3.844191675186157 and perplexity is 46.7209034177787
At time: 587.5613477230072 and batch: 550, loss is 3.801691117286682 and perplexity is 44.776843395139736
At time: 588.5487384796143 and batch: 600, loss is 3.784752941131592 and perplexity is 44.02479249962791
At time: 589.5368719100952 and batch: 650, loss is 3.822663817405701 and perplexity is 45.725851550492315
At time: 590.5235085487366 and batch: 700, loss is 3.8440679788589476 and perplexity is 46.71512457104044
At time: 591.5118763446808 and batch: 750, loss is 3.8050812101364135 and perplexity is 44.92889864685048
At time: 592.4994568824768 and batch: 800, loss is 3.7744128561019896 and perplexity is 43.57191781813488
At time: 593.4925529956818 and batch: 850, loss is 3.7735437154769897 and perplexity is 43.534064146714705
At time: 594.4875092506409 and batch: 900, loss is 3.7413579702377318 and perplexity is 42.15519681638313
At time: 595.4843783378601 and batch: 950, loss is 3.846919617652893 and perplexity is 46.84852935325512
At time: 596.480318069458 and batch: 1000, loss is 3.8162604093551638 and perplexity is 45.43398572982504
At time: 597.4766802787781 and batch: 1050, loss is 3.767941813468933 and perplexity is 43.290872389521425
At time: 598.472487449646 and batch: 1100, loss is 3.7763107347488405 and perplexity is 43.65469055202113
At time: 599.4677948951721 and batch: 1150, loss is 3.755981297492981 and perplexity is 42.77617537539556
At time: 600.4630513191223 and batch: 1200, loss is 3.810947365760803 and perplexity is 45.19323311388769
At time: 601.5002679824829 and batch: 1250, loss is 3.796465067863464 and perplexity is 44.54344779820364
At time: 602.4980776309967 and batch: 1300, loss is 3.7911461782455445 and perplexity is 44.30715508067582
At time: 603.4941635131836 and batch: 1350, loss is 3.6852447986602783 and perplexity is 39.85487767644023
At time: 604.4904737472534 and batch: 1400, loss is 3.708934726715088 and perplexity is 40.810309230677376
At time: 605.486823797226 and batch: 1450, loss is 3.6246258497238157 and perplexity is 37.51068590025308
At time: 606.4834711551666 and batch: 1500, loss is 3.644910526275635 and perplexity is 38.27934770252463
At time: 607.4802072048187 and batch: 1550, loss is 3.650713005065918 and perplexity is 38.50210846296208
At time: 608.4760463237762 and batch: 1600, loss is 3.7454424476623536 and perplexity is 42.32773088199333
At time: 609.4721827507019 and batch: 1650, loss is 3.6927950811386108 and perplexity is 40.156932124311815
At time: 610.4683039188385 and batch: 1700, loss is 3.700155692100525 and perplexity is 40.45360217609117
At time: 611.4641740322113 and batch: 1750, loss is 3.6980269002914428 and perplexity is 40.36757647701988
At time: 612.4602844715118 and batch: 1800, loss is 3.6569640588760377 and perplexity is 38.74354103258137
At time: 613.4540920257568 and batch: 1850, loss is 3.6904003715515135 and perplexity is 40.060882984763516
At time: 614.4682490825653 and batch: 1900, loss is 3.7620724201202393 and perplexity is 43.03752545477779
At time: 615.4692025184631 and batch: 1950, loss is 3.7073186016082764 and perplexity is 40.74440793202835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.25395990416061 and perplexity of 70.38357344287864
finished 15 epochs...
Completing Train Step...
At time: 618.6427509784698 and batch: 50, loss is 3.85438127040863 and perplexity is 47.199404236728014
At time: 619.6327431201935 and batch: 100, loss is 3.835215239524841 and perplexity is 46.30339291574408
At time: 620.598569393158 and batch: 150, loss is 3.802117958068848 and perplexity is 44.795960057592765
At time: 621.5641736984253 and batch: 200, loss is 3.8023381280899047 and perplexity is 44.805823870880054
At time: 622.5300424098969 and batch: 250, loss is 3.7953172540664672 and perplexity is 44.49234954550484
At time: 623.4965074062347 and batch: 300, loss is 3.796883125305176 and perplexity is 44.56207341105193
At time: 624.4647789001465 and batch: 350, loss is 3.8240551471710207 and perplexity is 45.78951556734987
At time: 625.4578340053558 and batch: 400, loss is 3.781081585884094 and perplexity is 43.86345818567117
At time: 626.429708480835 and batch: 450, loss is 3.817796506881714 and perplexity is 45.50383039329958
At time: 627.4017684459686 and batch: 500, loss is 3.83668909072876 and perplexity is 46.37168754283497
At time: 628.379804611206 and batch: 550, loss is 3.794459443092346 and perplexity is 44.454199884738436
At time: 629.3608434200287 and batch: 600, loss is 3.7781934118270875 and perplexity is 43.736955652291826
At time: 630.3412535190582 and batch: 650, loss is 3.816245880126953 and perplexity is 45.43332561387335
At time: 631.3211379051208 and batch: 700, loss is 3.8380784368515015 and perplexity is 46.43615864309356
At time: 632.3012042045593 and batch: 750, loss is 3.7998052883148192 and perplexity is 44.692481497653525
At time: 633.2819337844849 and batch: 800, loss is 3.769218325614929 and perplexity is 43.34616899982602
At time: 634.2641649246216 and batch: 850, loss is 3.768608570098877 and perplexity is 43.31974649063267
At time: 635.2471005916595 and batch: 900, loss is 3.736842293739319 and perplexity is 41.96526673897074
At time: 636.2348024845123 and batch: 950, loss is 3.842429533004761 and perplexity is 46.638647038116275
At time: 637.2228004932404 and batch: 1000, loss is 3.812099313735962 and perplexity is 45.24532336413303
At time: 638.2105331420898 and batch: 1050, loss is 3.7640259647369385 and perplexity is 43.12168335729016
At time: 639.1988198757172 and batch: 1100, loss is 3.772552089691162 and perplexity is 43.490916043066754
At time: 640.1865510940552 and batch: 1150, loss is 3.7525964879989626 and perplexity is 42.63163093656455
At time: 641.17427277565 and batch: 1200, loss is 3.8076892137527465 and perplexity is 45.04622630597685
At time: 642.1625664234161 and batch: 1250, loss is 3.7936603593826295 and perplexity is 44.418691446778666
At time: 643.1513378620148 and batch: 1300, loss is 3.7888446712493895 and perplexity is 44.20529910935358
At time: 644.1397264003754 and batch: 1350, loss is 3.6832288217544558 and perplexity is 39.774612097421326
At time: 645.127183675766 and batch: 1400, loss is 3.7073619174957275 and perplexity is 40.74617285044082
At time: 646.1141624450684 and batch: 1450, loss is 3.6235969400405885 and perplexity is 37.4721106409379
At time: 647.1330142021179 and batch: 1500, loss is 3.644290733337402 and perplexity is 38.255629783996916
At time: 648.1231577396393 and batch: 1550, loss is 3.6505192375183104 and perplexity is 38.49464872657824
At time: 649.1100785732269 and batch: 1600, loss is 3.7457529592514036 and perplexity is 42.34087617374748
At time: 650.0987365245819 and batch: 1650, loss is 3.6932499265670775 and perplexity is 40.175201475860355
At time: 651.0863809585571 and batch: 1700, loss is 3.7011104679107665 and perplexity is 40.49224474144381
At time: 652.0744717121124 and batch: 1750, loss is 3.6991424131393433 and perplexity is 40.41263215263896
At time: 653.0623586177826 and batch: 1800, loss is 3.65838059425354 and perplexity is 38.79846151832574
At time: 654.0510811805725 and batch: 1850, loss is 3.691725940704346 and perplexity is 40.1140216672015
At time: 655.0400896072388 and batch: 1900, loss is 3.7636381721496583 and perplexity is 43.10496433010009
At time: 656.0351040363312 and batch: 1950, loss is 3.708613872528076 and perplexity is 40.79721717252063
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253745287518169 and perplexity of 70.3684695774917
finished 16 epochs...
Completing Train Step...
At time: 659.2424521446228 and batch: 50, loss is 3.850732989311218 and perplexity is 47.02752127177422
At time: 660.2138276100159 and batch: 100, loss is 3.8307470989227297 and perplexity is 46.09696436516886
At time: 661.1858477592468 and batch: 150, loss is 3.79756872177124 and perplexity is 44.59263548653139
At time: 662.1705574989319 and batch: 200, loss is 3.797390685081482 and perplexity is 44.58469706800762
At time: 663.1573741436005 and batch: 250, loss is 3.7900677347183227 and perplexity is 44.25939807231634
At time: 664.1378755569458 and batch: 300, loss is 3.791461172103882 and perplexity is 44.32111376074046
At time: 665.1371715068817 and batch: 350, loss is 3.8187831926345823 and perplexity is 45.548750531835616
At time: 666.1170814037323 and batch: 400, loss is 3.7756278896331787 and perplexity is 43.62489133508472
At time: 667.0988512039185 and batch: 450, loss is 3.8124622821807863 and perplexity is 45.26174896959798
At time: 668.0801002979279 and batch: 500, loss is 3.83136372089386 and perplexity is 46.125397531555464
At time: 669.0605320930481 and batch: 550, loss is 3.7893125200271607 and perplexity is 44.225985343150185
At time: 670.040821313858 and batch: 600, loss is 3.773497519493103 and perplexity is 43.532053094240496
At time: 671.0278160572052 and batch: 650, loss is 3.8116209602355955 and perplexity is 45.22368528106557
At time: 672.0156600475311 and batch: 700, loss is 3.8337827491760255 and perplexity is 46.23711123754134
At time: 673.0037779808044 and batch: 750, loss is 3.7958755397796633 and perplexity is 44.517195923646234
At time: 673.991767168045 and batch: 800, loss is 3.7653934812545775 and perplexity is 43.180693310896565
At time: 675.0225751399994 and batch: 850, loss is 3.7649684715270997 and perplexity is 43.162344995582636
At time: 676.0090179443359 and batch: 900, loss is 3.7334357070922852 and perplexity is 41.82255164534008
At time: 676.9962728023529 and batch: 950, loss is 3.8391319608688352 and perplexity is 46.48510603059366
At time: 677.9840171337128 and batch: 1000, loss is 3.809041004180908 and perplexity is 45.10716053939987
At time: 678.9711062908173 and batch: 1050, loss is 3.7611242866516115 and perplexity is 42.996739474818924
At time: 679.9599235057831 and batch: 1100, loss is 3.769718008041382 and perplexity is 43.36783373102123
At time: 680.9480495452881 and batch: 1150, loss is 3.7500172233581544 and perplexity is 42.52181436219403
At time: 681.9346270561218 and batch: 1200, loss is 3.805157151222229 and perplexity is 44.93231072575506
At time: 682.9211511611938 and batch: 1250, loss is 3.791410388946533 and perplexity is 44.31886305179602
At time: 683.907557964325 and batch: 1300, loss is 3.786887774467468 and perplexity is 44.11887848747962
At time: 684.8962347507477 and batch: 1350, loss is 3.6814421701431272 and perplexity is 39.70361216758374
At time: 685.8840134143829 and batch: 1400, loss is 3.7058241748809815 and perplexity is 40.68356387464334
At time: 686.8710460662842 and batch: 1450, loss is 3.6223991107940674 and perplexity is 37.427252322549705
At time: 687.8611972332001 and batch: 1500, loss is 3.6432995700836184 and perplexity is 38.217730994551054
At time: 688.8481242656708 and batch: 1550, loss is 3.649773259162903 and perplexity is 38.46594325998875
At time: 689.8354377746582 and batch: 1600, loss is 3.745340051651001 and perplexity is 42.32339691307576
At time: 690.8232429027557 and batch: 1650, loss is 3.692870101928711 and perplexity is 40.1599448420946
At time: 691.8105034828186 and batch: 1700, loss is 3.701094126701355 and perplexity is 40.49158305459935
At time: 692.7987534999847 and batch: 1750, loss is 3.6991722774505615 and perplexity is 40.41383906608445
At time: 693.7859835624695 and batch: 1800, loss is 3.6585855674743653 and perplexity is 38.806414979041605
At time: 694.7737729549408 and batch: 1850, loss is 3.6918757009506225 and perplexity is 40.120029602829256
At time: 695.7613582611084 and batch: 1900, loss is 3.763941698074341 and perplexity is 43.118049790044495
At time: 696.748292684555 and batch: 1950, loss is 3.7087639570236206 and perplexity is 40.80334066178849
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253786734647529 and perplexity of 70.37138620899577
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 699.9304127693176 and batch: 50, loss is 3.850719871520996 and perplexity is 47.026904378661655
At time: 700.8827567100525 and batch: 100, loss is 3.8345958185195923 and perplexity is 46.27472050262202
At time: 701.8482754230499 and batch: 150, loss is 3.8039550399780273 and perplexity is 44.878329541998205
At time: 702.8196127414703 and batch: 200, loss is 3.8047674036026002 and perplexity is 44.91480187684301
At time: 703.7904329299927 and batch: 250, loss is 3.799687933921814 and perplexity is 44.68723694635706
At time: 704.7613396644592 and batch: 300, loss is 3.7991822147369385 and perplexity is 44.664643466773775
At time: 705.7340981960297 and batch: 350, loss is 3.8254552602767946 and perplexity is 45.85367097013247
At time: 706.7175464630127 and batch: 400, loss is 3.7844157314300535 and perplexity is 44.009949415245494
At time: 707.6988244056702 and batch: 450, loss is 3.822333426475525 and perplexity is 45.71074663926571
At time: 708.6793551445007 and batch: 500, loss is 3.841851987838745 and perplexity is 46.61171888982934
At time: 709.6608378887177 and batch: 550, loss is 3.800638852119446 and perplexity is 44.72975106369155
At time: 710.6430420875549 and batch: 600, loss is 3.785515604019165 and perplexity is 44.058381381869346
At time: 711.6246485710144 and batch: 650, loss is 3.818896884918213 and perplexity is 45.55392936769137
At time: 712.6048057079315 and batch: 700, loss is 3.840991554260254 and perplexity is 46.571629851196136
At time: 713.586275100708 and batch: 750, loss is 3.8010175800323487 and perplexity is 44.74669467726374
At time: 714.5708303451538 and batch: 800, loss is 3.7696862697601317 and perplexity is 43.36645733235944
At time: 715.5598771572113 and batch: 850, loss is 3.767543759346008 and perplexity is 43.27364370848301
At time: 716.5474743843079 and batch: 900, loss is 3.7340723276138306 and perplexity is 41.84918521682045
At time: 717.5374674797058 and batch: 950, loss is 3.840608959197998 and perplexity is 46.553815183693075
At time: 718.5351755619049 and batch: 1000, loss is 3.809448928833008 and perplexity is 45.12556461565311
At time: 719.5324988365173 and batch: 1050, loss is 3.762693691253662 and perplexity is 43.06427173448225
At time: 720.5292615890503 and batch: 1100, loss is 3.7708554029464723 and perplexity is 43.41718814656141
At time: 721.5289068222046 and batch: 1150, loss is 3.7546516180038454 and perplexity is 42.71933457077601
At time: 722.5263724327087 and batch: 1200, loss is 3.8093978500366212 and perplexity is 45.12325971499254
At time: 723.5234451293945 and batch: 1250, loss is 3.7938876247406004 and perplexity is 44.42878742378038
At time: 724.520724773407 and batch: 1300, loss is 3.788636507987976 and perplexity is 44.19609814780353
At time: 725.5188086032867 and batch: 1350, loss is 3.6803873491287233 and perplexity is 39.66175404341724
At time: 726.516330242157 and batch: 1400, loss is 3.7046534633636474 and perplexity is 40.635963026716226
At time: 727.5138294696808 and batch: 1450, loss is 3.619465765953064 and perplexity is 37.31762614932788
At time: 728.5111515522003 and batch: 1500, loss is 3.6384799671173096 and perplexity is 38.03397986431985
At time: 729.5099017620087 and batch: 1550, loss is 3.643402075767517 and perplexity is 38.22164872999535
At time: 730.5082695484161 and batch: 1600, loss is 3.7390080070495606 and perplexity is 42.056249961942015
At time: 731.505090713501 and batch: 1650, loss is 3.685943212509155 and perplexity is 39.88272259746213
At time: 732.5018763542175 and batch: 1700, loss is 3.6915158557891847 and perplexity is 40.10559520153043
At time: 733.499020576477 and batch: 1750, loss is 3.689733109474182 and perplexity is 40.03416079310741
At time: 734.4987082481384 and batch: 1800, loss is 3.6484194135665895 and perplexity is 38.41390154826822
At time: 735.4961626529694 and batch: 1850, loss is 3.6808356618881226 and perplexity is 39.67953890010627
At time: 736.4934511184692 and batch: 1900, loss is 3.7535094833374023 and perplexity is 42.670571190309865
At time: 737.4931881427765 and batch: 1950, loss is 3.700973877906799 and perplexity is 40.48671428328518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2523102516351745 and perplexity of 70.26756071984947
finished 18 epochs...
Completing Train Step...
At time: 740.6764886379242 and batch: 50, loss is 3.8509321308135984 and perplexity is 47.03688733556856
At time: 741.6327641010284 and batch: 100, loss is 3.83209144115448 and perplexity is 46.15897613430125
At time: 742.6042642593384 and batch: 150, loss is 3.8007319450378416 and perplexity is 44.73391528058373
At time: 743.5678045749664 and batch: 200, loss is 3.7999451398849486 and perplexity is 44.69873224844242
At time: 744.5330812931061 and batch: 250, loss is 3.7942315196990966 and perplexity is 44.44406888724603
At time: 745.4999732971191 and batch: 300, loss is 3.7937342071533204 and perplexity is 44.421971789240516
At time: 746.4713654518127 and batch: 350, loss is 3.819714822769165 and perplexity is 45.59120489323424
At time: 747.4521553516388 and batch: 400, loss is 3.7785267448425293 and perplexity is 43.75153705370189
At time: 748.4559397697449 and batch: 450, loss is 3.816337671279907 and perplexity is 45.437496182621715
At time: 749.4361636638641 and batch: 500, loss is 3.8364708375930787 and perplexity is 46.36156788098606
At time: 750.414078950882 and batch: 550, loss is 3.7944615697860717 and perplexity is 44.454294425306934
At time: 751.3918223381042 and batch: 600, loss is 3.779727883338928 and perplexity is 43.804120282682035
At time: 752.372371673584 and batch: 650, loss is 3.8137671899795533 and perplexity is 45.32084993108067
At time: 753.3527987003326 and batch: 700, loss is 3.836035737991333 and perplexity is 46.341400369021095
At time: 754.3338248729706 and batch: 750, loss is 3.796611604690552 and perplexity is 44.54997553197655
At time: 755.3141255378723 and batch: 800, loss is 3.7656699132919313 and perplexity is 43.19263148789412
At time: 756.2949867248535 and batch: 850, loss is 3.7641213941574097 and perplexity is 43.12579863089865
At time: 757.2773134708405 and batch: 900, loss is 3.7309690952301025 and perplexity is 41.71951876664448
At time: 758.2647948265076 and batch: 950, loss is 3.8375599145889283 and perplexity is 46.41208670250663
At time: 759.2520484924316 and batch: 1000, loss is 3.8068297576904295 and perplexity is 45.00752768595758
At time: 760.2390797138214 and batch: 1050, loss is 3.7598248720169067 and perplexity is 42.94090516611593
At time: 761.2427930831909 and batch: 1100, loss is 3.76819607257843 and perplexity is 43.30188088763069
At time: 762.2468726634979 and batch: 1150, loss is 3.75201301574707 and perplexity is 42.606763818202396
At time: 763.2422521114349 and batch: 1200, loss is 3.8071832180023195 and perplexity is 45.02343887255169
At time: 764.2497427463531 and batch: 1250, loss is 3.7921583604812623 and perplexity is 44.35202470024881
At time: 765.2549092769623 and batch: 1300, loss is 3.786787161827087 and perplexity is 44.114439793922436
At time: 766.2451138496399 and batch: 1350, loss is 3.67927942276001 and perplexity is 39.6178360737139
At time: 767.2325937747955 and batch: 1400, loss is 3.703743028640747 and perplexity is 40.59898347126819
At time: 768.2205190658569 and batch: 1450, loss is 3.6192025899887086 and perplexity is 37.30780633930424
At time: 769.2069880962372 and batch: 1500, loss is 3.6390690183639527 and perplexity is 38.05639042741079
At time: 770.1926491260529 and batch: 1550, loss is 3.6445626544952394 and perplexity is 38.26603371360176
At time: 771.1794068813324 and batch: 1600, loss is 3.7403345251083375 and perplexity is 42.11207535551123
At time: 772.1661515235901 and batch: 1650, loss is 3.6879713106155396 and perplexity is 39.96369074956442
At time: 773.1539721488953 and batch: 1700, loss is 3.6936531019210816 and perplexity is 40.191402392623296
At time: 774.1420040130615 and batch: 1750, loss is 3.692194595336914 and perplexity is 40.13282569524004
At time: 775.1291453838348 and batch: 1800, loss is 3.6512728357315063 and perplexity is 38.52366915857562
At time: 776.1163053512573 and batch: 1850, loss is 3.683637709617615 and perplexity is 39.790878778967524
At time: 777.1044063568115 and batch: 1900, loss is 3.756608805656433 and perplexity is 42.80302619831908
At time: 778.0919814109802 and batch: 1950, loss is 3.703641119003296 and perplexity is 40.59484625439647
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251852062136628 and perplexity of 70.23537223621486
finished 19 epochs...
Completing Train Step...
At time: 781.2509872913361 and batch: 50, loss is 3.850358166694641 and perplexity is 47.009897596282414
At time: 782.2411363124847 and batch: 100, loss is 3.8306172132492065 and perplexity is 46.090977418722616
At time: 783.1986253261566 and batch: 150, loss is 3.7990096187591553 and perplexity is 44.65693519418985
At time: 784.1624383926392 and batch: 200, loss is 3.7976606798172 and perplexity is 44.596736326704665
At time: 785.1425688266754 and batch: 250, loss is 3.7915577507019043 and perplexity is 44.32539443847787
At time: 786.1252887248993 and batch: 300, loss is 3.7908722829818724 and perplexity is 44.29502122253143
At time: 787.1069152355194 and batch: 350, loss is 3.816815586090088 and perplexity is 45.459216624832024
At time: 788.0883600711823 and batch: 400, loss is 3.775346989631653 and perplexity is 43.612638823987886
At time: 789.069367647171 and batch: 450, loss is 3.813229866027832 and perplexity is 45.29650449417925
At time: 790.0517349243164 and batch: 500, loss is 3.8335656785964964 and perplexity is 46.22707561026838
At time: 791.0329191684723 and batch: 550, loss is 3.7914703464508057 and perplexity is 44.32152037987939
At time: 792.0141236782074 and batch: 600, loss is 3.7770367813110353 and perplexity is 43.68639739895087
At time: 792.9962651729584 and batch: 650, loss is 3.811265048980713 and perplexity is 45.2075925264529
At time: 793.9764888286591 and batch: 700, loss is 3.8336406755447388 and perplexity is 46.23054262987164
At time: 794.9804728031158 and batch: 750, loss is 3.794515862464905 and perplexity is 44.456708033556964
At time: 795.9611923694611 and batch: 800, loss is 3.7636286783218384 and perplexity is 43.10455510093313
At time: 796.9441697597504 and batch: 850, loss is 3.7622958040237426 and perplexity is 43.04714041908515
At time: 797.9849300384521 and batch: 900, loss is 3.729276657104492 and perplexity is 41.64897077839369
At time: 798.9770088195801 and batch: 950, loss is 3.835970387458801 and perplexity is 46.33837203278149
At time: 799.9600789546967 and batch: 1000, loss is 3.80541136264801 and perplexity is 44.94373448449178
At time: 800.9460127353668 and batch: 1050, loss is 3.7583839750289916 and perplexity is 42.87907630041424
At time: 801.9348828792572 and batch: 1100, loss is 3.7668748712539672 and perplexity is 43.24470816190729
At time: 802.9327290058136 and batch: 1150, loss is 3.7507916021347047 and perplexity is 42.55475510543664
At time: 803.9225845336914 and batch: 1200, loss is 3.8060985088348387 and perplexity is 44.97462801323428
At time: 804.9117081165314 and batch: 1250, loss is 3.791324424743652 and perplexity is 44.31505337981123
At time: 805.900235414505 and batch: 1300, loss is 3.786047945022583 and perplexity is 44.08184170871607
At time: 806.8885834217072 and batch: 1350, loss is 3.6788118743896483 and perplexity is 39.59931714860437
At time: 807.8773174285889 and batch: 1400, loss is 3.703411703109741 and perplexity is 40.58553421967453
At time: 808.8648257255554 and batch: 1450, loss is 3.6191550064086915 and perplexity is 37.306031142551475
At time: 809.8536078929901 and batch: 1500, loss is 3.6393820571899416 and perplexity is 38.068305420021915
At time: 810.8427557945251 and batch: 1550, loss is 3.645193247795105 and perplexity is 38.29017162787762
At time: 811.8308501243591 and batch: 1600, loss is 3.741088981628418 and perplexity is 42.143859073546345
At time: 812.8196897506714 and batch: 1650, loss is 3.688931021690369 and perplexity is 40.002062756242516
At time: 813.8316180706024 and batch: 1700, loss is 3.694689540863037 and perplexity is 40.233079921570955
At time: 814.8392202854156 and batch: 1750, loss is 3.6933946800231934 and perplexity is 40.18101739605126
At time: 815.8359911441803 and batch: 1800, loss is 3.6526548862457275 and perplexity is 38.576947623630495
At time: 816.82337641716 and batch: 1850, loss is 3.6849695873260497 and perplexity is 39.843910671570626
At time: 817.8121268749237 and batch: 1900, loss is 3.7580263423919678 and perplexity is 42.863744085097494
At time: 818.8014433383942 and batch: 1950, loss is 3.704795408248901 and perplexity is 40.64173150321841
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251626657885175 and perplexity of 70.21954266880334
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f05ce5c4b38>
ELAPSED
4212.992871284485


RESULTS SO FAR:
[{'best_accuracy': -70.031277428607, 'params': {'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.29541346180265, 'params': {'tie_weights': True, 'rnn_dropout': 0.7288706260952753, 'num_layers': 2, 'dropout': 0.4475108336446092, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.10525313217852, 'params': {'tie_weights': True, 'rnn_dropout': 0.8506975178466405, 'num_layers': 2, 'dropout': 0.6098755685920833, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -72.46967563165478, 'params': {'tie_weights': True, 'rnn_dropout': 0.3930815480094526, 'num_layers': 2, 'dropout': 0.9281289718292313, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.21954266880334, 'params': {'tie_weights': True, 'rnn_dropout': 0.5551850193968754, 'num_layers': 2, 'dropout': 0.6113123772309402, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}]
SETTINGS FOR THIS RUN
{'tie_weights': True, 'rnn_dropout': 0.4150335755013944, 'num_layers': 2, 'dropout': 0.2817202687527763, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Building Vocab...
Loading Vectors From Memory...
Using these vectors: glove
Found 20471 tokens
Getting Batches...
Created Iterator with 1965 batches
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Initializing Model parameters...
Constructing LSTM with 2 layers and 200 hidden size...
Using Cross Entropy Loss ...
Begin Training...
finished 0 epochs...
Completing Train Step...
At time: 1.4213488101959229 and batch: 50, loss is 7.578636121749878 and perplexity is 1955.9594547996348
At time: 2.4316256046295166 and batch: 100, loss is 6.699472026824951 and perplexity is 811.9770098960428
At time: 3.402420997619629 and batch: 150, loss is 6.450666027069092 and perplexity is 633.1238300279584
At time: 4.381006240844727 and batch: 200, loss is 6.252216405868531 and perplexity is 519.1622246307908
At time: 5.3761889934539795 and batch: 250, loss is 6.0951557540893555 and perplexity is 443.7031483752529
At time: 6.352921009063721 and batch: 300, loss is 5.984487295150757 and perplexity is 397.2188130210693
At time: 7.323416233062744 and batch: 350, loss is 5.880556669235229 and perplexity is 358.0084785551591
At time: 8.295608043670654 and batch: 400, loss is 5.810040216445923 and perplexity is 333.6325429198896
At time: 9.265654563903809 and batch: 450, loss is 5.705314693450927 and perplexity is 300.46001797251114
At time: 10.237095594406128 and batch: 500, loss is 5.658559904098511 and perplexity is 286.7354185852792
At time: 11.206712007522583 and batch: 550, loss is 5.587131328582764 and perplexity is 266.96867477645867
At time: 12.176743745803833 and batch: 600, loss is 5.599847106933594 and perplexity is 270.385064264106
At time: 13.1465585231781 and batch: 650, loss is 5.643334569931031 and perplexity is 282.40284217599515
At time: 14.117389917373657 and batch: 700, loss is 5.58061559677124 and perplexity is 265.23483324689056
At time: 15.087703704833984 and batch: 750, loss is 5.520013294219971 and perplexity is 249.63835591485048
At time: 16.058663845062256 and batch: 800, loss is 5.504698896408081 and perplexity is 245.84441989527753
At time: 17.02833080291748 and batch: 850, loss is 5.508295431137085 and perplexity is 246.73019980366263
At time: 17.998816967010498 and batch: 900, loss is 5.5006645393371585 and perplexity is 244.85459372017723
At time: 18.97108483314514 and batch: 950, loss is 5.533781785964965 and perplexity is 253.0992706716056
At time: 19.940377235412598 and batch: 1000, loss is 5.489581995010376 and perplexity is 242.15596329834574
At time: 20.911062002182007 and batch: 1050, loss is 5.380857496261597 and perplexity is 217.2084510258406
At time: 21.882976055145264 and batch: 1100, loss is 5.4615765571594235 and perplexity is 235.4683612175274
At time: 22.884390592575073 and batch: 1150, loss is 5.358562250137329 and perplexity is 212.4193209461621
At time: 23.926114320755005 and batch: 1200, loss is 5.44042332649231 and perplexity is 230.53975639299313
At time: 25.005038499832153 and batch: 1250, loss is 5.3811466503143315 and perplexity is 217.27126681102467
At time: 26.088531494140625 and batch: 1300, loss is 5.397687091827392 and perplexity is 220.8949152500739
At time: 27.171645164489746 and batch: 1350, loss is 5.332435960769653 and perplexity is 206.94146195200818
At time: 28.25504493713379 and batch: 1400, loss is 5.341984996795654 and perplexity is 208.92701841498598
At time: 29.338929891586304 and batch: 1450, loss is 5.304129400253296 and perplexity is 201.1657912684497
At time: 30.421533584594727 and batch: 1500, loss is 5.269139709472657 and perplexity is 194.24878015751696
At time: 31.50472664833069 and batch: 1550, loss is 5.252198553085327 and perplexity is 190.98569941777555
At time: 32.587584257125854 and batch: 1600, loss is 5.281781091690063 and perplexity is 196.71993976082905
At time: 33.66967225074768 and batch: 1650, loss is 5.269936008453369 and perplexity is 194.4035218653164
At time: 34.75024700164795 and batch: 1700, loss is 5.290579051971435 and perplexity is 198.45830981969777
At time: 35.83337068557739 and batch: 1750, loss is 5.286605567932129 and perplexity is 197.67130350714774
At time: 36.91440224647522 and batch: 1800, loss is 5.256621532440185 and perplexity is 191.83229608301383
At time: 38.00373411178589 and batch: 1850, loss is 5.23847728729248 and perplexity is 188.38303066256768
At time: 39.09209728240967 and batch: 1900, loss is 5.290012474060059 and perplexity is 198.34589957261338
At time: 40.177924394607544 and batch: 1950, loss is 5.208398628234863 and perplexity is 182.80109117572462
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.8238956894985465 and perplexity of 124.44896217656884
finished 1 epochs...
Completing Train Step...
At time: 43.434584617614746 and batch: 50, loss is 5.036319103240967 and perplexity is 153.90247202261813
At time: 44.44848966598511 and batch: 100, loss is 4.98135627746582 and perplexity is 145.67181913904173
At time: 45.437724351882935 and batch: 150, loss is 4.918181619644165 and perplexity is 136.75371668878518
At time: 46.428351163864136 and batch: 200, loss is 4.8864503097534175 and perplexity is 132.48246668351334
At time: 47.42360258102417 and batch: 250, loss is 4.891617136001587 and perplexity is 133.16875200153265
At time: 48.42165780067444 and batch: 300, loss is 4.899113616943359 and perplexity is 134.1708002380156
At time: 49.4244441986084 and batch: 350, loss is 4.896372480392456 and perplexity is 133.80352336142587
At time: 50.42710471153259 and batch: 400, loss is 4.848942499160767 and perplexity is 127.60537567794304
At time: 51.4289665222168 and batch: 450, loss is 4.817344379425049 and perplexity is 123.63632326827184
At time: 52.45453214645386 and batch: 500, loss is 4.8082984447479244 and perplexity is 122.52296045998237
At time: 53.45658540725708 and batch: 550, loss is 4.766778259277344 and perplexity is 117.53994805824385
At time: 54.458373069763184 and batch: 600, loss is 4.7550735187530515 and perplexity is 116.17219368527006
At time: 55.46119976043701 and batch: 650, loss is 4.8226342868804934 and perplexity is 124.29208089589604
At time: 56.469659090042114 and batch: 700, loss is 4.819484653472901 and perplexity is 123.9012222594326
At time: 57.472434282302856 and batch: 750, loss is 4.778600845336914 and perplexity is 118.93782116505105
At time: 58.47515320777893 and batch: 800, loss is 4.755421457290649 and perplexity is 116.21262150124014
At time: 59.47802805900574 and batch: 850, loss is 4.74582992553711 and perplexity is 115.10329303615363
At time: 60.48061490058899 and batch: 900, loss is 4.738136854171753 and perplexity is 114.22119256982556
At time: 61.483474254608154 and batch: 950, loss is 4.807788600921631 and perplexity is 122.46050880666041
At time: 62.485706090927124 and batch: 1000, loss is 4.7769841289520265 and perplexity is 118.74568779522362
At time: 63.48702359199524 and batch: 1050, loss is 4.69016360282898 and perplexity is 108.87098995243124
At time: 64.48814964294434 and batch: 1100, loss is 4.752009382247925 and perplexity is 115.81677103556282
At time: 65.49850845336914 and batch: 1150, loss is 4.686375894546509 and perplexity is 108.45939838853816
At time: 66.50132536888123 and batch: 1200, loss is 4.770740833282471 and perplexity is 118.00663282679301
At time: 67.50276684761047 and batch: 1250, loss is 4.732206659317017 and perplexity is 113.54584309750773
At time: 68.50703191757202 and batch: 1300, loss is 4.749839372634888 and perplexity is 115.56572001913962
At time: 69.50913524627686 and batch: 1350, loss is 4.635777444839477 and perplexity is 103.10804766255896
At time: 70.53452372550964 and batch: 1400, loss is 4.654880323410034 and perplexity is 105.09664163855885
At time: 71.55394148826599 and batch: 1450, loss is 4.603878479003907 and perplexity is 99.87091269101941
At time: 72.5660548210144 and batch: 1500, loss is 4.590103235244751 and perplexity is 98.50459878342173
At time: 73.57325482368469 and batch: 1550, loss is 4.592674560546875 and perplexity is 98.75821207204729
At time: 74.5761034488678 and batch: 1600, loss is 4.652797155380249 and perplexity is 104.8779355545119
At time: 75.5784010887146 and batch: 1650, loss is 4.6137208652496335 and perplexity is 100.85873407384693
At time: 76.59706425666809 and batch: 1700, loss is 4.639914340972901 and perplexity is 103.5354784550713
At time: 77.59999823570251 and batch: 1750, loss is 4.63873857498169 and perplexity is 103.41381649763179
At time: 78.60274744033813 and batch: 1800, loss is 4.594845466613769 and perplexity is 98.9728397577706
At time: 79.60527896881104 and batch: 1850, loss is 4.615065002441407 and perplexity is 100.99439320124533
At time: 80.60761332511902 and batch: 1900, loss is 4.69957015991211 and perplexity is 109.89992290545554
At time: 81.61042046546936 and batch: 1950, loss is 4.619476900100708 and perplexity is 101.44095449522284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.526144338208575 and perplexity of 92.40160403735321
finished 2 epochs...
Completing Train Step...
At time: 84.80932021141052 and batch: 50, loss is 4.581738996505737 and perplexity is 97.68411893041741
At time: 85.79019045829773 and batch: 100, loss is 4.541795349121093 and perplexity is 93.85915890129623
At time: 86.74881219863892 and batch: 150, loss is 4.499599390029907 and perplexity is 89.98107676262951
At time: 87.71664500236511 and batch: 200, loss is 4.492027912139893 and perplexity is 89.30235971736609
At time: 88.68180680274963 and batch: 250, loss is 4.490381231307984 and perplexity is 89.15542824119905
At time: 89.65351605415344 and batch: 300, loss is 4.514475965499878 and perplexity is 91.3296935697593
At time: 90.62602066993713 and batch: 350, loss is 4.517213430404663 and perplexity is 91.58004791244439
At time: 91.60842728614807 and batch: 400, loss is 4.484357595443726 and perplexity is 88.62000262956654
At time: 92.58840489387512 and batch: 450, loss is 4.481938714981079 and perplexity is 88.4059004847461
At time: 93.57396078109741 and batch: 500, loss is 4.475273303985595 and perplexity is 87.81859830317113
At time: 94.56128454208374 and batch: 550, loss is 4.445334844589233 and perplexity is 85.22841133229632
At time: 95.54925990104675 and batch: 600, loss is 4.432421054840088 and perplexity is 84.13486565432177
At time: 96.53641772270203 and batch: 650, loss is 4.499689226150513 and perplexity is 89.98916067660208
At time: 97.52419376373291 and batch: 700, loss is 4.512801952362061 and perplexity is 91.1769343589869
At time: 98.51236820220947 and batch: 750, loss is 4.482338371276856 and perplexity is 88.44123952072236
At time: 99.50110960006714 and batch: 800, loss is 4.4512332153320315 and perplexity is 85.73260560073973
At time: 100.49037957191467 and batch: 850, loss is 4.446478853225708 and perplexity is 85.32596916379444
At time: 101.51960110664368 and batch: 900, loss is 4.431778879165649 and perplexity is 84.08085363468514
At time: 102.50736403465271 and batch: 950, loss is 4.511591958999634 and perplexity is 91.06667759203626
At time: 103.5023181438446 and batch: 1000, loss is 4.4885053539276125 and perplexity is 88.9883403572125
At time: 104.49869799613953 and batch: 1050, loss is 4.415427284240723 and perplexity is 82.71717710248365
At time: 105.49529147148132 and batch: 1100, loss is 4.469522361755371 and perplexity is 87.31500806472484
At time: 106.49170708656311 and batch: 1150, loss is 4.418584079742431 and perplexity is 82.97871090224633
At time: 107.48746538162231 and batch: 1200, loss is 4.502348594665527 and perplexity is 90.2287935119784
At time: 108.48516583442688 and batch: 1250, loss is 4.478371362686158 and perplexity is 88.09108735130357
At time: 109.48032069206238 and batch: 1300, loss is 4.482574529647827 and perplexity is 88.46212812618671
At time: 110.47443056106567 and batch: 1350, loss is 4.367749547958374 and perplexity is 78.86594780675878
At time: 111.4704749584198 and batch: 1400, loss is 4.389024562835694 and perplexity is 80.56179767016607
At time: 112.46753191947937 and batch: 1450, loss is 4.331490058898925 and perplexity is 76.05753237972309
At time: 113.46351146697998 and batch: 1500, loss is 4.328907113075257 and perplexity is 75.8613333888666
At time: 114.46092247962952 and batch: 1550, loss is 4.339359645843506 and perplexity is 76.65843507038485
At time: 115.45804905891418 and batch: 1600, loss is 4.411484546661377 and perplexity is 82.39168706242063
At time: 116.46536207199097 and batch: 1650, loss is 4.369944400787354 and perplexity is 79.03923705804769
At time: 117.4633092880249 and batch: 1700, loss is 4.396334581375122 and perplexity is 81.15286362421307
At time: 118.46033334732056 and batch: 1750, loss is 4.393159332275391 and perplexity is 80.89559173437368
At time: 119.45604157447815 and batch: 1800, loss is 4.3496864223480225 and perplexity is 77.45417121964499
At time: 120.45231461524963 and batch: 1850, loss is 4.381746616363525 and perplexity is 79.97760167128892
At time: 121.44873452186584 and batch: 1900, loss is 4.466045742034912 and perplexity is 87.01197405802483
At time: 122.44580602645874 and batch: 1950, loss is 4.392776403427124 and perplexity is 80.86462040888642
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.435844102016715 and perplexity of 84.42335674627112
finished 3 epochs...
Completing Train Step...
At time: 125.60620450973511 and batch: 50, loss is 4.368656582832337 and perplexity is 78.93751442358973
At time: 126.59077906608582 and batch: 100, loss is 4.333649225234986 and perplexity is 76.22193066098978
At time: 127.54857516288757 and batch: 150, loss is 4.296743850708008 and perplexity is 73.46020644613922
At time: 128.51403951644897 and batch: 200, loss is 4.294136695861816 and perplexity is 73.26893376000031
At time: 129.47867369651794 and batch: 250, loss is 4.2844203662872316 and perplexity is 72.56047603001572
At time: 130.44354486465454 and batch: 300, loss is 4.309050931930542 and perplexity is 74.36987336401212
At time: 131.41375350952148 and batch: 350, loss is 4.317742080688476 and perplexity is 75.0190499553415
At time: 132.38868927955627 and batch: 400, loss is 4.281054177284241 and perplexity is 72.3166343923234
At time: 133.36183261871338 and batch: 450, loss is 4.301827001571655 and perplexity is 73.83456641600942
At time: 134.33436608314514 and batch: 500, loss is 4.294947080612182 and perplexity is 73.32833385180851
At time: 135.3070788383484 and batch: 550, loss is 4.269607877731323 and perplexity is 71.4935958910609
At time: 136.27980661392212 and batch: 600, loss is 4.25599778175354 and perplexity is 70.52715279899476
At time: 137.25882768630981 and batch: 650, loss is 4.317357730865479 and perplexity is 74.99022193714644
At time: 138.24197936058044 and batch: 700, loss is 4.333189735412597 and perplexity is 76.1869155047783
At time: 139.24025893211365 and batch: 750, loss is 4.310805907249451 and perplexity is 74.50050525057658
At time: 140.22459316253662 and batch: 800, loss is 4.2770951557159425 and perplexity is 72.03089726994929
At time: 141.20800590515137 and batch: 850, loss is 4.275675506591797 and perplexity is 71.92871122105815
At time: 142.19070506095886 and batch: 900, loss is 4.257433304786682 and perplexity is 70.62846885466669
At time: 143.17308521270752 and batch: 950, loss is 4.342654027938843 and perplexity is 76.91139368872989
At time: 144.15519285202026 and batch: 1000, loss is 4.3244584369659425 and perplexity is 75.52460045063631
At time: 145.1384880542755 and batch: 1050, loss is 4.261602144241333 and perplexity is 70.92352218992593
At time: 146.1221888065338 and batch: 1100, loss is 4.305332117080688 and perplexity is 74.09381918988815
At time: 147.10458135604858 and batch: 1150, loss is 4.2627534627914425 and perplexity is 71.00522478049136
At time: 148.0874378681183 and batch: 1200, loss is 4.33886076927185 and perplexity is 76.62020151081497
At time: 149.08620715141296 and batch: 1250, loss is 4.324731550216675 and perplexity is 75.54523003675408
At time: 150.08429884910583 and batch: 1300, loss is 4.324524135589599 and perplexity is 75.52956247593549
At time: 151.07569003105164 and batch: 1350, loss is 4.211280946731567 and perplexity is 67.44287523337005
At time: 152.0583074092865 and batch: 1400, loss is 4.237121033668518 and perplexity is 69.20831633598804
At time: 153.0398814678192 and batch: 1450, loss is 4.170877056121826 and perplexity is 64.77223608857976
At time: 154.02307057380676 and batch: 1500, loss is 4.175247573852539 and perplexity is 65.05594381809225
At time: 155.0053789615631 and batch: 1550, loss is 4.186884388923645 and perplexity is 65.81740973175408
At time: 155.98604917526245 and batch: 1600, loss is 4.2650475025177 and perplexity is 71.16830056655836
At time: 156.9666051864624 and batch: 1650, loss is 4.224557209014892 and perplexity is 68.34423463667082
At time: 157.94811153411865 and batch: 1700, loss is 4.247537684440613 and perplexity is 69.93300304922698
At time: 158.93062090873718 and batch: 1750, loss is 4.247134518623352 and perplexity is 69.90481413568415
At time: 159.910742521286 and batch: 1800, loss is 4.1984025526046755 and perplexity is 66.57988817617401
At time: 160.8916666507721 and batch: 1850, loss is 4.232282867431641 and perplexity is 68.87428370087075
At time: 161.8713846206665 and batch: 1900, loss is 4.318810348510742 and perplexity is 75.0992332134376
At time: 162.8518283367157 and batch: 1950, loss is 4.247633094787598 and perplexity is 69.93967569962848
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.397117721202761 and perplexity of 81.21644255619165
finished 4 epochs...
Completing Train Step...
At time: 166.03713512420654 and batch: 50, loss is 4.2298799324035645 and perplexity is 68.70898195624746
At time: 166.9983401298523 and batch: 100, loss is 4.196864252090454 and perplexity is 66.47754703585159
At time: 167.966477394104 and batch: 150, loss is 4.163418636322022 and perplexity is 64.29093466564228
At time: 168.92580437660217 and batch: 200, loss is 4.164656300544738 and perplexity is 64.3705545164798
At time: 169.90252685546875 and batch: 250, loss is 4.155083684921265 and perplexity is 63.75729984918561
At time: 170.88423490524292 and batch: 300, loss is 4.173752470016479 and perplexity is 64.95875110163777
At time: 171.85624051094055 and batch: 350, loss is 4.183862380981445 and perplexity is 65.61880923409406
At time: 172.82786512374878 and batch: 400, loss is 4.146718411445618 and perplexity is 63.226177190253225
At time: 173.79918766021729 and batch: 450, loss is 4.173529901504517 and perplexity is 64.94429493786923
At time: 174.77044701576233 and batch: 500, loss is 4.175258312225342 and perplexity is 65.05664241682088
At time: 175.76515436172485 and batch: 550, loss is 4.1436738729476925 and perplexity is 63.03397539107262
At time: 176.73941254615784 and batch: 600, loss is 4.13488498210907 and perplexity is 62.48240406282068
At time: 177.7110939025879 and batch: 650, loss is 4.195038499832154 and perplexity is 66.35628623399997
At time: 178.6838972568512 and batch: 700, loss is 4.210683526992798 and perplexity is 67.40259556159981
At time: 179.65875959396362 and batch: 750, loss is 4.190913715362549 and perplexity is 66.08314456759885
At time: 180.6399049758911 and batch: 800, loss is 4.159029712677002 and perplexity is 64.00938496434779
At time: 181.62181735038757 and batch: 850, loss is 4.15611653804779 and perplexity is 63.82318579506907
At time: 182.60300207138062 and batch: 900, loss is 4.136972026824951 and perplexity is 62.61294380781477
At time: 183.58406567573547 and batch: 950, loss is 4.225791254043579 and perplexity is 68.42862656067093
At time: 184.5664517879486 and batch: 1000, loss is 4.210113763809204 and perplexity is 67.36420298254777
At time: 185.54876971244812 and batch: 1050, loss is 4.147323832511902 and perplexity is 63.26446723949649
At time: 186.5311679840088 and batch: 1100, loss is 4.189402160644531 and perplexity is 65.9833317339304
At time: 187.51326608657837 and batch: 1150, loss is 4.147547330856323 and perplexity is 63.278608323380745
At time: 188.495774269104 and batch: 1200, loss is 4.228620343208313 and perplexity is 68.62249134771187
At time: 189.4779450893402 and batch: 1250, loss is 4.213500232696533 and perplexity is 67.59271646858733
At time: 190.46051001548767 and batch: 1300, loss is 4.215048394203186 and perplexity is 67.69744195542064
At time: 191.44274234771729 and batch: 1350, loss is 4.096853518486023 and perplexity is 60.15072637971582
At time: 192.42534708976746 and batch: 1400, loss is 4.127039837837219 and perplexity is 61.99413835021758
At time: 193.40729975700378 and batch: 1450, loss is 4.0575125026702885 and perplexity is 57.83027934849904
At time: 194.38885188102722 and batch: 1500, loss is 4.068900113105774 and perplexity is 58.49259196286684
At time: 195.3695511817932 and batch: 1550, loss is 4.0754814624786375 and perplexity is 58.878821708646015
At time: 196.35097694396973 and batch: 1600, loss is 4.162969436645508 and perplexity is 64.2620616839402
At time: 197.33224749565125 and batch: 1650, loss is 4.1202247619628904 and perplexity is 61.573079995593474
At time: 198.31293416023254 and batch: 1700, loss is 4.141172289848328 and perplexity is 62.876487729913016
At time: 199.29504370689392 and batch: 1750, loss is 4.145324397087097 and perplexity is 63.13810039583678
At time: 200.2772901058197 and batch: 1800, loss is 4.0935423994064335 and perplexity is 59.95188952985485
At time: 201.2595179080963 and batch: 1850, loss is 4.126008849143982 and perplexity is 61.930256031164454
At time: 202.24039220809937 and batch: 1900, loss is 4.209771461486817 and perplexity is 67.34114800553226
At time: 203.2196490764618 and batch: 1950, loss is 4.139220504760742 and perplexity is 62.75388602381345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379250885719477 and perplexity of 79.77824798998185
finished 5 epochs...
Completing Train Step...
At time: 206.36717581748962 and batch: 50, loss is 4.126132016181946 and perplexity is 61.93788426712409
At time: 207.29853558540344 and batch: 100, loss is 4.0955623483657835 and perplexity is 60.07311167677903
At time: 208.23786163330078 and batch: 150, loss is 4.06872220993042 and perplexity is 58.48218687059889
At time: 209.1935670375824 and batch: 200, loss is 4.0656955480575565 and perplexity is 58.30544866367235
At time: 210.15010571479797 and batch: 250, loss is 4.059888606071472 and perplexity is 57.96785345237138
At time: 211.10666942596436 and batch: 300, loss is 4.069806418418884 and perplexity is 58.545628139594484
At time: 212.0646994113922 and batch: 350, loss is 4.086126866340638 and perplexity is 59.50895862480922
At time: 213.03001809120178 and batch: 400, loss is 4.046436672210693 and perplexity is 57.193295055791786
At time: 213.99526739120483 and batch: 450, loss is 4.08074134349823 and perplexity is 59.189333216307055
At time: 214.965558052063 and batch: 500, loss is 4.087155861854553 and perplexity is 59.570224592068804
At time: 215.9368884563446 and batch: 550, loss is 4.054092783927917 and perplexity is 57.63285382062233
At time: 216.90812826156616 and batch: 600, loss is 4.047329459190369 and perplexity is 57.24437928521665
At time: 217.8798747062683 and batch: 650, loss is 4.101896481513977 and perplexity is 60.45483041717781
At time: 218.85401129722595 and batch: 700, loss is 4.119478821754456 and perplexity is 61.52716728566471
At time: 219.83286118507385 and batch: 750, loss is 4.10223614692688 and perplexity is 60.47536831992358
At time: 220.82066559791565 and batch: 800, loss is 4.073368816375733 and perplexity is 58.75456289908125
At time: 221.79860496520996 and batch: 850, loss is 4.072335638999939 and perplexity is 58.69389036211264
At time: 222.77041220664978 and batch: 900, loss is 4.046776781082153 and perplexity is 57.21275031109321
At time: 223.76441311836243 and batch: 950, loss is 4.13933048248291 and perplexity is 62.76078793277666
At time: 224.7364604473114 and batch: 1000, loss is 4.119525899887085 and perplexity is 61.53006393799046
At time: 225.72291684150696 and batch: 1050, loss is 4.062907509803772 and perplexity is 58.143117240654824
At time: 226.69376230239868 and batch: 1100, loss is 4.104668231010437 and perplexity is 60.62262850264757
At time: 227.6660876274109 and batch: 1150, loss is 4.062472219467163 and perplexity is 58.117813611191906
At time: 228.63689184188843 and batch: 1200, loss is 4.139661378860474 and perplexity is 62.781558686450744
At time: 229.60794973373413 and batch: 1250, loss is 4.132976655960083 and perplexity is 62.36328095631653
At time: 230.57890725135803 and batch: 1300, loss is 4.125352430343628 and perplexity is 61.889617186304946
At time: 231.550395488739 and batch: 1350, loss is 4.015152020454407 and perplexity is 55.43172151750036
At time: 232.52208995819092 and batch: 1400, loss is 4.046974430084228 and perplexity is 57.22405947168351
At time: 233.49285459518433 and batch: 1450, loss is 3.9744769954681396 and perplexity is 53.22227413485416
At time: 234.4641137123108 and batch: 1500, loss is 3.986451573371887 and perplexity is 53.86341946387994
At time: 235.43999648094177 and batch: 1550, loss is 3.991460609436035 and perplexity is 54.13390013268546
At time: 236.41633534431458 and batch: 1600, loss is 4.081974868774414 and perplexity is 59.262389804220284
At time: 237.38741540908813 and batch: 1650, loss is 4.042791442871094 and perplexity is 56.9851919009232
At time: 238.35825395584106 and batch: 1700, loss is 4.05908757686615 and perplexity is 57.92143810129397
At time: 239.3304944038391 and batch: 1750, loss is 4.064588842391967 and perplexity is 58.24095738631497
At time: 240.30239176750183 and batch: 1800, loss is 4.013731355667114 and perplexity is 55.35302753476217
At time: 241.2735288143158 and batch: 1850, loss is 4.0446455717086796 and perplexity is 57.09094780077664
At time: 242.24528455734253 and batch: 1900, loss is 4.127999119758606 and perplexity is 62.05363673967092
At time: 243.21625804901123 and batch: 1950, loss is 4.061447291374207 and perplexity is 58.05827754662492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.377769008902616 and perplexity of 79.66011400542033
finished 6 epochs...
Completing Train Step...
At time: 246.3530924320221 and batch: 50, loss is 4.0485469388961794 and perplexity is 57.31411559792694
At time: 247.3005247116089 and batch: 100, loss is 4.0174159955978395 and perplexity is 55.55735972439832
At time: 248.2719841003418 and batch: 150, loss is 3.9905729866027833 and perplexity is 54.08587096592068
At time: 249.21872997283936 and batch: 200, loss is 3.9895489025115967 and perplexity is 54.030510837458166
At time: 250.1657247543335 and batch: 250, loss is 3.982879252433777 and perplexity is 53.67134532223229
At time: 251.12284994125366 and batch: 300, loss is 3.9936504125595094 and perplexity is 54.25257260353364
At time: 252.08038449287415 and batch: 350, loss is 4.009550576210022 and perplexity is 55.12209181638603
At time: 253.04364609718323 and batch: 400, loss is 3.973211612701416 and perplexity is 53.15497017797221
At time: 254.00890707969666 and batch: 450, loss is 4.004762225151062 and perplexity is 54.858778810330534
At time: 254.97412085533142 and batch: 500, loss is 4.021332111358642 and perplexity is 55.77535534589054
At time: 255.93895602226257 and batch: 550, loss is 3.9821042346954347 and perplexity is 53.62976519231726
At time: 256.9032645225525 and batch: 600, loss is 3.978226170539856 and perplexity is 53.42218828069536
At time: 257.86767292022705 and batch: 650, loss is 4.02969982624054 and perplexity is 56.244025732309154
At time: 258.83174300193787 and batch: 700, loss is 4.052199988365174 and perplexity is 57.52386978542939
At time: 259.7990815639496 and batch: 750, loss is 4.030723481178284 and perplexity is 56.301629685223936
At time: 260.76973366737366 and batch: 800, loss is 4.003716387748718 and perplexity is 54.80143543875192
At time: 261.74091029167175 and batch: 850, loss is 4.001269907951355 and perplexity is 54.66752870093781
At time: 262.71148705482483 and batch: 900, loss is 3.9763799619674685 and perplexity is 53.32365076712562
At time: 263.6807098388672 and batch: 950, loss is 4.073777666091919 and perplexity is 58.77858959676678
At time: 264.65076327323914 and batch: 1000, loss is 4.053584156036377 and perplexity is 57.60354759731317
At time: 265.6209843158722 and batch: 1050, loss is 3.99682231426239 and perplexity is 54.42492963623681
At time: 266.5936441421509 and batch: 1100, loss is 4.038330917358398 and perplexity is 56.731574053546964
At time: 267.56326699256897 and batch: 1150, loss is 3.993667387962341 and perplexity is 54.253493570625125
At time: 268.5344603061676 and batch: 1200, loss is 4.072194924354553 and perplexity is 58.68563185320424
At time: 269.50486636161804 and batch: 1250, loss is 4.0648317670822145 and perplexity is 58.255107271456374
At time: 270.47699451446533 and batch: 1300, loss is 4.059311227798462 and perplexity is 57.934393733641784
At time: 271.44861698150635 and batch: 1350, loss is 3.95197802066803 and perplexity is 52.038197731123816
At time: 272.4186158180237 and batch: 1400, loss is 3.983837814331055 and perplexity is 53.722817294428275
At time: 273.3881266117096 and batch: 1450, loss is 3.906472520828247 and perplexity is 49.72324454397372
At time: 274.3612813949585 and batch: 1500, loss is 3.917962770462036 and perplexity is 50.29787202083818
At time: 275.33558678627014 and batch: 1550, loss is 3.9235580587387084 and perplexity is 50.580091929076204
At time: 276.3088767528534 and batch: 1600, loss is 4.018614230155944 and perplexity is 55.62397037239757
At time: 277.29545736312866 and batch: 1650, loss is 3.978494448661804 and perplexity is 53.43652220769121
At time: 278.26897048950195 and batch: 1700, loss is 3.99389102935791 and perplexity is 54.26562825449998
At time: 279.241726398468 and batch: 1750, loss is 3.9999011039733885 and perplexity is 54.592750760033354
At time: 280.21351075172424 and batch: 1800, loss is 3.9515147399902344 and perplexity is 52.01409502319821
At time: 281.18448877334595 and batch: 1850, loss is 3.9782844591140747 and perplexity is 53.425302274636145
At time: 282.15627360343933 and batch: 1900, loss is 4.064253230094909 and perplexity is 58.22141428445977
At time: 283.1266040802002 and batch: 1950, loss is 3.999548382759094 and perplexity is 54.57349813429797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.373685898891715 and perplexity of 79.3355161318376
finished 7 epochs...
Completing Train Step...
At time: 286.2531569004059 and batch: 50, loss is 3.9875718116760255 and perplexity is 53.92379313969361
At time: 287.2206230163574 and batch: 100, loss is 3.9551445627212525 and perplexity is 52.20324004141496
At time: 288.16390085220337 and batch: 150, loss is 3.929614157676697 and perplexity is 50.88733939154819
At time: 289.1083197593689 and batch: 200, loss is 3.9285105991363527 and perplexity is 50.831213208527615
At time: 290.05217123031616 and batch: 250, loss is 3.920630598068237 and perplexity is 50.43223722425488
At time: 290.9951922893524 and batch: 300, loss is 3.92950900554657 and perplexity is 50.8819887607347
At time: 291.94163274765015 and batch: 350, loss is 3.948610682487488 and perplexity is 51.863262219869256
At time: 292.88984966278076 and batch: 400, loss is 3.9095135927200317 and perplexity is 49.874686661795735
At time: 293.8455159664154 and batch: 450, loss is 3.94570228099823 and perplexity is 51.712642168753746
At time: 294.8024733066559 and batch: 500, loss is 3.96572859287262 and perplexity is 52.75869499877983
At time: 295.7631211280823 and batch: 550, loss is 3.924107093811035 and perplexity is 50.607869798321225
At time: 296.74244141578674 and batch: 600, loss is 3.9209428310394285 and perplexity is 50.44798629008809
At time: 297.69843554496765 and batch: 650, loss is 3.9685238361358643 and perplexity is 52.90637468972685
At time: 298.65598011016846 and batch: 700, loss is 3.9958133554458617 and perplexity is 54.370044816558796
At time: 299.6128795146942 and batch: 750, loss is 3.976817545890808 and perplexity is 53.346989445377886
At time: 300.5704584121704 and batch: 800, loss is 3.9473970127105713 and perplexity is 51.80035552767801
At time: 301.5268006324768 and batch: 850, loss is 3.9438432359695437 and perplexity is 51.61659534375784
At time: 302.48379254341125 and batch: 900, loss is 3.9173829221725462 and perplexity is 50.26871533982465
At time: 303.4414002895355 and batch: 950, loss is 4.0181570148468015 and perplexity is 55.5985440546818
At time: 304.40630769729614 and batch: 1000, loss is 3.9961882781982423 and perplexity is 54.39043320520504
At time: 305.3704824447632 and batch: 1050, loss is 3.945982985496521 and perplexity is 51.727160177568905
At time: 306.3355197906494 and batch: 1100, loss is 3.9771816539764404 and perplexity is 53.36641705223882
At time: 307.30125761032104 and batch: 1150, loss is 3.9341521739959715 and perplexity is 51.11879173821184
At time: 308.26643538475037 and batch: 1200, loss is 4.018488893508911 and perplexity is 55.616999087344276
At time: 309.23207902908325 and batch: 1250, loss is 4.009438486099243 and perplexity is 55.11591352127733
At time: 310.1971638202667 and batch: 1300, loss is 4.002644634246826 and perplexity is 54.742733271157604
At time: 311.16240644454956 and batch: 1350, loss is 3.8959741735458375 and perplexity is 49.20396322195741
At time: 312.1280748844147 and batch: 1400, loss is 3.9338186502456667 and perplexity is 51.10174524994263
At time: 313.09267497062683 and batch: 1450, loss is 3.849818534851074 and perplexity is 46.98453640204607
At time: 314.0580897331238 and batch: 1500, loss is 3.8621436977386474 and perplexity is 47.5672118753079
At time: 315.0236191749573 and batch: 1550, loss is 3.868408341407776 and perplexity is 47.86613886594624
At time: 315.9890959262848 and batch: 1600, loss is 3.9640445852279664 and perplexity is 52.66992371981488
At time: 316.95361518859863 and batch: 1650, loss is 3.9242588567733763 and perplexity is 50.61555078138922
At time: 317.91700625419617 and batch: 1700, loss is 3.9429481554031374 and perplexity is 51.57041500300755
At time: 318.8804337978363 and batch: 1750, loss is 3.9495139694213868 and perplexity is 51.91013079167932
At time: 319.84581112861633 and batch: 1800, loss is 3.9011012840270998 and perplexity is 49.45688520293019
At time: 320.81066250801086 and batch: 1850, loss is 3.927179703712463 and perplexity is 50.76360717773525
At time: 321.7759485244751 and batch: 1900, loss is 4.011956434249878 and perplexity is 55.25486739971474
At time: 322.7415511608124 and batch: 1950, loss is 3.9448445415496827 and perplexity is 51.668305213073246
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.379537041242733 and perplexity of 79.80108024291168
Annealing...
finished 8 epochs...
Completing Train Step...
At time: 325.84203720092773 and batch: 50, loss is 3.968607006072998 and perplexity is 52.910775092571846
At time: 326.79714179039 and batch: 100, loss is 3.95941828250885 and perplexity is 52.4268194789894
At time: 327.7329831123352 and batch: 150, loss is 3.935025701522827 and perplexity is 51.16346491872054
At time: 328.6755037307739 and batch: 200, loss is 3.9296395492553713 and perplexity is 50.88863151783436
At time: 329.62366580963135 and batch: 250, loss is 3.9227915048599242 and perplexity is 50.54133442017594
At time: 330.5790934562683 and batch: 300, loss is 3.926801333427429 and perplexity is 50.744403370522164
At time: 331.53410959243774 and batch: 350, loss is 3.9347732973098757 and perplexity is 51.15055267424688
At time: 332.4896447658539 and batch: 400, loss is 3.8974814796447754 and perplexity is 49.27818457891339
At time: 333.4461534023285 and batch: 450, loss is 3.916467933654785 and perplexity is 50.22274107865413
At time: 334.4033179283142 and batch: 500, loss is 3.9310737562179567 and perplexity is 50.9616687101791
At time: 335.3597044944763 and batch: 550, loss is 3.8891371154785155 and perplexity is 48.86870028036423
At time: 336.31562972068787 and batch: 600, loss is 3.867047724723816 and perplexity is 47.801055685479675
At time: 337.2709765434265 and batch: 650, loss is 3.9040355253219605 and perplexity is 49.602216752452236
At time: 338.2262191772461 and batch: 700, loss is 3.9323017406463623 and perplexity is 51.024287285249535
At time: 339.1818096637726 and batch: 750, loss is 3.903471784591675 and perplexity is 49.57426184295731
At time: 340.13728857040405 and batch: 800, loss is 3.87450767993927 and perplexity is 48.158982820430005
At time: 341.0940372943878 and batch: 850, loss is 3.8618180418014525 and perplexity is 47.551723852365086
At time: 342.04923939704895 and batch: 900, loss is 3.825311207771301 and perplexity is 45.84706610967792
At time: 343.00335121154785 and batch: 950, loss is 3.9252660942077635 and perplexity is 50.666558342948704
At time: 343.95805978775024 and batch: 1000, loss is 3.9018498945236204 and perplexity is 49.493923008033434
At time: 344.9389135837555 and batch: 1050, loss is 3.8391624689102173 and perplexity is 46.4865242217651
At time: 345.89548420906067 and batch: 1100, loss is 3.864680776596069 and perplexity is 47.688046861992646
At time: 346.85204100608826 and batch: 1150, loss is 3.82367253780365 and perplexity is 45.77199942090097
At time: 347.80749225616455 and batch: 1200, loss is 3.8847503995895387 and perplexity is 48.654796686534645
At time: 348.7638096809387 and batch: 1250, loss is 3.8725027799606324 and perplexity is 48.06252560264919
At time: 349.72043633461 and batch: 1300, loss is 3.865837984085083 and perplexity is 47.74326376950537
At time: 350.67756056785583 and batch: 1350, loss is 3.753765821456909 and perplexity is 42.68151068633209
At time: 351.6337068080902 and batch: 1400, loss is 3.779749245643616 and perplexity is 43.80505604964113
At time: 352.5888214111328 and batch: 1450, loss is 3.6922277069091796 and perplexity is 40.13415457819884
At time: 353.54433584213257 and batch: 1500, loss is 3.6960173559188845 and perplexity is 40.28653749386438
At time: 354.5007300376892 and batch: 1550, loss is 3.699072437286377 and perplexity is 40.40980434317381
At time: 355.4563045501709 and batch: 1600, loss is 3.7871791744232177 and perplexity is 44.131736600054325
At time: 356.4213480949402 and batch: 1650, loss is 3.74366162776947 and perplexity is 42.252419894373446
At time: 357.3773741722107 and batch: 1700, loss is 3.750541453361511 and perplexity is 42.544111416961776
At time: 358.3341031074524 and batch: 1750, loss is 3.7447551822662355 and perplexity is 42.29865049137967
At time: 359.29132866859436 and batch: 1800, loss is 3.692324833869934 and perplexity is 40.13805287596731
At time: 360.2488648891449 and batch: 1850, loss is 3.703467926979065 and perplexity is 40.58781615959607
At time: 361.2066388130188 and batch: 1900, loss is 3.785021162033081 and perplexity is 44.03660245292739
At time: 362.1728558540344 and batch: 1950, loss is 3.7136213874816892 and perplexity is 41.00202220174051
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.296728515625 and perplexity of 73.45907993641318
finished 9 epochs...
Completing Train Step...
At time: 365.29972982406616 and batch: 50, loss is 3.879394326210022 and perplexity is 48.39489467367073
At time: 366.2743773460388 and batch: 100, loss is 3.866023201942444 and perplexity is 47.752107493506685
At time: 367.2158536911011 and batch: 150, loss is 3.835658617019653 and perplexity is 46.32392735001297
At time: 368.1816945075989 and batch: 200, loss is 3.827294511795044 and perplexity is 45.938085009610084
At time: 369.14515495300293 and batch: 250, loss is 3.817812819480896 and perplexity is 45.50457268510038
At time: 370.08845925331116 and batch: 300, loss is 3.822397313117981 and perplexity is 45.713667038678906
At time: 371.04288125038147 and batch: 350, loss is 3.8374377870559693 and perplexity is 46.40641885496533
At time: 371.99995827674866 and batch: 400, loss is 3.802137861251831 and perplexity is 44.79685164865541
At time: 372.9562966823578 and batch: 450, loss is 3.8298544025421144 and perplexity is 46.055832133951235
At time: 373.9127502441406 and batch: 500, loss is 3.8482049608230593 and perplexity is 46.90878450647082
At time: 374.86939764022827 and batch: 550, loss is 3.8091146039962767 and perplexity is 45.11048054026159
At time: 375.8261601924896 and batch: 600, loss is 3.7909927654266355 and perplexity is 44.30035831648577
At time: 376.78339171409607 and batch: 650, loss is 3.828900113105774 and perplexity is 46.01190250398863
At time: 377.7399582862854 and batch: 700, loss is 3.8585952711105347 and perplexity is 47.398722227433396
At time: 378.69511103630066 and batch: 750, loss is 3.8325777530670164 and perplexity is 46.181429253432974
At time: 379.65139985084534 and batch: 800, loss is 3.805347452163696 and perplexity is 44.9408622004395
At time: 380.60819816589355 and batch: 850, loss is 3.796858911514282 and perplexity is 44.560994407388
At time: 381.5644783973694 and batch: 900, loss is 3.7600232315063478 and perplexity is 42.94942374698356
At time: 382.5209176540375 and batch: 950, loss is 3.8644462490081786 and perplexity is 47.676864010785714
At time: 383.47731709480286 and batch: 1000, loss is 3.8406193351745603 and perplexity is 46.55429822749433
At time: 384.43390130996704 and batch: 1050, loss is 3.7844079542160034 and perplexity is 44.009607141779526
At time: 385.39033937454224 and batch: 1100, loss is 3.8099490451812743 and perplexity is 45.14813829250406
At time: 386.34705662727356 and batch: 1150, loss is 3.771968970298767 and perplexity is 43.465563039161516
At time: 387.3041341304779 and batch: 1200, loss is 3.836376814842224 and perplexity is 46.35720904375809
At time: 388.25966691970825 and batch: 1250, loss is 3.8265896892547606 and perplexity is 45.90571821959936
At time: 389.2146625518799 and batch: 1300, loss is 3.823270387649536 and perplexity is 45.753595905016155
At time: 390.16897463798523 and batch: 1350, loss is 3.7120250034332276 and perplexity is 40.93661944539106
At time: 391.12525939941406 and batch: 1400, loss is 3.742151656150818 and perplexity is 42.18866808333914
At time: 392.0814733505249 and batch: 1450, loss is 3.6560642242431642 and perplexity is 38.70869393322484
At time: 393.0375452041626 and batch: 1500, loss is 3.66347354888916 and perplexity is 38.9965643589585
At time: 393.9929060935974 and batch: 1550, loss is 3.668682532310486 and perplexity is 39.20022679280756
At time: 394.94926857948303 and batch: 1600, loss is 3.761471667289734 and perplexity is 43.01167830419468
At time: 395.9068968296051 and batch: 1650, loss is 3.7213451766967776 and perplexity is 41.319939360685936
At time: 396.8634617328644 and batch: 1700, loss is 3.7315442037582396 and perplexity is 41.74351891836142
At time: 397.81999707221985 and batch: 1750, loss is 3.728539156913757 and perplexity is 41.61826597829038
At time: 398.77726221084595 and batch: 1800, loss is 3.680706958770752 and perplexity is 39.67443234837561
At time: 399.7339725494385 and batch: 1850, loss is 3.695330481529236 and perplexity is 40.258875204358915
At time: 400.7073669433594 and batch: 1900, loss is 3.7796165704727174 and perplexity is 43.79924459187013
At time: 401.663782119751 and batch: 1950, loss is 3.7090982580184937 and perplexity is 40.8169835394526
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2970924554869185 and perplexity of 73.48581948932133
Annealing...
finished 10 epochs...
Completing Train Step...
At time: 404.7446012496948 and batch: 50, loss is 3.859266414642334 and perplexity is 47.430544250649945
At time: 405.667444229126 and batch: 100, loss is 3.8742978954315186 and perplexity is 48.148880871578434
At time: 406.61603450775146 and batch: 150, loss is 3.8555489778518677 and perplexity is 47.25455152405426
At time: 407.5626583099365 and batch: 200, loss is 3.8531056785583497 and perplexity is 47.13923544491435
At time: 408.5079047679901 and batch: 250, loss is 3.84646005153656 and perplexity is 46.82700430303503
At time: 409.4632863998413 and batch: 300, loss is 3.846118378639221 and perplexity is 46.81100751779072
At time: 410.4122290611267 and batch: 350, loss is 3.85847469329834 and perplexity is 47.39300733775775
At time: 411.3584334850311 and batch: 400, loss is 3.817549047470093 and perplexity is 45.49257143532896
At time: 412.3061981201172 and batch: 450, loss is 3.8473942136764525 and perplexity is 46.87076875594439
At time: 413.25872135162354 and batch: 500, loss is 3.8648036336898803 and perplexity is 47.69390603675287
At time: 414.21613121032715 and batch: 550, loss is 3.828765044212341 and perplexity is 46.00568814692528
At time: 415.1721303462982 and batch: 600, loss is 3.8058993148803713 and perplexity is 44.96567023142723
At time: 416.1631646156311 and batch: 650, loss is 3.832678589820862 and perplexity is 46.186086273642296
At time: 417.12002062797546 and batch: 700, loss is 3.8572969102859496 and perplexity is 47.33722151705395
At time: 418.0787148475647 and batch: 750, loss is 3.825032877922058 and perplexity is 45.83430727834354
At time: 419.0531120300293 and batch: 800, loss is 3.8011999464035036 and perplexity is 44.75485571371989
At time: 420.03199791908264 and batch: 850, loss is 3.796822500228882 and perplexity is 44.55937191384164
At time: 421.00236654281616 and batch: 900, loss is 3.750647940635681 and perplexity is 42.54864206464243
At time: 421.9671688079834 and batch: 950, loss is 3.8590624380111693 and perplexity is 47.42087051466096
At time: 422.94031143188477 and batch: 1000, loss is 3.8289460849761965 and perplexity is 46.01401780583025
At time: 423.9005079269409 and batch: 1050, loss is 3.770401773452759 and perplexity is 43.39749729599697
At time: 424.86165046691895 and batch: 1100, loss is 3.7934328603744505 and perplexity is 44.40858738790518
At time: 425.8209044933319 and batch: 1150, loss is 3.7596938896179197 and perplexity is 42.93528103168195
At time: 426.77948927879333 and batch: 1200, loss is 3.8151017475128173 and perplexity is 45.381373589939614
At time: 427.735915184021 and batch: 1250, loss is 3.8019941425323487 and perplexity is 44.79041396511853
At time: 428.70155215263367 and batch: 1300, loss is 3.7983021688461305 and perplexity is 44.625353821707535
At time: 429.6663932800293 and batch: 1350, loss is 3.684969720840454 and perplexity is 39.843915991306986
At time: 430.6235508918762 and batch: 1400, loss is 3.7121234226226805 and perplexity is 40.94064859256526
At time: 431.6070957183838 and batch: 1450, loss is 3.623312168121338 and perplexity is 37.46144115532936
At time: 432.57227659225464 and batch: 1500, loss is 3.6271388959884643 and perplexity is 37.60507053614438
At time: 433.550252199173 and batch: 1550, loss is 3.63303750038147 and perplexity is 37.82754346525542
At time: 434.50710010528564 and batch: 1600, loss is 3.721461682319641 and perplexity is 41.32475364639806
At time: 435.4613332748413 and batch: 1650, loss is 3.675674867630005 and perplexity is 39.47528846415459
At time: 436.4165790081024 and batch: 1700, loss is 3.678834023475647 and perplexity is 39.60019424699881
At time: 437.37334418296814 and batch: 1750, loss is 3.6737244844436647 and perplexity is 39.398371558360694
At time: 438.34724617004395 and batch: 1800, loss is 3.630324568748474 and perplexity is 37.72505900551347
At time: 439.30407547950745 and batch: 1850, loss is 3.637195334434509 and perplexity is 37.985151540674416
At time: 440.26041555404663 and batch: 1900, loss is 3.726464605331421 and perplexity is 41.53201623445552
At time: 441.21743273735046 and batch: 1950, loss is 3.659400477409363 and perplexity is 38.83805160089763
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.266769905977471 and perplexity of 71.29098672087771
finished 11 epochs...
Completing Train Step...
At time: 444.31071496009827 and batch: 50, loss is 3.843824143409729 and perplexity is 46.70373515628332
At time: 445.2335510253906 and batch: 100, loss is 3.840447630882263 and perplexity is 46.54630534088989
At time: 446.157452583313 and batch: 150, loss is 3.8151391410827635 and perplexity is 45.383070593235516
At time: 447.0901906490326 and batch: 200, loss is 3.810272912979126 and perplexity is 45.162762688687614
At time: 448.0326237678528 and batch: 250, loss is 3.802403283119202 and perplexity is 44.808743290753455
At time: 448.9753942489624 and batch: 300, loss is 3.799456601142883 and perplexity is 44.67690051927482
At time: 449.92339158058167 and batch: 350, loss is 3.814974751472473 and perplexity is 45.37561070112808
At time: 450.8713734149933 and batch: 400, loss is 3.7757456493377686 and perplexity is 43.63002889189375
At time: 451.8198127746582 and batch: 450, loss is 3.8090274858474733 and perplexity is 45.10655076988494
At time: 452.7751319408417 and batch: 500, loss is 3.8265923500061034 and perplexity is 45.90584036346325
At time: 453.7387251853943 and batch: 550, loss is 3.7920392465591433 and perplexity is 44.34674207125642
At time: 454.7025215625763 and batch: 600, loss is 3.772056527137756 and perplexity is 43.46936891307883
At time: 455.6612741947174 and batch: 650, loss is 3.801608557701111 and perplexity is 44.77314679010304
At time: 456.6199131011963 and batch: 700, loss is 3.827824559211731 and perplexity is 45.962440827195834
At time: 457.5796949863434 and batch: 750, loss is 3.797451558113098 and perplexity is 44.5874111562884
At time: 458.54130125045776 and batch: 800, loss is 3.772937650680542 and perplexity is 43.507687676721424
At time: 459.5051465034485 and batch: 850, loss is 3.7696561002731324 and perplexity is 43.36514900832458
At time: 460.4687349796295 and batch: 900, loss is 3.724910550117493 and perplexity is 41.46752331384086
At time: 461.4307289123535 and batch: 950, loss is 3.8338282823562624 and perplexity is 46.239216608192706
At time: 462.39030027389526 and batch: 1000, loss is 3.8043511581420897 and perplexity is 44.89611018488788
At time: 463.37368750572205 and batch: 1050, loss is 3.7487896347045897 and perplexity is 42.46964709187981
At time: 464.33369517326355 and batch: 1100, loss is 3.772643790245056 and perplexity is 43.49490436702022
At time: 465.2920751571655 and batch: 1150, loss is 3.740406470298767 and perplexity is 42.115105225783054
At time: 466.25195574760437 and batch: 1200, loss is 3.7977798318862916 and perplexity is 44.60205043670005
At time: 467.2114589214325 and batch: 1250, loss is 3.7865690422058105 and perplexity is 44.10481861834348
At time: 468.1693124771118 and batch: 1300, loss is 3.7839338684082033 and perplexity is 43.98874775658668
At time: 469.1274104118347 and batch: 1350, loss is 3.6720379829406737 and perplexity is 39.331982144171405
At time: 470.08525943756104 and batch: 1400, loss is 3.700972247123718 and perplexity is 40.48664825829036
At time: 471.0434765815735 and batch: 1450, loss is 3.613681921958923 and perplexity is 37.102409810279866
At time: 472.00317192077637 and batch: 1500, loss is 3.6198622179031372 and perplexity is 37.33242372805754
At time: 472.9627161026001 and batch: 1550, loss is 3.6273800849914553 and perplexity is 37.614141559485965
At time: 473.9214437007904 and batch: 1600, loss is 3.718211193084717 and perplexity is 41.19064605525336
At time: 474.8800690174103 and batch: 1650, loss is 3.6737694692611695 and perplexity is 39.40014392677977
At time: 475.8386740684509 and batch: 1700, loss is 3.6792551279067993 and perplexity is 39.61687357589389
At time: 476.8100390434265 and batch: 1750, loss is 3.6755501079559325 and perplexity is 39.47036384723507
At time: 477.7780554294586 and batch: 1800, loss is 3.633992099761963 and perplexity is 37.86367085566172
At time: 478.7450866699219 and batch: 1850, loss is 3.642294793128967 and perplexity is 38.179349984594865
At time: 479.70308804512024 and batch: 1900, loss is 3.7322409677505495 and perplexity is 41.772614434432896
At time: 480.6618580818176 and batch: 1950, loss is 3.665143427848816 and perplexity is 39.06173830243409
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.265547499545785 and perplexity of 71.20389340275013
finished 12 epochs...
Completing Train Step...
At time: 483.78104877471924 and batch: 50, loss is 3.8279396009445192 and perplexity is 45.967728730190714
At time: 484.7007348537445 and batch: 100, loss is 3.822661142349243 and perplexity is 45.72572923142145
At time: 485.62863421440125 and batch: 150, loss is 3.7966923570632933 and perplexity is 44.553573193464224
At time: 486.5686180591583 and batch: 200, loss is 3.7914899492263796 and perplexity is 44.32238921321223
At time: 487.5353012084961 and batch: 250, loss is 3.78294527053833 and perplexity is 43.94528206284227
At time: 488.47938227653503 and batch: 300, loss is 3.779913988113403 and perplexity is 43.812273197232955
At time: 489.422123670578 and batch: 350, loss is 3.796110682487488 and perplexity is 44.52766504846142
At time: 490.36477422714233 and batch: 400, loss is 3.7563928842544554 and perplexity is 42.7937851066041
At time: 491.3116533756256 and batch: 450, loss is 3.790845265388489 and perplexity is 44.29382449382557
At time: 492.2608857154846 and batch: 500, loss is 3.8088652229309083 and perplexity is 45.099232243179635
At time: 493.2266631126404 and batch: 550, loss is 3.774225797653198 and perplexity is 43.56376808503893
At time: 494.1748809814453 and batch: 600, loss is 3.75494957447052 and perplexity is 42.7320649692215
At time: 495.13045835494995 and batch: 650, loss is 3.7856981134414673 and perplexity is 44.06642318543307
At time: 496.09226870536804 and batch: 700, loss is 3.8125427198410033 and perplexity is 45.265389865213024
At time: 497.0492744445801 and batch: 750, loss is 3.7827668476104734 and perplexity is 43.93744191640287
At time: 498.0068118572235 and batch: 800, loss is 3.7580690145492555 and perplexity is 42.865573212553166
At time: 499.0014328956604 and batch: 850, loss is 3.7550866174697877 and perplexity is 42.73792150085895
At time: 499.963937997818 and batch: 900, loss is 3.711181740760803 and perplexity is 40.90211367303715
At time: 500.9197082519531 and batch: 950, loss is 3.820799355506897 and perplexity is 45.640676869633474
At time: 501.8791301250458 and batch: 1000, loss is 3.791652889251709 and perplexity is 44.32961169283283
At time: 502.83763551712036 and batch: 1050, loss is 3.7373866844177246 and perplexity is 41.98811845856745
At time: 503.79593539237976 and batch: 1100, loss is 3.761255397796631 and perplexity is 43.00237719613954
At time: 504.7731671333313 and batch: 1150, loss is 3.72978196144104 and perplexity is 41.67002150200382
At time: 505.7314224243164 and batch: 1200, loss is 3.787718620300293 and perplexity is 44.15554970577477
At time: 506.68943452835083 and batch: 1250, loss is 3.7771922731399536 and perplexity is 43.693190804927156
At time: 507.6495633125305 and batch: 1300, loss is 3.7751939868927002 and perplexity is 43.60596648125124
At time: 508.6080846786499 and batch: 1350, loss is 3.663961625099182 and perplexity is 39.015602299899804
At time: 509.5670337677002 and batch: 1400, loss is 3.693532304763794 and perplexity is 40.18654767869059
At time: 510.5252854824066 and batch: 1450, loss is 3.6066120767593386 and perplexity is 36.841026574615924
At time: 511.48612880706787 and batch: 1500, loss is 3.6137535190582275 and perplexity is 37.105066330297916
At time: 512.4470155239105 and batch: 1550, loss is 3.6219735240936277 and perplexity is 37.411327170734005
At time: 513.4079627990723 and batch: 1600, loss is 3.7138387727737427 and perplexity is 41.01093640718509
At time: 514.368305683136 and batch: 1650, loss is 3.6696715450286863 and perplexity is 39.23901549375952
At time: 515.3284845352173 and batch: 1700, loss is 3.6765385818481446 and perplexity is 39.50939856063338
At time: 516.2882335186005 and batch: 1750, loss is 3.673411865234375 and perplexity is 39.3860567956128
At time: 517.2651028633118 and batch: 1800, loss is 3.63262629032135 and perplexity is 37.81199159659446
At time: 518.2239148616791 and batch: 1850, loss is 3.641700949668884 and perplexity is 38.15668415793885
At time: 519.1846261024475 and batch: 1900, loss is 3.7319766998291017 and perplexity is 41.76157673096258
At time: 520.1447021961212 and batch: 1950, loss is 3.664844064712524 and perplexity is 39.050046408095255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.265698809956396 and perplexity of 71.21466810823998
Annealing...
finished 13 epochs...
Completing Train Step...
At time: 523.3281648159027 and batch: 50, loss is 3.8242850589752195 and perplexity is 45.80004432778413
At time: 524.2838492393494 and batch: 100, loss is 3.831053228378296 and perplexity is 46.111078163987784
At time: 525.2256901264191 and batch: 150, loss is 3.8119910526275635 and perplexity is 45.24042532041438
At time: 526.1545805931091 and batch: 200, loss is 3.8120566701889036 and perplexity is 45.243393984195066
At time: 527.1036882400513 and batch: 250, loss is 3.8084682607650757 and perplexity is 45.081333107145944
At time: 528.0500595569611 and batch: 300, loss is 3.80299768447876 and perplexity is 44.8353855860094
At time: 529.0080947875977 and batch: 350, loss is 3.820649676322937 and perplexity is 45.63384592160237
At time: 529.9544537067413 and batch: 400, loss is 3.779956412315369 and perplexity is 43.81413193738715
At time: 530.9011628627777 and batch: 450, loss is 3.8191155862808226 and perplexity is 45.563893163624456
At time: 531.8473162651062 and batch: 500, loss is 3.8350949239730836 and perplexity is 46.2978222326038
At time: 532.8051447868347 and batch: 550, loss is 3.8056149435043336 and perplexity is 44.95288509985795
At time: 533.7539753913879 and batch: 600, loss is 3.781838641166687 and perplexity is 43.896677821367156
At time: 534.7062067985535 and batch: 650, loss is 3.8045658111572265 and perplexity is 44.90574830469571
At time: 535.7017922401428 and batch: 700, loss is 3.828400058746338 and perplexity is 45.98889980333525
At time: 536.6551291942596 and batch: 750, loss is 3.7913358497619627 and perplexity is 44.31555968299979
At time: 537.641895532608 and batch: 800, loss is 3.7658125019073485 and perplexity is 43.19879070452085
At time: 538.6245131492615 and batch: 850, loss is 3.7613266611099245 and perplexity is 43.00544179721356
At time: 539.608633518219 and batch: 900, loss is 3.714221167564392 and perplexity is 41.026621774437075
At time: 540.5770213603973 and batch: 950, loss is 3.830001096725464 and perplexity is 46.06258875220079
At time: 541.5383777618408 and batch: 1000, loss is 3.797094850540161 and perplexity is 44.57150932539165
At time: 542.4990165233612 and batch: 1050, loss is 3.741350464820862 and perplexity is 42.15488042524512
At time: 543.4790644645691 and batch: 1100, loss is 3.760754384994507 and perplexity is 42.980837850836934
At time: 544.4496467113495 and batch: 1150, loss is 3.730422534942627 and perplexity is 41.69672276473621
At time: 545.4084324836731 and batch: 1200, loss is 3.7841856050491334 and perplexity is 43.999822730115476
At time: 546.3862357139587 and batch: 1250, loss is 3.774730978012085 and perplexity is 43.585781204864325
At time: 547.3650093078613 and batch: 1300, loss is 3.7708352422714233 and perplexity is 43.416312835563104
At time: 548.3267176151276 and batch: 1350, loss is 3.6599736547470094 and perplexity is 38.86031907290914
At time: 549.2880158424377 and batch: 1400, loss is 3.692746992111206 and perplexity is 40.15500106293421
At time: 550.2499163150787 and batch: 1450, loss is 3.601885666847229 and perplexity is 36.66731162884617
At time: 551.21071600914 and batch: 1500, loss is 3.6078323125839233 and perplexity is 36.88600875390862
At time: 552.1812086105347 and batch: 1550, loss is 3.6162684631347655 and perplexity is 37.19850093923561
At time: 553.1498634815216 and batch: 1600, loss is 3.7096074628829956 and perplexity is 40.83777303863303
At time: 554.132889509201 and batch: 1650, loss is 3.6563910961151125 and perplexity is 38.721348784616275
At time: 555.1171431541443 and batch: 1700, loss is 3.659684042930603 and perplexity is 38.8490662948637
At time: 556.0784742832184 and batch: 1750, loss is 3.654313898086548 and perplexity is 38.64100035394869
At time: 557.0376102924347 and batch: 1800, loss is 3.615928764343262 and perplexity is 37.1858667994433
At time: 557.9984936714172 and batch: 1850, loss is 3.622960982322693 and perplexity is 37.448287539015645
At time: 558.9589352607727 and batch: 1900, loss is 3.71358784198761 and perplexity is 41.00064679171703
At time: 559.9181180000305 and batch: 1950, loss is 3.6551904106140136 and perplexity is 38.67488452261253
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.253090366097384 and perplexity of 70.32239884741827
finished 14 epochs...
Completing Train Step...
At time: 562.9906871318817 and batch: 50, loss is 3.8248633623123167 and perplexity is 45.8265383062978
At time: 563.9379930496216 and batch: 100, loss is 3.8180237770080567 and perplexity is 45.51417322984651
At time: 564.864025592804 and batch: 150, loss is 3.793902039527893 and perplexity is 44.42942785991663
At time: 565.791570186615 and batch: 200, loss is 3.7900365877151487 and perplexity is 44.25801954617269
At time: 566.7348566055298 and batch: 250, loss is 3.78671281337738 and perplexity is 44.111160075636555
At time: 567.683899641037 and batch: 300, loss is 3.7810118103027346 and perplexity is 43.860397694150855
At time: 568.6323683261871 and batch: 350, loss is 3.7987658977508545 and perplexity is 44.64605268711836
At time: 569.5817952156067 and batch: 400, loss is 3.7597942209243773 and perplexity is 42.93958900062945
At time: 570.5307033061981 and batch: 450, loss is 3.7991476392745973 and perplexity is 44.663099192772755
At time: 571.4800305366516 and batch: 500, loss is 3.8158542680740357 and perplexity is 45.415536859331525
At time: 572.4289486408234 and batch: 550, loss is 3.7856906700134276 and perplexity is 44.06609518140385
At time: 573.37841963768 and batch: 600, loss is 3.7649412727355958 and perplexity is 43.16117104792533
At time: 574.3259811401367 and batch: 650, loss is 3.790341844558716 and perplexity is 44.271531671751376
At time: 575.2877690792084 and batch: 700, loss is 3.8155277442932127 and perplexity is 45.400710027316464
At time: 576.2406103610992 and batch: 750, loss is 3.78106173992157 and perplexity is 43.862587681761866
At time: 577.1993157863617 and batch: 800, loss is 3.7554959774017336 and perplexity is 42.75542027490016
At time: 578.1577017307281 and batch: 850, loss is 3.752163834571838 and perplexity is 42.61319020484649
At time: 579.1170206069946 and batch: 900, loss is 3.705637450218201 and perplexity is 40.67596795909258
At time: 580.0752546787262 and batch: 950, loss is 3.8214395666122436 and perplexity is 45.669905893195356
At time: 581.0483524799347 and batch: 1000, loss is 3.788887372016907 and perplexity is 44.20718674985545
At time: 582.0071911811829 and batch: 1050, loss is 3.7339947414398194 and perplexity is 41.84593842460872
At time: 582.9687745571136 and batch: 1100, loss is 3.7541067838668822 and perplexity is 42.69606595833629
At time: 583.9592089653015 and batch: 1150, loss is 3.723892502784729 and perplexity is 41.42532889393747
At time: 584.932776927948 and batch: 1200, loss is 3.7788508415222166 and perplexity is 43.76571907964183
At time: 585.8938751220703 and batch: 1250, loss is 3.7698585987091064 and perplexity is 43.3739312723419
At time: 586.8532016277313 and batch: 1300, loss is 3.7661049222946166 and perplexity is 43.21142475876567
At time: 587.8112037181854 and batch: 1350, loss is 3.6559059286117552 and perplexity is 38.70256700102376
At time: 588.7665791511536 and batch: 1400, loss is 3.6895668172836302 and perplexity is 40.02750397831572
At time: 589.7251491546631 and batch: 1450, loss is 3.6002766990661623 and perplexity is 36.608362542124816
At time: 590.6831257343292 and batch: 1500, loss is 3.607897386550903 and perplexity is 36.88840915092512
At time: 591.6409974098206 and batch: 1550, loss is 3.6173790311813354 and perplexity is 37.239835353850715
At time: 592.5996825695038 and batch: 1600, loss is 3.71135977268219 and perplexity is 40.90939620316533
At time: 593.5588726997375 and batch: 1650, loss is 3.658884801864624 and perplexity is 38.81802893052617
At time: 594.517005443573 and batch: 1700, loss is 3.6629150342941283 and perplexity is 38.97479028974167
At time: 595.4823656082153 and batch: 1750, loss is 3.658585352897644 and perplexity is 38.80640665208921
At time: 596.4441208839417 and batch: 1800, loss is 3.6206947326660157 and perplexity is 37.363516462729685
At time: 597.4024279117584 and batch: 1850, loss is 3.628087115287781 and perplexity is 37.640745300856125
At time: 598.3782997131348 and batch: 1900, loss is 3.718781886100769 and perplexity is 41.21415997826141
At time: 599.3376059532166 and batch: 1950, loss is 3.659726595878601 and perplexity is 38.85071947233506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251941769622093 and perplexity of 70.24167315746453
finished 15 epochs...
Completing Train Step...
At time: 602.4365148544312 and batch: 50, loss is 3.8208033990859986 and perplexity is 45.64086142169378
At time: 603.3875241279602 and batch: 100, loss is 3.812053527832031 and perplexity is 45.243251813528424
At time: 604.3130581378937 and batch: 150, loss is 3.787203993797302 and perplexity is 44.13283193572671
At time: 605.2452576160431 and batch: 200, loss is 3.782389283180237 and perplexity is 43.920855832534336
At time: 606.1776759624481 and batch: 250, loss is 3.7789425611495973 and perplexity is 43.76973343918283
At time: 607.1399879455566 and batch: 300, loss is 3.7729098701477053 and perplexity is 43.50647902676381
At time: 608.0820307731628 and batch: 350, loss is 3.7907807540893557 and perplexity is 44.29096713383088
At time: 609.0249180793762 and batch: 400, loss is 3.7517746257781983 and perplexity is 42.596608003672294
At time: 609.9683427810669 and batch: 450, loss is 3.7915748023986815 and perplexity is 44.32615026810743
At time: 610.9095108509064 and batch: 500, loss is 3.80833824634552 and perplexity is 45.075472264794485
At time: 611.8515448570251 and batch: 550, loss is 3.777990627288818 and perplexity is 43.72808737313991
At time: 612.7999560832977 and batch: 600, loss is 3.7580009794235227 and perplexity is 42.86265694709541
At time: 613.7480747699738 and batch: 650, loss is 3.7838214302062987 and perplexity is 43.98380201893503
At time: 614.695606470108 and batch: 700, loss is 3.8095967531204225 and perplexity is 45.13223576315326
At time: 615.6449880599976 and batch: 750, loss is 3.775614881515503 and perplexity is 43.62432386105552
At time: 616.5953888893127 and batch: 800, loss is 3.7499588537216186 and perplexity is 42.519332451779675
At time: 617.5547924041748 and batch: 850, loss is 3.746789393424988 and perplexity is 42.38478245380767
At time: 618.5144453048706 and batch: 900, loss is 3.7007323551177977 and perplexity is 40.476936999899884
At time: 619.4741470813751 and batch: 950, loss is 3.816563506126404 and perplexity is 45.447758711371996
At time: 620.4333131313324 and batch: 1000, loss is 3.7844446229934694 and perplexity is 44.01122094985818
At time: 621.3929636478424 and batch: 1050, loss is 3.7302950716018675 and perplexity is 41.691408299860804
At time: 622.3518311977386 and batch: 1100, loss is 3.7504804277420045 and perplexity is 42.541515215424404
At time: 623.3108870983124 and batch: 1150, loss is 3.720660014152527 and perplexity is 41.29163818246608
At time: 624.2690114974976 and batch: 1200, loss is 3.7759821701049803 and perplexity is 43.640349520274086
At time: 625.2275950908661 and batch: 1250, loss is 3.767339782714844 and perplexity is 43.26481779659163
At time: 626.1855525970459 and batch: 1300, loss is 3.7638001346588137 and perplexity is 43.11194628367214
At time: 627.1449983119965 and batch: 1350, loss is 3.653867635726929 and perplexity is 38.62376017705982
At time: 628.1031444072723 and batch: 1400, loss is 3.687872667312622 and perplexity is 39.959748793539084
At time: 629.0616481304169 and batch: 1450, loss is 3.599125099182129 and perplexity is 36.56622862143219
At time: 630.0194375514984 and batch: 1500, loss is 3.607275686264038 and perplexity is 36.86548274378938
At time: 630.9778423309326 and batch: 1550, loss is 3.617243185043335 and perplexity is 37.23477680963776
At time: 631.933788061142 and batch: 1600, loss is 3.711555676460266 and perplexity is 40.917411293507946
At time: 632.8918943405151 and batch: 1650, loss is 3.6593555068969725 and perplexity is 38.83630507308831
At time: 633.8507761955261 and batch: 1700, loss is 3.66366557598114 and perplexity is 39.004053474843126
At time: 634.8103640079498 and batch: 1750, loss is 3.659709949493408 and perplexity is 38.85007275367648
At time: 635.7668349742889 and batch: 1800, loss is 3.622058935165405 and perplexity is 37.414522648746924
At time: 636.7228870391846 and batch: 1850, loss is 3.62955548286438 and perplexity is 37.69605634935202
At time: 637.6799170970917 and batch: 1900, loss is 3.720129942893982 and perplexity is 41.26975647179263
At time: 638.6361062526703 and batch: 1950, loss is 3.660741868019104 and perplexity is 38.89018355545599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251698196765989 and perplexity of 70.2245662759866
finished 16 epochs...
Completing Train Step...
At time: 641.7148199081421 and batch: 50, loss is 3.8165669345855715 and perplexity is 45.4479145274241
At time: 642.6347172260284 and batch: 100, loss is 3.807078719139099 and perplexity is 45.01873422019092
At time: 643.564760684967 and batch: 150, loss is 3.781948490142822 and perplexity is 43.90150009133744
At time: 644.4962940216064 and batch: 200, loss is 3.776739273071289 and perplexity is 43.67340226893484
At time: 645.4278964996338 and batch: 250, loss is 3.773275499343872 and perplexity is 43.522389174148365
At time: 646.3694581985474 and batch: 300, loss is 3.7670449447631835 and perplexity is 43.25206356664144
At time: 647.3108808994293 and batch: 350, loss is 3.7850980806350707 and perplexity is 44.03998981709842
At time: 648.2518815994263 and batch: 400, loss is 3.7460336685180664 and perplexity is 42.35276331838585
At time: 649.1966924667358 and batch: 450, loss is 3.7861792993545533 and perplexity is 44.08763242989558
At time: 650.1448056697845 and batch: 500, loss is 3.803011336326599 and perplexity is 44.83599767604931
At time: 651.0940155982971 and batch: 550, loss is 3.7725961112976076 and perplexity is 43.49283062519793
At time: 652.0421099662781 and batch: 600, loss is 3.7530359506607054 and perplexity is 42.65037006384215
At time: 652.9901361465454 and batch: 650, loss is 3.7790672731399537 and perplexity is 43.775192390148646
At time: 653.947242975235 and batch: 700, loss is 3.8052562046051026 and perplexity is 44.93676164356837
At time: 654.944700717926 and batch: 750, loss is 3.771445646286011 and perplexity is 43.44282241717093
At time: 655.8991222381592 and batch: 800, loss is 3.7457758378982544 and perplexity is 42.34184488678219
At time: 656.849246263504 and batch: 850, loss is 3.7426920557022094 and perplexity is 42.2114729819687
At time: 657.8001718521118 and batch: 900, loss is 3.696943244934082 and perplexity is 40.32385562995045
At time: 658.7509524822235 and batch: 950, loss is 3.812812714576721 and perplexity is 45.27761293219446
At time: 659.7010011672974 and batch: 1000, loss is 3.7809731912612916 and perplexity is 43.858703880341544
At time: 660.6521816253662 and batch: 1050, loss is 3.727315654754639 and perplexity is 41.56737707769528
At time: 661.6195888519287 and batch: 1100, loss is 3.7475729417800903 and perplexity is 42.41800599480638
At time: 662.5986015796661 and batch: 1150, loss is 3.7180201768875123 and perplexity is 41.182778726101056
At time: 663.5744204521179 and batch: 1200, loss is 3.773499159812927 and perplexity is 43.53212450078873
At time: 664.5322914123535 and batch: 1250, loss is 3.7651917695999146 and perplexity is 43.17198414019948
At time: 665.4904437065125 and batch: 1300, loss is 3.7618013525009157 and perplexity is 43.02586095621654
At time: 666.4481265544891 and batch: 1350, loss is 3.652017812728882 and perplexity is 38.55237909874797
At time: 667.4062743186951 and batch: 1400, loss is 3.686234755516052 and perplexity is 39.89435182145853
At time: 668.3653178215027 and batch: 1450, loss is 3.597759370803833 and perplexity is 36.51632317171811
At time: 669.3238732814789 and batch: 1500, loss is 3.606181683540344 and perplexity is 36.82517385829293
At time: 670.2826814651489 and batch: 1550, loss is 3.6164638328552248 and perplexity is 37.20576910993273
At time: 671.2410793304443 and batch: 1600, loss is 3.711048097610474 and perplexity is 40.89664775096041
At time: 672.1991305351257 and batch: 1650, loss is 3.65898756980896 and perplexity is 38.82201838455301
At time: 673.1752438545227 and batch: 1700, loss is 3.663502869606018 and perplexity is 38.99770778294343
At time: 674.1335155963898 and batch: 1750, loss is 3.6597485017776488 and perplexity is 38.85157054159543
At time: 675.0900483131409 and batch: 1800, loss is 3.6223060989379885 and perplexity is 37.423771306233654
At time: 676.0479860305786 and batch: 1850, loss is 3.62989396572113 and perplexity is 37.70881797786776
At time: 677.0050940513611 and batch: 1900, loss is 3.7203650856018067 and perplexity is 41.279461895115716
At time: 677.9626083374023 and batch: 1950, loss is 3.660802888870239 and perplexity is 38.89255673996348
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.251725449672965 and perplexity of 70.22648012563765
Annealing...
finished 17 epochs...
Completing Train Step...
At time: 681.0619945526123 and batch: 50, loss is 3.8160025453567505 and perplexity is 45.4222714510112
At time: 681.9829382896423 and batch: 100, loss is 3.8105930614471437 and perplexity is 45.17722379270048
At time: 682.9096639156342 and batch: 150, loss is 3.7871273279190065 and perplexity is 44.1294485831002
At time: 683.8397300243378 and batch: 200, loss is 3.7825950050354002 and perplexity is 43.929892241938155
At time: 684.7795033454895 and batch: 250, loss is 3.780660181045532 and perplexity is 43.84497780628979
At time: 685.7220728397369 and batch: 300, loss is 3.774290132522583 and perplexity is 43.5665708445252
At time: 686.6643328666687 and batch: 350, loss is 3.7940425205230714 and perplexity is 44.4356697885835
At time: 687.6069145202637 and batch: 400, loss is 3.7556701040267946 and perplexity is 42.76286578014724
At time: 688.5468616485596 and batch: 450, loss is 3.7971319246292112 and perplexity is 44.57316180412937
At time: 689.4881112575531 and batch: 500, loss is 3.8140357637405398 and perplexity is 45.33302355688282
At time: 690.4305272102356 and batch: 550, loss is 3.78599063873291 and perplexity is 44.07931561430704
At time: 691.3827760219574 and batch: 600, loss is 3.766810026168823 and perplexity is 43.241904046042045
At time: 692.3401663303375 and batch: 650, loss is 3.7909459686279297 and perplexity is 44.29828525004184
At time: 693.2967216968536 and batch: 700, loss is 3.818243885040283 and perplexity is 45.52419236756044
At time: 694.2535674571991 and batch: 750, loss is 3.7795852756500246 and perplexity is 43.79787392372407
At time: 695.2103962898254 and batch: 800, loss is 3.751412854194641 and perplexity is 42.58120054849841
At time: 696.1651568412781 and batch: 850, loss is 3.747478895187378 and perplexity is 42.41401691345562
At time: 697.1193597316742 and batch: 900, loss is 3.6996873092651366 and perplexity is 40.43465883991532
At time: 698.07528424263 and batch: 950, loss is 3.8169261503219603 and perplexity is 45.46424306606684
At time: 699.0321052074432 and batch: 1000, loss is 3.785351724624634 and perplexity is 44.05116171259814
At time: 699.9879398345947 and batch: 1050, loss is 3.7306956481933593 and perplexity is 41.7081122474739
At time: 700.9444444179535 and batch: 1100, loss is 3.7470072889328003 and perplexity is 42.394018913758984
At time: 701.9408566951752 and batch: 1150, loss is 3.7181630611419676 and perplexity is 41.18866351714772
At time: 702.8969285488129 and batch: 1200, loss is 3.770786008834839 and perplexity is 43.414175353896596
At time: 703.8534367084503 and batch: 1250, loss is 3.7649637269973755 and perplexity is 43.16214021103964
At time: 704.8097167015076 and batch: 1300, loss is 3.760784158706665 and perplexity is 42.982117568982304
At time: 705.7675206661224 and batch: 1350, loss is 3.6484145164489745 and perplexity is 38.413713431334905
At time: 706.7235856056213 and batch: 1400, loss is 3.6827113914489744 and perplexity is 39.75403683132553
At time: 707.6796002388 and batch: 1450, loss is 3.591814250946045 and perplexity is 36.29987330143232
At time: 708.6378796100616 and batch: 1500, loss is 3.598968710899353 and perplexity is 36.560510538862694
At time: 709.605836391449 and batch: 1550, loss is 3.610123734474182 and perplexity is 36.97062707292101
At time: 710.5636096000671 and batch: 1600, loss is 3.706735677719116 and perplexity is 40.72066396443039
At time: 711.5385093688965 and batch: 1650, loss is 3.651710252761841 and perplexity is 38.54052375351125
At time: 712.4964234828949 and batch: 1700, loss is 3.6554507875442503 and perplexity is 38.684955881439635
At time: 713.4543242454529 and batch: 1750, loss is 3.65174515247345 and perplexity is 38.54186883014677
At time: 714.412392616272 and batch: 1800, loss is 3.612129373550415 and perplexity is 37.04485121579087
At time: 715.3718223571777 and batch: 1850, loss is 3.620239939689636 and perplexity is 37.34652766135619
At time: 716.3379039764404 and batch: 1900, loss is 3.710005044937134 and perplexity is 40.854012632395765
At time: 717.2995502948761 and batch: 1950, loss is 3.6523157262802126 and perplexity is 38.56386608589714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.249601994004361 and perplexity of 70.07751552416669
finished 18 epochs...
Completing Train Step...
At time: 720.4109737873077 and batch: 50, loss is 3.815300951004028 and perplexity is 45.390414618467
At time: 721.3282079696655 and batch: 100, loss is 3.807584285736084 and perplexity is 45.04149994276073
At time: 722.2509837150574 and batch: 150, loss is 3.7823142862319945 and perplexity is 43.91756202589697
At time: 723.1781544685364 and batch: 200, loss is 3.7768786334991455 and perplexity is 43.67948903707843
At time: 724.1046731472015 and batch: 250, loss is 3.77435537815094 and perplexity is 43.5694134655486
At time: 725.0394086837769 and batch: 300, loss is 3.7676169776916506 and perplexity is 43.276812249081495
At time: 726.0072603225708 and batch: 350, loss is 3.7869693756103517 and perplexity is 44.12247878527915
At time: 726.9517483711243 and batch: 400, loss is 3.7493022727966308 and perplexity is 42.49142423215355
At time: 727.8954350948334 and batch: 450, loss is 3.7903649520874025 and perplexity is 44.27255468925913
At time: 728.8575298786163 and batch: 500, loss is 3.8073788404464723 and perplexity is 45.03224732924592
At time: 729.8035717010498 and batch: 550, loss is 3.7785316371917723 and perplexity is 43.75175110202467
At time: 730.7534439563751 and batch: 600, loss is 3.759736943244934 and perplexity is 42.93712959105054
At time: 731.7026100158691 and batch: 650, loss is 3.78435275554657 and perplexity is 44.00717793706806
At time: 732.6511280536652 and batch: 700, loss is 3.8117863845825197 and perplexity is 45.231166998480745
At time: 733.6003448963165 and batch: 750, loss is 3.774721541404724 and perplexity is 43.58536990490122
At time: 734.5492579936981 and batch: 800, loss is 3.747280378341675 and perplexity is 42.40559785229473
At time: 735.4976048469543 and batch: 850, loss is 3.743785467147827 and perplexity is 42.25765273179622
At time: 736.4471151828766 and batch: 900, loss is 3.696126117706299 and perplexity is 40.29091936797686
At time: 737.3951473236084 and batch: 950, loss is 3.813609070777893 and perplexity is 45.31368440098987
At time: 738.3525674343109 and batch: 1000, loss is 3.782082233428955 and perplexity is 43.90737201488225
At time: 739.3116567134857 and batch: 1050, loss is 3.727731690406799 and perplexity is 41.58467418638384
At time: 740.2695741653442 and batch: 1100, loss is 3.74483247756958 and perplexity is 42.30192010476171
At time: 741.2283308506012 and batch: 1150, loss is 3.715817971229553 and perplexity is 41.09218556677652
At time: 742.184410572052 and batch: 1200, loss is 3.769212064743042 and perplexity is 43.345897615864665
At time: 743.1408851146698 and batch: 1250, loss is 3.763312463760376 and perplexity is 43.09092696776548
At time: 744.0984342098236 and batch: 1300, loss is 3.7589243698120116 and perplexity is 42.90225419158939
At time: 745.0570931434631 and batch: 1350, loss is 3.647273454666138 and perplexity is 38.36990600924233
At time: 746.0164318084717 and batch: 1400, loss is 3.682386212348938 and perplexity is 39.7411117510028
At time: 746.9754450321198 and batch: 1450, loss is 3.592029685974121 and perplexity is 36.30769440809609
At time: 747.9339823722839 and batch: 1500, loss is 3.6002825260162354 and perplexity is 36.60857585784709
At time: 748.8924922943115 and batch: 1550, loss is 3.611822681427002 and perplexity is 37.03349159375232
At time: 749.8509278297424 and batch: 1600, loss is 3.7086522912979127 and perplexity is 40.79878458152592
At time: 750.8098106384277 and batch: 1650, loss is 3.653809609413147 and perplexity is 38.62151904765522
At time: 751.7683389186859 and batch: 1700, loss is 3.6577630758285524 and perplexity is 38.77451014944391
At time: 752.7273178100586 and batch: 1750, loss is 3.6544442653656004 and perplexity is 38.64603820440299
At time: 753.6861343383789 and batch: 1800, loss is 3.615258822441101 and perplexity is 37.160962772163344
At time: 754.6454408168793 and batch: 1850, loss is 3.6236048698425294 and perplexity is 37.47240778853175
At time: 755.6042633056641 and batch: 1900, loss is 3.713276953697205 and perplexity is 40.98790215191274
At time: 756.5629577636719 and batch: 1950, loss is 3.655039110183716 and perplexity is 38.669033438589466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.248927768441134 and perplexity of 70.03028339613616
finished 19 epochs...
Completing Train Step...
At time: 759.6553630828857 and batch: 50, loss is 3.8144669675827028 and perplexity is 45.35257554596087
At time: 760.6133832931519 and batch: 100, loss is 3.8057018613815305 and perplexity is 44.956792479012805
At time: 761.5363419055939 and batch: 150, loss is 3.7798602533340455 and perplexity is 43.80991901765077
At time: 762.4690175056458 and batch: 200, loss is 3.773978409767151 and perplexity is 43.55299226950219
At time: 763.4044780731201 and batch: 250, loss is 3.7711784744262697 and perplexity is 43.43121726786703
At time: 764.3470997810364 and batch: 300, loss is 3.7644240617752076 and perplexity is 43.13885338916253
At time: 765.2895336151123 and batch: 350, loss is 3.7835944509506225 and perplexity is 43.973819741218804
At time: 766.2317264080048 and batch: 400, loss is 3.746081380844116 and perplexity is 42.35478411544648
At time: 767.1744871139526 and batch: 450, loss is 3.78705463886261 and perplexity is 44.12624097170392
At time: 768.1176679134369 and batch: 500, loss is 3.804174485206604 and perplexity is 44.88817895794683
At time: 769.0619142055511 and batch: 550, loss is 3.7749650716781615 and perplexity is 43.595985554515586
At time: 770.0056915283203 and batch: 600, loss is 3.7564228630065917 and perplexity is 42.795068030110905
At time: 770.9514524936676 and batch: 650, loss is 3.7812265586853027 and perplexity is 43.86981765503895
At time: 771.9006724357605 and batch: 700, loss is 3.8089417219161987 and perplexity is 45.10268242064947
At time: 772.8494398593903 and batch: 750, loss is 3.7724299144744875 and perplexity is 43.48560285555234
At time: 773.8231325149536 and batch: 800, loss is 3.7451651668548585 and perplexity is 42.31599584162086
At time: 774.7716500759125 and batch: 850, loss is 3.741773419380188 and perplexity is 42.172713795205546
At time: 775.720142364502 and batch: 900, loss is 3.6942511987686157 and perplexity is 40.21544793375667
At time: 776.689297914505 and batch: 950, loss is 3.811815843582153 and perplexity is 45.23249948303951
At time: 777.6424524784088 and batch: 1000, loss is 3.780349140167236 and perplexity is 43.83134234658667
At time: 778.6136910915375 and batch: 1050, loss is 3.726232657432556 and perplexity is 41.5223840876756
At time: 779.5874164104462 and batch: 1100, loss is 3.7436370277404785 and perplexity is 42.25138049640374
At time: 780.5362691879272 and batch: 1150, loss is 3.7146951150894165 and perplexity is 41.04607084884346
At time: 781.4850044250488 and batch: 1200, loss is 3.7684227657318115 and perplexity is 43.31169824027772
At time: 782.4344744682312 and batch: 1250, loss is 3.7625012493133543 and perplexity is 43.05598515983956
At time: 783.3862812519073 and batch: 1300, loss is 3.758156065940857 and perplexity is 42.869304882774294
At time: 784.3454480171204 and batch: 1350, loss is 3.6468449878692626 and perplexity is 38.353469300061676
At time: 785.3044474124908 and batch: 1400, loss is 3.682277970314026 and perplexity is 39.73681032499895
At time: 786.2628943920135 and batch: 1450, loss is 3.5922459506988527 and perplexity is 36.31554733075736
At time: 787.2206869125366 and batch: 1500, loss is 3.6009984827041626 and perplexity is 36.634795397475386
At time: 788.1788346767426 and batch: 1550, loss is 3.6127848768234254 and perplexity is 37.06914219755024
At time: 789.1371879577637 and batch: 1600, loss is 3.7096910953521727 and perplexity is 40.84118854524958
At time: 790.0933775901794 and batch: 1650, loss is 3.6548956346511843 and perplexity is 38.663485776410795
At time: 791.050665140152 and batch: 1700, loss is 3.6589633131027224 and perplexity is 38.82107670167862
At time: 792.0074408054352 and batch: 1750, loss is 3.655809550285339 and perplexity is 38.69883709213227
At time: 792.9664273262024 and batch: 1800, loss is 3.616745057106018 and perplexity is 37.216233745861594
At time: 793.9252896308899 and batch: 1850, loss is 3.625141773223877 and perplexity is 37.5300435377131
At time: 794.8839054107666 and batch: 1900, loss is 3.7147008275985716 and perplexity is 41.04630532556869
At time: 795.8429162502289 and batch: 1950, loss is 3.6561183643341066 and perplexity is 38.71078968216616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 216 batches
Done Evaluating: Achieved loss of 4.2486487100290695 and perplexity of 70.01074358295664
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f05ce5c4b38>
ELAPSED
5035.967682361603


RESULTS SO FAR:
[{'best_accuracy': -70.031277428607, 'params': {'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.29541346180265, 'params': {'tie_weights': True, 'rnn_dropout': 0.7288706260952753, 'num_layers': 2, 'dropout': 0.4475108336446092, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.10525313217852, 'params': {'tie_weights': True, 'rnn_dropout': 0.8506975178466405, 'num_layers': 2, 'dropout': 0.6098755685920833, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -72.46967563165478, 'params': {'tie_weights': True, 'rnn_dropout': 0.3930815480094526, 'num_layers': 2, 'dropout': 0.9281289718292313, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.21954266880334, 'params': {'tie_weights': True, 'rnn_dropout': 0.5551850193968754, 'num_layers': 2, 'dropout': 0.6113123772309402, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.01074358295664, 'params': {'tie_weights': True, 'rnn_dropout': 0.4150335755013944, 'num_layers': 2, 'dropout': 0.2817202687527763, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}]
here
Saving Model Parameters and Results...
/home-nfs/siddsach/ml/Interpreting-Attention/interpreting_language/trained_models/langmodel/



FINAL RESULTS:
[{'best_accuracy': -70.031277428607, 'params': {'tie_weights': True, 'rnn_dropout': 0.42948609121812287, 'num_layers': 2, 'dropout': 0.042393021980322354, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.29541346180265, 'params': {'tie_weights': True, 'rnn_dropout': 0.7288706260952753, 'num_layers': 2, 'dropout': 0.4475108336446092, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.10525313217852, 'params': {'tie_weights': True, 'rnn_dropout': 0.8506975178466405, 'num_layers': 2, 'dropout': 0.6098755685920833, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -72.46967563165478, 'params': {'tie_weights': True, 'rnn_dropout': 0.3930815480094526, 'num_layers': 2, 'dropout': 0.9281289718292313, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.21954266880334, 'params': {'tie_weights': True, 'rnn_dropout': 0.5551850193968754, 'num_layers': 2, 'dropout': 0.6113123772309402, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}, {'best_accuracy': -70.01074358295664, 'params': {'tie_weights': True, 'rnn_dropout': 0.4150335755013944, 'num_layers': 2, 'dropout': 0.2817202687527763, 'data': 'wikitext', 'wordvec_dim': 300, 'wordvec_source': 'glove', 'batch_size': 32, 'seq_len': 35, 'tune_wordvecs': True}}]
